09:59:33,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:59:58,970 root INFO 
id:en_de cur r: 0.1111 best r: 0.1111
10:00:11,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:37,624 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:00:37,630 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:01:03,422 root INFO Epoch 0 Global steps: 200 Train loss: 1.1142
en_de Dev loss: 0.8823 r:0.1130
en_zh Dev loss: 0.8143 r:0.1399
Current avg r:0.1264 Best avg r: 0.1264
10:02:19,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:45,446 root INFO 
id:en_de cur r: 0.1152 best r: 0.1152
10:03:11,257 root INFO 
id:en_zh cur r: 0.1578 best r: 0.1578
10:03:11,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:37,70 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:03:37,94 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:04:02,918 root INFO Epoch 0 Global steps: 400 Train loss: 1.2382
en_de Dev loss: 0.8850 r:0.1070
en_zh Dev loss: 0.8151 r:0.1791
Current avg r:0.1431 Best avg r: 0.1431
10:05:18,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:44,797 root INFO 
id:en_de cur r: 0.1155 best r: 0.1155
10:06:10,599 root INFO 
id:en_zh cur r: 0.1968 best r: 0.1968
10:06:10,599 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:36,410 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:06:36,417 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:07:02,214 root INFO Epoch 0 Global steps: 600 Train loss: 1.1394
en_de Dev loss: 0.8829 r:0.1072
en_zh Dev loss: 0.8094 r:0.2220
Current avg r:0.1646 Best avg r: 0.1646
10:08:18,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:44,185 root INFO 
id:en_de cur r: 0.1329 best r: 0.1329
10:09:09,998 root INFO 
id:en_zh cur r: 0.2294 best r: 0.2294
10:09:09,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:35,804 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:09:36,106 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:10:02,84 root INFO Epoch 0 Global steps: 800 Train loss: 1.2263
en_de Dev loss: 0.8825 r:0.1264
en_zh Dev loss: 0.7998 r:0.2813
Current avg r:0.2038 Best avg r: 0.2038
10:11:17,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:43,821 root INFO 
id:en_de cur r: 0.1433 best r: 0.1433
10:12:09,624 root INFO 
id:en_zh cur r: 0.2736 best r: 0.2736
10:12:09,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:35,452 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:12:35,458 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:13:01,264 root INFO Epoch 0 Global steps: 1000 Train loss: 1.0681
en_de Dev loss: 0.8813 r:0.1215
en_zh Dev loss: 0.7911 r:0.3172
Current avg r:0.2194 Best avg r: 0.2194
10:14:17,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:43,267 root INFO 
id:en_de cur r: 0.1545 best r: 0.1545
10:14:56,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:21,945 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:15:21,951 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:15:47,780 root INFO Epoch 0 Global steps: 1200 Train loss: 1.0878
en_de Dev loss: 0.8745 r:0.1381
en_zh Dev loss: 0.7739 r:0.3364
Current avg r:0.2373 Best avg r: 0.2373
10:17:03,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:17:42,585 root INFO 
id:en_zh cur r: 0.3172 best r: 0.3172
10:17:42,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:18:08,378 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:18:08,384 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:18:34,214 root INFO Epoch 0 Global steps: 1400 Train loss: 1.1176
en_de Dev loss: 0.8849 r:0.1515
en_zh Dev loss: 0.7790 r:0.3313
Current avg r:0.2414 Best avg r: 0.2414
10:19:50,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:29,96 root INFO 
id:en_zh cur r: 0.3310 best r: 0.3310
10:20:29,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:54,920 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:20:54,925 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:21:20,746 root INFO Epoch 0 Global steps: 1600 Train loss: 0.9829
en_de Dev loss: 0.8671 r:0.1525
en_zh Dev loss: 0.7481 r:0.3502
Current avg r:0.2514 Best avg r: 0.2514
10:22:36,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:23:02,777 root INFO 
id:en_de cur r: 0.1665 best r: 0.1665
10:23:28,689 root INFO 
id:en_zh cur r: 0.3492 best r: 0.3492
10:23:28,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:54,594 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:23:54,602 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:24:20,545 root INFO Epoch 0 Global steps: 1800 Train loss: 0.9894
en_de Dev loss: 0.8683 r:0.1673
en_zh Dev loss: 0.7549 r:0.3470
Current avg r:0.2571 Best avg r: 0.2571
10:25:36,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:26:03,38 root INFO 
id:en_de cur r: 0.1694 best r: 0.1694
10:26:29,157 root INFO 
id:en_zh cur r: 0.3578 best r: 0.3578
10:26:29,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:55,201 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:26:55,209 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:27:21,147 root INFO Epoch 0 Global steps: 2000 Train loss: 1.1605
en_de Dev loss: 0.8776 r:0.1883
en_zh Dev loss: 0.7637 r:0.3521
Current avg r:0.2702 Best avg r: 0.2702
10:28:37,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:03,986 root INFO 
id:en_de cur r: 0.1708 best r: 0.1708
10:29:29,976 root INFO 
id:en_zh cur r: 0.3851 best r: 0.3851
10:29:29,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:55,975 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:29:55,982 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:30:21,964 root INFO Epoch 0 Global steps: 2200 Train loss: 1.1285
en_de Dev loss: 0.8819 r:0.1793
en_zh Dev loss: 0.7330 r:0.3899
Current avg r:0.2846 Best avg r: 0.2846
10:31:38,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:32:04,885 root INFO 
id:en_de cur r: 0.1715 best r: 0.1715
10:32:30,879 root INFO 
id:en_zh cur r: 0.3988 best r: 0.3988
10:32:30,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:32:56,870 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:32:56,877 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:33:22,875 root INFO Epoch 0 Global steps: 2400 Train loss: 0.9942
en_de Dev loss: 0.8564 r:0.2134
en_zh Dev loss: 0.7324 r:0.3855
Current avg r:0.2995 Best avg r: 0.2995
10:34:39,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:35:18,679 root INFO 
id:en_zh cur r: 0.4098 best r: 0.4098
10:35:18,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:35:44,698 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:35:44,704 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:36:10,677 root INFO Epoch 0 Global steps: 2600 Train loss: 0.9929
en_de Dev loss: 0.8634 r:0.2183
en_zh Dev loss: 0.7316 r:0.3921
Current avg r:0.3052 Best avg r: 0.3052
10:37:27,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:37:53,635 root INFO 
id:en_de cur r: 0.1752 best r: 0.1752
10:38:19,574 root INFO 
id:en_zh cur r: 0.4187 best r: 0.4187
10:38:19,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:38:45,589 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:38:45,597 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:39:11,594 root INFO Epoch 0 Global steps: 2800 Train loss: 0.9381
en_de Dev loss: 0.8743 r:0.2134
en_zh Dev loss: 0.7327 r:0.4008
Current avg r:0.3071 Best avg r: 0.3071
10:40:28,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:40:54,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:41:20,454 root INFO Epoch 0 Global steps: 3000 Train loss: 1.3097
en_de Dev loss: 0.8549 r:0.1983
en_zh Dev loss: 0.7047 r:0.4117
Current avg r:0.3050 Best avg r: 0.3071
10:42:37,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:43:03,867 root INFO 
id:en_de cur r: 0.1790 best r: 0.1790
10:43:16,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:43:42,785 root INFO Epoch 1 Global steps: 3200 Train loss: 0.9932
en_de Dev loss: 0.8882 r:0.2118
en_zh Dev loss: 0.8001 r:0.3875
Current avg r:0.2996 Best avg r: 0.3071
10:44:59,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:45:38,592 root INFO 
id:en_zh cur r: 0.4422 best r: 0.4422
10:45:38,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:46:04,608 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:46:04,614 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:46:30,514 root INFO Epoch 1 Global steps: 3400 Train loss: 1.0389
en_de Dev loss: 0.8629 r:0.2190
en_zh Dev loss: 0.6984 r:0.4323
Current avg r:0.3257 Best avg r: 0.3257
10:47:47,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:48:13,434 root INFO 
id:en_de cur r: 0.1798 best r: 0.1798
10:48:39,389 root INFO 
id:en_zh cur r: 0.4428 best r: 0.4428
10:48:39,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:49:05,370 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:49:05,379 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:49:31,415 root INFO Epoch 1 Global steps: 3600 Train loss: 1.0452
en_de Dev loss: 0.8544 r:0.2117
en_zh Dev loss: 0.6871 r:0.4423
Current avg r:0.3270 Best avg r: 0.3270
10:50:48,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:51:14,168 root INFO 
id:en_de cur r: 0.2009 best r: 0.2009
10:51:40,164 root INFO 
id:en_zh cur r: 0.4481 best r: 0.4481
10:51:40,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:52:06,62 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:52:06,69 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:52:32,85 root INFO Epoch 1 Global steps: 3800 Train loss: 0.8369
en_de Dev loss: 0.8545 r:0.2201
en_zh Dev loss: 0.7094 r:0.4445
Current avg r:0.3323 Best avg r: 0.3323
10:53:48,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:54:15,0 root INFO 
id:en_de cur r: 0.2127 best r: 0.2127
10:54:41,2 root INFO 
id:en_zh cur r: 0.4683 best r: 0.4683
10:54:41,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:55:06,959 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:55:07,244 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:55:33,270 root INFO Epoch 1 Global steps: 4000 Train loss: 0.8613
en_de Dev loss: 0.8392 r:0.2372
en_zh Dev loss: 0.6463 r:0.4639
Current avg r:0.3506 Best avg r: 0.3506
10:56:50,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:57:16,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:57:42,255 root INFO Epoch 1 Global steps: 4200 Train loss: 1.1095
en_de Dev loss: 0.8388 r:0.2392
en_zh Dev loss: 0.6487 r:0.4613
Current avg r:0.3503 Best avg r: 0.3506
10:58:59,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:59:25,212 root INFO 
id:en_de cur r: 0.2138 best r: 0.2138
10:59:51,314 root INFO 
id:en_zh cur r: 0.4766 best r: 0.4766
10:59:51,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:00:17,331 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:00:17,338 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:00:43,298 root INFO Epoch 1 Global steps: 4400 Train loss: 1.0653
en_de Dev loss: 0.8479 r:0.2280
en_zh Dev loss: 0.6572 r:0.4776
Current avg r:0.3528 Best avg r: 0.3528
11:02:00,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:02:26,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:02:52,5 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:02:52,12 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:03:18,56 root INFO Epoch 1 Global steps: 4600 Train loss: 0.8541
en_de Dev loss: 0.8371 r:0.2410
en_zh Dev loss: 0.6504 r:0.4668
Current avg r:0.3539 Best avg r: 0.3539
11:04:35,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:05:01,16 root INFO 
id:en_de cur r: 0.2224 best r: 0.2224
11:05:14,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:05:40,14 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:05:40,20 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:06:05,962 root INFO Epoch 1 Global steps: 4800 Train loss: 0.9710
en_de Dev loss: 0.8676 r:0.2491
en_zh Dev loss: 0.7064 r:0.4704
Current avg r:0.3598 Best avg r: 0.3598
11:07:22,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:08:01,675 root INFO 
id:en_zh cur r: 0.4773 best r: 0.4773
11:08:01,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:08:27,631 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:08:27,637 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:08:53,666 root INFO Epoch 1 Global steps: 5000 Train loss: 0.9460
en_de Dev loss: 0.8335 r:0.2457
en_zh Dev loss: 0.6381 r:0.4779
Current avg r:0.3618 Best avg r: 0.3618
11:10:10,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:10:49,571 root INFO 
id:en_zh cur r: 0.4835 best r: 0.4835
11:10:49,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:11:15,516 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:11:15,521 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:11:41,403 root INFO Epoch 1 Global steps: 5200 Train loss: 0.9252
en_de Dev loss: 0.8424 r:0.2439
en_zh Dev loss: 0.6619 r:0.4835
Current avg r:0.3637 Best avg r: 0.3637
11:12:58,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:13:37,62 root INFO 
id:en_zh cur r: 0.4903 best r: 0.4903
11:13:37,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:14:03,10 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:14:03,15 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:14:29,51 root INFO Epoch 1 Global steps: 5400 Train loss: 0.8261
en_de Dev loss: 0.8391 r:0.2468
en_zh Dev loss: 0.6431 r:0.4874
Current avg r:0.3671 Best avg r: 0.3671
11:15:45,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:16:11,781 root INFO 
id:en_de cur r: 0.2261 best r: 0.2261
11:16:24,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:16:50,741 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:16:50,747 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:17:16,688 root INFO Epoch 1 Global steps: 5600 Train loss: 0.9642
en_de Dev loss: 0.8418 r:0.2545
en_zh Dev loss: 0.7012 r:0.4800
Current avg r:0.3672 Best avg r: 0.3672
11:18:33,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:18:59,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:19:25,392 root INFO Epoch 1 Global steps: 5800 Train loss: 0.8790
en_de Dev loss: 0.8359 r:0.2491
en_zh Dev loss: 0.6527 r:0.4828
Current avg r:0.3660 Best avg r: 0.3672
11:20:41,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:21:07,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:21:33,919 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:21:33,926 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:21:59,958 root INFO Epoch 1 Global steps: 6000 Train loss: 0.9828
en_de Dev loss: 0.8356 r:0.2459
en_zh Dev loss: 0.6620 r:0.4894
Current avg r:0.3677 Best avg r: 0.3677
11:23:17,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:23:43,307 root INFO 
id:en_de cur r: 0.2302 best r: 0.2302
11:23:56,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:24:22,228 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:24:22,234 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:24:48,263 root INFO Epoch 2 Global steps: 6200 Train loss: 0.8471
en_de Dev loss: 0.8355 r:0.2479
en_zh Dev loss: 0.6502 r:0.4930
Current avg r:0.3704 Best avg r: 0.3704
11:26:05,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:26:31,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:26:57,125 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:26:57,131 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:27:23,76 root INFO Epoch 2 Global steps: 6400 Train loss: 0.8611
en_de Dev loss: 0.8504 r:0.2567
en_zh Dev loss: 0.7546 r:0.4852
Current avg r:0.3709 Best avg r: 0.3709
11:28:40,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:29:06,73 root INFO 
id:en_de cur r: 0.2331 best r: 0.2331
11:29:19,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:29:45,50 root INFO Epoch 2 Global steps: 6600 Train loss: 0.7386
en_de Dev loss: 0.8518 r:0.2515
en_zh Dev loss: 0.6908 r:0.4873
Current avg r:0.3694 Best avg r: 0.3709
11:31:01,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:31:27,970 root INFO 
id:en_de cur r: 0.2451 best r: 0.2451
11:31:40,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:32:06,925 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:32:06,931 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:32:32,973 root INFO Epoch 2 Global steps: 6800 Train loss: 0.8996
en_de Dev loss: 0.8344 r:0.2613
en_zh Dev loss: 0.6783 r:0.4824
Current avg r:0.3719 Best avg r: 0.3719
11:33:49,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:34:15,926 root INFO 
id:en_de cur r: 0.2506 best r: 0.2506
11:34:28,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:34:54,932 root INFO Epoch 2 Global steps: 7000 Train loss: 0.8051
en_de Dev loss: 0.8321 r:0.2574
en_zh Dev loss: 0.6565 r:0.4840
Current avg r:0.3707 Best avg r: 0.3719
11:36:11,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:36:37,582 root INFO 
id:en_de cur r: 0.2553 best r: 0.2553
11:36:50,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:37:16,561 root INFO Epoch 2 Global steps: 7200 Train loss: 0.8720
en_de Dev loss: 0.8342 r:0.2613
en_zh Dev loss: 0.6850 r:0.4730
Current avg r:0.3672 Best avg r: 0.3719
11:38:33,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:38:59,585 root INFO 
id:en_de cur r: 0.2680 best r: 0.2680
11:39:12,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:39:38,518 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:39:38,524 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:40:04,536 root INFO Epoch 2 Global steps: 7400 Train loss: 0.8462
en_de Dev loss: 0.8311 r:0.2718
en_zh Dev loss: 0.6766 r:0.4797
Current avg r:0.3757 Best avg r: 0.3757
11:41:21,286 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:41:47,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:42:13,230 root INFO Epoch 2 Global steps: 7600 Train loss: 0.7571
en_de Dev loss: 0.8252 r:0.2745
en_zh Dev loss: 0.6797 r:0.4652
Current avg r:0.3698 Best avg r: 0.3757
11:43:30,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:43:56,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:44:22,204 root INFO Epoch 2 Global steps: 7800 Train loss: 0.8961
en_de Dev loss: 0.8283 r:0.2759
en_zh Dev loss: 0.7051 r:0.4651
Current avg r:0.3705 Best avg r: 0.3757
11:45:39,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:46:05,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:46:31,130 root INFO Epoch 2 Global steps: 8000 Train loss: 0.8566
en_de Dev loss: 0.8349 r:0.2681
en_zh Dev loss: 0.7182 r:0.4734
Current avg r:0.3707 Best avg r: 0.3757
11:47:48,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:48:13,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:48:40,1 root INFO Epoch 2 Global steps: 8200 Train loss: 0.7564
en_de Dev loss: 0.8263 r:0.2736
en_zh Dev loss: 0.6902 r:0.4634
Current avg r:0.3685 Best avg r: 0.3757
11:49:56,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:50:22,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:50:48,800 root INFO Epoch 2 Global steps: 8400 Train loss: 0.8271
en_de Dev loss: 0.8395 r:0.2771
en_zh Dev loss: 0.7151 r:0.4649
Current avg r:0.3710 Best avg r: 0.3757
11:52:05,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:52:31,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:52:57,697 root INFO Epoch 2 Global steps: 8600 Train loss: 0.8109
en_de Dev loss: 0.8389 r:0.2557
en_zh Dev loss: 0.7147 r:0.4748
Current avg r:0.3653 Best avg r: 0.3757
11:54:14,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:54:40,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:55:06,623 root INFO Epoch 2 Global steps: 8800 Train loss: 0.8206
en_de Dev loss: 0.8367 r:0.2490
en_zh Dev loss: 0.6688 r:0.4876
Current avg r:0.3683 Best avg r: 0.3757
11:56:23,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:56:49,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:57:15,468 root INFO Epoch 2 Global steps: 9000 Train loss: 0.9583
en_de Dev loss: 0.8333 r:0.2532
en_zh Dev loss: 0.6802 r:0.4840
Current avg r:0.3686 Best avg r: 0.3757
11:58:32,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:59:11,874 root INFO 
id:en_zh cur r: 0.4924 best r: 0.4924
11:59:11,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:59:37,848 root INFO Epoch 3 Global steps: 9200 Train loss: 0.8692
en_de Dev loss: 0.8374 r:0.2509
en_zh Dev loss: 0.7364 r:0.4875
Current avg r:0.3692 Best avg r: 0.3757
12:00:54,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:01:20,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:01:46,841 root INFO Epoch 3 Global steps: 9400 Train loss: 0.7376
en_de Dev loss: 0.8549 r:0.2363
en_zh Dev loss: 0.7163 r:0.4900
Current avg r:0.3631 Best avg r: 0.3757
12:03:03,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:03:29,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:03:55,790 root INFO Epoch 3 Global steps: 9600 Train loss: 0.7823
en_de Dev loss: 0.8637 r:0.2602
en_zh Dev loss: 0.8286 r:0.4716
Current avg r:0.3659 Best avg r: 0.3757
12:05:12,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:05:38,665 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:06:04,691 root INFO Epoch 3 Global steps: 9800 Train loss: 0.7989
en_de Dev loss: 0.8603 r:0.2399
en_zh Dev loss: 0.7192 r:0.4759
Current avg r:0.3579 Best avg r: 0.3757
12:07:21,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:07:47,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:08:13,657 root INFO Epoch 3 Global steps: 10000 Train loss: 0.7933
en_de Dev loss: 0.8434 r:0.2670
en_zh Dev loss: 0.7345 r:0.4623
Current avg r:0.3646 Best avg r: 0.3757
12:09:30,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:09:56,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:10:22,602 root INFO Epoch 3 Global steps: 10200 Train loss: 0.7144
en_de Dev loss: 0.8346 r:0.2612
en_zh Dev loss: 0.7083 r:0.4737
Current avg r:0.3674 Best avg r: 0.3757
12:11:39,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:12:05,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:12:31,527 root INFO Epoch 3 Global steps: 10400 Train loss: 0.6625
en_de Dev loss: 0.8285 r:0.2741
en_zh Dev loss: 0.7194 r:0.4725
Current avg r:0.3733 Best avg r: 0.3757
12:13:48,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:14:14,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:14:39,966 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
12:14:39,978 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
12:15:05,908 root INFO Epoch 3 Global steps: 10600 Train loss: 0.6453
en_de Dev loss: 0.8457 r:0.2773
en_zh Dev loss: 0.7791 r:0.4752
Current avg r:0.3763 Best avg r: 0.3763
12:16:22,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:17:01,692 root INFO 
id:en_zh cur r: 0.4956 best r: 0.4956
12:17:01,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:17:27,686 root INFO Epoch 3 Global steps: 10800 Train loss: 0.7400
en_de Dev loss: 0.8547 r:0.2529
en_zh Dev loss: 0.7681 r:0.4760
Current avg r:0.3644 Best avg r: 0.3763
12:18:44,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:19:10,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:19:36,615 root INFO Epoch 3 Global steps: 11000 Train loss: 0.6860
en_de Dev loss: 0.8254 r:0.2725
en_zh Dev loss: 0.7037 r:0.4736
Current avg r:0.3731 Best avg r: 0.3763
12:20:53,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:21:19,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:21:45,498 root INFO Epoch 3 Global steps: 11200 Train loss: 0.6426
en_de Dev loss: 0.8795 r:0.2755
en_zh Dev loss: 0.8711 r:0.4490
Current avg r:0.3622 Best avg r: 0.3763
12:23:02,466 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:23:28,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:23:54,457 root INFO Epoch 3 Global steps: 11400 Train loss: 0.7402
en_de Dev loss: 0.8405 r:0.2505
en_zh Dev loss: 0.6927 r:0.4781
Current avg r:0.3643 Best avg r: 0.3763
12:25:11,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:25:50,243 root INFO 
id:en_zh cur r: 0.4974 best r: 0.4974
12:25:50,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:26:16,219 root INFO Epoch 3 Global steps: 11600 Train loss: 0.7511
en_de Dev loss: 0.8432 r:0.2530
en_zh Dev loss: 0.7197 r:0.4878
Current avg r:0.3704 Best avg r: 0.3763
12:27:32,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:27:58,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:28:24,890 root INFO Epoch 3 Global steps: 11800 Train loss: 0.7371
en_de Dev loss: 0.8598 r:0.2558
en_zh Dev loss: 0.7628 r:0.4797
Current avg r:0.3678 Best avg r: 0.3763
12:29:41,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:30:07,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:30:33,600 root INFO Epoch 3 Global steps: 12000 Train loss: 0.5940
en_de Dev loss: 0.8301 r:0.2599
en_zh Dev loss: 0.6915 r:0.4694
Current avg r:0.3646 Best avg r: 0.3763
12:31:50,486 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:32:16,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:32:42,415 root INFO Epoch 4 Global steps: 12200 Train loss: 0.6136
en_de Dev loss: 0.8526 r:0.2555
en_zh Dev loss: 0.8247 r:0.4596
Current avg r:0.3575 Best avg r: 0.3763
12:33:59,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:34:25,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:34:51,3 root INFO Epoch 4 Global steps: 12400 Train loss: 0.6464
en_de Dev loss: 0.8340 r:0.2511
en_zh Dev loss: 0.7040 r:0.4743
Current avg r:0.3627 Best avg r: 0.3763
12:36:07,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:36:33,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:36:59,528 root INFO Epoch 4 Global steps: 12600 Train loss: 0.6029
en_de Dev loss: 0.8397 r:0.2731
en_zh Dev loss: 0.7570 r:0.4542
Current avg r:0.3637 Best avg r: 0.3763
12:38:16,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:38:42,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:39:08,173 root INFO Epoch 4 Global steps: 12800 Train loss: 0.6254
en_de Dev loss: 0.8299 r:0.2678
en_zh Dev loss: 0.7154 r:0.4677
Current avg r:0.3678 Best avg r: 0.3763
12:40:24,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:40:50,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:41:16,777 root INFO Epoch 4 Global steps: 13000 Train loss: 0.6363
en_de Dev loss: 0.8551 r:0.2569
en_zh Dev loss: 0.8110 r:0.4544
Current avg r:0.3556 Best avg r: 0.3763
12:42:33,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:42:59,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:43:25,451 root INFO Epoch 4 Global steps: 13200 Train loss: 0.6434
en_de Dev loss: 0.8549 r:0.2428
en_zh Dev loss: 0.7508 r:0.4523
Current avg r:0.3476 Best avg r: 0.3763
12:44:42,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:45:08,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:45:34,209 root INFO Epoch 4 Global steps: 13400 Train loss: 0.6045
en_de Dev loss: 0.8698 r:0.2492
en_zh Dev loss: 0.7722 r:0.4450
Current avg r:0.3471 Best avg r: 0.3763
12:46:51,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:47:16,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:47:42,937 root INFO Epoch 4 Global steps: 13600 Train loss: 0.5550
en_de Dev loss: 0.8410 r:0.2474
en_zh Dev loss: 0.7119 r:0.4715
Current avg r:0.3594 Best avg r: 0.3763
12:48:59,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:49:25,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:49:51,630 root INFO Epoch 4 Global steps: 13800 Train loss: 0.6283
en_de Dev loss: 0.8649 r:0.2411
en_zh Dev loss: 0.8140 r:0.4532
Current avg r:0.3471 Best avg r: 0.3763
12:51:08,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:51:34,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:52:00,278 root INFO Epoch 4 Global steps: 14000 Train loss: 0.5839
en_de Dev loss: 0.8636 r:0.2301
en_zh Dev loss: 0.8069 r:0.4581
Current avg r:0.3441 Best avg r: 0.3763
12:53:16,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:53:42,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:54:08,898 root INFO Epoch 4 Global steps: 14200 Train loss: 0.6325
en_de Dev loss: 0.8515 r:0.2191
en_zh Dev loss: 0.7498 r:0.4587
Current avg r:0.3389 Best avg r: 0.3763
12:55:25,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:55:51,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:56:17,417 root INFO Epoch 4 Global steps: 14400 Train loss: 0.6524
en_de Dev loss: 0.8627 r:0.2214
en_zh Dev loss: 0.7867 r:0.4463
Current avg r:0.3338 Best avg r: 0.3763
12:57:34,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:58:00,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:58:26,30 root INFO Epoch 4 Global steps: 14600 Train loss: 0.6442
en_de Dev loss: 0.8554 r:0.2176
en_zh Dev loss: 0.7115 r:0.4667
Current avg r:0.3422 Best avg r: 0.3763
12:59:42,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:00:08,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:00:34,573 root INFO Epoch 4 Global steps: 14800 Train loss: 0.6031
en_de Dev loss: 0.8466 r:0.2216
en_zh Dev loss: 0.7099 r:0.4563
Current avg r:0.3390 Best avg r: 0.3763
13:01:51,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:02:17,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:02:43,86 root INFO Epoch 4 Global steps: 15000 Train loss: 0.5655
en_de Dev loss: 0.8729 r:0.2068
en_zh Dev loss: 0.7879 r:0.4613
Current avg r:0.3341 Best avg r: 0.3763
13:04:00,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:04:26,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:04:52,35 root INFO Epoch 5 Global steps: 15200 Train loss: 0.5557
en_de Dev loss: 0.8552 r:0.2239
en_zh Dev loss: 0.7899 r:0.4461
Current avg r:0.3350 Best avg r: 0.3763
13:06:08,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:06:34,729 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:07:00,666 root INFO Epoch 5 Global steps: 15400 Train loss: 0.4940
en_de Dev loss: 0.8603 r:0.2121
en_zh Dev loss: 0.7886 r:0.4416
Current avg r:0.3269 Best avg r: 0.3763
13:08:17,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:08:43,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:09:08,969 root INFO Epoch 5 Global steps: 15600 Train loss: 0.5319
en_de Dev loss: 0.8738 r:0.2226
en_zh Dev loss: 0.7792 r:0.4570
Current avg r:0.3398 Best avg r: 0.3763
13:10:25,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:10:51,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:11:17,695 root INFO Epoch 5 Global steps: 15800 Train loss: 0.5152
en_de Dev loss: 0.8516 r:0.2206
en_zh Dev loss: 0.7411 r:0.4419
Current avg r:0.3312 Best avg r: 0.3763
13:12:34,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:13:00,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:13:26,456 root INFO Epoch 5 Global steps: 16000 Train loss: 0.5081
en_de Dev loss: 0.8703 r:0.2067
en_zh Dev loss: 0.7703 r:0.4589
Current avg r:0.3328 Best avg r: 0.3763
13:14:43,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:15:09,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:15:34,943 root INFO Epoch 5 Global steps: 16200 Train loss: 0.4851
en_de Dev loss: 0.8764 r:0.2152
en_zh Dev loss: 0.7739 r:0.4542
Current avg r:0.3347 Best avg r: 0.3763
13:16:51,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:17:17,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:17:43,614 root INFO Epoch 5 Global steps: 16400 Train loss: 0.4913
en_de Dev loss: 0.8579 r:0.2330
en_zh Dev loss: 0.7569 r:0.4590
Current avg r:0.3460 Best avg r: 0.3763
13:19:00,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:19:26,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:19:52,323 root INFO Epoch 5 Global steps: 16600 Train loss: 0.4930
en_de Dev loss: 0.8915 r:0.2158
en_zh Dev loss: 0.8873 r:0.4514
Current avg r:0.3336 Best avg r: 0.3763
13:21:08,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:21:34,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:22:00,835 root INFO Epoch 5 Global steps: 16800 Train loss: 0.5449
en_de Dev loss: 0.8663 r:0.2299
en_zh Dev loss: 0.7437 r:0.4695
Current avg r:0.3497 Best avg r: 0.3763
13:23:17,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:23:43,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:24:09,378 root INFO Epoch 5 Global steps: 17000 Train loss: 0.4974
en_de Dev loss: 0.8968 r:0.2214
en_zh Dev loss: 0.8356 r:0.4550
Current avg r:0.3382 Best avg r: 0.3763
13:25:26,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:25:51,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:26:17,951 root INFO Epoch 5 Global steps: 17200 Train loss: 0.4934
en_de Dev loss: 0.8555 r:0.2403
en_zh Dev loss: 0.7459 r:0.4581
Current avg r:0.3492 Best avg r: 0.3763
13:27:34,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:28:00,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:28:26,542 root INFO Epoch 5 Global steps: 17400 Train loss: 0.5549
en_de Dev loss: 0.8749 r:0.2204
en_zh Dev loss: 0.7701 r:0.4639
Current avg r:0.3421 Best avg r: 0.3763
13:29:43,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:30:09,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:30:35,231 root INFO Epoch 5 Global steps: 17600 Train loss: 0.5511
en_de Dev loss: 0.8661 r:0.2201
en_zh Dev loss: 0.7984 r:0.4554
Current avg r:0.3378 Best avg r: 0.3763
13:31:52,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:32:18,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:32:43,910 root INFO Epoch 5 Global steps: 17800 Train loss: 0.4744
en_de Dev loss: 0.8732 r:0.2197
en_zh Dev loss: 0.7820 r:0.4657
Current avg r:0.3427 Best avg r: 0.3763
13:34:00,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:34:26,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:34:52,668 root INFO Epoch 5 Global steps: 18000 Train loss: 0.5066
en_de Dev loss: 0.8777 r:0.2165
en_zh Dev loss: 0.8969 r:0.4518
Current avg r:0.3341 Best avg r: 0.3763
13:36:09,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:36:35,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:37:01,579 root INFO Epoch 6 Global steps: 18200 Train loss: 0.4675
en_de Dev loss: 0.8846 r:0.2223
en_zh Dev loss: 0.8824 r:0.4522
Current avg r:0.3372 Best avg r: 0.3763
13:38:18,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:38:44,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:39:10,227 root INFO Epoch 6 Global steps: 18400 Train loss: 0.4333
en_de Dev loss: 0.8625 r:0.2292
en_zh Dev loss: 0.7511 r:0.4722
Current avg r:0.3507 Best avg r: 0.3763
13:40:26,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:40:52,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:41:18,736 root INFO Epoch 6 Global steps: 18600 Train loss: 0.4436
en_de Dev loss: 0.8787 r:0.2028
en_zh Dev loss: 0.7338 r:0.4701
Current avg r:0.3365 Best avg r: 0.3763
13:42:35,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:43:01,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:43:27,344 root INFO Epoch 6 Global steps: 18800 Train loss: 0.4481
en_de Dev loss: 0.8837 r:0.2136
en_zh Dev loss: 0.7853 r:0.4789
Current avg r:0.3462 Best avg r: 0.3763
13:44:44,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:45:09,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:45:35,977 root INFO Epoch 6 Global steps: 19000 Train loss: 0.4157
en_de Dev loss: 0.8898 r:0.2186
en_zh Dev loss: 0.7820 r:0.4732
Current avg r:0.3459 Best avg r: 0.3763
13:46:52,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:47:18,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:47:44,623 root INFO Epoch 6 Global steps: 19200 Train loss: 0.4182
en_de Dev loss: 0.8710 r:0.2288
en_zh Dev loss: 0.7594 r:0.4618
Current avg r:0.3453 Best avg r: 0.3763
13:49:01,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:49:27,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:49:53,320 root INFO Epoch 6 Global steps: 19400 Train loss: 0.4688
en_de Dev loss: 0.8491 r:0.2346
en_zh Dev loss: 0.7161 r:0.4635
Current avg r:0.3490 Best avg r: 0.3763
13:51:10,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:51:35,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:52:01,844 root INFO Epoch 6 Global steps: 19600 Train loss: 0.4275
en_de Dev loss: 0.8524 r:0.2360
en_zh Dev loss: 0.7050 r:0.4773
Current avg r:0.3566 Best avg r: 0.3763
13:53:18,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:53:44,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:54:10,432 root INFO Epoch 6 Global steps: 19800 Train loss: 0.5405
en_de Dev loss: 0.8705 r:0.2202
en_zh Dev loss: 0.7740 r:0.4755
Current avg r:0.3478 Best avg r: 0.3763
13:55:26,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:55:52,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:56:18,802 root INFO Epoch 6 Global steps: 20000 Train loss: 0.4074
en_de Dev loss: 0.8796 r:0.2086
en_zh Dev loss: 0.7431 r:0.4792
Current avg r:0.3439 Best avg r: 0.3763
13:57:35,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:58:01,490 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:58:27,486 root INFO Epoch 6 Global steps: 20200 Train loss: 0.4575
en_de Dev loss: 0.8554 r:0.2278
en_zh Dev loss: 0.7657 r:0.4626
Current avg r:0.3452 Best avg r: 0.3763
13:59:43,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:00:09,568 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:00:35,416 root INFO Epoch 6 Global steps: 20400 Train loss: 0.4642
en_de Dev loss: 0.8978 r:0.2062
en_zh Dev loss: 0.8051 r:0.4744
Current avg r:0.3403 Best avg r: 0.3763
14:01:51,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:02:17,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:02:43,692 root INFO Epoch 6 Global steps: 20600 Train loss: 0.4129
en_de Dev loss: 0.9006 r:0.2059
en_zh Dev loss: 0.7632 r:0.4888
Current avg r:0.3473 Best avg r: 0.3763
14:04:00,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:04:26,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:04:52,187 root INFO Epoch 6 Global steps: 20800 Train loss: 0.4010
en_de Dev loss: 0.8815 r:0.2160
en_zh Dev loss: 0.7816 r:0.4771
Current avg r:0.3465 Best avg r: 0.3763
14:06:08,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:06:34,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:07:00,857 root INFO Epoch 6 Global steps: 21000 Train loss: 0.3949
en_de Dev loss: 0.8719 r:0.2155
en_zh Dev loss: 0.7500 r:0.4699
Current avg r:0.3427 Best avg r: 0.3763
14:08:17,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:08:43,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:09:08,942 root INFO Epoch 7 Global steps: 21200 Train loss: 0.3972
en_de Dev loss: 0.8771 r:0.2163
en_zh Dev loss: 0.7527 r:0.4838
Current avg r:0.3501 Best avg r: 0.3763
14:10:24,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:10:50,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:11:15,953 root INFO Epoch 7 Global steps: 21400 Train loss: 0.4049
en_de Dev loss: 0.8646 r:0.2290
en_zh Dev loss: 0.7701 r:0.4715
Current avg r:0.3502 Best avg r: 0.3763
14:12:31,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:12:57,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:13:23,155 root INFO Epoch 7 Global steps: 21600 Train loss: 0.3565
en_de Dev loss: 0.8588 r:0.2282
en_zh Dev loss: 0.7644 r:0.4739
Current avg r:0.3511 Best avg r: 0.3763
14:14:39,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:15:04,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:15:30,785 root INFO Epoch 7 Global steps: 21800 Train loss: 0.3737
en_de Dev loss: 0.8834 r:0.2087
en_zh Dev loss: 0.8084 r:0.4751
Current avg r:0.3419 Best avg r: 0.3763
14:16:46,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:17:12,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:17:38,5 root INFO Epoch 7 Global steps: 22000 Train loss: 0.3692
en_de Dev loss: 0.8671 r:0.2122
en_zh Dev loss: 0.7203 r:0.4746
Current avg r:0.3434 Best avg r: 0.3763
14:18:53,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:19:19,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:19:45,14 root INFO Epoch 7 Global steps: 22200 Train loss: 0.3480
en_de Dev loss: 0.8897 r:0.2181
en_zh Dev loss: 0.7495 r:0.4809
Current avg r:0.3495 Best avg r: 0.3763
14:21:00,980 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:21:27,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:21:53,84 root INFO Epoch 7 Global steps: 22400 Train loss: 0.3851
en_de Dev loss: 0.8858 r:0.2094
en_zh Dev loss: 0.7350 r:0.4926
Current avg r:0.3510 Best avg r: 0.3763
14:23:10,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:23:36,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:24:02,682 root INFO Epoch 7 Global steps: 22600 Train loss: 0.3580
en_de Dev loss: 0.8750 r:0.2131
en_zh Dev loss: 0.7640 r:0.4691
Current avg r:0.3411 Best avg r: 0.3763
14:25:20,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:25:46,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:26:12,547 root INFO Epoch 7 Global steps: 22800 Train loss: 0.4012
en_de Dev loss: 0.8751 r:0.2128
en_zh Dev loss: 0.7386 r:0.4766
Current avg r:0.3447 Best avg r: 0.3763
14:27:30,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:27:56,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:28:22,452 root INFO Epoch 7 Global steps: 23000 Train loss: 0.4579
en_de Dev loss: 0.8668 r:0.2129
en_zh Dev loss: 0.7787 r:0.4609
Current avg r:0.3369 Best avg r: 0.3763
14:29:40,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:30:06,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:30:32,424 root INFO Epoch 7 Global steps: 23200 Train loss: 0.3351
en_de Dev loss: 0.8905 r:0.2161
en_zh Dev loss: 0.7653 r:0.4725
Current avg r:0.3443 Best avg r: 0.3763
14:31:50,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:32:16,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:32:42,385 root INFO Epoch 7 Global steps: 23400 Train loss: 0.3931
en_de Dev loss: 0.8764 r:0.2199
en_zh Dev loss: 0.7684 r:0.4668
Current avg r:0.3433 Best avg r: 0.3763
14:34:00,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:34:26,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:34:52,324 root INFO Epoch 7 Global steps: 23600 Train loss: 0.3702
en_de Dev loss: 0.8598 r:0.2188
en_zh Dev loss: 0.7186 r:0.4730
Current avg r:0.3459 Best avg r: 0.3763
14:36:10,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:36:36,187 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:37:02,320 root INFO Epoch 7 Global steps: 23800 Train loss: 0.3952
en_de Dev loss: 0.8786 r:0.2234
en_zh Dev loss: 0.8297 r:0.4671
Current avg r:0.3453 Best avg r: 0.3763
14:38:19,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:38:46,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:12,171 root INFO Epoch 7 Global steps: 24000 Train loss: 0.4005
en_de Dev loss: 0.8987 r:0.1955
en_zh Dev loss: 0.7905 r:0.4711
Current avg r:0.3333 Best avg r: 0.3763
14:40:30,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:40:56,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:41:22,623 root INFO Epoch 8 Global steps: 24200 Train loss: 0.3552
en_de Dev loss: 0.8939 r:0.2194
en_zh Dev loss: 0.8640 r:0.4610
Current avg r:0.3402 Best avg r: 0.3763
14:42:40,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:43:06,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:32,469 root INFO Epoch 8 Global steps: 24400 Train loss: 0.4038
en_de Dev loss: 0.8851 r:0.2081
en_zh Dev loss: 0.7759 r:0.4706
Current avg r:0.3393 Best avg r: 0.3763
14:44:50,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:16,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:42,426 root INFO Epoch 8 Global steps: 24600 Train loss: 0.3586
en_de Dev loss: 0.8717 r:0.2247
en_zh Dev loss: 0.7756 r:0.4641
Current avg r:0.3444 Best avg r: 0.3763
14:46:59,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:47:26,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:52,148 root INFO Epoch 8 Global steps: 24800 Train loss: 0.3058
en_de Dev loss: 0.9758 r:0.1794
en_zh Dev loss: 0.8225 r:0.4724
Current avg r:0.3259 Best avg r: 0.3763
14:49:09,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:35,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:50:01,640 root INFO Epoch 8 Global steps: 25000 Train loss: 0.3965
en_de Dev loss: 0.9470 r:0.1708
en_zh Dev loss: 0.8865 r:0.4514
Current avg r:0.3111 Best avg r: 0.3763
14:51:19,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:45,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:11,486 root INFO Epoch 8 Global steps: 25200 Train loss: 0.3461
en_de Dev loss: 0.9105 r:0.1848
en_zh Dev loss: 0.7655 r:0.4591
Current avg r:0.3220 Best avg r: 0.3763
14:53:28,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:55,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:21,274 root INFO Epoch 8 Global steps: 25400 Train loss: 0.3642
en_de Dev loss: 0.9133 r:0.1803
en_zh Dev loss: 0.8089 r:0.4624
Current avg r:0.3214 Best avg r: 0.3763
14:55:38,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:04,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:56:30,952 root INFO Epoch 8 Global steps: 25600 Train loss: 0.3457
en_de Dev loss: 0.8883 r:0.1943
en_zh Dev loss: 0.7652 r:0.4628
Current avg r:0.3286 Best avg r: 0.3763
14:57:48,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:14,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:40,677 root INFO Epoch 8 Global steps: 25800 Train loss: 0.3195
en_de Dev loss: 0.9378 r:0.1851
en_zh Dev loss: 0.8553 r:0.4612
Current avg r:0.3232 Best avg r: 0.3763
14:59:58,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:24,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:50,464 root INFO Epoch 8 Global steps: 26000 Train loss: 0.3580
en_de Dev loss: 0.9193 r:0.1972
en_zh Dev loss: 0.8305 r:0.4454
Current avg r:0.3213 Best avg r: 0.3763
15:02:08,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:34,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:00,242 root INFO Epoch 8 Global steps: 26200 Train loss: 0.3107
en_de Dev loss: 0.9017 r:0.1998
en_zh Dev loss: 0.7628 r:0.4610
Current avg r:0.3304 Best avg r: 0.3763
15:04:17,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:43,852 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:09,933 root INFO Epoch 8 Global steps: 26400 Train loss: 0.3498
en_de Dev loss: 0.8734 r:0.2058
en_zh Dev loss: 0.7584 r:0.4543
Current avg r:0.3300 Best avg r: 0.3763
15:06:27,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:06:53,665 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:19,766 root INFO Epoch 8 Global steps: 26600 Train loss: 0.3075
en_de Dev loss: 0.8729 r:0.2104
en_zh Dev loss: 0.7518 r:0.4685
Current avg r:0.3394 Best avg r: 0.3763
15:08:37,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:03,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:29,643 root INFO Epoch 8 Global steps: 26800 Train loss: 0.3442
en_de Dev loss: 0.8973 r:0.1926
en_zh Dev loss: 0.7647 r:0.4811
Current avg r:0.3369 Best avg r: 0.3763
15:10:47,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:13,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:39,472 root INFO Epoch 8 Global steps: 27000 Train loss: 0.3352
en_de Dev loss: 0.9087 r:0.1780
en_zh Dev loss: 0.8030 r:0.4654
Current avg r:0.3217 Best avg r: 0.3763
15:12:57,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:23,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:49,411 root INFO Epoch 9 Global steps: 27200 Train loss: 0.3110
en_de Dev loss: 0.9015 r:0.1773
en_zh Dev loss: 0.7701 r:0.4756
Current avg r:0.3264 Best avg r: 0.3763
15:15:06,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:32,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:15:58,937 root INFO Epoch 9 Global steps: 27400 Train loss: 0.3163
en_de Dev loss: 0.9176 r:0.1752
en_zh Dev loss: 0.7745 r:0.4696
Current avg r:0.3224 Best avg r: 0.3763
15:17:16,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:42,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:08,479 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2824
en_de Dev loss: 0.9046 r:0.1720
en_zh Dev loss: 0.7238 r:0.4726
Current avg r:0.3223 Best avg r: 0.3763
15:19:25,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:51,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:17,782 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2682
en_de Dev loss: 0.9032 r:0.1980
en_zh Dev loss: 0.7464 r:0.4784
Current avg r:0.3382 Best avg r: 0.3763
15:21:35,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:01,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:27,246 root INFO Epoch 9 Global steps: 28000 Train loss: 0.3226
en_de Dev loss: 0.9081 r:0.1916
en_zh Dev loss: 0.7631 r:0.4702
Current avg r:0.3309 Best avg r: 0.3763
15:23:44,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:10,597 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:36,624 root INFO Epoch 9 Global steps: 28200 Train loss: 0.3565
en_de Dev loss: 0.9437 r:0.1653
en_zh Dev loss: 0.7982 r:0.4725
Current avg r:0.3189 Best avg r: 0.3763
15:25:54,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:20,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:46,210 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2862
en_de Dev loss: 0.9269 r:0.1684
en_zh Dev loss: 0.7749 r:0.4754
Current avg r:0.3219 Best avg r: 0.3763
15:28:03,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:28:29,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:55,714 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2937
en_de Dev loss: 0.9404 r:0.1758
en_zh Dev loss: 0.7981 r:0.4671
Current avg r:0.3214 Best avg r: 0.3763
15:30:13,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:39,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:05,222 root INFO Epoch 9 Global steps: 28800 Train loss: 0.3006
en_de Dev loss: 0.8871 r:0.1918
en_zh Dev loss: 0.7614 r:0.4608
Current avg r:0.3263 Best avg r: 0.3763
15:32:22,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:48,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:14,699 root INFO Epoch 9 Global steps: 29000 Train loss: 0.3084
en_de Dev loss: 0.9294 r:0.1877
en_zh Dev loss: 0.8225 r:0.4692
Current avg r:0.3285 Best avg r: 0.3763
15:34:32,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:58,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:24,139 root INFO Epoch 9 Global steps: 29200 Train loss: 0.3184
en_de Dev loss: 0.9139 r:0.1877
en_zh Dev loss: 0.7657 r:0.4781
Current avg r:0.3329 Best avg r: 0.3763
15:36:41,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:07,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:37:33,635 root INFO Epoch 9 Global steps: 29400 Train loss: 0.3038
en_de Dev loss: 0.9355 r:0.1693
en_zh Dev loss: 0.8185 r:0.4717
Current avg r:0.3205 Best avg r: 0.3763
15:38:50,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:17,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:43,85 root INFO Epoch 9 Global steps: 29600 Train loss: 0.3061
en_de Dev loss: 0.9032 r:0.1781
en_zh Dev loss: 0.8390 r:0.4552
Current avg r:0.3166 Best avg r: 0.3763
15:41:00,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:26,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:52,625 root INFO Epoch 9 Global steps: 29800 Train loss: 0.3305
en_de Dev loss: 0.9166 r:0.1683
en_zh Dev loss: 0.7828 r:0.4742
Current avg r:0.3213 Best avg r: 0.3763
15:43:10,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:49,91 root INFO 
id:en_zh cur r: 0.4987 best r: 0.4987
15:43:49,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:15,143 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2962
en_de Dev loss: 0.9423 r:0.1774
en_zh Dev loss: 0.7477 r:0.4946
Current avg r:0.3360 Best avg r: 0.3763
15:45:32,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:45:58,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:24,782 root INFO Epoch 10 Global steps: 30200 Train loss: 0.2983
en_de Dev loss: 0.9061 r:0.1765
en_zh Dev loss: 0.7190 r:0.4817
Current avg r:0.3291 Best avg r: 0.3763
15:47:42,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:08,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:34,135 root INFO Epoch 10 Global steps: 30400 Train loss: 0.3162
en_de Dev loss: 0.8937 r:0.1805
en_zh Dev loss: 0.7683 r:0.4684
Current avg r:0.3245 Best avg r: 0.3763
15:49:51,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:17,665 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:43,699 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2918
en_de Dev loss: 0.9214 r:0.1707
en_zh Dev loss: 0.8268 r:0.4733
Current avg r:0.3220 Best avg r: 0.3763
15:52:01,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:27,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:53,125 root INFO Epoch 10 Global steps: 30800 Train loss: 0.3204
en_de Dev loss: 0.9235 r:0.1760
en_zh Dev loss: 0.8016 r:0.4788
Current avg r:0.3274 Best avg r: 0.3763
15:54:10,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:36,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:02,712 root INFO Epoch 10 Global steps: 31000 Train loss: 0.3099
en_de Dev loss: 0.9064 r:0.1762
en_zh Dev loss: 0.7646 r:0.4732
Current avg r:0.3247 Best avg r: 0.3763
15:56:18,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:44,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:10,5 root INFO Epoch 10 Global steps: 31200 Train loss: 0.2531
en_de Dev loss: 0.8994 r:0.1722
en_zh Dev loss: 0.7360 r:0.4744
Current avg r:0.3233 Best avg r: 0.3763
15:58:25,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:51,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:17,197 root INFO Epoch 10 Global steps: 31400 Train loss: 0.2646
en_de Dev loss: 0.9327 r:0.1659
en_zh Dev loss: 0.8607 r:0.4703
Current avg r:0.3181 Best avg r: 0.3763
16:00:32,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:58,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:24,374 root INFO Epoch 10 Global steps: 31600 Train loss: 0.2663
en_de Dev loss: 0.9409 r:0.1524
en_zh Dev loss: 0.7247 r:0.4910
Current avg r:0.3217 Best avg r: 0.3763
16:02:40,104 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:05,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:31,524 root INFO Epoch 10 Global steps: 31800 Train loss: 0.2684
en_de Dev loss: 0.9273 r:0.1552
en_zh Dev loss: 0.7721 r:0.4847
Current avg r:0.3199 Best avg r: 0.3763
16:04:47,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:12,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:38,635 root INFO Epoch 10 Global steps: 32000 Train loss: 0.2715
en_de Dev loss: 0.9291 r:0.1655
en_zh Dev loss: 0.7851 r:0.4859
Current avg r:0.3257 Best avg r: 0.3763
16:06:54,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:19,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:45,568 root INFO Epoch 10 Global steps: 32200 Train loss: 0.2846
en_de Dev loss: 0.8914 r:0.1856
en_zh Dev loss: 0.6992 r:0.4924
Current avg r:0.3390 Best avg r: 0.3763
16:09:01,286 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:26,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:52,688 root INFO Epoch 10 Global steps: 32400 Train loss: 0.2575
en_de Dev loss: 0.9228 r:0.1729
en_zh Dev loss: 0.7600 r:0.4780
Current avg r:0.3255 Best avg r: 0.3763
16:11:08,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:33,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:59,593 root INFO Epoch 10 Global steps: 32600 Train loss: 0.2723
en_de Dev loss: 0.9105 r:0.1657
en_zh Dev loss: 0.7388 r:0.4754
Current avg r:0.3205 Best avg r: 0.3763
16:13:15,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:40,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:06,472 root INFO Epoch 10 Global steps: 32800 Train loss: 0.2577
en_de Dev loss: 0.9174 r:0.1698
en_zh Dev loss: 0.7362 r:0.4757
Current avg r:0.3228 Best avg r: 0.3763
16:15:21,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:47,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:13,420 root INFO Epoch 10 Global steps: 33000 Train loss: 0.3036
en_de Dev loss: 0.9451 r:0.1688
en_zh Dev loss: 0.7930 r:0.4755
Current avg r:0.3222 Best avg r: 0.3763
16:17:29,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:55,80 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:20,790 root INFO Epoch 11 Global steps: 33200 Train loss: 0.2625
en_de Dev loss: 0.9149 r:0.1861
en_zh Dev loss: 0.7471 r:0.4734
Current avg r:0.3297 Best avg r: 0.3763
16:19:36,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:02,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:27,906 root INFO Epoch 11 Global steps: 33400 Train loss: 0.2394
en_de Dev loss: 0.9089 r:0.1830
en_zh Dev loss: 0.7672 r:0.4782
Current avg r:0.3306 Best avg r: 0.3763
16:21:43,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:09,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:35,13 root INFO Epoch 11 Global steps: 33600 Train loss: 0.2720
en_de Dev loss: 0.9190 r:0.1874
en_zh Dev loss: 0.7682 r:0.4848
Current avg r:0.3361 Best avg r: 0.3763
16:23:50,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:16,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:24:42,160 root INFO Epoch 11 Global steps: 33800 Train loss: 0.2690
en_de Dev loss: 0.9272 r:0.1704
en_zh Dev loss: 0.7470 r:0.4830
Current avg r:0.3267 Best avg r: 0.3763
16:25:57,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:23,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:49,324 root INFO Epoch 11 Global steps: 34000 Train loss: 0.2708
en_de Dev loss: 0.9374 r:0.1850
en_zh Dev loss: 0.8523 r:0.4764
Current avg r:0.3307 Best avg r: 0.3763
16:28:05,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:30,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:56,439 root INFO Epoch 11 Global steps: 34200 Train loss: 0.2907
en_de Dev loss: 0.9203 r:0.1831
en_zh Dev loss: 0.7931 r:0.4796
Current avg r:0.3314 Best avg r: 0.3763
16:30:12,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:37,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:03,630 root INFO Epoch 11 Global steps: 34400 Train loss: 0.2794
en_de Dev loss: 0.9159 r:0.1762
en_zh Dev loss: 0.7466 r:0.4748
Current avg r:0.3255 Best avg r: 0.3763
16:32:19,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:45,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:11,159 root INFO Epoch 11 Global steps: 34600 Train loss: 0.2363
en_de Dev loss: 0.9272 r:0.1776
en_zh Dev loss: 0.7776 r:0.4709
Current avg r:0.3242 Best avg r: 0.3763
16:34:26,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:52,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:18,306 root INFO Epoch 11 Global steps: 34800 Train loss: 0.2658
en_de Dev loss: 0.9077 r:0.1832
en_zh Dev loss: 0.7495 r:0.4660
Current avg r:0.3246 Best avg r: 0.3763
16:36:33,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:59,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:25,348 root INFO Epoch 11 Global steps: 35000 Train loss: 0.2705
en_de Dev loss: 0.9167 r:0.1845
en_zh Dev loss: 0.7650 r:0.4798
Current avg r:0.3322 Best avg r: 0.3763
16:38:40,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:06,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:32,339 root INFO Epoch 11 Global steps: 35200 Train loss: 0.2261
en_de Dev loss: 0.9193 r:0.1843
en_zh Dev loss: 0.7721 r:0.4766
Current avg r:0.3305 Best avg r: 0.3763
16:40:47,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:13,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:39,298 root INFO Epoch 11 Global steps: 35400 Train loss: 0.2253
en_de Dev loss: 0.9261 r:0.1830
en_zh Dev loss: 0.7521 r:0.4839
Current avg r:0.3335 Best avg r: 0.3763
16:42:54,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:20,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:46,369 root INFO Epoch 11 Global steps: 35600 Train loss: 0.2632
en_de Dev loss: 0.9121 r:0.1963
en_zh Dev loss: 0.7789 r:0.4759
Current avg r:0.3361 Best avg r: 0.3763
16:45:02,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:28,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:54,498 root INFO Epoch 11 Global steps: 35800 Train loss: 0.2476
en_de Dev loss: 0.9538 r:0.1800
en_zh Dev loss: 0.8558 r:0.4738
Current avg r:0.3269 Best avg r: 0.3763
16:47:11,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:37,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:03,570 root INFO Epoch 11 Global steps: 36000 Train loss: 0.2452
en_de Dev loss: 0.9103 r:0.1822
en_zh Dev loss: 0.7179 r:0.4896
Current avg r:0.3359 Best avg r: 0.3763
16:49:21,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:47,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:13,14 root INFO Epoch 12 Global steps: 36200 Train loss: 0.2227
en_de Dev loss: 0.9182 r:0.1853
en_zh Dev loss: 0.7574 r:0.4834
Current avg r:0.3344 Best avg r: 0.3763
16:51:29,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:55,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:21,489 root INFO Epoch 12 Global steps: 36400 Train loss: 0.2104
en_de Dev loss: 0.9542 r:0.1785
en_zh Dev loss: 0.7954 r:0.4834
Current avg r:0.3310 Best avg r: 0.3763
16:53:38,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:04,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:29,990 root INFO Epoch 12 Global steps: 36600 Train loss: 0.2208
en_de Dev loss: 0.9654 r:0.1767
en_zh Dev loss: 0.8142 r:0.4827
Current avg r:0.3297 Best avg r: 0.3763
16:55:46,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:12,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:38,487 root INFO Epoch 12 Global steps: 36800 Train loss: 0.2303
en_de Dev loss: 0.9372 r:0.1814
en_zh Dev loss: 0.7795 r:0.4834
Current avg r:0.3324 Best avg r: 0.3763
16:57:54,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:20,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:46,861 root INFO Epoch 12 Global steps: 37000 Train loss: 0.2262
en_de Dev loss: 0.9211 r:0.1881
en_zh Dev loss: 0.7739 r:0.4854
Current avg r:0.3367 Best avg r: 0.3763
17:00:03,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:29,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:55,531 root INFO Epoch 12 Global steps: 37200 Train loss: 0.2242
en_de Dev loss: 0.9415 r:0.1579
en_zh Dev loss: 0.7672 r:0.4838
Current avg r:0.3208 Best avg r: 0.3763
17:02:12,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:38,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:03,988 root INFO Epoch 12 Global steps: 37400 Train loss: 0.2175
en_de Dev loss: 0.9335 r:0.1569
en_zh Dev loss: 0.7519 r:0.4850
Current avg r:0.3209 Best avg r: 0.3763
17:04:20,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:46,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:12,333 root INFO Epoch 12 Global steps: 37600 Train loss: 0.2596
en_de Dev loss: 0.9186 r:0.1715
en_zh Dev loss: 0.7693 r:0.4837
Current avg r:0.3276 Best avg r: 0.3763
17:06:28,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:54,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:20,638 root INFO Epoch 12 Global steps: 37800 Train loss: 0.2581
en_de Dev loss: 0.9321 r:0.1640
en_zh Dev loss: 0.7504 r:0.4870
Current avg r:0.3255 Best avg r: 0.3763
17:08:37,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:03,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:28,957 root INFO Epoch 12 Global steps: 38000 Train loss: 0.2299
en_de Dev loss: 0.9632 r:0.1531
en_zh Dev loss: 0.8064 r:0.4820
Current avg r:0.3175 Best avg r: 0.3763
17:10:45,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:11,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:37,463 root INFO Epoch 12 Global steps: 38200 Train loss: 0.2479
en_de Dev loss: 0.9584 r:0.1529
en_zh Dev loss: 0.8265 r:0.4706
Current avg r:0.3118 Best avg r: 0.3763
17:12:54,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:20,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:45,941 root INFO Epoch 12 Global steps: 38400 Train loss: 0.2400
en_de Dev loss: 0.9518 r:0.1450
en_zh Dev loss: 0.8324 r:0.4709
Current avg r:0.3079 Best avg r: 0.3763
17:15:02,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:28,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:54,271 root INFO Epoch 12 Global steps: 38600 Train loss: 0.2441
en_de Dev loss: 0.9572 r:0.1631
en_zh Dev loss: 0.7653 r:0.4842
Current avg r:0.3236 Best avg r: 0.3763
17:17:10,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:36,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:02,831 root INFO Epoch 12 Global steps: 38800 Train loss: 0.2136
en_de Dev loss: 0.9780 r:0.1621
en_zh Dev loss: 0.7793 r:0.4880
Current avg r:0.3250 Best avg r: 0.3763
17:19:19,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:45,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:11,327 root INFO Epoch 12 Global steps: 39000 Train loss: 0.2154
en_de Dev loss: 0.9464 r:0.1608
en_zh Dev loss: 0.7252 r:0.4949
Current avg r:0.3278 Best avg r: 0.3763
17:21:28,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:54,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:20,201 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1981
en_de Dev loss: 0.9446 r:0.1712
en_zh Dev loss: 0.7617 r:0.4917
Current avg r:0.3315 Best avg r: 0.3763
17:23:36,916 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:02,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:28,757 root INFO Epoch 13 Global steps: 39400 Train loss: 0.2130
en_de Dev loss: 0.9459 r:0.1733
en_zh Dev loss: 0.8192 r:0.4828
Current avg r:0.3280 Best avg r: 0.3763
17:25:45,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:11,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:37,246 root INFO Epoch 13 Global steps: 39600 Train loss: 0.2082
en_de Dev loss: 0.9773 r:0.1740
en_zh Dev loss: 0.8377 r:0.4857
Current avg r:0.3299 Best avg r: 0.3763
17:27:53,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:19,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:45,492 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1941
en_de Dev loss: 0.9300 r:0.1835
en_zh Dev loss: 0.7694 r:0.4875
Current avg r:0.3355 Best avg r: 0.3763
17:30:02,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:28,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:53,982 root INFO Epoch 13 Global steps: 40000 Train loss: 0.2247
en_de Dev loss: 0.9320 r:0.1744
en_zh Dev loss: 0.7257 r:0.4999
Current avg r:0.3371 Best avg r: 0.3763
17:32:10,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:36,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:02,474 root INFO Epoch 13 Global steps: 40200 Train loss: 0.2108
en_de Dev loss: 0.9488 r:0.1799
en_zh Dev loss: 0.7845 r:0.4888
Current avg r:0.3344 Best avg r: 0.3763
17:34:18,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:44,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:10,762 root INFO Epoch 13 Global steps: 40400 Train loss: 0.2064
en_de Dev loss: 0.9218 r:0.1797
en_zh Dev loss: 0.7501 r:0.4762
Current avg r:0.3279 Best avg r: 0.3763
17:36:27,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:53,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:19,59 root INFO Epoch 13 Global steps: 40600 Train loss: 0.2187
en_de Dev loss: 0.9283 r:0.1984
en_zh Dev loss: 0.7698 r:0.4911
Current avg r:0.3448 Best avg r: 0.3763
17:38:35,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:01,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:27,413 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1969
en_de Dev loss: 0.9313 r:0.1945
en_zh Dev loss: 0.7562 r:0.4901
Current avg r:0.3423 Best avg r: 0.3763
17:40:44,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:09,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:35,933 root INFO Epoch 13 Global steps: 41000 Train loss: 0.2095
en_de Dev loss: 0.9424 r:0.1784
en_zh Dev loss: 0.7664 r:0.4915
Current avg r:0.3350 Best avg r: 0.3763
17:42:52,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:18,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:44,306 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1858
en_de Dev loss: 0.9210 r:0.1841
en_zh Dev loss: 0.7266 r:0.4921
Current avg r:0.3381 Best avg r: 0.3763
17:45:00,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:26,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:52,556 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1954
en_de Dev loss: 0.9393 r:0.1795
en_zh Dev loss: 0.7851 r:0.4818
Current avg r:0.3306 Best avg r: 0.3763
17:47:08,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:34,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:00,704 root INFO Epoch 13 Global steps: 41600 Train loss: 0.2038
en_de Dev loss: 0.9729 r:0.1754
en_zh Dev loss: 0.8291 r:0.4847
Current avg r:0.3301 Best avg r: 0.3763
17:49:17,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:43,87 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:09,17 root INFO Epoch 13 Global steps: 41800 Train loss: 0.2072
en_de Dev loss: 0.9211 r:0.1821
en_zh Dev loss: 0.7387 r:0.4920
Current avg r:0.3370 Best avg r: 0.3763
17:51:25,445 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:51,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:17,281 root INFO Epoch 13 Global steps: 42000 Train loss: 0.2060
en_de Dev loss: 0.9433 r:0.1720
en_zh Dev loss: 0.7682 r:0.4916
Current avg r:0.3318 Best avg r: 0.3763
17:53:33,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:59,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:25,825 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1841
en_de Dev loss: 0.9498 r:0.1705
en_zh Dev loss: 0.8181 r:0.4772
Current avg r:0.3238 Best avg r: 0.3763
17:55:42,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:08,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:34,160 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1776
en_de Dev loss: 0.9060 r:0.1785
en_zh Dev loss: 0.7289 r:0.4844
Current avg r:0.3314 Best avg r: 0.3763
17:57:50,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:16,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:42,431 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1858
en_de Dev loss: 0.9649 r:0.1668
en_zh Dev loss: 0.8011 r:0.4839
Current avg r:0.3253 Best avg r: 0.3763
17:59:58,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:24,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:50,696 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1720
en_de Dev loss: 0.9697 r:0.1615
en_zh Dev loss: 0.7848 r:0.4858
Current avg r:0.3236 Best avg r: 0.3763
18:02:07,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:33,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:58,981 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1851
en_de Dev loss: 0.9476 r:0.1604
en_zh Dev loss: 0.7682 r:0.4817
Current avg r:0.3210 Best avg r: 0.3763
18:04:15,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:41,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:07,262 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1825
en_de Dev loss: 0.9597 r:0.1673
en_zh Dev loss: 0.7877 r:0.4894
Current avg r:0.3284 Best avg r: 0.3763
18:06:23,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:49,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:15,591 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1796
en_de Dev loss: 0.9651 r:0.1651
en_zh Dev loss: 0.8134 r:0.4908
Current avg r:0.3280 Best avg r: 0.3763
18:08:32,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:58,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:24,33 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1856
en_de Dev loss: 0.9766 r:0.1683
en_zh Dev loss: 0.8552 r:0.4829
Current avg r:0.3256 Best avg r: 0.3763
18:10:40,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:06,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:32,394 root INFO Epoch 14 Global steps: 43800 Train loss: 0.2017
en_de Dev loss: 0.9490 r:0.1678
en_zh Dev loss: 0.7368 r:0.4932
Current avg r:0.3305 Best avg r: 0.3763
18:12:48,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:14,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:40,674 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1878
en_de Dev loss: 0.9597 r:0.1601
en_zh Dev loss: 0.7716 r:0.4863
Current avg r:0.3232 Best avg r: 0.3763
18:14:57,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:15:22,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:48,889 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1951
en_de Dev loss: 0.9298 r:0.1741
en_zh Dev loss: 0.7536 r:0.4886
Current avg r:0.3313 Best avg r: 0.3763
18:17:05,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:31,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:57,152 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1888
en_de Dev loss: 0.9023 r:0.1726
en_zh Dev loss: 0.7165 r:0.4897
Current avg r:0.3311 Best avg r: 0.3763
18:19:13,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:39,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:05,359 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1768
en_de Dev loss: 0.9318 r:0.1769
en_zh Dev loss: 0.7552 r:0.4857
Current avg r:0.3313 Best avg r: 0.3763
18:21:21,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:47,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:13,647 root INFO Epoch 14 Global steps: 44800 Train loss: 0.2009
en_de Dev loss: 0.9102 r:0.1831
en_zh Dev loss: 0.7433 r:0.4818
Current avg r:0.3325 Best avg r: 0.3763
18:23:30,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:56,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:22,52 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1927
en_de Dev loss: 0.9593 r:0.1683
en_zh Dev loss: 0.7907 r:0.4801
Current avg r:0.3242 Best avg r: 0.3763
18:25:38,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:04,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:30,630 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1651
en_de Dev loss: 0.9654 r:0.1572
en_zh Dev loss: 0.7455 r:0.4856
Current avg r:0.3214 Best avg r: 0.3763
18:27:47,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:12,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:38,810 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1590
en_de Dev loss: 0.9319 r:0.1643
en_zh Dev loss: 0.7295 r:0.4907
Current avg r:0.3275 Best avg r: 0.3763
18:29:55,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:21,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:47,216 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1783
en_de Dev loss: 0.9344 r:0.1781
en_zh Dev loss: 0.7788 r:0.4802
Current avg r:0.3292 Best avg r: 0.3763
18:32:03,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:29,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:55,536 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1782
en_de Dev loss: 0.9391 r:0.1681
en_zh Dev loss: 0.7373 r:0.4872
Current avg r:0.3277 Best avg r: 0.3763
18:34:11,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:37,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:03,823 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1905
en_de Dev loss: 0.9254 r:0.1732
en_zh Dev loss: 0.7430 r:0.4877
Current avg r:0.3305 Best avg r: 0.3763
18:36:20,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:46,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:12,115 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1604
en_de Dev loss: 0.9652 r:0.1680
en_zh Dev loss: 0.8205 r:0.4823
Current avg r:0.3251 Best avg r: 0.3763
18:38:28,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:54,599 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:39:20,518 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1707
en_de Dev loss: 0.9575 r:0.1619
en_zh Dev loss: 0.7670 r:0.4860
Current avg r:0.3239 Best avg r: 0.3763
18:40:37,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:03,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:29,14 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1776
en_de Dev loss: 0.9912 r:0.1535
en_zh Dev loss: 0.7776 r:0.4882
Current avg r:0.3209 Best avg r: 0.3763
18:42:45,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:12,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:38,24 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1677
en_de Dev loss: 0.9596 r:0.1498
en_zh Dev loss: 0.7565 r:0.4903
Current avg r:0.3201 Best avg r: 0.3763
18:44:55,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:21,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:47,264 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1801
en_de Dev loss: 0.9894 r:0.1533
en_zh Dev loss: 0.8473 r:0.4788
Current avg r:0.3160 Best avg r: 0.3763
18:47:04,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:30,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:56,441 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1846
en_de Dev loss: 1.0046 r:0.1525
en_zh Dev loss: 0.8299 r:0.4844
Current avg r:0.3184 Best avg r: 0.3763
18:49:13,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:39,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:04,950 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1671
en_de Dev loss: 0.9847 r:0.1571
en_zh Dev loss: 0.8286 r:0.4827
Current avg r:0.3199 Best avg r: 0.3763
18:51:21,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:47,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:13,574 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1662
en_de Dev loss: 0.9426 r:0.1703
en_zh Dev loss: 0.7456 r:0.4879
Current avg r:0.3291 Best avg r: 0.3763
18:53:30,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:55,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:21,888 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1742
en_de Dev loss: 0.9312 r:0.1725
en_zh Dev loss: 0.7379 r:0.4895
Current avg r:0.3310 Best avg r: 0.3763
18:55:38,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:04,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:56:30,120 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1614
en_de Dev loss: 0.9268 r:0.1763
en_zh Dev loss: 0.7413 r:0.4865
Current avg r:0.3314 Best avg r: 0.3763
18:57:47,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:13,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:39,127 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1521
en_de Dev loss: 0.9845 r:0.1626
en_zh Dev loss: 0.8196 r:0.4841
Current avg r:0.3233 Best avg r: 0.3763
18:59:55,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:21,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:47,776 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1529
en_de Dev loss: 0.9297 r:0.1737
en_zh Dev loss: 0.7507 r:0.4839
Current avg r:0.3288 Best avg r: 0.3763
19:02:04,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:30,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:56,109 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1692
en_de Dev loss: 0.9286 r:0.1709
en_zh Dev loss: 0.7544 r:0.4796
Current avg r:0.3252 Best avg r: 0.3763
19:04:12,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:38,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:04,479 root INFO Epoch 16 Global steps: 48800 Train loss: 0.1566
en_de Dev loss: 0.9597 r:0.1684
en_zh Dev loss: 0.7482 r:0.4949
Current avg r:0.3316 Best avg r: 0.3763
19:06:21,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:47,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:13,343 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1630
en_de Dev loss: 1.0058 r:0.1687
en_zh Dev loss: 0.8500 r:0.4868
Current avg r:0.3277 Best avg r: 0.3763
19:08:29,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:55,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:21,836 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1676
en_de Dev loss: 0.9607 r:0.1773
en_zh Dev loss: 0.7519 r:0.4913
Current avg r:0.3343 Best avg r: 0.3763
19:10:38,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:04,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:30,413 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1661
en_de Dev loss: 0.9569 r:0.1610
en_zh Dev loss: 0.7547 r:0.4753
Current avg r:0.3182 Best avg r: 0.3763
19:12:46,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:12,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:38,932 root INFO Epoch 16 Global steps: 49600 Train loss: 0.1559
en_de Dev loss: 0.9536 r:0.1715
en_zh Dev loss: 0.7667 r:0.4788
Current avg r:0.3251 Best avg r: 0.3763
19:14:55,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:21,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:47,696 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1504
en_de Dev loss: 0.9406 r:0.1748
en_zh Dev loss: 0.7596 r:0.4796
Current avg r:0.3272 Best avg r: 0.3763
19:17:04,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:30,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:56,226 root INFO Epoch 16 Global steps: 50000 Train loss: 0.1557
en_de Dev loss: 0.9695 r:0.1784
en_zh Dev loss: 0.7800 r:0.4810
Current avg r:0.3297 Best avg r: 0.3763
19:19:12,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:39,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:04,935 root INFO Epoch 16 Global steps: 50200 Train loss: 0.1586
en_de Dev loss: 0.9841 r:0.1729
en_zh Dev loss: 0.7677 r:0.4855
Current avg r:0.3292 Best avg r: 0.3763
19:21:21,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:47,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:13,623 root INFO Epoch 16 Global steps: 50400 Train loss: 0.1694
en_de Dev loss: 0.9533 r:0.1758
en_zh Dev loss: 0.7460 r:0.4883
Current avg r:0.3320 Best avg r: 0.3763
19:23:30,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:56,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:22,264 root INFO Epoch 16 Global steps: 50600 Train loss: 0.1526
en_de Dev loss: 0.9764 r:0.1723
en_zh Dev loss: 0.8087 r:0.4833
Current avg r:0.3278 Best avg r: 0.3763
19:25:38,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:04,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:30,842 root INFO Epoch 16 Global steps: 50800 Train loss: 0.1591
en_de Dev loss: 0.9912 r:0.1679
en_zh Dev loss: 0.7812 r:0.4861
Current avg r:0.3270 Best avg r: 0.3763
