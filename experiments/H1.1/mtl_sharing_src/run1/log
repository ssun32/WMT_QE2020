09:59:34,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:00:00,318 root INFO 
id:en_de cur r: 0.0074 best r: 0.0074
10:00:25,853 root INFO 
id:en_zh cur r: 0.0004 best r: 0.0004
10:00:25,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:51,410 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:00:51,417 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:01:16,977 root INFO Epoch 0 Global steps: 200 Train loss: 1.2265
en_de Dev loss: 0.8930 r:-0.0053
en_zh Dev loss: 0.8152 r:0.0859
Current avg r:0.0403 Best avg r: 0.0403
10:02:32,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:58,211 root INFO 
id:en_de cur r: 0.0561 best r: 0.0561
10:03:10,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:36,531 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:03:36,541 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:04:02,146 root INFO Epoch 0 Global steps: 400 Train loss: 1.1215
en_de Dev loss: 0.8922 r:-0.0073
en_zh Dev loss: 0.8127 r:0.1136
Current avg r:0.0531 Best avg r: 0.0531
10:05:18,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:43,727 root INFO 
id:en_de cur r: 0.0688 best r: 0.0688
10:06:09,480 root INFO 
id:en_zh cur r: 0.0780 best r: 0.0780
10:06:09,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:35,61 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:06:35,70 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:07:00,675 root INFO Epoch 0 Global steps: 600 Train loss: 1.1043
en_de Dev loss: 0.8887 r:-0.0225
en_zh Dev loss: 0.8095 r:0.1496
Current avg r:0.0635 Best avg r: 0.0635
10:08:16,294 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:41,876 root INFO 
id:en_de cur r: 0.0929 best r: 0.0929
10:09:07,400 root INFO 
id:en_zh cur r: 0.1049 best r: 0.1049
10:09:07,401 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:32,981 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:09:32,989 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:09:58,558 root INFO Epoch 0 Global steps: 800 Train loss: 1.0362
en_de Dev loss: 0.8879 r:-0.0048
en_zh Dev loss: 0.8043 r:0.1972
Current avg r:0.0962 Best avg r: 0.0962
10:11:14,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:39,758 root INFO 
id:en_de cur r: 0.1093 best r: 0.1093
10:12:05,292 root INFO 
id:en_zh cur r: 0.1474 best r: 0.1474
10:12:05,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:30,874 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:12:30,883 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:12:56,493 root INFO Epoch 0 Global steps: 1000 Train loss: 1.0224
en_de Dev loss: 0.8854 r:0.0629
en_zh Dev loss: 0.8004 r:0.2304
Current avg r:0.1467 Best avg r: 0.1467
10:14:12,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:37,767 root INFO 
id:en_de cur r: 0.1287 best r: 0.1287
10:15:03,326 root INFO 
id:en_zh cur r: 0.2121 best r: 0.2121
10:15:03,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:28,894 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:15:28,901 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:15:54,615 root INFO Epoch 0 Global steps: 1200 Train loss: 1.1989
en_de Dev loss: 0.8863 r:0.0609
en_zh Dev loss: 0.7950 r:0.2816
Current avg r:0.1712 Best avg r: 0.1712
10:17:10,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:17:35,963 root INFO 
id:en_de cur r: 0.1356 best r: 0.1356
10:18:01,502 root INFO 
id:en_zh cur r: 0.2584 best r: 0.2584
10:18:01,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:18:27,158 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:18:27,165 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:18:52,810 root INFO Epoch 0 Global steps: 1400 Train loss: 1.3193
en_de Dev loss: 0.8818 r:0.0909
en_zh Dev loss: 0.7944 r:0.3091
Current avg r:0.2000 Best avg r: 0.2000
10:20:08,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:46,676 root INFO 
id:en_zh cur r: 0.3217 best r: 0.3217
10:20:46,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:21:12,364 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:21:12,371 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:21:37,999 root INFO Epoch 0 Global steps: 1600 Train loss: 1.0890
en_de Dev loss: 0.8835 r:0.1068
en_zh Dev loss: 0.7852 r:0.3153
Current avg r:0.2110 Best avg r: 0.2110
10:22:53,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:23:32,37 root INFO 
id:en_zh cur r: 0.3309 best r: 0.3309
10:23:32,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:57,752 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:23:57,758 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:24:23,392 root INFO Epoch 0 Global steps: 1800 Train loss: 1.1911
en_de Dev loss: 0.8810 r:0.1276
en_zh Dev loss: 0.7701 r:0.3158
Current avg r:0.2217 Best avg r: 0.2217
10:25:38,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:26:04,472 root INFO 
id:en_de cur r: 0.1554 best r: 0.1554
10:26:30,60 root INFO 
id:en_zh cur r: 0.3520 best r: 0.3520
10:26:30,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:55,744 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:26:55,758 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:27:21,375 root INFO Epoch 0 Global steps: 2000 Train loss: 0.9610
en_de Dev loss: 0.8931 r:0.1642
en_zh Dev loss: 0.7649 r:0.3531
Current avg r:0.2587 Best avg r: 0.2587
10:28:36,891 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:15,298 root INFO 
id:en_zh cur r: 0.3841 best r: 0.3841
10:29:15,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:41,13 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:29:41,19 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:30:06,661 root INFO Epoch 0 Global steps: 2200 Train loss: 1.3377
en_de Dev loss: 0.9212 r:0.1663
en_zh Dev loss: 0.7358 r:0.3755
Current avg r:0.2709 Best avg r: 0.2709
10:31:22,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:32:00,877 root INFO 
id:en_zh cur r: 0.3889 best r: 0.3889
10:32:00,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:32:26,575 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:32:26,585 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:32:52,190 root INFO Epoch 0 Global steps: 2400 Train loss: 1.0171
en_de Dev loss: 0.8784 r:0.1961
en_zh Dev loss: 0.7544 r:0.3806
Current avg r:0.2884 Best avg r: 0.2884
10:34:07,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:34:33,287 root INFO 
id:en_de cur r: 0.1791 best r: 0.1791
10:34:59,12 root INFO 
id:en_zh cur r: 0.4039 best r: 0.4039
10:34:59,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:35:24,635 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:35:24,642 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:35:50,238 root INFO Epoch 0 Global steps: 2600 Train loss: 1.1253
en_de Dev loss: 0.8669 r:0.2075
en_zh Dev loss: 0.6920 r:0.4005
Current avg r:0.3040 Best avg r: 0.3040
10:37:05,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:37:31,564 root INFO 
id:en_de cur r: 0.1915 best r: 0.1915
10:37:44,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:38:10,103 root INFO Epoch 0 Global steps: 2800 Train loss: 0.8829
en_de Dev loss: 0.9031 r:0.1962
en_zh Dev loss: 0.7860 r:0.3802
Current avg r:0.2882 Best avg r: 0.3040
10:39:25,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:39:51,404 root INFO 
id:en_de cur r: 0.1920 best r: 0.1920
10:40:17,13 root INFO 
id:en_zh cur r: 0.4244 best r: 0.4244
10:40:17,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:40:42,753 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:40:42,760 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:41:08,341 root INFO Epoch 0 Global steps: 3000 Train loss: 1.0399
en_de Dev loss: 0.8624 r:0.1974
en_zh Dev loss: 0.6876 r:0.4193
Current avg r:0.3083 Best avg r: 0.3083
10:42:24,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:42:49,861 root INFO 
id:en_de cur r: 0.1921 best r: 0.1921
10:43:02,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:43:28,332 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:43:28,338 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:43:53,974 root INFO Epoch 1 Global steps: 3200 Train loss: 0.9931
en_de Dev loss: 0.8587 r:0.2017
en_zh Dev loss: 0.6952 r:0.4234
Current avg r:0.3126 Best avg r: 0.3126
10:45:09,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:45:35,179 root INFO 
id:en_de cur r: 0.1958 best r: 0.1958
10:45:48,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:46:13,718 root INFO Epoch 1 Global steps: 3400 Train loss: 1.0389
en_de Dev loss: 0.8601 r:0.1984
en_zh Dev loss: 0.6934 r:0.4154
Current avg r:0.3069 Best avg r: 0.3126
10:47:29,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:47:55,322 root INFO 
id:en_de cur r: 0.2095 best r: 0.2095
10:48:20,894 root INFO 
id:en_zh cur r: 0.4368 best r: 0.4368
10:48:20,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:48:46,608 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:48:46,615 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:49:12,241 root INFO Epoch 1 Global steps: 3600 Train loss: 1.0333
en_de Dev loss: 0.8954 r:0.2146
en_zh Dev loss: 0.7519 r:0.4311
Current avg r:0.3229 Best avg r: 0.3229
10:50:27,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:50:53,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:51:19,194 root INFO Epoch 1 Global steps: 3800 Train loss: 0.8762
en_de Dev loss: 0.8929 r:0.2112
en_zh Dev loss: 0.7898 r:0.4226
Current avg r:0.3169 Best avg r: 0.3229
10:52:34,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:53:13,301 root INFO 
id:en_zh cur r: 0.4437 best r: 0.4437
10:53:13,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:53:38,869 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:53:38,877 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:54:04,559 root INFO Epoch 1 Global steps: 4000 Train loss: 1.0843
en_de Dev loss: 0.8721 r:0.2136
en_zh Dev loss: 0.7280 r:0.4373
Current avg r:0.3255 Best avg r: 0.3255
10:55:20,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:55:45,774 root INFO 
id:en_de cur r: 0.2221 best r: 0.2221
10:56:11,377 root INFO 
id:en_zh cur r: 0.4520 best r: 0.4520
10:56:11,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:56:36,961 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:56:36,968 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:57:02,724 root INFO Epoch 1 Global steps: 4200 Train loss: 0.9938
en_de Dev loss: 0.8615 r:0.2173
en_zh Dev loss: 0.6917 r:0.4499
Current avg r:0.3336 Best avg r: 0.3336
10:58:18,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:58:56,706 root INFO 
id:en_zh cur r: 0.4547 best r: 0.4547
10:58:56,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:59:22,278 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:59:22,285 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:59:48,52 root INFO Epoch 1 Global steps: 4400 Train loss: 0.9755
en_de Dev loss: 0.8616 r:0.2218
en_zh Dev loss: 0.7258 r:0.4471
Current avg r:0.3345 Best avg r: 0.3345
11:01:03,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:01:29,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:01:54,761 root INFO Epoch 1 Global steps: 4600 Train loss: 0.8639
en_de Dev loss: 0.8506 r:0.2130
en_zh Dev loss: 0.7173 r:0.4440
Current avg r:0.3285 Best avg r: 0.3345
11:03:10,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:03:48,915 root INFO 
id:en_zh cur r: 0.4677 best r: 0.4677
11:03:48,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:04:14,472 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
11:04:14,478 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:04:40,122 root INFO Epoch 1 Global steps: 4800 Train loss: 0.8504
en_de Dev loss: 0.8465 r:0.2159
en_zh Dev loss: 0.6469 r:0.4602
Current avg r:0.3380 Best avg r: 0.3380
11:05:55,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:06:34,285 root INFO 
id:en_zh cur r: 0.4683 best r: 0.4683
11:06:34,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:06:59,857 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
11:06:59,862 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:07:25,474 root INFO Epoch 1 Global steps: 5000 Train loss: 0.9529
en_de Dev loss: 0.8685 r:0.2370
en_zh Dev loss: 0.7445 r:0.4590
Current avg r:0.3480 Best avg r: 0.3480
11:08:41,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:09:06,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:09:32,378 root INFO Epoch 1 Global steps: 5200 Train loss: 0.8225
en_de Dev loss: 0.8530 r:0.2181
en_zh Dev loss: 0.7357 r:0.4472
Current avg r:0.3326 Best avg r: 0.3480
11:10:47,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:11:13,376 root INFO 
id:en_de cur r: 0.2336 best r: 0.2336
11:11:38,915 root INFO 
id:en_zh cur r: 0.4781 best r: 0.4781
11:11:38,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:12:04,491 root INFO Epoch 1 Global steps: 5400 Train loss: 0.9830
en_de Dev loss: 0.8457 r:0.2258
en_zh Dev loss: 0.7006 r:0.4673
Current avg r:0.3466 Best avg r: 0.3480
11:13:19,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:13:45,262 root INFO 
id:en_de cur r: 0.2450 best r: 0.2450
11:13:57,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:14:23,481 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
11:14:23,488 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:14:48,961 root INFO Epoch 1 Global steps: 5600 Train loss: 0.9922
en_de Dev loss: 0.8396 r:0.2441
en_zh Dev loss: 0.6849 r:0.4691
Current avg r:0.3566 Best avg r: 0.3566
11:16:03,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:16:29,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:16:54,660 root INFO Epoch 1 Global steps: 5800 Train loss: 0.8282
en_de Dev loss: 0.8430 r:0.2366
en_zh Dev loss: 0.6631 r:0.4690
Current avg r:0.3528 Best avg r: 0.3566
11:18:09,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:18:34,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:19:00,388 root INFO Epoch 1 Global steps: 6000 Train loss: 1.0276
en_de Dev loss: 0.8362 r:0.2394
en_zh Dev loss: 0.6874 r:0.4555
Current avg r:0.3475 Best avg r: 0.3566
11:20:15,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:20:41,173 root INFO 
id:en_de cur r: 0.2494 best r: 0.2494
11:20:53,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:21:19,370 root INFO Epoch 2 Global steps: 6200 Train loss: 0.9038
en_de Dev loss: 0.8602 r:0.2433
en_zh Dev loss: 0.7704 r:0.4475
Current avg r:0.3454 Best avg r: 0.3566
11:22:34,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:22:59,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:23:25,164 root INFO Epoch 2 Global steps: 6400 Train loss: 0.8321
en_de Dev loss: 0.8504 r:0.2345
en_zh Dev loss: 0.7334 r:0.4473
Current avg r:0.3409 Best avg r: 0.3566
11:24:40,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:25:05,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:25:30,868 root INFO Epoch 2 Global steps: 6600 Train loss: 0.8921
en_de Dev loss: 0.8684 r:0.2372
en_zh Dev loss: 0.7526 r:0.4526
Current avg r:0.3449 Best avg r: 0.3566
11:26:45,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:27:11,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:27:36,595 root INFO Epoch 2 Global steps: 6800 Train loss: 0.8780
en_de Dev loss: 0.8399 r:0.2338
en_zh Dev loss: 0.6678 r:0.4632
Current avg r:0.3485 Best avg r: 0.3566
11:28:51,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:29:16,968 root INFO 
id:en_de cur r: 0.2509 best r: 0.2509
11:29:29,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:29:55,197 root INFO Epoch 2 Global steps: 7000 Train loss: 0.7151
en_de Dev loss: 0.8403 r:0.2426
en_zh Dev loss: 0.7261 r:0.4585
Current avg r:0.3505 Best avg r: 0.3566
11:31:10,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:31:35,824 root INFO 
id:en_de cur r: 0.2654 best r: 0.2654
11:31:48,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:32:14,14 root INFO Epoch 2 Global steps: 7200 Train loss: 0.8382
en_de Dev loss: 0.8401 r:0.2497
en_zh Dev loss: 0.7335 r:0.4539
Current avg r:0.3518 Best avg r: 0.3566
11:33:28,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:33:54,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:34:19,808 root INFO Epoch 2 Global steps: 7400 Train loss: 0.9312
en_de Dev loss: 0.8368 r:0.2392
en_zh Dev loss: 0.6806 r:0.4623
Current avg r:0.3507 Best avg r: 0.3566
11:35:35,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:36:01,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:36:27,163 root INFO Epoch 2 Global steps: 7600 Train loss: 0.8952
en_de Dev loss: 0.8484 r:0.2250
en_zh Dev loss: 0.7095 r:0.4501
Current avg r:0.3376 Best avg r: 0.3566
11:37:43,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:38:09,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:38:34,826 root INFO Epoch 2 Global steps: 7800 Train loss: 0.9470
en_de Dev loss: 0.8636 r:0.2213
en_zh Dev loss: 0.7576 r:0.4506
Current avg r:0.3359 Best avg r: 0.3566
11:39:51,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:40:16,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:40:42,443 root INFO Epoch 2 Global steps: 8000 Train loss: 0.8340
en_de Dev loss: 0.8531 r:0.2442
en_zh Dev loss: 0.7647 r:0.4569
Current avg r:0.3506 Best avg r: 0.3566
11:41:58,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:42:24,422 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:42:50,153 root INFO Epoch 2 Global steps: 8200 Train loss: 0.7295
en_de Dev loss: 0.8474 r:0.2489
en_zh Dev loss: 0.8096 r:0.4493
Current avg r:0.3491 Best avg r: 0.3566
11:44:06,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:44:32,148 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:44:57,916 root INFO Epoch 2 Global steps: 8400 Train loss: 0.8240
en_de Dev loss: 0.8525 r:0.2418
en_zh Dev loss: 0.8436 r:0.4571
Current avg r:0.3495 Best avg r: 0.3566
11:46:14,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:46:40,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:47:05,927 root INFO Epoch 2 Global steps: 8600 Train loss: 0.9387
en_de Dev loss: 0.8461 r:0.2292
en_zh Dev loss: 0.7129 r:0.4688
Current avg r:0.3490 Best avg r: 0.3566
11:48:22,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:48:47,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:49:13,676 root INFO Epoch 2 Global steps: 8800 Train loss: 0.7886
en_de Dev loss: 0.8516 r:0.2369
en_zh Dev loss: 0.7534 r:0.4665
Current avg r:0.3517 Best avg r: 0.3566
11:50:29,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:50:55,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:51:21,379 root INFO Epoch 2 Global steps: 9000 Train loss: 0.8225
en_de Dev loss: 0.8469 r:0.2307
en_zh Dev loss: 0.7282 r:0.4680
Current avg r:0.3494 Best avg r: 0.3566
11:52:38,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:53:16,782 root INFO 
id:en_zh cur r: 0.4855 best r: 0.4855
11:53:16,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:53:42,448 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
11:53:42,454 root INFO Saving best dev results to: experiments/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:54:08,157 root INFO Epoch 3 Global steps: 9200 Train loss: 0.6599
en_de Dev loss: 0.8464 r:0.2367
en_zh Dev loss: 0.6993 r:0.4783
Current avg r:0.3575 Best avg r: 0.3575
11:55:24,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:55:50,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:56:16,62 root INFO Epoch 3 Global steps: 9400 Train loss: 0.7536
en_de Dev loss: 0.8594 r:0.2362
en_zh Dev loss: 0.8124 r:0.4612
Current avg r:0.3487 Best avg r: 0.3575
11:57:32,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:57:58,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:58:23,757 root INFO Epoch 3 Global steps: 9600 Train loss: 0.8485
en_de Dev loss: 0.8475 r:0.2464
en_zh Dev loss: 0.7920 r:0.4578
Current avg r:0.3521 Best avg r: 0.3575
11:59:40,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:00:05,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:00:31,616 root INFO Epoch 3 Global steps: 9800 Train loss: 0.7436
en_de Dev loss: 0.8503 r:0.2324
en_zh Dev loss: 0.7585 r:0.4686
Current avg r:0.3505 Best avg r: 0.3575
12:01:48,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:02:13,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:02:39,587 root INFO Epoch 3 Global steps: 10000 Train loss: 0.8121
en_de Dev loss: 0.8529 r:0.2366
en_zh Dev loss: 0.8130 r:0.4638
Current avg r:0.3502 Best avg r: 0.3575
12:03:55,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:04:21,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:04:47,182 root INFO Epoch 3 Global steps: 10200 Train loss: 0.6521
en_de Dev loss: 0.8536 r:0.2318
en_zh Dev loss: 0.7843 r:0.4615
Current avg r:0.3466 Best avg r: 0.3575
12:06:03,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:06:29,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:06:54,741 root INFO Epoch 3 Global steps: 10400 Train loss: 0.8305
en_de Dev loss: 0.8531 r:0.2189
en_zh Dev loss: 0.7913 r:0.4563
Current avg r:0.3376 Best avg r: 0.3575
12:08:11,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:08:36,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:09:02,335 root INFO Epoch 3 Global steps: 10600 Train loss: 0.6849
en_de Dev loss: 0.8413 r:0.2433
en_zh Dev loss: 0.7572 r:0.4702
Current avg r:0.3567 Best avg r: 0.3575
12:10:18,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:10:44,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:11:10,124 root INFO Epoch 3 Global steps: 10800 Train loss: 0.6859
en_de Dev loss: 0.8624 r:0.2406
en_zh Dev loss: 0.8911 r:0.4503
Current avg r:0.3455 Best avg r: 0.3575
12:12:26,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:12:51,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:13:17,647 root INFO Epoch 3 Global steps: 11000 Train loss: 0.7704
en_de Dev loss: 0.8611 r:0.2307
en_zh Dev loss: 0.8434 r:0.4573
Current avg r:0.3440 Best avg r: 0.3575
12:14:33,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:14:59,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:15:25,245 root INFO Epoch 3 Global steps: 11200 Train loss: 0.7259
en_de Dev loss: 0.8496 r:0.2320
en_zh Dev loss: 0.7852 r:0.4493
Current avg r:0.3406 Best avg r: 0.3575
12:16:41,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:17:07,342 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:17:33,0 root INFO Epoch 3 Global steps: 11400 Train loss: 0.6743
en_de Dev loss: 0.8669 r:0.2338
en_zh Dev loss: 0.8357 r:0.4445
Current avg r:0.3392 Best avg r: 0.3575
12:18:49,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:19:14,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:19:40,536 root INFO Epoch 3 Global steps: 11600 Train loss: 0.7124
en_de Dev loss: 0.8988 r:0.2322
en_zh Dev loss: 0.8951 r:0.4449
Current avg r:0.3385 Best avg r: 0.3575
12:20:56,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:21:22,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:21:48,154 root INFO Epoch 3 Global steps: 11800 Train loss: 0.7448
en_de Dev loss: 0.8730 r:0.2246
en_zh Dev loss: 0.7774 r:0.4671
Current avg r:0.3459 Best avg r: 0.3575
12:23:04,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:23:30,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:23:55,718 root INFO Epoch 3 Global steps: 12000 Train loss: 0.7364
en_de Dev loss: 0.8828 r:0.2222
en_zh Dev loss: 0.8457 r:0.4486
Current avg r:0.3354 Best avg r: 0.3575
12:25:12,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:25:38,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:26:03,739 root INFO Epoch 4 Global steps: 12200 Train loss: 0.6226
en_de Dev loss: 0.8543 r:0.2314
en_zh Dev loss: 0.7471 r:0.4668
Current avg r:0.3491 Best avg r: 0.3575
12:27:20,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:27:45,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:28:11,499 root INFO Epoch 4 Global steps: 12400 Train loss: 0.6417
en_de Dev loss: 0.8467 r:0.2420
en_zh Dev loss: 0.8052 r:0.4581
Current avg r:0.3501 Best avg r: 0.3575
12:29:27,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:29:53,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:30:19,94 root INFO Epoch 4 Global steps: 12600 Train loss: 0.6557
en_de Dev loss: 0.8457 r:0.2532
en_zh Dev loss: 0.8279 r:0.4523
Current avg r:0.3528 Best avg r: 0.3575
12:31:35,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:32:01,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:32:27,1 root INFO Epoch 4 Global steps: 12800 Train loss: 0.6603
en_de Dev loss: 0.8525 r:0.2263
en_zh Dev loss: 0.7658 r:0.4543
Current avg r:0.3403 Best avg r: 0.3575
12:33:43,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:34:09,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:34:34,748 root INFO Epoch 4 Global steps: 13000 Train loss: 0.6165
en_de Dev loss: 0.8813 r:0.2239
en_zh Dev loss: 0.8524 r:0.4509
Current avg r:0.3374 Best avg r: 0.3575
12:35:51,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:36:16,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:36:42,299 root INFO Epoch 4 Global steps: 13200 Train loss: 0.6072
en_de Dev loss: 0.8637 r:0.2213
en_zh Dev loss: 0.7868 r:0.4614
Current avg r:0.3413 Best avg r: 0.3575
12:37:58,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:38:24,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:38:49,892 root INFO Epoch 4 Global steps: 13400 Train loss: 0.6717
en_de Dev loss: 0.8441 r:0.2390
en_zh Dev loss: 0.8091 r:0.4432
Current avg r:0.3411 Best avg r: 0.3575
12:40:06,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:40:31,626 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:40:57,252 root INFO Epoch 4 Global steps: 13600 Train loss: 0.6534
en_de Dev loss: 0.8490 r:0.2256
en_zh Dev loss: 0.7809 r:0.4446
Current avg r:0.3351 Best avg r: 0.3575
12:42:13,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:42:38,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:43:04,479 root INFO Epoch 4 Global steps: 13800 Train loss: 0.6844
en_de Dev loss: 0.8705 r:0.2178
en_zh Dev loss: 0.7746 r:0.4684
Current avg r:0.3431 Best avg r: 0.3575
12:44:20,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:44:46,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:45:12,116 root INFO Epoch 4 Global steps: 14000 Train loss: 0.6073
en_de Dev loss: 0.8596 r:0.2239
en_zh Dev loss: 0.7879 r:0.4427
Current avg r:0.3333 Best avg r: 0.3575
12:46:28,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:46:53,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:47:19,257 root INFO Epoch 4 Global steps: 14200 Train loss: 0.6607
en_de Dev loss: 0.8765 r:0.2163
en_zh Dev loss: 0.8427 r:0.4347
Current avg r:0.3255 Best avg r: 0.3575
12:48:35,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:49:00,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:49:26,220 root INFO Epoch 4 Global steps: 14400 Train loss: 0.5582
en_de Dev loss: 0.8894 r:0.2088
en_zh Dev loss: 0.8176 r:0.4560
Current avg r:0.3324 Best avg r: 0.3575
12:50:41,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:51:07,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:51:33,69 root INFO Epoch 4 Global steps: 14600 Train loss: 0.5924
en_de Dev loss: 0.8743 r:0.2111
en_zh Dev loss: 0.8057 r:0.4472
Current avg r:0.3292 Best avg r: 0.3575
12:52:49,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:53:14,815 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:53:40,398 root INFO Epoch 4 Global steps: 14800 Train loss: 0.5770
en_de Dev loss: 0.8872 r:0.2100
en_zh Dev loss: 0.8483 r:0.4445
Current avg r:0.3273 Best avg r: 0.3575
12:54:56,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:55:21,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:55:47,426 root INFO Epoch 4 Global steps: 15000 Train loss: 0.5818
en_de Dev loss: 0.8857 r:0.2062
en_zh Dev loss: 0.8761 r:0.4435
Current avg r:0.3248 Best avg r: 0.3575
12:57:03,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:57:29,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:57:54,824 root INFO Epoch 5 Global steps: 15200 Train loss: 0.5528
en_de Dev loss: 0.8493 r:0.2353
en_zh Dev loss: 0.8257 r:0.4452
Current avg r:0.3402 Best avg r: 0.3575
12:59:10,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:59:36,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:00:01,905 root INFO Epoch 5 Global steps: 15400 Train loss: 0.4741
en_de Dev loss: 0.8678 r:0.2388
en_zh Dev loss: 0.8702 r:0.4360
Current avg r:0.3374 Best avg r: 0.3575
13:01:17,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:01:43,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:02:08,777 root INFO Epoch 5 Global steps: 15600 Train loss: 0.5417
en_de Dev loss: 0.8637 r:0.2395
en_zh Dev loss: 0.8508 r:0.4425
Current avg r:0.3410 Best avg r: 0.3575
13:03:24,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:03:50,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:04:15,755 root INFO Epoch 5 Global steps: 15800 Train loss: 0.4563
en_de Dev loss: 0.8727 r:0.2321
en_zh Dev loss: 0.8466 r:0.4401
Current avg r:0.3361 Best avg r: 0.3575
13:05:31,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:05:57,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:06:22,829 root INFO Epoch 5 Global steps: 16000 Train loss: 0.4899
en_de Dev loss: 0.9045 r:0.2366
en_zh Dev loss: 0.8856 r:0.4430
Current avg r:0.3398 Best avg r: 0.3575
13:07:38,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:08:04,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:08:29,789 root INFO Epoch 5 Global steps: 16200 Train loss: 0.4797
en_de Dev loss: 0.8517 r:0.2421
en_zh Dev loss: 0.7880 r:0.4588
Current avg r:0.3504 Best avg r: 0.3575
13:09:45,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:10:11,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:10:36,814 root INFO Epoch 5 Global steps: 16400 Train loss: 0.5381
en_de Dev loss: 0.8895 r:0.2175
en_zh Dev loss: 0.8469 r:0.4479
Current avg r:0.3327 Best avg r: 0.3575
13:11:53,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:12:18,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:12:44,257 root INFO Epoch 5 Global steps: 16600 Train loss: 0.5888
en_de Dev loss: 0.8559 r:0.2290
en_zh Dev loss: 0.8097 r:0.4400
Current avg r:0.3345 Best avg r: 0.3575
13:14:00,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:14:25,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:14:51,274 root INFO Epoch 5 Global steps: 16800 Train loss: 0.5701
en_de Dev loss: 0.8473 r:0.2424
en_zh Dev loss: 0.8206 r:0.4381
Current avg r:0.3403 Best avg r: 0.3575
13:16:06,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:16:32,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:16:58,169 root INFO Epoch 5 Global steps: 17000 Train loss: 0.5176
en_de Dev loss: 0.8507 r:0.2472
en_zh Dev loss: 0.8330 r:0.4377
Current avg r:0.3425 Best avg r: 0.3575
13:18:13,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:18:39,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:19:05,93 root INFO Epoch 5 Global steps: 17200 Train loss: 0.5020
en_de Dev loss: 0.8652 r:0.2388
en_zh Dev loss: 0.8312 r:0.4424
Current avg r:0.3406 Best avg r: 0.3575
13:20:21,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:20:46,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:21:12,184 root INFO Epoch 5 Global steps: 17400 Train loss: 0.5353
en_de Dev loss: 0.8734 r:0.2307
en_zh Dev loss: 0.8664 r:0.4401
Current avg r:0.3354 Best avg r: 0.3575
13:22:27,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:22:52,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:23:18,245 root INFO Epoch 5 Global steps: 17600 Train loss: 0.4961
en_de Dev loss: 0.8669 r:0.2462
en_zh Dev loss: 0.8990 r:0.4415
Current avg r:0.3439 Best avg r: 0.3575
13:24:33,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:24:58,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:25:24,475 root INFO Epoch 5 Global steps: 17800 Train loss: 0.5410
en_de Dev loss: 0.8792 r:0.2260
en_zh Dev loss: 0.8258 r:0.4579
Current avg r:0.3419 Best avg r: 0.3575
13:26:39,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:27:05,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:27:30,571 root INFO Epoch 5 Global steps: 18000 Train loss: 0.5084
en_de Dev loss: 0.8711 r:0.2198
en_zh Dev loss: 0.8257 r:0.4493
Current avg r:0.3346 Best avg r: 0.3575
13:28:45,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:29:11,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:29:36,916 root INFO Epoch 6 Global steps: 18200 Train loss: 0.4475
en_de Dev loss: 0.8829 r:0.2111
en_zh Dev loss: 0.8332 r:0.4503
Current avg r:0.3307 Best avg r: 0.3575
13:30:51,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:31:17,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:31:42,876 root INFO Epoch 6 Global steps: 18400 Train loss: 0.4637
en_de Dev loss: 0.8719 r:0.2174
en_zh Dev loss: 0.7681 r:0.4531
Current avg r:0.3353 Best avg r: 0.3575
13:32:58,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:33:23,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:33:49,24 root INFO Epoch 6 Global steps: 18600 Train loss: 0.4640
en_de Dev loss: 0.8724 r:0.2159
en_zh Dev loss: 0.7990 r:0.4596
Current avg r:0.3377 Best avg r: 0.3575
13:35:04,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:35:29,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:35:55,205 root INFO Epoch 6 Global steps: 18800 Train loss: 0.4048
en_de Dev loss: 0.8778 r:0.2060
en_zh Dev loss: 0.8021 r:0.4610
Current avg r:0.3335 Best avg r: 0.3575
13:37:10,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:37:35,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:38:01,461 root INFO Epoch 6 Global steps: 19000 Train loss: 0.5206
en_de Dev loss: 0.8942 r:0.2053
en_zh Dev loss: 0.8099 r:0.4687
Current avg r:0.3370 Best avg r: 0.3575
13:39:16,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:39:42,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:40:07,676 root INFO Epoch 6 Global steps: 19200 Train loss: 0.4378
en_de Dev loss: 0.8767 r:0.1985
en_zh Dev loss: 0.8337 r:0.4458
Current avg r:0.3221 Best avg r: 0.3575
13:41:22,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:41:48,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:42:13,724 root INFO Epoch 6 Global steps: 19400 Train loss: 0.5225
en_de Dev loss: 0.8805 r:0.2007
en_zh Dev loss: 0.8382 r:0.4488
Current avg r:0.3248 Best avg r: 0.3575
13:43:28,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:43:54,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:44:19,632 root INFO Epoch 6 Global steps: 19600 Train loss: 0.4275
en_de Dev loss: 0.8830 r:0.2284
en_zh Dev loss: 0.8207 r:0.4562
Current avg r:0.3423 Best avg r: 0.3575
13:45:34,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:46:00,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:46:25,566 root INFO Epoch 6 Global steps: 19800 Train loss: 0.4592
en_de Dev loss: 0.9054 r:0.2169
en_zh Dev loss: 0.8706 r:0.4412
Current avg r:0.3290 Best avg r: 0.3575
13:47:40,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:48:06,130 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:48:31,606 root INFO Epoch 6 Global steps: 20000 Train loss: 0.4716
en_de Dev loss: 0.9344 r:0.1954
en_zh Dev loss: 0.8516 r:0.4589
Current avg r:0.3271 Best avg r: 0.3575
13:49:46,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:50:12,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:50:37,721 root INFO Epoch 6 Global steps: 20200 Train loss: 0.4609
en_de Dev loss: 0.9156 r:0.2120
en_zh Dev loss: 0.8197 r:0.4714
Current avg r:0.3417 Best avg r: 0.3575
13:51:52,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:52:18,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:52:43,693 root INFO Epoch 6 Global steps: 20400 Train loss: 0.3979
en_de Dev loss: 0.9168 r:0.2071
en_zh Dev loss: 0.7975 r:0.4741
Current avg r:0.3406 Best avg r: 0.3575
13:53:58,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:54:24,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:54:49,691 root INFO Epoch 6 Global steps: 20600 Train loss: 0.4722
en_de Dev loss: 0.9207 r:0.2006
en_zh Dev loss: 0.8332 r:0.4619
Current avg r:0.3312 Best avg r: 0.3575
13:56:04,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:56:30,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:56:55,719 root INFO Epoch 6 Global steps: 20800 Train loss: 0.4055
en_de Dev loss: 0.8732 r:0.2142
en_zh Dev loss: 0.7736 r:0.4580
Current avg r:0.3361 Best avg r: 0.3575
13:58:10,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:58:36,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:59:01,787 root INFO Epoch 6 Global steps: 21000 Train loss: 0.4260
en_de Dev loss: 0.8954 r:0.2242
en_zh Dev loss: 0.8859 r:0.4527
Current avg r:0.3385 Best avg r: 0.3575
14:00:17,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:00:42,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:01:08,454 root INFO Epoch 7 Global steps: 21200 Train loss: 0.4262
en_de Dev loss: 0.9094 r:0.2137
en_zh Dev loss: 0.8451 r:0.4740
Current avg r:0.3439 Best avg r: 0.3575
14:02:23,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:02:49,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:03:14,740 root INFO Epoch 7 Global steps: 21400 Train loss: 0.3826
en_de Dev loss: 0.9087 r:0.2152
en_zh Dev loss: 0.8369 r:0.4745
Current avg r:0.3449 Best avg r: 0.3575
14:04:30,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:04:55,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:05:21,56 root INFO Epoch 7 Global steps: 21600 Train loss: 0.3552
en_de Dev loss: 0.8676 r:0.2339
en_zh Dev loss: 0.8209 r:0.4602
Current avg r:0.3470 Best avg r: 0.3575
14:06:36,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:07:01,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:07:27,320 root INFO Epoch 7 Global steps: 21800 Train loss: 0.3864
en_de Dev loss: 0.8934 r:0.2338
en_zh Dev loss: 0.8550 r:0.4606
Current avg r:0.3472 Best avg r: 0.3575
14:08:42,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:09:07,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:09:33,374 root INFO Epoch 7 Global steps: 22000 Train loss: 0.4202
en_de Dev loss: 0.8852 r:0.2269
en_zh Dev loss: 0.8707 r:0.4545
Current avg r:0.3407 Best avg r: 0.3575
14:10:48,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:11:13,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:11:39,377 root INFO Epoch 7 Global steps: 22200 Train loss: 0.3510
en_de Dev loss: 0.8812 r:0.2357
en_zh Dev loss: 0.8153 r:0.4593
Current avg r:0.3475 Best avg r: 0.3575
14:12:54,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:13:20,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:13:45,644 root INFO Epoch 7 Global steps: 22400 Train loss: 0.3799
en_de Dev loss: 0.8710 r:0.2500
en_zh Dev loss: 0.8532 r:0.4523
Current avg r:0.3512 Best avg r: 0.3575
14:15:00,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:15:26,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:15:51,725 root INFO Epoch 7 Global steps: 22600 Train loss: 0.3973
en_de Dev loss: 0.8629 r:0.2388
en_zh Dev loss: 0.7749 r:0.4694
Current avg r:0.3541 Best avg r: 0.3575
14:17:06,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:17:32,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:17:57,762 root INFO Epoch 7 Global steps: 22800 Train loss: 0.4449
en_de Dev loss: 0.8774 r:0.2278
en_zh Dev loss: 0.8036 r:0.4649
Current avg r:0.3464 Best avg r: 0.3575
14:19:12,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:19:38,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:20:03,825 root INFO Epoch 7 Global steps: 23000 Train loss: 0.4249
en_de Dev loss: 0.8716 r:0.2116
en_zh Dev loss: 0.7646 r:0.4596
Current avg r:0.3356 Best avg r: 0.3575
14:21:18,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:21:44,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:22:09,945 root INFO Epoch 7 Global steps: 23200 Train loss: 0.3934
en_de Dev loss: 0.8949 r:0.2128
en_zh Dev loss: 0.8034 r:0.4561
Current avg r:0.3345 Best avg r: 0.3575
14:23:25,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:23:50,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:24:16,422 root INFO Epoch 7 Global steps: 23400 Train loss: 0.3439
en_de Dev loss: 0.9088 r:0.2077
en_zh Dev loss: 0.8364 r:0.4410
Current avg r:0.3243 Best avg r: 0.3575
14:25:31,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:25:57,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:26:22,781 root INFO Epoch 7 Global steps: 23600 Train loss: 0.4617
en_de Dev loss: 0.9081 r:0.2044
en_zh Dev loss: 0.8243 r:0.4627
Current avg r:0.3336 Best avg r: 0.3575
14:27:38,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:28:03,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:28:29,534 root INFO Epoch 7 Global steps: 23800 Train loss: 0.4168
en_de Dev loss: 0.9170 r:0.1966
en_zh Dev loss: 0.7943 r:0.4639
Current avg r:0.3302 Best avg r: 0.3575
14:29:45,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:30:10,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:30:36,392 root INFO Epoch 7 Global steps: 24000 Train loss: 0.3974
en_de Dev loss: 0.8932 r:0.2055
en_zh Dev loss: 0.7642 r:0.4674
Current avg r:0.3365 Best avg r: 0.3575
14:31:52,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:32:17,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:32:43,209 root INFO Epoch 8 Global steps: 24200 Train loss: 0.3467
en_de Dev loss: 0.9026 r:0.1960
en_zh Dev loss: 0.7947 r:0.4682
Current avg r:0.3321 Best avg r: 0.3575
14:33:58,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:34:24,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:34:50,226 root INFO Epoch 8 Global steps: 24400 Train loss: 0.3544
en_de Dev loss: 0.9196 r:0.2066
en_zh Dev loss: 0.8345 r:0.4673
Current avg r:0.3370 Best avg r: 0.3575
14:36:05,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:36:30,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:36:56,412 root INFO Epoch 8 Global steps: 24600 Train loss: 0.3813
en_de Dev loss: 0.8928 r:0.2113
en_zh Dev loss: 0.8207 r:0.4667
Current avg r:0.3390 Best avg r: 0.3575
14:38:11,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:38:37,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:02,561 root INFO Epoch 8 Global steps: 24800 Train loss: 0.3507
en_de Dev loss: 0.8972 r:0.2164
en_zh Dev loss: 0.8715 r:0.4465
Current avg r:0.3315 Best avg r: 0.3575
14:40:17,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:40:43,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:41:08,657 root INFO Epoch 8 Global steps: 25000 Train loss: 0.3699
en_de Dev loss: 0.9063 r:0.1976
en_zh Dev loss: 0.8231 r:0.4676
Current avg r:0.3326 Best avg r: 0.3575
14:42:23,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:49,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:14,713 root INFO Epoch 8 Global steps: 25200 Train loss: 0.3559
en_de Dev loss: 0.9077 r:0.2052
en_zh Dev loss: 0.8670 r:0.4521
Current avg r:0.3286 Best avg r: 0.3575
14:44:29,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:55,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:20,892 root INFO Epoch 8 Global steps: 25400 Train loss: 0.3371
en_de Dev loss: 0.8864 r:0.2127
en_zh Dev loss: 0.8070 r:0.4566
Current avg r:0.3347 Best avg r: 0.3575
14:46:36,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:47:01,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:27,559 root INFO Epoch 8 Global steps: 25600 Train loss: 0.3719
en_de Dev loss: 0.9283 r:0.2089
en_zh Dev loss: 0.9203 r:0.4415
Current avg r:0.3252 Best avg r: 0.3575
14:48:42,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:08,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:34,111 root INFO Epoch 8 Global steps: 25800 Train loss: 0.3535
en_de Dev loss: 0.9275 r:0.2108
en_zh Dev loss: 0.8145 r:0.4716
Current avg r:0.3412 Best avg r: 0.3575
14:50:49,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:15,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:40,679 root INFO Epoch 8 Global steps: 26000 Train loss: 0.3406
en_de Dev loss: 0.8944 r:0.2088
en_zh Dev loss: 0.7979 r:0.4680
Current avg r:0.3384 Best avg r: 0.3575
14:52:56,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:21,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:47,124 root INFO Epoch 8 Global steps: 26200 Train loss: 0.3375
en_de Dev loss: 0.9079 r:0.2064
en_zh Dev loss: 0.8574 r:0.4497
Current avg r:0.3280 Best avg r: 0.3575
14:55:02,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:28,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:53,717 root INFO Epoch 8 Global steps: 26400 Train loss: 0.3392
en_de Dev loss: 0.9217 r:0.1936
en_zh Dev loss: 0.8110 r:0.4635
Current avg r:0.3285 Best avg r: 0.3575
14:57:09,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:34,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:00,263 root INFO Epoch 8 Global steps: 26600 Train loss: 0.3936
en_de Dev loss: 0.9071 r:0.1927
en_zh Dev loss: 0.7875 r:0.4583
Current avg r:0.3255 Best avg r: 0.3575
14:59:15,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:41,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:07,64 root INFO Epoch 8 Global steps: 26800 Train loss: 0.3101
en_de Dev loss: 0.9298 r:0.1936
en_zh Dev loss: 0.8778 r:0.4496
Current avg r:0.3216 Best avg r: 0.3575
15:01:22,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:48,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:13,861 root INFO Epoch 8 Global steps: 27000 Train loss: 0.3420
en_de Dev loss: 0.8786 r:0.2017
en_zh Dev loss: 0.7713 r:0.4654
Current avg r:0.3336 Best avg r: 0.3575
15:03:29,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:55,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:20,942 root INFO Epoch 9 Global steps: 27200 Train loss: 0.3286
en_de Dev loss: 0.9040 r:0.2039
en_zh Dev loss: 0.8260 r:0.4698
Current avg r:0.3368 Best avg r: 0.3575
15:05:36,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:06:02,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:27,747 root INFO Epoch 9 Global steps: 27400 Train loss: 0.3359
en_de Dev loss: 0.8894 r:0.2005
en_zh Dev loss: 0.8035 r:0.4715
Current avg r:0.3360 Best avg r: 0.3575
15:07:43,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:09,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:34,971 root INFO Epoch 9 Global steps: 27600 Train loss: 0.3190
en_de Dev loss: 0.9219 r:0.1847
en_zh Dev loss: 0.8255 r:0.4708
Current avg r:0.3278 Best avg r: 0.3575
15:09:50,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:16,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:41,794 root INFO Epoch 9 Global steps: 27800 Train loss: 0.3284
en_de Dev loss: 0.9098 r:0.2048
en_zh Dev loss: 0.8652 r:0.4572
Current avg r:0.3310 Best avg r: 0.3575
15:11:57,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:22,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:48,574 root INFO Epoch 9 Global steps: 28000 Train loss: 0.3287
en_de Dev loss: 0.9070 r:0.1998
en_zh Dev loss: 0.8120 r:0.4689
Current avg r:0.3343 Best avg r: 0.3575
15:14:04,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:29,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:55,263 root INFO Epoch 9 Global steps: 28200 Train loss: 0.3071
en_de Dev loss: 0.9155 r:0.2019
en_zh Dev loss: 0.8250 r:0.4697
Current avg r:0.3358 Best avg r: 0.3575
15:16:10,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:36,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:01,914 root INFO Epoch 9 Global steps: 28400 Train loss: 0.3132
en_de Dev loss: 0.9200 r:0.2043
en_zh Dev loss: 0.8297 r:0.4690
Current avg r:0.3367 Best avg r: 0.3575
15:18:17,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:43,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:09,158 root INFO Epoch 9 Global steps: 28600 Train loss: 0.3224
en_de Dev loss: 0.9247 r:0.2098
en_zh Dev loss: 0.8859 r:0.4578
Current avg r:0.3338 Best avg r: 0.3575
15:20:25,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:50,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:16,184 root INFO Epoch 9 Global steps: 28800 Train loss: 0.3174
en_de Dev loss: 0.9201 r:0.1990
en_zh Dev loss: 0.8638 r:0.4590
Current avg r:0.3290 Best avg r: 0.3575
15:22:31,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:57,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:22,774 root INFO Epoch 9 Global steps: 29000 Train loss: 0.3035
en_de Dev loss: 0.9064 r:0.1953
en_zh Dev loss: 0.8347 r:0.4588
Current avg r:0.3270 Best avg r: 0.3575
15:24:38,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:03,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:29,392 root INFO Epoch 9 Global steps: 29200 Train loss: 0.3166
en_de Dev loss: 0.9261 r:0.1882
en_zh Dev loss: 0.8580 r:0.4548
Current avg r:0.3215 Best avg r: 0.3575
15:26:44,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:10,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:36,69 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2870
en_de Dev loss: 0.9168 r:0.1860
en_zh Dev loss: 0.7947 r:0.4665
Current avg r:0.3262 Best avg r: 0.3575
15:28:51,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:17,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:42,703 root INFO Epoch 9 Global steps: 29600 Train loss: 0.3072
en_de Dev loss: 0.9190 r:0.1848
en_zh Dev loss: 0.8080 r:0.4727
Current avg r:0.3287 Best avg r: 0.3575
15:30:58,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:23,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:49,382 root INFO Epoch 9 Global steps: 29800 Train loss: 0.3098
en_de Dev loss: 0.9067 r:0.1926
en_zh Dev loss: 0.7888 r:0.4733
Current avg r:0.3329 Best avg r: 0.3575
15:33:04,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:30,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:56,61 root INFO Epoch 9 Global steps: 30000 Train loss: 0.3133
en_de Dev loss: 0.9314 r:0.1956
en_zh Dev loss: 0.8800 r:0.4647
Current avg r:0.3302 Best avg r: 0.3575
15:35:12,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:37,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:03,186 root INFO Epoch 10 Global steps: 30200 Train loss: 0.3007
en_de Dev loss: 0.8891 r:0.1945
en_zh Dev loss: 0.7940 r:0.4715
Current avg r:0.3330 Best avg r: 0.3575
15:37:19,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:44,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:10,373 root INFO Epoch 10 Global steps: 30400 Train loss: 0.3044
en_de Dev loss: 0.8996 r:0.2014
en_zh Dev loss: 0.7870 r:0.4727
Current avg r:0.3370 Best avg r: 0.3575
15:39:26,294 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:51,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:17,448 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2957
en_de Dev loss: 0.9193 r:0.2023
en_zh Dev loss: 0.8822 r:0.4591
Current avg r:0.3307 Best avg r: 0.3575
15:41:32,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:58,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:23,983 root INFO Epoch 10 Global steps: 30800 Train loss: 0.2769
en_de Dev loss: 0.9254 r:0.1914
en_zh Dev loss: 0.8296 r:0.4737
Current avg r:0.3326 Best avg r: 0.3575
15:43:39,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:05,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:30,657 root INFO Epoch 10 Global steps: 31000 Train loss: 0.2911
en_de Dev loss: 0.9412 r:0.1920
en_zh Dev loss: 0.8540 r:0.4695
Current avg r:0.3307 Best avg r: 0.3575
15:45:46,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:11,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:37,251 root INFO Epoch 10 Global steps: 31200 Train loss: 0.2569
en_de Dev loss: 0.9136 r:0.1912
en_zh Dev loss: 0.7868 r:0.4706
Current avg r:0.3309 Best avg r: 0.3575
15:47:52,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:18,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:43,980 root INFO Epoch 10 Global steps: 31400 Train loss: 0.3002
en_de Dev loss: 0.9202 r:0.2088
en_zh Dev loss: 0.8170 r:0.4616
Current avg r:0.3352 Best avg r: 0.3575
15:49:59,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:25,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:50,573 root INFO Epoch 10 Global steps: 31600 Train loss: 0.3144
en_de Dev loss: 0.9105 r:0.1998
en_zh Dev loss: 0.8080 r:0.4674
Current avg r:0.3336 Best avg r: 0.3575
15:52:05,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:31,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:57,70 root INFO Epoch 10 Global steps: 31800 Train loss: 0.2914
en_de Dev loss: 0.8877 r:0.1954
en_zh Dev loss: 0.7864 r:0.4639
Current avg r:0.3296 Best avg r: 0.3575
15:54:12,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:38,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:04,61 root INFO Epoch 10 Global steps: 32000 Train loss: 0.2650
en_de Dev loss: 0.9087 r:0.1923
en_zh Dev loss: 0.8359 r:0.4635
Current avg r:0.3279 Best avg r: 0.3575
15:56:19,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:45,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:10,665 root INFO Epoch 10 Global steps: 32200 Train loss: 0.2693
en_de Dev loss: 0.9082 r:0.1826
en_zh Dev loss: 0.7766 r:0.4674
Current avg r:0.3250 Best avg r: 0.3575
15:58:26,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:51,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:17,351 root INFO Epoch 10 Global steps: 32400 Train loss: 0.2752
en_de Dev loss: 0.9321 r:0.1744
en_zh Dev loss: 0.7878 r:0.4659
Current avg r:0.3201 Best avg r: 0.3575
16:00:32,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:58,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:24,28 root INFO Epoch 10 Global steps: 32600 Train loss: 0.2738
en_de Dev loss: 0.8950 r:0.2123
en_zh Dev loss: 0.7878 r:0.4635
Current avg r:0.3379 Best avg r: 0.3575
16:02:39,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:05,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:30,738 root INFO Epoch 10 Global steps: 32800 Train loss: 0.2837
en_de Dev loss: 0.8892 r:0.1987
en_zh Dev loss: 0.8003 r:0.4495
Current avg r:0.3241 Best avg r: 0.3575
16:04:46,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:11,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:37,440 root INFO Epoch 10 Global steps: 33000 Train loss: 0.3110
en_de Dev loss: 0.9136 r:0.2030
en_zh Dev loss: 0.8310 r:0.4568
Current avg r:0.3299 Best avg r: 0.3575
16:06:53,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:19,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:44,600 root INFO Epoch 11 Global steps: 33200 Train loss: 0.2616
en_de Dev loss: 0.9171 r:0.2021
en_zh Dev loss: 0.8317 r:0.4466
Current avg r:0.3243 Best avg r: 0.3575
16:09:00,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:25,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:51,242 root INFO Epoch 11 Global steps: 33400 Train loss: 0.2828
en_de Dev loss: 0.9044 r:0.2062
en_zh Dev loss: 0.8403 r:0.4518
Current avg r:0.3290 Best avg r: 0.3575
16:11:06,767 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:32,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:57,897 root INFO Epoch 11 Global steps: 33600 Train loss: 0.2704
en_de Dev loss: 0.9260 r:0.1774
en_zh Dev loss: 0.8082 r:0.4595
Current avg r:0.3184 Best avg r: 0.3575
16:13:13,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:38,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:04,559 root INFO Epoch 11 Global steps: 33800 Train loss: 0.2590
en_de Dev loss: 0.9232 r:0.1687
en_zh Dev loss: 0.7904 r:0.4566
Current avg r:0.3127 Best avg r: 0.3575
16:15:20,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:45,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:11,213 root INFO Epoch 11 Global steps: 34000 Train loss: 0.2300
en_de Dev loss: 0.9161 r:0.1766
en_zh Dev loss: 0.8147 r:0.4487
Current avg r:0.3127 Best avg r: 0.3575
16:17:26,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:52,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:17,923 root INFO Epoch 11 Global steps: 34200 Train loss: 0.2706
en_de Dev loss: 0.9097 r:0.1919
en_zh Dev loss: 0.8114 r:0.4585
Current avg r:0.3252 Best avg r: 0.3575
16:19:33,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:59,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:24,928 root INFO Epoch 11 Global steps: 34400 Train loss: 0.2635
en_de Dev loss: 0.9451 r:0.1781
en_zh Dev loss: 0.8366 r:0.4579
Current avg r:0.3180 Best avg r: 0.3575
16:21:40,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:06,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:32,32 root INFO Epoch 11 Global steps: 34600 Train loss: 0.2362
en_de Dev loss: 0.9421 r:0.1812
en_zh Dev loss: 0.8516 r:0.4688
Current avg r:0.3250 Best avg r: 0.3575
16:23:47,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:13,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:24:39,143 root INFO Epoch 11 Global steps: 34800 Train loss: 0.2664
en_de Dev loss: 0.9215 r:0.1722
en_zh Dev loss: 0.7963 r:0.4627
Current avg r:0.3175 Best avg r: 0.3575
16:25:54,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:20,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:46,89 root INFO Epoch 11 Global steps: 35000 Train loss: 0.2576
en_de Dev loss: 0.9455 r:0.1690
en_zh Dev loss: 0.8396 r:0.4534
Current avg r:0.3112 Best avg r: 0.3575
16:28:01,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:27,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:52,611 root INFO Epoch 11 Global steps: 35200 Train loss: 0.2553
en_de Dev loss: 0.9382 r:0.1812
en_zh Dev loss: 0.8325 r:0.4645
Current avg r:0.3228 Best avg r: 0.3575
16:30:07,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:33,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:59,0 root INFO Epoch 11 Global steps: 35400 Train loss: 0.2246
en_de Dev loss: 0.9203 r:0.1843
en_zh Dev loss: 0.8103 r:0.4715
Current avg r:0.3279 Best avg r: 0.3575
16:32:14,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:40,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:05,567 root INFO Epoch 11 Global steps: 35600 Train loss: 0.2697
en_de Dev loss: 0.9268 r:0.1679
en_zh Dev loss: 0.8102 r:0.4660
Current avg r:0.3170 Best avg r: 0.3575
16:34:21,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:46,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:12,150 root INFO Epoch 11 Global steps: 35800 Train loss: 0.2413
en_de Dev loss: 0.9752 r:0.1661
en_zh Dev loss: 0.8880 r:0.4641
Current avg r:0.3151 Best avg r: 0.3575
16:36:28,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:53,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:19,84 root INFO Epoch 11 Global steps: 36000 Train loss: 0.2603
en_de Dev loss: 0.9697 r:0.1736
en_zh Dev loss: 0.9035 r:0.4535
Current avg r:0.3136 Best avg r: 0.3575
16:38:34,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:00,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:25,676 root INFO Epoch 12 Global steps: 36200 Train loss: 0.2337
en_de Dev loss: 0.9370 r:0.1608
en_zh Dev loss: 0.7993 r:0.4699
Current avg r:0.3154 Best avg r: 0.3575
16:40:40,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:06,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:31,840 root INFO Epoch 12 Global steps: 36400 Train loss: 0.2345
en_de Dev loss: 0.9826 r:0.1700
en_zh Dev loss: 0.8502 r:0.4707
Current avg r:0.3204 Best avg r: 0.3575
16:42:47,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:13,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:38,577 root INFO Epoch 12 Global steps: 36600 Train loss: 0.2339
en_de Dev loss: 0.9330 r:0.1799
en_zh Dev loss: 0.8288 r:0.4574
Current avg r:0.3186 Best avg r: 0.3575
16:44:53,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:19,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:44,734 root INFO Epoch 12 Global steps: 36800 Train loss: 0.2328
en_de Dev loss: 0.9296 r:0.1706
en_zh Dev loss: 0.8311 r:0.4596
Current avg r:0.3151 Best avg r: 0.3575
16:46:59,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:25,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:50,906 root INFO Epoch 12 Global steps: 37000 Train loss: 0.2229
en_de Dev loss: 0.9773 r:0.1775
en_zh Dev loss: 0.8233 r:0.4755
Current avg r:0.3265 Best avg r: 0.3575
16:49:06,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:31,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:57,79 root INFO Epoch 12 Global steps: 37200 Train loss: 0.2159
en_de Dev loss: 0.9375 r:0.1795
en_zh Dev loss: 0.8043 r:0.4610
Current avg r:0.3202 Best avg r: 0.3575
16:51:12,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:37,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:03,321 root INFO Epoch 12 Global steps: 37400 Train loss: 0.2254
en_de Dev loss: 0.9404 r:0.1725
en_zh Dev loss: 0.8293 r:0.4612
Current avg r:0.3169 Best avg r: 0.3575
16:53:19,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:45,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:11,405 root INFO Epoch 12 Global steps: 37600 Train loss: 0.2246
en_de Dev loss: 0.9325 r:0.1656
en_zh Dev loss: 0.8018 r:0.4589
Current avg r:0.3123 Best avg r: 0.3575
16:55:27,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:53,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:19,316 root INFO Epoch 12 Global steps: 37800 Train loss: 0.2195
en_de Dev loss: 0.9458 r:0.1725
en_zh Dev loss: 0.8256 r:0.4610
Current avg r:0.3168 Best avg r: 0.3575
16:57:35,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:01,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:27,413 root INFO Epoch 12 Global steps: 38000 Train loss: 0.2304
en_de Dev loss: 0.9276 r:0.1787
en_zh Dev loss: 0.8243 r:0.4622
Current avg r:0.3204 Best avg r: 0.3575
16:59:44,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:09,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:35,641 root INFO Epoch 12 Global steps: 38200 Train loss: 0.2472
en_de Dev loss: 0.9553 r:0.1679
en_zh Dev loss: 0.8149 r:0.4619
Current avg r:0.3149 Best avg r: 0.3575
17:01:52,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:18,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:43,874 root INFO Epoch 12 Global steps: 38400 Train loss: 0.2160
en_de Dev loss: 0.9451 r:0.1697
en_zh Dev loss: 0.8191 r:0.4500
Current avg r:0.3099 Best avg r: 0.3575
17:04:00,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:26,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:52,287 root INFO Epoch 12 Global steps: 38600 Train loss: 0.2655
en_de Dev loss: 0.9553 r:0.1753
en_zh Dev loss: 0.8361 r:0.4615
Current avg r:0.3184 Best avg r: 0.3575
17:06:08,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:34,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:00,657 root INFO Epoch 12 Global steps: 38800 Train loss: 0.2420
en_de Dev loss: 0.9311 r:0.1740
en_zh Dev loss: 0.7907 r:0.4699
Current avg r:0.3220 Best avg r: 0.3575
17:08:16,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:42,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:08,508 root INFO Epoch 12 Global steps: 39000 Train loss: 0.2394
en_de Dev loss: 0.9440 r:0.1797
en_zh Dev loss: 0.8370 r:0.4604
Current avg r:0.3200 Best avg r: 0.3575
17:10:25,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:51,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:16,936 root INFO Epoch 13 Global steps: 39200 Train loss: 0.2053
en_de Dev loss: 0.9779 r:0.1739
en_zh Dev loss: 0.8792 r:0.4548
Current avg r:0.3144 Best avg r: 0.3575
17:12:33,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:59,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:25,154 root INFO Epoch 13 Global steps: 39400 Train loss: 0.2132
en_de Dev loss: 0.9166 r:0.1889
en_zh Dev loss: 0.7782 r:0.4704
Current avg r:0.3297 Best avg r: 0.3575
17:14:41,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:07,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:33,302 root INFO Epoch 13 Global steps: 39600 Train loss: 0.2241
en_de Dev loss: 0.9452 r:0.1850
en_zh Dev loss: 0.8590 r:0.4614
Current avg r:0.3232 Best avg r: 0.3575
17:16:50,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:15,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:41,811 root INFO Epoch 13 Global steps: 39800 Train loss: 0.2131
en_de Dev loss: 0.9552 r:0.1735
en_zh Dev loss: 0.8630 r:0.4705
Current avg r:0.3220 Best avg r: 0.3575
17:18:58,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:24,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:50,578 root INFO Epoch 13 Global steps: 40000 Train loss: 0.2089
en_de Dev loss: 0.9492 r:0.1730
en_zh Dev loss: 0.8974 r:0.4513
Current avg r:0.3122 Best avg r: 0.3575
17:21:07,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:33,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:58,904 root INFO Epoch 13 Global steps: 40200 Train loss: 0.2218
en_de Dev loss: 0.9354 r:0.1683
en_zh Dev loss: 0.7950 r:0.4614
Current avg r:0.3149 Best avg r: 0.3575
17:23:15,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:41,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:07,582 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1924
en_de Dev loss: 0.9370 r:0.1648
en_zh Dev loss: 0.7854 r:0.4653
Current avg r:0.3151 Best avg r: 0.3575
17:25:24,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:50,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:16,91 root INFO Epoch 13 Global steps: 40600 Train loss: 0.2069
en_de Dev loss: 0.9470 r:0.1737
en_zh Dev loss: 0.8380 r:0.4521
Current avg r:0.3129 Best avg r: 0.3575
17:27:32,466 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:58,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:24,130 root INFO Epoch 13 Global steps: 40800 Train loss: 0.2040
en_de Dev loss: 0.9549 r:0.1733
en_zh Dev loss: 0.8393 r:0.4541
Current avg r:0.3137 Best avg r: 0.3575
17:29:40,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:06,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:32,674 root INFO Epoch 13 Global steps: 41000 Train loss: 0.2144
en_de Dev loss: 0.9357 r:0.1638
en_zh Dev loss: 0.7958 r:0.4574
Current avg r:0.3106 Best avg r: 0.3575
17:31:49,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:15,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:41,390 root INFO Epoch 13 Global steps: 41200 Train loss: 0.2054
en_de Dev loss: 0.9638 r:0.1599
en_zh Dev loss: 0.8822 r:0.4529
Current avg r:0.3064 Best avg r: 0.3575
17:33:58,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:23,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:49,648 root INFO Epoch 13 Global steps: 41400 Train loss: 0.2256
en_de Dev loss: 0.9393 r:0.1628
en_zh Dev loss: 0.8103 r:0.4611
Current avg r:0.3120 Best avg r: 0.3575
17:36:06,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:32,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:58,31 root INFO Epoch 13 Global steps: 41600 Train loss: 0.2333
en_de Dev loss: 0.9468 r:0.1626
en_zh Dev loss: 0.8155 r:0.4598
Current avg r:0.3112 Best avg r: 0.3575
17:38:14,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:40,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:06,373 root INFO Epoch 13 Global steps: 41800 Train loss: 0.2118
en_de Dev loss: 0.9412 r:0.1701
en_zh Dev loss: 0.8477 r:0.4627
Current avg r:0.3164 Best avg r: 0.3575
17:40:22,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:48,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:14,475 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1899
en_de Dev loss: 0.9741 r:0.1648
en_zh Dev loss: 0.8696 r:0.4616
Current avg r:0.3132 Best avg r: 0.3575
17:42:31,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:57,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:22,945 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1856
en_de Dev loss: 0.9529 r:0.1567
en_zh Dev loss: 0.7840 r:0.4697
Current avg r:0.3132 Best avg r: 0.3575
17:44:39,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:05,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:31,13 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1909
en_de Dev loss: 0.9438 r:0.1524
en_zh Dev loss: 0.7588 r:0.4680
Current avg r:0.3102 Best avg r: 0.3575
17:46:47,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:13,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:39,365 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1923
en_de Dev loss: 0.9620 r:0.1551
en_zh Dev loss: 0.8115 r:0.4716
Current avg r:0.3133 Best avg r: 0.3575
17:48:56,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:21,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:47,768 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1899
en_de Dev loss: 0.9589 r:0.1669
en_zh Dev loss: 0.8196 r:0.4621
Current avg r:0.3145 Best avg r: 0.3575
17:51:04,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:30,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:56,26 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1726
en_de Dev loss: 0.9685 r:0.1565
en_zh Dev loss: 0.7960 r:0.4736
Current avg r:0.3151 Best avg r: 0.3575
17:53:12,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:38,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:04,442 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1915
en_de Dev loss: 0.9776 r:0.1502
en_zh Dev loss: 0.8384 r:0.4624
Current avg r:0.3063 Best avg r: 0.3575
17:55:21,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:47,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:12,822 root INFO Epoch 14 Global steps: 43400 Train loss: 0.2108
en_de Dev loss: 0.9569 r:0.1554
en_zh Dev loss: 0.7812 r:0.4700
Current avg r:0.3127 Best avg r: 0.3575
17:57:29,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:55,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:21,220 root INFO Epoch 14 Global steps: 43600 Train loss: 0.2042
en_de Dev loss: 0.9540 r:0.1531
en_zh Dev loss: 0.7587 r:0.4734
Current avg r:0.3133 Best avg r: 0.3575
17:59:37,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:03,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:29,624 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1770
en_de Dev loss: 0.9888 r:0.1546
en_zh Dev loss: 0.8205 r:0.4805
Current avg r:0.3176 Best avg r: 0.3575
18:01:46,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:12,490 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:38,331 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1936
en_de Dev loss: 0.9509 r:0.1464
en_zh Dev loss: 0.8021 r:0.4732
Current avg r:0.3098 Best avg r: 0.3575
18:03:54,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:20,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:46,476 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1892
en_de Dev loss: 0.9744 r:0.1571
en_zh Dev loss: 0.8598 r:0.4744
Current avg r:0.3157 Best avg r: 0.3575
18:06:03,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:42,36 root INFO 
id:en_zh cur r: 0.4887 best r: 0.4887
18:06:42,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:07,826 root INFO Epoch 14 Global steps: 44400 Train loss: 0.2010
en_de Dev loss: 0.9984 r:0.1515
en_zh Dev loss: 0.8015 r:0.4839
Current avg r:0.3177 Best avg r: 0.3575
18:08:24,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:50,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:15,922 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1785
en_de Dev loss: 0.9811 r:0.1505
en_zh Dev loss: 0.8182 r:0.4771
Current avg r:0.3138 Best avg r: 0.3575
18:10:32,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:10,961 root INFO 
id:en_zh cur r: 0.4898 best r: 0.4898
18:11:10,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:36,768 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1904
en_de Dev loss: 0.9614 r:0.1535
en_zh Dev loss: 0.7711 r:0.4876
Current avg r:0.3205 Best avg r: 0.3575
18:12:53,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:19,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:44,925 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1933
en_de Dev loss: 0.9632 r:0.1608
en_zh Dev loss: 0.7833 r:0.4860
Current avg r:0.3234 Best avg r: 0.3575
18:15:01,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:15:27,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:52,831 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1715
en_de Dev loss: 0.9687 r:0.1520
en_zh Dev loss: 0.7947 r:0.4779
Current avg r:0.3150 Best avg r: 0.3575
18:17:09,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:34,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:00,757 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1722
en_de Dev loss: 0.9432 r:0.1545
en_zh Dev loss: 0.7427 r:0.4830
Current avg r:0.3187 Best avg r: 0.3575
18:19:17,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:43,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:09,105 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1750
en_de Dev loss: 0.9921 r:0.1564
en_zh Dev loss: 0.8204 r:0.4789
Current avg r:0.3176 Best avg r: 0.3575
18:21:25,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:51,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:17,85 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1666
en_de Dev loss: 0.9768 r:0.1486
en_zh Dev loss: 0.7874 r:0.4780
Current avg r:0.3133 Best avg r: 0.3575
18:23:33,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:59,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:24,960 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1845
en_de Dev loss: 0.9437 r:0.1577
en_zh Dev loss: 0.7551 r:0.4796
Current avg r:0.3187 Best avg r: 0.3575
18:25:41,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:20,77 root INFO 
id:en_zh cur r: 0.4907 best r: 0.4907
18:26:20,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:45,882 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1648
en_de Dev loss: 1.0078 r:0.1521
en_zh Dev loss: 0.8042 r:0.4874
Current avg r:0.3198 Best avg r: 0.3575
18:28:02,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:28,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:53,818 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1728
en_de Dev loss: 0.9769 r:0.1568
en_zh Dev loss: 0.7742 r:0.4797
Current avg r:0.3182 Best avg r: 0.3575
18:30:10,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:36,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:01,861 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1868
en_de Dev loss: 0.9492 r:0.1638
en_zh Dev loss: 0.7722 r:0.4770
Current avg r:0.3204 Best avg r: 0.3575
18:32:18,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:44,370 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:10,165 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1880
en_de Dev loss: 0.9767 r:0.1500
en_zh Dev loss: 0.8222 r:0.4713
Current avg r:0.3106 Best avg r: 0.3575
18:34:26,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:52,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:18,108 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1655
en_de Dev loss: 0.9630 r:0.1617
en_zh Dev loss: 0.7805 r:0.4829
Current avg r:0.3223 Best avg r: 0.3575
18:36:34,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:59,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:25,211 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1812
en_de Dev loss: 0.9760 r:0.1537
en_zh Dev loss: 0.8410 r:0.4720
Current avg r:0.3128 Best avg r: 0.3575
18:38:40,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:18,889 root INFO 
id:en_zh cur r: 0.4915 best r: 0.4915
18:39:18,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:39:44,491 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1879
en_de Dev loss: 0.9719 r:0.1589
en_zh Dev loss: 0.7496 r:0.4905
Current avg r:0.3247 Best avg r: 0.3575
18:41:00,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:26,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:51,886 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1818
en_de Dev loss: 0.9466 r:0.1712
en_zh Dev loss: 0.7780 r:0.4819
Current avg r:0.3266 Best avg r: 0.3575
18:43:07,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:33,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:59,243 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1808
en_de Dev loss: 0.9416 r:0.1763
en_zh Dev loss: 0.7791 r:0.4826
Current avg r:0.3295 Best avg r: 0.3575
18:45:14,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:53,306 root INFO 
id:en_zh cur r: 0.4917 best r: 0.4917
18:45:53,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:19,12 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1691
en_de Dev loss: 0.9554 r:0.1849
en_zh Dev loss: 0.7873 r:0.4891
Current avg r:0.3370 Best avg r: 0.3575
18:47:35,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:00,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:26,394 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1537
en_de Dev loss: 0.9676 r:0.1812
en_zh Dev loss: 0.8522 r:0.4728
Current avg r:0.3270 Best avg r: 0.3575
18:49:42,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:07,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:33,477 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1682
en_de Dev loss: 0.9528 r:0.1649
en_zh Dev loss: 0.8065 r:0.4798
Current avg r:0.3223 Best avg r: 0.3575
18:51:49,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:14,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:40,440 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1871
en_de Dev loss: 0.9586 r:0.1724
en_zh Dev loss: 0.7986 r:0.4737
Current avg r:0.3230 Best avg r: 0.3575
18:53:56,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:21,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:47,548 root INFO Epoch 16 Global steps: 48800 Train loss: 0.1551
en_de Dev loss: 0.9695 r:0.1566
en_zh Dev loss: 0.8336 r:0.4738
Current avg r:0.3152 Best avg r: 0.3575
18:56:03,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:29,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:56:55,95 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1609
en_de Dev loss: 0.9497 r:0.1644
en_zh Dev loss: 0.7695 r:0.4836
Current avg r:0.3240 Best avg r: 0.3575
18:58:11,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:36,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:02,644 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1705
en_de Dev loss: 0.9749 r:0.1607
en_zh Dev loss: 0.8193 r:0.4777
Current avg r:0.3192 Best avg r: 0.3575
19:00:18,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:44,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:10,149 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1590
en_de Dev loss: 1.0011 r:0.1599
en_zh Dev loss: 0.8241 r:0.4846
Current avg r:0.3222 Best avg r: 0.3575
