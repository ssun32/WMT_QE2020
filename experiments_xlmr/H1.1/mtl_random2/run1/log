14:31:56,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:32:22,381 root INFO 
id:en_zh cur r: 0.1506 best r: 0.1506
14:32:48,244 root INFO 
id:ro_en cur r: 0.0179 best r: 0.0179
14:32:48,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:33:14,49 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:33:14,55 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:33:39,859 root INFO Epoch 0 Global steps: 200 Train loss: 0.9211
en_zh Dev loss: 0.8150 r:0.1614
ro_en Dev loss: 0.8509 r:0.2921
Current avg r:0.2267 Best avg r: 0.2267
14:34:56,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:35:22,407 root INFO 
id:en_zh cur r: 0.2021 best r: 0.2021
14:35:48,253 root INFO 
id:ro_en cur r: 0.1014 best r: 0.1014
14:35:48,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:36:14,46 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:36:14,53 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:36:39,848 root INFO Epoch 0 Global steps: 400 Train loss: 0.9243
en_zh Dev loss: 0.8102 r:0.2263
ro_en Dev loss: 0.8424 r:0.3726
Current avg r:0.2994 Best avg r: 0.2994
14:37:56,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:38:22,495 root INFO 
id:en_zh cur r: 0.2536 best r: 0.2536
14:38:48,271 root INFO 
id:ro_en cur r: 0.4775 best r: 0.4775
14:38:48,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:13,926 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:39:13,931 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:39:39,626 root INFO Epoch 0 Global steps: 600 Train loss: 0.8808
en_zh Dev loss: 0.7955 r:0.2640
ro_en Dev loss: 0.8099 r:0.4759
Current avg r:0.3700 Best avg r: 0.3700
14:40:56,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:41:21,950 root INFO 
id:en_zh cur r: 0.2745 best r: 0.2745
14:41:47,698 root INFO 
id:ro_en cur r: 0.5068 best r: 0.5068
14:41:47,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:42:13,384 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:42:13,395 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:42:39,93 root INFO Epoch 0 Global steps: 800 Train loss: 0.8492
en_zh Dev loss: 0.7715 r:0.2722
ro_en Dev loss: 0.6818 r:0.5544
Current avg r:0.4133 Best avg r: 0.4133
14:43:55,555 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:21,234 root INFO 
id:en_zh cur r: 0.2840 best r: 0.2840
14:44:46,965 root INFO 
id:ro_en cur r: 0.5670 best r: 0.5670
14:44:46,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:12,652 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:45:12,658 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:45:38,353 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7452
en_zh Dev loss: 0.7596 r:0.2692
ro_en Dev loss: 0.5864 r:0.5973
Current avg r:0.4333 Best avg r: 0.4333
14:46:54,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:47:20,443 root INFO 
id:en_zh cur r: 0.3354 best r: 0.3354
14:47:46,175 root INFO 
id:ro_en cur r: 0.6163 best r: 0.6163
14:47:46,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:11,852 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:48:11,858 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:48:37,572 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7406
en_zh Dev loss: 0.7438 r:0.3056
ro_en Dev loss: 0.5528 r:0.6302
Current avg r:0.4679 Best avg r: 0.4679
14:49:54,242 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:50:32,844 root INFO 
id:ro_en cur r: 0.6473 best r: 0.6473
14:50:32,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:50:58,541 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:50:58,546 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:51:24,243 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7393
en_zh Dev loss: 0.7612 r:0.2995
ro_en Dev loss: 0.5160 r:0.6445
Current avg r:0.4720 Best avg r: 0.4720
14:52:40,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:06,659 root INFO 
id:en_zh cur r: 0.3444 best r: 0.3444
14:53:32,380 root INFO 
id:ro_en cur r: 0.6698 best r: 0.6698
14:53:32,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:58,44 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:53:58,52 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:54:23,748 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7280
en_zh Dev loss: 0.7357 r:0.3297
ro_en Dev loss: 0.4850 r:0.6653
Current avg r:0.4975 Best avg r: 0.4975
14:55:40,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:19,38 root INFO 
id:ro_en cur r: 0.6833 best r: 0.6833
14:56:19,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:56:44,720 root INFO Epoch 0 Global steps: 1800 Train loss: 0.6625
en_zh Dev loss: 0.8203 r:0.2897
ro_en Dev loss: 0.4840 r:0.6846
Current avg r:0.4872 Best avg r: 0.4975
14:58:01,454 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:27,119 root INFO 
id:en_zh cur r: 0.3525 best r: 0.3525
14:58:52,875 root INFO 
id:ro_en cur r: 0.7076 best r: 0.7076
14:58:52,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:18,561 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:59:18,567 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:59:44,255 root INFO Epoch 0 Global steps: 2000 Train loss: 0.5946
en_zh Dev loss: 0.7387 r:0.3568
ro_en Dev loss: 0.4416 r:0.7063
Current avg r:0.5315 Best avg r: 0.5315
15:01:00,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:26,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:01:52,348 root INFO Epoch 0 Global steps: 2200 Train loss: 0.5898
en_zh Dev loss: 0.8138 r:0.3450
ro_en Dev loss: 0.4981 r:0.7055
Current avg r:0.5252 Best avg r: 0.5315
15:03:09,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:34,780 root INFO 
id:en_zh cur r: 0.3837 best r: 0.3837
15:04:00,517 root INFO 
id:ro_en cur r: 0.7265 best r: 0.7265
15:04:00,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:26,202 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:04:26,208 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:04:51,894 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6338
en_zh Dev loss: 0.7376 r:0.3886
ro_en Dev loss: 0.4348 r:0.7252
Current avg r:0.5569 Best avg r: 0.5569
15:06:08,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:06:47,220 root INFO 
id:ro_en cur r: 0.7297 best r: 0.7297
15:06:47,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:12,879 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:07:12,885 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:07:38,574 root INFO Epoch 0 Global steps: 2600 Train loss: 0.5877
en_zh Dev loss: 0.7292 r:0.3986
ro_en Dev loss: 0.4434 r:0.7284
Current avg r:0.5635 Best avg r: 0.5635
15:08:55,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:33,856 root INFO 
id:ro_en cur r: 0.7440 best r: 0.7440
15:09:33,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:59,546 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:09:59,552 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:10:25,245 root INFO Epoch 0 Global steps: 2800 Train loss: 0.5733
en_zh Dev loss: 0.7485 r:0.3997
ro_en Dev loss: 0.4204 r:0.7437
Current avg r:0.5717 Best avg r: 0.5717
15:11:42,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:07,739 root INFO 
id:en_zh cur r: 0.3921 best r: 0.3921
15:12:33,466 root INFO 
id:ro_en cur r: 0.7573 best r: 0.7573
15:12:33,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:59,134 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:12:59,139 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:13:24,852 root INFO Epoch 0 Global steps: 3000 Train loss: 0.5719
en_zh Dev loss: 0.7831 r:0.3987
ro_en Dev loss: 0.4773 r:0.7571
Current avg r:0.5779 Best avg r: 0.5779
15:14:41,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:07,550 root INFO 
id:en_zh cur r: 0.4163 best r: 0.4163
15:15:33,289 root INFO 
id:ro_en cur r: 0.7646 best r: 0.7646
15:15:33,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:15:58,968 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:15:58,975 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:16:24,671 root INFO Epoch 1 Global steps: 3200 Train loss: 0.5019
en_zh Dev loss: 0.7145 r:0.4127
ro_en Dev loss: 0.3936 r:0.7625
Current avg r:0.5876 Best avg r: 0.5876
15:17:41,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:07,86 root INFO 
id:en_zh cur r: 0.4238 best r: 0.4238
15:18:32,813 root INFO 
id:ro_en cur r: 0.7680 best r: 0.7680
15:18:32,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:58,480 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:18:58,486 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:19:24,187 root INFO Epoch 1 Global steps: 3400 Train loss: 0.5225
en_zh Dev loss: 0.7723 r:0.4214
ro_en Dev loss: 0.4279 r:0.7689
Current avg r:0.5952 Best avg r: 0.5952
15:20:40,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:21:19,509 root INFO 
id:ro_en cur r: 0.7697 best r: 0.7697
15:21:19,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:45,183 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:21:45,188 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:22:10,888 root INFO Epoch 1 Global steps: 3600 Train loss: 0.4987
en_zh Dev loss: 0.7427 r:0.4207
ro_en Dev loss: 0.3922 r:0.7716
Current avg r:0.5961 Best avg r: 0.5961
15:23:27,654 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:53,327 root INFO 
id:en_zh cur r: 0.4293 best r: 0.4293
15:24:19,61 root INFO 
id:ro_en cur r: 0.7842 best r: 0.7842
15:24:19,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:44,738 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:24:44,744 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:25:10,440 root INFO Epoch 1 Global steps: 3800 Train loss: 0.4913
en_zh Dev loss: 0.7788 r:0.4295
ro_en Dev loss: 0.4148 r:0.7870
Current avg r:0.6083 Best avg r: 0.6083
15:26:27,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:05,776 root INFO 
id:ro_en cur r: 0.7869 best r: 0.7869
15:27:05,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:31,472 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:27:31,478 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:27:57,167 root INFO Epoch 1 Global steps: 4000 Train loss: 0.4529
en_zh Dev loss: 0.7758 r:0.4313
ro_en Dev loss: 0.4077 r:0.7867
Current avg r:0.6090 Best avg r: 0.6090
15:29:13,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:39,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:05,299 root INFO Epoch 1 Global steps: 4200 Train loss: 0.4746
en_zh Dev loss: 0.7604 r:0.4301
ro_en Dev loss: 0.4207 r:0.7678
Current avg r:0.5989 Best avg r: 0.6090
15:31:21,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:47,589 root INFO 
id:en_zh cur r: 0.4548 best r: 0.4548
15:32:13,321 root INFO 
id:ro_en cur r: 0.7938 best r: 0.7938
15:32:13,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:38,994 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:32:39,2 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:33:04,690 root INFO Epoch 1 Global steps: 4400 Train loss: 0.5347
en_zh Dev loss: 0.6763 r:0.4526
ro_en Dev loss: 0.3302 r:0.7932
Current avg r:0.6229 Best avg r: 0.6229
15:34:21,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:59,956 root INFO 
id:ro_en cur r: 0.7951 best r: 0.7951
15:34:59,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:25,659 root INFO Epoch 1 Global steps: 4600 Train loss: 0.4734
en_zh Dev loss: 0.8051 r:0.4130
ro_en Dev loss: 0.3822 r:0.7921
Current avg r:0.6025 Best avg r: 0.6229
15:36:42,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:08,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:37:33,852 root INFO Epoch 1 Global steps: 4800 Train loss: 0.5044
en_zh Dev loss: 0.7135 r:0.4346
ro_en Dev loss: 0.3871 r:0.7875
Current avg r:0.6110 Best avg r: 0.6229
15:38:50,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:16,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:41,963 root INFO Epoch 1 Global steps: 5000 Train loss: 0.4659
en_zh Dev loss: 0.7357 r:0.4347
ro_en Dev loss: 0.3812 r:0.7935
Current avg r:0.6141 Best avg r: 0.6229
15:40:58,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:37,271 root INFO 
id:ro_en cur r: 0.7980 best r: 0.7980
15:41:37,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:02,959 root INFO Epoch 1 Global steps: 5200 Train loss: 0.4751
en_zh Dev loss: 0.6872 r:0.4445
ro_en Dev loss: 0.3224 r:0.8007
Current avg r:0.6226 Best avg r: 0.6229
15:43:19,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:45,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:11,8 root INFO Epoch 1 Global steps: 5400 Train loss: 0.4177
en_zh Dev loss: 0.8248 r:0.4254
ro_en Dev loss: 0.4307 r:0.7962
Current avg r:0.6108 Best avg r: 0.6229
15:45:27,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:06,268 root INFO 
id:ro_en cur r: 0.8067 best r: 0.8067
15:46:06,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:31,955 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:46:31,961 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:46:57,665 root INFO Epoch 1 Global steps: 5600 Train loss: 0.4705
en_zh Dev loss: 0.7351 r:0.4463
ro_en Dev loss: 0.3542 r:0.8047
Current avg r:0.6255 Best avg r: 0.6255
15:48:14,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:40,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:05,859 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:49:05,865 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:49:31,570 root INFO Epoch 1 Global steps: 5800 Train loss: 0.4999
en_zh Dev loss: 0.7193 r:0.4590
ro_en Dev loss: 0.3546 r:0.8023
Current avg r:0.6306 Best avg r: 0.6306
15:50:48,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:14,64 root INFO 
id:en_zh cur r: 0.4762 best r: 0.4762
15:51:26,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:52,626 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:51:52,632 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:52:18,317 root INFO Epoch 1 Global steps: 6000 Train loss: 0.4358
en_zh Dev loss: 0.6618 r:0.4754
ro_en Dev loss: 0.3481 r:0.8069
Current avg r:0.6411 Best avg r: 0.6411
15:53:35,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:01,45 root INFO 
id:en_zh cur r: 0.4855 best r: 0.4855
15:54:26,787 root INFO 
id:ro_en cur r: 0.8139 best r: 0.8139
15:54:26,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:52,465 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:54:52,471 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:55:18,174 root INFO Epoch 2 Global steps: 6200 Train loss: 0.4296
en_zh Dev loss: 0.6694 r:0.4840
ro_en Dev loss: 0.3572 r:0.8113
Current avg r:0.6477 Best avg r: 0.6477
15:56:34,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:13,530 root INFO 
id:ro_en cur r: 0.8147 best r: 0.8147
15:57:13,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:39,216 root INFO Epoch 2 Global steps: 6400 Train loss: 0.3984
en_zh Dev loss: 0.6647 r:0.4809
ro_en Dev loss: 0.3216 r:0.8124
Current avg r:0.6466 Best avg r: 0.6477
15:58:55,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:21,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:47,197 root INFO Epoch 2 Global steps: 6600 Train loss: 0.3932
en_zh Dev loss: 0.7123 r:0.4646
ro_en Dev loss: 0.3484 r:0.8057
Current avg r:0.6352 Best avg r: 0.6477
16:01:03,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:29,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:55,169 root INFO Epoch 2 Global steps: 6800 Train loss: 0.3943
en_zh Dev loss: 0.7036 r:0.4613
ro_en Dev loss: 0.3329 r:0.8066
Current avg r:0.6339 Best avg r: 0.6477
16:03:11,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:37,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:03,117 root INFO Epoch 2 Global steps: 7000 Train loss: 0.4140
en_zh Dev loss: 0.7784 r:0.4599
ro_en Dev loss: 0.3556 r:0.8092
Current avg r:0.6345 Best avg r: 0.6477
16:05:19,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:45,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:10,965 root INFO Epoch 2 Global steps: 7200 Train loss: 0.4137
en_zh Dev loss: 0.7939 r:0.4553
ro_en Dev loss: 0.4060 r:0.8037
Current avg r:0.6295 Best avg r: 0.6477
16:07:27,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:53,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:18,795 root INFO Epoch 2 Global steps: 7400 Train loss: 0.3985
en_zh Dev loss: 0.7228 r:0.4715
ro_en Dev loss: 0.3762 r:0.8107
Current avg r:0.6411 Best avg r: 0.6477
16:09:35,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:00,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:26,657 root INFO Epoch 2 Global steps: 7600 Train loss: 0.3959
en_zh Dev loss: 0.7061 r:0.4686
ro_en Dev loss: 0.3399 r:0.8112
Current avg r:0.6399 Best avg r: 0.6477
16:11:43,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:08,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:34,520 root INFO Epoch 2 Global steps: 7800 Train loss: 0.4394
en_zh Dev loss: 0.7032 r:0.4727
ro_en Dev loss: 0.3290 r:0.8153
Current avg r:0.6440 Best avg r: 0.6477
16:13:51,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:16,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:42,360 root INFO Epoch 2 Global steps: 8000 Train loss: 0.4161
en_zh Dev loss: 0.7202 r:0.4684
ro_en Dev loss: 0.3275 r:0.8125
Current avg r:0.6405 Best avg r: 0.6477
16:15:58,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:37,436 root INFO 
id:ro_en cur r: 0.8173 best r: 0.8173
16:16:37,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:17:03,124 root INFO Epoch 2 Global steps: 8200 Train loss: 0.4447
en_zh Dev loss: 0.7019 r:0.4757
ro_en Dev loss: 0.3379 r:0.8176
Current avg r:0.6466 Best avg r: 0.6477
16:18:19,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:45,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:11,156 root INFO Epoch 2 Global steps: 8400 Train loss: 0.4319
en_zh Dev loss: 0.7390 r:0.4571
ro_en Dev loss: 0.3780 r:0.8043
Current avg r:0.6307 Best avg r: 0.6477
16:20:27,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:21:06,362 root INFO 
id:ro_en cur r: 0.8177 best r: 0.8177
16:21:06,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:32,47 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:21:32,53 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:21:57,738 root INFO Epoch 2 Global steps: 8600 Train loss: 0.4032
en_zh Dev loss: 0.6494 r:0.4848
ro_en Dev loss: 0.2994 r:0.8173
Current avg r:0.6511 Best avg r: 0.6511
16:23:14,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:40,153 root INFO 
id:en_zh cur r: 0.4893 best r: 0.4893
16:23:53,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:24:18,677 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:24:18,682 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:24:44,364 root INFO Epoch 2 Global steps: 8800 Train loss: 0.4069
en_zh Dev loss: 0.7067 r:0.4912
ro_en Dev loss: 0.3579 r:0.8140
Current avg r:0.6526 Best avg r: 0.6526
16:26:00,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:39,583 root INFO 
id:ro_en cur r: 0.8179 best r: 0.8179
16:26:39,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:05,283 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:27:05,288 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:27:30,998 root INFO Epoch 2 Global steps: 9000 Train loss: 0.3546
en_zh Dev loss: 0.6519 r:0.4928
ro_en Dev loss: 0.3098 r:0.8159
Current avg r:0.6543 Best avg r: 0.6543
16:28:48,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:13,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:39,411 root INFO Epoch 3 Global steps: 9200 Train loss: 0.3738
en_zh Dev loss: 0.6954 r:0.4707
ro_en Dev loss: 0.3256 r:0.8164
Current avg r:0.6435 Best avg r: 0.6543
16:30:56,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:21,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:47,489 root INFO Epoch 3 Global steps: 9400 Train loss: 0.3691
en_zh Dev loss: 0.6855 r:0.4726
ro_en Dev loss: 0.3359 r:0.8140
Current avg r:0.6433 Best avg r: 0.6543
16:33:04,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:42,904 root INFO 
id:ro_en cur r: 0.8201 best r: 0.8201
16:33:42,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:08,584 root INFO Epoch 3 Global steps: 9600 Train loss: 0.3822
en_zh Dev loss: 0.6980 r:0.4821
ro_en Dev loss: 0.3366 r:0.8169
Current avg r:0.6495 Best avg r: 0.6543
16:35:25,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:51,56 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:16,739 root INFO Epoch 3 Global steps: 9800 Train loss: 0.3610
en_zh Dev loss: 0.7105 r:0.4840
ro_en Dev loss: 0.3501 r:0.8131
Current avg r:0.6485 Best avg r: 0.6543
16:37:33,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:59,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:24,837 root INFO Epoch 3 Global steps: 10000 Train loss: 0.3547
en_zh Dev loss: 0.7141 r:0.4919
ro_en Dev loss: 0.3820 r:0.8123
Current avg r:0.6521 Best avg r: 0.6543
16:39:41,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:07,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:33,228 root INFO Epoch 3 Global steps: 10200 Train loss: 0.3546
en_zh Dev loss: 0.6983 r:0.4811
ro_en Dev loss: 0.3147 r:0.8194
Current avg r:0.6502 Best avg r: 0.6543
16:41:49,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:15,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:41,359 root INFO Epoch 3 Global steps: 10400 Train loss: 0.3526
en_zh Dev loss: 0.6878 r:0.4866
ro_en Dev loss: 0.3291 r:0.8174
Current avg r:0.6520 Best avg r: 0.6543
16:43:58,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:23,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:49,542 root INFO Epoch 3 Global steps: 10600 Train loss: 0.3482
en_zh Dev loss: 0.7542 r:0.4762
ro_en Dev loss: 0.3647 r:0.8156
Current avg r:0.6459 Best avg r: 0.6543
16:46:06,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:32,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:57,709 root INFO Epoch 3 Global steps: 10800 Train loss: 0.3331
en_zh Dev loss: 0.7204 r:0.4860
ro_en Dev loss: 0.3655 r:0.8177
Current avg r:0.6518 Best avg r: 0.6543
16:48:14,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:40,122 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:05,816 root INFO Epoch 3 Global steps: 11000 Train loss: 0.3653
en_zh Dev loss: 0.7182 r:0.4786
ro_en Dev loss: 0.3438 r:0.8151
Current avg r:0.6468 Best avg r: 0.6543
16:50:22,555 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:48,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:13,931 root INFO Epoch 3 Global steps: 11200 Train loss: 0.3696
en_zh Dev loss: 0.6864 r:0.4862
ro_en Dev loss: 0.3380 r:0.8175
Current avg r:0.6519 Best avg r: 0.6543
16:52:30,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:56,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:21,967 root INFO Epoch 3 Global steps: 11400 Train loss: 0.3100
en_zh Dev loss: 0.7380 r:0.4851
ro_en Dev loss: 0.3931 r:0.8175
Current avg r:0.6513 Best avg r: 0.6543
16:54:38,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:04,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:30,185 root INFO Epoch 3 Global steps: 11600 Train loss: 0.3364
en_zh Dev loss: 0.7185 r:0.4831
ro_en Dev loss: 0.3729 r:0.8162
Current avg r:0.6497 Best avg r: 0.6543
16:56:46,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:12,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:38,235 root INFO Epoch 3 Global steps: 11800 Train loss: 0.3419
en_zh Dev loss: 0.7206 r:0.4857
ro_en Dev loss: 0.3566 r:0.8199
Current avg r:0.6528 Best avg r: 0.6543
16:58:54,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:33,487 root INFO 
id:ro_en cur r: 0.8216 best r: 0.8216
16:59:33,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:59,153 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:59:59,160 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:00:24,862 root INFO Epoch 3 Global steps: 12000 Train loss: 0.3398
en_zh Dev loss: 0.6906 r:0.4903
ro_en Dev loss: 0.3392 r:0.8201
Current avg r:0.6552 Best avg r: 0.6552
17:01:41,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:07,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:33,321 root INFO Epoch 4 Global steps: 12200 Train loss: 0.3017
en_zh Dev loss: 0.6900 r:0.4914
ro_en Dev loss: 0.3404 r:0.8170
Current avg r:0.6542 Best avg r: 0.6552
17:03:50,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:15,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:41,543 root INFO Epoch 4 Global steps: 12400 Train loss: 0.3294
en_zh Dev loss: 0.6715 r:0.4889
ro_en Dev loss: 0.3110 r:0.8195
Current avg r:0.6542 Best avg r: 0.6552
17:05:58,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:23,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:49,588 root INFO Epoch 4 Global steps: 12600 Train loss: 0.3335
en_zh Dev loss: 0.7601 r:0.4812
ro_en Dev loss: 0.3656 r:0.8141
Current avg r:0.6476 Best avg r: 0.6552
17:08:06,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:32,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:57,661 root INFO Epoch 4 Global steps: 12800 Train loss: 0.3275
en_zh Dev loss: 0.8147 r:0.4743
ro_en Dev loss: 0.4054 r:0.8103
Current avg r:0.6423 Best avg r: 0.6552
17:10:14,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:39,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:05,687 root INFO Epoch 4 Global steps: 13000 Train loss: 0.3084
en_zh Dev loss: 0.7244 r:0.4932
ro_en Dev loss: 0.3411 r:0.8169
Current avg r:0.6550 Best avg r: 0.6552
17:12:22,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:48,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:13,866 root INFO Epoch 4 Global steps: 13200 Train loss: 0.3053
en_zh Dev loss: 0.7383 r:0.4806
ro_en Dev loss: 0.3620 r:0.8113
Current avg r:0.6459 Best avg r: 0.6552
17:14:30,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:56,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:22,48 root INFO Epoch 4 Global steps: 13400 Train loss: 0.2950
en_zh Dev loss: 0.7259 r:0.4881
ro_en Dev loss: 0.3580 r:0.8135
Current avg r:0.6508 Best avg r: 0.6552
17:16:38,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:04,555 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:30,212 root INFO Epoch 4 Global steps: 13600 Train loss: 0.2848
en_zh Dev loss: 0.7384 r:0.4846
ro_en Dev loss: 0.3763 r:0.8055
Current avg r:0.6450 Best avg r: 0.6552
17:18:46,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:12,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:38,221 root INFO Epoch 4 Global steps: 13800 Train loss: 0.2956
en_zh Dev loss: 0.7326 r:0.4907
ro_en Dev loss: 0.3431 r:0.8173
Current avg r:0.6540 Best avg r: 0.6552
17:20:54,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:20,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:46,163 root INFO Epoch 4 Global steps: 14000 Train loss: 0.2749
en_zh Dev loss: 0.7553 r:0.4836
ro_en Dev loss: 0.3831 r:0.8102
Current avg r:0.6469 Best avg r: 0.6552
17:23:02,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:28,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:54,91 root INFO Epoch 4 Global steps: 14200 Train loss: 0.3063
en_zh Dev loss: 0.7281 r:0.4889
ro_en Dev loss: 0.3582 r:0.8128
Current avg r:0.6508 Best avg r: 0.6552
17:25:10,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:36,398 root INFO 
id:en_zh cur r: 0.4937 best r: 0.4937
17:25:49,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:14,952 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:26:14,957 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:26:40,659 root INFO Epoch 4 Global steps: 14400 Train loss: 0.2803
en_zh Dev loss: 0.6812 r:0.4960
ro_en Dev loss: 0.3196 r:0.8204
Current avg r:0.6582 Best avg r: 0.6582
17:27:57,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:23,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:48,778 root INFO Epoch 4 Global steps: 14600 Train loss: 0.2844
en_zh Dev loss: 0.7936 r:0.4766
ro_en Dev loss: 0.3664 r:0.8166
Current avg r:0.6466 Best avg r: 0.6582
17:30:05,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:31,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:56,763 root INFO Epoch 4 Global steps: 14800 Train loss: 0.2922
en_zh Dev loss: 0.7135 r:0.4933
ro_en Dev loss: 0.3335 r:0.8187
Current avg r:0.6560 Best avg r: 0.6582
17:32:13,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:39,43 root INFO 
id:en_zh cur r: 0.4977 best r: 0.4977
17:32:51,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:17,567 root INFO Epoch 4 Global steps: 15000 Train loss: 0.2809
en_zh Dev loss: 0.7218 r:0.4960
ro_en Dev loss: 0.3787 r:0.8136
Current avg r:0.6548 Best avg r: 0.6582
17:34:34,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:00,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:26,149 root INFO Epoch 5 Global steps: 15200 Train loss: 0.2680
en_zh Dev loss: 0.6930 r:0.4969
ro_en Dev loss: 0.3266 r:0.8160
Current avg r:0.6564 Best avg r: 0.6582
17:36:42,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:08,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:34,302 root INFO Epoch 5 Global steps: 15400 Train loss: 0.2752
en_zh Dev loss: 0.7747 r:0.4845
ro_en Dev loss: 0.3804 r:0.8144
Current avg r:0.6495 Best avg r: 0.6582
17:38:51,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:16,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:42,516 root INFO Epoch 5 Global steps: 15600 Train loss: 0.2711
en_zh Dev loss: 0.7549 r:0.4877
ro_en Dev loss: 0.3681 r:0.8144
Current avg r:0.6511 Best avg r: 0.6582
17:40:59,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:24,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:50,567 root INFO Epoch 5 Global steps: 15800 Train loss: 0.2597
en_zh Dev loss: 0.7221 r:0.4951
ro_en Dev loss: 0.3609 r:0.8168
Current avg r:0.6559 Best avg r: 0.6582
17:43:07,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:33,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:58,738 root INFO Epoch 5 Global steps: 16000 Train loss: 0.2577
en_zh Dev loss: 0.8519 r:0.4788
ro_en Dev loss: 0.3881 r:0.8160
Current avg r:0.6474 Best avg r: 0.6582
17:45:15,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:41,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:06,887 root INFO Epoch 5 Global steps: 16200 Train loss: 0.2650
en_zh Dev loss: 0.7932 r:0.4854
ro_en Dev loss: 0.3572 r:0.8160
Current avg r:0.6507 Best avg r: 0.6582
17:47:23,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:49,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:15,108 root INFO Epoch 5 Global steps: 16400 Train loss: 0.2366
en_zh Dev loss: 0.7610 r:0.4854
ro_en Dev loss: 0.3550 r:0.8161
Current avg r:0.6508 Best avg r: 0.6582
17:49:31,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:57,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:23,323 root INFO Epoch 5 Global steps: 16600 Train loss: 0.2585
en_zh Dev loss: 0.7467 r:0.4873
ro_en Dev loss: 0.3661 r:0.8096
Current avg r:0.6484 Best avg r: 0.6582
17:51:40,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:05,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:31,464 root INFO Epoch 5 Global steps: 16800 Train loss: 0.2327
en_zh Dev loss: 0.7422 r:0.4909
ro_en Dev loss: 0.3629 r:0.8144
Current avg r:0.6526 Best avg r: 0.6582
17:53:48,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:13,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:39,604 root INFO Epoch 5 Global steps: 17000 Train loss: 0.2330
en_zh Dev loss: 0.7944 r:0.4698
ro_en Dev loss: 0.3709 r:0.8096
Current avg r:0.6397 Best avg r: 0.6582
17:55:56,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:22,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:47,779 root INFO Epoch 5 Global steps: 17200 Train loss: 0.2580
en_zh Dev loss: 0.7795 r:0.4815
ro_en Dev loss: 0.3702 r:0.8151
Current avg r:0.6483 Best avg r: 0.6582
17:58:04,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:30,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:55,996 root INFO Epoch 5 Global steps: 17400 Train loss: 0.2348
en_zh Dev loss: 0.7982 r:0.4772
ro_en Dev loss: 0.3820 r:0.8098
Current avg r:0.6435 Best avg r: 0.6582
18:00:12,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:38,490 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:04,175 root INFO Epoch 5 Global steps: 17600 Train loss: 0.2306
en_zh Dev loss: 0.7279 r:0.4874
ro_en Dev loss: 0.3482 r:0.8104
Current avg r:0.6489 Best avg r: 0.6582
18:02:20,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:46,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:12,313 root INFO Epoch 5 Global steps: 17800 Train loss: 0.2512
en_zh Dev loss: 0.7629 r:0.4847
ro_en Dev loss: 0.3533 r:0.8119
Current avg r:0.6483 Best avg r: 0.6582
18:04:29,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:54,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:20,444 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:05:20,451 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:05:46,132 root INFO Epoch 5 Global steps: 18000 Train loss: 0.2508
en_zh Dev loss: 0.6966 r:0.4973
ro_en Dev loss: 0.3145 r:0.8194
Current avg r:0.6583 Best avg r: 0.6583
18:07:03,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:29,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:54,729 root INFO Epoch 6 Global steps: 18200 Train loss: 0.2086
en_zh Dev loss: 0.7940 r:0.4765
ro_en Dev loss: 0.3547 r:0.8140
Current avg r:0.6453 Best avg r: 0.6583
18:09:11,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:37,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:02,944 root INFO Epoch 6 Global steps: 18400 Train loss: 0.1966
en_zh Dev loss: 0.7598 r:0.4777
ro_en Dev loss: 0.3561 r:0.8125
Current avg r:0.6451 Best avg r: 0.6583
18:11:19,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:45,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:11,86 root INFO Epoch 6 Global steps: 18600 Train loss: 0.2301
en_zh Dev loss: 0.7827 r:0.4880
ro_en Dev loss: 0.3752 r:0.8155
Current avg r:0.6518 Best avg r: 0.6583
18:13:27,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:53,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:19,235 root INFO Epoch 6 Global steps: 18800 Train loss: 0.2196
en_zh Dev loss: 0.7613 r:0.4848
ro_en Dev loss: 0.3595 r:0.8144
Current avg r:0.6496 Best avg r: 0.6583
18:15:35,915 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:01,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:27,289 root INFO Epoch 6 Global steps: 19000 Train loss: 0.2077
en_zh Dev loss: 0.7763 r:0.4758
ro_en Dev loss: 0.3518 r:0.8144
Current avg r:0.6451 Best avg r: 0.6583
18:17:43,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:09,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:35,368 root INFO Epoch 6 Global steps: 19200 Train loss: 0.2174
en_zh Dev loss: 0.7597 r:0.4744
ro_en Dev loss: 0.3401 r:0.8176
Current avg r:0.6460 Best avg r: 0.6583
18:19:52,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:17,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:43,496 root INFO Epoch 6 Global steps: 19400 Train loss: 0.2112
en_zh Dev loss: 0.7658 r:0.4804
ro_en Dev loss: 0.3528 r:0.8142
Current avg r:0.6473 Best avg r: 0.6583
18:22:00,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:25,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:51,425 root INFO Epoch 6 Global steps: 19600 Train loss: 0.2230
en_zh Dev loss: 0.8030 r:0.4795
ro_en Dev loss: 0.3636 r:0.8137
Current avg r:0.6466 Best avg r: 0.6583
18:24:08,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:24:33,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:59,467 root INFO Epoch 6 Global steps: 19800 Train loss: 0.2140
en_zh Dev loss: 0.7790 r:0.4874
ro_en Dev loss: 0.3875 r:0.8168
Current avg r:0.6521 Best avg r: 0.6583
18:26:16,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:41,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:07,462 root INFO Epoch 6 Global steps: 20000 Train loss: 0.1978
en_zh Dev loss: 0.8203 r:0.4856
ro_en Dev loss: 0.3934 r:0.8140
Current avg r:0.6498 Best avg r: 0.6583
18:28:24,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:49,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:15,526 root INFO Epoch 6 Global steps: 20200 Train loss: 0.2199
en_zh Dev loss: 0.8025 r:0.4839
ro_en Dev loss: 0.3799 r:0.8126
Current avg r:0.6483 Best avg r: 0.6583
18:30:32,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:57,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:23,615 root INFO Epoch 6 Global steps: 20400 Train loss: 0.2332
en_zh Dev loss: 0.7790 r:0.4877
ro_en Dev loss: 0.3835 r:0.8111
Current avg r:0.6494 Best avg r: 0.6583
18:32:40,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:05,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:31,584 root INFO Epoch 6 Global steps: 20600 Train loss: 0.1987
en_zh Dev loss: 0.7571 r:0.4840
ro_en Dev loss: 0.3694 r:0.8098
Current avg r:0.6469 Best avg r: 0.6583
18:34:48,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:13,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:39,602 root INFO Epoch 6 Global steps: 20800 Train loss: 0.2052
en_zh Dev loss: 0.7244 r:0.4980
ro_en Dev loss: 0.3440 r:0.8128
Current avg r:0.6554 Best avg r: 0.6583
18:36:56,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:37:22,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:47,738 root INFO Epoch 6 Global steps: 21000 Train loss: 0.2171
en_zh Dev loss: 0.7636 r:0.4939
ro_en Dev loss: 0.3638 r:0.8134
Current avg r:0.6537 Best avg r: 0.6583
18:39:05,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:30,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:39:56,448 root INFO Epoch 7 Global steps: 21200 Train loss: 0.1862
en_zh Dev loss: 0.7613 r:0.4874
ro_en Dev loss: 0.3729 r:0.8109
Current avg r:0.6491 Best avg r: 0.6583
18:41:13,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:38,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:04,611 root INFO Epoch 7 Global steps: 21400 Train loss: 0.1899
en_zh Dev loss: 0.8794 r:0.4631
ro_en Dev loss: 0.4304 r:0.8058
Current avg r:0.6345 Best avg r: 0.6583
18:43:21,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:46,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:12,689 root INFO Epoch 7 Global steps: 21600 Train loss: 0.1710
en_zh Dev loss: 0.7926 r:0.4834
ro_en Dev loss: 0.3670 r:0.8147
Current avg r:0.6490 Best avg r: 0.6583
18:45:29,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:55,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:20,821 root INFO Epoch 7 Global steps: 21800 Train loss: 0.1792
en_zh Dev loss: 0.7876 r:0.4834
ro_en Dev loss: 0.3647 r:0.8140
Current avg r:0.6487 Best avg r: 0.6583
18:47:37,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:03,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:29,43 root INFO Epoch 7 Global steps: 22000 Train loss: 0.1834
en_zh Dev loss: 0.8199 r:0.4730
ro_en Dev loss: 0.3759 r:0.8090
Current avg r:0.6410 Best avg r: 0.6583
18:49:45,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:11,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:37,268 root INFO Epoch 7 Global steps: 22200 Train loss: 0.1804
en_zh Dev loss: 0.8355 r:0.4765
ro_en Dev loss: 0.4208 r:0.8064
Current avg r:0.6415 Best avg r: 0.6583
18:51:54,35 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:19,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:45,431 root INFO Epoch 7 Global steps: 22400 Train loss: 0.1981
en_zh Dev loss: 0.7820 r:0.4865
ro_en Dev loss: 0.3556 r:0.8129
Current avg r:0.6497 Best avg r: 0.6583
18:54:02,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:27,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:53,507 root INFO Epoch 7 Global steps: 22600 Train loss: 0.1717
en_zh Dev loss: 0.7921 r:0.4822
ro_en Dev loss: 0.3539 r:0.8126
Current avg r:0.6474 Best avg r: 0.6583
18:56:10,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:35,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:01,544 root INFO Epoch 7 Global steps: 22800 Train loss: 0.1898
en_zh Dev loss: 0.7841 r:0.4871
ro_en Dev loss: 0.3821 r:0.8109
Current avg r:0.6490 Best avg r: 0.6583
18:58:18,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:43,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:09,552 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2009
en_zh Dev loss: 0.8068 r:0.4847
ro_en Dev loss: 0.3841 r:0.8121
Current avg r:0.6484 Best avg r: 0.6583
19:00:26,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:51,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:17,575 root INFO Epoch 7 Global steps: 23200 Train loss: 0.1914
en_zh Dev loss: 0.7963 r:0.4868
ro_en Dev loss: 0.3990 r:0.8084
Current avg r:0.6476 Best avg r: 0.6583
19:02:34,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:59,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:25,610 root INFO Epoch 7 Global steps: 23400 Train loss: 0.1707
en_zh Dev loss: 0.7737 r:0.4905
ro_en Dev loss: 0.3855 r:0.8086
Current avg r:0.6495 Best avg r: 0.6583
19:04:42,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:07,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:33,657 root INFO Epoch 7 Global steps: 23600 Train loss: 0.1880
en_zh Dev loss: 0.7990 r:0.4816
ro_en Dev loss: 0.3707 r:0.8073
Current avg r:0.6445 Best avg r: 0.6583
19:06:50,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:16,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:41,759 root INFO Epoch 7 Global steps: 23800 Train loss: 0.1857
en_zh Dev loss: 0.7771 r:0.4863
ro_en Dev loss: 0.3670 r:0.8088
Current avg r:0.6476 Best avg r: 0.6583
19:08:58,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:24,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:49,782 root INFO Epoch 7 Global steps: 24000 Train loss: 0.1831
en_zh Dev loss: 0.8206 r:0.4686
ro_en Dev loss: 0.3802 r:0.8012
Current avg r:0.6349 Best avg r: 0.6583
19:11:06,726 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:32,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:58,86 root INFO Epoch 8 Global steps: 24200 Train loss: 0.1677
en_zh Dev loss: 0.7887 r:0.4824
ro_en Dev loss: 0.3774 r:0.8085
Current avg r:0.6454 Best avg r: 0.6583
19:13:14,558 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:40,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:05,927 root INFO Epoch 8 Global steps: 24400 Train loss: 0.1694
en_zh Dev loss: 0.7469 r:0.4871
ro_en Dev loss: 0.3670 r:0.8047
Current avg r:0.6459 Best avg r: 0.6583
19:15:22,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:48,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:13,763 root INFO Epoch 8 Global steps: 24600 Train loss: 0.1495
en_zh Dev loss: 0.8153 r:0.4791
ro_en Dev loss: 0.3928 r:0.8091
Current avg r:0.6441 Best avg r: 0.6583
19:17:30,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:55,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:21,587 root INFO Epoch 8 Global steps: 24800 Train loss: 0.1516
en_zh Dev loss: 0.7632 r:0.4890
ro_en Dev loss: 0.3672 r:0.8112
Current avg r:0.6501 Best avg r: 0.6583
19:19:38,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:03,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:29,408 root INFO Epoch 8 Global steps: 25000 Train loss: 0.1605
en_zh Dev loss: 0.8026 r:0.4873
ro_en Dev loss: 0.4029 r:0.8065
Current avg r:0.6469 Best avg r: 0.6583
19:21:46,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:11,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:37,494 root INFO Epoch 8 Global steps: 25200 Train loss: 0.1763
en_zh Dev loss: 0.7930 r:0.4969
ro_en Dev loss: 0.3909 r:0.8100
Current avg r:0.6535 Best avg r: 0.6583
19:23:54,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:19,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:45,635 root INFO Epoch 8 Global steps: 25400 Train loss: 0.1764
en_zh Dev loss: 0.8018 r:0.4877
ro_en Dev loss: 0.3598 r:0.8128
Current avg r:0.6503 Best avg r: 0.6583
19:26:02,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:28,124 root INFO 
id:en_zh cur r: 0.4995 best r: 0.4995
19:26:41,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:06,889 root INFO Epoch 8 Global steps: 25600 Train loss: 0.1593
en_zh Dev loss: 0.7594 r:0.5001
ro_en Dev loss: 0.3769 r:0.8102
Current avg r:0.6551 Best avg r: 0.6583
19:28:24,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:49,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:15,874 root INFO Epoch 8 Global steps: 25800 Train loss: 0.1560
en_zh Dev loss: 0.8273 r:0.4917
ro_en Dev loss: 0.3871 r:0.8147
Current avg r:0.6532 Best avg r: 0.6583
19:30:32,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:58,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:24,213 root INFO Epoch 8 Global steps: 26000 Train loss: 0.1559
en_zh Dev loss: 0.8554 r:0.4864
ro_en Dev loss: 0.4206 r:0.8115
Current avg r:0.6489 Best avg r: 0.6583
19:32:40,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:06,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:32,324 root INFO Epoch 8 Global steps: 26200 Train loss: 0.1615
en_zh Dev loss: 0.7706 r:0.4885
ro_en Dev loss: 0.3468 r:0.8135
Current avg r:0.6510 Best avg r: 0.6583
19:34:49,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:14,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:40,348 root INFO Epoch 8 Global steps: 26400 Train loss: 0.1514
en_zh Dev loss: 0.7751 r:0.4856
ro_en Dev loss: 0.3537 r:0.8137
Current avg r:0.6496 Best avg r: 0.6583
19:36:57,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:37:23,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:48,855 root INFO Epoch 8 Global steps: 26600 Train loss: 0.1687
en_zh Dev loss: 0.7815 r:0.4807
ro_en Dev loss: 0.3611 r:0.8138
Current avg r:0.6472 Best avg r: 0.6583
19:39:06,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:31,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:39:57,877 root INFO Epoch 8 Global steps: 26800 Train loss: 0.1574
en_zh Dev loss: 0.7831 r:0.4872
ro_en Dev loss: 0.3646 r:0.8155
Current avg r:0.6514 Best avg r: 0.6583
19:41:15,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:40,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:06,816 root INFO Epoch 8 Global steps: 27000 Train loss: 0.1579
en_zh Dev loss: 0.8026 r:0.4880
ro_en Dev loss: 0.3642 r:0.8116
Current avg r:0.6498 Best avg r: 0.6583
19:43:23,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:49,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:15,145 root INFO Epoch 9 Global steps: 27200 Train loss: 0.1358
en_zh Dev loss: 0.8032 r:0.4893
ro_en Dev loss: 0.3765 r:0.8087
Current avg r:0.6490 Best avg r: 0.6583
19:45:31,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:57,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:46:23,230 root INFO Epoch 9 Global steps: 27400 Train loss: 0.1552
en_zh Dev loss: 0.7975 r:0.4949
ro_en Dev loss: 0.3909 r:0.8086
Current avg r:0.6518 Best avg r: 0.6583
19:47:39,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:05,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:31,315 root INFO Epoch 9 Global steps: 27600 Train loss: 0.1543
en_zh Dev loss: 0.7633 r:0.4832
ro_en Dev loss: 0.3508 r:0.8115
Current avg r:0.6473 Best avg r: 0.6583
19:49:48,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:13,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:39,554 root INFO Epoch 9 Global steps: 27800 Train loss: 0.1481
en_zh Dev loss: 0.7523 r:0.4893
ro_en Dev loss: 0.3555 r:0.8161
Current avg r:0.6527 Best avg r: 0.6583
19:51:56,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:22,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:47,820 root INFO Epoch 9 Global steps: 28000 Train loss: 0.1460
en_zh Dev loss: 0.7973 r:0.4829
ro_en Dev loss: 0.3964 r:0.8070
Current avg r:0.6449 Best avg r: 0.6583
19:54:04,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:30,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:56,84 root INFO Epoch 9 Global steps: 28200 Train loss: 0.1451
en_zh Dev loss: 0.7403 r:0.4954
ro_en Dev loss: 0.3608 r:0.8095
Current avg r:0.6524 Best avg r: 0.6583
19:56:12,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:38,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:04,331 root INFO Epoch 9 Global steps: 28400 Train loss: 0.1419
en_zh Dev loss: 0.7815 r:0.4837
ro_en Dev loss: 0.3852 r:0.8052
Current avg r:0.6444 Best avg r: 0.6583
19:58:21,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:46,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:12,527 root INFO Epoch 9 Global steps: 28600 Train loss: 0.1440
en_zh Dev loss: 0.7511 r:0.4970
ro_en Dev loss: 0.3519 r:0.8166
Current avg r:0.6568 Best avg r: 0.6583
20:00:29,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:55,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:01:20,707 root INFO Epoch 9 Global steps: 28800 Train loss: 0.1443
en_zh Dev loss: 0.8537 r:0.4750
ro_en Dev loss: 0.3909 r:0.8110
Current avg r:0.6430 Best avg r: 0.6583
20:02:37,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:03,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:28,760 root INFO Epoch 9 Global steps: 29000 Train loss: 0.1558
en_zh Dev loss: 0.8284 r:0.4886
ro_en Dev loss: 0.4147 r:0.8112
Current avg r:0.6499 Best avg r: 0.6583
20:04:45,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:11,104 root INFO 
id:en_zh cur r: 0.5005 best r: 0.5005
20:05:23,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:49,661 root INFO Epoch 9 Global steps: 29200 Train loss: 0.1411
en_zh Dev loss: 0.7433 r:0.4991
ro_en Dev loss: 0.3541 r:0.8118
Current avg r:0.6555 Best avg r: 0.6583
20:07:06,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:07:32,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:57,914 root INFO Epoch 9 Global steps: 29400 Train loss: 0.1398
en_zh Dev loss: 0.8009 r:0.4951
ro_en Dev loss: 0.4066 r:0.8110
Current avg r:0.6531 Best avg r: 0.6583
20:09:14,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:40,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:06,120 root INFO Epoch 9 Global steps: 29600 Train loss: 0.1375
en_zh Dev loss: 0.7710 r:0.4943
ro_en Dev loss: 0.3678 r:0.8141
Current avg r:0.6542 Best avg r: 0.6583
20:11:22,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:48,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:14,233 root INFO Epoch 9 Global steps: 29800 Train loss: 0.1433
en_zh Dev loss: 0.7857 r:0.4966
ro_en Dev loss: 0.3601 r:0.8107
Current avg r:0.6536 Best avg r: 0.6583
20:13:30,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:56,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:22,248 root INFO Epoch 9 Global steps: 30000 Train loss: 0.1460
en_zh Dev loss: 0.8198 r:0.4939
ro_en Dev loss: 0.3941 r:0.8067
Current avg r:0.6503 Best avg r: 0.6583
20:15:39,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:05,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:30,803 root INFO Epoch 10 Global steps: 30200 Train loss: 0.1372
en_zh Dev loss: 0.8572 r:0.4867
ro_en Dev loss: 0.4034 r:0.8068
Current avg r:0.6467 Best avg r: 0.6583
20:17:47,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:13,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:38,845 root INFO Epoch 10 Global steps: 30400 Train loss: 0.1207
en_zh Dev loss: 0.7706 r:0.4935
ro_en Dev loss: 0.3610 r:0.8103
Current avg r:0.6519 Best avg r: 0.6583
20:19:55,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:21,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:47,64 root INFO Epoch 10 Global steps: 30600 Train loss: 0.1293
en_zh Dev loss: 0.7837 r:0.4895
ro_en Dev loss: 0.3775 r:0.8055
Current avg r:0.6475 Best avg r: 0.6583
20:22:03,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:22:29,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:55,184 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1296
en_zh Dev loss: 0.7828 r:0.4869
ro_en Dev loss: 0.4060 r:0.8082
Current avg r:0.6476 Best avg r: 0.6583
20:24:11,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:37,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:03,206 root INFO Epoch 10 Global steps: 31000 Train loss: 0.1255
en_zh Dev loss: 0.7752 r:0.4889
ro_en Dev loss: 0.3754 r:0.8087
Current avg r:0.6488 Best avg r: 0.6583
20:26:19,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:26:45,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:11,224 root INFO Epoch 10 Global steps: 31200 Train loss: 0.1310
en_zh Dev loss: 0.7817 r:0.4857
ro_en Dev loss: 0.3661 r:0.8126
Current avg r:0.6492 Best avg r: 0.6583
20:28:27,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:53,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:19,247 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1268
en_zh Dev loss: 0.8180 r:0.4805
ro_en Dev loss: 0.3919 r:0.8068
Current avg r:0.6436 Best avg r: 0.6583
20:30:36,181 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:01,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:27,587 root INFO Epoch 10 Global steps: 31600 Train loss: 0.1285
en_zh Dev loss: 0.7686 r:0.4862
ro_en Dev loss: 0.3768 r:0.8106
Current avg r:0.6484 Best avg r: 0.6583
20:32:44,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:33:10,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:35,715 root INFO Epoch 10 Global steps: 31800 Train loss: 0.1208
en_zh Dev loss: 0.7988 r:0.4804
ro_en Dev loss: 0.3793 r:0.8102
Current avg r:0.6453 Best avg r: 0.6583
20:34:52,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:18,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:43,967 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1135
en_zh Dev loss: 0.7601 r:0.4803
ro_en Dev loss: 0.3463 r:0.8142
Current avg r:0.6473 Best avg r: 0.6583
20:37:00,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:26,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:52,265 root INFO Epoch 10 Global steps: 32200 Train loss: 0.1345
en_zh Dev loss: 0.7870 r:0.4764
ro_en Dev loss: 0.3755 r:0.8064
Current avg r:0.6414 Best avg r: 0.6583
20:39:09,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:34,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:00,456 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1224
en_zh Dev loss: 0.7844 r:0.4770
ro_en Dev loss: 0.3906 r:0.8027
Current avg r:0.6398 Best avg r: 0.6583
20:41:17,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:42,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:08,580 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1190
en_zh Dev loss: 0.7745 r:0.4849
ro_en Dev loss: 0.3793 r:0.8048
Current avg r:0.6448 Best avg r: 0.6583
20:43:25,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:51,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:16,702 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1295
en_zh Dev loss: 0.7925 r:0.4833
ro_en Dev loss: 0.3825 r:0.8046
Current avg r:0.6440 Best avg r: 0.6583
20:45:33,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:59,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:24,873 root INFO Epoch 10 Global steps: 33000 Train loss: 0.1395
en_zh Dev loss: 0.8260 r:0.4848
ro_en Dev loss: 0.3985 r:0.8097
Current avg r:0.6472 Best avg r: 0.6583
20:47:41,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:07,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:33,125 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1195
en_zh Dev loss: 0.8332 r:0.4894
ro_en Dev loss: 0.4065 r:0.8100
Current avg r:0.6497 Best avg r: 0.6583
20:49:49,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:15,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:40,979 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1169
en_zh Dev loss: 0.7825 r:0.4947
ro_en Dev loss: 0.3831 r:0.8086
Current avg r:0.6517 Best avg r: 0.6583
20:51:57,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:23,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:48,889 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1153
en_zh Dev loss: 0.7411 r:0.4949
ro_en Dev loss: 0.3598 r:0.8110
Current avg r:0.6530 Best avg r: 0.6583
20:54:05,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:31,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:56,830 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1154
en_zh Dev loss: 0.7609 r:0.4916
ro_en Dev loss: 0.3735 r:0.8082
Current avg r:0.6499 Best avg r: 0.6583
20:56:13,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:39,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:57:04,708 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1178
en_zh Dev loss: 0.7815 r:0.4879
ro_en Dev loss: 0.3754 r:0.8085
Current avg r:0.6482 Best avg r: 0.6583
20:58:21,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:46,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:12,666 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1148
en_zh Dev loss: 0.8410 r:0.4813
ro_en Dev loss: 0.3916 r:0.8115
Current avg r:0.6464 Best avg r: 0.6583
21:00:29,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:54,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:20,606 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1190
en_zh Dev loss: 0.7694 r:0.4917
ro_en Dev loss: 0.3768 r:0.8087
Current avg r:0.6502 Best avg r: 0.6583
21:02:37,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:02,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:28,543 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1166
en_zh Dev loss: 0.7845 r:0.4900
ro_en Dev loss: 0.3521 r:0.8138
Current avg r:0.6519 Best avg r: 0.6583
21:04:45,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:10,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:36,408 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1096
en_zh Dev loss: 0.7471 r:0.4940
ro_en Dev loss: 0.3650 r:0.8126
Current avg r:0.6533 Best avg r: 0.6583
21:06:52,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:18,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:44,334 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1079
en_zh Dev loss: 0.8003 r:0.4880
ro_en Dev loss: 0.3822 r:0.8108
Current avg r:0.6494 Best avg r: 0.6583
21:09:00,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:26,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:52,242 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1209
en_zh Dev loss: 0.8044 r:0.4885
ro_en Dev loss: 0.3873 r:0.8091
Current avg r:0.6488 Best avg r: 0.6583
21:11:08,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:34,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:12:00,183 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1186
en_zh Dev loss: 0.7162 r:0.4954
ro_en Dev loss: 0.3390 r:0.8095
Current avg r:0.6525 Best avg r: 0.6583
21:13:16,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:42,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:08,220 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1185
en_zh Dev loss: 0.7942 r:0.4923
ro_en Dev loss: 0.3837 r:0.8113
Current avg r:0.6518 Best avg r: 0.6583
21:15:24,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:50,636 root INFO 
id:en_zh cur r: 0.5029 best r: 0.5029
21:16:03,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:29,187 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1218
en_zh Dev loss: 0.7600 r:0.5021
ro_en Dev loss: 0.3891 r:0.8079
Current avg r:0.6550 Best avg r: 0.6583
21:17:45,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:11,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:37,118 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1215
en_zh Dev loss: 0.7353 r:0.5005
ro_en Dev loss: 0.3655 r:0.8092
Current avg r:0.6549 Best avg r: 0.6583
21:19:54,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:19,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:45,616 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1041
en_zh Dev loss: 0.7870 r:0.4840
ro_en Dev loss: 0.3906 r:0.8072
Current avg r:0.6456 Best avg r: 0.6583
21:22:02,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:28,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:53,827 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1118
en_zh Dev loss: 0.7995 r:0.4956
ro_en Dev loss: 0.4020 r:0.8092
Current avg r:0.6524 Best avg r: 0.6583
21:24:10,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:36,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:01,976 root INFO Epoch 12 Global steps: 36600 Train loss: 0.0962
en_zh Dev loss: 0.7964 r:0.4994
ro_en Dev loss: 0.4007 r:0.8158
Current avg r:0.6576 Best avg r: 0.6583
21:26:18,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:26:44,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:10,62 root INFO Epoch 12 Global steps: 36800 Train loss: 0.0961
en_zh Dev loss: 0.7945 r:0.4988
ro_en Dev loss: 0.3799 r:0.8129
Current avg r:0.6558 Best avg r: 0.6583
21:28:26,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:52,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:17,968 root INFO Epoch 12 Global steps: 37000 Train loss: 0.0995
en_zh Dev loss: 0.7774 r:0.5011
ro_en Dev loss: 0.3797 r:0.8106
Current avg r:0.6559 Best avg r: 0.6583
21:30:34,519 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:00,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:25,884 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1019
en_zh Dev loss: 0.8083 r:0.4901
ro_en Dev loss: 0.4075 r:0.8056
Current avg r:0.6479 Best avg r: 0.6583
21:32:42,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:33:08,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:33,773 root INFO Epoch 12 Global steps: 37400 Train loss: 0.0988
en_zh Dev loss: 0.7899 r:0.4958
ro_en Dev loss: 0.3587 r:0.8148
Current avg r:0.6553 Best avg r: 0.6583
21:34:50,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:15,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:41,664 root INFO Epoch 12 Global steps: 37600 Train loss: 0.0972
en_zh Dev loss: 0.8003 r:0.4952
ro_en Dev loss: 0.3920 r:0.8104
Current avg r:0.6528 Best avg r: 0.6583
21:36:58,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:23,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:49,605 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1070
en_zh Dev loss: 0.7813 r:0.4992
ro_en Dev loss: 0.3514 r:0.8145
Current avg r:0.6569 Best avg r: 0.6583
21:39:06,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:31,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:57,528 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1113
en_zh Dev loss: 0.7751 r:0.4975
ro_en Dev loss: 0.3629 r:0.8116
Current avg r:0.6545 Best avg r: 0.6583
21:41:14,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:39,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:05,396 root INFO Epoch 12 Global steps: 38200 Train loss: 0.0992
en_zh Dev loss: 0.7596 r:0.4943
ro_en Dev loss: 0.3490 r:0.8162
Current avg r:0.6553 Best avg r: 0.6583
21:43:21,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:47,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:13,284 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1032
en_zh Dev loss: 0.8223 r:0.4946
ro_en Dev loss: 0.3950 r:0.8117
Current avg r:0.6532 Best avg r: 0.6583
21:45:29,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:55,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:21,252 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1015
en_zh Dev loss: 0.7885 r:0.4927
ro_en Dev loss: 0.3976 r:0.8076
Current avg r:0.6501 Best avg r: 0.6583
21:47:37,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:03,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:29,185 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1058
en_zh Dev loss: 0.8066 r:0.4960
ro_en Dev loss: 0.3762 r:0.8129
Current avg r:0.6544 Best avg r: 0.6583
21:49:45,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:11,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:50:37,215 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1072
en_zh Dev loss: 0.7974 r:0.4966
ro_en Dev loss: 0.4099 r:0.8081
Current avg r:0.6523 Best avg r: 0.6583
21:51:54,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:20,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:45,712 root INFO Epoch 13 Global steps: 39200 Train loss: 0.0934
en_zh Dev loss: 0.8246 r:0.4996
ro_en Dev loss: 0.4097 r:0.8091
Current avg r:0.6544 Best avg r: 0.6583
21:54:02,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:28,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:53,854 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
21:54:53,861 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
21:55:19,553 root INFO Epoch 13 Global steps: 39400 Train loss: 0.0919
en_zh Dev loss: 0.7298 r:0.5028
ro_en Dev loss: 0.3327 r:0.8145
Current avg r:0.6586 Best avg r: 0.6586
21:56:36,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:01,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:57:27,662 root INFO Epoch 13 Global steps: 39600 Train loss: 0.0982
en_zh Dev loss: 0.7964 r:0.4971
ro_en Dev loss: 0.3728 r:0.8132
Current avg r:0.6551 Best avg r: 0.6586
21:58:44,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:10,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:35,788 root INFO Epoch 13 Global steps: 39800 Train loss: 0.0902
en_zh Dev loss: 0.7652 r:0.5000
ro_en Dev loss: 0.3600 r:0.8134
Current avg r:0.6567 Best avg r: 0.6586
22:00:52,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:01:18,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:43,896 root INFO Epoch 13 Global steps: 40000 Train loss: 0.0904
en_zh Dev loss: 0.8148 r:0.4971
ro_en Dev loss: 0.4007 r:0.8082
Current avg r:0.6526 Best avg r: 0.6586
22:03:00,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:26,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:51,812 root INFO Epoch 13 Global steps: 40200 Train loss: 0.0884
en_zh Dev loss: 0.7845 r:0.4895
ro_en Dev loss: 0.3691 r:0.8109
Current avg r:0.6502 Best avg r: 0.6586
22:05:08,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:33,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:59,650 root INFO Epoch 13 Global steps: 40400 Train loss: 0.0893
en_zh Dev loss: 0.7821 r:0.4914
ro_en Dev loss: 0.3562 r:0.8141
Current avg r:0.6527 Best avg r: 0.6586
22:07:16,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:07:41,926 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:08:07,602 root INFO Epoch 13 Global steps: 40600 Train loss: 0.0939
en_zh Dev loss: 0.7734 r:0.4870
ro_en Dev loss: 0.3616 r:0.8118
Current avg r:0.6494 Best avg r: 0.6586
22:09:24,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:49,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:15,551 root INFO Epoch 13 Global steps: 40800 Train loss: 0.0967
en_zh Dev loss: 0.7957 r:0.4851
ro_en Dev loss: 0.3599 r:0.8112
Current avg r:0.6481 Best avg r: 0.6586
22:11:32,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:57,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:23,470 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1006
en_zh Dev loss: 0.8044 r:0.4939
ro_en Dev loss: 0.3942 r:0.8078
Current avg r:0.6509 Best avg r: 0.6586
22:13:40,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:05,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:31,417 root INFO Epoch 13 Global steps: 41200 Train loss: 0.0942
en_zh Dev loss: 0.7744 r:0.4942
ro_en Dev loss: 0.3810 r:0.8043
Current avg r:0.6492 Best avg r: 0.6586
22:15:47,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:16:13,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:16:39,321 root INFO Epoch 13 Global steps: 41400 Train loss: 0.0900
en_zh Dev loss: 0.8232 r:0.4969
ro_en Dev loss: 0.4000 r:0.8106
Current avg r:0.6537 Best avg r: 0.6586
22:17:55,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:21,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:47,213 root INFO Epoch 13 Global steps: 41600 Train loss: 0.0878
en_zh Dev loss: 0.7746 r:0.4989
ro_en Dev loss: 0.3679 r:0.8089
Current avg r:0.6539 Best avg r: 0.6586
22:20:03,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:29,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:55,277 root INFO Epoch 13 Global steps: 41800 Train loss: 0.0908
en_zh Dev loss: 0.7678 r:0.4975
ro_en Dev loss: 0.3712 r:0.8095
Current avg r:0.6535 Best avg r: 0.6586
22:22:12,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:37,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:03,448 root INFO Epoch 13 Global steps: 42000 Train loss: 0.0930
en_zh Dev loss: 0.8876 r:0.4827
ro_en Dev loss: 0.4009 r:0.8059
Current avg r:0.6443 Best avg r: 0.6586
22:24:20,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:46,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:25:11,974 root INFO Epoch 14 Global steps: 42200 Train loss: 0.0847
en_zh Dev loss: 0.8153 r:0.4903
ro_en Dev loss: 0.3798 r:0.8069
Current avg r:0.6486 Best avg r: 0.6586
22:26:28,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:26:54,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:20,138 root INFO Epoch 14 Global steps: 42400 Train loss: 0.0825
en_zh Dev loss: 0.8465 r:0.4906
ro_en Dev loss: 0.4100 r:0.8045
Current avg r:0.6476 Best avg r: 0.6586
22:28:36,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:02,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:28,289 root INFO Epoch 14 Global steps: 42600 Train loss: 0.0909
en_zh Dev loss: 0.8213 r:0.4868
ro_en Dev loss: 0.3914 r:0.8050
Current avg r:0.6459 Best avg r: 0.6586
22:30:45,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:10,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:36,448 root INFO Epoch 14 Global steps: 42800 Train loss: 0.0845
en_zh Dev loss: 0.7896 r:0.4940
ro_en Dev loss: 0.3969 r:0.8072
Current avg r:0.6506 Best avg r: 0.6586
22:32:53,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:18,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:33:44,586 root INFO Epoch 14 Global steps: 43000 Train loss: 0.0907
en_zh Dev loss: 0.7806 r:0.4981
ro_en Dev loss: 0.3767 r:0.8076
Current avg r:0.6529 Best avg r: 0.6586
22:35:01,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:26,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:52,512 root INFO Epoch 14 Global steps: 43200 Train loss: 0.0885
en_zh Dev loss: 0.7679 r:0.4980
ro_en Dev loss: 0.3738 r:0.8081
Current avg r:0.6530 Best avg r: 0.6586
22:37:09,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:34,780 root INFO 
id:en_zh cur r: 0.5033 best r: 0.5033
22:37:47,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:13,334 root INFO Epoch 14 Global steps: 43400 Train loss: 0.0861
en_zh Dev loss: 0.7721 r:0.4998
ro_en Dev loss: 0.3589 r:0.8130
Current avg r:0.6564 Best avg r: 0.6586
22:39:30,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:39:55,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:21,446 root INFO Epoch 14 Global steps: 43600 Train loss: 0.0806
en_zh Dev loss: 0.7947 r:0.4979
ro_en Dev loss: 0.3938 r:0.8100
Current avg r:0.6539 Best avg r: 0.6586
22:41:38,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:03,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:29,383 root INFO Epoch 14 Global steps: 43800 Train loss: 0.0850
en_zh Dev loss: 0.7866 r:0.4953
ro_en Dev loss: 0.3581 r:0.8111
Current avg r:0.6532 Best avg r: 0.6586
22:43:46,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:11,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:37,555 root INFO Epoch 14 Global steps: 44000 Train loss: 0.0849
en_zh Dev loss: 0.8309 r:0.4934
ro_en Dev loss: 0.3871 r:0.8085
Current avg r:0.6509 Best avg r: 0.6586
22:45:54,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:19,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:45,669 root INFO Epoch 14 Global steps: 44200 Train loss: 0.0826
en_zh Dev loss: 0.8242 r:0.4907
ro_en Dev loss: 0.3874 r:0.8084
Current avg r:0.6496 Best avg r: 0.6586
22:48:02,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:28,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:48:53,781 root INFO Epoch 14 Global steps: 44400 Train loss: 0.0826
en_zh Dev loss: 0.7560 r:0.5003
ro_en Dev loss: 0.3604 r:0.8105
Current avg r:0.6554 Best avg r: 0.6586
22:50:10,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:36,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:01,930 root INFO Epoch 14 Global steps: 44600 Train loss: 0.0876
en_zh Dev loss: 0.8167 r:0.4986
ro_en Dev loss: 0.3812 r:0.8095
Current avg r:0.6540 Best avg r: 0.6586
22:52:18,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:44,366 root INFO 
id:en_zh cur r: 0.5042 best r: 0.5042
22:52:57,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:22,956 root INFO Epoch 14 Global steps: 44800 Train loss: 0.0824
en_zh Dev loss: 0.7607 r:0.5035
ro_en Dev loss: 0.3736 r:0.8088
Current avg r:0.6562 Best avg r: 0.6586
22:54:39,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:05,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:31,173 root INFO Epoch 14 Global steps: 45000 Train loss: 0.0898
en_zh Dev loss: 0.8182 r:0.4965
ro_en Dev loss: 0.3700 r:0.8139
Current avg r:0.6552 Best avg r: 0.6586
22:56:48,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:13,936 root INFO 
id:en_zh cur r: 0.5064 best r: 0.5064
22:57:26,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:52,454 root INFO Epoch 15 Global steps: 45200 Train loss: 0.0758
en_zh Dev loss: 0.7875 r:0.5037
ro_en Dev loss: 0.3827 r:0.8113
Current avg r:0.6575 Best avg r: 0.6586
22:59:09,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:34,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:00,472 root INFO Epoch 15 Global steps: 45400 Train loss: 0.0800
en_zh Dev loss: 0.8597 r:0.4973
ro_en Dev loss: 0.4111 r:0.8101
Current avg r:0.6537 Best avg r: 0.6586
23:01:17,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:42,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:02:08,683 root INFO Epoch 15 Global steps: 45600 Train loss: 0.0731
en_zh Dev loss: 0.9200 r:0.4902
ro_en Dev loss: 0.4162 r:0.8087
Current avg r:0.6495 Best avg r: 0.6586
23:03:25,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:51,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:16,679 root INFO Epoch 15 Global steps: 45800 Train loss: 0.0774
en_zh Dev loss: 0.7962 r:0.4966
ro_en Dev loss: 0.3810 r:0.8097
Current avg r:0.6531 Best avg r: 0.6586
23:05:33,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:58,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:24,647 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
23:06:24,654 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
23:06:50,423 root INFO Epoch 15 Global steps: 46000 Train loss: 0.0736
en_zh Dev loss: 0.7810 r:0.5038
ro_en Dev loss: 0.3582 r:0.8135
Current avg r:0.6586 Best avg r: 0.6586
23:08:07,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:33,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:58,883 root INFO Epoch 15 Global steps: 46200 Train loss: 0.0733
en_zh Dev loss: 0.7519 r:0.5017
ro_en Dev loss: 0.3644 r:0.8099
Current avg r:0.6558 Best avg r: 0.6586
23:10:15,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:41,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:07,236 root INFO Epoch 15 Global steps: 46400 Train loss: 0.0785
en_zh Dev loss: 0.7885 r:0.5017
ro_en Dev loss: 0.4096 r:0.8075
Current avg r:0.6546 Best avg r: 0.6586
23:12:23,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:12:49,292 root INFO 
id:en_zh cur r: 0.5111 best r: 0.5111
23:13:02,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:27,812 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
23:13:27,818 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
23:13:53,509 root INFO Epoch 15 Global steps: 46600 Train loss: 0.0739
en_zh Dev loss: 0.7739 r:0.5112
ro_en Dev loss: 0.3944 r:0.8129
Current avg r:0.6620 Best avg r: 0.6620
23:15:10,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:35,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:01,366 root INFO Epoch 15 Global steps: 46800 Train loss: 0.0773
en_zh Dev loss: 0.7824 r:0.5026
ro_en Dev loss: 0.3725 r:0.8121
Current avg r:0.6573 Best avg r: 0.6620
23:17:17,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:43,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:09,146 root INFO Epoch 15 Global steps: 47000 Train loss: 0.0796
en_zh Dev loss: 0.8241 r:0.4947
ro_en Dev loss: 0.3884 r:0.8115
Current avg r:0.6531 Best avg r: 0.6620
23:19:25,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:51,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:16,930 root INFO Epoch 15 Global steps: 47200 Train loss: 0.0779
en_zh Dev loss: 0.8031 r:0.4992
ro_en Dev loss: 0.3821 r:0.8123
Current avg r:0.6557 Best avg r: 0.6620
23:21:33,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:59,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:25,32 root INFO Epoch 15 Global steps: 47400 Train loss: 0.0845
en_zh Dev loss: 0.7847 r:0.4972
ro_en Dev loss: 0.3584 r:0.8150
Current avg r:0.6561 Best avg r: 0.6620
23:23:41,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:07,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:24:33,356 root INFO Epoch 15 Global steps: 47600 Train loss: 0.0799
en_zh Dev loss: 0.7707 r:0.4966
ro_en Dev loss: 0.3641 r:0.8137
Current avg r:0.6552 Best avg r: 0.6620
23:25:49,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:15,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:41,257 root INFO Epoch 15 Global steps: 47800 Train loss: 0.0751
en_zh Dev loss: 0.7726 r:0.5051
ro_en Dev loss: 0.3551 r:0.8165
Current avg r:0.6608 Best avg r: 0.6620
23:27:57,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:23,130 root INFO 
id:en_zh cur r: 0.5122 best r: 0.5122
23:28:35,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:01,565 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
23:29:01,570 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
23:29:27,242 root INFO Epoch 15 Global steps: 48000 Train loss: 0.0801
en_zh Dev loss: 0.7434 r:0.5110
ro_en Dev loss: 0.3389 r:0.8174
Current avg r:0.6642 Best avg r: 0.6642
23:30:43,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:09,620 root INFO 
id:en_zh cur r: 0.5125 best r: 0.5125
23:31:22,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:48,66 root INFO Epoch 16 Global steps: 48200 Train loss: 0.0736
en_zh Dev loss: 0.7582 r:0.5110
ro_en Dev loss: 0.3560 r:0.8144
Current avg r:0.6627 Best avg r: 0.6642
23:33:04,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:29,927 root INFO 
id:en_zh cur r: 0.5128 best r: 0.5128
23:33:42,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:34:08,348 root INFO Epoch 16 Global steps: 48400 Train loss: 0.0748
en_zh Dev loss: 0.7557 r:0.5119
ro_en Dev loss: 0.3743 r:0.8087
Current avg r:0.6603 Best avg r: 0.6642
23:35:24,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:50,200 root INFO 
id:en_zh cur r: 0.5139 best r: 0.5139
23:36:03,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:28,665 root INFO Epoch 16 Global steps: 48600 Train loss: 0.0737
en_zh Dev loss: 0.7769 r:0.5135
ro_en Dev loss: 0.3794 r:0.8115
Current avg r:0.6625 Best avg r: 0.6642
23:37:44,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:38:10,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:36,166 root INFO Epoch 16 Global steps: 48800 Train loss: 0.0700
en_zh Dev loss: 0.7910 r:0.5106
ro_en Dev loss: 0.3973 r:0.8094
Current avg r:0.6600 Best avg r: 0.6642
23:39:52,434 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:18,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:43,889 root INFO Epoch 16 Global steps: 49000 Train loss: 0.0724
en_zh Dev loss: 0.7912 r:0.5057
ro_en Dev loss: 0.3802 r:0.8134
Current avg r:0.6595 Best avg r: 0.6642
23:42:00,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:25,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:51,373 root INFO Epoch 16 Global steps: 49200 Train loss: 0.0731
en_zh Dev loss: 0.7667 r:0.5087
ro_en Dev loss: 0.3538 r:0.8145
Current avg r:0.6616 Best avg r: 0.6642
23:44:07,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:33,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:58,887 root INFO Epoch 16 Global steps: 49400 Train loss: 0.0761
en_zh Dev loss: 0.8727 r:0.5027
ro_en Dev loss: 0.3917 r:0.8132
Current avg r:0.6579 Best avg r: 0.6642
23:46:15,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:40,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:47:06,460 root INFO Epoch 16 Global steps: 49600 Train loss: 0.0812
en_zh Dev loss: 0.7665 r:0.5085
ro_en Dev loss: 0.3565 r:0.8130
Current avg r:0.6607 Best avg r: 0.6642
23:48:22,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:48,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:13,911 root INFO Epoch 16 Global steps: 49800 Train loss: 0.0750
en_zh Dev loss: 0.8053 r:0.5015
ro_en Dev loss: 0.3754 r:0.8128
Current avg r:0.6572 Best avg r: 0.6642
23:50:30,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:55,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:51:21,508 root INFO Epoch 16 Global steps: 50000 Train loss: 0.0757
en_zh Dev loss: 0.7924 r:0.4970
ro_en Dev loss: 0.3786 r:0.8148
Current avg r:0.6559 Best avg r: 0.6642
23:52:37,865 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:53:03,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:29,95 root INFO Epoch 16 Global steps: 50200 Train loss: 0.0698
en_zh Dev loss: 0.8231 r:0.5020
ro_en Dev loss: 0.3723 r:0.8159
Current avg r:0.6590 Best avg r: 0.6642
23:54:45,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:11,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:36,713 root INFO Epoch 16 Global steps: 50400 Train loss: 0.0749
en_zh Dev loss: 0.7547 r:0.5050
ro_en Dev loss: 0.3690 r:0.8132
Current avg r:0.6591 Best avg r: 0.6642
23:56:53,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:18,765 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:44,392 root INFO Epoch 16 Global steps: 50600 Train loss: 0.0700
en_zh Dev loss: 0.7586 r:0.5049
ro_en Dev loss: 0.3631 r:0.8159
Current avg r:0.6604 Best avg r: 0.6642
23:59:00,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:26,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:52,105 root INFO Epoch 16 Global steps: 50800 Train loss: 0.0669
en_zh Dev loss: 0.7895 r:0.5024
ro_en Dev loss: 0.3832 r:0.8109
Current avg r:0.6566 Best avg r: 0.6642
00:01:08,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:34,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:59,756 root INFO Epoch 16 Global steps: 51000 Train loss: 0.0676
en_zh Dev loss: 0.7902 r:0.5066
ro_en Dev loss: 0.3619 r:0.8150
Current avg r:0.6608 Best avg r: 0.6642
00:03:16,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:42,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:07,721 root INFO Epoch 17 Global steps: 51200 Train loss: 0.0655
en_zh Dev loss: 0.8003 r:0.5013
ro_en Dev loss: 0.3655 r:0.8156
Current avg r:0.6585 Best avg r: 0.6642
00:05:24,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:49,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:06:15,313 root INFO Epoch 17 Global steps: 51400 Train loss: 0.0705
en_zh Dev loss: 0.7801 r:0.5042
ro_en Dev loss: 0.3638 r:0.8140
Current avg r:0.6591 Best avg r: 0.6642
00:07:31,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:57,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:23,101 root INFO Epoch 17 Global steps: 51600 Train loss: 0.0651
en_zh Dev loss: 0.8027 r:0.5039
ro_en Dev loss: 0.3777 r:0.8144
Current avg r:0.6592 Best avg r: 0.6642
00:09:39,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:05,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:30,720 root INFO Epoch 17 Global steps: 51800 Train loss: 0.0653
en_zh Dev loss: 0.7751 r:0.5078
ro_en Dev loss: 0.3659 r:0.8154
Current avg r:0.6616 Best avg r: 0.6642
00:11:47,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:12:12,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:38,302 root INFO Epoch 17 Global steps: 52000 Train loss: 0.0688
en_zh Dev loss: 0.7775 r:0.5062
ro_en Dev loss: 0.3680 r:0.8147
Current avg r:0.6605 Best avg r: 0.6642
00:13:54,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:20,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:45,915 root INFO Epoch 17 Global steps: 52200 Train loss: 0.0658
en_zh Dev loss: 0.8533 r:0.5071
ro_en Dev loss: 0.3915 r:0.8159
Current avg r:0.6615 Best avg r: 0.6642
00:16:02,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:16:27,924 root INFO 
id:en_zh cur r: 0.5167 best r: 0.5167
00:16:40,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:17:06,367 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:17:06,372 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
00:17:31,986 root INFO Epoch 17 Global steps: 52400 Train loss: 0.0619
en_zh Dev loss: 0.7313 r:0.5173
ro_en Dev loss: 0.3495 r:0.8185
Current avg r:0.6679 Best avg r: 0.6679
00:18:48,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:14,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:39,670 root INFO Epoch 17 Global steps: 52600 Train loss: 0.0641
en_zh Dev loss: 0.7559 r:0.5107
ro_en Dev loss: 0.3466 r:0.8160
Current avg r:0.6634 Best avg r: 0.6679
00:20:56,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:21:21,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:21:47,397 root INFO Epoch 17 Global steps: 52800 Train loss: 0.0624
en_zh Dev loss: 0.7895 r:0.5143
ro_en Dev loss: 0.4178 r:0.8103
Current avg r:0.6623 Best avg r: 0.6679
00:23:03,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:29,393 root INFO 
id:en_zh cur r: 0.5167 best r: 0.5167
00:23:42,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:24:07,848 root INFO Epoch 17 Global steps: 53000 Train loss: 0.0658
en_zh Dev loss: 0.7764 r:0.5169
ro_en Dev loss: 0.3754 r:0.8178
Current avg r:0.6674 Best avg r: 0.6679
00:25:24,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:25:49,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:26:15,491 root INFO Epoch 17 Global steps: 53200 Train loss: 0.0630
en_zh Dev loss: 0.7737 r:0.5123
ro_en Dev loss: 0.3579 r:0.8153
Current avg r:0.6638 Best avg r: 0.6679
00:27:31,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:27:57,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:28:23,122 root INFO Epoch 17 Global steps: 53400 Train loss: 0.0667
en_zh Dev loss: 0.8117 r:0.5131
ro_en Dev loss: 0.4075 r:0.8133
Current avg r:0.6632 Best avg r: 0.6679
00:29:39,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:30:05,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:30,776 root INFO Epoch 17 Global steps: 53600 Train loss: 0.0663
en_zh Dev loss: 0.7716 r:0.5133
ro_en Dev loss: 0.3806 r:0.8153
Current avg r:0.6643 Best avg r: 0.6679
00:31:47,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:32:12,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:38,391 root INFO Epoch 17 Global steps: 53800 Train loss: 0.0659
en_zh Dev loss: 0.7707 r:0.5038
ro_en Dev loss: 0.3589 r:0.8153
Current avg r:0.6595 Best avg r: 0.6679
00:33:54,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:20,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:45,972 root INFO Epoch 17 Global steps: 54000 Train loss: 0.0669
en_zh Dev loss: 0.8422 r:0.4989
ro_en Dev loss: 0.4057 r:0.8098
Current avg r:0.6543 Best avg r: 0.6679
00:36:02,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:28,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:53,925 root INFO Epoch 18 Global steps: 54200 Train loss: 0.0593
en_zh Dev loss: 0.8023 r:0.5055
ro_en Dev loss: 0.3684 r:0.8151
Current avg r:0.6603 Best avg r: 0.6679
00:38:10,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:38:35,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:01,517 root INFO Epoch 18 Global steps: 54400 Train loss: 0.0634
en_zh Dev loss: 0.8048 r:0.5076
ro_en Dev loss: 0.3731 r:0.8165
Current avg r:0.6620 Best avg r: 0.6679
00:40:17,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:43,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:09,195 root INFO Epoch 18 Global steps: 54600 Train loss: 0.0610
en_zh Dev loss: 0.7308 r:0.5097
ro_en Dev loss: 0.3463 r:0.8132
Current avg r:0.6615 Best avg r: 0.6679
00:42:25,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:51,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:16,862 root INFO Epoch 18 Global steps: 54800 Train loss: 0.0602
en_zh Dev loss: 0.7785 r:0.5090
ro_en Dev loss: 0.3755 r:0.8129
Current avg r:0.6609 Best avg r: 0.6679
00:44:33,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:58,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:24,593 root INFO Epoch 18 Global steps: 55000 Train loss: 0.0634
en_zh Dev loss: 0.7477 r:0.5130
ro_en Dev loss: 0.3623 r:0.8149
Current avg r:0.6640 Best avg r: 0.6679
00:46:41,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:47:06,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:32,322 root INFO Epoch 18 Global steps: 55200 Train loss: 0.0602
en_zh Dev loss: 0.7805 r:0.5121
ro_en Dev loss: 0.3707 r:0.8153
Current avg r:0.6637 Best avg r: 0.6679
00:48:48,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:14,356 root INFO 
id:en_zh cur r: 0.5179 best r: 0.5179
00:49:27,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:52,796 root INFO Epoch 18 Global steps: 55400 Train loss: 0.0588
en_zh Dev loss: 0.7657 r:0.5163
ro_en Dev loss: 0.3589 r:0.8166
Current avg r:0.6664 Best avg r: 0.6679
00:51:09,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:34,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:00,472 root INFO Epoch 18 Global steps: 55600 Train loss: 0.0615
en_zh Dev loss: 0.7593 r:0.5073
ro_en Dev loss: 0.3623 r:0.8145
Current avg r:0.6609 Best avg r: 0.6679
00:53:16,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:42,521 root INFO 
id:en_zh cur r: 0.5208 best r: 0.5208
00:53:55,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:21,6 root INFO Epoch 18 Global steps: 55800 Train loss: 0.0632
en_zh Dev loss: 0.7533 r:0.5191
ro_en Dev loss: 0.3631 r:0.8162
Current avg r:0.6677 Best avg r: 0.6679
00:55:37,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:03,68 root INFO 
id:en_zh cur r: 0.5219 best r: 0.5219
00:56:15,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:56:41,507 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:56:41,513 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
00:57:07,141 root INFO Epoch 18 Global steps: 56000 Train loss: 0.0639
en_zh Dev loss: 0.7683 r:0.5203
ro_en Dev loss: 0.3706 r:0.8161
Current avg r:0.6682 Best avg r: 0.6682
00:58:23,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:49,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:14,734 root INFO Epoch 18 Global steps: 56200 Train loss: 0.0617
en_zh Dev loss: 0.8350 r:0.5020
ro_en Dev loss: 0.3813 r:0.8141
Current avg r:0.6581 Best avg r: 0.6682
01:00:31,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:56,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:22,330 root INFO Epoch 18 Global steps: 56400 Train loss: 0.0613
en_zh Dev loss: 0.7702 r:0.5129
ro_en Dev loss: 0.3708 r:0.8151
Current avg r:0.6640 Best avg r: 0.6682
01:02:38,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:04,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:29,910 root INFO Epoch 18 Global steps: 56600 Train loss: 0.0575
en_zh Dev loss: 0.7572 r:0.5148
ro_en Dev loss: 0.3548 r:0.8152
Current avg r:0.6650 Best avg r: 0.6682
01:04:46,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:11,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:37,489 root INFO Epoch 18 Global steps: 56800 Train loss: 0.0592
en_zh Dev loss: 0.7964 r:0.5131
ro_en Dev loss: 0.3977 r:0.8108
Current avg r:0.6619 Best avg r: 0.6682
01:06:54,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:19,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:45,349 root INFO Epoch 18 Global steps: 57000 Train loss: 0.0589
en_zh Dev loss: 0.7979 r:0.5098
ro_en Dev loss: 0.3840 r:0.8115
Current avg r:0.6606 Best avg r: 0.6682
01:09:02,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:27,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:09:53,543 root INFO Epoch 19 Global steps: 57200 Train loss: 0.0563
en_zh Dev loss: 0.8123 r:0.5083
ro_en Dev loss: 0.3728 r:0.8132
Current avg r:0.6608 Best avg r: 0.6682
01:11:09,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:35,553 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:01,173 root INFO Epoch 19 Global steps: 57400 Train loss: 0.0581
en_zh Dev loss: 0.7468 r:0.5135
ro_en Dev loss: 0.3536 r:0.8162
Current avg r:0.6648 Best avg r: 0.6682
01:13:17,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:43,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:08,913 root INFO Epoch 19 Global steps: 57600 Train loss: 0.0596
en_zh Dev loss: 0.7660 r:0.5095
ro_en Dev loss: 0.3552 r:0.8170
Current avg r:0.6632 Best avg r: 0.6682
01:15:25,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:51,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:16,666 root INFO Epoch 19 Global steps: 57800 Train loss: 0.0536
en_zh Dev loss: 0.7833 r:0.5132
ro_en Dev loss: 0.3735 r:0.8169
Current avg r:0.6651 Best avg r: 0.6682
01:17:33,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:58,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:24,331 root INFO Epoch 19 Global steps: 58000 Train loss: 0.0546
en_zh Dev loss: 0.8251 r:0.5152
ro_en Dev loss: 0.3855 r:0.8157
Current avg r:0.6654 Best avg r: 0.6682
01:19:40,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:20:06,356 root INFO 
id:en_zh cur r: 0.5248 best r: 0.5248
01:20:19,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:20:44,785 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:20:44,791 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
01:21:10,410 root INFO Epoch 19 Global steps: 58200 Train loss: 0.0602
en_zh Dev loss: 0.7481 r:0.5231
ro_en Dev loss: 0.3634 r:0.8177
Current avg r:0.6704 Best avg r: 0.6704
01:22:27,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:22:52,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:18,466 root INFO Epoch 19 Global steps: 58400 Train loss: 0.0634
en_zh Dev loss: 0.7841 r:0.5094
ro_en Dev loss: 0.3653 r:0.8157
Current avg r:0.6626 Best avg r: 0.6704
01:24:34,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:00,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:26,229 root INFO Epoch 19 Global steps: 58600 Train loss: 0.0597
en_zh Dev loss: 0.7455 r:0.5090
ro_en Dev loss: 0.3535 r:0.8158
Current avg r:0.6624 Best avg r: 0.6704
01:26:42,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:27:08,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:27:33,870 root INFO Epoch 19 Global steps: 58800 Train loss: 0.0561
en_zh Dev loss: 0.7723 r:0.5119
ro_en Dev loss: 0.3551 r:0.8182
Current avg r:0.6650 Best avg r: 0.6704
01:28:50,403 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:16,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:29:41,726 root INFO Epoch 19 Global steps: 59000 Train loss: 0.0573
en_zh Dev loss: 0.7570 r:0.5181
ro_en Dev loss: 0.3539 r:0.8157
Current avg r:0.6669 Best avg r: 0.6704
01:30:58,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:23,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:31:49,414 root INFO Epoch 19 Global steps: 59200 Train loss: 0.0520
en_zh Dev loss: 0.8111 r:0.5118
ro_en Dev loss: 0.3526 r:0.8172
Current avg r:0.6645 Best avg r: 0.6704
01:33:05,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:33:31,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:33:56,996 root INFO Epoch 19 Global steps: 59400 Train loss: 0.0561
en_zh Dev loss: 0.8124 r:0.5125
ro_en Dev loss: 0.3744 r:0.8150
Current avg r:0.6638 Best avg r: 0.6704
01:35:13,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:39,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:04,694 root INFO Epoch 19 Global steps: 59600 Train loss: 0.0596
en_zh Dev loss: 0.7372 r:0.5153
ro_en Dev loss: 0.3380 r:0.8185
Current avg r:0.6669 Best avg r: 0.6704
01:37:21,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:37:46,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:12,473 root INFO Epoch 19 Global steps: 59800 Train loss: 0.0548
en_zh Dev loss: 0.7602 r:0.5143
ro_en Dev loss: 0.3456 r:0.8180
Current avg r:0.6661 Best avg r: 0.6704
01:39:29,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:39:54,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:40:20,388 root INFO Epoch 19 Global steps: 60000 Train loss: 0.0578
en_zh Dev loss: 0.7642 r:0.5200
ro_en Dev loss: 0.3546 r:0.8161
Current avg r:0.6681 Best avg r: 0.6704
00:34:02,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:28,586 root INFO 
id:en_zh cur r: 0.1310 best r: 0.1310
00:34:54,716 root INFO 
id:ro_en cur r: 0.2098 best r: 0.2098
00:34:54,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:20,779 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:35:20,785 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
00:35:46,886 root INFO Epoch 0 Global steps: 200 Train loss: 0.9498
en_zh Dev loss: 0.8162 r:0.1484
ro_en Dev loss: 0.8481 r:0.3730
Current avg r:0.2607 Best avg r: 0.2607
00:37:04,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:30,690 root INFO 
id:en_zh cur r: 0.2210 best r: 0.2210
00:37:56,856 root INFO 
id:ro_en cur r: 0.3023 best r: 0.3023
00:37:56,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:22,960 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:38:22,966 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
00:38:49,84 root INFO Epoch 0 Global steps: 400 Train loss: 0.8970
en_zh Dev loss: 0.8092 r:0.2633
ro_en Dev loss: 0.8408 r:0.3600
Current avg r:0.3116 Best avg r: 0.3116
00:40:06,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:32,992 root INFO 
id:en_zh cur r: 0.2587 best r: 0.2587
00:40:59,160 root INFO 
id:ro_en cur r: 0.5181 best r: 0.5181
00:40:59,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:25,268 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:41:25,273 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
00:41:51,399 root INFO Epoch 0 Global steps: 600 Train loss: 0.8527
en_zh Dev loss: 0.8003 r:0.2892
ro_en Dev loss: 0.8101 r:0.5086
Current avg r:0.3989 Best avg r: 0.3989
00:43:09,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:35,302 root INFO 
id:en_zh cur r: 0.2954 best r: 0.2954
00:44:01,570 root INFO 
id:ro_en cur r: 0.5746 best r: 0.5746
00:44:01,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:27,719 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:44:27,724 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
00:44:53,820 root INFO Epoch 0 Global steps: 800 Train loss: 0.8435
en_zh Dev loss: 0.7835 r:0.2958
ro_en Dev loss: 0.7241 r:0.5698
Current avg r:0.4328 Best avg r: 0.4328
00:46:11,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:37,570 root INFO 
id:en_zh cur r: 0.3226 best r: 0.3226
00:47:03,697 root INFO 
id:ro_en cur r: 0.6500 best r: 0.6500
00:47:03,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:29,757 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:47:29,764 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
00:47:55,862 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7728
en_zh Dev loss: 0.7556 r:0.2976
ro_en Dev loss: 0.6105 r:0.6534
Current avg r:0.4755 Best avg r: 0.4755
00:49:13,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:39,563 root INFO 
id:en_zh cur r: 0.3465 best r: 0.3465
00:50:05,682 root INFO 
id:ro_en cur r: 0.6865 best r: 0.6865
00:50:05,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:31,750 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:50:31,756 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
00:50:57,840 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7240
en_zh Dev loss: 0.7418 r:0.3161
ro_en Dev loss: 0.4946 r:0.6806
Current avg r:0.4983 Best avg r: 0.4983
00:52:15,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:54,499 root INFO 
id:ro_en cur r: 0.7041 best r: 0.7041
00:52:54,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:53:20,588 root INFO Epoch 0 Global steps: 1400 Train loss: 0.6648
en_zh Dev loss: 0.8243 r:0.2759
ro_en Dev loss: 0.6020 r:0.7019
Current avg r:0.4889 Best avg r: 0.4983
00:54:38,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:04,549 root INFO 
id:en_zh cur r: 0.3608 best r: 0.3608
00:55:30,683 root INFO 
id:ro_en cur r: 0.7248 best r: 0.7248
00:55:30,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:56,755 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:55:56,761 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
00:56:22,867 root INFO Epoch 0 Global steps: 1600 Train loss: 0.6491
en_zh Dev loss: 0.7842 r:0.3365
ro_en Dev loss: 0.4485 r:0.7243
Current avg r:0.5304 Best avg r: 0.5304
00:57:40,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:06,536 root INFO 
id:en_zh cur r: 0.4121 best r: 0.4121
00:58:32,673 root INFO 
id:ro_en cur r: 0.7491 best r: 0.7491
00:58:32,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:58,758 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:58:58,764 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
00:59:24,877 root INFO Epoch 0 Global steps: 1800 Train loss: 0.5851
en_zh Dev loss: 0.7194 r:0.4061
ro_en Dev loss: 0.4163 r:0.7498
Current avg r:0.5780 Best avg r: 0.5780
01:00:42,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:01:21,814 root INFO 
id:ro_en cur r: 0.7661 best r: 0.7661
01:01:21,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:47,926 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:01:47,932 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
01:02:14,41 root INFO Epoch 0 Global steps: 2000 Train loss: 0.5463
en_zh Dev loss: 0.7149 r:0.3942
ro_en Dev loss: 0.3707 r:0.7662
Current avg r:0.5802 Best avg r: 0.5802
01:03:31,602 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:57,659 root INFO 
id:en_zh cur r: 0.4128 best r: 0.4128
01:04:23,813 root INFO 
id:ro_en cur r: 0.7775 best r: 0.7775
01:04:23,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:50,34 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:04:50,40 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
01:05:16,272 root INFO Epoch 0 Global steps: 2200 Train loss: 0.5592
en_zh Dev loss: 0.7964 r:0.3934
ro_en Dev loss: 0.3903 r:0.7771
Current avg r:0.5852 Best avg r: 0.5852
01:06:33,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:59,919 root INFO 
id:en_zh cur r: 0.4235 best r: 0.4235
01:07:12,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:39,71 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:07:39,77 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
01:08:05,272 root INFO Epoch 0 Global steps: 2400 Train loss: 0.5233
en_zh Dev loss: 0.7771 r:0.4085
ro_en Dev loss: 0.4558 r:0.7709
Current avg r:0.5897 Best avg r: 0.5897
01:09:22,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:48,897 root INFO 
id:en_zh cur r: 0.4544 best r: 0.4544
01:10:15,39 root INFO 
id:ro_en cur r: 0.7799 best r: 0.7799
01:10:15,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:41,113 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:10:41,119 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
01:11:07,206 root INFO Epoch 0 Global steps: 2600 Train loss: 0.4956
en_zh Dev loss: 0.6972 r:0.4457
ro_en Dev loss: 0.3765 r:0.7779
Current avg r:0.6118 Best avg r: 0.6118
01:12:24,781 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:50,818 root INFO 
id:en_zh cur r: 0.4653 best r: 0.4653
01:13:16,946 root INFO 
id:ro_en cur r: 0.7923 best r: 0.7923
01:13:16,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:13:43,35 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:13:43,41 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
01:14:09,130 root INFO Epoch 0 Global steps: 2800 Train loss: 0.4983
en_zh Dev loss: 0.7235 r:0.4554
ro_en Dev loss: 0.3802 r:0.7898
Current avg r:0.6226 Best avg r: 0.6226
01:15:26,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:53,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:19,112 root INFO Epoch 0 Global steps: 3000 Train loss: 0.4883
en_zh Dev loss: 0.7606 r:0.4300
ro_en Dev loss: 0.4038 r:0.7828
Current avg r:0.6064 Best avg r: 0.6226
01:17:37,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:18:03,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:29,175 root INFO Epoch 1 Global steps: 3200 Train loss: 0.4870
en_zh Dev loss: 0.7496 r:0.4462
ro_en Dev loss: 0.4066 r:0.7902
Current avg r:0.6182 Best avg r: 0.6226
01:19:46,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:20,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:46,894 root INFO 
id:en_zh cur r: 0.0126 best r: 0.0126
09:54:13,56 root INFO 
id:ro_en cur r: 0.2968 best r: 0.2968
09:54:13,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:54:39,162 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
09:54:39,195 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
09:55:05,382 root INFO Epoch 0 Global steps: 200 Train loss: 0.8658
en_zh Dev loss: 0.8150 r:0.1112
ro_en Dev loss: 0.8345 r:0.3573
Current avg r:0.2342 Best avg r: 0.2342
09:56:23,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:49,375 root INFO 
id:en_zh cur r: 0.2081 best r: 0.2081
09:57:15,592 root INFO 
id:ro_en cur r: 0.5662 best r: 0.5662
09:57:15,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:41,734 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
09:57:41,741 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
09:58:07,962 root INFO Epoch 0 Global steps: 400 Train loss: 0.9295
en_zh Dev loss: 0.8075 r:0.1857
ro_en Dev loss: 0.8034 r:0.5764
Current avg r:0.3811 Best avg r: 0.3811
09:59:25,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:59:51,834 root INFO 
id:en_zh cur r: 0.2493 best r: 0.2493
10:00:18,25 root INFO 
id:ro_en cur r: 0.6350 best r: 0.6350
10:00:18,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:44,179 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:00:44,185 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:01:10,460 root INFO Epoch 0 Global steps: 600 Train loss: 0.8508
en_zh Dev loss: 0.7790 r:0.2474
ro_en Dev loss: 0.6847 r:0.6138
Current avg r:0.4306 Best avg r: 0.4306
10:02:28,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:54,422 root INFO 
id:en_zh cur r: 0.2919 best r: 0.2919
10:03:20,612 root INFO 
id:ro_en cur r: 0.6481 best r: 0.6481
10:03:20,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:46,752 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:03:46,758 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:04:13,7 root INFO Epoch 0 Global steps: 800 Train loss: 0.7647
en_zh Dev loss: 0.7820 r:0.2754
ro_en Dev loss: 0.6193 r:0.6286
Current avg r:0.4520 Best avg r: 0.4520
10:05:30,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:06:10,62 root INFO 
id:ro_en cur r: 0.6700 best r: 0.6700
10:06:10,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:36,188 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:06:36,194 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:07:02,398 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7613
en_zh Dev loss: 0.7710 r:0.2863
ro_en Dev loss: 0.5402 r:0.6559
Current avg r:0.4711 Best avg r: 0.4711
10:08:20,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:59,216 root INFO 
id:ro_en cur r: 0.6754 best r: 0.6754
10:08:59,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:25,337 root INFO Epoch 0 Global steps: 1200 Train loss: 0.6897
en_zh Dev loss: 0.7954 r:0.2746
ro_en Dev loss: 0.5049 r:0.6651
Current avg r:0.4698 Best avg r: 0.4711
10:10:42,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:09,67 root INFO 
id:en_zh cur r: 0.2982 best r: 0.2982
10:11:35,266 root INFO 
id:ro_en cur r: 0.6770 best r: 0.6770
10:11:35,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:01,380 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:12:01,404 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:12:27,593 root INFO Epoch 0 Global steps: 1400 Train loss: 0.6946
en_zh Dev loss: 0.7991 r:0.2907
ro_en Dev loss: 0.4739 r:0.6814
Current avg r:0.4861 Best avg r: 0.4861
10:13:45,286 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:11,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:37,527 root INFO Epoch 0 Global steps: 1600 Train loss: 0.6876
en_zh Dev loss: 0.7886 r:0.2906
ro_en Dev loss: 0.4881 r:0.6574
Current avg r:0.4740 Best avg r: 0.4861
10:15:55,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:21,323 root INFO 
id:en_zh cur r: 0.3103 best r: 0.3103
10:16:47,502 root INFO 
id:ro_en cur r: 0.6860 best r: 0.6860
10:16:47,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:13,626 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:17:13,633 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:17:39,854 root INFO Epoch 0 Global steps: 1800 Train loss: 0.6790
en_zh Dev loss: 0.7837 r:0.3059
ro_en Dev loss: 0.4771 r:0.6814
Current avg r:0.4937 Best avg r: 0.4937
10:18:57,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:23,635 root INFO 
id:en_zh cur r: 0.3607 best r: 0.3607
10:19:49,826 root INFO 
id:ro_en cur r: 0.7193 best r: 0.7193
10:19:49,826 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:15,958 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:20:15,965 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:20:42,178 root INFO Epoch 0 Global steps: 2000 Train loss: 0.6419
en_zh Dev loss: 0.7413 r:0.3637
ro_en Dev loss: 0.4446 r:0.7114
Current avg r:0.5375 Best avg r: 0.5375
10:21:59,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:22:26,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:52,112 root INFO Epoch 0 Global steps: 2200 Train loss: 0.5945
en_zh Dev loss: 0.7772 r:0.3508
ro_en Dev loss: 0.4888 r:0.7099
Current avg r:0.5304 Best avg r: 0.5375
10:24:09,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:35,923 root INFO 
id:en_zh cur r: 0.3978 best r: 0.3978
10:25:02,105 root INFO 
id:ro_en cur r: 0.7524 best r: 0.7524
10:25:02,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:25:28,224 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:25:28,230 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:25:54,465 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6191
en_zh Dev loss: 0.7028 r:0.3912
ro_en Dev loss: 0.3846 r:0.7426
Current avg r:0.5669 Best avg r: 0.5669
10:27:12,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:38,342 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:28:04,468 root INFO Epoch 0 Global steps: 2600 Train loss: 0.5832
en_zh Dev loss: 0.7489 r:0.3854
ro_en Dev loss: 0.4191 r:0.7370
Current avg r:0.5612 Best avg r: 0.5669
10:29:22,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:30:01,456 root INFO 
id:ro_en cur r: 0.7604 best r: 0.7604
10:30:01,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:27,572 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:30:27,577 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:30:53,800 root INFO Epoch 0 Global steps: 2800 Train loss: 0.5974
en_zh Dev loss: 0.7822 r:0.3860
ro_en Dev loss: 0.4266 r:0.7495
Current avg r:0.5678 Best avg r: 0.5678
10:32:11,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:32:37,542 root INFO 
id:en_zh cur r: 0.4022 best r: 0.4022
10:33:03,710 root INFO 
id:ro_en cur r: 0.7627 best r: 0.7627
10:33:03,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:33:29,816 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:33:29,846 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:33:56,1 root INFO Epoch 0 Global steps: 3000 Train loss: 0.5671
en_zh Dev loss: 0.6947 r:0.4028
ro_en Dev loss: 0.3681 r:0.7576
Current avg r:0.5802 Best avg r: 0.5802
10:35:14,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:35:40,160 root INFO 
id:en_zh cur r: 0.4093 best r: 0.4093
10:36:06,334 root INFO 
id:ro_en cur r: 0.7756 best r: 0.7756
10:36:06,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:36:32,456 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:36:32,462 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:36:58,654 root INFO Epoch 1 Global steps: 3200 Train loss: 0.5031
en_zh Dev loss: 0.7468 r:0.4001
ro_en Dev loss: 0.3646 r:0.7698
Current avg r:0.5850 Best avg r: 0.5850
10:38:16,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:38:55,614 root INFO 
id:ro_en cur r: 0.7851 best r: 0.7851
10:38:55,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:39:21,749 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:39:21,754 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:39:48,11 root INFO Epoch 1 Global steps: 3400 Train loss: 0.5601
en_zh Dev loss: 0.7525 r:0.4032
ro_en Dev loss: 0.3652 r:0.7822
Current avg r:0.5927 Best avg r: 0.5927
10:41:05,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:41:32,22 root INFO 
id:en_zh cur r: 0.4190 best r: 0.4190
10:41:58,225 root INFO 
id:ro_en cur r: 0.7975 best r: 0.7975
10:41:58,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:42:24,360 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:42:24,367 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:42:50,570 root INFO Epoch 1 Global steps: 3600 Train loss: 0.5350
en_zh Dev loss: 0.6800 r:0.4277
ro_en Dev loss: 0.3219 r:0.7963
Current avg r:0.6120 Best avg r: 0.6120
10:44:08,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:44:34,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:45:00,491 root INFO Epoch 1 Global steps: 3800 Train loss: 0.5090
en_zh Dev loss: 0.8300 r:0.4030
ro_en Dev loss: 0.4443 r:0.7757
Current avg r:0.5894 Best avg r: 0.6120
10:46:18,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:46:44,366 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:47:10,494 root INFO Epoch 1 Global steps: 4000 Train loss: 0.4953
en_zh Dev loss: 0.7362 r:0.4144
ro_en Dev loss: 0.3510 r:0.7889
Current avg r:0.6017 Best avg r: 0.6120
10:48:28,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:48:54,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:49:20,584 root INFO Epoch 1 Global steps: 4200 Train loss: 0.5274
en_zh Dev loss: 0.8408 r:0.3933
ro_en Dev loss: 0.3954 r:0.7862
Current avg r:0.5897 Best avg r: 0.6120
10:50:38,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:51:04,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:51:30,679 root INFO Epoch 1 Global steps: 4400 Train loss: 0.5388
en_zh Dev loss: 0.7436 r:0.4270
ro_en Dev loss: 0.3636 r:0.7911
Current avg r:0.6090 Best avg r: 0.6120
10:52:48,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:53:14,533 root INFO 
id:en_zh cur r: 0.4380 best r: 0.4380
10:53:40,745 root INFO 
id:ro_en cur r: 0.8011 best r: 0.8011
10:53:40,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:54:06,892 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:54:06,924 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:54:33,172 root INFO Epoch 1 Global steps: 4600 Train loss: 0.5093
en_zh Dev loss: 0.7794 r:0.4361
ro_en Dev loss: 0.4063 r:0.7982
Current avg r:0.6171 Best avg r: 0.6171
10:55:51,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:56:17,189 root INFO 
id:en_zh cur r: 0.4486 best r: 0.4486
10:56:43,377 root INFO 
id:ro_en cur r: 0.8071 best r: 0.8071
10:56:43,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:57:09,523 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:57:09,529 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
10:57:35,813 root INFO Epoch 1 Global steps: 4800 Train loss: 0.4647
en_zh Dev loss: 0.7325 r:0.4489
ro_en Dev loss: 0.3514 r:0.8027
Current avg r:0.6258 Best avg r: 0.6258
10:58:53,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:59:19,752 root INFO 
id:en_zh cur r: 0.4553 best r: 0.4553
10:59:45,981 root INFO 
id:ro_en cur r: 0.8093 best r: 0.8093
10:59:45,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:00:12,87 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:00:12,93 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
11:00:38,270 root INFO Epoch 1 Global steps: 5000 Train loss: 0.4675
en_zh Dev loss: 0.6983 r:0.4588
ro_en Dev loss: 0.3181 r:0.8101
Current avg r:0.6345 Best avg r: 0.6345
11:01:55,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:02:22,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:02:48,218 root INFO Epoch 1 Global steps: 5200 Train loss: 0.4522
en_zh Dev loss: 0.7425 r:0.4482
ro_en Dev loss: 0.3249 r:0.8091
Current avg r:0.6287 Best avg r: 0.6345
11:04:05,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:04:32,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:04:58,151 root INFO Epoch 1 Global steps: 5400 Train loss: 0.4877
en_zh Dev loss: 0.7508 r:0.4465
ro_en Dev loss: 0.3448 r:0.8014
Current avg r:0.6239 Best avg r: 0.6345
11:06:15,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:06:42,40 root INFO 
id:en_zh cur r: 0.4684 best r: 0.4684
11:06:55,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:07:21,217 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:07:21,222 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
11:07:47,389 root INFO Epoch 1 Global steps: 5600 Train loss: 0.4688
en_zh Dev loss: 0.6557 r:0.4705
ro_en Dev loss: 0.3151 r:0.8056
Current avg r:0.6381 Best avg r: 0.6381
11:09:05,105 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:09:31,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:09:57,323 root INFO Epoch 1 Global steps: 5800 Train loss: 0.4568
en_zh Dev loss: 0.6649 r:0.4632
ro_en Dev loss: 0.3266 r:0.8025
Current avg r:0.6328 Best avg r: 0.6381
11:11:15,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:11:41,159 root INFO 
id:en_zh cur r: 0.4695 best r: 0.4695
11:11:54,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:12:20,340 root INFO Epoch 1 Global steps: 6000 Train loss: 0.4451
en_zh Dev loss: 0.6896 r:0.4692
ro_en Dev loss: 0.3594 r:0.7999
Current avg r:0.6346 Best avg r: 0.6381
11:13:38,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:14:04,587 root INFO 
id:en_zh cur r: 0.4840 best r: 0.4840
11:14:30,743 root INFO 
id:ro_en cur r: 0.8142 best r: 0.8142
11:14:30,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:14:56,856 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:14:56,863 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
11:15:23,67 root INFO Epoch 2 Global steps: 6200 Train loss: 0.4261
en_zh Dev loss: 0.6669 r:0.4832
ro_en Dev loss: 0.3283 r:0.8121
Current avg r:0.6476 Best avg r: 0.6476
11:16:40,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:17:06,879 root INFO 
id:en_zh cur r: 0.4849 best r: 0.4849
11:17:33,26 root INFO 
id:ro_en cur r: 0.8199 best r: 0.8199
11:17:33,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:17:59,132 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:17:59,138 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
11:18:25,374 root INFO Epoch 2 Global steps: 6400 Train loss: 0.4371
en_zh Dev loss: 0.6566 r:0.4854
ro_en Dev loss: 0.3071 r:0.8223
Current avg r:0.6539 Best avg r: 0.6539
11:19:42,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:20:09,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:20:35,186 root INFO Epoch 2 Global steps: 6600 Train loss: 0.4106
en_zh Dev loss: 0.6935 r:0.4817
ro_en Dev loss: 0.3352 r:0.8135
Current avg r:0.6476 Best avg r: 0.6539
11:21:52,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:22:18,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:22:45,103 root INFO Epoch 2 Global steps: 6800 Train loss: 0.4380
en_zh Dev loss: 0.7051 r:0.4806
ro_en Dev loss: 0.3522 r:0.8126
Current avg r:0.6466 Best avg r: 0.6539
11:24:02,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:24:28,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:24:54,969 root INFO Epoch 2 Global steps: 7000 Train loss: 0.4392
en_zh Dev loss: 0.7453 r:0.4723
ro_en Dev loss: 0.3473 r:0.8131
Current avg r:0.6427 Best avg r: 0.6539
11:26:12,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:26:38,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:27:04,925 root INFO Epoch 2 Global steps: 7200 Train loss: 0.4250
en_zh Dev loss: 0.7022 r:0.4733
ro_en Dev loss: 0.3366 r:0.8173
Current avg r:0.6453 Best avg r: 0.6539
11:28:22,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:28:48,805 root INFO 
id:en_zh cur r: 0.4850 best r: 0.4850
11:29:14,989 root INFO 
id:ro_en cur r: 0.8201 best r: 0.8201
11:29:14,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:29:41,86 root INFO Epoch 2 Global steps: 7400 Train loss: 0.4110
en_zh Dev loss: 0.6474 r:0.4844
ro_en Dev loss: 0.2993 r:0.8201
Current avg r:0.6523 Best avg r: 0.6539
11:30:58,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:31:24,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:31:51,59 root INFO Epoch 2 Global steps: 7600 Train loss: 0.3954
en_zh Dev loss: 0.7158 r:0.4810
ro_en Dev loss: 0.3617 r:0.8095
Current avg r:0.6453 Best avg r: 0.6539
11:33:08,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:33:34,989 root INFO 
id:en_zh cur r: 0.4865 best r: 0.4865
11:34:01,149 root INFO 
id:ro_en cur r: 0.8202 best r: 0.8202
11:34:01,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:34:27,257 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:34:27,263 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
11:34:53,448 root INFO Epoch 2 Global steps: 7800 Train loss: 0.4089
en_zh Dev loss: 0.7649 r:0.4874
ro_en Dev loss: 0.3473 r:0.8207
Current avg r:0.6540 Best avg r: 0.6540
11:36:11,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:36:50,331 root INFO 
id:ro_en cur r: 0.8204 best r: 0.8204
11:36:50,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:37:16,450 root INFO Epoch 2 Global steps: 8000 Train loss: 0.4480
en_zh Dev loss: 0.7443 r:0.4827
ro_en Dev loss: 0.3225 r:0.8209
Current avg r:0.6518 Best avg r: 0.6540
11:38:34,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:39:00,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:39:26,526 root INFO Epoch 2 Global steps: 8200 Train loss: 0.4193
en_zh Dev loss: 0.6722 r:0.4853
ro_en Dev loss: 0.3293 r:0.8148
Current avg r:0.6501 Best avg r: 0.6540
11:40:44,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:41:10,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:41:36,828 root INFO Epoch 2 Global steps: 8400 Train loss: 0.4056
en_zh Dev loss: 0.6876 r:0.4863
ro_en Dev loss: 0.3621 r:0.8069
Current avg r:0.6466 Best avg r: 0.6540
11:42:54,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:43:20,851 root INFO 
id:en_zh cur r: 0.4944 best r: 0.4944
11:43:33,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:44:00,72 root INFO Epoch 2 Global steps: 8600 Train loss: 0.3839
en_zh Dev loss: 0.6991 r:0.4940
ro_en Dev loss: 0.3539 r:0.8133
Current avg r:0.6536 Best avg r: 0.6540
11:45:18,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:45:44,118 root INFO 
id:en_zh cur r: 0.4968 best r: 0.4968
11:45:57,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:46:23,352 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:46:23,358 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
11:46:49,584 root INFO Epoch 2 Global steps: 8800 Train loss: 0.3825
en_zh Dev loss: 0.6743 r:0.4965
ro_en Dev loss: 0.3227 r:0.8180
Current avg r:0.6573 Best avg r: 0.6573
11:48:07,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:48:33,640 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:48:59,771 root INFO Epoch 2 Global steps: 9000 Train loss: 0.3895
en_zh Dev loss: 0.7095 r:0.4854
ro_en Dev loss: 0.3320 r:0.8177
Current avg r:0.6515 Best avg r: 0.6573
11:50:18,120 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:50:44,267 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:51:10,417 root INFO Epoch 3 Global steps: 9200 Train loss: 0.3803
en_zh Dev loss: 0.6909 r:0.4939
ro_en Dev loss: 0.3448 r:0.8124
Current avg r:0.6531 Best avg r: 0.6573
11:52:28,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:52:54,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:53:20,589 root INFO Epoch 3 Global steps: 9400 Train loss: 0.3548
en_zh Dev loss: 0.7007 r:0.4895
ro_en Dev loss: 0.3610 r:0.8091
Current avg r:0.6493 Best avg r: 0.6573
11:54:38,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:55:04,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:55:30,710 root INFO Epoch 3 Global steps: 9600 Train loss: 0.3479
en_zh Dev loss: 0.7402 r:0.4807
ro_en Dev loss: 0.3746 r:0.8060
Current avg r:0.6434 Best avg r: 0.6573
11:56:48,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:57:14,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:57:40,929 root INFO Epoch 3 Global steps: 9800 Train loss: 0.3681
en_zh Dev loss: 0.6785 r:0.4963
ro_en Dev loss: 0.3266 r:0.8163
Current avg r:0.6563 Best avg r: 0.6573
11:58:58,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:59:25,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:59:51,211 root INFO Epoch 3 Global steps: 10000 Train loss: 0.3435
en_zh Dev loss: 0.7699 r:0.4903
ro_en Dev loss: 0.3732 r:0.8167
Current avg r:0.6535 Best avg r: 0.6573
12:01:09,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:01:35,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:02:01,676 root INFO Epoch 3 Global steps: 10200 Train loss: 0.3515
en_zh Dev loss: 0.7772 r:0.4720
ro_en Dev loss: 0.3243 r:0.8151
Current avg r:0.6435 Best avg r: 0.6573
12:03:19,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:03:45,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:04:11,847 root INFO Epoch 3 Global steps: 10400 Train loss: 0.3725
en_zh Dev loss: 0.7209 r:0.4804
ro_en Dev loss: 0.3254 r:0.8169
Current avg r:0.6487 Best avg r: 0.6573
12:05:29,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:05:55,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:06:21,996 root INFO Epoch 3 Global steps: 10600 Train loss: 0.3613
en_zh Dev loss: 0.7574 r:0.4846
ro_en Dev loss: 0.3401 r:0.8168
Current avg r:0.6507 Best avg r: 0.6573
12:07:40,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:08:06,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:08:32,264 root INFO Epoch 3 Global steps: 10800 Train loss: 0.3343
en_zh Dev loss: 0.7035 r:0.4879
ro_en Dev loss: 0.3230 r:0.8171
Current avg r:0.6525 Best avg r: 0.6573
12:09:50,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:10:16,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:10:42,563 root INFO Epoch 3 Global steps: 11000 Train loss: 0.3599
en_zh Dev loss: 0.7347 r:0.4767
ro_en Dev loss: 0.3485 r:0.8100
Current avg r:0.6434 Best avg r: 0.6573
12:12:00,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:12:26,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:12:52,997 root INFO Epoch 3 Global steps: 11200 Train loss: 0.3757
en_zh Dev loss: 0.7037 r:0.4936
ro_en Dev loss: 0.3380 r:0.8154
Current avg r:0.6545 Best avg r: 0.6573
12:14:11,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:14:37,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:15:03,304 root INFO Epoch 3 Global steps: 11400 Train loss: 0.3251
en_zh Dev loss: 0.6947 r:0.4857
ro_en Dev loss: 0.3332 r:0.8124
Current avg r:0.6491 Best avg r: 0.6573
12:16:21,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:16:47,234 root INFO 
id:en_zh cur r: 0.5005 best r: 0.5005
12:17:13,422 root INFO 
id:ro_en cur r: 0.8223 best r: 0.8223
12:17:13,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:17:39,549 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
12:17:39,555 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
12:18:05,812 root INFO Epoch 3 Global steps: 11600 Train loss: 0.3689
en_zh Dev loss: 0.6459 r:0.5024
ro_en Dev loss: 0.3018 r:0.8243
Current avg r:0.6633 Best avg r: 0.6633
12:19:23,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:19:49,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:20:15,960 root INFO Epoch 3 Global steps: 11800 Train loss: 0.3318
en_zh Dev loss: 0.7670 r:0.4856
ro_en Dev loss: 0.3626 r:0.8205
Current avg r:0.6530 Best avg r: 0.6633
12:21:33,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:21:59,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:22:26,149 root INFO Epoch 3 Global steps: 12000 Train loss: 0.3430
en_zh Dev loss: 0.6824 r:0.4821
ro_en Dev loss: 0.3278 r:0.8179
Current avg r:0.6500 Best avg r: 0.6633
12:23:44,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:24:10,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:24:36,873 root INFO Epoch 4 Global steps: 12200 Train loss: 0.3007
en_zh Dev loss: 0.7757 r:0.4874
ro_en Dev loss: 0.3943 r:0.8123
Current avg r:0.6499 Best avg r: 0.6633
12:25:54,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:26:21,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:26:47,264 root INFO Epoch 4 Global steps: 12400 Train loss: 0.3179
en_zh Dev loss: 0.7456 r:0.4901
ro_en Dev loss: 0.3324 r:0.8208
Current avg r:0.6555 Best avg r: 0.6633
12:28:05,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:28:31,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:28:57,480 root INFO Epoch 4 Global steps: 12600 Train loss: 0.2799
en_zh Dev loss: 0.7745 r:0.4716
ro_en Dev loss: 0.3585 r:0.8159
Current avg r:0.6438 Best avg r: 0.6633
12:30:15,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:30:41,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:31:07,520 root INFO Epoch 4 Global steps: 12800 Train loss: 0.3112
en_zh Dev loss: 0.7401 r:0.4863
ro_en Dev loss: 0.3584 r:0.8144
Current avg r:0.6503 Best avg r: 0.6633
12:32:25,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:32:51,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:33:17,680 root INFO Epoch 4 Global steps: 13000 Train loss: 0.3175
en_zh Dev loss: 0.7231 r:0.4910
ro_en Dev loss: 0.3711 r:0.8151
Current avg r:0.6531 Best avg r: 0.6633
12:34:35,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:35:01,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:35:27,807 root INFO Epoch 4 Global steps: 13200 Train loss: 0.2899
en_zh Dev loss: 0.7563 r:0.4779
ro_en Dev loss: 0.3634 r:0.8145
Current avg r:0.6462 Best avg r: 0.6633
12:36:45,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:37:11,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:37:37,857 root INFO Epoch 4 Global steps: 13400 Train loss: 0.2743
en_zh Dev loss: 0.7360 r:0.4897
ro_en Dev loss: 0.3568 r:0.8172
Current avg r:0.6534 Best avg r: 0.6633
12:38:55,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:39:21,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:39:47,859 root INFO Epoch 4 Global steps: 13600 Train loss: 0.3092
en_zh Dev loss: 0.7393 r:0.4838
ro_en Dev loss: 0.3505 r:0.8154
Current avg r:0.6496 Best avg r: 0.6633
12:41:05,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:41:31,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:41:57,909 root INFO Epoch 4 Global steps: 13800 Train loss: 0.2996
en_zh Dev loss: 0.7436 r:0.4868
ro_en Dev loss: 0.3668 r:0.8141
Current avg r:0.6505 Best avg r: 0.6633
12:43:15,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:43:41,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:44:07,968 root INFO Epoch 4 Global steps: 14000 Train loss: 0.2996
en_zh Dev loss: 0.7436 r:0.4862
ro_en Dev loss: 0.3426 r:0.8175
Current avg r:0.6518 Best avg r: 0.6633
12:45:25,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:45:51,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:46:17,941 root INFO Epoch 4 Global steps: 14200 Train loss: 0.2938
en_zh Dev loss: 0.7395 r:0.4836
ro_en Dev loss: 0.3485 r:0.8144
Current avg r:0.6490 Best avg r: 0.6633
12:47:35,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:48:01,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:48:27,940 root INFO Epoch 4 Global steps: 14400 Train loss: 0.2841
en_zh Dev loss: 0.7625 r:0.4805
ro_en Dev loss: 0.3759 r:0.8106
Current avg r:0.6455 Best avg r: 0.6633
12:49:45,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:50:11,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:50:37,899 root INFO Epoch 4 Global steps: 14600 Train loss: 0.3137
en_zh Dev loss: 0.7732 r:0.4790
ro_en Dev loss: 0.3631 r:0.8119
Current avg r:0.6455 Best avg r: 0.6633
12:51:55,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:52:21,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:52:47,868 root INFO Epoch 4 Global steps: 14800 Train loss: 0.2895
en_zh Dev loss: 0.7512 r:0.4818
ro_en Dev loss: 0.3767 r:0.8089
Current avg r:0.6453 Best avg r: 0.6633
12:54:05,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:54:31,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:54:57,983 root INFO Epoch 4 Global steps: 15000 Train loss: 0.2777
en_zh Dev loss: 0.8140 r:0.4779
ro_en Dev loss: 0.4016 r:0.8160
Current avg r:0.6470 Best avg r: 0.6633
12:56:16,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:56:42,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:57:08,222 root INFO Epoch 5 Global steps: 15200 Train loss: 0.2594
en_zh Dev loss: 0.7712 r:0.4750
ro_en Dev loss: 0.3742 r:0.8153
Current avg r:0.6452 Best avg r: 0.6633
12:58:25,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:58:52,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:59:18,256 root INFO Epoch 5 Global steps: 15400 Train loss: 0.2378
en_zh Dev loss: 0.8730 r:0.4595
ro_en Dev loss: 0.3838 r:0.8141
Current avg r:0.6368 Best avg r: 0.6633
13:00:36,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:01:02,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:01:28,391 root INFO Epoch 5 Global steps: 15600 Train loss: 0.2745
en_zh Dev loss: 0.7710 r:0.4743
ro_en Dev loss: 0.3402 r:0.8178
Current avg r:0.6461 Best avg r: 0.6633
13:02:46,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:03:12,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:03:38,316 root INFO Epoch 5 Global steps: 15800 Train loss: 0.2417
en_zh Dev loss: 0.7958 r:0.4675
ro_en Dev loss: 0.3425 r:0.8177
Current avg r:0.6426 Best avg r: 0.6633
13:04:56,36 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:05:22,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:05:48,246 root INFO Epoch 5 Global steps: 16000 Train loss: 0.2174
en_zh Dev loss: 0.7676 r:0.4769
ro_en Dev loss: 0.3764 r:0.8109
Current avg r:0.6439 Best avg r: 0.6633
13:07:06,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:07:32,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:07:58,407 root INFO Epoch 5 Global steps: 16200 Train loss: 0.2580
en_zh Dev loss: 0.8037 r:0.4754
ro_en Dev loss: 0.4095 r:0.8057
Current avg r:0.6406 Best avg r: 0.6633
13:09:16,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:09:42,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:10:08,547 root INFO Epoch 5 Global steps: 16400 Train loss: 0.2568
en_zh Dev loss: 0.7858 r:0.4678
ro_en Dev loss: 0.3591 r:0.8100
Current avg r:0.6389 Best avg r: 0.6633
13:11:26,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:11:52,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:12:18,774 root INFO Epoch 5 Global steps: 16600 Train loss: 0.2523
en_zh Dev loss: 0.7463 r:0.4810
ro_en Dev loss: 0.3461 r:0.8155
Current avg r:0.6483 Best avg r: 0.6633
13:13:36,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:14:02,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:14:28,623 root INFO Epoch 5 Global steps: 16800 Train loss: 0.2447
en_zh Dev loss: 0.7525 r:0.4770
ro_en Dev loss: 0.3561 r:0.8102
Current avg r:0.6436 Best avg r: 0.6633
13:15:46,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:16:12,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:16:38,390 root INFO Epoch 5 Global steps: 17000 Train loss: 0.2522
en_zh Dev loss: 0.8146 r:0.4684
ro_en Dev loss: 0.3579 r:0.8156
Current avg r:0.6420 Best avg r: 0.6633
13:17:55,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:18:22,56 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:18:48,164 root INFO Epoch 5 Global steps: 17200 Train loss: 0.2459
en_zh Dev loss: 0.7512 r:0.4837
ro_en Dev loss: 0.3698 r:0.8113
Current avg r:0.6475 Best avg r: 0.6633
13:20:05,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:20:31,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:20:57,979 root INFO Epoch 5 Global steps: 17400 Train loss: 0.2302
en_zh Dev loss: 0.7367 r:0.4875
ro_en Dev loss: 0.3431 r:0.8169
Current avg r:0.6522 Best avg r: 0.6633
13:22:15,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:22:41,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:23:07,734 root INFO Epoch 5 Global steps: 17600 Train loss: 0.2763
en_zh Dev loss: 0.8034 r:0.4745
ro_en Dev loss: 0.3662 r:0.8147
Current avg r:0.6446 Best avg r: 0.6633
13:24:25,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:24:51,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:25:17,484 root INFO Epoch 5 Global steps: 17800 Train loss: 0.2491
en_zh Dev loss: 0.7326 r:0.4893
ro_en Dev loss: 0.3515 r:0.8169
Current avg r:0.6531 Best avg r: 0.6633
13:26:35,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:27:01,138 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:27:27,266 root INFO Epoch 5 Global steps: 18000 Train loss: 0.2447
en_zh Dev loss: 0.7943 r:0.4821
ro_en Dev loss: 0.3692 r:0.8135
Current avg r:0.6478 Best avg r: 0.6633
13:28:45,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:29:11,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:29:37,548 root INFO Epoch 6 Global steps: 18200 Train loss: 0.2173
en_zh Dev loss: 0.7704 r:0.4862
ro_en Dev loss: 0.3544 r:0.8175
Current avg r:0.6519 Best avg r: 0.6633
13:30:55,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:31:21,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:31:47,280 root INFO Epoch 6 Global steps: 18400 Train loss: 0.2105
en_zh Dev loss: 0.7530 r:0.4920
ro_en Dev loss: 0.3555 r:0.8153
Current avg r:0.6536 Best avg r: 0.6633
13:33:04,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:33:30,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:33:56,855 root INFO Epoch 6 Global steps: 18600 Train loss: 0.2125
en_zh Dev loss: 0.7374 r:0.4935
ro_en Dev loss: 0.3461 r:0.8130
Current avg r:0.6533 Best avg r: 0.6633
13:35:14,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:35:40,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:36:07,59 root INFO Epoch 6 Global steps: 18800 Train loss: 0.2065
en_zh Dev loss: 0.7308 r:0.4905
ro_en Dev loss: 0.3436 r:0.8176
Current avg r:0.6541 Best avg r: 0.6633
13:37:24,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:37:51,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:38:17,196 root INFO Epoch 6 Global steps: 19000 Train loss: 0.2256
en_zh Dev loss: 0.7874 r:0.4768
ro_en Dev loss: 0.3617 r:0.8125
Current avg r:0.6446 Best avg r: 0.6633
13:39:35,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:40:01,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:40:27,428 root INFO Epoch 6 Global steps: 19200 Train loss: 0.2140
en_zh Dev loss: 0.7272 r:0.4916
ro_en Dev loss: 0.3252 r:0.8137
Current avg r:0.6527 Best avg r: 0.6633
13:41:45,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:42:11,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:42:37,536 root INFO Epoch 6 Global steps: 19400 Train loss: 0.2092
en_zh Dev loss: 0.7277 r:0.4969
ro_en Dev loss: 0.3453 r:0.8131
Current avg r:0.6550 Best avg r: 0.6633
13:43:55,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:44:21,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:44:47,624 root INFO Epoch 6 Global steps: 19600 Train loss: 0.2229
en_zh Dev loss: 0.7677 r:0.4924
ro_en Dev loss: 0.3752 r:0.8136
Current avg r:0.6530 Best avg r: 0.6633
13:46:05,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:46:31,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:46:57,765 root INFO Epoch 6 Global steps: 19800 Train loss: 0.1983
en_zh Dev loss: 0.7610 r:0.4915
ro_en Dev loss: 0.3504 r:0.8165
Current avg r:0.6540 Best avg r: 0.6633
13:48:15,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:48:41,772 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:49:07,899 root INFO Epoch 6 Global steps: 20000 Train loss: 0.2293
en_zh Dev loss: 0.8071 r:0.4897
ro_en Dev loss: 0.3789 r:0.8158
Current avg r:0.6528 Best avg r: 0.6633
13:50:25,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:50:51,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:51:18,36 root INFO Epoch 6 Global steps: 20200 Train loss: 0.1885
en_zh Dev loss: 0.8288 r:0.4827
ro_en Dev loss: 0.3928 r:0.8119
Current avg r:0.6473 Best avg r: 0.6633
13:52:35,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:53:02,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:53:28,198 root INFO Epoch 6 Global steps: 20400 Train loss: 0.2039
en_zh Dev loss: 0.7651 r:0.4885
ro_en Dev loss: 0.3491 r:0.8124
Current avg r:0.6505 Best avg r: 0.6633
13:54:46,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:55:12,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:55:38,317 root INFO Epoch 6 Global steps: 20600 Train loss: 0.2178
en_zh Dev loss: 0.7206 r:0.4910
ro_en Dev loss: 0.3211 r:0.8207
Current avg r:0.6559 Best avg r: 0.6633
13:56:56,104 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:57:22,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:57:48,366 root INFO Epoch 6 Global steps: 20800 Train loss: 0.2135
en_zh Dev loss: 0.7650 r:0.4892
ro_en Dev loss: 0.3665 r:0.8160
Current avg r:0.6526 Best avg r: 0.6633
13:59:06,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:59:32,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:59:58,425 root INFO Epoch 6 Global steps: 21000 Train loss: 0.2005
en_zh Dev loss: 0.7632 r:0.4908
ro_en Dev loss: 0.3600 r:0.8177
Current avg r:0.6543 Best avg r: 0.6633
14:01:16,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:01:42,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:02:09,5 root INFO Epoch 7 Global steps: 21200 Train loss: 0.1851
en_zh Dev loss: 0.7967 r:0.4780
ro_en Dev loss: 0.3650 r:0.8136
Current avg r:0.6458 Best avg r: 0.6633
14:03:26,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:03:53,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:04:19,210 root INFO Epoch 7 Global steps: 21400 Train loss: 0.1738
en_zh Dev loss: 0.8175 r:0.4873
ro_en Dev loss: 0.3920 r:0.8167
Current avg r:0.6520 Best avg r: 0.6633
14:05:37,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:06:03,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:06:29,343 root INFO Epoch 7 Global steps: 21600 Train loss: 0.1846
en_zh Dev loss: 0.7736 r:0.4866
ro_en Dev loss: 0.3506 r:0.8170
Current avg r:0.6518 Best avg r: 0.6633
14:07:47,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:08:13,270 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:08:39,384 root INFO Epoch 7 Global steps: 21800 Train loss: 0.1831
en_zh Dev loss: 0.8507 r:0.4740
ro_en Dev loss: 0.3790 r:0.8165
Current avg r:0.6452 Best avg r: 0.6633
14:09:57,242 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:10:23,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:10:49,462 root INFO Epoch 7 Global steps: 22000 Train loss: 0.1795
en_zh Dev loss: 0.8233 r:0.4781
ro_en Dev loss: 0.4419 r:0.8076
Current avg r:0.6429 Best avg r: 0.6633
14:12:07,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:12:33,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:12:59,431 root INFO Epoch 7 Global steps: 22200 Train loss: 0.1804
en_zh Dev loss: 0.7523 r:0.4920
ro_en Dev loss: 0.3628 r:0.8101
Current avg r:0.6511 Best avg r: 0.6633
14:14:17,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:14:43,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:15:09,497 root INFO Epoch 7 Global steps: 22400 Train loss: 0.1779
en_zh Dev loss: 0.7850 r:0.4795
ro_en Dev loss: 0.3671 r:0.8099
Current avg r:0.6447 Best avg r: 0.6633
14:16:27,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:16:53,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:17:19,678 root INFO Epoch 7 Global steps: 22600 Train loss: 0.1673
en_zh Dev loss: 0.7817 r:0.4860
ro_en Dev loss: 0.3993 r:0.8103
Current avg r:0.6482 Best avg r: 0.6633
14:18:37,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:19:03,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:19:29,671 root INFO Epoch 7 Global steps: 22800 Train loss: 0.1869
en_zh Dev loss: 0.7352 r:0.4867
ro_en Dev loss: 0.3350 r:0.8148
Current avg r:0.6507 Best avg r: 0.6633
14:20:47,486 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:21:13,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:21:39,708 root INFO Epoch 7 Global steps: 23000 Train loss: 0.1696
en_zh Dev loss: 0.8249 r:0.4771
ro_en Dev loss: 0.4208 r:0.8100
Current avg r:0.6436 Best avg r: 0.6633
14:22:57,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:23:23,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:23:49,759 root INFO Epoch 7 Global steps: 23200 Train loss: 0.1874
en_zh Dev loss: 0.7792 r:0.4901
ro_en Dev loss: 0.3722 r:0.8139
Current avg r:0.6520 Best avg r: 0.6633
14:25:07,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:25:33,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:25:59,823 root INFO Epoch 7 Global steps: 23400 Train loss: 0.1878
en_zh Dev loss: 0.7789 r:0.4811
ro_en Dev loss: 0.3824 r:0.8117
Current avg r:0.6464 Best avg r: 0.6633
14:27:17,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:27:43,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:28:10,108 root INFO Epoch 7 Global steps: 23600 Train loss: 0.1826
en_zh Dev loss: 0.7539 r:0.4816
ro_en Dev loss: 0.3545 r:0.8148
Current avg r:0.6482 Best avg r: 0.6633
14:29:28,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:29:54,138 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:30:20,249 root INFO Epoch 7 Global steps: 23800 Train loss: 0.1719
en_zh Dev loss: 0.7648 r:0.4704
ro_en Dev loss: 0.3391 r:0.8176
Current avg r:0.6440 Best avg r: 0.6633
14:31:38,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:32:04,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:32:30,386 root INFO Epoch 7 Global steps: 24000 Train loss: 0.1709
en_zh Dev loss: 0.7670 r:0.4849
ro_en Dev loss: 0.3646 r:0.8133
Current avg r:0.6491 Best avg r: 0.6633
14:33:48,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:34:14,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:34:40,871 root INFO Epoch 8 Global steps: 24200 Train loss: 0.1611
en_zh Dev loss: 0.7506 r:0.4890
ro_en Dev loss: 0.3746 r:0.8177
Current avg r:0.6533 Best avg r: 0.6633
14:35:58,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:36:24,808 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:36:50,958 root INFO Epoch 8 Global steps: 24400 Train loss: 0.1422
en_zh Dev loss: 0.8251 r:0.4731
ro_en Dev loss: 0.3543 r:0.8209
Current avg r:0.6470 Best avg r: 0.6633
14:38:08,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:38:35,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:01,138 root INFO Epoch 8 Global steps: 24600 Train loss: 0.1588
en_zh Dev loss: 0.8276 r:0.4812
ro_en Dev loss: 0.3980 r:0.8137
Current avg r:0.6474 Best avg r: 0.6633
14:40:19,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:40:45,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:41:11,382 root INFO Epoch 8 Global steps: 24800 Train loss: 0.1632
en_zh Dev loss: 0.8261 r:0.4791
ro_en Dev loss: 0.3865 r:0.8123
Current avg r:0.6457 Best avg r: 0.6633
14:42:29,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:55,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:21,512 root INFO Epoch 8 Global steps: 25000 Train loss: 0.1746
en_zh Dev loss: 0.7448 r:0.4831
ro_en Dev loss: 0.3281 r:0.8175
Current avg r:0.6503 Best avg r: 0.6633
14:44:39,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:05,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:31,694 root INFO Epoch 8 Global steps: 25200 Train loss: 0.1598
en_zh Dev loss: 0.7887 r:0.4798
ro_en Dev loss: 0.3363 r:0.8195
Current avg r:0.6497 Best avg r: 0.6633
14:46:49,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:47:15,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:41,880 root INFO Epoch 8 Global steps: 25400 Train loss: 0.1703
en_zh Dev loss: 0.7884 r:0.4795
ro_en Dev loss: 0.3694 r:0.8138
Current avg r:0.6466 Best avg r: 0.6633
14:48:59,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:25,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:52,21 root INFO Epoch 8 Global steps: 25600 Train loss: 0.1535
en_zh Dev loss: 0.8081 r:0.4852
ro_en Dev loss: 0.3986 r:0.8124
Current avg r:0.6488 Best avg r: 0.6633
14:51:09,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:35,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:02,84 root INFO Epoch 8 Global steps: 25800 Train loss: 0.1429
en_zh Dev loss: 0.8425 r:0.4831
ro_en Dev loss: 0.4006 r:0.8152
Current avg r:0.6491 Best avg r: 0.6633
14:53:19,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:46,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:12,162 root INFO Epoch 8 Global steps: 26000 Train loss: 0.1489
en_zh Dev loss: 0.7940 r:0.4749
ro_en Dev loss: 0.3612 r:0.8187
Current avg r:0.6468 Best avg r: 0.6633
14:55:30,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:56,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:56:22,281 root INFO Epoch 8 Global steps: 26200 Train loss: 0.1582
en_zh Dev loss: 0.8115 r:0.4728
ro_en Dev loss: 0.3538 r:0.8207
Current avg r:0.6467 Best avg r: 0.6633
14:57:40,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:06,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:32,363 root INFO Epoch 8 Global steps: 26400 Train loss: 0.1625
en_zh Dev loss: 0.8371 r:0.4700
ro_en Dev loss: 0.3776 r:0.8189
Current avg r:0.6444 Best avg r: 0.6633
14:59:50,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:16,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:42,381 root INFO Epoch 8 Global steps: 26600 Train loss: 0.1590
en_zh Dev loss: 0.8411 r:0.4728
ro_en Dev loss: 0.3839 r:0.8139
Current avg r:0.6433 Best avg r: 0.6633
15:02:00,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:26,346 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:52,466 root INFO Epoch 8 Global steps: 26800 Train loss: 0.1489
en_zh Dev loss: 0.7551 r:0.4833
ro_en Dev loss: 0.3373 r:0.8159
Current avg r:0.6496 Best avg r: 0.6633
15:04:10,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:36,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:02,521 root INFO Epoch 8 Global steps: 27000 Train loss: 0.1468
en_zh Dev loss: 0.8007 r:0.4829
ro_en Dev loss: 0.3847 r:0.8116
Current avg r:0.6473 Best avg r: 0.6633
15:06:20,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:06:46,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:12,980 root INFO Epoch 9 Global steps: 27200 Train loss: 0.1525
en_zh Dev loss: 0.8018 r:0.4765
ro_en Dev loss: 0.3768 r:0.8154
Current avg r:0.6459 Best avg r: 0.6633
15:08:30,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:56,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:23,14 root INFO Epoch 9 Global steps: 27400 Train loss: 0.1367
en_zh Dev loss: 0.7980 r:0.4812
ro_en Dev loss: 0.3586 r:0.8142
Current avg r:0.6477 Best avg r: 0.6633
15:10:40,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:07,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:33,149 root INFO Epoch 9 Global steps: 27600 Train loss: 0.1432
en_zh Dev loss: 0.7660 r:0.4884
ro_en Dev loss: 0.3576 r:0.8142
Current avg r:0.6513 Best avg r: 0.6633
15:12:51,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:17,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:43,252 root INFO Epoch 9 Global steps: 27800 Train loss: 0.1354
en_zh Dev loss: 0.7979 r:0.4842
ro_en Dev loss: 0.3797 r:0.8093
Current avg r:0.6468 Best avg r: 0.6633
15:15:01,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:27,250 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:15:53,385 root INFO Epoch 9 Global steps: 28000 Train loss: 0.1487
en_zh Dev loss: 0.7727 r:0.4808
ro_en Dev loss: 0.3566 r:0.8122
Current avg r:0.6465 Best avg r: 0.6633
15:17:11,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:37,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:03,402 root INFO Epoch 9 Global steps: 28200 Train loss: 0.1357
en_zh Dev loss: 0.7527 r:0.4827
ro_en Dev loss: 0.3355 r:0.8171
Current avg r:0.6499 Best avg r: 0.6633
15:19:21,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:47,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:13,422 root INFO Epoch 9 Global steps: 28400 Train loss: 0.1235
en_zh Dev loss: 0.8003 r:0.4874
ro_en Dev loss: 0.3564 r:0.8154
Current avg r:0.6514 Best avg r: 0.6633
15:21:31,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:21:57,346 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:23,442 root INFO Epoch 9 Global steps: 28600 Train loss: 0.1256
en_zh Dev loss: 0.7942 r:0.4944
ro_en Dev loss: 0.3662 r:0.8146
Current avg r:0.6545 Best avg r: 0.6633
15:23:41,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:07,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:33,404 root INFO Epoch 9 Global steps: 28800 Train loss: 0.1348
en_zh Dev loss: 0.8555 r:0.4850
ro_en Dev loss: 0.3863 r:0.8122
Current avg r:0.6486 Best avg r: 0.6633
15:25:51,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:17,414 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:43,525 root INFO Epoch 9 Global steps: 29000 Train loss: 0.1308
en_zh Dev loss: 0.7508 r:0.4872
ro_en Dev loss: 0.3696 r:0.8124
Current avg r:0.6498 Best avg r: 0.6633
15:28:01,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:28:27,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:53,698 root INFO Epoch 9 Global steps: 29200 Train loss: 0.1461
en_zh Dev loss: 0.7726 r:0.4850
ro_en Dev loss: 0.3755 r:0.8132
Current avg r:0.6491 Best avg r: 0.6633
15:30:11,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:37,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:03,677 root INFO Epoch 9 Global steps: 29400 Train loss: 0.1285
en_zh Dev loss: 0.8132 r:0.4823
ro_en Dev loss: 0.3802 r:0.8119
Current avg r:0.6471 Best avg r: 0.6633
15:32:21,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:47,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:13,719 root INFO Epoch 9 Global steps: 29600 Train loss: 0.1325
en_zh Dev loss: 0.8164 r:0.4859
ro_en Dev loss: 0.3994 r:0.8087
Current avg r:0.6473 Best avg r: 0.6633
15:34:31,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:57,665 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:23,789 root INFO Epoch 9 Global steps: 29800 Train loss: 0.1360
en_zh Dev loss: 0.7334 r:0.4921
ro_en Dev loss: 0.3431 r:0.8140
Current avg r:0.6531 Best avg r: 0.6633
15:36:41,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:07,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:37:33,905 root INFO Epoch 9 Global steps: 30000 Train loss: 0.1317
en_zh Dev loss: 0.7873 r:0.4849
ro_en Dev loss: 0.3710 r:0.8106
Current avg r:0.6477 Best avg r: 0.6633
15:38:52,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:18,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:44,480 root INFO Epoch 10 Global steps: 30200 Train loss: 0.1206
en_zh Dev loss: 0.7823 r:0.4875
ro_en Dev loss: 0.3791 r:0.8144
Current avg r:0.6509 Best avg r: 0.6633
15:41:02,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:28,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:54,576 root INFO Epoch 10 Global steps: 30400 Train loss: 0.1189
en_zh Dev loss: 0.7454 r:0.4916
ro_en Dev loss: 0.3628 r:0.8128
Current avg r:0.6522 Best avg r: 0.6633
15:43:12,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:38,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:04,737 root INFO Epoch 10 Global steps: 30600 Train loss: 0.1208
en_zh Dev loss: 0.8217 r:0.4810
ro_en Dev loss: 0.3881 r:0.8096
Current avg r:0.6453 Best avg r: 0.6633
15:45:22,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:45:48,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:14,870 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1130
en_zh Dev loss: 0.7999 r:0.4862
ro_en Dev loss: 0.3723 r:0.8153
Current avg r:0.6507 Best avg r: 0.6633
15:47:32,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:58,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:24,970 root INFO Epoch 10 Global steps: 31000 Train loss: 0.1278
en_zh Dev loss: 0.7613 r:0.4841
ro_en Dev loss: 0.3358 r:0.8204
Current avg r:0.6522 Best avg r: 0.6633
15:49:42,832 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:08,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:35,166 root INFO Epoch 10 Global steps: 31200 Train loss: 0.1263
en_zh Dev loss: 0.8394 r:0.4822
ro_en Dev loss: 0.4069 r:0.8119
Current avg r:0.6470 Best avg r: 0.6633
15:51:53,6 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:19,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:45,241 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1229
en_zh Dev loss: 0.7537 r:0.4946
ro_en Dev loss: 0.3401 r:0.8202
Current avg r:0.6574 Best avg r: 0.6633
15:54:03,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:29,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:55,307 root INFO Epoch 10 Global steps: 31600 Train loss: 0.1158
en_zh Dev loss: 0.7886 r:0.4900
ro_en Dev loss: 0.3794 r:0.8169
Current avg r:0.6534 Best avg r: 0.6633
15:56:13,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:39,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:05,367 root INFO Epoch 10 Global steps: 31800 Train loss: 0.1128
en_zh Dev loss: 0.8505 r:0.4756
ro_en Dev loss: 0.3956 r:0.8122
Current avg r:0.6439 Best avg r: 0.6633
15:58:23,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:49,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:15,377 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1195
en_zh Dev loss: 0.8085 r:0.4885
ro_en Dev loss: 0.3752 r:0.8180
Current avg r:0.6533 Best avg r: 0.6633
16:00:33,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:59,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:25,369 root INFO Epoch 10 Global steps: 32200 Train loss: 0.1076
en_zh Dev loss: 0.7473 r:0.4943
ro_en Dev loss: 0.3486 r:0.8183
Current avg r:0.6563 Best avg r: 0.6633
16:02:43,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:09,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:35,374 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1113
en_zh Dev loss: 0.8417 r:0.4776
ro_en Dev loss: 0.3966 r:0.8136
Current avg r:0.6456 Best avg r: 0.6633
16:04:53,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:19,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:45,411 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1131
en_zh Dev loss: 0.7649 r:0.4894
ro_en Dev loss: 0.3585 r:0.8161
Current avg r:0.6527 Best avg r: 0.6633
16:07:03,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:29,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:55,438 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1152
en_zh Dev loss: 0.8640 r:0.4864
ro_en Dev loss: 0.4202 r:0.8121
Current avg r:0.6493 Best avg r: 0.6633
16:09:13,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:39,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:05,490 root INFO Epoch 10 Global steps: 33000 Train loss: 0.1204
en_zh Dev loss: 0.8103 r:0.4947
ro_en Dev loss: 0.3950 r:0.8120
Current avg r:0.6534 Best avg r: 0.6633
16:11:23,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:49,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:16,37 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1094
en_zh Dev loss: 0.8009 r:0.4918
ro_en Dev loss: 0.3753 r:0.8154
Current avg r:0.6536 Best avg r: 0.6633
16:13:33,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:59,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:26,69 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1073
en_zh Dev loss: 0.7888 r:0.4934
ro_en Dev loss: 0.3705 r:0.8138
Current avg r:0.6536 Best avg r: 0.6633
16:15:43,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:09,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:36,80 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1056
en_zh Dev loss: 0.7524 r:0.4949
ro_en Dev loss: 0.3394 r:0.8185
Current avg r:0.6567 Best avg r: 0.6633
16:17:53,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:20,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:46,136 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1085
en_zh Dev loss: 0.8134 r:0.4904
ro_en Dev loss: 0.3714 r:0.8149
Current avg r:0.6527 Best avg r: 0.6633
16:20:03,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:30,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:56,240 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1019
en_zh Dev loss: 0.8247 r:0.4873
ro_en Dev loss: 0.3930 r:0.8148
Current avg r:0.6511 Best avg r: 0.6633
16:22:14,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:40,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:06,348 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1006
en_zh Dev loss: 0.7349 r:0.4937
ro_en Dev loss: 0.3319 r:0.8186
Current avg r:0.6561 Best avg r: 0.6633
16:24:24,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:50,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:16,478 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1135
en_zh Dev loss: 0.7386 r:0.4959
ro_en Dev loss: 0.3432 r:0.8192
Current avg r:0.6575 Best avg r: 0.6633
16:26:34,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:00,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:26,516 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1036
en_zh Dev loss: 0.7816 r:0.4898
ro_en Dev loss: 0.3769 r:0.8109
Current avg r:0.6504 Best avg r: 0.6633
16:28:44,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:10,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:36,557 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1046
en_zh Dev loss: 0.7584 r:0.4958
ro_en Dev loss: 0.3617 r:0.8155
Current avg r:0.6556 Best avg r: 0.6633
16:30:54,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:20,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:46,580 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1027
en_zh Dev loss: 0.8390 r:0.4944
ro_en Dev loss: 0.4090 r:0.8137
Current avg r:0.6541 Best avg r: 0.6633
16:33:04,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:30,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:56,626 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1058
en_zh Dev loss: 0.7501 r:0.4951
ro_en Dev loss: 0.3541 r:0.8178
Current avg r:0.6565 Best avg r: 0.6633
16:35:14,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:40,651 root INFO 
id:en_zh cur r: 0.5048 best r: 0.5048
16:35:53,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:19,895 root INFO Epoch 11 Global steps: 35400 Train loss: 0.0980
en_zh Dev loss: 0.7293 r:0.5032
ro_en Dev loss: 0.3391 r:0.8164
Current avg r:0.6598 Best avg r: 0.6633
16:37:37,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:03,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:30,27 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1127
en_zh Dev loss: 0.7768 r:0.4986
ro_en Dev loss: 0.3659 r:0.8157
Current avg r:0.6571 Best avg r: 0.6633
16:39:47,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:14,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:40,188 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1030
en_zh Dev loss: 0.8656 r:0.4906
ro_en Dev loss: 0.3871 r:0.8144
Current avg r:0.6525 Best avg r: 0.6633
16:41:58,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:24,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:50,355 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1018
en_zh Dev loss: 0.7424 r:0.4957
ro_en Dev loss: 0.3317 r:0.8177
Current avg r:0.6567 Best avg r: 0.6633
16:44:08,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:34,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:00,873 root INFO Epoch 12 Global steps: 36200 Train loss: 0.0945
en_zh Dev loss: 0.7591 r:0.4966
ro_en Dev loss: 0.3385 r:0.8188
Current avg r:0.6577 Best avg r: 0.6633
16:46:18,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:44,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:11,48 root INFO Epoch 12 Global steps: 36400 Train loss: 0.0964
en_zh Dev loss: 0.8255 r:0.4936
ro_en Dev loss: 0.3964 r:0.8127
Current avg r:0.6531 Best avg r: 0.6633
16:48:28,818 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:54,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:21,76 root INFO Epoch 12 Global steps: 36600 Train loss: 0.0967
en_zh Dev loss: 0.7443 r:0.5019
ro_en Dev loss: 0.3711 r:0.8135
Current avg r:0.6577 Best avg r: 0.6633
16:50:38,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:04,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:31,86 root INFO Epoch 12 Global steps: 36800 Train loss: 0.0955
en_zh Dev loss: 0.7548 r:0.4910
ro_en Dev loss: 0.3433 r:0.8187
Current avg r:0.6548 Best avg r: 0.6633
16:52:48,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:15,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:41,176 root INFO Epoch 12 Global steps: 37000 Train loss: 0.0939
en_zh Dev loss: 0.7657 r:0.4923
ro_en Dev loss: 0.3575 r:0.8148
Current avg r:0.6536 Best avg r: 0.6633
16:54:58,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:25,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:51,274 root INFO Epoch 12 Global steps: 37200 Train loss: 0.0962
en_zh Dev loss: 0.8053 r:0.4922
ro_en Dev loss: 0.3748 r:0.8155
Current avg r:0.6538 Best avg r: 0.6633
16:57:09,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:35,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:01,355 root INFO Epoch 12 Global steps: 37400 Train loss: 0.0957
en_zh Dev loss: 0.7604 r:0.4936
ro_en Dev loss: 0.3716 r:0.8136
Current avg r:0.6536 Best avg r: 0.6633
16:59:19,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:45,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:11,460 root INFO Epoch 12 Global steps: 37600 Train loss: 0.0996
en_zh Dev loss: 0.7822 r:0.4988
ro_en Dev loss: 0.3844 r:0.8168
Current avg r:0.6578 Best avg r: 0.6633
17:01:29,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:55,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:21,529 root INFO Epoch 12 Global steps: 37800 Train loss: 0.0890
en_zh Dev loss: 0.7638 r:0.4957
ro_en Dev loss: 0.3807 r:0.8155
Current avg r:0.6556 Best avg r: 0.6633
17:03:39,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:05,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:31,609 root INFO Epoch 12 Global steps: 38000 Train loss: 0.0912
en_zh Dev loss: 0.7444 r:0.4975
ro_en Dev loss: 0.3418 r:0.8215
Current avg r:0.6595 Best avg r: 0.6633
17:05:49,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:15,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:41,618 root INFO Epoch 12 Global steps: 38200 Train loss: 0.0982
en_zh Dev loss: 0.7943 r:0.4958
ro_en Dev loss: 0.3555 r:0.8217
Current avg r:0.6587 Best avg r: 0.6633
17:07:59,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:25,449 root INFO 
id:en_zh cur r: 0.5065 best r: 0.5065
17:08:38,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:04,636 root INFO Epoch 12 Global steps: 38400 Train loss: 0.0935
en_zh Dev loss: 0.8076 r:0.5029
ro_en Dev loss: 0.3737 r:0.8215
Current avg r:0.6622 Best avg r: 0.6633
17:10:22,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:48,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:14,582 root INFO Epoch 12 Global steps: 38600 Train loss: 0.0969
en_zh Dev loss: 0.8185 r:0.4970
ro_en Dev loss: 0.3894 r:0.8155
Current avg r:0.6562 Best avg r: 0.6633
17:12:32,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:58,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:24,561 root INFO Epoch 12 Global steps: 38800 Train loss: 0.0970
en_zh Dev loss: 0.7793 r:0.4977
ro_en Dev loss: 0.3737 r:0.8186
Current avg r:0.6582 Best avg r: 0.6633
17:14:42,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:08,546 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:34,677 root INFO Epoch 12 Global steps: 39000 Train loss: 0.0958
en_zh Dev loss: 0.7750 r:0.5018
ro_en Dev loss: 0.3758 r:0.8206
Current avg r:0.6612 Best avg r: 0.6633
17:16:52,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:19,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:45,210 root INFO Epoch 13 Global steps: 39200 Train loss: 0.0801
en_zh Dev loss: 0.7988 r:0.5034
ro_en Dev loss: 0.4116 r:0.8162
Current avg r:0.6598 Best avg r: 0.6633
17:19:02,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:28,958 root INFO 
id:en_zh cur r: 0.5111 best r: 0.5111
17:19:42,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:08,131 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:20:08,136 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:20:34,286 root INFO Epoch 13 Global steps: 39400 Train loss: 0.0842
en_zh Dev loss: 0.7494 r:0.5102
ro_en Dev loss: 0.3683 r:0.8194
Current avg r:0.6648 Best avg r: 0.6648
17:21:52,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:18,145 root INFO 
id:en_zh cur r: 0.5161 best r: 0.5161
17:22:31,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:57,306 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:22:57,313 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:23:23,486 root INFO Epoch 13 Global steps: 39600 Train loss: 0.0842
en_zh Dev loss: 0.7573 r:0.5148
ro_en Dev loss: 0.3652 r:0.8202
Current avg r:0.6675 Best avg r: 0.6675
17:24:41,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:07,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:33,339 root INFO Epoch 13 Global steps: 39800 Train loss: 0.0836
en_zh Dev loss: 0.7138 r:0.5087
ro_en Dev loss: 0.3378 r:0.8207
Current avg r:0.6647 Best avg r: 0.6675
17:26:51,77 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:17,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:43,313 root INFO Epoch 13 Global steps: 40000 Train loss: 0.0842
en_zh Dev loss: 0.7623 r:0.5022
ro_en Dev loss: 0.3723 r:0.8201
Current avg r:0.6611 Best avg r: 0.6675
17:29:01,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:27,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:53,262 root INFO Epoch 13 Global steps: 40200 Train loss: 0.0905
en_zh Dev loss: 0.7457 r:0.5018
ro_en Dev loss: 0.3640 r:0.8201
Current avg r:0.6609 Best avg r: 0.6675
17:31:10,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:37,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:03,177 root INFO Epoch 13 Global steps: 40400 Train loss: 0.0814
en_zh Dev loss: 0.7639 r:0.5050
ro_en Dev loss: 0.3899 r:0.8160
Current avg r:0.6605 Best avg r: 0.6675
17:33:20,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:47,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:13,201 root INFO Epoch 13 Global steps: 40600 Train loss: 0.0834
en_zh Dev loss: 0.7994 r:0.4984
ro_en Dev loss: 0.3842 r:0.8184
Current avg r:0.6584 Best avg r: 0.6675
17:35:31,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:57,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:23,226 root INFO Epoch 13 Global steps: 40800 Train loss: 0.0759
en_zh Dev loss: 0.7743 r:0.4981
ro_en Dev loss: 0.3687 r:0.8191
Current avg r:0.6586 Best avg r: 0.6675
17:37:40,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:07,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:33,197 root INFO Epoch 13 Global steps: 41000 Train loss: 0.0815
en_zh Dev loss: 0.7410 r:0.5052
ro_en Dev loss: 0.3520 r:0.8209
Current avg r:0.6630 Best avg r: 0.6675
17:39:50,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:17,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:43,211 root INFO Epoch 13 Global steps: 41200 Train loss: 0.0877
en_zh Dev loss: 0.7816 r:0.5005
ro_en Dev loss: 0.3684 r:0.8167
Current avg r:0.6586 Best avg r: 0.6675
17:42:01,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:27,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:53,223 root INFO Epoch 13 Global steps: 41400 Train loss: 0.0809
en_zh Dev loss: 0.7688 r:0.4998
ro_en Dev loss: 0.3610 r:0.8181
Current avg r:0.6589 Best avg r: 0.6675
17:44:11,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:37,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:03,287 root INFO Epoch 13 Global steps: 41600 Train loss: 0.0861
en_zh Dev loss: 0.7258 r:0.4992
ro_en Dev loss: 0.3552 r:0.8149
Current avg r:0.6570 Best avg r: 0.6675
17:46:21,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:47,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:13,373 root INFO Epoch 13 Global steps: 41800 Train loss: 0.0817
en_zh Dev loss: 0.7491 r:0.5020
ro_en Dev loss: 0.3386 r:0.8202
Current avg r:0.6611 Best avg r: 0.6675
17:48:31,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:57,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:23,434 root INFO Epoch 13 Global steps: 42000 Train loss: 0.0853
en_zh Dev loss: 0.7573 r:0.5010
ro_en Dev loss: 0.3771 r:0.8183
Current avg r:0.6596 Best avg r: 0.6675
17:50:41,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:07,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:33,769 root INFO Epoch 14 Global steps: 42200 Train loss: 0.0784
en_zh Dev loss: 0.8395 r:0.4943
ro_en Dev loss: 0.4000 r:0.8164
Current avg r:0.6553 Best avg r: 0.6675
17:52:51,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:17,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:43,710 root INFO Epoch 14 Global steps: 42400 Train loss: 0.0737
en_zh Dev loss: 0.8123 r:0.4918
ro_en Dev loss: 0.3917 r:0.8155
Current avg r:0.6536 Best avg r: 0.6675
17:55:01,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:27,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:53,759 root INFO Epoch 14 Global steps: 42600 Train loss: 0.0757
en_zh Dev loss: 0.7640 r:0.4979
ro_en Dev loss: 0.3499 r:0.8176
Current avg r:0.6578 Best avg r: 0.6675
17:57:11,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:37,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:03,779 root INFO Epoch 14 Global steps: 42800 Train loss: 0.0755
en_zh Dev loss: 0.7881 r:0.5000
ro_en Dev loss: 0.3576 r:0.8210
Current avg r:0.6605 Best avg r: 0.6675
17:59:21,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:47,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:13,766 root INFO Epoch 14 Global steps: 43000 Train loss: 0.0732
en_zh Dev loss: 0.8137 r:0.4932
ro_en Dev loss: 0.3703 r:0.8187
Current avg r:0.6559 Best avg r: 0.6675
18:01:31,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:57,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:23,753 root INFO Epoch 14 Global steps: 43200 Train loss: 0.0788
en_zh Dev loss: 0.7671 r:0.5012
ro_en Dev loss: 0.3657 r:0.8195
Current avg r:0.6604 Best avg r: 0.6675
18:03:41,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:07,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:33,780 root INFO Epoch 14 Global steps: 43400 Train loss: 0.0740
en_zh Dev loss: 0.7787 r:0.4965
ro_en Dev loss: 0.3747 r:0.8172
Current avg r:0.6569 Best avg r: 0.6675
18:05:51,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:17,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:43,807 root INFO Epoch 14 Global steps: 43600 Train loss: 0.0801
en_zh Dev loss: 0.7478 r:0.4956
ro_en Dev loss: 0.3541 r:0.8177
Current avg r:0.6567 Best avg r: 0.6675
18:08:01,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:27,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:53,824 root INFO Epoch 14 Global steps: 43800 Train loss: 0.0796
en_zh Dev loss: 0.7526 r:0.4984
ro_en Dev loss: 0.3596 r:0.8208
Current avg r:0.6596 Best avg r: 0.6675
18:10:11,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:37,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:03,873 root INFO Epoch 14 Global steps: 44000 Train loss: 0.0766
en_zh Dev loss: 0.8620 r:0.4918
ro_en Dev loss: 0.4007 r:0.8188
Current avg r:0.6553 Best avg r: 0.6675
18:12:21,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:47,765 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:13,882 root INFO Epoch 14 Global steps: 44200 Train loss: 0.0721
en_zh Dev loss: 0.7534 r:0.5002
ro_en Dev loss: 0.3662 r:0.8156
Current avg r:0.6579 Best avg r: 0.6675
18:14:31,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:57,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:23,941 root INFO Epoch 14 Global steps: 44400 Train loss: 0.0763
en_zh Dev loss: 0.7645 r:0.5054
ro_en Dev loss: 0.3564 r:0.8206
Current avg r:0.6630 Best avg r: 0.6675
18:16:41,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:07,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:34,25 root INFO Epoch 14 Global steps: 44600 Train loss: 0.0796
en_zh Dev loss: 0.7956 r:0.4966
ro_en Dev loss: 0.3615 r:0.8158
Current avg r:0.6562 Best avg r: 0.6675
18:18:51,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:17,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:44,65 root INFO Epoch 14 Global steps: 44800 Train loss: 0.0715
en_zh Dev loss: 0.7647 r:0.5010
ro_en Dev loss: 0.3526 r:0.8160
Current avg r:0.6585 Best avg r: 0.6675
18:21:01,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:27,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:54,15 root INFO Epoch 14 Global steps: 45000 Train loss: 0.0710
en_zh Dev loss: 0.8208 r:0.4960
ro_en Dev loss: 0.3983 r:0.8129
Current avg r:0.6544 Best avg r: 0.6675
18:23:12,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:38,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:04,553 root INFO Epoch 15 Global steps: 45200 Train loss: 0.0674
en_zh Dev loss: 0.7856 r:0.5039
ro_en Dev loss: 0.3744 r:0.8148
Current avg r:0.6594 Best avg r: 0.6675
18:25:22,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:48,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:14,713 root INFO Epoch 15 Global steps: 45400 Train loss: 0.0740
en_zh Dev loss: 0.7523 r:0.5091
ro_en Dev loss: 0.3476 r:0.8194
Current avg r:0.6642 Best avg r: 0.6675
18:27:32,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:58,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:24,804 root INFO Epoch 15 Global steps: 45600 Train loss: 0.0722
en_zh Dev loss: 0.7688 r:0.5086
ro_en Dev loss: 0.3607 r:0.8157
Current avg r:0.6622 Best avg r: 0.6675
18:29:42,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:08,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:34,841 root INFO Epoch 15 Global steps: 45800 Train loss: 0.0727
en_zh Dev loss: 0.8079 r:0.5004
ro_en Dev loss: 0.3697 r:0.8163
Current avg r:0.6584 Best avg r: 0.6675
18:31:52,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:18,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:45,71 root INFO Epoch 15 Global steps: 46000 Train loss: 0.0622
en_zh Dev loss: 0.7594 r:0.5062
ro_en Dev loss: 0.3589 r:0.8184
Current avg r:0.6623 Best avg r: 0.6675
18:34:02,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:29,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:55,168 root INFO Epoch 15 Global steps: 46200 Train loss: 0.0715
en_zh Dev loss: 0.7953 r:0.5037
ro_en Dev loss: 0.3500 r:0.8198
Current avg r:0.6617 Best avg r: 0.6675
18:36:12,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:39,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:05,191 root INFO Epoch 15 Global steps: 46400 Train loss: 0.0665
en_zh Dev loss: 0.7861 r:0.5105
ro_en Dev loss: 0.3824 r:0.8188
Current avg r:0.6647 Best avg r: 0.6675
18:38:22,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:49,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:39:15,229 root INFO Epoch 15 Global steps: 46600 Train loss: 0.0746
en_zh Dev loss: 0.7498 r:0.5074
ro_en Dev loss: 0.3499 r:0.8197
Current avg r:0.6636 Best avg r: 0.6675
18:40:33,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:59,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:25,264 root INFO Epoch 15 Global steps: 46800 Train loss: 0.0691
en_zh Dev loss: 0.7969 r:0.5020
ro_en Dev loss: 0.3802 r:0.8175
Current avg r:0.6598 Best avg r: 0.6675
18:42:43,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:09,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:35,270 root INFO Epoch 15 Global steps: 47000 Train loss: 0.0670
en_zh Dev loss: 0.7714 r:0.5090
ro_en Dev loss: 0.3613 r:0.8188
Current avg r:0.6639 Best avg r: 0.6675
18:44:53,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:19,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:45,308 root INFO Epoch 15 Global steps: 47200 Train loss: 0.0681
en_zh Dev loss: 0.7618 r:0.5115
ro_en Dev loss: 0.3386 r:0.8203
Current avg r:0.6659 Best avg r: 0.6675
18:47:03,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:29,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:55,296 root INFO Epoch 15 Global steps: 47400 Train loss: 0.0725
en_zh Dev loss: 0.7809 r:0.5063
ro_en Dev loss: 0.3547 r:0.8188
Current avg r:0.6625 Best avg r: 0.6675
18:49:13,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:39,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:05,315 root INFO Epoch 15 Global steps: 47600 Train loss: 0.0687
en_zh Dev loss: 0.7556 r:0.5075
ro_en Dev loss: 0.3771 r:0.8195
Current avg r:0.6635 Best avg r: 0.6675
18:51:23,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:49,286 root INFO 
id:en_zh cur r: 0.5175 best r: 0.5175
18:52:02,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:28,504 root INFO Epoch 15 Global steps: 47800 Train loss: 0.0709
en_zh Dev loss: 0.7034 r:0.5141
ro_en Dev loss: 0.3297 r:0.8202
Current avg r:0.6672 Best avg r: 0.6675
18:53:46,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:12,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:38,500 root INFO Epoch 15 Global steps: 48000 Train loss: 0.0660
en_zh Dev loss: 0.7885 r:0.5140
ro_en Dev loss: 0.3976 r:0.8147
Current avg r:0.6644 Best avg r: 0.6675
18:55:56,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:22,924 root INFO 
id:en_zh cur r: 0.5225 best r: 0.5225
18:56:36,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:02,121 root INFO Epoch 16 Global steps: 48200 Train loss: 0.0610
en_zh Dev loss: 0.7510 r:0.5192
ro_en Dev loss: 0.3777 r:0.8141
Current avg r:0.6666 Best avg r: 0.6675
18:58:19,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:46,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:12,165 root INFO Epoch 16 Global steps: 48400 Train loss: 0.0639
en_zh Dev loss: 0.7454 r:0.5119
ro_en Dev loss: 0.3538 r:0.8184
Current avg r:0.6652 Best avg r: 0.6675
19:00:29,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:56,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:22,169 root INFO Epoch 16 Global steps: 48600 Train loss: 0.0635
en_zh Dev loss: 0.7414 r:0.5135
ro_en Dev loss: 0.3452 r:0.8181
Current avg r:0.6658 Best avg r: 0.6675
19:02:39,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:06,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:32,177 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
19:03:32,193 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
19:03:58,378 root INFO Epoch 16 Global steps: 48800 Train loss: 0.0646
en_zh Dev loss: 0.7247 r:0.5147
ro_en Dev loss: 0.3291 r:0.8208
Current avg r:0.6678 Best avg r: 0.6678
19:05:16,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:42,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:08,351 root INFO Epoch 16 Global steps: 49000 Train loss: 0.0639
en_zh Dev loss: 0.8280 r:0.5112
ro_en Dev loss: 0.4122 r:0.8146
Current avg r:0.6629 Best avg r: 0.6678
19:07:26,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:52,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:18,416 root INFO Epoch 16 Global steps: 49200 Train loss: 0.0661
en_zh Dev loss: 0.7823 r:0.5132
ro_en Dev loss: 0.3731 r:0.8162
Current avg r:0.6647 Best avg r: 0.6678
19:09:36,219 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:02,328 root INFO 
id:en_zh cur r: 0.5232 best r: 0.5232
19:10:15,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:41,506 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
19:10:41,512 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
19:11:07,760 root INFO Epoch 16 Global steps: 49400 Train loss: 0.0583
en_zh Dev loss: 0.7328 r:0.5220
ro_en Dev loss: 0.3590 r:0.8201
Current avg r:0.6710 Best avg r: 0.6710
19:12:25,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:51,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:17,788 root INFO Epoch 16 Global steps: 49600 Train loss: 0.0661
en_zh Dev loss: 0.7653 r:0.5160
ro_en Dev loss: 0.3778 r:0.8170
Current avg r:0.6665 Best avg r: 0.6710
19:14:35,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:01,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:27,757 root INFO Epoch 16 Global steps: 49800 Train loss: 0.0626
en_zh Dev loss: 0.7786 r:0.5136
ro_en Dev loss: 0.3731 r:0.8176
Current avg r:0.6656 Best avg r: 0.6710
19:16:45,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:11,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:37,573 root INFO Epoch 16 Global steps: 50000 Train loss: 0.0623
en_zh Dev loss: 0.7859 r:0.5139
ro_en Dev loss: 0.3620 r:0.8207
Current avg r:0.6673 Best avg r: 0.6710
19:18:55,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:21,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:47,587 root INFO Epoch 16 Global steps: 50200 Train loss: 0.0608
en_zh Dev loss: 0.7997 r:0.5063
ro_en Dev loss: 0.3804 r:0.8173
Current avg r:0.6618 Best avg r: 0.6710
19:21:05,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:31,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:57,580 root INFO Epoch 16 Global steps: 50400 Train loss: 0.0644
en_zh Dev loss: 0.7498 r:0.5102
ro_en Dev loss: 0.3591 r:0.8214
Current avg r:0.6658 Best avg r: 0.6710
19:23:15,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:41,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:07,631 root INFO Epoch 16 Global steps: 50600 Train loss: 0.0650
en_zh Dev loss: 0.7789 r:0.5063
ro_en Dev loss: 0.3605 r:0.8193
Current avg r:0.6628 Best avg r: 0.6710
19:25:25,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:51,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:17,655 root INFO Epoch 16 Global steps: 50800 Train loss: 0.0660
en_zh Dev loss: 0.7932 r:0.5029
ro_en Dev loss: 0.3721 r:0.8170
Current avg r:0.6600 Best avg r: 0.6710
19:27:35,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:01,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:27,660 root INFO Epoch 16 Global steps: 51000 Train loss: 0.0653
en_zh Dev loss: 0.7383 r:0.5050
ro_en Dev loss: 0.3496 r:0.8201
Current avg r:0.6626 Best avg r: 0.6710
19:29:45,683 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:11,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:37,930 root INFO Epoch 17 Global steps: 51200 Train loss: 0.0587
en_zh Dev loss: 0.7471 r:0.5072
ro_en Dev loss: 0.3436 r:0.8195
Current avg r:0.6634 Best avg r: 0.6710
19:31:55,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:21,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:47,884 root INFO Epoch 17 Global steps: 51400 Train loss: 0.0612
en_zh Dev loss: 0.6954 r:0.5173
ro_en Dev loss: 0.3316 r:0.8211
Current avg r:0.6692 Best avg r: 0.6710
19:34:05,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:31,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:57,876 root INFO Epoch 17 Global steps: 51600 Train loss: 0.0574
en_zh Dev loss: 0.7270 r:0.5169
ro_en Dev loss: 0.3727 r:0.8214
Current avg r:0.6691 Best avg r: 0.6710
19:36:15,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:41,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:07,902 root INFO Epoch 17 Global steps: 51800 Train loss: 0.0608
en_zh Dev loss: 0.8012 r:0.5093
ro_en Dev loss: 0.3922 r:0.8185
Current avg r:0.6639 Best avg r: 0.6710
19:38:25,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:51,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:39:18,25 root INFO Epoch 17 Global steps: 52000 Train loss: 0.0602
en_zh Dev loss: 0.7881 r:0.5096
ro_en Dev loss: 0.3700 r:0.8219
Current avg r:0.6657 Best avg r: 0.6710
19:40:35,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:02,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:28,168 root INFO Epoch 17 Global steps: 52200 Train loss: 0.0576
en_zh Dev loss: 0.7354 r:0.5112
ro_en Dev loss: 0.3560 r:0.8216
Current avg r:0.6664 Best avg r: 0.6710
19:42:46,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:12,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:38,332 root INFO Epoch 17 Global steps: 52400 Train loss: 0.0592
en_zh Dev loss: 0.7429 r:0.5106
ro_en Dev loss: 0.3498 r:0.8196
Current avg r:0.6651 Best avg r: 0.6710
19:44:56,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:22,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:48,454 root INFO Epoch 17 Global steps: 52600 Train loss: 0.0621
en_zh Dev loss: 0.8029 r:0.5081
ro_en Dev loss: 0.4076 r:0.8172
Current avg r:0.6626 Best avg r: 0.6710
19:47:06,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:32,402 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:58,508 root INFO Epoch 17 Global steps: 52800 Train loss: 0.0627
en_zh Dev loss: 0.7400 r:0.5138
ro_en Dev loss: 0.3707 r:0.8189
Current avg r:0.6664 Best avg r: 0.6710
19:49:16,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:42,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:08,504 root INFO Epoch 17 Global steps: 53000 Train loss: 0.0627
en_zh Dev loss: 0.7493 r:0.5009
ro_en Dev loss: 0.3473 r:0.8182
Current avg r:0.6595 Best avg r: 0.6710
19:51:26,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:52,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:18,462 root INFO Epoch 17 Global steps: 53200 Train loss: 0.0552
en_zh Dev loss: 0.7973 r:0.5021
ro_en Dev loss: 0.3549 r:0.8215
Current avg r:0.6618 Best avg r: 0.6710
19:53:36,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:02,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:28,552 root INFO Epoch 17 Global steps: 53400 Train loss: 0.0593
en_zh Dev loss: 0.7434 r:0.5101
ro_en Dev loss: 0.3414 r:0.8228
Current avg r:0.6665 Best avg r: 0.6710
19:55:46,398 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:12,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:38,670 root INFO Epoch 17 Global steps: 53600 Train loss: 0.0599
en_zh Dev loss: 0.7629 r:0.5046
ro_en Dev loss: 0.3423 r:0.8224
Current avg r:0.6635 Best avg r: 0.6710
19:57:56,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:22,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:48,712 root INFO Epoch 17 Global steps: 53800 Train loss: 0.0622
en_zh Dev loss: 0.7823 r:0.5053
ro_en Dev loss: 0.3784 r:0.8196
Current avg r:0.6625 Best avg r: 0.6710
20:00:06,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:32,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:58,701 root INFO Epoch 17 Global steps: 54000 Train loss: 0.0595
en_zh Dev loss: 0.7883 r:0.5069
ro_en Dev loss: 0.3678 r:0.8190
Current avg r:0.6629 Best avg r: 0.6710
20:02:16,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:42,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:08,868 root INFO Epoch 18 Global steps: 54200 Train loss: 0.0597
en_zh Dev loss: 0.7595 r:0.5081
ro_en Dev loss: 0.3749 r:0.8201
Current avg r:0.6641 Best avg r: 0.6710
20:04:26,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:52,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:18,820 root INFO Epoch 18 Global steps: 54400 Train loss: 0.0538
en_zh Dev loss: 0.7714 r:0.5040
ro_en Dev loss: 0.3772 r:0.8195
Current avg r:0.6617 Best avg r: 0.6710
20:06:36,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:07:02,749 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:28,873 root INFO Epoch 18 Global steps: 54600 Train loss: 0.0561
en_zh Dev loss: 0.7409 r:0.5103
ro_en Dev loss: 0.3680 r:0.8180
Current avg r:0.6642 Best avg r: 0.6710
20:08:46,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:12,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:38,892 root INFO Epoch 18 Global steps: 54800 Train loss: 0.0521
en_zh Dev loss: 0.7480 r:0.5124
ro_en Dev loss: 0.3439 r:0.8220
Current avg r:0.6672 Best avg r: 0.6710
20:10:56,707 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:22,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:48,969 root INFO Epoch 18 Global steps: 55000 Train loss: 0.0567
en_zh Dev loss: 0.7022 r:0.5173
ro_en Dev loss: 0.3312 r:0.8221
Current avg r:0.6697 Best avg r: 0.6710
20:13:06,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:32,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:59,15 root INFO Epoch 18 Global steps: 55200 Train loss: 0.0573
en_zh Dev loss: 0.7698 r:0.5110
ro_en Dev loss: 0.3557 r:0.8234
Current avg r:0.6672 Best avg r: 0.6710
20:15:16,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:42,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:08,958 root INFO Epoch 18 Global steps: 55400 Train loss: 0.0589
en_zh Dev loss: 0.7706 r:0.4972
ro_en Dev loss: 0.3587 r:0.8173
Current avg r:0.6573 Best avg r: 0.6710
20:17:26,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:52,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:18,950 root INFO Epoch 18 Global steps: 55600 Train loss: 0.0525
en_zh Dev loss: 0.7614 r:0.4998
ro_en Dev loss: 0.3666 r:0.8187
Current avg r:0.6592 Best avg r: 0.6710
20:19:36,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:02,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:28,940 root INFO Epoch 18 Global steps: 55800 Train loss: 0.0504
en_zh Dev loss: 0.7811 r:0.5057
ro_en Dev loss: 0.3837 r:0.8209
Current avg r:0.6633 Best avg r: 0.6710
20:21:46,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:22:12,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:38,837 root INFO Epoch 18 Global steps: 56000 Train loss: 0.0555
en_zh Dev loss: 0.7482 r:0.5128
ro_en Dev loss: 0.3573 r:0.8216
Current avg r:0.6672 Best avg r: 0.6710
20:23:56,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:22,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:48,881 root INFO Epoch 18 Global steps: 56200 Train loss: 0.0570
en_zh Dev loss: 0.7234 r:0.5112
ro_en Dev loss: 0.3565 r:0.8170
Current avg r:0.6641 Best avg r: 0.6710
20:26:06,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:26:32,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:58,923 root INFO Epoch 18 Global steps: 56400 Train loss: 0.0592
en_zh Dev loss: 0.7708 r:0.5143
ro_en Dev loss: 0.3778 r:0.8197
Current avg r:0.6670 Best avg r: 0.6710
20:28:16,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:42,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:08,974 root INFO Epoch 18 Global steps: 56600 Train loss: 0.0511
en_zh Dev loss: 0.7710 r:0.5058
ro_en Dev loss: 0.3660 r:0.8172
Current avg r:0.6615 Best avg r: 0.6710
20:30:26,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:52,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:18,930 root INFO Epoch 18 Global steps: 56800 Train loss: 0.0510
en_zh Dev loss: 0.8135 r:0.5068
ro_en Dev loss: 0.3874 r:0.8170
Current avg r:0.6619 Best avg r: 0.6710
20:32:36,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:33:02,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:28,839 root INFO Epoch 18 Global steps: 57000 Train loss: 0.0554
en_zh Dev loss: 0.7334 r:0.5176
ro_en Dev loss: 0.3441 r:0.8228
Current avg r:0.6702 Best avg r: 0.6710
20:34:46,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:13,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:39,176 root INFO Epoch 19 Global steps: 57200 Train loss: 0.0551
en_zh Dev loss: 0.7203 r:0.5163
ro_en Dev loss: 0.3399 r:0.8227
Current avg r:0.6695 Best avg r: 0.6710
20:36:56,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:22,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:49,76 root INFO Epoch 19 Global steps: 57400 Train loss: 0.0495
en_zh Dev loss: 0.7763 r:0.5083
ro_en Dev loss: 0.3929 r:0.8190
Current avg r:0.6637 Best avg r: 0.6710
20:39:06,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:32,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:58,993 root INFO Epoch 19 Global steps: 57600 Train loss: 0.0517
en_zh Dev loss: 0.7976 r:0.5022
ro_en Dev loss: 0.3650 r:0.8204
Current avg r:0.6613 Best avg r: 0.6710
20:41:16,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:42,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:08,913 root INFO Epoch 19 Global steps: 57800 Train loss: 0.0505
en_zh Dev loss: 0.7822 r:0.5059
ro_en Dev loss: 0.3686 r:0.8204
Current avg r:0.6631 Best avg r: 0.6710
20:43:26,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:52,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:18,850 root INFO Epoch 19 Global steps: 58000 Train loss: 0.0511
en_zh Dev loss: 0.7555 r:0.5118
ro_en Dev loss: 0.3438 r:0.8237
Current avg r:0.6678 Best avg r: 0.6710
20:45:36,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:15,783 root INFO 
id:ro_en cur r: 0.8262 best r: 0.8262
20:46:15,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:41,903 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/en_zh.lang_agnost_mlp.dev.best.scores
20:46:41,909 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run1/ro_en.lang_agnost_mlp.dev.best.scores
20:47:08,118 root INFO Epoch 19 Global steps: 58200 Train loss: 0.0502
en_zh Dev loss: 0.7046 r:0.5153
ro_en Dev loss: 0.3127 r:0.8279
Current avg r:0.6716 Best avg r: 0.6716
20:48:25,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:51,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:18,41 root INFO Epoch 19 Global steps: 58400 Train loss: 0.0554
en_zh Dev loss: 0.7712 r:0.5147
ro_en Dev loss: 0.3828 r:0.8199
Current avg r:0.6673 Best avg r: 0.6716
20:50:35,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:01,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:27,965 root INFO Epoch 19 Global steps: 58600 Train loss: 0.0517
en_zh Dev loss: 0.7291 r:0.5190
ro_en Dev loss: 0.3331 r:0.8235
Current avg r:0.6713 Best avg r: 0.6716
20:52:45,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:11,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:37,979 root INFO Epoch 19 Global steps: 58800 Train loss: 0.0489
en_zh Dev loss: 0.7492 r:0.5155
ro_en Dev loss: 0.3556 r:0.8217
Current avg r:0.6686 Best avg r: 0.6716
20:54:55,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:21,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:47,866 root INFO Epoch 19 Global steps: 59000 Train loss: 0.0524
en_zh Dev loss: 0.7789 r:0.5140
ro_en Dev loss: 0.3629 r:0.8214
Current avg r:0.6677 Best avg r: 0.6716
20:57:05,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:31,880 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:57:58,34 root INFO Epoch 19 Global steps: 59200 Train loss: 0.0518
en_zh Dev loss: 0.7897 r:0.5147
ro_en Dev loss: 0.3722 r:0.8209
Current avg r:0.6678 Best avg r: 0.6716
20:59:15,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:42,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:08,170 root INFO Epoch 19 Global steps: 59400 Train loss: 0.0553
en_zh Dev loss: 0.7749 r:0.5163
ro_en Dev loss: 0.3472 r:0.8239
Current avg r:0.6701 Best avg r: 0.6716
21:01:25,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:52,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:18,219 root INFO Epoch 19 Global steps: 59600 Train loss: 0.0561
en_zh Dev loss: 0.7613 r:0.5165
ro_en Dev loss: 0.3685 r:0.8191
Current avg r:0.6678 Best avg r: 0.6716
21:03:35,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:02,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:28,236 root INFO Epoch 19 Global steps: 59800 Train loss: 0.0519
en_zh Dev loss: 0.7989 r:0.5104
ro_en Dev loss: 0.3833 r:0.8191
Current avg r:0.6648 Best avg r: 0.6716
21:05:46,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:12,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:38,368 root INFO Epoch 19 Global steps: 60000 Train loss: 0.0530
en_zh Dev loss: 0.7356 r:0.5115
ro_en Dev loss: 0.3708 r:0.8205
Current avg r:0.6660 Best avg r: 0.6716
