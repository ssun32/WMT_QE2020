14:42:29,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:55,105 root INFO 
id:en_zh cur r: 0.0834 best r: 0.0834
14:43:20,885 root INFO 
id:ro_en cur r: 0.1800 best r: 0.1800
14:43:20,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:46,598 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:43:46,604 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:44:12,315 root INFO Epoch 0 Global steps: 200 Train loss: 0.9331
en_zh Dev loss: 0.8172 r:0.0505
ro_en Dev loss: 0.8495 r:0.3156
Current avg r:0.1830 Best avg r: 0.1830
14:45:28,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:54,381 root INFO 
id:en_zh cur r: 0.1413 best r: 0.1413
14:46:20,135 root INFO 
id:ro_en cur r: 0.3892 best r: 0.3892
14:46:20,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:45,825 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:46:45,831 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:47:11,548 root INFO Epoch 0 Global steps: 400 Train loss: 0.9273
en_zh Dev loss: 0.8173 r:0.1258
ro_en Dev loss: 0.8303 r:0.4766
Current avg r:0.3012 Best avg r: 0.3012
14:48:28,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:53,765 root INFO 
id:en_zh cur r: 0.1855 best r: 0.1855
14:49:19,514 root INFO 
id:ro_en cur r: 0.4612 best r: 0.4612
14:49:19,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:45,215 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:49:45,220 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:50:10,933 root INFO Epoch 0 Global steps: 600 Train loss: 0.8822
en_zh Dev loss: 0.8032 r:0.2230
ro_en Dev loss: 0.8105 r:0.5027
Current avg r:0.3629 Best avg r: 0.3629
14:51:27,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:53,204 root INFO 
id:en_zh cur r: 0.2304 best r: 0.2304
14:52:18,961 root INFO 
id:ro_en cur r: 0.5948 best r: 0.5948
14:52:18,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:44,660 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:52:44,667 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:53:10,374 root INFO Epoch 0 Global steps: 800 Train loss: 0.9062
en_zh Dev loss: 0.8028 r:0.2533
ro_en Dev loss: 0.8099 r:0.6138
Current avg r:0.4335 Best avg r: 0.4335
14:54:27,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:52,686 root INFO 
id:en_zh cur r: 0.2825 best r: 0.2825
14:55:18,453 root INFO 
id:ro_en cur r: 0.6230 best r: 0.6230
14:55:18,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:44,145 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:55:44,151 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:56:09,880 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8501
en_zh Dev loss: 0.7673 r:0.3049
ro_en Dev loss: 0.7281 r:0.6371
Current avg r:0.4710 Best avg r: 0.4710
14:57:26,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:04,939 root INFO 
id:ro_en cur r: 0.6468 best r: 0.6468
14:58:04,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:30,642 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:58:30,648 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:58:56,352 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7989
en_zh Dev loss: 0.7983 r:0.3187
ro_en Dev loss: 0.7316 r:0.6324
Current avg r:0.4755 Best avg r: 0.4755
15:00:12,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:38,576 root INFO 
id:en_zh cur r: 0.3405 best r: 0.3405
15:01:04,335 root INFO 
id:ro_en cur r: 0.6826 best r: 0.6826
15:01:04,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:01:30,19 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:01:30,27 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:01:55,739 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7721
en_zh Dev loss: 0.7352 r:0.3460
ro_en Dev loss: 0.6125 r:0.6839
Current avg r:0.5149 Best avg r: 0.5149
15:03:12,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:37,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:03,695 root INFO Epoch 0 Global steps: 1600 Train loss: 0.6786
en_zh Dev loss: 0.8441 r:0.3209
ro_en Dev loss: 0.6654 r:0.6646
Current avg r:0.4927 Best avg r: 0.5149
15:05:20,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:45,862 root INFO 
id:en_zh cur r: 0.3744 best r: 0.3744
15:06:11,618 root INFO 
id:ro_en cur r: 0.7108 best r: 0.7108
15:06:11,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:37,323 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:06:37,330 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:07:03,42 root INFO Epoch 0 Global steps: 1800 Train loss: 0.6744
en_zh Dev loss: 0.7258 r:0.3665
ro_en Dev loss: 0.4677 r:0.7068
Current avg r:0.5367 Best avg r: 0.5367
15:08:19,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:58,199 root INFO 
id:ro_en cur r: 0.7190 best r: 0.7190
15:08:58,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:23,891 root INFO Epoch 0 Global steps: 2000 Train loss: 0.6792
en_zh Dev loss: 0.7777 r:0.3478
ro_en Dev loss: 0.5047 r:0.7110
Current avg r:0.5294 Best avg r: 0.5367
15:10:40,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:19,180 root INFO 
id:ro_en cur r: 0.7320 best r: 0.7320
15:11:19,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:44,883 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:11:44,888 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:12:10,622 root INFO Epoch 0 Global steps: 2200 Train loss: 0.6283
en_zh Dev loss: 0.7696 r:0.3618
ro_en Dev loss: 0.4665 r:0.7310
Current avg r:0.5464 Best avg r: 0.5464
15:13:27,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:52,922 root INFO 
id:en_zh cur r: 0.3985 best r: 0.3985
15:14:18,698 root INFO 
id:ro_en cur r: 0.7365 best r: 0.7365
15:14:18,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:44,422 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:14:44,436 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:15:10,164 root INFO Epoch 0 Global steps: 2400 Train loss: 0.5858
en_zh Dev loss: 0.7165 r:0.3913
ro_en Dev loss: 0.4452 r:0.7313
Current avg r:0.5613 Best avg r: 0.5613
15:16:26,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:52,546 root INFO 
id:en_zh cur r: 0.4299 best r: 0.4299
15:17:18,313 root INFO 
id:ro_en cur r: 0.7541 best r: 0.7541
15:17:18,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:44,29 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:17:44,36 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:18:09,771 root INFO Epoch 0 Global steps: 2600 Train loss: 0.5925
en_zh Dev loss: 0.6833 r:0.4248
ro_en Dev loss: 0.3853 r:0.7521
Current avg r:0.5885 Best avg r: 0.5885
15:19:26,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:04,873 root INFO 
id:ro_en cur r: 0.7585 best r: 0.7585
15:20:04,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:30,525 root INFO Epoch 0 Global steps: 2800 Train loss: 0.5810
en_zh Dev loss: 0.8633 r:0.3786
ro_en Dev loss: 0.4950 r:0.7552
Current avg r:0.5669 Best avg r: 0.5885
15:21:47,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:25,620 root INFO 
id:ro_en cur r: 0.7722 best r: 0.7722
15:22:25,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:51,330 root INFO Epoch 0 Global steps: 3000 Train loss: 0.5027
en_zh Dev loss: 0.7754 r:0.3908
ro_en Dev loss: 0.4382 r:0.7696
Current avg r:0.5802 Best avg r: 0.5885
15:24:08,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:46,794 root INFO 
id:ro_en cur r: 0.7843 best r: 0.7843
15:24:46,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:12,496 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:25:12,501 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:25:38,214 root INFO Epoch 1 Global steps: 3200 Train loss: 0.5016
en_zh Dev loss: 0.7485 r:0.4037
ro_en Dev loss: 0.4008 r:0.7781
Current avg r:0.5909 Best avg r: 0.5909
15:26:54,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:33,423 root INFO 
id:ro_en cur r: 0.7868 best r: 0.7868
15:27:33,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:59,124 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:27:59,131 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:28:24,844 root INFO Epoch 1 Global steps: 3400 Train loss: 0.5004
en_zh Dev loss: 0.7974 r:0.4108
ro_en Dev loss: 0.3994 r:0.7822
Current avg r:0.5965 Best avg r: 0.5965
15:29:41,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:07,107 root INFO 
id:en_zh cur r: 0.4521 best r: 0.4521
15:30:32,864 root INFO 
id:ro_en cur r: 0.8001 best r: 0.8001
15:30:32,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:58,557 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:30:58,562 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:31:24,264 root INFO Epoch 1 Global steps: 3600 Train loss: 0.4955
en_zh Dev loss: 0.7142 r:0.4440
ro_en Dev loss: 0.3352 r:0.7966
Current avg r:0.6203 Best avg r: 0.6203
15:32:40,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:06,449 root INFO 
id:en_zh cur r: 0.4671 best r: 0.4671
15:33:32,203 root INFO 
id:ro_en cur r: 0.8037 best r: 0.8037
15:33:32,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:57,897 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:33:57,904 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:34:23,618 root INFO Epoch 1 Global steps: 3800 Train loss: 0.4448
en_zh Dev loss: 0.6736 r:0.4596
ro_en Dev loss: 0.3367 r:0.8008
Current avg r:0.6302 Best avg r: 0.6302
15:35:40,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:18,739 root INFO 
id:ro_en cur r: 0.8066 best r: 0.8066
15:36:18,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:44,437 root INFO Epoch 1 Global steps: 4000 Train loss: 0.4888
en_zh Dev loss: 0.7197 r:0.4458
ro_en Dev loss: 0.3277 r:0.8066
Current avg r:0.6262 Best avg r: 0.6302
15:38:00,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:39,521 root INFO 
id:ro_en cur r: 0.8099 best r: 0.8099
15:38:39,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:05,220 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:39:05,225 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:39:30,936 root INFO Epoch 1 Global steps: 4200 Train loss: 0.4422
en_zh Dev loss: 0.6754 r:0.4622
ro_en Dev loss: 0.3052 r:0.8093
Current avg r:0.6358 Best avg r: 0.6358
15:40:47,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:13,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:38,714 root INFO Epoch 1 Global steps: 4400 Train loss: 0.4785
en_zh Dev loss: 0.7474 r:0.4557
ro_en Dev loss: 0.3698 r:0.8034
Current avg r:0.6296 Best avg r: 0.6358
15:42:55,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:33,733 root INFO 
id:ro_en cur r: 0.8108 best r: 0.8108
15:43:33,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:59,427 root INFO Epoch 1 Global steps: 4600 Train loss: 0.4830
en_zh Dev loss: 0.6804 r:0.4510
ro_en Dev loss: 0.3133 r:0.8093
Current avg r:0.6301 Best avg r: 0.6358
15:45:15,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:45:41,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:07,350 root INFO Epoch 1 Global steps: 4800 Train loss: 0.4532
en_zh Dev loss: 0.7613 r:0.4241
ro_en Dev loss: 0.3589 r:0.8099
Current avg r:0.6170 Best avg r: 0.6358
15:47:23,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:02,422 root INFO 
id:ro_en cur r: 0.8200 best r: 0.8200
15:48:02,422 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:28,116 root INFO Epoch 1 Global steps: 5000 Train loss: 0.4511
en_zh Dev loss: 0.7035 r:0.4512
ro_en Dev loss: 0.3071 r:0.8183
Current avg r:0.6348 Best avg r: 0.6358
15:49:44,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:10,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:35,909 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:50:35,915 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:51:01,623 root INFO Epoch 1 Global steps: 5200 Train loss: 0.4644
en_zh Dev loss: 0.7111 r:0.4635
ro_en Dev loss: 0.3308 r:0.8185
Current avg r:0.6410 Best avg r: 0.6410
15:52:18,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:43,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:09,511 root INFO Epoch 1 Global steps: 5400 Train loss: 0.4702
en_zh Dev loss: 0.6711 r:0.4597
ro_en Dev loss: 0.3169 r:0.8159
Current avg r:0.6378 Best avg r: 0.6410
15:54:26,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:51,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:17,433 root INFO Epoch 1 Global steps: 5600 Train loss: 0.4623
en_zh Dev loss: 0.7698 r:0.4336
ro_en Dev loss: 0.3929 r:0.8109
Current avg r:0.6222 Best avg r: 0.6410
15:56:33,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:12,527 root INFO 
id:ro_en cur r: 0.8202 best r: 0.8202
15:57:12,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:38,222 root INFO Epoch 1 Global steps: 5800 Train loss: 0.4132
en_zh Dev loss: 0.7526 r:0.4451
ro_en Dev loss: 0.3385 r:0.8181
Current avg r:0.6316 Best avg r: 0.6410
15:58:54,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:33,324 root INFO 
id:ro_en cur r: 0.8260 best r: 0.8260
15:59:33,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:59,16 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:59:59,22 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:00:24,751 root INFO Epoch 1 Global steps: 6000 Train loss: 0.4518
en_zh Dev loss: 0.6759 r:0.4631
ro_en Dev loss: 0.3266 r:0.8239
Current avg r:0.6435 Best avg r: 0.6435
16:01:41,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:02:07,362 root INFO 
id:en_zh cur r: 0.4718 best r: 0.4718
16:02:33,120 root INFO 
id:ro_en cur r: 0.8265 best r: 0.8265
16:02:33,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:58,814 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:02:58,820 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:03:24,523 root INFO Epoch 2 Global steps: 6200 Train loss: 0.3857
en_zh Dev loss: 0.7124 r:0.4707
ro_en Dev loss: 0.3473 r:0.8262
Current avg r:0.6485 Best avg r: 0.6485
16:04:41,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:06,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:32,401 root INFO Epoch 2 Global steps: 6400 Train loss: 0.4169
en_zh Dev loss: 0.6716 r:0.4648
ro_en Dev loss: 0.3258 r:0.8252
Current avg r:0.6450 Best avg r: 0.6485
16:06:48,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:14,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:40,295 root INFO Epoch 2 Global steps: 6600 Train loss: 0.4054
en_zh Dev loss: 0.7269 r:0.4509
ro_en Dev loss: 0.3345 r:0.8235
Current avg r:0.6372 Best avg r: 0.6485
16:08:56,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:22,512 root INFO 
id:en_zh cur r: 0.4725 best r: 0.4725
16:09:35,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:01,78 root INFO Epoch 2 Global steps: 6800 Train loss: 0.4063
en_zh Dev loss: 0.6935 r:0.4688
ro_en Dev loss: 0.3363 r:0.8226
Current avg r:0.6457 Best avg r: 0.6485
16:11:17,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:43,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:09,8 root INFO Epoch 2 Global steps: 7000 Train loss: 0.3722
en_zh Dev loss: 0.7136 r:0.4600
ro_en Dev loss: 0.3281 r:0.8192
Current avg r:0.6396 Best avg r: 0.6485
16:13:25,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:51,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:16,847 root INFO Epoch 2 Global steps: 7200 Train loss: 0.4021
en_zh Dev loss: 0.8428 r:0.4426
ro_en Dev loss: 0.3535 r:0.8208
Current avg r:0.6317 Best avg r: 0.6485
16:15:33,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:59,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:24,801 root INFO Epoch 2 Global steps: 7400 Train loss: 0.4124
en_zh Dev loss: 0.7743 r:0.4606
ro_en Dev loss: 0.3768 r:0.8149
Current avg r:0.6377 Best avg r: 0.6485
16:17:41,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:07,6 root INFO 
id:en_zh cur r: 0.4836 best r: 0.4836
16:18:19,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:45,561 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:18:45,567 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:19:11,270 root INFO Epoch 2 Global steps: 7600 Train loss: 0.4154
en_zh Dev loss: 0.6603 r:0.4868
ro_en Dev loss: 0.3096 r:0.8246
Current avg r:0.6557 Best avg r: 0.6557
16:20:27,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:53,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:19,137 root INFO Epoch 2 Global steps: 7800 Train loss: 0.3787
en_zh Dev loss: 0.7764 r:0.4645
ro_en Dev loss: 0.3660 r:0.8193
Current avg r:0.6419 Best avg r: 0.6557
16:22:35,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:01,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:27,19 root INFO Epoch 2 Global steps: 8000 Train loss: 0.3773
en_zh Dev loss: 0.6916 r:0.4776
ro_en Dev loss: 0.3296 r:0.8250
Current avg r:0.6513 Best avg r: 0.6557
16:24:43,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:09,226 root INFO 
id:en_zh cur r: 0.4955 best r: 0.4955
16:25:34,990 root INFO 
id:ro_en cur r: 0.8285 best r: 0.8285
16:25:34,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:00,684 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:26:00,691 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:26:26,413 root INFO Epoch 2 Global steps: 8200 Train loss: 0.3972
en_zh Dev loss: 0.6584 r:0.4957
ro_en Dev loss: 0.3045 r:0.8277
Current avg r:0.6617 Best avg r: 0.6617
16:27:42,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:21,486 root INFO 
id:ro_en cur r: 0.8303 best r: 0.8303
16:28:21,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:47,186 root INFO Epoch 2 Global steps: 8400 Train loss: 0.3694
en_zh Dev loss: 0.6635 r:0.4932
ro_en Dev loss: 0.2968 r:0.8295
Current avg r:0.6614 Best avg r: 0.6617
16:30:03,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:29,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:55,54 root INFO Epoch 2 Global steps: 8600 Train loss: 0.3905
en_zh Dev loss: 0.7346 r:0.4705
ro_en Dev loss: 0.3113 r:0.8254
Current avg r:0.6480 Best avg r: 0.6617
16:32:11,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:37,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:02,934 root INFO Epoch 2 Global steps: 8800 Train loss: 0.3572
en_zh Dev loss: 0.7891 r:0.4558
ro_en Dev loss: 0.4055 r:0.8182
Current avg r:0.6370 Best avg r: 0.6617
16:34:19,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:45,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:10,948 root INFO Epoch 2 Global steps: 9000 Train loss: 0.3492
en_zh Dev loss: 0.7373 r:0.4690
ro_en Dev loss: 0.3523 r:0.8203
Current avg r:0.6446 Best avg r: 0.6617
16:36:27,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:53,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:19,364 root INFO Epoch 3 Global steps: 9200 Train loss: 0.3117
en_zh Dev loss: 0.7785 r:0.4626
ro_en Dev loss: 0.3504 r:0.8228
Current avg r:0.6427 Best avg r: 0.6617
16:38:35,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:01,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:27,269 root INFO Epoch 3 Global steps: 9400 Train loss: 0.3470
en_zh Dev loss: 0.7750 r:0.4545
ro_en Dev loss: 0.3477 r:0.8190
Current avg r:0.6368 Best avg r: 0.6617
16:40:43,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:09,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:35,300 root INFO Epoch 3 Global steps: 9600 Train loss: 0.2982
en_zh Dev loss: 0.7971 r:0.4734
ro_en Dev loss: 0.3819 r:0.8206
Current avg r:0.6470 Best avg r: 0.6617
16:42:51,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:17,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:43,322 root INFO Epoch 3 Global steps: 9800 Train loss: 0.3040
en_zh Dev loss: 0.6881 r:0.4862
ro_en Dev loss: 0.3163 r:0.8258
Current avg r:0.6560 Best avg r: 0.6617
16:44:59,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:25,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:51,344 root INFO Epoch 3 Global steps: 10000 Train loss: 0.3598
en_zh Dev loss: 0.8358 r:0.4697
ro_en Dev loss: 0.3767 r:0.8216
Current avg r:0.6457 Best avg r: 0.6617
16:47:07,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:33,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:59,228 root INFO Epoch 3 Global steps: 10200 Train loss: 0.3130
en_zh Dev loss: 0.7033 r:0.4809
ro_en Dev loss: 0.3336 r:0.8248
Current avg r:0.6529 Best avg r: 0.6617
16:49:15,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:41,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:07,96 root INFO Epoch 3 Global steps: 10400 Train loss: 0.3143
en_zh Dev loss: 0.7222 r:0.4841
ro_en Dev loss: 0.3304 r:0.8258
Current avg r:0.6549 Best avg r: 0.6617
16:51:23,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:49,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:15,68 root INFO Epoch 3 Global steps: 10600 Train loss: 0.3147
en_zh Dev loss: 0.6952 r:0.4849
ro_en Dev loss: 0.3376 r:0.8254
Current avg r:0.6551 Best avg r: 0.6617
16:53:31,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:57,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:22,977 root INFO Epoch 3 Global steps: 10800 Train loss: 0.3094
en_zh Dev loss: 0.6729 r:0.4867
ro_en Dev loss: 0.3189 r:0.8260
Current avg r:0.6564 Best avg r: 0.6617
16:55:39,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:05,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:30,820 root INFO Epoch 3 Global steps: 11000 Train loss: 0.3099
en_zh Dev loss: 0.7393 r:0.4553
ro_en Dev loss: 0.3479 r:0.8190
Current avg r:0.6372 Best avg r: 0.6617
16:57:47,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:13,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:38,812 root INFO Epoch 3 Global steps: 11200 Train loss: 0.3119
en_zh Dev loss: 0.6713 r:0.4880
ro_en Dev loss: 0.3014 r:0.8269
Current avg r:0.6574 Best avg r: 0.6617
16:59:55,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:21,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:46,855 root INFO Epoch 3 Global steps: 11400 Train loss: 0.3265
en_zh Dev loss: 0.6830 r:0.4933
ro_en Dev loss: 0.3180 r:0.8240
Current avg r:0.6587 Best avg r: 0.6617
17:02:03,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:29,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:54,771 root INFO Epoch 3 Global steps: 11600 Train loss: 0.3155
en_zh Dev loss: 0.7609 r:0.4566
ro_en Dev loss: 0.3505 r:0.8164
Current avg r:0.6365 Best avg r: 0.6617
17:04:11,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:36,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:02,667 root INFO Epoch 3 Global steps: 11800 Train loss: 0.3092
en_zh Dev loss: 0.8055 r:0.4672
ro_en Dev loss: 0.3625 r:0.8193
Current avg r:0.6432 Best avg r: 0.6617
17:06:19,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:44,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:10,662 root INFO Epoch 3 Global steps: 12000 Train loss: 0.3214
en_zh Dev loss: 0.7215 r:0.4688
ro_en Dev loss: 0.3207 r:0.8172
Current avg r:0.6430 Best avg r: 0.6617
17:08:27,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:53,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:18,826 root INFO Epoch 4 Global steps: 12200 Train loss: 0.2967
en_zh Dev loss: 0.7633 r:0.4614
ro_en Dev loss: 0.3461 r:0.8169
Current avg r:0.6391 Best avg r: 0.6617
17:10:35,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:01,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:26,706 root INFO Epoch 4 Global steps: 12400 Train loss: 0.2530
en_zh Dev loss: 0.7553 r:0.4813
ro_en Dev loss: 0.3728 r:0.8208
Current avg r:0.6511 Best avg r: 0.6617
17:12:43,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:08,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:34,708 root INFO Epoch 4 Global steps: 12600 Train loss: 0.2660
en_zh Dev loss: 0.9641 r:0.4384
ro_en Dev loss: 0.4733 r:0.8029
Current avg r:0.6206 Best avg r: 0.6617
17:14:51,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:17,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:42,724 root INFO Epoch 4 Global steps: 12800 Train loss: 0.2647
en_zh Dev loss: 0.7157 r:0.4812
ro_en Dev loss: 0.3242 r:0.8213
Current avg r:0.6513 Best avg r: 0.6617
17:16:59,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:24,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:50,637 root INFO Epoch 4 Global steps: 13000 Train loss: 0.2890
en_zh Dev loss: 0.7151 r:0.4849
ro_en Dev loss: 0.3465 r:0.8178
Current avg r:0.6514 Best avg r: 0.6617
17:19:07,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:32,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:58,502 root INFO Epoch 4 Global steps: 13200 Train loss: 0.2778
en_zh Dev loss: 0.7195 r:0.4740
ro_en Dev loss: 0.3210 r:0.8225
Current avg r:0.6483 Best avg r: 0.6617
17:21:15,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:40,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:06,433 root INFO Epoch 4 Global steps: 13400 Train loss: 0.2741
en_zh Dev loss: 0.7465 r:0.4654
ro_en Dev loss: 0.3501 r:0.8182
Current avg r:0.6418 Best avg r: 0.6617
17:23:23,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:48,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:14,465 root INFO Epoch 4 Global steps: 13600 Train loss: 0.2564
en_zh Dev loss: 0.7389 r:0.4675
ro_en Dev loss: 0.3479 r:0.8164
Current avg r:0.6419 Best avg r: 0.6617
17:25:31,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:56,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:22,670 root INFO Epoch 4 Global steps: 13800 Train loss: 0.2576
en_zh Dev loss: 0.7431 r:0.4663
ro_en Dev loss: 0.3673 r:0.8170
Current avg r:0.6417 Best avg r: 0.6617
17:27:39,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:04,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:30,522 root INFO Epoch 4 Global steps: 14000 Train loss: 0.2710
en_zh Dev loss: 0.7094 r:0.4880
ro_en Dev loss: 0.3397 r:0.8199
Current avg r:0.6540 Best avg r: 0.6617
17:29:46,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:12,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:38,358 root INFO Epoch 4 Global steps: 14200 Train loss: 0.2637
en_zh Dev loss: 0.7367 r:0.4737
ro_en Dev loss: 0.3560 r:0.8211
Current avg r:0.6474 Best avg r: 0.6617
17:31:54,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:20,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:46,193 root INFO Epoch 4 Global steps: 14400 Train loss: 0.2567
en_zh Dev loss: 0.7657 r:0.4565
ro_en Dev loss: 0.3468 r:0.8177
Current avg r:0.6371 Best avg r: 0.6617
17:34:02,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:28,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:54,3 root INFO Epoch 4 Global steps: 14600 Train loss: 0.2731
en_zh Dev loss: 0.6962 r:0.4944
ro_en Dev loss: 0.3248 r:0.8195
Current avg r:0.6569 Best avg r: 0.6617
17:36:10,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:36,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:01,812 root INFO Epoch 4 Global steps: 14800 Train loss: 0.2491
en_zh Dev loss: 0.7760 r:0.4786
ro_en Dev loss: 0.3584 r:0.8196
Current avg r:0.6491 Best avg r: 0.6617
17:38:18,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:43,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:09,661 root INFO Epoch 4 Global steps: 15000 Train loss: 0.2377
en_zh Dev loss: 0.7322 r:0.4858
ro_en Dev loss: 0.3616 r:0.8176
Current avg r:0.6517 Best avg r: 0.6617
17:40:26,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:52,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:17,834 root INFO Epoch 5 Global steps: 15200 Train loss: 0.2316
en_zh Dev loss: 0.7475 r:0.4712
ro_en Dev loss: 0.3467 r:0.8176
Current avg r:0.6444 Best avg r: 0.6617
17:42:34,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:00,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:25,696 root INFO Epoch 5 Global steps: 15400 Train loss: 0.2249
en_zh Dev loss: 0.7193 r:0.4750
ro_en Dev loss: 0.3238 r:0.8229
Current avg r:0.6490 Best avg r: 0.6617
17:44:42,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:08,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:33,707 root INFO Epoch 5 Global steps: 15600 Train loss: 0.2191
en_zh Dev loss: 0.7296 r:0.4793
ro_en Dev loss: 0.3533 r:0.8207
Current avg r:0.6500 Best avg r: 0.6617
17:46:50,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:15,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:41,518 root INFO Epoch 5 Global steps: 15800 Train loss: 0.2160
en_zh Dev loss: 0.7270 r:0.4735
ro_en Dev loss: 0.3276 r:0.8218
Current avg r:0.6477 Best avg r: 0.6617
17:48:57,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:23,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:49,382 root INFO Epoch 5 Global steps: 16000 Train loss: 0.2177
en_zh Dev loss: 0.7335 r:0.4689
ro_en Dev loss: 0.3260 r:0.8217
Current avg r:0.6453 Best avg r: 0.6617
17:51:05,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:31,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:57,321 root INFO Epoch 5 Global steps: 16200 Train loss: 0.2195
en_zh Dev loss: 0.7226 r:0.4601
ro_en Dev loss: 0.3189 r:0.8225
Current avg r:0.6413 Best avg r: 0.6617
17:53:13,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:39,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:05,185 root INFO Epoch 5 Global steps: 16400 Train loss: 0.2221
en_zh Dev loss: 0.7770 r:0.4660
ro_en Dev loss: 0.3762 r:0.8206
Current avg r:0.6433 Best avg r: 0.6617
17:55:21,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:47,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:13,61 root INFO Epoch 5 Global steps: 16600 Train loss: 0.2375
en_zh Dev loss: 0.7678 r:0.4774
ro_en Dev loss: 0.3677 r:0.8224
Current avg r:0.6499 Best avg r: 0.6617
17:57:29,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:55,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:20,971 root INFO Epoch 5 Global steps: 16800 Train loss: 0.2173
en_zh Dev loss: 0.7052 r:0.4866
ro_en Dev loss: 0.3228 r:0.8225
Current avg r:0.6546 Best avg r: 0.6617
17:59:37,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:03,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:28,869 root INFO Epoch 5 Global steps: 17000 Train loss: 0.2043
en_zh Dev loss: 0.7560 r:0.4884
ro_en Dev loss: 0.3427 r:0.8255
Current avg r:0.6569 Best avg r: 0.6617
18:01:45,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:11,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:36,734 root INFO Epoch 5 Global steps: 17200 Train loss: 0.2081
en_zh Dev loss: 0.7659 r:0.4794
ro_en Dev loss: 0.3673 r:0.8214
Current avg r:0.6504 Best avg r: 0.6617
18:03:53,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:18,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:44,600 root INFO Epoch 5 Global steps: 17400 Train loss: 0.2208
en_zh Dev loss: 0.7255 r:0.4748
ro_en Dev loss: 0.3152 r:0.8229
Current avg r:0.6488 Best avg r: 0.6617
18:06:01,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:26,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:52,510 root INFO Epoch 5 Global steps: 17600 Train loss: 0.2068
en_zh Dev loss: 0.7227 r:0.4769
ro_en Dev loss: 0.3290 r:0.8197
Current avg r:0.6483 Best avg r: 0.6617
18:08:09,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:34,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:00,330 root INFO Epoch 5 Global steps: 17800 Train loss: 0.2182
en_zh Dev loss: 0.7652 r:0.4643
ro_en Dev loss: 0.3436 r:0.8201
Current avg r:0.6422 Best avg r: 0.6617
18:10:16,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:42,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:08,167 root INFO Epoch 5 Global steps: 18000 Train loss: 0.2100
en_zh Dev loss: 0.7475 r:0.4642
ro_en Dev loss: 0.3278 r:0.8211
Current avg r:0.6426 Best avg r: 0.6617
18:12:25,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:50,749 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:16,430 root INFO Epoch 6 Global steps: 18200 Train loss: 0.1929
en_zh Dev loss: 0.7735 r:0.4660
ro_en Dev loss: 0.3417 r:0.8202
Current avg r:0.6431 Best avg r: 0.6617
18:14:32,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:58,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:24,343 root INFO Epoch 6 Global steps: 18400 Train loss: 0.1766
en_zh Dev loss: 0.7870 r:0.4671
ro_en Dev loss: 0.3727 r:0.8159
Current avg r:0.6415 Best avg r: 0.6617
18:16:40,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:06,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:32,227 root INFO Epoch 6 Global steps: 18600 Train loss: 0.1972
en_zh Dev loss: 0.7837 r:0.4618
ro_en Dev loss: 0.3598 r:0.8138
Current avg r:0.6378 Best avg r: 0.6617
18:18:48,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:14,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:40,40 root INFO Epoch 6 Global steps: 18800 Train loss: 0.1824
en_zh Dev loss: 0.8090 r:0.4662
ro_en Dev loss: 0.3997 r:0.8104
Current avg r:0.6383 Best avg r: 0.6617
18:20:56,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:22,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:47,812 root INFO Epoch 6 Global steps: 19000 Train loss: 0.1826
en_zh Dev loss: 0.7761 r:0.4678
ro_en Dev loss: 0.3509 r:0.8160
Current avg r:0.6419 Best avg r: 0.6617
18:23:04,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:29,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:55,613 root INFO Epoch 6 Global steps: 19200 Train loss: 0.1850
en_zh Dev loss: 0.7461 r:0.4822
ro_en Dev loss: 0.3350 r:0.8195
Current avg r:0.6509 Best avg r: 0.6617
18:25:12,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:37,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:03,414 root INFO Epoch 6 Global steps: 19400 Train loss: 0.1878
en_zh Dev loss: 0.7839 r:0.4835
ro_en Dev loss: 0.3769 r:0.8156
Current avg r:0.6496 Best avg r: 0.6617
18:27:19,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:45,548 root INFO 
id:en_zh cur r: 0.5022 best r: 0.5022
18:27:58,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:24,59 root INFO Epoch 6 Global steps: 19600 Train loss: 0.1861
en_zh Dev loss: 0.7386 r:0.4969
ro_en Dev loss: 0.3398 r:0.8199
Current avg r:0.6584 Best avg r: 0.6617
18:29:40,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:06,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:32,18 root INFO Epoch 6 Global steps: 19800 Train loss: 0.1875
en_zh Dev loss: 0.7730 r:0.4838
ro_en Dev loss: 0.3627 r:0.8160
Current avg r:0.6499 Best avg r: 0.6617
18:31:48,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:14,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:39,986 root INFO Epoch 6 Global steps: 20000 Train loss: 0.1777
en_zh Dev loss: 0.7894 r:0.4767
ro_en Dev loss: 0.3701 r:0.8124
Current avg r:0.6445 Best avg r: 0.6617
18:33:56,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:22,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:47,895 root INFO Epoch 6 Global steps: 20200 Train loss: 0.1681
en_zh Dev loss: 0.7337 r:0.4829
ro_en Dev loss: 0.3228 r:0.8214
Current avg r:0.6521 Best avg r: 0.6617
18:36:04,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:30,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:55,910 root INFO Epoch 6 Global steps: 20400 Train loss: 0.1811
en_zh Dev loss: 0.7333 r:0.4888
ro_en Dev loss: 0.3358 r:0.8185
Current avg r:0.6537 Best avg r: 0.6617
18:38:12,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:38,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:39:03,979 root INFO Epoch 6 Global steps: 20600 Train loss: 0.1773
en_zh Dev loss: 0.7590 r:0.4867
ro_en Dev loss: 0.3524 r:0.8203
Current avg r:0.6535 Best avg r: 0.6617
18:40:20,602 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:46,302 root INFO 
id:en_zh cur r: 0.5044 best r: 0.5044
18:40:59,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:24,873 root INFO Epoch 6 Global steps: 20800 Train loss: 0.1685
en_zh Dev loss: 0.7301 r:0.4973
ro_en Dev loss: 0.3448 r:0.8224
Current avg r:0.6599 Best avg r: 0.6617
18:42:41,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:07,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:32,939 root INFO Epoch 6 Global steps: 21000 Train loss: 0.1835
en_zh Dev loss: 0.7138 r:0.4949
ro_en Dev loss: 0.3289 r:0.8208
Current avg r:0.6578 Best avg r: 0.6617
18:44:50,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:15,707 root INFO 
id:en_zh cur r: 0.5097 best r: 0.5097
18:45:28,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:54,279 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:45:54,284 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:46:20,0 root INFO Epoch 7 Global steps: 21200 Train loss: 0.1659
en_zh Dev loss: 0.6865 r:0.5069
ro_en Dev loss: 0.3205 r:0.8209
Current avg r:0.6639 Best avg r: 0.6639
18:47:36,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:02,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:28,127 root INFO Epoch 7 Global steps: 21400 Train loss: 0.1703
en_zh Dev loss: 0.7214 r:0.4939
ro_en Dev loss: 0.3526 r:0.8192
Current avg r:0.6566 Best avg r: 0.6639
18:49:44,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:10,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:36,222 root INFO Epoch 7 Global steps: 21600 Train loss: 0.1626
en_zh Dev loss: 0.7918 r:0.4932
ro_en Dev loss: 0.3802 r:0.8180
Current avg r:0.6556 Best avg r: 0.6639
18:51:52,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:18,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:44,355 root INFO Epoch 7 Global steps: 21800 Train loss: 0.1542
en_zh Dev loss: 0.7611 r:0.4886
ro_en Dev loss: 0.3467 r:0.8183
Current avg r:0.6534 Best avg r: 0.6639
18:54:01,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:26,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:52,488 root INFO Epoch 7 Global steps: 22000 Train loss: 0.1730
en_zh Dev loss: 0.7719 r:0.4787
ro_en Dev loss: 0.3512 r:0.8173
Current avg r:0.6480 Best avg r: 0.6639
18:56:09,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:34,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:00,595 root INFO Epoch 7 Global steps: 22200 Train loss: 0.1489
en_zh Dev loss: 0.8014 r:0.4686
ro_en Dev loss: 0.3699 r:0.8141
Current avg r:0.6413 Best avg r: 0.6639
18:58:17,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:42,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:08,620 root INFO Epoch 7 Global steps: 22400 Train loss: 0.1693
en_zh Dev loss: 0.7420 r:0.4815
ro_en Dev loss: 0.3382 r:0.8171
Current avg r:0.6493 Best avg r: 0.6639
19:00:25,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:50,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:16,703 root INFO Epoch 7 Global steps: 22600 Train loss: 0.1545
en_zh Dev loss: 0.7908 r:0.4781
ro_en Dev loss: 0.3614 r:0.8160
Current avg r:0.6470 Best avg r: 0.6639
19:02:33,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:59,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:24,817 root INFO Epoch 7 Global steps: 22800 Train loss: 0.1530
en_zh Dev loss: 0.7375 r:0.4923
ro_en Dev loss: 0.3561 r:0.8182
Current avg r:0.6552 Best avg r: 0.6639
19:04:41,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:07,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:32,883 root INFO Epoch 7 Global steps: 23000 Train loss: 0.1386
en_zh Dev loss: 0.7615 r:0.4919
ro_en Dev loss: 0.3627 r:0.8188
Current avg r:0.6554 Best avg r: 0.6639
19:06:49,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:15,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:40,962 root INFO Epoch 7 Global steps: 23200 Train loss: 0.1414
en_zh Dev loss: 0.7233 r:0.4809
ro_en Dev loss: 0.3331 r:0.8162
Current avg r:0.6486 Best avg r: 0.6639
19:08:57,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:23,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:49,56 root INFO Epoch 7 Global steps: 23400 Train loss: 0.1428
en_zh Dev loss: 0.7223 r:0.4890
ro_en Dev loss: 0.3299 r:0.8200
Current avg r:0.6545 Best avg r: 0.6639
19:11:05,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:31,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:57,177 root INFO Epoch 7 Global steps: 23600 Train loss: 0.1546
en_zh Dev loss: 0.7219 r:0.4906
ro_en Dev loss: 0.3368 r:0.8207
Current avg r:0.6557 Best avg r: 0.6639
19:13:13,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:39,562 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:05,251 root INFO Epoch 7 Global steps: 23800 Train loss: 0.1680
en_zh Dev loss: 0.7714 r:0.4824
ro_en Dev loss: 0.3547 r:0.8203
Current avg r:0.6514 Best avg r: 0.6639
19:15:21,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:47,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:13,282 root INFO Epoch 7 Global steps: 24000 Train loss: 0.1511
en_zh Dev loss: 0.7661 r:0.4949
ro_en Dev loss: 0.3559 r:0.8228
Current avg r:0.6589 Best avg r: 0.6639
19:17:30,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:55,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:21,571 root INFO Epoch 8 Global steps: 24200 Train loss: 0.1431
en_zh Dev loss: 0.7485 r:0.4863
ro_en Dev loss: 0.3279 r:0.8245
Current avg r:0.6554 Best avg r: 0.6639
19:19:37,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:03,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:29,386 root INFO Epoch 8 Global steps: 24400 Train loss: 0.1359
en_zh Dev loss: 0.7909 r:0.4798
ro_en Dev loss: 0.3522 r:0.8219
Current avg r:0.6508 Best avg r: 0.6639
19:21:45,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:11,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:37,172 root INFO Epoch 8 Global steps: 24600 Train loss: 0.1386
en_zh Dev loss: 0.8081 r:0.4812
ro_en Dev loss: 0.3426 r:0.8239
Current avg r:0.6526 Best avg r: 0.6639
19:23:53,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:19,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:45,49 root INFO Epoch 8 Global steps: 24800 Train loss: 0.1501
en_zh Dev loss: 0.7489 r:0.4914
ro_en Dev loss: 0.3454 r:0.8225
Current avg r:0.6570 Best avg r: 0.6639
19:26:01,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:27,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:52,919 root INFO Epoch 8 Global steps: 25000 Train loss: 0.1333
en_zh Dev loss: 0.7578 r:0.4881
ro_en Dev loss: 0.3462 r:0.8217
Current avg r:0.6549 Best avg r: 0.6639
19:28:09,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:35,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:00,748 root INFO Epoch 8 Global steps: 25200 Train loss: 0.1324
en_zh Dev loss: 0.7411 r:0.4904
ro_en Dev loss: 0.3320 r:0.8219
Current avg r:0.6561 Best avg r: 0.6639
19:30:17,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:42,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:08,576 root INFO Epoch 8 Global steps: 25400 Train loss: 0.1348
en_zh Dev loss: 0.7289 r:0.4905
ro_en Dev loss: 0.3404 r:0.8225
Current avg r:0.6565 Best avg r: 0.6639
19:32:25,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:50,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:16,449 root INFO Epoch 8 Global steps: 25600 Train loss: 0.1211
en_zh Dev loss: 0.7726 r:0.4892
ro_en Dev loss: 0.3483 r:0.8235
Current avg r:0.6563 Best avg r: 0.6639
19:34:32,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:58,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:24,333 root INFO Epoch 8 Global steps: 25800 Train loss: 0.1409
en_zh Dev loss: 0.7366 r:0.4965
ro_en Dev loss: 0.3476 r:0.8239
Current avg r:0.6602 Best avg r: 0.6639
19:36:40,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:37:06,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:32,139 root INFO Epoch 8 Global steps: 26000 Train loss: 0.1308
en_zh Dev loss: 0.7503 r:0.4861
ro_en Dev loss: 0.3416 r:0.8214
Current avg r:0.6538 Best avg r: 0.6639
19:38:48,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:14,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:39:39,985 root INFO Epoch 8 Global steps: 26200 Train loss: 0.1357
en_zh Dev loss: 0.7246 r:0.4918
ro_en Dev loss: 0.3203 r:0.8237
Current avg r:0.6578 Best avg r: 0.6639
19:40:56,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:22,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:47,864 root INFO Epoch 8 Global steps: 26400 Train loss: 0.1294
en_zh Dev loss: 0.7423 r:0.4906
ro_en Dev loss: 0.3316 r:0.8241
Current avg r:0.6574 Best avg r: 0.6639
19:43:04,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:30,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:55,699 root INFO Epoch 8 Global steps: 26600 Train loss: 0.1270
en_zh Dev loss: 0.7358 r:0.4895
ro_en Dev loss: 0.3333 r:0.8225
Current avg r:0.6560 Best avg r: 0.6639
19:45:12,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:37,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:46:03,504 root INFO Epoch 8 Global steps: 26800 Train loss: 0.1231
en_zh Dev loss: 0.7144 r:0.4974
ro_en Dev loss: 0.3392 r:0.8215
Current avg r:0.6595 Best avg r: 0.6639
19:47:19,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:45,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:11,355 root INFO Epoch 8 Global steps: 27000 Train loss: 0.1371
en_zh Dev loss: 0.7558 r:0.4919
ro_en Dev loss: 0.3417 r:0.8226
Current avg r:0.6573 Best avg r: 0.6639
19:49:28,105 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:53,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:19,493 root INFO Epoch 9 Global steps: 27200 Train loss: 0.1254
en_zh Dev loss: 0.7090 r:0.4987
ro_en Dev loss: 0.3067 r:0.8246
Current avg r:0.6616 Best avg r: 0.6639
19:51:35,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:01,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:27,244 root INFO Epoch 9 Global steps: 27400 Train loss: 0.1092
en_zh Dev loss: 0.7179 r:0.4966
ro_en Dev loss: 0.3371 r:0.8212
Current avg r:0.6589 Best avg r: 0.6639
19:53:43,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:09,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:35,60 root INFO Epoch 9 Global steps: 27600 Train loss: 0.1273
en_zh Dev loss: 0.7160 r:0.4926
ro_en Dev loss: 0.3295 r:0.8229
Current avg r:0.6578 Best avg r: 0.6639
19:55:51,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:17,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:42,918 root INFO Epoch 9 Global steps: 27800 Train loss: 0.1124
en_zh Dev loss: 0.7673 r:0.4937
ro_en Dev loss: 0.3724 r:0.8191
Current avg r:0.6564 Best avg r: 0.6639
19:57:59,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:25,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:50,804 root INFO Epoch 9 Global steps: 28000 Train loss: 0.1163
en_zh Dev loss: 0.7541 r:0.4929
ro_en Dev loss: 0.3508 r:0.8197
Current avg r:0.6563 Best avg r: 0.6639
20:00:07,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:33,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:58,789 root INFO Epoch 9 Global steps: 28200 Train loss: 0.1247
en_zh Dev loss: 0.7905 r:0.4899
ro_en Dev loss: 0.3659 r:0.8220
Current avg r:0.6560 Best avg r: 0.6639
20:02:15,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:41,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:06,754 root INFO Epoch 9 Global steps: 28400 Train loss: 0.1187
en_zh Dev loss: 0.7119 r:0.4999
ro_en Dev loss: 0.3340 r:0.8225
Current avg r:0.6612 Best avg r: 0.6639
20:04:23,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:48,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:14,625 root INFO Epoch 9 Global steps: 28600 Train loss: 0.1193
en_zh Dev loss: 0.7075 r:0.4978
ro_en Dev loss: 0.3154 r:0.8257
Current avg r:0.6617 Best avg r: 0.6639
20:06:31,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:56,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:22,537 root INFO Epoch 9 Global steps: 28800 Train loss: 0.1205
en_zh Dev loss: 0.7785 r:0.4871
ro_en Dev loss: 0.3443 r:0.8251
Current avg r:0.6561 Best avg r: 0.6639
20:08:39,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:04,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:30,542 root INFO Epoch 9 Global steps: 29000 Train loss: 0.1244
en_zh Dev loss: 0.7438 r:0.4934
ro_en Dev loss: 0.3349 r:0.8219
Current avg r:0.6576 Best avg r: 0.6639
20:10:47,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:12,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:38,425 root INFO Epoch 9 Global steps: 29200 Train loss: 0.1269
en_zh Dev loss: 0.7891 r:0.5010
ro_en Dev loss: 0.3946 r:0.8221
Current avg r:0.6615 Best avg r: 0.6639
20:12:54,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:20,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:46,288 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:13:46,296 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:14:11,999 root INFO Epoch 9 Global steps: 29400 Train loss: 0.1156
en_zh Dev loss: 0.7148 r:0.5080
ro_en Dev loss: 0.3214 r:0.8266
Current avg r:0.6673 Best avg r: 0.6673
20:15:28,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:54,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:19,994 root INFO Epoch 9 Global steps: 29600 Train loss: 0.1307
en_zh Dev loss: 0.7143 r:0.5019
ro_en Dev loss: 0.3302 r:0.8272
Current avg r:0.6646 Best avg r: 0.6673
20:17:36,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:02,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:27,767 root INFO Epoch 9 Global steps: 29800 Train loss: 0.1182
en_zh Dev loss: 0.7342 r:0.5058
ro_en Dev loss: 0.3376 r:0.8284
Current avg r:0.6671 Best avg r: 0.6673
20:19:44,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:09,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:35,613 root INFO Epoch 9 Global steps: 30000 Train loss: 0.1126
en_zh Dev loss: 0.7031 r:0.5050
ro_en Dev loss: 0.3143 r:0.8276
Current avg r:0.6663 Best avg r: 0.6673
20:21:52,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:22:18,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:43,794 root INFO Epoch 10 Global steps: 30200 Train loss: 0.1211
en_zh Dev loss: 0.7246 r:0.4954
ro_en Dev loss: 0.3186 r:0.8263
Current avg r:0.6608 Best avg r: 0.6673
20:24:00,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:25,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:51,608 root INFO Epoch 10 Global steps: 30400 Train loss: 0.1065
en_zh Dev loss: 0.7032 r:0.5022
ro_en Dev loss: 0.3237 r:0.8246
Current avg r:0.6634 Best avg r: 0.6673
20:26:08,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:26:33,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:59,428 root INFO Epoch 10 Global steps: 30600 Train loss: 0.1033
en_zh Dev loss: 0.7517 r:0.4929
ro_en Dev loss: 0.3441 r:0.8225
Current avg r:0.6577 Best avg r: 0.6673
20:28:15,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:41,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:07,301 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1031
en_zh Dev loss: 0.7612 r:0.4888
ro_en Dev loss: 0.3485 r:0.8211
Current avg r:0.6549 Best avg r: 0.6673
20:30:23,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:49,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:15,267 root INFO Epoch 10 Global steps: 31000 Train loss: 0.1101
en_zh Dev loss: 0.7651 r:0.4936
ro_en Dev loss: 0.3652 r:0.8193
Current avg r:0.6564 Best avg r: 0.6673
20:32:31,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:57,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:23,308 root INFO Epoch 10 Global steps: 31200 Train loss: 0.1091
en_zh Dev loss: 0.7389 r:0.4971
ro_en Dev loss: 0.3389 r:0.8218
Current avg r:0.6594 Best avg r: 0.6673
20:34:39,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:05,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:31,328 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1067
en_zh Dev loss: 0.7677 r:0.5021
ro_en Dev loss: 0.3622 r:0.8213
Current avg r:0.6617 Best avg r: 0.6673
20:36:48,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:13,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:39,454 root INFO Epoch 10 Global steps: 31600 Train loss: 0.1064
en_zh Dev loss: 0.7101 r:0.5009
ro_en Dev loss: 0.3230 r:0.8227
Current avg r:0.6618 Best avg r: 0.6673
20:38:56,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:21,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:47,483 root INFO Epoch 10 Global steps: 31800 Train loss: 0.1046
en_zh Dev loss: 0.7399 r:0.5038
ro_en Dev loss: 0.3504 r:0.8226
Current avg r:0.6632 Best avg r: 0.6673
20:41:04,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:29,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:55,422 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1072
en_zh Dev loss: 0.7151 r:0.5043
ro_en Dev loss: 0.3173 r:0.8252
Current avg r:0.6648 Best avg r: 0.6673
20:43:11,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:37,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:03,305 root INFO Epoch 10 Global steps: 32200 Train loss: 0.0993
en_zh Dev loss: 0.7556 r:0.4983
ro_en Dev loss: 0.3609 r:0.8218
Current avg r:0.6601 Best avg r: 0.6673
20:45:19,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:45,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:11,62 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1150
en_zh Dev loss: 0.7322 r:0.5009
ro_en Dev loss: 0.3211 r:0.8262
Current avg r:0.6635 Best avg r: 0.6673
20:47:27,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:53,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:18,737 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1138
en_zh Dev loss: 0.7300 r:0.4956
ro_en Dev loss: 0.3318 r:0.8210
Current avg r:0.6583 Best avg r: 0.6673
20:49:35,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:00,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:26,536 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1090
en_zh Dev loss: 0.8045 r:0.4846
ro_en Dev loss: 0.3579 r:0.8197
Current avg r:0.6521 Best avg r: 0.6673
20:51:43,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:08,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:34,442 root INFO Epoch 10 Global steps: 33000 Train loss: 0.0982
en_zh Dev loss: 0.7867 r:0.4876
ro_en Dev loss: 0.3737 r:0.8184
Current avg r:0.6530 Best avg r: 0.6673
20:53:51,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:17,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:42,773 root INFO Epoch 11 Global steps: 33200 Train loss: 0.0937
en_zh Dev loss: 0.7335 r:0.4947
ro_en Dev loss: 0.3539 r:0.8209
Current avg r:0.6578 Best avg r: 0.6673
20:55:59,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:25,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:50,764 root INFO Epoch 11 Global steps: 33400 Train loss: 0.0944
en_zh Dev loss: 0.7356 r:0.4940
ro_en Dev loss: 0.3389 r:0.8205
Current avg r:0.6573 Best avg r: 0.6673
20:58:07,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:33,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:58,782 root INFO Epoch 11 Global steps: 33600 Train loss: 0.0828
en_zh Dev loss: 0.8062 r:0.4969
ro_en Dev loss: 0.3650 r:0.8214
Current avg r:0.6591 Best avg r: 0.6673
21:00:15,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:41,82 root INFO 
id:en_zh cur r: 0.5104 best r: 0.5104
21:00:53,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:19,646 root INFO Epoch 11 Global steps: 33800 Train loss: 0.0963
en_zh Dev loss: 0.7328 r:0.5056
ro_en Dev loss: 0.3311 r:0.8240
Current avg r:0.6648 Best avg r: 0.6673
21:02:36,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:01,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:27,621 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1024
en_zh Dev loss: 0.7267 r:0.4925
ro_en Dev loss: 0.3311 r:0.8210
Current avg r:0.6568 Best avg r: 0.6673
21:04:44,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:09,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:35,469 root INFO Epoch 11 Global steps: 34200 Train loss: 0.0886
en_zh Dev loss: 0.8049 r:0.4859
ro_en Dev loss: 0.3582 r:0.8241
Current avg r:0.6550 Best avg r: 0.6673
21:06:51,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:17,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:43,315 root INFO Epoch 11 Global steps: 34400 Train loss: 0.0953
en_zh Dev loss: 0.8138 r:0.4873
ro_en Dev loss: 0.3630 r:0.8228
Current avg r:0.6550 Best avg r: 0.6673
21:08:59,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:25,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:51,186 root INFO Epoch 11 Global steps: 34600 Train loss: 0.0986
en_zh Dev loss: 0.7622 r:0.4965
ro_en Dev loss: 0.3601 r:0.8201
Current avg r:0.6583 Best avg r: 0.6673
21:11:07,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:33,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:59,450 root INFO Epoch 11 Global steps: 34800 Train loss: 0.0970
en_zh Dev loss: 0.7264 r:0.4960
ro_en Dev loss: 0.3546 r:0.8216
Current avg r:0.6588 Best avg r: 0.6673
21:13:16,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:41,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:07,615 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1022
en_zh Dev loss: 0.7207 r:0.4991
ro_en Dev loss: 0.3496 r:0.8194
Current avg r:0.6593 Best avg r: 0.6673
21:15:24,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:50,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:15,719 root INFO Epoch 11 Global steps: 35200 Train loss: 0.0974
en_zh Dev loss: 0.7673 r:0.4991
ro_en Dev loss: 0.3578 r:0.8218
Current avg r:0.6604 Best avg r: 0.6673
21:17:32,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:58,265 root INFO 
id:en_zh cur r: 0.5105 best r: 0.5105
21:18:11,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:36,876 root INFO Epoch 11 Global steps: 35400 Train loss: 0.0973
en_zh Dev loss: 0.7032 r:0.5063
ro_en Dev loss: 0.3191 r:0.8239
Current avg r:0.6651 Best avg r: 0.6673
21:19:53,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:19,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:44,986 root INFO Epoch 11 Global steps: 35600 Train loss: 0.0967
en_zh Dev loss: 0.7256 r:0.5061
ro_en Dev loss: 0.3510 r:0.8218
Current avg r:0.6639 Best avg r: 0.6673
21:22:01,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:27,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:52,977 root INFO Epoch 11 Global steps: 35800 Train loss: 0.0950
en_zh Dev loss: 0.7346 r:0.4990
ro_en Dev loss: 0.3215 r:0.8268
Current avg r:0.6629 Best avg r: 0.6673
21:24:09,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:35,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:00,988 root INFO Epoch 11 Global steps: 36000 Train loss: 0.0939
en_zh Dev loss: 0.7934 r:0.4952
ro_en Dev loss: 0.3647 r:0.8213
Current avg r:0.6583 Best avg r: 0.6673
21:26:18,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:26:43,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:09,419 root INFO Epoch 12 Global steps: 36200 Train loss: 0.0865
en_zh Dev loss: 0.7380 r:0.5029
ro_en Dev loss: 0.3551 r:0.8227
Current avg r:0.6628 Best avg r: 0.6673
21:28:26,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:51,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:17,458 root INFO Epoch 12 Global steps: 36400 Train loss: 0.0848
en_zh Dev loss: 0.7509 r:0.4929
ro_en Dev loss: 0.3363 r:0.8233
Current avg r:0.6581 Best avg r: 0.6673
21:30:34,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:59,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:25,435 root INFO Epoch 12 Global steps: 36600 Train loss: 0.0887
en_zh Dev loss: 0.7466 r:0.4978
ro_en Dev loss: 0.3388 r:0.8247
Current avg r:0.6612 Best avg r: 0.6673
21:32:42,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:33:07,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:33,498 root INFO Epoch 12 Global steps: 36800 Train loss: 0.0889
en_zh Dev loss: 0.8045 r:0.4921
ro_en Dev loss: 0.3587 r:0.8230
Current avg r:0.6576 Best avg r: 0.6673
21:34:50,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:16,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:41,752 root INFO Epoch 12 Global steps: 37000 Train loss: 0.0799
en_zh Dev loss: 0.7683 r:0.4974
ro_en Dev loss: 0.3463 r:0.8225
Current avg r:0.6600 Best avg r: 0.6673
21:36:58,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:24,107 root INFO 
id:en_zh cur r: 0.5137 best r: 0.5137
21:37:36,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:02,651 root INFO Epoch 12 Global steps: 37200 Train loss: 0.0872
en_zh Dev loss: 0.7247 r:0.5106
ro_en Dev loss: 0.3516 r:0.8200
Current avg r:0.6653 Best avg r: 0.6673
21:39:19,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:44,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:10,603 root INFO Epoch 12 Global steps: 37400 Train loss: 0.0840
en_zh Dev loss: 0.7392 r:0.5080
ro_en Dev loss: 0.3483 r:0.8219
Current avg r:0.6650 Best avg r: 0.6673
21:41:27,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:52,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:18,643 root INFO Epoch 12 Global steps: 37600 Train loss: 0.0918
en_zh Dev loss: 0.7728 r:0.4954
ro_en Dev loss: 0.3595 r:0.8237
Current avg r:0.6595 Best avg r: 0.6673
21:43:35,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:00,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:26,659 root INFO Epoch 12 Global steps: 37800 Train loss: 0.0833
en_zh Dev loss: 0.7052 r:0.5036
ro_en Dev loss: 0.3202 r:0.8248
Current avg r:0.6642 Best avg r: 0.6673
21:45:43,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:46:08,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:34,674 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
21:46:34,682 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
21:47:00,398 root INFO Epoch 12 Global steps: 38000 Train loss: 0.0831
en_zh Dev loss: 0.7121 r:0.5115
ro_en Dev loss: 0.3430 r:0.8251
Current avg r:0.6683 Best avg r: 0.6683
21:48:17,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:42,917 root INFO 
id:en_zh cur r: 0.5176 best r: 0.5176
21:48:55,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:21,523 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
21:49:21,531 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
21:49:47,276 root INFO Epoch 12 Global steps: 38200 Train loss: 0.0814
en_zh Dev loss: 0.7130 r:0.5150
ro_en Dev loss: 0.3479 r:0.8246
Current avg r:0.6698 Best avg r: 0.6698
21:51:03,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:29,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:55,287 root INFO Epoch 12 Global steps: 38400 Train loss: 0.0827
en_zh Dev loss: 0.7022 r:0.5077
ro_en Dev loss: 0.3305 r:0.8237
Current avg r:0.6657 Best avg r: 0.6698
21:53:11,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:37,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:03,330 root INFO Epoch 12 Global steps: 38600 Train loss: 0.0808
en_zh Dev loss: 0.7023 r:0.5126
ro_en Dev loss: 0.3396 r:0.8260
Current avg r:0.6693 Best avg r: 0.6698
21:55:19,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:45,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:11,441 root INFO Epoch 12 Global steps: 38800 Train loss: 0.0949
en_zh Dev loss: 0.7233 r:0.5054
ro_en Dev loss: 0.3316 r:0.8270
Current avg r:0.6662 Best avg r: 0.6698
21:57:28,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:53,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:19,492 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
21:58:19,499 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
21:58:45,249 root INFO Epoch 12 Global steps: 39000 Train loss: 0.0840
en_zh Dev loss: 0.7081 r:0.5117
ro_en Dev loss: 0.3166 r:0.8285
Current avg r:0.6701 Best avg r: 0.6701
22:00:02,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:27,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:53,573 root INFO Epoch 13 Global steps: 39200 Train loss: 0.0769
en_zh Dev loss: 0.7373 r:0.5048
ro_en Dev loss: 0.3556 r:0.8223
Current avg r:0.6635 Best avg r: 0.6701
22:02:10,183 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:35,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:01,600 root INFO Epoch 13 Global steps: 39400 Train loss: 0.0808
en_zh Dev loss: 0.7698 r:0.5113
ro_en Dev loss: 0.3384 r:0.8270
Current avg r:0.6691 Best avg r: 0.6701
22:04:18,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:43,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:09,658 root INFO Epoch 13 Global steps: 39600 Train loss: 0.0725
en_zh Dev loss: 0.7652 r:0.5050
ro_en Dev loss: 0.3506 r:0.8233
Current avg r:0.6642 Best avg r: 0.6701
22:06:26,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:51,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:17,654 root INFO Epoch 13 Global steps: 39800 Train loss: 0.0810
en_zh Dev loss: 0.7456 r:0.5070
ro_en Dev loss: 0.3385 r:0.8239
Current avg r:0.6654 Best avg r: 0.6701
22:08:34,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:59,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:25,631 root INFO Epoch 13 Global steps: 40000 Train loss: 0.0755
en_zh Dev loss: 0.7238 r:0.5027
ro_en Dev loss: 0.3429 r:0.8231
Current avg r:0.6629 Best avg r: 0.6701
22:10:42,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:07,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:33,634 root INFO Epoch 13 Global steps: 40200 Train loss: 0.0751
en_zh Dev loss: 0.7530 r:0.5062
ro_en Dev loss: 0.3837 r:0.8216
Current avg r:0.6639 Best avg r: 0.6701
22:12:50,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:15,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:41,649 root INFO Epoch 13 Global steps: 40400 Train loss: 0.0765
en_zh Dev loss: 0.7620 r:0.4986
ro_en Dev loss: 0.3527 r:0.8202
Current avg r:0.6594 Best avg r: 0.6701
22:14:58,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:23,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:49,690 root INFO Epoch 13 Global steps: 40600 Train loss: 0.0716
en_zh Dev loss: 0.7452 r:0.5011
ro_en Dev loss: 0.3449 r:0.8191
Current avg r:0.6601 Best avg r: 0.6701
22:17:06,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:32,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:57,739 root INFO Epoch 13 Global steps: 40800 Train loss: 0.0763
en_zh Dev loss: 0.7506 r:0.5083
ro_en Dev loss: 0.3561 r:0.8223
Current avg r:0.6653 Best avg r: 0.6701
22:19:14,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:40,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:05,742 root INFO Epoch 13 Global steps: 41000 Train loss: 0.0849
en_zh Dev loss: 0.6906 r:0.5070
ro_en Dev loss: 0.3205 r:0.8245
Current avg r:0.6658 Best avg r: 0.6701
22:21:22,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:48,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:13,724 root INFO Epoch 13 Global steps: 41200 Train loss: 0.0809
en_zh Dev loss: 0.7000 r:0.5099
ro_en Dev loss: 0.3233 r:0.8256
Current avg r:0.6678 Best avg r: 0.6701
22:23:30,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:56,67 root INFO 
id:en_zh cur r: 0.5179 best r: 0.5179
22:24:08,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:34,647 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
22:24:34,652 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
22:25:00,369 root INFO Epoch 13 Global steps: 41400 Train loss: 0.0756
en_zh Dev loss: 0.7232 r:0.5148
ro_en Dev loss: 0.3221 r:0.8261
Current avg r:0.6704 Best avg r: 0.6704
22:26:17,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:26:42,798 root INFO 
id:en_zh cur r: 0.5229 best r: 0.5229
22:26:55,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:21,426 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
22:27:21,431 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
22:27:47,169 root INFO Epoch 13 Global steps: 41600 Train loss: 0.0709
en_zh Dev loss: 0.7054 r:0.5185
ro_en Dev loss: 0.3436 r:0.8258
Current avg r:0.6721 Best avg r: 0.6721
22:29:03,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:29,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:55,428 root INFO Epoch 13 Global steps: 41800 Train loss: 0.0737
en_zh Dev loss: 0.7316 r:0.5155
ro_en Dev loss: 0.3353 r:0.8261
Current avg r:0.6708 Best avg r: 0.6721
22:31:12,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:37,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:03,471 root INFO Epoch 13 Global steps: 42000 Train loss: 0.0747
en_zh Dev loss: 0.6911 r:0.5103
ro_en Dev loss: 0.3328 r:0.8249
Current avg r:0.6676 Best avg r: 0.6721
22:33:20,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:46,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:11,889 root INFO Epoch 14 Global steps: 42200 Train loss: 0.0797
en_zh Dev loss: 0.7173 r:0.5112
ro_en Dev loss: 0.3490 r:0.8202
Current avg r:0.6657 Best avg r: 0.6721
22:35:28,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:54,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:19,927 root INFO Epoch 14 Global steps: 42400 Train loss: 0.0664
en_zh Dev loss: 0.7218 r:0.5098
ro_en Dev loss: 0.3337 r:0.8222
Current avg r:0.6660 Best avg r: 0.6721
22:37:36,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:02,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:27,971 root INFO Epoch 14 Global steps: 42600 Train loss: 0.0745
en_zh Dev loss: 0.7575 r:0.5097
ro_en Dev loss: 0.3708 r:0.8209
Current avg r:0.6653 Best avg r: 0.6721
22:39:44,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:10,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:36,70 root INFO Epoch 14 Global steps: 42800 Train loss: 0.0712
en_zh Dev loss: 0.7524 r:0.5029
ro_en Dev loss: 0.3645 r:0.8212
Current avg r:0.6620 Best avg r: 0.6721
22:41:52,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:18,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:44,183 root INFO Epoch 14 Global steps: 43000 Train loss: 0.0720
en_zh Dev loss: 0.7847 r:0.5053
ro_en Dev loss: 0.3724 r:0.8208
Current avg r:0.6630 Best avg r: 0.6721
22:44:00,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:26,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:52,240 root INFO Epoch 14 Global steps: 43200 Train loss: 0.0702
en_zh Dev loss: 0.7289 r:0.5127
ro_en Dev loss: 0.3454 r:0.8257
Current avg r:0.6692 Best avg r: 0.6721
22:46:08,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:34,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:00,281 root INFO Epoch 14 Global steps: 43400 Train loss: 0.0721
en_zh Dev loss: 0.7106 r:0.5112
ro_en Dev loss: 0.3246 r:0.8238
Current avg r:0.6675 Best avg r: 0.6721
22:48:16,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:42,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:08,364 root INFO Epoch 14 Global steps: 43600 Train loss: 0.0712
en_zh Dev loss: 0.7679 r:0.5041
ro_en Dev loss: 0.3418 r:0.8252
Current avg r:0.6646 Best avg r: 0.6721
22:50:24,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:50,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:16,389 root INFO Epoch 14 Global steps: 43800 Train loss: 0.0715
en_zh Dev loss: 0.6936 r:0.5163
ro_en Dev loss: 0.3234 r:0.8265
Current avg r:0.6714 Best avg r: 0.6721
22:52:33,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:59,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:24,706 root INFO Epoch 14 Global steps: 44000 Train loss: 0.0691
en_zh Dev loss: 0.7139 r:0.5126
ro_en Dev loss: 0.3271 r:0.8281
Current avg r:0.6703 Best avg r: 0.6721
22:54:41,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:07,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:32,912 root INFO Epoch 14 Global steps: 44200 Train loss: 0.0684
en_zh Dev loss: 0.7131 r:0.5139
ro_en Dev loss: 0.3325 r:0.8256
Current avg r:0.6697 Best avg r: 0.6721
22:56:49,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:15,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:41,22 root INFO Epoch 14 Global steps: 44400 Train loss: 0.0694
en_zh Dev loss: 0.7171 r:0.5062
ro_en Dev loss: 0.3272 r:0.8245
Current avg r:0.6653 Best avg r: 0.6721
22:58:57,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:23,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:49,71 root INFO Epoch 14 Global steps: 44600 Train loss: 0.0795
en_zh Dev loss: 0.7152 r:0.5146
ro_en Dev loss: 0.3446 r:0.8236
Current avg r:0.6691 Best avg r: 0.6721
23:01:05,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:31,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:57,125 root INFO Epoch 14 Global steps: 44800 Train loss: 0.0649
en_zh Dev loss: 0.7432 r:0.5074
ro_en Dev loss: 0.3337 r:0.8238
Current avg r:0.6656 Best avg r: 0.6721
23:03:13,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:39,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:05,197 root INFO Epoch 14 Global steps: 45000 Train loss: 0.0690
en_zh Dev loss: 0.7497 r:0.5036
ro_en Dev loss: 0.3453 r:0.8212
Current avg r:0.6624 Best avg r: 0.6721
23:05:22,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:47,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:13,577 root INFO Epoch 15 Global steps: 45200 Train loss: 0.0712
en_zh Dev loss: 0.7030 r:0.5085
ro_en Dev loss: 0.3079 r:0.8257
Current avg r:0.6671 Best avg r: 0.6721
23:07:30,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:55,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:21,649 root INFO Epoch 15 Global steps: 45400 Train loss: 0.0682
en_zh Dev loss: 0.7287 r:0.5045
ro_en Dev loss: 0.3373 r:0.8252
Current avg r:0.6649 Best avg r: 0.6721
23:09:38,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:04,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:29,707 root INFO Epoch 15 Global steps: 45600 Train loss: 0.0645
en_zh Dev loss: 0.7447 r:0.5146
ro_en Dev loss: 0.3578 r:0.8218
Current avg r:0.6682 Best avg r: 0.6721
23:11:46,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:12:11,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:37,675 root INFO Epoch 15 Global steps: 45800 Train loss: 0.0685
en_zh Dev loss: 0.7761 r:0.5129
ro_en Dev loss: 0.3493 r:0.8244
Current avg r:0.6687 Best avg r: 0.6721
23:13:54,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:20,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:45,713 root INFO Epoch 15 Global steps: 46000 Train loss: 0.0693
en_zh Dev loss: 0.6999 r:0.5155
ro_en Dev loss: 0.3246 r:0.8236
Current avg r:0.6695 Best avg r: 0.6721
23:16:02,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:28,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:53,748 root INFO Epoch 15 Global steps: 46200 Train loss: 0.0635
en_zh Dev loss: 0.7026 r:0.5157
ro_en Dev loss: 0.3340 r:0.8221
Current avg r:0.6689 Best avg r: 0.6721
23:18:10,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:36,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:01,730 root INFO Epoch 15 Global steps: 46400 Train loss: 0.0676
en_zh Dev loss: 0.7276 r:0.5106
ro_en Dev loss: 0.3493 r:0.8194
Current avg r:0.6650 Best avg r: 0.6721
23:20:18,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:44,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:21:09,725 root INFO Epoch 15 Global steps: 46600 Train loss: 0.0678
en_zh Dev loss: 0.7265 r:0.5114
ro_en Dev loss: 0.3446 r:0.8220
Current avg r:0.6667 Best avg r: 0.6721
23:22:26,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:52,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:17,744 root INFO Epoch 15 Global steps: 46800 Train loss: 0.0668
en_zh Dev loss: 0.7568 r:0.5091
ro_en Dev loss: 0.3551 r:0.8221
Current avg r:0.6656 Best avg r: 0.6721
23:24:34,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:00,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:25,702 root INFO Epoch 15 Global steps: 47000 Train loss: 0.0723
en_zh Dev loss: 0.7024 r:0.5152
ro_en Dev loss: 0.3260 r:0.8225
Current avg r:0.6689 Best avg r: 0.6721
23:26:42,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:27:07,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:33,673 root INFO Epoch 15 Global steps: 47200 Train loss: 0.0625
en_zh Dev loss: 0.7636 r:0.5051
ro_en Dev loss: 0.3628 r:0.8174
Current avg r:0.6612 Best avg r: 0.6721
23:28:50,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:15,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:41,626 root INFO Epoch 15 Global steps: 47400 Train loss: 0.0677
en_zh Dev loss: 0.6950 r:0.5121
ro_en Dev loss: 0.3285 r:0.8209
Current avg r:0.6665 Best avg r: 0.6721
23:30:58,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:23,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:49,641 root INFO Epoch 15 Global steps: 47600 Train loss: 0.0625
en_zh Dev loss: 0.7562 r:0.5050
ro_en Dev loss: 0.3494 r:0.8201
Current avg r:0.6625 Best avg r: 0.6721
23:33:06,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:31,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:57,661 root INFO Epoch 15 Global steps: 47800 Train loss: 0.0631
en_zh Dev loss: 0.7234 r:0.5110
ro_en Dev loss: 0.3332 r:0.8227
Current avg r:0.6668 Best avg r: 0.6721
23:35:14,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:39,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:05,648 root INFO Epoch 15 Global steps: 48000 Train loss: 0.0686
en_zh Dev loss: 0.7968 r:0.5006
ro_en Dev loss: 0.3673 r:0.8216
Current avg r:0.6611 Best avg r: 0.6721
23:37:22,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:48,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:13,932 root INFO Epoch 16 Global steps: 48200 Train loss: 0.0619
en_zh Dev loss: 0.7594 r:0.5025
ro_en Dev loss: 0.3663 r:0.8204
Current avg r:0.6615 Best avg r: 0.6721
23:39:30,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:56,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:21,927 root INFO Epoch 16 Global steps: 48400 Train loss: 0.0597
en_zh Dev loss: 0.7270 r:0.5101
ro_en Dev loss: 0.3138 r:0.8268
Current avg r:0.6684 Best avg r: 0.6721
23:41:38,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:04,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:29,798 root INFO Epoch 16 Global steps: 48600 Train loss: 0.0606
en_zh Dev loss: 0.7250 r:0.5050
ro_en Dev loss: 0.3414 r:0.8253
Current avg r:0.6652 Best avg r: 0.6721
23:43:46,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:12,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:37,747 root INFO Epoch 16 Global steps: 48800 Train loss: 0.0597
en_zh Dev loss: 0.7267 r:0.5129
ro_en Dev loss: 0.3341 r:0.8262
Current avg r:0.6696 Best avg r: 0.6721
23:45:54,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:20,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:45,765 root INFO Epoch 16 Global steps: 49000 Train loss: 0.0608
en_zh Dev loss: 0.7585 r:0.5119
ro_en Dev loss: 0.3651 r:0.8245
Current avg r:0.6682 Best avg r: 0.6721
23:48:02,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:28,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:53,811 root INFO Epoch 16 Global steps: 49200 Train loss: 0.0646
en_zh Dev loss: 0.6992 r:0.5143
ro_en Dev loss: 0.3377 r:0.8211
Current avg r:0.6677 Best avg r: 0.6721
23:50:10,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:36,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:51:01,746 root INFO Epoch 16 Global steps: 49400 Train loss: 0.0584
en_zh Dev loss: 0.7400 r:0.5017
ro_en Dev loss: 0.3535 r:0.8214
Current avg r:0.6615 Best avg r: 0.6721
23:52:18,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:44,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:09,723 root INFO Epoch 16 Global steps: 49600 Train loss: 0.0584
en_zh Dev loss: 0.7441 r:0.4938
ro_en Dev loss: 0.3317 r:0.8219
Current avg r:0.6578 Best avg r: 0.6721
23:54:26,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:52,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:17,757 root INFO Epoch 16 Global steps: 49800 Train loss: 0.0596
en_zh Dev loss: 0.7451 r:0.4970
ro_en Dev loss: 0.3416 r:0.8238
Current avg r:0.6604 Best avg r: 0.6721
23:56:34,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:00,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:25,776 root INFO Epoch 16 Global steps: 50000 Train loss: 0.0552
en_zh Dev loss: 0.7217 r:0.5078
ro_en Dev loss: 0.3237 r:0.8249
Current avg r:0.6664 Best avg r: 0.6721
23:58:42,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:08,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:33,740 root INFO Epoch 16 Global steps: 50200 Train loss: 0.0673
en_zh Dev loss: 0.7513 r:0.5039
ro_en Dev loss: 0.3332 r:0.8233
Current avg r:0.6636 Best avg r: 0.6721
00:00:50,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:16,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:41,793 root INFO Epoch 16 Global steps: 50400 Train loss: 0.0591
en_zh Dev loss: 0.7215 r:0.5022
ro_en Dev loss: 0.3385 r:0.8202
Current avg r:0.6612 Best avg r: 0.6721
00:02:58,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:24,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:49,768 root INFO Epoch 16 Global steps: 50600 Train loss: 0.0577
en_zh Dev loss: 0.7524 r:0.5092
ro_en Dev loss: 0.3478 r:0.8205
Current avg r:0.6648 Best avg r: 0.6721
00:05:06,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:32,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:57,726 root INFO Epoch 16 Global steps: 50800 Train loss: 0.0646
en_zh Dev loss: 0.7803 r:0.5036
ro_en Dev loss: 0.3748 r:0.8191
Current avg r:0.6613 Best avg r: 0.6721
00:07:14,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:40,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:05,729 root INFO Epoch 16 Global steps: 51000 Train loss: 0.0568
en_zh Dev loss: 0.7629 r:0.5070
ro_en Dev loss: 0.3625 r:0.8201
Current avg r:0.6636 Best avg r: 0.6721
00:09:22,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:48,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:14,90 root INFO Epoch 17 Global steps: 51200 Train loss: 0.0605
en_zh Dev loss: 0.7370 r:0.5104
ro_en Dev loss: 0.3422 r:0.8195
Current avg r:0.6650 Best avg r: 0.6721
00:11:30,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:56,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:22,286 root INFO Epoch 17 Global steps: 51400 Train loss: 0.0548
en_zh Dev loss: 0.7221 r:0.5104
ro_en Dev loss: 0.3545 r:0.8197
Current avg r:0.6651 Best avg r: 0.6721
00:13:38,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:04,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:30,342 root INFO Epoch 17 Global steps: 51600 Train loss: 0.0600
en_zh Dev loss: 0.7275 r:0.5070
ro_en Dev loss: 0.3370 r:0.8242
Current avg r:0.6656 Best avg r: 0.6721
00:15:47,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:16:12,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:16:38,465 root INFO Epoch 17 Global steps: 51800 Train loss: 0.0581
en_zh Dev loss: 0.7309 r:0.5149
ro_en Dev loss: 0.3298 r:0.8242
Current avg r:0.6695 Best avg r: 0.6721
00:17:55,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:20,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:18:46,397 root INFO Epoch 17 Global steps: 52000 Train loss: 0.0558
en_zh Dev loss: 0.7037 r:0.5141
ro_en Dev loss: 0.3306 r:0.8251
Current avg r:0.6696 Best avg r: 0.6721
00:20:02,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:28,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:54,386 root INFO Epoch 17 Global steps: 52200 Train loss: 0.0536
en_zh Dev loss: 0.7708 r:0.4960
ro_en Dev loss: 0.3644 r:0.8207
Current avg r:0.6584 Best avg r: 0.6721
00:22:10,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:36,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:02,369 root INFO Epoch 17 Global steps: 52400 Train loss: 0.0617
en_zh Dev loss: 0.7740 r:0.4993
ro_en Dev loss: 0.3679 r:0.8223
Current avg r:0.6608 Best avg r: 0.6721
00:24:18,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:44,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:10,392 root INFO Epoch 17 Global steps: 52600 Train loss: 0.0577
en_zh Dev loss: 0.7187 r:0.5091
ro_en Dev loss: 0.3112 r:0.8253
Current avg r:0.6672 Best avg r: 0.6721
00:26:27,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:52,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:18,480 root INFO Epoch 17 Global steps: 52800 Train loss: 0.0536
en_zh Dev loss: 0.7546 r:0.5117
ro_en Dev loss: 0.3730 r:0.8215
Current avg r:0.6666 Best avg r: 0.6721
00:28:35,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:00,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:26,437 root INFO Epoch 17 Global steps: 53000 Train loss: 0.0569
en_zh Dev loss: 0.7514 r:0.5138
ro_en Dev loss: 0.3509 r:0.8232
Current avg r:0.6685 Best avg r: 0.6721
00:30:42,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:08,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:34,390 root INFO Epoch 17 Global steps: 53200 Train loss: 0.0623
en_zh Dev loss: 0.6863 r:0.5142
ro_en Dev loss: 0.3254 r:0.8232
Current avg r:0.6687 Best avg r: 0.6721
00:32:50,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:33:16,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:33:42,305 root INFO Epoch 17 Global steps: 53400 Train loss: 0.0574
en_zh Dev loss: 0.7256 r:0.5109
ro_en Dev loss: 0.3327 r:0.8268
Current avg r:0.6688 Best avg r: 0.6721
00:34:58,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:24,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:50,303 root INFO Epoch 17 Global steps: 53600 Train loss: 0.0541
en_zh Dev loss: 0.7334 r:0.5073
ro_en Dev loss: 0.3240 r:0.8271
Current avg r:0.6672 Best avg r: 0.6721
00:37:06,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:32,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:58,211 root INFO Epoch 17 Global steps: 53800 Train loss: 0.0537
en_zh Dev loss: 0.7272 r:0.5092
ro_en Dev loss: 0.3470 r:0.8257
Current avg r:0.6675 Best avg r: 0.6721
00:39:14,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:39:40,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:06,100 root INFO Epoch 17 Global steps: 54000 Train loss: 0.0528
en_zh Dev loss: 0.7770 r:0.4993
ro_en Dev loss: 0.3754 r:0.8213
Current avg r:0.6603 Best avg r: 0.6721
00:41:22,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:48,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:14,382 root INFO Epoch 18 Global steps: 54200 Train loss: 0.0558
en_zh Dev loss: 0.7001 r:0.5098
ro_en Dev loss: 0.3209 r:0.8261
Current avg r:0.6679 Best avg r: 0.6721
00:43:30,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:56,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:22,197 root INFO Epoch 18 Global steps: 54400 Train loss: 0.0562
en_zh Dev loss: 0.7127 r:0.5103
ro_en Dev loss: 0.3368 r:0.8240
Current avg r:0.6671 Best avg r: 0.6721
00:45:38,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:04,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:30,165 root INFO Epoch 18 Global steps: 54600 Train loss: 0.0542
en_zh Dev loss: 0.7060 r:0.5163
ro_en Dev loss: 0.3354 r:0.8220
Current avg r:0.6692 Best avg r: 0.6721
00:47:46,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:12,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:48:38,149 root INFO Epoch 18 Global steps: 54800 Train loss: 0.0509
en_zh Dev loss: 0.7370 r:0.5168
ro_en Dev loss: 0.3630 r:0.8232
Current avg r:0.6700 Best avg r: 0.6721
00:49:54,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:20,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:46,167 root INFO Epoch 18 Global steps: 55000 Train loss: 0.0521
en_zh Dev loss: 0.7521 r:0.5149
ro_en Dev loss: 0.3616 r:0.8207
Current avg r:0.6678 Best avg r: 0.6721
00:52:02,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:28,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:54,101 root INFO Epoch 18 Global steps: 55200 Train loss: 0.0526
en_zh Dev loss: 0.7417 r:0.5109
ro_en Dev loss: 0.3460 r:0.8237
Current avg r:0.6673 Best avg r: 0.6721
00:54:10,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:54:36,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:01,872 root INFO Epoch 18 Global steps: 55400 Train loss: 0.0507
en_zh Dev loss: 0.7126 r:0.5176
ro_en Dev loss: 0.3227 r:0.8252
Current avg r:0.6714 Best avg r: 0.6721
00:56:18,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:44,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:09,798 root INFO Epoch 18 Global steps: 55600 Train loss: 0.0515
en_zh Dev loss: 0.7430 r:0.5086
ro_en Dev loss: 0.3550 r:0.8205
Current avg r:0.6645 Best avg r: 0.6721
00:58:26,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:52,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:17,758 root INFO Epoch 18 Global steps: 55800 Train loss: 0.0517
en_zh Dev loss: 0.7216 r:0.5148
ro_en Dev loss: 0.3354 r:0.8234
Current avg r:0.6691 Best avg r: 0.6721
01:00:34,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:59,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:25,672 root INFO Epoch 18 Global steps: 56000 Train loss: 0.0527
en_zh Dev loss: 0.7214 r:0.5172
ro_en Dev loss: 0.3396 r:0.8245
Current avg r:0.6709 Best avg r: 0.6721
01:02:42,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:07,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:33,573 root INFO Epoch 18 Global steps: 56200 Train loss: 0.0530
en_zh Dev loss: 0.7302 r:0.5161
ro_en Dev loss: 0.3501 r:0.8249
Current avg r:0.6705 Best avg r: 0.6721
01:04:50,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:15,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:41,573 root INFO Epoch 18 Global steps: 56400 Train loss: 0.0533
en_zh Dev loss: 0.7111 r:0.5166
ro_en Dev loss: 0.3260 r:0.8262
Current avg r:0.6714 Best avg r: 0.6721
01:06:58,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:23,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:49,520 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:07:49,534 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:08:15,232 root INFO Epoch 18 Global steps: 56600 Train loss: 0.0485
en_zh Dev loss: 0.7002 r:0.5206
ro_en Dev loss: 0.3157 r:0.8264
Current avg r:0.6735 Best avg r: 0.6735
01:09:31,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:57,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:22,951 root INFO Epoch 18 Global steps: 56800 Train loss: 0.0519
en_zh Dev loss: 0.7056 r:0.5173
ro_en Dev loss: 0.3333 r:0.8233
Current avg r:0.6703 Best avg r: 0.6735
01:11:39,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:05,241 root INFO 
id:en_zh cur r: 0.5230 best r: 0.5230
01:12:18,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:43,813 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:12:43,818 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:13:09,537 root INFO Epoch 18 Global steps: 57000 Train loss: 0.0540
en_zh Dev loss: 0.6781 r:0.5227
ro_en Dev loss: 0.3168 r:0.8262
Current avg r:0.6745 Best avg r: 0.6745
01:14:26,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:52,159 root INFO 
id:en_zh cur r: 0.5230 best r: 0.5230
01:15:05,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:30,728 root INFO Epoch 19 Global steps: 57200 Train loss: 0.0551
en_zh Dev loss: 0.7081 r:0.5218
ro_en Dev loss: 0.3374 r:0.8239
Current avg r:0.6729 Best avg r: 0.6745
01:16:47,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:12,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:38,564 root INFO Epoch 19 Global steps: 57400 Train loss: 0.0495
en_zh Dev loss: 0.7001 r:0.5216
ro_en Dev loss: 0.3232 r:0.8264
Current avg r:0.6740 Best avg r: 0.6745
01:18:55,104 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:20,806 root INFO 
id:en_zh cur r: 0.5239 best r: 0.5239
01:19:33,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:59,377 root INFO Epoch 19 Global steps: 57600 Train loss: 0.0497
en_zh Dev loss: 0.7194 r:0.5226
ro_en Dev loss: 0.3533 r:0.8240
Current avg r:0.6733 Best avg r: 0.6745
01:21:15,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:41,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:22:07,292 root INFO Epoch 19 Global steps: 57800 Train loss: 0.0455
en_zh Dev loss: 0.7363 r:0.5175
ro_en Dev loss: 0.3393 r:0.8228
Current avg r:0.6702 Best avg r: 0.6745
01:23:23,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:49,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:15,148 root INFO Epoch 19 Global steps: 58000 Train loss: 0.0502
en_zh Dev loss: 0.7199 r:0.5181
ro_en Dev loss: 0.3388 r:0.8249
Current avg r:0.6715 Best avg r: 0.6745
01:25:31,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:57,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:23,119 root INFO Epoch 19 Global steps: 58200 Train loss: 0.0467
en_zh Dev loss: 0.7656 r:0.5152
ro_en Dev loss: 0.3486 r:0.8246
Current avg r:0.6699 Best avg r: 0.6745
01:27:39,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:05,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:31,147 root INFO Epoch 19 Global steps: 58400 Train loss: 0.0472
en_zh Dev loss: 0.7250 r:0.5128
ro_en Dev loss: 0.3333 r:0.8255
Current avg r:0.6692 Best avg r: 0.6745
01:29:47,781 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:13,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:39,156 root INFO Epoch 19 Global steps: 58600 Train loss: 0.0503
en_zh Dev loss: 0.7047 r:0.5138
ro_en Dev loss: 0.3056 r:0.8279
Current avg r:0.6709 Best avg r: 0.6745
01:31:55,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:32:21,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:46,962 root INFO Epoch 19 Global steps: 58800 Train loss: 0.0493
en_zh Dev loss: 0.7335 r:0.5148
ro_en Dev loss: 0.3179 r:0.8258
Current avg r:0.6703 Best avg r: 0.6745
01:34:03,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:34:29,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:54,774 root INFO Epoch 19 Global steps: 59000 Train loss: 0.0504
en_zh Dev loss: 0.7550 r:0.5153
ro_en Dev loss: 0.3593 r:0.8251
Current avg r:0.6702 Best avg r: 0.6745
01:36:11,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:36:37,11 root INFO 
id:en_zh cur r: 0.5265 best r: 0.5265
01:36:49,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:15,609 root INFO Epoch 19 Global steps: 59200 Train loss: 0.0480
en_zh Dev loss: 0.7317 r:0.5234
ro_en Dev loss: 0.3595 r:0.8239
Current avg r:0.6737 Best avg r: 0.6745
01:38:32,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:38:57,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:23,534 root INFO Epoch 19 Global steps: 59400 Train loss: 0.0474
en_zh Dev loss: 0.6985 r:0.5133
ro_en Dev loss: 0.3158 r:0.8246
Current avg r:0.6689 Best avg r: 0.6745
01:40:40,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:41:05,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:41:31,368 root INFO Epoch 19 Global steps: 59600 Train loss: 0.0505
en_zh Dev loss: 0.7584 r:0.5135
ro_en Dev loss: 0.3601 r:0.8211
Current avg r:0.6673 Best avg r: 0.6745
01:42:47,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:13,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:39,349 root INFO Epoch 19 Global steps: 59800 Train loss: 0.0472
en_zh Dev loss: 0.7586 r:0.5072
ro_en Dev loss: 0.3419 r:0.8237
Current avg r:0.6654 Best avg r: 0.6745
01:44:55,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:45:21,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:47,275 root INFO Epoch 19 Global steps: 60000 Train loss: 0.0467
en_zh Dev loss: 0.7553 r:0.5156
ro_en Dev loss: 0.3510 r:0.8229
Current avg r:0.6692 Best avg r: 0.6745
00:34:50,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:16,249 root INFO 
id:en_zh cur r: 0.1749 best r: 0.1749
00:35:29,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:55,433 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:35:55,444 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
00:36:21,594 root INFO Epoch 0 Global steps: 200 Train loss: 0.9093
en_zh Dev loss: 0.8069 r:0.1682
ro_en Dev loss: 0.8335 r:0.3950
Current avg r:0.2816 Best avg r: 0.2816
00:37:38,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:38:04,842 root INFO 
id:en_zh cur r: 0.2274 best r: 0.2274
00:38:31,73 root INFO 
id:ro_en cur r: 0.0739 best r: 0.0739
00:38:31,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:57,244 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:38:57,254 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
00:39:23,459 root INFO Epoch 0 Global steps: 400 Train loss: 0.8505
en_zh Dev loss: 0.8002 r:0.2366
ro_en Dev loss: 0.8089 r:0.4862
Current avg r:0.3614 Best avg r: 0.3614
00:40:40,581 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:06,750 root INFO 
id:en_zh cur r: 0.2749 best r: 0.2749
00:41:33,9 root INFO 
id:ro_en cur r: 0.2362 best r: 0.2362
00:41:33,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:59,223 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:41:59,231 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
00:42:25,447 root INFO Epoch 0 Global steps: 600 Train loss: 0.8758
en_zh Dev loss: 0.7975 r:0.2699
ro_en Dev loss: 0.7826 r:0.5394
Current avg r:0.4046 Best avg r: 0.4046
00:43:42,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:09,63 root INFO 
id:en_zh cur r: 0.2860 best r: 0.2860
00:44:35,317 root INFO 
id:ro_en cur r: 0.5481 best r: 0.5481
00:44:35,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:01,508 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:45:01,514 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
00:45:27,738 root INFO Epoch 0 Global steps: 800 Train loss: 0.9224
en_zh Dev loss: 0.7584 r:0.2931
ro_en Dev loss: 0.7399 r:0.5893
Current avg r:0.4412 Best avg r: 0.4412
00:46:44,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:47:24,247 root INFO 
id:ro_en cur r: 0.5746 best r: 0.5746
00:47:24,247 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:50,428 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:47:50,433 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
00:48:16,659 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8089
en_zh Dev loss: 0.7426 r:0.3140
ro_en Dev loss: 0.7088 r:0.6034
Current avg r:0.4587 Best avg r: 0.4587
00:49:33,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:00,92 root INFO 
id:en_zh cur r: 0.2874 best r: 0.2874
00:50:26,351 root INFO 
id:ro_en cur r: 0.6084 best r: 0.6084
00:50:26,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:52,569 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:50:52,575 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
00:51:18,819 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7670
en_zh Dev loss: 0.7814 r:0.3102
ro_en Dev loss: 0.7019 r:0.6172
Current avg r:0.4637 Best avg r: 0.4637
00:52:36,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:02,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:53:28,435 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8211
en_zh Dev loss: 0.8409 r:0.2939
ro_en Dev loss: 0.7127 r:0.6127
Current avg r:0.4533 Best avg r: 0.4637
00:54:45,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:11,844 root INFO 
id:en_zh cur r: 0.3187 best r: 0.3187
00:55:38,55 root INFO 
id:ro_en cur r: 0.6420 best r: 0.6420
00:55:38,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:56:04,194 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:56:04,200 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
00:56:30,367 root INFO Epoch 0 Global steps: 1600 Train loss: 0.6904
en_zh Dev loss: 0.7669 r:0.3452
ro_en Dev loss: 0.5740 r:0.6505
Current avg r:0.4978 Best avg r: 0.4978
00:57:47,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:13,496 root INFO 
id:en_zh cur r: 0.3500 best r: 0.3500
00:58:39,712 root INFO 
id:ro_en cur r: 0.6664 best r: 0.6664
00:58:39,712 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:05,895 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:59:05,901 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
00:59:32,91 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7024
en_zh Dev loss: 0.7402 r:0.3769
ro_en Dev loss: 0.5208 r:0.6659
Current avg r:0.5214 Best avg r: 0.5214
01:00:49,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:01:15,353 root INFO 
id:en_zh cur r: 0.3894 best r: 0.3894
01:01:41,625 root INFO 
id:ro_en cur r: 0.6974 best r: 0.6974
01:01:41,626 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:07,837 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:02:07,843 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:02:34,99 root INFO Epoch 0 Global steps: 2000 Train loss: 0.6015
en_zh Dev loss: 0.7082 r:0.3988
ro_en Dev loss: 0.4783 r:0.6940
Current avg r:0.5464 Best avg r: 0.5464
01:03:51,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:30,719 root INFO 
id:ro_en cur r: 0.7053 best r: 0.7053
01:04:30,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:56,940 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:04:56,948 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:05:23,200 root INFO Epoch 0 Global steps: 2200 Train loss: 0.6256
en_zh Dev loss: 0.7644 r:0.3871
ro_en Dev loss: 0.5975 r:0.7076
Current avg r:0.5473 Best avg r: 0.5473
01:06:40,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:06,602 root INFO 
id:en_zh cur r: 0.3918 best r: 0.3918
01:07:32,850 root INFO 
id:ro_en cur r: 0.7267 best r: 0.7267
01:07:32,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:59,39 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:07:59,45 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:08:25,236 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6385
en_zh Dev loss: 0.7339 r:0.4053
ro_en Dev loss: 0.4646 r:0.7233
Current avg r:0.5643 Best avg r: 0.5643
01:09:42,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:08,354 root INFO 
id:en_zh cur r: 0.4149 best r: 0.4149
01:10:34,546 root INFO 
id:ro_en cur r: 0.7334 best r: 0.7334
01:10:34,546 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:00,708 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:11:00,715 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:11:26,894 root INFO Epoch 0 Global steps: 2600 Train loss: 0.5840
en_zh Dev loss: 0.7368 r:0.4185
ro_en Dev loss: 0.4784 r:0.7324
Current avg r:0.5755 Best avg r: 0.5755
01:12:43,916 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:10,64 root INFO 
id:en_zh cur r: 0.4168 best r: 0.4168
01:13:36,292 root INFO 
id:ro_en cur r: 0.7451 best r: 0.7451
01:13:36,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:02,493 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:14:02,499 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:14:28,737 root INFO Epoch 0 Global steps: 2800 Train loss: 0.5506
en_zh Dev loss: 0.7153 r:0.4204
ro_en Dev loss: 0.4187 r:0.7428
Current avg r:0.5816 Best avg r: 0.5816
01:15:45,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:25,283 root INFO 
id:ro_en cur r: 0.7584 best r: 0.7584
01:16:25,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:51,512 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:16:51,517 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:17:17,765 root INFO Epoch 0 Global steps: 3000 Train loss: 0.5327
en_zh Dev loss: 0.7813 r:0.4074
ro_en Dev loss: 0.4866 r:0.7578
Current avg r:0.5826 Best avg r: 0.5826
01:18:35,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:01,374 root INFO 
id:en_zh cur r: 0.4295 best r: 0.4295
01:19:27,578 root INFO 
id:ro_en cur r: 0.7692 best r: 0.7692
01:19:27,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:53,755 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:19:53,761 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
09:53:19,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:45,923 root INFO 
id:en_zh cur r: 0.1305 best r: 0.1305
09:54:11,946 root INFO 
id:ro_en cur r: 0.3190 best r: 0.3190
09:54:11,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:54:37,899 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
09:54:37,920 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
09:55:03,895 root INFO Epoch 0 Global steps: 200 Train loss: 0.8515
en_zh Dev loss: 0.8123 r:0.1240
ro_en Dev loss: 0.8457 r:0.2335
Current avg r:0.1787 Best avg r: 0.1787
09:56:20,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:46,326 root INFO 
id:en_zh cur r: 0.2420 best r: 0.2420
09:57:12,309 root INFO 
id:ro_en cur r: 0.5021 best r: 0.5021
09:57:12,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:38,273 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
09:57:38,279 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
09:58:04,239 root INFO Epoch 0 Global steps: 400 Train loss: 0.9309
en_zh Dev loss: 0.8028 r:0.2398
ro_en Dev loss: 0.8335 r:0.4734
Current avg r:0.3566 Best avg r: 0.3566
09:59:20,818 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:59:46,744 root INFO 
id:en_zh cur r: 0.2766 best r: 0.2766
09:59:59,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:25,648 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:00:25,654 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:00:51,605 root INFO Epoch 0 Global steps: 600 Train loss: 0.9081
en_zh Dev loss: 0.7991 r:0.2696
ro_en Dev loss: 0.8171 r:0.5002
Current avg r:0.3849 Best avg r: 0.3849
10:02:08,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:34,25 root INFO 
id:en_zh cur r: 0.2883 best r: 0.2883
10:02:47,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:12,971 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:03:12,977 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:03:38,961 root INFO Epoch 0 Global steps: 800 Train loss: 0.8090
en_zh Dev loss: 0.7669 r:0.2757
ro_en Dev loss: 0.7079 r:0.5402
Current avg r:0.4080 Best avg r: 0.4080
10:04:55,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:21,354 root INFO 
id:en_zh cur r: 0.3100 best r: 0.3100
10:05:47,353 root INFO 
id:ro_en cur r: 0.5441 best r: 0.5441
10:05:47,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:13,291 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:06:13,298 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:06:39,263 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7969
en_zh Dev loss: 0.7563 r:0.3022
ro_en Dev loss: 0.6301 r:0.5734
Current avg r:0.4378 Best avg r: 0.4378
10:07:55,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:21,629 root INFO 
id:en_zh cur r: 0.3150 best r: 0.3150
10:08:47,619 root INFO 
id:ro_en cur r: 0.6319 best r: 0.6319
10:08:47,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:13,564 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:09:13,572 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:09:39,526 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7262
en_zh Dev loss: 0.7398 r:0.3183
ro_en Dev loss: 0.5140 r:0.6494
Current avg r:0.4839 Best avg r: 0.4839
10:10:55,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:21,864 root INFO 
id:en_zh cur r: 0.3474 best r: 0.3474
10:11:47,837 root INFO 
id:ro_en cur r: 0.6603 best r: 0.6603
10:11:47,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:13,769 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:12:13,776 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:12:39,769 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7118
en_zh Dev loss: 0.7264 r:0.3431
ro_en Dev loss: 0.4870 r:0.6693
Current avg r:0.5062 Best avg r: 0.5062
10:13:56,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:35,123 root INFO 
id:ro_en cur r: 0.6733 best r: 0.6733
10:14:35,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:01,78 root INFO Epoch 0 Global steps: 1600 Train loss: 0.6773
en_zh Dev loss: 0.7538 r:0.3247
ro_en Dev loss: 0.4773 r:0.6810
Current avg r:0.5028 Best avg r: 0.5062
10:16:17,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:43,548 root INFO 
id:en_zh cur r: 0.3492 best r: 0.3492
10:17:09,569 root INFO 
id:ro_en cur r: 0.6866 best r: 0.6866
10:17:09,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:35,498 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:17:35,504 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:18:01,533 root INFO Epoch 0 Global steps: 1800 Train loss: 0.6343
en_zh Dev loss: 0.7898 r:0.3385
ro_en Dev loss: 0.5016 r:0.6854
Current avg r:0.5119 Best avg r: 0.5119
10:19:17,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:43,908 root INFO 
id:en_zh cur r: 0.3801 best r: 0.3801
10:20:09,942 root INFO 
id:ro_en cur r: 0.7109 best r: 0.7109
10:20:09,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:35,905 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:20:35,912 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:21:01,917 root INFO Epoch 0 Global steps: 2000 Train loss: 0.6021
en_zh Dev loss: 0.7157 r:0.3821
ro_en Dev loss: 0.4328 r:0.7093
Current avg r:0.5457 Best avg r: 0.5457
10:22:18,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:22:44,328 root INFO 
id:en_zh cur r: 0.4097 best r: 0.4097
10:23:10,316 root INFO 
id:ro_en cur r: 0.7297 best r: 0.7297
10:23:10,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:36,245 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:23:36,254 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:24:02,239 root INFO Epoch 0 Global steps: 2200 Train loss: 0.5717
en_zh Dev loss: 0.6996 r:0.4139
ro_en Dev loss: 0.4219 r:0.7299
Current avg r:0.5719 Best avg r: 0.5719
10:25:18,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:57,615 root INFO 
id:ro_en cur r: 0.7437 best r: 0.7437
10:25:57,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:23,581 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:26:23,586 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:26:49,551 root INFO Epoch 0 Global steps: 2400 Train loss: 0.5107
en_zh Dev loss: 0.7294 r:0.4081
ro_en Dev loss: 0.4477 r:0.7403
Current avg r:0.5742 Best avg r: 0.5742
10:28:06,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:31,940 root INFO 
id:en_zh cur r: 0.4251 best r: 0.4251
10:28:57,939 root INFO 
id:ro_en cur r: 0.7481 best r: 0.7481
10:28:57,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:23,891 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:29:23,900 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:29:49,859 root INFO Epoch 0 Global steps: 2600 Train loss: 0.5913
en_zh Dev loss: 0.7025 r:0.4291
ro_en Dev loss: 0.4266 r:0.7465
Current avg r:0.5878 Best avg r: 0.5878
10:31:06,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:31:32,290 root INFO 
id:en_zh cur r: 0.4332 best r: 0.4332
10:31:58,318 root INFO 
id:ro_en cur r: 0.7529 best r: 0.7529
10:31:58,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:32:24,257 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:32:24,264 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:32:50,283 root INFO Epoch 0 Global steps: 2800 Train loss: 0.5775
en_zh Dev loss: 0.6662 r:0.4430
ro_en Dev loss: 0.3752 r:0.7505
Current avg r:0.5967 Best avg r: 0.5967
10:34:06,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:34:45,700 root INFO 
id:ro_en cur r: 0.7683 best r: 0.7683
10:34:45,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:35:11,615 root INFO Epoch 0 Global steps: 3000 Train loss: 0.5683
en_zh Dev loss: 0.6998 r:0.4231
ro_en Dev loss: 0.3824 r:0.7668
Current avg r:0.5949 Best avg r: 0.5967
10:36:28,355 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:36:54,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:37:20,186 root INFO Epoch 1 Global steps: 3200 Train loss: 0.4983
en_zh Dev loss: 0.7366 r:0.4235
ro_en Dev loss: 0.4096 r:0.7679
Current avg r:0.5957 Best avg r: 0.5967
10:38:36,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:39:15,528 root INFO 
id:ro_en cur r: 0.7753 best r: 0.7753
10:39:15,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:39:41,433 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:39:41,439 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:40:07,379 root INFO Epoch 1 Global steps: 3400 Train loss: 0.4877
en_zh Dev loss: 0.7130 r:0.4323
ro_en Dev loss: 0.3928 r:0.7738
Current avg r:0.6031 Best avg r: 0.6031
10:41:23,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:42:02,660 root INFO 
id:ro_en cur r: 0.7774 best r: 0.7774
10:42:02,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:42:28,564 root INFO Epoch 1 Global steps: 3600 Train loss: 0.4817
en_zh Dev loss: 0.7115 r:0.4283
ro_en Dev loss: 0.4209 r:0.7740
Current avg r:0.6011 Best avg r: 0.6031
10:43:44,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:44:10,878 root INFO 
id:en_zh cur r: 0.4492 best r: 0.4492
10:44:36,866 root INFO 
id:ro_en cur r: 0.7951 best r: 0.7951
10:44:36,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:45:02,776 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:45:02,783 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:45:28,734 root INFO Epoch 1 Global steps: 3800 Train loss: 0.4522
en_zh Dev loss: 0.6803 r:0.4484
ro_en Dev loss: 0.3794 r:0.7906
Current avg r:0.6195 Best avg r: 0.6195
10:46:45,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:47:11,14 root INFO 
id:en_zh cur r: 0.4510 best r: 0.4510
10:47:36,979 root INFO 
id:ro_en cur r: 0.7953 best r: 0.7953
10:47:36,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:48:02,893 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:48:02,904 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:48:28,838 root INFO Epoch 1 Global steps: 4000 Train loss: 0.5073
en_zh Dev loss: 0.6934 r:0.4475
ro_en Dev loss: 0.3580 r:0.7920
Current avg r:0.6197 Best avg r: 0.6197
10:49:45,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:50:24,189 root INFO 
id:ro_en cur r: 0.7985 best r: 0.7985
10:50:24,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:50:50,109 root INFO Epoch 1 Global steps: 4200 Train loss: 0.4893
en_zh Dev loss: 0.7255 r:0.4299
ro_en Dev loss: 0.3405 r:0.7956
Current avg r:0.6127 Best avg r: 0.6197
10:52:06,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:52:32,445 root INFO 
id:en_zh cur r: 0.4708 best r: 0.4708
10:52:45,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:53:11,322 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:53:11,346 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:53:37,280 root INFO Epoch 1 Global steps: 4400 Train loss: 0.4585
en_zh Dev loss: 0.6578 r:0.4675
ro_en Dev loss: 0.3470 r:0.7954
Current avg r:0.6314 Best avg r: 0.6314
10:54:53,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:55:19,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:55:45,585 root INFO Epoch 1 Global steps: 4600 Train loss: 0.4527
en_zh Dev loss: 0.7347 r:0.4510
ro_en Dev loss: 0.3671 r:0.7992
Current avg r:0.6251 Best avg r: 0.6314
10:57:02,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:57:40,947 root INFO 
id:ro_en cur r: 0.8104 best r: 0.8104
10:57:40,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:58:06,853 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:58:06,859 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:58:32,818 root INFO Epoch 1 Global steps: 4800 Train loss: 0.4551
en_zh Dev loss: 0.6727 r:0.4639
ro_en Dev loss: 0.3267 r:0.8059
Current avg r:0.6349 Best avg r: 0.6349
10:59:49,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:00:15,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:00:41,89 root INFO Epoch 1 Global steps: 5000 Train loss: 0.4619
en_zh Dev loss: 0.7196 r:0.4580
ro_en Dev loss: 0.3904 r:0.8031
Current avg r:0.6306 Best avg r: 0.6349
11:01:57,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:02:23,452 root INFO 
id:en_zh cur r: 0.4803 best r: 0.4803
11:02:49,424 root INFO 
id:ro_en cur r: 0.8131 best r: 0.8131
11:02:49,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:03:15,336 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:03:15,342 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
11:03:41,303 root INFO Epoch 1 Global steps: 5200 Train loss: 0.4368
en_zh Dev loss: 0.6689 r:0.4837
ro_en Dev loss: 0.3539 r:0.8104
Current avg r:0.6470 Best avg r: 0.6470
11:04:57,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:05:23,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:05:49,686 root INFO Epoch 1 Global steps: 5400 Train loss: 0.4038
en_zh Dev loss: 0.7137 r:0.4678
ro_en Dev loss: 0.3371 r:0.8027
Current avg r:0.6352 Best avg r: 0.6470
11:07:06,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:07:32,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:07:58,48 root INFO Epoch 1 Global steps: 5600 Train loss: 0.4771
en_zh Dev loss: 0.6622 r:0.4704
ro_en Dev loss: 0.3091 r:0.8083
Current avg r:0.6393 Best avg r: 0.6470
11:09:14,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:09:53,435 root INFO 
id:ro_en cur r: 0.8137 best r: 0.8137
11:09:53,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:10:19,354 root INFO Epoch 1 Global steps: 5800 Train loss: 0.4680
en_zh Dev loss: 0.7037 r:0.4738
ro_en Dev loss: 0.3291 r:0.8092
Current avg r:0.6415 Best avg r: 0.6470
11:11:35,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:12:01,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:12:27,650 root INFO Epoch 1 Global steps: 6000 Train loss: 0.4416
en_zh Dev loss: 0.6492 r:0.4768
ro_en Dev loss: 0.3256 r:0.8103
Current avg r:0.6436 Best avg r: 0.6470
11:13:44,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:14:10,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:14:36,332 root INFO Epoch 2 Global steps: 6200 Train loss: 0.3931
en_zh Dev loss: 0.7739 r:0.4499
ro_en Dev loss: 0.3498 r:0.8110
Current avg r:0.6304 Best avg r: 0.6470
11:15:52,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:16:18,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:16:44,716 root INFO Epoch 2 Global steps: 6400 Train loss: 0.3836
en_zh Dev loss: 0.6708 r:0.4747
ro_en Dev loss: 0.3387 r:0.8107
Current avg r:0.6427 Best avg r: 0.6470
11:18:01,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:18:27,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:18:53,78 root INFO Epoch 2 Global steps: 6600 Train loss: 0.3912
en_zh Dev loss: 0.7183 r:0.4581
ro_en Dev loss: 0.3527 r:0.8073
Current avg r:0.6327 Best avg r: 0.6470
11:20:09,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:20:48,560 root INFO 
id:ro_en cur r: 0.8161 best r: 0.8161
11:20:48,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:21:14,525 root INFO Epoch 2 Global steps: 6800 Train loss: 0.4215
en_zh Dev loss: 0.6756 r:0.4770
ro_en Dev loss: 0.3525 r:0.8121
Current avg r:0.6446 Best avg r: 0.6470
11:22:30,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:22:56,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:23:22,909 root INFO Epoch 2 Global steps: 7000 Train loss: 0.3952
en_zh Dev loss: 0.7536 r:0.4615
ro_en Dev loss: 0.3934 r:0.8058
Current avg r:0.6336 Best avg r: 0.6470
11:24:39,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:25:18,397 root INFO 
id:ro_en cur r: 0.8171 best r: 0.8171
11:25:18,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:25:44,341 root INFO Epoch 2 Global steps: 7200 Train loss: 0.4141
en_zh Dev loss: 0.7045 r:0.4736
ro_en Dev loss: 0.3420 r:0.8127
Current avg r:0.6431 Best avg r: 0.6470
11:27:00,832 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:27:39,791 root INFO 
id:ro_en cur r: 0.8198 best r: 0.8198
11:27:39,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:28:05,733 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:28:05,740 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
11:28:31,763 root INFO Epoch 2 Global steps: 7400 Train loss: 0.4174
en_zh Dev loss: 0.6770 r:0.4798
ro_en Dev loss: 0.2948 r:0.8200
Current avg r:0.6499 Best avg r: 0.6499
11:29:48,294 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:30:14,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:30:40,184 root INFO Epoch 2 Global steps: 7600 Train loss: 0.3860
en_zh Dev loss: 0.7525 r:0.4626
ro_en Dev loss: 0.3348 r:0.8156
Current avg r:0.6391 Best avg r: 0.6499
11:31:56,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:32:22,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:32:48,540 root INFO Epoch 2 Global steps: 7800 Train loss: 0.3770
en_zh Dev loss: 0.7016 r:0.4718
ro_en Dev loss: 0.3448 r:0.8141
Current avg r:0.6430 Best avg r: 0.6499
11:34:05,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:34:30,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:34:56,932 root INFO Epoch 2 Global steps: 8000 Train loss: 0.3638
en_zh Dev loss: 0.6913 r:0.4727
ro_en Dev loss: 0.3553 r:0.8105
Current avg r:0.6416 Best avg r: 0.6499
11:36:13,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:36:39,380 root INFO 
id:en_zh cur r: 0.4824 best r: 0.4824
11:36:52,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:37:18,327 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:37:18,333 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
11:37:44,316 root INFO Epoch 2 Global steps: 8200 Train loss: 0.3820
en_zh Dev loss: 0.6716 r:0.4828
ro_en Dev loss: 0.3177 r:0.8173
Current avg r:0.6501 Best avg r: 0.6501
11:39:00,781 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:39:26,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:39:52,667 root INFO Epoch 2 Global steps: 8400 Train loss: 0.4016
en_zh Dev loss: 0.7832 r:0.4819
ro_en Dev loss: 0.3884 r:0.8155
Current avg r:0.6487 Best avg r: 0.6501
11:41:09,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:41:35,224 root INFO 
id:en_zh cur r: 0.4936 best r: 0.4936
11:41:48,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:42:14,169 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:42:14,175 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
11:42:40,148 root INFO Epoch 2 Global steps: 8600 Train loss: 0.3918
en_zh Dev loss: 0.6733 r:0.4912
ro_en Dev loss: 0.3193 r:0.8174
Current avg r:0.6543 Best avg r: 0.6543
11:43:56,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:44:22,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:44:48,527 root INFO Epoch 2 Global steps: 8800 Train loss: 0.4056
en_zh Dev loss: 0.6883 r:0.4845
ro_en Dev loss: 0.3299 r:0.8183
Current avg r:0.6514 Best avg r: 0.6543
11:46:05,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:46:30,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:46:56,938 root INFO Epoch 2 Global steps: 9000 Train loss: 0.3837
en_zh Dev loss: 0.6962 r:0.4877
ro_en Dev loss: 0.3710 r:0.8181
Current avg r:0.6529 Best avg r: 0.6543
11:48:13,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:48:52,811 root INFO 
id:ro_en cur r: 0.8237 best r: 0.8237
11:48:52,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:49:18,769 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:49:18,775 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
11:49:44,788 root INFO Epoch 3 Global steps: 9200 Train loss: 0.3586
en_zh Dev loss: 0.6883 r:0.4899
ro_en Dev loss: 0.3024 r:0.8267
Current avg r:0.6583 Best avg r: 0.6583
11:51:01,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:51:27,279 root INFO 
id:en_zh cur r: 0.4940 best r: 0.4940
11:51:53,318 root INFO 
id:ro_en cur r: 0.8240 best r: 0.8240
11:51:53,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:52:19,296 root INFO Epoch 3 Global steps: 9400 Train loss: 0.3510
en_zh Dev loss: 0.6837 r:0.4906
ro_en Dev loss: 0.3181 r:0.8242
Current avg r:0.6574 Best avg r: 0.6583
11:53:35,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:54:01,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:54:27,740 root INFO Epoch 3 Global steps: 9600 Train loss: 0.3494
en_zh Dev loss: 0.7268 r:0.4856
ro_en Dev loss: 0.3758 r:0.8181
Current avg r:0.6518 Best avg r: 0.6583
11:55:44,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:56:10,171 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:56:36,106 root INFO Epoch 3 Global steps: 9800 Train loss: 0.3347
en_zh Dev loss: 0.7147 r:0.4879
ro_en Dev loss: 0.3046 r:0.8205
Current avg r:0.6542 Best avg r: 0.6583
11:57:52,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:58:18,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:58:44,577 root INFO Epoch 3 Global steps: 10000 Train loss: 0.3430
en_zh Dev loss: 0.7451 r:0.4764
ro_en Dev loss: 0.3597 r:0.8129
Current avg r:0.6446 Best avg r: 0.6583
12:00:01,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:00:27,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:00:52,954 root INFO Epoch 3 Global steps: 10200 Train loss: 0.3584
en_zh Dev loss: 0.6749 r:0.4876
ro_en Dev loss: 0.3153 r:0.8180
Current avg r:0.6528 Best avg r: 0.6583
12:02:09,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:02:35,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:03:01,338 root INFO Epoch 3 Global steps: 10400 Train loss: 0.3451
en_zh Dev loss: 0.7202 r:0.4611
ro_en Dev loss: 0.3240 r:0.8172
Current avg r:0.6391 Best avg r: 0.6583
12:04:17,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:04:43,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:05:09,794 root INFO Epoch 3 Global steps: 10600 Train loss: 0.2828
en_zh Dev loss: 0.7859 r:0.4689
ro_en Dev loss: 0.4004 r:0.8112
Current avg r:0.6400 Best avg r: 0.6583
12:06:26,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:06:52,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:07:18,244 root INFO Epoch 3 Global steps: 10800 Train loss: 0.3548
en_zh Dev loss: 0.8753 r:0.4540
ro_en Dev loss: 0.4631 r:0.8039
Current avg r:0.6289 Best avg r: 0.6583
12:08:34,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:09:00,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:09:26,640 root INFO Epoch 3 Global steps: 11000 Train loss: 0.3486
en_zh Dev loss: 0.7281 r:0.4806
ro_en Dev loss: 0.3551 r:0.8162
Current avg r:0.6484 Best avg r: 0.6583
12:10:43,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:11:09,150 root INFO 
id:en_zh cur r: 0.4981 best r: 0.4981
12:11:35,168 root INFO 
id:ro_en cur r: 0.8248 best r: 0.8248
12:11:35,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:12:01,105 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
12:12:01,112 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
12:12:27,94 root INFO Epoch 3 Global steps: 11200 Train loss: 0.3457
en_zh Dev loss: 0.6543 r:0.4950
ro_en Dev loss: 0.3097 r:0.8230
Current avg r:0.6590 Best avg r: 0.6590
12:13:43,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:14:09,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:14:35,483 root INFO Epoch 3 Global steps: 11400 Train loss: 0.3258
en_zh Dev loss: 0.7752 r:0.4775
ro_en Dev loss: 0.3475 r:0.8206
Current avg r:0.6490 Best avg r: 0.6590
12:15:52,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:16:18,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:16:43,955 root INFO Epoch 3 Global steps: 11600 Train loss: 0.3181
en_zh Dev loss: 0.7152 r:0.4898
ro_en Dev loss: 0.3936 r:0.8159
Current avg r:0.6529 Best avg r: 0.6590
12:18:00,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:18:26,402 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:18:52,351 root INFO Epoch 3 Global steps: 11800 Train loss: 0.3429
en_zh Dev loss: 0.7545 r:0.4745
ro_en Dev loss: 0.3605 r:0.8158
Current avg r:0.6451 Best avg r: 0.6590
12:20:08,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:20:34,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:21:00,808 root INFO Epoch 3 Global steps: 12000 Train loss: 0.3130
en_zh Dev loss: 0.6744 r:0.4863
ro_en Dev loss: 0.3150 r:0.8167
Current avg r:0.6515 Best avg r: 0.6590
12:22:17,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:22:56,838 root INFO 
id:ro_en cur r: 0.8266 best r: 0.8266
12:22:56,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:23:22,802 root INFO Epoch 4 Global steps: 12200 Train loss: 0.2816
en_zh Dev loss: 0.6826 r:0.4897
ro_en Dev loss: 0.2911 r:0.8262
Current avg r:0.6579 Best avg r: 0.6590
12:24:39,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:25:05,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:25:31,347 root INFO Epoch 4 Global steps: 12400 Train loss: 0.2816
en_zh Dev loss: 0.7126 r:0.4825
ro_en Dev loss: 0.3491 r:0.8199
Current avg r:0.6512 Best avg r: 0.6590
12:26:47,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:27:13,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:27:39,895 root INFO Epoch 4 Global steps: 12600 Train loss: 0.2682
en_zh Dev loss: 0.7302 r:0.4729
ro_en Dev loss: 0.3371 r:0.8188
Current avg r:0.6459 Best avg r: 0.6590
12:28:56,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:29:22,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:29:48,487 root INFO Epoch 4 Global steps: 12800 Train loss: 0.2732
en_zh Dev loss: 0.7182 r:0.4789
ro_en Dev loss: 0.3209 r:0.8254
Current avg r:0.6522 Best avg r: 0.6590
12:31:05,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:31:31,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:31:57,20 root INFO Epoch 4 Global steps: 13000 Train loss: 0.2922
en_zh Dev loss: 0.7317 r:0.4774
ro_en Dev loss: 0.3613 r:0.8157
Current avg r:0.6466 Best avg r: 0.6590
12:33:13,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:33:39,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:34:05,452 root INFO Epoch 4 Global steps: 13200 Train loss: 0.3024
en_zh Dev loss: 0.7049 r:0.4756
ro_en Dev loss: 0.3346 r:0.8165
Current avg r:0.6460 Best avg r: 0.6590
12:35:21,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:35:47,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:36:13,847 root INFO Epoch 4 Global steps: 13400 Train loss: 0.2983
en_zh Dev loss: 0.7349 r:0.4777
ro_en Dev loss: 0.3352 r:0.8173
Current avg r:0.6475 Best avg r: 0.6590
12:37:30,403 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:37:56,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:38:22,333 root INFO Epoch 4 Global steps: 13600 Train loss: 0.2984
en_zh Dev loss: 0.6919 r:0.4892
ro_en Dev loss: 0.3239 r:0.8199
Current avg r:0.6545 Best avg r: 0.6590
12:39:38,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:40:04,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:40:30,774 root INFO Epoch 4 Global steps: 13800 Train loss: 0.2770
en_zh Dev loss: 0.7373 r:0.4753
ro_en Dev loss: 0.3457 r:0.8141
Current avg r:0.6447 Best avg r: 0.6590
12:41:47,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:42:13,236 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:42:39,185 root INFO Epoch 4 Global steps: 14000 Train loss: 0.2758
en_zh Dev loss: 0.7122 r:0.4898
ro_en Dev loss: 0.3376 r:0.8129
Current avg r:0.6513 Best avg r: 0.6590
12:43:55,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:44:21,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:44:47,669 root INFO Epoch 4 Global steps: 14200 Train loss: 0.2785
en_zh Dev loss: 0.7299 r:0.4871
ro_en Dev loss: 0.3669 r:0.8170
Current avg r:0.6520 Best avg r: 0.6590
12:46:04,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:46:30,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:46:56,99 root INFO Epoch 4 Global steps: 14400 Train loss: 0.2892
en_zh Dev loss: 0.7780 r:0.4728
ro_en Dev loss: 0.3424 r:0.8204
Current avg r:0.6466 Best avg r: 0.6590
12:48:12,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:48:38,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:49:04,580 root INFO Epoch 4 Global steps: 14600 Train loss: 0.2733
en_zh Dev loss: 0.7188 r:0.4801
ro_en Dev loss: 0.3320 r:0.8210
Current avg r:0.6506 Best avg r: 0.6590
12:50:21,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:50:47,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:51:13,50 root INFO Epoch 4 Global steps: 14800 Train loss: 0.2476
en_zh Dev loss: 0.7090 r:0.4810
ro_en Dev loss: 0.3258 r:0.8196
Current avg r:0.6503 Best avg r: 0.6590
12:52:29,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:52:55,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:53:21,470 root INFO Epoch 4 Global steps: 15000 Train loss: 0.2691
en_zh Dev loss: 0.7011 r:0.4877
ro_en Dev loss: 0.3225 r:0.8213
Current avg r:0.6545 Best avg r: 0.6590
12:54:38,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:55:04,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:55:30,156 root INFO Epoch 5 Global steps: 15200 Train loss: 0.2395
en_zh Dev loss: 0.7887 r:0.4624
ro_en Dev loss: 0.3647 r:0.8158
Current avg r:0.6391 Best avg r: 0.6590
12:56:46,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:57:12,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:57:38,620 root INFO Epoch 5 Global steps: 15400 Train loss: 0.2416
en_zh Dev loss: 0.7528 r:0.4690
ro_en Dev loss: 0.3498 r:0.8143
Current avg r:0.6417 Best avg r: 0.6590
12:58:55,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:59:21,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:59:47,23 root INFO Epoch 5 Global steps: 15600 Train loss: 0.2481
en_zh Dev loss: 0.7338 r:0.4673
ro_en Dev loss: 0.3585 r:0.8136
Current avg r:0.6405 Best avg r: 0.6590
13:01:03,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:01:29,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:01:55,462 root INFO Epoch 5 Global steps: 15800 Train loss: 0.2501
en_zh Dev loss: 0.7344 r:0.4768
ro_en Dev loss: 0.3388 r:0.8198
Current avg r:0.6483 Best avg r: 0.6590
13:03:11,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:03:37,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:04:03,887 root INFO Epoch 5 Global steps: 16000 Train loss: 0.2649
en_zh Dev loss: 0.7280 r:0.4705
ro_en Dev loss: 0.3720 r:0.8157
Current avg r:0.6431 Best avg r: 0.6590
13:05:20,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:05:46,342 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:06:12,304 root INFO Epoch 5 Global steps: 16200 Train loss: 0.2535
en_zh Dev loss: 0.7406 r:0.4705
ro_en Dev loss: 0.3479 r:0.8179
Current avg r:0.6442 Best avg r: 0.6590
13:07:28,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:07:54,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:08:20,779 root INFO Epoch 5 Global steps: 16400 Train loss: 0.2388
en_zh Dev loss: 0.7770 r:0.4575
ro_en Dev loss: 0.3499 r:0.8140
Current avg r:0.6358 Best avg r: 0.6590
13:09:37,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:10:03,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:10:29,282 root INFO Epoch 5 Global steps: 16600 Train loss: 0.2362
en_zh Dev loss: 0.7335 r:0.4868
ro_en Dev loss: 0.3341 r:0.8200
Current avg r:0.6534 Best avg r: 0.6590
13:11:45,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:12:11,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:12:37,793 root INFO Epoch 5 Global steps: 16800 Train loss: 0.2493
en_zh Dev loss: 0.7748 r:0.4699
ro_en Dev loss: 0.3489 r:0.8184
Current avg r:0.6441 Best avg r: 0.6590
13:13:54,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:14:20,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:14:46,249 root INFO Epoch 5 Global steps: 17000 Train loss: 0.2253
en_zh Dev loss: 0.7496 r:0.4672
ro_en Dev loss: 0.3642 r:0.8115
Current avg r:0.6394 Best avg r: 0.6590
13:16:02,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:16:28,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:16:54,722 root INFO Epoch 5 Global steps: 17200 Train loss: 0.2254
en_zh Dev loss: 0.7876 r:0.4629
ro_en Dev loss: 0.3834 r:0.8110
Current avg r:0.6370 Best avg r: 0.6590
13:18:11,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:18:37,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:19:03,217 root INFO Epoch 5 Global steps: 17400 Train loss: 0.2213
en_zh Dev loss: 0.7612 r:0.4783
ro_en Dev loss: 0.3748 r:0.8139
Current avg r:0.6461 Best avg r: 0.6590
13:20:19,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:20:45,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:21:11,723 root INFO Epoch 5 Global steps: 17600 Train loss: 0.2259
en_zh Dev loss: 0.7486 r:0.4774
ro_en Dev loss: 0.3552 r:0.8132
Current avg r:0.6453 Best avg r: 0.6590
13:22:28,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:22:54,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:23:20,194 root INFO Epoch 5 Global steps: 17800 Train loss: 0.2443
en_zh Dev loss: 0.8077 r:0.4571
ro_en Dev loss: 0.3949 r:0.8049
Current avg r:0.6310 Best avg r: 0.6590
13:24:36,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:25:02,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:25:28,666 root INFO Epoch 5 Global steps: 18000 Train loss: 0.2172
en_zh Dev loss: 0.7763 r:0.4719
ro_en Dev loss: 0.3653 r:0.8144
Current avg r:0.6431 Best avg r: 0.6590
13:26:45,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:27:11,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:27:37,530 root INFO Epoch 6 Global steps: 18200 Train loss: 0.2096
en_zh Dev loss: 0.7104 r:0.4816
ro_en Dev loss: 0.3351 r:0.8141
Current avg r:0.6478 Best avg r: 0.6590
13:28:54,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:29:20,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:29:46,50 root INFO Epoch 6 Global steps: 18400 Train loss: 0.2174
en_zh Dev loss: 0.7732 r:0.4720
ro_en Dev loss: 0.3806 r:0.8113
Current avg r:0.6416 Best avg r: 0.6590
13:31:02,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:31:28,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:31:54,443 root INFO Epoch 6 Global steps: 18600 Train loss: 0.2191
en_zh Dev loss: 0.7507 r:0.4699
ro_en Dev loss: 0.3730 r:0.8117
Current avg r:0.6408 Best avg r: 0.6590
13:33:10,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:33:36,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:34:02,906 root INFO Epoch 6 Global steps: 18800 Train loss: 0.2047
en_zh Dev loss: 0.7572 r:0.4741
ro_en Dev loss: 0.3552 r:0.8173
Current avg r:0.6457 Best avg r: 0.6590
13:35:19,466 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:35:45,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:36:11,410 root INFO Epoch 6 Global steps: 19000 Train loss: 0.2179
en_zh Dev loss: 0.7993 r:0.4529
ro_en Dev loss: 0.3365 r:0.8177
Current avg r:0.6353 Best avg r: 0.6590
13:37:27,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:37:53,880 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:38:19,855 root INFO Epoch 6 Global steps: 19200 Train loss: 0.2008
en_zh Dev loss: 0.7623 r:0.4683
ro_en Dev loss: 0.3711 r:0.8112
Current avg r:0.6398 Best avg r: 0.6590
13:39:36,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:40:02,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:40:28,325 root INFO Epoch 6 Global steps: 19400 Train loss: 0.2178
en_zh Dev loss: 0.7710 r:0.4687
ro_en Dev loss: 0.3396 r:0.8183
Current avg r:0.6435 Best avg r: 0.6590
13:41:44,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:42:10,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:42:36,822 root INFO Epoch 6 Global steps: 19600 Train loss: 0.1980
en_zh Dev loss: 0.7305 r:0.4831
ro_en Dev loss: 0.3183 r:0.8194
Current avg r:0.6513 Best avg r: 0.6590
13:43:53,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:44:19,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:44:45,281 root INFO Epoch 6 Global steps: 19800 Train loss: 0.2062
en_zh Dev loss: 0.8069 r:0.4722
ro_en Dev loss: 0.3796 r:0.8110
Current avg r:0.6416 Best avg r: 0.6590
13:46:01,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:46:27,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:46:53,728 root INFO Epoch 6 Global steps: 20000 Train loss: 0.1993
en_zh Dev loss: 0.8158 r:0.4736
ro_en Dev loss: 0.3835 r:0.8126
Current avg r:0.6431 Best avg r: 0.6590
13:48:10,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:48:36,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:49:02,164 root INFO Epoch 6 Global steps: 20200 Train loss: 0.1844
en_zh Dev loss: 0.8177 r:0.4555
ro_en Dev loss: 0.3578 r:0.8157
Current avg r:0.6356 Best avg r: 0.6590
13:50:18,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:50:44,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:51:10,626 root INFO Epoch 6 Global steps: 20400 Train loss: 0.2008
en_zh Dev loss: 0.8005 r:0.4597
ro_en Dev loss: 0.3920 r:0.8152
Current avg r:0.6374 Best avg r: 0.6590
13:52:27,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:52:53,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:53:19,131 root INFO Epoch 6 Global steps: 20600 Train loss: 0.1955
en_zh Dev loss: 0.8405 r:0.4459
ro_en Dev loss: 0.3869 r:0.8151
Current avg r:0.6305 Best avg r: 0.6590
13:54:35,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:55:01,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:55:27,590 root INFO Epoch 6 Global steps: 20800 Train loss: 0.1886
en_zh Dev loss: 0.7458 r:0.4697
ro_en Dev loss: 0.3374 r:0.8188
Current avg r:0.6442 Best avg r: 0.6590
13:56:44,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:57:10,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:57:36,125 root INFO Epoch 6 Global steps: 21000 Train loss: 0.1817
en_zh Dev loss: 0.7826 r:0.4621
ro_en Dev loss: 0.3512 r:0.8173
Current avg r:0.6397 Best avg r: 0.6590
13:58:53,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:59:19,56 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:59:45,45 root INFO Epoch 7 Global steps: 21200 Train loss: 0.1700
en_zh Dev loss: 0.8131 r:0.4614
ro_en Dev loss: 0.3482 r:0.8206
Current avg r:0.6410 Best avg r: 0.6590
14:01:01,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:01:27,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:01:53,532 root INFO Epoch 7 Global steps: 21400 Train loss: 0.1683
en_zh Dev loss: 0.8302 r:0.4529
ro_en Dev loss: 0.3772 r:0.8132
Current avg r:0.6330 Best avg r: 0.6590
14:03:10,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:03:36,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:04:02,97 root INFO Epoch 7 Global steps: 21600 Train loss: 0.1805
en_zh Dev loss: 0.7476 r:0.4763
ro_en Dev loss: 0.3340 r:0.8176
Current avg r:0.6470 Best avg r: 0.6590
14:05:18,683 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:05:44,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:06:10,603 root INFO Epoch 7 Global steps: 21800 Train loss: 0.1620
en_zh Dev loss: 0.7773 r:0.4709
ro_en Dev loss: 0.3481 r:0.8160
Current avg r:0.6435 Best avg r: 0.6590
14:07:27,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:07:53,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:08:19,39 root INFO Epoch 7 Global steps: 22000 Train loss: 0.1849
en_zh Dev loss: 0.7838 r:0.4622
ro_en Dev loss: 0.3437 r:0.8171
Current avg r:0.6396 Best avg r: 0.6590
14:09:35,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:10:01,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:10:27,521 root INFO Epoch 7 Global steps: 22200 Train loss: 0.1754
en_zh Dev loss: 0.7462 r:0.4569
ro_en Dev loss: 0.3196 r:0.8188
Current avg r:0.6378 Best avg r: 0.6590
14:11:44,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:12:09,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:12:35,933 root INFO Epoch 7 Global steps: 22400 Train loss: 0.1723
en_zh Dev loss: 0.7958 r:0.4610
ro_en Dev loss: 0.3563 r:0.8188
Current avg r:0.6399 Best avg r: 0.6590
14:13:52,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:14:18,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:14:44,353 root INFO Epoch 7 Global steps: 22600 Train loss: 0.1895
en_zh Dev loss: 0.7749 r:0.4623
ro_en Dev loss: 0.3629 r:0.8141
Current avg r:0.6382 Best avg r: 0.6590
14:16:00,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:16:26,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:16:52,842 root INFO Epoch 7 Global steps: 22800 Train loss: 0.1671
en_zh Dev loss: 0.8356 r:0.4562
ro_en Dev loss: 0.3932 r:0.8137
Current avg r:0.6349 Best avg r: 0.6590
14:18:09,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:18:35,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:19:01,296 root INFO Epoch 7 Global steps: 23000 Train loss: 0.1523
en_zh Dev loss: 0.7737 r:0.4663
ro_en Dev loss: 0.3357 r:0.8196
Current avg r:0.6430 Best avg r: 0.6590
14:20:17,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:20:43,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:21:09,728 root INFO Epoch 7 Global steps: 23200 Train loss: 0.1831
en_zh Dev loss: 0.8342 r:0.4625
ro_en Dev loss: 0.3918 r:0.8101
Current avg r:0.6363 Best avg r: 0.6590
14:22:26,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:22:52,236 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:23:18,201 root INFO Epoch 7 Global steps: 23400 Train loss: 0.1685
en_zh Dev loss: 0.7780 r:0.4682
ro_en Dev loss: 0.3589 r:0.8130
Current avg r:0.6406 Best avg r: 0.6590
14:24:34,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:25:00,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:25:26,668 root INFO Epoch 7 Global steps: 23600 Train loss: 0.1751
en_zh Dev loss: 0.7932 r:0.4634
ro_en Dev loss: 0.3471 r:0.8147
Current avg r:0.6391 Best avg r: 0.6590
14:26:43,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:27:09,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:27:35,133 root INFO Epoch 7 Global steps: 23800 Train loss: 0.1774
en_zh Dev loss: 0.8141 r:0.4611
ro_en Dev loss: 0.3524 r:0.8161
Current avg r:0.6386 Best avg r: 0.6590
14:28:51,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:29:17,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:29:43,579 root INFO Epoch 7 Global steps: 24000 Train loss: 0.1734
en_zh Dev loss: 0.7818 r:0.4578
ro_en Dev loss: 0.3488 r:0.8146
Current avg r:0.6362 Best avg r: 0.6590
14:31:00,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:31:26,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:31:52,338 root INFO Epoch 8 Global steps: 24200 Train loss: 0.1556
en_zh Dev loss: 0.8182 r:0.4593
ro_en Dev loss: 0.4140 r:0.8084
Current avg r:0.6338 Best avg r: 0.6590
14:33:08,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:33:34,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:34:00,751 root INFO Epoch 8 Global steps: 24400 Train loss: 0.1654
en_zh Dev loss: 0.7363 r:0.4761
ro_en Dev loss: 0.3308 r:0.8153
Current avg r:0.6457 Best avg r: 0.6590
14:35:17,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:35:43,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:36:09,107 root INFO Epoch 8 Global steps: 24600 Train loss: 0.1460
en_zh Dev loss: 0.7579 r:0.4789
ro_en Dev loss: 0.3423 r:0.8190
Current avg r:0.6489 Best avg r: 0.6590
14:37:25,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:51,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:38:17,455 root INFO Epoch 8 Global steps: 24800 Train loss: 0.1472
en_zh Dev loss: 0.7472 r:0.4825
ro_en Dev loss: 0.3509 r:0.8167
Current avg r:0.6496 Best avg r: 0.6590
14:39:33,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:39:59,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:25,818 root INFO Epoch 8 Global steps: 25000 Train loss: 0.1474
en_zh Dev loss: 0.7732 r:0.4615
ro_en Dev loss: 0.3626 r:0.8103
Current avg r:0.6359 Best avg r: 0.6590
14:41:42,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:08,270 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:42:34,225 root INFO Epoch 8 Global steps: 25200 Train loss: 0.1417
en_zh Dev loss: 0.7734 r:0.4632
ro_en Dev loss: 0.3485 r:0.8136
Current avg r:0.6384 Best avg r: 0.6590
14:43:50,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:16,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:44:42,681 root INFO Epoch 8 Global steps: 25400 Train loss: 0.1505
en_zh Dev loss: 0.7807 r:0.4625
ro_en Dev loss: 0.3434 r:0.8168
Current avg r:0.6397 Best avg r: 0.6590
14:45:59,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:46:25,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:51,134 root INFO Epoch 8 Global steps: 25600 Train loss: 0.1404
en_zh Dev loss: 0.7928 r:0.4659
ro_en Dev loss: 0.3810 r:0.8119
Current avg r:0.6389 Best avg r: 0.6590
14:48:07,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:33,597 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:59,567 root INFO Epoch 8 Global steps: 25800 Train loss: 0.1467
en_zh Dev loss: 0.7988 r:0.4580
ro_en Dev loss: 0.3604 r:0.8118
Current avg r:0.6349 Best avg r: 0.6590
14:50:16,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:50:42,87 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:08,57 root INFO Epoch 8 Global steps: 26000 Train loss: 0.1370
en_zh Dev loss: 0.8085 r:0.4640
ro_en Dev loss: 0.3672 r:0.8134
Current avg r:0.6387 Best avg r: 0.6590
14:52:24,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:50,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:16,523 root INFO Epoch 8 Global steps: 26200 Train loss: 0.1377
en_zh Dev loss: 0.8072 r:0.4625
ro_en Dev loss: 0.3560 r:0.8174
Current avg r:0.6399 Best avg r: 0.6590
14:54:33,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:59,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:25,11 root INFO Epoch 8 Global steps: 26400 Train loss: 0.1534
en_zh Dev loss: 0.7794 r:0.4679
ro_en Dev loss: 0.3476 r:0.8148
Current avg r:0.6413 Best avg r: 0.6590
14:56:41,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:07,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:33,497 root INFO Epoch 8 Global steps: 26600 Train loss: 0.1369
en_zh Dev loss: 0.7956 r:0.4729
ro_en Dev loss: 0.3719 r:0.8137
Current avg r:0.6433 Best avg r: 0.6590
14:58:50,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:15,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:41,936 root INFO Epoch 8 Global steps: 26800 Train loss: 0.1516
en_zh Dev loss: 0.7532 r:0.4756
ro_en Dev loss: 0.3525 r:0.8140
Current avg r:0.6448 Best avg r: 0.6590
15:00:58,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:24,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:01:50,421 root INFO Epoch 8 Global steps: 27000 Train loss: 0.1398
en_zh Dev loss: 0.7883 r:0.4701
ro_en Dev loss: 0.3467 r:0.8157
Current avg r:0.6429 Best avg r: 0.6590
15:03:07,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:33,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:59,168 root INFO Epoch 9 Global steps: 27200 Train loss: 0.1343
en_zh Dev loss: 0.8368 r:0.4599
ro_en Dev loss: 0.3866 r:0.8117
Current avg r:0.6358 Best avg r: 0.6590
15:05:15,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:41,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:07,679 root INFO Epoch 9 Global steps: 27400 Train loss: 0.1386
en_zh Dev loss: 0.8177 r:0.4642
ro_en Dev loss: 0.3445 r:0.8153
Current avg r:0.6397 Best avg r: 0.6590
15:07:24,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:50,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:16,182 root INFO Epoch 9 Global steps: 27600 Train loss: 0.1286
en_zh Dev loss: 0.7503 r:0.4836
ro_en Dev loss: 0.3182 r:0.8229
Current avg r:0.6532 Best avg r: 0.6590
15:09:32,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:58,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:24,616 root INFO Epoch 9 Global steps: 27800 Train loss: 0.1276
en_zh Dev loss: 0.8163 r:0.4675
ro_en Dev loss: 0.3492 r:0.8203
Current avg r:0.6439 Best avg r: 0.6590
15:11:41,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:07,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:33,71 root INFO Epoch 9 Global steps: 28000 Train loss: 0.1337
en_zh Dev loss: 0.7938 r:0.4759
ro_en Dev loss: 0.3517 r:0.8190
Current avg r:0.6474 Best avg r: 0.6590
15:13:49,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:15,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:41,517 root INFO Epoch 9 Global steps: 28200 Train loss: 0.1313
en_zh Dev loss: 0.7663 r:0.4715
ro_en Dev loss: 0.3379 r:0.8181
Current avg r:0.6448 Best avg r: 0.6590
15:15:58,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:24,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:49,975 root INFO Epoch 9 Global steps: 28400 Train loss: 0.1361
en_zh Dev loss: 0.7932 r:0.4654
ro_en Dev loss: 0.3571 r:0.8175
Current avg r:0.6414 Best avg r: 0.6590
15:18:06,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:32,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:58,438 root INFO Epoch 9 Global steps: 28600 Train loss: 0.1242
en_zh Dev loss: 0.7943 r:0.4735
ro_en Dev loss: 0.3542 r:0.8191
Current avg r:0.6463 Best avg r: 0.6590
15:20:14,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:40,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:06,834 root INFO Epoch 9 Global steps: 28800 Train loss: 0.1230
en_zh Dev loss: 0.7808 r:0.4769
ro_en Dev loss: 0.3682 r:0.8141
Current avg r:0.6455 Best avg r: 0.6590
15:22:23,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:49,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:15,293 root INFO Epoch 9 Global steps: 29000 Train loss: 0.1306
en_zh Dev loss: 0.8002 r:0.4613
ro_en Dev loss: 0.3587 r:0.8125
Current avg r:0.6369 Best avg r: 0.6590
15:24:31,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:57,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:23,753 root INFO Epoch 9 Global steps: 29200 Train loss: 0.1279
en_zh Dev loss: 0.8151 r:0.4645
ro_en Dev loss: 0.3977 r:0.8116
Current avg r:0.6380 Best avg r: 0.6590
15:26:40,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:06,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:32,199 root INFO Epoch 9 Global steps: 29400 Train loss: 0.1300
en_zh Dev loss: 0.7713 r:0.4673
ro_en Dev loss: 0.3655 r:0.8130
Current avg r:0.6401 Best avg r: 0.6590
15:28:48,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:14,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:40,723 root INFO Epoch 9 Global steps: 29600 Train loss: 0.1311
en_zh Dev loss: 0.7981 r:0.4698
ro_en Dev loss: 0.3542 r:0.8185
Current avg r:0.6441 Best avg r: 0.6590
15:30:57,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:23,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:49,238 root INFO Epoch 9 Global steps: 29800 Train loss: 0.1290
en_zh Dev loss: 0.7336 r:0.4863
ro_en Dev loss: 0.3544 r:0.8199
Current avg r:0.6531 Best avg r: 0.6590
15:33:05,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:31,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:57,703 root INFO Epoch 9 Global steps: 30000 Train loss: 0.1320
en_zh Dev loss: 0.7712 r:0.4740
ro_en Dev loss: 0.3478 r:0.8176
Current avg r:0.6458 Best avg r: 0.6590
15:35:14,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:40,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:06,608 root INFO Epoch 10 Global steps: 30200 Train loss: 0.1159
en_zh Dev loss: 0.7469 r:0.4841
ro_en Dev loss: 0.3474 r:0.8195
Current avg r:0.6518 Best avg r: 0.6590
15:37:23,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:49,130 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:15,83 root INFO Epoch 10 Global steps: 30400 Train loss: 0.1217
en_zh Dev loss: 0.7709 r:0.4850
ro_en Dev loss: 0.3374 r:0.8223
Current avg r:0.6536 Best avg r: 0.6590
15:39:31,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:57,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:23,532 root INFO Epoch 10 Global steps: 30600 Train loss: 0.1117
en_zh Dev loss: 0.7928 r:0.4725
ro_en Dev loss: 0.3624 r:0.8172
Current avg r:0.6449 Best avg r: 0.6590
15:41:40,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:06,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:32,31 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1149
en_zh Dev loss: 0.7928 r:0.4780
ro_en Dev loss: 0.3861 r:0.8152
Current avg r:0.6466 Best avg r: 0.6590
15:43:48,581 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:14,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:40,493 root INFO Epoch 10 Global steps: 31000 Train loss: 0.1143
en_zh Dev loss: 0.7465 r:0.4837
ro_en Dev loss: 0.3370 r:0.8213
Current avg r:0.6525 Best avg r: 0.6590
15:45:57,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:23,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:48,968 root INFO Epoch 10 Global steps: 31200 Train loss: 0.1282
en_zh Dev loss: 0.8143 r:0.4719
ro_en Dev loss: 0.3613 r:0.8167
Current avg r:0.6443 Best avg r: 0.6590
15:48:05,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:31,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:57,411 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1165
en_zh Dev loss: 0.7591 r:0.4825
ro_en Dev loss: 0.3353 r:0.8204
Current avg r:0.6514 Best avg r: 0.6590
15:50:13,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:39,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:05,878 root INFO Epoch 10 Global steps: 31600 Train loss: 0.1072
en_zh Dev loss: 0.7770 r:0.4800
ro_en Dev loss: 0.3384 r:0.8218
Current avg r:0.6509 Best avg r: 0.6590
15:52:22,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:48,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:14,385 root INFO Epoch 10 Global steps: 31800 Train loss: 0.1086
en_zh Dev loss: 0.7873 r:0.4727
ro_en Dev loss: 0.3378 r:0.8193
Current avg r:0.6460 Best avg r: 0.6590
15:54:30,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:56,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:22,862 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1092
en_zh Dev loss: 0.7745 r:0.4781
ro_en Dev loss: 0.3446 r:0.8175
Current avg r:0.6478 Best avg r: 0.6590
15:56:39,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:05,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:31,300 root INFO Epoch 10 Global steps: 32200 Train loss: 0.1085
en_zh Dev loss: 0.8407 r:0.4766
ro_en Dev loss: 0.3621 r:0.8200
Current avg r:0.6483 Best avg r: 0.6590
15:58:47,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:13,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:39,742 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1143
en_zh Dev loss: 0.8015 r:0.4894
ro_en Dev loss: 0.3692 r:0.8214
Current avg r:0.6554 Best avg r: 0.6590
16:00:56,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:22,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:48,175 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1165
en_zh Dev loss: 0.7475 r:0.4930
ro_en Dev loss: 0.3512 r:0.8204
Current avg r:0.6567 Best avg r: 0.6590
16:03:04,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:30,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:56,662 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1066
en_zh Dev loss: 0.7673 r:0.4839
ro_en Dev loss: 0.3453 r:0.8206
Current avg r:0.6523 Best avg r: 0.6590
16:05:13,206 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:39,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:05,97 root INFO Epoch 10 Global steps: 33000 Train loss: 0.1154
en_zh Dev loss: 0.8025 r:0.4821
ro_en Dev loss: 0.3593 r:0.8167
Current avg r:0.6494 Best avg r: 0.6590
16:07:22,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:47,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:13,917 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1000
en_zh Dev loss: 0.7607 r:0.4897
ro_en Dev loss: 0.3608 r:0.8141
Current avg r:0.6519 Best avg r: 0.6590
16:09:30,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:56,438 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:22,392 root INFO Epoch 11 Global steps: 33400 Train loss: 0.0999
en_zh Dev loss: 0.7748 r:0.4874
ro_en Dev loss: 0.3610 r:0.8158
Current avg r:0.6516 Best avg r: 0.6590
16:11:38,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:04,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:30,858 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1073
en_zh Dev loss: 0.7701 r:0.4860
ro_en Dev loss: 0.3451 r:0.8175
Current avg r:0.6518 Best avg r: 0.6590
16:13:47,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:13,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:39,273 root INFO Epoch 11 Global steps: 33800 Train loss: 0.0930
en_zh Dev loss: 0.7819 r:0.4799
ro_en Dev loss: 0.3403 r:0.8196
Current avg r:0.6497 Best avg r: 0.6590
16:15:55,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:21,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:47,786 root INFO Epoch 11 Global steps: 34000 Train loss: 0.0990
en_zh Dev loss: 0.7589 r:0.4868
ro_en Dev loss: 0.3611 r:0.8140
Current avg r:0.6504 Best avg r: 0.6590
16:18:04,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:30,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:56,250 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1062
en_zh Dev loss: 0.7415 r:0.4937
ro_en Dev loss: 0.3339 r:0.8203
Current avg r:0.6570 Best avg r: 0.6590
16:20:12,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:38,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:04,750 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1063
en_zh Dev loss: 0.7839 r:0.4873
ro_en Dev loss: 0.3568 r:0.8197
Current avg r:0.6535 Best avg r: 0.6590
16:22:21,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:47,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:13,241 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1023
en_zh Dev loss: 0.7304 r:0.4895
ro_en Dev loss: 0.3219 r:0.8232
Current avg r:0.6564 Best avg r: 0.6590
16:24:29,791 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:55,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:21,671 root INFO Epoch 11 Global steps: 34800 Train loss: 0.0987
en_zh Dev loss: 0.7710 r:0.4774
ro_en Dev loss: 0.3652 r:0.8155
Current avg r:0.6464 Best avg r: 0.6590
16:26:38,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:04,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:30,183 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1146
en_zh Dev loss: 0.7959 r:0.4753
ro_en Dev loss: 0.3560 r:0.8171
Current avg r:0.6462 Best avg r: 0.6590
16:28:46,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:12,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:38,661 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1079
en_zh Dev loss: 0.7894 r:0.4700
ro_en Dev loss: 0.3515 r:0.8159
Current avg r:0.6430 Best avg r: 0.6590
16:30:55,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:21,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:47,156 root INFO Epoch 11 Global steps: 35400 Train loss: 0.0986
en_zh Dev loss: 0.8282 r:0.4734
ro_en Dev loss: 0.4031 r:0.8150
Current avg r:0.6442 Best avg r: 0.6590
16:33:03,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:29,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:55,704 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1093
en_zh Dev loss: 0.7942 r:0.4724
ro_en Dev loss: 0.3526 r:0.8171
Current avg r:0.6447 Best avg r: 0.6590
16:35:12,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:38,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:04,218 root INFO Epoch 11 Global steps: 35800 Train loss: 0.0984
en_zh Dev loss: 0.8144 r:0.4710
ro_en Dev loss: 0.3462 r:0.8201
Current avg r:0.6456 Best avg r: 0.6590
16:37:20,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:46,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:12,737 root INFO Epoch 11 Global steps: 36000 Train loss: 0.0943
en_zh Dev loss: 0.8223 r:0.4650
ro_en Dev loss: 0.3557 r:0.8184
Current avg r:0.6417 Best avg r: 0.6590
16:39:29,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:55,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:21,645 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1001
en_zh Dev loss: 0.7829 r:0.4725
ro_en Dev loss: 0.3278 r:0.8231
Current avg r:0.6478 Best avg r: 0.6590
16:41:38,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:04,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:30,130 root INFO Epoch 12 Global steps: 36400 Train loss: 0.0885
en_zh Dev loss: 0.7533 r:0.4891
ro_en Dev loss: 0.3385 r:0.8211
Current avg r:0.6551 Best avg r: 0.6590
16:43:46,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:12,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:38,632 root INFO Epoch 12 Global steps: 36600 Train loss: 0.0892
en_zh Dev loss: 0.8158 r:0.4679
ro_en Dev loss: 0.3660 r:0.8203
Current avg r:0.6441 Best avg r: 0.6590
16:45:55,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:21,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:47,178 root INFO Epoch 12 Global steps: 36800 Train loss: 0.0894
en_zh Dev loss: 0.7703 r:0.4796
ro_en Dev loss: 0.3194 r:0.8254
Current avg r:0.6525 Best avg r: 0.6590
16:48:03,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:29,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:55,668 root INFO Epoch 12 Global steps: 37000 Train loss: 0.0933
en_zh Dev loss: 0.8463 r:0.4734
ro_en Dev loss: 0.3595 r:0.8201
Current avg r:0.6467 Best avg r: 0.6590
16:50:12,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:38,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:04,92 root INFO Epoch 12 Global steps: 37200 Train loss: 0.0873
en_zh Dev loss: 0.8114 r:0.4683
ro_en Dev loss: 0.3543 r:0.8200
Current avg r:0.6441 Best avg r: 0.6590
16:52:20,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:46,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:12,525 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1000
en_zh Dev loss: 0.8493 r:0.4639
ro_en Dev loss: 0.3637 r:0.8167
Current avg r:0.6403 Best avg r: 0.6590
16:54:28,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:54,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:20,898 root INFO Epoch 12 Global steps: 37600 Train loss: 0.0872
en_zh Dev loss: 0.8288 r:0.4741
ro_en Dev loss: 0.3631 r:0.8179
Current avg r:0.6460 Best avg r: 0.6590
16:56:37,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:03,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:29,341 root INFO Epoch 12 Global steps: 37800 Train loss: 0.0992
en_zh Dev loss: 0.7994 r:0.4756
ro_en Dev loss: 0.3559 r:0.8178
Current avg r:0.6467 Best avg r: 0.6590
16:58:45,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:11,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:37,749 root INFO Epoch 12 Global steps: 38000 Train loss: 0.0854
en_zh Dev loss: 0.7566 r:0.4765
ro_en Dev loss: 0.3404 r:0.8181
Current avg r:0.6473 Best avg r: 0.6590
17:00:54,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:20,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:46,230 root INFO Epoch 12 Global steps: 38200 Train loss: 0.0980
en_zh Dev loss: 0.8145 r:0.4723
ro_en Dev loss: 0.3861 r:0.8123
Current avg r:0.6423 Best avg r: 0.6590
17:03:02,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:28,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:54,682 root INFO Epoch 12 Global steps: 38400 Train loss: 0.0853
en_zh Dev loss: 0.7787 r:0.4746
ro_en Dev loss: 0.3546 r:0.8184
Current avg r:0.6465 Best avg r: 0.6590
17:05:11,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:37,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:03,79 root INFO Epoch 12 Global steps: 38600 Train loss: 0.0952
en_zh Dev loss: 0.7902 r:0.4812
ro_en Dev loss: 0.3436 r:0.8195
Current avg r:0.6503 Best avg r: 0.6590
17:07:19,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:45,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:11,506 root INFO Epoch 12 Global steps: 38800 Train loss: 0.0869
en_zh Dev loss: 0.7879 r:0.4824
ro_en Dev loss: 0.3481 r:0.8180
Current avg r:0.6502 Best avg r: 0.6590
17:09:27,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:53,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:10:19,865 root INFO Epoch 12 Global steps: 39000 Train loss: 0.0952
en_zh Dev loss: 0.8272 r:0.4770
ro_en Dev loss: 0.3720 r:0.8164
Current avg r:0.6467 Best avg r: 0.6590
17:11:36,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:02,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:28,580 root INFO Epoch 13 Global steps: 39200 Train loss: 0.0806
en_zh Dev loss: 0.8076 r:0.4793
ro_en Dev loss: 0.3686 r:0.8164
Current avg r:0.6478 Best avg r: 0.6590
17:13:45,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:10,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:36,908 root INFO Epoch 13 Global steps: 39400 Train loss: 0.0874
en_zh Dev loss: 0.8596 r:0.4747
ro_en Dev loss: 0.3994 r:0.8150
Current avg r:0.6449 Best avg r: 0.6590
17:15:53,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:19,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:45,247 root INFO Epoch 13 Global steps: 39600 Train loss: 0.0817
en_zh Dev loss: 0.7932 r:0.4798
ro_en Dev loss: 0.3756 r:0.8136
Current avg r:0.6467 Best avg r: 0.6590
17:18:01,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:27,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:53,598 root INFO Epoch 13 Global steps: 39800 Train loss: 0.0940
en_zh Dev loss: 0.8168 r:0.4821
ro_en Dev loss: 0.3862 r:0.8128
Current avg r:0.6474 Best avg r: 0.6590
17:20:10,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:36,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:01,929 root INFO Epoch 13 Global steps: 40000 Train loss: 0.0870
en_zh Dev loss: 0.8088 r:0.4819
ro_en Dev loss: 0.3575 r:0.8200
Current avg r:0.6509 Best avg r: 0.6590
17:22:18,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:44,342 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:10,270 root INFO Epoch 13 Global steps: 40200 Train loss: 0.0890
en_zh Dev loss: 0.7551 r:0.4808
ro_en Dev loss: 0.3413 r:0.8189
Current avg r:0.6499 Best avg r: 0.6590
17:24:26,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:52,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:18,602 root INFO Epoch 13 Global steps: 40400 Train loss: 0.0854
en_zh Dev loss: 0.8221 r:0.4799
ro_en Dev loss: 0.3749 r:0.8171
Current avg r:0.6485 Best avg r: 0.6590
17:26:35,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:01,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:26,938 root INFO Epoch 13 Global steps: 40600 Train loss: 0.0781
en_zh Dev loss: 0.7517 r:0.4898
ro_en Dev loss: 0.3368 r:0.8197
Current avg r:0.6548 Best avg r: 0.6590
17:28:43,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:09,280 root INFO 
id:en_zh cur r: 0.4997 best r: 0.4997
17:29:22,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:48,185 root INFO Epoch 13 Global steps: 40800 Train loss: 0.0814
en_zh Dev loss: 0.7267 r:0.4970
ro_en Dev loss: 0.3266 r:0.8204
Current avg r:0.6587 Best avg r: 0.6590
17:31:04,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:30,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:56,577 root INFO Epoch 13 Global steps: 41000 Train loss: 0.0882
en_zh Dev loss: 0.7257 r:0.4925
ro_en Dev loss: 0.3140 r:0.8221
Current avg r:0.6573 Best avg r: 0.6590
17:33:13,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:38,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:04,896 root INFO Epoch 13 Global steps: 41200 Train loss: 0.0841
en_zh Dev loss: 0.7614 r:0.4879
ro_en Dev loss: 0.3468 r:0.8195
Current avg r:0.6537 Best avg r: 0.6590
17:35:21,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:47,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:13,298 root INFO Epoch 13 Global steps: 41400 Train loss: 0.0786
en_zh Dev loss: 0.7706 r:0.4868
ro_en Dev loss: 0.3580 r:0.8176
Current avg r:0.6522 Best avg r: 0.6590
17:37:29,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:55,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:21,815 root INFO Epoch 13 Global steps: 41600 Train loss: 0.0831
en_zh Dev loss: 0.7454 r:0.4958
ro_en Dev loss: 0.3498 r:0.8182
Current avg r:0.6570 Best avg r: 0.6590
17:39:38,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:04,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:30,258 root INFO Epoch 13 Global steps: 41800 Train loss: 0.0787
en_zh Dev loss: 0.7951 r:0.4850
ro_en Dev loss: 0.3495 r:0.8184
Current avg r:0.6517 Best avg r: 0.6590
17:41:46,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:12,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:38,761 root INFO Epoch 13 Global steps: 42000 Train loss: 0.0860
en_zh Dev loss: 0.8048 r:0.4811
ro_en Dev loss: 0.3638 r:0.8153
Current avg r:0.6482 Best avg r: 0.6590
17:43:55,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:21,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:47,530 root INFO Epoch 14 Global steps: 42200 Train loss: 0.0780
en_zh Dev loss: 0.7735 r:0.4922
ro_en Dev loss: 0.3421 r:0.8178
Current avg r:0.6550 Best avg r: 0.6590
17:46:04,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:30,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:55,989 root INFO Epoch 14 Global steps: 42400 Train loss: 0.0728
en_zh Dev loss: 0.8131 r:0.4836
ro_en Dev loss: 0.3488 r:0.8168
Current avg r:0.6502 Best avg r: 0.6590
17:48:12,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:38,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:04,504 root INFO Epoch 14 Global steps: 42600 Train loss: 0.0725
en_zh Dev loss: 0.7891 r:0.4889
ro_en Dev loss: 0.3636 r:0.8153
Current avg r:0.6521 Best avg r: 0.6590
17:50:21,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:47,32 root INFO 
id:en_zh cur r: 0.5019 best r: 0.5019
17:51:00,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:25,988 root INFO Epoch 14 Global steps: 42800 Train loss: 0.0773
en_zh Dev loss: 0.7634 r:0.4986
ro_en Dev loss: 0.3671 r:0.8134
Current avg r:0.6560 Best avg r: 0.6590
17:52:42,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:08,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:34,568 root INFO Epoch 14 Global steps: 43000 Train loss: 0.0775
en_zh Dev loss: 0.7574 r:0.4975
ro_en Dev loss: 0.3631 r:0.8147
Current avg r:0.6561 Best avg r: 0.6590
17:54:51,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:17,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:43,85 root INFO Epoch 14 Global steps: 43200 Train loss: 0.0735
en_zh Dev loss: 0.7822 r:0.4863
ro_en Dev loss: 0.3315 r:0.8186
Current avg r:0.6524 Best avg r: 0.6590
17:56:59,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:25,665 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:51,640 root INFO Epoch 14 Global steps: 43400 Train loss: 0.0708
en_zh Dev loss: 0.7672 r:0.4934
ro_en Dev loss: 0.3647 r:0.8166
Current avg r:0.6550 Best avg r: 0.6590
17:59:08,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:34,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:00,151 root INFO Epoch 14 Global steps: 43600 Train loss: 0.0790
en_zh Dev loss: 0.7979 r:0.4891
ro_en Dev loss: 0.3642 r:0.8149
Current avg r:0.6520 Best avg r: 0.6590
18:01:16,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:42,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:08,601 root INFO Epoch 14 Global steps: 43800 Train loss: 0.0760
en_zh Dev loss: 0.7935 r:0.4900
ro_en Dev loss: 0.3777 r:0.8132
Current avg r:0.6516 Best avg r: 0.6590
18:03:25,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:51,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:17,77 root INFO Epoch 14 Global steps: 44000 Train loss: 0.0761
en_zh Dev loss: 0.7994 r:0.4911
ro_en Dev loss: 0.3681 r:0.8153
Current avg r:0.6532 Best avg r: 0.6590
18:05:33,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:59,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:25,542 root INFO Epoch 14 Global steps: 44200 Train loss: 0.0777
en_zh Dev loss: 0.8167 r:0.4871
ro_en Dev loss: 0.3768 r:0.8140
Current avg r:0.6505 Best avg r: 0.6590
18:07:42,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:08,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:33,989 root INFO Epoch 14 Global steps: 44400 Train loss: 0.0725
en_zh Dev loss: 0.8624 r:0.4832
ro_en Dev loss: 0.3980 r:0.8100
Current avg r:0.6466 Best avg r: 0.6590
18:09:50,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:16,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:42,439 root INFO Epoch 14 Global steps: 44600 Train loss: 0.0800
en_zh Dev loss: 0.7783 r:0.4891
ro_en Dev loss: 0.3402 r:0.8174
Current avg r:0.6532 Best avg r: 0.6590
18:11:58,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:24,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:50,817 root INFO Epoch 14 Global steps: 44800 Train loss: 0.0774
en_zh Dev loss: 0.7797 r:0.4866
ro_en Dev loss: 0.3629 r:0.8154
Current avg r:0.6510 Best avg r: 0.6590
18:14:07,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:33,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:59,263 root INFO Epoch 14 Global steps: 45000 Train loss: 0.0759
en_zh Dev loss: 0.7241 r:0.4934
ro_en Dev loss: 0.3308 r:0.8167
Current avg r:0.6551 Best avg r: 0.6590
18:16:16,245 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:42,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:08,126 root INFO Epoch 15 Global steps: 45200 Train loss: 0.0714
en_zh Dev loss: 0.7967 r:0.4881
ro_en Dev loss: 0.3519 r:0.8170
Current avg r:0.6525 Best avg r: 0.6590
18:18:24,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:50,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:16,549 root INFO Epoch 15 Global steps: 45400 Train loss: 0.0709
en_zh Dev loss: 0.8299 r:0.4808
ro_en Dev loss: 0.3596 r:0.8153
Current avg r:0.6480 Best avg r: 0.6590
18:20:33,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:59,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:25,16 root INFO Epoch 15 Global steps: 45600 Train loss: 0.0735
en_zh Dev loss: 0.7801 r:0.4941
ro_en Dev loss: 0.3741 r:0.8122
Current avg r:0.6531 Best avg r: 0.6590
18:22:41,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:07,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:33,447 root INFO Epoch 15 Global steps: 45800 Train loss: 0.0676
en_zh Dev loss: 0.8431 r:0.4881
ro_en Dev loss: 0.3744 r:0.8146
Current avg r:0.6514 Best avg r: 0.6590
18:24:50,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:15,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:41,890 root INFO Epoch 15 Global steps: 46000 Train loss: 0.0656
en_zh Dev loss: 0.7690 r:0.4895
ro_en Dev loss: 0.3530 r:0.8151
Current avg r:0.6523 Best avg r: 0.6590
18:26:58,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:24,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:50,398 root INFO Epoch 15 Global steps: 46200 Train loss: 0.0659
en_zh Dev loss: 0.7996 r:0.4919
ro_en Dev loss: 0.3823 r:0.8140
Current avg r:0.6530 Best avg r: 0.6590
18:29:06,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:32,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:58,835 root INFO Epoch 15 Global steps: 46400 Train loss: 0.0668
en_zh Dev loss: 0.7411 r:0.4974
ro_en Dev loss: 0.3401 r:0.8172
Current avg r:0.6573 Best avg r: 0.6590
18:31:15,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:41,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:07,226 root INFO Epoch 15 Global steps: 46600 Train loss: 0.0702
en_zh Dev loss: 0.7733 r:0.4925
ro_en Dev loss: 0.3531 r:0.8142
Current avg r:0.6534 Best avg r: 0.6590
18:33:23,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:49,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:15,688 root INFO Epoch 15 Global steps: 46800 Train loss: 0.0733
en_zh Dev loss: 0.7743 r:0.4971
ro_en Dev loss: 0.3678 r:0.8161
Current avg r:0.6566 Best avg r: 0.6590
18:35:32,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:58,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:24,84 root INFO Epoch 15 Global steps: 47000 Train loss: 0.0719
en_zh Dev loss: 0.7784 r:0.4977
ro_en Dev loss: 0.3581 r:0.8170
Current avg r:0.6573 Best avg r: 0.6590
18:37:40,655 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:06,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:32,591 root INFO Epoch 15 Global steps: 47200 Train loss: 0.0743
en_zh Dev loss: 0.7481 r:0.4955
ro_en Dev loss: 0.3341 r:0.8186
Current avg r:0.6571 Best avg r: 0.6590
18:39:49,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:15,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:41,27 root INFO Epoch 15 Global steps: 47400 Train loss: 0.0688
en_zh Dev loss: 0.7874 r:0.4924
ro_en Dev loss: 0.3722 r:0.8140
Current avg r:0.6532 Best avg r: 0.6590
18:41:57,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:23,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:49,427 root INFO Epoch 15 Global steps: 47600 Train loss: 0.0689
en_zh Dev loss: 0.7947 r:0.4893
ro_en Dev loss: 0.3697 r:0.8132
Current avg r:0.6512 Best avg r: 0.6590
18:44:05,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:31,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:57,863 root INFO Epoch 15 Global steps: 47800 Train loss: 0.0728
en_zh Dev loss: 0.7612 r:0.4967
ro_en Dev loss: 0.3469 r:0.8160
Current avg r:0.6563 Best avg r: 0.6590
18:46:14,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:40,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:06,250 root INFO Epoch 15 Global steps: 48000 Train loss: 0.0640
en_zh Dev loss: 0.8219 r:0.4901
ro_en Dev loss: 0.3796 r:0.8130
Current avg r:0.6515 Best avg r: 0.6590
18:48:23,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:49,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:15,127 root INFO Epoch 16 Global steps: 48200 Train loss: 0.0655
en_zh Dev loss: 0.8054 r:0.4884
ro_en Dev loss: 0.3459 r:0.8174
Current avg r:0.6529 Best avg r: 0.6590
18:50:31,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:57,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:23,585 root INFO Epoch 16 Global steps: 48400 Train loss: 0.0642
en_zh Dev loss: 0.8151 r:0.4922
ro_en Dev loss: 0.3649 r:0.8164
Current avg r:0.6543 Best avg r: 0.6590
18:52:40,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:06,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:31,959 root INFO Epoch 16 Global steps: 48600 Train loss: 0.0651
en_zh Dev loss: 0.7882 r:0.4916
ro_en Dev loss: 0.3561 r:0.8180
Current avg r:0.6548 Best avg r: 0.6590
18:54:48,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:14,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:40,272 root INFO Epoch 16 Global steps: 48800 Train loss: 0.0648
en_zh Dev loss: 0.7737 r:0.4992
ro_en Dev loss: 0.3633 r:0.8181
Current avg r:0.6586 Best avg r: 0.6590
18:56:56,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:22,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:48,592 root INFO Epoch 16 Global steps: 49000 Train loss: 0.0708
en_zh Dev loss: 0.7476 r:0.4946
ro_en Dev loss: 0.3493 r:0.8190
Current avg r:0.6568 Best avg r: 0.6590
18:59:05,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:30,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:56,863 root INFO Epoch 16 Global steps: 49200 Train loss: 0.0614
en_zh Dev loss: 0.8303 r:0.4872
ro_en Dev loss: 0.3855 r:0.8170
Current avg r:0.6521 Best avg r: 0.6590
19:01:13,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:39,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:05,213 root INFO Epoch 16 Global steps: 49400 Train loss: 0.0628
en_zh Dev loss: 0.7351 r:0.4957
ro_en Dev loss: 0.3531 r:0.8173
Current avg r:0.6565 Best avg r: 0.6590
19:03:21,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:47,597 root INFO 
id:en_zh cur r: 0.5060 best r: 0.5060
19:04:00,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:26,488 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
19:04:26,507 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
19:04:52,454 root INFO Epoch 16 Global steps: 49600 Train loss: 0.0639
en_zh Dev loss: 0.7175 r:0.5037
ro_en Dev loss: 0.3457 r:0.8168
Current avg r:0.6603 Best avg r: 0.6603
19:06:08,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:34,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:00,817 root INFO Epoch 16 Global steps: 49800 Train loss: 0.0660
en_zh Dev loss: 0.7983 r:0.4873
ro_en Dev loss: 0.3847 r:0.8164
Current avg r:0.6518 Best avg r: 0.6603
19:08:17,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:43,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:09,143 root INFO Epoch 16 Global steps: 50000 Train loss: 0.0624
en_zh Dev loss: 0.7687 r:0.4935
ro_en Dev loss: 0.3641 r:0.8163
Current avg r:0.6549 Best avg r: 0.6603
19:10:25,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:51,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:17,494 root INFO Epoch 16 Global steps: 50200 Train loss: 0.0638
en_zh Dev loss: 0.7431 r:0.5015
ro_en Dev loss: 0.3501 r:0.8187
Current avg r:0.6601 Best avg r: 0.6603
19:12:34,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:00,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:26,9 root INFO Epoch 16 Global steps: 50400 Train loss: 0.0597
en_zh Dev loss: 0.7490 r:0.4974
ro_en Dev loss: 0.3686 r:0.8150
Current avg r:0.6562 Best avg r: 0.6603
19:14:42,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:08,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:34,438 root INFO Epoch 16 Global steps: 50600 Train loss: 0.0675
en_zh Dev loss: 0.8052 r:0.4967
ro_en Dev loss: 0.3612 r:0.8183
Current avg r:0.6575 Best avg r: 0.6603
19:16:50,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:16,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:42,840 root INFO Epoch 16 Global steps: 50800 Train loss: 0.0671
en_zh Dev loss: 0.7615 r:0.4973
ro_en Dev loss: 0.3499 r:0.8176
Current avg r:0.6575 Best avg r: 0.6603
19:18:59,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:25,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:51,370 root INFO Epoch 16 Global steps: 51000 Train loss: 0.0676
en_zh Dev loss: 0.7887 r:0.4958
ro_en Dev loss: 0.3516 r:0.8189
Current avg r:0.6574 Best avg r: 0.6603
19:21:08,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:34,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:00,257 root INFO Epoch 17 Global steps: 51200 Train loss: 0.0688
en_zh Dev loss: 0.7713 r:0.4971
ro_en Dev loss: 0.3534 r:0.8185
Current avg r:0.6578 Best avg r: 0.6603
19:23:16,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:42,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:08,708 root INFO Epoch 17 Global steps: 51400 Train loss: 0.0601
en_zh Dev loss: 0.8328 r:0.4936
ro_en Dev loss: 0.3751 r:0.8185
Current avg r:0.6561 Best avg r: 0.6603
19:25:25,294 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:51,247 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:17,207 root INFO Epoch 17 Global steps: 51600 Train loss: 0.0587
en_zh Dev loss: 0.8103 r:0.4965
ro_en Dev loss: 0.3697 r:0.8183
Current avg r:0.6574 Best avg r: 0.6603
19:27:33,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:59,727 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:25,678 root INFO Epoch 17 Global steps: 51800 Train loss: 0.0585
en_zh Dev loss: 0.7981 r:0.4950
ro_en Dev loss: 0.3506 r:0.8176
Current avg r:0.6563 Best avg r: 0.6603
19:29:42,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:08,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:34,163 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
19:30:34,170 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
19:31:00,137 root INFO Epoch 17 Global steps: 52000 Train loss: 0.0578
en_zh Dev loss: 0.7533 r:0.5022
ro_en Dev loss: 0.3363 r:0.8184
Current avg r:0.6603 Best avg r: 0.6603
19:32:16,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:42,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:08,585 root INFO Epoch 17 Global steps: 52200 Train loss: 0.0584
en_zh Dev loss: 0.8343 r:0.4949
ro_en Dev loss: 0.3649 r:0.8196
Current avg r:0.6573 Best avg r: 0.6603
19:34:25,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:51,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:17,9 root INFO Epoch 17 Global steps: 52400 Train loss: 0.0613
en_zh Dev loss: 0.7778 r:0.4951
ro_en Dev loss: 0.3481 r:0.8199
Current avg r:0.6575 Best avg r: 0.6603
19:36:33,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:59,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:25,412 root INFO Epoch 17 Global steps: 52600 Train loss: 0.0612
en_zh Dev loss: 0.7942 r:0.4830
ro_en Dev loss: 0.3637 r:0.8163
Current avg r:0.6496 Best avg r: 0.6603
19:38:41,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:07,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:39:33,742 root INFO Epoch 17 Global steps: 52800 Train loss: 0.0647
en_zh Dev loss: 0.7629 r:0.4920
ro_en Dev loss: 0.3652 r:0.8148
Current avg r:0.6534 Best avg r: 0.6603
19:40:50,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:16,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:42,120 root INFO Epoch 17 Global steps: 53000 Train loss: 0.0659
en_zh Dev loss: 0.7825 r:0.4948
ro_en Dev loss: 0.3540 r:0.8184
Current avg r:0.6566 Best avg r: 0.6603
19:42:58,654 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:24,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:50,519 root INFO Epoch 17 Global steps: 53200 Train loss: 0.0588
en_zh Dev loss: 0.7770 r:0.4942
ro_en Dev loss: 0.3612 r:0.8148
Current avg r:0.6545 Best avg r: 0.6603
19:45:07,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:32,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:58,903 root INFO Epoch 17 Global steps: 53400 Train loss: 0.0606
en_zh Dev loss: 0.7530 r:0.4948
ro_en Dev loss: 0.3489 r:0.8179
Current avg r:0.6563 Best avg r: 0.6603
19:47:15,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:41,414 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:07,371 root INFO Epoch 17 Global steps: 53600 Train loss: 0.0634
en_zh Dev loss: 0.8096 r:0.4978
ro_en Dev loss: 0.3874 r:0.8164
Current avg r:0.6571 Best avg r: 0.6603
19:49:23,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:49,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:15,773 root INFO Epoch 17 Global steps: 53800 Train loss: 0.0622
en_zh Dev loss: 0.7602 r:0.4952
ro_en Dev loss: 0.3330 r:0.8185
Current avg r:0.6569 Best avg r: 0.6603
19:51:32,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:58,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:24,198 root INFO Epoch 17 Global steps: 54000 Train loss: 0.0590
en_zh Dev loss: 0.7623 r:0.4997
ro_en Dev loss: 0.3476 r:0.8184
Current avg r:0.6591 Best avg r: 0.6603
19:53:41,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:06,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:32,926 root INFO Epoch 18 Global steps: 54200 Train loss: 0.0592
en_zh Dev loss: 0.7600 r:0.4978
ro_en Dev loss: 0.3573 r:0.8151
Current avg r:0.6565 Best avg r: 0.6603
19:55:49,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:15,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:41,350 root INFO Epoch 18 Global steps: 54400 Train loss: 0.0577
en_zh Dev loss: 0.7713 r:0.4974
ro_en Dev loss: 0.3474 r:0.8194
Current avg r:0.6584 Best avg r: 0.6603
19:57:57,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:23,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:49,807 root INFO Epoch 18 Global steps: 54600 Train loss: 0.0512
en_zh Dev loss: 0.8309 r:0.4878
ro_en Dev loss: 0.3660 r:0.8172
Current avg r:0.6525 Best avg r: 0.6603
20:00:06,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:32,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:58,245 root INFO Epoch 18 Global steps: 54800 Train loss: 0.0566
en_zh Dev loss: 0.7351 r:0.4967
ro_en Dev loss: 0.3390 r:0.8172
Current avg r:0.6570 Best avg r: 0.6603
20:02:14,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:40,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:06,692 root INFO Epoch 18 Global steps: 55000 Train loss: 0.0578
en_zh Dev loss: 0.8066 r:0.4891
ro_en Dev loss: 0.3814 r:0.8141
Current avg r:0.6516 Best avg r: 0.6603
20:04:23,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:49,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:15,149 root INFO Epoch 18 Global steps: 55200 Train loss: 0.0596
en_zh Dev loss: 0.7715 r:0.4960
ro_en Dev loss: 0.3806 r:0.8147
Current avg r:0.6554 Best avg r: 0.6603
20:06:31,726 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:57,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:23,597 root INFO Epoch 18 Global steps: 55400 Train loss: 0.0581
en_zh Dev loss: 0.7807 r:0.4972
ro_en Dev loss: 0.3649 r:0.8172
Current avg r:0.6572 Best avg r: 0.6603
20:08:40,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:06,130 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:32,97 root INFO Epoch 18 Global steps: 55600 Train loss: 0.0565
en_zh Dev loss: 0.8050 r:0.4971
ro_en Dev loss: 0.3824 r:0.8165
Current avg r:0.6568 Best avg r: 0.6603
20:10:48,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:14,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:40,514 root INFO Epoch 18 Global steps: 55800 Train loss: 0.0567
en_zh Dev loss: 0.8073 r:0.4984
ro_en Dev loss: 0.3632 r:0.8206
Current avg r:0.6595 Best avg r: 0.6603
20:12:57,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:23,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:48,968 root INFO Epoch 18 Global steps: 56000 Train loss: 0.0567
en_zh Dev loss: 0.7883 r:0.4968
ro_en Dev loss: 0.3775 r:0.8187
Current avg r:0.6577 Best avg r: 0.6603
20:15:05,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:31,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:57,406 root INFO Epoch 18 Global steps: 56200 Train loss: 0.0535
en_zh Dev loss: 0.7777 r:0.4963
ro_en Dev loss: 0.3577 r:0.8178
Current avg r:0.6570 Best avg r: 0.6603
20:17:13,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:39,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:05,837 root INFO Epoch 18 Global steps: 56400 Train loss: 0.0597
en_zh Dev loss: 0.8277 r:0.4923
ro_en Dev loss: 0.3761 r:0.8171
Current avg r:0.6547 Best avg r: 0.6603
20:19:22,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:48,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:14,214 root INFO Epoch 18 Global steps: 56600 Train loss: 0.0509
en_zh Dev loss: 0.7963 r:0.4941
ro_en Dev loss: 0.3563 r:0.8198
Current avg r:0.6570 Best avg r: 0.6603
20:21:30,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:56,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:22,646 root INFO Epoch 18 Global steps: 56800 Train loss: 0.0596
en_zh Dev loss: 0.7362 r:0.5013
ro_en Dev loss: 0.3279 r:0.8187
Current avg r:0.6600 Best avg r: 0.6603
20:23:39,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:05,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:31,22 root INFO Epoch 18 Global steps: 57000 Train loss: 0.0492
en_zh Dev loss: 0.7701 r:0.4988
ro_en Dev loss: 0.3505 r:0.8167
Current avg r:0.6578 Best avg r: 0.6603
20:25:47,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:26:13,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:39,814 root INFO Epoch 19 Global steps: 57200 Train loss: 0.0516
en_zh Dev loss: 0.8299 r:0.4978
ro_en Dev loss: 0.3678 r:0.8162
Current avg r:0.6570 Best avg r: 0.6603
20:27:56,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:22,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:28:48,190 root INFO Epoch 19 Global steps: 57400 Train loss: 0.0546
en_zh Dev loss: 0.7494 r:0.5039
ro_en Dev loss: 0.3520 r:0.8159
Current avg r:0.6599 Best avg r: 0.6603
20:30:04,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:30,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:56,606 root INFO Epoch 19 Global steps: 57600 Train loss: 0.0548
en_zh Dev loss: 0.7824 r:0.4999
ro_en Dev loss: 0.3355 r:0.8165
Current avg r:0.6582 Best avg r: 0.6603
20:32:13,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:39,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:05,82 root INFO Epoch 19 Global steps: 57800 Train loss: 0.0500
en_zh Dev loss: 0.7814 r:0.4990
ro_en Dev loss: 0.3536 r:0.8161
Current avg r:0.6575 Best avg r: 0.6603
20:34:21,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:47,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:13,517 root INFO Epoch 19 Global steps: 58000 Train loss: 0.0530
en_zh Dev loss: 0.7748 r:0.4998
ro_en Dev loss: 0.3730 r:0.8142
Current avg r:0.6570 Best avg r: 0.6603
20:36:30,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:56,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:21,960 root INFO Epoch 19 Global steps: 58200 Train loss: 0.0530
en_zh Dev loss: 0.7721 r:0.4997
ro_en Dev loss: 0.3513 r:0.8158
Current avg r:0.6578 Best avg r: 0.6603
20:38:38,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:04,434 root INFO 
id:en_zh cur r: 0.5080 best r: 0.5080
20:39:17,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:43,360 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:39:43,366 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:40:09,327 root INFO Epoch 19 Global steps: 58400 Train loss: 0.0516
en_zh Dev loss: 0.7614 r:0.5056
ro_en Dev loss: 0.3619 r:0.8185
Current avg r:0.6620 Best avg r: 0.6620
20:41:25,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:51,831 root INFO 
id:en_zh cur r: 0.5092 best r: 0.5092
20:42:04,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:30,777 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:42:30,782 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:42:56,780 root INFO Epoch 19 Global steps: 58600 Train loss: 0.0554
en_zh Dev loss: 0.7387 r:0.5075
ro_en Dev loss: 0.3323 r:0.8198
Current avg r:0.6636 Best avg r: 0.6636
20:44:13,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:39,328 root INFO 
id:en_zh cur r: 0.5103 best r: 0.5103
20:44:52,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:18,261 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:45:18,299 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:45:44,323 root INFO Epoch 19 Global steps: 58800 Train loss: 0.0548
en_zh Dev loss: 0.7462 r:0.5077
ro_en Dev loss: 0.3204 r:0.8200
Current avg r:0.6638 Best avg r: 0.6638
20:47:00,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:26,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:52,765 root INFO Epoch 19 Global steps: 59000 Train loss: 0.0547
en_zh Dev loss: 0.7812 r:0.5056
ro_en Dev loss: 0.3574 r:0.8181
Current avg r:0.6619 Best avg r: 0.6638
20:49:09,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:35,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:01,220 root INFO Epoch 19 Global steps: 59200 Train loss: 0.0507
en_zh Dev loss: 0.7608 r:0.5055
ro_en Dev loss: 0.3722 r:0.8168
Current avg r:0.6612 Best avg r: 0.6638
20:51:17,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:43,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:09,559 root INFO Epoch 19 Global steps: 59400 Train loss: 0.0530
en_zh Dev loss: 0.7363 r:0.5046
ro_en Dev loss: 0.3291 r:0.8198
Current avg r:0.6622 Best avg r: 0.6638
20:53:26,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:52,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:17,953 root INFO Epoch 19 Global steps: 59600 Train loss: 0.0557
en_zh Dev loss: 0.7654 r:0.5035
ro_en Dev loss: 0.3472 r:0.8221
Current avg r:0.6628 Best avg r: 0.6638
20:55:34,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:00,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:26,369 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:56:26,377 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:56:52,345 root INFO Epoch 19 Global steps: 59800 Train loss: 0.0507
en_zh Dev loss: 0.7551 r:0.5049
ro_en Dev loss: 0.3433 r:0.8236
Current avg r:0.6642 Best avg r: 0.6642
20:58:08,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:34,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:00,685 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:59:00,694 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:59:26,672 root INFO Epoch 19 Global steps: 60000 Train loss: 0.0498
en_zh Dev loss: 0.7614 r:0.5031
ro_en Dev loss: 0.3366 r:0.8254
Current avg r:0.6642 Best avg r: 0.6642
