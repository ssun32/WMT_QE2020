14:42:29,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:55,105 root INFO 
id:en_zh cur r: 0.0834 best r: 0.0834
14:43:20,885 root INFO 
id:ro_en cur r: 0.1800 best r: 0.1800
14:43:20,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:46,598 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:43:46,604 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:44:12,315 root INFO Epoch 0 Global steps: 200 Train loss: 0.9331
en_zh Dev loss: 0.8172 r:0.0505
ro_en Dev loss: 0.8495 r:0.3156
Current avg r:0.1830 Best avg r: 0.1830
14:45:28,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:54,381 root INFO 
id:en_zh cur r: 0.1413 best r: 0.1413
14:46:20,135 root INFO 
id:ro_en cur r: 0.3892 best r: 0.3892
14:46:20,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:45,825 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:46:45,831 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:47:11,548 root INFO Epoch 0 Global steps: 400 Train loss: 0.9273
en_zh Dev loss: 0.8173 r:0.1258
ro_en Dev loss: 0.8303 r:0.4766
Current avg r:0.3012 Best avg r: 0.3012
14:48:28,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:53,765 root INFO 
id:en_zh cur r: 0.1855 best r: 0.1855
14:49:19,514 root INFO 
id:ro_en cur r: 0.4612 best r: 0.4612
14:49:19,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:45,215 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:49:45,220 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:50:10,933 root INFO Epoch 0 Global steps: 600 Train loss: 0.8822
en_zh Dev loss: 0.8032 r:0.2230
ro_en Dev loss: 0.8105 r:0.5027
Current avg r:0.3629 Best avg r: 0.3629
14:51:27,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:53,204 root INFO 
id:en_zh cur r: 0.2304 best r: 0.2304
14:52:18,961 root INFO 
id:ro_en cur r: 0.5948 best r: 0.5948
14:52:18,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:44,660 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:52:44,667 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:53:10,374 root INFO Epoch 0 Global steps: 800 Train loss: 0.9062
en_zh Dev loss: 0.8028 r:0.2533
ro_en Dev loss: 0.8099 r:0.6138
Current avg r:0.4335 Best avg r: 0.4335
14:54:27,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:52,686 root INFO 
id:en_zh cur r: 0.2825 best r: 0.2825
14:55:18,453 root INFO 
id:ro_en cur r: 0.6230 best r: 0.6230
14:55:18,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:44,145 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:55:44,151 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:56:09,880 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8501
en_zh Dev loss: 0.7673 r:0.3049
ro_en Dev loss: 0.7281 r:0.6371
Current avg r:0.4710 Best avg r: 0.4710
14:57:26,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:04,939 root INFO 
id:ro_en cur r: 0.6468 best r: 0.6468
14:58:04,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:30,642 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:58:30,648 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:58:56,352 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7989
en_zh Dev loss: 0.7983 r:0.3187
ro_en Dev loss: 0.7316 r:0.6324
Current avg r:0.4755 Best avg r: 0.4755
15:00:12,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:38,576 root INFO 
id:en_zh cur r: 0.3405 best r: 0.3405
15:01:04,335 root INFO 
id:ro_en cur r: 0.6826 best r: 0.6826
15:01:04,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:01:30,19 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:01:30,27 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:01:55,739 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7721
en_zh Dev loss: 0.7352 r:0.3460
ro_en Dev loss: 0.6125 r:0.6839
Current avg r:0.5149 Best avg r: 0.5149
15:03:12,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:37,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:03,695 root INFO Epoch 0 Global steps: 1600 Train loss: 0.6786
en_zh Dev loss: 0.8441 r:0.3209
ro_en Dev loss: 0.6654 r:0.6646
Current avg r:0.4927 Best avg r: 0.5149
15:05:20,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:45,862 root INFO 
id:en_zh cur r: 0.3744 best r: 0.3744
15:06:11,618 root INFO 
id:ro_en cur r: 0.7108 best r: 0.7108
15:06:11,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:37,323 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:06:37,330 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:07:03,42 root INFO Epoch 0 Global steps: 1800 Train loss: 0.6744
en_zh Dev loss: 0.7258 r:0.3665
ro_en Dev loss: 0.4677 r:0.7068
Current avg r:0.5367 Best avg r: 0.5367
15:08:19,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:58,199 root INFO 
id:ro_en cur r: 0.7190 best r: 0.7190
15:08:58,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:23,891 root INFO Epoch 0 Global steps: 2000 Train loss: 0.6792
en_zh Dev loss: 0.7777 r:0.3478
ro_en Dev loss: 0.5047 r:0.7110
Current avg r:0.5294 Best avg r: 0.5367
15:10:40,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:19,180 root INFO 
id:ro_en cur r: 0.7320 best r: 0.7320
15:11:19,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:44,883 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:11:44,888 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:12:10,622 root INFO Epoch 0 Global steps: 2200 Train loss: 0.6283
en_zh Dev loss: 0.7696 r:0.3618
ro_en Dev loss: 0.4665 r:0.7310
Current avg r:0.5464 Best avg r: 0.5464
15:13:27,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:52,922 root INFO 
id:en_zh cur r: 0.3985 best r: 0.3985
15:14:18,698 root INFO 
id:ro_en cur r: 0.7365 best r: 0.7365
15:14:18,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:44,422 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:14:44,436 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:15:10,164 root INFO Epoch 0 Global steps: 2400 Train loss: 0.5858
en_zh Dev loss: 0.7165 r:0.3913
ro_en Dev loss: 0.4452 r:0.7313
Current avg r:0.5613 Best avg r: 0.5613
15:16:26,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:52,546 root INFO 
id:en_zh cur r: 0.4299 best r: 0.4299
15:17:18,313 root INFO 
id:ro_en cur r: 0.7541 best r: 0.7541
15:17:18,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:44,29 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:17:44,36 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:18:09,771 root INFO Epoch 0 Global steps: 2600 Train loss: 0.5925
en_zh Dev loss: 0.6833 r:0.4248
ro_en Dev loss: 0.3853 r:0.7521
Current avg r:0.5885 Best avg r: 0.5885
15:19:26,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:04,873 root INFO 
id:ro_en cur r: 0.7585 best r: 0.7585
15:20:04,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:30,525 root INFO Epoch 0 Global steps: 2800 Train loss: 0.5810
en_zh Dev loss: 0.8633 r:0.3786
ro_en Dev loss: 0.4950 r:0.7552
Current avg r:0.5669 Best avg r: 0.5885
15:21:47,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:25,620 root INFO 
id:ro_en cur r: 0.7722 best r: 0.7722
15:22:25,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:51,330 root INFO Epoch 0 Global steps: 3000 Train loss: 0.5027
en_zh Dev loss: 0.7754 r:0.3908
ro_en Dev loss: 0.4382 r:0.7696
Current avg r:0.5802 Best avg r: 0.5885
15:24:08,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:46,794 root INFO 
id:ro_en cur r: 0.7843 best r: 0.7843
15:24:46,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:12,496 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:25:12,501 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:25:38,214 root INFO Epoch 1 Global steps: 3200 Train loss: 0.5016
en_zh Dev loss: 0.7485 r:0.4037
ro_en Dev loss: 0.4008 r:0.7781
Current avg r:0.5909 Best avg r: 0.5909
15:26:54,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:33,423 root INFO 
id:ro_en cur r: 0.7868 best r: 0.7868
15:27:33,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:59,124 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:27:59,131 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:28:24,844 root INFO Epoch 1 Global steps: 3400 Train loss: 0.5004
en_zh Dev loss: 0.7974 r:0.4108
ro_en Dev loss: 0.3994 r:0.7822
Current avg r:0.5965 Best avg r: 0.5965
15:29:41,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:07,107 root INFO 
id:en_zh cur r: 0.4521 best r: 0.4521
15:30:32,864 root INFO 
id:ro_en cur r: 0.8001 best r: 0.8001
15:30:32,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:58,557 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:30:58,562 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:31:24,264 root INFO Epoch 1 Global steps: 3600 Train loss: 0.4955
en_zh Dev loss: 0.7142 r:0.4440
ro_en Dev loss: 0.3352 r:0.7966
Current avg r:0.6203 Best avg r: 0.6203
15:32:40,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:06,449 root INFO 
id:en_zh cur r: 0.4671 best r: 0.4671
15:33:32,203 root INFO 
id:ro_en cur r: 0.8037 best r: 0.8037
15:33:32,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:57,897 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:33:57,904 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:34:23,618 root INFO Epoch 1 Global steps: 3800 Train loss: 0.4448
en_zh Dev loss: 0.6736 r:0.4596
ro_en Dev loss: 0.3367 r:0.8008
Current avg r:0.6302 Best avg r: 0.6302
15:35:40,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:18,739 root INFO 
id:ro_en cur r: 0.8066 best r: 0.8066
15:36:18,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:44,437 root INFO Epoch 1 Global steps: 4000 Train loss: 0.4888
en_zh Dev loss: 0.7197 r:0.4458
ro_en Dev loss: 0.3277 r:0.8066
Current avg r:0.6262 Best avg r: 0.6302
15:38:00,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:39,521 root INFO 
id:ro_en cur r: 0.8099 best r: 0.8099
15:38:39,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:05,220 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:39:05,225 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:39:30,936 root INFO Epoch 1 Global steps: 4200 Train loss: 0.4422
en_zh Dev loss: 0.6754 r:0.4622
ro_en Dev loss: 0.3052 r:0.8093
Current avg r:0.6358 Best avg r: 0.6358
15:40:47,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:13,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:38,714 root INFO Epoch 1 Global steps: 4400 Train loss: 0.4785
en_zh Dev loss: 0.7474 r:0.4557
ro_en Dev loss: 0.3698 r:0.8034
Current avg r:0.6296 Best avg r: 0.6358
15:42:55,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:33,733 root INFO 
id:ro_en cur r: 0.8108 best r: 0.8108
15:43:33,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:59,427 root INFO Epoch 1 Global steps: 4600 Train loss: 0.4830
en_zh Dev loss: 0.6804 r:0.4510
ro_en Dev loss: 0.3133 r:0.8093
Current avg r:0.6301 Best avg r: 0.6358
15:45:15,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:45:41,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:07,350 root INFO Epoch 1 Global steps: 4800 Train loss: 0.4532
en_zh Dev loss: 0.7613 r:0.4241
ro_en Dev loss: 0.3589 r:0.8099
Current avg r:0.6170 Best avg r: 0.6358
15:47:23,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:02,422 root INFO 
id:ro_en cur r: 0.8200 best r: 0.8200
15:48:02,422 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:28,116 root INFO Epoch 1 Global steps: 5000 Train loss: 0.4511
en_zh Dev loss: 0.7035 r:0.4512
ro_en Dev loss: 0.3071 r:0.8183
Current avg r:0.6348 Best avg r: 0.6358
15:49:44,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:10,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:35,909 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:50:35,915 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:51:01,623 root INFO Epoch 1 Global steps: 5200 Train loss: 0.4644
en_zh Dev loss: 0.7111 r:0.4635
ro_en Dev loss: 0.3308 r:0.8185
Current avg r:0.6410 Best avg r: 0.6410
15:52:18,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:43,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:09,511 root INFO Epoch 1 Global steps: 5400 Train loss: 0.4702
en_zh Dev loss: 0.6711 r:0.4597
ro_en Dev loss: 0.3169 r:0.8159
Current avg r:0.6378 Best avg r: 0.6410
15:54:26,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:51,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:17,433 root INFO Epoch 1 Global steps: 5600 Train loss: 0.4623
en_zh Dev loss: 0.7698 r:0.4336
ro_en Dev loss: 0.3929 r:0.8109
Current avg r:0.6222 Best avg r: 0.6410
15:56:33,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:12,527 root INFO 
id:ro_en cur r: 0.8202 best r: 0.8202
15:57:12,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:38,222 root INFO Epoch 1 Global steps: 5800 Train loss: 0.4132
en_zh Dev loss: 0.7526 r:0.4451
ro_en Dev loss: 0.3385 r:0.8181
Current avg r:0.6316 Best avg r: 0.6410
15:58:54,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:33,324 root INFO 
id:ro_en cur r: 0.8260 best r: 0.8260
15:59:33,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:59,16 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:59:59,22 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:00:24,751 root INFO Epoch 1 Global steps: 6000 Train loss: 0.4518
en_zh Dev loss: 0.6759 r:0.4631
ro_en Dev loss: 0.3266 r:0.8239
Current avg r:0.6435 Best avg r: 0.6435
16:01:41,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:02:07,362 root INFO 
id:en_zh cur r: 0.4718 best r: 0.4718
16:02:33,120 root INFO 
id:ro_en cur r: 0.8265 best r: 0.8265
16:02:33,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:58,814 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:02:58,820 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:03:24,523 root INFO Epoch 2 Global steps: 6200 Train loss: 0.3857
en_zh Dev loss: 0.7124 r:0.4707
ro_en Dev loss: 0.3473 r:0.8262
Current avg r:0.6485 Best avg r: 0.6485
16:04:41,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:06,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:32,401 root INFO Epoch 2 Global steps: 6400 Train loss: 0.4169
en_zh Dev loss: 0.6716 r:0.4648
ro_en Dev loss: 0.3258 r:0.8252
Current avg r:0.6450 Best avg r: 0.6485
16:06:48,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:14,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:40,295 root INFO Epoch 2 Global steps: 6600 Train loss: 0.4054
en_zh Dev loss: 0.7269 r:0.4509
ro_en Dev loss: 0.3345 r:0.8235
Current avg r:0.6372 Best avg r: 0.6485
16:08:56,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:22,512 root INFO 
id:en_zh cur r: 0.4725 best r: 0.4725
16:09:35,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:01,78 root INFO Epoch 2 Global steps: 6800 Train loss: 0.4063
en_zh Dev loss: 0.6935 r:0.4688
ro_en Dev loss: 0.3363 r:0.8226
Current avg r:0.6457 Best avg r: 0.6485
16:11:17,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:43,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:09,8 root INFO Epoch 2 Global steps: 7000 Train loss: 0.3722
en_zh Dev loss: 0.7136 r:0.4600
ro_en Dev loss: 0.3281 r:0.8192
Current avg r:0.6396 Best avg r: 0.6485
16:13:25,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:51,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:16,847 root INFO Epoch 2 Global steps: 7200 Train loss: 0.4021
en_zh Dev loss: 0.8428 r:0.4426
ro_en Dev loss: 0.3535 r:0.8208
Current avg r:0.6317 Best avg r: 0.6485
16:15:33,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:59,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:24,801 root INFO Epoch 2 Global steps: 7400 Train loss: 0.4124
en_zh Dev loss: 0.7743 r:0.4606
ro_en Dev loss: 0.3768 r:0.8149
Current avg r:0.6377 Best avg r: 0.6485
16:17:41,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:07,6 root INFO 
id:en_zh cur r: 0.4836 best r: 0.4836
16:18:19,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:45,561 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:18:45,567 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:19:11,270 root INFO Epoch 2 Global steps: 7600 Train loss: 0.4154
en_zh Dev loss: 0.6603 r:0.4868
ro_en Dev loss: 0.3096 r:0.8246
Current avg r:0.6557 Best avg r: 0.6557
16:20:27,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:53,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:19,137 root INFO Epoch 2 Global steps: 7800 Train loss: 0.3787
en_zh Dev loss: 0.7764 r:0.4645
ro_en Dev loss: 0.3660 r:0.8193
Current avg r:0.6419 Best avg r: 0.6557
16:22:35,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:01,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:27,19 root INFO Epoch 2 Global steps: 8000 Train loss: 0.3773
en_zh Dev loss: 0.6916 r:0.4776
ro_en Dev loss: 0.3296 r:0.8250
Current avg r:0.6513 Best avg r: 0.6557
16:24:43,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:09,226 root INFO 
id:en_zh cur r: 0.4955 best r: 0.4955
16:25:34,990 root INFO 
id:ro_en cur r: 0.8285 best r: 0.8285
16:25:34,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:00,684 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:26:00,691 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:26:26,413 root INFO Epoch 2 Global steps: 8200 Train loss: 0.3972
en_zh Dev loss: 0.6584 r:0.4957
ro_en Dev loss: 0.3045 r:0.8277
Current avg r:0.6617 Best avg r: 0.6617
16:27:42,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:21,486 root INFO 
id:ro_en cur r: 0.8303 best r: 0.8303
16:28:21,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:47,186 root INFO Epoch 2 Global steps: 8400 Train loss: 0.3694
en_zh Dev loss: 0.6635 r:0.4932
ro_en Dev loss: 0.2968 r:0.8295
Current avg r:0.6614 Best avg r: 0.6617
16:30:03,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:29,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:55,54 root INFO Epoch 2 Global steps: 8600 Train loss: 0.3905
en_zh Dev loss: 0.7346 r:0.4705
ro_en Dev loss: 0.3113 r:0.8254
Current avg r:0.6480 Best avg r: 0.6617
16:32:11,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:37,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:02,934 root INFO Epoch 2 Global steps: 8800 Train loss: 0.3572
en_zh Dev loss: 0.7891 r:0.4558
ro_en Dev loss: 0.4055 r:0.8182
Current avg r:0.6370 Best avg r: 0.6617
16:34:19,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:45,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:10,948 root INFO Epoch 2 Global steps: 9000 Train loss: 0.3492
en_zh Dev loss: 0.7373 r:0.4690
ro_en Dev loss: 0.3523 r:0.8203
Current avg r:0.6446 Best avg r: 0.6617
16:36:27,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:53,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:19,364 root INFO Epoch 3 Global steps: 9200 Train loss: 0.3117
en_zh Dev loss: 0.7785 r:0.4626
ro_en Dev loss: 0.3504 r:0.8228
Current avg r:0.6427 Best avg r: 0.6617
16:38:35,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:01,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:27,269 root INFO Epoch 3 Global steps: 9400 Train loss: 0.3470
en_zh Dev loss: 0.7750 r:0.4545
ro_en Dev loss: 0.3477 r:0.8190
Current avg r:0.6368 Best avg r: 0.6617
16:40:43,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:09,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:35,300 root INFO Epoch 3 Global steps: 9600 Train loss: 0.2982
en_zh Dev loss: 0.7971 r:0.4734
ro_en Dev loss: 0.3819 r:0.8206
Current avg r:0.6470 Best avg r: 0.6617
16:42:51,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:17,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:43,322 root INFO Epoch 3 Global steps: 9800 Train loss: 0.3040
en_zh Dev loss: 0.6881 r:0.4862
ro_en Dev loss: 0.3163 r:0.8258
Current avg r:0.6560 Best avg r: 0.6617
16:44:59,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:25,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:51,344 root INFO Epoch 3 Global steps: 10000 Train loss: 0.3598
en_zh Dev loss: 0.8358 r:0.4697
ro_en Dev loss: 0.3767 r:0.8216
Current avg r:0.6457 Best avg r: 0.6617
16:47:07,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:33,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:59,228 root INFO Epoch 3 Global steps: 10200 Train loss: 0.3130
en_zh Dev loss: 0.7033 r:0.4809
ro_en Dev loss: 0.3336 r:0.8248
Current avg r:0.6529 Best avg r: 0.6617
16:49:15,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:41,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:07,96 root INFO Epoch 3 Global steps: 10400 Train loss: 0.3143
en_zh Dev loss: 0.7222 r:0.4841
ro_en Dev loss: 0.3304 r:0.8258
Current avg r:0.6549 Best avg r: 0.6617
16:51:23,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:49,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:15,68 root INFO Epoch 3 Global steps: 10600 Train loss: 0.3147
en_zh Dev loss: 0.6952 r:0.4849
ro_en Dev loss: 0.3376 r:0.8254
Current avg r:0.6551 Best avg r: 0.6617
16:53:31,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:57,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:22,977 root INFO Epoch 3 Global steps: 10800 Train loss: 0.3094
en_zh Dev loss: 0.6729 r:0.4867
ro_en Dev loss: 0.3189 r:0.8260
Current avg r:0.6564 Best avg r: 0.6617
16:55:39,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:05,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:30,820 root INFO Epoch 3 Global steps: 11000 Train loss: 0.3099
en_zh Dev loss: 0.7393 r:0.4553
ro_en Dev loss: 0.3479 r:0.8190
Current avg r:0.6372 Best avg r: 0.6617
16:57:47,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:13,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:38,812 root INFO Epoch 3 Global steps: 11200 Train loss: 0.3119
en_zh Dev loss: 0.6713 r:0.4880
ro_en Dev loss: 0.3014 r:0.8269
Current avg r:0.6574 Best avg r: 0.6617
16:59:55,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:21,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:46,855 root INFO Epoch 3 Global steps: 11400 Train loss: 0.3265
en_zh Dev loss: 0.6830 r:0.4933
ro_en Dev loss: 0.3180 r:0.8240
Current avg r:0.6587 Best avg r: 0.6617
17:02:03,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:29,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:54,771 root INFO Epoch 3 Global steps: 11600 Train loss: 0.3155
en_zh Dev loss: 0.7609 r:0.4566
ro_en Dev loss: 0.3505 r:0.8164
Current avg r:0.6365 Best avg r: 0.6617
17:04:11,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:36,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:02,667 root INFO Epoch 3 Global steps: 11800 Train loss: 0.3092
en_zh Dev loss: 0.8055 r:0.4672
ro_en Dev loss: 0.3625 r:0.8193
Current avg r:0.6432 Best avg r: 0.6617
17:06:19,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:44,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:10,662 root INFO Epoch 3 Global steps: 12000 Train loss: 0.3214
en_zh Dev loss: 0.7215 r:0.4688
ro_en Dev loss: 0.3207 r:0.8172
Current avg r:0.6430 Best avg r: 0.6617
17:08:27,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:53,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:18,826 root INFO Epoch 4 Global steps: 12200 Train loss: 0.2967
en_zh Dev loss: 0.7633 r:0.4614
ro_en Dev loss: 0.3461 r:0.8169
Current avg r:0.6391 Best avg r: 0.6617
17:10:35,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:01,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:26,706 root INFO Epoch 4 Global steps: 12400 Train loss: 0.2530
en_zh Dev loss: 0.7553 r:0.4813
ro_en Dev loss: 0.3728 r:0.8208
Current avg r:0.6511 Best avg r: 0.6617
17:12:43,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:08,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:34,708 root INFO Epoch 4 Global steps: 12600 Train loss: 0.2660
en_zh Dev loss: 0.9641 r:0.4384
ro_en Dev loss: 0.4733 r:0.8029
Current avg r:0.6206 Best avg r: 0.6617
17:14:51,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:17,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:42,724 root INFO Epoch 4 Global steps: 12800 Train loss: 0.2647
en_zh Dev loss: 0.7157 r:0.4812
ro_en Dev loss: 0.3242 r:0.8213
Current avg r:0.6513 Best avg r: 0.6617
17:16:59,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:24,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:50,637 root INFO Epoch 4 Global steps: 13000 Train loss: 0.2890
en_zh Dev loss: 0.7151 r:0.4849
ro_en Dev loss: 0.3465 r:0.8178
Current avg r:0.6514 Best avg r: 0.6617
17:19:07,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:32,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:58,502 root INFO Epoch 4 Global steps: 13200 Train loss: 0.2778
en_zh Dev loss: 0.7195 r:0.4740
ro_en Dev loss: 0.3210 r:0.8225
Current avg r:0.6483 Best avg r: 0.6617
17:21:15,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:40,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:06,433 root INFO Epoch 4 Global steps: 13400 Train loss: 0.2741
en_zh Dev loss: 0.7465 r:0.4654
ro_en Dev loss: 0.3501 r:0.8182
Current avg r:0.6418 Best avg r: 0.6617
17:23:23,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:48,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:14,465 root INFO Epoch 4 Global steps: 13600 Train loss: 0.2564
en_zh Dev loss: 0.7389 r:0.4675
ro_en Dev loss: 0.3479 r:0.8164
Current avg r:0.6419 Best avg r: 0.6617
17:25:31,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:56,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:22,670 root INFO Epoch 4 Global steps: 13800 Train loss: 0.2576
en_zh Dev loss: 0.7431 r:0.4663
ro_en Dev loss: 0.3673 r:0.8170
Current avg r:0.6417 Best avg r: 0.6617
17:27:39,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:04,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:30,522 root INFO Epoch 4 Global steps: 14000 Train loss: 0.2710
en_zh Dev loss: 0.7094 r:0.4880
ro_en Dev loss: 0.3397 r:0.8199
Current avg r:0.6540 Best avg r: 0.6617
17:29:46,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:12,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:38,358 root INFO Epoch 4 Global steps: 14200 Train loss: 0.2637
en_zh Dev loss: 0.7367 r:0.4737
ro_en Dev loss: 0.3560 r:0.8211
Current avg r:0.6474 Best avg r: 0.6617
17:31:54,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:20,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:46,193 root INFO Epoch 4 Global steps: 14400 Train loss: 0.2567
en_zh Dev loss: 0.7657 r:0.4565
ro_en Dev loss: 0.3468 r:0.8177
Current avg r:0.6371 Best avg r: 0.6617
17:34:02,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:28,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:54,3 root INFO Epoch 4 Global steps: 14600 Train loss: 0.2731
en_zh Dev loss: 0.6962 r:0.4944
ro_en Dev loss: 0.3248 r:0.8195
Current avg r:0.6569 Best avg r: 0.6617
17:36:10,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:36,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:01,812 root INFO Epoch 4 Global steps: 14800 Train loss: 0.2491
en_zh Dev loss: 0.7760 r:0.4786
ro_en Dev loss: 0.3584 r:0.8196
Current avg r:0.6491 Best avg r: 0.6617
17:38:18,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:43,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:09,661 root INFO Epoch 4 Global steps: 15000 Train loss: 0.2377
en_zh Dev loss: 0.7322 r:0.4858
ro_en Dev loss: 0.3616 r:0.8176
Current avg r:0.6517 Best avg r: 0.6617
17:40:26,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:52,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:17,834 root INFO Epoch 5 Global steps: 15200 Train loss: 0.2316
en_zh Dev loss: 0.7475 r:0.4712
ro_en Dev loss: 0.3467 r:0.8176
Current avg r:0.6444 Best avg r: 0.6617
17:42:34,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:00,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:25,696 root INFO Epoch 5 Global steps: 15400 Train loss: 0.2249
en_zh Dev loss: 0.7193 r:0.4750
ro_en Dev loss: 0.3238 r:0.8229
Current avg r:0.6490 Best avg r: 0.6617
17:44:42,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:08,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:33,707 root INFO Epoch 5 Global steps: 15600 Train loss: 0.2191
en_zh Dev loss: 0.7296 r:0.4793
ro_en Dev loss: 0.3533 r:0.8207
Current avg r:0.6500 Best avg r: 0.6617
17:46:50,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:15,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:41,518 root INFO Epoch 5 Global steps: 15800 Train loss: 0.2160
en_zh Dev loss: 0.7270 r:0.4735
ro_en Dev loss: 0.3276 r:0.8218
Current avg r:0.6477 Best avg r: 0.6617
17:48:57,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:23,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:49,382 root INFO Epoch 5 Global steps: 16000 Train loss: 0.2177
en_zh Dev loss: 0.7335 r:0.4689
ro_en Dev loss: 0.3260 r:0.8217
Current avg r:0.6453 Best avg r: 0.6617
17:51:05,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:31,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:57,321 root INFO Epoch 5 Global steps: 16200 Train loss: 0.2195
en_zh Dev loss: 0.7226 r:0.4601
ro_en Dev loss: 0.3189 r:0.8225
Current avg r:0.6413 Best avg r: 0.6617
17:53:13,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:39,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:05,185 root INFO Epoch 5 Global steps: 16400 Train loss: 0.2221
en_zh Dev loss: 0.7770 r:0.4660
ro_en Dev loss: 0.3762 r:0.8206
Current avg r:0.6433 Best avg r: 0.6617
17:55:21,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:47,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:13,61 root INFO Epoch 5 Global steps: 16600 Train loss: 0.2375
en_zh Dev loss: 0.7678 r:0.4774
ro_en Dev loss: 0.3677 r:0.8224
Current avg r:0.6499 Best avg r: 0.6617
17:57:29,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:55,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:20,971 root INFO Epoch 5 Global steps: 16800 Train loss: 0.2173
en_zh Dev loss: 0.7052 r:0.4866
ro_en Dev loss: 0.3228 r:0.8225
Current avg r:0.6546 Best avg r: 0.6617
17:59:37,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:03,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:28,869 root INFO Epoch 5 Global steps: 17000 Train loss: 0.2043
en_zh Dev loss: 0.7560 r:0.4884
ro_en Dev loss: 0.3427 r:0.8255
Current avg r:0.6569 Best avg r: 0.6617
18:01:45,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:11,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:36,734 root INFO Epoch 5 Global steps: 17200 Train loss: 0.2081
en_zh Dev loss: 0.7659 r:0.4794
ro_en Dev loss: 0.3673 r:0.8214
Current avg r:0.6504 Best avg r: 0.6617
18:03:53,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:18,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:44,600 root INFO Epoch 5 Global steps: 17400 Train loss: 0.2208
en_zh Dev loss: 0.7255 r:0.4748
ro_en Dev loss: 0.3152 r:0.8229
Current avg r:0.6488 Best avg r: 0.6617
18:06:01,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:26,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:52,510 root INFO Epoch 5 Global steps: 17600 Train loss: 0.2068
en_zh Dev loss: 0.7227 r:0.4769
ro_en Dev loss: 0.3290 r:0.8197
Current avg r:0.6483 Best avg r: 0.6617
18:08:09,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:34,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:00,330 root INFO Epoch 5 Global steps: 17800 Train loss: 0.2182
en_zh Dev loss: 0.7652 r:0.4643
ro_en Dev loss: 0.3436 r:0.8201
Current avg r:0.6422 Best avg r: 0.6617
18:10:16,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:42,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:08,167 root INFO Epoch 5 Global steps: 18000 Train loss: 0.2100
en_zh Dev loss: 0.7475 r:0.4642
ro_en Dev loss: 0.3278 r:0.8211
Current avg r:0.6426 Best avg r: 0.6617
18:12:25,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:50,749 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:16,430 root INFO Epoch 6 Global steps: 18200 Train loss: 0.1929
en_zh Dev loss: 0.7735 r:0.4660
ro_en Dev loss: 0.3417 r:0.8202
Current avg r:0.6431 Best avg r: 0.6617
18:14:32,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:58,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:24,343 root INFO Epoch 6 Global steps: 18400 Train loss: 0.1766
en_zh Dev loss: 0.7870 r:0.4671
ro_en Dev loss: 0.3727 r:0.8159
Current avg r:0.6415 Best avg r: 0.6617
18:16:40,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:06,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:32,227 root INFO Epoch 6 Global steps: 18600 Train loss: 0.1972
en_zh Dev loss: 0.7837 r:0.4618
ro_en Dev loss: 0.3598 r:0.8138
Current avg r:0.6378 Best avg r: 0.6617
18:18:48,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:14,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:40,40 root INFO Epoch 6 Global steps: 18800 Train loss: 0.1824
en_zh Dev loss: 0.8090 r:0.4662
ro_en Dev loss: 0.3997 r:0.8104
Current avg r:0.6383 Best avg r: 0.6617
18:20:56,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:22,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:47,812 root INFO Epoch 6 Global steps: 19000 Train loss: 0.1826
en_zh Dev loss: 0.7761 r:0.4678
ro_en Dev loss: 0.3509 r:0.8160
Current avg r:0.6419 Best avg r: 0.6617
18:23:04,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:29,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:55,613 root INFO Epoch 6 Global steps: 19200 Train loss: 0.1850
en_zh Dev loss: 0.7461 r:0.4822
ro_en Dev loss: 0.3350 r:0.8195
Current avg r:0.6509 Best avg r: 0.6617
18:25:12,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:37,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:03,414 root INFO Epoch 6 Global steps: 19400 Train loss: 0.1878
en_zh Dev loss: 0.7839 r:0.4835
ro_en Dev loss: 0.3769 r:0.8156
Current avg r:0.6496 Best avg r: 0.6617
18:27:19,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:45,548 root INFO 
id:en_zh cur r: 0.5022 best r: 0.5022
18:27:58,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:24,59 root INFO Epoch 6 Global steps: 19600 Train loss: 0.1861
en_zh Dev loss: 0.7386 r:0.4969
ro_en Dev loss: 0.3398 r:0.8199
Current avg r:0.6584 Best avg r: 0.6617
18:29:40,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:06,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:32,18 root INFO Epoch 6 Global steps: 19800 Train loss: 0.1875
en_zh Dev loss: 0.7730 r:0.4838
ro_en Dev loss: 0.3627 r:0.8160
Current avg r:0.6499 Best avg r: 0.6617
18:31:48,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:14,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:39,986 root INFO Epoch 6 Global steps: 20000 Train loss: 0.1777
en_zh Dev loss: 0.7894 r:0.4767
ro_en Dev loss: 0.3701 r:0.8124
Current avg r:0.6445 Best avg r: 0.6617
18:33:56,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:22,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:47,895 root INFO Epoch 6 Global steps: 20200 Train loss: 0.1681
en_zh Dev loss: 0.7337 r:0.4829
ro_en Dev loss: 0.3228 r:0.8214
Current avg r:0.6521 Best avg r: 0.6617
18:36:04,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:30,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:55,910 root INFO Epoch 6 Global steps: 20400 Train loss: 0.1811
en_zh Dev loss: 0.7333 r:0.4888
ro_en Dev loss: 0.3358 r:0.8185
Current avg r:0.6537 Best avg r: 0.6617
18:38:12,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:38,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:39:03,979 root INFO Epoch 6 Global steps: 20600 Train loss: 0.1773
en_zh Dev loss: 0.7590 r:0.4867
ro_en Dev loss: 0.3524 r:0.8203
Current avg r:0.6535 Best avg r: 0.6617
18:40:20,602 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:46,302 root INFO 
id:en_zh cur r: 0.5044 best r: 0.5044
18:40:59,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:24,873 root INFO Epoch 6 Global steps: 20800 Train loss: 0.1685
en_zh Dev loss: 0.7301 r:0.4973
ro_en Dev loss: 0.3448 r:0.8224
Current avg r:0.6599 Best avg r: 0.6617
18:42:41,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:07,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:32,939 root INFO Epoch 6 Global steps: 21000 Train loss: 0.1835
en_zh Dev loss: 0.7138 r:0.4949
ro_en Dev loss: 0.3289 r:0.8208
Current avg r:0.6578 Best avg r: 0.6617
18:44:50,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:15,707 root INFO 
id:en_zh cur r: 0.5097 best r: 0.5097
18:45:28,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:54,279 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:45:54,284 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:46:20,0 root INFO Epoch 7 Global steps: 21200 Train loss: 0.1659
en_zh Dev loss: 0.6865 r:0.5069
ro_en Dev loss: 0.3205 r:0.8209
Current avg r:0.6639 Best avg r: 0.6639
18:47:36,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:02,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:28,127 root INFO Epoch 7 Global steps: 21400 Train loss: 0.1703
en_zh Dev loss: 0.7214 r:0.4939
ro_en Dev loss: 0.3526 r:0.8192
Current avg r:0.6566 Best avg r: 0.6639
18:49:44,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:10,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:36,222 root INFO Epoch 7 Global steps: 21600 Train loss: 0.1626
en_zh Dev loss: 0.7918 r:0.4932
ro_en Dev loss: 0.3802 r:0.8180
Current avg r:0.6556 Best avg r: 0.6639
18:51:52,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:18,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:44,355 root INFO Epoch 7 Global steps: 21800 Train loss: 0.1542
en_zh Dev loss: 0.7611 r:0.4886
ro_en Dev loss: 0.3467 r:0.8183
Current avg r:0.6534 Best avg r: 0.6639
18:54:01,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:26,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:52,488 root INFO Epoch 7 Global steps: 22000 Train loss: 0.1730
en_zh Dev loss: 0.7719 r:0.4787
ro_en Dev loss: 0.3512 r:0.8173
Current avg r:0.6480 Best avg r: 0.6639
18:56:09,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:34,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:00,595 root INFO Epoch 7 Global steps: 22200 Train loss: 0.1489
en_zh Dev loss: 0.8014 r:0.4686
ro_en Dev loss: 0.3699 r:0.8141
Current avg r:0.6413 Best avg r: 0.6639
18:58:17,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:42,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:08,620 root INFO Epoch 7 Global steps: 22400 Train loss: 0.1693
en_zh Dev loss: 0.7420 r:0.4815
ro_en Dev loss: 0.3382 r:0.8171
Current avg r:0.6493 Best avg r: 0.6639
19:00:25,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:50,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:16,703 root INFO Epoch 7 Global steps: 22600 Train loss: 0.1545
en_zh Dev loss: 0.7908 r:0.4781
ro_en Dev loss: 0.3614 r:0.8160
Current avg r:0.6470 Best avg r: 0.6639
19:02:33,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:59,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:24,817 root INFO Epoch 7 Global steps: 22800 Train loss: 0.1530
en_zh Dev loss: 0.7375 r:0.4923
ro_en Dev loss: 0.3561 r:0.8182
Current avg r:0.6552 Best avg r: 0.6639
19:04:41,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:07,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:32,883 root INFO Epoch 7 Global steps: 23000 Train loss: 0.1386
en_zh Dev loss: 0.7615 r:0.4919
ro_en Dev loss: 0.3627 r:0.8188
Current avg r:0.6554 Best avg r: 0.6639
19:06:49,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:15,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:40,962 root INFO Epoch 7 Global steps: 23200 Train loss: 0.1414
en_zh Dev loss: 0.7233 r:0.4809
ro_en Dev loss: 0.3331 r:0.8162
Current avg r:0.6486 Best avg r: 0.6639
19:08:57,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:23,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:49,56 root INFO Epoch 7 Global steps: 23400 Train loss: 0.1428
en_zh Dev loss: 0.7223 r:0.4890
ro_en Dev loss: 0.3299 r:0.8200
Current avg r:0.6545 Best avg r: 0.6639
19:11:05,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:31,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:57,177 root INFO Epoch 7 Global steps: 23600 Train loss: 0.1546
en_zh Dev loss: 0.7219 r:0.4906
ro_en Dev loss: 0.3368 r:0.8207
Current avg r:0.6557 Best avg r: 0.6639
19:13:13,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:39,562 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:05,251 root INFO Epoch 7 Global steps: 23800 Train loss: 0.1680
en_zh Dev loss: 0.7714 r:0.4824
ro_en Dev loss: 0.3547 r:0.8203
Current avg r:0.6514 Best avg r: 0.6639
19:15:21,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:47,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:13,282 root INFO Epoch 7 Global steps: 24000 Train loss: 0.1511
en_zh Dev loss: 0.7661 r:0.4949
ro_en Dev loss: 0.3559 r:0.8228
Current avg r:0.6589 Best avg r: 0.6639
19:17:30,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:55,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:21,571 root INFO Epoch 8 Global steps: 24200 Train loss: 0.1431
en_zh Dev loss: 0.7485 r:0.4863
ro_en Dev loss: 0.3279 r:0.8245
Current avg r:0.6554 Best avg r: 0.6639
19:19:37,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:03,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:29,386 root INFO Epoch 8 Global steps: 24400 Train loss: 0.1359
en_zh Dev loss: 0.7909 r:0.4798
ro_en Dev loss: 0.3522 r:0.8219
Current avg r:0.6508 Best avg r: 0.6639
19:21:45,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:11,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:37,172 root INFO Epoch 8 Global steps: 24600 Train loss: 0.1386
en_zh Dev loss: 0.8081 r:0.4812
ro_en Dev loss: 0.3426 r:0.8239
Current avg r:0.6526 Best avg r: 0.6639
19:23:53,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:19,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:45,49 root INFO Epoch 8 Global steps: 24800 Train loss: 0.1501
en_zh Dev loss: 0.7489 r:0.4914
ro_en Dev loss: 0.3454 r:0.8225
Current avg r:0.6570 Best avg r: 0.6639
19:26:01,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:27,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:52,919 root INFO Epoch 8 Global steps: 25000 Train loss: 0.1333
en_zh Dev loss: 0.7578 r:0.4881
ro_en Dev loss: 0.3462 r:0.8217
Current avg r:0.6549 Best avg r: 0.6639
19:28:09,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:35,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:00,748 root INFO Epoch 8 Global steps: 25200 Train loss: 0.1324
en_zh Dev loss: 0.7411 r:0.4904
ro_en Dev loss: 0.3320 r:0.8219
Current avg r:0.6561 Best avg r: 0.6639
19:30:17,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:42,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:08,576 root INFO Epoch 8 Global steps: 25400 Train loss: 0.1348
en_zh Dev loss: 0.7289 r:0.4905
ro_en Dev loss: 0.3404 r:0.8225
Current avg r:0.6565 Best avg r: 0.6639
19:32:25,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:50,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:16,449 root INFO Epoch 8 Global steps: 25600 Train loss: 0.1211
en_zh Dev loss: 0.7726 r:0.4892
ro_en Dev loss: 0.3483 r:0.8235
Current avg r:0.6563 Best avg r: 0.6639
19:34:32,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:58,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:24,333 root INFO Epoch 8 Global steps: 25800 Train loss: 0.1409
en_zh Dev loss: 0.7366 r:0.4965
ro_en Dev loss: 0.3476 r:0.8239
Current avg r:0.6602 Best avg r: 0.6639
19:36:40,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:37:06,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:32,139 root INFO Epoch 8 Global steps: 26000 Train loss: 0.1308
en_zh Dev loss: 0.7503 r:0.4861
ro_en Dev loss: 0.3416 r:0.8214
Current avg r:0.6538 Best avg r: 0.6639
19:38:48,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:14,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:39:39,985 root INFO Epoch 8 Global steps: 26200 Train loss: 0.1357
en_zh Dev loss: 0.7246 r:0.4918
ro_en Dev loss: 0.3203 r:0.8237
Current avg r:0.6578 Best avg r: 0.6639
19:40:56,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:22,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:47,864 root INFO Epoch 8 Global steps: 26400 Train loss: 0.1294
en_zh Dev loss: 0.7423 r:0.4906
ro_en Dev loss: 0.3316 r:0.8241
Current avg r:0.6574 Best avg r: 0.6639
19:43:04,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:30,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:55,699 root INFO Epoch 8 Global steps: 26600 Train loss: 0.1270
en_zh Dev loss: 0.7358 r:0.4895
ro_en Dev loss: 0.3333 r:0.8225
Current avg r:0.6560 Best avg r: 0.6639
19:45:12,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:37,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:46:03,504 root INFO Epoch 8 Global steps: 26800 Train loss: 0.1231
en_zh Dev loss: 0.7144 r:0.4974
ro_en Dev loss: 0.3392 r:0.8215
Current avg r:0.6595 Best avg r: 0.6639
19:47:19,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:45,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:11,355 root INFO Epoch 8 Global steps: 27000 Train loss: 0.1371
en_zh Dev loss: 0.7558 r:0.4919
ro_en Dev loss: 0.3417 r:0.8226
Current avg r:0.6573 Best avg r: 0.6639
19:49:28,105 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:53,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:19,493 root INFO Epoch 9 Global steps: 27200 Train loss: 0.1254
en_zh Dev loss: 0.7090 r:0.4987
ro_en Dev loss: 0.3067 r:0.8246
Current avg r:0.6616 Best avg r: 0.6639
19:51:35,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:01,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:27,244 root INFO Epoch 9 Global steps: 27400 Train loss: 0.1092
en_zh Dev loss: 0.7179 r:0.4966
ro_en Dev loss: 0.3371 r:0.8212
Current avg r:0.6589 Best avg r: 0.6639
19:53:43,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:09,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:35,60 root INFO Epoch 9 Global steps: 27600 Train loss: 0.1273
en_zh Dev loss: 0.7160 r:0.4926
ro_en Dev loss: 0.3295 r:0.8229
Current avg r:0.6578 Best avg r: 0.6639
19:55:51,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:17,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:42,918 root INFO Epoch 9 Global steps: 27800 Train loss: 0.1124
en_zh Dev loss: 0.7673 r:0.4937
ro_en Dev loss: 0.3724 r:0.8191
Current avg r:0.6564 Best avg r: 0.6639
19:57:59,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:25,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:50,804 root INFO Epoch 9 Global steps: 28000 Train loss: 0.1163
en_zh Dev loss: 0.7541 r:0.4929
ro_en Dev loss: 0.3508 r:0.8197
Current avg r:0.6563 Best avg r: 0.6639
20:00:07,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:33,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:58,789 root INFO Epoch 9 Global steps: 28200 Train loss: 0.1247
en_zh Dev loss: 0.7905 r:0.4899
ro_en Dev loss: 0.3659 r:0.8220
Current avg r:0.6560 Best avg r: 0.6639
20:02:15,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:41,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:06,754 root INFO Epoch 9 Global steps: 28400 Train loss: 0.1187
en_zh Dev loss: 0.7119 r:0.4999
ro_en Dev loss: 0.3340 r:0.8225
Current avg r:0.6612 Best avg r: 0.6639
20:04:23,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:48,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:14,625 root INFO Epoch 9 Global steps: 28600 Train loss: 0.1193
en_zh Dev loss: 0.7075 r:0.4978
ro_en Dev loss: 0.3154 r:0.8257
Current avg r:0.6617 Best avg r: 0.6639
20:06:31,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:56,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:22,537 root INFO Epoch 9 Global steps: 28800 Train loss: 0.1205
en_zh Dev loss: 0.7785 r:0.4871
ro_en Dev loss: 0.3443 r:0.8251
Current avg r:0.6561 Best avg r: 0.6639
20:08:39,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:04,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:30,542 root INFO Epoch 9 Global steps: 29000 Train loss: 0.1244
en_zh Dev loss: 0.7438 r:0.4934
ro_en Dev loss: 0.3349 r:0.8219
Current avg r:0.6576 Best avg r: 0.6639
20:10:47,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:12,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:38,425 root INFO Epoch 9 Global steps: 29200 Train loss: 0.1269
en_zh Dev loss: 0.7891 r:0.5010
ro_en Dev loss: 0.3946 r:0.8221
Current avg r:0.6615 Best avg r: 0.6639
20:12:54,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:20,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:46,288 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:13:46,296 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:14:11,999 root INFO Epoch 9 Global steps: 29400 Train loss: 0.1156
en_zh Dev loss: 0.7148 r:0.5080
ro_en Dev loss: 0.3214 r:0.8266
Current avg r:0.6673 Best avg r: 0.6673
20:15:28,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:54,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:19,994 root INFO Epoch 9 Global steps: 29600 Train loss: 0.1307
en_zh Dev loss: 0.7143 r:0.5019
ro_en Dev loss: 0.3302 r:0.8272
Current avg r:0.6646 Best avg r: 0.6673
20:17:36,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:02,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:27,767 root INFO Epoch 9 Global steps: 29800 Train loss: 0.1182
en_zh Dev loss: 0.7342 r:0.5058
ro_en Dev loss: 0.3376 r:0.8284
Current avg r:0.6671 Best avg r: 0.6673
20:19:44,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:09,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:35,613 root INFO Epoch 9 Global steps: 30000 Train loss: 0.1126
en_zh Dev loss: 0.7031 r:0.5050
ro_en Dev loss: 0.3143 r:0.8276
Current avg r:0.6663 Best avg r: 0.6673
20:21:52,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:22:18,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:43,794 root INFO Epoch 10 Global steps: 30200 Train loss: 0.1211
en_zh Dev loss: 0.7246 r:0.4954
ro_en Dev loss: 0.3186 r:0.8263
Current avg r:0.6608 Best avg r: 0.6673
20:24:00,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:25,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:51,608 root INFO Epoch 10 Global steps: 30400 Train loss: 0.1065
en_zh Dev loss: 0.7032 r:0.5022
ro_en Dev loss: 0.3237 r:0.8246
Current avg r:0.6634 Best avg r: 0.6673
20:26:08,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:26:33,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:59,428 root INFO Epoch 10 Global steps: 30600 Train loss: 0.1033
en_zh Dev loss: 0.7517 r:0.4929
ro_en Dev loss: 0.3441 r:0.8225
Current avg r:0.6577 Best avg r: 0.6673
20:28:15,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:41,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:07,301 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1031
en_zh Dev loss: 0.7612 r:0.4888
ro_en Dev loss: 0.3485 r:0.8211
Current avg r:0.6549 Best avg r: 0.6673
20:30:23,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:49,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:15,267 root INFO Epoch 10 Global steps: 31000 Train loss: 0.1101
en_zh Dev loss: 0.7651 r:0.4936
ro_en Dev loss: 0.3652 r:0.8193
Current avg r:0.6564 Best avg r: 0.6673
20:32:31,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:57,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:23,308 root INFO Epoch 10 Global steps: 31200 Train loss: 0.1091
en_zh Dev loss: 0.7389 r:0.4971
ro_en Dev loss: 0.3389 r:0.8218
Current avg r:0.6594 Best avg r: 0.6673
20:34:39,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:05,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:31,328 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1067
en_zh Dev loss: 0.7677 r:0.5021
ro_en Dev loss: 0.3622 r:0.8213
Current avg r:0.6617 Best avg r: 0.6673
20:36:48,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:13,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:39,454 root INFO Epoch 10 Global steps: 31600 Train loss: 0.1064
en_zh Dev loss: 0.7101 r:0.5009
ro_en Dev loss: 0.3230 r:0.8227
Current avg r:0.6618 Best avg r: 0.6673
20:38:56,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:21,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:47,483 root INFO Epoch 10 Global steps: 31800 Train loss: 0.1046
en_zh Dev loss: 0.7399 r:0.5038
ro_en Dev loss: 0.3504 r:0.8226
Current avg r:0.6632 Best avg r: 0.6673
20:41:04,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:29,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:55,422 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1072
en_zh Dev loss: 0.7151 r:0.5043
ro_en Dev loss: 0.3173 r:0.8252
Current avg r:0.6648 Best avg r: 0.6673
20:43:11,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:37,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:03,305 root INFO Epoch 10 Global steps: 32200 Train loss: 0.0993
en_zh Dev loss: 0.7556 r:0.4983
ro_en Dev loss: 0.3609 r:0.8218
Current avg r:0.6601 Best avg r: 0.6673
20:45:19,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:45,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:11,62 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1150
en_zh Dev loss: 0.7322 r:0.5009
ro_en Dev loss: 0.3211 r:0.8262
Current avg r:0.6635 Best avg r: 0.6673
20:47:27,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:53,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:18,737 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1138
en_zh Dev loss: 0.7300 r:0.4956
ro_en Dev loss: 0.3318 r:0.8210
Current avg r:0.6583 Best avg r: 0.6673
20:49:35,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:00,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:26,536 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1090
en_zh Dev loss: 0.8045 r:0.4846
ro_en Dev loss: 0.3579 r:0.8197
Current avg r:0.6521 Best avg r: 0.6673
20:51:43,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:08,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:34,442 root INFO Epoch 10 Global steps: 33000 Train loss: 0.0982
en_zh Dev loss: 0.7867 r:0.4876
ro_en Dev loss: 0.3737 r:0.8184
Current avg r:0.6530 Best avg r: 0.6673
20:53:51,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:17,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:42,773 root INFO Epoch 11 Global steps: 33200 Train loss: 0.0937
en_zh Dev loss: 0.7335 r:0.4947
ro_en Dev loss: 0.3539 r:0.8209
Current avg r:0.6578 Best avg r: 0.6673
20:55:59,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:25,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:50,764 root INFO Epoch 11 Global steps: 33400 Train loss: 0.0944
en_zh Dev loss: 0.7356 r:0.4940
ro_en Dev loss: 0.3389 r:0.8205
Current avg r:0.6573 Best avg r: 0.6673
20:58:07,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:33,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:58,782 root INFO Epoch 11 Global steps: 33600 Train loss: 0.0828
en_zh Dev loss: 0.8062 r:0.4969
ro_en Dev loss: 0.3650 r:0.8214
Current avg r:0.6591 Best avg r: 0.6673
21:00:15,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:41,82 root INFO 
id:en_zh cur r: 0.5104 best r: 0.5104
21:00:53,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:19,646 root INFO Epoch 11 Global steps: 33800 Train loss: 0.0963
en_zh Dev loss: 0.7328 r:0.5056
ro_en Dev loss: 0.3311 r:0.8240
Current avg r:0.6648 Best avg r: 0.6673
21:02:36,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:01,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:27,621 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1024
en_zh Dev loss: 0.7267 r:0.4925
ro_en Dev loss: 0.3311 r:0.8210
Current avg r:0.6568 Best avg r: 0.6673
21:04:44,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:09,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:35,469 root INFO Epoch 11 Global steps: 34200 Train loss: 0.0886
en_zh Dev loss: 0.8049 r:0.4859
ro_en Dev loss: 0.3582 r:0.8241
Current avg r:0.6550 Best avg r: 0.6673
21:06:51,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:17,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:43,315 root INFO Epoch 11 Global steps: 34400 Train loss: 0.0953
en_zh Dev loss: 0.8138 r:0.4873
ro_en Dev loss: 0.3630 r:0.8228
Current avg r:0.6550 Best avg r: 0.6673
21:08:59,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:25,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:51,186 root INFO Epoch 11 Global steps: 34600 Train loss: 0.0986
en_zh Dev loss: 0.7622 r:0.4965
ro_en Dev loss: 0.3601 r:0.8201
Current avg r:0.6583 Best avg r: 0.6673
21:11:07,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:33,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:59,450 root INFO Epoch 11 Global steps: 34800 Train loss: 0.0970
en_zh Dev loss: 0.7264 r:0.4960
ro_en Dev loss: 0.3546 r:0.8216
Current avg r:0.6588 Best avg r: 0.6673
21:13:16,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:41,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:07,615 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1022
en_zh Dev loss: 0.7207 r:0.4991
ro_en Dev loss: 0.3496 r:0.8194
Current avg r:0.6593 Best avg r: 0.6673
21:15:24,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:50,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:15,719 root INFO Epoch 11 Global steps: 35200 Train loss: 0.0974
en_zh Dev loss: 0.7673 r:0.4991
ro_en Dev loss: 0.3578 r:0.8218
Current avg r:0.6604 Best avg r: 0.6673
21:17:32,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:58,265 root INFO 
id:en_zh cur r: 0.5105 best r: 0.5105
21:18:11,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:36,876 root INFO Epoch 11 Global steps: 35400 Train loss: 0.0973
en_zh Dev loss: 0.7032 r:0.5063
ro_en Dev loss: 0.3191 r:0.8239
Current avg r:0.6651 Best avg r: 0.6673
21:19:53,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:19,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:44,986 root INFO Epoch 11 Global steps: 35600 Train loss: 0.0967
en_zh Dev loss: 0.7256 r:0.5061
ro_en Dev loss: 0.3510 r:0.8218
Current avg r:0.6639 Best avg r: 0.6673
21:22:01,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:27,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:52,977 root INFO Epoch 11 Global steps: 35800 Train loss: 0.0950
en_zh Dev loss: 0.7346 r:0.4990
ro_en Dev loss: 0.3215 r:0.8268
Current avg r:0.6629 Best avg r: 0.6673
21:24:09,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:35,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:00,988 root INFO Epoch 11 Global steps: 36000 Train loss: 0.0939
en_zh Dev loss: 0.7934 r:0.4952
ro_en Dev loss: 0.3647 r:0.8213
Current avg r:0.6583 Best avg r: 0.6673
21:26:18,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:26:43,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:09,419 root INFO Epoch 12 Global steps: 36200 Train loss: 0.0865
en_zh Dev loss: 0.7380 r:0.5029
ro_en Dev loss: 0.3551 r:0.8227
Current avg r:0.6628 Best avg r: 0.6673
21:28:26,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:51,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:17,458 root INFO Epoch 12 Global steps: 36400 Train loss: 0.0848
en_zh Dev loss: 0.7509 r:0.4929
ro_en Dev loss: 0.3363 r:0.8233
Current avg r:0.6581 Best avg r: 0.6673
21:30:34,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:59,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:25,435 root INFO Epoch 12 Global steps: 36600 Train loss: 0.0887
en_zh Dev loss: 0.7466 r:0.4978
ro_en Dev loss: 0.3388 r:0.8247
Current avg r:0.6612 Best avg r: 0.6673
21:32:42,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:33:07,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:33,498 root INFO Epoch 12 Global steps: 36800 Train loss: 0.0889
en_zh Dev loss: 0.8045 r:0.4921
ro_en Dev loss: 0.3587 r:0.8230
Current avg r:0.6576 Best avg r: 0.6673
21:34:50,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:16,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:41,752 root INFO Epoch 12 Global steps: 37000 Train loss: 0.0799
en_zh Dev loss: 0.7683 r:0.4974
ro_en Dev loss: 0.3463 r:0.8225
Current avg r:0.6600 Best avg r: 0.6673
21:36:58,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:24,107 root INFO 
id:en_zh cur r: 0.5137 best r: 0.5137
21:37:36,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:02,651 root INFO Epoch 12 Global steps: 37200 Train loss: 0.0872
en_zh Dev loss: 0.7247 r:0.5106
ro_en Dev loss: 0.3516 r:0.8200
Current avg r:0.6653 Best avg r: 0.6673
21:39:19,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:44,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:10,603 root INFO Epoch 12 Global steps: 37400 Train loss: 0.0840
en_zh Dev loss: 0.7392 r:0.5080
ro_en Dev loss: 0.3483 r:0.8219
Current avg r:0.6650 Best avg r: 0.6673
21:41:27,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:52,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:18,643 root INFO Epoch 12 Global steps: 37600 Train loss: 0.0918
en_zh Dev loss: 0.7728 r:0.4954
ro_en Dev loss: 0.3595 r:0.8237
Current avg r:0.6595 Best avg r: 0.6673
21:43:35,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:00,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:26,659 root INFO Epoch 12 Global steps: 37800 Train loss: 0.0833
en_zh Dev loss: 0.7052 r:0.5036
ro_en Dev loss: 0.3202 r:0.8248
Current avg r:0.6642 Best avg r: 0.6673
21:45:43,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:46:08,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:34,674 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
21:46:34,682 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
21:47:00,398 root INFO Epoch 12 Global steps: 38000 Train loss: 0.0831
en_zh Dev loss: 0.7121 r:0.5115
ro_en Dev loss: 0.3430 r:0.8251
Current avg r:0.6683 Best avg r: 0.6683
21:48:17,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:42,917 root INFO 
id:en_zh cur r: 0.5176 best r: 0.5176
21:48:55,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:21,523 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
21:49:21,531 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
21:49:47,276 root INFO Epoch 12 Global steps: 38200 Train loss: 0.0814
en_zh Dev loss: 0.7130 r:0.5150
ro_en Dev loss: 0.3479 r:0.8246
Current avg r:0.6698 Best avg r: 0.6698
21:51:03,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:29,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:55,287 root INFO Epoch 12 Global steps: 38400 Train loss: 0.0827
en_zh Dev loss: 0.7022 r:0.5077
ro_en Dev loss: 0.3305 r:0.8237
Current avg r:0.6657 Best avg r: 0.6698
21:53:11,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:37,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:03,330 root INFO Epoch 12 Global steps: 38600 Train loss: 0.0808
en_zh Dev loss: 0.7023 r:0.5126
ro_en Dev loss: 0.3396 r:0.8260
Current avg r:0.6693 Best avg r: 0.6698
21:55:19,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:45,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:11,441 root INFO Epoch 12 Global steps: 38800 Train loss: 0.0949
en_zh Dev loss: 0.7233 r:0.5054
ro_en Dev loss: 0.3316 r:0.8270
Current avg r:0.6662 Best avg r: 0.6698
21:57:28,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:53,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:19,492 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
21:58:19,499 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
21:58:45,249 root INFO Epoch 12 Global steps: 39000 Train loss: 0.0840
en_zh Dev loss: 0.7081 r:0.5117
ro_en Dev loss: 0.3166 r:0.8285
Current avg r:0.6701 Best avg r: 0.6701
22:00:02,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:27,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:53,573 root INFO Epoch 13 Global steps: 39200 Train loss: 0.0769
en_zh Dev loss: 0.7373 r:0.5048
ro_en Dev loss: 0.3556 r:0.8223
Current avg r:0.6635 Best avg r: 0.6701
22:02:10,183 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:35,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:01,600 root INFO Epoch 13 Global steps: 39400 Train loss: 0.0808
en_zh Dev loss: 0.7698 r:0.5113
ro_en Dev loss: 0.3384 r:0.8270
Current avg r:0.6691 Best avg r: 0.6701
22:04:18,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:43,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:09,658 root INFO Epoch 13 Global steps: 39600 Train loss: 0.0725
en_zh Dev loss: 0.7652 r:0.5050
ro_en Dev loss: 0.3506 r:0.8233
Current avg r:0.6642 Best avg r: 0.6701
22:06:26,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:51,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:17,654 root INFO Epoch 13 Global steps: 39800 Train loss: 0.0810
en_zh Dev loss: 0.7456 r:0.5070
ro_en Dev loss: 0.3385 r:0.8239
Current avg r:0.6654 Best avg r: 0.6701
22:08:34,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:59,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:25,631 root INFO Epoch 13 Global steps: 40000 Train loss: 0.0755
en_zh Dev loss: 0.7238 r:0.5027
ro_en Dev loss: 0.3429 r:0.8231
Current avg r:0.6629 Best avg r: 0.6701
22:10:42,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:07,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:33,634 root INFO Epoch 13 Global steps: 40200 Train loss: 0.0751
en_zh Dev loss: 0.7530 r:0.5062
ro_en Dev loss: 0.3837 r:0.8216
Current avg r:0.6639 Best avg r: 0.6701
22:12:50,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:15,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:41,649 root INFO Epoch 13 Global steps: 40400 Train loss: 0.0765
en_zh Dev loss: 0.7620 r:0.4986
ro_en Dev loss: 0.3527 r:0.8202
Current avg r:0.6594 Best avg r: 0.6701
22:14:58,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:23,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:49,690 root INFO Epoch 13 Global steps: 40600 Train loss: 0.0716
en_zh Dev loss: 0.7452 r:0.5011
ro_en Dev loss: 0.3449 r:0.8191
Current avg r:0.6601 Best avg r: 0.6701
22:17:06,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:32,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:57,739 root INFO Epoch 13 Global steps: 40800 Train loss: 0.0763
en_zh Dev loss: 0.7506 r:0.5083
ro_en Dev loss: 0.3561 r:0.8223
Current avg r:0.6653 Best avg r: 0.6701
22:19:14,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:40,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:05,742 root INFO Epoch 13 Global steps: 41000 Train loss: 0.0849
en_zh Dev loss: 0.6906 r:0.5070
ro_en Dev loss: 0.3205 r:0.8245
Current avg r:0.6658 Best avg r: 0.6701
22:21:22,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:48,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:13,724 root INFO Epoch 13 Global steps: 41200 Train loss: 0.0809
en_zh Dev loss: 0.7000 r:0.5099
ro_en Dev loss: 0.3233 r:0.8256
Current avg r:0.6678 Best avg r: 0.6701
22:23:30,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:56,67 root INFO 
id:en_zh cur r: 0.5179 best r: 0.5179
22:24:08,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:34,647 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
22:24:34,652 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
22:25:00,369 root INFO Epoch 13 Global steps: 41400 Train loss: 0.0756
en_zh Dev loss: 0.7232 r:0.5148
ro_en Dev loss: 0.3221 r:0.8261
Current avg r:0.6704 Best avg r: 0.6704
22:26:17,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:26:42,798 root INFO 
id:en_zh cur r: 0.5229 best r: 0.5229
22:26:55,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:21,426 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
22:27:21,431 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
22:27:47,169 root INFO Epoch 13 Global steps: 41600 Train loss: 0.0709
en_zh Dev loss: 0.7054 r:0.5185
ro_en Dev loss: 0.3436 r:0.8258
Current avg r:0.6721 Best avg r: 0.6721
22:29:03,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:29,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:55,428 root INFO Epoch 13 Global steps: 41800 Train loss: 0.0737
en_zh Dev loss: 0.7316 r:0.5155
ro_en Dev loss: 0.3353 r:0.8261
Current avg r:0.6708 Best avg r: 0.6721
22:31:12,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:37,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:03,471 root INFO Epoch 13 Global steps: 42000 Train loss: 0.0747
en_zh Dev loss: 0.6911 r:0.5103
ro_en Dev loss: 0.3328 r:0.8249
Current avg r:0.6676 Best avg r: 0.6721
22:33:20,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:46,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:11,889 root INFO Epoch 14 Global steps: 42200 Train loss: 0.0797
en_zh Dev loss: 0.7173 r:0.5112
ro_en Dev loss: 0.3490 r:0.8202
Current avg r:0.6657 Best avg r: 0.6721
22:35:28,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:54,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:19,927 root INFO Epoch 14 Global steps: 42400 Train loss: 0.0664
en_zh Dev loss: 0.7218 r:0.5098
ro_en Dev loss: 0.3337 r:0.8222
Current avg r:0.6660 Best avg r: 0.6721
22:37:36,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:02,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:27,971 root INFO Epoch 14 Global steps: 42600 Train loss: 0.0745
en_zh Dev loss: 0.7575 r:0.5097
ro_en Dev loss: 0.3708 r:0.8209
Current avg r:0.6653 Best avg r: 0.6721
22:39:44,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:10,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:36,70 root INFO Epoch 14 Global steps: 42800 Train loss: 0.0712
en_zh Dev loss: 0.7524 r:0.5029
ro_en Dev loss: 0.3645 r:0.8212
Current avg r:0.6620 Best avg r: 0.6721
22:41:52,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:18,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:44,183 root INFO Epoch 14 Global steps: 43000 Train loss: 0.0720
en_zh Dev loss: 0.7847 r:0.5053
ro_en Dev loss: 0.3724 r:0.8208
Current avg r:0.6630 Best avg r: 0.6721
22:44:00,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:26,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:52,240 root INFO Epoch 14 Global steps: 43200 Train loss: 0.0702
en_zh Dev loss: 0.7289 r:0.5127
ro_en Dev loss: 0.3454 r:0.8257
Current avg r:0.6692 Best avg r: 0.6721
22:46:08,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:34,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:00,281 root INFO Epoch 14 Global steps: 43400 Train loss: 0.0721
en_zh Dev loss: 0.7106 r:0.5112
ro_en Dev loss: 0.3246 r:0.8238
Current avg r:0.6675 Best avg r: 0.6721
22:48:16,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:42,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:08,364 root INFO Epoch 14 Global steps: 43600 Train loss: 0.0712
en_zh Dev loss: 0.7679 r:0.5041
ro_en Dev loss: 0.3418 r:0.8252
Current avg r:0.6646 Best avg r: 0.6721
22:50:24,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:50,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:16,389 root INFO Epoch 14 Global steps: 43800 Train loss: 0.0715
en_zh Dev loss: 0.6936 r:0.5163
ro_en Dev loss: 0.3234 r:0.8265
Current avg r:0.6714 Best avg r: 0.6721
22:52:33,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:59,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:24,706 root INFO Epoch 14 Global steps: 44000 Train loss: 0.0691
en_zh Dev loss: 0.7139 r:0.5126
ro_en Dev loss: 0.3271 r:0.8281
Current avg r:0.6703 Best avg r: 0.6721
22:54:41,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:07,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:32,912 root INFO Epoch 14 Global steps: 44200 Train loss: 0.0684
en_zh Dev loss: 0.7131 r:0.5139
ro_en Dev loss: 0.3325 r:0.8256
Current avg r:0.6697 Best avg r: 0.6721
22:56:49,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:15,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:41,22 root INFO Epoch 14 Global steps: 44400 Train loss: 0.0694
en_zh Dev loss: 0.7171 r:0.5062
ro_en Dev loss: 0.3272 r:0.8245
Current avg r:0.6653 Best avg r: 0.6721
22:58:57,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:23,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:49,71 root INFO Epoch 14 Global steps: 44600 Train loss: 0.0795
en_zh Dev loss: 0.7152 r:0.5146
ro_en Dev loss: 0.3446 r:0.8236
Current avg r:0.6691 Best avg r: 0.6721
23:01:05,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:31,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:57,125 root INFO Epoch 14 Global steps: 44800 Train loss: 0.0649
en_zh Dev loss: 0.7432 r:0.5074
ro_en Dev loss: 0.3337 r:0.8238
Current avg r:0.6656 Best avg r: 0.6721
23:03:13,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:39,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:05,197 root INFO Epoch 14 Global steps: 45000 Train loss: 0.0690
en_zh Dev loss: 0.7497 r:0.5036
ro_en Dev loss: 0.3453 r:0.8212
Current avg r:0.6624 Best avg r: 0.6721
23:05:22,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:47,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:13,577 root INFO Epoch 15 Global steps: 45200 Train loss: 0.0712
en_zh Dev loss: 0.7030 r:0.5085
ro_en Dev loss: 0.3079 r:0.8257
Current avg r:0.6671 Best avg r: 0.6721
23:07:30,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:55,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:21,649 root INFO Epoch 15 Global steps: 45400 Train loss: 0.0682
en_zh Dev loss: 0.7287 r:0.5045
ro_en Dev loss: 0.3373 r:0.8252
Current avg r:0.6649 Best avg r: 0.6721
23:09:38,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:04,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:29,707 root INFO Epoch 15 Global steps: 45600 Train loss: 0.0645
en_zh Dev loss: 0.7447 r:0.5146
ro_en Dev loss: 0.3578 r:0.8218
Current avg r:0.6682 Best avg r: 0.6721
23:11:46,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:12:11,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:37,675 root INFO Epoch 15 Global steps: 45800 Train loss: 0.0685
en_zh Dev loss: 0.7761 r:0.5129
ro_en Dev loss: 0.3493 r:0.8244
Current avg r:0.6687 Best avg r: 0.6721
23:13:54,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:20,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:45,713 root INFO Epoch 15 Global steps: 46000 Train loss: 0.0693
en_zh Dev loss: 0.6999 r:0.5155
ro_en Dev loss: 0.3246 r:0.8236
Current avg r:0.6695 Best avg r: 0.6721
23:16:02,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:28,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:53,748 root INFO Epoch 15 Global steps: 46200 Train loss: 0.0635
en_zh Dev loss: 0.7026 r:0.5157
ro_en Dev loss: 0.3340 r:0.8221
Current avg r:0.6689 Best avg r: 0.6721
23:18:10,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:36,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:01,730 root INFO Epoch 15 Global steps: 46400 Train loss: 0.0676
en_zh Dev loss: 0.7276 r:0.5106
ro_en Dev loss: 0.3493 r:0.8194
Current avg r:0.6650 Best avg r: 0.6721
23:20:18,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:44,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:21:09,725 root INFO Epoch 15 Global steps: 46600 Train loss: 0.0678
en_zh Dev loss: 0.7265 r:0.5114
ro_en Dev loss: 0.3446 r:0.8220
Current avg r:0.6667 Best avg r: 0.6721
23:22:26,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:52,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:17,744 root INFO Epoch 15 Global steps: 46800 Train loss: 0.0668
en_zh Dev loss: 0.7568 r:0.5091
ro_en Dev loss: 0.3551 r:0.8221
Current avg r:0.6656 Best avg r: 0.6721
23:24:34,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:00,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:25,702 root INFO Epoch 15 Global steps: 47000 Train loss: 0.0723
en_zh Dev loss: 0.7024 r:0.5152
ro_en Dev loss: 0.3260 r:0.8225
Current avg r:0.6689 Best avg r: 0.6721
23:26:42,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:27:07,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:33,673 root INFO Epoch 15 Global steps: 47200 Train loss: 0.0625
en_zh Dev loss: 0.7636 r:0.5051
ro_en Dev loss: 0.3628 r:0.8174
Current avg r:0.6612 Best avg r: 0.6721
23:28:50,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:15,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:41,626 root INFO Epoch 15 Global steps: 47400 Train loss: 0.0677
en_zh Dev loss: 0.6950 r:0.5121
ro_en Dev loss: 0.3285 r:0.8209
Current avg r:0.6665 Best avg r: 0.6721
23:30:58,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:23,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:49,641 root INFO Epoch 15 Global steps: 47600 Train loss: 0.0625
en_zh Dev loss: 0.7562 r:0.5050
ro_en Dev loss: 0.3494 r:0.8201
Current avg r:0.6625 Best avg r: 0.6721
23:33:06,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:31,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:57,661 root INFO Epoch 15 Global steps: 47800 Train loss: 0.0631
en_zh Dev loss: 0.7234 r:0.5110
ro_en Dev loss: 0.3332 r:0.8227
Current avg r:0.6668 Best avg r: 0.6721
23:35:14,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:39,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:05,648 root INFO Epoch 15 Global steps: 48000 Train loss: 0.0686
en_zh Dev loss: 0.7968 r:0.5006
ro_en Dev loss: 0.3673 r:0.8216
Current avg r:0.6611 Best avg r: 0.6721
23:37:22,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:48,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:13,932 root INFO Epoch 16 Global steps: 48200 Train loss: 0.0619
en_zh Dev loss: 0.7594 r:0.5025
ro_en Dev loss: 0.3663 r:0.8204
Current avg r:0.6615 Best avg r: 0.6721
23:39:30,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:56,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:21,927 root INFO Epoch 16 Global steps: 48400 Train loss: 0.0597
en_zh Dev loss: 0.7270 r:0.5101
ro_en Dev loss: 0.3138 r:0.8268
Current avg r:0.6684 Best avg r: 0.6721
23:41:38,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:04,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:29,798 root INFO Epoch 16 Global steps: 48600 Train loss: 0.0606
en_zh Dev loss: 0.7250 r:0.5050
ro_en Dev loss: 0.3414 r:0.8253
Current avg r:0.6652 Best avg r: 0.6721
23:43:46,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:12,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:37,747 root INFO Epoch 16 Global steps: 48800 Train loss: 0.0597
en_zh Dev loss: 0.7267 r:0.5129
ro_en Dev loss: 0.3341 r:0.8262
Current avg r:0.6696 Best avg r: 0.6721
23:45:54,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:20,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:45,765 root INFO Epoch 16 Global steps: 49000 Train loss: 0.0608
en_zh Dev loss: 0.7585 r:0.5119
ro_en Dev loss: 0.3651 r:0.8245
Current avg r:0.6682 Best avg r: 0.6721
23:48:02,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:28,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:53,811 root INFO Epoch 16 Global steps: 49200 Train loss: 0.0646
en_zh Dev loss: 0.6992 r:0.5143
ro_en Dev loss: 0.3377 r:0.8211
Current avg r:0.6677 Best avg r: 0.6721
23:50:10,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:36,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:51:01,746 root INFO Epoch 16 Global steps: 49400 Train loss: 0.0584
en_zh Dev loss: 0.7400 r:0.5017
ro_en Dev loss: 0.3535 r:0.8214
Current avg r:0.6615 Best avg r: 0.6721
23:52:18,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:44,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:09,723 root INFO Epoch 16 Global steps: 49600 Train loss: 0.0584
en_zh Dev loss: 0.7441 r:0.4938
ro_en Dev loss: 0.3317 r:0.8219
Current avg r:0.6578 Best avg r: 0.6721
23:54:26,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:52,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:17,757 root INFO Epoch 16 Global steps: 49800 Train loss: 0.0596
en_zh Dev loss: 0.7451 r:0.4970
ro_en Dev loss: 0.3416 r:0.8238
Current avg r:0.6604 Best avg r: 0.6721
23:56:34,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:00,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:25,776 root INFO Epoch 16 Global steps: 50000 Train loss: 0.0552
en_zh Dev loss: 0.7217 r:0.5078
ro_en Dev loss: 0.3237 r:0.8249
Current avg r:0.6664 Best avg r: 0.6721
23:58:42,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:08,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:33,740 root INFO Epoch 16 Global steps: 50200 Train loss: 0.0673
en_zh Dev loss: 0.7513 r:0.5039
ro_en Dev loss: 0.3332 r:0.8233
Current avg r:0.6636 Best avg r: 0.6721
00:00:50,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:16,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:41,793 root INFO Epoch 16 Global steps: 50400 Train loss: 0.0591
en_zh Dev loss: 0.7215 r:0.5022
ro_en Dev loss: 0.3385 r:0.8202
Current avg r:0.6612 Best avg r: 0.6721
00:02:58,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:24,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:49,768 root INFO Epoch 16 Global steps: 50600 Train loss: 0.0577
en_zh Dev loss: 0.7524 r:0.5092
ro_en Dev loss: 0.3478 r:0.8205
Current avg r:0.6648 Best avg r: 0.6721
00:05:06,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:32,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:57,726 root INFO Epoch 16 Global steps: 50800 Train loss: 0.0646
en_zh Dev loss: 0.7803 r:0.5036
ro_en Dev loss: 0.3748 r:0.8191
Current avg r:0.6613 Best avg r: 0.6721
00:07:14,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:40,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:05,729 root INFO Epoch 16 Global steps: 51000 Train loss: 0.0568
en_zh Dev loss: 0.7629 r:0.5070
ro_en Dev loss: 0.3625 r:0.8201
Current avg r:0.6636 Best avg r: 0.6721
00:09:22,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:48,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:14,90 root INFO Epoch 17 Global steps: 51200 Train loss: 0.0605
en_zh Dev loss: 0.7370 r:0.5104
ro_en Dev loss: 0.3422 r:0.8195
Current avg r:0.6650 Best avg r: 0.6721
00:11:30,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:56,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:22,286 root INFO Epoch 17 Global steps: 51400 Train loss: 0.0548
en_zh Dev loss: 0.7221 r:0.5104
ro_en Dev loss: 0.3545 r:0.8197
Current avg r:0.6651 Best avg r: 0.6721
00:13:38,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:04,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:30,342 root INFO Epoch 17 Global steps: 51600 Train loss: 0.0600
en_zh Dev loss: 0.7275 r:0.5070
ro_en Dev loss: 0.3370 r:0.8242
Current avg r:0.6656 Best avg r: 0.6721
00:15:47,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:16:12,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:16:38,465 root INFO Epoch 17 Global steps: 51800 Train loss: 0.0581
en_zh Dev loss: 0.7309 r:0.5149
ro_en Dev loss: 0.3298 r:0.8242
Current avg r:0.6695 Best avg r: 0.6721
00:17:55,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:20,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:18:46,397 root INFO Epoch 17 Global steps: 52000 Train loss: 0.0558
en_zh Dev loss: 0.7037 r:0.5141
ro_en Dev loss: 0.3306 r:0.8251
Current avg r:0.6696 Best avg r: 0.6721
00:20:02,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:28,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:54,386 root INFO Epoch 17 Global steps: 52200 Train loss: 0.0536
en_zh Dev loss: 0.7708 r:0.4960
ro_en Dev loss: 0.3644 r:0.8207
Current avg r:0.6584 Best avg r: 0.6721
00:22:10,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:36,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:02,369 root INFO Epoch 17 Global steps: 52400 Train loss: 0.0617
en_zh Dev loss: 0.7740 r:0.4993
ro_en Dev loss: 0.3679 r:0.8223
Current avg r:0.6608 Best avg r: 0.6721
00:24:18,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:44,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:10,392 root INFO Epoch 17 Global steps: 52600 Train loss: 0.0577
en_zh Dev loss: 0.7187 r:0.5091
ro_en Dev loss: 0.3112 r:0.8253
Current avg r:0.6672 Best avg r: 0.6721
00:26:27,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:52,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:18,480 root INFO Epoch 17 Global steps: 52800 Train loss: 0.0536
en_zh Dev loss: 0.7546 r:0.5117
ro_en Dev loss: 0.3730 r:0.8215
Current avg r:0.6666 Best avg r: 0.6721
00:28:35,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:00,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:26,437 root INFO Epoch 17 Global steps: 53000 Train loss: 0.0569
en_zh Dev loss: 0.7514 r:0.5138
ro_en Dev loss: 0.3509 r:0.8232
Current avg r:0.6685 Best avg r: 0.6721
00:30:42,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:08,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:34,390 root INFO Epoch 17 Global steps: 53200 Train loss: 0.0623
en_zh Dev loss: 0.6863 r:0.5142
ro_en Dev loss: 0.3254 r:0.8232
Current avg r:0.6687 Best avg r: 0.6721
00:32:50,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:33:16,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:33:42,305 root INFO Epoch 17 Global steps: 53400 Train loss: 0.0574
en_zh Dev loss: 0.7256 r:0.5109
ro_en Dev loss: 0.3327 r:0.8268
Current avg r:0.6688 Best avg r: 0.6721
00:34:58,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:24,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:50,303 root INFO Epoch 17 Global steps: 53600 Train loss: 0.0541
en_zh Dev loss: 0.7334 r:0.5073
ro_en Dev loss: 0.3240 r:0.8271
Current avg r:0.6672 Best avg r: 0.6721
00:37:06,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:32,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:58,211 root INFO Epoch 17 Global steps: 53800 Train loss: 0.0537
en_zh Dev loss: 0.7272 r:0.5092
ro_en Dev loss: 0.3470 r:0.8257
Current avg r:0.6675 Best avg r: 0.6721
00:39:14,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:39:40,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:06,100 root INFO Epoch 17 Global steps: 54000 Train loss: 0.0528
en_zh Dev loss: 0.7770 r:0.4993
ro_en Dev loss: 0.3754 r:0.8213
Current avg r:0.6603 Best avg r: 0.6721
00:41:22,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:48,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:14,382 root INFO Epoch 18 Global steps: 54200 Train loss: 0.0558
en_zh Dev loss: 0.7001 r:0.5098
ro_en Dev loss: 0.3209 r:0.8261
Current avg r:0.6679 Best avg r: 0.6721
00:43:30,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:56,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:22,197 root INFO Epoch 18 Global steps: 54400 Train loss: 0.0562
en_zh Dev loss: 0.7127 r:0.5103
ro_en Dev loss: 0.3368 r:0.8240
Current avg r:0.6671 Best avg r: 0.6721
00:45:38,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:04,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:30,165 root INFO Epoch 18 Global steps: 54600 Train loss: 0.0542
en_zh Dev loss: 0.7060 r:0.5163
ro_en Dev loss: 0.3354 r:0.8220
Current avg r:0.6692 Best avg r: 0.6721
00:47:46,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:12,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:48:38,149 root INFO Epoch 18 Global steps: 54800 Train loss: 0.0509
en_zh Dev loss: 0.7370 r:0.5168
ro_en Dev loss: 0.3630 r:0.8232
Current avg r:0.6700 Best avg r: 0.6721
00:49:54,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:20,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:46,167 root INFO Epoch 18 Global steps: 55000 Train loss: 0.0521
en_zh Dev loss: 0.7521 r:0.5149
ro_en Dev loss: 0.3616 r:0.8207
Current avg r:0.6678 Best avg r: 0.6721
00:52:02,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:28,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:54,101 root INFO Epoch 18 Global steps: 55200 Train loss: 0.0526
en_zh Dev loss: 0.7417 r:0.5109
ro_en Dev loss: 0.3460 r:0.8237
Current avg r:0.6673 Best avg r: 0.6721
00:54:10,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:54:36,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:01,872 root INFO Epoch 18 Global steps: 55400 Train loss: 0.0507
en_zh Dev loss: 0.7126 r:0.5176
ro_en Dev loss: 0.3227 r:0.8252
Current avg r:0.6714 Best avg r: 0.6721
00:56:18,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:44,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:09,798 root INFO Epoch 18 Global steps: 55600 Train loss: 0.0515
en_zh Dev loss: 0.7430 r:0.5086
ro_en Dev loss: 0.3550 r:0.8205
Current avg r:0.6645 Best avg r: 0.6721
00:58:26,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:52,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:17,758 root INFO Epoch 18 Global steps: 55800 Train loss: 0.0517
en_zh Dev loss: 0.7216 r:0.5148
ro_en Dev loss: 0.3354 r:0.8234
Current avg r:0.6691 Best avg r: 0.6721
01:00:34,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:59,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:25,672 root INFO Epoch 18 Global steps: 56000 Train loss: 0.0527
en_zh Dev loss: 0.7214 r:0.5172
ro_en Dev loss: 0.3396 r:0.8245
Current avg r:0.6709 Best avg r: 0.6721
01:02:42,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:07,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:33,573 root INFO Epoch 18 Global steps: 56200 Train loss: 0.0530
en_zh Dev loss: 0.7302 r:0.5161
ro_en Dev loss: 0.3501 r:0.8249
Current avg r:0.6705 Best avg r: 0.6721
01:04:50,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:15,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:41,573 root INFO Epoch 18 Global steps: 56400 Train loss: 0.0533
en_zh Dev loss: 0.7111 r:0.5166
ro_en Dev loss: 0.3260 r:0.8262
Current avg r:0.6714 Best avg r: 0.6721
01:06:58,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:23,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:49,520 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:07:49,534 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:08:15,232 root INFO Epoch 18 Global steps: 56600 Train loss: 0.0485
en_zh Dev loss: 0.7002 r:0.5206
ro_en Dev loss: 0.3157 r:0.8264
Current avg r:0.6735 Best avg r: 0.6735
01:09:31,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:57,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:22,951 root INFO Epoch 18 Global steps: 56800 Train loss: 0.0519
en_zh Dev loss: 0.7056 r:0.5173
ro_en Dev loss: 0.3333 r:0.8233
Current avg r:0.6703 Best avg r: 0.6735
01:11:39,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:05,241 root INFO 
id:en_zh cur r: 0.5230 best r: 0.5230
01:12:18,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:43,813 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:12:43,818 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_random2/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:13:09,537 root INFO Epoch 18 Global steps: 57000 Train loss: 0.0540
en_zh Dev loss: 0.6781 r:0.5227
ro_en Dev loss: 0.3168 r:0.8262
Current avg r:0.6745 Best avg r: 0.6745
01:14:26,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:52,159 root INFO 
id:en_zh cur r: 0.5230 best r: 0.5230
01:15:05,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:30,728 root INFO Epoch 19 Global steps: 57200 Train loss: 0.0551
en_zh Dev loss: 0.7081 r:0.5218
ro_en Dev loss: 0.3374 r:0.8239
Current avg r:0.6729 Best avg r: 0.6745
01:16:47,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:12,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:38,564 root INFO Epoch 19 Global steps: 57400 Train loss: 0.0495
en_zh Dev loss: 0.7001 r:0.5216
ro_en Dev loss: 0.3232 r:0.8264
Current avg r:0.6740 Best avg r: 0.6745
01:18:55,104 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:20,806 root INFO 
id:en_zh cur r: 0.5239 best r: 0.5239
01:19:33,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:59,377 root INFO Epoch 19 Global steps: 57600 Train loss: 0.0497
en_zh Dev loss: 0.7194 r:0.5226
ro_en Dev loss: 0.3533 r:0.8240
Current avg r:0.6733 Best avg r: 0.6745
01:21:15,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:41,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:22:07,292 root INFO Epoch 19 Global steps: 57800 Train loss: 0.0455
en_zh Dev loss: 0.7363 r:0.5175
ro_en Dev loss: 0.3393 r:0.8228
Current avg r:0.6702 Best avg r: 0.6745
01:23:23,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:49,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:15,148 root INFO Epoch 19 Global steps: 58000 Train loss: 0.0502
en_zh Dev loss: 0.7199 r:0.5181
ro_en Dev loss: 0.3388 r:0.8249
Current avg r:0.6715 Best avg r: 0.6745
01:25:31,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:57,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:23,119 root INFO Epoch 19 Global steps: 58200 Train loss: 0.0467
en_zh Dev loss: 0.7656 r:0.5152
ro_en Dev loss: 0.3486 r:0.8246
Current avg r:0.6699 Best avg r: 0.6745
01:27:39,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:05,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:31,147 root INFO Epoch 19 Global steps: 58400 Train loss: 0.0472
en_zh Dev loss: 0.7250 r:0.5128
ro_en Dev loss: 0.3333 r:0.8255
Current avg r:0.6692 Best avg r: 0.6745
01:29:47,781 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:13,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:39,156 root INFO Epoch 19 Global steps: 58600 Train loss: 0.0503
en_zh Dev loss: 0.7047 r:0.5138
ro_en Dev loss: 0.3056 r:0.8279
Current avg r:0.6709 Best avg r: 0.6745
01:31:55,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:32:21,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:46,962 root INFO Epoch 19 Global steps: 58800 Train loss: 0.0493
en_zh Dev loss: 0.7335 r:0.5148
ro_en Dev loss: 0.3179 r:0.8258
Current avg r:0.6703 Best avg r: 0.6745
01:34:03,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:34:29,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:54,774 root INFO Epoch 19 Global steps: 59000 Train loss: 0.0504
en_zh Dev loss: 0.7550 r:0.5153
ro_en Dev loss: 0.3593 r:0.8251
Current avg r:0.6702 Best avg r: 0.6745
01:36:11,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:36:37,11 root INFO 
id:en_zh cur r: 0.5265 best r: 0.5265
01:36:49,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:15,609 root INFO Epoch 19 Global steps: 59200 Train loss: 0.0480
en_zh Dev loss: 0.7317 r:0.5234
ro_en Dev loss: 0.3595 r:0.8239
Current avg r:0.6737 Best avg r: 0.6745
01:38:32,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:38:57,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:23,534 root INFO Epoch 19 Global steps: 59400 Train loss: 0.0474
en_zh Dev loss: 0.6985 r:0.5133
ro_en Dev loss: 0.3158 r:0.8246
Current avg r:0.6689 Best avg r: 0.6745
01:40:40,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:41:05,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:41:31,368 root INFO Epoch 19 Global steps: 59600 Train loss: 0.0505
en_zh Dev loss: 0.7584 r:0.5135
ro_en Dev loss: 0.3601 r:0.8211
Current avg r:0.6673 Best avg r: 0.6745
01:42:47,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:13,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:39,349 root INFO Epoch 19 Global steps: 59800 Train loss: 0.0472
en_zh Dev loss: 0.7586 r:0.5072
ro_en Dev loss: 0.3419 r:0.8237
Current avg r:0.6654 Best avg r: 0.6745
01:44:55,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:45:21,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:47,275 root INFO Epoch 19 Global steps: 60000 Train loss: 0.0467
en_zh Dev loss: 0.7553 r:0.5156
ro_en Dev loss: 0.3510 r:0.8229
Current avg r:0.6692 Best avg r: 0.6745
