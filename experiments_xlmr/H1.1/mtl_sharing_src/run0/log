14:41:46,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:12,860 root INFO 
id:en_de cur r: 0.0101 best r: 0.0101
14:42:38,732 root INFO 
id:en_zh cur r: 0.1003 best r: 0.1003
14:42:38,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:04,591 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
14:43:04,598 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:43:30,521 root INFO Epoch 0 Global steps: 200 Train loss: 0.8050
en_de Dev loss: 0.8871 r:0.0431
en_zh Dev loss: 0.8174 r:0.1185
Current avg r:0.0808 Best avg r: 0.0808
14:44:47,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:13,564 root INFO 
id:en_de cur r: 0.0462 best r: 0.0462
14:45:39,502 root INFO 
id:en_zh cur r: 0.1826 best r: 0.1826
14:45:39,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:05,447 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
14:46:05,453 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:46:31,446 root INFO Epoch 0 Global steps: 400 Train loss: 0.6495
en_de Dev loss: 0.8904 r:0.0369
en_zh Dev loss: 0.8187 r:0.1564
Current avg r:0.0966 Best avg r: 0.0966
14:47:48,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:14,542 root INFO 
id:en_de cur r: 0.0511 best r: 0.0511
14:48:27,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:53,438 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
14:48:53,447 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:49:19,414 root INFO Epoch 0 Global steps: 600 Train loss: 0.7217
en_de Dev loss: 0.8863 r:0.0852
en_zh Dev loss: 0.8160 r:0.1960
Current avg r:0.1406 Best avg r: 0.1406
14:50:36,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:02,418 root INFO 
id:en_de cur r: 0.0799 best r: 0.0799
14:51:28,368 root INFO 
id:en_zh cur r: 0.2239 best r: 0.2239
14:51:28,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:54,334 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
14:51:54,341 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:52:20,302 root INFO Epoch 0 Global steps: 800 Train loss: 0.7385
en_de Dev loss: 0.8885 r:0.0972
en_zh Dev loss: 0.8144 r:0.2141
Current avg r:0.1556 Best avg r: 0.1556
14:53:37,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:03,382 root INFO 
id:en_de cur r: 0.0978 best r: 0.0978
14:54:29,338 root INFO 
id:en_zh cur r: 0.2770 best r: 0.2770
14:54:29,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:55,303 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
14:54:55,310 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:55:21,285 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7411
en_de Dev loss: 0.8867 r:0.1059
en_zh Dev loss: 0.8100 r:0.2483
Current avg r:0.1771 Best avg r: 0.1771
14:56:38,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:04,325 root INFO 
id:en_de cur r: 0.1087 best r: 0.1087
14:57:30,260 root INFO 
id:en_zh cur r: 0.3095 best r: 0.3095
14:57:30,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:56,216 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
14:57:56,223 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:58:22,203 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7845
en_de Dev loss: 0.8828 r:0.1346
en_zh Dev loss: 0.8042 r:0.2945
Current avg r:0.2146 Best avg r: 0.2146
14:59:39,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:05,359 root INFO 
id:en_de cur r: 0.1314 best r: 0.1314
15:00:31,295 root INFO 
id:en_zh cur r: 0.3402 best r: 0.3402
15:00:31,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:57,260 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:00:57,266 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:01:23,235 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7337
en_de Dev loss: 0.8820 r:0.1364
en_zh Dev loss: 0.7929 r:0.3285
Current avg r:0.2325 Best avg r: 0.2325
15:02:40,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:19,281 root INFO 
id:en_zh cur r: 0.3813 best r: 0.3813
15:03:19,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:45,247 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:03:45,252 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:04:11,220 root INFO Epoch 0 Global steps: 1600 Train loss: 0.6846
en_de Dev loss: 0.8741 r:0.1731
en_zh Dev loss: 0.7526 r:0.3848
Current avg r:0.2790 Best avg r: 0.2790
15:05:28,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:54,264 root INFO 
id:en_de cur r: 0.1571 best r: 0.1571
15:06:20,202 root INFO 
id:en_zh cur r: 0.3921 best r: 0.3921
15:06:20,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:46,163 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:06:46,168 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:07:12,151 root INFO Epoch 0 Global steps: 1800 Train loss: 0.8363
en_de Dev loss: 0.8581 r:0.1844
en_zh Dev loss: 0.6960 r:0.4032
Current avg r:0.2938 Best avg r: 0.2938
15:08:29,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:55,281 root INFO 
id:en_de cur r: 0.1720 best r: 0.1720
15:09:08,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:34,196 root INFO Epoch 0 Global steps: 2000 Train loss: 0.8664
en_de Dev loss: 0.8873 r:0.1778
en_zh Dev loss: 0.7601 r:0.3903
Current avg r:0.2841 Best avg r: 0.2938
15:10:51,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:17,317 root INFO 
id:en_de cur r: 0.1776 best r: 0.1776
15:11:43,271 root INFO 
id:en_zh cur r: 0.4071 best r: 0.4071
15:11:43,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:09,241 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:12:09,247 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:12:35,222 root INFO Epoch 0 Global steps: 2200 Train loss: 0.6518
en_de Dev loss: 0.8571 r:0.2027
en_zh Dev loss: 0.6964 r:0.4153
Current avg r:0.3090 Best avg r: 0.3090
15:13:52,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:18,335 root INFO 
id:en_de cur r: 0.1858 best r: 0.1858
15:14:31,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:57,251 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:14:57,257 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:15:23,259 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6810
en_de Dev loss: 0.8844 r:0.2173
en_zh Dev loss: 0.7494 r:0.4089
Current avg r:0.3131 Best avg r: 0.3131
15:16:40,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:06,415 root INFO 
id:en_de cur r: 0.2228 best r: 0.2228
15:17:32,375 root INFO 
id:en_zh cur r: 0.4321 best r: 0.4321
15:17:32,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:58,353 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:17:58,360 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:18:24,328 root INFO Epoch 0 Global steps: 2600 Train loss: 0.6543
en_de Dev loss: 0.8508 r:0.2274
en_zh Dev loss: 0.7030 r:0.4388
Current avg r:0.3331 Best avg r: 0.3331
15:19:41,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:07,492 root INFO 
id:en_de cur r: 0.2271 best r: 0.2271
15:20:33,455 root INFO 
id:en_zh cur r: 0.4365 best r: 0.4365
15:20:33,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:59,420 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:20:59,426 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:21:25,401 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6217
en_de Dev loss: 0.8473 r:0.2365
en_zh Dev loss: 0.6815 r:0.4450
Current avg r:0.3408 Best avg r: 0.3408
15:22:42,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:08,605 root INFO 
id:en_de cur r: 0.2297 best r: 0.2297
15:23:34,542 root INFO 
id:en_zh cur r: 0.4516 best r: 0.4516
15:23:34,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:00,484 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:24:00,489 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:24:26,462 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6838
en_de Dev loss: 0.8470 r:0.2390
en_zh Dev loss: 0.6555 r:0.4573
Current avg r:0.3481 Best avg r: 0.3481
15:25:44,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:10,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:35,962 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6164
en_de Dev loss: 0.8701 r:0.2346
en_zh Dev loss: 0.7147 r:0.4421
Current avg r:0.3384 Best avg r: 0.3481
15:27:53,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:28:19,31 root INFO 
id:en_de cur r: 0.2478 best r: 0.2478
15:28:44,969 root INFO 
id:en_zh cur r: 0.4586 best r: 0.4586
15:28:44,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:10,914 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:29:10,921 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:29:36,901 root INFO Epoch 1 Global steps: 3400 Train loss: 0.6284
en_de Dev loss: 0.8425 r:0.2579
en_zh Dev loss: 0.6738 r:0.4557
Current avg r:0.3568 Best avg r: 0.3568
15:30:53,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:19,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:45,863 root INFO Epoch 1 Global steps: 3600 Train loss: 0.5612
en_de Dev loss: 0.8505 r:0.2428
en_zh Dev loss: 0.6782 r:0.4565
Current avg r:0.3497 Best avg r: 0.3568
15:33:03,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:29,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:54,957 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6250
en_de Dev loss: 0.8588 r:0.2408
en_zh Dev loss: 0.8179 r:0.4531
Current avg r:0.3470 Best avg r: 0.3568
15:35:12,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:38,51 root INFO 
id:en_de cur r: 0.2509 best r: 0.2509
15:36:04,10 root INFO 
id:en_zh cur r: 0.4660 best r: 0.4660
15:36:04,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:29,982 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:36:29,988 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:36:55,992 root INFO Epoch 1 Global steps: 4000 Train loss: 0.5919
en_de Dev loss: 0.8401 r:0.2551
en_zh Dev loss: 0.7525 r:0.4630
Current avg r:0.3590 Best avg r: 0.3590
15:38:13,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:51,992 root INFO 
id:en_zh cur r: 0.4709 best r: 0.4709
15:38:51,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:17,943 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:39:17,948 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:39:43,933 root INFO Epoch 1 Global steps: 4200 Train loss: 0.6442
en_de Dev loss: 0.8573 r:0.2519
en_zh Dev loss: 0.7913 r:0.4667
Current avg r:0.3593 Best avg r: 0.3593
15:41:01,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:27,34 root INFO 
id:en_de cur r: 0.2588 best r: 0.2588
15:41:52,964 root INFO 
id:en_zh cur r: 0.4763 best r: 0.4763
15:41:52,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:18,927 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:42:18,934 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:42:44,907 root INFO Epoch 1 Global steps: 4400 Train loss: 0.6625
en_de Dev loss: 0.8450 r:0.2568
en_zh Dev loss: 0.6825 r:0.4701
Current avg r:0.3634 Best avg r: 0.3634
15:44:01,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:40,891 root INFO 
id:en_zh cur r: 0.4775 best r: 0.4775
15:44:40,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:06,836 root INFO Epoch 1 Global steps: 4600 Train loss: 0.6300
en_de Dev loss: 0.8481 r:0.2460
en_zh Dev loss: 0.6980 r:0.4730
Current avg r:0.3595 Best avg r: 0.3634
15:46:24,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:02,963 root INFO 
id:en_zh cur r: 0.4885 best r: 0.4885
15:47:02,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:28,914 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:47:28,920 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:47:54,919 root INFO Epoch 1 Global steps: 4800 Train loss: 0.5355
en_de Dev loss: 0.8360 r:0.2473
en_zh Dev loss: 0.6376 r:0.4833
Current avg r:0.3653 Best avg r: 0.3653
15:49:12,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:38,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:03,958 root INFO Epoch 1 Global steps: 5000 Train loss: 0.5988
en_de Dev loss: 0.8593 r:0.2392
en_zh Dev loss: 0.7066 r:0.4716
Current avg r:0.3554 Best avg r: 0.3653
15:51:21,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:47,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:12,972 root INFO Epoch 1 Global steps: 5200 Train loss: 0.5759
en_de Dev loss: 0.8442 r:0.2388
en_zh Dev loss: 0.6876 r:0.4770
Current avg r:0.3579 Best avg r: 0.3653
15:53:30,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:55,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:21,901 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:54:21,907 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:54:47,873 root INFO Epoch 1 Global steps: 5400 Train loss: 0.6436
en_de Dev loss: 0.8359 r:0.2533
en_zh Dev loss: 0.6916 r:0.4802
Current avg r:0.3667 Best avg r: 0.3667
15:56:05,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:31,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:57,26 root INFO Epoch 1 Global steps: 5600 Train loss: 0.5630
en_de Dev loss: 0.8495 r:0.2437
en_zh Dev loss: 0.7169 r:0.4751
Current avg r:0.3594 Best avg r: 0.3667
15:58:14,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:53,54 root INFO 
id:en_zh cur r: 0.5054 best r: 0.5054
15:58:53,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:19,15 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:59:19,20 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:59:45,18 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6701
en_de Dev loss: 0.8397 r:0.2419
en_zh Dev loss: 0.6431 r:0.5011
Current avg r:0.3715 Best avg r: 0.3715
16:01:02,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:41,126 root INFO 
id:en_zh cur r: 0.5069 best r: 0.5069
16:01:41,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:07,73 root INFO Epoch 1 Global steps: 6000 Train loss: 0.6738
en_de Dev loss: 0.8420 r:0.2342
en_zh Dev loss: 0.6748 r:0.5023
Current avg r:0.3683 Best avg r: 0.3715
16:03:24,549 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:03,461 root INFO 
id:en_zh cur r: 0.5147 best r: 0.5147
16:04:03,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:29,432 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
16:04:29,440 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:04:55,443 root INFO Epoch 2 Global steps: 6200 Train loss: 0.5786
en_de Dev loss: 0.8364 r:0.2470
en_zh Dev loss: 0.6479 r:0.5110
Current avg r:0.3790 Best avg r: 0.3790
16:06:12,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:38,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:04,450 root INFO Epoch 2 Global steps: 6400 Train loss: 0.5367
en_de Dev loss: 0.8323 r:0.2571
en_zh Dev loss: 0.6747 r:0.4882
Current avg r:0.3726 Best avg r: 0.3790
16:08:21,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:08:47,599 root INFO 
id:en_de cur r: 0.2614 best r: 0.2614
16:09:00,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:26,500 root INFO Epoch 2 Global steps: 6600 Train loss: 0.4975
en_de Dev loss: 0.8406 r:0.2621
en_zh Dev loss: 0.6804 r:0.4945
Current avg r:0.3783 Best avg r: 0.3790
16:10:43,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:09,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:35,556 root INFO Epoch 2 Global steps: 6800 Train loss: 0.5839
en_de Dev loss: 0.8440 r:0.2468
en_zh Dev loss: 0.6642 r:0.5061
Current avg r:0.3765 Best avg r: 0.3790
16:12:52,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:18,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:44,706 root INFO Epoch 2 Global steps: 7000 Train loss: 0.5384
en_de Dev loss: 0.8394 r:0.2491
en_zh Dev loss: 0.6522 r:0.5077
Current avg r:0.3784 Best avg r: 0.3790
16:15:01,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:27,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:53,832 root INFO Epoch 2 Global steps: 7200 Train loss: 0.5156
en_de Dev loss: 0.8636 r:0.2422
en_zh Dev loss: 0.7376 r:0.4950
Current avg r:0.3686 Best avg r: 0.3790
16:17:10,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:36,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:02,866 root INFO Epoch 2 Global steps: 7400 Train loss: 0.5310
en_de Dev loss: 0.8439 r:0.2484
en_zh Dev loss: 0.7459 r:0.4953
Current avg r:0.3718 Best avg r: 0.3790
16:19:19,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:45,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:11,899 root INFO Epoch 2 Global steps: 7600 Train loss: 0.6511
en_de Dev loss: 0.8474 r:0.2343
en_zh Dev loss: 0.7774 r:0.4770
Current avg r:0.3557 Best avg r: 0.3790
16:21:29,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:21:54,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:20,924 root INFO Epoch 2 Global steps: 7800 Train loss: 0.5544
en_de Dev loss: 0.8431 r:0.2386
en_zh Dev loss: 0.7498 r:0.4817
Current avg r:0.3601 Best avg r: 0.3790
16:23:38,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:03,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:24:29,873 root INFO Epoch 2 Global steps: 8000 Train loss: 0.6193
en_de Dev loss: 0.8570 r:0.2307
en_zh Dev loss: 0.7154 r:0.5050
Current avg r:0.3678 Best avg r: 0.3790
16:25:46,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:12,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:38,880 root INFO Epoch 2 Global steps: 8200 Train loss: 0.4926
en_de Dev loss: 0.8565 r:0.2204
en_zh Dev loss: 0.7338 r:0.5014
Current avg r:0.3609 Best avg r: 0.3790
16:27:56,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:22,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:47,991 root INFO Epoch 2 Global steps: 8400 Train loss: 0.5515
en_de Dev loss: 0.8567 r:0.2359
en_zh Dev loss: 0.7537 r:0.4940
Current avg r:0.3650 Best avg r: 0.3790
16:30:05,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:31,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:57,59 root INFO Epoch 2 Global steps: 8600 Train loss: 0.5238
en_de Dev loss: 0.8697 r:0.2331
en_zh Dev loss: 0.7725 r:0.4894
Current avg r:0.3612 Best avg r: 0.3790
16:32:14,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:40,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:06,127 root INFO Epoch 2 Global steps: 8800 Train loss: 0.5939
en_de Dev loss: 0.8555 r:0.2183
en_zh Dev loss: 0.6889 r:0.5048
Current avg r:0.3615 Best avg r: 0.3790
16:34:23,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:49,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:15,327 root INFO Epoch 2 Global steps: 9000 Train loss: 0.4789
en_de Dev loss: 0.8491 r:0.2213
en_zh Dev loss: 0.6686 r:0.4944
Current avg r:0.3578 Best avg r: 0.3790
16:36:32,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:58,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:24,689 root INFO Epoch 3 Global steps: 9200 Train loss: 0.4785
en_de Dev loss: 0.8474 r:0.2239
en_zh Dev loss: 0.6927 r:0.4984
Current avg r:0.3611 Best avg r: 0.3790
16:38:41,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:07,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:33,707 root INFO Epoch 3 Global steps: 9400 Train loss: 0.5881
en_de Dev loss: 0.8525 r:0.2251
en_zh Dev loss: 0.7233 r:0.5004
Current avg r:0.3627 Best avg r: 0.3790
16:40:50,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:16,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:42,753 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
16:41:42,759 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:42:08,738 root INFO Epoch 3 Global steps: 9600 Train loss: 0.4242
en_de Dev loss: 0.8295 r:0.2587
en_zh Dev loss: 0.6906 r:0.5002
Current avg r:0.3794 Best avg r: 0.3794
16:43:25,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:51,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:17,930 root INFO Epoch 3 Global steps: 9800 Train loss: 0.4083
en_de Dev loss: 0.8454 r:0.2337
en_zh Dev loss: 0.6809 r:0.5077
Current avg r:0.3707 Best avg r: 0.3794
16:45:34,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:00,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:26,878 root INFO Epoch 3 Global steps: 10000 Train loss: 0.5090
en_de Dev loss: 0.8804 r:0.2233
en_zh Dev loss: 0.8212 r:0.4847
Current avg r:0.3540 Best avg r: 0.3794
16:47:43,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:09,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:35,798 root INFO Epoch 3 Global steps: 10200 Train loss: 0.4295
en_de Dev loss: 0.8569 r:0.2293
en_zh Dev loss: 0.6869 r:0.5089
Current avg r:0.3691 Best avg r: 0.3794
16:49:52,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:18,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:44,757 root INFO Epoch 3 Global steps: 10400 Train loss: 0.4871
en_de Dev loss: 0.8596 r:0.2284
en_zh Dev loss: 0.7035 r:0.5029
Current avg r:0.3657 Best avg r: 0.3794
16:52:01,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:27,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:53,748 root INFO Epoch 3 Global steps: 10600 Train loss: 0.5005
en_de Dev loss: 0.8581 r:0.2219
en_zh Dev loss: 0.7112 r:0.5013
Current avg r:0.3616 Best avg r: 0.3794
16:54:10,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:36,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:02,750 root INFO Epoch 3 Global steps: 10800 Train loss: 0.4863
en_de Dev loss: 0.8425 r:0.2326
en_zh Dev loss: 0.6647 r:0.4956
Current avg r:0.3641 Best avg r: 0.3794
16:56:19,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:45,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:11,795 root INFO Epoch 3 Global steps: 11000 Train loss: 0.4743
en_de Dev loss: 0.8676 r:0.2498
en_zh Dev loss: 0.7900 r:0.4598
Current avg r:0.3548 Best avg r: 0.3794
16:58:28,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:54,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:20,815 root INFO Epoch 3 Global steps: 11200 Train loss: 0.4998
en_de Dev loss: 0.8730 r:0.2233
en_zh Dev loss: 0.7276 r:0.5007
Current avg r:0.3620 Best avg r: 0.3794
17:00:37,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:03,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:29,830 root INFO Epoch 3 Global steps: 11400 Train loss: 0.4569
en_de Dev loss: 0.8547 r:0.2392
en_zh Dev loss: 0.7271 r:0.4933
Current avg r:0.3663 Best avg r: 0.3794
17:02:46,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:12,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:38,870 root INFO Epoch 3 Global steps: 11600 Train loss: 0.5495
en_de Dev loss: 0.8684 r:0.2353
en_zh Dev loss: 0.7924 r:0.4769
Current avg r:0.3561 Best avg r: 0.3794
17:04:56,70 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:22,42 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:48,39 root INFO Epoch 3 Global steps: 11800 Train loss: 0.4367
en_de Dev loss: 0.8631 r:0.2428
en_zh Dev loss: 0.7761 r:0.4748
Current avg r:0.3588 Best avg r: 0.3794
17:07:05,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:31,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:57,279 root INFO Epoch 3 Global steps: 12000 Train loss: 0.4548
en_de Dev loss: 0.8489 r:0.2462
en_zh Dev loss: 0.7483 r:0.4719
Current avg r:0.3590 Best avg r: 0.3794
17:09:14,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:40,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:10:06,604 root INFO Epoch 4 Global steps: 12200 Train loss: 0.3848
en_de Dev loss: 0.8629 r:0.2529
en_zh Dev loss: 0.8055 r:0.4382
Current avg r:0.3456 Best avg r: 0.3794
17:11:23,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:49,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:15,612 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4028
en_de Dev loss: 0.8492 r:0.2466
en_zh Dev loss: 0.7231 r:0.4705
Current avg r:0.3586 Best avg r: 0.3794
17:13:32,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:58,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:24,840 root INFO Epoch 4 Global steps: 12600 Train loss: 0.4376
en_de Dev loss: 0.8669 r:0.2220
en_zh Dev loss: 0.7395 r:0.4781
Current avg r:0.3500 Best avg r: 0.3794
17:15:42,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:08,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:34,27 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4681
en_de Dev loss: 0.8751 r:0.2090
en_zh Dev loss: 0.7579 r:0.4927
Current avg r:0.3508 Best avg r: 0.3794
17:17:51,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:17,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:43,84 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4275
en_de Dev loss: 0.8419 r:0.2460
en_zh Dev loss: 0.7172 r:0.4669
Current avg r:0.3564 Best avg r: 0.3794
17:20:00,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:26,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:52,293 root INFO Epoch 4 Global steps: 13200 Train loss: 0.4191
en_de Dev loss: 0.8599 r:0.2273
en_zh Dev loss: 0.7422 r:0.4708
Current avg r:0.3490 Best avg r: 0.3794
17:22:09,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:35,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:01,394 root INFO Epoch 4 Global steps: 13400 Train loss: 0.3634
en_de Dev loss: 0.8648 r:0.2313
en_zh Dev loss: 0.7438 r:0.4849
Current avg r:0.3581 Best avg r: 0.3794
17:24:18,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:44,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:10,433 root INFO Epoch 4 Global steps: 13600 Train loss: 0.4043
en_de Dev loss: 0.8604 r:0.2362
en_zh Dev loss: 0.8213 r:0.4814
Current avg r:0.3588 Best avg r: 0.3794
17:26:27,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:53,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:19,513 root INFO Epoch 4 Global steps: 13800 Train loss: 0.4229
en_de Dev loss: 0.8457 r:0.2484
en_zh Dev loss: 0.7430 r:0.4761
Current avg r:0.3622 Best avg r: 0.3794
17:28:36,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:02,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:28,647 root INFO Epoch 4 Global steps: 14000 Train loss: 0.4036
en_de Dev loss: 0.8759 r:0.2357
en_zh Dev loss: 0.8139 r:0.4714
Current avg r:0.3535 Best avg r: 0.3794
17:30:45,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:11,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:37,856 root INFO Epoch 4 Global steps: 14200 Train loss: 0.4249
en_de Dev loss: 0.8680 r:0.2351
en_zh Dev loss: 0.8179 r:0.4487
Current avg r:0.3419 Best avg r: 0.3794
17:32:55,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:21,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:47,15 root INFO Epoch 4 Global steps: 14400 Train loss: 0.3645
en_de Dev loss: 0.8644 r:0.2277
en_zh Dev loss: 0.7657 r:0.4612
Current avg r:0.3445 Best avg r: 0.3794
17:35:04,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:30,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:56,210 root INFO Epoch 4 Global steps: 14600 Train loss: 0.3830
en_de Dev loss: 0.8535 r:0.2167
en_zh Dev loss: 0.7052 r:0.4860
Current avg r:0.3513 Best avg r: 0.3794
17:37:13,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:39,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:05,320 root INFO Epoch 4 Global steps: 14800 Train loss: 0.4107
en_de Dev loss: 0.8610 r:0.2454
en_zh Dev loss: 0.8241 r:0.4579
Current avg r:0.3516 Best avg r: 0.3794
17:39:22,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:48,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:14,313 root INFO Epoch 4 Global steps: 15000 Train loss: 0.4133
en_de Dev loss: 0.8600 r:0.2347
en_zh Dev loss: 0.7813 r:0.4707
Current avg r:0.3527 Best avg r: 0.3794
17:41:31,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:57,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:23,873 root INFO Epoch 5 Global steps: 15200 Train loss: 0.3735
en_de Dev loss: 0.8593 r:0.2330
en_zh Dev loss: 0.8168 r:0.4571
Current avg r:0.3450 Best avg r: 0.3794
17:43:41,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:07,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:33,81 root INFO Epoch 5 Global steps: 15400 Train loss: 0.2958
en_de Dev loss: 0.8697 r:0.2280
en_zh Dev loss: 0.7932 r:0.4666
Current avg r:0.3473 Best avg r: 0.3794
17:45:50,355 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:16,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:42,307 root INFO Epoch 5 Global steps: 15600 Train loss: 0.3457
en_de Dev loss: 0.8388 r:0.2382
en_zh Dev loss: 0.7201 r:0.4532
Current avg r:0.3457 Best avg r: 0.3794
17:47:59,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:25,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:51,458 root INFO Epoch 5 Global steps: 15800 Train loss: 0.3571
en_de Dev loss: 0.8537 r:0.2329
en_zh Dev loss: 0.7597 r:0.4638
Current avg r:0.3484 Best avg r: 0.3794
17:50:08,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:34,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:00,627 root INFO Epoch 5 Global steps: 16000 Train loss: 0.3590
en_de Dev loss: 0.8606 r:0.2345
en_zh Dev loss: 0.7423 r:0.4657
Current avg r:0.3501 Best avg r: 0.3794
17:52:17,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:43,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:09,751 root INFO Epoch 5 Global steps: 16200 Train loss: 0.3644
en_de Dev loss: 0.8471 r:0.2442
en_zh Dev loss: 0.7721 r:0.4617
Current avg r:0.3529 Best avg r: 0.3794
17:54:26,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:52,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:18,784 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3186
en_de Dev loss: 0.8716 r:0.2527
en_zh Dev loss: 0.8140 r:0.4639
Current avg r:0.3583 Best avg r: 0.3794
17:56:35,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:01,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:27,912 root INFO Epoch 5 Global steps: 16600 Train loss: 0.3562
en_de Dev loss: 0.8617 r:0.2512
en_zh Dev loss: 0.7897 r:0.4594
Current avg r:0.3553 Best avg r: 0.3794
17:58:45,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:11,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:37,115 root INFO Epoch 5 Global steps: 16800 Train loss: 0.3374
en_de Dev loss: 0.8821 r:0.2314
en_zh Dev loss: 0.7331 r:0.4743
Current avg r:0.3528 Best avg r: 0.3794
18:00:54,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:20,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:46,142 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3692
en_de Dev loss: 0.8448 r:0.2508
en_zh Dev loss: 0.7121 r:0.4607
Current avg r:0.3558 Best avg r: 0.3794
18:03:03,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:29,283 root INFO 
id:en_de cur r: 0.2617 best r: 0.2617
18:03:42,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:08,192 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3126
en_de Dev loss: 0.8415 r:0.2578
en_zh Dev loss: 0.7410 r:0.4618
Current avg r:0.3598 Best avg r: 0.3794
18:05:25,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:51,321 root INFO 
id:en_de cur r: 0.2684 best r: 0.2684
18:06:04,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:30,244 root INFO Epoch 5 Global steps: 17400 Train loss: 0.3619
en_de Dev loss: 0.8688 r:0.2646
en_zh Dev loss: 0.8180 r:0.4629
Current avg r:0.3637 Best avg r: 0.3794
18:07:47,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:13,416 root INFO 
id:en_de cur r: 0.2690 best r: 0.2690
18:08:26,402 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:52,372 root INFO Epoch 5 Global steps: 17600 Train loss: 0.3579
en_de Dev loss: 0.8408 r:0.2648
en_zh Dev loss: 0.7830 r:0.4532
Current avg r:0.3590 Best avg r: 0.3794
18:10:09,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:35,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:01,487 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3430
en_de Dev loss: 0.8429 r:0.2470
en_zh Dev loss: 0.7755 r:0.4621
Current avg r:0.3545 Best avg r: 0.3794
18:12:18,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:44,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:10,519 root INFO Epoch 5 Global steps: 18000 Train loss: 0.3225
en_de Dev loss: 0.8693 r:0.2372
en_zh Dev loss: 0.8144 r:0.4625
Current avg r:0.3499 Best avg r: 0.3794
18:14:28,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:54,139 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:20,115 root INFO Epoch 6 Global steps: 18200 Train loss: 0.3038
en_de Dev loss: 0.8694 r:0.2213
en_zh Dev loss: 0.7811 r:0.4713
Current avg r:0.3463 Best avg r: 0.3794
18:16:37,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:03,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:29,223 root INFO Epoch 6 Global steps: 18400 Train loss: 0.3036
en_de Dev loss: 0.8559 r:0.2545
en_zh Dev loss: 0.8231 r:0.4615
Current avg r:0.3580 Best avg r: 0.3794
18:18:46,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:12,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:38,256 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3097
en_de Dev loss: 0.8713 r:0.2348
en_zh Dev loss: 0.8334 r:0.4655
Current avg r:0.3502 Best avg r: 0.3794
18:20:55,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:21,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:47,262 root INFO Epoch 6 Global steps: 18800 Train loss: 0.2829
en_de Dev loss: 0.8948 r:0.2201
en_zh Dev loss: 0.8066 r:0.4608
Current avg r:0.3404 Best avg r: 0.3794
18:23:04,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:30,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:56,305 root INFO Epoch 6 Global steps: 19000 Train loss: 0.2946
en_de Dev loss: 0.8693 r:0.2303
en_zh Dev loss: 0.7556 r:0.4771
Current avg r:0.3537 Best avg r: 0.3794
18:25:13,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:39,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:05,337 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3024
en_de Dev loss: 0.8666 r:0.2400
en_zh Dev loss: 0.7626 r:0.4702
Current avg r:0.3551 Best avg r: 0.3794
18:27:22,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:48,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:14,300 root INFO Epoch 6 Global steps: 19400 Train loss: 0.2901
en_de Dev loss: 0.8699 r:0.2210
en_zh Dev loss: 0.7710 r:0.4745
Current avg r:0.3478 Best avg r: 0.3794
18:29:31,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:57,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:23,343 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3390
en_de Dev loss: 0.8736 r:0.2270
en_zh Dev loss: 0.8206 r:0.4707
Current avg r:0.3489 Best avg r: 0.3794
18:31:40,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:06,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:32,305 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3156
en_de Dev loss: 0.8449 r:0.2580
en_zh Dev loss: 0.7772 r:0.4677
Current avg r:0.3628 Best avg r: 0.3794
18:33:49,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:15,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:41,413 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3279
en_de Dev loss: 0.8553 r:0.2376
en_zh Dev loss: 0.8124 r:0.4688
Current avg r:0.3532 Best avg r: 0.3794
18:35:58,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:24,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:50,568 root INFO Epoch 6 Global steps: 20200 Train loss: 0.2983
en_de Dev loss: 0.8606 r:0.2277
en_zh Dev loss: 0.7298 r:0.4859
Current avg r:0.3568 Best avg r: 0.3794
18:38:07,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:33,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:59,745 root INFO Epoch 6 Global steps: 20400 Train loss: 0.2528
en_de Dev loss: 0.9055 r:0.2225
en_zh Dev loss: 0.7626 r:0.4885
Current avg r:0.3555 Best avg r: 0.3794
18:40:16,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:42,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:08,755 root INFO Epoch 6 Global steps: 20600 Train loss: 0.2948
en_de Dev loss: 0.8531 r:0.2433
en_zh Dev loss: 0.7359 r:0.4866
Current avg r:0.3649 Best avg r: 0.3794
18:42:25,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:51,729 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:17,685 root INFO Epoch 6 Global steps: 20800 Train loss: 0.3013
en_de Dev loss: 0.8748 r:0.2352
en_zh Dev loss: 0.7988 r:0.4671
Current avg r:0.3512 Best avg r: 0.3794
18:44:34,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:00,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:26,746 root INFO Epoch 6 Global steps: 21000 Train loss: 0.2820
en_de Dev loss: 0.9090 r:0.2261
en_zh Dev loss: 0.8226 r:0.4837
Current avg r:0.3549 Best avg r: 0.3794
18:46:44,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:10,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:36,315 root INFO Epoch 7 Global steps: 21200 Train loss: 0.2777
en_de Dev loss: 0.8547 r:0.2424
en_zh Dev loss: 0.7323 r:0.4894
Current avg r:0.3659 Best avg r: 0.3794
18:48:53,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:19,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:45,430 root INFO Epoch 7 Global steps: 21400 Train loss: 0.2737
en_de Dev loss: 0.8745 r:0.2293
en_zh Dev loss: 0.7471 r:0.4861
Current avg r:0.3577 Best avg r: 0.3794
18:51:02,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:28,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:54,448 root INFO Epoch 7 Global steps: 21600 Train loss: 0.2768
en_de Dev loss: 0.8649 r:0.2379
en_zh Dev loss: 0.7606 r:0.4753
Current avg r:0.3566 Best avg r: 0.3794
18:53:11,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:37,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:03,485 root INFO Epoch 7 Global steps: 21800 Train loss: 0.2893
en_de Dev loss: 0.8736 r:0.2299
en_zh Dev loss: 0.7131 r:0.4899
Current avg r:0.3599 Best avg r: 0.3794
18:55:20,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:46,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:56:12,447 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2534
en_de Dev loss: 0.8581 r:0.2464
en_zh Dev loss: 0.7577 r:0.4737
Current avg r:0.3601 Best avg r: 0.3794
18:57:29,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:55,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:21,326 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2745
en_de Dev loss: 0.8862 r:0.2328
en_zh Dev loss: 0.7802 r:0.4664
Current avg r:0.3496 Best avg r: 0.3794
18:59:38,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:04,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:30,236 root INFO Epoch 7 Global steps: 22400 Train loss: 0.2578
en_de Dev loss: 0.8581 r:0.2210
en_zh Dev loss: 0.7197 r:0.4765
Current avg r:0.3487 Best avg r: 0.3794
19:01:47,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:13,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:39,111 root INFO Epoch 7 Global steps: 22600 Train loss: 0.2282
en_de Dev loss: 0.8833 r:0.2257
en_zh Dev loss: 0.8059 r:0.4699
Current avg r:0.3478 Best avg r: 0.3794
19:03:56,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:22,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:48,64 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2636
en_de Dev loss: 0.8846 r:0.2334
en_zh Dev loss: 0.8156 r:0.4786
Current avg r:0.3560 Best avg r: 0.3794
19:06:05,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:31,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:57,195 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2997
en_de Dev loss: 0.8898 r:0.2521
en_zh Dev loss: 0.8457 r:0.4840
Current avg r:0.3681 Best avg r: 0.3794
19:08:14,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:40,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:06,250 root INFO Epoch 7 Global steps: 23200 Train loss: 0.2682
en_de Dev loss: 0.8597 r:0.2303
en_zh Dev loss: 0.7397 r:0.4905
Current avg r:0.3604 Best avg r: 0.3794
19:10:23,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:49,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:15,291 root INFO Epoch 7 Global steps: 23400 Train loss: 0.2885
en_de Dev loss: 0.8863 r:0.2318
en_zh Dev loss: 0.7850 r:0.4965
Current avg r:0.3641 Best avg r: 0.3794
19:12:32,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:58,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:24,256 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2311
en_de Dev loss: 0.8764 r:0.2286
en_zh Dev loss: 0.7956 r:0.4667
Current avg r:0.3477 Best avg r: 0.3794
19:14:41,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:07,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:33,388 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2388
en_de Dev loss: 0.8974 r:0.2126
en_zh Dev loss: 0.7922 r:0.4840
Current avg r:0.3483 Best avg r: 0.3794
19:16:50,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:16,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:42,436 root INFO Epoch 7 Global steps: 24000 Train loss: 0.2390
en_de Dev loss: 0.8927 r:0.2116
en_zh Dev loss: 0.7934 r:0.4828
Current avg r:0.3472 Best avg r: 0.3794
19:19:00,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:25,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:51,887 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2382
en_de Dev loss: 0.8870 r:0.2009
en_zh Dev loss: 0.7256 r:0.4973
Current avg r:0.3491 Best avg r: 0.3794
19:21:08,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:34,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:00,865 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2382
en_de Dev loss: 0.8869 r:0.2027
en_zh Dev loss: 0.7676 r:0.4878
Current avg r:0.3452 Best avg r: 0.3794
19:23:17,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:43,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:09,886 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2433
en_de Dev loss: 0.8734 r:0.2223
en_zh Dev loss: 0.7804 r:0.4862
Current avg r:0.3543 Best avg r: 0.3794
19:25:27,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:52,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:18,892 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2594
en_de Dev loss: 0.8823 r:0.2149
en_zh Dev loss: 0.7238 r:0.4999
Current avg r:0.3574 Best avg r: 0.3794
19:27:35,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:01,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:27,834 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2271
en_de Dev loss: 0.8677 r:0.2345
en_zh Dev loss: 0.7542 r:0.4849
Current avg r:0.3597 Best avg r: 0.3794
19:29:44,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:10,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:36,893 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2471
en_de Dev loss: 0.8805 r:0.2230
en_zh Dev loss: 0.7558 r:0.4978
Current avg r:0.3604 Best avg r: 0.3794
19:31:53,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:19,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:45,865 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2447
en_de Dev loss: 0.8750 r:0.2194
en_zh Dev loss: 0.7897 r:0.4792
Current avg r:0.3493 Best avg r: 0.3794
19:34:02,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:28,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:54,807 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2311
en_de Dev loss: 0.8814 r:0.2371
en_zh Dev loss: 0.8525 r:0.4694
Current avg r:0.3533 Best avg r: 0.3794
19:36:11,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:37,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:03,893 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2449
en_de Dev loss: 0.8669 r:0.2336
en_zh Dev loss: 0.7535 r:0.4845
Current avg r:0.3590 Best avg r: 0.3794
19:38:21,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:47,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:39:13,95 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2304
en_de Dev loss: 0.8963 r:0.2267
en_zh Dev loss: 0.7530 r:0.4926
Current avg r:0.3597 Best avg r: 0.3794
19:40:30,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:56,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:22,233 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2144
en_de Dev loss: 0.8943 r:0.2340
en_zh Dev loss: 0.7784 r:0.4909
Current avg r:0.3624 Best avg r: 0.3794
19:42:39,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:05,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:31,305 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2603
en_de Dev loss: 0.9154 r:0.2115
en_zh Dev loss: 0.7627 r:0.4903
Current avg r:0.3509 Best avg r: 0.3794
19:44:48,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:14,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:40,505 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2170
en_de Dev loss: 0.8889 r:0.2361
en_zh Dev loss: 0.7744 r:0.4845
Current avg r:0.3603 Best avg r: 0.3794
19:46:57,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:23,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:49,679 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2270
en_de Dev loss: 0.8698 r:0.2260
en_zh Dev loss: 0.7366 r:0.4865
Current avg r:0.3563 Best avg r: 0.3794
19:49:06,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:32,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:58,756 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2350
en_de Dev loss: 0.8765 r:0.2441
en_zh Dev loss: 0.7709 r:0.4834
Current avg r:0.3637 Best avg r: 0.3794
19:51:16,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:42,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:08,57 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2523
en_de Dev loss: 0.8761 r:0.2292
en_zh Dev loss: 0.7792 r:0.4864
Current avg r:0.3578 Best avg r: 0.3794
19:53:25,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:51,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:17,45 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2167
en_de Dev loss: 0.8721 r:0.2340
en_zh Dev loss: 0.7527 r:0.4973
Current avg r:0.3656 Best avg r: 0.3794
19:55:34,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:00,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:25,986 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2213
en_de Dev loss: 0.8525 r:0.2391
en_zh Dev loss: 0.7219 r:0.4954
Current avg r:0.3672 Best avg r: 0.3794
19:57:43,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:08,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:34,948 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2056
en_de Dev loss: 0.8796 r:0.2497
en_zh Dev loss: 0.7903 r:0.4872
Current avg r:0.3685 Best avg r: 0.3794
19:59:52,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:18,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:43,965 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2159
en_de Dev loss: 0.8798 r:0.2320
en_zh Dev loss: 0.7891 r:0.4869
Current avg r:0.3594 Best avg r: 0.3794
20:02:01,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:27,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:52,981 root INFO Epoch 9 Global steps: 28200 Train loss: 0.1953
en_de Dev loss: 0.9184 r:0.2118
en_zh Dev loss: 0.8312 r:0.4871
Current avg r:0.3495 Best avg r: 0.3794
20:04:10,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:36,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:01,942 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2047
en_de Dev loss: 0.9110 r:0.2150
en_zh Dev loss: 0.8569 r:0.4781
Current avg r:0.3466 Best avg r: 0.3794
20:06:19,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:45,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:10,959 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2343
en_de Dev loss: 0.8983 r:0.2012
en_zh Dev loss: 0.7560 r:0.4927
Current avg r:0.3470 Best avg r: 0.3794
20:08:28,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:54,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:20,14 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2160
en_de Dev loss: 0.8938 r:0.2115
en_zh Dev loss: 0.7738 r:0.4822
Current avg r:0.3468 Best avg r: 0.3794
20:10:37,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:03,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:29,101 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2147
en_de Dev loss: 0.8786 r:0.2076
en_zh Dev loss: 0.7230 r:0.4886
Current avg r:0.3481 Best avg r: 0.3794
20:12:46,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:12,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:38,175 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2033
en_de Dev loss: 0.8820 r:0.2121
en_zh Dev loss: 0.7208 r:0.4840
Current avg r:0.3481 Best avg r: 0.3794
20:14:55,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:21,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:47,266 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2037
en_de Dev loss: 0.9041 r:0.2125
en_zh Dev loss: 0.7652 r:0.4778
Current avg r:0.3452 Best avg r: 0.3794
20:17:04,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:30,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:56,316 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2049
en_de Dev loss: 0.8914 r:0.2082
en_zh Dev loss: 0.7678 r:0.4799
Current avg r:0.3441 Best avg r: 0.3794
20:19:13,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:39,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:05,402 root INFO Epoch 9 Global steps: 29800 Train loss: 0.1891
en_de Dev loss: 0.8873 r:0.2088
en_zh Dev loss: 0.7918 r:0.4847
Current avg r:0.3468 Best avg r: 0.3794
20:21:22,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:48,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:14,579 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2147
en_de Dev loss: 0.9232 r:0.1951
en_zh Dev loss: 0.8164 r:0.4918
Current avg r:0.3435 Best avg r: 0.3794
20:23:32,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:58,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:24,153 root INFO Epoch 10 Global steps: 30200 Train loss: 0.2278
en_de Dev loss: 0.9010 r:0.2067
en_zh Dev loss: 0.7628 r:0.4900
Current avg r:0.3484 Best avg r: 0.3794
20:25:41,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:26:07,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:33,210 root INFO Epoch 10 Global steps: 30400 Train loss: 0.2106
en_de Dev loss: 0.8858 r:0.2128
en_zh Dev loss: 0.7665 r:0.4817
Current avg r:0.3472 Best avg r: 0.3794
20:27:50,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:16,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:28:42,133 root INFO Epoch 10 Global steps: 30600 Train loss: 0.1911
en_de Dev loss: 0.8919 r:0.2061
en_zh Dev loss: 0.7645 r:0.4768
Current avg r:0.3414 Best avg r: 0.3794
20:29:59,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:25,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:51,181 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1853
en_de Dev loss: 0.8994 r:0.2121
en_zh Dev loss: 0.7630 r:0.4806
Current avg r:0.3463 Best avg r: 0.3794
20:32:08,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:34,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:00,217 root INFO Epoch 10 Global steps: 31000 Train loss: 0.1976
en_de Dev loss: 0.9161 r:0.2157
en_zh Dev loss: 0.7869 r:0.4906
Current avg r:0.3531 Best avg r: 0.3794
20:34:17,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:43,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:09,221 root INFO Epoch 10 Global steps: 31200 Train loss: 0.1876
en_de Dev loss: 0.9128 r:0.2165
en_zh Dev loss: 0.7867 r:0.4864
Current avg r:0.3515 Best avg r: 0.3794
20:36:26,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:52,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:18,330 root INFO Epoch 10 Global steps: 31400 Train loss: 0.2078
en_de Dev loss: 0.9031 r:0.2121
en_zh Dev loss: 0.7963 r:0.4900
Current avg r:0.3510 Best avg r: 0.3794
20:38:35,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:01,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:27,539 root INFO Epoch 10 Global steps: 31600 Train loss: 0.1785
en_de Dev loss: 0.8932 r:0.2048
en_zh Dev loss: 0.7694 r:0.4913
Current avg r:0.3481 Best avg r: 0.3794
20:40:44,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:10,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:36,692 root INFO Epoch 10 Global steps: 31800 Train loss: 0.1985
en_de Dev loss: 0.9313 r:0.1834
en_zh Dev loss: 0.7801 r:0.4944
Current avg r:0.3389 Best avg r: 0.3794
20:42:53,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:19,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:45,789 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1734
en_de Dev loss: 0.9386 r:0.1966
en_zh Dev loss: 0.8074 r:0.4908
Current avg r:0.3437 Best avg r: 0.3794
20:45:02,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:28,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:54,844 root INFO Epoch 10 Global steps: 32200 Train loss: 0.1857
en_de Dev loss: 0.8942 r:0.1965
en_zh Dev loss: 0.7567 r:0.4881
Current avg r:0.3423 Best avg r: 0.3794
20:47:11,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:37,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:03,816 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1925
en_de Dev loss: 0.9155 r:0.1977
en_zh Dev loss: 0.7483 r:0.4983
Current avg r:0.3480 Best avg r: 0.3794
20:49:20,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:46,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:12,779 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1942
en_de Dev loss: 0.8946 r:0.2133
en_zh Dev loss: 0.7701 r:0.4916
Current avg r:0.3524 Best avg r: 0.3794
20:51:29,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:55,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:21,739 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1949
en_de Dev loss: 0.9050 r:0.1990
en_zh Dev loss: 0.8307 r:0.4850
Current avg r:0.3420 Best avg r: 0.3794
20:53:38,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:04,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:30,657 root INFO Epoch 10 Global steps: 33000 Train loss: 0.1989
en_de Dev loss: 0.9157 r:0.1889
en_zh Dev loss: 0.7948 r:0.4918
Current avg r:0.3403 Best avg r: 0.3794
20:55:48,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:14,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:39,913 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1924
en_de Dev loss: 0.9265 r:0.1779
en_zh Dev loss: 0.8196 r:0.4905
Current avg r:0.3342 Best avg r: 0.3794
20:57:56,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:22,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:48,697 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1732
en_de Dev loss: 0.9427 r:0.1849
en_zh Dev loss: 0.8014 r:0.4963
Current avg r:0.3406 Best avg r: 0.3794
21:00:05,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:31,688 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:57,618 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1551
en_de Dev loss: 0.9316 r:0.1864
en_zh Dev loss: 0.7712 r:0.4975
Current avg r:0.3420 Best avg r: 0.3794
21:02:14,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:40,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:06,549 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1708
en_de Dev loss: 0.9249 r:0.1929
en_zh Dev loss: 0.7317 r:0.5076
Current avg r:0.3503 Best avg r: 0.3794
21:04:23,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:49,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:15,333 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1742
en_de Dev loss: 0.9007 r:0.1955
en_zh Dev loss: 0.7282 r:0.5009
Current avg r:0.3482 Best avg r: 0.3794
21:06:32,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:58,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:24,160 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1817
en_de Dev loss: 0.8824 r:0.2039
en_zh Dev loss: 0.7276 r:0.4935
Current avg r:0.3487 Best avg r: 0.3794
21:08:41,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:07,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:32,974 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1572
en_de Dev loss: 0.8867 r:0.1930
en_zh Dev loss: 0.7419 r:0.4900
Current avg r:0.3415 Best avg r: 0.3794
21:10:49,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:15,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:41,654 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1765
en_de Dev loss: 0.9017 r:0.1825
en_zh Dev loss: 0.7537 r:0.4866
Current avg r:0.3346 Best avg r: 0.3794
21:12:58,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:24,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:50,459 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1727
en_de Dev loss: 0.9609 r:0.1835
en_zh Dev loss: 0.8318 r:0.4761
Current avg r:0.3298 Best avg r: 0.3794
21:15:07,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:33,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:59,453 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1710
en_de Dev loss: 0.9305 r:0.1877
en_zh Dev loss: 0.7809 r:0.4912
Current avg r:0.3394 Best avg r: 0.3794
21:17:16,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:42,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:08,517 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1584
en_de Dev loss: 0.9118 r:0.2075
en_zh Dev loss: 0.8030 r:0.4822
Current avg r:0.3448 Best avg r: 0.3794
21:19:25,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:51,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:17,476 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1757
en_de Dev loss: 0.9142 r:0.1958
en_zh Dev loss: 0.7720 r:0.4857
Current avg r:0.3407 Best avg r: 0.3794
21:21:34,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:00,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:26,532 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1777
en_de Dev loss: 0.9188 r:0.1862
en_zh Dev loss: 0.7793 r:0.4883
Current avg r:0.3373 Best avg r: 0.3794
21:23:43,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:09,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:35,587 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1696
en_de Dev loss: 0.9483 r:0.1686
en_zh Dev loss: 0.7795 r:0.4914
Current avg r:0.3300 Best avg r: 0.3794
21:25:52,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:26:18,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:44,654 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1693
en_de Dev loss: 0.9314 r:0.1949
en_zh Dev loss: 0.8706 r:0.4724
Current avg r:0.3336 Best avg r: 0.3794
21:28:02,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:28,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:28:54,15 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1452
en_de Dev loss: 0.9105 r:0.1918
en_zh Dev loss: 0.8014 r:0.4868
Current avg r:0.3393 Best avg r: 0.3794
21:30:11,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:37,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:03,35 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1605
en_de Dev loss: 0.9244 r:0.2001
en_zh Dev loss: 0.8531 r:0.4861
Current avg r:0.3431 Best avg r: 0.3794
21:32:20,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:46,187 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:12,142 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1605
en_de Dev loss: 0.9381 r:0.1921
en_zh Dev loss: 0.7997 r:0.4903
Current avg r:0.3412 Best avg r: 0.3794
21:34:29,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:55,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:21,222 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1600
en_de Dev loss: 0.8927 r:0.2004
en_zh Dev loss: 0.7276 r:0.4907
Current avg r:0.3456 Best avg r: 0.3794
21:36:38,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:04,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:30,367 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1656
en_de Dev loss: 0.8931 r:0.2023
en_zh Dev loss: 0.7271 r:0.4877
Current avg r:0.3450 Best avg r: 0.3794
21:38:47,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:13,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:39,515 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1696
en_de Dev loss: 0.9057 r:0.2088
en_zh Dev loss: 0.7624 r:0.4809
Current avg r:0.3449 Best avg r: 0.3794
21:40:56,709 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:22,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:48,604 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1635
en_de Dev loss: 0.9213 r:0.2077
en_zh Dev loss: 0.8326 r:0.4704
Current avg r:0.3390 Best avg r: 0.3794
21:43:05,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:31,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:57,682 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1574
en_de Dev loss: 0.9174 r:0.1973
en_zh Dev loss: 0.7777 r:0.4820
Current avg r:0.3397 Best avg r: 0.3794
21:45:14,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:40,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:06,857 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1407
en_de Dev loss: 0.9063 r:0.1963
en_zh Dev loss: 0.7809 r:0.4830
Current avg r:0.3396 Best avg r: 0.3794
21:47:24,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:49,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:15,926 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1673
en_de Dev loss: 0.8926 r:0.1885
en_zh Dev loss: 0.7621 r:0.4765
Current avg r:0.3325 Best avg r: 0.3794
21:49:33,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:59,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:50:25,10 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1583
en_de Dev loss: 0.9016 r:0.1887
en_zh Dev loss: 0.7349 r:0.4916
Current avg r:0.3401 Best avg r: 0.3794
21:51:42,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:08,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:34,79 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1618
en_de Dev loss: 0.9291 r:0.1999
en_zh Dev loss: 0.7642 r:0.4938
Current avg r:0.3469 Best avg r: 0.3794
21:53:51,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:17,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:43,77 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1487
en_de Dev loss: 0.9297 r:0.1878
en_zh Dev loss: 0.7483 r:0.4993
Current avg r:0.3436 Best avg r: 0.3794
21:56:00,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:56:26,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:52,67 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1416
en_de Dev loss: 0.9588 r:0.1809
en_zh Dev loss: 0.7912 r:0.5007
Current avg r:0.3408 Best avg r: 0.3794
21:58:09,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:35,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:01,109 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1584
en_de Dev loss: 0.9385 r:0.1799
en_zh Dev loss: 0.7445 r:0.4983
Current avg r:0.3391 Best avg r: 0.3794
22:00:18,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:44,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:10,616 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1407
en_de Dev loss: 0.9507 r:0.1913
en_zh Dev loss: 0.7807 r:0.4944
Current avg r:0.3428 Best avg r: 0.3794
22:02:27,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:53,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:19,757 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1533
en_de Dev loss: 0.9275 r:0.1923
en_zh Dev loss: 0.7572 r:0.4942
Current avg r:0.3433 Best avg r: 0.3794
22:04:36,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:02,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:28,842 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1516
en_de Dev loss: 0.9429 r:0.1760
en_zh Dev loss: 0.8080 r:0.4951
Current avg r:0.3355 Best avg r: 0.3794
22:06:46,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:07:12,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:38,18 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1507
en_de Dev loss: 0.9477 r:0.1669
en_zh Dev loss: 0.7811 r:0.4878
Current avg r:0.3273 Best avg r: 0.3794
22:08:55,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:21,250 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:47,217 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1439
en_de Dev loss: 0.9527 r:0.1616
en_zh Dev loss: 0.8368 r:0.4801
Current avg r:0.3208 Best avg r: 0.3794
22:11:04,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:30,408 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:56,360 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1387
en_de Dev loss: 0.9725 r:0.1523
en_zh Dev loss: 0.7812 r:0.4905
Current avg r:0.3214 Best avg r: 0.3794
22:13:13,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:39,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:05,483 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1484
en_de Dev loss: 0.9668 r:0.1571
en_zh Dev loss: 0.7588 r:0.4879
Current avg r:0.3225 Best avg r: 0.3794
22:15:22,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:48,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:16:14,588 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1409
en_de Dev loss: 0.9806 r:0.1710
en_zh Dev loss: 0.8026 r:0.4885
Current avg r:0.3297 Best avg r: 0.3794
22:17:31,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:57,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:23,643 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1402
en_de Dev loss: 0.9398 r:0.1746
en_zh Dev loss: 0.8300 r:0.4731
Current avg r:0.3238 Best avg r: 0.3794
22:19:40,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:06,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:32,693 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1469
en_de Dev loss: 0.9446 r:0.1667
en_zh Dev loss: 0.7886 r:0.4857
Current avg r:0.3262 Best avg r: 0.3794
22:21:49,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:15,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:41,744 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1437
en_de Dev loss: 0.9270 r:0.1794
en_zh Dev loss: 0.7665 r:0.4832
Current avg r:0.3313 Best avg r: 0.3794
22:23:58,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:24,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:50,869 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1425
en_de Dev loss: 0.9396 r:0.1750
en_zh Dev loss: 0.7972 r:0.4763
Current avg r:0.3257 Best avg r: 0.3794
22:26:07,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:26:33,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:59,853 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1394
en_de Dev loss: 0.9558 r:0.1817
en_zh Dev loss: 0.8571 r:0.4725
Current avg r:0.3271 Best avg r: 0.3794
22:28:16,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:42,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:08,811 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1346
en_de Dev loss: 0.9269 r:0.1837
en_zh Dev loss: 0.7850 r:0.4794
Current avg r:0.3316 Best avg r: 0.3794
22:30:25,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:51,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:17,846 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1412
en_de Dev loss: 0.9243 r:0.1774
en_zh Dev loss: 0.7557 r:0.4908
Current avg r:0.3341 Best avg r: 0.3794
22:32:35,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:01,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:33:27,384 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1452
en_de Dev loss: 0.9432 r:0.1688
en_zh Dev loss: 0.7504 r:0.4905
Current avg r:0.3297 Best avg r: 0.3794
22:34:44,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:10,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:36,443 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1534
en_de Dev loss: 0.9428 r:0.1673
en_zh Dev loss: 0.7429 r:0.4915
Current avg r:0.3294 Best avg r: 0.3794
22:36:53,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:19,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:45,517 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1320
en_de Dev loss: 0.9267 r:0.1749
en_zh Dev loss: 0.7550 r:0.4842
Current avg r:0.3295 Best avg r: 0.3794
22:39:02,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:39:28,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:54,668 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1408
en_de Dev loss: 0.9304 r:0.1691
en_zh Dev loss: 0.7508 r:0.4800
Current avg r:0.3245 Best avg r: 0.3794
22:41:11,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:37,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:03,838 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1334
en_de Dev loss: 0.9539 r:0.1752
en_zh Dev loss: 0.8015 r:0.4757
Current avg r:0.3255 Best avg r: 0.3794
22:43:20,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:46,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:12,926 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1401
en_de Dev loss: 0.9611 r:0.1743
en_zh Dev loss: 0.7914 r:0.4791
Current avg r:0.3267 Best avg r: 0.3794
22:45:30,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:45:56,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:22,87 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1246
en_de Dev loss: 0.9425 r:0.1685
en_zh Dev loss: 0.7985 r:0.4711
Current avg r:0.3198 Best avg r: 0.3794
22:47:39,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:05,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:48:31,107 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1357
en_de Dev loss: 0.9824 r:0.1872
en_zh Dev loss: 0.8646 r:0.4738
Current avg r:0.3305 Best avg r: 0.3794
22:49:48,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:14,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:40,86 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1382
en_de Dev loss: 0.9457 r:0.1682
en_zh Dev loss: 0.7831 r:0.4726
Current avg r:0.3204 Best avg r: 0.3794
22:51:57,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:23,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:49,161 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1226
en_de Dev loss: 0.9482 r:0.1913
en_zh Dev loss: 0.7581 r:0.4846
Current avg r:0.3380 Best avg r: 0.3794
22:54:06,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:54:32,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:58,336 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1403
en_de Dev loss: 0.9619 r:0.1892
en_zh Dev loss: 0.8080 r:0.4763
Current avg r:0.3327 Best avg r: 0.3794
22:56:15,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:41,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:07,403 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1200
en_de Dev loss: 0.9281 r:0.2009
en_zh Dev loss: 0.7616 r:0.4799
Current avg r:0.3404 Best avg r: 0.3794
22:58:24,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:50,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:16,393 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1332
en_de Dev loss: 0.9144 r:0.1971
en_zh Dev loss: 0.7490 r:0.4802
Current avg r:0.3387 Best avg r: 0.3794
23:00:33,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:00:59,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:25,516 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1357
en_de Dev loss: 0.9306 r:0.1876
en_zh Dev loss: 0.7563 r:0.4903
Current avg r:0.3389 Best avg r: 0.3794
23:02:42,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:08,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:34,612 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1238
en_de Dev loss: 0.9329 r:0.1853
en_zh Dev loss: 0.7841 r:0.4729
Current avg r:0.3291 Best avg r: 0.3794
23:04:52,28 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:17,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:43,919 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1268
en_de Dev loss: 0.9440 r:0.1888
en_zh Dev loss: 0.7815 r:0.4850
Current avg r:0.3369 Best avg r: 0.3794
23:07:01,5 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:26,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:52,917 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1251
en_de Dev loss: 0.9362 r:0.1910
en_zh Dev loss: 0.7611 r:0.4879
Current avg r:0.3395 Best avg r: 0.3794
23:09:10,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:09:35,975 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:01,934 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1254
en_de Dev loss: 0.9422 r:0.1838
en_zh Dev loss: 0.7985 r:0.4807
Current avg r:0.3323 Best avg r: 0.3794
23:11:19,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:44,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:10,920 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1231
en_de Dev loss: 0.9655 r:0.1668
en_zh Dev loss: 0.7695 r:0.4907
Current avg r:0.3287 Best avg r: 0.3794
23:13:27,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:53,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:19,869 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1148
en_de Dev loss: 0.9471 r:0.1625
en_zh Dev loss: 0.7553 r:0.4899
Current avg r:0.3262 Best avg r: 0.3794
23:15:37,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:02,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:28,909 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1211
en_de Dev loss: 0.9273 r:0.1672
en_zh Dev loss: 0.7268 r:0.4866
Current avg r:0.3269 Best avg r: 0.3794
23:17:45,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:11,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:37,875 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1157
en_de Dev loss: 0.9385 r:0.1671
en_zh Dev loss: 0.7515 r:0.4857
Current avg r:0.3264 Best avg r: 0.3794
23:19:54,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:20,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:46,763 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1170
en_de Dev loss: 0.9539 r:0.1893
en_zh Dev loss: 0.7728 r:0.4893
Current avg r:0.3393 Best avg r: 0.3794
23:22:03,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:29,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:55,752 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1172
en_de Dev loss: 0.9486 r:0.1828
en_zh Dev loss: 0.7765 r:0.4801
Current avg r:0.3315 Best avg r: 0.3794
23:24:12,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:38,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:04,715 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1267
en_de Dev loss: 0.9456 r:0.1758
en_zh Dev loss: 0.7885 r:0.4881
Current avg r:0.3320 Best avg r: 0.3794
23:26:21,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:47,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:13,617 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1206
en_de Dev loss: 0.9405 r:0.1826
en_zh Dev loss: 0.7740 r:0.4852
Current avg r:0.3339 Best avg r: 0.3794
23:28:30,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:56,562 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:22,510 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1162
en_de Dev loss: 0.9613 r:0.1813
en_zh Dev loss: 0.8052 r:0.4758
Current avg r:0.3286 Best avg r: 0.3794
23:30:39,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:05,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:31,647 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1338
en_de Dev loss: 0.9245 r:0.1899
en_zh Dev loss: 0.7578 r:0.4861
Current avg r:0.3380 Best avg r: 0.3794
23:32:48,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:14,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:40,682 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1239
en_de Dev loss: 0.9396 r:0.1782
en_zh Dev loss: 0.7521 r:0.4792
Current avg r:0.3287 Best avg r: 0.3794
23:34:57,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:23,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:49,695 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1314
en_de Dev loss: 0.9608 r:0.1783
en_zh Dev loss: 0.7811 r:0.4803
Current avg r:0.3293 Best avg r: 0.3794
23:37:07,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:33,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:59,119 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1170
en_de Dev loss: 0.9323 r:0.1849
en_zh Dev loss: 0.7358 r:0.4928
Current avg r:0.3388 Best avg r: 0.3794
23:39:16,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:42,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:08,18 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1101
en_de Dev loss: 0.9422 r:0.1774
en_zh Dev loss: 0.7394 r:0.4950
Current avg r:0.3362 Best avg r: 0.3794
23:41:24,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:50,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:16,758 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1102
en_de Dev loss: 0.9854 r:0.1762
en_zh Dev loss: 0.8751 r:0.4817
Current avg r:0.3289 Best avg r: 0.3794
23:43:33,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:59,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:25,504 root INFO Epoch 16 Global steps: 48800 Train loss: 0.1243
en_de Dev loss: 0.9377 r:0.1835
en_zh Dev loss: 0.8025 r:0.4820
Current avg r:0.3328 Best avg r: 0.3794
23:45:42,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:08,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:34,288 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1117
en_de Dev loss: 0.9165 r:0.1814
en_zh Dev loss: 0.7174 r:0.5016
Current avg r:0.3415 Best avg r: 0.3794
23:47:51,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:17,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:43,21 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1076
en_de Dev loss: 0.9290 r:0.1766
en_zh Dev loss: 0.7396 r:0.4967
Current avg r:0.3366 Best avg r: 0.3794
23:49:59,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:25,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:51,678 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1205
en_de Dev loss: 0.9552 r:0.1732
en_zh Dev loss: 0.7279 r:0.5030
Current avg r:0.3381 Best avg r: 0.3794
23:52:08,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:34,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:00,393 root INFO Epoch 16 Global steps: 49600 Train loss: 0.1169
en_de Dev loss: 0.9523 r:0.1806
en_zh Dev loss: 0.7560 r:0.5010
Current avg r:0.3408 Best avg r: 0.3794
23:54:17,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:43,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:09,40 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1108
en_de Dev loss: 0.9462 r:0.1724
en_zh Dev loss: 0.7316 r:0.4973
Current avg r:0.3348 Best avg r: 0.3794
00:34:25,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:51,216 root INFO 
id:en_de cur r: 0.0191 best r: 0.0191
00:35:16,802 root INFO 
id:en_zh cur r: 0.0282 best r: 0.0282
00:35:16,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:42,384 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
00:35:42,394 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
00:36:08,5 root INFO Epoch 0 Global steps: 200 Train loss: 0.7647
en_de Dev loss: 0.8874 r:-0.0040
en_zh Dev loss: 0.8181 r:0.0759
Current avg r:0.0360 Best avg r: 0.0360
00:37:23,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:48,982 root INFO 
id:en_de cur r: 0.0203 best r: 0.0203
00:38:14,565 root INFO 
id:en_zh cur r: 0.0860 best r: 0.0860
00:38:14,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:40,138 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
00:38:40,144 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
00:39:05,735 root INFO Epoch 0 Global steps: 400 Train loss: 0.8448
en_de Dev loss: 0.8869 r:0.0169
en_zh Dev loss: 0.8177 r:0.1612
Current avg r:0.0891 Best avg r: 0.0891
00:40:21,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:46,793 root INFO 
id:en_de cur r: 0.0336 best r: 0.0336
00:41:12,364 root INFO 
id:en_zh cur r: 0.1045 best r: 0.1045
00:41:12,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:37,950 root INFO Epoch 0 Global steps: 600 Train loss: 0.7578
en_de Dev loss: 0.8870 r:0.0135
en_zh Dev loss: 0.8197 r:0.0975
Current avg r:0.0555 Best avg r: 0.0891
00:42:56,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:34,462 root INFO 
id:en_zh cur r: 0.1463 best r: 0.1463
00:43:34,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:00,19 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
00:44:00,29 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
00:44:25,608 root INFO Epoch 0 Global steps: 800 Train loss: 0.8337
en_de Dev loss: 0.8869 r:0.0183
en_zh Dev loss: 0.8174 r:0.1835
Current avg r:0.1009 Best avg r: 0.1009
00:45:41,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:06,799 root INFO 
id:en_de cur r: 0.0415 best r: 0.0415
00:46:19,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:45,234 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
00:46:45,239 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
00:47:10,833 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7750
en_de Dev loss: 0.8865 r:0.0399
en_zh Dev loss: 0.8169 r:0.2048
Current avg r:0.1224 Best avg r: 0.1224
00:48:26,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:51,705 root INFO 
id:en_de cur r: 0.0444 best r: 0.0444
00:49:17,315 root INFO 
id:en_zh cur r: 0.1874 best r: 0.1874
00:49:17,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:42,898 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
00:49:42,906 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
00:50:08,510 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7448
en_de Dev loss: 0.8863 r:0.0574
en_zh Dev loss: 0.8159 r:0.2792
Current avg r:0.1683 Best avg r: 0.1683
00:51:23,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:02,147 root INFO 
id:en_zh cur r: 0.2296 best r: 0.2296
00:52:02,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:27,728 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
00:52:27,736 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
00:52:53,336 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7341
en_de Dev loss: 0.8850 r:0.1030
en_zh Dev loss: 0.8091 r:0.2386
Current avg r:0.1708 Best avg r: 0.1708
00:54:08,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:54:34,212 root INFO 
id:en_de cur r: 0.1132 best r: 0.1132
00:54:59,794 root INFO 
id:en_zh cur r: 0.2923 best r: 0.2923
00:54:59,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:25,379 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
00:55:25,387 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
00:55:50,995 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7571
en_de Dev loss: 0.8833 r:0.1284
en_zh Dev loss: 0.7998 r:0.2911
Current avg r:0.2098 Best avg r: 0.2098
00:57:06,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:44,591 root INFO 
id:en_zh cur r: 0.2983 best r: 0.2983
00:57:44,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:10,142 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
00:58:10,152 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
00:58:35,720 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7420
en_de Dev loss: 0.8820 r:0.1239
en_zh Dev loss: 0.7875 r:0.2993
Current avg r:0.2116 Best avg r: 0.2116
00:59:50,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:29,317 root INFO 
id:en_zh cur r: 0.3040 best r: 0.3040
01:00:29,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:00:54,870 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
01:00:54,876 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
01:01:20,450 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7356
en_de Dev loss: 0.8782 r:0.1286
en_zh Dev loss: 0.7913 r:0.2966
Current avg r:0.2126 Best avg r: 0.2126
01:02:35,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:01,306 root INFO 
id:en_de cur r: 0.1189 best r: 0.1189
01:03:26,864 root INFO 
id:en_zh cur r: 0.3409 best r: 0.3409
01:03:26,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:52,426 root INFO Epoch 0 Global steps: 2200 Train loss: 0.8076
en_de Dev loss: 0.8736 r:0.1245
en_zh Dev loss: 0.7879 r:0.2962
Current avg r:0.2104 Best avg r: 0.2126
01:05:07,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:33,248 root INFO 
id:en_de cur r: 0.1303 best r: 0.1303
01:05:58,788 root INFO 
id:en_zh cur r: 0.3671 best r: 0.3671
01:05:58,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:24,327 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
01:06:24,335 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
01:06:49,898 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6897
en_de Dev loss: 0.8916 r:0.1427
en_zh Dev loss: 0.8009 r:0.3620
Current avg r:0.2524 Best avg r: 0.2524
01:08:05,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:43,391 root INFO 
id:en_zh cur r: 0.3877 best r: 0.3877
01:08:43,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:09:08,931 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
01:09:08,937 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
01:09:34,505 root INFO Epoch 0 Global steps: 2600 Train loss: 0.7052
en_de Dev loss: 0.8821 r:0.1347
en_zh Dev loss: 0.7944 r:0.3740
Current avg r:0.2543 Best avg r: 0.2543
01:10:49,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:15,242 root INFO 
id:en_de cur r: 0.1523 best r: 0.1523
01:11:40,786 root INFO 
id:en_zh cur r: 0.4059 best r: 0.4059
01:11:40,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:06,328 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
01:12:06,334 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
01:12:31,907 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7724
en_de Dev loss: 0.8926 r:0.1642
en_zh Dev loss: 0.7994 r:0.3884
Current avg r:0.2763 Best avg r: 0.2763
01:13:47,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:12,639 root INFO 
id:en_de cur r: 0.1803 best r: 0.1803
01:14:25,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:50,949 root INFO Epoch 0 Global steps: 3000 Train loss: 0.5805
en_de Dev loss: 0.8611 r:0.1857
en_zh Dev loss: 0.7703 r:0.3157
Current avg r:0.2507 Best avg r: 0.2763
01:16:06,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:44,714 root INFO 
id:en_zh cur r: 0.4099 best r: 0.4099
01:16:44,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:10,289 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
01:17:10,294 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
01:17:35,884 root INFO Epoch 1 Global steps: 3200 Train loss: 0.7008
en_de Dev loss: 0.8590 r:0.1846
en_zh Dev loss: 0.7079 r:0.4062
Current avg r:0.2954 Best avg r: 0.2954
01:18:51,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:16,809 root INFO 
id:en_de cur r: 0.1949 best r: 0.1949
01:19:42,351 root INFO 
id:en_zh cur r: 0.4348 best r: 0.4348
01:19:42,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:20:07,901 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
01:20:07,909 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
01:20:33,462 root INFO Epoch 1 Global steps: 3400 Train loss: 0.6107
en_de Dev loss: 0.8781 r:0.1835
en_zh Dev loss: 0.6773 r:0.4318
Current avg r:0.3077 Best avg r: 0.3077
09:53:20,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:46,747 root INFO 
id:en_de cur r: 0.0295 best r: 0.0295
09:53:59,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:54:26,67 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
09:54:26,107 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
09:54:52,392 root INFO Epoch 0 Global steps: 200 Train loss: 0.8041
en_de Dev loss: 0.8873 r:0.0254
en_zh Dev loss: 0.8185 r:0.0925
Current avg r:0.0590 Best avg r: 0.0590
09:56:09,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:35,900 root INFO 
id:en_de cur r: 0.0387 best r: 0.0387
09:57:02,120 root INFO 
id:en_zh cur r: 0.0754 best r: 0.0754
09:57:02,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:28,351 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
09:57:28,358 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
09:57:54,664 root INFO Epoch 0 Global steps: 400 Train loss: 0.7154
en_de Dev loss: 0.8878 r:0.0540
en_zh Dev loss: 0.8171 r:0.1763
Current avg r:0.1152 Best avg r: 0.1152
09:59:11,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:59:38,300 root INFO 
id:en_de cur r: 0.0676 best r: 0.0676
10:00:04,568 root INFO 
id:en_zh cur r: 0.1863 best r: 0.1863
10:00:04,568 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:30,810 root INFO Epoch 0 Global steps: 600 Train loss: 0.6643
en_de Dev loss: 0.8897 r:0.0282
en_zh Dev loss: 0.8152 r:0.1892
Current avg r:0.1087 Best avg r: 0.1152
10:01:48,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:14,417 root INFO 
id:en_de cur r: 0.0713 best r: 0.0713
10:02:40,690 root INFO 
id:en_zh cur r: 0.2282 best r: 0.2282
10:02:40,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:06,917 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:03:06,928 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:03:33,203 root INFO Epoch 0 Global steps: 800 Train loss: 0.8025
en_de Dev loss: 0.8849 r:0.0828
en_zh Dev loss: 0.8100 r:0.2528
Current avg r:0.1678 Best avg r: 0.1678
10:04:50,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:29,829 root INFO 
id:en_zh cur r: 0.2512 best r: 0.2512
10:05:29,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:56,92 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:05:56,109 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:06:22,395 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8041
en_de Dev loss: 0.8834 r:0.0975
en_zh Dev loss: 0.8058 r:0.2682
Current avg r:0.1828 Best avg r: 0.1828
10:07:39,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:05,804 root INFO 
id:en_de cur r: 0.1110 best r: 0.1110
10:08:32,16 root INFO 
id:en_zh cur r: 0.2831 best r: 0.2831
10:08:32,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:08:58,193 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7483
en_de Dev loss: 0.8845 r:0.0764
en_zh Dev loss: 0.8042 r:0.2621
Current avg r:0.1692 Best avg r: 0.1828
10:10:15,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:54,513 root INFO 
id:en_zh cur r: 0.3073 best r: 0.3073
10:10:54,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:20,738 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:11:20,803 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:11:47,71 root INFO Epoch 0 Global steps: 1400 Train loss: 0.6921
en_de Dev loss: 0.8901 r:0.0880
en_zh Dev loss: 0.8082 r:0.2794
Current avg r:0.1837 Best avg r: 0.1837
10:13:04,242 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:30,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:13:56,735 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:13:56,762 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:14:23,73 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7488
en_de Dev loss: 0.8834 r:0.0959
en_zh Dev loss: 0.7986 r:0.2870
Current avg r:0.1915 Best avg r: 0.1915
10:15:40,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:06,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:16:32,835 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:16:32,843 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:16:59,113 root INFO Epoch 0 Global steps: 1800 Train loss: 0.8157
en_de Dev loss: 0.8777 r:0.1143
en_zh Dev loss: 0.7840 r:0.2923
Current avg r:0.2033 Best avg r: 0.2033
10:18:16,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:55,664 root INFO 
id:en_zh cur r: 0.3106 best r: 0.3106
10:18:55,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:21,899 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:19:21,906 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:19:48,165 root INFO Epoch 0 Global steps: 2000 Train loss: 0.8427
en_de Dev loss: 0.8840 r:0.1319
en_zh Dev loss: 0.7810 r:0.3049
Current avg r:0.2184 Best avg r: 0.2184
10:21:05,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:31,612 root INFO 
id:en_de cur r: 0.1390 best r: 0.1390
10:21:57,850 root INFO 
id:en_zh cur r: 0.3701 best r: 0.3701
10:21:57,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:24,99 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:22:24,108 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:22:50,400 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7587
en_de Dev loss: 0.8761 r:0.1292
en_zh Dev loss: 0.7437 r:0.3671
Current avg r:0.2481 Best avg r: 0.2481
10:24:07,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:33,844 root INFO 
id:en_de cur r: 0.1554 best r: 0.1554
10:25:00,96 root INFO 
id:en_zh cur r: 0.3900 best r: 0.3900
10:25:00,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:25:26,325 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:25:26,333 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:25:52,590 root INFO Epoch 0 Global steps: 2400 Train loss: 0.8056
en_de Dev loss: 0.8694 r:0.1456
en_zh Dev loss: 0.7133 r:0.3948
Current avg r:0.2702 Best avg r: 0.2702
10:27:09,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:36,50 root INFO 
id:en_de cur r: 0.1585 best r: 0.1585
10:28:02,301 root INFO 
id:en_zh cur r: 0.4089 best r: 0.4089
10:28:02,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:28:28,557 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:28:28,566 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:28:54,854 root INFO Epoch 0 Global steps: 2600 Train loss: 0.6477
en_de Dev loss: 0.8854 r:0.1529
en_zh Dev loss: 0.7472 r:0.4104
Current avg r:0.2817 Best avg r: 0.2817
10:30:12,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:30:38,346 root INFO 
id:en_de cur r: 0.1611 best r: 0.1611
10:30:51,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:31:17,697 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:31:17,735 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:31:44,60 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7104
en_de Dev loss: 0.8639 r:0.1724
en_zh Dev loss: 0.7139 r:0.3926
Current avg r:0.2825 Best avg r: 0.2825
10:33:01,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:33:27,532 root INFO 
id:en_de cur r: 0.1870 best r: 0.1870
10:33:40,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:34:06,876 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:34:06,885 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:34:33,169 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6488
en_de Dev loss: 0.8607 r:0.1775
en_zh Dev loss: 0.7142 r:0.3881
Current avg r:0.2828 Best avg r: 0.2828
10:35:50,791 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:36:17,117 root INFO 
id:en_de cur r: 0.1956 best r: 0.1956
10:36:30,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:36:56,502 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:36:56,510 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:37:22,791 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6699
en_de Dev loss: 0.8680 r:0.1926
en_zh Dev loss: 0.8047 r:0.4087
Current avg r:0.3007 Best avg r: 0.3007
10:38:40,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:39:06,283 root INFO 
id:en_de cur r: 0.2179 best r: 0.2179
10:39:32,522 root INFO 
id:en_zh cur r: 0.4171 best r: 0.4171
10:39:32,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:39:58,767 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:39:58,776 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:40:25,55 root INFO Epoch 1 Global steps: 3400 Train loss: 0.5576
en_de Dev loss: 0.8509 r:0.2037
en_zh Dev loss: 0.7542 r:0.4214
Current avg r:0.3126 Best avg r: 0.3126
10:41:42,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:42:21,699 root INFO 
id:en_zh cur r: 0.4262 best r: 0.4262
10:42:21,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:42:47,952 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:42:47,960 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:43:14,241 root INFO Epoch 1 Global steps: 3600 Train loss: 0.6168
en_de Dev loss: 0.8621 r:0.2172
en_zh Dev loss: 0.8457 r:0.4278
Current avg r:0.3225 Best avg r: 0.3225
10:44:31,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:44:57,668 root INFO 
id:en_de cur r: 0.2198 best r: 0.2198
10:45:23,893 root INFO 
id:en_zh cur r: 0.4424 best r: 0.4424
10:45:23,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:45:50,136 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:45:50,144 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:46:16,404 root INFO Epoch 1 Global steps: 3800 Train loss: 0.7711
en_de Dev loss: 0.8534 r:0.2148
en_zh Dev loss: 0.6839 r:0.4436
Current avg r:0.3292 Best avg r: 0.3292
10:47:33,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:47:59,937 root INFO 
id:en_de cur r: 0.2218 best r: 0.2218
10:48:26,191 root INFO 
id:en_zh cur r: 0.4553 best r: 0.4553
10:48:26,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:48:52,445 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:48:52,457 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:49:18,730 root INFO Epoch 1 Global steps: 4000 Train loss: 0.6352
en_de Dev loss: 0.8611 r:0.2171
en_zh Dev loss: 0.7020 r:0.4555
Current avg r:0.3363 Best avg r: 0.3363
10:50:35,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:51:02,121 root INFO 
id:en_de cur r: 0.2246 best r: 0.2246
10:51:15,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:51:41,406 root INFO Epoch 1 Global steps: 4200 Train loss: 0.6770
en_de Dev loss: 0.8786 r:0.2146
en_zh Dev loss: 0.8653 r:0.4330
Current avg r:0.3238 Best avg r: 0.3363
10:52:58,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:53:24,740 root INFO 
id:en_de cur r: 0.2304 best r: 0.2304
10:53:37,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:54:04,95 root INFO Epoch 1 Global steps: 4400 Train loss: 0.6900
en_de Dev loss: 0.8697 r:0.2182
en_zh Dev loss: 0.7876 r:0.4447
Current avg r:0.3315 Best avg r: 0.3363
10:55:21,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:55:47,660 root INFO 
id:en_de cur r: 0.2318 best r: 0.2318
10:56:13,929 root INFO 
id:en_zh cur r: 0.4714 best r: 0.4714
10:56:13,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:56:40,182 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:56:40,192 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:57:06,499 root INFO Epoch 1 Global steps: 4600 Train loss: 0.6356
en_de Dev loss: 0.8762 r:0.2191
en_zh Dev loss: 0.6624 r:0.4709
Current avg r:0.3450 Best avg r: 0.3450
10:58:23,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:58:49,913 root INFO 
id:en_de cur r: 0.2373 best r: 0.2373
10:59:03,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:59:29,188 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
10:59:29,196 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
10:59:55,433 root INFO Epoch 1 Global steps: 4800 Train loss: 0.6438
en_de Dev loss: 0.8551 r:0.2298
en_zh Dev loss: 0.6824 r:0.4737
Current avg r:0.3517 Best avg r: 0.3517
11:01:12,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:01:38,747 root INFO 
id:en_de cur r: 0.2456 best r: 0.2456
11:02:04,974 root INFO 
id:en_zh cur r: 0.4719 best r: 0.4719
11:02:04,975 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:02:31,212 root INFO Epoch 1 Global steps: 5000 Train loss: 0.5645
en_de Dev loss: 0.8698 r:0.2284
en_zh Dev loss: 0.6896 r:0.4731
Current avg r:0.3508 Best avg r: 0.3517
11:03:48,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:04:14,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:04:40,952 root INFO Epoch 1 Global steps: 5200 Train loss: 0.6410
en_de Dev loss: 0.8653 r:0.2244
en_zh Dev loss: 0.6775 r:0.4647
Current avg r:0.3445 Best avg r: 0.3517
11:05:58,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:06:24,510 root INFO 
id:en_de cur r: 0.2458 best r: 0.2458
11:06:37,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:07:03,877 root INFO Epoch 1 Global steps: 5400 Train loss: 0.5757
en_de Dev loss: 0.8525 r:0.2383
en_zh Dev loss: 0.7073 r:0.4608
Current avg r:0.3496 Best avg r: 0.3517
11:08:21,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:08:47,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:09:13,600 root INFO Epoch 1 Global steps: 5600 Train loss: 0.6039
en_de Dev loss: 0.8679 r:0.2291
en_zh Dev loss: 0.7448 r:0.4691
Current avg r:0.3491 Best avg r: 0.3517
11:10:30,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:10:57,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:11:23,366 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6278
en_de Dev loss: 0.8505 r:0.2314
en_zh Dev loss: 0.6681 r:0.4689
Current avg r:0.3501 Best avg r: 0.3517
11:12:40,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:13:06,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:13:33,94 root INFO Epoch 1 Global steps: 6000 Train loss: 0.7157
en_de Dev loss: 0.8446 r:0.2292
en_zh Dev loss: 0.6704 r:0.4728
Current avg r:0.3510 Best avg r: 0.3517
11:14:50,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:15:16,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:15:43,141 root INFO Epoch 2 Global steps: 6200 Train loss: 0.6829
en_de Dev loss: 0.8702 r:0.2320
en_zh Dev loss: 0.8315 r:0.4609
Current avg r:0.3464 Best avg r: 0.3517
11:17:00,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:17:39,716 root INFO 
id:en_zh cur r: 0.4827 best r: 0.4827
11:17:39,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:18:05,973 root INFO Epoch 2 Global steps: 6400 Train loss: 0.5387
en_de Dev loss: 0.8620 r:0.2111
en_zh Dev loss: 0.7062 r:0.4832
Current avg r:0.3471 Best avg r: 0.3517
11:19:23,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:19:49,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:20:15,748 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:20:15,756 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:20:42,21 root INFO Epoch 2 Global steps: 6600 Train loss: 0.6304
en_de Dev loss: 0.8557 r:0.2336
en_zh Dev loss: 0.7037 r:0.4848
Current avg r:0.3592 Best avg r: 0.3592
11:21:59,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:22:38,680 root INFO 
id:en_zh cur r: 0.4912 best r: 0.4912
11:22:38,680 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:23:04,941 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:23:04,947 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:23:31,200 root INFO Epoch 2 Global steps: 6800 Train loss: 0.5512
en_de Dev loss: 0.8736 r:0.2372
en_zh Dev loss: 0.6738 r:0.4918
Current avg r:0.3645 Best avg r: 0.3645
11:24:48,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:25:14,549 root INFO 
id:en_de cur r: 0.2539 best r: 0.2539
11:25:27,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:25:53,830 root INFO Epoch 2 Global steps: 7000 Train loss: 0.5801
en_de Dev loss: 0.8833 r:0.2415
en_zh Dev loss: 0.7779 r:0.4792
Current avg r:0.3604 Best avg r: 0.3645
11:27:10,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:27:37,187 root INFO 
id:en_de cur r: 0.2610 best r: 0.2610
11:27:50,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:28:16,521 root INFO Epoch 2 Global steps: 7200 Train loss: 0.5648
en_de Dev loss: 0.8496 r:0.2507
en_zh Dev loss: 0.7146 r:0.4781
Current avg r:0.3644 Best avg r: 0.3645
11:29:33,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:30:00,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:30:26,248 root INFO Epoch 2 Global steps: 7400 Train loss: 0.6193
en_de Dev loss: 0.8482 r:0.2331
en_zh Dev loss: 0.7536 r:0.4816
Current avg r:0.3574 Best avg r: 0.3645
11:31:43,529 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:32:09,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:32:36,32 root INFO Epoch 2 Global steps: 7600 Train loss: 0.5773
en_de Dev loss: 0.8399 r:0.2409
en_zh Dev loss: 0.7466 r:0.4720
Current avg r:0.3565 Best avg r: 0.3645
11:33:53,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:34:19,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:34:45,772 root INFO Epoch 2 Global steps: 7800 Train loss: 0.5658
en_de Dev loss: 0.8466 r:0.2191
en_zh Dev loss: 0.6615 r:0.4839
Current avg r:0.3515 Best avg r: 0.3645
11:36:03,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:36:29,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:36:55,496 root INFO Epoch 2 Global steps: 8000 Train loss: 0.4806
en_de Dev loss: 0.8562 r:0.2370
en_zh Dev loss: 0.8001 r:0.4824
Current avg r:0.3597 Best avg r: 0.3645
11:38:12,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:38:39,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:39:05,285 root INFO Epoch 2 Global steps: 8200 Train loss: 0.5843
en_de Dev loss: 0.8696 r:0.2300
en_zh Dev loss: 0.7492 r:0.4697
Current avg r:0.3498 Best avg r: 0.3645
11:40:22,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:40:48,749 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:41:14,980 root INFO Epoch 2 Global steps: 8400 Train loss: 0.5921
en_de Dev loss: 0.8377 r:0.2501
en_zh Dev loss: 0.6930 r:0.4779
Current avg r:0.3640 Best avg r: 0.3645
11:42:32,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:42:58,531 root INFO 
id:en_de cur r: 0.2703 best r: 0.2703
11:43:11,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:43:37,883 root INFO Epoch 2 Global steps: 8600 Train loss: 0.5132
en_de Dev loss: 0.8541 r:0.2559
en_zh Dev loss: 0.8240 r:0.4663
Current avg r:0.3611 Best avg r: 0.3645
11:44:55,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:45:21,450 root INFO 
id:en_de cur r: 0.2828 best r: 0.2828
11:45:34,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:46:00,806 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:46:00,817 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:46:27,70 root INFO Epoch 2 Global steps: 8800 Train loss: 0.5366
en_de Dev loss: 0.8354 r:0.2680
en_zh Dev loss: 0.7182 r:0.4802
Current avg r:0.3741 Best avg r: 0.3741
11:47:44,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:48:10,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:48:36,830 root INFO Epoch 2 Global steps: 9000 Train loss: 0.5180
en_de Dev loss: 0.8823 r:0.2526
en_zh Dev loss: 0.8781 r:0.4808
Current avg r:0.3667 Best avg r: 0.3741
11:49:54,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:50:33,976 root INFO 
id:en_zh cur r: 0.4990 best r: 0.4990
11:50:33,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:51:00,234 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
11:51:00,241 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
11:51:26,534 root INFO Epoch 3 Global steps: 9200 Train loss: 0.4522
en_de Dev loss: 0.8277 r:0.2586
en_zh Dev loss: 0.6656 r:0.4964
Current avg r:0.3775 Best avg r: 0.3775
11:52:43,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:53:10,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:53:36,293 root INFO Epoch 3 Global steps: 9400 Train loss: 0.5695
en_de Dev loss: 0.8376 r:0.2481
en_zh Dev loss: 0.7167 r:0.4889
Current avg r:0.3685 Best avg r: 0.3775
11:54:53,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:55:19,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:55:46,37 root INFO Epoch 3 Global steps: 9600 Train loss: 0.5170
en_de Dev loss: 0.8484 r:0.2522
en_zh Dev loss: 0.7109 r:0.4868
Current avg r:0.3695 Best avg r: 0.3775
11:57:03,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:57:29,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:57:55,830 root INFO Epoch 3 Global steps: 9800 Train loss: 0.4773
en_de Dev loss: 0.8563 r:0.2404
en_zh Dev loss: 0.7673 r:0.4903
Current avg r:0.3653 Best avg r: 0.3775
11:59:13,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:59:39,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:00:05,581 root INFO Epoch 3 Global steps: 10000 Train loss: 0.4626
en_de Dev loss: 0.8564 r:0.2395
en_zh Dev loss: 0.7278 r:0.4825
Current avg r:0.3610 Best avg r: 0.3775
12:01:22,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:01:49,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:02:15,343 root INFO Epoch 3 Global steps: 10200 Train loss: 0.4936
en_de Dev loss: 0.8493 r:0.2438
en_zh Dev loss: 0.7364 r:0.4719
Current avg r:0.3578 Best avg r: 0.3775
12:03:32,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:03:58,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:04:25,181 root INFO Epoch 3 Global steps: 10400 Train loss: 0.4878
en_de Dev loss: 0.8617 r:0.2499
en_zh Dev loss: 0.8142 r:0.4621
Current avg r:0.3560 Best avg r: 0.3775
12:05:42,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:06:08,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:06:34,982 root INFO Epoch 3 Global steps: 10600 Train loss: 0.4657
en_de Dev loss: 0.8599 r:0.2454
en_zh Dev loss: 0.7545 r:0.4834
Current avg r:0.3644 Best avg r: 0.3775
12:07:52,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:08:18,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:08:44,693 root INFO Epoch 3 Global steps: 10800 Train loss: 0.4909
en_de Dev loss: 0.8636 r:0.2331
en_zh Dev loss: 0.7516 r:0.4866
Current avg r:0.3598 Best avg r: 0.3775
12:10:02,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:10:28,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:10:54,486 root INFO Epoch 3 Global steps: 11000 Train loss: 0.5007
en_de Dev loss: 0.8750 r:0.2390
en_zh Dev loss: 0.8079 r:0.4780
Current avg r:0.3585 Best avg r: 0.3775
12:12:11,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:12:37,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:13:04,243 root INFO Epoch 3 Global steps: 11200 Train loss: 0.5578
en_de Dev loss: 0.8633 r:0.2469
en_zh Dev loss: 0.7115 r:0.4938
Current avg r:0.3704 Best avg r: 0.3775
12:14:21,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:14:47,660 root INFO 
id:en_de cur r: 0.2840 best r: 0.2840
12:15:00,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:15:26,935 root INFO Epoch 3 Global steps: 11400 Train loss: 0.5261
en_de Dev loss: 0.8466 r:0.2628
en_zh Dev loss: 0.7783 r:0.4859
Current avg r:0.3744 Best avg r: 0.3775
12:16:43,810 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:17:09,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:17:36,14 root INFO Epoch 3 Global steps: 11600 Train loss: 0.4588
en_de Dev loss: 0.8814 r:0.2463
en_zh Dev loss: 0.8081 r:0.4708
Current avg r:0.3585 Best avg r: 0.3775
12:18:52,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:19:18,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:19:44,990 root INFO Epoch 3 Global steps: 11800 Train loss: 0.5206
en_de Dev loss: 0.8316 r:0.2533
en_zh Dev loss: 0.6943 r:0.4855
Current avg r:0.3694 Best avg r: 0.3775
12:21:01,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:21:27,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:21:54,37 root INFO Epoch 3 Global steps: 12000 Train loss: 0.4986
en_de Dev loss: 0.8540 r:0.2418
en_zh Dev loss: 0.7461 r:0.4823
Current avg r:0.3621 Best avg r: 0.3775
12:23:11,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:23:37,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:24:03,575 root INFO Epoch 4 Global steps: 12200 Train loss: 0.4806
en_de Dev loss: 0.8621 r:0.2195
en_zh Dev loss: 0.7891 r:0.4850
Current avg r:0.3522 Best avg r: 0.3775
12:25:21,120 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:25:47,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:26:13,638 root INFO Epoch 4 Global steps: 12400 Train loss: 0.3778
en_de Dev loss: 0.8811 r:0.2225
en_zh Dev loss: 0.7952 r:0.4781
Current avg r:0.3503 Best avg r: 0.3775
12:27:31,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:27:57,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:28:23,601 root INFO Epoch 4 Global steps: 12600 Train loss: 0.4266
en_de Dev loss: 0.8838 r:0.2044
en_zh Dev loss: 0.8680 r:0.4792
Current avg r:0.3418 Best avg r: 0.3775
12:29:40,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:30:07,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:30:33,261 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4163
en_de Dev loss: 0.8623 r:0.2121
en_zh Dev loss: 0.7103 r:0.4938
Current avg r:0.3529 Best avg r: 0.3775
12:31:50,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:32:16,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:32:42,423 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4335
en_de Dev loss: 0.8605 r:0.2165
en_zh Dev loss: 0.7944 r:0.4814
Current avg r:0.3489 Best avg r: 0.3775
12:33:59,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:34:38,534 root INFO 
id:en_zh cur r: 0.4996 best r: 0.4996
12:34:38,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:35:04,682 root INFO Epoch 4 Global steps: 13200 Train loss: 0.4242
en_de Dev loss: 0.8467 r:0.2353
en_zh Dev loss: 0.6987 r:0.4927
Current avg r:0.3640 Best avg r: 0.3775
12:36:21,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:37:00,701 root INFO 
id:en_zh cur r: 0.4997 best r: 0.4997
12:37:00,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:37:26,816 root INFO Epoch 4 Global steps: 13400 Train loss: 0.4348
en_de Dev loss: 0.8595 r:0.2181
en_zh Dev loss: 0.7347 r:0.4954
Current avg r:0.3568 Best avg r: 0.3775
12:38:43,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:39:09,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:39:36,12 root INFO Epoch 4 Global steps: 13600 Train loss: 0.4792
en_de Dev loss: 0.8497 r:0.2467
en_zh Dev loss: 0.8367 r:0.4767
Current avg r:0.3617 Best avg r: 0.3775
12:40:53,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:41:19,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:41:45,459 root INFO Epoch 4 Global steps: 13800 Train loss: 0.4225
en_de Dev loss: 0.8805 r:0.2455
en_zh Dev loss: 0.8278 r:0.4796
Current avg r:0.3626 Best avg r: 0.3775
12:43:02,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:43:28,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:43:54,858 root INFO Epoch 4 Global steps: 14000 Train loss: 0.3767
en_de Dev loss: 0.8596 r:0.2546
en_zh Dev loss: 0.7890 r:0.4857
Current avg r:0.3701 Best avg r: 0.3775
12:45:11,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:45:38,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:46:04,296 root INFO Epoch 4 Global steps: 14200 Train loss: 0.3983
en_de Dev loss: 0.8709 r:0.2425
en_zh Dev loss: 0.7449 r:0.4803
Current avg r:0.3614 Best avg r: 0.3775
12:47:21,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:47:47,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:48:13,490 root INFO Epoch 4 Global steps: 14400 Train loss: 0.3754
en_de Dev loss: 0.8596 r:0.2497
en_zh Dev loss: 0.7688 r:0.4894
Current avg r:0.3696 Best avg r: 0.3775
12:49:30,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:49:56,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:50:22,503 root INFO Epoch 4 Global steps: 14600 Train loss: 0.3490
en_de Dev loss: 0.8559 r:0.2350
en_zh Dev loss: 0.7474 r:0.4828
Current avg r:0.3589 Best avg r: 0.3775
12:51:39,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:52:05,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:52:31,589 root INFO Epoch 4 Global steps: 14800 Train loss: 0.3921
en_de Dev loss: 0.8597 r:0.2304
en_zh Dev loss: 0.7197 r:0.4813
Current avg r:0.3558 Best avg r: 0.3775
12:53:48,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:54:14,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:54:40,673 root INFO Epoch 4 Global steps: 15000 Train loss: 0.4098
en_de Dev loss: 0.8392 r:0.2404
en_zh Dev loss: 0.7061 r:0.4767
Current avg r:0.3586 Best avg r: 0.3775
12:55:57,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:56:24,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:56:50,261 root INFO Epoch 5 Global steps: 15200 Train loss: 0.3379
en_de Dev loss: 0.8619 r:0.2294
en_zh Dev loss: 0.7900 r:0.4757
Current avg r:0.3525 Best avg r: 0.3775
12:58:07,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:58:33,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:58:59,672 root INFO Epoch 5 Global steps: 15400 Train loss: 0.3698
en_de Dev loss: 0.8544 r:0.2435
en_zh Dev loss: 0.8188 r:0.4637
Current avg r:0.3536 Best avg r: 0.3775
13:00:16,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:00:43,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:01:09,300 root INFO Epoch 5 Global steps: 15600 Train loss: 0.3555
en_de Dev loss: 0.8730 r:0.2230
en_zh Dev loss: 0.8613 r:0.4555
Current avg r:0.3393 Best avg r: 0.3775
13:02:26,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:02:52,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:03:18,605 root INFO Epoch 5 Global steps: 15800 Train loss: 0.4239
en_de Dev loss: 0.8776 r:0.2232
en_zh Dev loss: 0.8142 r:0.4538
Current avg r:0.3385 Best avg r: 0.3775
13:04:35,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:05:01,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:05:27,965 root INFO Epoch 5 Global steps: 16000 Train loss: 0.3421
en_de Dev loss: 0.8784 r:0.2226
en_zh Dev loss: 0.8442 r:0.4588
Current avg r:0.3407 Best avg r: 0.3775
13:06:44,832 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:07:11,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:07:37,351 root INFO Epoch 5 Global steps: 16200 Train loss: 0.3643
en_de Dev loss: 0.8911 r:0.2121
en_zh Dev loss: 0.7863 r:0.4677
Current avg r:0.3399 Best avg r: 0.3775
13:08:54,519 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:09:20,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:09:46,953 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3709
en_de Dev loss: 0.8731 r:0.1975
en_zh Dev loss: 0.7190 r:0.4823
Current avg r:0.3399 Best avg r: 0.3775
13:11:04,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:11:30,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:11:56,591 root INFO Epoch 5 Global steps: 16600 Train loss: 0.3183
en_de Dev loss: 0.9041 r:0.2138
en_zh Dev loss: 0.8456 r:0.4656
Current avg r:0.3397 Best avg r: 0.3775
13:13:13,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:13:39,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:14:05,942 root INFO Epoch 5 Global steps: 16800 Train loss: 0.3174
en_de Dev loss: 0.8743 r:0.1918
en_zh Dev loss: 0.7616 r:0.4715
Current avg r:0.3317 Best avg r: 0.3775
13:15:23,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:15:49,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:16:15,559 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3086
en_de Dev loss: 0.8794 r:0.2062
en_zh Dev loss: 0.7862 r:0.4702
Current avg r:0.3382 Best avg r: 0.3775
13:17:33,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:17:59,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:18:26,133 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3742
en_de Dev loss: 0.8711 r:0.1936
en_zh Dev loss: 0.7680 r:0.4779
Current avg r:0.3358 Best avg r: 0.3775
13:19:44,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:20:10,346 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:20:36,675 root INFO Epoch 5 Global steps: 17400 Train loss: 0.3005
en_de Dev loss: 0.8916 r:0.1933
en_zh Dev loss: 0.7642 r:0.4879
Current avg r:0.3406 Best avg r: 0.3775
13:21:54,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:22:20,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:22:47,153 root INFO Epoch 5 Global steps: 17600 Train loss: 0.3244
en_de Dev loss: 0.8675 r:0.1983
en_zh Dev loss: 0.6870 r:0.4854
Current avg r:0.3419 Best avg r: 0.3775
13:24:04,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:24:31,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:24:57,458 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3231
en_de Dev loss: 0.8861 r:0.1892
en_zh Dev loss: 0.7580 r:0.4904
Current avg r:0.3398 Best avg r: 0.3775
13:26:15,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:26:41,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:27:07,816 root INFO Epoch 5 Global steps: 18000 Train loss: 0.3438
en_de Dev loss: 0.8818 r:0.1777
en_zh Dev loss: 0.7302 r:0.4898
Current avg r:0.3338 Best avg r: 0.3775
13:28:26,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:29:05,636 root INFO 
id:en_zh cur r: 0.5000 best r: 0.5000
13:29:05,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:29:31,950 root INFO Epoch 6 Global steps: 18200 Train loss: 0.2720
en_de Dev loss: 0.9082 r:0.1829
en_zh Dev loss: 0.7479 r:0.4915
Current avg r:0.3372 Best avg r: 0.3775
13:30:49,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:31:15,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:31:42,156 root INFO Epoch 6 Global steps: 18400 Train loss: 0.2909
en_de Dev loss: 0.9173 r:0.1795
en_zh Dev loss: 0.7606 r:0.4907
Current avg r:0.3351 Best avg r: 0.3775
13:32:59,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:33:25,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:33:52,210 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3403
en_de Dev loss: 0.8757 r:0.1870
en_zh Dev loss: 0.7435 r:0.4722
Current avg r:0.3296 Best avg r: 0.3775
13:35:09,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:35:36,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:36:02,324 root INFO Epoch 6 Global steps: 18800 Train loss: 0.2921
en_de Dev loss: 0.9073 r:0.1811
en_zh Dev loss: 0.8350 r:0.4719
Current avg r:0.3265 Best avg r: 0.3775
13:37:19,553 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:37:45,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:38:11,914 root INFO Epoch 6 Global steps: 19000 Train loss: 0.3200
en_de Dev loss: 0.9061 r:0.1799
en_zh Dev loss: 0.8057 r:0.4743
Current avg r:0.3271 Best avg r: 0.3775
13:39:28,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:39:55,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:40:21,305 root INFO Epoch 6 Global steps: 19200 Train loss: 0.2984
en_de Dev loss: 0.8933 r:0.1909
en_zh Dev loss: 0.7323 r:0.4833
Current avg r:0.3371 Best avg r: 0.3775
13:41:38,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:42:04,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:42:30,641 root INFO Epoch 6 Global steps: 19400 Train loss: 0.2989
en_de Dev loss: 0.8845 r:0.1898
en_zh Dev loss: 0.7231 r:0.4888
Current avg r:0.3393 Best avg r: 0.3775
13:43:47,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:44:13,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:44:40,95 root INFO Epoch 6 Global steps: 19600 Train loss: 0.2722
en_de Dev loss: 0.8901 r:0.1923
en_zh Dev loss: 0.7760 r:0.4807
Current avg r:0.3365 Best avg r: 0.3775
13:45:57,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:46:23,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:46:49,627 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3149
en_de Dev loss: 0.9050 r:0.1874
en_zh Dev loss: 0.7930 r:0.4801
Current avg r:0.3338 Best avg r: 0.3775
13:48:06,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:48:32,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:48:58,886 root INFO Epoch 6 Global steps: 20000 Train loss: 0.2646
en_de Dev loss: 0.9128 r:0.1987
en_zh Dev loss: 0.7703 r:0.4791
Current avg r:0.3389 Best avg r: 0.3775
13:50:15,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:50:41,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:51:08,17 root INFO Epoch 6 Global steps: 20200 Train loss: 0.2808
en_de Dev loss: 0.8902 r:0.1960
en_zh Dev loss: 0.7553 r:0.4790
Current avg r:0.3375 Best avg r: 0.3775
13:52:24,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:52:50,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:53:17,141 root INFO Epoch 6 Global steps: 20400 Train loss: 0.2812
en_de Dev loss: 0.9189 r:0.1793
en_zh Dev loss: 0.7511 r:0.4701
Current avg r:0.3247 Best avg r: 0.3775
13:54:33,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:55:00,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:55:26,262 root INFO Epoch 6 Global steps: 20600 Train loss: 0.2921
en_de Dev loss: 0.9166 r:0.1839
en_zh Dev loss: 0.8319 r:0.4672
Current avg r:0.3255 Best avg r: 0.3775
13:56:43,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:57:09,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:57:35,376 root INFO Epoch 6 Global steps: 20800 Train loss: 0.2812
en_de Dev loss: 0.8992 r:0.1810
en_zh Dev loss: 0.7518 r:0.4806
Current avg r:0.3308 Best avg r: 0.3775
13:58:52,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:59:18,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:59:44,548 root INFO Epoch 6 Global steps: 21000 Train loss: 0.2722
en_de Dev loss: 0.8770 r:0.1822
en_zh Dev loss: 0.7606 r:0.4647
Current avg r:0.3235 Best avg r: 0.3775
14:01:01,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:01:27,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:01:54,124 root INFO Epoch 7 Global steps: 21200 Train loss: 0.2679
en_de Dev loss: 0.8925 r:0.1863
en_zh Dev loss: 0.7546 r:0.4750
Current avg r:0.3307 Best avg r: 0.3775
14:03:10,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:03:37,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:04:03,266 root INFO Epoch 7 Global steps: 21400 Train loss: 0.2637
en_de Dev loss: 0.9075 r:0.1794
en_zh Dev loss: 0.7631 r:0.4843
Current avg r:0.3318 Best avg r: 0.3775
14:05:20,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:05:59,405 root INFO 
id:en_zh cur r: 0.5021 best r: 0.5021
14:05:59,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:06:25,543 root INFO Epoch 7 Global steps: 21600 Train loss: 0.2731
en_de Dev loss: 0.8890 r:0.1877
en_zh Dev loss: 0.7362 r:0.4956
Current avg r:0.3417 Best avg r: 0.3775
14:07:42,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:08:08,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:08:34,688 root INFO Epoch 7 Global steps: 21800 Train loss: 0.2826
en_de Dev loss: 0.8847 r:0.1862
en_zh Dev loss: 0.8155 r:0.4784
Current avg r:0.3323 Best avg r: 0.3775
14:09:51,529 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:10:17,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:10:43,844 root INFO Epoch 7 Global steps: 22000 Train loss: 0.3021
en_de Dev loss: 0.9065 r:0.1965
en_zh Dev loss: 0.7498 r:0.4896
Current avg r:0.3430 Best avg r: 0.3775
14:12:00,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:12:26,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:12:53,79 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2591
en_de Dev loss: 0.9012 r:0.1908
en_zh Dev loss: 0.8589 r:0.4749
Current avg r:0.3329 Best avg r: 0.3775
14:14:09,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:14:36,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:15:02,249 root INFO Epoch 7 Global steps: 22400 Train loss: 0.2577
en_de Dev loss: 0.8665 r:0.2007
en_zh Dev loss: 0.7171 r:0.4832
Current avg r:0.3420 Best avg r: 0.3775
14:16:19,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:16:45,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:17:11,456 root INFO Epoch 7 Global steps: 22600 Train loss: 0.2641
en_de Dev loss: 0.9072 r:0.1923
en_zh Dev loss: 0.7362 r:0.4929
Current avg r:0.3426 Best avg r: 0.3775
14:18:28,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:18:54,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:19:20,713 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2447
en_de Dev loss: 0.8910 r:0.2142
en_zh Dev loss: 0.7279 r:0.4856
Current avg r:0.3499 Best avg r: 0.3775
14:20:37,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:21:03,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:21:30,164 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2642
en_de Dev loss: 0.9016 r:0.1909
en_zh Dev loss: 0.7730 r:0.4830
Current avg r:0.3370 Best avg r: 0.3775
14:22:47,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:23:13,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:23:39,408 root INFO Epoch 7 Global steps: 23200 Train loss: 0.2506
en_de Dev loss: 0.8878 r:0.2023
en_zh Dev loss: 0.7534 r:0.4846
Current avg r:0.3434 Best avg r: 0.3775
14:24:56,242 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:25:22,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:25:48,723 root INFO Epoch 7 Global steps: 23400 Train loss: 0.2326
en_de Dev loss: 0.9056 r:0.2019
en_zh Dev loss: 0.8315 r:0.4799
Current avg r:0.3409 Best avg r: 0.3775
14:27:06,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:27:32,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:27:58,807 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2677
en_de Dev loss: 0.8847 r:0.1992
en_zh Dev loss: 0.7423 r:0.4961
Current avg r:0.3476 Best avg r: 0.3775
14:29:16,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:29:42,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:30:08,910 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2399
en_de Dev loss: 0.9164 r:0.1765
en_zh Dev loss: 0.7655 r:0.4886
Current avg r:0.3326 Best avg r: 0.3775
14:31:25,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:31:52,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:32:18,255 root INFO Epoch 7 Global steps: 24000 Train loss: 0.2259
en_de Dev loss: 0.8959 r:0.1813
en_zh Dev loss: 0.7974 r:0.4764
Current avg r:0.3289 Best avg r: 0.3775
14:33:35,549 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:34:01,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:34:27,863 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2579
en_de Dev loss: 0.9116 r:0.1707
en_zh Dev loss: 0.8022 r:0.4884
Current avg r:0.3296 Best avg r: 0.3775
14:35:44,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:36:10,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:36:37,302 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2184
en_de Dev loss: 0.9071 r:0.1679
en_zh Dev loss: 0.7721 r:0.4886
Current avg r:0.3283 Best avg r: 0.3775
14:37:54,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:38:21,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:38:47,428 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2395
en_de Dev loss: 0.8855 r:0.1811
en_zh Dev loss: 0.7436 r:0.4826
Current avg r:0.3318 Best avg r: 0.3775
14:40:04,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:40:30,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:56,810 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2270
en_de Dev loss: 0.9124 r:0.1743
en_zh Dev loss: 0.7837 r:0.4789
Current avg r:0.3266 Best avg r: 0.3775
14:42:13,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:39,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:06,13 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2402
en_de Dev loss: 0.9363 r:0.1758
en_zh Dev loss: 0.8170 r:0.4767
Current avg r:0.3263 Best avg r: 0.3775
14:44:22,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:49,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:15,195 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2041
en_de Dev loss: 0.9397 r:0.1714
en_zh Dev loss: 0.8258 r:0.4742
Current avg r:0.3228 Best avg r: 0.3775
14:46:32,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:46:58,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:24,366 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2349
en_de Dev loss: 0.9120 r:0.1872
en_zh Dev loss: 0.7369 r:0.4840
Current avg r:0.3356 Best avg r: 0.3775
14:48:41,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:07,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:33,517 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2274
en_de Dev loss: 0.9180 r:0.1833
en_zh Dev loss: 0.7504 r:0.4876
Current avg r:0.3355 Best avg r: 0.3775
14:50:50,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:16,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:43,44 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2223
en_de Dev loss: 0.9354 r:0.1640
en_zh Dev loss: 0.7861 r:0.4770
Current avg r:0.3205 Best avg r: 0.3775
14:53:00,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:26,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:52,377 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2311
en_de Dev loss: 0.9173 r:0.1690
en_zh Dev loss: 0.7358 r:0.4744
Current avg r:0.3217 Best avg r: 0.3775
14:55:09,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:35,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:56:01,607 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2362
en_de Dev loss: 0.9041 r:0.1907
en_zh Dev loss: 0.7702 r:0.4808
Current avg r:0.3357 Best avg r: 0.3775
14:57:18,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:44,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:10,860 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2145
en_de Dev loss: 0.8964 r:0.1892
en_zh Dev loss: 0.7206 r:0.4795
Current avg r:0.3344 Best avg r: 0.3775
14:59:27,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:53,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:20,120 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2283
en_de Dev loss: 0.9264 r:0.1873
en_zh Dev loss: 0.7586 r:0.4774
Current avg r:0.3323 Best avg r: 0.3775
15:01:37,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:03,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:29,384 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2078
en_de Dev loss: 0.9130 r:0.1891
en_zh Dev loss: 0.8079 r:0.4754
Current avg r:0.3322 Best avg r: 0.3775
15:03:46,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:12,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:38,675 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2108
en_de Dev loss: 0.8955 r:0.1882
en_zh Dev loss: 0.7678 r:0.4684
Current avg r:0.3283 Best avg r: 0.3775
15:05:55,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:06:22,34 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:48,186 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2076
en_de Dev loss: 0.9128 r:0.1936
en_zh Dev loss: 0.7590 r:0.4730
Current avg r:0.3333 Best avg r: 0.3775
15:08:05,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:31,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:57,446 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2146
en_de Dev loss: 0.9306 r:0.1886
en_zh Dev loss: 0.8413 r:0.4538
Current avg r:0.3212 Best avg r: 0.3775
15:10:14,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:40,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:06,737 root INFO Epoch 9 Global steps: 27600 Train loss: 0.1868
en_de Dev loss: 0.9154 r:0.1860
en_zh Dev loss: 0.8089 r:0.4671
Current avg r:0.3266 Best avg r: 0.3775
15:12:23,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:49,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:16,5 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2154
en_de Dev loss: 0.9170 r:0.1820
en_zh Dev loss: 0.7907 r:0.4798
Current avg r:0.3309 Best avg r: 0.3775
15:14:32,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:59,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:15:25,293 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2200
en_de Dev loss: 0.9366 r:0.1756
en_zh Dev loss: 0.8309 r:0.4764
Current avg r:0.3260 Best avg r: 0.3775
15:16:42,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:08,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:34,630 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2071
en_de Dev loss: 0.9150 r:0.1906
en_zh Dev loss: 0.7635 r:0.4820
Current avg r:0.3363 Best avg r: 0.3775
15:18:51,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:17,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:43,923 root INFO Epoch 9 Global steps: 28400 Train loss: 0.1920
en_de Dev loss: 0.9196 r:0.1930
en_zh Dev loss: 0.8741 r:0.4655
Current avg r:0.3292 Best avg r: 0.3775
15:21:00,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:21:27,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:53,225 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2169
en_de Dev loss: 0.9171 r:0.1952
en_zh Dev loss: 0.8613 r:0.4624
Current avg r:0.3288 Best avg r: 0.3775
15:23:10,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:36,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:02,553 root INFO Epoch 9 Global steps: 28800 Train loss: 0.1833
en_de Dev loss: 0.8984 r:0.1937
en_zh Dev loss: 0.7594 r:0.4761
Current avg r:0.3349 Best avg r: 0.3775
15:25:19,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:45,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:11,983 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2317
en_de Dev loss: 0.8859 r:0.1929
en_zh Dev loss: 0.7417 r:0.4838
Current avg r:0.3383 Best avg r: 0.3775
15:27:29,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:55,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:21,490 root INFO Epoch 9 Global steps: 29200 Train loss: 0.1974
en_de Dev loss: 0.8978 r:0.1815
en_zh Dev loss: 0.7029 r:0.4827
Current avg r:0.3321 Best avg r: 0.3775
15:29:38,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:04,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:30,899 root INFO Epoch 9 Global steps: 29400 Train loss: 0.1993
en_de Dev loss: 0.9148 r:0.1776
en_zh Dev loss: 0.7742 r:0.4778
Current avg r:0.3277 Best avg r: 0.3775
15:31:47,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:14,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:40,189 root INFO Epoch 9 Global steps: 29600 Train loss: 0.1791
en_de Dev loss: 0.8889 r:0.1912
en_zh Dev loss: 0.7307 r:0.4890
Current avg r:0.3401 Best avg r: 0.3775
15:33:57,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:23,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:49,457 root INFO Epoch 9 Global steps: 29800 Train loss: 0.1917
en_de Dev loss: 0.9586 r:0.1729
en_zh Dev loss: 0.8002 r:0.4863
Current avg r:0.3296 Best avg r: 0.3775
15:36:06,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:32,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:58,686 root INFO Epoch 9 Global steps: 30000 Train loss: 0.1838
en_de Dev loss: 0.9174 r:0.1777
en_zh Dev loss: 0.7451 r:0.4809
Current avg r:0.3293 Best avg r: 0.3775
15:38:16,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:42,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:08,369 root INFO Epoch 10 Global steps: 30200 Train loss: 0.1925
en_de Dev loss: 0.9205 r:0.1921
en_zh Dev loss: 0.7704 r:0.4889
Current avg r:0.3405 Best avg r: 0.3775
15:40:25,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:51,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:17,611 root INFO Epoch 10 Global steps: 30400 Train loss: 0.2020
en_de Dev loss: 0.9267 r:0.1824
en_zh Dev loss: 0.7523 r:0.4853
Current avg r:0.3338 Best avg r: 0.3775
15:42:34,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:00,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:26,823 root INFO Epoch 10 Global steps: 30600 Train loss: 0.1937
en_de Dev loss: 0.9246 r:0.1880
en_zh Dev loss: 0.7633 r:0.4692
Current avg r:0.3286 Best avg r: 0.3775
15:44:43,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:45:09,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:36,51 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1771
en_de Dev loss: 0.9124 r:0.1793
en_zh Dev loss: 0.7349 r:0.4748
Current avg r:0.3270 Best avg r: 0.3775
15:46:52,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:19,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:45,276 root INFO Epoch 10 Global steps: 31000 Train loss: 0.1676
en_de Dev loss: 0.9152 r:0.1829
en_zh Dev loss: 0.7495 r:0.4827
Current avg r:0.3328 Best avg r: 0.3775
15:49:02,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:28,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:54,421 root INFO Epoch 10 Global steps: 31200 Train loss: 0.1785
en_de Dev loss: 0.9305 r:0.1653
en_zh Dev loss: 0.7396 r:0.4801
Current avg r:0.3227 Best avg r: 0.3775
15:51:11,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:37,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:03,641 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1908
en_de Dev loss: 0.8993 r:0.1758
en_zh Dev loss: 0.7052 r:0.4905
Current avg r:0.3332 Best avg r: 0.3775
15:53:20,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:46,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:12,863 root INFO Epoch 10 Global steps: 31600 Train loss: 0.1770
en_de Dev loss: 0.9115 r:0.1833
en_zh Dev loss: 0.7431 r:0.4895
Current avg r:0.3364 Best avg r: 0.3775
15:55:29,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:55,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:22,89 root INFO Epoch 10 Global steps: 31800 Train loss: 0.1736
en_de Dev loss: 0.9600 r:0.1743
en_zh Dev loss: 0.8148 r:0.4716
Current avg r:0.3229 Best avg r: 0.3775
15:57:39,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:05,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:31,349 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1861
en_de Dev loss: 0.9211 r:0.1818
en_zh Dev loss: 0.7568 r:0.4759
Current avg r:0.3289 Best avg r: 0.3775
15:59:48,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:14,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:40,759 root INFO Epoch 10 Global steps: 32200 Train loss: 0.1660
en_de Dev loss: 0.9309 r:0.1856
en_zh Dev loss: 0.7808 r:0.4707
Current avg r:0.3281 Best avg r: 0.3775
16:01:57,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:02:24,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:50,221 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1784
en_de Dev loss: 0.9143 r:0.1899
en_zh Dev loss: 0.7851 r:0.4673
Current avg r:0.3286 Best avg r: 0.3775
16:04:07,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:33,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:59,705 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1975
en_de Dev loss: 0.8923 r:0.2041
en_zh Dev loss: 0.7381 r:0.4790
Current avg r:0.3415 Best avg r: 0.3775
16:06:16,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:42,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:09,181 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1739
en_de Dev loss: 0.8916 r:0.1902
en_zh Dev loss: 0.7428 r:0.4705
Current avg r:0.3303 Best avg r: 0.3775
16:08:26,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:08:52,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:18,901 root INFO Epoch 10 Global steps: 33000 Train loss: 0.1850
en_de Dev loss: 0.9106 r:0.1930
en_zh Dev loss: 0.7489 r:0.4798
Current avg r:0.3364 Best avg r: 0.3775
16:10:36,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:02,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:28,705 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1719
en_de Dev loss: 0.9521 r:0.1800
en_zh Dev loss: 0.7952 r:0.4682
Current avg r:0.3241 Best avg r: 0.3775
16:12:45,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:11,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:38,49 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1694
en_de Dev loss: 0.9425 r:0.1810
en_zh Dev loss: 0.7673 r:0.4838
Current avg r:0.3324 Best avg r: 0.3775
16:14:55,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:21,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:47,463 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1641
en_de Dev loss: 0.9125 r:0.1879
en_zh Dev loss: 0.7368 r:0.4891
Current avg r:0.3385 Best avg r: 0.3775
16:17:04,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:30,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:17:56,801 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1584
en_de Dev loss: 0.9371 r:0.1829
en_zh Dev loss: 0.7925 r:0.4744
Current avg r:0.3286 Best avg r: 0.3775
16:19:13,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:39,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:06,198 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1752
en_de Dev loss: 0.9426 r:0.1797
en_zh Dev loss: 0.7640 r:0.4743
Current avg r:0.3270 Best avg r: 0.3775
16:21:23,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:21:49,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:15,601 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1639
en_de Dev loss: 0.9418 r:0.1862
en_zh Dev loss: 0.8654 r:0.4616
Current avg r:0.3239 Best avg r: 0.3775
16:23:32,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:58,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:24:24,993 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1631
en_de Dev loss: 0.9491 r:0.1775
en_zh Dev loss: 0.8309 r:0.4548
Current avg r:0.3161 Best avg r: 0.3775
16:25:41,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:08,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:34,364 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1643
en_de Dev loss: 0.9250 r:0.1786
en_zh Dev loss: 0.8188 r:0.4661
Current avg r:0.3223 Best avg r: 0.3775
16:27:51,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:17,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:43,659 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1461
en_de Dev loss: 0.9362 r:0.1859
en_zh Dev loss: 0.7718 r:0.4714
Current avg r:0.3286 Best avg r: 0.3775
16:30:00,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:26,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:52,925 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1743
en_de Dev loss: 0.9012 r:0.2009
en_zh Dev loss: 0.7391 r:0.4744
Current avg r:0.3376 Best avg r: 0.3775
16:32:09,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:36,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:02,294 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1654
en_de Dev loss: 0.9477 r:0.1859
en_zh Dev loss: 0.7733 r:0.4718
Current avg r:0.3289 Best avg r: 0.3775
16:34:19,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:45,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:11,534 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1527
en_de Dev loss: 0.9077 r:0.1903
en_zh Dev loss: 0.7416 r:0.4681
Current avg r:0.3292 Best avg r: 0.3775
16:36:28,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:54,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:20,830 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1702
en_de Dev loss: 0.9420 r:0.1765
en_zh Dev loss: 0.7983 r:0.4677
Current avg r:0.3221 Best avg r: 0.3775
16:38:37,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:04,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:30,267 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1599
en_de Dev loss: 0.9248 r:0.1888
en_zh Dev loss: 0.8354 r:0.4640
Current avg r:0.3264 Best avg r: 0.3775
16:40:47,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:13,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:39,690 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1688
en_de Dev loss: 0.9328 r:0.1813
en_zh Dev loss: 0.7760 r:0.4734
Current avg r:0.3273 Best avg r: 0.3775
16:42:57,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:23,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:49,418 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1515
en_de Dev loss: 0.9494 r:0.1757
en_zh Dev loss: 0.8075 r:0.4688
Current avg r:0.3222 Best avg r: 0.3775
16:45:06,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:32,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:58,760 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1539
en_de Dev loss: 0.9241 r:0.1809
en_zh Dev loss: 0.7386 r:0.4828
Current avg r:0.3319 Best avg r: 0.3775
16:47:15,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:41,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:08,57 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1618
en_de Dev loss: 0.9473 r:0.1668
en_zh Dev loss: 0.6937 r:0.4900
Current avg r:0.3284 Best avg r: 0.3775
16:49:25,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:51,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:17,341 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1390
en_de Dev loss: 0.9468 r:0.1713
en_zh Dev loss: 0.7771 r:0.4780
Current avg r:0.3246 Best avg r: 0.3775
16:51:34,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:00,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:26,566 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1526
en_de Dev loss: 0.9352 r:0.1841
en_zh Dev loss: 0.7329 r:0.4872
Current avg r:0.3356 Best avg r: 0.3775
16:53:43,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:09,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:36,9 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1504
en_de Dev loss: 0.9284 r:0.1748
en_zh Dev loss: 0.7421 r:0.4869
Current avg r:0.3308 Best avg r: 0.3775
16:55:53,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:19,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:45,561 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1520
en_de Dev loss: 0.9512 r:0.1768
en_zh Dev loss: 0.7905 r:0.4878
Current avg r:0.3323 Best avg r: 0.3775
16:58:02,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:28,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:55,40 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1377
en_de Dev loss: 0.9320 r:0.1885
en_zh Dev loss: 0.7222 r:0.4943
Current avg r:0.3414 Best avg r: 0.3775
17:00:12,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:38,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:04,557 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1517
en_de Dev loss: 0.9663 r:0.1730
en_zh Dev loss: 0.7603 r:0.4957
Current avg r:0.3343 Best avg r: 0.3775
17:02:21,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:47,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:13,876 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1507
en_de Dev loss: 0.9568 r:0.1565
en_zh Dev loss: 0.7549 r:0.4859
Current avg r:0.3212 Best avg r: 0.3775
17:04:30,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:56,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:23,51 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1534
en_de Dev loss: 0.9253 r:0.1712
en_zh Dev loss: 0.7462 r:0.4852
Current avg r:0.3282 Best avg r: 0.3775
17:06:39,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:06,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:32,228 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1420
en_de Dev loss: 0.9697 r:0.1720
en_zh Dev loss: 0.8194 r:0.4846
Current avg r:0.3283 Best avg r: 0.3775
17:08:49,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:15,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:41,478 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1549
en_de Dev loss: 0.9519 r:0.1601
en_zh Dev loss: 0.7476 r:0.4888
Current avg r:0.3245 Best avg r: 0.3775
17:10:58,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:24,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:50,623 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1504
en_de Dev loss: 0.9776 r:0.1476
en_zh Dev loss: 0.7626 r:0.4759
Current avg r:0.3117 Best avg r: 0.3775
17:13:07,545 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:33,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:59,924 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1487
en_de Dev loss: 0.9333 r:0.1722
en_zh Dev loss: 0.7304 r:0.4777
Current avg r:0.3250 Best avg r: 0.3775
17:15:17,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:43,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:09,649 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1386
en_de Dev loss: 0.9382 r:0.1731
en_zh Dev loss: 0.7714 r:0.4749
Current avg r:0.3240 Best avg r: 0.3775
17:17:26,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:52,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:18,974 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1310
en_de Dev loss: 0.9449 r:0.1773
en_zh Dev loss: 0.7656 r:0.4752
Current avg r:0.3263 Best avg r: 0.3775
17:19:35,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:02,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:28,293 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1348
en_de Dev loss: 0.9214 r:0.1866
en_zh Dev loss: 0.7600 r:0.4717
Current avg r:0.3292 Best avg r: 0.3775
17:21:45,286 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:11,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:37,658 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1314
en_de Dev loss: 0.9389 r:0.1740
en_zh Dev loss: 0.7650 r:0.4744
Current avg r:0.3242 Best avg r: 0.3775
17:23:54,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:20,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:47,61 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1299
en_de Dev loss: 0.9477 r:0.1650
en_zh Dev loss: 0.7685 r:0.4734
Current avg r:0.3192 Best avg r: 0.3775
17:26:04,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:30,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:56,531 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1276
en_de Dev loss: 0.9431 r:0.1657
en_zh Dev loss: 0.7845 r:0.4745
Current avg r:0.3201 Best avg r: 0.3775
17:28:13,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:39,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:05,989 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1311
en_de Dev loss: 0.9502 r:0.1646
en_zh Dev loss: 0.7597 r:0.4824
Current avg r:0.3235 Best avg r: 0.3775
17:30:23,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:49,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:15,433 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1401
en_de Dev loss: 0.9441 r:0.1741
en_zh Dev loss: 0.7202 r:0.4807
Current avg r:0.3274 Best avg r: 0.3775
17:32:32,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:58,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:24,867 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1405
en_de Dev loss: 0.9870 r:0.1624
en_zh Dev loss: 0.8180 r:0.4740
Current avg r:0.3182 Best avg r: 0.3775
17:34:41,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:08,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:34,301 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1183
en_de Dev loss: 0.9445 r:0.1654
en_zh Dev loss: 0.7364 r:0.4764
Current avg r:0.3209 Best avg r: 0.3775
17:36:51,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:17,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:43,735 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1313
en_de Dev loss: 0.9839 r:0.1550
en_zh Dev loss: 0.7879 r:0.4734
Current avg r:0.3142 Best avg r: 0.3775
17:39:00,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:26,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:53,138 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1438
en_de Dev loss: 0.9931 r:0.1646
en_zh Dev loss: 0.7684 r:0.4874
Current avg r:0.3260 Best avg r: 0.3775
17:41:10,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:36,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:02,490 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1396
en_de Dev loss: 0.9728 r:0.1758
en_zh Dev loss: 0.7925 r:0.4808
Current avg r:0.3283 Best avg r: 0.3775
17:43:19,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:45,752 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:11,937 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1359
en_de Dev loss: 0.9567 r:0.1595
en_zh Dev loss: 0.7226 r:0.4856
Current avg r:0.3225 Best avg r: 0.3775
17:45:28,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:55,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:21,286 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1374
en_de Dev loss: 0.9442 r:0.1746
en_zh Dev loss: 0.7711 r:0.4847
Current avg r:0.3296 Best avg r: 0.3775
17:47:38,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:04,749 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:30,949 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1168
en_de Dev loss: 0.9470 r:0.1934
en_zh Dev loss: 0.7776 r:0.4792
Current avg r:0.3363 Best avg r: 0.3775
17:49:48,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:14,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:40,385 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1179
en_de Dev loss: 0.9583 r:0.1765
en_zh Dev loss: 0.7895 r:0.4769
Current avg r:0.3267 Best avg r: 0.3775
17:51:57,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:23,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:49,768 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1330
en_de Dev loss: 0.9519 r:0.1738
en_zh Dev loss: 0.7698 r:0.4822
Current avg r:0.3280 Best avg r: 0.3775
17:54:06,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:32,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:59,178 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1255
en_de Dev loss: 0.9480 r:0.1799
en_zh Dev loss: 0.7478 r:0.4830
Current avg r:0.3315 Best avg r: 0.3775
17:56:16,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:42,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:08,664 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1272
en_de Dev loss: 0.9873 r:0.1598
en_zh Dev loss: 0.8364 r:0.4687
Current avg r:0.3142 Best avg r: 0.3775
17:58:25,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:52,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:18,246 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1172
en_de Dev loss: 0.9567 r:0.1601
en_zh Dev loss: 0.7626 r:0.4882
Current avg r:0.3241 Best avg r: 0.3775
18:00:35,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:01,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:27,851 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1134
en_de Dev loss: 0.9711 r:0.1666
en_zh Dev loss: 0.7755 r:0.4918
Current avg r:0.3292 Best avg r: 0.3775
18:02:44,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:11,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:37,432 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1056
en_de Dev loss: 0.9510 r:0.1651
en_zh Dev loss: 0.7270 r:0.4861
Current avg r:0.3256 Best avg r: 0.3775
18:04:54,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:20,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:46,961 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1257
en_de Dev loss: 0.9709 r:0.1789
en_zh Dev loss: 0.7896 r:0.4842
Current avg r:0.3316 Best avg r: 0.3775
18:07:04,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:30,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:56,588 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1234
en_de Dev loss: 0.9481 r:0.1613
en_zh Dev loss: 0.7203 r:0.4855
Current avg r:0.3234 Best avg r: 0.3775
18:09:13,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:39,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:06,45 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1146
en_de Dev loss: 0.9624 r:0.1469
en_zh Dev loss: 0.7748 r:0.4779
Current avg r:0.3124 Best avg r: 0.3775
18:11:23,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:49,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:15,557 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1355
en_de Dev loss: 0.9729 r:0.1629
en_zh Dev loss: 0.7658 r:0.4811
Current avg r:0.3220 Best avg r: 0.3775
18:13:32,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:58,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:25,119 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1206
en_de Dev loss: 0.9848 r:0.1696
en_zh Dev loss: 0.7909 r:0.4857
Current avg r:0.3277 Best avg r: 0.3775
18:15:42,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:08,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:34,651 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1118
en_de Dev loss: 0.9469 r:0.1608
en_zh Dev loss: 0.7356 r:0.4832
Current avg r:0.3220 Best avg r: 0.3775
18:17:51,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:18,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:44,274 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1156
en_de Dev loss: 0.9641 r:0.1440
en_zh Dev loss: 0.7549 r:0.4841
Current avg r:0.3141 Best avg r: 0.3775
18:20:01,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:28,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:54,277 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1132
en_de Dev loss: 1.0118 r:0.1446
en_zh Dev loss: 0.8280 r:0.4926
Current avg r:0.3186 Best avg r: 0.3775
18:22:11,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:37,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:03,913 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1110
en_de Dev loss: 0.9921 r:0.1482
en_zh Dev loss: 0.8077 r:0.4819
Current avg r:0.3151 Best avg r: 0.3775
18:24:21,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:24:47,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:13,579 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1132
en_de Dev loss: 1.0015 r:0.1474
en_zh Dev loss: 0.8648 r:0.4780
Current avg r:0.3127 Best avg r: 0.3775
18:26:30,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:56,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:23,198 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1164
en_de Dev loss: 0.9461 r:0.1658
en_zh Dev loss: 0.7755 r:0.4793
Current avg r:0.3225 Best avg r: 0.3775
18:28:40,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:06,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:32,836 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1068
en_de Dev loss: 0.9607 r:0.1628
en_zh Dev loss: 0.7310 r:0.4880
Current avg r:0.3254 Best avg r: 0.3775
18:30:50,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:16,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:42,499 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1100
en_de Dev loss: 0.9323 r:0.1791
en_zh Dev loss: 0.7090 r:0.4875
Current avg r:0.3333 Best avg r: 0.3775
18:32:59,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:25,913 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:52,140 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1056
en_de Dev loss: 0.9641 r:0.1638
en_zh Dev loss: 0.7792 r:0.4761
Current avg r:0.3200 Best avg r: 0.3775
18:35:09,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:35,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:01,849 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1105
en_de Dev loss: 0.9566 r:0.1549
en_zh Dev loss: 0.7460 r:0.4726
Current avg r:0.3137 Best avg r: 0.3775
18:37:19,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:37:45,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:11,536 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1106
en_de Dev loss: 0.9887 r:0.1513
en_zh Dev loss: 0.7910 r:0.4758
Current avg r:0.3136 Best avg r: 0.3775
18:39:28,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:54,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:21,192 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1142
en_de Dev loss: 1.0117 r:0.1612
en_zh Dev loss: 0.8212 r:0.4804
Current avg r:0.3208 Best avg r: 0.3775
18:41:38,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:04,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:30,793 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1062
en_de Dev loss: 0.9895 r:0.1563
en_zh Dev loss: 0.7642 r:0.4804
Current avg r:0.3184 Best avg r: 0.3775
18:43:47,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:14,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:40,386 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1118
en_de Dev loss: 0.9911 r:0.1553
en_zh Dev loss: 0.7799 r:0.4773
Current avg r:0.3163 Best avg r: 0.3775
18:45:57,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:23,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:50,25 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1149
en_de Dev loss: 0.9517 r:0.1646
en_zh Dev loss: 0.7478 r:0.4785
Current avg r:0.3216 Best avg r: 0.3775
18:48:07,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:33,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:59,654 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1122
en_de Dev loss: 0.9732 r:0.1699
en_zh Dev loss: 0.7758 r:0.4690
Current avg r:0.3194 Best avg r: 0.3775
18:50:16,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:43,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:09,256 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1132
en_de Dev loss: 0.9850 r:0.1641
en_zh Dev loss: 0.7649 r:0.4840
Current avg r:0.3241 Best avg r: 0.3775
18:52:26,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:53,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:19,326 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1053
en_de Dev loss: 1.0170 r:0.1604
en_zh Dev loss: 0.8064 r:0.4699
Current avg r:0.3151 Best avg r: 0.3775
18:54:36,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:02,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:28,993 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1032
en_de Dev loss: 1.0014 r:0.1553
en_zh Dev loss: 0.7928 r:0.4811
Current avg r:0.3182 Best avg r: 0.3775
18:56:46,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:12,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:38,607 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1004
en_de Dev loss: 1.0020 r:0.1636
en_zh Dev loss: 0.8090 r:0.4809
Current avg r:0.3223 Best avg r: 0.3775
18:58:55,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:21,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:48,234 root INFO Epoch 16 Global steps: 48800 Train loss: 0.0970
en_de Dev loss: 0.9826 r:0.1457
en_zh Dev loss: 0.7675 r:0.4719
Current avg r:0.3088 Best avg r: 0.3775
19:01:05,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:31,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:57,889 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1025
en_de Dev loss: 0.9647 r:0.1684
en_zh Dev loss: 0.7683 r:0.4697
Current avg r:0.3191 Best avg r: 0.3775
19:03:15,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:41,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:07,531 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1018
en_de Dev loss: 0.9796 r:0.1758
en_zh Dev loss: 0.7867 r:0.4800
Current avg r:0.3279 Best avg r: 0.3775
19:05:24,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:50,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:17,155 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1038
en_de Dev loss: 0.9916 r:0.1682
en_zh Dev loss: 0.8236 r:0.4740
Current avg r:0.3211 Best avg r: 0.3775
