14:41:46,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:12,860 root INFO 
id:en_de cur r: 0.0101 best r: 0.0101
14:42:38,732 root INFO 
id:en_zh cur r: 0.1003 best r: 0.1003
14:42:38,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:04,591 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
14:43:04,598 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:43:30,521 root INFO Epoch 0 Global steps: 200 Train loss: 0.8050
en_de Dev loss: 0.8871 r:0.0431
en_zh Dev loss: 0.8174 r:0.1185
Current avg r:0.0808 Best avg r: 0.0808
14:44:47,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:13,564 root INFO 
id:en_de cur r: 0.0462 best r: 0.0462
14:45:39,502 root INFO 
id:en_zh cur r: 0.1826 best r: 0.1826
14:45:39,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:05,447 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
14:46:05,453 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:46:31,446 root INFO Epoch 0 Global steps: 400 Train loss: 0.6495
en_de Dev loss: 0.8904 r:0.0369
en_zh Dev loss: 0.8187 r:0.1564
Current avg r:0.0966 Best avg r: 0.0966
14:47:48,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:14,542 root INFO 
id:en_de cur r: 0.0511 best r: 0.0511
14:48:27,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:53,438 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
14:48:53,447 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:49:19,414 root INFO Epoch 0 Global steps: 600 Train loss: 0.7217
en_de Dev loss: 0.8863 r:0.0852
en_zh Dev loss: 0.8160 r:0.1960
Current avg r:0.1406 Best avg r: 0.1406
14:50:36,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:02,418 root INFO 
id:en_de cur r: 0.0799 best r: 0.0799
14:51:28,368 root INFO 
id:en_zh cur r: 0.2239 best r: 0.2239
14:51:28,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:54,334 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
14:51:54,341 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:52:20,302 root INFO Epoch 0 Global steps: 800 Train loss: 0.7385
en_de Dev loss: 0.8885 r:0.0972
en_zh Dev loss: 0.8144 r:0.2141
Current avg r:0.1556 Best avg r: 0.1556
14:53:37,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:03,382 root INFO 
id:en_de cur r: 0.0978 best r: 0.0978
14:54:29,338 root INFO 
id:en_zh cur r: 0.2770 best r: 0.2770
14:54:29,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:55,303 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
14:54:55,310 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:55:21,285 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7411
en_de Dev loss: 0.8867 r:0.1059
en_zh Dev loss: 0.8100 r:0.2483
Current avg r:0.1771 Best avg r: 0.1771
14:56:38,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:04,325 root INFO 
id:en_de cur r: 0.1087 best r: 0.1087
14:57:30,260 root INFO 
id:en_zh cur r: 0.3095 best r: 0.3095
14:57:30,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:56,216 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
14:57:56,223 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:58:22,203 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7845
en_de Dev loss: 0.8828 r:0.1346
en_zh Dev loss: 0.8042 r:0.2945
Current avg r:0.2146 Best avg r: 0.2146
14:59:39,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:05,359 root INFO 
id:en_de cur r: 0.1314 best r: 0.1314
15:00:31,295 root INFO 
id:en_zh cur r: 0.3402 best r: 0.3402
15:00:31,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:57,260 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:00:57,266 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:01:23,235 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7337
en_de Dev loss: 0.8820 r:0.1364
en_zh Dev loss: 0.7929 r:0.3285
Current avg r:0.2325 Best avg r: 0.2325
15:02:40,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:19,281 root INFO 
id:en_zh cur r: 0.3813 best r: 0.3813
15:03:19,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:45,247 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:03:45,252 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:04:11,220 root INFO Epoch 0 Global steps: 1600 Train loss: 0.6846
en_de Dev loss: 0.8741 r:0.1731
en_zh Dev loss: 0.7526 r:0.3848
Current avg r:0.2790 Best avg r: 0.2790
15:05:28,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:54,264 root INFO 
id:en_de cur r: 0.1571 best r: 0.1571
15:06:20,202 root INFO 
id:en_zh cur r: 0.3921 best r: 0.3921
15:06:20,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:46,163 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:06:46,168 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:07:12,151 root INFO Epoch 0 Global steps: 1800 Train loss: 0.8363
en_de Dev loss: 0.8581 r:0.1844
en_zh Dev loss: 0.6960 r:0.4032
Current avg r:0.2938 Best avg r: 0.2938
15:08:29,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:55,281 root INFO 
id:en_de cur r: 0.1720 best r: 0.1720
15:09:08,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:34,196 root INFO Epoch 0 Global steps: 2000 Train loss: 0.8664
en_de Dev loss: 0.8873 r:0.1778
en_zh Dev loss: 0.7601 r:0.3903
Current avg r:0.2841 Best avg r: 0.2938
15:10:51,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:17,317 root INFO 
id:en_de cur r: 0.1776 best r: 0.1776
15:11:43,271 root INFO 
id:en_zh cur r: 0.4071 best r: 0.4071
15:11:43,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:09,241 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:12:09,247 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:12:35,222 root INFO Epoch 0 Global steps: 2200 Train loss: 0.6518
en_de Dev loss: 0.8571 r:0.2027
en_zh Dev loss: 0.6964 r:0.4153
Current avg r:0.3090 Best avg r: 0.3090
15:13:52,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:18,335 root INFO 
id:en_de cur r: 0.1858 best r: 0.1858
15:14:31,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:57,251 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:14:57,257 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:15:23,259 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6810
en_de Dev loss: 0.8844 r:0.2173
en_zh Dev loss: 0.7494 r:0.4089
Current avg r:0.3131 Best avg r: 0.3131
15:16:40,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:06,415 root INFO 
id:en_de cur r: 0.2228 best r: 0.2228
15:17:32,375 root INFO 
id:en_zh cur r: 0.4321 best r: 0.4321
15:17:32,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:58,353 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:17:58,360 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:18:24,328 root INFO Epoch 0 Global steps: 2600 Train loss: 0.6543
en_de Dev loss: 0.8508 r:0.2274
en_zh Dev loss: 0.7030 r:0.4388
Current avg r:0.3331 Best avg r: 0.3331
15:19:41,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:07,492 root INFO 
id:en_de cur r: 0.2271 best r: 0.2271
15:20:33,455 root INFO 
id:en_zh cur r: 0.4365 best r: 0.4365
15:20:33,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:59,420 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:20:59,426 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:21:25,401 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6217
en_de Dev loss: 0.8473 r:0.2365
en_zh Dev loss: 0.6815 r:0.4450
Current avg r:0.3408 Best avg r: 0.3408
15:22:42,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:08,605 root INFO 
id:en_de cur r: 0.2297 best r: 0.2297
15:23:34,542 root INFO 
id:en_zh cur r: 0.4516 best r: 0.4516
15:23:34,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:00,484 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:24:00,489 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:24:26,462 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6838
en_de Dev loss: 0.8470 r:0.2390
en_zh Dev loss: 0.6555 r:0.4573
Current avg r:0.3481 Best avg r: 0.3481
15:25:44,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:10,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:35,962 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6164
en_de Dev loss: 0.8701 r:0.2346
en_zh Dev loss: 0.7147 r:0.4421
Current avg r:0.3384 Best avg r: 0.3481
15:27:53,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:28:19,31 root INFO 
id:en_de cur r: 0.2478 best r: 0.2478
15:28:44,969 root INFO 
id:en_zh cur r: 0.4586 best r: 0.4586
15:28:44,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:10,914 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:29:10,921 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:29:36,901 root INFO Epoch 1 Global steps: 3400 Train loss: 0.6284
en_de Dev loss: 0.8425 r:0.2579
en_zh Dev loss: 0.6738 r:0.4557
Current avg r:0.3568 Best avg r: 0.3568
15:30:53,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:19,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:45,863 root INFO Epoch 1 Global steps: 3600 Train loss: 0.5612
en_de Dev loss: 0.8505 r:0.2428
en_zh Dev loss: 0.6782 r:0.4565
Current avg r:0.3497 Best avg r: 0.3568
15:33:03,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:29,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:54,957 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6250
en_de Dev loss: 0.8588 r:0.2408
en_zh Dev loss: 0.8179 r:0.4531
Current avg r:0.3470 Best avg r: 0.3568
15:35:12,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:38,51 root INFO 
id:en_de cur r: 0.2509 best r: 0.2509
15:36:04,10 root INFO 
id:en_zh cur r: 0.4660 best r: 0.4660
15:36:04,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:29,982 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:36:29,988 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:36:55,992 root INFO Epoch 1 Global steps: 4000 Train loss: 0.5919
en_de Dev loss: 0.8401 r:0.2551
en_zh Dev loss: 0.7525 r:0.4630
Current avg r:0.3590 Best avg r: 0.3590
15:38:13,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:51,992 root INFO 
id:en_zh cur r: 0.4709 best r: 0.4709
15:38:51,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:17,943 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:39:17,948 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:39:43,933 root INFO Epoch 1 Global steps: 4200 Train loss: 0.6442
en_de Dev loss: 0.8573 r:0.2519
en_zh Dev loss: 0.7913 r:0.4667
Current avg r:0.3593 Best avg r: 0.3593
15:41:01,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:27,34 root INFO 
id:en_de cur r: 0.2588 best r: 0.2588
15:41:52,964 root INFO 
id:en_zh cur r: 0.4763 best r: 0.4763
15:41:52,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:18,927 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:42:18,934 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:42:44,907 root INFO Epoch 1 Global steps: 4400 Train loss: 0.6625
en_de Dev loss: 0.8450 r:0.2568
en_zh Dev loss: 0.6825 r:0.4701
Current avg r:0.3634 Best avg r: 0.3634
15:44:01,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:40,891 root INFO 
id:en_zh cur r: 0.4775 best r: 0.4775
15:44:40,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:06,836 root INFO Epoch 1 Global steps: 4600 Train loss: 0.6300
en_de Dev loss: 0.8481 r:0.2460
en_zh Dev loss: 0.6980 r:0.4730
Current avg r:0.3595 Best avg r: 0.3634
15:46:24,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:02,963 root INFO 
id:en_zh cur r: 0.4885 best r: 0.4885
15:47:02,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:28,914 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:47:28,920 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:47:54,919 root INFO Epoch 1 Global steps: 4800 Train loss: 0.5355
en_de Dev loss: 0.8360 r:0.2473
en_zh Dev loss: 0.6376 r:0.4833
Current avg r:0.3653 Best avg r: 0.3653
15:49:12,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:38,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:03,958 root INFO Epoch 1 Global steps: 5000 Train loss: 0.5988
en_de Dev loss: 0.8593 r:0.2392
en_zh Dev loss: 0.7066 r:0.4716
Current avg r:0.3554 Best avg r: 0.3653
15:51:21,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:47,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:12,972 root INFO Epoch 1 Global steps: 5200 Train loss: 0.5759
en_de Dev loss: 0.8442 r:0.2388
en_zh Dev loss: 0.6876 r:0.4770
Current avg r:0.3579 Best avg r: 0.3653
15:53:30,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:55,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:21,901 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:54:21,907 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:54:47,873 root INFO Epoch 1 Global steps: 5400 Train loss: 0.6436
en_de Dev loss: 0.8359 r:0.2533
en_zh Dev loss: 0.6916 r:0.4802
Current avg r:0.3667 Best avg r: 0.3667
15:56:05,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:31,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:57,26 root INFO Epoch 1 Global steps: 5600 Train loss: 0.5630
en_de Dev loss: 0.8495 r:0.2437
en_zh Dev loss: 0.7169 r:0.4751
Current avg r:0.3594 Best avg r: 0.3667
15:58:14,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:53,54 root INFO 
id:en_zh cur r: 0.5054 best r: 0.5054
15:58:53,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:19,15 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
15:59:19,20 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:59:45,18 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6701
en_de Dev loss: 0.8397 r:0.2419
en_zh Dev loss: 0.6431 r:0.5011
Current avg r:0.3715 Best avg r: 0.3715
16:01:02,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:41,126 root INFO 
id:en_zh cur r: 0.5069 best r: 0.5069
16:01:41,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:07,73 root INFO Epoch 1 Global steps: 6000 Train loss: 0.6738
en_de Dev loss: 0.8420 r:0.2342
en_zh Dev loss: 0.6748 r:0.5023
Current avg r:0.3683 Best avg r: 0.3715
16:03:24,549 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:03,461 root INFO 
id:en_zh cur r: 0.5147 best r: 0.5147
16:04:03,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:29,432 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
16:04:29,440 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:04:55,443 root INFO Epoch 2 Global steps: 6200 Train loss: 0.5786
en_de Dev loss: 0.8364 r:0.2470
en_zh Dev loss: 0.6479 r:0.5110
Current avg r:0.3790 Best avg r: 0.3790
16:06:12,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:38,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:04,450 root INFO Epoch 2 Global steps: 6400 Train loss: 0.5367
en_de Dev loss: 0.8323 r:0.2571
en_zh Dev loss: 0.6747 r:0.4882
Current avg r:0.3726 Best avg r: 0.3790
16:08:21,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:08:47,599 root INFO 
id:en_de cur r: 0.2614 best r: 0.2614
16:09:00,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:26,500 root INFO Epoch 2 Global steps: 6600 Train loss: 0.4975
en_de Dev loss: 0.8406 r:0.2621
en_zh Dev loss: 0.6804 r:0.4945
Current avg r:0.3783 Best avg r: 0.3790
16:10:43,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:09,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:35,556 root INFO Epoch 2 Global steps: 6800 Train loss: 0.5839
en_de Dev loss: 0.8440 r:0.2468
en_zh Dev loss: 0.6642 r:0.5061
Current avg r:0.3765 Best avg r: 0.3790
16:12:52,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:18,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:44,706 root INFO Epoch 2 Global steps: 7000 Train loss: 0.5384
en_de Dev loss: 0.8394 r:0.2491
en_zh Dev loss: 0.6522 r:0.5077
Current avg r:0.3784 Best avg r: 0.3790
16:15:01,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:27,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:53,832 root INFO Epoch 2 Global steps: 7200 Train loss: 0.5156
en_de Dev loss: 0.8636 r:0.2422
en_zh Dev loss: 0.7376 r:0.4950
Current avg r:0.3686 Best avg r: 0.3790
16:17:10,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:36,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:02,866 root INFO Epoch 2 Global steps: 7400 Train loss: 0.5310
en_de Dev loss: 0.8439 r:0.2484
en_zh Dev loss: 0.7459 r:0.4953
Current avg r:0.3718 Best avg r: 0.3790
16:19:19,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:45,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:11,899 root INFO Epoch 2 Global steps: 7600 Train loss: 0.6511
en_de Dev loss: 0.8474 r:0.2343
en_zh Dev loss: 0.7774 r:0.4770
Current avg r:0.3557 Best avg r: 0.3790
16:21:29,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:21:54,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:20,924 root INFO Epoch 2 Global steps: 7800 Train loss: 0.5544
en_de Dev loss: 0.8431 r:0.2386
en_zh Dev loss: 0.7498 r:0.4817
Current avg r:0.3601 Best avg r: 0.3790
16:23:38,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:03,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:24:29,873 root INFO Epoch 2 Global steps: 8000 Train loss: 0.6193
en_de Dev loss: 0.8570 r:0.2307
en_zh Dev loss: 0.7154 r:0.5050
Current avg r:0.3678 Best avg r: 0.3790
16:25:46,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:12,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:38,880 root INFO Epoch 2 Global steps: 8200 Train loss: 0.4926
en_de Dev loss: 0.8565 r:0.2204
en_zh Dev loss: 0.7338 r:0.5014
Current avg r:0.3609 Best avg r: 0.3790
16:27:56,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:22,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:47,991 root INFO Epoch 2 Global steps: 8400 Train loss: 0.5515
en_de Dev loss: 0.8567 r:0.2359
en_zh Dev loss: 0.7537 r:0.4940
Current avg r:0.3650 Best avg r: 0.3790
16:30:05,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:31,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:57,59 root INFO Epoch 2 Global steps: 8600 Train loss: 0.5238
en_de Dev loss: 0.8697 r:0.2331
en_zh Dev loss: 0.7725 r:0.4894
Current avg r:0.3612 Best avg r: 0.3790
16:32:14,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:40,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:06,127 root INFO Epoch 2 Global steps: 8800 Train loss: 0.5939
en_de Dev loss: 0.8555 r:0.2183
en_zh Dev loss: 0.6889 r:0.5048
Current avg r:0.3615 Best avg r: 0.3790
16:34:23,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:49,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:15,327 root INFO Epoch 2 Global steps: 9000 Train loss: 0.4789
en_de Dev loss: 0.8491 r:0.2213
en_zh Dev loss: 0.6686 r:0.4944
Current avg r:0.3578 Best avg r: 0.3790
16:36:32,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:58,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:24,689 root INFO Epoch 3 Global steps: 9200 Train loss: 0.4785
en_de Dev loss: 0.8474 r:0.2239
en_zh Dev loss: 0.6927 r:0.4984
Current avg r:0.3611 Best avg r: 0.3790
16:38:41,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:07,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:33,707 root INFO Epoch 3 Global steps: 9400 Train loss: 0.5881
en_de Dev loss: 0.8525 r:0.2251
en_zh Dev loss: 0.7233 r:0.5004
Current avg r:0.3627 Best avg r: 0.3790
16:40:50,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:16,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:42,753 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_de.lang_agnost_mlp.dev.best.scores
16:41:42,759 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:42:08,738 root INFO Epoch 3 Global steps: 9600 Train loss: 0.4242
en_de Dev loss: 0.8295 r:0.2587
en_zh Dev loss: 0.6906 r:0.5002
Current avg r:0.3794 Best avg r: 0.3794
16:43:25,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:51,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:17,930 root INFO Epoch 3 Global steps: 9800 Train loss: 0.4083
en_de Dev loss: 0.8454 r:0.2337
en_zh Dev loss: 0.6809 r:0.5077
Current avg r:0.3707 Best avg r: 0.3794
16:45:34,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:00,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:26,878 root INFO Epoch 3 Global steps: 10000 Train loss: 0.5090
en_de Dev loss: 0.8804 r:0.2233
en_zh Dev loss: 0.8212 r:0.4847
Current avg r:0.3540 Best avg r: 0.3794
16:47:43,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:09,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:35,798 root INFO Epoch 3 Global steps: 10200 Train loss: 0.4295
en_de Dev loss: 0.8569 r:0.2293
en_zh Dev loss: 0.6869 r:0.5089
Current avg r:0.3691 Best avg r: 0.3794
16:49:52,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:18,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:44,757 root INFO Epoch 3 Global steps: 10400 Train loss: 0.4871
en_de Dev loss: 0.8596 r:0.2284
en_zh Dev loss: 0.7035 r:0.5029
Current avg r:0.3657 Best avg r: 0.3794
16:52:01,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:27,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:53,748 root INFO Epoch 3 Global steps: 10600 Train loss: 0.5005
en_de Dev loss: 0.8581 r:0.2219
en_zh Dev loss: 0.7112 r:0.5013
Current avg r:0.3616 Best avg r: 0.3794
16:54:10,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:36,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:02,750 root INFO Epoch 3 Global steps: 10800 Train loss: 0.4863
en_de Dev loss: 0.8425 r:0.2326
en_zh Dev loss: 0.6647 r:0.4956
Current avg r:0.3641 Best avg r: 0.3794
16:56:19,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:45,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:11,795 root INFO Epoch 3 Global steps: 11000 Train loss: 0.4743
en_de Dev loss: 0.8676 r:0.2498
en_zh Dev loss: 0.7900 r:0.4598
Current avg r:0.3548 Best avg r: 0.3794
16:58:28,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:54,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:20,815 root INFO Epoch 3 Global steps: 11200 Train loss: 0.4998
en_de Dev loss: 0.8730 r:0.2233
en_zh Dev loss: 0.7276 r:0.5007
Current avg r:0.3620 Best avg r: 0.3794
17:00:37,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:03,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:29,830 root INFO Epoch 3 Global steps: 11400 Train loss: 0.4569
en_de Dev loss: 0.8547 r:0.2392
en_zh Dev loss: 0.7271 r:0.4933
Current avg r:0.3663 Best avg r: 0.3794
17:02:46,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:12,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:38,870 root INFO Epoch 3 Global steps: 11600 Train loss: 0.5495
en_de Dev loss: 0.8684 r:0.2353
en_zh Dev loss: 0.7924 r:0.4769
Current avg r:0.3561 Best avg r: 0.3794
17:04:56,70 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:22,42 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:48,39 root INFO Epoch 3 Global steps: 11800 Train loss: 0.4367
en_de Dev loss: 0.8631 r:0.2428
en_zh Dev loss: 0.7761 r:0.4748
Current avg r:0.3588 Best avg r: 0.3794
17:07:05,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:31,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:57,279 root INFO Epoch 3 Global steps: 12000 Train loss: 0.4548
en_de Dev loss: 0.8489 r:0.2462
en_zh Dev loss: 0.7483 r:0.4719
Current avg r:0.3590 Best avg r: 0.3794
17:09:14,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:40,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:10:06,604 root INFO Epoch 4 Global steps: 12200 Train loss: 0.3848
en_de Dev loss: 0.8629 r:0.2529
en_zh Dev loss: 0.8055 r:0.4382
Current avg r:0.3456 Best avg r: 0.3794
17:11:23,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:49,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:15,612 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4028
en_de Dev loss: 0.8492 r:0.2466
en_zh Dev loss: 0.7231 r:0.4705
Current avg r:0.3586 Best avg r: 0.3794
17:13:32,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:58,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:24,840 root INFO Epoch 4 Global steps: 12600 Train loss: 0.4376
en_de Dev loss: 0.8669 r:0.2220
en_zh Dev loss: 0.7395 r:0.4781
Current avg r:0.3500 Best avg r: 0.3794
17:15:42,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:08,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:34,27 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4681
en_de Dev loss: 0.8751 r:0.2090
en_zh Dev loss: 0.7579 r:0.4927
Current avg r:0.3508 Best avg r: 0.3794
17:17:51,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:17,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:43,84 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4275
en_de Dev loss: 0.8419 r:0.2460
en_zh Dev loss: 0.7172 r:0.4669
Current avg r:0.3564 Best avg r: 0.3794
17:20:00,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:26,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:52,293 root INFO Epoch 4 Global steps: 13200 Train loss: 0.4191
en_de Dev loss: 0.8599 r:0.2273
en_zh Dev loss: 0.7422 r:0.4708
Current avg r:0.3490 Best avg r: 0.3794
17:22:09,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:35,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:01,394 root INFO Epoch 4 Global steps: 13400 Train loss: 0.3634
en_de Dev loss: 0.8648 r:0.2313
en_zh Dev loss: 0.7438 r:0.4849
Current avg r:0.3581 Best avg r: 0.3794
17:24:18,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:44,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:10,433 root INFO Epoch 4 Global steps: 13600 Train loss: 0.4043
en_de Dev loss: 0.8604 r:0.2362
en_zh Dev loss: 0.8213 r:0.4814
Current avg r:0.3588 Best avg r: 0.3794
17:26:27,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:53,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:19,513 root INFO Epoch 4 Global steps: 13800 Train loss: 0.4229
en_de Dev loss: 0.8457 r:0.2484
en_zh Dev loss: 0.7430 r:0.4761
Current avg r:0.3622 Best avg r: 0.3794
17:28:36,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:02,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:28,647 root INFO Epoch 4 Global steps: 14000 Train loss: 0.4036
en_de Dev loss: 0.8759 r:0.2357
en_zh Dev loss: 0.8139 r:0.4714
Current avg r:0.3535 Best avg r: 0.3794
17:30:45,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:11,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:37,856 root INFO Epoch 4 Global steps: 14200 Train loss: 0.4249
en_de Dev loss: 0.8680 r:0.2351
en_zh Dev loss: 0.8179 r:0.4487
Current avg r:0.3419 Best avg r: 0.3794
17:32:55,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:21,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:47,15 root INFO Epoch 4 Global steps: 14400 Train loss: 0.3645
en_de Dev loss: 0.8644 r:0.2277
en_zh Dev loss: 0.7657 r:0.4612
Current avg r:0.3445 Best avg r: 0.3794
17:35:04,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:30,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:56,210 root INFO Epoch 4 Global steps: 14600 Train loss: 0.3830
en_de Dev loss: 0.8535 r:0.2167
en_zh Dev loss: 0.7052 r:0.4860
Current avg r:0.3513 Best avg r: 0.3794
17:37:13,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:39,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:05,320 root INFO Epoch 4 Global steps: 14800 Train loss: 0.4107
en_de Dev loss: 0.8610 r:0.2454
en_zh Dev loss: 0.8241 r:0.4579
Current avg r:0.3516 Best avg r: 0.3794
17:39:22,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:48,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:14,313 root INFO Epoch 4 Global steps: 15000 Train loss: 0.4133
en_de Dev loss: 0.8600 r:0.2347
en_zh Dev loss: 0.7813 r:0.4707
Current avg r:0.3527 Best avg r: 0.3794
17:41:31,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:57,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:23,873 root INFO Epoch 5 Global steps: 15200 Train loss: 0.3735
en_de Dev loss: 0.8593 r:0.2330
en_zh Dev loss: 0.8168 r:0.4571
Current avg r:0.3450 Best avg r: 0.3794
17:43:41,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:07,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:33,81 root INFO Epoch 5 Global steps: 15400 Train loss: 0.2958
en_de Dev loss: 0.8697 r:0.2280
en_zh Dev loss: 0.7932 r:0.4666
Current avg r:0.3473 Best avg r: 0.3794
17:45:50,355 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:16,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:42,307 root INFO Epoch 5 Global steps: 15600 Train loss: 0.3457
en_de Dev loss: 0.8388 r:0.2382
en_zh Dev loss: 0.7201 r:0.4532
Current avg r:0.3457 Best avg r: 0.3794
17:47:59,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:25,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:51,458 root INFO Epoch 5 Global steps: 15800 Train loss: 0.3571
en_de Dev loss: 0.8537 r:0.2329
en_zh Dev loss: 0.7597 r:0.4638
Current avg r:0.3484 Best avg r: 0.3794
17:50:08,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:34,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:00,627 root INFO Epoch 5 Global steps: 16000 Train loss: 0.3590
en_de Dev loss: 0.8606 r:0.2345
en_zh Dev loss: 0.7423 r:0.4657
Current avg r:0.3501 Best avg r: 0.3794
17:52:17,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:43,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:09,751 root INFO Epoch 5 Global steps: 16200 Train loss: 0.3644
en_de Dev loss: 0.8471 r:0.2442
en_zh Dev loss: 0.7721 r:0.4617
Current avg r:0.3529 Best avg r: 0.3794
17:54:26,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:52,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:18,784 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3186
en_de Dev loss: 0.8716 r:0.2527
en_zh Dev loss: 0.8140 r:0.4639
Current avg r:0.3583 Best avg r: 0.3794
17:56:35,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:01,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:27,912 root INFO Epoch 5 Global steps: 16600 Train loss: 0.3562
en_de Dev loss: 0.8617 r:0.2512
en_zh Dev loss: 0.7897 r:0.4594
Current avg r:0.3553 Best avg r: 0.3794
17:58:45,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:11,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:37,115 root INFO Epoch 5 Global steps: 16800 Train loss: 0.3374
en_de Dev loss: 0.8821 r:0.2314
en_zh Dev loss: 0.7331 r:0.4743
Current avg r:0.3528 Best avg r: 0.3794
18:00:54,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:20,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:46,142 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3692
en_de Dev loss: 0.8448 r:0.2508
en_zh Dev loss: 0.7121 r:0.4607
Current avg r:0.3558 Best avg r: 0.3794
18:03:03,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:29,283 root INFO 
id:en_de cur r: 0.2617 best r: 0.2617
18:03:42,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:08,192 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3126
en_de Dev loss: 0.8415 r:0.2578
en_zh Dev loss: 0.7410 r:0.4618
Current avg r:0.3598 Best avg r: 0.3794
18:05:25,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:51,321 root INFO 
id:en_de cur r: 0.2684 best r: 0.2684
18:06:04,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:30,244 root INFO Epoch 5 Global steps: 17400 Train loss: 0.3619
en_de Dev loss: 0.8688 r:0.2646
en_zh Dev loss: 0.8180 r:0.4629
Current avg r:0.3637 Best avg r: 0.3794
18:07:47,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:13,416 root INFO 
id:en_de cur r: 0.2690 best r: 0.2690
18:08:26,402 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:52,372 root INFO Epoch 5 Global steps: 17600 Train loss: 0.3579
en_de Dev loss: 0.8408 r:0.2648
en_zh Dev loss: 0.7830 r:0.4532
Current avg r:0.3590 Best avg r: 0.3794
18:10:09,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:35,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:01,487 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3430
en_de Dev loss: 0.8429 r:0.2470
en_zh Dev loss: 0.7755 r:0.4621
Current avg r:0.3545 Best avg r: 0.3794
18:12:18,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:44,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:10,519 root INFO Epoch 5 Global steps: 18000 Train loss: 0.3225
en_de Dev loss: 0.8693 r:0.2372
en_zh Dev loss: 0.8144 r:0.4625
Current avg r:0.3499 Best avg r: 0.3794
18:14:28,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:54,139 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:20,115 root INFO Epoch 6 Global steps: 18200 Train loss: 0.3038
en_de Dev loss: 0.8694 r:0.2213
en_zh Dev loss: 0.7811 r:0.4713
Current avg r:0.3463 Best avg r: 0.3794
18:16:37,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:03,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:29,223 root INFO Epoch 6 Global steps: 18400 Train loss: 0.3036
en_de Dev loss: 0.8559 r:0.2545
en_zh Dev loss: 0.8231 r:0.4615
Current avg r:0.3580 Best avg r: 0.3794
18:18:46,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:12,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:38,256 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3097
en_de Dev loss: 0.8713 r:0.2348
en_zh Dev loss: 0.8334 r:0.4655
Current avg r:0.3502 Best avg r: 0.3794
18:20:55,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:21,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:47,262 root INFO Epoch 6 Global steps: 18800 Train loss: 0.2829
en_de Dev loss: 0.8948 r:0.2201
en_zh Dev loss: 0.8066 r:0.4608
Current avg r:0.3404 Best avg r: 0.3794
18:23:04,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:30,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:56,305 root INFO Epoch 6 Global steps: 19000 Train loss: 0.2946
en_de Dev loss: 0.8693 r:0.2303
en_zh Dev loss: 0.7556 r:0.4771
Current avg r:0.3537 Best avg r: 0.3794
18:25:13,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:39,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:05,337 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3024
en_de Dev loss: 0.8666 r:0.2400
en_zh Dev loss: 0.7626 r:0.4702
Current avg r:0.3551 Best avg r: 0.3794
18:27:22,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:48,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:14,300 root INFO Epoch 6 Global steps: 19400 Train loss: 0.2901
en_de Dev loss: 0.8699 r:0.2210
en_zh Dev loss: 0.7710 r:0.4745
Current avg r:0.3478 Best avg r: 0.3794
18:29:31,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:57,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:23,343 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3390
en_de Dev loss: 0.8736 r:0.2270
en_zh Dev loss: 0.8206 r:0.4707
Current avg r:0.3489 Best avg r: 0.3794
18:31:40,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:06,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:32,305 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3156
en_de Dev loss: 0.8449 r:0.2580
en_zh Dev loss: 0.7772 r:0.4677
Current avg r:0.3628 Best avg r: 0.3794
18:33:49,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:15,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:41,413 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3279
en_de Dev loss: 0.8553 r:0.2376
en_zh Dev loss: 0.8124 r:0.4688
Current avg r:0.3532 Best avg r: 0.3794
18:35:58,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:24,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:50,568 root INFO Epoch 6 Global steps: 20200 Train loss: 0.2983
en_de Dev loss: 0.8606 r:0.2277
en_zh Dev loss: 0.7298 r:0.4859
Current avg r:0.3568 Best avg r: 0.3794
18:38:07,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:33,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:59,745 root INFO Epoch 6 Global steps: 20400 Train loss: 0.2528
en_de Dev loss: 0.9055 r:0.2225
en_zh Dev loss: 0.7626 r:0.4885
Current avg r:0.3555 Best avg r: 0.3794
18:40:16,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:42,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:08,755 root INFO Epoch 6 Global steps: 20600 Train loss: 0.2948
en_de Dev loss: 0.8531 r:0.2433
en_zh Dev loss: 0.7359 r:0.4866
Current avg r:0.3649 Best avg r: 0.3794
18:42:25,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:51,729 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:17,685 root INFO Epoch 6 Global steps: 20800 Train loss: 0.3013
en_de Dev loss: 0.8748 r:0.2352
en_zh Dev loss: 0.7988 r:0.4671
Current avg r:0.3512 Best avg r: 0.3794
18:44:34,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:00,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:26,746 root INFO Epoch 6 Global steps: 21000 Train loss: 0.2820
en_de Dev loss: 0.9090 r:0.2261
en_zh Dev loss: 0.8226 r:0.4837
Current avg r:0.3549 Best avg r: 0.3794
18:46:44,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:10,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:36,315 root INFO Epoch 7 Global steps: 21200 Train loss: 0.2777
en_de Dev loss: 0.8547 r:0.2424
en_zh Dev loss: 0.7323 r:0.4894
Current avg r:0.3659 Best avg r: 0.3794
18:48:53,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:19,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:45,430 root INFO Epoch 7 Global steps: 21400 Train loss: 0.2737
en_de Dev loss: 0.8745 r:0.2293
en_zh Dev loss: 0.7471 r:0.4861
Current avg r:0.3577 Best avg r: 0.3794
18:51:02,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:28,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:54,448 root INFO Epoch 7 Global steps: 21600 Train loss: 0.2768
en_de Dev loss: 0.8649 r:0.2379
en_zh Dev loss: 0.7606 r:0.4753
Current avg r:0.3566 Best avg r: 0.3794
18:53:11,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:37,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:03,485 root INFO Epoch 7 Global steps: 21800 Train loss: 0.2893
en_de Dev loss: 0.8736 r:0.2299
en_zh Dev loss: 0.7131 r:0.4899
Current avg r:0.3599 Best avg r: 0.3794
18:55:20,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:46,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:56:12,447 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2534
en_de Dev loss: 0.8581 r:0.2464
en_zh Dev loss: 0.7577 r:0.4737
Current avg r:0.3601 Best avg r: 0.3794
18:57:29,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:55,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:21,326 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2745
en_de Dev loss: 0.8862 r:0.2328
en_zh Dev loss: 0.7802 r:0.4664
Current avg r:0.3496 Best avg r: 0.3794
18:59:38,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:04,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:30,236 root INFO Epoch 7 Global steps: 22400 Train loss: 0.2578
en_de Dev loss: 0.8581 r:0.2210
en_zh Dev loss: 0.7197 r:0.4765
Current avg r:0.3487 Best avg r: 0.3794
19:01:47,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:13,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:39,111 root INFO Epoch 7 Global steps: 22600 Train loss: 0.2282
en_de Dev loss: 0.8833 r:0.2257
en_zh Dev loss: 0.8059 r:0.4699
Current avg r:0.3478 Best avg r: 0.3794
19:03:56,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:22,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:48,64 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2636
en_de Dev loss: 0.8846 r:0.2334
en_zh Dev loss: 0.8156 r:0.4786
Current avg r:0.3560 Best avg r: 0.3794
19:06:05,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:31,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:57,195 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2997
en_de Dev loss: 0.8898 r:0.2521
en_zh Dev loss: 0.8457 r:0.4840
Current avg r:0.3681 Best avg r: 0.3794
19:08:14,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:40,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:06,250 root INFO Epoch 7 Global steps: 23200 Train loss: 0.2682
en_de Dev loss: 0.8597 r:0.2303
en_zh Dev loss: 0.7397 r:0.4905
Current avg r:0.3604 Best avg r: 0.3794
19:10:23,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:49,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:15,291 root INFO Epoch 7 Global steps: 23400 Train loss: 0.2885
en_de Dev loss: 0.8863 r:0.2318
en_zh Dev loss: 0.7850 r:0.4965
Current avg r:0.3641 Best avg r: 0.3794
19:12:32,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:58,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:24,256 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2311
en_de Dev loss: 0.8764 r:0.2286
en_zh Dev loss: 0.7956 r:0.4667
Current avg r:0.3477 Best avg r: 0.3794
19:14:41,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:07,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:33,388 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2388
en_de Dev loss: 0.8974 r:0.2126
en_zh Dev loss: 0.7922 r:0.4840
Current avg r:0.3483 Best avg r: 0.3794
19:16:50,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:16,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:42,436 root INFO Epoch 7 Global steps: 24000 Train loss: 0.2390
en_de Dev loss: 0.8927 r:0.2116
en_zh Dev loss: 0.7934 r:0.4828
Current avg r:0.3472 Best avg r: 0.3794
19:19:00,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:25,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:51,887 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2382
en_de Dev loss: 0.8870 r:0.2009
en_zh Dev loss: 0.7256 r:0.4973
Current avg r:0.3491 Best avg r: 0.3794
19:21:08,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:34,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:00,865 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2382
en_de Dev loss: 0.8869 r:0.2027
en_zh Dev loss: 0.7676 r:0.4878
Current avg r:0.3452 Best avg r: 0.3794
19:23:17,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:43,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:09,886 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2433
en_de Dev loss: 0.8734 r:0.2223
en_zh Dev loss: 0.7804 r:0.4862
Current avg r:0.3543 Best avg r: 0.3794
19:25:27,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:52,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:18,892 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2594
en_de Dev loss: 0.8823 r:0.2149
en_zh Dev loss: 0.7238 r:0.4999
Current avg r:0.3574 Best avg r: 0.3794
19:27:35,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:01,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:27,834 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2271
en_de Dev loss: 0.8677 r:0.2345
en_zh Dev loss: 0.7542 r:0.4849
Current avg r:0.3597 Best avg r: 0.3794
19:29:44,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:10,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:36,893 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2471
en_de Dev loss: 0.8805 r:0.2230
en_zh Dev loss: 0.7558 r:0.4978
Current avg r:0.3604 Best avg r: 0.3794
19:31:53,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:19,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:45,865 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2447
en_de Dev loss: 0.8750 r:0.2194
en_zh Dev loss: 0.7897 r:0.4792
Current avg r:0.3493 Best avg r: 0.3794
19:34:02,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:28,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:54,807 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2311
en_de Dev loss: 0.8814 r:0.2371
en_zh Dev loss: 0.8525 r:0.4694
Current avg r:0.3533 Best avg r: 0.3794
19:36:11,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:37,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:03,893 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2449
en_de Dev loss: 0.8669 r:0.2336
en_zh Dev loss: 0.7535 r:0.4845
Current avg r:0.3590 Best avg r: 0.3794
19:38:21,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:47,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:39:13,95 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2304
en_de Dev loss: 0.8963 r:0.2267
en_zh Dev loss: 0.7530 r:0.4926
Current avg r:0.3597 Best avg r: 0.3794
19:40:30,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:56,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:22,233 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2144
en_de Dev loss: 0.8943 r:0.2340
en_zh Dev loss: 0.7784 r:0.4909
Current avg r:0.3624 Best avg r: 0.3794
19:42:39,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:05,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:31,305 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2603
en_de Dev loss: 0.9154 r:0.2115
en_zh Dev loss: 0.7627 r:0.4903
Current avg r:0.3509 Best avg r: 0.3794
19:44:48,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:14,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:40,505 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2170
en_de Dev loss: 0.8889 r:0.2361
en_zh Dev loss: 0.7744 r:0.4845
Current avg r:0.3603 Best avg r: 0.3794
19:46:57,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:23,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:49,679 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2270
en_de Dev loss: 0.8698 r:0.2260
en_zh Dev loss: 0.7366 r:0.4865
Current avg r:0.3563 Best avg r: 0.3794
19:49:06,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:32,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:58,756 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2350
en_de Dev loss: 0.8765 r:0.2441
en_zh Dev loss: 0.7709 r:0.4834
Current avg r:0.3637 Best avg r: 0.3794
19:51:16,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:42,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:08,57 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2523
en_de Dev loss: 0.8761 r:0.2292
en_zh Dev loss: 0.7792 r:0.4864
Current avg r:0.3578 Best avg r: 0.3794
19:53:25,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:51,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:17,45 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2167
en_de Dev loss: 0.8721 r:0.2340
en_zh Dev loss: 0.7527 r:0.4973
Current avg r:0.3656 Best avg r: 0.3794
19:55:34,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:00,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:25,986 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2213
en_de Dev loss: 0.8525 r:0.2391
en_zh Dev loss: 0.7219 r:0.4954
Current avg r:0.3672 Best avg r: 0.3794
19:57:43,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:08,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:34,948 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2056
en_de Dev loss: 0.8796 r:0.2497
en_zh Dev loss: 0.7903 r:0.4872
Current avg r:0.3685 Best avg r: 0.3794
19:59:52,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:18,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:43,965 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2159
en_de Dev loss: 0.8798 r:0.2320
en_zh Dev loss: 0.7891 r:0.4869
Current avg r:0.3594 Best avg r: 0.3794
20:02:01,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:27,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:52,981 root INFO Epoch 9 Global steps: 28200 Train loss: 0.1953
en_de Dev loss: 0.9184 r:0.2118
en_zh Dev loss: 0.8312 r:0.4871
Current avg r:0.3495 Best avg r: 0.3794
20:04:10,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:36,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:01,942 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2047
en_de Dev loss: 0.9110 r:0.2150
en_zh Dev loss: 0.8569 r:0.4781
Current avg r:0.3466 Best avg r: 0.3794
20:06:19,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:45,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:10,959 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2343
en_de Dev loss: 0.8983 r:0.2012
en_zh Dev loss: 0.7560 r:0.4927
Current avg r:0.3470 Best avg r: 0.3794
20:08:28,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:54,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:20,14 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2160
en_de Dev loss: 0.8938 r:0.2115
en_zh Dev loss: 0.7738 r:0.4822
Current avg r:0.3468 Best avg r: 0.3794
20:10:37,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:03,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:29,101 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2147
en_de Dev loss: 0.8786 r:0.2076
en_zh Dev loss: 0.7230 r:0.4886
Current avg r:0.3481 Best avg r: 0.3794
20:12:46,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:12,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:38,175 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2033
en_de Dev loss: 0.8820 r:0.2121
en_zh Dev loss: 0.7208 r:0.4840
Current avg r:0.3481 Best avg r: 0.3794
20:14:55,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:21,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:47,266 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2037
en_de Dev loss: 0.9041 r:0.2125
en_zh Dev loss: 0.7652 r:0.4778
Current avg r:0.3452 Best avg r: 0.3794
20:17:04,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:30,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:56,316 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2049
en_de Dev loss: 0.8914 r:0.2082
en_zh Dev loss: 0.7678 r:0.4799
Current avg r:0.3441 Best avg r: 0.3794
20:19:13,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:39,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:05,402 root INFO Epoch 9 Global steps: 29800 Train loss: 0.1891
en_de Dev loss: 0.8873 r:0.2088
en_zh Dev loss: 0.7918 r:0.4847
Current avg r:0.3468 Best avg r: 0.3794
20:21:22,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:48,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:14,579 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2147
en_de Dev loss: 0.9232 r:0.1951
en_zh Dev loss: 0.8164 r:0.4918
Current avg r:0.3435 Best avg r: 0.3794
20:23:32,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:58,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:24,153 root INFO Epoch 10 Global steps: 30200 Train loss: 0.2278
en_de Dev loss: 0.9010 r:0.2067
en_zh Dev loss: 0.7628 r:0.4900
Current avg r:0.3484 Best avg r: 0.3794
20:25:41,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:26:07,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:33,210 root INFO Epoch 10 Global steps: 30400 Train loss: 0.2106
en_de Dev loss: 0.8858 r:0.2128
en_zh Dev loss: 0.7665 r:0.4817
Current avg r:0.3472 Best avg r: 0.3794
20:27:50,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:16,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:28:42,133 root INFO Epoch 10 Global steps: 30600 Train loss: 0.1911
en_de Dev loss: 0.8919 r:0.2061
en_zh Dev loss: 0.7645 r:0.4768
Current avg r:0.3414 Best avg r: 0.3794
20:29:59,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:25,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:51,181 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1853
en_de Dev loss: 0.8994 r:0.2121
en_zh Dev loss: 0.7630 r:0.4806
Current avg r:0.3463 Best avg r: 0.3794
20:32:08,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:34,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:00,217 root INFO Epoch 10 Global steps: 31000 Train loss: 0.1976
en_de Dev loss: 0.9161 r:0.2157
en_zh Dev loss: 0.7869 r:0.4906
Current avg r:0.3531 Best avg r: 0.3794
20:34:17,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:43,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:09,221 root INFO Epoch 10 Global steps: 31200 Train loss: 0.1876
en_de Dev loss: 0.9128 r:0.2165
en_zh Dev loss: 0.7867 r:0.4864
Current avg r:0.3515 Best avg r: 0.3794
20:36:26,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:52,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:18,330 root INFO Epoch 10 Global steps: 31400 Train loss: 0.2078
en_de Dev loss: 0.9031 r:0.2121
en_zh Dev loss: 0.7963 r:0.4900
Current avg r:0.3510 Best avg r: 0.3794
20:38:35,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:01,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:27,539 root INFO Epoch 10 Global steps: 31600 Train loss: 0.1785
en_de Dev loss: 0.8932 r:0.2048
en_zh Dev loss: 0.7694 r:0.4913
Current avg r:0.3481 Best avg r: 0.3794
20:40:44,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:10,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:36,692 root INFO Epoch 10 Global steps: 31800 Train loss: 0.1985
en_de Dev loss: 0.9313 r:0.1834
en_zh Dev loss: 0.7801 r:0.4944
Current avg r:0.3389 Best avg r: 0.3794
20:42:53,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:19,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:45,789 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1734
en_de Dev loss: 0.9386 r:0.1966
en_zh Dev loss: 0.8074 r:0.4908
Current avg r:0.3437 Best avg r: 0.3794
20:45:02,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:28,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:54,844 root INFO Epoch 10 Global steps: 32200 Train loss: 0.1857
en_de Dev loss: 0.8942 r:0.1965
en_zh Dev loss: 0.7567 r:0.4881
Current avg r:0.3423 Best avg r: 0.3794
20:47:11,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:37,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:03,816 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1925
en_de Dev loss: 0.9155 r:0.1977
en_zh Dev loss: 0.7483 r:0.4983
Current avg r:0.3480 Best avg r: 0.3794
20:49:20,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:46,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:12,779 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1942
en_de Dev loss: 0.8946 r:0.2133
en_zh Dev loss: 0.7701 r:0.4916
Current avg r:0.3524 Best avg r: 0.3794
20:51:29,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:55,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:21,739 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1949
en_de Dev loss: 0.9050 r:0.1990
en_zh Dev loss: 0.8307 r:0.4850
Current avg r:0.3420 Best avg r: 0.3794
20:53:38,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:04,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:30,657 root INFO Epoch 10 Global steps: 33000 Train loss: 0.1989
en_de Dev loss: 0.9157 r:0.1889
en_zh Dev loss: 0.7948 r:0.4918
Current avg r:0.3403 Best avg r: 0.3794
20:55:48,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:14,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:39,913 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1924
en_de Dev loss: 0.9265 r:0.1779
en_zh Dev loss: 0.8196 r:0.4905
Current avg r:0.3342 Best avg r: 0.3794
20:57:56,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:22,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:48,697 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1732
en_de Dev loss: 0.9427 r:0.1849
en_zh Dev loss: 0.8014 r:0.4963
Current avg r:0.3406 Best avg r: 0.3794
21:00:05,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:31,688 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:57,618 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1551
en_de Dev loss: 0.9316 r:0.1864
en_zh Dev loss: 0.7712 r:0.4975
Current avg r:0.3420 Best avg r: 0.3794
21:02:14,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:40,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:06,549 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1708
en_de Dev loss: 0.9249 r:0.1929
en_zh Dev loss: 0.7317 r:0.5076
Current avg r:0.3503 Best avg r: 0.3794
21:04:23,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:49,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:15,333 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1742
en_de Dev loss: 0.9007 r:0.1955
en_zh Dev loss: 0.7282 r:0.5009
Current avg r:0.3482 Best avg r: 0.3794
21:06:32,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:58,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:24,160 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1817
en_de Dev loss: 0.8824 r:0.2039
en_zh Dev loss: 0.7276 r:0.4935
Current avg r:0.3487 Best avg r: 0.3794
21:08:41,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:07,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:32,974 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1572
en_de Dev loss: 0.8867 r:0.1930
en_zh Dev loss: 0.7419 r:0.4900
Current avg r:0.3415 Best avg r: 0.3794
21:10:49,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:15,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:41,654 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1765
en_de Dev loss: 0.9017 r:0.1825
en_zh Dev loss: 0.7537 r:0.4866
Current avg r:0.3346 Best avg r: 0.3794
21:12:58,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:24,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:50,459 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1727
en_de Dev loss: 0.9609 r:0.1835
en_zh Dev loss: 0.8318 r:0.4761
Current avg r:0.3298 Best avg r: 0.3794
21:15:07,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:33,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:59,453 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1710
en_de Dev loss: 0.9305 r:0.1877
en_zh Dev loss: 0.7809 r:0.4912
Current avg r:0.3394 Best avg r: 0.3794
21:17:16,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:42,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:08,517 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1584
en_de Dev loss: 0.9118 r:0.2075
en_zh Dev loss: 0.8030 r:0.4822
Current avg r:0.3448 Best avg r: 0.3794
21:19:25,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:51,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:17,476 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1757
en_de Dev loss: 0.9142 r:0.1958
en_zh Dev loss: 0.7720 r:0.4857
Current avg r:0.3407 Best avg r: 0.3794
21:21:34,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:00,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:26,532 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1777
en_de Dev loss: 0.9188 r:0.1862
en_zh Dev loss: 0.7793 r:0.4883
Current avg r:0.3373 Best avg r: 0.3794
21:23:43,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:09,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:35,587 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1696
en_de Dev loss: 0.9483 r:0.1686
en_zh Dev loss: 0.7795 r:0.4914
Current avg r:0.3300 Best avg r: 0.3794
21:25:52,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:26:18,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:44,654 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1693
en_de Dev loss: 0.9314 r:0.1949
en_zh Dev loss: 0.8706 r:0.4724
Current avg r:0.3336 Best avg r: 0.3794
21:28:02,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:28,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:28:54,15 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1452
en_de Dev loss: 0.9105 r:0.1918
en_zh Dev loss: 0.8014 r:0.4868
Current avg r:0.3393 Best avg r: 0.3794
21:30:11,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:37,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:03,35 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1605
en_de Dev loss: 0.9244 r:0.2001
en_zh Dev loss: 0.8531 r:0.4861
Current avg r:0.3431 Best avg r: 0.3794
21:32:20,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:46,187 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:12,142 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1605
en_de Dev loss: 0.9381 r:0.1921
en_zh Dev loss: 0.7997 r:0.4903
Current avg r:0.3412 Best avg r: 0.3794
21:34:29,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:55,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:21,222 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1600
en_de Dev loss: 0.8927 r:0.2004
en_zh Dev loss: 0.7276 r:0.4907
Current avg r:0.3456 Best avg r: 0.3794
21:36:38,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:04,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:30,367 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1656
en_de Dev loss: 0.8931 r:0.2023
en_zh Dev loss: 0.7271 r:0.4877
Current avg r:0.3450 Best avg r: 0.3794
21:38:47,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:13,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:39,515 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1696
en_de Dev loss: 0.9057 r:0.2088
en_zh Dev loss: 0.7624 r:0.4809
Current avg r:0.3449 Best avg r: 0.3794
21:40:56,709 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:22,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:48,604 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1635
en_de Dev loss: 0.9213 r:0.2077
en_zh Dev loss: 0.8326 r:0.4704
Current avg r:0.3390 Best avg r: 0.3794
21:43:05,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:31,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:57,682 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1574
en_de Dev loss: 0.9174 r:0.1973
en_zh Dev loss: 0.7777 r:0.4820
Current avg r:0.3397 Best avg r: 0.3794
21:45:14,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:40,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:06,857 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1407
en_de Dev loss: 0.9063 r:0.1963
en_zh Dev loss: 0.7809 r:0.4830
Current avg r:0.3396 Best avg r: 0.3794
21:47:24,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:49,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:15,926 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1673
en_de Dev loss: 0.8926 r:0.1885
en_zh Dev loss: 0.7621 r:0.4765
Current avg r:0.3325 Best avg r: 0.3794
21:49:33,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:59,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:50:25,10 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1583
en_de Dev loss: 0.9016 r:0.1887
en_zh Dev loss: 0.7349 r:0.4916
Current avg r:0.3401 Best avg r: 0.3794
21:51:42,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:08,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:34,79 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1618
en_de Dev loss: 0.9291 r:0.1999
en_zh Dev loss: 0.7642 r:0.4938
Current avg r:0.3469 Best avg r: 0.3794
21:53:51,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:17,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:43,77 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1487
en_de Dev loss: 0.9297 r:0.1878
en_zh Dev loss: 0.7483 r:0.4993
Current avg r:0.3436 Best avg r: 0.3794
21:56:00,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:56:26,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:52,67 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1416
en_de Dev loss: 0.9588 r:0.1809
en_zh Dev loss: 0.7912 r:0.5007
Current avg r:0.3408 Best avg r: 0.3794
21:58:09,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:35,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:01,109 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1584
en_de Dev loss: 0.9385 r:0.1799
en_zh Dev loss: 0.7445 r:0.4983
Current avg r:0.3391 Best avg r: 0.3794
22:00:18,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:44,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:10,616 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1407
en_de Dev loss: 0.9507 r:0.1913
en_zh Dev loss: 0.7807 r:0.4944
Current avg r:0.3428 Best avg r: 0.3794
22:02:27,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:53,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:19,757 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1533
en_de Dev loss: 0.9275 r:0.1923
en_zh Dev loss: 0.7572 r:0.4942
Current avg r:0.3433 Best avg r: 0.3794
22:04:36,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:02,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:28,842 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1516
en_de Dev loss: 0.9429 r:0.1760
en_zh Dev loss: 0.8080 r:0.4951
Current avg r:0.3355 Best avg r: 0.3794
22:06:46,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:07:12,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:38,18 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1507
en_de Dev loss: 0.9477 r:0.1669
en_zh Dev loss: 0.7811 r:0.4878
Current avg r:0.3273 Best avg r: 0.3794
22:08:55,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:21,250 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:47,217 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1439
en_de Dev loss: 0.9527 r:0.1616
en_zh Dev loss: 0.8368 r:0.4801
Current avg r:0.3208 Best avg r: 0.3794
22:11:04,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:30,408 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:56,360 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1387
en_de Dev loss: 0.9725 r:0.1523
en_zh Dev loss: 0.7812 r:0.4905
Current avg r:0.3214 Best avg r: 0.3794
22:13:13,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:39,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:05,483 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1484
en_de Dev loss: 0.9668 r:0.1571
en_zh Dev loss: 0.7588 r:0.4879
Current avg r:0.3225 Best avg r: 0.3794
22:15:22,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:48,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:16:14,588 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1409
en_de Dev loss: 0.9806 r:0.1710
en_zh Dev loss: 0.8026 r:0.4885
Current avg r:0.3297 Best avg r: 0.3794
22:17:31,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:57,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:23,643 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1402
en_de Dev loss: 0.9398 r:0.1746
en_zh Dev loss: 0.8300 r:0.4731
Current avg r:0.3238 Best avg r: 0.3794
22:19:40,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:06,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:32,693 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1469
en_de Dev loss: 0.9446 r:0.1667
en_zh Dev loss: 0.7886 r:0.4857
Current avg r:0.3262 Best avg r: 0.3794
22:21:49,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:15,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:41,744 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1437
en_de Dev loss: 0.9270 r:0.1794
en_zh Dev loss: 0.7665 r:0.4832
Current avg r:0.3313 Best avg r: 0.3794
22:23:58,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:24,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:50,869 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1425
en_de Dev loss: 0.9396 r:0.1750
en_zh Dev loss: 0.7972 r:0.4763
Current avg r:0.3257 Best avg r: 0.3794
22:26:07,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:26:33,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:59,853 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1394
en_de Dev loss: 0.9558 r:0.1817
en_zh Dev loss: 0.8571 r:0.4725
Current avg r:0.3271 Best avg r: 0.3794
22:28:16,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:42,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:08,811 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1346
en_de Dev loss: 0.9269 r:0.1837
en_zh Dev loss: 0.7850 r:0.4794
Current avg r:0.3316 Best avg r: 0.3794
22:30:25,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:51,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:17,846 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1412
en_de Dev loss: 0.9243 r:0.1774
en_zh Dev loss: 0.7557 r:0.4908
Current avg r:0.3341 Best avg r: 0.3794
22:32:35,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:01,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:33:27,384 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1452
en_de Dev loss: 0.9432 r:0.1688
en_zh Dev loss: 0.7504 r:0.4905
Current avg r:0.3297 Best avg r: 0.3794
22:34:44,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:10,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:36,443 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1534
en_de Dev loss: 0.9428 r:0.1673
en_zh Dev loss: 0.7429 r:0.4915
Current avg r:0.3294 Best avg r: 0.3794
22:36:53,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:19,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:45,517 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1320
en_de Dev loss: 0.9267 r:0.1749
en_zh Dev loss: 0.7550 r:0.4842
Current avg r:0.3295 Best avg r: 0.3794
22:39:02,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:39:28,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:54,668 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1408
en_de Dev loss: 0.9304 r:0.1691
en_zh Dev loss: 0.7508 r:0.4800
Current avg r:0.3245 Best avg r: 0.3794
22:41:11,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:37,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:03,838 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1334
en_de Dev loss: 0.9539 r:0.1752
en_zh Dev loss: 0.8015 r:0.4757
Current avg r:0.3255 Best avg r: 0.3794
22:43:20,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:46,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:12,926 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1401
en_de Dev loss: 0.9611 r:0.1743
en_zh Dev loss: 0.7914 r:0.4791
Current avg r:0.3267 Best avg r: 0.3794
22:45:30,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:45:56,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:22,87 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1246
en_de Dev loss: 0.9425 r:0.1685
en_zh Dev loss: 0.7985 r:0.4711
Current avg r:0.3198 Best avg r: 0.3794
22:47:39,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:05,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:48:31,107 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1357
en_de Dev loss: 0.9824 r:0.1872
en_zh Dev loss: 0.8646 r:0.4738
Current avg r:0.3305 Best avg r: 0.3794
22:49:48,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:14,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:40,86 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1382
en_de Dev loss: 0.9457 r:0.1682
en_zh Dev loss: 0.7831 r:0.4726
Current avg r:0.3204 Best avg r: 0.3794
22:51:57,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:23,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:49,161 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1226
en_de Dev loss: 0.9482 r:0.1913
en_zh Dev loss: 0.7581 r:0.4846
Current avg r:0.3380 Best avg r: 0.3794
22:54:06,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:54:32,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:58,336 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1403
en_de Dev loss: 0.9619 r:0.1892
en_zh Dev loss: 0.8080 r:0.4763
Current avg r:0.3327 Best avg r: 0.3794
22:56:15,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:41,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:07,403 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1200
en_de Dev loss: 0.9281 r:0.2009
en_zh Dev loss: 0.7616 r:0.4799
Current avg r:0.3404 Best avg r: 0.3794
22:58:24,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:50,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:16,393 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1332
en_de Dev loss: 0.9144 r:0.1971
en_zh Dev loss: 0.7490 r:0.4802
Current avg r:0.3387 Best avg r: 0.3794
23:00:33,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:00:59,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:25,516 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1357
en_de Dev loss: 0.9306 r:0.1876
en_zh Dev loss: 0.7563 r:0.4903
Current avg r:0.3389 Best avg r: 0.3794
23:02:42,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:08,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:34,612 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1238
en_de Dev loss: 0.9329 r:0.1853
en_zh Dev loss: 0.7841 r:0.4729
Current avg r:0.3291 Best avg r: 0.3794
23:04:52,28 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:17,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:43,919 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1268
en_de Dev loss: 0.9440 r:0.1888
en_zh Dev loss: 0.7815 r:0.4850
Current avg r:0.3369 Best avg r: 0.3794
23:07:01,5 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:26,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:52,917 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1251
en_de Dev loss: 0.9362 r:0.1910
en_zh Dev loss: 0.7611 r:0.4879
Current avg r:0.3395 Best avg r: 0.3794
23:09:10,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:09:35,975 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:01,934 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1254
en_de Dev loss: 0.9422 r:0.1838
en_zh Dev loss: 0.7985 r:0.4807
Current avg r:0.3323 Best avg r: 0.3794
23:11:19,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:44,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:10,920 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1231
en_de Dev loss: 0.9655 r:0.1668
en_zh Dev loss: 0.7695 r:0.4907
Current avg r:0.3287 Best avg r: 0.3794
23:13:27,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:53,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:19,869 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1148
en_de Dev loss: 0.9471 r:0.1625
en_zh Dev loss: 0.7553 r:0.4899
Current avg r:0.3262 Best avg r: 0.3794
23:15:37,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:02,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:28,909 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1211
en_de Dev loss: 0.9273 r:0.1672
en_zh Dev loss: 0.7268 r:0.4866
Current avg r:0.3269 Best avg r: 0.3794
23:17:45,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:11,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:37,875 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1157
en_de Dev loss: 0.9385 r:0.1671
en_zh Dev loss: 0.7515 r:0.4857
Current avg r:0.3264 Best avg r: 0.3794
23:19:54,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:20,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:46,763 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1170
en_de Dev loss: 0.9539 r:0.1893
en_zh Dev loss: 0.7728 r:0.4893
Current avg r:0.3393 Best avg r: 0.3794
23:22:03,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:29,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:55,752 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1172
en_de Dev loss: 0.9486 r:0.1828
en_zh Dev loss: 0.7765 r:0.4801
Current avg r:0.3315 Best avg r: 0.3794
23:24:12,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:38,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:04,715 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1267
en_de Dev loss: 0.9456 r:0.1758
en_zh Dev loss: 0.7885 r:0.4881
Current avg r:0.3320 Best avg r: 0.3794
23:26:21,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:47,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:13,617 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1206
en_de Dev loss: 0.9405 r:0.1826
en_zh Dev loss: 0.7740 r:0.4852
Current avg r:0.3339 Best avg r: 0.3794
23:28:30,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:56,562 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:22,510 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1162
en_de Dev loss: 0.9613 r:0.1813
en_zh Dev loss: 0.8052 r:0.4758
Current avg r:0.3286 Best avg r: 0.3794
23:30:39,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:05,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:31,647 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1338
en_de Dev loss: 0.9245 r:0.1899
en_zh Dev loss: 0.7578 r:0.4861
Current avg r:0.3380 Best avg r: 0.3794
23:32:48,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:14,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:40,682 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1239
en_de Dev loss: 0.9396 r:0.1782
en_zh Dev loss: 0.7521 r:0.4792
Current avg r:0.3287 Best avg r: 0.3794
23:34:57,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:23,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:49,695 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1314
en_de Dev loss: 0.9608 r:0.1783
en_zh Dev loss: 0.7811 r:0.4803
Current avg r:0.3293 Best avg r: 0.3794
23:37:07,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:33,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:59,119 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1170
en_de Dev loss: 0.9323 r:0.1849
en_zh Dev loss: 0.7358 r:0.4928
Current avg r:0.3388 Best avg r: 0.3794
23:39:16,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:42,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:08,18 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1101
en_de Dev loss: 0.9422 r:0.1774
en_zh Dev loss: 0.7394 r:0.4950
Current avg r:0.3362 Best avg r: 0.3794
23:41:24,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:50,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:16,758 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1102
en_de Dev loss: 0.9854 r:0.1762
en_zh Dev loss: 0.8751 r:0.4817
Current avg r:0.3289 Best avg r: 0.3794
23:43:33,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:59,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:25,504 root INFO Epoch 16 Global steps: 48800 Train loss: 0.1243
en_de Dev loss: 0.9377 r:0.1835
en_zh Dev loss: 0.8025 r:0.4820
Current avg r:0.3328 Best avg r: 0.3794
23:45:42,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:08,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:34,288 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1117
en_de Dev loss: 0.9165 r:0.1814
en_zh Dev loss: 0.7174 r:0.5016
Current avg r:0.3415 Best avg r: 0.3794
23:47:51,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:17,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:43,21 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1076
en_de Dev loss: 0.9290 r:0.1766
en_zh Dev loss: 0.7396 r:0.4967
Current avg r:0.3366 Best avg r: 0.3794
23:49:59,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:25,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:51,678 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1205
en_de Dev loss: 0.9552 r:0.1732
en_zh Dev loss: 0.7279 r:0.5030
Current avg r:0.3381 Best avg r: 0.3794
23:52:08,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:34,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:00,393 root INFO Epoch 16 Global steps: 49600 Train loss: 0.1169
en_de Dev loss: 0.9523 r:0.1806
en_zh Dev loss: 0.7560 r:0.5010
Current avg r:0.3408 Best avg r: 0.3794
23:54:17,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:43,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:09,40 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1108
en_de Dev loss: 0.9462 r:0.1724
en_zh Dev loss: 0.7316 r:0.4973
Current avg r:0.3348 Best avg r: 0.3794
