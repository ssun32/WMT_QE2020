14:33:42,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:34:20,850 root INFO 
id:en_zh cur r: 0.0378 best r: 0.0378
14:34:20,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:34:46,686 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:34:46,691 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:35:12,557 root INFO Epoch 0 Global steps: 200 Train loss: 0.7891
en_de Dev loss: 0.8897 r:0.0130
en_zh Dev loss: 0.8156 r:0.0891
Current avg r:0.0511 Best avg r: 0.0511
14:36:29,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:08,142 root INFO 
id:en_zh cur r: 0.0446 best r: 0.0446
14:37:08,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:37:33,996 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:37:34,1 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:37:59,900 root INFO Epoch 0 Global steps: 400 Train loss: 0.8303
en_de Dev loss: 0.8911 r:0.0004
en_zh Dev loss: 0.8164 r:0.1388
Current avg r:0.0696 Best avg r: 0.0696
14:39:16,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:39:55,572 root INFO 
id:en_zh cur r: 0.1696 best r: 0.1696
14:39:55,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:21,435 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:40:21,440 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:40:47,323 root INFO Epoch 0 Global steps: 600 Train loss: 0.7685
en_de Dev loss: 0.8880 r:-0.0009
en_zh Dev loss: 0.8141 r:0.1498
Current avg r:0.0744 Best avg r: 0.0744
14:42:04,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:30,148 root INFO 
id:en_de cur r: 0.0010 best r: 0.0010
14:42:56,15 root INFO 
id:en_zh cur r: 0.1888 best r: 0.1888
14:42:56,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:21,897 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:43:21,903 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:43:47,808 root INFO Epoch 0 Global steps: 800 Train loss: 0.6684
en_de Dev loss: 0.8874 r:0.0303
en_zh Dev loss: 0.8116 r:0.2398
Current avg r:0.1351 Best avg r: 0.1351
14:45:04,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:30,621 root INFO 
id:en_de cur r: 0.0080 best r: 0.0080
14:45:56,482 root INFO 
id:en_zh cur r: 0.2634 best r: 0.2634
14:45:56,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:22,355 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:46:22,362 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:46:48,272 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7756
en_de Dev loss: 0.8854 r:0.0490
en_zh Dev loss: 0.8094 r:0.2594
Current avg r:0.1542 Best avg r: 0.1542
14:48:05,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:31,90 root INFO 
id:en_de cur r: 0.0131 best r: 0.0131
14:48:56,941 root INFO 
id:en_zh cur r: 0.2961 best r: 0.2961
14:48:56,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:22,832 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8367
en_de Dev loss: 0.8927 r:0.0569
en_zh Dev loss: 0.8248 r:0.2281
Current avg r:0.1425 Best avg r: 0.1542
14:50:39,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:05,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:31,526 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:51:31,544 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:51:57,452 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7146
en_de Dev loss: 0.8838 r:0.0843
en_zh Dev loss: 0.8073 r:0.2741
Current avg r:0.1792 Best avg r: 0.1792
14:53:14,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:53,189 root INFO 
id:en_zh cur r: 0.3063 best r: 0.3063
14:53:53,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:19,69 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:54:19,79 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:54:44,980 root INFO Epoch 0 Global steps: 1600 Train loss: 0.6304
en_de Dev loss: 0.8839 r:0.1208
en_zh Dev loss: 0.8010 r:0.3270
Current avg r:0.2239 Best avg r: 0.2239
14:56:01,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:27,796 root INFO 
id:en_de cur r: 0.0359 best r: 0.0359
14:56:53,658 root INFO 
id:en_zh cur r: 0.3456 best r: 0.3456
14:56:53,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:19,526 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:57:19,533 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:57:45,422 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7230
en_de Dev loss: 0.8813 r:0.1362
en_zh Dev loss: 0.7903 r:0.3563
Current avg r:0.2462 Best avg r: 0.2462
14:59:02,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:28,245 root INFO 
id:en_de cur r: 0.0898 best r: 0.0898
14:59:54,116 root INFO 
id:en_zh cur r: 0.3804 best r: 0.3804
14:59:54,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:20,0 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:00:20,8 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:00:45,888 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7792
en_de Dev loss: 0.8738 r:0.1784
en_zh Dev loss: 0.7554 r:0.3923
Current avg r:0.2854 Best avg r: 0.2854
15:02:02,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:28,735 root INFO 
id:en_de cur r: 0.1433 best r: 0.1433
15:02:41,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:07,560 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7229
en_de Dev loss: 0.9108 r:0.1682
en_zh Dev loss: 0.8079 r:0.3775
Current avg r:0.2729 Best avg r: 0.2854
15:04:24,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:50,447 root INFO 
id:en_de cur r: 0.1759 best r: 0.1759
15:05:16,315 root INFO 
id:en_zh cur r: 0.3831 best r: 0.3831
15:05:16,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:42,195 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:05:42,204 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:06:08,115 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6192
en_de Dev loss: 0.8557 r:0.1934
en_zh Dev loss: 0.6906 r:0.3978
Current avg r:0.2956 Best avg r: 0.2956
15:07:25,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:03,913 root INFO 
id:en_zh cur r: 0.4117 best r: 0.4117
15:08:03,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:29,800 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:08:29,806 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:08:55,717 root INFO Epoch 0 Global steps: 2600 Train loss: 0.7349
en_de Dev loss: 0.8578 r:0.1849
en_zh Dev loss: 0.7250 r:0.4277
Current avg r:0.3063 Best avg r: 0.3063
15:10:12,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:38,544 root INFO 
id:en_de cur r: 0.2104 best r: 0.2104
15:11:04,427 root INFO 
id:en_zh cur r: 0.4216 best r: 0.4216
15:11:04,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:30,314 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:11:30,324 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:11:56,235 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6648
en_de Dev loss: 0.8588 r:0.2166
en_zh Dev loss: 0.7051 r:0.4288
Current avg r:0.3227 Best avg r: 0.3227
15:13:13,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:39,113 root INFO 
id:en_de cur r: 0.2106 best r: 0.2106
15:14:04,994 root INFO 
id:en_zh cur r: 0.4473 best r: 0.4473
15:14:04,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:30,895 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:14:30,908 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:14:56,807 root INFO Epoch 0 Global steps: 3000 Train loss: 0.8591
en_de Dev loss: 0.8527 r:0.1968
en_zh Dev loss: 0.6669 r:0.4564
Current avg r:0.3266 Best avg r: 0.3266
15:16:14,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:40,45 root INFO 
id:en_de cur r: 0.2212 best r: 0.2212
15:16:52,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:18,872 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:17:18,878 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:17:44,779 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6722
en_de Dev loss: 0.8444 r:0.2189
en_zh Dev loss: 0.6935 r:0.4450
Current avg r:0.3319 Best avg r: 0.3319
15:19:01,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:40,546 root INFO 
id:en_zh cur r: 0.4617 best r: 0.4617
15:19:40,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:06,419 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:20:06,427 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:20:32,359 root INFO Epoch 1 Global steps: 3400 Train loss: 0.5610
en_de Dev loss: 0.8782 r:0.1925
en_zh Dev loss: 0.6865 r:0.4725
Current avg r:0.3325 Best avg r: 0.3325
15:21:49,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:15,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:41,35 root INFO Epoch 1 Global steps: 3600 Train loss: 0.7107
en_de Dev loss: 0.8619 r:0.1982
en_zh Dev loss: 0.6802 r:0.4544
Current avg r:0.3263 Best avg r: 0.3325
15:23:57,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:23,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:49,748 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:24:49,775 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:25:15,682 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6824
en_de Dev loss: 0.8533 r:0.2091
en_zh Dev loss: 0.6429 r:0.4646
Current avg r:0.3369 Best avg r: 0.3369
15:26:32,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:58,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:24,421 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:27:24,428 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:27:50,334 root INFO Epoch 1 Global steps: 4000 Train loss: 0.5917
en_de Dev loss: 0.8566 r:0.2267
en_zh Dev loss: 0.6991 r:0.4587
Current avg r:0.3427 Best avg r: 0.3427
15:29:07,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:33,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:59,55 root INFO Epoch 1 Global steps: 4200 Train loss: 0.5659
en_de Dev loss: 0.8586 r:0.2244
en_zh Dev loss: 0.7006 r:0.4576
Current avg r:0.3410 Best avg r: 0.3427
15:31:15,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:54,808 root INFO 
id:en_zh cur r: 0.4667 best r: 0.4667
15:31:54,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:20,689 root INFO Epoch 1 Global steps: 4400 Train loss: 0.5691
en_de Dev loss: 0.8674 r:0.2134
en_zh Dev loss: 0.7168 r:0.4659
Current avg r:0.3396 Best avg r: 0.3427
15:33:37,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:03,567 root INFO 
id:en_de cur r: 0.2295 best r: 0.2295
15:34:29,434 root INFO 
id:en_zh cur r: 0.4714 best r: 0.4714
15:34:29,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:55,311 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:34:55,317 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:35:21,231 root INFO Epoch 1 Global steps: 4600 Train loss: 0.5974
en_de Dev loss: 0.8603 r:0.2356
en_zh Dev loss: 0.7578 r:0.4675
Current avg r:0.3515 Best avg r: 0.3515
15:36:38,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:17,41 root INFO 
id:en_zh cur r: 0.4799 best r: 0.4799
15:37:17,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:37:42,937 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:37:42,944 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:38:08,845 root INFO Epoch 1 Global steps: 4800 Train loss: 0.6928
en_de Dev loss: 0.8566 r:0.2299
en_zh Dev loss: 0.7261 r:0.4794
Current avg r:0.3547 Best avg r: 0.3547
15:39:25,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:51,744 root INFO 
id:en_de cur r: 0.2302 best r: 0.2302
15:40:04,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:30,548 root INFO Epoch 1 Global steps: 5000 Train loss: 0.5726
en_de Dev loss: 0.8533 r:0.2358
en_zh Dev loss: 0.7159 r:0.4687
Current avg r:0.3522 Best avg r: 0.3547
15:41:47,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:13,448 root INFO 
id:en_de cur r: 0.2382 best r: 0.2382
15:42:26,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:52,264 root INFO Epoch 1 Global steps: 5200 Train loss: 0.6595
en_de Dev loss: 0.8476 r:0.2413
en_zh Dev loss: 0.7481 r:0.4579
Current avg r:0.3496 Best avg r: 0.3547
15:44:09,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:35,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:00,991 root INFO Epoch 1 Global steps: 5400 Train loss: 0.6588
en_de Dev loss: 0.8555 r:0.2344
en_zh Dev loss: 0.7274 r:0.4714
Current avg r:0.3529 Best avg r: 0.3547
15:46:17,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:56,736 root INFO 
id:en_zh cur r: 0.4905 best r: 0.4905
15:46:56,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:22,616 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:47:22,622 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:47:48,506 root INFO Epoch 1 Global steps: 5600 Train loss: 0.6724
en_de Dev loss: 0.8450 r:0.2352
en_zh Dev loss: 0.6598 r:0.4897
Current avg r:0.3625 Best avg r: 0.3625
15:49:05,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:31,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:57,285 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6574
en_de Dev loss: 0.8432 r:0.2339
en_zh Dev loss: 0.7072 r:0.4825
Current avg r:0.3582 Best avg r: 0.3625
15:51:14,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:40,157 root INFO 
id:en_de cur r: 0.2429 best r: 0.2429
15:52:06,45 root INFO 
id:en_zh cur r: 0.4954 best r: 0.4954
15:52:06,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:31,917 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:52:31,923 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:52:57,844 root INFO Epoch 1 Global steps: 6000 Train loss: 0.6357
en_de Dev loss: 0.8348 r:0.2435
en_zh Dev loss: 0.6274 r:0.4965
Current avg r:0.3700 Best avg r: 0.3700
15:54:15,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:53,951 root INFO 
id:en_zh cur r: 0.4988 best r: 0.4988
15:54:53,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:19,840 root INFO Epoch 2 Global steps: 6200 Train loss: 0.5785
en_de Dev loss: 0.8460 r:0.2292
en_zh Dev loss: 0.6478 r:0.4991
Current avg r:0.3642 Best avg r: 0.3700
15:56:36,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:02,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:28,473 root INFO Epoch 2 Global steps: 6400 Train loss: 0.6600
en_de Dev loss: 0.8384 r:0.2379
en_zh Dev loss: 0.6760 r:0.4916
Current avg r:0.3648 Best avg r: 0.3700
15:58:45,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:11,310 root INFO 
id:en_de cur r: 0.2547 best r: 0.2547
15:59:24,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:50,125 root INFO Epoch 2 Global steps: 6600 Train loss: 0.5789
en_de Dev loss: 0.8410 r:0.2496
en_zh Dev loss: 0.7965 r:0.4687
Current avg r:0.3592 Best avg r: 0.3700
16:01:07,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:32,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:58,836 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
16:01:58,843 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:02:24,739 root INFO Epoch 2 Global steps: 6800 Train loss: 0.6325
en_de Dev loss: 0.8358 r:0.2462
en_zh Dev loss: 0.6565 r:0.4942
Current avg r:0.3702 Best avg r: 0.3702
16:03:41,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:07,629 root INFO 
id:en_de cur r: 0.2603 best r: 0.2603
16:04:20,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:46,480 root INFO Epoch 2 Global steps: 7000 Train loss: 0.5113
en_de Dev loss: 0.8490 r:0.2568
en_zh Dev loss: 0.7662 r:0.4816
Current avg r:0.3692 Best avg r: 0.3702
16:06:03,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:29,376 root INFO 
id:en_de cur r: 0.2734 best r: 0.2734
16:06:42,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:08,193 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
16:07:08,198 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:07:34,84 root INFO Epoch 2 Global steps: 7200 Train loss: 0.5454
en_de Dev loss: 0.8309 r:0.2676
en_zh Dev loss: 0.6884 r:0.4912
Current avg r:0.3794 Best avg r: 0.3794
16:08:51,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:17,6 root INFO 
id:en_de cur r: 0.2805 best r: 0.2805
16:09:29,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:55,811 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
16:09:55,818 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:10:21,730 root INFO Epoch 2 Global steps: 7400 Train loss: 0.5698
en_de Dev loss: 0.8228 r:0.2765
en_zh Dev loss: 0.6532 r:0.4945
Current avg r:0.3855 Best avg r: 0.3855
16:11:38,683 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:17,481 root INFO 
id:en_zh cur r: 0.5027 best r: 0.5027
16:12:17,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:43,356 root INFO Epoch 2 Global steps: 7600 Train loss: 0.5378
en_de Dev loss: 0.8484 r:0.2709
en_zh Dev loss: 0.6857 r:0.4973
Current avg r:0.3841 Best avg r: 0.3855
16:14:00,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:26,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:52,38 root INFO Epoch 2 Global steps: 7800 Train loss: 0.5848
en_de Dev loss: 0.8476 r:0.2750
en_zh Dev loss: 0.7209 r:0.4845
Current avg r:0.3798 Best avg r: 0.3855
16:16:08,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:34,886 root INFO 
id:en_de cur r: 0.2809 best r: 0.2809
16:16:47,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:17:13,709 root INFO Epoch 2 Global steps: 8000 Train loss: 0.5628
en_de Dev loss: 0.8290 r:0.2713
en_zh Dev loss: 0.7073 r:0.4977
Current avg r:0.3845 Best avg r: 0.3855
16:18:30,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:56,595 root INFO 
id:en_de cur r: 0.2834 best r: 0.2834
16:19:22,454 root INFO 
id:en_zh cur r: 0.5100 best r: 0.5100
16:19:22,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:48,343 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
16:19:48,350 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:20:14,264 root INFO Epoch 2 Global steps: 8200 Train loss: 0.5697
en_de Dev loss: 0.8352 r:0.2779
en_zh Dev loss: 0.6509 r:0.5033
Current avg r:0.3906 Best avg r: 0.3906
16:21:31,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:10,40 root INFO 
id:en_zh cur r: 0.5123 best r: 0.5123
16:22:10,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:35,919 root INFO Epoch 2 Global steps: 8400 Train loss: 0.6089
en_de Dev loss: 0.8285 r:0.2715
en_zh Dev loss: 0.7036 r:0.5073
Current avg r:0.3894 Best avg r: 0.3906
16:23:52,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:31,663 root INFO 
id:en_zh cur r: 0.5140 best r: 0.5140
16:24:31,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:24:57,552 root INFO Epoch 2 Global steps: 8600 Train loss: 0.4977
en_de Dev loss: 0.8547 r:0.2628
en_zh Dev loss: 0.7212 r:0.5092
Current avg r:0.3860 Best avg r: 0.3906
16:26:14,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:40,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:06,279 root INFO Epoch 2 Global steps: 8800 Train loss: 0.6411
en_de Dev loss: 0.8330 r:0.2529
en_zh Dev loss: 0.6438 r:0.5040
Current avg r:0.3785 Best avg r: 0.3906
16:28:23,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:49,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:14,997 root INFO Epoch 2 Global steps: 9000 Train loss: 0.4947
en_de Dev loss: 0.8406 r:0.2588
en_zh Dev loss: 0.7121 r:0.4998
Current avg r:0.3793 Best avg r: 0.3906
16:30:32,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:58,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:24,48 root INFO Epoch 3 Global steps: 9200 Train loss: 0.5406
en_de Dev loss: 0.8340 r:0.2600
en_zh Dev loss: 0.7369 r:0.4991
Current avg r:0.3795 Best avg r: 0.3906
16:32:40,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:06,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:32,709 root INFO Epoch 3 Global steps: 9400 Train loss: 0.5218
en_de Dev loss: 0.8295 r:0.2710
en_zh Dev loss: 0.7563 r:0.4866
Current avg r:0.3788 Best avg r: 0.3906
16:34:49,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:15,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:41,379 root INFO Epoch 3 Global steps: 9600 Train loss: 0.5093
en_de Dev loss: 0.8315 r:0.2738
en_zh Dev loss: 0.7360 r:0.4873
Current avg r:0.3805 Best avg r: 0.3906
16:36:58,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:24,257 root INFO 
id:en_de cur r: 0.2983 best r: 0.2983
16:37:37,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:03,77 root INFO Epoch 3 Global steps: 9800 Train loss: 0.4924
en_de Dev loss: 0.8337 r:0.2892
en_zh Dev loss: 0.7182 r:0.4760
Current avg r:0.3826 Best avg r: 0.3906
16:39:19,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:45,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:11,722 root INFO Epoch 3 Global steps: 10000 Train loss: 0.5546
en_de Dev loss: 0.8265 r:0.2851
en_zh Dev loss: 0.7129 r:0.4810
Current avg r:0.3830 Best avg r: 0.3906
16:41:28,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:54,604 root INFO 
id:en_de cur r: 0.3043 best r: 0.3043
16:42:07,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:33,410 root INFO Epoch 3 Global steps: 10200 Train loss: 0.4841
en_de Dev loss: 0.8375 r:0.2943
en_zh Dev loss: 0.6944 r:0.4791
Current avg r:0.3867 Best avg r: 0.3906
16:43:50,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:16,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:42,112 root INFO Epoch 3 Global steps: 10400 Train loss: 0.5001
en_de Dev loss: 0.8482 r:0.2757
en_zh Dev loss: 0.7589 r:0.4877
Current avg r:0.3817 Best avg r: 0.3906
16:45:59,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:24,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:50,772 root INFO Epoch 3 Global steps: 10600 Train loss: 0.5068
en_de Dev loss: 0.8315 r:0.2786
en_zh Dev loss: 0.7082 r:0.4898
Current avg r:0.3842 Best avg r: 0.3906
16:48:07,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:33,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:59,453 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
16:48:59,483 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:49:25,388 root INFO Epoch 3 Global steps: 10800 Train loss: 0.4631
en_de Dev loss: 0.8219 r:0.2856
en_zh Dev loss: 0.6531 r:0.5007
Current avg r:0.3931 Best avg r: 0.3931
16:50:42,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:08,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:34,113 root INFO Epoch 3 Global steps: 11000 Train loss: 0.4957
en_de Dev loss: 0.8392 r:0.2733
en_zh Dev loss: 0.7111 r:0.4982
Current avg r:0.3858 Best avg r: 0.3931
16:52:51,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:16,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:42,852 root INFO Epoch 3 Global steps: 11200 Train loss: 0.4764
en_de Dev loss: 0.8488 r:0.2574
en_zh Dev loss: 0.8155 r:0.4868
Current avg r:0.3721 Best avg r: 0.3931
16:54:59,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:25,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:51,519 root INFO Epoch 3 Global steps: 11400 Train loss: 0.5541
en_de Dev loss: 0.8538 r:0.2661
en_zh Dev loss: 0.7759 r:0.4922
Current avg r:0.3792 Best avg r: 0.3931
16:57:08,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:34,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:00,187 root INFO Epoch 3 Global steps: 11600 Train loss: 0.5196
en_de Dev loss: 0.8402 r:0.2711
en_zh Dev loss: 0.7388 r:0.4931
Current avg r:0.3821 Best avg r: 0.3931
16:59:17,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:42,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:08,857 root INFO Epoch 3 Global steps: 11800 Train loss: 0.4788
en_de Dev loss: 0.8475 r:0.2703
en_zh Dev loss: 0.7477 r:0.4887
Current avg r:0.3795 Best avg r: 0.3931
17:01:25,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:51,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:17,502 root INFO Epoch 3 Global steps: 12000 Train loss: 0.4784
en_de Dev loss: 0.8339 r:0.2533
en_zh Dev loss: 0.6776 r:0.4990
Current avg r:0.3761 Best avg r: 0.3931
17:03:34,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:00,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:26,489 root INFO Epoch 4 Global steps: 12200 Train loss: 0.4759
en_de Dev loss: 0.8629 r:0.2458
en_zh Dev loss: 0.7700 r:0.4785
Current avg r:0.3621 Best avg r: 0.3931
17:05:43,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:09,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:35,109 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4378
en_de Dev loss: 0.8602 r:0.2634
en_zh Dev loss: 0.7987 r:0.4774
Current avg r:0.3704 Best avg r: 0.3931
17:07:52,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:17,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:43,739 root INFO Epoch 4 Global steps: 12600 Train loss: 0.4805
en_de Dev loss: 0.8356 r:0.2667
en_zh Dev loss: 0.7454 r:0.4758
Current avg r:0.3712 Best avg r: 0.3931
17:10:00,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:26,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:10:52,358 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4347
en_de Dev loss: 0.8301 r:0.2608
en_zh Dev loss: 0.7142 r:0.4804
Current avg r:0.3706 Best avg r: 0.3931
17:12:09,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:35,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:01,34 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4943
en_de Dev loss: 0.8395 r:0.2460
en_zh Dev loss: 0.7690 r:0.4809
Current avg r:0.3635 Best avg r: 0.3931
17:14:17,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:43,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:09,731 root INFO Epoch 4 Global steps: 13200 Train loss: 0.3855
en_de Dev loss: 0.8543 r:0.2331
en_zh Dev loss: 0.7386 r:0.4744
Current avg r:0.3538 Best avg r: 0.3931
17:16:26,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:52,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:18,434 root INFO Epoch 4 Global steps: 13400 Train loss: 0.4684
en_de Dev loss: 0.8627 r:0.2360
en_zh Dev loss: 0.8556 r:0.4747
Current avg r:0.3554 Best avg r: 0.3931
17:18:35,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:01,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:27,156 root INFO Epoch 4 Global steps: 13600 Train loss: 0.5149
en_de Dev loss: 0.8457 r:0.2377
en_zh Dev loss: 0.7634 r:0.4806
Current avg r:0.3592 Best avg r: 0.3931
17:20:44,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:09,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:35,876 root INFO Epoch 4 Global steps: 13800 Train loss: 0.3922
en_de Dev loss: 0.8567 r:0.2128
en_zh Dev loss: 0.7233 r:0.4891
Current avg r:0.3510 Best avg r: 0.3931
17:22:52,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:18,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:44,613 root INFO Epoch 4 Global steps: 14000 Train loss: 0.4358
en_de Dev loss: 0.8603 r:0.2261
en_zh Dev loss: 0.7587 r:0.4757
Current avg r:0.3509 Best avg r: 0.3931
17:25:01,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:27,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:53,367 root INFO Epoch 4 Global steps: 14200 Train loss: 0.4636
en_de Dev loss: 0.8567 r:0.2263
en_zh Dev loss: 0.7652 r:0.4816
Current avg r:0.3539 Best avg r: 0.3931
17:27:10,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:36,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:02,103 root INFO Epoch 4 Global steps: 14400 Train loss: 0.4129
en_de Dev loss: 0.8597 r:0.2614
en_zh Dev loss: 0.8087 r:0.4723
Current avg r:0.3668 Best avg r: 0.3931
17:29:19,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:44,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:10,865 root INFO Epoch 4 Global steps: 14600 Train loss: 0.4231
en_de Dev loss: 0.8546 r:0.2389
en_zh Dev loss: 0.7468 r:0.4928
Current avg r:0.3659 Best avg r: 0.3931
17:31:27,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:53,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:19,615 root INFO Epoch 4 Global steps: 14800 Train loss: 0.4224
en_de Dev loss: 0.8531 r:0.2467
en_zh Dev loss: 0.7646 r:0.4930
Current avg r:0.3698 Best avg r: 0.3931
17:33:36,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:02,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:28,433 root INFO Epoch 4 Global steps: 15000 Train loss: 0.3727
en_de Dev loss: 0.8492 r:0.2578
en_zh Dev loss: 0.7319 r:0.4877
Current avg r:0.3728 Best avg r: 0.3931
17:35:45,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:11,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:37,605 root INFO Epoch 5 Global steps: 15200 Train loss: 0.4277
en_de Dev loss: 0.8333 r:0.2576
en_zh Dev loss: 0.7453 r:0.4774
Current avg r:0.3675 Best avg r: 0.3931
17:37:54,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:20,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:46,390 root INFO Epoch 5 Global steps: 15400 Train loss: 0.3989
en_de Dev loss: 0.8474 r:0.2504
en_zh Dev loss: 0.7645 r:0.4964
Current avg r:0.3734 Best avg r: 0.3931
17:40:03,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:29,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:55,137 root INFO Epoch 5 Global steps: 15600 Train loss: 0.4206
en_de Dev loss: 0.8500 r:0.2484
en_zh Dev loss: 0.7948 r:0.4841
Current avg r:0.3662 Best avg r: 0.3931
17:42:12,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:38,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:03,908 root INFO Epoch 5 Global steps: 15800 Train loss: 0.3880
en_de Dev loss: 0.8478 r:0.2386
en_zh Dev loss: 0.7386 r:0.4847
Current avg r:0.3616 Best avg r: 0.3931
17:44:20,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:46,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:12,668 root INFO Epoch 5 Global steps: 16000 Train loss: 0.3982
en_de Dev loss: 0.8433 r:0.2497
en_zh Dev loss: 0.7344 r:0.4880
Current avg r:0.3689 Best avg r: 0.3931
17:46:29,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:55,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:21,451 root INFO Epoch 5 Global steps: 16200 Train loss: 0.3446
en_de Dev loss: 0.8754 r:0.2571
en_zh Dev loss: 0.7824 r:0.4767
Current avg r:0.3669 Best avg r: 0.3931
17:48:38,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:04,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:30,144 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3878
en_de Dev loss: 0.8516 r:0.2642
en_zh Dev loss: 0.8200 r:0.4775
Current avg r:0.3709 Best avg r: 0.3931
17:50:47,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:12,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:38,829 root INFO Epoch 5 Global steps: 16600 Train loss: 0.3590
en_de Dev loss: 0.8521 r:0.2588
en_zh Dev loss: 0.8302 r:0.4695
Current avg r:0.3641 Best avg r: 0.3931
17:52:55,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:21,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:47,504 root INFO Epoch 5 Global steps: 16800 Train loss: 0.3908
en_de Dev loss: 0.8660 r:0.2575
en_zh Dev loss: 0.8634 r:0.4621
Current avg r:0.3598 Best avg r: 0.3931
17:55:04,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:30,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:56,120 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3548
en_de Dev loss: 0.8471 r:0.2470
en_zh Dev loss: 0.7742 r:0.4709
Current avg r:0.3590 Best avg r: 0.3931
17:57:13,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:38,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:04,775 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3781
en_de Dev loss: 0.8558 r:0.2117
en_zh Dev loss: 0.7798 r:0.4732
Current avg r:0.3424 Best avg r: 0.3931
17:59:21,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:47,597 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:13,474 root INFO Epoch 5 Global steps: 17400 Train loss: 0.3719
en_de Dev loss: 0.8554 r:0.2153
en_zh Dev loss: 0.7573 r:0.4750
Current avg r:0.3451 Best avg r: 0.3931
18:01:30,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:56,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:22,112 root INFO Epoch 5 Global steps: 17600 Train loss: 0.3242
en_de Dev loss: 0.8800 r:0.2084
en_zh Dev loss: 0.8239 r:0.4765
Current avg r:0.3425 Best avg r: 0.3931
18:03:39,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:04,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:30,793 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3874
en_de Dev loss: 0.8624 r:0.2234
en_zh Dev loss: 0.7823 r:0.4668
Current avg r:0.3451 Best avg r: 0.3931
18:05:47,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:13,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:39,454 root INFO Epoch 5 Global steps: 18000 Train loss: 0.2987
en_de Dev loss: 0.8672 r:0.2280
en_zh Dev loss: 0.7877 r:0.4685
Current avg r:0.3482 Best avg r: 0.3931
18:07:56,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:22,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:48,512 root INFO Epoch 6 Global steps: 18200 Train loss: 0.3012
en_de Dev loss: 0.8635 r:0.2262
en_zh Dev loss: 0.7615 r:0.4844
Current avg r:0.3553 Best avg r: 0.3931
18:10:05,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:31,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:57,166 root INFO Epoch 6 Global steps: 18400 Train loss: 0.3079
en_de Dev loss: 0.8542 r:0.2197
en_zh Dev loss: 0.7912 r:0.4721
Current avg r:0.3459 Best avg r: 0.3931
18:12:14,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:39,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:05,846 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3637
en_de Dev loss: 0.8511 r:0.2367
en_zh Dev loss: 0.7606 r:0.4828
Current avg r:0.3598 Best avg r: 0.3931
18:14:22,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:48,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:14,555 root INFO Epoch 6 Global steps: 18800 Train loss: 0.3046
en_de Dev loss: 0.8569 r:0.2325
en_zh Dev loss: 0.7456 r:0.4893
Current avg r:0.3609 Best avg r: 0.3931
18:16:31,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:57,366 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:23,243 root INFO Epoch 6 Global steps: 19000 Train loss: 0.3449
en_de Dev loss: 0.8812 r:0.2084
en_zh Dev loss: 0.8078 r:0.4806
Current avg r:0.3445 Best avg r: 0.3931
18:18:40,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:06,56 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:31,939 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3495
en_de Dev loss: 0.8727 r:0.1938
en_zh Dev loss: 0.7406 r:0.4738
Current avg r:0.3338 Best avg r: 0.3931
18:20:48,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:14,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:40,649 root INFO Epoch 6 Global steps: 19400 Train loss: 0.3301
en_de Dev loss: 0.8995 r:0.1981
en_zh Dev loss: 0.7665 r:0.4773
Current avg r:0.3377 Best avg r: 0.3931
18:22:57,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:23,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:49,344 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3634
en_de Dev loss: 0.8658 r:0.2111
en_zh Dev loss: 0.7550 r:0.4768
Current avg r:0.3439 Best avg r: 0.3931
18:25:06,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:32,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:58,55 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3024
en_de Dev loss: 0.8991 r:0.1872
en_zh Dev loss: 0.7942 r:0.4786
Current avg r:0.3329 Best avg r: 0.3931
18:27:15,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:40,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:06,752 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3409
en_de Dev loss: 0.9012 r:0.1825
en_zh Dev loss: 0.7664 r:0.4857
Current avg r:0.3341 Best avg r: 0.3931
18:29:23,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:49,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:15,449 root INFO Epoch 6 Global steps: 20200 Train loss: 0.3205
en_de Dev loss: 0.8779 r:0.1974
en_zh Dev loss: 0.7674 r:0.4805
Current avg r:0.3390 Best avg r: 0.3931
18:31:32,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:58,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:24,131 root INFO Epoch 6 Global steps: 20400 Train loss: 0.3046
en_de Dev loss: 0.8838 r:0.1955
en_zh Dev loss: 0.8513 r:0.4488
Current avg r:0.3221 Best avg r: 0.3931
18:33:41,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:06,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:32,773 root INFO Epoch 6 Global steps: 20600 Train loss: 0.2932
en_de Dev loss: 0.8833 r:0.2085
en_zh Dev loss: 0.7561 r:0.4714
Current avg r:0.3399 Best avg r: 0.3931
18:35:49,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:15,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:41,414 root INFO Epoch 6 Global steps: 20800 Train loss: 0.2832
en_de Dev loss: 0.8993 r:0.2034
en_zh Dev loss: 0.7674 r:0.4856
Current avg r:0.3445 Best avg r: 0.3931
18:37:58,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:24,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:50,129 root INFO Epoch 6 Global steps: 21000 Train loss: 0.3222
en_de Dev loss: 0.8812 r:0.2105
en_zh Dev loss: 0.7912 r:0.4736
Current avg r:0.3420 Best avg r: 0.3931
18:40:07,454 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:33,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:59,218 root INFO Epoch 7 Global steps: 21200 Train loss: 0.3078
en_de Dev loss: 0.8957 r:0.2039
en_zh Dev loss: 0.8299 r:0.4706
Current avg r:0.3372 Best avg r: 0.3931
18:42:16,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:42,42 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:07,915 root INFO Epoch 7 Global steps: 21400 Train loss: 0.3031
en_de Dev loss: 0.8875 r:0.2041
en_zh Dev loss: 0.8082 r:0.4619
Current avg r:0.3330 Best avg r: 0.3931
18:44:24,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:50,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:16,623 root INFO Epoch 7 Global steps: 21600 Train loss: 0.3132
en_de Dev loss: 0.9061 r:0.1865
en_zh Dev loss: 0.8343 r:0.4603
Current avg r:0.3234 Best avg r: 0.3931
18:46:33,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:59,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:25,315 root INFO Epoch 7 Global steps: 21800 Train loss: 0.3136
en_de Dev loss: 0.8868 r:0.2071
en_zh Dev loss: 0.8550 r:0.4398
Current avg r:0.3234 Best avg r: 0.3931
18:48:42,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:08,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:34,1 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2610
en_de Dev loss: 0.8685 r:0.2120
en_zh Dev loss: 0.7654 r:0.4583
Current avg r:0.3351 Best avg r: 0.3931
18:50:50,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:16,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:42,675 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2680
en_de Dev loss: 0.8969 r:0.2018
en_zh Dev loss: 0.8381 r:0.4514
Current avg r:0.3266 Best avg r: 0.3931
18:52:59,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:25,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:51,320 root INFO Epoch 7 Global steps: 22400 Train loss: 0.2797
en_de Dev loss: 0.8903 r:0.1976
en_zh Dev loss: 0.8012 r:0.4636
Current avg r:0.3306 Best avg r: 0.3931
18:55:08,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:34,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:59,995 root INFO Epoch 7 Global steps: 22600 Train loss: 0.2761
en_de Dev loss: 0.8810 r:0.2106
en_zh Dev loss: 0.7875 r:0.4721
Current avg r:0.3414 Best avg r: 0.3931
18:57:16,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:42,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:08,671 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2898
en_de Dev loss: 0.9516 r:0.1968
en_zh Dev loss: 0.9609 r:0.4598
Current avg r:0.3283 Best avg r: 0.3931
18:59:25,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:51,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:17,372 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2611
en_de Dev loss: 0.8929 r:0.2083
en_zh Dev loss: 0.8194 r:0.4632
Current avg r:0.3357 Best avg r: 0.3931
19:01:34,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:00,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:26,73 root INFO Epoch 7 Global steps: 23200 Train loss: 0.2700
en_de Dev loss: 0.8968 r:0.1953
en_zh Dev loss: 0.7540 r:0.4788
Current avg r:0.3371 Best avg r: 0.3931
19:03:43,6 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:08,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:34,755 root INFO Epoch 7 Global steps: 23400 Train loss: 0.2858
en_de Dev loss: 0.8781 r:0.1852
en_zh Dev loss: 0.7370 r:0.4681
Current avg r:0.3266 Best avg r: 0.3931
19:05:51,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:17,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:43,459 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2720
en_de Dev loss: 0.8660 r:0.2150
en_zh Dev loss: 0.7839 r:0.4603
Current avg r:0.3377 Best avg r: 0.3931
19:08:00,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:26,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:52,154 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2625
en_de Dev loss: 0.9150 r:0.2000
en_zh Dev loss: 0.8407 r:0.4619
Current avg r:0.3309 Best avg r: 0.3931
19:10:09,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:34,975 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:00,866 root INFO Epoch 7 Global steps: 24000 Train loss: 0.2570
en_de Dev loss: 0.8997 r:0.1876
en_zh Dev loss: 0.7710 r:0.4731
Current avg r:0.3304 Best avg r: 0.3931
19:12:18,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:44,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:09,943 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2867
en_de Dev loss: 0.9003 r:0.2076
en_zh Dev loss: 0.7825 r:0.4782
Current avg r:0.3429 Best avg r: 0.3931
19:14:26,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:52,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:18,663 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2628
en_de Dev loss: 0.8799 r:0.2057
en_zh Dev loss: 0.7744 r:0.4774
Current avg r:0.3416 Best avg r: 0.3931
19:16:35,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:01,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:27,398 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2742
en_de Dev loss: 0.8869 r:0.1881
en_zh Dev loss: 0.7619 r:0.4681
Current avg r:0.3281 Best avg r: 0.3931
19:18:44,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:10,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:36,101 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2521
en_de Dev loss: 0.8977 r:0.1799
en_zh Dev loss: 0.8190 r:0.4632
Current avg r:0.3215 Best avg r: 0.3931
19:20:53,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:18,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:44,866 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2159
en_de Dev loss: 0.9064 r:0.1938
en_zh Dev loss: 0.8704 r:0.4646
Current avg r:0.3292 Best avg r: 0.3931
19:23:01,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:27,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:53,610 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2384
en_de Dev loss: 0.9065 r:0.1891
en_zh Dev loss: 0.8078 r:0.4648
Current avg r:0.3270 Best avg r: 0.3931
19:25:10,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:36,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:02,324 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2410
en_de Dev loss: 0.9035 r:0.1906
en_zh Dev loss: 0.8492 r:0.4540
Current avg r:0.3223 Best avg r: 0.3931
19:27:19,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:45,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:11,33 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2622
en_de Dev loss: 0.9056 r:0.1928
en_zh Dev loss: 0.8386 r:0.4524
Current avg r:0.3226 Best avg r: 0.3931
19:29:27,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:53,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:19,753 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2298
en_de Dev loss: 0.8882 r:0.1982
en_zh Dev loss: 0.8617 r:0.4517
Current avg r:0.3249 Best avg r: 0.3931
19:31:36,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:02,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:28,453 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2650
en_de Dev loss: 0.8908 r:0.1829
en_zh Dev loss: 0.7737 r:0.4620
Current avg r:0.3225 Best avg r: 0.3931
19:33:45,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:11,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:37,156 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2353
en_de Dev loss: 0.8770 r:0.2028
en_zh Dev loss: 0.7989 r:0.4645
Current avg r:0.3337 Best avg r: 0.3931
19:35:54,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:20,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:45,896 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2634
en_de Dev loss: 0.9188 r:0.1807
en_zh Dev loss: 0.8350 r:0.4610
Current avg r:0.3208 Best avg r: 0.3931
19:38:02,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:28,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:54,669 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2519
en_de Dev loss: 0.9221 r:0.1742
en_zh Dev loss: 0.8510 r:0.4560
Current avg r:0.3151 Best avg r: 0.3931
19:40:11,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:37,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:03,393 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2392
en_de Dev loss: 0.8977 r:0.1873
en_zh Dev loss: 0.7983 r:0.4618
Current avg r:0.3245 Best avg r: 0.3931
19:42:20,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:46,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:12,175 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2374
en_de Dev loss: 0.9024 r:0.1926
en_zh Dev loss: 0.8727 r:0.4537
Current avg r:0.3231 Best avg r: 0.3931
19:44:29,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:55,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:21,249 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2292
en_de Dev loss: 0.8943 r:0.1823
en_zh Dev loss: 0.7821 r:0.4691
Current avg r:0.3257 Best avg r: 0.3931
19:46:38,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:04,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:30,12 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2436
en_de Dev loss: 0.9220 r:0.1814
en_zh Dev loss: 0.8177 r:0.4720
Current avg r:0.3267 Best avg r: 0.3931
19:48:46,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:12,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:38,761 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2105
en_de Dev loss: 0.8961 r:0.1858
en_zh Dev loss: 0.8636 r:0.4506
Current avg r:0.3182 Best avg r: 0.3931
19:50:55,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:21,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:47,483 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2238
en_de Dev loss: 0.9063 r:0.1980
en_zh Dev loss: 0.7843 r:0.4796
Current avg r:0.3388 Best avg r: 0.3931
19:53:04,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:30,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:56,146 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2176
en_de Dev loss: 0.8941 r:0.1922
en_zh Dev loss: 0.8440 r:0.4577
Current avg r:0.3249 Best avg r: 0.3931
19:55:13,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:38,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:04,783 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2289
en_de Dev loss: 0.8982 r:0.1853
en_zh Dev loss: 0.7920 r:0.4696
Current avg r:0.3275 Best avg r: 0.3931
19:57:21,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:47,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:13,428 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2439
en_de Dev loss: 0.9164 r:0.1877
en_zh Dev loss: 0.8910 r:0.4642
Current avg r:0.3260 Best avg r: 0.3931
19:59:30,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:56,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:22,108 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2168
en_de Dev loss: 0.8897 r:0.1938
en_zh Dev loss: 0.8367 r:0.4612
Current avg r:0.3275 Best avg r: 0.3931
20:01:39,70 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:04,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:30,802 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2104
en_de Dev loss: 0.9175 r:0.1841
en_zh Dev loss: 0.8507 r:0.4634
Current avg r:0.3238 Best avg r: 0.3931
20:03:47,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:13,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:39,496 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2200
en_de Dev loss: 0.9118 r:0.1766
en_zh Dev loss: 0.8869 r:0.4603
Current avg r:0.3185 Best avg r: 0.3931
20:05:56,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:22,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:48,147 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2249
en_de Dev loss: 0.9172 r:0.1683
en_zh Dev loss: 0.8223 r:0.4674
Current avg r:0.3179 Best avg r: 0.3931
20:08:05,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:30,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:56,777 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2005
en_de Dev loss: 0.9389 r:0.1734
en_zh Dev loss: 0.8547 r:0.4662
Current avg r:0.3198 Best avg r: 0.3931
20:10:13,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:10:39,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:05,382 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2281
en_de Dev loss: 0.9219 r:0.1660
en_zh Dev loss: 0.8504 r:0.4675
Current avg r:0.3168 Best avg r: 0.3931
20:12:22,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:48,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:14,23 root INFO Epoch 9 Global steps: 29800 Train loss: 0.2222
en_de Dev loss: 0.9129 r:0.1874
en_zh Dev loss: 0.8276 r:0.4740
Current avg r:0.3307 Best avg r: 0.3931
20:14:30,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:56,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:22,697 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2199
en_de Dev loss: 0.8903 r:0.1668
en_zh Dev loss: 0.7616 r:0.4622
Current avg r:0.3145 Best avg r: 0.3931
20:16:39,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:05,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:31,718 root INFO Epoch 10 Global steps: 30200 Train loss: 0.2033
en_de Dev loss: 0.9209 r:0.1864
en_zh Dev loss: 0.7850 r:0.4766
Current avg r:0.3315 Best avg r: 0.3931
20:18:48,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:14,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:40,361 root INFO Epoch 10 Global steps: 30400 Train loss: 0.2104
en_de Dev loss: 0.9241 r:0.1819
en_zh Dev loss: 0.7941 r:0.4762
Current avg r:0.3291 Best avg r: 0.3931
20:20:57,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:23,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:48,984 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2293
en_de Dev loss: 0.9134 r:0.1803
en_zh Dev loss: 0.7712 r:0.4749
Current avg r:0.3276 Best avg r: 0.3931
20:23:05,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:31,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:57,642 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1863
en_de Dev loss: 0.8860 r:0.1835
en_zh Dev loss: 0.7487 r:0.4740
Current avg r:0.3288 Best avg r: 0.3931
20:25:14,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:40,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:06,345 root INFO Epoch 10 Global steps: 31000 Train loss: 0.2046
en_de Dev loss: 0.8901 r:0.2018
en_zh Dev loss: 0.7369 r:0.4837
Current avg r:0.3428 Best avg r: 0.3931
20:27:23,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:49,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:28:15,17 root INFO Epoch 10 Global steps: 31200 Train loss: 0.2266
en_de Dev loss: 0.9083 r:0.1782
en_zh Dev loss: 0.8011 r:0.4789
Current avg r:0.3286 Best avg r: 0.3931
20:29:31,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:57,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:23,671 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1888
en_de Dev loss: 0.9297 r:0.1779
en_zh Dev loss: 0.8709 r:0.4682
Current avg r:0.3231 Best avg r: 0.3931
20:31:40,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:06,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:32,333 root INFO Epoch 10 Global steps: 31600 Train loss: 0.1967
en_de Dev loss: 0.9193 r:0.1794
en_zh Dev loss: 0.8129 r:0.4716
Current avg r:0.3255 Best avg r: 0.3931
20:33:49,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:15,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:34:41,47 root INFO Epoch 10 Global steps: 31800 Train loss: 0.2038
en_de Dev loss: 0.9226 r:0.1789
en_zh Dev loss: 0.8057 r:0.4752
Current avg r:0.3271 Best avg r: 0.3931
20:35:57,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:23,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:49,735 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1962
en_de Dev loss: 0.9356 r:0.1724
en_zh Dev loss: 0.8006 r:0.4806
Current avg r:0.3265 Best avg r: 0.3931
20:38:06,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:32,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:58,391 root INFO Epoch 10 Global steps: 32200 Train loss: 0.2152
en_de Dev loss: 0.9473 r:0.1653
en_zh Dev loss: 0.7907 r:0.4725
Current avg r:0.3189 Best avg r: 0.3931
20:40:15,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:41,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:07,59 root INFO Epoch 10 Global steps: 32400 Train loss: 0.2096
en_de Dev loss: 0.9552 r:0.1757
en_zh Dev loss: 0.8007 r:0.4863
Current avg r:0.3310 Best avg r: 0.3931
20:42:24,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:49,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:15,814 root INFO Epoch 10 Global steps: 32600 Train loss: 0.2198
en_de Dev loss: 0.9174 r:0.1861
en_zh Dev loss: 0.7562 r:0.4888
Current avg r:0.3374 Best avg r: 0.3931
20:44:32,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:58,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:24,594 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1754
en_de Dev loss: 0.9351 r:0.1831
en_zh Dev loss: 0.7897 r:0.4899
Current avg r:0.3365 Best avg r: 0.3931
20:46:41,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:07,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:33,363 root INFO Epoch 10 Global steps: 33000 Train loss: 0.2014
en_de Dev loss: 0.9426 r:0.1686
en_zh Dev loss: 0.8169 r:0.4790
Current avg r:0.3238 Best avg r: 0.3931
20:48:50,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:16,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:42,442 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1806
en_de Dev loss: 0.9100 r:0.2072
en_zh Dev loss: 0.7745 r:0.4844
Current avg r:0.3458 Best avg r: 0.3931
20:50:59,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:25,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:51,169 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1858
en_de Dev loss: 0.9173 r:0.1871
en_zh Dev loss: 0.8090 r:0.4751
Current avg r:0.3311 Best avg r: 0.3931
20:53:08,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:34,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:59,927 root INFO Epoch 11 Global steps: 33600 Train loss: 0.2012
en_de Dev loss: 0.9291 r:0.2049
en_zh Dev loss: 0.8182 r:0.4863
Current avg r:0.3456 Best avg r: 0.3931
20:55:16,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:42,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:08,688 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1769
en_de Dev loss: 0.8764 r:0.2131
en_zh Dev loss: 0.7601 r:0.4743
Current avg r:0.3437 Best avg r: 0.3931
20:57:25,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:51,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:17,501 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1858
en_de Dev loss: 0.9038 r:0.1937
en_zh Dev loss: 0.7602 r:0.4746
Current avg r:0.3341 Best avg r: 0.3931
20:59:34,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:00,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:26,305 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1722
en_de Dev loss: 0.9081 r:0.1945
en_zh Dev loss: 0.7948 r:0.4767
Current avg r:0.3356 Best avg r: 0.3931
21:01:43,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:09,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:35,148 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1987
en_de Dev loss: 0.9159 r:0.1816
en_zh Dev loss: 0.8238 r:0.4835
Current avg r:0.3326 Best avg r: 0.3931
21:03:52,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:18,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:43,979 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1706
en_de Dev loss: 0.9547 r:0.1729
en_zh Dev loss: 0.8107 r:0.4841
Current avg r:0.3285 Best avg r: 0.3931
21:06:00,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:26,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:52,797 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1859
en_de Dev loss: 0.9245 r:0.1718
en_zh Dev loss: 0.8052 r:0.4800
Current avg r:0.3259 Best avg r: 0.3931
21:08:09,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:35,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:01,756 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1838
en_de Dev loss: 0.9890 r:0.1681
en_zh Dev loss: 0.8477 r:0.4750
Current avg r:0.3215 Best avg r: 0.3931
21:10:18,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:44,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:10,690 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1818
en_de Dev loss: 0.9413 r:0.1906
en_zh Dev loss: 0.8380 r:0.4753
Current avg r:0.3330 Best avg r: 0.3931
21:12:27,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:53,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:19,637 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1656
en_de Dev loss: 0.9345 r:0.1776
en_zh Dev loss: 0.8328 r:0.4764
Current avg r:0.3270 Best avg r: 0.3931
21:14:36,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:02,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:28,550 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1970
en_de Dev loss: 0.9204 r:0.1766
en_zh Dev loss: 0.8100 r:0.4652
Current avg r:0.3209 Best avg r: 0.3931
21:16:45,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:11,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:37,532 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1722
en_de Dev loss: 0.9253 r:0.1883
en_zh Dev loss: 0.8335 r:0.4727
Current avg r:0.3305 Best avg r: 0.3931
21:18:54,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:20,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:46,530 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1634
en_de Dev loss: 0.9324 r:0.1713
en_zh Dev loss: 0.8012 r:0.4668
Current avg r:0.3190 Best avg r: 0.3931
21:21:03,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:29,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:55,799 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1598
en_de Dev loss: 0.9485 r:0.1784
en_zh Dev loss: 0.8278 r:0.4733
Current avg r:0.3259 Best avg r: 0.3931
21:23:12,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:38,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:04,745 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1664
en_de Dev loss: 0.9727 r:0.1662
en_zh Dev loss: 0.8679 r:0.4638
Current avg r:0.3150 Best avg r: 0.3931
21:25:21,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:47,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:13,697 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1635
en_de Dev loss: 0.9415 r:0.1672
en_zh Dev loss: 0.8212 r:0.4773
Current avg r:0.3223 Best avg r: 0.3931
21:27:30,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:56,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:28:22,682 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1705
en_de Dev loss: 0.9572 r:0.1648
en_zh Dev loss: 0.8621 r:0.4742
Current avg r:0.3195 Best avg r: 0.3931
21:29:39,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:05,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:30:31,604 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1765
en_de Dev loss: 0.9215 r:0.1867
en_zh Dev loss: 0.7716 r:0.4824
Current avg r:0.3345 Best avg r: 0.3931
21:31:48,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:14,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:40,620 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1606
en_de Dev loss: 0.9428 r:0.1861
en_zh Dev loss: 0.8250 r:0.4784
Current avg r:0.3323 Best avg r: 0.3931
21:33:57,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:23,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:49,597 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1579
en_de Dev loss: 0.9419 r:0.1801
en_zh Dev loss: 0.8266 r:0.4796
Current avg r:0.3298 Best avg r: 0.3931
21:36:06,654 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:32,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:58,520 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1504
en_de Dev loss: 0.9287 r:0.1832
en_zh Dev loss: 0.8451 r:0.4716
Current avg r:0.3274 Best avg r: 0.3931
21:38:15,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:41,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:07,442 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1685
en_de Dev loss: 0.9008 r:0.1929
en_zh Dev loss: 0.7668 r:0.4773
Current avg r:0.3351 Best avg r: 0.3931
21:40:24,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:50,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:16,362 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1708
en_de Dev loss: 0.9195 r:0.1874
en_zh Dev loss: 0.7896 r:0.4805
Current avg r:0.3339 Best avg r: 0.3931
21:42:33,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:59,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:25,336 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1580
en_de Dev loss: 0.9379 r:0.1871
en_zh Dev loss: 0.8407 r:0.4800
Current avg r:0.3335 Best avg r: 0.3931
21:44:42,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:08,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:34,307 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1667
en_de Dev loss: 0.9168 r:0.1740
en_zh Dev loss: 0.8298 r:0.4853
Current avg r:0.3297 Best avg r: 0.3931
21:46:51,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:17,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:47:43,278 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1685
en_de Dev loss: 0.9199 r:0.1817
en_zh Dev loss: 0.7704 r:0.4774
Current avg r:0.3296 Best avg r: 0.3931
21:49:00,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:26,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:52,217 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1630
en_de Dev loss: 0.9151 r:0.1870
en_zh Dev loss: 0.8203 r:0.4834
Current avg r:0.3352 Best avg r: 0.3931
21:51:09,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:35,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:01,147 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1488
en_de Dev loss: 0.9622 r:0.1985
en_zh Dev loss: 0.8143 r:0.4903
Current avg r:0.3444 Best avg r: 0.3931
21:53:18,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:44,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:10,334 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1610
en_de Dev loss: 0.9263 r:0.1941
en_zh Dev loss: 0.8110 r:0.4893
Current avg r:0.3417 Best avg r: 0.3931
21:55:27,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:53,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:19,252 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1579
en_de Dev loss: 0.9375 r:0.1772
en_zh Dev loss: 0.8077 r:0.4821
Current avg r:0.3296 Best avg r: 0.3931
21:57:36,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:02,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:28,194 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1407
en_de Dev loss: 0.9474 r:0.1753
en_zh Dev loss: 0.7885 r:0.4895
Current avg r:0.3324 Best avg r: 0.3931
21:59:45,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:11,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:37,224 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1417
en_de Dev loss: 0.9510 r:0.1757
en_zh Dev loss: 0.7714 r:0.4893
Current avg r:0.3325 Best avg r: 0.3931
22:01:54,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:20,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:46,252 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1511
en_de Dev loss: 0.9712 r:0.1585
en_zh Dev loss: 0.8755 r:0.4729
Current avg r:0.3157 Best avg r: 0.3931
22:04:03,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:29,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:55,252 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1442
en_de Dev loss: 0.9391 r:0.1708
en_zh Dev loss: 0.7312 r:0.4870
Current avg r:0.3289 Best avg r: 0.3931
22:06:12,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:38,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:04,200 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1593
en_de Dev loss: 0.9645 r:0.1711
en_zh Dev loss: 0.8297 r:0.4832
Current avg r:0.3271 Best avg r: 0.3931
22:08:21,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:47,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:13,123 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1578
en_de Dev loss: 0.9412 r:0.1749
en_zh Dev loss: 0.8106 r:0.4842
Current avg r:0.3295 Best avg r: 0.3931
22:10:30,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:56,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:22,84 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1426
en_de Dev loss: 0.9474 r:0.1711
en_zh Dev loss: 0.8056 r:0.4800
Current avg r:0.3256 Best avg r: 0.3931
22:12:39,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:05,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:31,75 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1420
en_de Dev loss: 0.9259 r:0.1710
en_zh Dev loss: 0.8172 r:0.4785
Current avg r:0.3247 Best avg r: 0.3931
22:14:48,181 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:14,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:40,105 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1585
en_de Dev loss: 0.9423 r:0.1742
en_zh Dev loss: 0.7859 r:0.4787
Current avg r:0.3264 Best avg r: 0.3931
22:16:57,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:23,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:49,101 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1345
en_de Dev loss: 0.9318 r:0.1670
en_zh Dev loss: 0.7581 r:0.4768
Current avg r:0.3219 Best avg r: 0.3931
22:19:06,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:32,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:58,78 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1477
en_de Dev loss: 0.9346 r:0.1732
en_zh Dev loss: 0.7761 r:0.4855
Current avg r:0.3293 Best avg r: 0.3931
22:21:15,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:41,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:07,67 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1443
en_de Dev loss: 0.9200 r:0.1787
en_zh Dev loss: 0.7943 r:0.4849
Current avg r:0.3318 Best avg r: 0.3931
22:23:24,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:50,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:16,80 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1327
en_de Dev loss: 0.9300 r:0.1878
en_zh Dev loss: 0.8150 r:0.4794
Current avg r:0.3336 Best avg r: 0.3931
22:25:33,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:59,438 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:25,371 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1293
en_de Dev loss: 0.9219 r:0.1874
en_zh Dev loss: 0.8865 r:0.4732
Current avg r:0.3303 Best avg r: 0.3931
22:27:42,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:08,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:28:34,299 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1378
en_de Dev loss: 0.9237 r:0.1885
en_zh Dev loss: 0.8320 r:0.4723
Current avg r:0.3304 Best avg r: 0.3931
22:29:51,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:17,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:43,256 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1391
en_de Dev loss: 0.9024 r:0.2009
en_zh Dev loss: 0.8057 r:0.4744
Current avg r:0.3376 Best avg r: 0.3931
22:32:00,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:26,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:52,251 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1332
en_de Dev loss: 0.9397 r:0.1851
en_zh Dev loss: 0.7835 r:0.4843
Current avg r:0.3347 Best avg r: 0.3931
22:34:09,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:35,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:01,239 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1335
en_de Dev loss: 0.9902 r:0.1669
en_zh Dev loss: 0.8431 r:0.4723
Current avg r:0.3196 Best avg r: 0.3931
22:36:18,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:44,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:10,195 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1258
en_de Dev loss: 0.9654 r:0.1830
en_zh Dev loss: 0.8262 r:0.4779
Current avg r:0.3304 Best avg r: 0.3931
22:38:27,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:53,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:19,177 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1315
en_de Dev loss: 0.9299 r:0.1858
en_zh Dev loss: 0.7550 r:0.4807
Current avg r:0.3333 Best avg r: 0.3931
22:40:36,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:02,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:28,160 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1311
en_de Dev loss: 0.9533 r:0.1856
en_zh Dev loss: 0.8140 r:0.4796
Current avg r:0.3326 Best avg r: 0.3931
22:42:45,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:11,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:43:37,96 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1375
en_de Dev loss: 1.0404 r:0.1631
en_zh Dev loss: 0.8430 r:0.4821
Current avg r:0.3226 Best avg r: 0.3931
22:44:54,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:45:20,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:46,45 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1348
en_de Dev loss: 0.9364 r:0.1888
en_zh Dev loss: 0.7637 r:0.4857
Current avg r:0.3373 Best avg r: 0.3931
22:47:03,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:29,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:55,6 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1376
en_de Dev loss: 0.9137 r:0.1816
en_zh Dev loss: 0.7986 r:0.4818
Current avg r:0.3317 Best avg r: 0.3931
22:49:12,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:49:38,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:03,996 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1385
en_de Dev loss: 0.9303 r:0.1777
en_zh Dev loss: 0.7779 r:0.4840
Current avg r:0.3308 Best avg r: 0.3931
22:51:21,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:47,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:12,949 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1345
en_de Dev loss: 0.9330 r:0.1908
en_zh Dev loss: 0.8432 r:0.4756
Current avg r:0.3332 Best avg r: 0.3931
22:53:29,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:55,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:21,874 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1289
en_de Dev loss: 0.9320 r:0.1736
en_zh Dev loss: 0.8318 r:0.4736
Current avg r:0.3236 Best avg r: 0.3931
22:55:38,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:04,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:30,772 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1259
en_de Dev loss: 0.9229 r:0.1731
en_zh Dev loss: 0.7658 r:0.4819
Current avg r:0.3275 Best avg r: 0.3931
22:57:48,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:14,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:40,143 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1202
en_de Dev loss: 0.9437 r:0.1631
en_zh Dev loss: 0.8102 r:0.4831
Current avg r:0.3231 Best avg r: 0.3931
22:59:57,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:00:23,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:49,89 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1188
en_de Dev loss: 0.9520 r:0.1739
en_zh Dev loss: 0.8184 r:0.4879
Current avg r:0.3309 Best avg r: 0.3931
23:02:06,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:32,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:02:58,34 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1244
en_de Dev loss: 0.9300 r:0.1660
en_zh Dev loss: 0.8020 r:0.4957
Current avg r:0.3309 Best avg r: 0.3931
23:04:15,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:41,42 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:06,978 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1157
en_de Dev loss: 0.9373 r:0.1684
en_zh Dev loss: 0.7623 r:0.4964
Current avg r:0.3324 Best avg r: 0.3931
23:06:24,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:49,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:15,939 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1145
en_de Dev loss: 0.9307 r:0.1688
en_zh Dev loss: 0.7983 r:0.4891
Current avg r:0.3290 Best avg r: 0.3931
23:08:32,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:58,934 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:09:24,878 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1270
en_de Dev loss: 0.9580 r:0.1547
en_zh Dev loss: 0.7953 r:0.4863
Current avg r:0.3205 Best avg r: 0.3931
23:10:41,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:07,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:33,828 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1173
en_de Dev loss: 0.9466 r:0.1682
en_zh Dev loss: 0.7781 r:0.4891
Current avg r:0.3287 Best avg r: 0.3931
23:12:50,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:16,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:42,704 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1272
en_de Dev loss: 0.9517 r:0.1843
en_zh Dev loss: 0.8333 r:0.4878
Current avg r:0.3360 Best avg r: 0.3931
23:14:59,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:25,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:51,567 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1181
en_de Dev loss: 0.9427 r:0.1830
en_zh Dev loss: 0.7822 r:0.4937
Current avg r:0.3383 Best avg r: 0.3931
23:17:08,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:34,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:00,410 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1192
en_de Dev loss: 0.9489 r:0.1800
en_zh Dev loss: 0.7729 r:0.4977
Current avg r:0.3389 Best avg r: 0.3931
23:19:17,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:43,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:09,240 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1152
en_de Dev loss: 0.9331 r:0.1751
en_zh Dev loss: 0.7658 r:0.4907
Current avg r:0.3329 Best avg r: 0.3931
23:21:26,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:52,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:18,72 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1266
en_de Dev loss: 0.9877 r:0.1753
en_zh Dev loss: 0.8030 r:0.4907
Current avg r:0.3330 Best avg r: 0.3931
23:23:35,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:01,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:24:26,935 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1163
en_de Dev loss: 0.9439 r:0.1662
en_zh Dev loss: 0.7618 r:0.4923
Current avg r:0.3293 Best avg r: 0.3931
23:25:43,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:09,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:35,778 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1156
en_de Dev loss: 0.9723 r:0.1625
en_zh Dev loss: 0.8154 r:0.4911
Current avg r:0.3268 Best avg r: 0.3931
23:27:52,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:18,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:28:44,608 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1174
en_de Dev loss: 0.9608 r:0.1625
en_zh Dev loss: 0.8052 r:0.4917
Current avg r:0.3271 Best avg r: 0.3931
23:30:01,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:27,790 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:53,689 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1057
en_de Dev loss: 0.9650 r:0.1612
en_zh Dev loss: 0.8012 r:0.4916
Current avg r:0.3264 Best avg r: 0.3931
23:32:10,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:36,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:02,550 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1167
en_de Dev loss: 0.9599 r:0.1592
en_zh Dev loss: 0.7656 r:0.4965
Current avg r:0.3278 Best avg r: 0.3931
23:34:19,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:34:45,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:11,382 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1025
en_de Dev loss: 0.9690 r:0.1697
en_zh Dev loss: 0.8105 r:0.4904
Current avg r:0.3300 Best avg r: 0.3931
23:36:28,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:54,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:20,199 root INFO Epoch 16 Global steps: 48800 Train loss: 0.0969
en_de Dev loss: 0.9540 r:0.1630
en_zh Dev loss: 0.7721 r:0.4921
Current avg r:0.3276 Best avg r: 0.3931
23:38:37,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:03,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:29,25 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1127
en_de Dev loss: 0.9521 r:0.1581
en_zh Dev loss: 0.7450 r:0.4980
Current avg r:0.3280 Best avg r: 0.3931
23:40:46,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:11,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:37,894 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1101
en_de Dev loss: 0.9895 r:0.1499
en_zh Dev loss: 0.7945 r:0.4949
Current avg r:0.3224 Best avg r: 0.3931
23:42:54,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:20,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:46,769 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1037
en_de Dev loss: 0.9724 r:0.1696
en_zh Dev loss: 0.8056 r:0.4923
Current avg r:0.3309 Best avg r: 0.3931
23:45:03,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:29,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:55,658 root INFO Epoch 16 Global steps: 49600 Train loss: 0.1053
en_de Dev loss: 1.0058 r:0.1498
en_zh Dev loss: 0.7959 r:0.4935
Current avg r:0.3217 Best avg r: 0.3931
23:47:12,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:38,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:04,539 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1052
en_de Dev loss: 0.9849 r:0.1470
en_zh Dev loss: 0.8106 r:0.4952
Current avg r:0.3211 Best avg r: 0.3931
23:49:21,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:47,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:13,358 root INFO Epoch 16 Global steps: 50000 Train loss: 0.1158
en_de Dev loss: 0.9815 r:0.1572
en_zh Dev loss: 0.7849 r:0.5009
Current avg r:0.3291 Best avg r: 0.3931
23:51:30,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:56,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:22,202 root INFO Epoch 16 Global steps: 50200 Train loss: 0.1106
en_de Dev loss: 0.9767 r:0.1672
en_zh Dev loss: 0.8200 r:0.4966
Current avg r:0.3319 Best avg r: 0.3931
23:53:39,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:05,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:54:31,43 root INFO Epoch 16 Global steps: 50400 Train loss: 0.1039
en_de Dev loss: 0.9922 r:0.1631
en_zh Dev loss: 0.8116 r:0.4926
Current avg r:0.3278 Best avg r: 0.3931
23:55:48,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:13,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:39,881 root INFO Epoch 16 Global steps: 50600 Train loss: 0.1076
en_de Dev loss: 0.9761 r:0.1575
en_zh Dev loss: 0.7751 r:0.4907
Current avg r:0.3241 Best avg r: 0.3931
23:57:56,895 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:22,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:48,717 root INFO Epoch 16 Global steps: 50800 Train loss: 0.1081
en_de Dev loss: 0.9718 r:0.1617
en_zh Dev loss: 0.8034 r:0.4935
Current avg r:0.3276 Best avg r: 0.3931
00:00:05,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:00:31,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:57,505 root INFO Epoch 16 Global steps: 51000 Train loss: 0.1009
en_de Dev loss: 0.9663 r:0.1567
en_zh Dev loss: 0.7929 r:0.4951
Current avg r:0.3259 Best avg r: 0.3931
