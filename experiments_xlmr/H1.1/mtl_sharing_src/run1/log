14:33:42,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:34:20,850 root INFO 
id:en_zh cur r: 0.0378 best r: 0.0378
14:34:20,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:34:46,686 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:34:46,691 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:35:12,557 root INFO Epoch 0 Global steps: 200 Train loss: 0.7891
en_de Dev loss: 0.8897 r:0.0130
en_zh Dev loss: 0.8156 r:0.0891
Current avg r:0.0511 Best avg r: 0.0511
14:36:29,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:08,142 root INFO 
id:en_zh cur r: 0.0446 best r: 0.0446
14:37:08,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:37:33,996 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:37:34,1 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:37:59,900 root INFO Epoch 0 Global steps: 400 Train loss: 0.8303
en_de Dev loss: 0.8911 r:0.0004
en_zh Dev loss: 0.8164 r:0.1388
Current avg r:0.0696 Best avg r: 0.0696
14:39:16,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:39:55,572 root INFO 
id:en_zh cur r: 0.1696 best r: 0.1696
14:39:55,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:21,435 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:40:21,440 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:40:47,323 root INFO Epoch 0 Global steps: 600 Train loss: 0.7685
en_de Dev loss: 0.8880 r:-0.0009
en_zh Dev loss: 0.8141 r:0.1498
Current avg r:0.0744 Best avg r: 0.0744
14:42:04,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:30,148 root INFO 
id:en_de cur r: 0.0010 best r: 0.0010
14:42:56,15 root INFO 
id:en_zh cur r: 0.1888 best r: 0.1888
14:42:56,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:21,897 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:43:21,903 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:43:47,808 root INFO Epoch 0 Global steps: 800 Train loss: 0.6684
en_de Dev loss: 0.8874 r:0.0303
en_zh Dev loss: 0.8116 r:0.2398
Current avg r:0.1351 Best avg r: 0.1351
14:45:04,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:30,621 root INFO 
id:en_de cur r: 0.0080 best r: 0.0080
14:45:56,482 root INFO 
id:en_zh cur r: 0.2634 best r: 0.2634
14:45:56,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:22,355 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:46:22,362 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:46:48,272 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7756
en_de Dev loss: 0.8854 r:0.0490
en_zh Dev loss: 0.8094 r:0.2594
Current avg r:0.1542 Best avg r: 0.1542
14:48:05,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:31,90 root INFO 
id:en_de cur r: 0.0131 best r: 0.0131
14:48:56,941 root INFO 
id:en_zh cur r: 0.2961 best r: 0.2961
14:48:56,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:22,832 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8367
en_de Dev loss: 0.8927 r:0.0569
en_zh Dev loss: 0.8248 r:0.2281
Current avg r:0.1425 Best avg r: 0.1542
14:50:39,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:05,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:31,526 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:51:31,544 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:51:57,452 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7146
en_de Dev loss: 0.8838 r:0.0843
en_zh Dev loss: 0.8073 r:0.2741
Current avg r:0.1792 Best avg r: 0.1792
14:53:14,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:53,189 root INFO 
id:en_zh cur r: 0.3063 best r: 0.3063
14:53:53,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:19,69 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:54:19,79 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:54:44,980 root INFO Epoch 0 Global steps: 1600 Train loss: 0.6304
en_de Dev loss: 0.8839 r:0.1208
en_zh Dev loss: 0.8010 r:0.3270
Current avg r:0.2239 Best avg r: 0.2239
14:56:01,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:27,796 root INFO 
id:en_de cur r: 0.0359 best r: 0.0359
14:56:53,658 root INFO 
id:en_zh cur r: 0.3456 best r: 0.3456
14:56:53,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:19,526 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
14:57:19,533 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:57:45,422 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7230
en_de Dev loss: 0.8813 r:0.1362
en_zh Dev loss: 0.7903 r:0.3563
Current avg r:0.2462 Best avg r: 0.2462
14:59:02,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:28,245 root INFO 
id:en_de cur r: 0.0898 best r: 0.0898
14:59:54,116 root INFO 
id:en_zh cur r: 0.3804 best r: 0.3804
14:59:54,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:20,0 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:00:20,8 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:00:45,888 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7792
en_de Dev loss: 0.8738 r:0.1784
en_zh Dev loss: 0.7554 r:0.3923
Current avg r:0.2854 Best avg r: 0.2854
15:02:02,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:28,735 root INFO 
id:en_de cur r: 0.1433 best r: 0.1433
15:02:41,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:07,560 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7229
en_de Dev loss: 0.9108 r:0.1682
en_zh Dev loss: 0.8079 r:0.3775
Current avg r:0.2729 Best avg r: 0.2854
15:04:24,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:50,447 root INFO 
id:en_de cur r: 0.1759 best r: 0.1759
15:05:16,315 root INFO 
id:en_zh cur r: 0.3831 best r: 0.3831
15:05:16,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:42,195 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:05:42,204 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:06:08,115 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6192
en_de Dev loss: 0.8557 r:0.1934
en_zh Dev loss: 0.6906 r:0.3978
Current avg r:0.2956 Best avg r: 0.2956
15:07:25,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:03,913 root INFO 
id:en_zh cur r: 0.4117 best r: 0.4117
15:08:03,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:29,800 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:08:29,806 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:08:55,717 root INFO Epoch 0 Global steps: 2600 Train loss: 0.7349
en_de Dev loss: 0.8578 r:0.1849
en_zh Dev loss: 0.7250 r:0.4277
Current avg r:0.3063 Best avg r: 0.3063
15:10:12,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:38,544 root INFO 
id:en_de cur r: 0.2104 best r: 0.2104
15:11:04,427 root INFO 
id:en_zh cur r: 0.4216 best r: 0.4216
15:11:04,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:30,314 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:11:30,324 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:11:56,235 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6648
en_de Dev loss: 0.8588 r:0.2166
en_zh Dev loss: 0.7051 r:0.4288
Current avg r:0.3227 Best avg r: 0.3227
15:13:13,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:39,113 root INFO 
id:en_de cur r: 0.2106 best r: 0.2106
15:14:04,994 root INFO 
id:en_zh cur r: 0.4473 best r: 0.4473
15:14:04,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:30,895 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:14:30,908 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:14:56,807 root INFO Epoch 0 Global steps: 3000 Train loss: 0.8591
en_de Dev loss: 0.8527 r:0.1968
en_zh Dev loss: 0.6669 r:0.4564
Current avg r:0.3266 Best avg r: 0.3266
15:16:14,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:40,45 root INFO 
id:en_de cur r: 0.2212 best r: 0.2212
15:16:52,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:18,872 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:17:18,878 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:17:44,779 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6722
en_de Dev loss: 0.8444 r:0.2189
en_zh Dev loss: 0.6935 r:0.4450
Current avg r:0.3319 Best avg r: 0.3319
15:19:01,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:40,546 root INFO 
id:en_zh cur r: 0.4617 best r: 0.4617
15:19:40,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:06,419 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:20:06,427 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:20:32,359 root INFO Epoch 1 Global steps: 3400 Train loss: 0.5610
en_de Dev loss: 0.8782 r:0.1925
en_zh Dev loss: 0.6865 r:0.4725
Current avg r:0.3325 Best avg r: 0.3325
15:21:49,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:15,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:41,35 root INFO Epoch 1 Global steps: 3600 Train loss: 0.7107
en_de Dev loss: 0.8619 r:0.1982
en_zh Dev loss: 0.6802 r:0.4544
Current avg r:0.3263 Best avg r: 0.3325
15:23:57,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:23,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:49,748 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:24:49,775 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:25:15,682 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6824
en_de Dev loss: 0.8533 r:0.2091
en_zh Dev loss: 0.6429 r:0.4646
Current avg r:0.3369 Best avg r: 0.3369
15:26:32,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:58,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:24,421 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:27:24,428 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:27:50,334 root INFO Epoch 1 Global steps: 4000 Train loss: 0.5917
en_de Dev loss: 0.8566 r:0.2267
en_zh Dev loss: 0.6991 r:0.4587
Current avg r:0.3427 Best avg r: 0.3427
15:29:07,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:33,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:59,55 root INFO Epoch 1 Global steps: 4200 Train loss: 0.5659
en_de Dev loss: 0.8586 r:0.2244
en_zh Dev loss: 0.7006 r:0.4576
Current avg r:0.3410 Best avg r: 0.3427
15:31:15,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:54,808 root INFO 
id:en_zh cur r: 0.4667 best r: 0.4667
15:31:54,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:20,689 root INFO Epoch 1 Global steps: 4400 Train loss: 0.5691
en_de Dev loss: 0.8674 r:0.2134
en_zh Dev loss: 0.7168 r:0.4659
Current avg r:0.3396 Best avg r: 0.3427
15:33:37,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:03,567 root INFO 
id:en_de cur r: 0.2295 best r: 0.2295
15:34:29,434 root INFO 
id:en_zh cur r: 0.4714 best r: 0.4714
15:34:29,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:55,311 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:34:55,317 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:35:21,231 root INFO Epoch 1 Global steps: 4600 Train loss: 0.5974
en_de Dev loss: 0.8603 r:0.2356
en_zh Dev loss: 0.7578 r:0.4675
Current avg r:0.3515 Best avg r: 0.3515
15:36:38,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:17,41 root INFO 
id:en_zh cur r: 0.4799 best r: 0.4799
15:37:17,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:37:42,937 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:37:42,944 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:38:08,845 root INFO Epoch 1 Global steps: 4800 Train loss: 0.6928
en_de Dev loss: 0.8566 r:0.2299
en_zh Dev loss: 0.7261 r:0.4794
Current avg r:0.3547 Best avg r: 0.3547
15:39:25,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:51,744 root INFO 
id:en_de cur r: 0.2302 best r: 0.2302
15:40:04,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:30,548 root INFO Epoch 1 Global steps: 5000 Train loss: 0.5726
en_de Dev loss: 0.8533 r:0.2358
en_zh Dev loss: 0.7159 r:0.4687
Current avg r:0.3522 Best avg r: 0.3547
15:41:47,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:13,448 root INFO 
id:en_de cur r: 0.2382 best r: 0.2382
15:42:26,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:52,264 root INFO Epoch 1 Global steps: 5200 Train loss: 0.6595
en_de Dev loss: 0.8476 r:0.2413
en_zh Dev loss: 0.7481 r:0.4579
Current avg r:0.3496 Best avg r: 0.3547
15:44:09,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:35,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:00,991 root INFO Epoch 1 Global steps: 5400 Train loss: 0.6588
en_de Dev loss: 0.8555 r:0.2344
en_zh Dev loss: 0.7274 r:0.4714
Current avg r:0.3529 Best avg r: 0.3547
15:46:17,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:56,736 root INFO 
id:en_zh cur r: 0.4905 best r: 0.4905
15:46:56,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:22,616 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:47:22,622 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:47:48,506 root INFO Epoch 1 Global steps: 5600 Train loss: 0.6724
en_de Dev loss: 0.8450 r:0.2352
en_zh Dev loss: 0.6598 r:0.4897
Current avg r:0.3625 Best avg r: 0.3625
15:49:05,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:31,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:57,285 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6574
en_de Dev loss: 0.8432 r:0.2339
en_zh Dev loss: 0.7072 r:0.4825
Current avg r:0.3582 Best avg r: 0.3625
15:51:14,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:40,157 root INFO 
id:en_de cur r: 0.2429 best r: 0.2429
15:52:06,45 root INFO 
id:en_zh cur r: 0.4954 best r: 0.4954
15:52:06,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:31,917 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
15:52:31,923 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:52:57,844 root INFO Epoch 1 Global steps: 6000 Train loss: 0.6357
en_de Dev loss: 0.8348 r:0.2435
en_zh Dev loss: 0.6274 r:0.4965
Current avg r:0.3700 Best avg r: 0.3700
15:54:15,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:53,951 root INFO 
id:en_zh cur r: 0.4988 best r: 0.4988
15:54:53,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:19,840 root INFO Epoch 2 Global steps: 6200 Train loss: 0.5785
en_de Dev loss: 0.8460 r:0.2292
en_zh Dev loss: 0.6478 r:0.4991
Current avg r:0.3642 Best avg r: 0.3700
15:56:36,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:02,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:28,473 root INFO Epoch 2 Global steps: 6400 Train loss: 0.6600
en_de Dev loss: 0.8384 r:0.2379
en_zh Dev loss: 0.6760 r:0.4916
Current avg r:0.3648 Best avg r: 0.3700
15:58:45,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:11,310 root INFO 
id:en_de cur r: 0.2547 best r: 0.2547
15:59:24,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:50,125 root INFO Epoch 2 Global steps: 6600 Train loss: 0.5789
en_de Dev loss: 0.8410 r:0.2496
en_zh Dev loss: 0.7965 r:0.4687
Current avg r:0.3592 Best avg r: 0.3700
16:01:07,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:32,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:58,836 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
16:01:58,843 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:02:24,739 root INFO Epoch 2 Global steps: 6800 Train loss: 0.6325
en_de Dev loss: 0.8358 r:0.2462
en_zh Dev loss: 0.6565 r:0.4942
Current avg r:0.3702 Best avg r: 0.3702
16:03:41,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:07,629 root INFO 
id:en_de cur r: 0.2603 best r: 0.2603
16:04:20,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:46,480 root INFO Epoch 2 Global steps: 7000 Train loss: 0.5113
en_de Dev loss: 0.8490 r:0.2568
en_zh Dev loss: 0.7662 r:0.4816
Current avg r:0.3692 Best avg r: 0.3702
16:06:03,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:29,376 root INFO 
id:en_de cur r: 0.2734 best r: 0.2734
16:06:42,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:08,193 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
16:07:08,198 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:07:34,84 root INFO Epoch 2 Global steps: 7200 Train loss: 0.5454
en_de Dev loss: 0.8309 r:0.2676
en_zh Dev loss: 0.6884 r:0.4912
Current avg r:0.3794 Best avg r: 0.3794
16:08:51,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:17,6 root INFO 
id:en_de cur r: 0.2805 best r: 0.2805
16:09:29,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:55,811 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
16:09:55,818 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:10:21,730 root INFO Epoch 2 Global steps: 7400 Train loss: 0.5698
en_de Dev loss: 0.8228 r:0.2765
en_zh Dev loss: 0.6532 r:0.4945
Current avg r:0.3855 Best avg r: 0.3855
16:11:38,683 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:17,481 root INFO 
id:en_zh cur r: 0.5027 best r: 0.5027
16:12:17,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:43,356 root INFO Epoch 2 Global steps: 7600 Train loss: 0.5378
en_de Dev loss: 0.8484 r:0.2709
en_zh Dev loss: 0.6857 r:0.4973
Current avg r:0.3841 Best avg r: 0.3855
16:14:00,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:26,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:52,38 root INFO Epoch 2 Global steps: 7800 Train loss: 0.5848
en_de Dev loss: 0.8476 r:0.2750
en_zh Dev loss: 0.7209 r:0.4845
Current avg r:0.3798 Best avg r: 0.3855
16:16:08,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:34,886 root INFO 
id:en_de cur r: 0.2809 best r: 0.2809
16:16:47,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:17:13,709 root INFO Epoch 2 Global steps: 8000 Train loss: 0.5628
en_de Dev loss: 0.8290 r:0.2713
en_zh Dev loss: 0.7073 r:0.4977
Current avg r:0.3845 Best avg r: 0.3855
16:18:30,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:56,595 root INFO 
id:en_de cur r: 0.2834 best r: 0.2834
16:19:22,454 root INFO 
id:en_zh cur r: 0.5100 best r: 0.5100
16:19:22,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:48,343 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
16:19:48,350 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:20:14,264 root INFO Epoch 2 Global steps: 8200 Train loss: 0.5697
en_de Dev loss: 0.8352 r:0.2779
en_zh Dev loss: 0.6509 r:0.5033
Current avg r:0.3906 Best avg r: 0.3906
16:21:31,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:10,40 root INFO 
id:en_zh cur r: 0.5123 best r: 0.5123
16:22:10,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:35,919 root INFO Epoch 2 Global steps: 8400 Train loss: 0.6089
en_de Dev loss: 0.8285 r:0.2715
en_zh Dev loss: 0.7036 r:0.5073
Current avg r:0.3894 Best avg r: 0.3906
16:23:52,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:31,663 root INFO 
id:en_zh cur r: 0.5140 best r: 0.5140
16:24:31,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:24:57,552 root INFO Epoch 2 Global steps: 8600 Train loss: 0.4977
en_de Dev loss: 0.8547 r:0.2628
en_zh Dev loss: 0.7212 r:0.5092
Current avg r:0.3860 Best avg r: 0.3906
16:26:14,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:40,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:06,279 root INFO Epoch 2 Global steps: 8800 Train loss: 0.6411
en_de Dev loss: 0.8330 r:0.2529
en_zh Dev loss: 0.6438 r:0.5040
Current avg r:0.3785 Best avg r: 0.3906
16:28:23,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:49,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:14,997 root INFO Epoch 2 Global steps: 9000 Train loss: 0.4947
en_de Dev loss: 0.8406 r:0.2588
en_zh Dev loss: 0.7121 r:0.4998
Current avg r:0.3793 Best avg r: 0.3906
16:30:32,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:58,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:24,48 root INFO Epoch 3 Global steps: 9200 Train loss: 0.5406
en_de Dev loss: 0.8340 r:0.2600
en_zh Dev loss: 0.7369 r:0.4991
Current avg r:0.3795 Best avg r: 0.3906
16:32:40,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:06,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:32,709 root INFO Epoch 3 Global steps: 9400 Train loss: 0.5218
en_de Dev loss: 0.8295 r:0.2710
en_zh Dev loss: 0.7563 r:0.4866
Current avg r:0.3788 Best avg r: 0.3906
16:34:49,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:15,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:41,379 root INFO Epoch 3 Global steps: 9600 Train loss: 0.5093
en_de Dev loss: 0.8315 r:0.2738
en_zh Dev loss: 0.7360 r:0.4873
Current avg r:0.3805 Best avg r: 0.3906
16:36:58,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:24,257 root INFO 
id:en_de cur r: 0.2983 best r: 0.2983
16:37:37,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:03,77 root INFO Epoch 3 Global steps: 9800 Train loss: 0.4924
en_de Dev loss: 0.8337 r:0.2892
en_zh Dev loss: 0.7182 r:0.4760
Current avg r:0.3826 Best avg r: 0.3906
16:39:19,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:45,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:11,722 root INFO Epoch 3 Global steps: 10000 Train loss: 0.5546
en_de Dev loss: 0.8265 r:0.2851
en_zh Dev loss: 0.7129 r:0.4810
Current avg r:0.3830 Best avg r: 0.3906
16:41:28,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:54,604 root INFO 
id:en_de cur r: 0.3043 best r: 0.3043
16:42:07,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:33,410 root INFO Epoch 3 Global steps: 10200 Train loss: 0.4841
en_de Dev loss: 0.8375 r:0.2943
en_zh Dev loss: 0.6944 r:0.4791
Current avg r:0.3867 Best avg r: 0.3906
16:43:50,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:16,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:42,112 root INFO Epoch 3 Global steps: 10400 Train loss: 0.5001
en_de Dev loss: 0.8482 r:0.2757
en_zh Dev loss: 0.7589 r:0.4877
Current avg r:0.3817 Best avg r: 0.3906
16:45:59,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:24,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:50,772 root INFO Epoch 3 Global steps: 10600 Train loss: 0.5068
en_de Dev loss: 0.8315 r:0.2786
en_zh Dev loss: 0.7082 r:0.4898
Current avg r:0.3842 Best avg r: 0.3906
16:48:07,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:33,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:59,453 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
16:48:59,483 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:49:25,388 root INFO Epoch 3 Global steps: 10800 Train loss: 0.4631
en_de Dev loss: 0.8219 r:0.2856
en_zh Dev loss: 0.6531 r:0.5007
Current avg r:0.3931 Best avg r: 0.3931
16:50:42,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:08,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:34,113 root INFO Epoch 3 Global steps: 11000 Train loss: 0.4957
en_de Dev loss: 0.8392 r:0.2733
en_zh Dev loss: 0.7111 r:0.4982
Current avg r:0.3858 Best avg r: 0.3931
16:52:51,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:16,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:42,852 root INFO Epoch 3 Global steps: 11200 Train loss: 0.4764
en_de Dev loss: 0.8488 r:0.2574
en_zh Dev loss: 0.8155 r:0.4868
Current avg r:0.3721 Best avg r: 0.3931
16:54:59,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:25,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:51,519 root INFO Epoch 3 Global steps: 11400 Train loss: 0.5541
en_de Dev loss: 0.8538 r:0.2661
en_zh Dev loss: 0.7759 r:0.4922
Current avg r:0.3792 Best avg r: 0.3931
16:57:08,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:34,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:00,187 root INFO Epoch 3 Global steps: 11600 Train loss: 0.5196
en_de Dev loss: 0.8402 r:0.2711
en_zh Dev loss: 0.7388 r:0.4931
Current avg r:0.3821 Best avg r: 0.3931
16:59:17,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:42,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:08,857 root INFO Epoch 3 Global steps: 11800 Train loss: 0.4788
en_de Dev loss: 0.8475 r:0.2703
en_zh Dev loss: 0.7477 r:0.4887
Current avg r:0.3795 Best avg r: 0.3931
17:01:25,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:51,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:17,502 root INFO Epoch 3 Global steps: 12000 Train loss: 0.4784
en_de Dev loss: 0.8339 r:0.2533
en_zh Dev loss: 0.6776 r:0.4990
Current avg r:0.3761 Best avg r: 0.3931
17:03:34,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:00,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:26,489 root INFO Epoch 4 Global steps: 12200 Train loss: 0.4759
en_de Dev loss: 0.8629 r:0.2458
en_zh Dev loss: 0.7700 r:0.4785
Current avg r:0.3621 Best avg r: 0.3931
17:05:43,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:09,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:35,109 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4378
en_de Dev loss: 0.8602 r:0.2634
en_zh Dev loss: 0.7987 r:0.4774
Current avg r:0.3704 Best avg r: 0.3931
17:07:52,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:17,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:43,739 root INFO Epoch 4 Global steps: 12600 Train loss: 0.4805
en_de Dev loss: 0.8356 r:0.2667
en_zh Dev loss: 0.7454 r:0.4758
Current avg r:0.3712 Best avg r: 0.3931
17:10:00,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:26,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:10:52,358 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4347
en_de Dev loss: 0.8301 r:0.2608
en_zh Dev loss: 0.7142 r:0.4804
Current avg r:0.3706 Best avg r: 0.3931
17:12:09,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:35,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:01,34 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4943
en_de Dev loss: 0.8395 r:0.2460
en_zh Dev loss: 0.7690 r:0.4809
Current avg r:0.3635 Best avg r: 0.3931
17:14:17,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:43,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:09,731 root INFO Epoch 4 Global steps: 13200 Train loss: 0.3855
en_de Dev loss: 0.8543 r:0.2331
en_zh Dev loss: 0.7386 r:0.4744
Current avg r:0.3538 Best avg r: 0.3931
17:16:26,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:52,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:18,434 root INFO Epoch 4 Global steps: 13400 Train loss: 0.4684
en_de Dev loss: 0.8627 r:0.2360
en_zh Dev loss: 0.8556 r:0.4747
Current avg r:0.3554 Best avg r: 0.3931
17:18:35,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:01,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:27,156 root INFO Epoch 4 Global steps: 13600 Train loss: 0.5149
en_de Dev loss: 0.8457 r:0.2377
en_zh Dev loss: 0.7634 r:0.4806
Current avg r:0.3592 Best avg r: 0.3931
17:20:44,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:09,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:35,876 root INFO Epoch 4 Global steps: 13800 Train loss: 0.3922
en_de Dev loss: 0.8567 r:0.2128
en_zh Dev loss: 0.7233 r:0.4891
Current avg r:0.3510 Best avg r: 0.3931
17:22:52,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:18,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:44,613 root INFO Epoch 4 Global steps: 14000 Train loss: 0.4358
en_de Dev loss: 0.8603 r:0.2261
en_zh Dev loss: 0.7587 r:0.4757
Current avg r:0.3509 Best avg r: 0.3931
17:25:01,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:27,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:53,367 root INFO Epoch 4 Global steps: 14200 Train loss: 0.4636
en_de Dev loss: 0.8567 r:0.2263
en_zh Dev loss: 0.7652 r:0.4816
Current avg r:0.3539 Best avg r: 0.3931
17:27:10,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:36,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:02,103 root INFO Epoch 4 Global steps: 14400 Train loss: 0.4129
en_de Dev loss: 0.8597 r:0.2614
en_zh Dev loss: 0.8087 r:0.4723
Current avg r:0.3668 Best avg r: 0.3931
17:29:19,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:44,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:10,865 root INFO Epoch 4 Global steps: 14600 Train loss: 0.4231
en_de Dev loss: 0.8546 r:0.2389
en_zh Dev loss: 0.7468 r:0.4928
Current avg r:0.3659 Best avg r: 0.3931
17:31:27,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:53,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:19,615 root INFO Epoch 4 Global steps: 14800 Train loss: 0.4224
en_de Dev loss: 0.8531 r:0.2467
en_zh Dev loss: 0.7646 r:0.4930
Current avg r:0.3698 Best avg r: 0.3931
17:33:36,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:02,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:28,433 root INFO Epoch 4 Global steps: 15000 Train loss: 0.3727
en_de Dev loss: 0.8492 r:0.2578
en_zh Dev loss: 0.7319 r:0.4877
Current avg r:0.3728 Best avg r: 0.3931
17:35:45,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:11,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:37,605 root INFO Epoch 5 Global steps: 15200 Train loss: 0.4277
en_de Dev loss: 0.8333 r:0.2576
en_zh Dev loss: 0.7453 r:0.4774
Current avg r:0.3675 Best avg r: 0.3931
17:37:54,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:20,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:46,390 root INFO Epoch 5 Global steps: 15400 Train loss: 0.3989
en_de Dev loss: 0.8474 r:0.2504
en_zh Dev loss: 0.7645 r:0.4964
Current avg r:0.3734 Best avg r: 0.3931
17:40:03,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:29,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:55,137 root INFO Epoch 5 Global steps: 15600 Train loss: 0.4206
en_de Dev loss: 0.8500 r:0.2484
en_zh Dev loss: 0.7948 r:0.4841
Current avg r:0.3662 Best avg r: 0.3931
17:42:12,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:38,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:03,908 root INFO Epoch 5 Global steps: 15800 Train loss: 0.3880
en_de Dev loss: 0.8478 r:0.2386
en_zh Dev loss: 0.7386 r:0.4847
Current avg r:0.3616 Best avg r: 0.3931
17:44:20,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:46,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:12,668 root INFO Epoch 5 Global steps: 16000 Train loss: 0.3982
en_de Dev loss: 0.8433 r:0.2497
en_zh Dev loss: 0.7344 r:0.4880
Current avg r:0.3689 Best avg r: 0.3931
17:46:29,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:55,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:21,451 root INFO Epoch 5 Global steps: 16200 Train loss: 0.3446
en_de Dev loss: 0.8754 r:0.2571
en_zh Dev loss: 0.7824 r:0.4767
Current avg r:0.3669 Best avg r: 0.3931
17:48:38,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:04,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:30,144 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3878
en_de Dev loss: 0.8516 r:0.2642
en_zh Dev loss: 0.8200 r:0.4775
Current avg r:0.3709 Best avg r: 0.3931
17:50:47,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:12,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:38,829 root INFO Epoch 5 Global steps: 16600 Train loss: 0.3590
en_de Dev loss: 0.8521 r:0.2588
en_zh Dev loss: 0.8302 r:0.4695
Current avg r:0.3641 Best avg r: 0.3931
17:52:55,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:21,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:47,504 root INFO Epoch 5 Global steps: 16800 Train loss: 0.3908
en_de Dev loss: 0.8660 r:0.2575
en_zh Dev loss: 0.8634 r:0.4621
Current avg r:0.3598 Best avg r: 0.3931
17:55:04,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:30,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:56,120 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3548
en_de Dev loss: 0.8471 r:0.2470
en_zh Dev loss: 0.7742 r:0.4709
Current avg r:0.3590 Best avg r: 0.3931
17:57:13,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:38,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:04,775 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3781
en_de Dev loss: 0.8558 r:0.2117
en_zh Dev loss: 0.7798 r:0.4732
Current avg r:0.3424 Best avg r: 0.3931
17:59:21,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:47,597 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:13,474 root INFO Epoch 5 Global steps: 17400 Train loss: 0.3719
en_de Dev loss: 0.8554 r:0.2153
en_zh Dev loss: 0.7573 r:0.4750
Current avg r:0.3451 Best avg r: 0.3931
18:01:30,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:56,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:22,112 root INFO Epoch 5 Global steps: 17600 Train loss: 0.3242
en_de Dev loss: 0.8800 r:0.2084
en_zh Dev loss: 0.8239 r:0.4765
Current avg r:0.3425 Best avg r: 0.3931
18:03:39,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:04,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:30,793 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3874
en_de Dev loss: 0.8624 r:0.2234
en_zh Dev loss: 0.7823 r:0.4668
Current avg r:0.3451 Best avg r: 0.3931
18:05:47,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:13,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:39,454 root INFO Epoch 5 Global steps: 18000 Train loss: 0.2987
en_de Dev loss: 0.8672 r:0.2280
en_zh Dev loss: 0.7877 r:0.4685
Current avg r:0.3482 Best avg r: 0.3931
18:07:56,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:22,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:48,512 root INFO Epoch 6 Global steps: 18200 Train loss: 0.3012
en_de Dev loss: 0.8635 r:0.2262
en_zh Dev loss: 0.7615 r:0.4844
Current avg r:0.3553 Best avg r: 0.3931
18:10:05,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:31,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:57,166 root INFO Epoch 6 Global steps: 18400 Train loss: 0.3079
en_de Dev loss: 0.8542 r:0.2197
en_zh Dev loss: 0.7912 r:0.4721
Current avg r:0.3459 Best avg r: 0.3931
18:12:14,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:39,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:05,846 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3637
en_de Dev loss: 0.8511 r:0.2367
en_zh Dev loss: 0.7606 r:0.4828
Current avg r:0.3598 Best avg r: 0.3931
18:14:22,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:48,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:14,555 root INFO Epoch 6 Global steps: 18800 Train loss: 0.3046
en_de Dev loss: 0.8569 r:0.2325
en_zh Dev loss: 0.7456 r:0.4893
Current avg r:0.3609 Best avg r: 0.3931
18:16:31,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:57,366 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:23,243 root INFO Epoch 6 Global steps: 19000 Train loss: 0.3449
en_de Dev loss: 0.8812 r:0.2084
en_zh Dev loss: 0.8078 r:0.4806
Current avg r:0.3445 Best avg r: 0.3931
18:18:40,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:06,56 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:31,939 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3495
en_de Dev loss: 0.8727 r:0.1938
en_zh Dev loss: 0.7406 r:0.4738
Current avg r:0.3338 Best avg r: 0.3931
18:20:48,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:14,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:40,649 root INFO Epoch 6 Global steps: 19400 Train loss: 0.3301
en_de Dev loss: 0.8995 r:0.1981
en_zh Dev loss: 0.7665 r:0.4773
Current avg r:0.3377 Best avg r: 0.3931
18:22:57,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:23,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:49,344 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3634
en_de Dev loss: 0.8658 r:0.2111
en_zh Dev loss: 0.7550 r:0.4768
Current avg r:0.3439 Best avg r: 0.3931
18:25:06,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:32,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:58,55 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3024
en_de Dev loss: 0.8991 r:0.1872
en_zh Dev loss: 0.7942 r:0.4786
Current avg r:0.3329 Best avg r: 0.3931
18:27:15,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:40,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:06,752 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3409
en_de Dev loss: 0.9012 r:0.1825
en_zh Dev loss: 0.7664 r:0.4857
Current avg r:0.3341 Best avg r: 0.3931
18:29:23,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:49,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:15,449 root INFO Epoch 6 Global steps: 20200 Train loss: 0.3205
en_de Dev loss: 0.8779 r:0.1974
en_zh Dev loss: 0.7674 r:0.4805
Current avg r:0.3390 Best avg r: 0.3931
18:31:32,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:58,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:24,131 root INFO Epoch 6 Global steps: 20400 Train loss: 0.3046
en_de Dev loss: 0.8838 r:0.1955
en_zh Dev loss: 0.8513 r:0.4488
Current avg r:0.3221 Best avg r: 0.3931
18:33:41,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:06,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:32,773 root INFO Epoch 6 Global steps: 20600 Train loss: 0.2932
en_de Dev loss: 0.8833 r:0.2085
en_zh Dev loss: 0.7561 r:0.4714
Current avg r:0.3399 Best avg r: 0.3931
18:35:49,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:15,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:41,414 root INFO Epoch 6 Global steps: 20800 Train loss: 0.2832
en_de Dev loss: 0.8993 r:0.2034
en_zh Dev loss: 0.7674 r:0.4856
Current avg r:0.3445 Best avg r: 0.3931
18:37:58,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:24,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:50,129 root INFO Epoch 6 Global steps: 21000 Train loss: 0.3222
en_de Dev loss: 0.8812 r:0.2105
en_zh Dev loss: 0.7912 r:0.4736
Current avg r:0.3420 Best avg r: 0.3931
18:40:07,454 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:33,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:59,218 root INFO Epoch 7 Global steps: 21200 Train loss: 0.3078
en_de Dev loss: 0.8957 r:0.2039
en_zh Dev loss: 0.8299 r:0.4706
Current avg r:0.3372 Best avg r: 0.3931
18:42:16,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:42,42 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:07,915 root INFO Epoch 7 Global steps: 21400 Train loss: 0.3031
en_de Dev loss: 0.8875 r:0.2041
en_zh Dev loss: 0.8082 r:0.4619
Current avg r:0.3330 Best avg r: 0.3931
18:44:24,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:50,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:16,623 root INFO Epoch 7 Global steps: 21600 Train loss: 0.3132
en_de Dev loss: 0.9061 r:0.1865
en_zh Dev loss: 0.8343 r:0.4603
Current avg r:0.3234 Best avg r: 0.3931
18:46:33,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:59,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:25,315 root INFO Epoch 7 Global steps: 21800 Train loss: 0.3136
en_de Dev loss: 0.8868 r:0.2071
en_zh Dev loss: 0.8550 r:0.4398
Current avg r:0.3234 Best avg r: 0.3931
18:48:42,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:08,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:34,1 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2610
en_de Dev loss: 0.8685 r:0.2120
en_zh Dev loss: 0.7654 r:0.4583
Current avg r:0.3351 Best avg r: 0.3931
18:50:50,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:16,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:42,675 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2680
en_de Dev loss: 0.8969 r:0.2018
en_zh Dev loss: 0.8381 r:0.4514
Current avg r:0.3266 Best avg r: 0.3931
18:52:59,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:25,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:51,320 root INFO Epoch 7 Global steps: 22400 Train loss: 0.2797
en_de Dev loss: 0.8903 r:0.1976
en_zh Dev loss: 0.8012 r:0.4636
Current avg r:0.3306 Best avg r: 0.3931
18:55:08,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:34,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:59,995 root INFO Epoch 7 Global steps: 22600 Train loss: 0.2761
en_de Dev loss: 0.8810 r:0.2106
en_zh Dev loss: 0.7875 r:0.4721
Current avg r:0.3414 Best avg r: 0.3931
18:57:16,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:42,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:08,671 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2898
en_de Dev loss: 0.9516 r:0.1968
en_zh Dev loss: 0.9609 r:0.4598
Current avg r:0.3283 Best avg r: 0.3931
18:59:25,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:51,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:17,372 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2611
en_de Dev loss: 0.8929 r:0.2083
en_zh Dev loss: 0.8194 r:0.4632
Current avg r:0.3357 Best avg r: 0.3931
19:01:34,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:00,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:26,73 root INFO Epoch 7 Global steps: 23200 Train loss: 0.2700
en_de Dev loss: 0.8968 r:0.1953
en_zh Dev loss: 0.7540 r:0.4788
Current avg r:0.3371 Best avg r: 0.3931
19:03:43,6 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:08,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:34,755 root INFO Epoch 7 Global steps: 23400 Train loss: 0.2858
en_de Dev loss: 0.8781 r:0.1852
en_zh Dev loss: 0.7370 r:0.4681
Current avg r:0.3266 Best avg r: 0.3931
19:05:51,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:17,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:43,459 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2720
en_de Dev loss: 0.8660 r:0.2150
en_zh Dev loss: 0.7839 r:0.4603
Current avg r:0.3377 Best avg r: 0.3931
19:08:00,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:26,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:52,154 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2625
en_de Dev loss: 0.9150 r:0.2000
en_zh Dev loss: 0.8407 r:0.4619
Current avg r:0.3309 Best avg r: 0.3931
19:10:09,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:34,975 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:00,866 root INFO Epoch 7 Global steps: 24000 Train loss: 0.2570
en_de Dev loss: 0.8997 r:0.1876
en_zh Dev loss: 0.7710 r:0.4731
Current avg r:0.3304 Best avg r: 0.3931
19:12:18,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:44,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:09,943 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2867
en_de Dev loss: 0.9003 r:0.2076
en_zh Dev loss: 0.7825 r:0.4782
Current avg r:0.3429 Best avg r: 0.3931
19:14:26,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:52,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:18,663 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2628
en_de Dev loss: 0.8799 r:0.2057
en_zh Dev loss: 0.7744 r:0.4774
Current avg r:0.3416 Best avg r: 0.3931
19:16:35,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:01,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:27,398 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2742
en_de Dev loss: 0.8869 r:0.1881
en_zh Dev loss: 0.7619 r:0.4681
Current avg r:0.3281 Best avg r: 0.3931
19:18:44,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:10,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:36,101 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2521
en_de Dev loss: 0.8977 r:0.1799
en_zh Dev loss: 0.8190 r:0.4632
Current avg r:0.3215 Best avg r: 0.3931
19:20:53,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:18,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:44,866 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2159
en_de Dev loss: 0.9064 r:0.1938
en_zh Dev loss: 0.8704 r:0.4646
Current avg r:0.3292 Best avg r: 0.3931
19:23:01,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:27,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:53,610 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2384
en_de Dev loss: 0.9065 r:0.1891
en_zh Dev loss: 0.8078 r:0.4648
Current avg r:0.3270 Best avg r: 0.3931
19:25:10,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:36,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:02,324 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2410
en_de Dev loss: 0.9035 r:0.1906
en_zh Dev loss: 0.8492 r:0.4540
Current avg r:0.3223 Best avg r: 0.3931
19:27:19,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:45,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:11,33 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2622
en_de Dev loss: 0.9056 r:0.1928
en_zh Dev loss: 0.8386 r:0.4524
Current avg r:0.3226 Best avg r: 0.3931
19:29:27,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:53,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:19,753 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2298
en_de Dev loss: 0.8882 r:0.1982
en_zh Dev loss: 0.8617 r:0.4517
Current avg r:0.3249 Best avg r: 0.3931
19:31:36,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:02,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:28,453 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2650
en_de Dev loss: 0.8908 r:0.1829
en_zh Dev loss: 0.7737 r:0.4620
Current avg r:0.3225 Best avg r: 0.3931
19:33:45,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:11,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:37,156 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2353
en_de Dev loss: 0.8770 r:0.2028
en_zh Dev loss: 0.7989 r:0.4645
Current avg r:0.3337 Best avg r: 0.3931
19:35:54,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:20,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:45,896 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2634
en_de Dev loss: 0.9188 r:0.1807
en_zh Dev loss: 0.8350 r:0.4610
Current avg r:0.3208 Best avg r: 0.3931
19:38:02,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:28,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:54,669 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2519
en_de Dev loss: 0.9221 r:0.1742
en_zh Dev loss: 0.8510 r:0.4560
Current avg r:0.3151 Best avg r: 0.3931
19:40:11,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:37,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:03,393 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2392
en_de Dev loss: 0.8977 r:0.1873
en_zh Dev loss: 0.7983 r:0.4618
Current avg r:0.3245 Best avg r: 0.3931
19:42:20,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:46,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:12,175 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2374
en_de Dev loss: 0.9024 r:0.1926
en_zh Dev loss: 0.8727 r:0.4537
Current avg r:0.3231 Best avg r: 0.3931
19:44:29,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:55,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:21,249 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2292
en_de Dev loss: 0.8943 r:0.1823
en_zh Dev loss: 0.7821 r:0.4691
Current avg r:0.3257 Best avg r: 0.3931
19:46:38,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:04,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:30,12 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2436
en_de Dev loss: 0.9220 r:0.1814
en_zh Dev loss: 0.8177 r:0.4720
Current avg r:0.3267 Best avg r: 0.3931
19:48:46,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:12,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:38,761 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2105
en_de Dev loss: 0.8961 r:0.1858
en_zh Dev loss: 0.8636 r:0.4506
Current avg r:0.3182 Best avg r: 0.3931
19:50:55,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:21,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:47,483 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2238
en_de Dev loss: 0.9063 r:0.1980
en_zh Dev loss: 0.7843 r:0.4796
Current avg r:0.3388 Best avg r: 0.3931
19:53:04,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:30,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:56,146 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2176
en_de Dev loss: 0.8941 r:0.1922
en_zh Dev loss: 0.8440 r:0.4577
Current avg r:0.3249 Best avg r: 0.3931
19:55:13,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:38,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:04,783 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2289
en_de Dev loss: 0.8982 r:0.1853
en_zh Dev loss: 0.7920 r:0.4696
Current avg r:0.3275 Best avg r: 0.3931
19:57:21,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:47,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:13,428 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2439
en_de Dev loss: 0.9164 r:0.1877
en_zh Dev loss: 0.8910 r:0.4642
Current avg r:0.3260 Best avg r: 0.3931
19:59:30,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:56,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:22,108 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2168
en_de Dev loss: 0.8897 r:0.1938
en_zh Dev loss: 0.8367 r:0.4612
Current avg r:0.3275 Best avg r: 0.3931
20:01:39,70 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:04,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:30,802 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2104
en_de Dev loss: 0.9175 r:0.1841
en_zh Dev loss: 0.8507 r:0.4634
Current avg r:0.3238 Best avg r: 0.3931
20:03:47,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:13,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:39,496 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2200
en_de Dev loss: 0.9118 r:0.1766
en_zh Dev loss: 0.8869 r:0.4603
Current avg r:0.3185 Best avg r: 0.3931
20:05:56,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:22,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:48,147 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2249
en_de Dev loss: 0.9172 r:0.1683
en_zh Dev loss: 0.8223 r:0.4674
Current avg r:0.3179 Best avg r: 0.3931
20:08:05,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:30,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:56,777 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2005
en_de Dev loss: 0.9389 r:0.1734
en_zh Dev loss: 0.8547 r:0.4662
Current avg r:0.3198 Best avg r: 0.3931
20:10:13,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:10:39,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:05,382 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2281
en_de Dev loss: 0.9219 r:0.1660
en_zh Dev loss: 0.8504 r:0.4675
Current avg r:0.3168 Best avg r: 0.3931
20:12:22,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:48,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:14,23 root INFO Epoch 9 Global steps: 29800 Train loss: 0.2222
en_de Dev loss: 0.9129 r:0.1874
en_zh Dev loss: 0.8276 r:0.4740
Current avg r:0.3307 Best avg r: 0.3931
20:14:30,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:56,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:22,697 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2199
en_de Dev loss: 0.8903 r:0.1668
en_zh Dev loss: 0.7616 r:0.4622
Current avg r:0.3145 Best avg r: 0.3931
20:16:39,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:05,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:31,718 root INFO Epoch 10 Global steps: 30200 Train loss: 0.2033
en_de Dev loss: 0.9209 r:0.1864
en_zh Dev loss: 0.7850 r:0.4766
Current avg r:0.3315 Best avg r: 0.3931
20:18:48,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:14,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:40,361 root INFO Epoch 10 Global steps: 30400 Train loss: 0.2104
en_de Dev loss: 0.9241 r:0.1819
en_zh Dev loss: 0.7941 r:0.4762
Current avg r:0.3291 Best avg r: 0.3931
20:20:57,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:23,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:48,984 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2293
en_de Dev loss: 0.9134 r:0.1803
en_zh Dev loss: 0.7712 r:0.4749
Current avg r:0.3276 Best avg r: 0.3931
20:23:05,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:31,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:57,642 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1863
en_de Dev loss: 0.8860 r:0.1835
en_zh Dev loss: 0.7487 r:0.4740
Current avg r:0.3288 Best avg r: 0.3931
20:25:14,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:40,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:06,345 root INFO Epoch 10 Global steps: 31000 Train loss: 0.2046
en_de Dev loss: 0.8901 r:0.2018
en_zh Dev loss: 0.7369 r:0.4837
Current avg r:0.3428 Best avg r: 0.3931
20:27:23,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:49,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:28:15,17 root INFO Epoch 10 Global steps: 31200 Train loss: 0.2266
en_de Dev loss: 0.9083 r:0.1782
en_zh Dev loss: 0.8011 r:0.4789
Current avg r:0.3286 Best avg r: 0.3931
20:29:31,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:57,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:23,671 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1888
en_de Dev loss: 0.9297 r:0.1779
en_zh Dev loss: 0.8709 r:0.4682
Current avg r:0.3231 Best avg r: 0.3931
20:31:40,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:06,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:32,333 root INFO Epoch 10 Global steps: 31600 Train loss: 0.1967
en_de Dev loss: 0.9193 r:0.1794
en_zh Dev loss: 0.8129 r:0.4716
Current avg r:0.3255 Best avg r: 0.3931
20:33:49,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:15,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:34:41,47 root INFO Epoch 10 Global steps: 31800 Train loss: 0.2038
en_de Dev loss: 0.9226 r:0.1789
en_zh Dev loss: 0.8057 r:0.4752
Current avg r:0.3271 Best avg r: 0.3931
20:35:57,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:23,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:49,735 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1962
en_de Dev loss: 0.9356 r:0.1724
en_zh Dev loss: 0.8006 r:0.4806
Current avg r:0.3265 Best avg r: 0.3931
20:38:06,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:32,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:58,391 root INFO Epoch 10 Global steps: 32200 Train loss: 0.2152
en_de Dev loss: 0.9473 r:0.1653
en_zh Dev loss: 0.7907 r:0.4725
Current avg r:0.3189 Best avg r: 0.3931
20:40:15,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:41,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:07,59 root INFO Epoch 10 Global steps: 32400 Train loss: 0.2096
en_de Dev loss: 0.9552 r:0.1757
en_zh Dev loss: 0.8007 r:0.4863
Current avg r:0.3310 Best avg r: 0.3931
20:42:24,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:49,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:15,814 root INFO Epoch 10 Global steps: 32600 Train loss: 0.2198
en_de Dev loss: 0.9174 r:0.1861
en_zh Dev loss: 0.7562 r:0.4888
Current avg r:0.3374 Best avg r: 0.3931
20:44:32,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:58,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:24,594 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1754
en_de Dev loss: 0.9351 r:0.1831
en_zh Dev loss: 0.7897 r:0.4899
Current avg r:0.3365 Best avg r: 0.3931
20:46:41,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:07,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:33,363 root INFO Epoch 10 Global steps: 33000 Train loss: 0.2014
en_de Dev loss: 0.9426 r:0.1686
en_zh Dev loss: 0.8169 r:0.4790
Current avg r:0.3238 Best avg r: 0.3931
20:48:50,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:16,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:42,442 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1806
en_de Dev loss: 0.9100 r:0.2072
en_zh Dev loss: 0.7745 r:0.4844
Current avg r:0.3458 Best avg r: 0.3931
20:50:59,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:25,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:51,169 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1858
en_de Dev loss: 0.9173 r:0.1871
en_zh Dev loss: 0.8090 r:0.4751
Current avg r:0.3311 Best avg r: 0.3931
20:53:08,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:34,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:59,927 root INFO Epoch 11 Global steps: 33600 Train loss: 0.2012
en_de Dev loss: 0.9291 r:0.2049
en_zh Dev loss: 0.8182 r:0.4863
Current avg r:0.3456 Best avg r: 0.3931
20:55:16,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:42,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:08,688 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1769
en_de Dev loss: 0.8764 r:0.2131
en_zh Dev loss: 0.7601 r:0.4743
Current avg r:0.3437 Best avg r: 0.3931
20:57:25,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:51,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:17,501 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1858
en_de Dev loss: 0.9038 r:0.1937
en_zh Dev loss: 0.7602 r:0.4746
Current avg r:0.3341 Best avg r: 0.3931
20:59:34,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:00,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:26,305 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1722
en_de Dev loss: 0.9081 r:0.1945
en_zh Dev loss: 0.7948 r:0.4767
Current avg r:0.3356 Best avg r: 0.3931
21:01:43,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:09,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:35,148 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1987
en_de Dev loss: 0.9159 r:0.1816
en_zh Dev loss: 0.8238 r:0.4835
Current avg r:0.3326 Best avg r: 0.3931
21:03:52,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:18,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:43,979 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1706
en_de Dev loss: 0.9547 r:0.1729
en_zh Dev loss: 0.8107 r:0.4841
Current avg r:0.3285 Best avg r: 0.3931
21:06:00,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:26,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:52,797 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1859
en_de Dev loss: 0.9245 r:0.1718
en_zh Dev loss: 0.8052 r:0.4800
Current avg r:0.3259 Best avg r: 0.3931
21:08:09,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:35,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:01,756 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1838
en_de Dev loss: 0.9890 r:0.1681
en_zh Dev loss: 0.8477 r:0.4750
Current avg r:0.3215 Best avg r: 0.3931
21:10:18,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:44,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:10,690 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1818
en_de Dev loss: 0.9413 r:0.1906
en_zh Dev loss: 0.8380 r:0.4753
Current avg r:0.3330 Best avg r: 0.3931
21:12:27,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:53,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:19,637 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1656
en_de Dev loss: 0.9345 r:0.1776
en_zh Dev loss: 0.8328 r:0.4764
Current avg r:0.3270 Best avg r: 0.3931
21:14:36,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:02,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:28,550 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1970
en_de Dev loss: 0.9204 r:0.1766
en_zh Dev loss: 0.8100 r:0.4652
Current avg r:0.3209 Best avg r: 0.3931
21:16:45,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:11,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:37,532 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1722
en_de Dev loss: 0.9253 r:0.1883
en_zh Dev loss: 0.8335 r:0.4727
Current avg r:0.3305 Best avg r: 0.3931
21:18:54,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:20,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:46,530 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1634
en_de Dev loss: 0.9324 r:0.1713
en_zh Dev loss: 0.8012 r:0.4668
Current avg r:0.3190 Best avg r: 0.3931
21:21:03,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:29,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:55,799 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1598
en_de Dev loss: 0.9485 r:0.1784
en_zh Dev loss: 0.8278 r:0.4733
Current avg r:0.3259 Best avg r: 0.3931
21:23:12,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:38,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:04,745 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1664
en_de Dev loss: 0.9727 r:0.1662
en_zh Dev loss: 0.8679 r:0.4638
Current avg r:0.3150 Best avg r: 0.3931
21:25:21,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:47,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:13,697 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1635
en_de Dev loss: 0.9415 r:0.1672
en_zh Dev loss: 0.8212 r:0.4773
Current avg r:0.3223 Best avg r: 0.3931
21:27:30,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:56,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:28:22,682 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1705
en_de Dev loss: 0.9572 r:0.1648
en_zh Dev loss: 0.8621 r:0.4742
Current avg r:0.3195 Best avg r: 0.3931
21:29:39,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:05,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:30:31,604 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1765
en_de Dev loss: 0.9215 r:0.1867
en_zh Dev loss: 0.7716 r:0.4824
Current avg r:0.3345 Best avg r: 0.3931
21:31:48,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:14,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:40,620 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1606
en_de Dev loss: 0.9428 r:0.1861
en_zh Dev loss: 0.8250 r:0.4784
Current avg r:0.3323 Best avg r: 0.3931
21:33:57,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:23,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:49,597 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1579
en_de Dev loss: 0.9419 r:0.1801
en_zh Dev loss: 0.8266 r:0.4796
Current avg r:0.3298 Best avg r: 0.3931
21:36:06,654 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:32,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:58,520 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1504
en_de Dev loss: 0.9287 r:0.1832
en_zh Dev loss: 0.8451 r:0.4716
Current avg r:0.3274 Best avg r: 0.3931
21:38:15,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:41,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:07,442 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1685
en_de Dev loss: 0.9008 r:0.1929
en_zh Dev loss: 0.7668 r:0.4773
Current avg r:0.3351 Best avg r: 0.3931
21:40:24,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:50,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:16,362 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1708
en_de Dev loss: 0.9195 r:0.1874
en_zh Dev loss: 0.7896 r:0.4805
Current avg r:0.3339 Best avg r: 0.3931
21:42:33,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:59,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:25,336 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1580
en_de Dev loss: 0.9379 r:0.1871
en_zh Dev loss: 0.8407 r:0.4800
Current avg r:0.3335 Best avg r: 0.3931
21:44:42,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:08,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:34,307 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1667
en_de Dev loss: 0.9168 r:0.1740
en_zh Dev loss: 0.8298 r:0.4853
Current avg r:0.3297 Best avg r: 0.3931
21:46:51,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:17,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:47:43,278 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1685
en_de Dev loss: 0.9199 r:0.1817
en_zh Dev loss: 0.7704 r:0.4774
Current avg r:0.3296 Best avg r: 0.3931
21:49:00,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:26,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:52,217 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1630
en_de Dev loss: 0.9151 r:0.1870
en_zh Dev loss: 0.8203 r:0.4834
Current avg r:0.3352 Best avg r: 0.3931
21:51:09,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:35,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:01,147 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1488
en_de Dev loss: 0.9622 r:0.1985
en_zh Dev loss: 0.8143 r:0.4903
Current avg r:0.3444 Best avg r: 0.3931
21:53:18,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:44,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:10,334 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1610
en_de Dev loss: 0.9263 r:0.1941
en_zh Dev loss: 0.8110 r:0.4893
Current avg r:0.3417 Best avg r: 0.3931
21:55:27,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:53,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:19,252 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1579
en_de Dev loss: 0.9375 r:0.1772
en_zh Dev loss: 0.8077 r:0.4821
Current avg r:0.3296 Best avg r: 0.3931
21:57:36,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:02,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:28,194 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1407
en_de Dev loss: 0.9474 r:0.1753
en_zh Dev loss: 0.7885 r:0.4895
Current avg r:0.3324 Best avg r: 0.3931
21:59:45,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:11,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:37,224 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1417
en_de Dev loss: 0.9510 r:0.1757
en_zh Dev loss: 0.7714 r:0.4893
Current avg r:0.3325 Best avg r: 0.3931
22:01:54,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:20,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:46,252 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1511
en_de Dev loss: 0.9712 r:0.1585
en_zh Dev loss: 0.8755 r:0.4729
Current avg r:0.3157 Best avg r: 0.3931
22:04:03,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:29,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:55,252 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1442
en_de Dev loss: 0.9391 r:0.1708
en_zh Dev loss: 0.7312 r:0.4870
Current avg r:0.3289 Best avg r: 0.3931
22:06:12,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:38,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:04,200 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1593
en_de Dev loss: 0.9645 r:0.1711
en_zh Dev loss: 0.8297 r:0.4832
Current avg r:0.3271 Best avg r: 0.3931
22:08:21,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:47,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:13,123 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1578
en_de Dev loss: 0.9412 r:0.1749
en_zh Dev loss: 0.8106 r:0.4842
Current avg r:0.3295 Best avg r: 0.3931
22:10:30,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:56,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:22,84 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1426
en_de Dev loss: 0.9474 r:0.1711
en_zh Dev loss: 0.8056 r:0.4800
Current avg r:0.3256 Best avg r: 0.3931
22:12:39,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:05,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:31,75 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1420
en_de Dev loss: 0.9259 r:0.1710
en_zh Dev loss: 0.8172 r:0.4785
Current avg r:0.3247 Best avg r: 0.3931
22:14:48,181 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:14,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:40,105 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1585
en_de Dev loss: 0.9423 r:0.1742
en_zh Dev loss: 0.7859 r:0.4787
Current avg r:0.3264 Best avg r: 0.3931
22:16:57,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:23,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:49,101 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1345
en_de Dev loss: 0.9318 r:0.1670
en_zh Dev loss: 0.7581 r:0.4768
Current avg r:0.3219 Best avg r: 0.3931
22:19:06,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:32,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:58,78 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1477
en_de Dev loss: 0.9346 r:0.1732
en_zh Dev loss: 0.7761 r:0.4855
Current avg r:0.3293 Best avg r: 0.3931
22:21:15,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:41,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:07,67 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1443
en_de Dev loss: 0.9200 r:0.1787
en_zh Dev loss: 0.7943 r:0.4849
Current avg r:0.3318 Best avg r: 0.3931
22:23:24,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:50,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:16,80 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1327
en_de Dev loss: 0.9300 r:0.1878
en_zh Dev loss: 0.8150 r:0.4794
Current avg r:0.3336 Best avg r: 0.3931
22:25:33,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:59,438 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:25,371 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1293
en_de Dev loss: 0.9219 r:0.1874
en_zh Dev loss: 0.8865 r:0.4732
Current avg r:0.3303 Best avg r: 0.3931
22:27:42,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:08,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:28:34,299 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1378
en_de Dev loss: 0.9237 r:0.1885
en_zh Dev loss: 0.8320 r:0.4723
Current avg r:0.3304 Best avg r: 0.3931
22:29:51,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:17,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:43,256 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1391
en_de Dev loss: 0.9024 r:0.2009
en_zh Dev loss: 0.8057 r:0.4744
Current avg r:0.3376 Best avg r: 0.3931
22:32:00,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:26,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:52,251 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1332
en_de Dev loss: 0.9397 r:0.1851
en_zh Dev loss: 0.7835 r:0.4843
Current avg r:0.3347 Best avg r: 0.3931
22:34:09,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:35,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:01,239 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1335
en_de Dev loss: 0.9902 r:0.1669
en_zh Dev loss: 0.8431 r:0.4723
Current avg r:0.3196 Best avg r: 0.3931
22:36:18,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:44,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:10,195 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1258
en_de Dev loss: 0.9654 r:0.1830
en_zh Dev loss: 0.8262 r:0.4779
Current avg r:0.3304 Best avg r: 0.3931
22:38:27,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:53,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:19,177 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1315
en_de Dev loss: 0.9299 r:0.1858
en_zh Dev loss: 0.7550 r:0.4807
Current avg r:0.3333 Best avg r: 0.3931
22:40:36,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:02,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:28,160 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1311
en_de Dev loss: 0.9533 r:0.1856
en_zh Dev loss: 0.8140 r:0.4796
Current avg r:0.3326 Best avg r: 0.3931
22:42:45,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:11,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:43:37,96 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1375
en_de Dev loss: 1.0404 r:0.1631
en_zh Dev loss: 0.8430 r:0.4821
Current avg r:0.3226 Best avg r: 0.3931
22:44:54,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:45:20,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:46,45 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1348
en_de Dev loss: 0.9364 r:0.1888
en_zh Dev loss: 0.7637 r:0.4857
Current avg r:0.3373 Best avg r: 0.3931
22:47:03,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:29,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:55,6 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1376
en_de Dev loss: 0.9137 r:0.1816
en_zh Dev loss: 0.7986 r:0.4818
Current avg r:0.3317 Best avg r: 0.3931
22:49:12,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:49:38,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:03,996 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1385
en_de Dev loss: 0.9303 r:0.1777
en_zh Dev loss: 0.7779 r:0.4840
Current avg r:0.3308 Best avg r: 0.3931
22:51:21,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:47,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:12,949 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1345
en_de Dev loss: 0.9330 r:0.1908
en_zh Dev loss: 0.8432 r:0.4756
Current avg r:0.3332 Best avg r: 0.3931
22:53:29,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:55,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:21,874 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1289
en_de Dev loss: 0.9320 r:0.1736
en_zh Dev loss: 0.8318 r:0.4736
Current avg r:0.3236 Best avg r: 0.3931
22:55:38,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:04,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:30,772 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1259
en_de Dev loss: 0.9229 r:0.1731
en_zh Dev loss: 0.7658 r:0.4819
Current avg r:0.3275 Best avg r: 0.3931
22:57:48,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:14,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:40,143 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1202
en_de Dev loss: 0.9437 r:0.1631
en_zh Dev loss: 0.8102 r:0.4831
Current avg r:0.3231 Best avg r: 0.3931
22:59:57,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:00:23,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:49,89 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1188
en_de Dev loss: 0.9520 r:0.1739
en_zh Dev loss: 0.8184 r:0.4879
Current avg r:0.3309 Best avg r: 0.3931
23:02:06,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:32,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:02:58,34 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1244
en_de Dev loss: 0.9300 r:0.1660
en_zh Dev loss: 0.8020 r:0.4957
Current avg r:0.3309 Best avg r: 0.3931
23:04:15,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:41,42 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:06,978 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1157
en_de Dev loss: 0.9373 r:0.1684
en_zh Dev loss: 0.7623 r:0.4964
Current avg r:0.3324 Best avg r: 0.3931
23:06:24,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:49,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:15,939 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1145
en_de Dev loss: 0.9307 r:0.1688
en_zh Dev loss: 0.7983 r:0.4891
Current avg r:0.3290 Best avg r: 0.3931
23:08:32,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:58,934 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:09:24,878 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1270
en_de Dev loss: 0.9580 r:0.1547
en_zh Dev loss: 0.7953 r:0.4863
Current avg r:0.3205 Best avg r: 0.3931
23:10:41,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:07,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:33,828 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1173
en_de Dev loss: 0.9466 r:0.1682
en_zh Dev loss: 0.7781 r:0.4891
Current avg r:0.3287 Best avg r: 0.3931
23:12:50,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:16,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:42,704 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1272
en_de Dev loss: 0.9517 r:0.1843
en_zh Dev loss: 0.8333 r:0.4878
Current avg r:0.3360 Best avg r: 0.3931
23:14:59,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:25,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:51,567 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1181
en_de Dev loss: 0.9427 r:0.1830
en_zh Dev loss: 0.7822 r:0.4937
Current avg r:0.3383 Best avg r: 0.3931
23:17:08,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:34,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:00,410 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1192
en_de Dev loss: 0.9489 r:0.1800
en_zh Dev loss: 0.7729 r:0.4977
Current avg r:0.3389 Best avg r: 0.3931
23:19:17,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:43,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:09,240 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1152
en_de Dev loss: 0.9331 r:0.1751
en_zh Dev loss: 0.7658 r:0.4907
Current avg r:0.3329 Best avg r: 0.3931
23:21:26,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:52,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:18,72 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1266
en_de Dev loss: 0.9877 r:0.1753
en_zh Dev loss: 0.8030 r:0.4907
Current avg r:0.3330 Best avg r: 0.3931
23:23:35,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:01,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:24:26,935 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1163
en_de Dev loss: 0.9439 r:0.1662
en_zh Dev loss: 0.7618 r:0.4923
Current avg r:0.3293 Best avg r: 0.3931
23:25:43,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:09,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:35,778 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1156
en_de Dev loss: 0.9723 r:0.1625
en_zh Dev loss: 0.8154 r:0.4911
Current avg r:0.3268 Best avg r: 0.3931
23:27:52,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:18,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:28:44,608 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1174
en_de Dev loss: 0.9608 r:0.1625
en_zh Dev loss: 0.8052 r:0.4917
Current avg r:0.3271 Best avg r: 0.3931
23:30:01,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:27,790 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:53,689 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1057
en_de Dev loss: 0.9650 r:0.1612
en_zh Dev loss: 0.8012 r:0.4916
Current avg r:0.3264 Best avg r: 0.3931
23:32:10,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:36,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:02,550 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1167
en_de Dev loss: 0.9599 r:0.1592
en_zh Dev loss: 0.7656 r:0.4965
Current avg r:0.3278 Best avg r: 0.3931
23:34:19,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:34:45,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:11,382 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1025
en_de Dev loss: 0.9690 r:0.1697
en_zh Dev loss: 0.8105 r:0.4904
Current avg r:0.3300 Best avg r: 0.3931
23:36:28,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:54,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:20,199 root INFO Epoch 16 Global steps: 48800 Train loss: 0.0969
en_de Dev loss: 0.9540 r:0.1630
en_zh Dev loss: 0.7721 r:0.4921
Current avg r:0.3276 Best avg r: 0.3931
23:38:37,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:03,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:29,25 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1127
en_de Dev loss: 0.9521 r:0.1581
en_zh Dev loss: 0.7450 r:0.4980
Current avg r:0.3280 Best avg r: 0.3931
23:40:46,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:11,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:37,894 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1101
en_de Dev loss: 0.9895 r:0.1499
en_zh Dev loss: 0.7945 r:0.4949
Current avg r:0.3224 Best avg r: 0.3931
23:42:54,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:20,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:46,769 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1037
en_de Dev loss: 0.9724 r:0.1696
en_zh Dev loss: 0.8056 r:0.4923
Current avg r:0.3309 Best avg r: 0.3931
23:45:03,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:29,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:55,658 root INFO Epoch 16 Global steps: 49600 Train loss: 0.1053
en_de Dev loss: 1.0058 r:0.1498
en_zh Dev loss: 0.7959 r:0.4935
Current avg r:0.3217 Best avg r: 0.3931
23:47:12,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:38,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:04,539 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1052
en_de Dev loss: 0.9849 r:0.1470
en_zh Dev loss: 0.8106 r:0.4952
Current avg r:0.3211 Best avg r: 0.3931
23:49:21,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:47,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:13,358 root INFO Epoch 16 Global steps: 50000 Train loss: 0.1158
en_de Dev loss: 0.9815 r:0.1572
en_zh Dev loss: 0.7849 r:0.5009
Current avg r:0.3291 Best avg r: 0.3931
23:51:30,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:56,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:22,202 root INFO Epoch 16 Global steps: 50200 Train loss: 0.1106
en_de Dev loss: 0.9767 r:0.1672
en_zh Dev loss: 0.8200 r:0.4966
Current avg r:0.3319 Best avg r: 0.3931
23:53:39,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:05,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:54:31,43 root INFO Epoch 16 Global steps: 50400 Train loss: 0.1039
en_de Dev loss: 0.9922 r:0.1631
en_zh Dev loss: 0.8116 r:0.4926
Current avg r:0.3278 Best avg r: 0.3931
23:55:48,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:13,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:39,881 root INFO Epoch 16 Global steps: 50600 Train loss: 0.1076
en_de Dev loss: 0.9761 r:0.1575
en_zh Dev loss: 0.7751 r:0.4907
Current avg r:0.3241 Best avg r: 0.3931
23:57:56,895 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:22,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:48,717 root INFO Epoch 16 Global steps: 50800 Train loss: 0.1081
en_de Dev loss: 0.9718 r:0.1617
en_zh Dev loss: 0.8034 r:0.4935
Current avg r:0.3276 Best avg r: 0.3931
00:00:05,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:00:31,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:57,505 root INFO Epoch 16 Global steps: 51000 Train loss: 0.1009
en_de Dev loss: 0.9663 r:0.1567
en_zh Dev loss: 0.7929 r:0.4951
Current avg r:0.3259 Best avg r: 0.3931
00:33:56,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:35,287 root INFO 
id:en_zh cur r: 0.0946 best r: 0.0946
00:34:35,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:01,243 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
00:35:01,250 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:35:27,182 root INFO Epoch 0 Global steps: 200 Train loss: 0.7282
en_de Dev loss: 0.8988 r:0.0322
en_zh Dev loss: 0.8218 r:0.0976
Current avg r:0.0649 Best avg r: 0.0649
00:36:43,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:22,822 root INFO 
id:en_zh cur r: 0.1317 best r: 0.1317
00:37:22,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:48,784 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
00:37:48,791 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:38:14,810 root INFO Epoch 0 Global steps: 400 Train loss: 0.7758
en_de Dev loss: 0.9010 r:0.0627
en_zh Dev loss: 0.8187 r:0.1372
Current avg r:0.0999 Best avg r: 0.0999
00:39:31,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:39:57,879 root INFO 
id:en_de cur r: 0.0315 best r: 0.0315
00:40:23,796 root INFO 
id:en_zh cur r: 0.1646 best r: 0.1646
00:40:23,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:49,712 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
00:40:49,726 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:41:15,641 root INFO Epoch 0 Global steps: 600 Train loss: 0.8501
en_de Dev loss: 0.8976 r:0.0732
en_zh Dev loss: 0.8146 r:0.1980
Current avg r:0.1356 Best avg r: 0.1356
00:42:32,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:58,565 root INFO 
id:en_de cur r: 0.0586 best r: 0.0586
00:43:24,616 root INFO 
id:en_zh cur r: 0.2106 best r: 0.2106
00:43:24,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:50,702 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
00:43:50,709 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:44:16,715 root INFO Epoch 0 Global steps: 800 Train loss: 0.7902
en_de Dev loss: 0.8818 r:0.0947
en_zh Dev loss: 0.8075 r:0.1965
Current avg r:0.1456 Best avg r: 0.1456
00:45:33,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:59,359 root INFO 
id:en_de cur r: 0.0762 best r: 0.0762
00:46:25,275 root INFO 
id:en_zh cur r: 0.2347 best r: 0.2347
00:46:25,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:51,272 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
00:46:51,279 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:47:17,270 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7445
en_de Dev loss: 0.8821 r:0.1218
en_zh Dev loss: 0.8084 r:0.1769
Current avg r:0.1493 Best avg r: 0.1493
00:48:34,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:00,563 root INFO 
id:en_de cur r: 0.0889 best r: 0.0889
00:49:26,479 root INFO 
id:en_zh cur r: 0.2670 best r: 0.2670
00:49:26,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:52,386 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
00:49:52,392 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:50:18,294 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7870
en_de Dev loss: 0.8900 r:0.1115
en_zh Dev loss: 0.8163 r:0.2316
Current avg r:0.1715 Best avg r: 0.1715
00:51:34,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:01,41 root INFO 
id:en_de cur r: 0.0951 best r: 0.0951
00:52:27,102 root INFO 
id:en_zh cur r: 0.2819 best r: 0.2819
00:52:27,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:53,170 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
00:52:53,181 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:53:19,279 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7171
en_de Dev loss: 0.8963 r:0.1124
en_zh Dev loss: 0.8175 r:0.2482
Current avg r:0.1803 Best avg r: 0.1803
00:54:36,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:01,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:27,806 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
00:55:27,818 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:55:53,763 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7910
en_de Dev loss: 0.8844 r:0.1318
en_zh Dev loss: 0.7945 r:0.2905
Current avg r:0.2112 Best avg r: 0.2112
00:57:10,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:36,618 root INFO 
id:en_de cur r: 0.1253 best r: 0.1253
00:58:02,651 root INFO 
id:en_zh cur r: 0.3138 best r: 0.3138
00:58:02,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:28,628 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
00:58:28,635 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
00:58:54,584 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7288
en_de Dev loss: 0.8899 r:0.1671
en_zh Dev loss: 0.8023 r:0.2570
Current avg r:0.2121 Best avg r: 0.2121
01:00:11,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:37,159 root INFO 
id:en_de cur r: 0.1331 best r: 0.1331
01:01:03,125 root INFO 
id:en_zh cur r: 0.3535 best r: 0.3535
01:01:03,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:29,59 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
01:01:29,66 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:01:55,81 root INFO Epoch 0 Global steps: 2000 Train loss: 0.8153
en_de Dev loss: 0.8692 r:0.1680
en_zh Dev loss: 0.7641 r:0.3456
Current avg r:0.2568 Best avg r: 0.2568
01:03:11,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:37,867 root INFO 
id:en_de cur r: 0.1396 best r: 0.1396
01:04:03,753 root INFO 
id:en_zh cur r: 0.3602 best r: 0.3602
01:04:03,754 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:29,609 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
01:04:29,616 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:04:55,542 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7687
en_de Dev loss: 0.8663 r:0.1820
en_zh Dev loss: 0.7597 r:0.3549
Current avg r:0.2685 Best avg r: 0.2685
01:06:12,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:51,153 root INFO 
id:en_zh cur r: 0.3749 best r: 0.3749
01:06:51,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:17,179 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
01:07:17,190 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:07:43,206 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7987
en_de Dev loss: 0.8659 r:0.1719
en_zh Dev loss: 0.7492 r:0.3738
Current avg r:0.2728 Best avg r: 0.2728
01:08:59,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:25,672 root INFO 
id:en_de cur r: 0.1631 best r: 0.1631
01:09:38,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:04,571 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
01:10:04,579 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:10:30,517 root INFO Epoch 0 Global steps: 2600 Train loss: 0.7749
en_de Dev loss: 0.8655 r:0.1631
en_zh Dev loss: 0.7560 r:0.3836
Current avg r:0.2734 Best avg r: 0.2734
01:11:47,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:13,222 root INFO 
id:en_de cur r: 0.1658 best r: 0.1658
01:12:26,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:52,80 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
01:12:52,86 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:13:18,5 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6362
en_de Dev loss: 0.8772 r:0.1869
en_zh Dev loss: 0.7833 r:0.3782
Current avg r:0.2826 Best avg r: 0.2826
01:14:34,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:00,542 root INFO 
id:en_de cur r: 0.1823 best r: 0.1823
01:15:26,479 root INFO 
id:en_zh cur r: 0.3783 best r: 0.3783
01:15:26,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:52,434 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
01:15:52,441 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:16:18,498 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6112
en_de Dev loss: 0.8676 r:0.1884
en_zh Dev loss: 0.7222 r:0.3985
Current avg r:0.2935 Best avg r: 0.2935
01:17:35,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:18:14,382 root INFO 
id:en_zh cur r: 0.4065 best r: 0.4065
01:18:14,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:40,275 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
01:18:40,286 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
01:19:06,198 root INFO Epoch 1 Global steps: 3200 Train loss: 0.7456
en_de Dev loss: 0.8747 r:0.2017
en_zh Dev loss: 0.7256 r:0.4133
Current avg r:0.3075 Best avg r: 0.3075
09:55:13,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:39,899 root INFO 
id:en_de cur r: 0.0287 best r: 0.0287
09:56:05,915 root INFO 
id:en_zh cur r: 0.1295 best r: 0.1295
09:56:05,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:31,947 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
09:56:31,953 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
09:56:58,4 root INFO Epoch 0 Global steps: 200 Train loss: 0.7309
en_de Dev loss: 0.8860 r:0.0777
en_zh Dev loss: 0.8140 r:0.1601
Current avg r:0.1189 Best avg r: 0.1189
09:58:14,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:41,19 root INFO 
id:en_de cur r: 0.1290 best r: 0.1290
09:59:07,115 root INFO 
id:en_zh cur r: 0.2407 best r: 0.2407
09:59:07,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:33,203 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
09:59:33,230 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
09:59:59,344 root INFO Epoch 0 Global steps: 400 Train loss: 0.7529
en_de Dev loss: 0.8894 r:0.1169
en_zh Dev loss: 0.8137 r:0.2004
Current avg r:0.1586 Best avg r: 0.1586
10:01:16,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:01:42,602 root INFO 
id:en_de cur r: 0.1360 best r: 0.1360
10:02:08,705 root INFO 
id:en_zh cur r: 0.2632 best r: 0.2632
10:02:08,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:34,796 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:02:34,814 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:03:00,931 root INFO Epoch 0 Global steps: 600 Train loss: 0.8755
en_de Dev loss: 0.8775 r:0.1634
en_zh Dev loss: 0.8057 r:0.2487
Current avg r:0.2060 Best avg r: 0.2060
10:04:17,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:44,7 root INFO 
id:en_de cur r: 0.1511 best r: 0.1511
10:05:10,95 root INFO 
id:en_zh cur r: 0.2765 best r: 0.2765
10:05:10,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:36,188 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:05:36,195 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:06:02,368 root INFO Epoch 0 Global steps: 800 Train loss: 0.6715
en_de Dev loss: 0.8734 r:0.1889
en_zh Dev loss: 0.7884 r:0.2629
Current avg r:0.2259 Best avg r: 0.2259
10:07:19,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:07:45,625 root INFO 
id:en_de cur r: 0.1883 best r: 0.1883
10:08:11,779 root INFO 
id:en_zh cur r: 0.2950 best r: 0.2950
10:08:11,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:08:37,899 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:08:37,906 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:09:04,35 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7607
en_de Dev loss: 0.8831 r:0.2094
en_zh Dev loss: 0.7857 r:0.2721
Current avg r:0.2408 Best avg r: 0.2408
10:10:21,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:47,138 root INFO 
id:en_de cur r: 0.2054 best r: 0.2054
10:11:13,217 root INFO 
id:en_zh cur r: 0.3263 best r: 0.3263
10:11:13,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:39,306 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:11:39,312 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:12:05,471 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8015
en_de Dev loss: 0.8826 r:0.2348
en_zh Dev loss: 0.7721 r:0.3030
Current avg r:0.2689 Best avg r: 0.2689
10:13:22,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:01,653 root INFO 
id:en_zh cur r: 0.3321 best r: 0.3321
10:14:01,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:27,774 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7719
en_de Dev loss: 0.8838 r:0.1921
en_zh Dev loss: 0.7726 r:0.3109
Current avg r:0.2515 Best avg r: 0.2689
10:15:44,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:24,42 root INFO 
id:en_zh cur r: 0.3337 best r: 0.3337
10:16:24,42 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:16:50,123 root INFO Epoch 0 Global steps: 1600 Train loss: 0.6667
en_de Dev loss: 0.8759 r:0.1963
en_zh Dev loss: 0.7703 r:0.3247
Current avg r:0.2605 Best avg r: 0.2689
10:18:07,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:46,239 root INFO 
id:en_zh cur r: 0.3628 best r: 0.3628
10:18:46,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:12,341 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:19:12,347 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:19:38,476 root INFO Epoch 0 Global steps: 1800 Train loss: 0.6937
en_de Dev loss: 0.8572 r:0.1834
en_zh Dev loss: 0.7267 r:0.3695
Current avg r:0.2764 Best avg r: 0.2764
10:20:55,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:34,706 root INFO 
id:en_zh cur r: 0.3839 best r: 0.3839
10:21:34,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:00,848 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:22:00,855 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:22:27,9 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7272
en_de Dev loss: 0.8714 r:0.1712
en_zh Dev loss: 0.7255 r:0.3839
Current avg r:0.2776 Best avg r: 0.2776
10:23:44,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:23,154 root INFO 
id:en_zh cur r: 0.3996 best r: 0.3996
10:24:23,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:24:49,234 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:24:49,239 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:25:15,362 root INFO Epoch 0 Global steps: 2200 Train loss: 0.6623
en_de Dev loss: 0.8525 r:0.1980
en_zh Dev loss: 0.7061 r:0.3945
Current avg r:0.2962 Best avg r: 0.2962
10:26:32,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:11,545 root INFO 
id:en_zh cur r: 0.4088 best r: 0.4088
10:27:11,546 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:37,672 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:27:37,678 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:28:03,847 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6204
en_de Dev loss: 0.8610 r:0.2002
en_zh Dev loss: 0.7018 r:0.3987
Current avg r:0.2995 Best avg r: 0.2995
10:29:20,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:59,948 root INFO 
id:en_zh cur r: 0.4123 best r: 0.4123
10:29:59,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:26,95 root INFO Epoch 0 Global steps: 2600 Train loss: 0.7679
en_de Dev loss: 0.8537 r:0.1961
en_zh Dev loss: 0.6902 r:0.4003
Current avg r:0.2982 Best avg r: 0.2995
10:31:43,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:32:22,325 root INFO 
id:en_zh cur r: 0.4232 best r: 0.4232
10:32:22,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:32:48,434 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:32:48,445 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:33:14,578 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6409
en_de Dev loss: 0.8756 r:0.2122
en_zh Dev loss: 0.7222 r:0.3989
Current avg r:0.3055 Best avg r: 0.3055
10:34:31,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:34:58,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:35:24,161 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:35:24,168 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:35:50,305 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7257
en_de Dev loss: 0.8699 r:0.2267
en_zh Dev loss: 0.7360 r:0.3889
Current avg r:0.3078 Best avg r: 0.3078
10:37:07,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:37:33,866 root INFO 
id:en_de cur r: 0.2117 best r: 0.2117
10:37:46,911 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:38:13,19 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6991
en_de Dev loss: 0.8641 r:0.2320
en_zh Dev loss: 0.7479 r:0.3797
Current avg r:0.3058 Best avg r: 0.3078
10:39:30,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:39:56,260 root INFO 
id:en_de cur r: 0.2150 best r: 0.2150
10:40:22,353 root INFO 
id:en_zh cur r: 0.4311 best r: 0.4311
10:40:22,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:40:48,433 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:40:48,439 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:41:14,554 root INFO Epoch 1 Global steps: 3400 Train loss: 0.6854
en_de Dev loss: 0.8474 r:0.2186
en_zh Dev loss: 0.7000 r:0.4204
Current avg r:0.3195 Best avg r: 0.3195
10:42:31,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:42:57,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:43:23,835 root INFO Epoch 1 Global steps: 3600 Train loss: 0.6312
en_de Dev loss: 0.8637 r:0.2389
en_zh Dev loss: 0.7374 r:0.3917
Current avg r:0.3153 Best avg r: 0.3195
10:44:40,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:45:07,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:45:33,120 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6632
en_de Dev loss: 0.8517 r:0.2111
en_zh Dev loss: 0.6915 r:0.4064
Current avg r:0.3088 Best avg r: 0.3195
10:46:50,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:47:16,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:47:42,374 root INFO Epoch 1 Global steps: 4000 Train loss: 0.7200
en_de Dev loss: 0.8592 r:0.2178
en_zh Dev loss: 0.6992 r:0.4187
Current avg r:0.3182 Best avg r: 0.3195
10:48:59,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:49:38,528 root INFO 
id:en_zh cur r: 0.4347 best r: 0.4347
10:49:38,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:50:04,616 root INFO Epoch 1 Global steps: 4200 Train loss: 0.7097
en_de Dev loss: 0.8565 r:0.2201
en_zh Dev loss: 0.6987 r:0.4140
Current avg r:0.3170 Best avg r: 0.3195
10:51:21,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:51:47,829 root INFO 
id:en_de cur r: 0.2289 best r: 0.2289
10:52:13,944 root INFO 
id:en_zh cur r: 0.4362 best r: 0.4362
10:52:13,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:52:40,28 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
10:52:40,44 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
10:53:06,191 root INFO Epoch 1 Global steps: 4400 Train loss: 0.6708
en_de Dev loss: 0.8480 r:0.2290
en_zh Dev loss: 0.6820 r:0.4214
Current avg r:0.3252 Best avg r: 0.3252
10:54:23,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:54:49,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:55:15,429 root INFO Epoch 1 Global steps: 4600 Train loss: 0.6619
en_de Dev loss: 0.8560 r:0.2131
en_zh Dev loss: 0.7037 r:0.4099
Current avg r:0.3115 Best avg r: 0.3252
10:56:32,434 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:57:11,580 root INFO 
id:en_zh cur r: 0.4387 best r: 0.4387
10:57:11,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:57:37,687 root INFO Epoch 1 Global steps: 4800 Train loss: 0.5824
en_de Dev loss: 0.8494 r:0.2201
en_zh Dev loss: 0.6773 r:0.4232
Current avg r:0.3217 Best avg r: 0.3252
10:58:54,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:59:20,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:59:46,948 root INFO Epoch 1 Global steps: 5000 Train loss: 0.5974
en_de Dev loss: 0.8541 r:0.2354
en_zh Dev loss: 0.7120 r:0.4119
Current avg r:0.3236 Best avg r: 0.3252
11:01:03,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:01:43,146 root INFO 
id:en_zh cur r: 0.4405 best r: 0.4405
11:01:43,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:02:09,227 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
11:02:09,235 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:02:35,333 root INFO Epoch 1 Global steps: 5200 Train loss: 0.6239
en_de Dev loss: 0.8505 r:0.2353
en_zh Dev loss: 0.7129 r:0.4188
Current avg r:0.3270 Best avg r: 0.3270
11:03:52,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:04:31,359 root INFO 
id:en_zh cur r: 0.4478 best r: 0.4478
11:04:31,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:04:57,455 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
11:04:57,461 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:05:23,627 root INFO Epoch 1 Global steps: 5400 Train loss: 0.5154
en_de Dev loss: 0.8596 r:0.2374
en_zh Dev loss: 0.6986 r:0.4275
Current avg r:0.3324 Best avg r: 0.3324
11:06:40,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:07:06,791 root INFO 
id:en_de cur r: 0.2301 best r: 0.2301
11:07:32,864 root INFO 
id:en_zh cur r: 0.4589 best r: 0.4589
11:07:32,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:07:58,951 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
11:07:58,971 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:08:25,113 root INFO Epoch 1 Global steps: 5600 Train loss: 0.6615
en_de Dev loss: 0.8393 r:0.2419
en_zh Dev loss: 0.6841 r:0.4372
Current avg r:0.3395 Best avg r: 0.3395
11:09:42,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:10:08,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:10:34,324 root INFO Epoch 1 Global steps: 5800 Train loss: 0.5349
en_de Dev loss: 0.8415 r:0.2372
en_zh Dev loss: 0.6866 r:0.4388
Current avg r:0.3380 Best avg r: 0.3395
11:11:51,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:12:30,544 root INFO 
id:en_zh cur r: 0.4666 best r: 0.4666
11:12:30,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:12:56,625 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
11:12:56,631 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:13:22,759 root INFO Epoch 1 Global steps: 6000 Train loss: 0.6666
en_de Dev loss: 0.8498 r:0.2405
en_zh Dev loss: 0.6768 r:0.4421
Current avg r:0.3413 Best avg r: 0.3413
11:14:40,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:15:19,294 root INFO 
id:en_zh cur r: 0.4753 best r: 0.4753
11:15:19,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:15:45,378 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
11:15:45,384 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:16:11,504 root INFO Epoch 2 Global steps: 6200 Train loss: 0.6197
en_de Dev loss: 0.8428 r:0.2484
en_zh Dev loss: 0.6811 r:0.4512
Current avg r:0.3498 Best avg r: 0.3498
11:17:28,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:17:54,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:18:20,736 root INFO Epoch 2 Global steps: 6400 Train loss: 0.5656
en_de Dev loss: 0.8432 r:0.2457
en_zh Dev loss: 0.7101 r:0.4447
Current avg r:0.3452 Best avg r: 0.3498
11:19:37,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:20:03,799 root INFO 
id:en_de cur r: 0.2416 best r: 0.2416
11:20:16,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:20:42,907 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
11:20:42,916 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
11:21:09,14 root INFO Epoch 2 Global steps: 6600 Train loss: 0.6101
en_de Dev loss: 0.8289 r:0.2626
en_zh Dev loss: 0.6468 r:0.4644
Current avg r:0.3635 Best avg r: 0.3635
11:22:25,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:22:52,56 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:23:18,160 root INFO Epoch 2 Global steps: 6800 Train loss: 0.6718
en_de Dev loss: 0.8580 r:0.2356
en_zh Dev loss: 0.7756 r:0.4242
Current avg r:0.3299 Best avg r: 0.3635
11:24:35,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:25:14,398 root INFO 
id:en_zh cur r: 0.4766 best r: 0.4766
11:25:14,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:25:40,503 root INFO Epoch 2 Global steps: 7000 Train loss: 0.5996
en_de Dev loss: 0.8329 r:0.2489
en_zh Dev loss: 0.6921 r:0.4563
Current avg r:0.3526 Best avg r: 0.3635
11:26:57,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:27:36,766 root INFO 
id:en_zh cur r: 0.4799 best r: 0.4799
11:27:36,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:28:02,855 root INFO Epoch 2 Global steps: 7200 Train loss: 0.6165
en_de Dev loss: 0.8365 r:0.2472
en_zh Dev loss: 0.6741 r:0.4611
Current avg r:0.3542 Best avg r: 0.3635
11:29:19,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:29:45,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:30:12,18 root INFO Epoch 2 Global steps: 7400 Train loss: 0.5124
en_de Dev loss: 0.8644 r:0.2302
en_zh Dev loss: 0.6877 r:0.4497
Current avg r:0.3399 Best avg r: 0.3635
11:31:28,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:31:55,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:32:21,174 root INFO Epoch 2 Global steps: 7600 Train loss: 0.5886
en_de Dev loss: 0.8746 r:0.2227
en_zh Dev loss: 0.7692 r:0.4406
Current avg r:0.3316 Best avg r: 0.3635
11:33:38,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:34:04,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:34:30,288 root INFO Epoch 2 Global steps: 7800 Train loss: 0.6115
en_de Dev loss: 0.8493 r:0.2356
en_zh Dev loss: 0.7068 r:0.4617
Current avg r:0.3487 Best avg r: 0.3635
11:35:47,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:36:13,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:36:39,314 root INFO Epoch 2 Global steps: 8000 Train loss: 0.5425
en_de Dev loss: 0.8638 r:0.2403
en_zh Dev loss: 0.7878 r:0.4218
Current avg r:0.3311 Best avg r: 0.3635
11:37:56,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:38:22,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:38:48,455 root INFO Epoch 2 Global steps: 8200 Train loss: 0.6281
en_de Dev loss: 0.8581 r:0.2356
en_zh Dev loss: 0.7142 r:0.4349
Current avg r:0.3352 Best avg r: 0.3635
11:40:05,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:40:31,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:40:57,611 root INFO Epoch 2 Global steps: 8400 Train loss: 0.6156
en_de Dev loss: 0.8551 r:0.2425
en_zh Dev loss: 0.7716 r:0.4527
Current avg r:0.3476 Best avg r: 0.3635
11:42:14,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:42:53,704 root INFO 
id:en_zh cur r: 0.4884 best r: 0.4884
11:42:53,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:43:19,818 root INFO Epoch 2 Global steps: 8600 Train loss: 0.6150
en_de Dev loss: 0.8393 r:0.2437
en_zh Dev loss: 0.6562 r:0.4778
Current avg r:0.3608 Best avg r: 0.3635
11:44:36,891 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:45:02,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:45:29,58 root INFO Epoch 2 Global steps: 8800 Train loss: 0.5094
en_de Dev loss: 0.8665 r:0.2387
en_zh Dev loss: 0.6868 r:0.4633
Current avg r:0.3510 Best avg r: 0.3635
11:46:46,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:47:12,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:47:38,306 root INFO Epoch 2 Global steps: 9000 Train loss: 0.5761
en_de Dev loss: 0.8626 r:0.2363
en_zh Dev loss: 0.7298 r:0.4605
Current avg r:0.3484 Best avg r: 0.3635
11:48:55,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:49:21,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:49:47,800 root INFO Epoch 3 Global steps: 9200 Train loss: 0.5945
en_de Dev loss: 0.8432 r:0.2386
en_zh Dev loss: 0.6838 r:0.4745
Current avg r:0.3566 Best avg r: 0.3635
11:51:04,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:51:30,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:51:56,782 root INFO Epoch 3 Global steps: 9400 Train loss: 0.6125
en_de Dev loss: 0.8550 r:0.2356
en_zh Dev loss: 0.7445 r:0.4537
Current avg r:0.3447 Best avg r: 0.3635
11:53:13,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:53:39,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:54:06,3 root INFO Epoch 3 Global steps: 9600 Train loss: 0.4357
en_de Dev loss: 0.8560 r:0.2295
en_zh Dev loss: 0.6774 r:0.4693
Current avg r:0.3494 Best avg r: 0.3635
11:55:23,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:55:49,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:56:15,263 root INFO Epoch 3 Global steps: 9800 Train loss: 0.6631
en_de Dev loss: 0.8567 r:0.2287
en_zh Dev loss: 0.6934 r:0.4653
Current avg r:0.3470 Best avg r: 0.3635
11:57:32,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:57:58,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:58:24,287 root INFO Epoch 3 Global steps: 10000 Train loss: 0.5213
en_de Dev loss: 0.8623 r:0.2116
en_zh Dev loss: 0.7031 r:0.4673
Current avg r:0.3394 Best avg r: 0.3635
11:59:41,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:00:20,327 root INFO 
id:en_zh cur r: 0.4891 best r: 0.4891
12:00:20,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:00:46,432 root INFO Epoch 3 Global steps: 10200 Train loss: 0.5687
en_de Dev loss: 0.8537 r:0.2449
en_zh Dev loss: 0.7092 r:0.4768
Current avg r:0.3609 Best avg r: 0.3635
12:02:03,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:02:42,505 root INFO 
id:en_zh cur r: 0.4998 best r: 0.4998
12:02:42,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:03:08,589 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
12:03:08,595 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
12:03:34,682 root INFO Epoch 3 Global steps: 10400 Train loss: 0.5498
en_de Dev loss: 0.8306 r:0.2533
en_zh Dev loss: 0.6559 r:0.4912
Current avg r:0.3723 Best avg r: 0.3723
12:04:51,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:05:17,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:05:43,942 root INFO Epoch 3 Global steps: 10600 Train loss: 0.6367
en_de Dev loss: 0.8347 r:0.2541
en_zh Dev loss: 0.6724 r:0.4698
Current avg r:0.3620 Best avg r: 0.3723
12:07:01,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:07:27,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:07:53,176 root INFO Epoch 3 Global steps: 10800 Train loss: 0.5369
en_de Dev loss: 0.8406 r:0.2469
en_zh Dev loss: 0.6925 r:0.4740
Current avg r:0.3605 Best avg r: 0.3723
12:09:10,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:09:36,80 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:10:02,148 root INFO Epoch 3 Global steps: 11000 Train loss: 0.5202
en_de Dev loss: 0.8476 r:0.2557
en_zh Dev loss: 0.7097 r:0.4664
Current avg r:0.3611 Best avg r: 0.3723
12:11:19,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:11:45,172 root INFO 
id:en_de cur r: 0.2533 best r: 0.2533
12:11:58,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:12:24,293 root INFO Epoch 3 Global steps: 11200 Train loss: 0.4740
en_de Dev loss: 0.8315 r:0.2690
en_zh Dev loss: 0.6927 r:0.4712
Current avg r:0.3701 Best avg r: 0.3723
12:13:41,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:14:07,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:14:33,342 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_de.lang_agnost_mlp.dev.best.scores
12:14:33,349 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run1/en_zh.lang_agnost_mlp.dev.best.scores
12:14:59,433 root INFO Epoch 3 Global steps: 11400 Train loss: 0.4809
en_de Dev loss: 0.8346 r:0.2616
en_zh Dev loss: 0.6655 r:0.4865
Current avg r:0.3741 Best avg r: 0.3741
12:16:16,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:16:42,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:17:08,612 root INFO Epoch 3 Global steps: 11600 Train loss: 0.4602
en_de Dev loss: 0.8505 r:0.2516
en_zh Dev loss: 0.7006 r:0.4820
Current avg r:0.3668 Best avg r: 0.3741
12:18:25,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:18:51,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:19:17,696 root INFO Epoch 3 Global steps: 11800 Train loss: 0.5632
en_de Dev loss: 0.8413 r:0.2460
en_zh Dev loss: 0.7215 r:0.4671
Current avg r:0.3565 Best avg r: 0.3741
12:20:34,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:21:00,752 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:21:26,847 root INFO Epoch 3 Global steps: 12000 Train loss: 0.4905
en_de Dev loss: 0.8324 r:0.2681
en_zh Dev loss: 0.7111 r:0.4719
Current avg r:0.3700 Best avg r: 0.3741
12:22:44,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:23:10,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:23:36,544 root INFO Epoch 4 Global steps: 12200 Train loss: 0.5052
en_de Dev loss: 0.8471 r:0.2528
en_zh Dev loss: 0.7158 r:0.4680
Current avg r:0.3604 Best avg r: 0.3741
12:24:53,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:25:19,684 root INFO 
id:en_de cur r: 0.2575 best r: 0.2575
12:25:32,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:25:58,772 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4793
en_de Dev loss: 0.8358 r:0.2615
en_zh Dev loss: 0.6949 r:0.4581
Current avg r:0.3598 Best avg r: 0.3741
12:27:15,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:27:41,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:28:07,884 root INFO Epoch 4 Global steps: 12600 Train loss: 0.5055
en_de Dev loss: 0.8495 r:0.2334
en_zh Dev loss: 0.7617 r:0.4569
Current avg r:0.3451 Best avg r: 0.3741
12:29:24,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:29:50,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:30:16,975 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4179
en_de Dev loss: 0.8403 r:0.2346
en_zh Dev loss: 0.6857 r:0.4701
Current avg r:0.3523 Best avg r: 0.3741
12:31:33,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:32:00,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:32:26,148 root INFO Epoch 4 Global steps: 13000 Train loss: 0.3965
en_de Dev loss: 0.8615 r:0.2376
en_zh Dev loss: 0.7040 r:0.4776
Current avg r:0.3576 Best avg r: 0.3741
12:33:43,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:34:09,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:34:35,313 root INFO Epoch 4 Global steps: 13200 Train loss: 0.4670
en_de Dev loss: 0.8543 r:0.2431
en_zh Dev loss: 0.7109 r:0.4727
Current avg r:0.3579 Best avg r: 0.3741
12:35:52,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:36:18,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:36:44,490 root INFO Epoch 4 Global steps: 13400 Train loss: 0.4788
en_de Dev loss: 0.8503 r:0.2486
en_zh Dev loss: 0.7429 r:0.4590
Current avg r:0.3538 Best avg r: 0.3741
12:38:01,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:38:27,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:38:53,582 root INFO Epoch 4 Global steps: 13600 Train loss: 0.4421
en_de Dev loss: 0.8416 r:0.2466
en_zh Dev loss: 0.8003 r:0.4391
Current avg r:0.3429 Best avg r: 0.3741
12:40:10,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:40:36,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:41:02,634 root INFO Epoch 4 Global steps: 13800 Train loss: 0.5318
en_de Dev loss: 0.8314 r:0.2627
en_zh Dev loss: 0.7130 r:0.4526
Current avg r:0.3576 Best avg r: 0.3741
12:42:19,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:42:45,640 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:43:11,718 root INFO Epoch 4 Global steps: 14000 Train loss: 0.4303
en_de Dev loss: 0.8356 r:0.2583
en_zh Dev loss: 0.7099 r:0.4606
Current avg r:0.3595 Best avg r: 0.3741
12:44:28,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:44:54,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:45:20,820 root INFO Epoch 4 Global steps: 14200 Train loss: 0.5031
en_de Dev loss: 0.8492 r:0.2270
en_zh Dev loss: 0.7049 r:0.4733
Current avg r:0.3501 Best avg r: 0.3741
12:46:37,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:47:03,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:47:30,13 root INFO Epoch 4 Global steps: 14400 Train loss: 0.4792
en_de Dev loss: 0.8482 r:0.2336
en_zh Dev loss: 0.7235 r:0.4636
Current avg r:0.3486 Best avg r: 0.3741
12:48:47,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:49:13,171 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:49:39,265 root INFO Epoch 4 Global steps: 14600 Train loss: 0.5336
en_de Dev loss: 0.8718 r:0.2260
en_zh Dev loss: 0.7851 r:0.4516
Current avg r:0.3388 Best avg r: 0.3741
12:50:56,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:51:22,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:51:48,490 root INFO Epoch 4 Global steps: 14800 Train loss: 0.4548
en_de Dev loss: 0.8448 r:0.2327
en_zh Dev loss: 0.6952 r:0.4589
Current avg r:0.3458 Best avg r: 0.3741
12:53:05,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:53:31,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:53:57,741 root INFO Epoch 4 Global steps: 15000 Train loss: 0.4750
en_de Dev loss: 0.8438 r:0.2474
en_zh Dev loss: 0.7280 r:0.4591
Current avg r:0.3532 Best avg r: 0.3741
12:55:15,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:55:41,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:56:07,277 root INFO Epoch 5 Global steps: 15200 Train loss: 0.4125
en_de Dev loss: 0.8631 r:0.2180
en_zh Dev loss: 0.7086 r:0.4663
Current avg r:0.3421 Best avg r: 0.3741
12:57:24,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:57:50,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:58:16,459 root INFO Epoch 5 Global steps: 15400 Train loss: 0.4457
en_de Dev loss: 0.8597 r:0.2394
en_zh Dev loss: 0.7531 r:0.4593
Current avg r:0.3493 Best avg r: 0.3741
12:59:33,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:59:59,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:00:25,822 root INFO Epoch 5 Global steps: 15600 Train loss: 0.4095
en_de Dev loss: 0.8411 r:0.2501
en_zh Dev loss: 0.7108 r:0.4652
Current avg r:0.3576 Best avg r: 0.3741
13:01:42,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:02:09,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:02:35,135 root INFO Epoch 5 Global steps: 15800 Train loss: 0.4074
en_de Dev loss: 0.8539 r:0.2431
en_zh Dev loss: 0.7580 r:0.4633
Current avg r:0.3532 Best avg r: 0.3741
13:03:52,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:04:18,278 root INFO 
id:en_de cur r: 0.2606 best r: 0.2606
13:04:31,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:04:57,429 root INFO Epoch 5 Global steps: 16000 Train loss: 0.4166
en_de Dev loss: 0.8353 r:0.2640
en_zh Dev loss: 0.7465 r:0.4594
Current avg r:0.3617 Best avg r: 0.3741
13:06:14,519 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:06:40,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:07:06,876 root INFO Epoch 5 Global steps: 16200 Train loss: 0.4423
en_de Dev loss: 0.8668 r:0.2250
en_zh Dev loss: 0.7523 r:0.4599
Current avg r:0.3425 Best avg r: 0.3741
13:08:24,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:08:50,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:09:16,257 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3773
en_de Dev loss: 0.8857 r:0.2346
en_zh Dev loss: 0.8344 r:0.4360
Current avg r:0.3353 Best avg r: 0.3741
13:10:33,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:10:59,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:11:25,365 root INFO Epoch 5 Global steps: 16600 Train loss: 0.4252
en_de Dev loss: 0.8389 r:0.2392
en_zh Dev loss: 0.7331 r:0.4580
Current avg r:0.3486 Best avg r: 0.3741
13:12:42,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:13:08,408 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:13:34,495 root INFO Epoch 5 Global steps: 16800 Train loss: 0.4036
en_de Dev loss: 0.8603 r:0.2268
en_zh Dev loss: 0.7424 r:0.4604
Current avg r:0.3436 Best avg r: 0.3741
13:14:51,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:15:17,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:15:43,658 root INFO Epoch 5 Global steps: 17000 Train loss: 0.4126
en_de Dev loss: 0.8530 r:0.2350
en_zh Dev loss: 0.7934 r:0.4522
Current avg r:0.3436 Best avg r: 0.3741
13:17:00,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:17:26,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:17:52,750 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3526
en_de Dev loss: 0.8506 r:0.2464
en_zh Dev loss: 0.7503 r:0.4622
Current avg r:0.3543 Best avg r: 0.3741
13:19:09,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:19:35,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:20:01,874 root INFO Epoch 5 Global steps: 17400 Train loss: 0.3582
en_de Dev loss: 0.8442 r:0.2437
en_zh Dev loss: 0.7486 r:0.4572
Current avg r:0.3505 Best avg r: 0.3741
13:21:18,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:21:44,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:22:10,953 root INFO Epoch 5 Global steps: 17600 Train loss: 0.3944
en_de Dev loss: 0.8530 r:0.2509
en_zh Dev loss: 0.7799 r:0.4516
Current avg r:0.3512 Best avg r: 0.3741
13:23:27,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:23:53,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:24:20,55 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3822
en_de Dev loss: 0.8368 r:0.2530
en_zh Dev loss: 0.7362 r:0.4540
Current avg r:0.3535 Best avg r: 0.3741
13:25:37,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:26:03,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:26:29,316 root INFO Epoch 5 Global steps: 18000 Train loss: 0.3869
en_de Dev loss: 0.8496 r:0.2486
en_zh Dev loss: 0.8184 r:0.4513
Current avg r:0.3499 Best avg r: 0.3741
13:27:46,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:28:12,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:28:38,761 root INFO Epoch 6 Global steps: 18200 Train loss: 0.3446
en_de Dev loss: 0.8586 r:0.2603
en_zh Dev loss: 0.8230 r:0.4450
Current avg r:0.3527 Best avg r: 0.3741
13:29:55,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:30:21,845 root INFO 
id:en_de cur r: 0.2620 best r: 0.2620
13:30:34,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:31:00,971 root INFO Epoch 6 Global steps: 18400 Train loss: 0.3413
en_de Dev loss: 0.8413 r:0.2607
en_zh Dev loss: 0.7951 r:0.4473
Current avg r:0.3540 Best avg r: 0.3741
13:32:17,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:32:43,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:33:10,47 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3822
en_de Dev loss: 0.8343 r:0.2559
en_zh Dev loss: 0.7574 r:0.4534
Current avg r:0.3547 Best avg r: 0.3741
13:34:27,36 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:34:53,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:35:19,190 root INFO Epoch 6 Global steps: 18800 Train loss: 0.3609
en_de Dev loss: 0.8670 r:0.2469
en_zh Dev loss: 0.8676 r:0.4419
Current avg r:0.3444 Best avg r: 0.3741
13:36:36,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:37:02,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:37:28,764 root INFO Epoch 6 Global steps: 19000 Train loss: 0.3512
en_de Dev loss: 0.8428 r:0.2545
en_zh Dev loss: 0.7690 r:0.4603
Current avg r:0.3574 Best avg r: 0.3741
13:38:45,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:39:12,108 root INFO 
id:en_de cur r: 0.2640 best r: 0.2640
13:39:25,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:39:51,274 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3319
en_de Dev loss: 0.8406 r:0.2609
en_zh Dev loss: 0.7597 r:0.4554
Current avg r:0.3582 Best avg r: 0.3741
13:41:08,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:41:34,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:42:00,766 root INFO Epoch 6 Global steps: 19400 Train loss: 0.3519
en_de Dev loss: 0.8282 r:0.2584
en_zh Dev loss: 0.7260 r:0.4664
Current avg r:0.3624 Best avg r: 0.3741
13:43:18,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:43:44,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:44:10,307 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3464
en_de Dev loss: 0.8650 r:0.2257
en_zh Dev loss: 0.7981 r:0.4619
Current avg r:0.3438 Best avg r: 0.3741
13:45:27,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:45:53,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:46:19,847 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3647
en_de Dev loss: 0.8502 r:0.2365
en_zh Dev loss: 0.7238 r:0.4721
Current avg r:0.3543 Best avg r: 0.3741
13:47:36,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:48:03,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:48:29,160 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3765
en_de Dev loss: 0.8848 r:0.2189
en_zh Dev loss: 0.8450 r:0.4513
Current avg r:0.3351 Best avg r: 0.3741
13:49:46,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:50:12,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:50:38,611 root INFO Epoch 6 Global steps: 20200 Train loss: 0.3495
en_de Dev loss: 0.8811 r:0.2151
en_zh Dev loss: 0.9308 r:0.4397
Current avg r:0.3274 Best avg r: 0.3741
13:51:55,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:52:21,815 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:52:47,939 root INFO Epoch 6 Global steps: 20400 Train loss: 0.3315
en_de Dev loss: 0.8654 r:0.2108
en_zh Dev loss: 0.7359 r:0.4571
Current avg r:0.3340 Best avg r: 0.3741
13:54:05,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:54:31,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:54:57,313 root INFO Epoch 6 Global steps: 20600 Train loss: 0.3489
en_de Dev loss: 0.8578 r:0.2228
en_zh Dev loss: 0.6893 r:0.4766
Current avg r:0.3497 Best avg r: 0.3741
13:56:14,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:56:40,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:57:06,622 root INFO Epoch 6 Global steps: 20800 Train loss: 0.3080
en_de Dev loss: 0.8675 r:0.2229
en_zh Dev loss: 0.7721 r:0.4605
Current avg r:0.3417 Best avg r: 0.3741
13:58:23,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:58:49,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:59:15,999 root INFO Epoch 6 Global steps: 21000 Train loss: 0.3018
en_de Dev loss: 0.8722 r:0.2244
en_zh Dev loss: 0.8066 r:0.4540
Current avg r:0.3392 Best avg r: 0.3741
14:00:33,529 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:00:59,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:01:25,819 root INFO Epoch 7 Global steps: 21200 Train loss: 0.2886
en_de Dev loss: 0.8728 r:0.2280
en_zh Dev loss: 0.7669 r:0.4608
Current avg r:0.3444 Best avg r: 0.3741
14:02:43,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:03:09,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:03:35,381 root INFO Epoch 7 Global steps: 21400 Train loss: 0.3128
en_de Dev loss: 0.8516 r:0.2353
en_zh Dev loss: 0.7249 r:0.4736
Current avg r:0.3545 Best avg r: 0.3741
14:04:52,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:05:18,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:05:44,939 root INFO Epoch 7 Global steps: 21600 Train loss: 0.3005
en_de Dev loss: 0.8465 r:0.2390
en_zh Dev loss: 0.7090 r:0.4719
Current avg r:0.3555 Best avg r: 0.3741
14:07:02,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:07:28,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:07:54,534 root INFO Epoch 7 Global steps: 21800 Train loss: 0.3208
en_de Dev loss: 0.8659 r:0.2177
en_zh Dev loss: 0.7283 r:0.4636
Current avg r:0.3406 Best avg r: 0.3741
14:09:11,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:09:37,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:10:04,81 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2794
en_de Dev loss: 0.8637 r:0.2333
en_zh Dev loss: 0.8091 r:0.4501
Current avg r:0.3417 Best avg r: 0.3741
14:11:21,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:11:47,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:12:13,616 root INFO Epoch 7 Global steps: 22200 Train loss: 0.3592
en_de Dev loss: 0.8761 r:0.2341
en_zh Dev loss: 0.7770 r:0.4615
Current avg r:0.3478 Best avg r: 0.3741
14:13:30,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:13:56,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:14:22,978 root INFO Epoch 7 Global steps: 22400 Train loss: 0.2704
en_de Dev loss: 0.8884 r:0.2209
en_zh Dev loss: 0.8266 r:0.4398
Current avg r:0.3303 Best avg r: 0.3741
14:15:40,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:16:06,201 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:16:32,343 root INFO Epoch 7 Global steps: 22600 Train loss: 0.3175
en_de Dev loss: 0.9032 r:0.2234
en_zh Dev loss: 0.9000 r:0.4400
Current avg r:0.3317 Best avg r: 0.3741
14:17:49,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:18:15,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:18:41,876 root INFO Epoch 7 Global steps: 22800 Train loss: 0.3025
en_de Dev loss: 0.8524 r:0.2486
en_zh Dev loss: 0.7236 r:0.4613
Current avg r:0.3550 Best avg r: 0.3741
14:19:59,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:20:25,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:20:51,352 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2861
en_de Dev loss: 0.8597 r:0.2448
en_zh Dev loss: 0.7580 r:0.4556
Current avg r:0.3502 Best avg r: 0.3741
14:22:08,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:22:34,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:23:00,895 root INFO Epoch 7 Global steps: 23200 Train loss: 0.3560
en_de Dev loss: 0.8541 r:0.2254
en_zh Dev loss: 0.8121 r:0.4324
Current avg r:0.3289 Best avg r: 0.3741
14:24:17,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:24:44,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:25:10,220 root INFO Epoch 7 Global steps: 23400 Train loss: 0.3133
en_de Dev loss: 0.8794 r:0.2231
en_zh Dev loss: 0.8656 r:0.4391
Current avg r:0.3311 Best avg r: 0.3741
14:26:27,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:26:53,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:27:19,571 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2631
en_de Dev loss: 0.8653 r:0.2369
en_zh Dev loss: 0.7758 r:0.4580
Current avg r:0.3475 Best avg r: 0.3741
14:28:36,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:29:02,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:29:29,18 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2801
en_de Dev loss: 0.8690 r:0.2437
en_zh Dev loss: 0.7678 r:0.4551
Current avg r:0.3494 Best avg r: 0.3741
14:30:46,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:31:12,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:31:38,573 root INFO Epoch 7 Global steps: 24000 Train loss: 0.3138
en_de Dev loss: 0.8497 r:0.2513
en_zh Dev loss: 0.7610 r:0.4504
Current avg r:0.3509 Best avg r: 0.3741
14:32:56,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:33:22,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:33:48,507 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2826
en_de Dev loss: 0.8883 r:0.2111
en_zh Dev loss: 0.8452 r:0.4363
Current avg r:0.3237 Best avg r: 0.3741
14:35:05,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:35:31,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:35:57,786 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2531
en_de Dev loss: 0.8688 r:0.2532
en_zh Dev loss: 0.7202 r:0.4666
Current avg r:0.3599 Best avg r: 0.3741
14:37:14,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:40,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:38:07,57 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2673
en_de Dev loss: 0.9177 r:0.1981
en_zh Dev loss: 0.9214 r:0.4420
Current avg r:0.3201 Best avg r: 0.3741
14:39:24,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:39:50,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:16,456 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2821
en_de Dev loss: 0.8593 r:0.2368
en_zh Dev loss: 0.7523 r:0.4603
Current avg r:0.3486 Best avg r: 0.3741
14:41:33,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:41:59,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:42:25,829 root INFO Epoch 8 Global steps: 25000 Train loss: 0.3040
en_de Dev loss: 0.8545 r:0.2310
en_zh Dev loss: 0.7099 r:0.4614
Current avg r:0.3462 Best avg r: 0.3741
14:43:43,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:09,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:44:35,360 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2984
en_de Dev loss: 0.8913 r:0.2140
en_zh Dev loss: 0.7646 r:0.4641
Current avg r:0.3390 Best avg r: 0.3741
14:45:52,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:46:18,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:44,902 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2381
en_de Dev loss: 0.8752 r:0.2445
en_zh Dev loss: 0.7818 r:0.4544
Current avg r:0.3494 Best avg r: 0.3741
14:48:02,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:28,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:54,339 root INFO Epoch 8 Global steps: 25600 Train loss: 0.3000
en_de Dev loss: 0.8762 r:0.2223
en_zh Dev loss: 0.7521 r:0.4459
Current avg r:0.3341 Best avg r: 0.3741
14:50:11,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:50:37,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:03,863 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2960
en_de Dev loss: 0.8783 r:0.2279
en_zh Dev loss: 0.7843 r:0.4564
Current avg r:0.3421 Best avg r: 0.3741
14:52:21,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:47,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:13,378 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2736
en_de Dev loss: 0.8666 r:0.2311
en_zh Dev loss: 0.7339 r:0.4654
Current avg r:0.3482 Best avg r: 0.3741
14:54:30,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:56,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:22,859 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2664
en_de Dev loss: 0.8994 r:0.2042
en_zh Dev loss: 0.7841 r:0.4616
Current avg r:0.3329 Best avg r: 0.3741
14:56:40,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:06,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:32,229 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2698
en_de Dev loss: 0.8851 r:0.1980
en_zh Dev loss: 0.7257 r:0.4669
Current avg r:0.3325 Best avg r: 0.3741
14:58:49,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:15,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:41,483 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2659
en_de Dev loss: 0.9311 r:0.1667
en_zh Dev loss: 0.7997 r:0.4540
Current avg r:0.3103 Best avg r: 0.3741
15:00:58,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:24,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:01:50,806 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2762
en_de Dev loss: 0.9096 r:0.1893
en_zh Dev loss: 0.8120 r:0.4553
Current avg r:0.3223 Best avg r: 0.3741
15:03:07,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:34,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:00,212 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2595
en_de Dev loss: 0.9071 r:0.2015
en_zh Dev loss: 0.8128 r:0.4448
Current avg r:0.3232 Best avg r: 0.3741
15:05:17,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:43,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:09,818 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2311
en_de Dev loss: 0.9003 r:0.2027
en_zh Dev loss: 0.8025 r:0.4505
Current avg r:0.3266 Best avg r: 0.3741
15:07:26,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:53,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:19,99 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2491
en_de Dev loss: 0.9370 r:0.1865
en_zh Dev loss: 0.8709 r:0.4373
Current avg r:0.3119 Best avg r: 0.3741
15:09:36,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:02,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:28,334 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2195
en_de Dev loss: 0.9389 r:0.1738
en_zh Dev loss: 0.8499 r:0.4375
Current avg r:0.3056 Best avg r: 0.3741
15:11:45,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:11,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:37,598 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2463
en_de Dev loss: 0.8896 r:0.2205
en_zh Dev loss: 0.7555 r:0.4542
Current avg r:0.3373 Best avg r: 0.3741
15:13:54,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:20,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:46,851 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2457
en_de Dev loss: 0.9038 r:0.1883
en_zh Dev loss: 0.8150 r:0.4415
Current avg r:0.3149 Best avg r: 0.3741
15:16:03,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:30,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:56,210 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2455
en_de Dev loss: 0.9290 r:0.1895
en_zh Dev loss: 0.8441 r:0.4367
Current avg r:0.3131 Best avg r: 0.3741
15:18:13,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:39,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:05,492 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2341
en_de Dev loss: 0.9085 r:0.2119
en_zh Dev loss: 0.7982 r:0.4516
Current avg r:0.3318 Best avg r: 0.3741
15:20:22,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:48,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:14,739 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2440
en_de Dev loss: 0.8784 r:0.2063
en_zh Dev loss: 0.7707 r:0.4397
Current avg r:0.3230 Best avg r: 0.3741
15:22:31,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:57,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:24,20 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2523
en_de Dev loss: 0.8883 r:0.1979
en_zh Dev loss: 0.8148 r:0.4395
Current avg r:0.3187 Best avg r: 0.3741
15:24:41,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:07,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:33,273 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2371
en_de Dev loss: 0.9085 r:0.1933
en_zh Dev loss: 0.8407 r:0.4463
Current avg r:0.3198 Best avg r: 0.3741
15:26:50,522 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:16,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:42,784 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2779
en_de Dev loss: 0.8929 r:0.2021
en_zh Dev loss: 0.8316 r:0.4529
Current avg r:0.3275 Best avg r: 0.3741
15:28:59,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:25,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:52,48 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2573
en_de Dev loss: 0.8950 r:0.1989
en_zh Dev loss: 0.7763 r:0.4464
Current avg r:0.3226 Best avg r: 0.3741
15:31:09,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:35,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:01,324 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2414
en_de Dev loss: 0.9148 r:0.1924
en_zh Dev loss: 0.8240 r:0.4453
Current avg r:0.3189 Best avg r: 0.3741
15:33:18,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:44,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:10,605 root INFO Epoch 9 Global steps: 29800 Train loss: 0.2653
en_de Dev loss: 0.9155 r:0.2078
en_zh Dev loss: 0.8104 r:0.4569
Current avg r:0.3324 Best avg r: 0.3741
15:35:27,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:53,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:19,914 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2437
en_de Dev loss: 0.9087 r:0.2069
en_zh Dev loss: 0.7514 r:0.4706
Current avg r:0.3388 Best avg r: 0.3741
15:37:37,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:03,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:29,813 root INFO Epoch 10 Global steps: 30200 Train loss: 0.2147
en_de Dev loss: 0.9472 r:0.1813
en_zh Dev loss: 0.8786 r:0.4565
Current avg r:0.3189 Best avg r: 0.3741
15:39:47,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:13,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:39,309 root INFO Epoch 10 Global steps: 30400 Train loss: 0.2072
en_de Dev loss: 0.9217 r:0.1965
en_zh Dev loss: 0.8026 r:0.4506
Current avg r:0.3235 Best avg r: 0.3741
15:41:56,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:22,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:48,723 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2088
en_de Dev loss: 0.9179 r:0.2042
en_zh Dev loss: 0.7891 r:0.4597
Current avg r:0.3319 Best avg r: 0.3741
15:44:05,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:32,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:58,141 root INFO Epoch 10 Global steps: 30800 Train loss: 0.2451
en_de Dev loss: 0.9085 r:0.1998
en_zh Dev loss: 0.8369 r:0.4513
Current avg r:0.3256 Best avg r: 0.3741
15:46:15,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:41,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:07,410 root INFO Epoch 10 Global steps: 31000 Train loss: 0.2262
en_de Dev loss: 0.9123 r:0.1985
en_zh Dev loss: 0.8592 r:0.4587
Current avg r:0.3286 Best avg r: 0.3741
15:48:24,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:50,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:16,664 root INFO Epoch 10 Global steps: 31200 Train loss: 0.2396
en_de Dev loss: 0.8898 r:0.2177
en_zh Dev loss: 0.7900 r:0.4529
Current avg r:0.3353 Best avg r: 0.3741
15:50:33,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:59,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:25,926 root INFO Epoch 10 Global steps: 31400 Train loss: 0.2238
en_de Dev loss: 0.9265 r:0.1669
en_zh Dev loss: 0.8195 r:0.4457
Current avg r:0.3063 Best avg r: 0.3741
15:52:43,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:09,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:35,348 root INFO Epoch 10 Global steps: 31600 Train loss: 0.2063
en_de Dev loss: 0.9309 r:0.1691
en_zh Dev loss: 0.8142 r:0.4563
Current avg r:0.3127 Best avg r: 0.3741
15:54:52,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:18,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:44,883 root INFO Epoch 10 Global steps: 31800 Train loss: 0.2096
en_de Dev loss: 0.9388 r:0.1523
en_zh Dev loss: 0.8465 r:0.4506
Current avg r:0.3014 Best avg r: 0.3741
15:57:02,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:28,174 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:54,269 root INFO Epoch 10 Global steps: 32000 Train loss: 0.2085
en_de Dev loss: 0.9119 r:0.1918
en_zh Dev loss: 0.7448 r:0.4683
Current avg r:0.3301 Best avg r: 0.3741
15:59:11,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:37,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:03,630 root INFO Epoch 10 Global steps: 32200 Train loss: 0.2131
en_de Dev loss: 0.9073 r:0.1832
en_zh Dev loss: 0.7932 r:0.4653
Current avg r:0.3242 Best avg r: 0.3741
16:01:20,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:46,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:12,975 root INFO Epoch 10 Global steps: 32400 Train loss: 0.2198
en_de Dev loss: 0.9137 r:0.1801
en_zh Dev loss: 0.7921 r:0.4567
Current avg r:0.3184 Best avg r: 0.3741
16:03:30,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:56,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:22,380 root INFO Epoch 10 Global steps: 32600 Train loss: 0.2160
en_de Dev loss: 0.9199 r:0.1717
en_zh Dev loss: 0.7878 r:0.4538
Current avg r:0.3128 Best avg r: 0.3741
16:05:39,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:05,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:31,885 root INFO Epoch 10 Global steps: 32800 Train loss: 0.2113
en_de Dev loss: 0.9044 r:0.1743
en_zh Dev loss: 0.7853 r:0.4621
Current avg r:0.3182 Best avg r: 0.3741
16:07:49,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:08:15,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:41,431 root INFO Epoch 10 Global steps: 33000 Train loss: 0.2258
en_de Dev loss: 0.9507 r:0.1366
en_zh Dev loss: 0.8862 r:0.4443
Current avg r:0.2905 Best avg r: 0.3741
16:09:59,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:25,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:51,358 root INFO Epoch 11 Global steps: 33200 Train loss: 0.2013
en_de Dev loss: 0.9137 r:0.1787
en_zh Dev loss: 0.7651 r:0.4588
Current avg r:0.3187 Best avg r: 0.3741
16:12:08,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:34,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:00,685 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1952
en_de Dev loss: 0.9222 r:0.1877
en_zh Dev loss: 0.8096 r:0.4564
Current avg r:0.3221 Best avg r: 0.3741
16:14:17,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:44,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:10,152 root INFO Epoch 11 Global steps: 33600 Train loss: 0.2046
en_de Dev loss: 0.9039 r:0.1959
en_zh Dev loss: 0.7321 r:0.4633
Current avg r:0.3296 Best avg r: 0.3741
16:16:27,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:53,597 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:17:19,728 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1935
en_de Dev loss: 0.9444 r:0.1654
en_zh Dev loss: 0.7754 r:0.4558
Current avg r:0.3106 Best avg r: 0.3741
16:18:36,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:03,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:29,233 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1929
en_de Dev loss: 0.9299 r:0.1721
en_zh Dev loss: 0.8193 r:0.4513
Current avg r:0.3117 Best avg r: 0.3741
16:20:46,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:21:12,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:38,814 root INFO Epoch 11 Global steps: 34200 Train loss: 0.2077
en_de Dev loss: 0.9350 r:0.1523
en_zh Dev loss: 0.8402 r:0.4553
Current avg r:0.3038 Best avg r: 0.3741
16:22:56,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:22,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:48,334 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1820
en_de Dev loss: 0.9499 r:0.1628
en_zh Dev loss: 0.8490 r:0.4589
Current avg r:0.3109 Best avg r: 0.3741
16:25:05,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:31,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:57,632 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1785
en_de Dev loss: 0.9605 r:0.1442
en_zh Dev loss: 0.8188 r:0.4606
Current avg r:0.3024 Best avg r: 0.3741
16:27:14,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:40,826 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:06,957 root INFO Epoch 11 Global steps: 34800 Train loss: 0.2098
en_de Dev loss: 0.9364 r:0.1493
en_zh Dev loss: 0.8179 r:0.4568
Current avg r:0.3031 Best avg r: 0.3741
16:29:24,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:50,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:16,402 root INFO Epoch 11 Global steps: 35000 Train loss: 0.2058
en_de Dev loss: 0.9313 r:0.1595
en_zh Dev loss: 0.7883 r:0.4579
Current avg r:0.3087 Best avg r: 0.3741
16:31:33,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:59,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:32:25,929 root INFO Epoch 11 Global steps: 35200 Train loss: 0.2061
en_de Dev loss: 0.9316 r:0.1659
en_zh Dev loss: 0.7280 r:0.4758
Current avg r:0.3209 Best avg r: 0.3741
16:33:43,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:09,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:35,366 root INFO Epoch 11 Global steps: 35400 Train loss: 0.2304
en_de Dev loss: 0.9301 r:0.1565
en_zh Dev loss: 0.7979 r:0.4617
Current avg r:0.3091 Best avg r: 0.3741
16:35:52,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:18,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:44,880 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1971
en_de Dev loss: 0.9317 r:0.1689
en_zh Dev loss: 0.7825 r:0.4612
Current avg r:0.3151 Best avg r: 0.3741
16:38:02,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:28,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:54,395 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1931
en_de Dev loss: 0.9375 r:0.1692
en_zh Dev loss: 0.7759 r:0.4561
Current avg r:0.3127 Best avg r: 0.3741
16:40:11,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:37,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:03,863 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1996
en_de Dev loss: 0.9381 r:0.1749
en_zh Dev loss: 0.7525 r:0.4624
Current avg r:0.3186 Best avg r: 0.3741
16:42:21,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:47,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:13,597 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1778
en_de Dev loss: 0.9387 r:0.1694
en_zh Dev loss: 0.8353 r:0.4636
Current avg r:0.3165 Best avg r: 0.3741
16:44:30,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:56,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:22,891 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1852
en_de Dev loss: 0.9481 r:0.1523
en_zh Dev loss: 0.8384 r:0.4627
Current avg r:0.3075 Best avg r: 0.3741
16:46:39,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:06,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:32,158 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1743
en_de Dev loss: 0.9524 r:0.1549
en_zh Dev loss: 0.8182 r:0.4630
Current avg r:0.3090 Best avg r: 0.3741
16:48:49,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:15,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:41,538 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1693
en_de Dev loss: 0.9466 r:0.1496
en_zh Dev loss: 0.8265 r:0.4614
Current avg r:0.3055 Best avg r: 0.3741
16:50:58,545 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:24,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:50,805 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1752
en_de Dev loss: 0.9500 r:0.1700
en_zh Dev loss: 0.8010 r:0.4634
Current avg r:0.3167 Best avg r: 0.3741
16:53:08,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:34,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:00,259 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1847
en_de Dev loss: 0.9434 r:0.1744
en_zh Dev loss: 0.8250 r:0.4535
Current avg r:0.3139 Best avg r: 0.3741
16:55:17,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:43,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:09,476 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1792
en_de Dev loss: 0.9413 r:0.1619
en_zh Dev loss: 0.7753 r:0.4526
Current avg r:0.3073 Best avg r: 0.3741
16:57:26,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:52,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:18,763 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1766
en_de Dev loss: 0.9573 r:0.1803
en_zh Dev loss: 0.7925 r:0.4655
Current avg r:0.3229 Best avg r: 0.3741
16:59:35,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:02,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:28,218 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1813
en_de Dev loss: 0.9534 r:0.1733
en_zh Dev loss: 0.7841 r:0.4762
Current avg r:0.3248 Best avg r: 0.3741
17:01:45,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:11,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:37,625 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1818
en_de Dev loss: 0.9396 r:0.1608
en_zh Dev loss: 0.8232 r:0.4669
Current avg r:0.3138 Best avg r: 0.3741
17:03:54,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:20,906 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:46,998 root INFO Epoch 12 Global steps: 38200 Train loss: 0.2005
en_de Dev loss: 0.9446 r:0.1697
en_zh Dev loss: 0.7797 r:0.4729
Current avg r:0.3213 Best avg r: 0.3741
17:06:04,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:30,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:56,256 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1779
en_de Dev loss: 0.9474 r:0.1650
en_zh Dev loss: 0.8087 r:0.4696
Current avg r:0.3173 Best avg r: 0.3741
17:08:13,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:39,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:05,712 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1999
en_de Dev loss: 0.9369 r:0.1579
en_zh Dev loss: 0.7512 r:0.4682
Current avg r:0.3130 Best avg r: 0.3741
17:10:22,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:49,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:15,183 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1732
en_de Dev loss: 0.9489 r:0.1582
en_zh Dev loss: 0.7805 r:0.4613
Current avg r:0.3098 Best avg r: 0.3741
17:12:32,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:58,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:24,641 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1756
en_de Dev loss: 0.9472 r:0.1815
en_zh Dev loss: 0.8376 r:0.4622
Current avg r:0.3218 Best avg r: 0.3741
17:14:42,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:08,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:34,465 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1678
en_de Dev loss: 0.9399 r:0.1692
en_zh Dev loss: 0.8031 r:0.4620
Current avg r:0.3156 Best avg r: 0.3741
17:16:51,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:17,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:43,777 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1440
en_de Dev loss: 0.9426 r:0.1702
en_zh Dev loss: 0.7901 r:0.4641
Current avg r:0.3171 Best avg r: 0.3741
17:19:00,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:27,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:53,141 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1778
en_de Dev loss: 0.9609 r:0.1574
en_zh Dev loss: 0.8273 r:0.4603
Current avg r:0.3088 Best avg r: 0.3741
17:21:10,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:36,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:02,377 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1690
en_de Dev loss: 0.9674 r:0.1588
en_zh Dev loss: 0.8082 r:0.4573
Current avg r:0.3081 Best avg r: 0.3741
17:23:19,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:45,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:11,782 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1699
en_de Dev loss: 0.9710 r:0.1608
en_zh Dev loss: 0.7888 r:0.4664
Current avg r:0.3136 Best avg r: 0.3741
17:25:28,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:55,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:21,129 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1433
en_de Dev loss: 0.9744 r:0.1301
en_zh Dev loss: 0.8286 r:0.4613
Current avg r:0.2957 Best avg r: 0.3741
17:27:38,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:04,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:30,405 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1636
en_de Dev loss: 0.9653 r:0.1464
en_zh Dev loss: 0.7841 r:0.4706
Current avg r:0.3085 Best avg r: 0.3741
17:29:47,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:13,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:39,865 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1608
en_de Dev loss: 0.9641 r:0.1538
en_zh Dev loss: 0.7820 r:0.4691
Current avg r:0.3114 Best avg r: 0.3741
17:31:56,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:23,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:49,164 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1566
en_de Dev loss: 0.9975 r:0.1455
en_zh Dev loss: 0.8581 r:0.4723
Current avg r:0.3089 Best avg r: 0.3741
17:34:06,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:32,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:58,361 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1517
en_de Dev loss: 0.9880 r:0.1457
en_zh Dev loss: 0.7788 r:0.4732
Current avg r:0.3095 Best avg r: 0.3741
17:36:15,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:41,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:07,856 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1532
en_de Dev loss: 1.0192 r:0.1165
en_zh Dev loss: 0.8929 r:0.4567
Current avg r:0.2866 Best avg r: 0.3741
17:38:24,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:50,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:17,81 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1649
en_de Dev loss: 1.0061 r:0.1503
en_zh Dev loss: 0.7827 r:0.4749
Current avg r:0.3126 Best avg r: 0.3741
17:40:34,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:00,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:26,373 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1571
en_de Dev loss: 0.9812 r:0.1606
en_zh Dev loss: 0.7812 r:0.4734
Current avg r:0.3170 Best avg r: 0.3741
17:42:43,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:09,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:35,702 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1416
en_de Dev loss: 0.9751 r:0.1460
en_zh Dev loss: 0.7591 r:0.4603
Current avg r:0.3032 Best avg r: 0.3741
17:44:52,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:18,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:45,62 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1675
en_de Dev loss: 0.9800 r:0.1455
en_zh Dev loss: 0.8463 r:0.4463
Current avg r:0.2959 Best avg r: 0.3741
17:47:02,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:28,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:54,746 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1390
en_de Dev loss: 0.9895 r:0.1593
en_zh Dev loss: 0.8084 r:0.4608
Current avg r:0.3100 Best avg r: 0.3741
17:49:11,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:37,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:04,83 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1444
en_de Dev loss: 0.9931 r:0.1547
en_zh Dev loss: 0.8196 r:0.4562
Current avg r:0.3055 Best avg r: 0.3741
17:51:21,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:47,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:13,417 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1356
en_de Dev loss: 0.9558 r:0.1423
en_zh Dev loss: 0.8093 r:0.4580
Current avg r:0.3002 Best avg r: 0.3741
17:53:30,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:56,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:22,757 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1308
en_de Dev loss: 0.9895 r:0.1246
en_zh Dev loss: 0.8054 r:0.4572
Current avg r:0.2909 Best avg r: 0.3741
17:55:39,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:05,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:32,117 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1385
en_de Dev loss: 0.9643 r:0.1592
en_zh Dev loss: 0.7956 r:0.4674
Current avg r:0.3133 Best avg r: 0.3741
17:57:49,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:15,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:41,419 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1477
en_de Dev loss: 0.9731 r:0.1567
en_zh Dev loss: 0.8396 r:0.4566
Current avg r:0.3066 Best avg r: 0.3741
17:59:58,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:24,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:50,886 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1383
en_de Dev loss: 0.9513 r:0.1795
en_zh Dev loss: 0.8400 r:0.4596
Current avg r:0.3196 Best avg r: 0.3741
18:02:08,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:34,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:00,428 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1367
en_de Dev loss: 0.9710 r:0.1528
en_zh Dev loss: 0.8507 r:0.4543
Current avg r:0.3035 Best avg r: 0.3741
18:04:17,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:43,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:09,908 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1412
en_de Dev loss: 0.9973 r:0.1497
en_zh Dev loss: 0.8456 r:0.4486
Current avg r:0.2992 Best avg r: 0.3741
18:06:26,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:53,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:19,230 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1434
en_de Dev loss: 0.9638 r:0.1636
en_zh Dev loss: 0.7682 r:0.4621
Current avg r:0.3129 Best avg r: 0.3741
18:08:36,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:02,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:28,507 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1523
en_de Dev loss: 0.9695 r:0.1247
en_zh Dev loss: 0.8047 r:0.4562
Current avg r:0.2905 Best avg r: 0.3741
18:10:45,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:11,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:37,719 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1509
en_de Dev loss: 0.9643 r:0.1363
en_zh Dev loss: 0.7882 r:0.4555
Current avg r:0.2959 Best avg r: 0.3741
18:12:54,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:20,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:47,48 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1445
en_de Dev loss: 0.9745 r:0.1448
en_zh Dev loss: 0.8083 r:0.4571
Current avg r:0.3010 Best avg r: 0.3741
18:15:04,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:15:30,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:56,504 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1511
en_de Dev loss: 0.9607 r:0.1671
en_zh Dev loss: 0.8174 r:0.4570
Current avg r:0.3121 Best avg r: 0.3741
18:17:13,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:39,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:06,67 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1562
en_de Dev loss: 0.9548 r:0.1332
en_zh Dev loss: 0.8176 r:0.4541
Current avg r:0.2937 Best avg r: 0.3741
18:19:23,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:49,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:15,864 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1278
en_de Dev loss: 0.9555 r:0.1454
en_zh Dev loss: 0.7897 r:0.4557
Current avg r:0.3005 Best avg r: 0.3741
18:21:33,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:59,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:25,274 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1348
en_de Dev loss: 0.9725 r:0.1430
en_zh Dev loss: 0.7948 r:0.4646
Current avg r:0.3038 Best avg r: 0.3741
18:23:42,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:24:08,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:34,689 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1302
en_de Dev loss: 0.9781 r:0.1286
en_zh Dev loss: 0.8130 r:0.4639
Current avg r:0.2962 Best avg r: 0.3741
18:25:51,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:17,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:43,933 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1260
en_de Dev loss: 0.9837 r:0.1172
en_zh Dev loss: 0.8262 r:0.4603
Current avg r:0.2888 Best avg r: 0.3741
18:28:00,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:27,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:53,280 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1487
en_de Dev loss: 0.9935 r:0.1133
en_zh Dev loss: 0.8288 r:0.4658
Current avg r:0.2896 Best avg r: 0.3741
18:30:10,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:36,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:02,568 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1285
en_de Dev loss: 0.9983 r:0.1365
en_zh Dev loss: 0.8034 r:0.4657
Current avg r:0.3011 Best avg r: 0.3741
18:32:19,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:45,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:11,866 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1303
en_de Dev loss: 0.9716 r:0.1234
en_zh Dev loss: 0.7833 r:0.4634
Current avg r:0.2934 Best avg r: 0.3741
18:34:28,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:55,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:21,252 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1267
en_de Dev loss: 0.9742 r:0.1471
en_zh Dev loss: 0.7911 r:0.4711
Current avg r:0.3091 Best avg r: 0.3741
18:36:38,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:37:04,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:30,705 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1346
en_de Dev loss: 0.9952 r:0.1324
en_zh Dev loss: 0.8569 r:0.4599
Current avg r:0.2962 Best avg r: 0.3741
18:38:47,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:14,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:39:40,163 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1415
en_de Dev loss: 0.9691 r:0.1505
en_zh Dev loss: 0.7859 r:0.4549
Current avg r:0.3027 Best avg r: 0.3741
18:40:57,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:23,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:49,645 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1373
en_de Dev loss: 0.9439 r:0.1572
en_zh Dev loss: 0.7287 r:0.4682
Current avg r:0.3127 Best avg r: 0.3741
18:43:06,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:32,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:59,106 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1187
en_de Dev loss: 0.9534 r:0.1571
en_zh Dev loss: 0.7590 r:0.4668
Current avg r:0.3120 Best avg r: 0.3741
18:45:16,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:42,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:08,618 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1261
en_de Dev loss: 0.9455 r:0.1666
en_zh Dev loss: 0.7769 r:0.4644
Current avg r:0.3155 Best avg r: 0.3741
18:47:25,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:51,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:17,868 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1350
en_de Dev loss: 0.9943 r:0.1427
en_zh Dev loss: 0.8322 r:0.4677
Current avg r:0.3052 Best avg r: 0.3741
18:49:34,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:01,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:27,135 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1395
en_de Dev loss: 0.9545 r:0.1599
en_zh Dev loss: 0.7903 r:0.4622
Current avg r:0.3111 Best avg r: 0.3741
18:51:44,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:10,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:36,859 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1261
en_de Dev loss: 0.9690 r:0.1458
en_zh Dev loss: 0.7375 r:0.4756
Current avg r:0.3107 Best avg r: 0.3741
18:53:54,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:20,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:46,302 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1167
en_de Dev loss: 0.9829 r:0.1431
en_zh Dev loss: 0.8291 r:0.4667
Current avg r:0.3049 Best avg r: 0.3741
18:56:03,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:29,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:56:55,809 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1252
en_de Dev loss: 0.9787 r:0.1493
en_zh Dev loss: 0.8463 r:0.4682
Current avg r:0.3088 Best avg r: 0.3741
18:58:13,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:39,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:05,264 root INFO Epoch 16 Global steps: 48800 Train loss: 0.1202
en_de Dev loss: 0.9940 r:0.1193
en_zh Dev loss: 0.8740 r:0.4645
Current avg r:0.2919 Best avg r: 0.3741
19:00:22,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:48,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:14,748 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1154
en_de Dev loss: 0.9962 r:0.1262
en_zh Dev loss: 0.8297 r:0.4666
Current avg r:0.2964 Best avg r: 0.3741
19:02:31,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:58,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:24,160 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1366
en_de Dev loss: 0.9780 r:0.1326
en_zh Dev loss: 0.8130 r:0.4623
Current avg r:0.2975 Best avg r: 0.3741
19:04:41,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:07,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:33,522 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1128
en_de Dev loss: 1.0182 r:0.1368
en_zh Dev loss: 0.8319 r:0.4636
Current avg r:0.3002 Best avg r: 0.3741
19:06:50,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:16,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:42,949 root INFO Epoch 16 Global steps: 49600 Train loss: 0.1133
en_de Dev loss: 0.9948 r:0.1432
en_zh Dev loss: 0.7774 r:0.4658
Current avg r:0.3045 Best avg r: 0.3741
19:08:59,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:26,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:52,114 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1185
en_de Dev loss: 1.0029 r:0.1474
en_zh Dev loss: 0.8125 r:0.4636
Current avg r:0.3055 Best avg r: 0.3741
19:11:09,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:35,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:12:01,352 root INFO Epoch 16 Global steps: 50000 Train loss: 0.1229
en_de Dev loss: 0.9885 r:0.1168
en_zh Dev loss: 0.7491 r:0.4722
Current avg r:0.2945 Best avg r: 0.3741
19:13:18,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:44,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:10,642 root INFO Epoch 16 Global steps: 50200 Train loss: 0.1187
en_de Dev loss: 0.9752 r:0.1290
en_zh Dev loss: 0.7488 r:0.4742
Current avg r:0.3016 Best avg r: 0.3741
19:15:27,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:53,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:19,933 root INFO Epoch 16 Global steps: 50400 Train loss: 0.1173
en_de Dev loss: 1.0028 r:0.1373
en_zh Dev loss: 0.7938 r:0.4786
Current avg r:0.3080 Best avg r: 0.3741
19:17:37,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:03,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:29,381 root INFO Epoch 16 Global steps: 50600 Train loss: 0.1187
en_de Dev loss: 1.0091 r:0.1363
en_zh Dev loss: 0.7767 r:0.4750
Current avg r:0.3056 Best avg r: 0.3741
19:19:46,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:12,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:38,859 root INFO Epoch 16 Global steps: 50800 Train loss: 0.1124
en_de Dev loss: 1.0045 r:0.1255
en_zh Dev loss: 0.8873 r:0.4688
Current avg r:0.2971 Best avg r: 0.3741
19:21:56,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:22,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:48,262 root INFO Epoch 16 Global steps: 51000 Train loss: 0.1139
en_de Dev loss: 1.0042 r:0.1473
en_zh Dev loss: 0.8416 r:0.4804
Current avg r:0.3138 Best avg r: 0.3741
19:24:05,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:31,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:58,7 root INFO Epoch 17 Global steps: 51200 Train loss: 0.1056
en_de Dev loss: 0.9944 r:0.1476
en_zh Dev loss: 0.7819 r:0.4831
Current avg r:0.3153 Best avg r: 0.3741
19:26:15,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:41,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:07,535 root INFO Epoch 17 Global steps: 51400 Train loss: 0.1085
en_de Dev loss: 0.9963 r:0.1321
en_zh Dev loss: 0.8293 r:0.4816
Current avg r:0.3068 Best avg r: 0.3741
19:28:24,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:50,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:17,28 root INFO Epoch 17 Global steps: 51600 Train loss: 0.1055
en_de Dev loss: 1.0392 r:0.1517
en_zh Dev loss: 0.8198 r:0.4874
Current avg r:0.3195 Best avg r: 0.3741
