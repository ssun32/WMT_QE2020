14:34:00,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:34:39,362 root INFO 
id:en_zh cur r: 0.0797 best r: 0.0797
14:34:39,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:35:05,257 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:35:05,262 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:35:31,210 root INFO Epoch 0 Global steps: 200 Train loss: 0.8547
en_de Dev loss: 0.8923 r:0.0296
en_zh Dev loss: 0.8070 r:0.1493
Current avg r:0.0894 Best avg r: 0.0894
14:36:48,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:27,179 root INFO 
id:en_zh cur r: 0.1613 best r: 0.1613
14:37:27,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:37:53,132 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:37:53,141 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:38:19,134 root INFO Epoch 0 Global steps: 400 Train loss: 0.7642
en_de Dev loss: 0.8838 r:0.0642
en_zh Dev loss: 0.8036 r:0.2046
Current avg r:0.1344 Best avg r: 0.1344
14:39:36,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:40:15,203 root INFO 
id:en_zh cur r: 0.1972 best r: 0.1972
14:40:15,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:41,207 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:40:41,212 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:41:07,193 root INFO Epoch 0 Global steps: 600 Train loss: 0.8154
en_de Dev loss: 0.8842 r:0.0748
en_zh Dev loss: 0.8002 r:0.2407
Current avg r:0.1578 Best avg r: 0.1578
14:42:24,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:43:03,313 root INFO 
id:en_zh cur r: 0.2224 best r: 0.2224
14:43:03,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:29,260 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:43:29,265 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:43:55,278 root INFO Epoch 0 Global steps: 800 Train loss: 0.6681
en_de Dev loss: 0.8846 r:0.0796
en_zh Dev loss: 0.8059 r:0.2547
Current avg r:0.1671 Best avg r: 0.1671
14:45:12,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:38,494 root INFO 
id:en_de cur r: 0.0139 best r: 0.0139
14:46:04,485 root INFO 
id:en_zh cur r: 0.2455 best r: 0.2455
14:46:04,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:30,484 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7067
en_de Dev loss: 0.8849 r:0.0733
en_zh Dev loss: 0.8091 r:0.2249
Current avg r:0.1491 Best avg r: 0.1671
14:47:47,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:26,819 root INFO 
id:en_zh cur r: 0.2831 best r: 0.2831
14:48:26,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:52,806 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:48:52,811 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:49:18,799 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7048
en_de Dev loss: 0.8793 r:0.1282
en_zh Dev loss: 0.7956 r:0.2944
Current avg r:0.2113 Best avg r: 0.2113
14:50:35,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:14,760 root INFO 
id:en_zh cur r: 0.3149 best r: 0.3149
14:51:14,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:40,734 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:51:40,741 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:52:06,767 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7742
en_de Dev loss: 0.8762 r:0.1476
en_zh Dev loss: 0.7872 r:0.3323
Current avg r:0.2400 Best avg r: 0.2400
14:53:23,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:49,905 root INFO 
id:en_de cur r: 0.1538 best r: 0.1538
14:54:15,933 root INFO 
id:en_zh cur r: 0.3244 best r: 0.3244
14:54:15,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:41,972 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:54:41,979 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:55:08,5 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7849
en_de Dev loss: 0.8859 r:0.1409
en_zh Dev loss: 0.7848 r:0.3397
Current avg r:0.2403 Best avg r: 0.2403
14:56:25,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:51,267 root INFO 
id:en_de cur r: 0.1665 best r: 0.1665
14:57:17,237 root INFO 
id:en_zh cur r: 0.3567 best r: 0.3567
14:57:17,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:43,211 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:57:43,218 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:58:09,211 root INFO Epoch 0 Global steps: 1800 Train loss: 0.8167
en_de Dev loss: 0.8784 r:0.1132
en_zh Dev loss: 0.7664 r:0.3741
Current avg r:0.2437 Best avg r: 0.2437
14:59:26,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:52,326 root INFO 
id:en_de cur r: 0.1676 best r: 0.1676
15:00:18,292 root INFO 
id:en_zh cur r: 0.3749 best r: 0.3749
15:00:18,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:44,289 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:00:44,296 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:01:10,271 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7502
en_de Dev loss: 0.8653 r:0.1701
en_zh Dev loss: 0.7483 r:0.3944
Current avg r:0.2823 Best avg r: 0.2823
15:02:27,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:53,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:19,216 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:03:19,222 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:03:45,227 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7786
en_de Dev loss: 0.8665 r:0.1877
en_zh Dev loss: 0.7495 r:0.4007
Current avg r:0.2942 Best avg r: 0.2942
15:05:02,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:41,246 root INFO 
id:en_zh cur r: 0.3906 best r: 0.3906
15:05:41,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:07,228 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:06:07,247 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:06:33,262 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6270
en_de Dev loss: 0.8955 r:0.1930
en_zh Dev loss: 0.7635 r:0.4103
Current avg r:0.3016 Best avg r: 0.3016
15:07:50,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:16,487 root INFO 
id:en_de cur r: 0.1738 best r: 0.1738
15:08:42,433 root INFO 
id:en_zh cur r: 0.4010 best r: 0.4010
15:08:42,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:08,375 root INFO Epoch 0 Global steps: 2600 Train loss: 0.7108
en_de Dev loss: 0.8876 r:0.1639
en_zh Dev loss: 0.7162 r:0.4068
Current avg r:0.2854 Best avg r: 0.3016
15:10:25,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:51,392 root INFO 
id:en_de cur r: 0.1772 best r: 0.1772
15:11:04,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:30,361 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7041
en_de Dev loss: 0.8785 r:0.1652
en_zh Dev loss: 0.7233 r:0.4064
Current avg r:0.2858 Best avg r: 0.3016
15:12:47,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:13,448 root INFO 
id:en_de cur r: 0.1793 best r: 0.1793
15:13:26,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:52,386 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:13:52,391 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:14:18,401 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7079
en_de Dev loss: 0.8765 r:0.1974
en_zh Dev loss: 0.7230 r:0.4154
Current avg r:0.3064 Best avg r: 0.3064
15:15:35,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:01,884 root INFO 
id:en_de cur r: 0.2042 best r: 0.2042
15:16:27,870 root INFO 
id:en_zh cur r: 0.4030 best r: 0.4030
15:16:27,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:53,822 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:16:53,828 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:17:19,792 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6119
en_de Dev loss: 0.8517 r:0.2123
en_zh Dev loss: 0.6980 r:0.4194
Current avg r:0.3159 Best avg r: 0.3159
15:18:36,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:02,815 root INFO 
id:en_de cur r: 0.2250 best r: 0.2250
15:19:31,571 root INFO 
id:en_zh cur r: 0.4280 best r: 0.4280
15:19:31,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:57,492 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:19:57,498 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:20:23,469 root INFO Epoch 1 Global steps: 3400 Train loss: 0.7613
en_de Dev loss: 0.8579 r:0.2136
en_zh Dev loss: 0.7051 r:0.4269
Current avg r:0.3202 Best avg r: 0.3202
15:21:40,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:19,529 root INFO 
id:en_zh cur r: 0.4500 best r: 0.4500
15:22:19,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:45,553 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:22:45,558 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:23:11,599 root INFO Epoch 1 Global steps: 3600 Train loss: 0.6900
en_de Dev loss: 0.8524 r:0.2060
en_zh Dev loss: 0.6619 r:0.4478
Current avg r:0.3269 Best avg r: 0.3269
15:24:28,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:54,650 root INFO 
id:en_de cur r: 0.2346 best r: 0.2346
15:25:07,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:33,611 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6257
en_de Dev loss: 0.8562 r:0.2104
en_zh Dev loss: 0.7182 r:0.4388
Current avg r:0.3246 Best avg r: 0.3269
15:26:50,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:16,657 root INFO 
id:en_de cur r: 0.2357 best r: 0.2357
15:27:42,637 root INFO 
id:en_zh cur r: 0.4691 best r: 0.4691
15:27:42,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:08,629 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:28:08,635 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:28:34,638 root INFO Epoch 1 Global steps: 4000 Train loss: 0.6359
en_de Dev loss: 0.8683 r:0.1940
en_zh Dev loss: 0.6597 r:0.4654
Current avg r:0.3297 Best avg r: 0.3297
15:29:51,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:17,772 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:43,748 root INFO Epoch 1 Global steps: 4200 Train loss: 0.6140
en_de Dev loss: 0.8521 r:0.1996
en_zh Dev loss: 0.6750 r:0.4563
Current avg r:0.3279 Best avg r: 0.3297
15:32:00,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:26,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:52,643 root INFO Epoch 1 Global steps: 4400 Train loss: 0.6757
en_de Dev loss: 0.8742 r:0.1749
en_zh Dev loss: 0.7161 r:0.4248
Current avg r:0.2999 Best avg r: 0.3297
15:34:09,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:35,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:01,549 root INFO Epoch 1 Global steps: 4600 Train loss: 0.6867
en_de Dev loss: 0.8569 r:0.1859
en_zh Dev loss: 0.6650 r:0.4510
Current avg r:0.3184 Best avg r: 0.3297
15:36:18,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:44,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:37:10,619 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:37:10,625 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:37:36,637 root INFO Epoch 1 Global steps: 4800 Train loss: 0.5820
en_de Dev loss: 0.8776 r:0.2167
en_zh Dev loss: 0.7344 r:0.4467
Current avg r:0.3317 Best avg r: 0.3317
15:38:53,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:19,956 root INFO 
id:en_de cur r: 0.2373 best r: 0.2373
15:39:45,932 root INFO 
id:en_zh cur r: 0.4747 best r: 0.4747
15:39:45,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:11,922 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:40:11,928 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:40:37,903 root INFO Epoch 1 Global steps: 5000 Train loss: 0.6538
en_de Dev loss: 0.8496 r:0.2269
en_zh Dev loss: 0.6563 r:0.4697
Current avg r:0.3483 Best avg r: 0.3483
15:41:54,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:20,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:46,945 root INFO Epoch 1 Global steps: 5200 Train loss: 0.6488
en_de Dev loss: 0.8570 r:0.2211
en_zh Dev loss: 0.6667 r:0.4633
Current avg r:0.3422 Best avg r: 0.3483
15:44:04,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:43,160 root INFO 
id:en_zh cur r: 0.4784 best r: 0.4784
15:44:43,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:09,124 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:45:09,130 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:45:35,102 root INFO Epoch 1 Global steps: 5400 Train loss: 0.5697
en_de Dev loss: 0.8421 r:0.2396
en_zh Dev loss: 0.6422 r:0.4745
Current avg r:0.3570 Best avg r: 0.3570
15:46:52,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:18,477 root INFO 
id:en_de cur r: 0.2446 best r: 0.2446
15:47:31,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:57,402 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:47:57,408 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:48:23,413 root INFO Epoch 1 Global steps: 5600 Train loss: 0.6498
en_de Dev loss: 0.8412 r:0.2520
en_zh Dev loss: 0.6745 r:0.4635
Current avg r:0.3578 Best avg r: 0.3578
15:49:40,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:06,713 root INFO 
id:en_de cur r: 0.2525 best r: 0.2525
15:50:32,703 root INFO 
id:en_zh cur r: 0.4911 best r: 0.4911
15:50:32,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:58,679 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:50:58,686 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:51:24,663 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6754
en_de Dev loss: 0.8320 r:0.2511
en_zh Dev loss: 0.6300 r:0.4823
Current avg r:0.3667 Best avg r: 0.3667
15:52:41,891 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:07,889 root INFO 
id:en_de cur r: 0.2659 best r: 0.2659
15:53:20,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:46,832 root INFO Epoch 1 Global steps: 6000 Train loss: 0.6245
en_de Dev loss: 0.8404 r:0.2622
en_zh Dev loss: 0.6788 r:0.4650
Current avg r:0.3636 Best avg r: 0.3667
15:55:04,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:30,336 root INFO 
id:en_de cur r: 0.2684 best r: 0.2684
15:55:43,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:09,341 root INFO Epoch 2 Global steps: 6200 Train loss: 0.5980
en_de Dev loss: 0.8454 r:0.2590
en_zh Dev loss: 0.6831 r:0.4721
Current avg r:0.3655 Best avg r: 0.3667
15:57:27,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:53,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:19,735 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:58:19,741 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:58:45,741 root INFO Epoch 2 Global steps: 6400 Train loss: 0.5292
en_de Dev loss: 0.8290 r:0.2580
en_zh Dev loss: 0.6435 r:0.4812
Current avg r:0.3696 Best avg r: 0.3696
16:00:02,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:28,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:54,678 root INFO Epoch 2 Global steps: 6600 Train loss: 0.6050
en_de Dev loss: 0.8517 r:0.2451
en_zh Dev loss: 0.7255 r:0.4603
Current avg r:0.3527 Best avg r: 0.3696
16:02:11,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:02:37,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:03,690 root INFO Epoch 2 Global steps: 6800 Train loss: 0.6206
en_de Dev loss: 0.8481 r:0.2523
en_zh Dev loss: 0.6572 r:0.4650
Current avg r:0.3587 Best avg r: 0.3696
16:04:20,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:46,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:12,957 root INFO Epoch 2 Global steps: 7000 Train loss: 0.6275
en_de Dev loss: 0.8672 r:0.2345
en_zh Dev loss: 0.7828 r:0.4559
Current avg r:0.3452 Best avg r: 0.3696
16:06:30,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:56,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:21,972 root INFO Epoch 2 Global steps: 7200 Train loss: 0.6848
en_de Dev loss: 0.8450 r:0.2381
en_zh Dev loss: 0.6559 r:0.4783
Current avg r:0.3582 Best avg r: 0.3696
16:08:39,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:05,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:31,60 root INFO Epoch 2 Global steps: 7400 Train loss: 0.5966
en_de Dev loss: 0.8402 r:0.2409
en_zh Dev loss: 0.6613 r:0.4837
Current avg r:0.3623 Best avg r: 0.3696
16:10:48,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:27,36 root INFO 
id:en_zh cur r: 0.5029 best r: 0.5029
16:11:27,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:53,33 root INFO Epoch 2 Global steps: 7600 Train loss: 0.5470
en_de Dev loss: 0.8524 r:0.2352
en_zh Dev loss: 0.6461 r:0.4949
Current avg r:0.3651 Best avg r: 0.3696
16:13:10,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:36,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:02,303 root INFO Epoch 2 Global steps: 7800 Train loss: 0.5381
en_de Dev loss: 0.8421 r:0.2462
en_zh Dev loss: 0.6897 r:0.4868
Current avg r:0.3665 Best avg r: 0.3696
16:15:19,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:45,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:11,688 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
16:16:11,697 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:16:37,705 root INFO Epoch 2 Global steps: 8000 Train loss: 0.5317
en_de Dev loss: 0.8389 r:0.2626
en_zh Dev loss: 0.6901 r:0.4783
Current avg r:0.3704 Best avg r: 0.3704
16:17:54,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:20,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:46,655 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
16:18:46,662 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:19:12,656 root INFO Epoch 2 Global steps: 8200 Train loss: 0.5402
en_de Dev loss: 0.8405 r:0.2674
en_zh Dev loss: 0.6788 r:0.4856
Current avg r:0.3765 Best avg r: 0.3765
16:20:31,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:57,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:23,160 root INFO Epoch 2 Global steps: 8400 Train loss: 0.6633
en_de Dev loss: 0.8359 r:0.2694
en_zh Dev loss: 0.6697 r:0.4832
Current avg r:0.3763 Best avg r: 0.3765
16:22:40,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:06,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:32,280 root INFO Epoch 2 Global steps: 8600 Train loss: 0.5916
en_de Dev loss: 0.8302 r:0.2637
en_zh Dev loss: 0.6568 r:0.4884
Current avg r:0.3761 Best avg r: 0.3765
16:24:49,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:15,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:41,436 root INFO Epoch 2 Global steps: 8800 Train loss: 0.5936
en_de Dev loss: 0.8442 r:0.2604
en_zh Dev loss: 0.6742 r:0.4770
Current avg r:0.3687 Best avg r: 0.3765
16:27:00,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:26,77 root INFO 
id:en_de cur r: 0.2700 best r: 0.2700
16:27:39,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:05,36 root INFO Epoch 2 Global steps: 9000 Train loss: 0.5873
en_de Dev loss: 0.8330 r:0.2674
en_zh Dev loss: 0.6908 r:0.4801
Current avg r:0.3737 Best avg r: 0.3765
16:29:22,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:48,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:14,444 root INFO Epoch 3 Global steps: 9200 Train loss: 0.5139
en_de Dev loss: 0.8532 r:0.2527
en_zh Dev loss: 0.7648 r:0.4725
Current avg r:0.3626 Best avg r: 0.3765
16:31:31,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:57,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:32:23,457 root INFO Epoch 3 Global steps: 9400 Train loss: 0.4520
en_de Dev loss: 0.8512 r:0.2381
en_zh Dev loss: 0.7080 r:0.4742
Current avg r:0.3561 Best avg r: 0.3765
16:33:40,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:06,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:32,487 root INFO Epoch 3 Global steps: 9600 Train loss: 0.5786
en_de Dev loss: 0.8316 r:0.2515
en_zh Dev loss: 0.6553 r:0.4876
Current avg r:0.3695 Best avg r: 0.3765
16:35:49,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:15,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:41,419 root INFO Epoch 3 Global steps: 9800 Train loss: 0.5692
en_de Dev loss: 0.8603 r:0.2438
en_zh Dev loss: 0.7432 r:0.4768
Current avg r:0.3603 Best avg r: 0.3765
16:37:58,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:24,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:50,405 root INFO Epoch 3 Global steps: 10000 Train loss: 0.5268
en_de Dev loss: 0.8329 r:0.2479
en_zh Dev loss: 0.6698 r:0.4825
Current avg r:0.3652 Best avg r: 0.3765
16:40:08,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:34,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:00,683 root INFO Epoch 3 Global steps: 10200 Train loss: 0.5731
en_de Dev loss: 0.8446 r:0.2403
en_zh Dev loss: 0.6754 r:0.4804
Current avg r:0.3603 Best avg r: 0.3765
16:42:17,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:43,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:09,610 root INFO Epoch 3 Global steps: 10400 Train loss: 0.5491
en_de Dev loss: 0.8690 r:0.2435
en_zh Dev loss: 0.7557 r:0.4665
Current avg r:0.3550 Best avg r: 0.3765
16:44:27,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:53,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:19,880 root INFO Epoch 3 Global steps: 10600 Train loss: 0.5431
en_de Dev loss: 0.8408 r:0.2455
en_zh Dev loss: 0.6897 r:0.4847
Current avg r:0.3651 Best avg r: 0.3765
16:46:36,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:02,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:28,831 root INFO Epoch 3 Global steps: 10800 Train loss: 0.4935
en_de Dev loss: 0.8322 r:0.2599
en_zh Dev loss: 0.7220 r:0.4623
Current avg r:0.3611 Best avg r: 0.3765
16:48:45,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:11,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:37,764 root INFO Epoch 3 Global steps: 11000 Train loss: 0.4896
en_de Dev loss: 0.8615 r:0.2760
en_zh Dev loss: 0.8180 r:0.4477
Current avg r:0.3618 Best avg r: 0.3765
16:50:54,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:20,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:46,769 root INFO Epoch 3 Global steps: 11200 Train loss: 0.5200
en_de Dev loss: 0.8546 r:0.2700
en_zh Dev loss: 0.7413 r:0.4764
Current avg r:0.3732 Best avg r: 0.3765
16:53:03,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:29,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:55,884 root INFO Epoch 3 Global steps: 11400 Train loss: 0.5864
en_de Dev loss: 0.8334 r:0.2665
en_zh Dev loss: 0.7108 r:0.4766
Current avg r:0.3715 Best avg r: 0.3765
16:55:13,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:39,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:05,52 root INFO Epoch 3 Global steps: 11600 Train loss: 0.5761
en_de Dev loss: 0.8247 r:0.2701
en_zh Dev loss: 0.7212 r:0.4776
Current avg r:0.3738 Best avg r: 0.3765
16:57:22,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:48,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:14,26 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
16:58:14,33 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:58:40,8 root INFO Epoch 3 Global steps: 11800 Train loss: 0.4698
en_de Dev loss: 0.8272 r:0.2897
en_zh Dev loss: 0.6850 r:0.4718
Current avg r:0.3808 Best avg r: 0.3808
16:59:57,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:22,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:50,239 root INFO Epoch 3 Global steps: 12000 Train loss: 0.4649
en_de Dev loss: 0.8384 r:0.2836
en_zh Dev loss: 0.7191 r:0.4705
Current avg r:0.3771 Best avg r: 0.3808
17:02:07,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:33,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:59,699 root INFO Epoch 4 Global steps: 12200 Train loss: 0.4610
en_de Dev loss: 0.8445 r:0.2690
en_zh Dev loss: 0.7128 r:0.4756
Current avg r:0.3723 Best avg r: 0.3808
17:04:16,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:42,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:08,640 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4901
en_de Dev loss: 0.8356 r:0.2738
en_zh Dev loss: 0.7266 r:0.4715
Current avg r:0.3726 Best avg r: 0.3808
17:06:25,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:51,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:17,585 root INFO Epoch 4 Global steps: 12600 Train loss: 0.4974
en_de Dev loss: 0.8316 r:0.2692
en_zh Dev loss: 0.7330 r:0.4769
Current avg r:0.3730 Best avg r: 0.3808
17:08:34,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:00,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:26,633 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4370
en_de Dev loss: 0.8309 r:0.2578
en_zh Dev loss: 0.7365 r:0.4765
Current avg r:0.3672 Best avg r: 0.3808
17:10:43,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:09,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:35,599 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4758
en_de Dev loss: 0.8449 r:0.2542
en_zh Dev loss: 0.7777 r:0.4625
Current avg r:0.3584 Best avg r: 0.3808
17:12:52,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:18,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:44,537 root INFO Epoch 4 Global steps: 13200 Train loss: 0.5196
en_de Dev loss: 0.8448 r:0.2606
en_zh Dev loss: 0.7574 r:0.4620
Current avg r:0.3613 Best avg r: 0.3808
17:15:01,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:27,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:53,552 root INFO Epoch 4 Global steps: 13400 Train loss: 0.5038
en_de Dev loss: 0.8395 r:0.2450
en_zh Dev loss: 0.7292 r:0.4576
Current avg r:0.3513 Best avg r: 0.3808
17:17:10,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:36,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:02,530 root INFO Epoch 4 Global steps: 13600 Train loss: 0.4192
en_de Dev loss: 0.8399 r:0.2601
en_zh Dev loss: 0.7714 r:0.4503
Current avg r:0.3552 Best avg r: 0.3808
17:19:19,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:45,527 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:11,496 root INFO Epoch 4 Global steps: 13800 Train loss: 0.4249
en_de Dev loss: 0.8325 r:0.2540
en_zh Dev loss: 0.6977 r:0.4750
Current avg r:0.3645 Best avg r: 0.3808
17:21:28,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:54,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:20,562 root INFO Epoch 4 Global steps: 14000 Train loss: 0.4429
en_de Dev loss: 0.8567 r:0.2486
en_zh Dev loss: 0.7545 r:0.4507
Current avg r:0.3497 Best avg r: 0.3808
17:23:37,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:03,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:29,737 root INFO Epoch 4 Global steps: 14200 Train loss: 0.4416
en_de Dev loss: 0.8590 r:0.2529
en_zh Dev loss: 0.8046 r:0.4558
Current avg r:0.3544 Best avg r: 0.3808
17:25:46,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:12,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:38,739 root INFO Epoch 4 Global steps: 14400 Train loss: 0.4133
en_de Dev loss: 0.8440 r:0.2679
en_zh Dev loss: 0.7445 r:0.4561
Current avg r:0.3620 Best avg r: 0.3808
17:27:55,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:21,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:47,763 root INFO Epoch 4 Global steps: 14600 Train loss: 0.4233
en_de Dev loss: 0.8275 r:0.2601
en_zh Dev loss: 0.7050 r:0.4642
Current avg r:0.3622 Best avg r: 0.3808
17:30:04,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:30,810 root INFO 
id:en_de cur r: 0.2706 best r: 0.2706
17:30:43,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:09,743 root INFO Epoch 4 Global steps: 14800 Train loss: 0.4070
en_de Dev loss: 0.8460 r:0.2721
en_zh Dev loss: 0.8343 r:0.4535
Current avg r:0.3628 Best avg r: 0.3808
17:32:26,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:52,837 root INFO 
id:en_de cur r: 0.2753 best r: 0.2753
17:33:05,812 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:31,784 root INFO Epoch 4 Global steps: 15000 Train loss: 0.5083
en_de Dev loss: 0.8434 r:0.2707
en_zh Dev loss: 0.7866 r:0.4553
Current avg r:0.3630 Best avg r: 0.3808
17:34:49,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:15,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:41,224 root INFO Epoch 5 Global steps: 15200 Train loss: 0.3590
en_de Dev loss: 0.8292 r:0.2621
en_zh Dev loss: 0.7524 r:0.4580
Current avg r:0.3600 Best avg r: 0.3808
17:36:58,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:24,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:50,204 root INFO Epoch 5 Global steps: 15400 Train loss: 0.3836
en_de Dev loss: 0.8733 r:0.2492
en_zh Dev loss: 0.7778 r:0.4606
Current avg r:0.3549 Best avg r: 0.3808
17:39:07,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:33,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:59,447 root INFO Epoch 5 Global steps: 15600 Train loss: 0.3978
en_de Dev loss: 0.8347 r:0.2580
en_zh Dev loss: 0.7492 r:0.4577
Current avg r:0.3579 Best avg r: 0.3808
17:41:16,726 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:42,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:08,664 root INFO Epoch 5 Global steps: 15800 Train loss: 0.4269
en_de Dev loss: 0.8359 r:0.2525
en_zh Dev loss: 0.7234 r:0.4588
Current avg r:0.3557 Best avg r: 0.3808
17:43:25,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:51,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:17,742 root INFO Epoch 5 Global steps: 16000 Train loss: 0.3836
en_de Dev loss: 0.8434 r:0.2217
en_zh Dev loss: 0.6891 r:0.4740
Current avg r:0.3478 Best avg r: 0.3808
17:45:34,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:00,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:26,959 root INFO Epoch 5 Global steps: 16200 Train loss: 0.3805
en_de Dev loss: 0.8313 r:0.2550
en_zh Dev loss: 0.7234 r:0.4722
Current avg r:0.3636 Best avg r: 0.3808
17:47:44,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:10,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:36,132 root INFO Epoch 5 Global steps: 16400 Train loss: 0.4204
en_de Dev loss: 0.8622 r:0.2361
en_zh Dev loss: 0.7611 r:0.4714
Current avg r:0.3538 Best avg r: 0.3808
17:49:53,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:19,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:45,244 root INFO Epoch 5 Global steps: 16600 Train loss: 0.3807
en_de Dev loss: 0.8386 r:0.2459
en_zh Dev loss: 0.7599 r:0.4613
Current avg r:0.3536 Best avg r: 0.3808
17:52:02,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:28,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:54,296 root INFO Epoch 5 Global steps: 16800 Train loss: 0.3624
en_de Dev loss: 0.8666 r:0.2432
en_zh Dev loss: 0.8165 r:0.4390
Current avg r:0.3411 Best avg r: 0.3808
17:54:12,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:38,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:04,460 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3804
en_de Dev loss: 0.8678 r:0.2049
en_zh Dev loss: 0.7438 r:0.4638
Current avg r:0.3344 Best avg r: 0.3808
17:56:21,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:47,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:13,380 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3662
en_de Dev loss: 0.8830 r:0.2105
en_zh Dev loss: 0.7607 r:0.4591
Current avg r:0.3348 Best avg r: 0.3808
17:58:30,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:56,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:22,366 root INFO Epoch 5 Global steps: 17400 Train loss: 0.4371
en_de Dev loss: 0.8604 r:0.2235
en_zh Dev loss: 0.8404 r:0.4404
Current avg r:0.3319 Best avg r: 0.3808
18:00:39,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:05,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:31,287 root INFO Epoch 5 Global steps: 17600 Train loss: 0.4285
en_de Dev loss: 0.8485 r:0.2340
en_zh Dev loss: 0.7820 r:0.4376
Current avg r:0.3358 Best avg r: 0.3808
18:02:48,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:14,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:40,295 root INFO Epoch 5 Global steps: 17800 Train loss: 0.4059
en_de Dev loss: 0.8467 r:0.2357
en_zh Dev loss: 0.7671 r:0.4443
Current avg r:0.3400 Best avg r: 0.3808
18:04:57,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:23,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:49,271 root INFO Epoch 5 Global steps: 18000 Train loss: 0.4090
en_de Dev loss: 0.8426 r:0.2370
en_zh Dev loss: 0.7363 r:0.4547
Current avg r:0.3459 Best avg r: 0.3808
18:07:06,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:32,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:58,797 root INFO Epoch 6 Global steps: 18200 Train loss: 0.3282
en_de Dev loss: 0.8534 r:0.2242
en_zh Dev loss: 0.7525 r:0.4542
Current avg r:0.3392 Best avg r: 0.3808
18:09:15,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:41,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:07,961 root INFO Epoch 6 Global steps: 18400 Train loss: 0.3147
en_de Dev loss: 0.8622 r:0.2331
en_zh Dev loss: 0.7732 r:0.4575
Current avg r:0.3453 Best avg r: 0.3808
18:11:25,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:51,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:17,160 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3132
en_de Dev loss: 0.8525 r:0.2375
en_zh Dev loss: 0.7842 r:0.4479
Current avg r:0.3427 Best avg r: 0.3808
18:13:34,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:03,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:29,244 root INFO Epoch 6 Global steps: 18800 Train loss: 0.3502
en_de Dev loss: 0.8520 r:0.2357
en_zh Dev loss: 0.7858 r:0.4506
Current avg r:0.3432 Best avg r: 0.3808
18:15:46,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:12,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:38,445 root INFO Epoch 6 Global steps: 19000 Train loss: 0.3377
en_de Dev loss: 0.8510 r:0.2333
en_zh Dev loss: 0.7601 r:0.4680
Current avg r:0.3507 Best avg r: 0.3808
18:17:55,553 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:21,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:47,422 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3185
en_de Dev loss: 0.8579 r:0.2358
en_zh Dev loss: 0.7674 r:0.4594
Current avg r:0.3476 Best avg r: 0.3808
18:20:04,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:30,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:56,327 root INFO Epoch 6 Global steps: 19400 Train loss: 0.3471
en_de Dev loss: 0.8675 r:0.2123
en_zh Dev loss: 0.8027 r:0.4521
Current avg r:0.3322 Best avg r: 0.3808
18:22:13,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:39,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:08,510 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3414
en_de Dev loss: 0.8486 r:0.2259
en_zh Dev loss: 0.7745 r:0.4507
Current avg r:0.3383 Best avg r: 0.3808
18:24:28,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:24:54,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:20,285 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3397
en_de Dev loss: 0.8443 r:0.2338
en_zh Dev loss: 0.7681 r:0.4462
Current avg r:0.3400 Best avg r: 0.3808
18:26:37,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:03,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:29,286 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3399
en_de Dev loss: 0.8483 r:0.2254
en_zh Dev loss: 0.7509 r:0.4479
Current avg r:0.3367 Best avg r: 0.3808
18:28:46,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:12,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:38,251 root INFO Epoch 6 Global steps: 20200 Train loss: 0.3178
en_de Dev loss: 0.8750 r:0.2365
en_zh Dev loss: 0.8492 r:0.4392
Current avg r:0.3379 Best avg r: 0.3808
18:30:55,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:21,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:47,164 root INFO Epoch 6 Global steps: 20400 Train loss: 0.3707
en_de Dev loss: 0.8613 r:0.2251
en_zh Dev loss: 0.7487 r:0.4500
Current avg r:0.3375 Best avg r: 0.3808
18:33:04,214 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:30,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:56,77 root INFO Epoch 6 Global steps: 20600 Train loss: 0.3192
en_de Dev loss: 0.8521 r:0.2322
en_zh Dev loss: 0.7632 r:0.4527
Current avg r:0.3425 Best avg r: 0.3808
18:35:13,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:39,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:04,992 root INFO Epoch 6 Global steps: 20800 Train loss: 0.3110
en_de Dev loss: 0.8660 r:0.2207
en_zh Dev loss: 0.7820 r:0.4425
Current avg r:0.3316 Best avg r: 0.3808
18:37:22,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:37:48,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:14,310 root INFO Epoch 6 Global steps: 21000 Train loss: 0.2744
en_de Dev loss: 0.8550 r:0.2313
en_zh Dev loss: 0.7482 r:0.4611
Current avg r:0.3462 Best avg r: 0.3808
18:39:33,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:59,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:25,323 root INFO Epoch 7 Global steps: 21200 Train loss: 0.2700
en_de Dev loss: 0.9021 r:0.1960
en_zh Dev loss: 0.7691 r:0.4716
Current avg r:0.3338 Best avg r: 0.3808
18:41:42,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:08,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:34,230 root INFO Epoch 7 Global steps: 21400 Train loss: 0.2929
en_de Dev loss: 0.8807 r:0.1902
en_zh Dev loss: 0.8199 r:0.4535
Current avg r:0.3218 Best avg r: 0.3808
18:43:51,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:17,188 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:43,91 root INFO Epoch 7 Global steps: 21600 Train loss: 0.2821
en_de Dev loss: 0.8519 r:0.2410
en_zh Dev loss: 0.8022 r:0.4455
Current avg r:0.3433 Best avg r: 0.3808
18:46:00,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:26,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:52,86 root INFO Epoch 7 Global steps: 21800 Train loss: 0.3089
en_de Dev loss: 0.8736 r:0.2288
en_zh Dev loss: 0.7857 r:0.4687
Current avg r:0.3488 Best avg r: 0.3808
18:48:09,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:35,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:00,994 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2749
en_de Dev loss: 0.8612 r:0.2342
en_zh Dev loss: 0.7591 r:0.4679
Current avg r:0.3511 Best avg r: 0.3808
18:50:18,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:43,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:09,848 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2748
en_de Dev loss: 0.8664 r:0.2329
en_zh Dev loss: 0.7771 r:0.4642
Current avg r:0.3486 Best avg r: 0.3808
18:52:26,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:52,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:18,796 root INFO Epoch 7 Global steps: 22400 Train loss: 0.2794
en_de Dev loss: 0.8573 r:0.2405
en_zh Dev loss: 0.7729 r:0.4713
Current avg r:0.3559 Best avg r: 0.3808
18:54:35,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:01,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:27,764 root INFO Epoch 7 Global steps: 22600 Train loss: 0.2898
en_de Dev loss: 0.8484 r:0.2459
en_zh Dev loss: 0.7901 r:0.4654
Current avg r:0.3557 Best avg r: 0.3808
18:56:44,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:10,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:36,708 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2864
en_de Dev loss: 0.8610 r:0.2386
en_zh Dev loss: 0.7859 r:0.4730
Current avg r:0.3558 Best avg r: 0.3808
18:58:53,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:19,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:45,747 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2706
en_de Dev loss: 0.8554 r:0.2395
en_zh Dev loss: 0.7392 r:0.4796
Current avg r:0.3595 Best avg r: 0.3808
19:01:02,865 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:28,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:54,873 root INFO Epoch 7 Global steps: 23200 Train loss: 0.3008
en_de Dev loss: 0.8487 r:0.2315
en_zh Dev loss: 0.7371 r:0.4727
Current avg r:0.3521 Best avg r: 0.3808
19:03:12,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:38,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:04,666 root INFO Epoch 7 Global steps: 23400 Train loss: 0.2907
en_de Dev loss: 0.8487 r:0.2434
en_zh Dev loss: 0.7693 r:0.4655
Current avg r:0.3544 Best avg r: 0.3808
19:05:22,459 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:48,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:14,490 root INFO Epoch 7 Global steps: 23600 Train loss: 0.3080
en_de Dev loss: 0.8643 r:0.2269
en_zh Dev loss: 0.7931 r:0.4647
Current avg r:0.3458 Best avg r: 0.3808
19:07:31,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:57,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:23,811 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2568
en_de Dev loss: 0.8871 r:0.2123
en_zh Dev loss: 0.8204 r:0.4681
Current avg r:0.3402 Best avg r: 0.3808
19:09:41,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:07,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:33,18 root INFO Epoch 7 Global steps: 24000 Train loss: 0.3490
en_de Dev loss: 0.8651 r:0.2098
en_zh Dev loss: 0.7756 r:0.4629
Current avg r:0.3363 Best avg r: 0.3808
19:11:50,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:16,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:12:42,578 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2492
en_de Dev loss: 0.8631 r:0.2285
en_zh Dev loss: 0.7372 r:0.4718
Current avg r:0.3502 Best avg r: 0.3808
19:13:59,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:25,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:51,740 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2609
en_de Dev loss: 0.8613 r:0.2312
en_zh Dev loss: 0.7956 r:0.4698
Current avg r:0.3505 Best avg r: 0.3808
19:16:08,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:34,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:00,721 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2698
en_de Dev loss: 0.8581 r:0.2285
en_zh Dev loss: 0.8618 r:0.4543
Current avg r:0.3414 Best avg r: 0.3808
19:18:17,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:43,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:09,723 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2814
en_de Dev loss: 0.8898 r:0.2099
en_zh Dev loss: 0.8319 r:0.4639
Current avg r:0.3369 Best avg r: 0.3808
19:20:26,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:52,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:18,629 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2484
en_de Dev loss: 0.9003 r:0.1788
en_zh Dev loss: 0.8477 r:0.4596
Current avg r:0.3192 Best avg r: 0.3808
19:22:35,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:01,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:27,553 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2780
en_de Dev loss: 0.8797 r:0.1946
en_zh Dev loss: 0.7433 r:0.4730
Current avg r:0.3338 Best avg r: 0.3808
19:24:44,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:10,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:36,452 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2617
en_de Dev loss: 0.8784 r:0.1885
en_zh Dev loss: 0.8287 r:0.4607
Current avg r:0.3246 Best avg r: 0.3808
19:26:53,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:19,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:45,474 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2880
en_de Dev loss: 0.8924 r:0.1893
en_zh Dev loss: 0.7657 r:0.4686
Current avg r:0.3289 Best avg r: 0.3808
19:29:02,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:28,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:54,375 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2547
en_de Dev loss: 0.8882 r:0.1762
en_zh Dev loss: 0.7537 r:0.4656
Current avg r:0.3209 Best avg r: 0.3808
19:31:12,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:31:38,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:04,668 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2418
en_de Dev loss: 0.8902 r:0.1904
en_zh Dev loss: 0.7310 r:0.4843
Current avg r:0.3373 Best avg r: 0.3808
19:33:21,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:47,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:13,554 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2606
en_de Dev loss: 0.9035 r:0.1792
en_zh Dev loss: 0.8213 r:0.4702
Current avg r:0.3247 Best avg r: 0.3808
19:35:30,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:56,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:22,736 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2444
en_de Dev loss: 0.8811 r:0.1964
en_zh Dev loss: 0.7682 r:0.4762
Current avg r:0.3363 Best avg r: 0.3808
19:37:39,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:05,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:31,742 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2346
en_de Dev loss: 0.8780 r:0.1971
en_zh Dev loss: 0.7568 r:0.4753
Current avg r:0.3362 Best avg r: 0.3808
19:39:48,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:14,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:40,783 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2475
en_de Dev loss: 0.8983 r:0.2177
en_zh Dev loss: 0.8845 r:0.4460
Current avg r:0.3318 Best avg r: 0.3808
19:41:58,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:23,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:49,893 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2775
en_de Dev loss: 0.9045 r:0.1784
en_zh Dev loss: 0.7889 r:0.4625
Current avg r:0.3205 Best avg r: 0.3808
19:44:07,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:33,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:59,97 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2379
en_de Dev loss: 0.9119 r:0.1900
en_zh Dev loss: 0.7962 r:0.4679
Current avg r:0.3289 Best avg r: 0.3808
19:46:16,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:42,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:08,16 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2296
en_de Dev loss: 0.8823 r:0.1774
en_zh Dev loss: 0.7372 r:0.4687
Current avg r:0.3231 Best avg r: 0.3808
19:48:25,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:50,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:16,878 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2336
en_de Dev loss: 0.9013 r:0.2023
en_zh Dev loss: 0.7860 r:0.4682
Current avg r:0.3352 Best avg r: 0.3808
19:50:33,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:59,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:25,688 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2442
en_de Dev loss: 0.8938 r:0.1963
en_zh Dev loss: 0.7715 r:0.4638
Current avg r:0.3300 Best avg r: 0.3808
19:52:42,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:08,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:34,587 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2111
en_de Dev loss: 0.8948 r:0.2062
en_zh Dev loss: 0.7638 r:0.4755
Current avg r:0.3409 Best avg r: 0.3808
19:54:51,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:17,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:43,452 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2616
en_de Dev loss: 0.8961 r:0.1963
en_zh Dev loss: 0.7852 r:0.4687
Current avg r:0.3325 Best avg r: 0.3808
19:57:00,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:26,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:52,378 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2290
en_de Dev loss: 0.9110 r:0.1981
en_zh Dev loss: 0.7992 r:0.4688
Current avg r:0.3334 Best avg r: 0.3808
19:59:09,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:35,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:01,555 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2316
en_de Dev loss: 0.9073 r:0.1824
en_zh Dev loss: 0.8304 r:0.4642
Current avg r:0.3233 Best avg r: 0.3808
20:01:18,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:01:44,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:10,424 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2518
en_de Dev loss: 0.9020 r:0.1766
en_zh Dev loss: 0.8385 r:0.4618
Current avg r:0.3192 Best avg r: 0.3808
20:03:27,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:53,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:19,473 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2405
en_de Dev loss: 0.9060 r:0.2000
en_zh Dev loss: 0.7869 r:0.4724
Current avg r:0.3362 Best avg r: 0.3808
20:05:36,683 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:02,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:28,573 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2297
en_de Dev loss: 0.9212 r:0.1762
en_zh Dev loss: 0.8662 r:0.4618
Current avg r:0.3190 Best avg r: 0.3808
20:07:47,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:13,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:39,42 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2153
en_de Dev loss: 0.9229 r:0.1721
en_zh Dev loss: 0.8210 r:0.4651
Current avg r:0.3186 Best avg r: 0.3808
20:09:56,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:10:21,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:47,929 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2117
en_de Dev loss: 0.9839 r:0.1577
en_zh Dev loss: 0.9029 r:0.4560
Current avg r:0.3068 Best avg r: 0.3808
20:12:05,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:31,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:57,45 root INFO Epoch 9 Global steps: 29800 Train loss: 0.2200
en_de Dev loss: 0.9063 r:0.1648
en_zh Dev loss: 0.8013 r:0.4639
Current avg r:0.3144 Best avg r: 0.3808
20:14:14,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:39,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:05,901 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2215
en_de Dev loss: 0.9228 r:0.1831
en_zh Dev loss: 0.8176 r:0.4683
Current avg r:0.3257 Best avg r: 0.3808
20:16:23,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:49,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:15,196 root INFO Epoch 10 Global steps: 30200 Train loss: 0.2151
en_de Dev loss: 0.9255 r:0.2052
en_zh Dev loss: 0.7923 r:0.4744
Current avg r:0.3398 Best avg r: 0.3808
20:18:32,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:58,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:24,163 root INFO Epoch 10 Global steps: 30400 Train loss: 0.1946
en_de Dev loss: 0.9347 r:0.1859
en_zh Dev loss: 0.8199 r:0.4763
Current avg r:0.3311 Best avg r: 0.3808
20:20:41,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:07,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:33,138 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2053
en_de Dev loss: 0.9189 r:0.1938
en_zh Dev loss: 0.8362 r:0.4688
Current avg r:0.3313 Best avg r: 0.3808
20:22:50,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:16,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:42,160 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1997
en_de Dev loss: 0.9151 r:0.1771
en_zh Dev loss: 0.8132 r:0.4685
Current avg r:0.3228 Best avg r: 0.3808
20:24:59,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:25,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:51,9 root INFO Epoch 10 Global steps: 31000 Train loss: 0.2075
en_de Dev loss: 0.9000 r:0.1896
en_zh Dev loss: 0.7561 r:0.4769
Current avg r:0.3332 Best avg r: 0.3808
20:27:08,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:33,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:59,845 root INFO Epoch 10 Global steps: 31200 Train loss: 0.2046
en_de Dev loss: 0.9446 r:0.1852
en_zh Dev loss: 0.8546 r:0.4682
Current avg r:0.3267 Best avg r: 0.3808
20:29:16,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:42,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:08,743 root INFO Epoch 10 Global steps: 31400 Train loss: 0.2207
en_de Dev loss: 0.9065 r:0.1719
en_zh Dev loss: 0.7864 r:0.4635
Current avg r:0.3177 Best avg r: 0.3808
20:31:25,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:51,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:18,182 root INFO Epoch 10 Global steps: 31600 Train loss: 0.2104
en_de Dev loss: 0.9195 r:0.1812
en_zh Dev loss: 0.7647 r:0.4715
Current avg r:0.3264 Best avg r: 0.3808
20:33:36,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:02,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:34:28,456 root INFO Epoch 10 Global steps: 31800 Train loss: 0.2201
en_de Dev loss: 0.9151 r:0.1775
en_zh Dev loss: 0.8095 r:0.4610
Current avg r:0.3193 Best avg r: 0.3808
20:35:45,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:11,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:37,416 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1986
en_de Dev loss: 0.9279 r:0.1736
en_zh Dev loss: 0.7569 r:0.4770
Current avg r:0.3253 Best avg r: 0.3808
20:37:54,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:20,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:46,660 root INFO Epoch 10 Global steps: 32200 Train loss: 0.2185
en_de Dev loss: 0.9677 r:0.1724
en_zh Dev loss: 0.8884 r:0.4570
Current avg r:0.3147 Best avg r: 0.3808
20:40:03,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:31,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:57,64 root INFO Epoch 10 Global steps: 32400 Train loss: 0.2045
en_de Dev loss: 0.9289 r:0.1669
en_zh Dev loss: 0.8354 r:0.4576
Current avg r:0.3123 Best avg r: 0.3808
20:42:14,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:40,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:06,504 root INFO Epoch 10 Global steps: 32600 Train loss: 0.2154
en_de Dev loss: 0.9006 r:0.1715
en_zh Dev loss: 0.8391 r:0.4523
Current avg r:0.3119 Best avg r: 0.3808
20:44:23,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:49,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:15,602 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1887
en_de Dev loss: 0.8979 r:0.1673
en_zh Dev loss: 0.7869 r:0.4633
Current avg r:0.3153 Best avg r: 0.3808
20:46:32,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:58,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:24,470 root INFO Epoch 10 Global steps: 33000 Train loss: 0.2187
en_de Dev loss: 0.9354 r:0.1908
en_zh Dev loss: 0.8682 r:0.4545
Current avg r:0.3227 Best avg r: 0.3808
20:48:42,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:08,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:33,990 root INFO Epoch 11 Global steps: 33200 Train loss: 0.2025
en_de Dev loss: 0.9054 r:0.2054
en_zh Dev loss: 0.8079 r:0.4667
Current avg r:0.3360 Best avg r: 0.3808
20:50:51,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:16,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:42,886 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1784
en_de Dev loss: 0.9087 r:0.1826
en_zh Dev loss: 0.8046 r:0.4702
Current avg r:0.3264 Best avg r: 0.3808
20:52:59,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:25,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:51,819 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1782
en_de Dev loss: 0.9232 r:0.1992
en_zh Dev loss: 0.8564 r:0.4656
Current avg r:0.3324 Best avg r: 0.3808
20:55:08,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:34,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:00,694 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1880
en_de Dev loss: 0.8909 r:0.1880
en_zh Dev loss: 0.7554 r:0.4687
Current avg r:0.3283 Best avg r: 0.3808
20:57:17,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:44,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:10,868 root INFO Epoch 11 Global steps: 34000 Train loss: 0.2155
en_de Dev loss: 0.9070 r:0.1797
en_zh Dev loss: 0.8304 r:0.4630
Current avg r:0.3213 Best avg r: 0.3808
20:59:27,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:53,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:19,740 root INFO Epoch 11 Global steps: 34200 Train loss: 0.2064
en_de Dev loss: 0.8944 r:0.2116
en_zh Dev loss: 0.7688 r:0.4762
Current avg r:0.3439 Best avg r: 0.3808
21:01:36,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:02,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:30,26 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1993
en_de Dev loss: 0.8972 r:0.2060
en_zh Dev loss: 0.8289 r:0.4665
Current avg r:0.3363 Best avg r: 0.3808
21:03:47,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:12,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:38,911 root INFO Epoch 11 Global steps: 34600 Train loss: 0.2060
en_de Dev loss: 0.9182 r:0.1942
en_zh Dev loss: 0.8230 r:0.4627
Current avg r:0.3285 Best avg r: 0.3808
21:05:56,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:21,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:47,840 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1910
en_de Dev loss: 0.9154 r:0.2199
en_zh Dev loss: 0.8529 r:0.4612
Current avg r:0.3406 Best avg r: 0.3808
21:08:04,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:30,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:56,683 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1955
en_de Dev loss: 0.9144 r:0.1910
en_zh Dev loss: 0.8163 r:0.4596
Current avg r:0.3253 Best avg r: 0.3808
21:10:13,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:39,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:05,625 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1747
en_de Dev loss: 0.9001 r:0.1971
en_zh Dev loss: 0.7612 r:0.4697
Current avg r:0.3334 Best avg r: 0.3808
21:12:22,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:48,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:14,543 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1822
en_de Dev loss: 0.9317 r:0.2098
en_zh Dev loss: 0.8355 r:0.4710
Current avg r:0.3404 Best avg r: 0.3808
21:14:31,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:57,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:23,554 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1866
en_de Dev loss: 0.9027 r:0.2027
en_zh Dev loss: 0.8377 r:0.4644
Current avg r:0.3335 Best avg r: 0.3808
21:16:40,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:06,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:32,777 root INFO Epoch 11 Global steps: 35800 Train loss: 0.2034
en_de Dev loss: 0.9407 r:0.2140
en_zh Dev loss: 0.8696 r:0.4636
Current avg r:0.3388 Best avg r: 0.3808
21:18:50,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:15,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:41,886 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1903
en_de Dev loss: 0.8974 r:0.1946
en_zh Dev loss: 0.7791 r:0.4696
Current avg r:0.3321 Best avg r: 0.3808
21:20:59,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:25,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:51,166 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1943
en_de Dev loss: 0.9273 r:0.1876
en_zh Dev loss: 0.7229 r:0.4881
Current avg r:0.3379 Best avg r: 0.3808
21:23:08,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:34,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:00,212 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1851
en_de Dev loss: 0.9290 r:0.1884
en_zh Dev loss: 0.8377 r:0.4665
Current avg r:0.3275 Best avg r: 0.3808
21:25:17,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:43,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:09,100 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1497
en_de Dev loss: 0.9682 r:0.1873
en_zh Dev loss: 0.8062 r:0.4737
Current avg r:0.3305 Best avg r: 0.3808
21:27:26,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:52,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:28:19,364 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1657
en_de Dev loss: 0.9271 r:0.1863
en_zh Dev loss: 0.8020 r:0.4669
Current avg r:0.3266 Best avg r: 0.3808
21:29:36,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:02,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:30:28,284 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1664
en_de Dev loss: 0.9486 r:0.1805
en_zh Dev loss: 0.8037 r:0.4708
Current avg r:0.3256 Best avg r: 0.3808
21:31:45,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:11,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:37,120 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1602
en_de Dev loss: 0.9474 r:0.1640
en_zh Dev loss: 0.8003 r:0.4642
Current avg r:0.3141 Best avg r: 0.3808
21:33:54,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:20,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:46,77 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1639
en_de Dev loss: 0.9481 r:0.1891
en_zh Dev loss: 0.8066 r:0.4692
Current avg r:0.3292 Best avg r: 0.3808
21:36:03,153 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:29,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:54,998 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1842
en_de Dev loss: 0.9232 r:0.1810
en_zh Dev loss: 0.8025 r:0.4588
Current avg r:0.3199 Best avg r: 0.3808
21:38:12,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:37,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:03,862 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1870
en_de Dev loss: 0.9202 r:0.1745
en_zh Dev loss: 0.7745 r:0.4535
Current avg r:0.3140 Best avg r: 0.3808
21:40:20,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:46,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:12,808 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1815
en_de Dev loss: 0.9252 r:0.1754
en_zh Dev loss: 0.8431 r:0.4494
Current avg r:0.3124 Best avg r: 0.3808
21:42:29,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:55,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:21,720 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1666
en_de Dev loss: 0.9236 r:0.2048
en_zh Dev loss: 0.8154 r:0.4620
Current avg r:0.3334 Best avg r: 0.3808
21:44:38,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:04,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:30,583 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1612
en_de Dev loss: 0.9189 r:0.2247
en_zh Dev loss: 0.9322 r:0.4464
Current avg r:0.3355 Best avg r: 0.3808
21:46:47,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:13,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:47:39,562 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1689
en_de Dev loss: 0.9148 r:0.2236
en_zh Dev loss: 0.8058 r:0.4553
Current avg r:0.3395 Best avg r: 0.3808
21:48:56,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:22,546 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:48,467 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1686
en_de Dev loss: 0.9013 r:0.2175
en_zh Dev loss: 0.8109 r:0.4631
Current avg r:0.3403 Best avg r: 0.3808
21:51:05,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:31,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:57,363 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1711
en_de Dev loss: 0.9017 r:0.2164
en_zh Dev loss: 0.8043 r:0.4614
Current avg r:0.3389 Best avg r: 0.3808
21:53:14,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:40,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:06,781 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1506
en_de Dev loss: 0.9034 r:0.2148
en_zh Dev loss: 0.8088 r:0.4650
Current avg r:0.3399 Best avg r: 0.3808
21:55:24,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:49,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:15,912 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1706
en_de Dev loss: 0.8925 r:0.2138
en_zh Dev loss: 0.7556 r:0.4796
Current avg r:0.3467 Best avg r: 0.3808
21:57:32,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:58,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:24,834 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1500
en_de Dev loss: 0.8967 r:0.2146
en_zh Dev loss: 0.8189 r:0.4646
Current avg r:0.3396 Best avg r: 0.3808
21:59:41,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:07,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:33,725 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1570
en_de Dev loss: 0.9250 r:0.2092
en_zh Dev loss: 0.8073 r:0.4708
Current avg r:0.3400 Best avg r: 0.3808
22:01:50,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:16,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:42,655 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1562
en_de Dev loss: 0.9232 r:0.2092
en_zh Dev loss: 0.8635 r:0.4632
Current avg r:0.3362 Best avg r: 0.3808
22:03:59,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:25,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:51,619 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1579
en_de Dev loss: 0.9343 r:0.2034
en_zh Dev loss: 0.8683 r:0.4571
Current avg r:0.3303 Best avg r: 0.3808
22:06:08,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:34,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:00,574 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1459
en_de Dev loss: 0.9223 r:0.2123
en_zh Dev loss: 0.7691 r:0.4746
Current avg r:0.3434 Best avg r: 0.3808
22:08:17,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:43,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:09,510 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1690
en_de Dev loss: 0.9253 r:0.2039
en_zh Dev loss: 0.8033 r:0.4702
Current avg r:0.3371 Best avg r: 0.3808
22:10:26,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:52,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:18,508 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1680
en_de Dev loss: 0.9257 r:0.1966
en_zh Dev loss: 0.7730 r:0.4723
Current avg r:0.3345 Best avg r: 0.3808
22:12:35,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:01,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:27,462 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1461
en_de Dev loss: 0.9830 r:0.1925
en_zh Dev loss: 0.8314 r:0.4697
Current avg r:0.3311 Best avg r: 0.3808
22:14:44,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:10,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:36,329 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1432
en_de Dev loss: 0.9130 r:0.2096
en_zh Dev loss: 0.7914 r:0.4756
Current avg r:0.3426 Best avg r: 0.3808
22:16:53,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:19,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:45,384 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1537
en_de Dev loss: 0.9168 r:0.2049
en_zh Dev loss: 0.7738 r:0.4736
Current avg r:0.3393 Best avg r: 0.3808
22:19:02,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:28,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:54,344 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1510
en_de Dev loss: 0.8963 r:0.1802
en_zh Dev loss: 0.7922 r:0.4676
Current avg r:0.3239 Best avg r: 0.3808
22:21:12,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:38,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:04,610 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1467
en_de Dev loss: 0.9025 r:0.2074
en_zh Dev loss: 0.8213 r:0.4633
Current avg r:0.3354 Best avg r: 0.3808
22:23:21,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:47,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:13,886 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1463
en_de Dev loss: 0.8950 r:0.2249
en_zh Dev loss: 0.7709 r:0.4732
Current avg r:0.3490 Best avg r: 0.3808
22:25:31,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:57,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:23,176 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1424
en_de Dev loss: 0.8971 r:0.1928
en_zh Dev loss: 0.7578 r:0.4721
Current avg r:0.3325 Best avg r: 0.3808
22:27:40,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:06,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:28:32,112 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1550
en_de Dev loss: 0.9103 r:0.1969
en_zh Dev loss: 0.7833 r:0.4765
Current avg r:0.3367 Best avg r: 0.3808
22:29:49,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:16,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:42,313 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1537
en_de Dev loss: 0.9102 r:0.1916
en_zh Dev loss: 0.7838 r:0.4742
Current avg r:0.3329 Best avg r: 0.3808
22:31:59,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:25,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:51,129 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1386
en_de Dev loss: 0.9260 r:0.1896
en_zh Dev loss: 0.7840 r:0.4775
Current avg r:0.3336 Best avg r: 0.3808
22:34:08,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:34,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:00,460 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1305
en_de Dev loss: 0.9339 r:0.2093
en_zh Dev loss: 0.8104 r:0.4776
Current avg r:0.3435 Best avg r: 0.3808
22:36:17,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:43,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:09,786 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1374
en_de Dev loss: 0.9322 r:0.2118
en_zh Dev loss: 0.8272 r:0.4779
Current avg r:0.3449 Best avg r: 0.3808
22:38:26,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:52,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:18,642 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1443
en_de Dev loss: 0.9090 r:0.2066
en_zh Dev loss: 0.7659 r:0.4832
Current avg r:0.3449 Best avg r: 0.3808
22:40:37,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:02,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:28,777 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1533
en_de Dev loss: 0.9374 r:0.1985
en_zh Dev loss: 0.7924 r:0.4838
Current avg r:0.3412 Best avg r: 0.3808
22:42:45,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:11,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:43:37,482 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1389
en_de Dev loss: 0.9375 r:0.1845
en_zh Dev loss: 0.8857 r:0.4600
Current avg r:0.3222 Best avg r: 0.3808
22:44:54,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:45:20,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:46,243 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1556
en_de Dev loss: 0.9364 r:0.1717
en_zh Dev loss: 0.8772 r:0.4594
Current avg r:0.3155 Best avg r: 0.3808
22:47:03,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:29,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:55,79 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1314
en_de Dev loss: 0.9398 r:0.1820
en_zh Dev loss: 0.8311 r:0.4665
Current avg r:0.3243 Best avg r: 0.3808
22:49:13,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:49:39,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:05,232 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1399
en_de Dev loss: 0.9374 r:0.1865
en_zh Dev loss: 0.8196 r:0.4711
Current avg r:0.3288 Best avg r: 0.3808
22:51:22,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:48,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:14,115 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1312
en_de Dev loss: 0.9316 r:0.1861
en_zh Dev loss: 0.7888 r:0.4748
Current avg r:0.3305 Best avg r: 0.3808
22:53:31,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:57,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:23,67 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1424
en_de Dev loss: 0.9562 r:0.1763
en_zh Dev loss: 0.8155 r:0.4766
Current avg r:0.3265 Best avg r: 0.3808
22:55:40,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:05,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:31,891 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1366
en_de Dev loss: 0.9793 r:0.1842
en_zh Dev loss: 0.8133 r:0.4801
Current avg r:0.3321 Best avg r: 0.3808
22:57:49,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:15,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:42,430 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1236
en_de Dev loss: 0.9432 r:0.1893
en_zh Dev loss: 0.8220 r:0.4773
Current avg r:0.3333 Best avg r: 0.3808
22:59:59,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:00:26,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:52,404 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1184
en_de Dev loss: 0.9571 r:0.1839
en_zh Dev loss: 0.8148 r:0.4780
Current avg r:0.3310 Best avg r: 0.3808
23:02:09,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:35,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:01,69 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1276
en_de Dev loss: 0.9797 r:0.1539
en_zh Dev loss: 0.9378 r:0.4679
Current avg r:0.3109 Best avg r: 0.3808
23:04:18,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:43,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:09,835 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1312
en_de Dev loss: 0.9259 r:0.1907
en_zh Dev loss: 0.7560 r:0.4870
Current avg r:0.3389 Best avg r: 0.3808
23:06:26,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:52,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:18,500 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1351
en_de Dev loss: 0.9579 r:0.1599
en_zh Dev loss: 0.8603 r:0.4785
Current avg r:0.3192 Best avg r: 0.3808
23:08:35,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:09:01,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:09:27,195 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1365
en_de Dev loss: 0.9288 r:0.1997
en_zh Dev loss: 0.7776 r:0.4784
Current avg r:0.3391 Best avg r: 0.3808
23:10:44,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:10,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:35,996 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1231
en_de Dev loss: 0.9421 r:0.1893
en_zh Dev loss: 0.8445 r:0.4666
Current avg r:0.3279 Best avg r: 0.3808
23:12:52,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:18,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:44,634 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1252
en_de Dev loss: 0.9625 r:0.1779
en_zh Dev loss: 0.8370 r:0.4728
Current avg r:0.3254 Best avg r: 0.3808
23:15:01,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:27,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:53,277 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1280
en_de Dev loss: 0.9651 r:0.1743
en_zh Dev loss: 0.7980 r:0.4778
Current avg r:0.3261 Best avg r: 0.3808
23:17:10,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:36,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:04,968 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1224
en_de Dev loss: 0.9476 r:0.1775
en_zh Dev loss: 0.8001 r:0.4730
Current avg r:0.3253 Best avg r: 0.3808
23:19:21,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:47,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:13,590 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1225
en_de Dev loss: 0.9631 r:0.1675
en_zh Dev loss: 0.8028 r:0.4838
Current avg r:0.3256 Best avg r: 0.3808
23:21:30,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:56,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:22,285 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1178
en_de Dev loss: 0.9426 r:0.1616
en_zh Dev loss: 0.7655 r:0.4781
Current avg r:0.3198 Best avg r: 0.3808
23:23:39,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:05,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:24:31,133 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1160
en_de Dev loss: 0.9588 r:0.1673
en_zh Dev loss: 0.7825 r:0.4817
Current avg r:0.3245 Best avg r: 0.3808
23:25:47,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:13,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:39,690 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1212
en_de Dev loss: 0.9766 r:0.1627
en_zh Dev loss: 0.8231 r:0.4722
Current avg r:0.3175 Best avg r: 0.3808
23:27:56,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:22,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:28:48,332 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1286
en_de Dev loss: 0.9873 r:0.1656
en_zh Dev loss: 0.8211 r:0.4790
Current avg r:0.3223 Best avg r: 0.3808
23:30:05,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:31,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:57,464 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1176
en_de Dev loss: 0.9535 r:0.1780
en_zh Dev loss: 0.7401 r:0.4864
Current avg r:0.3322 Best avg r: 0.3808
23:32:14,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:40,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:06,172 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1210
en_de Dev loss: 0.9431 r:0.1595
en_zh Dev loss: 0.7685 r:0.4716
Current avg r:0.3156 Best avg r: 0.3808
23:34:23,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:34:49,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:14,938 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1187
en_de Dev loss: 0.9610 r:0.1664
en_zh Dev loss: 0.7774 r:0.4808
Current avg r:0.3236 Best avg r: 0.3808
23:36:31,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:57,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:23,600 root INFO Epoch 16 Global steps: 48800 Train loss: 0.1161
en_de Dev loss: 0.9844 r:0.1777
en_zh Dev loss: 0.8674 r:0.4662
Current avg r:0.3220 Best avg r: 0.3808
23:38:40,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:06,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:32,302 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1167
en_de Dev loss: 0.9475 r:0.1806
en_zh Dev loss: 0.7951 r:0.4798
Current avg r:0.3302 Best avg r: 0.3808
23:40:49,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:15,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:41,80 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1103
en_de Dev loss: 0.9515 r:0.1706
en_zh Dev loss: 0.8099 r:0.4703
Current avg r:0.3205 Best avg r: 0.3808
23:42:58,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:23,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:49,789 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1072
en_de Dev loss: 0.9498 r:0.1747
en_zh Dev loss: 0.8569 r:0.4720
Current avg r:0.3233 Best avg r: 0.3808
23:45:06,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:32,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:58,565 root INFO Epoch 16 Global steps: 49600 Train loss: 0.1100
en_de Dev loss: 0.9661 r:0.1951
en_zh Dev loss: 0.7978 r:0.4775
Current avg r:0.3363 Best avg r: 0.3808
23:47:16,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:42,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:08,594 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1240
en_de Dev loss: 0.9658 r:0.1570
en_zh Dev loss: 0.7604 r:0.4779
Current avg r:0.3175 Best avg r: 0.3808
23:49:25,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:51,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:17,301 root INFO Epoch 16 Global steps: 50000 Train loss: 0.1155
en_de Dev loss: 0.9612 r:0.1840
en_zh Dev loss: 0.7712 r:0.4837
Current avg r:0.3339 Best avg r: 0.3808
23:51:34,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:00,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:26,91 root INFO Epoch 16 Global steps: 50200 Train loss: 0.1176
en_de Dev loss: 0.9459 r:0.1805
en_zh Dev loss: 0.8151 r:0.4719
Current avg r:0.3262 Best avg r: 0.3808
23:53:43,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:08,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:54:34,794 root INFO Epoch 16 Global steps: 50400 Train loss: 0.1021
en_de Dev loss: 0.9654 r:0.1814
en_zh Dev loss: 0.8085 r:0.4794
Current avg r:0.3304 Best avg r: 0.3808
23:55:51,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:17,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:43,500 root INFO Epoch 16 Global steps: 50600 Train loss: 0.1075
en_de Dev loss: 0.9538 r:0.1482
en_zh Dev loss: 0.8455 r:0.4679
Current avg r:0.3081 Best avg r: 0.3808
23:58:00,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:26,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:52,240 root INFO Epoch 16 Global steps: 50800 Train loss: 0.1098
en_de Dev loss: 0.9780 r:0.1785
en_zh Dev loss: 0.8154 r:0.4697
Current avg r:0.3241 Best avg r: 0.3808
00:00:09,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:00:35,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:00,926 root INFO Epoch 16 Global steps: 51000 Train loss: 0.1162
en_de Dev loss: 0.9564 r:0.1745
en_zh Dev loss: 0.7958 r:0.4730
Current avg r:0.3237 Best avg r: 0.3808
00:02:18,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:44,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:09,971 root INFO Epoch 17 Global steps: 51200 Train loss: 0.1032
en_de Dev loss: 0.9616 r:0.1670
en_zh Dev loss: 0.8643 r:0.4695
Current avg r:0.3183 Best avg r: 0.3808
00:04:26,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:52,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:18,703 root INFO Epoch 17 Global steps: 51400 Train loss: 0.1002
en_de Dev loss: 0.9443 r:0.1775
en_zh Dev loss: 0.7947 r:0.4741
Current avg r:0.3258 Best avg r: 0.3808
00:06:35,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:01,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:27,361 root INFO Epoch 17 Global steps: 51600 Train loss: 0.1033
en_de Dev loss: 0.9504 r:0.1769
en_zh Dev loss: 0.7878 r:0.4759
Current avg r:0.3264 Best avg r: 0.3808
00:08:44,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:10,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:09:36,129 root INFO Epoch 17 Global steps: 51800 Train loss: 0.0993
en_de Dev loss: 0.9638 r:0.1568
en_zh Dev loss: 0.8292 r:0.4628
Current avg r:0.3098 Best avg r: 0.3808
00:10:53,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:18,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:44,827 root INFO Epoch 17 Global steps: 52000 Train loss: 0.1019
en_de Dev loss: 0.9661 r:0.1442
en_zh Dev loss: 0.8070 r:0.4683
Current avg r:0.3062 Best avg r: 0.3808
