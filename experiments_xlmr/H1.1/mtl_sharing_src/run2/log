14:34:00,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:34:39,362 root INFO 
id:en_zh cur r: 0.0797 best r: 0.0797
14:34:39,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:35:05,257 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:35:05,262 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:35:31,210 root INFO Epoch 0 Global steps: 200 Train loss: 0.8547
en_de Dev loss: 0.8923 r:0.0296
en_zh Dev loss: 0.8070 r:0.1493
Current avg r:0.0894 Best avg r: 0.0894
14:36:48,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:27,179 root INFO 
id:en_zh cur r: 0.1613 best r: 0.1613
14:37:27,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:37:53,132 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:37:53,141 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:38:19,134 root INFO Epoch 0 Global steps: 400 Train loss: 0.7642
en_de Dev loss: 0.8838 r:0.0642
en_zh Dev loss: 0.8036 r:0.2046
Current avg r:0.1344 Best avg r: 0.1344
14:39:36,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:40:15,203 root INFO 
id:en_zh cur r: 0.1972 best r: 0.1972
14:40:15,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:41,207 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:40:41,212 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:41:07,193 root INFO Epoch 0 Global steps: 600 Train loss: 0.8154
en_de Dev loss: 0.8842 r:0.0748
en_zh Dev loss: 0.8002 r:0.2407
Current avg r:0.1578 Best avg r: 0.1578
14:42:24,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:43:03,313 root INFO 
id:en_zh cur r: 0.2224 best r: 0.2224
14:43:03,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:29,260 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:43:29,265 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:43:55,278 root INFO Epoch 0 Global steps: 800 Train loss: 0.6681
en_de Dev loss: 0.8846 r:0.0796
en_zh Dev loss: 0.8059 r:0.2547
Current avg r:0.1671 Best avg r: 0.1671
14:45:12,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:38,494 root INFO 
id:en_de cur r: 0.0139 best r: 0.0139
14:46:04,485 root INFO 
id:en_zh cur r: 0.2455 best r: 0.2455
14:46:04,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:30,484 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7067
en_de Dev loss: 0.8849 r:0.0733
en_zh Dev loss: 0.8091 r:0.2249
Current avg r:0.1491 Best avg r: 0.1671
14:47:47,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:26,819 root INFO 
id:en_zh cur r: 0.2831 best r: 0.2831
14:48:26,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:52,806 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:48:52,811 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:49:18,799 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7048
en_de Dev loss: 0.8793 r:0.1282
en_zh Dev loss: 0.7956 r:0.2944
Current avg r:0.2113 Best avg r: 0.2113
14:50:35,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:14,760 root INFO 
id:en_zh cur r: 0.3149 best r: 0.3149
14:51:14,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:40,734 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:51:40,741 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:52:06,767 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7742
en_de Dev loss: 0.8762 r:0.1476
en_zh Dev loss: 0.7872 r:0.3323
Current avg r:0.2400 Best avg r: 0.2400
14:53:23,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:49,905 root INFO 
id:en_de cur r: 0.1538 best r: 0.1538
14:54:15,933 root INFO 
id:en_zh cur r: 0.3244 best r: 0.3244
14:54:15,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:41,972 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:54:41,979 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:55:08,5 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7849
en_de Dev loss: 0.8859 r:0.1409
en_zh Dev loss: 0.7848 r:0.3397
Current avg r:0.2403 Best avg r: 0.2403
14:56:25,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:51,267 root INFO 
id:en_de cur r: 0.1665 best r: 0.1665
14:57:17,237 root INFO 
id:en_zh cur r: 0.3567 best r: 0.3567
14:57:17,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:43,211 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
14:57:43,218 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:58:09,211 root INFO Epoch 0 Global steps: 1800 Train loss: 0.8167
en_de Dev loss: 0.8784 r:0.1132
en_zh Dev loss: 0.7664 r:0.3741
Current avg r:0.2437 Best avg r: 0.2437
14:59:26,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:52,326 root INFO 
id:en_de cur r: 0.1676 best r: 0.1676
15:00:18,292 root INFO 
id:en_zh cur r: 0.3749 best r: 0.3749
15:00:18,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:44,289 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:00:44,296 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:01:10,271 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7502
en_de Dev loss: 0.8653 r:0.1701
en_zh Dev loss: 0.7483 r:0.3944
Current avg r:0.2823 Best avg r: 0.2823
15:02:27,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:53,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:19,216 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:03:19,222 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:03:45,227 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7786
en_de Dev loss: 0.8665 r:0.1877
en_zh Dev loss: 0.7495 r:0.4007
Current avg r:0.2942 Best avg r: 0.2942
15:05:02,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:41,246 root INFO 
id:en_zh cur r: 0.3906 best r: 0.3906
15:05:41,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:07,228 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:06:07,247 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:06:33,262 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6270
en_de Dev loss: 0.8955 r:0.1930
en_zh Dev loss: 0.7635 r:0.4103
Current avg r:0.3016 Best avg r: 0.3016
15:07:50,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:16,487 root INFO 
id:en_de cur r: 0.1738 best r: 0.1738
15:08:42,433 root INFO 
id:en_zh cur r: 0.4010 best r: 0.4010
15:08:42,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:08,375 root INFO Epoch 0 Global steps: 2600 Train loss: 0.7108
en_de Dev loss: 0.8876 r:0.1639
en_zh Dev loss: 0.7162 r:0.4068
Current avg r:0.2854 Best avg r: 0.3016
15:10:25,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:51,392 root INFO 
id:en_de cur r: 0.1772 best r: 0.1772
15:11:04,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:30,361 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7041
en_de Dev loss: 0.8785 r:0.1652
en_zh Dev loss: 0.7233 r:0.4064
Current avg r:0.2858 Best avg r: 0.3016
15:12:47,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:13,448 root INFO 
id:en_de cur r: 0.1793 best r: 0.1793
15:13:26,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:52,386 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:13:52,391 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:14:18,401 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7079
en_de Dev loss: 0.8765 r:0.1974
en_zh Dev loss: 0.7230 r:0.4154
Current avg r:0.3064 Best avg r: 0.3064
15:15:35,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:01,884 root INFO 
id:en_de cur r: 0.2042 best r: 0.2042
15:16:27,870 root INFO 
id:en_zh cur r: 0.4030 best r: 0.4030
15:16:27,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:53,822 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:16:53,828 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:17:19,792 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6119
en_de Dev loss: 0.8517 r:0.2123
en_zh Dev loss: 0.6980 r:0.4194
Current avg r:0.3159 Best avg r: 0.3159
15:18:36,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:02,815 root INFO 
id:en_de cur r: 0.2250 best r: 0.2250
15:19:31,571 root INFO 
id:en_zh cur r: 0.4280 best r: 0.4280
15:19:31,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:57,492 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:19:57,498 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:20:23,469 root INFO Epoch 1 Global steps: 3400 Train loss: 0.7613
en_de Dev loss: 0.8579 r:0.2136
en_zh Dev loss: 0.7051 r:0.4269
Current avg r:0.3202 Best avg r: 0.3202
15:21:40,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:19,529 root INFO 
id:en_zh cur r: 0.4500 best r: 0.4500
15:22:19,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:45,553 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:22:45,558 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:23:11,599 root INFO Epoch 1 Global steps: 3600 Train loss: 0.6900
en_de Dev loss: 0.8524 r:0.2060
en_zh Dev loss: 0.6619 r:0.4478
Current avg r:0.3269 Best avg r: 0.3269
15:24:28,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:54,650 root INFO 
id:en_de cur r: 0.2346 best r: 0.2346
15:25:07,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:33,611 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6257
en_de Dev loss: 0.8562 r:0.2104
en_zh Dev loss: 0.7182 r:0.4388
Current avg r:0.3246 Best avg r: 0.3269
15:26:50,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:16,657 root INFO 
id:en_de cur r: 0.2357 best r: 0.2357
15:27:42,637 root INFO 
id:en_zh cur r: 0.4691 best r: 0.4691
15:27:42,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:08,629 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:28:08,635 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:28:34,638 root INFO Epoch 1 Global steps: 4000 Train loss: 0.6359
en_de Dev loss: 0.8683 r:0.1940
en_zh Dev loss: 0.6597 r:0.4654
Current avg r:0.3297 Best avg r: 0.3297
15:29:51,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:17,772 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:43,748 root INFO Epoch 1 Global steps: 4200 Train loss: 0.6140
en_de Dev loss: 0.8521 r:0.1996
en_zh Dev loss: 0.6750 r:0.4563
Current avg r:0.3279 Best avg r: 0.3297
15:32:00,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:26,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:52,643 root INFO Epoch 1 Global steps: 4400 Train loss: 0.6757
en_de Dev loss: 0.8742 r:0.1749
en_zh Dev loss: 0.7161 r:0.4248
Current avg r:0.2999 Best avg r: 0.3297
15:34:09,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:35,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:01,549 root INFO Epoch 1 Global steps: 4600 Train loss: 0.6867
en_de Dev loss: 0.8569 r:0.1859
en_zh Dev loss: 0.6650 r:0.4510
Current avg r:0.3184 Best avg r: 0.3297
15:36:18,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:44,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:37:10,619 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:37:10,625 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:37:36,637 root INFO Epoch 1 Global steps: 4800 Train loss: 0.5820
en_de Dev loss: 0.8776 r:0.2167
en_zh Dev loss: 0.7344 r:0.4467
Current avg r:0.3317 Best avg r: 0.3317
15:38:53,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:19,956 root INFO 
id:en_de cur r: 0.2373 best r: 0.2373
15:39:45,932 root INFO 
id:en_zh cur r: 0.4747 best r: 0.4747
15:39:45,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:11,922 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:40:11,928 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:40:37,903 root INFO Epoch 1 Global steps: 5000 Train loss: 0.6538
en_de Dev loss: 0.8496 r:0.2269
en_zh Dev loss: 0.6563 r:0.4697
Current avg r:0.3483 Best avg r: 0.3483
15:41:54,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:20,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:46,945 root INFO Epoch 1 Global steps: 5200 Train loss: 0.6488
en_de Dev loss: 0.8570 r:0.2211
en_zh Dev loss: 0.6667 r:0.4633
Current avg r:0.3422 Best avg r: 0.3483
15:44:04,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:43,160 root INFO 
id:en_zh cur r: 0.4784 best r: 0.4784
15:44:43,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:09,124 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:45:09,130 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:45:35,102 root INFO Epoch 1 Global steps: 5400 Train loss: 0.5697
en_de Dev loss: 0.8421 r:0.2396
en_zh Dev loss: 0.6422 r:0.4745
Current avg r:0.3570 Best avg r: 0.3570
15:46:52,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:18,477 root INFO 
id:en_de cur r: 0.2446 best r: 0.2446
15:47:31,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:57,402 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:47:57,408 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:48:23,413 root INFO Epoch 1 Global steps: 5600 Train loss: 0.6498
en_de Dev loss: 0.8412 r:0.2520
en_zh Dev loss: 0.6745 r:0.4635
Current avg r:0.3578 Best avg r: 0.3578
15:49:40,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:06,713 root INFO 
id:en_de cur r: 0.2525 best r: 0.2525
15:50:32,703 root INFO 
id:en_zh cur r: 0.4911 best r: 0.4911
15:50:32,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:58,679 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:50:58,686 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:51:24,663 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6754
en_de Dev loss: 0.8320 r:0.2511
en_zh Dev loss: 0.6300 r:0.4823
Current avg r:0.3667 Best avg r: 0.3667
15:52:41,891 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:07,889 root INFO 
id:en_de cur r: 0.2659 best r: 0.2659
15:53:20,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:46,832 root INFO Epoch 1 Global steps: 6000 Train loss: 0.6245
en_de Dev loss: 0.8404 r:0.2622
en_zh Dev loss: 0.6788 r:0.4650
Current avg r:0.3636 Best avg r: 0.3667
15:55:04,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:30,336 root INFO 
id:en_de cur r: 0.2684 best r: 0.2684
15:55:43,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:09,341 root INFO Epoch 2 Global steps: 6200 Train loss: 0.5980
en_de Dev loss: 0.8454 r:0.2590
en_zh Dev loss: 0.6831 r:0.4721
Current avg r:0.3655 Best avg r: 0.3667
15:57:27,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:53,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:19,735 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
15:58:19,741 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:58:45,741 root INFO Epoch 2 Global steps: 6400 Train loss: 0.5292
en_de Dev loss: 0.8290 r:0.2580
en_zh Dev loss: 0.6435 r:0.4812
Current avg r:0.3696 Best avg r: 0.3696
16:00:02,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:28,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:54,678 root INFO Epoch 2 Global steps: 6600 Train loss: 0.6050
en_de Dev loss: 0.8517 r:0.2451
en_zh Dev loss: 0.7255 r:0.4603
Current avg r:0.3527 Best avg r: 0.3696
16:02:11,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:02:37,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:03,690 root INFO Epoch 2 Global steps: 6800 Train loss: 0.6206
en_de Dev loss: 0.8481 r:0.2523
en_zh Dev loss: 0.6572 r:0.4650
Current avg r:0.3587 Best avg r: 0.3696
16:04:20,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:46,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:12,957 root INFO Epoch 2 Global steps: 7000 Train loss: 0.6275
en_de Dev loss: 0.8672 r:0.2345
en_zh Dev loss: 0.7828 r:0.4559
Current avg r:0.3452 Best avg r: 0.3696
16:06:30,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:56,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:21,972 root INFO Epoch 2 Global steps: 7200 Train loss: 0.6848
en_de Dev loss: 0.8450 r:0.2381
en_zh Dev loss: 0.6559 r:0.4783
Current avg r:0.3582 Best avg r: 0.3696
16:08:39,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:05,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:31,60 root INFO Epoch 2 Global steps: 7400 Train loss: 0.5966
en_de Dev loss: 0.8402 r:0.2409
en_zh Dev loss: 0.6613 r:0.4837
Current avg r:0.3623 Best avg r: 0.3696
16:10:48,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:27,36 root INFO 
id:en_zh cur r: 0.5029 best r: 0.5029
16:11:27,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:53,33 root INFO Epoch 2 Global steps: 7600 Train loss: 0.5470
en_de Dev loss: 0.8524 r:0.2352
en_zh Dev loss: 0.6461 r:0.4949
Current avg r:0.3651 Best avg r: 0.3696
16:13:10,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:36,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:02,303 root INFO Epoch 2 Global steps: 7800 Train loss: 0.5381
en_de Dev loss: 0.8421 r:0.2462
en_zh Dev loss: 0.6897 r:0.4868
Current avg r:0.3665 Best avg r: 0.3696
16:15:19,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:45,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:11,688 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
16:16:11,697 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:16:37,705 root INFO Epoch 2 Global steps: 8000 Train loss: 0.5317
en_de Dev loss: 0.8389 r:0.2626
en_zh Dev loss: 0.6901 r:0.4783
Current avg r:0.3704 Best avg r: 0.3704
16:17:54,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:20,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:46,655 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
16:18:46,662 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:19:12,656 root INFO Epoch 2 Global steps: 8200 Train loss: 0.5402
en_de Dev loss: 0.8405 r:0.2674
en_zh Dev loss: 0.6788 r:0.4856
Current avg r:0.3765 Best avg r: 0.3765
16:20:31,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:57,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:23,160 root INFO Epoch 2 Global steps: 8400 Train loss: 0.6633
en_de Dev loss: 0.8359 r:0.2694
en_zh Dev loss: 0.6697 r:0.4832
Current avg r:0.3763 Best avg r: 0.3765
16:22:40,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:06,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:32,280 root INFO Epoch 2 Global steps: 8600 Train loss: 0.5916
en_de Dev loss: 0.8302 r:0.2637
en_zh Dev loss: 0.6568 r:0.4884
Current avg r:0.3761 Best avg r: 0.3765
16:24:49,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:15,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:41,436 root INFO Epoch 2 Global steps: 8800 Train loss: 0.5936
en_de Dev loss: 0.8442 r:0.2604
en_zh Dev loss: 0.6742 r:0.4770
Current avg r:0.3687 Best avg r: 0.3765
16:27:00,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:26,77 root INFO 
id:en_de cur r: 0.2700 best r: 0.2700
16:27:39,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:05,36 root INFO Epoch 2 Global steps: 9000 Train loss: 0.5873
en_de Dev loss: 0.8330 r:0.2674
en_zh Dev loss: 0.6908 r:0.4801
Current avg r:0.3737 Best avg r: 0.3765
16:29:22,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:48,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:14,444 root INFO Epoch 3 Global steps: 9200 Train loss: 0.5139
en_de Dev loss: 0.8532 r:0.2527
en_zh Dev loss: 0.7648 r:0.4725
Current avg r:0.3626 Best avg r: 0.3765
16:31:31,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:57,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:32:23,457 root INFO Epoch 3 Global steps: 9400 Train loss: 0.4520
en_de Dev loss: 0.8512 r:0.2381
en_zh Dev loss: 0.7080 r:0.4742
Current avg r:0.3561 Best avg r: 0.3765
16:33:40,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:06,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:32,487 root INFO Epoch 3 Global steps: 9600 Train loss: 0.5786
en_de Dev loss: 0.8316 r:0.2515
en_zh Dev loss: 0.6553 r:0.4876
Current avg r:0.3695 Best avg r: 0.3765
16:35:49,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:15,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:41,419 root INFO Epoch 3 Global steps: 9800 Train loss: 0.5692
en_de Dev loss: 0.8603 r:0.2438
en_zh Dev loss: 0.7432 r:0.4768
Current avg r:0.3603 Best avg r: 0.3765
16:37:58,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:24,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:50,405 root INFO Epoch 3 Global steps: 10000 Train loss: 0.5268
en_de Dev loss: 0.8329 r:0.2479
en_zh Dev loss: 0.6698 r:0.4825
Current avg r:0.3652 Best avg r: 0.3765
16:40:08,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:34,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:00,683 root INFO Epoch 3 Global steps: 10200 Train loss: 0.5731
en_de Dev loss: 0.8446 r:0.2403
en_zh Dev loss: 0.6754 r:0.4804
Current avg r:0.3603 Best avg r: 0.3765
16:42:17,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:43,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:09,610 root INFO Epoch 3 Global steps: 10400 Train loss: 0.5491
en_de Dev loss: 0.8690 r:0.2435
en_zh Dev loss: 0.7557 r:0.4665
Current avg r:0.3550 Best avg r: 0.3765
16:44:27,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:53,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:19,880 root INFO Epoch 3 Global steps: 10600 Train loss: 0.5431
en_de Dev loss: 0.8408 r:0.2455
en_zh Dev loss: 0.6897 r:0.4847
Current avg r:0.3651 Best avg r: 0.3765
16:46:36,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:02,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:28,831 root INFO Epoch 3 Global steps: 10800 Train loss: 0.4935
en_de Dev loss: 0.8322 r:0.2599
en_zh Dev loss: 0.7220 r:0.4623
Current avg r:0.3611 Best avg r: 0.3765
16:48:45,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:11,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:37,764 root INFO Epoch 3 Global steps: 11000 Train loss: 0.4896
en_de Dev loss: 0.8615 r:0.2760
en_zh Dev loss: 0.8180 r:0.4477
Current avg r:0.3618 Best avg r: 0.3765
16:50:54,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:20,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:46,769 root INFO Epoch 3 Global steps: 11200 Train loss: 0.5200
en_de Dev loss: 0.8546 r:0.2700
en_zh Dev loss: 0.7413 r:0.4764
Current avg r:0.3732 Best avg r: 0.3765
16:53:03,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:29,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:55,884 root INFO Epoch 3 Global steps: 11400 Train loss: 0.5864
en_de Dev loss: 0.8334 r:0.2665
en_zh Dev loss: 0.7108 r:0.4766
Current avg r:0.3715 Best avg r: 0.3765
16:55:13,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:39,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:05,52 root INFO Epoch 3 Global steps: 11600 Train loss: 0.5761
en_de Dev loss: 0.8247 r:0.2701
en_zh Dev loss: 0.7212 r:0.4776
Current avg r:0.3738 Best avg r: 0.3765
16:57:22,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:48,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:14,26 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
16:58:14,33 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:58:40,8 root INFO Epoch 3 Global steps: 11800 Train loss: 0.4698
en_de Dev loss: 0.8272 r:0.2897
en_zh Dev loss: 0.6850 r:0.4718
Current avg r:0.3808 Best avg r: 0.3808
16:59:57,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:22,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:50,239 root INFO Epoch 3 Global steps: 12000 Train loss: 0.4649
en_de Dev loss: 0.8384 r:0.2836
en_zh Dev loss: 0.7191 r:0.4705
Current avg r:0.3771 Best avg r: 0.3808
17:02:07,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:33,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:59,699 root INFO Epoch 4 Global steps: 12200 Train loss: 0.4610
en_de Dev loss: 0.8445 r:0.2690
en_zh Dev loss: 0.7128 r:0.4756
Current avg r:0.3723 Best avg r: 0.3808
17:04:16,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:42,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:08,640 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4901
en_de Dev loss: 0.8356 r:0.2738
en_zh Dev loss: 0.7266 r:0.4715
Current avg r:0.3726 Best avg r: 0.3808
17:06:25,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:51,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:17,585 root INFO Epoch 4 Global steps: 12600 Train loss: 0.4974
en_de Dev loss: 0.8316 r:0.2692
en_zh Dev loss: 0.7330 r:0.4769
Current avg r:0.3730 Best avg r: 0.3808
17:08:34,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:00,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:26,633 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4370
en_de Dev loss: 0.8309 r:0.2578
en_zh Dev loss: 0.7365 r:0.4765
Current avg r:0.3672 Best avg r: 0.3808
17:10:43,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:09,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:35,599 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4758
en_de Dev loss: 0.8449 r:0.2542
en_zh Dev loss: 0.7777 r:0.4625
Current avg r:0.3584 Best avg r: 0.3808
17:12:52,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:18,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:44,537 root INFO Epoch 4 Global steps: 13200 Train loss: 0.5196
en_de Dev loss: 0.8448 r:0.2606
en_zh Dev loss: 0.7574 r:0.4620
Current avg r:0.3613 Best avg r: 0.3808
17:15:01,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:27,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:53,552 root INFO Epoch 4 Global steps: 13400 Train loss: 0.5038
en_de Dev loss: 0.8395 r:0.2450
en_zh Dev loss: 0.7292 r:0.4576
Current avg r:0.3513 Best avg r: 0.3808
17:17:10,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:36,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:02,530 root INFO Epoch 4 Global steps: 13600 Train loss: 0.4192
en_de Dev loss: 0.8399 r:0.2601
en_zh Dev loss: 0.7714 r:0.4503
Current avg r:0.3552 Best avg r: 0.3808
17:19:19,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:45,527 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:11,496 root INFO Epoch 4 Global steps: 13800 Train loss: 0.4249
en_de Dev loss: 0.8325 r:0.2540
en_zh Dev loss: 0.6977 r:0.4750
Current avg r:0.3645 Best avg r: 0.3808
17:21:28,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:54,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:20,562 root INFO Epoch 4 Global steps: 14000 Train loss: 0.4429
en_de Dev loss: 0.8567 r:0.2486
en_zh Dev loss: 0.7545 r:0.4507
Current avg r:0.3497 Best avg r: 0.3808
17:23:37,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:03,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:29,737 root INFO Epoch 4 Global steps: 14200 Train loss: 0.4416
en_de Dev loss: 0.8590 r:0.2529
en_zh Dev loss: 0.8046 r:0.4558
Current avg r:0.3544 Best avg r: 0.3808
17:25:46,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:12,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:38,739 root INFO Epoch 4 Global steps: 14400 Train loss: 0.4133
en_de Dev loss: 0.8440 r:0.2679
en_zh Dev loss: 0.7445 r:0.4561
Current avg r:0.3620 Best avg r: 0.3808
17:27:55,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:21,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:47,763 root INFO Epoch 4 Global steps: 14600 Train loss: 0.4233
en_de Dev loss: 0.8275 r:0.2601
en_zh Dev loss: 0.7050 r:0.4642
Current avg r:0.3622 Best avg r: 0.3808
17:30:04,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:30,810 root INFO 
id:en_de cur r: 0.2706 best r: 0.2706
17:30:43,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:09,743 root INFO Epoch 4 Global steps: 14800 Train loss: 0.4070
en_de Dev loss: 0.8460 r:0.2721
en_zh Dev loss: 0.8343 r:0.4535
Current avg r:0.3628 Best avg r: 0.3808
17:32:26,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:52,837 root INFO 
id:en_de cur r: 0.2753 best r: 0.2753
17:33:05,812 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:31,784 root INFO Epoch 4 Global steps: 15000 Train loss: 0.5083
en_de Dev loss: 0.8434 r:0.2707
en_zh Dev loss: 0.7866 r:0.4553
Current avg r:0.3630 Best avg r: 0.3808
17:34:49,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:15,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:41,224 root INFO Epoch 5 Global steps: 15200 Train loss: 0.3590
en_de Dev loss: 0.8292 r:0.2621
en_zh Dev loss: 0.7524 r:0.4580
Current avg r:0.3600 Best avg r: 0.3808
17:36:58,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:24,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:50,204 root INFO Epoch 5 Global steps: 15400 Train loss: 0.3836
en_de Dev loss: 0.8733 r:0.2492
en_zh Dev loss: 0.7778 r:0.4606
Current avg r:0.3549 Best avg r: 0.3808
17:39:07,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:33,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:59,447 root INFO Epoch 5 Global steps: 15600 Train loss: 0.3978
en_de Dev loss: 0.8347 r:0.2580
en_zh Dev loss: 0.7492 r:0.4577
Current avg r:0.3579 Best avg r: 0.3808
17:41:16,726 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:42,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:08,664 root INFO Epoch 5 Global steps: 15800 Train loss: 0.4269
en_de Dev loss: 0.8359 r:0.2525
en_zh Dev loss: 0.7234 r:0.4588
Current avg r:0.3557 Best avg r: 0.3808
17:43:25,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:51,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:17,742 root INFO Epoch 5 Global steps: 16000 Train loss: 0.3836
en_de Dev loss: 0.8434 r:0.2217
en_zh Dev loss: 0.6891 r:0.4740
Current avg r:0.3478 Best avg r: 0.3808
17:45:34,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:00,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:26,959 root INFO Epoch 5 Global steps: 16200 Train loss: 0.3805
en_de Dev loss: 0.8313 r:0.2550
en_zh Dev loss: 0.7234 r:0.4722
Current avg r:0.3636 Best avg r: 0.3808
17:47:44,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:10,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:36,132 root INFO Epoch 5 Global steps: 16400 Train loss: 0.4204
en_de Dev loss: 0.8622 r:0.2361
en_zh Dev loss: 0.7611 r:0.4714
Current avg r:0.3538 Best avg r: 0.3808
17:49:53,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:19,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:45,244 root INFO Epoch 5 Global steps: 16600 Train loss: 0.3807
en_de Dev loss: 0.8386 r:0.2459
en_zh Dev loss: 0.7599 r:0.4613
Current avg r:0.3536 Best avg r: 0.3808
17:52:02,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:28,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:54,296 root INFO Epoch 5 Global steps: 16800 Train loss: 0.3624
en_de Dev loss: 0.8666 r:0.2432
en_zh Dev loss: 0.8165 r:0.4390
Current avg r:0.3411 Best avg r: 0.3808
17:54:12,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:38,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:04,460 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3804
en_de Dev loss: 0.8678 r:0.2049
en_zh Dev loss: 0.7438 r:0.4638
Current avg r:0.3344 Best avg r: 0.3808
17:56:21,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:47,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:13,380 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3662
en_de Dev loss: 0.8830 r:0.2105
en_zh Dev loss: 0.7607 r:0.4591
Current avg r:0.3348 Best avg r: 0.3808
17:58:30,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:56,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:22,366 root INFO Epoch 5 Global steps: 17400 Train loss: 0.4371
en_de Dev loss: 0.8604 r:0.2235
en_zh Dev loss: 0.8404 r:0.4404
Current avg r:0.3319 Best avg r: 0.3808
18:00:39,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:05,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:31,287 root INFO Epoch 5 Global steps: 17600 Train loss: 0.4285
en_de Dev loss: 0.8485 r:0.2340
en_zh Dev loss: 0.7820 r:0.4376
Current avg r:0.3358 Best avg r: 0.3808
18:02:48,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:14,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:40,295 root INFO Epoch 5 Global steps: 17800 Train loss: 0.4059
en_de Dev loss: 0.8467 r:0.2357
en_zh Dev loss: 0.7671 r:0.4443
Current avg r:0.3400 Best avg r: 0.3808
18:04:57,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:23,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:49,271 root INFO Epoch 5 Global steps: 18000 Train loss: 0.4090
en_de Dev loss: 0.8426 r:0.2370
en_zh Dev loss: 0.7363 r:0.4547
Current avg r:0.3459 Best avg r: 0.3808
18:07:06,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:32,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:58,797 root INFO Epoch 6 Global steps: 18200 Train loss: 0.3282
en_de Dev loss: 0.8534 r:0.2242
en_zh Dev loss: 0.7525 r:0.4542
Current avg r:0.3392 Best avg r: 0.3808
18:09:15,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:41,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:07,961 root INFO Epoch 6 Global steps: 18400 Train loss: 0.3147
en_de Dev loss: 0.8622 r:0.2331
en_zh Dev loss: 0.7732 r:0.4575
Current avg r:0.3453 Best avg r: 0.3808
18:11:25,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:51,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:17,160 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3132
en_de Dev loss: 0.8525 r:0.2375
en_zh Dev loss: 0.7842 r:0.4479
Current avg r:0.3427 Best avg r: 0.3808
18:13:34,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:03,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:29,244 root INFO Epoch 6 Global steps: 18800 Train loss: 0.3502
en_de Dev loss: 0.8520 r:0.2357
en_zh Dev loss: 0.7858 r:0.4506
Current avg r:0.3432 Best avg r: 0.3808
18:15:46,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:12,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:38,445 root INFO Epoch 6 Global steps: 19000 Train loss: 0.3377
en_de Dev loss: 0.8510 r:0.2333
en_zh Dev loss: 0.7601 r:0.4680
Current avg r:0.3507 Best avg r: 0.3808
18:17:55,553 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:21,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:47,422 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3185
en_de Dev loss: 0.8579 r:0.2358
en_zh Dev loss: 0.7674 r:0.4594
Current avg r:0.3476 Best avg r: 0.3808
18:20:04,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:30,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:56,327 root INFO Epoch 6 Global steps: 19400 Train loss: 0.3471
en_de Dev loss: 0.8675 r:0.2123
en_zh Dev loss: 0.8027 r:0.4521
Current avg r:0.3322 Best avg r: 0.3808
18:22:13,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:39,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:08,510 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3414
en_de Dev loss: 0.8486 r:0.2259
en_zh Dev loss: 0.7745 r:0.4507
Current avg r:0.3383 Best avg r: 0.3808
18:24:28,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:24:54,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:20,285 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3397
en_de Dev loss: 0.8443 r:0.2338
en_zh Dev loss: 0.7681 r:0.4462
Current avg r:0.3400 Best avg r: 0.3808
18:26:37,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:03,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:29,286 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3399
en_de Dev loss: 0.8483 r:0.2254
en_zh Dev loss: 0.7509 r:0.4479
Current avg r:0.3367 Best avg r: 0.3808
18:28:46,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:12,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:38,251 root INFO Epoch 6 Global steps: 20200 Train loss: 0.3178
en_de Dev loss: 0.8750 r:0.2365
en_zh Dev loss: 0.8492 r:0.4392
Current avg r:0.3379 Best avg r: 0.3808
18:30:55,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:21,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:47,164 root INFO Epoch 6 Global steps: 20400 Train loss: 0.3707
en_de Dev loss: 0.8613 r:0.2251
en_zh Dev loss: 0.7487 r:0.4500
Current avg r:0.3375 Best avg r: 0.3808
18:33:04,214 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:30,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:56,77 root INFO Epoch 6 Global steps: 20600 Train loss: 0.3192
en_de Dev loss: 0.8521 r:0.2322
en_zh Dev loss: 0.7632 r:0.4527
Current avg r:0.3425 Best avg r: 0.3808
18:35:13,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:39,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:04,992 root INFO Epoch 6 Global steps: 20800 Train loss: 0.3110
en_de Dev loss: 0.8660 r:0.2207
en_zh Dev loss: 0.7820 r:0.4425
Current avg r:0.3316 Best avg r: 0.3808
18:37:22,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:37:48,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:14,310 root INFO Epoch 6 Global steps: 21000 Train loss: 0.2744
en_de Dev loss: 0.8550 r:0.2313
en_zh Dev loss: 0.7482 r:0.4611
Current avg r:0.3462 Best avg r: 0.3808
18:39:33,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:59,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:25,323 root INFO Epoch 7 Global steps: 21200 Train loss: 0.2700
en_de Dev loss: 0.9021 r:0.1960
en_zh Dev loss: 0.7691 r:0.4716
Current avg r:0.3338 Best avg r: 0.3808
18:41:42,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:08,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:34,230 root INFO Epoch 7 Global steps: 21400 Train loss: 0.2929
en_de Dev loss: 0.8807 r:0.1902
en_zh Dev loss: 0.8199 r:0.4535
Current avg r:0.3218 Best avg r: 0.3808
18:43:51,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:17,188 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:43,91 root INFO Epoch 7 Global steps: 21600 Train loss: 0.2821
en_de Dev loss: 0.8519 r:0.2410
en_zh Dev loss: 0.8022 r:0.4455
Current avg r:0.3433 Best avg r: 0.3808
18:46:00,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:26,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:52,86 root INFO Epoch 7 Global steps: 21800 Train loss: 0.3089
en_de Dev loss: 0.8736 r:0.2288
en_zh Dev loss: 0.7857 r:0.4687
Current avg r:0.3488 Best avg r: 0.3808
18:48:09,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:35,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:00,994 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2749
en_de Dev loss: 0.8612 r:0.2342
en_zh Dev loss: 0.7591 r:0.4679
Current avg r:0.3511 Best avg r: 0.3808
18:50:18,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:43,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:09,848 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2748
en_de Dev loss: 0.8664 r:0.2329
en_zh Dev loss: 0.7771 r:0.4642
Current avg r:0.3486 Best avg r: 0.3808
18:52:26,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:52,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:18,796 root INFO Epoch 7 Global steps: 22400 Train loss: 0.2794
en_de Dev loss: 0.8573 r:0.2405
en_zh Dev loss: 0.7729 r:0.4713
Current avg r:0.3559 Best avg r: 0.3808
18:54:35,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:01,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:27,764 root INFO Epoch 7 Global steps: 22600 Train loss: 0.2898
en_de Dev loss: 0.8484 r:0.2459
en_zh Dev loss: 0.7901 r:0.4654
Current avg r:0.3557 Best avg r: 0.3808
18:56:44,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:10,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:36,708 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2864
en_de Dev loss: 0.8610 r:0.2386
en_zh Dev loss: 0.7859 r:0.4730
Current avg r:0.3558 Best avg r: 0.3808
18:58:53,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:19,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:45,747 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2706
en_de Dev loss: 0.8554 r:0.2395
en_zh Dev loss: 0.7392 r:0.4796
Current avg r:0.3595 Best avg r: 0.3808
19:01:02,865 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:28,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:54,873 root INFO Epoch 7 Global steps: 23200 Train loss: 0.3008
en_de Dev loss: 0.8487 r:0.2315
en_zh Dev loss: 0.7371 r:0.4727
Current avg r:0.3521 Best avg r: 0.3808
19:03:12,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:38,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:04,666 root INFO Epoch 7 Global steps: 23400 Train loss: 0.2907
en_de Dev loss: 0.8487 r:0.2434
en_zh Dev loss: 0.7693 r:0.4655
Current avg r:0.3544 Best avg r: 0.3808
19:05:22,459 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:48,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:14,490 root INFO Epoch 7 Global steps: 23600 Train loss: 0.3080
en_de Dev loss: 0.8643 r:0.2269
en_zh Dev loss: 0.7931 r:0.4647
Current avg r:0.3458 Best avg r: 0.3808
19:07:31,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:57,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:23,811 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2568
en_de Dev loss: 0.8871 r:0.2123
en_zh Dev loss: 0.8204 r:0.4681
Current avg r:0.3402 Best avg r: 0.3808
19:09:41,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:07,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:33,18 root INFO Epoch 7 Global steps: 24000 Train loss: 0.3490
en_de Dev loss: 0.8651 r:0.2098
en_zh Dev loss: 0.7756 r:0.4629
Current avg r:0.3363 Best avg r: 0.3808
19:11:50,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:16,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:12:42,578 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2492
en_de Dev loss: 0.8631 r:0.2285
en_zh Dev loss: 0.7372 r:0.4718
Current avg r:0.3502 Best avg r: 0.3808
19:13:59,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:25,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:51,740 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2609
en_de Dev loss: 0.8613 r:0.2312
en_zh Dev loss: 0.7956 r:0.4698
Current avg r:0.3505 Best avg r: 0.3808
19:16:08,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:34,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:00,721 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2698
en_de Dev loss: 0.8581 r:0.2285
en_zh Dev loss: 0.8618 r:0.4543
Current avg r:0.3414 Best avg r: 0.3808
19:18:17,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:43,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:09,723 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2814
en_de Dev loss: 0.8898 r:0.2099
en_zh Dev loss: 0.8319 r:0.4639
Current avg r:0.3369 Best avg r: 0.3808
19:20:26,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:52,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:18,629 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2484
en_de Dev loss: 0.9003 r:0.1788
en_zh Dev loss: 0.8477 r:0.4596
Current avg r:0.3192 Best avg r: 0.3808
19:22:35,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:01,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:27,553 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2780
en_de Dev loss: 0.8797 r:0.1946
en_zh Dev loss: 0.7433 r:0.4730
Current avg r:0.3338 Best avg r: 0.3808
19:24:44,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:10,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:36,452 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2617
en_de Dev loss: 0.8784 r:0.1885
en_zh Dev loss: 0.8287 r:0.4607
Current avg r:0.3246 Best avg r: 0.3808
19:26:53,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:19,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:45,474 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2880
en_de Dev loss: 0.8924 r:0.1893
en_zh Dev loss: 0.7657 r:0.4686
Current avg r:0.3289 Best avg r: 0.3808
19:29:02,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:28,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:54,375 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2547
en_de Dev loss: 0.8882 r:0.1762
en_zh Dev loss: 0.7537 r:0.4656
Current avg r:0.3209 Best avg r: 0.3808
19:31:12,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:31:38,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:04,668 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2418
en_de Dev loss: 0.8902 r:0.1904
en_zh Dev loss: 0.7310 r:0.4843
Current avg r:0.3373 Best avg r: 0.3808
19:33:21,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:47,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:13,554 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2606
en_de Dev loss: 0.9035 r:0.1792
en_zh Dev loss: 0.8213 r:0.4702
Current avg r:0.3247 Best avg r: 0.3808
19:35:30,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:56,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:22,736 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2444
en_de Dev loss: 0.8811 r:0.1964
en_zh Dev loss: 0.7682 r:0.4762
Current avg r:0.3363 Best avg r: 0.3808
19:37:39,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:05,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:31,742 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2346
en_de Dev loss: 0.8780 r:0.1971
en_zh Dev loss: 0.7568 r:0.4753
Current avg r:0.3362 Best avg r: 0.3808
19:39:48,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:14,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:40,783 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2475
en_de Dev loss: 0.8983 r:0.2177
en_zh Dev loss: 0.8845 r:0.4460
Current avg r:0.3318 Best avg r: 0.3808
19:41:58,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:23,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:49,893 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2775
en_de Dev loss: 0.9045 r:0.1784
en_zh Dev loss: 0.7889 r:0.4625
Current avg r:0.3205 Best avg r: 0.3808
19:44:07,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:33,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:59,97 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2379
en_de Dev loss: 0.9119 r:0.1900
en_zh Dev loss: 0.7962 r:0.4679
Current avg r:0.3289 Best avg r: 0.3808
19:46:16,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:42,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:08,16 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2296
en_de Dev loss: 0.8823 r:0.1774
en_zh Dev loss: 0.7372 r:0.4687
Current avg r:0.3231 Best avg r: 0.3808
19:48:25,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:50,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:16,878 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2336
en_de Dev loss: 0.9013 r:0.2023
en_zh Dev loss: 0.7860 r:0.4682
Current avg r:0.3352 Best avg r: 0.3808
19:50:33,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:59,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:25,688 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2442
en_de Dev loss: 0.8938 r:0.1963
en_zh Dev loss: 0.7715 r:0.4638
Current avg r:0.3300 Best avg r: 0.3808
19:52:42,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:08,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:34,587 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2111
en_de Dev loss: 0.8948 r:0.2062
en_zh Dev loss: 0.7638 r:0.4755
Current avg r:0.3409 Best avg r: 0.3808
19:54:51,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:17,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:43,452 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2616
en_de Dev loss: 0.8961 r:0.1963
en_zh Dev loss: 0.7852 r:0.4687
Current avg r:0.3325 Best avg r: 0.3808
19:57:00,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:26,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:52,378 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2290
en_de Dev loss: 0.9110 r:0.1981
en_zh Dev loss: 0.7992 r:0.4688
Current avg r:0.3334 Best avg r: 0.3808
19:59:09,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:35,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:01,555 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2316
en_de Dev loss: 0.9073 r:0.1824
en_zh Dev loss: 0.8304 r:0.4642
Current avg r:0.3233 Best avg r: 0.3808
20:01:18,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:01:44,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:10,424 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2518
en_de Dev loss: 0.9020 r:0.1766
en_zh Dev loss: 0.8385 r:0.4618
Current avg r:0.3192 Best avg r: 0.3808
20:03:27,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:53,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:19,473 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2405
en_de Dev loss: 0.9060 r:0.2000
en_zh Dev loss: 0.7869 r:0.4724
Current avg r:0.3362 Best avg r: 0.3808
20:05:36,683 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:02,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:28,573 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2297
en_de Dev loss: 0.9212 r:0.1762
en_zh Dev loss: 0.8662 r:0.4618
Current avg r:0.3190 Best avg r: 0.3808
20:07:47,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:13,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:39,42 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2153
en_de Dev loss: 0.9229 r:0.1721
en_zh Dev loss: 0.8210 r:0.4651
Current avg r:0.3186 Best avg r: 0.3808
20:09:56,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:10:21,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:47,929 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2117
en_de Dev loss: 0.9839 r:0.1577
en_zh Dev loss: 0.9029 r:0.4560
Current avg r:0.3068 Best avg r: 0.3808
20:12:05,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:31,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:57,45 root INFO Epoch 9 Global steps: 29800 Train loss: 0.2200
en_de Dev loss: 0.9063 r:0.1648
en_zh Dev loss: 0.8013 r:0.4639
Current avg r:0.3144 Best avg r: 0.3808
20:14:14,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:39,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:05,901 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2215
en_de Dev loss: 0.9228 r:0.1831
en_zh Dev loss: 0.8176 r:0.4683
Current avg r:0.3257 Best avg r: 0.3808
20:16:23,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:49,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:15,196 root INFO Epoch 10 Global steps: 30200 Train loss: 0.2151
en_de Dev loss: 0.9255 r:0.2052
en_zh Dev loss: 0.7923 r:0.4744
Current avg r:0.3398 Best avg r: 0.3808
20:18:32,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:58,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:24,163 root INFO Epoch 10 Global steps: 30400 Train loss: 0.1946
en_de Dev loss: 0.9347 r:0.1859
en_zh Dev loss: 0.8199 r:0.4763
Current avg r:0.3311 Best avg r: 0.3808
20:20:41,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:07,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:33,138 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2053
en_de Dev loss: 0.9189 r:0.1938
en_zh Dev loss: 0.8362 r:0.4688
Current avg r:0.3313 Best avg r: 0.3808
20:22:50,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:16,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:42,160 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1997
en_de Dev loss: 0.9151 r:0.1771
en_zh Dev loss: 0.8132 r:0.4685
Current avg r:0.3228 Best avg r: 0.3808
20:24:59,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:25,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:51,9 root INFO Epoch 10 Global steps: 31000 Train loss: 0.2075
en_de Dev loss: 0.9000 r:0.1896
en_zh Dev loss: 0.7561 r:0.4769
Current avg r:0.3332 Best avg r: 0.3808
20:27:08,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:33,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:59,845 root INFO Epoch 10 Global steps: 31200 Train loss: 0.2046
en_de Dev loss: 0.9446 r:0.1852
en_zh Dev loss: 0.8546 r:0.4682
Current avg r:0.3267 Best avg r: 0.3808
20:29:16,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:42,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:08,743 root INFO Epoch 10 Global steps: 31400 Train loss: 0.2207
en_de Dev loss: 0.9065 r:0.1719
en_zh Dev loss: 0.7864 r:0.4635
Current avg r:0.3177 Best avg r: 0.3808
20:31:25,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:51,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:18,182 root INFO Epoch 10 Global steps: 31600 Train loss: 0.2104
en_de Dev loss: 0.9195 r:0.1812
en_zh Dev loss: 0.7647 r:0.4715
Current avg r:0.3264 Best avg r: 0.3808
20:33:36,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:02,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:34:28,456 root INFO Epoch 10 Global steps: 31800 Train loss: 0.2201
en_de Dev loss: 0.9151 r:0.1775
en_zh Dev loss: 0.8095 r:0.4610
Current avg r:0.3193 Best avg r: 0.3808
20:35:45,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:11,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:37,416 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1986
en_de Dev loss: 0.9279 r:0.1736
en_zh Dev loss: 0.7569 r:0.4770
Current avg r:0.3253 Best avg r: 0.3808
20:37:54,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:20,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:46,660 root INFO Epoch 10 Global steps: 32200 Train loss: 0.2185
en_de Dev loss: 0.9677 r:0.1724
en_zh Dev loss: 0.8884 r:0.4570
Current avg r:0.3147 Best avg r: 0.3808
20:40:03,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:31,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:57,64 root INFO Epoch 10 Global steps: 32400 Train loss: 0.2045
en_de Dev loss: 0.9289 r:0.1669
en_zh Dev loss: 0.8354 r:0.4576
Current avg r:0.3123 Best avg r: 0.3808
20:42:14,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:40,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:06,504 root INFO Epoch 10 Global steps: 32600 Train loss: 0.2154
en_de Dev loss: 0.9006 r:0.1715
en_zh Dev loss: 0.8391 r:0.4523
Current avg r:0.3119 Best avg r: 0.3808
20:44:23,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:49,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:15,602 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1887
en_de Dev loss: 0.8979 r:0.1673
en_zh Dev loss: 0.7869 r:0.4633
Current avg r:0.3153 Best avg r: 0.3808
20:46:32,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:58,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:24,470 root INFO Epoch 10 Global steps: 33000 Train loss: 0.2187
en_de Dev loss: 0.9354 r:0.1908
en_zh Dev loss: 0.8682 r:0.4545
Current avg r:0.3227 Best avg r: 0.3808
20:48:42,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:08,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:33,990 root INFO Epoch 11 Global steps: 33200 Train loss: 0.2025
en_de Dev loss: 0.9054 r:0.2054
en_zh Dev loss: 0.8079 r:0.4667
Current avg r:0.3360 Best avg r: 0.3808
20:50:51,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:16,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:42,886 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1784
en_de Dev loss: 0.9087 r:0.1826
en_zh Dev loss: 0.8046 r:0.4702
Current avg r:0.3264 Best avg r: 0.3808
20:52:59,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:25,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:51,819 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1782
en_de Dev loss: 0.9232 r:0.1992
en_zh Dev loss: 0.8564 r:0.4656
Current avg r:0.3324 Best avg r: 0.3808
20:55:08,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:34,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:00,694 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1880
en_de Dev loss: 0.8909 r:0.1880
en_zh Dev loss: 0.7554 r:0.4687
Current avg r:0.3283 Best avg r: 0.3808
20:57:17,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:44,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:10,868 root INFO Epoch 11 Global steps: 34000 Train loss: 0.2155
en_de Dev loss: 0.9070 r:0.1797
en_zh Dev loss: 0.8304 r:0.4630
Current avg r:0.3213 Best avg r: 0.3808
20:59:27,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:53,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:19,740 root INFO Epoch 11 Global steps: 34200 Train loss: 0.2064
en_de Dev loss: 0.8944 r:0.2116
en_zh Dev loss: 0.7688 r:0.4762
Current avg r:0.3439 Best avg r: 0.3808
21:01:36,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:02,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:30,26 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1993
en_de Dev loss: 0.8972 r:0.2060
en_zh Dev loss: 0.8289 r:0.4665
Current avg r:0.3363 Best avg r: 0.3808
21:03:47,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:12,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:38,911 root INFO Epoch 11 Global steps: 34600 Train loss: 0.2060
en_de Dev loss: 0.9182 r:0.1942
en_zh Dev loss: 0.8230 r:0.4627
Current avg r:0.3285 Best avg r: 0.3808
21:05:56,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:21,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:47,840 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1910
en_de Dev loss: 0.9154 r:0.2199
en_zh Dev loss: 0.8529 r:0.4612
Current avg r:0.3406 Best avg r: 0.3808
21:08:04,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:30,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:56,683 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1955
en_de Dev loss: 0.9144 r:0.1910
en_zh Dev loss: 0.8163 r:0.4596
Current avg r:0.3253 Best avg r: 0.3808
21:10:13,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:39,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:05,625 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1747
en_de Dev loss: 0.9001 r:0.1971
en_zh Dev loss: 0.7612 r:0.4697
Current avg r:0.3334 Best avg r: 0.3808
21:12:22,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:48,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:14,543 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1822
en_de Dev loss: 0.9317 r:0.2098
en_zh Dev loss: 0.8355 r:0.4710
Current avg r:0.3404 Best avg r: 0.3808
21:14:31,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:57,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:23,554 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1866
en_de Dev loss: 0.9027 r:0.2027
en_zh Dev loss: 0.8377 r:0.4644
Current avg r:0.3335 Best avg r: 0.3808
21:16:40,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:06,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:32,777 root INFO Epoch 11 Global steps: 35800 Train loss: 0.2034
en_de Dev loss: 0.9407 r:0.2140
en_zh Dev loss: 0.8696 r:0.4636
Current avg r:0.3388 Best avg r: 0.3808
21:18:50,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:15,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:41,886 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1903
en_de Dev loss: 0.8974 r:0.1946
en_zh Dev loss: 0.7791 r:0.4696
Current avg r:0.3321 Best avg r: 0.3808
21:20:59,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:25,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:51,166 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1943
en_de Dev loss: 0.9273 r:0.1876
en_zh Dev loss: 0.7229 r:0.4881
Current avg r:0.3379 Best avg r: 0.3808
21:23:08,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:34,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:00,212 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1851
en_de Dev loss: 0.9290 r:0.1884
en_zh Dev loss: 0.8377 r:0.4665
Current avg r:0.3275 Best avg r: 0.3808
21:25:17,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:43,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:09,100 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1497
en_de Dev loss: 0.9682 r:0.1873
en_zh Dev loss: 0.8062 r:0.4737
Current avg r:0.3305 Best avg r: 0.3808
21:27:26,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:52,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:28:19,364 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1657
en_de Dev loss: 0.9271 r:0.1863
en_zh Dev loss: 0.8020 r:0.4669
Current avg r:0.3266 Best avg r: 0.3808
21:29:36,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:02,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:30:28,284 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1664
en_de Dev loss: 0.9486 r:0.1805
en_zh Dev loss: 0.8037 r:0.4708
Current avg r:0.3256 Best avg r: 0.3808
21:31:45,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:11,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:37,120 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1602
en_de Dev loss: 0.9474 r:0.1640
en_zh Dev loss: 0.8003 r:0.4642
Current avg r:0.3141 Best avg r: 0.3808
21:33:54,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:20,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:46,77 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1639
en_de Dev loss: 0.9481 r:0.1891
en_zh Dev loss: 0.8066 r:0.4692
Current avg r:0.3292 Best avg r: 0.3808
21:36:03,153 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:29,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:54,998 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1842
en_de Dev loss: 0.9232 r:0.1810
en_zh Dev loss: 0.8025 r:0.4588
Current avg r:0.3199 Best avg r: 0.3808
21:38:12,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:37,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:03,862 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1870
en_de Dev loss: 0.9202 r:0.1745
en_zh Dev loss: 0.7745 r:0.4535
Current avg r:0.3140 Best avg r: 0.3808
21:40:20,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:46,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:12,808 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1815
en_de Dev loss: 0.9252 r:0.1754
en_zh Dev loss: 0.8431 r:0.4494
Current avg r:0.3124 Best avg r: 0.3808
21:42:29,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:55,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:21,720 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1666
en_de Dev loss: 0.9236 r:0.2048
en_zh Dev loss: 0.8154 r:0.4620
Current avg r:0.3334 Best avg r: 0.3808
21:44:38,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:04,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:30,583 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1612
en_de Dev loss: 0.9189 r:0.2247
en_zh Dev loss: 0.9322 r:0.4464
Current avg r:0.3355 Best avg r: 0.3808
21:46:47,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:13,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:47:39,562 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1689
en_de Dev loss: 0.9148 r:0.2236
en_zh Dev loss: 0.8058 r:0.4553
Current avg r:0.3395 Best avg r: 0.3808
21:48:56,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:22,546 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:48,467 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1686
en_de Dev loss: 0.9013 r:0.2175
en_zh Dev loss: 0.8109 r:0.4631
Current avg r:0.3403 Best avg r: 0.3808
21:51:05,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:31,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:57,363 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1711
en_de Dev loss: 0.9017 r:0.2164
en_zh Dev loss: 0.8043 r:0.4614
Current avg r:0.3389 Best avg r: 0.3808
21:53:14,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:40,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:06,781 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1506
en_de Dev loss: 0.9034 r:0.2148
en_zh Dev loss: 0.8088 r:0.4650
Current avg r:0.3399 Best avg r: 0.3808
21:55:24,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:49,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:15,912 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1706
en_de Dev loss: 0.8925 r:0.2138
en_zh Dev loss: 0.7556 r:0.4796
Current avg r:0.3467 Best avg r: 0.3808
21:57:32,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:58,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:24,834 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1500
en_de Dev loss: 0.8967 r:0.2146
en_zh Dev loss: 0.8189 r:0.4646
Current avg r:0.3396 Best avg r: 0.3808
21:59:41,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:07,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:33,725 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1570
en_de Dev loss: 0.9250 r:0.2092
en_zh Dev loss: 0.8073 r:0.4708
Current avg r:0.3400 Best avg r: 0.3808
22:01:50,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:16,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:42,655 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1562
en_de Dev loss: 0.9232 r:0.2092
en_zh Dev loss: 0.8635 r:0.4632
Current avg r:0.3362 Best avg r: 0.3808
22:03:59,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:25,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:51,619 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1579
en_de Dev loss: 0.9343 r:0.2034
en_zh Dev loss: 0.8683 r:0.4571
Current avg r:0.3303 Best avg r: 0.3808
22:06:08,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:34,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:00,574 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1459
en_de Dev loss: 0.9223 r:0.2123
en_zh Dev loss: 0.7691 r:0.4746
Current avg r:0.3434 Best avg r: 0.3808
22:08:17,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:43,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:09,510 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1690
en_de Dev loss: 0.9253 r:0.2039
en_zh Dev loss: 0.8033 r:0.4702
Current avg r:0.3371 Best avg r: 0.3808
22:10:26,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:52,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:18,508 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1680
en_de Dev loss: 0.9257 r:0.1966
en_zh Dev loss: 0.7730 r:0.4723
Current avg r:0.3345 Best avg r: 0.3808
22:12:35,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:01,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:27,462 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1461
en_de Dev loss: 0.9830 r:0.1925
en_zh Dev loss: 0.8314 r:0.4697
Current avg r:0.3311 Best avg r: 0.3808
22:14:44,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:10,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:36,329 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1432
en_de Dev loss: 0.9130 r:0.2096
en_zh Dev loss: 0.7914 r:0.4756
Current avg r:0.3426 Best avg r: 0.3808
22:16:53,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:19,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:45,384 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1537
en_de Dev loss: 0.9168 r:0.2049
en_zh Dev loss: 0.7738 r:0.4736
Current avg r:0.3393 Best avg r: 0.3808
22:19:02,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:28,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:54,344 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1510
en_de Dev loss: 0.8963 r:0.1802
en_zh Dev loss: 0.7922 r:0.4676
Current avg r:0.3239 Best avg r: 0.3808
22:21:12,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:38,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:04,610 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1467
en_de Dev loss: 0.9025 r:0.2074
en_zh Dev loss: 0.8213 r:0.4633
Current avg r:0.3354 Best avg r: 0.3808
22:23:21,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:47,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:13,886 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1463
en_de Dev loss: 0.8950 r:0.2249
en_zh Dev loss: 0.7709 r:0.4732
Current avg r:0.3490 Best avg r: 0.3808
22:25:31,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:57,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:23,176 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1424
en_de Dev loss: 0.8971 r:0.1928
en_zh Dev loss: 0.7578 r:0.4721
Current avg r:0.3325 Best avg r: 0.3808
22:27:40,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:06,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:28:32,112 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1550
en_de Dev loss: 0.9103 r:0.1969
en_zh Dev loss: 0.7833 r:0.4765
Current avg r:0.3367 Best avg r: 0.3808
22:29:49,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:16,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:42,313 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1537
en_de Dev loss: 0.9102 r:0.1916
en_zh Dev loss: 0.7838 r:0.4742
Current avg r:0.3329 Best avg r: 0.3808
22:31:59,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:25,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:51,129 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1386
en_de Dev loss: 0.9260 r:0.1896
en_zh Dev loss: 0.7840 r:0.4775
Current avg r:0.3336 Best avg r: 0.3808
22:34:08,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:34,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:00,460 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1305
en_de Dev loss: 0.9339 r:0.2093
en_zh Dev loss: 0.8104 r:0.4776
Current avg r:0.3435 Best avg r: 0.3808
22:36:17,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:43,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:09,786 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1374
en_de Dev loss: 0.9322 r:0.2118
en_zh Dev loss: 0.8272 r:0.4779
Current avg r:0.3449 Best avg r: 0.3808
22:38:26,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:52,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:18,642 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1443
en_de Dev loss: 0.9090 r:0.2066
en_zh Dev loss: 0.7659 r:0.4832
Current avg r:0.3449 Best avg r: 0.3808
22:40:37,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:02,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:28,777 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1533
en_de Dev loss: 0.9374 r:0.1985
en_zh Dev loss: 0.7924 r:0.4838
Current avg r:0.3412 Best avg r: 0.3808
22:42:45,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:11,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:43:37,482 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1389
en_de Dev loss: 0.9375 r:0.1845
en_zh Dev loss: 0.8857 r:0.4600
Current avg r:0.3222 Best avg r: 0.3808
22:44:54,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:45:20,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:46,243 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1556
en_de Dev loss: 0.9364 r:0.1717
en_zh Dev loss: 0.8772 r:0.4594
Current avg r:0.3155 Best avg r: 0.3808
22:47:03,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:29,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:55,79 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1314
en_de Dev loss: 0.9398 r:0.1820
en_zh Dev loss: 0.8311 r:0.4665
Current avg r:0.3243 Best avg r: 0.3808
22:49:13,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:49:39,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:05,232 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1399
en_de Dev loss: 0.9374 r:0.1865
en_zh Dev loss: 0.8196 r:0.4711
Current avg r:0.3288 Best avg r: 0.3808
22:51:22,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:48,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:14,115 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1312
en_de Dev loss: 0.9316 r:0.1861
en_zh Dev loss: 0.7888 r:0.4748
Current avg r:0.3305 Best avg r: 0.3808
22:53:31,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:57,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:23,67 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1424
en_de Dev loss: 0.9562 r:0.1763
en_zh Dev loss: 0.8155 r:0.4766
Current avg r:0.3265 Best avg r: 0.3808
22:55:40,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:05,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:31,891 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1366
en_de Dev loss: 0.9793 r:0.1842
en_zh Dev loss: 0.8133 r:0.4801
Current avg r:0.3321 Best avg r: 0.3808
22:57:49,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:15,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:42,430 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1236
en_de Dev loss: 0.9432 r:0.1893
en_zh Dev loss: 0.8220 r:0.4773
Current avg r:0.3333 Best avg r: 0.3808
22:59:59,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:00:26,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:52,404 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1184
en_de Dev loss: 0.9571 r:0.1839
en_zh Dev loss: 0.8148 r:0.4780
Current avg r:0.3310 Best avg r: 0.3808
23:02:09,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:35,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:01,69 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1276
en_de Dev loss: 0.9797 r:0.1539
en_zh Dev loss: 0.9378 r:0.4679
Current avg r:0.3109 Best avg r: 0.3808
23:04:18,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:43,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:09,835 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1312
en_de Dev loss: 0.9259 r:0.1907
en_zh Dev loss: 0.7560 r:0.4870
Current avg r:0.3389 Best avg r: 0.3808
23:06:26,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:52,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:18,500 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1351
en_de Dev loss: 0.9579 r:0.1599
en_zh Dev loss: 0.8603 r:0.4785
Current avg r:0.3192 Best avg r: 0.3808
23:08:35,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:09:01,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:09:27,195 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1365
en_de Dev loss: 0.9288 r:0.1997
en_zh Dev loss: 0.7776 r:0.4784
Current avg r:0.3391 Best avg r: 0.3808
23:10:44,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:10,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:35,996 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1231
en_de Dev loss: 0.9421 r:0.1893
en_zh Dev loss: 0.8445 r:0.4666
Current avg r:0.3279 Best avg r: 0.3808
23:12:52,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:18,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:44,634 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1252
en_de Dev loss: 0.9625 r:0.1779
en_zh Dev loss: 0.8370 r:0.4728
Current avg r:0.3254 Best avg r: 0.3808
23:15:01,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:27,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:53,277 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1280
en_de Dev loss: 0.9651 r:0.1743
en_zh Dev loss: 0.7980 r:0.4778
Current avg r:0.3261 Best avg r: 0.3808
23:17:10,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:36,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:04,968 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1224
en_de Dev loss: 0.9476 r:0.1775
en_zh Dev loss: 0.8001 r:0.4730
Current avg r:0.3253 Best avg r: 0.3808
23:19:21,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:47,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:13,590 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1225
en_de Dev loss: 0.9631 r:0.1675
en_zh Dev loss: 0.8028 r:0.4838
Current avg r:0.3256 Best avg r: 0.3808
23:21:30,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:56,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:22,285 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1178
en_de Dev loss: 0.9426 r:0.1616
en_zh Dev loss: 0.7655 r:0.4781
Current avg r:0.3198 Best avg r: 0.3808
23:23:39,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:05,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:24:31,133 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1160
en_de Dev loss: 0.9588 r:0.1673
en_zh Dev loss: 0.7825 r:0.4817
Current avg r:0.3245 Best avg r: 0.3808
23:25:47,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:13,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:39,690 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1212
en_de Dev loss: 0.9766 r:0.1627
en_zh Dev loss: 0.8231 r:0.4722
Current avg r:0.3175 Best avg r: 0.3808
23:27:56,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:22,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:28:48,332 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1286
en_de Dev loss: 0.9873 r:0.1656
en_zh Dev loss: 0.8211 r:0.4790
Current avg r:0.3223 Best avg r: 0.3808
23:30:05,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:31,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:57,464 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1176
en_de Dev loss: 0.9535 r:0.1780
en_zh Dev loss: 0.7401 r:0.4864
Current avg r:0.3322 Best avg r: 0.3808
23:32:14,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:40,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:06,172 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1210
en_de Dev loss: 0.9431 r:0.1595
en_zh Dev loss: 0.7685 r:0.4716
Current avg r:0.3156 Best avg r: 0.3808
23:34:23,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:34:49,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:14,938 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1187
en_de Dev loss: 0.9610 r:0.1664
en_zh Dev loss: 0.7774 r:0.4808
Current avg r:0.3236 Best avg r: 0.3808
23:36:31,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:57,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:23,600 root INFO Epoch 16 Global steps: 48800 Train loss: 0.1161
en_de Dev loss: 0.9844 r:0.1777
en_zh Dev loss: 0.8674 r:0.4662
Current avg r:0.3220 Best avg r: 0.3808
23:38:40,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:06,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:32,302 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1167
en_de Dev loss: 0.9475 r:0.1806
en_zh Dev loss: 0.7951 r:0.4798
Current avg r:0.3302 Best avg r: 0.3808
23:40:49,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:15,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:41,80 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1103
en_de Dev loss: 0.9515 r:0.1706
en_zh Dev loss: 0.8099 r:0.4703
Current avg r:0.3205 Best avg r: 0.3808
23:42:58,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:23,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:49,789 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1072
en_de Dev loss: 0.9498 r:0.1747
en_zh Dev loss: 0.8569 r:0.4720
Current avg r:0.3233 Best avg r: 0.3808
23:45:06,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:32,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:58,565 root INFO Epoch 16 Global steps: 49600 Train loss: 0.1100
en_de Dev loss: 0.9661 r:0.1951
en_zh Dev loss: 0.7978 r:0.4775
Current avg r:0.3363 Best avg r: 0.3808
23:47:16,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:42,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:08,594 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1240
en_de Dev loss: 0.9658 r:0.1570
en_zh Dev loss: 0.7604 r:0.4779
Current avg r:0.3175 Best avg r: 0.3808
23:49:25,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:51,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:17,301 root INFO Epoch 16 Global steps: 50000 Train loss: 0.1155
en_de Dev loss: 0.9612 r:0.1840
en_zh Dev loss: 0.7712 r:0.4837
Current avg r:0.3339 Best avg r: 0.3808
23:51:34,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:00,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:26,91 root INFO Epoch 16 Global steps: 50200 Train loss: 0.1176
en_de Dev loss: 0.9459 r:0.1805
en_zh Dev loss: 0.8151 r:0.4719
Current avg r:0.3262 Best avg r: 0.3808
23:53:43,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:08,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:54:34,794 root INFO Epoch 16 Global steps: 50400 Train loss: 0.1021
en_de Dev loss: 0.9654 r:0.1814
en_zh Dev loss: 0.8085 r:0.4794
Current avg r:0.3304 Best avg r: 0.3808
23:55:51,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:17,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:43,500 root INFO Epoch 16 Global steps: 50600 Train loss: 0.1075
en_de Dev loss: 0.9538 r:0.1482
en_zh Dev loss: 0.8455 r:0.4679
Current avg r:0.3081 Best avg r: 0.3808
23:58:00,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:26,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:52,240 root INFO Epoch 16 Global steps: 50800 Train loss: 0.1098
en_de Dev loss: 0.9780 r:0.1785
en_zh Dev loss: 0.8154 r:0.4697
Current avg r:0.3241 Best avg r: 0.3808
00:00:09,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:00:35,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:00,926 root INFO Epoch 16 Global steps: 51000 Train loss: 0.1162
en_de Dev loss: 0.9564 r:0.1745
en_zh Dev loss: 0.7958 r:0.4730
Current avg r:0.3237 Best avg r: 0.3808
00:02:18,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:44,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:09,971 root INFO Epoch 17 Global steps: 51200 Train loss: 0.1032
en_de Dev loss: 0.9616 r:0.1670
en_zh Dev loss: 0.8643 r:0.4695
Current avg r:0.3183 Best avg r: 0.3808
00:04:26,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:52,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:18,703 root INFO Epoch 17 Global steps: 51400 Train loss: 0.1002
en_de Dev loss: 0.9443 r:0.1775
en_zh Dev loss: 0.7947 r:0.4741
Current avg r:0.3258 Best avg r: 0.3808
00:06:35,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:01,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:27,361 root INFO Epoch 17 Global steps: 51600 Train loss: 0.1033
en_de Dev loss: 0.9504 r:0.1769
en_zh Dev loss: 0.7878 r:0.4759
Current avg r:0.3264 Best avg r: 0.3808
00:08:44,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:10,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:09:36,129 root INFO Epoch 17 Global steps: 51800 Train loss: 0.0993
en_de Dev loss: 0.9638 r:0.1568
en_zh Dev loss: 0.8292 r:0.4628
Current avg r:0.3098 Best avg r: 0.3808
00:10:53,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:18,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:44,827 root INFO Epoch 17 Global steps: 52000 Train loss: 0.1019
en_de Dev loss: 0.9661 r:0.1442
en_zh Dev loss: 0.8070 r:0.4683
Current avg r:0.3062 Best avg r: 0.3808
00:33:59,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:37,970 root INFO 
id:en_zh cur r: 0.1688 best r: 0.1688
00:34:37,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:03,647 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
00:35:03,652 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:35:29,347 root INFO Epoch 0 Global steps: 200 Train loss: 0.8426
en_de Dev loss: 0.8876 r:0.0694
en_zh Dev loss: 0.8016 r:0.1778
Current avg r:0.1236 Best avg r: 0.1236
00:36:45,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:24,145 root INFO 
id:en_zh cur r: 0.2367 best r: 0.2367
00:37:24,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:49,909 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
00:37:49,916 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:38:15,645 root INFO Epoch 0 Global steps: 400 Train loss: 0.8304
en_de Dev loss: 0.8807 r:0.0892
en_zh Dev loss: 0.7909 r:0.2347
Current avg r:0.1619 Best avg r: 0.1619
00:39:31,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:10,381 root INFO 
id:en_zh cur r: 0.2597 best r: 0.2597
00:40:10,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:36,98 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
00:40:36,105 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:41:01,901 root INFO Epoch 0 Global steps: 600 Train loss: 0.7525
en_de Dev loss: 0.8784 r:0.1184
en_zh Dev loss: 0.7850 r:0.2612
Current avg r:0.1898 Best avg r: 0.1898
00:42:18,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:56,867 root INFO 
id:en_zh cur r: 0.2750 best r: 0.2750
00:42:56,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:22,605 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
00:43:22,611 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:43:48,412 root INFO Epoch 0 Global steps: 800 Train loss: 0.6644
en_de Dev loss: 0.8818 r:0.1331
en_zh Dev loss: 0.7887 r:0.2742
Current avg r:0.2036 Best avg r: 0.2036
00:45:04,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:43,339 root INFO 
id:en_zh cur r: 0.2899 best r: 0.2899
00:45:43,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:09,109 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
00:46:09,115 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:46:34,861 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7917
en_de Dev loss: 0.8900 r:0.1492
en_zh Dev loss: 0.7978 r:0.2902
Current avg r:0.2197 Best avg r: 0.2197
00:47:51,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:29,770 root INFO 
id:en_zh cur r: 0.3089 best r: 0.3089
00:48:29,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:48:55,481 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
00:48:55,488 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:49:21,193 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8527
en_de Dev loss: 0.8771 r:0.1632
en_zh Dev loss: 0.7785 r:0.3086
Current avg r:0.2359 Best avg r: 0.2359
00:50:37,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:15,911 root INFO 
id:en_zh cur r: 0.3248 best r: 0.3248
00:51:15,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:51:41,599 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
00:51:41,605 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:52:07,338 root INFO Epoch 0 Global steps: 1400 Train loss: 0.6699
en_de Dev loss: 0.8798 r:0.1684
en_zh Dev loss: 0.7754 r:0.3249
Current avg r:0.2466 Best avg r: 0.2466
00:53:26,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:52,442 root INFO 
id:en_de cur r: 0.1194 best r: 0.1194
00:54:18,95 root INFO 
id:en_zh cur r: 0.3270 best r: 0.3270
00:54:18,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:43,758 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
00:54:43,766 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:55:09,441 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7257
en_de Dev loss: 0.8640 r:0.1788
en_zh Dev loss: 0.7550 r:0.3285
Current avg r:0.2537 Best avg r: 0.2537
00:56:25,549 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:51,303 root INFO 
id:en_de cur r: 0.1773 best r: 0.1773
00:57:17,28 root INFO 
id:en_zh cur r: 0.3404 best r: 0.3404
00:57:17,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:42,792 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
00:57:42,800 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
00:58:08,534 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7500
en_de Dev loss: 0.8628 r:0.1741
en_zh Dev loss: 0.7506 r:0.3456
Current avg r:0.2599 Best avg r: 0.2599
00:59:24,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:03,296 root INFO 
id:en_zh cur r: 0.3612 best r: 0.3612
01:00:03,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:00:29,1 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
01:00:29,7 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:00:54,764 root INFO Epoch 0 Global steps: 2000 Train loss: 0.6631
en_de Dev loss: 0.8682 r:0.1759
en_zh Dev loss: 0.7437 r:0.3601
Current avg r:0.2680 Best avg r: 0.2680
01:02:10,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:02:49,408 root INFO 
id:en_zh cur r: 0.3704 best r: 0.3704
01:02:49,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:15,148 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
01:03:15,155 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:03:40,990 root INFO Epoch 0 Global steps: 2200 Train loss: 0.5955
en_de Dev loss: 0.8586 r:0.1937
en_zh Dev loss: 0.7152 r:0.3681
Current avg r:0.2809 Best avg r: 0.2809
01:05:00,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:26,225 root INFO 
id:en_de cur r: 0.1900 best r: 0.1900
01:05:51,949 root INFO 
id:en_zh cur r: 0.3844 best r: 0.3844
01:05:51,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:17,694 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
01:06:17,701 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:06:43,460 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7913
en_de Dev loss: 0.8527 r:0.2045
en_zh Dev loss: 0.7117 r:0.3725
Current avg r:0.2885 Best avg r: 0.2885
01:07:59,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:38,65 root INFO 
id:en_zh cur r: 0.4054 best r: 0.4054
01:08:38,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:09:03,751 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
01:09:03,758 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:09:29,448 root INFO Epoch 0 Global steps: 2600 Train loss: 0.7154
en_de Dev loss: 0.8514 r:0.2051
en_zh Dev loss: 0.6978 r:0.3985
Current avg r:0.3018 Best avg r: 0.3018
01:10:45,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:24,70 root INFO 
id:en_zh cur r: 0.4093 best r: 0.4093
01:11:24,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:49,730 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
01:11:49,737 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:12:15,464 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6797
en_de Dev loss: 0.8502 r:0.2036
en_zh Dev loss: 0.6925 r:0.4002
Current avg r:0.3019 Best avg r: 0.3019
01:13:34,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:13,345 root INFO 
id:en_zh cur r: 0.4102 best r: 0.4102
01:14:13,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:39,55 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
01:14:39,61 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:15:04,785 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7763
en_de Dev loss: 0.8554 r:0.1934
en_zh Dev loss: 0.6993 r:0.4113
Current avg r:0.3024 Best avg r: 0.3024
01:16:23,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:01,970 root INFO 
id:en_zh cur r: 0.4406 best r: 0.4406
01:17:01,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:27,732 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
01:17:27,738 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
01:17:53,505 root INFO Epoch 1 Global steps: 3200 Train loss: 0.7312
en_de Dev loss: 0.8583 r:0.1965
en_zh Dev loss: 0.6633 r:0.4408
Current avg r:0.3187 Best avg r: 0.3187
01:19:09,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:48,321 root INFO 
id:en_zh cur r: 0.4473 best r: 0.4473
01:19:48,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:16,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:07:42,508 root INFO 
id:en_de cur r: 0.0372 best r: 0.0372
10:08:08,568 root INFO 
id:en_zh cur r: 0.0443 best r: 0.0443
10:08:08,568 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:08:34,585 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:08:34,597 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:09:00,655 root INFO Epoch 0 Global steps: 200 Train loss: 0.8594
en_de Dev loss: 0.8890 r:0.0057
en_zh Dev loss: 0.8183 r:0.0402
Current avg r:0.0230 Best avg r: 0.0230
10:10:17,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:43,626 root INFO 
id:en_de cur r: 0.0468 best r: 0.0468
10:11:09,657 root INFO 
id:en_zh cur r: 0.0918 best r: 0.0918
10:11:09,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:35,709 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:11:35,722 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:12:01,787 root INFO Epoch 0 Global steps: 400 Train loss: 0.8295
en_de Dev loss: 0.8867 r:0.0319
en_zh Dev loss: 0.8169 r:0.0635
Current avg r:0.0477 Best avg r: 0.0477
10:13:18,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:44,750 root INFO 
id:en_de cur r: 0.0573 best r: 0.0573
10:14:10,774 root INFO 
id:en_zh cur r: 0.1200 best r: 0.1200
10:14:10,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:36,805 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:14:36,813 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:15:02,885 root INFO Epoch 0 Global steps: 600 Train loss: 0.8228
en_de Dev loss: 0.8888 r:0.0554
en_zh Dev loss: 0.8166 r:0.0956
Current avg r:0.0755 Best avg r: 0.0755
10:16:19,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:45,948 root INFO 
id:en_de cur r: 0.0679 best r: 0.0679
10:17:12,14 root INFO 
id:en_zh cur r: 0.1641 best r: 0.1641
10:17:12,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:38,55 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:17:38,62 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:18:04,127 root INFO Epoch 0 Global steps: 800 Train loss: 0.7927
en_de Dev loss: 0.8893 r:0.1022
en_zh Dev loss: 0.8169 r:0.1367
Current avg r:0.1194 Best avg r: 0.1194
10:19:20,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:00,35 root INFO 
id:en_zh cur r: 0.2169 best r: 0.2169
10:20:00,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:26,73 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:20:26,89 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:20:52,201 root INFO Epoch 0 Global steps: 1000 Train loss: 0.6680
en_de Dev loss: 0.8840 r:0.1225
en_zh Dev loss: 0.8142 r:0.2103
Current avg r:0.1664 Best avg r: 0.1664
10:22:09,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:22:48,172 root INFO 
id:en_zh cur r: 0.2266 best r: 0.2266
10:22:48,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:14,217 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:23:14,223 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:23:40,286 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8094
en_de Dev loss: 0.8830 r:0.1326
en_zh Dev loss: 0.8109 r:0.2351
Current avg r:0.1839 Best avg r: 0.1839
10:24:57,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:23,214 root INFO 
id:en_de cur r: 0.0716 best r: 0.0716
10:25:49,246 root INFO 
id:en_zh cur r: 0.2632 best r: 0.2632
10:25:49,247 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:15,289 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:26:15,296 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:26:41,357 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7218
en_de Dev loss: 0.8818 r:0.1441
en_zh Dev loss: 0.8067 r:0.2634
Current avg r:0.2037 Best avg r: 0.2037
10:27:58,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:24,276 root INFO 
id:en_de cur r: 0.0978 best r: 0.0978
10:28:50,328 root INFO 
id:en_zh cur r: 0.2906 best r: 0.2906
10:28:50,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:16,377 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:29:16,388 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:29:42,468 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7489
en_de Dev loss: 0.8760 r:0.1400
en_zh Dev loss: 0.7954 r:0.2804
Current avg r:0.2102 Best avg r: 0.2102
10:30:59,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:31:25,347 root INFO 
id:en_de cur r: 0.1340 best r: 0.1340
10:31:51,396 root INFO 
id:en_zh cur r: 0.3161 best r: 0.3161
10:31:51,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:32:17,423 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:32:17,435 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:32:43,488 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7001
en_de Dev loss: 0.8753 r:0.1622
en_zh Dev loss: 0.7913 r:0.3041
Current avg r:0.2331 Best avg r: 0.2331
10:34:00,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:34:26,401 root INFO 
id:en_de cur r: 0.1494 best r: 0.1494
10:34:52,463 root INFO 
id:en_zh cur r: 0.3435 best r: 0.3435
10:34:52,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:35:18,494 root INFO Epoch 0 Global steps: 2000 Train loss: 0.6729
en_de Dev loss: 0.8950 r:0.1457
en_zh Dev loss: 0.8221 r:0.2702
Current avg r:0.2080 Best avg r: 0.2331
10:36:35,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:37:01,363 root INFO 
id:en_de cur r: 0.1617 best r: 0.1617
10:37:27,382 root INFO 
id:en_zh cur r: 0.3513 best r: 0.3513
10:37:27,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:37:53,421 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:37:53,429 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:38:19,490 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7268
en_de Dev loss: 0.8840 r:0.1648
en_zh Dev loss: 0.8057 r:0.3175
Current avg r:0.2412 Best avg r: 0.2412
10:39:36,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:40:02,358 root INFO 
id:en_de cur r: 0.1756 best r: 0.1756
10:40:28,394 root INFO 
id:en_zh cur r: 0.3684 best r: 0.3684
10:40:28,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:40:54,444 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:40:54,450 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:41:20,499 root INFO Epoch 0 Global steps: 2400 Train loss: 0.8129
en_de Dev loss: 0.8720 r:0.1788
en_zh Dev loss: 0.7736 r:0.3349
Current avg r:0.2568 Best avg r: 0.2568
10:42:37,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:43:16,303 root INFO 
id:en_zh cur r: 0.3770 best r: 0.3770
10:43:16,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:43:42,341 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:43:42,349 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:44:08,421 root INFO Epoch 0 Global steps: 2600 Train loss: 0.7564
en_de Dev loss: 0.8627 r:0.1672
en_zh Dev loss: 0.7219 r:0.3851
Current avg r:0.2761 Best avg r: 0.2761
10:45:25,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:45:51,365 root INFO 
id:en_de cur r: 0.1862 best r: 0.1862
10:46:17,412 root INFO 
id:en_zh cur r: 0.4030 best r: 0.4030
10:46:17,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:46:43,467 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:46:43,474 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:47:09,552 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7211
en_de Dev loss: 0.8739 r:0.1990
en_zh Dev loss: 0.7430 r:0.3814
Current avg r:0.2902 Best avg r: 0.2902
10:48:26,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:48:52,488 root INFO 
id:en_de cur r: 0.2272 best r: 0.2272
10:49:18,548 root INFO 
id:en_zh cur r: 0.4119 best r: 0.4119
10:49:18,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:49:44,590 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:49:44,619 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:50:10,722 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6358
en_de Dev loss: 0.8903 r:0.2037
en_zh Dev loss: 0.7558 r:0.3852
Current avg r:0.2944 Best avg r: 0.2944
10:51:27,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:52:07,31 root INFO 
id:en_zh cur r: 0.4268 best r: 0.4268
10:52:07,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:52:33,90 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:52:33,126 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:52:59,237 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6610
en_de Dev loss: 0.8682 r:0.2047
en_zh Dev loss: 0.7329 r:0.4053
Current avg r:0.3050 Best avg r: 0.3050
10:54:16,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:54:55,173 root INFO 
id:en_zh cur r: 0.4288 best r: 0.4288
10:54:55,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:55:21,219 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:55:21,249 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:55:47,319 root INFO Epoch 1 Global steps: 3400 Train loss: 0.7509
en_de Dev loss: 0.8603 r:0.2078
en_zh Dev loss: 0.7319 r:0.4142
Current avg r:0.3110 Best avg r: 0.3110
10:57:04,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:57:43,251 root INFO 
id:en_zh cur r: 0.4416 best r: 0.4416
10:57:43,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:58:09,321 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
10:58:09,327 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
10:58:35,420 root INFO Epoch 1 Global steps: 3600 Train loss: 0.6719
en_de Dev loss: 0.8627 r:0.2117
en_zh Dev loss: 0.7037 r:0.4252
Current avg r:0.3185 Best avg r: 0.3185
10:59:52,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:00:18,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:00:44,413 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
11:00:44,420 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:01:10,479 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6665
en_de Dev loss: 0.8889 r:0.2166
en_zh Dev loss: 0.7654 r:0.4262
Current avg r:0.3214 Best avg r: 0.3214
11:02:27,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:02:53,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:03:19,430 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
11:03:19,447 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:03:45,552 root INFO Epoch 1 Global steps: 4000 Train loss: 0.5736
en_de Dev loss: 0.8739 r:0.2219
en_zh Dev loss: 0.6977 r:0.4218
Current avg r:0.3218 Best avg r: 0.3218
11:05:02,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:05:41,594 root INFO 
id:en_zh cur r: 0.4483 best r: 0.4483
11:05:41,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:06:07,647 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
11:06:07,655 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:06:33,752 root INFO Epoch 1 Global steps: 4200 Train loss: 0.7942
en_de Dev loss: 0.8513 r:0.2115
en_zh Dev loss: 0.6608 r:0.4397
Current avg r:0.3256 Best avg r: 0.3256
11:07:50,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:08:29,665 root INFO 
id:en_zh cur r: 0.4534 best r: 0.4534
11:08:29,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:08:55,707 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
11:08:55,715 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:09:21,790 root INFO Epoch 1 Global steps: 4400 Train loss: 0.6442
en_de Dev loss: 0.8539 r:0.2075
en_zh Dev loss: 0.6867 r:0.4463
Current avg r:0.3269 Best avg r: 0.3269
11:10:38,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:11:17,828 root INFO 
id:en_zh cur r: 0.4647 best r: 0.4647
11:11:17,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:11:43,889 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
11:11:43,896 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:12:09,987 root INFO Epoch 1 Global steps: 4600 Train loss: 0.5733
en_de Dev loss: 0.8601 r:0.2184
en_zh Dev loss: 0.6857 r:0.4566
Current avg r:0.3375 Best avg r: 0.3375
11:13:26,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:13:52,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:14:18,935 root INFO Epoch 1 Global steps: 4800 Train loss: 0.7861
en_de Dev loss: 0.8489 r:0.2106
en_zh Dev loss: 0.7293 r:0.4413
Current avg r:0.3260 Best avg r: 0.3375
11:15:35,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:16:01,908 root INFO 
id:en_de cur r: 0.2367 best r: 0.2367
11:16:14,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:16:40,988 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
11:16:41,20 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:17:07,97 root INFO Epoch 1 Global steps: 5000 Train loss: 0.6236
en_de Dev loss: 0.8509 r:0.2251
en_zh Dev loss: 0.6826 r:0.4542
Current avg r:0.3396 Best avg r: 0.3396
11:18:23,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:18:50,83 root INFO 
id:en_de cur r: 0.2374 best r: 0.2374
11:19:16,115 root INFO 
id:en_zh cur r: 0.4720 best r: 0.4720
11:19:16,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:19:42,168 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
11:19:42,174 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:20:08,248 root INFO Epoch 1 Global steps: 5200 Train loss: 0.6230
en_de Dev loss: 0.8519 r:0.2246
en_zh Dev loss: 0.6675 r:0.4628
Current avg r:0.3437 Best avg r: 0.3437
11:21:25,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:21:51,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:22:17,282 root INFO Epoch 1 Global steps: 5400 Train loss: 0.6408
en_de Dev loss: 0.8594 r:0.2247
en_zh Dev loss: 0.7293 r:0.4488
Current avg r:0.3367 Best avg r: 0.3437
11:23:34,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:24:00,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:24:26,260 root INFO Epoch 1 Global steps: 5600 Train loss: 0.5477
en_de Dev loss: 0.8526 r:0.2231
en_zh Dev loss: 0.6854 r:0.4621
Current avg r:0.3426 Best avg r: 0.3437
11:25:43,105 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:26:09,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:26:35,193 root INFO Epoch 1 Global steps: 5800 Train loss: 0.7142
en_de Dev loss: 0.8616 r:0.2325
en_zh Dev loss: 0.7265 r:0.4410
Current avg r:0.3368 Best avg r: 0.3437
11:27:52,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:28:18,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:28:44,208 root INFO Epoch 1 Global steps: 6000 Train loss: 0.5305
en_de Dev loss: 0.8597 r:0.2281
en_zh Dev loss: 0.7275 r:0.4326
Current avg r:0.3303 Best avg r: 0.3437
11:30:01,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:30:27,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:30:53,557 root INFO Epoch 2 Global steps: 6200 Train loss: 0.6116
en_de Dev loss: 0.8709 r:0.2239
en_zh Dev loss: 0.7578 r:0.4456
Current avg r:0.3347 Best avg r: 0.3437
11:32:10,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:32:49,464 root INFO 
id:en_zh cur r: 0.4779 best r: 0.4779
11:32:49,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:33:15,499 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
11:33:15,506 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:33:41,596 root INFO Epoch 2 Global steps: 6400 Train loss: 0.6296
en_de Dev loss: 0.8634 r:0.2259
en_zh Dev loss: 0.7103 r:0.4733
Current avg r:0.3496 Best avg r: 0.3496
11:34:58,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:35:37,573 root INFO 
id:en_zh cur r: 0.4853 best r: 0.4853
11:35:37,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:36:03,615 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
11:36:03,637 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:36:29,738 root INFO Epoch 2 Global steps: 6600 Train loss: 0.6193
en_de Dev loss: 0.8548 r:0.2225
en_zh Dev loss: 0.6614 r:0.4802
Current avg r:0.3513 Best avg r: 0.3513
11:37:46,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:38:12,603 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:38:38,642 root INFO Epoch 2 Global steps: 6800 Train loss: 0.6627
en_de Dev loss: 0.8517 r:0.2219
en_zh Dev loss: 0.6814 r:0.4727
Current avg r:0.3473 Best avg r: 0.3513
11:39:55,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:40:21,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:40:47,634 root INFO Epoch 2 Global steps: 7000 Train loss: 0.6312
en_de Dev loss: 0.8523 r:0.2267
en_zh Dev loss: 0.6793 r:0.4656
Current avg r:0.3461 Best avg r: 0.3513
11:42:04,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:42:30,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:42:56,569 root INFO Epoch 2 Global steps: 7200 Train loss: 0.5522
en_de Dev loss: 0.8752 r:0.2310
en_zh Dev loss: 0.8081 r:0.4362
Current avg r:0.3336 Best avg r: 0.3513
11:44:13,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:44:39,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:45:05,501 root INFO Epoch 2 Global steps: 7400 Train loss: 0.6016
en_de Dev loss: 0.8499 r:0.2409
en_zh Dev loss: 0.6834 r:0.4562
Current avg r:0.3486 Best avg r: 0.3513
11:46:22,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:46:48,501 root INFO 
id:en_de cur r: 0.2444 best r: 0.2444
11:47:01,527 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:47:27,573 root INFO Epoch 2 Global steps: 7600 Train loss: 0.4723
en_de Dev loss: 0.8539 r:0.2472
en_zh Dev loss: 0.7355 r:0.4507
Current avg r:0.3489 Best avg r: 0.3513
11:48:44,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:49:10,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:49:36,463 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
11:49:36,471 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:50:02,537 root INFO Epoch 2 Global steps: 7800 Train loss: 0.6228
en_de Dev loss: 0.8392 r:0.2411
en_zh Dev loss: 0.6801 r:0.4660
Current avg r:0.3535 Best avg r: 0.3535
11:51:19,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:51:45,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:52:11,499 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
11:52:11,508 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:52:37,573 root INFO Epoch 2 Global steps: 8000 Train loss: 0.5240
en_de Dev loss: 0.8469 r:0.2410
en_zh Dev loss: 0.6798 r:0.4732
Current avg r:0.3571 Best avg r: 0.3571
11:53:54,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:54:20,555 root INFO 
id:en_de cur r: 0.2527 best r: 0.2527
11:54:33,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:54:59,601 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_de.lang_agnost_mlp.dev.best.scores
11:54:59,607 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run2/en_zh.lang_agnost_mlp.dev.best.scores
11:55:25,679 root INFO Epoch 2 Global steps: 8200 Train loss: 0.6004
en_de Dev loss: 0.8343 r:0.2528
en_zh Dev loss: 0.6699 r:0.4755
Current avg r:0.3641 Best avg r: 0.3641
11:56:42,555 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:57:21,642 root INFO 
id:en_zh cur r: 0.4900 best r: 0.4900
11:57:21,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:57:47,704 root INFO Epoch 2 Global steps: 8400 Train loss: 0.6476
en_de Dev loss: 0.8349 r:0.2451
en_zh Dev loss: 0.6491 r:0.4803
Current avg r:0.3627 Best avg r: 0.3641
11:59:04,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:59:30,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:59:56,717 root INFO Epoch 2 Global steps: 8600 Train loss: 0.4948
en_de Dev loss: 0.8461 r:0.2337
en_zh Dev loss: 0.6742 r:0.4771
Current avg r:0.3554 Best avg r: 0.3641
12:01:13,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:01:39,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:02:05,659 root INFO Epoch 2 Global steps: 8800 Train loss: 0.6812
en_de Dev loss: 0.8534 r:0.2209
en_zh Dev loss: 0.7392 r:0.4595
Current avg r:0.3402 Best avg r: 0.3641
12:03:22,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:03:48,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:04:14,653 root INFO Epoch 2 Global steps: 9000 Train loss: 0.5614
en_de Dev loss: 0.8501 r:0.2221
en_zh Dev loss: 0.6701 r:0.4802
Current avg r:0.3512 Best avg r: 0.3641
12:05:32,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:06:11,97 root INFO 
id:en_zh cur r: 0.4916 best r: 0.4916
12:06:11,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:06:37,149 root INFO Epoch 3 Global steps: 9200 Train loss: 0.4843
en_de Dev loss: 0.8593 r:0.2120
en_zh Dev loss: 0.6613 r:0.4859
Current avg r:0.3490 Best avg r: 0.3641
12:07:54,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:08:20,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:08:46,108 root INFO Epoch 3 Global steps: 9400 Train loss: 0.5503
en_de Dev loss: 0.8986 r:0.2035
en_zh Dev loss: 0.8524 r:0.4369
Current avg r:0.3202 Best avg r: 0.3641
12:10:03,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:10:29,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:10:55,128 root INFO Epoch 3 Global steps: 9600 Train loss: 0.4955
en_de Dev loss: 0.8751 r:0.1962
en_zh Dev loss: 0.7168 r:0.4535
Current avg r:0.3249 Best avg r: 0.3641
12:12:11,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:12:38,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:13:04,67 root INFO Epoch 3 Global steps: 9800 Train loss: 0.5778
en_de Dev loss: 0.8626 r:0.2083
en_zh Dev loss: 0.7620 r:0.4525
Current avg r:0.3304 Best avg r: 0.3641
12:14:20,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:14:46,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:15:12,992 root INFO Epoch 3 Global steps: 10000 Train loss: 0.5356
en_de Dev loss: 0.8567 r:0.2251
en_zh Dev loss: 0.6934 r:0.4686
Current avg r:0.3468 Best avg r: 0.3641
12:16:29,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:16:55,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:17:21,996 root INFO Epoch 3 Global steps: 10200 Train loss: 0.4784
en_de Dev loss: 0.8455 r:0.2310
en_zh Dev loss: 0.6780 r:0.4660
Current avg r:0.3485 Best avg r: 0.3641
12:18:38,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:19:04,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:19:30,902 root INFO Epoch 3 Global steps: 10400 Train loss: 0.5745
en_de Dev loss: 0.8646 r:0.2238
en_zh Dev loss: 0.7662 r:0.4636
Current avg r:0.3437 Best avg r: 0.3641
12:20:47,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:21:26,824 root INFO 
id:en_zh cur r: 0.4968 best r: 0.4968
12:21:26,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:21:52,883 root INFO Epoch 3 Global steps: 10600 Train loss: 0.5362
en_de Dev loss: 0.8523 r:0.2326
en_zh Dev loss: 0.6960 r:0.4857
Current avg r:0.3591 Best avg r: 0.3641
12:23:09,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:23:35,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:24:01,887 root INFO Epoch 3 Global steps: 10800 Train loss: 0.5202
en_de Dev loss: 0.8448 r:0.2226
en_zh Dev loss: 0.6822 r:0.4815
Current avg r:0.3521 Best avg r: 0.3641
12:25:18,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:25:44,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:26:10,819 root INFO Epoch 3 Global steps: 11000 Train loss: 0.5970
en_de Dev loss: 0.8444 r:0.2306
en_zh Dev loss: 0.6924 r:0.4709
Current avg r:0.3508 Best avg r: 0.3641
12:27:27,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:27:53,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:28:19,780 root INFO Epoch 3 Global steps: 11200 Train loss: 0.5988
en_de Dev loss: 0.8462 r:0.2266
en_zh Dev loss: 0.6956 r:0.4706
Current avg r:0.3486 Best avg r: 0.3641
12:29:36,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:30:02,802 root INFO 
id:en_de cur r: 0.2536 best r: 0.2536
12:30:15,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:30:41,854 root INFO Epoch 3 Global steps: 11400 Train loss: 0.5124
en_de Dev loss: 0.8413 r:0.2431
en_zh Dev loss: 0.7188 r:0.4588
Current avg r:0.3509 Best avg r: 0.3641
12:31:58,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:32:24,807 root INFO 
id:en_de cur r: 0.2658 best r: 0.2658
12:32:37,818 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:33:03,878 root INFO Epoch 3 Global steps: 11600 Train loss: 0.4583
en_de Dev loss: 0.8422 r:0.2572
en_zh Dev loss: 0.8011 r:0.4640
Current avg r:0.3606 Best avg r: 0.3641
12:34:20,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:34:46,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:35:12,917 root INFO Epoch 3 Global steps: 11800 Train loss: 0.5163
en_de Dev loss: 0.8438 r:0.2381
en_zh Dev loss: 0.6854 r:0.4765
Current avg r:0.3573 Best avg r: 0.3641
12:36:29,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:36:55,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:37:21,895 root INFO Epoch 3 Global steps: 12000 Train loss: 0.5245
en_de Dev loss: 0.8536 r:0.2248
en_zh Dev loss: 0.7030 r:0.4780
Current avg r:0.3514 Best avg r: 0.3641
12:38:39,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:39:05,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:39:31,284 root INFO Epoch 4 Global steps: 12200 Train loss: 0.5173
en_de Dev loss: 0.8750 r:0.2483
en_zh Dev loss: 0.8858 r:0.4228
Current avg r:0.3355 Best avg r: 0.3641
12:40:48,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:41:14,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:41:40,277 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4438
en_de Dev loss: 0.8511 r:0.2212
en_zh Dev loss: 0.7324 r:0.4615
Current avg r:0.3414 Best avg r: 0.3641
12:42:57,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:43:23,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:43:49,201 root INFO Epoch 4 Global steps: 12600 Train loss: 0.4779
en_de Dev loss: 0.8426 r:0.2260
en_zh Dev loss: 0.6938 r:0.4760
Current avg r:0.3510 Best avg r: 0.3641
12:45:06,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:45:32,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:45:58,136 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4431
en_de Dev loss: 0.8536 r:0.2219
en_zh Dev loss: 0.7477 r:0.4855
Current avg r:0.3537 Best avg r: 0.3641
12:47:15,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:47:41,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:48:07,97 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4487
en_de Dev loss: 0.8574 r:0.2165
en_zh Dev loss: 0.7552 r:0.4665
Current avg r:0.3415 Best avg r: 0.3641
12:49:23,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:49:49,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:50:16,41 root INFO Epoch 4 Global steps: 13200 Train loss: 0.5403
en_de Dev loss: 0.8453 r:0.2284
en_zh Dev loss: 0.7283 r:0.4689
Current avg r:0.3487 Best avg r: 0.3641
12:51:32,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:51:58,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:52:25,32 root INFO Epoch 4 Global steps: 13400 Train loss: 0.5167
en_de Dev loss: 0.8613 r:0.2484
en_zh Dev loss: 0.8539 r:0.4455
Current avg r:0.3469 Best avg r: 0.3641
12:53:41,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:54:07,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:54:33,952 root INFO Epoch 4 Global steps: 13600 Train loss: 0.4715
en_de Dev loss: 0.8426 r:0.2425
en_zh Dev loss: 0.6976 r:0.4689
Current avg r:0.3557 Best avg r: 0.3641
12:55:50,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:56:16,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:56:42,894 root INFO Epoch 4 Global steps: 13800 Train loss: 0.4467
en_de Dev loss: 0.8607 r:0.2438
en_zh Dev loss: 0.7738 r:0.4642
Current avg r:0.3540 Best avg r: 0.3641
12:57:59,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:58:25,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:58:51,854 root INFO Epoch 4 Global steps: 14000 Train loss: 0.4549
en_de Dev loss: 0.8696 r:0.2132
en_zh Dev loss: 0.8302 r:0.4576
Current avg r:0.3354 Best avg r: 0.3641
13:00:08,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:00:34,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:01:00,773 root INFO Epoch 4 Global steps: 14200 Train loss: 0.4612
en_de Dev loss: 0.8544 r:0.2176
en_zh Dev loss: 0.7051 r:0.4677
Current avg r:0.3427 Best avg r: 0.3641
13:02:17,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:02:43,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:03:09,720 root INFO Epoch 4 Global steps: 14400 Train loss: 0.4144
en_de Dev loss: 0.8481 r:0.2486
en_zh Dev loss: 0.7552 r:0.4536
Current avg r:0.3511 Best avg r: 0.3641
13:04:26,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:04:52,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:05:18,683 root INFO Epoch 4 Global steps: 14600 Train loss: 0.5098
en_de Dev loss: 0.8535 r:0.2079
en_zh Dev loss: 0.7168 r:0.4738
Current avg r:0.3409 Best avg r: 0.3641
13:06:35,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:07:01,555 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:07:27,609 root INFO Epoch 4 Global steps: 14800 Train loss: 0.4156
en_de Dev loss: 0.8493 r:0.2231
en_zh Dev loss: 0.7136 r:0.4776
Current avg r:0.3503 Best avg r: 0.3641
13:08:44,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:09:10,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:09:36,611 root INFO Epoch 4 Global steps: 15000 Train loss: 0.3906
en_de Dev loss: 0.8673 r:0.2351
en_zh Dev loss: 0.7688 r:0.4728
Current avg r:0.3540 Best avg r: 0.3641
13:10:53,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:11:19,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:11:45,935 root INFO Epoch 5 Global steps: 15200 Train loss: 0.4190
en_de Dev loss: 0.8587 r:0.2245
en_zh Dev loss: 0.7516 r:0.4674
Current avg r:0.3459 Best avg r: 0.3641
13:13:02,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:13:28,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:13:54,931 root INFO Epoch 5 Global steps: 15400 Train loss: 0.3676
en_de Dev loss: 0.8664 r:0.2158
en_zh Dev loss: 0.7619 r:0.4575
Current avg r:0.3366 Best avg r: 0.3641
13:15:11,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:15:37,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:16:03,943 root INFO Epoch 5 Global steps: 15600 Train loss: 0.4027
en_de Dev loss: 0.8642 r:0.2103
en_zh Dev loss: 0.7522 r:0.4610
Current avg r:0.3356 Best avg r: 0.3641
13:17:20,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:17:46,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:18:12,917 root INFO Epoch 5 Global steps: 15800 Train loss: 0.3909
en_de Dev loss: 0.8730 r:0.2279
en_zh Dev loss: 0.7794 r:0.4533
Current avg r:0.3406 Best avg r: 0.3641
13:19:29,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:19:55,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:20:21,933 root INFO Epoch 5 Global steps: 16000 Train loss: 0.4561
en_de Dev loss: 0.8676 r:0.2141
en_zh Dev loss: 0.7572 r:0.4672
Current avg r:0.3406 Best avg r: 0.3641
13:21:38,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:22:04,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:22:31,0 root INFO Epoch 5 Global steps: 16200 Train loss: 0.4013
en_de Dev loss: 0.8648 r:0.2087
en_zh Dev loss: 0.7676 r:0.4662
Current avg r:0.3375 Best avg r: 0.3641
13:23:47,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:24:13,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:24:39,975 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3523
en_de Dev loss: 0.8528 r:0.2346
en_zh Dev loss: 0.7493 r:0.4733
Current avg r:0.3540 Best avg r: 0.3641
13:25:56,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:26:22,926 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:26:48,976 root INFO Epoch 5 Global steps: 16600 Train loss: 0.3532
en_de Dev loss: 0.8781 r:0.2106
en_zh Dev loss: 0.7698 r:0.4814
Current avg r:0.3460 Best avg r: 0.3641
13:28:05,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:28:31,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:28:58,19 root INFO Epoch 5 Global steps: 16800 Train loss: 0.3559
en_de Dev loss: 0.8652 r:0.2305
en_zh Dev loss: 0.7602 r:0.4763
Current avg r:0.3534 Best avg r: 0.3641
13:30:14,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:30:40,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:31:07,5 root INFO Epoch 5 Global steps: 17000 Train loss: 0.4570
en_de Dev loss: 0.8552 r:0.2328
en_zh Dev loss: 0.7355 r:0.4816
Current avg r:0.3572 Best avg r: 0.3641
13:32:23,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:33:02,993 root INFO 
id:en_zh cur r: 0.5012 best r: 0.5012
13:33:02,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:33:29,41 root INFO Epoch 5 Global steps: 17200 Train loss: 0.4406
en_de Dev loss: 0.8752 r:0.2058
en_zh Dev loss: 0.7229 r:0.4912
Current avg r:0.3485 Best avg r: 0.3641
13:34:45,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:35:11,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:35:38,34 root INFO Epoch 5 Global steps: 17400 Train loss: 0.3767
en_de Dev loss: 0.8968 r:0.1865
en_zh Dev loss: 0.7704 r:0.4766
Current avg r:0.3315 Best avg r: 0.3641
13:36:54,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:37:20,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:37:47,44 root INFO Epoch 5 Global steps: 17600 Train loss: 0.4327
en_de Dev loss: 0.8851 r:0.1826
en_zh Dev loss: 0.7476 r:0.4809
Current avg r:0.3318 Best avg r: 0.3641
13:39:03,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:39:29,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:39:56,25 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3934
en_de Dev loss: 0.9002 r:0.1676
en_zh Dev loss: 0.6776 r:0.4924
Current avg r:0.3300 Best avg r: 0.3641
13:41:12,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:41:38,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:42:05,8 root INFO Epoch 5 Global steps: 18000 Train loss: 0.3824
en_de Dev loss: 0.9189 r:0.1486
en_zh Dev loss: 0.7415 r:0.4807
Current avg r:0.3147 Best avg r: 0.3641
13:43:22,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:43:48,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:44:14,389 root INFO Epoch 6 Global steps: 18200 Train loss: 0.3707
en_de Dev loss: 0.8936 r:0.1672
en_zh Dev loss: 0.7636 r:0.4628
Current avg r:0.3150 Best avg r: 0.3641
13:45:31,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:45:57,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:46:23,343 root INFO Epoch 6 Global steps: 18400 Train loss: 0.3382
en_de Dev loss: 0.9087 r:0.1700
en_zh Dev loss: 0.7249 r:0.4825
Current avg r:0.3263 Best avg r: 0.3641
13:47:40,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:48:06,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:48:32,340 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3674
en_de Dev loss: 0.9018 r:0.1882
en_zh Dev loss: 0.7251 r:0.4776
Current avg r:0.3329 Best avg r: 0.3641
13:49:49,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:50:15,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:50:41,342 root INFO Epoch 6 Global steps: 18800 Train loss: 0.3339
en_de Dev loss: 0.8717 r:0.2010
en_zh Dev loss: 0.7945 r:0.4665
Current avg r:0.3338 Best avg r: 0.3641
13:51:58,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:52:24,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:52:50,334 root INFO Epoch 6 Global steps: 19000 Train loss: 0.3121
en_de Dev loss: 0.8960 r:0.1914
en_zh Dev loss: 0.8578 r:0.4599
Current avg r:0.3257 Best avg r: 0.3641
13:54:07,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:54:33,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:54:59,381 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3596
en_de Dev loss: 0.8644 r:0.1976
en_zh Dev loss: 0.7682 r:0.4699
Current avg r:0.3337 Best avg r: 0.3641
13:56:16,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:56:42,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:57:08,399 root INFO Epoch 6 Global steps: 19400 Train loss: 0.3621
en_de Dev loss: 0.9001 r:0.1717
en_zh Dev loss: 0.7494 r:0.4729
Current avg r:0.3223 Best avg r: 0.3641
13:58:25,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:58:51,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:59:17,411 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3265
en_de Dev loss: 0.8712 r:0.1938
en_zh Dev loss: 0.7605 r:0.4676
Current avg r:0.3307 Best avg r: 0.3641
14:00:34,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:01:00,408 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:01:26,462 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3309
en_de Dev loss: 0.8947 r:0.1717
en_zh Dev loss: 0.8282 r:0.4543
Current avg r:0.3130 Best avg r: 0.3641
14:02:43,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:03:09,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:03:35,432 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3364
en_de Dev loss: 0.9070 r:0.1538
en_zh Dev loss: 0.7403 r:0.4781
Current avg r:0.3160 Best avg r: 0.3641
14:04:52,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:05:18,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:05:44,496 root INFO Epoch 6 Global steps: 20200 Train loss: 0.3543
en_de Dev loss: 0.8971 r:0.1589
en_zh Dev loss: 0.8030 r:0.4648
Current avg r:0.3118 Best avg r: 0.3641
14:07:01,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:07:27,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:07:53,479 root INFO Epoch 6 Global steps: 20400 Train loss: 0.3658
en_de Dev loss: 0.9053 r:0.1714
en_zh Dev loss: 0.8047 r:0.4661
Current avg r:0.3188 Best avg r: 0.3641
14:09:10,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:09:36,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:10:02,452 root INFO Epoch 6 Global steps: 20600 Train loss: 0.3062
en_de Dev loss: 0.9000 r:0.2046
en_zh Dev loss: 0.8836 r:0.4450
Current avg r:0.3248 Best avg r: 0.3641
14:11:19,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:11:45,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:12:11,446 root INFO Epoch 6 Global steps: 20800 Train loss: 0.3551
en_de Dev loss: 0.8808 r:0.1953
en_zh Dev loss: 0.8002 r:0.4515
Current avg r:0.3234 Best avg r: 0.3641
14:13:28,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:13:54,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:14:20,339 root INFO Epoch 6 Global steps: 21000 Train loss: 0.3220
en_de Dev loss: 0.8637 r:0.2101
en_zh Dev loss: 0.7520 r:0.4615
Current avg r:0.3358 Best avg r: 0.3641
14:15:37,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:16:03,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:16:29,734 root INFO Epoch 7 Global steps: 21200 Train loss: 0.2972
en_de Dev loss: 0.8782 r:0.1899
en_zh Dev loss: 0.7684 r:0.4615
Current avg r:0.3257 Best avg r: 0.3641
14:17:46,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:18:12,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:18:38,703 root INFO Epoch 7 Global steps: 21400 Train loss: 0.2711
en_de Dev loss: 0.8868 r:0.1780
en_zh Dev loss: 0.8131 r:0.4527
Current avg r:0.3153 Best avg r: 0.3641
14:19:55,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:20:21,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:20:47,627 root INFO Epoch 7 Global steps: 21600 Train loss: 0.3170
en_de Dev loss: 0.8781 r:0.1883
en_zh Dev loss: 0.7700 r:0.4588
Current avg r:0.3236 Best avg r: 0.3641
14:22:04,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:22:30,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:22:56,647 root INFO Epoch 7 Global steps: 21800 Train loss: 0.3188
en_de Dev loss: 0.8943 r:0.1871
en_zh Dev loss: 0.8265 r:0.4598
Current avg r:0.3235 Best avg r: 0.3641
14:24:13,529 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:24:39,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:25:05,619 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2892
en_de Dev loss: 0.8962 r:0.1919
en_zh Dev loss: 0.8264 r:0.4542
Current avg r:0.3230 Best avg r: 0.3641
14:26:22,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:26:48,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:27:14,601 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2787
en_de Dev loss: 0.8815 r:0.1849
en_zh Dev loss: 0.7460 r:0.4653
Current avg r:0.3251 Best avg r: 0.3641
14:28:31,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:28:57,586 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:29:23,631 root INFO Epoch 7 Global steps: 22400 Train loss: 0.3082
en_de Dev loss: 0.8924 r:0.1751
en_zh Dev loss: 0.8252 r:0.4534
Current avg r:0.3143 Best avg r: 0.3641
14:30:40,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:31:06,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:31:32,616 root INFO Epoch 7 Global steps: 22600 Train loss: 0.2980
en_de Dev loss: 0.8883 r:0.1876
en_zh Dev loss: 0.7926 r:0.4681
Current avg r:0.3279 Best avg r: 0.3641
14:32:49,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:33:15,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:33:41,573 root INFO Epoch 7 Global steps: 22800 Train loss: 0.3106
en_de Dev loss: 0.9235 r:0.1720
en_zh Dev loss: 0.7434 r:0.4800
Current avg r:0.3260 Best avg r: 0.3641
14:34:58,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:35:24,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:35:50,634 root INFO Epoch 7 Global steps: 23000 Train loss: 0.3065
en_de Dev loss: 0.8938 r:0.1713
en_zh Dev loss: 0.7864 r:0.4599
Current avg r:0.3156 Best avg r: 0.3641
14:37:07,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:33,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:37:59,578 root INFO Epoch 7 Global steps: 23200 Train loss: 0.3131
en_de Dev loss: 0.8807 r:0.1657
en_zh Dev loss: 0.7525 r:0.4606
Current avg r:0.3132 Best avg r: 0.3641
14:39:16,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:39:42,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:08,573 root INFO Epoch 7 Global steps: 23400 Train loss: 0.3270
en_de Dev loss: 0.9101 r:0.1855
en_zh Dev loss: 0.8299 r:0.4650
Current avg r:0.3253 Best avg r: 0.3641
14:41:25,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:41:51,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:42:17,558 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2920
en_de Dev loss: 0.8752 r:0.1930
en_zh Dev loss: 0.7716 r:0.4677
Current avg r:0.3304 Best avg r: 0.3641
14:43:34,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:00,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:44:26,514 root INFO Epoch 7 Global steps: 23800 Train loss: 0.3028
en_de Dev loss: 0.9004 r:0.1706
en_zh Dev loss: 0.8074 r:0.4584
Current avg r:0.3145 Best avg r: 0.3641
14:45:43,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:46:09,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:35,571 root INFO Epoch 7 Global steps: 24000 Train loss: 0.3405
en_de Dev loss: 0.8778 r:0.2080
en_zh Dev loss: 0.8467 r:0.4566
Current avg r:0.3323 Best avg r: 0.3641
14:47:52,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:18,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:45,7 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2448
en_de Dev loss: 0.8782 r:0.2068
en_zh Dev loss: 0.7593 r:0.4674
Current avg r:0.3371 Best avg r: 0.3641
14:50:01,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:50:27,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:50:54,11 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2789
en_de Dev loss: 0.8951 r:0.1761
en_zh Dev loss: 0.8180 r:0.4547
Current avg r:0.3154 Best avg r: 0.3641
14:52:10,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:37,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:03,94 root INFO Epoch 8 Global steps: 24600 Train loss: 0.3047
en_de Dev loss: 0.8883 r:0.1850
en_zh Dev loss: 0.8015 r:0.4574
Current avg r:0.3212 Best avg r: 0.3641
14:54:19,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:46,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:12,89 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2666
en_de Dev loss: 0.8927 r:0.1790
en_zh Dev loss: 0.7741 r:0.4654
Current avg r:0.3222 Best avg r: 0.3641
14:56:28,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:54,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:21,52 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2475
en_de Dev loss: 0.9363 r:0.1690
en_zh Dev loss: 0.9683 r:0.4568
Current avg r:0.3129 Best avg r: 0.3641
14:58:37,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:04,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:30,98 root INFO Epoch 8 Global steps: 25200 Train loss: 0.3031
en_de Dev loss: 0.8996 r:0.1915
en_zh Dev loss: 0.7603 r:0.4735
Current avg r:0.3325 Best avg r: 0.3641
15:00:47,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:13,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:01:39,126 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2551
en_de Dev loss: 0.9031 r:0.1752
en_zh Dev loss: 0.8550 r:0.4578
Current avg r:0.3165 Best avg r: 0.3641
15:02:56,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:22,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:48,123 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2755
en_de Dev loss: 0.9117 r:0.1749
en_zh Dev loss: 0.8426 r:0.4612
Current avg r:0.3180 Best avg r: 0.3641
15:05:05,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:31,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:57,158 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2716
en_de Dev loss: 0.9056 r:0.1741
en_zh Dev loss: 0.8548 r:0.4537
Current avg r:0.3139 Best avg r: 0.3641
15:07:14,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:40,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:06,173 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2658
en_de Dev loss: 0.8797 r:0.1983
en_zh Dev loss: 0.7691 r:0.4584
Current avg r:0.3283 Best avg r: 0.3641
15:09:23,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:49,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:15,188 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2703
en_de Dev loss: 0.8998 r:0.1899
en_zh Dev loss: 0.7426 r:0.4751
Current avg r:0.3325 Best avg r: 0.3641
15:11:32,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:58,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:24,175 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2517
en_de Dev loss: 0.9046 r:0.1758
en_zh Dev loss: 0.7704 r:0.4769
Current avg r:0.3264 Best avg r: 0.3641
15:13:41,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:07,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:33,118 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2604
en_de Dev loss: 0.8900 r:0.1882
en_zh Dev loss: 0.8056 r:0.4650
Current avg r:0.3266 Best avg r: 0.3641
15:15:50,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:16,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:42,131 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2575
en_de Dev loss: 0.9241 r:0.1821
en_zh Dev loss: 0.8160 r:0.4621
Current avg r:0.3221 Best avg r: 0.3641
15:17:59,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:25,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:51,132 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2574
en_de Dev loss: 0.9174 r:0.1858
en_zh Dev loss: 0.7577 r:0.4702
Current avg r:0.3280 Best avg r: 0.3641
15:20:08,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:34,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:00,364 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2315
en_de Dev loss: 0.8830 r:0.1949
en_zh Dev loss: 0.7507 r:0.4687
Current avg r:0.3318 Best avg r: 0.3641
15:22:17,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:43,346 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:09,399 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2699
en_de Dev loss: 0.8906 r:0.1974
en_zh Dev loss: 0.7952 r:0.4682
Current avg r:0.3328 Best avg r: 0.3641
15:24:26,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:52,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:18,372 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2467
en_de Dev loss: 0.8895 r:0.1849
en_zh Dev loss: 0.8145 r:0.4543
Current avg r:0.3196 Best avg r: 0.3641
15:26:35,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:01,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:27,343 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2223
en_de Dev loss: 0.9124 r:0.2019
en_zh Dev loss: 0.8080 r:0.4712
Current avg r:0.3365 Best avg r: 0.3641
15:28:44,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:10,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:36,376 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2585
en_de Dev loss: 0.8776 r:0.1950
en_zh Dev loss: 0.7436 r:0.4670
Current avg r:0.3310 Best avg r: 0.3641
15:30:53,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:19,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:45,292 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2469
en_de Dev loss: 0.9188 r:0.1913
en_zh Dev loss: 0.8607 r:0.4586
Current avg r:0.3249 Best avg r: 0.3641
15:33:02,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:28,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:54,323 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2520
en_de Dev loss: 0.9046 r:0.1861
en_zh Dev loss: 0.8676 r:0.4457
Current avg r:0.3159 Best avg r: 0.3641
15:35:11,245 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:37,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:03,334 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2592
en_de Dev loss: 0.8888 r:0.2175
en_zh Dev loss: 0.7827 r:0.4610
Current avg r:0.3392 Best avg r: 0.3641
15:37:20,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:46,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:12,272 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2442
en_de Dev loss: 0.9008 r:0.1992
en_zh Dev loss: 0.7699 r:0.4692
Current avg r:0.3342 Best avg r: 0.3641
15:39:29,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:55,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:21,299 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2327
en_de Dev loss: 0.8921 r:0.1997
en_zh Dev loss: 0.8356 r:0.4579
Current avg r:0.3288 Best avg r: 0.3641
15:41:38,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:04,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:30,251 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2121
en_de Dev loss: 0.8738 r:0.2089
en_zh Dev loss: 0.7547 r:0.4691
Current avg r:0.3390 Best avg r: 0.3641
15:43:47,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:13,122 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:39,163 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2375
en_de Dev loss: 0.8920 r:0.1923
en_zh Dev loss: 0.7955 r:0.4675
Current avg r:0.3299 Best avg r: 0.3641
15:45:56,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:22,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:48,186 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2620
en_de Dev loss: 0.8967 r:0.1890
en_zh Dev loss: 0.8167 r:0.4667
Current avg r:0.3279 Best avg r: 0.3641
15:48:05,70 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:31,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:57,134 root INFO Epoch 9 Global steps: 29800 Train loss: 0.2721
en_de Dev loss: 0.9056 r:0.1814
en_zh Dev loss: 0.7828 r:0.4580
Current avg r:0.3197 Best avg r: 0.3641
15:50:14,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:40,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:06,111 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2381
en_de Dev loss: 0.9039 r:0.1827
en_zh Dev loss: 0.7747 r:0.4655
Current avg r:0.3241 Best avg r: 0.3641
15:52:23,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:49,466 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:15,504 root INFO Epoch 10 Global steps: 30200 Train loss: 0.2312
en_de Dev loss: 0.8911 r:0.1707
en_zh Dev loss: 0.7734 r:0.4641
Current avg r:0.3174 Best avg r: 0.3641
15:54:32,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:58,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:24,438 root INFO Epoch 10 Global steps: 30400 Train loss: 0.2379
en_de Dev loss: 0.9068 r:0.1818
en_zh Dev loss: 0.8177 r:0.4556
Current avg r:0.3187 Best avg r: 0.3641
15:56:41,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:07,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:33,394 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2334
en_de Dev loss: 0.9196 r:0.1551
en_zh Dev loss: 0.7767 r:0.4493
Current avg r:0.3022 Best avg r: 0.3641
15:58:50,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:16,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:42,395 root INFO Epoch 10 Global steps: 30800 Train loss: 0.2546
en_de Dev loss: 0.9110 r:0.1701
en_zh Dev loss: 0.8139 r:0.4543
Current avg r:0.3122 Best avg r: 0.3641
16:00:59,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:25,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:51,287 root INFO Epoch 10 Global steps: 31000 Train loss: 0.2244
en_de Dev loss: 0.9159 r:0.1781
en_zh Dev loss: 0.8281 r:0.4496
Current avg r:0.3138 Best avg r: 0.3641
16:03:08,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:34,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:00,244 root INFO Epoch 10 Global steps: 31200 Train loss: 0.2378
en_de Dev loss: 0.9210 r:0.1614
en_zh Dev loss: 0.8383 r:0.4539
Current avg r:0.3076 Best avg r: 0.3641
16:05:17,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:43,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:09,158 root INFO Epoch 10 Global steps: 31400 Train loss: 0.2078
en_de Dev loss: 0.9061 r:0.1647
en_zh Dev loss: 0.7984 r:0.4437
Current avg r:0.3042 Best avg r: 0.3641
16:07:26,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:52,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:18,86 root INFO Epoch 10 Global steps: 31600 Train loss: 0.2176
en_de Dev loss: 0.9183 r:0.1744
en_zh Dev loss: 0.8504 r:0.4474
Current avg r:0.3109 Best avg r: 0.3641
16:09:34,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:01,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:27,67 root INFO Epoch 10 Global steps: 31800 Train loss: 0.1998
en_de Dev loss: 0.9070 r:0.1753
en_zh Dev loss: 0.8401 r:0.4471
Current avg r:0.3112 Best avg r: 0.3641
16:11:43,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:09,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:35,996 root INFO Epoch 10 Global steps: 32000 Train loss: 0.2161
en_de Dev loss: 0.9201 r:0.1687
en_zh Dev loss: 0.8508 r:0.4522
Current avg r:0.3104 Best avg r: 0.3641
16:13:52,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:18,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:44,926 root INFO Epoch 10 Global steps: 32200 Train loss: 0.2317
en_de Dev loss: 0.9100 r:0.1675
en_zh Dev loss: 0.8420 r:0.4571
Current avg r:0.3123 Best avg r: 0.3641
16:16:01,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:27,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:53,913 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1987
en_de Dev loss: 0.9340 r:0.1680
en_zh Dev loss: 0.8015 r:0.4624
Current avg r:0.3152 Best avg r: 0.3641
16:18:10,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:36,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:02,878 root INFO Epoch 10 Global steps: 32600 Train loss: 0.2107
en_de Dev loss: 0.9166 r:0.1756
en_zh Dev loss: 0.7487 r:0.4717
Current avg r:0.3237 Best avg r: 0.3641
16:20:19,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:45,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:11,812 root INFO Epoch 10 Global steps: 32800 Train loss: 0.2121
en_de Dev loss: 0.9098 r:0.1671
en_zh Dev loss: 0.8023 r:0.4488
Current avg r:0.3079 Best avg r: 0.3641
16:22:28,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:54,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:20,856 root INFO Epoch 10 Global steps: 33000 Train loss: 0.2160
en_de Dev loss: 0.9011 r:0.1637
en_zh Dev loss: 0.7709 r:0.4610
Current avg r:0.3123 Best avg r: 0.3641
16:24:38,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:04,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:30,215 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1988
en_de Dev loss: 0.9159 r:0.1569
en_zh Dev loss: 0.7594 r:0.4642
Current avg r:0.3106 Best avg r: 0.3641
16:26:47,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:13,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:39,169 root INFO Epoch 11 Global steps: 33400 Train loss: 0.2154
en_de Dev loss: 0.9284 r:0.1624
en_zh Dev loss: 0.7732 r:0.4713
Current avg r:0.3168 Best avg r: 0.3641
16:28:56,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:22,139 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:48,176 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1928
en_de Dev loss: 0.9332 r:0.1602
en_zh Dev loss: 0.7601 r:0.4730
Current avg r:0.3166 Best avg r: 0.3641
16:31:05,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:31,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:57,109 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1944
en_de Dev loss: 0.9416 r:0.1618
en_zh Dev loss: 0.7754 r:0.4704
Current avg r:0.3161 Best avg r: 0.3641
16:33:13,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:40,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:06,112 root INFO Epoch 11 Global steps: 34000 Train loss: 0.2045
en_de Dev loss: 0.9350 r:0.1618
en_zh Dev loss: 0.8564 r:0.4570
Current avg r:0.3094 Best avg r: 0.3641
16:35:22,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:49,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:15,76 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1998
en_de Dev loss: 0.9244 r:0.1707
en_zh Dev loss: 0.8238 r:0.4604
Current avg r:0.3156 Best avg r: 0.3641
16:37:31,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:58,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:24,39 root INFO Epoch 11 Global steps: 34400 Train loss: 0.2356
en_de Dev loss: 0.9290 r:0.1604
en_zh Dev loss: 0.7848 r:0.4554
Current avg r:0.3079 Best avg r: 0.3641
16:39:40,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:07,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:33,53 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1869
en_de Dev loss: 0.9368 r:0.1804
en_zh Dev loss: 0.8048 r:0.4579
Current avg r:0.3192 Best avg r: 0.3641
16:41:49,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:15,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:41,927 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1852
en_de Dev loss: 0.9343 r:0.1656
en_zh Dev loss: 0.8021 r:0.4522
Current avg r:0.3089 Best avg r: 0.3641
16:43:58,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:24,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:50,903 root INFO Epoch 11 Global steps: 35000 Train loss: 0.2252
en_de Dev loss: 0.9445 r:0.1741
en_zh Dev loss: 0.8194 r:0.4552
Current avg r:0.3146 Best avg r: 0.3641
16:46:07,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:33,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:59,917 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1777
en_de Dev loss: 0.9238 r:0.1775
en_zh Dev loss: 0.8332 r:0.4531
Current avg r:0.3153 Best avg r: 0.3641
16:48:16,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:42,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:08,880 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1902
en_de Dev loss: 0.9513 r:0.1472
en_zh Dev loss: 0.8529 r:0.4509
Current avg r:0.2991 Best avg r: 0.3641
16:50:25,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:51,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:17,835 root INFO Epoch 11 Global steps: 35600 Train loss: 0.2065
en_de Dev loss: 0.9281 r:0.1519
en_zh Dev loss: 0.8307 r:0.4424
Current avg r:0.2971 Best avg r: 0.3641
16:52:34,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:00,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:26,806 root INFO Epoch 11 Global steps: 35800 Train loss: 0.2005
en_de Dev loss: 0.9355 r:0.1506
en_zh Dev loss: 0.7855 r:0.4645
Current avg r:0.3076 Best avg r: 0.3641
16:54:43,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:09,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:35,791 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1805
en_de Dev loss: 0.9356 r:0.1405
en_zh Dev loss: 0.7968 r:0.4564
Current avg r:0.2984 Best avg r: 0.3641
16:56:53,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:19,148 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:45,193 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1703
en_de Dev loss: 0.9575 r:0.1332
en_zh Dev loss: 0.8335 r:0.4524
Current avg r:0.2928 Best avg r: 0.3641
16:59:02,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:28,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:54,155 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1777
en_de Dev loss: 0.9275 r:0.1484
en_zh Dev loss: 0.7964 r:0.4550
Current avg r:0.3017 Best avg r: 0.3641
17:01:11,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:37,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:03,108 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1913
en_de Dev loss: 0.9558 r:0.1160
en_zh Dev loss: 0.8328 r:0.4459
Current avg r:0.2810 Best avg r: 0.3641
17:03:19,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:45,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:12,7 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1862
en_de Dev loss: 0.9608 r:0.1289
en_zh Dev loss: 0.8518 r:0.4561
Current avg r:0.2925 Best avg r: 0.3641
17:05:28,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:54,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:20,912 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1769
en_de Dev loss: 0.9605 r:0.1245
en_zh Dev loss: 0.8171 r:0.4576
Current avg r:0.2910 Best avg r: 0.3641
17:07:37,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:03,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:29,767 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1819
en_de Dev loss: 0.9609 r:0.1306
en_zh Dev loss: 0.8204 r:0.4613
Current avg r:0.2960 Best avg r: 0.3641
17:09:46,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:12,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:10:38,618 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1894
en_de Dev loss: 0.9373 r:0.1416
en_zh Dev loss: 0.7900 r:0.4609
Current avg r:0.3013 Best avg r: 0.3641
17:11:55,403 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:21,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:47,465 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1841
en_de Dev loss: 0.9500 r:0.1412
en_zh Dev loss: 0.8394 r:0.4515
Current avg r:0.2964 Best avg r: 0.3641
17:14:04,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:30,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:56,288 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1741
en_de Dev loss: 0.9510 r:0.1275
en_zh Dev loss: 0.8266 r:0.4622
Current avg r:0.2948 Best avg r: 0.3641
17:16:13,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:39,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:05,180 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1790
en_de Dev loss: 0.9551 r:0.1168
en_zh Dev loss: 0.7923 r:0.4640
Current avg r:0.2904 Best avg r: 0.3641
17:18:21,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:48,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:14,47 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1690
en_de Dev loss: 0.9788 r:0.1270
en_zh Dev loss: 0.8434 r:0.4637
Current avg r:0.2953 Best avg r: 0.3641
17:20:30,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:56,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:22,927 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1737
en_de Dev loss: 0.9624 r:0.1337
en_zh Dev loss: 0.8000 r:0.4746
Current avg r:0.3041 Best avg r: 0.3641
17:22:39,772 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:05,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:31,845 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1959
en_de Dev loss: 0.9720 r:0.1275
en_zh Dev loss: 0.8264 r:0.4691
Current avg r:0.2983 Best avg r: 0.3641
17:24:48,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:14,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:40,726 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1706
en_de Dev loss: 0.9722 r:0.1416
en_zh Dev loss: 0.8509 r:0.4607
Current avg r:0.3011 Best avg r: 0.3641
17:26:57,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:23,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:49,594 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1783
en_de Dev loss: 0.9577 r:0.1274
en_zh Dev loss: 0.7907 r:0.4658
Current avg r:0.2966 Best avg r: 0.3641
17:29:06,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:32,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:58,905 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1945
en_de Dev loss: 0.9349 r:0.1359
en_zh Dev loss: 0.8219 r:0.4558
Current avg r:0.2958 Best avg r: 0.3641
17:31:15,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:41,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:07,803 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1713
en_de Dev loss: 0.9577 r:0.1370
en_zh Dev loss: 0.8131 r:0.4623
Current avg r:0.2996 Best avg r: 0.3641
17:33:24,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:50,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:16,693 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1581
en_de Dev loss: 1.0012 r:0.1447
en_zh Dev loss: 0.8569 r:0.4636
Current avg r:0.3041 Best avg r: 0.3641
17:35:33,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:59,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:25,619 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1621
en_de Dev loss: 0.9624 r:0.1269
en_zh Dev loss: 0.8347 r:0.4574
Current avg r:0.2922 Best avg r: 0.3641
17:37:42,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:08,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:34,533 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1599
en_de Dev loss: 0.9764 r:0.1299
en_zh Dev loss: 0.8644 r:0.4562
Current avg r:0.2930 Best avg r: 0.3641
17:39:51,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:17,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:43,466 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1684
en_de Dev loss: 0.9397 r:0.1277
en_zh Dev loss: 0.7701 r:0.4650
Current avg r:0.2964 Best avg r: 0.3641
17:42:00,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:26,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:52,451 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1506
en_de Dev loss: 0.9862 r:0.1250
en_zh Dev loss: 0.8340 r:0.4589
Current avg r:0.2920 Best avg r: 0.3641
17:44:09,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:35,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:01,413 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1733
en_de Dev loss: 0.9503 r:0.1375
en_zh Dev loss: 0.7757 r:0.4678
Current avg r:0.3026 Best avg r: 0.3641
17:46:18,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:44,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:10,389 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1686
en_de Dev loss: 0.9655 r:0.1340
en_zh Dev loss: 0.7655 r:0.4681
Current avg r:0.3010 Best avg r: 0.3641
17:48:27,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:53,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:19,290 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1536
en_de Dev loss: 0.9723 r:0.1249
en_zh Dev loss: 0.8112 r:0.4617
Current avg r:0.2933 Best avg r: 0.3641
17:50:36,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:02,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:28,152 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1559
en_de Dev loss: 0.9782 r:0.1368
en_zh Dev loss: 0.7847 r:0.4738
Current avg r:0.3053 Best avg r: 0.3641
17:52:45,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:11,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:37,123 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1639
en_de Dev loss: 0.9922 r:0.1159
en_zh Dev loss: 0.8768 r:0.4537
Current avg r:0.2848 Best avg r: 0.3641
17:54:53,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:20,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:46,84 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1636
en_de Dev loss: 0.9780 r:0.1258
en_zh Dev loss: 0.8290 r:0.4611
Current avg r:0.2934 Best avg r: 0.3641
17:57:02,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:29,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:55,56 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1604
en_de Dev loss: 0.9401 r:0.1266
en_zh Dev loss: 0.7420 r:0.4697
Current avg r:0.2981 Best avg r: 0.3641
17:59:12,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:38,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:04,125 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1620
en_de Dev loss: 0.9519 r:0.1212
en_zh Dev loss: 0.8354 r:0.4578
Current avg r:0.2895 Best avg r: 0.3641
18:01:21,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:47,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:13,420 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1653
en_de Dev loss: 0.9745 r:0.1270
en_zh Dev loss: 0.8157 r:0.4663
Current avg r:0.2966 Best avg r: 0.3641
18:03:30,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:56,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:22,468 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1378
en_de Dev loss: 0.9564 r:0.1263
en_zh Dev loss: 0.8365 r:0.4604
Current avg r:0.2933 Best avg r: 0.3641
18:05:39,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:05,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:31,504 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1672
en_de Dev loss: 0.9783 r:0.1254
en_zh Dev loss: 0.8889 r:0.4597
Current avg r:0.2925 Best avg r: 0.3641
18:07:48,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:14,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:40,422 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1437
en_de Dev loss: 0.9773 r:0.1052
en_zh Dev loss: 0.8722 r:0.4590
Current avg r:0.2821 Best avg r: 0.3641
18:09:57,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:23,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:49,405 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1492
en_de Dev loss: 0.9852 r:0.1127
en_zh Dev loss: 0.8491 r:0.4609
Current avg r:0.2868 Best avg r: 0.3641
18:12:06,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:32,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:58,320 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1385
en_de Dev loss: 0.9991 r:0.1276
en_zh Dev loss: 0.8447 r:0.4586
Current avg r:0.2931 Best avg r: 0.3641
18:14:15,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:41,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:07,183 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1504
en_de Dev loss: 0.9748 r:0.1264
en_zh Dev loss: 0.8074 r:0.4608
Current avg r:0.2936 Best avg r: 0.3641
18:16:24,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:50,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:16,132 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1551
en_de Dev loss: 1.0031 r:0.1223
en_zh Dev loss: 0.8347 r:0.4537
Current avg r:0.2880 Best avg r: 0.3641
18:18:32,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:58,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:25,11 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1426
en_de Dev loss: 0.9830 r:0.1214
en_zh Dev loss: 0.8387 r:0.4572
Current avg r:0.2893 Best avg r: 0.3641
18:20:41,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:07,830 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:33,872 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1319
en_de Dev loss: 0.9798 r:0.1161
en_zh Dev loss: 0.8278 r:0.4594
Current avg r:0.2877 Best avg r: 0.3641
18:22:50,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:16,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:42,811 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1527
en_de Dev loss: 0.9701 r:0.1067
en_zh Dev loss: 0.7636 r:0.4670
Current avg r:0.2868 Best avg r: 0.3641
18:24:59,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:25,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:51,692 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1551
en_de Dev loss: 0.9886 r:0.1057
en_zh Dev loss: 0.8524 r:0.4611
Current avg r:0.2834 Best avg r: 0.3641
18:27:08,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:34,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:00,577 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1422
en_de Dev loss: 0.9675 r:0.1181
en_zh Dev loss: 0.7420 r:0.4757
Current avg r:0.2969 Best avg r: 0.3641
18:29:17,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:43,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:09,491 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1308
en_de Dev loss: 0.9787 r:0.1172
en_zh Dev loss: 0.7940 r:0.4710
Current avg r:0.2941 Best avg r: 0.3641
18:31:26,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:52,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:18,387 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1560
en_de Dev loss: 0.9949 r:0.1201
en_zh Dev loss: 0.8587 r:0.4606
Current avg r:0.2903 Best avg r: 0.3641
18:33:35,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:01,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:27,644 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1344
en_de Dev loss: 0.9613 r:0.1136
en_zh Dev loss: 0.7627 r:0.4747
Current avg r:0.2941 Best avg r: 0.3641
18:35:44,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:10,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:36,515 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1392
en_de Dev loss: 0.9862 r:0.1069
en_zh Dev loss: 0.8366 r:0.4775
Current avg r:0.2922 Best avg r: 0.3641
18:37:53,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:19,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:45,326 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1334
en_de Dev loss: 0.9902 r:0.1169
en_zh Dev loss: 0.8118 r:0.4742
Current avg r:0.2956 Best avg r: 0.3641
18:40:02,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:28,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:54,248 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1242
en_de Dev loss: 0.9677 r:0.1214
en_zh Dev loss: 0.7790 r:0.4742
Current avg r:0.2978 Best avg r: 0.3641
18:42:11,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:37,87 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:03,109 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1415
en_de Dev loss: 1.0051 r:0.1267
en_zh Dev loss: 0.8483 r:0.4749
Current avg r:0.3008 Best avg r: 0.3641
18:44:19,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:45,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:11,907 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1295
en_de Dev loss: 0.9605 r:0.1329
en_zh Dev loss: 0.7799 r:0.4758
Current avg r:0.3044 Best avg r: 0.3641
18:46:28,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:54,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:20,777 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1361
en_de Dev loss: 0.9842 r:0.1268
en_zh Dev loss: 0.7786 r:0.4782
Current avg r:0.3025 Best avg r: 0.3641
18:48:37,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:03,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:29,606 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1395
en_de Dev loss: 0.9765 r:0.1187
en_zh Dev loss: 0.7860 r:0.4734
Current avg r:0.2960 Best avg r: 0.3641
18:50:46,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:12,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:38,406 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1273
en_de Dev loss: 0.9691 r:0.1169
en_zh Dev loss: 0.8398 r:0.4746
Current avg r:0.2957 Best avg r: 0.3641
18:52:55,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:21,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:47,315 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1213
en_de Dev loss: 0.9698 r:0.1393
en_zh Dev loss: 0.8134 r:0.4731
Current avg r:0.3062 Best avg r: 0.3641
18:55:04,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:30,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:56,114 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1292
en_de Dev loss: 0.9797 r:0.1189
en_zh Dev loss: 0.8534 r:0.4709
Current avg r:0.2949 Best avg r: 0.3641
18:57:12,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:38,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:04,971 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1391
en_de Dev loss: 0.9729 r:0.1414
en_zh Dev loss: 0.8233 r:0.4762
Current avg r:0.3088 Best avg r: 0.3641
18:59:21,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:47,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:13,843 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1303
en_de Dev loss: 0.9546 r:0.1347
en_zh Dev loss: 0.7345 r:0.4854
Current avg r:0.3100 Best avg r: 0.3641
19:01:30,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:56,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:22,691 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1357
en_de Dev loss: 0.9621 r:0.1223
en_zh Dev loss: 0.7523 r:0.4794
Current avg r:0.3009 Best avg r: 0.3641
19:03:39,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:05,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:31,578 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1333
en_de Dev loss: 0.9858 r:0.1159
en_zh Dev loss: 0.8314 r:0.4765
Current avg r:0.2962 Best avg r: 0.3641
19:05:48,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:14,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:40,862 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1235
en_de Dev loss: 1.0063 r:0.1265
en_zh Dev loss: 0.8022 r:0.4706
Current avg r:0.2986 Best avg r: 0.3641
19:07:57,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:23,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:49,658 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1260
en_de Dev loss: 0.9557 r:0.1271
en_zh Dev loss: 0.7914 r:0.4728
Current avg r:0.2999 Best avg r: 0.3641
