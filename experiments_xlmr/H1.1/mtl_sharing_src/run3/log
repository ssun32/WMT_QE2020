14:32:36,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:33:02,788 root INFO 
id:en_de cur r: 0.0244 best r: 0.0244
14:33:28,570 root INFO 
id:en_zh cur r: 0.0308 best r: 0.0308
14:33:28,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:33:54,375 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:33:54,382 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:34:20,199 root INFO Epoch 0 Global steps: 200 Train loss: 0.7812
en_de Dev loss: 0.8897 r:0.0530
en_zh Dev loss: 0.8297 r:0.0286
Current avg r:0.0408 Best avg r: 0.0408
14:35:36,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:36:02,564 root INFO 
id:en_de cur r: 0.0525 best r: 0.0525
14:36:28,402 root INFO 
id:en_zh cur r: 0.1192 best r: 0.1192
14:36:28,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:36:54,226 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:36:54,239 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:37:20,101 root INFO Epoch 0 Global steps: 400 Train loss: 0.7105
en_de Dev loss: 0.8860 r:0.0697
en_zh Dev loss: 0.8169 r:0.0888
Current avg r:0.0793 Best avg r: 0.0793
14:38:36,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:39:02,562 root INFO 
id:en_de cur r: 0.0769 best r: 0.0769
14:39:16,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:42,850 root INFO Epoch 0 Global steps: 600 Train loss: 0.8191
en_de Dev loss: 0.8933 r:0.0318
en_zh Dev loss: 0.8171 r:0.1103
Current avg r:0.0710 Best avg r: 0.0793
14:40:59,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:41:38,198 root INFO 
id:en_zh cur r: 0.1222 best r: 0.1222
14:41:38,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:42:03,958 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:42:03,963 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:42:29,734 root INFO Epoch 0 Global steps: 800 Train loss: 0.8119
en_de Dev loss: 0.8836 r:0.0874
en_zh Dev loss: 0.8143 r:0.1485
Current avg r:0.1179 Best avg r: 0.1179
14:43:47,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:26,143 root INFO 
id:en_zh cur r: 0.1967 best r: 0.1967
14:44:26,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:44:51,966 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7607
en_de Dev loss: 0.9087 r:0.0813
en_zh Dev loss: 0.8251 r:0.1407
Current avg r:0.1110 Best avg r: 0.1179
14:46:09,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:46:35,457 root INFO 
id:en_de cur r: 0.0793 best r: 0.0793
14:47:01,212 root INFO 
id:en_zh cur r: 0.2207 best r: 0.2207
14:47:01,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:26,962 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:47:26,972 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:47:52,772 root INFO Epoch 0 Global steps: 1200 Train loss: 0.6828
en_de Dev loss: 0.8935 r:0.0756
en_zh Dev loss: 0.8133 r:0.1678
Current avg r:0.1217 Best avg r: 0.1217
14:49:09,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:47,798 root INFO 
id:en_zh cur r: 0.2514 best r: 0.2514
14:49:47,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:50:13,597 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:50:13,607 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:50:39,404 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7235
en_de Dev loss: 0.8800 r:0.1425
en_zh Dev loss: 0.8069 r:0.2459
Current avg r:0.1942 Best avg r: 0.1942
14:51:55,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:21,688 root INFO 
id:en_de cur r: 0.1081 best r: 0.1081
14:52:47,445 root INFO 
id:en_zh cur r: 0.2626 best r: 0.2626
14:52:47,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:13,204 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:53:13,212 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:53:38,990 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7098
en_de Dev loss: 0.8853 r:0.1294
en_zh Dev loss: 0.8031 r:0.2677
Current avg r:0.1986 Best avg r: 0.1986
14:54:55,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:21,125 root INFO 
id:en_de cur r: 0.1205 best r: 0.1205
14:55:46,856 root INFO 
id:en_zh cur r: 0.3053 best r: 0.3053
14:55:46,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:56:12,603 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:56:12,610 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:56:38,372 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7413
en_de Dev loss: 0.8774 r:0.1688
en_zh Dev loss: 0.7986 r:0.3168
Current avg r:0.2428 Best avg r: 0.2428
14:57:54,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:20,477 root INFO 
id:en_de cur r: 0.1506 best r: 0.1506
14:58:46,254 root INFO 
id:en_zh cur r: 0.3398 best r: 0.3398
14:58:46,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:12,16 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:59:12,23 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:59:37,813 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7634
en_de Dev loss: 0.8737 r:0.1908
en_zh Dev loss: 0.7855 r:0.3352
Current avg r:0.2630 Best avg r: 0.2630
15:00:54,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:19,950 root INFO 
id:en_de cur r: 0.1966 best r: 0.1966
15:01:45,720 root INFO 
id:en_zh cur r: 0.3509 best r: 0.3509
15:01:45,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:11,489 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:02:11,495 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:02:37,277 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7146
en_de Dev loss: 0.8652 r:0.2163
en_zh Dev loss: 0.7588 r:0.3438
Current avg r:0.2801 Best avg r: 0.2801
15:03:53,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:33,733 root INFO 
id:en_zh cur r: 0.3769 best r: 0.3769
15:04:33,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:59,602 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:04:59,614 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:05:25,495 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7476
en_de Dev loss: 0.8593 r:0.2109
en_zh Dev loss: 0.7360 r:0.3695
Current avg r:0.2902 Best avg r: 0.2902
15:06:42,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:07,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:33,633 root INFO Epoch 0 Global steps: 2600 Train loss: 0.8000
en_de Dev loss: 0.8532 r:0.2046
en_zh Dev loss: 0.7744 r:0.3487
Current avg r:0.2767 Best avg r: 0.2902
15:08:50,36 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:15,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:44,547 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6953
en_de Dev loss: 0.8661 r:0.1954
en_zh Dev loss: 0.7836 r:0.3299
Current avg r:0.2626 Best avg r: 0.2902
15:11:00,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:26,592 root INFO 
id:en_de cur r: 0.2100 best r: 0.2100
15:11:52,366 root INFO 
id:en_zh cur r: 0.4113 best r: 0.4113
15:11:52,366 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:18,131 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:12:18,140 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:12:43,915 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7459
en_de Dev loss: 0.8616 r:0.1784
en_zh Dev loss: 0.7032 r:0.4032
Current avg r:0.2908 Best avg r: 0.2908
15:14:00,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:26,694 root INFO 
id:en_de cur r: 0.2112 best r: 0.2112
15:14:39,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:15:05,429 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:15:05,436 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:15:31,326 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6887
en_de Dev loss: 0.8531 r:0.2020
en_zh Dev loss: 0.7231 r:0.3933
Current avg r:0.2976 Best avg r: 0.2976
15:16:47,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:13,623 root INFO 
id:en_de cur r: 0.2226 best r: 0.2226
15:17:26,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:52,254 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:17:52,260 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:18:18,40 root INFO Epoch 1 Global steps: 3400 Train loss: 0.7428
en_de Dev loss: 0.8522 r:0.2103
en_zh Dev loss: 0.7275 r:0.4012
Current avg r:0.3058 Best avg r: 0.3058
15:19:34,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:13,48 root INFO 
id:en_zh cur r: 0.4256 best r: 0.4256
15:20:13,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:40,255 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:20:40,262 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:21:06,118 root INFO Epoch 1 Global steps: 3600 Train loss: 0.7392
en_de Dev loss: 0.8554 r:0.2036
en_zh Dev loss: 0.6755 r:0.4190
Current avg r:0.3113 Best avg r: 0.3113
15:22:22,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:48,316 root INFO 
id:en_de cur r: 0.2246 best r: 0.2246
15:23:14,147 root INFO 
id:en_zh cur r: 0.4258 best r: 0.4258
15:23:14,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:40,11 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:23:40,19 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:24:05,872 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6070
en_de Dev loss: 0.8574 r:0.2160
en_zh Dev loss: 0.7041 r:0.4201
Current avg r:0.3181 Best avg r: 0.3181
15:25:22,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:48,18 root INFO 
id:en_de cur r: 0.2442 best r: 0.2442
15:26:00,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:26,649 root INFO Epoch 1 Global steps: 4000 Train loss: 0.6583
en_de Dev loss: 0.8701 r:0.2356
en_zh Dev loss: 0.8198 r:0.4004
Current avg r:0.3180 Best avg r: 0.3181
15:27:42,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:28:08,834 root INFO 
id:en_de cur r: 0.2517 best r: 0.2517
15:28:21,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:47,480 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:28:47,486 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:29:13,266 root INFO Epoch 1 Global steps: 4200 Train loss: 0.6203
en_de Dev loss: 0.8398 r:0.2419
en_zh Dev loss: 0.6920 r:0.4152
Current avg r:0.3285 Best avg r: 0.3285
15:30:31,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:57,277 root INFO 
id:en_de cur r: 0.2635 best r: 0.2635
15:31:23,101 root INFO 
id:en_zh cur r: 0.4300 best r: 0.4300
15:31:23,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:48,952 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:31:48,959 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:32:14,808 root INFO Epoch 1 Global steps: 4400 Train loss: 0.6848
en_de Dev loss: 0.8924 r:0.2509
en_zh Dev loss: 0.8210 r:0.4157
Current avg r:0.3333 Best avg r: 0.3333
15:33:32,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:11,168 root INFO 
id:en_zh cur r: 0.4457 best r: 0.4457
15:34:11,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:36,936 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:34:36,942 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:35:02,712 root INFO Epoch 1 Global steps: 4600 Train loss: 0.5839
en_de Dev loss: 0.8451 r:0.2393
en_zh Dev loss: 0.6802 r:0.4335
Current avg r:0.3364 Best avg r: 0.3364
15:36:19,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:44,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:37:10,696 root INFO Epoch 1 Global steps: 4800 Train loss: 0.7007
en_de Dev loss: 0.8467 r:0.2425
en_zh Dev loss: 0.7089 r:0.4224
Current avg r:0.3324 Best avg r: 0.3364
15:38:28,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:55,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:21,435 root INFO Epoch 1 Global steps: 5000 Train loss: 0.5900
en_de Dev loss: 0.8540 r:0.2449
en_zh Dev loss: 0.7650 r:0.4270
Current avg r:0.3360 Best avg r: 0.3364
15:40:37,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:16,636 root INFO 
id:en_zh cur r: 0.4472 best r: 0.4472
15:41:16,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:42,464 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:41:42,471 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:42:08,300 root INFO Epoch 1 Global steps: 5200 Train loss: 0.6428
en_de Dev loss: 0.8527 r:0.2529
en_zh Dev loss: 0.7096 r:0.4303
Current avg r:0.3416 Best avg r: 0.3416
15:43:24,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:50,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:16,401 root INFO Epoch 1 Global steps: 5400 Train loss: 0.6750
en_de Dev loss: 0.8644 r:0.2233
en_zh Dev loss: 0.7774 r:0.4268
Current avg r:0.3250 Best avg r: 0.3416
15:45:32,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:11,416 root INFO 
id:en_zh cur r: 0.4512 best r: 0.4512
15:46:11,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:37,180 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:46:37,186 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:47:02,966 root INFO Epoch 1 Global steps: 5600 Train loss: 0.6746
en_de Dev loss: 0.8463 r:0.2489
en_zh Dev loss: 0.7271 r:0.4429
Current avg r:0.3459 Best avg r: 0.3459
15:48:19,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:58,158 root INFO 
id:en_zh cur r: 0.4569 best r: 0.4569
15:48:58,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:24,30 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:49:24,36 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:49:49,887 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6240
en_de Dev loss: 0.8359 r:0.2408
en_zh Dev loss: 0.6681 r:0.4531
Current avg r:0.3469 Best avg r: 0.3469
15:51:06,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:32,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:58,40 root INFO Epoch 1 Global steps: 6000 Train loss: 0.5658
en_de Dev loss: 0.8360 r:0.2406
en_zh Dev loss: 0.6663 r:0.4491
Current avg r:0.3448 Best avg r: 0.3469
15:53:16,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:41,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:07,750 root INFO Epoch 2 Global steps: 6200 Train loss: 0.6141
en_de Dev loss: 0.8538 r:0.2468
en_zh Dev loss: 0.7651 r:0.4319
Current avg r:0.3393 Best avg r: 0.3469
15:55:24,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:51,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:17,205 root INFO Epoch 2 Global steps: 6400 Train loss: 0.5738
en_de Dev loss: 0.8381 r:0.2513
en_zh Dev loss: 0.7021 r:0.4351
Current avg r:0.3432 Best avg r: 0.3469
15:57:33,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:59,448 root INFO 
id:en_de cur r: 0.2715 best r: 0.2715
15:58:12,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:38,71 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:58:38,77 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:59:03,859 root INFO Epoch 2 Global steps: 6600 Train loss: 0.6287
en_de Dev loss: 0.8495 r:0.2656
en_zh Dev loss: 0.7408 r:0.4355
Current avg r:0.3505 Best avg r: 0.3505
16:00:20,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:46,10 root INFO 
id:en_de cur r: 0.2724 best r: 0.2724
16:01:11,797 root INFO 
id:en_zh cur r: 0.4682 best r: 0.4682
16:01:11,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:37,563 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:01:37,570 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:02:03,362 root INFO Epoch 2 Global steps: 6800 Train loss: 0.5774
en_de Dev loss: 0.8519 r:0.2601
en_zh Dev loss: 0.7066 r:0.4574
Current avg r:0.3587 Best avg r: 0.3587
16:03:19,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:58,541 root INFO 
id:en_zh cur r: 0.4775 best r: 0.4775
16:03:58,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:24,371 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:04:24,377 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:04:50,234 root INFO Epoch 2 Global steps: 7000 Train loss: 0.6402
en_de Dev loss: 0.8336 r:0.2546
en_zh Dev loss: 0.6729 r:0.4755
Current avg r:0.3651 Best avg r: 0.3651
16:06:06,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:32,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:58,469 root INFO Epoch 2 Global steps: 7200 Train loss: 0.5905
en_de Dev loss: 0.8485 r:0.2430
en_zh Dev loss: 0.7199 r:0.4696
Current avg r:0.3563 Best avg r: 0.3651
16:08:14,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:08:40,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:06,511 root INFO Epoch 2 Global steps: 7400 Train loss: 0.5687
en_de Dev loss: 0.8486 r:0.2455
en_zh Dev loss: 0.7700 r:0.4607
Current avg r:0.3531 Best avg r: 0.3651
16:10:24,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:50,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:16,33 root INFO Epoch 2 Global steps: 7600 Train loss: 0.5946
en_de Dev loss: 0.8423 r:0.2598
en_zh Dev loss: 0.7606 r:0.4673
Current avg r:0.3636 Best avg r: 0.3651
16:12:32,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:11,418 root INFO 
id:en_zh cur r: 0.4797 best r: 0.4797
16:13:11,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:37,192 root INFO Epoch 2 Global steps: 7800 Train loss: 0.6391
en_de Dev loss: 0.8356 r:0.2494
en_zh Dev loss: 0.7149 r:0.4773
Current avg r:0.3633 Best avg r: 0.3651
16:14:53,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:32,243 root INFO 
id:en_zh cur r: 0.4887 best r: 0.4887
16:15:32,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:58,16 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:15:58,28 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:16:23,825 root INFO Epoch 2 Global steps: 8000 Train loss: 0.5640
en_de Dev loss: 0.8462 r:0.2658
en_zh Dev loss: 0.7063 r:0.4800
Current avg r:0.3729 Best avg r: 0.3729
16:17:40,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:18,957 root INFO 
id:en_zh cur r: 0.4963 best r: 0.4963
16:18:18,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:44,710 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:18:44,716 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:19:10,474 root INFO Epoch 2 Global steps: 8200 Train loss: 0.5489
en_de Dev loss: 0.8417 r:0.2650
en_zh Dev loss: 0.6967 r:0.4859
Current avg r:0.3754 Best avg r: 0.3754
16:20:26,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:52,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:18,505 root INFO Epoch 2 Global steps: 8400 Train loss: 0.5613
en_de Dev loss: 0.8501 r:0.2565
en_zh Dev loss: 0.7803 r:0.4805
Current avg r:0.3685 Best avg r: 0.3754
16:22:34,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:00,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:26,374 root INFO Epoch 2 Global steps: 8600 Train loss: 0.5850
en_de Dev loss: 0.8373 r:0.2646
en_zh Dev loss: 0.7073 r:0.4799
Current avg r:0.3722 Best avg r: 0.3754
16:24:42,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:08,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:34,222 root INFO Epoch 2 Global steps: 8800 Train loss: 0.5467
en_de Dev loss: 0.8402 r:0.2646
en_zh Dev loss: 0.7593 r:0.4727
Current avg r:0.3687 Best avg r: 0.3754
16:26:50,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:16,479 root INFO 
id:en_de cur r: 0.2734 best r: 0.2734
16:27:29,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:55,117 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:27:55,123 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:28:21,482 root INFO Epoch 2 Global steps: 9000 Train loss: 0.6708
en_de Dev loss: 0.8331 r:0.2793
en_zh Dev loss: 0.7186 r:0.4777
Current avg r:0.3785 Best avg r: 0.3785
16:29:38,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:04,607 root INFO 
id:en_de cur r: 0.2804 best r: 0.2804
16:30:17,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:44,680 root INFO Epoch 3 Global steps: 9200 Train loss: 0.4808
en_de Dev loss: 0.8383 r:0.2800
en_zh Dev loss: 0.7041 r:0.4739
Current avg r:0.3770 Best avg r: 0.3785
16:32:01,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:26,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:32:52,588 root INFO Epoch 3 Global steps: 9400 Train loss: 0.5250
en_de Dev loss: 0.8399 r:0.2678
en_zh Dev loss: 0.7503 r:0.4629
Current avg r:0.3654 Best avg r: 0.3785
16:34:09,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:34,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:00,741 root INFO Epoch 3 Global steps: 9600 Train loss: 0.5634
en_de Dev loss: 0.8523 r:0.2517
en_zh Dev loss: 0.7630 r:0.4678
Current avg r:0.3598 Best avg r: 0.3785
16:36:18,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:45,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:11,519 root INFO Epoch 3 Global steps: 9800 Train loss: 0.5599
en_de Dev loss: 0.8471 r:0.2572
en_zh Dev loss: 0.7592 r:0.4884
Current avg r:0.3728 Best avg r: 0.3785
16:38:28,27 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:06,695 root INFO 
id:en_zh cur r: 0.5019 best r: 0.5019
16:39:06,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:32,449 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:39:32,455 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:39:58,243 root INFO Epoch 3 Global steps: 10000 Train loss: 0.6021
en_de Dev loss: 0.8260 r:0.2762
en_zh Dev loss: 0.6697 r:0.4878
Current avg r:0.3820 Best avg r: 0.3820
16:41:14,581 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:40,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:06,139 root INFO Epoch 3 Global steps: 10200 Train loss: 0.4818
en_de Dev loss: 0.8431 r:0.2695
en_zh Dev loss: 0.7719 r:0.4728
Current avg r:0.3712 Best avg r: 0.3820
16:43:22,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:48,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:14,150 root INFO Epoch 3 Global steps: 10400 Train loss: 0.5036
en_de Dev loss: 0.8312 r:0.2674
en_zh Dev loss: 0.7120 r:0.4846
Current avg r:0.3760 Best avg r: 0.3820
16:45:30,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:56,773 root INFO 
id:en_de cur r: 0.2811 best r: 0.2811
16:46:09,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:35,392 root INFO Epoch 3 Global steps: 10600 Train loss: 0.5373
en_de Dev loss: 0.8387 r:0.2806
en_zh Dev loss: 0.7728 r:0.4768
Current avg r:0.3787 Best avg r: 0.3820
16:47:51,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:17,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:43,384 root INFO Epoch 3 Global steps: 10800 Train loss: 0.5389
en_de Dev loss: 0.8366 r:0.2785
en_zh Dev loss: 0.7295 r:0.4822
Current avg r:0.3804 Best avg r: 0.3820
16:50:00,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:25,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:51,580 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:50:51,589 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:51:17,343 root INFO Epoch 3 Global steps: 11000 Train loss: 0.4967
en_de Dev loss: 0.8450 r:0.2730
en_zh Dev loss: 0.7501 r:0.4916
Current avg r:0.3823 Best avg r: 0.3823
16:52:33,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:59,742 root INFO 
id:en_de cur r: 0.2839 best r: 0.2839
16:53:12,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:38,367 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:53:38,374 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:54:04,152 root INFO Epoch 3 Global steps: 11200 Train loss: 0.5107
en_de Dev loss: 0.8414 r:0.2840
en_zh Dev loss: 0.7584 r:0.4817
Current avg r:0.3828 Best avg r: 0.3828
16:55:20,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:46,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:12,144 root INFO Epoch 3 Global steps: 11400 Train loss: 0.4513
en_de Dev loss: 0.8291 r:0.2755
en_zh Dev loss: 0.6952 r:0.4685
Current avg r:0.3720 Best avg r: 0.3828
16:57:28,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:54,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:20,323 root INFO Epoch 3 Global steps: 11600 Train loss: 0.5788
en_de Dev loss: 0.8302 r:0.2652
en_zh Dev loss: 0.6886 r:0.4811
Current avg r:0.3731 Best avg r: 0.3828
16:59:36,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:02,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:28,517 root INFO Epoch 3 Global steps: 11800 Train loss: 0.5205
en_de Dev loss: 0.8266 r:0.2774
en_zh Dev loss: 0.7286 r:0.4864
Current avg r:0.3819 Best avg r: 0.3828
17:01:44,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:10,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:36,435 root INFO Epoch 3 Global steps: 12000 Train loss: 0.4897
en_de Dev loss: 0.8442 r:0.2768
en_zh Dev loss: 0.7574 r:0.4728
Current avg r:0.3748 Best avg r: 0.3828
17:03:53,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:19,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:44,938 root INFO Epoch 4 Global steps: 12200 Train loss: 0.4451
en_de Dev loss: 0.8402 r:0.2842
en_zh Dev loss: 0.7765 r:0.4650
Current avg r:0.3746 Best avg r: 0.3828
17:06:01,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:28,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:54,561 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4607
en_de Dev loss: 0.8377 r:0.2750
en_zh Dev loss: 0.7631 r:0.4820
Current avg r:0.3785 Best avg r: 0.3828
17:08:13,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:39,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:05,425 root INFO Epoch 4 Global steps: 12600 Train loss: 0.3829
en_de Dev loss: 0.8329 r:0.2761
en_zh Dev loss: 0.7649 r:0.4839
Current avg r:0.3800 Best avg r: 0.3828
17:10:21,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:47,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:13,372 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4276
en_de Dev loss: 0.8301 r:0.2830
en_zh Dev loss: 0.8081 r:0.4746
Current avg r:0.3788 Best avg r: 0.3828
17:12:31,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:56,985 root INFO 
id:en_de cur r: 0.2887 best r: 0.2887
17:13:09,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:35,629 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4448
en_de Dev loss: 0.8234 r:0.2853
en_zh Dev loss: 0.7127 r:0.4752
Current avg r:0.3803 Best avg r: 0.3828
17:14:52,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:18,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:44,27 root INFO Epoch 4 Global steps: 13200 Train loss: 0.4291
en_de Dev loss: 0.8254 r:0.2770
en_zh Dev loss: 0.6863 r:0.4735
Current avg r:0.3752 Best avg r: 0.3828
17:17:00,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:26,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:52,83 root INFO Epoch 4 Global steps: 13400 Train loss: 0.5108
en_de Dev loss: 0.8338 r:0.2727
en_zh Dev loss: 0.7927 r:0.4795
Current avg r:0.3761 Best avg r: 0.3828
17:19:08,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:34,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:00,9 root INFO Epoch 4 Global steps: 13600 Train loss: 0.4437
en_de Dev loss: 0.8331 r:0.2669
en_zh Dev loss: 0.7293 r:0.4647
Current avg r:0.3658 Best avg r: 0.3828
17:21:17,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:43,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:09,242 root INFO Epoch 4 Global steps: 13800 Train loss: 0.4760
en_de Dev loss: 0.8403 r:0.2652
en_zh Dev loss: 0.7999 r:0.4447
Current avg r:0.3550 Best avg r: 0.3828
17:23:27,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:52,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:18,789 root INFO Epoch 4 Global steps: 14000 Train loss: 0.4838
en_de Dev loss: 0.8405 r:0.2628
en_zh Dev loss: 0.7551 r:0.4623
Current avg r:0.3625 Best avg r: 0.3828
17:25:35,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:01,118 root INFO 
id:en_de cur r: 0.2954 best r: 0.2954
17:26:13,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:39,763 root INFO Epoch 4 Global steps: 14200 Train loss: 0.4181
en_de Dev loss: 0.8593 r:0.2925
en_zh Dev loss: 0.9027 r:0.4485
Current avg r:0.3705 Best avg r: 0.3828
17:27:56,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:22,310 root INFO 
id:en_de cur r: 0.2999 best r: 0.2999
17:28:35,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:00,955 root INFO Epoch 4 Global steps: 14400 Train loss: 0.5126
en_de Dev loss: 0.8255 r:0.2941
en_zh Dev loss: 0.7377 r:0.4637
Current avg r:0.3789 Best avg r: 0.3828
17:30:17,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:43,375 root INFO 
id:en_de cur r: 0.3011 best r: 0.3011
17:30:56,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:23,543 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
17:31:23,560 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:31:49,434 root INFO Epoch 4 Global steps: 14600 Train loss: 0.4270
en_de Dev loss: 0.8326 r:0.3031
en_zh Dev loss: 0.7390 r:0.4670
Current avg r:0.3850 Best avg r: 0.3850
17:33:08,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:34,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:00,549 root INFO Epoch 4 Global steps: 14800 Train loss: 0.4104
en_de Dev loss: 0.8423 r:0.2904
en_zh Dev loss: 0.7577 r:0.4673
Current avg r:0.3789 Best avg r: 0.3850
17:35:17,77 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:42,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:08,612 root INFO Epoch 4 Global steps: 15000 Train loss: 0.4852
en_de Dev loss: 0.8356 r:0.2706
en_zh Dev loss: 0.7143 r:0.4701
Current avg r:0.3704 Best avg r: 0.3850
17:37:25,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:51,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:17,44 root INFO Epoch 5 Global steps: 15200 Train loss: 0.3547
en_de Dev loss: 0.8366 r:0.2679
en_zh Dev loss: 0.7222 r:0.4729
Current avg r:0.3704 Best avg r: 0.3850
17:39:33,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:59,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:25,45 root INFO Epoch 5 Global steps: 15400 Train loss: 0.4618
en_de Dev loss: 0.8433 r:0.2747
en_zh Dev loss: 0.7354 r:0.4654
Current avg r:0.3701 Best avg r: 0.3850
17:41:42,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:08,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:34,452 root INFO Epoch 5 Global steps: 15600 Train loss: 0.3859
en_de Dev loss: 0.8393 r:0.2918
en_zh Dev loss: 0.7681 r:0.4556
Current avg r:0.3737 Best avg r: 0.3850
17:43:50,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:16,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:42,398 root INFO Epoch 5 Global steps: 15800 Train loss: 0.3647
en_de Dev loss: 0.8446 r:0.2506
en_zh Dev loss: 0.7773 r:0.4542
Current avg r:0.3524 Best avg r: 0.3850
17:45:58,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:24,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:50,466 root INFO Epoch 5 Global steps: 16000 Train loss: 0.4139
en_de Dev loss: 0.8445 r:0.2647
en_zh Dev loss: 0.7944 r:0.4625
Current avg r:0.3636 Best avg r: 0.3850
17:48:06,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:32,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:58,501 root INFO Epoch 5 Global steps: 16200 Train loss: 0.3858
en_de Dev loss: 0.8568 r:0.2751
en_zh Dev loss: 0.8409 r:0.4456
Current avg r:0.3603 Best avg r: 0.3850
17:50:15,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:40,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:06,694 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3994
en_de Dev loss: 0.8438 r:0.2602
en_zh Dev loss: 0.7386 r:0.4692
Current avg r:0.3647 Best avg r: 0.3850
17:52:23,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:48,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:14,722 root INFO Epoch 5 Global steps: 16600 Train loss: 0.4364
en_de Dev loss: 0.8427 r:0.2491
en_zh Dev loss: 0.7346 r:0.4686
Current avg r:0.3588 Best avg r: 0.3850
17:54:31,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:57,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:23,91 root INFO Epoch 5 Global steps: 16800 Train loss: 0.3480
en_de Dev loss: 0.8416 r:0.2564
en_zh Dev loss: 0.7499 r:0.4636
Current avg r:0.3600 Best avg r: 0.3850
17:56:39,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:05,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:31,325 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3420
en_de Dev loss: 0.8328 r:0.2634
en_zh Dev loss: 0.7345 r:0.4662
Current avg r:0.3648 Best avg r: 0.3850
17:58:48,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:13,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:39,595 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3467
en_de Dev loss: 0.8405 r:0.2891
en_zh Dev loss: 0.8519 r:0.4503
Current avg r:0.3697 Best avg r: 0.3850
18:00:56,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:21,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:47,756 root INFO Epoch 5 Global steps: 17400 Train loss: 0.3831
en_de Dev loss: 0.8283 r:0.2788
en_zh Dev loss: 0.7635 r:0.4772
Current avg r:0.3780 Best avg r: 0.3850
18:03:04,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:30,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:56,87 root INFO Epoch 5 Global steps: 17600 Train loss: 0.4046
en_de Dev loss: 0.8256 r:0.2719
en_zh Dev loss: 0.7704 r:0.4739
Current avg r:0.3729 Best avg r: 0.3850
18:05:12,683 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:38,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:04,243 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3813
en_de Dev loss: 0.8446 r:0.2594
en_zh Dev loss: 0.8152 r:0.4631
Current avg r:0.3612 Best avg r: 0.3850
18:07:20,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:46,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:12,718 root INFO Epoch 5 Global steps: 18000 Train loss: 0.3499
en_de Dev loss: 0.8328 r:0.2861
en_zh Dev loss: 0.7715 r:0.4520
Current avg r:0.3690 Best avg r: 0.3850
18:09:29,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:55,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:21,291 root INFO Epoch 6 Global steps: 18200 Train loss: 0.3669
en_de Dev loss: 0.8252 r:0.2752
en_zh Dev loss: 0.7588 r:0.4563
Current avg r:0.3657 Best avg r: 0.3850
18:11:37,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:03,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:29,474 root INFO Epoch 6 Global steps: 18400 Train loss: 0.2989
en_de Dev loss: 0.8483 r:0.2798
en_zh Dev loss: 0.7868 r:0.4490
Current avg r:0.3644 Best avg r: 0.3850
18:13:45,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:11,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:37,336 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3277
en_de Dev loss: 0.8456 r:0.2771
en_zh Dev loss: 0.8017 r:0.4642
Current avg r:0.3707 Best avg r: 0.3850
18:15:53,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:19,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:45,328 root INFO Epoch 6 Global steps: 18800 Train loss: 0.3036
en_de Dev loss: 0.8560 r:0.2888
en_zh Dev loss: 0.8577 r:0.4667
Current avg r:0.3778 Best avg r: 0.3850
18:18:03,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:28,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:54,833 root INFO Epoch 6 Global steps: 19000 Train loss: 0.3590
en_de Dev loss: 0.8296 r:0.2805
en_zh Dev loss: 0.7103 r:0.4841
Current avg r:0.3823 Best avg r: 0.3850
18:20:11,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:37,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:03,359 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3677
en_de Dev loss: 0.8615 r:0.2466
en_zh Dev loss: 0.8151 r:0.4787
Current avg r:0.3627 Best avg r: 0.3850
18:22:21,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:46,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:12,593 root INFO Epoch 6 Global steps: 19400 Train loss: 0.3232
en_de Dev loss: 0.8697 r:0.2552
en_zh Dev loss: 0.7848 r:0.4699
Current avg r:0.3626 Best avg r: 0.3850
18:24:29,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:24:54,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:20,648 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3382
en_de Dev loss: 0.8309 r:0.2599
en_zh Dev loss: 0.6910 r:0.4822
Current avg r:0.3710 Best avg r: 0.3850
18:26:38,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:04,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:30,33 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3397
en_de Dev loss: 0.8458 r:0.2660
en_zh Dev loss: 0.7178 r:0.4852
Current avg r:0.3756 Best avg r: 0.3850
18:28:46,445 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:12,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:37,956 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3605
en_de Dev loss: 0.8761 r:0.2655
en_zh Dev loss: 0.8243 r:0.4742
Current avg r:0.3699 Best avg r: 0.3850
18:30:54,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:20,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:46,372 root INFO Epoch 6 Global steps: 20200 Train loss: 0.3232
en_de Dev loss: 0.8375 r:0.2623
en_zh Dev loss: 0.7321 r:0.4841
Current avg r:0.3732 Best avg r: 0.3850
18:33:04,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:30,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:55,874 root INFO Epoch 6 Global steps: 20400 Train loss: 0.3040
en_de Dev loss: 0.8489 r:0.2589
en_zh Dev loss: 0.7881 r:0.4712
Current avg r:0.3651 Best avg r: 0.3850
18:35:12,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:38,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:03,980 root INFO Epoch 6 Global steps: 20600 Train loss: 0.2947
en_de Dev loss: 0.8490 r:0.2415
en_zh Dev loss: 0.7579 r:0.4793
Current avg r:0.3604 Best avg r: 0.3850
18:37:20,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:37:46,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:12,115 root INFO Epoch 6 Global steps: 20800 Train loss: 0.3052
en_de Dev loss: 0.8606 r:0.2340
en_zh Dev loss: 0.7581 r:0.4728
Current avg r:0.3534 Best avg r: 0.3850
18:39:28,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:54,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:20,312 root INFO Epoch 6 Global steps: 21000 Train loss: 0.3340
en_de Dev loss: 0.8386 r:0.2480
en_zh Dev loss: 0.7622 r:0.4636
Current avg r:0.3558 Best avg r: 0.3850
18:41:37,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:03,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:28,874 root INFO Epoch 7 Global steps: 21200 Train loss: 0.3063
en_de Dev loss: 0.8840 r:0.2442
en_zh Dev loss: 0.8960 r:0.4729
Current avg r:0.3585 Best avg r: 0.3850
18:43:45,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:12,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:38,448 root INFO Epoch 7 Global steps: 21400 Train loss: 0.2654
en_de Dev loss: 0.8735 r:0.2434
en_zh Dev loss: 0.8372 r:0.4745
Current avg r:0.3589 Best avg r: 0.3850
18:45:54,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:20,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:46,584 root INFO Epoch 7 Global steps: 21600 Train loss: 0.2600
en_de Dev loss: 0.8586 r:0.2389
en_zh Dev loss: 0.7965 r:0.4677
Current avg r:0.3533 Best avg r: 0.3850
18:48:03,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:28,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:54,782 root INFO Epoch 7 Global steps: 21800 Train loss: 0.3057
en_de Dev loss: 0.8702 r:0.2487
en_zh Dev loss: 0.8381 r:0.4620
Current avg r:0.3554 Best avg r: 0.3850
18:50:11,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:37,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:03,181 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2824
en_de Dev loss: 0.8586 r:0.2510
en_zh Dev loss: 0.7836 r:0.4681
Current avg r:0.3596 Best avg r: 0.3850
18:52:19,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:45,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:11,254 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2895
en_de Dev loss: 0.8498 r:0.2467
en_zh Dev loss: 0.7178 r:0.4766
Current avg r:0.3616 Best avg r: 0.3850
18:54:27,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:53,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:19,319 root INFO Epoch 7 Global steps: 22400 Train loss: 0.3001
en_de Dev loss: 0.8521 r:0.2373
en_zh Dev loss: 0.7515 r:0.4707
Current avg r:0.3540 Best avg r: 0.3850
18:56:36,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:01,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:27,750 root INFO Epoch 7 Global steps: 22600 Train loss: 0.2783
en_de Dev loss: 0.8665 r:0.2411
en_zh Dev loss: 0.7820 r:0.4715
Current avg r:0.3563 Best avg r: 0.3850
18:58:44,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:10,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:36,208 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2807
en_de Dev loss: 0.8533 r:0.2395
en_zh Dev loss: 0.7758 r:0.4715
Current avg r:0.3555 Best avg r: 0.3850
19:00:52,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:18,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:44,720 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2805
en_de Dev loss: 0.9682 r:0.1647
en_zh Dev loss: 0.8982 r:0.4712
Current avg r:0.3180 Best avg r: 0.3850
19:03:01,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:27,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:53,26 root INFO Epoch 7 Global steps: 23200 Train loss: 0.3154
en_de Dev loss: 0.8970 r:0.1952
en_zh Dev loss: 0.8526 r:0.4672
Current avg r:0.3312 Best avg r: 0.3850
19:05:09,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:35,711 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:01,567 root INFO Epoch 7 Global steps: 23400 Train loss: 0.3338
en_de Dev loss: 0.8944 r:0.1913
en_zh Dev loss: 0.8182 r:0.4735
Current avg r:0.3324 Best avg r: 0.3850
19:07:19,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:45,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:11,484 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2872
en_de Dev loss: 0.8806 r:0.2095
en_zh Dev loss: 0.7371 r:0.4821
Current avg r:0.3458 Best avg r: 0.3850
19:09:27,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:53,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:19,619 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2502
en_de Dev loss: 0.8934 r:0.1933
en_zh Dev loss: 0.7502 r:0.4830
Current avg r:0.3381 Best avg r: 0.3850
19:11:36,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:01,934 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:12:27,763 root INFO Epoch 7 Global steps: 24000 Train loss: 0.2752
en_de Dev loss: 0.8836 r:0.2082
en_zh Dev loss: 0.7509 r:0.4701
Current avg r:0.3391 Best avg r: 0.3850
19:13:44,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:10,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:36,130 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2657
en_de Dev loss: 0.9145 r:0.1865
en_zh Dev loss: 0.7845 r:0.4731
Current avg r:0.3298 Best avg r: 0.3850
19:15:52,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:18,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:44,138 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2621
en_de Dev loss: 0.9030 r:0.2278
en_zh Dev loss: 0.7960 r:0.4650
Current avg r:0.3464 Best avg r: 0.3850
19:18:00,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:26,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:52,239 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2139
en_de Dev loss: 0.8959 r:0.2050
en_zh Dev loss: 0.8050 r:0.4663
Current avg r:0.3356 Best avg r: 0.3850
19:20:08,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:34,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:00,331 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2749
en_de Dev loss: 0.8784 r:0.2089
en_zh Dev loss: 0.7930 r:0.4658
Current avg r:0.3373 Best avg r: 0.3850
19:22:16,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:42,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:08,456 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2907
en_de Dev loss: 0.8812 r:0.1960
en_zh Dev loss: 0.8010 r:0.4506
Current avg r:0.3233 Best avg r: 0.3850
19:24:24,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:50,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:16,399 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2636
en_de Dev loss: 0.8813 r:0.2065
en_zh Dev loss: 0.8068 r:0.4622
Current avg r:0.3344 Best avg r: 0.3850
19:26:32,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:58,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:24,426 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2820
en_de Dev loss: 0.8684 r:0.1956
en_zh Dev loss: 0.7554 r:0.4648
Current avg r:0.3302 Best avg r: 0.3850
19:28:40,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:08,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:33,902 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2621
en_de Dev loss: 0.8705 r:0.2087
en_zh Dev loss: 0.8086 r:0.4462
Current avg r:0.3275 Best avg r: 0.3850
19:30:51,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:31:17,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:44,534 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2342
en_de Dev loss: 0.8880 r:0.1970
en_zh Dev loss: 0.8591 r:0.4445
Current avg r:0.3207 Best avg r: 0.3850
19:33:01,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:27,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:52,887 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2481
en_de Dev loss: 0.9029 r:0.1997
en_zh Dev loss: 0.8680 r:0.4398
Current avg r:0.3198 Best avg r: 0.3850
19:35:09,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:35,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:00,952 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2782
en_de Dev loss: 0.8808 r:0.2066
en_zh Dev loss: 0.7808 r:0.4479
Current avg r:0.3273 Best avg r: 0.3850
19:37:17,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:37:43,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:09,200 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2401
en_de Dev loss: 0.9094 r:0.2095
en_zh Dev loss: 0.8101 r:0.4577
Current avg r:0.3336 Best avg r: 0.3850
19:39:25,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:51,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:17,165 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2665
en_de Dev loss: 0.8814 r:0.2098
en_zh Dev loss: 0.8137 r:0.4582
Current avg r:0.3340 Best avg r: 0.3850
19:41:33,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:59,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:25,156 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2254
en_de Dev loss: 0.8938 r:0.2023
en_zh Dev loss: 0.8178 r:0.4621
Current avg r:0.3322 Best avg r: 0.3850
19:43:41,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:07,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:33,159 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2776
en_de Dev loss: 0.8945 r:0.2091
en_zh Dev loss: 0.8163 r:0.4532
Current avg r:0.3311 Best avg r: 0.3850
19:45:50,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:15,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:46:41,727 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2320
en_de Dev loss: 0.8906 r:0.2147
en_zh Dev loss: 0.8095 r:0.4476
Current avg r:0.3312 Best avg r: 0.3850
19:48:01,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:27,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:52,894 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2093
en_de Dev loss: 0.8884 r:0.2200
en_zh Dev loss: 0.8070 r:0.4551
Current avg r:0.3375 Best avg r: 0.3850
19:50:10,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:36,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:02,549 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2141
en_de Dev loss: 0.8583 r:0.2305
en_zh Dev loss: 0.7824 r:0.4582
Current avg r:0.3444 Best avg r: 0.3850
19:52:19,459 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:45,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:11,82 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2255
en_de Dev loss: 0.8908 r:0.2013
en_zh Dev loss: 0.8681 r:0.4533
Current avg r:0.3273 Best avg r: 0.3850
19:54:28,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:53,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:19,586 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2233
en_de Dev loss: 0.8916 r:0.2161
en_zh Dev loss: 0.8326 r:0.4472
Current avg r:0.3316 Best avg r: 0.3850
19:56:37,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:03,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:29,36 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2329
en_de Dev loss: 0.8813 r:0.2056
en_zh Dev loss: 0.8344 r:0.4467
Current avg r:0.3261 Best avg r: 0.3850
19:58:47,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:12,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:38,749 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2060
en_de Dev loss: 0.9066 r:0.1997
en_zh Dev loss: 0.8468 r:0.4518
Current avg r:0.3257 Best avg r: 0.3850
20:00:55,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:01:21,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:01:47,330 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2294
en_de Dev loss: 0.9021 r:0.2070
en_zh Dev loss: 0.7828 r:0.4545
Current avg r:0.3308 Best avg r: 0.3850
20:03:04,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:30,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:55,906 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2146
en_de Dev loss: 0.8975 r:0.1926
en_zh Dev loss: 0.7806 r:0.4533
Current avg r:0.3230 Best avg r: 0.3850
20:05:12,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:38,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:04,57 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2273
en_de Dev loss: 0.9100 r:0.1992
en_zh Dev loss: 0.7741 r:0.4603
Current avg r:0.3298 Best avg r: 0.3850
20:07:20,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:07:46,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:12,40 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2487
en_de Dev loss: 0.9297 r:0.1670
en_zh Dev loss: 0.7815 r:0.4474
Current avg r:0.3072 Best avg r: 0.3850
20:09:30,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:56,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:21,933 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2391
en_de Dev loss: 0.9252 r:0.1856
en_zh Dev loss: 0.7826 r:0.4587
Current avg r:0.3221 Best avg r: 0.3850
20:11:38,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:04,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:30,347 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2364
en_de Dev loss: 0.9332 r:0.1686
en_zh Dev loss: 0.7890 r:0.4557
Current avg r:0.3122 Best avg r: 0.3850
20:13:48,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:14,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:40,104 root INFO Epoch 9 Global steps: 29800 Train loss: 0.2013
en_de Dev loss: 0.9416 r:0.1894
en_zh Dev loss: 0.8278 r:0.4550
Current avg r:0.3222 Best avg r: 0.3850
20:15:56,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:22,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:48,725 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2345
en_de Dev loss: 0.9465 r:0.1772
en_zh Dev loss: 0.8668 r:0.4442
Current avg r:0.3107 Best avg r: 0.3850
20:18:05,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:31,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:57,120 root INFO Epoch 10 Global steps: 30200 Train loss: 0.2196
en_de Dev loss: 0.9136 r:0.1987
en_zh Dev loss: 0.7515 r:0.4625
Current avg r:0.3306 Best avg r: 0.3850
20:20:14,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:40,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:06,437 root INFO Epoch 10 Global steps: 30400 Train loss: 0.1925
en_de Dev loss: 0.9229 r:0.1905
en_zh Dev loss: 0.7717 r:0.4639
Current avg r:0.3272 Best avg r: 0.3850
20:22:22,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:22:48,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:14,436 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2385
en_de Dev loss: 0.9232 r:0.1949
en_zh Dev loss: 0.8060 r:0.4613
Current avg r:0.3281 Best avg r: 0.3850
20:24:30,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:56,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:22,578 root INFO Epoch 10 Global steps: 30800 Train loss: 0.2087
en_de Dev loss: 0.9300 r:0.1640
en_zh Dev loss: 0.8066 r:0.4652
Current avg r:0.3146 Best avg r: 0.3850
20:26:39,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:04,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:30,557 root INFO Epoch 10 Global steps: 31000 Train loss: 0.2006
en_de Dev loss: 0.9054 r:0.1810
en_zh Dev loss: 0.8081 r:0.4508
Current avg r:0.3159 Best avg r: 0.3850
20:28:48,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:14,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:39,908 root INFO Epoch 10 Global steps: 31200 Train loss: 0.1989
en_de Dev loss: 0.9213 r:0.1751
en_zh Dev loss: 0.7802 r:0.4656
Current avg r:0.3204 Best avg r: 0.3850
20:30:56,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:22,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:48,139 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1854
en_de Dev loss: 0.9033 r:0.1874
en_zh Dev loss: 0.7783 r:0.4540
Current avg r:0.3207 Best avg r: 0.3850
20:33:04,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:33:30,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:56,328 root INFO Epoch 10 Global steps: 31600 Train loss: 0.2046
en_de Dev loss: 0.9059 r:0.1740
en_zh Dev loss: 0.7651 r:0.4629
Current avg r:0.3184 Best avg r: 0.3850
20:35:14,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:41,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:07,116 root INFO Epoch 10 Global steps: 31800 Train loss: 0.2138
en_de Dev loss: 0.9129 r:0.1828
en_zh Dev loss: 0.7744 r:0.4669
Current avg r:0.3248 Best avg r: 0.3850
20:37:23,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:49,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:15,64 root INFO Epoch 10 Global steps: 32000 Train loss: 0.2045
en_de Dev loss: 0.9172 r:0.1736
en_zh Dev loss: 0.8425 r:0.4565
Current avg r:0.3150 Best avg r: 0.3850
20:39:31,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:57,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:23,99 root INFO Epoch 10 Global steps: 32200 Train loss: 0.2037
en_de Dev loss: 0.9468 r:0.1667
en_zh Dev loss: 0.9238 r:0.4507
Current avg r:0.3087 Best avg r: 0.3850
20:41:42,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:08,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:33,919 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1920
en_de Dev loss: 0.9331 r:0.1649
en_zh Dev loss: 0.8323 r:0.4544
Current avg r:0.3096 Best avg r: 0.3850
20:43:50,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:16,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:42,133 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1945
en_de Dev loss: 0.9182 r:0.1676
en_zh Dev loss: 0.8357 r:0.4502
Current avg r:0.3089 Best avg r: 0.3850
20:45:58,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:24,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:50,334 root INFO Epoch 10 Global steps: 32800 Train loss: 0.2104
en_de Dev loss: 0.9198 r:0.1788
en_zh Dev loss: 0.8169 r:0.4474
Current avg r:0.3131 Best avg r: 0.3850
20:48:08,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:33,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:59,780 root INFO Epoch 10 Global steps: 33000 Train loss: 0.1833
en_de Dev loss: 0.9217 r:0.1796
en_zh Dev loss: 0.8116 r:0.4546
Current avg r:0.3171 Best avg r: 0.3850
20:50:17,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:42,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:08,660 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1689
en_de Dev loss: 0.9181 r:0.1758
en_zh Dev loss: 0.8169 r:0.4530
Current avg r:0.3144 Best avg r: 0.3850
20:52:25,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:50,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:16,721 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1751
en_de Dev loss: 0.9301 r:0.1828
en_zh Dev loss: 0.8298 r:0.4500
Current avg r:0.3164 Best avg r: 0.3850
20:54:33,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:59,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:25,14 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1818
en_de Dev loss: 0.8939 r:0.2074
en_zh Dev loss: 0.8388 r:0.4527
Current avg r:0.3301 Best avg r: 0.3850
20:56:41,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:07,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:57:33,44 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1805
en_de Dev loss: 0.9058 r:0.2054
en_zh Dev loss: 0.7849 r:0.4510
Current avg r:0.3282 Best avg r: 0.3850
20:58:49,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:15,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:41,95 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1947
en_de Dev loss: 0.9352 r:0.1858
en_zh Dev loss: 0.8569 r:0.4563
Current avg r:0.3210 Best avg r: 0.3850
21:00:57,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:23,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:49,117 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1768
en_de Dev loss: 0.8993 r:0.1963
en_zh Dev loss: 0.8024 r:0.4515
Current avg r:0.3239 Best avg r: 0.3850
21:03:05,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:31,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:57,250 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1949
en_de Dev loss: 0.9102 r:0.1899
en_zh Dev loss: 0.7640 r:0.4664
Current avg r:0.3281 Best avg r: 0.3850
21:05:13,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:39,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:06,521 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1794
en_de Dev loss: 0.9056 r:0.1817
en_zh Dev loss: 0.8139 r:0.4559
Current avg r:0.3188 Best avg r: 0.3850
21:07:22,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:48,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:14,674 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1787
en_de Dev loss: 0.9036 r:0.1967
en_zh Dev loss: 0.7911 r:0.4507
Current avg r:0.3237 Best avg r: 0.3850
21:09:31,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:57,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:23,151 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1796
en_de Dev loss: 0.9402 r:0.1920
en_zh Dev loss: 0.8778 r:0.4450
Current avg r:0.3185 Best avg r: 0.3850
21:11:40,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:05,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:12:31,625 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1923
en_de Dev loss: 0.9100 r:0.1798
en_zh Dev loss: 0.8634 r:0.4359
Current avg r:0.3078 Best avg r: 0.3850
21:13:48,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:14,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:40,37 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1870
en_de Dev loss: 0.8861 r:0.1923
en_zh Dev loss: 0.7680 r:0.4597
Current avg r:0.3260 Best avg r: 0.3850
21:15:56,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:22,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:48,618 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1830
en_de Dev loss: 0.8980 r:0.1953
en_zh Dev loss: 0.8028 r:0.4503
Current avg r:0.3228 Best avg r: 0.3850
21:18:05,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:31,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:57,121 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1756
en_de Dev loss: 0.9148 r:0.1889
en_zh Dev loss: 0.7931 r:0.4599
Current avg r:0.3244 Best avg r: 0.3850
21:20:13,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:39,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:05,692 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1782
en_de Dev loss: 0.9309 r:0.1865
en_zh Dev loss: 0.7753 r:0.4676
Current avg r:0.3271 Best avg r: 0.3850
21:22:25,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:51,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:17,451 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1750
en_de Dev loss: 0.9259 r:0.1723
en_zh Dev loss: 0.8659 r:0.4531
Current avg r:0.3127 Best avg r: 0.3850
21:24:34,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:01,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:27,382 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1646
en_de Dev loss: 0.9618 r:0.1698
en_zh Dev loss: 0.8788 r:0.4618
Current avg r:0.3158 Best avg r: 0.3850
21:26:43,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:09,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:35,479 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1647
en_de Dev loss: 0.9284 r:0.1899
en_zh Dev loss: 0.8062 r:0.4587
Current avg r:0.3243 Best avg r: 0.3850
21:28:54,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:29:20,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:46,511 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1701
en_de Dev loss: 0.9141 r:0.1870
en_zh Dev loss: 0.7995 r:0.4547
Current avg r:0.3208 Best avg r: 0.3850
21:31:03,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:28,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:54,727 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1605
en_de Dev loss: 0.9033 r:0.1955
en_zh Dev loss: 0.8429 r:0.4643
Current avg r:0.3299 Best avg r: 0.3850
21:33:11,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:33:37,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:02,870 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1588
en_de Dev loss: 0.9174 r:0.1942
en_zh Dev loss: 0.8305 r:0.4545
Current avg r:0.3243 Best avg r: 0.3850
21:35:19,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:45,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:11,14 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1766
en_de Dev loss: 0.9514 r:0.1941
en_zh Dev loss: 0.7955 r:0.4623
Current avg r:0.3282 Best avg r: 0.3850
21:37:27,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:54,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:20,492 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1707
en_de Dev loss: 0.9381 r:0.1790
en_zh Dev loss: 0.8194 r:0.4598
Current avg r:0.3194 Best avg r: 0.3850
21:39:37,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:02,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:28,563 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1684
en_de Dev loss: 0.9419 r:0.2018
en_zh Dev loss: 0.8306 r:0.4639
Current avg r:0.3329 Best avg r: 0.3850
21:41:45,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:10,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:36,684 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1553
en_de Dev loss: 0.9169 r:0.1971
en_zh Dev loss: 0.7575 r:0.4690
Current avg r:0.3330 Best avg r: 0.3850
21:43:53,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:19,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:44,777 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1632
en_de Dev loss: 0.9060 r:0.1902
en_zh Dev loss: 0.8248 r:0.4542
Current avg r:0.3222 Best avg r: 0.3850
21:46:02,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:46:29,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:55,573 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1623
en_de Dev loss: 0.9190 r:0.1994
en_zh Dev loss: 0.8109 r:0.4661
Current avg r:0.3327 Best avg r: 0.3850
21:48:15,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:42,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:08,280 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1627
en_de Dev loss: 0.9061 r:0.2001
en_zh Dev loss: 0.7810 r:0.4645
Current avg r:0.3323 Best avg r: 0.3850
21:50:25,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:50,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:16,769 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1571
en_de Dev loss: 0.9043 r:0.1928
en_zh Dev loss: 0.7673 r:0.4632
Current avg r:0.3280 Best avg r: 0.3850
21:52:33,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:59,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:24,856 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1585
en_de Dev loss: 0.9098 r:0.1742
en_zh Dev loss: 0.8058 r:0.4556
Current avg r:0.3149 Best avg r: 0.3850
21:54:41,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:07,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:55:33,424 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1433
en_de Dev loss: 0.8983 r:0.1852
en_zh Dev loss: 0.7995 r:0.4636
Current avg r:0.3244 Best avg r: 0.3850
21:56:49,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:15,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:57:42,958 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1710
en_de Dev loss: 0.9617 r:0.1741
en_zh Dev loss: 0.7814 r:0.4756
Current avg r:0.3248 Best avg r: 0.3850
21:58:59,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:25,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:51,41 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1519
en_de Dev loss: 0.9560 r:0.1718
en_zh Dev loss: 0.8744 r:0.4661
Current avg r:0.3189 Best avg r: 0.3850
22:01:07,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:01:33,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:59,123 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1587
en_de Dev loss: 0.9414 r:0.1751
en_zh Dev loss: 0.7824 r:0.4654
Current avg r:0.3203 Best avg r: 0.3850
22:03:15,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:41,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:07,272 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1469
en_de Dev loss: 0.9272 r:0.1759
en_zh Dev loss: 0.7692 r:0.4593
Current avg r:0.3176 Best avg r: 0.3850
22:05:26,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:52,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:18,380 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1381
en_de Dev loss: 0.9723 r:0.1667
en_zh Dev loss: 0.7857 r:0.4732
Current avg r:0.3200 Best avg r: 0.3850
22:07:36,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:02,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:08:27,869 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1610
en_de Dev loss: 0.9089 r:0.1684
en_zh Dev loss: 0.7524 r:0.4644
Current avg r:0.3164 Best avg r: 0.3850
22:09:44,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:10,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:35,958 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1458
en_de Dev loss: 0.9364 r:0.1754
en_zh Dev loss: 0.8260 r:0.4673
Current avg r:0.3213 Best avg r: 0.3850
22:11:52,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:18,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:43,972 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1633
en_de Dev loss: 0.9339 r:0.1772
en_zh Dev loss: 0.8502 r:0.4632
Current avg r:0.3202 Best avg r: 0.3850
22:14:00,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:26,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:52,444 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1538
en_de Dev loss: 0.9225 r:0.1826
en_zh Dev loss: 0.7515 r:0.4722
Current avg r:0.3274 Best avg r: 0.3850
22:16:09,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:16:36,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:02,363 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1407
en_de Dev loss: 0.9008 r:0.1944
en_zh Dev loss: 0.7786 r:0.4608
Current avg r:0.3276 Best avg r: 0.3850
22:18:20,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:46,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:11,811 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1632
en_de Dev loss: 0.9265 r:0.1807
en_zh Dev loss: 0.8064 r:0.4587
Current avg r:0.3197 Best avg r: 0.3850
22:20:28,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:54,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:21:20,84 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1316
en_de Dev loss: 0.9429 r:0.1756
en_zh Dev loss: 0.7964 r:0.4602
Current avg r:0.3179 Best avg r: 0.3850
22:22:36,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:02,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:28,129 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1578
en_de Dev loss: 0.9605 r:0.1759
en_zh Dev loss: 0.8103 r:0.4649
Current avg r:0.3204 Best avg r: 0.3850
22:24:44,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:10,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:25:36,236 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1407
en_de Dev loss: 0.9669 r:0.1789
en_zh Dev loss: 0.8445 r:0.4597
Current avg r:0.3193 Best avg r: 0.3850
22:26:53,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:27:19,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:44,754 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1348
en_de Dev loss: 0.9680 r:0.1794
en_zh Dev loss: 0.8637 r:0.4532
Current avg r:0.3163 Best avg r: 0.3850
22:29:01,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:27,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:52,905 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1268
en_de Dev loss: 0.9428 r:0.1784
en_zh Dev loss: 0.8025 r:0.4566
Current avg r:0.3175 Best avg r: 0.3850
22:31:09,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:35,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:01,385 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1438
en_de Dev loss: 0.9404 r:0.1789
en_zh Dev loss: 0.8287 r:0.4605
Current avg r:0.3197 Best avg r: 0.3850
22:33:18,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:44,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:09,887 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1438
en_de Dev loss: 0.9504 r:0.1729
en_zh Dev loss: 0.7791 r:0.4640
Current avg r:0.3184 Best avg r: 0.3850
22:35:26,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:52,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:18,385 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1409
en_de Dev loss: 0.9492 r:0.1701
en_zh Dev loss: 0.8005 r:0.4598
Current avg r:0.3149 Best avg r: 0.3850
22:37:34,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:00,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:26,588 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1385
en_de Dev loss: 0.9310 r:0.1804
en_zh Dev loss: 0.7760 r:0.4619
Current avg r:0.3212 Best avg r: 0.3850
22:39:43,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:08,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:34,714 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1340
en_de Dev loss: 0.9108 r:0.1856
en_zh Dev loss: 0.7460 r:0.4671
Current avg r:0.3264 Best avg r: 0.3850
22:41:51,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:17,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:42,788 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1365
en_de Dev loss: 0.9305 r:0.1767
en_zh Dev loss: 0.7544 r:0.4673
Current avg r:0.3220 Best avg r: 0.3850
22:43:59,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:25,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:50,779 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1232
en_de Dev loss: 0.9593 r:0.1590
en_zh Dev loss: 0.8441 r:0.4662
Current avg r:0.3126 Best avg r: 0.3850
22:46:07,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:33,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:58,767 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1354
en_de Dev loss: 0.9553 r:0.1612
en_zh Dev loss: 0.7982 r:0.4586
Current avg r:0.3099 Best avg r: 0.3850
22:48:15,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:41,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:06,850 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1406
en_de Dev loss: 0.9294 r:0.1668
en_zh Dev loss: 0.7829 r:0.4593
Current avg r:0.3131 Best avg r: 0.3850
22:50:23,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:49,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:14,895 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1300
en_de Dev loss: 0.9605 r:0.1564
en_zh Dev loss: 0.8338 r:0.4684
Current avg r:0.3124 Best avg r: 0.3850
22:52:31,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:57,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:22,906 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1332
en_de Dev loss: 0.9520 r:0.1478
en_zh Dev loss: 0.8344 r:0.4615
Current avg r:0.3047 Best avg r: 0.3850
22:54:39,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:05,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:30,872 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1337
en_de Dev loss: 0.9618 r:0.1627
en_zh Dev loss: 0.8393 r:0.4626
Current avg r:0.3127 Best avg r: 0.3850
22:56:47,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:13,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:39,105 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1280
en_de Dev loss: 0.9600 r:0.1649
en_zh Dev loss: 0.8087 r:0.4661
Current avg r:0.3155 Best avg r: 0.3850
22:58:56,77 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:21,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:47,781 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1232
en_de Dev loss: 1.0237 r:0.1523
en_zh Dev loss: 0.7955 r:0.4668
Current avg r:0.3095 Best avg r: 0.3850
23:01:05,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:31,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:57,83 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1265
en_de Dev loss: 0.9733 r:0.1585
en_zh Dev loss: 0.9224 r:0.4574
Current avg r:0.3080 Best avg r: 0.3850
23:03:13,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:39,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:05,438 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1306
en_de Dev loss: 0.9432 r:0.1729
en_zh Dev loss: 0.7967 r:0.4658
Current avg r:0.3194 Best avg r: 0.3850
23:05:22,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:48,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:13,843 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1238
en_de Dev loss: 0.9362 r:0.1634
en_zh Dev loss: 0.7789 r:0.4661
Current avg r:0.3148 Best avg r: 0.3850
23:07:30,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:56,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:21,976 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1218
en_de Dev loss: 0.9976 r:0.1618
en_zh Dev loss: 0.8269 r:0.4767
Current avg r:0.3192 Best avg r: 0.3850
23:09:38,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:04,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:29,964 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1264
en_de Dev loss: 0.9239 r:0.1718
en_zh Dev loss: 0.7586 r:0.4687
Current avg r:0.3203 Best avg r: 0.3850
23:11:46,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:12:12,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:37,878 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1267
en_de Dev loss: 0.9293 r:0.1890
en_zh Dev loss: 0.7583 r:0.4694
Current avg r:0.3292 Best avg r: 0.3850
23:13:54,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:20,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:46,73 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1239
en_de Dev loss: 0.9386 r:0.1763
en_zh Dev loss: 0.8081 r:0.4586
Current avg r:0.3175 Best avg r: 0.3850
23:16:03,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:29,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:55,378 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1208
en_de Dev loss: 0.9441 r:0.1852
en_zh Dev loss: 0.7788 r:0.4599
Current avg r:0.3225 Best avg r: 0.3850
23:18:11,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:37,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:03,557 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1159
en_de Dev loss: 0.9477 r:0.1750
en_zh Dev loss: 0.8155 r:0.4610
Current avg r:0.3180 Best avg r: 0.3850
23:20:21,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:47,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:21:12,861 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1206
en_de Dev loss: 0.9468 r:0.1860
en_zh Dev loss: 0.7857 r:0.4677
Current avg r:0.3268 Best avg r: 0.3850
23:22:29,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:55,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:20,824 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1217
en_de Dev loss: 0.9505 r:0.1769
en_zh Dev loss: 0.7918 r:0.4708
Current avg r:0.3238 Best avg r: 0.3850
23:24:37,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:03,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:28,818 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1190
en_de Dev loss: 0.9326 r:0.1693
en_zh Dev loss: 0.7481 r:0.4693
Current avg r:0.3193 Best avg r: 0.3850
23:26:45,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:27:11,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:37,101 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1115
en_de Dev loss: 0.9344 r:0.1604
en_zh Dev loss: 0.8163 r:0.4606
Current avg r:0.3105 Best avg r: 0.3850
23:28:56,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:25,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:51,49 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1221
en_de Dev loss: 0.9701 r:0.1661
en_zh Dev loss: 0.8289 r:0.4618
Current avg r:0.3140 Best avg r: 0.3850
23:31:07,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:33,749 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:59,512 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1068
en_de Dev loss: 0.9431 r:0.1591
en_zh Dev loss: 0.8127 r:0.4615
Current avg r:0.3103 Best avg r: 0.3850
23:33:15,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:41,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:34:07,504 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1085
en_de Dev loss: 0.9673 r:0.1602
en_zh Dev loss: 0.8018 r:0.4634
Current avg r:0.3118 Best avg r: 0.3850
23:35:25,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:51,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:16,950 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1033
en_de Dev loss: 0.9561 r:0.1590
en_zh Dev loss: 0.7908 r:0.4688
Current avg r:0.3139 Best avg r: 0.3850
23:37:33,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:59,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:25,22 root INFO Epoch 16 Global steps: 48800 Train loss: 0.1083
en_de Dev loss: 0.9451 r:0.1739
en_zh Dev loss: 0.7939 r:0.4740
Current avg r:0.3239 Best avg r: 0.3850
23:39:41,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:08,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:34,539 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1079
en_de Dev loss: 0.9641 r:0.1841
en_zh Dev loss: 0.8071 r:0.4690
Current avg r:0.3266 Best avg r: 0.3850
23:41:50,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:16,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:42,655 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1173
en_de Dev loss: 0.9411 r:0.1694
en_zh Dev loss: 0.7754 r:0.4765
Current avg r:0.3229 Best avg r: 0.3850
23:43:59,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:24,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:50,753 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1121
en_de Dev loss: 0.9714 r:0.1644
en_zh Dev loss: 0.8546 r:0.4671
Current avg r:0.3158 Best avg r: 0.3850
23:46:07,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:33,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:58,859 root INFO Epoch 16 Global steps: 49600 Train loss: 0.1108
en_de Dev loss: 0.9471 r:0.1776
en_zh Dev loss: 0.7781 r:0.4766
Current avg r:0.3271 Best avg r: 0.3850
23:48:15,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:41,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:06,903 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1026
en_de Dev loss: 0.9557 r:0.1604
en_zh Dev loss: 0.7650 r:0.4790
Current avg r:0.3197 Best avg r: 0.3850
23:50:23,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:49,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:51:14,852 root INFO Epoch 16 Global steps: 50000 Train loss: 0.1110
en_de Dev loss: 0.9647 r:0.1542
en_zh Dev loss: 0.7950 r:0.4747
Current avg r:0.3145 Best avg r: 0.3850
23:52:31,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:57,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:23,298 root INFO Epoch 16 Global steps: 50200 Train loss: 0.1030
en_de Dev loss: 0.9555 r:0.1632
en_zh Dev loss: 0.7713 r:0.4739
Current avg r:0.3185 Best avg r: 0.3850
23:54:39,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:05,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:31,437 root INFO Epoch 16 Global steps: 50400 Train loss: 0.1069
en_de Dev loss: 0.9348 r:0.1501
en_zh Dev loss: 0.7590 r:0.4772
Current avg r:0.3136 Best avg r: 0.3850
23:56:49,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:15,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:43,643 root INFO Epoch 16 Global steps: 50600 Train loss: 0.1090
en_de Dev loss: 0.9726 r:0.1507
en_zh Dev loss: 0.7861 r:0.4775
Current avg r:0.3141 Best avg r: 0.3850
23:59:01,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:27,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:53,113 root INFO Epoch 16 Global steps: 50800 Train loss: 0.1093
en_de Dev loss: 0.9451 r:0.1658
en_zh Dev loss: 0.7921 r:0.4807
Current avg r:0.3233 Best avg r: 0.3850
00:01:09,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:35,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:02:01,194 root INFO Epoch 16 Global steps: 51000 Train loss: 0.1082
en_de Dev loss: 0.9416 r:0.1465
en_zh Dev loss: 0.7799 r:0.4749
Current avg r:0.3107 Best avg r: 0.3850
00:03:18,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:44,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:10,73 root INFO Epoch 17 Global steps: 51200 Train loss: 0.1023
en_de Dev loss: 1.0000 r:0.1550
en_zh Dev loss: 0.8026 r:0.4855
Current avg r:0.3202 Best avg r: 0.3850
00:05:26,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:52,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:06:18,590 root INFO Epoch 17 Global steps: 51400 Train loss: 0.1052
en_de Dev loss: 0.9921 r:0.1522
en_zh Dev loss: 0.7412 r:0.4858
Current avg r:0.3190 Best avg r: 0.3850
00:07:35,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:08:01,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:27,42 root INFO Epoch 17 Global steps: 51600 Train loss: 0.0991
en_de Dev loss: 0.9576 r:0.1559
en_zh Dev loss: 0.8102 r:0.4784
Current avg r:0.3172 Best avg r: 0.3850
00:09:43,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:09,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:35,386 root INFO Epoch 17 Global steps: 51800 Train loss: 0.1058
en_de Dev loss: 0.9919 r:0.1419
en_zh Dev loss: 0.8250 r:0.4770
Current avg r:0.3095 Best avg r: 0.3850
00:11:51,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:12:17,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:44,829 root INFO Epoch 17 Global steps: 52000 Train loss: 0.0923
en_de Dev loss: 0.9697 r:0.1540
en_zh Dev loss: 0.7352 r:0.4852
Current avg r:0.3196 Best avg r: 0.3850
00:14:01,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:27,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:52,970 root INFO Epoch 17 Global steps: 52200 Train loss: 0.0977
en_de Dev loss: 0.9813 r:0.1392
en_zh Dev loss: 0.7824 r:0.4783
Current avg r:0.3088 Best avg r: 0.3850
00:16:09,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:16:35,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:17:01,471 root INFO Epoch 17 Global steps: 52400 Train loss: 0.0958
en_de Dev loss: 0.9524 r:0.1636
en_zh Dev loss: 0.7793 r:0.4768
Current avg r:0.3202 Best avg r: 0.3850
00:18:18,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:44,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:09,970 root INFO Epoch 17 Global steps: 52600 Train loss: 0.0970
en_de Dev loss: 0.9701 r:0.1591
en_zh Dev loss: 0.8141 r:0.4727
Current avg r:0.3159 Best avg r: 0.3850
00:20:26,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:52,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:21:18,369 root INFO Epoch 17 Global steps: 52800 Train loss: 0.1081
en_de Dev loss: 0.9633 r:0.1654
en_zh Dev loss: 0.7544 r:0.4824
Current avg r:0.3239 Best avg r: 0.3850
00:22:35,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:00,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:26,772 root INFO Epoch 17 Global steps: 53000 Train loss: 0.0950
en_de Dev loss: 0.9682 r:0.1591
en_zh Dev loss: 0.7585 r:0.4810
Current avg r:0.3201 Best avg r: 0.3850
00:24:43,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:25:09,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:34,774 root INFO Epoch 17 Global steps: 53200 Train loss: 0.0999
en_de Dev loss: 0.9534 r:0.1620
en_zh Dev loss: 0.7700 r:0.4850
Current avg r:0.3235 Best avg r: 0.3850
00:26:51,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:27:17,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:42,777 root INFO Epoch 17 Global steps: 53400 Train loss: 0.1008
en_de Dev loss: 0.9538 r:0.1520
en_zh Dev loss: 0.7504 r:0.4842
Current avg r:0.3181 Best avg r: 0.3850
00:28:59,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:25,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:50,831 root INFO Epoch 17 Global steps: 53600 Train loss: 0.0960
en_de Dev loss: 0.9605 r:0.1540
en_zh Dev loss: 0.7962 r:0.4807
Current avg r:0.3173 Best avg r: 0.3850
00:31:07,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:32,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:58,724 root INFO Epoch 17 Global steps: 53800 Train loss: 0.0986
en_de Dev loss: 0.9587 r:0.1600
en_zh Dev loss: 0.7703 r:0.4839
Current avg r:0.3220 Best avg r: 0.3850
00:33:15,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:33:40,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:06,689 root INFO Epoch 17 Global steps: 54000 Train loss: 0.0981
en_de Dev loss: 0.9493 r:0.1424
en_zh Dev loss: 0.8048 r:0.4729
Current avg r:0.3076 Best avg r: 0.3850
00:35:23,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:49,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:16,893 root INFO Epoch 18 Global steps: 54200 Train loss: 0.0857
en_de Dev loss: 0.9723 r:0.1463
en_zh Dev loss: 0.7332 r:0.4842
Current avg r:0.3152 Best avg r: 0.3850
00:37:33,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:59,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:24,864 root INFO Epoch 18 Global steps: 54400 Train loss: 0.0871
en_de Dev loss: 0.9540 r:0.1625
en_zh Dev loss: 0.7500 r:0.4872
Current avg r:0.3248 Best avg r: 0.3850
00:39:41,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:07,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:34,652 root INFO Epoch 18 Global steps: 54600 Train loss: 0.0860
en_de Dev loss: 0.9631 r:0.1600
en_zh Dev loss: 0.7945 r:0.4781
Current avg r:0.3190 Best avg r: 0.3850
00:41:52,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:18,527 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:44,297 root INFO Epoch 18 Global steps: 54800 Train loss: 0.0907
en_de Dev loss: 0.9499 r:0.1598
en_zh Dev loss: 0.7557 r:0.4821
Current avg r:0.3210 Best avg r: 0.3850
