14:32:36,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:33:02,788 root INFO 
id:en_de cur r: 0.0244 best r: 0.0244
14:33:28,570 root INFO 
id:en_zh cur r: 0.0308 best r: 0.0308
14:33:28,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:33:54,375 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:33:54,382 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:34:20,199 root INFO Epoch 0 Global steps: 200 Train loss: 0.7812
en_de Dev loss: 0.8897 r:0.0530
en_zh Dev loss: 0.8297 r:0.0286
Current avg r:0.0408 Best avg r: 0.0408
14:35:36,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:36:02,564 root INFO 
id:en_de cur r: 0.0525 best r: 0.0525
14:36:28,402 root INFO 
id:en_zh cur r: 0.1192 best r: 0.1192
14:36:28,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:36:54,226 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:36:54,239 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:37:20,101 root INFO Epoch 0 Global steps: 400 Train loss: 0.7105
en_de Dev loss: 0.8860 r:0.0697
en_zh Dev loss: 0.8169 r:0.0888
Current avg r:0.0793 Best avg r: 0.0793
14:38:36,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:39:02,562 root INFO 
id:en_de cur r: 0.0769 best r: 0.0769
14:39:16,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:42,850 root INFO Epoch 0 Global steps: 600 Train loss: 0.8191
en_de Dev loss: 0.8933 r:0.0318
en_zh Dev loss: 0.8171 r:0.1103
Current avg r:0.0710 Best avg r: 0.0793
14:40:59,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:41:38,198 root INFO 
id:en_zh cur r: 0.1222 best r: 0.1222
14:41:38,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:42:03,958 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:42:03,963 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:42:29,734 root INFO Epoch 0 Global steps: 800 Train loss: 0.8119
en_de Dev loss: 0.8836 r:0.0874
en_zh Dev loss: 0.8143 r:0.1485
Current avg r:0.1179 Best avg r: 0.1179
14:43:47,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:26,143 root INFO 
id:en_zh cur r: 0.1967 best r: 0.1967
14:44:26,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:44:51,966 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7607
en_de Dev loss: 0.9087 r:0.0813
en_zh Dev loss: 0.8251 r:0.1407
Current avg r:0.1110 Best avg r: 0.1179
14:46:09,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:46:35,457 root INFO 
id:en_de cur r: 0.0793 best r: 0.0793
14:47:01,212 root INFO 
id:en_zh cur r: 0.2207 best r: 0.2207
14:47:01,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:26,962 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:47:26,972 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:47:52,772 root INFO Epoch 0 Global steps: 1200 Train loss: 0.6828
en_de Dev loss: 0.8935 r:0.0756
en_zh Dev loss: 0.8133 r:0.1678
Current avg r:0.1217 Best avg r: 0.1217
14:49:09,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:47,798 root INFO 
id:en_zh cur r: 0.2514 best r: 0.2514
14:49:47,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:50:13,597 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:50:13,607 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:50:39,404 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7235
en_de Dev loss: 0.8800 r:0.1425
en_zh Dev loss: 0.8069 r:0.2459
Current avg r:0.1942 Best avg r: 0.1942
14:51:55,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:21,688 root INFO 
id:en_de cur r: 0.1081 best r: 0.1081
14:52:47,445 root INFO 
id:en_zh cur r: 0.2626 best r: 0.2626
14:52:47,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:13,204 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:53:13,212 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:53:38,990 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7098
en_de Dev loss: 0.8853 r:0.1294
en_zh Dev loss: 0.8031 r:0.2677
Current avg r:0.1986 Best avg r: 0.1986
14:54:55,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:21,125 root INFO 
id:en_de cur r: 0.1205 best r: 0.1205
14:55:46,856 root INFO 
id:en_zh cur r: 0.3053 best r: 0.3053
14:55:46,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:56:12,603 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:56:12,610 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:56:38,372 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7413
en_de Dev loss: 0.8774 r:0.1688
en_zh Dev loss: 0.7986 r:0.3168
Current avg r:0.2428 Best avg r: 0.2428
14:57:54,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:20,477 root INFO 
id:en_de cur r: 0.1506 best r: 0.1506
14:58:46,254 root INFO 
id:en_zh cur r: 0.3398 best r: 0.3398
14:58:46,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:12,16 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
14:59:12,23 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:59:37,813 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7634
en_de Dev loss: 0.8737 r:0.1908
en_zh Dev loss: 0.7855 r:0.3352
Current avg r:0.2630 Best avg r: 0.2630
15:00:54,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:19,950 root INFO 
id:en_de cur r: 0.1966 best r: 0.1966
15:01:45,720 root INFO 
id:en_zh cur r: 0.3509 best r: 0.3509
15:01:45,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:11,489 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:02:11,495 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:02:37,277 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7146
en_de Dev loss: 0.8652 r:0.2163
en_zh Dev loss: 0.7588 r:0.3438
Current avg r:0.2801 Best avg r: 0.2801
15:03:53,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:33,733 root INFO 
id:en_zh cur r: 0.3769 best r: 0.3769
15:04:33,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:59,602 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:04:59,614 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:05:25,495 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7476
en_de Dev loss: 0.8593 r:0.2109
en_zh Dev loss: 0.7360 r:0.3695
Current avg r:0.2902 Best avg r: 0.2902
15:06:42,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:07,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:33,633 root INFO Epoch 0 Global steps: 2600 Train loss: 0.8000
en_de Dev loss: 0.8532 r:0.2046
en_zh Dev loss: 0.7744 r:0.3487
Current avg r:0.2767 Best avg r: 0.2902
15:08:50,36 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:15,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:44,547 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6953
en_de Dev loss: 0.8661 r:0.1954
en_zh Dev loss: 0.7836 r:0.3299
Current avg r:0.2626 Best avg r: 0.2902
15:11:00,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:26,592 root INFO 
id:en_de cur r: 0.2100 best r: 0.2100
15:11:52,366 root INFO 
id:en_zh cur r: 0.4113 best r: 0.4113
15:11:52,366 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:18,131 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:12:18,140 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:12:43,915 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7459
en_de Dev loss: 0.8616 r:0.1784
en_zh Dev loss: 0.7032 r:0.4032
Current avg r:0.2908 Best avg r: 0.2908
15:14:00,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:26,694 root INFO 
id:en_de cur r: 0.2112 best r: 0.2112
15:14:39,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:15:05,429 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:15:05,436 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:15:31,326 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6887
en_de Dev loss: 0.8531 r:0.2020
en_zh Dev loss: 0.7231 r:0.3933
Current avg r:0.2976 Best avg r: 0.2976
15:16:47,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:13,623 root INFO 
id:en_de cur r: 0.2226 best r: 0.2226
15:17:26,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:52,254 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:17:52,260 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:18:18,40 root INFO Epoch 1 Global steps: 3400 Train loss: 0.7428
en_de Dev loss: 0.8522 r:0.2103
en_zh Dev loss: 0.7275 r:0.4012
Current avg r:0.3058 Best avg r: 0.3058
15:19:34,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:13,48 root INFO 
id:en_zh cur r: 0.4256 best r: 0.4256
15:20:13,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:40,255 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:20:40,262 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:21:06,118 root INFO Epoch 1 Global steps: 3600 Train loss: 0.7392
en_de Dev loss: 0.8554 r:0.2036
en_zh Dev loss: 0.6755 r:0.4190
Current avg r:0.3113 Best avg r: 0.3113
15:22:22,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:48,316 root INFO 
id:en_de cur r: 0.2246 best r: 0.2246
15:23:14,147 root INFO 
id:en_zh cur r: 0.4258 best r: 0.4258
15:23:14,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:40,11 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:23:40,19 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:24:05,872 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6070
en_de Dev loss: 0.8574 r:0.2160
en_zh Dev loss: 0.7041 r:0.4201
Current avg r:0.3181 Best avg r: 0.3181
15:25:22,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:48,18 root INFO 
id:en_de cur r: 0.2442 best r: 0.2442
15:26:00,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:26,649 root INFO Epoch 1 Global steps: 4000 Train loss: 0.6583
en_de Dev loss: 0.8701 r:0.2356
en_zh Dev loss: 0.8198 r:0.4004
Current avg r:0.3180 Best avg r: 0.3181
15:27:42,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:28:08,834 root INFO 
id:en_de cur r: 0.2517 best r: 0.2517
15:28:21,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:47,480 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:28:47,486 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:29:13,266 root INFO Epoch 1 Global steps: 4200 Train loss: 0.6203
en_de Dev loss: 0.8398 r:0.2419
en_zh Dev loss: 0.6920 r:0.4152
Current avg r:0.3285 Best avg r: 0.3285
15:30:31,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:57,277 root INFO 
id:en_de cur r: 0.2635 best r: 0.2635
15:31:23,101 root INFO 
id:en_zh cur r: 0.4300 best r: 0.4300
15:31:23,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:48,952 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:31:48,959 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:32:14,808 root INFO Epoch 1 Global steps: 4400 Train loss: 0.6848
en_de Dev loss: 0.8924 r:0.2509
en_zh Dev loss: 0.8210 r:0.4157
Current avg r:0.3333 Best avg r: 0.3333
15:33:32,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:11,168 root INFO 
id:en_zh cur r: 0.4457 best r: 0.4457
15:34:11,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:36,936 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:34:36,942 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:35:02,712 root INFO Epoch 1 Global steps: 4600 Train loss: 0.5839
en_de Dev loss: 0.8451 r:0.2393
en_zh Dev loss: 0.6802 r:0.4335
Current avg r:0.3364 Best avg r: 0.3364
15:36:19,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:44,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:37:10,696 root INFO Epoch 1 Global steps: 4800 Train loss: 0.7007
en_de Dev loss: 0.8467 r:0.2425
en_zh Dev loss: 0.7089 r:0.4224
Current avg r:0.3324 Best avg r: 0.3364
15:38:28,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:55,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:21,435 root INFO Epoch 1 Global steps: 5000 Train loss: 0.5900
en_de Dev loss: 0.8540 r:0.2449
en_zh Dev loss: 0.7650 r:0.4270
Current avg r:0.3360 Best avg r: 0.3364
15:40:37,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:16,636 root INFO 
id:en_zh cur r: 0.4472 best r: 0.4472
15:41:16,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:42,464 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:41:42,471 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:42:08,300 root INFO Epoch 1 Global steps: 5200 Train loss: 0.6428
en_de Dev loss: 0.8527 r:0.2529
en_zh Dev loss: 0.7096 r:0.4303
Current avg r:0.3416 Best avg r: 0.3416
15:43:24,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:50,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:16,401 root INFO Epoch 1 Global steps: 5400 Train loss: 0.6750
en_de Dev loss: 0.8644 r:0.2233
en_zh Dev loss: 0.7774 r:0.4268
Current avg r:0.3250 Best avg r: 0.3416
15:45:32,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:11,416 root INFO 
id:en_zh cur r: 0.4512 best r: 0.4512
15:46:11,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:37,180 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:46:37,186 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:47:02,966 root INFO Epoch 1 Global steps: 5600 Train loss: 0.6746
en_de Dev loss: 0.8463 r:0.2489
en_zh Dev loss: 0.7271 r:0.4429
Current avg r:0.3459 Best avg r: 0.3459
15:48:19,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:58,158 root INFO 
id:en_zh cur r: 0.4569 best r: 0.4569
15:48:58,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:24,30 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:49:24,36 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:49:49,887 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6240
en_de Dev loss: 0.8359 r:0.2408
en_zh Dev loss: 0.6681 r:0.4531
Current avg r:0.3469 Best avg r: 0.3469
15:51:06,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:32,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:58,40 root INFO Epoch 1 Global steps: 6000 Train loss: 0.5658
en_de Dev loss: 0.8360 r:0.2406
en_zh Dev loss: 0.6663 r:0.4491
Current avg r:0.3448 Best avg r: 0.3469
15:53:16,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:41,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:07,750 root INFO Epoch 2 Global steps: 6200 Train loss: 0.6141
en_de Dev loss: 0.8538 r:0.2468
en_zh Dev loss: 0.7651 r:0.4319
Current avg r:0.3393 Best avg r: 0.3469
15:55:24,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:51,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:17,205 root INFO Epoch 2 Global steps: 6400 Train loss: 0.5738
en_de Dev loss: 0.8381 r:0.2513
en_zh Dev loss: 0.7021 r:0.4351
Current avg r:0.3432 Best avg r: 0.3469
15:57:33,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:59,448 root INFO 
id:en_de cur r: 0.2715 best r: 0.2715
15:58:12,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:38,71 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
15:58:38,77 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:59:03,859 root INFO Epoch 2 Global steps: 6600 Train loss: 0.6287
en_de Dev loss: 0.8495 r:0.2656
en_zh Dev loss: 0.7408 r:0.4355
Current avg r:0.3505 Best avg r: 0.3505
16:00:20,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:46,10 root INFO 
id:en_de cur r: 0.2724 best r: 0.2724
16:01:11,797 root INFO 
id:en_zh cur r: 0.4682 best r: 0.4682
16:01:11,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:37,563 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:01:37,570 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:02:03,362 root INFO Epoch 2 Global steps: 6800 Train loss: 0.5774
en_de Dev loss: 0.8519 r:0.2601
en_zh Dev loss: 0.7066 r:0.4574
Current avg r:0.3587 Best avg r: 0.3587
16:03:19,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:58,541 root INFO 
id:en_zh cur r: 0.4775 best r: 0.4775
16:03:58,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:24,371 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:04:24,377 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:04:50,234 root INFO Epoch 2 Global steps: 7000 Train loss: 0.6402
en_de Dev loss: 0.8336 r:0.2546
en_zh Dev loss: 0.6729 r:0.4755
Current avg r:0.3651 Best avg r: 0.3651
16:06:06,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:32,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:58,469 root INFO Epoch 2 Global steps: 7200 Train loss: 0.5905
en_de Dev loss: 0.8485 r:0.2430
en_zh Dev loss: 0.7199 r:0.4696
Current avg r:0.3563 Best avg r: 0.3651
16:08:14,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:08:40,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:06,511 root INFO Epoch 2 Global steps: 7400 Train loss: 0.5687
en_de Dev loss: 0.8486 r:0.2455
en_zh Dev loss: 0.7700 r:0.4607
Current avg r:0.3531 Best avg r: 0.3651
16:10:24,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:50,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:16,33 root INFO Epoch 2 Global steps: 7600 Train loss: 0.5946
en_de Dev loss: 0.8423 r:0.2598
en_zh Dev loss: 0.7606 r:0.4673
Current avg r:0.3636 Best avg r: 0.3651
16:12:32,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:11,418 root INFO 
id:en_zh cur r: 0.4797 best r: 0.4797
16:13:11,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:37,192 root INFO Epoch 2 Global steps: 7800 Train loss: 0.6391
en_de Dev loss: 0.8356 r:0.2494
en_zh Dev loss: 0.7149 r:0.4773
Current avg r:0.3633 Best avg r: 0.3651
16:14:53,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:32,243 root INFO 
id:en_zh cur r: 0.4887 best r: 0.4887
16:15:32,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:58,16 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:15:58,28 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:16:23,825 root INFO Epoch 2 Global steps: 8000 Train loss: 0.5640
en_de Dev loss: 0.8462 r:0.2658
en_zh Dev loss: 0.7063 r:0.4800
Current avg r:0.3729 Best avg r: 0.3729
16:17:40,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:18,957 root INFO 
id:en_zh cur r: 0.4963 best r: 0.4963
16:18:18,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:44,710 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:18:44,716 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:19:10,474 root INFO Epoch 2 Global steps: 8200 Train loss: 0.5489
en_de Dev loss: 0.8417 r:0.2650
en_zh Dev loss: 0.6967 r:0.4859
Current avg r:0.3754 Best avg r: 0.3754
16:20:26,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:52,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:18,505 root INFO Epoch 2 Global steps: 8400 Train loss: 0.5613
en_de Dev loss: 0.8501 r:0.2565
en_zh Dev loss: 0.7803 r:0.4805
Current avg r:0.3685 Best avg r: 0.3754
16:22:34,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:00,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:26,374 root INFO Epoch 2 Global steps: 8600 Train loss: 0.5850
en_de Dev loss: 0.8373 r:0.2646
en_zh Dev loss: 0.7073 r:0.4799
Current avg r:0.3722 Best avg r: 0.3754
16:24:42,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:08,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:34,222 root INFO Epoch 2 Global steps: 8800 Train loss: 0.5467
en_de Dev loss: 0.8402 r:0.2646
en_zh Dev loss: 0.7593 r:0.4727
Current avg r:0.3687 Best avg r: 0.3754
16:26:50,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:16,479 root INFO 
id:en_de cur r: 0.2734 best r: 0.2734
16:27:29,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:55,117 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:27:55,123 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:28:21,482 root INFO Epoch 2 Global steps: 9000 Train loss: 0.6708
en_de Dev loss: 0.8331 r:0.2793
en_zh Dev loss: 0.7186 r:0.4777
Current avg r:0.3785 Best avg r: 0.3785
16:29:38,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:04,607 root INFO 
id:en_de cur r: 0.2804 best r: 0.2804
16:30:17,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:44,680 root INFO Epoch 3 Global steps: 9200 Train loss: 0.4808
en_de Dev loss: 0.8383 r:0.2800
en_zh Dev loss: 0.7041 r:0.4739
Current avg r:0.3770 Best avg r: 0.3785
16:32:01,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:26,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:32:52,588 root INFO Epoch 3 Global steps: 9400 Train loss: 0.5250
en_de Dev loss: 0.8399 r:0.2678
en_zh Dev loss: 0.7503 r:0.4629
Current avg r:0.3654 Best avg r: 0.3785
16:34:09,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:34,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:00,741 root INFO Epoch 3 Global steps: 9600 Train loss: 0.5634
en_de Dev loss: 0.8523 r:0.2517
en_zh Dev loss: 0.7630 r:0.4678
Current avg r:0.3598 Best avg r: 0.3785
16:36:18,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:45,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:11,519 root INFO Epoch 3 Global steps: 9800 Train loss: 0.5599
en_de Dev loss: 0.8471 r:0.2572
en_zh Dev loss: 0.7592 r:0.4884
Current avg r:0.3728 Best avg r: 0.3785
16:38:28,27 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:06,695 root INFO 
id:en_zh cur r: 0.5019 best r: 0.5019
16:39:06,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:32,449 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:39:32,455 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:39:58,243 root INFO Epoch 3 Global steps: 10000 Train loss: 0.6021
en_de Dev loss: 0.8260 r:0.2762
en_zh Dev loss: 0.6697 r:0.4878
Current avg r:0.3820 Best avg r: 0.3820
16:41:14,581 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:40,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:06,139 root INFO Epoch 3 Global steps: 10200 Train loss: 0.4818
en_de Dev loss: 0.8431 r:0.2695
en_zh Dev loss: 0.7719 r:0.4728
Current avg r:0.3712 Best avg r: 0.3820
16:43:22,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:48,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:14,150 root INFO Epoch 3 Global steps: 10400 Train loss: 0.5036
en_de Dev loss: 0.8312 r:0.2674
en_zh Dev loss: 0.7120 r:0.4846
Current avg r:0.3760 Best avg r: 0.3820
16:45:30,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:56,773 root INFO 
id:en_de cur r: 0.2811 best r: 0.2811
16:46:09,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:35,392 root INFO Epoch 3 Global steps: 10600 Train loss: 0.5373
en_de Dev loss: 0.8387 r:0.2806
en_zh Dev loss: 0.7728 r:0.4768
Current avg r:0.3787 Best avg r: 0.3820
16:47:51,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:17,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:43,384 root INFO Epoch 3 Global steps: 10800 Train loss: 0.5389
en_de Dev loss: 0.8366 r:0.2785
en_zh Dev loss: 0.7295 r:0.4822
Current avg r:0.3804 Best avg r: 0.3820
16:50:00,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:25,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:51,580 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:50:51,589 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:51:17,343 root INFO Epoch 3 Global steps: 11000 Train loss: 0.4967
en_de Dev loss: 0.8450 r:0.2730
en_zh Dev loss: 0.7501 r:0.4916
Current avg r:0.3823 Best avg r: 0.3823
16:52:33,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:59,742 root INFO 
id:en_de cur r: 0.2839 best r: 0.2839
16:53:12,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:38,367 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
16:53:38,374 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:54:04,152 root INFO Epoch 3 Global steps: 11200 Train loss: 0.5107
en_de Dev loss: 0.8414 r:0.2840
en_zh Dev loss: 0.7584 r:0.4817
Current avg r:0.3828 Best avg r: 0.3828
16:55:20,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:46,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:12,144 root INFO Epoch 3 Global steps: 11400 Train loss: 0.4513
en_de Dev loss: 0.8291 r:0.2755
en_zh Dev loss: 0.6952 r:0.4685
Current avg r:0.3720 Best avg r: 0.3828
16:57:28,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:54,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:20,323 root INFO Epoch 3 Global steps: 11600 Train loss: 0.5788
en_de Dev loss: 0.8302 r:0.2652
en_zh Dev loss: 0.6886 r:0.4811
Current avg r:0.3731 Best avg r: 0.3828
16:59:36,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:02,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:28,517 root INFO Epoch 3 Global steps: 11800 Train loss: 0.5205
en_de Dev loss: 0.8266 r:0.2774
en_zh Dev loss: 0.7286 r:0.4864
Current avg r:0.3819 Best avg r: 0.3828
17:01:44,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:10,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:36,435 root INFO Epoch 3 Global steps: 12000 Train loss: 0.4897
en_de Dev loss: 0.8442 r:0.2768
en_zh Dev loss: 0.7574 r:0.4728
Current avg r:0.3748 Best avg r: 0.3828
17:03:53,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:19,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:44,938 root INFO Epoch 4 Global steps: 12200 Train loss: 0.4451
en_de Dev loss: 0.8402 r:0.2842
en_zh Dev loss: 0.7765 r:0.4650
Current avg r:0.3746 Best avg r: 0.3828
17:06:01,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:28,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:54,561 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4607
en_de Dev loss: 0.8377 r:0.2750
en_zh Dev loss: 0.7631 r:0.4820
Current avg r:0.3785 Best avg r: 0.3828
17:08:13,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:39,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:05,425 root INFO Epoch 4 Global steps: 12600 Train loss: 0.3829
en_de Dev loss: 0.8329 r:0.2761
en_zh Dev loss: 0.7649 r:0.4839
Current avg r:0.3800 Best avg r: 0.3828
17:10:21,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:47,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:13,372 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4276
en_de Dev loss: 0.8301 r:0.2830
en_zh Dev loss: 0.8081 r:0.4746
Current avg r:0.3788 Best avg r: 0.3828
17:12:31,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:56,985 root INFO 
id:en_de cur r: 0.2887 best r: 0.2887
17:13:09,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:35,629 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4448
en_de Dev loss: 0.8234 r:0.2853
en_zh Dev loss: 0.7127 r:0.4752
Current avg r:0.3803 Best avg r: 0.3828
17:14:52,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:18,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:44,27 root INFO Epoch 4 Global steps: 13200 Train loss: 0.4291
en_de Dev loss: 0.8254 r:0.2770
en_zh Dev loss: 0.6863 r:0.4735
Current avg r:0.3752 Best avg r: 0.3828
17:17:00,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:26,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:52,83 root INFO Epoch 4 Global steps: 13400 Train loss: 0.5108
en_de Dev loss: 0.8338 r:0.2727
en_zh Dev loss: 0.7927 r:0.4795
Current avg r:0.3761 Best avg r: 0.3828
17:19:08,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:34,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:00,9 root INFO Epoch 4 Global steps: 13600 Train loss: 0.4437
en_de Dev loss: 0.8331 r:0.2669
en_zh Dev loss: 0.7293 r:0.4647
Current avg r:0.3658 Best avg r: 0.3828
17:21:17,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:43,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:09,242 root INFO Epoch 4 Global steps: 13800 Train loss: 0.4760
en_de Dev loss: 0.8403 r:0.2652
en_zh Dev loss: 0.7999 r:0.4447
Current avg r:0.3550 Best avg r: 0.3828
17:23:27,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:52,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:18,789 root INFO Epoch 4 Global steps: 14000 Train loss: 0.4838
en_de Dev loss: 0.8405 r:0.2628
en_zh Dev loss: 0.7551 r:0.4623
Current avg r:0.3625 Best avg r: 0.3828
17:25:35,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:01,118 root INFO 
id:en_de cur r: 0.2954 best r: 0.2954
17:26:13,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:39,763 root INFO Epoch 4 Global steps: 14200 Train loss: 0.4181
en_de Dev loss: 0.8593 r:0.2925
en_zh Dev loss: 0.9027 r:0.4485
Current avg r:0.3705 Best avg r: 0.3828
17:27:56,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:22,310 root INFO 
id:en_de cur r: 0.2999 best r: 0.2999
17:28:35,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:00,955 root INFO Epoch 4 Global steps: 14400 Train loss: 0.5126
en_de Dev loss: 0.8255 r:0.2941
en_zh Dev loss: 0.7377 r:0.4637
Current avg r:0.3789 Best avg r: 0.3828
17:30:17,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:43,375 root INFO 
id:en_de cur r: 0.3011 best r: 0.3011
17:30:56,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:23,543 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
17:31:23,560 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:31:49,434 root INFO Epoch 4 Global steps: 14600 Train loss: 0.4270
en_de Dev loss: 0.8326 r:0.3031
en_zh Dev loss: 0.7390 r:0.4670
Current avg r:0.3850 Best avg r: 0.3850
17:33:08,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:34,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:00,549 root INFO Epoch 4 Global steps: 14800 Train loss: 0.4104
en_de Dev loss: 0.8423 r:0.2904
en_zh Dev loss: 0.7577 r:0.4673
Current avg r:0.3789 Best avg r: 0.3850
17:35:17,77 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:42,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:08,612 root INFO Epoch 4 Global steps: 15000 Train loss: 0.4852
en_de Dev loss: 0.8356 r:0.2706
en_zh Dev loss: 0.7143 r:0.4701
Current avg r:0.3704 Best avg r: 0.3850
17:37:25,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:51,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:17,44 root INFO Epoch 5 Global steps: 15200 Train loss: 0.3547
en_de Dev loss: 0.8366 r:0.2679
en_zh Dev loss: 0.7222 r:0.4729
Current avg r:0.3704 Best avg r: 0.3850
17:39:33,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:59,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:25,45 root INFO Epoch 5 Global steps: 15400 Train loss: 0.4618
en_de Dev loss: 0.8433 r:0.2747
en_zh Dev loss: 0.7354 r:0.4654
Current avg r:0.3701 Best avg r: 0.3850
17:41:42,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:08,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:34,452 root INFO Epoch 5 Global steps: 15600 Train loss: 0.3859
en_de Dev loss: 0.8393 r:0.2918
en_zh Dev loss: 0.7681 r:0.4556
Current avg r:0.3737 Best avg r: 0.3850
17:43:50,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:16,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:42,398 root INFO Epoch 5 Global steps: 15800 Train loss: 0.3647
en_de Dev loss: 0.8446 r:0.2506
en_zh Dev loss: 0.7773 r:0.4542
Current avg r:0.3524 Best avg r: 0.3850
17:45:58,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:24,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:50,466 root INFO Epoch 5 Global steps: 16000 Train loss: 0.4139
en_de Dev loss: 0.8445 r:0.2647
en_zh Dev loss: 0.7944 r:0.4625
Current avg r:0.3636 Best avg r: 0.3850
17:48:06,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:32,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:58,501 root INFO Epoch 5 Global steps: 16200 Train loss: 0.3858
en_de Dev loss: 0.8568 r:0.2751
en_zh Dev loss: 0.8409 r:0.4456
Current avg r:0.3603 Best avg r: 0.3850
17:50:15,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:40,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:06,694 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3994
en_de Dev loss: 0.8438 r:0.2602
en_zh Dev loss: 0.7386 r:0.4692
Current avg r:0.3647 Best avg r: 0.3850
17:52:23,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:48,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:14,722 root INFO Epoch 5 Global steps: 16600 Train loss: 0.4364
en_de Dev loss: 0.8427 r:0.2491
en_zh Dev loss: 0.7346 r:0.4686
Current avg r:0.3588 Best avg r: 0.3850
17:54:31,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:57,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:23,91 root INFO Epoch 5 Global steps: 16800 Train loss: 0.3480
en_de Dev loss: 0.8416 r:0.2564
en_zh Dev loss: 0.7499 r:0.4636
Current avg r:0.3600 Best avg r: 0.3850
17:56:39,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:05,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:31,325 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3420
en_de Dev loss: 0.8328 r:0.2634
en_zh Dev loss: 0.7345 r:0.4662
Current avg r:0.3648 Best avg r: 0.3850
17:58:48,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:13,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:39,595 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3467
en_de Dev loss: 0.8405 r:0.2891
en_zh Dev loss: 0.8519 r:0.4503
Current avg r:0.3697 Best avg r: 0.3850
18:00:56,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:21,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:47,756 root INFO Epoch 5 Global steps: 17400 Train loss: 0.3831
en_de Dev loss: 0.8283 r:0.2788
en_zh Dev loss: 0.7635 r:0.4772
Current avg r:0.3780 Best avg r: 0.3850
18:03:04,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:30,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:56,87 root INFO Epoch 5 Global steps: 17600 Train loss: 0.4046
en_de Dev loss: 0.8256 r:0.2719
en_zh Dev loss: 0.7704 r:0.4739
Current avg r:0.3729 Best avg r: 0.3850
18:05:12,683 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:38,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:04,243 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3813
en_de Dev loss: 0.8446 r:0.2594
en_zh Dev loss: 0.8152 r:0.4631
Current avg r:0.3612 Best avg r: 0.3850
18:07:20,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:46,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:12,718 root INFO Epoch 5 Global steps: 18000 Train loss: 0.3499
en_de Dev loss: 0.8328 r:0.2861
en_zh Dev loss: 0.7715 r:0.4520
Current avg r:0.3690 Best avg r: 0.3850
18:09:29,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:55,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:21,291 root INFO Epoch 6 Global steps: 18200 Train loss: 0.3669
en_de Dev loss: 0.8252 r:0.2752
en_zh Dev loss: 0.7588 r:0.4563
Current avg r:0.3657 Best avg r: 0.3850
18:11:37,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:03,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:29,474 root INFO Epoch 6 Global steps: 18400 Train loss: 0.2989
en_de Dev loss: 0.8483 r:0.2798
en_zh Dev loss: 0.7868 r:0.4490
Current avg r:0.3644 Best avg r: 0.3850
18:13:45,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:11,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:37,336 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3277
en_de Dev loss: 0.8456 r:0.2771
en_zh Dev loss: 0.8017 r:0.4642
Current avg r:0.3707 Best avg r: 0.3850
18:15:53,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:19,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:45,328 root INFO Epoch 6 Global steps: 18800 Train loss: 0.3036
en_de Dev loss: 0.8560 r:0.2888
en_zh Dev loss: 0.8577 r:0.4667
Current avg r:0.3778 Best avg r: 0.3850
18:18:03,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:28,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:54,833 root INFO Epoch 6 Global steps: 19000 Train loss: 0.3590
en_de Dev loss: 0.8296 r:0.2805
en_zh Dev loss: 0.7103 r:0.4841
Current avg r:0.3823 Best avg r: 0.3850
18:20:11,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:37,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:03,359 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3677
en_de Dev loss: 0.8615 r:0.2466
en_zh Dev loss: 0.8151 r:0.4787
Current avg r:0.3627 Best avg r: 0.3850
18:22:21,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:46,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:12,593 root INFO Epoch 6 Global steps: 19400 Train loss: 0.3232
en_de Dev loss: 0.8697 r:0.2552
en_zh Dev loss: 0.7848 r:0.4699
Current avg r:0.3626 Best avg r: 0.3850
18:24:29,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:24:54,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:20,648 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3382
en_de Dev loss: 0.8309 r:0.2599
en_zh Dev loss: 0.6910 r:0.4822
Current avg r:0.3710 Best avg r: 0.3850
18:26:38,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:04,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:30,33 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3397
en_de Dev loss: 0.8458 r:0.2660
en_zh Dev loss: 0.7178 r:0.4852
Current avg r:0.3756 Best avg r: 0.3850
18:28:46,445 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:12,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:37,956 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3605
en_de Dev loss: 0.8761 r:0.2655
en_zh Dev loss: 0.8243 r:0.4742
Current avg r:0.3699 Best avg r: 0.3850
18:30:54,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:20,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:46,372 root INFO Epoch 6 Global steps: 20200 Train loss: 0.3232
en_de Dev loss: 0.8375 r:0.2623
en_zh Dev loss: 0.7321 r:0.4841
Current avg r:0.3732 Best avg r: 0.3850
18:33:04,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:30,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:55,874 root INFO Epoch 6 Global steps: 20400 Train loss: 0.3040
en_de Dev loss: 0.8489 r:0.2589
en_zh Dev loss: 0.7881 r:0.4712
Current avg r:0.3651 Best avg r: 0.3850
18:35:12,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:38,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:03,980 root INFO Epoch 6 Global steps: 20600 Train loss: 0.2947
en_de Dev loss: 0.8490 r:0.2415
en_zh Dev loss: 0.7579 r:0.4793
Current avg r:0.3604 Best avg r: 0.3850
18:37:20,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:37:46,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:12,115 root INFO Epoch 6 Global steps: 20800 Train loss: 0.3052
en_de Dev loss: 0.8606 r:0.2340
en_zh Dev loss: 0.7581 r:0.4728
Current avg r:0.3534 Best avg r: 0.3850
18:39:28,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:54,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:20,312 root INFO Epoch 6 Global steps: 21000 Train loss: 0.3340
en_de Dev loss: 0.8386 r:0.2480
en_zh Dev loss: 0.7622 r:0.4636
Current avg r:0.3558 Best avg r: 0.3850
18:41:37,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:03,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:28,874 root INFO Epoch 7 Global steps: 21200 Train loss: 0.3063
en_de Dev loss: 0.8840 r:0.2442
en_zh Dev loss: 0.8960 r:0.4729
Current avg r:0.3585 Best avg r: 0.3850
18:43:45,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:12,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:38,448 root INFO Epoch 7 Global steps: 21400 Train loss: 0.2654
en_de Dev loss: 0.8735 r:0.2434
en_zh Dev loss: 0.8372 r:0.4745
Current avg r:0.3589 Best avg r: 0.3850
18:45:54,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:20,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:46,584 root INFO Epoch 7 Global steps: 21600 Train loss: 0.2600
en_de Dev loss: 0.8586 r:0.2389
en_zh Dev loss: 0.7965 r:0.4677
Current avg r:0.3533 Best avg r: 0.3850
18:48:03,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:28,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:54,782 root INFO Epoch 7 Global steps: 21800 Train loss: 0.3057
en_de Dev loss: 0.8702 r:0.2487
en_zh Dev loss: 0.8381 r:0.4620
Current avg r:0.3554 Best avg r: 0.3850
18:50:11,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:37,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:03,181 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2824
en_de Dev loss: 0.8586 r:0.2510
en_zh Dev loss: 0.7836 r:0.4681
Current avg r:0.3596 Best avg r: 0.3850
18:52:19,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:45,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:11,254 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2895
en_de Dev loss: 0.8498 r:0.2467
en_zh Dev loss: 0.7178 r:0.4766
Current avg r:0.3616 Best avg r: 0.3850
18:54:27,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:53,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:19,319 root INFO Epoch 7 Global steps: 22400 Train loss: 0.3001
en_de Dev loss: 0.8521 r:0.2373
en_zh Dev loss: 0.7515 r:0.4707
Current avg r:0.3540 Best avg r: 0.3850
18:56:36,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:01,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:27,750 root INFO Epoch 7 Global steps: 22600 Train loss: 0.2783
en_de Dev loss: 0.8665 r:0.2411
en_zh Dev loss: 0.7820 r:0.4715
Current avg r:0.3563 Best avg r: 0.3850
18:58:44,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:10,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:36,208 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2807
en_de Dev loss: 0.8533 r:0.2395
en_zh Dev loss: 0.7758 r:0.4715
Current avg r:0.3555 Best avg r: 0.3850
19:00:52,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:18,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:44,720 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2805
en_de Dev loss: 0.9682 r:0.1647
en_zh Dev loss: 0.8982 r:0.4712
Current avg r:0.3180 Best avg r: 0.3850
19:03:01,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:27,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:53,26 root INFO Epoch 7 Global steps: 23200 Train loss: 0.3154
en_de Dev loss: 0.8970 r:0.1952
en_zh Dev loss: 0.8526 r:0.4672
Current avg r:0.3312 Best avg r: 0.3850
19:05:09,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:35,711 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:01,567 root INFO Epoch 7 Global steps: 23400 Train loss: 0.3338
en_de Dev loss: 0.8944 r:0.1913
en_zh Dev loss: 0.8182 r:0.4735
Current avg r:0.3324 Best avg r: 0.3850
19:07:19,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:45,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:11,484 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2872
en_de Dev loss: 0.8806 r:0.2095
en_zh Dev loss: 0.7371 r:0.4821
Current avg r:0.3458 Best avg r: 0.3850
19:09:27,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:53,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:19,619 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2502
en_de Dev loss: 0.8934 r:0.1933
en_zh Dev loss: 0.7502 r:0.4830
Current avg r:0.3381 Best avg r: 0.3850
19:11:36,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:01,934 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:12:27,763 root INFO Epoch 7 Global steps: 24000 Train loss: 0.2752
en_de Dev loss: 0.8836 r:0.2082
en_zh Dev loss: 0.7509 r:0.4701
Current avg r:0.3391 Best avg r: 0.3850
19:13:44,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:10,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:36,130 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2657
en_de Dev loss: 0.9145 r:0.1865
en_zh Dev loss: 0.7845 r:0.4731
Current avg r:0.3298 Best avg r: 0.3850
19:15:52,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:18,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:44,138 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2621
en_de Dev loss: 0.9030 r:0.2278
en_zh Dev loss: 0.7960 r:0.4650
Current avg r:0.3464 Best avg r: 0.3850
19:18:00,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:26,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:52,239 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2139
en_de Dev loss: 0.8959 r:0.2050
en_zh Dev loss: 0.8050 r:0.4663
Current avg r:0.3356 Best avg r: 0.3850
19:20:08,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:34,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:00,331 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2749
en_de Dev loss: 0.8784 r:0.2089
en_zh Dev loss: 0.7930 r:0.4658
Current avg r:0.3373 Best avg r: 0.3850
19:22:16,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:42,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:08,456 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2907
en_de Dev loss: 0.8812 r:0.1960
en_zh Dev loss: 0.8010 r:0.4506
Current avg r:0.3233 Best avg r: 0.3850
19:24:24,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:50,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:16,399 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2636
en_de Dev loss: 0.8813 r:0.2065
en_zh Dev loss: 0.8068 r:0.4622
Current avg r:0.3344 Best avg r: 0.3850
19:26:32,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:58,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:24,426 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2820
en_de Dev loss: 0.8684 r:0.1956
en_zh Dev loss: 0.7554 r:0.4648
Current avg r:0.3302 Best avg r: 0.3850
19:28:40,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:08,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:33,902 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2621
en_de Dev loss: 0.8705 r:0.2087
en_zh Dev loss: 0.8086 r:0.4462
Current avg r:0.3275 Best avg r: 0.3850
19:30:51,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:31:17,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:44,534 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2342
en_de Dev loss: 0.8880 r:0.1970
en_zh Dev loss: 0.8591 r:0.4445
Current avg r:0.3207 Best avg r: 0.3850
19:33:01,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:27,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:52,887 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2481
en_de Dev loss: 0.9029 r:0.1997
en_zh Dev loss: 0.8680 r:0.4398
Current avg r:0.3198 Best avg r: 0.3850
19:35:09,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:35,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:00,952 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2782
en_de Dev loss: 0.8808 r:0.2066
en_zh Dev loss: 0.7808 r:0.4479
Current avg r:0.3273 Best avg r: 0.3850
19:37:17,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:37:43,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:09,200 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2401
en_de Dev loss: 0.9094 r:0.2095
en_zh Dev loss: 0.8101 r:0.4577
Current avg r:0.3336 Best avg r: 0.3850
19:39:25,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:51,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:17,165 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2665
en_de Dev loss: 0.8814 r:0.2098
en_zh Dev loss: 0.8137 r:0.4582
Current avg r:0.3340 Best avg r: 0.3850
19:41:33,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:59,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:25,156 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2254
en_de Dev loss: 0.8938 r:0.2023
en_zh Dev loss: 0.8178 r:0.4621
Current avg r:0.3322 Best avg r: 0.3850
19:43:41,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:07,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:33,159 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2776
en_de Dev loss: 0.8945 r:0.2091
en_zh Dev loss: 0.8163 r:0.4532
Current avg r:0.3311 Best avg r: 0.3850
19:45:50,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:15,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:46:41,727 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2320
en_de Dev loss: 0.8906 r:0.2147
en_zh Dev loss: 0.8095 r:0.4476
Current avg r:0.3312 Best avg r: 0.3850
19:48:01,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:27,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:52,894 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2093
en_de Dev loss: 0.8884 r:0.2200
en_zh Dev loss: 0.8070 r:0.4551
Current avg r:0.3375 Best avg r: 0.3850
19:50:10,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:36,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:02,549 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2141
en_de Dev loss: 0.8583 r:0.2305
en_zh Dev loss: 0.7824 r:0.4582
Current avg r:0.3444 Best avg r: 0.3850
19:52:19,459 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:45,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:11,82 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2255
en_de Dev loss: 0.8908 r:0.2013
en_zh Dev loss: 0.8681 r:0.4533
Current avg r:0.3273 Best avg r: 0.3850
19:54:28,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:53,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:19,586 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2233
en_de Dev loss: 0.8916 r:0.2161
en_zh Dev loss: 0.8326 r:0.4472
Current avg r:0.3316 Best avg r: 0.3850
19:56:37,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:03,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:29,36 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2329
en_de Dev loss: 0.8813 r:0.2056
en_zh Dev loss: 0.8344 r:0.4467
Current avg r:0.3261 Best avg r: 0.3850
19:58:47,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:12,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:38,749 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2060
en_de Dev loss: 0.9066 r:0.1997
en_zh Dev loss: 0.8468 r:0.4518
Current avg r:0.3257 Best avg r: 0.3850
20:00:55,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:01:21,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:01:47,330 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2294
en_de Dev loss: 0.9021 r:0.2070
en_zh Dev loss: 0.7828 r:0.4545
Current avg r:0.3308 Best avg r: 0.3850
20:03:04,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:30,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:55,906 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2146
en_de Dev loss: 0.8975 r:0.1926
en_zh Dev loss: 0.7806 r:0.4533
Current avg r:0.3230 Best avg r: 0.3850
20:05:12,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:38,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:04,57 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2273
en_de Dev loss: 0.9100 r:0.1992
en_zh Dev loss: 0.7741 r:0.4603
Current avg r:0.3298 Best avg r: 0.3850
20:07:20,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:07:46,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:12,40 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2487
en_de Dev loss: 0.9297 r:0.1670
en_zh Dev loss: 0.7815 r:0.4474
Current avg r:0.3072 Best avg r: 0.3850
20:09:30,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:56,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:21,933 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2391
en_de Dev loss: 0.9252 r:0.1856
en_zh Dev loss: 0.7826 r:0.4587
Current avg r:0.3221 Best avg r: 0.3850
20:11:38,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:04,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:30,347 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2364
en_de Dev loss: 0.9332 r:0.1686
en_zh Dev loss: 0.7890 r:0.4557
Current avg r:0.3122 Best avg r: 0.3850
20:13:48,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:14,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:40,104 root INFO Epoch 9 Global steps: 29800 Train loss: 0.2013
en_de Dev loss: 0.9416 r:0.1894
en_zh Dev loss: 0.8278 r:0.4550
Current avg r:0.3222 Best avg r: 0.3850
20:15:56,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:22,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:48,725 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2345
en_de Dev loss: 0.9465 r:0.1772
en_zh Dev loss: 0.8668 r:0.4442
Current avg r:0.3107 Best avg r: 0.3850
20:18:05,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:31,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:57,120 root INFO Epoch 10 Global steps: 30200 Train loss: 0.2196
en_de Dev loss: 0.9136 r:0.1987
en_zh Dev loss: 0.7515 r:0.4625
Current avg r:0.3306 Best avg r: 0.3850
20:20:14,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:40,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:06,437 root INFO Epoch 10 Global steps: 30400 Train loss: 0.1925
en_de Dev loss: 0.9229 r:0.1905
en_zh Dev loss: 0.7717 r:0.4639
Current avg r:0.3272 Best avg r: 0.3850
20:22:22,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:22:48,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:14,436 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2385
en_de Dev loss: 0.9232 r:0.1949
en_zh Dev loss: 0.8060 r:0.4613
Current avg r:0.3281 Best avg r: 0.3850
20:24:30,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:56,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:22,578 root INFO Epoch 10 Global steps: 30800 Train loss: 0.2087
en_de Dev loss: 0.9300 r:0.1640
en_zh Dev loss: 0.8066 r:0.4652
Current avg r:0.3146 Best avg r: 0.3850
20:26:39,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:04,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:30,557 root INFO Epoch 10 Global steps: 31000 Train loss: 0.2006
en_de Dev loss: 0.9054 r:0.1810
en_zh Dev loss: 0.8081 r:0.4508
Current avg r:0.3159 Best avg r: 0.3850
20:28:48,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:14,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:39,908 root INFO Epoch 10 Global steps: 31200 Train loss: 0.1989
en_de Dev loss: 0.9213 r:0.1751
en_zh Dev loss: 0.7802 r:0.4656
Current avg r:0.3204 Best avg r: 0.3850
20:30:56,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:22,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:48,139 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1854
en_de Dev loss: 0.9033 r:0.1874
en_zh Dev loss: 0.7783 r:0.4540
Current avg r:0.3207 Best avg r: 0.3850
20:33:04,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:33:30,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:56,328 root INFO Epoch 10 Global steps: 31600 Train loss: 0.2046
en_de Dev loss: 0.9059 r:0.1740
en_zh Dev loss: 0.7651 r:0.4629
Current avg r:0.3184 Best avg r: 0.3850
20:35:14,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:41,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:07,116 root INFO Epoch 10 Global steps: 31800 Train loss: 0.2138
en_de Dev loss: 0.9129 r:0.1828
en_zh Dev loss: 0.7744 r:0.4669
Current avg r:0.3248 Best avg r: 0.3850
20:37:23,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:49,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:15,64 root INFO Epoch 10 Global steps: 32000 Train loss: 0.2045
en_de Dev loss: 0.9172 r:0.1736
en_zh Dev loss: 0.8425 r:0.4565
Current avg r:0.3150 Best avg r: 0.3850
20:39:31,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:57,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:23,99 root INFO Epoch 10 Global steps: 32200 Train loss: 0.2037
en_de Dev loss: 0.9468 r:0.1667
en_zh Dev loss: 0.9238 r:0.4507
Current avg r:0.3087 Best avg r: 0.3850
20:41:42,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:08,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:33,919 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1920
en_de Dev loss: 0.9331 r:0.1649
en_zh Dev loss: 0.8323 r:0.4544
Current avg r:0.3096 Best avg r: 0.3850
20:43:50,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:16,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:42,133 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1945
en_de Dev loss: 0.9182 r:0.1676
en_zh Dev loss: 0.8357 r:0.4502
Current avg r:0.3089 Best avg r: 0.3850
20:45:58,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:24,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:50,334 root INFO Epoch 10 Global steps: 32800 Train loss: 0.2104
en_de Dev loss: 0.9198 r:0.1788
en_zh Dev loss: 0.8169 r:0.4474
Current avg r:0.3131 Best avg r: 0.3850
20:48:08,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:33,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:59,780 root INFO Epoch 10 Global steps: 33000 Train loss: 0.1833
en_de Dev loss: 0.9217 r:0.1796
en_zh Dev loss: 0.8116 r:0.4546
Current avg r:0.3171 Best avg r: 0.3850
20:50:17,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:42,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:08,660 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1689
en_de Dev loss: 0.9181 r:0.1758
en_zh Dev loss: 0.8169 r:0.4530
Current avg r:0.3144 Best avg r: 0.3850
20:52:25,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:50,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:16,721 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1751
en_de Dev loss: 0.9301 r:0.1828
en_zh Dev loss: 0.8298 r:0.4500
Current avg r:0.3164 Best avg r: 0.3850
20:54:33,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:59,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:25,14 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1818
en_de Dev loss: 0.8939 r:0.2074
en_zh Dev loss: 0.8388 r:0.4527
Current avg r:0.3301 Best avg r: 0.3850
20:56:41,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:07,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:57:33,44 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1805
en_de Dev loss: 0.9058 r:0.2054
en_zh Dev loss: 0.7849 r:0.4510
Current avg r:0.3282 Best avg r: 0.3850
20:58:49,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:15,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:41,95 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1947
en_de Dev loss: 0.9352 r:0.1858
en_zh Dev loss: 0.8569 r:0.4563
Current avg r:0.3210 Best avg r: 0.3850
21:00:57,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:23,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:49,117 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1768
en_de Dev loss: 0.8993 r:0.1963
en_zh Dev loss: 0.8024 r:0.4515
Current avg r:0.3239 Best avg r: 0.3850
21:03:05,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:31,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:57,250 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1949
en_de Dev loss: 0.9102 r:0.1899
en_zh Dev loss: 0.7640 r:0.4664
Current avg r:0.3281 Best avg r: 0.3850
21:05:13,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:39,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:06,521 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1794
en_de Dev loss: 0.9056 r:0.1817
en_zh Dev loss: 0.8139 r:0.4559
Current avg r:0.3188 Best avg r: 0.3850
21:07:22,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:48,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:14,674 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1787
en_de Dev loss: 0.9036 r:0.1967
en_zh Dev loss: 0.7911 r:0.4507
Current avg r:0.3237 Best avg r: 0.3850
21:09:31,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:57,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:23,151 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1796
en_de Dev loss: 0.9402 r:0.1920
en_zh Dev loss: 0.8778 r:0.4450
Current avg r:0.3185 Best avg r: 0.3850
21:11:40,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:05,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:12:31,625 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1923
en_de Dev loss: 0.9100 r:0.1798
en_zh Dev loss: 0.8634 r:0.4359
Current avg r:0.3078 Best avg r: 0.3850
21:13:48,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:14,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:40,37 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1870
en_de Dev loss: 0.8861 r:0.1923
en_zh Dev loss: 0.7680 r:0.4597
Current avg r:0.3260 Best avg r: 0.3850
21:15:56,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:22,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:48,618 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1830
en_de Dev loss: 0.8980 r:0.1953
en_zh Dev loss: 0.8028 r:0.4503
Current avg r:0.3228 Best avg r: 0.3850
21:18:05,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:31,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:57,121 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1756
en_de Dev loss: 0.9148 r:0.1889
en_zh Dev loss: 0.7931 r:0.4599
Current avg r:0.3244 Best avg r: 0.3850
21:20:13,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:39,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:05,692 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1782
en_de Dev loss: 0.9309 r:0.1865
en_zh Dev loss: 0.7753 r:0.4676
Current avg r:0.3271 Best avg r: 0.3850
21:22:25,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:51,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:17,451 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1750
en_de Dev loss: 0.9259 r:0.1723
en_zh Dev loss: 0.8659 r:0.4531
Current avg r:0.3127 Best avg r: 0.3850
21:24:34,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:01,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:27,382 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1646
en_de Dev loss: 0.9618 r:0.1698
en_zh Dev loss: 0.8788 r:0.4618
Current avg r:0.3158 Best avg r: 0.3850
21:26:43,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:09,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:35,479 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1647
en_de Dev loss: 0.9284 r:0.1899
en_zh Dev loss: 0.8062 r:0.4587
Current avg r:0.3243 Best avg r: 0.3850
21:28:54,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:29:20,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:46,511 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1701
en_de Dev loss: 0.9141 r:0.1870
en_zh Dev loss: 0.7995 r:0.4547
Current avg r:0.3208 Best avg r: 0.3850
21:31:03,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:28,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:54,727 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1605
en_de Dev loss: 0.9033 r:0.1955
en_zh Dev loss: 0.8429 r:0.4643
Current avg r:0.3299 Best avg r: 0.3850
21:33:11,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:33:37,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:02,870 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1588
en_de Dev loss: 0.9174 r:0.1942
en_zh Dev loss: 0.8305 r:0.4545
Current avg r:0.3243 Best avg r: 0.3850
21:35:19,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:45,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:11,14 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1766
en_de Dev loss: 0.9514 r:0.1941
en_zh Dev loss: 0.7955 r:0.4623
Current avg r:0.3282 Best avg r: 0.3850
21:37:27,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:54,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:20,492 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1707
en_de Dev loss: 0.9381 r:0.1790
en_zh Dev loss: 0.8194 r:0.4598
Current avg r:0.3194 Best avg r: 0.3850
21:39:37,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:02,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:28,563 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1684
en_de Dev loss: 0.9419 r:0.2018
en_zh Dev loss: 0.8306 r:0.4639
Current avg r:0.3329 Best avg r: 0.3850
21:41:45,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:10,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:36,684 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1553
en_de Dev loss: 0.9169 r:0.1971
en_zh Dev loss: 0.7575 r:0.4690
Current avg r:0.3330 Best avg r: 0.3850
21:43:53,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:19,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:44,777 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1632
en_de Dev loss: 0.9060 r:0.1902
en_zh Dev loss: 0.8248 r:0.4542
Current avg r:0.3222 Best avg r: 0.3850
21:46:02,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:46:29,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:55,573 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1623
en_de Dev loss: 0.9190 r:0.1994
en_zh Dev loss: 0.8109 r:0.4661
Current avg r:0.3327 Best avg r: 0.3850
21:48:15,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:42,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:08,280 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1627
en_de Dev loss: 0.9061 r:0.2001
en_zh Dev loss: 0.7810 r:0.4645
Current avg r:0.3323 Best avg r: 0.3850
21:50:25,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:50,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:16,769 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1571
en_de Dev loss: 0.9043 r:0.1928
en_zh Dev loss: 0.7673 r:0.4632
Current avg r:0.3280 Best avg r: 0.3850
21:52:33,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:59,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:24,856 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1585
en_de Dev loss: 0.9098 r:0.1742
en_zh Dev loss: 0.8058 r:0.4556
Current avg r:0.3149 Best avg r: 0.3850
21:54:41,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:07,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:55:33,424 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1433
en_de Dev loss: 0.8983 r:0.1852
en_zh Dev loss: 0.7995 r:0.4636
Current avg r:0.3244 Best avg r: 0.3850
21:56:49,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:15,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:57:42,958 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1710
en_de Dev loss: 0.9617 r:0.1741
en_zh Dev loss: 0.7814 r:0.4756
Current avg r:0.3248 Best avg r: 0.3850
21:58:59,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:25,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:51,41 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1519
en_de Dev loss: 0.9560 r:0.1718
en_zh Dev loss: 0.8744 r:0.4661
Current avg r:0.3189 Best avg r: 0.3850
22:01:07,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:01:33,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:59,123 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1587
en_de Dev loss: 0.9414 r:0.1751
en_zh Dev loss: 0.7824 r:0.4654
Current avg r:0.3203 Best avg r: 0.3850
22:03:15,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:41,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:07,272 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1469
en_de Dev loss: 0.9272 r:0.1759
en_zh Dev loss: 0.7692 r:0.4593
Current avg r:0.3176 Best avg r: 0.3850
22:05:26,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:52,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:18,380 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1381
en_de Dev loss: 0.9723 r:0.1667
en_zh Dev loss: 0.7857 r:0.4732
Current avg r:0.3200 Best avg r: 0.3850
22:07:36,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:02,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:08:27,869 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1610
en_de Dev loss: 0.9089 r:0.1684
en_zh Dev loss: 0.7524 r:0.4644
Current avg r:0.3164 Best avg r: 0.3850
22:09:44,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:10,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:35,958 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1458
en_de Dev loss: 0.9364 r:0.1754
en_zh Dev loss: 0.8260 r:0.4673
Current avg r:0.3213 Best avg r: 0.3850
22:11:52,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:18,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:43,972 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1633
en_de Dev loss: 0.9339 r:0.1772
en_zh Dev loss: 0.8502 r:0.4632
Current avg r:0.3202 Best avg r: 0.3850
22:14:00,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:26,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:52,444 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1538
en_de Dev loss: 0.9225 r:0.1826
en_zh Dev loss: 0.7515 r:0.4722
Current avg r:0.3274 Best avg r: 0.3850
22:16:09,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:16:36,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:02,363 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1407
en_de Dev loss: 0.9008 r:0.1944
en_zh Dev loss: 0.7786 r:0.4608
Current avg r:0.3276 Best avg r: 0.3850
22:18:20,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:46,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:11,811 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1632
en_de Dev loss: 0.9265 r:0.1807
en_zh Dev loss: 0.8064 r:0.4587
Current avg r:0.3197 Best avg r: 0.3850
22:20:28,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:54,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:21:20,84 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1316
en_de Dev loss: 0.9429 r:0.1756
en_zh Dev loss: 0.7964 r:0.4602
Current avg r:0.3179 Best avg r: 0.3850
22:22:36,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:02,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:28,129 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1578
en_de Dev loss: 0.9605 r:0.1759
en_zh Dev loss: 0.8103 r:0.4649
Current avg r:0.3204 Best avg r: 0.3850
22:24:44,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:10,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:25:36,236 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1407
en_de Dev loss: 0.9669 r:0.1789
en_zh Dev loss: 0.8445 r:0.4597
Current avg r:0.3193 Best avg r: 0.3850
22:26:53,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:27:19,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:44,754 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1348
en_de Dev loss: 0.9680 r:0.1794
en_zh Dev loss: 0.8637 r:0.4532
Current avg r:0.3163 Best avg r: 0.3850
22:29:01,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:27,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:52,905 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1268
en_de Dev loss: 0.9428 r:0.1784
en_zh Dev loss: 0.8025 r:0.4566
Current avg r:0.3175 Best avg r: 0.3850
22:31:09,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:35,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:01,385 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1438
en_de Dev loss: 0.9404 r:0.1789
en_zh Dev loss: 0.8287 r:0.4605
Current avg r:0.3197 Best avg r: 0.3850
22:33:18,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:44,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:09,887 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1438
en_de Dev loss: 0.9504 r:0.1729
en_zh Dev loss: 0.7791 r:0.4640
Current avg r:0.3184 Best avg r: 0.3850
22:35:26,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:52,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:18,385 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1409
en_de Dev loss: 0.9492 r:0.1701
en_zh Dev loss: 0.8005 r:0.4598
Current avg r:0.3149 Best avg r: 0.3850
22:37:34,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:00,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:26,588 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1385
en_de Dev loss: 0.9310 r:0.1804
en_zh Dev loss: 0.7760 r:0.4619
Current avg r:0.3212 Best avg r: 0.3850
22:39:43,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:08,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:34,714 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1340
en_de Dev loss: 0.9108 r:0.1856
en_zh Dev loss: 0.7460 r:0.4671
Current avg r:0.3264 Best avg r: 0.3850
22:41:51,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:17,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:42,788 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1365
en_de Dev loss: 0.9305 r:0.1767
en_zh Dev loss: 0.7544 r:0.4673
Current avg r:0.3220 Best avg r: 0.3850
22:43:59,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:25,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:50,779 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1232
en_de Dev loss: 0.9593 r:0.1590
en_zh Dev loss: 0.8441 r:0.4662
Current avg r:0.3126 Best avg r: 0.3850
22:46:07,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:33,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:58,767 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1354
en_de Dev loss: 0.9553 r:0.1612
en_zh Dev loss: 0.7982 r:0.4586
Current avg r:0.3099 Best avg r: 0.3850
22:48:15,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:41,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:06,850 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1406
en_de Dev loss: 0.9294 r:0.1668
en_zh Dev loss: 0.7829 r:0.4593
Current avg r:0.3131 Best avg r: 0.3850
22:50:23,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:49,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:14,895 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1300
en_de Dev loss: 0.9605 r:0.1564
en_zh Dev loss: 0.8338 r:0.4684
Current avg r:0.3124 Best avg r: 0.3850
22:52:31,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:57,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:22,906 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1332
en_de Dev loss: 0.9520 r:0.1478
en_zh Dev loss: 0.8344 r:0.4615
Current avg r:0.3047 Best avg r: 0.3850
22:54:39,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:05,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:30,872 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1337
en_de Dev loss: 0.9618 r:0.1627
en_zh Dev loss: 0.8393 r:0.4626
Current avg r:0.3127 Best avg r: 0.3850
22:56:47,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:13,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:39,105 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1280
en_de Dev loss: 0.9600 r:0.1649
en_zh Dev loss: 0.8087 r:0.4661
Current avg r:0.3155 Best avg r: 0.3850
22:58:56,77 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:21,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:47,781 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1232
en_de Dev loss: 1.0237 r:0.1523
en_zh Dev loss: 0.7955 r:0.4668
Current avg r:0.3095 Best avg r: 0.3850
23:01:05,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:31,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:57,83 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1265
en_de Dev loss: 0.9733 r:0.1585
en_zh Dev loss: 0.9224 r:0.4574
Current avg r:0.3080 Best avg r: 0.3850
23:03:13,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:39,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:05,438 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1306
en_de Dev loss: 0.9432 r:0.1729
en_zh Dev loss: 0.7967 r:0.4658
Current avg r:0.3194 Best avg r: 0.3850
23:05:22,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:48,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:13,843 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1238
en_de Dev loss: 0.9362 r:0.1634
en_zh Dev loss: 0.7789 r:0.4661
Current avg r:0.3148 Best avg r: 0.3850
23:07:30,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:56,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:21,976 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1218
en_de Dev loss: 0.9976 r:0.1618
en_zh Dev loss: 0.8269 r:0.4767
Current avg r:0.3192 Best avg r: 0.3850
23:09:38,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:04,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:29,964 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1264
en_de Dev loss: 0.9239 r:0.1718
en_zh Dev loss: 0.7586 r:0.4687
Current avg r:0.3203 Best avg r: 0.3850
23:11:46,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:12:12,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:37,878 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1267
en_de Dev loss: 0.9293 r:0.1890
en_zh Dev loss: 0.7583 r:0.4694
Current avg r:0.3292 Best avg r: 0.3850
23:13:54,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:20,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:46,73 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1239
en_de Dev loss: 0.9386 r:0.1763
en_zh Dev loss: 0.8081 r:0.4586
Current avg r:0.3175 Best avg r: 0.3850
23:16:03,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:29,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:55,378 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1208
en_de Dev loss: 0.9441 r:0.1852
en_zh Dev loss: 0.7788 r:0.4599
Current avg r:0.3225 Best avg r: 0.3850
23:18:11,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:37,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:03,557 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1159
en_de Dev loss: 0.9477 r:0.1750
en_zh Dev loss: 0.8155 r:0.4610
Current avg r:0.3180 Best avg r: 0.3850
23:20:21,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:47,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:21:12,861 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1206
en_de Dev loss: 0.9468 r:0.1860
en_zh Dev loss: 0.7857 r:0.4677
Current avg r:0.3268 Best avg r: 0.3850
23:22:29,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:55,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:20,824 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1217
en_de Dev loss: 0.9505 r:0.1769
en_zh Dev loss: 0.7918 r:0.4708
Current avg r:0.3238 Best avg r: 0.3850
23:24:37,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:03,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:28,818 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1190
en_de Dev loss: 0.9326 r:0.1693
en_zh Dev loss: 0.7481 r:0.4693
Current avg r:0.3193 Best avg r: 0.3850
23:26:45,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:27:11,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:37,101 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1115
en_de Dev loss: 0.9344 r:0.1604
en_zh Dev loss: 0.8163 r:0.4606
Current avg r:0.3105 Best avg r: 0.3850
23:28:56,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:25,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:51,49 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1221
en_de Dev loss: 0.9701 r:0.1661
en_zh Dev loss: 0.8289 r:0.4618
Current avg r:0.3140 Best avg r: 0.3850
23:31:07,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:33,749 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:59,512 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1068
en_de Dev loss: 0.9431 r:0.1591
en_zh Dev loss: 0.8127 r:0.4615
Current avg r:0.3103 Best avg r: 0.3850
23:33:15,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:41,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:34:07,504 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1085
en_de Dev loss: 0.9673 r:0.1602
en_zh Dev loss: 0.8018 r:0.4634
Current avg r:0.3118 Best avg r: 0.3850
23:35:25,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:51,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:16,950 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1033
en_de Dev loss: 0.9561 r:0.1590
en_zh Dev loss: 0.7908 r:0.4688
Current avg r:0.3139 Best avg r: 0.3850
23:37:33,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:59,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:25,22 root INFO Epoch 16 Global steps: 48800 Train loss: 0.1083
en_de Dev loss: 0.9451 r:0.1739
en_zh Dev loss: 0.7939 r:0.4740
Current avg r:0.3239 Best avg r: 0.3850
23:39:41,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:08,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:34,539 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1079
en_de Dev loss: 0.9641 r:0.1841
en_zh Dev loss: 0.8071 r:0.4690
Current avg r:0.3266 Best avg r: 0.3850
23:41:50,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:16,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:42,655 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1173
en_de Dev loss: 0.9411 r:0.1694
en_zh Dev loss: 0.7754 r:0.4765
Current avg r:0.3229 Best avg r: 0.3850
23:43:59,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:24,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:50,753 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1121
en_de Dev loss: 0.9714 r:0.1644
en_zh Dev loss: 0.8546 r:0.4671
Current avg r:0.3158 Best avg r: 0.3850
23:46:07,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:33,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:58,859 root INFO Epoch 16 Global steps: 49600 Train loss: 0.1108
en_de Dev loss: 0.9471 r:0.1776
en_zh Dev loss: 0.7781 r:0.4766
Current avg r:0.3271 Best avg r: 0.3850
23:48:15,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:41,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:06,903 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1026
en_de Dev loss: 0.9557 r:0.1604
en_zh Dev loss: 0.7650 r:0.4790
Current avg r:0.3197 Best avg r: 0.3850
23:50:23,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:49,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:51:14,852 root INFO Epoch 16 Global steps: 50000 Train loss: 0.1110
en_de Dev loss: 0.9647 r:0.1542
en_zh Dev loss: 0.7950 r:0.4747
Current avg r:0.3145 Best avg r: 0.3850
23:52:31,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:57,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:23,298 root INFO Epoch 16 Global steps: 50200 Train loss: 0.1030
en_de Dev loss: 0.9555 r:0.1632
en_zh Dev loss: 0.7713 r:0.4739
Current avg r:0.3185 Best avg r: 0.3850
23:54:39,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:05,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:31,437 root INFO Epoch 16 Global steps: 50400 Train loss: 0.1069
en_de Dev loss: 0.9348 r:0.1501
en_zh Dev loss: 0.7590 r:0.4772
Current avg r:0.3136 Best avg r: 0.3850
23:56:49,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:15,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:43,643 root INFO Epoch 16 Global steps: 50600 Train loss: 0.1090
en_de Dev loss: 0.9726 r:0.1507
en_zh Dev loss: 0.7861 r:0.4775
Current avg r:0.3141 Best avg r: 0.3850
23:59:01,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:27,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:53,113 root INFO Epoch 16 Global steps: 50800 Train loss: 0.1093
en_de Dev loss: 0.9451 r:0.1658
en_zh Dev loss: 0.7921 r:0.4807
Current avg r:0.3233 Best avg r: 0.3850
00:01:09,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:35,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:02:01,194 root INFO Epoch 16 Global steps: 51000 Train loss: 0.1082
en_de Dev loss: 0.9416 r:0.1465
en_zh Dev loss: 0.7799 r:0.4749
Current avg r:0.3107 Best avg r: 0.3850
00:03:18,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:44,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:10,73 root INFO Epoch 17 Global steps: 51200 Train loss: 0.1023
en_de Dev loss: 1.0000 r:0.1550
en_zh Dev loss: 0.8026 r:0.4855
Current avg r:0.3202 Best avg r: 0.3850
00:05:26,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:52,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:06:18,590 root INFO Epoch 17 Global steps: 51400 Train loss: 0.1052
en_de Dev loss: 0.9921 r:0.1522
en_zh Dev loss: 0.7412 r:0.4858
Current avg r:0.3190 Best avg r: 0.3850
00:07:35,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:08:01,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:27,42 root INFO Epoch 17 Global steps: 51600 Train loss: 0.0991
en_de Dev loss: 0.9576 r:0.1559
en_zh Dev loss: 0.8102 r:0.4784
Current avg r:0.3172 Best avg r: 0.3850
00:09:43,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:09,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:35,386 root INFO Epoch 17 Global steps: 51800 Train loss: 0.1058
en_de Dev loss: 0.9919 r:0.1419
en_zh Dev loss: 0.8250 r:0.4770
Current avg r:0.3095 Best avg r: 0.3850
00:11:51,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:12:17,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:44,829 root INFO Epoch 17 Global steps: 52000 Train loss: 0.0923
en_de Dev loss: 0.9697 r:0.1540
en_zh Dev loss: 0.7352 r:0.4852
Current avg r:0.3196 Best avg r: 0.3850
00:14:01,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:27,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:52,970 root INFO Epoch 17 Global steps: 52200 Train loss: 0.0977
en_de Dev loss: 0.9813 r:0.1392
en_zh Dev loss: 0.7824 r:0.4783
Current avg r:0.3088 Best avg r: 0.3850
00:16:09,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:16:35,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:17:01,471 root INFO Epoch 17 Global steps: 52400 Train loss: 0.0958
en_de Dev loss: 0.9524 r:0.1636
en_zh Dev loss: 0.7793 r:0.4768
Current avg r:0.3202 Best avg r: 0.3850
00:18:18,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:44,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:09,970 root INFO Epoch 17 Global steps: 52600 Train loss: 0.0970
en_de Dev loss: 0.9701 r:0.1591
en_zh Dev loss: 0.8141 r:0.4727
Current avg r:0.3159 Best avg r: 0.3850
00:20:26,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:52,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:21:18,369 root INFO Epoch 17 Global steps: 52800 Train loss: 0.1081
en_de Dev loss: 0.9633 r:0.1654
en_zh Dev loss: 0.7544 r:0.4824
Current avg r:0.3239 Best avg r: 0.3850
00:22:35,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:00,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:26,772 root INFO Epoch 17 Global steps: 53000 Train loss: 0.0950
en_de Dev loss: 0.9682 r:0.1591
en_zh Dev loss: 0.7585 r:0.4810
Current avg r:0.3201 Best avg r: 0.3850
00:24:43,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:25:09,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:34,774 root INFO Epoch 17 Global steps: 53200 Train loss: 0.0999
en_de Dev loss: 0.9534 r:0.1620
en_zh Dev loss: 0.7700 r:0.4850
Current avg r:0.3235 Best avg r: 0.3850
00:26:51,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:27:17,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:42,777 root INFO Epoch 17 Global steps: 53400 Train loss: 0.1008
en_de Dev loss: 0.9538 r:0.1520
en_zh Dev loss: 0.7504 r:0.4842
Current avg r:0.3181 Best avg r: 0.3850
00:28:59,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:25,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:50,831 root INFO Epoch 17 Global steps: 53600 Train loss: 0.0960
en_de Dev loss: 0.9605 r:0.1540
en_zh Dev loss: 0.7962 r:0.4807
Current avg r:0.3173 Best avg r: 0.3850
00:31:07,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:32,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:58,724 root INFO Epoch 17 Global steps: 53800 Train loss: 0.0986
en_de Dev loss: 0.9587 r:0.1600
en_zh Dev loss: 0.7703 r:0.4839
Current avg r:0.3220 Best avg r: 0.3850
00:33:15,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:33:40,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:06,689 root INFO Epoch 17 Global steps: 54000 Train loss: 0.0981
en_de Dev loss: 0.9493 r:0.1424
en_zh Dev loss: 0.8048 r:0.4729
Current avg r:0.3076 Best avg r: 0.3850
00:35:23,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:49,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:16,893 root INFO Epoch 18 Global steps: 54200 Train loss: 0.0857
en_de Dev loss: 0.9723 r:0.1463
en_zh Dev loss: 0.7332 r:0.4842
Current avg r:0.3152 Best avg r: 0.3850
00:37:33,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:59,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:24,864 root INFO Epoch 18 Global steps: 54400 Train loss: 0.0871
en_de Dev loss: 0.9540 r:0.1625
en_zh Dev loss: 0.7500 r:0.4872
Current avg r:0.3248 Best avg r: 0.3850
00:39:41,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:07,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:34,652 root INFO Epoch 18 Global steps: 54600 Train loss: 0.0860
en_de Dev loss: 0.9631 r:0.1600
en_zh Dev loss: 0.7945 r:0.4781
Current avg r:0.3190 Best avg r: 0.3850
00:41:52,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:18,527 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:44,297 root INFO Epoch 18 Global steps: 54800 Train loss: 0.0907
en_de Dev loss: 0.9499 r:0.1598
en_zh Dev loss: 0.7557 r:0.4821
Current avg r:0.3210 Best avg r: 0.3850
00:34:31,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:57,345 root INFO 
id:en_de cur r: 0.0726 best r: 0.0726
00:35:23,453 root INFO 
id:en_zh cur r: 0.1673 best r: 0.1673
00:35:23,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:49,538 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
00:35:49,546 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
00:36:15,672 root INFO Epoch 0 Global steps: 200 Train loss: 0.7421
en_de Dev loss: 0.8883 r:0.0680
en_zh Dev loss: 0.8183 r:0.1681
Current avg r:0.1181 Best avg r: 0.1181
00:37:33,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:38:12,619 root INFO 
id:en_zh cur r: 0.1877 best r: 0.1877
00:38:12,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:38,699 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
00:38:38,704 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
00:39:04,810 root INFO Epoch 0 Global steps: 400 Train loss: 0.7021
en_de Dev loss: 0.8830 r:0.0711
en_zh Dev loss: 0.8066 r:0.2053
Current avg r:0.1382 Best avg r: 0.1382
00:40:22,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:01,916 root INFO 
id:en_zh cur r: 0.2459 best r: 0.2459
00:41:01,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:28,8 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
00:41:28,17 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
00:41:54,119 root INFO Epoch 0 Global steps: 600 Train loss: 0.8096
en_de Dev loss: 0.8828 r:0.0760
en_zh Dev loss: 0.7977 r:0.2556
Current avg r:0.1658 Best avg r: 0.1658
00:43:12,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:38,175 root INFO 
id:en_de cur r: 0.1120 best r: 0.1120
00:44:04,265 root INFO 
id:en_zh cur r: 0.2934 best r: 0.2934
00:44:04,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:30,400 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
00:44:30,408 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
00:44:56,555 root INFO Epoch 0 Global steps: 800 Train loss: 0.7839
en_de Dev loss: 0.8788 r:0.1073
en_zh Dev loss: 0.7899 r:0.2912
Current avg r:0.1993 Best avg r: 0.1993
00:46:14,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:40,770 root INFO 
id:en_de cur r: 0.1167 best r: 0.1167
00:47:06,914 root INFO 
id:en_zh cur r: 0.2974 best r: 0.2974
00:47:06,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:33,48 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
00:47:33,55 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
00:47:59,215 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7535
en_de Dev loss: 0.8777 r:0.1281
en_zh Dev loss: 0.7929 r:0.2985
Current avg r:0.2133 Best avg r: 0.2133
00:49:17,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:43,303 root INFO 
id:en_de cur r: 0.1295 best r: 0.1295
00:50:09,405 root INFO 
id:en_zh cur r: 0.3121 best r: 0.3121
00:50:09,405 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:35,536 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8013
en_de Dev loss: 0.8791 r:0.1361
en_zh Dev loss: 0.7949 r:0.2858
Current avg r:0.2109 Best avg r: 0.2133
00:51:53,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:19,697 root INFO 
id:en_de cur r: 0.1441 best r: 0.1441
00:52:32,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:58,900 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
00:52:58,906 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
00:53:25,56 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8313
en_de Dev loss: 0.8717 r:0.1582
en_zh Dev loss: 0.7801 r:0.3110
Current avg r:0.2346 Best avg r: 0.2346
00:54:42,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:22,202 root INFO 
id:en_zh cur r: 0.3442 best r: 0.3442
00:55:22,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:48,328 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
00:55:48,344 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
00:56:14,507 root INFO Epoch 0 Global steps: 1600 Train loss: 0.6850
en_de Dev loss: 0.8691 r:0.1496
en_zh Dev loss: 0.7485 r:0.3532
Current avg r:0.2514 Best avg r: 0.2514
00:57:32,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:58,398 root INFO 
id:en_de cur r: 0.1615 best r: 0.1615
00:58:11,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:37,590 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7111
en_de Dev loss: 0.9037 r:0.1413
en_zh Dev loss: 0.8013 r:0.3082
Current avg r:0.2248 Best avg r: 0.2514
00:59:55,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:34,633 root INFO 
id:en_zh cur r: 0.3507 best r: 0.3507
01:00:34,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:00,771 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
01:01:00,779 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
01:01:26,909 root INFO Epoch 0 Global steps: 2000 Train loss: 0.6734
en_de Dev loss: 0.8742 r:0.1730
en_zh Dev loss: 0.7683 r:0.3562
Current avg r:0.2646 Best avg r: 0.2646
01:02:44,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:10,851 root INFO 
id:en_de cur r: 0.1700 best r: 0.1700
01:03:36,945 root INFO 
id:en_zh cur r: 0.3591 best r: 0.3591
01:03:36,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:03,47 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
01:04:03,55 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
01:04:29,249 root INFO Epoch 0 Global steps: 2200 Train loss: 0.6890
en_de Dev loss: 0.8889 r:0.1840
en_zh Dev loss: 0.8218 r:0.3484
Current avg r:0.2662 Best avg r: 0.2662
01:05:47,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:13,343 root INFO 
id:en_de cur r: 0.1827 best r: 0.1827
01:06:39,418 root INFO 
id:en_zh cur r: 0.3888 best r: 0.3888
01:06:39,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:05,531 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
01:07:05,539 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
01:07:31,677 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6837
en_de Dev loss: 0.8638 r:0.1843
en_zh Dev loss: 0.7374 r:0.3853
Current avg r:0.2848 Best avg r: 0.2848
01:08:49,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:15,673 root INFO 
id:en_de cur r: 0.1940 best r: 0.1940
01:09:41,742 root INFO 
id:en_zh cur r: 0.4015 best r: 0.4015
01:09:41,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:07,818 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
01:10:07,836 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
01:10:33,993 root INFO Epoch 0 Global steps: 2600 Train loss: 0.7328
en_de Dev loss: 0.8544 r:0.1977
en_zh Dev loss: 0.7249 r:0.4040
Current avg r:0.3009 Best avg r: 0.3009
01:11:51,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:31,105 root INFO 
id:en_zh cur r: 0.4111 best r: 0.4111
01:12:31,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:57,223 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6686
en_de Dev loss: 0.9000 r:0.2039
en_zh Dev loss: 0.8428 r:0.3932
Current avg r:0.2986 Best avg r: 0.3009
01:14:15,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:54,308 root INFO 
id:en_zh cur r: 0.4297 best r: 0.4297
01:14:54,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:20,454 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
01:15:20,460 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
01:15:46,594 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7863
en_de Dev loss: 0.8588 r:0.1793
en_zh Dev loss: 0.6985 r:0.4253
Current avg r:0.3023 Best avg r: 0.3023
01:17:04,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:44,42 root INFO 
id:en_zh cur r: 0.4411 best r: 0.4411
01:17:44,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:10,90 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
01:18:10,96 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
01:18:36,157 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6773
en_de Dev loss: 0.8653 r:0.2088
en_zh Dev loss: 0.7888 r:0.4284
Current avg r:0.3186 Best avg r: 0.3186
01:19:53,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:20:19,818 root INFO 
id:en_de cur r: 0.2013 best r: 0.2013
09:53:19,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:45,677 root INFO 
id:en_de cur r: 0.0024 best r: 0.0024
09:54:11,414 root INFO 
id:en_zh cur r: 0.0838 best r: 0.0838
09:54:11,414 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:54:37,120 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
09:54:37,129 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
09:55:02,891 root INFO Epoch 0 Global steps: 200 Train loss: 0.7734
en_de Dev loss: 0.9040 r:0.0279
en_zh Dev loss: 0.8180 r:0.0858
Current avg r:0.0568 Best avg r: 0.0568
09:56:19,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:57,748 root INFO 
id:en_zh cur r: 0.1526 best r: 0.1526
09:56:57,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:23,463 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
09:57:23,469 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
09:57:49,265 root INFO Epoch 0 Global steps: 400 Train loss: 0.7468
en_de Dev loss: 0.8922 r:0.0541
en_zh Dev loss: 0.8112 r:0.1141
Current avg r:0.0841 Best avg r: 0.0841
09:59:05,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:59:44,193 root INFO 
id:en_zh cur r: 0.1622 best r: 0.1622
09:59:44,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:09,917 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:00:09,925 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:00:35,770 root INFO Epoch 0 Global steps: 600 Train loss: 0.7789
en_de Dev loss: 0.8839 r:0.0680
en_zh Dev loss: 0.8162 r:0.1336
Current avg r:0.1008 Best avg r: 0.1008
10:01:52,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:17,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:43,644 root INFO Epoch 0 Global steps: 800 Train loss: 0.6937
en_de Dev loss: 0.8857 r:0.0505
en_zh Dev loss: 0.8236 r:0.1440
Current avg r:0.0973 Best avg r: 0.1008
10:03:59,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:25,938 root INFO 
id:en_de cur r: 0.0196 best r: 0.0196
10:04:51,698 root INFO 
id:en_zh cur r: 0.1936 best r: 0.1936
10:04:51,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:17,457 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:05:17,476 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:05:43,266 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7633
en_de Dev loss: 0.8856 r:0.0536
en_zh Dev loss: 0.8066 r:0.2041
Current avg r:0.1289 Best avg r: 0.1289
10:06:59,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:07:25,459 root INFO 
id:en_de cur r: 0.0282 best r: 0.0282
10:07:51,214 root INFO 
id:en_zh cur r: 0.2376 best r: 0.2376
10:07:51,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:08:17,8 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:08:17,55 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:08:42,853 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7757
en_de Dev loss: 0.8836 r:0.0831
en_zh Dev loss: 0.8045 r:0.2300
Current avg r:0.1565 Best avg r: 0.1565
10:09:59,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:37,841 root INFO 
id:en_zh cur r: 0.2402 best r: 0.2402
10:10:37,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:03,616 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:11:03,625 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:11:29,429 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7862
en_de Dev loss: 0.8835 r:0.0798
en_zh Dev loss: 0.7999 r:0.2454
Current avg r:0.1626 Best avg r: 0.1626
10:12:45,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:11,679 root INFO 
id:en_de cur r: 0.0588 best r: 0.0588
10:13:37,479 root INFO 
id:en_zh cur r: 0.2690 best r: 0.2690
10:13:37,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:03,251 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:14:03,260 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:14:29,61 root INFO Epoch 0 Global steps: 1600 Train loss: 0.8129
en_de Dev loss: 0.8805 r:0.0981
en_zh Dev loss: 0.7926 r:0.2856
Current avg r:0.1918 Best avg r: 0.1918
10:15:45,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:11,241 root INFO 
id:en_de cur r: 0.0831 best r: 0.0831
10:16:36,986 root INFO 
id:en_zh cur r: 0.2769 best r: 0.2769
10:16:36,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:02,753 root INFO Epoch 0 Global steps: 1800 Train loss: 0.8748
en_de Dev loss: 0.8812 r:0.1000
en_zh Dev loss: 0.7890 r:0.2802
Current avg r:0.1901 Best avg r: 0.1918
10:18:19,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:45,10 root INFO 
id:en_de cur r: 0.0921 best r: 0.0921
10:19:10,765 root INFO 
id:en_zh cur r: 0.2838 best r: 0.2838
10:19:10,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:36,548 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7146
en_de Dev loss: 0.8855 r:0.0881
en_zh Dev loss: 0.7938 r:0.2760
Current avg r:0.1820 Best avg r: 0.1918
10:20:52,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:31,461 root INFO 
id:en_zh cur r: 0.3000 best r: 0.3000
10:21:31,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:21:57,238 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:21:57,245 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:22:23,142 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7734
en_de Dev loss: 0.8776 r:0.1123
en_zh Dev loss: 0.7758 r:0.3067
Current avg r:0.2095 Best avg r: 0.2095
10:23:39,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:05,458 root INFO 
id:en_de cur r: 0.1291 best r: 0.1291
10:24:31,239 root INFO 
id:en_zh cur r: 0.3262 best r: 0.3262
10:24:31,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:24:57,15 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:24:57,22 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:25:22,897 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7478
en_de Dev loss: 0.8767 r:0.1302
en_zh Dev loss: 0.7633 r:0.3350
Current avg r:0.2326 Best avg r: 0.2326
10:26:39,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:17,878 root INFO 
id:en_zh cur r: 0.3302 best r: 0.3302
10:27:17,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:43,670 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:27:43,680 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:28:09,543 root INFO Epoch 0 Global steps: 2600 Train loss: 0.7143
en_de Dev loss: 0.8874 r:0.1199
en_zh Dev loss: 0.7523 r:0.3468
Current avg r:0.2333 Best avg r: 0.2333
10:29:25,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:30:04,562 root INFO 
id:en_zh cur r: 0.3688 best r: 0.3688
10:30:04,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:30,352 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:30:30,359 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:30:56,188 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7953
en_de Dev loss: 0.8734 r:0.1386
en_zh Dev loss: 0.7432 r:0.3908
Current avg r:0.2647 Best avg r: 0.2647
10:32:12,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:32:51,138 root INFO 
id:en_zh cur r: 0.4000 best r: 0.4000
10:32:51,138 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:33:16,928 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:33:16,933 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:33:42,775 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6193
en_de Dev loss: 0.8856 r:0.1608
en_zh Dev loss: 0.7565 r:0.4134
Current avg r:0.2871 Best avg r: 0.2871
10:34:59,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:35:25,273 root INFO 
id:en_de cur r: 0.1398 best r: 0.1398
10:35:51,33 root INFO 
id:en_zh cur r: 0.4093 best r: 0.4093
10:35:51,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:36:16,827 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:36:16,834 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:36:42,652 root INFO Epoch 1 Global steps: 3200 Train loss: 0.7478
en_de Dev loss: 0.8619 r:0.1796
en_zh Dev loss: 0.7103 r:0.4263
Current avg r:0.3029 Best avg r: 0.3029
10:37:58,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:38:24,892 root INFO 
id:en_de cur r: 0.1400 best r: 0.1400
10:38:37,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:39:03,548 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:39:03,556 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:39:29,396 root INFO Epoch 1 Global steps: 3400 Train loss: 0.6460
en_de Dev loss: 0.8769 r:0.1935
en_zh Dev loss: 0.7406 r:0.4176
Current avg r:0.3056 Best avg r: 0.3056
10:40:45,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:41:24,375 root INFO 
id:en_zh cur r: 0.4132 best r: 0.4132
10:41:24,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:41:50,150 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:41:50,174 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:42:15,981 root INFO Epoch 1 Global steps: 3600 Train loss: 0.5423
en_de Dev loss: 0.9021 r:0.2051
en_zh Dev loss: 0.7224 r:0.4243
Current avg r:0.3147 Best avg r: 0.3147
10:43:32,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:43:58,145 root INFO 
id:en_de cur r: 0.1552 best r: 0.1552
10:44:11,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:44:36,784 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:44:36,791 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:45:02,583 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6170
en_de Dev loss: 0.8950 r:0.2126
en_zh Dev loss: 0.7362 r:0.4248
Current avg r:0.3187 Best avg r: 0.3187
10:46:18,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:46:44,759 root INFO 
id:en_de cur r: 0.1669 best r: 0.1669
10:47:10,535 root INFO 
id:en_zh cur r: 0.4172 best r: 0.4172
10:47:10,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:47:36,313 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:47:36,320 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:48:02,115 root INFO Epoch 1 Global steps: 4000 Train loss: 0.6958
en_de Dev loss: 0.8633 r:0.2190
en_zh Dev loss: 0.7165 r:0.4300
Current avg r:0.3245 Best avg r: 0.3245
10:49:18,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:49:44,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:50:10,197 root INFO Epoch 1 Global steps: 4200 Train loss: 0.6110
en_de Dev loss: 0.9140 r:0.2371
en_zh Dev loss: 0.8525 r:0.4064
Current avg r:0.3217 Best avg r: 0.3245
10:51:29,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:51:55,667 root INFO 
id:en_de cur r: 0.1890 best r: 0.1890
10:52:21,504 root INFO 
id:en_zh cur r: 0.4341 best r: 0.4341
10:52:21,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:52:47,338 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:52:47,359 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:53:13,175 root INFO Epoch 1 Global steps: 4400 Train loss: 0.7498
en_de Dev loss: 0.8546 r:0.2346
en_zh Dev loss: 0.6910 r:0.4468
Current avg r:0.3407 Best avg r: 0.3407
10:54:29,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:54:55,485 root INFO 
id:en_de cur r: 0.1983 best r: 0.1983
10:55:21,228 root INFO 
id:en_zh cur r: 0.4692 best r: 0.4692
10:55:21,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:55:46,993 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
10:55:47,23 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
10:56:12,856 root INFO Epoch 1 Global steps: 4600 Train loss: 0.6744
en_de Dev loss: 0.8503 r:0.2255
en_zh Dev loss: 0.6727 r:0.4701
Current avg r:0.3478 Best avg r: 0.3478
10:57:29,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:57:54,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:58:20,641 root INFO Epoch 1 Global steps: 4800 Train loss: 0.7126
en_de Dev loss: 0.8452 r:0.2170
en_zh Dev loss: 0.6733 r:0.4743
Current avg r:0.3456 Best avg r: 0.3478
10:59:36,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:00:02,846 root INFO 
id:en_de cur r: 0.2022 best r: 0.2022
11:00:28,617 root INFO 
id:en_zh cur r: 0.4743 best r: 0.4743
11:00:28,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:00:54,382 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
11:00:54,389 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
11:01:20,194 root INFO Epoch 1 Global steps: 5000 Train loss: 0.7080
en_de Dev loss: 0.8633 r:0.2212
en_zh Dev loss: 0.7095 r:0.4758
Current avg r:0.3485 Best avg r: 0.3485
11:02:36,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:03:02,393 root INFO 
id:en_de cur r: 0.2084 best r: 0.2084
11:03:28,146 root INFO 
id:en_zh cur r: 0.4892 best r: 0.4892
11:03:28,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:03:53,926 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
11:03:53,931 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
11:04:19,729 root INFO Epoch 1 Global steps: 5200 Train loss: 0.6205
en_de Dev loss: 0.8555 r:0.2241
en_zh Dev loss: 0.6722 r:0.4871
Current avg r:0.3556 Best avg r: 0.3556
11:05:36,36 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:06:01,970 root INFO 
id:en_de cur r: 0.2176 best r: 0.2176
11:06:14,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:06:40,588 root INFO Epoch 1 Global steps: 5400 Train loss: 0.5987
en_de Dev loss: 0.8652 r:0.2235
en_zh Dev loss: 0.6957 r:0.4805
Current avg r:0.3520 Best avg r: 0.3556
11:07:57,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:08:23,93 root INFO 
id:en_de cur r: 0.2258 best r: 0.2258
11:08:35,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:09:01,731 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
11:09:01,739 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
11:09:27,520 root INFO Epoch 1 Global steps: 5600 Train loss: 0.6965
en_de Dev loss: 0.8394 r:0.2369
en_zh Dev loss: 0.6414 r:0.4805
Current avg r:0.3587 Best avg r: 0.3587
11:10:43,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:11:22,486 root INFO 
id:en_zh cur r: 0.4929 best r: 0.4929
11:11:22,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:11:48,322 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
11:11:48,382 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
11:12:14,224 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6133
en_de Dev loss: 0.8403 r:0.2327
en_zh Dev loss: 0.6223 r:0.4905
Current avg r:0.3616 Best avg r: 0.3616
11:13:30,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:13:56,499 root INFO 
id:en_de cur r: 0.2405 best r: 0.2405
11:14:09,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:14:35,146 root INFO Epoch 1 Global steps: 6000 Train loss: 0.6390
en_de Dev loss: 0.8514 r:0.2389
en_zh Dev loss: 0.6667 r:0.4819
Current avg r:0.3604 Best avg r: 0.3616
11:15:54,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:16:20,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:16:46,143 root INFO Epoch 2 Global steps: 6200 Train loss: 0.6476
en_de Dev loss: 0.8967 r:0.2544
en_zh Dev loss: 0.8093 r:0.4599
Current avg r:0.3571 Best avg r: 0.3616
11:18:04,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:18:30,773 root INFO 
id:en_de cur r: 0.2448 best r: 0.2448
11:18:56,527 root INFO 
id:en_zh cur r: 0.4934 best r: 0.4934
11:18:56,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:19:22,309 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
11:19:22,316 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
11:19:48,91 root INFO Epoch 2 Global steps: 6400 Train loss: 0.5899
en_de Dev loss: 0.8353 r:0.2430
en_zh Dev loss: 0.6292 r:0.4883
Current avg r:0.3657 Best avg r: 0.3657
11:21:04,434 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:21:30,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:21:56,19 root INFO Epoch 2 Global steps: 6600 Train loss: 0.6386
en_de Dev loss: 0.8421 r:0.2446
en_zh Dev loss: 0.6665 r:0.4737
Current avg r:0.3592 Best avg r: 0.3657
11:23:15,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:23:41,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:24:07,332 root INFO Epoch 2 Global steps: 6800 Train loss: 0.5624
en_de Dev loss: 0.8461 r:0.2274
en_zh Dev loss: 0.6492 r:0.4821
Current avg r:0.3547 Best avg r: 0.3657
11:25:27,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:25:52,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:26:18,630 root INFO Epoch 2 Global steps: 7000 Train loss: 0.5987
en_de Dev loss: 0.8489 r:0.2382
en_zh Dev loss: 0.7069 r:0.4629
Current avg r:0.3505 Best avg r: 0.3657
11:27:35,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:28:01,80 root INFO 
id:en_de cur r: 0.2451 best r: 0.2451
11:28:13,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:28:39,730 root INFO Epoch 2 Global steps: 7200 Train loss: 0.5447
en_de Dev loss: 0.8468 r:0.2596
en_zh Dev loss: 0.7198 r:0.4570
Current avg r:0.3583 Best avg r: 0.3657
11:29:56,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:30:22,7 root INFO 
id:en_de cur r: 0.2469 best r: 0.2469
11:30:34,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:31:00,646 root INFO Epoch 2 Global steps: 7400 Train loss: 0.5537
en_de Dev loss: 0.8594 r:0.2611
en_zh Dev loss: 0.7423 r:0.4645
Current avg r:0.3628 Best avg r: 0.3657
11:32:16,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:32:42,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:33:08,487 root INFO Epoch 2 Global steps: 7600 Train loss: 0.5696
en_de Dev loss: 0.8455 r:0.2202
en_zh Dev loss: 0.6408 r:0.4890
Current avg r:0.3546 Best avg r: 0.3657
11:34:24,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:34:50,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:35:16,340 root INFO Epoch 2 Global steps: 7800 Train loss: 0.6502
en_de Dev loss: 0.8446 r:0.2227
en_zh Dev loss: 0.6623 r:0.4767
Current avg r:0.3497 Best avg r: 0.3657
11:36:32,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:36:58,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:37:24,275 root INFO Epoch 2 Global steps: 8000 Train loss: 0.5655
en_de Dev loss: 0.8439 r:0.2313
en_zh Dev loss: 0.6602 r:0.4782
Current avg r:0.3547 Best avg r: 0.3657
11:38:40,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:39:06,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:39:32,212 root INFO Epoch 2 Global steps: 8200 Train loss: 0.6017
en_de Dev loss: 0.8441 r:0.2324
en_zh Dev loss: 0.6898 r:0.4754
Current avg r:0.3539 Best avg r: 0.3657
11:40:48,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:41:14,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:41:40,150 root INFO Epoch 2 Global steps: 8400 Train loss: 0.5805
en_de Dev loss: 0.8472 r:0.2365
en_zh Dev loss: 0.7154 r:0.4735
Current avg r:0.3550 Best avg r: 0.3657
11:42:56,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:43:22,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:43:48,162 root INFO Epoch 2 Global steps: 8600 Train loss: 0.5336
en_de Dev loss: 0.8591 r:0.2463
en_zh Dev loss: 0.7169 r:0.4727
Current avg r:0.3595 Best avg r: 0.3657
11:45:07,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:45:33,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:45:59,480 root INFO Epoch 2 Global steps: 8800 Train loss: 0.6323
en_de Dev loss: 0.8524 r:0.2407
en_zh Dev loss: 0.7317 r:0.4624
Current avg r:0.3516 Best avg r: 0.3657
11:47:19,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:47:44,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:48:10,826 root INFO Epoch 2 Global steps: 9000 Train loss: 0.5936
en_de Dev loss: 0.8787 r:0.2212
en_zh Dev loss: 0.7234 r:0.4774
Current avg r:0.3493 Best avg r: 0.3657
11:49:27,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:49:53,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:50:19,212 root INFO Epoch 3 Global steps: 9200 Train loss: 0.5406
en_de Dev loss: 0.8568 r:0.2311
en_zh Dev loss: 0.6849 r:0.4872
Current avg r:0.3592 Best avg r: 0.3657
11:51:35,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:52:01,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:52:27,52 root INFO Epoch 3 Global steps: 9400 Train loss: 0.5650
en_de Dev loss: 0.8534 r:0.2445
en_zh Dev loss: 0.7789 r:0.4590
Current avg r:0.3518 Best avg r: 0.3657
11:53:43,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:54:09,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:54:34,902 root INFO Epoch 3 Global steps: 9600 Train loss: 0.5657
en_de Dev loss: 0.8482 r:0.2483
en_zh Dev loss: 0.7044 r:0.4639
Current avg r:0.3561 Best avg r: 0.3657
11:55:51,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:56:17,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:56:42,778 root INFO Epoch 3 Global steps: 9800 Train loss: 0.4894
en_de Dev loss: 0.8474 r:0.2436
en_zh Dev loss: 0.7187 r:0.4640
Current avg r:0.3538 Best avg r: 0.3657
11:57:59,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:58:24,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:58:50,625 root INFO Epoch 3 Global steps: 10000 Train loss: 0.6796
en_de Dev loss: 0.8840 r:0.2263
en_zh Dev loss: 0.8028 r:0.4671
Current avg r:0.3467 Best avg r: 0.3657
12:00:06,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:00:32,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:00:58,490 root INFO Epoch 3 Global steps: 10200 Train loss: 0.5335
en_de Dev loss: 0.8549 r:0.2301
en_zh Dev loss: 0.7257 r:0.4784
Current avg r:0.3543 Best avg r: 0.3657
12:02:15,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:02:41,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:03:07,151 root INFO Epoch 3 Global steps: 10400 Train loss: 0.5116
en_de Dev loss: 0.8447 r:0.2482
en_zh Dev loss: 0.6971 r:0.4772
Current avg r:0.3627 Best avg r: 0.3657
12:04:26,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:04:52,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:05:17,880 root INFO Epoch 3 Global steps: 10600 Train loss: 0.4788
en_de Dev loss: 0.8715 r:0.2452
en_zh Dev loss: 0.7857 r:0.4694
Current avg r:0.3573 Best avg r: 0.3657
12:06:34,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:07:00,0 root INFO 
id:en_de cur r: 0.2484 best r: 0.2484
12:07:12,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:07:38,596 root INFO Epoch 3 Global steps: 10800 Train loss: 0.4831
en_de Dev loss: 0.8461 r:0.2525
en_zh Dev loss: 0.7179 r:0.4729
Current avg r:0.3627 Best avg r: 0.3657
12:08:54,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:09:20,675 root INFO 
id:en_de cur r: 0.2603 best r: 0.2603
12:09:33,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:09:59,321 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_de.lang_agnost_mlp.dev.best.scores
12:09:59,327 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run3/en_zh.lang_agnost_mlp.dev.best.scores
12:10:25,114 root INFO Epoch 3 Global steps: 11000 Train loss: 0.5191
en_de Dev loss: 0.8360 r:0.2592
en_zh Dev loss: 0.6851 r:0.4803
Current avg r:0.3698 Best avg r: 0.3698
12:11:41,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:12:07,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:12:32,833 root INFO Epoch 3 Global steps: 11200 Train loss: 0.4695
en_de Dev loss: 0.8631 r:0.2454
en_zh Dev loss: 0.7106 r:0.4718
Current avg r:0.3586 Best avg r: 0.3698
12:13:49,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:14:14,727 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:14:40,453 root INFO Epoch 3 Global steps: 11400 Train loss: 0.6193
en_de Dev loss: 0.8411 r:0.2414
en_zh Dev loss: 0.6711 r:0.4855
Current avg r:0.3635 Best avg r: 0.3698
12:15:56,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:16:22,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:16:48,90 root INFO Epoch 3 Global steps: 11600 Train loss: 0.5883
en_de Dev loss: 0.8433 r:0.2241
en_zh Dev loss: 0.7044 r:0.4793
Current avg r:0.3517 Best avg r: 0.3698
12:18:04,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:18:30,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:18:55,746 root INFO Epoch 3 Global steps: 11800 Train loss: 0.5297
en_de Dev loss: 0.8499 r:0.2502
en_zh Dev loss: 0.7416 r:0.4712
Current avg r:0.3607 Best avg r: 0.3698
12:20:11,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:20:37,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:21:03,374 root INFO Epoch 3 Global steps: 12000 Train loss: 0.4447
en_de Dev loss: 0.8374 r:0.2472
en_zh Dev loss: 0.6899 r:0.4801
Current avg r:0.3637 Best avg r: 0.3698
12:22:20,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:22:45,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:23:11,570 root INFO Epoch 4 Global steps: 12200 Train loss: 0.4969
en_de Dev loss: 0.8557 r:0.2516
en_zh Dev loss: 0.7843 r:0.4611
Current avg r:0.3564 Best avg r: 0.3698
12:24:27,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:24:53,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:25:19,375 root INFO Epoch 4 Global steps: 12400 Train loss: 0.5481
en_de Dev loss: 0.8459 r:0.2537
en_zh Dev loss: 0.7308 r:0.4696
Current avg r:0.3617 Best avg r: 0.3698
12:26:35,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:27:01,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:27:27,152 root INFO Epoch 4 Global steps: 12600 Train loss: 0.4904
en_de Dev loss: 0.8413 r:0.2541
en_zh Dev loss: 0.7176 r:0.4735
Current avg r:0.3638 Best avg r: 0.3698
12:28:43,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:29:09,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:29:34,900 root INFO Epoch 4 Global steps: 12800 Train loss: 0.5309
en_de Dev loss: 0.8427 r:0.2524
en_zh Dev loss: 0.7113 r:0.4625
Current avg r:0.3575 Best avg r: 0.3698
12:30:51,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:31:16,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:31:42,699 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4729
en_de Dev loss: 0.8610 r:0.2361
en_zh Dev loss: 0.7466 r:0.4624
Current avg r:0.3492 Best avg r: 0.3698
12:32:58,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:33:24,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:33:50,395 root INFO Epoch 4 Global steps: 13200 Train loss: 0.5321
en_de Dev loss: 0.8474 r:0.2403
en_zh Dev loss: 0.7099 r:0.4679
Current avg r:0.3541 Best avg r: 0.3698
12:35:06,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:35:32,250 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:35:57,974 root INFO Epoch 4 Global steps: 13400 Train loss: 0.4683
en_de Dev loss: 0.8508 r:0.2421
en_zh Dev loss: 0.7272 r:0.4548
Current avg r:0.3484 Best avg r: 0.3698
12:37:14,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:37:39,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:38:05,635 root INFO Epoch 4 Global steps: 13600 Train loss: 0.4414
en_de Dev loss: 0.8502 r:0.2340
en_zh Dev loss: 0.7601 r:0.4566
Current avg r:0.3453 Best avg r: 0.3698
12:39:24,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:39:50,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:40:16,517 root INFO Epoch 4 Global steps: 13800 Train loss: 0.4566
en_de Dev loss: 0.8577 r:0.2338
en_zh Dev loss: 0.7474 r:0.4596
Current avg r:0.3467 Best avg r: 0.3698
12:41:35,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:42:01,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:42:27,394 root INFO Epoch 4 Global steps: 14000 Train loss: 0.4021
en_de Dev loss: 0.8579 r:0.2284
en_zh Dev loss: 0.7680 r:0.4621
Current avg r:0.3453 Best avg r: 0.3698
12:43:46,655 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:44:12,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:44:38,217 root INFO Epoch 4 Global steps: 14200 Train loss: 0.5046
en_de Dev loss: 0.8529 r:0.2383
en_zh Dev loss: 0.7466 r:0.4619
Current avg r:0.3501 Best avg r: 0.3698
12:45:57,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:46:23,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:46:49,125 root INFO Epoch 4 Global steps: 14400 Train loss: 0.4364
en_de Dev loss: 0.8361 r:0.2500
en_zh Dev loss: 0.7199 r:0.4650
Current avg r:0.3575 Best avg r: 0.3698
12:48:08,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:48:34,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:48:59,990 root INFO Epoch 4 Global steps: 14600 Train loss: 0.4873
en_de Dev loss: 0.8333 r:0.2529
en_zh Dev loss: 0.7138 r:0.4578
Current avg r:0.3554 Best avg r: 0.3698
12:50:16,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:50:42,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:51:07,822 root INFO Epoch 4 Global steps: 14800 Train loss: 0.4198
en_de Dev loss: 0.8386 r:0.2368
en_zh Dev loss: 0.6946 r:0.4705
Current avg r:0.3537 Best avg r: 0.3698
12:52:24,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:52:49,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:53:15,615 root INFO Epoch 4 Global steps: 15000 Train loss: 0.4616
en_de Dev loss: 0.8508 r:0.2404
en_zh Dev loss: 0.7246 r:0.4721
Current avg r:0.3563 Best avg r: 0.3698
12:54:32,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:54:57,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:55:23,652 root INFO Epoch 5 Global steps: 15200 Train loss: 0.4076
en_de Dev loss: 0.8347 r:0.2475
en_zh Dev loss: 0.6975 r:0.4694
Current avg r:0.3584 Best avg r: 0.3698
12:56:39,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:57:05,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:57:31,295 root INFO Epoch 5 Global steps: 15400 Train loss: 0.4324
en_de Dev loss: 0.8525 r:0.2458
en_zh Dev loss: 0.7667 r:0.4543
Current avg r:0.3500 Best avg r: 0.3698
12:58:47,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:59:13,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:59:38,915 root INFO Epoch 5 Global steps: 15600 Train loss: 0.3999
en_de Dev loss: 0.8431 r:0.2466
en_zh Dev loss: 0.7281 r:0.4558
Current avg r:0.3512 Best avg r: 0.3698
13:00:55,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:01:20,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:01:46,537 root INFO Epoch 5 Global steps: 15800 Train loss: 0.3624
en_de Dev loss: 0.8728 r:0.2409
en_zh Dev loss: 0.7434 r:0.4532
Current avg r:0.3471 Best avg r: 0.3698
13:03:05,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:03:31,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:03:57,422 root INFO Epoch 5 Global steps: 16000 Train loss: 0.4497
en_de Dev loss: 0.8392 r:0.2432
en_zh Dev loss: 0.7118 r:0.4688
Current avg r:0.3560 Best avg r: 0.3698
13:05:16,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:05:42,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:06:08,273 root INFO Epoch 5 Global steps: 16200 Train loss: 0.3979
en_de Dev loss: 0.8583 r:0.2336
en_zh Dev loss: 0.7456 r:0.4667
Current avg r:0.3502 Best avg r: 0.3698
13:07:27,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:07:53,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:08:19,165 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3986
en_de Dev loss: 0.8637 r:0.2451
en_zh Dev loss: 0.8016 r:0.4647
Current avg r:0.3549 Best avg r: 0.3698
13:09:35,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:10:01,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:10:26,946 root INFO Epoch 5 Global steps: 16600 Train loss: 0.4000
en_de Dev loss: 0.8737 r:0.2328
en_zh Dev loss: 0.8081 r:0.4647
Current avg r:0.3488 Best avg r: 0.3698
13:11:43,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:12:08,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:12:34,745 root INFO Epoch 5 Global steps: 16800 Train loss: 0.4603
en_de Dev loss: 0.8417 r:0.2306
en_zh Dev loss: 0.6815 r:0.4810
Current avg r:0.3558 Best avg r: 0.3698
13:13:50,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:14:16,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:14:42,463 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3994
en_de Dev loss: 0.8458 r:0.2383
en_zh Dev loss: 0.7488 r:0.4647
Current avg r:0.3515 Best avg r: 0.3698
13:15:58,707 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:16:24,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:16:50,168 root INFO Epoch 5 Global steps: 17200 Train loss: 0.4598
en_de Dev loss: 0.8513 r:0.2305
en_zh Dev loss: 0.7264 r:0.4684
Current avg r:0.3494 Best avg r: 0.3698
13:18:06,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:18:32,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:18:57,814 root INFO Epoch 5 Global steps: 17400 Train loss: 0.4066
en_de Dev loss: 0.8574 r:0.2307
en_zh Dev loss: 0.8117 r:0.4486
Current avg r:0.3397 Best avg r: 0.3698
13:20:17,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:20:42,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:21:08,648 root INFO Epoch 5 Global steps: 17600 Train loss: 0.4109
en_de Dev loss: 0.8482 r:0.2457
en_zh Dev loss: 0.7777 r:0.4504
Current avg r:0.3480 Best avg r: 0.3698
13:22:26,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:22:52,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:23:18,33 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3561
en_de Dev loss: 0.8596 r:0.2453
en_zh Dev loss: 0.8066 r:0.4545
Current avg r:0.3499 Best avg r: 0.3698
13:24:34,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:25:00,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:25:25,770 root INFO Epoch 5 Global steps: 18000 Train loss: 0.4160
en_de Dev loss: 0.8501 r:0.2506
en_zh Dev loss: 0.7705 r:0.4580
Current avg r:0.3543 Best avg r: 0.3698
13:26:42,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:27:08,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:27:33,769 root INFO Epoch 6 Global steps: 18200 Train loss: 0.3796
en_de Dev loss: 0.8642 r:0.2253
en_zh Dev loss: 0.7570 r:0.4719
Current avg r:0.3486 Best avg r: 0.3698
13:28:49,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:29:15,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:29:41,360 root INFO Epoch 6 Global steps: 18400 Train loss: 0.4049
en_de Dev loss: 0.8668 r:0.2208
en_zh Dev loss: 0.7329 r:0.4781
Current avg r:0.3494 Best avg r: 0.3698
13:30:57,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:31:23,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:31:48,931 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3309
en_de Dev loss: 0.8628 r:0.2075
en_zh Dev loss: 0.7149 r:0.4823
Current avg r:0.3449 Best avg r: 0.3698
13:33:05,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:33:30,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:33:56,620 root INFO Epoch 6 Global steps: 18800 Train loss: 0.3639
en_de Dev loss: 0.8698 r:0.2011
en_zh Dev loss: 0.7569 r:0.4708
Current avg r:0.3359 Best avg r: 0.3698
13:35:15,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:35:41,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:36:07,467 root INFO Epoch 6 Global steps: 19000 Train loss: 0.3717
en_de Dev loss: 0.8660 r:0.2080
en_zh Dev loss: 0.7598 r:0.4818
Current avg r:0.3449 Best avg r: 0.3698
13:37:26,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:37:52,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:38:18,431 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3344
en_de Dev loss: 0.8491 r:0.2294
en_zh Dev loss: 0.7547 r:0.4716
Current avg r:0.3505 Best avg r: 0.3698
13:39:37,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:40:03,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:40:29,289 root INFO Epoch 6 Global steps: 19400 Train loss: 0.3571
en_de Dev loss: 0.8917 r:0.1763
en_zh Dev loss: 0.7091 r:0.4859
Current avg r:0.3311 Best avg r: 0.3698
13:41:45,613 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:42:11,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:42:37,126 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3696
en_de Dev loss: 0.8867 r:0.1881
en_zh Dev loss: 0.7493 r:0.4647
Current avg r:0.3264 Best avg r: 0.3698
13:43:53,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:44:19,236 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:44:44,993 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3901
en_de Dev loss: 0.8529 r:0.2128
en_zh Dev loss: 0.7203 r:0.4691
Current avg r:0.3410 Best avg r: 0.3698
13:46:01,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:46:27,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:46:52,851 root INFO Epoch 6 Global steps: 20000 Train loss: 0.2910
en_de Dev loss: 0.8740 r:0.2178
en_zh Dev loss: 0.7495 r:0.4751
Current avg r:0.3464 Best avg r: 0.3698
13:48:09,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:48:34,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:49:00,719 root INFO Epoch 6 Global steps: 20200 Train loss: 0.3810
en_de Dev loss: 0.8721 r:0.2221
en_zh Dev loss: 0.8028 r:0.4632
Current avg r:0.3426 Best avg r: 0.3698
13:50:17,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:50:42,812 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:51:08,591 root INFO Epoch 6 Global steps: 20400 Train loss: 0.3271
en_de Dev loss: 0.8600 r:0.2276
en_zh Dev loss: 0.7888 r:0.4653
Current avg r:0.3465 Best avg r: 0.3698
13:52:24,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:52:50,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:53:16,419 root INFO Epoch 6 Global steps: 20600 Train loss: 0.3279
en_de Dev loss: 0.8859 r:0.2218
en_zh Dev loss: 0.7939 r:0.4602
Current avg r:0.3410 Best avg r: 0.3698
13:54:32,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:54:58,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:55:24,147 root INFO Epoch 6 Global steps: 20800 Train loss: 0.3515
en_de Dev loss: 0.8608 r:0.2371
en_zh Dev loss: 0.8596 r:0.4507
Current avg r:0.3439 Best avg r: 0.3698
13:56:40,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:57:06,188 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:57:32,22 root INFO Epoch 6 Global steps: 21000 Train loss: 0.3319
en_de Dev loss: 0.8703 r:0.2226
en_zh Dev loss: 0.7782 r:0.4662
Current avg r:0.3444 Best avg r: 0.3698
13:58:48,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:59:14,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:59:40,275 root INFO Epoch 7 Global steps: 21200 Train loss: 0.3269
en_de Dev loss: 0.8579 r:0.2303
en_zh Dev loss: 0.7747 r:0.4666
Current avg r:0.3485 Best avg r: 0.3698
14:00:56,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:01:22,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:01:48,94 root INFO Epoch 7 Global steps: 21400 Train loss: 0.2987
en_de Dev loss: 0.8661 r:0.2245
en_zh Dev loss: 0.7755 r:0.4673
Current avg r:0.3459 Best avg r: 0.3698
14:03:04,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:03:30,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:03:55,951 root INFO Epoch 7 Global steps: 21600 Train loss: 0.3201
en_de Dev loss: 0.8658 r:0.2038
en_zh Dev loss: 0.7879 r:0.4663
Current avg r:0.3351 Best avg r: 0.3698
14:05:12,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:05:38,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:06:03,785 root INFO Epoch 7 Global steps: 21800 Train loss: 0.3031
en_de Dev loss: 0.8644 r:0.2006
en_zh Dev loss: 0.7225 r:0.4817
Current avg r:0.3411 Best avg r: 0.3698
14:07:20,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:07:45,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:08:11,597 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2947
en_de Dev loss: 0.9239 r:0.1666
en_zh Dev loss: 0.8105 r:0.4730
Current avg r:0.3198 Best avg r: 0.3698
14:09:27,810 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:09:53,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:10:19,340 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2894
en_de Dev loss: 0.8989 r:0.1806
en_zh Dev loss: 0.7715 r:0.4835
Current avg r:0.3320 Best avg r: 0.3698
14:11:35,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:12:01,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:12:27,111 root INFO Epoch 7 Global steps: 22400 Train loss: 0.2986
en_de Dev loss: 0.8846 r:0.1905
en_zh Dev loss: 0.7423 r:0.4790
Current avg r:0.3347 Best avg r: 0.3698
14:13:43,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:14:09,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:14:35,61 root INFO Epoch 7 Global steps: 22600 Train loss: 0.3136
en_de Dev loss: 0.9101 r:0.1579
en_zh Dev loss: 0.7658 r:0.4759
Current avg r:0.3169 Best avg r: 0.3698
14:15:51,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:16:17,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:16:42,944 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2918
en_de Dev loss: 0.8868 r:0.1981
en_zh Dev loss: 0.7309 r:0.4829
Current avg r:0.3405 Best avg r: 0.3698
14:17:59,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:18:25,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:18:50,839 root INFO Epoch 7 Global steps: 23000 Train loss: 0.3105
en_de Dev loss: 0.8763 r:0.2074
en_zh Dev loss: 0.7614 r:0.4838
Current avg r:0.3456 Best avg r: 0.3698
14:20:07,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:20:32,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:20:58,740 root INFO Epoch 7 Global steps: 23200 Train loss: 0.2595
en_de Dev loss: 0.8756 r:0.2097
en_zh Dev loss: 0.7818 r:0.4771
Current avg r:0.3434 Best avg r: 0.3698
14:22:14,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:22:40,800 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:23:06,663 root INFO Epoch 7 Global steps: 23400 Train loss: 0.2986
en_de Dev loss: 0.8839 r:0.2239
en_zh Dev loss: 0.8141 r:0.4730
Current avg r:0.3485 Best avg r: 0.3698
14:24:26,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:24:51,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:25:17,618 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2911
en_de Dev loss: 0.8744 r:0.2066
en_zh Dev loss: 0.7292 r:0.4846
Current avg r:0.3456 Best avg r: 0.3698
14:26:33,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:26:59,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:27:25,372 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2764
en_de Dev loss: 0.8748 r:0.2139
en_zh Dev loss: 0.8089 r:0.4658
Current avg r:0.3398 Best avg r: 0.3698
14:28:44,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:29:10,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:29:36,38 root INFO Epoch 7 Global steps: 24000 Train loss: 0.2973
en_de Dev loss: 0.8684 r:0.2250
en_zh Dev loss: 0.8176 r:0.4643
Current avg r:0.3447 Best avg r: 0.3698
14:30:52,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:31:18,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:31:44,298 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2949
en_de Dev loss: 0.8836 r:0.1777
en_zh Dev loss: 0.8132 r:0.4686
Current avg r:0.3232 Best avg r: 0.3698
14:33:00,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:33:26,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:33:52,135 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2628
en_de Dev loss: 0.8898 r:0.2035
en_zh Dev loss: 0.8393 r:0.4727
Current avg r:0.3381 Best avg r: 0.3698
14:35:09,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:35:35,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:36:01,570 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2506
en_de Dev loss: 0.8917 r:0.1846
en_zh Dev loss: 0.7688 r:0.4819
Current avg r:0.3333 Best avg r: 0.3698
14:37:20,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:46,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:38:12,533 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2717
en_de Dev loss: 0.8813 r:0.1906
en_zh Dev loss: 0.7998 r:0.4683
Current avg r:0.3295 Best avg r: 0.3698
14:39:31,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:39:57,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:23,522 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2515
en_de Dev loss: 0.9113 r:0.1804
en_zh Dev loss: 0.8572 r:0.4693
Current avg r:0.3248 Best avg r: 0.3698
14:41:42,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:08,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:42:34,362 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2585
en_de Dev loss: 0.8799 r:0.1964
en_zh Dev loss: 0.7983 r:0.4675
Current avg r:0.3319 Best avg r: 0.3698
14:43:53,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:19,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:44:45,284 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2791
en_de Dev loss: 0.8878 r:0.2129
en_zh Dev loss: 0.7620 r:0.4789
Current avg r:0.3459 Best avg r: 0.3698
14:46:01,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:46:27,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:53,175 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2553
en_de Dev loss: 0.8807 r:0.1936
en_zh Dev loss: 0.6933 r:0.4860
Current avg r:0.3398 Best avg r: 0.3698
14:48:09,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:35,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:01,29 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2532
en_de Dev loss: 0.9111 r:0.1661
en_zh Dev loss: 0.7770 r:0.4728
Current avg r:0.3194 Best avg r: 0.3698
14:50:17,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:50:43,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:08,938 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2597
en_de Dev loss: 0.9060 r:0.1754
en_zh Dev loss: 0.7942 r:0.4681
Current avg r:0.3217 Best avg r: 0.3698
14:52:25,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:51,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:16,781 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2699
en_de Dev loss: 0.8981 r:0.1738
en_zh Dev loss: 0.7527 r:0.4660
Current avg r:0.3199 Best avg r: 0.3698
14:54:32,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:58,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:24,475 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2471
en_de Dev loss: 0.8944 r:0.1839
en_zh Dev loss: 0.8082 r:0.4589
Current avg r:0.3214 Best avg r: 0.3698
14:56:40,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:06,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:32,299 root INFO Epoch 8 Global steps: 26600 Train loss: 0.3099
en_de Dev loss: 0.8885 r:0.1892
en_zh Dev loss: 0.7861 r:0.4648
Current avg r:0.3270 Best avg r: 0.3698
14:58:51,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:17,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:43,275 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2646
en_de Dev loss: 0.8688 r:0.2046
en_zh Dev loss: 0.7882 r:0.4636
Current avg r:0.3341 Best avg r: 0.3698
15:01:02,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:28,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:01:54,296 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2638
en_de Dev loss: 0.8898 r:0.1877
en_zh Dev loss: 0.8094 r:0.4520
Current avg r:0.3198 Best avg r: 0.3698
15:03:10,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:36,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:02,364 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2082
en_de Dev loss: 0.9083 r:0.1879
en_zh Dev loss: 0.8235 r:0.4597
Current avg r:0.3238 Best avg r: 0.3698
15:05:18,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:44,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:10,16 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2454
en_de Dev loss: 0.8988 r:0.1792
en_zh Dev loss: 0.7763 r:0.4737
Current avg r:0.3265 Best avg r: 0.3698
15:07:26,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:51,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:17,689 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2334
en_de Dev loss: 0.8925 r:0.1954
en_zh Dev loss: 0.7916 r:0.4755
Current avg r:0.3354 Best avg r: 0.3698
15:09:34,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:59,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:25,640 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2485
en_de Dev loss: 0.9568 r:0.1734
en_zh Dev loss: 0.8676 r:0.4610
Current avg r:0.3172 Best avg r: 0.3698
15:11:41,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:07,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:33,489 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2324
en_de Dev loss: 0.9155 r:0.1742
en_zh Dev loss: 0.8001 r:0.4665
Current avg r:0.3203 Best avg r: 0.3698
15:13:49,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:15,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:41,348 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2472
en_de Dev loss: 0.9164 r:0.1554
en_zh Dev loss: 0.8895 r:0.4587
Current avg r:0.3070 Best avg r: 0.3698
15:15:57,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:23,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:49,170 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2189
en_de Dev loss: 0.8867 r:0.1739
en_zh Dev loss: 0.7539 r:0.4718
Current avg r:0.3228 Best avg r: 0.3698
15:18:08,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:34,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:00,202 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2196
en_de Dev loss: 0.9056 r:0.1816
en_zh Dev loss: 0.8478 r:0.4654
Current avg r:0.3235 Best avg r: 0.3698
15:20:19,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:45,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:11,185 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2286
en_de Dev loss: 0.9008 r:0.1768
en_zh Dev loss: 0.7842 r:0.4615
Current avg r:0.3191 Best avg r: 0.3698
15:22:27,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:53,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:19,111 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2082
en_de Dev loss: 0.8986 r:0.1792
en_zh Dev loss: 0.7856 r:0.4683
Current avg r:0.3237 Best avg r: 0.3698
15:24:35,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:01,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:26,939 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2325
en_de Dev loss: 0.8992 r:0.1752
en_zh Dev loss: 0.7934 r:0.4694
Current avg r:0.3223 Best avg r: 0.3698
15:26:43,183 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:08,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:34,678 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2558
en_de Dev loss: 0.9019 r:0.1653
en_zh Dev loss: 0.7488 r:0.4715
Current avg r:0.3184 Best avg r: 0.3698
15:28:50,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:16,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:42,459 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2312
en_de Dev loss: 0.9103 r:0.1529
en_zh Dev loss: 0.7809 r:0.4724
Current avg r:0.3126 Best avg r: 0.3698
15:30:58,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:24,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:50,198 root INFO Epoch 9 Global steps: 29800 Train loss: 0.2435
en_de Dev loss: 0.9184 r:0.1742
en_zh Dev loss: 0.8094 r:0.4707
Current avg r:0.3224 Best avg r: 0.3698
15:33:06,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:32,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:58,95 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2169
en_de Dev loss: 0.9280 r:0.1685
en_zh Dev loss: 0.7857 r:0.4702
Current avg r:0.3193 Best avg r: 0.3698
15:35:14,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:40,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:06,415 root INFO Epoch 10 Global steps: 30200 Train loss: 0.1860
en_de Dev loss: 0.9076 r:0.1734
en_zh Dev loss: 0.7651 r:0.4687
Current avg r:0.3211 Best avg r: 0.3698
15:37:22,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:48,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:14,342 root INFO Epoch 10 Global steps: 30400 Train loss: 0.2145
en_de Dev loss: 0.9250 r:0.1650
en_zh Dev loss: 0.8082 r:0.4641
Current avg r:0.3145 Best avg r: 0.3698
15:39:30,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:56,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:22,178 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2145
en_de Dev loss: 0.9063 r:0.1700
en_zh Dev loss: 0.7900 r:0.4640
Current avg r:0.3170 Best avg r: 0.3698
15:41:38,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:04,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:29,994 root INFO Epoch 10 Global steps: 30800 Train loss: 0.2263
en_de Dev loss: 0.9143 r:0.1804
en_zh Dev loss: 0.7728 r:0.4686
Current avg r:0.3245 Best avg r: 0.3698
15:43:46,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:12,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:37,774 root INFO Epoch 10 Global steps: 31000 Train loss: 0.2052
en_de Dev loss: 0.9151 r:0.1755
en_zh Dev loss: 0.7660 r:0.4709
Current avg r:0.3232 Best avg r: 0.3698
15:45:54,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:20,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:46,101 root INFO Epoch 10 Global steps: 31200 Train loss: 0.2065
en_de Dev loss: 0.9216 r:0.1720
en_zh Dev loss: 0.7995 r:0.4661
Current avg r:0.3191 Best avg r: 0.3698
15:48:05,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:31,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:57,12 root INFO Epoch 10 Global steps: 31400 Train loss: 0.2262
en_de Dev loss: 0.9220 r:0.1550
en_zh Dev loss: 0.8276 r:0.4609
Current avg r:0.3080 Best avg r: 0.3698
15:50:16,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:42,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:07,855 root INFO Epoch 10 Global steps: 31600 Train loss: 0.2081
en_de Dev loss: 0.8926 r:0.1901
en_zh Dev loss: 0.7987 r:0.4651
Current avg r:0.3276 Best avg r: 0.3698
15:52:24,219 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:49,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:15,719 root INFO Epoch 10 Global steps: 31800 Train loss: 0.2246
en_de Dev loss: 0.8998 r:0.1738
en_zh Dev loss: 0.8002 r:0.4585
Current avg r:0.3162 Best avg r: 0.3698
15:54:32,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:57,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:23,545 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1890
en_de Dev loss: 0.9128 r:0.1682
en_zh Dev loss: 0.7681 r:0.4635
Current avg r:0.3159 Best avg r: 0.3698
15:56:39,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:05,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:31,386 root INFO Epoch 10 Global steps: 32200 Train loss: 0.2178
en_de Dev loss: 0.9243 r:0.1888
en_zh Dev loss: 0.7740 r:0.4722
Current avg r:0.3305 Best avg r: 0.3698
15:58:47,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:13,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:39,242 root INFO Epoch 10 Global steps: 32400 Train loss: 0.2043
en_de Dev loss: 0.9038 r:0.1827
en_zh Dev loss: 0.7507 r:0.4707
Current avg r:0.3267 Best avg r: 0.3698
16:00:55,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:21,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:47,130 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1893
en_de Dev loss: 0.9244 r:0.1830
en_zh Dev loss: 0.8403 r:0.4578
Current avg r:0.3204 Best avg r: 0.3698
16:03:03,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:29,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:54,948 root INFO Epoch 10 Global steps: 32800 Train loss: 0.2303
en_de Dev loss: 0.9095 r:0.1804
en_zh Dev loss: 0.7812 r:0.4596
Current avg r:0.3200 Best avg r: 0.3698
16:05:11,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:37,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:02,820 root INFO Epoch 10 Global steps: 33000 Train loss: 0.2086
en_de Dev loss: 0.8742 r:0.1913
en_zh Dev loss: 0.7605 r:0.4592
Current avg r:0.3253 Best avg r: 0.3698
16:07:19,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:45,270 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:11,18 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1760
en_de Dev loss: 0.9287 r:0.1811
en_zh Dev loss: 0.8566 r:0.4521
Current avg r:0.3166 Best avg r: 0.3698
16:09:27,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:52,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:18,674 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1800
en_de Dev loss: 0.9012 r:0.1712
en_zh Dev loss: 0.8074 r:0.4535
Current avg r:0.3123 Best avg r: 0.3698
16:11:36,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:01,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:27,691 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1876
en_de Dev loss: 0.9107 r:0.1738
en_zh Dev loss: 0.8104 r:0.4569
Current avg r:0.3154 Best avg r: 0.3698
16:13:46,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:12,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:38,326 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1950
en_de Dev loss: 0.9382 r:0.1751
en_zh Dev loss: 0.8306 r:0.4614
Current avg r:0.3182 Best avg r: 0.3698
16:15:56,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:22,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:48,454 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1914
en_de Dev loss: 0.9180 r:0.1745
en_zh Dev loss: 0.8433 r:0.4611
Current avg r:0.3178 Best avg r: 0.3698
16:18:06,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:32,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:58,146 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1957
en_de Dev loss: 0.9342 r:0.1465
en_zh Dev loss: 0.8787 r:0.4502
Current avg r:0.2983 Best avg r: 0.3698
16:20:17,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:43,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:09,193 root INFO Epoch 11 Global steps: 34400 Train loss: 0.2005
en_de Dev loss: 0.9029 r:0.1758
en_zh Dev loss: 0.7804 r:0.4551
Current avg r:0.3155 Best avg r: 0.3698
16:22:28,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:54,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:20,266 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1767
en_de Dev loss: 0.9031 r:0.1802
en_zh Dev loss: 0.8155 r:0.4591
Current avg r:0.3197 Best avg r: 0.3698
16:24:39,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:05,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:31,212 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1894
en_de Dev loss: 0.9033 r:0.1772
en_zh Dev loss: 0.7294 r:0.4753
Current avg r:0.3262 Best avg r: 0.3698
16:26:47,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:13,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:39,24 root INFO Epoch 11 Global steps: 35000 Train loss: 0.2013
en_de Dev loss: 0.9239 r:0.1700
en_zh Dev loss: 0.7862 r:0.4635
Current avg r:0.3167 Best avg r: 0.3698
16:28:55,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:21,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:46,892 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1825
en_de Dev loss: 0.9113 r:0.1808
en_zh Dev loss: 0.7960 r:0.4649
Current avg r:0.3228 Best avg r: 0.3698
16:31:03,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:29,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:54,771 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1866
en_de Dev loss: 0.9082 r:0.2057
en_zh Dev loss: 0.7769 r:0.4662
Current avg r:0.3359 Best avg r: 0.3698
16:33:11,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:36,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:02,686 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1722
en_de Dev loss: 0.9501 r:0.1563
en_zh Dev loss: 0.8207 r:0.4640
Current avg r:0.3102 Best avg r: 0.3698
16:35:19,105 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:44,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:10,669 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1872
en_de Dev loss: 0.8952 r:0.1651
en_zh Dev loss: 0.7677 r:0.4552
Current avg r:0.3101 Best avg r: 0.3698
16:37:27,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:52,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:18,543 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1920
en_de Dev loss: 0.9425 r:0.1556
en_zh Dev loss: 0.8503 r:0.4502
Current avg r:0.3029 Best avg r: 0.3698
16:39:35,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:01,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:26,814 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1900
en_de Dev loss: 0.9223 r:0.1571
en_zh Dev loss: 0.7898 r:0.4672
Current avg r:0.3121 Best avg r: 0.3698
16:41:43,6 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:08,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:34,499 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1627
en_de Dev loss: 0.9169 r:0.1679
en_zh Dev loss: 0.7719 r:0.4672
Current avg r:0.3175 Best avg r: 0.3698
16:43:50,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:16,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:42,233 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1515
en_de Dev loss: 0.8945 r:0.1779
en_zh Dev loss: 0.7475 r:0.4685
Current avg r:0.3232 Best avg r: 0.3698
16:45:58,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:24,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:49,942 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1613
en_de Dev loss: 0.9255 r:0.1854
en_zh Dev loss: 0.8354 r:0.4599
Current avg r:0.3226 Best avg r: 0.3698
16:48:06,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:31,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:57,606 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1771
en_de Dev loss: 0.8919 r:0.1883
en_zh Dev loss: 0.7445 r:0.4713
Current avg r:0.3298 Best avg r: 0.3698
16:50:13,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:39,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:05,205 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1656
en_de Dev loss: 0.9000 r:0.1823
en_zh Dev loss: 0.8154 r:0.4612
Current avg r:0.3217 Best avg r: 0.3698
16:52:21,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:47,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:12,875 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1674
en_de Dev loss: 0.9162 r:0.1832
en_zh Dev loss: 0.8221 r:0.4679
Current avg r:0.3255 Best avg r: 0.3698
16:54:29,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:54,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:20,589 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1679
en_de Dev loss: 0.9266 r:0.1815
en_zh Dev loss: 0.8688 r:0.4557
Current avg r:0.3186 Best avg r: 0.3698
16:56:36,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:02,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:28,310 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1682
en_de Dev loss: 0.9298 r:0.1866
en_zh Dev loss: 0.8378 r:0.4637
Current avg r:0.3251 Best avg r: 0.3698
16:58:45,294 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:11,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:36,829 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1750
en_de Dev loss: 0.8973 r:0.1891
en_zh Dev loss: 0.7807 r:0.4718
Current avg r:0.3304 Best avg r: 0.3698
17:00:53,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:18,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:44,641 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1629
en_de Dev loss: 0.8902 r:0.1888
en_zh Dev loss: 0.7790 r:0.4690
Current avg r:0.3289 Best avg r: 0.3698
17:03:00,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:26,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:52,476 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1732
en_de Dev loss: 0.9157 r:0.1772
en_zh Dev loss: 0.8074 r:0.4682
Current avg r:0.3227 Best avg r: 0.3698
17:05:11,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:37,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:03,486 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1729
en_de Dev loss: 0.9274 r:0.1415
en_zh Dev loss: 0.8078 r:0.4607
Current avg r:0.3011 Best avg r: 0.3698
17:07:22,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:48,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:14,454 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1696
en_de Dev loss: 0.9245 r:0.1814
en_zh Dev loss: 0.7527 r:0.4745
Current avg r:0.3280 Best avg r: 0.3698
17:09:33,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:59,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:10:25,474 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1504
en_de Dev loss: 0.9193 r:0.1820
en_zh Dev loss: 0.7727 r:0.4729
Current avg r:0.3274 Best avg r: 0.3698
17:11:45,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:10,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:36,778 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1559
en_de Dev loss: 0.9516 r:0.1808
en_zh Dev loss: 0.9361 r:0.4558
Current avg r:0.3183 Best avg r: 0.3698
17:13:56,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:21,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:47,767 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1502
en_de Dev loss: 0.9234 r:0.1932
en_zh Dev loss: 0.7863 r:0.4732
Current avg r:0.3332 Best avg r: 0.3698
17:16:05,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:31,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:56,854 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1611
en_de Dev loss: 0.9222 r:0.1782
en_zh Dev loss: 0.7995 r:0.4664
Current avg r:0.3223 Best avg r: 0.3698
17:18:13,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:38,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:04,688 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1578
en_de Dev loss: 0.8907 r:0.1802
en_zh Dev loss: 0.7723 r:0.4706
Current avg r:0.3254 Best avg r: 0.3698
17:20:21,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:47,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:12,917 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1418
en_de Dev loss: 0.9181 r:0.1686
en_zh Dev loss: 0.7865 r:0.4731
Current avg r:0.3208 Best avg r: 0.3698
17:22:32,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:58,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:23,944 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1538
en_de Dev loss: 0.9574 r:0.1690
en_zh Dev loss: 0.8395 r:0.4643
Current avg r:0.3167 Best avg r: 0.3698
17:24:43,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:09,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:34,975 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1528
en_de Dev loss: 0.9298 r:0.1787
en_zh Dev loss: 0.7771 r:0.4686
Current avg r:0.3236 Best avg r: 0.3698
17:26:54,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:20,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:46,8 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1539
en_de Dev loss: 0.9392 r:0.1644
en_zh Dev loss: 0.7896 r:0.4759
Current avg r:0.3201 Best avg r: 0.3698
17:29:02,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:28,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:53,924 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1638
en_de Dev loss: 0.9499 r:0.1758
en_zh Dev loss: 0.8097 r:0.4711
Current avg r:0.3235 Best avg r: 0.3698
17:31:10,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:35,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:01,747 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1432
en_de Dev loss: 0.9391 r:0.1670
en_zh Dev loss: 0.7923 r:0.4668
Current avg r:0.3169 Best avg r: 0.3698
17:33:17,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:43,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:09,596 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1541
en_de Dev loss: 0.9544 r:0.1601
en_zh Dev loss: 0.7704 r:0.4750
Current avg r:0.3176 Best avg r: 0.3698
17:35:28,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:54,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:20,618 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1380
en_de Dev loss: 0.9609 r:0.1756
en_zh Dev loss: 0.8447 r:0.4740
Current avg r:0.3248 Best avg r: 0.3698
17:37:38,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:04,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:30,465 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1527
en_de Dev loss: 0.9452 r:0.1821
en_zh Dev loss: 0.8481 r:0.4680
Current avg r:0.3251 Best avg r: 0.3698
17:39:46,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:12,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:38,360 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1469
en_de Dev loss: 0.9515 r:0.1459
en_zh Dev loss: 0.8087 r:0.4680
Current avg r:0.3070 Best avg r: 0.3698
17:41:57,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:23,597 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:49,412 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1442
en_de Dev loss: 0.9013 r:0.1894
en_zh Dev loss: 0.7326 r:0.4847
Current avg r:0.3370 Best avg r: 0.3698
17:44:06,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:31,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:57,625 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1372
en_de Dev loss: 0.9255 r:0.1595
en_zh Dev loss: 0.8187 r:0.4769
Current avg r:0.3182 Best avg r: 0.3698
17:46:13,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:39,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:05,484 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1362
en_de Dev loss: 0.9566 r:0.1818
en_zh Dev loss: 0.7718 r:0.4764
Current avg r:0.3291 Best avg r: 0.3698
17:48:21,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:47,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:13,291 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1354
en_de Dev loss: 0.9412 r:0.1650
en_zh Dev loss: 0.8084 r:0.4740
Current avg r:0.3195 Best avg r: 0.3698
17:50:30,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:56,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:21,986 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1423
en_de Dev loss: 0.9575 r:0.1856
en_zh Dev loss: 0.8660 r:0.4732
Current avg r:0.3294 Best avg r: 0.3698
17:52:41,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:07,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:33,26 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1365
en_de Dev loss: 0.9202 r:0.1861
en_zh Dev loss: 0.7872 r:0.4738
Current avg r:0.3300 Best avg r: 0.3698
17:54:52,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:18,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:44,2 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1440
en_de Dev loss: 0.9266 r:0.1765
en_zh Dev loss: 0.7995 r:0.4746
Current avg r:0.3256 Best avg r: 0.3698
17:57:03,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:29,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:54,949 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1392
en_de Dev loss: 0.9255 r:0.2044
en_zh Dev loss: 0.7769 r:0.4800
Current avg r:0.3422 Best avg r: 0.3698
17:59:11,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:37,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:02,868 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1407
en_de Dev loss: 0.9540 r:0.1943
en_zh Dev loss: 0.8009 r:0.4835
Current avg r:0.3389 Best avg r: 0.3698
18:01:19,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:44,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:10,726 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1326
en_de Dev loss: 0.9294 r:0.1849
en_zh Dev loss: 0.8238 r:0.4750
Current avg r:0.3299 Best avg r: 0.3698
18:03:27,35 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:52,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:18,538 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1248
en_de Dev loss: 0.9305 r:0.1938
en_zh Dev loss: 0.7722 r:0.4756
Current avg r:0.3347 Best avg r: 0.3698
18:05:34,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:00,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:26,279 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1330
en_de Dev loss: 0.9486 r:0.1864
en_zh Dev loss: 0.8157 r:0.4723
Current avg r:0.3293 Best avg r: 0.3698
18:07:42,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:08,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:34,67 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1365
en_de Dev loss: 0.9682 r:0.1857
en_zh Dev loss: 0.8169 r:0.4774
Current avg r:0.3315 Best avg r: 0.3698
18:09:50,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:15,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:41,710 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1357
en_de Dev loss: 0.9351 r:0.1783
en_zh Dev loss: 0.7530 r:0.4771
Current avg r:0.3277 Best avg r: 0.3698
18:11:59,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:24,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:50,683 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1346
en_de Dev loss: 0.9237 r:0.1788
en_zh Dev loss: 0.7442 r:0.4806
Current avg r:0.3297 Best avg r: 0.3698
18:14:10,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:35,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:01,734 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1226
en_de Dev loss: 0.9545 r:0.1688
en_zh Dev loss: 0.8039 r:0.4779
Current avg r:0.3233 Best avg r: 0.3698
18:16:18,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:44,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:09,914 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1305
en_de Dev loss: 0.9575 r:0.1713
en_zh Dev loss: 0.7983 r:0.4756
Current avg r:0.3235 Best avg r: 0.3698
18:18:26,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:51,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:17,698 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1197
en_de Dev loss: 0.9594 r:0.1640
en_zh Dev loss: 0.7957 r:0.4815
Current avg r:0.3228 Best avg r: 0.3698
18:20:33,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:59,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:25,365 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1179
en_de Dev loss: 0.9255 r:0.1749
en_zh Dev loss: 0.7736 r:0.4756
Current avg r:0.3252 Best avg r: 0.3698
18:22:41,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:07,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:33,19 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1323
en_de Dev loss: 0.9082 r:0.1846
en_zh Dev loss: 0.7695 r:0.4715
Current avg r:0.3281 Best avg r: 0.3698
18:24:49,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:14,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:40,666 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1277
en_de Dev loss: 0.9350 r:0.1844
en_zh Dev loss: 0.7759 r:0.4786
Current avg r:0.3315 Best avg r: 0.3698
18:26:56,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:22,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:48,318 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1316
en_de Dev loss: 0.9475 r:0.1697
en_zh Dev loss: 0.8198 r:0.4758
Current avg r:0.3227 Best avg r: 0.3698
18:29:04,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:30,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:55,962 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1140
en_de Dev loss: 0.9665 r:0.1624
en_zh Dev loss: 0.8050 r:0.4748
Current avg r:0.3186 Best avg r: 0.3698
18:31:12,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:37,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:03,615 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1273
en_de Dev loss: 0.9384 r:0.1936
en_zh Dev loss: 0.8009 r:0.4648
Current avg r:0.3292 Best avg r: 0.3698
18:33:19,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:45,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:11,294 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1291
en_de Dev loss: 0.9490 r:0.1876
en_zh Dev loss: 0.8178 r:0.4705
Current avg r:0.3290 Best avg r: 0.3698
18:35:27,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:53,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:19,6 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1234
en_de Dev loss: 0.9392 r:0.1683
en_zh Dev loss: 0.8176 r:0.4630
Current avg r:0.3157 Best avg r: 0.3698
18:37:35,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:00,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:26,596 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1288
en_de Dev loss: 0.9276 r:0.1853
en_zh Dev loss: 0.7918 r:0.4736
Current avg r:0.3294 Best avg r: 0.3698
18:39:42,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:08,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:34,138 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1368
en_de Dev loss: 0.9437 r:0.1828
en_zh Dev loss: 0.7532 r:0.4790
Current avg r:0.3309 Best avg r: 0.3698
18:41:50,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:15,913 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:41,667 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1220
en_de Dev loss: 0.9497 r:0.1596
en_zh Dev loss: 0.8164 r:0.4676
Current avg r:0.3136 Best avg r: 0.3698
18:43:57,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:23,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:49,218 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1260
en_de Dev loss: 0.9476 r:0.1799
en_zh Dev loss: 0.7701 r:0.4801
Current avg r:0.3300 Best avg r: 0.3698
18:46:05,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:31,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:56,735 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1285
en_de Dev loss: 0.9510 r:0.1658
en_zh Dev loss: 0.7789 r:0.4760
Current avg r:0.3209 Best avg r: 0.3698
18:48:13,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:38,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:04,728 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1151
en_de Dev loss: 0.9762 r:0.1490
en_zh Dev loss: 0.8103 r:0.4815
Current avg r:0.3152 Best avg r: 0.3698
18:50:20,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:46,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:12,273 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1163
en_de Dev loss: 0.9620 r:0.1622
en_zh Dev loss: 0.8301 r:0.4744
Current avg r:0.3183 Best avg r: 0.3698
18:52:28,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:54,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:19,789 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1156
en_de Dev loss: 0.9249 r:0.1642
en_zh Dev loss: 0.7366 r:0.4766
Current avg r:0.3204 Best avg r: 0.3698
18:54:35,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:01,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:27,274 root INFO Epoch 16 Global steps: 48800 Train loss: 0.1098
en_de Dev loss: 0.9213 r:0.1878
en_zh Dev loss: 0.7912 r:0.4815
Current avg r:0.3347 Best avg r: 0.3698
18:56:43,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:09,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:34,722 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1100
en_de Dev loss: 0.9264 r:0.1716
en_zh Dev loss: 0.7785 r:0.4782
Current avg r:0.3249 Best avg r: 0.3698
18:58:50,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:16,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:42,190 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1066
en_de Dev loss: 0.9303 r:0.1859
en_zh Dev loss: 0.7997 r:0.4785
Current avg r:0.3322 Best avg r: 0.3698
19:00:58,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:23,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:49,647 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1118
en_de Dev loss: 0.9435 r:0.1776
en_zh Dev loss: 0.8441 r:0.4770
Current avg r:0.3273 Best avg r: 0.3698
19:03:05,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:44,329 root INFO 
id:en_zh cur r: 0.4962 best r: 0.4962
19:03:44,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:10,65 root INFO Epoch 16 Global steps: 49600 Train loss: 0.1163
en_de Dev loss: 0.9634 r:0.1656
en_zh Dev loss: 0.7857 r:0.4968
Current avg r:0.3312 Best avg r: 0.3698
19:05:26,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:51,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:17,545 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1174
en_de Dev loss: 0.9233 r:0.1701
en_zh Dev loss: 0.7717 r:0.4879
Current avg r:0.3290 Best avg r: 0.3698
19:07:33,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:59,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:25,135 root INFO Epoch 16 Global steps: 50000 Train loss: 0.1210
en_de Dev loss: 0.9486 r:0.1421
en_zh Dev loss: 0.8061 r:0.4812
Current avg r:0.3116 Best avg r: 0.3698
19:09:41,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:06,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:32,605 root INFO Epoch 16 Global steps: 50200 Train loss: 0.1213
en_de Dev loss: 0.9738 r:0.1789
en_zh Dev loss: 0.8330 r:0.4763
Current avg r:0.3276 Best avg r: 0.3698
19:11:48,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:14,370 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:12:40,97 root INFO Epoch 16 Global steps: 50400 Train loss: 0.1107
en_de Dev loss: 0.9297 r:0.1524
en_zh Dev loss: 0.8198 r:0.4771
Current avg r:0.3147 Best avg r: 0.3698
19:13:56,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:21,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:47,602 root INFO Epoch 16 Global steps: 50600 Train loss: 0.1176
en_de Dev loss: 0.9471 r:0.1765
en_zh Dev loss: 0.7810 r:0.4848
Current avg r:0.3307 Best avg r: 0.3698
19:16:03,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:29,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:55,89 root INFO Epoch 16 Global steps: 50800 Train loss: 0.1126
en_de Dev loss: 0.9371 r:0.1824
en_zh Dev loss: 0.7587 r:0.4919
Current avg r:0.3372 Best avg r: 0.3698
19:18:11,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:36,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:02,600 root INFO Epoch 16 Global steps: 51000 Train loss: 0.1061
en_de Dev loss: 0.9549 r:0.1725
en_zh Dev loss: 0.7648 r:0.4868
Current avg r:0.3296 Best avg r: 0.3698
19:20:19,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:44,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:10,475 root INFO Epoch 17 Global steps: 51200 Train loss: 0.1023
en_de Dev loss: 0.9279 r:0.1756
en_zh Dev loss: 0.7375 r:0.4850
Current avg r:0.3303 Best avg r: 0.3698
