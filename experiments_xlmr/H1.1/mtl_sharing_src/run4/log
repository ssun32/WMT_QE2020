14:41:31,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:14,426 root INFO 
id:en_zh cur r: 0.1279 best r: 0.1279
14:42:14,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:42:44,48 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
14:42:44,54 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:43:13,856 root INFO Epoch 0 Global steps: 200 Train loss: 0.6620
en_de Dev loss: 0.8889 r:0.0817
en_zh Dev loss: 0.8144 r:0.1256
Current avg r:0.1037 Best avg r: 0.1037
14:44:43,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:28,329 root INFO 
id:en_zh cur r: 0.1944 best r: 0.1944
14:45:28,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:58,511 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
14:45:58,517 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:46:28,714 root INFO Epoch 0 Global steps: 400 Train loss: 0.7213
en_de Dev loss: 0.8894 r:0.1193
en_zh Dev loss: 0.8130 r:0.1794
Current avg r:0.1493 Best avg r: 0.1493
14:47:58,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:43,828 root INFO 
id:en_zh cur r: 0.2226 best r: 0.2226
14:48:43,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:14,209 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
14:49:14,214 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:49:44,391 root INFO Epoch 0 Global steps: 600 Train loss: 0.7761
en_de Dev loss: 0.8824 r:0.1197
en_zh Dev loss: 0.8122 r:0.2243
Current avg r:0.1720 Best avg r: 0.1720
14:51:14,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:59,557 root INFO 
id:en_zh cur r: 0.2478 best r: 0.2478
14:51:59,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:30,3 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
14:52:30,21 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:53:00,238 root INFO Epoch 0 Global steps: 800 Train loss: 0.7803
en_de Dev loss: 0.8836 r:0.1316
en_zh Dev loss: 0.8079 r:0.2516
Current avg r:0.1916 Best avg r: 0.1916
14:54:29,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:15,355 root INFO 
id:en_zh cur r: 0.2881 best r: 0.2881
14:55:15,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:45,737 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
14:55:45,743 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:56:15,860 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8406
en_de Dev loss: 0.8781 r:0.1553
en_zh Dev loss: 0.7994 r:0.2970
Current avg r:0.2261 Best avg r: 0.2261
14:57:45,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:31,44 root INFO 
id:en_zh cur r: 0.3249 best r: 0.3249
14:58:31,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:01,438 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
14:59:01,444 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:59:31,774 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7898
en_de Dev loss: 0.8812 r:0.1730
en_zh Dev loss: 0.7965 r:0.3354
Current avg r:0.2542 Best avg r: 0.2542
15:01:01,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:46,866 root INFO 
id:en_zh cur r: 0.3428 best r: 0.3428
15:01:46,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:17,268 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:02:17,274 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:02:47,351 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7047
en_de Dev loss: 0.8732 r:0.1929
en_zh Dev loss: 0.7827 r:0.3488
Current avg r:0.2708 Best avg r: 0.2708
15:04:17,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:47,289 root INFO 
id:en_de cur r: 0.1853 best r: 0.1853
15:05:17,546 root INFO 
id:en_zh cur r: 0.3534 best r: 0.3534
15:05:17,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:47,857 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:05:47,863 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:06:18,336 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7779
en_de Dev loss: 0.8704 r:0.2063
en_zh Dev loss: 0.7773 r:0.3613
Current avg r:0.2838 Best avg r: 0.2838
15:07:47,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:33,216 root INFO 
id:en_zh cur r: 0.3657 best r: 0.3657
15:08:33,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:03,691 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7489
en_de Dev loss: 0.8651 r:0.1804
en_zh Dev loss: 0.7498 r:0.3497
Current avg r:0.2650 Best avg r: 0.2838
15:10:33,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:03,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:33,612 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7267
en_de Dev loss: 0.8681 r:0.1790
en_zh Dev loss: 0.7457 r:0.3541
Current avg r:0.2665 Best avg r: 0.2838
15:13:03,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:33,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:03,890 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7522
en_de Dev loss: 0.8744 r:0.1568
en_zh Dev loss: 0.7621 r:0.3114
Current avg r:0.2341 Best avg r: 0.2838
15:15:33,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:18,691 root INFO 
id:en_zh cur r: 0.3809 best r: 0.3809
15:16:18,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:48,857 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7530
en_de Dev loss: 0.8642 r:0.1696
en_zh Dev loss: 0.7127 r:0.3722
Current avg r:0.2709 Best avg r: 0.2838
15:18:18,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:48,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:18,816 root INFO Epoch 0 Global steps: 2600 Train loss: 0.6907
en_de Dev loss: 0.8729 r:0.1928
en_zh Dev loss: 0.7471 r:0.3645
Current avg r:0.2787 Best avg r: 0.2838
15:20:48,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:21:18,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:48,709 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6545
en_de Dev loss: 0.8872 r:0.2021
en_zh Dev loss: 0.7755 r:0.3563
Current avg r:0.2792 Best avg r: 0.2838
15:23:18,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:03,760 root INFO 
id:en_zh cur r: 0.4102 best r: 0.4102
15:24:03,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:33,887 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:24:33,893 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:25:04,39 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6681
en_de Dev loss: 0.8518 r:0.2022
en_zh Dev loss: 0.6940 r:0.3965
Current avg r:0.2993 Best avg r: 0.2993
15:26:33,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:03,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:34,285 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6379
en_de Dev loss: 0.8855 r:0.1892
en_zh Dev loss: 0.7324 r:0.3877
Current avg r:0.2884 Best avg r: 0.2993
15:29:03,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:48,868 root INFO 
id:en_zh cur r: 0.4154 best r: 0.4154
15:29:48,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:19,28 root INFO Epoch 1 Global steps: 3400 Train loss: 0.6554
en_de Dev loss: 0.8701 r:0.2030
en_zh Dev loss: 0.7301 r:0.3945
Current avg r:0.2987 Best avg r: 0.2993
15:31:48,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:18,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:49,21 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:32:49,28 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:33:19,92 root INFO Epoch 1 Global steps: 3600 Train loss: 0.6631
en_de Dev loss: 0.8721 r:0.2026
en_zh Dev loss: 0.7208 r:0.3978
Current avg r:0.3002 Best avg r: 0.3002
15:34:48,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:33,956 root INFO 
id:en_zh cur r: 0.4243 best r: 0.4243
15:35:33,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:04,77 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:36:04,82 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:36:34,200 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6404
en_de Dev loss: 0.8647 r:0.2297
en_zh Dev loss: 0.7267 r:0.4193
Current avg r:0.3245 Best avg r: 0.3245
15:38:03,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:48,844 root INFO 
id:en_zh cur r: 0.4246 best r: 0.4246
15:38:48,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:19,46 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:39:19,52 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:39:49,273 root INFO Epoch 1 Global steps: 4000 Train loss: 0.6432
en_de Dev loss: 0.8521 r:0.2309
en_zh Dev loss: 0.7055 r:0.4228
Current avg r:0.3268 Best avg r: 0.3268
15:41:18,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:48,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:19,41 root INFO Epoch 1 Global steps: 4200 Train loss: 0.6661
en_de Dev loss: 0.8818 r:0.2213
en_zh Dev loss: 0.7742 r:0.4048
Current avg r:0.3130 Best avg r: 0.3268
15:43:48,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:18,428 root INFO 
id:en_de cur r: 0.1903 best r: 0.1903
15:44:33,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:03,600 root INFO Epoch 1 Global steps: 4400 Train loss: 0.6066
en_de Dev loss: 0.8454 r:0.2395
en_zh Dev loss: 0.7000 r:0.4060
Current avg r:0.3227 Best avg r: 0.3268
15:46:32,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:02,969 root INFO 
id:en_de cur r: 0.2073 best r: 0.2073
15:47:33,216 root INFO 
id:en_zh cur r: 0.4326 best r: 0.4326
15:47:33,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:03,308 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:48:03,315 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:48:33,408 root INFO Epoch 1 Global steps: 4600 Train loss: 0.6702
en_de Dev loss: 0.8379 r:0.2527
en_zh Dev loss: 0.6745 r:0.4331
Current avg r:0.3429 Best avg r: 0.3429
15:50:02,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:32,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:03,125 root INFO Epoch 1 Global steps: 4800 Train loss: 0.6659
en_de Dev loss: 0.8492 r:0.2522
en_zh Dev loss: 0.7557 r:0.4230
Current avg r:0.3376 Best avg r: 0.3429
15:52:32,529 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:17,505 root INFO 
id:en_zh cur r: 0.4388 best r: 0.4388
15:53:17,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:47,894 root INFO Epoch 1 Global steps: 5000 Train loss: 0.6246
en_de Dev loss: 0.8458 r:0.2364
en_zh Dev loss: 0.7192 r:0.4218
Current avg r:0.3291 Best avg r: 0.3429
15:55:17,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:47,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:17,445 root INFO Epoch 1 Global steps: 5200 Train loss: 0.5880
en_de Dev loss: 0.8532 r:0.2351
en_zh Dev loss: 0.7073 r:0.4259
Current avg r:0.3305 Best avg r: 0.3429
15:57:46,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:32,221 root INFO 
id:en_zh cur r: 0.4405 best r: 0.4405
15:58:32,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:02,361 root INFO Epoch 1 Global steps: 5400 Train loss: 0.7316
en_de Dev loss: 0.8531 r:0.2430
en_zh Dev loss: 0.7330 r:0.4319
Current avg r:0.3375 Best avg r: 0.3429
16:00:31,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:16,958 root INFO 
id:en_zh cur r: 0.4517 best r: 0.4517
16:01:16,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:47,125 root INFO Epoch 1 Global steps: 5600 Train loss: 0.5881
en_de Dev loss: 0.8560 r:0.2303
en_zh Dev loss: 0.7073 r:0.4424
Current avg r:0.3364 Best avg r: 0.3429
16:03:16,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:46,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:16,696 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6454
en_de Dev loss: 0.8490 r:0.2296
en_zh Dev loss: 0.7071 r:0.4328
Current avg r:0.3312 Best avg r: 0.3429
16:05:46,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:31,469 root INFO 
id:en_zh cur r: 0.4526 best r: 0.4526
16:06:31,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:01,569 root INFO Epoch 1 Global steps: 6000 Train loss: 0.6260
en_de Dev loss: 0.8454 r:0.2200
en_zh Dev loss: 0.7088 r:0.4298
Current avg r:0.3249 Best avg r: 0.3429
16:08:31,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:01,91 root INFO 
id:en_de cur r: 0.2113 best r: 0.2113
16:09:16,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:46,495 root INFO Epoch 2 Global steps: 6200 Train loss: 0.5614
en_de Dev loss: 0.8548 r:0.2308
en_zh Dev loss: 0.7584 r:0.4211
Current avg r:0.3260 Best avg r: 0.3429
16:11:15,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:45,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:15,987 root INFO Epoch 2 Global steps: 6400 Train loss: 0.5462
en_de Dev loss: 0.8608 r:0.2213
en_zh Dev loss: 0.7428 r:0.4091
Current avg r:0.3152 Best avg r: 0.3429
16:13:45,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:15,380 root INFO 
id:en_de cur r: 0.2143 best r: 0.2143
16:14:45,653 root INFO 
id:en_zh cur r: 0.4682 best r: 0.4682
16:14:45,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:15,709 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
16:15:15,716 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:15:45,709 root INFO Epoch 2 Global steps: 6600 Train loss: 0.5861
en_de Dev loss: 0.8473 r:0.2300
en_zh Dev loss: 0.6685 r:0.4590
Current avg r:0.3445 Best avg r: 0.3445
16:17:15,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:45,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:15,261 root INFO Epoch 2 Global steps: 6800 Train loss: 0.6568
en_de Dev loss: 0.8490 r:0.2241
en_zh Dev loss: 0.6910 r:0.4488
Current avg r:0.3365 Best avg r: 0.3445
16:19:44,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:14,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:44,779 root INFO Epoch 2 Global steps: 7000 Train loss: 0.6713
en_de Dev loss: 0.8574 r:0.2269
en_zh Dev loss: 0.6902 r:0.4438
Current avg r:0.3353 Best avg r: 0.3445
16:22:14,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:44,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:14,567 root INFO Epoch 2 Global steps: 7200 Train loss: 0.6993
en_de Dev loss: 0.8397 r:0.2348
en_zh Dev loss: 0.7123 r:0.4538
Current avg r:0.3443 Best avg r: 0.3445
16:24:43,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:29,184 root INFO 
id:en_zh cur r: 0.4709 best r: 0.4709
16:25:29,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:59,400 root INFO Epoch 2 Global steps: 7400 Train loss: 0.5687
en_de Dev loss: 0.8515 r:0.2236
en_zh Dev loss: 0.7197 r:0.4584
Current avg r:0.3410 Best avg r: 0.3445
16:27:28,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:58,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:28,775 root INFO Epoch 2 Global steps: 7600 Train loss: 0.5549
en_de Dev loss: 0.8642 r:0.2149
en_zh Dev loss: 0.7700 r:0.4211
Current avg r:0.3180 Best avg r: 0.3445
16:29:58,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:28,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:58,565 root INFO Epoch 2 Global steps: 7800 Train loss: 0.5086
en_de Dev loss: 0.8481 r:0.2360
en_zh Dev loss: 0.7054 r:0.4443
Current avg r:0.3401 Best avg r: 0.3445
16:32:27,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:58,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:28,198 root INFO Epoch 2 Global steps: 8000 Train loss: 0.6739
en_de Dev loss: 0.8397 r:0.2318
en_zh Dev loss: 0.6956 r:0.4528
Current avg r:0.3423 Best avg r: 0.3445
16:34:57,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:27,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:57,590 root INFO Epoch 2 Global steps: 8200 Train loss: 0.5877
en_de Dev loss: 0.8506 r:0.2369
en_zh Dev loss: 0.7394 r:0.4514
Current avg r:0.3442 Best avg r: 0.3445
16:37:26,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:57,62 root INFO 
id:en_de cur r: 0.2145 best r: 0.2145
16:38:12,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:42,504 root INFO Epoch 2 Global steps: 8400 Train loss: 0.5328
en_de Dev loss: 0.8405 r:0.2338
en_zh Dev loss: 0.6996 r:0.4548
Current avg r:0.3443 Best avg r: 0.3445
16:40:11,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:56,926 root INFO 
id:en_zh cur r: 0.4839 best r: 0.4839
16:40:56,926 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:27,65 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
16:41:27,71 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:41:57,217 root INFO Epoch 2 Global steps: 8600 Train loss: 0.4950
en_de Dev loss: 0.8431 r:0.2237
en_zh Dev loss: 0.6386 r:0.4785
Current avg r:0.3511 Best avg r: 0.3511
16:43:26,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:56,549 root INFO 
id:en_de cur r: 0.2279 best r: 0.2279
16:44:11,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:41,806 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
16:44:41,814 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:45:11,986 root INFO Epoch 2 Global steps: 8800 Train loss: 0.5356
en_de Dev loss: 0.8480 r:0.2421
en_zh Dev loss: 0.7076 r:0.4603
Current avg r:0.3512 Best avg r: 0.3512
16:46:41,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:11,322 root INFO 
id:en_de cur r: 0.2298 best r: 0.2298
16:47:26,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:56,706 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
16:47:56,714 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:48:26,741 root INFO Epoch 2 Global steps: 9000 Train loss: 0.5475
en_de Dev loss: 0.8338 r:0.2449
en_zh Dev loss: 0.6515 r:0.4763
Current avg r:0.3606 Best avg r: 0.3606
16:49:56,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:26,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:56,475 root INFO Epoch 3 Global steps: 9200 Train loss: 0.4985
en_de Dev loss: 0.8763 r:0.2449
en_zh Dev loss: 0.7908 r:0.4470
Current avg r:0.3460 Best avg r: 0.3606
16:52:25,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:55,823 root INFO 
id:en_de cur r: 0.2345 best r: 0.2345
16:53:11,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:41,145 root INFO Epoch 3 Global steps: 9400 Train loss: 0.5323
en_de Dev loss: 0.8596 r:0.2564
en_zh Dev loss: 0.8063 r:0.4309
Current avg r:0.3436 Best avg r: 0.3606
16:55:10,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:40,472 root INFO 
id:en_de cur r: 0.2400 best r: 0.2400
16:55:55,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:25,699 root INFO Epoch 3 Global steps: 9600 Train loss: 0.5701
en_de Dev loss: 0.8398 r:0.2551
en_zh Dev loss: 0.8020 r:0.4364
Current avg r:0.3458 Best avg r: 0.3606
16:57:54,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:24,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:55,326 root INFO Epoch 3 Global steps: 9800 Train loss: 0.4723
en_de Dev loss: 0.8287 r:0.2567
en_zh Dev loss: 0.6804 r:0.4636
Current avg r:0.3601 Best avg r: 0.3606
17:00:24,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:54,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:24,837 root INFO Epoch 3 Global steps: 10000 Train loss: 0.4456
en_de Dev loss: 0.8524 r:0.2476
en_zh Dev loss: 0.7371 r:0.4553
Current avg r:0.3514 Best avg r: 0.3606
17:02:54,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:24,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:54,565 root INFO Epoch 3 Global steps: 10200 Train loss: 0.5691
en_de Dev loss: 0.8403 r:0.2421
en_zh Dev loss: 0.7049 r:0.4658
Current avg r:0.3539 Best avg r: 0.3606
17:05:24,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:53,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:24,62 root INFO Epoch 3 Global steps: 10400 Train loss: 0.4810
en_de Dev loss: 0.8450 r:0.2546
en_zh Dev loss: 0.7338 r:0.4519
Current avg r:0.3533 Best avg r: 0.3606
17:07:53,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:23,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:53,676 root INFO Epoch 3 Global steps: 10600 Train loss: 0.5617
en_de Dev loss: 0.8545 r:0.2394
en_zh Dev loss: 0.7396 r:0.4543
Current avg r:0.3469 Best avg r: 0.3606
17:10:23,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:53,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:23,380 root INFO Epoch 3 Global steps: 10800 Train loss: 0.5413
en_de Dev loss: 0.8547 r:0.2222
en_zh Dev loss: 0.6909 r:0.4613
Current avg r:0.3418 Best avg r: 0.3606
17:12:52,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:36,880 root INFO 
id:en_zh cur r: 0.4854 best r: 0.4854
17:13:36,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:06,574 root INFO Epoch 3 Global steps: 11000 Train loss: 0.5042
en_de Dev loss: 0.8395 r:0.2403
en_zh Dev loss: 0.6736 r:0.4725
Current avg r:0.3564 Best avg r: 0.3606
17:15:35,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:04,517 root INFO 
id:en_de cur r: 0.2412 best r: 0.2412
17:16:19,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:49,126 root INFO Epoch 3 Global steps: 11200 Train loss: 0.4467
en_de Dev loss: 0.8343 r:0.2508
en_zh Dev loss: 0.6965 r:0.4584
Current avg r:0.3546 Best avg r: 0.3606
17:18:17,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:46,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:16,410 root INFO Epoch 3 Global steps: 11400 Train loss: 0.5368
en_de Dev loss: 0.8352 r:0.2534
en_zh Dev loss: 0.6940 r:0.4493
Current avg r:0.3514 Best avg r: 0.3606
17:20:44,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:29,149 root INFO 
id:en_zh cur r: 0.4949 best r: 0.4949
17:21:29,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:58,550 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
17:21:58,558 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:22:27,970 root INFO Epoch 3 Global steps: 11600 Train loss: 0.5054
en_de Dev loss: 0.8399 r:0.2425
en_zh Dev loss: 0.6488 r:0.4869
Current avg r:0.3647 Best avg r: 0.3647
17:23:56,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:25,918 root INFO 
id:en_de cur r: 0.2478 best r: 0.2478
17:24:40,712 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:10,103 root INFO Epoch 3 Global steps: 11800 Train loss: 0.4726
en_de Dev loss: 0.8475 r:0.2622
en_zh Dev loss: 0.7339 r:0.4622
Current avg r:0.3622 Best avg r: 0.3647
17:26:38,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:07,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:37,405 root INFO Epoch 3 Global steps: 12000 Train loss: 0.5864
en_de Dev loss: 0.8467 r:0.2323
en_zh Dev loss: 0.7042 r:0.4628
Current avg r:0.3476 Best avg r: 0.3647
17:29:06,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:35,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:04,957 root INFO Epoch 4 Global steps: 12200 Train loss: 0.4461
en_de Dev loss: 0.8352 r:0.2433
en_zh Dev loss: 0.7158 r:0.4470
Current avg r:0.3452 Best avg r: 0.3647
17:31:33,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:02,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:32,54 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4696
en_de Dev loss: 0.8344 r:0.2526
en_zh Dev loss: 0.7515 r:0.4483
Current avg r:0.3504 Best avg r: 0.3647
17:34:00,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:29,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:59,205 root INFO Epoch 4 Global steps: 12600 Train loss: 0.4430
en_de Dev loss: 0.8379 r:0.2565
en_zh Dev loss: 0.7496 r:0.4409
Current avg r:0.3487 Best avg r: 0.3647
17:36:27,797 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:57,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:26,541 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4912
en_de Dev loss: 0.8457 r:0.2382
en_zh Dev loss: 0.7263 r:0.4478
Current avg r:0.3430 Best avg r: 0.3647
17:38:55,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:24,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:53,657 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4450
en_de Dev loss: 0.8518 r:0.2294
en_zh Dev loss: 0.7326 r:0.4469
Current avg r:0.3381 Best avg r: 0.3647
17:41:22,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:51,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:21,268 root INFO Epoch 4 Global steps: 13200 Train loss: 0.4484
en_de Dev loss: 0.8478 r:0.2325
en_zh Dev loss: 0.7352 r:0.4531
Current avg r:0.3428 Best avg r: 0.3647
17:43:49,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:19,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:48,674 root INFO Epoch 4 Global steps: 13400 Train loss: 0.4396
en_de Dev loss: 0.8591 r:0.2141
en_zh Dev loss: 0.7302 r:0.4515
Current avg r:0.3328 Best avg r: 0.3647
17:46:17,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:46,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:16,185 root INFO Epoch 4 Global steps: 13600 Train loss: 0.5168
en_de Dev loss: 0.8682 r:0.2160
en_zh Dev loss: 0.7273 r:0.4649
Current avg r:0.3404 Best avg r: 0.3647
17:48:44,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:13,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:43,721 root INFO Epoch 4 Global steps: 13800 Train loss: 0.4311
en_de Dev loss: 0.8515 r:0.2218
en_zh Dev loss: 0.7089 r:0.4567
Current avg r:0.3393 Best avg r: 0.3647
17:51:12,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:41,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:11,151 root INFO Epoch 4 Global steps: 14000 Train loss: 0.5030
en_de Dev loss: 0.8599 r:0.2257
en_zh Dev loss: 0.7857 r:0.4389
Current avg r:0.3323 Best avg r: 0.3647
17:53:39,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:08,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:38,625 root INFO Epoch 4 Global steps: 14200 Train loss: 0.4147
en_de Dev loss: 0.8496 r:0.2245
en_zh Dev loss: 0.7030 r:0.4625
Current avg r:0.3435 Best avg r: 0.3647
17:56:07,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:36,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:06,183 root INFO Epoch 4 Global steps: 14400 Train loss: 0.4041
en_de Dev loss: 0.8596 r:0.2224
en_zh Dev loss: 0.7410 r:0.4490
Current avg r:0.3357 Best avg r: 0.3647
17:58:34,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:04,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:33,909 root INFO Epoch 4 Global steps: 14600 Train loss: 0.4489
en_de Dev loss: 0.8716 r:0.2084
en_zh Dev loss: 0.7008 r:0.4680
Current avg r:0.3382 Best avg r: 0.3647
18:01:02,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:31,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:01,529 root INFO Epoch 4 Global steps: 14800 Train loss: 0.3667
en_de Dev loss: 0.8755 r:0.2022
en_zh Dev loss: 0.7196 r:0.4539
Current avg r:0.3281 Best avg r: 0.3647
18:03:30,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:59,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:29,447 root INFO Epoch 4 Global steps: 15000 Train loss: 0.4035
en_de Dev loss: 0.8600 r:0.2122
en_zh Dev loss: 0.7527 r:0.4385
Current avg r:0.3254 Best avg r: 0.3647
18:05:58,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:27,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:57,713 root INFO Epoch 5 Global steps: 15200 Train loss: 0.3379
en_de Dev loss: 0.8625 r:0.2060
en_zh Dev loss: 0.8085 r:0.4234
Current avg r:0.3147 Best avg r: 0.3647
18:08:26,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:55,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:25,730 root INFO Epoch 5 Global steps: 15400 Train loss: 0.3733
en_de Dev loss: 0.8688 r:0.2117
en_zh Dev loss: 0.7775 r:0.4384
Current avg r:0.3250 Best avg r: 0.3647
18:10:54,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:23,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:53,851 root INFO Epoch 5 Global steps: 15600 Train loss: 0.3834
en_de Dev loss: 0.8767 r:0.2109
en_zh Dev loss: 0.7747 r:0.4507
Current avg r:0.3308 Best avg r: 0.3647
18:13:22,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:51,911 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:21,741 root INFO Epoch 5 Global steps: 15800 Train loss: 0.3942
en_de Dev loss: 0.8593 r:0.2208
en_zh Dev loss: 0.7295 r:0.4375
Current avg r:0.3292 Best avg r: 0.3647
18:15:50,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:19,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:49,728 root INFO Epoch 5 Global steps: 16000 Train loss: 0.4294
en_de Dev loss: 0.8944 r:0.1858
en_zh Dev loss: 0.8057 r:0.4304
Current avg r:0.3081 Best avg r: 0.3647
18:18:18,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:47,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:17,630 root INFO Epoch 5 Global steps: 16200 Train loss: 0.4188
en_de Dev loss: 0.8932 r:0.1823
en_zh Dev loss: 0.8208 r:0.4293
Current avg r:0.3058 Best avg r: 0.3647
18:20:46,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:15,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:45,665 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3663
en_de Dev loss: 0.8653 r:0.1941
en_zh Dev loss: 0.7042 r:0.4535
Current avg r:0.3238 Best avg r: 0.3647
18:23:14,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:43,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:13,400 root INFO Epoch 5 Global steps: 16600 Train loss: 0.3588
en_de Dev loss: 0.8597 r:0.2028
en_zh Dev loss: 0.7122 r:0.4466
Current avg r:0.3247 Best avg r: 0.3647
18:25:42,5 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:11,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:41,240 root INFO Epoch 5 Global steps: 16800 Train loss: 0.4272
en_de Dev loss: 0.8659 r:0.1926
en_zh Dev loss: 0.7707 r:0.4327
Current avg r:0.3127 Best avg r: 0.3647
18:28:09,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:39,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:08,944 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3818
en_de Dev loss: 0.8730 r:0.2124
en_zh Dev loss: 0.8191 r:0.4269
Current avg r:0.3197 Best avg r: 0.3647
18:30:37,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:06,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:36,629 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3342
en_de Dev loss: 0.8864 r:0.1961
en_zh Dev loss: 0.8232 r:0.4395
Current avg r:0.3178 Best avg r: 0.3647
18:33:05,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:34,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:04,247 root INFO Epoch 5 Global steps: 17400 Train loss: 0.3647
en_de Dev loss: 0.8813 r:0.1927
en_zh Dev loss: 0.7669 r:0.4607
Current avg r:0.3267 Best avg r: 0.3647
18:35:32,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:02,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:31,940 root INFO Epoch 5 Global steps: 17600 Train loss: 0.3769
en_de Dev loss: 0.8681 r:0.1992
en_zh Dev loss: 0.7684 r:0.4454
Current avg r:0.3223 Best avg r: 0.3647
18:38:00,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:29,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:59,378 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3290
en_de Dev loss: 0.8758 r:0.1927
en_zh Dev loss: 0.7424 r:0.4542
Current avg r:0.3235 Best avg r: 0.3647
18:40:27,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:57,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:27,219 root INFO Epoch 5 Global steps: 18000 Train loss: 0.3639
en_de Dev loss: 0.8968 r:0.1778
en_zh Dev loss: 0.7599 r:0.4631
Current avg r:0.3204 Best avg r: 0.3647
18:42:56,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:25,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:55,120 root INFO Epoch 6 Global steps: 18200 Train loss: 0.2998
en_de Dev loss: 0.8853 r:0.1896
en_zh Dev loss: 0.8171 r:0.4479
Current avg r:0.3187 Best avg r: 0.3647
18:45:23,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:52,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:22,724 root INFO Epoch 6 Global steps: 18400 Train loss: 0.3190
en_de Dev loss: 0.8903 r:0.1813
en_zh Dev loss: 0.8997 r:0.4226
Current avg r:0.3019 Best avg r: 0.3647
18:47:51,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:20,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:50,320 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3014
en_de Dev loss: 0.9226 r:0.1932
en_zh Dev loss: 0.7451 r:0.4640
Current avg r:0.3286 Best avg r: 0.3647
18:50:18,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:48,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:17,881 root INFO Epoch 6 Global steps: 18800 Train loss: 0.2872
en_de Dev loss: 0.8999 r:0.1926
en_zh Dev loss: 0.8228 r:0.4548
Current avg r:0.3237 Best avg r: 0.3647
18:52:46,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:15,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:45,387 root INFO Epoch 6 Global steps: 19000 Train loss: 0.3330
en_de Dev loss: 0.8830 r:0.1726
en_zh Dev loss: 0.7935 r:0.4452
Current avg r:0.3089 Best avg r: 0.3647
18:55:13,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:43,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:56:12,919 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3155
en_de Dev loss: 0.8968 r:0.1831
en_zh Dev loss: 0.8970 r:0.4360
Current avg r:0.3095 Best avg r: 0.3647
18:57:41,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:10,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:40,192 root INFO Epoch 6 Global steps: 19400 Train loss: 0.3200
en_de Dev loss: 0.8816 r:0.2080
en_zh Dev loss: 0.7828 r:0.4455
Current avg r:0.3268 Best avg r: 0.3647
19:00:08,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:38,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:07,906 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3167
en_de Dev loss: 0.8811 r:0.1900
en_zh Dev loss: 0.8335 r:0.4420
Current avg r:0.3160 Best avg r: 0.3647
19:02:36,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:05,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:35,48 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3349
en_de Dev loss: 0.8963 r:0.1975
en_zh Dev loss: 0.8826 r:0.4426
Current avg r:0.3200 Best avg r: 0.3647
19:05:03,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:32,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:02,746 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3457
en_de Dev loss: 0.8936 r:0.1956
en_zh Dev loss: 0.7715 r:0.4524
Current avg r:0.3240 Best avg r: 0.3647
19:07:31,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:00,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:30,178 root INFO Epoch 6 Global steps: 20200 Train loss: 0.2980
en_de Dev loss: 0.8524 r:0.2244
en_zh Dev loss: 0.7375 r:0.4584
Current avg r:0.3414 Best avg r: 0.3647
19:09:58,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:28,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:57,722 root INFO Epoch 6 Global steps: 20400 Train loss: 0.2870
en_de Dev loss: 0.8822 r:0.1899
en_zh Dev loss: 0.7768 r:0.4584
Current avg r:0.3242 Best avg r: 0.3647
19:12:26,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:55,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:25,138 root INFO Epoch 6 Global steps: 20600 Train loss: 0.3416
en_de Dev loss: 0.8729 r:0.2024
en_zh Dev loss: 0.7883 r:0.4549
Current avg r:0.3286 Best avg r: 0.3647
19:14:53,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:22,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:52,779 root INFO Epoch 6 Global steps: 20800 Train loss: 0.3257
en_de Dev loss: 0.8595 r:0.2102
en_zh Dev loss: 0.8321 r:0.4431
Current avg r:0.3267 Best avg r: 0.3647
19:17:21,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:50,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:20,242 root INFO Epoch 6 Global steps: 21000 Train loss: 0.2953
en_de Dev loss: 0.8767 r:0.2075
en_zh Dev loss: 0.7849 r:0.4587
Current avg r:0.3331 Best avg r: 0.3647
19:19:49,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:18,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:47,896 root INFO Epoch 7 Global steps: 21200 Train loss: 0.2897
en_de Dev loss: 0.8855 r:0.2014
en_zh Dev loss: 0.8443 r:0.4421
Current avg r:0.3217 Best avg r: 0.3647
19:22:16,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:45,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:15,470 root INFO Epoch 7 Global steps: 21400 Train loss: 0.2962
en_de Dev loss: 0.8837 r:0.2080
en_zh Dev loss: 0.8310 r:0.4438
Current avg r:0.3259 Best avg r: 0.3647
19:24:43,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:13,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:43,13 root INFO Epoch 7 Global steps: 21600 Train loss: 0.3116
en_de Dev loss: 0.9166 r:0.1967
en_zh Dev loss: 0.9313 r:0.4423
Current avg r:0.3195 Best avg r: 0.3647
19:27:11,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:40,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:10,292 root INFO Epoch 7 Global steps: 21800 Train loss: 0.2528
en_de Dev loss: 0.8918 r:0.1847
en_zh Dev loss: 0.8324 r:0.4501
Current avg r:0.3174 Best avg r: 0.3647
19:29:38,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:08,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:37,612 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2743
en_de Dev loss: 0.8990 r:0.1820
en_zh Dev loss: 0.8290 r:0.4436
Current avg r:0.3128 Best avg r: 0.3647
19:32:06,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:35,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:05,55 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2438
en_de Dev loss: 0.8945 r:0.1859
en_zh Dev loss: 0.8391 r:0.4437
Current avg r:0.3148 Best avg r: 0.3647
19:34:33,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:02,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:32,475 root INFO Epoch 7 Global steps: 22400 Train loss: 0.2841
en_de Dev loss: 0.9087 r:0.1835
en_zh Dev loss: 0.8457 r:0.4463
Current avg r:0.3149 Best avg r: 0.3647
19:37:00,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:37:30,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:59,990 root INFO Epoch 7 Global steps: 22600 Train loss: 0.3097
en_de Dev loss: 0.9246 r:0.1607
en_zh Dev loss: 0.8353 r:0.4518
Current avg r:0.3062 Best avg r: 0.3647
19:39:28,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:57,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:27,345 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2973
en_de Dev loss: 0.9119 r:0.1632
en_zh Dev loss: 0.7926 r:0.4623
Current avg r:0.3127 Best avg r: 0.3647
19:41:55,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:24,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:54,510 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2519
en_de Dev loss: 0.8999 r:0.1698
en_zh Dev loss: 0.8511 r:0.4493
Current avg r:0.3095 Best avg r: 0.3647
19:44:23,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:52,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:22,94 root INFO Epoch 7 Global steps: 23200 Train loss: 0.2689
en_de Dev loss: 0.9007 r:0.1795
en_zh Dev loss: 0.7568 r:0.4620
Current avg r:0.3207 Best avg r: 0.3647
19:46:50,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:19,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:49,575 root INFO Epoch 7 Global steps: 23400 Train loss: 0.2916
en_de Dev loss: 0.9144 r:0.1643
en_zh Dev loss: 0.7840 r:0.4575
Current avg r:0.3109 Best avg r: 0.3647
19:49:18,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:47,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:17,158 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2582
en_de Dev loss: 0.8864 r:0.1730
en_zh Dev loss: 0.7790 r:0.4596
Current avg r:0.3163 Best avg r: 0.3647
19:51:45,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:14,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:44,511 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2669
en_de Dev loss: 0.8970 r:0.1638
en_zh Dev loss: 0.7658 r:0.4739
Current avg r:0.3189 Best avg r: 0.3647
19:54:13,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:42,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:11,997 root INFO Epoch 7 Global steps: 24000 Train loss: 0.2686
en_de Dev loss: 0.9098 r:0.1827
en_zh Dev loss: 0.7683 r:0.4756
Current avg r:0.3291 Best avg r: 0.3647
19:56:40,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:09,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:39,534 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2336
en_de Dev loss: 0.9184 r:0.1798
en_zh Dev loss: 0.7910 r:0.4750
Current avg r:0.3274 Best avg r: 0.3647
19:59:08,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:37,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:06,811 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2382
en_de Dev loss: 0.9052 r:0.1805
en_zh Dev loss: 0.7710 r:0.4685
Current avg r:0.3245 Best avg r: 0.3647
20:01:35,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:04,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:34,90 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2568
en_de Dev loss: 0.9260 r:0.1792
en_zh Dev loss: 0.7935 r:0.4621
Current avg r:0.3206 Best avg r: 0.3647
20:04:02,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:31,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:01,299 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2385
en_de Dev loss: 0.9425 r:0.1723
en_zh Dev loss: 0.7711 r:0.4719
Current avg r:0.3221 Best avg r: 0.3647
20:06:29,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:59,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:28,812 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2579
en_de Dev loss: 0.9116 r:0.1869
en_zh Dev loss: 0.7825 r:0.4673
Current avg r:0.3271 Best avg r: 0.3647
20:08:57,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:26,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:56,301 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2342
en_de Dev loss: 0.9180 r:0.1624
en_zh Dev loss: 0.7754 r:0.4690
Current avg r:0.3157 Best avg r: 0.3647
20:11:24,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:53,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:23,628 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2376
en_de Dev loss: 0.9143 r:0.1658
en_zh Dev loss: 0.7478 r:0.4712
Current avg r:0.3185 Best avg r: 0.3647
20:13:52,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:21,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:50,906 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2314
en_de Dev loss: 0.9214 r:0.1707
en_zh Dev loss: 0.8020 r:0.4615
Current avg r:0.3161 Best avg r: 0.3647
20:16:19,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:48,555 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:18,297 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2658
en_de Dev loss: 0.9249 r:0.1674
en_zh Dev loss: 0.7559 r:0.4758
Current avg r:0.3216 Best avg r: 0.3647
20:18:46,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:15,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:45,697 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2433
en_de Dev loss: 0.9044 r:0.1470
en_zh Dev loss: 0.7984 r:0.4567
Current avg r:0.3018 Best avg r: 0.3647
20:21:14,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:43,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:13,10 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2521
en_de Dev loss: 0.9142 r:0.1501
en_zh Dev loss: 0.8089 r:0.4472
Current avg r:0.2986 Best avg r: 0.3647
20:23:41,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:10,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:40,601 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2459
en_de Dev loss: 0.9019 r:0.1697
en_zh Dev loss: 0.8120 r:0.4562
Current avg r:0.3129 Best avg r: 0.3647
20:26:09,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:26:38,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:08,212 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2418
en_de Dev loss: 0.8979 r:0.1672
en_zh Dev loss: 0.7830 r:0.4555
Current avg r:0.3114 Best avg r: 0.3647
20:28:36,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:05,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:35,564 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2290
en_de Dev loss: 0.9047 r:0.1688
en_zh Dev loss: 0.8052 r:0.4656
Current avg r:0.3172 Best avg r: 0.3647
20:31:04,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:33,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:03,63 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2381
en_de Dev loss: 0.9179 r:0.1679
en_zh Dev loss: 0.8642 r:0.4578
Current avg r:0.3128 Best avg r: 0.3647
20:33:31,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:01,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:34:30,819 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2219
en_de Dev loss: 0.9496 r:0.1636
en_zh Dev loss: 0.9416 r:0.4586
Current avg r:0.3111 Best avg r: 0.3647
20:35:59,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:28,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:58,423 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2036
en_de Dev loss: 0.9305 r:0.1504
en_zh Dev loss: 0.8795 r:0.4505
Current avg r:0.3004 Best avg r: 0.3647
20:38:26,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:56,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:25,970 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2098
en_de Dev loss: 0.9099 r:0.1690
en_zh Dev loss: 0.7955 r:0.4662
Current avg r:0.3176 Best avg r: 0.3647
20:40:54,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:23,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:53,546 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2137
en_de Dev loss: 0.9125 r:0.1698
en_zh Dev loss: 0.8121 r:0.4747
Current avg r:0.3222 Best avg r: 0.3647
20:43:22,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:51,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:20,919 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2172
en_de Dev loss: 0.9307 r:0.1821
en_zh Dev loss: 0.7623 r:0.4764
Current avg r:0.3292 Best avg r: 0.3647
20:45:49,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:18,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:48,471 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2343
en_de Dev loss: 0.9062 r:0.1818
en_zh Dev loss: 0.7948 r:0.4669
Current avg r:0.3244 Best avg r: 0.3647
20:48:16,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:46,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:16,121 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2223
en_de Dev loss: 0.8860 r:0.1847
en_zh Dev loss: 0.7771 r:0.4616
Current avg r:0.3231 Best avg r: 0.3647
20:50:44,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:13,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:43,565 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2089
en_de Dev loss: 0.9198 r:0.1660
en_zh Dev loss: 0.8886 r:0.4421
Current avg r:0.3040 Best avg r: 0.3647
20:53:12,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:41,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:11,143 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2215
en_de Dev loss: 0.9363 r:0.1538
en_zh Dev loss: 0.8558 r:0.4519
Current avg r:0.3028 Best avg r: 0.3647
20:55:39,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:08,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:38,369 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2199
en_de Dev loss: 0.9156 r:0.1736
en_zh Dev loss: 0.7589 r:0.4703
Current avg r:0.3219 Best avg r: 0.3647
20:58:06,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:36,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:05,734 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2175
en_de Dev loss: 0.9100 r:0.1653
en_zh Dev loss: 0.8285 r:0.4517
Current avg r:0.3085 Best avg r: 0.3647
21:00:34,219 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:03,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:32,739 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2216
en_de Dev loss: 0.9226 r:0.1678
en_zh Dev loss: 0.8311 r:0.4585
Current avg r:0.3131 Best avg r: 0.3647
21:03:01,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:30,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:00,122 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2196
en_de Dev loss: 0.9666 r:0.1398
en_zh Dev loss: 0.9598 r:0.4451
Current avg r:0.2925 Best avg r: 0.3647
21:05:28,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:57,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:27,375 root INFO Epoch 9 Global steps: 29800 Train loss: 0.2128
en_de Dev loss: 0.9306 r:0.1602
en_zh Dev loss: 0.8203 r:0.4704
Current avg r:0.3153 Best avg r: 0.3647
21:07:55,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:25,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:54,690 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2025
en_de Dev loss: 0.9251 r:0.1755
en_zh Dev loss: 0.7789 r:0.4701
Current avg r:0.3228 Best avg r: 0.3647
21:10:23,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:52,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:22,397 root INFO Epoch 10 Global steps: 30200 Train loss: 0.1753
en_de Dev loss: 0.9274 r:0.1735
en_zh Dev loss: 0.8168 r:0.4664
Current avg r:0.3200 Best avg r: 0.3647
21:12:50,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:19,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:49,664 root INFO Epoch 10 Global steps: 30400 Train loss: 0.2009
en_de Dev loss: 0.9550 r:0.1678
en_zh Dev loss: 0.8484 r:0.4625
Current avg r:0.3152 Best avg r: 0.3647
21:15:18,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:47,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:17,212 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2160
en_de Dev loss: 0.9343 r:0.1678
en_zh Dev loss: 0.8124 r:0.4687
Current avg r:0.3183 Best avg r: 0.3647
21:17:45,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:14,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:44,156 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1888
en_de Dev loss: 0.9516 r:0.1541
en_zh Dev loss: 0.8543 r:0.4577
Current avg r:0.3059 Best avg r: 0.3647
21:20:12,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:41,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:11,487 root INFO Epoch 10 Global steps: 31000 Train loss: 0.1961
en_de Dev loss: 0.9063 r:0.1514
en_zh Dev loss: 0.7783 r:0.4589
Current avg r:0.3052 Best avg r: 0.3647
21:22:39,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:09,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:38,924 root INFO Epoch 10 Global steps: 31200 Train loss: 0.2038
en_de Dev loss: 0.9489 r:0.1825
en_zh Dev loss: 0.7751 r:0.4650
Current avg r:0.3237 Best avg r: 0.3647
21:25:07,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:36,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:06,118 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1819
en_de Dev loss: 0.9384 r:0.1594
en_zh Dev loss: 0.7767 r:0.4616
Current avg r:0.3105 Best avg r: 0.3647
21:27:34,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:03,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:28:33,566 root INFO Epoch 10 Global steps: 31600 Train loss: 0.1855
en_de Dev loss: 0.9511 r:0.1361
en_zh Dev loss: 0.9187 r:0.4487
Current avg r:0.2924 Best avg r: 0.3647
21:30:01,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:31,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:00,374 root INFO Epoch 10 Global steps: 31800 Train loss: 0.2010
en_de Dev loss: 0.9964 r:0.1420
en_zh Dev loss: 0.9331 r:0.4506
Current avg r:0.2963 Best avg r: 0.3647
21:32:28,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:57,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:27,281 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1840
en_de Dev loss: 0.9430 r:0.1231
en_zh Dev loss: 0.8953 r:0.4455
Current avg r:0.2843 Best avg r: 0.3647
21:34:55,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:24,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:54,277 root INFO Epoch 10 Global steps: 32200 Train loss: 0.1864
en_de Dev loss: 0.9454 r:0.1426
en_zh Dev loss: 0.8575 r:0.4581
Current avg r:0.3003 Best avg r: 0.3647
21:37:22,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:51,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:21,144 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1957
en_de Dev loss: 0.9378 r:0.1579
en_zh Dev loss: 0.8223 r:0.4661
Current avg r:0.3120 Best avg r: 0.3647
21:39:49,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:18,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:48,84 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1880
en_de Dev loss: 0.9832 r:0.1549
en_zh Dev loss: 0.9351 r:0.4543
Current avg r:0.3046 Best avg r: 0.3647
21:42:16,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:45,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:15,242 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1845
en_de Dev loss: 0.9425 r:0.1495
en_zh Dev loss: 0.8035 r:0.4582
Current avg r:0.3039 Best avg r: 0.3647
21:44:43,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:12,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:42,0 root INFO Epoch 10 Global steps: 33000 Train loss: 0.2009
en_de Dev loss: 0.9360 r:0.1723
en_zh Dev loss: 0.8147 r:0.4595
Current avg r:0.3159 Best avg r: 0.3647
21:47:10,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:39,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:09,194 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1893
en_de Dev loss: 0.9363 r:0.1408
en_zh Dev loss: 0.8196 r:0.4534
Current avg r:0.2971 Best avg r: 0.3647
21:49:37,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:06,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:50:36,92 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1567
en_de Dev loss: 0.9500 r:0.1566
en_zh Dev loss: 0.8471 r:0.4618
Current avg r:0.3092 Best avg r: 0.3647
21:52:04,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:33,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:02,858 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1603
en_de Dev loss: 0.9516 r:0.1741
en_zh Dev loss: 0.8032 r:0.4713
Current avg r:0.3227 Best avg r: 0.3647
21:54:31,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:00,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:55:29,775 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1718
en_de Dev loss: 0.9477 r:0.1493
en_zh Dev loss: 0.8167 r:0.4693
Current avg r:0.3093 Best avg r: 0.3647
21:56:58,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:27,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:57:56,711 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1745
en_de Dev loss: 0.9210 r:0.1585
en_zh Dev loss: 0.7947 r:0.4690
Current avg r:0.3138 Best avg r: 0.3647
21:59:25,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:54,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:23,671 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1796
en_de Dev loss: 0.9350 r:0.1594
en_zh Dev loss: 0.7941 r:0.4729
Current avg r:0.3162 Best avg r: 0.3647
22:01:52,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:21,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:50,788 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1696
en_de Dev loss: 0.9197 r:0.1762
en_zh Dev loss: 0.7536 r:0.4715
Current avg r:0.3238 Best avg r: 0.3647
22:04:19,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:48,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:17,831 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1758
en_de Dev loss: 0.9548 r:0.1648
en_zh Dev loss: 0.8022 r:0.4741
Current avg r:0.3195 Best avg r: 0.3647
22:06:46,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:07:15,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:44,925 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1786
en_de Dev loss: 0.9335 r:0.1736
en_zh Dev loss: 0.8297 r:0.4725
Current avg r:0.3230 Best avg r: 0.3647
22:09:13,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:42,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:11,723 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1830
en_de Dev loss: 0.9096 r:0.1678
en_zh Dev loss: 0.7792 r:0.4632
Current avg r:0.3155 Best avg r: 0.3647
22:11:40,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:09,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:38,707 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1714
en_de Dev loss: 0.9246 r:0.1718
en_zh Dev loss: 0.8212 r:0.4608
Current avg r:0.3163 Best avg r: 0.3647
22:14:07,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:36,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:05,908 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1738
en_de Dev loss: 0.9130 r:0.1932
en_zh Dev loss: 0.7481 r:0.4712
Current avg r:0.3322 Best avg r: 0.3647
22:16:34,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:03,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:32,845 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1599
en_de Dev loss: 0.9331 r:0.1640
en_zh Dev loss: 0.8201 r:0.4623
Current avg r:0.3131 Best avg r: 0.3647
22:19:01,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:30,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:59,825 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1698
en_de Dev loss: 0.9867 r:0.1556
en_zh Dev loss: 0.8904 r:0.4598
Current avg r:0.3077 Best avg r: 0.3647
22:21:28,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:57,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:26,742 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1739
en_de Dev loss: 0.9197 r:0.1690
en_zh Dev loss: 0.8140 r:0.4643
Current avg r:0.3166 Best avg r: 0.3647
22:23:55,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:24,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:54,174 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1683
en_de Dev loss: 0.9516 r:0.1591
en_zh Dev loss: 0.8965 r:0.4540
Current avg r:0.3065 Best avg r: 0.3647
22:26:22,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:26:51,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:21,6 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1630
en_de Dev loss: 0.9304 r:0.1923
en_zh Dev loss: 0.7845 r:0.4711
Current avg r:0.3317 Best avg r: 0.3647
22:28:49,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:18,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:48,46 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1537
en_de Dev loss: 0.9388 r:0.1900
en_zh Dev loss: 0.7711 r:0.4738
Current avg r:0.3319 Best avg r: 0.3647
22:31:16,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:45,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:14,880 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1476
en_de Dev loss: 0.9351 r:0.1857
en_zh Dev loss: 0.7963 r:0.4729
Current avg r:0.3293 Best avg r: 0.3647
22:33:43,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:12,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:41,893 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1651
en_de Dev loss: 0.9729 r:0.1849
en_zh Dev loss: 0.8177 r:0.4669
Current avg r:0.3259 Best avg r: 0.3647
22:36:10,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:39,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:08,989 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1349
en_de Dev loss: 0.9642 r:0.1683
en_zh Dev loss: 0.8599 r:0.4618
Current avg r:0.3150 Best avg r: 0.3647
22:38:37,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:39:06,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:35,981 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1536
en_de Dev loss: 0.9417 r:0.1614
en_zh Dev loss: 0.7998 r:0.4613
Current avg r:0.3113 Best avg r: 0.3647
22:41:04,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:33,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:02,742 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1502
en_de Dev loss: 0.9670 r:0.1571
en_zh Dev loss: 0.8556 r:0.4553
Current avg r:0.3062 Best avg r: 0.3647
22:43:31,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:00,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:29,525 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1667
en_de Dev loss: 0.9262 r:0.1616
en_zh Dev loss: 0.8130 r:0.4677
Current avg r:0.3147 Best avg r: 0.3647
22:45:58,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:26,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:56,350 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1571
en_de Dev loss: 0.9516 r:0.1582
en_zh Dev loss: 0.8781 r:0.4734
Current avg r:0.3158 Best avg r: 0.3647
22:48:24,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:53,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:23,117 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1669
en_de Dev loss: 0.9584 r:0.1337
en_zh Dev loss: 0.8448 r:0.4634
Current avg r:0.2985 Best avg r: 0.3647
22:50:51,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:20,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:49,900 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1630
en_de Dev loss: 1.0009 r:0.1539
en_zh Dev loss: 0.9112 r:0.4584
Current avg r:0.3062 Best avg r: 0.3647
22:53:18,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:47,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:16,878 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1461
en_de Dev loss: 0.9351 r:0.1530
en_zh Dev loss: 0.7934 r:0.4697
Current avg r:0.3114 Best avg r: 0.3647
22:55:45,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:14,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:43,535 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1463
en_de Dev loss: 0.9597 r:0.1736
en_zh Dev loss: 0.8356 r:0.4646
Current avg r:0.3191 Best avg r: 0.3647
22:58:11,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:41,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:10,512 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1633
en_de Dev loss: 0.9281 r:0.1703
en_zh Dev loss: 0.7960 r:0.4697
Current avg r:0.3200 Best avg r: 0.3647
23:00:39,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:08,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:37,657 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1468
en_de Dev loss: 0.9400 r:0.1604
en_zh Dev loss: 0.8102 r:0.4632
Current avg r:0.3118 Best avg r: 0.3647
23:03:06,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:35,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:04,763 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1401
en_de Dev loss: 0.9525 r:0.1694
en_zh Dev loss: 0.8518 r:0.4607
Current avg r:0.3151 Best avg r: 0.3647
23:05:33,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:02,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:31,489 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1395
en_de Dev loss: 0.9565 r:0.1590
en_zh Dev loss: 0.7784 r:0.4687
Current avg r:0.3138 Best avg r: 0.3647
23:07:59,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:28,934 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:58,282 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1382
en_de Dev loss: 0.9753 r:0.1373
en_zh Dev loss: 0.8616 r:0.4582
Current avg r:0.2977 Best avg r: 0.3647
23:10:26,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:55,688 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:25,68 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1346
en_de Dev loss: 0.9572 r:0.1477
en_zh Dev loss: 0.8647 r:0.4611
Current avg r:0.3044 Best avg r: 0.3647
23:12:53,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:22,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:52,108 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1354
en_de Dev loss: 0.9477 r:0.1605
en_zh Dev loss: 0.7677 r:0.4736
Current avg r:0.3171 Best avg r: 0.3647
23:15:20,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:49,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:18,909 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1346
en_de Dev loss: 0.9440 r:0.1562
en_zh Dev loss: 0.7841 r:0.4722
Current avg r:0.3142 Best avg r: 0.3647
23:17:47,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:16,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:45,966 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1333
en_de Dev loss: 0.9672 r:0.1415
en_zh Dev loss: 0.8001 r:0.4710
Current avg r:0.3063 Best avg r: 0.3647
23:20:14,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:43,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:21:13,160 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1400
en_de Dev loss: 0.9583 r:0.1555
en_zh Dev loss: 0.7985 r:0.4729
Current avg r:0.3142 Best avg r: 0.3647
23:22:41,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:23:10,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:40,336 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1435
en_de Dev loss: 0.9905 r:0.1685
en_zh Dev loss: 0.8123 r:0.4711
Current avg r:0.3198 Best avg r: 0.3647
23:25:08,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:37,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:07,332 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1501
en_de Dev loss: 0.9732 r:0.1868
en_zh Dev loss: 0.7799 r:0.4748
Current avg r:0.3308 Best avg r: 0.3647
23:27:35,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:04,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:28:34,708 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1379
en_de Dev loss: 0.9734 r:0.1340
en_zh Dev loss: 0.8154 r:0.4649
Current avg r:0.2994 Best avg r: 0.3647
23:30:03,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:32,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:01,713 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1271
en_de Dev loss: 0.9536 r:0.1683
en_zh Dev loss: 0.7787 r:0.4715
Current avg r:0.3199 Best avg r: 0.3647
23:32:30,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:59,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:29,91 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1311
en_de Dev loss: 0.9619 r:0.1486
en_zh Dev loss: 0.8133 r:0.4616
Current avg r:0.3051 Best avg r: 0.3647
23:34:57,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:26,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:56,308 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1333
en_de Dev loss: 0.9452 r:0.1390
en_zh Dev loss: 0.7765 r:0.4580
Current avg r:0.2985 Best avg r: 0.3647
23:37:25,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:54,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:23,588 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1181
en_de Dev loss: 0.9438 r:0.1580
en_zh Dev loss: 0.7791 r:0.4659
Current avg r:0.3119 Best avg r: 0.3647
23:39:52,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:21,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:50,877 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1229
en_de Dev loss: 0.9838 r:0.1687
en_zh Dev loss: 0.8461 r:0.4689
Current avg r:0.3188 Best avg r: 0.3647
23:42:19,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:48,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:18,167 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1390
en_de Dev loss: 0.9968 r:0.1726
en_zh Dev loss: 0.8747 r:0.4694
Current avg r:0.3210 Best avg r: 0.3647
23:44:46,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:15,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:45,650 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1354
en_de Dev loss: 0.9636 r:0.1592
en_zh Dev loss: 0.8349 r:0.4647
Current avg r:0.3119 Best avg r: 0.3647
23:47:14,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:43,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:12,878 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1297
en_de Dev loss: 0.9638 r:0.1697
en_zh Dev loss: 0.8148 r:0.4699
Current avg r:0.3198 Best avg r: 0.3647
23:49:41,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:10,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:40,172 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1286
en_de Dev loss: 0.9870 r:0.1563
en_zh Dev loss: 0.8592 r:0.4703
Current avg r:0.3133 Best avg r: 0.3647
23:52:08,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:37,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:07,511 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1240
en_de Dev loss: 0.9571 r:0.1539
en_zh Dev loss: 0.7621 r:0.4797
Current avg r:0.3168 Best avg r: 0.3647
23:54:36,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:05,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:34,602 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1255
en_de Dev loss: 0.9722 r:0.1464
en_zh Dev loss: 0.8217 r:0.4720
Current avg r:0.3092 Best avg r: 0.3647
23:57:03,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:32,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:01,936 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1241
en_de Dev loss: 0.9650 r:0.1308
en_zh Dev loss: 0.8181 r:0.4748
Current avg r:0.3028 Best avg r: 0.3647
23:59:30,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:59,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:29,469 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1291
en_de Dev loss: 0.9661 r:0.1512
en_zh Dev loss: 0.8153 r:0.4711
Current avg r:0.3111 Best avg r: 0.3647
00:01:57,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:27,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:02:56,833 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1211
en_de Dev loss: 0.9578 r:0.1735
en_zh Dev loss: 0.8055 r:0.4714
Current avg r:0.3225 Best avg r: 0.3647
00:04:25,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:54,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:24,169 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1313
en_de Dev loss: 0.9909 r:0.1549
en_zh Dev loss: 0.8279 r:0.4648
Current avg r:0.3098 Best avg r: 0.3647
00:06:52,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:21,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:51,733 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1190
en_de Dev loss: 0.9537 r:0.1663
en_zh Dev loss: 0.7801 r:0.4709
Current avg r:0.3186 Best avg r: 0.3647
00:09:20,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:49,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:19,190 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1296
en_de Dev loss: 0.9723 r:0.1711
en_zh Dev loss: 0.8021 r:0.4733
Current avg r:0.3222 Best avg r: 0.3647
00:11:47,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:12:16,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:46,482 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1227
en_de Dev loss: 0.9552 r:0.1632
en_zh Dev loss: 0.7961 r:0.4742
Current avg r:0.3187 Best avg r: 0.3647
00:14:15,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:44,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:14,287 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1206
en_de Dev loss: 0.9336 r:0.1785
en_zh Dev loss: 0.7013 r:0.4925
Current avg r:0.3355 Best avg r: 0.3647
00:16:42,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:11,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:17:41,711 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1107
en_de Dev loss: 0.9469 r:0.1501
en_zh Dev loss: 0.7687 r:0.4846
Current avg r:0.3174 Best avg r: 0.3647
00:19:10,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:39,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:09,149 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1073
en_de Dev loss: 0.9776 r:0.1549
en_zh Dev loss: 0.8632 r:0.4756
Current avg r:0.3152 Best avg r: 0.3647
00:21:37,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:06,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:36,622 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1182
en_de Dev loss: 0.9871 r:0.1592
en_zh Dev loss: 0.8061 r:0.4868
Current avg r:0.3230 Best avg r: 0.3647
00:24:05,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:34,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:04,100 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1174
en_de Dev loss: 0.9644 r:0.1447
en_zh Dev loss: 0.8343 r:0.4825
Current avg r:0.3136 Best avg r: 0.3647
00:26:32,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:27:01,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:31,608 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1190
en_de Dev loss: 0.9960 r:0.1573
en_zh Dev loss: 0.8200 r:0.4887
Current avg r:0.3230 Best avg r: 0.3647
00:29:00,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:29,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:59,76 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1154
en_de Dev loss: 0.9618 r:0.1661
en_zh Dev loss: 0.7861 r:0.4869
Current avg r:0.3265 Best avg r: 0.3647
00:31:27,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:56,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:26,189 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1192
en_de Dev loss: 0.9415 r:0.1748
en_zh Dev loss: 0.7613 r:0.4813
Current avg r:0.3280 Best avg r: 0.3647
00:33:54,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:23,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:53,623 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1229
en_de Dev loss: 0.9838 r:0.1485
en_zh Dev loss: 0.8087 r:0.4835
Current avg r:0.3160 Best avg r: 0.3647
00:36:22,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:51,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:21,146 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1118
en_de Dev loss: 0.9793 r:0.1712
en_zh Dev loss: 0.8500 r:0.4848
Current avg r:0.3280 Best avg r: 0.3647
00:38:49,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:39:18,852 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:48,588 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1210
en_de Dev loss: 0.9601 r:0.1651
en_zh Dev loss: 0.8233 r:0.4761
Current avg r:0.3206 Best avg r: 0.3647
00:41:17,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:46,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:16,210 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1207
en_de Dev loss: 0.9893 r:0.1624
en_zh Dev loss: 0.8523 r:0.4843
Current avg r:0.3233 Best avg r: 0.3647
00:43:44,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:14,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:43,783 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1199
en_de Dev loss: 1.0118 r:0.1676
en_zh Dev loss: 0.8631 r:0.4799
Current avg r:0.3238 Best avg r: 0.3647
00:46:12,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:41,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:11,260 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1198
en_de Dev loss: 1.0172 r:0.1655
en_zh Dev loss: 0.9048 r:0.4768
Current avg r:0.3212 Best avg r: 0.3647
00:48:39,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:08,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:38,552 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1159
en_de Dev loss: 0.9581 r:0.1543
en_zh Dev loss: 0.7605 r:0.4814
Current avg r:0.3178 Best avg r: 0.3647
00:51:07,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:36,665 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:06,192 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1119
en_de Dev loss: 0.9763 r:0.1587
en_zh Dev loss: 0.8365 r:0.4720
Current avg r:0.3154 Best avg r: 0.3647
00:53:34,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:54:04,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:33,832 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1263
en_de Dev loss: 1.0076 r:0.1481
en_zh Dev loss: 0.8369 r:0.4748
Current avg r:0.3114 Best avg r: 0.3647
00:56:02,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:31,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:01,359 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1151
en_de Dev loss: 0.9814 r:0.1319
en_zh Dev loss: 0.8083 r:0.4767
Current avg r:0.3043 Best avg r: 0.3647
00:58:29,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:59,247 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:29,63 root INFO Epoch 16 Global steps: 48800 Train loss: 0.1185
en_de Dev loss: 0.9615 r:0.1593
en_zh Dev loss: 0.7951 r:0.4787
Current avg r:0.3190 Best avg r: 0.3647
01:00:57,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:01:26,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:56,592 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1064
en_de Dev loss: 1.0040 r:0.1603
en_zh Dev loss: 0.8706 r:0.4761
Current avg r:0.3182 Best avg r: 0.3647
01:03:25,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:54,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:24,64 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1154
en_de Dev loss: 0.9625 r:0.1478
en_zh Dev loss: 0.8253 r:0.4802
Current avg r:0.3140 Best avg r: 0.3647
01:05:52,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:21,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:51,586 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1107
en_de Dev loss: 0.9735 r:0.1673
en_zh Dev loss: 0.8176 r:0.4758
Current avg r:0.3215 Best avg r: 0.3647
01:08:20,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:49,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:09:18,696 root INFO Epoch 16 Global steps: 49600 Train loss: 0.0958
en_de Dev loss: 0.9903 r:0.1759
en_zh Dev loss: 0.8727 r:0.4742
Current avg r:0.3250 Best avg r: 0.3647
01:10:47,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:16,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:46,138 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1094
en_de Dev loss: 0.9342 r:0.1708
en_zh Dev loss: 0.7444 r:0.4813
Current avg r:0.3261 Best avg r: 0.3647
01:13:14,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:43,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:13,735 root INFO Epoch 16 Global steps: 50000 Train loss: 0.1081
en_de Dev loss: 0.9964 r:0.1719
en_zh Dev loss: 0.7729 r:0.4830
Current avg r:0.3274 Best avg r: 0.3647
01:15:42,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:11,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:40,814 root INFO Epoch 16 Global steps: 50200 Train loss: 0.1035
en_de Dev loss: 0.9746 r:0.1742
en_zh Dev loss: 0.7836 r:0.4863
Current avg r:0.3302 Best avg r: 0.3647
01:18:09,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:18:38,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:08,485 root INFO Epoch 16 Global steps: 50400 Train loss: 0.1083
en_de Dev loss: 0.9777 r:0.1762
en_zh Dev loss: 0.7975 r:0.4837
Current avg r:0.3299 Best avg r: 0.3647
01:20:36,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:06,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:21:35,925 root INFO Epoch 16 Global steps: 50600 Train loss: 0.1114
en_de Dev loss: 0.9700 r:0.1690
en_zh Dev loss: 0.7696 r:0.4894
Current avg r:0.3292 Best avg r: 0.3647
01:23:04,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:33,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:03,291 root INFO Epoch 16 Global steps: 50800 Train loss: 0.1008
en_de Dev loss: 0.9782 r:0.1456
en_zh Dev loss: 0.7942 r:0.4865
Current avg r:0.3160 Best avg r: 0.3647
01:25:31,810 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:26:01,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:30,755 root INFO Epoch 16 Global steps: 51000 Train loss: 0.1012
en_de Dev loss: 0.9598 r:0.1513
en_zh Dev loss: 0.7982 r:0.4809
Current avg r:0.3161 Best avg r: 0.3647
01:27:59,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:28,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:58,475 root INFO Epoch 17 Global steps: 51200 Train loss: 0.1050
en_de Dev loss: 0.9826 r:0.1463
en_zh Dev loss: 0.8035 r:0.4765
Current avg r:0.3114 Best avg r: 0.3647
01:30:26,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:56,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:31:25,740 root INFO Epoch 17 Global steps: 51400 Train loss: 0.0929
en_de Dev loss: 1.0357 r:0.1529
en_zh Dev loss: 0.8941 r:0.4768
Current avg r:0.3148 Best avg r: 0.3647
01:32:54,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:33:23,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:33:53,316 root INFO Epoch 17 Global steps: 51600 Train loss: 0.0981
en_de Dev loss: 0.9661 r:0.1694
en_zh Dev loss: 0.7724 r:0.4868
Current avg r:0.3281 Best avg r: 0.3647
01:35:21,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:50,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:20,946 root INFO Epoch 17 Global steps: 51800 Train loss: 0.0916
en_de Dev loss: 0.9986 r:0.1383
en_zh Dev loss: 0.8169 r:0.4822
Current avg r:0.3102 Best avg r: 0.3647
00:34:53,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:19,738 root INFO 
id:en_de cur r: 0.0172 best r: 0.0172
00:35:45,477 root INFO 
id:en_zh cur r: 0.0819 best r: 0.0819
00:35:45,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:11,222 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
00:36:11,229 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
00:36:37,6 root INFO Epoch 0 Global steps: 200 Train loss: 0.8448
en_de Dev loss: 0.8906 r:0.0159
en_zh Dev loss: 0.8205 r:0.1446
Current avg r:0.0803 Best avg r: 0.0803
00:37:54,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:38:19,952 root INFO 
id:en_de cur r: 0.0278 best r: 0.0278
00:38:45,682 root INFO 
id:en_zh cur r: 0.1371 best r: 0.1371
00:38:45,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:11,452 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
00:39:11,458 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
00:39:37,224 root INFO Epoch 0 Global steps: 400 Train loss: 0.7635
en_de Dev loss: 0.8890 r:0.0412
en_zh Dev loss: 0.8168 r:0.2058
Current avg r:0.1235 Best avg r: 0.1235
00:40:54,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:20,236 root INFO 
id:en_de cur r: 0.0343 best r: 0.0343
00:41:45,996 root INFO 
id:en_zh cur r: 0.1524 best r: 0.1524
00:41:45,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:11,730 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
00:42:11,756 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
00:42:37,562 root INFO Epoch 0 Global steps: 600 Train loss: 0.8331
en_de Dev loss: 0.8887 r:0.0482
en_zh Dev loss: 0.8158 r:0.2640
Current avg r:0.1561 Best avg r: 0.1561
00:43:54,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:33,426 root INFO 
id:en_zh cur r: 0.1862 best r: 0.1862
00:44:33,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:59,182 root INFO Epoch 0 Global steps: 800 Train loss: 0.8163
en_de Dev loss: 0.8871 r:0.0495
en_zh Dev loss: 0.8104 r:0.2160
Current avg r:0.1327 Best avg r: 0.1561
00:46:15,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:41,630 root INFO 
id:en_de cur r: 0.0763 best r: 0.0763
00:47:07,319 root INFO 
id:en_zh cur r: 0.2142 best r: 0.2142
00:47:07,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:33,59 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
00:47:33,65 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
00:47:58,810 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8122
en_de Dev loss: 0.8876 r:0.0999
en_zh Dev loss: 0.8095 r:0.3072
Current avg r:0.2036 Best avg r: 0.2036
00:49:15,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:53,946 root INFO 
id:en_zh cur r: 0.2645 best r: 0.2645
00:49:53,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:19,692 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7224
en_de Dev loss: 0.8856 r:0.0672
en_zh Dev loss: 0.8054 r:0.3181
Current avg r:0.1926 Best avg r: 0.2036
00:51:36,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:15,136 root INFO 
id:en_zh cur r: 0.2790 best r: 0.2790
00:52:15,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:40,818 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7124
en_de Dev loss: 0.8841 r:0.0660
en_zh Dev loss: 0.8006 r:0.3211
Current avg r:0.1935 Best avg r: 0.2036
00:53:57,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:54:23,485 root INFO 
id:en_de cur r: 0.1215 best r: 0.1215
00:54:49,353 root INFO 
id:en_zh cur r: 0.2886 best r: 0.2886
00:54:49,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:15,123 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
00:55:15,129 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
00:55:40,887 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7612
en_de Dev loss: 0.8834 r:0.1104
en_zh Dev loss: 0.7903 r:0.3427
Current avg r:0.2266 Best avg r: 0.2266
00:56:57,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:23,421 root INFO 
id:en_de cur r: 0.1734 best r: 0.1734
00:57:49,127 root INFO 
id:en_zh cur r: 0.3286 best r: 0.3286
00:57:49,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:14,870 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
00:58:14,878 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
00:58:40,621 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7238
en_de Dev loss: 0.8740 r:0.1402
en_zh Dev loss: 0.7726 r:0.3484
Current avg r:0.2443 Best avg r: 0.2443
00:59:57,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:22,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:00:48,698 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
01:00:48,704 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
01:01:14,463 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7397
en_de Dev loss: 0.8676 r:0.1654
en_zh Dev loss: 0.7628 r:0.3499
Current avg r:0.2577 Best avg r: 0.2577
01:02:31,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:02:56,972 root INFO 
id:en_de cur r: 0.1864 best r: 0.1864
01:03:22,707 root INFO 
id:en_zh cur r: 0.3410 best r: 0.3410
01:03:22,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:48,449 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
01:03:48,455 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
01:04:14,232 root INFO Epoch 0 Global steps: 2200 Train loss: 0.6645
en_de Dev loss: 0.8665 r:0.2105
en_zh Dev loss: 0.7591 r:0.3657
Current avg r:0.2881 Best avg r: 0.2881
01:05:31,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:57,355 root INFO 
id:en_de cur r: 0.2236 best r: 0.2236
01:06:10,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:36,2 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7150
en_de Dev loss: 0.8836 r:0.1914
en_zh Dev loss: 0.7949 r:0.3607
Current avg r:0.2760 Best avg r: 0.2881
01:07:52,980 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:31,674 root INFO 
id:en_zh cur r: 0.3773 best r: 0.3773
01:08:31,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:57,391 root INFO Epoch 0 Global steps: 2600 Train loss: 0.6925
en_de Dev loss: 0.8662 r:0.1650
en_zh Dev loss: 0.7092 r:0.3787
Current avg r:0.2718 Best avg r: 0.2881
01:10:13,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:39,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:05,454 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6886
en_de Dev loss: 0.8626 r:0.2014
en_zh Dev loss: 0.7229 r:0.3721
Current avg r:0.2868 Best avg r: 0.2881
01:12:21,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:00,625 root INFO 
id:en_zh cur r: 0.3920 best r: 0.3920
01:13:00,626 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:13:26,396 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6920
en_de Dev loss: 0.8710 r:0.1846
en_zh Dev loss: 0.7390 r:0.3857
Current avg r:0.2852 Best avg r: 0.2881
01:14:43,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:22,292 root INFO 
id:en_zh cur r: 0.4023 best r: 0.4023
01:15:22,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:48,116 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
01:15:48,122 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
01:16:13,924 root INFO Epoch 1 Global steps: 3200 Train loss: 0.7184
en_de Dev loss: 0.8651 r:0.1892
en_zh Dev loss: 0.7296 r:0.4041
Current avg r:0.2967 Best avg r: 0.2967
01:17:30,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:56,511 root INFO 
id:en_de cur r: 0.2332 best r: 0.2332
01:18:22,252 root INFO 
id:en_zh cur r: 0.4055 best r: 0.4055
01:18:22,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:48,29 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
01:18:48,35 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
01:19:13,881 root INFO Epoch 1 Global steps: 3400 Train loss: 0.6837
en_de Dev loss: 0.8480 r:0.2237
en_zh Dev loss: 0.7034 r:0.4085
Current avg r:0.3161 Best avg r: 0.3161
09:54:18,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:54:57,446 root INFO 
id:en_zh cur r: 0.1372 best r: 0.1372
09:54:57,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:55:23,197 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
09:55:23,203 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
09:55:48,975 root INFO Epoch 0 Global steps: 200 Train loss: 0.7919
en_de Dev loss: 0.8960 r:0.0362
en_zh Dev loss: 0.8221 r:0.1327
Current avg r:0.0844 Best avg r: 0.0844
09:57:05,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:43,650 root INFO 
id:en_zh cur r: 0.1924 best r: 0.1924
09:57:43,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:09,386 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
09:58:09,410 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
09:58:35,194 root INFO Epoch 0 Global steps: 400 Train loss: 0.7425
en_de Dev loss: 0.8859 r:0.0801
en_zh Dev loss: 0.8153 r:0.1913
Current avg r:0.1357 Best avg r: 0.1357
09:59:51,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:00:17,94 root INFO 
id:en_de cur r: 0.0007 best r: 0.0007
10:00:42,837 root INFO 
id:en_zh cur r: 0.2515 best r: 0.2515
10:00:42,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:01:08,639 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:01:08,652 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:01:34,427 root INFO Epoch 0 Global steps: 600 Train loss: 0.7912
en_de Dev loss: 0.8831 r:0.0938
en_zh Dev loss: 0.8043 r:0.2643
Current avg r:0.1790 Best avg r: 0.1790
10:02:50,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:03:16,513 root INFO 
id:en_de cur r: 0.0689 best r: 0.0689
10:03:42,257 root INFO 
id:en_zh cur r: 0.2901 best r: 0.2901
10:03:42,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:04:07,974 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:04:07,979 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:04:33,827 root INFO Epoch 0 Global steps: 800 Train loss: 0.8137
en_de Dev loss: 0.8815 r:0.0998
en_zh Dev loss: 0.7891 r:0.2961
Current avg r:0.1980 Best avg r: 0.1980
10:05:49,891 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:06:28,565 root INFO 
id:en_zh cur r: 0.2971 best r: 0.2971
10:06:28,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:54,401 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:06:54,407 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:07:20,220 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7146
en_de Dev loss: 0.8890 r:0.0955
en_zh Dev loss: 0.8018 r:0.3172
Current avg r:0.2064 Best avg r: 0.2064
10:08:36,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:09:02,356 root INFO 
id:en_de cur r: 0.0736 best r: 0.0736
10:09:28,120 root INFO 
id:en_zh cur r: 0.3073 best r: 0.3073
10:09:28,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:53,878 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7739
en_de Dev loss: 0.8790 r:0.1016
en_zh Dev loss: 0.7680 r:0.3043
Current avg r:0.2029 Best avg r: 0.2064
10:11:10,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:35,999 root INFO 
id:en_de cur r: 0.1369 best r: 0.1369
10:11:48,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:14,702 root INFO Epoch 0 Global steps: 1400 Train loss: 0.6756
en_de Dev loss: 0.9095 r:0.1341
en_zh Dev loss: 0.8357 r:0.1946
Current avg r:0.1644 Best avg r: 0.2064
10:13:31,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:56,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:22,522 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7121
en_de Dev loss: 0.8823 r:0.1528
en_zh Dev loss: 0.8162 r:0.2205
Current avg r:0.1867 Best avg r: 0.2064
10:15:38,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:04,643 root INFO 
id:en_de cur r: 0.1715 best r: 0.1715
10:16:30,394 root INFO 
id:en_zh cur r: 0.3285 best r: 0.3285
10:16:30,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:16:56,157 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:16:56,194 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:17:22,70 root INFO Epoch 0 Global steps: 1800 Train loss: 0.6911
en_de Dev loss: 0.8679 r:0.1760
en_zh Dev loss: 0.7527 r:0.3539
Current avg r:0.2649 Best avg r: 0.2649
10:18:38,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:17,119 root INFO 
id:en_zh cur r: 0.3694 best r: 0.3694
10:19:17,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:42,960 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7041
en_de Dev loss: 0.8780 r:0.1459
en_zh Dev loss: 0.7148 r:0.3606
Current avg r:0.2533 Best avg r: 0.2649
10:20:59,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:37,803 root INFO 
id:en_zh cur r: 0.3918 best r: 0.3918
10:21:37,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:03,595 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:22:03,603 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:22:29,396 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7597
en_de Dev loss: 0.8662 r:0.1655
en_zh Dev loss: 0.7224 r:0.3956
Current avg r:0.2805 Best avg r: 0.2805
10:23:45,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:24,412 root INFO 
id:en_zh cur r: 0.4007 best r: 0.4007
10:24:24,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:24:50,252 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7490
en_de Dev loss: 0.8696 r:0.1723
en_zh Dev loss: 0.7651 r:0.3849
Current avg r:0.2786 Best avg r: 0.2805
10:26:06,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:26:32,372 root INFO 
id:en_de cur r: 0.1955 best r: 0.1955
10:26:58,134 root INFO 
id:en_zh cur r: 0.4186 best r: 0.4186
10:26:58,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:23,903 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:27:23,910 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:27:49,701 root INFO Epoch 0 Global steps: 2600 Train loss: 0.6675
en_de Dev loss: 0.8590 r:0.1918
en_zh Dev loss: 0.7125 r:0.4063
Current avg r:0.2990 Best avg r: 0.2990
10:29:06,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:31,859 root INFO 
id:en_de cur r: 0.1977 best r: 0.1977
10:29:44,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:10,530 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:30:10,535 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:30:36,482 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7252
en_de Dev loss: 0.8824 r:0.2012
en_zh Dev loss: 0.7720 r:0.4012
Current avg r:0.3012 Best avg r: 0.3012
10:31:52,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:32:18,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:32:44,292 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:32:44,314 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:33:10,140 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6325
en_de Dev loss: 0.8548 r:0.2248
en_zh Dev loss: 0.7573 r:0.3976
Current avg r:0.3112 Best avg r: 0.3112
10:34:26,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:35:05,424 root INFO 
id:en_zh cur r: 0.4294 best r: 0.4294
10:35:05,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:35:31,285 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:35:31,296 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:35:57,97 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6095
en_de Dev loss: 0.8670 r:0.2020
en_zh Dev loss: 0.7374 r:0.4247
Current avg r:0.3134 Best avg r: 0.3134
10:37:13,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:37:52,89 root INFO 
id:en_zh cur r: 0.4332 best r: 0.4332
10:37:52,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:38:17,836 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:38:17,842 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:38:43,627 root INFO Epoch 1 Global steps: 3400 Train loss: 0.7118
en_de Dev loss: 0.8552 r:0.2034
en_zh Dev loss: 0.7124 r:0.4241
Current avg r:0.3138 Best avg r: 0.3138
10:39:59,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:40:25,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:40:51,481 root INFO Epoch 1 Global steps: 3600 Train loss: 0.6704
en_de Dev loss: 0.8667 r:0.2143
en_zh Dev loss: 0.7365 r:0.4065
Current avg r:0.3104 Best avg r: 0.3138
10:42:07,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:42:33,677 root INFO 
id:en_de cur r: 0.2192 best r: 0.2192
10:42:46,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:43:12,275 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:43:12,282 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:43:38,94 root INFO Epoch 1 Global steps: 3800 Train loss: 0.7115
en_de Dev loss: 0.8844 r:0.2376
en_zh Dev loss: 0.8171 r:0.3981
Current avg r:0.3178 Best avg r: 0.3178
10:44:54,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:45:33,75 root INFO 
id:en_zh cur r: 0.4333 best r: 0.4333
10:45:33,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:45:58,848 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:45:58,854 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:46:24,647 root INFO Epoch 1 Global steps: 4000 Train loss: 0.7046
en_de Dev loss: 0.8672 r:0.2360
en_zh Dev loss: 0.7534 r:0.4243
Current avg r:0.3301 Best avg r: 0.3301
10:47:41,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:48:06,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:48:32,522 root INFO Epoch 1 Global steps: 4200 Train loss: 0.5641
en_de Dev loss: 0.8473 r:0.2372
en_zh Dev loss: 0.7126 r:0.4225
Current avg r:0.3298 Best avg r: 0.3301
10:49:48,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:50:14,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:50:40,357 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:50:40,372 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:51:06,184 root INFO Epoch 1 Global steps: 4400 Train loss: 0.5865
en_de Dev loss: 0.8499 r:0.2479
en_zh Dev loss: 0.7351 r:0.4175
Current avg r:0.3327 Best avg r: 0.3327
10:52:22,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:52:48,312 root INFO 
id:en_de cur r: 0.2253 best r: 0.2253
10:53:01,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:53:26,925 root INFO Epoch 1 Global steps: 4600 Train loss: 0.5417
en_de Dev loss: 0.8687 r:0.2149
en_zh Dev loss: 0.7579 r:0.4205
Current avg r:0.3177 Best avg r: 0.3327
10:54:43,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:55:09,36 root INFO 
id:en_de cur r: 0.2257 best r: 0.2257
10:55:21,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:55:47,636 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:55:47,641 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:56:13,429 root INFO Epoch 1 Global steps: 4800 Train loss: 0.6679
en_de Dev loss: 0.8461 r:0.2414
en_zh Dev loss: 0.7355 r:0.4286
Current avg r:0.3350 Best avg r: 0.3350
10:57:29,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:58:08,316 root INFO 
id:en_zh cur r: 0.4507 best r: 0.4507
10:58:08,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:58:34,89 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
10:58:34,95 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
10:58:59,959 root INFO Epoch 1 Global steps: 5000 Train loss: 0.7680
en_de Dev loss: 0.8413 r:0.2344
en_zh Dev loss: 0.6677 r:0.4482
Current avg r:0.3413 Best avg r: 0.3413
11:00:16,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:00:42,77 root INFO 
id:en_de cur r: 0.2323 best r: 0.2323
11:00:54,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:01:20,691 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
11:01:20,726 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
11:01:46,499 root INFO Epoch 1 Global steps: 5200 Train loss: 0.6878
en_de Dev loss: 0.8542 r:0.2536
en_zh Dev loss: 0.7457 r:0.4380
Current avg r:0.3458 Best avg r: 0.3458
11:03:02,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:03:41,441 root INFO 
id:en_zh cur r: 0.4538 best r: 0.4538
11:03:41,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:04:07,186 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
11:04:07,194 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
11:04:32,980 root INFO Epoch 1 Global steps: 5400 Train loss: 0.5636
en_de Dev loss: 0.8514 r:0.2576
en_zh Dev loss: 0.7503 r:0.4540
Current avg r:0.3558 Best avg r: 0.3558
11:05:49,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:06:27,955 root INFO 
id:en_zh cur r: 0.4630 best r: 0.4630
11:06:27,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:06:53,711 root INFO Epoch 1 Global steps: 5600 Train loss: 0.6384
en_de Dev loss: 0.8459 r:0.2457
en_zh Dev loss: 0.6896 r:0.4617
Current avg r:0.3537 Best avg r: 0.3558
11:08:10,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:08:48,679 root INFO 
id:en_zh cur r: 0.4776 best r: 0.4776
11:08:48,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:09:14,440 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6526
en_de Dev loss: 0.8668 r:0.2206
en_zh Dev loss: 0.7131 r:0.4762
Current avg r:0.3484 Best avg r: 0.3558
11:10:30,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:11:09,419 root INFO 
id:en_zh cur r: 0.4824 best r: 0.4824
11:11:09,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:11:35,183 root INFO Epoch 1 Global steps: 6000 Train loss: 0.5856
en_de Dev loss: 0.8540 r:0.2233
en_zh Dev loss: 0.7037 r:0.4792
Current avg r:0.3512 Best avg r: 0.3558
11:12:51,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:13:17,740 root INFO 
id:en_de cur r: 0.2425 best r: 0.2425
11:13:30,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:13:56,365 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
11:13:56,394 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
11:14:22,166 root INFO Epoch 2 Global steps: 6200 Train loss: 0.5747
en_de Dev loss: 0.8343 r:0.2514
en_zh Dev loss: 0.7102 r:0.4767
Current avg r:0.3640 Best avg r: 0.3640
11:15:38,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:16:04,296 root INFO 
id:en_de cur r: 0.2572 best r: 0.2572
11:16:17,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:16:42,943 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
11:16:42,964 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
11:17:08,786 root INFO Epoch 2 Global steps: 6400 Train loss: 0.6426
en_de Dev loss: 0.8216 r:0.2753
en_zh Dev loss: 0.6811 r:0.4620
Current avg r:0.3686 Best avg r: 0.3686
11:18:25,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:18:50,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:19:16,641 root INFO Epoch 2 Global steps: 6600 Train loss: 0.6239
en_de Dev loss: 0.8518 r:0.2668
en_zh Dev loss: 0.7770 r:0.4517
Current avg r:0.3593 Best avg r: 0.3686
11:20:32,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:20:58,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:21:24,460 root INFO Epoch 2 Global steps: 6800 Train loss: 0.5785
en_de Dev loss: 0.8319 r:0.2516
en_zh Dev loss: 0.6643 r:0.4762
Current avg r:0.3639 Best avg r: 0.3686
11:22:40,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:23:06,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:23:32,335 root INFO Epoch 2 Global steps: 7000 Train loss: 0.6118
en_de Dev loss: 0.8342 r:0.2487
en_zh Dev loss: 0.6758 r:0.4643
Current avg r:0.3565 Best avg r: 0.3686
11:24:48,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:25:14,471 root INFO 
id:en_de cur r: 0.2699 best r: 0.2699
11:25:27,342 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:25:53,103 root INFO Epoch 2 Global steps: 7200 Train loss: 0.5475
en_de Dev loss: 0.8586 r:0.2651
en_zh Dev loss: 0.7905 r:0.4690
Current avg r:0.3671 Best avg r: 0.3686
11:27:09,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:27:35,280 root INFO 
id:en_de cur r: 0.2714 best r: 0.2714
11:27:48,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:28:13,971 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
11:28:13,977 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
11:28:39,808 root INFO Epoch 2 Global steps: 7400 Train loss: 0.4785
en_de Dev loss: 0.8506 r:0.2802
en_zh Dev loss: 0.7219 r:0.4672
Current avg r:0.3737 Best avg r: 0.3737
11:29:56,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:30:21,952 root INFO 
id:en_de cur r: 0.2748 best r: 0.2748
11:30:34,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:31:00,553 root INFO Epoch 2 Global steps: 7600 Train loss: 0.5583
en_de Dev loss: 0.8325 r:0.2697
en_zh Dev loss: 0.6715 r:0.4735
Current avg r:0.3716 Best avg r: 0.3737
11:32:16,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:32:42,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:33:08,365 root INFO Epoch 2 Global steps: 7800 Train loss: 0.5207
en_de Dev loss: 0.8442 r:0.2641
en_zh Dev loss: 0.7153 r:0.4676
Current avg r:0.3659 Best avg r: 0.3737
11:34:24,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:34:50,500 root INFO 
id:en_de cur r: 0.2760 best r: 0.2760
11:35:03,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:35:29,115 root INFO Epoch 2 Global steps: 8000 Train loss: 0.6506
en_de Dev loss: 0.8421 r:0.2673
en_zh Dev loss: 0.7552 r:0.4601
Current avg r:0.3637 Best avg r: 0.3737
11:36:45,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:37:11,232 root INFO 
id:en_de cur r: 0.2860 best r: 0.2860
11:37:24,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:37:49,859 root INFO Epoch 2 Global steps: 8200 Train loss: 0.5154
en_de Dev loss: 0.8348 r:0.2717
en_zh Dev loss: 0.7274 r:0.4688
Current avg r:0.3702 Best avg r: 0.3737
11:39:06,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:39:31,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:39:57,668 root INFO Epoch 2 Global steps: 8400 Train loss: 0.6108
en_de Dev loss: 0.8404 r:0.2556
en_zh Dev loss: 0.7240 r:0.4767
Current avg r:0.3661 Best avg r: 0.3737
11:41:13,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:41:39,804 root INFO 
id:en_de cur r: 0.2867 best r: 0.2867
11:41:52,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:42:18,444 root INFO Epoch 2 Global steps: 8600 Train loss: 0.5866
en_de Dev loss: 0.8236 r:0.2770
en_zh Dev loss: 0.7044 r:0.4567
Current avg r:0.3668 Best avg r: 0.3737
11:43:34,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:44:00,568 root INFO 
id:en_de cur r: 0.2944 best r: 0.2944
11:44:13,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:44:39,195 root INFO Epoch 2 Global steps: 8800 Train loss: 0.4682
en_de Dev loss: 0.8415 r:0.2849
en_zh Dev loss: 0.7184 r:0.4553
Current avg r:0.3701 Best avg r: 0.3737
11:45:55,510 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:46:21,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:46:47,46 root INFO Epoch 2 Global steps: 9000 Train loss: 0.7009
en_de Dev loss: 0.8714 r:0.2740
en_zh Dev loss: 0.7813 r:0.4534
Current avg r:0.3637 Best avg r: 0.3737
11:48:03,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:48:29,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:48:55,269 root INFO Epoch 3 Global steps: 9200 Train loss: 0.5098
en_de Dev loss: 0.8278 r:0.2713
en_zh Dev loss: 0.6665 r:0.4757
Current avg r:0.3735 Best avg r: 0.3737
11:50:11,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:50:37,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:51:02,999 root INFO Epoch 3 Global steps: 9400 Train loss: 0.4553
en_de Dev loss: 0.8470 r:0.2765
en_zh Dev loss: 0.7596 r:0.4361
Current avg r:0.3563 Best avg r: 0.3737
11:52:19,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:52:45,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:53:10,861 root INFO Epoch 3 Global steps: 9600 Train loss: 0.5198
en_de Dev loss: 0.8470 r:0.2380
en_zh Dev loss: 0.7025 r:0.4660
Current avg r:0.3520 Best avg r: 0.3737
11:54:27,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:54:52,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:55:18,615 root INFO Epoch 3 Global steps: 9800 Train loss: 0.4874
en_de Dev loss: 0.8536 r:0.2562
en_zh Dev loss: 0.7582 r:0.4499
Current avg r:0.3530 Best avg r: 0.3737
11:56:34,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:57:00,640 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:57:26,387 root INFO Epoch 3 Global steps: 10000 Train loss: 0.5198
en_de Dev loss: 0.8425 r:0.2401
en_zh Dev loss: 0.7062 r:0.4448
Current avg r:0.3424 Best avg r: 0.3737
11:58:42,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:59:08,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:59:34,134 root INFO Epoch 3 Global steps: 10200 Train loss: 0.5739
en_de Dev loss: 0.8560 r:0.2200
en_zh Dev loss: 0.7075 r:0.4677
Current avg r:0.3438 Best avg r: 0.3737
12:00:50,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:01:15,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:01:41,651 root INFO Epoch 3 Global steps: 10400 Train loss: 0.5235
en_de Dev loss: 0.8659 r:0.2314
en_zh Dev loss: 0.7541 r:0.4550
Current avg r:0.3432 Best avg r: 0.3737
12:02:57,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:03:23,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:03:48,995 root INFO Epoch 3 Global steps: 10600 Train loss: 0.5363
en_de Dev loss: 0.8460 r:0.2428
en_zh Dev loss: 0.7223 r:0.4550
Current avg r:0.3489 Best avg r: 0.3737
12:05:04,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:05:30,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:05:56,235 root INFO Epoch 3 Global steps: 10800 Train loss: 0.4666
en_de Dev loss: 0.8313 r:0.2546
en_zh Dev loss: 0.6995 r:0.4570
Current avg r:0.3558 Best avg r: 0.3737
12:07:12,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:07:37,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:08:03,451 root INFO Epoch 3 Global steps: 11000 Train loss: 0.4887
en_de Dev loss: 0.8459 r:0.2626
en_zh Dev loss: 0.7418 r:0.4499
Current avg r:0.3563 Best avg r: 0.3737
12:09:19,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:09:45,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:10:10,714 root INFO Epoch 3 Global steps: 11200 Train loss: 0.4996
en_de Dev loss: 0.8477 r:0.2671
en_zh Dev loss: 0.7824 r:0.4404
Current avg r:0.3537 Best avg r: 0.3737
12:11:26,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:11:52,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:12:17,979 root INFO Epoch 3 Global steps: 11400 Train loss: 0.4816
en_de Dev loss: 0.8331 r:0.2661
en_zh Dev loss: 0.7106 r:0.4473
Current avg r:0.3567 Best avg r: 0.3737
12:13:33,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:13:59,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:14:25,263 root INFO Epoch 3 Global steps: 11600 Train loss: 0.5313
en_de Dev loss: 0.8722 r:0.2470
en_zh Dev loss: 0.7895 r:0.4456
Current avg r:0.3463 Best avg r: 0.3737
12:15:41,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:16:06,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:16:32,507 root INFO Epoch 3 Global steps: 11800 Train loss: 0.5044
en_de Dev loss: 0.8676 r:0.2546
en_zh Dev loss: 0.7495 r:0.4437
Current avg r:0.3492 Best avg r: 0.3737
12:17:48,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:18:14,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:18:39,758 root INFO Epoch 3 Global steps: 12000 Train loss: 0.5392
en_de Dev loss: 0.8373 r:0.2530
en_zh Dev loss: 0.7116 r:0.4706
Current avg r:0.3618 Best avg r: 0.3737
12:19:56,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:20:21,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:20:47,475 root INFO Epoch 4 Global steps: 12200 Train loss: 0.4760
en_de Dev loss: 0.8537 r:0.2415
en_zh Dev loss: 0.7757 r:0.4432
Current avg r:0.3424 Best avg r: 0.3737
12:22:03,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:22:29,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:22:54,754 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4540
en_de Dev loss: 0.8386 r:0.2640
en_zh Dev loss: 0.7522 r:0.4401
Current avg r:0.3520 Best avg r: 0.3737
12:24:10,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:24:36,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:25:02,62 root INFO Epoch 4 Global steps: 12600 Train loss: 0.3809
en_de Dev loss: 0.8581 r:0.2594
en_zh Dev loss: 0.8102 r:0.4275
Current avg r:0.3435 Best avg r: 0.3737
12:26:18,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:26:43,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:27:09,675 root INFO Epoch 4 Global steps: 12800 Train loss: 0.3724
en_de Dev loss: 0.8519 r:0.2601
en_zh Dev loss: 0.7930 r:0.4324
Current avg r:0.3463 Best avg r: 0.3737
12:28:25,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:28:51,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:29:17,189 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4487
en_de Dev loss: 0.8371 r:0.2679
en_zh Dev loss: 0.7686 r:0.4393
Current avg r:0.3536 Best avg r: 0.3737
12:30:33,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:30:58,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:31:24,775 root INFO Epoch 4 Global steps: 13200 Train loss: 0.4425
en_de Dev loss: 0.8323 r:0.2668
en_zh Dev loss: 0.7651 r:0.4255
Current avg r:0.3461 Best avg r: 0.3737
12:32:40,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:33:06,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:33:32,339 root INFO Epoch 4 Global steps: 13400 Train loss: 0.4381
en_de Dev loss: 0.8488 r:0.2495
en_zh Dev loss: 0.7477 r:0.4448
Current avg r:0.3471 Best avg r: 0.3737
12:34:48,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:35:14,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:35:39,797 root INFO Epoch 4 Global steps: 13600 Train loss: 0.4039
en_de Dev loss: 0.8435 r:0.2457
en_zh Dev loss: 0.7323 r:0.4441
Current avg r:0.3449 Best avg r: 0.3737
12:36:55,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:37:21,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:37:47,114 root INFO Epoch 4 Global steps: 13800 Train loss: 0.4484
en_de Dev loss: 0.8550 r:0.2454
en_zh Dev loss: 0.7674 r:0.4341
Current avg r:0.3398 Best avg r: 0.3737
12:39:03,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:39:28,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:39:54,416 root INFO Epoch 4 Global steps: 14000 Train loss: 0.4081
en_de Dev loss: 0.8604 r:0.2205
en_zh Dev loss: 0.7367 r:0.4434
Current avg r:0.3320 Best avg r: 0.3737
12:41:10,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:41:35,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:42:01,671 root INFO Epoch 4 Global steps: 14200 Train loss: 0.4007
en_de Dev loss: 0.8520 r:0.2224
en_zh Dev loss: 0.7195 r:0.4546
Current avg r:0.3385 Best avg r: 0.3737
12:43:17,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:43:43,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:44:08,975 root INFO Epoch 4 Global steps: 14400 Train loss: 0.3637
en_de Dev loss: 0.8763 r:0.2071
en_zh Dev loss: 0.7502 r:0.4687
Current avg r:0.3379 Best avg r: 0.3737
12:45:24,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:45:50,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:46:16,242 root INFO Epoch 4 Global steps: 14600 Train loss: 0.3959
en_de Dev loss: 0.8568 r:0.2354
en_zh Dev loss: 0.7560 r:0.4628
Current avg r:0.3491 Best avg r: 0.3737
12:47:32,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:47:57,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:48:23,486 root INFO Epoch 4 Global steps: 14800 Train loss: 0.4587
en_de Dev loss: 0.8709 r:0.2362
en_zh Dev loss: 0.7886 r:0.4583
Current avg r:0.3472 Best avg r: 0.3737
12:49:39,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:50:05,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:50:30,801 root INFO Epoch 4 Global steps: 15000 Train loss: 0.4463
en_de Dev loss: 0.8498 r:0.2289
en_zh Dev loss: 0.7705 r:0.4288
Current avg r:0.3288 Best avg r: 0.3737
12:51:47,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:52:12,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:52:38,397 root INFO Epoch 5 Global steps: 15200 Train loss: 0.3506
en_de Dev loss: 0.8477 r:0.2405
en_zh Dev loss: 0.7638 r:0.4325
Current avg r:0.3365 Best avg r: 0.3737
12:53:54,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:54:19,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:54:45,716 root INFO Epoch 5 Global steps: 15400 Train loss: 0.3454
en_de Dev loss: 0.8619 r:0.2361
en_zh Dev loss: 0.7733 r:0.4459
Current avg r:0.3410 Best avg r: 0.3737
12:56:01,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:56:27,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:56:53,2 root INFO Epoch 5 Global steps: 15600 Train loss: 0.3776
en_de Dev loss: 0.8451 r:0.2456
en_zh Dev loss: 0.7748 r:0.4486
Current avg r:0.3471 Best avg r: 0.3737
12:58:08,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:58:34,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:59:00,226 root INFO Epoch 5 Global steps: 15800 Train loss: 0.3460
en_de Dev loss: 0.8530 r:0.2439
en_zh Dev loss: 0.8027 r:0.4415
Current avg r:0.3427 Best avg r: 0.3737
13:00:16,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:00:41,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:01:07,569 root INFO Epoch 5 Global steps: 16000 Train loss: 0.3220
en_de Dev loss: 0.8409 r:0.2527
en_zh Dev loss: 0.7693 r:0.4589
Current avg r:0.3558 Best avg r: 0.3737
13:02:23,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:02:49,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:03:14,838 root INFO Epoch 5 Global steps: 16200 Train loss: 0.3492
en_de Dev loss: 0.8438 r:0.2486
en_zh Dev loss: 0.7723 r:0.4409
Current avg r:0.3447 Best avg r: 0.3737
13:04:30,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:04:56,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:05:22,39 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3781
en_de Dev loss: 0.8480 r:0.2493
en_zh Dev loss: 0.7958 r:0.4487
Current avg r:0.3490 Best avg r: 0.3737
13:06:37,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:07:03,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:07:29,342 root INFO Epoch 5 Global steps: 16600 Train loss: 0.3945
en_de Dev loss: 0.8623 r:0.2389
en_zh Dev loss: 0.8146 r:0.4383
Current avg r:0.3386 Best avg r: 0.3737
13:08:45,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:09:10,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:09:36,601 root INFO Epoch 5 Global steps: 16800 Train loss: 0.3381
en_de Dev loss: 0.8702 r:0.2497
en_zh Dev loss: 0.8673 r:0.4173
Current avg r:0.3335 Best avg r: 0.3737
13:10:52,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:11:18,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:11:43,877 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3173
en_de Dev loss: 0.8518 r:0.2566
en_zh Dev loss: 0.7764 r:0.4387
Current avg r:0.3476 Best avg r: 0.3737
13:12:59,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:13:25,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:13:51,117 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3424
en_de Dev loss: 0.8391 r:0.2700
en_zh Dev loss: 0.7776 r:0.4287
Current avg r:0.3494 Best avg r: 0.3737
13:15:06,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:15:32,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:15:58,351 root INFO Epoch 5 Global steps: 17400 Train loss: 0.3252
en_de Dev loss: 0.8467 r:0.2460
en_zh Dev loss: 0.7647 r:0.4286
Current avg r:0.3373 Best avg r: 0.3737
13:17:14,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:17:39,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:18:05,659 root INFO Epoch 5 Global steps: 17600 Train loss: 0.3326
en_de Dev loss: 0.8547 r:0.2626
en_zh Dev loss: 0.8062 r:0.4301
Current avg r:0.3463 Best avg r: 0.3737
13:19:21,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:19:47,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:20:12,943 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3540
en_de Dev loss: 0.8524 r:0.2344
en_zh Dev loss: 0.7524 r:0.4409
Current avg r:0.3377 Best avg r: 0.3737
13:21:28,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:21:54,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:22:20,206 root INFO Epoch 5 Global steps: 18000 Train loss: 0.3485
en_de Dev loss: 0.8937 r:0.1876
en_zh Dev loss: 0.7447 r:0.4515
Current avg r:0.3196 Best avg r: 0.3737
13:23:36,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:24:02,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:24:27,932 root INFO Epoch 6 Global steps: 18200 Train loss: 0.3236
en_de Dev loss: 0.8670 r:0.2120
en_zh Dev loss: 0.7488 r:0.4488
Current avg r:0.3304 Best avg r: 0.3737
13:25:43,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:26:09,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:26:35,175 root INFO Epoch 6 Global steps: 18400 Train loss: 0.3142
en_de Dev loss: 0.8962 r:0.2000
en_zh Dev loss: 0.8303 r:0.4372
Current avg r:0.3186 Best avg r: 0.3737
13:27:51,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:28:16,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:28:42,460 root INFO Epoch 6 Global steps: 18600 Train loss: 0.2908
en_de Dev loss: 0.8761 r:0.2124
en_zh Dev loss: 0.7818 r:0.4332
Current avg r:0.3228 Best avg r: 0.3737
13:29:58,355 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:30:24,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:30:49,748 root INFO Epoch 6 Global steps: 18800 Train loss: 0.2990
en_de Dev loss: 0.8695 r:0.2126
en_zh Dev loss: 0.7842 r:0.4314
Current avg r:0.3220 Best avg r: 0.3737
13:32:05,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:32:31,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:32:57,1 root INFO Epoch 6 Global steps: 19000 Train loss: 0.2890
en_de Dev loss: 0.8619 r:0.2079
en_zh Dev loss: 0.7620 r:0.4330
Current avg r:0.3204 Best avg r: 0.3737
13:34:12,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:34:38,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:35:04,352 root INFO Epoch 6 Global steps: 19200 Train loss: 0.2610
en_de Dev loss: 0.8995 r:0.2118
en_zh Dev loss: 0.8495 r:0.4311
Current avg r:0.3214 Best avg r: 0.3737
13:36:20,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:36:45,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:37:11,653 root INFO Epoch 6 Global steps: 19400 Train loss: 0.2717
en_de Dev loss: 0.8705 r:0.2126
en_zh Dev loss: 0.7974 r:0.4345
Current avg r:0.3235 Best avg r: 0.3737
13:38:27,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:38:53,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:39:18,991 root INFO Epoch 6 Global steps: 19600 Train loss: 0.2919
en_de Dev loss: 0.8869 r:0.2026
en_zh Dev loss: 0.7813 r:0.4474
Current avg r:0.3250 Best avg r: 0.3737
13:40:34,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:41:00,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:41:26,354 root INFO Epoch 6 Global steps: 19800 Train loss: 0.2721
en_de Dev loss: 0.8937 r:0.1965
en_zh Dev loss: 0.7675 r:0.4441
Current avg r:0.3203 Best avg r: 0.3737
13:42:42,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:43:08,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:43:33,705 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3040
en_de Dev loss: 0.8811 r:0.2056
en_zh Dev loss: 0.7688 r:0.4433
Current avg r:0.3244 Best avg r: 0.3737
13:44:49,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:45:15,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:45:41,46 root INFO Epoch 6 Global steps: 20200 Train loss: 0.2897
en_de Dev loss: 0.8939 r:0.2092
en_zh Dev loss: 0.8324 r:0.4330
Current avg r:0.3211 Best avg r: 0.3737
13:46:56,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:47:22,727 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:47:48,437 root INFO Epoch 6 Global steps: 20400 Train loss: 0.2751
en_de Dev loss: 0.8708 r:0.2167
en_zh Dev loss: 0.8153 r:0.4344
Current avg r:0.3256 Best avg r: 0.3737
13:49:04,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:49:30,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:49:55,802 root INFO Epoch 6 Global steps: 20600 Train loss: 0.2939
en_de Dev loss: 0.8638 r:0.2236
en_zh Dev loss: 0.7701 r:0.4412
Current avg r:0.3324 Best avg r: 0.3737
13:51:11,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:51:37,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:52:03,152 root INFO Epoch 6 Global steps: 20800 Train loss: 0.2991
en_de Dev loss: 0.8815 r:0.2128
en_zh Dev loss: 0.7581 r:0.4554
Current avg r:0.3341 Best avg r: 0.3737
13:53:19,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:53:44,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:54:10,500 root INFO Epoch 6 Global steps: 21000 Train loss: 0.2499
en_de Dev loss: 0.8897 r:0.2138
en_zh Dev loss: 0.9082 r:0.4159
Current avg r:0.3149 Best avg r: 0.3737
13:55:26,810 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:55:52,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:56:18,197 root INFO Epoch 7 Global steps: 21200 Train loss: 0.2644
en_de Dev loss: 0.9116 r:0.2161
en_zh Dev loss: 0.9117 r:0.4236
Current avg r:0.3199 Best avg r: 0.3737
13:57:34,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:57:59,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:58:25,522 root INFO Epoch 7 Global steps: 21400 Train loss: 0.2406
en_de Dev loss: 0.8867 r:0.2191
en_zh Dev loss: 0.7882 r:0.4353
Current avg r:0.3272 Best avg r: 0.3737
13:59:41,434 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:00:07,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:00:32,805 root INFO Epoch 7 Global steps: 21600 Train loss: 0.2370
en_de Dev loss: 0.9094 r:0.2171
en_zh Dev loss: 0.8802 r:0.4136
Current avg r:0.3153 Best avg r: 0.3737
14:01:48,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:02:14,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:02:40,80 root INFO Epoch 7 Global steps: 21800 Train loss: 0.2420
en_de Dev loss: 0.8640 r:0.2257
en_zh Dev loss: 0.7746 r:0.4346
Current avg r:0.3302 Best avg r: 0.3737
14:03:56,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:04:21,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:04:47,497 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2570
en_de Dev loss: 0.8719 r:0.2257
en_zh Dev loss: 0.8377 r:0.4167
Current avg r:0.3212 Best avg r: 0.3737
14:06:03,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:06:29,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:06:54,884 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2742
en_de Dev loss: 0.8842 r:0.2445
en_zh Dev loss: 0.8693 r:0.4320
Current avg r:0.3382 Best avg r: 0.3737
14:08:10,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:08:36,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:09:02,226 root INFO Epoch 7 Global steps: 22400 Train loss: 0.2420
en_de Dev loss: 0.8646 r:0.2320
en_zh Dev loss: 0.7872 r:0.4333
Current avg r:0.3327 Best avg r: 0.3737
14:10:18,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:10:43,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:11:09,560 root INFO Epoch 7 Global steps: 22600 Train loss: 0.2256
en_de Dev loss: 0.8941 r:0.2110
en_zh Dev loss: 0.7336 r:0.4654
Current avg r:0.3382 Best avg r: 0.3737
14:12:25,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:12:51,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:13:16,886 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2708
en_de Dev loss: 0.8804 r:0.2263
en_zh Dev loss: 0.8282 r:0.4154
Current avg r:0.3208 Best avg r: 0.3737
14:14:32,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:14:58,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:15:24,312 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2458
en_de Dev loss: 0.8839 r:0.2307
en_zh Dev loss: 0.8257 r:0.4268
Current avg r:0.3288 Best avg r: 0.3737
14:16:40,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:17:05,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:17:31,683 root INFO Epoch 7 Global steps: 23200 Train loss: 0.2481
en_de Dev loss: 0.8530 r:0.2304
en_zh Dev loss: 0.7641 r:0.4210
Current avg r:0.3257 Best avg r: 0.3737
14:18:47,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:19:13,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:19:39,24 root INFO Epoch 7 Global steps: 23400 Train loss: 0.2610
en_de Dev loss: 0.8587 r:0.2225
en_zh Dev loss: 0.7640 r:0.4325
Current avg r:0.3275 Best avg r: 0.3737
14:20:55,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:21:20,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:21:46,441 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2293
en_de Dev loss: 0.8503 r:0.2188
en_zh Dev loss: 0.7501 r:0.4400
Current avg r:0.3294 Best avg r: 0.3737
14:23:02,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:23:28,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:23:53,849 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2519
en_de Dev loss: 0.8774 r:0.1971
en_zh Dev loss: 0.8265 r:0.4273
Current avg r:0.3122 Best avg r: 0.3737
14:25:09,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:25:35,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:26:01,225 root INFO Epoch 7 Global steps: 24000 Train loss: 0.2628
en_de Dev loss: 0.8698 r:0.2008
en_zh Dev loss: 0.8385 r:0.4172
Current avg r:0.3090 Best avg r: 0.3737
14:27:17,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:27:43,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:28:08,992 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2358
en_de Dev loss: 0.8492 r:0.2313
en_zh Dev loss: 0.7592 r:0.4296
Current avg r:0.3304 Best avg r: 0.3737
14:29:24,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:29:50,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:30:16,332 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2157
en_de Dev loss: 0.8672 r:0.2317
en_zh Dev loss: 0.8057 r:0.4305
Current avg r:0.3311 Best avg r: 0.3737
14:31:32,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:31:57,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:32:23,654 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2096
en_de Dev loss: 0.8787 r:0.2229
en_zh Dev loss: 0.7814 r:0.4505
Current avg r:0.3367 Best avg r: 0.3737
14:33:39,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:34:05,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:34:30,968 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2106
en_de Dev loss: 0.8836 r:0.2034
en_zh Dev loss: 0.8077 r:0.4366
Current avg r:0.3200 Best avg r: 0.3737
14:35:46,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:36:12,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:36:38,279 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2201
en_de Dev loss: 0.8849 r:0.2020
en_zh Dev loss: 0.8282 r:0.4150
Current avg r:0.3085 Best avg r: 0.3737
14:37:54,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:38:19,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:38:45,607 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2592
en_de Dev loss: 0.8689 r:0.2276
en_zh Dev loss: 0.8204 r:0.4309
Current avg r:0.3292 Best avg r: 0.3737
14:40:01,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:40:27,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:52,885 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2310
en_de Dev loss: 0.8739 r:0.2152
en_zh Dev loss: 0.7815 r:0.4409
Current avg r:0.3281 Best avg r: 0.3737
14:42:08,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:34,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:00,145 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2176
en_de Dev loss: 0.8946 r:0.1860
en_zh Dev loss: 0.8105 r:0.4353
Current avg r:0.3107 Best avg r: 0.3737
14:44:16,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:42,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:07,763 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2109
en_de Dev loss: 0.8847 r:0.1945
en_zh Dev loss: 0.8177 r:0.4131
Current avg r:0.3038 Best avg r: 0.3737
14:46:23,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:46:49,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:15,362 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2375
en_de Dev loss: 0.8935 r:0.2051
en_zh Dev loss: 0.8330 r:0.4246
Current avg r:0.3149 Best avg r: 0.3737
14:48:31,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:57,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:22,938 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2189
en_de Dev loss: 0.9007 r:0.2112
en_zh Dev loss: 0.8259 r:0.4311
Current avg r:0.3212 Best avg r: 0.3737
14:50:38,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:04,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:30,399 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2361
en_de Dev loss: 0.8986 r:0.2059
en_zh Dev loss: 0.8173 r:0.4374
Current avg r:0.3217 Best avg r: 0.3737
14:52:46,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:12,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:37,928 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2206
en_de Dev loss: 0.9056 r:0.1920
en_zh Dev loss: 0.8577 r:0.4269
Current avg r:0.3095 Best avg r: 0.3737
14:54:54,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:19,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:45,413 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2134
en_de Dev loss: 0.8973 r:0.2026
en_zh Dev loss: 0.8719 r:0.4129
Current avg r:0.3077 Best avg r: 0.3737
14:57:01,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:27,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:52,716 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2253
en_de Dev loss: 0.9061 r:0.1851
en_zh Dev loss: 0.8847 r:0.4081
Current avg r:0.2966 Best avg r: 0.3737
14:59:09,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:34,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:00,591 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2129
en_de Dev loss: 0.8864 r:0.2137
en_zh Dev loss: 0.8009 r:0.4388
Current avg r:0.3262 Best avg r: 0.3737
15:01:16,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:42,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:08,179 root INFO Epoch 9 Global steps: 27400 Train loss: 0.1898
en_de Dev loss: 0.9019 r:0.1908
en_zh Dev loss: 0.8731 r:0.4184
Current avg r:0.3046 Best avg r: 0.3737
15:03:24,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:49,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:15,678 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2042
en_de Dev loss: 0.8939 r:0.2245
en_zh Dev loss: 0.8233 r:0.4349
Current avg r:0.3297 Best avg r: 0.3737
15:05:31,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:57,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:23,313 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2323
en_de Dev loss: 0.9115 r:0.2353
en_zh Dev loss: 0.8357 r:0.4357
Current avg r:0.3355 Best avg r: 0.3737
15:07:39,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:05,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:30,945 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2044
en_de Dev loss: 0.8715 r:0.2430
en_zh Dev loss: 0.7956 r:0.4442
Current avg r:0.3436 Best avg r: 0.3737
15:09:47,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:12,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:38,545 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2102
en_de Dev loss: 0.8661 r:0.2231
en_zh Dev loss: 0.7802 r:0.4405
Current avg r:0.3318 Best avg r: 0.3737
15:11:54,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:20,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:46,195 root INFO Epoch 9 Global steps: 28400 Train loss: 0.1952
en_de Dev loss: 0.8836 r:0.2306
en_zh Dev loss: 0.8327 r:0.4345
Current avg r:0.3326 Best avg r: 0.3737
15:14:02,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:28,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:53,845 root INFO Epoch 9 Global steps: 28600 Train loss: 0.1966
en_de Dev loss: 0.9021 r:0.2084
en_zh Dev loss: 0.8676 r:0.4262
Current avg r:0.3173 Best avg r: 0.3737
15:16:10,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:35,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:01,561 root INFO Epoch 9 Global steps: 28800 Train loss: 0.1980
en_de Dev loss: 0.9164 r:0.2019
en_zh Dev loss: 0.8879 r:0.4297
Current avg r:0.3158 Best avg r: 0.3737
15:18:17,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:43,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:08,890 root INFO Epoch 9 Global steps: 29000 Train loss: 0.1897
en_de Dev loss: 0.9136 r:0.2200
en_zh Dev loss: 0.8545 r:0.4393
Current avg r:0.3296 Best avg r: 0.3737
15:20:24,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:50,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:16,185 root INFO Epoch 9 Global steps: 29200 Train loss: 0.1961
en_de Dev loss: 0.8881 r:0.2152
en_zh Dev loss: 0.8058 r:0.4378
Current avg r:0.3265 Best avg r: 0.3737
15:22:32,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:57,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:23,574 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2105
en_de Dev loss: 0.8805 r:0.2019
en_zh Dev loss: 0.7768 r:0.4330
Current avg r:0.3175 Best avg r: 0.3737
15:24:39,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:05,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:30,909 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2324
en_de Dev loss: 0.8623 r:0.2202
en_zh Dev loss: 0.7918 r:0.4289
Current avg r:0.3246 Best avg r: 0.3737
15:26:46,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:12,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:38,199 root INFO Epoch 9 Global steps: 29800 Train loss: 0.2054
en_de Dev loss: 0.8664 r:0.2135
en_zh Dev loss: 0.7588 r:0.4359
Current avg r:0.3247 Best avg r: 0.3737
15:28:54,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:19,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:45,606 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2030
en_de Dev loss: 0.8579 r:0.2116
en_zh Dev loss: 0.7678 r:0.4266
Current avg r:0.3191 Best avg r: 0.3737
15:31:01,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:27,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:53,316 root INFO Epoch 10 Global steps: 30200 Train loss: 0.2080
en_de Dev loss: 0.8982 r:0.2244
en_zh Dev loss: 0.8202 r:0.4443
Current avg r:0.3343 Best avg r: 0.3737
15:33:09,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:34,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:00,630 root INFO Epoch 10 Global steps: 30400 Train loss: 0.1713
en_de Dev loss: 0.8786 r:0.2375
en_zh Dev loss: 0.7987 r:0.4396
Current avg r:0.3385 Best avg r: 0.3737
15:35:16,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:42,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:07,991 root INFO Epoch 10 Global steps: 30600 Train loss: 0.1789
en_de Dev loss: 0.8754 r:0.2277
en_zh Dev loss: 0.7983 r:0.4286
Current avg r:0.3282 Best avg r: 0.3737
15:37:23,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:49,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:15,348 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1655
en_de Dev loss: 0.9164 r:0.2065
en_zh Dev loss: 0.8767 r:0.4311
Current avg r:0.3188 Best avg r: 0.3737
15:39:31,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:57,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:22,753 root INFO Epoch 10 Global steps: 31000 Train loss: 0.1777
en_de Dev loss: 0.8723 r:0.2081
en_zh Dev loss: 0.7854 r:0.4282
Current avg r:0.3182 Best avg r: 0.3737
15:41:38,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:04,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:30,150 root INFO Epoch 10 Global steps: 31200 Train loss: 0.1887
en_de Dev loss: 0.8852 r:0.1990
en_zh Dev loss: 0.7846 r:0.4526
Current avg r:0.3258 Best avg r: 0.3737
15:43:46,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:11,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:37,506 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1888
en_de Dev loss: 0.8976 r:0.1921
en_zh Dev loss: 0.8067 r:0.4317
Current avg r:0.3119 Best avg r: 0.3737
15:45:53,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:19,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:44,890 root INFO Epoch 10 Global steps: 31600 Train loss: 0.2018
en_de Dev loss: 0.8987 r:0.2014
en_zh Dev loss: 0.8136 r:0.4371
Current avg r:0.3192 Best avg r: 0.3737
15:48:00,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:26,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:52,204 root INFO Epoch 10 Global steps: 31800 Train loss: 0.1817
en_de Dev loss: 0.9148 r:0.2019
en_zh Dev loss: 0.8508 r:0.4276
Current avg r:0.3147 Best avg r: 0.3737
15:50:08,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:33,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:59,464 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1734
en_de Dev loss: 0.9110 r:0.1904
en_zh Dev loss: 0.8378 r:0.4304
Current avg r:0.3104 Best avg r: 0.3737
15:52:15,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:41,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:06,823 root INFO Epoch 10 Global steps: 32200 Train loss: 0.1788
en_de Dev loss: 0.9131 r:0.2002
en_zh Dev loss: 0.8040 r:0.4440
Current avg r:0.3221 Best avg r: 0.3737
15:54:22,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:48,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:14,133 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1908
en_de Dev loss: 0.8983 r:0.1970
en_zh Dev loss: 0.8271 r:0.4237
Current avg r:0.3103 Best avg r: 0.3737
15:56:30,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:55,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:21,435 root INFO Epoch 10 Global steps: 32600 Train loss: 0.2071
en_de Dev loss: 0.9206 r:0.1915
en_zh Dev loss: 0.8297 r:0.4449
Current avg r:0.3182 Best avg r: 0.3737
15:58:37,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:03,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:28,769 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1811
en_de Dev loss: 0.9057 r:0.1989
en_zh Dev loss: 0.8012 r:0.4526
Current avg r:0.3257 Best avg r: 0.3737
16:00:44,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:10,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:36,90 root INFO Epoch 10 Global steps: 33000 Train loss: 0.1898
en_de Dev loss: 0.9081 r:0.2132
en_zh Dev loss: 0.8105 r:0.4542
Current avg r:0.3337 Best avg r: 0.3737
16:02:52,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:18,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:44,129 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1523
en_de Dev loss: 0.9039 r:0.2049
en_zh Dev loss: 0.8128 r:0.4440
Current avg r:0.3244 Best avg r: 0.3737
16:05:00,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:26,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:51,791 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1652
en_de Dev loss: 0.9017 r:0.2047
en_zh Dev loss: 0.8236 r:0.4278
Current avg r:0.3162 Best avg r: 0.3737
16:07:07,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:33,586 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:59,278 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1966
en_de Dev loss: 0.9302 r:0.1977
en_zh Dev loss: 0.8502 r:0.4440
Current avg r:0.3208 Best avg r: 0.3737
16:09:15,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:41,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:06,709 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1793
en_de Dev loss: 0.8884 r:0.2086
en_zh Dev loss: 0.7897 r:0.4450
Current avg r:0.3268 Best avg r: 0.3737
16:11:22,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:48,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:14,43 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1580
en_de Dev loss: 0.9281 r:0.1989
en_zh Dev loss: 0.8469 r:0.4465
Current avg r:0.3227 Best avg r: 0.3737
16:13:29,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:55,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:21,420 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1694
en_de Dev loss: 0.9151 r:0.1992
en_zh Dev loss: 0.8171 r:0.4331
Current avg r:0.3161 Best avg r: 0.3737
16:15:37,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:03,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:28,803 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1618
en_de Dev loss: 0.9001 r:0.2027
en_zh Dev loss: 0.8003 r:0.4395
Current avg r:0.3211 Best avg r: 0.3737
16:17:44,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:10,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:36,149 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1613
en_de Dev loss: 0.8874 r:0.2064
en_zh Dev loss: 0.7826 r:0.4410
Current avg r:0.3237 Best avg r: 0.3737
16:19:52,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:17,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:43,569 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1643
en_de Dev loss: 0.8777 r:0.2223
en_zh Dev loss: 0.8017 r:0.4406
Current avg r:0.3315 Best avg r: 0.3737
16:21:59,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:25,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:50,952 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1690
en_de Dev loss: 0.8956 r:0.1863
en_zh Dev loss: 0.7706 r:0.4422
Current avg r:0.3142 Best avg r: 0.3737
16:24:06,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:32,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:24:58,286 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1621
en_de Dev loss: 0.9336 r:0.2069
en_zh Dev loss: 0.8108 r:0.4532
Current avg r:0.3301 Best avg r: 0.3737
16:26:14,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:39,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:05,666 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1722
en_de Dev loss: 0.9320 r:0.2010
en_zh Dev loss: 0.8107 r:0.4420
Current avg r:0.3215 Best avg r: 0.3737
16:28:21,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:47,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:13,48 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1486
en_de Dev loss: 0.9291 r:0.1934
en_zh Dev loss: 0.8292 r:0.4409
Current avg r:0.3172 Best avg r: 0.3737
16:30:28,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:54,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:20,400 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1625
en_de Dev loss: 0.9115 r:0.1940
en_zh Dev loss: 0.8127 r:0.4380
Current avg r:0.3160 Best avg r: 0.3737
16:32:36,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:02,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:27,828 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1746
en_de Dev loss: 0.9397 r:0.1968
en_zh Dev loss: 0.8481 r:0.4328
Current avg r:0.3148 Best avg r: 0.3737
16:34:44,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:09,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:35,637 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1566
en_de Dev loss: 0.9109 r:0.2031
en_zh Dev loss: 0.8134 r:0.4401
Current avg r:0.3216 Best avg r: 0.3737
16:36:51,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:17,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:43,16 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1589
en_de Dev loss: 0.9251 r:0.1893
en_zh Dev loss: 0.8138 r:0.4511
Current avg r:0.3202 Best avg r: 0.3737
16:38:58,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:24,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:50,395 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1466
en_de Dev loss: 0.8691 r:0.2203
en_zh Dev loss: 0.7528 r:0.4441
Current avg r:0.3322 Best avg r: 0.3737
16:41:06,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:32,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:57,712 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1526
en_de Dev loss: 0.8886 r:0.2080
en_zh Dev loss: 0.7729 r:0.4530
Current avg r:0.3305 Best avg r: 0.3737
16:43:13,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:39,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:05,67 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1485
en_de Dev loss: 0.9023 r:0.2021
en_zh Dev loss: 0.7712 r:0.4594
Current avg r:0.3307 Best avg r: 0.3737
16:45:20,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:46,711 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:12,403 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1641
en_de Dev loss: 0.9531 r:0.2067
en_zh Dev loss: 0.8175 r:0.4503
Current avg r:0.3285 Best avg r: 0.3737
16:47:28,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:54,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:19,734 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1474
en_de Dev loss: 0.9187 r:0.2003
en_zh Dev loss: 0.8223 r:0.4467
Current avg r:0.3235 Best avg r: 0.3737
16:49:35,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:01,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:27,48 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1459
en_de Dev loss: 0.9170 r:0.2123
en_zh Dev loss: 0.7998 r:0.4536
Current avg r:0.3329 Best avg r: 0.3737
16:51:42,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:08,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:34,329 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1481
en_de Dev loss: 0.8916 r:0.2199
en_zh Dev loss: 0.7913 r:0.4471
Current avg r:0.3335 Best avg r: 0.3737
16:53:50,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:15,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:41,655 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1589
en_de Dev loss: 0.9346 r:0.2049
en_zh Dev loss: 0.8037 r:0.4632
Current avg r:0.3341 Best avg r: 0.3737
16:55:57,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:23,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:49,20 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1557
en_de Dev loss: 0.9389 r:0.1986
en_zh Dev loss: 0.8271 r:0.4525
Current avg r:0.3255 Best avg r: 0.3737
16:58:04,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:30,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:56,326 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1542
en_de Dev loss: 0.9499 r:0.1915
en_zh Dev loss: 0.8278 r:0.4581
Current avg r:0.3248 Best avg r: 0.3737
17:00:12,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:37,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:03,648 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1449
en_de Dev loss: 0.9065 r:0.1866
en_zh Dev loss: 0.7818 r:0.4516
Current avg r:0.3191 Best avg r: 0.3737
17:02:19,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:45,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:10,951 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1407
en_de Dev loss: 0.9066 r:0.2006
en_zh Dev loss: 0.7906 r:0.4503
Current avg r:0.3255 Best avg r: 0.3737
17:04:26,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:52,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:18,244 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1385
en_de Dev loss: 0.9176 r:0.1830
en_zh Dev loss: 0.7689 r:0.4542
Current avg r:0.3186 Best avg r: 0.3737
17:06:34,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:00,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:26,24 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1414
en_de Dev loss: 0.9158 r:0.1876
en_zh Dev loss: 0.7670 r:0.4471
Current avg r:0.3173 Best avg r: 0.3737
17:08:41,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:07,640 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:33,338 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1323
en_de Dev loss: 0.9208 r:0.1918
en_zh Dev loss: 0.7601 r:0.4543
Current avg r:0.3231 Best avg r: 0.3737
17:10:49,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:14,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:40,642 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1468
en_de Dev loss: 0.9416 r:0.1960
en_zh Dev loss: 0.8272 r:0.4505
Current avg r:0.3232 Best avg r: 0.3737
17:12:56,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:22,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:47,978 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1328
en_de Dev loss: 0.9341 r:0.2029
en_zh Dev loss: 0.8315 r:0.4506
Current avg r:0.3267 Best avg r: 0.3737
17:15:03,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:29,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:55,319 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1349
en_de Dev loss: 0.9517 r:0.2090
en_zh Dev loss: 0.8401 r:0.4525
Current avg r:0.3308 Best avg r: 0.3737
17:17:11,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:36,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:02,671 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1266
en_de Dev loss: 0.9163 r:0.2089
en_zh Dev loss: 0.7704 r:0.4579
Current avg r:0.3334 Best avg r: 0.3737
17:19:18,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:44,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:10,39 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1478
en_de Dev loss: 0.9434 r:0.1874
en_zh Dev loss: 0.8373 r:0.4548
Current avg r:0.3211 Best avg r: 0.3737
17:21:25,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:51,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:17,343 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1374
en_de Dev loss: 0.9187 r:0.2072
en_zh Dev loss: 0.7713 r:0.4618
Current avg r:0.3345 Best avg r: 0.3737
17:23:33,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:59,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:24,715 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1381
en_de Dev loss: 0.9513 r:0.1926
en_zh Dev loss: 0.7971 r:0.4565
Current avg r:0.3246 Best avg r: 0.3737
17:25:40,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:06,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:32,64 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1352
en_de Dev loss: 0.9191 r:0.1944
en_zh Dev loss: 0.7788 r:0.4621
Current avg r:0.3282 Best avg r: 0.3737
17:27:47,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:13,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:39,374 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1288
en_de Dev loss: 0.9255 r:0.1948
en_zh Dev loss: 0.7927 r:0.4568
Current avg r:0.3258 Best avg r: 0.3737
17:29:55,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:21,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:46,738 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1383
en_de Dev loss: 0.9155 r:0.2055
en_zh Dev loss: 0.7977 r:0.4478
Current avg r:0.3266 Best avg r: 0.3737
17:32:02,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:28,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:54,58 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1275
en_de Dev loss: 0.9216 r:0.1857
en_zh Dev loss: 0.7665 r:0.4482
Current avg r:0.3169 Best avg r: 0.3737
17:34:09,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:35,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:01,450 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1290
en_de Dev loss: 0.9460 r:0.1954
en_zh Dev loss: 0.8035 r:0.4528
Current avg r:0.3241 Best avg r: 0.3737
17:36:17,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:43,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:08,817 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1307
en_de Dev loss: 0.9583 r:0.1821
en_zh Dev loss: 0.8356 r:0.4483
Current avg r:0.3152 Best avg r: 0.3737
17:38:25,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:50,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:16,460 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1151
en_de Dev loss: 0.9321 r:0.1786
en_zh Dev loss: 0.8104 r:0.4491
Current avg r:0.3138 Best avg r: 0.3737
17:40:32,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:58,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:23,853 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1249
en_de Dev loss: 0.9199 r:0.1994
en_zh Dev loss: 0.7823 r:0.4589
Current avg r:0.3291 Best avg r: 0.3737
17:42:39,797 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:05,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:31,235 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1273
en_de Dev loss: 0.9132 r:0.1876
en_zh Dev loss: 0.7708 r:0.4546
Current avg r:0.3211 Best avg r: 0.3737
17:44:47,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:12,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:38,624 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1204
en_de Dev loss: 0.9076 r:0.2023
en_zh Dev loss: 0.8038 r:0.4506
Current avg r:0.3265 Best avg r: 0.3737
17:46:54,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:20,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:46,45 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1156
en_de Dev loss: 0.8983 r:0.2032
en_zh Dev loss: 0.7912 r:0.4560
Current avg r:0.3296 Best avg r: 0.3737
17:49:01,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:27,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:53,378 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1268
en_de Dev loss: 0.9178 r:0.2028
en_zh Dev loss: 0.7988 r:0.4467
Current avg r:0.3247 Best avg r: 0.3737
17:51:09,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:35,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:00,840 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1168
en_de Dev loss: 0.9861 r:0.1800
en_zh Dev loss: 0.8661 r:0.4320
Current avg r:0.3060 Best avg r: 0.3737
17:53:16,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:42,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:08,203 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1300
en_de Dev loss: 0.9634 r:0.1791
en_zh Dev loss: 0.8255 r:0.4482
Current avg r:0.3136 Best avg r: 0.3737
17:55:24,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:49,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:15,559 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1173
en_de Dev loss: 0.9519 r:0.1811
en_zh Dev loss: 0.7873 r:0.4530
Current avg r:0.3171 Best avg r: 0.3737
17:57:31,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:57,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:22,926 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1207
en_de Dev loss: 0.9046 r:0.1886
en_zh Dev loss: 0.7857 r:0.4402
Current avg r:0.3144 Best avg r: 0.3737
17:59:38,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:04,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:30,283 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1166
en_de Dev loss: 0.9645 r:0.1841
en_zh Dev loss: 0.8588 r:0.4457
Current avg r:0.3149 Best avg r: 0.3737
18:01:46,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:11,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:37,564 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1171
en_de Dev loss: 0.9564 r:0.1804
en_zh Dev loss: 0.7942 r:0.4523
Current avg r:0.3163 Best avg r: 0.3737
18:03:53,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:19,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:44,870 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1261
en_de Dev loss: 0.9418 r:0.1763
en_zh Dev loss: 0.8159 r:0.4437
Current avg r:0.3100 Best avg r: 0.3737
18:06:00,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:26,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:52,138 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1227
en_de Dev loss: 0.9686 r:0.1912
en_zh Dev loss: 0.8808 r:0.4427
Current avg r:0.3169 Best avg r: 0.3737
18:08:08,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:33,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:59,455 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1144
en_de Dev loss: 0.9295 r:0.1903
en_zh Dev loss: 0.8164 r:0.4558
Current avg r:0.3231 Best avg r: 0.3737
18:10:15,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:41,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:07,211 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1183
en_de Dev loss: 0.9221 r:0.1939
en_zh Dev loss: 0.7708 r:0.4612
Current avg r:0.3276 Best avg r: 0.3737
18:12:23,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:48,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:14,506 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1119
en_de Dev loss: 0.9391 r:0.1830
en_zh Dev loss: 0.7749 r:0.4699
Current avg r:0.3265 Best avg r: 0.3737
18:14:30,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:56,130 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:21,862 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1099
en_de Dev loss: 0.9478 r:0.1887
en_zh Dev loss: 0.7752 r:0.4633
Current avg r:0.3260 Best avg r: 0.3737
18:16:37,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:03,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:29,203 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1136
en_de Dev loss: 0.9524 r:0.1711
en_zh Dev loss: 0.7850 r:0.4621
Current avg r:0.3166 Best avg r: 0.3737
18:18:45,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:10,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:36,515 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1060
en_de Dev loss: 0.9311 r:0.1970
en_zh Dev loss: 0.7664 r:0.4649
Current avg r:0.3310 Best avg r: 0.3737
18:20:52,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:18,171 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:43,891 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1199
en_de Dev loss: 0.9789 r:0.1929
en_zh Dev loss: 0.8244 r:0.4667
Current avg r:0.3298 Best avg r: 0.3737
18:22:59,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:25,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:51,219 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1092
en_de Dev loss: 0.9300 r:0.1909
en_zh Dev loss: 0.7653 r:0.4670
Current avg r:0.3290 Best avg r: 0.3737
18:25:07,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:32,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:58,533 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1072
en_de Dev loss: 0.9241 r:0.1868
en_zh Dev loss: 0.7585 r:0.4694
Current avg r:0.3281 Best avg r: 0.3737
18:27:14,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:40,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:06,199 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1123
en_de Dev loss: 0.9438 r:0.1867
en_zh Dev loss: 0.7681 r:0.4675
Current avg r:0.3271 Best avg r: 0.3737
18:29:22,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:48,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:13,832 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1158
en_de Dev loss: 0.9133 r:0.1698
en_zh Dev loss: 0.7556 r:0.4575
Current avg r:0.3136 Best avg r: 0.3737
18:31:29,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:55,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:21,375 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1064
en_de Dev loss: 0.9476 r:0.1727
en_zh Dev loss: 0.7479 r:0.4625
Current avg r:0.3176 Best avg r: 0.3737
18:33:37,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:03,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:28,891 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1080
en_de Dev loss: 0.9341 r:0.1660
en_zh Dev loss: 0.7495 r:0.4581
Current avg r:0.3120 Best avg r: 0.3737
18:35:44,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:10,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:36,230 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1030
en_de Dev loss: 0.9837 r:0.1751
en_zh Dev loss: 0.8566 r:0.4545
Current avg r:0.3148 Best avg r: 0.3737
