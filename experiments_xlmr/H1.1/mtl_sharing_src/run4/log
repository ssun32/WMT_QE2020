14:41:31,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:14,426 root INFO 
id:en_zh cur r: 0.1279 best r: 0.1279
14:42:14,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:42:44,48 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
14:42:44,54 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:43:13,856 root INFO Epoch 0 Global steps: 200 Train loss: 0.6620
en_de Dev loss: 0.8889 r:0.0817
en_zh Dev loss: 0.8144 r:0.1256
Current avg r:0.1037 Best avg r: 0.1037
14:44:43,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:28,329 root INFO 
id:en_zh cur r: 0.1944 best r: 0.1944
14:45:28,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:58,511 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
14:45:58,517 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:46:28,714 root INFO Epoch 0 Global steps: 400 Train loss: 0.7213
en_de Dev loss: 0.8894 r:0.1193
en_zh Dev loss: 0.8130 r:0.1794
Current avg r:0.1493 Best avg r: 0.1493
14:47:58,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:43,828 root INFO 
id:en_zh cur r: 0.2226 best r: 0.2226
14:48:43,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:14,209 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
14:49:14,214 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:49:44,391 root INFO Epoch 0 Global steps: 600 Train loss: 0.7761
en_de Dev loss: 0.8824 r:0.1197
en_zh Dev loss: 0.8122 r:0.2243
Current avg r:0.1720 Best avg r: 0.1720
14:51:14,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:59,557 root INFO 
id:en_zh cur r: 0.2478 best r: 0.2478
14:51:59,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:30,3 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
14:52:30,21 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:53:00,238 root INFO Epoch 0 Global steps: 800 Train loss: 0.7803
en_de Dev loss: 0.8836 r:0.1316
en_zh Dev loss: 0.8079 r:0.2516
Current avg r:0.1916 Best avg r: 0.1916
14:54:29,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:15,355 root INFO 
id:en_zh cur r: 0.2881 best r: 0.2881
14:55:15,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:45,737 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
14:55:45,743 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:56:15,860 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8406
en_de Dev loss: 0.8781 r:0.1553
en_zh Dev loss: 0.7994 r:0.2970
Current avg r:0.2261 Best avg r: 0.2261
14:57:45,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:31,44 root INFO 
id:en_zh cur r: 0.3249 best r: 0.3249
14:58:31,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:01,438 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
14:59:01,444 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:59:31,774 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7898
en_de Dev loss: 0.8812 r:0.1730
en_zh Dev loss: 0.7965 r:0.3354
Current avg r:0.2542 Best avg r: 0.2542
15:01:01,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:46,866 root INFO 
id:en_zh cur r: 0.3428 best r: 0.3428
15:01:46,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:17,268 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:02:17,274 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:02:47,351 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7047
en_de Dev loss: 0.8732 r:0.1929
en_zh Dev loss: 0.7827 r:0.3488
Current avg r:0.2708 Best avg r: 0.2708
15:04:17,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:47,289 root INFO 
id:en_de cur r: 0.1853 best r: 0.1853
15:05:17,546 root INFO 
id:en_zh cur r: 0.3534 best r: 0.3534
15:05:17,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:47,857 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:05:47,863 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:06:18,336 root INFO Epoch 0 Global steps: 1600 Train loss: 0.7779
en_de Dev loss: 0.8704 r:0.2063
en_zh Dev loss: 0.7773 r:0.3613
Current avg r:0.2838 Best avg r: 0.2838
15:07:47,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:33,216 root INFO 
id:en_zh cur r: 0.3657 best r: 0.3657
15:08:33,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:03,691 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7489
en_de Dev loss: 0.8651 r:0.1804
en_zh Dev loss: 0.7498 r:0.3497
Current avg r:0.2650 Best avg r: 0.2838
15:10:33,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:03,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:33,612 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7267
en_de Dev loss: 0.8681 r:0.1790
en_zh Dev loss: 0.7457 r:0.3541
Current avg r:0.2665 Best avg r: 0.2838
15:13:03,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:33,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:03,890 root INFO Epoch 0 Global steps: 2200 Train loss: 0.7522
en_de Dev loss: 0.8744 r:0.1568
en_zh Dev loss: 0.7621 r:0.3114
Current avg r:0.2341 Best avg r: 0.2838
15:15:33,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:18,691 root INFO 
id:en_zh cur r: 0.3809 best r: 0.3809
15:16:18,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:48,857 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7530
en_de Dev loss: 0.8642 r:0.1696
en_zh Dev loss: 0.7127 r:0.3722
Current avg r:0.2709 Best avg r: 0.2838
15:18:18,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:48,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:18,816 root INFO Epoch 0 Global steps: 2600 Train loss: 0.6907
en_de Dev loss: 0.8729 r:0.1928
en_zh Dev loss: 0.7471 r:0.3645
Current avg r:0.2787 Best avg r: 0.2838
15:20:48,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:21:18,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:48,709 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6545
en_de Dev loss: 0.8872 r:0.2021
en_zh Dev loss: 0.7755 r:0.3563
Current avg r:0.2792 Best avg r: 0.2838
15:23:18,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:03,760 root INFO 
id:en_zh cur r: 0.4102 best r: 0.4102
15:24:03,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:33,887 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:24:33,893 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:25:04,39 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6681
en_de Dev loss: 0.8518 r:0.2022
en_zh Dev loss: 0.6940 r:0.3965
Current avg r:0.2993 Best avg r: 0.2993
15:26:33,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:03,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:34,285 root INFO Epoch 1 Global steps: 3200 Train loss: 0.6379
en_de Dev loss: 0.8855 r:0.1892
en_zh Dev loss: 0.7324 r:0.3877
Current avg r:0.2884 Best avg r: 0.2993
15:29:03,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:48,868 root INFO 
id:en_zh cur r: 0.4154 best r: 0.4154
15:29:48,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:19,28 root INFO Epoch 1 Global steps: 3400 Train loss: 0.6554
en_de Dev loss: 0.8701 r:0.2030
en_zh Dev loss: 0.7301 r:0.3945
Current avg r:0.2987 Best avg r: 0.2993
15:31:48,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:18,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:49,21 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:32:49,28 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:33:19,92 root INFO Epoch 1 Global steps: 3600 Train loss: 0.6631
en_de Dev loss: 0.8721 r:0.2026
en_zh Dev loss: 0.7208 r:0.3978
Current avg r:0.3002 Best avg r: 0.3002
15:34:48,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:33,956 root INFO 
id:en_zh cur r: 0.4243 best r: 0.4243
15:35:33,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:04,77 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:36:04,82 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:36:34,200 root INFO Epoch 1 Global steps: 3800 Train loss: 0.6404
en_de Dev loss: 0.8647 r:0.2297
en_zh Dev loss: 0.7267 r:0.4193
Current avg r:0.3245 Best avg r: 0.3245
15:38:03,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:48,844 root INFO 
id:en_zh cur r: 0.4246 best r: 0.4246
15:38:48,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:19,46 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:39:19,52 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:39:49,273 root INFO Epoch 1 Global steps: 4000 Train loss: 0.6432
en_de Dev loss: 0.8521 r:0.2309
en_zh Dev loss: 0.7055 r:0.4228
Current avg r:0.3268 Best avg r: 0.3268
15:41:18,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:48,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:19,41 root INFO Epoch 1 Global steps: 4200 Train loss: 0.6661
en_de Dev loss: 0.8818 r:0.2213
en_zh Dev loss: 0.7742 r:0.4048
Current avg r:0.3130 Best avg r: 0.3268
15:43:48,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:18,428 root INFO 
id:en_de cur r: 0.1903 best r: 0.1903
15:44:33,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:03,600 root INFO Epoch 1 Global steps: 4400 Train loss: 0.6066
en_de Dev loss: 0.8454 r:0.2395
en_zh Dev loss: 0.7000 r:0.4060
Current avg r:0.3227 Best avg r: 0.3268
15:46:32,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:02,969 root INFO 
id:en_de cur r: 0.2073 best r: 0.2073
15:47:33,216 root INFO 
id:en_zh cur r: 0.4326 best r: 0.4326
15:47:33,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:03,308 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
15:48:03,315 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:48:33,408 root INFO Epoch 1 Global steps: 4600 Train loss: 0.6702
en_de Dev loss: 0.8379 r:0.2527
en_zh Dev loss: 0.6745 r:0.4331
Current avg r:0.3429 Best avg r: 0.3429
15:50:02,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:32,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:03,125 root INFO Epoch 1 Global steps: 4800 Train loss: 0.6659
en_de Dev loss: 0.8492 r:0.2522
en_zh Dev loss: 0.7557 r:0.4230
Current avg r:0.3376 Best avg r: 0.3429
15:52:32,529 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:17,505 root INFO 
id:en_zh cur r: 0.4388 best r: 0.4388
15:53:17,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:47,894 root INFO Epoch 1 Global steps: 5000 Train loss: 0.6246
en_de Dev loss: 0.8458 r:0.2364
en_zh Dev loss: 0.7192 r:0.4218
Current avg r:0.3291 Best avg r: 0.3429
15:55:17,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:47,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:17,445 root INFO Epoch 1 Global steps: 5200 Train loss: 0.5880
en_de Dev loss: 0.8532 r:0.2351
en_zh Dev loss: 0.7073 r:0.4259
Current avg r:0.3305 Best avg r: 0.3429
15:57:46,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:32,221 root INFO 
id:en_zh cur r: 0.4405 best r: 0.4405
15:58:32,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:02,361 root INFO Epoch 1 Global steps: 5400 Train loss: 0.7316
en_de Dev loss: 0.8531 r:0.2430
en_zh Dev loss: 0.7330 r:0.4319
Current avg r:0.3375 Best avg r: 0.3429
16:00:31,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:16,958 root INFO 
id:en_zh cur r: 0.4517 best r: 0.4517
16:01:16,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:47,125 root INFO Epoch 1 Global steps: 5600 Train loss: 0.5881
en_de Dev loss: 0.8560 r:0.2303
en_zh Dev loss: 0.7073 r:0.4424
Current avg r:0.3364 Best avg r: 0.3429
16:03:16,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:46,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:16,696 root INFO Epoch 1 Global steps: 5800 Train loss: 0.6454
en_de Dev loss: 0.8490 r:0.2296
en_zh Dev loss: 0.7071 r:0.4328
Current avg r:0.3312 Best avg r: 0.3429
16:05:46,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:31,469 root INFO 
id:en_zh cur r: 0.4526 best r: 0.4526
16:06:31,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:01,569 root INFO Epoch 1 Global steps: 6000 Train loss: 0.6260
en_de Dev loss: 0.8454 r:0.2200
en_zh Dev loss: 0.7088 r:0.4298
Current avg r:0.3249 Best avg r: 0.3429
16:08:31,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:01,91 root INFO 
id:en_de cur r: 0.2113 best r: 0.2113
16:09:16,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:46,495 root INFO Epoch 2 Global steps: 6200 Train loss: 0.5614
en_de Dev loss: 0.8548 r:0.2308
en_zh Dev loss: 0.7584 r:0.4211
Current avg r:0.3260 Best avg r: 0.3429
16:11:15,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:45,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:15,987 root INFO Epoch 2 Global steps: 6400 Train loss: 0.5462
en_de Dev loss: 0.8608 r:0.2213
en_zh Dev loss: 0.7428 r:0.4091
Current avg r:0.3152 Best avg r: 0.3429
16:13:45,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:15,380 root INFO 
id:en_de cur r: 0.2143 best r: 0.2143
16:14:45,653 root INFO 
id:en_zh cur r: 0.4682 best r: 0.4682
16:14:45,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:15,709 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
16:15:15,716 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:15:45,709 root INFO Epoch 2 Global steps: 6600 Train loss: 0.5861
en_de Dev loss: 0.8473 r:0.2300
en_zh Dev loss: 0.6685 r:0.4590
Current avg r:0.3445 Best avg r: 0.3445
16:17:15,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:45,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:15,261 root INFO Epoch 2 Global steps: 6800 Train loss: 0.6568
en_de Dev loss: 0.8490 r:0.2241
en_zh Dev loss: 0.6910 r:0.4488
Current avg r:0.3365 Best avg r: 0.3445
16:19:44,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:14,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:44,779 root INFO Epoch 2 Global steps: 7000 Train loss: 0.6713
en_de Dev loss: 0.8574 r:0.2269
en_zh Dev loss: 0.6902 r:0.4438
Current avg r:0.3353 Best avg r: 0.3445
16:22:14,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:44,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:14,567 root INFO Epoch 2 Global steps: 7200 Train loss: 0.6993
en_de Dev loss: 0.8397 r:0.2348
en_zh Dev loss: 0.7123 r:0.4538
Current avg r:0.3443 Best avg r: 0.3445
16:24:43,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:29,184 root INFO 
id:en_zh cur r: 0.4709 best r: 0.4709
16:25:29,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:59,400 root INFO Epoch 2 Global steps: 7400 Train loss: 0.5687
en_de Dev loss: 0.8515 r:0.2236
en_zh Dev loss: 0.7197 r:0.4584
Current avg r:0.3410 Best avg r: 0.3445
16:27:28,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:58,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:28,775 root INFO Epoch 2 Global steps: 7600 Train loss: 0.5549
en_de Dev loss: 0.8642 r:0.2149
en_zh Dev loss: 0.7700 r:0.4211
Current avg r:0.3180 Best avg r: 0.3445
16:29:58,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:28,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:58,565 root INFO Epoch 2 Global steps: 7800 Train loss: 0.5086
en_de Dev loss: 0.8481 r:0.2360
en_zh Dev loss: 0.7054 r:0.4443
Current avg r:0.3401 Best avg r: 0.3445
16:32:27,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:58,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:28,198 root INFO Epoch 2 Global steps: 8000 Train loss: 0.6739
en_de Dev loss: 0.8397 r:0.2318
en_zh Dev loss: 0.6956 r:0.4528
Current avg r:0.3423 Best avg r: 0.3445
16:34:57,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:27,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:57,590 root INFO Epoch 2 Global steps: 8200 Train loss: 0.5877
en_de Dev loss: 0.8506 r:0.2369
en_zh Dev loss: 0.7394 r:0.4514
Current avg r:0.3442 Best avg r: 0.3445
16:37:26,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:57,62 root INFO 
id:en_de cur r: 0.2145 best r: 0.2145
16:38:12,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:42,504 root INFO Epoch 2 Global steps: 8400 Train loss: 0.5328
en_de Dev loss: 0.8405 r:0.2338
en_zh Dev loss: 0.6996 r:0.4548
Current avg r:0.3443 Best avg r: 0.3445
16:40:11,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:56,926 root INFO 
id:en_zh cur r: 0.4839 best r: 0.4839
16:40:56,926 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:27,65 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
16:41:27,71 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:41:57,217 root INFO Epoch 2 Global steps: 8600 Train loss: 0.4950
en_de Dev loss: 0.8431 r:0.2237
en_zh Dev loss: 0.6386 r:0.4785
Current avg r:0.3511 Best avg r: 0.3511
16:43:26,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:56,549 root INFO 
id:en_de cur r: 0.2279 best r: 0.2279
16:44:11,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:41,806 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
16:44:41,814 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:45:11,986 root INFO Epoch 2 Global steps: 8800 Train loss: 0.5356
en_de Dev loss: 0.8480 r:0.2421
en_zh Dev loss: 0.7076 r:0.4603
Current avg r:0.3512 Best avg r: 0.3512
16:46:41,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:11,322 root INFO 
id:en_de cur r: 0.2298 best r: 0.2298
16:47:26,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:56,706 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
16:47:56,714 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:48:26,741 root INFO Epoch 2 Global steps: 9000 Train loss: 0.5475
en_de Dev loss: 0.8338 r:0.2449
en_zh Dev loss: 0.6515 r:0.4763
Current avg r:0.3606 Best avg r: 0.3606
16:49:56,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:26,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:56,475 root INFO Epoch 3 Global steps: 9200 Train loss: 0.4985
en_de Dev loss: 0.8763 r:0.2449
en_zh Dev loss: 0.7908 r:0.4470
Current avg r:0.3460 Best avg r: 0.3606
16:52:25,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:55,823 root INFO 
id:en_de cur r: 0.2345 best r: 0.2345
16:53:11,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:41,145 root INFO Epoch 3 Global steps: 9400 Train loss: 0.5323
en_de Dev loss: 0.8596 r:0.2564
en_zh Dev loss: 0.8063 r:0.4309
Current avg r:0.3436 Best avg r: 0.3606
16:55:10,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:40,472 root INFO 
id:en_de cur r: 0.2400 best r: 0.2400
16:55:55,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:25,699 root INFO Epoch 3 Global steps: 9600 Train loss: 0.5701
en_de Dev loss: 0.8398 r:0.2551
en_zh Dev loss: 0.8020 r:0.4364
Current avg r:0.3458 Best avg r: 0.3606
16:57:54,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:24,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:55,326 root INFO Epoch 3 Global steps: 9800 Train loss: 0.4723
en_de Dev loss: 0.8287 r:0.2567
en_zh Dev loss: 0.6804 r:0.4636
Current avg r:0.3601 Best avg r: 0.3606
17:00:24,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:54,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:24,837 root INFO Epoch 3 Global steps: 10000 Train loss: 0.4456
en_de Dev loss: 0.8524 r:0.2476
en_zh Dev loss: 0.7371 r:0.4553
Current avg r:0.3514 Best avg r: 0.3606
17:02:54,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:24,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:54,565 root INFO Epoch 3 Global steps: 10200 Train loss: 0.5691
en_de Dev loss: 0.8403 r:0.2421
en_zh Dev loss: 0.7049 r:0.4658
Current avg r:0.3539 Best avg r: 0.3606
17:05:24,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:53,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:24,62 root INFO Epoch 3 Global steps: 10400 Train loss: 0.4810
en_de Dev loss: 0.8450 r:0.2546
en_zh Dev loss: 0.7338 r:0.4519
Current avg r:0.3533 Best avg r: 0.3606
17:07:53,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:23,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:53,676 root INFO Epoch 3 Global steps: 10600 Train loss: 0.5617
en_de Dev loss: 0.8545 r:0.2394
en_zh Dev loss: 0.7396 r:0.4543
Current avg r:0.3469 Best avg r: 0.3606
17:10:23,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:53,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:23,380 root INFO Epoch 3 Global steps: 10800 Train loss: 0.5413
en_de Dev loss: 0.8547 r:0.2222
en_zh Dev loss: 0.6909 r:0.4613
Current avg r:0.3418 Best avg r: 0.3606
17:12:52,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:36,880 root INFO 
id:en_zh cur r: 0.4854 best r: 0.4854
17:13:36,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:06,574 root INFO Epoch 3 Global steps: 11000 Train loss: 0.5042
en_de Dev loss: 0.8395 r:0.2403
en_zh Dev loss: 0.6736 r:0.4725
Current avg r:0.3564 Best avg r: 0.3606
17:15:35,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:04,517 root INFO 
id:en_de cur r: 0.2412 best r: 0.2412
17:16:19,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:49,126 root INFO Epoch 3 Global steps: 11200 Train loss: 0.4467
en_de Dev loss: 0.8343 r:0.2508
en_zh Dev loss: 0.6965 r:0.4584
Current avg r:0.3546 Best avg r: 0.3606
17:18:17,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:46,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:16,410 root INFO Epoch 3 Global steps: 11400 Train loss: 0.5368
en_de Dev loss: 0.8352 r:0.2534
en_zh Dev loss: 0.6940 r:0.4493
Current avg r:0.3514 Best avg r: 0.3606
17:20:44,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:29,149 root INFO 
id:en_zh cur r: 0.4949 best r: 0.4949
17:21:29,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:58,550 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_de.lang_agnost_mlp.dev.best.scores
17:21:58,558 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_src/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:22:27,970 root INFO Epoch 3 Global steps: 11600 Train loss: 0.5054
en_de Dev loss: 0.8399 r:0.2425
en_zh Dev loss: 0.6488 r:0.4869
Current avg r:0.3647 Best avg r: 0.3647
17:23:56,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:25,918 root INFO 
id:en_de cur r: 0.2478 best r: 0.2478
17:24:40,712 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:10,103 root INFO Epoch 3 Global steps: 11800 Train loss: 0.4726
en_de Dev loss: 0.8475 r:0.2622
en_zh Dev loss: 0.7339 r:0.4622
Current avg r:0.3622 Best avg r: 0.3647
17:26:38,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:07,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:37,405 root INFO Epoch 3 Global steps: 12000 Train loss: 0.5864
en_de Dev loss: 0.8467 r:0.2323
en_zh Dev loss: 0.7042 r:0.4628
Current avg r:0.3476 Best avg r: 0.3647
17:29:06,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:35,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:04,957 root INFO Epoch 4 Global steps: 12200 Train loss: 0.4461
en_de Dev loss: 0.8352 r:0.2433
en_zh Dev loss: 0.7158 r:0.4470
Current avg r:0.3452 Best avg r: 0.3647
17:31:33,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:02,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:32,54 root INFO Epoch 4 Global steps: 12400 Train loss: 0.4696
en_de Dev loss: 0.8344 r:0.2526
en_zh Dev loss: 0.7515 r:0.4483
Current avg r:0.3504 Best avg r: 0.3647
17:34:00,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:29,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:59,205 root INFO Epoch 4 Global steps: 12600 Train loss: 0.4430
en_de Dev loss: 0.8379 r:0.2565
en_zh Dev loss: 0.7496 r:0.4409
Current avg r:0.3487 Best avg r: 0.3647
17:36:27,797 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:57,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:26,541 root INFO Epoch 4 Global steps: 12800 Train loss: 0.4912
en_de Dev loss: 0.8457 r:0.2382
en_zh Dev loss: 0.7263 r:0.4478
Current avg r:0.3430 Best avg r: 0.3647
17:38:55,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:24,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:53,657 root INFO Epoch 4 Global steps: 13000 Train loss: 0.4450
en_de Dev loss: 0.8518 r:0.2294
en_zh Dev loss: 0.7326 r:0.4469
Current avg r:0.3381 Best avg r: 0.3647
17:41:22,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:51,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:21,268 root INFO Epoch 4 Global steps: 13200 Train loss: 0.4484
en_de Dev loss: 0.8478 r:0.2325
en_zh Dev loss: 0.7352 r:0.4531
Current avg r:0.3428 Best avg r: 0.3647
17:43:49,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:19,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:48,674 root INFO Epoch 4 Global steps: 13400 Train loss: 0.4396
en_de Dev loss: 0.8591 r:0.2141
en_zh Dev loss: 0.7302 r:0.4515
Current avg r:0.3328 Best avg r: 0.3647
17:46:17,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:46,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:16,185 root INFO Epoch 4 Global steps: 13600 Train loss: 0.5168
en_de Dev loss: 0.8682 r:0.2160
en_zh Dev loss: 0.7273 r:0.4649
Current avg r:0.3404 Best avg r: 0.3647
17:48:44,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:13,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:43,721 root INFO Epoch 4 Global steps: 13800 Train loss: 0.4311
en_de Dev loss: 0.8515 r:0.2218
en_zh Dev loss: 0.7089 r:0.4567
Current avg r:0.3393 Best avg r: 0.3647
17:51:12,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:41,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:11,151 root INFO Epoch 4 Global steps: 14000 Train loss: 0.5030
en_de Dev loss: 0.8599 r:0.2257
en_zh Dev loss: 0.7857 r:0.4389
Current avg r:0.3323 Best avg r: 0.3647
17:53:39,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:08,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:38,625 root INFO Epoch 4 Global steps: 14200 Train loss: 0.4147
en_de Dev loss: 0.8496 r:0.2245
en_zh Dev loss: 0.7030 r:0.4625
Current avg r:0.3435 Best avg r: 0.3647
17:56:07,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:36,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:06,183 root INFO Epoch 4 Global steps: 14400 Train loss: 0.4041
en_de Dev loss: 0.8596 r:0.2224
en_zh Dev loss: 0.7410 r:0.4490
Current avg r:0.3357 Best avg r: 0.3647
17:58:34,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:04,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:33,909 root INFO Epoch 4 Global steps: 14600 Train loss: 0.4489
en_de Dev loss: 0.8716 r:0.2084
en_zh Dev loss: 0.7008 r:0.4680
Current avg r:0.3382 Best avg r: 0.3647
18:01:02,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:31,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:01,529 root INFO Epoch 4 Global steps: 14800 Train loss: 0.3667
en_de Dev loss: 0.8755 r:0.2022
en_zh Dev loss: 0.7196 r:0.4539
Current avg r:0.3281 Best avg r: 0.3647
18:03:30,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:59,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:29,447 root INFO Epoch 4 Global steps: 15000 Train loss: 0.4035
en_de Dev loss: 0.8600 r:0.2122
en_zh Dev loss: 0.7527 r:0.4385
Current avg r:0.3254 Best avg r: 0.3647
18:05:58,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:27,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:57,713 root INFO Epoch 5 Global steps: 15200 Train loss: 0.3379
en_de Dev loss: 0.8625 r:0.2060
en_zh Dev loss: 0.8085 r:0.4234
Current avg r:0.3147 Best avg r: 0.3647
18:08:26,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:55,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:25,730 root INFO Epoch 5 Global steps: 15400 Train loss: 0.3733
en_de Dev loss: 0.8688 r:0.2117
en_zh Dev loss: 0.7775 r:0.4384
Current avg r:0.3250 Best avg r: 0.3647
18:10:54,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:23,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:53,851 root INFO Epoch 5 Global steps: 15600 Train loss: 0.3834
en_de Dev loss: 0.8767 r:0.2109
en_zh Dev loss: 0.7747 r:0.4507
Current avg r:0.3308 Best avg r: 0.3647
18:13:22,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:51,911 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:21,741 root INFO Epoch 5 Global steps: 15800 Train loss: 0.3942
en_de Dev loss: 0.8593 r:0.2208
en_zh Dev loss: 0.7295 r:0.4375
Current avg r:0.3292 Best avg r: 0.3647
18:15:50,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:19,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:49,728 root INFO Epoch 5 Global steps: 16000 Train loss: 0.4294
en_de Dev loss: 0.8944 r:0.1858
en_zh Dev loss: 0.8057 r:0.4304
Current avg r:0.3081 Best avg r: 0.3647
18:18:18,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:47,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:17,630 root INFO Epoch 5 Global steps: 16200 Train loss: 0.4188
en_de Dev loss: 0.8932 r:0.1823
en_zh Dev loss: 0.8208 r:0.4293
Current avg r:0.3058 Best avg r: 0.3647
18:20:46,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:15,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:45,665 root INFO Epoch 5 Global steps: 16400 Train loss: 0.3663
en_de Dev loss: 0.8653 r:0.1941
en_zh Dev loss: 0.7042 r:0.4535
Current avg r:0.3238 Best avg r: 0.3647
18:23:14,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:43,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:13,400 root INFO Epoch 5 Global steps: 16600 Train loss: 0.3588
en_de Dev loss: 0.8597 r:0.2028
en_zh Dev loss: 0.7122 r:0.4466
Current avg r:0.3247 Best avg r: 0.3647
18:25:42,5 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:11,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:41,240 root INFO Epoch 5 Global steps: 16800 Train loss: 0.4272
en_de Dev loss: 0.8659 r:0.1926
en_zh Dev loss: 0.7707 r:0.4327
Current avg r:0.3127 Best avg r: 0.3647
18:28:09,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:39,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:08,944 root INFO Epoch 5 Global steps: 17000 Train loss: 0.3818
en_de Dev loss: 0.8730 r:0.2124
en_zh Dev loss: 0.8191 r:0.4269
Current avg r:0.3197 Best avg r: 0.3647
18:30:37,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:06,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:36,629 root INFO Epoch 5 Global steps: 17200 Train loss: 0.3342
en_de Dev loss: 0.8864 r:0.1961
en_zh Dev loss: 0.8232 r:0.4395
Current avg r:0.3178 Best avg r: 0.3647
18:33:05,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:34,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:04,247 root INFO Epoch 5 Global steps: 17400 Train loss: 0.3647
en_de Dev loss: 0.8813 r:0.1927
en_zh Dev loss: 0.7669 r:0.4607
Current avg r:0.3267 Best avg r: 0.3647
18:35:32,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:02,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:31,940 root INFO Epoch 5 Global steps: 17600 Train loss: 0.3769
en_de Dev loss: 0.8681 r:0.1992
en_zh Dev loss: 0.7684 r:0.4454
Current avg r:0.3223 Best avg r: 0.3647
18:38:00,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:29,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:59,378 root INFO Epoch 5 Global steps: 17800 Train loss: 0.3290
en_de Dev loss: 0.8758 r:0.1927
en_zh Dev loss: 0.7424 r:0.4542
Current avg r:0.3235 Best avg r: 0.3647
18:40:27,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:57,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:27,219 root INFO Epoch 5 Global steps: 18000 Train loss: 0.3639
en_de Dev loss: 0.8968 r:0.1778
en_zh Dev loss: 0.7599 r:0.4631
Current avg r:0.3204 Best avg r: 0.3647
18:42:56,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:25,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:55,120 root INFO Epoch 6 Global steps: 18200 Train loss: 0.2998
en_de Dev loss: 0.8853 r:0.1896
en_zh Dev loss: 0.8171 r:0.4479
Current avg r:0.3187 Best avg r: 0.3647
18:45:23,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:52,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:22,724 root INFO Epoch 6 Global steps: 18400 Train loss: 0.3190
en_de Dev loss: 0.8903 r:0.1813
en_zh Dev loss: 0.8997 r:0.4226
Current avg r:0.3019 Best avg r: 0.3647
18:47:51,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:20,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:50,320 root INFO Epoch 6 Global steps: 18600 Train loss: 0.3014
en_de Dev loss: 0.9226 r:0.1932
en_zh Dev loss: 0.7451 r:0.4640
Current avg r:0.3286 Best avg r: 0.3647
18:50:18,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:48,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:17,881 root INFO Epoch 6 Global steps: 18800 Train loss: 0.2872
en_de Dev loss: 0.8999 r:0.1926
en_zh Dev loss: 0.8228 r:0.4548
Current avg r:0.3237 Best avg r: 0.3647
18:52:46,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:15,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:45,387 root INFO Epoch 6 Global steps: 19000 Train loss: 0.3330
en_de Dev loss: 0.8830 r:0.1726
en_zh Dev loss: 0.7935 r:0.4452
Current avg r:0.3089 Best avg r: 0.3647
18:55:13,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:43,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:56:12,919 root INFO Epoch 6 Global steps: 19200 Train loss: 0.3155
en_de Dev loss: 0.8968 r:0.1831
en_zh Dev loss: 0.8970 r:0.4360
Current avg r:0.3095 Best avg r: 0.3647
18:57:41,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:10,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:40,192 root INFO Epoch 6 Global steps: 19400 Train loss: 0.3200
en_de Dev loss: 0.8816 r:0.2080
en_zh Dev loss: 0.7828 r:0.4455
Current avg r:0.3268 Best avg r: 0.3647
19:00:08,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:38,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:07,906 root INFO Epoch 6 Global steps: 19600 Train loss: 0.3167
en_de Dev loss: 0.8811 r:0.1900
en_zh Dev loss: 0.8335 r:0.4420
Current avg r:0.3160 Best avg r: 0.3647
19:02:36,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:05,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:35,48 root INFO Epoch 6 Global steps: 19800 Train loss: 0.3349
en_de Dev loss: 0.8963 r:0.1975
en_zh Dev loss: 0.8826 r:0.4426
Current avg r:0.3200 Best avg r: 0.3647
19:05:03,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:32,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:02,746 root INFO Epoch 6 Global steps: 20000 Train loss: 0.3457
en_de Dev loss: 0.8936 r:0.1956
en_zh Dev loss: 0.7715 r:0.4524
Current avg r:0.3240 Best avg r: 0.3647
19:07:31,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:00,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:30,178 root INFO Epoch 6 Global steps: 20200 Train loss: 0.2980
en_de Dev loss: 0.8524 r:0.2244
en_zh Dev loss: 0.7375 r:0.4584
Current avg r:0.3414 Best avg r: 0.3647
19:09:58,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:28,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:57,722 root INFO Epoch 6 Global steps: 20400 Train loss: 0.2870
en_de Dev loss: 0.8822 r:0.1899
en_zh Dev loss: 0.7768 r:0.4584
Current avg r:0.3242 Best avg r: 0.3647
19:12:26,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:55,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:25,138 root INFO Epoch 6 Global steps: 20600 Train loss: 0.3416
en_de Dev loss: 0.8729 r:0.2024
en_zh Dev loss: 0.7883 r:0.4549
Current avg r:0.3286 Best avg r: 0.3647
19:14:53,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:22,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:52,779 root INFO Epoch 6 Global steps: 20800 Train loss: 0.3257
en_de Dev loss: 0.8595 r:0.2102
en_zh Dev loss: 0.8321 r:0.4431
Current avg r:0.3267 Best avg r: 0.3647
19:17:21,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:50,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:20,242 root INFO Epoch 6 Global steps: 21000 Train loss: 0.2953
en_de Dev loss: 0.8767 r:0.2075
en_zh Dev loss: 0.7849 r:0.4587
Current avg r:0.3331 Best avg r: 0.3647
19:19:49,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:18,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:47,896 root INFO Epoch 7 Global steps: 21200 Train loss: 0.2897
en_de Dev loss: 0.8855 r:0.2014
en_zh Dev loss: 0.8443 r:0.4421
Current avg r:0.3217 Best avg r: 0.3647
19:22:16,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:45,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:15,470 root INFO Epoch 7 Global steps: 21400 Train loss: 0.2962
en_de Dev loss: 0.8837 r:0.2080
en_zh Dev loss: 0.8310 r:0.4438
Current avg r:0.3259 Best avg r: 0.3647
19:24:43,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:13,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:43,13 root INFO Epoch 7 Global steps: 21600 Train loss: 0.3116
en_de Dev loss: 0.9166 r:0.1967
en_zh Dev loss: 0.9313 r:0.4423
Current avg r:0.3195 Best avg r: 0.3647
19:27:11,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:40,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:10,292 root INFO Epoch 7 Global steps: 21800 Train loss: 0.2528
en_de Dev loss: 0.8918 r:0.1847
en_zh Dev loss: 0.8324 r:0.4501
Current avg r:0.3174 Best avg r: 0.3647
19:29:38,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:08,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:37,612 root INFO Epoch 7 Global steps: 22000 Train loss: 0.2743
en_de Dev loss: 0.8990 r:0.1820
en_zh Dev loss: 0.8290 r:0.4436
Current avg r:0.3128 Best avg r: 0.3647
19:32:06,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:35,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:05,55 root INFO Epoch 7 Global steps: 22200 Train loss: 0.2438
en_de Dev loss: 0.8945 r:0.1859
en_zh Dev loss: 0.8391 r:0.4437
Current avg r:0.3148 Best avg r: 0.3647
19:34:33,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:02,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:32,475 root INFO Epoch 7 Global steps: 22400 Train loss: 0.2841
en_de Dev loss: 0.9087 r:0.1835
en_zh Dev loss: 0.8457 r:0.4463
Current avg r:0.3149 Best avg r: 0.3647
19:37:00,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:37:30,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:59,990 root INFO Epoch 7 Global steps: 22600 Train loss: 0.3097
en_de Dev loss: 0.9246 r:0.1607
en_zh Dev loss: 0.8353 r:0.4518
Current avg r:0.3062 Best avg r: 0.3647
19:39:28,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:57,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:27,345 root INFO Epoch 7 Global steps: 22800 Train loss: 0.2973
en_de Dev loss: 0.9119 r:0.1632
en_zh Dev loss: 0.7926 r:0.4623
Current avg r:0.3127 Best avg r: 0.3647
19:41:55,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:24,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:54,510 root INFO Epoch 7 Global steps: 23000 Train loss: 0.2519
en_de Dev loss: 0.8999 r:0.1698
en_zh Dev loss: 0.8511 r:0.4493
Current avg r:0.3095 Best avg r: 0.3647
19:44:23,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:52,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:22,94 root INFO Epoch 7 Global steps: 23200 Train loss: 0.2689
en_de Dev loss: 0.9007 r:0.1795
en_zh Dev loss: 0.7568 r:0.4620
Current avg r:0.3207 Best avg r: 0.3647
19:46:50,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:19,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:49,575 root INFO Epoch 7 Global steps: 23400 Train loss: 0.2916
en_de Dev loss: 0.9144 r:0.1643
en_zh Dev loss: 0.7840 r:0.4575
Current avg r:0.3109 Best avg r: 0.3647
19:49:18,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:47,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:17,158 root INFO Epoch 7 Global steps: 23600 Train loss: 0.2582
en_de Dev loss: 0.8864 r:0.1730
en_zh Dev loss: 0.7790 r:0.4596
Current avg r:0.3163 Best avg r: 0.3647
19:51:45,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:14,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:44,511 root INFO Epoch 7 Global steps: 23800 Train loss: 0.2669
en_de Dev loss: 0.8970 r:0.1638
en_zh Dev loss: 0.7658 r:0.4739
Current avg r:0.3189 Best avg r: 0.3647
19:54:13,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:42,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:11,997 root INFO Epoch 7 Global steps: 24000 Train loss: 0.2686
en_de Dev loss: 0.9098 r:0.1827
en_zh Dev loss: 0.7683 r:0.4756
Current avg r:0.3291 Best avg r: 0.3647
19:56:40,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:09,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:39,534 root INFO Epoch 8 Global steps: 24200 Train loss: 0.2336
en_de Dev loss: 0.9184 r:0.1798
en_zh Dev loss: 0.7910 r:0.4750
Current avg r:0.3274 Best avg r: 0.3647
19:59:08,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:37,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:06,811 root INFO Epoch 8 Global steps: 24400 Train loss: 0.2382
en_de Dev loss: 0.9052 r:0.1805
en_zh Dev loss: 0.7710 r:0.4685
Current avg r:0.3245 Best avg r: 0.3647
20:01:35,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:04,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:34,90 root INFO Epoch 8 Global steps: 24600 Train loss: 0.2568
en_de Dev loss: 0.9260 r:0.1792
en_zh Dev loss: 0.7935 r:0.4621
Current avg r:0.3206 Best avg r: 0.3647
20:04:02,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:31,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:01,299 root INFO Epoch 8 Global steps: 24800 Train loss: 0.2385
en_de Dev loss: 0.9425 r:0.1723
en_zh Dev loss: 0.7711 r:0.4719
Current avg r:0.3221 Best avg r: 0.3647
20:06:29,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:59,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:28,812 root INFO Epoch 8 Global steps: 25000 Train loss: 0.2579
en_de Dev loss: 0.9116 r:0.1869
en_zh Dev loss: 0.7825 r:0.4673
Current avg r:0.3271 Best avg r: 0.3647
20:08:57,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:26,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:56,301 root INFO Epoch 8 Global steps: 25200 Train loss: 0.2342
en_de Dev loss: 0.9180 r:0.1624
en_zh Dev loss: 0.7754 r:0.4690
Current avg r:0.3157 Best avg r: 0.3647
20:11:24,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:53,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:23,628 root INFO Epoch 8 Global steps: 25400 Train loss: 0.2376
en_de Dev loss: 0.9143 r:0.1658
en_zh Dev loss: 0.7478 r:0.4712
Current avg r:0.3185 Best avg r: 0.3647
20:13:52,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:21,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:50,906 root INFO Epoch 8 Global steps: 25600 Train loss: 0.2314
en_de Dev loss: 0.9214 r:0.1707
en_zh Dev loss: 0.8020 r:0.4615
Current avg r:0.3161 Best avg r: 0.3647
20:16:19,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:48,555 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:18,297 root INFO Epoch 8 Global steps: 25800 Train loss: 0.2658
en_de Dev loss: 0.9249 r:0.1674
en_zh Dev loss: 0.7559 r:0.4758
Current avg r:0.3216 Best avg r: 0.3647
20:18:46,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:15,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:45,697 root INFO Epoch 8 Global steps: 26000 Train loss: 0.2433
en_de Dev loss: 0.9044 r:0.1470
en_zh Dev loss: 0.7984 r:0.4567
Current avg r:0.3018 Best avg r: 0.3647
20:21:14,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:43,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:13,10 root INFO Epoch 8 Global steps: 26200 Train loss: 0.2521
en_de Dev loss: 0.9142 r:0.1501
en_zh Dev loss: 0.8089 r:0.4472
Current avg r:0.2986 Best avg r: 0.3647
20:23:41,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:10,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:40,601 root INFO Epoch 8 Global steps: 26400 Train loss: 0.2459
en_de Dev loss: 0.9019 r:0.1697
en_zh Dev loss: 0.8120 r:0.4562
Current avg r:0.3129 Best avg r: 0.3647
20:26:09,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:26:38,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:08,212 root INFO Epoch 8 Global steps: 26600 Train loss: 0.2418
en_de Dev loss: 0.8979 r:0.1672
en_zh Dev loss: 0.7830 r:0.4555
Current avg r:0.3114 Best avg r: 0.3647
20:28:36,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:05,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:35,564 root INFO Epoch 8 Global steps: 26800 Train loss: 0.2290
en_de Dev loss: 0.9047 r:0.1688
en_zh Dev loss: 0.8052 r:0.4656
Current avg r:0.3172 Best avg r: 0.3647
20:31:04,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:33,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:03,63 root INFO Epoch 8 Global steps: 27000 Train loss: 0.2381
en_de Dev loss: 0.9179 r:0.1679
en_zh Dev loss: 0.8642 r:0.4578
Current avg r:0.3128 Best avg r: 0.3647
20:33:31,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:01,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:34:30,819 root INFO Epoch 9 Global steps: 27200 Train loss: 0.2219
en_de Dev loss: 0.9496 r:0.1636
en_zh Dev loss: 0.9416 r:0.4586
Current avg r:0.3111 Best avg r: 0.3647
20:35:59,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:28,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:58,423 root INFO Epoch 9 Global steps: 27400 Train loss: 0.2036
en_de Dev loss: 0.9305 r:0.1504
en_zh Dev loss: 0.8795 r:0.4505
Current avg r:0.3004 Best avg r: 0.3647
20:38:26,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:56,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:25,970 root INFO Epoch 9 Global steps: 27600 Train loss: 0.2098
en_de Dev loss: 0.9099 r:0.1690
en_zh Dev loss: 0.7955 r:0.4662
Current avg r:0.3176 Best avg r: 0.3647
20:40:54,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:23,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:53,546 root INFO Epoch 9 Global steps: 27800 Train loss: 0.2137
en_de Dev loss: 0.9125 r:0.1698
en_zh Dev loss: 0.8121 r:0.4747
Current avg r:0.3222 Best avg r: 0.3647
20:43:22,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:51,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:20,919 root INFO Epoch 9 Global steps: 28000 Train loss: 0.2172
en_de Dev loss: 0.9307 r:0.1821
en_zh Dev loss: 0.7623 r:0.4764
Current avg r:0.3292 Best avg r: 0.3647
20:45:49,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:18,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:48,471 root INFO Epoch 9 Global steps: 28200 Train loss: 0.2343
en_de Dev loss: 0.9062 r:0.1818
en_zh Dev loss: 0.7948 r:0.4669
Current avg r:0.3244 Best avg r: 0.3647
20:48:16,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:46,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:16,121 root INFO Epoch 9 Global steps: 28400 Train loss: 0.2223
en_de Dev loss: 0.8860 r:0.1847
en_zh Dev loss: 0.7771 r:0.4616
Current avg r:0.3231 Best avg r: 0.3647
20:50:44,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:13,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:43,565 root INFO Epoch 9 Global steps: 28600 Train loss: 0.2089
en_de Dev loss: 0.9198 r:0.1660
en_zh Dev loss: 0.8886 r:0.4421
Current avg r:0.3040 Best avg r: 0.3647
20:53:12,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:41,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:11,143 root INFO Epoch 9 Global steps: 28800 Train loss: 0.2215
en_de Dev loss: 0.9363 r:0.1538
en_zh Dev loss: 0.8558 r:0.4519
Current avg r:0.3028 Best avg r: 0.3647
20:55:39,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:08,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:38,369 root INFO Epoch 9 Global steps: 29000 Train loss: 0.2199
en_de Dev loss: 0.9156 r:0.1736
en_zh Dev loss: 0.7589 r:0.4703
Current avg r:0.3219 Best avg r: 0.3647
20:58:06,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:36,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:05,734 root INFO Epoch 9 Global steps: 29200 Train loss: 0.2175
en_de Dev loss: 0.9100 r:0.1653
en_zh Dev loss: 0.8285 r:0.4517
Current avg r:0.3085 Best avg r: 0.3647
21:00:34,219 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:03,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:32,739 root INFO Epoch 9 Global steps: 29400 Train loss: 0.2216
en_de Dev loss: 0.9226 r:0.1678
en_zh Dev loss: 0.8311 r:0.4585
Current avg r:0.3131 Best avg r: 0.3647
21:03:01,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:30,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:00,122 root INFO Epoch 9 Global steps: 29600 Train loss: 0.2196
en_de Dev loss: 0.9666 r:0.1398
en_zh Dev loss: 0.9598 r:0.4451
Current avg r:0.2925 Best avg r: 0.3647
21:05:28,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:57,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:27,375 root INFO Epoch 9 Global steps: 29800 Train loss: 0.2128
en_de Dev loss: 0.9306 r:0.1602
en_zh Dev loss: 0.8203 r:0.4704
Current avg r:0.3153 Best avg r: 0.3647
21:07:55,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:25,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:54,690 root INFO Epoch 9 Global steps: 30000 Train loss: 0.2025
en_de Dev loss: 0.9251 r:0.1755
en_zh Dev loss: 0.7789 r:0.4701
Current avg r:0.3228 Best avg r: 0.3647
21:10:23,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:52,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:22,397 root INFO Epoch 10 Global steps: 30200 Train loss: 0.1753
en_de Dev loss: 0.9274 r:0.1735
en_zh Dev loss: 0.8168 r:0.4664
Current avg r:0.3200 Best avg r: 0.3647
21:12:50,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:19,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:49,664 root INFO Epoch 10 Global steps: 30400 Train loss: 0.2009
en_de Dev loss: 0.9550 r:0.1678
en_zh Dev loss: 0.8484 r:0.4625
Current avg r:0.3152 Best avg r: 0.3647
21:15:18,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:47,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:17,212 root INFO Epoch 10 Global steps: 30600 Train loss: 0.2160
en_de Dev loss: 0.9343 r:0.1678
en_zh Dev loss: 0.8124 r:0.4687
Current avg r:0.3183 Best avg r: 0.3647
21:17:45,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:14,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:44,156 root INFO Epoch 10 Global steps: 30800 Train loss: 0.1888
en_de Dev loss: 0.9516 r:0.1541
en_zh Dev loss: 0.8543 r:0.4577
Current avg r:0.3059 Best avg r: 0.3647
21:20:12,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:41,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:11,487 root INFO Epoch 10 Global steps: 31000 Train loss: 0.1961
en_de Dev loss: 0.9063 r:0.1514
en_zh Dev loss: 0.7783 r:0.4589
Current avg r:0.3052 Best avg r: 0.3647
21:22:39,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:09,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:38,924 root INFO Epoch 10 Global steps: 31200 Train loss: 0.2038
en_de Dev loss: 0.9489 r:0.1825
en_zh Dev loss: 0.7751 r:0.4650
Current avg r:0.3237 Best avg r: 0.3647
21:25:07,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:36,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:06,118 root INFO Epoch 10 Global steps: 31400 Train loss: 0.1819
en_de Dev loss: 0.9384 r:0.1594
en_zh Dev loss: 0.7767 r:0.4616
Current avg r:0.3105 Best avg r: 0.3647
21:27:34,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:03,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:28:33,566 root INFO Epoch 10 Global steps: 31600 Train loss: 0.1855
en_de Dev loss: 0.9511 r:0.1361
en_zh Dev loss: 0.9187 r:0.4487
Current avg r:0.2924 Best avg r: 0.3647
21:30:01,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:31,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:00,374 root INFO Epoch 10 Global steps: 31800 Train loss: 0.2010
en_de Dev loss: 0.9964 r:0.1420
en_zh Dev loss: 0.9331 r:0.4506
Current avg r:0.2963 Best avg r: 0.3647
21:32:28,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:57,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:27,281 root INFO Epoch 10 Global steps: 32000 Train loss: 0.1840
en_de Dev loss: 0.9430 r:0.1231
en_zh Dev loss: 0.8953 r:0.4455
Current avg r:0.2843 Best avg r: 0.3647
21:34:55,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:24,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:54,277 root INFO Epoch 10 Global steps: 32200 Train loss: 0.1864
en_de Dev loss: 0.9454 r:0.1426
en_zh Dev loss: 0.8575 r:0.4581
Current avg r:0.3003 Best avg r: 0.3647
21:37:22,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:51,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:21,144 root INFO Epoch 10 Global steps: 32400 Train loss: 0.1957
en_de Dev loss: 0.9378 r:0.1579
en_zh Dev loss: 0.8223 r:0.4661
Current avg r:0.3120 Best avg r: 0.3647
21:39:49,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:18,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:48,84 root INFO Epoch 10 Global steps: 32600 Train loss: 0.1880
en_de Dev loss: 0.9832 r:0.1549
en_zh Dev loss: 0.9351 r:0.4543
Current avg r:0.3046 Best avg r: 0.3647
21:42:16,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:45,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:15,242 root INFO Epoch 10 Global steps: 32800 Train loss: 0.1845
en_de Dev loss: 0.9425 r:0.1495
en_zh Dev loss: 0.8035 r:0.4582
Current avg r:0.3039 Best avg r: 0.3647
21:44:43,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:12,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:42,0 root INFO Epoch 10 Global steps: 33000 Train loss: 0.2009
en_de Dev loss: 0.9360 r:0.1723
en_zh Dev loss: 0.8147 r:0.4595
Current avg r:0.3159 Best avg r: 0.3647
21:47:10,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:39,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:09,194 root INFO Epoch 11 Global steps: 33200 Train loss: 0.1893
en_de Dev loss: 0.9363 r:0.1408
en_zh Dev loss: 0.8196 r:0.4534
Current avg r:0.2971 Best avg r: 0.3647
21:49:37,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:06,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:50:36,92 root INFO Epoch 11 Global steps: 33400 Train loss: 0.1567
en_de Dev loss: 0.9500 r:0.1566
en_zh Dev loss: 0.8471 r:0.4618
Current avg r:0.3092 Best avg r: 0.3647
21:52:04,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:33,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:02,858 root INFO Epoch 11 Global steps: 33600 Train loss: 0.1603
en_de Dev loss: 0.9516 r:0.1741
en_zh Dev loss: 0.8032 r:0.4713
Current avg r:0.3227 Best avg r: 0.3647
21:54:31,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:00,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:55:29,775 root INFO Epoch 11 Global steps: 33800 Train loss: 0.1718
en_de Dev loss: 0.9477 r:0.1493
en_zh Dev loss: 0.8167 r:0.4693
Current avg r:0.3093 Best avg r: 0.3647
21:56:58,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:27,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:57:56,711 root INFO Epoch 11 Global steps: 34000 Train loss: 0.1745
en_de Dev loss: 0.9210 r:0.1585
en_zh Dev loss: 0.7947 r:0.4690
Current avg r:0.3138 Best avg r: 0.3647
21:59:25,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:54,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:23,671 root INFO Epoch 11 Global steps: 34200 Train loss: 0.1796
en_de Dev loss: 0.9350 r:0.1594
en_zh Dev loss: 0.7941 r:0.4729
Current avg r:0.3162 Best avg r: 0.3647
22:01:52,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:21,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:50,788 root INFO Epoch 11 Global steps: 34400 Train loss: 0.1696
en_de Dev loss: 0.9197 r:0.1762
en_zh Dev loss: 0.7536 r:0.4715
Current avg r:0.3238 Best avg r: 0.3647
22:04:19,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:48,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:17,831 root INFO Epoch 11 Global steps: 34600 Train loss: 0.1758
en_de Dev loss: 0.9548 r:0.1648
en_zh Dev loss: 0.8022 r:0.4741
Current avg r:0.3195 Best avg r: 0.3647
22:06:46,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:07:15,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:44,925 root INFO Epoch 11 Global steps: 34800 Train loss: 0.1786
en_de Dev loss: 0.9335 r:0.1736
en_zh Dev loss: 0.8297 r:0.4725
Current avg r:0.3230 Best avg r: 0.3647
22:09:13,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:42,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:11,723 root INFO Epoch 11 Global steps: 35000 Train loss: 0.1830
en_de Dev loss: 0.9096 r:0.1678
en_zh Dev loss: 0.7792 r:0.4632
Current avg r:0.3155 Best avg r: 0.3647
22:11:40,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:09,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:38,707 root INFO Epoch 11 Global steps: 35200 Train loss: 0.1714
en_de Dev loss: 0.9246 r:0.1718
en_zh Dev loss: 0.8212 r:0.4608
Current avg r:0.3163 Best avg r: 0.3647
22:14:07,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:36,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:05,908 root INFO Epoch 11 Global steps: 35400 Train loss: 0.1738
en_de Dev loss: 0.9130 r:0.1932
en_zh Dev loss: 0.7481 r:0.4712
Current avg r:0.3322 Best avg r: 0.3647
22:16:34,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:03,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:32,845 root INFO Epoch 11 Global steps: 35600 Train loss: 0.1599
en_de Dev loss: 0.9331 r:0.1640
en_zh Dev loss: 0.8201 r:0.4623
Current avg r:0.3131 Best avg r: 0.3647
22:19:01,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:30,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:59,825 root INFO Epoch 11 Global steps: 35800 Train loss: 0.1698
en_de Dev loss: 0.9867 r:0.1556
en_zh Dev loss: 0.8904 r:0.4598
Current avg r:0.3077 Best avg r: 0.3647
22:21:28,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:57,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:26,742 root INFO Epoch 11 Global steps: 36000 Train loss: 0.1739
en_de Dev loss: 0.9197 r:0.1690
en_zh Dev loss: 0.8140 r:0.4643
Current avg r:0.3166 Best avg r: 0.3647
22:23:55,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:24,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:54,174 root INFO Epoch 12 Global steps: 36200 Train loss: 0.1683
en_de Dev loss: 0.9516 r:0.1591
en_zh Dev loss: 0.8965 r:0.4540
Current avg r:0.3065 Best avg r: 0.3647
22:26:22,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:26:51,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:21,6 root INFO Epoch 12 Global steps: 36400 Train loss: 0.1630
en_de Dev loss: 0.9304 r:0.1923
en_zh Dev loss: 0.7845 r:0.4711
Current avg r:0.3317 Best avg r: 0.3647
22:28:49,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:18,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:48,46 root INFO Epoch 12 Global steps: 36600 Train loss: 0.1537
en_de Dev loss: 0.9388 r:0.1900
en_zh Dev loss: 0.7711 r:0.4738
Current avg r:0.3319 Best avg r: 0.3647
22:31:16,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:45,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:14,880 root INFO Epoch 12 Global steps: 36800 Train loss: 0.1476
en_de Dev loss: 0.9351 r:0.1857
en_zh Dev loss: 0.7963 r:0.4729
Current avg r:0.3293 Best avg r: 0.3647
22:33:43,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:12,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:41,893 root INFO Epoch 12 Global steps: 37000 Train loss: 0.1651
en_de Dev loss: 0.9729 r:0.1849
en_zh Dev loss: 0.8177 r:0.4669
Current avg r:0.3259 Best avg r: 0.3647
22:36:10,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:39,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:08,989 root INFO Epoch 12 Global steps: 37200 Train loss: 0.1349
en_de Dev loss: 0.9642 r:0.1683
en_zh Dev loss: 0.8599 r:0.4618
Current avg r:0.3150 Best avg r: 0.3647
22:38:37,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:39:06,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:35,981 root INFO Epoch 12 Global steps: 37400 Train loss: 0.1536
en_de Dev loss: 0.9417 r:0.1614
en_zh Dev loss: 0.7998 r:0.4613
Current avg r:0.3113 Best avg r: 0.3647
22:41:04,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:33,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:02,742 root INFO Epoch 12 Global steps: 37600 Train loss: 0.1502
en_de Dev loss: 0.9670 r:0.1571
en_zh Dev loss: 0.8556 r:0.4553
Current avg r:0.3062 Best avg r: 0.3647
22:43:31,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:00,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:29,525 root INFO Epoch 12 Global steps: 37800 Train loss: 0.1667
en_de Dev loss: 0.9262 r:0.1616
en_zh Dev loss: 0.8130 r:0.4677
Current avg r:0.3147 Best avg r: 0.3647
22:45:58,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:26,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:56,350 root INFO Epoch 12 Global steps: 38000 Train loss: 0.1571
en_de Dev loss: 0.9516 r:0.1582
en_zh Dev loss: 0.8781 r:0.4734
Current avg r:0.3158 Best avg r: 0.3647
22:48:24,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:53,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:23,117 root INFO Epoch 12 Global steps: 38200 Train loss: 0.1669
en_de Dev loss: 0.9584 r:0.1337
en_zh Dev loss: 0.8448 r:0.4634
Current avg r:0.2985 Best avg r: 0.3647
22:50:51,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:20,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:49,900 root INFO Epoch 12 Global steps: 38400 Train loss: 0.1630
en_de Dev loss: 1.0009 r:0.1539
en_zh Dev loss: 0.9112 r:0.4584
Current avg r:0.3062 Best avg r: 0.3647
22:53:18,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:47,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:16,878 root INFO Epoch 12 Global steps: 38600 Train loss: 0.1461
en_de Dev loss: 0.9351 r:0.1530
en_zh Dev loss: 0.7934 r:0.4697
Current avg r:0.3114 Best avg r: 0.3647
22:55:45,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:14,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:43,535 root INFO Epoch 12 Global steps: 38800 Train loss: 0.1463
en_de Dev loss: 0.9597 r:0.1736
en_zh Dev loss: 0.8356 r:0.4646
Current avg r:0.3191 Best avg r: 0.3647
22:58:11,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:41,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:10,512 root INFO Epoch 12 Global steps: 39000 Train loss: 0.1633
en_de Dev loss: 0.9281 r:0.1703
en_zh Dev loss: 0.7960 r:0.4697
Current avg r:0.3200 Best avg r: 0.3647
23:00:39,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:08,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:37,657 root INFO Epoch 13 Global steps: 39200 Train loss: 0.1468
en_de Dev loss: 0.9400 r:0.1604
en_zh Dev loss: 0.8102 r:0.4632
Current avg r:0.3118 Best avg r: 0.3647
23:03:06,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:35,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:04,763 root INFO Epoch 13 Global steps: 39400 Train loss: 0.1401
en_de Dev loss: 0.9525 r:0.1694
en_zh Dev loss: 0.8518 r:0.4607
Current avg r:0.3151 Best avg r: 0.3647
23:05:33,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:02,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:31,489 root INFO Epoch 13 Global steps: 39600 Train loss: 0.1395
en_de Dev loss: 0.9565 r:0.1590
en_zh Dev loss: 0.7784 r:0.4687
Current avg r:0.3138 Best avg r: 0.3647
23:07:59,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:28,934 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:58,282 root INFO Epoch 13 Global steps: 39800 Train loss: 0.1382
en_de Dev loss: 0.9753 r:0.1373
en_zh Dev loss: 0.8616 r:0.4582
Current avg r:0.2977 Best avg r: 0.3647
23:10:26,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:55,688 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:25,68 root INFO Epoch 13 Global steps: 40000 Train loss: 0.1346
en_de Dev loss: 0.9572 r:0.1477
en_zh Dev loss: 0.8647 r:0.4611
Current avg r:0.3044 Best avg r: 0.3647
23:12:53,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:22,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:52,108 root INFO Epoch 13 Global steps: 40200 Train loss: 0.1354
en_de Dev loss: 0.9477 r:0.1605
en_zh Dev loss: 0.7677 r:0.4736
Current avg r:0.3171 Best avg r: 0.3647
23:15:20,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:49,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:18,909 root INFO Epoch 13 Global steps: 40400 Train loss: 0.1346
en_de Dev loss: 0.9440 r:0.1562
en_zh Dev loss: 0.7841 r:0.4722
Current avg r:0.3142 Best avg r: 0.3647
23:17:47,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:16,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:45,966 root INFO Epoch 13 Global steps: 40600 Train loss: 0.1333
en_de Dev loss: 0.9672 r:0.1415
en_zh Dev loss: 0.8001 r:0.4710
Current avg r:0.3063 Best avg r: 0.3647
23:20:14,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:43,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:21:13,160 root INFO Epoch 13 Global steps: 40800 Train loss: 0.1400
en_de Dev loss: 0.9583 r:0.1555
en_zh Dev loss: 0.7985 r:0.4729
Current avg r:0.3142 Best avg r: 0.3647
23:22:41,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:23:10,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:40,336 root INFO Epoch 13 Global steps: 41000 Train loss: 0.1435
en_de Dev loss: 0.9905 r:0.1685
en_zh Dev loss: 0.8123 r:0.4711
Current avg r:0.3198 Best avg r: 0.3647
23:25:08,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:37,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:07,332 root INFO Epoch 13 Global steps: 41200 Train loss: 0.1501
en_de Dev loss: 0.9732 r:0.1868
en_zh Dev loss: 0.7799 r:0.4748
Current avg r:0.3308 Best avg r: 0.3647
23:27:35,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:04,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:28:34,708 root INFO Epoch 13 Global steps: 41400 Train loss: 0.1379
en_de Dev loss: 0.9734 r:0.1340
en_zh Dev loss: 0.8154 r:0.4649
Current avg r:0.2994 Best avg r: 0.3647
23:30:03,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:32,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:01,713 root INFO Epoch 13 Global steps: 41600 Train loss: 0.1271
en_de Dev loss: 0.9536 r:0.1683
en_zh Dev loss: 0.7787 r:0.4715
Current avg r:0.3199 Best avg r: 0.3647
23:32:30,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:59,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:29,91 root INFO Epoch 13 Global steps: 41800 Train loss: 0.1311
en_de Dev loss: 0.9619 r:0.1486
en_zh Dev loss: 0.8133 r:0.4616
Current avg r:0.3051 Best avg r: 0.3647
23:34:57,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:26,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:56,308 root INFO Epoch 13 Global steps: 42000 Train loss: 0.1333
en_de Dev loss: 0.9452 r:0.1390
en_zh Dev loss: 0.7765 r:0.4580
Current avg r:0.2985 Best avg r: 0.3647
23:37:25,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:54,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:23,588 root INFO Epoch 14 Global steps: 42200 Train loss: 0.1181
en_de Dev loss: 0.9438 r:0.1580
en_zh Dev loss: 0.7791 r:0.4659
Current avg r:0.3119 Best avg r: 0.3647
23:39:52,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:21,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:50,877 root INFO Epoch 14 Global steps: 42400 Train loss: 0.1229
en_de Dev loss: 0.9838 r:0.1687
en_zh Dev loss: 0.8461 r:0.4689
Current avg r:0.3188 Best avg r: 0.3647
23:42:19,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:48,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:18,167 root INFO Epoch 14 Global steps: 42600 Train loss: 0.1390
en_de Dev loss: 0.9968 r:0.1726
en_zh Dev loss: 0.8747 r:0.4694
Current avg r:0.3210 Best avg r: 0.3647
23:44:46,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:15,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:45,650 root INFO Epoch 14 Global steps: 42800 Train loss: 0.1354
en_de Dev loss: 0.9636 r:0.1592
en_zh Dev loss: 0.8349 r:0.4647
Current avg r:0.3119 Best avg r: 0.3647
23:47:14,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:43,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:12,878 root INFO Epoch 14 Global steps: 43000 Train loss: 0.1297
en_de Dev loss: 0.9638 r:0.1697
en_zh Dev loss: 0.8148 r:0.4699
Current avg r:0.3198 Best avg r: 0.3647
23:49:41,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:10,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:40,172 root INFO Epoch 14 Global steps: 43200 Train loss: 0.1286
en_de Dev loss: 0.9870 r:0.1563
en_zh Dev loss: 0.8592 r:0.4703
Current avg r:0.3133 Best avg r: 0.3647
23:52:08,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:37,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:07,511 root INFO Epoch 14 Global steps: 43400 Train loss: 0.1240
en_de Dev loss: 0.9571 r:0.1539
en_zh Dev loss: 0.7621 r:0.4797
Current avg r:0.3168 Best avg r: 0.3647
23:54:36,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:05,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:34,602 root INFO Epoch 14 Global steps: 43600 Train loss: 0.1255
en_de Dev loss: 0.9722 r:0.1464
en_zh Dev loss: 0.8217 r:0.4720
Current avg r:0.3092 Best avg r: 0.3647
23:57:03,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:32,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:01,936 root INFO Epoch 14 Global steps: 43800 Train loss: 0.1241
en_de Dev loss: 0.9650 r:0.1308
en_zh Dev loss: 0.8181 r:0.4748
Current avg r:0.3028 Best avg r: 0.3647
23:59:30,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:59,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:29,469 root INFO Epoch 14 Global steps: 44000 Train loss: 0.1291
en_de Dev loss: 0.9661 r:0.1512
en_zh Dev loss: 0.8153 r:0.4711
Current avg r:0.3111 Best avg r: 0.3647
00:01:57,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:27,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:02:56,833 root INFO Epoch 14 Global steps: 44200 Train loss: 0.1211
en_de Dev loss: 0.9578 r:0.1735
en_zh Dev loss: 0.8055 r:0.4714
Current avg r:0.3225 Best avg r: 0.3647
00:04:25,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:54,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:24,169 root INFO Epoch 14 Global steps: 44400 Train loss: 0.1313
en_de Dev loss: 0.9909 r:0.1549
en_zh Dev loss: 0.8279 r:0.4648
Current avg r:0.3098 Best avg r: 0.3647
00:06:52,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:21,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:51,733 root INFO Epoch 14 Global steps: 44600 Train loss: 0.1190
en_de Dev loss: 0.9537 r:0.1663
en_zh Dev loss: 0.7801 r:0.4709
Current avg r:0.3186 Best avg r: 0.3647
00:09:20,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:49,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:19,190 root INFO Epoch 14 Global steps: 44800 Train loss: 0.1296
en_de Dev loss: 0.9723 r:0.1711
en_zh Dev loss: 0.8021 r:0.4733
Current avg r:0.3222 Best avg r: 0.3647
00:11:47,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:12:16,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:46,482 root INFO Epoch 14 Global steps: 45000 Train loss: 0.1227
en_de Dev loss: 0.9552 r:0.1632
en_zh Dev loss: 0.7961 r:0.4742
Current avg r:0.3187 Best avg r: 0.3647
00:14:15,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:44,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:14,287 root INFO Epoch 15 Global steps: 45200 Train loss: 0.1206
en_de Dev loss: 0.9336 r:0.1785
en_zh Dev loss: 0.7013 r:0.4925
Current avg r:0.3355 Best avg r: 0.3647
00:16:42,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:11,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:17:41,711 root INFO Epoch 15 Global steps: 45400 Train loss: 0.1107
en_de Dev loss: 0.9469 r:0.1501
en_zh Dev loss: 0.7687 r:0.4846
Current avg r:0.3174 Best avg r: 0.3647
00:19:10,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:39,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:09,149 root INFO Epoch 15 Global steps: 45600 Train loss: 0.1073
en_de Dev loss: 0.9776 r:0.1549
en_zh Dev loss: 0.8632 r:0.4756
Current avg r:0.3152 Best avg r: 0.3647
00:21:37,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:06,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:36,622 root INFO Epoch 15 Global steps: 45800 Train loss: 0.1182
en_de Dev loss: 0.9871 r:0.1592
en_zh Dev loss: 0.8061 r:0.4868
Current avg r:0.3230 Best avg r: 0.3647
00:24:05,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:34,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:04,100 root INFO Epoch 15 Global steps: 46000 Train loss: 0.1174
en_de Dev loss: 0.9644 r:0.1447
en_zh Dev loss: 0.8343 r:0.4825
Current avg r:0.3136 Best avg r: 0.3647
00:26:32,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:27:01,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:31,608 root INFO Epoch 15 Global steps: 46200 Train loss: 0.1190
en_de Dev loss: 0.9960 r:0.1573
en_zh Dev loss: 0.8200 r:0.4887
Current avg r:0.3230 Best avg r: 0.3647
00:29:00,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:29,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:59,76 root INFO Epoch 15 Global steps: 46400 Train loss: 0.1154
en_de Dev loss: 0.9618 r:0.1661
en_zh Dev loss: 0.7861 r:0.4869
Current avg r:0.3265 Best avg r: 0.3647
00:31:27,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:56,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:26,189 root INFO Epoch 15 Global steps: 46600 Train loss: 0.1192
en_de Dev loss: 0.9415 r:0.1748
en_zh Dev loss: 0.7613 r:0.4813
Current avg r:0.3280 Best avg r: 0.3647
00:33:54,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:23,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:53,623 root INFO Epoch 15 Global steps: 46800 Train loss: 0.1229
en_de Dev loss: 0.9838 r:0.1485
en_zh Dev loss: 0.8087 r:0.4835
Current avg r:0.3160 Best avg r: 0.3647
00:36:22,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:51,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:21,146 root INFO Epoch 15 Global steps: 47000 Train loss: 0.1118
en_de Dev loss: 0.9793 r:0.1712
en_zh Dev loss: 0.8500 r:0.4848
Current avg r:0.3280 Best avg r: 0.3647
00:38:49,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:39:18,852 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:48,588 root INFO Epoch 15 Global steps: 47200 Train loss: 0.1210
en_de Dev loss: 0.9601 r:0.1651
en_zh Dev loss: 0.8233 r:0.4761
Current avg r:0.3206 Best avg r: 0.3647
00:41:17,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:46,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:16,210 root INFO Epoch 15 Global steps: 47400 Train loss: 0.1207
en_de Dev loss: 0.9893 r:0.1624
en_zh Dev loss: 0.8523 r:0.4843
Current avg r:0.3233 Best avg r: 0.3647
00:43:44,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:14,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:43,783 root INFO Epoch 15 Global steps: 47600 Train loss: 0.1199
en_de Dev loss: 1.0118 r:0.1676
en_zh Dev loss: 0.8631 r:0.4799
Current avg r:0.3238 Best avg r: 0.3647
00:46:12,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:41,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:11,260 root INFO Epoch 15 Global steps: 47800 Train loss: 0.1198
en_de Dev loss: 1.0172 r:0.1655
en_zh Dev loss: 0.9048 r:0.4768
Current avg r:0.3212 Best avg r: 0.3647
00:48:39,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:08,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:38,552 root INFO Epoch 15 Global steps: 48000 Train loss: 0.1159
en_de Dev loss: 0.9581 r:0.1543
en_zh Dev loss: 0.7605 r:0.4814
Current avg r:0.3178 Best avg r: 0.3647
00:51:07,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:36,665 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:06,192 root INFO Epoch 16 Global steps: 48200 Train loss: 0.1119
en_de Dev loss: 0.9763 r:0.1587
en_zh Dev loss: 0.8365 r:0.4720
Current avg r:0.3154 Best avg r: 0.3647
00:53:34,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:54:04,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:33,832 root INFO Epoch 16 Global steps: 48400 Train loss: 0.1263
en_de Dev loss: 1.0076 r:0.1481
en_zh Dev loss: 0.8369 r:0.4748
Current avg r:0.3114 Best avg r: 0.3647
00:56:02,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:31,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:01,359 root INFO Epoch 16 Global steps: 48600 Train loss: 0.1151
en_de Dev loss: 0.9814 r:0.1319
en_zh Dev loss: 0.8083 r:0.4767
Current avg r:0.3043 Best avg r: 0.3647
00:58:29,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:59,247 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:29,63 root INFO Epoch 16 Global steps: 48800 Train loss: 0.1185
en_de Dev loss: 0.9615 r:0.1593
en_zh Dev loss: 0.7951 r:0.4787
Current avg r:0.3190 Best avg r: 0.3647
01:00:57,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:01:26,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:56,592 root INFO Epoch 16 Global steps: 49000 Train loss: 0.1064
en_de Dev loss: 1.0040 r:0.1603
en_zh Dev loss: 0.8706 r:0.4761
Current avg r:0.3182 Best avg r: 0.3647
01:03:25,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:54,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:24,64 root INFO Epoch 16 Global steps: 49200 Train loss: 0.1154
en_de Dev loss: 0.9625 r:0.1478
en_zh Dev loss: 0.8253 r:0.4802
Current avg r:0.3140 Best avg r: 0.3647
01:05:52,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:21,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:51,586 root INFO Epoch 16 Global steps: 49400 Train loss: 0.1107
en_de Dev loss: 0.9735 r:0.1673
en_zh Dev loss: 0.8176 r:0.4758
Current avg r:0.3215 Best avg r: 0.3647
01:08:20,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:49,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:09:18,696 root INFO Epoch 16 Global steps: 49600 Train loss: 0.0958
en_de Dev loss: 0.9903 r:0.1759
en_zh Dev loss: 0.8727 r:0.4742
Current avg r:0.3250 Best avg r: 0.3647
01:10:47,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:16,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:46,138 root INFO Epoch 16 Global steps: 49800 Train loss: 0.1094
en_de Dev loss: 0.9342 r:0.1708
en_zh Dev loss: 0.7444 r:0.4813
Current avg r:0.3261 Best avg r: 0.3647
01:13:14,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:43,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:13,735 root INFO Epoch 16 Global steps: 50000 Train loss: 0.1081
en_de Dev loss: 0.9964 r:0.1719
en_zh Dev loss: 0.7729 r:0.4830
Current avg r:0.3274 Best avg r: 0.3647
01:15:42,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:11,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:40,814 root INFO Epoch 16 Global steps: 50200 Train loss: 0.1035
en_de Dev loss: 0.9746 r:0.1742
en_zh Dev loss: 0.7836 r:0.4863
Current avg r:0.3302 Best avg r: 0.3647
01:18:09,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:18:38,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:08,485 root INFO Epoch 16 Global steps: 50400 Train loss: 0.1083
en_de Dev loss: 0.9777 r:0.1762
en_zh Dev loss: 0.7975 r:0.4837
Current avg r:0.3299 Best avg r: 0.3647
01:20:36,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:06,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:21:35,925 root INFO Epoch 16 Global steps: 50600 Train loss: 0.1114
en_de Dev loss: 0.9700 r:0.1690
en_zh Dev loss: 0.7696 r:0.4894
Current avg r:0.3292 Best avg r: 0.3647
01:23:04,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:33,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:03,291 root INFO Epoch 16 Global steps: 50800 Train loss: 0.1008
en_de Dev loss: 0.9782 r:0.1456
en_zh Dev loss: 0.7942 r:0.4865
Current avg r:0.3160 Best avg r: 0.3647
01:25:31,810 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:26:01,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:30,755 root INFO Epoch 16 Global steps: 51000 Train loss: 0.1012
en_de Dev loss: 0.9598 r:0.1513
en_zh Dev loss: 0.7982 r:0.4809
Current avg r:0.3161 Best avg r: 0.3647
01:27:59,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:28,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:58,475 root INFO Epoch 17 Global steps: 51200 Train loss: 0.1050
en_de Dev loss: 0.9826 r:0.1463
en_zh Dev loss: 0.8035 r:0.4765
Current avg r:0.3114 Best avg r: 0.3647
01:30:26,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:56,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:31:25,740 root INFO Epoch 17 Global steps: 51400 Train loss: 0.0929
en_de Dev loss: 1.0357 r:0.1529
en_zh Dev loss: 0.8941 r:0.4768
Current avg r:0.3148 Best avg r: 0.3647
01:32:54,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:33:23,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:33:53,316 root INFO Epoch 17 Global steps: 51600 Train loss: 0.0981
en_de Dev loss: 0.9661 r:0.1694
en_zh Dev loss: 0.7724 r:0.4868
Current avg r:0.3281 Best avg r: 0.3647
01:35:21,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:50,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:20,946 root INFO Epoch 17 Global steps: 51800 Train loss: 0.0916
en_de Dev loss: 0.9986 r:0.1383
en_zh Dev loss: 0.8169 r:0.4822
Current avg r:0.3102 Best avg r: 0.3647
