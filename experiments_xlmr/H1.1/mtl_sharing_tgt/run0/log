14:43:41,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:11,610 root INFO 
id:ro_en cur r: 0.5054 best r: 0.5054
14:44:41,579 root INFO 
id:et_en cur r: 0.3826 best r: 0.3826
14:45:11,772 root INFO 
id:si_en cur r: 0.4420 best r: 0.4420
14:45:41,942 root INFO 
id:ne_en cur r: 0.4976 best r: 0.4976
14:46:11,887 root INFO 
id:ru_en cur r: 0.5972 best r: 0.5972
14:46:11,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:27,116 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:47:27,123 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
14:47:27,127 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
14:47:27,132 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:47:27,138 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:48:42,447 root INFO Epoch 0 Global steps: 500 Train loss: 0.9012
ro_en Dev loss: 0.7133 r:0.5470
et_en Dev loss: 0.6683 r:0.4280
si_en Dev loss: 0.7655 r:0.4281
ne_en Dev loss: 0.6859 r:0.4730
ru_en Dev loss: 0.6284 r:0.6166
Current avg r:0.4986 Best avg r: 0.4986
14:52:27,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:57,414 root INFO 
id:ro_en cur r: 0.5500 best r: 0.5500
14:53:27,686 root INFO 
id:et_en cur r: 0.4379 best r: 0.4379
14:54:13,82 root INFO 
id:ne_en cur r: 0.5312 best r: 0.5312
14:54:28,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:43,606 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:55:43,612 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
14:55:43,617 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
14:55:43,620 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:55:43,625 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:56:59,149 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8546
ro_en Dev loss: 0.6728 r:0.5771
et_en Dev loss: 0.6211 r:0.4178
si_en Dev loss: 0.7537 r:0.4138
ne_en Dev loss: 0.6184 r:0.5100
ru_en Dev loss: 0.5780 r:0.6300
Current avg r:0.5097 Best avg r: 0.5097
15:00:45,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:15,250 root INFO 
id:ro_en cur r: 0.5875 best r: 0.5875
15:01:45,538 root INFO 
id:et_en cur r: 0.4809 best r: 0.4809
15:02:30,997 root INFO 
id:ne_en cur r: 0.5363 best r: 0.5363
15:03:01,172 root INFO 
id:ru_en cur r: 0.5985 best r: 0.5985
15:03:01,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:17,470 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:04:17,476 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
15:04:17,480 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
15:04:17,484 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:04:17,489 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:05:33,502 root INFO Epoch 0 Global steps: 1500 Train loss: 0.7966
ro_en Dev loss: 0.6189 r:0.6126
et_en Dev loss: 0.5765 r:0.4747
si_en Dev loss: 0.8587 r:0.3809
ne_en Dev loss: 0.6301 r:0.4975
ru_en Dev loss: 0.5233 r:0.6513
Current avg r:0.5234 Best avg r: 0.5234
15:09:19,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:49,689 root INFO 
id:ro_en cur r: 0.6060 best r: 0.6060
15:10:20,225 root INFO 
id:et_en cur r: 0.4946 best r: 0.4946
15:11:06,111 root INFO 
id:ne_en cur r: 0.5623 best r: 0.5623
15:11:36,290 root INFO 
id:ru_en cur r: 0.6097 best r: 0.6097
15:11:36,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:52,53 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:12:52,59 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
15:12:52,63 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
15:12:52,68 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:12:52,72 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:14:08,24 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7145
ro_en Dev loss: 0.6124 r:0.6267
et_en Dev loss: 0.5671 r:0.5172
si_en Dev loss: 0.8692 r:0.4212
ne_en Dev loss: 0.7605 r:0.4655
ru_en Dev loss: 0.5981 r:0.6380
Current avg r:0.5337 Best avg r: 0.5337
15:17:53,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:24,106 root INFO 
id:ro_en cur r: 0.6890 best r: 0.6890
15:18:54,652 root INFO 
id:et_en cur r: 0.5975 best r: 0.5975
15:19:24,957 root INFO 
id:si_en cur r: 0.4985 best r: 0.4985
15:19:55,200 root INFO 
id:ne_en cur r: 0.6545 best r: 0.6545
15:20:25,608 root INFO 
id:ru_en cur r: 0.6966 best r: 0.6966
15:20:25,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:41,297 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:21:41,302 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
15:21:41,307 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
15:21:41,311 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:21:41,316 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:22:57,12 root INFO Epoch 0 Global steps: 2500 Train loss: 0.6634
ro_en Dev loss: 0.4385 r:0.7019
et_en Dev loss: 0.4406 r:0.6273
si_en Dev loss: 0.6073 r:0.5150
ne_en Dev loss: 0.4779 r:0.6361
ru_en Dev loss: 0.4257 r:0.7161
Current avg r:0.6393 Best avg r: 0.6393
15:26:42,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:12,873 root INFO 
id:ro_en cur r: 0.7050 best r: 0.7050
15:27:43,156 root INFO 
id:et_en cur r: 0.6429 best r: 0.6429
15:28:13,444 root INFO 
id:si_en cur r: 0.5038 best r: 0.5038
15:28:43,724 root INFO 
id:ne_en cur r: 0.6650 best r: 0.6650
15:29:13,833 root INFO 
id:ru_en cur r: 0.7127 best r: 0.7127
15:29:13,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:29,385 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:30:29,391 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
15:30:29,395 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
15:30:29,400 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:30:29,404 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:31:44,959 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6419
ro_en Dev loss: 0.4198 r:0.7176
et_en Dev loss: 0.4151 r:0.6669
si_en Dev loss: 0.5965 r:0.5254
ne_en Dev loss: 0.4527 r:0.6778
ru_en Dev loss: 0.3958 r:0.7329
Current avg r:0.6641 Best avg r: 0.6641
15:35:29,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:59,380 root INFO 
id:ro_en cur r: 0.7175 best r: 0.7175
15:36:59,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:14,151 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6193
ro_en Dev loss: 0.4302 r:0.7372
et_en Dev loss: 0.3991 r:0.6622
si_en Dev loss: 0.6714 r:0.5196
ne_en Dev loss: 0.4776 r:0.6546
ru_en Dev loss: 0.4729 r:0.7256
Current avg r:0.6598 Best avg r: 0.6641
15:41:57,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:12,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:27,372 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:44:27,379 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
15:44:27,384 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
15:44:27,395 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:44:27,399 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:45:42,209 root INFO Epoch 0 Global steps: 4000 Train loss: 0.5895
ro_en Dev loss: 0.5398 r:0.7308
et_en Dev loss: 0.4105 r:0.6763
si_en Dev loss: 0.8045 r:0.5212
ne_en Dev loss: 0.5141 r:0.6631
ru_en Dev loss: 0.4901 r:0.7364
Current avg r:0.6656 Best avg r: 0.6656
15:49:25,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:55,785 root INFO 
id:ro_en cur r: 0.7485 best r: 0.7485
15:50:25,832 root INFO 
id:et_en cur r: 0.6862 best r: 0.6862
15:50:55,916 root INFO 
id:si_en cur r: 0.5410 best r: 0.5410
15:51:25,979 root INFO 
id:ne_en cur r: 0.7047 best r: 0.7047
15:51:55,886 root INFO 
id:ru_en cur r: 0.7331 best r: 0.7331
15:51:55,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:10,906 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:53:10,911 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
15:53:10,916 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
15:53:10,920 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:53:10,923 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:54:26,242 root INFO Epoch 0 Global steps: 4500 Train loss: 0.5893
ro_en Dev loss: 0.3719 r:0.7635
et_en Dev loss: 0.3675 r:0.6993
si_en Dev loss: 0.5971 r:0.5573
ne_en Dev loss: 0.3950 r:0.7086
ru_en Dev loss: 0.3909 r:0.7502
Current avg r:0.6958 Best avg r: 0.6958
15:58:10,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:39,920 root INFO 
id:ro_en cur r: 0.7509 best r: 0.7509
15:59:40,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:54,711 root INFO Epoch 0 Global steps: 5000 Train loss: 0.5683
ro_en Dev loss: 0.4243 r:0.7654
et_en Dev loss: 0.3804 r:0.6905
si_en Dev loss: 0.6710 r:0.5658
ne_en Dev loss: 0.4875 r:0.6974
ru_en Dev loss: 0.5241 r:0.7199
Current avg r:0.6878 Best avg r: 0.6958
16:04:38,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:08,619 root INFO 
id:ro_en cur r: 0.7607 best r: 0.7607
16:05:53,820 root INFO 
id:si_en cur r: 0.5506 best r: 0.5506
16:06:23,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:38,910 root INFO Epoch 0 Global steps: 5500 Train loss: 0.5561
ro_en Dev loss: 0.4432 r:0.7775
et_en Dev loss: 0.3826 r:0.6923
si_en Dev loss: 0.7441 r:0.5696
ne_en Dev loss: 0.4722 r:0.7053
ru_en Dev loss: 0.5170 r:0.7311
Current avg r:0.6952 Best avg r: 0.6958
16:11:22,818 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:52,811 root INFO 
id:ro_en cur r: 0.7664 best r: 0.7664
16:12:52,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:08,183 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5495
ro_en Dev loss: 0.4802 r:0.7804
et_en Dev loss: 0.4200 r:0.6951
si_en Dev loss: 0.8478 r:0.5593
ne_en Dev loss: 0.5639 r:0.7074
ru_en Dev loss: 0.5964 r:0.7277
Current avg r:0.6940 Best avg r: 0.6958
16:17:52,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:22,160 root INFO 
id:ro_en cur r: 0.7786 best r: 0.7786
16:18:52,154 root INFO 
id:et_en cur r: 0.6877 best r: 0.6877
16:19:22,160 root INFO 
id:si_en cur r: 0.5754 best r: 0.5754
16:19:52,162 root INFO 
id:ne_en cur r: 0.7268 best r: 0.7268
16:20:07,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:21,894 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:21:21,901 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
16:21:21,907 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
16:21:21,911 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:21:21,916 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:22:37,126 root INFO Epoch 0 Global steps: 6500 Train loss: 0.5346
ro_en Dev loss: 0.3434 r:0.7846
et_en Dev loss: 0.3692 r:0.6957
si_en Dev loss: 0.5961 r:0.5803
ne_en Dev loss: 0.3759 r:0.7264
ru_en Dev loss: 0.4196 r:0.7306
Current avg r:0.7035 Best avg r: 0.7035
16:26:20,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:51,123 root INFO 
id:ro_en cur r: 0.7915 best r: 0.7915
16:27:36,105 root INFO 
id:si_en cur r: 0.5838 best r: 0.5838
16:28:06,96 root INFO 
id:ne_en cur r: 0.7282 best r: 0.7282
16:28:20,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:35,782 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:29:35,788 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
16:29:35,792 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
16:29:35,797 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:29:35,802 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:30:50,794 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5197
ro_en Dev loss: 0.3648 r:0.7925
et_en Dev loss: 0.3726 r:0.6969
si_en Dev loss: 0.6507 r:0.5896
ne_en Dev loss: 0.4033 r:0.7305
ru_en Dev loss: 0.4921 r:0.7226
Current avg r:0.7064 Best avg r: 0.7064
16:34:34,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:50,42 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:04,848 root INFO Epoch 0 Global steps: 7500 Train loss: 0.5002
ro_en Dev loss: 0.3829 r:0.7900
et_en Dev loss: 0.3864 r:0.6925
si_en Dev loss: 0.6999 r:0.5805
ne_en Dev loss: 0.4442 r:0.7249
ru_en Dev loss: 0.4922 r:0.7303
Current avg r:0.7037 Best avg r: 0.7064
16:40:49,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:19,189 root INFO 
id:ro_en cur r: 0.7927 best r: 0.7927
16:41:49,392 root INFO 
id:et_en cur r: 0.7035 best r: 0.7035
16:42:19,380 root INFO 
id:si_en cur r: 0.5839 best r: 0.5839
16:42:49,368 root INFO 
id:ne_en cur r: 0.7374 best r: 0.7374
16:43:19,127 root INFO 
id:ru_en cur r: 0.7448 best r: 0.7448
16:43:19,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:33,925 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:44:33,938 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
16:44:33,942 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
16:44:33,947 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:44:33,952 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:45:48,766 root INFO Epoch 1 Global steps: 8000 Train loss: 0.4793
ro_en Dev loss: 0.3622 r:0.7968
et_en Dev loss: 0.3545 r:0.7124
si_en Dev loss: 0.6367 r:0.5901
ne_en Dev loss: 0.4111 r:0.7327
ru_en Dev loss: 0.4518 r:0.7512
Current avg r:0.7167 Best avg r: 0.7167
16:49:32,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:01,966 root INFO 
id:ro_en cur r: 0.7985 best r: 0.7985
16:51:01,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:16,834 root INFO Epoch 1 Global steps: 8500 Train loss: 0.4679
ro_en Dev loss: 0.3956 r:0.7981
et_en Dev loss: 0.3929 r:0.7061
si_en Dev loss: 0.7300 r:0.5852
ne_en Dev loss: 0.4441 r:0.7278
ru_en Dev loss: 0.5026 r:0.7496
Current avg r:0.7134 Best avg r: 0.7167
16:56:00,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:59,977 root INFO 
id:si_en cur r: 0.5841 best r: 0.5841
16:57:29,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:44,490 root INFO Epoch 1 Global steps: 9000 Train loss: 0.4660
ro_en Dev loss: 0.3796 r:0.8002
et_en Dev loss: 0.3780 r:0.7014
si_en Dev loss: 0.7042 r:0.5892
ne_en Dev loss: 0.4366 r:0.7298
ru_en Dev loss: 0.4808 r:0.7360
Current avg r:0.7113 Best avg r: 0.7167
17:02:28,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:57,923 root INFO 
id:ro_en cur r: 0.8085 best r: 0.8085
17:03:43,126 root INFO 
id:si_en cur r: 0.6051 best r: 0.6051
17:04:13,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:27,800 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:05:27,806 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
17:05:27,811 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
17:05:27,815 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:05:27,820 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:06:42,534 root INFO Epoch 1 Global steps: 9500 Train loss: 0.4735
ro_en Dev loss: 0.3474 r:0.8104
et_en Dev loss: 0.3710 r:0.7075
si_en Dev loss: 0.6314 r:0.6111
ne_en Dev loss: 0.4363 r:0.7360
ru_en Dev loss: 0.4924 r:0.7406
Current avg r:0.7211 Best avg r: 0.7211
17:10:26,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:41,393 root INFO 
id:ne_en cur r: 0.7392 best r: 0.7392
17:11:56,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:11,422 root INFO Epoch 1 Global steps: 10000 Train loss: 0.4874
ro_en Dev loss: 0.3221 r:0.8068
et_en Dev loss: 0.3534 r:0.7088
si_en Dev loss: 0.6445 r:0.6073
ne_en Dev loss: 0.4538 r:0.7384
ru_en Dev loss: 0.4526 r:0.7399
Current avg r:0.7202 Best avg r: 0.7211
17:16:54,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:10,88 root INFO 
id:ne_en cur r: 0.7421 best r: 0.7421
17:18:25,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:40,319 root INFO Epoch 1 Global steps: 10500 Train loss: 0.4677
ro_en Dev loss: 0.3838 r:0.8064
et_en Dev loss: 0.3784 r:0.7084
si_en Dev loss: 0.7330 r:0.5983
ne_en Dev loss: 0.4376 r:0.7390
ru_en Dev loss: 0.5062 r:0.7411
Current avg r:0.7186 Best avg r: 0.7211
17:23:23,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:53,745 root INFO 
id:ro_en cur r: 0.8116 best r: 0.8116
17:24:23,489 root INFO 
id:et_en cur r: 0.7053 best r: 0.7053
17:25:08,416 root INFO 
id:ne_en cur r: 0.7500 best r: 0.7500
17:25:38,297 root INFO 
id:ru_en cur r: 0.7500 best r: 0.7500
17:25:38,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:53,211 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:26:53,217 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
17:26:53,222 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
17:26:53,227 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:26:53,231 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:28:08,202 root INFO Epoch 1 Global steps: 11000 Train loss: 0.4609
ro_en Dev loss: 0.3690 r:0.8080
et_en Dev loss: 0.3702 r:0.7110
si_en Dev loss: 0.7471 r:0.6027
ne_en Dev loss: 0.4664 r:0.7444
ru_en Dev loss: 0.4464 r:0.7536
Current avg r:0.7239 Best avg r: 0.7239
17:31:51,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:21,508 root INFO 
id:ro_en cur r: 0.8133 best r: 0.8133
17:32:51,513 root INFO 
id:et_en cur r: 0.7195 best r: 0.7195
17:33:21,535 root INFO 
id:si_en cur r: 0.6053 best r: 0.6053
17:33:51,552 root INFO 
id:ne_en cur r: 0.7570 best r: 0.7570
17:34:21,114 root INFO 
id:ru_en cur r: 0.7652 best r: 0.7652
17:34:21,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:35,875 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:35:35,881 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
17:35:35,887 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
17:35:35,939 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:35:35,944 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:36:51,218 root INFO Epoch 1 Global steps: 11500 Train loss: 0.4565
ro_en Dev loss: 0.3139 r:0.8118
et_en Dev loss: 0.3462 r:0.7252
si_en Dev loss: 0.5742 r:0.6168
ne_en Dev loss: 0.3782 r:0.7489
ru_en Dev loss: 0.3842 r:0.7664
Current avg r:0.7338 Best avg r: 0.7338
17:40:35,77 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:49,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:04,452 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4617
ro_en Dev loss: 0.3295 r:0.8113
et_en Dev loss: 0.3533 r:0.7157
si_en Dev loss: 0.6253 r:0.6051
ne_en Dev loss: 0.4143 r:0.7457
ru_en Dev loss: 0.4169 r:0.7526
Current avg r:0.7261 Best avg r: 0.7338
17:46:48,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:03,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:18,184 root INFO Epoch 1 Global steps: 12500 Train loss: 0.4524
ro_en Dev loss: 0.3439 r:0.8073
et_en Dev loss: 0.3611 r:0.7107
si_en Dev loss: 0.6947 r:0.6011
ne_en Dev loss: 0.4941 r:0.7388
ru_en Dev loss: 0.4702 r:0.7479
Current avg r:0.7212 Best avg r: 0.7338
17:53:01,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:16,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:32,207 root INFO Epoch 1 Global steps: 13000 Train loss: 0.4586
ro_en Dev loss: 0.4004 r:0.8061
et_en Dev loss: 0.4062 r:0.7062
si_en Dev loss: 0.7691 r:0.5993
ne_en Dev loss: 0.4608 r:0.7486
ru_en Dev loss: 0.5084 r:0.7512
Current avg r:0.7223 Best avg r: 0.7338
17:59:16,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:45,803 root INFO 
id:ro_en cur r: 0.8194 best r: 0.8194
18:00:45,794 root INFO 
id:ne_en cur r: 0.7571 best r: 0.7571
18:01:00,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:15,606 root INFO Epoch 1 Global steps: 13500 Train loss: 0.4533
ro_en Dev loss: 0.3081 r:0.8207
et_en Dev loss: 0.3485 r:0.7174
si_en Dev loss: 0.6916 r:0.6051
ne_en Dev loss: 0.4404 r:0.7542
ru_en Dev loss: 0.3972 r:0.7655
Current avg r:0.7326 Best avg r: 0.7338
18:05:59,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:14,416 root INFO 
id:ne_en cur r: 0.7590 best r: 0.7590
18:07:29,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:44,403 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4297
ro_en Dev loss: 0.4215 r:0.8114
et_en Dev loss: 0.3999 r:0.6991
si_en Dev loss: 0.8232 r:0.5985
ne_en Dev loss: 0.4460 r:0.7568
ru_en Dev loss: 0.5384 r:0.7383
Current avg r:0.7208 Best avg r: 0.7338
18:12:28,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:28,355 root INFO 
id:si_en cur r: 0.6075 best r: 0.6075
18:13:58,651 root INFO 
id:ne_en cur r: 0.7686 best r: 0.7686
18:14:13,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:28,681 root INFO Epoch 1 Global steps: 14500 Train loss: 0.4673
ro_en Dev loss: 0.3296 r:0.8161
et_en Dev loss: 0.3643 r:0.7123
si_en Dev loss: 0.6510 r:0.6136
ne_en Dev loss: 0.3719 r:0.7656
ru_en Dev loss: 0.4336 r:0.7578
Current avg r:0.7331 Best avg r: 0.7338
18:19:12,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:26,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:41,996 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4345
ro_en Dev loss: 0.3764 r:0.8110
et_en Dev loss: 0.3833 r:0.6997
si_en Dev loss: 0.7346 r:0.6024
ne_en Dev loss: 0.4552 r:0.7570
ru_en Dev loss: 0.4923 r:0.7458
Current avg r:0.7232 Best avg r: 0.7338
18:25:26,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:41,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:56,946 root INFO Epoch 2 Global steps: 15500 Train loss: 0.3976
ro_en Dev loss: 0.3852 r:0.8103
et_en Dev loss: 0.3898 r:0.7015
si_en Dev loss: 0.7800 r:0.5993
ne_en Dev loss: 0.4870 r:0.7527
ru_en Dev loss: 0.4800 r:0.7435
Current avg r:0.7215 Best avg r: 0.7338
18:31:40,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:10,806 root INFO 
id:ro_en cur r: 0.8251 best r: 0.8251
18:32:56,49 root INFO 
id:si_en cur r: 0.6095 best r: 0.6095
18:33:25,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:40,914 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:34:40,921 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
18:34:40,926 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
18:34:40,930 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:34:40,937 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:35:55,909 root INFO Epoch 2 Global steps: 16000 Train loss: 0.3988
ro_en Dev loss: 0.3320 r:0.8246
et_en Dev loss: 0.3591 r:0.7135
si_en Dev loss: 0.7465 r:0.6173
ne_en Dev loss: 0.4488 r:0.7599
ru_en Dev loss: 0.4539 r:0.7568
Current avg r:0.7344 Best avg r: 0.7344
18:39:39,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:54,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:09,720 root INFO Epoch 2 Global steps: 16500 Train loss: 0.4157
ro_en Dev loss: 0.3257 r:0.8189
et_en Dev loss: 0.3704 r:0.7032
si_en Dev loss: 0.7524 r:0.6036
ne_en Dev loss: 0.4755 r:0.7564
ru_en Dev loss: 0.4213 r:0.7564
Current avg r:0.7277 Best avg r: 0.7344
18:45:53,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:08,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:23,678 root INFO Epoch 2 Global steps: 17000 Train loss: 0.3958
ro_en Dev loss: 0.3539 r:0.8144
et_en Dev loss: 0.3810 r:0.6972
si_en Dev loss: 0.7901 r:0.5932
ne_en Dev loss: 0.4526 r:0.7552
ru_en Dev loss: 0.4448 r:0.7460
Current avg r:0.7212 Best avg r: 0.7344
18:52:07,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:22,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:37,736 root INFO Epoch 2 Global steps: 17500 Train loss: 0.3937
ro_en Dev loss: 0.3444 r:0.8174
et_en Dev loss: 0.3778 r:0.7041
si_en Dev loss: 0.7322 r:0.6011
ne_en Dev loss: 0.4269 r:0.7556
ru_en Dev loss: 0.4345 r:0.7535
Current avg r:0.7263 Best avg r: 0.7344
18:58:21,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:36,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:51,326 root INFO Epoch 2 Global steps: 18000 Train loss: 0.4059
ro_en Dev loss: 0.3808 r:0.8120
et_en Dev loss: 0.3933 r:0.6991
si_en Dev loss: 0.9165 r:0.5865
ne_en Dev loss: 0.6191 r:0.7525
ru_en Dev loss: 0.5528 r:0.7169
Current avg r:0.7134 Best avg r: 0.7344
19:04:35,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:50,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:04,986 root INFO Epoch 2 Global steps: 18500 Train loss: 0.4123
ro_en Dev loss: 0.3598 r:0.8199
et_en Dev loss: 0.3843 r:0.7048
si_en Dev loss: 0.7595 r:0.6034
ne_en Dev loss: 0.4896 r:0.7579
ru_en Dev loss: 0.4963 r:0.7440
Current avg r:0.7260 Best avg r: 0.7344
19:10:48,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:03,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:18,229 root INFO Epoch 2 Global steps: 19000 Train loss: 0.3897
ro_en Dev loss: 0.3202 r:0.8220
et_en Dev loss: 0.3678 r:0.7046
si_en Dev loss: 0.7141 r:0.6040
ne_en Dev loss: 0.4561 r:0.7621
ru_en Dev loss: 0.3981 r:0.7601
Current avg r:0.7306 Best avg r: 0.7344
19:17:01,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:16,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:31,364 root INFO Epoch 2 Global steps: 19500 Train loss: 0.3886
ro_en Dev loss: 0.3469 r:0.8196
et_en Dev loss: 0.3824 r:0.7043
si_en Dev loss: 0.6908 r:0.6125
ne_en Dev loss: 0.4841 r:0.7536
ru_en Dev loss: 0.4694 r:0.7404
Current avg r:0.7261 Best avg r: 0.7344
19:23:14,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:44,333 root INFO 
id:ro_en cur r: 0.8275 best r: 0.8275
19:24:29,388 root INFO 
id:si_en cur r: 0.6139 best r: 0.6139
19:24:59,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:14,357 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
19:26:14,362 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
19:26:14,367 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
19:26:14,372 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
19:26:14,376 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
19:27:29,353 root INFO Epoch 2 Global steps: 20000 Train loss: 0.4012
ro_en Dev loss: 0.3059 r:0.8270
et_en Dev loss: 0.3909 r:0.7081
si_en Dev loss: 0.6167 r:0.6214
ne_en Dev loss: 0.3741 r:0.7617
ru_en Dev loss: 0.4005 r:0.7578
Current avg r:0.7352 Best avg r: 0.7352
19:31:12,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:12,307 root INFO 
id:si_en cur r: 0.6192 best r: 0.6192
19:32:42,220 root INFO 
id:ne_en cur r: 0.7756 best r: 0.7756
19:32:57,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:12,12 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
19:34:12,18 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
19:34:12,22 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
19:34:12,26 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
19:34:12,30 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
19:35:27,123 root INFO Epoch 2 Global steps: 20500 Train loss: 0.3938
ro_en Dev loss: 0.3397 r:0.8252
et_en Dev loss: 0.3683 r:0.7142
si_en Dev loss: 0.7096 r:0.6205
ne_en Dev loss: 0.4577 r:0.7683
ru_en Dev loss: 0.4293 r:0.7597
Current avg r:0.7376 Best avg r: 0.7376
19:39:10,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:24,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:39,595 root INFO Epoch 2 Global steps: 21000 Train loss: 0.3897
ro_en Dev loss: 0.3372 r:0.8204
et_en Dev loss: 0.4003 r:0.7079
si_en Dev loss: 0.7329 r:0.6121
ne_en Dev loss: 0.4324 r:0.7561
ru_en Dev loss: 0.4427 r:0.7563
Current avg r:0.7305 Best avg r: 0.7376
19:45:23,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:37,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:52,694 root INFO Epoch 2 Global steps: 21500 Train loss: 0.3915
ro_en Dev loss: 0.3190 r:0.8222
et_en Dev loss: 0.3832 r:0.7145
si_en Dev loss: 0.6276 r:0.6166
ne_en Dev loss: 0.3554 r:0.7594
ru_en Dev loss: 0.4123 r:0.7637
Current avg r:0.7353 Best avg r: 0.7376
19:51:36,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:50,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:05,649 root INFO Epoch 2 Global steps: 22000 Train loss: 0.3844
ro_en Dev loss: 0.3243 r:0.8206
et_en Dev loss: 0.3711 r:0.7134
si_en Dev loss: 0.7574 r:0.6057
ne_en Dev loss: 0.4377 r:0.7555
ru_en Dev loss: 0.4295 r:0.7587
Current avg r:0.7308 Best avg r: 0.7376
19:57:49,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:03,553 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:18,245 root INFO Epoch 2 Global steps: 22500 Train loss: 0.3605
ro_en Dev loss: 0.3565 r:0.8207
et_en Dev loss: 0.3751 r:0.7112
si_en Dev loss: 0.7940 r:0.6102
ne_en Dev loss: 0.4969 r:0.7553
ru_en Dev loss: 0.4960 r:0.7414
Current avg r:0.7278 Best avg r: 0.7376
20:04:02,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:17,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:31,755 root INFO Epoch 3 Global steps: 23000 Train loss: 0.3472
ro_en Dev loss: 0.3369 r:0.8152
et_en Dev loss: 0.3839 r:0.7023
si_en Dev loss: 0.7008 r:0.6041
ne_en Dev loss: 0.4273 r:0.7563
ru_en Dev loss: 0.4796 r:0.7349
Current avg r:0.7226 Best avg r: 0.7376
20:10:15,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:29,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:45,27 root INFO Epoch 3 Global steps: 23500 Train loss: 0.3271
ro_en Dev loss: 0.3052 r:0.8232
et_en Dev loss: 0.3694 r:0.7107
si_en Dev loss: 0.6864 r:0.6148
ne_en Dev loss: 0.3999 r:0.7614
ru_en Dev loss: 0.4412 r:0.7482
Current avg r:0.7317 Best avg r: 0.7376
20:16:28,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:42,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:57,806 root INFO Epoch 3 Global steps: 24000 Train loss: 0.3583
ro_en Dev loss: 0.3168 r:0.8208
et_en Dev loss: 0.3912 r:0.7006
si_en Dev loss: 0.6910 r:0.6114
ne_en Dev loss: 0.3880 r:0.7580
ru_en Dev loss: 0.4344 r:0.7480
Current avg r:0.7278 Best avg r: 0.7376
20:22:41,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:55,712 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:10,169 root INFO Epoch 3 Global steps: 24500 Train loss: 0.3417
ro_en Dev loss: 0.3313 r:0.8193
et_en Dev loss: 0.3777 r:0.7013
si_en Dev loss: 0.7675 r:0.6011
ne_en Dev loss: 0.5162 r:0.7566
ru_en Dev loss: 0.4665 r:0.7487
Current avg r:0.7254 Best avg r: 0.7376
20:28:53,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:08,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:23,536 root INFO Epoch 3 Global steps: 25000 Train loss: 0.3256
ro_en Dev loss: 0.3561 r:0.8157
et_en Dev loss: 0.3929 r:0.6992
si_en Dev loss: 0.8786 r:0.5942
ne_en Dev loss: 0.5555 r:0.7461
ru_en Dev loss: 0.5445 r:0.7285
Current avg r:0.7167 Best avg r: 0.7376
20:35:07,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:21,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:37,205 root INFO Epoch 3 Global steps: 25500 Train loss: 0.3368
ro_en Dev loss: 0.3195 r:0.8163
et_en Dev loss: 0.3854 r:0.7029
si_en Dev loss: 0.6807 r:0.6035
ne_en Dev loss: 0.3978 r:0.7557
ru_en Dev loss: 0.4553 r:0.7327
Current avg r:0.7222 Best avg r: 0.7376
20:41:20,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:35,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:50,220 root INFO Epoch 3 Global steps: 26000 Train loss: 0.3307
ro_en Dev loss: 0.3554 r:0.8128
et_en Dev loss: 0.3910 r:0.7013
si_en Dev loss: 0.7268 r:0.6025
ne_en Dev loss: 0.4448 r:0.7526
ru_en Dev loss: 0.4311 r:0.7541
Current avg r:0.7247 Best avg r: 0.7376
20:47:33,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:48,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:03,743 root INFO Epoch 3 Global steps: 26500 Train loss: 0.3334
ro_en Dev loss: 0.3622 r:0.8175
et_en Dev loss: 0.4073 r:0.6991
si_en Dev loss: 0.7470 r:0.6100
ne_en Dev loss: 0.4414 r:0.7584
ru_en Dev loss: 0.4867 r:0.7432
Current avg r:0.7256 Best avg r: 0.7376
20:53:47,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:02,247 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:17,48 root INFO Epoch 3 Global steps: 27000 Train loss: 0.3246
ro_en Dev loss: 0.3385 r:0.8177
et_en Dev loss: 0.3995 r:0.6938
si_en Dev loss: 0.6593 r:0.6134
ne_en Dev loss: 0.4061 r:0.7621
ru_en Dev loss: 0.4739 r:0.7329
Current avg r:0.7240 Best avg r: 0.7376
21:00:00,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:15,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:29,901 root INFO Epoch 3 Global steps: 27500 Train loss: 0.3520
ro_en Dev loss: 0.3486 r:0.8136
et_en Dev loss: 0.3907 r:0.6912
si_en Dev loss: 0.7951 r:0.5989
ne_en Dev loss: 0.5248 r:0.7603
ru_en Dev loss: 0.5130 r:0.7204
Current avg r:0.7169 Best avg r: 0.7376
21:06:13,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:28,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:43,307 root INFO Epoch 3 Global steps: 28000 Train loss: 0.3404
ro_en Dev loss: 0.3425 r:0.8204
et_en Dev loss: 0.3948 r:0.7027
si_en Dev loss: 0.7406 r:0.6008
ne_en Dev loss: 0.4281 r:0.7617
ru_en Dev loss: 0.4712 r:0.7431
Current avg r:0.7258 Best avg r: 0.7376
21:12:26,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:41,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:56,721 root INFO Epoch 3 Global steps: 28500 Train loss: 0.3485
ro_en Dev loss: 0.3293 r:0.8157
et_en Dev loss: 0.4097 r:0.7027
si_en Dev loss: 0.6740 r:0.6007
ne_en Dev loss: 0.3975 r:0.7592
ru_en Dev loss: 0.4195 r:0.7467
Current avg r:0.7250 Best avg r: 0.7376
21:18:40,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:54,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:09,707 root INFO Epoch 3 Global steps: 29000 Train loss: 0.3187
ro_en Dev loss: 0.3367 r:0.8179
et_en Dev loss: 0.4163 r:0.7049
si_en Dev loss: 0.6372 r:0.6124
ne_en Dev loss: 0.3880 r:0.7507
ru_en Dev loss: 0.4265 r:0.7524
Current avg r:0.7276 Best avg r: 0.7376
21:24:53,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:26:08,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:22,302 root INFO Epoch 3 Global steps: 29500 Train loss: 0.3394
ro_en Dev loss: 0.3249 r:0.8177
et_en Dev loss: 0.3826 r:0.7007
si_en Dev loss: 0.6809 r:0.6016
ne_en Dev loss: 0.4047 r:0.7497
ru_en Dev loss: 0.4259 r:0.7511
Current avg r:0.7242 Best avg r: 0.7376
21:31:06,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:20,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:35,481 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3133
ro_en Dev loss: 0.3250 r:0.8203
et_en Dev loss: 0.3986 r:0.7070
si_en Dev loss: 0.6431 r:0.6109
ne_en Dev loss: 0.3952 r:0.7569
ru_en Dev loss: 0.4079 r:0.7644
Current avg r:0.7319 Best avg r: 0.7376
21:37:19,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:34,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:49,163 root INFO Epoch 4 Global steps: 30500 Train loss: 0.2919
ro_en Dev loss: 0.3703 r:0.8148
et_en Dev loss: 0.4140 r:0.6916
si_en Dev loss: 0.8027 r:0.5908
ne_en Dev loss: 0.5269 r:0.7547
ru_en Dev loss: 0.4828 r:0.7374
Current avg r:0.7179 Best avg r: 0.7376
21:43:32,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:47,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:01,669 root INFO Epoch 4 Global steps: 31000 Train loss: 0.2948
ro_en Dev loss: 0.3356 r:0.8231
et_en Dev loss: 0.3935 r:0.7056
si_en Dev loss: 0.7422 r:0.6062
ne_en Dev loss: 0.4050 r:0.7592
ru_en Dev loss: 0.4660 r:0.7494
Current avg r:0.7287 Best avg r: 0.7376
21:49:45,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:59,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:14,817 root INFO Epoch 4 Global steps: 31500 Train loss: 0.2849
ro_en Dev loss: 0.3596 r:0.8201
et_en Dev loss: 0.4105 r:0.6954
si_en Dev loss: 0.7889 r:0.5986
ne_en Dev loss: 0.4791 r:0.7550
ru_en Dev loss: 0.5144 r:0.7380
Current avg r:0.7214 Best avg r: 0.7376
21:55:58,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:13,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:28,130 root INFO Epoch 4 Global steps: 32000 Train loss: 0.2833
ro_en Dev loss: 0.3578 r:0.8206
et_en Dev loss: 0.3949 r:0.6983
si_en Dev loss: 0.7843 r:0.5992
ne_en Dev loss: 0.5498 r:0.7547
ru_en Dev loss: 0.4697 r:0.7479
Current avg r:0.7242 Best avg r: 0.7376
22:02:11,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:26,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:40,488 root INFO Epoch 4 Global steps: 32500 Train loss: 0.2905
ro_en Dev loss: 0.3327 r:0.8187
et_en Dev loss: 0.4144 r:0.6992
si_en Dev loss: 0.6710 r:0.6061
ne_en Dev loss: 0.4350 r:0.7489
ru_en Dev loss: 0.4458 r:0.7442
Current avg r:0.7234 Best avg r: 0.7376
22:08:24,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:39,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:53,900 root INFO Epoch 4 Global steps: 33000 Train loss: 0.2898
ro_en Dev loss: 0.3465 r:0.8190
et_en Dev loss: 0.3994 r:0.6970
si_en Dev loss: 0.7431 r:0.5994
ne_en Dev loss: 0.5147 r:0.7519
ru_en Dev loss: 0.4542 r:0.7425
Current avg r:0.7220 Best avg r: 0.7376
22:14:37,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:52,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:07,8 root INFO Epoch 4 Global steps: 33500 Train loss: 0.2944
ro_en Dev loss: 0.3580 r:0.8246
et_en Dev loss: 0.4110 r:0.7006
si_en Dev loss: 0.7936 r:0.5977
ne_en Dev loss: 0.5001 r:0.7525
ru_en Dev loss: 0.4773 r:0.7511
Current avg r:0.7253 Best avg r: 0.7376
22:20:50,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:05,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:19,659 root INFO Epoch 4 Global steps: 34000 Train loss: 0.3003
ro_en Dev loss: 0.3324 r:0.8257
et_en Dev loss: 0.3910 r:0.7025
si_en Dev loss: 0.7899 r:0.5972
ne_en Dev loss: 0.4628 r:0.7555
ru_en Dev loss: 0.4964 r:0.7402
Current avg r:0.7242 Best avg r: 0.7376
22:27:03,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:18,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:32,760 root INFO Epoch 4 Global steps: 34500 Train loss: 0.2918
ro_en Dev loss: 0.3520 r:0.8196
et_en Dev loss: 0.3903 r:0.7021
si_en Dev loss: 0.7652 r:0.6040
ne_en Dev loss: 0.4270 r:0.7530
ru_en Dev loss: 0.4870 r:0.7380
Current avg r:0.7234 Best avg r: 0.7376
22:33:16,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:31,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:45,909 root INFO Epoch 4 Global steps: 35000 Train loss: 0.2776
ro_en Dev loss: 0.3376 r:0.8177
et_en Dev loss: 0.4273 r:0.6941
si_en Dev loss: 0.7186 r:0.5989
ne_en Dev loss: 0.4315 r:0.7507
ru_en Dev loss: 0.4415 r:0.7416
Current avg r:0.7206 Best avg r: 0.7376
22:39:29,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:43,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:58,777 root INFO Epoch 4 Global steps: 35500 Train loss: 0.2702
ro_en Dev loss: 0.3957 r:0.8159
et_en Dev loss: 0.4358 r:0.6881
si_en Dev loss: 0.9648 r:0.5854
ne_en Dev loss: 0.6401 r:0.7495
ru_en Dev loss: 0.4976 r:0.7407
Current avg r:0.7159 Best avg r: 0.7376
22:45:42,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:56,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:48:10,794 root INFO Epoch 4 Global steps: 36000 Train loss: 0.2749
ro_en Dev loss: 0.3300 r:0.8184
et_en Dev loss: 0.4304 r:0.6943
si_en Dev loss: 0.6830 r:0.5996
ne_en Dev loss: 0.4407 r:0.7514
ru_en Dev loss: 0.4058 r:0.7552
Current avg r:0.7238 Best avg r: 0.7376
22:51:54,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:08,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:23,758 root INFO Epoch 4 Global steps: 36500 Train loss: 0.2859
ro_en Dev loss: 0.3627 r:0.8131
et_en Dev loss: 0.4226 r:0.6955
si_en Dev loss: 0.7576 r:0.5938
ne_en Dev loss: 0.5023 r:0.7450
ru_en Dev loss: 0.4594 r:0.7466
Current avg r:0.7188 Best avg r: 0.7376
22:58:07,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:21,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:36,646 root INFO Epoch 4 Global steps: 37000 Train loss: 0.2800
ro_en Dev loss: 0.3565 r:0.8169
et_en Dev loss: 0.4098 r:0.6964
si_en Dev loss: 0.8194 r:0.5945
ne_en Dev loss: 0.5277 r:0.7549
ru_en Dev loss: 0.5173 r:0.7291
Current avg r:0.7184 Best avg r: 0.7376
23:04:20,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:34,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:49,183 root INFO Epoch 4 Global steps: 37500 Train loss: 0.2665
ro_en Dev loss: 0.3072 r:0.8219
et_en Dev loss: 0.3846 r:0.6990
si_en Dev loss: 0.6878 r:0.6044
ne_en Dev loss: 0.4781 r:0.7503
ru_en Dev loss: 0.4133 r:0.7527
Current avg r:0.7257 Best avg r: 0.7376
23:10:33,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:48,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:02,935 root INFO Epoch 5 Global steps: 38000 Train loss: 0.2430
ro_en Dev loss: 0.3468 r:0.8175
et_en Dev loss: 0.4414 r:0.6906
si_en Dev loss: 0.7091 r:0.5916
ne_en Dev loss: 0.4289 r:0.7484
ru_en Dev loss: 0.4157 r:0.7567
Current avg r:0.7210 Best avg r: 0.7376
23:16:46,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:01,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:16,193 root INFO Epoch 5 Global steps: 38500 Train loss: 0.2460
ro_en Dev loss: 0.3668 r:0.8131
et_en Dev loss: 0.4317 r:0.6801
si_en Dev loss: 0.7438 r:0.5926
ne_en Dev loss: 0.4712 r:0.7465
ru_en Dev loss: 0.4814 r:0.7371
Current avg r:0.7139 Best avg r: 0.7376
23:22:59,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:14,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:29,114 root INFO Epoch 5 Global steps: 39000 Train loss: 0.2545
ro_en Dev loss: 0.3495 r:0.8168
et_en Dev loss: 0.4285 r:0.6806
si_en Dev loss: 0.7764 r:0.5942
ne_en Dev loss: 0.4638 r:0.7488
ru_en Dev loss: 0.4557 r:0.7396
Current avg r:0.7160 Best avg r: 0.7376
23:29:12,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:27,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:42,432 root INFO Epoch 5 Global steps: 39500 Train loss: 0.2396
ro_en Dev loss: 0.3650 r:0.8148
et_en Dev loss: 0.4442 r:0.6856
si_en Dev loss: 0.7853 r:0.5884
ne_en Dev loss: 0.4552 r:0.7496
ru_en Dev loss: 0.4587 r:0.7393
Current avg r:0.7155 Best avg r: 0.7376
23:35:26,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:41,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:56,37 root INFO Epoch 5 Global steps: 40000 Train loss: 0.2389
ro_en Dev loss: 0.3273 r:0.8157
et_en Dev loss: 0.4284 r:0.6862
si_en Dev loss: 0.7030 r:0.5919
ne_en Dev loss: 0.4618 r:0.7440
ru_en Dev loss: 0.4484 r:0.7356
Current avg r:0.7147 Best avg r: 0.7376
23:41:39,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:54,466 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:09,513 root INFO Epoch 5 Global steps: 40500 Train loss: 0.2270
ro_en Dev loss: 0.3415 r:0.8169
et_en Dev loss: 0.4436 r:0.6747
si_en Dev loss: 0.8613 r:0.5742
ne_en Dev loss: 0.5654 r:0.7416
ru_en Dev loss: 0.4510 r:0.7378
Current avg r:0.7090 Best avg r: 0.7376
23:47:53,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:07,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:22,491 root INFO Epoch 5 Global steps: 41000 Train loss: 0.2430
ro_en Dev loss: 0.3465 r:0.8167
et_en Dev loss: 0.4416 r:0.6811
si_en Dev loss: 0.8110 r:0.5792
ne_en Dev loss: 0.5584 r:0.7427
ru_en Dev loss: 0.4599 r:0.7446
Current avg r:0.7128 Best avg r: 0.7376
23:54:06,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:21,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:35,917 root INFO Epoch 5 Global steps: 41500 Train loss: 0.2413
ro_en Dev loss: 0.3464 r:0.8160
et_en Dev loss: 0.4336 r:0.6832
si_en Dev loss: 0.8174 r:0.5830
ne_en Dev loss: 0.4810 r:0.7423
ru_en Dev loss: 0.4806 r:0.7332
Current avg r:0.7115 Best avg r: 0.7376
00:00:19,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:34,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:02:49,443 root INFO Epoch 5 Global steps: 42000 Train loss: 0.2398
ro_en Dev loss: 0.3811 r:0.8161
et_en Dev loss: 0.4506 r:0.6767
si_en Dev loss: 0.9143 r:0.5722
ne_en Dev loss: 0.5506 r:0.7414
ru_en Dev loss: 0.4948 r:0.7357
Current avg r:0.7084 Best avg r: 0.7376
00:06:33,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:47,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:09:02,604 root INFO Epoch 5 Global steps: 42500 Train loss: 0.2300
ro_en Dev loss: 0.3392 r:0.8181
et_en Dev loss: 0.4584 r:0.6821
si_en Dev loss: 0.7220 r:0.5810
ne_en Dev loss: 0.4503 r:0.7427
ru_en Dev loss: 0.4433 r:0.7384
Current avg r:0.7124 Best avg r: 0.7376
00:12:46,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:01,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:16,161 root INFO Epoch 5 Global steps: 43000 Train loss: 0.2292
ro_en Dev loss: 0.3823 r:0.8175
et_en Dev loss: 0.4602 r:0.6777
si_en Dev loss: 0.8916 r:0.5758
ne_en Dev loss: 0.5106 r:0.7464
ru_en Dev loss: 0.4915 r:0.7386
Current avg r:0.7112 Best avg r: 0.7376
00:19:00,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:15,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:21:30,22 root INFO Epoch 5 Global steps: 43500 Train loss: 0.2284
ro_en Dev loss: 0.3425 r:0.8149
et_en Dev loss: 0.4410 r:0.6899
si_en Dev loss: 0.7902 r:0.5777
ne_en Dev loss: 0.4478 r:0.7479
ru_en Dev loss: 0.4218 r:0.7530
Current avg r:0.7167 Best avg r: 0.7376
00:25:13,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:29,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:44,315 root INFO Epoch 5 Global steps: 44000 Train loss: 0.2247
ro_en Dev loss: 0.3875 r:0.8170
et_en Dev loss: 0.4433 r:0.6835
si_en Dev loss: 0.8662 r:0.5755
ne_en Dev loss: 0.5439 r:0.7429
ru_en Dev loss: 0.5258 r:0.7270
Current avg r:0.7092 Best avg r: 0.7376
00:31:28,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:32:42,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:33:57,816 root INFO Epoch 5 Global steps: 44500 Train loss: 0.2343
ro_en Dev loss: 0.3436 r:0.8164
et_en Dev loss: 0.4483 r:0.6835
si_en Dev loss: 0.7963 r:0.5794
ne_en Dev loss: 0.4679 r:0.7445
ru_en Dev loss: 0.4376 r:0.7383
Current avg r:0.7124 Best avg r: 0.7376
00:37:42,5 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:38:57,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:12,606 root INFO Epoch 5 Global steps: 45000 Train loss: 0.2304
ro_en Dev loss: 0.3491 r:0.8175
et_en Dev loss: 0.4432 r:0.6887
si_en Dev loss: 0.7596 r:0.5862
ne_en Dev loss: 0.4948 r:0.7460
ru_en Dev loss: 0.4444 r:0.7457
Current avg r:0.7168 Best avg r: 0.7376
00:43:58,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:13,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:28,990 root INFO Epoch 6 Global steps: 45500 Train loss: 0.1977
ro_en Dev loss: 0.3449 r:0.8206
et_en Dev loss: 0.4318 r:0.6801
si_en Dev loss: 0.9095 r:0.5702
ne_en Dev loss: 0.5729 r:0.7384
ru_en Dev loss: 0.4938 r:0.7289
Current avg r:0.7076 Best avg r: 0.7376
00:50:13,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:28,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:44,533 root INFO Epoch 6 Global steps: 46000 Train loss: 0.2020
ro_en Dev loss: 0.3763 r:0.8140
et_en Dev loss: 0.4468 r:0.6805
si_en Dev loss: 0.8894 r:0.5702
ne_en Dev loss: 0.5462 r:0.7437
ru_en Dev loss: 0.4987 r:0.7333
Current avg r:0.7083 Best avg r: 0.7376
00:56:29,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:44,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:59,990 root INFO Epoch 6 Global steps: 46500 Train loss: 0.2036
ro_en Dev loss: 0.3268 r:0.8180
et_en Dev loss: 0.4231 r:0.6885
si_en Dev loss: 0.7745 r:0.5776
ne_en Dev loss: 0.4465 r:0.7462
ru_en Dev loss: 0.4345 r:0.7390
Current avg r:0.7138 Best avg r: 0.7376
01:02:44,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:59,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:14,202 root INFO Epoch 6 Global steps: 47000 Train loss: 0.1991
ro_en Dev loss: 0.3493 r:0.8173
et_en Dev loss: 0.4563 r:0.6805
si_en Dev loss: 0.8238 r:0.5764
ne_en Dev loss: 0.4901 r:0.7398
ru_en Dev loss: 0.4754 r:0.7282
Current avg r:0.7084 Best avg r: 0.7376
01:08:57,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:12,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:28,4 root INFO Epoch 6 Global steps: 47500 Train loss: 0.2079
ro_en Dev loss: 0.3292 r:0.8188
et_en Dev loss: 0.4489 r:0.6758
si_en Dev loss: 0.8108 r:0.5734
ne_en Dev loss: 0.5061 r:0.7366
ru_en Dev loss: 0.4224 r:0.7421
Current avg r:0.7093 Best avg r: 0.7376
01:15:12,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:27,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:43,246 root INFO Epoch 6 Global steps: 48000 Train loss: 0.2056
ro_en Dev loss: 0.3405 r:0.8157
et_en Dev loss: 0.4462 r:0.6798
si_en Dev loss: 0.7386 r:0.5792
ne_en Dev loss: 0.4464 r:0.7351
ru_en Dev loss: 0.4063 r:0.7563
Current avg r:0.7132 Best avg r: 0.7376
01:21:28,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:22:43,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:59,206 root INFO Epoch 6 Global steps: 48500 Train loss: 0.2092
ro_en Dev loss: 0.3712 r:0.8174
et_en Dev loss: 0.4608 r:0.6778
si_en Dev loss: 0.8476 r:0.5718
ne_en Dev loss: 0.4916 r:0.7339
ru_en Dev loss: 0.4653 r:0.7414
Current avg r:0.7085 Best avg r: 0.7376
01:27:44,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:59,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:14,903 root INFO Epoch 6 Global steps: 49000 Train loss: 0.1904
ro_en Dev loss: 0.3666 r:0.8172
et_en Dev loss: 0.4470 r:0.6687
si_en Dev loss: 0.9366 r:0.5560
ne_en Dev loss: 0.5585 r:0.7288
ru_en Dev loss: 0.4726 r:0.7332
Current avg r:0.7008 Best avg r: 0.7376
01:33:59,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:15,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:30,805 root INFO Epoch 6 Global steps: 49500 Train loss: 0.2117
ro_en Dev loss: 0.3924 r:0.8172
et_en Dev loss: 0.4463 r:0.6814
si_en Dev loss: 0.9195 r:0.5622
ne_en Dev loss: 0.5281 r:0.7301
ru_en Dev loss: 0.5309 r:0.7217
Current avg r:0.7025 Best avg r: 0.7376
01:40:15,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:41:31,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:42:46,887 root INFO Epoch 6 Global steps: 50000 Train loss: 0.1962
ro_en Dev loss: 0.3487 r:0.8156
et_en Dev loss: 0.4606 r:0.6824
si_en Dev loss: 0.7810 r:0.5666
ne_en Dev loss: 0.4632 r:0.7313
ru_en Dev loss: 0.4186 r:0.7495
Current avg r:0.7091 Best avg r: 0.7376
01:46:31,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:47:46,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:49:02,218 root INFO Epoch 6 Global steps: 50500 Train loss: 0.1951
ro_en Dev loss: 0.3515 r:0.8144
et_en Dev loss: 0.4704 r:0.6748
si_en Dev loss: 0.8084 r:0.5662
ne_en Dev loss: 0.4831 r:0.7360
ru_en Dev loss: 0.4028 r:0.7542
Current avg r:0.7091 Best avg r: 0.7376
01:52:46,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:54:02,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:55:17,607 root INFO Epoch 6 Global steps: 51000 Train loss: 0.1922
ro_en Dev loss: 0.3607 r:0.8185
et_en Dev loss: 0.4543 r:0.6811
si_en Dev loss: 0.8223 r:0.5764
ne_en Dev loss: 0.5117 r:0.7355
ru_en Dev loss: 0.4530 r:0.7475
Current avg r:0.7118 Best avg r: 0.7376
01:59:01,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:00:17,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:01:32,668 root INFO Epoch 6 Global steps: 51500 Train loss: 0.1944
ro_en Dev loss: 0.3738 r:0.8174
et_en Dev loss: 0.4606 r:0.6740
si_en Dev loss: 0.8172 r:0.5755
ne_en Dev loss: 0.5441 r:0.7368
ru_en Dev loss: 0.4536 r:0.7444
Current avg r:0.7096 Best avg r: 0.7376
02:05:17,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:32,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:47,909 root INFO Epoch 6 Global steps: 52000 Train loss: 0.1981
ro_en Dev loss: 0.3396 r:0.8190
et_en Dev loss: 0.4889 r:0.6734
si_en Dev loss: 0.7599 r:0.5740
ne_en Dev loss: 0.4678 r:0.7342
ru_en Dev loss: 0.4009 r:0.7563
Current avg r:0.7114 Best avg r: 0.7376
02:11:32,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:48,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:03,701 root INFO Epoch 6 Global steps: 52500 Train loss: 0.1893
ro_en Dev loss: 0.3533 r:0.8199
et_en Dev loss: 0.4543 r:0.6714
si_en Dev loss: 0.7937 r:0.5721
ne_en Dev loss: 0.4752 r:0.7354
ru_en Dev loss: 0.4437 r:0.7464
Current avg r:0.7091 Best avg r: 0.7376
02:17:49,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:19:04,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:20:20,223 root INFO Epoch 7 Global steps: 53000 Train loss: 0.1690
ro_en Dev loss: 0.4092 r:0.8148
et_en Dev loss: 0.4809 r:0.6626
si_en Dev loss: 0.9466 r:0.5605
ne_en Dev loss: 0.5809 r:0.7341
ru_en Dev loss: 0.5267 r:0.7285
Current avg r:0.7001 Best avg r: 0.7376
02:24:05,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:25:20,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:26:35,811 root INFO Epoch 7 Global steps: 53500 Train loss: 0.1756
ro_en Dev loss: 0.3966 r:0.8131
et_en Dev loss: 0.4922 r:0.6649
si_en Dev loss: 0.8915 r:0.5673
ne_en Dev loss: 0.5602 r:0.7391
ru_en Dev loss: 0.5137 r:0.7240
Current avg r:0.7017 Best avg r: 0.7376
02:30:20,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:36,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:32:52,33 root INFO Epoch 7 Global steps: 54000 Train loss: 0.1748
ro_en Dev loss: 0.3453 r:0.8163
et_en Dev loss: 0.4584 r:0.6751
si_en Dev loss: 0.8389 r:0.5692
ne_en Dev loss: 0.5469 r:0.7317
ru_en Dev loss: 0.4448 r:0.7343
Current avg r:0.7053 Best avg r: 0.7376
02:36:36,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:52,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:39:08,603 root INFO Epoch 7 Global steps: 54500 Train loss: 0.1654
ro_en Dev loss: 0.4344 r:0.8140
et_en Dev loss: 0.5152 r:0.6560
si_en Dev loss: 1.0455 r:0.5569
ne_en Dev loss: 0.6930 r:0.7279
ru_en Dev loss: 0.5390 r:0.7178
Current avg r:0.6945 Best avg r: 0.7376
02:42:53,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:44:09,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:24,829 root INFO Epoch 7 Global steps: 55000 Train loss: 0.1660
ro_en Dev loss: 0.3602 r:0.8159
et_en Dev loss: 0.4868 r:0.6702
si_en Dev loss: 0.8362 r:0.5767
ne_en Dev loss: 0.4891 r:0.7352
ru_en Dev loss: 0.4340 r:0.7509
Current avg r:0.7098 Best avg r: 0.7376
02:49:10,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:25,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:41,61 root INFO Epoch 7 Global steps: 55500 Train loss: 0.1688
ro_en Dev loss: 0.3472 r:0.8146
et_en Dev loss: 0.4562 r:0.6671
si_en Dev loss: 0.8795 r:0.5619
ne_en Dev loss: 0.5560 r:0.7306
ru_en Dev loss: 0.4589 r:0.7377
Current avg r:0.7024 Best avg r: 0.7376
02:55:26,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:41,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:57:57,600 root INFO Epoch 7 Global steps: 56000 Train loss: 0.1622
ro_en Dev loss: 0.3457 r:0.8158
et_en Dev loss: 0.4581 r:0.6766
si_en Dev loss: 0.7856 r:0.5746
ne_en Dev loss: 0.4646 r:0.7348
ru_en Dev loss: 0.4109 r:0.7543
Current avg r:0.7112 Best avg r: 0.7376
03:01:42,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:02:58,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:14,177 root INFO Epoch 7 Global steps: 56500 Train loss: 0.1670
ro_en Dev loss: 0.3180 r:0.8184
et_en Dev loss: 0.4510 r:0.6799
si_en Dev loss: 0.7416 r:0.5757
ne_en Dev loss: 0.4492 r:0.7347
ru_en Dev loss: 0.3834 r:0.7617
Current avg r:0.7141 Best avg r: 0.7376
03:07:59,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:14,391 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:10:29,817 root INFO Epoch 7 Global steps: 57000 Train loss: 0.1710
ro_en Dev loss: 0.3763 r:0.8137
et_en Dev loss: 0.4665 r:0.6616
si_en Dev loss: 0.9388 r:0.5625
ne_en Dev loss: 0.5734 r:0.7357
ru_en Dev loss: 0.4944 r:0.7287
Current avg r:0.7005 Best avg r: 0.7376
03:14:14,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:15:29,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:45,311 root INFO Epoch 7 Global steps: 57500 Train loss: 0.1689
ro_en Dev loss: 0.3583 r:0.8140
et_en Dev loss: 0.4662 r:0.6639
si_en Dev loss: 0.9246 r:0.5597
ne_en Dev loss: 0.5285 r:0.7347
ru_en Dev loss: 0.4481 r:0.7431
Current avg r:0.7031 Best avg r: 0.7376
03:20:29,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:45,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:00,521 root INFO Epoch 7 Global steps: 58000 Train loss: 0.1664
ro_en Dev loss: 0.3985 r:0.8129
et_en Dev loss: 0.4774 r:0.6609
si_en Dev loss: 0.9951 r:0.5573
ne_en Dev loss: 0.6623 r:0.7372
ru_en Dev loss: 0.5146 r:0.7238
Current avg r:0.6984 Best avg r: 0.7376
03:26:45,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:00,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:29:16,6 root INFO Epoch 7 Global steps: 58500 Train loss: 0.1746
ro_en Dev loss: 0.3491 r:0.8176
et_en Dev loss: 0.4958 r:0.6701
si_en Dev loss: 0.8291 r:0.5623
ne_en Dev loss: 0.5214 r:0.7298
ru_en Dev loss: 0.4391 r:0.7413
Current avg r:0.7042 Best avg r: 0.7376
03:33:00,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:34:16,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:35:31,308 root INFO Epoch 7 Global steps: 59000 Train loss: 0.1632
ro_en Dev loss: 0.3254 r:0.8178
et_en Dev loss: 0.4693 r:0.6635
si_en Dev loss: 0.8371 r:0.5520
ne_en Dev loss: 0.4946 r:0.7340
ru_en Dev loss: 0.4433 r:0.7316
Current avg r:0.6998 Best avg r: 0.7376
03:39:15,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:31,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:46,517 root INFO Epoch 7 Global steps: 59500 Train loss: 0.1705
ro_en Dev loss: 0.3503 r:0.8168
et_en Dev loss: 0.4735 r:0.6508
si_en Dev loss: 0.8892 r:0.5494
ne_en Dev loss: 0.5574 r:0.7306
ru_en Dev loss: 0.4534 r:0.7348
Current avg r:0.6965 Best avg r: 0.7376
03:45:31,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:46:46,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:48:01,699 root INFO Epoch 7 Global steps: 60000 Train loss: 0.1642
ro_en Dev loss: 0.3808 r:0.8113
et_en Dev loss: 0.4982 r:0.6462
si_en Dev loss: 0.9724 r:0.5459
ne_en Dev loss: 0.5320 r:0.7344
ru_en Dev loss: 0.5059 r:0.7266
Current avg r:0.6929 Best avg r: 0.7376
03:51:47,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:53:02,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:54:18,100 root INFO Epoch 8 Global steps: 60500 Train loss: 0.1453
ro_en Dev loss: 0.3572 r:0.8148
et_en Dev loss: 0.4846 r:0.6600
si_en Dev loss: 0.8547 r:0.5547
ne_en Dev loss: 0.5288 r:0.7295
ru_en Dev loss: 0.4785 r:0.7316
Current avg r:0.6981 Best avg r: 0.7376
03:58:02,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:59:17,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:33,334 root INFO Epoch 8 Global steps: 61000 Train loss: 0.1557
ro_en Dev loss: 0.3265 r:0.8166
et_en Dev loss: 0.4616 r:0.6649
si_en Dev loss: 0.8180 r:0.5615
ne_en Dev loss: 0.5220 r:0.7347
ru_en Dev loss: 0.4214 r:0.7443
Current avg r:0.7044 Best avg r: 0.7376
04:04:17,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:05:33,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:06:48,723 root INFO Epoch 8 Global steps: 61500 Train loss: 0.1500
ro_en Dev loss: 0.3674 r:0.8169
et_en Dev loss: 0.4654 r:0.6660
si_en Dev loss: 0.9753 r:0.5562
ne_en Dev loss: 0.6273 r:0.7352
ru_en Dev loss: 0.4630 r:0.7403
Current avg r:0.7029 Best avg r: 0.7376
04:10:33,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:11:48,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:13:04,186 root INFO Epoch 8 Global steps: 62000 Train loss: 0.1496
ro_en Dev loss: 0.3628 r:0.8160
et_en Dev loss: 0.4737 r:0.6597
si_en Dev loss: 0.9327 r:0.5550
ne_en Dev loss: 0.5890 r:0.7323
ru_en Dev loss: 0.4792 r:0.7276
Current avg r:0.6981 Best avg r: 0.7376
04:16:48,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:18:04,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:19,433 root INFO Epoch 8 Global steps: 62500 Train loss: 0.1431
ro_en Dev loss: 0.3817 r:0.8143
et_en Dev loss: 0.4892 r:0.6620
si_en Dev loss: 0.8764 r:0.5617
ne_en Dev loss: 0.4938 r:0.7368
ru_en Dev loss: 0.4788 r:0.7412
Current avg r:0.7032 Best avg r: 0.7376
04:23:03,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:24:19,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:25:34,505 root INFO Epoch 8 Global steps: 63000 Train loss: 0.1476
ro_en Dev loss: 0.3904 r:0.8125
et_en Dev loss: 0.4753 r:0.6525
si_en Dev loss: 0.9124 r:0.5577
ne_en Dev loss: 0.5752 r:0.7352
ru_en Dev loss: 0.4909 r:0.7343
Current avg r:0.6984 Best avg r: 0.7376
04:29:18,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:34,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:49,612 root INFO Epoch 8 Global steps: 63500 Train loss: 0.1448
ro_en Dev loss: 0.3684 r:0.8121
et_en Dev loss: 0.4670 r:0.6568
si_en Dev loss: 0.9300 r:0.5540
ne_en Dev loss: 0.5137 r:0.7350
ru_en Dev loss: 0.4362 r:0.7494
Current avg r:0.7015 Best avg r: 0.7376
04:35:34,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:49,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:04,638 root INFO Epoch 8 Global steps: 64000 Train loss: 0.1420
ro_en Dev loss: 0.3858 r:0.8112
et_en Dev loss: 0.4854 r:0.6611
si_en Dev loss: 0.8806 r:0.5605
ne_en Dev loss: 0.5704 r:0.7271
ru_en Dev loss: 0.5132 r:0.7295
Current avg r:0.6979 Best avg r: 0.7376
04:41:49,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:04,391 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:19,822 root INFO Epoch 8 Global steps: 64500 Train loss: 0.1432
ro_en Dev loss: 0.3866 r:0.8069
et_en Dev loss: 0.4884 r:0.6596
si_en Dev loss: 0.9127 r:0.5534
ne_en Dev loss: 0.5448 r:0.7310
ru_en Dev loss: 0.4867 r:0.7324
Current avg r:0.6967 Best avg r: 0.7376
04:48:04,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:49:19,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:50:35,150 root INFO Epoch 8 Global steps: 65000 Train loss: 0.1442
ro_en Dev loss: 0.3625 r:0.8130
et_en Dev loss: 0.4746 r:0.6660
si_en Dev loss: 0.9108 r:0.5580
ne_en Dev loss: 0.5561 r:0.7276
ru_en Dev loss: 0.4743 r:0.7357
Current avg r:0.7001 Best avg r: 0.7376
04:54:19,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:55:34,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:56:50,157 root INFO Epoch 8 Global steps: 65500 Train loss: 0.1492
ro_en Dev loss: 0.3617 r:0.8145
et_en Dev loss: 0.4783 r:0.6735
si_en Dev loss: 0.8166 r:0.5694
ne_en Dev loss: 0.4761 r:0.7295
ru_en Dev loss: 0.4392 r:0.7558
Current avg r:0.7086 Best avg r: 0.7376
05:00:34,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:01:50,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:05,322 root INFO Epoch 8 Global steps: 66000 Train loss: 0.1443
ro_en Dev loss: 0.3547 r:0.8149
et_en Dev loss: 0.4711 r:0.6683
si_en Dev loss: 0.8948 r:0.5547
ne_en Dev loss: 0.5219 r:0.7309
ru_en Dev loss: 0.4770 r:0.7314
Current avg r:0.7000 Best avg r: 0.7376
05:06:49,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:08:05,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:09:20,532 root INFO Epoch 8 Global steps: 66500 Train loss: 0.1406
ro_en Dev loss: 0.3768 r:0.8127
et_en Dev loss: 0.4912 r:0.6672
si_en Dev loss: 0.8845 r:0.5524
ne_en Dev loss: 0.5372 r:0.7257
ru_en Dev loss: 0.4539 r:0.7471
Current avg r:0.7010 Best avg r: 0.7376
05:13:05,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:20,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:35,697 root INFO Epoch 8 Global steps: 67000 Train loss: 0.1380
ro_en Dev loss: 0.3429 r:0.8163
et_en Dev loss: 0.4817 r:0.6675
si_en Dev loss: 0.7795 r:0.5626
ne_en Dev loss: 0.4611 r:0.7296
ru_en Dev loss: 0.4016 r:0.7617
Current avg r:0.7075 Best avg r: 0.7376
05:19:19,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:35,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:21:50,741 root INFO Epoch 8 Global steps: 67500 Train loss: 0.1430
ro_en Dev loss: 0.4184 r:0.8142
et_en Dev loss: 0.5019 r:0.6556
si_en Dev loss: 1.1145 r:0.5425
ne_en Dev loss: 0.7599 r:0.7190
ru_en Dev loss: 0.5161 r:0.7347
Current avg r:0.6932 Best avg r: 0.7376
05:25:35,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:26:50,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:28:06,228 root INFO Epoch 9 Global steps: 68000 Train loss: 0.1278
ro_en Dev loss: 0.3582 r:0.8157
et_en Dev loss: 0.4718 r:0.6608
si_en Dev loss: 0.8635 r:0.5526
ne_en Dev loss: 0.5162 r:0.7245
ru_en Dev loss: 0.5037 r:0.7212
Current avg r:0.6949 Best avg r: 0.7376
05:31:50,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:33:05,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:34:20,805 root INFO Epoch 9 Global steps: 68500 Train loss: 0.1305
ro_en Dev loss: 0.3805 r:0.8124
et_en Dev loss: 0.4858 r:0.6579
si_en Dev loss: 0.9437 r:0.5437
ne_en Dev loss: 0.5999 r:0.7234
ru_en Dev loss: 0.4998 r:0.7277
Current avg r:0.6930 Best avg r: 0.7376
05:38:04,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:39:20,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:40:35,614 root INFO Epoch 9 Global steps: 69000 Train loss: 0.1230
ro_en Dev loss: 0.3460 r:0.8156
et_en Dev loss: 0.4487 r:0.6634
si_en Dev loss: 0.8739 r:0.5537
ne_en Dev loss: 0.5655 r:0.7217
ru_en Dev loss: 0.4382 r:0.7431
Current avg r:0.6995 Best avg r: 0.7376
05:44:19,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:45:35,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:49,964 root INFO Epoch 9 Global steps: 69500 Train loss: 0.1308
ro_en Dev loss: 0.3533 r:0.8179
et_en Dev loss: 0.4477 r:0.6688
si_en Dev loss: 0.9171 r:0.5506
ne_en Dev loss: 0.6475 r:0.7221
ru_en Dev loss: 0.4576 r:0.7357
Current avg r:0.6990 Best avg r: 0.7376
05:50:33,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:48,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:04,68 root INFO Epoch 9 Global steps: 70000 Train loss: 0.1255
ro_en Dev loss: 0.3757 r:0.8138
et_en Dev loss: 0.4883 r:0.6673
si_en Dev loss: 0.9098 r:0.5462
ne_en Dev loss: 0.5788 r:0.7226
ru_en Dev loss: 0.4553 r:0.7422
Current avg r:0.6984 Best avg r: 0.7376
05:56:48,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:58:03,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:18,897 root INFO Epoch 9 Global steps: 70500 Train loss: 0.1305
ro_en Dev loss: 0.3501 r:0.8158
et_en Dev loss: 0.4818 r:0.6723
si_en Dev loss: 0.8344 r:0.5624
ne_en Dev loss: 0.5120 r:0.7216
ru_en Dev loss: 0.4421 r:0.7408
Current avg r:0.7026 Best avg r: 0.7376
06:03:03,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:18,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:34,285 root INFO Epoch 9 Global steps: 71000 Train loss: 0.1275
ro_en Dev loss: 0.3623 r:0.8135
et_en Dev loss: 0.4621 r:0.6595
si_en Dev loss: 0.9191 r:0.5472
ne_en Dev loss: 0.5938 r:0.7277
ru_en Dev loss: 0.4801 r:0.7269
Current avg r:0.6949 Best avg r: 0.7376
06:09:18,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:10:34,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:49,822 root INFO Epoch 9 Global steps: 71500 Train loss: 0.1242
ro_en Dev loss: 0.3688 r:0.8119
et_en Dev loss: 0.4855 r:0.6629
si_en Dev loss: 0.8975 r:0.5513
ne_en Dev loss: 0.5596 r:0.7270
ru_en Dev loss: 0.4648 r:0.7361
Current avg r:0.6978 Best avg r: 0.7376
06:15:34,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:16:50,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:05,303 root INFO Epoch 9 Global steps: 72000 Train loss: 0.1299
ro_en Dev loss: 0.3718 r:0.8155
et_en Dev loss: 0.4844 r:0.6602
si_en Dev loss: 0.9074 r:0.5560
ne_en Dev loss: 0.5814 r:0.7215
ru_en Dev loss: 0.4634 r:0.7437
Current avg r:0.6994 Best avg r: 0.7376
06:21:50,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:23:05,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:21,151 root INFO Epoch 9 Global steps: 72500 Train loss: 0.1263
ro_en Dev loss: 0.3573 r:0.8126
et_en Dev loss: 0.4708 r:0.6536
si_en Dev loss: 0.9199 r:0.5452
ne_en Dev loss: 0.6015 r:0.7232
ru_en Dev loss: 0.4376 r:0.7456
Current avg r:0.6960 Best avg r: 0.7376
06:28:06,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:21,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:37,31 root INFO Epoch 9 Global steps: 73000 Train loss: 0.1273
ro_en Dev loss: 0.3782 r:0.8138
et_en Dev loss: 0.4938 r:0.6629
si_en Dev loss: 0.9303 r:0.5554
ne_en Dev loss: 0.5526 r:0.7307
ru_en Dev loss: 0.4530 r:0.7502
Current avg r:0.7026 Best avg r: 0.7376
06:34:21,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:35:37,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:36:52,876 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1227
ro_en Dev loss: 0.3542 r:0.8119
et_en Dev loss: 0.4809 r:0.6564
si_en Dev loss: 0.8754 r:0.5445
ne_en Dev loss: 0.5030 r:0.7228
ru_en Dev loss: 0.4647 r:0.7371
Current avg r:0.6946 Best avg r: 0.7376
06:40:37,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:53,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:43:08,717 root INFO Epoch 9 Global steps: 74000 Train loss: 0.1300
ro_en Dev loss: 0.4054 r:0.8124
et_en Dev loss: 0.5025 r:0.6638
si_en Dev loss: 0.9751 r:0.5511
ne_en Dev loss: 0.6056 r:0.7251
ru_en Dev loss: 0.5247 r:0.7290
Current avg r:0.6963 Best avg r: 0.7376
06:46:53,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:48:08,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:49:24,397 root INFO Epoch 9 Global steps: 74500 Train loss: 0.1242
ro_en Dev loss: 0.3699 r:0.8165
et_en Dev loss: 0.4767 r:0.6659
si_en Dev loss: 0.8817 r:0.5526
ne_en Dev loss: 0.5776 r:0.7195
ru_en Dev loss: 0.4764 r:0.7423
Current avg r:0.6993 Best avg r: 0.7376
06:53:09,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:24,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:55:40,205 root INFO Epoch 9 Global steps: 75000 Train loss: 0.1270
ro_en Dev loss: 0.3677 r:0.8138
et_en Dev loss: 0.4898 r:0.6665
si_en Dev loss: 0.9387 r:0.5471
ne_en Dev loss: 0.5709 r:0.7157
ru_en Dev loss: 0.4678 r:0.7412
Current avg r:0.6969 Best avg r: 0.7376
06:59:25,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:41,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:56,680 root INFO Epoch 10 Global steps: 75500 Train loss: 0.1084
ro_en Dev loss: 0.3252 r:0.8174
et_en Dev loss: 0.4676 r:0.6740
si_en Dev loss: 0.8144 r:0.5593
ne_en Dev loss: 0.4895 r:0.7211
ru_en Dev loss: 0.4112 r:0.7467
Current avg r:0.7037 Best avg r: 0.7376
07:05:41,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:06:57,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:12,551 root INFO Epoch 10 Global steps: 76000 Train loss: 0.1136
ro_en Dev loss: 0.3756 r:0.8114
et_en Dev loss: 0.4762 r:0.6578
si_en Dev loss: 0.9588 r:0.5471
ne_en Dev loss: 0.6455 r:0.7172
ru_en Dev loss: 0.5120 r:0.7230
Current avg r:0.6913 Best avg r: 0.7376
07:11:57,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:12,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:14:28,349 root INFO Epoch 10 Global steps: 76500 Train loss: 0.1161
ro_en Dev loss: 0.3290 r:0.8141
et_en Dev loss: 0.4629 r:0.6625
si_en Dev loss: 0.8128 r:0.5515
ne_en Dev loss: 0.5372 r:0.7167
ru_en Dev loss: 0.4299 r:0.7411
Current avg r:0.6972 Best avg r: 0.7376
07:18:13,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:19:28,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:44,296 root INFO Epoch 10 Global steps: 77000 Train loss: 0.1170
ro_en Dev loss: 0.3857 r:0.8107
et_en Dev loss: 0.4869 r:0.6583
si_en Dev loss: 0.9845 r:0.5513
ne_en Dev loss: 0.6376 r:0.7213
ru_en Dev loss: 0.5093 r:0.7316
Current avg r:0.6946 Best avg r: 0.7376
07:24:29,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:44,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:27:00,383 root INFO Epoch 10 Global steps: 77500 Train loss: 0.1142
ro_en Dev loss: 0.3392 r:0.8148
et_en Dev loss: 0.4801 r:0.6660
si_en Dev loss: 0.8294 r:0.5552
ne_en Dev loss: 0.5291 r:0.7140
ru_en Dev loss: 0.4244 r:0.7521
Current avg r:0.7004 Best avg r: 0.7376
07:30:45,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:00,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:33:16,322 root INFO Epoch 10 Global steps: 78000 Train loss: 0.1123
ro_en Dev loss: 0.3732 r:0.8178
et_en Dev loss: 0.4730 r:0.6625
si_en Dev loss: 0.8663 r:0.5597
ne_en Dev loss: 0.5647 r:0.7120
ru_en Dev loss: 0.4843 r:0.7438
Current avg r:0.6992 Best avg r: 0.7376
07:37:01,153 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:16,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:39:32,458 root INFO Epoch 10 Global steps: 78500 Train loss: 0.1175
ro_en Dev loss: 0.3678 r:0.8155
et_en Dev loss: 0.4885 r:0.6664
si_en Dev loss: 0.8867 r:0.5562
ne_en Dev loss: 0.5578 r:0.7123
ru_en Dev loss: 0.4760 r:0.7397
Current avg r:0.6980 Best avg r: 0.7376
07:43:17,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:44:32,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:48,71 root INFO Epoch 10 Global steps: 79000 Train loss: 0.1083
ro_en Dev loss: 0.3797 r:0.8139
et_en Dev loss: 0.4855 r:0.6520
si_en Dev loss: 0.9231 r:0.5499
ne_en Dev loss: 0.6399 r:0.7108
ru_en Dev loss: 0.5373 r:0.7173
Current avg r:0.6888 Best avg r: 0.7376
07:49:33,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:50:48,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:04,65 root INFO Epoch 10 Global steps: 79500 Train loss: 0.1143
ro_en Dev loss: 0.3427 r:0.8173
et_en Dev loss: 0.4766 r:0.6625
si_en Dev loss: 0.8620 r:0.5534
ne_en Dev loss: 0.5659 r:0.7163
ru_en Dev loss: 0.4015 r:0.7553
Current avg r:0.7009 Best avg r: 0.7376
07:55:48,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:57:04,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:58:19,896 root INFO Epoch 10 Global steps: 80000 Train loss: 0.1109
ro_en Dev loss: 0.3740 r:0.8141
et_en Dev loss: 0.4852 r:0.6603
si_en Dev loss: 0.9131 r:0.5537
ne_en Dev loss: 0.5838 r:0.7179
ru_en Dev loss: 0.5086 r:0.7255
Current avg r:0.6943 Best avg r: 0.7376
08:02:04,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:03:19,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:04:35,465 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1089
ro_en Dev loss: 0.3733 r:0.8137
et_en Dev loss: 0.4810 r:0.6559
si_en Dev loss: 0.9661 r:0.5524
ne_en Dev loss: 0.6287 r:0.7142
ru_en Dev loss: 0.4951 r:0.7234
Current avg r:0.6919 Best avg r: 0.7376
08:08:20,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:35,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:51,85 root INFO Epoch 10 Global steps: 81000 Train loss: 0.1130
ro_en Dev loss: 0.3499 r:0.8143
et_en Dev loss: 0.4729 r:0.6692
si_en Dev loss: 0.8579 r:0.5576
ne_en Dev loss: 0.5467 r:0.7208
ru_en Dev loss: 0.4671 r:0.7317
Current avg r:0.6987 Best avg r: 0.7376
08:14:35,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:51,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:17:06,709 root INFO Epoch 10 Global steps: 81500 Train loss: 0.1078
ro_en Dev loss: 0.3826 r:0.8131
et_en Dev loss: 0.4953 r:0.6634
si_en Dev loss: 0.9363 r:0.5568
ne_en Dev loss: 0.6416 r:0.7231
ru_en Dev loss: 0.5043 r:0.7200
Current avg r:0.6953 Best avg r: 0.7376
08:20:51,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:22:07,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:22,675 root INFO Epoch 10 Global steps: 82000 Train loss: 0.1123
ro_en Dev loss: 0.3373 r:0.8166
et_en Dev loss: 0.4720 r:0.6761
si_en Dev loss: 0.7957 r:0.5637
ne_en Dev loss: 0.5294 r:0.7230
ru_en Dev loss: 0.4103 r:0.7480
Current avg r:0.7055 Best avg r: 0.7376
08:27:07,555 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:22,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:38,367 root INFO Epoch 10 Global steps: 82500 Train loss: 0.1108
ro_en Dev loss: 0.3365 r:0.8155
et_en Dev loss: 0.4536 r:0.6654
si_en Dev loss: 0.8896 r:0.5531
ne_en Dev loss: 0.5746 r:0.7217
ru_en Dev loss: 0.4173 r:0.7493
Current avg r:0.7010 Best avg r: 0.7376
08:33:23,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:34:39,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:35:54,811 root INFO Epoch 11 Global steps: 83000 Train loss: 0.0972
ro_en Dev loss: 0.3837 r:0.8145
et_en Dev loss: 0.4926 r:0.6641
si_en Dev loss: 0.9388 r:0.5611
ne_en Dev loss: 0.5977 r:0.7182
ru_en Dev loss: 0.4776 r:0.7413
Current avg r:0.6998 Best avg r: 0.7376
08:39:39,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:40:54,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:42:10,286 root INFO Epoch 11 Global steps: 83500 Train loss: 0.1029
ro_en Dev loss: 0.3725 r:0.8127
et_en Dev loss: 0.4699 r:0.6601
si_en Dev loss: 0.9400 r:0.5520
ne_en Dev loss: 0.5916 r:0.7153
ru_en Dev loss: 0.4831 r:0.7314
Current avg r:0.6943 Best avg r: 0.7376
08:45:54,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:10,298 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:48:25,806 root INFO Epoch 11 Global steps: 84000 Train loss: 0.0977
ro_en Dev loss: 0.3699 r:0.8159
et_en Dev loss: 0.4751 r:0.6730
si_en Dev loss: 0.9080 r:0.5613
ne_en Dev loss: 0.5659 r:0.7228
ru_en Dev loss: 0.4397 r:0.7528
Current avg r:0.7052 Best avg r: 0.7376
08:52:10,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:26,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:41,198 root INFO Epoch 11 Global steps: 84500 Train loss: 0.1000
ro_en Dev loss: 0.3469 r:0.8191
et_en Dev loss: 0.4555 r:0.6825
si_en Dev loss: 0.8093 r:0.5753
ne_en Dev loss: 0.5325 r:0.7231
ru_en Dev loss: 0.4180 r:0.7601
Current avg r:0.7120 Best avg r: 0.7376
08:58:25,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:59:41,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:00:56,623 root INFO Epoch 11 Global steps: 85000 Train loss: 0.1008
ro_en Dev loss: 0.3654 r:0.8159
et_en Dev loss: 0.4684 r:0.6731
si_en Dev loss: 0.8661 r:0.5691
ne_en Dev loss: 0.5751 r:0.7248
ru_en Dev loss: 0.4650 r:0.7479
Current avg r:0.7061 Best avg r: 0.7376
09:04:41,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:05:56,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:07:11,548 root INFO Epoch 11 Global steps: 85500 Train loss: 0.1032
ro_en Dev loss: 0.3569 r:0.8102
et_en Dev loss: 0.4687 r:0.6706
si_en Dev loss: 0.8462 r:0.5597
ne_en Dev loss: 0.5820 r:0.7157
ru_en Dev loss: 0.4394 r:0.7423
Current avg r:0.6997 Best avg r: 0.7376
09:10:56,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:12:11,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:13:27,400 root INFO Epoch 11 Global steps: 86000 Train loss: 0.0972
ro_en Dev loss: 0.3750 r:0.8150
et_en Dev loss: 0.4515 r:0.6665
si_en Dev loss: 0.9194 r:0.5654
ne_en Dev loss: 0.6468 r:0.7137
ru_en Dev loss: 0.4693 r:0.7397
Current avg r:0.7000 Best avg r: 0.7376
09:17:12,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:27,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:43,116 root INFO Epoch 11 Global steps: 86500 Train loss: 0.1034
ro_en Dev loss: 0.3484 r:0.8111
et_en Dev loss: 0.4680 r:0.6695
si_en Dev loss: 0.8489 r:0.5603
ne_en Dev loss: 0.5797 r:0.7173
ru_en Dev loss: 0.4261 r:0.7509
Current avg r:0.7018 Best avg r: 0.7376
09:23:28,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:24:43,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:25:59,221 root INFO Epoch 11 Global steps: 87000 Train loss: 0.1016
ro_en Dev loss: 0.3616 r:0.8121
et_en Dev loss: 0.4728 r:0.6644
si_en Dev loss: 0.8721 r:0.5521
ne_en Dev loss: 0.5545 r:0.7202
ru_en Dev loss: 0.4585 r:0.7451
Current avg r:0.6988 Best avg r: 0.7376
09:29:44,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:59,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:32:15,178 root INFO Epoch 11 Global steps: 87500 Train loss: 0.0972
ro_en Dev loss: 0.3753 r:0.8167
et_en Dev loss: 0.4551 r:0.6718
si_en Dev loss: 0.8907 r:0.5605
ne_en Dev loss: 0.5847 r:0.7202
ru_en Dev loss: 0.4579 r:0.7478
Current avg r:0.7034 Best avg r: 0.7376
09:35:59,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:37:15,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:38:30,719 root INFO Epoch 11 Global steps: 88000 Train loss: 0.1012
ro_en Dev loss: 0.3512 r:0.8134
et_en Dev loss: 0.4544 r:0.6659
si_en Dev loss: 0.9024 r:0.5504
ne_en Dev loss: 0.5869 r:0.7163
ru_en Dev loss: 0.4244 r:0.7509
Current avg r:0.6994 Best avg r: 0.7376
09:42:15,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:31,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:44:46,477 root INFO Epoch 11 Global steps: 88500 Train loss: 0.0949
ro_en Dev loss: 0.3603 r:0.8137
et_en Dev loss: 0.4641 r:0.6697
si_en Dev loss: 0.8147 r:0.5611
ne_en Dev loss: 0.5324 r:0.7137
ru_en Dev loss: 0.4211 r:0.7562
Current avg r:0.7029 Best avg r: 0.7376
09:48:31,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:49:47,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:02,501 root INFO Epoch 11 Global steps: 89000 Train loss: 0.0967
ro_en Dev loss: 0.3710 r:0.8173
et_en Dev loss: 0.4588 r:0.6790
si_en Dev loss: 0.9061 r:0.5606
ne_en Dev loss: 0.5939 r:0.7196
ru_en Dev loss: 0.4725 r:0.7452
Current avg r:0.7043 Best avg r: 0.7376
09:54:47,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:03,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:18,746 root INFO Epoch 11 Global steps: 89500 Train loss: 0.0918
ro_en Dev loss: 0.3613 r:0.8168
et_en Dev loss: 0.4840 r:0.6700
si_en Dev loss: 0.8889 r:0.5587
ne_en Dev loss: 0.5836 r:0.7205
ru_en Dev loss: 0.4605 r:0.7469
Current avg r:0.7026 Best avg r: 0.7376
10:01:03,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:18,765 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:33,981 root INFO Epoch 11 Global steps: 90000 Train loss: 0.0953
ro_en Dev loss: 0.3613 r:0.8131
et_en Dev loss: 0.4669 r:0.6656
si_en Dev loss: 0.9308 r:0.5499
ne_en Dev loss: 0.5883 r:0.7235
ru_en Dev loss: 0.4448 r:0.7457
Current avg r:0.6996 Best avg r: 0.7376
10:07:19,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:35,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:50,643 root INFO Epoch 12 Global steps: 90500 Train loss: 0.0907
ro_en Dev loss: 0.3481 r:0.8177
et_en Dev loss: 0.4580 r:0.6734
si_en Dev loss: 0.8796 r:0.5623
ne_en Dev loss: 0.5544 r:0.7254
ru_en Dev loss: 0.4167 r:0.7568
Current avg r:0.7071 Best avg r: 0.7376
10:13:35,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:51,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:16:06,758 root INFO Epoch 12 Global steps: 91000 Train loss: 0.0920
ro_en Dev loss: 0.3538 r:0.8148
et_en Dev loss: 0.4614 r:0.6702
si_en Dev loss: 0.9017 r:0.5535
ne_en Dev loss: 0.5477 r:0.7174
ru_en Dev loss: 0.4632 r:0.7384
Current avg r:0.6989 Best avg r: 0.7376
10:19:51,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:07,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:22,912 root INFO Epoch 12 Global steps: 91500 Train loss: 0.0942
ro_en Dev loss: 0.3552 r:0.8158
et_en Dev loss: 0.4741 r:0.6730
si_en Dev loss: 0.8779 r:0.5548
ne_en Dev loss: 0.5673 r:0.7176
ru_en Dev loss: 0.4465 r:0.7452
Current avg r:0.7013 Best avg r: 0.7376
10:26:07,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:23,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:28:38,406 root INFO Epoch 12 Global steps: 92000 Train loss: 0.0920
ro_en Dev loss: 0.3273 r:0.8192
et_en Dev loss: 0.4525 r:0.6776
si_en Dev loss: 0.8018 r:0.5643
ne_en Dev loss: 0.5251 r:0.7168
ru_en Dev loss: 0.4532 r:0.7466
Current avg r:0.7049 Best avg r: 0.7376
10:32:22,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:33:37,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:34:52,157 root INFO Epoch 12 Global steps: 92500 Train loss: 0.0912
ro_en Dev loss: 0.3699 r:0.8137
et_en Dev loss: 0.4721 r:0.6594
si_en Dev loss: 0.9683 r:0.5540
ne_en Dev loss: 0.6314 r:0.7155
ru_en Dev loss: 0.4752 r:0.7374
Current avg r:0.6960 Best avg r: 0.7376
10:38:36,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
