14:43:41,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:11,610 root INFO 
id:ro_en cur r: 0.5054 best r: 0.5054
14:44:41,579 root INFO 
id:et_en cur r: 0.3826 best r: 0.3826
14:45:11,772 root INFO 
id:si_en cur r: 0.4420 best r: 0.4420
14:45:41,942 root INFO 
id:ne_en cur r: 0.4976 best r: 0.4976
14:46:11,887 root INFO 
id:ru_en cur r: 0.5972 best r: 0.5972
14:46:11,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:27,116 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:47:27,123 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
14:47:27,127 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
14:47:27,132 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:47:27,138 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:48:42,447 root INFO Epoch 0 Global steps: 500 Train loss: 0.9012
ro_en Dev loss: 0.7133 r:0.5470
et_en Dev loss: 0.6683 r:0.4280
si_en Dev loss: 0.7655 r:0.4281
ne_en Dev loss: 0.6859 r:0.4730
ru_en Dev loss: 0.6284 r:0.6166
Current avg r:0.4986 Best avg r: 0.4986
14:52:27,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:57,414 root INFO 
id:ro_en cur r: 0.5500 best r: 0.5500
14:53:27,686 root INFO 
id:et_en cur r: 0.4379 best r: 0.4379
14:54:13,82 root INFO 
id:ne_en cur r: 0.5312 best r: 0.5312
14:54:28,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:43,606 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:55:43,612 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
14:55:43,617 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
14:55:43,620 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:55:43,625 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:56:59,149 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8546
ro_en Dev loss: 0.6728 r:0.5771
et_en Dev loss: 0.6211 r:0.4178
si_en Dev loss: 0.7537 r:0.4138
ne_en Dev loss: 0.6184 r:0.5100
ru_en Dev loss: 0.5780 r:0.6300
Current avg r:0.5097 Best avg r: 0.5097
15:00:45,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:15,250 root INFO 
id:ro_en cur r: 0.5875 best r: 0.5875
15:01:45,538 root INFO 
id:et_en cur r: 0.4809 best r: 0.4809
15:02:30,997 root INFO 
id:ne_en cur r: 0.5363 best r: 0.5363
15:03:01,172 root INFO 
id:ru_en cur r: 0.5985 best r: 0.5985
15:03:01,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:17,470 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:04:17,476 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
15:04:17,480 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
15:04:17,484 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:04:17,489 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:05:33,502 root INFO Epoch 0 Global steps: 1500 Train loss: 0.7966
ro_en Dev loss: 0.6189 r:0.6126
et_en Dev loss: 0.5765 r:0.4747
si_en Dev loss: 0.8587 r:0.3809
ne_en Dev loss: 0.6301 r:0.4975
ru_en Dev loss: 0.5233 r:0.6513
Current avg r:0.5234 Best avg r: 0.5234
15:09:19,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:49,689 root INFO 
id:ro_en cur r: 0.6060 best r: 0.6060
15:10:20,225 root INFO 
id:et_en cur r: 0.4946 best r: 0.4946
15:11:06,111 root INFO 
id:ne_en cur r: 0.5623 best r: 0.5623
15:11:36,290 root INFO 
id:ru_en cur r: 0.6097 best r: 0.6097
15:11:36,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:52,53 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:12:52,59 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
15:12:52,63 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
15:12:52,68 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:12:52,72 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:14:08,24 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7145
ro_en Dev loss: 0.6124 r:0.6267
et_en Dev loss: 0.5671 r:0.5172
si_en Dev loss: 0.8692 r:0.4212
ne_en Dev loss: 0.7605 r:0.4655
ru_en Dev loss: 0.5981 r:0.6380
Current avg r:0.5337 Best avg r: 0.5337
15:17:53,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:24,106 root INFO 
id:ro_en cur r: 0.6890 best r: 0.6890
15:18:54,652 root INFO 
id:et_en cur r: 0.5975 best r: 0.5975
15:19:24,957 root INFO 
id:si_en cur r: 0.4985 best r: 0.4985
15:19:55,200 root INFO 
id:ne_en cur r: 0.6545 best r: 0.6545
15:20:25,608 root INFO 
id:ru_en cur r: 0.6966 best r: 0.6966
15:20:25,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:41,297 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:21:41,302 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
15:21:41,307 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
15:21:41,311 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:21:41,316 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:22:57,12 root INFO Epoch 0 Global steps: 2500 Train loss: 0.6634
ro_en Dev loss: 0.4385 r:0.7019
et_en Dev loss: 0.4406 r:0.6273
si_en Dev loss: 0.6073 r:0.5150
ne_en Dev loss: 0.4779 r:0.6361
ru_en Dev loss: 0.4257 r:0.7161
Current avg r:0.6393 Best avg r: 0.6393
15:26:42,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:12,873 root INFO 
id:ro_en cur r: 0.7050 best r: 0.7050
15:27:43,156 root INFO 
id:et_en cur r: 0.6429 best r: 0.6429
15:28:13,444 root INFO 
id:si_en cur r: 0.5038 best r: 0.5038
15:28:43,724 root INFO 
id:ne_en cur r: 0.6650 best r: 0.6650
15:29:13,833 root INFO 
id:ru_en cur r: 0.7127 best r: 0.7127
15:29:13,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:29,385 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:30:29,391 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
15:30:29,395 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
15:30:29,400 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:30:29,404 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:31:44,959 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6419
ro_en Dev loss: 0.4198 r:0.7176
et_en Dev loss: 0.4151 r:0.6669
si_en Dev loss: 0.5965 r:0.5254
ne_en Dev loss: 0.4527 r:0.6778
ru_en Dev loss: 0.3958 r:0.7329
Current avg r:0.6641 Best avg r: 0.6641
15:35:29,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:59,380 root INFO 
id:ro_en cur r: 0.7175 best r: 0.7175
15:36:59,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:14,151 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6193
ro_en Dev loss: 0.4302 r:0.7372
et_en Dev loss: 0.3991 r:0.6622
si_en Dev loss: 0.6714 r:0.5196
ne_en Dev loss: 0.4776 r:0.6546
ru_en Dev loss: 0.4729 r:0.7256
Current avg r:0.6598 Best avg r: 0.6641
15:41:57,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:12,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:27,372 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:44:27,379 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
15:44:27,384 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
15:44:27,395 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:44:27,399 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:45:42,209 root INFO Epoch 0 Global steps: 4000 Train loss: 0.5895
ro_en Dev loss: 0.5398 r:0.7308
et_en Dev loss: 0.4105 r:0.6763
si_en Dev loss: 0.8045 r:0.5212
ne_en Dev loss: 0.5141 r:0.6631
ru_en Dev loss: 0.4901 r:0.7364
Current avg r:0.6656 Best avg r: 0.6656
15:49:25,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:55,785 root INFO 
id:ro_en cur r: 0.7485 best r: 0.7485
15:50:25,832 root INFO 
id:et_en cur r: 0.6862 best r: 0.6862
15:50:55,916 root INFO 
id:si_en cur r: 0.5410 best r: 0.5410
15:51:25,979 root INFO 
id:ne_en cur r: 0.7047 best r: 0.7047
15:51:55,886 root INFO 
id:ru_en cur r: 0.7331 best r: 0.7331
15:51:55,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:10,906 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:53:10,911 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
15:53:10,916 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
15:53:10,920 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:53:10,923 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:54:26,242 root INFO Epoch 0 Global steps: 4500 Train loss: 0.5893
ro_en Dev loss: 0.3719 r:0.7635
et_en Dev loss: 0.3675 r:0.6993
si_en Dev loss: 0.5971 r:0.5573
ne_en Dev loss: 0.3950 r:0.7086
ru_en Dev loss: 0.3909 r:0.7502
Current avg r:0.6958 Best avg r: 0.6958
15:58:10,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:39,920 root INFO 
id:ro_en cur r: 0.7509 best r: 0.7509
15:59:40,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:54,711 root INFO Epoch 0 Global steps: 5000 Train loss: 0.5683
ro_en Dev loss: 0.4243 r:0.7654
et_en Dev loss: 0.3804 r:0.6905
si_en Dev loss: 0.6710 r:0.5658
ne_en Dev loss: 0.4875 r:0.6974
ru_en Dev loss: 0.5241 r:0.7199
Current avg r:0.6878 Best avg r: 0.6958
16:04:38,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:08,619 root INFO 
id:ro_en cur r: 0.7607 best r: 0.7607
16:05:53,820 root INFO 
id:si_en cur r: 0.5506 best r: 0.5506
16:06:23,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:38,910 root INFO Epoch 0 Global steps: 5500 Train loss: 0.5561
ro_en Dev loss: 0.4432 r:0.7775
et_en Dev loss: 0.3826 r:0.6923
si_en Dev loss: 0.7441 r:0.5696
ne_en Dev loss: 0.4722 r:0.7053
ru_en Dev loss: 0.5170 r:0.7311
Current avg r:0.6952 Best avg r: 0.6958
16:11:22,818 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:52,811 root INFO 
id:ro_en cur r: 0.7664 best r: 0.7664
16:12:52,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:08,183 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5495
ro_en Dev loss: 0.4802 r:0.7804
et_en Dev loss: 0.4200 r:0.6951
si_en Dev loss: 0.8478 r:0.5593
ne_en Dev loss: 0.5639 r:0.7074
ru_en Dev loss: 0.5964 r:0.7277
Current avg r:0.6940 Best avg r: 0.6958
16:17:52,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:22,160 root INFO 
id:ro_en cur r: 0.7786 best r: 0.7786
16:18:52,154 root INFO 
id:et_en cur r: 0.6877 best r: 0.6877
16:19:22,160 root INFO 
id:si_en cur r: 0.5754 best r: 0.5754
16:19:52,162 root INFO 
id:ne_en cur r: 0.7268 best r: 0.7268
16:20:07,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:21,894 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:21:21,901 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
16:21:21,907 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
16:21:21,911 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:21:21,916 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:22:37,126 root INFO Epoch 0 Global steps: 6500 Train loss: 0.5346
ro_en Dev loss: 0.3434 r:0.7846
et_en Dev loss: 0.3692 r:0.6957
si_en Dev loss: 0.5961 r:0.5803
ne_en Dev loss: 0.3759 r:0.7264
ru_en Dev loss: 0.4196 r:0.7306
Current avg r:0.7035 Best avg r: 0.7035
16:26:20,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:51,123 root INFO 
id:ro_en cur r: 0.7915 best r: 0.7915
16:27:36,105 root INFO 
id:si_en cur r: 0.5838 best r: 0.5838
16:28:06,96 root INFO 
id:ne_en cur r: 0.7282 best r: 0.7282
16:28:20,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:35,782 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:29:35,788 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
16:29:35,792 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
16:29:35,797 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:29:35,802 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:30:50,794 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5197
ro_en Dev loss: 0.3648 r:0.7925
et_en Dev loss: 0.3726 r:0.6969
si_en Dev loss: 0.6507 r:0.5896
ne_en Dev loss: 0.4033 r:0.7305
ru_en Dev loss: 0.4921 r:0.7226
Current avg r:0.7064 Best avg r: 0.7064
16:34:34,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:50,42 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:04,848 root INFO Epoch 0 Global steps: 7500 Train loss: 0.5002
ro_en Dev loss: 0.3829 r:0.7900
et_en Dev loss: 0.3864 r:0.6925
si_en Dev loss: 0.6999 r:0.5805
ne_en Dev loss: 0.4442 r:0.7249
ru_en Dev loss: 0.4922 r:0.7303
Current avg r:0.7037 Best avg r: 0.7064
16:40:49,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:19,189 root INFO 
id:ro_en cur r: 0.7927 best r: 0.7927
16:41:49,392 root INFO 
id:et_en cur r: 0.7035 best r: 0.7035
16:42:19,380 root INFO 
id:si_en cur r: 0.5839 best r: 0.5839
16:42:49,368 root INFO 
id:ne_en cur r: 0.7374 best r: 0.7374
16:43:19,127 root INFO 
id:ru_en cur r: 0.7448 best r: 0.7448
16:43:19,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:33,925 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:44:33,938 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
16:44:33,942 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
16:44:33,947 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:44:33,952 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:45:48,766 root INFO Epoch 1 Global steps: 8000 Train loss: 0.4793
ro_en Dev loss: 0.3622 r:0.7968
et_en Dev loss: 0.3545 r:0.7124
si_en Dev loss: 0.6367 r:0.5901
ne_en Dev loss: 0.4111 r:0.7327
ru_en Dev loss: 0.4518 r:0.7512
Current avg r:0.7167 Best avg r: 0.7167
16:49:32,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:01,966 root INFO 
id:ro_en cur r: 0.7985 best r: 0.7985
16:51:01,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:16,834 root INFO Epoch 1 Global steps: 8500 Train loss: 0.4679
ro_en Dev loss: 0.3956 r:0.7981
et_en Dev loss: 0.3929 r:0.7061
si_en Dev loss: 0.7300 r:0.5852
ne_en Dev loss: 0.4441 r:0.7278
ru_en Dev loss: 0.5026 r:0.7496
Current avg r:0.7134 Best avg r: 0.7167
16:56:00,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:59,977 root INFO 
id:si_en cur r: 0.5841 best r: 0.5841
16:57:29,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:44,490 root INFO Epoch 1 Global steps: 9000 Train loss: 0.4660
ro_en Dev loss: 0.3796 r:0.8002
et_en Dev loss: 0.3780 r:0.7014
si_en Dev loss: 0.7042 r:0.5892
ne_en Dev loss: 0.4366 r:0.7298
ru_en Dev loss: 0.4808 r:0.7360
Current avg r:0.7113 Best avg r: 0.7167
17:02:28,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:57,923 root INFO 
id:ro_en cur r: 0.8085 best r: 0.8085
17:03:43,126 root INFO 
id:si_en cur r: 0.6051 best r: 0.6051
17:04:13,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:27,800 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:05:27,806 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
17:05:27,811 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
17:05:27,815 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:05:27,820 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:06:42,534 root INFO Epoch 1 Global steps: 9500 Train loss: 0.4735
ro_en Dev loss: 0.3474 r:0.8104
et_en Dev loss: 0.3710 r:0.7075
si_en Dev loss: 0.6314 r:0.6111
ne_en Dev loss: 0.4363 r:0.7360
ru_en Dev loss: 0.4924 r:0.7406
Current avg r:0.7211 Best avg r: 0.7211
17:10:26,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:41,393 root INFO 
id:ne_en cur r: 0.7392 best r: 0.7392
17:11:56,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:11,422 root INFO Epoch 1 Global steps: 10000 Train loss: 0.4874
ro_en Dev loss: 0.3221 r:0.8068
et_en Dev loss: 0.3534 r:0.7088
si_en Dev loss: 0.6445 r:0.6073
ne_en Dev loss: 0.4538 r:0.7384
ru_en Dev loss: 0.4526 r:0.7399
Current avg r:0.7202 Best avg r: 0.7211
17:16:54,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:10,88 root INFO 
id:ne_en cur r: 0.7421 best r: 0.7421
17:18:25,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:40,319 root INFO Epoch 1 Global steps: 10500 Train loss: 0.4677
ro_en Dev loss: 0.3838 r:0.8064
et_en Dev loss: 0.3784 r:0.7084
si_en Dev loss: 0.7330 r:0.5983
ne_en Dev loss: 0.4376 r:0.7390
ru_en Dev loss: 0.5062 r:0.7411
Current avg r:0.7186 Best avg r: 0.7211
17:23:23,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:53,745 root INFO 
id:ro_en cur r: 0.8116 best r: 0.8116
17:24:23,489 root INFO 
id:et_en cur r: 0.7053 best r: 0.7053
17:25:08,416 root INFO 
id:ne_en cur r: 0.7500 best r: 0.7500
17:25:38,297 root INFO 
id:ru_en cur r: 0.7500 best r: 0.7500
17:25:38,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:53,211 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:26:53,217 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
17:26:53,222 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
17:26:53,227 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:26:53,231 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:28:08,202 root INFO Epoch 1 Global steps: 11000 Train loss: 0.4609
ro_en Dev loss: 0.3690 r:0.8080
et_en Dev loss: 0.3702 r:0.7110
si_en Dev loss: 0.7471 r:0.6027
ne_en Dev loss: 0.4664 r:0.7444
ru_en Dev loss: 0.4464 r:0.7536
Current avg r:0.7239 Best avg r: 0.7239
17:31:51,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:21,508 root INFO 
id:ro_en cur r: 0.8133 best r: 0.8133
17:32:51,513 root INFO 
id:et_en cur r: 0.7195 best r: 0.7195
17:33:21,535 root INFO 
id:si_en cur r: 0.6053 best r: 0.6053
17:33:51,552 root INFO 
id:ne_en cur r: 0.7570 best r: 0.7570
17:34:21,114 root INFO 
id:ru_en cur r: 0.7652 best r: 0.7652
17:34:21,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:35,875 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:35:35,881 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
17:35:35,887 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
17:35:35,939 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:35:35,944 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:36:51,218 root INFO Epoch 1 Global steps: 11500 Train loss: 0.4565
ro_en Dev loss: 0.3139 r:0.8118
et_en Dev loss: 0.3462 r:0.7252
si_en Dev loss: 0.5742 r:0.6168
ne_en Dev loss: 0.3782 r:0.7489
ru_en Dev loss: 0.3842 r:0.7664
Current avg r:0.7338 Best avg r: 0.7338
17:40:35,77 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:49,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:04,452 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4617
ro_en Dev loss: 0.3295 r:0.8113
et_en Dev loss: 0.3533 r:0.7157
si_en Dev loss: 0.6253 r:0.6051
ne_en Dev loss: 0.4143 r:0.7457
ru_en Dev loss: 0.4169 r:0.7526
Current avg r:0.7261 Best avg r: 0.7338
17:46:48,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:03,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:18,184 root INFO Epoch 1 Global steps: 12500 Train loss: 0.4524
ro_en Dev loss: 0.3439 r:0.8073
et_en Dev loss: 0.3611 r:0.7107
si_en Dev loss: 0.6947 r:0.6011
ne_en Dev loss: 0.4941 r:0.7388
ru_en Dev loss: 0.4702 r:0.7479
Current avg r:0.7212 Best avg r: 0.7338
17:53:01,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:16,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:32,207 root INFO Epoch 1 Global steps: 13000 Train loss: 0.4586
ro_en Dev loss: 0.4004 r:0.8061
et_en Dev loss: 0.4062 r:0.7062
si_en Dev loss: 0.7691 r:0.5993
ne_en Dev loss: 0.4608 r:0.7486
ru_en Dev loss: 0.5084 r:0.7512
Current avg r:0.7223 Best avg r: 0.7338
17:59:16,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:45,803 root INFO 
id:ro_en cur r: 0.8194 best r: 0.8194
18:00:45,794 root INFO 
id:ne_en cur r: 0.7571 best r: 0.7571
18:01:00,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:15,606 root INFO Epoch 1 Global steps: 13500 Train loss: 0.4533
ro_en Dev loss: 0.3081 r:0.8207
et_en Dev loss: 0.3485 r:0.7174
si_en Dev loss: 0.6916 r:0.6051
ne_en Dev loss: 0.4404 r:0.7542
ru_en Dev loss: 0.3972 r:0.7655
Current avg r:0.7326 Best avg r: 0.7338
18:05:59,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:14,416 root INFO 
id:ne_en cur r: 0.7590 best r: 0.7590
18:07:29,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:44,403 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4297
ro_en Dev loss: 0.4215 r:0.8114
et_en Dev loss: 0.3999 r:0.6991
si_en Dev loss: 0.8232 r:0.5985
ne_en Dev loss: 0.4460 r:0.7568
ru_en Dev loss: 0.5384 r:0.7383
Current avg r:0.7208 Best avg r: 0.7338
18:12:28,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:28,355 root INFO 
id:si_en cur r: 0.6075 best r: 0.6075
18:13:58,651 root INFO 
id:ne_en cur r: 0.7686 best r: 0.7686
18:14:13,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:28,681 root INFO Epoch 1 Global steps: 14500 Train loss: 0.4673
ro_en Dev loss: 0.3296 r:0.8161
et_en Dev loss: 0.3643 r:0.7123
si_en Dev loss: 0.6510 r:0.6136
ne_en Dev loss: 0.3719 r:0.7656
ru_en Dev loss: 0.4336 r:0.7578
Current avg r:0.7331 Best avg r: 0.7338
18:19:12,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:26,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:41,996 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4345
ro_en Dev loss: 0.3764 r:0.8110
et_en Dev loss: 0.3833 r:0.6997
si_en Dev loss: 0.7346 r:0.6024
ne_en Dev loss: 0.4552 r:0.7570
ru_en Dev loss: 0.4923 r:0.7458
Current avg r:0.7232 Best avg r: 0.7338
18:25:26,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:41,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:56,946 root INFO Epoch 2 Global steps: 15500 Train loss: 0.3976
ro_en Dev loss: 0.3852 r:0.8103
et_en Dev loss: 0.3898 r:0.7015
si_en Dev loss: 0.7800 r:0.5993
ne_en Dev loss: 0.4870 r:0.7527
ru_en Dev loss: 0.4800 r:0.7435
Current avg r:0.7215 Best avg r: 0.7338
18:31:40,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:10,806 root INFO 
id:ro_en cur r: 0.8251 best r: 0.8251
18:32:56,49 root INFO 
id:si_en cur r: 0.6095 best r: 0.6095
18:33:25,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:40,914 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:34:40,921 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
18:34:40,926 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
18:34:40,930 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:34:40,937 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:35:55,909 root INFO Epoch 2 Global steps: 16000 Train loss: 0.3988
ro_en Dev loss: 0.3320 r:0.8246
et_en Dev loss: 0.3591 r:0.7135
si_en Dev loss: 0.7465 r:0.6173
ne_en Dev loss: 0.4488 r:0.7599
ru_en Dev loss: 0.4539 r:0.7568
Current avg r:0.7344 Best avg r: 0.7344
18:39:39,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:54,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:09,720 root INFO Epoch 2 Global steps: 16500 Train loss: 0.4157
ro_en Dev loss: 0.3257 r:0.8189
et_en Dev loss: 0.3704 r:0.7032
si_en Dev loss: 0.7524 r:0.6036
ne_en Dev loss: 0.4755 r:0.7564
ru_en Dev loss: 0.4213 r:0.7564
Current avg r:0.7277 Best avg r: 0.7344
18:45:53,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:08,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:23,678 root INFO Epoch 2 Global steps: 17000 Train loss: 0.3958
ro_en Dev loss: 0.3539 r:0.8144
et_en Dev loss: 0.3810 r:0.6972
si_en Dev loss: 0.7901 r:0.5932
ne_en Dev loss: 0.4526 r:0.7552
ru_en Dev loss: 0.4448 r:0.7460
Current avg r:0.7212 Best avg r: 0.7344
18:52:07,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:22,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:37,736 root INFO Epoch 2 Global steps: 17500 Train loss: 0.3937
ro_en Dev loss: 0.3444 r:0.8174
et_en Dev loss: 0.3778 r:0.7041
si_en Dev loss: 0.7322 r:0.6011
ne_en Dev loss: 0.4269 r:0.7556
ru_en Dev loss: 0.4345 r:0.7535
Current avg r:0.7263 Best avg r: 0.7344
18:58:21,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:36,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:51,326 root INFO Epoch 2 Global steps: 18000 Train loss: 0.4059
ro_en Dev loss: 0.3808 r:0.8120
et_en Dev loss: 0.3933 r:0.6991
si_en Dev loss: 0.9165 r:0.5865
ne_en Dev loss: 0.6191 r:0.7525
ru_en Dev loss: 0.5528 r:0.7169
Current avg r:0.7134 Best avg r: 0.7344
19:04:35,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:50,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:04,986 root INFO Epoch 2 Global steps: 18500 Train loss: 0.4123
ro_en Dev loss: 0.3598 r:0.8199
et_en Dev loss: 0.3843 r:0.7048
si_en Dev loss: 0.7595 r:0.6034
ne_en Dev loss: 0.4896 r:0.7579
ru_en Dev loss: 0.4963 r:0.7440
Current avg r:0.7260 Best avg r: 0.7344
19:10:48,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:03,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:18,229 root INFO Epoch 2 Global steps: 19000 Train loss: 0.3897
ro_en Dev loss: 0.3202 r:0.8220
et_en Dev loss: 0.3678 r:0.7046
si_en Dev loss: 0.7141 r:0.6040
ne_en Dev loss: 0.4561 r:0.7621
ru_en Dev loss: 0.3981 r:0.7601
Current avg r:0.7306 Best avg r: 0.7344
19:17:01,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:16,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:31,364 root INFO Epoch 2 Global steps: 19500 Train loss: 0.3886
ro_en Dev loss: 0.3469 r:0.8196
et_en Dev loss: 0.3824 r:0.7043
si_en Dev loss: 0.6908 r:0.6125
ne_en Dev loss: 0.4841 r:0.7536
ru_en Dev loss: 0.4694 r:0.7404
Current avg r:0.7261 Best avg r: 0.7344
19:23:14,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:44,333 root INFO 
id:ro_en cur r: 0.8275 best r: 0.8275
19:24:29,388 root INFO 
id:si_en cur r: 0.6139 best r: 0.6139
19:24:59,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:14,357 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
19:26:14,362 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
19:26:14,367 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
19:26:14,372 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
19:26:14,376 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
19:27:29,353 root INFO Epoch 2 Global steps: 20000 Train loss: 0.4012
ro_en Dev loss: 0.3059 r:0.8270
et_en Dev loss: 0.3909 r:0.7081
si_en Dev loss: 0.6167 r:0.6214
ne_en Dev loss: 0.3741 r:0.7617
ru_en Dev loss: 0.4005 r:0.7578
Current avg r:0.7352 Best avg r: 0.7352
19:31:12,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:12,307 root INFO 
id:si_en cur r: 0.6192 best r: 0.6192
19:32:42,220 root INFO 
id:ne_en cur r: 0.7756 best r: 0.7756
19:32:57,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:12,12 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
19:34:12,18 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
19:34:12,22 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
19:34:12,26 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
19:34:12,30 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
19:35:27,123 root INFO Epoch 2 Global steps: 20500 Train loss: 0.3938
ro_en Dev loss: 0.3397 r:0.8252
et_en Dev loss: 0.3683 r:0.7142
si_en Dev loss: 0.7096 r:0.6205
ne_en Dev loss: 0.4577 r:0.7683
ru_en Dev loss: 0.4293 r:0.7597
Current avg r:0.7376 Best avg r: 0.7376
19:39:10,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:24,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:39,595 root INFO Epoch 2 Global steps: 21000 Train loss: 0.3897
ro_en Dev loss: 0.3372 r:0.8204
et_en Dev loss: 0.4003 r:0.7079
si_en Dev loss: 0.7329 r:0.6121
ne_en Dev loss: 0.4324 r:0.7561
ru_en Dev loss: 0.4427 r:0.7563
Current avg r:0.7305 Best avg r: 0.7376
19:45:23,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:37,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:52,694 root INFO Epoch 2 Global steps: 21500 Train loss: 0.3915
ro_en Dev loss: 0.3190 r:0.8222
et_en Dev loss: 0.3832 r:0.7145
si_en Dev loss: 0.6276 r:0.6166
ne_en Dev loss: 0.3554 r:0.7594
ru_en Dev loss: 0.4123 r:0.7637
Current avg r:0.7353 Best avg r: 0.7376
19:51:36,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:50,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:05,649 root INFO Epoch 2 Global steps: 22000 Train loss: 0.3844
ro_en Dev loss: 0.3243 r:0.8206
et_en Dev loss: 0.3711 r:0.7134
si_en Dev loss: 0.7574 r:0.6057
ne_en Dev loss: 0.4377 r:0.7555
ru_en Dev loss: 0.4295 r:0.7587
Current avg r:0.7308 Best avg r: 0.7376
19:57:49,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:03,553 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:18,245 root INFO Epoch 2 Global steps: 22500 Train loss: 0.3605
ro_en Dev loss: 0.3565 r:0.8207
et_en Dev loss: 0.3751 r:0.7112
si_en Dev loss: 0.7940 r:0.6102
ne_en Dev loss: 0.4969 r:0.7553
ru_en Dev loss: 0.4960 r:0.7414
Current avg r:0.7278 Best avg r: 0.7376
20:04:02,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:17,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:31,755 root INFO Epoch 3 Global steps: 23000 Train loss: 0.3472
ro_en Dev loss: 0.3369 r:0.8152
et_en Dev loss: 0.3839 r:0.7023
si_en Dev loss: 0.7008 r:0.6041
ne_en Dev loss: 0.4273 r:0.7563
ru_en Dev loss: 0.4796 r:0.7349
Current avg r:0.7226 Best avg r: 0.7376
20:10:15,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:29,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:45,27 root INFO Epoch 3 Global steps: 23500 Train loss: 0.3271
ro_en Dev loss: 0.3052 r:0.8232
et_en Dev loss: 0.3694 r:0.7107
si_en Dev loss: 0.6864 r:0.6148
ne_en Dev loss: 0.3999 r:0.7614
ru_en Dev loss: 0.4412 r:0.7482
Current avg r:0.7317 Best avg r: 0.7376
20:16:28,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:42,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:57,806 root INFO Epoch 3 Global steps: 24000 Train loss: 0.3583
ro_en Dev loss: 0.3168 r:0.8208
et_en Dev loss: 0.3912 r:0.7006
si_en Dev loss: 0.6910 r:0.6114
ne_en Dev loss: 0.3880 r:0.7580
ru_en Dev loss: 0.4344 r:0.7480
Current avg r:0.7278 Best avg r: 0.7376
20:22:41,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:55,712 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:10,169 root INFO Epoch 3 Global steps: 24500 Train loss: 0.3417
ro_en Dev loss: 0.3313 r:0.8193
et_en Dev loss: 0.3777 r:0.7013
si_en Dev loss: 0.7675 r:0.6011
ne_en Dev loss: 0.5162 r:0.7566
ru_en Dev loss: 0.4665 r:0.7487
Current avg r:0.7254 Best avg r: 0.7376
20:28:53,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:08,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:23,536 root INFO Epoch 3 Global steps: 25000 Train loss: 0.3256
ro_en Dev loss: 0.3561 r:0.8157
et_en Dev loss: 0.3929 r:0.6992
si_en Dev loss: 0.8786 r:0.5942
ne_en Dev loss: 0.5555 r:0.7461
ru_en Dev loss: 0.5445 r:0.7285
Current avg r:0.7167 Best avg r: 0.7376
20:35:07,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:21,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:37,205 root INFO Epoch 3 Global steps: 25500 Train loss: 0.3368
ro_en Dev loss: 0.3195 r:0.8163
et_en Dev loss: 0.3854 r:0.7029
si_en Dev loss: 0.6807 r:0.6035
ne_en Dev loss: 0.3978 r:0.7557
ru_en Dev loss: 0.4553 r:0.7327
Current avg r:0.7222 Best avg r: 0.7376
20:41:20,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:35,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:50,220 root INFO Epoch 3 Global steps: 26000 Train loss: 0.3307
ro_en Dev loss: 0.3554 r:0.8128
et_en Dev loss: 0.3910 r:0.7013
si_en Dev loss: 0.7268 r:0.6025
ne_en Dev loss: 0.4448 r:0.7526
ru_en Dev loss: 0.4311 r:0.7541
Current avg r:0.7247 Best avg r: 0.7376
20:47:33,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:48,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:03,743 root INFO Epoch 3 Global steps: 26500 Train loss: 0.3334
ro_en Dev loss: 0.3622 r:0.8175
et_en Dev loss: 0.4073 r:0.6991
si_en Dev loss: 0.7470 r:0.6100
ne_en Dev loss: 0.4414 r:0.7584
ru_en Dev loss: 0.4867 r:0.7432
Current avg r:0.7256 Best avg r: 0.7376
20:53:47,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:02,247 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:17,48 root INFO Epoch 3 Global steps: 27000 Train loss: 0.3246
ro_en Dev loss: 0.3385 r:0.8177
et_en Dev loss: 0.3995 r:0.6938
si_en Dev loss: 0.6593 r:0.6134
ne_en Dev loss: 0.4061 r:0.7621
ru_en Dev loss: 0.4739 r:0.7329
Current avg r:0.7240 Best avg r: 0.7376
21:00:00,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:15,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:29,901 root INFO Epoch 3 Global steps: 27500 Train loss: 0.3520
ro_en Dev loss: 0.3486 r:0.8136
et_en Dev loss: 0.3907 r:0.6912
si_en Dev loss: 0.7951 r:0.5989
ne_en Dev loss: 0.5248 r:0.7603
ru_en Dev loss: 0.5130 r:0.7204
Current avg r:0.7169 Best avg r: 0.7376
21:06:13,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:28,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:43,307 root INFO Epoch 3 Global steps: 28000 Train loss: 0.3404
ro_en Dev loss: 0.3425 r:0.8204
et_en Dev loss: 0.3948 r:0.7027
si_en Dev loss: 0.7406 r:0.6008
ne_en Dev loss: 0.4281 r:0.7617
ru_en Dev loss: 0.4712 r:0.7431
Current avg r:0.7258 Best avg r: 0.7376
21:12:26,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:41,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:56,721 root INFO Epoch 3 Global steps: 28500 Train loss: 0.3485
ro_en Dev loss: 0.3293 r:0.8157
et_en Dev loss: 0.4097 r:0.7027
si_en Dev loss: 0.6740 r:0.6007
ne_en Dev loss: 0.3975 r:0.7592
ru_en Dev loss: 0.4195 r:0.7467
Current avg r:0.7250 Best avg r: 0.7376
21:18:40,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:54,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:09,707 root INFO Epoch 3 Global steps: 29000 Train loss: 0.3187
ro_en Dev loss: 0.3367 r:0.8179
et_en Dev loss: 0.4163 r:0.7049
si_en Dev loss: 0.6372 r:0.6124
ne_en Dev loss: 0.3880 r:0.7507
ru_en Dev loss: 0.4265 r:0.7524
Current avg r:0.7276 Best avg r: 0.7376
21:24:53,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:26:08,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:22,302 root INFO Epoch 3 Global steps: 29500 Train loss: 0.3394
ro_en Dev loss: 0.3249 r:0.8177
et_en Dev loss: 0.3826 r:0.7007
si_en Dev loss: 0.6809 r:0.6016
ne_en Dev loss: 0.4047 r:0.7497
ru_en Dev loss: 0.4259 r:0.7511
Current avg r:0.7242 Best avg r: 0.7376
21:31:06,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:20,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:35,481 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3133
ro_en Dev loss: 0.3250 r:0.8203
et_en Dev loss: 0.3986 r:0.7070
si_en Dev loss: 0.6431 r:0.6109
ne_en Dev loss: 0.3952 r:0.7569
ru_en Dev loss: 0.4079 r:0.7644
Current avg r:0.7319 Best avg r: 0.7376
21:37:19,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:34,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:49,163 root INFO Epoch 4 Global steps: 30500 Train loss: 0.2919
ro_en Dev loss: 0.3703 r:0.8148
et_en Dev loss: 0.4140 r:0.6916
si_en Dev loss: 0.8027 r:0.5908
ne_en Dev loss: 0.5269 r:0.7547
ru_en Dev loss: 0.4828 r:0.7374
Current avg r:0.7179 Best avg r: 0.7376
21:43:32,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:47,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:01,669 root INFO Epoch 4 Global steps: 31000 Train loss: 0.2948
ro_en Dev loss: 0.3356 r:0.8231
et_en Dev loss: 0.3935 r:0.7056
si_en Dev loss: 0.7422 r:0.6062
ne_en Dev loss: 0.4050 r:0.7592
ru_en Dev loss: 0.4660 r:0.7494
Current avg r:0.7287 Best avg r: 0.7376
21:49:45,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:59,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:14,817 root INFO Epoch 4 Global steps: 31500 Train loss: 0.2849
ro_en Dev loss: 0.3596 r:0.8201
et_en Dev loss: 0.4105 r:0.6954
si_en Dev loss: 0.7889 r:0.5986
ne_en Dev loss: 0.4791 r:0.7550
ru_en Dev loss: 0.5144 r:0.7380
Current avg r:0.7214 Best avg r: 0.7376
21:55:58,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:13,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:28,130 root INFO Epoch 4 Global steps: 32000 Train loss: 0.2833
ro_en Dev loss: 0.3578 r:0.8206
et_en Dev loss: 0.3949 r:0.6983
si_en Dev loss: 0.7843 r:0.5992
ne_en Dev loss: 0.5498 r:0.7547
ru_en Dev loss: 0.4697 r:0.7479
Current avg r:0.7242 Best avg r: 0.7376
22:02:11,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:26,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:40,488 root INFO Epoch 4 Global steps: 32500 Train loss: 0.2905
ro_en Dev loss: 0.3327 r:0.8187
et_en Dev loss: 0.4144 r:0.6992
si_en Dev loss: 0.6710 r:0.6061
ne_en Dev loss: 0.4350 r:0.7489
ru_en Dev loss: 0.4458 r:0.7442
Current avg r:0.7234 Best avg r: 0.7376
22:08:24,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:39,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:53,900 root INFO Epoch 4 Global steps: 33000 Train loss: 0.2898
ro_en Dev loss: 0.3465 r:0.8190
et_en Dev loss: 0.3994 r:0.6970
si_en Dev loss: 0.7431 r:0.5994
ne_en Dev loss: 0.5147 r:0.7519
ru_en Dev loss: 0.4542 r:0.7425
Current avg r:0.7220 Best avg r: 0.7376
22:14:37,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:52,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:07,8 root INFO Epoch 4 Global steps: 33500 Train loss: 0.2944
ro_en Dev loss: 0.3580 r:0.8246
et_en Dev loss: 0.4110 r:0.7006
si_en Dev loss: 0.7936 r:0.5977
ne_en Dev loss: 0.5001 r:0.7525
ru_en Dev loss: 0.4773 r:0.7511
Current avg r:0.7253 Best avg r: 0.7376
22:20:50,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:05,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:19,659 root INFO Epoch 4 Global steps: 34000 Train loss: 0.3003
ro_en Dev loss: 0.3324 r:0.8257
et_en Dev loss: 0.3910 r:0.7025
si_en Dev loss: 0.7899 r:0.5972
ne_en Dev loss: 0.4628 r:0.7555
ru_en Dev loss: 0.4964 r:0.7402
Current avg r:0.7242 Best avg r: 0.7376
22:27:03,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:18,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:32,760 root INFO Epoch 4 Global steps: 34500 Train loss: 0.2918
ro_en Dev loss: 0.3520 r:0.8196
et_en Dev loss: 0.3903 r:0.7021
si_en Dev loss: 0.7652 r:0.6040
ne_en Dev loss: 0.4270 r:0.7530
ru_en Dev loss: 0.4870 r:0.7380
Current avg r:0.7234 Best avg r: 0.7376
22:33:16,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:31,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:45,909 root INFO Epoch 4 Global steps: 35000 Train loss: 0.2776
ro_en Dev loss: 0.3376 r:0.8177
et_en Dev loss: 0.4273 r:0.6941
si_en Dev loss: 0.7186 r:0.5989
ne_en Dev loss: 0.4315 r:0.7507
ru_en Dev loss: 0.4415 r:0.7416
Current avg r:0.7206 Best avg r: 0.7376
22:39:29,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:43,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:58,777 root INFO Epoch 4 Global steps: 35500 Train loss: 0.2702
ro_en Dev loss: 0.3957 r:0.8159
et_en Dev loss: 0.4358 r:0.6881
si_en Dev loss: 0.9648 r:0.5854
ne_en Dev loss: 0.6401 r:0.7495
ru_en Dev loss: 0.4976 r:0.7407
Current avg r:0.7159 Best avg r: 0.7376
22:45:42,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:56,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:48:10,794 root INFO Epoch 4 Global steps: 36000 Train loss: 0.2749
ro_en Dev loss: 0.3300 r:0.8184
et_en Dev loss: 0.4304 r:0.6943
si_en Dev loss: 0.6830 r:0.5996
ne_en Dev loss: 0.4407 r:0.7514
ru_en Dev loss: 0.4058 r:0.7552
Current avg r:0.7238 Best avg r: 0.7376
22:51:54,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:08,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:23,758 root INFO Epoch 4 Global steps: 36500 Train loss: 0.2859
ro_en Dev loss: 0.3627 r:0.8131
et_en Dev loss: 0.4226 r:0.6955
si_en Dev loss: 0.7576 r:0.5938
ne_en Dev loss: 0.5023 r:0.7450
ru_en Dev loss: 0.4594 r:0.7466
Current avg r:0.7188 Best avg r: 0.7376
22:58:07,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:21,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:36,646 root INFO Epoch 4 Global steps: 37000 Train loss: 0.2800
ro_en Dev loss: 0.3565 r:0.8169
et_en Dev loss: 0.4098 r:0.6964
si_en Dev loss: 0.8194 r:0.5945
ne_en Dev loss: 0.5277 r:0.7549
ru_en Dev loss: 0.5173 r:0.7291
Current avg r:0.7184 Best avg r: 0.7376
23:04:20,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:34,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:49,183 root INFO Epoch 4 Global steps: 37500 Train loss: 0.2665
ro_en Dev loss: 0.3072 r:0.8219
et_en Dev loss: 0.3846 r:0.6990
si_en Dev loss: 0.6878 r:0.6044
ne_en Dev loss: 0.4781 r:0.7503
ru_en Dev loss: 0.4133 r:0.7527
Current avg r:0.7257 Best avg r: 0.7376
23:10:33,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:48,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:02,935 root INFO Epoch 5 Global steps: 38000 Train loss: 0.2430
ro_en Dev loss: 0.3468 r:0.8175
et_en Dev loss: 0.4414 r:0.6906
si_en Dev loss: 0.7091 r:0.5916
ne_en Dev loss: 0.4289 r:0.7484
ru_en Dev loss: 0.4157 r:0.7567
Current avg r:0.7210 Best avg r: 0.7376
23:16:46,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:01,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:16,193 root INFO Epoch 5 Global steps: 38500 Train loss: 0.2460
ro_en Dev loss: 0.3668 r:0.8131
et_en Dev loss: 0.4317 r:0.6801
si_en Dev loss: 0.7438 r:0.5926
ne_en Dev loss: 0.4712 r:0.7465
ru_en Dev loss: 0.4814 r:0.7371
Current avg r:0.7139 Best avg r: 0.7376
23:22:59,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:14,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:29,114 root INFO Epoch 5 Global steps: 39000 Train loss: 0.2545
ro_en Dev loss: 0.3495 r:0.8168
et_en Dev loss: 0.4285 r:0.6806
si_en Dev loss: 0.7764 r:0.5942
ne_en Dev loss: 0.4638 r:0.7488
ru_en Dev loss: 0.4557 r:0.7396
Current avg r:0.7160 Best avg r: 0.7376
23:29:12,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:27,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:42,432 root INFO Epoch 5 Global steps: 39500 Train loss: 0.2396
ro_en Dev loss: 0.3650 r:0.8148
et_en Dev loss: 0.4442 r:0.6856
si_en Dev loss: 0.7853 r:0.5884
ne_en Dev loss: 0.4552 r:0.7496
ru_en Dev loss: 0.4587 r:0.7393
Current avg r:0.7155 Best avg r: 0.7376
23:35:26,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:41,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:56,37 root INFO Epoch 5 Global steps: 40000 Train loss: 0.2389
ro_en Dev loss: 0.3273 r:0.8157
et_en Dev loss: 0.4284 r:0.6862
si_en Dev loss: 0.7030 r:0.5919
ne_en Dev loss: 0.4618 r:0.7440
ru_en Dev loss: 0.4484 r:0.7356
Current avg r:0.7147 Best avg r: 0.7376
23:41:39,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:54,466 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:09,513 root INFO Epoch 5 Global steps: 40500 Train loss: 0.2270
ro_en Dev loss: 0.3415 r:0.8169
et_en Dev loss: 0.4436 r:0.6747
si_en Dev loss: 0.8613 r:0.5742
ne_en Dev loss: 0.5654 r:0.7416
ru_en Dev loss: 0.4510 r:0.7378
Current avg r:0.7090 Best avg r: 0.7376
23:47:53,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:07,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:22,491 root INFO Epoch 5 Global steps: 41000 Train loss: 0.2430
ro_en Dev loss: 0.3465 r:0.8167
et_en Dev loss: 0.4416 r:0.6811
si_en Dev loss: 0.8110 r:0.5792
ne_en Dev loss: 0.5584 r:0.7427
ru_en Dev loss: 0.4599 r:0.7446
Current avg r:0.7128 Best avg r: 0.7376
23:54:06,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:21,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:35,917 root INFO Epoch 5 Global steps: 41500 Train loss: 0.2413
ro_en Dev loss: 0.3464 r:0.8160
et_en Dev loss: 0.4336 r:0.6832
si_en Dev loss: 0.8174 r:0.5830
ne_en Dev loss: 0.4810 r:0.7423
ru_en Dev loss: 0.4806 r:0.7332
Current avg r:0.7115 Best avg r: 0.7376
00:00:19,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:34,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:02:49,443 root INFO Epoch 5 Global steps: 42000 Train loss: 0.2398
ro_en Dev loss: 0.3811 r:0.8161
et_en Dev loss: 0.4506 r:0.6767
si_en Dev loss: 0.9143 r:0.5722
ne_en Dev loss: 0.5506 r:0.7414
ru_en Dev loss: 0.4948 r:0.7357
Current avg r:0.7084 Best avg r: 0.7376
00:06:33,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:47,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:09:02,604 root INFO Epoch 5 Global steps: 42500 Train loss: 0.2300
ro_en Dev loss: 0.3392 r:0.8181
et_en Dev loss: 0.4584 r:0.6821
si_en Dev loss: 0.7220 r:0.5810
ne_en Dev loss: 0.4503 r:0.7427
ru_en Dev loss: 0.4433 r:0.7384
Current avg r:0.7124 Best avg r: 0.7376
00:12:46,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:01,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:16,161 root INFO Epoch 5 Global steps: 43000 Train loss: 0.2292
ro_en Dev loss: 0.3823 r:0.8175
et_en Dev loss: 0.4602 r:0.6777
si_en Dev loss: 0.8916 r:0.5758
ne_en Dev loss: 0.5106 r:0.7464
ru_en Dev loss: 0.4915 r:0.7386
Current avg r:0.7112 Best avg r: 0.7376
00:19:00,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:15,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:21:30,22 root INFO Epoch 5 Global steps: 43500 Train loss: 0.2284
ro_en Dev loss: 0.3425 r:0.8149
et_en Dev loss: 0.4410 r:0.6899
si_en Dev loss: 0.7902 r:0.5777
ne_en Dev loss: 0.4478 r:0.7479
ru_en Dev loss: 0.4218 r:0.7530
Current avg r:0.7167 Best avg r: 0.7376
00:25:13,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:29,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:44,315 root INFO Epoch 5 Global steps: 44000 Train loss: 0.2247
ro_en Dev loss: 0.3875 r:0.8170
et_en Dev loss: 0.4433 r:0.6835
si_en Dev loss: 0.8662 r:0.5755
ne_en Dev loss: 0.5439 r:0.7429
ru_en Dev loss: 0.5258 r:0.7270
Current avg r:0.7092 Best avg r: 0.7376
00:31:28,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:32:42,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:33:57,816 root INFO Epoch 5 Global steps: 44500 Train loss: 0.2343
ro_en Dev loss: 0.3436 r:0.8164
et_en Dev loss: 0.4483 r:0.6835
si_en Dev loss: 0.7963 r:0.5794
ne_en Dev loss: 0.4679 r:0.7445
ru_en Dev loss: 0.4376 r:0.7383
Current avg r:0.7124 Best avg r: 0.7376
00:37:42,5 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:38:57,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:12,606 root INFO Epoch 5 Global steps: 45000 Train loss: 0.2304
ro_en Dev loss: 0.3491 r:0.8175
et_en Dev loss: 0.4432 r:0.6887
si_en Dev loss: 0.7596 r:0.5862
ne_en Dev loss: 0.4948 r:0.7460
ru_en Dev loss: 0.4444 r:0.7457
Current avg r:0.7168 Best avg r: 0.7376
00:43:58,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:13,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:28,990 root INFO Epoch 6 Global steps: 45500 Train loss: 0.1977
ro_en Dev loss: 0.3449 r:0.8206
et_en Dev loss: 0.4318 r:0.6801
si_en Dev loss: 0.9095 r:0.5702
ne_en Dev loss: 0.5729 r:0.7384
ru_en Dev loss: 0.4938 r:0.7289
Current avg r:0.7076 Best avg r: 0.7376
00:50:13,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:28,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:44,533 root INFO Epoch 6 Global steps: 46000 Train loss: 0.2020
ro_en Dev loss: 0.3763 r:0.8140
et_en Dev loss: 0.4468 r:0.6805
si_en Dev loss: 0.8894 r:0.5702
ne_en Dev loss: 0.5462 r:0.7437
ru_en Dev loss: 0.4987 r:0.7333
Current avg r:0.7083 Best avg r: 0.7376
00:56:29,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:44,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:59,990 root INFO Epoch 6 Global steps: 46500 Train loss: 0.2036
ro_en Dev loss: 0.3268 r:0.8180
et_en Dev loss: 0.4231 r:0.6885
si_en Dev loss: 0.7745 r:0.5776
ne_en Dev loss: 0.4465 r:0.7462
ru_en Dev loss: 0.4345 r:0.7390
Current avg r:0.7138 Best avg r: 0.7376
01:02:44,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:59,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:14,202 root INFO Epoch 6 Global steps: 47000 Train loss: 0.1991
ro_en Dev loss: 0.3493 r:0.8173
et_en Dev loss: 0.4563 r:0.6805
si_en Dev loss: 0.8238 r:0.5764
ne_en Dev loss: 0.4901 r:0.7398
ru_en Dev loss: 0.4754 r:0.7282
Current avg r:0.7084 Best avg r: 0.7376
01:08:57,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:12,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:28,4 root INFO Epoch 6 Global steps: 47500 Train loss: 0.2079
ro_en Dev loss: 0.3292 r:0.8188
et_en Dev loss: 0.4489 r:0.6758
si_en Dev loss: 0.8108 r:0.5734
ne_en Dev loss: 0.5061 r:0.7366
ru_en Dev loss: 0.4224 r:0.7421
Current avg r:0.7093 Best avg r: 0.7376
01:15:12,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:27,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:43,246 root INFO Epoch 6 Global steps: 48000 Train loss: 0.2056
ro_en Dev loss: 0.3405 r:0.8157
et_en Dev loss: 0.4462 r:0.6798
si_en Dev loss: 0.7386 r:0.5792
ne_en Dev loss: 0.4464 r:0.7351
ru_en Dev loss: 0.4063 r:0.7563
Current avg r:0.7132 Best avg r: 0.7376
01:21:28,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:22:43,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:59,206 root INFO Epoch 6 Global steps: 48500 Train loss: 0.2092
ro_en Dev loss: 0.3712 r:0.8174
et_en Dev loss: 0.4608 r:0.6778
si_en Dev loss: 0.8476 r:0.5718
ne_en Dev loss: 0.4916 r:0.7339
ru_en Dev loss: 0.4653 r:0.7414
Current avg r:0.7085 Best avg r: 0.7376
01:27:44,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:59,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:14,903 root INFO Epoch 6 Global steps: 49000 Train loss: 0.1904
ro_en Dev loss: 0.3666 r:0.8172
et_en Dev loss: 0.4470 r:0.6687
si_en Dev loss: 0.9366 r:0.5560
ne_en Dev loss: 0.5585 r:0.7288
ru_en Dev loss: 0.4726 r:0.7332
Current avg r:0.7008 Best avg r: 0.7376
01:33:59,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:15,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:30,805 root INFO Epoch 6 Global steps: 49500 Train loss: 0.2117
ro_en Dev loss: 0.3924 r:0.8172
et_en Dev loss: 0.4463 r:0.6814
si_en Dev loss: 0.9195 r:0.5622
ne_en Dev loss: 0.5281 r:0.7301
ru_en Dev loss: 0.5309 r:0.7217
Current avg r:0.7025 Best avg r: 0.7376
01:40:15,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:41:31,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:42:46,887 root INFO Epoch 6 Global steps: 50000 Train loss: 0.1962
ro_en Dev loss: 0.3487 r:0.8156
et_en Dev loss: 0.4606 r:0.6824
si_en Dev loss: 0.7810 r:0.5666
ne_en Dev loss: 0.4632 r:0.7313
ru_en Dev loss: 0.4186 r:0.7495
Current avg r:0.7091 Best avg r: 0.7376
01:46:31,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:47:46,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:49:02,218 root INFO Epoch 6 Global steps: 50500 Train loss: 0.1951
ro_en Dev loss: 0.3515 r:0.8144
et_en Dev loss: 0.4704 r:0.6748
si_en Dev loss: 0.8084 r:0.5662
ne_en Dev loss: 0.4831 r:0.7360
ru_en Dev loss: 0.4028 r:0.7542
Current avg r:0.7091 Best avg r: 0.7376
01:52:46,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:54:02,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:55:17,607 root INFO Epoch 6 Global steps: 51000 Train loss: 0.1922
ro_en Dev loss: 0.3607 r:0.8185
et_en Dev loss: 0.4543 r:0.6811
si_en Dev loss: 0.8223 r:0.5764
ne_en Dev loss: 0.5117 r:0.7355
ru_en Dev loss: 0.4530 r:0.7475
Current avg r:0.7118 Best avg r: 0.7376
01:59:01,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:00:17,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:01:32,668 root INFO Epoch 6 Global steps: 51500 Train loss: 0.1944
ro_en Dev loss: 0.3738 r:0.8174
et_en Dev loss: 0.4606 r:0.6740
si_en Dev loss: 0.8172 r:0.5755
ne_en Dev loss: 0.5441 r:0.7368
ru_en Dev loss: 0.4536 r:0.7444
Current avg r:0.7096 Best avg r: 0.7376
02:05:17,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:32,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:47,909 root INFO Epoch 6 Global steps: 52000 Train loss: 0.1981
ro_en Dev loss: 0.3396 r:0.8190
et_en Dev loss: 0.4889 r:0.6734
si_en Dev loss: 0.7599 r:0.5740
ne_en Dev loss: 0.4678 r:0.7342
ru_en Dev loss: 0.4009 r:0.7563
Current avg r:0.7114 Best avg r: 0.7376
02:11:32,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:48,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:03,701 root INFO Epoch 6 Global steps: 52500 Train loss: 0.1893
ro_en Dev loss: 0.3533 r:0.8199
et_en Dev loss: 0.4543 r:0.6714
si_en Dev loss: 0.7937 r:0.5721
ne_en Dev loss: 0.4752 r:0.7354
ru_en Dev loss: 0.4437 r:0.7464
Current avg r:0.7091 Best avg r: 0.7376
02:17:49,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:19:04,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:20:20,223 root INFO Epoch 7 Global steps: 53000 Train loss: 0.1690
ro_en Dev loss: 0.4092 r:0.8148
et_en Dev loss: 0.4809 r:0.6626
si_en Dev loss: 0.9466 r:0.5605
ne_en Dev loss: 0.5809 r:0.7341
ru_en Dev loss: 0.5267 r:0.7285
Current avg r:0.7001 Best avg r: 0.7376
02:24:05,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:25:20,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:26:35,811 root INFO Epoch 7 Global steps: 53500 Train loss: 0.1756
ro_en Dev loss: 0.3966 r:0.8131
et_en Dev loss: 0.4922 r:0.6649
si_en Dev loss: 0.8915 r:0.5673
ne_en Dev loss: 0.5602 r:0.7391
ru_en Dev loss: 0.5137 r:0.7240
Current avg r:0.7017 Best avg r: 0.7376
02:30:20,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:36,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:32:52,33 root INFO Epoch 7 Global steps: 54000 Train loss: 0.1748
ro_en Dev loss: 0.3453 r:0.8163
et_en Dev loss: 0.4584 r:0.6751
si_en Dev loss: 0.8389 r:0.5692
ne_en Dev loss: 0.5469 r:0.7317
ru_en Dev loss: 0.4448 r:0.7343
Current avg r:0.7053 Best avg r: 0.7376
02:36:36,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:52,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:39:08,603 root INFO Epoch 7 Global steps: 54500 Train loss: 0.1654
ro_en Dev loss: 0.4344 r:0.8140
et_en Dev loss: 0.5152 r:0.6560
si_en Dev loss: 1.0455 r:0.5569
ne_en Dev loss: 0.6930 r:0.7279
ru_en Dev loss: 0.5390 r:0.7178
Current avg r:0.6945 Best avg r: 0.7376
02:42:53,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:44:09,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:24,829 root INFO Epoch 7 Global steps: 55000 Train loss: 0.1660
ro_en Dev loss: 0.3602 r:0.8159
et_en Dev loss: 0.4868 r:0.6702
si_en Dev loss: 0.8362 r:0.5767
ne_en Dev loss: 0.4891 r:0.7352
ru_en Dev loss: 0.4340 r:0.7509
Current avg r:0.7098 Best avg r: 0.7376
02:49:10,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:25,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:41,61 root INFO Epoch 7 Global steps: 55500 Train loss: 0.1688
ro_en Dev loss: 0.3472 r:0.8146
et_en Dev loss: 0.4562 r:0.6671
si_en Dev loss: 0.8795 r:0.5619
ne_en Dev loss: 0.5560 r:0.7306
ru_en Dev loss: 0.4589 r:0.7377
Current avg r:0.7024 Best avg r: 0.7376
02:55:26,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:41,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:57:57,600 root INFO Epoch 7 Global steps: 56000 Train loss: 0.1622
ro_en Dev loss: 0.3457 r:0.8158
et_en Dev loss: 0.4581 r:0.6766
si_en Dev loss: 0.7856 r:0.5746
ne_en Dev loss: 0.4646 r:0.7348
ru_en Dev loss: 0.4109 r:0.7543
Current avg r:0.7112 Best avg r: 0.7376
03:01:42,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:02:58,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:14,177 root INFO Epoch 7 Global steps: 56500 Train loss: 0.1670
ro_en Dev loss: 0.3180 r:0.8184
et_en Dev loss: 0.4510 r:0.6799
si_en Dev loss: 0.7416 r:0.5757
ne_en Dev loss: 0.4492 r:0.7347
ru_en Dev loss: 0.3834 r:0.7617
Current avg r:0.7141 Best avg r: 0.7376
03:07:59,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:14,391 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:10:29,817 root INFO Epoch 7 Global steps: 57000 Train loss: 0.1710
ro_en Dev loss: 0.3763 r:0.8137
et_en Dev loss: 0.4665 r:0.6616
si_en Dev loss: 0.9388 r:0.5625
ne_en Dev loss: 0.5734 r:0.7357
ru_en Dev loss: 0.4944 r:0.7287
Current avg r:0.7005 Best avg r: 0.7376
03:14:14,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:15:29,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:45,311 root INFO Epoch 7 Global steps: 57500 Train loss: 0.1689
ro_en Dev loss: 0.3583 r:0.8140
et_en Dev loss: 0.4662 r:0.6639
si_en Dev loss: 0.9246 r:0.5597
ne_en Dev loss: 0.5285 r:0.7347
ru_en Dev loss: 0.4481 r:0.7431
Current avg r:0.7031 Best avg r: 0.7376
03:20:29,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:45,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:00,521 root INFO Epoch 7 Global steps: 58000 Train loss: 0.1664
ro_en Dev loss: 0.3985 r:0.8129
et_en Dev loss: 0.4774 r:0.6609
si_en Dev loss: 0.9951 r:0.5573
ne_en Dev loss: 0.6623 r:0.7372
ru_en Dev loss: 0.5146 r:0.7238
Current avg r:0.6984 Best avg r: 0.7376
03:26:45,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:00,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:29:16,6 root INFO Epoch 7 Global steps: 58500 Train loss: 0.1746
ro_en Dev loss: 0.3491 r:0.8176
et_en Dev loss: 0.4958 r:0.6701
si_en Dev loss: 0.8291 r:0.5623
ne_en Dev loss: 0.5214 r:0.7298
ru_en Dev loss: 0.4391 r:0.7413
Current avg r:0.7042 Best avg r: 0.7376
03:33:00,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:34:16,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:35:31,308 root INFO Epoch 7 Global steps: 59000 Train loss: 0.1632
ro_en Dev loss: 0.3254 r:0.8178
et_en Dev loss: 0.4693 r:0.6635
si_en Dev loss: 0.8371 r:0.5520
ne_en Dev loss: 0.4946 r:0.7340
ru_en Dev loss: 0.4433 r:0.7316
Current avg r:0.6998 Best avg r: 0.7376
03:39:15,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:31,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:46,517 root INFO Epoch 7 Global steps: 59500 Train loss: 0.1705
ro_en Dev loss: 0.3503 r:0.8168
et_en Dev loss: 0.4735 r:0.6508
si_en Dev loss: 0.8892 r:0.5494
ne_en Dev loss: 0.5574 r:0.7306
ru_en Dev loss: 0.4534 r:0.7348
Current avg r:0.6965 Best avg r: 0.7376
03:45:31,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:46:46,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:48:01,699 root INFO Epoch 7 Global steps: 60000 Train loss: 0.1642
ro_en Dev loss: 0.3808 r:0.8113
et_en Dev loss: 0.4982 r:0.6462
si_en Dev loss: 0.9724 r:0.5459
ne_en Dev loss: 0.5320 r:0.7344
ru_en Dev loss: 0.5059 r:0.7266
Current avg r:0.6929 Best avg r: 0.7376
03:51:47,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:53:02,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:54:18,100 root INFO Epoch 8 Global steps: 60500 Train loss: 0.1453
ro_en Dev loss: 0.3572 r:0.8148
et_en Dev loss: 0.4846 r:0.6600
si_en Dev loss: 0.8547 r:0.5547
ne_en Dev loss: 0.5288 r:0.7295
ru_en Dev loss: 0.4785 r:0.7316
Current avg r:0.6981 Best avg r: 0.7376
03:58:02,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:59:17,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:33,334 root INFO Epoch 8 Global steps: 61000 Train loss: 0.1557
ro_en Dev loss: 0.3265 r:0.8166
et_en Dev loss: 0.4616 r:0.6649
si_en Dev loss: 0.8180 r:0.5615
ne_en Dev loss: 0.5220 r:0.7347
ru_en Dev loss: 0.4214 r:0.7443
Current avg r:0.7044 Best avg r: 0.7376
04:04:17,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:05:33,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:06:48,723 root INFO Epoch 8 Global steps: 61500 Train loss: 0.1500
ro_en Dev loss: 0.3674 r:0.8169
et_en Dev loss: 0.4654 r:0.6660
si_en Dev loss: 0.9753 r:0.5562
ne_en Dev loss: 0.6273 r:0.7352
ru_en Dev loss: 0.4630 r:0.7403
Current avg r:0.7029 Best avg r: 0.7376
04:10:33,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:11:48,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:13:04,186 root INFO Epoch 8 Global steps: 62000 Train loss: 0.1496
ro_en Dev loss: 0.3628 r:0.8160
et_en Dev loss: 0.4737 r:0.6597
si_en Dev loss: 0.9327 r:0.5550
ne_en Dev loss: 0.5890 r:0.7323
ru_en Dev loss: 0.4792 r:0.7276
Current avg r:0.6981 Best avg r: 0.7376
04:16:48,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:18:04,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:19,433 root INFO Epoch 8 Global steps: 62500 Train loss: 0.1431
ro_en Dev loss: 0.3817 r:0.8143
et_en Dev loss: 0.4892 r:0.6620
si_en Dev loss: 0.8764 r:0.5617
ne_en Dev loss: 0.4938 r:0.7368
ru_en Dev loss: 0.4788 r:0.7412
Current avg r:0.7032 Best avg r: 0.7376
04:23:03,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:24:19,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:25:34,505 root INFO Epoch 8 Global steps: 63000 Train loss: 0.1476
ro_en Dev loss: 0.3904 r:0.8125
et_en Dev loss: 0.4753 r:0.6525
si_en Dev loss: 0.9124 r:0.5577
ne_en Dev loss: 0.5752 r:0.7352
ru_en Dev loss: 0.4909 r:0.7343
Current avg r:0.6984 Best avg r: 0.7376
04:29:18,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:34,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:49,612 root INFO Epoch 8 Global steps: 63500 Train loss: 0.1448
ro_en Dev loss: 0.3684 r:0.8121
et_en Dev loss: 0.4670 r:0.6568
si_en Dev loss: 0.9300 r:0.5540
ne_en Dev loss: 0.5137 r:0.7350
ru_en Dev loss: 0.4362 r:0.7494
Current avg r:0.7015 Best avg r: 0.7376
04:35:34,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:49,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:04,638 root INFO Epoch 8 Global steps: 64000 Train loss: 0.1420
ro_en Dev loss: 0.3858 r:0.8112
et_en Dev loss: 0.4854 r:0.6611
si_en Dev loss: 0.8806 r:0.5605
ne_en Dev loss: 0.5704 r:0.7271
ru_en Dev loss: 0.5132 r:0.7295
Current avg r:0.6979 Best avg r: 0.7376
04:41:49,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:04,391 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:19,822 root INFO Epoch 8 Global steps: 64500 Train loss: 0.1432
ro_en Dev loss: 0.3866 r:0.8069
et_en Dev loss: 0.4884 r:0.6596
si_en Dev loss: 0.9127 r:0.5534
ne_en Dev loss: 0.5448 r:0.7310
ru_en Dev loss: 0.4867 r:0.7324
Current avg r:0.6967 Best avg r: 0.7376
04:48:04,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:49:19,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:50:35,150 root INFO Epoch 8 Global steps: 65000 Train loss: 0.1442
ro_en Dev loss: 0.3625 r:0.8130
et_en Dev loss: 0.4746 r:0.6660
si_en Dev loss: 0.9108 r:0.5580
ne_en Dev loss: 0.5561 r:0.7276
ru_en Dev loss: 0.4743 r:0.7357
Current avg r:0.7001 Best avg r: 0.7376
04:54:19,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:55:34,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:56:50,157 root INFO Epoch 8 Global steps: 65500 Train loss: 0.1492
ro_en Dev loss: 0.3617 r:0.8145
et_en Dev loss: 0.4783 r:0.6735
si_en Dev loss: 0.8166 r:0.5694
ne_en Dev loss: 0.4761 r:0.7295
ru_en Dev loss: 0.4392 r:0.7558
Current avg r:0.7086 Best avg r: 0.7376
05:00:34,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:01:50,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:05,322 root INFO Epoch 8 Global steps: 66000 Train loss: 0.1443
ro_en Dev loss: 0.3547 r:0.8149
et_en Dev loss: 0.4711 r:0.6683
si_en Dev loss: 0.8948 r:0.5547
ne_en Dev loss: 0.5219 r:0.7309
ru_en Dev loss: 0.4770 r:0.7314
Current avg r:0.7000 Best avg r: 0.7376
05:06:49,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:08:05,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:09:20,532 root INFO Epoch 8 Global steps: 66500 Train loss: 0.1406
ro_en Dev loss: 0.3768 r:0.8127
et_en Dev loss: 0.4912 r:0.6672
si_en Dev loss: 0.8845 r:0.5524
ne_en Dev loss: 0.5372 r:0.7257
ru_en Dev loss: 0.4539 r:0.7471
Current avg r:0.7010 Best avg r: 0.7376
05:13:05,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:20,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:35,697 root INFO Epoch 8 Global steps: 67000 Train loss: 0.1380
ro_en Dev loss: 0.3429 r:0.8163
et_en Dev loss: 0.4817 r:0.6675
si_en Dev loss: 0.7795 r:0.5626
ne_en Dev loss: 0.4611 r:0.7296
ru_en Dev loss: 0.4016 r:0.7617
Current avg r:0.7075 Best avg r: 0.7376
05:19:19,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:35,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:21:50,741 root INFO Epoch 8 Global steps: 67500 Train loss: 0.1430
ro_en Dev loss: 0.4184 r:0.8142
et_en Dev loss: 0.5019 r:0.6556
si_en Dev loss: 1.1145 r:0.5425
ne_en Dev loss: 0.7599 r:0.7190
ru_en Dev loss: 0.5161 r:0.7347
Current avg r:0.6932 Best avg r: 0.7376
05:25:35,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:26:50,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:28:06,228 root INFO Epoch 9 Global steps: 68000 Train loss: 0.1278
ro_en Dev loss: 0.3582 r:0.8157
et_en Dev loss: 0.4718 r:0.6608
si_en Dev loss: 0.8635 r:0.5526
ne_en Dev loss: 0.5162 r:0.7245
ru_en Dev loss: 0.5037 r:0.7212
Current avg r:0.6949 Best avg r: 0.7376
05:31:50,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:33:05,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:34:20,805 root INFO Epoch 9 Global steps: 68500 Train loss: 0.1305
ro_en Dev loss: 0.3805 r:0.8124
et_en Dev loss: 0.4858 r:0.6579
si_en Dev loss: 0.9437 r:0.5437
ne_en Dev loss: 0.5999 r:0.7234
ru_en Dev loss: 0.4998 r:0.7277
Current avg r:0.6930 Best avg r: 0.7376
05:38:04,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:39:20,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:40:35,614 root INFO Epoch 9 Global steps: 69000 Train loss: 0.1230
ro_en Dev loss: 0.3460 r:0.8156
et_en Dev loss: 0.4487 r:0.6634
si_en Dev loss: 0.8739 r:0.5537
ne_en Dev loss: 0.5655 r:0.7217
ru_en Dev loss: 0.4382 r:0.7431
Current avg r:0.6995 Best avg r: 0.7376
05:44:19,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:45:35,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:49,964 root INFO Epoch 9 Global steps: 69500 Train loss: 0.1308
ro_en Dev loss: 0.3533 r:0.8179
et_en Dev loss: 0.4477 r:0.6688
si_en Dev loss: 0.9171 r:0.5506
ne_en Dev loss: 0.6475 r:0.7221
ru_en Dev loss: 0.4576 r:0.7357
Current avg r:0.6990 Best avg r: 0.7376
05:50:33,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:48,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:04,68 root INFO Epoch 9 Global steps: 70000 Train loss: 0.1255
ro_en Dev loss: 0.3757 r:0.8138
et_en Dev loss: 0.4883 r:0.6673
si_en Dev loss: 0.9098 r:0.5462
ne_en Dev loss: 0.5788 r:0.7226
ru_en Dev loss: 0.4553 r:0.7422
Current avg r:0.6984 Best avg r: 0.7376
05:56:48,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:58:03,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:18,897 root INFO Epoch 9 Global steps: 70500 Train loss: 0.1305
ro_en Dev loss: 0.3501 r:0.8158
et_en Dev loss: 0.4818 r:0.6723
si_en Dev loss: 0.8344 r:0.5624
ne_en Dev loss: 0.5120 r:0.7216
ru_en Dev loss: 0.4421 r:0.7408
Current avg r:0.7026 Best avg r: 0.7376
06:03:03,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:18,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:34,285 root INFO Epoch 9 Global steps: 71000 Train loss: 0.1275
ro_en Dev loss: 0.3623 r:0.8135
et_en Dev loss: 0.4621 r:0.6595
si_en Dev loss: 0.9191 r:0.5472
ne_en Dev loss: 0.5938 r:0.7277
ru_en Dev loss: 0.4801 r:0.7269
Current avg r:0.6949 Best avg r: 0.7376
06:09:18,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:10:34,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:49,822 root INFO Epoch 9 Global steps: 71500 Train loss: 0.1242
ro_en Dev loss: 0.3688 r:0.8119
et_en Dev loss: 0.4855 r:0.6629
si_en Dev loss: 0.8975 r:0.5513
ne_en Dev loss: 0.5596 r:0.7270
ru_en Dev loss: 0.4648 r:0.7361
Current avg r:0.6978 Best avg r: 0.7376
06:15:34,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:16:50,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:05,303 root INFO Epoch 9 Global steps: 72000 Train loss: 0.1299
ro_en Dev loss: 0.3718 r:0.8155
et_en Dev loss: 0.4844 r:0.6602
si_en Dev loss: 0.9074 r:0.5560
ne_en Dev loss: 0.5814 r:0.7215
ru_en Dev loss: 0.4634 r:0.7437
Current avg r:0.6994 Best avg r: 0.7376
06:21:50,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:23:05,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:21,151 root INFO Epoch 9 Global steps: 72500 Train loss: 0.1263
ro_en Dev loss: 0.3573 r:0.8126
et_en Dev loss: 0.4708 r:0.6536
si_en Dev loss: 0.9199 r:0.5452
ne_en Dev loss: 0.6015 r:0.7232
ru_en Dev loss: 0.4376 r:0.7456
Current avg r:0.6960 Best avg r: 0.7376
06:28:06,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:21,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:37,31 root INFO Epoch 9 Global steps: 73000 Train loss: 0.1273
ro_en Dev loss: 0.3782 r:0.8138
et_en Dev loss: 0.4938 r:0.6629
si_en Dev loss: 0.9303 r:0.5554
ne_en Dev loss: 0.5526 r:0.7307
ru_en Dev loss: 0.4530 r:0.7502
Current avg r:0.7026 Best avg r: 0.7376
06:34:21,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:35:37,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:36:52,876 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1227
ro_en Dev loss: 0.3542 r:0.8119
et_en Dev loss: 0.4809 r:0.6564
si_en Dev loss: 0.8754 r:0.5445
ne_en Dev loss: 0.5030 r:0.7228
ru_en Dev loss: 0.4647 r:0.7371
Current avg r:0.6946 Best avg r: 0.7376
06:40:37,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:53,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:43:08,717 root INFO Epoch 9 Global steps: 74000 Train loss: 0.1300
ro_en Dev loss: 0.4054 r:0.8124
et_en Dev loss: 0.5025 r:0.6638
si_en Dev loss: 0.9751 r:0.5511
ne_en Dev loss: 0.6056 r:0.7251
ru_en Dev loss: 0.5247 r:0.7290
Current avg r:0.6963 Best avg r: 0.7376
06:46:53,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:48:08,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:49:24,397 root INFO Epoch 9 Global steps: 74500 Train loss: 0.1242
ro_en Dev loss: 0.3699 r:0.8165
et_en Dev loss: 0.4767 r:0.6659
si_en Dev loss: 0.8817 r:0.5526
ne_en Dev loss: 0.5776 r:0.7195
ru_en Dev loss: 0.4764 r:0.7423
Current avg r:0.6993 Best avg r: 0.7376
06:53:09,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:24,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:55:40,205 root INFO Epoch 9 Global steps: 75000 Train loss: 0.1270
ro_en Dev loss: 0.3677 r:0.8138
et_en Dev loss: 0.4898 r:0.6665
si_en Dev loss: 0.9387 r:0.5471
ne_en Dev loss: 0.5709 r:0.7157
ru_en Dev loss: 0.4678 r:0.7412
Current avg r:0.6969 Best avg r: 0.7376
06:59:25,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:41,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:56,680 root INFO Epoch 10 Global steps: 75500 Train loss: 0.1084
ro_en Dev loss: 0.3252 r:0.8174
et_en Dev loss: 0.4676 r:0.6740
si_en Dev loss: 0.8144 r:0.5593
ne_en Dev loss: 0.4895 r:0.7211
ru_en Dev loss: 0.4112 r:0.7467
Current avg r:0.7037 Best avg r: 0.7376
07:05:41,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:06:57,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:12,551 root INFO Epoch 10 Global steps: 76000 Train loss: 0.1136
ro_en Dev loss: 0.3756 r:0.8114
et_en Dev loss: 0.4762 r:0.6578
si_en Dev loss: 0.9588 r:0.5471
ne_en Dev loss: 0.6455 r:0.7172
ru_en Dev loss: 0.5120 r:0.7230
Current avg r:0.6913 Best avg r: 0.7376
07:11:57,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:12,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:14:28,349 root INFO Epoch 10 Global steps: 76500 Train loss: 0.1161
ro_en Dev loss: 0.3290 r:0.8141
et_en Dev loss: 0.4629 r:0.6625
si_en Dev loss: 0.8128 r:0.5515
ne_en Dev loss: 0.5372 r:0.7167
ru_en Dev loss: 0.4299 r:0.7411
Current avg r:0.6972 Best avg r: 0.7376
07:18:13,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:19:28,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:44,296 root INFO Epoch 10 Global steps: 77000 Train loss: 0.1170
ro_en Dev loss: 0.3857 r:0.8107
et_en Dev loss: 0.4869 r:0.6583
si_en Dev loss: 0.9845 r:0.5513
ne_en Dev loss: 0.6376 r:0.7213
ru_en Dev loss: 0.5093 r:0.7316
Current avg r:0.6946 Best avg r: 0.7376
07:24:29,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:44,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:27:00,383 root INFO Epoch 10 Global steps: 77500 Train loss: 0.1142
ro_en Dev loss: 0.3392 r:0.8148
et_en Dev loss: 0.4801 r:0.6660
si_en Dev loss: 0.8294 r:0.5552
ne_en Dev loss: 0.5291 r:0.7140
ru_en Dev loss: 0.4244 r:0.7521
Current avg r:0.7004 Best avg r: 0.7376
07:30:45,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:00,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:33:16,322 root INFO Epoch 10 Global steps: 78000 Train loss: 0.1123
ro_en Dev loss: 0.3732 r:0.8178
et_en Dev loss: 0.4730 r:0.6625
si_en Dev loss: 0.8663 r:0.5597
ne_en Dev loss: 0.5647 r:0.7120
ru_en Dev loss: 0.4843 r:0.7438
Current avg r:0.6992 Best avg r: 0.7376
07:37:01,153 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:16,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:39:32,458 root INFO Epoch 10 Global steps: 78500 Train loss: 0.1175
ro_en Dev loss: 0.3678 r:0.8155
et_en Dev loss: 0.4885 r:0.6664
si_en Dev loss: 0.8867 r:0.5562
ne_en Dev loss: 0.5578 r:0.7123
ru_en Dev loss: 0.4760 r:0.7397
Current avg r:0.6980 Best avg r: 0.7376
07:43:17,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:44:32,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:48,71 root INFO Epoch 10 Global steps: 79000 Train loss: 0.1083
ro_en Dev loss: 0.3797 r:0.8139
et_en Dev loss: 0.4855 r:0.6520
si_en Dev loss: 0.9231 r:0.5499
ne_en Dev loss: 0.6399 r:0.7108
ru_en Dev loss: 0.5373 r:0.7173
Current avg r:0.6888 Best avg r: 0.7376
07:49:33,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:50:48,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:04,65 root INFO Epoch 10 Global steps: 79500 Train loss: 0.1143
ro_en Dev loss: 0.3427 r:0.8173
et_en Dev loss: 0.4766 r:0.6625
si_en Dev loss: 0.8620 r:0.5534
ne_en Dev loss: 0.5659 r:0.7163
ru_en Dev loss: 0.4015 r:0.7553
Current avg r:0.7009 Best avg r: 0.7376
07:55:48,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:57:04,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:58:19,896 root INFO Epoch 10 Global steps: 80000 Train loss: 0.1109
ro_en Dev loss: 0.3740 r:0.8141
et_en Dev loss: 0.4852 r:0.6603
si_en Dev loss: 0.9131 r:0.5537
ne_en Dev loss: 0.5838 r:0.7179
ru_en Dev loss: 0.5086 r:0.7255
Current avg r:0.6943 Best avg r: 0.7376
08:02:04,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:03:19,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:04:35,465 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1089
ro_en Dev loss: 0.3733 r:0.8137
et_en Dev loss: 0.4810 r:0.6559
si_en Dev loss: 0.9661 r:0.5524
ne_en Dev loss: 0.6287 r:0.7142
ru_en Dev loss: 0.4951 r:0.7234
Current avg r:0.6919 Best avg r: 0.7376
08:08:20,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:35,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:51,85 root INFO Epoch 10 Global steps: 81000 Train loss: 0.1130
ro_en Dev loss: 0.3499 r:0.8143
et_en Dev loss: 0.4729 r:0.6692
si_en Dev loss: 0.8579 r:0.5576
ne_en Dev loss: 0.5467 r:0.7208
ru_en Dev loss: 0.4671 r:0.7317
Current avg r:0.6987 Best avg r: 0.7376
08:14:35,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:51,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:17:06,709 root INFO Epoch 10 Global steps: 81500 Train loss: 0.1078
ro_en Dev loss: 0.3826 r:0.8131
et_en Dev loss: 0.4953 r:0.6634
si_en Dev loss: 0.9363 r:0.5568
ne_en Dev loss: 0.6416 r:0.7231
ru_en Dev loss: 0.5043 r:0.7200
Current avg r:0.6953 Best avg r: 0.7376
08:20:51,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:22:07,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:22,675 root INFO Epoch 10 Global steps: 82000 Train loss: 0.1123
ro_en Dev loss: 0.3373 r:0.8166
et_en Dev loss: 0.4720 r:0.6761
si_en Dev loss: 0.7957 r:0.5637
ne_en Dev loss: 0.5294 r:0.7230
ru_en Dev loss: 0.4103 r:0.7480
Current avg r:0.7055 Best avg r: 0.7376
08:27:07,555 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:22,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:38,367 root INFO Epoch 10 Global steps: 82500 Train loss: 0.1108
ro_en Dev loss: 0.3365 r:0.8155
et_en Dev loss: 0.4536 r:0.6654
si_en Dev loss: 0.8896 r:0.5531
ne_en Dev loss: 0.5746 r:0.7217
ru_en Dev loss: 0.4173 r:0.7493
Current avg r:0.7010 Best avg r: 0.7376
08:33:23,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:34:39,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:35:54,811 root INFO Epoch 11 Global steps: 83000 Train loss: 0.0972
ro_en Dev loss: 0.3837 r:0.8145
et_en Dev loss: 0.4926 r:0.6641
si_en Dev loss: 0.9388 r:0.5611
ne_en Dev loss: 0.5977 r:0.7182
ru_en Dev loss: 0.4776 r:0.7413
Current avg r:0.6998 Best avg r: 0.7376
08:39:39,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:40:54,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:42:10,286 root INFO Epoch 11 Global steps: 83500 Train loss: 0.1029
ro_en Dev loss: 0.3725 r:0.8127
et_en Dev loss: 0.4699 r:0.6601
si_en Dev loss: 0.9400 r:0.5520
ne_en Dev loss: 0.5916 r:0.7153
ru_en Dev loss: 0.4831 r:0.7314
Current avg r:0.6943 Best avg r: 0.7376
08:45:54,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:10,298 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:48:25,806 root INFO Epoch 11 Global steps: 84000 Train loss: 0.0977
ro_en Dev loss: 0.3699 r:0.8159
et_en Dev loss: 0.4751 r:0.6730
si_en Dev loss: 0.9080 r:0.5613
ne_en Dev loss: 0.5659 r:0.7228
ru_en Dev loss: 0.4397 r:0.7528
Current avg r:0.7052 Best avg r: 0.7376
08:52:10,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:26,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:41,198 root INFO Epoch 11 Global steps: 84500 Train loss: 0.1000
ro_en Dev loss: 0.3469 r:0.8191
et_en Dev loss: 0.4555 r:0.6825
si_en Dev loss: 0.8093 r:0.5753
ne_en Dev loss: 0.5325 r:0.7231
ru_en Dev loss: 0.4180 r:0.7601
Current avg r:0.7120 Best avg r: 0.7376
08:58:25,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:59:41,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:00:56,623 root INFO Epoch 11 Global steps: 85000 Train loss: 0.1008
ro_en Dev loss: 0.3654 r:0.8159
et_en Dev loss: 0.4684 r:0.6731
si_en Dev loss: 0.8661 r:0.5691
ne_en Dev loss: 0.5751 r:0.7248
ru_en Dev loss: 0.4650 r:0.7479
Current avg r:0.7061 Best avg r: 0.7376
09:04:41,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:05:56,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:07:11,548 root INFO Epoch 11 Global steps: 85500 Train loss: 0.1032
ro_en Dev loss: 0.3569 r:0.8102
et_en Dev loss: 0.4687 r:0.6706
si_en Dev loss: 0.8462 r:0.5597
ne_en Dev loss: 0.5820 r:0.7157
ru_en Dev loss: 0.4394 r:0.7423
Current avg r:0.6997 Best avg r: 0.7376
09:10:56,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:12:11,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:13:27,400 root INFO Epoch 11 Global steps: 86000 Train loss: 0.0972
ro_en Dev loss: 0.3750 r:0.8150
et_en Dev loss: 0.4515 r:0.6665
si_en Dev loss: 0.9194 r:0.5654
ne_en Dev loss: 0.6468 r:0.7137
ru_en Dev loss: 0.4693 r:0.7397
Current avg r:0.7000 Best avg r: 0.7376
09:17:12,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:27,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:43,116 root INFO Epoch 11 Global steps: 86500 Train loss: 0.1034
ro_en Dev loss: 0.3484 r:0.8111
et_en Dev loss: 0.4680 r:0.6695
si_en Dev loss: 0.8489 r:0.5603
ne_en Dev loss: 0.5797 r:0.7173
ru_en Dev loss: 0.4261 r:0.7509
Current avg r:0.7018 Best avg r: 0.7376
09:23:28,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:24:43,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:25:59,221 root INFO Epoch 11 Global steps: 87000 Train loss: 0.1016
ro_en Dev loss: 0.3616 r:0.8121
et_en Dev loss: 0.4728 r:0.6644
si_en Dev loss: 0.8721 r:0.5521
ne_en Dev loss: 0.5545 r:0.7202
ru_en Dev loss: 0.4585 r:0.7451
Current avg r:0.6988 Best avg r: 0.7376
09:29:44,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:59,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:32:15,178 root INFO Epoch 11 Global steps: 87500 Train loss: 0.0972
ro_en Dev loss: 0.3753 r:0.8167
et_en Dev loss: 0.4551 r:0.6718
si_en Dev loss: 0.8907 r:0.5605
ne_en Dev loss: 0.5847 r:0.7202
ru_en Dev loss: 0.4579 r:0.7478
Current avg r:0.7034 Best avg r: 0.7376
09:35:59,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:37:15,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:38:30,719 root INFO Epoch 11 Global steps: 88000 Train loss: 0.1012
ro_en Dev loss: 0.3512 r:0.8134
et_en Dev loss: 0.4544 r:0.6659
si_en Dev loss: 0.9024 r:0.5504
ne_en Dev loss: 0.5869 r:0.7163
ru_en Dev loss: 0.4244 r:0.7509
Current avg r:0.6994 Best avg r: 0.7376
09:42:15,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:31,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:44:46,477 root INFO Epoch 11 Global steps: 88500 Train loss: 0.0949
ro_en Dev loss: 0.3603 r:0.8137
et_en Dev loss: 0.4641 r:0.6697
si_en Dev loss: 0.8147 r:0.5611
ne_en Dev loss: 0.5324 r:0.7137
ru_en Dev loss: 0.4211 r:0.7562
Current avg r:0.7029 Best avg r: 0.7376
09:48:31,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:49:47,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:02,501 root INFO Epoch 11 Global steps: 89000 Train loss: 0.0967
ro_en Dev loss: 0.3710 r:0.8173
et_en Dev loss: 0.4588 r:0.6790
si_en Dev loss: 0.9061 r:0.5606
ne_en Dev loss: 0.5939 r:0.7196
ru_en Dev loss: 0.4725 r:0.7452
Current avg r:0.7043 Best avg r: 0.7376
09:54:47,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:03,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:18,746 root INFO Epoch 11 Global steps: 89500 Train loss: 0.0918
ro_en Dev loss: 0.3613 r:0.8168
et_en Dev loss: 0.4840 r:0.6700
si_en Dev loss: 0.8889 r:0.5587
ne_en Dev loss: 0.5836 r:0.7205
ru_en Dev loss: 0.4605 r:0.7469
Current avg r:0.7026 Best avg r: 0.7376
10:01:03,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:18,765 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:33,981 root INFO Epoch 11 Global steps: 90000 Train loss: 0.0953
ro_en Dev loss: 0.3613 r:0.8131
et_en Dev loss: 0.4669 r:0.6656
si_en Dev loss: 0.9308 r:0.5499
ne_en Dev loss: 0.5883 r:0.7235
ru_en Dev loss: 0.4448 r:0.7457
Current avg r:0.6996 Best avg r: 0.7376
10:07:19,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:35,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:50,643 root INFO Epoch 12 Global steps: 90500 Train loss: 0.0907
ro_en Dev loss: 0.3481 r:0.8177
et_en Dev loss: 0.4580 r:0.6734
si_en Dev loss: 0.8796 r:0.5623
ne_en Dev loss: 0.5544 r:0.7254
ru_en Dev loss: 0.4167 r:0.7568
Current avg r:0.7071 Best avg r: 0.7376
10:13:35,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:51,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:16:06,758 root INFO Epoch 12 Global steps: 91000 Train loss: 0.0920
ro_en Dev loss: 0.3538 r:0.8148
et_en Dev loss: 0.4614 r:0.6702
si_en Dev loss: 0.9017 r:0.5535
ne_en Dev loss: 0.5477 r:0.7174
ru_en Dev loss: 0.4632 r:0.7384
Current avg r:0.6989 Best avg r: 0.7376
10:19:51,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:07,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:22,912 root INFO Epoch 12 Global steps: 91500 Train loss: 0.0942
ro_en Dev loss: 0.3552 r:0.8158
et_en Dev loss: 0.4741 r:0.6730
si_en Dev loss: 0.8779 r:0.5548
ne_en Dev loss: 0.5673 r:0.7176
ru_en Dev loss: 0.4465 r:0.7452
Current avg r:0.7013 Best avg r: 0.7376
10:26:07,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:23,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:28:38,406 root INFO Epoch 12 Global steps: 92000 Train loss: 0.0920
ro_en Dev loss: 0.3273 r:0.8192
et_en Dev loss: 0.4525 r:0.6776
si_en Dev loss: 0.8018 r:0.5643
ne_en Dev loss: 0.5251 r:0.7168
ru_en Dev loss: 0.4532 r:0.7466
Current avg r:0.7049 Best avg r: 0.7376
10:32:22,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:33:37,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:34:52,157 root INFO Epoch 12 Global steps: 92500 Train loss: 0.0912
ro_en Dev loss: 0.3699 r:0.8137
et_en Dev loss: 0.4721 r:0.6594
si_en Dev loss: 0.9683 r:0.5540
ne_en Dev loss: 0.6314 r:0.7155
ru_en Dev loss: 0.4752 r:0.7374
Current avg r:0.6960 Best avg r: 0.7376
10:38:36,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:50,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:16,435 root INFO 
id:ro_en cur r: 0.5114 best r: 0.5114
00:36:42,268 root INFO 
id:et_en cur r: 0.0132 best r: 0.0132
00:37:08,120 root INFO 
id:si_en cur r: 0.2762 best r: 0.2762
00:37:33,979 root INFO 
id:ne_en cur r: 0.4284 best r: 0.4284
00:37:59,585 root INFO 
id:ru_en cur r: 0.3742 best r: 0.3742
00:37:59,586 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:03,963 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
00:39:03,970 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
00:39:03,976 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
00:39:03,981 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
00:39:03,990 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
00:40:08,421 root INFO Epoch 0 Global steps: 500 Train loss: 0.9315
ro_en Dev loss: 0.7900 r:0.4966
et_en Dev loss: 0.7331 r:0.3081
si_en Dev loss: 0.8287 r:0.3076
ne_en Dev loss: 0.7602 r:0.4700
ru_en Dev loss: 0.7795 r:0.4044
Current avg r:0.3973 Best avg r: 0.3973
00:43:19,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:44,883 root INFO 
id:ro_en cur r: 0.5897 best r: 0.5897
00:44:10,725 root INFO 
id:et_en cur r: 0.3828 best r: 0.3828
00:44:36,563 root INFO 
id:si_en cur r: 0.4116 best r: 0.4116
00:45:02,414 root INFO 
id:ne_en cur r: 0.5873 best r: 0.5873
00:45:28,24 root INFO 
id:ru_en cur r: 0.4052 best r: 0.4052
00:45:28,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:32,421 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
00:46:32,430 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
00:46:32,437 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
00:46:32,442 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
00:46:32,447 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
00:47:36,880 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8686
ro_en Dev loss: 0.7116 r:0.6019
et_en Dev loss: 0.6244 r:0.4145
si_en Dev loss: 0.7630 r:0.4296
ne_en Dev loss: 0.6113 r:0.6037
ru_en Dev loss: 0.7013 r:0.4620
Current avg r:0.5023 Best avg r: 0.5023
00:50:47,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:13,148 root INFO 
id:ro_en cur r: 0.6314 best r: 0.6314
00:51:38,975 root INFO 
id:et_en cur r: 0.4255 best r: 0.4255
00:52:04,814 root INFO 
id:si_en cur r: 0.4430 best r: 0.4430
00:52:30,644 root INFO 
id:ne_en cur r: 0.6270 best r: 0.6270
00:52:56,254 root INFO 
id:ru_en cur r: 0.4919 best r: 0.4919
00:52:56,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:00,634 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
00:54:00,644 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
00:54:00,648 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
00:54:00,653 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
00:54:00,657 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
00:55:05,74 root INFO Epoch 0 Global steps: 1500 Train loss: 0.8415
ro_en Dev loss: 0.6157 r:0.6167
et_en Dev loss: 0.5820 r:0.4794
si_en Dev loss: 0.6847 r:0.4463
ne_en Dev loss: 0.5450 r:0.6256
ru_en Dev loss: 0.6287 r:0.5226
Current avg r:0.5381 Best avg r: 0.5381
00:58:15,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:41,284 root INFO 
id:ro_en cur r: 0.6537 best r: 0.6537
00:59:07,108 root INFO 
id:et_en cur r: 0.5569 best r: 0.5569
00:59:58,521 root INFO 
id:ru_en cur r: 0.5741 best r: 0.5741
00:59:58,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:02,922 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
01:01:02,929 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
01:01:02,934 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
01:01:02,940 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
01:01:02,945 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
01:02:07,360 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7952
ro_en Dev loss: 0.6471 r:0.6574
et_en Dev loss: 0.4885 r:0.5825
si_en Dev loss: 0.7714 r:0.4778
ne_en Dev loss: 0.4958 r:0.6476
ru_en Dev loss: 0.5842 r:0.6082
Current avg r:0.5947 Best avg r: 0.5947
01:05:17,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:43,643 root INFO 
id:ro_en cur r: 0.6794 best r: 0.6794
01:06:09,473 root INFO 
id:et_en cur r: 0.6105 best r: 0.6105
01:06:35,309 root INFO 
id:si_en cur r: 0.4931 best r: 0.4931
01:07:13,816 root INFO 
id:ru_en cur r: 0.6007 best r: 0.6007
01:07:13,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:18,230 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
01:08:18,236 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
01:08:18,241 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
01:08:18,245 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
01:08:18,250 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
01:09:22,661 root INFO Epoch 0 Global steps: 2500 Train loss: 0.7008
ro_en Dev loss: 0.5271 r:0.6955
et_en Dev loss: 0.4253 r:0.6534
si_en Dev loss: 0.6533 r:0.5226
ne_en Dev loss: 0.4793 r:0.6458
ru_en Dev loss: 0.5695 r:0.6573
Current avg r:0.6349 Best avg r: 0.6349
01:12:33,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:58,957 root INFO 
id:ro_en cur r: 0.7230 best r: 0.7230
01:13:24,784 root INFO 
id:et_en cur r: 0.6701 best r: 0.6701
01:13:50,603 root INFO 
id:si_en cur r: 0.5437 best r: 0.5437
01:14:16,426 root INFO 
id:ne_en cur r: 0.6872 best r: 0.6872
01:14:42,15 root INFO 
id:ru_en cur r: 0.6728 best r: 0.6728
01:14:42,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:46,406 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
01:15:46,414 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
01:15:46,419 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
01:15:46,424 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
01:15:46,429 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
01:16:50,899 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6590
ro_en Dev loss: 0.4587 r:0.7284
et_en Dev loss: 0.3809 r:0.6851
si_en Dev loss: 0.6198 r:0.5602
ne_en Dev loss: 0.4180 r:0.7029
ru_en Dev loss: 0.4852 r:0.6882
Current avg r:0.6730 Best avg r: 0.6730
01:20:01,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:05,70 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:30,812 root INFO 
id:ro_en cur r: 0.5781 best r: 0.5781
09:58:22,254 root INFO 
id:ne_en cur r: 0.5195 best r: 0.5195
09:58:47,894 root INFO 
id:ru_en cur r: 0.4458 best r: 0.4458
09:58:47,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:52,96 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
09:59:52,124 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
09:59:52,138 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
09:59:52,144 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
09:59:52,150 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
10:00:56,405 root INFO Epoch 0 Global steps: 500 Train loss: 0.9238
ro_en Dev loss: 0.7156 r:0.5044
et_en Dev loss: 0.6796 r:0.4118
si_en Dev loss: 0.7163 r:0.3939
ne_en Dev loss: 0.6904 r:0.5152
ru_en Dev loss: 0.6617 r:0.5478
Current avg r:0.4746 Best avg r: 0.4746
10:04:06,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:32,141 root INFO 
id:ro_en cur r: 0.5802 best r: 0.5802
10:04:57,875 root INFO 
id:et_en cur r: 0.3807 best r: 0.3807
10:05:23,588 root INFO 
id:si_en cur r: 0.3266 best r: 0.3266
10:05:49,324 root INFO 
id:ne_en cur r: 0.5228 best r: 0.5228
10:06:14,925 root INFO 
id:ru_en cur r: 0.5982 best r: 0.5982
10:06:14,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:19,90 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
10:07:19,102 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
10:07:19,107 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
10:07:19,125 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
10:07:19,132 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
10:08:23,343 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8551
ro_en Dev loss: 0.6461 r:0.6118
et_en Dev loss: 0.5985 r:0.4386
si_en Dev loss: 0.7750 r:0.3843
ne_en Dev loss: 0.6119 r:0.5306
ru_en Dev loss: 0.6121 r:0.5877
Current avg r:0.5106 Best avg r: 0.5106
10:11:33,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:58,960 root INFO 
id:ro_en cur r: 0.6237 best r: 0.6237
10:12:24,687 root INFO 
id:et_en cur r: 0.4993 best r: 0.4993
10:12:50,414 root INFO 
id:si_en cur r: 0.3967 best r: 0.3967
10:13:16,160 root INFO 
id:ne_en cur r: 0.5834 best r: 0.5834
10:13:41,780 root INFO 
id:ru_en cur r: 0.6229 best r: 0.6229
10:13:41,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:45,987 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
10:14:46,23 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
10:14:46,27 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
10:14:46,35 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
10:14:46,40 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
10:15:50,238 root INFO Epoch 0 Global steps: 1500 Train loss: 0.7963
ro_en Dev loss: 0.5909 r:0.6555
et_en Dev loss: 0.5159 r:0.5608
si_en Dev loss: 0.7494 r:0.4447
ne_en Dev loss: 0.5551 r:0.5819
ru_en Dev loss: 0.5416 r:0.6489
Current avg r:0.5784 Best avg r: 0.5784
10:18:59,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:25,589 root INFO 
id:ro_en cur r: 0.6669 best r: 0.6669
10:19:51,319 root INFO 
id:et_en cur r: 0.5258 best r: 0.5258
10:20:17,42 root INFO 
id:si_en cur r: 0.4123 best r: 0.4123
10:20:55,488 root INFO 
id:ru_en cur r: 0.6232 best r: 0.6232
10:20:55,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:21:59,657 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
10:21:59,666 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
10:21:59,671 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
10:21:59,679 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
10:21:59,708 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
10:23:03,972 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7105
ro_en Dev loss: 0.6159 r:0.6937
et_en Dev loss: 0.5189 r:0.5782
si_en Dev loss: 0.8435 r:0.4536
ne_en Dev loss: 0.6658 r:0.5471
ru_en Dev loss: 0.5684 r:0.6649
Current avg r:0.5875 Best avg r: 0.5875
10:26:13,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:26:39,387 root INFO 
id:ro_en cur r: 0.6885 best r: 0.6885
10:27:05,120 root INFO 
id:et_en cur r: 0.5833 best r: 0.5833
10:27:30,853 root INFO 
id:si_en cur r: 0.4606 best r: 0.4606
10:27:56,611 root INFO 
id:ne_en cur r: 0.6310 best r: 0.6310
10:28:22,234 root INFO 
id:ru_en cur r: 0.6885 best r: 0.6885
10:28:22,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:26,432 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
10:29:26,439 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
10:29:26,443 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
10:29:26,492 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
10:29:26,498 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
10:30:30,699 root INFO Epoch 0 Global steps: 2500 Train loss: 0.6389
ro_en Dev loss: 0.5017 r:0.7147
et_en Dev loss: 0.4427 r:0.6305
si_en Dev loss: 0.6844 r:0.5104
ne_en Dev loss: 0.4994 r:0.6389
ru_en Dev loss: 0.4878 r:0.7112
Current avg r:0.6411 Best avg r: 0.6411
10:33:40,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:34:06,218 root INFO 
id:ro_en cur r: 0.7230 best r: 0.7230
10:34:31,953 root INFO 
id:et_en cur r: 0.6110 best r: 0.6110
10:34:57,679 root INFO 
id:si_en cur r: 0.4828 best r: 0.4828
10:35:23,401 root INFO 
id:ne_en cur r: 0.6478 best r: 0.6478
10:35:49,19 root INFO 
id:ru_en cur r: 0.7050 best r: 0.7050
10:35:49,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:36:53,220 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
10:36:53,234 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
10:36:53,239 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
10:36:53,253 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
10:36:53,258 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
10:37:57,495 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6328
ro_en Dev loss: 0.4814 r:0.7447
et_en Dev loss: 0.4221 r:0.6474
si_en Dev loss: 0.7162 r:0.5169
ne_en Dev loss: 0.4807 r:0.6505
ru_en Dev loss: 0.4745 r:0.7185
Current avg r:0.6556 Best avg r: 0.6556
10:41:07,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:41:32,906 root INFO 
id:ro_en cur r: 0.7539 best r: 0.7539
10:41:58,622 root INFO 
id:et_en cur r: 0.6730 best r: 0.6730
10:42:24,379 root INFO 
id:si_en cur r: 0.4980 best r: 0.4980
10:42:50,116 root INFO 
id:ne_en cur r: 0.6982 best r: 0.6982
10:43:15,735 root INFO 
id:ru_en cur r: 0.7206 best r: 0.7206
10:43:15,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:44:19,897 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
10:44:19,904 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
10:44:19,909 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
10:44:19,914 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
10:44:19,921 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
10:45:24,203 root INFO Epoch 0 Global steps: 3500 Train loss: 0.5972
ro_en Dev loss: 0.4160 r:0.7706
et_en Dev loss: 0.3746 r:0.6903
si_en Dev loss: 0.6513 r:0.5577
ne_en Dev loss: 0.4283 r:0.6978
ru_en Dev loss: 0.4407 r:0.7397
Current avg r:0.6912 Best avg r: 0.6912
10:48:34,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:48:59,739 root INFO 
id:ro_en cur r: 0.7638 best r: 0.7638
10:49:25,462 root INFO 
id:et_en cur r: 0.6799 best r: 0.6799
10:49:51,197 root INFO 
id:si_en cur r: 0.5253 best r: 0.5253
10:50:29,692 root INFO 
id:ru_en cur r: 0.7255 best r: 0.7255
10:50:29,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:51:33,872 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
10:51:33,879 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
10:51:33,886 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
10:51:33,892 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
10:51:33,912 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
10:52:38,129 root INFO Epoch 0 Global steps: 4000 Train loss: 0.5662
ro_en Dev loss: 0.3831 r:0.7742
et_en Dev loss: 0.3638 r:0.6961
si_en Dev loss: 0.6366 r:0.5701
ne_en Dev loss: 0.4416 r:0.7088
ru_en Dev loss: 0.4460 r:0.7365
Current avg r:0.6971 Best avg r: 0.6971
10:55:47,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:56:13,547 root INFO 
id:ro_en cur r: 0.7803 best r: 0.7803
10:56:52,128 root INFO 
id:si_en cur r: 0.5554 best r: 0.5554
10:57:17,864 root INFO 
id:ne_en cur r: 0.7047 best r: 0.7047
10:57:43,486 root INFO 
id:ru_en cur r: 0.7258 best r: 0.7258
10:57:43,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:58:47,675 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
10:58:47,680 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
10:58:47,701 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
10:58:47,723 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
10:58:47,728 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
10:59:51,939 root INFO Epoch 0 Global steps: 4500 Train loss: 0.5488
ro_en Dev loss: 0.3658 r:0.7882
et_en Dev loss: 0.3671 r:0.6959
si_en Dev loss: 0.6042 r:0.5825
ne_en Dev loss: 0.3806 r:0.7236
ru_en Dev loss: 0.4707 r:0.7379
Current avg r:0.7056 Best avg r: 0.7056
11:03:01,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:03:27,413 root INFO 
id:ro_en cur r: 0.7887 best r: 0.7887
11:03:53,155 root INFO 
id:et_en cur r: 0.6849 best r: 0.6849
11:04:31,747 root INFO 
id:ne_en cur r: 0.7149 best r: 0.7149
11:04:57,363 root INFO 
id:ru_en cur r: 0.7274 best r: 0.7274
11:04:57,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:06:01,554 root INFO Epoch 0 Global steps: 5000 Train loss: 0.5314
ro_en Dev loss: 0.4760 r:0.7976
et_en Dev loss: 0.4160 r:0.6941
si_en Dev loss: 0.9399 r:0.5565
ne_en Dev loss: 0.4932 r:0.7122
ru_en Dev loss: 0.6257 r:0.7298
Current avg r:0.6980 Best avg r: 0.7056
11:09:11,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:09:36,931 root INFO 
id:ro_en cur r: 0.7944 best r: 0.7944
11:10:28,345 root INFO 
id:ne_en cur r: 0.7178 best r: 0.7178
11:10:41,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:11:45,336 root INFO Epoch 0 Global steps: 5500 Train loss: 0.5425
ro_en Dev loss: 0.4320 r:0.8015
et_en Dev loss: 0.4111 r:0.6934
si_en Dev loss: 0.7831 r:0.5765
ne_en Dev loss: 0.5375 r:0.7159
ru_en Dev loss: 0.6246 r:0.7215
Current avg r:0.7018 Best avg r: 0.7056
11:14:55,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:15:20,787 root INFO 
id:ro_en cur r: 0.8008 best r: 0.8008
11:15:46,499 root INFO 
id:et_en cur r: 0.6947 best r: 0.6947
11:16:12,252 root INFO 
id:si_en cur r: 0.5903 best r: 0.5903
11:16:37,957 root INFO 
id:ne_en cur r: 0.7399 best r: 0.7399
11:17:03,544 root INFO 
id:ru_en cur r: 0.7326 best r: 0.7326
11:17:03,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:18:07,724 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
11:18:07,731 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
11:18:07,735 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
11:18:07,740 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
11:18:07,748 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
11:19:11,986 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5294
ro_en Dev loss: 0.4069 r:0.8043
et_en Dev loss: 0.3840 r:0.7055
si_en Dev loss: 0.6491 r:0.6040
ne_en Dev loss: 0.4371 r:0.7383
ru_en Dev loss: 0.5604 r:0.7371
Current avg r:0.7178 Best avg r: 0.7178
11:22:21,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:22:47,460 root INFO 
id:ro_en cur r: 0.8020 best r: 0.8020
11:23:26,34 root INFO 
id:si_en cur r: 0.5915 best r: 0.5915
11:24:04,496 root INFO 
id:ru_en cur r: 0.7369 best r: 0.7369
11:24:04,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:25:08,670 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
11:25:08,676 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
11:25:08,687 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
11:25:08,692 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
11:25:08,710 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
11:26:12,937 root INFO Epoch 0 Global steps: 6500 Train loss: 0.5237
ro_en Dev loss: 0.4302 r:0.8070
et_en Dev loss: 0.4091 r:0.7039
si_en Dev loss: 0.6802 r:0.6033
ne_en Dev loss: 0.4471 r:0.7383
ru_en Dev loss: 0.5534 r:0.7407
Current avg r:0.7186 Best avg r: 0.7186
11:29:22,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:29:48,413 root INFO 
id:ro_en cur r: 0.8163 best r: 0.8163
11:30:27,38 root INFO 
id:si_en cur r: 0.5928 best r: 0.5928
11:30:52,736 root INFO 
id:ne_en cur r: 0.7426 best r: 0.7426
11:31:18,343 root INFO 
id:ru_en cur r: 0.7469 best r: 0.7469
11:31:18,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:32:22,530 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
11:32:22,537 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
11:32:22,542 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
11:32:22,559 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
11:32:22,563 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
11:33:26,780 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5210
ro_en Dev loss: 0.3236 r:0.8191
et_en Dev loss: 0.3590 r:0.7056
si_en Dev loss: 0.5822 r:0.6098
ne_en Dev loss: 0.3967 r:0.7519
ru_en Dev loss: 0.4525 r:0.7519
Current avg r:0.7277 Best avg r: 0.7277
11:36:36,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:37:40,688 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:38:44,889 root INFO Epoch 0 Global steps: 7500 Train loss: 0.4948
ro_en Dev loss: 0.3835 r:0.8056
et_en Dev loss: 0.3896 r:0.6928
si_en Dev loss: 0.6958 r:0.5898
ne_en Dev loss: 0.3908 r:0.7373
ru_en Dev loss: 0.4932 r:0.7343
Current avg r:0.7120 Best avg r: 0.7277
11:41:55,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:43:00,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:44:04,230 root INFO Epoch 1 Global steps: 8000 Train loss: 0.4521
ro_en Dev loss: 0.4267 r:0.8085
et_en Dev loss: 0.4102 r:0.6951
si_en Dev loss: 0.8125 r:0.5851
ne_en Dev loss: 0.4584 r:0.7342
ru_en Dev loss: 0.5288 r:0.7346
Current avg r:0.7115 Best avg r: 0.7277
11:47:14,28 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:48:18,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:49:22,409 root INFO Epoch 1 Global steps: 8500 Train loss: 0.4538
ro_en Dev loss: 0.3961 r:0.8072
et_en Dev loss: 0.4131 r:0.6939
si_en Dev loss: 0.7333 r:0.5915
ne_en Dev loss: 0.4118 r:0.7411
ru_en Dev loss: 0.5328 r:0.7284
Current avg r:0.7124 Best avg r: 0.7277
11:52:32,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:53:36,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:54:40,552 root INFO Epoch 1 Global steps: 9000 Train loss: 0.4815
ro_en Dev loss: 0.4551 r:0.8036
et_en Dev loss: 0.4280 r:0.6904
si_en Dev loss: 0.8027 r:0.5917
ne_en Dev loss: 0.5168 r:0.7377
ru_en Dev loss: 0.5751 r:0.7195
Current avg r:0.7086 Best avg r: 0.7277
11:57:50,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:58:16,25 root INFO 
id:ro_en cur r: 0.8164 best r: 0.8164
11:58:41,770 root INFO 
id:et_en cur r: 0.6979 best r: 0.6979
11:59:07,499 root INFO 
id:si_en cur r: 0.6018 best r: 0.6018
11:59:33,248 root INFO 
id:ne_en cur r: 0.7561 best r: 0.7561
11:59:46,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:00:50,237 root INFO Epoch 1 Global steps: 9500 Train loss: 0.4672
ro_en Dev loss: 0.3104 r:0.8127
et_en Dev loss: 0.3743 r:0.7034
si_en Dev loss: 0.5898 r:0.6109
ne_en Dev loss: 0.3615 r:0.7554
ru_en Dev loss: 0.4122 r:0.7432
Current avg r:0.7251 Best avg r: 0.7277
12:04:00,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:05:04,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:06:08,427 root INFO Epoch 1 Global steps: 10000 Train loss: 0.4858
ro_en Dev loss: 0.3401 r:0.8154
et_en Dev loss: 0.3722 r:0.7006
si_en Dev loss: 0.6957 r:0.6041
ne_en Dev loss: 0.4552 r:0.7510
ru_en Dev loss: 0.4725 r:0.7389
Current avg r:0.7220 Best avg r: 0.7277
12:09:18,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:10:22,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:11:26,510 root INFO Epoch 1 Global steps: 10500 Train loss: 0.4719
ro_en Dev loss: 0.3572 r:0.8148
et_en Dev loss: 0.3841 r:0.6941
si_en Dev loss: 0.7055 r:0.5968
ne_en Dev loss: 0.5316 r:0.7452
ru_en Dev loss: 0.5146 r:0.7173
Current avg r:0.7136 Best avg r: 0.7277
12:14:36,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:15:40,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:16:44,653 root INFO Epoch 1 Global steps: 11000 Train loss: 0.4446
ro_en Dev loss: 0.4061 r:0.8091
et_en Dev loss: 0.3842 r:0.6973
si_en Dev loss: 0.7657 r:0.5991
ne_en Dev loss: 0.4908 r:0.7386
ru_en Dev loss: 0.5175 r:0.7261
Current avg r:0.7140 Best avg r: 0.7277
12:19:54,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:20:58,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:22:02,967 root INFO Epoch 1 Global steps: 11500 Train loss: 0.4573
ro_en Dev loss: 0.4097 r:0.8039
et_en Dev loss: 0.3926 r:0.6988
si_en Dev loss: 0.7000 r:0.6008
ne_en Dev loss: 0.4659 r:0.7447
ru_en Dev loss: 0.5371 r:0.7142
Current avg r:0.7125 Best avg r: 0.7277
12:25:12,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:25:38,363 root INFO 
id:ro_en cur r: 0.8205 best r: 0.8205
12:26:04,89 root INFO 
id:et_en cur r: 0.6982 best r: 0.6982
12:26:29,829 root INFO 
id:si_en cur r: 0.6082 best r: 0.6082
12:26:55,555 root INFO 
id:ne_en cur r: 0.7631 best r: 0.7631
12:27:08,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:28:12,563 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4410
ro_en Dev loss: 0.3461 r:0.8167
et_en Dev loss: 0.3865 r:0.7003
si_en Dev loss: 0.6826 r:0.6092
ne_en Dev loss: 0.3858 r:0.7552
ru_en Dev loss: 0.5302 r:0.7232
Current avg r:0.7209 Best avg r: 0.7277
12:31:22,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:31:48,35 root INFO 
id:ro_en cur r: 0.8218 best r: 0.8218
12:32:13,760 root INFO 
id:et_en cur r: 0.6993 best r: 0.6993
12:32:39,492 root INFO 
id:si_en cur r: 0.6176 best r: 0.6176
12:33:05,205 root INFO 
id:ne_en cur r: 0.7649 best r: 0.7649
12:33:18,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:34:22,195 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
12:34:22,203 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
12:34:22,208 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
12:34:22,229 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
12:34:22,254 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
12:35:26,475 root INFO Epoch 1 Global steps: 12500 Train loss: 0.4490
ro_en Dev loss: 0.3235 r:0.8199
et_en Dev loss: 0.3774 r:0.7030
si_en Dev loss: 0.6317 r:0.6221
ne_en Dev loss: 0.3491 r:0.7627
ru_en Dev loss: 0.4458 r:0.7466
Current avg r:0.7309 Best avg r: 0.7309
12:38:36,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:39:14,815 root INFO 
id:et_en cur r: 0.7013 best r: 0.7013
12:39:53,383 root INFO 
id:ne_en cur r: 0.7684 best r: 0.7684
12:40:06,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:41:10,380 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
12:41:10,386 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
12:41:10,391 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
12:41:10,398 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
12:41:10,404 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
12:42:14,629 root INFO Epoch 1 Global steps: 13000 Train loss: 0.4509
ro_en Dev loss: 0.3322 r:0.8132
et_en Dev loss: 0.3822 r:0.7068
si_en Dev loss: 0.6100 r:0.6199
ne_en Dev loss: 0.3464 r:0.7656
ru_en Dev loss: 0.4258 r:0.7492
Current avg r:0.7310 Best avg r: 0.7310
12:45:24,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:46:02,910 root INFO 
id:et_en cur r: 0.7021 best r: 0.7021
12:46:28,609 root INFO 
id:si_en cur r: 0.6222 best r: 0.6222
12:46:54,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:47:58,453 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
12:47:58,460 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
12:47:58,481 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
12:47:58,485 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
12:47:58,494 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
12:49:02,716 root INFO Epoch 1 Global steps: 13500 Train loss: 0.4369
ro_en Dev loss: 0.3426 r:0.8134
et_en Dev loss: 0.3904 r:0.7059
si_en Dev loss: 0.5667 r:0.6294
ne_en Dev loss: 0.3628 r:0.7621
ru_en Dev loss: 0.4389 r:0.7488
Current avg r:0.7319 Best avg r: 0.7319
12:52:12,522 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:53:16,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:54:20,919 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4362
ro_en Dev loss: 0.3916 r:0.8125
et_en Dev loss: 0.4046 r:0.7043
si_en Dev loss: 0.7741 r:0.6160
ne_en Dev loss: 0.4566 r:0.7558
ru_en Dev loss: 0.5272 r:0.7374
Current avg r:0.7252 Best avg r: 0.7319
12:57:30,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:58:34,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:59:39,157 root INFO Epoch 1 Global steps: 14500 Train loss: 0.4218
ro_en Dev loss: 0.3494 r:0.8116
et_en Dev loss: 0.3842 r:0.7040
si_en Dev loss: 0.6880 r:0.6098
ne_en Dev loss: 0.3996 r:0.7557
ru_en Dev loss: 0.4696 r:0.7401
Current avg r:0.7242 Best avg r: 0.7319
13:02:49,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:03:27,691 root INFO 
id:et_en cur r: 0.7026 best r: 0.7026
13:04:06,293 root INFO 
id:ne_en cur r: 0.7707 best r: 0.7707
13:04:31,913 root INFO 
id:ru_en cur r: 0.7537 best r: 0.7537
13:04:31,913 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:05:36,57 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
13:05:36,64 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
13:05:36,72 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
13:05:36,77 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
13:05:36,85 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
13:06:40,324 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4530
ro_en Dev loss: 0.3345 r:0.8186
et_en Dev loss: 0.3840 r:0.7080
si_en Dev loss: 0.6334 r:0.6198
ne_en Dev loss: 0.3952 r:0.7678
ru_en Dev loss: 0.3998 r:0.7553
Current avg r:0.7339 Best avg r: 0.7339
13:09:51,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:10:29,969 root INFO 
id:et_en cur r: 0.7040 best r: 0.7040
13:11:08,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:12:12,658 root INFO Epoch 2 Global steps: 15500 Train loss: 0.4008
ro_en Dev loss: 0.4038 r:0.8159
et_en Dev loss: 0.3939 r:0.7070
si_en Dev loss: 0.7283 r:0.6183
ne_en Dev loss: 0.4500 r:0.7586
ru_en Dev loss: 0.5468 r:0.7300
Current avg r:0.7260 Best avg r: 0.7339
13:15:22,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:16:26,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:17:30,753 root INFO Epoch 2 Global steps: 16000 Train loss: 0.3800
ro_en Dev loss: 0.4044 r:0.8153
et_en Dev loss: 0.4268 r:0.7045
si_en Dev loss: 0.7311 r:0.6183
ne_en Dev loss: 0.4489 r:0.7603
ru_en Dev loss: 0.4732 r:0.7488
Current avg r:0.7294 Best avg r: 0.7339
13:20:40,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:21:44,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:22:48,992 root INFO Epoch 2 Global steps: 16500 Train loss: 0.4011
ro_en Dev loss: 0.3965 r:0.8173
et_en Dev loss: 0.4078 r:0.6982
si_en Dev loss: 0.8885 r:0.6022
ne_en Dev loss: 0.6406 r:0.7522
ru_en Dev loss: 0.5217 r:0.7306
Current avg r:0.7201 Best avg r: 0.7339
13:25:58,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:27:03,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:28:07,346 root INFO Epoch 2 Global steps: 17000 Train loss: 0.3892
ro_en Dev loss: 0.3927 r:0.8181
et_en Dev loss: 0.4012 r:0.7010
si_en Dev loss: 0.7712 r:0.6103
ne_en Dev loss: 0.4806 r:0.7623
ru_en Dev loss: 0.5054 r:0.7362
Current avg r:0.7256 Best avg r: 0.7339
13:31:17,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:32:21,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:33:25,564 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4032
ro_en Dev loss: 0.3349 r:0.8205
et_en Dev loss: 0.3712 r:0.7034
si_en Dev loss: 0.7282 r:0.6132
ne_en Dev loss: 0.4146 r:0.7587
ru_en Dev loss: 0.4634 r:0.7387
Current avg r:0.7269 Best avg r: 0.7339
13:36:35,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:37:01,461 root INFO 
id:ro_en cur r: 0.8222 best r: 0.8222
13:37:53,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:38:57,444 root INFO Epoch 2 Global steps: 18000 Train loss: 0.3852
ro_en Dev loss: 0.3670 r:0.8228
et_en Dev loss: 0.3656 r:0.7069
si_en Dev loss: 0.7188 r:0.6193
ne_en Dev loss: 0.4628 r:0.7608
ru_en Dev loss: 0.4695 r:0.7455
Current avg r:0.7310 Best avg r: 0.7339
13:42:07,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:43:11,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:44:16,141 root INFO Epoch 2 Global steps: 18500 Train loss: 0.3783
ro_en Dev loss: 0.4102 r:0.8118
et_en Dev loss: 0.4126 r:0.6972
si_en Dev loss: 0.7122 r:0.6151
ne_en Dev loss: 0.4779 r:0.7543
ru_en Dev loss: 0.5035 r:0.7358
Current avg r:0.7228 Best avg r: 0.7339
13:47:26,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:48:30,586 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:49:34,852 root INFO Epoch 2 Global steps: 19000 Train loss: 0.3878
ro_en Dev loss: 0.4396 r:0.8126
et_en Dev loss: 0.4209 r:0.6951
si_en Dev loss: 0.8359 r:0.6058
ne_en Dev loss: 0.5524 r:0.7592
ru_en Dev loss: 0.6193 r:0.7069
Current avg r:0.7159 Best avg r: 0.7339
13:52:45,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:53:49,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:54:53,672 root INFO Epoch 2 Global steps: 19500 Train loss: 0.3887
ro_en Dev loss: 0.3350 r:0.8201
et_en Dev loss: 0.3738 r:0.7039
si_en Dev loss: 0.6433 r:0.6141
ne_en Dev loss: 0.4070 r:0.7608
ru_en Dev loss: 0.4482 r:0.7330
Current avg r:0.7264 Best avg r: 0.7339
13:58:03,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:58:29,598 root INFO 
id:ro_en cur r: 0.8238 best r: 0.8238
13:59:21,141 root INFO 
id:ne_en cur r: 0.7718 best r: 0.7718
13:59:33,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:00:38,261 root INFO Epoch 2 Global steps: 20000 Train loss: 0.3880
ro_en Dev loss: 0.3072 r:0.8213
et_en Dev loss: 0.3789 r:0.7077
si_en Dev loss: 0.6150 r:0.6212
ne_en Dev loss: 0.3652 r:0.7652
ru_en Dev loss: 0.3872 r:0.7530
Current avg r:0.7337 Best avg r: 0.7339
14:03:48,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:04:52,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:05:57,208 root INFO Epoch 2 Global steps: 20500 Train loss: 0.3761
ro_en Dev loss: 0.3357 r:0.8191
et_en Dev loss: 0.3989 r:0.7037
si_en Dev loss: 0.6072 r:0.6208
ne_en Dev loss: 0.3913 r:0.7550
ru_en Dev loss: 0.4297 r:0.7485
Current avg r:0.7294 Best avg r: 0.7339
14:09:07,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:10:11,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:11:16,184 root INFO Epoch 2 Global steps: 21000 Train loss: 0.3994
ro_en Dev loss: 0.3575 r:0.8194
et_en Dev loss: 0.3888 r:0.6986
si_en Dev loss: 0.7982 r:0.6054
ne_en Dev loss: 0.4311 r:0.7587
ru_en Dev loss: 0.4706 r:0.7417
Current avg r:0.7248 Best avg r: 0.7339
14:14:26,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:15:30,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:16:35,34 root INFO Epoch 2 Global steps: 21500 Train loss: 0.3910
ro_en Dev loss: 0.4080 r:0.8169
et_en Dev loss: 0.4242 r:0.6989
si_en Dev loss: 0.6986 r:0.6153
ne_en Dev loss: 0.4746 r:0.7555
ru_en Dev loss: 0.5199 r:0.7348
Current avg r:0.7243 Best avg r: 0.7339
14:19:45,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:20:49,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:21:53,847 root INFO Epoch 2 Global steps: 22000 Train loss: 0.3701
ro_en Dev loss: 0.3305 r:0.8179
et_en Dev loss: 0.3795 r:0.6989
si_en Dev loss: 0.6811 r:0.6150
ne_en Dev loss: 0.3917 r:0.7619
ru_en Dev loss: 0.4589 r:0.7383
Current avg r:0.7264 Best avg r: 0.7339
14:25:04,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:26:08,366 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:27:12,632 root INFO Epoch 2 Global steps: 22500 Train loss: 0.3771
ro_en Dev loss: 0.3279 r:0.8174
et_en Dev loss: 0.3906 r:0.6947
si_en Dev loss: 0.6294 r:0.6138
ne_en Dev loss: 0.4181 r:0.7558
ru_en Dev loss: 0.4660 r:0.7257
Current avg r:0.7215 Best avg r: 0.7339
14:30:24,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:31:28,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:32:32,877 root INFO Epoch 3 Global steps: 23000 Train loss: 0.3526
ro_en Dev loss: 0.3902 r:0.8133
et_en Dev loss: 0.4135 r:0.6910
si_en Dev loss: 0.8040 r:0.5981
ne_en Dev loss: 0.5336 r:0.7521
ru_en Dev loss: 0.5439 r:0.7144
Current avg r:0.7138 Best avg r: 0.7339
14:35:43,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:36:08,948 root INFO 
id:ro_en cur r: 0.8249 best r: 0.8249
14:37:00,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:38:04,661 root INFO Epoch 3 Global steps: 23500 Train loss: 0.3473
ro_en Dev loss: 0.3384 r:0.8204
et_en Dev loss: 0.3988 r:0.7003
si_en Dev loss: 0.7054 r:0.6157
ne_en Dev loss: 0.4572 r:0.7616
ru_en Dev loss: 0.4312 r:0.7498
Current avg r:0.7296 Best avg r: 0.7339
14:41:14,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:19,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:43:23,359 root INFO Epoch 3 Global steps: 24000 Train loss: 0.3281
ro_en Dev loss: 0.3641 r:0.8137
et_en Dev loss: 0.4141 r:0.6884
si_en Dev loss: 0.7601 r:0.5989
ne_en Dev loss: 0.4870 r:0.7575
ru_en Dev loss: 0.4575 r:0.7351
Current avg r:0.7187 Best avg r: 0.7339
14:46:33,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:47:50,557 root INFO 
id:ru_en cur r: 0.7572 best r: 0.7572
14:47:50,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:54,827 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:48:54,836 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/et_en.lang_agnost_mlp.dev.best.scores
14:48:54,842 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/si_en.lang_agnost_mlp.dev.best.scores
14:48:54,847 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:48:54,852 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:49:59,151 root INFO Epoch 3 Global steps: 24500 Train loss: 0.3293
ro_en Dev loss: 0.3261 r:0.8201
et_en Dev loss: 0.4104 r:0.7016
si_en Dev loss: 0.6314 r:0.6212
ne_en Dev loss: 0.3567 r:0.7645
ru_en Dev loss: 0.4023 r:0.7658
Current avg r:0.7346 Best avg r: 0.7346
14:53:09,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:13,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:18,30 root INFO Epoch 3 Global steps: 25000 Train loss: 0.3370
ro_en Dev loss: 0.3770 r:0.8143
et_en Dev loss: 0.4317 r:0.6956
si_en Dev loss: 0.6532 r:0.6153
ne_en Dev loss: 0.4086 r:0.7510
ru_en Dev loss: 0.5079 r:0.7288
Current avg r:0.7210 Best avg r: 0.7346
14:58:28,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:32,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:37,13 root INFO Epoch 3 Global steps: 25500 Train loss: 0.3525
ro_en Dev loss: 0.3844 r:0.8117
et_en Dev loss: 0.4105 r:0.6851
si_en Dev loss: 0.7755 r:0.6011
ne_en Dev loss: 0.5887 r:0.7524
ru_en Dev loss: 0.5046 r:0.7278
Current avg r:0.7156 Best avg r: 0.7346
15:03:47,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:13,36 root INFO 
id:ro_en cur r: 0.8261 best r: 0.8261
15:05:04,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:08,749 root INFO Epoch 3 Global steps: 26000 Train loss: 0.3317
ro_en Dev loss: 0.3487 r:0.8240
et_en Dev loss: 0.3887 r:0.7001
si_en Dev loss: 0.7276 r:0.6180
ne_en Dev loss: 0.4664 r:0.7616
ru_en Dev loss: 0.4986 r:0.7324
Current avg r:0.7272 Best avg r: 0.7346
15:09:18,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:23,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:27,425 root INFO Epoch 3 Global steps: 26500 Train loss: 0.3355
ro_en Dev loss: 0.3525 r:0.8163
et_en Dev loss: 0.4072 r:0.6957
si_en Dev loss: 0.6530 r:0.6148
ne_en Dev loss: 0.4532 r:0.7628
ru_en Dev loss: 0.4332 r:0.7441
Current avg r:0.7267 Best avg r: 0.7346
15:14:37,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:41,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:46,191 root INFO Epoch 3 Global steps: 27000 Train loss: 0.3431
ro_en Dev loss: 0.3442 r:0.8214
et_en Dev loss: 0.3885 r:0.7032
si_en Dev loss: 0.7092 r:0.6137
ne_en Dev loss: 0.4661 r:0.7630
ru_en Dev loss: 0.4532 r:0.7497
Current avg r:0.7302 Best avg r: 0.7346
15:19:56,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:21:00,603 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:04,883 root INFO Epoch 3 Global steps: 27500 Train loss: 0.3209
ro_en Dev loss: 0.3568 r:0.8242
et_en Dev loss: 0.4040 r:0.6969
si_en Dev loss: 0.7257 r:0.6152
ne_en Dev loss: 0.4350 r:0.7621
ru_en Dev loss: 0.4450 r:0.7543
Current avg r:0.7305 Best avg r: 0.7346
15:25:14,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:32,124 root INFO 
id:ru_en cur r: 0.7619 best r: 0.7619
15:26:32,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:36,393 root INFO Epoch 3 Global steps: 28000 Train loss: 0.3189
ro_en Dev loss: 0.3559 r:0.8208
et_en Dev loss: 0.4140 r:0.6953
si_en Dev loss: 0.6809 r:0.6201
ne_en Dev loss: 0.4427 r:0.7616
ru_en Dev loss: 0.4299 r:0.7589
Current avg r:0.7314 Best avg r: 0.7346
15:30:46,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:50,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:55,155 root INFO Epoch 3 Global steps: 28500 Train loss: 0.3308
ro_en Dev loss: 0.3835 r:0.8156
et_en Dev loss: 0.4159 r:0.6909
si_en Dev loss: 0.8654 r:0.6059
ne_en Dev loss: 0.4517 r:0.7641
ru_en Dev loss: 0.4375 r:0.7556
Current avg r:0.7264 Best avg r: 0.7346
15:36:05,294 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:09,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:13,835 root INFO Epoch 3 Global steps: 29000 Train loss: 0.3286
ro_en Dev loss: 0.3495 r:0.8174
et_en Dev loss: 0.3946 r:0.6963
si_en Dev loss: 0.6829 r:0.6139
ne_en Dev loss: 0.4310 r:0.7666
ru_en Dev loss: 0.4295 r:0.7491
Current avg r:0.7287 Best avg r: 0.7346
15:41:24,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:28,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:32,513 root INFO Epoch 3 Global steps: 29500 Train loss: 0.3501
ro_en Dev loss: 0.3253 r:0.8190
et_en Dev loss: 0.3995 r:0.6937
si_en Dev loss: 0.6825 r:0.6170
ne_en Dev loss: 0.3804 r:0.7673
ru_en Dev loss: 0.4004 r:0.7530
Current avg r:0.7300 Best avg r: 0.7346
15:46:42,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:46,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:51,199 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3184
ro_en Dev loss: 0.3259 r:0.8174
et_en Dev loss: 0.3953 r:0.6924
si_en Dev loss: 0.6204 r:0.6246
ne_en Dev loss: 0.3758 r:0.7628
ru_en Dev loss: 0.4628 r:0.7283
Current avg r:0.7251 Best avg r: 0.7346
15:52:02,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:06,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:10,970 root INFO Epoch 4 Global steps: 30500 Train loss: 0.2898
ro_en Dev loss: 0.3756 r:0.8115
et_en Dev loss: 0.4240 r:0.6890
si_en Dev loss: 0.7822 r:0.6083
ne_en Dev loss: 0.4929 r:0.7572
ru_en Dev loss: 0.4759 r:0.7292
Current avg r:0.7191 Best avg r: 0.7346
15:57:21,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:25,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:29,789 root INFO Epoch 4 Global steps: 31000 Train loss: 0.2919
ro_en Dev loss: 0.4141 r:0.8038
et_en Dev loss: 0.4553 r:0.6747
si_en Dev loss: 0.8538 r:0.5905
ne_en Dev loss: 0.5794 r:0.7446
ru_en Dev loss: 0.5712 r:0.6944
Current avg r:0.7016 Best avg r: 0.7346
16:02:39,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:44,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:48,498 root INFO Epoch 4 Global steps: 31500 Train loss: 0.2954
ro_en Dev loss: 0.3684 r:0.8111
et_en Dev loss: 0.4126 r:0.6831
si_en Dev loss: 0.7932 r:0.5979
ne_en Dev loss: 0.5334 r:0.7556
ru_en Dev loss: 0.5093 r:0.7146
Current avg r:0.7124 Best avg r: 0.7346
16:07:58,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:02,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:07,242 root INFO Epoch 4 Global steps: 32000 Train loss: 0.3041
ro_en Dev loss: 0.3646 r:0.8136
et_en Dev loss: 0.4198 r:0.6938
si_en Dev loss: 0.6855 r:0.6127
ne_en Dev loss: 0.4135 r:0.7612
ru_en Dev loss: 0.4307 r:0.7509
Current avg r:0.7265 Best avg r: 0.7346
16:13:17,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:21,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:26,86 root INFO Epoch 4 Global steps: 32500 Train loss: 0.2789
ro_en Dev loss: 0.4195 r:0.8061
et_en Dev loss: 0.4594 r:0.6704
si_en Dev loss: 0.9300 r:0.5861
ne_en Dev loss: 0.5853 r:0.7564
ru_en Dev loss: 0.5309 r:0.7111
Current avg r:0.7060 Best avg r: 0.7346
16:18:36,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:40,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:44,836 root INFO Epoch 4 Global steps: 33000 Train loss: 0.2921
ro_en Dev loss: 0.3493 r:0.8135
et_en Dev loss: 0.4251 r:0.6969
si_en Dev loss: 0.6208 r:0.6155
ne_en Dev loss: 0.3913 r:0.7573
ru_en Dev loss: 0.4168 r:0.7499
Current avg r:0.7266 Best avg r: 0.7346
16:23:55,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:59,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:03,513 root INFO Epoch 4 Global steps: 33500 Train loss: 0.2832
ro_en Dev loss: 0.3738 r:0.8079
et_en Dev loss: 0.4217 r:0.6820
si_en Dev loss: 0.7637 r:0.6002
ne_en Dev loss: 0.5245 r:0.7482
ru_en Dev loss: 0.4976 r:0.7145
Current avg r:0.7105 Best avg r: 0.7346
16:29:13,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:18,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:22,342 root INFO Epoch 4 Global steps: 34000 Train loss: 0.2962
ro_en Dev loss: 0.4009 r:0.8112
et_en Dev loss: 0.4134 r:0.6900
si_en Dev loss: 0.7711 r:0.6075
ne_en Dev loss: 0.4433 r:0.7527
ru_en Dev loss: 0.4826 r:0.7401
Current avg r:0.7203 Best avg r: 0.7346
16:34:32,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:36,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:41,113 root INFO Epoch 4 Global steps: 34500 Train loss: 0.3010
ro_en Dev loss: 0.3718 r:0.8098
et_en Dev loss: 0.4173 r:0.6832
si_en Dev loss: 0.8195 r:0.5960
ne_en Dev loss: 0.5723 r:0.7476
ru_en Dev loss: 0.5276 r:0.7042
Current avg r:0.7081 Best avg r: 0.7346
16:39:51,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:55,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:59,755 root INFO Epoch 4 Global steps: 35000 Train loss: 0.2877
ro_en Dev loss: 0.3657 r:0.8118
et_en Dev loss: 0.4395 r:0.6942
si_en Dev loss: 0.6725 r:0.6093
ne_en Dev loss: 0.4436 r:0.7511
ru_en Dev loss: 0.4755 r:0.7313
Current avg r:0.7195 Best avg r: 0.7346
16:45:09,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:14,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:18,346 root INFO Epoch 4 Global steps: 35500 Train loss: 0.2783
ro_en Dev loss: 0.3832 r:0.8105
et_en Dev loss: 0.4515 r:0.6934
si_en Dev loss: 0.7796 r:0.5961
ne_en Dev loss: 0.4957 r:0.7429
ru_en Dev loss: 0.4571 r:0.7428
Current avg r:0.7171 Best avg r: 0.7346
16:50:28,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:32,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:36,970 root INFO Epoch 4 Global steps: 36000 Train loss: 0.2867
ro_en Dev loss: 0.3291 r:0.8161
et_en Dev loss: 0.4061 r:0.6958
si_en Dev loss: 0.6748 r:0.6134
ne_en Dev loss: 0.4409 r:0.7537
ru_en Dev loss: 0.4012 r:0.7497
Current avg r:0.7257 Best avg r: 0.7346
16:55:47,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:51,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:55,686 root INFO Epoch 4 Global steps: 36500 Train loss: 0.2804
ro_en Dev loss: 0.3626 r:0.8158
et_en Dev loss: 0.4270 r:0.6841
si_en Dev loss: 0.7861 r:0.6019
ne_en Dev loss: 0.4760 r:0.7575
ru_en Dev loss: 0.4293 r:0.7461
Current avg r:0.7211 Best avg r: 0.7346
17:01:05,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:31,656 root INFO 
id:ro_en cur r: 0.8278 best r: 0.8278
17:02:23,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:27,301 root INFO Epoch 4 Global steps: 37000 Train loss: 0.2822
ro_en Dev loss: 0.3292 r:0.8218
et_en Dev loss: 0.4196 r:0.6902
si_en Dev loss: 0.7121 r:0.6100
ne_en Dev loss: 0.4242 r:0.7581
ru_en Dev loss: 0.4078 r:0.7534
Current avg r:0.7267 Best avg r: 0.7346
17:06:37,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:41,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:45,911 root INFO Epoch 4 Global steps: 37500 Train loss: 0.2679
ro_en Dev loss: 0.3766 r:0.8132
et_en Dev loss: 0.4641 r:0.6761
si_en Dev loss: 0.7615 r:0.5949
ne_en Dev loss: 0.4992 r:0.7506
ru_en Dev loss: 0.4450 r:0.7408
Current avg r:0.7151 Best avg r: 0.7346
17:11:57,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:01,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:05,735 root INFO Epoch 5 Global steps: 38000 Train loss: 0.2534
ro_en Dev loss: 0.3892 r:0.8173
et_en Dev loss: 0.4370 r:0.6816
si_en Dev loss: 0.7772 r:0.6018
ne_en Dev loss: 0.5683 r:0.7472
ru_en Dev loss: 0.5670 r:0.7086
Current avg r:0.7113 Best avg r: 0.7346
17:17:15,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:20,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:24,347 root INFO Epoch 5 Global steps: 38500 Train loss: 0.2482
ro_en Dev loss: 0.3469 r:0.8137
et_en Dev loss: 0.4392 r:0.6816
si_en Dev loss: 0.6388 r:0.6109
ne_en Dev loss: 0.4751 r:0.7430
ru_en Dev loss: 0.4423 r:0.7343
Current avg r:0.7167 Best avg r: 0.7346
17:22:34,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:38,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:43,51 root INFO Epoch 5 Global steps: 39000 Train loss: 0.2480
ro_en Dev loss: 0.3650 r:0.8107
et_en Dev loss: 0.4604 r:0.6839
si_en Dev loss: 0.7194 r:0.6019
ne_en Dev loss: 0.4671 r:0.7456
ru_en Dev loss: 0.4493 r:0.7449
Current avg r:0.7174 Best avg r: 0.7346
17:27:53,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:57,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:01,775 root INFO Epoch 5 Global steps: 39500 Train loss: 0.2352
ro_en Dev loss: 0.3838 r:0.8091
et_en Dev loss: 0.4590 r:0.6654
si_en Dev loss: 0.8967 r:0.5754
ne_en Dev loss: 0.6119 r:0.7438
ru_en Dev loss: 0.4794 r:0.7277
Current avg r:0.7043 Best avg r: 0.7346
17:33:12,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:16,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:20,566 root INFO Epoch 5 Global steps: 40000 Train loss: 0.2384
ro_en Dev loss: 0.3874 r:0.8092
et_en Dev loss: 0.4609 r:0.6709
si_en Dev loss: 0.8438 r:0.5828
ne_en Dev loss: 0.4805 r:0.7553
ru_en Dev loss: 0.4519 r:0.7404
Current avg r:0.7117 Best avg r: 0.7346
17:38:30,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:35,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:39,438 root INFO Epoch 5 Global steps: 40500 Train loss: 0.2355
ro_en Dev loss: 0.4150 r:0.8052
et_en Dev loss: 0.4680 r:0.6695
si_en Dev loss: 0.8328 r:0.5889
ne_en Dev loss: 0.5417 r:0.7498
ru_en Dev loss: 0.5186 r:0.7216
Current avg r:0.7070 Best avg r: 0.7346
17:43:49,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:54,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:58,321 root INFO Epoch 5 Global steps: 41000 Train loss: 0.2472
ro_en Dev loss: 0.3832 r:0.8125
et_en Dev loss: 0.4379 r:0.6796
si_en Dev loss: 0.7667 r:0.5930
ne_en Dev loss: 0.5306 r:0.7482
ru_en Dev loss: 0.4824 r:0.7343
Current avg r:0.7135 Best avg r: 0.7346
17:49:08,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:12,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:17,190 root INFO Epoch 5 Global steps: 41500 Train loss: 0.2507
ro_en Dev loss: 0.3585 r:0.8142
et_en Dev loss: 0.4582 r:0.6792
si_en Dev loss: 0.7322 r:0.5954
ne_en Dev loss: 0.4516 r:0.7513
ru_en Dev loss: 0.4343 r:0.7421
Current avg r:0.7164 Best avg r: 0.7346
17:54:27,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:31,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:35,914 root INFO Epoch 5 Global steps: 42000 Train loss: 0.2462
ro_en Dev loss: 0.3785 r:0.8145
et_en Dev loss: 0.4618 r:0.6736
si_en Dev loss: 0.8592 r:0.5894
ne_en Dev loss: 0.4422 r:0.7498
ru_en Dev loss: 0.4683 r:0.7406
Current avg r:0.7136 Best avg r: 0.7346
17:59:46,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:50,405 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:54,677 root INFO Epoch 5 Global steps: 42500 Train loss: 0.2258
ro_en Dev loss: 0.4351 r:0.8075
et_en Dev loss: 0.4759 r:0.6601
si_en Dev loss: 0.9553 r:0.5746
ne_en Dev loss: 0.6329 r:0.7453
ru_en Dev loss: 0.5328 r:0.7176
Current avg r:0.7010 Best avg r: 0.7346
18:05:04,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:09,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:13,383 root INFO Epoch 5 Global steps: 43000 Train loss: 0.2393
ro_en Dev loss: 0.4171 r:0.8076
et_en Dev loss: 0.4705 r:0.6555
si_en Dev loss: 0.9430 r:0.5723
ne_en Dev loss: 0.5666 r:0.7379
ru_en Dev loss: 0.5975 r:0.6892
Current avg r:0.6925 Best avg r: 0.7346
18:10:23,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:27,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:32,155 root INFO Epoch 5 Global steps: 43500 Train loss: 0.2438
ro_en Dev loss: 0.3692 r:0.8112
et_en Dev loss: 0.4663 r:0.6817
si_en Dev loss: 0.7639 r:0.5962
ne_en Dev loss: 0.4200 r:0.7509
ru_en Dev loss: 0.4431 r:0.7365
Current avg r:0.7153 Best avg r: 0.7346
18:15:42,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:46,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:50,886 root INFO Epoch 5 Global steps: 44000 Train loss: 0.2309
ro_en Dev loss: 0.3942 r:0.8105
et_en Dev loss: 0.4814 r:0.6817
si_en Dev loss: 0.8171 r:0.5897
ne_en Dev loss: 0.4956 r:0.7483
ru_en Dev loss: 0.4792 r:0.7339
Current avg r:0.7128 Best avg r: 0.7346
18:21:01,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:05,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:09,685 root INFO Epoch 5 Global steps: 44500 Train loss: 0.2263
ro_en Dev loss: 0.3465 r:0.8123
et_en Dev loss: 0.4766 r:0.6810
si_en Dev loss: 0.6879 r:0.5953
ne_en Dev loss: 0.4104 r:0.7437
ru_en Dev loss: 0.4142 r:0.7469
Current avg r:0.7158 Best avg r: 0.7346
18:26:19,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:24,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:28,454 root INFO Epoch 5 Global steps: 45000 Train loss: 0.2286
ro_en Dev loss: 0.3622 r:0.8143
et_en Dev loss: 0.4394 r:0.6794
si_en Dev loss: 0.8159 r:0.5881
ne_en Dev loss: 0.4653 r:0.7564
ru_en Dev loss: 0.4362 r:0.7491
Current avg r:0.7175 Best avg r: 0.7346
18:31:39,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:44,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:48,291 root INFO Epoch 6 Global steps: 45500 Train loss: 0.2174
ro_en Dev loss: 0.3791 r:0.8094
et_en Dev loss: 0.4541 r:0.6698
si_en Dev loss: 0.7747 r:0.5819
ne_en Dev loss: 0.4902 r:0.7463
ru_en Dev loss: 0.4959 r:0.7220
Current avg r:0.7059 Best avg r: 0.7346
18:36:58,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:02,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:39:07,147 root INFO Epoch 6 Global steps: 46000 Train loss: 0.2032
ro_en Dev loss: 0.3457 r:0.8174
et_en Dev loss: 0.4496 r:0.6743
si_en Dev loss: 0.7820 r:0.5857
ne_en Dev loss: 0.4832 r:0.7451
ru_en Dev loss: 0.4600 r:0.7421
Current avg r:0.7129 Best avg r: 0.7346
18:42:17,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:21,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:25,899 root INFO Epoch 6 Global steps: 46500 Train loss: 0.2188
ro_en Dev loss: 0.3346 r:0.8140
et_en Dev loss: 0.4431 r:0.6717
si_en Dev loss: 0.7435 r:0.5784
ne_en Dev loss: 0.4634 r:0.7402
ru_en Dev loss: 0.4531 r:0.7289
Current avg r:0.7066 Best avg r: 0.7346
18:47:36,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:40,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:44,560 root INFO Epoch 6 Global steps: 47000 Train loss: 0.2028
ro_en Dev loss: 0.4147 r:0.8091
et_en Dev loss: 0.4706 r:0.6658
si_en Dev loss: 0.9115 r:0.5770
ne_en Dev loss: 0.5978 r:0.7436
ru_en Dev loss: 0.5444 r:0.7080
Current avg r:0.7007 Best avg r: 0.7346
18:52:54,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:58,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:03,235 root INFO Epoch 6 Global steps: 47500 Train loss: 0.2139
ro_en Dev loss: 0.4332 r:0.8119
et_en Dev loss: 0.4768 r:0.6623
si_en Dev loss: 0.9945 r:0.5743
ne_en Dev loss: 0.5773 r:0.7456
ru_en Dev loss: 0.5168 r:0.7265
Current avg r:0.7041 Best avg r: 0.7346
18:58:13,466 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:17,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:22,16 root INFO Epoch 6 Global steps: 48000 Train loss: 0.2103
ro_en Dev loss: 0.3696 r:0.8177
et_en Dev loss: 0.4463 r:0.6743
si_en Dev loss: 0.8111 r:0.5870
ne_en Dev loss: 0.4327 r:0.7499
ru_en Dev loss: 0.4618 r:0.7393
Current avg r:0.7136 Best avg r: 0.7346
19:03:32,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:36,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:40,531 root INFO Epoch 6 Global steps: 48500 Train loss: 0.2050
ro_en Dev loss: 0.3857 r:0.8137
et_en Dev loss: 0.4768 r:0.6764
si_en Dev loss: 0.7596 r:0.5882
ne_en Dev loss: 0.5010 r:0.7456
ru_en Dev loss: 0.4394 r:0.7432
Current avg r:0.7134 Best avg r: 0.7346
19:08:50,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:54,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:59,135 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2088
ro_en Dev loss: 0.3809 r:0.8138
et_en Dev loss: 0.4650 r:0.6780
si_en Dev loss: 0.7922 r:0.5896
ne_en Dev loss: 0.5805 r:0.7432
ru_en Dev loss: 0.4516 r:0.7390
Current avg r:0.7127 Best avg r: 0.7346
19:14:09,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:13,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:17,716 root INFO Epoch 6 Global steps: 49500 Train loss: 0.2070
ro_en Dev loss: 0.3697 r:0.8139
et_en Dev loss: 0.4682 r:0.6703
si_en Dev loss: 0.8999 r:0.5742
ne_en Dev loss: 0.5843 r:0.7423
ru_en Dev loss: 0.4584 r:0.7270
Current avg r:0.7056 Best avg r: 0.7346
19:19:27,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:32,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:36,314 root INFO Epoch 6 Global steps: 50000 Train loss: 0.2036
ro_en Dev loss: 0.3908 r:0.8130
et_en Dev loss: 0.4738 r:0.6741
si_en Dev loss: 0.8027 r:0.5868
ne_en Dev loss: 0.5648 r:0.7353
ru_en Dev loss: 0.4452 r:0.7436
Current avg r:0.7106 Best avg r: 0.7346
19:24:46,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:50,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:54,924 root INFO Epoch 6 Global steps: 50500 Train loss: 0.1976
ro_en Dev loss: 0.3675 r:0.8154
et_en Dev loss: 0.5021 r:0.6811
si_en Dev loss: 0.7069 r:0.5941
ne_en Dev loss: 0.4384 r:0.7413
ru_en Dev loss: 0.4173 r:0.7527
Current avg r:0.7169 Best avg r: 0.7346
19:30:05,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:31:09,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:13,349 root INFO Epoch 6 Global steps: 51000 Train loss: 0.2044
ro_en Dev loss: 0.4228 r:0.8123
et_en Dev loss: 0.4727 r:0.6698
si_en Dev loss: 0.9095 r:0.5813
ne_en Dev loss: 0.5695 r:0.7373
ru_en Dev loss: 0.4967 r:0.7392
Current avg r:0.7080 Best avg r: 0.7346
19:35:23,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:27,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:31,595 root INFO Epoch 6 Global steps: 51500 Train loss: 0.2017
ro_en Dev loss: 0.3732 r:0.8153
et_en Dev loss: 0.4601 r:0.6687
si_en Dev loss: 0.8056 r:0.5803
ne_en Dev loss: 0.4770 r:0.7444
ru_en Dev loss: 0.4475 r:0.7422
Current avg r:0.7102 Best avg r: 0.7346
19:40:41,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:45,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:49,775 root INFO Epoch 6 Global steps: 52000 Train loss: 0.1956
ro_en Dev loss: 0.3946 r:0.8186
et_en Dev loss: 0.4420 r:0.6788
si_en Dev loss: 0.9015 r:0.5778
ne_en Dev loss: 0.5844 r:0.7455
ru_en Dev loss: 0.4964 r:0.7440
Current avg r:0.7129 Best avg r: 0.7346
19:45:59,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:03,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:08,45 root INFO Epoch 6 Global steps: 52500 Train loss: 0.1984
ro_en Dev loss: 0.3869 r:0.8123
et_en Dev loss: 0.4867 r:0.6744
si_en Dev loss: 0.8349 r:0.5679
ne_en Dev loss: 0.5067 r:0.7383
ru_en Dev loss: 0.4942 r:0.7248
Current avg r:0.7036 Best avg r: 0.7346
19:51:19,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:23,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:27,380 root INFO Epoch 7 Global steps: 53000 Train loss: 0.2100
ro_en Dev loss: 0.3809 r:0.8052
et_en Dev loss: 0.4626 r:0.6678
si_en Dev loss: 0.8841 r:0.5676
ne_en Dev loss: 0.5698 r:0.7196
ru_en Dev loss: 0.4887 r:0.7275
Current avg r:0.6975 Best avg r: 0.7346
19:56:37,522 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:41,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:46,64 root INFO Epoch 7 Global steps: 53500 Train loss: 0.2165
ro_en Dev loss: 0.3663 r:0.8129
et_en Dev loss: 0.4694 r:0.6852
si_en Dev loss: 0.8109 r:0.5863
ne_en Dev loss: 0.4870 r:0.7353
ru_en Dev loss: 0.4656 r:0.7446
Current avg r:0.7129 Best avg r: 0.7346
20:01:56,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:00,512 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:04,613 root INFO Epoch 7 Global steps: 54000 Train loss: 0.2026
ro_en Dev loss: 0.3906 r:0.8074
et_en Dev loss: 0.5013 r:0.6673
si_en Dev loss: 0.8898 r:0.5720
ne_en Dev loss: 0.5524 r:0.7273
ru_en Dev loss: 0.5522 r:0.7067
Current avg r:0.6961 Best avg r: 0.7346
20:07:14,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:18,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:22,701 root INFO Epoch 7 Global steps: 54500 Train loss: 0.2026
ro_en Dev loss: 0.3988 r:0.8076
et_en Dev loss: 0.4797 r:0.6560
si_en Dev loss: 0.9045 r:0.5693
ne_en Dev loss: 0.6402 r:0.7314
ru_en Dev loss: 0.5545 r:0.7068
Current avg r:0.6942 Best avg r: 0.7346
20:12:32,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:36,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:40,853 root INFO Epoch 7 Global steps: 55000 Train loss: 0.1908
ro_en Dev loss: 0.3678 r:0.8143
et_en Dev loss: 0.5039 r:0.6693
si_en Dev loss: 0.8251 r:0.5731
ne_en Dev loss: 0.5119 r:0.7337
ru_en Dev loss: 0.4421 r:0.7419
Current avg r:0.7065 Best avg r: 0.7346
20:17:50,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:54,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:59,62 root INFO Epoch 7 Global steps: 55500 Train loss: 0.1963
ro_en Dev loss: 0.4101 r:0.8103
et_en Dev loss: 0.4762 r:0.6617
si_en Dev loss: 0.8809 r:0.5666
ne_en Dev loss: 0.5322 r:0.7357
ru_en Dev loss: 0.5086 r:0.7264
Current avg r:0.7001 Best avg r: 0.7346
20:23:08,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:13,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:17,227 root INFO Epoch 7 Global steps: 56000 Train loss: 0.1883
ro_en Dev loss: 0.4101 r:0.8113
et_en Dev loss: 0.4850 r:0.6580
si_en Dev loss: 0.9981 r:0.5596
ne_en Dev loss: 0.6840 r:0.7323
ru_en Dev loss: 0.5154 r:0.7258
Current avg r:0.6974 Best avg r: 0.7346
20:28:27,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:31,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:35,339 root INFO Epoch 7 Global steps: 56500 Train loss: 0.1943
ro_en Dev loss: 0.3482 r:0.8100
et_en Dev loss: 0.4518 r:0.6739
si_en Dev loss: 0.8712 r:0.5575
ne_en Dev loss: 0.4976 r:0.7436
ru_en Dev loss: 0.4458 r:0.7297
Current avg r:0.7029 Best avg r: 0.7346
20:33:45,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:49,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:53,504 root INFO Epoch 7 Global steps: 57000 Train loss: 0.1820
ro_en Dev loss: 0.3554 r:0.8123
et_en Dev loss: 0.4732 r:0.6588
si_en Dev loss: 0.8545 r:0.5672
ne_en Dev loss: 0.5381 r:0.7380
ru_en Dev loss: 0.4802 r:0.7232
Current avg r:0.6999 Best avg r: 0.7346
20:39:03,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:07,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:11,616 root INFO Epoch 7 Global steps: 57500 Train loss: 0.1941
ro_en Dev loss: 0.3806 r:0.8105
et_en Dev loss: 0.4915 r:0.6613
si_en Dev loss: 0.8554 r:0.5690
ne_en Dev loss: 0.5412 r:0.7392
ru_en Dev loss: 0.4397 r:0.7414
Current avg r:0.7043 Best avg r: 0.7346
20:44:21,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:25,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:29,708 root INFO Epoch 7 Global steps: 58000 Train loss: 0.1929
ro_en Dev loss: 0.3757 r:0.8109
et_en Dev loss: 0.4803 r:0.6603
si_en Dev loss: 0.8452 r:0.5672
ne_en Dev loss: 0.4995 r:0.7419
ru_en Dev loss: 0.4725 r:0.7317
Current avg r:0.7024 Best avg r: 0.7346
20:49:39,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:43,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:47,864 root INFO Epoch 7 Global steps: 58500 Train loss: 0.1892
ro_en Dev loss: 0.3512 r:0.8148
et_en Dev loss: 0.4510 r:0.6651
si_en Dev loss: 0.8520 r:0.5627
ne_en Dev loss: 0.5094 r:0.7433
ru_en Dev loss: 0.4302 r:0.7413
Current avg r:0.7055 Best avg r: 0.7346
20:54:57,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:01,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:57:06,85 root INFO Epoch 7 Global steps: 59000 Train loss: 0.1779
ro_en Dev loss: 0.4056 r:0.8137
et_en Dev loss: 0.4807 r:0.6678
si_en Dev loss: 0.8871 r:0.5655
ne_en Dev loss: 0.5692 r:0.7449
ru_en Dev loss: 0.4803 r:0.7386
Current avg r:0.7061 Best avg r: 0.7346
21:00:16,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:21,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:25,626 root INFO Epoch 7 Global steps: 59500 Train loss: 0.1766
ro_en Dev loss: 0.3839 r:0.8117
et_en Dev loss: 0.4933 r:0.6649
si_en Dev loss: 0.9072 r:0.5553
ne_en Dev loss: 0.5620 r:0.7415
ru_en Dev loss: 0.4464 r:0.7434
Current avg r:0.7034 Best avg r: 0.7346
21:05:36,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:40,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:45,162 root INFO Epoch 7 Global steps: 60000 Train loss: 0.1713
ro_en Dev loss: 0.3634 r:0.8128
et_en Dev loss: 0.4810 r:0.6691
si_en Dev loss: 0.8500 r:0.5649
ne_en Dev loss: 0.5190 r:0.7364
ru_en Dev loss: 0.4180 r:0.7498
Current avg r:0.7066 Best avg r: 0.7346
21:10:57,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:01,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:05,809 root INFO Epoch 8 Global steps: 60500 Train loss: 0.1559
ro_en Dev loss: 0.3761 r:0.8122
et_en Dev loss: 0.4770 r:0.6649
si_en Dev loss: 0.8962 r:0.5552
ne_en Dev loss: 0.5430 r:0.7293
ru_en Dev loss: 0.4641 r:0.7322
Current avg r:0.6988 Best avg r: 0.7346
21:16:16,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:20,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:25,193 root INFO Epoch 8 Global steps: 61000 Train loss: 0.1626
ro_en Dev loss: 0.3730 r:0.8104
et_en Dev loss: 0.4827 r:0.6636
si_en Dev loss: 0.8411 r:0.5584
ne_en Dev loss: 0.5228 r:0.7335
ru_en Dev loss: 0.4280 r:0.7445
Current avg r:0.7021 Best avg r: 0.7346
21:21:36,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:40,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:44,787 root INFO Epoch 8 Global steps: 61500 Train loss: 0.1614
ro_en Dev loss: 0.3683 r:0.8122
et_en Dev loss: 0.4687 r:0.6747
si_en Dev loss: 0.8082 r:0.5682
ne_en Dev loss: 0.5131 r:0.7428
ru_en Dev loss: 0.4202 r:0.7544
Current avg r:0.7105 Best avg r: 0.7346
21:26:55,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:00,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:04,381 root INFO Epoch 8 Global steps: 62000 Train loss: 0.1587
ro_en Dev loss: 0.3660 r:0.8126
et_en Dev loss: 0.4564 r:0.6568
si_en Dev loss: 0.8321 r:0.5640
ne_en Dev loss: 0.5380 r:0.7305
ru_en Dev loss: 0.4897 r:0.7225
Current avg r:0.6973 Best avg r: 0.7346
21:32:15,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:33:19,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:23,973 root INFO Epoch 8 Global steps: 62500 Train loss: 0.1637
ro_en Dev loss: 0.3673 r:0.8143
et_en Dev loss: 0.4570 r:0.6608
si_en Dev loss: 0.8664 r:0.5575
ne_en Dev loss: 0.5353 r:0.7216
ru_en Dev loss: 0.4964 r:0.7242
Current avg r:0.6957 Best avg r: 0.7346
21:37:34,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:39,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:43,379 root INFO Epoch 8 Global steps: 63000 Train loss: 0.1527
ro_en Dev loss: 0.3947 r:0.8083
et_en Dev loss: 0.4877 r:0.6561
si_en Dev loss: 0.8369 r:0.5677
ne_en Dev loss: 0.5014 r:0.7287
ru_en Dev loss: 0.5115 r:0.7177
Current avg r:0.6957 Best avg r: 0.7346
21:42:54,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:58,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:02,821 root INFO Epoch 8 Global steps: 63500 Train loss: 0.1589
ro_en Dev loss: 0.4116 r:0.8088
et_en Dev loss: 0.5400 r:0.6661
si_en Dev loss: 0.8428 r:0.5746
ne_en Dev loss: 0.5057 r:0.7214
ru_en Dev loss: 0.4776 r:0.7289
Current avg r:0.7000 Best avg r: 0.7346
21:48:13,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:17,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:50:21,908 root INFO Epoch 8 Global steps: 64000 Train loss: 0.1725
ro_en Dev loss: 0.4202 r:0.8091
et_en Dev loss: 0.4861 r:0.6526
si_en Dev loss: 1.0277 r:0.5570
ne_en Dev loss: 0.6120 r:0.7319
ru_en Dev loss: 0.5145 r:0.7218
Current avg r:0.6945 Best avg r: 0.7346
21:53:32,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:36,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:55:40,941 root INFO Epoch 8 Global steps: 64500 Train loss: 0.1472
ro_en Dev loss: 0.3794 r:0.8116
et_en Dev loss: 0.4859 r:0.6573
si_en Dev loss: 0.8824 r:0.5644
ne_en Dev loss: 0.5107 r:0.7316
ru_en Dev loss: 0.5168 r:0.7129
Current avg r:0.6956 Best avg r: 0.7346
21:58:51,519 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:55,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:00,55 root INFO Epoch 8 Global steps: 65000 Train loss: 0.1475
ro_en Dev loss: 0.3577 r:0.8132
et_en Dev loss: 0.4824 r:0.6715
si_en Dev loss: 0.8535 r:0.5674
ne_en Dev loss: 0.5233 r:0.7296
ru_en Dev loss: 0.4393 r:0.7418
Current avg r:0.7047 Best avg r: 0.7346
22:04:10,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:14,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:19,212 root INFO Epoch 8 Global steps: 65500 Train loss: 0.1511
ro_en Dev loss: 0.3875 r:0.8135
et_en Dev loss: 0.4941 r:0.6477
si_en Dev loss: 0.8597 r:0.5607
ne_en Dev loss: 0.5729 r:0.7262
ru_en Dev loss: 0.4939 r:0.7301
Current avg r:0.6956 Best avg r: 0.7346
22:09:29,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:34,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:38,331 root INFO Epoch 8 Global steps: 66000 Train loss: 0.1588
ro_en Dev loss: 0.3605 r:0.8149
et_en Dev loss: 0.4737 r:0.6512
si_en Dev loss: 0.8427 r:0.5595
ne_en Dev loss: 0.6056 r:0.7190
ru_en Dev loss: 0.5125 r:0.7190
Current avg r:0.6927 Best avg r: 0.7346
22:14:48,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:53,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:16:57,533 root INFO Epoch 8 Global steps: 66500 Train loss: 0.1523
ro_en Dev loss: 0.3813 r:0.8120
et_en Dev loss: 0.4904 r:0.6449
si_en Dev loss: 0.9149 r:0.5513
ne_en Dev loss: 0.5798 r:0.7207
ru_en Dev loss: 0.4593 r:0.7334
Current avg r:0.6925 Best avg r: 0.7346
22:20:08,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:12,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:16,767 root INFO Epoch 8 Global steps: 67000 Train loss: 0.1524
ro_en Dev loss: 0.3985 r:0.8122
et_en Dev loss: 0.5265 r:0.6542
si_en Dev loss: 0.9266 r:0.5546
ne_en Dev loss: 0.5584 r:0.7265
ru_en Dev loss: 0.4731 r:0.7337
Current avg r:0.6962 Best avg r: 0.7346
22:25:27,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:26:31,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:35,886 root INFO Epoch 8 Global steps: 67500 Train loss: 0.1457
ro_en Dev loss: 0.4099 r:0.8093
et_en Dev loss: 0.5171 r:0.6469
si_en Dev loss: 0.9362 r:0.5560
ne_en Dev loss: 0.6240 r:0.7201
ru_en Dev loss: 0.4874 r:0.7343
Current avg r:0.6933 Best avg r: 0.7346
22:30:47,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:51,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:56,173 root INFO Epoch 9 Global steps: 68000 Train loss: 0.1358
ro_en Dev loss: 0.3752 r:0.8128
et_en Dev loss: 0.4852 r:0.6553
si_en Dev loss: 0.9311 r:0.5538
ne_en Dev loss: 0.6228 r:0.7284
ru_en Dev loss: 0.4558 r:0.7376
Current avg r:0.6976 Best avg r: 0.7346
22:36:06,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:11,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:15,379 root INFO Epoch 9 Global steps: 68500 Train loss: 0.1396
ro_en Dev loss: 0.3924 r:0.8142
et_en Dev loss: 0.4779 r:0.6637
si_en Dev loss: 0.9214 r:0.5575
ne_en Dev loss: 0.6930 r:0.7247
ru_en Dev loss: 0.4621 r:0.7407
Current avg r:0.7002 Best avg r: 0.7346
22:41:25,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:30,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:43:34,567 root INFO Epoch 9 Global steps: 69000 Train loss: 0.1464
ro_en Dev loss: 0.3890 r:0.8104
et_en Dev loss: 0.5028 r:0.6597
si_en Dev loss: 0.8731 r:0.5595
ne_en Dev loss: 0.5840 r:0.7246
ru_en Dev loss: 0.4615 r:0.7328
Current avg r:0.6974 Best avg r: 0.7346
22:46:45,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:49,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:48:53,792 root INFO Epoch 9 Global steps: 69500 Train loss: 0.1376
ro_en Dev loss: 0.3932 r:0.8148
et_en Dev loss: 0.4681 r:0.6672
si_en Dev loss: 0.8745 r:0.5646
ne_en Dev loss: 0.5496 r:0.7328
ru_en Dev loss: 0.4651 r:0.7421
Current avg r:0.7043 Best avg r: 0.7346
22:52:04,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:08,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:12,993 root INFO Epoch 9 Global steps: 70000 Train loss: 0.1399
ro_en Dev loss: 0.3624 r:0.8127
et_en Dev loss: 0.5103 r:0.6693
si_en Dev loss: 0.7797 r:0.5660
ne_en Dev loss: 0.4798 r:0.7248
ru_en Dev loss: 0.4372 r:0.7367
Current avg r:0.7019 Best avg r: 0.7346
22:57:23,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:27,906 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:32,194 root INFO Epoch 9 Global steps: 70500 Train loss: 0.1457
ro_en Dev loss: 0.3632 r:0.8127
et_en Dev loss: 0.4931 r:0.6664
si_en Dev loss: 0.8186 r:0.5581
ne_en Dev loss: 0.4632 r:0.7325
ru_en Dev loss: 0.4168 r:0.7522
Current avg r:0.7044 Best avg r: 0.7346
23:02:42,810 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:47,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:51,425 root INFO Epoch 9 Global steps: 71000 Train loss: 0.1389
ro_en Dev loss: 0.3692 r:0.8137
et_en Dev loss: 0.4682 r:0.6669
si_en Dev loss: 0.8503 r:0.5639
ne_en Dev loss: 0.5629 r:0.7271
ru_en Dev loss: 0.4661 r:0.7388
Current avg r:0.7021 Best avg r: 0.7346
23:08:02,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:09:06,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:10,790 root INFO Epoch 9 Global steps: 71500 Train loss: 0.1284
ro_en Dev loss: 0.3957 r:0.8107
et_en Dev loss: 0.5124 r:0.6555
si_en Dev loss: 0.9490 r:0.5493
ne_en Dev loss: 0.6238 r:0.7266
ru_en Dev loss: 0.4559 r:0.7403
Current avg r:0.6965 Best avg r: 0.7346
23:13:21,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:25,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:30,13 root INFO Epoch 9 Global steps: 72000 Train loss: 0.1354
ro_en Dev loss: 0.3906 r:0.8079
et_en Dev loss: 0.4868 r:0.6510
si_en Dev loss: 0.9355 r:0.5518
ne_en Dev loss: 0.6472 r:0.7276
ru_en Dev loss: 0.4836 r:0.7279
Current avg r:0.6932 Best avg r: 0.7346
23:18:40,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:44,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:49,91 root INFO Epoch 9 Global steps: 72500 Train loss: 0.1405
ro_en Dev loss: 0.3801 r:0.8090
et_en Dev loss: 0.5076 r:0.6556
si_en Dev loss: 0.8557 r:0.5544
ne_en Dev loss: 0.6141 r:0.7169
ru_en Dev loss: 0.4650 r:0.7260
Current avg r:0.6924 Best avg r: 0.7346
23:23:59,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:03,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:08,212 root INFO Epoch 9 Global steps: 73000 Train loss: 0.1377
ro_en Dev loss: 0.4008 r:0.8114
et_en Dev loss: 0.4909 r:0.6642
si_en Dev loss: 0.9558 r:0.5582
ne_en Dev loss: 0.6392 r:0.7269
ru_en Dev loss: 0.5088 r:0.7279
Current avg r:0.6977 Best avg r: 0.7346
23:29:18,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:22,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:27,222 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1295
ro_en Dev loss: 0.3604 r:0.8117
et_en Dev loss: 0.4702 r:0.6633
si_en Dev loss: 0.8891 r:0.5632
ne_en Dev loss: 0.5607 r:0.7354
ru_en Dev loss: 0.4556 r:0.7327
Current avg r:0.7013 Best avg r: 0.7346
23:34:37,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:41,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:46,153 root INFO Epoch 9 Global steps: 74000 Train loss: 0.1413
ro_en Dev loss: 0.3316 r:0.8156
et_en Dev loss: 0.4647 r:0.6664
si_en Dev loss: 0.7868 r:0.5671
ne_en Dev loss: 0.4557 r:0.7399
ru_en Dev loss: 0.4136 r:0.7451
Current avg r:0.7068 Best avg r: 0.7346
23:39:57,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:02,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:06,584 root INFO Epoch 9 Global steps: 74500 Train loss: 0.1246
ro_en Dev loss: 0.3563 r:0.8135
et_en Dev loss: 0.4713 r:0.6531
si_en Dev loss: 0.8798 r:0.5533
ne_en Dev loss: 0.5767 r:0.7272
ru_en Dev loss: 0.4797 r:0.7292
Current avg r:0.6953 Best avg r: 0.7346
23:45:18,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:23,818 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:47:28,811 root INFO Epoch 9 Global steps: 75000 Train loss: 0.1310
ro_en Dev loss: 0.3469 r:0.8123
et_en Dev loss: 0.4703 r:0.6715
si_en Dev loss: 0.8001 r:0.5693
ne_en Dev loss: 0.4927 r:0.7321
ru_en Dev loss: 0.4157 r:0.7502
Current avg r:0.7071 Best avg r: 0.7346
23:50:43,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:48,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:53,508 root INFO Epoch 10 Global steps: 75500 Train loss: 0.1279
ro_en Dev loss: 0.4186 r:0.8094
et_en Dev loss: 0.4779 r:0.6576
si_en Dev loss: 0.9904 r:0.5554
ne_en Dev loss: 0.6361 r:0.7323
ru_en Dev loss: 0.4987 r:0.7319
Current avg r:0.6973 Best avg r: 0.7346
23:56:04,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:08,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:13,150 root INFO Epoch 10 Global steps: 76000 Train loss: 0.1207
ro_en Dev loss: 0.3652 r:0.8142
et_en Dev loss: 0.4497 r:0.6632
si_en Dev loss: 0.9082 r:0.5530
ne_en Dev loss: 0.6455 r:0.7280
ru_en Dev loss: 0.4567 r:0.7402
Current avg r:0.6997 Best avg r: 0.7346
00:01:23,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:27,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:32,80 root INFO Epoch 10 Global steps: 76500 Train loss: 0.1202
ro_en Dev loss: 0.3659 r:0.8096
et_en Dev loss: 0.4800 r:0.6679
si_en Dev loss: 0.8145 r:0.5618
ne_en Dev loss: 0.5023 r:0.7344
ru_en Dev loss: 0.4340 r:0.7424
Current avg r:0.7032 Best avg r: 0.7346
00:06:42,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:46,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:51,145 root INFO Epoch 10 Global steps: 77000 Train loss: 0.1170
ro_en Dev loss: 0.3816 r:0.8112
et_en Dev loss: 0.4915 r:0.6638
si_en Dev loss: 0.8524 r:0.5644
ne_en Dev loss: 0.5418 r:0.7338
ru_en Dev loss: 0.4371 r:0.7515
Current avg r:0.7049 Best avg r: 0.7346
00:12:01,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:05,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:10,254 root INFO Epoch 10 Global steps: 77500 Train loss: 0.1220
ro_en Dev loss: 0.3597 r:0.8141
et_en Dev loss: 0.5053 r:0.6784
si_en Dev loss: 0.7700 r:0.5765
ne_en Dev loss: 0.4716 r:0.7333
ru_en Dev loss: 0.4206 r:0.7537
Current avg r:0.7112 Best avg r: 0.7346
00:17:20,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:25,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:29,307 root INFO Epoch 10 Global steps: 78000 Train loss: 0.1184
ro_en Dev loss: 0.3941 r:0.8076
et_en Dev loss: 0.4872 r:0.6566
si_en Dev loss: 0.9333 r:0.5561
ne_en Dev loss: 0.5727 r:0.7245
ru_en Dev loss: 0.4914 r:0.7405
Current avg r:0.6971 Best avg r: 0.7346
00:22:39,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:44,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:24:48,301 root INFO Epoch 10 Global steps: 78500 Train loss: 0.1194
ro_en Dev loss: 0.4355 r:0.8064
et_en Dev loss: 0.5083 r:0.6530
si_en Dev loss: 0.9640 r:0.5543
ne_en Dev loss: 0.6808 r:0.7145
ru_en Dev loss: 0.5498 r:0.7169
Current avg r:0.6890 Best avg r: 0.7346
00:27:58,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:03,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:07,305 root INFO Epoch 10 Global steps: 79000 Train loss: 0.1191
ro_en Dev loss: 0.3675 r:0.8079
et_en Dev loss: 0.4808 r:0.6610
si_en Dev loss: 0.8662 r:0.5569
ne_en Dev loss: 0.5289 r:0.7212
ru_en Dev loss: 0.4307 r:0.7440
Current avg r:0.6982 Best avg r: 0.7346
00:33:17,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:22,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:26,316 root INFO Epoch 10 Global steps: 79500 Train loss: 0.1235
ro_en Dev loss: 0.4593 r:0.8029
et_en Dev loss: 0.5211 r:0.6471
si_en Dev loss: 1.0345 r:0.5529
ne_en Dev loss: 0.6941 r:0.7179
ru_en Dev loss: 0.5734 r:0.7182
Current avg r:0.6878 Best avg r: 0.7346
00:38:36,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:39:41,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:45,366 root INFO Epoch 10 Global steps: 80000 Train loss: 0.1166
ro_en Dev loss: 0.4083 r:0.8085
et_en Dev loss: 0.5169 r:0.6606
si_en Dev loss: 0.9075 r:0.5571
ne_en Dev loss: 0.5393 r:0.7211
ru_en Dev loss: 0.4723 r:0.7452
Current avg r:0.6985 Best avg r: 0.7346
00:43:55,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:00,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:04,388 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1256
ro_en Dev loss: 0.3807 r:0.8116
et_en Dev loss: 0.4830 r:0.6672
si_en Dev loss: 0.8793 r:0.5672
ne_en Dev loss: 0.6068 r:0.7175
ru_en Dev loss: 0.4620 r:0.7416
Current avg r:0.7010 Best avg r: 0.7346
00:49:14,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:19,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:51:23,380 root INFO Epoch 10 Global steps: 81000 Train loss: 0.1176
ro_en Dev loss: 0.3829 r:0.8130
et_en Dev loss: 0.4693 r:0.6645
si_en Dev loss: 0.9128 r:0.5580
ne_en Dev loss: 0.6111 r:0.7222
ru_en Dev loss: 0.4526 r:0.7390
Current avg r:0.6994 Best avg r: 0.7346
00:54:33,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:38,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:56:42,409 root INFO Epoch 10 Global steps: 81500 Train loss: 0.1215
ro_en Dev loss: 0.3587 r:0.8142
et_en Dev loss: 0.4722 r:0.6684
si_en Dev loss: 0.8524 r:0.5633
ne_en Dev loss: 0.5741 r:0.7140
ru_en Dev loss: 0.4533 r:0.7371
Current avg r:0.6994 Best avg r: 0.7346
00:59:52,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:57,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:01,512 root INFO Epoch 10 Global steps: 82000 Train loss: 0.1170
ro_en Dev loss: 0.3759 r:0.8097
et_en Dev loss: 0.4952 r:0.6596
si_en Dev loss: 0.8605 r:0.5543
ne_en Dev loss: 0.5708 r:0.7165
ru_en Dev loss: 0.4306 r:0.7388
Current avg r:0.6958 Best avg r: 0.7346
01:05:12,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:16,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:20,625 root INFO Epoch 10 Global steps: 82500 Train loss: 0.1182
ro_en Dev loss: 0.3686 r:0.8153
et_en Dev loss: 0.4624 r:0.6635
si_en Dev loss: 0.8620 r:0.5609
ne_en Dev loss: 0.5426 r:0.7242
ru_en Dev loss: 0.4434 r:0.7422
Current avg r:0.7012 Best avg r: 0.7346
01:10:32,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:36,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:40,712 root INFO Epoch 11 Global steps: 83000 Train loss: 0.1047
ro_en Dev loss: 0.4201 r:0.8147
et_en Dev loss: 0.4947 r:0.6570
si_en Dev loss: 0.9919 r:0.5552
ne_en Dev loss: 0.6601 r:0.7213
ru_en Dev loss: 0.5237 r:0.7244
Current avg r:0.6945 Best avg r: 0.7346
01:15:51,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:55,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:59,797 root INFO Epoch 11 Global steps: 83500 Train loss: 0.1063
ro_en Dev loss: 0.3723 r:0.8174
et_en Dev loss: 0.4717 r:0.6607
si_en Dev loss: 0.8940 r:0.5625
ne_en Dev loss: 0.5821 r:0.7204
ru_en Dev loss: 0.4572 r:0.7415
Current avg r:0.7005 Best avg r: 0.7346
01:21:10,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:22:14,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:18,822 root INFO Epoch 11 Global steps: 84000 Train loss: 0.1039
ro_en Dev loss: 0.3576 r:0.8144
et_en Dev loss: 0.4548 r:0.6713
si_en Dev loss: 0.7901 r:0.5647
ne_en Dev loss: 0.5016 r:0.7226
ru_en Dev loss: 0.4247 r:0.7526
Current avg r:0.7051 Best avg r: 0.7346
01:26:29,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:27:33,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:37,805 root INFO Epoch 11 Global steps: 84500 Train loss: 0.1016
ro_en Dev loss: 0.3721 r:0.8147
et_en Dev loss: 0.4865 r:0.6649
si_en Dev loss: 0.8449 r:0.5530
ne_en Dev loss: 0.5292 r:0.7176
ru_en Dev loss: 0.4264 r:0.7535
Current avg r:0.7007 Best avg r: 0.7346
01:31:48,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:32:52,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:33:56,856 root INFO Epoch 11 Global steps: 85000 Train loss: 0.1065
ro_en Dev loss: 0.3517 r:0.8154
et_en Dev loss: 0.4794 r:0.6645
si_en Dev loss: 0.8302 r:0.5573
ne_en Dev loss: 0.4958 r:0.7230
ru_en Dev loss: 0.4147 r:0.7500
Current avg r:0.7020 Best avg r: 0.7346
01:37:07,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:38:11,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:15,937 root INFO Epoch 11 Global steps: 85500 Train loss: 0.1033
ro_en Dev loss: 0.3644 r:0.8126
et_en Dev loss: 0.4924 r:0.6541
si_en Dev loss: 0.8956 r:0.5478
ne_en Dev loss: 0.5382 r:0.7137
ru_en Dev loss: 0.4461 r:0.7387
Current avg r:0.6934 Best avg r: 0.7346
01:42:26,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:30,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:44:35,190 root INFO Epoch 11 Global steps: 86000 Train loss: 0.1009
ro_en Dev loss: 0.4017 r:0.8133
et_en Dev loss: 0.5133 r:0.6509
si_en Dev loss: 0.9827 r:0.5534
ne_en Dev loss: 0.6079 r:0.7228
ru_en Dev loss: 0.4781 r:0.7430
Current avg r:0.6967 Best avg r: 0.7346
01:47:45,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:48:49,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:49:54,288 root INFO Epoch 11 Global steps: 86500 Train loss: 0.1087
ro_en Dev loss: 0.3922 r:0.8116
et_en Dev loss: 0.5143 r:0.6504
si_en Dev loss: 0.9249 r:0.5552
ne_en Dev loss: 0.6419 r:0.7152
ru_en Dev loss: 0.5055 r:0.7292
Current avg r:0.6923 Best avg r: 0.7346
01:53:04,797 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:54:09,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:55:13,342 root INFO Epoch 11 Global steps: 87000 Train loss: 0.1064
ro_en Dev loss: 0.3947 r:0.8125
et_en Dev loss: 0.5284 r:0.6565
si_en Dev loss: 0.8765 r:0.5562
ne_en Dev loss: 0.5884 r:0.7172
ru_en Dev loss: 0.4370 r:0.7516
Current avg r:0.6988 Best avg r: 0.7346
01:58:23,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:59:28,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:32,456 root INFO Epoch 11 Global steps: 87500 Train loss: 0.1007
ro_en Dev loss: 0.4014 r:0.8145
et_en Dev loss: 0.4867 r:0.6601
si_en Dev loss: 0.9384 r:0.5499
ne_en Dev loss: 0.5916 r:0.7197
ru_en Dev loss: 0.4816 r:0.7445
Current avg r:0.6977 Best avg r: 0.7346
02:03:43,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:04:47,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:05:51,593 root INFO Epoch 11 Global steps: 88000 Train loss: 0.1056
ro_en Dev loss: 0.4087 r:0.8130
et_en Dev loss: 0.5177 r:0.6488
si_en Dev loss: 1.0444 r:0.5418
ne_en Dev loss: 0.6851 r:0.7201
ru_en Dev loss: 0.4938 r:0.7328
Current avg r:0.6913 Best avg r: 0.7346
02:09:02,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:10:06,408 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:11:10,683 root INFO Epoch 11 Global steps: 88500 Train loss: 0.1084
ro_en Dev loss: 0.3525 r:0.8175
et_en Dev loss: 0.4652 r:0.6554
si_en Dev loss: 0.8481 r:0.5558
ne_en Dev loss: 0.5818 r:0.7265
ru_en Dev loss: 0.4851 r:0.7225
Current avg r:0.6956 Best avg r: 0.7346
02:14:21,183 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:15:38,302 root INFO 
id:ru_en cur r: 0.7651 best r: 0.7651
02:15:38,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:16:42,597 root INFO Epoch 11 Global steps: 89000 Train loss: 0.1048
ro_en Dev loss: 0.3393 r:0.8204
et_en Dev loss: 0.4728 r:0.6701
si_en Dev loss: 0.7854 r:0.5595
ne_en Dev loss: 0.4936 r:0.7181
ru_en Dev loss: 0.3943 r:0.7630
Current avg r:0.7062 Best avg r: 0.7346
02:19:53,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:57,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:01,742 root INFO Epoch 11 Global steps: 89500 Train loss: 0.1063
ro_en Dev loss: 0.3885 r:0.8143
et_en Dev loss: 0.4916 r:0.6453
si_en Dev loss: 0.9301 r:0.5497
ne_en Dev loss: 0.6457 r:0.7142
ru_en Dev loss: 0.5022 r:0.7330
Current avg r:0.6913 Best avg r: 0.7346
02:25:12,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:26:16,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:20,882 root INFO Epoch 11 Global steps: 90000 Train loss: 0.1050
ro_en Dev loss: 0.3717 r:0.8149
et_en Dev loss: 0.4834 r:0.6482
si_en Dev loss: 0.8870 r:0.5536
ne_en Dev loss: 0.5755 r:0.7188
ru_en Dev loss: 0.4692 r:0.7360
Current avg r:0.6943 Best avg r: 0.7346
02:30:32,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:36,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:32:41,62 root INFO Epoch 12 Global steps: 90500 Train loss: 0.0950
ro_en Dev loss: 0.3793 r:0.8109
et_en Dev loss: 0.4822 r:0.6588
si_en Dev loss: 0.8758 r:0.5587
ne_en Dev loss: 0.6049 r:0.7181
ru_en Dev loss: 0.4435 r:0.7456
Current avg r:0.6984 Best avg r: 0.7346
02:35:51,553 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:55,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:00,120 root INFO Epoch 12 Global steps: 91000 Train loss: 0.0954
ro_en Dev loss: 0.3967 r:0.8129
et_en Dev loss: 0.4931 r:0.6538
si_en Dev loss: 0.9438 r:0.5549
ne_en Dev loss: 0.6848 r:0.7112
ru_en Dev loss: 0.4738 r:0.7391
Current avg r:0.6944 Best avg r: 0.7346
02:41:10,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:42:14,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:43:19,137 root INFO Epoch 12 Global steps: 91500 Train loss: 0.0958
ro_en Dev loss: 0.3804 r:0.8110
et_en Dev loss: 0.4835 r:0.6555
si_en Dev loss: 0.8748 r:0.5580
ne_en Dev loss: 0.6009 r:0.7142
ru_en Dev loss: 0.4564 r:0.7429
Current avg r:0.6963 Best avg r: 0.7346
02:46:29,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:47:33,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:48:38,179 root INFO Epoch 12 Global steps: 92000 Train loss: 0.0929
ro_en Dev loss: 0.4116 r:0.8042
et_en Dev loss: 0.5009 r:0.6366
si_en Dev loss: 1.0237 r:0.5392
ne_en Dev loss: 0.7268 r:0.7083
ru_en Dev loss: 0.5306 r:0.7165
Current avg r:0.6809 Best avg r: 0.7346
02:51:48,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:52:52,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:57,232 root INFO Epoch 12 Global steps: 92500 Train loss: 0.0910
ro_en Dev loss: 0.3832 r:0.8130
et_en Dev loss: 0.4934 r:0.6648
si_en Dev loss: 0.9029 r:0.5564
ne_en Dev loss: 0.5910 r:0.7208
ru_en Dev loss: 0.4447 r:0.7445
Current avg r:0.6999 Best avg r: 0.7346
02:57:07,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:58:11,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:59:16,261 root INFO Epoch 12 Global steps: 93000 Train loss: 0.0960
ro_en Dev loss: 0.4059 r:0.8121
et_en Dev loss: 0.5048 r:0.6559
si_en Dev loss: 0.9584 r:0.5525
ne_en Dev loss: 0.6768 r:0.7158
ru_en Dev loss: 0.4751 r:0.7468
Current avg r:0.6966 Best avg r: 0.7346
03:02:26,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:30,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:35,234 root INFO Epoch 12 Global steps: 93500 Train loss: 0.0908
ro_en Dev loss: 0.3805 r:0.8131
et_en Dev loss: 0.4932 r:0.6533
si_en Dev loss: 0.9000 r:0.5507
ne_en Dev loss: 0.6164 r:0.7110
ru_en Dev loss: 0.4856 r:0.7313
Current avg r:0.6919 Best avg r: 0.7346
03:07:45,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:08:50,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:09:54,326 root INFO Epoch 12 Global steps: 94000 Train loss: 0.0921
ro_en Dev loss: 0.3759 r:0.8150
et_en Dev loss: 0.4729 r:0.6586
si_en Dev loss: 0.8618 r:0.5606
ne_en Dev loss: 0.5697 r:0.7127
ru_en Dev loss: 0.4528 r:0.7479
Current avg r:0.6990 Best avg r: 0.7346
03:13:04,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:09,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:15:13,457 root INFO Epoch 12 Global steps: 94500 Train loss: 0.0932
ro_en Dev loss: 0.3640 r:0.8142
et_en Dev loss: 0.4777 r:0.6573
si_en Dev loss: 0.8745 r:0.5553
ne_en Dev loss: 0.6183 r:0.7114
ru_en Dev loss: 0.4378 r:0.7468
Current avg r:0.6970 Best avg r: 0.7346
03:18:23,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:19:28,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:20:32,505 root INFO Epoch 12 Global steps: 95000 Train loss: 0.0971
ro_en Dev loss: 0.3710 r:0.8154
et_en Dev loss: 0.4747 r:0.6595
si_en Dev loss: 0.8495 r:0.5621
ne_en Dev loss: 0.6192 r:0.7153
ru_en Dev loss: 0.4555 r:0.7451
Current avg r:0.6995 Best avg r: 0.7346
03:23:42,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:24:47,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:51,510 root INFO Epoch 12 Global steps: 95500 Train loss: 0.0946
ro_en Dev loss: 0.3337 r:0.8195
et_en Dev loss: 0.4635 r:0.6654
si_en Dev loss: 0.7999 r:0.5629
ne_en Dev loss: 0.5369 r:0.7178
ru_en Dev loss: 0.4257 r:0.7454
Current avg r:0.7022 Best avg r: 0.7346
03:29:01,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:30:06,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:10,541 root INFO Epoch 12 Global steps: 96000 Train loss: 0.0957
ro_en Dev loss: 0.3747 r:0.8114
et_en Dev loss: 0.4899 r:0.6571
si_en Dev loss: 0.9280 r:0.5501
ne_en Dev loss: 0.5978 r:0.7242
ru_en Dev loss: 0.4398 r:0.7453
Current avg r:0.6976 Best avg r: 0.7346
03:34:21,6 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:25,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:29,615 root INFO Epoch 12 Global steps: 96500 Train loss: 0.0911
ro_en Dev loss: 0.3781 r:0.8162
et_en Dev loss: 0.4851 r:0.6654
si_en Dev loss: 0.8848 r:0.5564
ne_en Dev loss: 0.5733 r:0.7198
ru_en Dev loss: 0.4462 r:0.7533
Current avg r:0.7022 Best avg r: 0.7346
03:39:40,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:44,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:48,999 root INFO Epoch 12 Global steps: 97000 Train loss: 0.0911
ro_en Dev loss: 0.4152 r:0.8110
et_en Dev loss: 0.5134 r:0.6562
si_en Dev loss: 1.0448 r:0.5522
ne_en Dev loss: 0.6836 r:0.7210
ru_en Dev loss: 0.5127 r:0.7389
Current avg r:0.6959 Best avg r: 0.7346
03:44:59,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:46:03,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:47:07,953 root INFO Epoch 12 Global steps: 97500 Train loss: 0.0948
ro_en Dev loss: 0.4128 r:0.8108
et_en Dev loss: 0.4997 r:0.6632
si_en Dev loss: 0.9636 r:0.5585
ne_en Dev loss: 0.6452 r:0.7211
ru_en Dev loss: 0.5093 r:0.7466
Current avg r:0.7000 Best avg r: 0.7346
03:50:19,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:23,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:28,139 root INFO Epoch 13 Global steps: 98000 Train loss: 0.0868
ro_en Dev loss: 0.3695 r:0.8130
et_en Dev loss: 0.4991 r:0.6642
si_en Dev loss: 0.8430 r:0.5612
ne_en Dev loss: 0.5903 r:0.7166
ru_en Dev loss: 0.4429 r:0.7510
Current avg r:0.7012 Best avg r: 0.7346
03:55:38,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:56:42,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:57:47,93 root INFO Epoch 13 Global steps: 98500 Train loss: 0.0832
ro_en Dev loss: 0.3700 r:0.8114
et_en Dev loss: 0.4645 r:0.6596
si_en Dev loss: 0.9257 r:0.5506
ne_en Dev loss: 0.6618 r:0.7111
ru_en Dev loss: 0.4623 r:0.7445
Current avg r:0.6955 Best avg r: 0.7346
04:00:57,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:02:01,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:03:06,71 root INFO Epoch 13 Global steps: 99000 Train loss: 0.0816
ro_en Dev loss: 0.3495 r:0.8120
et_en Dev loss: 0.4669 r:0.6649
si_en Dev loss: 0.8208 r:0.5595
ne_en Dev loss: 0.5343 r:0.7142
ru_en Dev loss: 0.4017 r:0.7592
Current avg r:0.7020 Best avg r: 0.7346
04:06:16,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:07:20,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:24,995 root INFO Epoch 13 Global steps: 99500 Train loss: 0.0816
ro_en Dev loss: 0.3910 r:0.8128
et_en Dev loss: 0.4922 r:0.6618
si_en Dev loss: 0.9270 r:0.5535
ne_en Dev loss: 0.6683 r:0.7074
ru_en Dev loss: 0.4607 r:0.7503
Current avg r:0.6971 Best avg r: 0.7346
04:11:35,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:12:39,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:13:44,36 root INFO Epoch 13 Global steps: 100000 Train loss: 0.0885
ro_en Dev loss: 0.3699 r:0.8129
et_en Dev loss: 0.4803 r:0.6571
si_en Dev loss: 0.8305 r:0.5555
ne_en Dev loss: 0.5837 r:0.7137
ru_en Dev loss: 0.4413 r:0.7476
Current avg r:0.6974 Best avg r: 0.7346
04:16:54,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:17:58,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:02,990 root INFO Epoch 13 Global steps: 100500 Train loss: 0.0862
ro_en Dev loss: 0.3731 r:0.8134
et_en Dev loss: 0.4865 r:0.6618
si_en Dev loss: 0.9210 r:0.5474
ne_en Dev loss: 0.5922 r:0.7156
ru_en Dev loss: 0.4312 r:0.7539
Current avg r:0.6984 Best avg r: 0.7346
04:22:13,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:23:17,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:24:21,889 root INFO Epoch 13 Global steps: 101000 Train loss: 0.0839
ro_en Dev loss: 0.3564 r:0.8156
et_en Dev loss: 0.4708 r:0.6649
si_en Dev loss: 0.8669 r:0.5544
ne_en Dev loss: 0.6303 r:0.7228
ru_en Dev loss: 0.4207 r:0.7548
Current avg r:0.7025 Best avg r: 0.7346
04:27:32,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:28:36,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:29:40,911 root INFO Epoch 13 Global steps: 101500 Train loss: 0.0839
ro_en Dev loss: 0.3457 r:0.8167
et_en Dev loss: 0.4585 r:0.6631
si_en Dev loss: 0.8149 r:0.5556
ne_en Dev loss: 0.5287 r:0.7127
ru_en Dev loss: 0.4329 r:0.7469
Current avg r:0.6990 Best avg r: 0.7346
04:32:51,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:34:08,466 root INFO 
id:ru_en cur r: 0.7673 best r: 0.7673
04:34:08,466 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:35:12,753 root INFO Epoch 13 Global steps: 102000 Train loss: 0.0881
ro_en Dev loss: 0.3578 r:0.8166
et_en Dev loss: 0.4890 r:0.6790
si_en Dev loss: 0.7974 r:0.5673
ne_en Dev loss: 0.5095 r:0.7251
ru_en Dev loss: 0.3954 r:0.7646
Current avg r:0.7105 Best avg r: 0.7346
04:38:23,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:39:27,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:40:31,764 root INFO Epoch 13 Global steps: 102500 Train loss: 0.0848
ro_en Dev loss: 0.3695 r:0.8149
et_en Dev loss: 0.4946 r:0.6614
si_en Dev loss: 0.8492 r:0.5575
ne_en Dev loss: 0.6217 r:0.7087
ru_en Dev loss: 0.4494 r:0.7440
Current avg r:0.6973 Best avg r: 0.7346
04:43:42,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:46,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:50,895 root INFO Epoch 13 Global steps: 103000 Train loss: 0.0804
ro_en Dev loss: 0.3590 r:0.8150
et_en Dev loss: 0.4817 r:0.6574
si_en Dev loss: 0.8666 r:0.5565
ne_en Dev loss: 0.5734 r:0.7194
ru_en Dev loss: 0.4493 r:0.7450
Current avg r:0.6987 Best avg r: 0.7346
04:49:01,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:05,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:09,922 root INFO Epoch 13 Global steps: 103500 Train loss: 0.0815
ro_en Dev loss: 0.3772 r:0.8132
et_en Dev loss: 0.4880 r:0.6535
si_en Dev loss: 0.9031 r:0.5473
ne_en Dev loss: 0.6231 r:0.7118
ru_en Dev loss: 0.4903 r:0.7272
Current avg r:0.6906 Best avg r: 0.7346
04:54:20,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:55:24,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:56:28,877 root INFO Epoch 13 Global steps: 104000 Train loss: 0.0785
ro_en Dev loss: 0.3720 r:0.8171
et_en Dev loss: 0.4727 r:0.6622
si_en Dev loss: 0.9313 r:0.5552
ne_en Dev loss: 0.6487 r:0.7124
ru_en Dev loss: 0.4774 r:0.7441
Current avg r:0.6982 Best avg r: 0.7346
04:59:39,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:00:43,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:01:47,835 root INFO Epoch 13 Global steps: 104500 Train loss: 0.0862
ro_en Dev loss: 0.3339 r:0.8170
et_en Dev loss: 0.4678 r:0.6710
si_en Dev loss: 0.8195 r:0.5550
ne_en Dev loss: 0.5283 r:0.7174
ru_en Dev loss: 0.3983 r:0.7570
Current avg r:0.7035 Best avg r: 0.7346
05:04:58,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:02,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:07:06,763 root INFO Epoch 13 Global steps: 105000 Train loss: 0.0817
ro_en Dev loss: 0.3685 r:0.8160
et_en Dev loss: 0.4743 r:0.6624
si_en Dev loss: 0.8932 r:0.5583
ne_en Dev loss: 0.5962 r:0.7209
ru_en Dev loss: 0.4341 r:0.7521
Current avg r:0.7019 Best avg r: 0.7346
05:10:18,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:11:22,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:12:26,657 root INFO Epoch 14 Global steps: 105500 Train loss: 0.0789
ro_en Dev loss: 0.3792 r:0.8153
et_en Dev loss: 0.4827 r:0.6536
si_en Dev loss: 0.9533 r:0.5492
ne_en Dev loss: 0.6604 r:0.7167
ru_en Dev loss: 0.4932 r:0.7352
Current avg r:0.6940 Best avg r: 0.7346
05:15:37,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:16:41,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:17:45,538 root INFO Epoch 14 Global steps: 106000 Train loss: 0.0793
ro_en Dev loss: 0.3335 r:0.8193
et_en Dev loss: 0.4473 r:0.6708
si_en Dev loss: 0.8008 r:0.5566
ne_en Dev loss: 0.5259 r:0.7243
ru_en Dev loss: 0.3886 r:0.7649
Current avg r:0.7072 Best avg r: 0.7346
05:20:55,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:22:00,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:04,524 root INFO Epoch 14 Global steps: 106500 Train loss: 0.0789
ro_en Dev loss: 0.3846 r:0.8136
et_en Dev loss: 0.4840 r:0.6611
si_en Dev loss: 0.9277 r:0.5540
ne_en Dev loss: 0.6116 r:0.7212
ru_en Dev loss: 0.4540 r:0.7517
Current avg r:0.7003 Best avg r: 0.7346
05:26:14,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:27:19,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:28:23,523 root INFO Epoch 14 Global steps: 107000 Train loss: 0.0762
ro_en Dev loss: 0.3675 r:0.8140
et_en Dev loss: 0.4787 r:0.6586
si_en Dev loss: 0.9113 r:0.5463
ne_en Dev loss: 0.5881 r:0.7090
ru_en Dev loss: 0.4482 r:0.7482
Current avg r:0.6952 Best avg r: 0.7346
05:31:33,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:32:38,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:33:42,549 root INFO Epoch 14 Global steps: 107500 Train loss: 0.0746
ro_en Dev loss: 0.3527 r:0.8170
et_en Dev loss: 0.4520 r:0.6623
si_en Dev loss: 0.8326 r:0.5515
ne_en Dev loss: 0.5222 r:0.7148
ru_en Dev loss: 0.4275 r:0.7533
Current avg r:0.6998 Best avg r: 0.7346
05:36:53,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:57,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:39:01,610 root INFO Epoch 14 Global steps: 108000 Train loss: 0.0801
ro_en Dev loss: 0.3763 r:0.8120
et_en Dev loss: 0.4838 r:0.6585
si_en Dev loss: 0.8666 r:0.5508
ne_en Dev loss: 0.6175 r:0.7114
ru_en Dev loss: 0.4634 r:0.7449
Current avg r:0.6955 Best avg r: 0.7346
05:42:12,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:16,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:44:20,829 root INFO Epoch 14 Global steps: 108500 Train loss: 0.0718
ro_en Dev loss: 0.3876 r:0.8153
et_en Dev loss: 0.4869 r:0.6611
si_en Dev loss: 0.9822 r:0.5543
ne_en Dev loss: 0.6330 r:0.7173
ru_en Dev loss: 0.4985 r:0.7421
Current avg r:0.6980 Best avg r: 0.7346
05:47:32,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:48:38,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:49:42,976 root INFO Epoch 14 Global steps: 109000 Train loss: 0.0765
ro_en Dev loss: 0.3657 r:0.8147
et_en Dev loss: 0.4757 r:0.6570
si_en Dev loss: 0.8861 r:0.5509
ne_en Dev loss: 0.5969 r:0.7106
ru_en Dev loss: 0.4244 r:0.7548
Current avg r:0.6976 Best avg r: 0.7346
05:52:53,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:53:58,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:55:02,384 root INFO Epoch 14 Global steps: 109500 Train loss: 0.0743
ro_en Dev loss: 0.3537 r:0.8157
et_en Dev loss: 0.5001 r:0.6652
si_en Dev loss: 0.8329 r:0.5576
ne_en Dev loss: 0.5693 r:0.7156
ru_en Dev loss: 0.4417 r:0.7466
Current avg r:0.7001 Best avg r: 0.7346
05:58:13,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:17,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:00:22,274 root INFO Epoch 14 Global steps: 110000 Train loss: 0.0766
ro_en Dev loss: 0.3361 r:0.8229
et_en Dev loss: 0.5042 r:0.6748
si_en Dev loss: 0.8234 r:0.5604
ne_en Dev loss: 0.5101 r:0.7127
ru_en Dev loss: 0.4104 r:0.7577
Current avg r:0.7057 Best avg r: 0.7346
06:03:33,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:38,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:42,519 root INFO Epoch 14 Global steps: 110500 Train loss: 0.0780
ro_en Dev loss: 0.3991 r:0.8148
et_en Dev loss: 0.5049 r:0.6602
si_en Dev loss: 0.9359 r:0.5533
ne_en Dev loss: 0.6206 r:0.7082
ru_en Dev loss: 0.4621 r:0.7554
Current avg r:0.6984 Best avg r: 0.7346
06:08:52,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:57,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:01,572 root INFO Epoch 14 Global steps: 111000 Train loss: 0.0753
ro_en Dev loss: 0.3483 r:0.8154
et_en Dev loss: 0.4849 r:0.6587
si_en Dev loss: 0.8433 r:0.5572
ne_en Dev loss: 0.5572 r:0.7073
ru_en Dev loss: 0.4345 r:0.7472
Current avg r:0.6971 Best avg r: 0.7346
06:14:11,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:15:16,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:16:20,440 root INFO Epoch 14 Global steps: 111500 Train loss: 0.0763
ro_en Dev loss: 0.3748 r:0.8133
et_en Dev loss: 0.4881 r:0.6510
si_en Dev loss: 0.9218 r:0.5502
ne_en Dev loss: 0.6533 r:0.7067
ru_en Dev loss: 0.4592 r:0.7520
Current avg r:0.6946 Best avg r: 0.7346
06:19:30,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:20:34,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:21:38,937 root INFO Epoch 14 Global steps: 112000 Train loss: 0.0740
ro_en Dev loss: 0.3833 r:0.8162
et_en Dev loss: 0.4884 r:0.6637
si_en Dev loss: 0.9295 r:0.5594
ne_en Dev loss: 0.5604 r:0.7161
ru_en Dev loss: 0.4773 r:0.7543
Current avg r:0.7019 Best avg r: 0.7346
06:24:48,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:25:53,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:57,412 root INFO Epoch 14 Global steps: 112500 Train loss: 0.0756
ro_en Dev loss: 0.3690 r:0.8146
et_en Dev loss: 0.4810 r:0.6656
si_en Dev loss: 0.8754 r:0.5579
ne_en Dev loss: 0.5739 r:0.7139
ru_en Dev loss: 0.4158 r:0.7626
Current avg r:0.7029 Best avg r: 0.7346
06:30:08,664 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:31:25,705 root INFO 
id:ru_en cur r: 0.7703 best r: 0.7703
06:31:25,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:29,923 root INFO Epoch 15 Global steps: 113000 Train loss: 0.0698
ro_en Dev loss: 0.3469 r:0.8192
et_en Dev loss: 0.4620 r:0.6635
si_en Dev loss: 0.8537 r:0.5555
ne_en Dev loss: 0.5387 r:0.7109
ru_en Dev loss: 0.4024 r:0.7666
Current avg r:0.7032 Best avg r: 0.7346
06:35:39,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:44,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:48,317 root INFO Epoch 15 Global steps: 113500 Train loss: 0.0698
ro_en Dev loss: 0.3638 r:0.8167
et_en Dev loss: 0.4794 r:0.6665
si_en Dev loss: 0.9039 r:0.5555
ne_en Dev loss: 0.5830 r:0.7158
ru_en Dev loss: 0.4349 r:0.7578
Current avg r:0.7024 Best avg r: 0.7346
06:40:58,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:42:02,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:43:06,669 root INFO Epoch 15 Global steps: 114000 Train loss: 0.0683
ro_en Dev loss: 0.3677 r:0.8151
et_en Dev loss: 0.4852 r:0.6618
si_en Dev loss: 0.9031 r:0.5540
ne_en Dev loss: 0.6120 r:0.7087
ru_en Dev loss: 0.4358 r:0.7534
Current avg r:0.6986 Best avg r: 0.7346
06:46:16,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:20,727 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:48:24,907 root INFO Epoch 15 Global steps: 114500 Train loss: 0.0709
ro_en Dev loss: 0.3715 r:0.8137
et_en Dev loss: 0.4600 r:0.6731
si_en Dev loss: 0.8586 r:0.5651
ne_en Dev loss: 0.5988 r:0.7159
ru_en Dev loss: 0.4440 r:0.7549
Current avg r:0.7045 Best avg r: 0.7346
06:51:34,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:39,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:53:43,225 root INFO Epoch 15 Global steps: 115000 Train loss: 0.0693
ro_en Dev loss: 0.3651 r:0.8168
et_en Dev loss: 0.4664 r:0.6627
si_en Dev loss: 0.8883 r:0.5512
ne_en Dev loss: 0.5832 r:0.7079
ru_en Dev loss: 0.4620 r:0.7479
Current avg r:0.6973 Best avg r: 0.7346
06:56:53,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:57:57,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:59:01,662 root INFO Epoch 15 Global steps: 115500 Train loss: 0.0722
ro_en Dev loss: 0.3703 r:0.8145
et_en Dev loss: 0.4729 r:0.6539
si_en Dev loss: 0.9167 r:0.5526
ne_en Dev loss: 0.6050 r:0.7154
ru_en Dev loss: 0.4825 r:0.7398
Current avg r:0.6952 Best avg r: 0.7346
07:02:11,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:03:15,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:04:20,8 root INFO Epoch 15 Global steps: 116000 Train loss: 0.0704
ro_en Dev loss: 0.3514 r:0.8150
et_en Dev loss: 0.4695 r:0.6718
si_en Dev loss: 0.8246 r:0.5573
ne_en Dev loss: 0.5554 r:0.7167
ru_en Dev loss: 0.4394 r:0.7546
Current avg r:0.7031 Best avg r: 0.7346
07:07:30,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:34,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:09:38,470 root INFO Epoch 15 Global steps: 116500 Train loss: 0.0688
ro_en Dev loss: 0.4036 r:0.8127
et_en Dev loss: 0.4913 r:0.6624
si_en Dev loss: 0.9495 r:0.5521
ne_en Dev loss: 0.6190 r:0.7155
ru_en Dev loss: 0.4863 r:0.7511
Current avg r:0.6988 Best avg r: 0.7346
07:12:48,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:52,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:14:56,787 root INFO Epoch 15 Global steps: 117000 Train loss: 0.0699
ro_en Dev loss: 0.3454 r:0.8187
et_en Dev loss: 0.4692 r:0.6640
si_en Dev loss: 0.8287 r:0.5555
ne_en Dev loss: 0.5742 r:0.7078
ru_en Dev loss: 0.4056 r:0.7611
Current avg r:0.7014 Best avg r: 0.7346
07:18:06,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:19:11,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:15,253 root INFO Epoch 15 Global steps: 117500 Train loss: 0.0675
ro_en Dev loss: 0.3756 r:0.8166
et_en Dev loss: 0.4851 r:0.6586
si_en Dev loss: 0.8961 r:0.5489
ne_en Dev loss: 0.5639 r:0.7089
ru_en Dev loss: 0.4630 r:0.7519
Current avg r:0.6970 Best avg r: 0.7346
07:23:25,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:24:29,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:25:33,644 root INFO Epoch 15 Global steps: 118000 Train loss: 0.0697
ro_en Dev loss: 0.3810 r:0.8153
et_en Dev loss: 0.4762 r:0.6657
si_en Dev loss: 0.9181 r:0.5496
ne_en Dev loss: 0.5977 r:0.7134
ru_en Dev loss: 0.4612 r:0.7554
Current avg r:0.6999 Best avg r: 0.7346
07:28:43,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:29:47,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:52,74 root INFO Epoch 15 Global steps: 118500 Train loss: 0.0727
ro_en Dev loss: 0.3354 r:0.8172
et_en Dev loss: 0.4488 r:0.6611
si_en Dev loss: 0.8562 r:0.5424
ne_en Dev loss: 0.5618 r:0.7139
ru_en Dev loss: 0.4054 r:0.7586
Current avg r:0.6986 Best avg r: 0.7346
07:34:02,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:35:06,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:36:10,573 root INFO Epoch 15 Global steps: 119000 Train loss: 0.0710
ro_en Dev loss: 0.3547 r:0.8159
et_en Dev loss: 0.4672 r:0.6649
si_en Dev loss: 0.8297 r:0.5541
ne_en Dev loss: 0.5639 r:0.7125
ru_en Dev loss: 0.4720 r:0.7424
Current avg r:0.6979 Best avg r: 0.7346
07:39:20,558 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:24,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:41:28,981 root INFO Epoch 15 Global steps: 119500 Train loss: 0.0677
ro_en Dev loss: 0.3497 r:0.8150
et_en Dev loss: 0.4593 r:0.6653
si_en Dev loss: 0.8654 r:0.5490
ne_en Dev loss: 0.5897 r:0.7104
ru_en Dev loss: 0.4503 r:0.7496
Current avg r:0.6979 Best avg r: 0.7346
07:44:39,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:45:43,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:46:47,541 root INFO Epoch 15 Global steps: 120000 Train loss: 0.0695
ro_en Dev loss: 0.3214 r:0.8215
et_en Dev loss: 0.4358 r:0.6771
si_en Dev loss: 0.7797 r:0.5542
ne_en Dev loss: 0.5027 r:0.7076
ru_en Dev loss: 0.3788 r:0.7669
Current avg r:0.7055 Best avg r: 0.7346
07:49:58,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:51:02,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:07,46 root INFO Epoch 16 Global steps: 120500 Train loss: 0.0689
ro_en Dev loss: 0.3646 r:0.8178
et_en Dev loss: 0.4806 r:0.6599
si_en Dev loss: 0.8704 r:0.5535
ne_en Dev loss: 0.5645 r:0.7095
ru_en Dev loss: 0.4475 r:0.7532
Current avg r:0.6988 Best avg r: 0.7346
07:55:17,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:56:21,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:57:25,546 root INFO Epoch 16 Global steps: 121000 Train loss: 0.0664
ro_en Dev loss: 0.3944 r:0.8119
et_en Dev loss: 0.4889 r:0.6570
si_en Dev loss: 0.9231 r:0.5512
ne_en Dev loss: 0.6110 r:0.7061
ru_en Dev loss: 0.4462 r:0.7570
Current avg r:0.6966 Best avg r: 0.7346
08:00:35,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:01:39,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:44,74 root INFO Epoch 16 Global steps: 121500 Train loss: 0.0638
ro_en Dev loss: 0.3814 r:0.8130
et_en Dev loss: 0.4823 r:0.6610
si_en Dev loss: 0.8797 r:0.5596
ne_en Dev loss: 0.6217 r:0.7060
ru_en Dev loss: 0.4264 r:0.7620
Current avg r:0.7003 Best avg r: 0.7346
08:05:54,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:06:58,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:08:02,474 root INFO Epoch 16 Global steps: 122000 Train loss: 0.0683
ro_en Dev loss: 0.3781 r:0.8153
et_en Dev loss: 0.4868 r:0.6567
si_en Dev loss: 0.9037 r:0.5547
ne_en Dev loss: 0.5727 r:0.7044
ru_en Dev loss: 0.4482 r:0.7539
Current avg r:0.6970 Best avg r: 0.7346
08:11:12,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:12:16,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:13:20,962 root INFO Epoch 16 Global steps: 122500 Train loss: 0.0674
ro_en Dev loss: 0.3439 r:0.8172
et_en Dev loss: 0.4587 r:0.6586
si_en Dev loss: 0.8578 r:0.5547
ne_en Dev loss: 0.6047 r:0.7005
ru_en Dev loss: 0.4415 r:0.7461
Current avg r:0.6954 Best avg r: 0.7346
08:16:30,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:17:35,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:18:39,442 root INFO Epoch 16 Global steps: 123000 Train loss: 0.0685
ro_en Dev loss: 0.3573 r:0.8168
et_en Dev loss: 0.4623 r:0.6620
si_en Dev loss: 0.8267 r:0.5601
ne_en Dev loss: 0.5729 r:0.7058
ru_en Dev loss: 0.4590 r:0.7443
Current avg r:0.6978 Best avg r: 0.7346
08:21:49,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:22:53,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:58,2 root INFO Epoch 16 Global steps: 123500 Train loss: 0.0665
ro_en Dev loss: 0.3624 r:0.8178
et_en Dev loss: 0.4510 r:0.6615
si_en Dev loss: 0.9074 r:0.5524
ne_en Dev loss: 0.6288 r:0.7049
ru_en Dev loss: 0.4550 r:0.7498
Current avg r:0.6973 Best avg r: 0.7346
08:27:08,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:12,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:16,532 root INFO Epoch 16 Global steps: 124000 Train loss: 0.0650
ro_en Dev loss: 0.3287 r:0.8198
et_en Dev loss: 0.4393 r:0.6715
si_en Dev loss: 0.8044 r:0.5575
ne_en Dev loss: 0.5328 r:0.7150
ru_en Dev loss: 0.4258 r:0.7547
Current avg r:0.7037 Best avg r: 0.7346
08:32:26,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:33:30,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:34:35,47 root INFO Epoch 16 Global steps: 124500 Train loss: 0.0626
ro_en Dev loss: 0.3696 r:0.8151
et_en Dev loss: 0.4778 r:0.6688
si_en Dev loss: 0.8738 r:0.5536
ne_en Dev loss: 0.6052 r:0.7114
ru_en Dev loss: 0.4604 r:0.7480
Current avg r:0.6994 Best avg r: 0.7346
08:37:45,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:38:49,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:39:53,374 root INFO Epoch 16 Global steps: 125000 Train loss: 0.0642
ro_en Dev loss: 0.3925 r:0.8153
et_en Dev loss: 0.4832 r:0.6640
si_en Dev loss: 0.9507 r:0.5490
ne_en Dev loss: 0.6668 r:0.7063
ru_en Dev loss: 0.4813 r:0.7511
Current avg r:0.6972 Best avg r: 0.7346
