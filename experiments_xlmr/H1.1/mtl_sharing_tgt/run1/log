14:42:58,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:43:23,992 root INFO 
id:ro_en cur r: 0.5044 best r: 0.5044
14:43:49,904 root INFO 
id:et_en cur r: 0.5034 best r: 0.5034
14:44:15,908 root INFO 
id:si_en cur r: 0.4398 best r: 0.4398
14:44:41,999 root INFO 
id:ne_en cur r: 0.5807 best r: 0.5807
14:45:07,720 root INFO 
id:ru_en cur r: 0.4678 best r: 0.4678
14:45:07,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:12,436 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:46:12,442 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
14:46:12,447 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
14:46:12,452 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:46:12,457 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:47:17,303 root INFO Epoch 0 Global steps: 500 Train loss: 0.8823
ro_en Dev loss: 0.6291 r:0.5821
et_en Dev loss: 0.5559 r:0.5279
si_en Dev loss: 0.6916 r:0.4420
ne_en Dev loss: 0.5280 r:0.6182
ru_en Dev loss: 0.6600 r:0.4698
Current avg r:0.5280 Best avg r: 0.5280
14:50:29,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:50:55,703 root INFO 
id:ro_en cur r: 0.6199 best r: 0.6199
14:51:21,547 root INFO 
id:et_en cur r: 0.5575 best r: 0.5575
14:51:47,448 root INFO 
id:si_en cur r: 0.4695 best r: 0.4695
14:52:25,995 root INFO 
id:ru_en cur r: 0.5440 best r: 0.5440
14:52:25,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:30,469 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:53:30,475 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
14:53:30,480 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
14:53:30,486 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:53:30,491 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:54:35,27 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8114
ro_en Dev loss: 0.6258 r:0.6491
et_en Dev loss: 0.4863 r:0.6077
si_en Dev loss: 0.7765 r:0.4537
ne_en Dev loss: 0.5348 r:0.5996
ru_en Dev loss: 0.5959 r:0.5855
Current avg r:0.5791 Best avg r: 0.5791
14:57:47,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:39,235 root INFO 
id:si_en cur r: 0.4749 best r: 0.4749
14:59:17,804 root INFO 
id:ru_en cur r: 0.6329 best r: 0.6329
14:59:17,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:22,360 root INFO Epoch 0 Global steps: 1500 Train loss: 0.7701
ro_en Dev loss: 0.7532 r:0.6134
et_en Dev loss: 0.5405 r:0.5682
si_en Dev loss: 0.8640 r:0.4715
ne_en Dev loss: 0.7323 r:0.5241
ru_en Dev loss: 0.6469 r:0.6594
Current avg r:0.5673 Best avg r: 0.5791
15:03:35,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:00,815 root INFO 
id:ro_en cur r: 0.6348 best r: 0.6348
15:04:26,662 root INFO 
id:et_en cur r: 0.6074 best r: 0.6074
15:05:05,465 root INFO 
id:ne_en cur r: 0.6025 best r: 0.6025
15:05:31,144 root INFO 
id:ru_en cur r: 0.6762 best r: 0.6762
15:05:31,144 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:35,633 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:06:35,639 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
15:06:35,644 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
15:06:35,649 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:06:35,655 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:07:40,168 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7179
ro_en Dev loss: 0.6479 r:0.6684
et_en Dev loss: 0.4674 r:0.6324
si_en Dev loss: 0.8180 r:0.5012
ne_en Dev loss: 0.5029 r:0.6396
ru_en Dev loss: 0.5641 r:0.6968
Current avg r:0.6277 Best avg r: 0.6277
15:10:52,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:18,463 root INFO 
id:ro_en cur r: 0.6781 best r: 0.6781
15:11:44,315 root INFO 
id:et_en cur r: 0.6511 best r: 0.6511
15:12:10,189 root INFO 
id:si_en cur r: 0.5080 best r: 0.5080
15:12:36,155 root INFO 
id:ne_en cur r: 0.6712 best r: 0.6712
15:13:01,843 root INFO 
id:ru_en cur r: 0.7055 best r: 0.7055
15:13:01,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:06,337 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:14:06,343 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
15:14:06,349 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
15:14:06,356 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:14:06,361 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:15:10,881 root INFO Epoch 0 Global steps: 2500 Train loss: 0.6528
ro_en Dev loss: 0.6486 r:0.6927
et_en Dev loss: 0.4801 r:0.6594
si_en Dev loss: 0.8630 r:0.5195
ne_en Dev loss: 0.5462 r:0.6656
ru_en Dev loss: 0.5987 r:0.7116
Current avg r:0.6497 Best avg r: 0.6497
15:18:24,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:28,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:33,704 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6238
ro_en Dev loss: 0.6021 r:0.6935
et_en Dev loss: 0.4442 r:0.6609
si_en Dev loss: 0.8609 r:0.5113
ne_en Dev loss: 0.5971 r:0.6445
ru_en Dev loss: 0.5572 r:0.7088
Current avg r:0.6438 Best avg r: 0.6497
15:23:47,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:13,91 root INFO 
id:ro_en cur r: 0.7006 best r: 0.7006
15:24:39,29 root INFO 
id:et_en cur r: 0.6627 best r: 0.6627
15:25:04,987 root INFO 
id:si_en cur r: 0.5192 best r: 0.5192
15:25:43,641 root INFO 
id:ru_en cur r: 0.7141 best r: 0.7141
15:25:43,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:48,271 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:26:48,277 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
15:26:48,282 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
15:26:48,288 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:26:48,300 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:27:53,29 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6354
ro_en Dev loss: 0.5444 r:0.7168
et_en Dev loss: 0.4157 r:0.6838
si_en Dev loss: 0.7779 r:0.5281
ne_en Dev loss: 0.5955 r:0.6668
ru_en Dev loss: 0.5165 r:0.7248
Current avg r:0.6641 Best avg r: 0.6641
15:31:06,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:32,37 root INFO 
id:ro_en cur r: 0.7160 best r: 0.7160
15:31:57,920 root INFO 
id:et_en cur r: 0.6910 best r: 0.6910
15:32:23,834 root INFO 
id:si_en cur r: 0.5395 best r: 0.5395
15:32:49,739 root INFO 
id:ne_en cur r: 0.7062 best r: 0.7062
15:33:15,416 root INFO 
id:ru_en cur r: 0.7312 best r: 0.7312
15:33:15,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:20,18 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:34:20,24 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
15:34:20,29 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
15:34:20,33 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:34:20,39 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:35:24,678 root INFO Epoch 0 Global steps: 4000 Train loss: 0.5830
ro_en Dev loss: 0.4293 r:0.7274
et_en Dev loss: 0.3587 r:0.7043
si_en Dev loss: 0.6307 r:0.5512
ne_en Dev loss: 0.4146 r:0.7031
ru_en Dev loss: 0.4209 r:0.7410
Current avg r:0.6854 Best avg r: 0.6854
15:38:37,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:03,625 root INFO 
id:ro_en cur r: 0.7338 best r: 0.7338
15:39:29,561 root INFO 
id:et_en cur r: 0.6956 best r: 0.6956
15:39:55,487 root INFO 
id:si_en cur r: 0.5479 best r: 0.5479
15:40:21,407 root INFO 
id:ne_en cur r: 0.7099 best r: 0.7099
15:40:47,74 root INFO 
id:ru_en cur r: 0.7394 best r: 0.7394
15:40:47,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:51,694 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:41:51,700 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
15:41:51,704 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
15:41:51,709 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:41:51,713 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:42:56,435 root INFO Epoch 0 Global steps: 4500 Train loss: 0.5980
ro_en Dev loss: 0.4374 r:0.7403
et_en Dev loss: 0.3693 r:0.7003
si_en Dev loss: 0.7302 r:0.5532
ne_en Dev loss: 0.4426 r:0.7079
ru_en Dev loss: 0.4289 r:0.7478
Current avg r:0.6899 Best avg r: 0.6899
15:46:09,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:35,435 root INFO 
id:ro_en cur r: 0.7410 best r: 0.7410
15:47:01,350 root INFO 
id:et_en cur r: 0.6975 best r: 0.6975
15:47:40,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:44,827 root INFO Epoch 0 Global steps: 5000 Train loss: 0.5715
ro_en Dev loss: 0.5668 r:0.7475
et_en Dev loss: 0.4487 r:0.7026
si_en Dev loss: 0.9550 r:0.5539
ne_en Dev loss: 0.6436 r:0.7024
ru_en Dev loss: 0.6152 r:0.7283
Current avg r:0.6869 Best avg r: 0.6899
15:51:58,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:24,827 root INFO 
id:ro_en cur r: 0.7633 best r: 0.7633
15:52:50,746 root INFO 
id:et_en cur r: 0.7036 best r: 0.7036
15:53:16,680 root INFO 
id:si_en cur r: 0.5674 best r: 0.5674
15:53:42,650 root INFO 
id:ne_en cur r: 0.7220 best r: 0.7220
15:53:55,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:00,96 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:55:00,102 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
15:55:00,107 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
15:55:00,113 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:55:00,118 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:56:04,774 root INFO Epoch 0 Global steps: 5500 Train loss: 0.5794
ro_en Dev loss: 0.4495 r:0.7677
et_en Dev loss: 0.3806 r:0.7099
si_en Dev loss: 0.7310 r:0.5754
ne_en Dev loss: 0.4738 r:0.7231
ru_en Dev loss: 0.4789 r:0.7452
Current avg r:0.7043 Best avg r: 0.7043
15:59:18,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:44,351 root INFO 
id:ro_en cur r: 0.7687 best r: 0.7687
16:00:10,289 root INFO 
id:et_en cur r: 0.7102 best r: 0.7102
16:00:36,252 root INFO 
id:si_en cur r: 0.5718 best r: 0.5718
16:01:02,183 root INFO 
id:ne_en cur r: 0.7278 best r: 0.7278
16:01:15,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:19,664 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:02:19,670 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
16:02:19,675 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
16:02:19,680 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:02:19,685 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:03:24,427 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5403
ro_en Dev loss: 0.4217 r:0.7686
et_en Dev loss: 0.3676 r:0.7156
si_en Dev loss: 0.7160 r:0.5776
ne_en Dev loss: 0.4343 r:0.7281
ru_en Dev loss: 0.4820 r:0.7424
Current avg r:0.7065 Best avg r: 0.7065
16:06:37,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:03,595 root INFO 
id:ro_en cur r: 0.7851 best r: 0.7851
16:07:29,536 root INFO 
id:et_en cur r: 0.7174 best r: 0.7174
16:07:55,497 root INFO 
id:si_en cur r: 0.5818 best r: 0.5818
16:08:21,470 root INFO 
id:ne_en cur r: 0.7419 best r: 0.7419
16:08:47,155 root INFO 
id:ru_en cur r: 0.7482 best r: 0.7482
16:08:47,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:51,814 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:09:51,820 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
16:09:51,825 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
16:09:51,830 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:09:51,835 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:10:56,577 root INFO Epoch 0 Global steps: 6500 Train loss: 0.5371
ro_en Dev loss: 0.3934 r:0.7816
et_en Dev loss: 0.3534 r:0.7193
si_en Dev loss: 0.6710 r:0.5896
ne_en Dev loss: 0.3775 r:0.7404
ru_en Dev loss: 0.4460 r:0.7527
Current avg r:0.7167 Best avg r: 0.7167
16:14:09,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:01,672 root INFO 
id:si_en cur r: 0.5853 best r: 0.5853
16:15:27,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:32,183 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5308
ro_en Dev loss: 0.4138 r:0.7822
et_en Dev loss: 0.3722 r:0.7194
si_en Dev loss: 0.7096 r:0.5884
ne_en Dev loss: 0.4584 r:0.7374
ru_en Dev loss: 0.5271 r:0.7357
Current avg r:0.7126 Best avg r: 0.7167
16:19:46,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:11,870 root INFO 
id:ro_en cur r: 0.7967 best r: 0.7967
16:20:37,806 root INFO 
id:et_en cur r: 0.7285 best r: 0.7285
16:21:03,755 root INFO 
id:si_en cur r: 0.6037 best r: 0.6037
16:21:29,700 root INFO 
id:ne_en cur r: 0.7460 best r: 0.7460
16:21:55,389 root INFO 
id:ru_en cur r: 0.7503 best r: 0.7503
16:21:55,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:00,50 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:23:00,59 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
16:23:00,65 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
16:23:00,70 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:23:00,75 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:24:04,692 root INFO Epoch 0 Global steps: 7500 Train loss: 0.5245
ro_en Dev loss: 0.3391 r:0.7924
et_en Dev loss: 0.3440 r:0.7316
si_en Dev loss: 0.6055 r:0.6056
ne_en Dev loss: 0.3853 r:0.7461
ru_en Dev loss: 0.4373 r:0.7561
Current avg r:0.7264 Best avg r: 0.7264
16:27:18,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:44,575 root INFO 
id:ro_en cur r: 0.8044 best r: 0.8044
16:28:36,392 root INFO 
id:ne_en cur r: 0.7480 best r: 0.7480
16:28:49,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:53,889 root INFO Epoch 1 Global steps: 8000 Train loss: 0.5071
ro_en Dev loss: 0.3553 r:0.8016
et_en Dev loss: 0.3495 r:0.7237
si_en Dev loss: 0.6520 r:0.6043
ne_en Dev loss: 0.4383 r:0.7430
ru_en Dev loss: 0.4291 r:0.7478
Current avg r:0.7241 Best avg r: 0.7264
16:33:07,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:11,920 root INFO 
id:ne_en cur r: 0.7492 best r: 0.7492
16:34:24,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:29,377 root INFO Epoch 1 Global steps: 8500 Train loss: 0.4918
ro_en Dev loss: 0.3450 r:0.7994
et_en Dev loss: 0.3396 r:0.7289
si_en Dev loss: 0.6493 r:0.6061
ne_en Dev loss: 0.4016 r:0.7482
ru_en Dev loss: 0.4543 r:0.7435
Current avg r:0.7252 Best avg r: 0.7264
16:38:43,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:48,154 root INFO 
id:ne_en cur r: 0.7567 best r: 0.7567
16:40:00,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:05,590 root INFO Epoch 1 Global steps: 9000 Train loss: 0.4787
ro_en Dev loss: 0.3648 r:0.7979
et_en Dev loss: 0.3372 r:0.7284
si_en Dev loss: 0.6910 r:0.6040
ne_en Dev loss: 0.4331 r:0.7515
ru_en Dev loss: 0.4615 r:0.7369
Current avg r:0.7237 Best avg r: 0.7264
16:44:18,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:23,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:28,218 root INFO Epoch 1 Global steps: 9500 Train loss: 0.4943
ro_en Dev loss: 0.3648 r:0.7979
et_en Dev loss: 0.3562 r:0.7214
si_en Dev loss: 0.7363 r:0.5959
ne_en Dev loss: 0.4319 r:0.7439
ru_en Dev loss: 0.4386 r:0.7408
Current avg r:0.7200 Best avg r: 0.7264
16:49:42,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:08,28 root INFO 
id:ro_en cur r: 0.8160 best r: 0.8160
16:50:33,945 root INFO 
id:et_en cur r: 0.7302 best r: 0.7302
16:50:59,883 root INFO 
id:si_en cur r: 0.6196 best r: 0.6196
16:51:25,819 root INFO 
id:ne_en cur r: 0.7579 best r: 0.7579
16:51:38,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:43,256 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:52:43,263 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
16:52:43,267 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
16:52:43,272 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:52:43,277 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:53:47,926 root INFO Epoch 1 Global steps: 10000 Train loss: 0.4900
ro_en Dev loss: 0.3031 r:0.8118
et_en Dev loss: 0.3357 r:0.7305
si_en Dev loss: 0.5442 r:0.6186
ne_en Dev loss: 0.3822 r:0.7563
ru_en Dev loss: 0.4070 r:0.7433
Current avg r:0.7321 Best avg r: 0.7321
16:57:01,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:18,448 root INFO 
id:ru_en cur r: 0.7524 best r: 0.7524
16:58:18,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:22,996 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:59:23,4 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
16:59:23,9 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
16:59:23,16 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:59:23,29 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:00:27,601 root INFO Epoch 1 Global steps: 10500 Train loss: 0.4781
ro_en Dev loss: 0.3166 r:0.8117
et_en Dev loss: 0.3399 r:0.7287
si_en Dev loss: 0.5988 r:0.6159
ne_en Dev loss: 0.4183 r:0.7565
ru_en Dev loss: 0.4041 r:0.7541
Current avg r:0.7334 Best avg r: 0.7334
17:03:40,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:45,115 root INFO 
id:ne_en cur r: 0.7622 best r: 0.7622
17:05:10,784 root INFO 
id:ru_en cur r: 0.7737 best r: 0.7737
17:05:10,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:15,376 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:06:15,384 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
17:06:15,389 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
17:06:15,393 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:06:15,398 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:07:19,976 root INFO Epoch 1 Global steps: 11000 Train loss: 0.4879
ro_en Dev loss: 0.3040 r:0.8089
et_en Dev loss: 0.3405 r:0.7289
si_en Dev loss: 0.5611 r:0.6214
ne_en Dev loss: 0.3669 r:0.7596
ru_en Dev loss: 0.3478 r:0.7734
Current avg r:0.7384 Best avg r: 0.7384
17:10:32,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:37,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:41,824 root INFO Epoch 1 Global steps: 11500 Train loss: 0.4780
ro_en Dev loss: 0.3223 r:0.8005
et_en Dev loss: 0.3468 r:0.7166
si_en Dev loss: 0.6845 r:0.5975
ne_en Dev loss: 0.4164 r:0.7435
ru_en Dev loss: 0.4345 r:0.7314
Current avg r:0.7179 Best avg r: 0.7384
17:15:54,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:20,503 root INFO 
id:ro_en cur r: 0.8221 best r: 0.8221
17:16:46,392 root INFO 
id:et_en cur r: 0.7309 best r: 0.7309
17:17:12,300 root INFO 
id:si_en cur r: 0.6232 best r: 0.6232
17:17:38,217 root INFO 
id:ne_en cur r: 0.7680 best r: 0.7680
17:17:51,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:55,640 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:18:55,646 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
17:18:55,651 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
17:18:55,656 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:18:55,663 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:20:00,217 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4642
ro_en Dev loss: 0.3047 r:0.8153
et_en Dev loss: 0.3263 r:0.7363
si_en Dev loss: 0.5767 r:0.6205
ne_en Dev loss: 0.3851 r:0.7657
ru_en Dev loss: 0.3909 r:0.7573
Current avg r:0.7390 Best avg r: 0.7390
17:23:13,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:17,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:22,334 root INFO Epoch 1 Global steps: 12500 Train loss: 0.4511
ro_en Dev loss: 0.3285 r:0.8127
et_en Dev loss: 0.3487 r:0.7225
si_en Dev loss: 0.6681 r:0.6090
ne_en Dev loss: 0.3901 r:0.7619
ru_en Dev loss: 0.4578 r:0.7376
Current avg r:0.7287 Best avg r: 0.7390
17:28:35,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:01,73 root INFO 
id:ro_en cur r: 0.8240 best r: 0.8240
17:29:39,905 root INFO 
id:si_en cur r: 0.6269 best r: 0.6269
17:30:05,822 root INFO 
id:ne_en cur r: 0.7732 best r: 0.7732
17:30:18,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:23,191 root INFO Epoch 1 Global steps: 13000 Train loss: 0.4792
ro_en Dev loss: 0.3411 r:0.8167
et_en Dev loss: 0.3533 r:0.7261
si_en Dev loss: 0.6753 r:0.6245
ne_en Dev loss: 0.4138 r:0.7722
ru_en Dev loss: 0.4741 r:0.7444
Current avg r:0.7368 Best avg r: 0.7390
17:34:36,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:01,799 root INFO 
id:ro_en cur r: 0.8284 best r: 0.8284
17:35:40,631 root INFO 
id:si_en cur r: 0.6307 best r: 0.6307
17:36:06,527 root INFO 
id:ne_en cur r: 0.7747 best r: 0.7747
17:36:19,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:23,829 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:37:23,835 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/et_en.lang_agnost_mlp.dev.best.scores
17:37:23,839 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/si_en.lang_agnost_mlp.dev.best.scores
17:37:23,844 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:37:23,849 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:38:28,303 root INFO Epoch 1 Global steps: 13500 Train loss: 0.4583
ro_en Dev loss: 0.2972 r:0.8214
et_en Dev loss: 0.3376 r:0.7263
si_en Dev loss: 0.5816 r:0.6272
ne_en Dev loss: 0.3526 r:0.7740
ru_en Dev loss: 0.3827 r:0.7652
Current avg r:0.7428 Best avg r: 0.7428
17:41:40,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:45,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:49,933 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4721
ro_en Dev loss: 0.3090 r:0.8110
et_en Dev loss: 0.3410 r:0.7220
si_en Dev loss: 0.6810 r:0.6012
ne_en Dev loss: 0.4116 r:0.7610
ru_en Dev loss: 0.4042 r:0.7520
Current avg r:0.7294 Best avg r: 0.7428
17:47:02,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:07,435 root INFO 
id:ne_en cur r: 0.7799 best r: 0.7799
17:48:20,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:24,819 root INFO Epoch 1 Global steps: 14500 Train loss: 0.4616
ro_en Dev loss: 0.2899 r:0.8167
et_en Dev loss: 0.3368 r:0.7283
si_en Dev loss: 0.5582 r:0.6211
ne_en Dev loss: 0.3224 r:0.7758
ru_en Dev loss: 0.3498 r:0.7662
Current avg r:0.7416 Best avg r: 0.7428
17:52:37,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:42,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:46,638 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4555
ro_en Dev loss: 0.3037 r:0.8120
et_en Dev loss: 0.3403 r:0.7220
si_en Dev loss: 0.6601 r:0.6012
ne_en Dev loss: 0.3920 r:0.7623
ru_en Dev loss: 0.3914 r:0.7575
Current avg r:0.7310 Best avg r: 0.7428
17:58:00,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:04,934 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:09,476 root INFO Epoch 2 Global steps: 15500 Train loss: 0.4152
ro_en Dev loss: 0.3036 r:0.8194
et_en Dev loss: 0.3418 r:0.7300
si_en Dev loss: 0.5822 r:0.6154
ne_en Dev loss: 0.3388 r:0.7768
ru_en Dev loss: 0.3948 r:0.7594
Current avg r:0.7402 Best avg r: 0.7428
18:03:22,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:27,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:31,894 root INFO Epoch 2 Global steps: 16000 Train loss: 0.4156
ro_en Dev loss: 0.3207 r:0.8154
et_en Dev loss: 0.3496 r:0.7203
si_en Dev loss: 0.6120 r:0.6140
ne_en Dev loss: 0.3799 r:0.7734
ru_en Dev loss: 0.4063 r:0.7464
Current avg r:0.7339 Best avg r: 0.7428
18:08:44,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:49,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:53,835 root INFO Epoch 2 Global steps: 16500 Train loss: 0.4183
ro_en Dev loss: 0.3642 r:0.8082
et_en Dev loss: 0.3831 r:0.7098
si_en Dev loss: 0.7931 r:0.5956
ne_en Dev loss: 0.4662 r:0.7605
ru_en Dev loss: 0.4836 r:0.7346
Current avg r:0.7217 Best avg r: 0.7428
18:14:06,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:15:11,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:15,701 root INFO Epoch 2 Global steps: 17000 Train loss: 0.4138
ro_en Dev loss: 0.3136 r:0.8170
et_en Dev loss: 0.3699 r:0.7220
si_en Dev loss: 0.5953 r:0.6197
ne_en Dev loss: 0.3674 r:0.7723
ru_en Dev loss: 0.4353 r:0.7277
Current avg r:0.7317 Best avg r: 0.7428
18:19:28,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:33,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:37,613 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4219
ro_en Dev loss: 0.3551 r:0.8115
et_en Dev loss: 0.3756 r:0.7089
si_en Dev loss: 0.8045 r:0.6002
ne_en Dev loss: 0.4442 r:0.7640
ru_en Dev loss: 0.4982 r:0.7287
Current avg r:0.7227 Best avg r: 0.7428
18:24:50,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:55,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:59,572 root INFO Epoch 2 Global steps: 18000 Train loss: 0.3991
ro_en Dev loss: 0.3173 r:0.8211
et_en Dev loss: 0.3508 r:0.7255
si_en Dev loss: 0.6135 r:0.6282
ne_en Dev loss: 0.4001 r:0.7765
ru_en Dev loss: 0.4092 r:0.7587
Current avg r:0.7420 Best avg r: 0.7428
18:30:13,120 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:17,712 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:22,326 root INFO Epoch 2 Global steps: 18500 Train loss: 0.4067
ro_en Dev loss: 0.3071 r:0.8204
et_en Dev loss: 0.3547 r:0.7240
si_en Dev loss: 0.5483 r:0.6299
ne_en Dev loss: 0.3598 r:0.7728
ru_en Dev loss: 0.4109 r:0.7526
Current avg r:0.7399 Best avg r: 0.7428
18:35:35,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:40,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:44,655 root INFO Epoch 2 Global steps: 19000 Train loss: 0.3875
ro_en Dev loss: 0.3088 r:0.8202
et_en Dev loss: 0.3563 r:0.7180
si_en Dev loss: 0.6462 r:0.6255
ne_en Dev loss: 0.4166 r:0.7708
ru_en Dev loss: 0.4165 r:0.7485
Current avg r:0.7366 Best avg r: 0.7428
18:40:57,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:02,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:06,688 root INFO Epoch 2 Global steps: 19500 Train loss: 0.4105
ro_en Dev loss: 0.2985 r:0.8226
et_en Dev loss: 0.3545 r:0.7159
si_en Dev loss: 0.6420 r:0.6233
ne_en Dev loss: 0.4436 r:0.7639
ru_en Dev loss: 0.4186 r:0.7392
Current avg r:0.7330 Best avg r: 0.7428
18:46:19,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:24,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:28,682 root INFO Epoch 2 Global steps: 20000 Train loss: 0.3917
ro_en Dev loss: 0.3289 r:0.8228
et_en Dev loss: 0.3691 r:0.7187
si_en Dev loss: 0.6715 r:0.6260
ne_en Dev loss: 0.4007 r:0.7681
ru_en Dev loss: 0.4333 r:0.7493
Current avg r:0.7370 Best avg r: 0.7428
18:51:41,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:45,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:50,109 root INFO Epoch 2 Global steps: 20500 Train loss: 0.4108
ro_en Dev loss: 0.3100 r:0.8210
et_en Dev loss: 0.3606 r:0.7204
si_en Dev loss: 0.6331 r:0.6238
ne_en Dev loss: 0.3649 r:0.7642
ru_en Dev loss: 0.4323 r:0.7421
Current avg r:0.7343 Best avg r: 0.7428
18:57:02,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:07,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:11,859 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4151
ro_en Dev loss: 0.3176 r:0.8188
et_en Dev loss: 0.3731 r:0.7153
si_en Dev loss: 0.6319 r:0.6174
ne_en Dev loss: 0.3517 r:0.7622
ru_en Dev loss: 0.3885 r:0.7511
Current avg r:0.7330 Best avg r: 0.7428
19:02:24,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:50,496 root INFO 
id:ro_en cur r: 0.8299 best r: 0.8299
19:03:42,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:46,754 root INFO Epoch 2 Global steps: 21500 Train loss: 0.4061
ro_en Dev loss: 0.3017 r:0.8253
et_en Dev loss: 0.3451 r:0.7260
si_en Dev loss: 0.6392 r:0.6257
ne_en Dev loss: 0.3501 r:0.7664
ru_en Dev loss: 0.3794 r:0.7627
Current avg r:0.7413 Best avg r: 0.7428
19:08:00,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:04,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:09,368 root INFO Epoch 2 Global steps: 22000 Train loss: 0.3822
ro_en Dev loss: 0.3134 r:0.8238
et_en Dev loss: 0.3433 r:0.7226
si_en Dev loss: 0.5966 r:0.6318
ne_en Dev loss: 0.3754 r:0.7663
ru_en Dev loss: 0.3978 r:0.7597
Current avg r:0.7408 Best avg r: 0.7428
19:13:22,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:27,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:31,862 root INFO Epoch 2 Global steps: 22500 Train loss: 0.4025
ro_en Dev loss: 0.3215 r:0.8170
et_en Dev loss: 0.3900 r:0.7078
si_en Dev loss: 0.6308 r:0.6194
ne_en Dev loss: 0.3722 r:0.7651
ru_en Dev loss: 0.4066 r:0.7463
Current avg r:0.7311 Best avg r: 0.7428
19:18:45,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:50,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:54,579 root INFO Epoch 3 Global steps: 23000 Train loss: 0.3602
ro_en Dev loss: 0.3274 r:0.8172
et_en Dev loss: 0.3698 r:0.7072
si_en Dev loss: 0.7392 r:0.6079
ne_en Dev loss: 0.4664 r:0.7650
ru_en Dev loss: 0.4285 r:0.7418
Current avg r:0.7278 Best avg r: 0.7428
19:24:07,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:11,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:16,520 root INFO Epoch 3 Global steps: 23500 Train loss: 0.3513
ro_en Dev loss: 0.3165 r:0.8184
et_en Dev loss: 0.3761 r:0.7056
si_en Dev loss: 0.7534 r:0.6022
ne_en Dev loss: 0.4509 r:0.7621
ru_en Dev loss: 0.4436 r:0.7329
Current avg r:0.7242 Best avg r: 0.7428
19:29:29,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:33,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:38,429 root INFO Epoch 3 Global steps: 24000 Train loss: 0.3616
ro_en Dev loss: 0.3370 r:0.8141
et_en Dev loss: 0.3876 r:0.7025
si_en Dev loss: 0.7923 r:0.5980
ne_en Dev loss: 0.4539 r:0.7656
ru_en Dev loss: 0.4419 r:0.7420
Current avg r:0.7244 Best avg r: 0.7428
19:34:51,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:55,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:00,230 root INFO Epoch 3 Global steps: 24500 Train loss: 0.3652
ro_en Dev loss: 0.3084 r:0.8211
et_en Dev loss: 0.3803 r:0.7149
si_en Dev loss: 0.6046 r:0.6151
ne_en Dev loss: 0.3704 r:0.7583
ru_en Dev loss: 0.3918 r:0.7583
Current avg r:0.7335 Best avg r: 0.7428
19:40:13,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:17,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:22,132 root INFO Epoch 3 Global steps: 25000 Train loss: 0.3570
ro_en Dev loss: 0.3084 r:0.8201
et_en Dev loss: 0.3742 r:0.7128
si_en Dev loss: 0.6420 r:0.6053
ne_en Dev loss: 0.3788 r:0.7642
ru_en Dev loss: 0.3923 r:0.7501
Current avg r:0.7305 Best avg r: 0.7428
19:45:34,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:39,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:44,39 root INFO Epoch 3 Global steps: 25500 Train loss: 0.3407
ro_en Dev loss: 0.3044 r:0.8244
et_en Dev loss: 0.3704 r:0.7168
si_en Dev loss: 0.6532 r:0.6148
ne_en Dev loss: 0.3792 r:0.7605
ru_en Dev loss: 0.3818 r:0.7604
Current avg r:0.7354 Best avg r: 0.7428
19:50:56,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:01,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:05,862 root INFO Epoch 3 Global steps: 26000 Train loss: 0.3399
ro_en Dev loss: 0.3342 r:0.8200
et_en Dev loss: 0.3734 r:0.7028
si_en Dev loss: 0.6921 r:0.6021
ne_en Dev loss: 0.4212 r:0.7591
ru_en Dev loss: 0.4667 r:0.7261
Current avg r:0.7220 Best avg r: 0.7428
19:56:19,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:44,943 root INFO 
id:ro_en cur r: 0.8303 best r: 0.8303
19:57:36,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:41,111 root INFO Epoch 3 Global steps: 26500 Train loss: 0.3506
ro_en Dev loss: 0.2893 r:0.8262
et_en Dev loss: 0.3751 r:0.7176
si_en Dev loss: 0.5711 r:0.6204
ne_en Dev loss: 0.3327 r:0.7705
ru_en Dev loss: 0.3572 r:0.7643
Current avg r:0.7398 Best avg r: 0.7428
20:01:53,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:58,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:02,558 root INFO Epoch 3 Global steps: 27000 Train loss: 0.3497
ro_en Dev loss: 0.2975 r:0.8204
et_en Dev loss: 0.3685 r:0.7119
si_en Dev loss: 0.6071 r:0.6105
ne_en Dev loss: 0.3353 r:0.7707
ru_en Dev loss: 0.3843 r:0.7478
Current avg r:0.7323 Best avg r: 0.7428
20:07:15,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:19,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:24,256 root INFO Epoch 3 Global steps: 27500 Train loss: 0.3388
ro_en Dev loss: 0.3476 r:0.8175
et_en Dev loss: 0.3971 r:0.7113
si_en Dev loss: 0.7182 r:0.6063
ne_en Dev loss: 0.3995 r:0.7698
ru_en Dev loss: 0.3937 r:0.7587
Current avg r:0.7327 Best avg r: 0.7428
20:12:37,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:42,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:46,824 root INFO Epoch 3 Global steps: 28000 Train loss: 0.3702
ro_en Dev loss: 0.3466 r:0.8091
et_en Dev loss: 0.3924 r:0.6900
si_en Dev loss: 0.8107 r:0.5829
ne_en Dev loss: 0.4669 r:0.7618
ru_en Dev loss: 0.4712 r:0.7104
Current avg r:0.7108 Best avg r: 0.7428
20:18:00,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:04,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:09,269 root INFO Epoch 3 Global steps: 28500 Train loss: 0.3461
ro_en Dev loss: 0.3186 r:0.8117
et_en Dev loss: 0.3806 r:0.6986
si_en Dev loss: 0.6798 r:0.6033
ne_en Dev loss: 0.4121 r:0.7641
ru_en Dev loss: 0.4707 r:0.7020
Current avg r:0.7159 Best avg r: 0.7428
20:23:22,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:26,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:31,257 root INFO Epoch 3 Global steps: 29000 Train loss: 0.3461
ro_en Dev loss: 0.3535 r:0.8125
et_en Dev loss: 0.3863 r:0.7011
si_en Dev loss: 0.7975 r:0.6009
ne_en Dev loss: 0.4528 r:0.7642
ru_en Dev loss: 0.4942 r:0.7180
Current avg r:0.7193 Best avg r: 0.7428
20:28:44,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:48,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:53,261 root INFO Epoch 3 Global steps: 29500 Train loss: 0.3387
ro_en Dev loss: 0.3444 r:0.8193
et_en Dev loss: 0.3797 r:0.7081
si_en Dev loss: 0.7626 r:0.6073
ne_en Dev loss: 0.4472 r:0.7661
ru_en Dev loss: 0.4490 r:0.7407
Current avg r:0.7283 Best avg r: 0.7428
20:34:06,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:11,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:15,799 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3251
ro_en Dev loss: 0.3146 r:0.8171
et_en Dev loss: 0.3834 r:0.7052
si_en Dev loss: 0.5965 r:0.6172
ne_en Dev loss: 0.3512 r:0.7667
ru_en Dev loss: 0.3754 r:0.7565
Current avg r:0.7326 Best avg r: 0.7428
20:39:30,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:35,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:39,845 root INFO Epoch 4 Global steps: 30500 Train loss: 0.3241
ro_en Dev loss: 0.3126 r:0.8192
et_en Dev loss: 0.3688 r:0.7073
si_en Dev loss: 0.7580 r:0.6068
ne_en Dev loss: 0.4455 r:0.7614
ru_en Dev loss: 0.3975 r:0.7485
Current avg r:0.7286 Best avg r: 0.7428
20:44:53,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:57,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:02,495 root INFO Epoch 4 Global steps: 31000 Train loss: 0.3165
ro_en Dev loss: 0.3304 r:0.8172
et_en Dev loss: 0.3848 r:0.7062
si_en Dev loss: 0.7170 r:0.6075
ne_en Dev loss: 0.4560 r:0.7560
ru_en Dev loss: 0.4178 r:0.7501
Current avg r:0.7274 Best avg r: 0.7428
20:50:15,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:20,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:24,998 root INFO Epoch 4 Global steps: 31500 Train loss: 0.3116
ro_en Dev loss: 0.3302 r:0.8165
et_en Dev loss: 0.4135 r:0.7010
si_en Dev loss: 0.6721 r:0.6005
ne_en Dev loss: 0.4428 r:0.7457
ru_en Dev loss: 0.3927 r:0.7490
Current avg r:0.7225 Best avg r: 0.7428
20:55:38,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:42,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:57:47,458 root INFO Epoch 4 Global steps: 32000 Train loss: 0.2952
ro_en Dev loss: 0.3630 r:0.8157
et_en Dev loss: 0.4027 r:0.6928
si_en Dev loss: 0.8880 r:0.5810
ne_en Dev loss: 0.5078 r:0.7453
ru_en Dev loss: 0.4664 r:0.7302
Current avg r:0.7130 Best avg r: 0.7428
21:01:00,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:05,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:09,933 root INFO Epoch 4 Global steps: 32500 Train loss: 0.3009
ro_en Dev loss: 0.3429 r:0.8115
et_en Dev loss: 0.3961 r:0.6860
si_en Dev loss: 0.8158 r:0.5755
ne_en Dev loss: 0.5075 r:0.7505
ru_en Dev loss: 0.4117 r:0.7426
Current avg r:0.7132 Best avg r: 0.7428
21:06:23,355 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:27,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:32,367 root INFO Epoch 4 Global steps: 33000 Train loss: 0.2887
ro_en Dev loss: 0.3250 r:0.8213
et_en Dev loss: 0.4104 r:0.6884
si_en Dev loss: 0.7184 r:0.5988
ne_en Dev loss: 0.4951 r:0.7527
ru_en Dev loss: 0.4398 r:0.7260
Current avg r:0.7174 Best avg r: 0.7428
21:11:45,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:49,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:54,167 root INFO Epoch 4 Global steps: 33500 Train loss: 0.2967
ro_en Dev loss: 0.2990 r:0.8258
et_en Dev loss: 0.4158 r:0.7107
si_en Dev loss: 0.6661 r:0.5990
ne_en Dev loss: 0.3845 r:0.7479
ru_en Dev loss: 0.3842 r:0.7505
Current avg r:0.7268 Best avg r: 0.7428
21:17:06,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:11,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:15,618 root INFO Epoch 4 Global steps: 34000 Train loss: 0.2979
ro_en Dev loss: 0.3208 r:0.8193
et_en Dev loss: 0.4109 r:0.6960
si_en Dev loss: 0.6992 r:0.5965
ne_en Dev loss: 0.4050 r:0.7563
ru_en Dev loss: 0.4222 r:0.7320
Current avg r:0.7200 Best avg r: 0.7428
21:22:28,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:32,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:37,418 root INFO Epoch 4 Global steps: 34500 Train loss: 0.3034
ro_en Dev loss: 0.3235 r:0.8221
et_en Dev loss: 0.3939 r:0.6975
si_en Dev loss: 0.7124 r:0.6010
ne_en Dev loss: 0.4579 r:0.7563
ru_en Dev loss: 0.4269 r:0.7423
Current avg r:0.7239 Best avg r: 0.7428
21:27:50,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:54,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:59,276 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3036
ro_en Dev loss: 0.3107 r:0.8233
et_en Dev loss: 0.3898 r:0.7015
si_en Dev loss: 0.6707 r:0.6041
ne_en Dev loss: 0.4231 r:0.7599
ru_en Dev loss: 0.4239 r:0.7368
Current avg r:0.7251 Best avg r: 0.7428
21:33:12,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:16,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:21,136 root INFO Epoch 4 Global steps: 35500 Train loss: 0.3023
ro_en Dev loss: 0.3276 r:0.8220
et_en Dev loss: 0.4018 r:0.6900
si_en Dev loss: 0.7580 r:0.5910
ne_en Dev loss: 0.4964 r:0.7493
ru_en Dev loss: 0.4854 r:0.7219
Current avg r:0.7148 Best avg r: 0.7428
21:38:33,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:38,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:42,980 root INFO Epoch 4 Global steps: 36000 Train loss: 0.2751
ro_en Dev loss: 0.3264 r:0.8215
et_en Dev loss: 0.4059 r:0.6838
si_en Dev loss: 0.7577 r:0.5885
ne_en Dev loss: 0.4608 r:0.7457
ru_en Dev loss: 0.4744 r:0.7234
Current avg r:0.7126 Best avg r: 0.7428
21:43:55,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:00,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:05,58 root INFO Epoch 4 Global steps: 36500 Train loss: 0.2816
ro_en Dev loss: 0.3328 r:0.8217
et_en Dev loss: 0.4041 r:0.6852
si_en Dev loss: 0.7733 r:0.5914
ne_en Dev loss: 0.4841 r:0.7477
ru_en Dev loss: 0.4459 r:0.7373
Current avg r:0.7167 Best avg r: 0.7428
21:49:17,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:22,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:26,899 root INFO Epoch 4 Global steps: 37000 Train loss: 0.2731
ro_en Dev loss: 0.3220 r:0.8194
et_en Dev loss: 0.4198 r:0.6761
si_en Dev loss: 0.7989 r:0.5828
ne_en Dev loss: 0.4719 r:0.7485
ru_en Dev loss: 0.4349 r:0.7265
Current avg r:0.7106 Best avg r: 0.7428
21:54:39,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:44,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:48,919 root INFO Epoch 4 Global steps: 37500 Train loss: 0.2833
ro_en Dev loss: 0.3284 r:0.8227
et_en Dev loss: 0.4050 r:0.6920
si_en Dev loss: 0.7836 r:0.5904
ne_en Dev loss: 0.5259 r:0.7501
ru_en Dev loss: 0.4705 r:0.7274
Current avg r:0.7165 Best avg r: 0.7428
22:00:03,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:01:08,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:12,691 root INFO Epoch 5 Global steps: 38000 Train loss: 0.2501
ro_en Dev loss: 0.3164 r:0.8232
et_en Dev loss: 0.4039 r:0.6875
si_en Dev loss: 0.7224 r:0.5928
ne_en Dev loss: 0.4533 r:0.7502
ru_en Dev loss: 0.4426 r:0.7302
Current avg r:0.7168 Best avg r: 0.7428
22:05:26,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:51,989 root INFO 
id:ro_en cur r: 0.8321 best r: 0.8321
22:06:43,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:48,166 root INFO Epoch 5 Global steps: 38500 Train loss: 0.2522
ro_en Dev loss: 0.3208 r:0.8265
et_en Dev loss: 0.4397 r:0.6975
si_en Dev loss: 0.7296 r:0.5946
ne_en Dev loss: 0.4309 r:0.7464
ru_en Dev loss: 0.4180 r:0.7483
Current avg r:0.7227 Best avg r: 0.7428
22:11:01,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:05,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:10,193 root INFO Epoch 5 Global steps: 39000 Train loss: 0.2487
ro_en Dev loss: 0.3513 r:0.8205
et_en Dev loss: 0.4319 r:0.6755
si_en Dev loss: 0.8538 r:0.5750
ne_en Dev loss: 0.5380 r:0.7413
ru_en Dev loss: 0.4271 r:0.7448
Current avg r:0.7114 Best avg r: 0.7428
22:16:23,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:27,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:32,174 root INFO Epoch 5 Global steps: 39500 Train loss: 0.2436
ro_en Dev loss: 0.3361 r:0.8213
et_en Dev loss: 0.4311 r:0.6793
si_en Dev loss: 0.7598 r:0.5803
ne_en Dev loss: 0.5121 r:0.7306
ru_en Dev loss: 0.4436 r:0.7297
Current avg r:0.7082 Best avg r: 0.7428
22:21:44,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:49,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:53,950 root INFO Epoch 5 Global steps: 40000 Train loss: 0.2573
ro_en Dev loss: 0.3159 r:0.8235
et_en Dev loss: 0.4237 r:0.6825
si_en Dev loss: 0.7122 r:0.5898
ne_en Dev loss: 0.4704 r:0.7406
ru_en Dev loss: 0.4238 r:0.7399
Current avg r:0.7153 Best avg r: 0.7428
22:27:06,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:10,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:15,375 root INFO Epoch 5 Global steps: 40500 Train loss: 0.2590
ro_en Dev loss: 0.3118 r:0.8221
et_en Dev loss: 0.4121 r:0.6904
si_en Dev loss: 0.7587 r:0.5787
ne_en Dev loss: 0.4911 r:0.7405
ru_en Dev loss: 0.4312 r:0.7270
Current avg r:0.7117 Best avg r: 0.7428
22:32:28,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:32,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:37,429 root INFO Epoch 5 Global steps: 41000 Train loss: 0.2425
ro_en Dev loss: 0.3355 r:0.8198
et_en Dev loss: 0.4124 r:0.6872
si_en Dev loss: 0.7821 r:0.5752
ne_en Dev loss: 0.5460 r:0.7378
ru_en Dev loss: 0.4664 r:0.7188
Current avg r:0.7078 Best avg r: 0.7428
22:37:50,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:55,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:59,948 root INFO Epoch 5 Global steps: 41500 Train loss: 0.2410
ro_en Dev loss: 0.3081 r:0.8207
et_en Dev loss: 0.4489 r:0.6976
si_en Dev loss: 0.6922 r:0.5831
ne_en Dev loss: 0.4198 r:0.7379
ru_en Dev loss: 0.4029 r:0.7420
Current avg r:0.7163 Best avg r: 0.7428
22:43:12,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:17,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:21,813 root INFO Epoch 5 Global steps: 42000 Train loss: 0.2437
ro_en Dev loss: 0.3036 r:0.8239
et_en Dev loss: 0.4305 r:0.6974
si_en Dev loss: 0.6678 r:0.5871
ne_en Dev loss: 0.4253 r:0.7395
ru_en Dev loss: 0.4023 r:0.7472
Current avg r:0.7190 Best avg r: 0.7428
22:48:34,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:49:39,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:43,788 root INFO Epoch 5 Global steps: 42500 Train loss: 0.2499
ro_en Dev loss: 0.3285 r:0.8224
et_en Dev loss: 0.4224 r:0.6785
si_en Dev loss: 0.8688 r:0.5644
ne_en Dev loss: 0.5635 r:0.7340
ru_en Dev loss: 0.4589 r:0.7189
Current avg r:0.7036 Best avg r: 0.7428
22:53:56,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:01,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:05,727 root INFO Epoch 5 Global steps: 43000 Train loss: 0.2513
ro_en Dev loss: 0.3438 r:0.8196
et_en Dev loss: 0.4601 r:0.6745
si_en Dev loss: 0.8297 r:0.5705
ne_en Dev loss: 0.4641 r:0.7467
ru_en Dev loss: 0.4621 r:0.7243
Current avg r:0.7071 Best avg r: 0.7428
22:59:18,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:00:23,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:27,651 root INFO Epoch 5 Global steps: 43500 Train loss: 0.2432
ro_en Dev loss: 0.3809 r:0.8194
et_en Dev loss: 0.4724 r:0.6819
si_en Dev loss: 0.8253 r:0.5767
ne_en Dev loss: 0.4968 r:0.7405
ru_en Dev loss: 0.4999 r:0.7221
Current avg r:0.7081 Best avg r: 0.7428
23:04:40,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:45,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:49,637 root INFO Epoch 5 Global steps: 44000 Train loss: 0.2415
ro_en Dev loss: 0.3162 r:0.8216
et_en Dev loss: 0.4238 r:0.6838
si_en Dev loss: 0.7656 r:0.5749
ne_en Dev loss: 0.4355 r:0.7426
ru_en Dev loss: 0.4326 r:0.7345
Current avg r:0.7115 Best avg r: 0.7428
23:10:02,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:07,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:11,539 root INFO Epoch 5 Global steps: 44500 Train loss: 0.2352
ro_en Dev loss: 0.3224 r:0.8232
et_en Dev loss: 0.4245 r:0.6858
si_en Dev loss: 0.8467 r:0.5665
ne_en Dev loss: 0.4744 r:0.7447
ru_en Dev loss: 0.4594 r:0.7305
Current avg r:0.7101 Best avg r: 0.7428
23:15:24,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:28,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:17:33,327 root INFO Epoch 5 Global steps: 45000 Train loss: 0.2379
ro_en Dev loss: 0.3296 r:0.8149
et_en Dev loss: 0.4220 r:0.6770
si_en Dev loss: 0.7951 r:0.5681
ne_en Dev loss: 0.4648 r:0.7372
ru_en Dev loss: 0.4728 r:0.7032
Current avg r:0.7001 Best avg r: 0.7428
23:20:47,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:51,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:56,404 root INFO Epoch 6 Global steps: 45500 Train loss: 0.2232
ro_en Dev loss: 0.3544 r:0.8080
et_en Dev loss: 0.4234 r:0.6734
si_en Dev loss: 0.8166 r:0.5568
ne_en Dev loss: 0.5609 r:0.7312
ru_en Dev loss: 0.5004 r:0.6879
Current avg r:0.6915 Best avg r: 0.7428
23:26:09,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:27:13,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:28:18,455 root INFO Epoch 6 Global steps: 46000 Train loss: 0.2201
ro_en Dev loss: 0.3384 r:0.8185
et_en Dev loss: 0.4353 r:0.6890
si_en Dev loss: 0.8140 r:0.5663
ne_en Dev loss: 0.5311 r:0.7287
ru_en Dev loss: 0.4433 r:0.7255
Current avg r:0.7056 Best avg r: 0.7428
23:31:31,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:36,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:40,493 root INFO Epoch 6 Global steps: 46500 Train loss: 0.2194
ro_en Dev loss: 0.3538 r:0.8167
et_en Dev loss: 0.4340 r:0.6780
si_en Dev loss: 0.8279 r:0.5646
ne_en Dev loss: 0.5165 r:0.7345
ru_en Dev loss: 0.4814 r:0.7122
Current avg r:0.7012 Best avg r: 0.7428
23:36:53,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:57,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:01,920 root INFO Epoch 6 Global steps: 47000 Train loss: 0.2150
ro_en Dev loss: 0.3188 r:0.8194
et_en Dev loss: 0.4150 r:0.6754
si_en Dev loss: 0.7593 r:0.5659
ne_en Dev loss: 0.4516 r:0.7380
ru_en Dev loss: 0.4514 r:0.7153
Current avg r:0.7028 Best avg r: 0.7428
23:42:14,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:18,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:23,310 root INFO Epoch 6 Global steps: 47500 Train loss: 0.2077
ro_en Dev loss: 0.3255 r:0.8198
et_en Dev loss: 0.4388 r:0.6877
si_en Dev loss: 0.7499 r:0.5752
ne_en Dev loss: 0.4412 r:0.7351
ru_en Dev loss: 0.4261 r:0.7305
Current avg r:0.7097 Best avg r: 0.7428
23:47:36,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:41,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:45,811 root INFO Epoch 6 Global steps: 48000 Train loss: 0.2218
ro_en Dev loss: 0.3339 r:0.8200
et_en Dev loss: 0.4342 r:0.6771
si_en Dev loss: 0.8109 r:0.5703
ne_en Dev loss: 0.5052 r:0.7275
ru_en Dev loss: 0.4462 r:0.7308
Current avg r:0.7052 Best avg r: 0.7428
23:52:59,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:03,680 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:08,235 root INFO Epoch 6 Global steps: 48500 Train loss: 0.2237
ro_en Dev loss: 0.3478 r:0.8150
et_en Dev loss: 0.4366 r:0.6673
si_en Dev loss: 0.8960 r:0.5592
ne_en Dev loss: 0.6212 r:0.7252
ru_en Dev loss: 0.4613 r:0.7237
Current avg r:0.6981 Best avg r: 0.7428
23:58:21,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:26,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:30,633 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2053
ro_en Dev loss: 0.3436 r:0.8172
et_en Dev loss: 0.4390 r:0.6759
si_en Dev loss: 0.8239 r:0.5672
ne_en Dev loss: 0.5254 r:0.7217
ru_en Dev loss: 0.4608 r:0.7290
Current avg r:0.7022 Best avg r: 0.7428
00:03:44,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:48,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:53,149 root INFO Epoch 6 Global steps: 49500 Train loss: 0.2035
ro_en Dev loss: 0.3355 r:0.8179
et_en Dev loss: 0.4676 r:0.6752
si_en Dev loss: 0.7645 r:0.5704
ne_en Dev loss: 0.4891 r:0.7205
ru_en Dev loss: 0.4659 r:0.7205
Current avg r:0.7009 Best avg r: 0.7428
00:09:06,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:11,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:15,591 root INFO Epoch 6 Global steps: 50000 Train loss: 0.2113
ro_en Dev loss: 0.3223 r:0.8194
et_en Dev loss: 0.4618 r:0.6733
si_en Dev loss: 0.8299 r:0.5598
ne_en Dev loss: 0.5041 r:0.7213
ru_en Dev loss: 0.4308 r:0.7324
Current avg r:0.7012 Best avg r: 0.7428
00:14:28,466 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:15:32,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:16:37,264 root INFO Epoch 6 Global steps: 50500 Train loss: 0.2034
ro_en Dev loss: 0.3327 r:0.8229
et_en Dev loss: 0.4547 r:0.6833
si_en Dev loss: 0.7724 r:0.5717
ne_en Dev loss: 0.4729 r:0.7259
ru_en Dev loss: 0.4549 r:0.7302
Current avg r:0.7068 Best avg r: 0.7428
00:19:49,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:54,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:21:58,717 root INFO Epoch 6 Global steps: 51000 Train loss: 0.2017
ro_en Dev loss: 0.3483 r:0.8196
et_en Dev loss: 0.4546 r:0.6626
si_en Dev loss: 0.9045 r:0.5504
ne_en Dev loss: 0.5463 r:0.7154
ru_en Dev loss: 0.4972 r:0.7148
Current avg r:0.6926 Best avg r: 0.7428
00:25:11,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:15,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:20,273 root INFO Epoch 6 Global steps: 51500 Train loss: 0.1944
ro_en Dev loss: 0.3273 r:0.8173
et_en Dev loss: 0.4485 r:0.6626
si_en Dev loss: 0.8557 r:0.5581
ne_en Dev loss: 0.5212 r:0.7175
ru_en Dev loss: 0.4433 r:0.7295
Current avg r:0.6970 Best avg r: 0.7428
00:30:32,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:37,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:41,688 root INFO Epoch 6 Global steps: 52000 Train loss: 0.2040
ro_en Dev loss: 0.3139 r:0.8223
et_en Dev loss: 0.4394 r:0.6774
si_en Dev loss: 0.7887 r:0.5641
ne_en Dev loss: 0.4833 r:0.7199
ru_en Dev loss: 0.4374 r:0.7319
Current avg r:0.7031 Best avg r: 0.7428
00:35:54,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:58,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:03,250 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2043
ro_en Dev loss: 0.3688 r:0.8207
et_en Dev loss: 0.4842 r:0.6737
si_en Dev loss: 0.8904 r:0.5637
ne_en Dev loss: 0.5705 r:0.7266
ru_en Dev loss: 0.4792 r:0.7330
Current avg r:0.7036 Best avg r: 0.7428
00:41:16,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:21,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:25,704 root INFO Epoch 7 Global steps: 53000 Train loss: 0.1837
ro_en Dev loss: 0.2928 r:0.8261
et_en Dev loss: 0.4245 r:0.6798
si_en Dev loss: 0.7510 r:0.5659
ne_en Dev loss: 0.4507 r:0.7345
ru_en Dev loss: 0.3815 r:0.7531
Current avg r:0.7119 Best avg r: 0.7428
00:46:39,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:47:43,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:48:47,992 root INFO Epoch 7 Global steps: 53500 Train loss: 0.1826
ro_en Dev loss: 0.3400 r:0.8223
et_en Dev loss: 0.4751 r:0.6796
si_en Dev loss: 0.8691 r:0.5575
ne_en Dev loss: 0.4749 r:0.7220
ru_en Dev loss: 0.4265 r:0.7485
Current avg r:0.7060 Best avg r: 0.7428
00:52:00,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:05,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:09,655 root INFO Epoch 7 Global steps: 54000 Train loss: 0.1755
ro_en Dev loss: 0.3430 r:0.8224
et_en Dev loss: 0.4517 r:0.6655
si_en Dev loss: 0.8945 r:0.5457
ne_en Dev loss: 0.5113 r:0.7241
ru_en Dev loss: 0.4363 r:0.7400
Current avg r:0.6996 Best avg r: 0.7428
00:57:22,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:27,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:31,895 root INFO Epoch 7 Global steps: 54500 Train loss: 0.1812
ro_en Dev loss: 0.3269 r:0.8224
et_en Dev loss: 0.4793 r:0.6777
si_en Dev loss: 0.7979 r:0.5544
ne_en Dev loss: 0.4744 r:0.7207
ru_en Dev loss: 0.3988 r:0.7473
Current avg r:0.7045 Best avg r: 0.7428
01:02:44,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:49,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:53,509 root INFO Epoch 7 Global steps: 55000 Train loss: 0.1817
ro_en Dev loss: 0.3301 r:0.8217
et_en Dev loss: 0.4618 r:0.6694
si_en Dev loss: 0.8542 r:0.5564
ne_en Dev loss: 0.5242 r:0.7186
ru_en Dev loss: 0.4213 r:0.7392
Current avg r:0.7011 Best avg r: 0.7428
01:08:06,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:10,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:14,946 root INFO Epoch 7 Global steps: 55500 Train loss: 0.1852
ro_en Dev loss: 0.3644 r:0.8169
et_en Dev loss: 0.4603 r:0.6601
si_en Dev loss: 0.9920 r:0.5279
ne_en Dev loss: 0.6340 r:0.7099
ru_en Dev loss: 0.5057 r:0.7038
Current avg r:0.6837 Best avg r: 0.7428
01:13:27,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:32,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:36,531 root INFO Epoch 7 Global steps: 56000 Train loss: 0.1726
ro_en Dev loss: 0.3461 r:0.8170
et_en Dev loss: 0.4597 r:0.6644
si_en Dev loss: 0.8626 r:0.5377
ne_en Dev loss: 0.5448 r:0.7072
ru_en Dev loss: 0.4262 r:0.7364
Current avg r:0.6925 Best avg r: 0.7428
01:18:49,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:53,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:20:57,983 root INFO Epoch 7 Global steps: 56500 Train loss: 0.1947
ro_en Dev loss: 0.3429 r:0.8203
et_en Dev loss: 0.4575 r:0.6688
si_en Dev loss: 0.8565 r:0.5497
ne_en Dev loss: 0.4963 r:0.7221
ru_en Dev loss: 0.4419 r:0.7332
Current avg r:0.6988 Best avg r: 0.7428
01:24:10,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:15,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:19,503 root INFO Epoch 7 Global steps: 57000 Train loss: 0.1818
ro_en Dev loss: 0.3367 r:0.8188
et_en Dev loss: 0.4665 r:0.6721
si_en Dev loss: 0.8566 r:0.5498
ne_en Dev loss: 0.5128 r:0.7244
ru_en Dev loss: 0.4238 r:0.7382
Current avg r:0.7007 Best avg r: 0.7428
01:29:32,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:36,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:31:41,27 root INFO Epoch 7 Global steps: 57500 Train loss: 0.1742
ro_en Dev loss: 0.3567 r:0.8170
et_en Dev loss: 0.4687 r:0.6723
si_en Dev loss: 0.8870 r:0.5509
ne_en Dev loss: 0.5673 r:0.7198
ru_en Dev loss: 0.4800 r:0.7239
Current avg r:0.6968 Best avg r: 0.7428
01:34:53,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:57,962 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:02,345 root INFO Epoch 7 Global steps: 58000 Train loss: 0.1819
ro_en Dev loss: 0.3268 r:0.8177
et_en Dev loss: 0.4736 r:0.6806
si_en Dev loss: 0.7813 r:0.5582
ne_en Dev loss: 0.4944 r:0.7179
ru_en Dev loss: 0.3906 r:0.7575
Current avg r:0.7064 Best avg r: 0.7428
01:40:15,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:41:19,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:42:23,815 root INFO Epoch 7 Global steps: 58500 Train loss: 0.1607
ro_en Dev loss: 0.3505 r:0.8134
et_en Dev loss: 0.4617 r:0.6668
si_en Dev loss: 0.8282 r:0.5491
ne_en Dev loss: 0.5554 r:0.7141
ru_en Dev loss: 0.4747 r:0.7197
Current avg r:0.6926 Best avg r: 0.7428
01:45:36,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:46:40,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:47:45,252 root INFO Epoch 7 Global steps: 59000 Train loss: 0.1666
ro_en Dev loss: 0.3427 r:0.8210
et_en Dev loss: 0.4556 r:0.6701
si_en Dev loss: 0.8907 r:0.5489
ne_en Dev loss: 0.5557 r:0.7200
ru_en Dev loss: 0.4610 r:0.7279
Current avg r:0.6976 Best avg r: 0.7428
01:50:57,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:52:02,201 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:53:06,619 root INFO Epoch 7 Global steps: 59500 Train loss: 0.1726
ro_en Dev loss: 0.3705 r:0.8239
et_en Dev loss: 0.4688 r:0.6726
si_en Dev loss: 0.9552 r:0.5441
ne_en Dev loss: 0.6217 r:0.7146
ru_en Dev loss: 0.4677 r:0.7347
Current avg r:0.6980 Best avg r: 0.7428
01:56:19,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:23,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:58:28,275 root INFO Epoch 7 Global steps: 60000 Train loss: 0.1629
ro_en Dev loss: 0.3190 r:0.8232
et_en Dev loss: 0.4651 r:0.6755
si_en Dev loss: 0.8110 r:0.5530
ne_en Dev loss: 0.5043 r:0.7262
ru_en Dev loss: 0.4612 r:0.7185
Current avg r:0.6993 Best avg r: 0.7428
02:01:45,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:02:50,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:03:56,20 root INFO Epoch 8 Global steps: 60500 Train loss: 0.1524
ro_en Dev loss: 0.3174 r:0.8258
et_en Dev loss: 0.4484 r:0.6715
si_en Dev loss: 0.8101 r:0.5486
ne_en Dev loss: 0.5245 r:0.7151
ru_en Dev loss: 0.4219 r:0.7458
Current avg r:0.7013 Best avg r: 0.7428
02:07:11,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:08:16,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:09:21,862 root INFO Epoch 8 Global steps: 61000 Train loss: 0.1535
ro_en Dev loss: 0.3113 r:0.8265
et_en Dev loss: 0.4700 r:0.6790
si_en Dev loss: 0.7755 r:0.5578
ne_en Dev loss: 0.4773 r:0.7288
ru_en Dev loss: 0.3927 r:0.7533
Current avg r:0.7091 Best avg r: 0.7428
02:12:37,529 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:42,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:47,797 root INFO Epoch 8 Global steps: 61500 Train loss: 0.1556
ro_en Dev loss: 0.3182 r:0.8207
et_en Dev loss: 0.4530 r:0.6698
si_en Dev loss: 0.8223 r:0.5442
ne_en Dev loss: 0.5202 r:0.7221
ru_en Dev loss: 0.4513 r:0.7266
Current avg r:0.6967 Best avg r: 0.7428
02:18:03,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:19:08,852 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:20:14,51 root INFO Epoch 8 Global steps: 62000 Train loss: 0.1501
ro_en Dev loss: 0.3383 r:0.8169
et_en Dev loss: 0.4782 r:0.6599
si_en Dev loss: 0.8566 r:0.5411
ne_en Dev loss: 0.5726 r:0.7131
ru_en Dev loss: 0.4770 r:0.7220
Current avg r:0.6906 Best avg r: 0.7428
02:23:30,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:35,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:41,47 root INFO Epoch 8 Global steps: 62500 Train loss: 0.1567
ro_en Dev loss: 0.3408 r:0.8220
et_en Dev loss: 0.4686 r:0.6646
si_en Dev loss: 0.8534 r:0.5454
ne_en Dev loss: 0.5503 r:0.7153
ru_en Dev loss: 0.4446 r:0.7334
Current avg r:0.6961 Best avg r: 0.7428
02:28:57,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:30:01,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:31:06,513 root INFO Epoch 8 Global steps: 63000 Train loss: 0.1490
ro_en Dev loss: 0.3385 r:0.8233
et_en Dev loss: 0.4587 r:0.6680
si_en Dev loss: 0.9108 r:0.5437
ne_en Dev loss: 0.5575 r:0.7158
ru_en Dev loss: 0.4589 r:0.7369
Current avg r:0.6976 Best avg r: 0.7428
02:34:19,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:24,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:29,374 root INFO Epoch 8 Global steps: 63500 Train loss: 0.1525
ro_en Dev loss: 0.3285 r:0.8228
et_en Dev loss: 0.4677 r:0.6626
si_en Dev loss: 0.8924 r:0.5390
ne_en Dev loss: 0.5336 r:0.7144
ru_en Dev loss: 0.4233 r:0.7436
Current avg r:0.6965 Best avg r: 0.7428
02:39:43,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:40:48,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:41:52,878 root INFO Epoch 8 Global steps: 64000 Train loss: 0.1504
ro_en Dev loss: 0.3276 r:0.8246
et_en Dev loss: 0.4588 r:0.6680
si_en Dev loss: 0.8730 r:0.5417
ne_en Dev loss: 0.5292 r:0.7143
ru_en Dev loss: 0.4347 r:0.7439
Current avg r:0.6985 Best avg r: 0.7428
02:45:06,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:46:11,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:47:16,216 root INFO Epoch 8 Global steps: 64500 Train loss: 0.1542
ro_en Dev loss: 0.3151 r:0.8253
et_en Dev loss: 0.4652 r:0.6708
si_en Dev loss: 0.8214 r:0.5487
ne_en Dev loss: 0.4827 r:0.7263
ru_en Dev loss: 0.4315 r:0.7408
Current avg r:0.7024 Best avg r: 0.7428
02:50:30,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:34,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:39,435 root INFO Epoch 8 Global steps: 65000 Train loss: 0.1582
ro_en Dev loss: 0.3709 r:0.8188
et_en Dev loss: 0.5070 r:0.6581
si_en Dev loss: 0.9791 r:0.5396
ne_en Dev loss: 0.6009 r:0.7178
ru_en Dev loss: 0.4836 r:0.7293
Current avg r:0.6927 Best avg r: 0.7428
02:55:54,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:57:00,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:58:05,266 root INFO Epoch 8 Global steps: 65500 Train loss: 0.1469
ro_en Dev loss: 0.3194 r:0.8231
et_en Dev loss: 0.4648 r:0.6717
si_en Dev loss: 0.8571 r:0.5454
ne_en Dev loss: 0.4976 r:0.7179
ru_en Dev loss: 0.4094 r:0.7483
Current avg r:0.7013 Best avg r: 0.7428
03:01:20,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:02:26,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:31,408 root INFO Epoch 8 Global steps: 66000 Train loss: 0.1433
ro_en Dev loss: 0.3411 r:0.8220
et_en Dev loss: 0.4980 r:0.6684
si_en Dev loss: 0.8755 r:0.5385
ne_en Dev loss: 0.5373 r:0.7064
ru_en Dev loss: 0.4641 r:0.7286
Current avg r:0.6928 Best avg r: 0.7428
03:06:47,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:07:52,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:58,84 root INFO Epoch 8 Global steps: 66500 Train loss: 0.1532
ro_en Dev loss: 0.3154 r:0.8191
et_en Dev loss: 0.4941 r:0.6683
si_en Dev loss: 0.7937 r:0.5411
ne_en Dev loss: 0.5218 r:0.7077
ru_en Dev loss: 0.4261 r:0.7305
Current avg r:0.6934 Best avg r: 0.7428
03:12:13,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:19,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:24,233 root INFO Epoch 8 Global steps: 67000 Train loss: 0.1459
ro_en Dev loss: 0.3305 r:0.8213
et_en Dev loss: 0.4743 r:0.6586
si_en Dev loss: 0.9416 r:0.5373
ne_en Dev loss: 0.5668 r:0.7160
ru_en Dev loss: 0.4368 r:0.7345
Current avg r:0.6935 Best avg r: 0.7428
03:17:39,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:18:44,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:49,593 root INFO Epoch 8 Global steps: 67500 Train loss: 0.1414
ro_en Dev loss: 0.3311 r:0.8237
et_en Dev loss: 0.4671 r:0.6684
si_en Dev loss: 0.8150 r:0.5483
ne_en Dev loss: 0.5462 r:0.7079
ru_en Dev loss: 0.4338 r:0.7396
Current avg r:0.6976 Best avg r: 0.7428
03:23:04,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:24:08,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:13,682 root INFO Epoch 9 Global steps: 68000 Train loss: 0.1431
ro_en Dev loss: 0.3419 r:0.8204
et_en Dev loss: 0.4574 r:0.6626
si_en Dev loss: 0.9577 r:0.5299
ne_en Dev loss: 0.5808 r:0.7107
ru_en Dev loss: 0.4712 r:0.7226
Current avg r:0.6892 Best avg r: 0.7428
03:28:27,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:32,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:37,300 root INFO Epoch 9 Global steps: 68500 Train loss: 0.1318
ro_en Dev loss: 0.3293 r:0.8266
et_en Dev loss: 0.4966 r:0.6679
si_en Dev loss: 0.8517 r:0.5540
ne_en Dev loss: 0.5261 r:0.7162
ru_en Dev loss: 0.4266 r:0.7378
Current avg r:0.7005 Best avg r: 0.7428
03:33:51,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:34:55,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:00,340 root INFO Epoch 9 Global steps: 69000 Train loss: 0.1319
ro_en Dev loss: 0.3267 r:0.8262
et_en Dev loss: 0.4676 r:0.6691
si_en Dev loss: 0.8282 r:0.5467
ne_en Dev loss: 0.5314 r:0.7089
ru_en Dev loss: 0.4456 r:0.7337
Current avg r:0.6969 Best avg r: 0.7428
03:39:13,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:18,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:22,944 root INFO Epoch 9 Global steps: 69500 Train loss: 0.1281
ro_en Dev loss: 0.3318 r:0.8271
et_en Dev loss: 0.5149 r:0.6695
si_en Dev loss: 0.8303 r:0.5484
ne_en Dev loss: 0.5429 r:0.7081
ru_en Dev loss: 0.4251 r:0.7437
Current avg r:0.6994 Best avg r: 0.7428
03:44:38,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:45:43,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:46:49,8 root INFO Epoch 9 Global steps: 70000 Train loss: 0.1331
ro_en Dev loss: 0.3245 r:0.8284
et_en Dev loss: 0.4519 r:0.6694
si_en Dev loss: 0.8440 r:0.5492
ne_en Dev loss: 0.5721 r:0.7087
ru_en Dev loss: 0.4539 r:0.7341
Current avg r:0.6979 Best avg r: 0.7428
03:50:04,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:09,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:15,40 root INFO Epoch 9 Global steps: 70500 Train loss: 0.1307
ro_en Dev loss: 0.3051 r:0.8266
et_en Dev loss: 0.4708 r:0.6619
si_en Dev loss: 0.7927 r:0.5470
ne_en Dev loss: 0.5071 r:0.7137
ru_en Dev loss: 0.4082 r:0.7371
Current avg r:0.6973 Best avg r: 0.7428
03:55:30,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:56:35,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:57:41,209 root INFO Epoch 9 Global steps: 71000 Train loss: 0.1294
ro_en Dev loss: 0.3525 r:0.8247
et_en Dev loss: 0.5005 r:0.6681
si_en Dev loss: 0.8859 r:0.5484
ne_en Dev loss: 0.5399 r:0.7125
ru_en Dev loss: 0.4292 r:0.7490
Current avg r:0.7005 Best avg r: 0.7428
04:00:56,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:02:01,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:03:07,100 root INFO Epoch 9 Global steps: 71500 Train loss: 0.1269
ro_en Dev loss: 0.3464 r:0.8207
et_en Dev loss: 0.4990 r:0.6610
si_en Dev loss: 0.8349 r:0.5423
ne_en Dev loss: 0.5263 r:0.7065
ru_en Dev loss: 0.4434 r:0.7370
Current avg r:0.6935 Best avg r: 0.7428
04:06:22,522 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:07:27,87 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:31,690 root INFO Epoch 9 Global steps: 72000 Train loss: 0.1247
ro_en Dev loss: 0.3121 r:0.8270
et_en Dev loss: 0.4591 r:0.6779
si_en Dev loss: 0.8348 r:0.5464
ne_en Dev loss: 0.5415 r:0.7164
ru_en Dev loss: 0.3973 r:0.7520
Current avg r:0.7039 Best avg r: 0.7428
04:11:44,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:12:49,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:13:54,106 root INFO Epoch 9 Global steps: 72500 Train loss: 0.1289
ro_en Dev loss: 0.3494 r:0.8236
et_en Dev loss: 0.4939 r:0.6697
si_en Dev loss: 0.8646 r:0.5409
ne_en Dev loss: 0.5309 r:0.7080
ru_en Dev loss: 0.4382 r:0.7445
Current avg r:0.6973 Best avg r: 0.7428
04:17:07,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:18:12,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:16,668 root INFO Epoch 9 Global steps: 73000 Train loss: 0.1270
ro_en Dev loss: 0.3173 r:0.8265
et_en Dev loss: 0.4675 r:0.6725
si_en Dev loss: 0.8736 r:0.5413
ne_en Dev loss: 0.5577 r:0.7004
ru_en Dev loss: 0.4251 r:0.7494
Current avg r:0.6980 Best avg r: 0.7428
04:22:29,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:23:34,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:24:39,88 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1352
ro_en Dev loss: 0.3316 r:0.8228
et_en Dev loss: 0.4832 r:0.6651
si_en Dev loss: 0.8618 r:0.5381
ne_en Dev loss: 0.5743 r:0.7015
ru_en Dev loss: 0.4594 r:0.7283
Current avg r:0.6912 Best avg r: 0.7428
04:27:54,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:28:59,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:04,687 root INFO Epoch 9 Global steps: 74000 Train loss: 0.1314
ro_en Dev loss: 0.3282 r:0.8241
et_en Dev loss: 0.4891 r:0.6641
si_en Dev loss: 0.8009 r:0.5468
ne_en Dev loss: 0.5281 r:0.7064
ru_en Dev loss: 0.4393 r:0.7379
Current avg r:0.6959 Best avg r: 0.7428
04:33:20,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:34:25,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:35:31,137 root INFO Epoch 9 Global steps: 74500 Train loss: 0.1233
ro_en Dev loss: 0.3884 r:0.8225
et_en Dev loss: 0.4649 r:0.6597
si_en Dev loss: 0.9955 r:0.5323
ne_en Dev loss: 0.6813 r:0.7015
ru_en Dev loss: 0.4597 r:0.7417
Current avg r:0.6915 Best avg r: 0.7428
04:38:47,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:39:52,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:40:57,324 root INFO Epoch 9 Global steps: 75000 Train loss: 0.1240
ro_en Dev loss: 0.3243 r:0.8222
et_en Dev loss: 0.4859 r:0.6692
si_en Dev loss: 0.8517 r:0.5355
ne_en Dev loss: 0.5436 r:0.7062
ru_en Dev loss: 0.4153 r:0.7420
Current avg r:0.6950 Best avg r: 0.7428
04:44:14,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:45:19,906 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:46:25,62 root INFO Epoch 10 Global steps: 75500 Train loss: 0.1103
ro_en Dev loss: 0.3287 r:0.8251
et_en Dev loss: 0.4727 r:0.6691
si_en Dev loss: 0.8838 r:0.5386
ne_en Dev loss: 0.5634 r:0.7063
ru_en Dev loss: 0.4249 r:0.7507
Current avg r:0.6980 Best avg r: 0.7428
04:49:40,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:45,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:50,253 root INFO Epoch 10 Global steps: 76000 Train loss: 0.1162
ro_en Dev loss: 0.3364 r:0.8210
et_en Dev loss: 0.4823 r:0.6754
si_en Dev loss: 0.8618 r:0.5420
ne_en Dev loss: 0.5574 r:0.7062
ru_en Dev loss: 0.4193 r:0.7519
Current avg r:0.6993 Best avg r: 0.7428
04:55:04,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:56:08,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:57:13,527 root INFO Epoch 10 Global steps: 76500 Train loss: 0.1173
ro_en Dev loss: 0.3364 r:0.8240
et_en Dev loss: 0.4663 r:0.6761
si_en Dev loss: 0.8656 r:0.5429
ne_en Dev loss: 0.5442 r:0.7094
ru_en Dev loss: 0.4484 r:0.7478
Current avg r:0.7000 Best avg r: 0.7428
05:00:27,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:01:32,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:02:36,657 root INFO Epoch 10 Global steps: 77000 Train loss: 0.1142
ro_en Dev loss: 0.3211 r:0.8258
et_en Dev loss: 0.4513 r:0.6715
si_en Dev loss: 0.9246 r:0.5406
ne_en Dev loss: 0.5912 r:0.7132
ru_en Dev loss: 0.4414 r:0.7385
Current avg r:0.6979 Best avg r: 0.7428
05:05:49,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:54,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:07:59,245 root INFO Epoch 10 Global steps: 77500 Train loss: 0.1200
ro_en Dev loss: 0.3338 r:0.8256
et_en Dev loss: 0.4931 r:0.6748
si_en Dev loss: 0.8593 r:0.5487
ne_en Dev loss: 0.5301 r:0.7135
ru_en Dev loss: 0.4237 r:0.7489
Current avg r:0.7023 Best avg r: 0.7428
05:11:15,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:12:20,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:13:25,802 root INFO Epoch 10 Global steps: 78000 Train loss: 0.1212
ro_en Dev loss: 0.3474 r:0.8273
et_en Dev loss: 0.4597 r:0.6695
si_en Dev loss: 0.8834 r:0.5450
ne_en Dev loss: 0.6153 r:0.7031
ru_en Dev loss: 0.4679 r:0.7377
Current avg r:0.6965 Best avg r: 0.7428
05:16:42,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:47,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:52,566 root INFO Epoch 10 Global steps: 78500 Train loss: 0.1125
ro_en Dev loss: 0.3218 r:0.8263
et_en Dev loss: 0.4712 r:0.6755
si_en Dev loss: 0.8550 r:0.5383
ne_en Dev loss: 0.5310 r:0.7014
ru_en Dev loss: 0.4382 r:0.7354
Current avg r:0.6954 Best avg r: 0.7428
05:22:08,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:23:13,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:24:18,427 root INFO Epoch 10 Global steps: 79000 Train loss: 0.1175
ro_en Dev loss: 0.3141 r:0.8258
et_en Dev loss: 0.4947 r:0.6803
si_en Dev loss: 0.7990 r:0.5489
ne_en Dev loss: 0.4925 r:0.7179
ru_en Dev loss: 0.3852 r:0.7557
Current avg r:0.7057 Best avg r: 0.7428
05:27:34,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:39,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:29:44,758 root INFO Epoch 10 Global steps: 79500 Train loss: 0.1218
ro_en Dev loss: 0.3323 r:0.8221
et_en Dev loss: 0.4527 r:0.6712
si_en Dev loss: 0.8855 r:0.5427
ne_en Dev loss: 0.5409 r:0.7188
ru_en Dev loss: 0.4050 r:0.7576
Current avg r:0.7025 Best avg r: 0.7428
05:32:59,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:34:04,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:35:08,766 root INFO Epoch 10 Global steps: 80000 Train loss: 0.1210
ro_en Dev loss: 0.3283 r:0.8252
et_en Dev loss: 0.4727 r:0.6686
si_en Dev loss: 0.8461 r:0.5407
ne_en Dev loss: 0.5090 r:0.7117
ru_en Dev loss: 0.4161 r:0.7490
Current avg r:0.6990 Best avg r: 0.7428
05:38:21,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:39:26,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:40:30,920 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1204
ro_en Dev loss: 0.3117 r:0.8279
et_en Dev loss: 0.4670 r:0.6585
si_en Dev loss: 0.7985 r:0.5494
ne_en Dev loss: 0.5250 r:0.7023
ru_en Dev loss: 0.4038 r:0.7533
Current avg r:0.6983 Best avg r: 0.7428
05:43:43,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:48,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:53,44 root INFO Epoch 10 Global steps: 81000 Train loss: 0.1142
ro_en Dev loss: 0.3592 r:0.8263
et_en Dev loss: 0.4698 r:0.6615
si_en Dev loss: 0.9773 r:0.5432
ne_en Dev loss: 0.6453 r:0.7003
ru_en Dev loss: 0.4957 r:0.7359
Current avg r:0.6934 Best avg r: 0.7428
05:49:05,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:50:10,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:51:15,454 root INFO Epoch 10 Global steps: 81500 Train loss: 0.1066
ro_en Dev loss: 0.3520 r:0.8263
et_en Dev loss: 0.4820 r:0.6693
si_en Dev loss: 0.8890 r:0.5487
ne_en Dev loss: 0.5866 r:0.7053
ru_en Dev loss: 0.4550 r:0.7418
Current avg r:0.6983 Best avg r: 0.7428
05:54:31,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:55:36,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:56:41,226 root INFO Epoch 10 Global steps: 82000 Train loss: 0.1115
ro_en Dev loss: 0.3547 r:0.8211
et_en Dev loss: 0.5096 r:0.6664
si_en Dev loss: 0.8679 r:0.5453
ne_en Dev loss: 0.5869 r:0.7045
ru_en Dev loss: 0.4495 r:0.7377
Current avg r:0.6950 Best avg r: 0.7428
05:59:56,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:01:01,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:02:06,979 root INFO Epoch 10 Global steps: 82500 Train loss: 0.1080
ro_en Dev loss: 0.3247 r:0.8242
et_en Dev loss: 0.4677 r:0.6686
si_en Dev loss: 0.8263 r:0.5450
ne_en Dev loss: 0.5450 r:0.7099
ru_en Dev loss: 0.4097 r:0.7492
Current avg r:0.6994 Best avg r: 0.7428
06:05:23,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:06:29,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:07:34,154 root INFO Epoch 11 Global steps: 83000 Train loss: 0.1020
ro_en Dev loss: 0.3499 r:0.8212
et_en Dev loss: 0.4839 r:0.6650
si_en Dev loss: 0.9319 r:0.5384
ne_en Dev loss: 0.6138 r:0.7102
ru_en Dev loss: 0.4736 r:0.7347
Current avg r:0.6939 Best avg r: 0.7428
06:10:49,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:54,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:13:00,74 root INFO Epoch 11 Global steps: 83500 Train loss: 0.1021
ro_en Dev loss: 0.3256 r:0.8252
et_en Dev loss: 0.4719 r:0.6715
si_en Dev loss: 0.8836 r:0.5352
ne_en Dev loss: 0.5852 r:0.7060
ru_en Dev loss: 0.4279 r:0.7443
Current avg r:0.6964 Best avg r: 0.7428
06:16:15,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:20,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:24,675 root INFO Epoch 11 Global steps: 84000 Train loss: 0.1004
ro_en Dev loss: 0.3743 r:0.8191
et_en Dev loss: 0.4612 r:0.6666
si_en Dev loss: 1.0100 r:0.5270
ne_en Dev loss: 0.6674 r:0.7004
ru_en Dev loss: 0.4609 r:0.7397
Current avg r:0.6906 Best avg r: 0.7428
06:21:38,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:22:43,438 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:48,136 root INFO Epoch 11 Global steps: 84500 Train loss: 0.0983
ro_en Dev loss: 0.3261 r:0.8236
et_en Dev loss: 0.4799 r:0.6767
si_en Dev loss: 0.8468 r:0.5385
ne_en Dev loss: 0.5547 r:0.6970
ru_en Dev loss: 0.4045 r:0.7524
Current avg r:0.6976 Best avg r: 0.7428
06:27:02,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:28:06,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:29:11,492 root INFO Epoch 11 Global steps: 85000 Train loss: 0.1027
ro_en Dev loss: 0.3195 r:0.8247
et_en Dev loss: 0.4544 r:0.6750
si_en Dev loss: 0.8345 r:0.5397
ne_en Dev loss: 0.5285 r:0.6933
ru_en Dev loss: 0.3953 r:0.7600
Current avg r:0.6985 Best avg r: 0.7428
06:32:24,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:33:29,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:34:33,582 root INFO Epoch 11 Global steps: 85500 Train loss: 0.0991
ro_en Dev loss: 0.3660 r:0.8192
et_en Dev loss: 0.4811 r:0.6660
si_en Dev loss: 0.9774 r:0.5291
ne_en Dev loss: 0.6313 r:0.6977
ru_en Dev loss: 0.4802 r:0.7329
Current avg r:0.6890 Best avg r: 0.7428
06:37:46,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:38:50,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:55,84 root INFO Epoch 11 Global steps: 86000 Train loss: 0.0972
ro_en Dev loss: 0.3313 r:0.8229
et_en Dev loss: 0.4886 r:0.6784
si_en Dev loss: 0.8569 r:0.5407
ne_en Dev loss: 0.5363 r:0.7030
ru_en Dev loss: 0.4214 r:0.7514
Current avg r:0.6993 Best avg r: 0.7428
06:43:08,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:44:12,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:17,79 root INFO Epoch 11 Global steps: 86500 Train loss: 0.1015
ro_en Dev loss: 0.3469 r:0.8215
et_en Dev loss: 0.4737 r:0.6802
si_en Dev loss: 0.9153 r:0.5354
ne_en Dev loss: 0.5688 r:0.6961
ru_en Dev loss: 0.4636 r:0.7413
Current avg r:0.6949 Best avg r: 0.7428
06:48:29,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:49:34,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:50:38,582 root INFO Epoch 11 Global steps: 87000 Train loss: 0.1011
ro_en Dev loss: 0.3364 r:0.8215
et_en Dev loss: 0.4487 r:0.6739
si_en Dev loss: 0.9443 r:0.5261
ne_en Dev loss: 0.6177 r:0.6935
ru_en Dev loss: 0.4405 r:0.7401
Current avg r:0.6910 Best avg r: 0.7428
06:53:51,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:55,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:00,486 root INFO Epoch 11 Global steps: 87500 Train loss: 0.1068
ro_en Dev loss: 0.3487 r:0.8202
et_en Dev loss: 0.4770 r:0.6812
si_en Dev loss: 0.8943 r:0.5330
ne_en Dev loss: 0.5667 r:0.6928
ru_en Dev loss: 0.4258 r:0.7482
Current avg r:0.6951 Best avg r: 0.7428
06:59:13,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:17,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:22,225 root INFO Epoch 11 Global steps: 88000 Train loss: 0.0970
ro_en Dev loss: 0.3341 r:0.8241
et_en Dev loss: 0.4669 r:0.6863
si_en Dev loss: 0.8551 r:0.5369
ne_en Dev loss: 0.5651 r:0.6934
ru_en Dev loss: 0.4261 r:0.7538
Current avg r:0.6989 Best avg r: 0.7428
07:04:34,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:05:39,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:06:43,946 root INFO Epoch 11 Global steps: 88500 Train loss: 0.1006
ro_en Dev loss: 0.3141 r:0.8252
et_en Dev loss: 0.4523 r:0.6835
si_en Dev loss: 0.8309 r:0.5370
ne_en Dev loss: 0.5370 r:0.6976
ru_en Dev loss: 0.3836 r:0.7623
Current avg r:0.7011 Best avg r: 0.7428
07:09:56,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:11:01,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:12:05,419 root INFO Epoch 11 Global steps: 89000 Train loss: 0.0939
ro_en Dev loss: 0.3175 r:0.8249
et_en Dev loss: 0.4557 r:0.6808
si_en Dev loss: 0.8485 r:0.5369
ne_en Dev loss: 0.5112 r:0.7019
ru_en Dev loss: 0.4401 r:0.7343
Current avg r:0.6957 Best avg r: 0.7428
07:15:17,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:16:22,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:26,679 root INFO Epoch 11 Global steps: 89500 Train loss: 0.1048
ro_en Dev loss: 0.3284 r:0.8264
et_en Dev loss: 0.4690 r:0.6769
si_en Dev loss: 0.8627 r:0.5437
ne_en Dev loss: 0.5686 r:0.7005
ru_en Dev loss: 0.4283 r:0.7500
Current avg r:0.6995 Best avg r: 0.7428
07:20:39,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:21:43,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:22:48,79 root INFO Epoch 11 Global steps: 90000 Train loss: 0.0974
ro_en Dev loss: 0.3434 r:0.8239
et_en Dev loss: 0.4706 r:0.6700
si_en Dev loss: 0.9375 r:0.5336
ne_en Dev loss: 0.6036 r:0.6969
ru_en Dev loss: 0.4524 r:0.7432
Current avg r:0.6935 Best avg r: 0.7428
07:26:01,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:27:06,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:28:10,585 root INFO Epoch 12 Global steps: 90500 Train loss: 0.0940
ro_en Dev loss: 0.3478 r:0.8256
et_en Dev loss: 0.4650 r:0.6699
si_en Dev loss: 0.8992 r:0.5365
ne_en Dev loss: 0.5918 r:0.7020
ru_en Dev loss: 0.4437 r:0.7488
Current avg r:0.6966 Best avg r: 0.7428
07:31:23,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:27,512 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:33:31,904 root INFO Epoch 12 Global steps: 91000 Train loss: 0.0920
ro_en Dev loss: 0.3562 r:0.8238
et_en Dev loss: 0.4719 r:0.6727
si_en Dev loss: 0.9247 r:0.5370
ne_en Dev loss: 0.5616 r:0.7012
ru_en Dev loss: 0.4478 r:0.7500
Current avg r:0.6969 Best avg r: 0.7428
07:36:44,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:37:48,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:38:53,449 root INFO Epoch 12 Global steps: 91500 Train loss: 0.0915
ro_en Dev loss: 0.3182 r:0.8262
et_en Dev loss: 0.4560 r:0.6754
si_en Dev loss: 0.8715 r:0.5320
ne_en Dev loss: 0.5421 r:0.6977
ru_en Dev loss: 0.4397 r:0.7424
Current avg r:0.6947 Best avg r: 0.7428
07:42:06,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:43:11,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:44:15,886 root INFO Epoch 12 Global steps: 92000 Train loss: 0.0911
ro_en Dev loss: 0.3270 r:0.8229
et_en Dev loss: 0.4719 r:0.6754
si_en Dev loss: 0.9035 r:0.5332
ne_en Dev loss: 0.5841 r:0.6979
ru_en Dev loss: 0.4185 r:0.7495
Current avg r:0.6958 Best avg r: 0.7428
07:47:29,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:33,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:49:38,153 root INFO Epoch 12 Global steps: 92500 Train loss: 0.0902
ro_en Dev loss: 0.3350 r:0.8246
et_en Dev loss: 0.4519 r:0.6700
si_en Dev loss: 0.9394 r:0.5331
ne_en Dev loss: 0.6060 r:0.6924
ru_en Dev loss: 0.4494 r:0.7411
Current avg r:0.6922 Best avg r: 0.7428
07:52:51,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:53:56,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:00,601 root INFO Epoch 12 Global steps: 93000 Train loss: 0.0914
ro_en Dev loss: 0.3530 r:0.8253
et_en Dev loss: 0.4751 r:0.6750
si_en Dev loss: 0.9565 r:0.5307
ne_en Dev loss: 0.5881 r:0.6983
ru_en Dev loss: 0.4649 r:0.7460
Current avg r:0.6951 Best avg r: 0.7428
07:58:13,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:59:18,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:00:23,4 root INFO Epoch 12 Global steps: 93500 Train loss: 0.0886
ro_en Dev loss: 0.3382 r:0.8227
et_en Dev loss: 0.4465 r:0.6790
si_en Dev loss: 0.9177 r:0.5359
ne_en Dev loss: 0.6247 r:0.6984
ru_en Dev loss: 0.4148 r:0.7601
Current avg r:0.6992 Best avg r: 0.7428
08:03:36,294 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:04:40,808 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:05:45,314 root INFO Epoch 12 Global steps: 94000 Train loss: 0.0886
ro_en Dev loss: 0.3345 r:0.8224
et_en Dev loss: 0.4551 r:0.6725
si_en Dev loss: 0.8890 r:0.5344
ne_en Dev loss: 0.5327 r:0.7083
ru_en Dev loss: 0.4241 r:0.7525
Current avg r:0.6980 Best avg r: 0.7428
08:08:58,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:10:03,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:11:07,580 root INFO Epoch 12 Global steps: 94500 Train loss: 0.0898
ro_en Dev loss: 0.3792 r:0.8193
et_en Dev loss: 0.4895 r:0.6620
si_en Dev loss: 1.0218 r:0.5191
ne_en Dev loss: 0.6667 r:0.6929
ru_en Dev loss: 0.4864 r:0.7331
Current avg r:0.6853 Best avg r: 0.7428
08:14:20,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:25,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:29,561 root INFO Epoch 12 Global steps: 95000 Train loss: 0.0921
ro_en Dev loss: 0.3329 r:0.8240
et_en Dev loss: 0.4440 r:0.6737
si_en Dev loss: 0.9699 r:0.5304
ne_en Dev loss: 0.6405 r:0.6976
ru_en Dev loss: 0.4353 r:0.7443
Current avg r:0.6940 Best avg r: 0.7428
08:19:42,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:20:46,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:21:51,384 root INFO Epoch 12 Global steps: 95500 Train loss: 0.0874
ro_en Dev loss: 0.3275 r:0.8240
et_en Dev loss: 0.4484 r:0.6759
si_en Dev loss: 0.9332 r:0.5324
ne_en Dev loss: 0.5625 r:0.7025
ru_en Dev loss: 0.4237 r:0.7484
Current avg r:0.6967 Best avg r: 0.7428
08:25:03,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:07,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:27:12,389 root INFO Epoch 12 Global steps: 96000 Train loss: 0.0866
ro_en Dev loss: 0.3432 r:0.8252
et_en Dev loss: 0.4667 r:0.6773
si_en Dev loss: 0.9261 r:0.5368
ne_en Dev loss: 0.5995 r:0.6990
ru_en Dev loss: 0.4425 r:0.7474
Current avg r:0.6971 Best avg r: 0.7428
08:30:25,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:31:29,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:32:34,157 root INFO Epoch 12 Global steps: 96500 Train loss: 0.0894
ro_en Dev loss: 0.3406 r:0.8247
et_en Dev loss: 0.4822 r:0.6758
si_en Dev loss: 0.8919 r:0.5359
ne_en Dev loss: 0.5965 r:0.7024
ru_en Dev loss: 0.4174 r:0.7536
Current avg r:0.6985 Best avg r: 0.7428
08:35:47,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:52,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:37:56,646 root INFO Epoch 12 Global steps: 97000 Train loss: 0.0880
ro_en Dev loss: 0.3418 r:0.8233
et_en Dev loss: 0.4798 r:0.6806
si_en Dev loss: 0.8991 r:0.5350
ne_en Dev loss: 0.5570 r:0.7069
ru_en Dev loss: 0.3998 r:0.7627
Current avg r:0.7017 Best avg r: 0.7428
08:41:09,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:14,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:18,664 root INFO Epoch 12 Global steps: 97500 Train loss: 0.0888
ro_en Dev loss: 0.3424 r:0.8220
et_en Dev loss: 0.4619 r:0.6770
si_en Dev loss: 0.8602 r:0.5437
ne_en Dev loss: 0.5584 r:0.7105
ru_en Dev loss: 0.4039 r:0.7604
Current avg r:0.7027 Best avg r: 0.7428
08:46:33,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:37,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:48:42,171 root INFO Epoch 13 Global steps: 98000 Train loss: 0.0803
ro_en Dev loss: 0.3196 r:0.8253
et_en Dev loss: 0.4377 r:0.6739
si_en Dev loss: 0.8779 r:0.5363
ne_en Dev loss: 0.5880 r:0.7043
ru_en Dev loss: 0.4101 r:0.7553
Current avg r:0.6990 Best avg r: 0.7428
08:51:55,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:52:59,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:04,499 root INFO Epoch 13 Global steps: 98500 Train loss: 0.0835
ro_en Dev loss: 0.3108 r:0.8248
et_en Dev loss: 0.4628 r:0.6751
si_en Dev loss: 0.8377 r:0.5376
ne_en Dev loss: 0.5397 r:0.7077
ru_en Dev loss: 0.3899 r:0.7558
Current avg r:0.7002 Best avg r: 0.7428
08:57:17,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:58:22,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:59:26,742 root INFO Epoch 13 Global steps: 99000 Train loss: 0.0798
ro_en Dev loss: 0.3127 r:0.8263
et_en Dev loss: 0.4554 r:0.6818
si_en Dev loss: 0.7964 r:0.5426
ne_en Dev loss: 0.5058 r:0.7118
ru_en Dev loss: 0.3941 r:0.7568
Current avg r:0.7039 Best avg r: 0.7428
09:02:39,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:03:43,752 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:04:48,200 root INFO Epoch 13 Global steps: 99500 Train loss: 0.0800
ro_en Dev loss: 0.3455 r:0.8258
et_en Dev loss: 0.4848 r:0.6730
si_en Dev loss: 0.8885 r:0.5443
ne_en Dev loss: 0.5945 r:0.6952
ru_en Dev loss: 0.4567 r:0.7468
Current avg r:0.6970 Best avg r: 0.7428
09:08:01,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:05,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:10,339 root INFO Epoch 13 Global steps: 100000 Train loss: 0.0823
ro_en Dev loss: 0.3222 r:0.8251
et_en Dev loss: 0.4627 r:0.6690
si_en Dev loss: 0.8748 r:0.5419
ne_en Dev loss: 0.5524 r:0.7030
ru_en Dev loss: 0.4185 r:0.7502
Current avg r:0.6979 Best avg r: 0.7428
09:13:23,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:14:28,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:15:32,599 root INFO Epoch 13 Global steps: 100500 Train loss: 0.0840
ro_en Dev loss: 0.3341 r:0.8244
et_en Dev loss: 0.4664 r:0.6783
si_en Dev loss: 0.8897 r:0.5327
ne_en Dev loss: 0.5583 r:0.6950
ru_en Dev loss: 0.4114 r:0.7582
Current avg r:0.6977 Best avg r: 0.7428
09:18:45,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:19:49,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:20:54,319 root INFO Epoch 13 Global steps: 101000 Train loss: 0.0793
ro_en Dev loss: 0.3282 r:0.8249
et_en Dev loss: 0.4591 r:0.6747
si_en Dev loss: 0.8898 r:0.5379
ne_en Dev loss: 0.5827 r:0.6936
ru_en Dev loss: 0.4249 r:0.7535
Current avg r:0.6969 Best avg r: 0.7428
09:24:07,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:11,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:16,65 root INFO Epoch 13 Global steps: 101500 Train loss: 0.0809
ro_en Dev loss: 0.3469 r:0.8241
et_en Dev loss: 0.4546 r:0.6725
si_en Dev loss: 0.9870 r:0.5337
ne_en Dev loss: 0.6457 r:0.6959
ru_en Dev loss: 0.4574 r:0.7450
Current avg r:0.6942 Best avg r: 0.7428
09:29:28,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:33,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:31:37,802 root INFO Epoch 13 Global steps: 102000 Train loss: 0.0831
ro_en Dev loss: 0.3298 r:0.8242
et_en Dev loss: 0.4739 r:0.6810
si_en Dev loss: 0.8604 r:0.5426
ne_en Dev loss: 0.5545 r:0.6968
ru_en Dev loss: 0.4155 r:0.7579
Current avg r:0.7005 Best avg r: 0.7428
09:34:50,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:54,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:59,112 root INFO Epoch 13 Global steps: 102500 Train loss: 0.0817
ro_en Dev loss: 0.3399 r:0.8239
et_en Dev loss: 0.4639 r:0.6752
si_en Dev loss: 0.8619 r:0.5423
ne_en Dev loss: 0.5717 r:0.6978
ru_en Dev loss: 0.4287 r:0.7501
Current avg r:0.6979 Best avg r: 0.7428
09:40:11,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:16,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:42:20,725 root INFO Epoch 13 Global steps: 103000 Train loss: 0.0828
ro_en Dev loss: 0.3373 r:0.8240
et_en Dev loss: 0.4403 r:0.6730
si_en Dev loss: 0.8728 r:0.5444
ne_en Dev loss: 0.6282 r:0.6985
ru_en Dev loss: 0.4236 r:0.7479
Current avg r:0.6976 Best avg r: 0.7428
09:45:33,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:46:51,249 root INFO 
id:ru_en cur r: 0.7751 best r: 0.7751
09:46:51,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:47:55,829 root INFO Epoch 13 Global steps: 103500 Train loss: 0.0802
ro_en Dev loss: 0.3086 r:0.8268
et_en Dev loss: 0.4458 r:0.6867
si_en Dev loss: 0.8213 r:0.5448
ne_en Dev loss: 0.5226 r:0.7099
ru_en Dev loss: 0.3586 r:0.7736
Current avg r:0.7083 Best avg r: 0.7428
09:51:09,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:52:13,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:53:18,290 root INFO Epoch 13 Global steps: 104000 Train loss: 0.0806
ro_en Dev loss: 0.3114 r:0.8280
et_en Dev loss: 0.4385 r:0.6863
si_en Dev loss: 0.8406 r:0.5448
ne_en Dev loss: 0.5589 r:0.6980
ru_en Dev loss: 0.3753 r:0.7722
Current avg r:0.7059 Best avg r: 0.7428
09:56:31,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:35,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:40,24 root INFO Epoch 13 Global steps: 104500 Train loss: 0.0797
ro_en Dev loss: 0.2975 r:0.8279
et_en Dev loss: 0.4442 r:0.6880
si_en Dev loss: 0.7860 r:0.5452
ne_en Dev loss: 0.5094 r:0.7015
ru_en Dev loss: 0.3751 r:0.7641
Current avg r:0.7054 Best avg r: 0.7428
10:01:52,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:57,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:04:01,761 root INFO Epoch 13 Global steps: 105000 Train loss: 0.0795
ro_en Dev loss: 0.3568 r:0.8226
et_en Dev loss: 0.4583 r:0.6733
si_en Dev loss: 0.8794 r:0.5354
ne_en Dev loss: 0.5976 r:0.6990
ru_en Dev loss: 0.4734 r:0.7372
Current avg r:0.6935 Best avg r: 0.7428
10:07:15,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:20,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:24,559 root INFO Epoch 14 Global steps: 105500 Train loss: 0.0732
ro_en Dev loss: 0.3384 r:0.8280
et_en Dev loss: 0.4516 r:0.6804
si_en Dev loss: 0.8347 r:0.5492
ne_en Dev loss: 0.5535 r:0.7114
ru_en Dev loss: 0.4362 r:0.7508
Current avg r:0.7039 Best avg r: 0.7428
10:12:37,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:41,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:46,130 root INFO Epoch 14 Global steps: 106000 Train loss: 0.0779
ro_en Dev loss: 0.3252 r:0.8291
et_en Dev loss: 0.4354 r:0.6792
si_en Dev loss: 0.8659 r:0.5476
ne_en Dev loss: 0.5618 r:0.7045
ru_en Dev loss: 0.4305 r:0.7534
Current avg r:0.7028 Best avg r: 0.7428
10:17:58,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:03,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:07,772 root INFO Epoch 14 Global steps: 106500 Train loss: 0.0721
ro_en Dev loss: 0.3440 r:0.8242
et_en Dev loss: 0.4713 r:0.6753
si_en Dev loss: 0.8832 r:0.5424
ne_en Dev loss: 0.5897 r:0.6998
ru_en Dev loss: 0.4298 r:0.7546
Current avg r:0.6993 Best avg r: 0.7428
10:23:20,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:24,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:25:29,284 root INFO Epoch 14 Global steps: 107000 Train loss: 0.0705
ro_en Dev loss: 0.3375 r:0.8257
et_en Dev loss: 0.4608 r:0.6745
si_en Dev loss: 0.9283 r:0.5383
ne_en Dev loss: 0.5976 r:0.6999
ru_en Dev loss: 0.4319 r:0.7556
Current avg r:0.6988 Best avg r: 0.7428
10:28:42,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:46,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:51,188 root INFO Epoch 14 Global steps: 107500 Train loss: 0.0771
ro_en Dev loss: 0.3168 r:0.8280
et_en Dev loss: 0.4370 r:0.6856
si_en Dev loss: 0.7805 r:0.5558
ne_en Dev loss: 0.4992 r:0.7034
ru_en Dev loss: 0.3980 r:0.7611
Current avg r:0.7068 Best avg r: 0.7428
10:34:03,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:35:08,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:36:12,678 root INFO Epoch 14 Global steps: 108000 Train loss: 0.0716
ro_en Dev loss: 0.3235 r:0.8237
et_en Dev loss: 0.4588 r:0.6779
si_en Dev loss: 0.8273 r:0.5494
ne_en Dev loss: 0.5243 r:0.7120
ru_en Dev loss: 0.4013 r:0.7573
Current avg r:0.7041 Best avg r: 0.7428
