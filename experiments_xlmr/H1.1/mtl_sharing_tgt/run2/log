14:36:39,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:05,171 root INFO 
id:ro_en cur r: 0.5767 best r: 0.5767
14:37:31,332 root INFO 
id:et_en cur r: 0.5430 best r: 0.5430
14:37:57,517 root INFO 
id:si_en cur r: 0.4550 best r: 0.4550
14:38:23,702 root INFO 
id:ne_en cur r: 0.3786 best r: 0.3786
14:38:49,706 root INFO 
id:ru_en cur r: 0.5325 best r: 0.5325
14:38:49,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:56,357 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:39:56,362 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
14:39:56,367 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
14:39:56,373 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:39:56,378 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:41:01,687 root INFO Epoch 0 Global steps: 500 Train loss: 0.8853
ro_en Dev loss: 0.6403 r:0.5896
et_en Dev loss: 0.6338 r:0.5488
si_en Dev loss: 0.6481 r:0.4553
ne_en Dev loss: 0.7314 r:0.5497
ru_en Dev loss: 0.7380 r:0.5002
Current avg r:0.5287 Best avg r: 0.5287
14:44:16,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:42,354 root INFO 
id:ro_en cur r: 0.6453 best r: 0.6453
14:45:08,553 root INFO 
id:et_en cur r: 0.5842 best r: 0.5842
14:45:47,867 root INFO 
id:ne_en cur r: 0.4021 best r: 0.4021
14:46:13,903 root INFO 
id:ru_en cur r: 0.5865 best r: 0.5865
14:46:13,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:19,267 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:47:19,279 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
14:47:19,285 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
14:47:19,291 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:47:19,296 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:48:24,644 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8270
ro_en Dev loss: 0.5693 r:0.6458
et_en Dev loss: 0.4985 r:0.5782
si_en Dev loss: 0.7285 r:0.4697
ne_en Dev loss: 0.5648 r:0.5646
ru_en Dev loss: 0.5388 r:0.6569
Current avg r:0.5831 Best avg r: 0.5831
14:51:39,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:05,284 root INFO 
id:ro_en cur r: 0.6521 best r: 0.6521
14:52:31,472 root INFO 
id:et_en cur r: 0.5914 best r: 0.5914
14:53:10,766 root INFO 
id:ne_en cur r: 0.4376 best r: 0.4376
14:53:23,772 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:29,108 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:54:29,115 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
14:54:29,119 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
14:54:29,124 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:54:29,129 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:55:34,494 root INFO Epoch 0 Global steps: 1500 Train loss: 0.7273
ro_en Dev loss: 0.5604 r:0.6613
et_en Dev loss: 0.4921 r:0.5769
si_en Dev loss: 0.7650 r:0.4665
ne_en Dev loss: 0.5662 r:0.5766
ru_en Dev loss: 0.5546 r:0.6713
Current avg r:0.5905 Best avg r: 0.5905
14:58:49,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:15,251 root INFO 
id:ro_en cur r: 0.6880 best r: 0.6880
14:59:41,427 root INFO 
id:et_en cur r: 0.6503 best r: 0.6503
15:00:07,624 root INFO 
id:si_en cur r: 0.4962 best r: 0.4962
15:00:33,824 root INFO 
id:ne_en cur r: 0.5933 best r: 0.5933
15:00:59,837 root INFO 
id:ru_en cur r: 0.6664 best r: 0.6664
15:00:59,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:05,160 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:02:05,167 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
15:02:05,172 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
15:02:05,176 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:02:05,181 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:03:10,539 root INFO Epoch 0 Global steps: 2000 Train loss: 0.6876
ro_en Dev loss: 0.4972 r:0.6985
et_en Dev loss: 0.4188 r:0.6559
si_en Dev loss: 0.6986 r:0.5317
ne_en Dev loss: 0.5445 r:0.6361
ru_en Dev loss: 0.5294 r:0.7023
Current avg r:0.6449 Best avg r: 0.6449
15:06:25,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:04,314 root INFO 
id:et_en cur r: 0.6629 best r: 0.6629
15:07:30,509 root INFO 
id:si_en cur r: 0.5065 best r: 0.5065
15:07:56,698 root INFO 
id:ne_en cur r: 0.6584 best r: 0.6584
15:08:22,726 root INFO 
id:ru_en cur r: 0.6961 best r: 0.6961
15:08:22,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:28,61 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:09:28,68 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
15:09:28,73 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
15:09:28,78 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:09:28,83 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:10:33,463 root INFO Epoch 0 Global steps: 2500 Train loss: 0.6790
ro_en Dev loss: 0.4275 r:0.7115
et_en Dev loss: 0.4039 r:0.6645
si_en Dev loss: 0.6058 r:0.5405
ne_en Dev loss: 0.4541 r:0.6707
ru_en Dev loss: 0.4343 r:0.7197
Current avg r:0.6614 Best avg r: 0.6614
15:13:48,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:14,209 root INFO 
id:ro_en cur r: 0.7138 best r: 0.7138
15:15:06,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:11,782 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6310
ro_en Dev loss: 0.4794 r:0.7283
et_en Dev loss: 0.4134 r:0.6560
si_en Dev loss: 0.8352 r:0.5098
ne_en Dev loss: 0.5752 r:0.6262
ru_en Dev loss: 0.5497 r:0.7114
Current avg r:0.6463 Best avg r: 0.6614
15:19:26,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:52,472 root INFO 
id:ro_en cur r: 0.7286 best r: 0.7286
15:20:44,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:50,16 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6003
ro_en Dev loss: 0.4548 r:0.7395
et_en Dev loss: 0.4078 r:0.6601
si_en Dev loss: 0.7822 r:0.5208
ne_en Dev loss: 0.4991 r:0.6502
ru_en Dev loss: 0.5167 r:0.7121
Current avg r:0.6565 Best avg r: 0.6614
15:25:04,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:30,730 root INFO 
id:ro_en cur r: 0.7552 best r: 0.7552
15:25:56,901 root INFO 
id:et_en cur r: 0.6773 best r: 0.6773
15:26:23,91 root INFO 
id:si_en cur r: 0.5268 best r: 0.5268
15:26:49,274 root INFO 
id:ne_en cur r: 0.6722 best r: 0.6722
15:27:15,276 root INFO 
id:ru_en cur r: 0.7000 best r: 0.7000
15:27:15,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:20,576 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:28:20,582 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
15:28:20,592 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
15:28:20,597 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:28:20,602 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:29:25,946 root INFO Epoch 0 Global steps: 4000 Train loss: 0.5975
ro_en Dev loss: 0.4069 r:0.7671
et_en Dev loss: 0.3861 r:0.6827
si_en Dev loss: 0.7168 r:0.5526
ne_en Dev loss: 0.4579 r:0.6913
ru_en Dev loss: 0.5135 r:0.7205
Current avg r:0.6828 Best avg r: 0.6828
15:32:40,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:06,788 root INFO 
id:ro_en cur r: 0.7611 best r: 0.7611
15:33:32,969 root INFO 
id:et_en cur r: 0.6802 best r: 0.6802
15:34:12,258 root INFO 
id:ne_en cur r: 0.6805 best r: 0.6805
15:34:38,268 root INFO 
id:ru_en cur r: 0.7070 best r: 0.7070
15:34:38,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:43,596 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:35:43,605 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
15:35:43,613 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
15:35:43,622 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:35:43,631 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:36:48,986 root INFO Epoch 0 Global steps: 4500 Train loss: 0.5591
ro_en Dev loss: 0.3670 r:0.7734
et_en Dev loss: 0.3752 r:0.6875
si_en Dev loss: 0.6576 r:0.5493
ne_en Dev loss: 0.4135 r:0.6986
ru_en Dev loss: 0.4638 r:0.7314
Current avg r:0.6880 Best avg r: 0.6880
15:40:03,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:29,843 root INFO 
id:ro_en cur r: 0.7701 best r: 0.7701
15:40:56,19 root INFO 
id:et_en cur r: 0.6864 best r: 0.6864
15:41:22,235 root INFO 
id:si_en cur r: 0.5519 best r: 0.5519
15:41:48,432 root INFO 
id:ne_en cur r: 0.7095 best r: 0.7095
15:42:14,467 root INFO 
id:ru_en cur r: 0.7189 best r: 0.7189
15:42:14,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:19,810 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:43:19,816 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
15:43:19,821 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
15:43:19,825 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:43:19,830 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:44:25,211 root INFO Epoch 0 Global steps: 5000 Train loss: 0.5901
ro_en Dev loss: 0.3494 r:0.7790
et_en Dev loss: 0.3674 r:0.6937
si_en Dev loss: 0.5916 r:0.5736
ne_en Dev loss: 0.4130 r:0.7104
ru_en Dev loss: 0.4258 r:0.7380
Current avg r:0.6989 Best avg r: 0.6989
15:47:39,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:06,85 root INFO 
id:ro_en cur r: 0.7818 best r: 0.7818
15:48:32,268 root INFO 
id:et_en cur r: 0.6884 best r: 0.6884
15:48:58,480 root INFO 
id:si_en cur r: 0.5555 best r: 0.5555
15:49:24,690 root INFO 
id:ne_en cur r: 0.7304 best r: 0.7304
15:49:50,714 root INFO 
id:ru_en cur r: 0.7406 best r: 0.7406
15:49:50,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:56,87 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:50:56,94 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
15:50:56,99 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
15:50:56,104 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:50:56,108 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:52:01,509 root INFO Epoch 0 Global steps: 5500 Train loss: 0.5453
ro_en Dev loss: 0.3497 r:0.7902
et_en Dev loss: 0.3722 r:0.6982
si_en Dev loss: 0.6823 r:0.5774
ne_en Dev loss: 0.4230 r:0.7257
ru_en Dev loss: 0.4652 r:0.7455
Current avg r:0.7074 Best avg r: 0.7074
15:55:16,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:21,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:26,828 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5276
ro_en Dev loss: 0.3664 r:0.7837
et_en Dev loss: 0.3859 r:0.6885
si_en Dev loss: 0.6945 r:0.5687
ne_en Dev loss: 0.4567 r:0.7176
ru_en Dev loss: 0.5431 r:0.7224
Current avg r:0.6962 Best avg r: 0.7074
16:00:41,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:46,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:51,933 root INFO Epoch 0 Global steps: 6500 Train loss: 0.5045
ro_en Dev loss: 0.3464 r:0.7860
et_en Dev loss: 0.3680 r:0.6959
si_en Dev loss: 0.6604 r:0.5738
ne_en Dev loss: 0.4180 r:0.7221
ru_en Dev loss: 0.4633 r:0.7369
Current avg r:0.7029 Best avg r: 0.7074
16:06:06,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:32,564 root INFO 
id:ro_en cur r: 0.7910 best r: 0.7910
16:06:58,731 root INFO 
id:et_en cur r: 0.7001 best r: 0.7001
16:07:24,914 root INFO 
id:si_en cur r: 0.5565 best r: 0.5565
16:07:51,93 root INFO 
id:ne_en cur r: 0.7358 best r: 0.7358
16:08:04,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:09,389 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:09:09,395 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
16:09:09,401 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
16:09:09,408 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:09:09,414 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:10:14,753 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5178
ro_en Dev loss: 0.3468 r:0.7993
et_en Dev loss: 0.3569 r:0.7087
si_en Dev loss: 0.6541 r:0.5809
ne_en Dev loss: 0.3849 r:0.7372
ru_en Dev loss: 0.4521 r:0.7448
Current avg r:0.7142 Best avg r: 0.7142
16:13:29,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:55,410 root INFO 
id:ro_en cur r: 0.7943 best r: 0.7943
16:14:34,677 root INFO 
id:si_en cur r: 0.5603 best r: 0.5603
16:15:00,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:06,56 root INFO Epoch 0 Global steps: 7500 Train loss: 0.5313
ro_en Dev loss: 0.3311 r:0.7991
et_en Dev loss: 0.3649 r:0.7038
si_en Dev loss: 0.6384 r:0.5820
ne_en Dev loss: 0.3804 r:0.7356
ru_en Dev loss: 0.4349 r:0.7434
Current avg r:0.7128 Best avg r: 0.7142
16:19:21,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:28,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:33,904 root INFO Epoch 1 Global steps: 8000 Train loss: 0.4846
ro_en Dev loss: 0.4100 r:0.7909
et_en Dev loss: 0.4305 r:0.6782
si_en Dev loss: 0.8250 r:0.5522
ne_en Dev loss: 0.5883 r:0.6987
ru_en Dev loss: 0.6117 r:0.7089
Current avg r:0.6858 Best avg r: 0.7142
16:24:48,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:14,906 root INFO 
id:ro_en cur r: 0.8016 best r: 0.8016
16:25:54,177 root INFO 
id:si_en cur r: 0.5651 best r: 0.5651
16:26:20,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:25,631 root INFO Epoch 1 Global steps: 8500 Train loss: 0.4920
ro_en Dev loss: 0.3427 r:0.8049
et_en Dev loss: 0.3828 r:0.6965
si_en Dev loss: 0.7035 r:0.5804
ne_en Dev loss: 0.5150 r:0.7276
ru_en Dev loss: 0.5118 r:0.7292
Current avg r:0.7077 Best avg r: 0.7142
16:30:40,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:32,759 root INFO 
id:si_en cur r: 0.5677 best r: 0.5677
16:31:58,960 root INFO 
id:ne_en cur r: 0.7413 best r: 0.7413
16:32:11,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:17,343 root INFO Epoch 1 Global steps: 9000 Train loss: 0.4898
ro_en Dev loss: 0.3390 r:0.8062
et_en Dev loss: 0.3747 r:0.7014
si_en Dev loss: 0.7715 r:0.5764
ne_en Dev loss: 0.4295 r:0.7390
ru_en Dev loss: 0.4633 r:0.7476
Current avg r:0.7141 Best avg r: 0.7142
16:36:32,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:58,278 root INFO 
id:ro_en cur r: 0.8068 best r: 0.8068
16:37:24,480 root INFO 
id:et_en cur r: 0.7032 best r: 0.7032
16:37:50,692 root INFO 
id:si_en cur r: 0.5789 best r: 0.5789
16:38:16,917 root INFO 
id:ne_en cur r: 0.7553 best r: 0.7553
16:38:29,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:35,312 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:39:35,320 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
16:39:35,326 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
16:39:35,330 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:39:35,336 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:40:40,787 root INFO Epoch 1 Global steps: 9500 Train loss: 0.4706
ro_en Dev loss: 0.3218 r:0.8123
et_en Dev loss: 0.3581 r:0.7074
si_en Dev loss: 0.6624 r:0.5836
ne_en Dev loss: 0.4060 r:0.7471
ru_en Dev loss: 0.4254 r:0.7467
Current avg r:0.7194 Best avg r: 0.7194
16:43:55,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:21,613 root INFO 
id:ro_en cur r: 0.8125 best r: 0.8125
16:45:00,922 root INFO 
id:si_en cur r: 0.5938 best r: 0.5938
16:45:27,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:32,404 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:46:32,413 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
16:46:32,418 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
16:46:32,424 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:46:32,429 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:47:37,825 root INFO Epoch 1 Global steps: 10000 Train loss: 0.4768
ro_en Dev loss: 0.3143 r:0.8165
et_en Dev loss: 0.3551 r:0.7072
si_en Dev loss: 0.6039 r:0.6024
ne_en Dev loss: 0.4007 r:0.7521
ru_en Dev loss: 0.5036 r:0.7324
Current avg r:0.7221 Best avg r: 0.7221
16:50:52,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:57,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:02,822 root INFO Epoch 1 Global steps: 10500 Train loss: 0.4713
ro_en Dev loss: 0.3540 r:0.8105
et_en Dev loss: 0.3652 r:0.7041
si_en Dev loss: 0.6837 r:0.5889
ne_en Dev loss: 0.4219 r:0.7467
ru_en Dev loss: 0.4906 r:0.7419
Current avg r:0.7184 Best avg r: 0.7221
16:56:17,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:43,239 root INFO 
id:ro_en cur r: 0.8181 best r: 0.8181
16:57:22,482 root INFO 
id:si_en cur r: 0.6105 best r: 0.6105
16:57:48,649 root INFO 
id:ne_en cur r: 0.7636 best r: 0.7636
16:58:01,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:06,884 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:59:06,890 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
16:59:06,897 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
16:59:06,902 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:59:06,907 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:00:12,197 root INFO Epoch 1 Global steps: 11000 Train loss: 0.4800
ro_en Dev loss: 0.3078 r:0.8176
et_en Dev loss: 0.3662 r:0.7068
si_en Dev loss: 0.6210 r:0.6025
ne_en Dev loss: 0.4051 r:0.7575
ru_en Dev loss: 0.4363 r:0.7470
Current avg r:0.7263 Best avg r: 0.7263
17:03:26,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:44,708 root INFO 
id:ru_en cur r: 0.7465 best r: 0.7465
17:04:44,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:49,942 root INFO Epoch 1 Global steps: 11500 Train loss: 0.4735
ro_en Dev loss: 0.3276 r:0.8108
et_en Dev loss: 0.3669 r:0.7023
si_en Dev loss: 0.6228 r:0.5997
ne_en Dev loss: 0.3879 r:0.7543
ru_en Dev loss: 0.4281 r:0.7519
Current avg r:0.7238 Best avg r: 0.7263
17:09:04,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:09,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:14,708 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4491
ro_en Dev loss: 0.3801 r:0.8085
et_en Dev loss: 0.3869 r:0.7017
si_en Dev loss: 0.7185 r:0.5943
ne_en Dev loss: 0.3891 r:0.7606
ru_en Dev loss: 0.5053 r:0.7398
Current avg r:0.7210 Best avg r: 0.7263
17:14:28,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:34,305 root INFO 
id:ne_en cur r: 0.7641 best r: 0.7641
17:15:47,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:52,536 root INFO Epoch 1 Global steps: 12500 Train loss: 0.4484
ro_en Dev loss: 0.4071 r:0.8101
et_en Dev loss: 0.4044 r:0.7039
si_en Dev loss: 0.8396 r:0.5864
ne_en Dev loss: 0.5339 r:0.7534
ru_en Dev loss: 0.5469 r:0.7367
Current avg r:0.7181 Best avg r: 0.7263
17:20:06,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:12,114 root INFO 
id:ne_en cur r: 0.7667 best r: 0.7667
17:21:25,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:30,357 root INFO Epoch 1 Global steps: 13000 Train loss: 0.4339
ro_en Dev loss: 0.3585 r:0.8139
et_en Dev loss: 0.3774 r:0.7067
si_en Dev loss: 0.7149 r:0.5966
ne_en Dev loss: 0.4252 r:0.7556
ru_en Dev loss: 0.4948 r:0.7450
Current avg r:0.7236 Best avg r: 0.7263
17:25:44,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:10,666 root INFO 
id:ro_en cur r: 0.8181 best r: 0.8181
17:26:36,803 root INFO 
id:et_en cur r: 0.7086 best r: 0.7086
17:27:16,19 root INFO 
id:ne_en cur r: 0.7722 best r: 0.7722
17:27:41,994 root INFO 
id:ru_en cur r: 0.7665 best r: 0.7665
17:27:41,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:47,214 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:28:47,221 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
17:28:47,226 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
17:28:47,231 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:28:47,236 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:29:52,483 root INFO Epoch 1 Global steps: 13500 Train loss: 0.4498
ro_en Dev loss: 0.3412 r:0.8157
et_en Dev loss: 0.3705 r:0.7075
si_en Dev loss: 0.6816 r:0.6011
ne_en Dev loss: 0.3621 r:0.7618
ru_en Dev loss: 0.4243 r:0.7656
Current avg r:0.7303 Best avg r: 0.7303
17:33:06,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:32,799 root INFO 
id:ro_en cur r: 0.8210 best r: 0.8210
17:34:24,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:30,205 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4592
ro_en Dev loss: 0.3394 r:0.8190
et_en Dev loss: 0.3820 r:0.7043
si_en Dev loss: 0.7255 r:0.6000
ne_en Dev loss: 0.4322 r:0.7612
ru_en Dev loss: 0.4570 r:0.7550
Current avg r:0.7279 Best avg r: 0.7303
17:38:44,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:10,504 root INFO 
id:ro_en cur r: 0.8269 best r: 0.8269
17:39:36,639 root INFO 
id:et_en cur r: 0.7160 best r: 0.7160
17:40:02,796 root INFO 
id:si_en cur r: 0.6181 best r: 0.6181
17:40:28,946 root INFO 
id:ne_en cur r: 0.7800 best r: 0.7800
17:40:54,914 root INFO 
id:ru_en cur r: 0.7786 best r: 0.7786
17:40:54,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:00,148 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:42:00,155 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
17:42:00,160 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
17:42:00,165 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:42:00,170 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:43:05,434 root INFO Epoch 1 Global steps: 14500 Train loss: 0.4308
ro_en Dev loss: 0.2964 r:0.8242
et_en Dev loss: 0.3536 r:0.7177
si_en Dev loss: 0.6098 r:0.6192
ne_en Dev loss: 0.3315 r:0.7743
ru_en Dev loss: 0.3454 r:0.7798
Current avg r:0.7430 Best avg r: 0.7430
17:46:19,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:24,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:30,82 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4309
ro_en Dev loss: 0.4079 r:0.8113
et_en Dev loss: 0.4162 r:0.6989
si_en Dev loss: 0.7930 r:0.5974
ne_en Dev loss: 0.4685 r:0.7594
ru_en Dev loss: 0.5246 r:0.7515
Current avg r:0.7237 Best avg r: 0.7430
17:51:45,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:50,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:55,768 root INFO Epoch 2 Global steps: 15500 Train loss: 0.4086
ro_en Dev loss: 0.3264 r:0.8193
et_en Dev loss: 0.3802 r:0.7088
si_en Dev loss: 0.7028 r:0.6060
ne_en Dev loss: 0.3346 r:0.7719
ru_en Dev loss: 0.3851 r:0.7763
Current avg r:0.7364 Best avg r: 0.7430
17:57:10,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:15,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:20,485 root INFO Epoch 2 Global steps: 16000 Train loss: 0.3953
ro_en Dev loss: 0.3127 r:0.8205
et_en Dev loss: 0.3626 r:0.7049
si_en Dev loss: 0.7393 r:0.6010
ne_en Dev loss: 0.4432 r:0.7646
ru_en Dev loss: 0.4227 r:0.7557
Current avg r:0.7293 Best avg r: 0.7430
18:02:36,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:41,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:46,450 root INFO Epoch 2 Global steps: 16500 Train loss: 0.3986
ro_en Dev loss: 0.3205 r:0.8170
et_en Dev loss: 0.3666 r:0.7103
si_en Dev loss: 0.7015 r:0.6060
ne_en Dev loss: 0.3880 r:0.7674
ru_en Dev loss: 0.4220 r:0.7610
Current avg r:0.7323 Best avg r: 0.7430
18:08:00,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:05,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:11,96 root INFO Epoch 2 Global steps: 17000 Train loss: 0.4038
ro_en Dev loss: 0.4093 r:0.8086
et_en Dev loss: 0.4065 r:0.6983
si_en Dev loss: 0.8365 r:0.5946
ne_en Dev loss: 0.4990 r:0.7625
ru_en Dev loss: 0.5200 r:0.7400
Current avg r:0.7208 Best avg r: 0.7430
18:13:25,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:30,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:35,753 root INFO Epoch 2 Global steps: 17500 Train loss: 0.3950
ro_en Dev loss: 0.3384 r:0.8144
et_en Dev loss: 0.3836 r:0.7050
si_en Dev loss: 0.6767 r:0.6057
ne_en Dev loss: 0.3822 r:0.7594
ru_en Dev loss: 0.4398 r:0.7436
Current avg r:0.7256 Best avg r: 0.7430
18:18:50,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:55,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:00,477 root INFO Epoch 2 Global steps: 18000 Train loss: 0.3961
ro_en Dev loss: 0.3419 r:0.8174
et_en Dev loss: 0.3852 r:0.7038
si_en Dev loss: 0.7021 r:0.6062
ne_en Dev loss: 0.4168 r:0.7655
ru_en Dev loss: 0.4659 r:0.7422
Current avg r:0.7270 Best avg r: 0.7430
18:24:14,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:20,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:25,283 root INFO Epoch 2 Global steps: 18500 Train loss: 0.3801
ro_en Dev loss: 0.3223 r:0.8174
et_en Dev loss: 0.3847 r:0.7039
si_en Dev loss: 0.6309 r:0.6099
ne_en Dev loss: 0.3670 r:0.7655
ru_en Dev loss: 0.4296 r:0.7485
Current avg r:0.7291 Best avg r: 0.7430
18:29:39,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:44,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:50,75 root INFO Epoch 2 Global steps: 19000 Train loss: 0.3965
ro_en Dev loss: 0.3263 r:0.8194
et_en Dev loss: 0.3800 r:0.7033
si_en Dev loss: 0.6503 r:0.6082
ne_en Dev loss: 0.3684 r:0.7726
ru_en Dev loss: 0.4350 r:0.7547
Current avg r:0.7316 Best avg r: 0.7430
18:35:04,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:09,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:14,996 root INFO Epoch 2 Global steps: 19500 Train loss: 0.3775
ro_en Dev loss: 0.3099 r:0.8182
et_en Dev loss: 0.3680 r:0.7006
si_en Dev loss: 0.7211 r:0.5979
ne_en Dev loss: 0.4280 r:0.7630
ru_en Dev loss: 0.3977 r:0.7594
Current avg r:0.7278 Best avg r: 0.7430
18:40:29,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:34,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:39,900 root INFO Epoch 2 Global steps: 20000 Train loss: 0.3924
ro_en Dev loss: 0.3408 r:0.8152
et_en Dev loss: 0.3782 r:0.7006
si_en Dev loss: 0.7756 r:0.5952
ne_en Dev loss: 0.4187 r:0.7692
ru_en Dev loss: 0.4115 r:0.7596
Current avg r:0.7280 Best avg r: 0.7430
18:45:54,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:59,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:04,669 root INFO Epoch 2 Global steps: 20500 Train loss: 0.3737
ro_en Dev loss: 0.3894 r:0.8110
et_en Dev loss: 0.4057 r:0.6877
si_en Dev loss: 0.7848 r:0.5936
ne_en Dev loss: 0.4978 r:0.7631
ru_en Dev loss: 0.5447 r:0.7276
Current avg r:0.7166 Best avg r: 0.7430
18:51:24,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:29,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:34,998 root INFO Epoch 2 Global steps: 21000 Train loss: 0.3901
ro_en Dev loss: 0.3715 r:0.8105
et_en Dev loss: 0.3845 r:0.6942
si_en Dev loss: 0.7142 r:0.6015
ne_en Dev loss: 0.4437 r:0.7644
ru_en Dev loss: 0.4773 r:0.7407
Current avg r:0.7223 Best avg r: 0.7430
18:56:56,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:02,174 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:07,424 root INFO Epoch 2 Global steps: 21500 Train loss: 0.3626
ro_en Dev loss: 0.3708 r:0.8110
et_en Dev loss: 0.4248 r:0.6966
si_en Dev loss: 0.6975 r:0.6052
ne_en Dev loss: 0.4200 r:0.7612
ru_en Dev loss: 0.5153 r:0.7357
Current avg r:0.7220 Best avg r: 0.7430
19:02:29,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:34,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:39,853 root INFO Epoch 2 Global steps: 22000 Train loss: 0.3825
ro_en Dev loss: 0.3822 r:0.8099
et_en Dev loss: 0.4065 r:0.6882
si_en Dev loss: 0.8107 r:0.5991
ne_en Dev loss: 0.5052 r:0.7636
ru_en Dev loss: 0.5729 r:0.7163
Current avg r:0.7154 Best avg r: 0.7430
19:08:01,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:06,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:12,340 root INFO Epoch 2 Global steps: 22500 Train loss: 0.3831
ro_en Dev loss: 0.3269 r:0.8173
et_en Dev loss: 0.3894 r:0.7010
si_en Dev loss: 0.6951 r:0.6101
ne_en Dev loss: 0.4245 r:0.7686
ru_en Dev loss: 0.4062 r:0.7615
Current avg r:0.7317 Best avg r: 0.7430
19:13:27,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:33,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:38,348 root INFO Epoch 3 Global steps: 23000 Train loss: 0.3362
ro_en Dev loss: 0.3408 r:0.8171
et_en Dev loss: 0.3997 r:0.6951
si_en Dev loss: 0.7651 r:0.5996
ne_en Dev loss: 0.4252 r:0.7641
ru_en Dev loss: 0.4606 r:0.7405
Current avg r:0.7233 Best avg r: 0.7430
19:18:52,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:58,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:03,338 root INFO Epoch 3 Global steps: 23500 Train loss: 0.3460
ro_en Dev loss: 0.3801 r:0.8151
et_en Dev loss: 0.4088 r:0.6991
si_en Dev loss: 0.8033 r:0.6110
ne_en Dev loss: 0.4269 r:0.7663
ru_en Dev loss: 0.5806 r:0.7264
Current avg r:0.7236 Best avg r: 0.7430
19:24:17,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:22,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:28,84 root INFO Epoch 3 Global steps: 24000 Train loss: 0.3341
ro_en Dev loss: 0.3747 r:0.8150
et_en Dev loss: 0.4186 r:0.6877
si_en Dev loss: 0.8285 r:0.5965
ne_en Dev loss: 0.4775 r:0.7629
ru_en Dev loss: 0.5058 r:0.7331
Current avg r:0.7190 Best avg r: 0.7430
19:29:42,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:47,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:52,788 root INFO Epoch 3 Global steps: 24500 Train loss: 0.3500
ro_en Dev loss: 0.3342 r:0.8157
et_en Dev loss: 0.4079 r:0.6894
si_en Dev loss: 0.7197 r:0.6026
ne_en Dev loss: 0.4033 r:0.7637
ru_en Dev loss: 0.4657 r:0.7344
Current avg r:0.7212 Best avg r: 0.7430
19:35:07,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:12,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:17,509 root INFO Epoch 3 Global steps: 25000 Train loss: 0.3349
ro_en Dev loss: 0.3661 r:0.8069
et_en Dev loss: 0.4141 r:0.6912
si_en Dev loss: 0.7693 r:0.5916
ne_en Dev loss: 0.4954 r:0.7466
ru_en Dev loss: 0.5075 r:0.7228
Current avg r:0.7118 Best avg r: 0.7430
19:40:31,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:37,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:42,296 root INFO Epoch 3 Global steps: 25500 Train loss: 0.3513
ro_en Dev loss: 0.3513 r:0.8069
et_en Dev loss: 0.4027 r:0.6958
si_en Dev loss: 0.7438 r:0.5968
ne_en Dev loss: 0.4824 r:0.7533
ru_en Dev loss: 0.4534 r:0.7247
Current avg r:0.7155 Best avg r: 0.7430
19:45:56,602 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:01,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:07,74 root INFO Epoch 3 Global steps: 26000 Train loss: 0.3513
ro_en Dev loss: 0.3216 r:0.8146
et_en Dev loss: 0.3847 r:0.7051
si_en Dev loss: 0.6079 r:0.6092
ne_en Dev loss: 0.3785 r:0.7573
ru_en Dev loss: 0.4444 r:0.7137
Current avg r:0.7200 Best avg r: 0.7430
19:51:21,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:26,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:31,843 root INFO Epoch 3 Global steps: 26500 Train loss: 0.3268
ro_en Dev loss: 0.3507 r:0.8137
et_en Dev loss: 0.3895 r:0.6962
si_en Dev loss: 0.7558 r:0.5984
ne_en Dev loss: 0.4678 r:0.7573
ru_en Dev loss: 0.4415 r:0.7386
Current avg r:0.7208 Best avg r: 0.7430
19:56:46,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:51,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:56,685 root INFO Epoch 3 Global steps: 27000 Train loss: 0.3511
ro_en Dev loss: 0.3406 r:0.8109
et_en Dev loss: 0.3983 r:0.6888
si_en Dev loss: 0.7186 r:0.5926
ne_en Dev loss: 0.4053 r:0.7507
ru_en Dev loss: 0.5252 r:0.6912
Current avg r:0.7069 Best avg r: 0.7430
20:02:11,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:16,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:21,481 root INFO Epoch 3 Global steps: 27500 Train loss: 0.3402
ro_en Dev loss: 0.3294 r:0.8154
et_en Dev loss: 0.3876 r:0.6976
si_en Dev loss: 0.7175 r:0.5978
ne_en Dev loss: 0.4127 r:0.7512
ru_en Dev loss: 0.4436 r:0.7292
Current avg r:0.7182 Best avg r: 0.7430
20:07:35,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:41,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:46,227 root INFO Epoch 3 Global steps: 28000 Train loss: 0.3126
ro_en Dev loss: 0.3743 r:0.8149
et_en Dev loss: 0.4015 r:0.6868
si_en Dev loss: 0.7968 r:0.5885
ne_en Dev loss: 0.4651 r:0.7548
ru_en Dev loss: 0.5267 r:0.7101
Current avg r:0.7110 Best avg r: 0.7430
20:13:00,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:05,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:11,24 root INFO Epoch 3 Global steps: 28500 Train loss: 0.3342
ro_en Dev loss: 0.3724 r:0.8140
et_en Dev loss: 0.4111 r:0.6836
si_en Dev loss: 0.8360 r:0.5853
ne_en Dev loss: 0.4842 r:0.7522
ru_en Dev loss: 0.4879 r:0.7264
Current avg r:0.7123 Best avg r: 0.7430
20:18:29,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:35,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:40,728 root INFO Epoch 3 Global steps: 29000 Train loss: 0.3268
ro_en Dev loss: 0.3869 r:0.8084
et_en Dev loss: 0.4123 r:0.6834
si_en Dev loss: 0.8514 r:0.5863
ne_en Dev loss: 0.5101 r:0.7569
ru_en Dev loss: 0.4670 r:0.7402
Current avg r:0.7150 Best avg r: 0.7430
20:24:02,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:07,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:12,796 root INFO Epoch 3 Global steps: 29500 Train loss: 0.3189
ro_en Dev loss: 0.3338 r:0.8166
et_en Dev loss: 0.4079 r:0.6967
si_en Dev loss: 0.6783 r:0.6016
ne_en Dev loss: 0.3759 r:0.7590
ru_en Dev loss: 0.4118 r:0.7533
Current avg r:0.7255 Best avg r: 0.7430
20:29:27,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:32,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:37,845 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3378
ro_en Dev loss: 0.3246 r:0.8205
et_en Dev loss: 0.3882 r:0.6993
si_en Dev loss: 0.6912 r:0.6072
ne_en Dev loss: 0.4240 r:0.7569
ru_en Dev loss: 0.4448 r:0.7409
Current avg r:0.7250 Best avg r: 0.7430
20:34:53,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:58,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:04,235 root INFO Epoch 4 Global steps: 30500 Train loss: 0.3043
ro_en Dev loss: 0.3449 r:0.8168
et_en Dev loss: 0.4085 r:0.6924
si_en Dev loss: 0.7707 r:0.5930
ne_en Dev loss: 0.4499 r:0.7590
ru_en Dev loss: 0.4588 r:0.7389
Current avg r:0.7200 Best avg r: 0.7430
20:40:18,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:24,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:29,500 root INFO Epoch 4 Global steps: 31000 Train loss: 0.2835
ro_en Dev loss: 0.3885 r:0.8111
et_en Dev loss: 0.4250 r:0.6880
si_en Dev loss: 0.8735 r:0.5849
ne_en Dev loss: 0.4593 r:0.7534
ru_en Dev loss: 0.5005 r:0.7286
Current avg r:0.7132 Best avg r: 0.7430
20:45:44,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:49,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:54,711 root INFO Epoch 4 Global steps: 31500 Train loss: 0.2934
ro_en Dev loss: 0.3549 r:0.8156
et_en Dev loss: 0.4113 r:0.6836
si_en Dev loss: 0.8005 r:0.5872
ne_en Dev loss: 0.4819 r:0.7516
ru_en Dev loss: 0.4506 r:0.7355
Current avg r:0.7147 Best avg r: 0.7430
20:51:09,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:14,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:19,673 root INFO Epoch 4 Global steps: 32000 Train loss: 0.2948
ro_en Dev loss: 0.3286 r:0.8154
et_en Dev loss: 0.4055 r:0.6925
si_en Dev loss: 0.7302 r:0.5835
ne_en Dev loss: 0.4675 r:0.7468
ru_en Dev loss: 0.4096 r:0.7416
Current avg r:0.7160 Best avg r: 0.7430
20:56:34,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:40,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:45,700 root INFO Epoch 4 Global steps: 32500 Train loss: 0.2931
ro_en Dev loss: 0.3487 r:0.8204
et_en Dev loss: 0.3944 r:0.6992
si_en Dev loss: 0.7091 r:0.6012
ne_en Dev loss: 0.4443 r:0.7530
ru_en Dev loss: 0.4877 r:0.7292
Current avg r:0.7206 Best avg r: 0.7430
21:02:07,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:12,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:17,980 root INFO Epoch 4 Global steps: 33000 Train loss: 0.2935
ro_en Dev loss: 0.4130 r:0.8087
et_en Dev loss: 0.4271 r:0.6776
si_en Dev loss: 0.8923 r:0.5796
ne_en Dev loss: 0.5529 r:0.7470
ru_en Dev loss: 0.5112 r:0.7300
Current avg r:0.7086 Best avg r: 0.7430
21:07:39,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:44,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:50,66 root INFO Epoch 4 Global steps: 33500 Train loss: 0.2912
ro_en Dev loss: 0.3593 r:0.8150
et_en Dev loss: 0.4048 r:0.6838
si_en Dev loss: 0.7954 r:0.5822
ne_en Dev loss: 0.5041 r:0.7523
ru_en Dev loss: 0.4409 r:0.7444
Current avg r:0.7155 Best avg r: 0.7430
21:13:04,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:09,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:14,868 root INFO Epoch 4 Global steps: 34000 Train loss: 0.2770
ro_en Dev loss: 0.3586 r:0.8155
et_en Dev loss: 0.4364 r:0.6879
si_en Dev loss: 0.6865 r:0.5935
ne_en Dev loss: 0.4038 r:0.7542
ru_en Dev loss: 0.4425 r:0.7442
Current avg r:0.7191 Best avg r: 0.7430
21:18:29,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:34,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:39,632 root INFO Epoch 4 Global steps: 34500 Train loss: 0.2840
ro_en Dev loss: 0.3617 r:0.8179
et_en Dev loss: 0.4189 r:0.6836
si_en Dev loss: 0.8318 r:0.5901
ne_en Dev loss: 0.4624 r:0.7599
ru_en Dev loss: 0.5105 r:0.7330
Current avg r:0.7169 Best avg r: 0.7430
21:23:54,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:59,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:04,506 root INFO Epoch 4 Global steps: 35000 Train loss: 0.2894
ro_en Dev loss: 0.3595 r:0.8157
et_en Dev loss: 0.4195 r:0.6839
si_en Dev loss: 0.7826 r:0.5897
ne_en Dev loss: 0.4653 r:0.7458
ru_en Dev loss: 0.4901 r:0.7412
Current avg r:0.7153 Best avg r: 0.7430
21:29:18,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:24,100 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:29,328 root INFO Epoch 4 Global steps: 35500 Train loss: 0.2817
ro_en Dev loss: 0.3899 r:0.8101
et_en Dev loss: 0.4431 r:0.6718
si_en Dev loss: 0.8506 r:0.5803
ne_en Dev loss: 0.4780 r:0.7526
ru_en Dev loss: 0.5173 r:0.7239
Current avg r:0.7078 Best avg r: 0.7430
21:34:43,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:48,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:54,248 root INFO Epoch 4 Global steps: 36000 Train loss: 0.2811
ro_en Dev loss: 0.3713 r:0.8091
et_en Dev loss: 0.4472 r:0.6793
si_en Dev loss: 0.8153 r:0.5811
ne_en Dev loss: 0.4765 r:0.7444
ru_en Dev loss: 0.5453 r:0.7019
Current avg r:0.7032 Best avg r: 0.7430
21:40:15,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:21,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:26,433 root INFO Epoch 4 Global steps: 36500 Train loss: 0.2734
ro_en Dev loss: 0.3696 r:0.8140
et_en Dev loss: 0.4133 r:0.6823
si_en Dev loss: 0.8471 r:0.5834
ne_en Dev loss: 0.4574 r:0.7556
ru_en Dev loss: 0.4670 r:0.7341
Current avg r:0.7139 Best avg r: 0.7430
21:45:47,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:46:52,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:47:58,226 root INFO Epoch 4 Global steps: 37000 Train loss: 0.2921
ro_en Dev loss: 0.3534 r:0.8128
et_en Dev loss: 0.4163 r:0.6740
si_en Dev loss: 0.8051 r:0.5823
ne_en Dev loss: 0.4791 r:0.7486
ru_en Dev loss: 0.4354 r:0.7396
Current avg r:0.7115 Best avg r: 0.7430
21:51:19,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:25,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:30,686 root INFO Epoch 4 Global steps: 37500 Train loss: 0.2718
ro_en Dev loss: 0.3437 r:0.8150
et_en Dev loss: 0.4205 r:0.6776
si_en Dev loss: 0.7081 r:0.5902
ne_en Dev loss: 0.4158 r:0.7495
ru_en Dev loss: 0.4670 r:0.7254
Current avg r:0.7115 Best avg r: 0.7430
21:56:46,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:51,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:56,562 root INFO Epoch 5 Global steps: 38000 Train loss: 0.2464
ro_en Dev loss: 0.3427 r:0.8133
et_en Dev loss: 0.4619 r:0.6769
si_en Dev loss: 0.7373 r:0.5803
ne_en Dev loss: 0.4268 r:0.7477
ru_en Dev loss: 0.4461 r:0.7288
Current avg r:0.7094 Best avg r: 0.7430
22:02:10,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:16,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:21,365 root INFO Epoch 5 Global steps: 38500 Train loss: 0.2498
ro_en Dev loss: 0.3756 r:0.8104
et_en Dev loss: 0.4395 r:0.6741
si_en Dev loss: 0.7989 r:0.5771
ne_en Dev loss: 0.4574 r:0.7523
ru_en Dev loss: 0.5070 r:0.7175
Current avg r:0.7063 Best avg r: 0.7430
22:07:35,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:41,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:46,285 root INFO Epoch 5 Global steps: 39000 Train loss: 0.2506
ro_en Dev loss: 0.3486 r:0.8112
et_en Dev loss: 0.4324 r:0.6659
si_en Dev loss: 0.7546 r:0.5763
ne_en Dev loss: 0.4627 r:0.7459
ru_en Dev loss: 0.5169 r:0.7077
Current avg r:0.7014 Best avg r: 0.7430
22:13:00,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:06,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:11,296 root INFO Epoch 5 Global steps: 39500 Train loss: 0.2451
ro_en Dev loss: 0.3663 r:0.8119
et_en Dev loss: 0.4424 r:0.6727
si_en Dev loss: 0.8000 r:0.5792
ne_en Dev loss: 0.4537 r:0.7472
ru_en Dev loss: 0.5099 r:0.7079
Current avg r:0.7038 Best avg r: 0.7430
22:18:25,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:31,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:36,342 root INFO Epoch 5 Global steps: 40000 Train loss: 0.2441
ro_en Dev loss: 0.3557 r:0.8127
et_en Dev loss: 0.4657 r:0.6520
si_en Dev loss: 0.8878 r:0.5621
ne_en Dev loss: 0.5300 r:0.7406
ru_en Dev loss: 0.5180 r:0.7056
Current avg r:0.6946 Best avg r: 0.7430
22:23:50,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:56,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:01,354 root INFO Epoch 5 Global steps: 40500 Train loss: 0.2452
ro_en Dev loss: 0.3658 r:0.8092
et_en Dev loss: 0.4318 r:0.6664
si_en Dev loss: 0.8339 r:0.5656
ne_en Dev loss: 0.4797 r:0.7470
ru_en Dev loss: 0.4510 r:0.7288
Current avg r:0.7034 Best avg r: 0.7430
22:29:15,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:21,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:26,301 root INFO Epoch 5 Global steps: 41000 Train loss: 0.2520
ro_en Dev loss: 0.4073 r:0.8098
et_en Dev loss: 0.4811 r:0.6576
si_en Dev loss: 0.9580 r:0.5632
ne_en Dev loss: 0.5795 r:0.7471
ru_en Dev loss: 0.5242 r:0.7152
Current avg r:0.6986 Best avg r: 0.7430
22:34:40,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:45,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:51,176 root INFO Epoch 5 Global steps: 41500 Train loss: 0.2417
ro_en Dev loss: 0.3561 r:0.8125
et_en Dev loss: 0.4654 r:0.6784
si_en Dev loss: 0.7712 r:0.5780
ne_en Dev loss: 0.4160 r:0.7504
ru_en Dev loss: 0.4480 r:0.7322
Current avg r:0.7103 Best avg r: 0.7430
22:40:05,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:10,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:16,128 root INFO Epoch 5 Global steps: 42000 Train loss: 0.2416
ro_en Dev loss: 0.3343 r:0.8147
et_en Dev loss: 0.4462 r:0.6753
si_en Dev loss: 0.7517 r:0.5757
ne_en Dev loss: 0.4361 r:0.7513
ru_en Dev loss: 0.4144 r:0.7350
Current avg r:0.7104 Best avg r: 0.7430
22:45:30,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:35,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:41,43 root INFO Epoch 5 Global steps: 42500 Train loss: 0.2535
ro_en Dev loss: 0.3690 r:0.8106
et_en Dev loss: 0.4373 r:0.6674
si_en Dev loss: 0.8021 r:0.5714
ne_en Dev loss: 0.4685 r:0.7503
ru_en Dev loss: 0.4748 r:0.7239
Current avg r:0.7047 Best avg r: 0.7430
22:50:55,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:00,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:06,12 root INFO Epoch 5 Global steps: 43000 Train loss: 0.2417
ro_en Dev loss: 0.4141 r:0.8034
et_en Dev loss: 0.4391 r:0.6636
si_en Dev loss: 0.8110 r:0.5701
ne_en Dev loss: 0.5294 r:0.7467
ru_en Dev loss: 0.5118 r:0.7171
Current avg r:0.7002 Best avg r: 0.7430
22:56:20,445 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:25,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:31,22 root INFO Epoch 5 Global steps: 43500 Train loss: 0.2366
ro_en Dev loss: 0.4204 r:0.8045
et_en Dev loss: 0.4598 r:0.6664
si_en Dev loss: 0.9555 r:0.5616
ne_en Dev loss: 0.6171 r:0.7434
ru_en Dev loss: 0.5521 r:0.7106
Current avg r:0.6973 Best avg r: 0.7430
23:01:45,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:50,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:56,67 root INFO Epoch 5 Global steps: 44000 Train loss: 0.2396
ro_en Dev loss: 0.4028 r:0.8091
et_en Dev loss: 0.4401 r:0.6656
si_en Dev loss: 0.9487 r:0.5669
ne_en Dev loss: 0.5103 r:0.7520
ru_en Dev loss: 0.5077 r:0.7159
Current avg r:0.7019 Best avg r: 0.7430
23:07:10,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:15,815 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:09:21,108 root INFO Epoch 5 Global steps: 44500 Train loss: 0.2500
ro_en Dev loss: 0.3957 r:0.8037
et_en Dev loss: 0.4519 r:0.6623
si_en Dev loss: 0.8876 r:0.5684
ne_en Dev loss: 0.5083 r:0.7521
ru_en Dev loss: 0.5247 r:0.7098
Current avg r:0.6993 Best avg r: 0.7430
23:12:35,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:40,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:46,59 root INFO Epoch 5 Global steps: 45000 Train loss: 0.2465
ro_en Dev loss: 0.3902 r:0.8006
et_en Dev loss: 0.4321 r:0.6752
si_en Dev loss: 0.8950 r:0.5658
ne_en Dev loss: 0.4967 r:0.7445
ru_en Dev loss: 0.4503 r:0.7290
Current avg r:0.7030 Best avg r: 0.7430
23:18:01,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:06,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:12,85 root INFO Epoch 6 Global steps: 45500 Train loss: 0.2158
ro_en Dev loss: 0.3703 r:0.8041
et_en Dev loss: 0.4533 r:0.6626
si_en Dev loss: 0.8175 r:0.5627
ne_en Dev loss: 0.5200 r:0.7391
ru_en Dev loss: 0.4815 r:0.7167
Current avg r:0.6970 Best avg r: 0.7430
23:23:26,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:31,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:36,779 root INFO Epoch 6 Global steps: 46000 Train loss: 0.2090
ro_en Dev loss: 0.3809 r:0.8041
et_en Dev loss: 0.4551 r:0.6662
si_en Dev loss: 0.8760 r:0.5612
ne_en Dev loss: 0.5359 r:0.7420
ru_en Dev loss: 0.4747 r:0.7269
Current avg r:0.7001 Best avg r: 0.7430
23:28:51,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:56,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:01,494 root INFO Epoch 6 Global steps: 46500 Train loss: 0.1912
ro_en Dev loss: 0.3512 r:0.8111
et_en Dev loss: 0.4138 r:0.6739
si_en Dev loss: 0.8225 r:0.5712
ne_en Dev loss: 0.5661 r:0.7387
ru_en Dev loss: 0.4580 r:0.7297
Current avg r:0.7049 Best avg r: 0.7430
23:34:15,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:20,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:26,186 root INFO Epoch 6 Global steps: 47000 Train loss: 0.2093
ro_en Dev loss: 0.3578 r:0.8092
et_en Dev loss: 0.4390 r:0.6809
si_en Dev loss: 0.7526 r:0.5753
ne_en Dev loss: 0.4468 r:0.7377
ru_en Dev loss: 0.4392 r:0.7299
Current avg r:0.7066 Best avg r: 0.7430
23:39:40,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:45,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:50,791 root INFO Epoch 6 Global steps: 47500 Train loss: 0.2064
ro_en Dev loss: 0.4014 r:0.8019
et_en Dev loss: 0.4696 r:0.6565
si_en Dev loss: 0.9264 r:0.5538
ne_en Dev loss: 0.6183 r:0.7301
ru_en Dev loss: 0.5547 r:0.7079
Current avg r:0.6900 Best avg r: 0.7430
23:45:04,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:10,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:47:15,341 root INFO Epoch 6 Global steps: 48000 Train loss: 0.2089
ro_en Dev loss: 0.3741 r:0.8047
et_en Dev loss: 0.4495 r:0.6645
si_en Dev loss: 0.8573 r:0.5647
ne_en Dev loss: 0.5448 r:0.7352
ru_en Dev loss: 0.4697 r:0.7245
Current avg r:0.6987 Best avg r: 0.7430
23:50:29,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:34,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:39,940 root INFO Epoch 6 Global steps: 48500 Train loss: 0.2163
ro_en Dev loss: 0.3521 r:0.8056
et_en Dev loss: 0.4433 r:0.6647
si_en Dev loss: 0.7686 r:0.5667
ne_en Dev loss: 0.4728 r:0.7316
ru_en Dev loss: 0.4451 r:0.7220
Current avg r:0.6981 Best avg r: 0.7430
23:55:56,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:01,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:06,498 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2168
ro_en Dev loss: 0.3818 r:0.8067
et_en Dev loss: 0.4378 r:0.6704
si_en Dev loss: 0.8421 r:0.5626
ne_en Dev loss: 0.5108 r:0.7312
ru_en Dev loss: 0.4988 r:0.7118
Current avg r:0.6966 Best avg r: 0.7430
00:01:23,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:29,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:34,474 root INFO Epoch 6 Global steps: 49500 Train loss: 0.2189
ro_en Dev loss: 0.3908 r:0.8027
et_en Dev loss: 0.4639 r:0.6628
si_en Dev loss: 0.8931 r:0.5494
ne_en Dev loss: 0.4948 r:0.7321
ru_en Dev loss: 0.4740 r:0.7205
Current avg r:0.6935 Best avg r: 0.7430
00:06:56,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:08:01,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:09:06,960 root INFO Epoch 6 Global steps: 50000 Train loss: 0.2048
ro_en Dev loss: 0.4004 r:0.8021
et_en Dev loss: 0.4689 r:0.6630
si_en Dev loss: 0.8265 r:0.5591
ne_en Dev loss: 0.5171 r:0.7307
ru_en Dev loss: 0.4949 r:0.7175
Current avg r:0.6945 Best avg r: 0.7430
00:12:28,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:34,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:39,413 root INFO Epoch 6 Global steps: 50500 Train loss: 0.2027
ro_en Dev loss: 0.3741 r:0.8087
et_en Dev loss: 0.4640 r:0.6676
si_en Dev loss: 0.7830 r:0.5616
ne_en Dev loss: 0.4296 r:0.7360
ru_en Dev loss: 0.4804 r:0.7228
Current avg r:0.6994 Best avg r: 0.7430
00:18:01,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:06,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:11,750 root INFO Epoch 6 Global steps: 51000 Train loss: 0.2082
ro_en Dev loss: 0.3682 r:0.8077
et_en Dev loss: 0.4663 r:0.6553
si_en Dev loss: 0.9525 r:0.5493
ne_en Dev loss: 0.5986 r:0.7330
ru_en Dev loss: 0.4632 r:0.7214
Current avg r:0.6933 Best avg r: 0.7430
00:23:26,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:31,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:36,749 root INFO Epoch 6 Global steps: 51500 Train loss: 0.2170
ro_en Dev loss: 0.3770 r:0.8074
et_en Dev loss: 0.4474 r:0.6671
si_en Dev loss: 0.8980 r:0.5508
ne_en Dev loss: 0.4941 r:0.7380
ru_en Dev loss: 0.5037 r:0.7172
Current avg r:0.6961 Best avg r: 0.7430
00:28:51,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:56,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:01,533 root INFO Epoch 6 Global steps: 52000 Train loss: 0.2124
ro_en Dev loss: 0.3553 r:0.8025
et_en Dev loss: 0.4766 r:0.6759
si_en Dev loss: 0.7250 r:0.5678
ne_en Dev loss: 0.4205 r:0.7293
ru_en Dev loss: 0.4327 r:0.7303
Current avg r:0.7011 Best avg r: 0.7430
00:34:15,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:21,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:26,407 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2099
ro_en Dev loss: 0.3857 r:0.8046
et_en Dev loss: 0.4424 r:0.6668
si_en Dev loss: 0.8292 r:0.5647
ne_en Dev loss: 0.4817 r:0.7339
ru_en Dev loss: 0.4905 r:0.7058
Current avg r:0.6952 Best avg r: 0.7430
00:39:42,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:47,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:52,471 root INFO Epoch 7 Global steps: 53000 Train loss: 0.1876
ro_en Dev loss: 0.4175 r:0.8004
et_en Dev loss: 0.4833 r:0.6481
si_en Dev loss: 1.0062 r:0.5395
ne_en Dev loss: 0.6693 r:0.7287
ru_en Dev loss: 0.5049 r:0.7095
Current avg r:0.6853 Best avg r: 0.7430
00:45:06,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:12,174 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:17,387 root INFO Epoch 7 Global steps: 53500 Train loss: 0.1835
ro_en Dev loss: 0.4030 r:0.8067
et_en Dev loss: 0.4573 r:0.6618
si_en Dev loss: 0.8808 r:0.5587
ne_en Dev loss: 0.4921 r:0.7367
ru_en Dev loss: 0.4818 r:0.7283
Current avg r:0.6984 Best avg r: 0.7430
00:50:31,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:36,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:42,44 root INFO Epoch 7 Global steps: 54000 Train loss: 0.1894
ro_en Dev loss: 0.4102 r:0.8064
et_en Dev loss: 0.4765 r:0.6626
si_en Dev loss: 0.9093 r:0.5549
ne_en Dev loss: 0.5023 r:0.7351
ru_en Dev loss: 0.4731 r:0.7339
Current avg r:0.6986 Best avg r: 0.7430
00:55:56,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:01,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:06,690 root INFO Epoch 7 Global steps: 54500 Train loss: 0.1863
ro_en Dev loss: 0.4096 r:0.8014
et_en Dev loss: 0.4955 r:0.6447
si_en Dev loss: 0.9697 r:0.5455
ne_en Dev loss: 0.5978 r:0.7275
ru_en Dev loss: 0.5357 r:0.6975
Current avg r:0.6833 Best avg r: 0.7430
01:01:20,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:02:26,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:31,179 root INFO Epoch 7 Global steps: 55000 Train loss: 0.1801
ro_en Dev loss: 0.4361 r:0.8048
et_en Dev loss: 0.4960 r:0.6480
si_en Dev loss: 0.9792 r:0.5452
ne_en Dev loss: 0.5202 r:0.7257
ru_en Dev loss: 0.5775 r:0.6974
Current avg r:0.6842 Best avg r: 0.7430
01:06:45,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:50,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:55,829 root INFO Epoch 7 Global steps: 55500 Train loss: 0.1887
ro_en Dev loss: 0.3997 r:0.8035
et_en Dev loss: 0.4709 r:0.6451
si_en Dev loss: 1.0280 r:0.5395
ne_en Dev loss: 0.6071 r:0.7306
ru_en Dev loss: 0.5552 r:0.6886
Current avg r:0.6815 Best avg r: 0.7430
01:12:10,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:15,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:20,658 root INFO Epoch 7 Global steps: 56000 Train loss: 0.1829
ro_en Dev loss: 0.3571 r:0.8099
et_en Dev loss: 0.4664 r:0.6788
si_en Dev loss: 0.7683 r:0.5609
ne_en Dev loss: 0.4896 r:0.7370
ru_en Dev loss: 0.4530 r:0.7291
Current avg r:0.7031 Best avg r: 0.7430
01:17:34,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:18:40,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:45,223 root INFO Epoch 7 Global steps: 56500 Train loss: 0.1805
ro_en Dev loss: 0.3864 r:0.7992
et_en Dev loss: 0.4775 r:0.6632
si_en Dev loss: 0.8790 r:0.5493
ne_en Dev loss: 0.5169 r:0.7285
ru_en Dev loss: 0.4771 r:0.7157
Current avg r:0.6912 Best avg r: 0.7430
01:22:59,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:24:04,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:09,801 root INFO Epoch 7 Global steps: 57000 Train loss: 0.1793
ro_en Dev loss: 0.3425 r:0.8110
et_en Dev loss: 0.4387 r:0.6738
si_en Dev loss: 0.8457 r:0.5544
ne_en Dev loss: 0.4671 r:0.7333
ru_en Dev loss: 0.4385 r:0.7279
Current avg r:0.7001 Best avg r: 0.7430
01:28:23,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:29,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:34,315 root INFO Epoch 7 Global steps: 57500 Train loss: 0.1836
ro_en Dev loss: 0.3340 r:0.8116
et_en Dev loss: 0.4236 r:0.6659
si_en Dev loss: 0.8187 r:0.5516
ne_en Dev loss: 0.5469 r:0.7334
ru_en Dev loss: 0.4395 r:0.7246
Current avg r:0.6974 Best avg r: 0.7430
01:33:48,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:34:53,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:35:58,699 root INFO Epoch 7 Global steps: 58000 Train loss: 0.1772
ro_en Dev loss: 0.3649 r:0.8122
et_en Dev loss: 0.4190 r:0.6756
si_en Dev loss: 0.8122 r:0.5618
ne_en Dev loss: 0.4996 r:0.7344
ru_en Dev loss: 0.4306 r:0.7427
Current avg r:0.7053 Best avg r: 0.7430
01:39:12,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:40:17,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:41:23,130 root INFO Epoch 7 Global steps: 58500 Train loss: 0.1826
ro_en Dev loss: 0.3930 r:0.8092
et_en Dev loss: 0.4571 r:0.6614
si_en Dev loss: 0.9186 r:0.5489
ne_en Dev loss: 0.6088 r:0.7307
ru_en Dev loss: 0.5017 r:0.7210
Current avg r:0.6942 Best avg r: 0.7430
01:44:37,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:45:42,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:46:47,384 root INFO Epoch 7 Global steps: 59000 Train loss: 0.1806
ro_en Dev loss: 0.3665 r:0.8087
et_en Dev loss: 0.4593 r:0.6617
si_en Dev loss: 0.9000 r:0.5493
ne_en Dev loss: 0.5229 r:0.7306
ru_en Dev loss: 0.4770 r:0.7239
Current avg r:0.6949 Best avg r: 0.7430
01:50:01,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:06,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:11,650 root INFO Epoch 7 Global steps: 59500 Train loss: 0.1647
ro_en Dev loss: 0.3719 r:0.8068
et_en Dev loss: 0.4658 r:0.6665
si_en Dev loss: 0.8910 r:0.5508
ne_en Dev loss: 0.4916 r:0.7368
ru_en Dev loss: 0.4753 r:0.7224
Current avg r:0.6967 Best avg r: 0.7430
01:55:25,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:56:30,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:57:36,20 root INFO Epoch 7 Global steps: 60000 Train loss: 0.1710
ro_en Dev loss: 0.3480 r:0.8119
et_en Dev loss: 0.4669 r:0.6791
si_en Dev loss: 0.8388 r:0.5609
ne_en Dev loss: 0.4402 r:0.7447
ru_en Dev loss: 0.4116 r:0.7494
Current avg r:0.7092 Best avg r: 0.7430
02:00:56,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:02:02,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:03:07,879 root INFO Epoch 8 Global steps: 60500 Train loss: 0.1599
ro_en Dev loss: 0.3468 r:0.8088
et_en Dev loss: 0.4664 r:0.6641
si_en Dev loss: 0.8179 r:0.5488
ne_en Dev loss: 0.5215 r:0.7300
ru_en Dev loss: 0.4253 r:0.7397
Current avg r:0.6983 Best avg r: 0.7430
02:06:29,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:07:35,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:08:40,860 root INFO Epoch 8 Global steps: 61000 Train loss: 0.1595
ro_en Dev loss: 0.3608 r:0.8073
et_en Dev loss: 0.4697 r:0.6687
si_en Dev loss: 0.8367 r:0.5542
ne_en Dev loss: 0.5201 r:0.7292
ru_en Dev loss: 0.4726 r:0.7244
Current avg r:0.6967 Best avg r: 0.7430
02:12:04,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:10,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:16,14 root INFO Epoch 8 Global steps: 61500 Train loss: 0.1580
ro_en Dev loss: 0.3711 r:0.8095
et_en Dev loss: 0.4724 r:0.6614
si_en Dev loss: 0.9458 r:0.5424
ne_en Dev loss: 0.6481 r:0.7242
ru_en Dev loss: 0.4859 r:0.7174
Current avg r:0.6910 Best avg r: 0.7430
02:17:33,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:18:39,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:44,980 root INFO Epoch 8 Global steps: 62000 Train loss: 0.1510
ro_en Dev loss: 0.3796 r:0.8085
et_en Dev loss: 0.4878 r:0.6728
si_en Dev loss: 0.8858 r:0.5584
ne_en Dev loss: 0.4847 r:0.7357
ru_en Dev loss: 0.4834 r:0.7243
Current avg r:0.6999 Best avg r: 0.7430
02:23:03,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:09,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:15,198 root INFO Epoch 8 Global steps: 62500 Train loss: 0.1547
ro_en Dev loss: 0.3789 r:0.8095
et_en Dev loss: 0.4964 r:0.6568
si_en Dev loss: 0.8809 r:0.5529
ne_en Dev loss: 0.5370 r:0.7301
ru_en Dev loss: 0.4755 r:0.7198
Current avg r:0.6938 Best avg r: 0.7430
02:28:33,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:39,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:30:44,219 root INFO Epoch 8 Global steps: 63000 Train loss: 0.1572
ro_en Dev loss: 0.3789 r:0.8097
et_en Dev loss: 0.4902 r:0.6559
si_en Dev loss: 0.9053 r:0.5498
ne_en Dev loss: 0.5741 r:0.7262
ru_en Dev loss: 0.5054 r:0.7122
Current avg r:0.6907 Best avg r: 0.7430
02:34:06,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:11,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:16,856 root INFO Epoch 8 Global steps: 63500 Train loss: 0.1574
ro_en Dev loss: 0.4238 r:0.8033
et_en Dev loss: 0.4811 r:0.6535
si_en Dev loss: 0.9624 r:0.5457
ne_en Dev loss: 0.5634 r:0.7318
ru_en Dev loss: 0.5190 r:0.7136
Current avg r:0.6896 Best avg r: 0.7430
02:39:39,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:40:44,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:41:49,803 root INFO Epoch 8 Global steps: 64000 Train loss: 0.1616
ro_en Dev loss: 0.3589 r:0.8063
et_en Dev loss: 0.4753 r:0.6584
si_en Dev loss: 0.8446 r:0.5467
ne_en Dev loss: 0.5194 r:0.7273
ru_en Dev loss: 0.4517 r:0.7246
Current avg r:0.6927 Best avg r: 0.7430
02:45:12,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:46:17,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:47:22,785 root INFO Epoch 8 Global steps: 64500 Train loss: 0.1549
ro_en Dev loss: 0.3740 r:0.8062
et_en Dev loss: 0.4658 r:0.6599
si_en Dev loss: 0.9059 r:0.5440
ne_en Dev loss: 0.5396 r:0.7285
ru_en Dev loss: 0.4833 r:0.7218
Current avg r:0.6921 Best avg r: 0.7430
02:50:45,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:50,366 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:55,633 root INFO Epoch 8 Global steps: 65000 Train loss: 0.1606
ro_en Dev loss: 0.4035 r:0.8019
et_en Dev loss: 0.4637 r:0.6587
si_en Dev loss: 0.9932 r:0.5360
ne_en Dev loss: 0.6979 r:0.7208
ru_en Dev loss: 0.5144 r:0.7129
Current avg r:0.6861 Best avg r: 0.7430
02:56:10,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:57:16,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:58:21,513 root INFO Epoch 8 Global steps: 65500 Train loss: 0.1516
ro_en Dev loss: 0.3861 r:0.8078
et_en Dev loss: 0.4616 r:0.6634
si_en Dev loss: 0.9590 r:0.5358
ne_en Dev loss: 0.5522 r:0.7242
ru_en Dev loss: 0.4898 r:0.7177
Current avg r:0.6898 Best avg r: 0.7430
03:01:41,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:02:47,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:52,278 root INFO Epoch 8 Global steps: 66000 Train loss: 0.1620
ro_en Dev loss: 0.3563 r:0.8132
et_en Dev loss: 0.4558 r:0.6620
si_en Dev loss: 0.8959 r:0.5488
ne_en Dev loss: 0.5253 r:0.7249
ru_en Dev loss: 0.5066 r:0.7142
Current avg r:0.6926 Best avg r: 0.7430
03:07:09,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:08:14,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:09:19,494 root INFO Epoch 8 Global steps: 66500 Train loss: 0.1521
ro_en Dev loss: 0.3954 r:0.8083
et_en Dev loss: 0.4678 r:0.6630
si_en Dev loss: 0.9994 r:0.5423
ne_en Dev loss: 0.6508 r:0.7226
ru_en Dev loss: 0.5442 r:0.7037
Current avg r:0.6880 Best avg r: 0.7430
03:12:34,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:39,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:44,360 root INFO Epoch 8 Global steps: 67000 Train loss: 0.1575
ro_en Dev loss: 0.3905 r:0.8069
et_en Dev loss: 0.4767 r:0.6511
si_en Dev loss: 0.9990 r:0.5407
ne_en Dev loss: 0.6396 r:0.7199
ru_en Dev loss: 0.4883 r:0.7183
Current avg r:0.6874 Best avg r: 0.7430
03:17:58,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:19:04,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:20:09,176 root INFO Epoch 8 Global steps: 67500 Train loss: 0.1600
ro_en Dev loss: 0.3547 r:0.8122
et_en Dev loss: 0.4529 r:0.6686
si_en Dev loss: 0.8653 r:0.5535
ne_en Dev loss: 0.5539 r:0.7204
ru_en Dev loss: 0.4319 r:0.7419
Current avg r:0.6993 Best avg r: 0.7430
03:23:25,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:24:30,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:36,137 root INFO Epoch 9 Global steps: 68000 Train loss: 0.1448
ro_en Dev loss: 0.4139 r:0.8078
et_en Dev loss: 0.4699 r:0.6589
si_en Dev loss: 0.9438 r:0.5498
ne_en Dev loss: 0.5642 r:0.7190
ru_en Dev loss: 0.5264 r:0.7222
Current avg r:0.6915 Best avg r: 0.7430
03:28:54,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:59,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:04,712 root INFO Epoch 9 Global steps: 68500 Train loss: 0.1380
ro_en Dev loss: 0.3732 r:0.8075
et_en Dev loss: 0.4646 r:0.6603
si_en Dev loss: 0.9239 r:0.5459
ne_en Dev loss: 0.5452 r:0.7187
ru_en Dev loss: 0.4271 r:0.7372
Current avg r:0.6939 Best avg r: 0.7430
03:34:19,214 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:24,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:29,485 root INFO Epoch 9 Global steps: 69000 Train loss: 0.1350
ro_en Dev loss: 0.3586 r:0.8131
et_en Dev loss: 0.4524 r:0.6545
si_en Dev loss: 0.9286 r:0.5432
ne_en Dev loss: 0.5928 r:0.7169
ru_en Dev loss: 0.4251 r:0.7412
Current avg r:0.6938 Best avg r: 0.7430
03:39:44,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:49,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:54,376 root INFO Epoch 9 Global steps: 69500 Train loss: 0.1420
ro_en Dev loss: 0.3911 r:0.8081
et_en Dev loss: 0.4809 r:0.6510
si_en Dev loss: 0.9655 r:0.5379
ne_en Dev loss: 0.6029 r:0.7106
ru_en Dev loss: 0.4946 r:0.7196
Current avg r:0.6854 Best avg r: 0.7430
03:45:16,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:46:21,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:47:27,243 root INFO Epoch 9 Global steps: 70000 Train loss: 0.1376
ro_en Dev loss: 0.4459 r:0.8053
et_en Dev loss: 0.4919 r:0.6491
si_en Dev loss: 0.9918 r:0.5505
ne_en Dev loss: 0.5986 r:0.7214
ru_en Dev loss: 0.5455 r:0.7210
Current avg r:0.6895 Best avg r: 0.7430
03:50:49,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:54,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:59,940 root INFO Epoch 9 Global steps: 70500 Train loss: 0.1431
ro_en Dev loss: 0.3971 r:0.8052
et_en Dev loss: 0.4903 r:0.6518
si_en Dev loss: 0.9052 r:0.5439
ne_en Dev loss: 0.5977 r:0.7158
ru_en Dev loss: 0.4934 r:0.7253
Current avg r:0.6884 Best avg r: 0.7430
03:56:22,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:27,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:58:32,824 root INFO Epoch 9 Global steps: 71000 Train loss: 0.1350
ro_en Dev loss: 0.3627 r:0.8108
et_en Dev loss: 0.4745 r:0.6620
si_en Dev loss: 0.8528 r:0.5495
ne_en Dev loss: 0.4756 r:0.7227
ru_en Dev loss: 0.4710 r:0.7245
Current avg r:0.6939 Best avg r: 0.7430
04:01:55,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:03:00,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:05,705 root INFO Epoch 9 Global steps: 71500 Train loss: 0.1407
ro_en Dev loss: 0.3748 r:0.8079
et_en Dev loss: 0.4835 r:0.6553
si_en Dev loss: 0.9258 r:0.5358
ne_en Dev loss: 0.5164 r:0.7160
ru_en Dev loss: 0.4931 r:0.7234
Current avg r:0.6877 Best avg r: 0.7430
04:07:24,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:08:29,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:09:35,11 root INFO Epoch 9 Global steps: 72000 Train loss: 0.1472
ro_en Dev loss: 0.3582 r:0.8053
et_en Dev loss: 0.4546 r:0.6621
si_en Dev loss: 0.8570 r:0.5462
ne_en Dev loss: 0.5431 r:0.7221
ru_en Dev loss: 0.4765 r:0.7277
Current avg r:0.6927 Best avg r: 0.7430
04:12:57,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:02,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:07,807 root INFO Epoch 9 Global steps: 72500 Train loss: 0.1373
ro_en Dev loss: 0.3953 r:0.8071
et_en Dev loss: 0.4712 r:0.6566
si_en Dev loss: 0.9997 r:0.5367
ne_en Dev loss: 0.6628 r:0.7119
ru_en Dev loss: 0.4982 r:0.7253
Current avg r:0.6875 Best avg r: 0.7430
04:18:30,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:19:35,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:20:40,704 root INFO Epoch 9 Global steps: 73000 Train loss: 0.1391
ro_en Dev loss: 0.3670 r:0.8095
et_en Dev loss: 0.4706 r:0.6543
si_en Dev loss: 0.9284 r:0.5465
ne_en Dev loss: 0.6402 r:0.7204
ru_en Dev loss: 0.5182 r:0.7145
Current avg r:0.6890 Best avg r: 0.7430
04:24:03,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:25:08,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:26:13,762 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1366
ro_en Dev loss: 0.4153 r:0.8024
et_en Dev loss: 0.4854 r:0.6567
si_en Dev loss: 1.0036 r:0.5379
ne_en Dev loss: 0.6240 r:0.7235
ru_en Dev loss: 0.4983 r:0.7294
Current avg r:0.6900 Best avg r: 0.7430
04:29:36,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:41,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:46,728 root INFO Epoch 9 Global steps: 74000 Train loss: 0.1406
ro_en Dev loss: 0.3532 r:0.8127
et_en Dev loss: 0.4494 r:0.6642
si_en Dev loss: 0.9003 r:0.5439
ne_en Dev loss: 0.5616 r:0.7151
ru_en Dev loss: 0.4245 r:0.7466
Current avg r:0.6965 Best avg r: 0.7430
04:35:01,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:06,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:11,696 root INFO Epoch 9 Global steps: 74500 Train loss: 0.1367
ro_en Dev loss: 0.3975 r:0.8086
et_en Dev loss: 0.4866 r:0.6548
si_en Dev loss: 1.0403 r:0.5387
ne_en Dev loss: 0.6869 r:0.7217
ru_en Dev loss: 0.5402 r:0.7253
Current avg r:0.6898 Best avg r: 0.7430
04:40:33,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:41:38,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:42:44,225 root INFO Epoch 9 Global steps: 75000 Train loss: 0.1343
ro_en Dev loss: 0.3861 r:0.8062
et_en Dev loss: 0.4886 r:0.6460
si_en Dev loss: 0.9683 r:0.5363
ne_en Dev loss: 0.6470 r:0.7197
ru_en Dev loss: 0.4859 r:0.7261
Current avg r:0.6869 Best avg r: 0.7430
04:45:59,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:47:04,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:09,832 root INFO Epoch 10 Global steps: 75500 Train loss: 0.1247
ro_en Dev loss: 0.4148 r:0.8098
et_en Dev loss: 0.4802 r:0.6566
si_en Dev loss: 1.0283 r:0.5435
ne_en Dev loss: 0.6857 r:0.7204
ru_en Dev loss: 0.5540 r:0.7153
Current avg r:0.6891 Best avg r: 0.7430
04:51:23,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:52:29,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:34,269 root INFO Epoch 10 Global steps: 76000 Train loss: 0.1211
ro_en Dev loss: 0.3551 r:0.8125
et_en Dev loss: 0.4615 r:0.6639
si_en Dev loss: 0.8986 r:0.5452
ne_en Dev loss: 0.5275 r:0.7165
ru_en Dev loss: 0.4504 r:0.7373
Current avg r:0.6951 Best avg r: 0.7430
04:56:48,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:53,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:58,755 root INFO Epoch 10 Global steps: 76500 Train loss: 0.1244
ro_en Dev loss: 0.3701 r:0.8096
et_en Dev loss: 0.4704 r:0.6706
si_en Dev loss: 0.9027 r:0.5473
ne_en Dev loss: 0.5126 r:0.7204
ru_en Dev loss: 0.4519 r:0.7445
Current avg r:0.6985 Best avg r: 0.7430
05:02:12,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:18,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:04:23,203 root INFO Epoch 10 Global steps: 77000 Train loss: 0.1205
ro_en Dev loss: 0.3906 r:0.8098
et_en Dev loss: 0.4716 r:0.6646
si_en Dev loss: 0.9553 r:0.5470
ne_en Dev loss: 0.5803 r:0.7215
ru_en Dev loss: 0.4869 r:0.7297
Current avg r:0.6945 Best avg r: 0.7430
05:07:37,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:08:42,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:09:47,814 root INFO Epoch 10 Global steps: 77500 Train loss: 0.1245
ro_en Dev loss: 0.4225 r:0.8092
et_en Dev loss: 0.4897 r:0.6543
si_en Dev loss: 1.0467 r:0.5429
ne_en Dev loss: 0.7125 r:0.7187
ru_en Dev loss: 0.5357 r:0.7241
Current avg r:0.6899 Best avg r: 0.7430
05:13:01,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:07,87 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:12,236 root INFO Epoch 10 Global steps: 78000 Train loss: 0.1187
ro_en Dev loss: 0.3737 r:0.8097
et_en Dev loss: 0.4606 r:0.6547
si_en Dev loss: 0.9644 r:0.5388
ne_en Dev loss: 0.6970 r:0.7112
ru_en Dev loss: 0.4944 r:0.7221
Current avg r:0.6873 Best avg r: 0.7430
05:18:26,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:19:31,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:20:36,801 root INFO Epoch 10 Global steps: 78500 Train loss: 0.1222
ro_en Dev loss: 0.3635 r:0.8118
et_en Dev loss: 0.4617 r:0.6625
si_en Dev loss: 0.8953 r:0.5470
ne_en Dev loss: 0.5564 r:0.7188
ru_en Dev loss: 0.4376 r:0.7440
Current avg r:0.6968 Best avg r: 0.7430
05:23:51,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:24:57,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:02,975 root INFO Epoch 10 Global steps: 79000 Train loss: 0.1160
ro_en Dev loss: 0.3751 r:0.8086
et_en Dev loss: 0.4666 r:0.6535
si_en Dev loss: 1.0166 r:0.5294
ne_en Dev loss: 0.6521 r:0.7086
ru_en Dev loss: 0.4963 r:0.7246
Current avg r:0.6849 Best avg r: 0.7430
05:29:19,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:25,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:30,832 root INFO Epoch 10 Global steps: 79500 Train loss: 0.1267
ro_en Dev loss: 0.3610 r:0.8091
et_en Dev loss: 0.4741 r:0.6634
si_en Dev loss: 0.8696 r:0.5448
ne_en Dev loss: 0.5590 r:0.7153
ru_en Dev loss: 0.4523 r:0.7345
Current avg r:0.6934 Best avg r: 0.7430
05:34:46,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:35:52,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:36:57,945 root INFO Epoch 10 Global steps: 80000 Train loss: 0.1233
ro_en Dev loss: 0.3674 r:0.8082
et_en Dev loss: 0.4612 r:0.6591
si_en Dev loss: 0.9495 r:0.5351
ne_en Dev loss: 0.5511 r:0.7161
ru_en Dev loss: 0.4634 r:0.7324
Current avg r:0.6902 Best avg r: 0.7430
05:40:17,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:41:22,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:42:28,343 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1214
ro_en Dev loss: 0.4019 r:0.8060
et_en Dev loss: 0.4772 r:0.6666
si_en Dev loss: 0.9622 r:0.5425
ne_en Dev loss: 0.6635 r:0.7173
ru_en Dev loss: 0.5138 r:0.7219
Current avg r:0.6908 Best avg r: 0.7430
05:45:46,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:46:52,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:47:57,674 root INFO Epoch 10 Global steps: 81000 Train loss: 0.1238
ro_en Dev loss: 0.4221 r:0.7998
et_en Dev loss: 0.4961 r:0.6464
si_en Dev loss: 1.0539 r:0.5248
ne_en Dev loss: 0.6874 r:0.7111
ru_en Dev loss: 0.5565 r:0.6965
Current avg r:0.6757 Best avg r: 0.7430
05:51:19,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:25,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:30,234 root INFO Epoch 10 Global steps: 81500 Train loss: 0.1258
ro_en Dev loss: 0.3528 r:0.8121
et_en Dev loss: 0.4497 r:0.6614
si_en Dev loss: 0.8963 r:0.5399
ne_en Dev loss: 0.5522 r:0.7146
ru_en Dev loss: 0.4460 r:0.7310
Current avg r:0.6918 Best avg r: 0.7430
05:56:45,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:57:50,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:58:55,349 root INFO Epoch 10 Global steps: 82000 Train loss: 0.1169
ro_en Dev loss: 0.3505 r:0.8120
et_en Dev loss: 0.4510 r:0.6705
si_en Dev loss: 0.8723 r:0.5435
ne_en Dev loss: 0.5867 r:0.7183
ru_en Dev loss: 0.4416 r:0.7342
Current avg r:0.6957 Best avg r: 0.7430
06:02:09,486 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:14,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:19,756 root INFO Epoch 10 Global steps: 82500 Train loss: 0.1237
ro_en Dev loss: 0.3598 r:0.8103
et_en Dev loss: 0.4654 r:0.6726
si_en Dev loss: 0.8834 r:0.5426
ne_en Dev loss: 0.5179 r:0.7214
ru_en Dev loss: 0.4966 r:0.7208
Current avg r:0.6936 Best avg r: 0.7430
06:07:42,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:08:48,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:09:53,594 root INFO Epoch 11 Global steps: 83000 Train loss: 0.1097
ro_en Dev loss: 0.3580 r:0.8148
et_en Dev loss: 0.4542 r:0.6652
si_en Dev loss: 0.8681 r:0.5498
ne_en Dev loss: 0.5135 r:0.7269
ru_en Dev loss: 0.4810 r:0.7297
Current avg r:0.6973 Best avg r: 0.7430
06:13:11,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:16,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:21,765 root INFO Epoch 11 Global steps: 83500 Train loss: 0.1132
ro_en Dev loss: 0.3558 r:0.8088
et_en Dev loss: 0.4642 r:0.6671
si_en Dev loss: 0.8441 r:0.5512
ne_en Dev loss: 0.5649 r:0.7218
ru_en Dev loss: 0.4361 r:0.7375
Current avg r:0.6973 Best avg r: 0.7430
06:18:36,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:19:41,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:20:46,448 root INFO Epoch 11 Global steps: 84000 Train loss: 0.1129
ro_en Dev loss: 0.4012 r:0.8078
et_en Dev loss: 0.4774 r:0.6553
si_en Dev loss: 0.9638 r:0.5450
ne_en Dev loss: 0.6151 r:0.7184
ru_en Dev loss: 0.5073 r:0.7335
Current avg r:0.6920 Best avg r: 0.7430
06:24:00,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:25:05,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:11,233 root INFO Epoch 11 Global steps: 84500 Train loss: 0.1096
ro_en Dev loss: 0.3659 r:0.8100
et_en Dev loss: 0.4625 r:0.6582
si_en Dev loss: 0.9203 r:0.5436
ne_en Dev loss: 0.5700 r:0.7144
ru_en Dev loss: 0.4604 r:0.7313
Current avg r:0.6915 Best avg r: 0.7430
06:29:33,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:39,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:44,412 root INFO Epoch 11 Global steps: 85000 Train loss: 0.1107
ro_en Dev loss: 0.3519 r:0.8112
et_en Dev loss: 0.4480 r:0.6610
si_en Dev loss: 0.8627 r:0.5544
ne_en Dev loss: 0.5885 r:0.7114
ru_en Dev loss: 0.4426 r:0.7324
Current avg r:0.6941 Best avg r: 0.7430
06:35:02,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:07,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:13,133 root INFO Epoch 11 Global steps: 85500 Train loss: 0.1165
ro_en Dev loss: 0.3590 r:0.8130
et_en Dev loss: 0.4621 r:0.6666
si_en Dev loss: 0.8543 r:0.5547
ne_en Dev loss: 0.5275 r:0.7175
ru_en Dev loss: 0.4538 r:0.7357
Current avg r:0.6975 Best avg r: 0.7430
06:40:28,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:33,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:42:38,491 root INFO Epoch 11 Global steps: 86000 Train loss: 0.1069
ro_en Dev loss: 0.3746 r:0.8111
et_en Dev loss: 0.4761 r:0.6532
si_en Dev loss: 0.9521 r:0.5431
ne_en Dev loss: 0.5716 r:0.7146
ru_en Dev loss: 0.4756 r:0.7369
Current avg r:0.6918 Best avg r: 0.7430
06:45:58,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:03,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:48:08,873 root INFO Epoch 11 Global steps: 86500 Train loss: 0.1066
ro_en Dev loss: 0.3679 r:0.8099
et_en Dev loss: 0.4651 r:0.6625
si_en Dev loss: 0.9364 r:0.5444
ne_en Dev loss: 0.5803 r:0.7123
ru_en Dev loss: 0.4424 r:0.7413
Current avg r:0.6941 Best avg r: 0.7430
06:51:23,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:28,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:53:34,266 root INFO Epoch 11 Global steps: 87000 Train loss: 0.1096
ro_en Dev loss: 0.3800 r:0.8101
et_en Dev loss: 0.4713 r:0.6591
si_en Dev loss: 0.9244 r:0.5493
ne_en Dev loss: 0.6031 r:0.7186
ru_en Dev loss: 0.4896 r:0.7324
Current avg r:0.6939 Best avg r: 0.7430
06:56:56,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:58:02,122 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:59:07,495 root INFO Epoch 11 Global steps: 87500 Train loss: 0.1065
ro_en Dev loss: 0.3521 r:0.8109
et_en Dev loss: 0.4537 r:0.6688
si_en Dev loss: 0.8396 r:0.5484
ne_en Dev loss: 0.5392 r:0.7117
ru_en Dev loss: 0.4441 r:0.7420
Current avg r:0.6964 Best avg r: 0.7430
07:02:29,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:03:35,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:04:40,264 root INFO Epoch 11 Global steps: 88000 Train loss: 0.1124
ro_en Dev loss: 0.3635 r:0.8109
et_en Dev loss: 0.4608 r:0.6645
si_en Dev loss: 0.9163 r:0.5414
ne_en Dev loss: 0.5858 r:0.7101
ru_en Dev loss: 0.4591 r:0.7392
Current avg r:0.6932 Best avg r: 0.7430
07:07:54,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:59,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:10:04,926 root INFO Epoch 11 Global steps: 88500 Train loss: 0.1045
ro_en Dev loss: 0.3788 r:0.8080
et_en Dev loss: 0.4932 r:0.6618
si_en Dev loss: 0.9432 r:0.5392
ne_en Dev loss: 0.5917 r:0.7114
ru_en Dev loss: 0.4566 r:0.7368
Current avg r:0.6914 Best avg r: 0.7430
07:13:19,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:14:24,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:29,673 root INFO Epoch 11 Global steps: 89000 Train loss: 0.1091
ro_en Dev loss: 0.3724 r:0.8069
et_en Dev loss: 0.4607 r:0.6581
si_en Dev loss: 0.9033 r:0.5431
ne_en Dev loss: 0.5327 r:0.7142
ru_en Dev loss: 0.4773 r:0.7255
Current avg r:0.6896 Best avg r: 0.7430
07:18:44,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:19:49,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:54,657 root INFO Epoch 11 Global steps: 89500 Train loss: 0.1109
ro_en Dev loss: 0.3770 r:0.8089
et_en Dev loss: 0.4750 r:0.6682
si_en Dev loss: 0.9096 r:0.5443
ne_en Dev loss: 0.5590 r:0.7163
ru_en Dev loss: 0.4611 r:0.7325
Current avg r:0.6940 Best avg r: 0.7430
07:24:17,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:22,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:27,815 root INFO Epoch 11 Global steps: 90000 Train loss: 0.1082
ro_en Dev loss: 0.3812 r:0.8107
et_en Dev loss: 0.5141 r:0.6691
si_en Dev loss: 0.8908 r:0.5481
ne_en Dev loss: 0.5657 r:0.7143
ru_en Dev loss: 0.4836 r:0.7316
Current avg r:0.6947 Best avg r: 0.7430
07:29:43,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:30:48,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:31:53,981 root INFO Epoch 12 Global steps: 90500 Train loss: 0.1079
ro_en Dev loss: 0.4102 r:0.8089
et_en Dev loss: 0.4821 r:0.6591
si_en Dev loss: 0.9773 r:0.5427
ne_en Dev loss: 0.7222 r:0.7106
ru_en Dev loss: 0.5211 r:0.7204
Current avg r:0.6884 Best avg r: 0.7430
07:35:13,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:36:19,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:24,652 root INFO Epoch 12 Global steps: 91000 Train loss: 0.1063
ro_en Dev loss: 0.4007 r:0.8078
et_en Dev loss: 0.4790 r:0.6582
si_en Dev loss: 0.9332 r:0.5405
ne_en Dev loss: 0.6223 r:0.7103
ru_en Dev loss: 0.5248 r:0.7131
Current avg r:0.6860 Best avg r: 0.7430
07:40:46,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:41:52,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:57,631 root INFO Epoch 12 Global steps: 91500 Train loss: 0.1082
ro_en Dev loss: 0.3621 r:0.8119
et_en Dev loss: 0.4478 r:0.6647
si_en Dev loss: 0.9170 r:0.5414
ne_en Dev loss: 0.6621 r:0.7050
ru_en Dev loss: 0.4907 r:0.7119
Current avg r:0.6870 Best avg r: 0.7430
07:46:20,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:25,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:48:30,721 root INFO Epoch 12 Global steps: 92000 Train loss: 0.1035
ro_en Dev loss: 0.3916 r:0.8086
et_en Dev loss: 0.4508 r:0.6621
si_en Dev loss: 0.9856 r:0.5371
ne_en Dev loss: 0.6121 r:0.7160
ru_en Dev loss: 0.4993 r:0.7277
Current avg r:0.6903 Best avg r: 0.7430
07:51:53,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:52:58,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:54:03,746 root INFO Epoch 12 Global steps: 92500 Train loss: 0.1033
ro_en Dev loss: 0.3831 r:0.8076
et_en Dev loss: 0.4848 r:0.6657
si_en Dev loss: 0.9272 r:0.5413
ne_en Dev loss: 0.5995 r:0.7112
ru_en Dev loss: 0.4682 r:0.7354
Current avg r:0.6922 Best avg r: 0.7430
07:57:26,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:58:31,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:59:36,878 root INFO Epoch 12 Global steps: 93000 Train loss: 0.1003
ro_en Dev loss: 0.3605 r:0.8081
et_en Dev loss: 0.4823 r:0.6536
si_en Dev loss: 0.8796 r:0.5383
ne_en Dev loss: 0.5846 r:0.7099
ru_en Dev loss: 0.4936 r:0.7174
Current avg r:0.6854 Best avg r: 0.7430
08:02:59,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:04:04,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:05:09,811 root INFO Epoch 12 Global steps: 93500 Train loss: 0.1059
ro_en Dev loss: 0.3778 r:0.8115
et_en Dev loss: 0.4660 r:0.6620
si_en Dev loss: 0.9659 r:0.5336
ne_en Dev loss: 0.6327 r:0.7128
ru_en Dev loss: 0.5095 r:0.7144
Current avg r:0.6869 Best avg r: 0.7430
08:08:32,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:37,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:42,749 root INFO Epoch 12 Global steps: 94000 Train loss: 0.0973
ro_en Dev loss: 0.3477 r:0.8147
et_en Dev loss: 0.4624 r:0.6687
si_en Dev loss: 0.9079 r:0.5409
ne_en Dev loss: 0.6053 r:0.7125
ru_en Dev loss: 0.4434 r:0.7384
Current avg r:0.6950 Best avg r: 0.7430
08:13:58,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:03,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:08,800 root INFO Epoch 12 Global steps: 94500 Train loss: 0.1033
ro_en Dev loss: 0.3924 r:0.8085
et_en Dev loss: 0.4851 r:0.6618
si_en Dev loss: 0.9314 r:0.5395
ne_en Dev loss: 0.6006 r:0.7123
ru_en Dev loss: 0.5069 r:0.7233
Current avg r:0.6891 Best avg r: 0.7430
08:19:31,28 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:20:36,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:21:41,731 root INFO Epoch 12 Global steps: 95000 Train loss: 0.0983
ro_en Dev loss: 0.3743 r:0.8102
et_en Dev loss: 0.4743 r:0.6616
si_en Dev loss: 0.8672 r:0.5497
ne_en Dev loss: 0.5624 r:0.7075
ru_en Dev loss: 0.4917 r:0.7198
Current avg r:0.6898 Best avg r: 0.7430
08:25:03,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:09,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:27:14,357 root INFO Epoch 12 Global steps: 95500 Train loss: 0.0944
ro_en Dev loss: 0.4057 r:0.8073
et_en Dev loss: 0.4805 r:0.6620
si_en Dev loss: 1.0186 r:0.5359
ne_en Dev loss: 0.6307 r:0.7084
ru_en Dev loss: 0.4921 r:0.7331
Current avg r:0.6893 Best avg r: 0.7430
08:30:28,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:31:34,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:32:39,305 root INFO Epoch 12 Global steps: 96000 Train loss: 0.1037
ro_en Dev loss: 0.4024 r:0.8089
et_en Dev loss: 0.4845 r:0.6643
si_en Dev loss: 1.0241 r:0.5390
ne_en Dev loss: 0.6026 r:0.7119
ru_en Dev loss: 0.5361 r:0.7295
Current avg r:0.6907 Best avg r: 0.7430
08:35:53,772 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:58,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:38:04,95 root INFO Epoch 12 Global steps: 96500 Train loss: 0.0998
ro_en Dev loss: 0.3976 r:0.8123
et_en Dev loss: 0.4754 r:0.6608
si_en Dev loss: 1.0803 r:0.5327
ne_en Dev loss: 0.7249 r:0.7090
ru_en Dev loss: 0.5135 r:0.7323
Current avg r:0.6894 Best avg r: 0.7430
08:41:20,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:26,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:31,918 root INFO Epoch 12 Global steps: 97000 Train loss: 0.0949
ro_en Dev loss: 0.3819 r:0.8127
et_en Dev loss: 0.4721 r:0.6600
si_en Dev loss: 0.9839 r:0.5387
ne_en Dev loss: 0.5861 r:0.7106
ru_en Dev loss: 0.5022 r:0.7292
Current avg r:0.6902 Best avg r: 0.7430
08:46:49,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:55,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:00,961 root INFO Epoch 12 Global steps: 97500 Train loss: 0.1021
ro_en Dev loss: 0.3844 r:0.8076
et_en Dev loss: 0.4909 r:0.6708
si_en Dev loss: 0.9280 r:0.5429
ne_en Dev loss: 0.5925 r:0.7059
ru_en Dev loss: 0.4642 r:0.7387
Current avg r:0.6932 Best avg r: 0.7430
08:52:26,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:32,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:37,796 root INFO Epoch 13 Global steps: 98000 Train loss: 0.0914
ro_en Dev loss: 0.3581 r:0.8153
et_en Dev loss: 0.4677 r:0.6658
si_en Dev loss: 0.8826 r:0.5466
ne_en Dev loss: 0.5270 r:0.7144
ru_en Dev loss: 0.4367 r:0.7452
Current avg r:0.6975 Best avg r: 0.7430
08:57:54,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:59:00,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:00:06,30 root INFO Epoch 13 Global steps: 98500 Train loss: 0.0895
ro_en Dev loss: 0.3584 r:0.8143
et_en Dev loss: 0.4666 r:0.6674
si_en Dev loss: 0.9492 r:0.5408
ne_en Dev loss: 0.5959 r:0.7171
ru_en Dev loss: 0.4644 r:0.7383
Current avg r:0.6956 Best avg r: 0.7430
09:03:21,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:04:26,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:05:32,196 root INFO Epoch 13 Global steps: 99000 Train loss: 0.0903
ro_en Dev loss: 0.3479 r:0.8144
et_en Dev loss: 0.4418 r:0.6736
si_en Dev loss: 0.8715 r:0.5507
ne_en Dev loss: 0.5220 r:0.7162
ru_en Dev loss: 0.4448 r:0.7408
Current avg r:0.6992 Best avg r: 0.7430
09:08:46,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:52,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:57,282 root INFO Epoch 13 Global steps: 99500 Train loss: 0.0918
ro_en Dev loss: 0.3612 r:0.8124
et_en Dev loss: 0.4662 r:0.6694
si_en Dev loss: 0.8724 r:0.5513
ne_en Dev loss: 0.5482 r:0.7139
ru_en Dev loss: 0.4848 r:0.7371
Current avg r:0.6968 Best avg r: 0.7430
09:14:12,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:17,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:22,515 root INFO Epoch 13 Global steps: 100000 Train loss: 0.0916
ro_en Dev loss: 0.3926 r:0.8059
et_en Dev loss: 0.4889 r:0.6538
si_en Dev loss: 1.0046 r:0.5327
ne_en Dev loss: 0.6563 r:0.7003
ru_en Dev loss: 0.4936 r:0.7272
Current avg r:0.6840 Best avg r: 0.7430
09:19:40,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:20:45,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:21:50,774 root INFO Epoch 13 Global steps: 100500 Train loss: 0.0877
ro_en Dev loss: 0.3599 r:0.8099
et_en Dev loss: 0.4351 r:0.6712
si_en Dev loss: 0.8825 r:0.5509
ne_en Dev loss: 0.5515 r:0.7175
ru_en Dev loss: 0.4405 r:0.7449
Current avg r:0.6989 Best avg r: 0.7430
09:25:05,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:26:10,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:27:15,908 root INFO Epoch 13 Global steps: 101000 Train loss: 0.0917
ro_en Dev loss: 0.3713 r:0.8082
et_en Dev loss: 0.4692 r:0.6700
si_en Dev loss: 0.8578 r:0.5559
ne_en Dev loss: 0.5484 r:0.7199
ru_en Dev loss: 0.4616 r:0.7377
Current avg r:0.6983 Best avg r: 0.7430
09:30:30,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:31:35,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:32:41,67 root INFO Epoch 13 Global steps: 101500 Train loss: 0.0934
ro_en Dev loss: 0.3823 r:0.8098
et_en Dev loss: 0.4765 r:0.6529
si_en Dev loss: 1.0039 r:0.5369
ne_en Dev loss: 0.6589 r:0.7138
ru_en Dev loss: 0.4742 r:0.7293
Current avg r:0.6885 Best avg r: 0.7430
09:36:03,486 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:37:08,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:38:14,226 root INFO Epoch 13 Global steps: 102000 Train loss: 0.0844
ro_en Dev loss: 0.3602 r:0.8123
et_en Dev loss: 0.4748 r:0.6671
si_en Dev loss: 0.8391 r:0.5526
ne_en Dev loss: 0.5450 r:0.7125
ru_en Dev loss: 0.4642 r:0.7343
Current avg r:0.6958 Best avg r: 0.7430
09:41:35,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:40,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:45,857 root INFO Epoch 13 Global steps: 102500 Train loss: 0.0891
ro_en Dev loss: 0.3681 r:0.8106
et_en Dev loss: 0.4775 r:0.6730
si_en Dev loss: 0.8751 r:0.5524
ne_en Dev loss: 0.5558 r:0.7212
ru_en Dev loss: 0.4460 r:0.7402
Current avg r:0.6995 Best avg r: 0.7430
09:47:00,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:05,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:11,181 root INFO Epoch 13 Global steps: 103000 Train loss: 0.0906
ro_en Dev loss: 0.3674 r:0.8076
et_en Dev loss: 0.4617 r:0.6509
si_en Dev loss: 0.9955 r:0.5349
ne_en Dev loss: 0.6593 r:0.7157
ru_en Dev loss: 0.4728 r:0.7225
Current avg r:0.6863 Best avg r: 0.7430
09:52:25,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:31,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:54:36,419 root INFO Epoch 13 Global steps: 103500 Train loss: 0.0900
ro_en Dev loss: 0.3538 r:0.8135
et_en Dev loss: 0.4590 r:0.6630
si_en Dev loss: 0.8661 r:0.5500
ne_en Dev loss: 0.5314 r:0.7087
ru_en Dev loss: 0.4643 r:0.7340
Current avg r:0.6938 Best avg r: 0.7430
09:57:51,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:56,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:01,441 root INFO Epoch 13 Global steps: 104000 Train loss: 0.0896
ro_en Dev loss: 0.3523 r:0.8093
et_en Dev loss: 0.4661 r:0.6595
si_en Dev loss: 0.8940 r:0.5463
ne_en Dev loss: 0.5715 r:0.7081
ru_en Dev loss: 0.4451 r:0.7337
Current avg r:0.6914 Best avg r: 0.7430
10:03:16,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:21,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:26,575 root INFO Epoch 13 Global steps: 104500 Train loss: 0.0895
ro_en Dev loss: 0.3492 r:0.8138
et_en Dev loss: 0.4543 r:0.6617
si_en Dev loss: 0.8795 r:0.5526
ne_en Dev loss: 0.5506 r:0.7119
ru_en Dev loss: 0.4339 r:0.7514
Current avg r:0.6983 Best avg r: 0.7430
10:08:43,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:09:48,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:54,650 root INFO Epoch 13 Global steps: 105000 Train loss: 0.0882
ro_en Dev loss: 0.3375 r:0.8147
et_en Dev loss: 0.4376 r:0.6757
si_en Dev loss: 0.8092 r:0.5627
ne_en Dev loss: 0.5116 r:0.7227
ru_en Dev loss: 0.4273 r:0.7495
Current avg r:0.7050 Best avg r: 0.7430
10:14:19,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:15:25,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:16:30,786 root INFO Epoch 14 Global steps: 105500 Train loss: 0.0834
ro_en Dev loss: 0.3834 r:0.8105
et_en Dev loss: 0.4603 r:0.6625
si_en Dev loss: 0.9048 r:0.5539
ne_en Dev loss: 0.5474 r:0.7168
ru_en Dev loss: 0.4804 r:0.7438
Current avg r:0.6975 Best avg r: 0.7430
10:19:48,772 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:54,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:00,312 root INFO Epoch 14 Global steps: 106000 Train loss: 0.0834
ro_en Dev loss: 0.3765 r:0.8096
et_en Dev loss: 0.4678 r:0.6689
si_en Dev loss: 0.9079 r:0.5538
ne_en Dev loss: 0.6120 r:0.7111
ru_en Dev loss: 0.4624 r:0.7506
Current avg r:0.6988 Best avg r: 0.7430
10:25:19,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:26:25,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:31,297 root INFO Epoch 14 Global steps: 106500 Train loss: 0.0865
ro_en Dev loss: 0.3635 r:0.8088
et_en Dev loss: 0.4895 r:0.6641
si_en Dev loss: 0.8900 r:0.5495
ne_en Dev loss: 0.5741 r:0.7044
ru_en Dev loss: 0.4582 r:0.7430
Current avg r:0.6940 Best avg r: 0.7430
10:30:47,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:31:52,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
