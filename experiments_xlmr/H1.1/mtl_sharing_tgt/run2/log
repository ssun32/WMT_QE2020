14:36:39,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:05,171 root INFO 
id:ro_en cur r: 0.5767 best r: 0.5767
14:37:31,332 root INFO 
id:et_en cur r: 0.5430 best r: 0.5430
14:37:57,517 root INFO 
id:si_en cur r: 0.4550 best r: 0.4550
14:38:23,702 root INFO 
id:ne_en cur r: 0.3786 best r: 0.3786
14:38:49,706 root INFO 
id:ru_en cur r: 0.5325 best r: 0.5325
14:38:49,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:56,357 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:39:56,362 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
14:39:56,367 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
14:39:56,373 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:39:56,378 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:41:01,687 root INFO Epoch 0 Global steps: 500 Train loss: 0.8853
ro_en Dev loss: 0.6403 r:0.5896
et_en Dev loss: 0.6338 r:0.5488
si_en Dev loss: 0.6481 r:0.4553
ne_en Dev loss: 0.7314 r:0.5497
ru_en Dev loss: 0.7380 r:0.5002
Current avg r:0.5287 Best avg r: 0.5287
14:44:16,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:42,354 root INFO 
id:ro_en cur r: 0.6453 best r: 0.6453
14:45:08,553 root INFO 
id:et_en cur r: 0.5842 best r: 0.5842
14:45:47,867 root INFO 
id:ne_en cur r: 0.4021 best r: 0.4021
14:46:13,903 root INFO 
id:ru_en cur r: 0.5865 best r: 0.5865
14:46:13,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:19,267 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:47:19,279 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
14:47:19,285 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
14:47:19,291 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:47:19,296 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:48:24,644 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8270
ro_en Dev loss: 0.5693 r:0.6458
et_en Dev loss: 0.4985 r:0.5782
si_en Dev loss: 0.7285 r:0.4697
ne_en Dev loss: 0.5648 r:0.5646
ru_en Dev loss: 0.5388 r:0.6569
Current avg r:0.5831 Best avg r: 0.5831
14:51:39,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:05,284 root INFO 
id:ro_en cur r: 0.6521 best r: 0.6521
14:52:31,472 root INFO 
id:et_en cur r: 0.5914 best r: 0.5914
14:53:10,766 root INFO 
id:ne_en cur r: 0.4376 best r: 0.4376
14:53:23,772 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:29,108 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:54:29,115 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
14:54:29,119 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
14:54:29,124 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:54:29,129 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:55:34,494 root INFO Epoch 0 Global steps: 1500 Train loss: 0.7273
ro_en Dev loss: 0.5604 r:0.6613
et_en Dev loss: 0.4921 r:0.5769
si_en Dev loss: 0.7650 r:0.4665
ne_en Dev loss: 0.5662 r:0.5766
ru_en Dev loss: 0.5546 r:0.6713
Current avg r:0.5905 Best avg r: 0.5905
14:58:49,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:15,251 root INFO 
id:ro_en cur r: 0.6880 best r: 0.6880
14:59:41,427 root INFO 
id:et_en cur r: 0.6503 best r: 0.6503
15:00:07,624 root INFO 
id:si_en cur r: 0.4962 best r: 0.4962
15:00:33,824 root INFO 
id:ne_en cur r: 0.5933 best r: 0.5933
15:00:59,837 root INFO 
id:ru_en cur r: 0.6664 best r: 0.6664
15:00:59,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:05,160 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:02:05,167 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
15:02:05,172 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
15:02:05,176 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:02:05,181 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:03:10,539 root INFO Epoch 0 Global steps: 2000 Train loss: 0.6876
ro_en Dev loss: 0.4972 r:0.6985
et_en Dev loss: 0.4188 r:0.6559
si_en Dev loss: 0.6986 r:0.5317
ne_en Dev loss: 0.5445 r:0.6361
ru_en Dev loss: 0.5294 r:0.7023
Current avg r:0.6449 Best avg r: 0.6449
15:06:25,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:04,314 root INFO 
id:et_en cur r: 0.6629 best r: 0.6629
15:07:30,509 root INFO 
id:si_en cur r: 0.5065 best r: 0.5065
15:07:56,698 root INFO 
id:ne_en cur r: 0.6584 best r: 0.6584
15:08:22,726 root INFO 
id:ru_en cur r: 0.6961 best r: 0.6961
15:08:22,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:28,61 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:09:28,68 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
15:09:28,73 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
15:09:28,78 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:09:28,83 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:10:33,463 root INFO Epoch 0 Global steps: 2500 Train loss: 0.6790
ro_en Dev loss: 0.4275 r:0.7115
et_en Dev loss: 0.4039 r:0.6645
si_en Dev loss: 0.6058 r:0.5405
ne_en Dev loss: 0.4541 r:0.6707
ru_en Dev loss: 0.4343 r:0.7197
Current avg r:0.6614 Best avg r: 0.6614
15:13:48,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:14,209 root INFO 
id:ro_en cur r: 0.7138 best r: 0.7138
15:15:06,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:11,782 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6310
ro_en Dev loss: 0.4794 r:0.7283
et_en Dev loss: 0.4134 r:0.6560
si_en Dev loss: 0.8352 r:0.5098
ne_en Dev loss: 0.5752 r:0.6262
ru_en Dev loss: 0.5497 r:0.7114
Current avg r:0.6463 Best avg r: 0.6614
15:19:26,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:52,472 root INFO 
id:ro_en cur r: 0.7286 best r: 0.7286
15:20:44,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:50,16 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6003
ro_en Dev loss: 0.4548 r:0.7395
et_en Dev loss: 0.4078 r:0.6601
si_en Dev loss: 0.7822 r:0.5208
ne_en Dev loss: 0.4991 r:0.6502
ru_en Dev loss: 0.5167 r:0.7121
Current avg r:0.6565 Best avg r: 0.6614
15:25:04,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:30,730 root INFO 
id:ro_en cur r: 0.7552 best r: 0.7552
15:25:56,901 root INFO 
id:et_en cur r: 0.6773 best r: 0.6773
15:26:23,91 root INFO 
id:si_en cur r: 0.5268 best r: 0.5268
15:26:49,274 root INFO 
id:ne_en cur r: 0.6722 best r: 0.6722
15:27:15,276 root INFO 
id:ru_en cur r: 0.7000 best r: 0.7000
15:27:15,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:20,576 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:28:20,582 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
15:28:20,592 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
15:28:20,597 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:28:20,602 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:29:25,946 root INFO Epoch 0 Global steps: 4000 Train loss: 0.5975
ro_en Dev loss: 0.4069 r:0.7671
et_en Dev loss: 0.3861 r:0.6827
si_en Dev loss: 0.7168 r:0.5526
ne_en Dev loss: 0.4579 r:0.6913
ru_en Dev loss: 0.5135 r:0.7205
Current avg r:0.6828 Best avg r: 0.6828
15:32:40,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:06,788 root INFO 
id:ro_en cur r: 0.7611 best r: 0.7611
15:33:32,969 root INFO 
id:et_en cur r: 0.6802 best r: 0.6802
15:34:12,258 root INFO 
id:ne_en cur r: 0.6805 best r: 0.6805
15:34:38,268 root INFO 
id:ru_en cur r: 0.7070 best r: 0.7070
15:34:38,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:43,596 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:35:43,605 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
15:35:43,613 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
15:35:43,622 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:35:43,631 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:36:48,986 root INFO Epoch 0 Global steps: 4500 Train loss: 0.5591
ro_en Dev loss: 0.3670 r:0.7734
et_en Dev loss: 0.3752 r:0.6875
si_en Dev loss: 0.6576 r:0.5493
ne_en Dev loss: 0.4135 r:0.6986
ru_en Dev loss: 0.4638 r:0.7314
Current avg r:0.6880 Best avg r: 0.6880
15:40:03,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:29,843 root INFO 
id:ro_en cur r: 0.7701 best r: 0.7701
15:40:56,19 root INFO 
id:et_en cur r: 0.6864 best r: 0.6864
15:41:22,235 root INFO 
id:si_en cur r: 0.5519 best r: 0.5519
15:41:48,432 root INFO 
id:ne_en cur r: 0.7095 best r: 0.7095
15:42:14,467 root INFO 
id:ru_en cur r: 0.7189 best r: 0.7189
15:42:14,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:19,810 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:43:19,816 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
15:43:19,821 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
15:43:19,825 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:43:19,830 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:44:25,211 root INFO Epoch 0 Global steps: 5000 Train loss: 0.5901
ro_en Dev loss: 0.3494 r:0.7790
et_en Dev loss: 0.3674 r:0.6937
si_en Dev loss: 0.5916 r:0.5736
ne_en Dev loss: 0.4130 r:0.7104
ru_en Dev loss: 0.4258 r:0.7380
Current avg r:0.6989 Best avg r: 0.6989
15:47:39,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:06,85 root INFO 
id:ro_en cur r: 0.7818 best r: 0.7818
15:48:32,268 root INFO 
id:et_en cur r: 0.6884 best r: 0.6884
15:48:58,480 root INFO 
id:si_en cur r: 0.5555 best r: 0.5555
15:49:24,690 root INFO 
id:ne_en cur r: 0.7304 best r: 0.7304
15:49:50,714 root INFO 
id:ru_en cur r: 0.7406 best r: 0.7406
15:49:50,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:56,87 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:50:56,94 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
15:50:56,99 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
15:50:56,104 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:50:56,108 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:52:01,509 root INFO Epoch 0 Global steps: 5500 Train loss: 0.5453
ro_en Dev loss: 0.3497 r:0.7902
et_en Dev loss: 0.3722 r:0.6982
si_en Dev loss: 0.6823 r:0.5774
ne_en Dev loss: 0.4230 r:0.7257
ru_en Dev loss: 0.4652 r:0.7455
Current avg r:0.7074 Best avg r: 0.7074
15:55:16,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:21,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:26,828 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5276
ro_en Dev loss: 0.3664 r:0.7837
et_en Dev loss: 0.3859 r:0.6885
si_en Dev loss: 0.6945 r:0.5687
ne_en Dev loss: 0.4567 r:0.7176
ru_en Dev loss: 0.5431 r:0.7224
Current avg r:0.6962 Best avg r: 0.7074
16:00:41,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:46,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:51,933 root INFO Epoch 0 Global steps: 6500 Train loss: 0.5045
ro_en Dev loss: 0.3464 r:0.7860
et_en Dev loss: 0.3680 r:0.6959
si_en Dev loss: 0.6604 r:0.5738
ne_en Dev loss: 0.4180 r:0.7221
ru_en Dev loss: 0.4633 r:0.7369
Current avg r:0.7029 Best avg r: 0.7074
16:06:06,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:32,564 root INFO 
id:ro_en cur r: 0.7910 best r: 0.7910
16:06:58,731 root INFO 
id:et_en cur r: 0.7001 best r: 0.7001
16:07:24,914 root INFO 
id:si_en cur r: 0.5565 best r: 0.5565
16:07:51,93 root INFO 
id:ne_en cur r: 0.7358 best r: 0.7358
16:08:04,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:09,389 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:09:09,395 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
16:09:09,401 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
16:09:09,408 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:09:09,414 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:10:14,753 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5178
ro_en Dev loss: 0.3468 r:0.7993
et_en Dev loss: 0.3569 r:0.7087
si_en Dev loss: 0.6541 r:0.5809
ne_en Dev loss: 0.3849 r:0.7372
ru_en Dev loss: 0.4521 r:0.7448
Current avg r:0.7142 Best avg r: 0.7142
16:13:29,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:55,410 root INFO 
id:ro_en cur r: 0.7943 best r: 0.7943
16:14:34,677 root INFO 
id:si_en cur r: 0.5603 best r: 0.5603
16:15:00,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:06,56 root INFO Epoch 0 Global steps: 7500 Train loss: 0.5313
ro_en Dev loss: 0.3311 r:0.7991
et_en Dev loss: 0.3649 r:0.7038
si_en Dev loss: 0.6384 r:0.5820
ne_en Dev loss: 0.3804 r:0.7356
ru_en Dev loss: 0.4349 r:0.7434
Current avg r:0.7128 Best avg r: 0.7142
16:19:21,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:28,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:33,904 root INFO Epoch 1 Global steps: 8000 Train loss: 0.4846
ro_en Dev loss: 0.4100 r:0.7909
et_en Dev loss: 0.4305 r:0.6782
si_en Dev loss: 0.8250 r:0.5522
ne_en Dev loss: 0.5883 r:0.6987
ru_en Dev loss: 0.6117 r:0.7089
Current avg r:0.6858 Best avg r: 0.7142
16:24:48,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:14,906 root INFO 
id:ro_en cur r: 0.8016 best r: 0.8016
16:25:54,177 root INFO 
id:si_en cur r: 0.5651 best r: 0.5651
16:26:20,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:25,631 root INFO Epoch 1 Global steps: 8500 Train loss: 0.4920
ro_en Dev loss: 0.3427 r:0.8049
et_en Dev loss: 0.3828 r:0.6965
si_en Dev loss: 0.7035 r:0.5804
ne_en Dev loss: 0.5150 r:0.7276
ru_en Dev loss: 0.5118 r:0.7292
Current avg r:0.7077 Best avg r: 0.7142
16:30:40,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:32,759 root INFO 
id:si_en cur r: 0.5677 best r: 0.5677
16:31:58,960 root INFO 
id:ne_en cur r: 0.7413 best r: 0.7413
16:32:11,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:17,343 root INFO Epoch 1 Global steps: 9000 Train loss: 0.4898
ro_en Dev loss: 0.3390 r:0.8062
et_en Dev loss: 0.3747 r:0.7014
si_en Dev loss: 0.7715 r:0.5764
ne_en Dev loss: 0.4295 r:0.7390
ru_en Dev loss: 0.4633 r:0.7476
Current avg r:0.7141 Best avg r: 0.7142
16:36:32,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:58,278 root INFO 
id:ro_en cur r: 0.8068 best r: 0.8068
16:37:24,480 root INFO 
id:et_en cur r: 0.7032 best r: 0.7032
16:37:50,692 root INFO 
id:si_en cur r: 0.5789 best r: 0.5789
16:38:16,917 root INFO 
id:ne_en cur r: 0.7553 best r: 0.7553
16:38:29,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:35,312 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:39:35,320 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
16:39:35,326 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
16:39:35,330 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:39:35,336 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:40:40,787 root INFO Epoch 1 Global steps: 9500 Train loss: 0.4706
ro_en Dev loss: 0.3218 r:0.8123
et_en Dev loss: 0.3581 r:0.7074
si_en Dev loss: 0.6624 r:0.5836
ne_en Dev loss: 0.4060 r:0.7471
ru_en Dev loss: 0.4254 r:0.7467
Current avg r:0.7194 Best avg r: 0.7194
16:43:55,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:21,613 root INFO 
id:ro_en cur r: 0.8125 best r: 0.8125
16:45:00,922 root INFO 
id:si_en cur r: 0.5938 best r: 0.5938
16:45:27,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:32,404 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:46:32,413 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
16:46:32,418 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
16:46:32,424 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:46:32,429 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:47:37,825 root INFO Epoch 1 Global steps: 10000 Train loss: 0.4768
ro_en Dev loss: 0.3143 r:0.8165
et_en Dev loss: 0.3551 r:0.7072
si_en Dev loss: 0.6039 r:0.6024
ne_en Dev loss: 0.4007 r:0.7521
ru_en Dev loss: 0.5036 r:0.7324
Current avg r:0.7221 Best avg r: 0.7221
16:50:52,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:57,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:02,822 root INFO Epoch 1 Global steps: 10500 Train loss: 0.4713
ro_en Dev loss: 0.3540 r:0.8105
et_en Dev loss: 0.3652 r:0.7041
si_en Dev loss: 0.6837 r:0.5889
ne_en Dev loss: 0.4219 r:0.7467
ru_en Dev loss: 0.4906 r:0.7419
Current avg r:0.7184 Best avg r: 0.7221
16:56:17,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:43,239 root INFO 
id:ro_en cur r: 0.8181 best r: 0.8181
16:57:22,482 root INFO 
id:si_en cur r: 0.6105 best r: 0.6105
16:57:48,649 root INFO 
id:ne_en cur r: 0.7636 best r: 0.7636
16:58:01,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:06,884 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:59:06,890 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
16:59:06,897 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
16:59:06,902 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:59:06,907 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:00:12,197 root INFO Epoch 1 Global steps: 11000 Train loss: 0.4800
ro_en Dev loss: 0.3078 r:0.8176
et_en Dev loss: 0.3662 r:0.7068
si_en Dev loss: 0.6210 r:0.6025
ne_en Dev loss: 0.4051 r:0.7575
ru_en Dev loss: 0.4363 r:0.7470
Current avg r:0.7263 Best avg r: 0.7263
17:03:26,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:44,708 root INFO 
id:ru_en cur r: 0.7465 best r: 0.7465
17:04:44,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:49,942 root INFO Epoch 1 Global steps: 11500 Train loss: 0.4735
ro_en Dev loss: 0.3276 r:0.8108
et_en Dev loss: 0.3669 r:0.7023
si_en Dev loss: 0.6228 r:0.5997
ne_en Dev loss: 0.3879 r:0.7543
ru_en Dev loss: 0.4281 r:0.7519
Current avg r:0.7238 Best avg r: 0.7263
17:09:04,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:09,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:14,708 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4491
ro_en Dev loss: 0.3801 r:0.8085
et_en Dev loss: 0.3869 r:0.7017
si_en Dev loss: 0.7185 r:0.5943
ne_en Dev loss: 0.3891 r:0.7606
ru_en Dev loss: 0.5053 r:0.7398
Current avg r:0.7210 Best avg r: 0.7263
17:14:28,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:34,305 root INFO 
id:ne_en cur r: 0.7641 best r: 0.7641
17:15:47,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:52,536 root INFO Epoch 1 Global steps: 12500 Train loss: 0.4484
ro_en Dev loss: 0.4071 r:0.8101
et_en Dev loss: 0.4044 r:0.7039
si_en Dev loss: 0.8396 r:0.5864
ne_en Dev loss: 0.5339 r:0.7534
ru_en Dev loss: 0.5469 r:0.7367
Current avg r:0.7181 Best avg r: 0.7263
17:20:06,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:12,114 root INFO 
id:ne_en cur r: 0.7667 best r: 0.7667
17:21:25,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:30,357 root INFO Epoch 1 Global steps: 13000 Train loss: 0.4339
ro_en Dev loss: 0.3585 r:0.8139
et_en Dev loss: 0.3774 r:0.7067
si_en Dev loss: 0.7149 r:0.5966
ne_en Dev loss: 0.4252 r:0.7556
ru_en Dev loss: 0.4948 r:0.7450
Current avg r:0.7236 Best avg r: 0.7263
17:25:44,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:10,666 root INFO 
id:ro_en cur r: 0.8181 best r: 0.8181
17:26:36,803 root INFO 
id:et_en cur r: 0.7086 best r: 0.7086
17:27:16,19 root INFO 
id:ne_en cur r: 0.7722 best r: 0.7722
17:27:41,994 root INFO 
id:ru_en cur r: 0.7665 best r: 0.7665
17:27:41,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:47,214 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:28:47,221 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
17:28:47,226 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
17:28:47,231 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:28:47,236 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:29:52,483 root INFO Epoch 1 Global steps: 13500 Train loss: 0.4498
ro_en Dev loss: 0.3412 r:0.8157
et_en Dev loss: 0.3705 r:0.7075
si_en Dev loss: 0.6816 r:0.6011
ne_en Dev loss: 0.3621 r:0.7618
ru_en Dev loss: 0.4243 r:0.7656
Current avg r:0.7303 Best avg r: 0.7303
17:33:06,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:32,799 root INFO 
id:ro_en cur r: 0.8210 best r: 0.8210
17:34:24,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:30,205 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4592
ro_en Dev loss: 0.3394 r:0.8190
et_en Dev loss: 0.3820 r:0.7043
si_en Dev loss: 0.7255 r:0.6000
ne_en Dev loss: 0.4322 r:0.7612
ru_en Dev loss: 0.4570 r:0.7550
Current avg r:0.7279 Best avg r: 0.7303
17:38:44,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:10,504 root INFO 
id:ro_en cur r: 0.8269 best r: 0.8269
17:39:36,639 root INFO 
id:et_en cur r: 0.7160 best r: 0.7160
17:40:02,796 root INFO 
id:si_en cur r: 0.6181 best r: 0.6181
17:40:28,946 root INFO 
id:ne_en cur r: 0.7800 best r: 0.7800
17:40:54,914 root INFO 
id:ru_en cur r: 0.7786 best r: 0.7786
17:40:54,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:00,148 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:42:00,155 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
17:42:00,160 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
17:42:00,165 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:42:00,170 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:43:05,434 root INFO Epoch 1 Global steps: 14500 Train loss: 0.4308
ro_en Dev loss: 0.2964 r:0.8242
et_en Dev loss: 0.3536 r:0.7177
si_en Dev loss: 0.6098 r:0.6192
ne_en Dev loss: 0.3315 r:0.7743
ru_en Dev loss: 0.3454 r:0.7798
Current avg r:0.7430 Best avg r: 0.7430
17:46:19,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:24,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:30,82 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4309
ro_en Dev loss: 0.4079 r:0.8113
et_en Dev loss: 0.4162 r:0.6989
si_en Dev loss: 0.7930 r:0.5974
ne_en Dev loss: 0.4685 r:0.7594
ru_en Dev loss: 0.5246 r:0.7515
Current avg r:0.7237 Best avg r: 0.7430
17:51:45,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:50,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:55,768 root INFO Epoch 2 Global steps: 15500 Train loss: 0.4086
ro_en Dev loss: 0.3264 r:0.8193
et_en Dev loss: 0.3802 r:0.7088
si_en Dev loss: 0.7028 r:0.6060
ne_en Dev loss: 0.3346 r:0.7719
ru_en Dev loss: 0.3851 r:0.7763
Current avg r:0.7364 Best avg r: 0.7430
17:57:10,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:15,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:20,485 root INFO Epoch 2 Global steps: 16000 Train loss: 0.3953
ro_en Dev loss: 0.3127 r:0.8205
et_en Dev loss: 0.3626 r:0.7049
si_en Dev loss: 0.7393 r:0.6010
ne_en Dev loss: 0.4432 r:0.7646
ru_en Dev loss: 0.4227 r:0.7557
Current avg r:0.7293 Best avg r: 0.7430
18:02:36,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:41,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:46,450 root INFO Epoch 2 Global steps: 16500 Train loss: 0.3986
ro_en Dev loss: 0.3205 r:0.8170
et_en Dev loss: 0.3666 r:0.7103
si_en Dev loss: 0.7015 r:0.6060
ne_en Dev loss: 0.3880 r:0.7674
ru_en Dev loss: 0.4220 r:0.7610
Current avg r:0.7323 Best avg r: 0.7430
18:08:00,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:05,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:11,96 root INFO Epoch 2 Global steps: 17000 Train loss: 0.4038
ro_en Dev loss: 0.4093 r:0.8086
et_en Dev loss: 0.4065 r:0.6983
si_en Dev loss: 0.8365 r:0.5946
ne_en Dev loss: 0.4990 r:0.7625
ru_en Dev loss: 0.5200 r:0.7400
Current avg r:0.7208 Best avg r: 0.7430
18:13:25,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:30,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:35,753 root INFO Epoch 2 Global steps: 17500 Train loss: 0.3950
ro_en Dev loss: 0.3384 r:0.8144
et_en Dev loss: 0.3836 r:0.7050
si_en Dev loss: 0.6767 r:0.6057
ne_en Dev loss: 0.3822 r:0.7594
ru_en Dev loss: 0.4398 r:0.7436
Current avg r:0.7256 Best avg r: 0.7430
18:18:50,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:55,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:00,477 root INFO Epoch 2 Global steps: 18000 Train loss: 0.3961
ro_en Dev loss: 0.3419 r:0.8174
et_en Dev loss: 0.3852 r:0.7038
si_en Dev loss: 0.7021 r:0.6062
ne_en Dev loss: 0.4168 r:0.7655
ru_en Dev loss: 0.4659 r:0.7422
Current avg r:0.7270 Best avg r: 0.7430
18:24:14,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:20,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:25,283 root INFO Epoch 2 Global steps: 18500 Train loss: 0.3801
ro_en Dev loss: 0.3223 r:0.8174
et_en Dev loss: 0.3847 r:0.7039
si_en Dev loss: 0.6309 r:0.6099
ne_en Dev loss: 0.3670 r:0.7655
ru_en Dev loss: 0.4296 r:0.7485
Current avg r:0.7291 Best avg r: 0.7430
18:29:39,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:44,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:50,75 root INFO Epoch 2 Global steps: 19000 Train loss: 0.3965
ro_en Dev loss: 0.3263 r:0.8194
et_en Dev loss: 0.3800 r:0.7033
si_en Dev loss: 0.6503 r:0.6082
ne_en Dev loss: 0.3684 r:0.7726
ru_en Dev loss: 0.4350 r:0.7547
Current avg r:0.7316 Best avg r: 0.7430
18:35:04,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:09,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:14,996 root INFO Epoch 2 Global steps: 19500 Train loss: 0.3775
ro_en Dev loss: 0.3099 r:0.8182
et_en Dev loss: 0.3680 r:0.7006
si_en Dev loss: 0.7211 r:0.5979
ne_en Dev loss: 0.4280 r:0.7630
ru_en Dev loss: 0.3977 r:0.7594
Current avg r:0.7278 Best avg r: 0.7430
18:40:29,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:34,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:39,900 root INFO Epoch 2 Global steps: 20000 Train loss: 0.3924
ro_en Dev loss: 0.3408 r:0.8152
et_en Dev loss: 0.3782 r:0.7006
si_en Dev loss: 0.7756 r:0.5952
ne_en Dev loss: 0.4187 r:0.7692
ru_en Dev loss: 0.4115 r:0.7596
Current avg r:0.7280 Best avg r: 0.7430
18:45:54,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:59,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:04,669 root INFO Epoch 2 Global steps: 20500 Train loss: 0.3737
ro_en Dev loss: 0.3894 r:0.8110
et_en Dev loss: 0.4057 r:0.6877
si_en Dev loss: 0.7848 r:0.5936
ne_en Dev loss: 0.4978 r:0.7631
ru_en Dev loss: 0.5447 r:0.7276
Current avg r:0.7166 Best avg r: 0.7430
18:51:24,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:29,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:34,998 root INFO Epoch 2 Global steps: 21000 Train loss: 0.3901
ro_en Dev loss: 0.3715 r:0.8105
et_en Dev loss: 0.3845 r:0.6942
si_en Dev loss: 0.7142 r:0.6015
ne_en Dev loss: 0.4437 r:0.7644
ru_en Dev loss: 0.4773 r:0.7407
Current avg r:0.7223 Best avg r: 0.7430
18:56:56,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:02,174 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:07,424 root INFO Epoch 2 Global steps: 21500 Train loss: 0.3626
ro_en Dev loss: 0.3708 r:0.8110
et_en Dev loss: 0.4248 r:0.6966
si_en Dev loss: 0.6975 r:0.6052
ne_en Dev loss: 0.4200 r:0.7612
ru_en Dev loss: 0.5153 r:0.7357
Current avg r:0.7220 Best avg r: 0.7430
19:02:29,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:34,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:39,853 root INFO Epoch 2 Global steps: 22000 Train loss: 0.3825
ro_en Dev loss: 0.3822 r:0.8099
et_en Dev loss: 0.4065 r:0.6882
si_en Dev loss: 0.8107 r:0.5991
ne_en Dev loss: 0.5052 r:0.7636
ru_en Dev loss: 0.5729 r:0.7163
Current avg r:0.7154 Best avg r: 0.7430
19:08:01,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:06,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:12,340 root INFO Epoch 2 Global steps: 22500 Train loss: 0.3831
ro_en Dev loss: 0.3269 r:0.8173
et_en Dev loss: 0.3894 r:0.7010
si_en Dev loss: 0.6951 r:0.6101
ne_en Dev loss: 0.4245 r:0.7686
ru_en Dev loss: 0.4062 r:0.7615
Current avg r:0.7317 Best avg r: 0.7430
19:13:27,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:33,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:38,348 root INFO Epoch 3 Global steps: 23000 Train loss: 0.3362
ro_en Dev loss: 0.3408 r:0.8171
et_en Dev loss: 0.3997 r:0.6951
si_en Dev loss: 0.7651 r:0.5996
ne_en Dev loss: 0.4252 r:0.7641
ru_en Dev loss: 0.4606 r:0.7405
Current avg r:0.7233 Best avg r: 0.7430
19:18:52,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:58,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:03,338 root INFO Epoch 3 Global steps: 23500 Train loss: 0.3460
ro_en Dev loss: 0.3801 r:0.8151
et_en Dev loss: 0.4088 r:0.6991
si_en Dev loss: 0.8033 r:0.6110
ne_en Dev loss: 0.4269 r:0.7663
ru_en Dev loss: 0.5806 r:0.7264
Current avg r:0.7236 Best avg r: 0.7430
19:24:17,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:22,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:28,84 root INFO Epoch 3 Global steps: 24000 Train loss: 0.3341
ro_en Dev loss: 0.3747 r:0.8150
et_en Dev loss: 0.4186 r:0.6877
si_en Dev loss: 0.8285 r:0.5965
ne_en Dev loss: 0.4775 r:0.7629
ru_en Dev loss: 0.5058 r:0.7331
Current avg r:0.7190 Best avg r: 0.7430
19:29:42,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:47,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:52,788 root INFO Epoch 3 Global steps: 24500 Train loss: 0.3500
ro_en Dev loss: 0.3342 r:0.8157
et_en Dev loss: 0.4079 r:0.6894
si_en Dev loss: 0.7197 r:0.6026
ne_en Dev loss: 0.4033 r:0.7637
ru_en Dev loss: 0.4657 r:0.7344
Current avg r:0.7212 Best avg r: 0.7430
19:35:07,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:12,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:17,509 root INFO Epoch 3 Global steps: 25000 Train loss: 0.3349
ro_en Dev loss: 0.3661 r:0.8069
et_en Dev loss: 0.4141 r:0.6912
si_en Dev loss: 0.7693 r:0.5916
ne_en Dev loss: 0.4954 r:0.7466
ru_en Dev loss: 0.5075 r:0.7228
Current avg r:0.7118 Best avg r: 0.7430
19:40:31,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:37,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:42,296 root INFO Epoch 3 Global steps: 25500 Train loss: 0.3513
ro_en Dev loss: 0.3513 r:0.8069
et_en Dev loss: 0.4027 r:0.6958
si_en Dev loss: 0.7438 r:0.5968
ne_en Dev loss: 0.4824 r:0.7533
ru_en Dev loss: 0.4534 r:0.7247
Current avg r:0.7155 Best avg r: 0.7430
19:45:56,602 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:01,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:07,74 root INFO Epoch 3 Global steps: 26000 Train loss: 0.3513
ro_en Dev loss: 0.3216 r:0.8146
et_en Dev loss: 0.3847 r:0.7051
si_en Dev loss: 0.6079 r:0.6092
ne_en Dev loss: 0.3785 r:0.7573
ru_en Dev loss: 0.4444 r:0.7137
Current avg r:0.7200 Best avg r: 0.7430
19:51:21,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:26,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:31,843 root INFO Epoch 3 Global steps: 26500 Train loss: 0.3268
ro_en Dev loss: 0.3507 r:0.8137
et_en Dev loss: 0.3895 r:0.6962
si_en Dev loss: 0.7558 r:0.5984
ne_en Dev loss: 0.4678 r:0.7573
ru_en Dev loss: 0.4415 r:0.7386
Current avg r:0.7208 Best avg r: 0.7430
19:56:46,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:51,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:56,685 root INFO Epoch 3 Global steps: 27000 Train loss: 0.3511
ro_en Dev loss: 0.3406 r:0.8109
et_en Dev loss: 0.3983 r:0.6888
si_en Dev loss: 0.7186 r:0.5926
ne_en Dev loss: 0.4053 r:0.7507
ru_en Dev loss: 0.5252 r:0.6912
Current avg r:0.7069 Best avg r: 0.7430
20:02:11,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:16,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:21,481 root INFO Epoch 3 Global steps: 27500 Train loss: 0.3402
ro_en Dev loss: 0.3294 r:0.8154
et_en Dev loss: 0.3876 r:0.6976
si_en Dev loss: 0.7175 r:0.5978
ne_en Dev loss: 0.4127 r:0.7512
ru_en Dev loss: 0.4436 r:0.7292
Current avg r:0.7182 Best avg r: 0.7430
20:07:35,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:41,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:46,227 root INFO Epoch 3 Global steps: 28000 Train loss: 0.3126
ro_en Dev loss: 0.3743 r:0.8149
et_en Dev loss: 0.4015 r:0.6868
si_en Dev loss: 0.7968 r:0.5885
ne_en Dev loss: 0.4651 r:0.7548
ru_en Dev loss: 0.5267 r:0.7101
Current avg r:0.7110 Best avg r: 0.7430
20:13:00,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:05,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:11,24 root INFO Epoch 3 Global steps: 28500 Train loss: 0.3342
ro_en Dev loss: 0.3724 r:0.8140
et_en Dev loss: 0.4111 r:0.6836
si_en Dev loss: 0.8360 r:0.5853
ne_en Dev loss: 0.4842 r:0.7522
ru_en Dev loss: 0.4879 r:0.7264
Current avg r:0.7123 Best avg r: 0.7430
20:18:29,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:35,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:40,728 root INFO Epoch 3 Global steps: 29000 Train loss: 0.3268
ro_en Dev loss: 0.3869 r:0.8084
et_en Dev loss: 0.4123 r:0.6834
si_en Dev loss: 0.8514 r:0.5863
ne_en Dev loss: 0.5101 r:0.7569
ru_en Dev loss: 0.4670 r:0.7402
Current avg r:0.7150 Best avg r: 0.7430
20:24:02,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:07,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:12,796 root INFO Epoch 3 Global steps: 29500 Train loss: 0.3189
ro_en Dev loss: 0.3338 r:0.8166
et_en Dev loss: 0.4079 r:0.6967
si_en Dev loss: 0.6783 r:0.6016
ne_en Dev loss: 0.3759 r:0.7590
ru_en Dev loss: 0.4118 r:0.7533
Current avg r:0.7255 Best avg r: 0.7430
20:29:27,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:32,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:37,845 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3378
ro_en Dev loss: 0.3246 r:0.8205
et_en Dev loss: 0.3882 r:0.6993
si_en Dev loss: 0.6912 r:0.6072
ne_en Dev loss: 0.4240 r:0.7569
ru_en Dev loss: 0.4448 r:0.7409
Current avg r:0.7250 Best avg r: 0.7430
20:34:53,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:58,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:04,235 root INFO Epoch 4 Global steps: 30500 Train loss: 0.3043
ro_en Dev loss: 0.3449 r:0.8168
et_en Dev loss: 0.4085 r:0.6924
si_en Dev loss: 0.7707 r:0.5930
ne_en Dev loss: 0.4499 r:0.7590
ru_en Dev loss: 0.4588 r:0.7389
Current avg r:0.7200 Best avg r: 0.7430
20:40:18,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:24,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:29,500 root INFO Epoch 4 Global steps: 31000 Train loss: 0.2835
ro_en Dev loss: 0.3885 r:0.8111
et_en Dev loss: 0.4250 r:0.6880
si_en Dev loss: 0.8735 r:0.5849
ne_en Dev loss: 0.4593 r:0.7534
ru_en Dev loss: 0.5005 r:0.7286
Current avg r:0.7132 Best avg r: 0.7430
20:45:44,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:49,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:54,711 root INFO Epoch 4 Global steps: 31500 Train loss: 0.2934
ro_en Dev loss: 0.3549 r:0.8156
et_en Dev loss: 0.4113 r:0.6836
si_en Dev loss: 0.8005 r:0.5872
ne_en Dev loss: 0.4819 r:0.7516
ru_en Dev loss: 0.4506 r:0.7355
Current avg r:0.7147 Best avg r: 0.7430
20:51:09,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:14,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:19,673 root INFO Epoch 4 Global steps: 32000 Train loss: 0.2948
ro_en Dev loss: 0.3286 r:0.8154
et_en Dev loss: 0.4055 r:0.6925
si_en Dev loss: 0.7302 r:0.5835
ne_en Dev loss: 0.4675 r:0.7468
ru_en Dev loss: 0.4096 r:0.7416
Current avg r:0.7160 Best avg r: 0.7430
20:56:34,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:40,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:45,700 root INFO Epoch 4 Global steps: 32500 Train loss: 0.2931
ro_en Dev loss: 0.3487 r:0.8204
et_en Dev loss: 0.3944 r:0.6992
si_en Dev loss: 0.7091 r:0.6012
ne_en Dev loss: 0.4443 r:0.7530
ru_en Dev loss: 0.4877 r:0.7292
Current avg r:0.7206 Best avg r: 0.7430
21:02:07,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:12,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:17,980 root INFO Epoch 4 Global steps: 33000 Train loss: 0.2935
ro_en Dev loss: 0.4130 r:0.8087
et_en Dev loss: 0.4271 r:0.6776
si_en Dev loss: 0.8923 r:0.5796
ne_en Dev loss: 0.5529 r:0.7470
ru_en Dev loss: 0.5112 r:0.7300
Current avg r:0.7086 Best avg r: 0.7430
21:07:39,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:44,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:50,66 root INFO Epoch 4 Global steps: 33500 Train loss: 0.2912
ro_en Dev loss: 0.3593 r:0.8150
et_en Dev loss: 0.4048 r:0.6838
si_en Dev loss: 0.7954 r:0.5822
ne_en Dev loss: 0.5041 r:0.7523
ru_en Dev loss: 0.4409 r:0.7444
Current avg r:0.7155 Best avg r: 0.7430
21:13:04,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:09,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:14,868 root INFO Epoch 4 Global steps: 34000 Train loss: 0.2770
ro_en Dev loss: 0.3586 r:0.8155
et_en Dev loss: 0.4364 r:0.6879
si_en Dev loss: 0.6865 r:0.5935
ne_en Dev loss: 0.4038 r:0.7542
ru_en Dev loss: 0.4425 r:0.7442
Current avg r:0.7191 Best avg r: 0.7430
21:18:29,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:34,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:39,632 root INFO Epoch 4 Global steps: 34500 Train loss: 0.2840
ro_en Dev loss: 0.3617 r:0.8179
et_en Dev loss: 0.4189 r:0.6836
si_en Dev loss: 0.8318 r:0.5901
ne_en Dev loss: 0.4624 r:0.7599
ru_en Dev loss: 0.5105 r:0.7330
Current avg r:0.7169 Best avg r: 0.7430
21:23:54,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:59,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:04,506 root INFO Epoch 4 Global steps: 35000 Train loss: 0.2894
ro_en Dev loss: 0.3595 r:0.8157
et_en Dev loss: 0.4195 r:0.6839
si_en Dev loss: 0.7826 r:0.5897
ne_en Dev loss: 0.4653 r:0.7458
ru_en Dev loss: 0.4901 r:0.7412
Current avg r:0.7153 Best avg r: 0.7430
21:29:18,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:24,100 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:29,328 root INFO Epoch 4 Global steps: 35500 Train loss: 0.2817
ro_en Dev loss: 0.3899 r:0.8101
et_en Dev loss: 0.4431 r:0.6718
si_en Dev loss: 0.8506 r:0.5803
ne_en Dev loss: 0.4780 r:0.7526
ru_en Dev loss: 0.5173 r:0.7239
Current avg r:0.7078 Best avg r: 0.7430
21:34:43,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:48,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:54,248 root INFO Epoch 4 Global steps: 36000 Train loss: 0.2811
ro_en Dev loss: 0.3713 r:0.8091
et_en Dev loss: 0.4472 r:0.6793
si_en Dev loss: 0.8153 r:0.5811
ne_en Dev loss: 0.4765 r:0.7444
ru_en Dev loss: 0.5453 r:0.7019
Current avg r:0.7032 Best avg r: 0.7430
21:40:15,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:21,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:26,433 root INFO Epoch 4 Global steps: 36500 Train loss: 0.2734
ro_en Dev loss: 0.3696 r:0.8140
et_en Dev loss: 0.4133 r:0.6823
si_en Dev loss: 0.8471 r:0.5834
ne_en Dev loss: 0.4574 r:0.7556
ru_en Dev loss: 0.4670 r:0.7341
Current avg r:0.7139 Best avg r: 0.7430
21:45:47,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:46:52,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:47:58,226 root INFO Epoch 4 Global steps: 37000 Train loss: 0.2921
ro_en Dev loss: 0.3534 r:0.8128
et_en Dev loss: 0.4163 r:0.6740
si_en Dev loss: 0.8051 r:0.5823
ne_en Dev loss: 0.4791 r:0.7486
ru_en Dev loss: 0.4354 r:0.7396
Current avg r:0.7115 Best avg r: 0.7430
21:51:19,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:25,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:30,686 root INFO Epoch 4 Global steps: 37500 Train loss: 0.2718
ro_en Dev loss: 0.3437 r:0.8150
et_en Dev loss: 0.4205 r:0.6776
si_en Dev loss: 0.7081 r:0.5902
ne_en Dev loss: 0.4158 r:0.7495
ru_en Dev loss: 0.4670 r:0.7254
Current avg r:0.7115 Best avg r: 0.7430
21:56:46,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:51,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:56,562 root INFO Epoch 5 Global steps: 38000 Train loss: 0.2464
ro_en Dev loss: 0.3427 r:0.8133
et_en Dev loss: 0.4619 r:0.6769
si_en Dev loss: 0.7373 r:0.5803
ne_en Dev loss: 0.4268 r:0.7477
ru_en Dev loss: 0.4461 r:0.7288
Current avg r:0.7094 Best avg r: 0.7430
22:02:10,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:16,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:21,365 root INFO Epoch 5 Global steps: 38500 Train loss: 0.2498
ro_en Dev loss: 0.3756 r:0.8104
et_en Dev loss: 0.4395 r:0.6741
si_en Dev loss: 0.7989 r:0.5771
ne_en Dev loss: 0.4574 r:0.7523
ru_en Dev loss: 0.5070 r:0.7175
Current avg r:0.7063 Best avg r: 0.7430
22:07:35,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:41,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:46,285 root INFO Epoch 5 Global steps: 39000 Train loss: 0.2506
ro_en Dev loss: 0.3486 r:0.8112
et_en Dev loss: 0.4324 r:0.6659
si_en Dev loss: 0.7546 r:0.5763
ne_en Dev loss: 0.4627 r:0.7459
ru_en Dev loss: 0.5169 r:0.7077
Current avg r:0.7014 Best avg r: 0.7430
22:13:00,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:06,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:11,296 root INFO Epoch 5 Global steps: 39500 Train loss: 0.2451
ro_en Dev loss: 0.3663 r:0.8119
et_en Dev loss: 0.4424 r:0.6727
si_en Dev loss: 0.8000 r:0.5792
ne_en Dev loss: 0.4537 r:0.7472
ru_en Dev loss: 0.5099 r:0.7079
Current avg r:0.7038 Best avg r: 0.7430
22:18:25,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:31,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:36,342 root INFO Epoch 5 Global steps: 40000 Train loss: 0.2441
ro_en Dev loss: 0.3557 r:0.8127
et_en Dev loss: 0.4657 r:0.6520
si_en Dev loss: 0.8878 r:0.5621
ne_en Dev loss: 0.5300 r:0.7406
ru_en Dev loss: 0.5180 r:0.7056
Current avg r:0.6946 Best avg r: 0.7430
22:23:50,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:56,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:01,354 root INFO Epoch 5 Global steps: 40500 Train loss: 0.2452
ro_en Dev loss: 0.3658 r:0.8092
et_en Dev loss: 0.4318 r:0.6664
si_en Dev loss: 0.8339 r:0.5656
ne_en Dev loss: 0.4797 r:0.7470
ru_en Dev loss: 0.4510 r:0.7288
Current avg r:0.7034 Best avg r: 0.7430
22:29:15,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:21,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:26,301 root INFO Epoch 5 Global steps: 41000 Train loss: 0.2520
ro_en Dev loss: 0.4073 r:0.8098
et_en Dev loss: 0.4811 r:0.6576
si_en Dev loss: 0.9580 r:0.5632
ne_en Dev loss: 0.5795 r:0.7471
ru_en Dev loss: 0.5242 r:0.7152
Current avg r:0.6986 Best avg r: 0.7430
22:34:40,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:45,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:51,176 root INFO Epoch 5 Global steps: 41500 Train loss: 0.2417
ro_en Dev loss: 0.3561 r:0.8125
et_en Dev loss: 0.4654 r:0.6784
si_en Dev loss: 0.7712 r:0.5780
ne_en Dev loss: 0.4160 r:0.7504
ru_en Dev loss: 0.4480 r:0.7322
Current avg r:0.7103 Best avg r: 0.7430
22:40:05,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:10,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:16,128 root INFO Epoch 5 Global steps: 42000 Train loss: 0.2416
ro_en Dev loss: 0.3343 r:0.8147
et_en Dev loss: 0.4462 r:0.6753
si_en Dev loss: 0.7517 r:0.5757
ne_en Dev loss: 0.4361 r:0.7513
ru_en Dev loss: 0.4144 r:0.7350
Current avg r:0.7104 Best avg r: 0.7430
22:45:30,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:35,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:41,43 root INFO Epoch 5 Global steps: 42500 Train loss: 0.2535
ro_en Dev loss: 0.3690 r:0.8106
et_en Dev loss: 0.4373 r:0.6674
si_en Dev loss: 0.8021 r:0.5714
ne_en Dev loss: 0.4685 r:0.7503
ru_en Dev loss: 0.4748 r:0.7239
Current avg r:0.7047 Best avg r: 0.7430
22:50:55,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:00,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:06,12 root INFO Epoch 5 Global steps: 43000 Train loss: 0.2417
ro_en Dev loss: 0.4141 r:0.8034
et_en Dev loss: 0.4391 r:0.6636
si_en Dev loss: 0.8110 r:0.5701
ne_en Dev loss: 0.5294 r:0.7467
ru_en Dev loss: 0.5118 r:0.7171
Current avg r:0.7002 Best avg r: 0.7430
22:56:20,445 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:25,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:31,22 root INFO Epoch 5 Global steps: 43500 Train loss: 0.2366
ro_en Dev loss: 0.4204 r:0.8045
et_en Dev loss: 0.4598 r:0.6664
si_en Dev loss: 0.9555 r:0.5616
ne_en Dev loss: 0.6171 r:0.7434
ru_en Dev loss: 0.5521 r:0.7106
Current avg r:0.6973 Best avg r: 0.7430
23:01:45,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:50,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:56,67 root INFO Epoch 5 Global steps: 44000 Train loss: 0.2396
ro_en Dev loss: 0.4028 r:0.8091
et_en Dev loss: 0.4401 r:0.6656
si_en Dev loss: 0.9487 r:0.5669
ne_en Dev loss: 0.5103 r:0.7520
ru_en Dev loss: 0.5077 r:0.7159
Current avg r:0.7019 Best avg r: 0.7430
23:07:10,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:15,815 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:09:21,108 root INFO Epoch 5 Global steps: 44500 Train loss: 0.2500
ro_en Dev loss: 0.3957 r:0.8037
et_en Dev loss: 0.4519 r:0.6623
si_en Dev loss: 0.8876 r:0.5684
ne_en Dev loss: 0.5083 r:0.7521
ru_en Dev loss: 0.5247 r:0.7098
Current avg r:0.6993 Best avg r: 0.7430
23:12:35,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:40,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:46,59 root INFO Epoch 5 Global steps: 45000 Train loss: 0.2465
ro_en Dev loss: 0.3902 r:0.8006
et_en Dev loss: 0.4321 r:0.6752
si_en Dev loss: 0.8950 r:0.5658
ne_en Dev loss: 0.4967 r:0.7445
ru_en Dev loss: 0.4503 r:0.7290
Current avg r:0.7030 Best avg r: 0.7430
23:18:01,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:06,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:12,85 root INFO Epoch 6 Global steps: 45500 Train loss: 0.2158
ro_en Dev loss: 0.3703 r:0.8041
et_en Dev loss: 0.4533 r:0.6626
si_en Dev loss: 0.8175 r:0.5627
ne_en Dev loss: 0.5200 r:0.7391
ru_en Dev loss: 0.4815 r:0.7167
Current avg r:0.6970 Best avg r: 0.7430
23:23:26,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:31,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:36,779 root INFO Epoch 6 Global steps: 46000 Train loss: 0.2090
ro_en Dev loss: 0.3809 r:0.8041
et_en Dev loss: 0.4551 r:0.6662
si_en Dev loss: 0.8760 r:0.5612
ne_en Dev loss: 0.5359 r:0.7420
ru_en Dev loss: 0.4747 r:0.7269
Current avg r:0.7001 Best avg r: 0.7430
23:28:51,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:56,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:01,494 root INFO Epoch 6 Global steps: 46500 Train loss: 0.1912
ro_en Dev loss: 0.3512 r:0.8111
et_en Dev loss: 0.4138 r:0.6739
si_en Dev loss: 0.8225 r:0.5712
ne_en Dev loss: 0.5661 r:0.7387
ru_en Dev loss: 0.4580 r:0.7297
Current avg r:0.7049 Best avg r: 0.7430
23:34:15,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:20,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:26,186 root INFO Epoch 6 Global steps: 47000 Train loss: 0.2093
ro_en Dev loss: 0.3578 r:0.8092
et_en Dev loss: 0.4390 r:0.6809
si_en Dev loss: 0.7526 r:0.5753
ne_en Dev loss: 0.4468 r:0.7377
ru_en Dev loss: 0.4392 r:0.7299
Current avg r:0.7066 Best avg r: 0.7430
23:39:40,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:45,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:50,791 root INFO Epoch 6 Global steps: 47500 Train loss: 0.2064
ro_en Dev loss: 0.4014 r:0.8019
et_en Dev loss: 0.4696 r:0.6565
si_en Dev loss: 0.9264 r:0.5538
ne_en Dev loss: 0.6183 r:0.7301
ru_en Dev loss: 0.5547 r:0.7079
Current avg r:0.6900 Best avg r: 0.7430
23:45:04,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:10,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:47:15,341 root INFO Epoch 6 Global steps: 48000 Train loss: 0.2089
ro_en Dev loss: 0.3741 r:0.8047
et_en Dev loss: 0.4495 r:0.6645
si_en Dev loss: 0.8573 r:0.5647
ne_en Dev loss: 0.5448 r:0.7352
ru_en Dev loss: 0.4697 r:0.7245
Current avg r:0.6987 Best avg r: 0.7430
23:50:29,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:34,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:39,940 root INFO Epoch 6 Global steps: 48500 Train loss: 0.2163
ro_en Dev loss: 0.3521 r:0.8056
et_en Dev loss: 0.4433 r:0.6647
si_en Dev loss: 0.7686 r:0.5667
ne_en Dev loss: 0.4728 r:0.7316
ru_en Dev loss: 0.4451 r:0.7220
Current avg r:0.6981 Best avg r: 0.7430
23:55:56,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:01,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:06,498 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2168
ro_en Dev loss: 0.3818 r:0.8067
et_en Dev loss: 0.4378 r:0.6704
si_en Dev loss: 0.8421 r:0.5626
ne_en Dev loss: 0.5108 r:0.7312
ru_en Dev loss: 0.4988 r:0.7118
Current avg r:0.6966 Best avg r: 0.7430
00:01:23,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:29,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:34,474 root INFO Epoch 6 Global steps: 49500 Train loss: 0.2189
ro_en Dev loss: 0.3908 r:0.8027
et_en Dev loss: 0.4639 r:0.6628
si_en Dev loss: 0.8931 r:0.5494
ne_en Dev loss: 0.4948 r:0.7321
ru_en Dev loss: 0.4740 r:0.7205
Current avg r:0.6935 Best avg r: 0.7430
00:06:56,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:08:01,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:09:06,960 root INFO Epoch 6 Global steps: 50000 Train loss: 0.2048
ro_en Dev loss: 0.4004 r:0.8021
et_en Dev loss: 0.4689 r:0.6630
si_en Dev loss: 0.8265 r:0.5591
ne_en Dev loss: 0.5171 r:0.7307
ru_en Dev loss: 0.4949 r:0.7175
Current avg r:0.6945 Best avg r: 0.7430
00:12:28,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:34,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:39,413 root INFO Epoch 6 Global steps: 50500 Train loss: 0.2027
ro_en Dev loss: 0.3741 r:0.8087
et_en Dev loss: 0.4640 r:0.6676
si_en Dev loss: 0.7830 r:0.5616
ne_en Dev loss: 0.4296 r:0.7360
ru_en Dev loss: 0.4804 r:0.7228
Current avg r:0.6994 Best avg r: 0.7430
00:18:01,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:06,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:11,750 root INFO Epoch 6 Global steps: 51000 Train loss: 0.2082
ro_en Dev loss: 0.3682 r:0.8077
et_en Dev loss: 0.4663 r:0.6553
si_en Dev loss: 0.9525 r:0.5493
ne_en Dev loss: 0.5986 r:0.7330
ru_en Dev loss: 0.4632 r:0.7214
Current avg r:0.6933 Best avg r: 0.7430
00:23:26,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:31,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:36,749 root INFO Epoch 6 Global steps: 51500 Train loss: 0.2170
ro_en Dev loss: 0.3770 r:0.8074
et_en Dev loss: 0.4474 r:0.6671
si_en Dev loss: 0.8980 r:0.5508
ne_en Dev loss: 0.4941 r:0.7380
ru_en Dev loss: 0.5037 r:0.7172
Current avg r:0.6961 Best avg r: 0.7430
00:28:51,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:56,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:01,533 root INFO Epoch 6 Global steps: 52000 Train loss: 0.2124
ro_en Dev loss: 0.3553 r:0.8025
et_en Dev loss: 0.4766 r:0.6759
si_en Dev loss: 0.7250 r:0.5678
ne_en Dev loss: 0.4205 r:0.7293
ru_en Dev loss: 0.4327 r:0.7303
Current avg r:0.7011 Best avg r: 0.7430
00:34:15,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:21,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:26,407 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2099
ro_en Dev loss: 0.3857 r:0.8046
et_en Dev loss: 0.4424 r:0.6668
si_en Dev loss: 0.8292 r:0.5647
ne_en Dev loss: 0.4817 r:0.7339
ru_en Dev loss: 0.4905 r:0.7058
Current avg r:0.6952 Best avg r: 0.7430
00:39:42,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:47,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:52,471 root INFO Epoch 7 Global steps: 53000 Train loss: 0.1876
ro_en Dev loss: 0.4175 r:0.8004
et_en Dev loss: 0.4833 r:0.6481
si_en Dev loss: 1.0062 r:0.5395
ne_en Dev loss: 0.6693 r:0.7287
ru_en Dev loss: 0.5049 r:0.7095
Current avg r:0.6853 Best avg r: 0.7430
00:45:06,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:12,174 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:17,387 root INFO Epoch 7 Global steps: 53500 Train loss: 0.1835
ro_en Dev loss: 0.4030 r:0.8067
et_en Dev loss: 0.4573 r:0.6618
si_en Dev loss: 0.8808 r:0.5587
ne_en Dev loss: 0.4921 r:0.7367
ru_en Dev loss: 0.4818 r:0.7283
Current avg r:0.6984 Best avg r: 0.7430
00:50:31,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:36,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:42,44 root INFO Epoch 7 Global steps: 54000 Train loss: 0.1894
ro_en Dev loss: 0.4102 r:0.8064
et_en Dev loss: 0.4765 r:0.6626
si_en Dev loss: 0.9093 r:0.5549
ne_en Dev loss: 0.5023 r:0.7351
ru_en Dev loss: 0.4731 r:0.7339
Current avg r:0.6986 Best avg r: 0.7430
00:55:56,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:01,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:06,690 root INFO Epoch 7 Global steps: 54500 Train loss: 0.1863
ro_en Dev loss: 0.4096 r:0.8014
et_en Dev loss: 0.4955 r:0.6447
si_en Dev loss: 0.9697 r:0.5455
ne_en Dev loss: 0.5978 r:0.7275
ru_en Dev loss: 0.5357 r:0.6975
Current avg r:0.6833 Best avg r: 0.7430
01:01:20,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:02:26,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:31,179 root INFO Epoch 7 Global steps: 55000 Train loss: 0.1801
ro_en Dev loss: 0.4361 r:0.8048
et_en Dev loss: 0.4960 r:0.6480
si_en Dev loss: 0.9792 r:0.5452
ne_en Dev loss: 0.5202 r:0.7257
ru_en Dev loss: 0.5775 r:0.6974
Current avg r:0.6842 Best avg r: 0.7430
01:06:45,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:50,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:55,829 root INFO Epoch 7 Global steps: 55500 Train loss: 0.1887
ro_en Dev loss: 0.3997 r:0.8035
et_en Dev loss: 0.4709 r:0.6451
si_en Dev loss: 1.0280 r:0.5395
ne_en Dev loss: 0.6071 r:0.7306
ru_en Dev loss: 0.5552 r:0.6886
Current avg r:0.6815 Best avg r: 0.7430
01:12:10,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:15,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:20,658 root INFO Epoch 7 Global steps: 56000 Train loss: 0.1829
ro_en Dev loss: 0.3571 r:0.8099
et_en Dev loss: 0.4664 r:0.6788
si_en Dev loss: 0.7683 r:0.5609
ne_en Dev loss: 0.4896 r:0.7370
ru_en Dev loss: 0.4530 r:0.7291
Current avg r:0.7031 Best avg r: 0.7430
01:17:34,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:18:40,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:45,223 root INFO Epoch 7 Global steps: 56500 Train loss: 0.1805
ro_en Dev loss: 0.3864 r:0.7992
et_en Dev loss: 0.4775 r:0.6632
si_en Dev loss: 0.8790 r:0.5493
ne_en Dev loss: 0.5169 r:0.7285
ru_en Dev loss: 0.4771 r:0.7157
Current avg r:0.6912 Best avg r: 0.7430
01:22:59,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:24:04,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:09,801 root INFO Epoch 7 Global steps: 57000 Train loss: 0.1793
ro_en Dev loss: 0.3425 r:0.8110
et_en Dev loss: 0.4387 r:0.6738
si_en Dev loss: 0.8457 r:0.5544
ne_en Dev loss: 0.4671 r:0.7333
ru_en Dev loss: 0.4385 r:0.7279
Current avg r:0.7001 Best avg r: 0.7430
01:28:23,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:29,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:34,315 root INFO Epoch 7 Global steps: 57500 Train loss: 0.1836
ro_en Dev loss: 0.3340 r:0.8116
et_en Dev loss: 0.4236 r:0.6659
si_en Dev loss: 0.8187 r:0.5516
ne_en Dev loss: 0.5469 r:0.7334
ru_en Dev loss: 0.4395 r:0.7246
Current avg r:0.6974 Best avg r: 0.7430
01:33:48,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:34:53,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:35:58,699 root INFO Epoch 7 Global steps: 58000 Train loss: 0.1772
ro_en Dev loss: 0.3649 r:0.8122
et_en Dev loss: 0.4190 r:0.6756
si_en Dev loss: 0.8122 r:0.5618
ne_en Dev loss: 0.4996 r:0.7344
ru_en Dev loss: 0.4306 r:0.7427
Current avg r:0.7053 Best avg r: 0.7430
01:39:12,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:40:17,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:41:23,130 root INFO Epoch 7 Global steps: 58500 Train loss: 0.1826
ro_en Dev loss: 0.3930 r:0.8092
et_en Dev loss: 0.4571 r:0.6614
si_en Dev loss: 0.9186 r:0.5489
ne_en Dev loss: 0.6088 r:0.7307
ru_en Dev loss: 0.5017 r:0.7210
Current avg r:0.6942 Best avg r: 0.7430
01:44:37,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:45:42,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:46:47,384 root INFO Epoch 7 Global steps: 59000 Train loss: 0.1806
ro_en Dev loss: 0.3665 r:0.8087
et_en Dev loss: 0.4593 r:0.6617
si_en Dev loss: 0.9000 r:0.5493
ne_en Dev loss: 0.5229 r:0.7306
ru_en Dev loss: 0.4770 r:0.7239
Current avg r:0.6949 Best avg r: 0.7430
01:50:01,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:06,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:11,650 root INFO Epoch 7 Global steps: 59500 Train loss: 0.1647
ro_en Dev loss: 0.3719 r:0.8068
et_en Dev loss: 0.4658 r:0.6665
si_en Dev loss: 0.8910 r:0.5508
ne_en Dev loss: 0.4916 r:0.7368
ru_en Dev loss: 0.4753 r:0.7224
Current avg r:0.6967 Best avg r: 0.7430
01:55:25,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:56:30,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:57:36,20 root INFO Epoch 7 Global steps: 60000 Train loss: 0.1710
ro_en Dev loss: 0.3480 r:0.8119
et_en Dev loss: 0.4669 r:0.6791
si_en Dev loss: 0.8388 r:0.5609
ne_en Dev loss: 0.4402 r:0.7447
ru_en Dev loss: 0.4116 r:0.7494
Current avg r:0.7092 Best avg r: 0.7430
02:00:56,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:02:02,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:03:07,879 root INFO Epoch 8 Global steps: 60500 Train loss: 0.1599
ro_en Dev loss: 0.3468 r:0.8088
et_en Dev loss: 0.4664 r:0.6641
si_en Dev loss: 0.8179 r:0.5488
ne_en Dev loss: 0.5215 r:0.7300
ru_en Dev loss: 0.4253 r:0.7397
Current avg r:0.6983 Best avg r: 0.7430
02:06:29,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:07:35,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:08:40,860 root INFO Epoch 8 Global steps: 61000 Train loss: 0.1595
ro_en Dev loss: 0.3608 r:0.8073
et_en Dev loss: 0.4697 r:0.6687
si_en Dev loss: 0.8367 r:0.5542
ne_en Dev loss: 0.5201 r:0.7292
ru_en Dev loss: 0.4726 r:0.7244
Current avg r:0.6967 Best avg r: 0.7430
02:12:04,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:10,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:16,14 root INFO Epoch 8 Global steps: 61500 Train loss: 0.1580
ro_en Dev loss: 0.3711 r:0.8095
et_en Dev loss: 0.4724 r:0.6614
si_en Dev loss: 0.9458 r:0.5424
ne_en Dev loss: 0.6481 r:0.7242
ru_en Dev loss: 0.4859 r:0.7174
Current avg r:0.6910 Best avg r: 0.7430
02:17:33,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:18:39,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:44,980 root INFO Epoch 8 Global steps: 62000 Train loss: 0.1510
ro_en Dev loss: 0.3796 r:0.8085
et_en Dev loss: 0.4878 r:0.6728
si_en Dev loss: 0.8858 r:0.5584
ne_en Dev loss: 0.4847 r:0.7357
ru_en Dev loss: 0.4834 r:0.7243
Current avg r:0.6999 Best avg r: 0.7430
02:23:03,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:09,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:15,198 root INFO Epoch 8 Global steps: 62500 Train loss: 0.1547
ro_en Dev loss: 0.3789 r:0.8095
et_en Dev loss: 0.4964 r:0.6568
si_en Dev loss: 0.8809 r:0.5529
ne_en Dev loss: 0.5370 r:0.7301
ru_en Dev loss: 0.4755 r:0.7198
Current avg r:0.6938 Best avg r: 0.7430
02:28:33,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:39,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:30:44,219 root INFO Epoch 8 Global steps: 63000 Train loss: 0.1572
ro_en Dev loss: 0.3789 r:0.8097
et_en Dev loss: 0.4902 r:0.6559
si_en Dev loss: 0.9053 r:0.5498
ne_en Dev loss: 0.5741 r:0.7262
ru_en Dev loss: 0.5054 r:0.7122
Current avg r:0.6907 Best avg r: 0.7430
02:34:06,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:11,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:16,856 root INFO Epoch 8 Global steps: 63500 Train loss: 0.1574
ro_en Dev loss: 0.4238 r:0.8033
et_en Dev loss: 0.4811 r:0.6535
si_en Dev loss: 0.9624 r:0.5457
ne_en Dev loss: 0.5634 r:0.7318
ru_en Dev loss: 0.5190 r:0.7136
Current avg r:0.6896 Best avg r: 0.7430
02:39:39,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:40:44,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:41:49,803 root INFO Epoch 8 Global steps: 64000 Train loss: 0.1616
ro_en Dev loss: 0.3589 r:0.8063
et_en Dev loss: 0.4753 r:0.6584
si_en Dev loss: 0.8446 r:0.5467
ne_en Dev loss: 0.5194 r:0.7273
ru_en Dev loss: 0.4517 r:0.7246
Current avg r:0.6927 Best avg r: 0.7430
02:45:12,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:46:17,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:47:22,785 root INFO Epoch 8 Global steps: 64500 Train loss: 0.1549
ro_en Dev loss: 0.3740 r:0.8062
et_en Dev loss: 0.4658 r:0.6599
si_en Dev loss: 0.9059 r:0.5440
ne_en Dev loss: 0.5396 r:0.7285
ru_en Dev loss: 0.4833 r:0.7218
Current avg r:0.6921 Best avg r: 0.7430
02:50:45,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:50,366 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:55,633 root INFO Epoch 8 Global steps: 65000 Train loss: 0.1606
ro_en Dev loss: 0.4035 r:0.8019
et_en Dev loss: 0.4637 r:0.6587
si_en Dev loss: 0.9932 r:0.5360
ne_en Dev loss: 0.6979 r:0.7208
ru_en Dev loss: 0.5144 r:0.7129
Current avg r:0.6861 Best avg r: 0.7430
02:56:10,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:57:16,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:58:21,513 root INFO Epoch 8 Global steps: 65500 Train loss: 0.1516
ro_en Dev loss: 0.3861 r:0.8078
et_en Dev loss: 0.4616 r:0.6634
si_en Dev loss: 0.9590 r:0.5358
ne_en Dev loss: 0.5522 r:0.7242
ru_en Dev loss: 0.4898 r:0.7177
Current avg r:0.6898 Best avg r: 0.7430
03:01:41,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:02:47,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:52,278 root INFO Epoch 8 Global steps: 66000 Train loss: 0.1620
ro_en Dev loss: 0.3563 r:0.8132
et_en Dev loss: 0.4558 r:0.6620
si_en Dev loss: 0.8959 r:0.5488
ne_en Dev loss: 0.5253 r:0.7249
ru_en Dev loss: 0.5066 r:0.7142
Current avg r:0.6926 Best avg r: 0.7430
03:07:09,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:08:14,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:09:19,494 root INFO Epoch 8 Global steps: 66500 Train loss: 0.1521
ro_en Dev loss: 0.3954 r:0.8083
et_en Dev loss: 0.4678 r:0.6630
si_en Dev loss: 0.9994 r:0.5423
ne_en Dev loss: 0.6508 r:0.7226
ru_en Dev loss: 0.5442 r:0.7037
Current avg r:0.6880 Best avg r: 0.7430
03:12:34,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:39,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:44,360 root INFO Epoch 8 Global steps: 67000 Train loss: 0.1575
ro_en Dev loss: 0.3905 r:0.8069
et_en Dev loss: 0.4767 r:0.6511
si_en Dev loss: 0.9990 r:0.5407
ne_en Dev loss: 0.6396 r:0.7199
ru_en Dev loss: 0.4883 r:0.7183
Current avg r:0.6874 Best avg r: 0.7430
03:17:58,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:19:04,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:20:09,176 root INFO Epoch 8 Global steps: 67500 Train loss: 0.1600
ro_en Dev loss: 0.3547 r:0.8122
et_en Dev loss: 0.4529 r:0.6686
si_en Dev loss: 0.8653 r:0.5535
ne_en Dev loss: 0.5539 r:0.7204
ru_en Dev loss: 0.4319 r:0.7419
Current avg r:0.6993 Best avg r: 0.7430
03:23:25,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:24:30,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:36,137 root INFO Epoch 9 Global steps: 68000 Train loss: 0.1448
ro_en Dev loss: 0.4139 r:0.8078
et_en Dev loss: 0.4699 r:0.6589
si_en Dev loss: 0.9438 r:0.5498
ne_en Dev loss: 0.5642 r:0.7190
ru_en Dev loss: 0.5264 r:0.7222
Current avg r:0.6915 Best avg r: 0.7430
03:28:54,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:59,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:04,712 root INFO Epoch 9 Global steps: 68500 Train loss: 0.1380
ro_en Dev loss: 0.3732 r:0.8075
et_en Dev loss: 0.4646 r:0.6603
si_en Dev loss: 0.9239 r:0.5459
ne_en Dev loss: 0.5452 r:0.7187
ru_en Dev loss: 0.4271 r:0.7372
Current avg r:0.6939 Best avg r: 0.7430
03:34:19,214 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:24,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:29,485 root INFO Epoch 9 Global steps: 69000 Train loss: 0.1350
ro_en Dev loss: 0.3586 r:0.8131
et_en Dev loss: 0.4524 r:0.6545
si_en Dev loss: 0.9286 r:0.5432
ne_en Dev loss: 0.5928 r:0.7169
ru_en Dev loss: 0.4251 r:0.7412
Current avg r:0.6938 Best avg r: 0.7430
03:39:44,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:49,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:54,376 root INFO Epoch 9 Global steps: 69500 Train loss: 0.1420
ro_en Dev loss: 0.3911 r:0.8081
et_en Dev loss: 0.4809 r:0.6510
si_en Dev loss: 0.9655 r:0.5379
ne_en Dev loss: 0.6029 r:0.7106
ru_en Dev loss: 0.4946 r:0.7196
Current avg r:0.6854 Best avg r: 0.7430
03:45:16,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:46:21,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:47:27,243 root INFO Epoch 9 Global steps: 70000 Train loss: 0.1376
ro_en Dev loss: 0.4459 r:0.8053
et_en Dev loss: 0.4919 r:0.6491
si_en Dev loss: 0.9918 r:0.5505
ne_en Dev loss: 0.5986 r:0.7214
ru_en Dev loss: 0.5455 r:0.7210
Current avg r:0.6895 Best avg r: 0.7430
03:50:49,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:54,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:59,940 root INFO Epoch 9 Global steps: 70500 Train loss: 0.1431
ro_en Dev loss: 0.3971 r:0.8052
et_en Dev loss: 0.4903 r:0.6518
si_en Dev loss: 0.9052 r:0.5439
ne_en Dev loss: 0.5977 r:0.7158
ru_en Dev loss: 0.4934 r:0.7253
Current avg r:0.6884 Best avg r: 0.7430
03:56:22,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:27,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:58:32,824 root INFO Epoch 9 Global steps: 71000 Train loss: 0.1350
ro_en Dev loss: 0.3627 r:0.8108
et_en Dev loss: 0.4745 r:0.6620
si_en Dev loss: 0.8528 r:0.5495
ne_en Dev loss: 0.4756 r:0.7227
ru_en Dev loss: 0.4710 r:0.7245
Current avg r:0.6939 Best avg r: 0.7430
04:01:55,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:03:00,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:05,705 root INFO Epoch 9 Global steps: 71500 Train loss: 0.1407
ro_en Dev loss: 0.3748 r:0.8079
et_en Dev loss: 0.4835 r:0.6553
si_en Dev loss: 0.9258 r:0.5358
ne_en Dev loss: 0.5164 r:0.7160
ru_en Dev loss: 0.4931 r:0.7234
Current avg r:0.6877 Best avg r: 0.7430
04:07:24,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:08:29,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:09:35,11 root INFO Epoch 9 Global steps: 72000 Train loss: 0.1472
ro_en Dev loss: 0.3582 r:0.8053
et_en Dev loss: 0.4546 r:0.6621
si_en Dev loss: 0.8570 r:0.5462
ne_en Dev loss: 0.5431 r:0.7221
ru_en Dev loss: 0.4765 r:0.7277
Current avg r:0.6927 Best avg r: 0.7430
04:12:57,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:02,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:07,807 root INFO Epoch 9 Global steps: 72500 Train loss: 0.1373
ro_en Dev loss: 0.3953 r:0.8071
et_en Dev loss: 0.4712 r:0.6566
si_en Dev loss: 0.9997 r:0.5367
ne_en Dev loss: 0.6628 r:0.7119
ru_en Dev loss: 0.4982 r:0.7253
Current avg r:0.6875 Best avg r: 0.7430
04:18:30,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:19:35,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:20:40,704 root INFO Epoch 9 Global steps: 73000 Train loss: 0.1391
ro_en Dev loss: 0.3670 r:0.8095
et_en Dev loss: 0.4706 r:0.6543
si_en Dev loss: 0.9284 r:0.5465
ne_en Dev loss: 0.6402 r:0.7204
ru_en Dev loss: 0.5182 r:0.7145
Current avg r:0.6890 Best avg r: 0.7430
04:24:03,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:25:08,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:26:13,762 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1366
ro_en Dev loss: 0.4153 r:0.8024
et_en Dev loss: 0.4854 r:0.6567
si_en Dev loss: 1.0036 r:0.5379
ne_en Dev loss: 0.6240 r:0.7235
ru_en Dev loss: 0.4983 r:0.7294
Current avg r:0.6900 Best avg r: 0.7430
04:29:36,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:41,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:46,728 root INFO Epoch 9 Global steps: 74000 Train loss: 0.1406
ro_en Dev loss: 0.3532 r:0.8127
et_en Dev loss: 0.4494 r:0.6642
si_en Dev loss: 0.9003 r:0.5439
ne_en Dev loss: 0.5616 r:0.7151
ru_en Dev loss: 0.4245 r:0.7466
Current avg r:0.6965 Best avg r: 0.7430
04:35:01,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:06,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:11,696 root INFO Epoch 9 Global steps: 74500 Train loss: 0.1367
ro_en Dev loss: 0.3975 r:0.8086
et_en Dev loss: 0.4866 r:0.6548
si_en Dev loss: 1.0403 r:0.5387
ne_en Dev loss: 0.6869 r:0.7217
ru_en Dev loss: 0.5402 r:0.7253
Current avg r:0.6898 Best avg r: 0.7430
04:40:33,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:41:38,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:42:44,225 root INFO Epoch 9 Global steps: 75000 Train loss: 0.1343
ro_en Dev loss: 0.3861 r:0.8062
et_en Dev loss: 0.4886 r:0.6460
si_en Dev loss: 0.9683 r:0.5363
ne_en Dev loss: 0.6470 r:0.7197
ru_en Dev loss: 0.4859 r:0.7261
Current avg r:0.6869 Best avg r: 0.7430
04:45:59,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:47:04,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:09,832 root INFO Epoch 10 Global steps: 75500 Train loss: 0.1247
ro_en Dev loss: 0.4148 r:0.8098
et_en Dev loss: 0.4802 r:0.6566
si_en Dev loss: 1.0283 r:0.5435
ne_en Dev loss: 0.6857 r:0.7204
ru_en Dev loss: 0.5540 r:0.7153
Current avg r:0.6891 Best avg r: 0.7430
04:51:23,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:52:29,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:34,269 root INFO Epoch 10 Global steps: 76000 Train loss: 0.1211
ro_en Dev loss: 0.3551 r:0.8125
et_en Dev loss: 0.4615 r:0.6639
si_en Dev loss: 0.8986 r:0.5452
ne_en Dev loss: 0.5275 r:0.7165
ru_en Dev loss: 0.4504 r:0.7373
Current avg r:0.6951 Best avg r: 0.7430
04:56:48,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:53,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:58,755 root INFO Epoch 10 Global steps: 76500 Train loss: 0.1244
ro_en Dev loss: 0.3701 r:0.8096
et_en Dev loss: 0.4704 r:0.6706
si_en Dev loss: 0.9027 r:0.5473
ne_en Dev loss: 0.5126 r:0.7204
ru_en Dev loss: 0.4519 r:0.7445
Current avg r:0.6985 Best avg r: 0.7430
05:02:12,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:18,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:04:23,203 root INFO Epoch 10 Global steps: 77000 Train loss: 0.1205
ro_en Dev loss: 0.3906 r:0.8098
et_en Dev loss: 0.4716 r:0.6646
si_en Dev loss: 0.9553 r:0.5470
ne_en Dev loss: 0.5803 r:0.7215
ru_en Dev loss: 0.4869 r:0.7297
Current avg r:0.6945 Best avg r: 0.7430
05:07:37,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:08:42,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:09:47,814 root INFO Epoch 10 Global steps: 77500 Train loss: 0.1245
ro_en Dev loss: 0.4225 r:0.8092
et_en Dev loss: 0.4897 r:0.6543
si_en Dev loss: 1.0467 r:0.5429
ne_en Dev loss: 0.7125 r:0.7187
ru_en Dev loss: 0.5357 r:0.7241
Current avg r:0.6899 Best avg r: 0.7430
05:13:01,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:07,87 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:12,236 root INFO Epoch 10 Global steps: 78000 Train loss: 0.1187
ro_en Dev loss: 0.3737 r:0.8097
et_en Dev loss: 0.4606 r:0.6547
si_en Dev loss: 0.9644 r:0.5388
ne_en Dev loss: 0.6970 r:0.7112
ru_en Dev loss: 0.4944 r:0.7221
Current avg r:0.6873 Best avg r: 0.7430
05:18:26,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:19:31,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:20:36,801 root INFO Epoch 10 Global steps: 78500 Train loss: 0.1222
ro_en Dev loss: 0.3635 r:0.8118
et_en Dev loss: 0.4617 r:0.6625
si_en Dev loss: 0.8953 r:0.5470
ne_en Dev loss: 0.5564 r:0.7188
ru_en Dev loss: 0.4376 r:0.7440
Current avg r:0.6968 Best avg r: 0.7430
05:23:51,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:24:57,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:02,975 root INFO Epoch 10 Global steps: 79000 Train loss: 0.1160
ro_en Dev loss: 0.3751 r:0.8086
et_en Dev loss: 0.4666 r:0.6535
si_en Dev loss: 1.0166 r:0.5294
ne_en Dev loss: 0.6521 r:0.7086
ru_en Dev loss: 0.4963 r:0.7246
Current avg r:0.6849 Best avg r: 0.7430
05:29:19,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:25,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:30,832 root INFO Epoch 10 Global steps: 79500 Train loss: 0.1267
ro_en Dev loss: 0.3610 r:0.8091
et_en Dev loss: 0.4741 r:0.6634
si_en Dev loss: 0.8696 r:0.5448
ne_en Dev loss: 0.5590 r:0.7153
ru_en Dev loss: 0.4523 r:0.7345
Current avg r:0.6934 Best avg r: 0.7430
05:34:46,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:35:52,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:36:57,945 root INFO Epoch 10 Global steps: 80000 Train loss: 0.1233
ro_en Dev loss: 0.3674 r:0.8082
et_en Dev loss: 0.4612 r:0.6591
si_en Dev loss: 0.9495 r:0.5351
ne_en Dev loss: 0.5511 r:0.7161
ru_en Dev loss: 0.4634 r:0.7324
Current avg r:0.6902 Best avg r: 0.7430
05:40:17,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:41:22,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:42:28,343 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1214
ro_en Dev loss: 0.4019 r:0.8060
et_en Dev loss: 0.4772 r:0.6666
si_en Dev loss: 0.9622 r:0.5425
ne_en Dev loss: 0.6635 r:0.7173
ru_en Dev loss: 0.5138 r:0.7219
Current avg r:0.6908 Best avg r: 0.7430
05:45:46,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:46:52,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:47:57,674 root INFO Epoch 10 Global steps: 81000 Train loss: 0.1238
ro_en Dev loss: 0.4221 r:0.7998
et_en Dev loss: 0.4961 r:0.6464
si_en Dev loss: 1.0539 r:0.5248
ne_en Dev loss: 0.6874 r:0.7111
ru_en Dev loss: 0.5565 r:0.6965
Current avg r:0.6757 Best avg r: 0.7430
05:51:19,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:25,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:30,234 root INFO Epoch 10 Global steps: 81500 Train loss: 0.1258
ro_en Dev loss: 0.3528 r:0.8121
et_en Dev loss: 0.4497 r:0.6614
si_en Dev loss: 0.8963 r:0.5399
ne_en Dev loss: 0.5522 r:0.7146
ru_en Dev loss: 0.4460 r:0.7310
Current avg r:0.6918 Best avg r: 0.7430
05:56:45,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:57:50,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:58:55,349 root INFO Epoch 10 Global steps: 82000 Train loss: 0.1169
ro_en Dev loss: 0.3505 r:0.8120
et_en Dev loss: 0.4510 r:0.6705
si_en Dev loss: 0.8723 r:0.5435
ne_en Dev loss: 0.5867 r:0.7183
ru_en Dev loss: 0.4416 r:0.7342
Current avg r:0.6957 Best avg r: 0.7430
06:02:09,486 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:14,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:19,756 root INFO Epoch 10 Global steps: 82500 Train loss: 0.1237
ro_en Dev loss: 0.3598 r:0.8103
et_en Dev loss: 0.4654 r:0.6726
si_en Dev loss: 0.8834 r:0.5426
ne_en Dev loss: 0.5179 r:0.7214
ru_en Dev loss: 0.4966 r:0.7208
Current avg r:0.6936 Best avg r: 0.7430
06:07:42,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:08:48,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:09:53,594 root INFO Epoch 11 Global steps: 83000 Train loss: 0.1097
ro_en Dev loss: 0.3580 r:0.8148
et_en Dev loss: 0.4542 r:0.6652
si_en Dev loss: 0.8681 r:0.5498
ne_en Dev loss: 0.5135 r:0.7269
ru_en Dev loss: 0.4810 r:0.7297
Current avg r:0.6973 Best avg r: 0.7430
06:13:11,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:16,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:21,765 root INFO Epoch 11 Global steps: 83500 Train loss: 0.1132
ro_en Dev loss: 0.3558 r:0.8088
et_en Dev loss: 0.4642 r:0.6671
si_en Dev loss: 0.8441 r:0.5512
ne_en Dev loss: 0.5649 r:0.7218
ru_en Dev loss: 0.4361 r:0.7375
Current avg r:0.6973 Best avg r: 0.7430
06:18:36,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:19:41,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:20:46,448 root INFO Epoch 11 Global steps: 84000 Train loss: 0.1129
ro_en Dev loss: 0.4012 r:0.8078
et_en Dev loss: 0.4774 r:0.6553
si_en Dev loss: 0.9638 r:0.5450
ne_en Dev loss: 0.6151 r:0.7184
ru_en Dev loss: 0.5073 r:0.7335
Current avg r:0.6920 Best avg r: 0.7430
06:24:00,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:25:05,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:11,233 root INFO Epoch 11 Global steps: 84500 Train loss: 0.1096
ro_en Dev loss: 0.3659 r:0.8100
et_en Dev loss: 0.4625 r:0.6582
si_en Dev loss: 0.9203 r:0.5436
ne_en Dev loss: 0.5700 r:0.7144
ru_en Dev loss: 0.4604 r:0.7313
Current avg r:0.6915 Best avg r: 0.7430
06:29:33,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:39,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:44,412 root INFO Epoch 11 Global steps: 85000 Train loss: 0.1107
ro_en Dev loss: 0.3519 r:0.8112
et_en Dev loss: 0.4480 r:0.6610
si_en Dev loss: 0.8627 r:0.5544
ne_en Dev loss: 0.5885 r:0.7114
ru_en Dev loss: 0.4426 r:0.7324
Current avg r:0.6941 Best avg r: 0.7430
06:35:02,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:07,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:13,133 root INFO Epoch 11 Global steps: 85500 Train loss: 0.1165
ro_en Dev loss: 0.3590 r:0.8130
et_en Dev loss: 0.4621 r:0.6666
si_en Dev loss: 0.8543 r:0.5547
ne_en Dev loss: 0.5275 r:0.7175
ru_en Dev loss: 0.4538 r:0.7357
Current avg r:0.6975 Best avg r: 0.7430
06:40:28,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:33,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:42:38,491 root INFO Epoch 11 Global steps: 86000 Train loss: 0.1069
ro_en Dev loss: 0.3746 r:0.8111
et_en Dev loss: 0.4761 r:0.6532
si_en Dev loss: 0.9521 r:0.5431
ne_en Dev loss: 0.5716 r:0.7146
ru_en Dev loss: 0.4756 r:0.7369
Current avg r:0.6918 Best avg r: 0.7430
06:45:58,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:03,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:48:08,873 root INFO Epoch 11 Global steps: 86500 Train loss: 0.1066
ro_en Dev loss: 0.3679 r:0.8099
et_en Dev loss: 0.4651 r:0.6625
si_en Dev loss: 0.9364 r:0.5444
ne_en Dev loss: 0.5803 r:0.7123
ru_en Dev loss: 0.4424 r:0.7413
Current avg r:0.6941 Best avg r: 0.7430
06:51:23,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:28,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:53:34,266 root INFO Epoch 11 Global steps: 87000 Train loss: 0.1096
ro_en Dev loss: 0.3800 r:0.8101
et_en Dev loss: 0.4713 r:0.6591
si_en Dev loss: 0.9244 r:0.5493
ne_en Dev loss: 0.6031 r:0.7186
ru_en Dev loss: 0.4896 r:0.7324
Current avg r:0.6939 Best avg r: 0.7430
06:56:56,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:58:02,122 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:59:07,495 root INFO Epoch 11 Global steps: 87500 Train loss: 0.1065
ro_en Dev loss: 0.3521 r:0.8109
et_en Dev loss: 0.4537 r:0.6688
si_en Dev loss: 0.8396 r:0.5484
ne_en Dev loss: 0.5392 r:0.7117
ru_en Dev loss: 0.4441 r:0.7420
Current avg r:0.6964 Best avg r: 0.7430
07:02:29,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:03:35,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:04:40,264 root INFO Epoch 11 Global steps: 88000 Train loss: 0.1124
ro_en Dev loss: 0.3635 r:0.8109
et_en Dev loss: 0.4608 r:0.6645
si_en Dev loss: 0.9163 r:0.5414
ne_en Dev loss: 0.5858 r:0.7101
ru_en Dev loss: 0.4591 r:0.7392
Current avg r:0.6932 Best avg r: 0.7430
07:07:54,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:59,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:10:04,926 root INFO Epoch 11 Global steps: 88500 Train loss: 0.1045
ro_en Dev loss: 0.3788 r:0.8080
et_en Dev loss: 0.4932 r:0.6618
si_en Dev loss: 0.9432 r:0.5392
ne_en Dev loss: 0.5917 r:0.7114
ru_en Dev loss: 0.4566 r:0.7368
Current avg r:0.6914 Best avg r: 0.7430
07:13:19,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:14:24,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:29,673 root INFO Epoch 11 Global steps: 89000 Train loss: 0.1091
ro_en Dev loss: 0.3724 r:0.8069
et_en Dev loss: 0.4607 r:0.6581
si_en Dev loss: 0.9033 r:0.5431
ne_en Dev loss: 0.5327 r:0.7142
ru_en Dev loss: 0.4773 r:0.7255
Current avg r:0.6896 Best avg r: 0.7430
07:18:44,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:19:49,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:54,657 root INFO Epoch 11 Global steps: 89500 Train loss: 0.1109
ro_en Dev loss: 0.3770 r:0.8089
et_en Dev loss: 0.4750 r:0.6682
si_en Dev loss: 0.9096 r:0.5443
ne_en Dev loss: 0.5590 r:0.7163
ru_en Dev loss: 0.4611 r:0.7325
Current avg r:0.6940 Best avg r: 0.7430
07:24:17,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:22,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:27,815 root INFO Epoch 11 Global steps: 90000 Train loss: 0.1082
ro_en Dev loss: 0.3812 r:0.8107
et_en Dev loss: 0.5141 r:0.6691
si_en Dev loss: 0.8908 r:0.5481
ne_en Dev loss: 0.5657 r:0.7143
ru_en Dev loss: 0.4836 r:0.7316
Current avg r:0.6947 Best avg r: 0.7430
07:29:43,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:30:48,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:31:53,981 root INFO Epoch 12 Global steps: 90500 Train loss: 0.1079
ro_en Dev loss: 0.4102 r:0.8089
et_en Dev loss: 0.4821 r:0.6591
si_en Dev loss: 0.9773 r:0.5427
ne_en Dev loss: 0.7222 r:0.7106
ru_en Dev loss: 0.5211 r:0.7204
Current avg r:0.6884 Best avg r: 0.7430
07:35:13,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:36:19,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:24,652 root INFO Epoch 12 Global steps: 91000 Train loss: 0.1063
ro_en Dev loss: 0.4007 r:0.8078
et_en Dev loss: 0.4790 r:0.6582
si_en Dev loss: 0.9332 r:0.5405
ne_en Dev loss: 0.6223 r:0.7103
ru_en Dev loss: 0.5248 r:0.7131
Current avg r:0.6860 Best avg r: 0.7430
07:40:46,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:41:52,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:57,631 root INFO Epoch 12 Global steps: 91500 Train loss: 0.1082
ro_en Dev loss: 0.3621 r:0.8119
et_en Dev loss: 0.4478 r:0.6647
si_en Dev loss: 0.9170 r:0.5414
ne_en Dev loss: 0.6621 r:0.7050
ru_en Dev loss: 0.4907 r:0.7119
Current avg r:0.6870 Best avg r: 0.7430
07:46:20,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:25,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:48:30,721 root INFO Epoch 12 Global steps: 92000 Train loss: 0.1035
ro_en Dev loss: 0.3916 r:0.8086
et_en Dev loss: 0.4508 r:0.6621
si_en Dev loss: 0.9856 r:0.5371
ne_en Dev loss: 0.6121 r:0.7160
ru_en Dev loss: 0.4993 r:0.7277
Current avg r:0.6903 Best avg r: 0.7430
07:51:53,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:52:58,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:54:03,746 root INFO Epoch 12 Global steps: 92500 Train loss: 0.1033
ro_en Dev loss: 0.3831 r:0.8076
et_en Dev loss: 0.4848 r:0.6657
si_en Dev loss: 0.9272 r:0.5413
ne_en Dev loss: 0.5995 r:0.7112
ru_en Dev loss: 0.4682 r:0.7354
Current avg r:0.6922 Best avg r: 0.7430
07:57:26,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:58:31,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:59:36,878 root INFO Epoch 12 Global steps: 93000 Train loss: 0.1003
ro_en Dev loss: 0.3605 r:0.8081
et_en Dev loss: 0.4823 r:0.6536
si_en Dev loss: 0.8796 r:0.5383
ne_en Dev loss: 0.5846 r:0.7099
ru_en Dev loss: 0.4936 r:0.7174
Current avg r:0.6854 Best avg r: 0.7430
08:02:59,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:04:04,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:05:09,811 root INFO Epoch 12 Global steps: 93500 Train loss: 0.1059
ro_en Dev loss: 0.3778 r:0.8115
et_en Dev loss: 0.4660 r:0.6620
si_en Dev loss: 0.9659 r:0.5336
ne_en Dev loss: 0.6327 r:0.7128
ru_en Dev loss: 0.5095 r:0.7144
Current avg r:0.6869 Best avg r: 0.7430
08:08:32,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:37,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:42,749 root INFO Epoch 12 Global steps: 94000 Train loss: 0.0973
ro_en Dev loss: 0.3477 r:0.8147
et_en Dev loss: 0.4624 r:0.6687
si_en Dev loss: 0.9079 r:0.5409
ne_en Dev loss: 0.6053 r:0.7125
ru_en Dev loss: 0.4434 r:0.7384
Current avg r:0.6950 Best avg r: 0.7430
08:13:58,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:03,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:08,800 root INFO Epoch 12 Global steps: 94500 Train loss: 0.1033
ro_en Dev loss: 0.3924 r:0.8085
et_en Dev loss: 0.4851 r:0.6618
si_en Dev loss: 0.9314 r:0.5395
ne_en Dev loss: 0.6006 r:0.7123
ru_en Dev loss: 0.5069 r:0.7233
Current avg r:0.6891 Best avg r: 0.7430
08:19:31,28 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:20:36,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:21:41,731 root INFO Epoch 12 Global steps: 95000 Train loss: 0.0983
ro_en Dev loss: 0.3743 r:0.8102
et_en Dev loss: 0.4743 r:0.6616
si_en Dev loss: 0.8672 r:0.5497
ne_en Dev loss: 0.5624 r:0.7075
ru_en Dev loss: 0.4917 r:0.7198
Current avg r:0.6898 Best avg r: 0.7430
08:25:03,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:09,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:27:14,357 root INFO Epoch 12 Global steps: 95500 Train loss: 0.0944
ro_en Dev loss: 0.4057 r:0.8073
et_en Dev loss: 0.4805 r:0.6620
si_en Dev loss: 1.0186 r:0.5359
ne_en Dev loss: 0.6307 r:0.7084
ru_en Dev loss: 0.4921 r:0.7331
Current avg r:0.6893 Best avg r: 0.7430
08:30:28,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:31:34,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:32:39,305 root INFO Epoch 12 Global steps: 96000 Train loss: 0.1037
ro_en Dev loss: 0.4024 r:0.8089
et_en Dev loss: 0.4845 r:0.6643
si_en Dev loss: 1.0241 r:0.5390
ne_en Dev loss: 0.6026 r:0.7119
ru_en Dev loss: 0.5361 r:0.7295
Current avg r:0.6907 Best avg r: 0.7430
08:35:53,772 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:58,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:38:04,95 root INFO Epoch 12 Global steps: 96500 Train loss: 0.0998
ro_en Dev loss: 0.3976 r:0.8123
et_en Dev loss: 0.4754 r:0.6608
si_en Dev loss: 1.0803 r:0.5327
ne_en Dev loss: 0.7249 r:0.7090
ru_en Dev loss: 0.5135 r:0.7323
Current avg r:0.6894 Best avg r: 0.7430
08:41:20,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:26,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:31,918 root INFO Epoch 12 Global steps: 97000 Train loss: 0.0949
ro_en Dev loss: 0.3819 r:0.8127
et_en Dev loss: 0.4721 r:0.6600
si_en Dev loss: 0.9839 r:0.5387
ne_en Dev loss: 0.5861 r:0.7106
ru_en Dev loss: 0.5022 r:0.7292
Current avg r:0.6902 Best avg r: 0.7430
08:46:49,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:55,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:00,961 root INFO Epoch 12 Global steps: 97500 Train loss: 0.1021
ro_en Dev loss: 0.3844 r:0.8076
et_en Dev loss: 0.4909 r:0.6708
si_en Dev loss: 0.9280 r:0.5429
ne_en Dev loss: 0.5925 r:0.7059
ru_en Dev loss: 0.4642 r:0.7387
Current avg r:0.6932 Best avg r: 0.7430
08:52:26,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:32,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:37,796 root INFO Epoch 13 Global steps: 98000 Train loss: 0.0914
ro_en Dev loss: 0.3581 r:0.8153
et_en Dev loss: 0.4677 r:0.6658
si_en Dev loss: 0.8826 r:0.5466
ne_en Dev loss: 0.5270 r:0.7144
ru_en Dev loss: 0.4367 r:0.7452
Current avg r:0.6975 Best avg r: 0.7430
08:57:54,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:59:00,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:00:06,30 root INFO Epoch 13 Global steps: 98500 Train loss: 0.0895
ro_en Dev loss: 0.3584 r:0.8143
et_en Dev loss: 0.4666 r:0.6674
si_en Dev loss: 0.9492 r:0.5408
ne_en Dev loss: 0.5959 r:0.7171
ru_en Dev loss: 0.4644 r:0.7383
Current avg r:0.6956 Best avg r: 0.7430
09:03:21,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:04:26,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:05:32,196 root INFO Epoch 13 Global steps: 99000 Train loss: 0.0903
ro_en Dev loss: 0.3479 r:0.8144
et_en Dev loss: 0.4418 r:0.6736
si_en Dev loss: 0.8715 r:0.5507
ne_en Dev loss: 0.5220 r:0.7162
ru_en Dev loss: 0.4448 r:0.7408
Current avg r:0.6992 Best avg r: 0.7430
09:08:46,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:52,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:57,282 root INFO Epoch 13 Global steps: 99500 Train loss: 0.0918
ro_en Dev loss: 0.3612 r:0.8124
et_en Dev loss: 0.4662 r:0.6694
si_en Dev loss: 0.8724 r:0.5513
ne_en Dev loss: 0.5482 r:0.7139
ru_en Dev loss: 0.4848 r:0.7371
Current avg r:0.6968 Best avg r: 0.7430
09:14:12,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:17,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:22,515 root INFO Epoch 13 Global steps: 100000 Train loss: 0.0916
ro_en Dev loss: 0.3926 r:0.8059
et_en Dev loss: 0.4889 r:0.6538
si_en Dev loss: 1.0046 r:0.5327
ne_en Dev loss: 0.6563 r:0.7003
ru_en Dev loss: 0.4936 r:0.7272
Current avg r:0.6840 Best avg r: 0.7430
09:19:40,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:20:45,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:21:50,774 root INFO Epoch 13 Global steps: 100500 Train loss: 0.0877
ro_en Dev loss: 0.3599 r:0.8099
et_en Dev loss: 0.4351 r:0.6712
si_en Dev loss: 0.8825 r:0.5509
ne_en Dev loss: 0.5515 r:0.7175
ru_en Dev loss: 0.4405 r:0.7449
Current avg r:0.6989 Best avg r: 0.7430
09:25:05,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:26:10,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:27:15,908 root INFO Epoch 13 Global steps: 101000 Train loss: 0.0917
ro_en Dev loss: 0.3713 r:0.8082
et_en Dev loss: 0.4692 r:0.6700
si_en Dev loss: 0.8578 r:0.5559
ne_en Dev loss: 0.5484 r:0.7199
ru_en Dev loss: 0.4616 r:0.7377
Current avg r:0.6983 Best avg r: 0.7430
09:30:30,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:31:35,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:32:41,67 root INFO Epoch 13 Global steps: 101500 Train loss: 0.0934
ro_en Dev loss: 0.3823 r:0.8098
et_en Dev loss: 0.4765 r:0.6529
si_en Dev loss: 1.0039 r:0.5369
ne_en Dev loss: 0.6589 r:0.7138
ru_en Dev loss: 0.4742 r:0.7293
Current avg r:0.6885 Best avg r: 0.7430
09:36:03,486 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:37:08,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:38:14,226 root INFO Epoch 13 Global steps: 102000 Train loss: 0.0844
ro_en Dev loss: 0.3602 r:0.8123
et_en Dev loss: 0.4748 r:0.6671
si_en Dev loss: 0.8391 r:0.5526
ne_en Dev loss: 0.5450 r:0.7125
ru_en Dev loss: 0.4642 r:0.7343
Current avg r:0.6958 Best avg r: 0.7430
09:41:35,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:40,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:45,857 root INFO Epoch 13 Global steps: 102500 Train loss: 0.0891
ro_en Dev loss: 0.3681 r:0.8106
et_en Dev loss: 0.4775 r:0.6730
si_en Dev loss: 0.8751 r:0.5524
ne_en Dev loss: 0.5558 r:0.7212
ru_en Dev loss: 0.4460 r:0.7402
Current avg r:0.6995 Best avg r: 0.7430
09:47:00,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:05,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:11,181 root INFO Epoch 13 Global steps: 103000 Train loss: 0.0906
ro_en Dev loss: 0.3674 r:0.8076
et_en Dev loss: 0.4617 r:0.6509
si_en Dev loss: 0.9955 r:0.5349
ne_en Dev loss: 0.6593 r:0.7157
ru_en Dev loss: 0.4728 r:0.7225
Current avg r:0.6863 Best avg r: 0.7430
09:52:25,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:31,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:54:36,419 root INFO Epoch 13 Global steps: 103500 Train loss: 0.0900
ro_en Dev loss: 0.3538 r:0.8135
et_en Dev loss: 0.4590 r:0.6630
si_en Dev loss: 0.8661 r:0.5500
ne_en Dev loss: 0.5314 r:0.7087
ru_en Dev loss: 0.4643 r:0.7340
Current avg r:0.6938 Best avg r: 0.7430
09:57:51,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:56,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:01,441 root INFO Epoch 13 Global steps: 104000 Train loss: 0.0896
ro_en Dev loss: 0.3523 r:0.8093
et_en Dev loss: 0.4661 r:0.6595
si_en Dev loss: 0.8940 r:0.5463
ne_en Dev loss: 0.5715 r:0.7081
ru_en Dev loss: 0.4451 r:0.7337
Current avg r:0.6914 Best avg r: 0.7430
10:03:16,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:21,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:26,575 root INFO Epoch 13 Global steps: 104500 Train loss: 0.0895
ro_en Dev loss: 0.3492 r:0.8138
et_en Dev loss: 0.4543 r:0.6617
si_en Dev loss: 0.8795 r:0.5526
ne_en Dev loss: 0.5506 r:0.7119
ru_en Dev loss: 0.4339 r:0.7514
Current avg r:0.6983 Best avg r: 0.7430
10:08:43,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:09:48,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:54,650 root INFO Epoch 13 Global steps: 105000 Train loss: 0.0882
ro_en Dev loss: 0.3375 r:0.8147
et_en Dev loss: 0.4376 r:0.6757
si_en Dev loss: 0.8092 r:0.5627
ne_en Dev loss: 0.5116 r:0.7227
ru_en Dev loss: 0.4273 r:0.7495
Current avg r:0.7050 Best avg r: 0.7430
10:14:19,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:15:25,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:16:30,786 root INFO Epoch 14 Global steps: 105500 Train loss: 0.0834
ro_en Dev loss: 0.3834 r:0.8105
et_en Dev loss: 0.4603 r:0.6625
si_en Dev loss: 0.9048 r:0.5539
ne_en Dev loss: 0.5474 r:0.7168
ru_en Dev loss: 0.4804 r:0.7438
Current avg r:0.6975 Best avg r: 0.7430
10:19:48,772 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:54,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:00,312 root INFO Epoch 14 Global steps: 106000 Train loss: 0.0834
ro_en Dev loss: 0.3765 r:0.8096
et_en Dev loss: 0.4678 r:0.6689
si_en Dev loss: 0.9079 r:0.5538
ne_en Dev loss: 0.6120 r:0.7111
ru_en Dev loss: 0.4624 r:0.7506
Current avg r:0.6988 Best avg r: 0.7430
10:25:19,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:26:25,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:31,297 root INFO Epoch 14 Global steps: 106500 Train loss: 0.0865
ro_en Dev loss: 0.3635 r:0.8088
et_en Dev loss: 0.4895 r:0.6641
si_en Dev loss: 0.8900 r:0.5495
ne_en Dev loss: 0.5741 r:0.7044
ru_en Dev loss: 0.4582 r:0.7430
Current avg r:0.6940 Best avg r: 0.7430
10:30:47,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:31:52,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:13,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:39,854 root INFO 
id:ro_en cur r: 0.4390 best r: 0.4390
00:38:18,889 root INFO 
id:si_en cur r: 0.2840 best r: 0.2840
00:38:44,962 root INFO 
id:ne_en cur r: 0.5146 best r: 0.5146
00:39:10,856 root INFO 
id:ru_en cur r: 0.3800 best r: 0.3800
00:39:10,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:15,931 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
00:40:15,939 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
00:40:15,944 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
00:40:15,957 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
00:40:15,963 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
00:41:21,40 root INFO Epoch 0 Global steps: 500 Train loss: 0.8913
ro_en Dev loss: 0.8131 r:0.5064
et_en Dev loss: 0.7134 r:0.3948
si_en Dev loss: 0.8095 r:0.3326
ne_en Dev loss: 0.7429 r:0.5351
ru_en Dev loss: 0.7787 r:0.3911
Current avg r:0.4320 Best avg r: 0.4320
00:44:33,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:59,831 root INFO 
id:ro_en cur r: 0.5698 best r: 0.5698
00:45:25,831 root INFO 
id:et_en cur r: 0.4677 best r: 0.4677
00:45:51,875 root INFO 
id:si_en cur r: 0.4209 best r: 0.4209
00:46:17,904 root INFO 
id:ne_en cur r: 0.5865 best r: 0.5865
00:46:43,735 root INFO 
id:ru_en cur r: 0.5089 best r: 0.5089
00:46:43,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:48,651 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
00:47:48,657 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
00:47:48,662 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
00:47:48,668 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
00:47:48,678 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
00:48:53,649 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8709
ro_en Dev loss: 0.6602 r:0.6118
et_en Dev loss: 0.5638 r:0.5286
si_en Dev loss: 0.7205 r:0.4581
ne_en Dev loss: 0.5696 r:0.6435
ru_en Dev loss: 0.6433 r:0.5506
Current avg r:0.5585 Best avg r: 0.5585
00:52:06,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:32,48 root INFO 
id:ro_en cur r: 0.6243 best r: 0.6243
00:52:58,80 root INFO 
id:et_en cur r: 0.5877 best r: 0.5877
00:53:24,136 root INFO 
id:si_en cur r: 0.4224 best r: 0.4224
00:53:50,189 root INFO 
id:ne_en cur r: 0.5940 best r: 0.5940
00:54:16,33 root INFO 
id:ru_en cur r: 0.6303 best r: 0.6303
00:54:16,34 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:21,29 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
00:55:21,35 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
00:55:21,40 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
00:55:21,52 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
00:55:21,59 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
00:56:26,32 root INFO Epoch 0 Global steps: 1500 Train loss: 0.7869
ro_en Dev loss: 0.6599 r:0.6669
et_en Dev loss: 0.4950 r:0.6213
si_en Dev loss: 0.7736 r:0.4978
ne_en Dev loss: 0.5399 r:0.6523
ru_en Dev loss: 0.6146 r:0.6850
Current avg r:0.6247 Best avg r: 0.6247
00:59:38,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:04,552 root INFO 
id:ro_en cur r: 0.6421 best r: 0.6421
01:00:30,620 root INFO 
id:et_en cur r: 0.6380 best r: 0.6380
01:00:56,701 root INFO 
id:si_en cur r: 0.4593 best r: 0.4593
01:01:22,789 root INFO 
id:ne_en cur r: 0.6457 best r: 0.6457
01:01:48,646 root INFO 
id:ru_en cur r: 0.6818 best r: 0.6818
01:01:48,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:53,609 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:02:53,614 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
01:02:53,619 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
01:02:53,624 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
01:02:53,628 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
01:03:58,644 root INFO Epoch 0 Global steps: 2000 Train loss: 0.7030
ro_en Dev loss: 0.5138 r:0.6679
et_en Dev loss: 0.4023 r:0.6568
si_en Dev loss: 0.6475 r:0.4974
ne_en Dev loss: 0.4394 r:0.6822
ru_en Dev loss: 0.4717 r:0.6963
Current avg r:0.6401 Best avg r: 0.6401
01:07:11,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:37,94 root INFO 
id:ro_en cur r: 0.7048 best r: 0.7048
01:08:03,143 root INFO 
id:et_en cur r: 0.6633 best r: 0.6633
01:08:29,198 root INFO 
id:si_en cur r: 0.5245 best r: 0.5245
01:08:55,260 root INFO 
id:ne_en cur r: 0.6731 best r: 0.6731
01:09:21,93 root INFO 
id:ru_en cur r: 0.7287 best r: 0.7287
01:09:21,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:26,48 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:10:26,54 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
01:10:26,63 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
01:10:26,67 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
01:10:26,72 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
01:11:31,59 root INFO Epoch 0 Global steps: 2500 Train loss: 0.6544
ro_en Dev loss: 0.4997 r:0.7240
et_en Dev loss: 0.3954 r:0.6829
si_en Dev loss: 0.6872 r:0.5421
ne_en Dev loss: 0.4696 r:0.6783
ru_en Dev loss: 0.4761 r:0.7387
Current avg r:0.6732 Best avg r: 0.6732
01:14:43,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:09,515 root INFO 
id:ro_en cur r: 0.7291 best r: 0.7291
01:15:35,541 root INFO 
id:et_en cur r: 0.6770 best r: 0.6770
01:16:01,581 root INFO 
id:si_en cur r: 0.5355 best r: 0.5355
01:16:27,607 root INFO 
id:ne_en cur r: 0.6853 best r: 0.6853
01:16:53,437 root INFO 
id:ru_en cur r: 0.7306 best r: 0.7306
01:16:53,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:58,396 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
01:17:58,402 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
01:17:58,407 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
01:17:58,412 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
01:17:58,417 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
01:19:03,400 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6047
ro_en Dev loss: 0.4243 r:0.7469
et_en Dev loss: 0.3686 r:0.6946
si_en Dev loss: 0.6487 r:0.5532
ne_en Dev loss: 0.4543 r:0.6856
ru_en Dev loss: 0.4395 r:0.7403
Current avg r:0.6841 Best avg r: 0.6841
09:55:12,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:37,909 root INFO 
id:ro_en cur r: 0.5467 best r: 0.5467
09:56:03,802 root INFO 
id:et_en cur r: 0.5459 best r: 0.5459
09:56:29,723 root INFO 
id:si_en cur r: 0.3740 best r: 0.3740
09:56:55,658 root INFO 
id:ne_en cur r: 0.5062 best r: 0.5062
09:57:21,490 root INFO 
id:ru_en cur r: 0.5893 best r: 0.5893
09:57:21,490 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:26,330 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
09:58:26,337 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
09:58:26,343 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
09:58:26,348 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
09:58:26,353 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
09:59:31,382 root INFO Epoch 0 Global steps: 500 Train loss: 0.8532
ro_en Dev loss: 0.5898 r:0.5746
et_en Dev loss: 0.5531 r:0.5554
si_en Dev loss: 0.6513 r:0.4421
ne_en Dev loss: 0.6087 r:0.5137
ru_en Dev loss: 0.5654 r:0.5900
Current avg r:0.5352 Best avg r: 0.5352
10:02:43,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:03:09,662 root INFO 
id:ro_en cur r: 0.5725 best r: 0.5725
10:03:35,658 root INFO 
id:et_en cur r: 0.5478 best r: 0.5478
10:04:14,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:19,484 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:05:19,491 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
10:05:19,495 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
10:05:19,503 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
10:05:19,545 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
10:06:24,860 root INFO Epoch 0 Global steps: 1000 Train loss: 0.7788
ro_en Dev loss: 0.5933 r:0.6278
et_en Dev loss: 0.5307 r:0.5300
si_en Dev loss: 0.7260 r:0.4443
ne_en Dev loss: 0.6085 r:0.5095
ru_en Dev loss: 0.5959 r:0.6201
Current avg r:0.5463 Best avg r: 0.5463
10:09:36,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:02,586 root INFO 
id:ro_en cur r: 0.6116 best r: 0.6116
10:10:28,496 root INFO 
id:et_en cur r: 0.5849 best r: 0.5849
10:10:54,414 root INFO 
id:si_en cur r: 0.4005 best r: 0.4005
10:11:20,393 root INFO 
id:ne_en cur r: 0.5203 best r: 0.5203
10:11:46,141 root INFO 
id:ru_en cur r: 0.6320 best r: 0.6320
10:11:46,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:50,827 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:12:50,834 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
10:12:50,841 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
10:12:50,850 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
10:12:50,854 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
10:13:55,762 root INFO Epoch 0 Global steps: 1500 Train loss: 0.7378
ro_en Dev loss: 0.5880 r:0.6476
et_en Dev loss: 0.4947 r:0.5790
si_en Dev loss: 0.7435 r:0.4653
ne_en Dev loss: 0.5850 r:0.5592
ru_en Dev loss: 0.5328 r:0.6632
Current avg r:0.5828 Best avg r: 0.5828
10:17:07,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:17:33,332 root INFO 
id:ro_en cur r: 0.6788 best r: 0.6788
10:17:59,279 root INFO 
id:et_en cur r: 0.6359 best r: 0.6359
10:18:25,241 root INFO 
id:si_en cur r: 0.4871 best r: 0.4871
10:18:51,174 root INFO 
id:ne_en cur r: 0.5959 best r: 0.5959
10:19:16,998 root INFO 
id:ru_en cur r: 0.6862 best r: 0.6862
10:19:16,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:21,702 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:20:21,708 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
10:20:21,714 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
10:20:21,719 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
10:20:21,724 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
10:21:26,620 root INFO Epoch 0 Global steps: 2000 Train loss: 0.6932
ro_en Dev loss: 0.4453 r:0.7092
et_en Dev loss: 0.4239 r:0.6440
si_en Dev loss: 0.6064 r:0.5278
ne_en Dev loss: 0.5043 r:0.6390
ru_en Dev loss: 0.4560 r:0.7051
Current avg r:0.6450 Best avg r: 0.6450
10:24:38,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:04,36 root INFO 
id:ro_en cur r: 0.6877 best r: 0.6877
10:25:29,994 root INFO 
id:et_en cur r: 0.6384 best r: 0.6384
10:25:55,967 root INFO 
id:si_en cur r: 0.4961 best r: 0.4961
10:26:21,915 root INFO 
id:ne_en cur r: 0.6490 best r: 0.6490
10:26:34,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:39,484 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:27:39,491 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
10:27:39,523 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
10:27:39,528 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
10:27:39,533 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
10:28:44,336 root INFO Epoch 0 Global steps: 2500 Train loss: 0.6568
ro_en Dev loss: 0.4273 r:0.7121
et_en Dev loss: 0.4145 r:0.6493
si_en Dev loss: 0.6055 r:0.5321
ne_en Dev loss: 0.4587 r:0.6636
ru_en Dev loss: 0.4718 r:0.6967
Current avg r:0.6508 Best avg r: 0.6508
10:31:55,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:32:21,795 root INFO 
id:ro_en cur r: 0.7089 best r: 0.7089
10:32:47,720 root INFO 
id:et_en cur r: 0.6434 best r: 0.6434
10:33:26,670 root INFO 
id:ne_en cur r: 0.6563 best r: 0.6563
10:33:39,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:34:44,225 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:34:44,256 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
10:34:44,262 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
10:34:44,267 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
10:34:44,276 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
10:35:49,117 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6323
ro_en Dev loss: 0.4117 r:0.7223
et_en Dev loss: 0.4141 r:0.6537
si_en Dev loss: 0.6355 r:0.5226
ne_en Dev loss: 0.4440 r:0.6703
ru_en Dev loss: 0.4654 r:0.6904
Current avg r:0.6519 Best avg r: 0.6519
10:39:00,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:39:26,644 root INFO 
id:ro_en cur r: 0.7252 best r: 0.7252
10:39:52,681 root INFO 
id:et_en cur r: 0.6570 best r: 0.6570
10:40:18,799 root INFO 
id:si_en cur r: 0.4974 best r: 0.4974
10:40:44,880 root INFO 
id:ne_en cur r: 0.6789 best r: 0.6789
10:40:57,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:42:02,785 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:42:02,791 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
10:42:02,796 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
10:42:02,800 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
10:42:02,807 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
10:43:07,902 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6036
ro_en Dev loss: 0.3996 r:0.7379
et_en Dev loss: 0.3958 r:0.6679
si_en Dev loss: 0.6439 r:0.5394
ne_en Dev loss: 0.4272 r:0.6841
ru_en Dev loss: 0.4596 r:0.7057
Current avg r:0.6670 Best avg r: 0.6670
10:46:19,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:46:45,517 root INFO 
id:ro_en cur r: 0.7318 best r: 0.7318
10:47:11,549 root INFO 
id:et_en cur r: 0.6613 best r: 0.6613
10:47:37,648 root INFO 
id:si_en cur r: 0.4989 best r: 0.4989
10:48:16,577 root INFO 
id:ru_en cur r: 0.6995 best r: 0.6995
10:48:16,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:49:21,614 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:49:21,621 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
10:49:21,667 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
10:49:21,672 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
10:49:21,678 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
10:50:26,980 root INFO Epoch 0 Global steps: 4000 Train loss: 0.5941
ro_en Dev loss: 0.4018 r:0.7488
et_en Dev loss: 0.3856 r:0.6751
si_en Dev loss: 0.7041 r:0.5412
ne_en Dev loss: 0.4497 r:0.6839
ru_en Dev loss: 0.4820 r:0.7170
Current avg r:0.6732 Best avg r: 0.6732
10:53:45,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:54:11,983 root INFO 
id:ro_en cur r: 0.7501 best r: 0.7501
10:54:38,64 root INFO 
id:et_en cur r: 0.6756 best r: 0.6756
10:55:04,143 root INFO 
id:si_en cur r: 0.5250 best r: 0.5250
10:55:30,248 root INFO 
id:ne_en cur r: 0.6998 best r: 0.6998
10:55:56,144 root INFO 
id:ru_en cur r: 0.7121 best r: 0.7121
10:55:56,144 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:57:01,151 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
10:57:01,159 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
10:57:01,163 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
10:57:01,168 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
10:57:01,174 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
10:58:06,363 root INFO Epoch 0 Global steps: 4500 Train loss: 0.5662
ro_en Dev loss: 0.3725 r:0.7640
et_en Dev loss: 0.3737 r:0.6912
si_en Dev loss: 0.6281 r:0.5642
ne_en Dev loss: 0.4286 r:0.7062
ru_en Dev loss: 0.4279 r:0.7263
Current avg r:0.6904 Best avg r: 0.6904
11:01:18,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:01:44,469 root INFO 
id:ro_en cur r: 0.7567 best r: 0.7567
11:02:10,428 root INFO 
id:et_en cur r: 0.6770 best r: 0.6770
11:02:36,434 root INFO 
id:si_en cur r: 0.5419 best r: 0.5419
11:03:02,471 root INFO 
id:ne_en cur r: 0.7060 best r: 0.7060
11:03:28,317 root INFO 
id:ru_en cur r: 0.7196 best r: 0.7196
11:03:28,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:04:33,226 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
11:04:33,233 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
11:04:33,238 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
11:04:33,242 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
11:04:33,247 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
11:05:38,287 root INFO Epoch 0 Global steps: 5000 Train loss: 0.5749
ro_en Dev loss: 0.3960 r:0.7685
et_en Dev loss: 0.3780 r:0.6849
si_en Dev loss: 0.6233 r:0.5685
ne_en Dev loss: 0.4159 r:0.7083
ru_en Dev loss: 0.4550 r:0.7268
Current avg r:0.6914 Best avg r: 0.6914
11:08:50,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:09:16,227 root INFO 
id:ro_en cur r: 0.7632 best r: 0.7632
11:09:42,165 root INFO 
id:et_en cur r: 0.6771 best r: 0.6771
11:10:20,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:11:25,666 root INFO Epoch 0 Global steps: 5500 Train loss: 0.5475
ro_en Dev loss: 0.4323 r:0.7729
et_en Dev loss: 0.3936 r:0.6830
si_en Dev loss: 0.7642 r:0.5484
ne_en Dev loss: 0.4778 r:0.6905
ru_en Dev loss: 0.5293 r:0.7167
Current avg r:0.6823 Best avg r: 0.6914
11:14:37,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:15:03,217 root INFO 
id:ro_en cur r: 0.7780 best r: 0.7780
11:15:29,174 root INFO 
id:et_en cur r: 0.6877 best r: 0.6877
11:16:08,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:17:12,680 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5412
ro_en Dev loss: 0.4000 r:0.7785
et_en Dev loss: 0.3917 r:0.6897
si_en Dev loss: 0.7711 r:0.5594
ne_en Dev loss: 0.4223 r:0.7071
ru_en Dev loss: 0.5801 r:0.7095
Current avg r:0.6888 Best avg r: 0.6914
11:20:24,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:21:03,342 root INFO 
id:et_en cur r: 0.6878 best r: 0.6878
11:21:29,326 root INFO 
id:si_en cur r: 0.5574 best r: 0.5574
11:21:55,351 root INFO 
id:ne_en cur r: 0.7229 best r: 0.7229
11:22:08,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:23:12,967 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
11:23:12,974 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
11:23:12,979 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
11:23:12,985 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
11:23:12,990 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
11:24:17,804 root INFO Epoch 0 Global steps: 6500 Train loss: 0.5372
ro_en Dev loss: 0.3847 r:0.7832
et_en Dev loss: 0.3859 r:0.6933
si_en Dev loss: 0.6715 r:0.5735
ne_en Dev loss: 0.3762 r:0.7265
ru_en Dev loss: 0.5252 r:0.7229
Current avg r:0.6999 Best avg r: 0.6999
11:27:29,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:27:55,505 root INFO 
id:ro_en cur r: 0.7792 best r: 0.7792
11:28:47,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:29:51,988 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5166
ro_en Dev loss: 0.4109 r:0.7878
et_en Dev loss: 0.3914 r:0.6906
si_en Dev loss: 0.7665 r:0.5665
ne_en Dev loss: 0.5035 r:0.7132
ru_en Dev loss: 0.5806 r:0.7190
Current avg r:0.6954 Best avg r: 0.6999
11:33:03,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:33:29,649 root INFO 
id:ro_en cur r: 0.8002 best r: 0.8002
11:33:55,591 root INFO 
id:et_en cur r: 0.6976 best r: 0.6976
11:34:21,588 root INFO 
id:si_en cur r: 0.5936 best r: 0.5936
11:34:47,545 root INFO 
id:ne_en cur r: 0.7437 best r: 0.7437
11:35:13,346 root INFO 
id:ru_en cur r: 0.7236 best r: 0.7236
11:35:13,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:36:18,53 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
11:36:18,60 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
11:36:18,65 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
11:36:18,103 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
11:36:18,109 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
11:37:22,922 root INFO Epoch 0 Global steps: 7500 Train loss: 0.5195
ro_en Dev loss: 0.3270 r:0.7978
et_en Dev loss: 0.3652 r:0.7047
si_en Dev loss: 0.5495 r:0.6034
ne_en Dev loss: 0.3702 r:0.7403
ru_en Dev loss: 0.4218 r:0.7329
Current avg r:0.7158 Best avg r: 0.7158
11:40:36,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:41:53,975 root INFO 
id:ru_en cur r: 0.7340 best r: 0.7340
11:41:53,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:42:58,715 root INFO Epoch 1 Global steps: 8000 Train loss: 0.4921
ro_en Dev loss: 0.3964 r:0.7927
et_en Dev loss: 0.3850 r:0.6977
si_en Dev loss: 0.7365 r:0.5829
ne_en Dev loss: 0.4789 r:0.7343
ru_en Dev loss: 0.4833 r:0.7360
Current avg r:0.7087 Best avg r: 0.7158
11:46:10,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:46:36,442 root INFO 
id:ro_en cur r: 0.8047 best r: 0.8047
11:47:02,415 root INFO 
id:et_en cur r: 0.7009 best r: 0.7009
11:47:28,401 root INFO 
id:si_en cur r: 0.5950 best r: 0.5950
11:47:54,351 root INFO 
id:ne_en cur r: 0.7539 best r: 0.7539
11:48:07,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:49:11,947 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
11:49:11,956 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
11:49:11,961 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
11:49:11,983 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
11:49:12,15 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
11:50:16,827 root INFO Epoch 1 Global steps: 8500 Train loss: 0.5103
ro_en Dev loss: 0.3440 r:0.8058
et_en Dev loss: 0.3608 r:0.7047
si_en Dev loss: 0.6753 r:0.5968
ne_en Dev loss: 0.3945 r:0.7440
ru_en Dev loss: 0.5134 r:0.7312
Current avg r:0.7165 Best avg r: 0.7165
11:53:28,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:54:33,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
11:55:38,41 root INFO Epoch 1 Global steps: 9000 Train loss: 0.4653
ro_en Dev loss: 0.3439 r:0.7985
et_en Dev loss: 0.3702 r:0.6959
si_en Dev loss: 0.6398 r:0.5888
ne_en Dev loss: 0.3975 r:0.7361
ru_en Dev loss: 0.4977 r:0.7144
Current avg r:0.7067 Best avg r: 0.7165
11:58:51,294 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
11:59:56,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:01:01,588 root INFO Epoch 1 Global steps: 9500 Train loss: 0.4808
ro_en Dev loss: 0.3864 r:0.7992
et_en Dev loss: 0.3845 r:0.6975
si_en Dev loss: 0.7071 r:0.5954
ne_en Dev loss: 0.4367 r:0.7468
ru_en Dev loss: 0.5075 r:0.7332
Current avg r:0.7144 Best avg r: 0.7165
12:04:16,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:04:42,770 root INFO 
id:ro_en cur r: 0.8069 best r: 0.8069
12:05:21,714 root INFO 
id:si_en cur r: 0.6016 best r: 0.6016
12:05:47,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:06:52,346 root INFO Epoch 1 Global steps: 10000 Train loss: 0.4815
ro_en Dev loss: 0.3640 r:0.8029
et_en Dev loss: 0.3892 r:0.6918
si_en Dev loss: 0.7166 r:0.5910
ne_en Dev loss: 0.4125 r:0.7418
ru_en Dev loss: 0.4862 r:0.7340
Current avg r:0.7123 Best avg r: 0.7165
12:10:04,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:10:30,324 root INFO 
id:ro_en cur r: 0.8101 best r: 0.8101
12:11:09,453 root INFO 
id:si_en cur r: 0.6030 best r: 0.6030
12:11:35,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:12:40,503 root INFO Epoch 1 Global steps: 10500 Train loss: 0.4582
ro_en Dev loss: 0.3393 r:0.8037
et_en Dev loss: 0.3863 r:0.6918
si_en Dev loss: 0.6351 r:0.5935
ne_en Dev loss: 0.3809 r:0.7407
ru_en Dev loss: 0.5031 r:0.7142
Current avg r:0.7088 Best avg r: 0.7165
12:15:52,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:16:31,584 root INFO 
id:et_en cur r: 0.7043 best r: 0.7043
12:16:57,561 root INFO 
id:si_en cur r: 0.6115 best r: 0.6115
12:17:36,351 root INFO 
id:ru_en cur r: 0.7625 best r: 0.7625
12:17:36,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:18:41,109 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
12:18:41,118 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
12:18:41,123 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
12:18:41,142 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
12:18:41,146 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
12:19:46,2 root INFO Epoch 1 Global steps: 11000 Train loss: 0.4785
ro_en Dev loss: 0.3649 r:0.8011
et_en Dev loss: 0.3828 r:0.7043
si_en Dev loss: 0.6083 r:0.6057
ne_en Dev loss: 0.3672 r:0.7478
ru_en Dev loss: 0.4203 r:0.7601
Current avg r:0.7238 Best avg r: 0.7238
12:22:57,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:23:23,990 root INFO 
id:ro_en cur r: 0.8180 best r: 0.8180
12:23:50,90 root INFO 
id:et_en cur r: 0.7055 best r: 0.7055
12:24:16,179 root INFO 
id:si_en cur r: 0.6120 best r: 0.6120
12:24:42,289 root INFO 
id:ne_en cur r: 0.7575 best r: 0.7575
12:24:55,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:26:00,337 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
12:26:00,345 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
12:26:00,350 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
12:26:00,355 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
12:26:00,359 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
12:27:05,583 root INFO Epoch 1 Global steps: 11500 Train loss: 0.4841
ro_en Dev loss: 0.3257 r:0.8111
et_en Dev loss: 0.3569 r:0.7097
si_en Dev loss: 0.6106 r:0.6133
ne_en Dev loss: 0.4867 r:0.7502
ru_en Dev loss: 0.4039 r:0.7580
Current avg r:0.7285 Best avg r: 0.7285
12:30:17,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:31:22,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:32:27,587 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4593
ro_en Dev loss: 0.4281 r:0.7974
et_en Dev loss: 0.4061 r:0.6953
si_en Dev loss: 0.8436 r:0.5884
ne_en Dev loss: 0.6187 r:0.7365
ru_en Dev loss: 0.5695 r:0.7210
Current avg r:0.7077 Best avg r: 0.7285
12:35:39,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:36:45,29 root INFO 
id:ne_en cur r: 0.7598 best r: 0.7598
12:36:57,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:38:02,961 root INFO Epoch 1 Global steps: 12500 Train loss: 0.4548
ro_en Dev loss: 0.4277 r:0.8094
et_en Dev loss: 0.3921 r:0.7042
si_en Dev loss: 0.7495 r:0.6055
ne_en Dev loss: 0.5338 r:0.7529
ru_en Dev loss: 0.5344 r:0.7368
Current avg r:0.7218 Best avg r: 0.7285
12:41:14,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:42:19,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:43:24,844 root INFO Epoch 1 Global steps: 13000 Train loss: 0.4571
ro_en Dev loss: 0.4211 r:0.8051
et_en Dev loss: 0.4271 r:0.6900
si_en Dev loss: 0.8848 r:0.5869
ne_en Dev loss: 0.6012 r:0.7437
ru_en Dev loss: 0.5169 r:0.7304
Current avg r:0.7112 Best avg r: 0.7285
12:46:36,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:47:41,498 root INFO 
id:ne_en cur r: 0.7620 best r: 0.7620
12:47:54,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:48:59,15 root INFO Epoch 1 Global steps: 13500 Train loss: 0.4322
ro_en Dev loss: 0.3637 r:0.8135
et_en Dev loss: 0.3898 r:0.6961
si_en Dev loss: 0.7338 r:0.6104
ne_en Dev loss: 0.5058 r:0.7538
ru_en Dev loss: 0.4979 r:0.7398
Current avg r:0.7227 Best avg r: 0.7285
12:52:10,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:52:36,493 root INFO 
id:ro_en cur r: 0.8183 best r: 0.8183
12:53:28,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
12:54:33,412 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4403
ro_en Dev loss: 0.3393 r:0.8154
et_en Dev loss: 0.3780 r:0.6989
si_en Dev loss: 0.6690 r:0.6161
ne_en Dev loss: 0.4334 r:0.7576
ru_en Dev loss: 0.4683 r:0.7396
Current avg r:0.7255 Best avg r: 0.7285
12:57:45,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
12:58:11,200 root INFO 
id:ro_en cur r: 0.8282 best r: 0.8282
12:58:37,149 root INFO 
id:et_en cur r: 0.7084 best r: 0.7084
12:59:03,133 root INFO 
id:si_en cur r: 0.6239 best r: 0.6239
12:59:29,86 root INFO 
id:ne_en cur r: 0.7702 best r: 0.7702
12:59:41,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:00:46,664 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ro_en.lang_agnost_mlp.dev.best.scores
13:00:46,671 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/et_en.lang_agnost_mlp.dev.best.scores
13:00:46,679 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/si_en.lang_agnost_mlp.dev.best.scores
13:00:46,684 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ne_en.lang_agnost_mlp.dev.best.scores
13:00:46,690 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run2/ru_en.lang_agnost_mlp.dev.best.scores
13:01:51,449 root INFO Epoch 1 Global steps: 14500 Train loss: 0.4448
ro_en Dev loss: 0.2947 r:0.8266
et_en Dev loss: 0.3669 r:0.7086
si_en Dev loss: 0.5510 r:0.6271
ne_en Dev loss: 0.3683 r:0.7678
ru_en Dev loss: 0.4081 r:0.7573
Current avg r:0.7375 Best avg r: 0.7375
13:05:03,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:06:07,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:07:12,524 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4468
ro_en Dev loss: 0.3280 r:0.8179
et_en Dev loss: 0.3862 r:0.7045
si_en Dev loss: 0.5913 r:0.6162
ne_en Dev loss: 0.3530 r:0.7577
ru_en Dev loss: 0.4204 r:0.7439
Current avg r:0.7280 Best avg r: 0.7375
13:10:25,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:11:30,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:12:35,474 root INFO Epoch 2 Global steps: 15500 Train loss: 0.4330
ro_en Dev loss: 0.3142 r:0.8171
et_en Dev loss: 0.3690 r:0.7006
si_en Dev loss: 0.7077 r:0.6104
ne_en Dev loss: 0.4943 r:0.7582
ru_en Dev loss: 0.4208 r:0.7522
Current avg r:0.7277 Best avg r: 0.7375
13:15:47,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:16:52,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:17:57,780 root INFO Epoch 2 Global steps: 16000 Train loss: 0.4037
ro_en Dev loss: 0.3275 r:0.8123
et_en Dev loss: 0.3766 r:0.6956
si_en Dev loss: 0.6703 r:0.6031
ne_en Dev loss: 0.4336 r:0.7565
ru_en Dev loss: 0.3997 r:0.7535
Current avg r:0.7242 Best avg r: 0.7375
13:21:09,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:22:14,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:23:19,217 root INFO Epoch 2 Global steps: 16500 Train loss: 0.4161
ro_en Dev loss: 0.3477 r:0.8066
et_en Dev loss: 0.3875 r:0.6878
si_en Dev loss: 0.7265 r:0.5951
ne_en Dev loss: 0.4471 r:0.7516
ru_en Dev loss: 0.4593 r:0.7330
Current avg r:0.7148 Best avg r: 0.7375
13:26:30,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:27:35,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:28:40,801 root INFO Epoch 2 Global steps: 17000 Train loss: 0.4072
ro_en Dev loss: 0.3430 r:0.8142
et_en Dev loss: 0.3896 r:0.6943
si_en Dev loss: 0.7016 r:0.6106
ne_en Dev loss: 0.3728 r:0.7620
ru_en Dev loss: 0.4560 r:0.7492
Current avg r:0.7260 Best avg r: 0.7375
13:31:52,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:32:57,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:34:02,125 root INFO Epoch 2 Global steps: 17500 Train loss: 0.3981
ro_en Dev loss: 0.4555 r:0.7999
et_en Dev loss: 0.4768 r:0.6797
si_en Dev loss: 1.1133 r:0.5715
ne_en Dev loss: 0.7362 r:0.7483
ru_en Dev loss: 0.5958 r:0.7120
Current avg r:0.7023 Best avg r: 0.7375
13:37:13,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:38:18,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:39:23,714 root INFO Epoch 2 Global steps: 18000 Train loss: 0.4108
ro_en Dev loss: 0.3266 r:0.8103
et_en Dev loss: 0.3807 r:0.6966
si_en Dev loss: 0.6911 r:0.6032
ne_en Dev loss: 0.3952 r:0.7576
ru_en Dev loss: 0.4033 r:0.7577
Current avg r:0.7251 Best avg r: 0.7375
13:42:35,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:43:40,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:44:45,3 root INFO Epoch 2 Global steps: 18500 Train loss: 0.3971
ro_en Dev loss: 0.3352 r:0.8172
et_en Dev loss: 0.3735 r:0.7031
si_en Dev loss: 0.7049 r:0.6111
ne_en Dev loss: 0.4138 r:0.7662
ru_en Dev loss: 0.4606 r:0.7382
Current avg r:0.7272 Best avg r: 0.7375
13:47:56,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:49:01,402 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:50:06,105 root INFO Epoch 2 Global steps: 19000 Train loss: 0.4022
ro_en Dev loss: 0.3238 r:0.8212
et_en Dev loss: 0.3710 r:0.7026
si_en Dev loss: 0.8290 r:0.6010
ne_en Dev loss: 0.4066 r:0.7656
ru_en Dev loss: 0.4812 r:0.7352
Current avg r:0.7251 Best avg r: 0.7375
13:53:17,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:54:22,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
13:55:27,221 root INFO Epoch 2 Global steps: 19500 Train loss: 0.4036
ro_en Dev loss: 0.3619 r:0.8157
et_en Dev loss: 0.3892 r:0.6962
si_en Dev loss: 0.6803 r:0.6149
ne_en Dev loss: 0.4104 r:0.7605
ru_en Dev loss: 0.5160 r:0.7313
Current avg r:0.7237 Best avg r: 0.7375
13:58:38,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
13:59:43,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:00:48,354 root INFO Epoch 2 Global steps: 20000 Train loss: 0.3854
ro_en Dev loss: 0.3492 r:0.8178
et_en Dev loss: 0.3961 r:0.6916
si_en Dev loss: 0.7622 r:0.6058
ne_en Dev loss: 0.3888 r:0.7638
ru_en Dev loss: 0.5054 r:0.7295
Current avg r:0.7217 Best avg r: 0.7375
14:04:00,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:05:05,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:06:09,841 root INFO Epoch 2 Global steps: 20500 Train loss: 0.3747
ro_en Dev loss: 0.3394 r:0.8144
et_en Dev loss: 0.4099 r:0.6959
si_en Dev loss: 0.6476 r:0.6082
ne_en Dev loss: 0.4115 r:0.7571
ru_en Dev loss: 0.4309 r:0.7490
Current avg r:0.7249 Best avg r: 0.7375
14:09:21,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:10:26,780 root INFO 
id:ne_en cur r: 0.7707 best r: 0.7707
14:10:39,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:11:44,337 root INFO Epoch 2 Global steps: 21000 Train loss: 0.3934
ro_en Dev loss: 0.3259 r:0.8200
et_en Dev loss: 0.3789 r:0.6971
si_en Dev loss: 0.6662 r:0.6183
ne_en Dev loss: 0.3855 r:0.7696
ru_en Dev loss: 0.4863 r:0.7324
Current avg r:0.7275 Best avg r: 0.7375
14:14:56,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:16:01,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:17:06,440 root INFO Epoch 2 Global steps: 21500 Train loss: 0.3863
ro_en Dev loss: 0.3579 r:0.8176
et_en Dev loss: 0.4026 r:0.6949
si_en Dev loss: 0.6453 r:0.6242
ne_en Dev loss: 0.4324 r:0.7637
ru_en Dev loss: 0.5275 r:0.7315
Current avg r:0.7264 Best avg r: 0.7375
14:20:18,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:21:23,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:22:28,535 root INFO Epoch 2 Global steps: 22000 Train loss: 0.3995
ro_en Dev loss: 0.3189 r:0.8177
et_en Dev loss: 0.3843 r:0.6972
si_en Dev loss: 0.6501 r:0.6117
ne_en Dev loss: 0.4053 r:0.7637
ru_en Dev loss: 0.4534 r:0.7334
Current avg r:0.7247 Best avg r: 0.7375
14:25:42,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:26:47,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:27:52,403 root INFO Epoch 2 Global steps: 22500 Train loss: 0.3725
ro_en Dev loss: 0.3243 r:0.8191
et_en Dev loss: 0.3919 r:0.6982
si_en Dev loss: 0.6785 r:0.6115
ne_en Dev loss: 0.4426 r:0.7569
ru_en Dev loss: 0.4404 r:0.7465
Current avg r:0.7265 Best avg r: 0.7375
14:31:05,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:32:10,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:33:15,645 root INFO Epoch 3 Global steps: 23000 Train loss: 0.3484
ro_en Dev loss: 0.3348 r:0.8176
et_en Dev loss: 0.4000 r:0.6926
si_en Dev loss: 0.7806 r:0.6024
ne_en Dev loss: 0.4779 r:0.7566
ru_en Dev loss: 0.4953 r:0.7248
Current avg r:0.7188 Best avg r: 0.7375
14:36:27,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:32,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:38:37,856 root INFO Epoch 3 Global steps: 23500 Train loss: 0.3524
ro_en Dev loss: 0.3774 r:0.8154
et_en Dev loss: 0.4088 r:0.6931
si_en Dev loss: 0.7660 r:0.6035
ne_en Dev loss: 0.4460 r:0.7610
ru_en Dev loss: 0.4972 r:0.7291
Current avg r:0.7204 Best avg r: 0.7375
14:41:50,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:55,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:44:00,517 root INFO Epoch 3 Global steps: 24000 Train loss: 0.3562
ro_en Dev loss: 0.3737 r:0.8122
et_en Dev loss: 0.3976 r:0.6909
si_en Dev loss: 0.7916 r:0.6032
ne_en Dev loss: 0.5211 r:0.7580
ru_en Dev loss: 0.4733 r:0.7348
Current avg r:0.7198 Best avg r: 0.7375
14:47:13,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:18,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:23,309 root INFO Epoch 3 Global steps: 24500 Train loss: 0.3511
ro_en Dev loss: 0.3974 r:0.8071
et_en Dev loss: 0.4199 r:0.6866
si_en Dev loss: 0.8260 r:0.5940
ne_en Dev loss: 0.5536 r:0.7529
ru_en Dev loss: 0.5088 r:0.7251
Current avg r:0.7131 Best avg r: 0.7375
14:52:35,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:40,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:45,572 root INFO Epoch 3 Global steps: 25000 Train loss: 0.3332
ro_en Dev loss: 0.3515 r:0.8158
et_en Dev loss: 0.3929 r:0.6928
si_en Dev loss: 0.7924 r:0.5990
ne_en Dev loss: 0.5044 r:0.7575
ru_en Dev loss: 0.4861 r:0.7321
Current avg r:0.7194 Best avg r: 0.7375
14:57:57,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:02,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:07,536 root INFO Epoch 3 Global steps: 25500 Train loss: 0.3385
ro_en Dev loss: 0.3836 r:0.8104
et_en Dev loss: 0.4160 r:0.6859
si_en Dev loss: 0.8008 r:0.5967
ne_en Dev loss: 0.5645 r:0.7605
ru_en Dev loss: 0.4977 r:0.7242
Current avg r:0.7156 Best avg r: 0.7375
15:03:19,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:24,512 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:29,402 root INFO Epoch 3 Global steps: 26000 Train loss: 0.3487
ro_en Dev loss: 0.3137 r:0.8165
et_en Dev loss: 0.3840 r:0.6926
si_en Dev loss: 0.6411 r:0.6033
ne_en Dev loss: 0.4175 r:0.7626
ru_en Dev loss: 0.4996 r:0.7051
Current avg r:0.7160 Best avg r: 0.7375
15:08:41,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:46,595 root INFO 
id:ne_en cur r: 0.7733 best r: 0.7733
15:09:59,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:04,408 root INFO Epoch 3 Global steps: 26500 Train loss: 0.3295
ro_en Dev loss: 0.3538 r:0.8188
et_en Dev loss: 0.3967 r:0.6929
si_en Dev loss: 0.8111 r:0.5975
ne_en Dev loss: 0.4353 r:0.7708
ru_en Dev loss: 0.5447 r:0.7086
Current avg r:0.7177 Best avg r: 0.7375
15:14:16,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:21,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:26,409 root INFO Epoch 3 Global steps: 27000 Train loss: 0.3432
ro_en Dev loss: 0.3242 r:0.8186
et_en Dev loss: 0.3983 r:0.6925
si_en Dev loss: 0.6984 r:0.6015
ne_en Dev loss: 0.4053 r:0.7668
ru_en Dev loss: 0.4760 r:0.7253
Current avg r:0.7209 Best avg r: 0.7375
15:19:38,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:43,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:48,484 root INFO Epoch 3 Global steps: 27500 Train loss: 0.3348
ro_en Dev loss: 0.3481 r:0.8102
et_en Dev loss: 0.4158 r:0.6762
si_en Dev loss: 0.8118 r:0.5828
ne_en Dev loss: 0.4928 r:0.7567
ru_en Dev loss: 0.4941 r:0.7231
Current avg r:0.7098 Best avg r: 0.7375
15:25:00,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:05,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:10,448 root INFO Epoch 3 Global steps: 28000 Train loss: 0.3408
ro_en Dev loss: 0.4155 r:0.8042
et_en Dev loss: 0.4546 r:0.6714
si_en Dev loss: 0.8837 r:0.5824
ne_en Dev loss: 0.6003 r:0.7537
ru_en Dev loss: 0.6187 r:0.6934
Current avg r:0.7010 Best avg r: 0.7375
15:30:22,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:27,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:32,727 root INFO Epoch 3 Global steps: 28500 Train loss: 0.3346
ro_en Dev loss: 0.3557 r:0.8150
et_en Dev loss: 0.4220 r:0.6828
si_en Dev loss: 0.7825 r:0.5952
ne_en Dev loss: 0.4943 r:0.7586
ru_en Dev loss: 0.4795 r:0.7302
Current avg r:0.7164 Best avg r: 0.7375
15:35:45,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:49,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:37:54,929 root INFO Epoch 3 Global steps: 29000 Train loss: 0.3453
ro_en Dev loss: 0.3884 r:0.8141
et_en Dev loss: 0.4351 r:0.6812
si_en Dev loss: 0.8333 r:0.5918
ne_en Dev loss: 0.4738 r:0.7596
ru_en Dev loss: 0.5228 r:0.7181
Current avg r:0.7130 Best avg r: 0.7375
15:41:07,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:12,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:16,976 root INFO Epoch 3 Global steps: 29500 Train loss: 0.3270
ro_en Dev loss: 0.3500 r:0.8175
et_en Dev loss: 0.4088 r:0.6957
si_en Dev loss: 0.7092 r:0.6056
ne_en Dev loss: 0.3738 r:0.7663
ru_en Dev loss: 0.4624 r:0.7282
Current avg r:0.7227 Best avg r: 0.7375
15:46:29,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:34,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:38,962 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3120
ro_en Dev loss: 0.4025 r:0.8117
et_en Dev loss: 0.4250 r:0.6842
si_en Dev loss: 0.8334 r:0.5849
ne_en Dev loss: 0.5492 r:0.7542
ru_en Dev loss: 0.5645 r:0.7018
Current avg r:0.7074 Best avg r: 0.7375
15:51:52,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:57,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:01,880 root INFO Epoch 4 Global steps: 30500 Train loss: 0.2932
ro_en Dev loss: 0.3917 r:0.8152
et_en Dev loss: 0.4190 r:0.6898
si_en Dev loss: 0.7448 r:0.5955
ne_en Dev loss: 0.5018 r:0.7617
ru_en Dev loss: 0.4712 r:0.7328
Current avg r:0.7190 Best avg r: 0.7375
15:57:13,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:18,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:23,445 root INFO Epoch 4 Global steps: 31000 Train loss: 0.2950
ro_en Dev loss: 0.3238 r:0.8171
et_en Dev loss: 0.4426 r:0.6959
si_en Dev loss: 0.6150 r:0.6033
ne_en Dev loss: 0.4151 r:0.7535
ru_en Dev loss: 0.3961 r:0.7481
Current avg r:0.7236 Best avg r: 0.7375
16:02:35,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:40,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:45,24 root INFO Epoch 4 Global steps: 31500 Train loss: 0.2903
ro_en Dev loss: 0.3479 r:0.8151
et_en Dev loss: 0.4336 r:0.6919
si_en Dev loss: 0.7032 r:0.5966
ne_en Dev loss: 0.4187 r:0.7584
ru_en Dev loss: 0.4155 r:0.7468
Current avg r:0.7218 Best avg r: 0.7375
16:07:56,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:01,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:06,597 root INFO Epoch 4 Global steps: 32000 Train loss: 0.2965
ro_en Dev loss: 0.2993 r:0.8222
et_en Dev loss: 0.3899 r:0.6942
si_en Dev loss: 0.6817 r:0.5970
ne_en Dev loss: 0.4541 r:0.7585
ru_en Dev loss: 0.4149 r:0.7332
Current avg r:0.7210 Best avg r: 0.7375
16:13:18,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:23,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:28,176 root INFO Epoch 4 Global steps: 32500 Train loss: 0.2818
ro_en Dev loss: 0.3806 r:0.8122
et_en Dev loss: 0.4318 r:0.6749
si_en Dev loss: 1.0085 r:0.5712
ne_en Dev loss: 0.6776 r:0.7447
ru_en Dev loss: 0.5554 r:0.7008
Current avg r:0.7008 Best avg r: 0.7375
16:18:41,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:46,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:51,312 root INFO Epoch 4 Global steps: 33000 Train loss: 0.2951
ro_en Dev loss: 0.3665 r:0.8151
et_en Dev loss: 0.4261 r:0.6854
si_en Dev loss: 0.7681 r:0.5907
ne_en Dev loss: 0.4319 r:0.7543
ru_en Dev loss: 0.5145 r:0.7092
Current avg r:0.7109 Best avg r: 0.7375
16:24:03,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:08,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:12,882 root INFO Epoch 4 Global steps: 33500 Train loss: 0.2872
ro_en Dev loss: 0.3140 r:0.8200
et_en Dev loss: 0.4088 r:0.6872
si_en Dev loss: 0.7010 r:0.5956
ne_en Dev loss: 0.3906 r:0.7580
ru_en Dev loss: 0.4243 r:0.7323
Current avg r:0.7186 Best avg r: 0.7375
16:29:24,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:29,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:34,624 root INFO Epoch 4 Global steps: 34000 Train loss: 0.3021
ro_en Dev loss: 0.3629 r:0.8157
et_en Dev loss: 0.4316 r:0.6779
si_en Dev loss: 0.7687 r:0.5863
ne_en Dev loss: 0.4840 r:0.7505
ru_en Dev loss: 0.4726 r:0.7242
Current avg r:0.7109 Best avg r: 0.7375
16:34:49,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:54,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:59,224 root INFO Epoch 4 Global steps: 34500 Train loss: 0.2947
ro_en Dev loss: 0.3365 r:0.8186
et_en Dev loss: 0.4271 r:0.6777
si_en Dev loss: 0.7155 r:0.5916
ne_en Dev loss: 0.4255 r:0.7530
ru_en Dev loss: 0.4837 r:0.7147
Current avg r:0.7111 Best avg r: 0.7375
16:40:19,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:25,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:30,294 root INFO Epoch 4 Global steps: 35000 Train loss: 0.2854
ro_en Dev loss: 0.3656 r:0.8163
et_en Dev loss: 0.4440 r:0.6767
si_en Dev loss: 0.7358 r:0.5990
ne_en Dev loss: 0.5018 r:0.7513
ru_en Dev loss: 0.4545 r:0.7386
Current avg r:0.7164 Best avg r: 0.7375
16:45:48,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:54,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:59,348 root INFO Epoch 4 Global steps: 35500 Train loss: 0.2959
ro_en Dev loss: 0.3260 r:0.8188
et_en Dev loss: 0.4306 r:0.6792
si_en Dev loss: 0.6297 r:0.6084
ne_en Dev loss: 0.3730 r:0.7564
ru_en Dev loss: 0.4420 r:0.7350
Current avg r:0.7196 Best avg r: 0.7375
16:51:19,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:24,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:30,12 root INFO Epoch 4 Global steps: 36000 Train loss: 0.3018
ro_en Dev loss: 0.3314 r:0.8175
et_en Dev loss: 0.4397 r:0.6798
si_en Dev loss: 0.6852 r:0.5983
ne_en Dev loss: 0.4046 r:0.7558
ru_en Dev loss: 0.4343 r:0.7332
Current avg r:0.7169 Best avg r: 0.7375
16:56:50,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:55,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:01,97 root INFO Epoch 4 Global steps: 36500 Train loss: 0.2788
ro_en Dev loss: 0.3425 r:0.8158
et_en Dev loss: 0.4592 r:0.6799
si_en Dev loss: 0.6982 r:0.5933
ne_en Dev loss: 0.4080 r:0.7511
ru_en Dev loss: 0.4275 r:0.7349
Current avg r:0.7150 Best avg r: 0.7375
17:02:15,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:21,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:26,135 root INFO Epoch 4 Global steps: 37000 Train loss: 0.2845
ro_en Dev loss: 0.3482 r:0.8146
et_en Dev loss: 0.4310 r:0.6765
si_en Dev loss: 0.6877 r:0.5898
ne_en Dev loss: 0.4357 r:0.7475
ru_en Dev loss: 0.4325 r:0.7317
Current avg r:0.7120 Best avg r: 0.7375
17:07:38,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:43,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:48,387 root INFO Epoch 4 Global steps: 37500 Train loss: 0.2788
ro_en Dev loss: 0.3553 r:0.8144
et_en Dev loss: 0.4274 r:0.6755
si_en Dev loss: 0.7533 r:0.5914
ne_en Dev loss: 0.5258 r:0.7479
ru_en Dev loss: 0.4472 r:0.7255
Current avg r:0.7109 Best avg r: 0.7375
17:13:01,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:06,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:11,326 root INFO Epoch 5 Global steps: 38000 Train loss: 0.2508
ro_en Dev loss: 0.4038 r:0.8130
et_en Dev loss: 0.4728 r:0.6660
si_en Dev loss: 0.8507 r:0.5835
ne_en Dev loss: 0.5332 r:0.7396
ru_en Dev loss: 0.5055 r:0.7142
Current avg r:0.7032 Best avg r: 0.7375
17:18:23,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:28,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:33,12 root INFO Epoch 5 Global steps: 38500 Train loss: 0.2540
ro_en Dev loss: 0.3866 r:0.8087
et_en Dev loss: 0.4531 r:0.6708
si_en Dev loss: 0.7625 r:0.5844
ne_en Dev loss: 0.4495 r:0.7465
ru_en Dev loss: 0.4671 r:0.7222
Current avg r:0.7065 Best avg r: 0.7375
17:23:45,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:49,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:54,882 root INFO Epoch 5 Global steps: 39000 Train loss: 0.2399
ro_en Dev loss: 0.3621 r:0.8115
et_en Dev loss: 0.4427 r:0.6642
si_en Dev loss: 0.8214 r:0.5787
ne_en Dev loss: 0.5362 r:0.7396
ru_en Dev loss: 0.5176 r:0.6993
Current avg r:0.6987 Best avg r: 0.7375
17:29:07,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:12,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:16,940 root INFO Epoch 5 Global steps: 39500 Train loss: 0.2607
ro_en Dev loss: 0.3234 r:0.8169
et_en Dev loss: 0.4291 r:0.6732
si_en Dev loss: 0.7407 r:0.5895
ne_en Dev loss: 0.4455 r:0.7486
ru_en Dev loss: 0.4373 r:0.7299
Current avg r:0.7116 Best avg r: 0.7375
17:34:29,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:34,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:38,927 root INFO Epoch 5 Global steps: 40000 Train loss: 0.2554
ro_en Dev loss: 0.3791 r:0.8105
et_en Dev loss: 0.4764 r:0.6713
si_en Dev loss: 0.7946 r:0.5832
ne_en Dev loss: 0.5045 r:0.7487
ru_en Dev loss: 0.4545 r:0.7335
Current avg r:0.7094 Best avg r: 0.7375
17:39:51,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:56,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:01,65 root INFO Epoch 5 Global steps: 40500 Train loss: 0.2432
ro_en Dev loss: 0.3577 r:0.8112
et_en Dev loss: 0.4485 r:0.6655
si_en Dev loss: 0.7856 r:0.5823
ne_en Dev loss: 0.5288 r:0.7468
ru_en Dev loss: 0.4955 r:0.7154
Current avg r:0.7042 Best avg r: 0.7375
17:45:13,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:18,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:22,927 root INFO Epoch 5 Global steps: 41000 Train loss: 0.2567
ro_en Dev loss: 0.3765 r:0.8115
et_en Dev loss: 0.4425 r:0.6706
si_en Dev loss: 0.9175 r:0.5742
ne_en Dev loss: 0.5239 r:0.7519
ru_en Dev loss: 0.4853 r:0.7233
Current avg r:0.7063 Best avg r: 0.7375
17:50:34,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:39,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:44,651 root INFO Epoch 5 Global steps: 41500 Train loss: 0.2535
ro_en Dev loss: 0.3652 r:0.8106
et_en Dev loss: 0.4562 r:0.6652
si_en Dev loss: 0.8116 r:0.5813
ne_en Dev loss: 0.4768 r:0.7451
ru_en Dev loss: 0.4913 r:0.7142
Current avg r:0.7033 Best avg r: 0.7375
17:55:56,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:01,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:06,313 root INFO Epoch 5 Global steps: 42000 Train loss: 0.2431
ro_en Dev loss: 0.3517 r:0.8120
et_en Dev loss: 0.4273 r:0.6710
si_en Dev loss: 0.8480 r:0.5796
ne_en Dev loss: 0.5878 r:0.7496
ru_en Dev loss: 0.4526 r:0.7265
Current avg r:0.7077 Best avg r: 0.7375
18:01:18,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:23,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:28,41 root INFO Epoch 5 Global steps: 42500 Train loss: 0.2427
ro_en Dev loss: 0.3239 r:0.8122
et_en Dev loss: 0.4389 r:0.6802
si_en Dev loss: 0.7197 r:0.5891
ne_en Dev loss: 0.4080 r:0.7562
ru_en Dev loss: 0.3881 r:0.7482
Current avg r:0.7172 Best avg r: 0.7375
18:06:39,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:44,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:49,617 root INFO Epoch 5 Global steps: 43000 Train loss: 0.2406
ro_en Dev loss: 0.3839 r:0.8084
et_en Dev loss: 0.4592 r:0.6641
si_en Dev loss: 0.8747 r:0.5733
ne_en Dev loss: 0.5155 r:0.7426
ru_en Dev loss: 0.4817 r:0.7143
Current avg r:0.7005 Best avg r: 0.7375
18:12:01,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:06,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:11,247 root INFO Epoch 5 Global steps: 43500 Train loss: 0.2494
ro_en Dev loss: 0.3677 r:0.8155
et_en Dev loss: 0.4393 r:0.6705
si_en Dev loss: 0.8156 r:0.5841
ne_en Dev loss: 0.4800 r:0.7510
ru_en Dev loss: 0.4829 r:0.7189
Current avg r:0.7080 Best avg r: 0.7375
18:17:23,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:28,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:32,857 root INFO Epoch 5 Global steps: 44000 Train loss: 0.2423
ro_en Dev loss: 0.3677 r:0.8126
et_en Dev loss: 0.4465 r:0.6734
si_en Dev loss: 0.7960 r:0.5825
ne_en Dev loss: 0.4907 r:0.7509
ru_en Dev loss: 0.5034 r:0.7100
Current avg r:0.7059 Best avg r: 0.7375
18:22:44,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:49,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:54,440 root INFO Epoch 5 Global steps: 44500 Train loss: 0.2357
ro_en Dev loss: 0.3666 r:0.8110
et_en Dev loss: 0.4562 r:0.6724
si_en Dev loss: 0.7535 r:0.5824
ne_en Dev loss: 0.4966 r:0.7393
ru_en Dev loss: 0.4821 r:0.7124
Current avg r:0.7035 Best avg r: 0.7375
18:28:06,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:11,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:16,64 root INFO Epoch 5 Global steps: 45000 Train loss: 0.2333
ro_en Dev loss: 0.3646 r:0.8080
et_en Dev loss: 0.4492 r:0.6728
si_en Dev loss: 0.7472 r:0.5876
ne_en Dev loss: 0.4865 r:0.7422
ru_en Dev loss: 0.4581 r:0.7222
Current avg r:0.7066 Best avg r: 0.7375
18:33:29,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:34,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:39,106 root INFO Epoch 6 Global steps: 45500 Train loss: 0.2265
ro_en Dev loss: 0.3808 r:0.8104
et_en Dev loss: 0.4695 r:0.6639
si_en Dev loss: 0.7975 r:0.5794
ne_en Dev loss: 0.5146 r:0.7442
ru_en Dev loss: 0.4903 r:0.7153
Current avg r:0.7026 Best avg r: 0.7375
18:38:51,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:55,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:00,776 root INFO Epoch 6 Global steps: 46000 Train loss: 0.2140
ro_en Dev loss: 0.3530 r:0.8131
et_en Dev loss: 0.4565 r:0.6719
si_en Dev loss: 0.7298 r:0.5884
ne_en Dev loss: 0.4858 r:0.7411
ru_en Dev loss: 0.4597 r:0.7296
Current avg r:0.7088 Best avg r: 0.7375
18:44:12,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:17,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:22,440 root INFO Epoch 6 Global steps: 46500 Train loss: 0.2110
ro_en Dev loss: 0.3809 r:0.8080
et_en Dev loss: 0.4569 r:0.6689
si_en Dev loss: 0.7999 r:0.5816
ne_en Dev loss: 0.4906 r:0.7435
ru_en Dev loss: 0.4810 r:0.7273
Current avg r:0.7059 Best avg r: 0.7375
18:49:34,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:39,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:44,621 root INFO Epoch 6 Global steps: 47000 Train loss: 0.2104
ro_en Dev loss: 0.4141 r:0.8091
et_en Dev loss: 0.4762 r:0.6682
si_en Dev loss: 0.9398 r:0.5777
ne_en Dev loss: 0.5804 r:0.7442
ru_en Dev loss: 0.5101 r:0.7285
Current avg r:0.7056 Best avg r: 0.7375
18:54:57,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:01,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:06,770 root INFO Epoch 6 Global steps: 47500 Train loss: 0.2142
ro_en Dev loss: 0.3552 r:0.8127
et_en Dev loss: 0.4447 r:0.6748
si_en Dev loss: 0.7541 r:0.5797
ne_en Dev loss: 0.4545 r:0.7393
ru_en Dev loss: 0.4706 r:0.7236
Current avg r:0.7060 Best avg r: 0.7375
19:00:19,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:23,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:28,769 root INFO Epoch 6 Global steps: 48000 Train loss: 0.2113
ro_en Dev loss: 0.3969 r:0.8087
et_en Dev loss: 0.5059 r:0.6671
si_en Dev loss: 0.8609 r:0.5740
ne_en Dev loss: 0.5639 r:0.7390
ru_en Dev loss: 0.4939 r:0.7248
Current avg r:0.7027 Best avg r: 0.7375
19:05:40,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:45,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:50,219 root INFO Epoch 6 Global steps: 48500 Train loss: 0.2100
ro_en Dev loss: 0.3897 r:0.8081
et_en Dev loss: 0.4780 r:0.6574
si_en Dev loss: 0.9161 r:0.5559
ne_en Dev loss: 0.6049 r:0.7348
ru_en Dev loss: 0.5128 r:0.7136
Current avg r:0.6940 Best avg r: 0.7375
19:11:01,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:06,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:11,90 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2075
ro_en Dev loss: 0.4089 r:0.8090
et_en Dev loss: 0.4914 r:0.6482
si_en Dev loss: 0.9396 r:0.5600
ne_en Dev loss: 0.6019 r:0.7373
ru_en Dev loss: 0.5800 r:0.6976
Current avg r:0.6904 Best avg r: 0.7375
19:16:22,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:27,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:32,41 root INFO Epoch 6 Global steps: 49500 Train loss: 0.2084
ro_en Dev loss: 0.3566 r:0.8088
et_en Dev loss: 0.4841 r:0.6529
si_en Dev loss: 0.8394 r:0.5582
ne_en Dev loss: 0.4688 r:0.7399
ru_en Dev loss: 0.4940 r:0.7102
Current avg r:0.6940 Best avg r: 0.7375
19:21:43,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:48,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:53,39 root INFO Epoch 6 Global steps: 50000 Train loss: 0.2012
ro_en Dev loss: 0.3911 r:0.8086
et_en Dev loss: 0.4837 r:0.6573
si_en Dev loss: 0.8562 r:0.5569
ne_en Dev loss: 0.5088 r:0.7355
ru_en Dev loss: 0.5229 r:0.7201
Current avg r:0.6957 Best avg r: 0.7375
19:27:04,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:09,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:14,10 root INFO Epoch 6 Global steps: 50500 Train loss: 0.2210
ro_en Dev loss: 0.4217 r:0.8090
et_en Dev loss: 0.4692 r:0.6673
si_en Dev loss: 0.8981 r:0.5654
ne_en Dev loss: 0.5365 r:0.7424
ru_en Dev loss: 0.5618 r:0.7084
Current avg r:0.6985 Best avg r: 0.7375
19:32:25,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:30,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:35,138 root INFO Epoch 6 Global steps: 51000 Train loss: 0.1996
ro_en Dev loss: 0.3752 r:0.8104
et_en Dev loss: 0.4871 r:0.6711
si_en Dev loss: 0.8734 r:0.5667
ne_en Dev loss: 0.4967 r:0.7409
ru_en Dev loss: 0.4659 r:0.7289
Current avg r:0.7036 Best avg r: 0.7375
19:37:54,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:58,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:03,887 root INFO Epoch 6 Global steps: 51500 Train loss: 0.2095
ro_en Dev loss: 0.3890 r:0.8123
et_en Dev loss: 0.4863 r:0.6574
si_en Dev loss: 0.8930 r:0.5664
ne_en Dev loss: 0.5521 r:0.7389
ru_en Dev loss: 0.5258 r:0.7097
Current avg r:0.6969 Best avg r: 0.7375
19:43:15,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:20,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:25,783 root INFO Epoch 6 Global steps: 52000 Train loss: 0.2105
ro_en Dev loss: 0.4191 r:0.8081
et_en Dev loss: 0.4856 r:0.6428
si_en Dev loss: 1.0292 r:0.5464
ne_en Dev loss: 0.6551 r:0.7359
ru_en Dev loss: 0.5951 r:0.6843
Current avg r:0.6835 Best avg r: 0.7375
19:48:37,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:42,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:46,968 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2108
ro_en Dev loss: 0.3892 r:0.8087
et_en Dev loss: 0.4902 r:0.6463
si_en Dev loss: 0.8979 r:0.5561
ne_en Dev loss: 0.5378 r:0.7402
ru_en Dev loss: 0.5173 r:0.7057
Current avg r:0.6914 Best avg r: 0.7375
19:53:59,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:04,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:09,910 root INFO Epoch 7 Global steps: 53000 Train loss: 0.1922
ro_en Dev loss: 0.3848 r:0.8079
et_en Dev loss: 0.4637 r:0.6609
si_en Dev loss: 0.8830 r:0.5558
ne_en Dev loss: 0.5571 r:0.7404
ru_en Dev loss: 0.4741 r:0.7211
Current avg r:0.6972 Best avg r: 0.7375
19:59:22,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:26,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:01:31,512 root INFO Epoch 7 Global steps: 53500 Train loss: 0.1947
ro_en Dev loss: 0.3885 r:0.8072
et_en Dev loss: 0.4645 r:0.6612
si_en Dev loss: 0.8646 r:0.5572
ne_en Dev loss: 0.4993 r:0.7397
ru_en Dev loss: 0.4651 r:0.7356
Current avg r:0.7002 Best avg r: 0.7375
20:04:42,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:47,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:52,627 root INFO Epoch 7 Global steps: 54000 Train loss: 0.1872
ro_en Dev loss: 0.3571 r:0.8101
et_en Dev loss: 0.4583 r:0.6624
si_en Dev loss: 0.8289 r:0.5604
ne_en Dev loss: 0.4876 r:0.7412
ru_en Dev loss: 0.4637 r:0.7208
Current avg r:0.6990 Best avg r: 0.7375
20:10:04,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:09,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:14,313 root INFO Epoch 7 Global steps: 54500 Train loss: 0.1851
ro_en Dev loss: 0.3708 r:0.8118
et_en Dev loss: 0.4859 r:0.6635
si_en Dev loss: 0.8531 r:0.5610
ne_en Dev loss: 0.4947 r:0.7371
ru_en Dev loss: 0.4883 r:0.7181
Current avg r:0.6983 Best avg r: 0.7375
20:15:25,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:30,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:35,337 root INFO Epoch 7 Global steps: 55000 Train loss: 0.1760
ro_en Dev loss: 0.3861 r:0.8141
et_en Dev loss: 0.5042 r:0.6690
si_en Dev loss: 0.8702 r:0.5688
ne_en Dev loss: 0.4876 r:0.7388
ru_en Dev loss: 0.5031 r:0.7167
Current avg r:0.7015 Best avg r: 0.7375
20:20:46,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:51,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:56,35 root INFO Epoch 7 Global steps: 55500 Train loss: 0.1792
ro_en Dev loss: 0.3422 r:0.8157
et_en Dev loss: 0.4700 r:0.6646
si_en Dev loss: 0.8331 r:0.5657
ne_en Dev loss: 0.4713 r:0.7432
ru_en Dev loss: 0.4331 r:0.7386
Current avg r:0.7056 Best avg r: 0.7375
20:26:07,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:12,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:28:17,361 root INFO Epoch 7 Global steps: 56000 Train loss: 0.1879
ro_en Dev loss: 0.3624 r:0.8148
et_en Dev loss: 0.4800 r:0.6585
si_en Dev loss: 0.9343 r:0.5523
ne_en Dev loss: 0.5420 r:0.7392
ru_en Dev loss: 0.5207 r:0.7113
Current avg r:0.6952 Best avg r: 0.7375
20:31:28,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:33,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:38,288 root INFO Epoch 7 Global steps: 56500 Train loss: 0.1646
ro_en Dev loss: 0.3838 r:0.8124
et_en Dev loss: 0.5016 r:0.6544
si_en Dev loss: 0.9233 r:0.5501
ne_en Dev loss: 0.5506 r:0.7390
ru_en Dev loss: 0.5219 r:0.7083
Current avg r:0.6928 Best avg r: 0.7375
20:36:49,655 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:54,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:59,135 root INFO Epoch 7 Global steps: 57000 Train loss: 0.1788
ro_en Dev loss: 0.3772 r:0.8142
et_en Dev loss: 0.4870 r:0.6493
si_en Dev loss: 0.8751 r:0.5615
ne_en Dev loss: 0.5437 r:0.7376
ru_en Dev loss: 0.4699 r:0.7186
Current avg r:0.6962 Best avg r: 0.7375
20:42:10,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:15,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:19,951 root INFO Epoch 7 Global steps: 57500 Train loss: 0.1855
ro_en Dev loss: 0.3591 r:0.8137
et_en Dev loss: 0.5056 r:0.6617
si_en Dev loss: 0.8677 r:0.5565
ne_en Dev loss: 0.5288 r:0.7352
ru_en Dev loss: 0.4609 r:0.7250
Current avg r:0.6984 Best avg r: 0.7375
20:47:31,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:36,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:40,732 root INFO Epoch 7 Global steps: 58000 Train loss: 0.1843
ro_en Dev loss: 0.3599 r:0.8130
et_en Dev loss: 0.4930 r:0.6601
si_en Dev loss: 0.8940 r:0.5610
ne_en Dev loss: 0.5116 r:0.7397
ru_en Dev loss: 0.4473 r:0.7266
Current avg r:0.7001 Best avg r: 0.7375
20:52:52,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:57,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:02,53 root INFO Epoch 7 Global steps: 58500 Train loss: 0.1712
ro_en Dev loss: 0.3731 r:0.8117
et_en Dev loss: 0.5182 r:0.6640
si_en Dev loss: 0.8187 r:0.5656
ne_en Dev loss: 0.4675 r:0.7411
ru_en Dev loss: 0.4595 r:0.7272
Current avg r:0.7019 Best avg r: 0.7375
20:58:14,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:19,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:24,173 root INFO Epoch 7 Global steps: 59000 Train loss: 0.1815
ro_en Dev loss: 0.3675 r:0.8102
et_en Dev loss: 0.4769 r:0.6639
si_en Dev loss: 0.8023 r:0.5631
ne_en Dev loss: 0.5094 r:0.7325
ru_en Dev loss: 0.4708 r:0.7231
Current avg r:0.6986 Best avg r: 0.7375
21:03:36,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:40,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:46,16 root INFO Epoch 7 Global steps: 59500 Train loss: 0.1758
ro_en Dev loss: 0.3745 r:0.8142
et_en Dev loss: 0.4972 r:0.6598
si_en Dev loss: 0.8355 r:0.5603
ne_en Dev loss: 0.5081 r:0.7350
ru_en Dev loss: 0.5236 r:0.7099
Current avg r:0.6958 Best avg r: 0.7375
21:08:57,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:01,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:05,703 root INFO Epoch 7 Global steps: 60000 Train loss: 0.1710
ro_en Dev loss: 0.3712 r:0.8168
et_en Dev loss: 0.4904 r:0.6584
si_en Dev loss: 0.8692 r:0.5611
ne_en Dev loss: 0.4766 r:0.7316
ru_en Dev loss: 0.5080 r:0.7185
Current avg r:0.6973 Best avg r: 0.7375
21:14:17,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:22,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:27,484 root INFO Epoch 8 Global steps: 60500 Train loss: 0.1572
ro_en Dev loss: 0.4071 r:0.8164
et_en Dev loss: 0.4898 r:0.6510
si_en Dev loss: 0.9426 r:0.5506
ne_en Dev loss: 0.6394 r:0.7279
ru_en Dev loss: 0.5606 r:0.6988
Current avg r:0.6889 Best avg r: 0.7375
21:19:39,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:44,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:49,803 root INFO Epoch 8 Global steps: 61000 Train loss: 0.1642
ro_en Dev loss: 0.3833 r:0.8134
et_en Dev loss: 0.4653 r:0.6659
si_en Dev loss: 0.8527 r:0.5581
ne_en Dev loss: 0.5186 r:0.7274
ru_en Dev loss: 0.4906 r:0.7308
Current avg r:0.6991 Best avg r: 0.7375
21:25:02,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:26:07,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:12,285 root INFO Epoch 8 Global steps: 61500 Train loss: 0.1496
ro_en Dev loss: 0.3725 r:0.8140
et_en Dev loss: 0.5059 r:0.6635
si_en Dev loss: 0.8975 r:0.5530
ne_en Dev loss: 0.5186 r:0.7278
ru_en Dev loss: 0.4757 r:0.7301
Current avg r:0.6977 Best avg r: 0.7375
21:30:24,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:29,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:34,242 root INFO Epoch 8 Global steps: 62000 Train loss: 0.1602
ro_en Dev loss: 0.3455 r:0.8171
et_en Dev loss: 0.4697 r:0.6605
si_en Dev loss: 0.8739 r:0.5533
ne_en Dev loss: 0.4883 r:0.7327
ru_en Dev loss: 0.4639 r:0.7205
Current avg r:0.6968 Best avg r: 0.7375
21:35:46,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:51,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:55,755 root INFO Epoch 8 Global steps: 62500 Train loss: 0.1584
ro_en Dev loss: 0.3708 r:0.8115
et_en Dev loss: 0.4878 r:0.6535
si_en Dev loss: 0.9125 r:0.5476
ne_en Dev loss: 0.5708 r:0.7295
ru_en Dev loss: 0.5096 r:0.6987
Current avg r:0.6882 Best avg r: 0.7375
21:41:07,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:12,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:17,621 root INFO Epoch 8 Global steps: 63000 Train loss: 0.1587
ro_en Dev loss: 0.3928 r:0.8121
et_en Dev loss: 0.4824 r:0.6557
si_en Dev loss: 0.9476 r:0.5450
ne_en Dev loss: 0.6076 r:0.7334
ru_en Dev loss: 0.5203 r:0.7061
Current avg r:0.6905 Best avg r: 0.7375
21:46:29,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:34,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:39,511 root INFO Epoch 8 Global steps: 63500 Train loss: 0.1471
ro_en Dev loss: 0.3768 r:0.8131
et_en Dev loss: 0.4744 r:0.6586
si_en Dev loss: 0.9080 r:0.5493
ne_en Dev loss: 0.5639 r:0.7311
ru_en Dev loss: 0.5117 r:0.7108
Current avg r:0.6926 Best avg r: 0.7375
21:51:51,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:56,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:01,484 root INFO Epoch 8 Global steps: 64000 Train loss: 0.1568
ro_en Dev loss: 0.4416 r:0.8120
et_en Dev loss: 0.5149 r:0.6571
si_en Dev loss: 0.9703 r:0.5504
ne_en Dev loss: 0.6309 r:0.7298
ru_en Dev loss: 0.5451 r:0.7206
Current avg r:0.6940 Best avg r: 0.7375
21:57:13,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:18,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:23,488 root INFO Epoch 8 Global steps: 64500 Train loss: 0.1642
ro_en Dev loss: 0.3679 r:0.8132
et_en Dev loss: 0.4816 r:0.6593
si_en Dev loss: 0.9002 r:0.5443
ne_en Dev loss: 0.6168 r:0.7354
ru_en Dev loss: 0.4606 r:0.7166
Current avg r:0.6937 Best avg r: 0.7375
22:02:35,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:40,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:45,377 root INFO Epoch 8 Global steps: 65000 Train loss: 0.1650
ro_en Dev loss: 0.3817 r:0.8158
et_en Dev loss: 0.4919 r:0.6566
si_en Dev loss: 0.9214 r:0.5441
ne_en Dev loss: 0.5742 r:0.7337
ru_en Dev loss: 0.4910 r:0.7210
Current avg r:0.6942 Best avg r: 0.7375
22:07:57,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:02,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:06,974 root INFO Epoch 8 Global steps: 65500 Train loss: 0.1494
ro_en Dev loss: 0.3973 r:0.8162
et_en Dev loss: 0.4990 r:0.6549
si_en Dev loss: 0.9333 r:0.5476
ne_en Dev loss: 0.5990 r:0.7317
ru_en Dev loss: 0.5293 r:0.7067
Current avg r:0.6914 Best avg r: 0.7375
22:13:19,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:23,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:28,861 root INFO Epoch 8 Global steps: 66000 Train loss: 0.1592
ro_en Dev loss: 0.3672 r:0.8102
et_en Dev loss: 0.5032 r:0.6519
si_en Dev loss: 0.8920 r:0.5431
ne_en Dev loss: 0.5889 r:0.7290
ru_en Dev loss: 0.4711 r:0.7174
Current avg r:0.6903 Best avg r: 0.7375
22:18:40,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:45,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:50,504 root INFO Epoch 8 Global steps: 66500 Train loss: 0.1510
ro_en Dev loss: 0.4006 r:0.8109
et_en Dev loss: 0.4824 r:0.6541
si_en Dev loss: 0.9777 r:0.5435
ne_en Dev loss: 0.6317 r:0.7291
ru_en Dev loss: 0.4946 r:0.7230
Current avg r:0.6921 Best avg r: 0.7375
22:24:02,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:07,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:12,343 root INFO Epoch 8 Global steps: 67000 Train loss: 0.1532
ro_en Dev loss: 0.3816 r:0.8122
et_en Dev loss: 0.4605 r:0.6576
si_en Dev loss: 0.9263 r:0.5474
ne_en Dev loss: 0.6679 r:0.7237
ru_en Dev loss: 0.5092 r:0.7133
Current avg r:0.6908 Best avg r: 0.7375
22:29:24,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:29,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:34,393 root INFO Epoch 8 Global steps: 67500 Train loss: 0.1561
ro_en Dev loss: 0.3607 r:0.8083
et_en Dev loss: 0.4653 r:0.6453
si_en Dev loss: 0.9963 r:0.5353
ne_en Dev loss: 0.6331 r:0.7240
ru_en Dev loss: 0.4820 r:0.7115
Current avg r:0.6849 Best avg r: 0.7375
22:34:47,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:52,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:57,304 root INFO Epoch 9 Global steps: 68000 Train loss: 0.1375
ro_en Dev loss: 0.4047 r:0.8093
et_en Dev loss: 0.4841 r:0.6556
si_en Dev loss: 0.9214 r:0.5487
ne_en Dev loss: 0.6229 r:0.7319
ru_en Dev loss: 0.5363 r:0.7097
Current avg r:0.6910 Best avg r: 0.7375
22:40:09,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:14,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:19,5 root INFO Epoch 9 Global steps: 68500 Train loss: 0.1424
ro_en Dev loss: 0.3689 r:0.8115
et_en Dev loss: 0.4731 r:0.6601
si_en Dev loss: 0.8617 r:0.5486
ne_en Dev loss: 0.5494 r:0.7263
ru_en Dev loss: 0.4559 r:0.7318
Current avg r:0.6957 Best avg r: 0.7375
22:45:30,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:35,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:40,247 root INFO Epoch 9 Global steps: 69000 Train loss: 0.1368
ro_en Dev loss: 0.3914 r:0.8086
et_en Dev loss: 0.4931 r:0.6474
si_en Dev loss: 0.9733 r:0.5383
ne_en Dev loss: 0.6115 r:0.7209
ru_en Dev loss: 0.5367 r:0.6973
Current avg r:0.6825 Best avg r: 0.7375
22:50:52,219 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:57,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:01,952 root INFO Epoch 9 Global steps: 69500 Train loss: 0.1403
ro_en Dev loss: 0.3830 r:0.8098
et_en Dev loss: 0.4847 r:0.6580
si_en Dev loss: 0.9006 r:0.5459
ne_en Dev loss: 0.5907 r:0.7218
ru_en Dev loss: 0.4729 r:0.7264
Current avg r:0.6924 Best avg r: 0.7375
22:56:14,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:19,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:23,727 root INFO Epoch 9 Global steps: 70000 Train loss: 0.1407
ro_en Dev loss: 0.3883 r:0.8088
et_en Dev loss: 0.4913 r:0.6601
si_en Dev loss: 0.9045 r:0.5482
ne_en Dev loss: 0.5397 r:0.7266
ru_en Dev loss: 0.4632 r:0.7273
Current avg r:0.6942 Best avg r: 0.7375
23:01:35,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:40,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:45,927 root INFO Epoch 9 Global steps: 70500 Train loss: 0.1388
ro_en Dev loss: 0.4036 r:0.8054
et_en Dev loss: 0.4990 r:0.6526
si_en Dev loss: 0.9041 r:0.5447
ne_en Dev loss: 0.5845 r:0.7177
ru_en Dev loss: 0.4788 r:0.7242
Current avg r:0.6889 Best avg r: 0.7375
23:06:58,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:02,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:09:07,857 root INFO Epoch 9 Global steps: 71000 Train loss: 0.1445
ro_en Dev loss: 0.4112 r:0.8036
et_en Dev loss: 0.5086 r:0.6448
si_en Dev loss: 0.9325 r:0.5391
ne_en Dev loss: 0.5570 r:0.7237
ru_en Dev loss: 0.5124 r:0.7114
Current avg r:0.6845 Best avg r: 0.7375
23:12:20,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:24,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:29,757 root INFO Epoch 9 Global steps: 71500 Train loss: 0.1341
ro_en Dev loss: 0.3958 r:0.8064
et_en Dev loss: 0.5097 r:0.6595
si_en Dev loss: 0.9185 r:0.5388
ne_en Dev loss: 0.5290 r:0.7215
ru_en Dev loss: 0.4674 r:0.7327
Current avg r:0.6918 Best avg r: 0.7375
23:17:41,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:46,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:51,293 root INFO Epoch 9 Global steps: 72000 Train loss: 0.1353
ro_en Dev loss: 0.3822 r:0.8116
et_en Dev loss: 0.4887 r:0.6609
si_en Dev loss: 0.8899 r:0.5532
ne_en Dev loss: 0.5783 r:0.7270
ru_en Dev loss: 0.4814 r:0.7300
Current avg r:0.6965 Best avg r: 0.7375
23:23:03,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:08,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:13,122 root INFO Epoch 9 Global steps: 72500 Train loss: 0.1398
ro_en Dev loss: 0.3713 r:0.8101
et_en Dev loss: 0.4754 r:0.6510
si_en Dev loss: 0.8430 r:0.5466
ne_en Dev loss: 0.5477 r:0.7239
ru_en Dev loss: 0.4852 r:0.7161
Current avg r:0.6895 Best avg r: 0.7375
23:28:25,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:29,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:34,654 root INFO Epoch 9 Global steps: 73000 Train loss: 0.1367
ro_en Dev loss: 0.3880 r:0.8081
et_en Dev loss: 0.4974 r:0.6492
si_en Dev loss: 0.9220 r:0.5436
ne_en Dev loss: 0.6345 r:0.7251
ru_en Dev loss: 0.5270 r:0.7045
Current avg r:0.6861 Best avg r: 0.7375
23:33:46,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:34:51,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:56,727 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1297
ro_en Dev loss: 0.3781 r:0.8084
et_en Dev loss: 0.5176 r:0.6555
si_en Dev loss: 0.8583 r:0.5485
ne_en Dev loss: 0.5320 r:0.7222
ru_en Dev loss: 0.5109 r:0.7083
Current avg r:0.6886 Best avg r: 0.7375
23:39:09,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:15,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:20,696 root INFO Epoch 9 Global steps: 74000 Train loss: 0.1338
ro_en Dev loss: 0.3841 r:0.8097
et_en Dev loss: 0.5022 r:0.6616
si_en Dev loss: 0.8946 r:0.5455
ne_en Dev loss: 0.5898 r:0.7184
ru_en Dev loss: 0.4795 r:0.7340
Current avg r:0.6939 Best avg r: 0.7375
23:44:44,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:49,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:55,117 root INFO Epoch 9 Global steps: 74500 Train loss: 0.1336
ro_en Dev loss: 0.3370 r:0.8160
et_en Dev loss: 0.4639 r:0.6671
si_en Dev loss: 0.8206 r:0.5541
ne_en Dev loss: 0.4767 r:0.7265
ru_en Dev loss: 0.4382 r:0.7410
Current avg r:0.7009 Best avg r: 0.7375
23:50:13,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:18,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:23,632 root INFO Epoch 9 Global steps: 75000 Train loss: 0.1250
ro_en Dev loss: 0.3484 r:0.8135
et_en Dev loss: 0.4642 r:0.6660
si_en Dev loss: 0.8126 r:0.5519
ne_en Dev loss: 0.5123 r:0.7288
ru_en Dev loss: 0.4551 r:0.7279
Current avg r:0.6976 Best avg r: 0.7375
23:55:44,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:49,880 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:55,171 root INFO Epoch 10 Global steps: 75500 Train loss: 0.1250
ro_en Dev loss: 0.3640 r:0.8156
et_en Dev loss: 0.4773 r:0.6576
si_en Dev loss: 0.9784 r:0.5432
ne_en Dev loss: 0.6614 r:0.7225
ru_en Dev loss: 0.4749 r:0.7287
Current avg r:0.6935 Best avg r: 0.7375
00:01:16,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:21,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:26,401 root INFO Epoch 10 Global steps: 76000 Train loss: 0.1198
ro_en Dev loss: 0.3809 r:0.8138
et_en Dev loss: 0.4939 r:0.6647
si_en Dev loss: 0.8582 r:0.5554
ne_en Dev loss: 0.5441 r:0.7287
ru_en Dev loss: 0.4724 r:0.7406
Current avg r:0.7007 Best avg r: 0.7375
00:06:47,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:52,458 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:57,514 root INFO Epoch 10 Global steps: 76500 Train loss: 0.1204
ro_en Dev loss: 0.3744 r:0.8098
et_en Dev loss: 0.4865 r:0.6495
si_en Dev loss: 0.9209 r:0.5393
ne_en Dev loss: 0.6025 r:0.7182
ru_en Dev loss: 0.4714 r:0.7292
Current avg r:0.6892 Best avg r: 0.7375
00:12:18,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:23,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:29,332 root INFO Epoch 10 Global steps: 77000 Train loss: 0.1206
ro_en Dev loss: 0.3742 r:0.8115
et_en Dev loss: 0.4903 r:0.6452
si_en Dev loss: 0.9136 r:0.5433
ne_en Dev loss: 0.5473 r:0.7175
ru_en Dev loss: 0.4828 r:0.7249
Current avg r:0.6885 Best avg r: 0.7375
00:17:41,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:46,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:51,254 root INFO Epoch 10 Global steps: 77500 Train loss: 0.1164
ro_en Dev loss: 0.3830 r:0.8113
et_en Dev loss: 0.4973 r:0.6546
si_en Dev loss: 0.9398 r:0.5358
ne_en Dev loss: 0.5694 r:0.7143
ru_en Dev loss: 0.4599 r:0.7382
Current avg r:0.6908 Best avg r: 0.7375
00:23:03,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:08,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:13,207 root INFO Epoch 10 Global steps: 78000 Train loss: 0.1241
ro_en Dev loss: 0.3714 r:0.8135
et_en Dev loss: 0.4862 r:0.6570
si_en Dev loss: 0.8953 r:0.5504
ne_en Dev loss: 0.5744 r:0.7139
ru_en Dev loss: 0.4679 r:0.7320
Current avg r:0.6934 Best avg r: 0.7375
00:28:25,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:30,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:34,859 root INFO Epoch 10 Global steps: 78500 Train loss: 0.1250
ro_en Dev loss: 0.4036 r:0.8111
et_en Dev loss: 0.4952 r:0.6584
si_en Dev loss: 0.9331 r:0.5458
ne_en Dev loss: 0.5596 r:0.7152
ru_en Dev loss: 0.5106 r:0.7261
Current avg r:0.6913 Best avg r: 0.7375
00:33:46,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:51,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:57,49 root INFO Epoch 10 Global steps: 79000 Train loss: 0.1194
ro_en Dev loss: 0.3948 r:0.8109
et_en Dev loss: 0.4817 r:0.6493
si_en Dev loss: 0.9542 r:0.5406
ne_en Dev loss: 0.6683 r:0.7136
ru_en Dev loss: 0.5096 r:0.7202
Current avg r:0.6869 Best avg r: 0.7375
00:39:09,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:14,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:19,172 root INFO Epoch 10 Global steps: 79500 Train loss: 0.1232
ro_en Dev loss: 0.3492 r:0.8128
et_en Dev loss: 0.4975 r:0.6634
si_en Dev loss: 0.7723 r:0.5530
ne_en Dev loss: 0.5157 r:0.7229
ru_en Dev loss: 0.4183 r:0.7445
Current avg r:0.6993 Best avg r: 0.7375
00:44:31,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:36,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:40,809 root INFO Epoch 10 Global steps: 80000 Train loss: 0.1144
ro_en Dev loss: 0.4042 r:0.8105
et_en Dev loss: 0.5004 r:0.6494
si_en Dev loss: 0.9534 r:0.5418
ne_en Dev loss: 0.6723 r:0.7163
ru_en Dev loss: 0.5258 r:0.7173
Current avg r:0.6870 Best avg r: 0.7375
00:49:52,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:57,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:03,79 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1240
ro_en Dev loss: 0.3804 r:0.8118
et_en Dev loss: 0.4797 r:0.6493
si_en Dev loss: 0.9252 r:0.5405
ne_en Dev loss: 0.5870 r:0.7218
ru_en Dev loss: 0.5322 r:0.7027
Current avg r:0.6852 Best avg r: 0.7375
00:55:15,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:20,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:25,96 root INFO Epoch 10 Global steps: 81000 Train loss: 0.1182
ro_en Dev loss: 0.3682 r:0.8169
et_en Dev loss: 0.4625 r:0.6644
si_en Dev loss: 0.8931 r:0.5539
ne_en Dev loss: 0.5637 r:0.7305
ru_en Dev loss: 0.4889 r:0.7195
Current avg r:0.6970 Best avg r: 0.7375
01:00:37,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:01:42,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:46,988 root INFO Epoch 10 Global steps: 81500 Train loss: 0.1185
ro_en Dev loss: 0.3831 r:0.8131
et_en Dev loss: 0.4789 r:0.6498
si_en Dev loss: 0.9714 r:0.5416
ne_en Dev loss: 0.6550 r:0.7237
ru_en Dev loss: 0.4894 r:0.7232
Current avg r:0.6903 Best avg r: 0.7375
01:05:59,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:04,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:09,445 root INFO Epoch 10 Global steps: 82000 Train loss: 0.1169
ro_en Dev loss: 0.3747 r:0.8106
et_en Dev loss: 0.4961 r:0.6540
si_en Dev loss: 0.9290 r:0.5412
ne_en Dev loss: 0.6055 r:0.7226
ru_en Dev loss: 0.4681 r:0.7216
Current avg r:0.6900 Best avg r: 0.7375
01:11:21,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:26,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:13:31,994 root INFO Epoch 10 Global steps: 82500 Train loss: 0.1166
ro_en Dev loss: 0.3643 r:0.8139
et_en Dev loss: 0.4861 r:0.6625
si_en Dev loss: 0.8329 r:0.5502
ne_en Dev loss: 0.5209 r:0.7246
ru_en Dev loss: 0.4619 r:0.7359
Current avg r:0.6974 Best avg r: 0.7375
01:16:45,70 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:49,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:54,875 root INFO Epoch 11 Global steps: 83000 Train loss: 0.1125
ro_en Dev loss: 0.3811 r:0.8140
et_en Dev loss: 0.4706 r:0.6625
si_en Dev loss: 0.9689 r:0.5469
ne_en Dev loss: 0.6400 r:0.7188
ru_en Dev loss: 0.4959 r:0.7229
Current avg r:0.6930 Best avg r: 0.7375
01:22:06,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:11,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:16,466 root INFO Epoch 11 Global steps: 83500 Train loss: 0.1057
ro_en Dev loss: 0.3506 r:0.8181
et_en Dev loss: 0.4614 r:0.6669
si_en Dev loss: 0.9030 r:0.5552
ne_en Dev loss: 0.5564 r:0.7264
ru_en Dev loss: 0.4498 r:0.7341
Current avg r:0.7002 Best avg r: 0.7375
01:27:28,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:33,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:29:38,190 root INFO Epoch 11 Global steps: 84000 Train loss: 0.1057
ro_en Dev loss: 0.3620 r:0.8157
et_en Dev loss: 0.4911 r:0.6631
si_en Dev loss: 0.8379 r:0.5534
ne_en Dev loss: 0.5081 r:0.7268
ru_en Dev loss: 0.4781 r:0.7254
Current avg r:0.6969 Best avg r: 0.7375
01:32:50,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:33:55,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:35:00,654 root INFO Epoch 11 Global steps: 84500 Train loss: 0.1059
ro_en Dev loss: 0.3841 r:0.8110
et_en Dev loss: 0.5013 r:0.6597
si_en Dev loss: 0.8816 r:0.5564
ne_en Dev loss: 0.5819 r:0.7237
ru_en Dev loss: 0.4972 r:0.7219
Current avg r:0.6945 Best avg r: 0.7375
01:38:13,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:39:18,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:40:23,345 root INFO Epoch 11 Global steps: 85000 Train loss: 0.1098
ro_en Dev loss: 0.3703 r:0.8143
et_en Dev loss: 0.4678 r:0.6581
si_en Dev loss: 0.8957 r:0.5470
ne_en Dev loss: 0.5814 r:0.7244
ru_en Dev loss: 0.5088 r:0.7094
Current avg r:0.6906 Best avg r: 0.7375
01:43:35,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:40,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:44,893 root INFO Epoch 11 Global steps: 85500 Train loss: 0.1110
ro_en Dev loss: 0.3766 r:0.8132
et_en Dev loss: 0.4728 r:0.6592
si_en Dev loss: 0.9745 r:0.5388
ne_en Dev loss: 0.6370 r:0.7221
ru_en Dev loss: 0.5283 r:0.7130
Current avg r:0.6893 Best avg r: 0.7375
01:48:56,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:01,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:06,880 root INFO Epoch 11 Global steps: 86000 Train loss: 0.1076
ro_en Dev loss: 0.3519 r:0.8140
et_en Dev loss: 0.4840 r:0.6624
si_en Dev loss: 0.8315 r:0.5509
ne_en Dev loss: 0.5436 r:0.7149
ru_en Dev loss: 0.4768 r:0.7338
Current avg r:0.6952 Best avg r: 0.7375
01:54:19,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:55:23,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:56:28,923 root INFO Epoch 11 Global steps: 86500 Train loss: 0.1118
ro_en Dev loss: 0.3865 r:0.8092
et_en Dev loss: 0.5240 r:0.6567
si_en Dev loss: 0.9108 r:0.5415
ne_en Dev loss: 0.5686 r:0.7172
ru_en Dev loss: 0.4975 r:0.7321
Current avg r:0.6913 Best avg r: 0.7375
01:59:41,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:00:46,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:01:51,572 root INFO Epoch 11 Global steps: 87000 Train loss: 0.1077
ro_en Dev loss: 0.3610 r:0.8157
et_en Dev loss: 0.4820 r:0.6604
si_en Dev loss: 0.9334 r:0.5459
ne_en Dev loss: 0.5267 r:0.7196
ru_en Dev loss: 0.4660 r:0.7421
Current avg r:0.6967 Best avg r: 0.7375
02:05:04,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:09,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:14,122 root INFO Epoch 11 Global steps: 87500 Train loss: 0.1078
ro_en Dev loss: 0.3650 r:0.8156
et_en Dev loss: 0.4831 r:0.6586
si_en Dev loss: 0.9678 r:0.5495
ne_en Dev loss: 0.6189 r:0.7208
ru_en Dev loss: 0.4833 r:0.7291
Current avg r:0.6947 Best avg r: 0.7375
02:10:26,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:11:31,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:12:35,990 root INFO Epoch 11 Global steps: 88000 Train loss: 0.1044
ro_en Dev loss: 0.3571 r:0.8138
et_en Dev loss: 0.5037 r:0.6621
si_en Dev loss: 0.8675 r:0.5492
ne_en Dev loss: 0.6076 r:0.7169
ru_en Dev loss: 0.4804 r:0.7245
Current avg r:0.6933 Best avg r: 0.7375
02:15:48,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:53,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:17:58,553 root INFO Epoch 11 Global steps: 88500 Train loss: 0.1044
ro_en Dev loss: 0.3450 r:0.8139
et_en Dev loss: 0.4799 r:0.6598
si_en Dev loss: 0.9118 r:0.5342
ne_en Dev loss: 0.6348 r:0.7165
ru_en Dev loss: 0.4265 r:0.7359
Current avg r:0.6921 Best avg r: 0.7375
02:21:10,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:22:16,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:23:21,119 root INFO Epoch 11 Global steps: 89000 Train loss: 0.1006
ro_en Dev loss: 0.4031 r:0.8136
et_en Dev loss: 0.5122 r:0.6621
si_en Dev loss: 0.9771 r:0.5432
ne_en Dev loss: 0.6539 r:0.7166
ru_en Dev loss: 0.5138 r:0.7263
Current avg r:0.6924 Best avg r: 0.7375
02:26:33,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:27:37,880 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:28:42,871 root INFO Epoch 11 Global steps: 89500 Train loss: 0.1034
ro_en Dev loss: 0.3566 r:0.8147
et_en Dev loss: 0.4888 r:0.6612
si_en Dev loss: 0.9087 r:0.5389
ne_en Dev loss: 0.5695 r:0.7244
ru_en Dev loss: 0.4878 r:0.7203
Current avg r:0.6919 Best avg r: 0.7375
02:31:54,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:32:59,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:34:04,722 root INFO Epoch 11 Global steps: 90000 Train loss: 0.1043
ro_en Dev loss: 0.3529 r:0.8156
et_en Dev loss: 0.4930 r:0.6565
si_en Dev loss: 0.8733 r:0.5394
ne_en Dev loss: 0.5204 r:0.7180
ru_en Dev loss: 0.4564 r:0.7309
Current avg r:0.6921 Best avg r: 0.7375
02:37:18,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:38:23,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:39:28,404 root INFO Epoch 12 Global steps: 90500 Train loss: 0.0973
ro_en Dev loss: 0.3534 r:0.8143
et_en Dev loss: 0.4793 r:0.6684
si_en Dev loss: 0.8390 r:0.5450
ne_en Dev loss: 0.5578 r:0.7196
ru_en Dev loss: 0.4482 r:0.7370
Current avg r:0.6969 Best avg r: 0.7375
02:42:49,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:54,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:59,588 root INFO Epoch 12 Global steps: 91000 Train loss: 0.0998
ro_en Dev loss: 0.3999 r:0.8122
et_en Dev loss: 0.4943 r:0.6560
si_en Dev loss: 0.9665 r:0.5426
ne_en Dev loss: 0.6627 r:0.7169
ru_en Dev loss: 0.5110 r:0.7259
Current avg r:0.6907 Best avg r: 0.7375
02:48:12,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:49:17,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:50:22,250 root INFO Epoch 12 Global steps: 91500 Train loss: 0.0988
ro_en Dev loss: 0.3784 r:0.8128
et_en Dev loss: 0.4947 r:0.6672
si_en Dev loss: 0.8836 r:0.5445
ne_en Dev loss: 0.6115 r:0.7187
ru_en Dev loss: 0.4449 r:0.7431
Current avg r:0.6973 Best avg r: 0.7375
02:53:34,810 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:54:39,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:55:44,592 root INFO Epoch 12 Global steps: 92000 Train loss: 0.0999
ro_en Dev loss: 0.3795 r:0.8143
et_en Dev loss: 0.4816 r:0.6555
si_en Dev loss: 0.9526 r:0.5376
ne_en Dev loss: 0.6396 r:0.7129
ru_en Dev loss: 0.4867 r:0.7307
Current avg r:0.6902 Best avg r: 0.7375
02:58:57,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:00:02,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:01:07,288 root INFO Epoch 12 Global steps: 92500 Train loss: 0.1021
ro_en Dev loss: 0.3205 r:0.8216
et_en Dev loss: 0.4654 r:0.6655
si_en Dev loss: 0.8333 r:0.5450
ne_en Dev loss: 0.4937 r:0.7195
ru_en Dev loss: 0.4235 r:0.7468
Current avg r:0.6997 Best avg r: 0.7375
03:04:19,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:05:24,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:06:29,690 root INFO Epoch 12 Global steps: 93000 Train loss: 0.0993
ro_en Dev loss: 0.3729 r:0.8158
et_en Dev loss: 0.4896 r:0.6532
si_en Dev loss: 0.9904 r:0.5376
ne_en Dev loss: 0.6025 r:0.7204
ru_en Dev loss: 0.5200 r:0.7184
Current avg r:0.6891 Best avg r: 0.7375
03:09:42,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:47,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:51,738 root INFO Epoch 12 Global steps: 93500 Train loss: 0.0930
ro_en Dev loss: 0.3426 r:0.8188
et_en Dev loss: 0.4615 r:0.6591
si_en Dev loss: 0.9100 r:0.5435
ne_en Dev loss: 0.6089 r:0.7216
ru_en Dev loss: 0.4807 r:0.7273
Current avg r:0.6941 Best avg r: 0.7375
03:15:03,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:16:08,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:17:14,106 root INFO Epoch 12 Global steps: 94000 Train loss: 0.0979
ro_en Dev loss: 0.3841 r:0.8151
et_en Dev loss: 0.4784 r:0.6539
si_en Dev loss: 0.9606 r:0.5425
ne_en Dev loss: 0.6097 r:0.7242
ru_en Dev loss: 0.5327 r:0.7218
Current avg r:0.6915 Best avg r: 0.7375
03:20:26,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:31,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:36,431 root INFO Epoch 12 Global steps: 94500 Train loss: 0.0973
ro_en Dev loss: 0.3613 r:0.8168
et_en Dev loss: 0.4943 r:0.6562
si_en Dev loss: 0.9223 r:0.5427
ne_en Dev loss: 0.5831 r:0.7221
ru_en Dev loss: 0.5013 r:0.7321
Current avg r:0.6940 Best avg r: 0.7375
03:25:50,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:26:55,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:28:00,584 root INFO Epoch 12 Global steps: 95000 Train loss: 0.0949
ro_en Dev loss: 0.3501 r:0.8153
et_en Dev loss: 0.5075 r:0.6551
si_en Dev loss: 0.9268 r:0.5422
ne_en Dev loss: 0.5883 r:0.7211
ru_en Dev loss: 0.4618 r:0.7413
Current avg r:0.6950 Best avg r: 0.7375
03:31:12,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:32:17,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:33:22,504 root INFO Epoch 12 Global steps: 95500 Train loss: 0.0911
ro_en Dev loss: 0.3611 r:0.8155
et_en Dev loss: 0.4946 r:0.6627
si_en Dev loss: 0.8968 r:0.5442
ne_en Dev loss: 0.5959 r:0.7154
ru_en Dev loss: 0.4727 r:0.7356
Current avg r:0.6947 Best avg r: 0.7375
03:36:34,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:39,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:44,887 root INFO Epoch 12 Global steps: 96000 Train loss: 0.0940
ro_en Dev loss: 0.3805 r:0.8157
et_en Dev loss: 0.4959 r:0.6576
si_en Dev loss: 0.8934 r:0.5458
ne_en Dev loss: 0.5754 r:0.7184
ru_en Dev loss: 0.5005 r:0.7358
Current avg r:0.6947 Best avg r: 0.7375
03:41:57,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:02,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:44:07,513 root INFO Epoch 12 Global steps: 96500 Train loss: 0.0934
ro_en Dev loss: 0.3572 r:0.8150
et_en Dev loss: 0.4687 r:0.6556
si_en Dev loss: 0.9022 r:0.5391
ne_en Dev loss: 0.5826 r:0.7246
ru_en Dev loss: 0.4856 r:0.7295
Current avg r:0.6928 Best avg r: 0.7375
03:47:20,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:48:24,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:49:29,841 root INFO Epoch 12 Global steps: 97000 Train loss: 0.0908
ro_en Dev loss: 0.3699 r:0.8146
et_en Dev loss: 0.4816 r:0.6533
si_en Dev loss: 0.9397 r:0.5360
ne_en Dev loss: 0.6534 r:0.7170
ru_en Dev loss: 0.4771 r:0.7367
Current avg r:0.6915 Best avg r: 0.7375
03:52:41,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:53:46,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:54:52,44 root INFO Epoch 12 Global steps: 97500 Train loss: 0.0964
ro_en Dev loss: 0.3476 r:0.8188
et_en Dev loss: 0.4619 r:0.6660
si_en Dev loss: 0.8705 r:0.5448
ne_en Dev loss: 0.5325 r:0.7231
ru_en Dev loss: 0.4588 r:0.7455
Current avg r:0.6997 Best avg r: 0.7375
03:58:05,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:59:11,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:16,68 root INFO Epoch 13 Global steps: 98000 Train loss: 0.0869
ro_en Dev loss: 0.3715 r:0.8137
et_en Dev loss: 0.4743 r:0.6631
si_en Dev loss: 0.9308 r:0.5455
ne_en Dev loss: 0.6050 r:0.7240
ru_en Dev loss: 0.4632 r:0.7434
Current avg r:0.6979 Best avg r: 0.7375
04:03:28,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:33,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:05:38,161 root INFO Epoch 13 Global steps: 98500 Train loss: 0.0875
ro_en Dev loss: 0.3768 r:0.8145
et_en Dev loss: 0.4769 r:0.6558
si_en Dev loss: 0.9333 r:0.5440
ne_en Dev loss: 0.6165 r:0.7152
ru_en Dev loss: 0.4974 r:0.7349
Current avg r:0.6929 Best avg r: 0.7375
04:08:50,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:09:55,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:11:00,683 root INFO Epoch 13 Global steps: 99000 Train loss: 0.0869
ro_en Dev loss: 0.3439 r:0.8141
et_en Dev loss: 0.4571 r:0.6604
si_en Dev loss: 0.8346 r:0.5478
ne_en Dev loss: 0.5601 r:0.7135
ru_en Dev loss: 0.4328 r:0.7399
Current avg r:0.6952 Best avg r: 0.7375
04:14:13,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:15:18,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:16:23,120 root INFO Epoch 13 Global steps: 99500 Train loss: 0.0935
ro_en Dev loss: 0.3377 r:0.8155
et_en Dev loss: 0.4625 r:0.6689
si_en Dev loss: 0.7879 r:0.5515
ne_en Dev loss: 0.5087 r:0.7167
ru_en Dev loss: 0.4318 r:0.7409
Current avg r:0.6987 Best avg r: 0.7375
04:19:35,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:20:40,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:21:45,256 root INFO Epoch 13 Global steps: 100000 Train loss: 0.0880
ro_en Dev loss: 0.3840 r:0.8110
et_en Dev loss: 0.4913 r:0.6598
si_en Dev loss: 0.8918 r:0.5462
ne_en Dev loss: 0.6036 r:0.7189
ru_en Dev loss: 0.5150 r:0.7287
Current avg r:0.6929 Best avg r: 0.7375
04:24:57,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:26:02,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:27:06,847 root INFO Epoch 13 Global steps: 100500 Train loss: 0.0846
ro_en Dev loss: 0.3656 r:0.8109
et_en Dev loss: 0.4785 r:0.6497
si_en Dev loss: 0.8954 r:0.5368
ne_en Dev loss: 0.5928 r:0.7170
ru_en Dev loss: 0.4660 r:0.7353
Current avg r:0.6900 Best avg r: 0.7375
04:30:27,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:31:32,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:32:37,806 root INFO Epoch 13 Global steps: 101000 Train loss: 0.0862
ro_en Dev loss: 0.3705 r:0.8182
et_en Dev loss: 0.4777 r:0.6654
si_en Dev loss: 0.8702 r:0.5538
ne_en Dev loss: 0.5584 r:0.7212
ru_en Dev loss: 0.4892 r:0.7512
Current avg r:0.7020 Best avg r: 0.7375
04:35:59,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:37:04,512 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:09,591 root INFO Epoch 13 Global steps: 101500 Train loss: 0.0841
ro_en Dev loss: 0.3711 r:0.8136
et_en Dev loss: 0.4937 r:0.6572
si_en Dev loss: 0.9325 r:0.5483
ne_en Dev loss: 0.5921 r:0.7199
ru_en Dev loss: 0.4551 r:0.7530
Current avg r:0.6984 Best avg r: 0.7375
04:41:22,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:42:27,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:43:31,756 root INFO Epoch 13 Global steps: 102000 Train loss: 0.0870
ro_en Dev loss: 0.3538 r:0.8192
et_en Dev loss: 0.4774 r:0.6623
si_en Dev loss: 0.9379 r:0.5484
ne_en Dev loss: 0.5909 r:0.7217
ru_en Dev loss: 0.4570 r:0.7484
Current avg r:0.7000 Best avg r: 0.7375
04:46:44,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:47:49,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:54,354 root INFO Epoch 13 Global steps: 102500 Train loss: 0.0813
ro_en Dev loss: 0.3536 r:0.8168
et_en Dev loss: 0.4684 r:0.6612
si_en Dev loss: 0.9115 r:0.5499
ne_en Dev loss: 0.6389 r:0.7181
ru_en Dev loss: 0.4583 r:0.7458
Current avg r:0.6984 Best avg r: 0.7375
04:52:06,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:53:11,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:54:16,866 root INFO Epoch 13 Global steps: 103000 Train loss: 0.0879
ro_en Dev loss: 0.3622 r:0.8112
et_en Dev loss: 0.4872 r:0.6525
si_en Dev loss: 0.9508 r:0.5415
ne_en Dev loss: 0.6224 r:0.7170
ru_en Dev loss: 0.4635 r:0.7395
Current avg r:0.6923 Best avg r: 0.7375
04:57:29,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:58:34,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:59:39,142 root INFO Epoch 13 Global steps: 103500 Train loss: 0.0879
ro_en Dev loss: 0.3875 r:0.8096
et_en Dev loss: 0.5015 r:0.6483
si_en Dev loss: 1.0059 r:0.5319
ne_en Dev loss: 0.6514 r:0.7127
ru_en Dev loss: 0.4858 r:0.7412
Current avg r:0.6887 Best avg r: 0.7375
05:02:51,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:56,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:05:01,679 root INFO Epoch 13 Global steps: 104000 Train loss: 0.0936
ro_en Dev loss: 0.3607 r:0.8155
et_en Dev loss: 0.4850 r:0.6638
si_en Dev loss: 0.9171 r:0.5483
ne_en Dev loss: 0.6132 r:0.7212
ru_en Dev loss: 0.4499 r:0.7494
Current avg r:0.6996 Best avg r: 0.7375
05:08:13,865 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:09:18,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:10:24,19 root INFO Epoch 13 Global steps: 104500 Train loss: 0.0886
ro_en Dev loss: 0.3365 r:0.8166
et_en Dev loss: 0.4934 r:0.6615
si_en Dev loss: 0.8479 r:0.5432
ne_en Dev loss: 0.5266 r:0.7199
ru_en Dev loss: 0.4269 r:0.7476
Current avg r:0.6978 Best avg r: 0.7375
05:13:41,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:46,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:51,842 root INFO Epoch 13 Global steps: 105000 Train loss: 0.0819
ro_en Dev loss: 0.4080 r:0.8105
et_en Dev loss: 0.5073 r:0.6567
si_en Dev loss: 1.0069 r:0.5469
ne_en Dev loss: 0.6758 r:0.7180
ru_en Dev loss: 0.5357 r:0.7299
Current avg r:0.6924 Best avg r: 0.7375
05:19:05,545 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:10,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:21:15,376 root INFO Epoch 14 Global steps: 105500 Train loss: 0.0808
ro_en Dev loss: 0.3705 r:0.8155
et_en Dev loss: 0.4634 r:0.6690
si_en Dev loss: 0.9405 r:0.5466
ne_en Dev loss: 0.5928 r:0.7219
ru_en Dev loss: 0.4394 r:0.7506
Current avg r:0.7007 Best avg r: 0.7375
05:24:30,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:25:35,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:40,671 root INFO Epoch 14 Global steps: 106000 Train loss: 0.0808
ro_en Dev loss: 0.3609 r:0.8157
et_en Dev loss: 0.4645 r:0.6666
si_en Dev loss: 0.9245 r:0.5477
ne_en Dev loss: 0.6279 r:0.7194
ru_en Dev loss: 0.4713 r:0.7368
Current avg r:0.6972 Best avg r: 0.7375
05:30:01,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:31:07,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:32:12,230 root INFO Epoch 14 Global steps: 106500 Train loss: 0.0778
ro_en Dev loss: 0.3672 r:0.8140
et_en Dev loss: 0.4773 r:0.6639
si_en Dev loss: 0.9260 r:0.5412
ne_en Dev loss: 0.5987 r:0.7111
ru_en Dev loss: 0.4583 r:0.7441
Current avg r:0.6948 Best avg r: 0.7375
05:35:24,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:29,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:37:34,279 root INFO Epoch 14 Global steps: 107000 Train loss: 0.0719
ro_en Dev loss: 0.3665 r:0.8158
et_en Dev loss: 0.4531 r:0.6699
si_en Dev loss: 0.9076 r:0.5466
ne_en Dev loss: 0.6153 r:0.7152
ru_en Dev loss: 0.4998 r:0.7338
Current avg r:0.6963 Best avg r: 0.7375
05:40:46,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:41:51,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:42:56,208 root INFO Epoch 14 Global steps: 107500 Train loss: 0.0791
ro_en Dev loss: 0.3824 r:0.8133
et_en Dev loss: 0.4715 r:0.6677
si_en Dev loss: 0.9556 r:0.5489
ne_en Dev loss: 0.6513 r:0.7135
ru_en Dev loss: 0.5317 r:0.7284
Current avg r:0.6944 Best avg r: 0.7375
05:46:09,709 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:47:15,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:48:20,789 root INFO Epoch 14 Global steps: 108000 Train loss: 0.0814
ro_en Dev loss: 0.3487 r:0.8156
et_en Dev loss: 0.4576 r:0.6676
si_en Dev loss: 0.8609 r:0.5468
ne_en Dev loss: 0.5783 r:0.7148
ru_en Dev loss: 0.4728 r:0.7356
Current avg r:0.6961 Best avg r: 0.7375
05:51:33,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:38,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:43,74 root INFO Epoch 14 Global steps: 108500 Train loss: 0.0799
ro_en Dev loss: 0.3471 r:0.8176
et_en Dev loss: 0.4614 r:0.6790
si_en Dev loss: 0.8889 r:0.5491
ne_en Dev loss: 0.5681 r:0.7171
ru_en Dev loss: 0.4408 r:0.7478
Current avg r:0.7021 Best avg r: 0.7375
05:56:55,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:58:00,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:05,643 root INFO Epoch 14 Global steps: 109000 Train loss: 0.0807
ro_en Dev loss: 0.3601 r:0.8187
et_en Dev loss: 0.4590 r:0.6665
si_en Dev loss: 0.9322 r:0.5387
ne_en Dev loss: 0.6056 r:0.7141
ru_en Dev loss: 0.5037 r:0.7315
Current avg r:0.6939 Best avg r: 0.7375
06:02:17,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:22,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:27,909 root INFO Epoch 14 Global steps: 109500 Train loss: 0.0788
ro_en Dev loss: 0.3857 r:0.8115
et_en Dev loss: 0.4894 r:0.6657
si_en Dev loss: 0.9235 r:0.5495
ne_en Dev loss: 0.5809 r:0.7213
ru_en Dev loss: 0.4668 r:0.7423
Current avg r:0.6981 Best avg r: 0.7375
06:07:40,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:08:45,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:09:50,250 root INFO Epoch 14 Global steps: 110000 Train loss: 0.0787
ro_en Dev loss: 0.3545 r:0.8163
et_en Dev loss: 0.4583 r:0.6724
si_en Dev loss: 0.8840 r:0.5505
ne_en Dev loss: 0.5408 r:0.7106
ru_en Dev loss: 0.4441 r:0.7482
Current avg r:0.6996 Best avg r: 0.7375
06:13:02,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:07,553 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:12,393 root INFO Epoch 14 Global steps: 110500 Train loss: 0.0772
ro_en Dev loss: 0.3786 r:0.8122
et_en Dev loss: 0.4877 r:0.6677
si_en Dev loss: 0.9438 r:0.5490
ne_en Dev loss: 0.6392 r:0.7144
ru_en Dev loss: 0.4889 r:0.7341
Current avg r:0.6955 Best avg r: 0.7375
06:18:24,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:19:29,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:20:34,308 root INFO Epoch 14 Global steps: 111000 Train loss: 0.0788
ro_en Dev loss: 0.3400 r:0.8178
et_en Dev loss: 0.4636 r:0.6689
si_en Dev loss: 0.8709 r:0.5432
ne_en Dev loss: 0.5377 r:0.7107
ru_en Dev loss: 0.4549 r:0.7366
Current avg r:0.6954 Best avg r: 0.7375
06:23:46,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:24:51,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:25:56,519 root INFO Epoch 14 Global steps: 111500 Train loss: 0.0814
ro_en Dev loss: 0.3857 r:0.8122
et_en Dev loss: 0.4719 r:0.6698
si_en Dev loss: 0.9728 r:0.5380
ne_en Dev loss: 0.6362 r:0.7124
ru_en Dev loss: 0.4762 r:0.7415
Current avg r:0.6948 Best avg r: 0.7375
06:29:08,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:13,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:18,672 root INFO Epoch 14 Global steps: 112000 Train loss: 0.0781
ro_en Dev loss: 0.3930 r:0.8116
et_en Dev loss: 0.4909 r:0.6623
si_en Dev loss: 0.9120 r:0.5447
ne_en Dev loss: 0.5848 r:0.7178
ru_en Dev loss: 0.4831 r:0.7436
Current avg r:0.6960 Best avg r: 0.7375
06:34:31,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:35:36,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:36:41,107 root INFO Epoch 14 Global steps: 112500 Train loss: 0.0754
ro_en Dev loss: 0.3496 r:0.8171
et_en Dev loss: 0.4738 r:0.6649
si_en Dev loss: 0.8579 r:0.5472
ne_en Dev loss: 0.5752 r:0.7159
ru_en Dev loss: 0.4616 r:0.7426
Current avg r:0.6975 Best avg r: 0.7375
06:39:54,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:40:59,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:42:04,408 root INFO Epoch 15 Global steps: 113000 Train loss: 0.0649
ro_en Dev loss: 0.3404 r:0.8184
et_en Dev loss: 0.4640 r:0.6728
si_en Dev loss: 0.8240 r:0.5499
ne_en Dev loss: 0.5344 r:0.7170
ru_en Dev loss: 0.4240 r:0.7524
Current avg r:0.7021 Best avg r: 0.7375
06:45:16,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:46:21,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:47:26,232 root INFO Epoch 15 Global steps: 113500 Train loss: 0.0695
ro_en Dev loss: 0.3799 r:0.8152
et_en Dev loss: 0.4802 r:0.6631
si_en Dev loss: 0.9276 r:0.5458
ne_en Dev loss: 0.5827 r:0.7175
ru_en Dev loss: 0.4883 r:0.7410
Current avg r:0.6965 Best avg r: 0.7375
06:50:38,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:43,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:52:48,651 root INFO Epoch 15 Global steps: 114000 Train loss: 0.0740
ro_en Dev loss: 0.3848 r:0.8172
et_en Dev loss: 0.4785 r:0.6721
si_en Dev loss: 0.9653 r:0.5459
ne_en Dev loss: 0.5722 r:0.7174
ru_en Dev loss: 0.5045 r:0.7381
Current avg r:0.6981 Best avg r: 0.7375
06:56:00,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:57:06,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:58:11,40 root INFO Epoch 15 Global steps: 114500 Train loss: 0.0707
ro_en Dev loss: 0.3653 r:0.8161
et_en Dev loss: 0.4648 r:0.6696
si_en Dev loss: 0.9208 r:0.5435
ne_en Dev loss: 0.5874 r:0.7162
ru_en Dev loss: 0.4553 r:0.7417
Current avg r:0.6974 Best avg r: 0.7375
07:01:23,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:28,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:03:33,74 root INFO Epoch 15 Global steps: 115000 Train loss: 0.0698
ro_en Dev loss: 0.3623 r:0.8142
et_en Dev loss: 0.4764 r:0.6678
si_en Dev loss: 0.9678 r:0.5396
ne_en Dev loss: 0.5783 r:0.7185
ru_en Dev loss: 0.4642 r:0.7435
Current avg r:0.6967 Best avg r: 0.7375
