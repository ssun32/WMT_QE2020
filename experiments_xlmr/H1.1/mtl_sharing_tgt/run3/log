14:36:20,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:36:46,687 root INFO 
id:ro_en cur r: 0.5344 best r: 0.5344
14:37:13,76 root INFO 
id:et_en cur r: 0.3135 best r: 0.3135
14:37:39,464 root INFO 
id:si_en cur r: 0.3294 best r: 0.3294
14:38:05,825 root INFO 
id:ne_en cur r: 0.4882 best r: 0.4882
14:38:31,939 root INFO 
id:ru_en cur r: 0.5763 best r: 0.5763
14:38:31,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:37,529 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:39:37,537 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
14:39:37,541 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
14:39:37,547 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:39:37,552 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:40:43,248 root INFO Epoch 0 Global steps: 500 Train loss: 0.9308
ro_en Dev loss: 0.7548 r:0.5539
et_en Dev loss: 0.7069 r:0.3741
si_en Dev loss: 0.7686 r:0.4211
ne_en Dev loss: 0.7080 r:0.4808
ru_en Dev loss: 0.6867 r:0.6099
Current avg r:0.4880 Best avg r: 0.4880
14:43:59,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:25,836 root INFO 
id:ro_en cur r: 0.6324 best r: 0.6324
14:44:52,335 root INFO 
id:et_en cur r: 0.4745 best r: 0.4745
14:45:18,788 root INFO 
id:si_en cur r: 0.3820 best r: 0.3820
14:45:45,412 root INFO 
id:ne_en cur r: 0.5531 best r: 0.5531
14:46:11,688 root INFO 
id:ru_en cur r: 0.6230 best r: 0.6230
14:46:11,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:17,547 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:47:17,556 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
14:47:17,564 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
14:47:17,571 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:47:17,577 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:48:23,447 root INFO Epoch 0 Global steps: 1000 Train loss: 0.8781
ro_en Dev loss: 0.6225 r:0.6558
et_en Dev loss: 0.5767 r:0.4755
si_en Dev loss: 0.7307 r:0.4407
ne_en Dev loss: 0.5918 r:0.5702
ru_en Dev loss: 0.5523 r:0.6542
Current avg r:0.5593 Best avg r: 0.5593
14:51:41,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:07,562 root INFO 
id:ro_en cur r: 0.6597 best r: 0.6597
14:52:33,951 root INFO 
id:et_en cur r: 0.5820 best r: 0.5820
14:53:00,359 root INFO 
id:si_en cur r: 0.4433 best r: 0.4433
14:53:26,743 root INFO 
id:ne_en cur r: 0.5965 best r: 0.5965
14:53:52,953 root INFO 
id:ru_en cur r: 0.6575 best r: 0.6575
14:53:52,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:58,768 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:54:58,792 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
14:54:58,803 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
14:54:58,817 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:54:58,828 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:56:04,702 root INFO Epoch 0 Global steps: 1500 Train loss: 0.7401
ro_en Dev loss: 0.5319 r:0.6693
et_en Dev loss: 0.4759 r:0.5783
si_en Dev loss: 0.7122 r:0.4695
ne_en Dev loss: 0.5080 r:0.6182
ru_en Dev loss: 0.4830 r:0.6724
Current avg r:0.6015 Best avg r: 0.6015
14:59:22,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:48,838 root INFO 
id:ro_en cur r: 0.6962 best r: 0.6962
15:00:15,222 root INFO 
id:et_en cur r: 0.6495 best r: 0.6495
15:00:41,615 root INFO 
id:si_en cur r: 0.4707 best r: 0.4707
15:01:08,21 root INFO 
id:ne_en cur r: 0.6388 best r: 0.6388
15:01:34,227 root INFO 
id:ru_en cur r: 0.7043 best r: 0.7043
15:01:34,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:40,35 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:02:40,42 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
15:02:40,48 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
15:02:40,53 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:02:40,57 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:03:45,897 root INFO Epoch 0 Global steps: 2000 Train loss: 0.6385
ro_en Dev loss: 0.4830 r:0.7150
et_en Dev loss: 0.4290 r:0.6461
si_en Dev loss: 0.7497 r:0.5107
ne_en Dev loss: 0.4931 r:0.6523
ru_en Dev loss: 0.4655 r:0.7050
Current avg r:0.6458 Best avg r: 0.6458
15:07:03,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:30,76 root INFO 
id:ro_en cur r: 0.7312 best r: 0.7312
15:07:56,463 root INFO 
id:et_en cur r: 0.6762 best r: 0.6762
15:08:22,863 root INFO 
id:si_en cur r: 0.5085 best r: 0.5085
15:08:49,275 root INFO 
id:ne_en cur r: 0.6913 best r: 0.6913
15:09:15,501 root INFO 
id:ru_en cur r: 0.7191 best r: 0.7191
15:09:15,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:21,344 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:10:21,356 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
15:10:21,363 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
15:10:21,371 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:10:21,377 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:11:27,275 root INFO Epoch 0 Global steps: 2500 Train loss: 0.6211
ro_en Dev loss: 0.3972 r:0.7456
et_en Dev loss: 0.3799 r:0.6803
si_en Dev loss: 0.6602 r:0.5455
ne_en Dev loss: 0.4158 r:0.6999
ru_en Dev loss: 0.4128 r:0.7211
Current avg r:0.6785 Best avg r: 0.6785
15:14:45,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:11,504 root INFO 
id:ro_en cur r: 0.7408 best r: 0.7408
15:15:51,95 root INFO 
id:si_en cur r: 0.5139 best r: 0.5139
15:16:17,401 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:23,214 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6049
ro_en Dev loss: 0.4532 r:0.7535
et_en Dev loss: 0.3905 r:0.6805
si_en Dev loss: 0.7381 r:0.5408
ne_en Dev loss: 0.4165 r:0.7019
ru_en Dev loss: 0.5981 r:0.6828
Current avg r:0.6719 Best avg r: 0.6785
15:20:40,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:21:06,742 root INFO 
id:ro_en cur r: 0.7725 best r: 0.7725
15:21:33,123 root INFO 
id:et_en cur r: 0.6868 best r: 0.6868
15:21:59,535 root INFO 
id:si_en cur r: 0.5271 best r: 0.5271
15:22:25,931 root INFO 
id:ne_en cur r: 0.6989 best r: 0.6989
15:22:39,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:44,867 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:23:44,899 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
15:23:44,912 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
15:23:44,927 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:23:44,940 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:24:50,817 root INFO Epoch 0 Global steps: 3500 Train loss: 0.5780
ro_en Dev loss: 0.4061 r:0.7778
et_en Dev loss: 0.4013 r:0.6918
si_en Dev loss: 0.8047 r:0.5585
ne_en Dev loss: 0.4944 r:0.7071
ru_en Dev loss: 0.5056 r:0.7166
Current avg r:0.6904 Best avg r: 0.6904
15:28:08,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:28:34,702 root INFO 
id:ro_en cur r: 0.7841 best r: 0.7841
15:29:01,82 root INFO 
id:et_en cur r: 0.7039 best r: 0.7039
15:29:27,485 root INFO 
id:si_en cur r: 0.5577 best r: 0.5577
15:29:53,890 root INFO 
id:ne_en cur r: 0.7251 best r: 0.7251
15:30:20,112 root INFO 
id:ru_en cur r: 0.7195 best r: 0.7195
15:30:20,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:25,952 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:31:25,972 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
15:31:25,980 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
15:31:25,988 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:31:25,996 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:32:31,870 root INFO Epoch 0 Global steps: 4000 Train loss: 0.5557
ro_en Dev loss: 0.3688 r:0.7872
et_en Dev loss: 0.3620 r:0.7082
si_en Dev loss: 0.7084 r:0.5792
ne_en Dev loss: 0.4625 r:0.7249
ru_en Dev loss: 0.4621 r:0.7314
Current avg r:0.7062 Best avg r: 0.7062
15:35:49,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:15,510 root INFO 
id:ro_en cur r: 0.7847 best r: 0.7847
15:36:55,95 root INFO 
id:si_en cur r: 0.5715 best r: 0.5715
15:37:21,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:27,235 root INFO Epoch 0 Global steps: 4500 Train loss: 0.5584
ro_en Dev loss: 0.5184 r:0.7907
et_en Dev loss: 0.4209 r:0.7003
si_en Dev loss: 0.6918 r:0.5862
ne_en Dev loss: 0.4748 r:0.7262
ru_en Dev loss: 0.6040 r:0.7156
Current avg r:0.7038 Best avg r: 0.7062
15:41:44,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:50,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:56,477 root INFO Epoch 0 Global steps: 5000 Train loss: 0.5317
ro_en Dev loss: 0.5078 r:0.7912
et_en Dev loss: 0.4340 r:0.6941
si_en Dev loss: 0.8716 r:0.5718
ne_en Dev loss: 0.6101 r:0.7124
ru_en Dev loss: 0.5974 r:0.7078
Current avg r:0.6955 Best avg r: 0.7062
15:47:14,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:40,526 root INFO 
id:ro_en cur r: 0.7975 best r: 0.7975
15:48:20,101 root INFO 
id:si_en cur r: 0.5826 best r: 0.5826
15:48:46,500 root INFO 
id:ne_en cur r: 0.7318 best r: 0.7318
15:48:59,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:05,460 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:50:05,479 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
15:50:05,484 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
15:50:05,489 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:50:05,494 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:51:11,404 root INFO Epoch 0 Global steps: 5500 Train loss: 0.5281
ro_en Dev loss: 0.3981 r:0.7995
et_en Dev loss: 0.3922 r:0.7018
si_en Dev loss: 0.7493 r:0.5939
ne_en Dev loss: 0.4446 r:0.7322
ru_en Dev loss: 0.5252 r:0.7215
Current avg r:0.7098 Best avg r: 0.7098
15:54:29,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:21,924 root INFO 
id:si_en cur r: 0.5988 best r: 0.5988
15:55:48,302 root INFO 
id:ne_en cur r: 0.7360 best r: 0.7360
15:56:14,500 root INFO 
id:ru_en cur r: 0.7251 best r: 0.7251
15:56:14,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:20,275 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:57:20,310 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
15:57:20,319 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
15:57:20,329 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:57:20,337 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:58:26,250 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5269
ro_en Dev loss: 0.3809 r:0.8054
et_en Dev loss: 0.3741 r:0.7044
si_en Dev loss: 0.6504 r:0.6069
ne_en Dev loss: 0.4472 r:0.7368
ru_en Dev loss: 0.4802 r:0.7380
Current avg r:0.7183 Best avg r: 0.7183
16:01:43,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:02:36,636 root INFO 
id:si_en cur r: 0.6094 best r: 0.6094
16:03:02,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:08,754 root INFO Epoch 0 Global steps: 6500 Train loss: 0.5228
ro_en Dev loss: 0.3790 r:0.8025
et_en Dev loss: 0.3793 r:0.7021
si_en Dev loss: 0.6309 r:0.6078
ne_en Dev loss: 0.3770 r:0.7369
ru_en Dev loss: 0.5168 r:0.7289
Current avg r:0.7156 Best avg r: 0.7183
16:07:26,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:52,654 root INFO 
id:ro_en cur r: 0.8024 best r: 0.8024
16:08:45,427 root INFO 
id:ne_en cur r: 0.7488 best r: 0.7488
16:09:11,661 root INFO 
id:ru_en cur r: 0.7464 best r: 0.7464
16:09:11,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:17,520 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:10:17,528 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
16:10:17,535 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
16:10:17,541 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:10:17,547 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:11:23,461 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5101
ro_en Dev loss: 0.3481 r:0.8030
et_en Dev loss: 0.3741 r:0.7015
si_en Dev loss: 0.5932 r:0.6130
ne_en Dev loss: 0.3651 r:0.7471
ru_en Dev loss: 0.3846 r:0.7492
Current avg r:0.7228 Best avg r: 0.7228
16:14:41,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:07,678 root INFO 
id:ro_en cur r: 0.8031 best r: 0.8031
16:16:00,472 root INFO 
id:ne_en cur r: 0.7527 best r: 0.7527
16:16:13,586 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:17:19,440 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:17:19,448 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
16:17:19,455 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
16:17:19,460 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:17:19,465 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:18:25,365 root INFO Epoch 0 Global steps: 7500 Train loss: 0.5119
ro_en Dev loss: 0.3762 r:0.8072
et_en Dev loss: 0.3700 r:0.7066
si_en Dev loss: 0.5686 r:0.6191
ne_en Dev loss: 0.3619 r:0.7546
ru_en Dev loss: 0.4267 r:0.7391
Current avg r:0.7253 Best avg r: 0.7253
16:21:44,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:50,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:56,402 root INFO Epoch 1 Global steps: 8000 Train loss: 0.4620
ro_en Dev loss: 0.3973 r:0.8060
et_en Dev loss: 0.3935 r:0.7040
si_en Dev loss: 0.6776 r:0.6127
ne_en Dev loss: 0.5226 r:0.7440
ru_en Dev loss: 0.4970 r:0.7240
Current avg r:0.7182 Best avg r: 0.7253
16:27:14,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:40,698 root INFO 
id:ro_en cur r: 0.8075 best r: 0.8075
16:28:07,74 root INFO 
id:et_en cur r: 0.7048 best r: 0.7048
16:28:46,659 root INFO 
id:ne_en cur r: 0.7556 best r: 0.7556
16:28:59,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:05,588 root INFO Epoch 1 Global steps: 8500 Train loss: 0.4915
ro_en Dev loss: 0.4027 r:0.8082
et_en Dev loss: 0.4066 r:0.7050
si_en Dev loss: 0.7254 r:0.6148
ne_en Dev loss: 0.4275 r:0.7480
ru_en Dev loss: 0.4566 r:0.7479
Current avg r:0.7248 Best avg r: 0.7253
16:33:23,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:29,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:35,251 root INFO Epoch 1 Global steps: 9000 Train loss: 0.4773
ro_en Dev loss: 0.3561 r:0.8066
et_en Dev loss: 0.3779 r:0.7016
si_en Dev loss: 0.7034 r:0.6107
ne_en Dev loss: 0.4039 r:0.7452
ru_en Dev loss: 0.4538 r:0.7410
Current avg r:0.7210 Best avg r: 0.7253
16:38:53,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:59,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:05,29 root INFO Epoch 1 Global steps: 9500 Train loss: 0.4570
ro_en Dev loss: 0.4600 r:0.7908
et_en Dev loss: 0.4288 r:0.6862
si_en Dev loss: 0.9114 r:0.5773
ne_en Dev loss: 0.5833 r:0.7183
ru_en Dev loss: 0.5951 r:0.6969
Current avg r:0.6939 Best avg r: 0.7253
16:44:22,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:28,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:34,586 root INFO Epoch 1 Global steps: 10000 Train loss: 0.4591
ro_en Dev loss: 0.3622 r:0.8054
et_en Dev loss: 0.3825 r:0.6960
si_en Dev loss: 0.7338 r:0.6014
ne_en Dev loss: 0.4235 r:0.7397
ru_en Dev loss: 0.4489 r:0.7450
Current avg r:0.7175 Best avg r: 0.7253
16:49:52,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:18,942 root INFO 
id:ro_en cur r: 0.8158 best r: 0.8158
16:50:45,333 root INFO 
id:et_en cur r: 0.7129 best r: 0.7129
16:51:24,950 root INFO 
id:ne_en cur r: 0.7563 best r: 0.7563
16:51:51,180 root INFO 
id:ru_en cur r: 0.7478 best r: 0.7478
16:51:51,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:57,22 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:52:57,32 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
16:52:57,37 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
16:52:57,43 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:52:57,50 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:54:02,922 root INFO Epoch 1 Global steps: 10500 Train loss: 0.4554
ro_en Dev loss: 0.3658 r:0.8165
et_en Dev loss: 0.3843 r:0.7132
si_en Dev loss: 0.6436 r:0.6151
ne_en Dev loss: 0.4441 r:0.7494
ru_en Dev loss: 0.5041 r:0.7513
Current avg r:0.7291 Best avg r: 0.7291
16:57:20,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:26,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:32,420 root INFO Epoch 1 Global steps: 11000 Train loss: 0.4711
ro_en Dev loss: 0.3629 r:0.8137
et_en Dev loss: 0.3648 r:0.7078
si_en Dev loss: 0.6623 r:0.6069
ne_en Dev loss: 0.3992 r:0.7438
ru_en Dev loss: 0.5400 r:0.7321
Current avg r:0.7209 Best avg r: 0.7291
17:02:49,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:55,298 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:01,37 root INFO Epoch 1 Global steps: 11500 Train loss: 0.4417
ro_en Dev loss: 0.3987 r:0.8084
et_en Dev loss: 0.4054 r:0.7001
si_en Dev loss: 0.8532 r:0.5927
ne_en Dev loss: 0.4917 r:0.7380
ru_en Dev loss: 0.5228 r:0.7356
Current avg r:0.7150 Best avg r: 0.7291
17:08:18,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:23,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:10:29,696 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4401
ro_en Dev loss: 0.3328 r:0.8152
et_en Dev loss: 0.3702 r:0.7088
si_en Dev loss: 0.6546 r:0.6159
ne_en Dev loss: 0.4113 r:0.7429
ru_en Dev loss: 0.4353 r:0.7496
Current avg r:0.7265 Best avg r: 0.7291
17:13:46,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:39,600 root INFO 
id:si_en cur r: 0.6110 best r: 0.6110
17:15:05,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:11,552 root INFO Epoch 1 Global steps: 12500 Train loss: 0.4566
ro_en Dev loss: 0.4218 r:0.8079
et_en Dev loss: 0.4313 r:0.6987
si_en Dev loss: 0.7179 r:0.6196
ne_en Dev loss: 0.4194 r:0.7329
ru_en Dev loss: 0.5774 r:0.7285
Current avg r:0.7175 Best avg r: 0.7291
17:19:28,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:21,467 root INFO 
id:si_en cur r: 0.6123 best r: 0.6123
17:20:47,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:53,460 root INFO Epoch 1 Global steps: 13000 Train loss: 0.4451
ro_en Dev loss: 0.3862 r:0.8148
et_en Dev loss: 0.3953 r:0.7064
si_en Dev loss: 0.7765 r:0.6223
ne_en Dev loss: 0.4697 r:0.7491
ru_en Dev loss: 0.4984 r:0.7374
Current avg r:0.7260 Best avg r: 0.7291
17:25:10,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:16,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:22,491 root INFO Epoch 1 Global steps: 13500 Train loss: 0.4382
ro_en Dev loss: 0.3415 r:0.8057
et_en Dev loss: 0.3755 r:0.7027
si_en Dev loss: 0.6883 r:0.6069
ne_en Dev loss: 0.4596 r:0.7427
ru_en Dev loss: 0.4868 r:0.7193
Current avg r:0.7155 Best avg r: 0.7291
17:30:39,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:06,50 root INFO 
id:ro_en cur r: 0.8205 best r: 0.8205
17:31:45,612 root INFO 
id:si_en cur r: 0.6321 best r: 0.6321
17:32:11,991 root INFO 
id:ne_en cur r: 0.7638 best r: 0.7638
17:32:25,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:30,866 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:33:30,872 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
17:33:30,876 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
17:33:30,881 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:33:30,885 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:34:36,730 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4505
ro_en Dev loss: 0.3408 r:0.8215
et_en Dev loss: 0.3605 r:0.7139
si_en Dev loss: 0.6690 r:0.6325
ne_en Dev loss: 0.4060 r:0.7604
ru_en Dev loss: 0.4981 r:0.7326
Current avg r:0.7322 Best avg r: 0.7322
17:37:53,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:20,46 root INFO 
id:ro_en cur r: 0.8227 best r: 0.8227
17:38:59,542 root INFO 
id:si_en cur r: 0.6334 best r: 0.6334
17:39:25,886 root INFO 
id:ne_en cur r: 0.7649 best r: 0.7649
17:39:38,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:44,696 root INFO Epoch 1 Global steps: 14500 Train loss: 0.4558
ro_en Dev loss: 0.3411 r:0.8218
et_en Dev loss: 0.3697 r:0.7139
si_en Dev loss: 0.8010 r:0.6289
ne_en Dev loss: 0.4293 r:0.7594
ru_en Dev loss: 0.5137 r:0.7343
Current avg r:0.7317 Best avg r: 0.7322
17:44:01,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:07,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:13,70 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4450
ro_en Dev loss: 0.4063 r:0.8177
et_en Dev loss: 0.3954 r:0.7084
si_en Dev loss: 0.7601 r:0.6213
ne_en Dev loss: 0.4205 r:0.7565
ru_en Dev loss: 0.4717 r:0.7487
Current avg r:0.7305 Best avg r: 0.7322
17:49:31,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:36,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:42,473 root INFO Epoch 2 Global steps: 15500 Train loss: 0.3902
ro_en Dev loss: 0.3597 r:0.8148
et_en Dev loss: 0.3745 r:0.7070
si_en Dev loss: 0.6552 r:0.6209
ne_en Dev loss: 0.4135 r:0.7473
ru_en Dev loss: 0.4560 r:0.7433
Current avg r:0.7267 Best avg r: 0.7322
17:54:59,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:05,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:10,899 root INFO Epoch 2 Global steps: 16000 Train loss: 0.3797
ro_en Dev loss: 0.4183 r:0.8127
et_en Dev loss: 0.4113 r:0.7032
si_en Dev loss: 0.6359 r:0.6286
ne_en Dev loss: 0.4065 r:0.7501
ru_en Dev loss: 0.5077 r:0.7439
Current avg r:0.7277 Best avg r: 0.7322
18:00:27,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:33,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:39,281 root INFO Epoch 2 Global steps: 16500 Train loss: 0.4179
ro_en Dev loss: 0.4625 r:0.8120
et_en Dev loss: 0.4092 r:0.7053
si_en Dev loss: 0.8742 r:0.6142
ne_en Dev loss: 0.5541 r:0.7525
ru_en Dev loss: 0.6390 r:0.7159
Current avg r:0.7200 Best avg r: 0.7322
18:05:56,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:01,913 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:07,596 root INFO Epoch 2 Global steps: 17000 Train loss: 0.4249
ro_en Dev loss: 0.3382 r:0.8160
et_en Dev loss: 0.3671 r:0.7090
si_en Dev loss: 0.6764 r:0.6121
ne_en Dev loss: 0.3759 r:0.7604
ru_en Dev loss: 0.4857 r:0.7214
Current avg r:0.7238 Best avg r: 0.7322
18:11:24,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:30,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:35,915 root INFO Epoch 2 Global steps: 17500 Train loss: 0.3889
ro_en Dev loss: 0.4098 r:0.8163
et_en Dev loss: 0.4187 r:0.6986
si_en Dev loss: 0.8287 r:0.6071
ne_en Dev loss: 0.4930 r:0.7532
ru_en Dev loss: 0.5329 r:0.7210
Current avg r:0.7192 Best avg r: 0.7322
18:16:52,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:58,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:04,247 root INFO Epoch 2 Global steps: 18000 Train loss: 0.3991
ro_en Dev loss: 0.3922 r:0.8117
et_en Dev loss: 0.4229 r:0.6952
si_en Dev loss: 0.6966 r:0.6130
ne_en Dev loss: 0.3978 r:0.7535
ru_en Dev loss: 0.4884 r:0.7230
Current avg r:0.7193 Best avg r: 0.7322
18:22:21,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:26,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:32,697 root INFO Epoch 2 Global steps: 18500 Train loss: 0.4041
ro_en Dev loss: 0.4307 r:0.8125
et_en Dev loss: 0.4250 r:0.7009
si_en Dev loss: 0.7984 r:0.6211
ne_en Dev loss: 0.4648 r:0.7513
ru_en Dev loss: 0.5168 r:0.7338
Current avg r:0.7239 Best avg r: 0.7322
18:27:49,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:55,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:01,168 root INFO Epoch 2 Global steps: 19000 Train loss: 0.3982
ro_en Dev loss: 0.4368 r:0.8086
et_en Dev loss: 0.4135 r:0.6997
si_en Dev loss: 0.8017 r:0.6178
ne_en Dev loss: 0.4907 r:0.7561
ru_en Dev loss: 0.5408 r:0.7169
Current avg r:0.7198 Best avg r: 0.7322
18:33:18,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:23,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:29,647 root INFO Epoch 2 Global steps: 19500 Train loss: 0.4086
ro_en Dev loss: 0.3739 r:0.8151
et_en Dev loss: 0.3902 r:0.6969
si_en Dev loss: 0.6963 r:0.6195
ne_en Dev loss: 0.4371 r:0.7505
ru_en Dev loss: 0.5352 r:0.7111
Current avg r:0.7186 Best avg r: 0.7322
18:38:46,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:52,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:58,206 root INFO Epoch 2 Global steps: 20000 Train loss: 0.3882
ro_en Dev loss: 0.3939 r:0.8182
et_en Dev loss: 0.4020 r:0.7039
si_en Dev loss: 0.7884 r:0.6193
ne_en Dev loss: 0.5373 r:0.7492
ru_en Dev loss: 0.5113 r:0.7330
Current avg r:0.7247 Best avg r: 0.7322
18:44:15,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:21,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:26,788 root INFO Epoch 2 Global steps: 20500 Train loss: 0.3718
ro_en Dev loss: 0.4044 r:0.8164
et_en Dev loss: 0.4034 r:0.7006
si_en Dev loss: 0.7507 r:0.6153
ne_en Dev loss: 0.4825 r:0.7498
ru_en Dev loss: 0.5037 r:0.7336
Current avg r:0.7231 Best avg r: 0.7322
18:49:43,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:49,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:55,306 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4026
ro_en Dev loss: 0.3663 r:0.8171
et_en Dev loss: 0.3879 r:0.7037
si_en Dev loss: 0.6917 r:0.6201
ne_en Dev loss: 0.4562 r:0.7518
ru_en Dev loss: 0.4781 r:0.7256
Current avg r:0.7237 Best avg r: 0.7322
18:55:12,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:31,185 root INFO 
id:ru_en cur r: 0.7560 best r: 0.7560
18:56:31,187 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:36,882 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ro_en.lang_agnost_mlp.dev.best.scores
18:57:36,889 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/et_en.lang_agnost_mlp.dev.best.scores
18:57:36,894 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/si_en.lang_agnost_mlp.dev.best.scores
18:57:36,899 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ne_en.lang_agnost_mlp.dev.best.scores
18:57:36,907 root INFO Saving best dev results to: experiments_xlmr/H1.1/mtl_sharing_tgt/run3/ru_en.lang_agnost_mlp.dev.best.scores
18:58:42,662 root INFO Epoch 2 Global steps: 21500 Train loss: 0.3827
ro_en Dev loss: 0.3842 r:0.8189
et_en Dev loss: 0.3965 r:0.7070
si_en Dev loss: 0.7077 r:0.6228
ne_en Dev loss: 0.3785 r:0.7595
ru_en Dev loss: 0.4234 r:0.7544
Current avg r:0.7325 Best avg r: 0.7325
19:01:59,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:05,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:11,243 root INFO Epoch 2 Global steps: 22000 Train loss: 0.3712
ro_en Dev loss: 0.4036 r:0.8084
et_en Dev loss: 0.4171 r:0.6931
si_en Dev loss: 0.8103 r:0.6033
ne_en Dev loss: 0.5509 r:0.7413
ru_en Dev loss: 0.5767 r:0.6876
Current avg r:0.7067 Best avg r: 0.7325
19:07:28,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:34,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:39,823 root INFO Epoch 2 Global steps: 22500 Train loss: 0.3725
ro_en Dev loss: 0.3473 r:0.8170
et_en Dev loss: 0.3812 r:0.7070
si_en Dev loss: 0.6889 r:0.6220
ne_en Dev loss: 0.4194 r:0.7553
ru_en Dev loss: 0.4900 r:0.7250
Current avg r:0.7253 Best avg r: 0.7325
19:12:57,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:03,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:09,207 root INFO Epoch 3 Global steps: 23000 Train loss: 0.3452
ro_en Dev loss: 0.3626 r:0.8150
et_en Dev loss: 0.4106 r:0.7084
si_en Dev loss: 0.5851 r:0.6250
ne_en Dev loss: 0.3776 r:0.7527
ru_en Dev loss: 0.4404 r:0.7419
Current avg r:0.7286 Best avg r: 0.7325
19:18:26,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:31,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:37,599 root INFO Epoch 3 Global steps: 23500 Train loss: 0.3448
ro_en Dev loss: 0.3684 r:0.8155
et_en Dev loss: 0.3956 r:0.6998
si_en Dev loss: 0.8713 r:0.6031
ne_en Dev loss: 0.5082 r:0.7535
ru_en Dev loss: 0.4980 r:0.7220
Current avg r:0.7188 Best avg r: 0.7325
19:23:54,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:00,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:05,965 root INFO Epoch 3 Global steps: 24000 Train loss: 0.3431
ro_en Dev loss: 0.3804 r:0.8130
et_en Dev loss: 0.4063 r:0.6994
si_en Dev loss: 0.7063 r:0.6182
ne_en Dev loss: 0.4061 r:0.7551
ru_en Dev loss: 0.4753 r:0.7205
Current avg r:0.7212 Best avg r: 0.7325
19:29:22,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:28,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:34,343 root INFO Epoch 3 Global steps: 24500 Train loss: 0.3454
ro_en Dev loss: 0.3701 r:0.8121
et_en Dev loss: 0.4079 r:0.7008
si_en Dev loss: 0.6619 r:0.6237
ne_en Dev loss: 0.4068 r:0.7528
ru_en Dev loss: 0.4970 r:0.7060
Current avg r:0.7191 Best avg r: 0.7325
19:34:51,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:57,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:02,922 root INFO Epoch 3 Global steps: 25000 Train loss: 0.3389
ro_en Dev loss: 0.3818 r:0.8131
et_en Dev loss: 0.4001 r:0.7007
si_en Dev loss: 0.7539 r:0.6157
ne_en Dev loss: 0.5134 r:0.7550
ru_en Dev loss: 0.4987 r:0.7207
Current avg r:0.7210 Best avg r: 0.7325
19:40:19,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:25,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:31,400 root INFO Epoch 3 Global steps: 25500 Train loss: 0.3344
ro_en Dev loss: 0.4266 r:0.8127
et_en Dev loss: 0.4320 r:0.6952
si_en Dev loss: 0.7716 r:0.6113
ne_en Dev loss: 0.4827 r:0.7518
ru_en Dev loss: 0.5563 r:0.7079
Current avg r:0.7158 Best avg r: 0.7325
19:45:48,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:53,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:59,715 root INFO Epoch 3 Global steps: 26000 Train loss: 0.3671
ro_en Dev loss: 0.3423 r:0.8155
et_en Dev loss: 0.3993 r:0.7009
si_en Dev loss: 0.6207 r:0.6188
ne_en Dev loss: 0.3997 r:0.7518
ru_en Dev loss: 0.4646 r:0.7105
Current avg r:0.7195 Best avg r: 0.7325
19:51:16,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:22,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:28,192 root INFO Epoch 3 Global steps: 26500 Train loss: 0.3338
ro_en Dev loss: 0.4065 r:0.8168
et_en Dev loss: 0.4177 r:0.7048
si_en Dev loss: 0.7865 r:0.6207
ne_en Dev loss: 0.4447 r:0.7555
ru_en Dev loss: 0.4967 r:0.7297
Current avg r:0.7255 Best avg r: 0.7325
19:56:45,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:51,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:56,703 root INFO Epoch 3 Global steps: 27000 Train loss: 0.3193
ro_en Dev loss: 0.3500 r:0.8155
et_en Dev loss: 0.3961 r:0.7011
si_en Dev loss: 0.7741 r:0.6077
ne_en Dev loss: 0.4507 r:0.7485
ru_en Dev loss: 0.5073 r:0.7016
Current avg r:0.7149 Best avg r: 0.7325
20:02:13,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:19,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:25,272 root INFO Epoch 3 Global steps: 27500 Train loss: 0.3534
ro_en Dev loss: 0.3439 r:0.8163
et_en Dev loss: 0.3825 r:0.7045
si_en Dev loss: 0.7196 r:0.6099
ne_en Dev loss: 0.4429 r:0.7498
ru_en Dev loss: 0.4721 r:0.7129
Current avg r:0.7187 Best avg r: 0.7325
20:07:42,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:48,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:53,830 root INFO Epoch 3 Global steps: 28000 Train loss: 0.3304
ro_en Dev loss: 0.4109 r:0.8078
et_en Dev loss: 0.4330 r:0.6932
si_en Dev loss: 0.8568 r:0.6030
ne_en Dev loss: 0.5049 r:0.7430
ru_en Dev loss: 0.5347 r:0.7152
Current avg r:0.7124 Best avg r: 0.7325
20:13:10,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:16,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:22,416 root INFO Epoch 3 Global steps: 28500 Train loss: 0.3276
ro_en Dev loss: 0.3973 r:0.8114
et_en Dev loss: 0.4132 r:0.6976
si_en Dev loss: 0.8348 r:0.6049
ne_en Dev loss: 0.4729 r:0.7460
ru_en Dev loss: 0.4804 r:0.7299
Current avg r:0.7179 Best avg r: 0.7325
20:18:39,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:45,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:50,989 root INFO Epoch 3 Global steps: 29000 Train loss: 0.3398
ro_en Dev loss: 0.3577 r:0.8154
et_en Dev loss: 0.4022 r:0.6957
si_en Dev loss: 0.7165 r:0.6066
ne_en Dev loss: 0.4610 r:0.7502
ru_en Dev loss: 0.5136 r:0.7104
Current avg r:0.7156 Best avg r: 0.7325
20:24:08,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:13,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:19,537 root INFO Epoch 3 Global steps: 29500 Train loss: 0.3401
ro_en Dev loss: 0.4185 r:0.8116
et_en Dev loss: 0.4468 r:0.6864
si_en Dev loss: 0.8496 r:0.6050
ne_en Dev loss: 0.4848 r:0.7466
ru_en Dev loss: 0.6013 r:0.6978
Current avg r:0.7095 Best avg r: 0.7325
20:29:35,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:41,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:47,253 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3369
ro_en Dev loss: 0.3069 r:0.8197
et_en Dev loss: 0.3942 r:0.7001
si_en Dev loss: 0.6571 r:0.6115
ne_en Dev loss: 0.4164 r:0.7522
ru_en Dev loss: 0.4360 r:0.7335
Current avg r:0.7234 Best avg r: 0.7325
20:35:05,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:11,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:17,169 root INFO Epoch 4 Global steps: 30500 Train loss: 0.3013
ro_en Dev loss: 0.3793 r:0.8093
et_en Dev loss: 0.4403 r:0.6860
si_en Dev loss: 0.7835 r:0.5974
ne_en Dev loss: 0.4688 r:0.7502
ru_en Dev loss: 0.4897 r:0.7197
Current avg r:0.7125 Best avg r: 0.7325
20:40:34,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:40,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:45,956 root INFO Epoch 4 Global steps: 31000 Train loss: 0.2982
ro_en Dev loss: 0.3433 r:0.8144
et_en Dev loss: 0.4209 r:0.6915
si_en Dev loss: 0.6794 r:0.6090
ne_en Dev loss: 0.4254 r:0.7524
ru_en Dev loss: 0.4624 r:0.7210
Current avg r:0.7177 Best avg r: 0.7325
20:46:03,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:08,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:14,623 root INFO Epoch 4 Global steps: 31500 Train loss: 0.2923
ro_en Dev loss: 0.3793 r:0.8122
et_en Dev loss: 0.4466 r:0.6869
si_en Dev loss: 0.8348 r:0.6003
ne_en Dev loss: 0.4965 r:0.7455
ru_en Dev loss: 0.4824 r:0.7222
Current avg r:0.7134 Best avg r: 0.7325
20:51:31,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:37,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:43,385 root INFO Epoch 4 Global steps: 32000 Train loss: 0.2957
ro_en Dev loss: 0.4457 r:0.8099
et_en Dev loss: 0.4356 r:0.6839
si_en Dev loss: 0.8590 r:0.5974
ne_en Dev loss: 0.4935 r:0.7464
ru_en Dev loss: 0.5460 r:0.7109
Current avg r:0.7097 Best avg r: 0.7325
20:57:00,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:06,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:12,250 root INFO Epoch 4 Global steps: 32500 Train loss: 0.2906
ro_en Dev loss: 0.4097 r:0.8122
et_en Dev loss: 0.4558 r:0.6846
si_en Dev loss: 0.7934 r:0.6077
ne_en Dev loss: 0.4482 r:0.7480
ru_en Dev loss: 0.4816 r:0.7258
Current avg r:0.7157 Best avg r: 0.7325
21:02:29,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:35,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:41,96 root INFO Epoch 4 Global steps: 33000 Train loss: 0.2852
ro_en Dev loss: 0.4075 r:0.8078
et_en Dev loss: 0.4289 r:0.6798
si_en Dev loss: 0.7743 r:0.6064
ne_en Dev loss: 0.4580 r:0.7422
ru_en Dev loss: 0.5216 r:0.7120
Current avg r:0.7097 Best avg r: 0.7325
21:07:58,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:04,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:09,959 root INFO Epoch 4 Global steps: 33500 Train loss: 0.2895
ro_en Dev loss: 0.3302 r:0.8153
et_en Dev loss: 0.4183 r:0.6884
si_en Dev loss: 0.6794 r:0.6092
ne_en Dev loss: 0.4171 r:0.7439
ru_en Dev loss: 0.4494 r:0.7192
Current avg r:0.7152 Best avg r: 0.7325
21:13:27,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:33,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:38,901 root INFO Epoch 4 Global steps: 34000 Train loss: 0.3064
ro_en Dev loss: 0.3737 r:0.8126
et_en Dev loss: 0.4313 r:0.6763
si_en Dev loss: 0.8331 r:0.5914
ne_en Dev loss: 0.4665 r:0.7419
ru_en Dev loss: 0.5547 r:0.6932
Current avg r:0.7031 Best avg r: 0.7325
21:18:56,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:02,56 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:07,827 root INFO Epoch 4 Global steps: 34500 Train loss: 0.2940
ro_en Dev loss: 0.3951 r:0.8112
et_en Dev loss: 0.4443 r:0.6843
si_en Dev loss: 0.8008 r:0.5981
ne_en Dev loss: 0.4344 r:0.7441
ru_en Dev loss: 0.5554 r:0.7009
Current avg r:0.7077 Best avg r: 0.7325
21:24:25,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:31,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:36,784 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3048
ro_en Dev loss: 0.3777 r:0.8117
et_en Dev loss: 0.4270 r:0.6830
si_en Dev loss: 0.8654 r:0.5891
ne_en Dev loss: 0.4950 r:0.7418
ru_en Dev loss: 0.5178 r:0.7056
Current avg r:0.7063 Best avg r: 0.7325
21:29:54,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:59,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:05,718 root INFO Epoch 4 Global steps: 35500 Train loss: 0.2868
ro_en Dev loss: 0.3977 r:0.8094
et_en Dev loss: 0.4296 r:0.6869
si_en Dev loss: 0.7763 r:0.5965
ne_en Dev loss: 0.4795 r:0.7453
ru_en Dev loss: 0.4841 r:0.7177
Current avg r:0.7111 Best avg r: 0.7325
21:35:23,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:28,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:34,632 root INFO Epoch 4 Global steps: 36000 Train loss: 0.2872
ro_en Dev loss: 0.3468 r:0.8145
et_en Dev loss: 0.4448 r:0.6859
si_en Dev loss: 0.7601 r:0.5940
ne_en Dev loss: 0.4474 r:0.7438
ru_en Dev loss: 0.4757 r:0.7150
Current avg r:0.7106 Best avg r: 0.7325
21:40:51,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:57,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:03,385 root INFO Epoch 4 Global steps: 36500 Train loss: 0.2903
ro_en Dev loss: 0.3958 r:0.8129
et_en Dev loss: 0.4805 r:0.6879
si_en Dev loss: 0.7551 r:0.6012
ne_en Dev loss: 0.4367 r:0.7406
ru_en Dev loss: 0.4675 r:0.7301
Current avg r:0.7145 Best avg r: 0.7325
21:46:20,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:26,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:32,149 root INFO Epoch 4 Global steps: 37000 Train loss: 0.2888
ro_en Dev loss: 0.4026 r:0.8117
et_en Dev loss: 0.4412 r:0.6788
si_en Dev loss: 0.8050 r:0.5908
ne_en Dev loss: 0.6119 r:0.7396
ru_en Dev loss: 0.5237 r:0.7026
Current avg r:0.7047 Best avg r: 0.7325
21:51:49,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:55,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:00,910 root INFO Epoch 4 Global steps: 37500 Train loss: 0.2754
ro_en Dev loss: 0.3382 r:0.8196
et_en Dev loss: 0.4209 r:0.6928
si_en Dev loss: 0.6956 r:0.6027
ne_en Dev loss: 0.4387 r:0.7406
ru_en Dev loss: 0.4501 r:0.7265
Current avg r:0.7164 Best avg r: 0.7325
21:57:19,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:25,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:30,951 root INFO Epoch 5 Global steps: 38000 Train loss: 0.2604
ro_en Dev loss: 0.3823 r:0.8171
et_en Dev loss: 0.4495 r:0.6869
si_en Dev loss: 0.7835 r:0.5901
ne_en Dev loss: 0.4877 r:0.7380
ru_en Dev loss: 0.4316 r:0.7420
Current avg r:0.7148 Best avg r: 0.7325
22:02:48,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:53,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:59,614 root INFO Epoch 5 Global steps: 38500 Train loss: 0.2571
ro_en Dev loss: 0.3720 r:0.8232
et_en Dev loss: 0.4311 r:0.6845
si_en Dev loss: 0.8376 r:0.5933
ne_en Dev loss: 0.5616 r:0.7378
ru_en Dev loss: 0.5417 r:0.7085
Current avg r:0.7095 Best avg r: 0.7325
22:08:16,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:22,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:27,781 root INFO Epoch 5 Global steps: 39000 Train loss: 0.2692
ro_en Dev loss: 0.3577 r:0.8201
et_en Dev loss: 0.4208 r:0.6805
si_en Dev loss: 0.8238 r:0.5823
ne_en Dev loss: 0.4968 r:0.7328
ru_en Dev loss: 0.4947 r:0.7170
Current avg r:0.7065 Best avg r: 0.7325
22:13:44,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:50,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:55,907 root INFO Epoch 5 Global steps: 39500 Train loss: 0.2409
ro_en Dev loss: 0.3494 r:0.8173
et_en Dev loss: 0.4361 r:0.6836
si_en Dev loss: 0.7136 r:0.5907
ne_en Dev loss: 0.4557 r:0.7317
ru_en Dev loss: 0.4767 r:0.7246
Current avg r:0.7096 Best avg r: 0.7325
22:19:12,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:18,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:21:23,906 root INFO Epoch 5 Global steps: 40000 Train loss: 0.2424
ro_en Dev loss: 0.3658 r:0.8176
et_en Dev loss: 0.4377 r:0.6817
si_en Dev loss: 0.8210 r:0.5905
ne_en Dev loss: 0.4544 r:0.7381
ru_en Dev loss: 0.4844 r:0.7210
Current avg r:0.7098 Best avg r: 0.7325
22:24:40,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:46,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:52,66 root INFO Epoch 5 Global steps: 40500 Train loss: 0.2590
ro_en Dev loss: 0.3404 r:0.8225
et_en Dev loss: 0.4256 r:0.6869
si_en Dev loss: 0.7589 r:0.5938
ne_en Dev loss: 0.4656 r:0.7418
ru_en Dev loss: 0.4472 r:0.7377
Current avg r:0.7165 Best avg r: 0.7325
22:30:08,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:14,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:20,289 root INFO Epoch 5 Global steps: 41000 Train loss: 0.2448
ro_en Dev loss: 0.3525 r:0.8168
et_en Dev loss: 0.4395 r:0.6831
si_en Dev loss: 0.8563 r:0.5755
ne_en Dev loss: 0.4929 r:0.7335
ru_en Dev loss: 0.4670 r:0.7264
Current avg r:0.7071 Best avg r: 0.7325
22:35:37,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:42,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:48,580 root INFO Epoch 5 Global steps: 41500 Train loss: 0.2545
ro_en Dev loss: 0.3604 r:0.8196
et_en Dev loss: 0.4377 r:0.6882
si_en Dev loss: 0.7854 r:0.5854
ne_en Dev loss: 0.4585 r:0.7404
ru_en Dev loss: 0.4406 r:0.7391
Current avg r:0.7145 Best avg r: 0.7325
22:41:05,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:11,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:43:16,848 root INFO Epoch 5 Global steps: 42000 Train loss: 0.2425
ro_en Dev loss: 0.3912 r:0.8141
et_en Dev loss: 0.4459 r:0.6827
si_en Dev loss: 0.7657 r:0.5864
ne_en Dev loss: 0.5210 r:0.7368
ru_en Dev loss: 0.4625 r:0.7346
Current avg r:0.7109 Best avg r: 0.7325
22:46:33,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:39,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:48:45,86 root INFO Epoch 5 Global steps: 42500 Train loss: 0.2361
ro_en Dev loss: 0.4091 r:0.8146
et_en Dev loss: 0.4615 r:0.6739
si_en Dev loss: 0.9452 r:0.5746
ne_en Dev loss: 0.5778 r:0.7389
ru_en Dev loss: 0.5192 r:0.7190
Current avg r:0.7042 Best avg r: 0.7325
22:52:01,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:07,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:13,179 root INFO Epoch 5 Global steps: 43000 Train loss: 0.2375
ro_en Dev loss: 0.3705 r:0.8159
et_en Dev loss: 0.4279 r:0.6747
si_en Dev loss: 0.9133 r:0.5677
ne_en Dev loss: 0.6176 r:0.7412
ru_en Dev loss: 0.5459 r:0.6950
Current avg r:0.6989 Best avg r: 0.7325
22:57:30,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:35,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:41,533 root INFO Epoch 5 Global steps: 43500 Train loss: 0.2458
ro_en Dev loss: 0.3860 r:0.8154
et_en Dev loss: 0.4540 r:0.6714
si_en Dev loss: 0.8594 r:0.5710
ne_en Dev loss: 0.5197 r:0.7365
ru_en Dev loss: 0.5529 r:0.6974
Current avg r:0.6983 Best avg r: 0.7325
23:02:58,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:04,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:09,780 root INFO Epoch 5 Global steps: 44000 Train loss: 0.2464
ro_en Dev loss: 0.3557 r:0.8210
et_en Dev loss: 0.4349 r:0.6778
si_en Dev loss: 0.8680 r:0.5767
ne_en Dev loss: 0.5823 r:0.7389
ru_en Dev loss: 0.4930 r:0.7176
Current avg r:0.7064 Best avg r: 0.7325
23:08:26,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:09:32,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:37,969 root INFO Epoch 5 Global steps: 44500 Train loss: 0.2390
ro_en Dev loss: 0.3370 r:0.8221
et_en Dev loss: 0.4324 r:0.6800
si_en Dev loss: 0.7911 r:0.5829
ne_en Dev loss: 0.4845 r:0.7428
ru_en Dev loss: 0.4918 r:0.7125
Current avg r:0.7081 Best avg r: 0.7325
23:13:54,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:00,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:06,212 root INFO Epoch 5 Global steps: 45000 Train loss: 0.2375
ro_en Dev loss: 0.3207 r:0.8220
et_en Dev loss: 0.4398 r:0.6798
si_en Dev loss: 0.7427 r:0.5858
ne_en Dev loss: 0.4430 r:0.7368
ru_en Dev loss: 0.4637 r:0.7154
Current avg r:0.7079 Best avg r: 0.7325
23:19:24,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:29,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:21:35,704 root INFO Epoch 6 Global steps: 45500 Train loss: 0.2150
ro_en Dev loss: 0.3773 r:0.8161
et_en Dev loss: 0.4524 r:0.6789
si_en Dev loss: 0.8620 r:0.5732
ne_en Dev loss: 0.4912 r:0.7327
ru_en Dev loss: 0.4758 r:0.7218
Current avg r:0.7046 Best avg r: 0.7325
23:24:52,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:58,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:03,838 root INFO Epoch 6 Global steps: 46000 Train loss: 0.2060
ro_en Dev loss: 0.3917 r:0.8177
et_en Dev loss: 0.4623 r:0.6732
si_en Dev loss: 0.9068 r:0.5719
ne_en Dev loss: 0.5794 r:0.7304
ru_en Dev loss: 0.5250 r:0.7114
Current avg r:0.7009 Best avg r: 0.7325
23:30:20,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:26,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:32:31,934 root INFO Epoch 6 Global steps: 46500 Train loss: 0.2240
ro_en Dev loss: 0.3624 r:0.8165
et_en Dev loss: 0.4513 r:0.6665
si_en Dev loss: 0.8872 r:0.5636
ne_en Dev loss: 0.5181 r:0.7302
ru_en Dev loss: 0.4947 r:0.7119
Current avg r:0.6977 Best avg r: 0.7325
23:35:48,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:54,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:00,64 root INFO Epoch 6 Global steps: 47000 Train loss: 0.2031
ro_en Dev loss: 0.4129 r:0.8119
et_en Dev loss: 0.4735 r:0.6684
si_en Dev loss: 0.9648 r:0.5625
ne_en Dev loss: 0.5921 r:0.7255
ru_en Dev loss: 0.5774 r:0.6947
Current avg r:0.6926 Best avg r: 0.7325
23:41:16,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:22,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:28,45 root INFO Epoch 6 Global steps: 47500 Train loss: 0.2084
ro_en Dev loss: 0.3626 r:0.8181
et_en Dev loss: 0.4503 r:0.6839
si_en Dev loss: 0.8068 r:0.5772
ne_en Dev loss: 0.4782 r:0.7319
ru_en Dev loss: 0.5029 r:0.7119
Current avg r:0.7046 Best avg r: 0.7325
23:46:44,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:50,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:55,993 root INFO Epoch 6 Global steps: 48000 Train loss: 0.2043
ro_en Dev loss: 0.3713 r:0.8158
et_en Dev loss: 0.4544 r:0.6821
si_en Dev loss: 0.8659 r:0.5713
ne_en Dev loss: 0.5853 r:0.7335
ru_en Dev loss: 0.4986 r:0.7171
Current avg r:0.7039 Best avg r: 0.7325
23:52:12,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:53:18,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:54:24,7 root INFO Epoch 6 Global steps: 48500 Train loss: 0.2061
ro_en Dev loss: 0.3878 r:0.8161
et_en Dev loss: 0.4643 r:0.6770
si_en Dev loss: 0.8640 r:0.5751
ne_en Dev loss: 0.5120 r:0.7277
ru_en Dev loss: 0.5291 r:0.7148
Current avg r:0.7022 Best avg r: 0.7325
23:57:40,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:46,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:51,956 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2089
ro_en Dev loss: 0.4004 r:0.8114
et_en Dev loss: 0.4685 r:0.6743
si_en Dev loss: 0.9248 r:0.5660
ne_en Dev loss: 0.5867 r:0.7279
ru_en Dev loss: 0.5283 r:0.7134
Current avg r:0.6986 Best avg r: 0.7325
00:03:08,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:14,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:19,997 root INFO Epoch 6 Global steps: 49500 Train loss: 0.2117
ro_en Dev loss: 0.3725 r:0.8097
et_en Dev loss: 0.4642 r:0.6746
si_en Dev loss: 0.7907 r:0.5748
ne_en Dev loss: 0.5173 r:0.7274
ru_en Dev loss: 0.4489 r:0.7301
Current avg r:0.7033 Best avg r: 0.7325
00:08:36,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:42,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:47,959 root INFO Epoch 6 Global steps: 50000 Train loss: 0.2023
ro_en Dev loss: 0.4467 r:0.8038
et_en Dev loss: 0.4922 r:0.6524
si_en Dev loss: 0.9667 r:0.5589
ne_en Dev loss: 0.6963 r:0.7245
ru_en Dev loss: 0.5405 r:0.7030
Current avg r:0.6885 Best avg r: 0.7325
00:14:04,602 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:15:10,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:16:16,26 root INFO Epoch 6 Global steps: 50500 Train loss: 0.2182
ro_en Dev loss: 0.3910 r:0.8072
et_en Dev loss: 0.4841 r:0.6625
si_en Dev loss: 0.9030 r:0.5578
ne_en Dev loss: 0.4988 r:0.7303
ru_en Dev loss: 0.5298 r:0.6949
Current avg r:0.6905 Best avg r: 0.7325
00:19:32,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:38,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:21:44,74 root INFO Epoch 6 Global steps: 51000 Train loss: 0.2147
ro_en Dev loss: 0.4222 r:0.8113
et_en Dev loss: 0.4639 r:0.6689
si_en Dev loss: 0.9207 r:0.5574
ne_en Dev loss: 0.6326 r:0.7162
ru_en Dev loss: 0.5637 r:0.6844
Current avg r:0.6877 Best avg r: 0.7325
00:25:00,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:06,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:11,987 root INFO Epoch 6 Global steps: 51500 Train loss: 0.2248
ro_en Dev loss: 0.4217 r:0.8086
et_en Dev loss: 0.4550 r:0.6650
si_en Dev loss: 1.0806 r:0.5517
ne_en Dev loss: 0.6209 r:0.7265
ru_en Dev loss: 0.5793 r:0.6719
Current avg r:0.6847 Best avg r: 0.7325
00:30:28,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:34,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:40,93 root INFO Epoch 6 Global steps: 52000 Train loss: 0.2145
ro_en Dev loss: 0.3663 r:0.8117
et_en Dev loss: 0.4545 r:0.6661
si_en Dev loss: 0.8708 r:0.5657
ne_en Dev loss: 0.5291 r:0.7272
ru_en Dev loss: 0.5283 r:0.6844
Current avg r:0.6910 Best avg r: 0.7325
00:35:56,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:02,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:08,139 root INFO Epoch 6 Global steps: 52500 Train loss: 0.1995
ro_en Dev loss: 0.3923 r:0.8071
et_en Dev loss: 0.4443 r:0.6651
si_en Dev loss: 0.9118 r:0.5602
ne_en Dev loss: 0.5621 r:0.7278
ru_en Dev loss: 0.5516 r:0.6864
Current avg r:0.6893 Best avg r: 0.7325
00:41:25,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:31,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:37,210 root INFO Epoch 7 Global steps: 53000 Train loss: 0.1887
ro_en Dev loss: 0.3883 r:0.8085
et_en Dev loss: 0.4718 r:0.6618
si_en Dev loss: 0.8843 r:0.5562
ne_en Dev loss: 0.5625 r:0.7225
ru_en Dev loss: 0.5088 r:0.7043
Current avg r:0.6906 Best avg r: 0.7325
00:46:53,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:47:59,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:05,266 root INFO Epoch 7 Global steps: 53500 Train loss: 0.1905
ro_en Dev loss: 0.3656 r:0.8121
et_en Dev loss: 0.4478 r:0.6667
si_en Dev loss: 0.8420 r:0.5617
ne_en Dev loss: 0.4737 r:0.7262
ru_en Dev loss: 0.4943 r:0.7000
Current avg r:0.6933 Best avg r: 0.7325
00:52:22,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:27,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:33,378 root INFO Epoch 7 Global steps: 54000 Train loss: 0.1883
ro_en Dev loss: 0.3976 r:0.8143
et_en Dev loss: 0.4752 r:0.6727
si_en Dev loss: 0.9301 r:0.5638
ne_en Dev loss: 0.5518 r:0.7282
ru_en Dev loss: 0.5218 r:0.7048
Current avg r:0.6968 Best avg r: 0.7325
00:57:50,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:55,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:00:01,463 root INFO Epoch 7 Global steps: 54500 Train loss: 0.1800
ro_en Dev loss: 0.4526 r:0.8058
et_en Dev loss: 0.4989 r:0.6569
si_en Dev loss: 1.0026 r:0.5518
ne_en Dev loss: 0.7089 r:0.7221
ru_en Dev loss: 0.6151 r:0.6799
Current avg r:0.6833 Best avg r: 0.7325
01:03:18,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:23,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:29,561 root INFO Epoch 7 Global steps: 55000 Train loss: 0.1815
ro_en Dev loss: 0.4021 r:0.8147
et_en Dev loss: 0.4677 r:0.6698
si_en Dev loss: 0.8522 r:0.5689
ne_en Dev loss: 0.5409 r:0.7226
ru_en Dev loss: 0.5018 r:0.7140
Current avg r:0.6980 Best avg r: 0.7325
01:08:46,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:51,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:57,621 root INFO Epoch 7 Global steps: 55500 Train loss: 0.1842
ro_en Dev loss: 0.4016 r:0.8117
et_en Dev loss: 0.4827 r:0.6665
si_en Dev loss: 0.8850 r:0.5607
ne_en Dev loss: 0.5545 r:0.7271
ru_en Dev loss: 0.5265 r:0.6949
Current avg r:0.6922 Best avg r: 0.7325
01:14:14,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:20,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:25,767 root INFO Epoch 7 Global steps: 56000 Train loss: 0.1901
ro_en Dev loss: 0.4088 r:0.8097
et_en Dev loss: 0.4876 r:0.6629
si_en Dev loss: 0.9331 r:0.5571
ne_en Dev loss: 0.5572 r:0.7208
ru_en Dev loss: 0.5306 r:0.7022
Current avg r:0.6906 Best avg r: 0.7325
01:19:42,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:20:48,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:21:53,849 root INFO Epoch 7 Global steps: 56500 Train loss: 0.1878
ro_en Dev loss: 0.4410 r:0.8083
et_en Dev loss: 0.4841 r:0.6644
si_en Dev loss: 0.9127 r:0.5621
ne_en Dev loss: 0.6306 r:0.7231
ru_en Dev loss: 0.5622 r:0.6902
Current avg r:0.6896 Best avg r: 0.7325
01:25:10,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:26:16,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:27:22,47 root INFO Epoch 7 Global steps: 57000 Train loss: 0.1836
ro_en Dev loss: 0.3290 r:0.8182
et_en Dev loss: 0.4345 r:0.6856
si_en Dev loss: 0.7122 r:0.5874
ne_en Dev loss: 0.4213 r:0.7322
ru_en Dev loss: 0.4289 r:0.7277
Current avg r:0.7102 Best avg r: 0.7325
01:30:38,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:44,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:50,458 root INFO Epoch 7 Global steps: 57500 Train loss: 0.1904
ro_en Dev loss: 0.3458 r:0.8153
et_en Dev loss: 0.4342 r:0.6712
si_en Dev loss: 0.8197 r:0.5759
ne_en Dev loss: 0.6751 r:0.7220
ru_en Dev loss: 0.4910 r:0.6978
Current avg r:0.6964 Best avg r: 0.7325
01:36:07,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:37:13,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:19,166 root INFO Epoch 7 Global steps: 58000 Train loss: 0.1840
ro_en Dev loss: 0.3664 r:0.8123
et_en Dev loss: 0.4530 r:0.6694
si_en Dev loss: 0.8626 r:0.5650
ne_en Dev loss: 0.5889 r:0.7225
ru_en Dev loss: 0.5128 r:0.7014
Current avg r:0.6941 Best avg r: 0.7325
01:41:36,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:41,975 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:47,699 root INFO Epoch 7 Global steps: 58500 Train loss: 0.1809
ro_en Dev loss: 0.3773 r:0.8117
et_en Dev loss: 0.4669 r:0.6745
si_en Dev loss: 0.8683 r:0.5620
ne_en Dev loss: 0.5835 r:0.7213
ru_en Dev loss: 0.5031 r:0.6995
Current avg r:0.6938 Best avg r: 0.7325
01:47:04,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:48:10,512 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:49:16,215 root INFO Epoch 7 Global steps: 59000 Train loss: 0.1907
ro_en Dev loss: 0.4122 r:0.8102
et_en Dev loss: 0.4913 r:0.6664
si_en Dev loss: 0.9459 r:0.5566
ne_en Dev loss: 0.5250 r:0.7185
ru_en Dev loss: 0.5363 r:0.7028
Current avg r:0.6909 Best avg r: 0.7325
01:52:33,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:53:39,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:54:44,760 root INFO Epoch 7 Global steps: 59500 Train loss: 0.1716
ro_en Dev loss: 0.3750 r:0.8124
et_en Dev loss: 0.4775 r:0.6746
si_en Dev loss: 0.8022 r:0.5676
ne_en Dev loss: 0.5208 r:0.7151
ru_en Dev loss: 0.4692 r:0.7240
Current avg r:0.6988 Best avg r: 0.7325
01:58:01,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:59:07,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:13,618 root INFO Epoch 7 Global steps: 60000 Train loss: 0.1715
ro_en Dev loss: 0.3591 r:0.8164
et_en Dev loss: 0.4876 r:0.6735
si_en Dev loss: 0.7760 r:0.5680
ne_en Dev loss: 0.5108 r:0.7128
ru_en Dev loss: 0.4631 r:0.7267
Current avg r:0.6995 Best avg r: 0.7325
02:03:34,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:04:40,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:05:46,801 root INFO Epoch 8 Global steps: 60500 Train loss: 0.1666
ro_en Dev loss: 0.4043 r:0.8154
et_en Dev loss: 0.4616 r:0.6606
si_en Dev loss: 0.9260 r:0.5529
ne_en Dev loss: 0.6355 r:0.7163
ru_en Dev loss: 0.5572 r:0.7004
Current avg r:0.6891 Best avg r: 0.7325
02:09:05,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:10:12,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:11:18,378 root INFO Epoch 8 Global steps: 61000 Train loss: 0.1743
ro_en Dev loss: 0.3528 r:0.8164
et_en Dev loss: 0.4467 r:0.6749
si_en Dev loss: 0.8289 r:0.5605
ne_en Dev loss: 0.5525 r:0.7160
ru_en Dev loss: 0.4733 r:0.7182
Current avg r:0.6972 Best avg r: 0.7325
02:14:37,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:15:43,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:16:49,656 root INFO Epoch 8 Global steps: 61500 Train loss: 0.1570
ro_en Dev loss: 0.3640 r:0.8113
et_en Dev loss: 0.4450 r:0.6688
si_en Dev loss: 0.8647 r:0.5584
ne_en Dev loss: 0.5600 r:0.7101
ru_en Dev loss: 0.4948 r:0.7069
Current avg r:0.6911 Best avg r: 0.7325
02:20:08,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:15,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:21,455 root INFO Epoch 8 Global steps: 62000 Train loss: 0.1623
ro_en Dev loss: 0.4267 r:0.8089
et_en Dev loss: 0.4852 r:0.6712
si_en Dev loss: 0.9081 r:0.5610
ne_en Dev loss: 0.6059 r:0.7201
ru_en Dev loss: 0.5495 r:0.6971
Current avg r:0.6916 Best avg r: 0.7325
02:25:40,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:26:46,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:52,650 root INFO Epoch 8 Global steps: 62500 Train loss: 0.1586
ro_en Dev loss: 0.3983 r:0.8098
et_en Dev loss: 0.4579 r:0.6714
si_en Dev loss: 0.8794 r:0.5553
ne_en Dev loss: 0.5681 r:0.7161
ru_en Dev loss: 0.4963 r:0.7111
Current avg r:0.6927 Best avg r: 0.7325
02:31:10,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:32:16,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:33:22,373 root INFO Epoch 8 Global steps: 63000 Train loss: 0.1548
ro_en Dev loss: 0.3921 r:0.8060
et_en Dev loss: 0.4703 r:0.6713
si_en Dev loss: 0.8755 r:0.5504
ne_en Dev loss: 0.5481 r:0.7177
ru_en Dev loss: 0.4417 r:0.7261
Current avg r:0.6943 Best avg r: 0.7325
02:36:40,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:46,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:52,199 root INFO Epoch 8 Global steps: 63500 Train loss: 0.1644
ro_en Dev loss: 0.4379 r:0.8052
et_en Dev loss: 0.4742 r:0.6684
si_en Dev loss: 1.0777 r:0.5392
ne_en Dev loss: 0.7262 r:0.7124
ru_en Dev loss: 0.5698 r:0.6915
Current avg r:0.6833 Best avg r: 0.7325
02:42:10,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:16,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:22,32 root INFO Epoch 8 Global steps: 64000 Train loss: 0.1602
ro_en Dev loss: 0.3872 r:0.8056
et_en Dev loss: 0.4800 r:0.6833
si_en Dev loss: 0.8686 r:0.5540
ne_en Dev loss: 0.5718 r:0.7149
ru_en Dev loss: 0.4808 r:0.7159
Current avg r:0.6948 Best avg r: 0.7325
02:47:39,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:48:45,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:49:51,235 root INFO Epoch 8 Global steps: 64500 Train loss: 0.1648
ro_en Dev loss: 0.4045 r:0.8073
et_en Dev loss: 0.4488 r:0.6648
si_en Dev loss: 0.9274 r:0.5450
ne_en Dev loss: 0.6825 r:0.7205
ru_en Dev loss: 0.5223 r:0.7000
Current avg r:0.6875 Best avg r: 0.7325
02:53:08,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:54:14,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:55:20,742 root INFO Epoch 8 Global steps: 65000 Train loss: 0.1601
ro_en Dev loss: 0.3864 r:0.8075
et_en Dev loss: 0.4809 r:0.6746
si_en Dev loss: 0.8812 r:0.5560
ne_en Dev loss: 0.5228 r:0.7151
ru_en Dev loss: 0.4995 r:0.7090
Current avg r:0.6924 Best avg r: 0.7325
02:58:38,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:59:44,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:50,513 root INFO Epoch 8 Global steps: 65500 Train loss: 0.1575
ro_en Dev loss: 0.3449 r:0.8140
et_en Dev loss: 0.4488 r:0.6787
si_en Dev loss: 0.8051 r:0.5557
ne_en Dev loss: 0.4934 r:0.7172
ru_en Dev loss: 0.4607 r:0.7197
Current avg r:0.6971 Best avg r: 0.7325
03:04:09,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:05:16,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:06:22,321 root INFO Epoch 8 Global steps: 66000 Train loss: 0.1680
ro_en Dev loss: 0.3918 r:0.8100
et_en Dev loss: 0.4677 r:0.6737
si_en Dev loss: 0.9294 r:0.5495
ne_en Dev loss: 0.5915 r:0.7151
ru_en Dev loss: 0.4948 r:0.7165
Current avg r:0.6930 Best avg r: 0.7325
03:09:41,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:47,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:54,32 root INFO Epoch 8 Global steps: 66500 Train loss: 0.1582
ro_en Dev loss: 0.4334 r:0.8083
et_en Dev loss: 0.4867 r:0.6754
si_en Dev loss: 0.9375 r:0.5570
ne_en Dev loss: 0.5739 r:0.7198
ru_en Dev loss: 0.5366 r:0.7166
Current avg r:0.6954 Best avg r: 0.7325
03:15:13,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:16:19,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:17:25,493 root INFO Epoch 8 Global steps: 67000 Train loss: 0.1528
ro_en Dev loss: 0.4576 r:0.8084
et_en Dev loss: 0.5133 r:0.6562
si_en Dev loss: 1.0375 r:0.5431
ne_en Dev loss: 0.6952 r:0.7160
ru_en Dev loss: 0.5367 r:0.7176
Current avg r:0.6883 Best avg r: 0.7325
03:20:44,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:50,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:56,612 root INFO Epoch 8 Global steps: 67500 Train loss: 0.1527
ro_en Dev loss: 0.3938 r:0.8100
et_en Dev loss: 0.4729 r:0.6725
si_en Dev loss: 0.8818 r:0.5630
ne_en Dev loss: 0.5502 r:0.7210
ru_en Dev loss: 0.5102 r:0.7114
Current avg r:0.6956 Best avg r: 0.7325
03:26:16,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:27:22,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:28:27,971 root INFO Epoch 9 Global steps: 68000 Train loss: 0.1339
ro_en Dev loss: 0.3949 r:0.8098
et_en Dev loss: 0.4805 r:0.6554
si_en Dev loss: 0.9291 r:0.5542
ne_en Dev loss: 0.6706 r:0.7141
ru_en Dev loss: 0.4707 r:0.7269
Current avg r:0.6921 Best avg r: 0.7325
03:31:45,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:32:51,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:33:57,178 root INFO Epoch 9 Global steps: 68500 Train loss: 0.1380
ro_en Dev loss: 0.4191 r:0.8094
et_en Dev loss: 0.4941 r:0.6671
si_en Dev loss: 0.9522 r:0.5577
ne_en Dev loss: 0.5912 r:0.7190
ru_en Dev loss: 0.5447 r:0.7163
Current avg r:0.6939 Best avg r: 0.7325
03:37:14,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:38:20,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:39:26,398 root INFO Epoch 9 Global steps: 69000 Train loss: 0.1385
ro_en Dev loss: 0.4009 r:0.8092
et_en Dev loss: 0.4645 r:0.6714
si_en Dev loss: 0.9667 r:0.5515
ne_en Dev loss: 0.6302 r:0.7113
ru_en Dev loss: 0.5289 r:0.7033
Current avg r:0.6893 Best avg r: 0.7325
03:42:43,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:49,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:44:55,653 root INFO Epoch 9 Global steps: 69500 Train loss: 0.1518
ro_en Dev loss: 0.4351 r:0.8020
et_en Dev loss: 0.4791 r:0.6530
si_en Dev loss: 0.9981 r:0.5458
ne_en Dev loss: 0.6852 r:0.7170
ru_en Dev loss: 0.5576 r:0.6978
Current avg r:0.6831 Best avg r: 0.7325
03:48:13,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:49:19,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:50:25,707 root INFO Epoch 9 Global steps: 70000 Train loss: 0.1445
ro_en Dev loss: 0.3890 r:0.8086
et_en Dev loss: 0.4702 r:0.6619
si_en Dev loss: 0.8617 r:0.5522
ne_en Dev loss: 0.6479 r:0.7081
ru_en Dev loss: 0.5031 r:0.7150
Current avg r:0.6891 Best avg r: 0.7325
03:53:43,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:54:49,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:55:55,125 root INFO Epoch 9 Global steps: 70500 Train loss: 0.1408
ro_en Dev loss: 0.3845 r:0.8138
et_en Dev loss: 0.4714 r:0.6730
si_en Dev loss: 0.8685 r:0.5541
ne_en Dev loss: 0.5900 r:0.7075
ru_en Dev loss: 0.4846 r:0.7272
Current avg r:0.6951 Best avg r: 0.7325
03:59:13,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:00:19,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:01:25,779 root INFO Epoch 9 Global steps: 71000 Train loss: 0.1355
ro_en Dev loss: 0.3848 r:0.8063
et_en Dev loss: 0.4717 r:0.6536
si_en Dev loss: 0.9375 r:0.5379
ne_en Dev loss: 0.6112 r:0.7110
ru_en Dev loss: 0.4876 r:0.7074
Current avg r:0.6832 Best avg r: 0.7325
04:04:44,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:05:50,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:06:56,995 root INFO Epoch 9 Global steps: 71500 Train loss: 0.1414
ro_en Dev loss: 0.3844 r:0.8132
et_en Dev loss: 0.4530 r:0.6625
si_en Dev loss: 0.9236 r:0.5418
ne_en Dev loss: 0.4937 r:0.7070
ru_en Dev loss: 0.4933 r:0.7209
Current avg r:0.6891 Best avg r: 0.7325
04:10:15,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:11:22,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:12:28,405 root INFO Epoch 9 Global steps: 72000 Train loss: 0.1338
ro_en Dev loss: 0.3693 r:0.8104
et_en Dev loss: 0.4476 r:0.6591
si_en Dev loss: 0.9048 r:0.5436
ne_en Dev loss: 0.6590 r:0.7107
ru_en Dev loss: 0.5034 r:0.7037
Current avg r:0.6855 Best avg r: 0.7325
04:15:47,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:16:53,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:17:59,814 root INFO Epoch 9 Global steps: 72500 Train loss: 0.1391
ro_en Dev loss: 0.3704 r:0.8101
et_en Dev loss: 0.4759 r:0.6675
si_en Dev loss: 0.8595 r:0.5507
ne_en Dev loss: 0.5852 r:0.7149
ru_en Dev loss: 0.4750 r:0.7202
Current avg r:0.6927 Best avg r: 0.7325
04:21:18,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:22:24,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:30,600 root INFO Epoch 9 Global steps: 73000 Train loss: 0.1371
ro_en Dev loss: 0.3746 r:0.8123
et_en Dev loss: 0.4536 r:0.6614
si_en Dev loss: 0.8924 r:0.5491
ne_en Dev loss: 0.6236 r:0.7089
ru_en Dev loss: 0.4812 r:0.7279
Current avg r:0.6919 Best avg r: 0.7325
04:26:48,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:27:54,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:29:00,364 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1398
ro_en Dev loss: 0.3976 r:0.8081
et_en Dev loss: 0.4941 r:0.6631
si_en Dev loss: 0.8869 r:0.5466
ne_en Dev loss: 0.5729 r:0.7013
ru_en Dev loss: 0.5070 r:0.7154
Current avg r:0.6869 Best avg r: 0.7325
04:32:17,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:33:23,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:34:29,574 root INFO Epoch 9 Global steps: 74000 Train loss: 0.1348
ro_en Dev loss: 0.3862 r:0.8114
et_en Dev loss: 0.4764 r:0.6591
si_en Dev loss: 0.9580 r:0.5413
ne_en Dev loss: 0.6348 r:0.7142
ru_en Dev loss: 0.5445 r:0.7027
Current avg r:0.6857 Best avg r: 0.7325
04:37:47,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:38:53,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:39:59,473 root INFO Epoch 9 Global steps: 74500 Train loss: 0.1355
ro_en Dev loss: 0.3829 r:0.8131
et_en Dev loss: 0.4811 r:0.6704
si_en Dev loss: 0.9136 r:0.5515
ne_en Dev loss: 0.5712 r:0.7119
ru_en Dev loss: 0.4567 r:0.7360
Current avg r:0.6966 Best avg r: 0.7325
04:43:17,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:23,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:29,254 root INFO Epoch 9 Global steps: 75000 Train loss: 0.1293
ro_en Dev loss: 0.3597 r:0.8133
et_en Dev loss: 0.4525 r:0.6664
si_en Dev loss: 0.8644 r:0.5504
ne_en Dev loss: 0.5115 r:0.7140
ru_en Dev loss: 0.4519 r:0.7282
Current avg r:0.6945 Best avg r: 0.7325
04:48:48,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:49:54,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:00,392 root INFO Epoch 10 Global steps: 75500 Train loss: 0.1211
ro_en Dev loss: 0.4057 r:0.8106
et_en Dev loss: 0.4670 r:0.6618
si_en Dev loss: 0.9349 r:0.5462
ne_en Dev loss: 0.5544 r:0.7187
ru_en Dev loss: 0.5055 r:0.7166
Current avg r:0.6908 Best avg r: 0.7325
04:54:18,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:55:25,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:56:31,323 root INFO Epoch 10 Global steps: 76000 Train loss: 0.1220
ro_en Dev loss: 0.3731 r:0.8150
et_en Dev loss: 0.4666 r:0.6654
si_en Dev loss: 0.8900 r:0.5504
ne_en Dev loss: 0.5808 r:0.7136
ru_en Dev loss: 0.4939 r:0.7292
Current avg r:0.6947 Best avg r: 0.7325
04:59:50,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:00:56,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:02:02,713 root INFO Epoch 10 Global steps: 76500 Train loss: 0.1290
ro_en Dev loss: 0.3532 r:0.8147
et_en Dev loss: 0.4680 r:0.6705
si_en Dev loss: 0.8449 r:0.5566
ne_en Dev loss: 0.5355 r:0.7147
ru_en Dev loss: 0.4834 r:0.7243
Current avg r:0.6962 Best avg r: 0.7325
05:05:21,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:27,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:07:33,975 root INFO Epoch 10 Global steps: 77000 Train loss: 0.1223
ro_en Dev loss: 0.4057 r:0.8132
et_en Dev loss: 0.4929 r:0.6767
si_en Dev loss: 0.9227 r:0.5531
ne_en Dev loss: 0.5859 r:0.7118
ru_en Dev loss: 0.5089 r:0.7271
Current avg r:0.6964 Best avg r: 0.7325
05:10:52,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:11:59,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:13:05,255 root INFO Epoch 10 Global steps: 77500 Train loss: 0.1195
ro_en Dev loss: 0.3917 r:0.8118
et_en Dev loss: 0.4515 r:0.6712
si_en Dev loss: 0.8640 r:0.5536
ne_en Dev loss: 0.5582 r:0.7174
ru_en Dev loss: 0.4535 r:0.7331
Current avg r:0.6974 Best avg r: 0.7325
05:16:24,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:30,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:36,26 root INFO Epoch 10 Global steps: 78000 Train loss: 0.1259
ro_en Dev loss: 0.3857 r:0.8091
et_en Dev loss: 0.4814 r:0.6647
si_en Dev loss: 0.8731 r:0.5504
ne_en Dev loss: 0.5724 r:0.7146
ru_en Dev loss: 0.4840 r:0.7225
Current avg r:0.6923 Best avg r: 0.7325
05:21:53,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:22:59,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:24:05,358 root INFO Epoch 10 Global steps: 78500 Train loss: 0.1260
ro_en Dev loss: 0.4251 r:0.8075
et_en Dev loss: 0.4975 r:0.6535
si_en Dev loss: 1.0781 r:0.5273
ne_en Dev loss: 0.6926 r:0.7111
ru_en Dev loss: 0.5242 r:0.7110
Current avg r:0.6821 Best avg r: 0.7325
05:27:22,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:28,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:29:34,642 root INFO Epoch 10 Global steps: 79000 Train loss: 0.1301
ro_en Dev loss: 0.4065 r:0.8027
et_en Dev loss: 0.4787 r:0.6633
si_en Dev loss: 0.9348 r:0.5416
ne_en Dev loss: 0.6397 r:0.7031
ru_en Dev loss: 0.4964 r:0.7155
Current avg r:0.6852 Best avg r: 0.7325
05:32:52,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:33:57,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:35:03,885 root INFO Epoch 10 Global steps: 79500 Train loss: 0.1184
ro_en Dev loss: 0.4389 r:0.8043
et_en Dev loss: 0.4985 r:0.6612
si_en Dev loss: 1.0030 r:0.5369
ne_en Dev loss: 0.6579 r:0.7024
ru_en Dev loss: 0.5344 r:0.7118
Current avg r:0.6833 Best avg r: 0.7325
05:38:21,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:39:27,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:40:33,180 root INFO Epoch 10 Global steps: 80000 Train loss: 0.1203
ro_en Dev loss: 0.3948 r:0.8130
et_en Dev loss: 0.4862 r:0.6713
si_en Dev loss: 0.9468 r:0.5510
ne_en Dev loss: 0.6213 r:0.7128
ru_en Dev loss: 0.4990 r:0.7256
Current avg r:0.6948 Best avg r: 0.7325
05:43:50,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:56,790 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:02,691 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1201
ro_en Dev loss: 0.3669 r:0.8134
et_en Dev loss: 0.4723 r:0.6660
si_en Dev loss: 0.8903 r:0.5479
ne_en Dev loss: 0.5778 r:0.7090
ru_en Dev loss: 0.4825 r:0.7194
Current avg r:0.6912 Best avg r: 0.7325
05:49:20,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:50:26,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:51:32,941 root INFO Epoch 10 Global steps: 81000 Train loss: 0.1145
ro_en Dev loss: 0.4070 r:0.8085
et_en Dev loss: 0.4814 r:0.6660
si_en Dev loss: 0.9126 r:0.5549
ne_en Dev loss: 0.5953 r:0.7147
ru_en Dev loss: 0.5007 r:0.7155
Current avg r:0.6919 Best avg r: 0.7325
05:54:52,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:55:58,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:57:04,757 root INFO Epoch 10 Global steps: 81500 Train loss: 0.1203
ro_en Dev loss: 0.4198 r:0.8073
et_en Dev loss: 0.4960 r:0.6658
si_en Dev loss: 0.9422 r:0.5509
ne_en Dev loss: 0.5761 r:0.7122
ru_en Dev loss: 0.5192 r:0.7203
Current avg r:0.6913 Best avg r: 0.7325
06:00:23,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:01:29,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:02:36,154 root INFO Epoch 10 Global steps: 82000 Train loss: 0.1206
ro_en Dev loss: 0.3972 r:0.8075
et_en Dev loss: 0.4902 r:0.6642
si_en Dev loss: 0.8931 r:0.5558
ne_en Dev loss: 0.6085 r:0.7038
ru_en Dev loss: 0.5230 r:0.7176
Current avg r:0.6898 Best avg r: 0.7325
06:05:55,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:01,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:07,597 root INFO Epoch 10 Global steps: 82500 Train loss: 0.1182
ro_en Dev loss: 0.3846 r:0.8067
et_en Dev loss: 0.4709 r:0.6589
si_en Dev loss: 0.9481 r:0.5431
ne_en Dev loss: 0.6355 r:0.7070
ru_en Dev loss: 0.4765 r:0.7262
Current avg r:0.6884 Best avg r: 0.7325
06:11:28,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:12:34,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:13:40,351 root INFO Epoch 11 Global steps: 83000 Train loss: 0.1046
ro_en Dev loss: 0.3954 r:0.8107
et_en Dev loss: 0.4739 r:0.6601
si_en Dev loss: 0.9315 r:0.5474
ne_en Dev loss: 0.6539 r:0.7010
ru_en Dev loss: 0.5160 r:0.7235
Current avg r:0.6885 Best avg r: 0.7325
06:16:58,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:18:04,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:19:10,29 root INFO Epoch 11 Global steps: 83500 Train loss: 0.1149
ro_en Dev loss: 0.3829 r:0.8095
et_en Dev loss: 0.4768 r:0.6658
si_en Dev loss: 0.8857 r:0.5516
ne_en Dev loss: 0.5720 r:0.7107
ru_en Dev loss: 0.4815 r:0.7326
Current avg r:0.6940 Best avg r: 0.7325
06:22:27,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:23:33,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:39,326 root INFO Epoch 11 Global steps: 84000 Train loss: 0.1095
ro_en Dev loss: 0.4239 r:0.8060
et_en Dev loss: 0.5180 r:0.6501
si_en Dev loss: 0.9852 r:0.5474
ne_en Dev loss: 0.5990 r:0.7105
ru_en Dev loss: 0.5086 r:0.7273
Current avg r:0.6883 Best avg r: 0.7325
06:27:56,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:02,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:08,450 root INFO Epoch 11 Global steps: 84500 Train loss: 0.1093
ro_en Dev loss: 0.3597 r:0.8108
et_en Dev loss: 0.4667 r:0.6579
si_en Dev loss: 0.9013 r:0.5386
ne_en Dev loss: 0.5965 r:0.7034
ru_en Dev loss: 0.4532 r:0.7318
Current avg r:0.6885 Best avg r: 0.7325
06:33:26,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:34:32,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:35:37,982 root INFO Epoch 11 Global steps: 85000 Train loss: 0.1108
ro_en Dev loss: 0.3904 r:0.8070
et_en Dev loss: 0.4572 r:0.6581
si_en Dev loss: 0.9050 r:0.5508
ne_en Dev loss: 0.6080 r:0.7106
ru_en Dev loss: 0.4487 r:0.7393
Current avg r:0.6932 Best avg r: 0.7325
06:38:55,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:40:01,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:41:07,676 root INFO Epoch 11 Global steps: 85500 Train loss: 0.1127
ro_en Dev loss: 0.4455 r:0.8037
et_en Dev loss: 0.4935 r:0.6552
si_en Dev loss: 1.0108 r:0.5387
ne_en Dev loss: 0.7487 r:0.7026
ru_en Dev loss: 0.5374 r:0.7166
Current avg r:0.6834 Best avg r: 0.7325
06:44:25,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:31,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:37,840 root INFO Epoch 11 Global steps: 86000 Train loss: 0.1070
ro_en Dev loss: 0.4679 r:0.8047
et_en Dev loss: 0.5043 r:0.6582
si_en Dev loss: 1.0390 r:0.5398
ne_en Dev loss: 0.6716 r:0.7063
ru_en Dev loss: 0.5326 r:0.7218
Current avg r:0.6862 Best avg r: 0.7325
06:49:56,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:03,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:52:09,281 root INFO Epoch 11 Global steps: 86500 Train loss: 0.1084
ro_en Dev loss: 0.3599 r:0.8108
et_en Dev loss: 0.4587 r:0.6626
si_en Dev loss: 0.8436 r:0.5475
ne_en Dev loss: 0.5813 r:0.7060
ru_en Dev loss: 0.4901 r:0.7186
Current avg r:0.6891 Best avg r: 0.7325
06:55:28,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:56:34,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:57:40,979 root INFO Epoch 11 Global steps: 87000 Train loss: 0.1100
ro_en Dev loss: 0.4205 r:0.8069
et_en Dev loss: 0.5004 r:0.6568
si_en Dev loss: 0.9637 r:0.5432
ne_en Dev loss: 0.6133 r:0.7047
ru_en Dev loss: 0.5227 r:0.7245
Current avg r:0.6872 Best avg r: 0.7325
07:01:00,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:06,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:03:12,490 root INFO Epoch 11 Global steps: 87500 Train loss: 0.1104
ro_en Dev loss: 0.3873 r:0.8090
et_en Dev loss: 0.4752 r:0.6585
si_en Dev loss: 0.9279 r:0.5417
ne_en Dev loss: 0.6268 r:0.7067
ru_en Dev loss: 0.4897 r:0.7240
Current avg r:0.6880 Best avg r: 0.7325
07:06:31,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:07:37,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:43,443 root INFO Epoch 11 Global steps: 88000 Train loss: 0.1093
ro_en Dev loss: 0.3588 r:0.8164
et_en Dev loss: 0.4488 r:0.6716
si_en Dev loss: 0.8629 r:0.5523
ne_en Dev loss: 0.5690 r:0.7050
ru_en Dev loss: 0.4654 r:0.7416
Current avg r:0.6974 Best avg r: 0.7325
07:12:01,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:07,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:14:13,333 root INFO Epoch 11 Global steps: 88500 Train loss: 0.1101
ro_en Dev loss: 0.3835 r:0.8122
et_en Dev loss: 0.4815 r:0.6653
si_en Dev loss: 0.9809 r:0.5420
ne_en Dev loss: 0.6875 r:0.6962
ru_en Dev loss: 0.4880 r:0.7385
Current avg r:0.6909 Best avg r: 0.7325
07:17:31,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:18:37,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:19:43,326 root INFO Epoch 11 Global steps: 89000 Train loss: 0.1091
ro_en Dev loss: 0.4088 r:0.8097
et_en Dev loss: 0.4924 r:0.6630
si_en Dev loss: 0.9735 r:0.5504
ne_en Dev loss: 0.6444 r:0.7041
ru_en Dev loss: 0.5067 r:0.7303
Current avg r:0.6915 Best avg r: 0.7325
07:23:01,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:24:07,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:25:13,259 root INFO Epoch 11 Global steps: 89500 Train loss: 0.1029
ro_en Dev loss: 0.3734 r:0.8137
et_en Dev loss: 0.4593 r:0.6621
si_en Dev loss: 0.9667 r:0.5465
ne_en Dev loss: 0.6068 r:0.7107
ru_en Dev loss: 0.4533 r:0.7398
Current avg r:0.6946 Best avg r: 0.7325
07:28:31,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:29:37,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:42,893 root INFO Epoch 11 Global steps: 90000 Train loss: 0.1056
ro_en Dev loss: 0.3781 r:0.8071
et_en Dev loss: 0.4785 r:0.6650
si_en Dev loss: 0.8661 r:0.5526
ne_en Dev loss: 0.5497 r:0.7106
ru_en Dev loss: 0.4686 r:0.7215
Current avg r:0.6914 Best avg r: 0.7325
07:34:01,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:35:07,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:36:13,629 root INFO Epoch 12 Global steps: 90500 Train loss: 0.0917
ro_en Dev loss: 0.4122 r:0.8029
et_en Dev loss: 0.4654 r:0.6594
si_en Dev loss: 0.9045 r:0.5548
ne_en Dev loss: 0.6096 r:0.7115
ru_en Dev loss: 0.5316 r:0.6999
Current avg r:0.6857 Best avg r: 0.7325
07:39:31,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:37,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:41:43,171 root INFO Epoch 12 Global steps: 91000 Train loss: 0.0950
ro_en Dev loss: 0.3801 r:0.8085
et_en Dev loss: 0.4710 r:0.6659
si_en Dev loss: 0.8570 r:0.5532
ne_en Dev loss: 0.5760 r:0.7058
ru_en Dev loss: 0.4751 r:0.7290
Current avg r:0.6925 Best avg r: 0.7325
07:45:00,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:46:05,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:47:11,652 root INFO Epoch 12 Global steps: 91500 Train loss: 0.1003
ro_en Dev loss: 0.4311 r:0.8083
et_en Dev loss: 0.4737 r:0.6654
si_en Dev loss: 1.0092 r:0.5487
ne_en Dev loss: 0.6304 r:0.7192
ru_en Dev loss: 0.5576 r:0.7179
Current avg r:0.6919 Best avg r: 0.7325
07:50:29,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:51:34,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:40,652 root INFO Epoch 12 Global steps: 92000 Train loss: 0.1001
ro_en Dev loss: 0.3541 r:0.8155
et_en Dev loss: 0.4615 r:0.6778
si_en Dev loss: 0.8780 r:0.5548
ne_en Dev loss: 0.5365 r:0.7203
ru_en Dev loss: 0.4563 r:0.7379
Current avg r:0.7013 Best avg r: 0.7325
07:55:57,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:57:03,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:58:09,304 root INFO Epoch 12 Global steps: 92500 Train loss: 0.0993
ro_en Dev loss: 0.3949 r:0.8101
et_en Dev loss: 0.4702 r:0.6673
si_en Dev loss: 0.9520 r:0.5478
ne_en Dev loss: 0.5726 r:0.7161
ru_en Dev loss: 0.4976 r:0.7271
Current avg r:0.6937 Best avg r: 0.7325
08:01:26,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:32,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:38,187 root INFO Epoch 12 Global steps: 93000 Train loss: 0.0984
ro_en Dev loss: 0.4020 r:0.8067
et_en Dev loss: 0.4943 r:0.6748
si_en Dev loss: 0.9062 r:0.5522
ne_en Dev loss: 0.5723 r:0.7229
ru_en Dev loss: 0.4907 r:0.7338
Current avg r:0.6981 Best avg r: 0.7325
08:06:55,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:01,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:09:06,973 root INFO Epoch 12 Global steps: 93500 Train loss: 0.0990
ro_en Dev loss: 0.3993 r:0.8055
et_en Dev loss: 0.4794 r:0.6497
si_en Dev loss: 0.9644 r:0.5369
ne_en Dev loss: 0.6581 r:0.7087
ru_en Dev loss: 0.5185 r:0.7122
Current avg r:0.6826 Best avg r: 0.7325
08:12:24,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:13:29,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:14:35,642 root INFO Epoch 12 Global steps: 94000 Train loss: 0.1008
ro_en Dev loss: 0.3557 r:0.8108
et_en Dev loss: 0.4586 r:0.6624
si_en Dev loss: 0.8464 r:0.5408
ne_en Dev loss: 0.5761 r:0.7107
ru_en Dev loss: 0.4501 r:0.7313
Current avg r:0.6912 Best avg r: 0.7325
08:17:53,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:18:58,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:20:04,542 root INFO Epoch 12 Global steps: 94500 Train loss: 0.0973
ro_en Dev loss: 0.3751 r:0.8146
et_en Dev loss: 0.4581 r:0.6761
si_en Dev loss: 0.9429 r:0.5441
ne_en Dev loss: 0.5755 r:0.7176
ru_en Dev loss: 0.4784 r:0.7406
Current avg r:0.6986 Best avg r: 0.7325
08:23:21,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:24:27,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:25:32,947 root INFO Epoch 12 Global steps: 95000 Train loss: 0.0968
ro_en Dev loss: 0.4302 r:0.8100
et_en Dev loss: 0.5136 r:0.6571
si_en Dev loss: 1.0460 r:0.5402
ne_en Dev loss: 0.6914 r:0.7057
ru_en Dev loss: 0.5366 r:0.7358
Current avg r:0.6898 Best avg r: 0.7325
08:28:49,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:29:55,414 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:31:01,123 root INFO Epoch 12 Global steps: 95500 Train loss: 0.1036
ro_en Dev loss: 0.3770 r:0.8153
et_en Dev loss: 0.4631 r:0.6735
si_en Dev loss: 0.9618 r:0.5486
ne_en Dev loss: 0.5792 r:0.7115
ru_en Dev loss: 0.4684 r:0.7451
Current avg r:0.6988 Best avg r: 0.7325
08:34:17,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:23,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:29,83 root INFO Epoch 12 Global steps: 96000 Train loss: 0.0975
ro_en Dev loss: 0.3933 r:0.8114
et_en Dev loss: 0.4947 r:0.6689
si_en Dev loss: 0.9475 r:0.5483
ne_en Dev loss: 0.6012 r:0.7075
ru_en Dev loss: 0.4932 r:0.7409
Current avg r:0.6954 Best avg r: 0.7325
08:39:45,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:40:51,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:57,171 root INFO Epoch 12 Global steps: 96500 Train loss: 0.0976
ro_en Dev loss: 0.3708 r:0.8125
et_en Dev loss: 0.4660 r:0.6691
si_en Dev loss: 0.9238 r:0.5434
ne_en Dev loss: 0.5910 r:0.7095
ru_en Dev loss: 0.4687 r:0.7393
Current avg r:0.6948 Best avg r: 0.7325
08:45:13,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:46:19,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:47:25,352 root INFO Epoch 12 Global steps: 97000 Train loss: 0.0967
ro_en Dev loss: 0.4506 r:0.8060
et_en Dev loss: 0.5097 r:0.6621
si_en Dev loss: 1.0320 r:0.5425
ne_en Dev loss: 0.6883 r:0.7090
ru_en Dev loss: 0.5455 r:0.7244
Current avg r:0.6888 Best avg r: 0.7325
08:50:42,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:51:47,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:52:53,373 root INFO Epoch 12 Global steps: 97500 Train loss: 0.0968
ro_en Dev loss: 0.4010 r:0.8070
et_en Dev loss: 0.4728 r:0.6641
si_en Dev loss: 0.9530 r:0.5379
ne_en Dev loss: 0.6126 r:0.7071
ru_en Dev loss: 0.4740 r:0.7352
Current avg r:0.6903 Best avg r: 0.7325
08:56:12,27 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:57:17,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:58:23,521 root INFO Epoch 13 Global steps: 98000 Train loss: 0.0861
ro_en Dev loss: 0.3956 r:0.8068
et_en Dev loss: 0.4593 r:0.6729
si_en Dev loss: 0.9403 r:0.5464
ne_en Dev loss: 0.6249 r:0.7107
ru_en Dev loss: 0.4432 r:0.7429
Current avg r:0.6959 Best avg r: 0.7325
09:01:40,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:46,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:52,409 root INFO Epoch 13 Global steps: 98500 Train loss: 0.0879
ro_en Dev loss: 0.3932 r:0.8085
et_en Dev loss: 0.4427 r:0.6770
si_en Dev loss: 0.8839 r:0.5479
ne_en Dev loss: 0.6367 r:0.7123
ru_en Dev loss: 0.4803 r:0.7374
Current avg r:0.6966 Best avg r: 0.7325
09:07:09,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:08:15,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:21,222 root INFO Epoch 13 Global steps: 99000 Train loss: 0.0890
ro_en Dev loss: 0.3778 r:0.8079
et_en Dev loss: 0.4726 r:0.6720
si_en Dev loss: 0.8997 r:0.5503
ne_en Dev loss: 0.5786 r:0.7090
ru_en Dev loss: 0.4653 r:0.7340
Current avg r:0.6946 Best avg r: 0.7325
09:12:38,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:13:44,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:14:50,57 root INFO Epoch 13 Global steps: 99500 Train loss: 0.0861
ro_en Dev loss: 0.3940 r:0.8066
et_en Dev loss: 0.4718 r:0.6650
si_en Dev loss: 0.9809 r:0.5414
ne_en Dev loss: 0.6674 r:0.7123
ru_en Dev loss: 0.4898 r:0.7310
Current avg r:0.6913 Best avg r: 0.7325
09:18:07,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:19:13,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:20:19,84 root INFO Epoch 13 Global steps: 100000 Train loss: 0.0898
ro_en Dev loss: 0.4170 r:0.8058
et_en Dev loss: 0.4671 r:0.6612
si_en Dev loss: 0.9780 r:0.5433
ne_en Dev loss: 0.6276 r:0.7100
ru_en Dev loss: 0.4977 r:0.7293
Current avg r:0.6899 Best avg r: 0.7325
09:23:36,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:24:42,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:25:47,933 root INFO Epoch 13 Global steps: 100500 Train loss: 0.0893
ro_en Dev loss: 0.3600 r:0.8125
et_en Dev loss: 0.4485 r:0.6794
si_en Dev loss: 0.8298 r:0.5592
ne_en Dev loss: 0.5559 r:0.7152
ru_en Dev loss: 0.4270 r:0.7470
Current avg r:0.7027 Best avg r: 0.7325
09:29:05,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:11,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:31:16,872 root INFO Epoch 13 Global steps: 101000 Train loss: 0.0849
ro_en Dev loss: 0.3787 r:0.8104
et_en Dev loss: 0.4551 r:0.6760
si_en Dev loss: 0.8565 r:0.5557
ne_en Dev loss: 0.5634 r:0.7095
ru_en Dev loss: 0.4843 r:0.7348
Current avg r:0.6973 Best avg r: 0.7325
09:34:34,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:40,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:45,794 root INFO Epoch 13 Global steps: 101500 Train loss: 0.0843
ro_en Dev loss: 0.3719 r:0.8076
et_en Dev loss: 0.4587 r:0.6635
si_en Dev loss: 0.8940 r:0.5470
ne_en Dev loss: 0.5759 r:0.7118
ru_en Dev loss: 0.4639 r:0.7303
Current avg r:0.6920 Best avg r: 0.7325
09:40:03,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:08,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:42:14,627 root INFO Epoch 13 Global steps: 102000 Train loss: 0.0889
ro_en Dev loss: 0.3457 r:0.8144
et_en Dev loss: 0.4380 r:0.6839
si_en Dev loss: 0.7931 r:0.5616
ne_en Dev loss: 0.4922 r:0.7155
ru_en Dev loss: 0.4384 r:0.7449
Current avg r:0.7041 Best avg r: 0.7325
09:45:31,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:46:37,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:47:43,508 root INFO Epoch 13 Global steps: 102500 Train loss: 0.0868
ro_en Dev loss: 0.4099 r:0.8030
et_en Dev loss: 0.4744 r:0.6608
si_en Dev loss: 0.9279 r:0.5488
ne_en Dev loss: 0.6341 r:0.7138
ru_en Dev loss: 0.4990 r:0.7262
Current avg r:0.6905 Best avg r: 0.7325
09:51:00,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:52:06,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:53:12,358 root INFO Epoch 13 Global steps: 103000 Train loss: 0.0863
ro_en Dev loss: 0.3818 r:0.8083
et_en Dev loss: 0.4736 r:0.6693
si_en Dev loss: 0.9123 r:0.5469
ne_en Dev loss: 0.6640 r:0.7070
ru_en Dev loss: 0.4388 r:0.7511
Current avg r:0.6965 Best avg r: 0.7325
09:56:29,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:35,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:41,203 root INFO Epoch 13 Global steps: 103500 Train loss: 0.0893
ro_en Dev loss: 0.4040 r:0.8042
et_en Dev loss: 0.4701 r:0.6580
si_en Dev loss: 0.9687 r:0.5335
ne_en Dev loss: 0.6666 r:0.7107
ru_en Dev loss: 0.5521 r:0.7027
Current avg r:0.6818 Best avg r: 0.7325
10:01:58,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:03:04,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:04:10,137 root INFO Epoch 13 Global steps: 104000 Train loss: 0.0859
ro_en Dev loss: 0.3892 r:0.8107
et_en Dev loss: 0.4735 r:0.6658
si_en Dev loss: 0.9305 r:0.5442
ne_en Dev loss: 0.6265 r:0.7110
ru_en Dev loss: 0.5109 r:0.7241
Current avg r:0.6911 Best avg r: 0.7325
10:07:27,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:46,363 root INFO 
id:ru_en cur r: 0.7560 best r: 0.7560
10:08:46,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:52,115 root INFO Epoch 13 Global steps: 104500 Train loss: 0.0867
ro_en Dev loss: 0.3718 r:0.8140
et_en Dev loss: 0.4555 r:0.6678
si_en Dev loss: 0.9328 r:0.5461
ne_en Dev loss: 0.5662 r:0.7141
ru_en Dev loss: 0.4507 r:0.7492
Current avg r:0.6982 Best avg r: 0.7325
10:13:09,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:15,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:20,932 root INFO Epoch 13 Global steps: 105000 Train loss: 0.0874
ro_en Dev loss: 0.3554 r:0.8126
et_en Dev loss: 0.4502 r:0.6660
si_en Dev loss: 0.8622 r:0.5490
ne_en Dev loss: 0.5713 r:0.7155
ru_en Dev loss: 0.4562 r:0.7340
Current avg r:0.6954 Best avg r: 0.7325
10:18:39,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:45,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:51,214 root INFO Epoch 14 Global steps: 105500 Train loss: 0.0814
ro_en Dev loss: 0.4020 r:0.8126
et_en Dev loss: 0.4772 r:0.6693
si_en Dev loss: 0.9850 r:0.5446
ne_en Dev loss: 0.5988 r:0.7103
ru_en Dev loss: 0.5069 r:0.7365
Current avg r:0.6947 Best avg r: 0.7325
10:24:08,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:14,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:20,141 root INFO Epoch 14 Global steps: 106000 Train loss: 0.0771
ro_en Dev loss: 0.3811 r:0.8101
et_en Dev loss: 0.4704 r:0.6695
si_en Dev loss: 0.9445 r:0.5432
ne_en Dev loss: 0.6509 r:0.7056
ru_en Dev loss: 0.4860 r:0.7300
Current avg r:0.6917 Best avg r: 0.7325
10:29:37,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:30:43,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
