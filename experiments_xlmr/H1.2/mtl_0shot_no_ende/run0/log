14:48:00,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:48:13,199 root INFO 
id:en_zh cur r: 0.2693 best r: 0.2693
14:48:26,190 root INFO 
id:ro_en cur r: 0.5757 best r: 0.5757
14:48:52,215 root INFO 
id:si_en cur r: 0.4103 best r: 0.4103
14:49:05,237 root INFO 
id:ne_en cur r: 0.5039 best r: 0.5039
14:49:18,174 root INFO 
id:ru_en cur r: 0.6203 best r: 0.6203
14:49:18,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:50:48,939 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
14:50:48,952 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:50:48,959 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:50:48,967 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
14:50:48,972 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
14:50:48,979 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:50:48,986 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:51:01,990 root INFO Epoch 0 Global steps: 600 Train loss: 0.8861
en_de Dev loss: 0.8926 r:0.0977
en_zh Dev loss: 0.7659 r:0.2574
ro_en Dev loss: 0.6410 r:0.5817
et_en Dev loss: 0.5825 r:0.5453
si_en Dev loss: 0.6657 r:0.4409
ne_en Dev loss: 0.6100 r:0.5548
ru_en Dev loss: 0.5833 r:0.6451
Current avg r:0.4461 Best avg r: 0.4461
14:54:54,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:07,897 root INFO 
id:en_zh cur r: 0.3209 best r: 0.3209
14:55:20,881 root INFO 
id:ro_en cur r: 0.6103 best r: 0.6103
14:55:33,884 root INFO 
id:et_en cur r: 0.5531 best r: 0.5531
14:55:46,895 root INFO 
id:si_en cur r: 0.4585 best r: 0.4585
14:55:59,918 root INFO 
id:ne_en cur r: 0.5787 best r: 0.5787
14:56:12,840 root INFO 
id:ru_en cur r: 0.6642 best r: 0.6642
14:56:12,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:43,706 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
14:57:43,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:57:43,719 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:57:43,726 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
14:57:43,732 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
14:57:43,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:57:43,742 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:57:56,745 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8479
en_de Dev loss: 0.9309 r:0.1036
en_zh Dev loss: 0.7542 r:0.3138
ro_en Dev loss: 0.5633 r:0.6524
et_en Dev loss: 0.5014 r:0.5938
si_en Dev loss: 0.6940 r:0.4702
ne_en Dev loss: 0.5334 r:0.5986
ru_en Dev loss: 0.4852 r:0.7031
Current avg r:0.4908 Best avg r: 0.4908
15:01:49,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:15,267 root INFO 
id:ro_en cur r: 0.6421 best r: 0.6421
15:02:41,265 root INFO 
id:si_en cur r: 0.4659 best r: 0.4659
15:02:54,271 root INFO 
id:ne_en cur r: 0.5838 best r: 0.5838
15:03:07,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:38,40 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:04:38,51 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:04:38,59 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:04:38,66 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:04:38,73 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:04:38,79 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:04:38,86 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:04:51,98 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7326
en_de Dev loss: 0.9768 r:0.1312
en_zh Dev loss: 0.7701 r:0.3086
ro_en Dev loss: 0.4889 r:0.6635
et_en Dev loss: 0.4579 r:0.6200
si_en Dev loss: 0.6530 r:0.4904
ne_en Dev loss: 0.4863 r:0.6356
ru_en Dev loss: 0.4629 r:0.6894
Current avg r:0.5055 Best avg r: 0.5055
15:08:43,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:09,643 root INFO 
id:ro_en cur r: 0.6723 best r: 0.6723
15:09:22,657 root INFO 
id:et_en cur r: 0.6057 best r: 0.6057
15:10:01,623 root INFO 
id:ru_en cur r: 0.6649 best r: 0.6649
15:10:01,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:32,477 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6713
en_de Dev loss: 1.0850 r:0.0869
en_zh Dev loss: 0.8636 r:0.3206
ro_en Dev loss: 0.5295 r:0.6916
et_en Dev loss: 0.4412 r:0.6334
si_en Dev loss: 0.8687 r:0.4700
ne_en Dev loss: 0.5421 r:0.6178
ru_en Dev loss: 0.5462 r:0.7048
Current avg r:0.5036 Best avg r: 0.5055
15:15:25,355 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:38,306 root INFO 
id:en_zh cur r: 0.3591 best r: 0.3591
15:15:51,300 root INFO 
id:ro_en cur r: 0.6948 best r: 0.6948
15:16:04,300 root INFO 
id:et_en cur r: 0.6325 best r: 0.6325
15:16:17,331 root INFO 
id:si_en cur r: 0.4917 best r: 0.4917
15:16:30,344 root INFO 
id:ne_en cur r: 0.6522 best r: 0.6522
15:16:43,256 root INFO 
id:ru_en cur r: 0.7077 best r: 0.7077
15:16:43,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:14,101 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:18:14,107 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:18:14,112 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:18:14,120 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:18:14,125 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:18:14,131 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:18:14,136 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:18:27,142 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6336
en_de Dev loss: 1.0520 r:0.1136
en_zh Dev loss: 0.7626 r:0.3674
ro_en Dev loss: 0.4502 r:0.7017
et_en Dev loss: 0.4039 r:0.6601
si_en Dev loss: 0.7387 r:0.5127
ne_en Dev loss: 0.4590 r:0.6621
ru_en Dev loss: 0.4638 r:0.7293
Current avg r:0.5353 Best avg r: 0.5353
15:22:20,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:33,348 root INFO 
id:en_zh cur r: 0.3699 best r: 0.3699
15:22:46,339 root INFO 
id:ro_en cur r: 0.7136 best r: 0.7136
15:22:59,349 root INFO 
id:et_en cur r: 0.6555 best r: 0.6555
15:23:38,315 root INFO 
id:ru_en cur r: 0.7186 best r: 0.7186
15:23:38,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:09,151 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:25:09,160 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:25:09,165 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:25:09,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:25:09,180 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:25:09,188 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:25:09,196 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:25:22,204 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6280
en_de Dev loss: 1.0392 r:0.1265
en_zh Dev loss: 0.7606 r:0.3841
ro_en Dev loss: 0.4271 r:0.7199
et_en Dev loss: 0.3958 r:0.6708
si_en Dev loss: 0.6603 r:0.5261
ne_en Dev loss: 0.4273 r:0.6857
ru_en Dev loss: 0.4672 r:0.7393
Current avg r:0.5503 Best avg r: 0.5503
15:29:15,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:28,215 root INFO 
id:en_zh cur r: 0.4090 best r: 0.4090
15:29:41,214 root INFO 
id:ro_en cur r: 0.7408 best r: 0.7408
15:29:54,230 root INFO 
id:et_en cur r: 0.6737 best r: 0.6737
15:30:07,265 root INFO 
id:si_en cur r: 0.5398 best r: 0.5398
15:30:20,289 root INFO 
id:ne_en cur r: 0.6775 best r: 0.6775
15:30:33,206 root INFO 
id:ru_en cur r: 0.7270 best r: 0.7270
15:30:33,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:04,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:32:04,68 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:32:04,80 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:32:04,93 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:32:04,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:32:04,120 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:32:04,132 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:32:17,136 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6102
en_de Dev loss: 1.0229 r:0.1636
en_zh Dev loss: 0.7176 r:0.4201
ro_en Dev loss: 0.4206 r:0.7424
et_en Dev loss: 0.3816 r:0.6869
si_en Dev loss: 0.6879 r:0.5465
ne_en Dev loss: 0.4833 r:0.6847
ru_en Dev loss: 0.4857 r:0.7431
Current avg r:0.5696 Best avg r: 0.5696
15:36:09,891 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:48,827 root INFO 
id:et_en cur r: 0.6743 best r: 0.6743
15:37:14,855 root INFO 
id:ne_en cur r: 0.6835 best r: 0.6835
15:37:27,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:58,623 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:38:58,634 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:38:58,640 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:38:58,647 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:38:58,654 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:38:58,662 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:38:58,668 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:39:11,671 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6152
en_de Dev loss: 1.0302 r:0.1694
en_zh Dev loss: 0.7026 r:0.4165
ro_en Dev loss: 0.4185 r:0.7473
et_en Dev loss: 0.3756 r:0.6863
si_en Dev loss: 0.6385 r:0.5528
ne_en Dev loss: 0.4222 r:0.6953
ru_en Dev loss: 0.4340 r:0.7467
Current avg r:0.5735 Best avg r: 0.5735
15:43:04,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:17,768 root INFO 
id:en_zh cur r: 0.4193 best r: 0.4193
15:43:30,754 root INFO 
id:ro_en cur r: 0.7425 best r: 0.7425
15:43:56,769 root INFO 
id:si_en cur r: 0.5566 best r: 0.5566
15:44:09,796 root INFO 
id:ne_en cur r: 0.7008 best r: 0.7008
15:44:22,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:53,600 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:45:53,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:45:53,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:45:53,636 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:45:53,644 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:45:53,652 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:45:53,661 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:46:06,677 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5715
en_de Dev loss: 1.0217 r:0.1790
en_zh Dev loss: 0.6942 r:0.4309
ro_en Dev loss: 0.4005 r:0.7363
et_en Dev loss: 0.3719 r:0.6906
si_en Dev loss: 0.5733 r:0.5699
ne_en Dev loss: 0.3892 r:0.7164
ru_en Dev loss: 0.4291 r:0.7444
Current avg r:0.5811 Best avg r: 0.5811
15:49:59,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:12,346 root INFO 
id:en_zh cur r: 0.4283 best r: 0.4283
15:50:25,333 root INFO 
id:ro_en cur r: 0.7590 best r: 0.7590
15:50:38,334 root INFO 
id:et_en cur r: 0.6930 best r: 0.6930
15:50:51,375 root INFO 
id:si_en cur r: 0.5576 best r: 0.5576
15:51:04,400 root INFO 
id:ne_en cur r: 0.7119 best r: 0.7119
15:51:17,330 root INFO 
id:ru_en cur r: 0.7393 best r: 0.7393
15:51:17,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:48,334 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:52:48,342 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:52:48,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:52:48,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:52:48,359 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:52:48,364 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:52:48,369 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:53:01,387 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5646
en_de Dev loss: 1.0280 r:0.1792
en_zh Dev loss: 0.7008 r:0.4376
ro_en Dev loss: 0.4093 r:0.7561
et_en Dev loss: 0.3642 r:0.6984
si_en Dev loss: 0.6098 r:0.5751
ne_en Dev loss: 0.4025 r:0.7143
ru_en Dev loss: 0.4052 r:0.7542
Current avg r:0.5878 Best avg r: 0.5878
15:56:54,558 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:07,508 root INFO 
id:en_zh cur r: 0.4323 best r: 0.4323
15:57:20,509 root INFO 
id:ro_en cur r: 0.7718 best r: 0.7718
15:57:46,512 root INFO 
id:si_en cur r: 0.5744 best r: 0.5744
15:57:59,524 root INFO 
id:ne_en cur r: 0.7178 best r: 0.7178
15:58:12,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:43,379 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:59:43,389 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:59:43,395 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:59:43,403 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:59:43,409 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:59:43,415 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:59:43,422 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:59:56,446 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5560
en_de Dev loss: 1.0184 r:0.1786
en_zh Dev loss: 0.6749 r:0.4412
ro_en Dev loss: 0.3782 r:0.7685
et_en Dev loss: 0.3708 r:0.6956
si_en Dev loss: 0.5748 r:0.5953
ne_en Dev loss: 0.4256 r:0.7210
ru_en Dev loss: 0.4477 r:0.7476
Current avg r:0.5925 Best avg r: 0.5925
16:03:49,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:15,401 root INFO 
id:ro_en cur r: 0.7812 best r: 0.7812
16:04:28,421 root INFO 
id:et_en cur r: 0.6953 best r: 0.6953
16:04:54,451 root INFO 
id:ne_en cur r: 0.7196 best r: 0.7196
16:05:07,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:38,181 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5481
en_de Dev loss: 1.1273 r:0.1878
en_zh Dev loss: 0.7950 r:0.4350
ro_en Dev loss: 0.4391 r:0.7793
et_en Dev loss: 0.4285 r:0.6966
si_en Dev loss: 0.8492 r:0.5694
ne_en Dev loss: 0.5369 r:0.7101
ru_en Dev loss: 0.5996 r:0.7314
Current avg r:0.5871 Best avg r: 0.5925
16:10:31,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:23,66 root INFO 
id:si_en cur r: 0.5945 best r: 0.5945
16:11:36,80 root INFO 
id:ne_en cur r: 0.7201 best r: 0.7201
16:11:48,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:19,805 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5393
en_de Dev loss: 1.1281 r:0.1667
en_zh Dev loss: 0.7863 r:0.4173
ro_en Dev loss: 0.4089 r:0.7781
et_en Dev loss: 0.4126 r:0.6913
si_en Dev loss: 0.6534 r:0.5887
ne_en Dev loss: 0.4254 r:0.7213
ru_en Dev loss: 0.5261 r:0.7256
Current avg r:0.5841 Best avg r: 0.5925
16:17:12,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:30,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:01,433 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5193
en_de Dev loss: 1.1333 r:0.1458
en_zh Dev loss: 0.7738 r:0.3996
ro_en Dev loss: 0.3915 r:0.7823
et_en Dev loss: 0.4053 r:0.6785
si_en Dev loss: 0.7044 r:0.5881
ne_en Dev loss: 0.5381 r:0.7191
ru_en Dev loss: 0.5167 r:0.6618
Current avg r:0.5679 Best avg r: 0.5925
16:23:54,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:20,286 root INFO 
id:ro_en cur r: 0.7892 best r: 0.7892
16:24:59,360 root INFO 
id:ne_en cur r: 0.7297 best r: 0.7297
16:25:12,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:43,284 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5448
en_de Dev loss: 1.2469 r:0.1646
en_zh Dev loss: 0.9314 r:0.4085
ro_en Dev loss: 0.4295 r:0.7899
et_en Dev loss: 0.4386 r:0.6892
si_en Dev loss: 0.7619 r:0.5852
ne_en Dev loss: 0.5639 r:0.7264
ru_en Dev loss: 0.5955 r:0.7000
Current avg r:0.5805 Best avg r: 0.5925
16:30:37,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:03,728 root INFO 
id:ro_en cur r: 0.7924 best r: 0.7924
16:31:42,824 root INFO 
id:ne_en cur r: 0.7404 best r: 0.7404
16:31:55,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:26,724 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
16:33:26,735 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:33:26,741 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:33:26,748 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
16:33:26,753 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
16:33:26,759 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:33:26,767 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:33:39,793 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5111
en_de Dev loss: 1.1187 r:0.1992
en_zh Dev loss: 0.7773 r:0.4319
ro_en Dev loss: 0.3917 r:0.7944
et_en Dev loss: 0.4247 r:0.6920
si_en Dev loss: 0.6695 r:0.5948
ne_en Dev loss: 0.5094 r:0.7379
ru_en Dev loss: 0.4917 r:0.7192
Current avg r:0.5956 Best avg r: 0.5956
16:37:32,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:45,672 root INFO 
id:en_zh cur r: 0.4424 best r: 0.4424
16:37:58,672 root INFO 
id:ro_en cur r: 0.7967 best r: 0.7967
16:38:11,692 root INFO 
id:et_en cur r: 0.6963 best r: 0.6963
16:38:50,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:21,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
16:40:21,621 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:40:21,626 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:40:21,631 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
16:40:21,638 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
16:40:21,643 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:40:21,648 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:40:34,688 root INFO Epoch 1 Global steps: 10200 Train loss: 0.4982
en_de Dev loss: 1.1359 r:0.2039
en_zh Dev loss: 0.7707 r:0.4523
ro_en Dev loss: 0.3667 r:0.7971
et_en Dev loss: 0.3823 r:0.7014
si_en Dev loss: 0.7297 r:0.5905
ne_en Dev loss: 0.5204 r:0.7400
ru_en Dev loss: 0.4862 r:0.7464
Current avg r:0.6045 Best avg r: 0.6045
16:44:27,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:40,906 root INFO 
id:en_zh cur r: 0.4489 best r: 0.4489
16:44:53,907 root INFO 
id:ro_en cur r: 0.8033 best r: 0.8033
16:45:06,923 root INFO 
id:et_en cur r: 0.6986 best r: 0.6986
16:45:19,966 root INFO 
id:si_en cur r: 0.5963 best r: 0.5963
16:45:32,987 root INFO 
id:ne_en cur r: 0.7433 best r: 0.7433
16:45:45,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:16,808 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
16:47:16,827 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:47:16,834 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:47:16,841 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
16:47:16,846 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
16:47:16,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:47:16,859 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:47:29,886 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5060
en_de Dev loss: 1.1851 r:0.2032
en_zh Dev loss: 0.7769 r:0.4567
ro_en Dev loss: 0.4106 r:0.8051
et_en Dev loss: 0.3883 r:0.7076
si_en Dev loss: 0.7270 r:0.5992
ne_en Dev loss: 0.5404 r:0.7458
ru_en Dev loss: 0.5197 r:0.7432
Current avg r:0.6087 Best avg r: 0.6087
16:51:23,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:49,45 root INFO 
id:ro_en cur r: 0.8033 best r: 0.8033
16:52:28,87 root INFO 
id:ne_en cur r: 0.7442 best r: 0.7442
16:52:41,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:11,973 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4813
en_de Dev loss: 1.1709 r:0.1968
en_zh Dev loss: 0.7744 r:0.4537
ro_en Dev loss: 0.3517 r:0.8043
et_en Dev loss: 0.3874 r:0.7035
si_en Dev loss: 0.7415 r:0.5972
ne_en Dev loss: 0.4399 r:0.7510
ru_en Dev loss: 0.5290 r:0.7331
Current avg r:0.6057 Best avg r: 0.6087
16:58:05,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:31,100 root INFO 
id:ro_en cur r: 0.8072 best r: 0.8072
16:58:44,103 root INFO 
id:et_en cur r: 0.7043 best r: 0.7043
16:58:57,120 root INFO 
id:si_en cur r: 0.5966 best r: 0.5966
16:59:10,131 root INFO 
id:ne_en cur r: 0.7499 best r: 0.7499
16:59:23,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:53,795 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
17:00:53,828 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:00:53,841 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:00:53,851 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
17:00:53,862 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
17:00:53,871 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:00:53,881 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:01:06,886 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4958
en_de Dev loss: 1.1355 r:0.1927
en_zh Dev loss: 0.7472 r:0.4503
ro_en Dev loss: 0.3442 r:0.8064
et_en Dev loss: 0.3834 r:0.7077
si_en Dev loss: 0.6187 r:0.6059
ne_en Dev loss: 0.3566 r:0.7579
ru_en Dev loss: 0.4509 r:0.7436
Current avg r:0.6092 Best avg r: 0.6092
17:04:59,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:38,517 root INFO 
id:et_en cur r: 0.7098 best r: 0.7098
17:06:17,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:48,168 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4761
en_de Dev loss: 1.2430 r:0.2072
en_zh Dev loss: 0.8613 r:0.4520
ro_en Dev loss: 0.4186 r:0.8010
et_en Dev loss: 0.4046 r:0.7028
si_en Dev loss: 0.8875 r:0.5820
ne_en Dev loss: 0.4367 r:0.7480
ru_en Dev loss: 0.5696 r:0.7294
Current avg r:0.6032 Best avg r: 0.6092
17:11:40,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:53,571 root INFO 
id:en_zh cur r: 0.4642 best r: 0.4642
17:12:45,569 root INFO 
id:ne_en cur r: 0.7510 best r: 0.7510
17:12:58,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:29,271 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4903
en_de Dev loss: 1.2157 r:0.2059
en_zh Dev loss: 0.8102 r:0.4692
ro_en Dev loss: 0.4161 r:0.8001
et_en Dev loss: 0.4259 r:0.6979
si_en Dev loss: 0.9145 r:0.5852
ne_en Dev loss: 0.5462 r:0.7535
ru_en Dev loss: 0.4909 r:0.7435
Current avg r:0.6079 Best avg r: 0.6092
17:18:21,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:26,722 root INFO 
id:ne_en cur r: 0.7533 best r: 0.7533
17:19:39,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:10,690 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4739
en_de Dev loss: 1.1434 r:0.2044
en_zh Dev loss: 0.7309 r:0.4642
ro_en Dev loss: 0.3788 r:0.7983
et_en Dev loss: 0.3783 r:0.6984
si_en Dev loss: 0.6923 r:0.5951
ne_en Dev loss: 0.3854 r:0.7579
ru_en Dev loss: 0.4437 r:0.7415
Current avg r:0.6086 Best avg r: 0.6092
17:25:04,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:17,393 root INFO 
id:en_zh cur r: 0.4778 best r: 0.4778
17:25:30,418 root INFO 
id:ro_en cur r: 0.8130 best r: 0.8130
17:25:56,533 root INFO 
id:si_en cur r: 0.6150 best r: 0.6150
17:26:09,592 root INFO 
id:ne_en cur r: 0.7583 best r: 0.7583
17:26:22,553 root INFO 
id:ru_en cur r: 0.7451 best r: 0.7451
17:26:22,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:53,721 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
17:27:53,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:27:53,733 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:27:53,740 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
17:27:53,744 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
17:27:53,751 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:27:53,756 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:28:06,815 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4798
en_de Dev loss: 1.0522 r:0.2075
en_zh Dev loss: 0.6803 r:0.4767
ro_en Dev loss: 0.3115 r:0.8106
et_en Dev loss: 0.3608 r:0.7049
si_en Dev loss: 0.7009 r:0.6067
ne_en Dev loss: 0.4252 r:0.7626
ru_en Dev loss: 0.3852 r:0.7600
Current avg r:0.6184 Best avg r: 0.6184
17:32:00,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:05,926 root INFO 
id:ne_en cur r: 0.7629 best r: 0.7629
17:33:18,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:50,65 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4654
en_de Dev loss: 1.1195 r:0.2186
en_zh Dev loss: 0.7287 r:0.4716
ro_en Dev loss: 0.3511 r:0.8066
et_en Dev loss: 0.3842 r:0.6998
si_en Dev loss: 0.6904 r:0.6025
ne_en Dev loss: 0.4012 r:0.7636
ru_en Dev loss: 0.4517 r:0.7435
Current avg r:0.6152 Best avg r: 0.6184
17:38:42,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:00,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:31,469 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4559
en_de Dev loss: 1.1336 r:0.2039
en_zh Dev loss: 0.7215 r:0.4639
ro_en Dev loss: 0.3686 r:0.8034
et_en Dev loss: 0.3965 r:0.6947
si_en Dev loss: 0.7323 r:0.5969
ne_en Dev loss: 0.5040 r:0.7558
ru_en Dev loss: 0.4579 r:0.7444
Current avg r:0.6090 Best avg r: 0.6184
17:45:24,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:41,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:12,580 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4681
en_de Dev loss: 1.1252 r:0.2055
en_zh Dev loss: 0.7365 r:0.4646
ro_en Dev loss: 0.3253 r:0.8142
et_en Dev loss: 0.3617 r:0.7078
si_en Dev loss: 0.6766 r:0.6074
ne_en Dev loss: 0.4276 r:0.7623
ru_en Dev loss: 0.4311 r:0.7517
Current avg r:0.6162 Best avg r: 0.6184
17:52:05,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:18,53 root INFO 
id:en_zh cur r: 0.4887 best r: 0.4887
17:52:31,48 root INFO 
id:ro_en cur r: 0.8180 best r: 0.8180
17:52:44,63 root INFO 
id:et_en cur r: 0.7141 best r: 0.7141
17:53:22,973 root INFO 
id:ru_en cur r: 0.7567 best r: 0.7567
17:53:22,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:53,716 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
17:54:53,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:54:53,760 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:54:53,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
17:54:53,787 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
17:54:53,800 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:54:53,813 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:55:06,815 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4703
en_de Dev loss: 1.0323 r:0.2063
en_zh Dev loss: 0.6429 r:0.4844
ro_en Dev loss: 0.3057 r:0.8149
et_en Dev loss: 0.3752 r:0.7115
si_en Dev loss: 0.5834 r:0.6130
ne_en Dev loss: 0.3291 r:0.7645
ru_en Dev loss: 0.3538 r:0.7673
Current avg r:0.6231 Best avg r: 0.6231
17:58:59,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:17,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:47,864 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4515
en_de Dev loss: 1.0992 r:0.2169
en_zh Dev loss: 0.7091 r:0.4720
ro_en Dev loss: 0.3299 r:0.8079
et_en Dev loss: 0.3683 r:0.7038
si_en Dev loss: 0.6449 r:0.5994
ne_en Dev loss: 0.3664 r:0.7611
ru_en Dev loss: 0.4421 r:0.7373
Current avg r:0.6141 Best avg r: 0.6231
18:05:40,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:53,169 root INFO 
id:en_zh cur r: 0.4888 best r: 0.4888
18:06:06,156 root INFO 
id:ro_en cur r: 0.8189 best r: 0.8189
18:06:58,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:28,830 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4544
en_de Dev loss: 1.1108 r:0.2123
en_zh Dev loss: 0.6732 r:0.4835
ro_en Dev loss: 0.3390 r:0.8144
et_en Dev loss: 0.3702 r:0.7082
si_en Dev loss: 0.6867 r:0.6050
ne_en Dev loss: 0.3770 r:0.7629
ru_en Dev loss: 0.4252 r:0.7548
Current avg r:0.6202 Best avg r: 0.6231
18:12:22,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:48,316 root INFO 
id:ro_en cur r: 0.8207 best r: 0.8207
18:13:40,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:10,974 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4312
en_de Dev loss: 1.1335 r:0.2042
en_zh Dev loss: 0.7036 r:0.4697
ro_en Dev loss: 0.3329 r:0.8160
et_en Dev loss: 0.3791 r:0.7042
si_en Dev loss: 0.6493 r:0.6112
ne_en Dev loss: 0.3792 r:0.7575
ru_en Dev loss: 0.4125 r:0.7525
Current avg r:0.6165 Best avg r: 0.6231
18:19:03,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:21,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:52,227 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4249
en_de Dev loss: 1.1685 r:0.2127
en_zh Dev loss: 0.7375 r:0.4732
ro_en Dev loss: 0.3544 r:0.8120
et_en Dev loss: 0.3851 r:0.6999
si_en Dev loss: 0.7070 r:0.6043
ne_en Dev loss: 0.4387 r:0.7595
ru_en Dev loss: 0.4737 r:0.7362
Current avg r:0.6140 Best avg r: 0.6231
18:25:44,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:10,737 root INFO 
id:ro_en cur r: 0.8210 best r: 0.8210
18:27:02,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:33,375 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4346
en_de Dev loss: 1.0887 r:0.2088
en_zh Dev loss: 0.6752 r:0.4841
ro_en Dev loss: 0.3010 r:0.8198
et_en Dev loss: 0.3696 r:0.7004
si_en Dev loss: 0.6417 r:0.6146
ne_en Dev loss: 0.3830 r:0.7569
ru_en Dev loss: 0.4534 r:0.7405
Current avg r:0.6179 Best avg r: 0.6231
18:32:25,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:43,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:14,449 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4288
en_de Dev loss: 1.0852 r:0.2251
en_zh Dev loss: 0.6818 r:0.4789
ro_en Dev loss: 0.3214 r:0.8155
et_en Dev loss: 0.3841 r:0.6979
si_en Dev loss: 0.6660 r:0.6072
ne_en Dev loss: 0.3566 r:0.7563
ru_en Dev loss: 0.4185 r:0.7408
Current avg r:0.6174 Best avg r: 0.6231
18:39:06,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:32,861 root INFO 
id:ro_en cur r: 0.8227 best r: 0.8227
18:39:58,864 root INFO 
id:si_en cur r: 0.6172 best r: 0.6172
18:40:24,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:55,479 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
18:41:55,485 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:41:55,490 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:41:55,496 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
18:41:55,500 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
18:41:55,505 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:41:55,510 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:42:08,491 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4122
en_de Dev loss: 1.1150 r:0.2181
en_zh Dev loss: 0.7042 r:0.4825
ro_en Dev loss: 0.3152 r:0.8226
et_en Dev loss: 0.3651 r:0.7076
si_en Dev loss: 0.6236 r:0.6221
ne_en Dev loss: 0.3696 r:0.7606
ru_en Dev loss: 0.4177 r:0.7581
Current avg r:0.6245 Best avg r: 0.6245
18:46:00,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:18,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:49,483 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4110
en_de Dev loss: 1.1104 r:0.2148
en_zh Dev loss: 0.7023 r:0.4847
ro_en Dev loss: 0.3438 r:0.8131
et_en Dev loss: 0.3906 r:0.6966
si_en Dev loss: 0.6374 r:0.6062
ne_en Dev loss: 0.3859 r:0.7578
ru_en Dev loss: 0.4040 r:0.7490
Current avg r:0.6175 Best avg r: 0.6245
18:52:42,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:55,86 root INFO 
id:en_zh cur r: 0.4914 best r: 0.4914
18:53:08,57 root INFO 
id:ro_en cur r: 0.8229 best r: 0.8229
18:53:59,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:30,691 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4116
en_de Dev loss: 1.1792 r:0.2149
en_zh Dev loss: 0.7173 r:0.4911
ro_en Dev loss: 0.3546 r:0.8210
et_en Dev loss: 0.3909 r:0.7080
si_en Dev loss: 0.6314 r:0.6153
ne_en Dev loss: 0.3505 r:0.7571
ru_en Dev loss: 0.4161 r:0.7511
Current avg r:0.6226 Best avg r: 0.6245
18:59:23,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:41,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:11,954 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4107
en_de Dev loss: 1.2096 r:0.2253
en_zh Dev loss: 0.7363 r:0.4862
ro_en Dev loss: 0.4061 r:0.8128
et_en Dev loss: 0.3908 r:0.7033
si_en Dev loss: 0.8094 r:0.6009
ne_en Dev loss: 0.3817 r:0.7555
ru_en Dev loss: 0.4067 r:0.7610
Current avg r:0.6207 Best avg r: 0.6245
19:06:04,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:22,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:53,378 root INFO Epoch 2 Global steps: 23400 Train loss: 0.3985
en_de Dev loss: 1.1688 r:0.2192
en_zh Dev loss: 0.7234 r:0.4750
ro_en Dev loss: 0.3409 r:0.8177
et_en Dev loss: 0.3850 r:0.7021
si_en Dev loss: 0.6622 r:0.6153
ne_en Dev loss: 0.4165 r:0.7514
ru_en Dev loss: 0.4071 r:0.7539
Current avg r:0.6192 Best avg r: 0.6245
19:12:45,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:03,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:34,427 root INFO Epoch 2 Global steps: 24000 Train loss: 0.3977
en_de Dev loss: 1.1692 r:0.2308
en_zh Dev loss: 0.7201 r:0.4773
ro_en Dev loss: 0.3612 r:0.8121
et_en Dev loss: 0.4158 r:0.6911
si_en Dev loss: 0.7396 r:0.6047
ne_en Dev loss: 0.4046 r:0.7585
ru_en Dev loss: 0.4459 r:0.7384
Current avg r:0.6161 Best avg r: 0.6245
19:19:27,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:44,880 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:15,591 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4097
en_de Dev loss: 1.1290 r:0.2267
en_zh Dev loss: 0.7244 r:0.4606
ro_en Dev loss: 0.3682 r:0.8074
et_en Dev loss: 0.4054 r:0.6806
si_en Dev loss: 0.6683 r:0.6064
ne_en Dev loss: 0.4612 r:0.7553
ru_en Dev loss: 0.4830 r:0.7072
Current avg r:0.6063 Best avg r: 0.6245
19:26:08,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:25,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:56,567 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4234
en_de Dev loss: 1.1643 r:0.2183
en_zh Dev loss: 0.7209 r:0.4813
ro_en Dev loss: 0.3639 r:0.8149
et_en Dev loss: 0.4214 r:0.6994
si_en Dev loss: 0.6729 r:0.6148
ne_en Dev loss: 0.4128 r:0.7569
ru_en Dev loss: 0.4093 r:0.7511
Current avg r:0.6195 Best avg r: 0.6245
19:32:49,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:07,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:37,774 root INFO Epoch 2 Global steps: 25800 Train loss: 0.3992
en_de Dev loss: 1.1686 r:0.2230
en_zh Dev loss: 0.7439 r:0.4743
ro_en Dev loss: 0.3529 r:0.8148
et_en Dev loss: 0.3983 r:0.6947
si_en Dev loss: 0.6502 r:0.6102
ne_en Dev loss: 0.3536 r:0.7607
ru_en Dev loss: 0.4353 r:0.7481
Current avg r:0.6179 Best avg r: 0.6245
19:39:30,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:48,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:19,49 root INFO Epoch 2 Global steps: 26400 Train loss: 0.3859
en_de Dev loss: 1.1222 r:0.2296
en_zh Dev loss: 0.7062 r:0.4741
ro_en Dev loss: 0.3444 r:0.8156
et_en Dev loss: 0.3969 r:0.6914
si_en Dev loss: 0.7865 r:0.5947
ne_en Dev loss: 0.4240 r:0.7589
ru_en Dev loss: 0.4842 r:0.7230
Current avg r:0.6125 Best avg r: 0.6245
19:46:11,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:29,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:00,280 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4290
en_de Dev loss: 1.2058 r:0.2323
en_zh Dev loss: 0.7604 r:0.4661
ro_en Dev loss: 0.3995 r:0.8109
et_en Dev loss: 0.4187 r:0.6908
si_en Dev loss: 0.7870 r:0.5981
ne_en Dev loss: 0.5191 r:0.7561
ru_en Dev loss: 0.4839 r:0.7283
Current avg r:0.6118 Best avg r: 0.6245
19:52:54,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:12,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:43,247 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3705
en_de Dev loss: 1.1623 r:0.2248
en_zh Dev loss: 0.7259 r:0.4642
ro_en Dev loss: 0.3697 r:0.8122
et_en Dev loss: 0.4205 r:0.6876
si_en Dev loss: 0.7036 r:0.6031
ne_en Dev loss: 0.4298 r:0.7549
ru_en Dev loss: 0.4482 r:0.7240
Current avg r:0.6101 Best avg r: 0.6245
19:59:36,459 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:54,342 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:25,277 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3663
en_de Dev loss: 1.1364 r:0.2199
en_zh Dev loss: 0.6847 r:0.4887
ro_en Dev loss: 0.3511 r:0.8161
et_en Dev loss: 0.3951 r:0.6976
si_en Dev loss: 0.6802 r:0.6085
ne_en Dev loss: 0.3700 r:0.7609
ru_en Dev loss: 0.4197 r:0.7421
Current avg r:0.6191 Best avg r: 0.6245
20:06:18,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:31,463 root INFO 
id:en_zh cur r: 0.4971 best r: 0.4971
20:06:44,451 root INFO 
id:ro_en cur r: 0.8244 best r: 0.8244
20:07:23,466 root INFO 
id:ne_en cur r: 0.7638 best r: 0.7638
20:07:36,375 root INFO 
id:ru_en cur r: 0.7585 best r: 0.7585
20:07:36,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:07,248 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
20:09:07,271 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
20:09:07,280 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
20:09:07,295 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
20:09:07,304 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
20:09:07,314 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
20:09:07,322 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
20:09:20,333 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3738
en_de Dev loss: 1.1017 r:0.2237
en_zh Dev loss: 0.6708 r:0.4966
ro_en Dev loss: 0.3227 r:0.8219
et_en Dev loss: 0.4058 r:0.7000
si_en Dev loss: 0.6285 r:0.6128
ne_en Dev loss: 0.3577 r:0.7652
ru_en Dev loss: 0.3745 r:0.7565
Current avg r:0.6252 Best avg r: 0.6252
20:13:13,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:30,926 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:01,737 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3506
en_de Dev loss: 1.1750 r:0.2293
en_zh Dev loss: 0.7156 r:0.4844
ro_en Dev loss: 0.3562 r:0.8150
et_en Dev loss: 0.4292 r:0.6853
si_en Dev loss: 0.7510 r:0.5952
ne_en Dev loss: 0.4004 r:0.7540
ru_en Dev loss: 0.4763 r:0.7263
Current avg r:0.6128 Best avg r: 0.6252
20:19:54,466 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:12,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:43,94 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3631
en_de Dev loss: 1.1558 r:0.2238
en_zh Dev loss: 0.7255 r:0.4690
ro_en Dev loss: 0.3429 r:0.8149
et_en Dev loss: 0.4287 r:0.6812
si_en Dev loss: 0.6762 r:0.6077
ne_en Dev loss: 0.3631 r:0.7589
ru_en Dev loss: 0.4364 r:0.7350
Current avg r:0.6129 Best avg r: 0.6252
20:26:35,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:53,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:24,605 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3708
en_de Dev loss: 1.1178 r:0.2352
en_zh Dev loss: 0.7024 r:0.4727
ro_en Dev loss: 0.3263 r:0.8164
et_en Dev loss: 0.4102 r:0.6894
si_en Dev loss: 0.6787 r:0.6097
ne_en Dev loss: 0.3638 r:0.7652
ru_en Dev loss: 0.4142 r:0.7421
Current avg r:0.6187 Best avg r: 0.6252
20:33:17,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:35,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:06,279 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3734
en_de Dev loss: 1.1581 r:0.2294
en_zh Dev loss: 0.7156 r:0.4725
ro_en Dev loss: 0.3387 r:0.8146
et_en Dev loss: 0.4010 r:0.6857
si_en Dev loss: 0.7918 r:0.5969
ne_en Dev loss: 0.4280 r:0.7648
ru_en Dev loss: 0.4884 r:0.7225
Current avg r:0.6123 Best avg r: 0.6252
20:39:58,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:16,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:47,642 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3729
en_de Dev loss: 1.1583 r:0.2201
en_zh Dev loss: 0.7489 r:0.4519
ro_en Dev loss: 0.3455 r:0.8080
et_en Dev loss: 0.4279 r:0.6787
si_en Dev loss: 0.7400 r:0.5930
ne_en Dev loss: 0.4366 r:0.7519
ru_en Dev loss: 0.4638 r:0.7141
Current avg r:0.6025 Best avg r: 0.6252
20:46:40,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:58,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:29,12 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3564
en_de Dev loss: 1.1977 r:0.2337
en_zh Dev loss: 0.7762 r:0.4643
ro_en Dev loss: 0.3557 r:0.8127
et_en Dev loss: 0.3964 r:0.6878
si_en Dev loss: 0.7478 r:0.6042
ne_en Dev loss: 0.4639 r:0.7539
ru_en Dev loss: 0.5030 r:0.7119
Current avg r:0.6098 Best avg r: 0.6252
20:53:21,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:39,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:10,489 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3547
en_de Dev loss: 1.0918 r:0.2361
en_zh Dev loss: 0.6886 r:0.4791
ro_en Dev loss: 0.3154 r:0.8165
et_en Dev loss: 0.4127 r:0.6815
si_en Dev loss: 0.6647 r:0.6054
ne_en Dev loss: 0.4060 r:0.7598
ru_en Dev loss: 0.4376 r:0.7205
Current avg r:0.6141 Best avg r: 0.6252
21:00:03,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:21,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:52,496 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3698
en_de Dev loss: 1.2862 r:0.2302
en_zh Dev loss: 0.7957 r:0.4757
ro_en Dev loss: 0.4030 r:0.8140
et_en Dev loss: 0.4423 r:0.6810
si_en Dev loss: 0.8281 r:0.5963
ne_en Dev loss: 0.4315 r:0.7560
ru_en Dev loss: 0.5361 r:0.7130
Current avg r:0.6095 Best avg r: 0.6252
21:06:45,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:03,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:34,558 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3571
en_de Dev loss: 1.1679 r:0.2430
en_zh Dev loss: 0.7276 r:0.4751
ro_en Dev loss: 0.3428 r:0.8210
et_en Dev loss: 0.4327 r:0.6876
si_en Dev loss: 0.6785 r:0.6067
ne_en Dev loss: 0.3941 r:0.7643
ru_en Dev loss: 0.4315 r:0.7343
Current avg r:0.6188 Best avg r: 0.6252
21:13:27,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:45,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:16,532 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3446
en_de Dev loss: 1.2519 r:0.2312
en_zh Dev loss: 0.7649 r:0.4799
ro_en Dev loss: 0.3848 r:0.8213
et_en Dev loss: 0.4205 r:0.6891
si_en Dev loss: 0.7056 r:0.6123
ne_en Dev loss: 0.3886 r:0.7620
ru_en Dev loss: 0.4275 r:0.7469
Current avg r:0.6204 Best avg r: 0.6252
21:20:09,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:27,704 root INFO 
id:ru_en cur r: 0.7592 best r: 0.7592
21:21:27,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:58,608 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3447
en_de Dev loss: 1.1514 r:0.2250
en_zh Dev loss: 0.7218 r:0.4788
ro_en Dev loss: 0.3295 r:0.8196
et_en Dev loss: 0.4552 r:0.6920
si_en Dev loss: 0.6138 r:0.6170
ne_en Dev loss: 0.3509 r:0.7635
ru_en Dev loss: 0.3815 r:0.7579
Current avg r:0.6220 Best avg r: 0.6252
21:26:51,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:09,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:40,180 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3564
en_de Dev loss: 1.2175 r:0.2125
en_zh Dev loss: 0.7652 r:0.4743
ro_en Dev loss: 0.3508 r:0.8171
et_en Dev loss: 0.4147 r:0.6905
si_en Dev loss: 0.7063 r:0.6072
ne_en Dev loss: 0.4262 r:0.7556
ru_en Dev loss: 0.4243 r:0.7534
Current avg r:0.6158 Best avg r: 0.6252
21:33:34,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:52,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:23,120 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3332
en_de Dev loss: 1.2313 r:0.2331
en_zh Dev loss: 0.8017 r:0.4677
ro_en Dev loss: 0.3604 r:0.8148
et_en Dev loss: 0.4127 r:0.6887
si_en Dev loss: 0.8431 r:0.5906
ne_en Dev loss: 0.5267 r:0.7527
ru_en Dev loss: 0.4944 r:0.7302
Current avg r:0.6111 Best avg r: 0.6252
21:40:16,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:34,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:05,76 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3197
en_de Dev loss: 1.2311 r:0.2220
en_zh Dev loss: 0.7720 r:0.4725
ro_en Dev loss: 0.3533 r:0.8194
et_en Dev loss: 0.4595 r:0.6905
si_en Dev loss: 0.6890 r:0.5968
ne_en Dev loss: 0.4233 r:0.7507
ru_en Dev loss: 0.4791 r:0.7276
Current avg r:0.6114 Best avg r: 0.6252
21:46:58,70 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:15,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:46,934 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3095
en_de Dev loss: 1.2055 r:0.2409
en_zh Dev loss: 0.7475 r:0.4818
ro_en Dev loss: 0.3492 r:0.8194
et_en Dev loss: 0.4318 r:0.6878
si_en Dev loss: 0.7934 r:0.5919
ne_en Dev loss: 0.4589 r:0.7545
ru_en Dev loss: 0.4692 r:0.7303
Current avg r:0.6153 Best avg r: 0.6252
21:53:40,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:57,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:28,717 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3068
en_de Dev loss: 1.2089 r:0.2196
en_zh Dev loss: 0.7595 r:0.4784
ro_en Dev loss: 0.3509 r:0.8184
et_en Dev loss: 0.4534 r:0.6942
si_en Dev loss: 0.6631 r:0.6042
ne_en Dev loss: 0.3939 r:0.7593
ru_en Dev loss: 0.4248 r:0.7444
Current avg r:0.6169 Best avg r: 0.6252
22:00:21,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:01:39,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:10,274 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3161
en_de Dev loss: 1.1673 r:0.2310
en_zh Dev loss: 0.7376 r:0.4765
ro_en Dev loss: 0.3439 r:0.8211
et_en Dev loss: 0.4322 r:0.6896
si_en Dev loss: 0.7008 r:0.5982
ne_en Dev loss: 0.3970 r:0.7610
ru_en Dev loss: 0.4342 r:0.7355
Current avg r:0.6161 Best avg r: 0.6252
22:07:03,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:21,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:52,131 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3090
en_de Dev loss: 1.2071 r:0.2264
en_zh Dev loss: 0.7637 r:0.4676
ro_en Dev loss: 0.3704 r:0.8128
et_en Dev loss: 0.4496 r:0.6765
si_en Dev loss: 0.8144 r:0.5851
ne_en Dev loss: 0.5083 r:0.7509
ru_en Dev loss: 0.4891 r:0.7163
Current avg r:0.6051 Best avg r: 0.6252
22:13:45,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:03,201 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:16:34,160 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3005
en_de Dev loss: 1.2112 r:0.2268
en_zh Dev loss: 0.7580 r:0.4661
ro_en Dev loss: 0.3722 r:0.8138
et_en Dev loss: 0.4201 r:0.6812
si_en Dev loss: 0.8082 r:0.5891
ne_en Dev loss: 0.5566 r:0.7536
ru_en Dev loss: 0.4468 r:0.7303
Current avg r:0.6087 Best avg r: 0.6252
22:20:26,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:44,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:15,735 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3127
en_de Dev loss: 1.2791 r:0.2344
en_zh Dev loss: 0.8136 r:0.4634
ro_en Dev loss: 0.4038 r:0.8147
et_en Dev loss: 0.4473 r:0.6751
si_en Dev loss: 0.8916 r:0.6019
ne_en Dev loss: 0.5900 r:0.7557
ru_en Dev loss: 0.5403 r:0.7130
Current avg r:0.6083 Best avg r: 0.6252
22:27:08,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:26,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:57,321 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3048
en_de Dev loss: 1.2110 r:0.2320
en_zh Dev loss: 0.7580 r:0.4680
ro_en Dev loss: 0.3611 r:0.8185
et_en Dev loss: 0.4375 r:0.6784
si_en Dev loss: 0.7722 r:0.5937
ne_en Dev loss: 0.4736 r:0.7548
ru_en Dev loss: 0.4734 r:0.7229
Current avg r:0.6097 Best avg r: 0.6252
22:33:50,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:07,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:38,877 root INFO Epoch 4 Global steps: 42000 Train loss: 0.2982
en_de Dev loss: 1.2422 r:0.2361
en_zh Dev loss: 0.7972 r:0.4701
ro_en Dev loss: 0.3639 r:0.8188
et_en Dev loss: 0.4400 r:0.6719
si_en Dev loss: 0.8892 r:0.5881
ne_en Dev loss: 0.4932 r:0.7586
ru_en Dev loss: 0.5265 r:0.7162
Current avg r:0.6085 Best avg r: 0.6252
22:40:31,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:49,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:43:20,376 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3113
en_de Dev loss: 1.1760 r:0.2386
en_zh Dev loss: 0.7568 r:0.4784
ro_en Dev loss: 0.3498 r:0.8182
et_en Dev loss: 0.4565 r:0.6839
si_en Dev loss: 0.7053 r:0.6002
ne_en Dev loss: 0.4305 r:0.7542
ru_en Dev loss: 0.4408 r:0.7309
Current avg r:0.6149 Best avg r: 0.6252
22:47:13,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:31,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:01,872 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3048
en_de Dev loss: 1.2753 r:0.2236
en_zh Dev loss: 0.8162 r:0.4545
ro_en Dev loss: 0.3812 r:0.8131
et_en Dev loss: 0.4591 r:0.6650
si_en Dev loss: 0.8585 r:0.5834
ne_en Dev loss: 0.5167 r:0.7483
ru_en Dev loss: 0.5568 r:0.7008
Current avg r:0.5984 Best avg r: 0.6252
22:53:54,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:12,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:43,855 root INFO Epoch 4 Global steps: 43800 Train loss: 0.2884
en_de Dev loss: 1.1951 r:0.2229
en_zh Dev loss: 0.7503 r:0.4696
ro_en Dev loss: 0.3427 r:0.8163
et_en Dev loss: 0.4552 r:0.6770
si_en Dev loss: 0.6524 r:0.5965
ne_en Dev loss: 0.3980 r:0.7461
ru_en Dev loss: 0.4209 r:0.7394
Current avg r:0.6097 Best avg r: 0.6252
23:00:36,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:54,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:25,519 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3007
en_de Dev loss: 1.2809 r:0.2382
en_zh Dev loss: 0.8046 r:0.4592
ro_en Dev loss: 0.4105 r:0.8086
et_en Dev loss: 0.4591 r:0.6603
si_en Dev loss: 0.9433 r:0.5661
ne_en Dev loss: 0.5308 r:0.7485
ru_en Dev loss: 0.5344 r:0.7045
Current avg r:0.5979 Best avg r: 0.6252
23:07:18,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:36,623 root INFO 
id:ru_en cur r: 0.7634 best r: 0.7634
23:08:36,626 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:07,543 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3005
en_de Dev loss: 1.1958 r:0.2267
en_zh Dev loss: 0.7291 r:0.4754
ro_en Dev loss: 0.3236 r:0.8204
et_en Dev loss: 0.4387 r:0.6753
si_en Dev loss: 0.7080 r:0.5955
ne_en Dev loss: 0.3817 r:0.7554
ru_en Dev loss: 0.3815 r:0.7582
Current avg r:0.6153 Best avg r: 0.6252
23:14:01,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:19,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:50,570 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2734
en_de Dev loss: 1.2540 r:0.2250
en_zh Dev loss: 0.7577 r:0.4737
ro_en Dev loss: 0.3888 r:0.8121
et_en Dev loss: 0.4608 r:0.6654
si_en Dev loss: 0.8090 r:0.5785
ne_en Dev loss: 0.4741 r:0.7440
ru_en Dev loss: 0.5049 r:0.7141
Current avg r:0.6018 Best avg r: 0.6252
23:20:43,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:01,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:32,396 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2673
en_de Dev loss: 1.2574 r:0.2219
en_zh Dev loss: 0.7647 r:0.4706
ro_en Dev loss: 0.3728 r:0.8161
et_en Dev loss: 0.4331 r:0.6738
si_en Dev loss: 0.7647 r:0.5862
ne_en Dev loss: 0.5242 r:0.7454
ru_en Dev loss: 0.4746 r:0.7256
Current avg r:0.6056 Best avg r: 0.6252
23:27:25,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:43,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:14,81 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2778
en_de Dev loss: 1.2135 r:0.2127
en_zh Dev loss: 0.7493 r:0.4687
ro_en Dev loss: 0.3375 r:0.8136
et_en Dev loss: 0.4479 r:0.6723
si_en Dev loss: 0.7193 r:0.5868
ne_en Dev loss: 0.4847 r:0.7479
ru_en Dev loss: 0.4717 r:0.7138
Current avg r:0.6023 Best avg r: 0.6252
23:34:07,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:24,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:55,829 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2609
en_de Dev loss: 1.2168 r:0.2201
en_zh Dev loss: 0.7619 r:0.4587
ro_en Dev loss: 0.3635 r:0.8118
et_en Dev loss: 0.4399 r:0.6584
si_en Dev loss: 0.8787 r:0.5730
ne_en Dev loss: 0.5531 r:0.7435
ru_en Dev loss: 0.4737 r:0.7171
Current avg r:0.5975 Best avg r: 0.6252
23:40:48,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:06,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:37,501 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2708
en_de Dev loss: 1.2084 r:0.2188
en_zh Dev loss: 0.7726 r:0.4637
ro_en Dev loss: 0.3406 r:0.8172
et_en Dev loss: 0.4388 r:0.6798
si_en Dev loss: 0.7264 r:0.5892
ne_en Dev loss: 0.4547 r:0.7376
ru_en Dev loss: 0.4968 r:0.7059
Current avg r:0.6017 Best avg r: 0.6252
23:47:30,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:47,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:18,789 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2734
en_de Dev loss: 1.2753 r:0.2252
en_zh Dev loss: 0.8091 r:0.4590
ro_en Dev loss: 0.3752 r:0.8130
et_en Dev loss: 0.4208 r:0.6775
si_en Dev loss: 0.9220 r:0.5790
ne_en Dev loss: 0.5153 r:0.7473
ru_en Dev loss: 0.4958 r:0.7240
Current avg r:0.6036 Best avg r: 0.6252
23:54:11,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:29,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:00,254 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2563
en_de Dev loss: 1.3071 r:0.2281
en_zh Dev loss: 0.8248 r:0.4524
ro_en Dev loss: 0.3904 r:0.8145
et_en Dev loss: 0.4322 r:0.6720
si_en Dev loss: 0.9076 r:0.5752
ne_en Dev loss: 0.5709 r:0.7374
ru_en Dev loss: 0.5427 r:0.7150
Current avg r:0.5992 Best avg r: 0.6252
00:00:52,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:10,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:41,713 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2649
en_de Dev loss: 1.2811 r:0.2276
en_zh Dev loss: 0.8049 r:0.4552
ro_en Dev loss: 0.3726 r:0.8156
et_en Dev loss: 0.4561 r:0.6700
si_en Dev loss: 0.8996 r:0.5734
ne_en Dev loss: 0.5577 r:0.7420
ru_en Dev loss: 0.4666 r:0.7312
Current avg r:0.6021 Best avg r: 0.6252
00:07:34,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:08:52,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:23,52 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2626
en_de Dev loss: 1.2547 r:0.2148
en_zh Dev loss: 0.7751 r:0.4607
ro_en Dev loss: 0.3718 r:0.8137
et_en Dev loss: 0.4556 r:0.6660
si_en Dev loss: 0.8008 r:0.5815
ne_en Dev loss: 0.4670 r:0.7436
ru_en Dev loss: 0.5024 r:0.7104
Current avg r:0.5987 Best avg r: 0.6252
00:14:15,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:15:33,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:17:04,322 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2659
en_de Dev loss: 1.2982 r:0.2138
en_zh Dev loss: 0.8123 r:0.4604
ro_en Dev loss: 0.3967 r:0.8119
et_en Dev loss: 0.4575 r:0.6651
si_en Dev loss: 0.8638 r:0.5793
ne_en Dev loss: 0.5129 r:0.7372
ru_en Dev loss: 0.5323 r:0.7101
Current avg r:0.5968 Best avg r: 0.6252
00:20:57,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:14,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:45,684 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2579
en_de Dev loss: 1.2859 r:0.2162
en_zh Dev loss: 0.7984 r:0.4596
ro_en Dev loss: 0.3770 r:0.8136
et_en Dev loss: 0.4500 r:0.6672
si_en Dev loss: 0.8658 r:0.5788
ne_en Dev loss: 0.4755 r:0.7469
ru_en Dev loss: 0.5206 r:0.7052
Current avg r:0.5982 Best avg r: 0.6252
00:27:38,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:56,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:26,999 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2536
en_de Dev loss: 1.3137 r:0.1956
en_zh Dev loss: 0.8271 r:0.4501
ro_en Dev loss: 0.3911 r:0.8108
et_en Dev loss: 0.4671 r:0.6642
si_en Dev loss: 0.7953 r:0.5766
ne_en Dev loss: 0.4868 r:0.7358
ru_en Dev loss: 0.5141 r:0.7063
Current avg r:0.5913 Best avg r: 0.6252
00:34:19,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:37,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:08,467 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2544
en_de Dev loss: 1.2676 r:0.2060
en_zh Dev loss: 0.7727 r:0.4730
ro_en Dev loss: 0.3681 r:0.8168
et_en Dev loss: 0.4870 r:0.6851
si_en Dev loss: 0.7818 r:0.5834
ne_en Dev loss: 0.4017 r:0.7494
ru_en Dev loss: 0.4140 r:0.7486
Current avg r:0.6089 Best avg r: 0.6252
00:41:01,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:19,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:49,972 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2591
en_de Dev loss: 1.1741 r:0.2129
en_zh Dev loss: 0.7417 r:0.4675
ro_en Dev loss: 0.3224 r:0.8166
et_en Dev loss: 0.4393 r:0.6740
si_en Dev loss: 0.7146 r:0.5822
ne_en Dev loss: 0.4123 r:0.7459
ru_en Dev loss: 0.4065 r:0.7455
Current avg r:0.6064 Best avg r: 0.6252
00:47:42,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:00,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:31,714 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2430
en_de Dev loss: 1.2386 r:0.2094
en_zh Dev loss: 0.7844 r:0.4626
ro_en Dev loss: 0.3625 r:0.8122
et_en Dev loss: 0.4895 r:0.6735
si_en Dev loss: 0.8036 r:0.5813
ne_en Dev loss: 0.4283 r:0.7458
ru_en Dev loss: 0.4348 r:0.7348
Current avg r:0.6028 Best avg r: 0.6252
00:54:26,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:44,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:14,956 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2280
en_de Dev loss: 1.2759 r:0.2068
en_zh Dev loss: 0.8073 r:0.4550
ro_en Dev loss: 0.3616 r:0.8145
et_en Dev loss: 0.4561 r:0.6665
si_en Dev loss: 0.9345 r:0.5676
ne_en Dev loss: 0.5458 r:0.7430
ru_en Dev loss: 0.4564 r:0.7296
Current avg r:0.5976 Best avg r: 0.6252
01:01:07,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:02:25,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:56,283 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2334
en_de Dev loss: 1.2038 r:0.2013
en_zh Dev loss: 0.7555 r:0.4694
ro_en Dev loss: 0.3486 r:0.8129
et_en Dev loss: 0.4789 r:0.6678
si_en Dev loss: 0.8029 r:0.5713
ne_en Dev loss: 0.4405 r:0.7370
ru_en Dev loss: 0.4180 r:0.7379
Current avg r:0.5997 Best avg r: 0.6252
01:07:49,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:07,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:38,8 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2272
en_de Dev loss: 1.2891 r:0.2183
en_zh Dev loss: 0.7890 r:0.4695
ro_en Dev loss: 0.3797 r:0.8170
et_en Dev loss: 0.4701 r:0.6631
si_en Dev loss: 0.8213 r:0.5739
ne_en Dev loss: 0.5044 r:0.7384
ru_en Dev loss: 0.4860 r:0.7237
Current avg r:0.6006 Best avg r: 0.6252
01:14:30,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:48,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:19,492 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2235
en_de Dev loss: 1.2728 r:0.2346
en_zh Dev loss: 0.8020 r:0.4717
ro_en Dev loss: 0.3655 r:0.8178
et_en Dev loss: 0.4522 r:0.6750
si_en Dev loss: 0.8904 r:0.5720
ne_en Dev loss: 0.4912 r:0.7395
ru_en Dev loss: 0.4692 r:0.7360
Current avg r:0.6067 Best avg r: 0.6252
01:21:12,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:22:30,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:00,824 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2342
en_de Dev loss: 1.2557 r:0.2156
en_zh Dev loss: 0.7737 r:0.4691
ro_en Dev loss: 0.3704 r:0.8127
et_en Dev loss: 0.4834 r:0.6592
si_en Dev loss: 0.8929 r:0.5619
ne_en Dev loss: 0.5075 r:0.7367
ru_en Dev loss: 0.4552 r:0.7263
Current avg r:0.5974 Best avg r: 0.6252
01:27:53,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:11,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:42,150 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2291
en_de Dev loss: 1.2601 r:0.2289
en_zh Dev loss: 0.7820 r:0.4788
ro_en Dev loss: 0.3606 r:0.8172
et_en Dev loss: 0.4830 r:0.6756
si_en Dev loss: 0.8332 r:0.5686
ne_en Dev loss: 0.4626 r:0.7375
ru_en Dev loss: 0.4745 r:0.7300
Current avg r:0.6052 Best avg r: 0.6252
01:34:34,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:52,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:23,497 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2241
en_de Dev loss: 1.2603 r:0.2205
en_zh Dev loss: 0.7732 r:0.4665
ro_en Dev loss: 0.3586 r:0.8162
et_en Dev loss: 0.5004 r:0.6718
si_en Dev loss: 0.8261 r:0.5632
ne_en Dev loss: 0.4452 r:0.7379
ru_en Dev loss: 0.4623 r:0.7259
Current avg r:0.6003 Best avg r: 0.6252
01:41:16,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:33,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:44:04,659 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2220
en_de Dev loss: 1.2796 r:0.2172
en_zh Dev loss: 0.7983 r:0.4644
ro_en Dev loss: 0.3747 r:0.8126
et_en Dev loss: 0.4704 r:0.6638
si_en Dev loss: 0.8947 r:0.5563
ne_en Dev loss: 0.5465 r:0.7458
ru_en Dev loss: 0.5162 r:0.7083
Current avg r:0.5955 Best avg r: 0.6252
01:47:57,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:49:14,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:50:45,557 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2263
en_de Dev loss: 1.2803 r:0.2014
en_zh Dev loss: 0.7550 r:0.4818
ro_en Dev loss: 0.3610 r:0.8201
et_en Dev loss: 0.4943 r:0.6712
si_en Dev loss: 0.7996 r:0.5658
ne_en Dev loss: 0.4689 r:0.7393
ru_en Dev loss: 0.4378 r:0.7359
Current avg r:0.6022 Best avg r: 0.6252
01:54:37,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:55:55,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:57:26,410 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2148
en_de Dev loss: 1.2777 r:0.2027
en_zh Dev loss: 0.7819 r:0.4710
ro_en Dev loss: 0.3724 r:0.8141
et_en Dev loss: 0.4823 r:0.6630
si_en Dev loss: 0.8869 r:0.5502
ne_en Dev loss: 0.4400 r:0.7298
ru_en Dev loss: 0.4897 r:0.7193
Current avg r:0.5929 Best avg r: 0.6252
02:01:23,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:02:41,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:04:14,58 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2156
en_de Dev loss: 1.2728 r:0.2095
en_zh Dev loss: 0.7899 r:0.4649
ro_en Dev loss: 0.3572 r:0.8185
et_en Dev loss: 0.4965 r:0.6665
si_en Dev loss: 0.8402 r:0.5593
ne_en Dev loss: 0.4630 r:0.7404
ru_en Dev loss: 0.4295 r:0.7472
Current avg r:0.6009 Best avg r: 0.6252
02:08:11,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:09:30,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:11:02,607 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2212
en_de Dev loss: 1.2583 r:0.1923
en_zh Dev loss: 0.7863 r:0.4550
ro_en Dev loss: 0.3429 r:0.8172
et_en Dev loss: 0.4649 r:0.6592
si_en Dev loss: 0.8656 r:0.5555
ne_en Dev loss: 0.4624 r:0.7389
ru_en Dev loss: 0.4428 r:0.7371
Current avg r:0.5936 Best avg r: 0.6252
02:15:00,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:18,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:17:50,885 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2071
en_de Dev loss: 1.3010 r:0.1954
en_zh Dev loss: 0.8239 r:0.4565
ro_en Dev loss: 0.3648 r:0.8169
et_en Dev loss: 0.4966 r:0.6596
si_en Dev loss: 0.8909 r:0.5551
ne_en Dev loss: 0.5010 r:0.7369
ru_en Dev loss: 0.4705 r:0.7308
Current avg r:0.5930 Best avg r: 0.6252
02:21:48,403 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:23:07,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:24:39,208 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2158
en_de Dev loss: 1.2062 r:0.2007
en_zh Dev loss: 0.7507 r:0.4651
ro_en Dev loss: 0.3087 r:0.8226
et_en Dev loss: 0.4474 r:0.6761
si_en Dev loss: 0.7122 r:0.5751
ne_en Dev loss: 0.3986 r:0.7373
ru_en Dev loss: 0.3943 r:0.7549
Current avg r:0.6045 Best avg r: 0.6252
02:28:36,553 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:55,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:31:26,443 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2162
en_de Dev loss: 1.2233 r:0.1977
en_zh Dev loss: 0.7803 r:0.4647
ro_en Dev loss: 0.3557 r:0.8132
et_en Dev loss: 0.5294 r:0.6745
si_en Dev loss: 0.7644 r:0.5719
ne_en Dev loss: 0.4530 r:0.7336
ru_en Dev loss: 0.4351 r:0.7330
Current avg r:0.5984 Best avg r: 0.6252
02:35:21,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:39,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:10,32 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1986
en_de Dev loss: 1.2704 r:0.2204
en_zh Dev loss: 0.8035 r:0.4651
ro_en Dev loss: 0.3729 r:0.8164
et_en Dev loss: 0.4883 r:0.6722
si_en Dev loss: 0.9053 r:0.5643
ne_en Dev loss: 0.5084 r:0.7394
ru_en Dev loss: 0.4516 r:0.7437
Current avg r:0.6031 Best avg r: 0.6252
02:42:03,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:21,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:52,53 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1890
en_de Dev loss: 1.3144 r:0.2047
en_zh Dev loss: 0.8338 r:0.4574
ro_en Dev loss: 0.3932 r:0.8108
et_en Dev loss: 0.5009 r:0.6544
si_en Dev loss: 0.9289 r:0.5564
ne_en Dev loss: 0.5347 r:0.7399
ru_en Dev loss: 0.5151 r:0.7214
Current avg r:0.5921 Best avg r: 0.6252
02:48:45,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:03,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:34,35 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1870
en_de Dev loss: 1.2745 r:0.2125
en_zh Dev loss: 0.8138 r:0.4597
ro_en Dev loss: 0.3734 r:0.8102
et_en Dev loss: 0.4764 r:0.6454
si_en Dev loss: 1.0674 r:0.5413
ne_en Dev loss: 0.6197 r:0.7322
ru_en Dev loss: 0.5317 r:0.7106
Current avg r:0.5874 Best avg r: 0.6252
02:55:27,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:45,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:58:16,303 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1951
en_de Dev loss: 1.2377 r:0.1988
en_zh Dev loss: 0.7683 r:0.4722
ro_en Dev loss: 0.3584 r:0.8121
et_en Dev loss: 0.4897 r:0.6607
si_en Dev loss: 0.8513 r:0.5585
ne_en Dev loss: 0.5453 r:0.7369
ru_en Dev loss: 0.4389 r:0.7352
Current avg r:0.5963 Best avg r: 0.6252
03:02:10,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:29,405 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:05:01,239 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1938
en_de Dev loss: 1.2711 r:0.2017
en_zh Dev loss: 0.7718 r:0.4760
ro_en Dev loss: 0.3734 r:0.8115
et_en Dev loss: 0.4778 r:0.6523
si_en Dev loss: 0.8499 r:0.5627
ne_en Dev loss: 0.5483 r:0.7343
ru_en Dev loss: 0.4578 r:0.7365
Current avg r:0.5964 Best avg r: 0.6252
03:08:58,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:17,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:49,94 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1973
en_de Dev loss: 1.2753 r:0.2034
en_zh Dev loss: 0.7898 r:0.4651
ro_en Dev loss: 0.3835 r:0.8122
et_en Dev loss: 0.5013 r:0.6552
si_en Dev loss: 0.9073 r:0.5589
ne_en Dev loss: 0.4829 r:0.7363
ru_en Dev loss: 0.4868 r:0.7249
Current avg r:0.5937 Best avg r: 0.6252
03:15:46,35 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:17:04,830 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:18:36,738 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1894
en_de Dev loss: 1.2775 r:0.1931
en_zh Dev loss: 0.7865 r:0.4674
ro_en Dev loss: 0.3699 r:0.8144
et_en Dev loss: 0.4777 r:0.6528
si_en Dev loss: 0.8559 r:0.5620
ne_en Dev loss: 0.5147 r:0.7345
ru_en Dev loss: 0.4707 r:0.7254
Current avg r:0.5928 Best avg r: 0.6252
03:22:33,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:23:52,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:24,35 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1894
en_de Dev loss: 1.3077 r:0.2034
en_zh Dev loss: 0.8313 r:0.4684
ro_en Dev loss: 0.3942 r:0.8112
et_en Dev loss: 0.5197 r:0.6542
si_en Dev loss: 0.8711 r:0.5589
ne_en Dev loss: 0.4889 r:0.7366
ru_en Dev loss: 0.4551 r:0.7354
Current avg r:0.5955 Best avg r: 0.6252
03:29:18,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:30:36,466 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:32:07,568 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1931
en_de Dev loss: 1.2377 r:0.2020
en_zh Dev loss: 0.8030 r:0.4536
ro_en Dev loss: 0.3532 r:0.8123
et_en Dev loss: 0.4811 r:0.6502
si_en Dev loss: 0.9176 r:0.5460
ne_en Dev loss: 0.5018 r:0.7323
ru_en Dev loss: 0.4301 r:0.7333
Current avg r:0.5899 Best avg r: 0.6252
03:36:00,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:19,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:50,188 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1879
en_de Dev loss: 1.3158 r:0.2016
en_zh Dev loss: 0.8357 r:0.4604
ro_en Dev loss: 0.3845 r:0.8121
et_en Dev loss: 0.5038 r:0.6508
si_en Dev loss: 0.9054 r:0.5433
ne_en Dev loss: 0.5369 r:0.7246
ru_en Dev loss: 0.4744 r:0.7281
Current avg r:0.5887 Best avg r: 0.6252
03:42:43,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:01,800 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:32,922 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1871
en_de Dev loss: 1.2866 r:0.2071
en_zh Dev loss: 0.8288 r:0.4562
ro_en Dev loss: 0.3827 r:0.8101
et_en Dev loss: 0.4963 r:0.6466
si_en Dev loss: 0.9219 r:0.5460
ne_en Dev loss: 0.5731 r:0.7309
ru_en Dev loss: 0.5006 r:0.7142
Current avg r:0.5873 Best avg r: 0.6252
03:49:26,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:50:44,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:15,669 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1814
en_de Dev loss: 1.3155 r:0.2060
en_zh Dev loss: 0.8361 r:0.4564
ro_en Dev loss: 0.3825 r:0.8148
et_en Dev loss: 0.4964 r:0.6469
si_en Dev loss: 0.9862 r:0.5379
ne_en Dev loss: 0.5994 r:0.7237
ru_en Dev loss: 0.4789 r:0.7254
Current avg r:0.5873 Best avg r: 0.6252
03:56:09,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:27,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:58:58,939 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1845
en_de Dev loss: 1.2625 r:0.2102
en_zh Dev loss: 0.8224 r:0.4546
ro_en Dev loss: 0.3544 r:0.8146
et_en Dev loss: 0.4802 r:0.6568
si_en Dev loss: 0.8326 r:0.5451
ne_en Dev loss: 0.5228 r:0.7289
ru_en Dev loss: 0.4620 r:0.7308
Current avg r:0.5916 Best avg r: 0.6252
04:02:55,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:14,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:05:46,194 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1809
en_de Dev loss: 1.3120 r:0.2080
en_zh Dev loss: 0.8361 r:0.4623
ro_en Dev loss: 0.3880 r:0.8094
et_en Dev loss: 0.5111 r:0.6454
si_en Dev loss: 0.9040 r:0.5417
ne_en Dev loss: 0.5411 r:0.7230
ru_en Dev loss: 0.4911 r:0.7291
Current avg r:0.5884 Best avg r: 0.6252
04:09:43,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:11:02,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:12:34,37 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1856
en_de Dev loss: 1.2669 r:0.2192
en_zh Dev loss: 0.8080 r:0.4604
ro_en Dev loss: 0.3942 r:0.8105
et_en Dev loss: 0.5080 r:0.6448
si_en Dev loss: 0.9057 r:0.5406
ne_en Dev loss: 0.5729 r:0.7257
ru_en Dev loss: 0.4892 r:0.7204
Current avg r:0.5888 Best avg r: 0.6252
04:16:32,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:17:51,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:23,543 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1592
en_de Dev loss: 1.2581 r:0.2082
en_zh Dev loss: 0.7890 r:0.4713
ro_en Dev loss: 0.3755 r:0.8119
et_en Dev loss: 0.5289 r:0.6560
si_en Dev loss: 0.8335 r:0.5504
ne_en Dev loss: 0.5063 r:0.7296
ru_en Dev loss: 0.4169 r:0.7510
Current avg r:0.5969 Best avg r: 0.6252
04:23:19,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:24:38,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:26:10,193 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1671
en_de Dev loss: 1.2291 r:0.2103
en_zh Dev loss: 0.7860 r:0.4666
ro_en Dev loss: 0.3516 r:0.8163
et_en Dev loss: 0.5008 r:0.6547
si_en Dev loss: 0.8241 r:0.5489
ne_en Dev loss: 0.4658 r:0.7315
ru_en Dev loss: 0.4205 r:0.7437
Current avg r:0.5960 Best avg r: 0.6252
04:30:03,245 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:31:21,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:32:52,220 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1637
en_de Dev loss: 1.2665 r:0.2193
en_zh Dev loss: 0.8035 r:0.4625
ro_en Dev loss: 0.3737 r:0.8115
et_en Dev loss: 0.5084 r:0.6491
si_en Dev loss: 0.8582 r:0.5451
ne_en Dev loss: 0.4821 r:0.7265
ru_en Dev loss: 0.4782 r:0.7295
Current avg r:0.5919 Best avg r: 0.6252
04:36:45,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:38:03,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:39:34,390 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1746
en_de Dev loss: 1.2833 r:0.2152
en_zh Dev loss: 0.8153 r:0.4568
ro_en Dev loss: 0.3852 r:0.8090
et_en Dev loss: 0.5047 r:0.6504
si_en Dev loss: 0.8780 r:0.5459
ne_en Dev loss: 0.5191 r:0.7274
ru_en Dev loss: 0.4815 r:0.7288
Current avg r:0.5905 Best avg r: 0.6252
04:43:28,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:46,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:46:17,151 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1623
en_de Dev loss: 1.2489 r:0.2069
en_zh Dev loss: 0.7961 r:0.4676
ro_en Dev loss: 0.3840 r:0.8054
et_en Dev loss: 0.5276 r:0.6487
si_en Dev loss: 0.8470 r:0.5453
ne_en Dev loss: 0.5224 r:0.7288
ru_en Dev loss: 0.4261 r:0.7429
Current avg r:0.5922 Best avg r: 0.6252
04:50:10,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:51:28,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:52:59,563 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1693
en_de Dev loss: 1.2247 r:0.2184
en_zh Dev loss: 0.8007 r:0.4709
ro_en Dev loss: 0.3595 r:0.8104
et_en Dev loss: 0.5057 r:0.6533
si_en Dev loss: 0.8187 r:0.5523
ne_en Dev loss: 0.4937 r:0.7262
ru_en Dev loss: 0.4474 r:0.7314
Current avg r:0.5947 Best avg r: 0.6252
04:56:54,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:58:12,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:59:44,271 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1619
en_de Dev loss: 1.2819 r:0.2011
en_zh Dev loss: 0.8258 r:0.4582
ro_en Dev loss: 0.3833 r:0.8106
et_en Dev loss: 0.4907 r:0.6470
si_en Dev loss: 0.9157 r:0.5438
ne_en Dev loss: 0.5437 r:0.7262
ru_en Dev loss: 0.4842 r:0.7270
Current avg r:0.5877 Best avg r: 0.6252
05:03:41,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:05:00,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:06:32,45 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1665
en_de Dev loss: 1.3160 r:0.1993
en_zh Dev loss: 0.8532 r:0.4567
ro_en Dev loss: 0.3754 r:0.8098
et_en Dev loss: 0.5143 r:0.6519
si_en Dev loss: 0.9796 r:0.5412
ne_en Dev loss: 0.6228 r:0.7216
ru_en Dev loss: 0.4790 r:0.7283
Current avg r:0.5870 Best avg r: 0.6252
05:10:28,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:11:47,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:13:19,487 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1657
en_de Dev loss: 1.2500 r:0.2140
en_zh Dev loss: 0.8228 r:0.4468
ro_en Dev loss: 0.3794 r:0.8111
et_en Dev loss: 0.4995 r:0.6410
si_en Dev loss: 0.9454 r:0.5348
ne_en Dev loss: 0.5711 r:0.7249
ru_en Dev loss: 0.4892 r:0.7183
Current avg r:0.5844 Best avg r: 0.6252
05:17:16,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:18:35,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:20:07,488 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1661
en_de Dev loss: 1.2126 r:0.2059
en_zh Dev loss: 0.7572 r:0.4719
ro_en Dev loss: 0.3464 r:0.8162
et_en Dev loss: 0.4668 r:0.6545
si_en Dev loss: 0.8727 r:0.5495
ne_en Dev loss: 0.4902 r:0.7340
ru_en Dev loss: 0.4109 r:0.7505
Current avg r:0.5975 Best avg r: 0.6252
05:24:04,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:25:23,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:55,307 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1642
en_de Dev loss: 1.3372 r:0.2047
en_zh Dev loss: 0.8851 r:0.4495
ro_en Dev loss: 0.4062 r:0.8100
et_en Dev loss: 0.5208 r:0.6324
si_en Dev loss: 0.9456 r:0.5454
ne_en Dev loss: 0.6161 r:0.7241
ru_en Dev loss: 0.5179 r:0.7121
Current avg r:0.5826 Best avg r: 0.6252
05:30:51,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:32:10,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:33:42,43 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1687
en_de Dev loss: 1.2007 r:0.2192
en_zh Dev loss: 0.7461 r:0.4704
ro_en Dev loss: 0.3353 r:0.8201
et_en Dev loss: 0.4534 r:0.6546
si_en Dev loss: 0.8518 r:0.5612
ne_en Dev loss: 0.4671 r:0.7303
ru_en Dev loss: 0.4338 r:0.7369
Current avg r:0.5989 Best avg r: 0.6252
05:37:38,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:38:57,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:40:28,697 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1570
en_de Dev loss: 1.3761 r:0.2092
en_zh Dev loss: 0.8766 r:0.4628
ro_en Dev loss: 0.4481 r:0.8071
et_en Dev loss: 0.5134 r:0.6414
si_en Dev loss: 1.0341 r:0.5418
ne_en Dev loss: 0.6070 r:0.7260
ru_en Dev loss: 0.5352 r:0.7221
Current avg r:0.5872 Best avg r: 0.6252
05:44:22,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:45:40,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:47:11,513 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1665
en_de Dev loss: 1.2526 r:0.2274
en_zh Dev loss: 0.8350 r:0.4521
ro_en Dev loss: 0.3907 r:0.8086
et_en Dev loss: 0.4989 r:0.6477
si_en Dev loss: 0.9407 r:0.5401
ne_en Dev loss: 0.5624 r:0.7316
ru_en Dev loss: 0.4839 r:0.7308
Current avg r:0.5912 Best avg r: 0.6252
05:51:05,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:24,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:55,945 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1594
en_de Dev loss: 1.2598 r:0.2118
en_zh Dev loss: 0.8051 r:0.4716
ro_en Dev loss: 0.3698 r:0.8149
et_en Dev loss: 0.5192 r:0.6505
si_en Dev loss: 0.9254 r:0.5435
ne_en Dev loss: 0.5250 r:0.7265
ru_en Dev loss: 0.4473 r:0.7428
Current avg r:0.5945 Best avg r: 0.6252
05:57:51,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:10,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:00:42,699 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1476
en_de Dev loss: 1.2818 r:0.1999
en_zh Dev loss: 0.8301 r:0.4533
ro_en Dev loss: 0.3838 r:0.8067
et_en Dev loss: 0.5047 r:0.6342
si_en Dev loss: 0.9652 r:0.5460
ne_en Dev loss: 0.5564 r:0.7209
ru_en Dev loss: 0.5112 r:0.7130
Current avg r:0.5820 Best avg r: 0.6252
06:04:39,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:05:58,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:07:30,440 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1597
en_de Dev loss: 1.3160 r:0.2103
en_zh Dev loss: 0.8537 r:0.4532
ro_en Dev loss: 0.4158 r:0.8071
et_en Dev loss: 0.5590 r:0.6333
si_en Dev loss: 0.9585 r:0.5411
ne_en Dev loss: 0.6258 r:0.7162
ru_en Dev loss: 0.4950 r:0.7219
Current avg r:0.5833 Best avg r: 0.6252
06:11:27,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:12:45,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:14:17,547 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1576
en_de Dev loss: 1.2283 r:0.2076
en_zh Dev loss: 0.7784 r:0.4602
ro_en Dev loss: 0.3499 r:0.8132
et_en Dev loss: 0.4917 r:0.6460
si_en Dev loss: 0.7949 r:0.5585
ne_en Dev loss: 0.5325 r:0.7239
ru_en Dev loss: 0.4283 r:0.7406
Current avg r:0.5929 Best avg r: 0.6252
06:18:13,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:19:31,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:21:03,763 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1484
en_de Dev loss: 1.3273 r:0.2003
en_zh Dev loss: 0.8560 r:0.4543
ro_en Dev loss: 0.3861 r:0.8115
et_en Dev loss: 0.4984 r:0.6376
si_en Dev loss: 0.9696 r:0.5389
ne_en Dev loss: 0.6470 r:0.7271
ru_en Dev loss: 0.5097 r:0.7190
Current avg r:0.5841 Best avg r: 0.6252
06:24:58,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:26:16,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:27:47,813 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1481
en_de Dev loss: 1.2889 r:0.2062
en_zh Dev loss: 0.8249 r:0.4634
ro_en Dev loss: 0.3834 r:0.8124
et_en Dev loss: 0.5176 r:0.6409
si_en Dev loss: 0.9655 r:0.5424
ne_en Dev loss: 0.5793 r:0.7285
ru_en Dev loss: 0.4563 r:0.7387
Current avg r:0.5904 Best avg r: 0.6252
06:31:41,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:32:59,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:34:30,426 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1440
en_de Dev loss: 1.2949 r:0.1998
en_zh Dev loss: 0.8325 r:0.4658
ro_en Dev loss: 0.3767 r:0.8101
et_en Dev loss: 0.5180 r:0.6365
si_en Dev loss: 0.9431 r:0.5440
ne_en Dev loss: 0.6747 r:0.7208
ru_en Dev loss: 0.4728 r:0.7262
Current avg r:0.5862 Best avg r: 0.6252
06:38:24,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:39:42,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:41:13,262 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1579
en_de Dev loss: 1.2126 r:0.2002
en_zh Dev loss: 0.7739 r:0.4719
ro_en Dev loss: 0.3605 r:0.8122
et_en Dev loss: 0.5237 r:0.6409
si_en Dev loss: 0.8511 r:0.5520
ne_en Dev loss: 0.5166 r:0.7230
ru_en Dev loss: 0.4406 r:0.7284
Current avg r:0.5898 Best avg r: 0.6252
06:45:07,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:46:25,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:47:57,278 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1406
en_de Dev loss: 1.2492 r:0.2048
en_zh Dev loss: 0.7971 r:0.4630
ro_en Dev loss: 0.3570 r:0.8160
et_en Dev loss: 0.5260 r:0.6450
si_en Dev loss: 0.8886 r:0.5571
ne_en Dev loss: 0.5247 r:0.7204
ru_en Dev loss: 0.4265 r:0.7418
Current avg r:0.5926 Best avg r: 0.6252
06:51:52,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:53:10,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:54:42,261 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1467
en_de Dev loss: 1.2246 r:0.2079
en_zh Dev loss: 0.7845 r:0.4649
ro_en Dev loss: 0.3625 r:0.8137
et_en Dev loss: 0.5116 r:0.6488
si_en Dev loss: 0.8887 r:0.5519
ne_en Dev loss: 0.5149 r:0.7299
ru_en Dev loss: 0.4089 r:0.7468
Current avg r:0.5949 Best avg r: 0.6252
06:58:39,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:59:57,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:29,897 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1463
en_de Dev loss: 1.3190 r:0.2037
en_zh Dev loss: 0.8400 r:0.4595
ro_en Dev loss: 0.3906 r:0.8106
et_en Dev loss: 0.5090 r:0.6386
si_en Dev loss: 1.0388 r:0.5437
ne_en Dev loss: 0.6146 r:0.7311
ru_en Dev loss: 0.4927 r:0.7307
Current avg r:0.5883 Best avg r: 0.6252
07:05:26,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:06:45,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:17,620 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1474
en_de Dev loss: 1.3119 r:0.1761
en_zh Dev loss: 0.8292 r:0.4585
ro_en Dev loss: 0.3847 r:0.8107
et_en Dev loss: 0.5169 r:0.6419
si_en Dev loss: 0.8909 r:0.5522
ne_en Dev loss: 0.5262 r:0.7289
ru_en Dev loss: 0.4521 r:0.7335
Current avg r:0.5860 Best avg r: 0.6252
07:12:13,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:32,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:04,108 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1594
en_de Dev loss: 1.2748 r:0.2080
en_zh Dev loss: 0.8114 r:0.4577
ro_en Dev loss: 0.3946 r:0.8095
et_en Dev loss: 0.4991 r:0.6360
si_en Dev loss: 1.0488 r:0.5427
ne_en Dev loss: 0.5715 r:0.7319
ru_en Dev loss: 0.4687 r:0.7262
Current avg r:0.5874 Best avg r: 0.6252
07:19:00,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:20:18,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:21:49,917 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1468
en_de Dev loss: 1.2457 r:0.1950
en_zh Dev loss: 0.7667 r:0.4756
ro_en Dev loss: 0.3408 r:0.8177
et_en Dev loss: 0.4931 r:0.6495
si_en Dev loss: 0.8355 r:0.5639
ne_en Dev loss: 0.4992 r:0.7244
ru_en Dev loss: 0.4048 r:0.7570
Current avg r:0.5976 Best avg r: 0.6252
07:25:43,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:27:01,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:28:32,341 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1424
en_de Dev loss: 1.2821 r:0.1976
en_zh Dev loss: 0.7958 r:0.4704
ro_en Dev loss: 0.3707 r:0.8101
et_en Dev loss: 0.5031 r:0.6439
si_en Dev loss: 0.8773 r:0.5576
ne_en Dev loss: 0.5619 r:0.7252
ru_en Dev loss: 0.4762 r:0.7319
Current avg r:0.5910 Best avg r: 0.6252
07:32:25,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:33:43,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:35:14,653 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1412
en_de Dev loss: 1.3154 r:0.2015
en_zh Dev loss: 0.8270 r:0.4701
ro_en Dev loss: 0.3623 r:0.8168
et_en Dev loss: 0.5139 r:0.6453
si_en Dev loss: 0.8891 r:0.5551
ne_en Dev loss: 0.5305 r:0.7273
ru_en Dev loss: 0.4699 r:0.7383
Current avg r:0.5935 Best avg r: 0.6252
07:39:09,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:27,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:41:58,854 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1312
en_de Dev loss: 1.2775 r:0.2067
en_zh Dev loss: 0.8070 r:0.4625
ro_en Dev loss: 0.3480 r:0.8161
et_en Dev loss: 0.4809 r:0.6488
si_en Dev loss: 0.8449 r:0.5622
ne_en Dev loss: 0.5311 r:0.7253
ru_en Dev loss: 0.4670 r:0.7325
Current avg r:0.5935 Best avg r: 0.6252
07:45:52,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:10,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:48:41,254 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1297
en_de Dev loss: 1.2772 r:0.2081
en_zh Dev loss: 0.7865 r:0.4722
ro_en Dev loss: 0.3612 r:0.8182
et_en Dev loss: 0.4767 r:0.6510
si_en Dev loss: 0.8432 r:0.5657
ne_en Dev loss: 0.5420 r:0.7276
ru_en Dev loss: 0.4618 r:0.7400
Current avg r:0.5976 Best avg r: 0.6252
07:52:35,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:53:54,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:26,351 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1312
en_de Dev loss: 1.3284 r:0.2058
en_zh Dev loss: 0.8236 r:0.4731
ro_en Dev loss: 0.3969 r:0.8134
et_en Dev loss: 0.5075 r:0.6454
si_en Dev loss: 0.9714 r:0.5440
ne_en Dev loss: 0.6463 r:0.7222
ru_en Dev loss: 0.4793 r:0.7288
Current avg r:0.5904 Best avg r: 0.6252
07:59:22,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:00:40,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:12,286 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1247
en_de Dev loss: 1.2194 r:0.1950
en_zh Dev loss: 0.7679 r:0.4706
ro_en Dev loss: 0.3378 r:0.8172
et_en Dev loss: 0.4974 r:0.6540
si_en Dev loss: 0.7386 r:0.5660
ne_en Dev loss: 0.4727 r:0.7235
ru_en Dev loss: 0.3895 r:0.7569
Current avg r:0.5976 Best avg r: 0.6252
08:06:07,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:07:26,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:08:57,683 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1297
en_de Dev loss: 1.3524 r:0.1968
en_zh Dev loss: 0.8471 r:0.4682
ro_en Dev loss: 0.3772 r:0.8160
et_en Dev loss: 0.4922 r:0.6473
si_en Dev loss: 0.9030 r:0.5560
ne_en Dev loss: 0.5858 r:0.7270
ru_en Dev loss: 0.4669 r:0.7335
Current avg r:0.5921 Best avg r: 0.6252
08:12:52,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:14:11,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:15:42,233 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1280
en_de Dev loss: 1.2964 r:0.1994
en_zh Dev loss: 0.8309 r:0.4602
ro_en Dev loss: 0.3606 r:0.8123
et_en Dev loss: 0.4843 r:0.6475
si_en Dev loss: 0.8959 r:0.5553
ne_en Dev loss: 0.6083 r:0.7187
ru_en Dev loss: 0.4647 r:0.7262
Current avg r:0.5885 Best avg r: 0.6252
08:19:34,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:20:52,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:22:23,565 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1306
en_de Dev loss: 1.3015 r:0.2043
en_zh Dev loss: 0.8122 r:0.4682
ro_en Dev loss: 0.3623 r:0.8118
et_en Dev loss: 0.5029 r:0.6447
si_en Dev loss: 0.9392 r:0.5479
ne_en Dev loss: 0.5455 r:0.7215
ru_en Dev loss: 0.4825 r:0.7219
Current avg r:0.5886 Best avg r: 0.6252
08:26:16,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:27:34,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:05,73 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1338
en_de Dev loss: 1.3149 r:0.2010
en_zh Dev loss: 0.8245 r:0.4685
ro_en Dev loss: 0.3764 r:0.8099
et_en Dev loss: 0.5104 r:0.6373
si_en Dev loss: 0.9721 r:0.5463
ne_en Dev loss: 0.6912 r:0.7182
ru_en Dev loss: 0.4853 r:0.7210
Current avg r:0.5860 Best avg r: 0.6252
08:32:57,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:34:15,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:35:46,580 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1333
en_de Dev loss: 1.3364 r:0.2081
en_zh Dev loss: 0.8198 r:0.4656
ro_en Dev loss: 0.3934 r:0.8061
et_en Dev loss: 0.5199 r:0.6344
si_en Dev loss: 1.0674 r:0.5342
ne_en Dev loss: 0.7975 r:0.7114
ru_en Dev loss: 0.4926 r:0.7201
Current avg r:0.5828 Best avg r: 0.6252
08:39:39,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:40:57,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:42:27,997 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1263
en_de Dev loss: 1.2990 r:0.1980
en_zh Dev loss: 0.7913 r:0.4729
ro_en Dev loss: 0.3707 r:0.8114
et_en Dev loss: 0.4971 r:0.6443
si_en Dev loss: 0.9053 r:0.5504
ne_en Dev loss: 0.5729 r:0.7197
ru_en Dev loss: 0.4479 r:0.7345
Current avg r:0.5902 Best avg r: 0.6252
08:46:20,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:38,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:09,470 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1227
en_de Dev loss: 1.2762 r:0.2123
en_zh Dev loss: 0.7846 r:0.4761
ro_en Dev loss: 0.3604 r:0.8115
et_en Dev loss: 0.4780 r:0.6495
si_en Dev loss: 0.8866 r:0.5502
ne_en Dev loss: 0.5808 r:0.7263
ru_en Dev loss: 0.4994 r:0.7127
Current avg r:0.5912 Best avg r: 0.6252
08:53:02,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:54:20,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:55:50,985 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1308
en_de Dev loss: 1.3806 r:0.2041
en_zh Dev loss: 0.8344 r:0.4772
ro_en Dev loss: 0.3975 r:0.8140
et_en Dev loss: 0.5171 r:0.6527
si_en Dev loss: 0.9485 r:0.5522
ne_en Dev loss: 0.6192 r:0.7251
ru_en Dev loss: 0.5043 r:0.7276
Current avg r:0.5933 Best avg r: 0.6252
08:59:43,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:01,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:02:32,444 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1235
en_de Dev loss: 1.3067 r:0.2114
en_zh Dev loss: 0.8041 r:0.4740
ro_en Dev loss: 0.3756 r:0.8129
et_en Dev loss: 0.5138 r:0.6477
si_en Dev loss: 0.9555 r:0.5465
ne_en Dev loss: 0.5775 r:0.7251
ru_en Dev loss: 0.4748 r:0.7316
Current avg r:0.5927 Best avg r: 0.6252
09:06:25,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:07:43,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:13,867 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1331
en_de Dev loss: 1.3060 r:0.2129
en_zh Dev loss: 0.8025 r:0.4717
ro_en Dev loss: 0.3676 r:0.8154
et_en Dev loss: 0.4881 r:0.6431
si_en Dev loss: 0.9416 r:0.5482
ne_en Dev loss: 0.5533 r:0.7211
ru_en Dev loss: 0.4583 r:0.7356
Current avg r:0.5926 Best avg r: 0.6252
09:13:06,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:14:24,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:15:55,314 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1272
en_de Dev loss: 1.3112 r:0.2054
en_zh Dev loss: 0.7986 r:0.4749
ro_en Dev loss: 0.3855 r:0.8140
et_en Dev loss: 0.5225 r:0.6422
si_en Dev loss: 0.9297 r:0.5496
ne_en Dev loss: 0.5806 r:0.7146
ru_en Dev loss: 0.4878 r:0.7222
Current avg r:0.5890 Best avg r: 0.6252
09:19:49,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:21:07,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:22:38,416 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1166
en_de Dev loss: 1.2698 r:0.2030
en_zh Dev loss: 0.7814 r:0.4699
ro_en Dev loss: 0.3592 r:0.8139
et_en Dev loss: 0.4864 r:0.6407
si_en Dev loss: 0.9153 r:0.5467
ne_en Dev loss: 0.5300 r:0.7239
ru_en Dev loss: 0.4293 r:0.7429
Current avg r:0.5916 Best avg r: 0.6252
09:26:31,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:27:49,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:29:19,843 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1185
en_de Dev loss: 1.2708 r:0.2174
en_zh Dev loss: 0.7840 r:0.4663
ro_en Dev loss: 0.3641 r:0.8116
et_en Dev loss: 0.4851 r:0.6323
si_en Dev loss: 0.9149 r:0.5517
ne_en Dev loss: 0.5480 r:0.7200
ru_en Dev loss: 0.4518 r:0.7380
Current avg r:0.5910 Best avg r: 0.6252
09:33:12,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:34:30,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:00,827 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1261
en_de Dev loss: 1.2909 r:0.2140
en_zh Dev loss: 0.8051 r:0.4688
ro_en Dev loss: 0.3763 r:0.8129
et_en Dev loss: 0.5230 r:0.6447
si_en Dev loss: 0.8575 r:0.5551
ne_en Dev loss: 0.5200 r:0.7180
ru_en Dev loss: 0.4278 r:0.7508
Current avg r:0.5949 Best avg r: 0.6252
09:39:53,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:11,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:42:41,831 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1226
en_de Dev loss: 1.2746 r:0.2099
en_zh Dev loss: 0.8143 r:0.4565
ro_en Dev loss: 0.3757 r:0.8060
et_en Dev loss: 0.5185 r:0.6294
si_en Dev loss: 0.9073 r:0.5426
ne_en Dev loss: 0.5681 r:0.7150
ru_en Dev loss: 0.4632 r:0.7309
Current avg r:0.5843 Best avg r: 0.6252
09:46:34,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:52,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:22,867 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1222
en_de Dev loss: 1.3019 r:0.2048
en_zh Dev loss: 0.7991 r:0.4744
ro_en Dev loss: 0.3864 r:0.8093
et_en Dev loss: 0.5113 r:0.6378
si_en Dev loss: 0.8883 r:0.5541
ne_en Dev loss: 0.5511 r:0.7188
ru_en Dev loss: 0.4555 r:0.7348
Current avg r:0.5906 Best avg r: 0.6252
09:53:15,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:54:33,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:03,887 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1205
en_de Dev loss: 1.3464 r:0.2123
en_zh Dev loss: 0.8409 r:0.4729
ro_en Dev loss: 0.3926 r:0.8102
et_en Dev loss: 0.5189 r:0.6446
si_en Dev loss: 0.9419 r:0.5448
ne_en Dev loss: 0.5654 r:0.7147
ru_en Dev loss: 0.4688 r:0.7396
Current avg r:0.5913 Best avg r: 0.6252
09:59:56,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:01:14,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:44,782 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1171
en_de Dev loss: 1.3430 r:0.2112
en_zh Dev loss: 0.8321 r:0.4733
ro_en Dev loss: 0.3860 r:0.8085
et_en Dev loss: 0.5139 r:0.6519
si_en Dev loss: 0.9230 r:0.5509
ne_en Dev loss: 0.6155 r:0.7126
ru_en Dev loss: 0.4857 r:0.7295
Current avg r:0.5911 Best avg r: 0.6252
10:06:37,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:07:54,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:25,736 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1167
en_de Dev loss: 1.3041 r:0.2076
en_zh Dev loss: 0.8155 r:0.4712
ro_en Dev loss: 0.3634 r:0.8115
et_en Dev loss: 0.5036 r:0.6535
si_en Dev loss: 0.8934 r:0.5518
ne_en Dev loss: 0.5658 r:0.7174
ru_en Dev loss: 0.4306 r:0.7494
Current avg r:0.5946 Best avg r: 0.6252
10:13:19,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:38,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:16:09,852 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1138
en_de Dev loss: 1.2454 r:0.2187
en_zh Dev loss: 0.7757 r:0.4751
ro_en Dev loss: 0.3531 r:0.8115
et_en Dev loss: 0.4996 r:0.6489
si_en Dev loss: 0.8733 r:0.5513
ne_en Dev loss: 0.5818 r:0.7115
ru_en Dev loss: 0.4507 r:0.7379
Current avg r:0.5935 Best avg r: 0.6252
10:20:05,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:23,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:55,323 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1193
en_de Dev loss: 1.2988 r:0.2159
en_zh Dev loss: 0.8253 r:0.4641
ro_en Dev loss: 0.3636 r:0.8126
et_en Dev loss: 0.5140 r:0.6464
si_en Dev loss: 0.8560 r:0.5512
ne_en Dev loss: 0.5483 r:0.7176
ru_en Dev loss: 0.4417 r:0.7426
Current avg r:0.5929 Best avg r: 0.6252
10:26:50,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:09,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:40,959 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1121
en_de Dev loss: 1.2888 r:0.2202
en_zh Dev loss: 0.8023 r:0.4698
ro_en Dev loss: 0.3963 r:0.8065
et_en Dev loss: 0.5343 r:0.6480
si_en Dev loss: 0.9155 r:0.5476
ne_en Dev loss: 0.5700 r:0.7160
ru_en Dev loss: 0.4671 r:0.7363
Current avg r:0.5921 Best avg r: 0.6252
