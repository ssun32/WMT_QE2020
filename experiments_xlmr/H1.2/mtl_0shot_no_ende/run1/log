14:44:02,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:15,759 root INFO 
id:en_zh cur r: 0.2684 best r: 0.2684
14:44:29,40 root INFO 
id:ro_en cur r: 0.4741 best r: 0.4741
14:44:42,349 root INFO 
id:et_en cur r: 0.5331 best r: 0.5331
14:44:55,657 root INFO 
id:si_en cur r: 0.3594 best r: 0.3594
14:45:08,973 root INFO 
id:ne_en cur r: 0.5088 best r: 0.5088
14:45:22,197 root INFO 
id:ru_en cur r: 0.5622 best r: 0.5622
14:45:22,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:55,141 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
14:46:55,147 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:46:55,152 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:46:55,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
14:46:55,162 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
14:46:55,167 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:46:55,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:47:08,475 root INFO Epoch 0 Global steps: 600 Train loss: 0.8991
en_de Dev loss: 0.9089 r:0.0970
en_zh Dev loss: 0.7778 r:0.2375
ro_en Dev loss: 0.6366 r:0.5622
et_en Dev loss: 0.6006 r:0.5072
si_en Dev loss: 0.7132 r:0.4052
ne_en Dev loss: 0.6258 r:0.5024
ru_en Dev loss: 0.5920 r:0.5854
Current avg r:0.4138 Best avg r: 0.4138
14:51:06,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:32,804 root INFO 
id:ro_en cur r: 0.5802 best r: 0.5802
14:51:46,102 root INFO 
id:et_en cur r: 0.5421 best r: 0.5421
14:51:59,413 root INFO 
id:si_en cur r: 0.4070 best r: 0.4070
14:52:12,717 root INFO 
id:ne_en cur r: 0.5632 best r: 0.5632
14:52:25,945 root INFO 
id:ru_en cur r: 0.6170 best r: 0.6170
14:52:25,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:58,872 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
14:53:58,877 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:53:58,883 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:53:58,887 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
14:53:58,894 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
14:53:58,899 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:53:58,904 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:54:12,204 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8217
en_de Dev loss: 0.9281 r:0.0923
en_zh Dev loss: 0.8025 r:0.2297
ro_en Dev loss: 0.5810 r:0.6475
et_en Dev loss: 0.5520 r:0.5198
si_en Dev loss: 0.7649 r:0.4542
ne_en Dev loss: 0.5875 r:0.5519
ru_en Dev loss: 0.5634 r:0.6352
Current avg r:0.4472 Best avg r: 0.4472
14:58:09,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:22,953 root INFO 
id:en_zh cur r: 0.3079 best r: 0.3079
14:58:36,241 root INFO 
id:ro_en cur r: 0.6481 best r: 0.6481
14:58:49,535 root INFO 
id:et_en cur r: 0.6164 best r: 0.6164
14:59:02,841 root INFO 
id:si_en cur r: 0.4389 best r: 0.4389
14:59:16,151 root INFO 
id:ne_en cur r: 0.6199 best r: 0.6199
14:59:29,374 root INFO 
id:ru_en cur r: 0.6603 best r: 0.6603
14:59:29,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:01:02,298 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:01:02,308 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:01:02,313 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:01:02,318 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:01:02,324 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:01:02,330 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:01:02,334 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:01:15,689 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7578
en_de Dev loss: 0.9649 r:0.0975
en_zh Dev loss: 0.7646 r:0.2992
ro_en Dev loss: 0.4818 r:0.6861
et_en Dev loss: 0.4709 r:0.6182
si_en Dev loss: 0.6341 r:0.4881
ne_en Dev loss: 0.5078 r:0.6185
ru_en Dev loss: 0.4919 r:0.6776
Current avg r:0.4979 Best avg r: 0.4979
15:05:13,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:26,462 root INFO 
id:en_zh cur r: 0.3357 best r: 0.3357
15:05:39,763 root INFO 
id:ro_en cur r: 0.6651 best r: 0.6651
15:05:53,86 root INFO 
id:et_en cur r: 0.6263 best r: 0.6263
15:06:06,408 root INFO 
id:si_en cur r: 0.4389 best r: 0.4389
15:06:19,718 root INFO 
id:ne_en cur r: 0.6348 best r: 0.6348
15:06:32,942 root INFO 
id:ru_en cur r: 0.6989 best r: 0.6989
15:06:32,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:05,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:08:05,856 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:08:05,860 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:08:05,865 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:08:05,870 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:08:05,875 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:08:05,880 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:08:19,188 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6929
en_de Dev loss: 1.0487 r:0.1041
en_zh Dev loss: 0.8186 r:0.3286
ro_en Dev loss: 0.4961 r:0.6989
et_en Dev loss: 0.4480 r:0.6263
si_en Dev loss: 0.7707 r:0.4760
ne_en Dev loss: 0.5116 r:0.6212
ru_en Dev loss: 0.4799 r:0.7090
Current avg r:0.5091 Best avg r: 0.5091
15:12:17,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:30,503 root INFO 
id:en_zh cur r: 0.3557 best r: 0.3557
15:12:43,802 root INFO 
id:ro_en cur r: 0.6892 best r: 0.6892
15:12:57,118 root INFO 
id:et_en cur r: 0.6274 best r: 0.6274
15:13:10,441 root INFO 
id:si_en cur r: 0.4641 best r: 0.4641
15:13:23,763 root INFO 
id:ne_en cur r: 0.6527 best r: 0.6527
15:13:37,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:15:10,44 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:15:10,50 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:15:10,56 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:15:10,61 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:15:10,65 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:15:10,70 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:15:10,75 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:15:23,396 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6651
en_de Dev loss: 1.0961 r:0.1091
en_zh Dev loss: 0.7945 r:0.3560
ro_en Dev loss: 0.4717 r:0.7196
et_en Dev loss: 0.4192 r:0.6464
si_en Dev loss: 0.6951 r:0.5061
ne_en Dev loss: 0.4760 r:0.6437
ru_en Dev loss: 0.4837 r:0.7090
Current avg r:0.5271 Best avg r: 0.5271
15:19:21,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:48,104 root INFO 
id:ro_en cur r: 0.6969 best r: 0.6969
15:20:01,424 root INFO 
id:et_en cur r: 0.6534 best r: 0.6534
15:20:41,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:14,364 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:22:14,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:22:14,375 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:22:14,380 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:22:14,385 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:22:14,389 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:22:14,393 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:22:27,704 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6552
en_de Dev loss: 1.1382 r:0.1200
en_zh Dev loss: 0.8848 r:0.3473
ro_en Dev loss: 0.5051 r:0.7330
et_en Dev loss: 0.4280 r:0.6570
si_en Dev loss: 0.7760 r:0.5064
ne_en Dev loss: 0.5650 r:0.6302
ru_en Dev loss: 0.5356 r:0.7086
Current avg r:0.5289 Best avg r: 0.5289
15:26:25,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:38,971 root INFO 
id:en_zh cur r: 0.3661 best r: 0.3661
15:26:52,265 root INFO 
id:ro_en cur r: 0.7211 best r: 0.7211
15:27:05,589 root INFO 
id:et_en cur r: 0.6710 best r: 0.6710
15:27:18,916 root INFO 
id:si_en cur r: 0.5013 best r: 0.5013
15:27:32,235 root INFO 
id:ne_en cur r: 0.6830 best r: 0.6830
15:27:45,464 root INFO 
id:ru_en cur r: 0.7013 best r: 0.7013
15:27:45,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:18,506 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:29:18,512 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:29:18,517 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:29:18,522 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:29:18,528 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:29:18,533 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:29:18,538 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:29:31,847 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6157
en_de Dev loss: 1.0947 r:0.1469
en_zh Dev loss: 0.7730 r:0.3861
ro_en Dev loss: 0.4642 r:0.7436
et_en Dev loss: 0.4030 r:0.6722
si_en Dev loss: 0.7594 r:0.5308
ne_en Dev loss: 0.4630 r:0.6761
ru_en Dev loss: 0.4824 r:0.7254
Current avg r:0.5545 Best avg r: 0.5545
15:33:29,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:42,967 root INFO 
id:en_zh cur r: 0.3809 best r: 0.3809
15:33:56,266 root INFO 
id:ro_en cur r: 0.7340 best r: 0.7340
15:34:49,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:22,515 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6030
en_de Dev loss: 1.1234 r:0.1518
en_zh Dev loss: 0.7793 r:0.3889
ro_en Dev loss: 0.4340 r:0.7531
et_en Dev loss: 0.3821 r:0.6826
si_en Dev loss: 0.8204 r:0.5162
ne_en Dev loss: 0.5439 r:0.6635
ru_en Dev loss: 0.5138 r:0.7202
Current avg r:0.5537 Best avg r: 0.5545
15:40:20,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:33,825 root INFO 
id:en_zh cur r: 0.3930 best r: 0.3930
15:40:47,120 root INFO 
id:ro_en cur r: 0.7491 best r: 0.7491
15:41:00,433 root INFO 
id:et_en cur r: 0.6755 best r: 0.6755
15:41:13,756 root INFO 
id:si_en cur r: 0.5250 best r: 0.5250
15:41:27,80 root INFO 
id:ne_en cur r: 0.6900 best r: 0.6900
15:41:40,309 root INFO 
id:ru_en cur r: 0.7052 best r: 0.7052
15:41:40,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:13,382 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:43:13,389 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:43:13,394 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:43:13,398 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:43:13,403 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:43:13,407 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:43:13,412 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:43:26,728 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5617
en_de Dev loss: 1.1726 r:0.1660
en_zh Dev loss: 0.7676 r:0.4077
ro_en Dev loss: 0.4430 r:0.7597
et_en Dev loss: 0.3912 r:0.6851
si_en Dev loss: 0.7020 r:0.5477
ne_en Dev loss: 0.4502 r:0.6920
ru_en Dev loss: 0.5434 r:0.7243
Current avg r:0.5689 Best avg r: 0.5689
15:47:24,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:38,177 root INFO 
id:en_zh cur r: 0.4217 best r: 0.4217
15:47:51,476 root INFO 
id:ro_en cur r: 0.7720 best r: 0.7720
15:48:04,793 root INFO 
id:et_en cur r: 0.6959 best r: 0.6959
15:48:18,124 root INFO 
id:si_en cur r: 0.5498 best r: 0.5498
15:48:31,458 root INFO 
id:ne_en cur r: 0.7155 best r: 0.7155
15:48:44,687 root INFO 
id:ru_en cur r: 0.7493 best r: 0.7493
15:48:44,688 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:17,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:50:17,761 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:50:17,766 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:50:17,773 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:50:17,777 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:50:17,783 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:50:17,788 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:50:31,111 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5959
en_de Dev loss: 1.0496 r:0.1918
en_zh Dev loss: 0.7093 r:0.4310
ro_en Dev loss: 0.3567 r:0.7781
et_en Dev loss: 0.3651 r:0.7015
si_en Dev loss: 0.6470 r:0.5672
ne_en Dev loss: 0.4179 r:0.7070
ru_en Dev loss: 0.4436 r:0.7535
Current avg r:0.5900 Best avg r: 0.5900
15:54:29,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:42,544 root INFO 
id:en_zh cur r: 0.4395 best r: 0.4395
15:55:09,159 root INFO 
id:et_en cur r: 0.6995 best r: 0.6995
15:55:49,34 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:22,100 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5608
en_de Dev loss: 1.0521 r:0.1831
en_zh Dev loss: 0.6774 r:0.4448
ro_en Dev loss: 0.3589 r:0.7773
et_en Dev loss: 0.3651 r:0.7011
si_en Dev loss: 0.6745 r:0.5606
ne_en Dev loss: 0.4781 r:0.6929
ru_en Dev loss: 0.4237 r:0.7534
Current avg r:0.5876 Best avg r: 0.5900
16:01:20,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:46,859 root INFO 
id:ro_en cur r: 0.7798 best r: 0.7798
16:02:13,505 root INFO 
id:si_en cur r: 0.5565 best r: 0.5565
16:02:26,825 root INFO 
id:ne_en cur r: 0.7191 best r: 0.7191
16:02:40,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:13,67 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5460
en_de Dev loss: 1.1446 r:0.1866
en_zh Dev loss: 0.7447 r:0.4201
ro_en Dev loss: 0.3641 r:0.7865
et_en Dev loss: 0.3637 r:0.7029
si_en Dev loss: 0.6859 r:0.5752
ne_en Dev loss: 0.4395 r:0.7136
ru_en Dev loss: 0.4976 r:0.7431
Current avg r:0.5897 Best avg r: 0.5900
16:08:11,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:08:37,794 root INFO 
id:ro_en cur r: 0.7814 best r: 0.7814
16:09:04,431 root INFO 
id:si_en cur r: 0.5591 best r: 0.5591
16:09:17,758 root INFO 
id:ne_en cur r: 0.7257 best r: 0.7257
16:09:31,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:04,32 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
16:11:04,39 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:11:04,44 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:11:04,50 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
16:11:04,54 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
16:11:04,58 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:11:04,63 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:11:17,377 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5469
en_de Dev loss: 1.0887 r:0.1935
en_zh Dev loss: 0.7201 r:0.4306
ro_en Dev loss: 0.3519 r:0.7902
et_en Dev loss: 0.3631 r:0.7036
si_en Dev loss: 0.6419 r:0.5763
ne_en Dev loss: 0.4464 r:0.7109
ru_en Dev loss: 0.4482 r:0.7472
Current avg r:0.5932 Best avg r: 0.5932
16:15:15,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:28,804 root INFO 
id:en_zh cur r: 0.4524 best r: 0.4524
16:15:42,100 root INFO 
id:ro_en cur r: 0.7956 best r: 0.7956
16:15:55,415 root INFO 
id:et_en cur r: 0.7084 best r: 0.7084
16:16:08,754 root INFO 
id:si_en cur r: 0.5710 best r: 0.5710
16:16:22,79 root INFO 
id:ne_en cur r: 0.7439 best r: 0.7439
16:16:35,313 root INFO 
id:ru_en cur r: 0.7519 best r: 0.7519
16:16:35,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:08,352 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
16:18:08,359 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:18:08,364 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:18:08,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
16:18:08,378 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
16:18:08,384 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:18:08,392 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:18:21,703 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5748
en_de Dev loss: 0.9636 r:0.2129
en_zh Dev loss: 0.6522 r:0.4605
ro_en Dev loss: 0.3207 r:0.7933
et_en Dev loss: 0.3583 r:0.7154
si_en Dev loss: 0.5659 r:0.5917
ne_en Dev loss: 0.3840 r:0.7336
ru_en Dev loss: 0.3744 r:0.7570
Current avg r:0.6092 Best avg r: 0.6092
16:22:19,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:13,91 root INFO 
id:si_en cur r: 0.5794 best r: 0.5794
16:23:39,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:12,660 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5185
en_de Dev loss: 1.0729 r:0.2123
en_zh Dev loss: 0.7283 r:0.4450
ro_en Dev loss: 0.3676 r:0.7928
et_en Dev loss: 0.3581 r:0.7084
si_en Dev loss: 0.6285 r:0.5885
ne_en Dev loss: 0.4195 r:0.7171
ru_en Dev loss: 0.4473 r:0.7563
Current avg r:0.6029 Best avg r: 0.6092
16:29:11,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:31,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:32:04,319 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5162
en_de Dev loss: 1.1715 r:0.1998
en_zh Dev loss: 0.7512 r:0.4494
ro_en Dev loss: 0.3999 r:0.7897
et_en Dev loss: 0.3973 r:0.6957
si_en Dev loss: 0.7036 r:0.5862
ne_en Dev loss: 0.4425 r:0.7166
ru_en Dev loss: 0.5144 r:0.7461
Current avg r:0.5976 Best avg r: 0.6092
16:36:01,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:21,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:54,561 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5003
en_de Dev loss: 1.0956 r:0.1965
en_zh Dev loss: 0.7408 r:0.4434
ro_en Dev loss: 0.3873 r:0.7897
et_en Dev loss: 0.4011 r:0.6903
si_en Dev loss: 0.7700 r:0.5645
ne_en Dev loss: 0.4913 r:0.7045
ru_en Dev loss: 0.4859 r:0.7421
Current avg r:0.5902 Best avg r: 0.6092
16:42:52,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:19,273 root INFO 
id:ro_en cur r: 0.7969 best r: 0.7969
16:44:12,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:45,539 root INFO Epoch 1 Global steps: 10800 Train loss: 0.4834
en_de Dev loss: 1.1151 r:0.2201
en_zh Dev loss: 0.7213 r:0.4572
ro_en Dev loss: 0.3858 r:0.7968
et_en Dev loss: 0.3971 r:0.6943
si_en Dev loss: 0.7086 r:0.5800
ne_en Dev loss: 0.3903 r:0.7349
ru_en Dev loss: 0.4651 r:0.7445
Current avg r:0.6040 Best avg r: 0.6092
16:49:43,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:57,33 root INFO 
id:en_zh cur r: 0.4557 best r: 0.4557
16:50:10,326 root INFO 
id:ro_en cur r: 0.8093 best r: 0.8093
16:50:36,966 root INFO 
id:si_en cur r: 0.6009 best r: 0.6009
16:50:50,290 root INFO 
id:ne_en cur r: 0.7513 best r: 0.7513
16:51:03,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:36,454 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
16:52:36,460 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:52:36,465 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:52:36,470 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
16:52:36,476 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
16:52:36,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:52:36,488 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:52:49,792 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4572
en_de Dev loss: 1.1017 r:0.2233
en_zh Dev loss: 0.6867 r:0.4610
ro_en Dev loss: 0.3378 r:0.8076
et_en Dev loss: 0.3703 r:0.7026
si_en Dev loss: 0.6150 r:0.6003
ne_en Dev loss: 0.4481 r:0.7427
ru_en Dev loss: 0.4486 r:0.7510
Current avg r:0.6126 Best avg r: 0.6126
16:56:47,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:06,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:39,919 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4971
en_de Dev loss: 1.2290 r:0.2160
en_zh Dev loss: 0.8682 r:0.4235
ro_en Dev loss: 0.4052 r:0.7891
et_en Dev loss: 0.4005 r:0.6886
si_en Dev loss: 0.7473 r:0.5655
ne_en Dev loss: 0.4280 r:0.7246
ru_en Dev loss: 0.5956 r:0.7079
Current avg r:0.5879 Best avg r: 0.6126
17:03:37,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:50,730 root INFO 
id:en_zh cur r: 0.4636 best r: 0.4636
17:04:04,16 root INFO 
id:ro_en cur r: 0.8138 best r: 0.8138
17:04:30,635 root INFO 
id:si_en cur r: 0.6091 best r: 0.6091
17:04:43,946 root INFO 
id:ne_en cur r: 0.7579 best r: 0.7579
17:04:57,166 root INFO 
id:ru_en cur r: 0.7679 best r: 0.7679
17:04:57,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:30,124 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
17:06:30,130 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:06:30,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:06:30,138 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
17:06:30,143 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
17:06:30,148 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:06:30,154 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:06:43,451 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5007
en_de Dev loss: 1.0671 r:0.2239
en_zh Dev loss: 0.6827 r:0.4605
ro_en Dev loss: 0.3382 r:0.8105
et_en Dev loss: 0.3605 r:0.7117
si_en Dev loss: 0.6027 r:0.6047
ne_en Dev loss: 0.3581 r:0.7536
ru_en Dev loss: 0.4165 r:0.7611
Current avg r:0.6180 Best avg r: 0.6180
17:10:41,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:07,564 root INFO 
id:ro_en cur r: 0.8160 best r: 0.8160
17:11:34,181 root INFO 
id:si_en cur r: 0.6108 best r: 0.6108
17:12:00,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:33,666 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4733
en_de Dev loss: 1.0671 r:0.2211
en_zh Dev loss: 0.6787 r:0.4637
ro_en Dev loss: 0.3218 r:0.8106
et_en Dev loss: 0.3536 r:0.7139
si_en Dev loss: 0.6231 r:0.6028
ne_en Dev loss: 0.3793 r:0.7478
ru_en Dev loss: 0.3855 r:0.7596
Current avg r:0.6171 Best avg r: 0.6180
17:17:31,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:57,795 root INFO 
id:ro_en cur r: 0.8187 best r: 0.8187
17:18:50,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:23,889 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4835
en_de Dev loss: 1.0955 r:0.2310
en_zh Dev loss: 0.7005 r:0.4626
ro_en Dev loss: 0.3298 r:0.8158
et_en Dev loss: 0.3550 r:0.7129
si_en Dev loss: 0.6736 r:0.5984
ne_en Dev loss: 0.4203 r:0.7410
ru_en Dev loss: 0.4698 r:0.7409
Current avg r:0.6146 Best avg r: 0.6180
17:24:21,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:47,965 root INFO 
id:ro_en cur r: 0.8212 best r: 0.8212
17:25:41,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:14,46 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4737
en_de Dev loss: 1.1271 r:0.2300
en_zh Dev loss: 0.7368 r:0.4506
ro_en Dev loss: 0.3192 r:0.8172
et_en Dev loss: 0.3551 r:0.7108
si_en Dev loss: 0.6436 r:0.5974
ne_en Dev loss: 0.3926 r:0.7470
ru_en Dev loss: 0.4123 r:0.7537
Current avg r:0.6152 Best avg r: 0.6180
17:31:11,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:31,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:04,178 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4670
en_de Dev loss: 1.1336 r:0.2335
en_zh Dev loss: 0.7338 r:0.4686
ro_en Dev loss: 0.3426 r:0.8150
et_en Dev loss: 0.3683 r:0.7075
si_en Dev loss: 0.7064 r:0.5927
ne_en Dev loss: 0.4192 r:0.7504
ru_en Dev loss: 0.4479 r:0.7501
Current avg r:0.6168 Best avg r: 0.6180
17:38:01,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:14,832 root INFO 
id:en_zh cur r: 0.4893 best r: 0.4893
17:39:08,32 root INFO 
id:ne_en cur r: 0.7649 best r: 0.7649
17:39:21,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:54,209 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
17:40:54,218 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:40:54,223 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:40:54,229 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
17:40:54,238 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
17:40:54,244 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:40:54,250 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:41:07,555 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4986
en_de Dev loss: 1.0795 r:0.2326
en_zh Dev loss: 0.6629 r:0.4924
ro_en Dev loss: 0.3362 r:0.8152
et_en Dev loss: 0.3624 r:0.7105
si_en Dev loss: 0.6793 r:0.6001
ne_en Dev loss: 0.5046 r:0.7545
ru_en Dev loss: 0.4155 r:0.7662
Current avg r:0.6245 Best avg r: 0.6245
17:45:05,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:24,727 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:57,690 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4633
en_de Dev loss: 1.1353 r:0.2195
en_zh Dev loss: 0.7332 r:0.4618
ro_en Dev loss: 0.3287 r:0.8142
et_en Dev loss: 0.3721 r:0.7042
si_en Dev loss: 0.6468 r:0.6046
ne_en Dev loss: 0.4630 r:0.7545
ru_en Dev loss: 0.4776 r:0.7434
Current avg r:0.6146 Best avg r: 0.6245
17:51:55,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:14,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:47,800 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4600
en_de Dev loss: 1.0918 r:0.2209
en_zh Dev loss: 0.7065 r:0.4649
ro_en Dev loss: 0.3164 r:0.8112
et_en Dev loss: 0.3847 r:0.6984
si_en Dev loss: 0.5954 r:0.6051
ne_en Dev loss: 0.3665 r:0.7613
ru_en Dev loss: 0.4248 r:0.7497
Current avg r:0.6159 Best avg r: 0.6245
17:58:45,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:05,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:38,183 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4534
en_de Dev loss: 1.1010 r:0.2339
en_zh Dev loss: 0.6910 r:0.4789
ro_en Dev loss: 0.3383 r:0.8132
et_en Dev loss: 0.3837 r:0.6973
si_en Dev loss: 0.7132 r:0.5993
ne_en Dev loss: 0.4013 r:0.7592
ru_en Dev loss: 0.4395 r:0.7485
Current avg r:0.6186 Best avg r: 0.6245
18:05:36,36 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:55,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:28,825 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4546
en_de Dev loss: 1.1501 r:0.2224
en_zh Dev loss: 0.7248 r:0.4689
ro_en Dev loss: 0.3333 r:0.8126
et_en Dev loss: 0.3865 r:0.7020
si_en Dev loss: 0.6635 r:0.5988
ne_en Dev loss: 0.4203 r:0.7563
ru_en Dev loss: 0.4184 r:0.7565
Current avg r:0.6168 Best avg r: 0.6245
18:12:28,294 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:48,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:21,31 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4309
en_de Dev loss: 1.1514 r:0.2200
en_zh Dev loss: 0.7398 r:0.4634
ro_en Dev loss: 0.3480 r:0.8130
et_en Dev loss: 0.4091 r:0.6989
si_en Dev loss: 0.6394 r:0.6062
ne_en Dev loss: 0.3916 r:0.7587
ru_en Dev loss: 0.4404 r:0.7399
Current avg r:0.6143 Best avg r: 0.6245
18:19:19,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:12,414 root INFO 
id:si_en cur r: 0.6124 best r: 0.6124
18:20:38,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:11,969 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4251
en_de Dev loss: 1.1445 r:0.2268
en_zh Dev loss: 0.7132 r:0.4763
ro_en Dev loss: 0.3479 r:0.8141
et_en Dev loss: 0.3948 r:0.6942
si_en Dev loss: 0.6628 r:0.6087
ne_en Dev loss: 0.3709 r:0.7605
ru_en Dev loss: 0.4879 r:0.7374
Current avg r:0.6169 Best avg r: 0.6245
18:26:10,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:16,738 root INFO 
id:ne_en cur r: 0.7687 best r: 0.7687
18:27:29,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:03,4 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4226
en_de Dev loss: 1.0955 r:0.2300
en_zh Dev loss: 0.6781 r:0.4799
ro_en Dev loss: 0.3335 r:0.8157
et_en Dev loss: 0.3934 r:0.7008
si_en Dev loss: 0.7378 r:0.6030
ne_en Dev loss: 0.4189 r:0.7671
ru_en Dev loss: 0.4272 r:0.7438
Current avg r:0.6200 Best avg r: 0.6245
18:33:01,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:20,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:53,975 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4329
en_de Dev loss: 1.1086 r:0.2216
en_zh Dev loss: 0.7275 r:0.4743
ro_en Dev loss: 0.3143 r:0.8165
et_en Dev loss: 0.3809 r:0.7014
si_en Dev loss: 0.7293 r:0.6002
ne_en Dev loss: 0.3992 r:0.7629
ru_en Dev loss: 0.4327 r:0.7450
Current avg r:0.6174 Best avg r: 0.6245
18:39:52,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:11,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:44,972 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4256
en_de Dev loss: 1.0434 r:0.2254
en_zh Dev loss: 0.6679 r:0.4892
ro_en Dev loss: 0.3024 r:0.8186
et_en Dev loss: 0.3614 r:0.7046
si_en Dev loss: 0.6157 r:0.6037
ne_en Dev loss: 0.3981 r:0.7615
ru_en Dev loss: 0.4271 r:0.7439
Current avg r:0.6210 Best avg r: 0.6245
18:46:43,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:49,732 root INFO 
id:ne_en cur r: 0.7728 best r: 0.7728
18:48:02,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:35,990 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4082
en_de Dev loss: 1.0675 r:0.2195
en_zh Dev loss: 0.6595 r:0.4901
ro_en Dev loss: 0.3118 r:0.8208
et_en Dev loss: 0.3993 r:0.7043
si_en Dev loss: 0.6043 r:0.6115
ne_en Dev loss: 0.4015 r:0.7686
ru_en Dev loss: 0.4165 r:0.7433
Current avg r:0.6226 Best avg r: 0.6245
18:53:34,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:53,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:56:26,903 root INFO Epoch 2 Global steps: 22200 Train loss: 0.3992
en_de Dev loss: 1.1782 r:0.2259
en_zh Dev loss: 0.7531 r:0.4634
ro_en Dev loss: 0.3626 r:0.8132
et_en Dev loss: 0.4090 r:0.6962
si_en Dev loss: 0.7374 r:0.5930
ne_en Dev loss: 0.4748 r:0.7577
ru_en Dev loss: 0.5341 r:0.7102
Current avg r:0.6085 Best avg r: 0.6245
19:00:24,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:51,348 root INFO 
id:ro_en cur r: 0.8222 best r: 0.8222
19:01:44,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:17,413 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4095
en_de Dev loss: 1.1110 r:0.2282
en_zh Dev loss: 0.7197 r:0.4723
ro_en Dev loss: 0.3429 r:0.8166
et_en Dev loss: 0.3726 r:0.6993
si_en Dev loss: 0.6979 r:0.5932
ne_en Dev loss: 0.4563 r:0.7585
ru_en Dev loss: 0.4798 r:0.7276
Current avg r:0.6137 Best avg r: 0.6245
19:07:15,181 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:41,708 root INFO 
id:ro_en cur r: 0.8226 best r: 0.8226
19:08:34,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:07,783 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4313
en_de Dev loss: 1.1761 r:0.2257
en_zh Dev loss: 0.7807 r:0.4675
ro_en Dev loss: 0.3674 r:0.8159
et_en Dev loss: 0.3992 r:0.6941
si_en Dev loss: 0.7605 r:0.5918
ne_en Dev loss: 0.4906 r:0.7552
ru_en Dev loss: 0.4978 r:0.7305
Current avg r:0.6116 Best avg r: 0.6245
19:14:05,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:31,879 root INFO 
id:ro_en cur r: 0.8283 best r: 0.8283
19:15:25,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:57,916 root INFO Epoch 2 Global steps: 24000 Train loss: 0.3971
en_de Dev loss: 1.0727 r:0.2271
en_zh Dev loss: 0.6902 r:0.4789
ro_en Dev loss: 0.2995 r:0.8249
et_en Dev loss: 0.4018 r:0.7053
si_en Dev loss: 0.6012 r:0.6131
ne_en Dev loss: 0.3781 r:0.7557
ru_en Dev loss: 0.4167 r:0.7474
Current avg r:0.6218 Best avg r: 0.6245
19:20:55,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:21,806 root INFO 
id:ro_en cur r: 0.8303 best r: 0.8303
19:22:14,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:47,837 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
19:23:47,843 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
19:23:47,848 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
19:23:47,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
19:23:47,857 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
19:23:47,862 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
19:23:47,866 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
19:24:01,156 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4109
en_de Dev loss: 1.1198 r:0.2367
en_zh Dev loss: 0.7081 r:0.4848
ro_en Dev loss: 0.3374 r:0.8272
et_en Dev loss: 0.3775 r:0.7060
si_en Dev loss: 0.7582 r:0.6115
ne_en Dev loss: 0.4311 r:0.7705
ru_en Dev loss: 0.4424 r:0.7497
Current avg r:0.6266 Best avg r: 0.6266
19:27:58,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:18,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:51,565 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3941
en_de Dev loss: 1.1621 r:0.2287
en_zh Dev loss: 0.7564 r:0.4744
ro_en Dev loss: 0.3561 r:0.8181
et_en Dev loss: 0.3968 r:0.6976
si_en Dev loss: 0.8445 r:0.5898
ne_en Dev loss: 0.4849 r:0.7565
ru_en Dev loss: 0.5284 r:0.7255
Current avg r:0.6129 Best avg r: 0.6266
19:34:49,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:03,42 root INFO 
id:en_zh cur r: 0.4957 best r: 0.4957
19:35:42,968 root INFO 
id:si_en cur r: 0.6143 best r: 0.6143
19:36:09,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:42,519 root INFO Epoch 2 Global steps: 25800 Train loss: 0.3994
en_de Dev loss: 1.0718 r:0.2162
en_zh Dev loss: 0.6722 r:0.4975
ro_en Dev loss: 0.3028 r:0.8226
et_en Dev loss: 0.3707 r:0.7080
si_en Dev loss: 0.6652 r:0.6072
ne_en Dev loss: 0.3607 r:0.7594
ru_en Dev loss: 0.3821 r:0.7659
Current avg r:0.6253 Best avg r: 0.6266
19:41:40,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:00,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:33,421 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4239
en_de Dev loss: 1.0725 r:0.2286
en_zh Dev loss: 0.7032 r:0.4962
ro_en Dev loss: 0.3135 r:0.8210
et_en Dev loss: 0.3743 r:0.7026
si_en Dev loss: 0.7498 r:0.5984
ne_en Dev loss: 0.4564 r:0.7580
ru_en Dev loss: 0.4498 r:0.7382
Current avg r:0.6204 Best avg r: 0.6266
19:48:31,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:51,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:24,367 root INFO Epoch 2 Global steps: 27000 Train loss: 0.3880
en_de Dev loss: 1.1317 r:0.2309
en_zh Dev loss: 0.7292 r:0.4811
ro_en Dev loss: 0.3268 r:0.8197
et_en Dev loss: 0.3851 r:0.6958
si_en Dev loss: 0.7613 r:0.5931
ne_en Dev loss: 0.4760 r:0.7534
ru_en Dev loss: 0.5209 r:0.7113
Current avg r:0.6122 Best avg r: 0.6266
19:55:23,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:43,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:16,261 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3732
en_de Dev loss: 1.1525 r:0.2308
en_zh Dev loss: 0.7842 r:0.4731
ro_en Dev loss: 0.3716 r:0.8151
et_en Dev loss: 0.4051 r:0.6870
si_en Dev loss: 0.8337 r:0.5850
ne_en Dev loss: 0.5031 r:0.7475
ru_en Dev loss: 0.5289 r:0.7245
Current avg r:0.6090 Best avg r: 0.6266
20:02:14,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:34,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:07,127 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3734
en_de Dev loss: 1.1265 r:0.2286
en_zh Dev loss: 0.7295 r:0.4834
ro_en Dev loss: 0.3481 r:0.8162
et_en Dev loss: 0.3916 r:0.6947
si_en Dev loss: 0.7532 r:0.5971
ne_en Dev loss: 0.5484 r:0.7519
ru_en Dev loss: 0.4927 r:0.7327
Current avg r:0.6150 Best avg r: 0.6266
20:09:05,403 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:10:25,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:58,202 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3603
en_de Dev loss: 1.0780 r:0.2335
en_zh Dev loss: 0.6940 r:0.4823
ro_en Dev loss: 0.3027 r:0.8217
et_en Dev loss: 0.3887 r:0.6997
si_en Dev loss: 0.5967 r:0.6092
ne_en Dev loss: 0.3780 r:0.7629
ru_en Dev loss: 0.4395 r:0.7359
Current avg r:0.6207 Best avg r: 0.6266
20:15:56,454 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:16,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:49,188 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3721
en_de Dev loss: 1.2037 r:0.2352
en_zh Dev loss: 0.7891 r:0.4819
ro_en Dev loss: 0.3779 r:0.8133
et_en Dev loss: 0.4217 r:0.6871
si_en Dev loss: 0.8243 r:0.5831
ne_en Dev loss: 0.5551 r:0.7561
ru_en Dev loss: 0.5990 r:0.6991
Current avg r:0.6080 Best avg r: 0.6266
20:22:47,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:07,187 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:40,230 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3683
en_de Dev loss: 1.1309 r:0.2350
en_zh Dev loss: 0.7381 r:0.4779
ro_en Dev loss: 0.3358 r:0.8171
et_en Dev loss: 0.4030 r:0.6891
si_en Dev loss: 0.7755 r:0.5910
ne_en Dev loss: 0.4598 r:0.7601
ru_en Dev loss: 0.4613 r:0.7308
Current avg r:0.6144 Best avg r: 0.6266
20:29:38,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:58,144 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:31,201 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3495
en_de Dev loss: 1.1802 r:0.2376
en_zh Dev loss: 0.7699 r:0.4765
ro_en Dev loss: 0.4040 r:0.8145
et_en Dev loss: 0.4134 r:0.6873
si_en Dev loss: 0.7839 r:0.5998
ne_en Dev loss: 0.4783 r:0.7586
ru_en Dev loss: 0.5181 r:0.7279
Current avg r:0.6146 Best avg r: 0.6266
20:36:29,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:49,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:22,227 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3513
en_de Dev loss: 1.1276 r:0.2285
en_zh Dev loss: 0.7256 r:0.4829
ro_en Dev loss: 0.3534 r:0.8163
et_en Dev loss: 0.4032 r:0.6911
si_en Dev loss: 0.7847 r:0.5947
ne_en Dev loss: 0.4971 r:0.7552
ru_en Dev loss: 0.4642 r:0.7409
Current avg r:0.6157 Best avg r: 0.6266
20:43:20,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:40,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:13,243 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3595
en_de Dev loss: 1.1691 r:0.2387
en_zh Dev loss: 0.7588 r:0.4836
ro_en Dev loss: 0.3504 r:0.8163
et_en Dev loss: 0.4020 r:0.6865
si_en Dev loss: 0.7943 r:0.5938
ne_en Dev loss: 0.5019 r:0.7569
ru_en Dev loss: 0.4684 r:0.7379
Current avg r:0.6162 Best avg r: 0.6266
20:50:11,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:31,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:04,124 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3641
en_de Dev loss: 1.1374 r:0.2273
en_zh Dev loss: 0.7389 r:0.4740
ro_en Dev loss: 0.3637 r:0.8071
et_en Dev loss: 0.4217 r:0.6755
si_en Dev loss: 0.8344 r:0.5733
ne_en Dev loss: 0.4899 r:0.7536
ru_en Dev loss: 0.4672 r:0.7259
Current avg r:0.6052 Best avg r: 0.6266
20:57:02,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:21,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:54,576 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3562
en_de Dev loss: 1.1151 r:0.2344
en_zh Dev loss: 0.7033 r:0.4886
ro_en Dev loss: 0.3370 r:0.8185
et_en Dev loss: 0.4203 r:0.6883
si_en Dev loss: 0.7709 r:0.5979
ne_en Dev loss: 0.4040 r:0.7577
ru_en Dev loss: 0.4184 r:0.7514
Current avg r:0.6195 Best avg r: 0.6266
21:03:52,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:05,691 root INFO 
id:en_zh cur r: 0.4970 best r: 0.4970
21:05:12,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:44,899 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3446
en_de Dev loss: 1.0998 r:0.2277
en_zh Dev loss: 0.6971 r:0.4930
ro_en Dev loss: 0.3191 r:0.8185
et_en Dev loss: 0.4117 r:0.6897
si_en Dev loss: 0.7218 r:0.5928
ne_en Dev loss: 0.4332 r:0.7577
ru_en Dev loss: 0.4024 r:0.7537
Current avg r:0.6190 Best avg r: 0.6266
21:10:42,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:02,270 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:35,129 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3443
en_de Dev loss: 1.0921 r:0.2290
en_zh Dev loss: 0.6975 r:0.4909
ro_en Dev loss: 0.3272 r:0.8183
et_en Dev loss: 0.4171 r:0.6906
si_en Dev loss: 0.6399 r:0.6042
ne_en Dev loss: 0.3900 r:0.7602
ru_en Dev loss: 0.4154 r:0.7384
Current avg r:0.6188 Best avg r: 0.6266
21:17:33,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:52,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:25,810 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3572
en_de Dev loss: 1.1236 r:0.2430
en_zh Dev loss: 0.7214 r:0.4776
ro_en Dev loss: 0.3445 r:0.8164
et_en Dev loss: 0.3989 r:0.6893
si_en Dev loss: 0.7437 r:0.5968
ne_en Dev loss: 0.4842 r:0.7564
ru_en Dev loss: 0.4856 r:0.7227
Current avg r:0.6146 Best avg r: 0.6266
21:24:23,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:43,586 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:16,599 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3390
en_de Dev loss: 1.1658 r:0.2339
en_zh Dev loss: 0.7344 r:0.4849
ro_en Dev loss: 0.3411 r:0.8215
et_en Dev loss: 0.4070 r:0.6910
si_en Dev loss: 0.7953 r:0.5937
ne_en Dev loss: 0.4563 r:0.7530
ru_en Dev loss: 0.4572 r:0.7443
Current avg r:0.6175 Best avg r: 0.6266
21:31:14,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:34,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:07,503 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3354
en_de Dev loss: 1.2242 r:0.2413
en_zh Dev loss: 0.7959 r:0.4722
ro_en Dev loss: 0.3947 r:0.8143
et_en Dev loss: 0.4350 r:0.6854
si_en Dev loss: 0.8897 r:0.5841
ne_en Dev loss: 0.5503 r:0.7510
ru_en Dev loss: 0.5052 r:0.7243
Current avg r:0.6104 Best avg r: 0.6266
21:38:06,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:26,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:59,623 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3015
en_de Dev loss: 1.2724 r:0.2440
en_zh Dev loss: 0.8065 r:0.4701
ro_en Dev loss: 0.4026 r:0.8156
et_en Dev loss: 0.4343 r:0.6875
si_en Dev loss: 0.8858 r:0.5887
ne_en Dev loss: 0.6100 r:0.7528
ru_en Dev loss: 0.5690 r:0.7057
Current avg r:0.6092 Best avg r: 0.6266
21:44:57,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:46:17,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:47:50,556 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3120
en_de Dev loss: 1.1737 r:0.2402
en_zh Dev loss: 0.7612 r:0.4738
ro_en Dev loss: 0.3401 r:0.8205
et_en Dev loss: 0.4158 r:0.6814
si_en Dev loss: 0.7623 r:0.5955
ne_en Dev loss: 0.4089 r:0.7578
ru_en Dev loss: 0.4812 r:0.7239
Current avg r:0.6133 Best avg r: 0.6266
21:51:48,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:08,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:41,355 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3069
en_de Dev loss: 1.1197 r:0.2320
en_zh Dev loss: 0.7208 r:0.4725
ro_en Dev loss: 0.3139 r:0.8205
et_en Dev loss: 0.4046 r:0.6817
si_en Dev loss: 0.7637 r:0.5940
ne_en Dev loss: 0.4695 r:0.7573
ru_en Dev loss: 0.4281 r:0.7351
Current avg r:0.6133 Best avg r: 0.6266
21:58:39,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:59,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:32,283 root INFO Epoch 4 Global steps: 38400 Train loss: 0.2900
en_de Dev loss: 1.1351 r:0.2271
en_zh Dev loss: 0.7397 r:0.4855
ro_en Dev loss: 0.3450 r:0.8187
et_en Dev loss: 0.4959 r:0.6934
si_en Dev loss: 0.6183 r:0.6124
ne_en Dev loss: 0.3728 r:0.7523
ru_en Dev loss: 0.4227 r:0.7387
Current avg r:0.6183 Best avg r: 0.6266
22:05:30,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:50,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:08:23,181 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3119
en_de Dev loss: 1.0640 r:0.2291
en_zh Dev loss: 0.6778 r:0.4856
ro_en Dev loss: 0.3050 r:0.8237
et_en Dev loss: 0.4049 r:0.6930
si_en Dev loss: 0.7111 r:0.6044
ne_en Dev loss: 0.4513 r:0.7555
ru_en Dev loss: 0.3891 r:0.7453
Current avg r:0.6195 Best avg r: 0.6266
22:12:21,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:41,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:14,217 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3078
en_de Dev loss: 1.1613 r:0.2382
en_zh Dev loss: 0.7265 r:0.4880
ro_en Dev loss: 0.3759 r:0.8131
et_en Dev loss: 0.4420 r:0.6765
si_en Dev loss: 0.8479 r:0.5850
ne_en Dev loss: 0.4737 r:0.7588
ru_en Dev loss: 0.4531 r:0.7375
Current avg r:0.6139 Best avg r: 0.6266
22:19:12,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:32,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:05,159 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3023
en_de Dev loss: 1.1121 r:0.2394
en_zh Dev loss: 0.7065 r:0.4872
ro_en Dev loss: 0.3364 r:0.8200
et_en Dev loss: 0.4118 r:0.6876
si_en Dev loss: 0.7244 r:0.5971
ne_en Dev loss: 0.4359 r:0.7619
ru_en Dev loss: 0.4294 r:0.7430
Current avg r:0.6195 Best avg r: 0.6266
22:26:03,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:27:23,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:28:56,146 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3109
en_de Dev loss: 1.0923 r:0.2297
en_zh Dev loss: 0.6986 r:0.4872
ro_en Dev loss: 0.3225 r:0.8181
et_en Dev loss: 0.4377 r:0.6921
si_en Dev loss: 0.6472 r:0.6009
ne_en Dev loss: 0.4086 r:0.7508
ru_en Dev loss: 0.4001 r:0.7519
Current avg r:0.6187 Best avg r: 0.6266
22:32:54,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:14,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:47,148 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3062
en_de Dev loss: 1.1714 r:0.2527
en_zh Dev loss: 0.7600 r:0.4829
ro_en Dev loss: 0.3588 r:0.8200
et_en Dev loss: 0.4245 r:0.6907
si_en Dev loss: 0.8066 r:0.5897
ne_en Dev loss: 0.4266 r:0.7559
ru_en Dev loss: 0.4602 r:0.7423
Current avg r:0.6192 Best avg r: 0.6266
22:39:45,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:05,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:38,146 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3014
en_de Dev loss: 1.1041 r:0.2378
en_zh Dev loss: 0.7171 r:0.4834
ro_en Dev loss: 0.3270 r:0.8181
et_en Dev loss: 0.4619 r:0.6883
si_en Dev loss: 0.6618 r:0.5940
ne_en Dev loss: 0.3921 r:0.7493
ru_en Dev loss: 0.4342 r:0.7356
Current avg r:0.6152 Best avg r: 0.6266
22:46:36,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:56,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:29,107 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3043
en_de Dev loss: 1.1028 r:0.2353
en_zh Dev loss: 0.7312 r:0.4735
ro_en Dev loss: 0.3267 r:0.8158
et_en Dev loss: 0.4342 r:0.6761
si_en Dev loss: 0.7374 r:0.5815
ne_en Dev loss: 0.4387 r:0.7461
ru_en Dev loss: 0.4185 r:0.7404
Current avg r:0.6098 Best avg r: 0.6266
22:53:27,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:54:47,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:20,67 root INFO Epoch 4 Global steps: 43200 Train loss: 0.2961
en_de Dev loss: 1.1174 r:0.2488
en_zh Dev loss: 0.7389 r:0.4736
ro_en Dev loss: 0.3346 r:0.8176
et_en Dev loss: 0.4406 r:0.6812
si_en Dev loss: 0.7595 r:0.5826
ne_en Dev loss: 0.4391 r:0.7476
ru_en Dev loss: 0.4606 r:0.7239
Current avg r:0.6108 Best avg r: 0.6266
23:00:18,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:37,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:11,33 root INFO Epoch 4 Global steps: 43800 Train loss: 0.2859
en_de Dev loss: 1.1442 r:0.2441
en_zh Dev loss: 0.7693 r:0.4661
ro_en Dev loss: 0.3449 r:0.8184
et_en Dev loss: 0.4437 r:0.6726
si_en Dev loss: 0.7900 r:0.5845
ne_en Dev loss: 0.4674 r:0.7519
ru_en Dev loss: 0.4457 r:0.7389
Current avg r:0.6109 Best avg r: 0.6266
23:07:09,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:28,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:02,47 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2988
en_de Dev loss: 1.1744 r:0.2402
en_zh Dev loss: 0.7668 r:0.4755
ro_en Dev loss: 0.3633 r:0.8217
et_en Dev loss: 0.4413 r:0.6821
si_en Dev loss: 0.7693 r:0.5942
ne_en Dev loss: 0.4596 r:0.7540
ru_en Dev loss: 0.4859 r:0.7390
Current avg r:0.6152 Best avg r: 0.6266
23:13:59,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:19,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:52,421 root INFO Epoch 4 Global steps: 45000 Train loss: 0.2899
en_de Dev loss: 1.1860 r:0.2375
en_zh Dev loss: 0.7828 r:0.4701
ro_en Dev loss: 0.3805 r:0.8183
et_en Dev loss: 0.4459 r:0.6751
si_en Dev loss: 0.8192 r:0.5755
ne_en Dev loss: 0.5049 r:0.7421
ru_en Dev loss: 0.4799 r:0.7436
Current avg r:0.6089 Best avg r: 0.6266
23:20:51,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:10,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:43,770 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2653
en_de Dev loss: 1.1598 r:0.2258
en_zh Dev loss: 0.7657 r:0.4632
ro_en Dev loss: 0.3659 r:0.8158
et_en Dev loss: 0.4456 r:0.6739
si_en Dev loss: 0.7417 r:0.5820
ne_en Dev loss: 0.4382 r:0.7418
ru_en Dev loss: 0.4649 r:0.7335
Current avg r:0.6051 Best avg r: 0.6266
23:27:41,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:00,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:33,615 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2569
en_de Dev loss: 1.2147 r:0.2319
en_zh Dev loss: 0.7924 r:0.4700
ro_en Dev loss: 0.3865 r:0.8197
et_en Dev loss: 0.4519 r:0.6745
si_en Dev loss: 0.8369 r:0.5809
ne_en Dev loss: 0.4819 r:0.7456
ru_en Dev loss: 0.4574 r:0.7461
Current avg r:0.6098 Best avg r: 0.6266
23:34:31,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:50,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:23,594 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2516
en_de Dev loss: 1.1568 r:0.2338
en_zh Dev loss: 0.7605 r:0.4693
ro_en Dev loss: 0.3564 r:0.8160
et_en Dev loss: 0.4470 r:0.6750
si_en Dev loss: 0.7902 r:0.5775
ne_en Dev loss: 0.4501 r:0.7510
ru_en Dev loss: 0.4614 r:0.7331
Current avg r:0.6080 Best avg r: 0.6266
23:41:21,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:40,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:13,666 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2649
en_de Dev loss: 1.1517 r:0.2428
en_zh Dev loss: 0.7467 r:0.4811
ro_en Dev loss: 0.3603 r:0.8197
et_en Dev loss: 0.4606 r:0.6784
si_en Dev loss: 0.8213 r:0.5790
ne_en Dev loss: 0.4695 r:0.7475
ru_en Dev loss: 0.4335 r:0.7495
Current avg r:0.6140 Best avg r: 0.6266
23:48:11,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:31,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:51:03,887 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2615
en_de Dev loss: 1.1634 r:0.2427
en_zh Dev loss: 0.7760 r:0.4599
ro_en Dev loss: 0.3579 r:0.8174
et_en Dev loss: 0.4513 r:0.6643
si_en Dev loss: 0.8337 r:0.5665
ne_en Dev loss: 0.4948 r:0.7446
ru_en Dev loss: 0.4601 r:0.7320
Current avg r:0.6039 Best avg r: 0.6266
23:55:01,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:20,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:53,414 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2550
en_de Dev loss: 1.1615 r:0.2381
en_zh Dev loss: 0.7746 r:0.4635
ro_en Dev loss: 0.3424 r:0.8213
et_en Dev loss: 0.4677 r:0.6786
si_en Dev loss: 0.7927 r:0.5707
ne_en Dev loss: 0.4342 r:0.7410
ru_en Dev loss: 0.4259 r:0.7488
Current avg r:0.6089 Best avg r: 0.6266
00:01:50,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:10,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:42,727 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2627
en_de Dev loss: 1.1607 r:0.2469
en_zh Dev loss: 0.7767 r:0.4681
ro_en Dev loss: 0.3620 r:0.8188
et_en Dev loss: 0.4515 r:0.6733
si_en Dev loss: 0.7827 r:0.5774
ne_en Dev loss: 0.4607 r:0.7474
ru_en Dev loss: 0.4436 r:0.7494
Current avg r:0.6116 Best avg r: 0.6266
00:08:39,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:59,270 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:31,998 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2622
en_de Dev loss: 1.1319 r:0.2521
en_zh Dev loss: 0.7746 r:0.4689
ro_en Dev loss: 0.3550 r:0.8155
et_en Dev loss: 0.4505 r:0.6652
si_en Dev loss: 0.8340 r:0.5693
ne_en Dev loss: 0.4977 r:0.7428
ru_en Dev loss: 0.4858 r:0.7257
Current avg r:0.6056 Best avg r: 0.6266
00:15:28,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:16:48,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:18:21,80 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2574
en_de Dev loss: 1.1522 r:0.2481
en_zh Dev loss: 0.7897 r:0.4680
ro_en Dev loss: 0.3895 r:0.8066
et_en Dev loss: 0.5144 r:0.6609
si_en Dev loss: 0.8171 r:0.5632
ne_en Dev loss: 0.4983 r:0.7314
ru_en Dev loss: 0.5040 r:0.7184
Current avg r:0.5995 Best avg r: 0.6266
00:22:17,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:37,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:10,149 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2546
en_de Dev loss: 1.1387 r:0.2436
en_zh Dev loss: 0.7827 r:0.4668
ro_en Dev loss: 0.3549 r:0.8147
et_en Dev loss: 0.4700 r:0.6756
si_en Dev loss: 0.7939 r:0.5729
ne_en Dev loss: 0.5156 r:0.7379
ru_en Dev loss: 0.4773 r:0.7336
Current avg r:0.6065 Best avg r: 0.6266
00:29:07,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:30:26,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:59,600 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2444
en_de Dev loss: 1.0829 r:0.2476
en_zh Dev loss: 0.7498 r:0.4589
ro_en Dev loss: 0.3221 r:0.8162
et_en Dev loss: 0.4653 r:0.6761
si_en Dev loss: 0.7438 r:0.5676
ne_en Dev loss: 0.4448 r:0.7422
ru_en Dev loss: 0.4330 r:0.7331
Current avg r:0.6059 Best avg r: 0.6266
00:35:56,654 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:16,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:48,866 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2530
en_de Dev loss: 1.2130 r:0.2523
en_zh Dev loss: 0.8343 r:0.4581
ro_en Dev loss: 0.4075 r:0.8134
et_en Dev loss: 0.4667 r:0.6661
si_en Dev loss: 0.9411 r:0.5607
ne_en Dev loss: 0.5930 r:0.7417
ru_en Dev loss: 0.5302 r:0.7209
Current avg r:0.6019 Best avg r: 0.6266
00:42:46,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:05,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:38,682 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2473
en_de Dev loss: 1.1636 r:0.2462
en_zh Dev loss: 0.7823 r:0.4576
ro_en Dev loss: 0.3756 r:0.8099
et_en Dev loss: 0.4795 r:0.6622
si_en Dev loss: 0.8794 r:0.5628
ne_en Dev loss: 0.5190 r:0.7373
ru_en Dev loss: 0.4629 r:0.7301
Current avg r:0.6009 Best avg r: 0.6266
00:49:36,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:55,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:28,571 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2425
en_de Dev loss: 1.1279 r:0.2233
en_zh Dev loss: 0.7394 r:0.4725
ro_en Dev loss: 0.3385 r:0.8153
et_en Dev loss: 0.4795 r:0.6698
si_en Dev loss: 0.7159 r:0.5796
ne_en Dev loss: 0.4313 r:0.7373
ru_en Dev loss: 0.4141 r:0.7438
Current avg r:0.6059 Best avg r: 0.6266
00:56:26,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:45,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:18,429 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2624
en_de Dev loss: 1.1427 r:0.2499
en_zh Dev loss: 0.7578 r:0.4711
ro_en Dev loss: 0.3643 r:0.8153
et_en Dev loss: 0.4563 r:0.6633
si_en Dev loss: 0.8448 r:0.5674
ne_en Dev loss: 0.4945 r:0.7343
ru_en Dev loss: 0.5005 r:0.7143
Current avg r:0.6022 Best avg r: 0.6266
01:03:16,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:36,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:08,664 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2145
en_de Dev loss: 1.2840 r:0.2407
en_zh Dev loss: 0.8736 r:0.4591
ro_en Dev loss: 0.4295 r:0.8081
et_en Dev loss: 0.5111 r:0.6534
si_en Dev loss: 0.9847 r:0.5536
ne_en Dev loss: 0.5667 r:0.7286
ru_en Dev loss: 0.5982 r:0.6986
Current avg r:0.5917 Best avg r: 0.6266
01:10:05,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:24,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:57,660 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2192
en_de Dev loss: 1.1375 r:0.2437
en_zh Dev loss: 0.7813 r:0.4557
ro_en Dev loss: 0.3627 r:0.8106
et_en Dev loss: 0.4658 r:0.6558
si_en Dev loss: 0.8251 r:0.5673
ne_en Dev loss: 0.5141 r:0.7388
ru_en Dev loss: 0.4752 r:0.7243
Current avg r:0.5995 Best avg r: 0.6266
01:16:54,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:18:14,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:46,796 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2223
en_de Dev loss: 1.1676 r:0.2272
en_zh Dev loss: 0.7928 r:0.4631
ro_en Dev loss: 0.3626 r:0.8133
et_en Dev loss: 0.5174 r:0.6737
si_en Dev loss: 0.8071 r:0.5743
ne_en Dev loss: 0.4540 r:0.7380
ru_en Dev loss: 0.4161 r:0.7588
Current avg r:0.6069 Best avg r: 0.6266
01:23:43,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:03,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:35,777 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2248
en_de Dev loss: 1.2475 r:0.2301
en_zh Dev loss: 0.8767 r:0.4449
ro_en Dev loss: 0.4027 r:0.8065
et_en Dev loss: 0.5028 r:0.6428
si_en Dev loss: 1.0265 r:0.5479
ne_en Dev loss: 0.6288 r:0.7251
ru_en Dev loss: 0.5542 r:0.7071
Current avg r:0.5864 Best avg r: 0.6266
01:30:32,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:51,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:33:24,594 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2149
en_de Dev loss: 1.1527 r:0.2414
en_zh Dev loss: 0.8027 r:0.4449
ro_en Dev loss: 0.3756 r:0.8073
et_en Dev loss: 0.4958 r:0.6553
si_en Dev loss: 0.8375 r:0.5643
ne_en Dev loss: 0.4495 r:0.7319
ru_en Dev loss: 0.4955 r:0.7163
Current avg r:0.5945 Best avg r: 0.6266
01:37:21,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:38:40,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:40:13,374 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2167
en_de Dev loss: 1.1681 r:0.2422
en_zh Dev loss: 0.7972 r:0.4630
ro_en Dev loss: 0.3626 r:0.8148
et_en Dev loss: 0.4999 r:0.6728
si_en Dev loss: 0.7477 r:0.5805
ne_en Dev loss: 0.4407 r:0.7351
ru_en Dev loss: 0.4717 r:0.7351
Current avg r:0.6062 Best avg r: 0.6266
01:44:10,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:45:29,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:47:02,255 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2102
en_de Dev loss: 1.1455 r:0.2363
en_zh Dev loss: 0.7855 r:0.4523
ro_en Dev loss: 0.3434 r:0.8161
et_en Dev loss: 0.4601 r:0.6663
si_en Dev loss: 0.7470 r:0.5767
ne_en Dev loss: 0.4289 r:0.7363
ru_en Dev loss: 0.4492 r:0.7337
Current avg r:0.6025 Best avg r: 0.6266
01:50:59,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:52:18,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:53:51,94 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2128
en_de Dev loss: 1.1840 r:0.2362
en_zh Dev loss: 0.8179 r:0.4502
ro_en Dev loss: 0.3954 r:0.8069
et_en Dev loss: 0.4963 r:0.6572
si_en Dev loss: 0.8736 r:0.5519
ne_en Dev loss: 0.5231 r:0.7299
ru_en Dev loss: 0.5166 r:0.7143
Current avg r:0.5924 Best avg r: 0.6266
01:57:47,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:59:07,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:40,100 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2182
en_de Dev loss: 1.1337 r:0.2337
en_zh Dev loss: 0.7779 r:0.4624
ro_en Dev loss: 0.3454 r:0.8151
et_en Dev loss: 0.4673 r:0.6715
si_en Dev loss: 0.7478 r:0.5706
ne_en Dev loss: 0.4328 r:0.7389
ru_en Dev loss: 0.4067 r:0.7541
Current avg r:0.6066 Best avg r: 0.6266
02:04:37,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:56,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:29,319 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2062
en_de Dev loss: 1.2021 r:0.2327
en_zh Dev loss: 0.8254 r:0.4556
ro_en Dev loss: 0.3825 r:0.8124
et_en Dev loss: 0.4847 r:0.6698
si_en Dev loss: 0.8419 r:0.5639
ne_en Dev loss: 0.5095 r:0.7293
ru_en Dev loss: 0.4582 r:0.7413
Current avg r:0.6007 Best avg r: 0.6266
02:11:26,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:45,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:18,471 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2152
en_de Dev loss: 1.1180 r:0.2470
en_zh Dev loss: 0.7618 r:0.4654
ro_en Dev loss: 0.3470 r:0.8124
et_en Dev loss: 0.4715 r:0.6657
si_en Dev loss: 0.7594 r:0.5655
ne_en Dev loss: 0.4478 r:0.7303
ru_en Dev loss: 0.4411 r:0.7335
Current avg r:0.6028 Best avg r: 0.6266
02:18:15,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:19:34,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:21:07,716 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2110
en_de Dev loss: 1.1956 r:0.2434
en_zh Dev loss: 0.8160 r:0.4642
ro_en Dev loss: 0.3767 r:0.8126
et_en Dev loss: 0.4891 r:0.6637
si_en Dev loss: 0.8698 r:0.5646
ne_en Dev loss: 0.5041 r:0.7344
ru_en Dev loss: 0.4976 r:0.7231
Current avg r:0.6009 Best avg r: 0.6266
02:25:04,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:26:24,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:57,71 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2015
en_de Dev loss: 1.1705 r:0.2269
en_zh Dev loss: 0.7870 r:0.4621
ro_en Dev loss: 0.3480 r:0.8133
et_en Dev loss: 0.4902 r:0.6624
si_en Dev loss: 0.8213 r:0.5631
ne_en Dev loss: 0.4525 r:0.7361
ru_en Dev loss: 0.4113 r:0.7523
Current avg r:0.6023 Best avg r: 0.6266
02:31:54,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:33:13,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:34:46,418 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2141
en_de Dev loss: 1.1343 r:0.2364
en_zh Dev loss: 0.7547 r:0.4750
ro_en Dev loss: 0.3318 r:0.8190
et_en Dev loss: 0.4607 r:0.6679
si_en Dev loss: 0.7817 r:0.5681
ne_en Dev loss: 0.4681 r:0.7368
ru_en Dev loss: 0.4160 r:0.7490
Current avg r:0.6075 Best avg r: 0.6266
02:38:43,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:40:02,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:41:35,602 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2070
en_de Dev loss: 1.1552 r:0.2357
en_zh Dev loss: 0.7836 r:0.4698
ro_en Dev loss: 0.3666 r:0.8090
et_en Dev loss: 0.4793 r:0.6602
si_en Dev loss: 0.8440 r:0.5544
ne_en Dev loss: 0.5215 r:0.7326
ru_en Dev loss: 0.4572 r:0.7319
Current avg r:0.5991 Best avg r: 0.6266
02:45:33,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:46:53,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:48:26,112 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1901
en_de Dev loss: 1.1580 r:0.2330
en_zh Dev loss: 0.7780 r:0.4636
ro_en Dev loss: 0.3574 r:0.8134
et_en Dev loss: 0.4628 r:0.6547
si_en Dev loss: 0.8677 r:0.5513
ne_en Dev loss: 0.5505 r:0.7303
ru_en Dev loss: 0.4330 r:0.7412
Current avg r:0.5982 Best avg r: 0.6266
02:52:23,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:53:42,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:55:15,319 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1793
en_de Dev loss: 1.3069 r:0.2260
en_zh Dev loss: 0.8871 r:0.4538
ro_en Dev loss: 0.4270 r:0.8082
et_en Dev loss: 0.5114 r:0.6516
si_en Dev loss: 0.9796 r:0.5384
ne_en Dev loss: 0.5581 r:0.7286
ru_en Dev loss: 0.5183 r:0.7268
Current avg r:0.5905 Best avg r: 0.6266
02:59:12,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:00:32,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:02:04,808 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1915
en_de Dev loss: 1.1747 r:0.2220
en_zh Dev loss: 0.7891 r:0.4567
ro_en Dev loss: 0.3520 r:0.8120
et_en Dev loss: 0.5005 r:0.6661
si_en Dev loss: 0.7738 r:0.5587
ne_en Dev loss: 0.4486 r:0.7269
ru_en Dev loss: 0.4209 r:0.7430
Current avg r:0.5979 Best avg r: 0.6266
03:06:01,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:07:21,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:54,202 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1778
en_de Dev loss: 1.2091 r:0.2203
en_zh Dev loss: 0.8007 r:0.4637
ro_en Dev loss: 0.3682 r:0.8116
et_en Dev loss: 0.4951 r:0.6417
si_en Dev loss: 0.9113 r:0.5373
ne_en Dev loss: 0.5101 r:0.7280
ru_en Dev loss: 0.4741 r:0.7299
Current avg r:0.5903 Best avg r: 0.6266
03:12:51,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:11,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:15:44,69 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1886
en_de Dev loss: 1.2075 r:0.2323
en_zh Dev loss: 0.8048 r:0.4599
ro_en Dev loss: 0.3754 r:0.8125
et_en Dev loss: 0.4844 r:0.6509
si_en Dev loss: 0.9261 r:0.5441
ne_en Dev loss: 0.5119 r:0.7236
ru_en Dev loss: 0.4739 r:0.7303
Current avg r:0.5934 Best avg r: 0.6266
03:19:41,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:01,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:34,207 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1794
en_de Dev loss: 1.1742 r:0.2151
en_zh Dev loss: 0.7507 r:0.4748
ro_en Dev loss: 0.3334 r:0.8185
et_en Dev loss: 0.4997 r:0.6706
si_en Dev loss: 0.7272 r:0.5708
ne_en Dev loss: 0.4313 r:0.7264
ru_en Dev loss: 0.4108 r:0.7479
Current avg r:0.6035 Best avg r: 0.6266
03:26:31,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:27:51,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:29:24,245 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1860
en_de Dev loss: 1.2597 r:0.2313
en_zh Dev loss: 0.8244 r:0.4658
ro_en Dev loss: 0.3853 r:0.8127
et_en Dev loss: 0.4947 r:0.6519
si_en Dev loss: 0.8745 r:0.5456
ne_en Dev loss: 0.5625 r:0.7243
ru_en Dev loss: 0.4953 r:0.7310
Current avg r:0.5947 Best avg r: 0.6266
03:33:21,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:34:41,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:14,116 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1886
en_de Dev loss: 1.1645 r:0.2216
en_zh Dev loss: 0.7424 r:0.4781
ro_en Dev loss: 0.3211 r:0.8207
et_en Dev loss: 0.4596 r:0.6721
si_en Dev loss: 0.7917 r:0.5626
ne_en Dev loss: 0.4510 r:0.7318
ru_en Dev loss: 0.4275 r:0.7406
Current avg r:0.6039 Best avg r: 0.6266
03:40:11,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:41:30,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:43:03,417 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1762
en_de Dev loss: 1.1982 r:0.2288
en_zh Dev loss: 0.7731 r:0.4730
ro_en Dev loss: 0.3679 r:0.8163
et_en Dev loss: 0.4727 r:0.6616
si_en Dev loss: 0.8511 r:0.5574
ne_en Dev loss: 0.4819 r:0.7278
ru_en Dev loss: 0.4667 r:0.7345
Current avg r:0.5999 Best avg r: 0.6266
03:47:00,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:48:19,815 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:49:52,501 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1833
en_de Dev loss: 1.1342 r:0.2206
en_zh Dev loss: 0.7447 r:0.4772
ro_en Dev loss: 0.3539 r:0.8133
et_en Dev loss: 0.5007 r:0.6711
si_en Dev loss: 0.8065 r:0.5576
ne_en Dev loss: 0.4846 r:0.7264
ru_en Dev loss: 0.4181 r:0.7454
Current avg r:0.6017 Best avg r: 0.6266
03:53:49,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:55:09,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:56:41,986 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1725
en_de Dev loss: 1.1443 r:0.2186
en_zh Dev loss: 0.7595 r:0.4692
ro_en Dev loss: 0.3390 r:0.8154
et_en Dev loss: 0.4645 r:0.6681
si_en Dev loss: 0.8196 r:0.5544
ne_en Dev loss: 0.5089 r:0.7258
ru_en Dev loss: 0.4367 r:0.7398
Current avg r:0.5988 Best avg r: 0.6266
04:00:39,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:01:59,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:03:32,28 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1705
en_de Dev loss: 1.1187 r:0.2212
en_zh Dev loss: 0.7368 r:0.4732
ro_en Dev loss: 0.3433 r:0.8152
et_en Dev loss: 0.4737 r:0.6528
si_en Dev loss: 0.9074 r:0.5415
ne_en Dev loss: 0.5347 r:0.7249
ru_en Dev loss: 0.4550 r:0.7338
Current avg r:0.5947 Best avg r: 0.6266
04:07:29,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:08:49,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:10:22,131 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1762
en_de Dev loss: 1.1824 r:0.2247
en_zh Dev loss: 0.7779 r:0.4673
ro_en Dev loss: 0.3744 r:0.8126
et_en Dev loss: 0.4847 r:0.6558
si_en Dev loss: 0.9036 r:0.5500
ne_en Dev loss: 0.5375 r:0.7276
ru_en Dev loss: 0.4462 r:0.7441
Current avg r:0.5974 Best avg r: 0.6266
04:14:19,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:15:39,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:17:12,141 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1677
en_de Dev loss: 1.2371 r:0.2293
en_zh Dev loss: 0.8258 r:0.4669
ro_en Dev loss: 0.3905 r:0.8106
et_en Dev loss: 0.4951 r:0.6519
si_en Dev loss: 0.9153 r:0.5439
ne_en Dev loss: 0.5786 r:0.7247
ru_en Dev loss: 0.4641 r:0.7438
Current avg r:0.5959 Best avg r: 0.6266
04:21:09,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:22:29,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:24:02,227 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1729
en_de Dev loss: 1.2112 r:0.2193
en_zh Dev loss: 0.8083 r:0.4676
ro_en Dev loss: 0.3756 r:0.8108
et_en Dev loss: 0.5040 r:0.6592
si_en Dev loss: 0.8546 r:0.5521
ne_en Dev loss: 0.5056 r:0.7268
ru_en Dev loss: 0.4556 r:0.7343
Current avg r:0.5957 Best avg r: 0.6266
04:28:00,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:19,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:52,675 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1560
en_de Dev loss: 1.1954 r:0.2217
en_zh Dev loss: 0.7825 r:0.4755
ro_en Dev loss: 0.3657 r:0.8131
et_en Dev loss: 0.5089 r:0.6581
si_en Dev loss: 0.8848 r:0.5470
ne_en Dev loss: 0.5028 r:0.7276
ru_en Dev loss: 0.4341 r:0.7471
Current avg r:0.5986 Best avg r: 0.6266
04:34:49,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:09,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:42,142 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1660
en_de Dev loss: 1.2202 r:0.2212
en_zh Dev loss: 0.7896 r:0.4800
ro_en Dev loss: 0.4012 r:0.8090
et_en Dev loss: 0.4836 r:0.6469
si_en Dev loss: 0.9014 r:0.5473
ne_en Dev loss: 0.6663 r:0.7209
ru_en Dev loss: 0.4927 r:0.7277
Current avg r:0.5933 Best avg r: 0.6266
04:41:39,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:42:58,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:31,418 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1609
en_de Dev loss: 1.2041 r:0.2223
en_zh Dev loss: 0.7826 r:0.4717
ro_en Dev loss: 0.3740 r:0.8121
et_en Dev loss: 0.4727 r:0.6466
si_en Dev loss: 0.8695 r:0.5500
ne_en Dev loss: 0.5110 r:0.7285
ru_en Dev loss: 0.4851 r:0.7219
Current avg r:0.5933 Best avg r: 0.6266
04:48:28,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:49:48,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:20,804 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1559
en_de Dev loss: 1.2253 r:0.2260
en_zh Dev loss: 0.7892 r:0.4719
ro_en Dev loss: 0.3899 r:0.8142
et_en Dev loss: 0.4747 r:0.6620
si_en Dev loss: 0.8886 r:0.5575
ne_en Dev loss: 0.5503 r:0.7343
ru_en Dev loss: 0.4593 r:0.7405
Current avg r:0.6009 Best avg r: 0.6266
04:55:18,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:56:38,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:11,41 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1563
en_de Dev loss: 1.1945 r:0.2237
en_zh Dev loss: 0.7619 r:0.4833
ro_en Dev loss: 0.3556 r:0.8176
et_en Dev loss: 0.5154 r:0.6689
si_en Dev loss: 0.7882 r:0.5675
ne_en Dev loss: 0.4558 r:0.7375
ru_en Dev loss: 0.4123 r:0.7496
Current avg r:0.6069 Best avg r: 0.6266
05:02:08,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:28,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:05:01,263 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1545
en_de Dev loss: 1.1764 r:0.2273
en_zh Dev loss: 0.7644 r:0.4705
ro_en Dev loss: 0.3490 r:0.8155
et_en Dev loss: 0.4748 r:0.6606
si_en Dev loss: 0.8386 r:0.5495
ne_en Dev loss: 0.5125 r:0.7265
ru_en Dev loss: 0.4609 r:0.7293
Current avg r:0.5970 Best avg r: 0.6266
05:08:59,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:18,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:51,509 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1524
en_de Dev loss: 1.2661 r:0.2295
en_zh Dev loss: 0.8281 r:0.4710
ro_en Dev loss: 0.4142 r:0.8097
et_en Dev loss: 0.4992 r:0.6479
si_en Dev loss: 0.9485 r:0.5419
ne_en Dev loss: 0.6833 r:0.7273
ru_en Dev loss: 0.5385 r:0.7141
Current avg r:0.5916 Best avg r: 0.6266
05:15:49,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:08,711 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:41,566 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1592
en_de Dev loss: 1.1414 r:0.2321
en_zh Dev loss: 0.7403 r:0.4757
ro_en Dev loss: 0.3469 r:0.8136
et_en Dev loss: 0.4918 r:0.6532
si_en Dev loss: 0.7909 r:0.5597
ne_en Dev loss: 0.4827 r:0.7309
ru_en Dev loss: 0.4277 r:0.7324
Current avg r:0.5997 Best avg r: 0.6266
05:22:39,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:23:58,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:31,449 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1524
en_de Dev loss: 1.1993 r:0.2351
en_zh Dev loss: 0.7703 r:0.4794
ro_en Dev loss: 0.3577 r:0.8151
et_en Dev loss: 0.4904 r:0.6628
si_en Dev loss: 0.8245 r:0.5597
ne_en Dev loss: 0.5022 r:0.7264
ru_en Dev loss: 0.4587 r:0.7284
Current avg r:0.6010 Best avg r: 0.6266
05:29:29,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:48,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:32:21,424 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1533
en_de Dev loss: 1.2784 r:0.2413
en_zh Dev loss: 0.8389 r:0.4668
ro_en Dev loss: 0.4206 r:0.8106
et_en Dev loss: 0.5282 r:0.6494
si_en Dev loss: 0.9076 r:0.5460
ne_en Dev loss: 0.6046 r:0.7254
ru_en Dev loss: 0.5041 r:0.7250
Current avg r:0.5949 Best avg r: 0.6266
05:36:19,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:38,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:39:11,389 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1510
en_de Dev loss: 1.2175 r:0.2332
en_zh Dev loss: 0.8063 r:0.4688
ro_en Dev loss: 0.3939 r:0.8085
et_en Dev loss: 0.4998 r:0.6345
si_en Dev loss: 0.9749 r:0.5306
ne_en Dev loss: 0.6608 r:0.7182
ru_en Dev loss: 0.5019 r:0.7197
Current avg r:0.5876 Best avg r: 0.6266
05:43:08,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:28,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:01,400 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1577
en_de Dev loss: 1.2627 r:0.2231
en_zh Dev loss: 0.8003 r:0.4820
ro_en Dev loss: 0.3810 r:0.8174
et_en Dev loss: 0.5038 r:0.6598
si_en Dev loss: 0.8634 r:0.5583
ne_en Dev loss: 0.5125 r:0.7316
ru_en Dev loss: 0.4677 r:0.7349
Current avg r:0.6010 Best avg r: 0.6266
05:49:59,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:18,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:52:51,548 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1606
en_de Dev loss: 1.2295 r:0.2261
en_zh Dev loss: 0.7965 r:0.4715
ro_en Dev loss: 0.3603 r:0.8184
et_en Dev loss: 0.4914 r:0.6606
si_en Dev loss: 0.8792 r:0.5457
ne_en Dev loss: 0.5316 r:0.7212
ru_en Dev loss: 0.4831 r:0.7230
Current avg r:0.5952 Best avg r: 0.6266
05:56:49,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:58:08,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:41,709 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1547
en_de Dev loss: 1.2022 r:0.2322
en_zh Dev loss: 0.7851 r:0.4770
ro_en Dev loss: 0.3759 r:0.8153
et_en Dev loss: 0.4823 r:0.6497
si_en Dev loss: 0.9106 r:0.5368
ne_en Dev loss: 0.5843 r:0.7194
ru_en Dev loss: 0.4572 r:0.7368
Current avg r:0.5953 Best avg r: 0.6266
06:03:39,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:59,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:06:31,937 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1541
en_de Dev loss: 1.2282 r:0.2382
en_zh Dev loss: 0.8143 r:0.4756
ro_en Dev loss: 0.3968 r:0.8098
et_en Dev loss: 0.5037 r:0.6432
si_en Dev loss: 0.9060 r:0.5360
ne_en Dev loss: 0.5787 r:0.7151
ru_en Dev loss: 0.5145 r:0.7172
Current avg r:0.5907 Best avg r: 0.6266
06:10:30,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:50,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:13:23,21 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1344
en_de Dev loss: 1.1648 r:0.2150
en_zh Dev loss: 0.7463 r:0.4829
ro_en Dev loss: 0.3379 r:0.8148
et_en Dev loss: 0.4794 r:0.6502
si_en Dev loss: 0.8441 r:0.5492
ne_en Dev loss: 0.5144 r:0.7198
ru_en Dev loss: 0.4433 r:0.7338
Current avg r:0.5951 Best avg r: 0.6266
06:17:20,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:18:39,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:20:12,444 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1373
en_de Dev loss: 1.1878 r:0.2266
en_zh Dev loss: 0.7645 r:0.4845
ro_en Dev loss: 0.3609 r:0.8153
et_en Dev loss: 0.5090 r:0.6584
si_en Dev loss: 0.8403 r:0.5506
ne_en Dev loss: 0.5020 r:0.7222
ru_en Dev loss: 0.4349 r:0.7445
Current avg r:0.6003 Best avg r: 0.6266
06:24:09,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:25:29,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:27:02,223 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1341
en_de Dev loss: 1.1441 r:0.2233
en_zh Dev loss: 0.7441 r:0.4784
ro_en Dev loss: 0.3453 r:0.8137
et_en Dev loss: 0.4809 r:0.6556
si_en Dev loss: 0.8195 r:0.5507
ne_en Dev loss: 0.5293 r:0.7182
ru_en Dev loss: 0.4329 r:0.7344
Current avg r:0.5963 Best avg r: 0.6266
06:30:59,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:32:19,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:33:52,342 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1414
en_de Dev loss: 1.1843 r:0.2236
en_zh Dev loss: 0.7644 r:0.4773
ro_en Dev loss: 0.3532 r:0.8146
et_en Dev loss: 0.4797 r:0.6610
si_en Dev loss: 0.8409 r:0.5540
ne_en Dev loss: 0.5457 r:0.7196
ru_en Dev loss: 0.4586 r:0.7310
Current avg r:0.5973 Best avg r: 0.6266
06:37:50,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:39:09,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:40:42,521 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1392
en_de Dev loss: 1.2554 r:0.2240
en_zh Dev loss: 0.8253 r:0.4635
ro_en Dev loss: 0.4088 r:0.8103
et_en Dev loss: 0.4835 r:0.6561
si_en Dev loss: 0.9021 r:0.5483
ne_en Dev loss: 0.6032 r:0.7143
ru_en Dev loss: 0.4993 r:0.7287
Current avg r:0.5922 Best avg r: 0.6266
06:44:40,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:59,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:47:32,670 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1409
en_de Dev loss: 1.2213 r:0.2225
en_zh Dev loss: 0.8102 r:0.4676
ro_en Dev loss: 0.3722 r:0.8120
et_en Dev loss: 0.4825 r:0.6461
si_en Dev loss: 0.9268 r:0.5417
ne_en Dev loss: 0.6176 r:0.7113
ru_en Dev loss: 0.4789 r:0.7337
Current avg r:0.5907 Best avg r: 0.6266
06:51:30,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:50,80 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:54:22,977 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1343
en_de Dev loss: 1.2293 r:0.2138
en_zh Dev loss: 0.7911 r:0.4740
ro_en Dev loss: 0.3730 r:0.8113
et_en Dev loss: 0.4865 r:0.6586
si_en Dev loss: 0.8587 r:0.5518
ne_en Dev loss: 0.5249 r:0.7159
ru_en Dev loss: 0.4586 r:0.7396
Current avg r:0.5950 Best avg r: 0.6266
06:58:20,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:59:40,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:13,353 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1368
en_de Dev loss: 1.1482 r:0.2266
en_zh Dev loss: 0.7246 r:0.4898
ro_en Dev loss: 0.3510 r:0.8135
et_en Dev loss: 0.4675 r:0.6612
si_en Dev loss: 0.8337 r:0.5501
ne_en Dev loss: 0.5325 r:0.7169
ru_en Dev loss: 0.4132 r:0.7508
Current avg r:0.6013 Best avg r: 0.6266
07:05:11,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:06:30,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:03,713 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1380
en_de Dev loss: 1.2032 r:0.2177
en_zh Dev loss: 0.7517 r:0.4859
ro_en Dev loss: 0.3614 r:0.8143
et_en Dev loss: 0.4847 r:0.6559
si_en Dev loss: 0.8667 r:0.5477
ne_en Dev loss: 0.5116 r:0.7226
ru_en Dev loss: 0.4158 r:0.7524
Current avg r:0.5995 Best avg r: 0.6266
07:12:01,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:21,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:14:54,49 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1307
en_de Dev loss: 1.2145 r:0.2032
en_zh Dev loss: 0.7564 r:0.4798
ro_en Dev loss: 0.3586 r:0.8131
et_en Dev loss: 0.4804 r:0.6517
si_en Dev loss: 0.8684 r:0.5502
ne_en Dev loss: 0.5550 r:0.7186
ru_en Dev loss: 0.4256 r:0.7468
Current avg r:0.5948 Best avg r: 0.6266
07:18:51,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:20:11,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:21:43,747 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1324
en_de Dev loss: 1.2782 r:0.2257
en_zh Dev loss: 0.8250 r:0.4665
ro_en Dev loss: 0.3992 r:0.8120
et_en Dev loss: 0.5127 r:0.6448
si_en Dev loss: 0.9274 r:0.5494
ne_en Dev loss: 0.6040 r:0.7179
ru_en Dev loss: 0.4731 r:0.7339
Current avg r:0.5929 Best avg r: 0.6266
07:25:40,865 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:27:00,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:28:33,120 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1374
en_de Dev loss: 1.1839 r:0.2321
en_zh Dev loss: 0.7558 r:0.4769
ro_en Dev loss: 0.3391 r:0.8172
et_en Dev loss: 0.5030 r:0.6563
si_en Dev loss: 0.8010 r:0.5538
ne_en Dev loss: 0.4956 r:0.7144
ru_en Dev loss: 0.4520 r:0.7317
Current avg r:0.5975 Best avg r: 0.6266
07:32:30,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:33:49,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:35:22,500 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1346
en_de Dev loss: 1.2424 r:0.2381
en_zh Dev loss: 0.8114 r:0.4735
ro_en Dev loss: 0.3568 r:0.8151
et_en Dev loss: 0.5120 r:0.6468
si_en Dev loss: 0.8499 r:0.5484
ne_en Dev loss: 0.5313 r:0.7205
ru_en Dev loss: 0.4210 r:0.7571
Current avg r:0.5999 Best avg r: 0.6266
07:39:19,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:39,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:11,934 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1390
en_de Dev loss: 1.2291 r:0.2317
en_zh Dev loss: 0.8042 r:0.4674
ro_en Dev loss: 0.3573 r:0.8155
et_en Dev loss: 0.5121 r:0.6460
si_en Dev loss: 0.8877 r:0.5405
ne_en Dev loss: 0.5470 r:0.7172
ru_en Dev loss: 0.4428 r:0.7444
Current avg r:0.5947 Best avg r: 0.6266
07:46:08,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:28,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:49:01,130 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1274
en_de Dev loss: 1.2920 r:0.2301
en_zh Dev loss: 0.8428 r:0.4674
ro_en Dev loss: 0.4015 r:0.8076
et_en Dev loss: 0.5087 r:0.6346
si_en Dev loss: 1.0018 r:0.5344
ne_en Dev loss: 0.7025 r:0.7118
ru_en Dev loss: 0.5305 r:0.7186
Current avg r:0.5864 Best avg r: 0.6266
07:52:59,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:54:19,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:52,246 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1232
en_de Dev loss: 1.1925 r:0.2459
en_zh Dev loss: 0.7765 r:0.4772
ro_en Dev loss: 0.3611 r:0.8125
et_en Dev loss: 0.5068 r:0.6386
si_en Dev loss: 0.9012 r:0.5407
ne_en Dev loss: 0.5659 r:0.7140
ru_en Dev loss: 0.4585 r:0.7361
Current avg r:0.5950 Best avg r: 0.6266
07:59:49,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:01:09,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:42,150 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1270
en_de Dev loss: 1.1860 r:0.2379
en_zh Dev loss: 0.7788 r:0.4725
ro_en Dev loss: 0.3556 r:0.8152
et_en Dev loss: 0.5083 r:0.6504
si_en Dev loss: 0.8765 r:0.5424
ne_en Dev loss: 0.5526 r:0.7159
ru_en Dev loss: 0.4324 r:0.7419
Current avg r:0.5966 Best avg r: 0.6266
08:06:39,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:07:59,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:09:31,952 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1215
en_de Dev loss: 1.2756 r:0.2274
en_zh Dev loss: 0.8251 r:0.4714
ro_en Dev loss: 0.3902 r:0.8149
et_en Dev loss: 0.5122 r:0.6512
si_en Dev loss: 0.9963 r:0.5361
ne_en Dev loss: 0.6307 r:0.7158
ru_en Dev loss: 0.4898 r:0.7275
Current avg r:0.5921 Best avg r: 0.6266
08:13:29,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:14:49,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:21,890 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1252
en_de Dev loss: 1.1876 r:0.2120
en_zh Dev loss: 0.7638 r:0.4671
ro_en Dev loss: 0.3605 r:0.8122
et_en Dev loss: 0.4932 r:0.6572
si_en Dev loss: 0.8289 r:0.5519
ne_en Dev loss: 0.5485 r:0.7147
ru_en Dev loss: 0.4764 r:0.7182
Current avg r:0.5905 Best avg r: 0.6266
08:20:19,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:39,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:11,887 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1268
en_de Dev loss: 1.2091 r:0.2356
en_zh Dev loss: 0.7724 r:0.4736
ro_en Dev loss: 0.3833 r:0.8121
et_en Dev loss: 0.4966 r:0.6507
si_en Dev loss: 0.8915 r:0.5491
ne_en Dev loss: 0.6034 r:0.7174
ru_en Dev loss: 0.4787 r:0.7346
Current avg r:0.5962 Best avg r: 0.6266
08:27:09,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:29,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:02,3 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1228
en_de Dev loss: 1.1857 r:0.2205
en_zh Dev loss: 0.7509 r:0.4737
ro_en Dev loss: 0.3537 r:0.8157
et_en Dev loss: 0.4687 r:0.6537
si_en Dev loss: 0.8625 r:0.5461
ne_en Dev loss: 0.5470 r:0.7116
ru_en Dev loss: 0.4157 r:0.7493
Current avg r:0.5958 Best avg r: 0.6266
08:33:59,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:19,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:52,47 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1201
en_de Dev loss: 1.2275 r:0.2323
en_zh Dev loss: 0.8085 r:0.4696
ro_en Dev loss: 0.3702 r:0.8116
et_en Dev loss: 0.5125 r:0.6424
si_en Dev loss: 0.8646 r:0.5444
ne_en Dev loss: 0.5536 r:0.7089
ru_en Dev loss: 0.4582 r:0.7365
Current avg r:0.5922 Best avg r: 0.6266
08:40:49,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:09,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:42,52 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1182
en_de Dev loss: 1.1967 r:0.2209
en_zh Dev loss: 0.7757 r:0.4706
ro_en Dev loss: 0.3435 r:0.8135
et_en Dev loss: 0.4756 r:0.6510
si_en Dev loss: 0.8461 r:0.5444
ne_en Dev loss: 0.5905 r:0.7123
ru_en Dev loss: 0.4598 r:0.7249
Current avg r:0.5911 Best avg r: 0.6266
08:47:39,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:59,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:50:32,61 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1186
en_de Dev loss: 1.2304 r:0.2196
en_zh Dev loss: 0.7873 r:0.4742
ro_en Dev loss: 0.3499 r:0.8149
et_en Dev loss: 0.5071 r:0.6604
si_en Dev loss: 0.8128 r:0.5537
ne_en Dev loss: 0.5051 r:0.7090
ru_en Dev loss: 0.4298 r:0.7440
Current avg r:0.5965 Best avg r: 0.6266
08:54:29,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:55:48,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:57:21,551 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1227
en_de Dev loss: 1.2111 r:0.2229
en_zh Dev loss: 0.7754 r:0.4720
ro_en Dev loss: 0.3610 r:0.8112
et_en Dev loss: 0.4897 r:0.6500
si_en Dev loss: 0.8761 r:0.5424
ne_en Dev loss: 0.6143 r:0.7189
ru_en Dev loss: 0.4339 r:0.7427
Current avg r:0.5943 Best avg r: 0.6266
09:01:19,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:38,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:04:11,647 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1233
en_de Dev loss: 1.2388 r:0.2266
en_zh Dev loss: 0.7971 r:0.4766
ro_en Dev loss: 0.3861 r:0.8106
et_en Dev loss: 0.5176 r:0.6545
si_en Dev loss: 0.8970 r:0.5445
ne_en Dev loss: 0.5451 r:0.7208
ru_en Dev loss: 0.4641 r:0.7349
Current avg r:0.5955 Best avg r: 0.6266
09:08:09,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:28,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:01,767 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1167
en_de Dev loss: 1.2185 r:0.2265
en_zh Dev loss: 0.7906 r:0.4756
ro_en Dev loss: 0.3513 r:0.8151
et_en Dev loss: 0.4930 r:0.6550
si_en Dev loss: 0.9075 r:0.5411
ne_en Dev loss: 0.5239 r:0.7184
ru_en Dev loss: 0.4504 r:0.7422
Current avg r:0.5963 Best avg r: 0.6266
09:14:59,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:16:19,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:17:51,870 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1191
en_de Dev loss: 1.2161 r:0.2223
en_zh Dev loss: 0.7910 r:0.4750
ro_en Dev loss: 0.3606 r:0.8139
et_en Dev loss: 0.5349 r:0.6595
si_en Dev loss: 0.8517 r:0.5468
ne_en Dev loss: 0.4862 r:0.7199
ru_en Dev loss: 0.4457 r:0.7359
Current avg r:0.5962 Best avg r: 0.6266
09:21:49,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:23:09,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:24:41,873 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1212
en_de Dev loss: 1.2024 r:0.2225
en_zh Dev loss: 0.7759 r:0.4795
ro_en Dev loss: 0.3456 r:0.8178
et_en Dev loss: 0.5082 r:0.6580
si_en Dev loss: 0.8271 r:0.5531
ne_en Dev loss: 0.5058 r:0.7209
ru_en Dev loss: 0.4261 r:0.7451
Current avg r:0.5996 Best avg r: 0.6266
09:28:39,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:29:59,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:31:31,918 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1161
en_de Dev loss: 1.2024 r:0.2166
en_zh Dev loss: 0.7569 r:0.4805
ro_en Dev loss: 0.3577 r:0.8124
et_en Dev loss: 0.4929 r:0.6543
si_en Dev loss: 0.8691 r:0.5410
ne_en Dev loss: 0.6079 r:0.7121
ru_en Dev loss: 0.4639 r:0.7301
Current avg r:0.5924 Best avg r: 0.6266
09:35:30,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:36:49,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:38:22,592 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1077
en_de Dev loss: 1.2428 r:0.2299
en_zh Dev loss: 0.7995 r:0.4740
ro_en Dev loss: 0.3737 r:0.8119
et_en Dev loss: 0.4847 r:0.6527
si_en Dev loss: 0.8994 r:0.5433
ne_en Dev loss: 0.5967 r:0.7081
ru_en Dev loss: 0.4741 r:0.7346
Current avg r:0.5935 Best avg r: 0.6266
09:42:19,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:39,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:45:11,772 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1137
en_de Dev loss: 1.2299 r:0.2384
en_zh Dev loss: 0.8126 r:0.4735
ro_en Dev loss: 0.3848 r:0.8097
et_en Dev loss: 0.5138 r:0.6464
si_en Dev loss: 0.9333 r:0.5446
ne_en Dev loss: 0.6721 r:0.7088
ru_en Dev loss: 0.4684 r:0.7351
Current avg r:0.5938 Best avg r: 0.6266
09:49:08,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:50:28,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:52:01,52 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1108
en_de Dev loss: 1.2364 r:0.2311
en_zh Dev loss: 0.7992 r:0.4766
ro_en Dev loss: 0.3696 r:0.8134
et_en Dev loss: 0.5103 r:0.6505
si_en Dev loss: 0.8754 r:0.5548
ne_en Dev loss: 0.5807 r:0.7091
ru_en Dev loss: 0.4686 r:0.7340
Current avg r:0.5956 Best avg r: 0.6266
09:55:58,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:17,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:50,327 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1071
en_de Dev loss: 1.2433 r:0.2281
en_zh Dev loss: 0.8032 r:0.4788
ro_en Dev loss: 0.3726 r:0.8123
et_en Dev loss: 0.5034 r:0.6487
si_en Dev loss: 0.8494 r:0.5539
ne_en Dev loss: 0.5300 r:0.7142
ru_en Dev loss: 0.4600 r:0.7377
Current avg r:0.5962 Best avg r: 0.6266
10:02:47,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:06,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:39,567 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1104
en_de Dev loss: 1.2194 r:0.2197
en_zh Dev loss: 0.7820 r:0.4816
ro_en Dev loss: 0.3455 r:0.8168
et_en Dev loss: 0.4928 r:0.6538
si_en Dev loss: 0.8516 r:0.5537
ne_en Dev loss: 0.5706 r:0.7161
ru_en Dev loss: 0.4230 r:0.7482
Current avg r:0.5986 Best avg r: 0.6266
10:09:36,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:56,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:28,792 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1120
en_de Dev loss: 1.2526 r:0.2175
en_zh Dev loss: 0.8261 r:0.4672
ro_en Dev loss: 0.3665 r:0.8125
et_en Dev loss: 0.5100 r:0.6505
si_en Dev loss: 0.8756 r:0.5463
ne_en Dev loss: 0.5561 r:0.7140
ru_en Dev loss: 0.4658 r:0.7362
Current avg r:0.5920 Best avg r: 0.6266
10:16:25,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:17:45,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:18,22 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1114
en_de Dev loss: 1.2382 r:0.2270
en_zh Dev loss: 0.7988 r:0.4780
ro_en Dev loss: 0.3826 r:0.8100
et_en Dev loss: 0.4974 r:0.6516
si_en Dev loss: 0.9139 r:0.5465
ne_en Dev loss: 0.6245 r:0.7188
ru_en Dev loss: 0.4781 r:0.7298
Current avg r:0.5945 Best avg r: 0.6266
10:23:14,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:34,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:07,224 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1130
en_de Dev loss: 1.2281 r:0.2343
en_zh Dev loss: 0.7859 r:0.4822
ro_en Dev loss: 0.3668 r:0.8142
et_en Dev loss: 0.4942 r:0.6518
si_en Dev loss: 0.8654 r:0.5502
ne_en Dev loss: 0.5960 r:0.7159
ru_en Dev loss: 0.4616 r:0.7354
Current avg r:0.5977 Best avg r: 0.6266
10:30:04,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:31:23,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:32:56,372 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1077
en_de Dev loss: 1.2504 r:0.2174
en_zh Dev loss: 0.7846 r:0.4867
ro_en Dev loss: 0.3688 r:0.8139
et_en Dev loss: 0.4938 r:0.6637
si_en Dev loss: 0.8586 r:0.5546
ne_en Dev loss: 0.5200 r:0.7169
ru_en Dev loss: 0.4317 r:0.7494
Current avg r:0.6004 Best avg r: 0.6266
10:36:53,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:38:12,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
