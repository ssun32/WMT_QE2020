14:42:33,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:46,21 root INFO 
id:en_zh cur r: 0.0842 best r: 0.0842
14:42:59,13 root INFO 
id:ro_en cur r: 0.4064 best r: 0.4064
14:43:12,31 root INFO 
id:et_en cur r: 0.4397 best r: 0.4397
14:43:38,116 root INFO 
id:ne_en cur r: 0.2734 best r: 0.2734
14:43:51,48 root INFO 
id:ru_en cur r: 0.4653 best r: 0.4653
14:43:51,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:22,99 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
14:45:22,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:45:22,111 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:45:22,116 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
14:45:22,120 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
14:45:22,126 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:45:22,132 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:45:35,170 root INFO Epoch 0 Global steps: 600 Train loss: 0.9453
en_de Dev loss: 0.9543 r:0.0644
en_zh Dev loss: 0.8679 r:0.2171
ro_en Dev loss: 0.7804 r:0.4495
et_en Dev loss: 0.7875 r:0.4250
si_en Dev loss: 0.7601 r:0.3523
ne_en Dev loss: 0.7388 r:0.3712
ru_en Dev loss: 0.8085 r:0.3872
Current avg r:0.3238 Best avg r: 0.3238
14:49:29,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:42,54 root INFO 
id:en_zh cur r: 0.1718 best r: 0.1718
14:49:55,63 root INFO 
id:ro_en cur r: 0.4942 best r: 0.4942
14:50:08,91 root INFO 
id:et_en cur r: 0.5392 best r: 0.5392
14:50:21,126 root INFO 
id:si_en cur r: 0.2401 best r: 0.2401
14:50:34,150 root INFO 
id:ne_en cur r: 0.3791 best r: 0.3791
14:50:47,96 root INFO 
id:ru_en cur r: 0.6845 best r: 0.6845
14:50:47,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:18,149 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
14:52:18,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:52:18,163 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:52:18,168 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
14:52:18,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
14:52:18,179 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:52:18,184 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:52:31,228 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8738
en_de Dev loss: 0.8944 r:0.0863
en_zh Dev loss: 0.7643 r:0.2764
ro_en Dev loss: 0.6859 r:0.5691
et_en Dev loss: 0.5887 r:0.5075
si_en Dev loss: 0.7820 r:0.4309
ne_en Dev loss: 0.6695 r:0.4808
ru_en Dev loss: 0.5399 r:0.6772
Current avg r:0.4326 Best avg r: 0.4326
14:56:25,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:38,286 root INFO 
id:en_zh cur r: 0.2257 best r: 0.2257
14:56:51,299 root INFO 
id:ro_en cur r: 0.5960 best r: 0.5960
14:57:04,327 root INFO 
id:et_en cur r: 0.5670 best r: 0.5670
14:57:17,360 root INFO 
id:si_en cur r: 0.3871 best r: 0.3871
14:57:30,391 root INFO 
id:ne_en cur r: 0.4683 best r: 0.4683
14:57:43,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:14,373 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
14:59:14,380 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:59:14,385 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:59:14,392 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
14:59:14,397 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
14:59:14,404 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:59:14,409 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:59:27,440 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7769
en_de Dev loss: 0.9502 r:0.0761
en_zh Dev loss: 0.8019 r:0.2690
ro_en Dev loss: 0.5990 r:0.5987
et_en Dev loss: 0.5064 r:0.5605
si_en Dev loss: 0.7545 r:0.4470
ne_en Dev loss: 0.6303 r:0.5225
ru_en Dev loss: 0.5351 r:0.6642
Current avg r:0.4483 Best avg r: 0.4483
15:03:20,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:33,343 root INFO 
id:en_zh cur r: 0.3303 best r: 0.3303
15:03:46,364 root INFO 
id:ro_en cur r: 0.6803 best r: 0.6803
15:03:59,394 root INFO 
id:et_en cur r: 0.5992 best r: 0.5992
15:04:12,443 root INFO 
id:si_en cur r: 0.4778 best r: 0.4778
15:04:25,480 root INFO 
id:ne_en cur r: 0.6318 best r: 0.6318
15:04:38,428 root INFO 
id:ru_en cur r: 0.7005 best r: 0.7005
15:04:38,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:09,462 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:06:09,470 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:06:09,477 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:06:09,483 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:06:09,487 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:06:09,493 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:06:09,498 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:06:22,522 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7204
en_de Dev loss: 0.9593 r:0.1105
en_zh Dev loss: 0.7293 r:0.3475
ro_en Dev loss: 0.4861 r:0.6772
et_en Dev loss: 0.4558 r:0.6113
si_en Dev loss: 0.6290 r:0.5065
ne_en Dev loss: 0.4900 r:0.6464
ru_en Dev loss: 0.4692 r:0.6804
Current avg r:0.5114 Best avg r: 0.5114
15:10:15,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:41,370 root INFO 
id:ro_en cur r: 0.6853 best r: 0.6853
15:10:54,399 root INFO 
id:et_en cur r: 0.6132 best r: 0.6132
15:11:33,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:04,451 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:13:04,458 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:13:04,462 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:13:04,467 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:13:04,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:13:04,478 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:13:04,483 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:13:17,493 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6739
en_de Dev loss: 1.0228 r:0.1038
en_zh Dev loss: 0.7852 r:0.3453
ro_en Dev loss: 0.4990 r:0.6876
et_en Dev loss: 0.4300 r:0.6272
si_en Dev loss: 0.7606 r:0.4949
ne_en Dev loss: 0.5251 r:0.6360
ru_en Dev loss: 0.5171 r:0.6918
Current avg r:0.5124 Best avg r: 0.5124
15:17:10,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:23,375 root INFO 
id:en_zh cur r: 0.3563 best r: 0.3563
15:17:36,395 root INFO 
id:ro_en cur r: 0.7289 best r: 0.7289
15:17:49,422 root INFO 
id:et_en cur r: 0.6459 best r: 0.6459
15:18:02,468 root INFO 
id:si_en cur r: 0.5222 best r: 0.5222
15:18:15,507 root INFO 
id:ne_en cur r: 0.6832 best r: 0.6832
15:18:28,463 root INFO 
id:ru_en cur r: 0.7125 best r: 0.7125
15:18:28,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:59,486 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:19:59,494 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:19:59,502 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:19:59,507 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:19:59,511 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:19:59,518 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:19:59,523 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:20:12,567 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6252
en_de Dev loss: 0.9914 r:0.1344
en_zh Dev loss: 0.7450 r:0.3743
ro_en Dev loss: 0.4123 r:0.7297
et_en Dev loss: 0.3992 r:0.6602
si_en Dev loss: 0.6077 r:0.5405
ne_en Dev loss: 0.4583 r:0.6869
ru_en Dev loss: 0.4486 r:0.7156
Current avg r:0.5488 Best avg r: 0.5488
15:24:05,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:18,572 root INFO 
id:en_zh cur r: 0.3565 best r: 0.3565
15:24:31,595 root INFO 
id:ro_en cur r: 0.7405 best r: 0.7405
15:24:44,639 root INFO 
id:et_en cur r: 0.6593 best r: 0.6593
15:24:57,699 root INFO 
id:si_en cur r: 0.5272 best r: 0.5272
15:25:10,741 root INFO 
id:ne_en cur r: 0.6971 best r: 0.6971
15:25:23,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:54,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:26:54,753 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:26:54,758 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:26:54,762 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:26:54,766 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:26:54,771 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:26:54,776 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:27:07,803 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6033
en_de Dev loss: 1.0716 r:0.1365
en_zh Dev loss: 0.8162 r:0.3672
ro_en Dev loss: 0.4710 r:0.7368
et_en Dev loss: 0.3943 r:0.6700
si_en Dev loss: 0.7520 r:0.5301
ne_en Dev loss: 0.4656 r:0.6952
ru_en Dev loss: 0.5163 r:0.7209
Current avg r:0.5510 Best avg r: 0.5510
15:31:00,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:13,711 root INFO 
id:en_zh cur r: 0.3767 best r: 0.3767
15:31:28,90 root INFO 
id:ro_en cur r: 0.7582 best r: 0.7582
15:31:41,117 root INFO 
id:et_en cur r: 0.6788 best r: 0.6788
15:31:54,150 root INFO 
id:si_en cur r: 0.5462 best r: 0.5462
15:32:07,196 root INFO 
id:ne_en cur r: 0.7136 best r: 0.7136
15:32:20,148 root INFO 
id:ru_en cur r: 0.7186 best r: 0.7186
15:32:20,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:51,246 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:33:51,252 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:33:51,256 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:33:51,261 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:33:51,266 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:33:51,272 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:33:51,276 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:34:04,317 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5966
en_de Dev loss: 1.0545 r:0.1601
en_zh Dev loss: 0.8139 r:0.3913
ro_en Dev loss: 0.4446 r:0.7551
et_en Dev loss: 0.3730 r:0.6884
si_en Dev loss: 0.8403 r:0.5408
ne_en Dev loss: 0.6559 r:0.6936
ru_en Dev loss: 0.4759 r:0.7295
Current avg r:0.5655 Best avg r: 0.5655
15:37:57,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:23,19 root INFO 
id:ro_en cur r: 0.7643 best r: 0.7643
15:38:49,97 root INFO 
id:si_en cur r: 0.5579 best r: 0.5579
15:39:15,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:46,197 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:40:46,204 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:40:46,209 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:40:46,214 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:40:46,218 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:40:46,223 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:40:46,228 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:40:59,266 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5851
en_de Dev loss: 1.0524 r:0.1622
en_zh Dev loss: 0.8038 r:0.3966
ro_en Dev loss: 0.4195 r:0.7662
et_en Dev loss: 0.3762 r:0.6846
si_en Dev loss: 0.6445 r:0.5641
ne_en Dev loss: 0.5061 r:0.7109
ru_en Dev loss: 0.4882 r:0.7200
Current avg r:0.5721 Best avg r: 0.5721
15:44:52,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:45:05,65 root INFO 
id:en_zh cur r: 0.3849 best r: 0.3849
15:45:18,66 root INFO 
id:ro_en cur r: 0.7649 best r: 0.7649
15:45:44,124 root INFO 
id:si_en cur r: 0.5652 best r: 0.5652
15:45:57,172 root INFO 
id:ne_en cur r: 0.7304 best r: 0.7304
15:46:10,110 root INFO 
id:ru_en cur r: 0.7353 best r: 0.7353
15:46:10,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:41,221 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:47:41,227 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:47:41,234 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:47:41,238 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:47:41,243 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:47:41,250 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:47:41,254 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:47:54,290 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5658
en_de Dev loss: 1.0547 r:0.1749
en_zh Dev loss: 0.7548 r:0.4008
ro_en Dev loss: 0.4286 r:0.7649
et_en Dev loss: 0.3755 r:0.6876
si_en Dev loss: 0.6975 r:0.5654
ne_en Dev loss: 0.4173 r:0.7286
ru_en Dev loss: 0.4386 r:0.7462
Current avg r:0.5812 Best avg r: 0.5812
15:51:48,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:01,417 root INFO 
id:en_zh cur r: 0.4224 best r: 0.4224
15:52:14,418 root INFO 
id:ro_en cur r: 0.7836 best r: 0.7836
15:52:27,443 root INFO 
id:et_en cur r: 0.6820 best r: 0.6820
15:52:40,486 root INFO 
id:si_en cur r: 0.5676 best r: 0.5676
15:52:53,510 root INFO 
id:ne_en cur r: 0.7458 best r: 0.7458
15:53:06,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:37,497 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:54:37,504 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:54:37,508 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:54:37,513 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:54:37,517 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:54:37,523 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:54:37,527 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:54:50,558 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5569
en_de Dev loss: 1.0346 r:0.1880
en_zh Dev loss: 0.7098 r:0.4287
ro_en Dev loss: 0.3744 r:0.7810
et_en Dev loss: 0.3663 r:0.6956
si_en Dev loss: 0.7170 r:0.5722
ne_en Dev loss: 0.3824 r:0.7434
ru_en Dev loss: 0.4718 r:0.7365
Current avg r:0.5922 Best avg r: 0.5922
15:58:43,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:56,595 root INFO 
id:en_zh cur r: 0.4290 best r: 0.4290
15:59:22,623 root INFO 
id:et_en cur r: 0.6877 best r: 0.6877
15:59:35,668 root INFO 
id:si_en cur r: 0.5924 best r: 0.5924
16:00:01,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:32,750 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
16:01:32,757 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:01:32,761 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:01:32,766 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
16:01:32,770 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
16:01:32,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:01:32,780 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:01:45,806 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5422
en_de Dev loss: 1.0176 r:0.1962
en_zh Dev loss: 0.7290 r:0.4316
ro_en Dev loss: 0.3797 r:0.7786
et_en Dev loss: 0.3692 r:0.7008
si_en Dev loss: 0.6508 r:0.5845
ne_en Dev loss: 0.4447 r:0.7407
ru_en Dev loss: 0.4468 r:0.7448
Current avg r:0.5968 Best avg r: 0.5968
16:05:38,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:51,727 root INFO 
id:en_zh cur r: 0.4371 best r: 0.4371
16:06:04,740 root INFO 
id:ro_en cur r: 0.7906 best r: 0.7906
16:06:17,766 root INFO 
id:et_en cur r: 0.7066 best r: 0.7066
16:06:30,806 root INFO 
id:si_en cur r: 0.6000 best r: 0.6000
16:06:43,844 root INFO 
id:ne_en cur r: 0.7551 best r: 0.7551
16:06:56,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:27,831 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
16:08:27,839 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:08:27,844 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:08:27,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
16:08:27,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
16:08:27,861 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:08:27,866 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:08:40,905 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5323
en_de Dev loss: 1.0135 r:0.1966
en_zh Dev loss: 0.6950 r:0.4432
ro_en Dev loss: 0.3464 r:0.7903
et_en Dev loss: 0.3496 r:0.7115
si_en Dev loss: 0.6872 r:0.5944
ne_en Dev loss: 0.3738 r:0.7543
ru_en Dev loss: 0.4325 r:0.7488
Current avg r:0.6056 Best avg r: 0.6056
16:12:33,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:59,711 root INFO 
id:ro_en cur r: 0.7922 best r: 0.7922
16:13:38,816 root INFO 
id:ne_en cur r: 0.7567 best r: 0.7567
16:13:51,756 root INFO 
id:ru_en cur r: 0.7382 best r: 0.7382
16:13:51,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:22,785 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5198
en_de Dev loss: 1.0960 r:0.2034
en_zh Dev loss: 0.8127 r:0.4218
ro_en Dev loss: 0.3797 r:0.7983
et_en Dev loss: 0.3746 r:0.7077
si_en Dev loss: 0.7167 r:0.5914
ne_en Dev loss: 0.3995 r:0.7536
ru_en Dev loss: 0.4541 r:0.7488
Current avg r:0.6036 Best avg r: 0.6056
16:19:15,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:41,612 root INFO 
id:ro_en cur r: 0.7965 best r: 0.7965
16:20:33,662 root INFO 
id:ru_en cur r: 0.7430 best r: 0.7430
16:20:33,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:04,660 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5225
en_de Dev loss: 1.0929 r:0.2098
en_zh Dev loss: 0.7866 r:0.4348
ro_en Dev loss: 0.4167 r:0.7946
et_en Dev loss: 0.3801 r:0.7053
si_en Dev loss: 0.8639 r:0.5859
ne_en Dev loss: 0.4283 r:0.7533
ru_en Dev loss: 0.4995 r:0.7484
Current avg r:0.6046 Best avg r: 0.6056
16:25:58,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:11,760 root INFO 
id:en_zh cur r: 0.4456 best r: 0.4456
16:26:24,773 root INFO 
id:ro_en cur r: 0.8035 best r: 0.8035
16:27:03,902 root INFO 
id:ne_en cur r: 0.7621 best r: 0.7621
16:27:16,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:47,918 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
16:28:47,925 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:28:47,930 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:28:47,934 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
16:28:47,939 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
16:28:47,946 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:28:47,953 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:29:00,976 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5002
en_de Dev loss: 1.0379 r:0.2260
en_zh Dev loss: 0.7202 r:0.4492
ro_en Dev loss: 0.3304 r:0.8080
et_en Dev loss: 0.3497 r:0.7145
si_en Dev loss: 0.6299 r:0.6029
ne_en Dev loss: 0.4645 r:0.7549
ru_en Dev loss: 0.4491 r:0.7453
Current avg r:0.6144 Best avg r: 0.6144
16:32:54,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:12,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:43,301 root INFO Epoch 1 Global steps: 10200 Train loss: 0.4938
en_de Dev loss: 1.1130 r:0.2209
en_zh Dev loss: 0.8114 r:0.4250
ro_en Dev loss: 0.4223 r:0.7980
et_en Dev loss: 0.3973 r:0.7006
si_en Dev loss: 0.8527 r:0.5778
ne_en Dev loss: 0.5494 r:0.7330
ru_en Dev loss: 0.5598 r:0.7244
Current avg r:0.5971 Best avg r: 0.6144
16:39:36,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:54,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:25,174 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5135
en_de Dev loss: 1.0621 r:0.2113
en_zh Dev loss: 0.7273 r:0.4444
ro_en Dev loss: 0.3784 r:0.8051
et_en Dev loss: 0.3873 r:0.7031
si_en Dev loss: 0.7262 r:0.5944
ne_en Dev loss: 0.4245 r:0.7560
ru_en Dev loss: 0.4588 r:0.7399
Current avg r:0.6077 Best avg r: 0.6144
16:46:18,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:44,1 root INFO 
id:ro_en cur r: 0.8147 best r: 0.8147
16:47:10,38 root INFO 
id:si_en cur r: 0.6014 best r: 0.6014
16:47:23,60 root INFO 
id:ne_en cur r: 0.7631 best r: 0.7631
16:47:35,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:06,969 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4825
en_de Dev loss: 1.0578 r:0.2258
en_zh Dev loss: 0.7675 r:0.4351
ro_en Dev loss: 0.3265 r:0.8129
et_en Dev loss: 0.3695 r:0.7071
si_en Dev loss: 0.6096 r:0.6098
ne_en Dev loss: 0.3734 r:0.7608
ru_en Dev loss: 0.4560 r:0.7400
Current avg r:0.6131 Best avg r: 0.6144
16:52:59,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:12,856 root INFO 
id:en_zh cur r: 0.4592 best r: 0.4592
16:54:17,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:48,888 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
16:55:48,894 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:55:48,899 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:55:48,904 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
16:55:48,908 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
16:55:48,914 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:55:48,918 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:56:01,943 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4973
en_de Dev loss: 1.1103 r:0.2341
en_zh Dev loss: 0.7405 r:0.4645
ro_en Dev loss: 0.3803 r:0.8139
et_en Dev loss: 0.3871 r:0.7067
si_en Dev loss: 0.8687 r:0.5951
ne_en Dev loss: 0.4109 r:0.7589
ru_en Dev loss: 0.4952 r:0.7392
Current avg r:0.6161 Best avg r: 0.6161
16:59:54,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:59,905 root INFO 
id:ne_en cur r: 0.7657 best r: 0.7657
17:01:12,843 root INFO 
id:ru_en cur r: 0.7453 best r: 0.7453
17:01:12,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:43,841 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4749
en_de Dev loss: 1.1353 r:0.2334
en_zh Dev loss: 0.8059 r:0.4510
ro_en Dev loss: 0.3845 r:0.8072
et_en Dev loss: 0.3843 r:0.7036
si_en Dev loss: 0.8367 r:0.5981
ne_en Dev loss: 0.4388 r:0.7625
ru_en Dev loss: 0.4341 r:0.7530
Current avg r:0.6155 Best avg r: 0.6161
17:06:36,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:15,720 root INFO 
id:et_en cur r: 0.7080 best r: 0.7080
17:07:28,761 root INFO 
id:si_en cur r: 0.6072 best r: 0.6072
17:07:41,802 root INFO 
id:ne_en cur r: 0.7708 best r: 0.7708
17:07:54,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:25,731 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
17:09:25,738 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:09:25,744 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:09:25,749 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
17:09:25,754 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
17:09:25,759 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:09:25,765 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:09:38,797 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4890
en_de Dev loss: 1.1001 r:0.2383
en_zh Dev loss: 0.7916 r:0.4498
ro_en Dev loss: 0.3776 r:0.8135
et_en Dev loss: 0.3641 r:0.7121
si_en Dev loss: 0.7073 r:0.6095
ne_en Dev loss: 0.4549 r:0.7670
ru_en Dev loss: 0.4676 r:0.7483
Current avg r:0.6198 Best avg r: 0.6198
17:13:32,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:50,973 root INFO 
id:ru_en cur r: 0.7506 best r: 0.7506
17:14:50,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:23,384 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4742
en_de Dev loss: 1.0694 r:0.2097
en_zh Dev loss: 0.7318 r:0.4593
ro_en Dev loss: 0.3378 r:0.8146
et_en Dev loss: 0.3679 r:0.7093
si_en Dev loss: 0.7191 r:0.6071
ne_en Dev loss: 0.4272 r:0.7679
ru_en Dev loss: 0.4052 r:0.7570
Current avg r:0.6178 Best avg r: 0.6198
17:20:16,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:29,111 root INFO 
id:en_zh cur r: 0.4599 best r: 0.4599
17:20:42,133 root INFO 
id:ro_en cur r: 0.8189 best r: 0.8189
17:21:08,202 root INFO 
id:si_en cur r: 0.6168 best r: 0.6168
17:21:34,183 root INFO 
id:ru_en cur r: 0.7517 best r: 0.7517
17:21:34,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:05,275 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
17:23:05,283 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:23:05,288 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:23:05,295 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
17:23:05,300 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
17:23:05,306 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:23:05,311 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:23:18,345 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4738
en_de Dev loss: 1.0553 r:0.2127
en_zh Dev loss: 0.7217 r:0.4589
ro_en Dev loss: 0.3186 r:0.8163
et_en Dev loss: 0.3778 r:0.7094
si_en Dev loss: 0.6260 r:0.6179
ne_en Dev loss: 0.3459 r:0.7684
ru_en Dev loss: 0.3897 r:0.7553
Current avg r:0.6198 Best avg r: 0.6198
17:27:10,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:23,916 root INFO 
id:en_zh cur r: 0.4729 best r: 0.4729
17:28:28,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:00,72 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4734
en_de Dev loss: 1.0314 r:0.2249
en_zh Dev loss: 0.6776 r:0.4722
ro_en Dev loss: 0.3382 r:0.8133
et_en Dev loss: 0.3711 r:0.7075
si_en Dev loss: 0.6825 r:0.6091
ne_en Dev loss: 0.4005 r:0.7674
ru_en Dev loss: 0.4644 r:0.7316
Current avg r:0.6180 Best avg r: 0.6198
17:33:52,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:44,902 root INFO 
id:si_en cur r: 0.6187 best r: 0.6187
17:34:57,985 root INFO 
id:ne_en cur r: 0.7737 best r: 0.7737
17:35:10,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:41,970 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
17:36:41,976 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:36:41,981 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:36:41,985 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
17:36:41,990 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
17:36:41,996 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:36:42,1 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:36:55,30 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4866
en_de Dev loss: 1.0620 r:0.2233
en_zh Dev loss: 0.7110 r:0.4710
ro_en Dev loss: 0.3300 r:0.8190
et_en Dev loss: 0.3634 r:0.7059
si_en Dev loss: 0.6649 r:0.6189
ne_en Dev loss: 0.4065 r:0.7725
ru_en Dev loss: 0.4598 r:0.7358
Current avg r:0.6209 Best avg r: 0.6209
17:40:47,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:05,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:36,886 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4501
en_de Dev loss: 1.0479 r:0.2369
en_zh Dev loss: 0.7154 r:0.4695
ro_en Dev loss: 0.3411 r:0.8145
et_en Dev loss: 0.3733 r:0.7040
si_en Dev loss: 0.7471 r:0.6096
ne_en Dev loss: 0.3712 r:0.7707
ru_en Dev loss: 0.4766 r:0.7287
Current avg r:0.6191 Best avg r: 0.6209
17:47:29,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:42,864 root INFO 
id:en_zh cur r: 0.4768 best r: 0.4768
17:48:47,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:18,814 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4529
en_de Dev loss: 1.1858 r:0.2259
en_zh Dev loss: 0.8207 r:0.4845
ro_en Dev loss: 0.4895 r:0.8063
et_en Dev loss: 0.4580 r:0.6948
si_en Dev loss: 0.9111 r:0.6139
ne_en Dev loss: 0.6422 r:0.7658
ru_en Dev loss: 0.6395 r:0.6947
Current avg r:0.6123 Best avg r: 0.6209
17:54:11,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:24,683 root INFO 
id:en_zh cur r: 0.4797 best r: 0.4797
17:54:37,694 root INFO 
id:ro_en cur r: 0.8199 best r: 0.8199
17:55:03,739 root INFO 
id:si_en cur r: 0.6212 best r: 0.6212
17:55:16,762 root INFO 
id:ne_en cur r: 0.7753 best r: 0.7753
17:55:29,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:00,666 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4577
en_de Dev loss: 1.1233 r:0.2138
en_zh Dev loss: 0.7454 r:0.4834
ro_en Dev loss: 0.3898 r:0.8158
et_en Dev loss: 0.3893 r:0.7050
si_en Dev loss: 0.7104 r:0.6225
ne_en Dev loss: 0.3873 r:0.7742
ru_en Dev loss: 0.5047 r:0.7264
Current avg r:0.6202 Best avg r: 0.6209
18:00:53,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:06,646 root INFO 
id:en_zh cur r: 0.4826 best r: 0.4826
18:01:19,657 root INFO 
id:ro_en cur r: 0.8257 best r: 0.8257
18:01:32,687 root INFO 
id:et_en cur r: 0.7110 best r: 0.7110
18:01:45,752 root INFO 
id:si_en cur r: 0.6323 best r: 0.6323
18:01:58,793 root INFO 
id:ne_en cur r: 0.7754 best r: 0.7754
18:02:11,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:42,741 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
18:03:42,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:03:42,752 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:03:42,758 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
18:03:42,762 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
18:03:42,770 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:03:42,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:03:55,802 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4578
en_de Dev loss: 1.0420 r:0.2257
en_zh Dev loss: 0.6885 r:0.4810
ro_en Dev loss: 0.3229 r:0.8250
et_en Dev loss: 0.3593 r:0.7134
si_en Dev loss: 0.6317 r:0.6311
ne_en Dev loss: 0.4207 r:0.7752
ru_en Dev loss: 0.4453 r:0.7431
Current avg r:0.6278 Best avg r: 0.6278
18:07:50,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:03,62 root INFO 
id:en_zh cur r: 0.4843 best r: 0.4843
18:09:08,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:39,167 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4191
en_de Dev loss: 1.0813 r:0.2322
en_zh Dev loss: 0.7215 r:0.4834
ro_en Dev loss: 0.3382 r:0.8191
et_en Dev loss: 0.3926 r:0.7022
si_en Dev loss: 0.7705 r:0.6167
ne_en Dev loss: 0.4052 r:0.7702
ru_en Dev loss: 0.4268 r:0.7457
Current avg r:0.6242 Best avg r: 0.6278
18:14:33,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:15:51,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:22,235 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4193
en_de Dev loss: 1.0828 r:0.2308
en_zh Dev loss: 0.7095 r:0.4760
ro_en Dev loss: 0.3445 r:0.8146
et_en Dev loss: 0.3945 r:0.7004
si_en Dev loss: 0.7287 r:0.6082
ne_en Dev loss: 0.4108 r:0.7694
ru_en Dev loss: 0.4783 r:0.7198
Current avg r:0.6170 Best avg r: 0.6278
18:21:14,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:19,790 root INFO 
id:ne_en cur r: 0.7770 best r: 0.7770
18:22:32,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:03,644 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
18:24:03,649 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:24:03,653 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:24:03,659 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
18:24:03,663 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
18:24:03,668 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:24:03,672 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:24:16,690 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4148
en_de Dev loss: 1.0260 r:0.2464
en_zh Dev loss: 0.6776 r:0.4720
ro_en Dev loss: 0.3048 r:0.8245
et_en Dev loss: 0.3657 r:0.7151
si_en Dev loss: 0.5787 r:0.6263
ne_en Dev loss: 0.3538 r:0.7748
ru_en Dev loss: 0.4012 r:0.7500
Current avg r:0.6299 Best avg r: 0.6299
18:28:09,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:27,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:58,270 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4266
en_de Dev loss: 1.1290 r:0.2499
en_zh Dev loss: 0.7956 r:0.4603
ro_en Dev loss: 0.3557 r:0.8186
et_en Dev loss: 0.4030 r:0.6970
si_en Dev loss: 0.7734 r:0.6153
ne_en Dev loss: 0.4492 r:0.7677
ru_en Dev loss: 0.5296 r:0.7142
Current avg r:0.6176 Best avg r: 0.6299
18:34:51,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:08,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:39,877 root INFO Epoch 2 Global steps: 21000 Train loss: 0.3995
en_de Dev loss: 1.0413 r:0.2525
en_zh Dev loss: 0.7066 r:0.4758
ro_en Dev loss: 0.3256 r:0.8192
et_en Dev loss: 0.3839 r:0.7003
si_en Dev loss: 0.7073 r:0.6172
ne_en Dev loss: 0.4113 r:0.7688
ru_en Dev loss: 0.4010 r:0.7515
Current avg r:0.6265 Best avg r: 0.6299
18:41:34,35 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:51,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:22,863 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4078
en_de Dev loss: 1.0516 r:0.2451
en_zh Dev loss: 0.7220 r:0.4785
ro_en Dev loss: 0.3414 r:0.8146
et_en Dev loss: 0.3816 r:0.7042
si_en Dev loss: 0.7060 r:0.6171
ne_en Dev loss: 0.3573 r:0.7721
ru_en Dev loss: 0.4341 r:0.7399
Current avg r:0.6245 Best avg r: 0.6299
18:48:17,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:30,122 root INFO 
id:en_zh cur r: 0.4924 best r: 0.4924
18:48:56,119 root INFO 
id:et_en cur r: 0.7151 best r: 0.7151
18:49:35,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:05,991 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4117
en_de Dev loss: 1.0305 r:0.2450
en_zh Dev loss: 0.6903 r:0.4855
ro_en Dev loss: 0.3257 r:0.8180
et_en Dev loss: 0.3843 r:0.7128
si_en Dev loss: 0.6900 r:0.6192
ne_en Dev loss: 0.3785 r:0.7631
ru_en Dev loss: 0.4067 r:0.7486
Current avg r:0.6275 Best avg r: 0.6299
18:54:58,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:11,891 root INFO 
id:en_zh cur r: 0.4937 best r: 0.4937
18:56:16,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:47,753 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4047
en_de Dev loss: 1.0018 r:0.2413
en_zh Dev loss: 0.6879 r:0.4868
ro_en Dev loss: 0.3006 r:0.8227
et_en Dev loss: 0.3650 r:0.7101
si_en Dev loss: 0.7069 r:0.6157
ne_en Dev loss: 0.3975 r:0.7536
ru_en Dev loss: 0.4216 r:0.7396
Current avg r:0.6243 Best avg r: 0.6299
19:01:40,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:58,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:29,396 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4131
en_de Dev loss: 1.0307 r:0.2477
en_zh Dev loss: 0.7198 r:0.4801
ro_en Dev loss: 0.3205 r:0.8232
et_en Dev loss: 0.3723 r:0.7088
si_en Dev loss: 0.6893 r:0.6190
ne_en Dev loss: 0.4006 r:0.7599
ru_en Dev loss: 0.4190 r:0.7441
Current avg r:0.6261 Best avg r: 0.6299
19:08:24,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:42,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:13,183 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4036
en_de Dev loss: 1.1182 r:0.2464
en_zh Dev loss: 0.7914 r:0.4773
ro_en Dev loss: 0.3809 r:0.8184
et_en Dev loss: 0.4098 r:0.6954
si_en Dev loss: 0.8392 r:0.6004
ne_en Dev loss: 0.4501 r:0.7613
ru_en Dev loss: 0.5183 r:0.7124
Current avg r:0.6159 Best avg r: 0.6299
19:15:06,6 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:24,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:55,728 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4107
en_de Dev loss: 1.0567 r:0.2500
en_zh Dev loss: 0.7216 r:0.4749
ro_en Dev loss: 0.3596 r:0.8120
et_en Dev loss: 0.3997 r:0.6902
si_en Dev loss: 0.7088 r:0.6009
ne_en Dev loss: 0.3896 r:0.7719
ru_en Dev loss: 0.5175 r:0.6984
Current avg r:0.6140 Best avg r: 0.6299
19:21:50,5 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:07,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:40,286 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4141
en_de Dev loss: 1.0484 r:0.2480
en_zh Dev loss: 0.7073 r:0.4756
ro_en Dev loss: 0.3471 r:0.8180
et_en Dev loss: 0.3897 r:0.6983
si_en Dev loss: 0.6247 r:0.6197
ne_en Dev loss: 0.3787 r:0.7723
ru_en Dev loss: 0.4801 r:0.7194
Current avg r:0.6216 Best avg r: 0.6299
19:28:34,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:13,460 root INFO 
id:et_en cur r: 0.7160 best r: 0.7160
19:29:39,629 root INFO 
id:ne_en cur r: 0.7789 best r: 0.7789
19:29:52,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:24,148 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4180
en_de Dev loss: 1.0353 r:0.2324
en_zh Dev loss: 0.6835 r:0.4872
ro_en Dev loss: 0.3143 r:0.8241
et_en Dev loss: 0.3709 r:0.7137
si_en Dev loss: 0.6014 r:0.6301
ne_en Dev loss: 0.3665 r:0.7757
ru_en Dev loss: 0.4172 r:0.7448
Current avg r:0.6297 Best avg r: 0.6299
19:35:18,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:36,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:07,52 root INFO Epoch 2 Global steps: 26400 Train loss: 0.3868
en_de Dev loss: 1.0604 r:0.2185
en_zh Dev loss: 0.6923 r:0.4841
ro_en Dev loss: 0.3417 r:0.8224
et_en Dev loss: 0.3831 r:0.7047
si_en Dev loss: 0.6727 r:0.6219
ne_en Dev loss: 0.3657 r:0.7713
ru_en Dev loss: 0.4424 r:0.7273
Current avg r:0.6215 Best avg r: 0.6299
19:42:01,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:19,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:49,934 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4096
en_de Dev loss: 1.1048 r:0.2277
en_zh Dev loss: 0.8075 r:0.4815
ro_en Dev loss: 0.3946 r:0.8159
et_en Dev loss: 0.3941 r:0.6930
si_en Dev loss: 0.7737 r:0.6116
ne_en Dev loss: 0.4822 r:0.7675
ru_en Dev loss: 0.5371 r:0.7057
Current avg r:0.6147 Best avg r: 0.6299
19:48:43,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:01,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:32,208 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3548
en_de Dev loss: 1.0338 r:0.2272
en_zh Dev loss: 0.6981 r:0.4830
ro_en Dev loss: 0.3270 r:0.8176
et_en Dev loss: 0.4438 r:0.6935
si_en Dev loss: 0.6428 r:0.6114
ne_en Dev loss: 0.3614 r:0.7657
ru_en Dev loss: 0.3897 r:0.7460
Current avg r:0.6206 Best avg r: 0.6299
19:55:24,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:42,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:13,2 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3514
en_de Dev loss: 1.0885 r:0.2384
en_zh Dev loss: 0.7652 r:0.4701
ro_en Dev loss: 0.3487 r:0.8178
et_en Dev loss: 0.4311 r:0.6880
si_en Dev loss: 0.8581 r:0.5934
ne_en Dev loss: 0.4992 r:0.7682
ru_en Dev loss: 0.4848 r:0.7246
Current avg r:0.6144 Best avg r: 0.6299
20:02:06,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:25,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:56,352 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3716
en_de Dev loss: 1.0304 r:0.2481
en_zh Dev loss: 0.7104 r:0.4745
ro_en Dev loss: 0.3099 r:0.8206
et_en Dev loss: 0.3989 r:0.6878
si_en Dev loss: 0.6439 r:0.6085
ne_en Dev loss: 0.3794 r:0.7608
ru_en Dev loss: 0.4582 r:0.7257
Current avg r:0.6180 Best avg r: 0.6299
20:08:48,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:10:06,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:36,875 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3501
en_de Dev loss: 1.1206 r:0.2443
en_zh Dev loss: 0.7615 r:0.4774
ro_en Dev loss: 0.3887 r:0.8131
et_en Dev loss: 0.4444 r:0.6867
si_en Dev loss: 0.7937 r:0.6018
ne_en Dev loss: 0.4307 r:0.7653
ru_en Dev loss: 0.5117 r:0.7176
Current avg r:0.6152 Best avg r: 0.6299
20:15:30,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:48,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:19,548 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3435
en_de Dev loss: 1.0752 r:0.2358
en_zh Dev loss: 0.7252 r:0.4731
ro_en Dev loss: 0.3326 r:0.8240
et_en Dev loss: 0.4146 r:0.6946
si_en Dev loss: 0.6541 r:0.6138
ne_en Dev loss: 0.3487 r:0.7632
ru_en Dev loss: 0.4710 r:0.7194
Current avg r:0.6177 Best avg r: 0.6299
20:22:11,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:29,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:59,938 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3600
en_de Dev loss: 1.0759 r:0.2383
en_zh Dev loss: 0.7356 r:0.4703
ro_en Dev loss: 0.3370 r:0.8217
et_en Dev loss: 0.4154 r:0.6896
si_en Dev loss: 0.7385 r:0.6005
ne_en Dev loss: 0.3885 r:0.7691
ru_en Dev loss: 0.4735 r:0.7156
Current avg r:0.6150 Best avg r: 0.6299
20:28:52,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:09,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:40,369 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3613
en_de Dev loss: 1.0761 r:0.2452
en_zh Dev loss: 0.7375 r:0.4668
ro_en Dev loss: 0.3397 r:0.8212
et_en Dev loss: 0.4155 r:0.6914
si_en Dev loss: 0.6573 r:0.6064
ne_en Dev loss: 0.3704 r:0.7556
ru_en Dev loss: 0.4672 r:0.7197
Current avg r:0.6152 Best avg r: 0.6299
20:35:32,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:50,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:20,642 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3595
en_de Dev loss: 1.1155 r:0.2504
en_zh Dev loss: 0.7839 r:0.4727
ro_en Dev loss: 0.3572 r:0.8197
et_en Dev loss: 0.4342 r:0.6867
si_en Dev loss: 0.7345 r:0.6093
ne_en Dev loss: 0.4117 r:0.7511
ru_en Dev loss: 0.5198 r:0.7115
Current avg r:0.6145 Best avg r: 0.6299
20:42:12,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:31,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:02,508 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3394
en_de Dev loss: 1.0966 r:0.2620
en_zh Dev loss: 0.8165 r:0.4597
ro_en Dev loss: 0.3350 r:0.8251
et_en Dev loss: 0.4010 r:0.6870
si_en Dev loss: 0.7578 r:0.6010
ne_en Dev loss: 0.5499 r:0.7589
ru_en Dev loss: 0.4723 r:0.7201
Current avg r:0.6163 Best avg r: 0.6299
20:48:54,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:12,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:45,644 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3620
en_de Dev loss: 1.1038 r:0.2371
en_zh Dev loss: 0.7610 r:0.4730
ro_en Dev loss: 0.3574 r:0.8177
et_en Dev loss: 0.4567 r:0.6839
si_en Dev loss: 0.7045 r:0.5977
ne_en Dev loss: 0.4202 r:0.7558
ru_en Dev loss: 0.4779 r:0.7232
Current avg r:0.6126 Best avg r: 0.6299
20:55:39,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:05,401 root INFO 
id:ro_en cur r: 0.8267 best r: 0.8267
20:56:57,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:27,848 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3513
en_de Dev loss: 1.0874 r:0.2482
en_zh Dev loss: 0.7322 r:0.4841
ro_en Dev loss: 0.3668 r:0.8252
et_en Dev loss: 0.4175 r:0.6844
si_en Dev loss: 0.7034 r:0.6037
ne_en Dev loss: 0.4366 r:0.7546
ru_en Dev loss: 0.4809 r:0.7147
Current avg r:0.6164 Best avg r: 0.6299
21:02:19,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:37,414 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:09,425 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3424
en_de Dev loss: 1.1116 r:0.2450
en_zh Dev loss: 0.7838 r:0.4663
ro_en Dev loss: 0.3671 r:0.8215
et_en Dev loss: 0.4292 r:0.6790
si_en Dev loss: 0.7740 r:0.5926
ne_en Dev loss: 0.4593 r:0.7537
ru_en Dev loss: 0.5286 r:0.6999
Current avg r:0.6083 Best avg r: 0.6299
21:09:01,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:19,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:50,656 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3493
en_de Dev loss: 1.0972 r:0.2402
en_zh Dev loss: 0.7338 r:0.4805
ro_en Dev loss: 0.3444 r:0.8229
et_en Dev loss: 0.4370 r:0.6858
si_en Dev loss: 0.6871 r:0.6067
ne_en Dev loss: 0.3957 r:0.7625
ru_en Dev loss: 0.4659 r:0.7270
Current avg r:0.6179 Best avg r: 0.6299
21:15:42,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:00,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:32,103 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3513
en_de Dev loss: 1.0131 r:0.2480
en_zh Dev loss: 0.6708 r:0.4934
ro_en Dev loss: 0.3054 r:0.8243
et_en Dev loss: 0.4048 r:0.6893
si_en Dev loss: 0.6158 r:0.6078
ne_en Dev loss: 0.3590 r:0.7668
ru_en Dev loss: 0.4060 r:0.7412
Current avg r:0.6244 Best avg r: 0.6299
21:22:24,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:41,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:12,187 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3300
en_de Dev loss: 1.0898 r:0.2459
en_zh Dev loss: 0.7446 r:0.4742
ro_en Dev loss: 0.3451 r:0.8176
et_en Dev loss: 0.4334 r:0.6710
si_en Dev loss: 0.8762 r:0.5838
ne_en Dev loss: 0.5003 r:0.7585
ru_en Dev loss: 0.4633 r:0.7234
Current avg r:0.6106 Best avg r: 0.6299
21:29:05,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:22,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:53,511 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3006
en_de Dev loss: 1.0996 r:0.2432
en_zh Dev loss: 0.7424 r:0.4713
ro_en Dev loss: 0.3409 r:0.8217
et_en Dev loss: 0.4414 r:0.6870
si_en Dev loss: 0.6958 r:0.6055
ne_en Dev loss: 0.3830 r:0.7582
ru_en Dev loss: 0.4597 r:0.7294
Current avg r:0.6166 Best avg r: 0.6299
21:35:47,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:04,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:35,265 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3008
en_de Dev loss: 1.1287 r:0.2506
en_zh Dev loss: 0.7884 r:0.4637
ro_en Dev loss: 0.3661 r:0.8137
et_en Dev loss: 0.4452 r:0.6672
si_en Dev loss: 0.8578 r:0.5786
ne_en Dev loss: 0.4954 r:0.7473
ru_en Dev loss: 0.4864 r:0.7206
Current avg r:0.6060 Best avg r: 0.6299
21:42:29,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:46,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:17,392 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3146
en_de Dev loss: 1.1138 r:0.2543
en_zh Dev loss: 0.7725 r:0.4693
ro_en Dev loss: 0.3657 r:0.8191
et_en Dev loss: 0.4497 r:0.6765
si_en Dev loss: 0.7697 r:0.5905
ne_en Dev loss: 0.4637 r:0.7497
ru_en Dev loss: 0.4815 r:0.7222
Current avg r:0.6117 Best avg r: 0.6299
21:49:10,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:28,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:58,742 root INFO Epoch 4 Global steps: 38400 Train loss: 0.2985
en_de Dev loss: 1.1198 r:0.2504
en_zh Dev loss: 0.7958 r:0.4651
ro_en Dev loss: 0.3458 r:0.8222
et_en Dev loss: 0.4540 r:0.6773
si_en Dev loss: 0.7020 r:0.5974
ne_en Dev loss: 0.4472 r:0.7527
ru_en Dev loss: 0.5138 r:0.6950
Current avg r:0.6086 Best avg r: 0.6299
21:55:50,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:08,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:38,582 root INFO Epoch 4 Global steps: 39000 Train loss: 0.2983
en_de Dev loss: 1.0718 r:0.2497
en_zh Dev loss: 0.7479 r:0.4709
ro_en Dev loss: 0.3542 r:0.8157
et_en Dev loss: 0.4511 r:0.6685
si_en Dev loss: 0.8097 r:0.5819
ne_en Dev loss: 0.4620 r:0.7522
ru_en Dev loss: 0.4441 r:0.7213
Current avg r:0.6086 Best avg r: 0.6299
22:02:31,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:48,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:19,162 root INFO Epoch 4 Global steps: 39600 Train loss: 0.2835
en_de Dev loss: 1.1295 r:0.2365
en_zh Dev loss: 0.7779 r:0.4752
ro_en Dev loss: 0.3535 r:0.8228
et_en Dev loss: 0.4479 r:0.6739
si_en Dev loss: 0.7588 r:0.5857
ne_en Dev loss: 0.3828 r:0.7474
ru_en Dev loss: 0.4949 r:0.7182
Current avg r:0.6085 Best avg r: 0.6299
22:09:12,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:29,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:00,256 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3089
en_de Dev loss: 1.1094 r:0.2514
en_zh Dev loss: 0.7636 r:0.4705
ro_en Dev loss: 0.3540 r:0.8208
et_en Dev loss: 0.4493 r:0.6628
si_en Dev loss: 0.8884 r:0.5738
ne_en Dev loss: 0.5442 r:0.7516
ru_en Dev loss: 0.4696 r:0.7242
Current avg r:0.6079 Best avg r: 0.6299
22:15:52,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:09,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:40,24 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3021
en_de Dev loss: 1.1085 r:0.2487
en_zh Dev loss: 0.7593 r:0.4599
ro_en Dev loss: 0.3304 r:0.8228
et_en Dev loss: 0.4253 r:0.6702
si_en Dev loss: 0.8335 r:0.5816
ne_en Dev loss: 0.4649 r:0.7541
ru_en Dev loss: 0.5129 r:0.6966
Current avg r:0.6048 Best avg r: 0.6299
22:22:31,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:49,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:25:20,235 root INFO Epoch 4 Global steps: 41400 Train loss: 0.2923
en_de Dev loss: 1.1846 r:0.2563
en_zh Dev loss: 0.8352 r:0.4703
ro_en Dev loss: 0.3873 r:0.8188
et_en Dev loss: 0.4605 r:0.6577
si_en Dev loss: 0.9861 r:0.5663
ne_en Dev loss: 0.6091 r:0.7501
ru_en Dev loss: 0.6137 r:0.6727
Current avg r:0.5989 Best avg r: 0.6299
22:29:12,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:29,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:01,481 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3035
en_de Dev loss: 1.1048 r:0.2464
en_zh Dev loss: 0.7317 r:0.4801
ro_en Dev loss: 0.3294 r:0.8241
et_en Dev loss: 0.4355 r:0.6696
si_en Dev loss: 0.7939 r:0.5844
ne_en Dev loss: 0.4349 r:0.7554
ru_en Dev loss: 0.4876 r:0.7135
Current avg r:0.6105 Best avg r: 0.6299
22:35:53,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:11,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:41,770 root INFO Epoch 4 Global steps: 42600 Train loss: 0.2869
en_de Dev loss: 1.1366 r:0.2255
en_zh Dev loss: 0.7403 r:0.4763
ro_en Dev loss: 0.3603 r:0.8185
et_en Dev loss: 0.4574 r:0.6607
si_en Dev loss: 0.7824 r:0.5871
ne_en Dev loss: 0.5130 r:0.7447
ru_en Dev loss: 0.5027 r:0.7011
Current avg r:0.6020 Best avg r: 0.6299
22:42:33,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:53,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:23,737 root INFO Epoch 4 Global steps: 43200 Train loss: 0.2957
en_de Dev loss: 1.0666 r:0.2334
en_zh Dev loss: 0.6910 r:0.4878
ro_en Dev loss: 0.3206 r:0.8242
et_en Dev loss: 0.4335 r:0.6710
si_en Dev loss: 0.6440 r:0.5994
ne_en Dev loss: 0.3930 r:0.7524
ru_en Dev loss: 0.4128 r:0.7386
Current avg r:0.6152 Best avg r: 0.6299
22:49:16,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:34,140 root INFO 
id:ru_en cur r: 0.7517 best r: 0.7517
22:50:34,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:05,120 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3082
en_de Dev loss: 1.1280 r:0.2262
en_zh Dev loss: 0.7382 r:0.4841
ro_en Dev loss: 0.3390 r:0.8255
et_en Dev loss: 0.4308 r:0.6800
si_en Dev loss: 0.7145 r:0.5941
ne_en Dev loss: 0.4193 r:0.7562
ru_en Dev loss: 0.4218 r:0.7454
Current avg r:0.6159 Best avg r: 0.6299
22:55:57,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:23,749 root INFO 
id:ro_en cur r: 0.8279 best r: 0.8279
22:57:15,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:47,70 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2772
en_de Dev loss: 1.1503 r:0.2431
en_zh Dev loss: 0.7949 r:0.4708
ro_en Dev loss: 0.3452 r:0.8257
et_en Dev loss: 0.4537 r:0.6712
si_en Dev loss: 0.7779 r:0.5814
ne_en Dev loss: 0.4349 r:0.7440
ru_en Dev loss: 0.4953 r:0.7225
Current avg r:0.6084 Best avg r: 0.6299
23:02:40,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:58,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:29,256 root INFO Epoch 4 Global steps: 45000 Train loss: 0.2857
en_de Dev loss: 1.1108 r:0.2172
en_zh Dev loss: 0.7218 r:0.4814
ro_en Dev loss: 0.3208 r:0.8234
et_en Dev loss: 0.4495 r:0.6810
si_en Dev loss: 0.7290 r:0.5862
ne_en Dev loss: 0.4119 r:0.7460
ru_en Dev loss: 0.4641 r:0.7210
Current avg r:0.6080 Best avg r: 0.6299
23:09:23,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:41,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:12,565 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2479
en_de Dev loss: 1.1703 r:0.2388
en_zh Dev loss: 0.7993 r:0.4738
ro_en Dev loss: 0.3919 r:0.8171
et_en Dev loss: 0.4817 r:0.6594
si_en Dev loss: 0.8731 r:0.5720
ne_en Dev loss: 0.5014 r:0.7478
ru_en Dev loss: 0.4948 r:0.7294
Current avg r:0.6055 Best avg r: 0.6299
23:16:04,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:22,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:53,170 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2617
en_de Dev loss: 1.1695 r:0.2250
en_zh Dev loss: 0.8089 r:0.4615
ro_en Dev loss: 0.3611 r:0.8187
et_en Dev loss: 0.4526 r:0.6622
si_en Dev loss: 0.8530 r:0.5760
ne_en Dev loss: 0.4742 r:0.7479
ru_en Dev loss: 0.5424 r:0.6952
Current avg r:0.5981 Best avg r: 0.6299
23:22:45,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:23:11,278 root INFO 
id:ro_en cur r: 0.8280 best r: 0.8280
23:24:03,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:33,837 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2617
en_de Dev loss: 1.1342 r:0.2408
en_zh Dev loss: 0.7547 r:0.4828
ro_en Dev loss: 0.3396 r:0.8281
et_en Dev loss: 0.4521 r:0.6771
si_en Dev loss: 0.7303 r:0.5856
ne_en Dev loss: 0.4768 r:0.7471
ru_en Dev loss: 0.4523 r:0.7332
Current avg r:0.6135 Best avg r: 0.6299
23:29:26,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:43,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:32:14,462 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2644
en_de Dev loss: 1.0898 r:0.2324
en_zh Dev loss: 0.7148 r:0.4916
ro_en Dev loss: 0.3298 r:0.8259
et_en Dev loss: 0.4443 r:0.6646
si_en Dev loss: 0.8117 r:0.5838
ne_en Dev loss: 0.4333 r:0.7515
ru_en Dev loss: 0.4315 r:0.7356
Current avg r:0.6122 Best avg r: 0.6299
23:36:07,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:27,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:57,783 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2553
en_de Dev loss: 1.1438 r:0.2337
en_zh Dev loss: 0.7924 r:0.4724
ro_en Dev loss: 0.3492 r:0.8231
et_en Dev loss: 0.4738 r:0.6622
si_en Dev loss: 0.8198 r:0.5806
ne_en Dev loss: 0.4558 r:0.7493
ru_en Dev loss: 0.4699 r:0.7241
Current avg r:0.6065 Best avg r: 0.6299
23:42:51,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:09,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:39,832 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2577
en_de Dev loss: 1.1462 r:0.2347
en_zh Dev loss: 0.7933 r:0.4667
ro_en Dev loss: 0.3654 r:0.8235
et_en Dev loss: 0.4457 r:0.6592
si_en Dev loss: 0.7964 r:0.5722
ne_en Dev loss: 0.5645 r:0.7447
ru_en Dev loss: 0.5080 r:0.7145
Current avg r:0.6022 Best avg r: 0.6299
23:49:31,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:49,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:20,535 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2633
en_de Dev loss: 1.1672 r:0.2251
en_zh Dev loss: 0.7761 r:0.4803
ro_en Dev loss: 0.3815 r:0.8161
et_en Dev loss: 0.5188 r:0.6641
si_en Dev loss: 0.7781 r:0.5861
ne_en Dev loss: 0.4681 r:0.7424
ru_en Dev loss: 0.4680 r:0.7319
Current avg r:0.6066 Best avg r: 0.6299
23:56:12,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:30,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:01,406 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2540
en_de Dev loss: 1.1915 r:0.2408
en_zh Dev loss: 0.8158 r:0.4803
ro_en Dev loss: 0.4138 r:0.8145
et_en Dev loss: 0.4863 r:0.6565
si_en Dev loss: 0.9194 r:0.5727
ne_en Dev loss: 0.5119 r:0.7439
ru_en Dev loss: 0.5098 r:0.7220
Current avg r:0.6044 Best avg r: 0.6299
00:02:53,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:11,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:42,68 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2567
en_de Dev loss: 1.1452 r:0.2321
en_zh Dev loss: 0.7727 r:0.4798
ro_en Dev loss: 0.3588 r:0.8215
et_en Dev loss: 0.4521 r:0.6624
si_en Dev loss: 0.8944 r:0.5741
ne_en Dev loss: 0.4920 r:0.7425
ru_en Dev loss: 0.5026 r:0.7204
Current avg r:0.6047 Best avg r: 0.6299
00:09:34,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:51,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:22,711 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2391
en_de Dev loss: 1.1531 r:0.2455
en_zh Dev loss: 0.7882 r:0.4763
ro_en Dev loss: 0.3633 r:0.8203
et_en Dev loss: 0.4878 r:0.6622
si_en Dev loss: 0.8603 r:0.5696
ne_en Dev loss: 0.4745 r:0.7406
ru_en Dev loss: 0.5119 r:0.7164
Current avg r:0.6044 Best avg r: 0.6299
00:16:14,895 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:32,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:03,390 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2533
en_de Dev loss: 1.1469 r:0.2543
en_zh Dev loss: 0.7792 r:0.4644
ro_en Dev loss: 0.3581 r:0.8221
et_en Dev loss: 0.4523 r:0.6588
si_en Dev loss: 0.8066 r:0.5731
ne_en Dev loss: 0.4964 r:0.7369
ru_en Dev loss: 0.5056 r:0.7164
Current avg r:0.6037 Best avg r: 0.6299
00:22:55,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:13,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:44,770 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2479
en_de Dev loss: 1.1465 r:0.2304
en_zh Dev loss: 0.7567 r:0.4893
ro_en Dev loss: 0.3316 r:0.8246
et_en Dev loss: 0.4857 r:0.6652
si_en Dev loss: 0.7860 r:0.5716
ne_en Dev loss: 0.4647 r:0.7408
ru_en Dev loss: 0.4604 r:0.7313
Current avg r:0.6076 Best avg r: 0.6299
00:29:39,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:30:59,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:31,299 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2465
en_de Dev loss: 1.1129 r:0.2460
en_zh Dev loss: 0.7449 r:0.4823
ro_en Dev loss: 0.3213 r:0.8267
et_en Dev loss: 0.4210 r:0.6812
si_en Dev loss: 0.7446 r:0.5765
ne_en Dev loss: 0.4256 r:0.7374
ru_en Dev loss: 0.4440 r:0.7429
Current avg r:0.6133 Best avg r: 0.6299
00:36:25,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:43,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:14,655 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2464
en_de Dev loss: 1.1710 r:0.2394
en_zh Dev loss: 0.7894 r:0.4826
ro_en Dev loss: 0.3846 r:0.8197
et_en Dev loss: 0.4689 r:0.6587
si_en Dev loss: 0.8706 r:0.5617
ne_en Dev loss: 0.4805 r:0.7338
ru_en Dev loss: 0.5367 r:0.7136
Current avg r:0.6014 Best avg r: 0.6299
00:43:07,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:24,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:55,579 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2415
en_de Dev loss: 1.1290 r:0.2438
en_zh Dev loss: 0.7659 r:0.4758
ro_en Dev loss: 0.3456 r:0.8209
et_en Dev loss: 0.4598 r:0.6721
si_en Dev loss: 0.8729 r:0.5659
ne_en Dev loss: 0.4433 r:0.7370
ru_en Dev loss: 0.4791 r:0.7259
Current avg r:0.6059 Best avg r: 0.6299
00:49:48,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:08,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:39,628 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2268
en_de Dev loss: 1.1080 r:0.2372
en_zh Dev loss: 0.7408 r:0.4898
ro_en Dev loss: 0.3290 r:0.8240
et_en Dev loss: 0.4439 r:0.6701
si_en Dev loss: 0.7912 r:0.5713
ne_en Dev loss: 0.4040 r:0.7387
ru_en Dev loss: 0.4504 r:0.7352
Current avg r:0.6095 Best avg r: 0.6299
00:56:31,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:49,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:20,104 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2199
en_de Dev loss: 1.1352 r:0.2375
en_zh Dev loss: 0.7787 r:0.4814
ro_en Dev loss: 0.3532 r:0.8169
et_en Dev loss: 0.4927 r:0.6523
si_en Dev loss: 0.8416 r:0.5635
ne_en Dev loss: 0.4859 r:0.7278
ru_en Dev loss: 0.4755 r:0.7240
Current avg r:0.6005 Best avg r: 0.6299
01:03:12,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:29,808 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:00,498 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2252
en_de Dev loss: 1.2012 r:0.2261
en_zh Dev loss: 0.8041 r:0.4873
ro_en Dev loss: 0.3736 r:0.8198
et_en Dev loss: 0.5232 r:0.6691
si_en Dev loss: 0.8185 r:0.5693
ne_en Dev loss: 0.4764 r:0.7333
ru_en Dev loss: 0.4735 r:0.7376
Current avg r:0.6061 Best avg r: 0.6299
01:09:54,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:12,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:43,423 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2210
en_de Dev loss: 1.1297 r:0.2501
en_zh Dev loss: 0.7510 r:0.4835
ro_en Dev loss: 0.3554 r:0.8202
et_en Dev loss: 0.4703 r:0.6572
si_en Dev loss: 0.9149 r:0.5521
ne_en Dev loss: 0.4757 r:0.7348
ru_en Dev loss: 0.4819 r:0.7214
Current avg r:0.6028 Best avg r: 0.6299
01:16:36,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:55,138 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:26,382 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2191
en_de Dev loss: 1.1656 r:0.2225
en_zh Dev loss: 0.7834 r:0.4702
ro_en Dev loss: 0.3536 r:0.8181
et_en Dev loss: 0.4851 r:0.6582
si_en Dev loss: 0.8334 r:0.5557
ne_en Dev loss: 0.4629 r:0.7363
ru_en Dev loss: 0.4784 r:0.7236
Current avg r:0.5978 Best avg r: 0.6299
01:23:22,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:24:40,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:11,940 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2110
en_de Dev loss: 1.1799 r:0.2135
en_zh Dev loss: 0.7949 r:0.4776
ro_en Dev loss: 0.3592 r:0.8179
et_en Dev loss: 0.4770 r:0.6519
si_en Dev loss: 0.8902 r:0.5555
ne_en Dev loss: 0.4931 r:0.7369
ru_en Dev loss: 0.4852 r:0.7268
Current avg r:0.5972 Best avg r: 0.6299
01:30:05,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:23,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:55,257 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2117
en_de Dev loss: 1.2025 r:0.2159
en_zh Dev loss: 0.8449 r:0.4755
ro_en Dev loss: 0.3933 r:0.8095
et_en Dev loss: 0.4905 r:0.6509
si_en Dev loss: 0.9684 r:0.5430
ne_en Dev loss: 0.5665 r:0.7344
ru_en Dev loss: 0.5358 r:0.7078
Current avg r:0.5910 Best avg r: 0.6299
01:36:48,832 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:38:07,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:38,403 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2112
en_de Dev loss: 1.1234 r:0.2301
en_zh Dev loss: 0.7882 r:0.4719
ro_en Dev loss: 0.3617 r:0.8104
et_en Dev loss: 0.4920 r:0.6553
si_en Dev loss: 0.8485 r:0.5518
ne_en Dev loss: 0.5165 r:0.7313
ru_en Dev loss: 0.4818 r:0.7109
Current avg r:0.5945 Best avg r: 0.6299
01:43:31,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:50,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:46:22,754 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2181
en_de Dev loss: 1.1305 r:0.2241
en_zh Dev loss: 0.7639 r:0.4881
ro_en Dev loss: 0.3529 r:0.8150
et_en Dev loss: 0.4782 r:0.6606
si_en Dev loss: 0.8374 r:0.5554
ne_en Dev loss: 0.5506 r:0.7301
ru_en Dev loss: 0.4650 r:0.7225
Current avg r:0.5994 Best avg r: 0.6299
01:50:17,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:36,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:53:08,539 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2168
en_de Dev loss: 1.1946 r:0.2564
en_zh Dev loss: 0.8364 r:0.4817
ro_en Dev loss: 0.4213 r:0.8198
et_en Dev loss: 0.4782 r:0.6675
si_en Dev loss: 0.9225 r:0.5539
ne_en Dev loss: 0.5843 r:0.7281
ru_en Dev loss: 0.5140 r:0.7306
Current avg r:0.6054 Best avg r: 0.6299
01:57:03,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:16,724 root INFO 
id:en_zh cur r: 0.4984 best r: 0.4984
01:58:22,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:54,141 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2105
en_de Dev loss: 1.1610 r:0.2448
en_zh Dev loss: 0.7866 r:0.4942
ro_en Dev loss: 0.3736 r:0.8205
et_en Dev loss: 0.4618 r:0.6686
si_en Dev loss: 0.9179 r:0.5517
ne_en Dev loss: 0.4754 r:0.7318
ru_en Dev loss: 0.5025 r:0.7258
Current avg r:0.6053 Best avg r: 0.6299
02:03:49,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:07,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:06:39,831 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2097
en_de Dev loss: 1.1013 r:0.2536
en_zh Dev loss: 0.7426 r:0.4898
ro_en Dev loss: 0.3392 r:0.8202
et_en Dev loss: 0.4607 r:0.6635
si_en Dev loss: 0.8484 r:0.5516
ne_en Dev loss: 0.4680 r:0.7326
ru_en Dev loss: 0.4662 r:0.7256
Current avg r:0.6053 Best avg r: 0.6299
02:10:35,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:11:53,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:13:25,598 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2070
en_de Dev loss: 1.1551 r:0.2498
en_zh Dev loss: 0.8097 r:0.4761
ro_en Dev loss: 0.3863 r:0.8135
et_en Dev loss: 0.4921 r:0.6587
si_en Dev loss: 0.9062 r:0.5510
ne_en Dev loss: 0.4890 r:0.7332
ru_en Dev loss: 0.4878 r:0.7295
Current avg r:0.6017 Best avg r: 0.6299
02:17:20,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:18:37,962 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:20:08,724 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2184
en_de Dev loss: 1.1325 r:0.2369
en_zh Dev loss: 0.7698 r:0.4869
ro_en Dev loss: 0.3458 r:0.8153
et_en Dev loss: 0.4612 r:0.6635
si_en Dev loss: 0.8964 r:0.5537
ne_en Dev loss: 0.4874 r:0.7271
ru_en Dev loss: 0.4646 r:0.7352
Current avg r:0.6026 Best avg r: 0.6299
02:24:01,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:25:18,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:26:49,693 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2146
en_de Dev loss: 1.1463 r:0.2445
en_zh Dev loss: 0.8066 r:0.4743
ro_en Dev loss: 0.3419 r:0.8202
et_en Dev loss: 0.4678 r:0.6603
si_en Dev loss: 0.9465 r:0.5551
ne_en Dev loss: 0.5036 r:0.7331
ru_en Dev loss: 0.4790 r:0.7323
Current avg r:0.6028 Best avg r: 0.6299
02:30:43,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:32:01,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:33:32,88 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1922
en_de Dev loss: 1.1681 r:0.2315
en_zh Dev loss: 0.8141 r:0.4695
ro_en Dev loss: 0.3395 r:0.8209
et_en Dev loss: 0.4885 r:0.6654
si_en Dev loss: 0.8581 r:0.5615
ne_en Dev loss: 0.4331 r:0.7313
ru_en Dev loss: 0.4588 r:0.7353
Current avg r:0.6022 Best avg r: 0.6299
02:37:24,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:38:42,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:40:13,127 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1855
en_de Dev loss: 1.1442 r:0.2442
en_zh Dev loss: 0.8120 r:0.4715
ro_en Dev loss: 0.3346 r:0.8204
et_en Dev loss: 0.4843 r:0.6570
si_en Dev loss: 0.9045 r:0.5559
ne_en Dev loss: 0.5047 r:0.7309
ru_en Dev loss: 0.4755 r:0.7232
Current avg r:0.6004 Best avg r: 0.6299
02:44:05,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:45:23,298 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:46:54,129 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1829
en_de Dev loss: 1.0874 r:0.2564
en_zh Dev loss: 0.7754 r:0.4717
ro_en Dev loss: 0.3328 r:0.8219
et_en Dev loss: 0.4625 r:0.6510
si_en Dev loss: 0.9017 r:0.5433
ne_en Dev loss: 0.5295 r:0.7352
ru_en Dev loss: 0.4372 r:0.7319
Current avg r:0.6016 Best avg r: 0.6299
02:50:46,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:52:04,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:35,175 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1925
en_de Dev loss: 1.1081 r:0.2543
en_zh Dev loss: 0.7719 r:0.4759
ro_en Dev loss: 0.3651 r:0.8158
et_en Dev loss: 0.4745 r:0.6454
si_en Dev loss: 0.8738 r:0.5448
ne_en Dev loss: 0.5437 r:0.7302
ru_en Dev loss: 0.5128 r:0.7074
Current avg r:0.5963 Best avg r: 0.6299
02:57:27,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:58:45,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:16,157 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1857
en_de Dev loss: 1.1380 r:0.2509
en_zh Dev loss: 0.7963 r:0.4768
ro_en Dev loss: 0.3654 r:0.8199
et_en Dev loss: 0.4911 r:0.6555
si_en Dev loss: 0.8361 r:0.5549
ne_en Dev loss: 0.4632 r:0.7363
ru_en Dev loss: 0.4421 r:0.7410
Current avg r:0.6050 Best avg r: 0.6299
03:04:08,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:05:26,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:06:57,541 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1959
en_de Dev loss: 1.1257 r:0.2442
en_zh Dev loss: 0.7661 r:0.4798
ro_en Dev loss: 0.3631 r:0.8157
et_en Dev loss: 0.5210 r:0.6565
si_en Dev loss: 0.8140 r:0.5543
ne_en Dev loss: 0.4316 r:0.7396
ru_en Dev loss: 0.4377 r:0.7420
Current avg r:0.6046 Best avg r: 0.6299
03:10:51,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:12:09,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:13:42,663 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1807
en_de Dev loss: 1.1530 r:0.2321
en_zh Dev loss: 0.8031 r:0.4666
ro_en Dev loss: 0.3741 r:0.8177
et_en Dev loss: 0.4832 r:0.6460
si_en Dev loss: 0.8853 r:0.5430
ne_en Dev loss: 0.5143 r:0.7331
ru_en Dev loss: 0.4724 r:0.7223
Current avg r:0.5944 Best avg r: 0.6299
03:17:36,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:18:54,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:20:26,490 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1871
en_de Dev loss: 1.1396 r:0.2419
en_zh Dev loss: 0.7824 r:0.4727
ro_en Dev loss: 0.3566 r:0.8226
et_en Dev loss: 0.4799 r:0.6522
si_en Dev loss: 0.8818 r:0.5439
ne_en Dev loss: 0.5191 r:0.7298
ru_en Dev loss: 0.4788 r:0.7290
Current avg r:0.5989 Best avg r: 0.6299
03:24:20,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:25:38,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:27:10,485 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1854
en_de Dev loss: 1.1257 r:0.2303
en_zh Dev loss: 0.7795 r:0.4671
ro_en Dev loss: 0.3631 r:0.8139
et_en Dev loss: 0.4869 r:0.6540
si_en Dev loss: 0.8362 r:0.5487
ne_en Dev loss: 0.5301 r:0.7381
ru_en Dev loss: 0.4509 r:0.7315
Current avg r:0.5977 Best avg r: 0.6299
03:31:03,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:32:21,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:33:52,513 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1827
en_de Dev loss: 1.1100 r:0.2418
en_zh Dev loss: 0.7609 r:0.4738
ro_en Dev loss: 0.3421 r:0.8189
et_en Dev loss: 0.4922 r:0.6611
si_en Dev loss: 0.7983 r:0.5495
ne_en Dev loss: 0.4841 r:0.7393
ru_en Dev loss: 0.4486 r:0.7283
Current avg r:0.6018 Best avg r: 0.6299
03:37:44,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:39:02,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:40:33,555 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1855
en_de Dev loss: 1.1831 r:0.2525
en_zh Dev loss: 0.8326 r:0.4658
ro_en Dev loss: 0.3895 r:0.8126
et_en Dev loss: 0.5123 r:0.6348
si_en Dev loss: 0.9871 r:0.5286
ne_en Dev loss: 0.5818 r:0.7317
ru_en Dev loss: 0.4888 r:0.7278
Current avg r:0.5934 Best avg r: 0.6299
03:44:25,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:45:43,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:47:14,565 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1840
en_de Dev loss: 1.1095 r:0.2544
en_zh Dev loss: 0.7729 r:0.4671
ro_en Dev loss: 0.3397 r:0.8161
et_en Dev loss: 0.4810 r:0.6482
si_en Dev loss: 0.9009 r:0.5345
ne_en Dev loss: 0.5032 r:0.7347
ru_en Dev loss: 0.4518 r:0.7277
Current avg r:0.5975 Best avg r: 0.6299
03:51:08,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:52:26,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:53:56,962 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1791
en_de Dev loss: 1.1672 r:0.2517
en_zh Dev loss: 0.8025 r:0.4773
ro_en Dev loss: 0.3447 r:0.8202
et_en Dev loss: 0.4820 r:0.6663
si_en Dev loss: 0.8624 r:0.5557
ne_en Dev loss: 0.4931 r:0.7368
ru_en Dev loss: 0.4629 r:0.7413
Current avg r:0.6070 Best avg r: 0.6299
03:57:49,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:59:07,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:38,85 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1807
en_de Dev loss: 1.1475 r:0.2250
en_zh Dev loss: 0.7667 r:0.4779
ro_en Dev loss: 0.3285 r:0.8208
et_en Dev loss: 0.4671 r:0.6571
si_en Dev loss: 0.8413 r:0.5527
ne_en Dev loss: 0.4624 r:0.7414
ru_en Dev loss: 0.4381 r:0.7406
Current avg r:0.6022 Best avg r: 0.6299
04:04:30,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:05:48,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:07:19,156 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1871
en_de Dev loss: 1.1670 r:0.2463
en_zh Dev loss: 0.7953 r:0.4739
ro_en Dev loss: 0.3497 r:0.8205
et_en Dev loss: 0.4769 r:0.6586
si_en Dev loss: 0.8925 r:0.5513
ne_en Dev loss: 0.5236 r:0.7222
ru_en Dev loss: 0.4825 r:0.7366
Current avg r:0.6014 Best avg r: 0.6299
04:11:13,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:12:31,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:14:03,233 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1636
en_de Dev loss: 1.1677 r:0.2450
en_zh Dev loss: 0.7793 r:0.4803
ro_en Dev loss: 0.3617 r:0.8186
et_en Dev loss: 0.4921 r:0.6592
si_en Dev loss: 0.8920 r:0.5524
ne_en Dev loss: 0.5709 r:0.7292
ru_en Dev loss: 0.4827 r:0.7334
Current avg r:0.6026 Best avg r: 0.6299
04:17:57,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:19:15,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:20:47,144 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1629
en_de Dev loss: 1.1124 r:0.2469
en_zh Dev loss: 0.7565 r:0.4730
ro_en Dev loss: 0.3483 r:0.8168
et_en Dev loss: 0.4960 r:0.6552
si_en Dev loss: 0.8688 r:0.5434
ne_en Dev loss: 0.5167 r:0.7246
ru_en Dev loss: 0.4656 r:0.7224
Current avg r:0.5975 Best avg r: 0.6299
04:24:41,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:25:59,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:27:31,153 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1608
en_de Dev loss: 1.1462 r:0.2315
en_zh Dev loss: 0.7631 r:0.4813
ro_en Dev loss: 0.3389 r:0.8183
et_en Dev loss: 0.4859 r:0.6506
si_en Dev loss: 0.8744 r:0.5415
ne_en Dev loss: 0.5176 r:0.7255
ru_en Dev loss: 0.4595 r:0.7287
Current avg r:0.5968 Best avg r: 0.6299
04:31:25,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:32:43,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:34:15,143 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1584
en_de Dev loss: 1.1124 r:0.2435
en_zh Dev loss: 0.7648 r:0.4704
ro_en Dev loss: 0.3500 r:0.8153
et_en Dev loss: 0.4903 r:0.6399
si_en Dev loss: 0.8836 r:0.5403
ne_en Dev loss: 0.5226 r:0.7186
ru_en Dev loss: 0.4269 r:0.7393
Current avg r:0.5953 Best avg r: 0.6299
04:38:07,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:39:25,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:40:56,147 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1602
en_de Dev loss: 1.1740 r:0.2448
en_zh Dev loss: 0.8261 r:0.4728
ro_en Dev loss: 0.3705 r:0.8186
et_en Dev loss: 0.4815 r:0.6520
si_en Dev loss: 0.9196 r:0.5403
ne_en Dev loss: 0.6104 r:0.7174
ru_en Dev loss: 0.4860 r:0.7272
Current avg r:0.5962 Best avg r: 0.6299
04:44:48,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:46:06,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:47:37,256 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1615
en_de Dev loss: 1.1618 r:0.2318
en_zh Dev loss: 0.7866 r:0.4802
ro_en Dev loss: 0.3602 r:0.8172
et_en Dev loss: 0.5154 r:0.6594
si_en Dev loss: 0.8392 r:0.5516
ne_en Dev loss: 0.4784 r:0.7268
ru_en Dev loss: 0.4453 r:0.7426
Current avg r:0.6014 Best avg r: 0.6299
04:51:29,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:52:47,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:54:18,399 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1534
en_de Dev loss: 1.1822 r:0.2165
en_zh Dev loss: 0.8046 r:0.4712
ro_en Dev loss: 0.3659 r:0.8133
et_en Dev loss: 0.4969 r:0.6546
si_en Dev loss: 0.9130 r:0.5390
ne_en Dev loss: 0.5591 r:0.7251
ru_en Dev loss: 0.4505 r:0.7375
Current avg r:0.5939 Best avg r: 0.6299
04:58:10,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:59:29,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:01:00,848 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1503
en_de Dev loss: 1.1853 r:0.2314
en_zh Dev loss: 0.8262 r:0.4655
ro_en Dev loss: 0.3495 r:0.8176
et_en Dev loss: 0.4935 r:0.6536
si_en Dev loss: 0.8806 r:0.5446
ne_en Dev loss: 0.5297 r:0.7215
ru_en Dev loss: 0.4837 r:0.7270
Current avg r:0.5945 Best avg r: 0.6299
05:04:53,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:11,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:07:41,838 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1658
en_de Dev loss: 1.1914 r:0.2265
en_zh Dev loss: 0.7984 r:0.4810
ro_en Dev loss: 0.3679 r:0.8179
et_en Dev loss: 0.5132 r:0.6522
si_en Dev loss: 0.8575 r:0.5462
ne_en Dev loss: 0.5089 r:0.7244
ru_en Dev loss: 0.4852 r:0.7239
Current avg r:0.5960 Best avg r: 0.6299
05:11:34,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:12:52,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:14:22,961 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1585
en_de Dev loss: 1.1923 r:0.2353
en_zh Dev loss: 0.8068 r:0.4811
ro_en Dev loss: 0.3832 r:0.8156
et_en Dev loss: 0.5006 r:0.6434
si_en Dev loss: 0.9177 r:0.5423
ne_en Dev loss: 0.5433 r:0.7187
ru_en Dev loss: 0.4710 r:0.7337
Current avg r:0.5957 Best avg r: 0.6299
05:18:15,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:19:33,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:21:04,828 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1523
en_de Dev loss: 1.1630 r:0.2370
en_zh Dev loss: 0.7721 r:0.4875
ro_en Dev loss: 0.3642 r:0.8186
et_en Dev loss: 0.4804 r:0.6440
si_en Dev loss: 0.9833 r:0.5349
ne_en Dev loss: 0.6504 r:0.7191
ru_en Dev loss: 0.4827 r:0.7302
Current avg r:0.5959 Best avg r: 0.6299
05:24:58,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:26:17,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:27:48,793 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1607
en_de Dev loss: 1.1838 r:0.2215
en_zh Dev loss: 0.7952 r:0.4784
ro_en Dev loss: 0.3691 r:0.8152
et_en Dev loss: 0.5267 r:0.6575
si_en Dev loss: 0.9033 r:0.5384
ne_en Dev loss: 0.5354 r:0.7241
ru_en Dev loss: 0.4370 r:0.7476
Current avg r:0.5975 Best avg r: 0.6299
05:31:42,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:33:01,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:34:32,620 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1529
en_de Dev loss: 1.1755 r:0.2239
en_zh Dev loss: 0.7914 r:0.4837
ro_en Dev loss: 0.3495 r:0.8206
et_en Dev loss: 0.4818 r:0.6643
si_en Dev loss: 0.8305 r:0.5481
ne_en Dev loss: 0.4941 r:0.7149
ru_en Dev loss: 0.4454 r:0.7455
Current avg r:0.6001 Best avg r: 0.6299
05:38:26,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:39:44,954 root INFO 
id:ru_en cur r: 0.7523 best r: 0.7523
05:39:44,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:41:16,457 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1482
en_de Dev loss: 1.1479 r:0.2365
en_zh Dev loss: 0.7782 r:0.4843
ro_en Dev loss: 0.3498 r:0.8203
et_en Dev loss: 0.4684 r:0.6511
si_en Dev loss: 0.9580 r:0.5355
ne_en Dev loss: 0.5338 r:0.7216
ru_en Dev loss: 0.4478 r:0.7450
Current avg r:0.5992 Best avg r: 0.6299
05:45:09,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:46:27,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:47:58,56 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1575
en_de Dev loss: 1.1607 r:0.2397
en_zh Dev loss: 0.8031 r:0.4798
ro_en Dev loss: 0.3682 r:0.8168
et_en Dev loss: 0.4908 r:0.6511
si_en Dev loss: 0.9587 r:0.5361
ne_en Dev loss: 0.5481 r:0.7205
ru_en Dev loss: 0.4738 r:0.7346
Current avg r:0.5969 Best avg r: 0.6299
05:51:51,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:53:09,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:54:40,377 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1425
en_de Dev loss: 1.2453 r:0.2330
en_zh Dev loss: 0.8697 r:0.4797
ro_en Dev loss: 0.4068 r:0.8169
et_en Dev loss: 0.5098 r:0.6507
si_en Dev loss: 0.9598 r:0.5424
ne_en Dev loss: 0.5524 r:0.7198
ru_en Dev loss: 0.5616 r:0.7187
Current avg r:0.5945 Best avg r: 0.6299
05:58:32,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:50,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:01:22,545 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1445
en_de Dev loss: 1.1358 r:0.2346
en_zh Dev loss: 0.7648 r:0.4777
ro_en Dev loss: 0.3423 r:0.8185
et_en Dev loss: 0.4908 r:0.6542
si_en Dev loss: 0.8910 r:0.5388
ne_en Dev loss: 0.5192 r:0.7188
ru_en Dev loss: 0.4561 r:0.7352
Current avg r:0.5968 Best avg r: 0.6299
06:05:16,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:06:33,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:04,806 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1314
en_de Dev loss: 1.1804 r:0.2352
en_zh Dev loss: 0.8012 r:0.4770
ro_en Dev loss: 0.3688 r:0.8179
et_en Dev loss: 0.5100 r:0.6439
si_en Dev loss: 0.9445 r:0.5325
ne_en Dev loss: 0.5209 r:0.7210
ru_en Dev loss: 0.4877 r:0.7252
Current avg r:0.5932 Best avg r: 0.6299
06:11:57,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:13:14,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:14:47,279 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1382
en_de Dev loss: 1.1542 r:0.2352
en_zh Dev loss: 0.7776 r:0.4846
ro_en Dev loss: 0.3509 r:0.8168
et_en Dev loss: 0.4884 r:0.6497
si_en Dev loss: 0.9008 r:0.5405
ne_en Dev loss: 0.5735 r:0.7183
ru_en Dev loss: 0.4664 r:0.7302
Current avg r:0.5965 Best avg r: 0.6299
06:18:39,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:19:57,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:21:28,176 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1403
en_de Dev loss: 1.1647 r:0.2433
en_zh Dev loss: 0.7873 r:0.4903
ro_en Dev loss: 0.3522 r:0.8188
et_en Dev loss: 0.4840 r:0.6631
si_en Dev loss: 0.8641 r:0.5444
ne_en Dev loss: 0.5409 r:0.7180
ru_en Dev loss: 0.4860 r:0.7260
Current avg r:0.6006 Best avg r: 0.6299
06:25:21,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:26:40,71 root INFO 
id:ru_en cur r: 0.7578 best r: 0.7578
06:26:40,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:28:11,579 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1414
en_de Dev loss: 1.1934 r:0.2412
en_zh Dev loss: 0.8111 r:0.4816
ro_en Dev loss: 0.3663 r:0.8170
et_en Dev loss: 0.4956 r:0.6616
si_en Dev loss: 0.9199 r:0.5328
ne_en Dev loss: 0.5449 r:0.7173
ru_en Dev loss: 0.4318 r:0.7532
Current avg r:0.6007 Best avg r: 0.6299
06:32:05,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:33:23,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:34:55,463 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1413
en_de Dev loss: 1.1611 r:0.2424
en_zh Dev loss: 0.7875 r:0.4823
ro_en Dev loss: 0.3474 r:0.8184
et_en Dev loss: 0.4774 r:0.6550
si_en Dev loss: 0.8795 r:0.5404
ne_en Dev loss: 0.5241 r:0.7220
ru_en Dev loss: 0.4556 r:0.7375
Current avg r:0.5997 Best avg r: 0.6299
06:38:49,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:40:07,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:41:40,700 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1415
en_de Dev loss: 1.2060 r:0.2348
en_zh Dev loss: 0.8023 r:0.4830
ro_en Dev loss: 0.3826 r:0.8141
et_en Dev loss: 0.4922 r:0.6516
si_en Dev loss: 0.9760 r:0.5350
ne_en Dev loss: 0.5671 r:0.7099
ru_en Dev loss: 0.4832 r:0.7353
Current avg r:0.5948 Best avg r: 0.6299
06:45:34,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:46:52,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:48:23,164 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1355
en_de Dev loss: 1.1509 r:0.2266
en_zh Dev loss: 0.7643 r:0.4792
ro_en Dev loss: 0.3363 r:0.8178
et_en Dev loss: 0.4980 r:0.6607
si_en Dev loss: 0.8429 r:0.5433
ne_en Dev loss: 0.5028 r:0.7191
ru_en Dev loss: 0.4162 r:0.7498
Current avg r:0.5995 Best avg r: 0.6299
06:52:15,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:53:33,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:55:04,223 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1371
en_de Dev loss: 1.2286 r:0.2345
en_zh Dev loss: 0.8302 r:0.4855
ro_en Dev loss: 0.3830 r:0.8168
et_en Dev loss: 0.5096 r:0.6571
si_en Dev loss: 0.9351 r:0.5459
ne_en Dev loss: 0.5148 r:0.7253
ru_en Dev loss: 0.4634 r:0.7494
Current avg r:0.6021 Best avg r: 0.6299
06:58:56,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:14,222 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:45,136 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1346
en_de Dev loss: 1.2396 r:0.2222
en_zh Dev loss: 0.8194 r:0.4799
ro_en Dev loss: 0.3673 r:0.8177
et_en Dev loss: 0.4827 r:0.6585
si_en Dev loss: 0.9465 r:0.5383
ne_en Dev loss: 0.5780 r:0.7134
ru_en Dev loss: 0.4855 r:0.7339
Current avg r:0.5949 Best avg r: 0.6299
07:05:37,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:06:55,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:26,226 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1426
en_de Dev loss: 1.1685 r:0.2258
en_zh Dev loss: 0.7475 r:0.4911
ro_en Dev loss: 0.3536 r:0.8178
et_en Dev loss: 0.4852 r:0.6651
si_en Dev loss: 0.8782 r:0.5453
ne_en Dev loss: 0.4959 r:0.7197
ru_en Dev loss: 0.4471 r:0.7405
Current avg r:0.6008 Best avg r: 0.6299
07:12:18,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:36,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:07,297 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1332
en_de Dev loss: 1.1862 r:0.2217
en_zh Dev loss: 0.7813 r:0.4791
ro_en Dev loss: 0.3873 r:0.8114
et_en Dev loss: 0.4775 r:0.6415
si_en Dev loss: 1.0510 r:0.5325
ne_en Dev loss: 0.7526 r:0.7180
ru_en Dev loss: 0.4960 r:0.7250
Current avg r:0.5899 Best avg r: 0.6299
07:19:00,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:20:18,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:21:50,1 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1363
en_de Dev loss: 1.1869 r:0.2363
en_zh Dev loss: 0.7781 r:0.4886
ro_en Dev loss: 0.3547 r:0.8207
et_en Dev loss: 0.4831 r:0.6560
si_en Dev loss: 0.8954 r:0.5426
ne_en Dev loss: 0.5318 r:0.7216
ru_en Dev loss: 0.4587 r:0.7431
Current avg r:0.6013 Best avg r: 0.6299
07:25:43,28 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:27:01,527 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:28:33,230 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1408
en_de Dev loss: 1.1833 r:0.2303
en_zh Dev loss: 0.7851 r:0.4859
ro_en Dev loss: 0.3599 r:0.8190
et_en Dev loss: 0.4672 r:0.6596
si_en Dev loss: 0.8623 r:0.5484
ne_en Dev loss: 0.5056 r:0.7219
ru_en Dev loss: 0.4493 r:0.7470
Current avg r:0.6017 Best avg r: 0.6299
07:32:29,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:33:48,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:35:21,546 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1181
en_de Dev loss: 1.2209 r:0.2291
en_zh Dev loss: 0.8343 r:0.4818
ro_en Dev loss: 0.3835 r:0.8161
et_en Dev loss: 0.5044 r:0.6497
si_en Dev loss: 0.9662 r:0.5345
ne_en Dev loss: 0.5862 r:0.7110
ru_en Dev loss: 0.5104 r:0.7320
Current avg r:0.5935 Best avg r: 0.6299
07:39:16,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:35,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:07,451 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1234
en_de Dev loss: 1.1680 r:0.2289
en_zh Dev loss: 0.7698 r:0.4883
ro_en Dev loss: 0.3527 r:0.8179
et_en Dev loss: 0.4817 r:0.6520
si_en Dev loss: 0.9235 r:0.5400
ne_en Dev loss: 0.5058 r:0.7242
ru_en Dev loss: 0.4522 r:0.7406
Current avg r:0.5988 Best avg r: 0.6299
07:46:01,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:20,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:48:52,462 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1253
en_de Dev loss: 1.1819 r:0.2385
en_zh Dev loss: 0.7925 r:0.4802
ro_en Dev loss: 0.3663 r:0.8152
et_en Dev loss: 0.5160 r:0.6612
si_en Dev loss: 0.8457 r:0.5452
ne_en Dev loss: 0.5017 r:0.7170
ru_en Dev loss: 0.4498 r:0.7428
Current avg r:0.6000 Best avg r: 0.6299
07:52:47,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:54:04,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:35,940 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1222
en_de Dev loss: 1.1491 r:0.2381
en_zh Dev loss: 0.7725 r:0.4826
ro_en Dev loss: 0.3498 r:0.8135
et_en Dev loss: 0.4917 r:0.6476
si_en Dev loss: 0.8677 r:0.5378
ne_en Dev loss: 0.5400 r:0.7067
ru_en Dev loss: 0.4283 r:0.7438
Current avg r:0.5957 Best avg r: 0.6299
07:59:31,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:00:48,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:19,163 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1209
en_de Dev loss: 1.1883 r:0.2448
en_zh Dev loss: 0.8170 r:0.4840
ro_en Dev loss: 0.3674 r:0.8132
et_en Dev loss: 0.4804 r:0.6540
si_en Dev loss: 0.9598 r:0.5384
ne_en Dev loss: 0.5597 r:0.7120
ru_en Dev loss: 0.4778 r:0.7361
Current avg r:0.5975 Best avg r: 0.6299
08:06:10,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:07:28,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:08:59,507 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1192
en_de Dev loss: 1.1624 r:0.2337
en_zh Dev loss: 0.7743 r:0.4807
ro_en Dev loss: 0.3442 r:0.8170
et_en Dev loss: 0.4723 r:0.6549
si_en Dev loss: 0.8662 r:0.5421
ne_en Dev loss: 0.5378 r:0.7140
ru_en Dev loss: 0.4527 r:0.7413
Current avg r:0.5977 Best avg r: 0.6299
08:12:51,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:14:09,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:15:40,413 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1154
en_de Dev loss: 1.1449 r:0.2258
en_zh Dev loss: 0.7549 r:0.4812
ro_en Dev loss: 0.3409 r:0.8167
et_en Dev loss: 0.5075 r:0.6605
si_en Dev loss: 0.8474 r:0.5442
ne_en Dev loss: 0.5273 r:0.7103
ru_en Dev loss: 0.4071 r:0.7442
Current avg r:0.5976 Best avg r: 0.6299
08:19:32,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:20:50,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:22:21,544 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1165
en_de Dev loss: 1.1752 r:0.2476
en_zh Dev loss: 0.7928 r:0.4821
ro_en Dev loss: 0.3643 r:0.8117
et_en Dev loss: 0.4927 r:0.6543
si_en Dev loss: 1.0336 r:0.5298
ne_en Dev loss: 0.5706 r:0.7108
ru_en Dev loss: 0.4791 r:0.7343
Current avg r:0.5958 Best avg r: 0.6299
08:26:13,818 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:27:31,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:02,579 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1233
en_de Dev loss: 1.1923 r:0.2323
en_zh Dev loss: 0.8035 r:0.4856
ro_en Dev loss: 0.3824 r:0.8099
et_en Dev loss: 0.4930 r:0.6592
si_en Dev loss: 0.9679 r:0.5342
ne_en Dev loss: 0.5788 r:0.7113
ru_en Dev loss: 0.4713 r:0.7392
Current avg r:0.5960 Best avg r: 0.6299
08:32:54,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:34:12,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:35:43,201 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1224
en_de Dev loss: 1.1370 r:0.2316
en_zh Dev loss: 0.7591 r:0.4901
ro_en Dev loss: 0.3372 r:0.8170
et_en Dev loss: 0.4634 r:0.6577
si_en Dev loss: 0.8619 r:0.5497
ne_en Dev loss: 0.5060 r:0.7154
ru_en Dev loss: 0.4223 r:0.7480
Current avg r:0.6014 Best avg r: 0.6299
08:39:35,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:40:53,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:42:23,782 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1193
en_de Dev loss: 1.2330 r:0.2225
en_zh Dev loss: 0.8326 r:0.4850
ro_en Dev loss: 0.3865 r:0.8157
et_en Dev loss: 0.4818 r:0.6513
si_en Dev loss: 0.9806 r:0.5348
ne_en Dev loss: 0.6129 r:0.7065
ru_en Dev loss: 0.4761 r:0.7406
Current avg r:0.5938 Best avg r: 0.6299
08:46:15,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:33,626 root INFO 
id:ru_en cur r: 0.7609 best r: 0.7609
08:47:33,626 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:04,387 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1194
en_de Dev loss: 1.2085 r:0.2198
en_zh Dev loss: 0.7751 r:0.4937
ro_en Dev loss: 0.3610 r:0.8188
et_en Dev loss: 0.4666 r:0.6596
si_en Dev loss: 0.9334 r:0.5383
ne_en Dev loss: 0.6115 r:0.7189
ru_en Dev loss: 0.4365 r:0.7525
Current avg r:0.6002 Best avg r: 0.6299
08:52:56,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:09,405 root INFO 
id:en_zh cur r: 0.5001 best r: 0.5001
08:54:14,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:55:44,968 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1149
en_de Dev loss: 1.2456 r:0.2239
en_zh Dev loss: 0.8110 r:0.4961
ro_en Dev loss: 0.3827 r:0.8163
et_en Dev loss: 0.5234 r:0.6532
si_en Dev loss: 0.9390 r:0.5396
ne_en Dev loss: 0.5432 r:0.7216
ru_en Dev loss: 0.4767 r:0.7396
Current avg r:0.5986 Best avg r: 0.6299
08:59:37,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:00:54,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:02:25,447 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1198
en_de Dev loss: 1.2408 r:0.2360
en_zh Dev loss: 0.8429 r:0.4892
ro_en Dev loss: 0.3819 r:0.8145
et_en Dev loss: 0.4907 r:0.6537
si_en Dev loss: 0.9656 r:0.5303
ne_en Dev loss: 0.6475 r:0.7124
ru_en Dev loss: 0.5136 r:0.7339
Current avg r:0.5957 Best avg r: 0.6299
09:06:18,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:07:36,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:07,99 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1167
en_de Dev loss: 1.2106 r:0.2417
en_zh Dev loss: 0.8065 r:0.4891
ro_en Dev loss: 0.3793 r:0.8135
et_en Dev loss: 0.4942 r:0.6513
si_en Dev loss: 0.9470 r:0.5353
ne_en Dev loss: 0.6175 r:0.7204
ru_en Dev loss: 0.4836 r:0.7391
Current avg r:0.5986 Best avg r: 0.6299
09:13:00,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:14:18,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:15:48,766 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1050
en_de Dev loss: 1.1614 r:0.2551
en_zh Dev loss: 0.7872 r:0.4941
ro_en Dev loss: 0.3545 r:0.8183
et_en Dev loss: 0.5050 r:0.6543
si_en Dev loss: 0.9356 r:0.5350
ne_en Dev loss: 0.5625 r:0.7221
ru_en Dev loss: 0.4463 r:0.7502
Current avg r:0.6042 Best avg r: 0.6299
09:19:40,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:19:53,883 root INFO 
id:en_zh cur r: 0.5029 best r: 0.5029
09:20:58,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:22:29,343 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1105
en_de Dev loss: 1.1355 r:0.2341
en_zh Dev loss: 0.7435 r:0.4981
ro_en Dev loss: 0.3458 r:0.8147
et_en Dev loss: 0.4806 r:0.6472
si_en Dev loss: 0.8339 r:0.5373
ne_en Dev loss: 0.4836 r:0.7198
ru_en Dev loss: 0.4202 r:0.7468
Current avg r:0.5997 Best avg r: 0.6299
09:26:21,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:27:39,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:29:09,965 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1151
en_de Dev loss: 1.2308 r:0.2341
en_zh Dev loss: 0.8186 r:0.4976
ro_en Dev loss: 0.3896 r:0.8136
et_en Dev loss: 0.5155 r:0.6535
si_en Dev loss: 0.9632 r:0.5345
ne_en Dev loss: 0.5531 r:0.7210
ru_en Dev loss: 0.4733 r:0.7410
Current avg r:0.5994 Best avg r: 0.6299
09:33:02,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:34:19,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:35:50,533 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1049
en_de Dev loss: 1.1926 r:0.2318
en_zh Dev loss: 0.7988 r:0.4889
ro_en Dev loss: 0.3581 r:0.8157
et_en Dev loss: 0.4817 r:0.6573
si_en Dev loss: 0.8954 r:0.5323
ne_en Dev loss: 0.5388 r:0.7138
ru_en Dev loss: 0.4876 r:0.7269
Current avg r:0.5953 Best avg r: 0.6299
09:39:42,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:00,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:42:31,222 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1106
en_de Dev loss: 1.2320 r:0.2327
en_zh Dev loss: 0.8380 r:0.4870
ro_en Dev loss: 0.3831 r:0.8156
et_en Dev loss: 0.4824 r:0.6529
si_en Dev loss: 1.0261 r:0.5250
ne_en Dev loss: 0.6593 r:0.7144
ru_en Dev loss: 0.4793 r:0.7377
Current avg r:0.5950 Best avg r: 0.6299
09:46:23,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:41,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:11,888 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1023
en_de Dev loss: 1.2420 r:0.2300
en_zh Dev loss: 0.8546 r:0.4779
ro_en Dev loss: 0.3861 r:0.8119
et_en Dev loss: 0.5053 r:0.6451
si_en Dev loss: 1.0129 r:0.5252
ne_en Dev loss: 0.6202 r:0.7171
ru_en Dev loss: 0.4625 r:0.7416
Current avg r:0.5927 Best avg r: 0.6299
09:53:03,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:54:21,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:55:52,494 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1108
en_de Dev loss: 1.1579 r:0.2349
en_zh Dev loss: 0.7557 r:0.4913
ro_en Dev loss: 0.3551 r:0.8147
et_en Dev loss: 0.4874 r:0.6558
si_en Dev loss: 0.9242 r:0.5327
ne_en Dev loss: 0.5684 r:0.7162
ru_en Dev loss: 0.4353 r:0.7482
Current avg r:0.5991 Best avg r: 0.6299
09:59:44,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:01:02,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:33,212 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1084
en_de Dev loss: 1.1747 r:0.2245
en_zh Dev loss: 0.7523 r:0.4971
ro_en Dev loss: 0.3344 r:0.8217
et_en Dev loss: 0.4849 r:0.6694
si_en Dev loss: 0.8049 r:0.5488
ne_en Dev loss: 0.4746 r:0.7225
ru_en Dev loss: 0.4271 r:0.7510
Current avg r:0.6050 Best avg r: 0.6299
10:06:25,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:07:43,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:13,895 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1069
en_de Dev loss: 1.1916 r:0.2264
en_zh Dev loss: 0.7780 r:0.4915
ro_en Dev loss: 0.3501 r:0.8191
et_en Dev loss: 0.4772 r:0.6644
si_en Dev loss: 0.8489 r:0.5414
ne_en Dev loss: 0.5301 r:0.7195
ru_en Dev loss: 0.4188 r:0.7530
Current avg r:0.6022 Best avg r: 0.6299
10:13:06,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:23,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:54,570 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1066
en_de Dev loss: 1.2623 r:0.2361
en_zh Dev loss: 0.8544 r:0.4846
ro_en Dev loss: 0.4062 r:0.8127
et_en Dev loss: 0.4986 r:0.6472
si_en Dev loss: 1.0542 r:0.5187
ne_en Dev loss: 0.6263 r:0.7116
ru_en Dev loss: 0.4808 r:0.7450
Current avg r:0.5937 Best avg r: 0.6299
10:19:47,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:04,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:35,875 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1021
en_de Dev loss: 1.1891 r:0.2422
en_zh Dev loss: 0.7766 r:0.4912
ro_en Dev loss: 0.3735 r:0.8158
et_en Dev loss: 0.4861 r:0.6544
si_en Dev loss: 0.9835 r:0.5294
ne_en Dev loss: 0.5721 r:0.7243
ru_en Dev loss: 0.4549 r:0.7522
Current avg r:0.6014 Best avg r: 0.6299
10:26:28,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:46,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:17,121 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1004
en_de Dev loss: 1.1977 r:0.2324
en_zh Dev loss: 0.7971 r:0.4898
ro_en Dev loss: 0.3746 r:0.8143
et_en Dev loss: 0.4826 r:0.6545
si_en Dev loss: 0.9439 r:0.5301
ne_en Dev loss: 0.5453 r:0.7228
ru_en Dev loss: 0.4375 r:0.7506
Current avg r:0.5992 Best avg r: 0.6299
10:33:09,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:34:27,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:35:57,727 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1042
en_de Dev loss: 1.1993 r:0.2310
en_zh Dev loss: 0.7973 r:0.4880
ro_en Dev loss: 0.3707 r:0.8126
et_en Dev loss: 0.4839 r:0.6452
si_en Dev loss: 0.9625 r:0.5316
ne_en Dev loss: 0.6520 r:0.7175
ru_en Dev loss: 0.4770 r:0.7337
Current avg r:0.5942 Best avg r: 0.6299
