14:50:17,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:50:30,111 root INFO 
id:en_zh cur r: 0.1550 best r: 0.1550
14:50:43,79 root INFO 
id:ro_en cur r: 0.3566 best r: 0.3566
14:50:56,74 root INFO 
id:et_en cur r: 0.0220 best r: 0.0220
14:51:09,95 root INFO 
id:si_en cur r: 0.1945 best r: 0.1945
14:51:22,112 root INFO 
id:ne_en cur r: 0.0382 best r: 0.0382
14:51:35,19 root INFO 
id:ru_en cur r: 0.4176 best r: 0.4176
14:51:35,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:05,868 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
14:53:05,874 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:53:05,878 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:53:05,883 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
14:53:05,888 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
14:53:05,893 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:53:05,898 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:53:18,900 root INFO Epoch 0 Global steps: 600 Train loss: 0.9031
en_de Dev loss: 0.8889 r:0.0541
en_zh Dev loss: 0.8301 r:0.1212
ro_en Dev loss: 0.8332 r:0.5031
et_en Dev loss: 0.7474 r:0.3914
si_en Dev loss: 0.8010 r:0.3850
ne_en Dev loss: 0.7620 r:0.5086
ru_en Dev loss: 0.8131 r:0.3873
Current avg r:0.3358 Best avg r: 0.3358
14:57:11,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:24,647 root INFO 
id:en_zh cur r: 0.1929 best r: 0.1929
14:57:37,634 root INFO 
id:ro_en cur r: 0.6287 best r: 0.6287
14:57:50,653 root INFO 
id:et_en cur r: 0.4475 best r: 0.4475
14:58:03,688 root INFO 
id:si_en cur r: 0.3502 best r: 0.3502
14:58:16,721 root INFO 
id:ne_en cur r: 0.5370 best r: 0.5370
14:58:29,642 root INFO 
id:ru_en cur r: 0.5697 best r: 0.5697
14:58:29,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:00,602 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:00:00,609 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:00:00,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:00:00,621 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:00:00,626 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:00:00,632 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:00:00,637 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:00:13,658 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8828
en_de Dev loss: 0.9395 r:0.0814
en_zh Dev loss: 0.7636 r:0.2608
ro_en Dev loss: 0.6958 r:0.6349
et_en Dev loss: 0.5789 r:0.4921
si_en Dev loss: 0.7707 r:0.4419
ne_en Dev loss: 0.6801 r:0.5340
ru_en Dev loss: 0.6354 r:0.5691
Current avg r:0.4306 Best avg r: 0.4306
15:04:06,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:19,536 root INFO 
id:en_zh cur r: 0.2942 best r: 0.2942
15:04:32,532 root INFO 
id:ro_en cur r: 0.6803 best r: 0.6803
15:04:45,552 root INFO 
id:et_en cur r: 0.6293 best r: 0.6293
15:04:58,576 root INFO 
id:si_en cur r: 0.4856 best r: 0.4856
15:05:11,592 root INFO 
id:ne_en cur r: 0.6705 best r: 0.6705
15:05:24,507 root INFO 
id:ru_en cur r: 0.6570 best r: 0.6570
15:05:24,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:55,399 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:06:55,405 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:06:55,410 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:06:55,414 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:06:55,419 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:06:55,424 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:06:55,430 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:07:08,434 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7672
en_de Dev loss: 0.9773 r:0.1183
en_zh Dev loss: 0.7586 r:0.3075
ro_en Dev loss: 0.5189 r:0.6888
et_en Dev loss: 0.4330 r:0.6394
si_en Dev loss: 0.6634 r:0.5064
ne_en Dev loss: 0.4497 r:0.6717
ru_en Dev loss: 0.5072 r:0.6714
Current avg r:0.5148 Best avg r: 0.5148
15:11:01,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:27,110 root INFO 
id:ro_en cur r: 0.6962 best r: 0.6962
15:11:40,124 root INFO 
id:et_en cur r: 0.6574 best r: 0.6574
15:11:53,157 root INFO 
id:si_en cur r: 0.5189 best r: 0.5189
15:12:06,171 root INFO 
id:ne_en cur r: 0.6706 best r: 0.6706
15:12:19,84 root INFO 
id:ru_en cur r: 0.6744 best r: 0.6744
15:12:19,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:50,28 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:13:50,35 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:13:50,39 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:13:50,44 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:13:50,49 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:13:50,53 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:13:50,58 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:14:03,73 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6863
en_de Dev loss: 1.0968 r:0.1216
en_zh Dev loss: 0.8354 r:0.2945
ro_en Dev loss: 0.5153 r:0.7037
et_en Dev loss: 0.4282 r:0.6587
si_en Dev loss: 0.8049 r:0.5207
ne_en Dev loss: 0.5598 r:0.6651
ru_en Dev loss: 0.5296 r:0.6847
Current avg r:0.5213 Best avg r: 0.5213
15:17:55,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:21,709 root INFO 
id:ro_en cur r: 0.7205 best r: 0.7205
15:18:34,719 root INFO 
id:et_en cur r: 0.6786 best r: 0.6786
15:18:47,762 root INFO 
id:si_en cur r: 0.5439 best r: 0.5439
15:19:00,796 root INFO 
id:ne_en cur r: 0.6844 best r: 0.6844
15:19:13,720 root INFO 
id:ru_en cur r: 0.6988 best r: 0.6988
15:19:13,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:44,686 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:20:44,693 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:20:44,697 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:20:44,702 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:20:44,707 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:20:44,711 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:20:44,718 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:20:57,737 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6244
en_de Dev loss: 1.0282 r:0.1224
en_zh Dev loss: 0.7841 r:0.2903
ro_en Dev loss: 0.4255 r:0.7239
et_en Dev loss: 0.3831 r:0.6789
si_en Dev loss: 0.6348 r:0.5565
ne_en Dev loss: 0.4285 r:0.6875
ru_en Dev loss: 0.4533 r:0.7124
Current avg r:0.5388 Best avg r: 0.5388
15:24:50,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:03,638 root INFO 
id:en_zh cur r: 0.3267 best r: 0.3267
15:25:16,640 root INFO 
id:ro_en cur r: 0.7447 best r: 0.7447
15:25:29,669 root INFO 
id:et_en cur r: 0.7000 best r: 0.7000
15:25:42,725 root INFO 
id:si_en cur r: 0.5751 best r: 0.5751
15:25:55,785 root INFO 
id:ne_en cur r: 0.7202 best r: 0.7202
15:26:08,710 root INFO 
id:ru_en cur r: 0.7195 best r: 0.7195
15:26:08,711 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:39,758 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:27:39,764 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:27:39,771 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:27:39,776 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:27:39,781 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:27:39,785 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:27:39,792 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:27:52,823 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6320
en_de Dev loss: 1.0329 r:0.1338
en_zh Dev loss: 0.7665 r:0.3279
ro_en Dev loss: 0.3920 r:0.7492
et_en Dev loss: 0.3618 r:0.6989
si_en Dev loss: 0.6078 r:0.5797
ne_en Dev loss: 0.4097 r:0.7155
ru_en Dev loss: 0.4123 r:0.7288
Current avg r:0.5620 Best avg r: 0.5620
15:31:45,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:58,649 root INFO 
id:en_zh cur r: 0.3528 best r: 0.3528
15:32:11,647 root INFO 
id:ro_en cur r: 0.7641 best r: 0.7641
15:32:24,674 root INFO 
id:et_en cur r: 0.7043 best r: 0.7043
15:32:50,744 root INFO 
id:ne_en cur r: 0.7300 best r: 0.7300
15:33:03,667 root INFO 
id:ru_en cur r: 0.7240 best r: 0.7240
15:33:03,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:34,708 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:34:34,715 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:34:34,720 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:34:34,724 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:34:34,729 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:34:34,734 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:34:34,739 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:34:47,771 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5957
en_de Dev loss: 1.0791 r:0.1327
en_zh Dev loss: 0.7641 r:0.3479
ro_en Dev loss: 0.3821 r:0.7652
et_en Dev loss: 0.3630 r:0.6992
si_en Dev loss: 0.6605 r:0.5793
ne_en Dev loss: 0.4337 r:0.7262
ru_en Dev loss: 0.4099 r:0.7355
Current avg r:0.5694 Best avg r: 0.5694
15:38:40,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:53,696 root INFO 
id:en_zh cur r: 0.4022 best r: 0.4022
15:39:06,707 root INFO 
id:ro_en cur r: 0.7741 best r: 0.7741
15:39:19,724 root INFO 
id:et_en cur r: 0.7079 best r: 0.7079
15:39:32,765 root INFO 
id:si_en cur r: 0.6033 best r: 0.6033
15:39:45,800 root INFO 
id:ne_en cur r: 0.7399 best r: 0.7399
15:39:58,749 root INFO 
id:ru_en cur r: 0.7360 best r: 0.7360
15:39:58,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:29,721 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:41:29,727 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:41:29,731 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:41:29,739 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:41:29,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:41:29,749 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:41:29,754 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:41:42,788 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5919
en_de Dev loss: 1.0023 r:0.1587
en_zh Dev loss: 0.6958 r:0.3981
ro_en Dev loss: 0.3515 r:0.7716
et_en Dev loss: 0.3653 r:0.7057
si_en Dev loss: 0.5215 r:0.6096
ne_en Dev loss: 0.3554 r:0.7443
ru_en Dev loss: 0.3837 r:0.7376
Current avg r:0.5894 Best avg r: 0.5894
15:45:35,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:01,823 root INFO 
id:ro_en cur r: 0.7760 best r: 0.7760
15:46:14,855 root INFO 
id:et_en cur r: 0.7123 best r: 0.7123
15:46:40,925 root INFO 
id:ne_en cur r: 0.7434 best r: 0.7434
15:46:53,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:24,885 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5643
en_de Dev loss: 0.9988 r:0.1591
en_zh Dev loss: 0.7080 r:0.3937
ro_en Dev loss: 0.3543 r:0.7774
et_en Dev loss: 0.3512 r:0.7128
si_en Dev loss: 0.5690 r:0.5948
ne_en Dev loss: 0.3746 r:0.7388
ru_en Dev loss: 0.4101 r:0.7358
Current avg r:0.5875 Best avg r: 0.5894
15:52:18,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:30,972 root INFO 
id:en_zh cur r: 0.4281 best r: 0.4281
15:52:43,979 root INFO 
id:ro_en cur r: 0.7901 best r: 0.7901
15:52:57,2 root INFO 
id:et_en cur r: 0.7167 best r: 0.7167
15:53:23,70 root INFO 
id:ne_en cur r: 0.7448 best r: 0.7448
15:53:35,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:07,19 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:55:07,25 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:55:07,29 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:55:07,34 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:55:07,39 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:55:07,45 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:55:07,50 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:55:20,76 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5506
en_de Dev loss: 1.0639 r:0.1735
en_zh Dev loss: 0.7130 r:0.4207
ro_en Dev loss: 0.3682 r:0.7875
et_en Dev loss: 0.3515 r:0.7139
si_en Dev loss: 0.6963 r:0.5966
ne_en Dev loss: 0.4367 r:0.7417
ru_en Dev loss: 0.5090 r:0.7210
Current avg r:0.5936 Best avg r: 0.5936
15:59:13,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:26,11 root INFO 
id:en_zh cur r: 0.4361 best r: 0.4361
15:59:39,11 root INFO 
id:ro_en cur r: 0.8044 best r: 0.8044
15:59:52,28 root INFO 
id:et_en cur r: 0.7214 best r: 0.7214
16:00:05,67 root INFO 
id:si_en cur r: 0.6118 best r: 0.6118
16:00:18,92 root INFO 
id:ne_en cur r: 0.7572 best r: 0.7572
16:00:31,21 root INFO 
id:ru_en cur r: 0.7431 best r: 0.7431
16:00:31,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:01,982 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
16:02:01,987 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:02:01,992 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:02:01,996 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
16:02:02,1 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
16:02:02,5 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:02:02,10 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:02:15,37 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5466
en_de Dev loss: 1.0202 r:0.1803
en_zh Dev loss: 0.6814 r:0.4274
ro_en Dev loss: 0.3129 r:0.8000
et_en Dev loss: 0.3499 r:0.7203
si_en Dev loss: 0.5640 r:0.6105
ne_en Dev loss: 0.3385 r:0.7575
ru_en Dev loss: 0.3977 r:0.7409
Current avg r:0.6053 Best avg r: 0.6053
16:06:08,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:21,8 root INFO 
id:en_zh cur r: 0.4381 best r: 0.4381
16:06:34,11 root INFO 
id:ro_en cur r: 0.8145 best r: 0.8145
16:06:47,48 root INFO 
id:et_en cur r: 0.7253 best r: 0.7253
16:07:13,101 root INFO 
id:ne_en cur r: 0.7579 best r: 0.7579
16:07:26,24 root INFO 
id:ru_en cur r: 0.7490 best r: 0.7490
16:07:26,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:56,999 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
16:08:57,6 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:08:57,11 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:08:57,16 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
16:08:57,20 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
16:08:57,25 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:08:57,30 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:09:10,56 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5234
en_de Dev loss: 1.1088 r:0.1778
en_zh Dev loss: 0.7091 r:0.4326
ro_en Dev loss: 0.3387 r:0.8080
et_en Dev loss: 0.3497 r:0.7200
si_en Dev loss: 0.6351 r:0.6040
ne_en Dev loss: 0.3577 r:0.7555
ru_en Dev loss: 0.4247 r:0.7528
Current avg r:0.6072 Best avg r: 0.6072
16:13:03,77 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:20,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:51,899 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5242
en_de Dev loss: 1.1328 r:0.1717
en_zh Dev loss: 0.7487 r:0.4161
ro_en Dev loss: 0.3458 r:0.8058
et_en Dev loss: 0.3586 r:0.7143
si_en Dev loss: 0.7054 r:0.5962
ne_en Dev loss: 0.4042 r:0.7554
ru_en Dev loss: 0.4667 r:0.7388
Current avg r:0.5997 Best avg r: 0.6072
16:19:44,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:57,592 root INFO 
id:en_zh cur r: 0.4439 best r: 0.4439
16:20:49,650 root INFO 
id:ne_en cur r: 0.7611 best r: 0.7611
16:21:02,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:33,587 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5015
en_de Dev loss: 1.0309 r:0.1748
en_zh Dev loss: 0.6801 r:0.4363
ro_en Dev loss: 0.3146 r:0.8051
et_en Dev loss: 0.3537 r:0.7178
si_en Dev loss: 0.5836 r:0.6078
ne_en Dev loss: 0.3574 r:0.7600
ru_en Dev loss: 0.3960 r:0.7425
Current avg r:0.6063 Best avg r: 0.6072
16:26:26,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:52,548 root INFO 
id:ro_en cur r: 0.8167 best r: 0.8167
16:27:44,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:15,508 root INFO Epoch 0 Global steps: 9000 Train loss: 0.4862
en_de Dev loss: 1.1454 r:0.1835
en_zh Dev loss: 0.8012 r:0.4136
ro_en Dev loss: 0.3388 r:0.8083
et_en Dev loss: 0.3616 r:0.7092
si_en Dev loss: 0.6484 r:0.6017
ne_en Dev loss: 0.4363 r:0.7555
ru_en Dev loss: 0.5481 r:0.6903
Current avg r:0.5946 Best avg r: 0.6072
16:33:09,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:14,740 root INFO 
id:ne_en cur r: 0.7642 best r: 0.7642
16:34:27,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:58,685 root INFO Epoch 1 Global steps: 9600 Train loss: 0.4926
en_de Dev loss: 1.1103 r:0.1777
en_zh Dev loss: 0.7531 r:0.4272
ro_en Dev loss: 0.3225 r:0.8106
et_en Dev loss: 0.3528 r:0.7135
si_en Dev loss: 0.6480 r:0.6062
ne_en Dev loss: 0.4268 r:0.7633
ru_en Dev loss: 0.4793 r:0.7156
Current avg r:0.6020 Best avg r: 0.6072
16:39:51,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:09,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:40,913 root INFO Epoch 1 Global steps: 10200 Train loss: 0.4966
en_de Dev loss: 1.1799 r:0.1803
en_zh Dev loss: 0.8175 r:0.4118
ro_en Dev loss: 0.4315 r:0.8004
et_en Dev loss: 0.4168 r:0.6956
si_en Dev loss: 0.9079 r:0.5785
ne_en Dev loss: 0.5914 r:0.7510
ru_en Dev loss: 0.6209 r:0.6902
Current avg r:0.5868 Best avg r: 0.6072
16:46:34,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:46,996 root INFO 
id:en_zh cur r: 0.4478 best r: 0.4478
16:46:59,995 root INFO 
id:ro_en cur r: 0.8171 best r: 0.8171
16:47:39,89 root INFO 
id:ne_en cur r: 0.7660 best r: 0.7660
16:47:52,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:23,23 root INFO Epoch 1 Global steps: 10800 Train loss: 0.4927
en_de Dev loss: 1.1228 r:0.1979
en_zh Dev loss: 0.7307 r:0.4356
ro_en Dev loss: 0.3633 r:0.8119
et_en Dev loss: 0.3666 r:0.7119
si_en Dev loss: 0.6999 r:0.6070
ne_en Dev loss: 0.3860 r:0.7660
ru_en Dev loss: 0.4808 r:0.7171
Current avg r:0.6068 Best avg r: 0.6072
16:53:16,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:34,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:05,155 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4871
en_de Dev loss: 1.1720 r:0.1769
en_zh Dev loss: 0.7580 r:0.4196
ro_en Dev loss: 0.3606 r:0.8097
et_en Dev loss: 0.3637 r:0.7121
si_en Dev loss: 0.7785 r:0.5971
ne_en Dev loss: 0.4804 r:0.7535
ru_en Dev loss: 0.4925 r:0.7079
Current avg r:0.5967 Best avg r: 0.6072
16:59:58,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:50,405 root INFO 
id:si_en cur r: 0.6120 best r: 0.6120
17:01:16,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:47,17 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4653
en_de Dev loss: 1.2769 r:0.1886
en_zh Dev loss: 0.7838 r:0.4313
ro_en Dev loss: 0.4255 r:0.8130
et_en Dev loss: 0.3831 r:0.7134
si_en Dev loss: 0.7999 r:0.6065
ne_en Dev loss: 0.5152 r:0.7600
ru_en Dev loss: 0.5439 r:0.7007
Current avg r:0.6019 Best avg r: 0.6072
17:06:37,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:50,760 root INFO 
id:en_zh cur r: 0.4564 best r: 0.4564
17:07:03,645 root INFO 
id:ro_en cur r: 0.8297 best r: 0.8297
17:07:16,553 root INFO 
id:et_en cur r: 0.7350 best r: 0.7350
17:07:29,473 root INFO 
id:si_en cur r: 0.6244 best r: 0.6244
17:07:42,388 root INFO 
id:ne_en cur r: 0.7766 best r: 0.7766
17:07:55,171 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:25,280 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
17:09:25,287 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:09:25,294 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:09:25,299 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
17:09:25,303 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
17:09:25,309 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:09:25,314 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:09:38,209 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4828
en_de Dev loss: 1.0655 r:0.1966
en_zh Dev loss: 0.6887 r:0.4457
ro_en Dev loss: 0.2900 r:0.8232
et_en Dev loss: 0.3341 r:0.7312
si_en Dev loss: 0.5862 r:0.6195
ne_en Dev loss: 0.3295 r:0.7753
ru_en Dev loss: 0.4123 r:0.7386
Current avg r:0.6186 Best avg r: 0.6186
17:13:28,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:46,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:16,93 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4551
en_de Dev loss: 1.0853 r:0.1928
en_zh Dev loss: 0.7035 r:0.4436
ro_en Dev loss: 0.3264 r:0.8140
et_en Dev loss: 0.3467 r:0.7189
si_en Dev loss: 0.7385 r:0.6009
ne_en Dev loss: 0.5005 r:0.7558
ru_en Dev loss: 0.4703 r:0.7205
Current avg r:0.6066 Best avg r: 0.6186
17:20:06,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:58,210 root INFO 
id:si_en cur r: 0.6244 best r: 0.6244
17:21:23,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:53,909 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4697
en_de Dev loss: 1.1626 r:0.1927
en_zh Dev loss: 0.7661 r:0.4427
ro_en Dev loss: 0.3213 r:0.8223
et_en Dev loss: 0.3497 r:0.7242
si_en Dev loss: 0.7695 r:0.6171
ne_en Dev loss: 0.4252 r:0.7642
ru_en Dev loss: 0.4410 r:0.7416
Current avg r:0.6150 Best avg r: 0.6186
17:26:44,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:01,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:31,715 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4661
en_de Dev loss: 1.0914 r:0.1953
en_zh Dev loss: 0.7245 r:0.4340
ro_en Dev loss: 0.3290 r:0.8113
et_en Dev loss: 0.3592 r:0.7100
si_en Dev loss: 0.7318 r:0.5959
ne_en Dev loss: 0.4692 r:0.7520
ru_en Dev loss: 0.4576 r:0.7233
Current avg r:0.6031 Best avg r: 0.6186
17:33:22,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:35,188 root INFO 
id:en_zh cur r: 0.4576 best r: 0.4576
17:34:39,479 root INFO 
id:ru_en cur r: 0.7530 best r: 0.7530
17:34:39,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:09,471 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
17:36:09,478 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:36:09,484 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:36:09,489 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
17:36:09,494 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
17:36:09,499 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:36:09,503 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:36:22,397 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4694
en_de Dev loss: 1.1391 r:0.1949
en_zh Dev loss: 0.7302 r:0.4527
ro_en Dev loss: 0.3243 r:0.8276
et_en Dev loss: 0.3430 r:0.7305
si_en Dev loss: 0.7001 r:0.6136
ne_en Dev loss: 0.3655 r:0.7728
ru_en Dev loss: 0.4129 r:0.7571
Current avg r:0.6213 Best avg r: 0.6213
17:40:13,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:25,913 root INFO 
id:en_zh cur r: 0.4601 best r: 0.4601
17:41:30,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:00,237 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4458
en_de Dev loss: 1.0868 r:0.1881
en_zh Dev loss: 0.6852 r:0.4546
ro_en Dev loss: 0.3074 r:0.8207
et_en Dev loss: 0.3479 r:0.7210
si_en Dev loss: 0.6024 r:0.6139
ne_en Dev loss: 0.4095 r:0.7660
ru_en Dev loss: 0.4108 r:0.7426
Current avg r:0.6153 Best avg r: 0.6213
17:46:50,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:03,681 root INFO 
id:en_zh cur r: 0.4789 best r: 0.4789
17:48:07,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:38,10 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4560
en_de Dev loss: 1.0671 r:0.1932
en_zh Dev loss: 0.6663 r:0.4714
ro_en Dev loss: 0.3101 r:0.8236
et_en Dev loss: 0.3412 r:0.7223
si_en Dev loss: 0.6547 r:0.6118
ne_en Dev loss: 0.4256 r:0.7695
ru_en Dev loss: 0.3972 r:0.7507
Current avg r:0.6204 Best avg r: 0.6213
17:53:28,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:54,294 root INFO 
id:ro_en cur r: 0.8304 best r: 0.8304
17:54:20,86 root INFO 
id:si_en cur r: 0.6254 best r: 0.6254
17:54:45,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:15,774 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4500
en_de Dev loss: 1.1314 r:0.1883
en_zh Dev loss: 0.6893 r:0.4677
ro_en Dev loss: 0.3152 r:0.8235
et_en Dev loss: 0.3667 r:0.7223
si_en Dev loss: 0.6235 r:0.6216
ne_en Dev loss: 0.3658 r:0.7669
ru_en Dev loss: 0.4349 r:0.7360
Current avg r:0.6180 Best avg r: 0.6213
18:00:06,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:23,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:53,499 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4502
en_de Dev loss: 1.1257 r:0.1897
en_zh Dev loss: 0.6958 r:0.4603
ro_en Dev loss: 0.3147 r:0.8207
et_en Dev loss: 0.3507 r:0.7198
si_en Dev loss: 0.6728 r:0.6166
ne_en Dev loss: 0.4113 r:0.7726
ru_en Dev loss: 0.4451 r:0.7350
Current avg r:0.6164 Best avg r: 0.6213
18:06:44,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:01,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:31,222 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4392
en_de Dev loss: 1.1699 r:0.1897
en_zh Dev loss: 0.7218 r:0.4594
ro_en Dev loss: 0.3328 r:0.8189
et_en Dev loss: 0.3619 r:0.7147
si_en Dev loss: 0.7385 r:0.6029
ne_en Dev loss: 0.4120 r:0.7721
ru_en Dev loss: 0.5000 r:0.7064
Current avg r:0.6092 Best avg r: 0.6213
18:13:23,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:40,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:10,567 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4287
en_de Dev loss: 1.2686 r:0.1935
en_zh Dev loss: 0.8353 r:0.4399
ro_en Dev loss: 0.3898 r:0.8202
et_en Dev loss: 0.3699 r:0.7131
si_en Dev loss: 0.8474 r:0.6025
ne_en Dev loss: 0.5041 r:0.7671
ru_en Dev loss: 0.5483 r:0.7129
Current avg r:0.6070 Best avg r: 0.6213
18:20:01,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:18,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:48,455 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4083
en_de Dev loss: 1.1948 r:0.1821
en_zh Dev loss: 0.7461 r:0.4591
ro_en Dev loss: 0.3630 r:0.8136
et_en Dev loss: 0.3788 r:0.7119
si_en Dev loss: 0.6977 r:0.6137
ne_en Dev loss: 0.3976 r:0.7634
ru_en Dev loss: 0.4928 r:0.7206
Current avg r:0.6092 Best avg r: 0.6213
18:26:39,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:56,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:26,213 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4158
en_de Dev loss: 1.1200 r:0.1949
en_zh Dev loss: 0.7140 r:0.4593
ro_en Dev loss: 0.3188 r:0.8152
et_en Dev loss: 0.3635 r:0.7114
si_en Dev loss: 0.7084 r:0.6035
ne_en Dev loss: 0.4219 r:0.7629
ru_en Dev loss: 0.4422 r:0.7234
Current avg r:0.6101 Best avg r: 0.6213
18:33:16,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:33,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:04,50 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4052
en_de Dev loss: 1.1621 r:0.1977
en_zh Dev loss: 0.7263 r:0.4660
ro_en Dev loss: 0.3347 r:0.8200
et_en Dev loss: 0.3701 r:0.7165
si_en Dev loss: 0.7057 r:0.6184
ne_en Dev loss: 0.4264 r:0.7679
ru_en Dev loss: 0.4492 r:0.7321
Current avg r:0.6169 Best avg r: 0.6213
18:39:54,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:11,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:41,966 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4120
en_de Dev loss: 1.1982 r:0.1947
en_zh Dev loss: 0.7437 r:0.4592
ro_en Dev loss: 0.3552 r:0.8143
et_en Dev loss: 0.3818 r:0.7075
si_en Dev loss: 0.7786 r:0.6038
ne_en Dev loss: 0.5194 r:0.7578
ru_en Dev loss: 0.4823 r:0.7279
Current avg r:0.6093 Best avg r: 0.6213
18:46:32,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:45,523 root INFO 
id:en_zh cur r: 0.4861 best r: 0.4861
18:47:49,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:19,863 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
18:49:19,868 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
18:49:19,873 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
18:49:19,878 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
18:49:19,884 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
18:49:19,889 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
18:49:19,893 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
18:49:32,777 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4059
en_de Dev loss: 1.0594 r:0.2070
en_zh Dev loss: 0.6654 r:0.4795
ro_en Dev loss: 0.3115 r:0.8209
et_en Dev loss: 0.3717 r:0.7179
si_en Dev loss: 0.6450 r:0.6190
ne_en Dev loss: 0.4135 r:0.7684
ru_en Dev loss: 0.4022 r:0.7471
Current avg r:0.6228 Best avg r: 0.6228
18:53:23,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:53:49,138 root INFO 
id:ro_en cur r: 0.8306 best r: 0.8306
18:54:40,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:56:10,663 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4041
en_de Dev loss: 1.0612 r:0.2012
en_zh Dev loss: 0.6772 r:0.4688
ro_en Dev loss: 0.2859 r:0.8266
et_en Dev loss: 0.3655 r:0.7141
si_en Dev loss: 0.6063 r:0.6167
ne_en Dev loss: 0.4087 r:0.7600
ru_en Dev loss: 0.3821 r:0.7518
Current avg r:0.6199 Best avg r: 0.6228
19:00:01,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:18,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:48,632 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4065
en_de Dev loss: 1.0721 r:0.2036
en_zh Dev loss: 0.6953 r:0.4569
ro_en Dev loss: 0.3004 r:0.8253
et_en Dev loss: 0.3707 r:0.7206
si_en Dev loss: 0.5706 r:0.6201
ne_en Dev loss: 0.3763 r:0.7633
ru_en Dev loss: 0.4226 r:0.7342
Current avg r:0.6177 Best avg r: 0.6228
19:06:39,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:52,121 root INFO 
id:en_zh cur r: 0.4886 best r: 0.4886
19:07:04,993 root INFO 
id:ro_en cur r: 0.8313 best r: 0.8313
19:07:56,491 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:26,542 root INFO Epoch 2 Global steps: 23400 Train loss: 0.3910
en_de Dev loss: 1.0575 r:0.1943
en_zh Dev loss: 0.6548 r:0.4806
ro_en Dev loss: 0.2888 r:0.8271
et_en Dev loss: 0.3626 r:0.7143
si_en Dev loss: 0.6611 r:0.6154
ne_en Dev loss: 0.4374 r:0.7624
ru_en Dev loss: 0.4010 r:0.7446
Current avg r:0.6198 Best avg r: 0.6228
19:13:17,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:08,720 root INFO 
id:si_en cur r: 0.6303 best r: 0.6303
19:14:34,420 root INFO 
id:ru_en cur r: 0.7626 best r: 0.7626
19:14:34,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:04,474 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
19:16:04,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
19:16:04,485 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
19:16:04,490 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
19:16:04,494 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
19:16:04,500 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
19:16:04,506 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
19:16:17,443 root INFO Epoch 2 Global steps: 24000 Train loss: 0.3956
en_de Dev loss: 1.0804 r:0.1877
en_zh Dev loss: 0.6665 r:0.4805
ro_en Dev loss: 0.2910 r:0.8269
et_en Dev loss: 0.3808 r:0.7191
si_en Dev loss: 0.6088 r:0.6213
ne_en Dev loss: 0.3458 r:0.7662
ru_en Dev loss: 0.3687 r:0.7583
Current avg r:0.6228 Best avg r: 0.6228
19:20:08,120 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:25,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:55,344 root INFO Epoch 2 Global steps: 24600 Train loss: 0.3824
en_de Dev loss: 1.1371 r:0.1857
en_zh Dev loss: 0.7018 r:0.4701
ro_en Dev loss: 0.3220 r:0.8236
et_en Dev loss: 0.3705 r:0.7148
si_en Dev loss: 0.7117 r:0.6057
ne_en Dev loss: 0.3945 r:0.7665
ru_en Dev loss: 0.4373 r:0.7377
Current avg r:0.6149 Best avg r: 0.6228
19:26:46,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:03,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:33,324 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3962
en_de Dev loss: 1.1077 r:0.1861
en_zh Dev loss: 0.6801 r:0.4701
ro_en Dev loss: 0.3103 r:0.8222
et_en Dev loss: 0.3589 r:0.7212
si_en Dev loss: 0.6823 r:0.6133
ne_en Dev loss: 0.4018 r:0.7684
ru_en Dev loss: 0.3938 r:0.7539
Current avg r:0.6193 Best avg r: 0.6228
19:33:23,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:41,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:11,98 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4095
en_de Dev loss: 1.1164 r:0.1871
en_zh Dev loss: 0.6888 r:0.4690
ro_en Dev loss: 0.3029 r:0.8239
et_en Dev loss: 0.3665 r:0.7138
si_en Dev loss: 0.6752 r:0.6086
ne_en Dev loss: 0.4041 r:0.7641
ru_en Dev loss: 0.4482 r:0.7275
Current avg r:0.6134 Best avg r: 0.6228
19:40:01,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:18,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:49,28 root INFO Epoch 2 Global steps: 26400 Train loss: 0.3816
en_de Dev loss: 1.1543 r:0.1846
en_zh Dev loss: 0.7009 r:0.4686
ro_en Dev loss: 0.3176 r:0.8210
et_en Dev loss: 0.3647 r:0.7116
si_en Dev loss: 0.6947 r:0.6125
ne_en Dev loss: 0.4510 r:0.7684
ru_en Dev loss: 0.4421 r:0.7361
Current avg r:0.6147 Best avg r: 0.6228
19:46:39,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:56,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:26,928 root INFO Epoch 2 Global steps: 27000 Train loss: 0.3660
en_de Dev loss: 1.1446 r:0.2043
en_zh Dev loss: 0.7336 r:0.4608
ro_en Dev loss: 0.3488 r:0.8126
et_en Dev loss: 0.3866 r:0.7000
si_en Dev loss: 0.7479 r:0.5948
ne_en Dev loss: 0.4763 r:0.7641
ru_en Dev loss: 0.4845 r:0.7180
Current avg r:0.6078 Best avg r: 0.6228
19:53:18,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:35,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:05,932 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3551
en_de Dev loss: 1.1379 r:0.1919
en_zh Dev loss: 0.7037 r:0.4740
ro_en Dev loss: 0.3265 r:0.8192
et_en Dev loss: 0.3752 r:0.7061
si_en Dev loss: 0.6966 r:0.6031
ne_en Dev loss: 0.4938 r:0.7604
ru_en Dev loss: 0.4470 r:0.7287
Current avg r:0.6119 Best avg r: 0.6228
19:59:56,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:09,454 root INFO 
id:en_zh cur r: 0.4975 best r: 0.4975
20:01:13,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:43,784 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
20:02:43,791 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
20:02:43,795 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
20:02:43,799 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
20:02:43,807 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
20:02:43,812 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
20:02:43,816 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
20:02:56,716 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3529
en_de Dev loss: 1.1170 r:0.2049
en_zh Dev loss: 0.6783 r:0.4890
ro_en Dev loss: 0.3011 r:0.8255
et_en Dev loss: 0.4061 r:0.7192
si_en Dev loss: 0.6288 r:0.6157
ne_en Dev loss: 0.3519 r:0.7625
ru_en Dev loss: 0.3903 r:0.7513
Current avg r:0.6240 Best avg r: 0.6240
20:06:47,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:04,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:34,457 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3638
en_de Dev loss: 1.1895 r:0.1944
en_zh Dev loss: 0.7672 r:0.4541
ro_en Dev loss: 0.3355 r:0.8196
et_en Dev loss: 0.3689 r:0.7048
si_en Dev loss: 0.7519 r:0.5936
ne_en Dev loss: 0.5347 r:0.7515
ru_en Dev loss: 0.5649 r:0.6925
Current avg r:0.6015 Best avg r: 0.6240
20:13:24,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:42,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:12,71 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3350
en_de Dev loss: 1.1739 r:0.1926
en_zh Dev loss: 0.7174 r:0.4739
ro_en Dev loss: 0.3299 r:0.8250
et_en Dev loss: 0.4258 r:0.7153
si_en Dev loss: 0.6203 r:0.6128
ne_en Dev loss: 0.3902 r:0.7602
ru_en Dev loss: 0.4380 r:0.7339
Current avg r:0.6162 Best avg r: 0.6240
20:20:02,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:19,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:49,686 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3344
en_de Dev loss: 1.1613 r:0.1942
en_zh Dev loss: 0.7166 r:0.4705
ro_en Dev loss: 0.3193 r:0.8238
et_en Dev loss: 0.3987 r:0.7105
si_en Dev loss: 0.6509 r:0.6051
ne_en Dev loss: 0.3935 r:0.7606
ru_en Dev loss: 0.4224 r:0.7407
Current avg r:0.6151 Best avg r: 0.6240
20:26:40,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:57,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:27,278 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3486
en_de Dev loss: 1.1521 r:0.1993
en_zh Dev loss: 0.7463 r:0.4486
ro_en Dev loss: 0.3140 r:0.8238
et_en Dev loss: 0.3829 r:0.7035
si_en Dev loss: 0.7415 r:0.5983
ne_en Dev loss: 0.4769 r:0.7640
ru_en Dev loss: 0.4327 r:0.7305
Current avg r:0.6097 Best avg r: 0.6240
20:33:17,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:34,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:04,869 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3398
en_de Dev loss: 1.1348 r:0.1922
en_zh Dev loss: 0.7042 r:0.4692
ro_en Dev loss: 0.3159 r:0.8259
et_en Dev loss: 0.4064 r:0.7103
si_en Dev loss: 0.6657 r:0.6074
ne_en Dev loss: 0.3874 r:0.7634
ru_en Dev loss: 0.4042 r:0.7426
Current avg r:0.6159 Best avg r: 0.6240
20:39:55,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:12,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:42,538 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3328
en_de Dev loss: 1.1011 r:0.2013
en_zh Dev loss: 0.7043 r:0.4650
ro_en Dev loss: 0.3124 r:0.8214
et_en Dev loss: 0.3871 r:0.7046
si_en Dev loss: 0.6315 r:0.6050
ne_en Dev loss: 0.4052 r:0.7584
ru_en Dev loss: 0.4541 r:0.7191
Current avg r:0.6107 Best avg r: 0.6240
20:46:33,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:50,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:20,63 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3416
en_de Dev loss: 1.0966 r:0.1932
en_zh Dev loss: 0.6959 r:0.4690
ro_en Dev loss: 0.3065 r:0.8230
et_en Dev loss: 0.3894 r:0.7060
si_en Dev loss: 0.6723 r:0.6041
ne_en Dev loss: 0.3926 r:0.7610
ru_en Dev loss: 0.4161 r:0.7341
Current avg r:0.6129 Best avg r: 0.6240
20:53:10,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:27,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:57,639 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3283
en_de Dev loss: 1.2123 r:0.1858
en_zh Dev loss: 0.7854 r:0.4598
ro_en Dev loss: 0.3586 r:0.8159
et_en Dev loss: 0.4053 r:0.6903
si_en Dev loss: 0.7940 r:0.5913
ne_en Dev loss: 0.4371 r:0.7515
ru_en Dev loss: 0.4740 r:0.7237
Current avg r:0.6026 Best avg r: 0.6240
20:59:48,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:13,967 root INFO 
id:ro_en cur r: 0.8325 best r: 0.8325
21:01:05,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:35,607 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3162
en_de Dev loss: 1.1424 r:0.2016
en_zh Dev loss: 0.7222 r:0.4766
ro_en Dev loss: 0.2953 r:0.8285
et_en Dev loss: 0.3819 r:0.7106
si_en Dev loss: 0.6479 r:0.6132
ne_en Dev loss: 0.3708 r:0.7605
ru_en Dev loss: 0.4145 r:0.7524
Current avg r:0.6205 Best avg r: 0.6240
21:06:26,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:43,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:13,447 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3348
en_de Dev loss: 1.0539 r:0.1935
en_zh Dev loss: 0.6670 r:0.4756
ro_en Dev loss: 0.2820 r:0.8275
et_en Dev loss: 0.3934 r:0.7044
si_en Dev loss: 0.6443 r:0.6059
ne_en Dev loss: 0.4492 r:0.7562
ru_en Dev loss: 0.3618 r:0.7596
Current avg r:0.6175 Best avg r: 0.6240
21:13:04,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:21,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:51,336 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3372
en_de Dev loss: 1.1670 r:0.1850
en_zh Dev loss: 0.7271 r:0.4663
ro_en Dev loss: 0.3046 r:0.8277
et_en Dev loss: 0.4136 r:0.7035
si_en Dev loss: 0.6016 r:0.6180
ne_en Dev loss: 0.3957 r:0.7481
ru_en Dev loss: 0.3887 r:0.7571
Current avg r:0.6151 Best avg r: 0.6240
21:19:41,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:58,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:28,862 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3297
en_de Dev loss: 1.1580 r:0.1851
en_zh Dev loss: 0.7336 r:0.4624
ro_en Dev loss: 0.3222 r:0.8215
et_en Dev loss: 0.4021 r:0.6982
si_en Dev loss: 0.7225 r:0.5986
ne_en Dev loss: 0.4142 r:0.7569
ru_en Dev loss: 0.4078 r:0.7474
Current avg r:0.6100 Best avg r: 0.6240
21:26:19,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:36,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:06,444 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3177
en_de Dev loss: 1.2119 r:0.1795
en_zh Dev loss: 0.7551 r:0.4644
ro_en Dev loss: 0.3582 r:0.8154
et_en Dev loss: 0.4288 r:0.6789
si_en Dev loss: 0.8821 r:0.5771
ne_en Dev loss: 0.5929 r:0.7504
ru_en Dev loss: 0.5861 r:0.6777
Current avg r:0.5919 Best avg r: 0.6240
21:32:58,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:15,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:45,173 root INFO Epoch 4 Global steps: 36600 Train loss: 0.2846
en_de Dev loss: 1.1557 r:0.1940
en_zh Dev loss: 0.7210 r:0.4709
ro_en Dev loss: 0.3213 r:0.8207
et_en Dev loss: 0.4035 r:0.6887
si_en Dev loss: 0.7450 r:0.5906
ne_en Dev loss: 0.4780 r:0.7520
ru_en Dev loss: 0.4654 r:0.7187
Current avg r:0.6051 Best avg r: 0.6240
21:39:35,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:52,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:22,639 root INFO Epoch 4 Global steps: 37200 Train loss: 0.2869
en_de Dev loss: 1.1458 r:0.1839
en_zh Dev loss: 0.7102 r:0.4741
ro_en Dev loss: 0.3018 r:0.8249
et_en Dev loss: 0.4068 r:0.6981
si_en Dev loss: 0.7043 r:0.5990
ne_en Dev loss: 0.3943 r:0.7528
ru_en Dev loss: 0.4455 r:0.7257
Current avg r:0.6083 Best avg r: 0.6240
21:46:13,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:30,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:00,110 root INFO Epoch 4 Global steps: 37800 Train loss: 0.2845
en_de Dev loss: 1.2241 r:0.1873
en_zh Dev loss: 0.7819 r:0.4595
ro_en Dev loss: 0.3571 r:0.8174
et_en Dev loss: 0.4211 r:0.6875
si_en Dev loss: 0.7964 r:0.5869
ne_en Dev loss: 0.4680 r:0.7508
ru_en Dev loss: 0.5103 r:0.7117
Current avg r:0.6001 Best avg r: 0.6240
21:52:50,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:07,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:55:37,602 root INFO Epoch 4 Global steps: 38400 Train loss: 0.2828
en_de Dev loss: 1.2334 r:0.1776
en_zh Dev loss: 0.7499 r:0.4715
ro_en Dev loss: 0.3356 r:0.8251
et_en Dev loss: 0.4006 r:0.6939
si_en Dev loss: 0.8351 r:0.6000
ne_en Dev loss: 0.4652 r:0.7553
ru_en Dev loss: 0.4908 r:0.7278
Current avg r:0.6073 Best avg r: 0.6240
21:59:28,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:45,187 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:15,152 root INFO Epoch 4 Global steps: 39000 Train loss: 0.2917
en_de Dev loss: 1.1827 r:0.1826
en_zh Dev loss: 0.7383 r:0.4552
ro_en Dev loss: 0.3178 r:0.8227
et_en Dev loss: 0.4075 r:0.6928
si_en Dev loss: 0.7428 r:0.5963
ne_en Dev loss: 0.4718 r:0.7514
ru_en Dev loss: 0.4642 r:0.7167
Current avg r:0.6025 Best avg r: 0.6240
22:06:05,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:07:22,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:08:52,604 root INFO Epoch 4 Global steps: 39600 Train loss: 0.2969
en_de Dev loss: 1.2694 r:0.1822
en_zh Dev loss: 0.7890 r:0.4621
ro_en Dev loss: 0.3697 r:0.8214
et_en Dev loss: 0.4227 r:0.6910
si_en Dev loss: 0.7997 r:0.5968
ne_en Dev loss: 0.4544 r:0.7509
ru_en Dev loss: 0.4395 r:0.7491
Current avg r:0.6076 Best avg r: 0.6240
22:12:43,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:00,171 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:30,122 root INFO Epoch 4 Global steps: 40200 Train loss: 0.2918
en_de Dev loss: 1.2152 r:0.1918
en_zh Dev loss: 0.7868 r:0.4512
ro_en Dev loss: 0.3415 r:0.8203
et_en Dev loss: 0.4225 r:0.6885
si_en Dev loss: 0.8774 r:0.5789
ne_en Dev loss: 0.5006 r:0.7476
ru_en Dev loss: 0.5052 r:0.7127
Current avg r:0.5987 Best avg r: 0.6240
22:19:20,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:37,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:07,730 root INFO Epoch 4 Global steps: 40800 Train loss: 0.2803
en_de Dev loss: 1.2015 r:0.1968
en_zh Dev loss: 0.7400 r:0.4761
ro_en Dev loss: 0.3286 r:0.8229
et_en Dev loss: 0.4177 r:0.6895
si_en Dev loss: 0.8079 r:0.5875
ne_en Dev loss: 0.5050 r:0.7470
ru_en Dev loss: 0.4820 r:0.7318
Current avg r:0.6074 Best avg r: 0.6240
22:25:58,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:27:15,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:28:45,448 root INFO Epoch 4 Global steps: 41400 Train loss: 0.2829
en_de Dev loss: 1.2143 r:0.1978
en_zh Dev loss: 0.7753 r:0.4692
ro_en Dev loss: 0.3312 r:0.8240
et_en Dev loss: 0.4289 r:0.6876
si_en Dev loss: 0.7718 r:0.5926
ne_en Dev loss: 0.4291 r:0.7493
ru_en Dev loss: 0.4779 r:0.7281
Current avg r:0.6069 Best avg r: 0.6240
22:32:36,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:53,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:23,188 root INFO Epoch 4 Global steps: 42000 Train loss: 0.2941
en_de Dev loss: 1.2007 r:0.1933
en_zh Dev loss: 0.7561 r:0.4678
ro_en Dev loss: 0.3350 r:0.8221
et_en Dev loss: 0.4288 r:0.6837
si_en Dev loss: 0.8184 r:0.5775
ne_en Dev loss: 0.4931 r:0.7500
ru_en Dev loss: 0.4649 r:0.7310
Current avg r:0.6036 Best avg r: 0.6240
22:39:13,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:31,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:01,18 root INFO Epoch 4 Global steps: 42600 Train loss: 0.2780
en_de Dev loss: 1.2108 r:0.1858
en_zh Dev loss: 0.7537 r:0.4720
ro_en Dev loss: 0.3304 r:0.8245
et_en Dev loss: 0.4637 r:0.6926
si_en Dev loss: 0.6898 r:0.5987
ne_en Dev loss: 0.4248 r:0.7473
ru_en Dev loss: 0.4518 r:0.7303
Current avg r:0.6073 Best avg r: 0.6240
22:45:51,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:08,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:48:38,807 root INFO Epoch 4 Global steps: 43200 Train loss: 0.2843
en_de Dev loss: 1.1811 r:0.1959
en_zh Dev loss: 0.7309 r:0.4728
ro_en Dev loss: 0.3088 r:0.8269
et_en Dev loss: 0.4111 r:0.6954
si_en Dev loss: 0.7142 r:0.5973
ne_en Dev loss: 0.4370 r:0.7476
ru_en Dev loss: 0.4167 r:0.7480
Current avg r:0.6120 Best avg r: 0.6240
22:52:29,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:46,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:16,546 root INFO Epoch 4 Global steps: 43800 Train loss: 0.2812
en_de Dev loss: 1.1773 r:0.1911
en_zh Dev loss: 0.7334 r:0.4774
ro_en Dev loss: 0.3181 r:0.8249
et_en Dev loss: 0.4143 r:0.6883
si_en Dev loss: 0.8256 r:0.5785
ne_en Dev loss: 0.4965 r:0.7442
ru_en Dev loss: 0.4374 r:0.7375
Current avg r:0.6060 Best avg r: 0.6240
22:59:07,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:00:24,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:54,33 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2783
en_de Dev loss: 1.2151 r:0.1868
en_zh Dev loss: 0.7485 r:0.4800
ro_en Dev loss: 0.3378 r:0.8249
et_en Dev loss: 0.4384 r:0.6904
si_en Dev loss: 0.7594 r:0.5923
ne_en Dev loss: 0.4324 r:0.7550
ru_en Dev loss: 0.4521 r:0.7304
Current avg r:0.6085 Best avg r: 0.6240
23:05:44,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:01,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:31,552 root INFO Epoch 4 Global steps: 45000 Train loss: 0.2821
en_de Dev loss: 1.1334 r:0.1831
en_zh Dev loss: 0.7315 r:0.4605
ro_en Dev loss: 0.3016 r:0.8232
et_en Dev loss: 0.4221 r:0.6842
si_en Dev loss: 0.6646 r:0.5904
ne_en Dev loss: 0.4452 r:0.7512
ru_en Dev loss: 0.4283 r:0.7233
Current avg r:0.6023 Best avg r: 0.6240
23:12:23,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:40,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:10,304 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2349
en_de Dev loss: 1.2048 r:0.1856
en_zh Dev loss: 0.7501 r:0.4708
ro_en Dev loss: 0.3369 r:0.8211
et_en Dev loss: 0.4320 r:0.6821
si_en Dev loss: 0.7423 r:0.5832
ne_en Dev loss: 0.4070 r:0.7511
ru_en Dev loss: 0.4332 r:0.7369
Current avg r:0.6044 Best avg r: 0.6240
23:19:00,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:17,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:21:47,667 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2588
en_de Dev loss: 1.2274 r:0.1898
en_zh Dev loss: 0.7523 r:0.4786
ro_en Dev loss: 0.3303 r:0.8239
et_en Dev loss: 0.4228 r:0.6905
si_en Dev loss: 0.8212 r:0.5872
ne_en Dev loss: 0.4661 r:0.7473
ru_en Dev loss: 0.4381 r:0.7359
Current avg r:0.6076 Best avg r: 0.6240
23:25:38,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:55,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:28:24,881 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2485
en_de Dev loss: 1.2756 r:0.1876
en_zh Dev loss: 0.8104 r:0.4614
ro_en Dev loss: 0.3541 r:0.8201
et_en Dev loss: 0.4242 r:0.6833
si_en Dev loss: 0.8477 r:0.5781
ne_en Dev loss: 0.5328 r:0.7477
ru_en Dev loss: 0.4853 r:0.7221
Current avg r:0.6001 Best avg r: 0.6240
23:32:15,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:32,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:02,37 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2486
en_de Dev loss: 1.2844 r:0.1998
en_zh Dev loss: 0.8181 r:0.4711
ro_en Dev loss: 0.3516 r:0.8231
et_en Dev loss: 0.4315 r:0.6892
si_en Dev loss: 0.8017 r:0.5853
ne_en Dev loss: 0.4689 r:0.7505
ru_en Dev loss: 0.5014 r:0.7216
Current avg r:0.6058 Best avg r: 0.6240
23:38:52,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:09,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:39,372 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2402
en_de Dev loss: 1.2396 r:0.1859
en_zh Dev loss: 0.8000 r:0.4638
ro_en Dev loss: 0.3283 r:0.8221
et_en Dev loss: 0.4313 r:0.6736
si_en Dev loss: 0.7797 r:0.5730
ne_en Dev loss: 0.4886 r:0.7435
ru_en Dev loss: 0.4662 r:0.7266
Current avg r:0.5984 Best avg r: 0.6240
23:45:29,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:47,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:16,947 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2395
en_de Dev loss: 1.2362 r:0.1939
en_zh Dev loss: 0.7746 r:0.4728
ro_en Dev loss: 0.3383 r:0.8239
et_en Dev loss: 0.4380 r:0.6831
si_en Dev loss: 0.7890 r:0.5804
ne_en Dev loss: 0.4834 r:0.7450
ru_en Dev loss: 0.4549 r:0.7354
Current avg r:0.6049 Best avg r: 0.6240
23:52:07,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:53:24,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:54:54,560 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2391
en_de Dev loss: 1.2179 r:0.1879
en_zh Dev loss: 0.8003 r:0.4498
ro_en Dev loss: 0.3292 r:0.8220
et_en Dev loss: 0.4364 r:0.6771
si_en Dev loss: 0.7602 r:0.5756
ne_en Dev loss: 0.4648 r:0.7439
ru_en Dev loss: 0.4479 r:0.7297
Current avg r:0.5980 Best avg r: 0.6240
23:58:45,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:00:02,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:32,347 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2359
en_de Dev loss: 1.2029 r:0.1934
en_zh Dev loss: 0.8008 r:0.4430
ro_en Dev loss: 0.3290 r:0.8196
et_en Dev loss: 0.4343 r:0.6812
si_en Dev loss: 0.7957 r:0.5690
ne_en Dev loss: 0.4967 r:0.7372
ru_en Dev loss: 0.4857 r:0.7088
Current avg r:0.5932 Best avg r: 0.6240
00:05:22,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:06:40,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:10,123 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2398
en_de Dev loss: 1.2045 r:0.1907
en_zh Dev loss: 0.7361 r:0.4785
ro_en Dev loss: 0.3251 r:0.8245
et_en Dev loss: 0.4454 r:0.6808
si_en Dev loss: 0.7580 r:0.5748
ne_en Dev loss: 0.4236 r:0.7304
ru_en Dev loss: 0.4136 r:0.7445
Current avg r:0.6035 Best avg r: 0.6240
00:12:00,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:17,880 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:47,869 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2450
en_de Dev loss: 1.1868 r:0.1840
en_zh Dev loss: 0.7402 r:0.4634
ro_en Dev loss: 0.3166 r:0.8243
et_en Dev loss: 0.4586 r:0.6803
si_en Dev loss: 0.7116 r:0.5838
ne_en Dev loss: 0.4158 r:0.7372
ru_en Dev loss: 0.4258 r:0.7309
Current avg r:0.6006 Best avg r: 0.6240
00:18:38,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:55,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:21:25,382 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2322
en_de Dev loss: 1.1852 r:0.1835
en_zh Dev loss: 0.7645 r:0.4505
ro_en Dev loss: 0.3198 r:0.8211
et_en Dev loss: 0.4412 r:0.6776
si_en Dev loss: 0.7482 r:0.5743
ne_en Dev loss: 0.4375 r:0.7416
ru_en Dev loss: 0.4449 r:0.7222
Current avg r:0.5958 Best avg r: 0.6240
00:25:15,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:33,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:28:03,66 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2339
en_de Dev loss: 1.2137 r:0.1867
en_zh Dev loss: 0.7642 r:0.4632
ro_en Dev loss: 0.3394 r:0.8215
et_en Dev loss: 0.4352 r:0.6849
si_en Dev loss: 0.8349 r:0.5616
ne_en Dev loss: 0.4972 r:0.7420
ru_en Dev loss: 0.4502 r:0.7323
Current avg r:0.5989 Best avg r: 0.6240
00:31:53,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:33:10,586 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:40,508 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2377
en_de Dev loss: 1.1721 r:0.2040
en_zh Dev loss: 0.7461 r:0.4635
ro_en Dev loss: 0.3148 r:0.8236
et_en Dev loss: 0.4336 r:0.6833
si_en Dev loss: 0.7861 r:0.5691
ne_en Dev loss: 0.5829 r:0.7391
ru_en Dev loss: 0.4444 r:0.7275
Current avg r:0.6015 Best avg r: 0.6240
00:38:31,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:39:48,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:18,120 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2301
en_de Dev loss: 1.2679 r:0.1817
en_zh Dev loss: 0.7727 r:0.4725
ro_en Dev loss: 0.3274 r:0.8257
et_en Dev loss: 0.4582 r:0.6908
si_en Dev loss: 0.8152 r:0.5742
ne_en Dev loss: 0.4630 r:0.7453
ru_en Dev loss: 0.4386 r:0.7415
Current avg r:0.6045 Best avg r: 0.6240
00:45:08,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:25,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:55,681 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2394
en_de Dev loss: 1.2587 r:0.1773
en_zh Dev loss: 0.7555 r:0.4765
ro_en Dev loss: 0.3261 r:0.8242
et_en Dev loss: 0.4665 r:0.6868
si_en Dev loss: 0.7508 r:0.5800
ne_en Dev loss: 0.4691 r:0.7361
ru_en Dev loss: 0.4345 r:0.7445
Current avg r:0.6036 Best avg r: 0.6240
00:51:47,510 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:04,584 root INFO 
id:ru_en cur r: 0.7637 best r: 0.7637
00:53:04,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:34,502 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2130
en_de Dev loss: 1.2306 r:0.1737
en_zh Dev loss: 0.7262 r:0.4897
ro_en Dev loss: 0.3073 r:0.8253
et_en Dev loss: 0.4475 r:0.6902
si_en Dev loss: 0.6888 r:0.5870
ne_en Dev loss: 0.4305 r:0.7378
ru_en Dev loss: 0.3797 r:0.7614
Current avg r:0.6093 Best avg r: 0.6240
00:58:25,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:59:42,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:12,62 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2045
en_de Dev loss: 1.2785 r:0.1789
en_zh Dev loss: 0.7612 r:0.4789
ro_en Dev loss: 0.3416 r:0.8208
et_en Dev loss: 0.4779 r:0.6835
si_en Dev loss: 0.8334 r:0.5658
ne_en Dev loss: 0.4658 r:0.7344
ru_en Dev loss: 0.4389 r:0.7415
Current avg r:0.6005 Best avg r: 0.6240
01:05:02,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:19,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:49,500 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2021
en_de Dev loss: 1.2474 r:0.1863
en_zh Dev loss: 0.7685 r:0.4650
ro_en Dev loss: 0.3507 r:0.8178
et_en Dev loss: 0.4689 r:0.6717
si_en Dev loss: 0.8706 r:0.5609
ne_en Dev loss: 0.4826 r:0.7358
ru_en Dev loss: 0.4657 r:0.7267
Current avg r:0.5949 Best avg r: 0.6240
01:11:39,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:57,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:26,915 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2060
en_de Dev loss: 1.2334 r:0.1896
en_zh Dev loss: 0.7562 r:0.4623
ro_en Dev loss: 0.3184 r:0.8256
et_en Dev loss: 0.4532 r:0.6796
si_en Dev loss: 0.7738 r:0.5723
ne_en Dev loss: 0.4881 r:0.7317
ru_en Dev loss: 0.4297 r:0.7357
Current avg r:0.5995 Best avg r: 0.6240
01:18:17,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:34,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:21:04,155 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2076
en_de Dev loss: 1.2794 r:0.1799
en_zh Dev loss: 0.7673 r:0.4794
ro_en Dev loss: 0.3680 r:0.8191
et_en Dev loss: 0.4691 r:0.6794
si_en Dev loss: 0.8449 r:0.5651
ne_en Dev loss: 0.5253 r:0.7283
ru_en Dev loss: 0.4970 r:0.7226
Current avg r:0.5963 Best avg r: 0.6240
01:24:54,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:26:11,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:27:41,636 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2044
en_de Dev loss: 1.2395 r:0.1803
en_zh Dev loss: 0.7781 r:0.4639
ro_en Dev loss: 0.3289 r:0.8200
et_en Dev loss: 0.4796 r:0.6849
si_en Dev loss: 0.7799 r:0.5747
ne_en Dev loss: 0.4482 r:0.7271
ru_en Dev loss: 0.4302 r:0.7416
Current avg r:0.5989 Best avg r: 0.6240
01:31:32,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:32:49,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:19,98 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2045
en_de Dev loss: 1.2355 r:0.1823
en_zh Dev loss: 0.7702 r:0.4640
ro_en Dev loss: 0.3407 r:0.8189
et_en Dev loss: 0.4861 r:0.6849
si_en Dev loss: 0.7866 r:0.5746
ne_en Dev loss: 0.4748 r:0.7282
ru_en Dev loss: 0.4568 r:0.7283
Current avg r:0.5973 Best avg r: 0.6240
01:38:09,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:39:26,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:40:56,642 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2092
en_de Dev loss: 1.3144 r:0.1843
en_zh Dev loss: 0.8186 r:0.4584
ro_en Dev loss: 0.3681 r:0.8200
et_en Dev loss: 0.4828 r:0.6692
si_en Dev loss: 0.9256 r:0.5627
ne_en Dev loss: 0.5934 r:0.7237
ru_en Dev loss: 0.4820 r:0.7220
Current avg r:0.5915 Best avg r: 0.6240
01:44:47,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:46:04,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:47:34,144 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2079
en_de Dev loss: 1.2453 r:0.1954
en_zh Dev loss: 0.7899 r:0.4675
ro_en Dev loss: 0.3453 r:0.8199
et_en Dev loss: 0.4931 r:0.6759
si_en Dev loss: 0.8314 r:0.5644
ne_en Dev loss: 0.5122 r:0.7322
ru_en Dev loss: 0.4557 r:0.7315
Current avg r:0.5981 Best avg r: 0.6240
01:51:24,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:52:41,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:54:11,722 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2041
en_de Dev loss: 1.2905 r:0.1934
en_zh Dev loss: 0.8293 r:0.4571
ro_en Dev loss: 0.3576 r:0.8188
et_en Dev loss: 0.4683 r:0.6656
si_en Dev loss: 0.8678 r:0.5532
ne_en Dev loss: 0.5243 r:0.7272
ru_en Dev loss: 0.5035 r:0.7132
Current avg r:0.5898 Best avg r: 0.6240
01:58:02,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:59:20,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:51,967 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2136
en_de Dev loss: 1.2564 r:0.2023
en_zh Dev loss: 0.8044 r:0.4618
ro_en Dev loss: 0.3375 r:0.8228
et_en Dev loss: 0.4460 r:0.6762
si_en Dev loss: 0.8414 r:0.5609
ne_en Dev loss: 0.4930 r:0.7347
ru_en Dev loss: 0.4816 r:0.7301
Current avg r:0.5984 Best avg r: 0.6240
02:04:48,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:06,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:38,238 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2116
en_de Dev loss: 1.2800 r:0.1976
en_zh Dev loss: 0.7833 r:0.4741
ro_en Dev loss: 0.3654 r:0.8235
et_en Dev loss: 0.4487 r:0.6707
si_en Dev loss: 0.8995 r:0.5617
ne_en Dev loss: 0.5649 r:0.7320
ru_en Dev loss: 0.4992 r:0.7271
Current avg r:0.5981 Best avg r: 0.6240
02:11:34,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:52,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:24,77 root INFO Epoch 6 Global steps: 61800 Train loss: 0.1963
en_de Dev loss: 1.2510 r:0.1948
en_zh Dev loss: 0.7776 r:0.4712
ro_en Dev loss: 0.3456 r:0.8214
et_en Dev loss: 0.4705 r:0.6684
si_en Dev loss: 0.8700 r:0.5546
ne_en Dev loss: 0.5074 r:0.7295
ru_en Dev loss: 0.4591 r:0.7325
Current avg r:0.5961 Best avg r: 0.6240
02:18:20,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:19:38,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:21:09,875 root INFO Epoch 6 Global steps: 62400 Train loss: 0.1952
en_de Dev loss: 1.2602 r:0.2080
en_zh Dev loss: 0.8293 r:0.4478
ro_en Dev loss: 0.3781 r:0.8163
et_en Dev loss: 0.4570 r:0.6633
si_en Dev loss: 0.9514 r:0.5414
ne_en Dev loss: 0.5766 r:0.7219
ru_en Dev loss: 0.5154 r:0.7052
Current avg r:0.5863 Best avg r: 0.6240
02:25:05,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:26:24,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:55,525 root INFO Epoch 6 Global steps: 63000 Train loss: 0.1969
en_de Dev loss: 1.2172 r:0.2063
en_zh Dev loss: 0.7718 r:0.4645
ro_en Dev loss: 0.3335 r:0.8196
et_en Dev loss: 0.4529 r:0.6770
si_en Dev loss: 0.8810 r:0.5604
ne_en Dev loss: 0.5587 r:0.7320
ru_en Dev loss: 0.4219 r:0.7433
Current avg r:0.6004 Best avg r: 0.6240
02:31:50,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:33:08,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:34:38,712 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1766
en_de Dev loss: 1.3081 r:0.2062
en_zh Dev loss: 0.8253 r:0.4696
ro_en Dev loss: 0.3798 r:0.8198
et_en Dev loss: 0.4883 r:0.6786
si_en Dev loss: 0.8498 r:0.5670
ne_en Dev loss: 0.4560 r:0.7322
ru_en Dev loss: 0.4955 r:0.7324
Current avg r:0.6008 Best avg r: 0.6240
02:38:30,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:39:47,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:41:17,953 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1735
en_de Dev loss: 1.2388 r:0.1930
en_zh Dev loss: 0.7877 r:0.4619
ro_en Dev loss: 0.3535 r:0.8173
et_en Dev loss: 0.4780 r:0.6690
si_en Dev loss: 0.9195 r:0.5536
ne_en Dev loss: 0.5179 r:0.7335
ru_en Dev loss: 0.4770 r:0.7222
Current avg r:0.5929 Best avg r: 0.6240
02:45:09,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:46:27,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:47:57,660 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1781
en_de Dev loss: 1.1851 r:0.1920
en_zh Dev loss: 0.7539 r:0.4657
ro_en Dev loss: 0.3187 r:0.8236
et_en Dev loss: 0.4653 r:0.6773
si_en Dev loss: 0.8200 r:0.5608
ne_en Dev loss: 0.4561 r:0.7354
ru_en Dev loss: 0.4277 r:0.7357
Current avg r:0.5986 Best avg r: 0.6240
02:51:49,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:53:06,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:54:37,412 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1837
en_de Dev loss: 1.2388 r:0.1887
en_zh Dev loss: 0.7633 r:0.4789
ro_en Dev loss: 0.3354 r:0.8212
et_en Dev loss: 0.4531 r:0.6710
si_en Dev loss: 0.8476 r:0.5557
ne_en Dev loss: 0.4731 r:0.7364
ru_en Dev loss: 0.4369 r:0.7382
Current avg r:0.5986 Best avg r: 0.6240
02:58:29,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:59:46,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:01:17,365 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1766
en_de Dev loss: 1.2625 r:0.1955
en_zh Dev loss: 0.7934 r:0.4722
ro_en Dev loss: 0.3388 r:0.8266
et_en Dev loss: 0.4671 r:0.6737
si_en Dev loss: 0.8288 r:0.5649
ne_en Dev loss: 0.4593 r:0.7409
ru_en Dev loss: 0.4452 r:0.7405
Current avg r:0.6020 Best avg r: 0.6240
03:05:09,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:06:26,826 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:07:57,279 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1702
en_de Dev loss: 1.2073 r:0.2005
en_zh Dev loss: 0.7643 r:0.4708
ro_en Dev loss: 0.3227 r:0.8266
et_en Dev loss: 0.4878 r:0.6767
si_en Dev loss: 0.7964 r:0.5613
ne_en Dev loss: 0.4691 r:0.7302
ru_en Dev loss: 0.4374 r:0.7348
Current avg r:0.6001 Best avg r: 0.6240
03:11:49,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:06,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:37,923 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1807
en_de Dev loss: 1.1986 r:0.1928
en_zh Dev loss: 0.7701 r:0.4659
ro_en Dev loss: 0.3248 r:0.8221
et_en Dev loss: 0.4628 r:0.6736
si_en Dev loss: 0.8106 r:0.5583
ne_en Dev loss: 0.4746 r:0.7251
ru_en Dev loss: 0.4285 r:0.7374
Current avg r:0.5964 Best avg r: 0.6240
03:18:32,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:19:50,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:21:21,381 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1688
en_de Dev loss: 1.3059 r:0.1815
en_zh Dev loss: 0.8452 r:0.4552
ro_en Dev loss: 0.3607 r:0.8182
et_en Dev loss: 0.4537 r:0.6629
si_en Dev loss: 0.9388 r:0.5474
ne_en Dev loss: 0.5735 r:0.7279
ru_en Dev loss: 0.5120 r:0.7110
Current avg r:0.5863 Best avg r: 0.6240
03:25:15,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:26:33,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:28:05,160 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1757
en_de Dev loss: 1.1697 r:0.2032
en_zh Dev loss: 0.7482 r:0.4777
ro_en Dev loss: 0.3200 r:0.8240
et_en Dev loss: 0.4902 r:0.6809
si_en Dev loss: 0.7552 r:0.5694
ne_en Dev loss: 0.4672 r:0.7265
ru_en Dev loss: 0.4031 r:0.7450
Current avg r:0.6038 Best avg r: 0.6240
03:32:01,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:33:19,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:34:50,718 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1728
en_de Dev loss: 1.1846 r:0.1935
en_zh Dev loss: 0.7462 r:0.4840
ro_en Dev loss: 0.3152 r:0.8256
et_en Dev loss: 0.4809 r:0.6817
si_en Dev loss: 0.7472 r:0.5773
ne_en Dev loss: 0.4650 r:0.7261
ru_en Dev loss: 0.3853 r:0.7585
Current avg r:0.6067 Best avg r: 0.6240
03:38:46,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:04,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:35,94 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1755
en_de Dev loss: 1.2203 r:0.1903
en_zh Dev loss: 0.7520 r:0.4794
ro_en Dev loss: 0.3155 r:0.8255
et_en Dev loss: 0.4559 r:0.6798
si_en Dev loss: 0.7702 r:0.5747
ne_en Dev loss: 0.4857 r:0.7230
ru_en Dev loss: 0.4391 r:0.7385
Current avg r:0.6016 Best avg r: 0.6240
03:45:29,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:46:47,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:48:18,73 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1786
en_de Dev loss: 1.2595 r:0.1903
en_zh Dev loss: 0.7971 r:0.4724
ro_en Dev loss: 0.3464 r:0.8200
et_en Dev loss: 0.4703 r:0.6767
si_en Dev loss: 0.8514 r:0.5679
ne_en Dev loss: 0.5152 r:0.7287
ru_en Dev loss: 0.4245 r:0.7526
Current avg r:0.6012 Best avg r: 0.6240
03:52:11,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:53:29,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:54:59,612 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1772
en_de Dev loss: 1.2257 r:0.1830
en_zh Dev loss: 0.7689 r:0.4762
ro_en Dev loss: 0.3375 r:0.8174
et_en Dev loss: 0.4862 r:0.6718
si_en Dev loss: 0.8409 r:0.5580
ne_en Dev loss: 0.5806 r:0.7229
ru_en Dev loss: 0.4666 r:0.7278
Current avg r:0.5939 Best avg r: 0.6240
03:58:52,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:00:11,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:01:42,176 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1675
en_de Dev loss: 1.2750 r:0.1827
en_zh Dev loss: 0.7876 r:0.4791
ro_en Dev loss: 0.3434 r:0.8180
et_en Dev loss: 0.4719 r:0.6748
si_en Dev loss: 0.8181 r:0.5714
ne_en Dev loss: 0.5576 r:0.7222
ru_en Dev loss: 0.4579 r:0.7374
Current avg r:0.5980 Best avg r: 0.6240
04:05:36,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:06:54,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:25,745 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1710
en_de Dev loss: 1.2209 r:0.1925
en_zh Dev loss: 0.7652 r:0.4804
ro_en Dev loss: 0.3410 r:0.8155
et_en Dev loss: 0.4469 r:0.6677
si_en Dev loss: 0.9156 r:0.5469
ne_en Dev loss: 0.5919 r:0.7202
ru_en Dev loss: 0.4394 r:0.7373
Current avg r:0.5944 Best avg r: 0.6240
04:12:22,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:13:40,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:11,398 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1482
en_de Dev loss: 1.2241 r:0.1994
en_zh Dev loss: 0.7622 r:0.4862
ro_en Dev loss: 0.3440 r:0.8188
et_en Dev loss: 0.4735 r:0.6787
si_en Dev loss: 0.8330 r:0.5577
ne_en Dev loss: 0.5221 r:0.7218
ru_en Dev loss: 0.4262 r:0.7468
Current avg r:0.6014 Best avg r: 0.6240
04:19:06,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:20:24,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:21:54,808 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1511
en_de Dev loss: 1.2612 r:0.1847
en_zh Dev loss: 0.7823 r:0.4794
ro_en Dev loss: 0.3460 r:0.8176
et_en Dev loss: 0.4614 r:0.6701
si_en Dev loss: 0.9261 r:0.5452
ne_en Dev loss: 0.5343 r:0.7222
ru_en Dev loss: 0.4543 r:0.7334
Current avg r:0.5932 Best avg r: 0.6240
04:25:46,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:27:04,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:28:34,882 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1511
en_de Dev loss: 1.2001 r:0.1875
en_zh Dev loss: 0.7303 r:0.4887
ro_en Dev loss: 0.3218 r:0.8222
et_en Dev loss: 0.4351 r:0.6859
si_en Dev loss: 0.7717 r:0.5653
ne_en Dev loss: 0.4793 r:0.7309
ru_en Dev loss: 0.4025 r:0.7516
Current avg r:0.6046 Best avg r: 0.6240
04:32:26,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:33:44,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:35:14,463 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1527
en_de Dev loss: 1.2261 r:0.1812
en_zh Dev loss: 0.7621 r:0.4810
ro_en Dev loss: 0.3297 r:0.8165
et_en Dev loss: 0.4633 r:0.6746
si_en Dev loss: 0.8403 r:0.5538
ne_en Dev loss: 0.5219 r:0.7198
ru_en Dev loss: 0.4339 r:0.7362
Current avg r:0.5947 Best avg r: 0.6240
04:39:06,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:40:24,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:41:55,671 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1485
en_de Dev loss: 1.2018 r:0.1904
en_zh Dev loss: 0.7555 r:0.4826
ro_en Dev loss: 0.3179 r:0.8192
et_en Dev loss: 0.4550 r:0.6824
si_en Dev loss: 0.7981 r:0.5605
ne_en Dev loss: 0.4541 r:0.7268
ru_en Dev loss: 0.4325 r:0.7380
Current avg r:0.6000 Best avg r: 0.6240
04:45:50,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:47:08,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:40,288 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1363
en_de Dev loss: 1.2646 r:0.1849
en_zh Dev loss: 0.7783 r:0.4836
ro_en Dev loss: 0.3456 r:0.8164
et_en Dev loss: 0.4552 r:0.6741
si_en Dev loss: 0.8754 r:0.5590
ne_en Dev loss: 0.4860 r:0.7226
ru_en Dev loss: 0.4079 r:0.7537
Current avg r:0.5992 Best avg r: 0.6240
04:52:35,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:53:54,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:55:25,425 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1489
en_de Dev loss: 1.2600 r:0.1870
en_zh Dev loss: 0.7914 r:0.4719
ro_en Dev loss: 0.3517 r:0.8171
et_en Dev loss: 0.4609 r:0.6759
si_en Dev loss: 0.8355 r:0.5569
ne_en Dev loss: 0.5407 r:0.7178
ru_en Dev loss: 0.4510 r:0.7338
Current avg r:0.5943 Best avg r: 0.6240
04:59:20,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:00:39,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:02:10,547 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1546
en_de Dev loss: 1.2075 r:0.1902
en_zh Dev loss: 0.7553 r:0.4788
ro_en Dev loss: 0.3201 r:0.8200
et_en Dev loss: 0.4528 r:0.6871
si_en Dev loss: 0.7922 r:0.5633
ne_en Dev loss: 0.4753 r:0.7227
ru_en Dev loss: 0.4059 r:0.7481
Current avg r:0.6015 Best avg r: 0.6240
05:06:05,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:07:23,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:53,924 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1537
en_de Dev loss: 1.2137 r:0.2002
en_zh Dev loss: 0.7602 r:0.4835
ro_en Dev loss: 0.3321 r:0.8197
et_en Dev loss: 0.4393 r:0.6771
si_en Dev loss: 0.8339 r:0.5572
ne_en Dev loss: 0.5491 r:0.7195
ru_en Dev loss: 0.4550 r:0.7272
Current avg r:0.5978 Best avg r: 0.6240
05:12:45,717 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:03,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:33,847 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1544
en_de Dev loss: 1.2346 r:0.1946
en_zh Dev loss: 0.8228 r:0.4608
ro_en Dev loss: 0.3368 r:0.8156
et_en Dev loss: 0.4629 r:0.6717
si_en Dev loss: 0.8268 r:0.5510
ne_en Dev loss: 0.5003 r:0.7170
ru_en Dev loss: 0.4874 r:0.7176
Current avg r:0.5898 Best avg r: 0.6240
05:19:25,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:43,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:22:14,435 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1562
en_de Dev loss: 1.2942 r:0.1730
en_zh Dev loss: 0.8013 r:0.4720
ro_en Dev loss: 0.3663 r:0.8165
et_en Dev loss: 0.4704 r:0.6650
si_en Dev loss: 0.9300 r:0.5462
ne_en Dev loss: 0.5931 r:0.7224
ru_en Dev loss: 0.5160 r:0.7128
Current avg r:0.5868 Best avg r: 0.6240
05:26:09,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:27:27,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:28:58,598 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1541
en_de Dev loss: 1.2634 r:0.1818
en_zh Dev loss: 0.7640 r:0.4870
ro_en Dev loss: 0.3553 r:0.8163
et_en Dev loss: 0.4578 r:0.6770
si_en Dev loss: 0.8643 r:0.5523
ne_en Dev loss: 0.5350 r:0.7229
ru_en Dev loss: 0.4586 r:0.7382
Current avg r:0.5965 Best avg r: 0.6240
05:32:53,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:34:11,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:35:42,116 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1472
en_de Dev loss: 1.2582 r:0.1827
en_zh Dev loss: 0.7574 r:0.4859
ro_en Dev loss: 0.3517 r:0.8200
et_en Dev loss: 0.4872 r:0.6734
si_en Dev loss: 0.8759 r:0.5516
ne_en Dev loss: 0.5338 r:0.7209
ru_en Dev loss: 0.4374 r:0.7425
Current avg r:0.5967 Best avg r: 0.6240
05:39:36,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:40:54,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:42:25,642 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1462
en_de Dev loss: 1.2642 r:0.1820
en_zh Dev loss: 0.7685 r:0.4901
ro_en Dev loss: 0.3427 r:0.8178
et_en Dev loss: 0.4855 r:0.6761
si_en Dev loss: 0.8342 r:0.5539
ne_en Dev loss: 0.5309 r:0.7207
ru_en Dev loss: 0.4455 r:0.7395
Current avg r:0.5972 Best avg r: 0.6240
05:46:18,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:47:36,402 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:49:07,358 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1534
en_de Dev loss: 1.2306 r:0.1720
en_zh Dev loss: 0.7506 r:0.4827
ro_en Dev loss: 0.3278 r:0.8195
et_en Dev loss: 0.4663 r:0.6706
si_en Dev loss: 0.8115 r:0.5502
ne_en Dev loss: 0.5085 r:0.7246
ru_en Dev loss: 0.4075 r:0.7458
Current avg r:0.5951 Best avg r: 0.6240
05:53:02,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:20,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:55:51,715 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1376
en_de Dev loss: 1.2750 r:0.1825
en_zh Dev loss: 0.7881 r:0.4761
ro_en Dev loss: 0.3404 r:0.8200
et_en Dev loss: 0.4963 r:0.6699
si_en Dev loss: 0.8008 r:0.5537
ne_en Dev loss: 0.4990 r:0.7163
ru_en Dev loss: 0.4599 r:0.7328
Current avg r:0.5931 Best avg r: 0.6240
05:59:45,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:01:03,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:02:34,393 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1283
en_de Dev loss: 1.2527 r:0.1790
en_zh Dev loss: 0.7760 r:0.4728
ro_en Dev loss: 0.3380 r:0.8192
et_en Dev loss: 0.4842 r:0.6614
si_en Dev loss: 0.8738 r:0.5454
ne_en Dev loss: 0.5338 r:0.7166
ru_en Dev loss: 0.4731 r:0.7200
Current avg r:0.5878 Best avg r: 0.6240
06:06:29,865 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:48,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:09:19,379 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1275
en_de Dev loss: 1.3173 r:0.1772
en_zh Dev loss: 0.8330 r:0.4663
ro_en Dev loss: 0.3763 r:0.8130
et_en Dev loss: 0.4922 r:0.6597
si_en Dev loss: 0.9443 r:0.5422
ne_en Dev loss: 0.5962 r:0.7192
ru_en Dev loss: 0.4921 r:0.7212
Current avg r:0.5856 Best avg r: 0.6240
06:13:13,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:31,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:16:02,716 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1356
en_de Dev loss: 1.2199 r:0.1681
en_zh Dev loss: 0.7316 r:0.4843
ro_en Dev loss: 0.3201 r:0.8207
et_en Dev loss: 0.4959 r:0.6735
si_en Dev loss: 0.7766 r:0.5587
ne_en Dev loss: 0.4843 r:0.7225
ru_en Dev loss: 0.3937 r:0.7507
Current avg r:0.5969 Best avg r: 0.6240
06:19:57,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:21:15,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:22:46,416 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1313
en_de Dev loss: 1.2754 r:0.1850
en_zh Dev loss: 0.7771 r:0.4859
ro_en Dev loss: 0.3466 r:0.8180
et_en Dev loss: 0.5314 r:0.6759
si_en Dev loss: 0.8285 r:0.5566
ne_en Dev loss: 0.5150 r:0.7186
ru_en Dev loss: 0.4199 r:0.7513
Current avg r:0.5988 Best avg r: 0.6240
06:26:40,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:27:58,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:29:28,981 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1380
en_de Dev loss: 1.3104 r:0.1769
en_zh Dev loss: 0.8126 r:0.4759
ro_en Dev loss: 0.3403 r:0.8217
et_en Dev loss: 0.4730 r:0.6736
si_en Dev loss: 0.8542 r:0.5483
ne_en Dev loss: 0.5196 r:0.7155
ru_en Dev loss: 0.4594 r:0.7400
Current avg r:0.5931 Best avg r: 0.6240
06:33:20,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:34:38,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:36:08,762 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1345
en_de Dev loss: 1.2727 r:0.1703
en_zh Dev loss: 0.7518 r:0.4880
ro_en Dev loss: 0.3416 r:0.8206
et_en Dev loss: 0.4790 r:0.6739
si_en Dev loss: 0.8421 r:0.5485
ne_en Dev loss: 0.5106 r:0.7155
ru_en Dev loss: 0.4403 r:0.7406
Current avg r:0.5939 Best avg r: 0.6240
06:40:00,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:18,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:42:49,22 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1328
en_de Dev loss: 1.2548 r:0.1753
en_zh Dev loss: 0.7820 r:0.4760
ro_en Dev loss: 0.3482 r:0.8176
et_en Dev loss: 0.4583 r:0.6691
si_en Dev loss: 0.8679 r:0.5442
ne_en Dev loss: 0.5656 r:0.7140
ru_en Dev loss: 0.4451 r:0.7406
Current avg r:0.5910 Best avg r: 0.6240
06:46:42,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:48:00,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:49:31,636 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1335
en_de Dev loss: 1.2968 r:0.1746
en_zh Dev loss: 0.7854 r:0.4818
ro_en Dev loss: 0.3719 r:0.8132
et_en Dev loss: 0.4980 r:0.6697
si_en Dev loss: 0.8711 r:0.5477
ne_en Dev loss: 0.5346 r:0.7166
ru_en Dev loss: 0.4581 r:0.7406
Current avg r:0.5920 Best avg r: 0.6240
06:53:24,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:42,414 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:13,341 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1296
en_de Dev loss: 1.2419 r:0.1899
en_zh Dev loss: 0.7656 r:0.4819
ro_en Dev loss: 0.3463 r:0.8184
et_en Dev loss: 0.4427 r:0.6729
si_en Dev loss: 0.9603 r:0.5366
ne_en Dev loss: 0.6569 r:0.7023
ru_en Dev loss: 0.4541 r:0.7360
Current avg r:0.5912 Best avg r: 0.6240
07:00:06,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:01:24,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:55,644 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1275
en_de Dev loss: 1.2857 r:0.1842
en_zh Dev loss: 0.7797 r:0.4842
ro_en Dev loss: 0.3515 r:0.8162
et_en Dev loss: 0.4688 r:0.6691
si_en Dev loss: 0.8711 r:0.5448
ne_en Dev loss: 0.5211 r:0.7147
ru_en Dev loss: 0.4364 r:0.7482
Current avg r:0.5945 Best avg r: 0.6240
07:06:48,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:05,680 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:09:36,60 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1284
en_de Dev loss: 1.2878 r:0.1963
en_zh Dev loss: 0.8063 r:0.4839
ro_en Dev loss: 0.3531 r:0.8165
et_en Dev loss: 0.4728 r:0.6693
si_en Dev loss: 0.8675 r:0.5490
ne_en Dev loss: 0.5108 r:0.7218
ru_en Dev loss: 0.4547 r:0.7453
Current avg r:0.5975 Best avg r: 0.6240
07:13:27,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:14:45,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:16:15,429 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1304
en_de Dev loss: 1.2503 r:0.1840
en_zh Dev loss: 0.7750 r:0.4779
ro_en Dev loss: 0.3294 r:0.8221
et_en Dev loss: 0.4661 r:0.6708
si_en Dev loss: 0.8700 r:0.5477
ne_en Dev loss: 0.5437 r:0.7179
ru_en Dev loss: 0.4337 r:0.7462
Current avg r:0.5952 Best avg r: 0.6240
07:20:06,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:21:24,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:22:54,688 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1285
en_de Dev loss: 1.2388 r:0.1884
en_zh Dev loss: 0.7560 r:0.4861
ro_en Dev loss: 0.3288 r:0.8199
et_en Dev loss: 0.4530 r:0.6704
si_en Dev loss: 0.8283 r:0.5531
ne_en Dev loss: 0.5399 r:0.7122
ru_en Dev loss: 0.4385 r:0.7399
Current avg r:0.5957 Best avg r: 0.6240
07:26:45,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:28:03,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:29:33,680 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1221
en_de Dev loss: 1.2694 r:0.1849
en_zh Dev loss: 0.7824 r:0.4848
ro_en Dev loss: 0.3497 r:0.8149
et_en Dev loss: 0.4703 r:0.6720
si_en Dev loss: 0.9005 r:0.5419
ne_en Dev loss: 0.5792 r:0.7218
ru_en Dev loss: 0.4367 r:0.7480
Current avg r:0.5955 Best avg r: 0.6240
07:33:27,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:33:40,36 root INFO 
id:en_zh cur r: 0.5008 best r: 0.5008
07:34:44,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:36:15,856 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1218
en_de Dev loss: 1.2518 r:0.1835
en_zh Dev loss: 0.7477 r:0.4957
ro_en Dev loss: 0.3436 r:0.8159
et_en Dev loss: 0.4874 r:0.6709
si_en Dev loss: 0.8203 r:0.5590
ne_en Dev loss: 0.5064 r:0.7166
ru_en Dev loss: 0.4060 r:0.7543
Current avg r:0.5994 Best avg r: 0.6240
07:40:08,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:21,798 root INFO 
id:en_zh cur r: 0.5052 best r: 0.5052
07:41:26,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:57,777 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1174
en_de Dev loss: 1.1833 r:0.1883
en_zh Dev loss: 0.7117 r:0.4989
ro_en Dev loss: 0.3176 r:0.8201
et_en Dev loss: 0.4728 r:0.6763
si_en Dev loss: 0.7905 r:0.5520
ne_en Dev loss: 0.4842 r:0.7224
ru_en Dev loss: 0.3768 r:0.7599
Current avg r:0.6026 Best avg r: 0.6240
07:46:50,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:08,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:49:39,765 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1162
en_de Dev loss: 1.2421 r:0.1799
en_zh Dev loss: 0.7541 r:0.4841
ro_en Dev loss: 0.3255 r:0.8208
et_en Dev loss: 0.4681 r:0.6704
si_en Dev loss: 0.8377 r:0.5453
ne_en Dev loss: 0.5324 r:0.7173
ru_en Dev loss: 0.4180 r:0.7485
Current avg r:0.5952 Best avg r: 0.6240
07:53:32,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:54:50,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:56:20,524 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1134
en_de Dev loss: 1.2227 r:0.1875
en_zh Dev loss: 0.7342 r:0.4937
ro_en Dev loss: 0.3311 r:0.8204
et_en Dev loss: 0.4569 r:0.6738
si_en Dev loss: 0.8512 r:0.5424
ne_en Dev loss: 0.6121 r:0.7154
ru_en Dev loss: 0.4047 r:0.7519
Current avg r:0.5979 Best avg r: 0.6240
08:00:11,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:01:29,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:59,322 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1129
en_de Dev loss: 1.2756 r:0.1731
en_zh Dev loss: 0.7695 r:0.4838
ro_en Dev loss: 0.3470 r:0.8160
et_en Dev loss: 0.4763 r:0.6715
si_en Dev loss: 0.8368 r:0.5446
ne_en Dev loss: 0.5332 r:0.7118
ru_en Dev loss: 0.4186 r:0.7525
Current avg r:0.5933 Best avg r: 0.6240
08:06:50,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:08,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:09:38,566 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1114
en_de Dev loss: 1.2584 r:0.1878
en_zh Dev loss: 0.7768 r:0.4895
ro_en Dev loss: 0.3485 r:0.8181
et_en Dev loss: 0.5097 r:0.6788
si_en Dev loss: 0.8592 r:0.5475
ne_en Dev loss: 0.5134 r:0.7149
ru_en Dev loss: 0.4045 r:0.7584
Current avg r:0.5993 Best avg r: 0.6240
08:13:30,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:14:47,512 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:17,923 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1169
en_de Dev loss: 1.2723 r:0.1835
en_zh Dev loss: 0.7843 r:0.4824
ro_en Dev loss: 0.3470 r:0.8168
et_en Dev loss: 0.4661 r:0.6719
si_en Dev loss: 0.8973 r:0.5454
ne_en Dev loss: 0.5548 r:0.7205
ru_en Dev loss: 0.4390 r:0.7456
Current avg r:0.5952 Best avg r: 0.6240
08:20:09,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:26,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:22:56,960 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1175
en_de Dev loss: 1.2872 r:0.1838
en_zh Dev loss: 0.7883 r:0.4917
ro_en Dev loss: 0.3507 r:0.8187
et_en Dev loss: 0.4916 r:0.6806
si_en Dev loss: 0.8215 r:0.5609
ne_en Dev loss: 0.5081 r:0.7192
ru_en Dev loss: 0.4168 r:0.7568
Current avg r:0.6017 Best avg r: 0.6240
08:26:47,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:04,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:34,961 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1181
en_de Dev loss: 1.2498 r:0.1829
en_zh Dev loss: 0.7660 r:0.4843
ro_en Dev loss: 0.3364 r:0.8192
et_en Dev loss: 0.4692 r:0.6750
si_en Dev loss: 0.8494 r:0.5601
ne_en Dev loss: 0.5477 r:0.7201
ru_en Dev loss: 0.4084 r:0.7574
Current avg r:0.5999 Best avg r: 0.6240
08:33:25,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:34:42,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:12,945 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1142
en_de Dev loss: 1.2501 r:0.1980
en_zh Dev loss: 0.7840 r:0.4846
ro_en Dev loss: 0.3612 r:0.8127
et_en Dev loss: 0.4627 r:0.6614
si_en Dev loss: 0.9612 r:0.5428
ne_en Dev loss: 0.6116 r:0.7073
ru_en Dev loss: 0.4957 r:0.7321
Current avg r:0.5913 Best avg r: 0.6240
08:40:03,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:41:20,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:42:50,911 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1141
en_de Dev loss: 1.2259 r:0.1865
en_zh Dev loss: 0.7738 r:0.4791
ro_en Dev loss: 0.3406 r:0.8157
et_en Dev loss: 0.4518 r:0.6814
si_en Dev loss: 0.8259 r:0.5561
ne_en Dev loss: 0.5496 r:0.7213
ru_en Dev loss: 0.4236 r:0.7529
Current avg r:0.5990 Best avg r: 0.6240
08:46:41,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:58,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:28,844 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1100
en_de Dev loss: 1.3100 r:0.1794
en_zh Dev loss: 0.8139 r:0.4860
ro_en Dev loss: 0.3794 r:0.8148
et_en Dev loss: 0.4885 r:0.6759
si_en Dev loss: 0.9126 r:0.5498
ne_en Dev loss: 0.5574 r:0.7135
ru_en Dev loss: 0.4807 r:0.7391
Current avg r:0.5941 Best avg r: 0.6240
08:53:19,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:54:36,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:06,763 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1162
en_de Dev loss: 1.1868 r:0.2025
en_zh Dev loss: 0.7417 r:0.4940
ro_en Dev loss: 0.3291 r:0.8157
et_en Dev loss: 0.4479 r:0.6795
si_en Dev loss: 0.8284 r:0.5485
ne_en Dev loss: 0.5119 r:0.7162
ru_en Dev loss: 0.3952 r:0.7576
Current avg r:0.6020 Best avg r: 0.6240
08:59:57,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:14,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:02:44,817 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1161
en_de Dev loss: 1.3216 r:0.1824
en_zh Dev loss: 0.8382 r:0.4840
ro_en Dev loss: 0.3689 r:0.8169
et_en Dev loss: 0.4823 r:0.6700
si_en Dev loss: 0.9398 r:0.5421
ne_en Dev loss: 0.5968 r:0.7100
ru_en Dev loss: 0.5090 r:0.7283
Current avg r:0.5905 Best avg r: 0.6240
09:06:35,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:07:52,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:22,800 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1125
en_de Dev loss: 1.3183 r:0.1852
en_zh Dev loss: 0.8129 r:0.4897
ro_en Dev loss: 0.3458 r:0.8226
et_en Dev loss: 0.4622 r:0.6705
si_en Dev loss: 0.9068 r:0.5453
ne_en Dev loss: 0.5532 r:0.7085
ru_en Dev loss: 0.4700 r:0.7431
Current avg r:0.5950 Best avg r: 0.6240
09:13:14,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:14:32,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:02,213 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1097
en_de Dev loss: 1.2555 r:0.1928
en_zh Dev loss: 0.7673 r:0.4963
ro_en Dev loss: 0.3498 r:0.8208
et_en Dev loss: 0.4544 r:0.6732
si_en Dev loss: 0.8830 r:0.5491
ne_en Dev loss: 0.5822 r:0.7064
ru_en Dev loss: 0.4209 r:0.7611
Current avg r:0.5999 Best avg r: 0.6240
09:19:52,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:20:05,815 root INFO 
id:en_zh cur r: 0.5137 best r: 0.5137
09:21:10,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:22:40,315 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1001
en_de Dev loss: 1.2574 r:0.1893
en_zh Dev loss: 0.7459 r:0.5103
ro_en Dev loss: 0.3631 r:0.8183
et_en Dev loss: 0.4848 r:0.6744
si_en Dev loss: 0.9343 r:0.5484
ne_en Dev loss: 0.5937 r:0.7074
ru_en Dev loss: 0.4149 r:0.7594
Current avg r:0.6011 Best avg r: 0.6240
09:26:31,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:27:48,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:29:18,476 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1054
en_de Dev loss: 1.2321 r:0.1904
en_zh Dev loss: 0.7477 r:0.4960
ro_en Dev loss: 0.3532 r:0.8200
et_en Dev loss: 0.4567 r:0.6726
si_en Dev loss: 0.9192 r:0.5426
ne_en Dev loss: 0.5923 r:0.7101
ru_en Dev loss: 0.4142 r:0.7581
Current avg r:0.5985 Best avg r: 0.6240
09:33:09,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:34:26,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:35:56,551 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1016
en_de Dev loss: 1.2393 r:0.2051
en_zh Dev loss: 0.7797 r:0.4942
ro_en Dev loss: 0.3302 r:0.8234
et_en Dev loss: 0.4423 r:0.6789
si_en Dev loss: 0.8755 r:0.5490
ne_en Dev loss: 0.5547 r:0.7051
ru_en Dev loss: 0.4559 r:0.7448
Current avg r:0.6001 Best avg r: 0.6240
09:39:47,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:04,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:42:34,772 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1027
en_de Dev loss: 1.2618 r:0.1966
en_zh Dev loss: 0.7658 r:0.5020
ro_en Dev loss: 0.3458 r:0.8204
et_en Dev loss: 0.4818 r:0.6786
si_en Dev loss: 0.8275 r:0.5548
ne_en Dev loss: 0.5113 r:0.7085
ru_en Dev loss: 0.4137 r:0.7633
Current avg r:0.6034 Best avg r: 0.6240
09:46:25,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:42,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:12,760 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1009
en_de Dev loss: 1.2349 r:0.1922
en_zh Dev loss: 0.7555 r:0.4951
ro_en Dev loss: 0.3438 r:0.8207
et_en Dev loss: 0.4750 r:0.6780
si_en Dev loss: 0.8430 r:0.5614
ne_en Dev loss: 0.5516 r:0.7131
ru_en Dev loss: 0.4100 r:0.7632
Current avg r:0.6034 Best avg r: 0.6240
09:53:03,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:54:20,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:55:50,508 root INFO Epoch 11 Global steps: 103200 Train loss: 0.0995
en_de Dev loss: 1.2249 r:0.1959
en_zh Dev loss: 0.7482 r:0.4945
ro_en Dev loss: 0.3426 r:0.8177
et_en Dev loss: 0.4507 r:0.6713
si_en Dev loss: 0.8480 r:0.5460
ne_en Dev loss: 0.5619 r:0.7011
ru_en Dev loss: 0.4425 r:0.7496
Current avg r:0.5966 Best avg r: 0.6240
09:59:41,120 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:00:58,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:28,331 root INFO Epoch 11 Global steps: 103800 Train loss: 0.0980
en_de Dev loss: 1.2471 r:0.2037
en_zh Dev loss: 0.7668 r:0.4985
ro_en Dev loss: 0.3552 r:0.8191
et_en Dev loss: 0.4600 r:0.6746
si_en Dev loss: 0.8773 r:0.5568
ne_en Dev loss: 0.5950 r:0.7044
ru_en Dev loss: 0.4419 r:0.7510
Current avg r:0.6012 Best avg r: 0.6240
10:06:18,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:07:36,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:06,213 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1045
en_de Dev loss: 1.1992 r:0.2014
en_zh Dev loss: 0.7517 r:0.4954
ro_en Dev loss: 0.3401 r:0.8182
et_en Dev loss: 0.4454 r:0.6696
si_en Dev loss: 0.9094 r:0.5440
ne_en Dev loss: 0.6342 r:0.7014
ru_en Dev loss: 0.4227 r:0.7458
Current avg r:0.5965 Best avg r: 0.6240
10:12:56,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:13,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:44,43 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1029
en_de Dev loss: 1.3072 r:0.1888
en_zh Dev loss: 0.7844 r:0.5003
ro_en Dev loss: 0.3764 r:0.8180
et_en Dev loss: 0.4784 r:0.6744
si_en Dev loss: 0.9006 r:0.5508
ne_en Dev loss: 0.5487 r:0.7115
ru_en Dev loss: 0.4550 r:0.7540
Current avg r:0.5997 Best avg r: 0.6240
10:19:34,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:51,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:22,66 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1034
en_de Dev loss: 1.2853 r:0.1936
en_zh Dev loss: 0.7612 r:0.5052
ro_en Dev loss: 0.3626 r:0.8171
et_en Dev loss: 0.5163 r:0.6765
si_en Dev loss: 0.8831 r:0.5514
ne_en Dev loss: 0.5913 r:0.7039
ru_en Dev loss: 0.4133 r:0.7629
Current avg r:0.6015 Best avg r: 0.6240
10:26:12,915 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:30,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:00,235 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1073
en_de Dev loss: 1.2912 r:0.1883
en_zh Dev loss: 0.7926 r:0.4960
ro_en Dev loss: 0.3636 r:0.8161
et_en Dev loss: 0.4885 r:0.6661
si_en Dev loss: 0.9175 r:0.5481
ne_en Dev loss: 0.5505 r:0.7108
ru_en Dev loss: 0.4699 r:0.7423
Current avg r:0.5954 Best avg r: 0.6240
