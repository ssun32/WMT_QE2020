14:42:19,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:46,187 root INFO 
id:ro_en cur r: 0.5438 best r: 0.5438
14:42:59,473 root INFO 
id:et_en cur r: 0.4748 best r: 0.4748
14:43:12,781 root INFO 
id:si_en cur r: 0.4667 best r: 0.4667
14:43:26,86 root INFO 
id:ne_en cur r: 0.5268 best r: 0.5268
14:43:39,262 root INFO 
id:ru_en cur r: 0.4165 best r: 0.4165
14:43:39,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:11,773 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
14:45:11,779 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:45:11,784 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:45:11,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
14:45:11,794 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
14:45:11,799 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:45:11,804 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:45:25,3 root INFO Epoch 0 Global steps: 600 Train loss: 0.8774
en_de Dev loss: 0.8888 r:0.0966
en_zh Dev loss: 0.8147 r:0.2557
ro_en Dev loss: 0.6434 r:0.5984
et_en Dev loss: 0.5463 r:0.5044
si_en Dev loss: 0.6857 r:0.4747
ne_en Dev loss: 0.5838 r:0.6221
ru_en Dev loss: 0.6863 r:0.4258
Current avg r:0.4254 Best avg r: 0.4254
14:49:20,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:33,836 root INFO 
id:en_zh cur r: 0.2945 best r: 0.2945
14:50:00,107 root INFO 
id:et_en cur r: 0.5161 best r: 0.5161
14:50:39,322 root INFO 
id:ru_en cur r: 0.5895 best r: 0.5895
14:50:39,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:10,690 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
14:52:10,696 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:52:10,701 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:52:10,705 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
14:52:10,710 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
14:52:10,715 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:52:10,721 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:52:23,785 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8202
en_de Dev loss: 1.0252 r:0.0805
en_zh Dev loss: 0.7736 r:0.2840
ro_en Dev loss: 0.7194 r:0.6339
et_en Dev loss: 0.5571 r:0.5252
si_en Dev loss: 0.8833 r:0.4218
ne_en Dev loss: 0.6097 r:0.5510
ru_en Dev loss: 0.6633 r:0.6099
Current avg r:0.4438 Best avg r: 0.4438
14:56:17,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:30,157 root INFO 
id:en_zh cur r: 0.3111 best r: 0.3111
14:56:43,195 root INFO 
id:ro_en cur r: 0.6784 best r: 0.6784
14:56:56,268 root INFO 
id:et_en cur r: 0.6062 best r: 0.6062
14:57:22,384 root INFO 
id:ne_en cur r: 0.6288 best r: 0.6288
14:57:35,339 root INFO 
id:ru_en cur r: 0.6814 best r: 0.6814
14:57:35,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:06,513 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
14:59:06,519 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:59:06,523 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:59:06,528 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
14:59:06,534 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
14:59:06,539 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:59:06,544 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:59:19,587 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7488
en_de Dev loss: 0.9992 r:0.1220
en_zh Dev loss: 0.7796 r:0.3146
ro_en Dev loss: 0.5457 r:0.7100
et_en Dev loss: 0.4472 r:0.6246
si_en Dev loss: 0.7315 r:0.4911
ne_en Dev loss: 0.4829 r:0.6543
ru_en Dev loss: 0.6060 r:0.6898
Current avg r:0.5152 Best avg r: 0.5152
15:03:12,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:25,883 root INFO 
id:en_zh cur r: 0.3220 best r: 0.3220
15:04:30,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:02,94 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7331
en_de Dev loss: 1.0271 r:0.1446
en_zh Dev loss: 0.7921 r:0.3321
ro_en Dev loss: 0.6292 r:0.6822
et_en Dev loss: 0.5096 r:0.5958
si_en Dev loss: 0.8304 r:0.4698
ne_en Dev loss: 0.5399 r:0.6109
ru_en Dev loss: 0.6182 r:0.6793
Current avg r:0.5021 Best avg r: 0.5152
15:09:55,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:08,457 root INFO 
id:en_zh cur r: 0.3328 best r: 0.3328
15:10:21,496 root INFO 
id:ro_en cur r: 0.7070 best r: 0.7070
15:10:34,534 root INFO 
id:et_en cur r: 0.6113 best r: 0.6113
15:10:47,588 root INFO 
id:si_en cur r: 0.4970 best r: 0.4970
15:11:00,653 root INFO 
id:ne_en cur r: 0.6485 best r: 0.6485
15:11:13,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:44,732 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:12:44,739 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:12:44,746 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:12:44,751 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:12:44,756 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:12:44,763 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:12:44,768 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:12:57,804 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6699
en_de Dev loss: 1.0998 r:0.1520
en_zh Dev loss: 0.8214 r:0.3557
ro_en Dev loss: 0.6294 r:0.7276
et_en Dev loss: 0.4905 r:0.6507
si_en Dev loss: 0.8738 r:0.5221
ne_en Dev loss: 0.5705 r:0.6727
ru_en Dev loss: 0.6224 r:0.7095
Current avg r:0.5415 Best avg r: 0.5415
15:16:51,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:04,106 root INFO 
id:en_zh cur r: 0.3656 best r: 0.3656
15:17:17,159 root INFO 
id:ro_en cur r: 0.7307 best r: 0.7307
15:17:30,207 root INFO 
id:et_en cur r: 0.6465 best r: 0.6465
15:17:43,252 root INFO 
id:si_en cur r: 0.5317 best r: 0.5317
15:17:56,306 root INFO 
id:ne_en cur r: 0.6952 best r: 0.6952
15:18:09,272 root INFO 
id:ru_en cur r: 0.7136 best r: 0.7136
15:18:09,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:40,399 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:19:40,409 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:19:40,415 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:19:40,420 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:19:40,424 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:19:40,429 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:19:40,433 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:19:53,471 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6516
en_de Dev loss: 1.0420 r:0.1520
en_zh Dev loss: 0.7347 r:0.3820
ro_en Dev loss: 0.4667 r:0.7381
et_en Dev loss: 0.4059 r:0.6721
si_en Dev loss: 0.7321 r:0.5459
ne_en Dev loss: 0.4566 r:0.6970
ru_en Dev loss: 0.4885 r:0.7318
Current avg r:0.5598 Best avg r: 0.5598
15:23:46,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:12,697 root INFO 
id:ro_en cur r: 0.7391 best r: 0.7391
15:24:25,747 root INFO 
id:et_en cur r: 0.6636 best r: 0.6636
15:24:38,794 root INFO 
id:si_en cur r: 0.5432 best r: 0.5432
15:24:51,836 root INFO 
id:ne_en cur r: 0.7080 best r: 0.7080
15:25:04,799 root INFO 
id:ru_en cur r: 0.7270 best r: 0.7270
15:25:04,800 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:35,918 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:26:35,925 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:26:35,930 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:26:35,934 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:26:35,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:26:35,947 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:26:35,952 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:26:48,982 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6115
en_de Dev loss: 0.9913 r:0.1581
en_zh Dev loss: 0.7319 r:0.3756
ro_en Dev loss: 0.4202 r:0.7445
et_en Dev loss: 0.3782 r:0.6815
si_en Dev loss: 0.6256 r:0.5577
ne_en Dev loss: 0.4407 r:0.6963
ru_en Dev loss: 0.4362 r:0.7374
Current avg r:0.5644 Best avg r: 0.5644
15:30:42,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:55,202 root INFO 
id:en_zh cur r: 0.3701 best r: 0.3701
15:31:08,221 root INFO 
id:ro_en cur r: 0.7453 best r: 0.7453
15:31:21,264 root INFO 
id:et_en cur r: 0.6871 best r: 0.6871
15:31:34,313 root INFO 
id:si_en cur r: 0.5565 best r: 0.5565
15:31:47,365 root INFO 
id:ne_en cur r: 0.7202 best r: 0.7202
15:32:00,312 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:31,392 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:33:31,398 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:33:31,402 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:33:31,407 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:33:31,411 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:33:31,417 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:33:31,421 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:33:44,457 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5893
en_de Dev loss: 1.0153 r:0.1627
en_zh Dev loss: 0.7284 r:0.3856
ro_en Dev loss: 0.4103 r:0.7496
et_en Dev loss: 0.3652 r:0.6965
si_en Dev loss: 0.5897 r:0.5735
ne_en Dev loss: 0.4013 r:0.7141
ru_en Dev loss: 0.4353 r:0.7393
Current avg r:0.5745 Best avg r: 0.5745
15:37:37,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:50,799 root INFO 
id:en_zh cur r: 0.3962 best r: 0.3962
15:38:03,830 root INFO 
id:ro_en cur r: 0.7669 best r: 0.7669
15:38:16,882 root INFO 
id:et_en cur r: 0.7000 best r: 0.7000
15:38:29,965 root INFO 
id:si_en cur r: 0.5781 best r: 0.5781
15:38:43,35 root INFO 
id:ne_en cur r: 0.7363 best r: 0.7363
15:38:56,6 root INFO 
id:ru_en cur r: 0.7536 best r: 0.7536
15:38:56,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:27,149 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:40:27,154 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:40:27,159 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:40:27,163 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:40:27,168 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:40:27,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:40:27,177 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:40:40,211 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5873
en_de Dev loss: 1.0020 r:0.1697
en_zh Dev loss: 0.7087 r:0.4067
ro_en Dev loss: 0.3940 r:0.7662
et_en Dev loss: 0.3512 r:0.7117
si_en Dev loss: 0.5667 r:0.5933
ne_en Dev loss: 0.3804 r:0.7283
ru_en Dev loss: 0.3922 r:0.7633
Current avg r:0.5913 Best avg r: 0.5913
15:44:33,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:46,541 root INFO 
id:en_zh cur r: 0.4023 best r: 0.4023
15:44:59,567 root INFO 
id:ro_en cur r: 0.7812 best r: 0.7812
15:45:12,610 root INFO 
id:et_en cur r: 0.7096 best r: 0.7096
15:45:25,662 root INFO 
id:si_en cur r: 0.5810 best r: 0.5810
15:45:38,732 root INFO 
id:ne_en cur r: 0.7379 best r: 0.7379
15:45:51,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:22,774 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:47:22,781 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:47:22,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:47:22,791 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:47:22,795 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:47:22,800 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:47:22,805 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:47:35,830 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5695
en_de Dev loss: 1.0115 r:0.1650
en_zh Dev loss: 0.7096 r:0.4091
ro_en Dev loss: 0.3704 r:0.7765
et_en Dev loss: 0.3476 r:0.7168
si_en Dev loss: 0.5909 r:0.5970
ne_en Dev loss: 0.4187 r:0.7306
ru_en Dev loss: 0.3984 r:0.7599
Current avg r:0.5936 Best avg r: 0.5936
15:51:29,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:55,111 root INFO 
id:ro_en cur r: 0.7884 best r: 0.7884
15:52:21,192 root INFO 
id:si_en cur r: 0.5842 best r: 0.5842
15:52:34,236 root INFO 
id:ne_en cur r: 0.7423 best r: 0.7423
15:52:47,187 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:18,250 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:54:18,256 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:54:18,261 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:54:18,265 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:54:18,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:54:18,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:54:18,278 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:54:31,320 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5584
en_de Dev loss: 1.0112 r:0.1785
en_zh Dev loss: 0.7159 r:0.4101
ro_en Dev loss: 0.3694 r:0.7848
et_en Dev loss: 0.3499 r:0.7140
si_en Dev loss: 0.5915 r:0.6027
ne_en Dev loss: 0.3920 r:0.7370
ru_en Dev loss: 0.4314 r:0.7494
Current avg r:0.5967 Best avg r: 0.5967
15:58:24,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:37,566 root INFO 
id:en_zh cur r: 0.4274 best r: 0.4274
15:58:50,607 root INFO 
id:ro_en cur r: 0.7906 best r: 0.7906
15:59:03,655 root INFO 
id:et_en cur r: 0.7138 best r: 0.7138
15:59:16,705 root INFO 
id:si_en cur r: 0.5931 best r: 0.5931
15:59:29,740 root INFO 
id:ne_en cur r: 0.7486 best r: 0.7486
15:59:42,704 root INFO 
id:ru_en cur r: 0.7551 best r: 0.7551
15:59:42,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:13,835 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
16:01:13,841 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:01:13,846 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:01:13,851 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
16:01:13,855 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
16:01:13,860 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:01:13,865 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:01:26,910 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5602
en_de Dev loss: 1.0415 r:0.1787
en_zh Dev loss: 0.7233 r:0.4299
ro_en Dev loss: 0.3449 r:0.7900
et_en Dev loss: 0.3490 r:0.7181
si_en Dev loss: 0.6564 r:0.5990
ne_en Dev loss: 0.3983 r:0.7398
ru_en Dev loss: 0.4267 r:0.7581
Current avg r:0.6019 Best avg r: 0.6019
16:05:20,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:33,102 root INFO 
id:en_zh cur r: 0.4352 best r: 0.4352
16:05:46,118 root INFO 
id:ro_en cur r: 0.7980 best r: 0.7980
16:05:59,176 root INFO 
id:et_en cur r: 0.7162 best r: 0.7162
16:06:12,237 root INFO 
id:si_en cur r: 0.5998 best r: 0.5998
16:06:25,281 root INFO 
id:ne_en cur r: 0.7567 best r: 0.7567
16:06:38,236 root INFO 
id:ru_en cur r: 0.7655 best r: 0.7655
16:06:38,236 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:09,368 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
16:08:09,375 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:08:09,379 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:08:09,384 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
16:08:09,388 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
16:08:09,392 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:08:09,397 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:08:22,420 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5406
en_de Dev loss: 1.0464 r:0.1849
en_zh Dev loss: 0.6959 r:0.4364
ro_en Dev loss: 0.3399 r:0.7951
et_en Dev loss: 0.3497 r:0.7226
si_en Dev loss: 0.5602 r:0.6062
ne_en Dev loss: 0.3478 r:0.7521
ru_en Dev loss: 0.3601 r:0.7715
Current avg r:0.6098 Best avg r: 0.6098
16:12:15,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:41,946 root INFO 
id:ro_en cur r: 0.8040 best r: 0.8040
16:13:33,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:05,87 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5254
en_de Dev loss: 1.0754 r:0.1904
en_zh Dev loss: 0.7558 r:0.4204
ro_en Dev loss: 0.3548 r:0.8001
et_en Dev loss: 0.3518 r:0.7172
si_en Dev loss: 0.6894 r:0.5969
ne_en Dev loss: 0.4146 r:0.7435
ru_en Dev loss: 0.4360 r:0.7580
Current avg r:0.6038 Best avg r: 0.6098
16:18:58,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:24,593 root INFO 
id:ro_en cur r: 0.8128 best r: 0.8128
16:19:37,629 root INFO 
id:et_en cur r: 0.7194 best r: 0.7194
16:19:50,666 root INFO 
id:si_en cur r: 0.6031 best r: 0.6031
16:20:03,713 root INFO 
id:ne_en cur r: 0.7645 best r: 0.7645
16:20:16,668 root INFO 
id:ru_en cur r: 0.7690 best r: 0.7690
16:20:16,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:47,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
16:21:47,706 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:21:47,711 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:21:47,715 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
16:21:47,720 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
16:21:47,725 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:21:47,729 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:22:00,756 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5193
en_de Dev loss: 1.0177 r:0.2028
en_zh Dev loss: 0.7011 r:0.4327
ro_en Dev loss: 0.3156 r:0.8086
et_en Dev loss: 0.3398 r:0.7240
si_en Dev loss: 0.5569 r:0.6062
ne_en Dev loss: 0.3467 r:0.7554
ru_en Dev loss: 0.3787 r:0.7676
Current avg r:0.6139 Best avg r: 0.6139
16:25:55,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:08,88 root INFO 
id:en_zh cur r: 0.4361 best r: 0.4361
16:26:47,191 root INFO 
id:si_en cur r: 0.6127 best r: 0.6127
16:27:13,205 root INFO 
id:ru_en cur r: 0.7701 best r: 0.7701
16:27:13,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:44,299 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
16:28:44,305 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:28:44,311 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:28:44,316 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
16:28:44,321 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
16:28:44,326 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:28:44,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:28:57,377 root INFO Epoch 1 Global steps: 9600 Train loss: 0.4955
en_de Dev loss: 1.0497 r:0.2113
en_zh Dev loss: 0.7481 r:0.4358
ro_en Dev loss: 0.3396 r:0.8120
et_en Dev loss: 0.3691 r:0.7162
si_en Dev loss: 0.6327 r:0.6131
ne_en Dev loss: 0.4677 r:0.7555
ru_en Dev loss: 0.4180 r:0.7639
Current avg r:0.6154 Best avg r: 0.6154
16:32:50,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:16,935 root INFO 
id:ro_en cur r: 0.8166 best r: 0.8166
16:34:08,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:40,76 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5012
en_de Dev loss: 1.0772 r:0.1897
en_zh Dev loss: 0.7519 r:0.4304
ro_en Dev loss: 0.3409 r:0.8113
et_en Dev loss: 0.3643 r:0.7125
si_en Dev loss: 0.7077 r:0.5979
ne_en Dev loss: 0.4765 r:0.7451
ru_en Dev loss: 0.4076 r:0.7617
Current avg r:0.6069 Best avg r: 0.6154
16:39:33,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:46,281 root INFO 
id:en_zh cur r: 0.4499 best r: 0.4499
16:39:59,308 root INFO 
id:ro_en cur r: 0.8214 best r: 0.8214
16:40:38,449 root INFO 
id:ne_en cur r: 0.7667 best r: 0.7667
16:40:51,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:22,488 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5042
en_de Dev loss: 1.0694 r:0.1933
en_zh Dev loss: 0.7262 r:0.4445
ro_en Dev loss: 0.3428 r:0.8190
et_en Dev loss: 0.3644 r:0.7143
si_en Dev loss: 0.6732 r:0.6074
ne_en Dev loss: 0.4294 r:0.7552
ru_en Dev loss: 0.4470 r:0.7535
Current avg r:0.6125 Best avg r: 0.6154
16:46:15,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:33,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:04,808 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4958
en_de Dev loss: 1.1183 r:0.1796
en_zh Dev loss: 0.7413 r:0.4332
ro_en Dev loss: 0.3547 r:0.8115
et_en Dev loss: 0.3636 r:0.7172
si_en Dev loss: 0.6310 r:0.6078
ne_en Dev loss: 0.3893 r:0.7528
ru_en Dev loss: 0.4396 r:0.7477
Current avg r:0.6071 Best avg r: 0.6154
16:52:57,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:16,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:47,178 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4893
en_de Dev loss: 1.1645 r:0.1772
en_zh Dev loss: 0.7852 r:0.4182
ro_en Dev loss: 0.3824 r:0.8146
et_en Dev loss: 0.3728 r:0.7161
si_en Dev loss: 0.7075 r:0.6052
ne_en Dev loss: 0.4442 r:0.7508
ru_en Dev loss: 0.5225 r:0.7262
Current avg r:0.6012 Best avg r: 0.6154
16:59:40,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:45,460 root INFO 
id:ne_en cur r: 0.7693 best r: 0.7693
17:00:58,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:29,513 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4708
en_de Dev loss: 1.2331 r:0.1749
en_zh Dev loss: 0.8590 r:0.4194
ro_en Dev loss: 0.4468 r:0.8136
et_en Dev loss: 0.3891 r:0.7132
si_en Dev loss: 0.8259 r:0.5999
ne_en Dev loss: 0.5117 r:0.7568
ru_en Dev loss: 0.5651 r:0.7188
Current avg r:0.5995 Best avg r: 0.6154
17:06:22,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:40,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:11,927 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4808
en_de Dev loss: 1.2262 r:0.1790
en_zh Dev loss: 0.8547 r:0.4257
ro_en Dev loss: 0.4135 r:0.8125
et_en Dev loss: 0.3888 r:0.7097
si_en Dev loss: 0.8119 r:0.5944
ne_en Dev loss: 0.5025 r:0.7534
ru_en Dev loss: 0.5441 r:0.7270
Current avg r:0.6002 Best avg r: 0.6154
17:13:05,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:31,197 root INFO 
id:ro_en cur r: 0.8245 best r: 0.8245
17:14:23,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:54,390 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4694
en_de Dev loss: 1.1122 r:0.1956
en_zh Dev loss: 0.7522 r:0.4131
ro_en Dev loss: 0.3329 r:0.8199
et_en Dev loss: 0.3713 r:0.7112
si_en Dev loss: 0.7592 r:0.6018
ne_en Dev loss: 0.4874 r:0.7584
ru_en Dev loss: 0.5029 r:0.7052
Current avg r:0.6008 Best avg r: 0.6154
17:19:47,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:13,771 root INFO 
id:ro_en cur r: 0.8282 best r: 0.8282
17:20:39,885 root INFO 
id:si_en cur r: 0.6171 best r: 0.6171
17:20:52,946 root INFO 
id:ne_en cur r: 0.7735 best r: 0.7735
17:21:05,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:37,232 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4733
en_de Dev loss: 1.1895 r:0.1780
en_zh Dev loss: 0.8114 r:0.3949
ro_en Dev loss: 0.3424 r:0.8219
et_en Dev loss: 0.3536 r:0.7249
si_en Dev loss: 0.6359 r:0.6247
ne_en Dev loss: 0.4154 r:0.7703
ru_en Dev loss: 0.5017 r:0.7281
Current avg r:0.6061 Best avg r: 0.6154
17:26:30,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:56,880 root INFO 
id:ro_en cur r: 0.8317 best r: 0.8317
17:27:09,921 root INFO 
id:et_en cur r: 0.7202 best r: 0.7202
17:27:22,976 root INFO 
id:si_en cur r: 0.6217 best r: 0.6217
17:27:36,38 root INFO 
id:ne_en cur r: 0.7808 best r: 0.7808
17:27:48,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:20,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
17:29:20,110 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:29:20,115 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:29:20,119 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
17:29:20,124 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
17:29:20,129 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:29:20,133 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:29:33,191 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4740
en_de Dev loss: 1.0757 r:0.1822
en_zh Dev loss: 0.6953 r:0.4426
ro_en Dev loss: 0.2989 r:0.8248
et_en Dev loss: 0.3422 r:0.7253
si_en Dev loss: 0.6140 r:0.6245
ne_en Dev loss: 0.3383 r:0.7754
ru_en Dev loss: 0.3980 r:0.7508
Current avg r:0.6180 Best avg r: 0.6180
17:33:26,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:44,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:16,91 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4539
en_de Dev loss: 1.0925 r:0.1934
en_zh Dev loss: 0.7481 r:0.4208
ro_en Dev loss: 0.3250 r:0.8202
et_en Dev loss: 0.3661 r:0.7118
si_en Dev loss: 0.6793 r:0.6139
ne_en Dev loss: 0.5225 r:0.7678
ru_en Dev loss: 0.4666 r:0.7321
Current avg r:0.6086 Best avg r: 0.6180
17:40:09,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:27,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:58,828 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4612
en_de Dev loss: 1.0675 r:0.1994
en_zh Dev loss: 0.7479 r:0.4108
ro_en Dev loss: 0.3166 r:0.8150
et_en Dev loss: 0.3605 r:0.7071
si_en Dev loss: 0.6650 r:0.6041
ne_en Dev loss: 0.4426 r:0.7646
ru_en Dev loss: 0.4278 r:0.7351
Current avg r:0.6052 Best avg r: 0.6180
17:46:52,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:05,433 root INFO 
id:en_zh cur r: 0.4506 best r: 0.4506
17:48:10,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:41,790 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4475
en_de Dev loss: 1.1064 r:0.1978
en_zh Dev loss: 0.7415 r:0.4422
ro_en Dev loss: 0.3342 r:0.8191
et_en Dev loss: 0.3701 r:0.7115
si_en Dev loss: 0.7623 r:0.6015
ne_en Dev loss: 0.4705 r:0.7624
ru_en Dev loss: 0.4231 r:0.7482
Current avg r:0.6118 Best avg r: 0.6180
17:53:35,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:53,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:24,787 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4438
en_de Dev loss: 1.1126 r:0.1942
en_zh Dev loss: 0.7567 r:0.4356
ro_en Dev loss: 0.3400 r:0.8159
et_en Dev loss: 0.3664 r:0.7112
si_en Dev loss: 0.6819 r:0.6024
ne_en Dev loss: 0.3840 r:0.7641
ru_en Dev loss: 0.4709 r:0.7361
Current avg r:0.6085 Best avg r: 0.6180
18:00:18,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:31,466 root INFO 
id:en_zh cur r: 0.4540 best r: 0.4540
18:00:57,525 root INFO 
id:et_en cur r: 0.7226 best r: 0.7226
18:01:36,590 root INFO 
id:ru_en cur r: 0.7739 best r: 0.7739
18:01:36,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:07,744 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
18:03:07,749 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:03:07,754 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:03:07,758 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
18:03:07,763 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
18:03:07,767 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:03:07,773 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:03:20,811 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4626
en_de Dev loss: 1.0426 r:0.1903
en_zh Dev loss: 0.6864 r:0.4534
ro_en Dev loss: 0.2884 r:0.8248
et_en Dev loss: 0.3507 r:0.7250
si_en Dev loss: 0.5832 r:0.6235
ne_en Dev loss: 0.3430 r:0.7688
ru_en Dev loss: 0.3572 r:0.7720
Current avg r:0.6225 Best avg r: 0.6225
18:07:15,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:28,402 root INFO 
id:en_zh cur r: 0.4552 best r: 0.4552
18:08:33,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:04,631 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4190
en_de Dev loss: 1.1011 r:0.1935
en_zh Dev loss: 0.7228 r:0.4533
ro_en Dev loss: 0.3358 r:0.8189
et_en Dev loss: 0.3675 r:0.7114
si_en Dev loss: 0.6998 r:0.6062
ne_en Dev loss: 0.4447 r:0.7630
ru_en Dev loss: 0.4307 r:0.7470
Current avg r:0.6133 Best avg r: 0.6225
18:13:57,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:10,943 root INFO 
id:en_zh cur r: 0.4615 best r: 0.4615
18:15:16,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:47,305 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4288
en_de Dev loss: 1.0981 r:0.1846
en_zh Dev loss: 0.7220 r:0.4520
ro_en Dev loss: 0.3253 r:0.8115
et_en Dev loss: 0.3911 r:0.7101
si_en Dev loss: 0.5980 r:0.6015
ne_en Dev loss: 0.3685 r:0.7607
ru_en Dev loss: 0.4150 r:0.7442
Current avg r:0.6092 Best avg r: 0.6225
18:20:40,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:58,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:29,939 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4180
en_de Dev loss: 1.1174 r:0.1933
en_zh Dev loss: 0.7812 r:0.4210
ro_en Dev loss: 0.3275 r:0.8156
et_en Dev loss: 0.3743 r:0.7026
si_en Dev loss: 0.7161 r:0.5916
ne_en Dev loss: 0.4333 r:0.7549
ru_en Dev loss: 0.4504 r:0.7286
Current avg r:0.6011 Best avg r: 0.6225
18:27:23,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:41,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:12,512 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4299
en_de Dev loss: 1.1557 r:0.1954
en_zh Dev loss: 0.7850 r:0.4406
ro_en Dev loss: 0.3441 r:0.8182
et_en Dev loss: 0.3769 r:0.7081
si_en Dev loss: 0.7289 r:0.5960
ne_en Dev loss: 0.4041 r:0.7603
ru_en Dev loss: 0.4747 r:0.7315
Current avg r:0.6072 Best avg r: 0.6225
18:34:05,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:23,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:55,9 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4165
en_de Dev loss: 1.1004 r:0.1966
en_zh Dev loss: 0.7061 r:0.4542
ro_en Dev loss: 0.3084 r:0.8244
et_en Dev loss: 0.3675 r:0.7110
si_en Dev loss: 0.6424 r:0.6046
ne_en Dev loss: 0.3637 r:0.7667
ru_en Dev loss: 0.4174 r:0.7448
Current avg r:0.6146 Best avg r: 0.6225
18:40:48,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:01,313 root INFO 
id:en_zh cur r: 0.4716 best r: 0.4716
18:41:14,355 root INFO 
id:ro_en cur r: 0.8351 best r: 0.8351
18:42:06,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:37,655 root INFO Epoch 2 Global steps: 21600 Train loss: 0.3963
en_de Dev loss: 1.0674 r:0.1973
en_zh Dev loss: 0.6853 r:0.4618
ro_en Dev loss: 0.2960 r:0.8269
et_en Dev loss: 0.3689 r:0.7137
si_en Dev loss: 0.5825 r:0.6151
ne_en Dev loss: 0.3351 r:0.7706
ru_en Dev loss: 0.3943 r:0.7483
Current avg r:0.6191 Best avg r: 0.6225
18:47:31,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:49,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:20,614 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4077
en_de Dev loss: 1.1907 r:0.1981
en_zh Dev loss: 0.8057 r:0.4456
ro_en Dev loss: 0.3970 r:0.8202
et_en Dev loss: 0.4198 r:0.6979
si_en Dev loss: 0.9305 r:0.5889
ne_en Dev loss: 0.6296 r:0.7577
ru_en Dev loss: 0.5199 r:0.7276
Current avg r:0.6051 Best avg r: 0.6225
18:54:14,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:27,143 root INFO 
id:en_zh cur r: 0.4793 best r: 0.4793
18:54:40,168 root INFO 
id:ro_en cur r: 0.8361 best r: 0.8361
18:55:32,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:03,432 root INFO Epoch 2 Global steps: 22800 Train loss: 0.3940
en_de Dev loss: 1.1446 r:0.1882
en_zh Dev loss: 0.7070 r:0.4707
ro_en Dev loss: 0.3214 r:0.8323
et_en Dev loss: 0.3781 r:0.7103
si_en Dev loss: 0.7143 r:0.6229
ne_en Dev loss: 0.4404 r:0.7684
ru_en Dev loss: 0.4302 r:0.7516
Current avg r:0.6206 Best avg r: 0.6225
19:00:56,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:15,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:46,368 root INFO Epoch 2 Global steps: 23400 Train loss: 0.3903
en_de Dev loss: 1.1568 r:0.1869
en_zh Dev loss: 0.7613 r:0.4554
ro_en Dev loss: 0.3447 r:0.8230
et_en Dev loss: 0.3898 r:0.7031
si_en Dev loss: 0.7037 r:0.6085
ne_en Dev loss: 0.4343 r:0.7627
ru_en Dev loss: 0.4688 r:0.7341
Current avg r:0.6105 Best avg r: 0.6225
19:07:39,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:58,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:29,324 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4120
en_de Dev loss: 1.0470 r:0.2041
en_zh Dev loss: 0.6996 r:0.4608
ro_en Dev loss: 0.2870 r:0.8301
et_en Dev loss: 0.3564 r:0.7102
si_en Dev loss: 0.5868 r:0.6161
ne_en Dev loss: 0.4354 r:0.7653
ru_en Dev loss: 0.3936 r:0.7477
Current avg r:0.6192 Best avg r: 0.6225
19:14:22,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:41,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:12,185 root INFO Epoch 2 Global steps: 24600 Train loss: 0.3869
en_de Dev loss: 1.1753 r:0.2020
en_zh Dev loss: 0.7864 r:0.4534
ro_en Dev loss: 0.3442 r:0.8268
et_en Dev loss: 0.3936 r:0.7025
si_en Dev loss: 0.7180 r:0.6058
ne_en Dev loss: 0.4674 r:0.7699
ru_en Dev loss: 0.4726 r:0.7345
Current avg r:0.6136 Best avg r: 0.6225
19:21:05,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:23,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:54,604 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3885
en_de Dev loss: 1.1207 r:0.1988
en_zh Dev loss: 0.7211 r:0.4619
ro_en Dev loss: 0.3281 r:0.8247
et_en Dev loss: 0.3831 r:0.7025
si_en Dev loss: 0.7534 r:0.5997
ne_en Dev loss: 0.4642 r:0.7630
ru_en Dev loss: 0.4805 r:0.7229
Current avg r:0.6105 Best avg r: 0.6225
19:27:47,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:05,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:36,956 root INFO Epoch 2 Global steps: 25800 Train loss: 0.3940
en_de Dev loss: 1.0653 r:0.1946
en_zh Dev loss: 0.6995 r:0.4605
ro_en Dev loss: 0.2966 r:0.8236
et_en Dev loss: 0.3753 r:0.6960
si_en Dev loss: 0.6813 r:0.5920
ne_en Dev loss: 0.4433 r:0.7600
ru_en Dev loss: 0.4225 r:0.7289
Current avg r:0.6080 Best avg r: 0.6225
19:34:30,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:48,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:19,317 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4062
en_de Dev loss: 1.1157 r:0.1880
en_zh Dev loss: 0.6873 r:0.4817
ro_en Dev loss: 0.3079 r:0.8277
et_en Dev loss: 0.3877 r:0.7051
si_en Dev loss: 0.6624 r:0.6093
ne_en Dev loss: 0.4340 r:0.7653
ru_en Dev loss: 0.4304 r:0.7385
Current avg r:0.6165 Best avg r: 0.6225
19:41:12,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:38,538 root INFO 
id:ro_en cur r: 0.8370 best r: 0.8370
19:42:30,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:01,726 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4034
en_de Dev loss: 1.0713 r:0.1819
en_zh Dev loss: 0.6924 r:0.4602
ro_en Dev loss: 0.2870 r:0.8324
et_en Dev loss: 0.3945 r:0.7115
si_en Dev loss: 0.5788 r:0.6155
ne_en Dev loss: 0.3317 r:0.7706
ru_en Dev loss: 0.3739 r:0.7539
Current avg r:0.6180 Best avg r: 0.6225
19:47:55,895 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:21,869 root INFO 
id:ro_en cur r: 0.8385 best r: 0.8385
19:49:13,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:44,923 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3766
en_de Dev loss: 1.1851 r:0.1775
en_zh Dev loss: 0.7415 r:0.4618
ro_en Dev loss: 0.3225 r:0.8327
et_en Dev loss: 0.3841 r:0.7126
si_en Dev loss: 0.6536 r:0.6194
ne_en Dev loss: 0.3510 r:0.7711
ru_en Dev loss: 0.3964 r:0.7642
Current avg r:0.6199 Best avg r: 0.6225
19:54:38,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:56,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:27,86 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3644
en_de Dev loss: 1.1679 r:0.1858
en_zh Dev loss: 0.7506 r:0.4634
ro_en Dev loss: 0.3431 r:0.8271
et_en Dev loss: 0.4010 r:0.6959
si_en Dev loss: 0.7305 r:0.6055
ne_en Dev loss: 0.4589 r:0.7626
ru_en Dev loss: 0.4253 r:0.7495
Current avg r:0.6128 Best avg r: 0.6225
20:01:20,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:38,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:09,192 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3620
en_de Dev loss: 1.1268 r:0.1812
en_zh Dev loss: 0.7313 r:0.4534
ro_en Dev loss: 0.3189 r:0.8226
et_en Dev loss: 0.3852 r:0.6950
si_en Dev loss: 0.7629 r:0.5971
ne_en Dev loss: 0.4764 r:0.7570
ru_en Dev loss: 0.4121 r:0.7415
Current avg r:0.6068 Best avg r: 0.6225
20:08:02,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:20,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:51,374 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3357
en_de Dev loss: 1.1736 r:0.1966
en_zh Dev loss: 0.7673 r:0.4462
ro_en Dev loss: 0.3401 r:0.8197
et_en Dev loss: 0.4162 r:0.6873
si_en Dev loss: 0.7182 r:0.6015
ne_en Dev loss: 0.4264 r:0.7568
ru_en Dev loss: 0.4750 r:0.7215
Current avg r:0.6042 Best avg r: 0.6225
20:14:44,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:02,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:33,620 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3557
en_de Dev loss: 1.1427 r:0.1896
en_zh Dev loss: 0.7245 r:0.4633
ro_en Dev loss: 0.3080 r:0.8257
et_en Dev loss: 0.3992 r:0.6906
si_en Dev loss: 0.7247 r:0.6024
ne_en Dev loss: 0.4493 r:0.7622
ru_en Dev loss: 0.4141 r:0.7479
Current avg r:0.6117 Best avg r: 0.6225
20:21:26,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:39,764 root INFO 
id:en_zh cur r: 0.4824 best r: 0.4824
20:22:44,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:15,867 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3520
en_de Dev loss: 1.0880 r:0.1840
en_zh Dev loss: 0.6830 r:0.4747
ro_en Dev loss: 0.2794 r:0.8302
et_en Dev loss: 0.3986 r:0.6999
si_en Dev loss: 0.5888 r:0.6174
ne_en Dev loss: 0.3615 r:0.7624
ru_en Dev loss: 0.3769 r:0.7553
Current avg r:0.6177 Best avg r: 0.6225
20:28:09,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:27,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:58,151 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3451
en_de Dev loss: 1.1579 r:0.1859
en_zh Dev loss: 0.7150 r:0.4686
ro_en Dev loss: 0.2974 r:0.8299
et_en Dev loss: 0.3959 r:0.6965
si_en Dev loss: 0.7431 r:0.6054
ne_en Dev loss: 0.4215 r:0.7556
ru_en Dev loss: 0.3918 r:0.7586
Current avg r:0.6144 Best avg r: 0.6225
20:34:51,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:09,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:40,418 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3443
en_de Dev loss: 1.1301 r:0.1883
en_zh Dev loss: 0.7107 r:0.4709
ro_en Dev loss: 0.3088 r:0.8266
et_en Dev loss: 0.3993 r:0.6962
si_en Dev loss: 0.6713 r:0.6048
ne_en Dev loss: 0.4435 r:0.7586
ru_en Dev loss: 0.3965 r:0.7539
Current avg r:0.6142 Best avg r: 0.6225
20:41:33,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:51,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:22,903 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3373
en_de Dev loss: 1.1884 r:0.1842
en_zh Dev loss: 0.7500 r:0.4688
ro_en Dev loss: 0.3173 r:0.8282
et_en Dev loss: 0.4048 r:0.6989
si_en Dev loss: 0.7231 r:0.6020
ne_en Dev loss: 0.4271 r:0.7621
ru_en Dev loss: 0.4328 r:0.7480
Current avg r:0.6132 Best avg r: 0.6225
20:48:16,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:34,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:05,497 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3407
en_de Dev loss: 1.1939 r:0.1882
en_zh Dev loss: 0.7583 r:0.4546
ro_en Dev loss: 0.3422 r:0.8204
et_en Dev loss: 0.4143 r:0.6966
si_en Dev loss: 0.7243 r:0.5947
ne_en Dev loss: 0.4196 r:0.7594
ru_en Dev loss: 0.4318 r:0.7466
Current avg r:0.6087 Best avg r: 0.6225
20:54:58,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:16,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:57:48,17 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3375
en_de Dev loss: 1.1460 r:0.1830
en_zh Dev loss: 0.7389 r:0.4539
ro_en Dev loss: 0.3152 r:0.8263
et_en Dev loss: 0.3881 r:0.6962
si_en Dev loss: 0.6399 r:0.6070
ne_en Dev loss: 0.4457 r:0.7596
ru_en Dev loss: 0.4158 r:0.7455
Current avg r:0.6102 Best avg r: 0.6225
21:01:41,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:59,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:30,626 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3374
en_de Dev loss: 1.1574 r:0.1875
en_zh Dev loss: 0.7562 r:0.4487
ro_en Dev loss: 0.3283 r:0.8253
et_en Dev loss: 0.3895 r:0.6962
si_en Dev loss: 0.7475 r:0.5949
ne_en Dev loss: 0.5449 r:0.7631
ru_en Dev loss: 0.4705 r:0.7308
Current avg r:0.6067 Best avg r: 0.6225
21:08:23,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:41,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:12,778 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3313
en_de Dev loss: 1.2260 r:0.1876
en_zh Dev loss: 0.7849 r:0.4563
ro_en Dev loss: 0.3627 r:0.8271
et_en Dev loss: 0.4172 r:0.6939
si_en Dev loss: 0.8397 r:0.5946
ne_en Dev loss: 0.5959 r:0.7512
ru_en Dev loss: 0.5154 r:0.7199
Current avg r:0.6044 Best avg r: 0.6225
21:15:05,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:24,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:55,184 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3406
en_de Dev loss: 1.1979 r:0.1814
en_zh Dev loss: 0.7563 r:0.4603
ro_en Dev loss: 0.3433 r:0.8242
et_en Dev loss: 0.3999 r:0.6901
si_en Dev loss: 0.7594 r:0.5929
ne_en Dev loss: 0.4902 r:0.7582
ru_en Dev loss: 0.5036 r:0.7131
Current avg r:0.6029 Best avg r: 0.6225
21:21:48,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:06,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:37,715 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3326
en_de Dev loss: 1.1376 r:0.1693
en_zh Dev loss: 0.7075 r:0.4655
ro_en Dev loss: 0.2963 r:0.8308
et_en Dev loss: 0.3935 r:0.6986
si_en Dev loss: 0.6772 r:0.5995
ne_en Dev loss: 0.4076 r:0.7627
ru_en Dev loss: 0.4292 r:0.7350
Current avg r:0.6088 Best avg r: 0.6225
21:28:32,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:29:50,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:21,103 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3045
en_de Dev loss: 1.1965 r:0.1834
en_zh Dev loss: 0.7299 r:0.4753
ro_en Dev loss: 0.3334 r:0.8268
et_en Dev loss: 0.4016 r:0.6900
si_en Dev loss: 0.7776 r:0.5926
ne_en Dev loss: 0.5576 r:0.7542
ru_en Dev loss: 0.4770 r:0.7263
Current avg r:0.6069 Best avg r: 0.6225
21:35:14,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:32,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:03,170 root INFO Epoch 4 Global steps: 37200 Train loss: 0.2998
en_de Dev loss: 1.2044 r:0.1827
en_zh Dev loss: 0.7876 r:0.4519
ro_en Dev loss: 0.3364 r:0.8236
et_en Dev loss: 0.4092 r:0.6892
si_en Dev loss: 0.7944 r:0.5933
ne_en Dev loss: 0.5082 r:0.7526
ru_en Dev loss: 0.4537 r:0.7326
Current avg r:0.6037 Best avg r: 0.6225
21:41:56,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:14,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:45,352 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3122
en_de Dev loss: 1.1880 r:0.1726
en_zh Dev loss: 0.7493 r:0.4609
ro_en Dev loss: 0.3280 r:0.8238
et_en Dev loss: 0.4219 r:0.6930
si_en Dev loss: 0.7427 r:0.5998
ne_en Dev loss: 0.4808 r:0.7512
ru_en Dev loss: 0.4397 r:0.7377
Current avg r:0.6056 Best avg r: 0.6225
21:48:38,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:56,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:27,448 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3015
en_de Dev loss: 1.1844 r:0.1692
en_zh Dev loss: 0.7866 r:0.4450
ro_en Dev loss: 0.3441 r:0.8193
et_en Dev loss: 0.4080 r:0.6819
si_en Dev loss: 0.7560 r:0.5963
ne_en Dev loss: 0.4777 r:0.7530
ru_en Dev loss: 0.5013 r:0.7134
Current avg r:0.5969 Best avg r: 0.6225
21:55:20,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:56:38,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:09,703 root INFO Epoch 4 Global steps: 39000 Train loss: 0.2989
en_de Dev loss: 1.1622 r:0.1895
en_zh Dev loss: 0.7720 r:0.4494
ro_en Dev loss: 0.3372 r:0.8246
et_en Dev loss: 0.4036 r:0.6874
si_en Dev loss: 0.7340 r:0.5997
ne_en Dev loss: 0.5159 r:0.7520
ru_en Dev loss: 0.4493 r:0.7324
Current avg r:0.6050 Best avg r: 0.6225
22:02:03,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:21,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:52,203 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3018
en_de Dev loss: 1.2162 r:0.1979
en_zh Dev loss: 0.7982 r:0.4442
ro_en Dev loss: 0.3786 r:0.8220
et_en Dev loss: 0.4349 r:0.6732
si_en Dev loss: 0.8946 r:0.5792
ne_en Dev loss: 0.5692 r:0.7474
ru_en Dev loss: 0.4984 r:0.7151
Current avg r:0.5970 Best avg r: 0.6225
22:08:45,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:03,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:34,368 root INFO Epoch 4 Global steps: 40200 Train loss: 0.2849
en_de Dev loss: 1.2167 r:0.1991
en_zh Dev loss: 0.8057 r:0.4380
ro_en Dev loss: 0.3572 r:0.8223
et_en Dev loss: 0.4330 r:0.6770
si_en Dev loss: 0.8398 r:0.5762
ne_en Dev loss: 0.4787 r:0.7477
ru_en Dev loss: 0.4969 r:0.7112
Current avg r:0.5959 Best avg r: 0.6225
22:15:27,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:16:45,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:16,513 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3097
en_de Dev loss: 1.1872 r:0.1914
en_zh Dev loss: 0.7410 r:0.4727
ro_en Dev loss: 0.3189 r:0.8279
et_en Dev loss: 0.4121 r:0.6847
si_en Dev loss: 0.7701 r:0.5830
ne_en Dev loss: 0.4361 r:0.7497
ru_en Dev loss: 0.4633 r:0.7298
Current avg r:0.6056 Best avg r: 0.6225
22:22:09,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:27,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:58,671 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3026
en_de Dev loss: 1.1192 r:0.1987
en_zh Dev loss: 0.7116 r:0.4727
ro_en Dev loss: 0.3022 r:0.8283
et_en Dev loss: 0.3964 r:0.6864
si_en Dev loss: 0.7099 r:0.5848
ne_en Dev loss: 0.4429 r:0.7581
ru_en Dev loss: 0.4183 r:0.7403
Current avg r:0.6099 Best avg r: 0.6225
22:28:51,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:09,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:40,756 root INFO Epoch 4 Global steps: 42000 Train loss: 0.2847
en_de Dev loss: 1.1362 r:0.1929
en_zh Dev loss: 0.7311 r:0.4675
ro_en Dev loss: 0.3145 r:0.8252
et_en Dev loss: 0.4160 r:0.6867
si_en Dev loss: 0.7537 r:0.5809
ne_en Dev loss: 0.4414 r:0.7436
ru_en Dev loss: 0.4503 r:0.7300
Current avg r:0.6038 Best avg r: 0.6225
22:35:33,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:51,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:22,852 root INFO Epoch 4 Global steps: 42600 Train loss: 0.2973
en_de Dev loss: 1.2159 r:0.2074
en_zh Dev loss: 0.8011 r:0.4635
ro_en Dev loss: 0.3676 r:0.8243
et_en Dev loss: 0.4419 r:0.6838
si_en Dev loss: 0.8987 r:0.5779
ne_en Dev loss: 0.4895 r:0.7437
ru_en Dev loss: 0.5024 r:0.7315
Current avg r:0.6046 Best avg r: 0.6225
22:42:15,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:33,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:04,899 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3078
en_de Dev loss: 1.1804 r:0.1917
en_zh Dev loss: 0.7556 r:0.4753
ro_en Dev loss: 0.3304 r:0.8243
et_en Dev loss: 0.4441 r:0.6788
si_en Dev loss: 0.7473 r:0.5830
ne_en Dev loss: 0.4673 r:0.7362
ru_en Dev loss: 0.4528 r:0.7384
Current avg r:0.6040 Best avg r: 0.6225
22:48:58,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:16,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:47,58 root INFO Epoch 4 Global steps: 43800 Train loss: 0.2909
en_de Dev loss: 1.2296 r:0.1979
en_zh Dev loss: 0.8281 r:0.4525
ro_en Dev loss: 0.3893 r:0.8208
et_en Dev loss: 0.4547 r:0.6701
si_en Dev loss: 0.9825 r:0.5601
ne_en Dev loss: 0.5410 r:0.7373
ru_en Dev loss: 0.5420 r:0.7255
Current avg r:0.5949 Best avg r: 0.6225
22:55:40,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:58,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:29,237 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2847
en_de Dev loss: 1.2192 r:0.1928
en_zh Dev loss: 0.7694 r:0.4695
ro_en Dev loss: 0.3290 r:0.8304
et_en Dev loss: 0.4318 r:0.6890
si_en Dev loss: 0.7724 r:0.5864
ne_en Dev loss: 0.3989 r:0.7512
ru_en Dev loss: 0.4509 r:0.7504
Current avg r:0.6100 Best avg r: 0.6225
23:02:22,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:40,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:11,228 root INFO Epoch 4 Global steps: 45000 Train loss: 0.2836
en_de Dev loss: 1.1589 r:0.1960
en_zh Dev loss: 0.7303 r:0.4724
ro_en Dev loss: 0.3134 r:0.8273
et_en Dev loss: 0.4282 r:0.6871
si_en Dev loss: 0.6767 r:0.5891
ne_en Dev loss: 0.4090 r:0.7492
ru_en Dev loss: 0.4207 r:0.7456
Current avg r:0.6095 Best avg r: 0.6225
23:09:05,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:23,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:54,636 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2636
en_de Dev loss: 1.2769 r:0.1805
en_zh Dev loss: 0.8239 r:0.4636
ro_en Dev loss: 0.3964 r:0.8196
et_en Dev loss: 0.4699 r:0.6766
si_en Dev loss: 0.8930 r:0.5714
ne_en Dev loss: 0.5975 r:0.7417
ru_en Dev loss: 0.4964 r:0.7303
Current avg r:0.5977 Best avg r: 0.6225
23:15:47,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:05,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:36,582 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2537
en_de Dev loss: 1.1553 r:0.1848
en_zh Dev loss: 0.7230 r:0.4731
ro_en Dev loss: 0.3297 r:0.8203
et_en Dev loss: 0.4302 r:0.6726
si_en Dev loss: 0.7722 r:0.5747
ne_en Dev loss: 0.4662 r:0.7468
ru_en Dev loss: 0.4482 r:0.7312
Current avg r:0.6005 Best avg r: 0.6225
23:22:29,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:42,539 root INFO 
id:en_zh cur r: 0.4880 best r: 0.4880
23:23:47,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:18,511 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2645
en_de Dev loss: 1.2216 r:0.1901
en_zh Dev loss: 0.7475 r:0.4805
ro_en Dev loss: 0.3362 r:0.8232
et_en Dev loss: 0.4598 r:0.6771
si_en Dev loss: 0.7867 r:0.5696
ne_en Dev loss: 0.4305 r:0.7499
ru_en Dev loss: 0.4503 r:0.7359
Current avg r:0.6038 Best avg r: 0.6225
23:29:11,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:29,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:32:00,428 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2495
en_de Dev loss: 1.2999 r:0.1980
en_zh Dev loss: 0.8484 r:0.4568
ro_en Dev loss: 0.4068 r:0.8147
et_en Dev loss: 0.4894 r:0.6605
si_en Dev loss: 1.0344 r:0.5462
ne_en Dev loss: 0.5763 r:0.7392
ru_en Dev loss: 0.5590 r:0.7001
Current avg r:0.5879 Best avg r: 0.6225
23:35:53,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:11,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:42,202 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2414
en_de Dev loss: 1.2438 r:0.1807
en_zh Dev loss: 0.7870 r:0.4680
ro_en Dev loss: 0.3533 r:0.8215
et_en Dev loss: 0.4561 r:0.6695
si_en Dev loss: 0.9623 r:0.5550
ne_en Dev loss: 0.5235 r:0.7426
ru_en Dev loss: 0.4633 r:0.7282
Current avg r:0.5951 Best avg r: 0.6225
23:42:35,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:53,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:24,131 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2596
en_de Dev loss: 1.2344 r:0.1876
en_zh Dev loss: 0.7736 r:0.4744
ro_en Dev loss: 0.3391 r:0.8279
et_en Dev loss: 0.4518 r:0.6819
si_en Dev loss: 0.8157 r:0.5716
ne_en Dev loss: 0.4706 r:0.7433
ru_en Dev loss: 0.4613 r:0.7320
Current avg r:0.6027 Best avg r: 0.6225
23:49:17,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:35,130 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:06,153 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2490
en_de Dev loss: 1.2479 r:0.1825
en_zh Dev loss: 0.7935 r:0.4714
ro_en Dev loss: 0.3458 r:0.8259
et_en Dev loss: 0.4524 r:0.6720
si_en Dev loss: 0.8544 r:0.5686
ne_en Dev loss: 0.4940 r:0.7363
ru_en Dev loss: 0.4862 r:0.7254
Current avg r:0.5974 Best avg r: 0.6225
23:55:59,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:17,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:48,294 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2581
en_de Dev loss: 1.2568 r:0.1957
en_zh Dev loss: 0.8103 r:0.4561
ro_en Dev loss: 0.3633 r:0.8229
et_en Dev loss: 0.4597 r:0.6743
si_en Dev loss: 0.9334 r:0.5644
ne_en Dev loss: 0.5691 r:0.7427
ru_en Dev loss: 0.5121 r:0.7142
Current avg r:0.5958 Best avg r: 0.6225
00:02:41,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:59,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:30,979 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2444
en_de Dev loss: 1.2513 r:0.1833
en_zh Dev loss: 0.7728 r:0.4752
ro_en Dev loss: 0.3387 r:0.8283
et_en Dev loss: 0.4902 r:0.6816
si_en Dev loss: 0.7792 r:0.5761
ne_en Dev loss: 0.4798 r:0.7408
ru_en Dev loss: 0.4669 r:0.7290
Current avg r:0.6021 Best avg r: 0.6225
00:09:24,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:42,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:13,501 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2302
en_de Dev loss: 1.2409 r:0.1906
en_zh Dev loss: 0.7692 r:0.4747
ro_en Dev loss: 0.3444 r:0.8240
et_en Dev loss: 0.4794 r:0.6742
si_en Dev loss: 0.8035 r:0.5715
ne_en Dev loss: 0.4782 r:0.7415
ru_en Dev loss: 0.4542 r:0.7283
Current avg r:0.6007 Best avg r: 0.6225
00:16:06,403 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:24,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:18:55,286 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2486
en_de Dev loss: 1.1882 r:0.1972
en_zh Dev loss: 0.7511 r:0.4659
ro_en Dev loss: 0.3232 r:0.8252
et_en Dev loss: 0.4237 r:0.6780
si_en Dev loss: 0.8092 r:0.5704
ne_en Dev loss: 0.5228 r:0.7422
ru_en Dev loss: 0.4608 r:0.7275
Current avg r:0.6009 Best avg r: 0.6225
00:22:48,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:06,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:37,428 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2411
en_de Dev loss: 1.2021 r:0.1863
en_zh Dev loss: 0.7621 r:0.4647
ro_en Dev loss: 0.3158 r:0.8271
et_en Dev loss: 0.4469 r:0.6833
si_en Dev loss: 0.7684 r:0.5679
ne_en Dev loss: 0.4376 r:0.7365
ru_en Dev loss: 0.4328 r:0.7359
Current avg r:0.6003 Best avg r: 0.6225
00:29:30,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:30:48,401 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:19,368 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2381
en_de Dev loss: 1.2260 r:0.1915
en_zh Dev loss: 0.7967 r:0.4552
ro_en Dev loss: 0.3531 r:0.8239
et_en Dev loss: 0.4536 r:0.6673
si_en Dev loss: 0.9119 r:0.5529
ne_en Dev loss: 0.5542 r:0.7363
ru_en Dev loss: 0.4661 r:0.7280
Current avg r:0.5936 Best avg r: 0.6225
00:36:12,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:30,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:01,333 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2346
en_de Dev loss: 1.2231 r:0.2028
en_zh Dev loss: 0.7734 r:0.4727
ro_en Dev loss: 0.3449 r:0.8241
et_en Dev loss: 0.4669 r:0.6737
si_en Dev loss: 0.8079 r:0.5647
ne_en Dev loss: 0.4990 r:0.7392
ru_en Dev loss: 0.4627 r:0.7307
Current avg r:0.6011 Best avg r: 0.6225
00:42:54,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:12,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:43,90 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2366
en_de Dev loss: 1.1759 r:0.1989
en_zh Dev loss: 0.7882 r:0.4549
ro_en Dev loss: 0.3260 r:0.8211
et_en Dev loss: 0.4568 r:0.6712
si_en Dev loss: 0.8230 r:0.5577
ne_en Dev loss: 0.4776 r:0.7403
ru_en Dev loss: 0.4587 r:0.7147
Current avg r:0.5941 Best avg r: 0.6225
00:49:37,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:55,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:26,614 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2273
en_de Dev loss: 1.1562 r:0.1973
en_zh Dev loss: 0.7521 r:0.4685
ro_en Dev loss: 0.3122 r:0.8257
et_en Dev loss: 0.4258 r:0.6665
si_en Dev loss: 0.8183 r:0.5570
ne_en Dev loss: 0.5512 r:0.7364
ru_en Dev loss: 0.4745 r:0.7110
Current avg r:0.5946 Best avg r: 0.6225
00:56:19,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:37,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:08,688 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2164
en_de Dev loss: 1.2621 r:0.1877
en_zh Dev loss: 0.8040 r:0.4698
ro_en Dev loss: 0.3553 r:0.8216
et_en Dev loss: 0.4726 r:0.6582
si_en Dev loss: 0.9369 r:0.5493
ne_en Dev loss: 0.6184 r:0.7377
ru_en Dev loss: 0.5239 r:0.7021
Current avg r:0.5895 Best avg r: 0.6225
01:03:01,654 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:19,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:50,566 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2031
en_de Dev loss: 1.2229 r:0.1947
en_zh Dev loss: 0.8014 r:0.4568
ro_en Dev loss: 0.3244 r:0.8260
et_en Dev loss: 0.4539 r:0.6746
si_en Dev loss: 0.8218 r:0.5613
ne_en Dev loss: 0.5028 r:0.7416
ru_en Dev loss: 0.4912 r:0.7109
Current avg r:0.5951 Best avg r: 0.6225
01:09:43,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:01,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:32,263 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2171
en_de Dev loss: 1.1876 r:0.1932
en_zh Dev loss: 0.7530 r:0.4696
ro_en Dev loss: 0.3103 r:0.8285
et_en Dev loss: 0.4993 r:0.6871
si_en Dev loss: 0.7266 r:0.5736
ne_en Dev loss: 0.4213 r:0.7418
ru_en Dev loss: 0.4080 r:0.7451
Current avg r:0.6056 Best avg r: 0.6225
01:16:25,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:43,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:14,123 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2213
en_de Dev loss: 1.2017 r:0.1890
en_zh Dev loss: 0.7948 r:0.4513
ro_en Dev loss: 0.3413 r:0.8196
et_en Dev loss: 0.4667 r:0.6630
si_en Dev loss: 0.7813 r:0.5595
ne_en Dev loss: 0.4568 r:0.7367
ru_en Dev loss: 0.4796 r:0.7111
Current avg r:0.5900 Best avg r: 0.6225
01:23:06,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:19,887 root INFO 
id:en_zh cur r: 0.4881 best r: 0.4881
01:24:24,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:55,928 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2088
en_de Dev loss: 1.2121 r:0.1832
en_zh Dev loss: 0.7527 r:0.4772
ro_en Dev loss: 0.3163 r:0.8305
et_en Dev loss: 0.4523 r:0.6769
si_en Dev loss: 0.8261 r:0.5629
ne_en Dev loss: 0.4958 r:0.7387
ru_en Dev loss: 0.4453 r:0.7363
Current avg r:0.6008 Best avg r: 0.6225
01:29:48,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:06,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:37,938 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2013
en_de Dev loss: 1.1825 r:0.1817
en_zh Dev loss: 0.7674 r:0.4517
ro_en Dev loss: 0.3088 r:0.8260
et_en Dev loss: 0.4585 r:0.6659
si_en Dev loss: 0.8107 r:0.5527
ne_en Dev loss: 0.4867 r:0.7430
ru_en Dev loss: 0.4770 r:0.7064
Current avg r:0.5897 Best avg r: 0.6225
01:36:30,767 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:37:48,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:19,696 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2142
en_de Dev loss: 1.2255 r:0.2034
en_zh Dev loss: 0.7762 r:0.4668
ro_en Dev loss: 0.3368 r:0.8236
et_en Dev loss: 0.4810 r:0.6638
si_en Dev loss: 0.8324 r:0.5583
ne_en Dev loss: 0.5029 r:0.7358
ru_en Dev loss: 0.4614 r:0.7311
Current avg r:0.5976 Best avg r: 0.6225
01:43:12,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:30,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:46:01,825 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2036
en_de Dev loss: 1.1651 r:0.2113
en_zh Dev loss: 0.7546 r:0.4653
ro_en Dev loss: 0.3191 r:0.8229
et_en Dev loss: 0.4563 r:0.6605
si_en Dev loss: 0.8330 r:0.5523
ne_en Dev loss: 0.5337 r:0.7283
ru_en Dev loss: 0.4286 r:0.7380
Current avg r:0.5970 Best avg r: 0.6225
01:49:54,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:12,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:43,976 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2072
en_de Dev loss: 1.2476 r:0.1915
en_zh Dev loss: 0.7961 r:0.4716
ro_en Dev loss: 0.3489 r:0.8198
et_en Dev loss: 0.4958 r:0.6608
si_en Dev loss: 0.8691 r:0.5547
ne_en Dev loss: 0.5082 r:0.7255
ru_en Dev loss: 0.4463 r:0.7359
Current avg r:0.5943 Best avg r: 0.6225
01:56:37,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:55,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:27,531 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2014
en_de Dev loss: 1.1987 r:0.1957
en_zh Dev loss: 0.7573 r:0.4740
ro_en Dev loss: 0.3147 r:0.8276
et_en Dev loss: 0.4461 r:0.6761
si_en Dev loss: 0.7323 r:0.5695
ne_en Dev loss: 0.5088 r:0.7265
ru_en Dev loss: 0.4162 r:0.7484
Current avg r:0.6026 Best avg r: 0.6225
02:03:26,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:04:46,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:06:19,440 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2074
en_de Dev loss: 1.2015 r:0.1996
en_zh Dev loss: 0.7659 r:0.4667
ro_en Dev loss: 0.3267 r:0.8244
et_en Dev loss: 0.4770 r:0.6656
si_en Dev loss: 0.7829 r:0.5560
ne_en Dev loss: 0.4631 r:0.7283
ru_en Dev loss: 0.4526 r:0.7261
Current avg r:0.5952 Best avg r: 0.6225
02:10:18,196 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:11:37,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:13:10,21 root INFO Epoch 6 Global steps: 61800 Train loss: 0.1986
en_de Dev loss: 1.2551 r:0.1942
en_zh Dev loss: 0.8058 r:0.4653
ro_en Dev loss: 0.3345 r:0.8271
et_en Dev loss: 0.4871 r:0.6578
si_en Dev loss: 0.8554 r:0.5510
ne_en Dev loss: 0.5251 r:0.7315
ru_en Dev loss: 0.4762 r:0.7228
Current avg r:0.5928 Best avg r: 0.6225
02:17:08,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:18:27,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:20:00,343 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2008
en_de Dev loss: 1.2633 r:0.2026
en_zh Dev loss: 0.8213 r:0.4625
ro_en Dev loss: 0.3528 r:0.8241
et_en Dev loss: 0.4854 r:0.6557
si_en Dev loss: 0.9028 r:0.5413
ne_en Dev loss: 0.5356 r:0.7316
ru_en Dev loss: 0.4934 r:0.7211
Current avg r:0.5913 Best avg r: 0.6225
02:23:59,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:25:18,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:26:50,745 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2065
en_de Dev loss: 1.2601 r:0.1977
en_zh Dev loss: 0.8238 r:0.4590
ro_en Dev loss: 0.3640 r:0.8230
et_en Dev loss: 0.4719 r:0.6506
si_en Dev loss: 0.9521 r:0.5427
ne_en Dev loss: 0.6459 r:0.7247
ru_en Dev loss: 0.5099 r:0.7147
Current avg r:0.5875 Best avg r: 0.6225
02:30:50,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:32:09,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:33:41,13 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1803
en_de Dev loss: 1.2517 r:0.1911
en_zh Dev loss: 0.8140 r:0.4559
ro_en Dev loss: 0.3492 r:0.8234
et_en Dev loss: 0.4639 r:0.6573
si_en Dev loss: 0.8929 r:0.5412
ne_en Dev loss: 0.5461 r:0.7228
ru_en Dev loss: 0.4671 r:0.7300
Current avg r:0.5888 Best avg r: 0.6225
02:37:35,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:38:54,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:40:25,760 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1785
en_de Dev loss: 1.2563 r:0.1972
en_zh Dev loss: 0.8078 r:0.4632
ro_en Dev loss: 0.3572 r:0.8218
et_en Dev loss: 0.5213 r:0.6684
si_en Dev loss: 0.8479 r:0.5540
ne_en Dev loss: 0.5263 r:0.7293
ru_en Dev loss: 0.4681 r:0.7254
Current avg r:0.5942 Best avg r: 0.6225
02:44:20,286 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:45:38,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:47:10,270 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1833
en_de Dev loss: 1.1893 r:0.2048
en_zh Dev loss: 0.7519 r:0.4770
ro_en Dev loss: 0.3199 r:0.8266
et_en Dev loss: 0.4704 r:0.6738
si_en Dev loss: 0.7993 r:0.5588
ne_en Dev loss: 0.4831 r:0.7348
ru_en Dev loss: 0.4545 r:0.7277
Current avg r:0.6005 Best avg r: 0.6225
02:51:04,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:52:23,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:56,142 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1789
en_de Dev loss: 1.1840 r:0.2023
en_zh Dev loss: 0.7548 r:0.4726
ro_en Dev loss: 0.3191 r:0.8278
et_en Dev loss: 0.4631 r:0.6617
si_en Dev loss: 0.8287 r:0.5529
ne_en Dev loss: 0.5129 r:0.7371
ru_en Dev loss: 0.4479 r:0.7304
Current avg r:0.5978 Best avg r: 0.6225
02:57:53,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:59:12,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:45,208 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1854
en_de Dev loss: 1.1957 r:0.1915
en_zh Dev loss: 0.7395 r:0.4785
ro_en Dev loss: 0.3076 r:0.8293
et_en Dev loss: 0.4790 r:0.6654
si_en Dev loss: 0.8040 r:0.5510
ne_en Dev loss: 0.4855 r:0.7315
ru_en Dev loss: 0.4116 r:0.7437
Current avg r:0.5987 Best avg r: 0.6225
03:04:42,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:06:01,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:07:34,28 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1815
en_de Dev loss: 1.2168 r:0.1983
en_zh Dev loss: 0.7692 r:0.4683
ro_en Dev loss: 0.3402 r:0.8229
et_en Dev loss: 0.5131 r:0.6694
si_en Dev loss: 0.8214 r:0.5487
ne_en Dev loss: 0.4473 r:0.7302
ru_en Dev loss: 0.4224 r:0.7451
Current avg r:0.5976 Best avg r: 0.6225
03:11:31,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:12:50,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:22,829 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1791
en_de Dev loss: 1.2552 r:0.1905
en_zh Dev loss: 0.7979 r:0.4687
ro_en Dev loss: 0.3346 r:0.8276
et_en Dev loss: 0.4845 r:0.6672
si_en Dev loss: 0.8616 r:0.5549
ne_en Dev loss: 0.4796 r:0.7339
ru_en Dev loss: 0.4310 r:0.7497
Current avg r:0.5989 Best avg r: 0.6225
03:18:18,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:19:36,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:21:08,433 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1843
en_de Dev loss: 1.2630 r:0.1889
en_zh Dev loss: 0.7986 r:0.4640
ro_en Dev loss: 0.3444 r:0.8240
et_en Dev loss: 0.4887 r:0.6508
si_en Dev loss: 0.8851 r:0.5442
ne_en Dev loss: 0.4855 r:0.7231
ru_en Dev loss: 0.4444 r:0.7373
Current avg r:0.5903 Best avg r: 0.6225
03:25:03,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:26:21,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:27:53,217 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1838
en_de Dev loss: 1.2331 r:0.1958
en_zh Dev loss: 0.7699 r:0.4759
ro_en Dev loss: 0.3186 r:0.8298
et_en Dev loss: 0.4815 r:0.6808
si_en Dev loss: 0.8025 r:0.5604
ne_en Dev loss: 0.4673 r:0.7281
ru_en Dev loss: 0.4152 r:0.7511
Current avg r:0.6032 Best avg r: 0.6225
03:31:48,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:33:06,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:34:38,891 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1778
en_de Dev loss: 1.2513 r:0.1959
en_zh Dev loss: 0.7905 r:0.4709
ro_en Dev loss: 0.3447 r:0.8227
et_en Dev loss: 0.4823 r:0.6658
si_en Dev loss: 0.8570 r:0.5470
ne_en Dev loss: 0.4732 r:0.7212
ru_en Dev loss: 0.4464 r:0.7427
Current avg r:0.5952 Best avg r: 0.6225
03:38:36,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:39:55,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:27,681 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1727
en_de Dev loss: 1.2371 r:0.1977
en_zh Dev loss: 0.7957 r:0.4639
ro_en Dev loss: 0.3393 r:0.8238
et_en Dev loss: 0.4854 r:0.6608
si_en Dev loss: 0.8790 r:0.5454
ne_en Dev loss: 0.5324 r:0.7273
ru_en Dev loss: 0.4557 r:0.7341
Current avg r:0.5933 Best avg r: 0.6225
03:45:25,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:46:44,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:48:16,350 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1722
en_de Dev loss: 1.2143 r:0.2006
en_zh Dev loss: 0.7894 r:0.4592
ro_en Dev loss: 0.3259 r:0.8257
et_en Dev loss: 0.4978 r:0.6657
si_en Dev loss: 0.8157 r:0.5485
ne_en Dev loss: 0.5011 r:0.7229
ru_en Dev loss: 0.4303 r:0.7479
Current avg r:0.5958 Best avg r: 0.6225
03:52:14,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:53:33,458 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:55:05,690 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1731
en_de Dev loss: 1.2521 r:0.1938
en_zh Dev loss: 0.7939 r:0.4719
ro_en Dev loss: 0.3436 r:0.8252
et_en Dev loss: 0.4826 r:0.6556
si_en Dev loss: 0.8956 r:0.5446
ne_en Dev loss: 0.5553 r:0.7260
ru_en Dev loss: 0.4593 r:0.7434
Current avg r:0.5944 Best avg r: 0.6225
03:59:02,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:00:20,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:01:51,996 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1853
en_de Dev loss: 1.1907 r:0.1928
en_zh Dev loss: 0.7617 r:0.4705
ro_en Dev loss: 0.3242 r:0.8264
et_en Dev loss: 0.4628 r:0.6485
si_en Dev loss: 0.8840 r:0.5380
ne_en Dev loss: 0.5608 r:0.7187
ru_en Dev loss: 0.4467 r:0.7379
Current avg r:0.5904 Best avg r: 0.6225
04:05:47,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:07:07,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:39,294 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1764
en_de Dev loss: 1.2266 r:0.1884
en_zh Dev loss: 0.7767 r:0.4707
ro_en Dev loss: 0.3310 r:0.8250
et_en Dev loss: 0.4902 r:0.6466
si_en Dev loss: 0.8432 r:0.5445
ne_en Dev loss: 0.5168 r:0.7190
ru_en Dev loss: 0.4443 r:0.7378
Current avg r:0.5903 Best avg r: 0.6225
04:12:38,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:12:51,917 root INFO 
id:en_zh cur r: 0.4892 best r: 0.4892
04:13:57,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:30,97 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1500
en_de Dev loss: 1.2632 r:0.1902
en_zh Dev loss: 0.7886 r:0.4809
ro_en Dev loss: 0.3419 r:0.8259
et_en Dev loss: 0.5023 r:0.6584
si_en Dev loss: 0.8530 r:0.5559
ne_en Dev loss: 0.5217 r:0.7239
ru_en Dev loss: 0.4410 r:0.7472
Current avg r:0.5975 Best avg r: 0.6225
04:19:28,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:20:47,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:22:20,161 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1599
en_de Dev loss: 1.2138 r:0.1921
en_zh Dev loss: 0.7643 r:0.4753
ro_en Dev loss: 0.3436 r:0.8221
et_en Dev loss: 0.4663 r:0.6467
si_en Dev loss: 0.9810 r:0.5327
ne_en Dev loss: 0.6748 r:0.7162
ru_en Dev loss: 0.4763 r:0.7225
Current avg r:0.5868 Best avg r: 0.6225
04:26:18,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:27:37,729 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:29:10,145 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1667
en_de Dev loss: 1.2206 r:0.1815
en_zh Dev loss: 0.7591 r:0.4798
ro_en Dev loss: 0.3561 r:0.8182
et_en Dev loss: 0.4770 r:0.6493
si_en Dev loss: 0.9264 r:0.5328
ne_en Dev loss: 0.6354 r:0.7245
ru_en Dev loss: 0.4538 r:0.7310
Current avg r:0.5882 Best avg r: 0.6225
04:33:07,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:33:20,462 root INFO 
id:en_zh cur r: 0.4950 best r: 0.4950
04:34:26,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:35:58,614 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1651
en_de Dev loss: 1.2104 r:0.1860
en_zh Dev loss: 0.7356 r:0.4935
ro_en Dev loss: 0.3246 r:0.8270
et_en Dev loss: 0.4971 r:0.6637
si_en Dev loss: 0.8236 r:0.5430
ne_en Dev loss: 0.5260 r:0.7185
ru_en Dev loss: 0.4244 r:0.7414
Current avg r:0.5962 Best avg r: 0.6225
04:39:55,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:41:14,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:42:46,366 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1544
en_de Dev loss: 1.2549 r:0.1814
en_zh Dev loss: 0.7820 r:0.4818
ro_en Dev loss: 0.3565 r:0.8225
et_en Dev loss: 0.4997 r:0.6557
si_en Dev loss: 0.9058 r:0.5373
ne_en Dev loss: 0.5496 r:0.7232
ru_en Dev loss: 0.4491 r:0.7401
Current avg r:0.5917 Best avg r: 0.6225
04:46:41,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:47:59,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:49:31,25 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1587
en_de Dev loss: 1.2131 r:0.1886
en_zh Dev loss: 0.7608 r:0.4764
ro_en Dev loss: 0.3409 r:0.8241
et_en Dev loss: 0.4627 r:0.6601
si_en Dev loss: 0.8255 r:0.5473
ne_en Dev loss: 0.5501 r:0.7232
ru_en Dev loss: 0.4475 r:0.7382
Current avg r:0.5940 Best avg r: 0.6225
04:53:25,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:54:43,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:56:15,194 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1534
en_de Dev loss: 1.2655 r:0.1848
en_zh Dev loss: 0.7886 r:0.4826
ro_en Dev loss: 0.3677 r:0.8199
et_en Dev loss: 0.4844 r:0.6554
si_en Dev loss: 0.9017 r:0.5371
ne_en Dev loss: 0.5571 r:0.7231
ru_en Dev loss: 0.4519 r:0.7443
Current avg r:0.5924 Best avg r: 0.6225
05:00:10,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:01:29,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:01,206 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1542
en_de Dev loss: 1.2380 r:0.1985
en_zh Dev loss: 0.7810 r:0.4824
ro_en Dev loss: 0.3586 r:0.8219
et_en Dev loss: 0.4627 r:0.6586
si_en Dev loss: 0.8910 r:0.5402
ne_en Dev loss: 0.5310 r:0.7256
ru_en Dev loss: 0.5084 r:0.7283
Current avg r:0.5936 Best avg r: 0.6225
05:06:58,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:08:17,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:09:49,927 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1585
en_de Dev loss: 1.2100 r:0.1937
en_zh Dev loss: 0.7628 r:0.4754
ro_en Dev loss: 0.3251 r:0.8266
et_en Dev loss: 0.4520 r:0.6631
si_en Dev loss: 0.8704 r:0.5380
ne_en Dev loss: 0.4946 r:0.7222
ru_en Dev loss: 0.4408 r:0.7461
Current avg r:0.5950 Best avg r: 0.6225
05:13:47,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:15:07,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:16:39,548 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1476
en_de Dev loss: 1.2267 r:0.2062
en_zh Dev loss: 0.7942 r:0.4655
ro_en Dev loss: 0.3438 r:0.8212
et_en Dev loss: 0.4767 r:0.6569
si_en Dev loss: 0.9201 r:0.5400
ne_en Dev loss: 0.5612 r:0.7230
ru_en Dev loss: 0.4859 r:0.7255
Current avg r:0.5912 Best avg r: 0.6225
05:20:37,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:21:57,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:29,465 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1577
en_de Dev loss: 1.2332 r:0.1933
en_zh Dev loss: 0.7982 r:0.4739
ro_en Dev loss: 0.3686 r:0.8221
et_en Dev loss: 0.4477 r:0.6635
si_en Dev loss: 0.9216 r:0.5498
ne_en Dev loss: 0.6004 r:0.7240
ru_en Dev loss: 0.4597 r:0.7395
Current avg r:0.5952 Best avg r: 0.6225
05:27:27,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:46,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:18,733 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1533
en_de Dev loss: 1.2021 r:0.1985
en_zh Dev loss: 0.7568 r:0.4748
ro_en Dev loss: 0.3244 r:0.8228
et_en Dev loss: 0.4807 r:0.6701
si_en Dev loss: 0.8440 r:0.5482
ne_en Dev loss: 0.5316 r:0.7242
ru_en Dev loss: 0.3980 r:0.7551
Current avg r:0.5991 Best avg r: 0.6225
05:34:16,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:35:35,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:37:07,79 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1548
en_de Dev loss: 1.2126 r:0.1949
en_zh Dev loss: 0.7598 r:0.4759
ro_en Dev loss: 0.3254 r:0.8266
et_en Dev loss: 0.4633 r:0.6669
si_en Dev loss: 0.8763 r:0.5469
ne_en Dev loss: 0.4957 r:0.7326
ru_en Dev loss: 0.4210 r:0.7485
Current avg r:0.5989 Best avg r: 0.6225
05:41:02,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:42:20,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:43:52,240 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1526
en_de Dev loss: 1.2595 r:0.1865
en_zh Dev loss: 0.7944 r:0.4706
ro_en Dev loss: 0.3487 r:0.8201
et_en Dev loss: 0.4894 r:0.6549
si_en Dev loss: 0.9027 r:0.5414
ne_en Dev loss: 0.5598 r:0.7229
ru_en Dev loss: 0.4529 r:0.7388
Current avg r:0.5908 Best avg r: 0.6225
05:47:49,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:49:08,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:50:40,682 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1551
en_de Dev loss: 1.2547 r:0.1873
en_zh Dev loss: 0.7879 r:0.4727
ro_en Dev loss: 0.3446 r:0.8232
et_en Dev loss: 0.4924 r:0.6605
si_en Dev loss: 0.8742 r:0.5365
ne_en Dev loss: 0.5418 r:0.7176
ru_en Dev loss: 0.4546 r:0.7427
Current avg r:0.5915 Best avg r: 0.6225
05:54:39,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:55:58,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:57:30,322 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1395
en_de Dev loss: 1.2231 r:0.1968
en_zh Dev loss: 0.7786 r:0.4718
ro_en Dev loss: 0.3372 r:0.8235
et_en Dev loss: 0.4724 r:0.6596
si_en Dev loss: 0.8947 r:0.5406
ne_en Dev loss: 0.5640 r:0.7225
ru_en Dev loss: 0.4209 r:0.7574
Current avg r:0.5960 Best avg r: 0.6225
06:01:27,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:02:46,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:18,693 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1351
en_de Dev loss: 1.2911 r:0.1925
en_zh Dev loss: 0.8139 r:0.4708
ro_en Dev loss: 0.3633 r:0.8250
et_en Dev loss: 0.5024 r:0.6607
si_en Dev loss: 0.9771 r:0.5326
ne_en Dev loss: 0.6013 r:0.7147
ru_en Dev loss: 0.4819 r:0.7370
Current avg r:0.5905 Best avg r: 0.6225
06:08:16,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:35,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:07,975 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1373
en_de Dev loss: 1.3118 r:0.1886
en_zh Dev loss: 0.8643 r:0.4730
ro_en Dev loss: 0.3738 r:0.8275
et_en Dev loss: 0.4762 r:0.6564
si_en Dev loss: 1.0744 r:0.5264
ne_en Dev loss: 0.6729 r:0.7103
ru_en Dev loss: 0.4947 r:0.7357
Current avg r:0.5883 Best avg r: 0.6225
06:15:05,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:16:23,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:17:56,180 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1410
en_de Dev loss: 1.2169 r:0.2003
en_zh Dev loss: 0.7979 r:0.4696
ro_en Dev loss: 0.3478 r:0.8246
et_en Dev loss: 0.4767 r:0.6464
si_en Dev loss: 0.9925 r:0.5217
ne_en Dev loss: 0.6096 r:0.7085
ru_en Dev loss: 0.4650 r:0.7335
Current avg r:0.5864 Best avg r: 0.6225
06:21:53,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:23:12,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:44,990 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1411
en_de Dev loss: 1.2188 r:0.1995
en_zh Dev loss: 0.7935 r:0.4708
ro_en Dev loss: 0.3439 r:0.8211
et_en Dev loss: 0.4872 r:0.6594
si_en Dev loss: 0.9319 r:0.5283
ne_en Dev loss: 0.5360 r:0.7141
ru_en Dev loss: 0.4389 r:0.7456
Current avg r:0.5913 Best avg r: 0.6225
06:28:42,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:01,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:32,471 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1288
en_de Dev loss: 1.2972 r:0.1875
en_zh Dev loss: 0.8238 r:0.4732
ro_en Dev loss: 0.3581 r:0.8265
et_en Dev loss: 0.5009 r:0.6707
si_en Dev loss: 0.9072 r:0.5450
ne_en Dev loss: 0.6038 r:0.7095
ru_en Dev loss: 0.4619 r:0.7461
Current avg r:0.5941 Best avg r: 0.6225
06:35:26,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:45,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:38:16,402 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1337
en_de Dev loss: 1.2041 r:0.2026
en_zh Dev loss: 0.7950 r:0.4685
ro_en Dev loss: 0.3354 r:0.8257
et_en Dev loss: 0.4606 r:0.6600
si_en Dev loss: 0.9050 r:0.5327
ne_en Dev loss: 0.5579 r:0.7168
ru_en Dev loss: 0.4451 r:0.7395
Current avg r:0.5923 Best avg r: 0.6225
06:42:10,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:43:29,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:00,293 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1355
en_de Dev loss: 1.3133 r:0.1887
en_zh Dev loss: 0.8341 r:0.4788
ro_en Dev loss: 0.3917 r:0.8234
et_en Dev loss: 0.5049 r:0.6621
si_en Dev loss: 0.9915 r:0.5293
ne_en Dev loss: 0.6039 r:0.7120
ru_en Dev loss: 0.4791 r:0.7429
Current avg r:0.5910 Best avg r: 0.6225
06:48:54,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:49:07,66 root INFO 
id:en_zh cur r: 0.4978 best r: 0.4978
06:50:12,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:51:43,580 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1346
en_de Dev loss: 1.2467 r:0.1863
en_zh Dev loss: 0.7768 r:0.4894
ro_en Dev loss: 0.3285 r:0.8280
et_en Dev loss: 0.5044 r:0.6764
si_en Dev loss: 0.8235 r:0.5487
ne_en Dev loss: 0.5015 r:0.7205
ru_en Dev loss: 0.4243 r:0.7541
Current avg r:0.6005 Best avg r: 0.6225
06:55:40,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:56:59,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:58:31,528 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1310
en_de Dev loss: 1.2061 r:0.1847
en_zh Dev loss: 0.7670 r:0.4767
ro_en Dev loss: 0.3052 r:0.8302
et_en Dev loss: 0.4656 r:0.6764
si_en Dev loss: 0.7846 r:0.5452
ne_en Dev loss: 0.5507 r:0.7207
ru_en Dev loss: 0.4250 r:0.7449
Current avg r:0.5970 Best avg r: 0.6225
07:02:28,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:03:47,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:05:19,425 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1328
en_de Dev loss: 1.2061 r:0.1907
en_zh Dev loss: 0.7555 r:0.4825
ro_en Dev loss: 0.3120 r:0.8293
et_en Dev loss: 0.5037 r:0.6721
si_en Dev loss: 0.8095 r:0.5420
ne_en Dev loss: 0.5073 r:0.7138
ru_en Dev loss: 0.4169 r:0.7438
Current avg r:0.5963 Best avg r: 0.6225
07:09:16,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:10:35,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:12:07,220 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1349
en_de Dev loss: 1.2498 r:0.1859
en_zh Dev loss: 0.7719 r:0.4811
ro_en Dev loss: 0.3377 r:0.8276
et_en Dev loss: 0.4788 r:0.6616
si_en Dev loss: 0.9210 r:0.5312
ne_en Dev loss: 0.5919 r:0.7145
ru_en Dev loss: 0.4632 r:0.7401
Current avg r:0.5917 Best avg r: 0.6225
07:16:03,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:21,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:18:53,72 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1320
en_de Dev loss: 1.2612 r:0.1864
en_zh Dev loss: 0.8019 r:0.4710
ro_en Dev loss: 0.3533 r:0.8237
et_en Dev loss: 0.4834 r:0.6637
si_en Dev loss: 0.9571 r:0.5284
ne_en Dev loss: 0.5791 r:0.7115
ru_en Dev loss: 0.4627 r:0.7411
Current avg r:0.5894 Best avg r: 0.6225
07:22:46,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:24:05,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:25:36,484 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1335
en_de Dev loss: 1.2391 r:0.1858
en_zh Dev loss: 0.7875 r:0.4710
ro_en Dev loss: 0.3525 r:0.8211
et_en Dev loss: 0.4747 r:0.6547
si_en Dev loss: 0.9345 r:0.5327
ne_en Dev loss: 0.5853 r:0.7116
ru_en Dev loss: 0.4772 r:0.7314
Current avg r:0.5869 Best avg r: 0.6225
07:29:30,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:30:48,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:19,738 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1349
en_de Dev loss: 1.2618 r:0.1988
en_zh Dev loss: 0.8136 r:0.4698
ro_en Dev loss: 0.3550 r:0.8255
et_en Dev loss: 0.4787 r:0.6672
si_en Dev loss: 0.8698 r:0.5462
ne_en Dev loss: 0.5130 r:0.7221
ru_en Dev loss: 0.4759 r:0.7362
Current avg r:0.5951 Best avg r: 0.6225
07:36:14,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:37:32,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:39:05,10 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1217
en_de Dev loss: 1.2375 r:0.2008
en_zh Dev loss: 0.7939 r:0.4778
ro_en Dev loss: 0.3542 r:0.8257
et_en Dev loss: 0.4588 r:0.6556
si_en Dev loss: 0.9596 r:0.5328
ne_en Dev loss: 0.6628 r:0.7066
ru_en Dev loss: 0.4920 r:0.7277
Current avg r:0.5896 Best avg r: 0.6225
07:43:02,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:44:20,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:53,101 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1212
en_de Dev loss: 1.2715 r:0.1988
en_zh Dev loss: 0.8018 r:0.4794
ro_en Dev loss: 0.3463 r:0.8261
et_en Dev loss: 0.4946 r:0.6617
si_en Dev loss: 0.8963 r:0.5394
ne_en Dev loss: 0.5373 r:0.7230
ru_en Dev loss: 0.4536 r:0.7470
Current avg r:0.5965 Best avg r: 0.6225
07:49:50,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:51:09,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:41,267 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1186
en_de Dev loss: 1.2453 r:0.1917
en_zh Dev loss: 0.7892 r:0.4729
ro_en Dev loss: 0.3419 r:0.8237
et_en Dev loss: 0.4843 r:0.6607
si_en Dev loss: 0.8794 r:0.5344
ne_en Dev loss: 0.5669 r:0.7141
ru_en Dev loss: 0.4550 r:0.7352
Current avg r:0.5904 Best avg r: 0.6225
07:56:38,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:57:57,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:59:29,180 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1213
en_de Dev loss: 1.2847 r:0.1979
en_zh Dev loss: 0.8190 r:0.4702
ro_en Dev loss: 0.3621 r:0.8254
et_en Dev loss: 0.4854 r:0.6642
si_en Dev loss: 0.9220 r:0.5356
ne_en Dev loss: 0.5613 r:0.7171
ru_en Dev loss: 0.4698 r:0.7392
Current avg r:0.5928 Best avg r: 0.6225
08:03:24,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:04:43,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:06:14,300 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1178
en_de Dev loss: 1.2047 r:0.2025
en_zh Dev loss: 0.7581 r:0.4808
ro_en Dev loss: 0.3206 r:0.8252
et_en Dev loss: 0.4734 r:0.6682
si_en Dev loss: 0.8384 r:0.5408
ne_en Dev loss: 0.5360 r:0.7148
ru_en Dev loss: 0.4442 r:0.7363
Current avg r:0.5955 Best avg r: 0.6225
08:10:08,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:11:26,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:12:57,667 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1260
en_de Dev loss: 1.2595 r:0.2105
en_zh Dev loss: 0.8238 r:0.4728
ro_en Dev loss: 0.3818 r:0.8176
et_en Dev loss: 0.4713 r:0.6520
si_en Dev loss: 0.9769 r:0.5244
ne_en Dev loss: 0.6849 r:0.7012
ru_en Dev loss: 0.5042 r:0.7264
Current avg r:0.5864 Best avg r: 0.6225
08:16:51,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:18:10,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:19:41,510 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1177
en_de Dev loss: 1.1705 r:0.2049
en_zh Dev loss: 0.7572 r:0.4720
ro_en Dev loss: 0.3078 r:0.8288
et_en Dev loss: 0.4358 r:0.6778
si_en Dev loss: 0.8231 r:0.5396
ne_en Dev loss: 0.5481 r:0.7037
ru_en Dev loss: 0.4135 r:0.7507
Current avg r:0.5968 Best avg r: 0.6225
08:23:35,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:24:53,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:24,575 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1192
en_de Dev loss: 1.1996 r:0.2011
en_zh Dev loss: 0.7571 r:0.4805
ro_en Dev loss: 0.3111 r:0.8300
et_en Dev loss: 0.4465 r:0.6774
si_en Dev loss: 0.8269 r:0.5433
ne_en Dev loss: 0.5265 r:0.7028
ru_en Dev loss: 0.4200 r:0.7500
Current avg r:0.5979 Best avg r: 0.6225
08:30:17,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:31:35,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:33:06,848 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1159
en_de Dev loss: 1.1853 r:0.2032
en_zh Dev loss: 0.7333 r:0.4886
ro_en Dev loss: 0.3197 r:0.8252
et_en Dev loss: 0.4669 r:0.6813
si_en Dev loss: 0.7866 r:0.5532
ne_en Dev loss: 0.4804 r:0.7120
ru_en Dev loss: 0.3978 r:0.7554
Current avg r:0.6027 Best avg r: 0.6225
08:37:00,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:38:18,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:39:49,153 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1201
en_de Dev loss: 1.1835 r:0.1990
en_zh Dev loss: 0.7413 r:0.4787
ro_en Dev loss: 0.3083 r:0.8288
et_en Dev loss: 0.4439 r:0.6730
si_en Dev loss: 0.8242 r:0.5459
ne_en Dev loss: 0.5160 r:0.7092
ru_en Dev loss: 0.4222 r:0.7444
Current avg r:0.5970 Best avg r: 0.6225
08:43:42,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:45:00,267 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:46:31,314 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1163
en_de Dev loss: 1.2896 r:0.1956
en_zh Dev loss: 0.8375 r:0.4670
ro_en Dev loss: 0.3612 r:0.8224
et_en Dev loss: 0.5066 r:0.6682
si_en Dev loss: 0.9590 r:0.5316
ne_en Dev loss: 0.5887 r:0.7066
ru_en Dev loss: 0.4592 r:0.7395
Current avg r:0.5901 Best avg r: 0.6225
08:50:24,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:51:42,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:53:13,507 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1135
en_de Dev loss: 1.2143 r:0.1947
en_zh Dev loss: 0.7555 r:0.4807
ro_en Dev loss: 0.3143 r:0.8288
et_en Dev loss: 0.4764 r:0.6782
si_en Dev loss: 0.7673 r:0.5568
ne_en Dev loss: 0.4917 r:0.7156
ru_en Dev loss: 0.4061 r:0.7539
Current avg r:0.6013 Best avg r: 0.6225
08:57:06,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:58:24,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:59:55,808 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1173
en_de Dev loss: 1.2538 r:0.2011
en_zh Dev loss: 0.7849 r:0.4764
ro_en Dev loss: 0.3620 r:0.8210
et_en Dev loss: 0.4841 r:0.6678
si_en Dev loss: 0.9360 r:0.5346
ne_en Dev loss: 0.5951 r:0.7119
ru_en Dev loss: 0.4473 r:0.7484
Current avg r:0.5944 Best avg r: 0.6225
09:03:49,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:05:07,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:06:38,149 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1205
en_de Dev loss: 1.2122 r:0.1955
en_zh Dev loss: 0.7543 r:0.4850
ro_en Dev loss: 0.3245 r:0.8275
et_en Dev loss: 0.4726 r:0.6744
si_en Dev loss: 0.8732 r:0.5334
ne_en Dev loss: 0.5616 r:0.7125
ru_en Dev loss: 0.4381 r:0.7452
Current avg r:0.5962 Best avg r: 0.6225
09:10:31,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:11:49,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:13:20,643 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1168
en_de Dev loss: 1.2257 r:0.1877
en_zh Dev loss: 0.7618 r:0.4867
ro_en Dev loss: 0.3426 r:0.8195
et_en Dev loss: 0.4743 r:0.6669
si_en Dev loss: 0.9291 r:0.5249
ne_en Dev loss: 0.5668 r:0.7120
ru_en Dev loss: 0.4246 r:0.7504
Current avg r:0.5926 Best avg r: 0.6225
09:17:15,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:33,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:20:04,369 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1039
en_de Dev loss: 1.3284 r:0.1894
en_zh Dev loss: 0.8600 r:0.4779
ro_en Dev loss: 0.3970 r:0.8192
et_en Dev loss: 0.4837 r:0.6563
si_en Dev loss: 1.0443 r:0.5196
ne_en Dev loss: 0.7268 r:0.7112
ru_en Dev loss: 0.4870 r:0.7426
Current avg r:0.5880 Best avg r: 0.6225
09:23:57,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:15,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:46,734 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1125
en_de Dev loss: 1.2502 r:0.1889
en_zh Dev loss: 0.7822 r:0.4794
ro_en Dev loss: 0.3472 r:0.8204
et_en Dev loss: 0.4775 r:0.6680
si_en Dev loss: 0.9137 r:0.5248
ne_en Dev loss: 0.5377 r:0.7093
ru_en Dev loss: 0.4411 r:0.7504
Current avg r:0.5916 Best avg r: 0.6225
09:30:39,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:31:57,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:33:29,48 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1053
en_de Dev loss: 1.2934 r:0.1919
en_zh Dev loss: 0.8241 r:0.4803
ro_en Dev loss: 0.3785 r:0.8199
et_en Dev loss: 0.4613 r:0.6668
si_en Dev loss: 0.9079 r:0.5341
ne_en Dev loss: 0.6062 r:0.7135
ru_en Dev loss: 0.4826 r:0.7411
Current avg r:0.5925 Best avg r: 0.6225
09:37:22,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:38:40,414 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:40:11,503 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1105
en_de Dev loss: 1.2520 r:0.1955
en_zh Dev loss: 0.7787 r:0.4817
ro_en Dev loss: 0.3696 r:0.8182
et_en Dev loss: 0.4767 r:0.6684
si_en Dev loss: 0.8860 r:0.5390
ne_en Dev loss: 0.5472 r:0.7207
ru_en Dev loss: 0.4538 r:0.7437
Current avg r:0.5953 Best avg r: 0.6225
09:44:04,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:44:17,798 root INFO 
id:en_zh cur r: 0.4999 best r: 0.4999
09:45:22,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:46:54,102 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1060
en_de Dev loss: 1.2209 r:0.1876
en_zh Dev loss: 0.7438 r:0.4935
ro_en Dev loss: 0.3281 r:0.8183
et_en Dev loss: 0.4707 r:0.6723
si_en Dev loss: 0.8199 r:0.5457
ne_en Dev loss: 0.5096 r:0.7198
ru_en Dev loss: 0.3927 r:0.7628
Current avg r:0.6000 Best avg r: 0.6225
09:50:47,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:52:05,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:53:36,944 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1087
en_de Dev loss: 1.2864 r:0.1971
en_zh Dev loss: 0.8160 r:0.4830
ro_en Dev loss: 0.3589 r:0.8196
et_en Dev loss: 0.4871 r:0.6596
si_en Dev loss: 0.9264 r:0.5322
ne_en Dev loss: 0.5780 r:0.7084
ru_en Dev loss: 0.4288 r:0.7561
Current avg r:0.5937 Best avg r: 0.6225
09:57:30,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:48,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:19,800 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1051
en_de Dev loss: 1.2447 r:0.1963
en_zh Dev loss: 0.7676 r:0.4904
ro_en Dev loss: 0.3448 r:0.8222
et_en Dev loss: 0.4531 r:0.6697
si_en Dev loss: 0.8903 r:0.5355
ne_en Dev loss: 0.5614 r:0.7127
ru_en Dev loss: 0.4371 r:0.7521
Current avg r:0.5970 Best avg r: 0.6225
10:04:13,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:31,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:02,669 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1057
en_de Dev loss: 1.2671 r:0.1897
en_zh Dev loss: 0.7753 r:0.4892
ro_en Dev loss: 0.3475 r:0.8221
et_en Dev loss: 0.4549 r:0.6748
si_en Dev loss: 0.8886 r:0.5298
ne_en Dev loss: 0.5676 r:0.7046
ru_en Dev loss: 0.4600 r:0.7455
Current avg r:0.5937 Best avg r: 0.6225
10:10:56,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:12:14,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:13:45,534 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1052
en_de Dev loss: 1.2663 r:0.1953
en_zh Dev loss: 0.7895 r:0.4880
ro_en Dev loss: 0.3717 r:0.8174
et_en Dev loss: 0.4593 r:0.6638
si_en Dev loss: 0.9595 r:0.5197
ne_en Dev loss: 0.6077 r:0.7031
ru_en Dev loss: 0.4515 r:0.7523
Current avg r:0.5914 Best avg r: 0.6225
10:17:39,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:57,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:28,612 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1065
en_de Dev loss: 1.2329 r:0.1975
en_zh Dev loss: 0.7746 r:0.4852
ro_en Dev loss: 0.3339 r:0.8226
et_en Dev loss: 0.4658 r:0.6793
si_en Dev loss: 0.8741 r:0.5337
ne_en Dev loss: 0.5332 r:0.7171
ru_en Dev loss: 0.4219 r:0.7574
Current avg r:0.5990 Best avg r: 0.6225
10:24:22,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:35,237 root INFO 
id:en_zh cur r: 0.5004 best r: 0.5004
10:25:40,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:11,421 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1042
en_de Dev loss: 1.2243 r:0.2014
en_zh Dev loss: 0.7677 r:0.4953
ro_en Dev loss: 0.3300 r:0.8219
et_en Dev loss: 0.4459 r:0.6708
si_en Dev loss: 0.8742 r:0.5329
ne_en Dev loss: 0.5575 r:0.7177
ru_en Dev loss: 0.4501 r:0.7462
Current avg r:0.5980 Best avg r: 0.6225
10:31:04,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:32:22,826 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:33:53,894 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1042
en_de Dev loss: 1.2777 r:0.2005
en_zh Dev loss: 0.8330 r:0.4819
ro_en Dev loss: 0.3663 r:0.8159
et_en Dev loss: 0.4595 r:0.6613
si_en Dev loss: 0.9246 r:0.5296
ne_en Dev loss: 0.6272 r:0.7128
ru_en Dev loss: 0.5017 r:0.7341
Current avg r:0.5909 Best avg r: 0.6225
10:37:47,196 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
