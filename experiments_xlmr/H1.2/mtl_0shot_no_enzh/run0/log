14:43:36,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:43:49,67 root INFO 
id:en_de cur r: 0.0655 best r: 0.0655
14:44:02,33 root INFO 
id:ro_en cur r: 0.5826 best r: 0.5826
14:44:15,21 root INFO 
id:et_en cur r: 0.5695 best r: 0.5695
14:44:28,27 root INFO 
id:si_en cur r: 0.3853 best r: 0.3853
14:44:41,23 root INFO 
id:ne_en cur r: 0.5264 best r: 0.5264
14:44:53,905 root INFO 
id:ru_en cur r: 0.5886 best r: 0.5886
14:44:53,906 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:24,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
14:46:24,686 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:46:24,691 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:46:24,695 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
14:46:24,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
14:46:24,704 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:46:24,709 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:46:37,665 root INFO Epoch 0 Global steps: 600 Train loss: 0.8496
en_de Dev loss: 0.9190 r:0.0907
en_zh Dev loss: 0.7753 r:0.2370
ro_en Dev loss: 0.5995 r:0.6330
et_en Dev loss: 0.5377 r:0.5614
si_en Dev loss: 0.6820 r:0.4561
ne_en Dev loss: 0.5939 r:0.5566
ru_en Dev loss: 0.6084 r:0.6121
Current avg r:0.4495 Best avg r: 0.4495
14:50:30,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:50:43,550 root INFO 
id:en_de cur r: 0.0868 best r: 0.0868
14:50:56,530 root INFO 
id:ro_en cur r: 0.5909 best r: 0.5909
14:51:48,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:19,376 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8334
en_de Dev loss: 0.9763 r:0.0884
en_zh Dev loss: 0.8081 r:0.2119
ro_en Dev loss: 0.6388 r:0.6399
et_en Dev loss: 0.5605 r:0.4816
si_en Dev loss: 0.8954 r:0.3779
ne_en Dev loss: 0.6327 r:0.5067
ru_en Dev loss: 0.6735 r:0.5659
Current avg r:0.4103 Best avg r: 0.4495
14:57:12,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:38,659 root INFO 
id:ro_en cur r: 0.6194 best r: 0.6194
14:58:30,672 root INFO 
id:ru_en cur r: 0.6440 best r: 0.6440
14:58:30,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:01,603 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
15:00:01,611 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:00:01,617 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:00:01,622 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
15:00:01,627 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
15:00:01,634 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:00:01,638 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:00:14,619 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7344
en_de Dev loss: 0.9854 r:0.0913
en_zh Dev loss: 0.7944 r:0.2326
ro_en Dev loss: 0.5751 r:0.6765
et_en Dev loss: 0.4962 r:0.5734
si_en Dev loss: 0.7626 r:0.4449
ne_en Dev loss: 0.5452 r:0.5820
ru_en Dev loss: 0.5140 r:0.6851
Current avg r:0.4694 Best avg r: 0.4694
15:04:08,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:34,54 root INFO 
id:ro_en cur r: 0.6662 best r: 0.6662
15:04:47,81 root INFO 
id:et_en cur r: 0.6240 best r: 0.6240
15:05:00,128 root INFO 
id:si_en cur r: 0.4094 best r: 0.4094
15:05:13,166 root INFO 
id:ne_en cur r: 0.5888 best r: 0.5888
15:05:26,91 root INFO 
id:ru_en cur r: 0.6568 best r: 0.6568
15:05:26,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:57,91 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
15:06:57,99 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:06:57,104 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:06:57,109 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
15:06:57,118 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
15:06:57,123 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:06:57,128 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:07:10,115 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6715
en_de Dev loss: 1.0286 r:0.1017
en_zh Dev loss: 0.8115 r:0.2595
ro_en Dev loss: 0.5166 r:0.6982
et_en Dev loss: 0.4346 r:0.6314
si_en Dev loss: 0.7955 r:0.4607
ne_en Dev loss: 0.5177 r:0.6076
ru_en Dev loss: 0.5061 r:0.6842
Current avg r:0.4919 Best avg r: 0.4919
15:11:03,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:29,529 root INFO 
id:ro_en cur r: 0.7132 best r: 0.7132
15:11:42,551 root INFO 
id:et_en cur r: 0.6279 best r: 0.6279
15:11:55,590 root INFO 
id:si_en cur r: 0.4372 best r: 0.4372
15:12:08,625 root INFO 
id:ne_en cur r: 0.6345 best r: 0.6345
15:12:21,565 root INFO 
id:ru_en cur r: 0.7083 best r: 0.7083
15:12:21,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:52,529 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
15:13:52,536 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:13:52,541 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:13:52,546 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
15:13:52,550 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
15:13:52,554 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:13:52,559 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:14:05,541 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6394
en_de Dev loss: 0.9380 r:0.1449
en_zh Dev loss: 0.7569 r:0.3014
ro_en Dev loss: 0.4269 r:0.7390
et_en Dev loss: 0.4166 r:0.6490
si_en Dev loss: 0.7118 r:0.4953
ne_en Dev loss: 0.4752 r:0.6419
ru_en Dev loss: 0.4312 r:0.7208
Current avg r:0.5275 Best avg r: 0.5275
15:17:58,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:11,923 root INFO 
id:en_de cur r: 0.1025 best r: 0.1025
15:18:24,923 root INFO 
id:ro_en cur r: 0.7302 best r: 0.7302
15:18:37,946 root INFO 
id:et_en cur r: 0.6619 best r: 0.6619
15:18:50,987 root INFO 
id:si_en cur r: 0.5045 best r: 0.5045
15:19:04,16 root INFO 
id:ne_en cur r: 0.6807 best r: 0.6807
15:19:16,946 root INFO 
id:ru_en cur r: 0.7336 best r: 0.7336
15:19:16,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:47,893 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
15:20:47,899 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:20:47,904 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:20:47,909 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
15:20:47,914 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
15:20:47,919 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:20:47,924 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:21:00,903 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6173
en_de Dev loss: 0.9241 r:0.1644
en_zh Dev loss: 0.7366 r:0.3348
ro_en Dev loss: 0.4056 r:0.7493
et_en Dev loss: 0.3820 r:0.6842
si_en Dev loss: 0.6895 r:0.5218
ne_en Dev loss: 0.4771 r:0.6586
ru_en Dev loss: 0.4287 r:0.7450
Current avg r:0.5511 Best avg r: 0.5511
15:24:53,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:06,871 root INFO 
id:en_de cur r: 0.1133 best r: 0.1133
15:25:19,872 root INFO 
id:ro_en cur r: 0.7452 best r: 0.7452
15:25:45,909 root INFO 
id:si_en cur r: 0.5387 best r: 0.5387
15:25:58,938 root INFO 
id:ne_en cur r: 0.6994 best r: 0.6994
15:26:11,865 root INFO 
id:ru_en cur r: 0.7395 best r: 0.7395
15:26:11,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:42,810 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
15:27:42,816 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:27:42,821 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:27:42,825 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
15:27:42,830 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
15:27:42,834 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:27:42,839 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:27:55,817 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5638
en_de Dev loss: 0.9149 r:0.1569
en_zh Dev loss: 0.7252 r:0.3443
ro_en Dev loss: 0.3968 r:0.7539
et_en Dev loss: 0.3772 r:0.6861
si_en Dev loss: 0.5939 r:0.5559
ne_en Dev loss: 0.4132 r:0.7009
ru_en Dev loss: 0.4363 r:0.7459
Current avg r:0.5634 Best avg r: 0.5634
15:31:48,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:01,707 root INFO 
id:en_de cur r: 0.1557 best r: 0.1557
15:32:14,699 root INFO 
id:ro_en cur r: 0.7478 best r: 0.7478
15:33:06,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:37,563 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
15:34:37,569 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:34:37,574 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:34:37,579 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
15:34:37,584 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
15:34:37,589 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:34:37,593 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:34:50,571 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5865
en_de Dev loss: 0.9079 r:0.1855
en_zh Dev loss: 0.7459 r:0.3489
ro_en Dev loss: 0.4250 r:0.7757
et_en Dev loss: 0.3844 r:0.6869
si_en Dev loss: 0.6917 r:0.5400
ne_en Dev loss: 0.4403 r:0.6912
ru_en Dev loss: 0.4199 r:0.7452
Current avg r:0.5676 Best avg r: 0.5676
15:38:43,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:09,702 root INFO 
id:ro_en cur r: 0.7613 best r: 0.7613
15:39:22,720 root INFO 
id:et_en cur r: 0.6690 best r: 0.6690
15:39:48,780 root INFO 
id:ne_en cur r: 0.7023 best r: 0.7023
15:40:01,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:32,625 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5653
en_de Dev loss: 0.9262 r:0.1633
en_zh Dev loss: 0.8078 r:0.3421
ro_en Dev loss: 0.4674 r:0.7758
et_en Dev loss: 0.4088 r:0.6892
si_en Dev loss: 0.8507 r:0.5345
ne_en Dev loss: 0.5253 r:0.6802
ru_en Dev loss: 0.5481 r:0.7334
Current avg r:0.5598 Best avg r: 0.5676
15:45:25,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:45:51,798 root INFO 
id:ro_en cur r: 0.7853 best r: 0.7853
15:46:04,821 root INFO 
id:et_en cur r: 0.6801 best r: 0.6801
15:46:17,853 root INFO 
id:si_en cur r: 0.5591 best r: 0.5591
15:46:30,888 root INFO 
id:ne_en cur r: 0.7131 best r: 0.7131
15:46:43,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:14,770 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
15:48:14,776 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:48:14,781 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:48:14,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
15:48:14,792 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
15:48:14,797 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:48:14,801 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:48:27,774 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5529
en_de Dev loss: 0.8772 r:0.1639
en_zh Dev loss: 0.7383 r:0.3463
ro_en Dev loss: 0.3423 r:0.7871
et_en Dev loss: 0.3615 r:0.6995
si_en Dev loss: 0.6334 r:0.5689
ne_en Dev loss: 0.4305 r:0.7052
ru_en Dev loss: 0.4266 r:0.7492
Current avg r:0.5743 Best avg r: 0.5743
15:52:20,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:46,942 root INFO 
id:ro_en cur r: 0.7905 best r: 0.7905
15:52:59,960 root INFO 
id:et_en cur r: 0.6937 best r: 0.6937
15:53:12,999 root INFO 
id:si_en cur r: 0.5732 best r: 0.5732
15:53:26,45 root INFO 
id:ne_en cur r: 0.7333 best r: 0.7333
15:53:38,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:09,929 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
15:55:09,935 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:55:09,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:55:09,944 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
15:55:09,949 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
15:55:09,954 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:55:09,958 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:55:22,938 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5641
en_de Dev loss: 0.9379 r:0.1802
en_zh Dev loss: 0.8171 r:0.3383
ro_en Dev loss: 0.3778 r:0.7936
et_en Dev loss: 0.3605 r:0.7057
si_en Dev loss: 0.6595 r:0.5725
ne_en Dev loss: 0.4406 r:0.7124
ru_en Dev loss: 0.4853 r:0.7431
Current avg r:0.5780 Best avg r: 0.5780
15:59:16,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:29,134 root INFO 
id:en_de cur r: 0.1753 best r: 0.1753
15:59:55,165 root INFO 
id:et_en cur r: 0.6952 best r: 0.6952
16:00:34,148 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:05,162 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5539
en_de Dev loss: 0.9018 r:0.1964
en_zh Dev loss: 0.7799 r:0.3464
ro_en Dev loss: 0.3834 r:0.7910
et_en Dev loss: 0.3677 r:0.7038
si_en Dev loss: 0.7260 r:0.5578
ne_en Dev loss: 0.4330 r:0.7049
ru_en Dev loss: 0.4916 r:0.7351
Current avg r:0.5765 Best avg r: 0.5780
16:05:58,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:24,250 root INFO 
id:ro_en cur r: 0.8016 best r: 0.8016
16:06:37,273 root INFO 
id:et_en cur r: 0.7009 best r: 0.7009
16:06:50,310 root INFO 
id:si_en cur r: 0.5960 best r: 0.5960
16:07:03,350 root INFO 
id:ne_en cur r: 0.7460 best r: 0.7460
16:07:16,292 root INFO 
id:ru_en cur r: 0.7491 best r: 0.7491
16:07:16,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:47,267 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
16:08:47,273 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:08:47,278 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:08:47,283 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
16:08:47,289 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
16:08:47,295 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:08:47,300 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:09:00,285 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5252
en_de Dev loss: 0.9071 r:0.1935
en_zh Dev loss: 0.7684 r:0.3598
ro_en Dev loss: 0.3544 r:0.7992
et_en Dev loss: 0.3729 r:0.7125
si_en Dev loss: 0.6826 r:0.5810
ne_en Dev loss: 0.4340 r:0.7267
ru_en Dev loss: 0.4436 r:0.7479
Current avg r:0.5887 Best avg r: 0.5887
16:12:53,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:06,430 root INFO 
id:en_de cur r: 0.1774 best r: 0.1774
16:14:11,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:42,435 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5550
en_de Dev loss: 0.8773 r:0.1995
en_zh Dev loss: 0.7521 r:0.3517
ro_en Dev loss: 0.3654 r:0.8036
et_en Dev loss: 0.3829 r:0.7054
si_en Dev loss: 0.7316 r:0.5801
ne_en Dev loss: 0.4722 r:0.7230
ru_en Dev loss: 0.4913 r:0.7325
Current avg r:0.5851 Best avg r: 0.5887
16:19:35,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:53,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:24,516 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5431
en_de Dev loss: 0.8619 r:0.1793
en_zh Dev loss: 0.7237 r:0.3515
ro_en Dev loss: 0.3223 r:0.7998
et_en Dev loss: 0.3609 r:0.7012
si_en Dev loss: 0.6509 r:0.5762
ne_en Dev loss: 0.3833 r:0.7335
ru_en Dev loss: 0.4293 r:0.7348
Current avg r:0.5823 Best avg r: 0.5887
16:26:18,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:31,865 root INFO 
id:en_de cur r: 0.1774 best r: 0.1774
16:26:44,857 root INFO 
id:ro_en cur r: 0.8062 best r: 0.8062
16:27:36,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:07,796 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5000
en_de Dev loss: 0.8721 r:0.1831
en_zh Dev loss: 0.7500 r:0.3593
ro_en Dev loss: 0.3554 r:0.8012
et_en Dev loss: 0.3774 r:0.7041
si_en Dev loss: 0.6145 r:0.5914
ne_en Dev loss: 0.3782 r:0.7342
ru_en Dev loss: 0.4315 r:0.7410
Current avg r:0.5877 Best avg r: 0.5887
16:33:00,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:13,994 root INFO 
id:en_de cur r: 0.2024 best r: 0.2024
16:34:18,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:49,934 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
16:35:49,942 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:35:49,946 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:35:49,952 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
16:35:49,957 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
16:35:49,962 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:35:49,966 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:36:02,950 root INFO Epoch 1 Global steps: 10200 Train loss: 0.4906
en_de Dev loss: 0.8866 r:0.1983
en_zh Dev loss: 0.7705 r:0.3666
ro_en Dev loss: 0.3508 r:0.8059
et_en Dev loss: 0.3760 r:0.7086
si_en Dev loss: 0.6298 r:0.5959
ne_en Dev loss: 0.3957 r:0.7370
ru_en Dev loss: 0.4312 r:0.7515
Current avg r:0.5948 Best avg r: 0.5948
16:39:56,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:09,127 root INFO 
id:en_de cur r: 0.2029 best r: 0.2029
16:40:35,120 root INFO 
id:et_en cur r: 0.7080 best r: 0.7080
16:41:14,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:45,24 root INFO Epoch 1 Global steps: 10800 Train loss: 0.4983
en_de Dev loss: 0.9002 r:0.2026
en_zh Dev loss: 0.8167 r:0.3515
ro_en Dev loss: 0.4274 r:0.8060
et_en Dev loss: 0.3784 r:0.7135
si_en Dev loss: 0.7833 r:0.5862
ne_en Dev loss: 0.4804 r:0.7362
ru_en Dev loss: 0.5016 r:0.7425
Current avg r:0.5912 Best avg r: 0.5948
16:46:38,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:04,250 root INFO 
id:ro_en cur r: 0.8108 best r: 0.8108
16:47:43,303 root INFO 
id:ne_en cur r: 0.7538 best r: 0.7538
16:47:56,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:27,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
16:49:27,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:49:27,180 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:49:27,187 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
16:49:27,199 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
16:49:27,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:49:27,212 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:49:40,204 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4817
en_de Dev loss: 0.8875 r:0.1920
en_zh Dev loss: 0.7622 r:0.3568
ro_en Dev loss: 0.3283 r:0.8109
et_en Dev loss: 0.3582 r:0.7143
si_en Dev loss: 0.6819 r:0.5975
ne_en Dev loss: 0.3623 r:0.7494
ru_en Dev loss: 0.4305 r:0.7493
Current avg r:0.5957 Best avg r: 0.5957
16:53:33,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:12,364 root INFO 
id:et_en cur r: 0.7084 best r: 0.7084
16:54:51,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:22,310 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5030
en_de Dev loss: 0.8526 r:0.1972
en_zh Dev loss: 0.7165 r:0.3648
ro_en Dev loss: 0.2955 r:0.8124
et_en Dev loss: 0.3461 r:0.7169
si_en Dev loss: 0.6027 r:0.5917
ne_en Dev loss: 0.3753 r:0.7418
ru_en Dev loss: 0.3870 r:0.7444
Current avg r:0.5956 Best avg r: 0.5957
17:00:15,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:20,542 root INFO 
id:ne_en cur r: 0.7560 best r: 0.7560
17:01:33,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:04,449 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
17:03:04,455 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:03:04,460 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:03:04,466 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
17:03:04,471 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
17:03:04,475 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:03:04,480 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:03:17,467 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5342
en_de Dev loss: 0.8656 r:0.2147
en_zh Dev loss: 0.7307 r:0.3760
ro_en Dev loss: 0.3295 r:0.8118
et_en Dev loss: 0.3603 r:0.7105
si_en Dev loss: 0.7072 r:0.5855
ne_en Dev loss: 0.4063 r:0.7463
ru_en Dev loss: 0.4264 r:0.7488
Current avg r:0.5991 Best avg r: 0.5991
17:07:10,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:28,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:59,671 root INFO Epoch 1 Global steps: 13200 Train loss: 0.5055
en_de Dev loss: 0.9259 r:0.2010
en_zh Dev loss: 0.8262 r:0.3497
ro_en Dev loss: 0.3870 r:0.8059
et_en Dev loss: 0.3611 r:0.7104
si_en Dev loss: 0.6600 r:0.5914
ne_en Dev loss: 0.4106 r:0.7526
ru_en Dev loss: 0.5318 r:0.7261
Current avg r:0.5910 Best avg r: 0.5991
17:13:52,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:18,848 root INFO 
id:ro_en cur r: 0.8200 best r: 0.8200
17:14:31,881 root INFO 
id:et_en cur r: 0.7105 best r: 0.7105
17:14:44,926 root INFO 
id:si_en cur r: 0.6143 best r: 0.6143
17:14:57,960 root INFO 
id:ne_en cur r: 0.7638 best r: 0.7638
17:15:10,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:41,911 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_de.lang_agnost_mlp.dev.best.scores
17:16:41,920 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:16:41,926 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:16:41,933 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/et_en.lang_agnost_mlp.dev.best.scores
17:16:41,938 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/si_en.lang_agnost_mlp.dev.best.scores
17:16:41,944 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:16:41,949 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:16:54,944 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4945
en_de Dev loss: 0.8531 r:0.2056
en_zh Dev loss: 0.7108 r:0.3775
ro_en Dev loss: 0.3039 r:0.8207
et_en Dev loss: 0.3675 r:0.7138
si_en Dev loss: 0.5178 r:0.6147
ne_en Dev loss: 0.3356 r:0.7603
ru_en Dev loss: 0.3726 r:0.7504
Current avg r:0.6061 Best avg r: 0.6061
17:20:48,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:06,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:37,143 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4956
en_de Dev loss: 0.9085 r:0.1879
en_zh Dev loss: 0.8279 r:0.3446
ro_en Dev loss: 0.3467 r:0.8098
et_en Dev loss: 0.3746 r:0.6982
si_en Dev loss: 0.6665 r:0.5736
ne_en Dev loss: 0.3949 r:0.7396
ru_en Dev loss: 0.4650 r:0.7338
Current avg r:0.5839 Best avg r: 0.6061
17:27:30,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:48,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:20,31 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4647
en_de Dev loss: 0.9370 r:0.1899
en_zh Dev loss: 0.8558 r:0.3476
ro_en Dev loss: 0.3520 r:0.8120
et_en Dev loss: 0.3840 r:0.6934
si_en Dev loss: 0.7103 r:0.5727
ne_en Dev loss: 0.4319 r:0.7353
ru_en Dev loss: 0.4785 r:0.7355
Current avg r:0.5838 Best avg r: 0.6061
17:34:14,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:27,168 root INFO 
id:en_de cur r: 0.2289 best r: 0.2289
17:35:32,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:03,228 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4884
en_de Dev loss: 0.8816 r:0.2077
en_zh Dev loss: 0.7971 r:0.3656
ro_en Dev loss: 0.3432 r:0.8137
et_en Dev loss: 0.3609 r:0.7098
si_en Dev loss: 0.6997 r:0.5849
ne_en Dev loss: 0.3903 r:0.7464
ru_en Dev loss: 0.4304 r:0.7511
Current avg r:0.5970 Best avg r: 0.6061
17:40:56,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:14,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:45,941 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4570
en_de Dev loss: 0.8555 r:0.2044
en_zh Dev loss: 0.7434 r:0.3745
ro_en Dev loss: 0.3125 r:0.8142
et_en Dev loss: 0.3541 r:0.7095
si_en Dev loss: 0.6614 r:0.5827
ne_en Dev loss: 0.3913 r:0.7447
ru_en Dev loss: 0.4275 r:0.7400
Current avg r:0.5957 Best avg r: 0.6061
17:47:39,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:57,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:28,849 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4855
en_de Dev loss: 0.9146 r:0.2101
en_zh Dev loss: 0.8069 r:0.3674
ro_en Dev loss: 0.3637 r:0.8150
et_en Dev loss: 0.3601 r:0.7099
si_en Dev loss: 0.6414 r:0.5998
ne_en Dev loss: 0.5070 r:0.7451
ru_en Dev loss: 0.5010 r:0.7398
Current avg r:0.5982 Best avg r: 0.6061
17:54:22,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:40,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:11,428 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4667
en_de Dev loss: 0.8739 r:0.1889
en_zh Dev loss: 0.7972 r:0.3615
ro_en Dev loss: 0.3571 r:0.8189
et_en Dev loss: 0.3699 r:0.7086
si_en Dev loss: 0.7333 r:0.5918
ne_en Dev loss: 0.4788 r:0.7491
ru_en Dev loss: 0.4817 r:0.7446
Current avg r:0.5948 Best avg r: 0.6061
18:01:04,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:22,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:53,814 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4822
en_de Dev loss: 0.8688 r:0.2063
en_zh Dev loss: 0.7995 r:0.3702
ro_en Dev loss: 0.3577 r:0.8128
et_en Dev loss: 0.3655 r:0.6990
si_en Dev loss: 0.6994 r:0.5904
ne_en Dev loss: 0.4522 r:0.7458
ru_en Dev loss: 0.5024 r:0.7230
Current avg r:0.5925 Best avg r: 0.6061
18:07:48,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:06,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:37,587 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4618
en_de Dev loss: 0.8574 r:0.2183
en_zh Dev loss: 0.7651 r:0.3893
ro_en Dev loss: 0.3680 r:0.8152
et_en Dev loss: 0.3863 r:0.7043
si_en Dev loss: 0.6862 r:0.6058
ne_en Dev loss: 0.4133 r:0.7540
ru_en Dev loss: 0.4519 r:0.7545
Current avg r:0.6059 Best avg r: 0.6061
18:14:31,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:15:49,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:20,300 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4581
en_de Dev loss: 0.8633 r:0.2121
en_zh Dev loss: 0.8301 r:0.3758
ro_en Dev loss: 0.3492 r:0.8213
et_en Dev loss: 0.3913 r:0.7024
si_en Dev loss: 0.8348 r:0.5980
ne_en Dev loss: 0.6107 r:0.7486
ru_en Dev loss: 0.4866 r:0.7400
Current avg r:0.5997 Best avg r: 0.6061
18:21:13,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:32,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:03,30 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4368
en_de Dev loss: 0.9002 r:0.2135
en_zh Dev loss: 0.9158 r:0.3784
ro_en Dev loss: 0.4037 r:0.8177
et_en Dev loss: 0.4220 r:0.7012
si_en Dev loss: 0.8949 r:0.5938
ne_en Dev loss: 0.4793 r:0.7498
ru_en Dev loss: 0.5679 r:0.7364
Current avg r:0.5987 Best avg r: 0.6061
18:27:56,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:22,830 root INFO 
id:ro_en cur r: 0.8222 best r: 0.8222
18:29:14,854 root INFO 
id:ru_en cur r: 0.7584 best r: 0.7584
18:29:14,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:45,850 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4464
en_de Dev loss: 0.8699 r:0.2026
en_zh Dev loss: 0.7894 r:0.3776
ro_en Dev loss: 0.3256 r:0.8196
et_en Dev loss: 0.3937 r:0.7068
si_en Dev loss: 0.6351 r:0.5982
ne_en Dev loss: 0.3917 r:0.7472
ru_en Dev loss: 0.3911 r:0.7551
Current avg r:0.6010 Best avg r: 0.6061
18:34:39,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:57,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:28,58 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4235
en_de Dev loss: 0.9227 r:0.1726
en_zh Dev loss: 0.8769 r:0.3430
ro_en Dev loss: 0.3969 r:0.8091
et_en Dev loss: 0.4006 r:0.6858
si_en Dev loss: 0.6946 r:0.5804
ne_en Dev loss: 0.4398 r:0.7460
ru_en Dev loss: 0.4774 r:0.7339
Current avg r:0.5815 Best avg r: 0.6061
18:41:21,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:39,298 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:10,204 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4140
en_de Dev loss: 0.8983 r:0.1949
en_zh Dev loss: 0.9231 r:0.3509
ro_en Dev loss: 0.4394 r:0.8147
et_en Dev loss: 0.4001 r:0.6985
si_en Dev loss: 0.7566 r:0.5905
ne_en Dev loss: 0.4382 r:0.7496
ru_en Dev loss: 0.5433 r:0.7252
Current avg r:0.5892 Best avg r: 0.6061
18:48:03,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:21,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:52,449 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4170
en_de Dev loss: 0.8636 r:0.1695
en_zh Dev loss: 0.7658 r:0.3640
ro_en Dev loss: 0.3282 r:0.8152
et_en Dev loss: 0.3769 r:0.6923
si_en Dev loss: 0.6951 r:0.5996
ne_en Dev loss: 0.4335 r:0.7487
ru_en Dev loss: 0.4203 r:0.7331
Current avg r:0.5889 Best avg r: 0.6061
18:54:45,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:11,661 root INFO 
id:ro_en cur r: 0.8249 best r: 0.8249
18:56:03,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:34,452 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4224
en_de Dev loss: 0.9033 r:0.1786
en_zh Dev loss: 0.8801 r:0.3581
ro_en Dev loss: 0.4018 r:0.8205
et_en Dev loss: 0.3957 r:0.7083
si_en Dev loss: 0.7990 r:0.6056
ne_en Dev loss: 0.4956 r:0.7537
ru_en Dev loss: 0.5524 r:0.7297
Current avg r:0.5935 Best avg r: 0.6061
19:01:27,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:45,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:16,605 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4129
en_de Dev loss: 0.8981 r:0.1562
en_zh Dev loss: 0.8347 r:0.3623
ro_en Dev loss: 0.3503 r:0.8218
et_en Dev loss: 0.3826 r:0.7009
si_en Dev loss: 0.7523 r:0.5968
ne_en Dev loss: 0.4349 r:0.7554
ru_en Dev loss: 0.4683 r:0.7354
Current avg r:0.5898 Best avg r: 0.6061
19:08:10,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:36,65 root INFO 
id:ro_en cur r: 0.8286 best r: 0.8286
19:09:28,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:58,959 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4039
en_de Dev loss: 0.8750 r:0.1617
en_zh Dev loss: 0.8202 r:0.3631
ro_en Dev loss: 0.3379 r:0.8265
et_en Dev loss: 0.3792 r:0.7035
si_en Dev loss: 0.6945 r:0.6103
ne_en Dev loss: 0.4775 r:0.7544
ru_en Dev loss: 0.4585 r:0.7440
Current avg r:0.5948 Best avg r: 0.6061
19:14:52,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:10,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:41,210 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4443
en_de Dev loss: 0.9161 r:0.1690
en_zh Dev loss: 0.9071 r:0.3469
ro_en Dev loss: 0.4183 r:0.8158
et_en Dev loss: 0.4135 r:0.6956
si_en Dev loss: 0.7516 r:0.5993
ne_en Dev loss: 0.4973 r:0.7475
ru_en Dev loss: 0.5977 r:0.7104
Current avg r:0.5835 Best avg r: 0.6061
19:21:34,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:52,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:23,677 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4495
en_de Dev loss: 0.8745 r:0.1683
en_zh Dev loss: 0.7934 r:0.3725
ro_en Dev loss: 0.3385 r:0.8196
et_en Dev loss: 0.3796 r:0.6939
si_en Dev loss: 0.7577 r:0.5984
ne_en Dev loss: 0.5187 r:0.7498
ru_en Dev loss: 0.4452 r:0.7303
Current avg r:0.5904 Best avg r: 0.6061
19:28:17,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:43,92 root INFO 
id:ro_en cur r: 0.8292 best r: 0.8292
19:29:35,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:06,22 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4164
en_de Dev loss: 0.8892 r:0.1558
en_zh Dev loss: 0.7192 r:0.3762
ro_en Dev loss: 0.2851 r:0.8316
et_en Dev loss: 0.3798 r:0.7124
si_en Dev loss: 0.5692 r:0.6206
ne_en Dev loss: 0.3476 r:0.7576
ru_en Dev loss: 0.3690 r:0.7518
Current avg r:0.6009 Best avg r: 0.6061
19:34:59,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:17,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:48,174 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4137
en_de Dev loss: 0.9192 r:0.1548
en_zh Dev loss: 0.8558 r:0.3707
ro_en Dev loss: 0.3701 r:0.8214
et_en Dev loss: 0.3919 r:0.7039
si_en Dev loss: 0.7451 r:0.6056
ne_en Dev loss: 0.4864 r:0.7554
ru_en Dev loss: 0.5081 r:0.7281
Current avg r:0.5914 Best avg r: 0.6061
19:41:41,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:59,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:30,357 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4053
en_de Dev loss: 0.8882 r:0.1664
en_zh Dev loss: 0.7774 r:0.3709
ro_en Dev loss: 0.3272 r:0.8269
et_en Dev loss: 0.3927 r:0.7042
si_en Dev loss: 0.6578 r:0.6151
ne_en Dev loss: 0.3810 r:0.7585
ru_en Dev loss: 0.4542 r:0.7436
Current avg r:0.5979 Best avg r: 0.6061
19:48:25,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:43,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:14,18 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3551
en_de Dev loss: 0.8957 r:0.1530
en_zh Dev loss: 0.8284 r:0.3502
ro_en Dev loss: 0.3516 r:0.8231
et_en Dev loss: 0.3913 r:0.6939
si_en Dev loss: 0.7495 r:0.6007
ne_en Dev loss: 0.4630 r:0.7528
ru_en Dev loss: 0.4328 r:0.7456
Current avg r:0.5885 Best avg r: 0.6061
19:55:07,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:25,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:56,195 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3852
en_de Dev loss: 0.9396 r:0.1657
en_zh Dev loss: 0.9613 r:0.3417
ro_en Dev loss: 0.4377 r:0.8193
et_en Dev loss: 0.4144 r:0.6970
si_en Dev loss: 0.9313 r:0.5995
ne_en Dev loss: 0.4728 r:0.7539
ru_en Dev loss: 0.5422 r:0.7366
Current avg r:0.5877 Best avg r: 0.6061
20:01:49,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:07,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:38,254 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3873
en_de Dev loss: 0.8874 r:0.1776
en_zh Dev loss: 0.8267 r:0.3611
ro_en Dev loss: 0.3438 r:0.8251
et_en Dev loss: 0.3931 r:0.6997
si_en Dev loss: 0.7698 r:0.6028
ne_en Dev loss: 0.3967 r:0.7560
ru_en Dev loss: 0.4629 r:0.7405
Current avg r:0.5947 Best avg r: 0.6061
20:08:31,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:49,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:20,623 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3744
en_de Dev loss: 0.8970 r:0.1607
en_zh Dev loss: 0.8351 r:0.3447
ro_en Dev loss: 0.3232 r:0.8246
et_en Dev loss: 0.3835 r:0.6905
si_en Dev loss: 0.7822 r:0.5957
ne_en Dev loss: 0.4091 r:0.7503
ru_en Dev loss: 0.4740 r:0.7182
Current avg r:0.5835 Best avg r: 0.6061
20:15:14,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:32,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:03,191 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3806
en_de Dev loss: 0.8757 r:0.1548
en_zh Dev loss: 0.7562 r:0.3486
ro_en Dev loss: 0.2928 r:0.8252
et_en Dev loss: 0.3819 r:0.7010
si_en Dev loss: 0.6603 r:0.6017
ne_en Dev loss: 0.3891 r:0.7527
ru_en Dev loss: 0.3983 r:0.7358
Current avg r:0.5885 Best avg r: 0.6061
20:21:56,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:14,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:45,702 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3699
en_de Dev loss: 0.9665 r:0.1408
en_zh Dev loss: 1.0122 r:0.3438
ro_en Dev loss: 0.4800 r:0.8162
et_en Dev loss: 0.4790 r:0.6758
si_en Dev loss: 1.0249 r:0.5788
ne_en Dev loss: 0.6111 r:0.7444
ru_en Dev loss: 0.6050 r:0.7094
Current avg r:0.5727 Best avg r: 0.6061
20:28:39,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:56,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:27,980 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3791
en_de Dev loss: 0.9031 r:0.1560
en_zh Dev loss: 0.8596 r:0.3622
ro_en Dev loss: 0.3969 r:0.8211
et_en Dev loss: 0.4068 r:0.6908
si_en Dev loss: 0.8324 r:0.5938
ne_en Dev loss: 0.4976 r:0.7584
ru_en Dev loss: 0.5050 r:0.7168
Current avg r:0.5856 Best avg r: 0.6061
20:35:21,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:39,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:10,638 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3885
en_de Dev loss: 0.8628 r:0.1740
en_zh Dev loss: 0.7816 r:0.3479
ro_en Dev loss: 0.3402 r:0.8193
et_en Dev loss: 0.3950 r:0.6920
si_en Dev loss: 0.7303 r:0.5967
ne_en Dev loss: 0.4035 r:0.7535
ru_en Dev loss: 0.4453 r:0.7210
Current avg r:0.5864 Best avg r: 0.6061
20:42:04,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:22,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:53,366 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3560
en_de Dev loss: 0.8800 r:0.1596
en_zh Dev loss: 0.7596 r:0.3555
ro_en Dev loss: 0.3167 r:0.8208
et_en Dev loss: 0.4014 r:0.6955
si_en Dev loss: 0.6781 r:0.5995
ne_en Dev loss: 0.3867 r:0.7534
ru_en Dev loss: 0.4067 r:0.7346
Current avg r:0.5884 Best avg r: 0.6061
20:48:47,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:05,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:35,995 root INFO Epoch 3 Global steps: 33000 Train loss: 0.4025
en_de Dev loss: 0.8761 r:0.1876
en_zh Dev loss: 0.8418 r:0.3262
ro_en Dev loss: 0.3704 r:0.8151
et_en Dev loss: 0.4225 r:0.6776
si_en Dev loss: 0.7959 r:0.5912
ne_en Dev loss: 0.5611 r:0.7525
ru_en Dev loss: 0.5168 r:0.7080
Current avg r:0.5798 Best avg r: 0.6061
20:55:29,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:47,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:18,62 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3634
en_de Dev loss: 0.8852 r:0.1668
en_zh Dev loss: 0.8419 r:0.3179
ro_en Dev loss: 0.3779 r:0.8173
et_en Dev loss: 0.4204 r:0.6844
si_en Dev loss: 0.8067 r:0.5818
ne_en Dev loss: 0.4988 r:0.7477
ru_en Dev loss: 0.4212 r:0.7470
Current avg r:0.5804 Best avg r: 0.6061
21:02:11,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:28,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:59,287 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3705
en_de Dev loss: 0.8850 r:0.1637
en_zh Dev loss: 0.8205 r:0.3346
ro_en Dev loss: 0.3543 r:0.8224
et_en Dev loss: 0.4176 r:0.6915
si_en Dev loss: 0.6955 r:0.6023
ne_en Dev loss: 0.4118 r:0.7495
ru_en Dev loss: 0.4551 r:0.7338
Current avg r:0.5854 Best avg r: 0.6061
21:08:51,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:56,666 root INFO 
id:ne_en cur r: 0.7665 best r: 0.7665
21:10:09,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:40,196 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3691
en_de Dev loss: 0.8830 r:0.1504
en_zh Dev loss: 0.8431 r:0.3225
ro_en Dev loss: 0.3545 r:0.8225
et_en Dev loss: 0.3991 r:0.6934
si_en Dev loss: 0.8032 r:0.5924
ne_en Dev loss: 0.4791 r:0.7598
ru_en Dev loss: 0.4488 r:0.7314
Current avg r:0.5818 Best avg r: 0.6061
21:15:33,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:58,921 root INFO 
id:ro_en cur r: 0.8293 best r: 0.8293
21:16:50,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:21,601 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3622
en_de Dev loss: 0.8949 r:0.1446
en_zh Dev loss: 0.8351 r:0.3310
ro_en Dev loss: 0.3325 r:0.8275
et_en Dev loss: 0.3803 r:0.7005
si_en Dev loss: 0.6894 r:0.6035
ne_en Dev loss: 0.3930 r:0.7581
ru_en Dev loss: 0.4412 r:0.7383
Current avg r:0.5862 Best avg r: 0.6061
21:22:14,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:40,867 root INFO 
id:ro_en cur r: 0.8298 best r: 0.8298
21:23:32,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:03,668 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3365
en_de Dev loss: 0.8711 r:0.1574
en_zh Dev loss: 0.8056 r:0.3269
ro_en Dev loss: 0.3102 r:0.8292
et_en Dev loss: 0.3857 r:0.6931
si_en Dev loss: 0.6989 r:0.5997
ne_en Dev loss: 0.4121 r:0.7572
ru_en Dev loss: 0.4614 r:0.7199
Current avg r:0.5834 Best avg r: 0.6061
21:28:57,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:15,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:46,696 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3237
en_de Dev loss: 0.8799 r:0.1767
en_zh Dev loss: 0.8267 r:0.3165
ro_en Dev loss: 0.3465 r:0.8205
et_en Dev loss: 0.3913 r:0.6951
si_en Dev loss: 0.7323 r:0.5927
ne_en Dev loss: 0.4133 r:0.7523
ru_en Dev loss: 0.4307 r:0.7326
Current avg r:0.5838 Best avg r: 0.6061
21:35:39,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:57,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:28,523 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3226
en_de Dev loss: 0.9017 r:0.1580
en_zh Dev loss: 0.8856 r:0.3075
ro_en Dev loss: 0.3731 r:0.8171
et_en Dev loss: 0.4068 r:0.6810
si_en Dev loss: 0.8870 r:0.5767
ne_en Dev loss: 0.5592 r:0.7500
ru_en Dev loss: 0.5124 r:0.6993
Current avg r:0.5700 Best avg r: 0.6061
21:42:21,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:39,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:10,425 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3044
en_de Dev loss: 0.9260 r:0.1504
en_zh Dev loss: 0.9635 r:0.2993
ro_en Dev loss: 0.4010 r:0.8173
et_en Dev loss: 0.4536 r:0.6663
si_en Dev loss: 1.0652 r:0.5612
ne_en Dev loss: 0.6150 r:0.7455
ru_en Dev loss: 0.5758 r:0.6963
Current avg r:0.5623 Best avg r: 0.6061
21:49:03,613 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:21,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:52,331 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3356
en_de Dev loss: 0.9138 r:0.1513
en_zh Dev loss: 0.9305 r:0.3017
ro_en Dev loss: 0.3583 r:0.8250
et_en Dev loss: 0.4103 r:0.6891
si_en Dev loss: 0.8341 r:0.5864
ne_en Dev loss: 0.5048 r:0.7476
ru_en Dev loss: 0.5329 r:0.7166
Current avg r:0.5740 Best avg r: 0.6061
21:55:45,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:03,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:34,398 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3252
en_de Dev loss: 0.8891 r:0.1350
en_zh Dev loss: 0.8558 r:0.2957
ro_en Dev loss: 0.3248 r:0.8240
et_en Dev loss: 0.3903 r:0.6848
si_en Dev loss: 0.7075 r:0.5906
ne_en Dev loss: 0.4072 r:0.7424
ru_en Dev loss: 0.4932 r:0.7005
Current avg r:0.5676 Best avg r: 0.6061
22:02:27,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:45,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:16,444 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3263
en_de Dev loss: 0.8994 r:0.1648
en_zh Dev loss: 0.8645 r:0.3273
ro_en Dev loss: 0.3754 r:0.8229
et_en Dev loss: 0.4135 r:0.6910
si_en Dev loss: 0.7808 r:0.5930
ne_en Dev loss: 0.4704 r:0.7518
ru_en Dev loss: 0.4804 r:0.7317
Current avg r:0.5832 Best avg r: 0.6061
22:09:09,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:27,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:58,549 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3319
en_de Dev loss: 0.8896 r:0.1426
en_zh Dev loss: 0.8351 r:0.3094
ro_en Dev loss: 0.3640 r:0.8229
et_en Dev loss: 0.4423 r:0.6735
si_en Dev loss: 0.7680 r:0.5843
ne_en Dev loss: 0.4799 r:0.7416
ru_en Dev loss: 0.4963 r:0.7003
Current avg r:0.5678 Best avg r: 0.6061
22:15:51,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:09,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:40,708 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3173
en_de Dev loss: 0.9187 r:0.1555
en_zh Dev loss: 0.9162 r:0.3124
ro_en Dev loss: 0.4098 r:0.8238
et_en Dev loss: 0.4446 r:0.6801
si_en Dev loss: 0.9095 r:0.5799
ne_en Dev loss: 0.5620 r:0.7419
ru_en Dev loss: 0.5424 r:0.7190
Current avg r:0.5732 Best avg r: 0.6061
22:22:34,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:52,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:25:23,112 root INFO Epoch 4 Global steps: 41400 Train loss: 0.2962
en_de Dev loss: 0.8866 r:0.1610
en_zh Dev loss: 0.8149 r:0.3288
ro_en Dev loss: 0.3588 r:0.8237
et_en Dev loss: 0.4275 r:0.6842
si_en Dev loss: 0.7671 r:0.5881
ne_en Dev loss: 0.4750 r:0.7441
ru_en Dev loss: 0.4698 r:0.7183
Current avg r:0.5783 Best avg r: 0.6061
22:29:16,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:34,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:05,626 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3354
en_de Dev loss: 0.9015 r:0.1531
en_zh Dev loss: 0.8425 r:0.3244
ro_en Dev loss: 0.3812 r:0.8260
et_en Dev loss: 0.4149 r:0.6903
si_en Dev loss: 0.7272 r:0.5977
ne_en Dev loss: 0.5030 r:0.7423
ru_en Dev loss: 0.4257 r:0.7420
Current avg r:0.5822 Best avg r: 0.6061
22:35:59,183 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:17,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:48,36 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3267
en_de Dev loss: 0.9352 r:0.1446
en_zh Dev loss: 0.8961 r:0.3145
ro_en Dev loss: 0.3789 r:0.8189
et_en Dev loss: 0.4492 r:0.6718
si_en Dev loss: 0.8592 r:0.5768
ne_en Dev loss: 0.4881 r:0.7383
ru_en Dev loss: 0.5116 r:0.7174
Current avg r:0.5689 Best avg r: 0.6061
22:42:41,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:59,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:30,468 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3077
en_de Dev loss: 0.8966 r:0.1551
en_zh Dev loss: 0.8480 r:0.3307
ro_en Dev loss: 0.3544 r:0.8225
et_en Dev loss: 0.4217 r:0.6940
si_en Dev loss: 0.7632 r:0.5916
ne_en Dev loss: 0.4232 r:0.7437
ru_en Dev loss: 0.4524 r:0.7368
Current avg r:0.5821 Best avg r: 0.6061
22:49:24,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:41,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:12,952 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3017
en_de Dev loss: 0.8890 r:0.1451
en_zh Dev loss: 0.8707 r:0.3009
ro_en Dev loss: 0.3572 r:0.8184
et_en Dev loss: 0.4455 r:0.6727
si_en Dev loss: 0.7945 r:0.5756
ne_en Dev loss: 0.4562 r:0.7416
ru_en Dev loss: 0.4830 r:0.7054
Current avg r:0.5657 Best avg r: 0.6061
22:56:06,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:24,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:55,219 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3096
en_de Dev loss: 0.9208 r:0.1285
en_zh Dev loss: 0.9555 r:0.2898
ro_en Dev loss: 0.4125 r:0.8168
et_en Dev loss: 0.4435 r:0.6725
si_en Dev loss: 0.8476 r:0.5765
ne_en Dev loss: 0.5283 r:0.7401
ru_en Dev loss: 0.5790 r:0.6797
Current avg r:0.5577 Best avg r: 0.6061
23:02:48,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:06,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:37,252 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3142
en_de Dev loss: 0.9162 r:0.1443
en_zh Dev loss: 0.9030 r:0.2954
ro_en Dev loss: 0.3523 r:0.8231
et_en Dev loss: 0.4278 r:0.6805
si_en Dev loss: 0.7425 r:0.5928
ne_en Dev loss: 0.4289 r:0.7459
ru_en Dev loss: 0.5044 r:0.7028
Current avg r:0.5693 Best avg r: 0.6061
23:09:32,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:50,366 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:21,253 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2761
en_de Dev loss: 0.9590 r:0.1600
en_zh Dev loss: 1.0269 r:0.3028
ro_en Dev loss: 0.4745 r:0.8173
et_en Dev loss: 0.5112 r:0.6640
si_en Dev loss: 1.0165 r:0.5721
ne_en Dev loss: 0.6001 r:0.7438
ru_en Dev loss: 0.6142 r:0.7030
Current avg r:0.5661 Best avg r: 0.6061
23:16:14,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:32,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:03,174 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2782
en_de Dev loss: 0.8866 r:0.1737
en_zh Dev loss: 0.8872 r:0.3098
ro_en Dev loss: 0.3727 r:0.8196
et_en Dev loss: 0.4465 r:0.6782
si_en Dev loss: 0.7946 r:0.5842
ne_en Dev loss: 0.4742 r:0.7442
ru_en Dev loss: 0.4654 r:0.7223
Current avg r:0.5760 Best avg r: 0.6061
23:22:56,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:14,139 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:44,967 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2826
en_de Dev loss: 0.8755 r:0.1721
en_zh Dev loss: 0.8540 r:0.3098
ro_en Dev loss: 0.3613 r:0.8177
et_en Dev loss: 0.4505 r:0.6746
si_en Dev loss: 0.7764 r:0.5810
ne_en Dev loss: 0.5261 r:0.7403
ru_en Dev loss: 0.4980 r:0.6958
Current avg r:0.5702 Best avg r: 0.6061
23:29:37,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:55,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:32:26,756 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2657
en_de Dev loss: 0.9320 r:0.1471
en_zh Dev loss: 0.9538 r:0.3062
ro_en Dev loss: 0.3929 r:0.8153
et_en Dev loss: 0.4336 r:0.6750
si_en Dev loss: 0.8480 r:0.5746
ne_en Dev loss: 0.6151 r:0.7364
ru_en Dev loss: 0.5130 r:0.7126
Current avg r:0.5667 Best avg r: 0.6061
23:36:20,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:38,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:09,95 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2849
en_de Dev loss: 0.8982 r:0.1764
en_zh Dev loss: 0.8921 r:0.3132
ro_en Dev loss: 0.3590 r:0.8237
et_en Dev loss: 0.4316 r:0.6856
si_en Dev loss: 0.8112 r:0.5840
ne_en Dev loss: 0.4667 r:0.7415
ru_en Dev loss: 0.4269 r:0.7480
Current avg r:0.5818 Best avg r: 0.6061
23:43:02,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:20,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:50,949 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2748
en_de Dev loss: 0.8841 r:0.1819
en_zh Dev loss: 0.8808 r:0.3045
ro_en Dev loss: 0.3542 r:0.8231
et_en Dev loss: 0.4502 r:0.6803
si_en Dev loss: 0.8531 r:0.5739
ne_en Dev loss: 0.5139 r:0.7407
ru_en Dev loss: 0.4642 r:0.7236
Current avg r:0.5754 Best avg r: 0.6061
23:49:44,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:01,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:32,424 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2557
en_de Dev loss: 0.9398 r:0.1597
en_zh Dev loss: 1.0080 r:0.3101
ro_en Dev loss: 0.4543 r:0.8178
et_en Dev loss: 0.4710 r:0.6679
si_en Dev loss: 0.9454 r:0.5711
ne_en Dev loss: 0.5441 r:0.7432
ru_en Dev loss: 0.5679 r:0.7174
Current avg r:0.5696 Best avg r: 0.6061
23:56:25,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:42,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:13,469 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2725
en_de Dev loss: 0.9210 r:0.1837
en_zh Dev loss: 0.9306 r:0.3127
ro_en Dev loss: 0.4020 r:0.8193
et_en Dev loss: 0.4500 r:0.6712
si_en Dev loss: 0.8927 r:0.5659
ne_en Dev loss: 0.4988 r:0.7431
ru_en Dev loss: 0.5301 r:0.7136
Current avg r:0.5728 Best avg r: 0.6061
00:03:06,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:23,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:54,402 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2756
en_de Dev loss: 0.8880 r:0.1845
en_zh Dev loss: 0.8769 r:0.3205
ro_en Dev loss: 0.3666 r:0.8213
et_en Dev loss: 0.4357 r:0.6718
si_en Dev loss: 0.8450 r:0.5705
ne_en Dev loss: 0.5048 r:0.7401
ru_en Dev loss: 0.5022 r:0.7117
Current avg r:0.5743 Best avg r: 0.6061
00:09:47,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:04,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:35,269 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2520
en_de Dev loss: 0.8852 r:0.1755
en_zh Dev loss: 0.8362 r:0.3294
ro_en Dev loss: 0.3387 r:0.8157
et_en Dev loss: 0.4436 r:0.6709
si_en Dev loss: 0.7672 r:0.5639
ne_en Dev loss: 0.4425 r:0.7357
ru_en Dev loss: 0.4562 r:0.7160
Current avg r:0.5724 Best avg r: 0.6061
00:16:27,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:45,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:16,60 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2723
en_de Dev loss: 0.8815 r:0.1969
en_zh Dev loss: 0.8592 r:0.3283
ro_en Dev loss: 0.3617 r:0.8200
et_en Dev loss: 0.4527 r:0.6681
si_en Dev loss: 0.8539 r:0.5672
ne_en Dev loss: 0.4902 r:0.7375
ru_en Dev loss: 0.5165 r:0.7062
Current avg r:0.5749 Best avg r: 0.6061
00:23:08,767 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:26,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:56,892 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2764
en_de Dev loss: 0.9186 r:0.1717
en_zh Dev loss: 0.9327 r:0.3076
ro_en Dev loss: 0.3982 r:0.8196
et_en Dev loss: 0.4524 r:0.6691
si_en Dev loss: 0.8779 r:0.5673
ne_en Dev loss: 0.5268 r:0.7417
ru_en Dev loss: 0.4852 r:0.7203
Current avg r:0.5710 Best avg r: 0.6061
00:29:49,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:07,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:37,736 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2813
en_de Dev loss: 0.9096 r:0.1750
en_zh Dev loss: 0.9262 r:0.3055
ro_en Dev loss: 0.4080 r:0.8143
et_en Dev loss: 0.4483 r:0.6605
si_en Dev loss: 0.8999 r:0.5638
ne_en Dev loss: 0.5607 r:0.7431
ru_en Dev loss: 0.5524 r:0.6960
Current avg r:0.5655 Best avg r: 0.6061
00:36:30,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:47,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:18,430 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2713
en_de Dev loss: 0.9042 r:0.1786
en_zh Dev loss: 0.9040 r:0.3045
ro_en Dev loss: 0.3721 r:0.8214
et_en Dev loss: 0.4573 r:0.6581
si_en Dev loss: 0.8589 r:0.5717
ne_en Dev loss: 0.5285 r:0.7318
ru_en Dev loss: 0.4960 r:0.7139
Current avg r:0.5686 Best avg r: 0.6061
00:43:11,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:28,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:59,203 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2816
en_de Dev loss: 0.8811 r:0.1757
en_zh Dev loss: 0.8440 r:0.3132
ro_en Dev loss: 0.3408 r:0.8231
et_en Dev loss: 0.4338 r:0.6719
si_en Dev loss: 0.8121 r:0.5742
ne_en Dev loss: 0.4849 r:0.7411
ru_en Dev loss: 0.4489 r:0.7234
Current avg r:0.5747 Best avg r: 0.6061
00:49:52,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:10,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:40,801 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2399
en_de Dev loss: 0.9434 r:0.1704
en_zh Dev loss: 0.9817 r:0.2893
ro_en Dev loss: 0.4248 r:0.8133
et_en Dev loss: 0.4973 r:0.6482
si_en Dev loss: 0.9308 r:0.5622
ne_en Dev loss: 0.5976 r:0.7315
ru_en Dev loss: 0.5708 r:0.6929
Current avg r:0.5583 Best avg r: 0.6061
00:56:33,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:50,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:21,46 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2585
en_de Dev loss: 0.8870 r:0.1912
en_zh Dev loss: 0.9004 r:0.2974
ro_en Dev loss: 0.3440 r:0.8225
et_en Dev loss: 0.4602 r:0.6633
si_en Dev loss: 0.8053 r:0.5775
ne_en Dev loss: 0.5000 r:0.7266
ru_en Dev loss: 0.4907 r:0.7091
Current avg r:0.5696 Best avg r: 0.6061
01:03:13,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:30,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:01,159 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2463
en_de Dev loss: 0.9051 r:0.1850
en_zh Dev loss: 0.9401 r:0.3010
ro_en Dev loss: 0.3814 r:0.8246
et_en Dev loss: 0.4634 r:0.6681
si_en Dev loss: 0.9423 r:0.5648
ne_en Dev loss: 0.5351 r:0.7279
ru_en Dev loss: 0.5170 r:0.7140
Current avg r:0.5693 Best avg r: 0.6061
01:09:53,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:10,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:41,133 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2311
en_de Dev loss: 0.9127 r:0.1535
en_zh Dev loss: 0.8996 r:0.3164
ro_en Dev loss: 0.3612 r:0.8190
et_en Dev loss: 0.4533 r:0.6555
si_en Dev loss: 0.8836 r:0.5609
ne_en Dev loss: 0.5344 r:0.7353
ru_en Dev loss: 0.5365 r:0.6969
Current avg r:0.5625 Best avg r: 0.6061
01:16:33,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:50,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:21,13 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2341
en_de Dev loss: 0.9169 r:0.1783
en_zh Dev loss: 0.8963 r:0.3061
ro_en Dev loss: 0.3493 r:0.8195
et_en Dev loss: 0.4551 r:0.6641
si_en Dev loss: 0.7771 r:0.5729
ne_en Dev loss: 0.4548 r:0.7341
ru_en Dev loss: 0.4833 r:0.7172
Current avg r:0.5703 Best avg r: 0.6061
01:23:13,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:24:30,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:00,829 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2397
en_de Dev loss: 0.8964 r:0.1719
en_zh Dev loss: 0.9276 r:0.2923
ro_en Dev loss: 0.3945 r:0.8172
et_en Dev loss: 0.4638 r:0.6446
si_en Dev loss: 0.9000 r:0.5544
ne_en Dev loss: 0.5496 r:0.7267
ru_en Dev loss: 0.5181 r:0.6963
Current avg r:0.5576 Best avg r: 0.6061
01:29:52,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:10,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:40,603 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2277
en_de Dev loss: 0.9243 r:0.1497
en_zh Dev loss: 0.9696 r:0.2709
ro_en Dev loss: 0.3707 r:0.8165
et_en Dev loss: 0.4781 r:0.6419
si_en Dev loss: 0.9719 r:0.5483
ne_en Dev loss: 0.5685 r:0.7243
ru_en Dev loss: 0.4999 r:0.6970
Current avg r:0.5498 Best avg r: 0.6061
01:36:32,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:37:50,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:20,379 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2363
en_de Dev loss: 0.8898 r:0.1384
en_zh Dev loss: 0.8926 r:0.2899
ro_en Dev loss: 0.3404 r:0.8223
et_en Dev loss: 0.4535 r:0.6586
si_en Dev loss: 0.8545 r:0.5639
ne_en Dev loss: 0.5456 r:0.7289
ru_en Dev loss: 0.4886 r:0.7029
Current avg r:0.5578 Best avg r: 0.6061
01:43:12,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:29,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:46:00,93 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2561
en_de Dev loss: 0.9268 r:0.1947
en_zh Dev loss: 0.9396 r:0.3176
ro_en Dev loss: 0.3818 r:0.8188
et_en Dev loss: 0.5060 r:0.6617
si_en Dev loss: 0.8756 r:0.5630
ne_en Dev loss: 0.5146 r:0.7329
ru_en Dev loss: 0.4960 r:0.7119
Current avg r:0.5715 Best avg r: 0.6061
01:49:52,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:09,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:39,971 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2284
en_de Dev loss: 0.9262 r:0.1202
en_zh Dev loss: 0.8882 r:0.3053
ro_en Dev loss: 0.3572 r:0.8206
et_en Dev loss: 0.4538 r:0.6633
si_en Dev loss: 0.8212 r:0.5674
ne_en Dev loss: 0.4785 r:0.7316
ru_en Dev loss: 0.4803 r:0.7097
Current avg r:0.5597 Best avg r: 0.6061
01:56:32,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:49,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:19,885 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2381
en_de Dev loss: 0.8960 r:0.1572
en_zh Dev loss: 0.8473 r:0.3141
ro_en Dev loss: 0.3358 r:0.8199
et_en Dev loss: 0.4632 r:0.6667
si_en Dev loss: 0.7706 r:0.5642
ne_en Dev loss: 0.4607 r:0.7356
ru_en Dev loss: 0.4435 r:0.7205
Current avg r:0.5683 Best avg r: 0.6061
02:03:12,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:04:29,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:06:00,96 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2324
en_de Dev loss: 0.8994 r:0.1685
en_zh Dev loss: 0.9248 r:0.2961
ro_en Dev loss: 0.4180 r:0.8160
et_en Dev loss: 0.4841 r:0.6598
si_en Dev loss: 0.9511 r:0.5583
ne_en Dev loss: 0.5778 r:0.7302
ru_en Dev loss: 0.4963 r:0.7155
Current avg r:0.5635 Best avg r: 0.6061
02:09:52,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:11:09,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:12:40,87 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2433
en_de Dev loss: 0.9204 r:0.1552
en_zh Dev loss: 0.9514 r:0.2918
ro_en Dev loss: 0.3784 r:0.8191
et_en Dev loss: 0.4911 r:0.6543
si_en Dev loss: 0.8737 r:0.5609
ne_en Dev loss: 0.4815 r:0.7299
ru_en Dev loss: 0.5076 r:0.7123
Current avg r:0.5605 Best avg r: 0.6061
02:16:32,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:17:49,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:20,293 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2321
en_de Dev loss: 0.9114 r:0.1420
en_zh Dev loss: 0.9142 r:0.2843
ro_en Dev loss: 0.3613 r:0.8189
et_en Dev loss: 0.4481 r:0.6539
si_en Dev loss: 0.8291 r:0.5655
ne_en Dev loss: 0.5404 r:0.7247
ru_en Dev loss: 0.5163 r:0.7010
Current avg r:0.5557 Best avg r: 0.6061
02:23:12,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:30,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:26:00,515 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2441
en_de Dev loss: 0.9410 r:0.1353
en_zh Dev loss: 0.9643 r:0.2787
ro_en Dev loss: 0.3862 r:0.8138
et_en Dev loss: 0.4628 r:0.6621
si_en Dev loss: 0.8849 r:0.5607
ne_en Dev loss: 0.4957 r:0.7281
ru_en Dev loss: 0.5435 r:0.6973
Current avg r:0.5537 Best avg r: 0.6061
02:29:54,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:11,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:32:42,173 root INFO Epoch 7 Global steps: 63600 Train loss: 0.2145
en_de Dev loss: 0.9159 r:0.1499
en_zh Dev loss: 0.9459 r:0.2949
ro_en Dev loss: 0.3766 r:0.8163
et_en Dev loss: 0.4597 r:0.6661
si_en Dev loss: 0.8843 r:0.5570
ne_en Dev loss: 0.5709 r:0.7317
ru_en Dev loss: 0.5028 r:0.7130
Current avg r:0.5613 Best avg r: 0.6061
02:36:34,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:51,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:39:22,269 root INFO Epoch 7 Global steps: 64200 Train loss: 0.2091
en_de Dev loss: 0.9454 r:0.1418
en_zh Dev loss: 0.9564 r:0.2911
ro_en Dev loss: 0.3602 r:0.8176
et_en Dev loss: 0.4761 r:0.6539
si_en Dev loss: 0.9098 r:0.5531
ne_en Dev loss: 0.4977 r:0.7308
ru_en Dev loss: 0.5275 r:0.7074
Current avg r:0.5565 Best avg r: 0.6061
02:43:14,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:44:32,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:46:02,549 root INFO Epoch 7 Global steps: 64800 Train loss: 0.2207
en_de Dev loss: 0.9084 r:0.1522
en_zh Dev loss: 0.8958 r:0.2982
ro_en Dev loss: 0.3374 r:0.8167
et_en Dev loss: 0.4492 r:0.6632
si_en Dev loss: 0.8527 r:0.5533
ne_en Dev loss: 0.4775 r:0.7313
ru_en Dev loss: 0.4556 r:0.7224
Current avg r:0.5625 Best avg r: 0.6061
02:49:54,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:12,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:42,787 root INFO Epoch 7 Global steps: 65400 Train loss: 0.2132
en_de Dev loss: 0.8991 r:0.1569
en_zh Dev loss: 0.9411 r:0.2905
ro_en Dev loss: 0.3515 r:0.8145
et_en Dev loss: 0.4629 r:0.6553
si_en Dev loss: 0.9629 r:0.5488
ne_en Dev loss: 0.5871 r:0.7296
ru_en Dev loss: 0.4948 r:0.7047
Current avg r:0.5572 Best avg r: 0.6061
02:56:35,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:57:52,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:59:23,48 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1955
en_de Dev loss: 0.9120 r:0.1456
en_zh Dev loss: 0.9361 r:0.2870
ro_en Dev loss: 0.3565 r:0.8130
et_en Dev loss: 0.4533 r:0.6540
si_en Dev loss: 0.8500 r:0.5475
ne_en Dev loss: 0.5205 r:0.7352
ru_en Dev loss: 0.4814 r:0.7088
Current avg r:0.5559 Best avg r: 0.6061
03:03:15,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:04:32,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:06:03,221 root INFO Epoch 7 Global steps: 66600 Train loss: 0.2142
en_de Dev loss: 0.9217 r:0.1397
en_zh Dev loss: 0.9137 r:0.3030
ro_en Dev loss: 0.3854 r:0.8135
et_en Dev loss: 0.5059 r:0.6576
si_en Dev loss: 0.8723 r:0.5497
ne_en Dev loss: 0.4811 r:0.7348
ru_en Dev loss: 0.4870 r:0.7108
Current avg r:0.5584 Best avg r: 0.6061
03:09:55,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:11:13,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:12:43,509 root INFO Epoch 7 Global steps: 67200 Train loss: 0.2112
en_de Dev loss: 0.9164 r:0.1471
en_zh Dev loss: 0.9039 r:0.2995
ro_en Dev loss: 0.3508 r:0.8178
et_en Dev loss: 0.4878 r:0.6619
si_en Dev loss: 0.8380 r:0.5539
ne_en Dev loss: 0.4607 r:0.7330
ru_en Dev loss: 0.4454 r:0.7300
Current avg r:0.5633 Best avg r: 0.6061
03:16:35,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:17:53,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:23,799 root INFO Epoch 7 Global steps: 67800 Train loss: 0.2055
en_de Dev loss: 0.9134 r:0.1387
en_zh Dev loss: 0.9587 r:0.2842
ro_en Dev loss: 0.4011 r:0.8151
et_en Dev loss: 0.4632 r:0.6571
si_en Dev loss: 1.0429 r:0.5423
ne_en Dev loss: 0.6860 r:0.7290
ru_en Dev loss: 0.5406 r:0.6966
Current avg r:0.5518 Best avg r: 0.6061
03:23:16,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:24:33,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:26:04,138 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2098
en_de Dev loss: 0.9601 r:0.1422
en_zh Dev loss: 1.0284 r:0.2907
ro_en Dev loss: 0.4202 r:0.8134
et_en Dev loss: 0.4957 r:0.6526
si_en Dev loss: 0.9846 r:0.5477
ne_en Dev loss: 0.6415 r:0.7267
ru_en Dev loss: 0.5433 r:0.7166
Current avg r:0.5557 Best avg r: 0.6061
03:29:56,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:31:13,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:32:44,401 root INFO Epoch 7 Global steps: 69000 Train loss: 0.2185
en_de Dev loss: 0.9452 r:0.1512
en_zh Dev loss: 0.9922 r:0.2951
ro_en Dev loss: 0.3803 r:0.8123
et_en Dev loss: 0.4925 r:0.6496
si_en Dev loss: 0.9539 r:0.5471
ne_en Dev loss: 0.5128 r:0.7288
ru_en Dev loss: 0.4946 r:0.7234
Current avg r:0.5582 Best avg r: 0.6061
03:36:36,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:54,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:39:24,716 root INFO Epoch 7 Global steps: 69600 Train loss: 0.2014
en_de Dev loss: 0.9298 r:0.1457
en_zh Dev loss: 0.9809 r:0.2971
ro_en Dev loss: 0.3777 r:0.8153
et_en Dev loss: 0.4747 r:0.6514
si_en Dev loss: 0.9354 r:0.5483
ne_en Dev loss: 0.5051 r:0.7317
ru_en Dev loss: 0.5201 r:0.7161
Current avg r:0.5579 Best avg r: 0.6061
03:43:17,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:34,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:46:04,883 root INFO Epoch 7 Global steps: 70200 Train loss: 0.2120
en_de Dev loss: 0.9166 r:0.1617
en_zh Dev loss: 0.9722 r:0.2907
ro_en Dev loss: 0.4281 r:0.8063
et_en Dev loss: 0.4939 r:0.6479
si_en Dev loss: 0.9821 r:0.5399
ne_en Dev loss: 0.5559 r:0.7331
ru_en Dev loss: 0.5509 r:0.6984
Current avg r:0.5540 Best avg r: 0.6061
03:49:57,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:14,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:45,5 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1958
en_de Dev loss: 0.8917 r:0.1800
en_zh Dev loss: 0.9627 r:0.2968
ro_en Dev loss: 0.4387 r:0.8107
et_en Dev loss: 0.4831 r:0.6515
si_en Dev loss: 0.9552 r:0.5483
ne_en Dev loss: 0.5827 r:0.7334
ru_en Dev loss: 0.5003 r:0.7221
Current avg r:0.5633 Best avg r: 0.6061
03:56:37,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:54,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:59:25,419 root INFO Epoch 7 Global steps: 71400 Train loss: 0.2092
en_de Dev loss: 0.9145 r:0.1498
en_zh Dev loss: 0.9235 r:0.3015
ro_en Dev loss: 0.3924 r:0.8111
et_en Dev loss: 0.4845 r:0.6552
si_en Dev loss: 0.8704 r:0.5521
ne_en Dev loss: 0.5580 r:0.7290
ru_en Dev loss: 0.4620 r:0.7249
Current avg r:0.5605 Best avg r: 0.6061
04:03:18,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:35,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:06:06,209 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1975
en_de Dev loss: 0.9328 r:0.1483
en_zh Dev loss: 0.9656 r:0.3007
ro_en Dev loss: 0.4032 r:0.8121
et_en Dev loss: 0.4818 r:0.6561
si_en Dev loss: 0.8952 r:0.5481
ne_en Dev loss: 0.5302 r:0.7266
ru_en Dev loss: 0.5180 r:0.7081
Current avg r:0.5571 Best avg r: 0.6061
04:09:59,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:11:17,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:12:47,753 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1913
en_de Dev loss: 0.9531 r:0.1472
en_zh Dev loss: 0.9688 r:0.3026
ro_en Dev loss: 0.3983 r:0.8124
et_en Dev loss: 0.4977 r:0.6566
si_en Dev loss: 0.9099 r:0.5481
ne_en Dev loss: 0.5726 r:0.7261
ru_en Dev loss: 0.5251 r:0.7065
Current avg r:0.5571 Best avg r: 0.6061
04:16:40,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:17:57,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:28,76 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1921
en_de Dev loss: 0.9358 r:0.1345
en_zh Dev loss: 0.9496 r:0.2942
ro_en Dev loss: 0.3707 r:0.8139
et_en Dev loss: 0.5177 r:0.6540
si_en Dev loss: 0.8917 r:0.5537
ne_en Dev loss: 0.5543 r:0.7293
ru_en Dev loss: 0.4778 r:0.7207
Current avg r:0.5572 Best avg r: 0.6061
04:23:20,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:24:37,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:26:08,347 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1861
en_de Dev loss: 0.9336 r:0.1353
en_zh Dev loss: 0.9608 r:0.2974
ro_en Dev loss: 0.4161 r:0.8056
et_en Dev loss: 0.4768 r:0.6505
si_en Dev loss: 0.9440 r:0.5502
ne_en Dev loss: 0.5806 r:0.7292
ru_en Dev loss: 0.5129 r:0.7113
Current avg r:0.5542 Best avg r: 0.6061
04:30:00,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:31:18,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:32:48,864 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1761
en_de Dev loss: 0.9442 r:0.1436
en_zh Dev loss: 0.9439 r:0.2848
ro_en Dev loss: 0.3651 r:0.8100
et_en Dev loss: 0.4625 r:0.6494
si_en Dev loss: 0.8951 r:0.5508
ne_en Dev loss: 0.5251 r:0.7297
ru_en Dev loss: 0.4583 r:0.7242
Current avg r:0.5561 Best avg r: 0.6061
04:36:41,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:37:58,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:39:29,382 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1959
en_de Dev loss: 0.9283 r:0.1583
en_zh Dev loss: 0.9879 r:0.2944
ro_en Dev loss: 0.4019 r:0.8069
et_en Dev loss: 0.4688 r:0.6499
si_en Dev loss: 1.0233 r:0.5370
ne_en Dev loss: 0.6750 r:0.7285
ru_en Dev loss: 0.5333 r:0.7047
Current avg r:0.5543 Best avg r: 0.6061
04:43:21,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:39,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:46:09,723 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1806
en_de Dev loss: 0.9366 r:0.1537
en_zh Dev loss: 0.9753 r:0.2875
ro_en Dev loss: 0.3689 r:0.8125
et_en Dev loss: 0.4733 r:0.6576
si_en Dev loss: 0.9483 r:0.5399
ne_en Dev loss: 0.5435 r:0.7267
ru_en Dev loss: 0.4759 r:0.7272
Current avg r:0.5579 Best avg r: 0.6061
04:50:01,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:51:19,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:52:49,855 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1913
en_de Dev loss: 0.9133 r:0.1472
en_zh Dev loss: 0.9517 r:0.2941
ro_en Dev loss: 0.3690 r:0.8114
et_en Dev loss: 0.4720 r:0.6506
si_en Dev loss: 0.9310 r:0.5429
ne_en Dev loss: 0.5793 r:0.7235
ru_en Dev loss: 0.4993 r:0.7113
Current avg r:0.5544 Best avg r: 0.6061
04:56:42,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:59,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:59:30,190 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1886
en_de Dev loss: 0.9435 r:0.1390
en_zh Dev loss: 1.0195 r:0.3031
ro_en Dev loss: 0.4234 r:0.8085
et_en Dev loss: 0.5197 r:0.6414
si_en Dev loss: 1.0206 r:0.5371
ne_en Dev loss: 0.7153 r:0.7170
ru_en Dev loss: 0.5601 r:0.6999
Current avg r:0.5494 Best avg r: 0.6061
05:03:22,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:04:40,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:06:10,500 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1801
en_de Dev loss: 0.9433 r:0.1578
en_zh Dev loss: 0.9845 r:0.3090
ro_en Dev loss: 0.3852 r:0.8138
et_en Dev loss: 0.4963 r:0.6546
si_en Dev loss: 0.8668 r:0.5535
ne_en Dev loss: 0.4970 r:0.7222
ru_en Dev loss: 0.5191 r:0.7200
Current avg r:0.5616 Best avg r: 0.6061
05:10:02,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:11:20,458 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:12:50,850 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1778
en_de Dev loss: 0.9210 r:0.1569
en_zh Dev loss: 0.9160 r:0.3138
ro_en Dev loss: 0.3468 r:0.8167
et_en Dev loss: 0.4770 r:0.6547
si_en Dev loss: 0.8077 r:0.5562
ne_en Dev loss: 0.4873 r:0.7189
ru_en Dev loss: 0.4478 r:0.7327
Current avg r:0.5643 Best avg r: 0.6061
05:16:43,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:18:00,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:19:31,68 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1828
en_de Dev loss: 0.9068 r:0.1641
en_zh Dev loss: 0.9116 r:0.2983
ro_en Dev loss: 0.3478 r:0.8135
et_en Dev loss: 0.4982 r:0.6520
si_en Dev loss: 0.8802 r:0.5484
ne_en Dev loss: 0.5240 r:0.7188
ru_en Dev loss: 0.4576 r:0.7239
Current avg r:0.5599 Best avg r: 0.6061
05:23:23,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:24:40,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:11,268 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1789
en_de Dev loss: 0.9090 r:0.1572
en_zh Dev loss: 0.9432 r:0.2943
ro_en Dev loss: 0.3529 r:0.8128
et_en Dev loss: 0.4820 r:0.6523
si_en Dev loss: 0.8461 r:0.5473
ne_en Dev loss: 0.5428 r:0.7158
ru_en Dev loss: 0.4824 r:0.7176
Current avg r:0.5568 Best avg r: 0.6061
05:30:03,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:31:20,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:32:51,352 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1839
en_de Dev loss: 0.9153 r:0.1431
en_zh Dev loss: 0.9180 r:0.2956
ro_en Dev loss: 0.3651 r:0.8159
et_en Dev loss: 0.4927 r:0.6553
si_en Dev loss: 0.8509 r:0.5475
ne_en Dev loss: 0.5185 r:0.7256
ru_en Dev loss: 0.4383 r:0.7352
Current avg r:0.5597 Best avg r: 0.6061
05:36:43,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:38:01,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:39:31,414 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1843
en_de Dev loss: 0.9332 r:0.1432
en_zh Dev loss: 0.9365 r:0.3021
ro_en Dev loss: 0.3638 r:0.8143
et_en Dev loss: 0.4868 r:0.6568
si_en Dev loss: 0.9394 r:0.5408
ne_en Dev loss: 0.5974 r:0.7205
ru_en Dev loss: 0.4530 r:0.7291
Current avg r:0.5581 Best avg r: 0.6061
05:43:23,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:41,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:11,529 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1744
en_de Dev loss: 0.9461 r:0.1504
en_zh Dev loss: 0.9511 r:0.3094
ro_en Dev loss: 0.3910 r:0.8164
et_en Dev loss: 0.4941 r:0.6538
si_en Dev loss: 0.8708 r:0.5502
ne_en Dev loss: 0.4872 r:0.7241
ru_en Dev loss: 0.5039 r:0.7222
Current avg r:0.5609 Best avg r: 0.6061
05:50:05,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:22,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:52:53,164 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1661
en_de Dev loss: 0.9410 r:0.1512
en_zh Dev loss: 0.9543 r:0.2992
ro_en Dev loss: 0.3706 r:0.8174
et_en Dev loss: 0.4554 r:0.6548
si_en Dev loss: 0.8620 r:0.5505
ne_en Dev loss: 0.4758 r:0.7234
ru_en Dev loss: 0.5171 r:0.7116
Current avg r:0.5583 Best avg r: 0.6061
05:56:45,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:58:03,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:33,507 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1608
en_de Dev loss: 0.9251 r:0.1491
en_zh Dev loss: 0.9674 r:0.2990
ro_en Dev loss: 0.3782 r:0.8181
et_en Dev loss: 0.4805 r:0.6558
si_en Dev loss: 0.9400 r:0.5442
ne_en Dev loss: 0.5517 r:0.7210
ru_en Dev loss: 0.5463 r:0.7054
Current avg r:0.5561 Best avg r: 0.6061
06:03:25,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:43,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:06:13,834 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1636
en_de Dev loss: 0.9248 r:0.1801
en_zh Dev loss: 0.9628 r:0.3087
ro_en Dev loss: 0.4114 r:0.8147
et_en Dev loss: 0.4981 r:0.6472
si_en Dev loss: 0.9161 r:0.5465
ne_en Dev loss: 0.5684 r:0.7201
ru_en Dev loss: 0.5208 r:0.7157
Current avg r:0.5619 Best avg r: 0.6061
06:10:06,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:23,808 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:12:54,198 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1738
en_de Dev loss: 0.9135 r:0.1635
en_zh Dev loss: 0.9553 r:0.2885
ro_en Dev loss: 0.3916 r:0.8135
et_en Dev loss: 0.5182 r:0.6381
si_en Dev loss: 0.9979 r:0.5362
ne_en Dev loss: 0.6072 r:0.7170
ru_en Dev loss: 0.4789 r:0.7273
Current avg r:0.5549 Best avg r: 0.6061
06:16:46,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:18:04,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:19:34,522 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1641
en_de Dev loss: 0.9444 r:0.1611
en_zh Dev loss: 1.0010 r:0.2923
ro_en Dev loss: 0.4204 r:0.8132
et_en Dev loss: 0.5018 r:0.6449
si_en Dev loss: 1.0153 r:0.5452
ne_en Dev loss: 0.6502 r:0.7220
ru_en Dev loss: 0.5160 r:0.7209
Current avg r:0.5571 Best avg r: 0.6061
06:23:26,810 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:24:44,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:14,725 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1546
en_de Dev loss: 0.9044 r:0.1758
en_zh Dev loss: 0.9079 r:0.2996
ro_en Dev loss: 0.3724 r:0.8142
et_en Dev loss: 0.4801 r:0.6472
si_en Dev loss: 0.9036 r:0.5459
ne_en Dev loss: 0.5158 r:0.7207
ru_en Dev loss: 0.4574 r:0.7273
Current avg r:0.5615 Best avg r: 0.6061
06:30:07,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:31:24,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:55,54 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1609
en_de Dev loss: 0.9395 r:0.1604
en_zh Dev loss: 0.9894 r:0.2850
ro_en Dev loss: 0.4333 r:0.8145
et_en Dev loss: 0.5045 r:0.6405
si_en Dev loss: 0.9912 r:0.5395
ne_en Dev loss: 0.6441 r:0.7184
ru_en Dev loss: 0.5388 r:0.7084
Current avg r:0.5524 Best avg r: 0.6061
06:36:47,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:38:04,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:35,468 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1640
en_de Dev loss: 0.9322 r:0.1451
en_zh Dev loss: 0.9839 r:0.2821
ro_en Dev loss: 0.3878 r:0.8101
et_en Dev loss: 0.5108 r:0.6229
si_en Dev loss: 0.9810 r:0.5311
ne_en Dev loss: 0.5973 r:0.7149
ru_en Dev loss: 0.5009 r:0.7134
Current avg r:0.5457 Best avg r: 0.6061
06:43:27,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:44:45,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:15,875 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1643
en_de Dev loss: 0.9312 r:0.1465
en_zh Dev loss: 1.0079 r:0.2847
ro_en Dev loss: 0.4090 r:0.8092
et_en Dev loss: 0.5112 r:0.6295
si_en Dev loss: 1.0428 r:0.5270
ne_en Dev loss: 0.7000 r:0.7040
ru_en Dev loss: 0.5375 r:0.7123
Current avg r:0.5447 Best avg r: 0.6061
06:50:08,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:26,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:52:56,548 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1648
en_de Dev loss: 0.9488 r:0.1494
en_zh Dev loss: 0.9942 r:0.2875
ro_en Dev loss: 0.4068 r:0.8061
et_en Dev loss: 0.5175 r:0.6291
si_en Dev loss: 0.9996 r:0.5334
ne_en Dev loss: 0.6214 r:0.7109
ru_en Dev loss: 0.5071 r:0.7215
Current avg r:0.5483 Best avg r: 0.6061
06:56:49,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:58:06,765 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:59:37,338 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1670
en_de Dev loss: 0.9446 r:0.1551
en_zh Dev loss: 0.9601 r:0.3030
ro_en Dev loss: 0.3749 r:0.8155
et_en Dev loss: 0.5005 r:0.6527
si_en Dev loss: 0.8784 r:0.5535
ne_en Dev loss: 0.5293 r:0.7169
ru_en Dev loss: 0.5051 r:0.7226
Current avg r:0.5599 Best avg r: 0.6061
07:03:30,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:04:48,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:06:18,633 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1631
en_de Dev loss: 0.9535 r:0.1565
en_zh Dev loss: 0.9862 r:0.3016
ro_en Dev loss: 0.3689 r:0.8177
et_en Dev loss: 0.4828 r:0.6639
si_en Dev loss: 0.9107 r:0.5558
ne_en Dev loss: 0.5307 r:0.7191
ru_en Dev loss: 0.4755 r:0.7389
Current avg r:0.5648 Best avg r: 0.6061
07:10:11,791 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:11:29,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:13:00,56 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1577
en_de Dev loss: 0.9216 r:0.1542
en_zh Dev loss: 0.9381 r:0.2981
ro_en Dev loss: 0.3614 r:0.8155
et_en Dev loss: 0.5051 r:0.6578
si_en Dev loss: 0.8976 r:0.5454
ne_en Dev loss: 0.5373 r:0.7110
ru_en Dev loss: 0.4833 r:0.7216
Current avg r:0.5577 Best avg r: 0.6061
07:16:53,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:18:10,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:19:41,357 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1602
en_de Dev loss: 0.9600 r:0.1192
en_zh Dev loss: 0.9657 r:0.3076
ro_en Dev loss: 0.3744 r:0.8106
et_en Dev loss: 0.5122 r:0.6339
si_en Dev loss: 0.9348 r:0.5430
ne_en Dev loss: 0.6067 r:0.7087
ru_en Dev loss: 0.5294 r:0.7091
Current avg r:0.5474 Best avg r: 0.6061
07:23:34,219 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:24:51,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:22,354 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1603
en_de Dev loss: 0.9501 r:0.1380
en_zh Dev loss: 0.9290 r:0.3131
ro_en Dev loss: 0.3796 r:0.8138
et_en Dev loss: 0.5027 r:0.6598
si_en Dev loss: 0.8750 r:0.5529
ne_en Dev loss: 0.5902 r:0.7179
ru_en Dev loss: 0.4455 r:0.7445
Current avg r:0.5628 Best avg r: 0.6061
07:30:16,35 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:31:33,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:33:04,226 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1471
en_de Dev loss: 1.0047 r:0.1244
en_zh Dev loss: 1.1183 r:0.2937
ro_en Dev loss: 0.4647 r:0.8080
et_en Dev loss: 0.5324 r:0.6444
si_en Dev loss: 1.0639 r:0.5457
ne_en Dev loss: 0.7133 r:0.7179
ru_en Dev loss: 0.6083 r:0.7111
Current avg r:0.5493 Best avg r: 0.6061
07:36:56,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:14,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:39:44,952 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1510
en_de Dev loss: 0.9291 r:0.1421
en_zh Dev loss: 0.9422 r:0.3038
ro_en Dev loss: 0.3834 r:0.8103
et_en Dev loss: 0.4960 r:0.6548
si_en Dev loss: 0.9065 r:0.5493
ne_en Dev loss: 0.5664 r:0.7191
ru_en Dev loss: 0.4619 r:0.7298
Current avg r:0.5584 Best avg r: 0.6061
07:43:37,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:44:55,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:46:25,639 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1483
en_de Dev loss: 0.9581 r:0.1304
en_zh Dev loss: 1.0172 r:0.2947
ro_en Dev loss: 0.4328 r:0.8130
et_en Dev loss: 0.5086 r:0.6619
si_en Dev loss: 0.9894 r:0.5470
ne_en Dev loss: 0.5771 r:0.7171
ru_en Dev loss: 0.5302 r:0.7240
Current avg r:0.5555 Best avg r: 0.6061
07:50:18,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:51:35,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:53:06,116 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1494
en_de Dev loss: 0.9637 r:0.1234
en_zh Dev loss: 0.9908 r:0.2892
ro_en Dev loss: 0.3974 r:0.8110
et_en Dev loss: 0.4901 r:0.6437
si_en Dev loss: 1.0161 r:0.5362
ne_en Dev loss: 0.5991 r:0.7154
ru_en Dev loss: 0.5423 r:0.7085
Current avg r:0.5468 Best avg r: 0.6061
07:56:58,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:58:16,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:59:47,180 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1517
en_de Dev loss: 0.9947 r:0.1346
en_zh Dev loss: 0.9868 r:0.3092
ro_en Dev loss: 0.3711 r:0.8157
et_en Dev loss: 0.4905 r:0.6561
si_en Dev loss: 0.9646 r:0.5458
ne_en Dev loss: 0.5854 r:0.7165
ru_en Dev loss: 0.4742 r:0.7441
Current avg r:0.5603 Best avg r: 0.6061
08:03:39,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:04:57,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:06:28,121 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1501
en_de Dev loss: 0.9834 r:0.1394
en_zh Dev loss: 0.9979 r:0.2938
ro_en Dev loss: 0.3862 r:0.8154
et_en Dev loss: 0.4683 r:0.6620
si_en Dev loss: 0.9204 r:0.5450
ne_en Dev loss: 0.5445 r:0.7228
ru_en Dev loss: 0.4958 r:0.7334
Current avg r:0.5588 Best avg r: 0.6061
08:10:21,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:11:38,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:13:09,260 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1454
en_de Dev loss: 0.9597 r:0.1348
en_zh Dev loss: 0.9665 r:0.3062
ro_en Dev loss: 0.3769 r:0.8148
et_en Dev loss: 0.4826 r:0.6599
si_en Dev loss: 0.9490 r:0.5444
ne_en Dev loss: 0.5313 r:0.7261
ru_en Dev loss: 0.4949 r:0.7294
Current avg r:0.5594 Best avg r: 0.6061
08:17:01,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:18:19,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:19:50,48 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1435
en_de Dev loss: 0.9637 r:0.1397
en_zh Dev loss: 0.9682 r:0.3046
ro_en Dev loss: 0.3662 r:0.8134
et_en Dev loss: 0.5077 r:0.6484
si_en Dev loss: 0.9255 r:0.5389
ne_en Dev loss: 0.5639 r:0.7117
ru_en Dev loss: 0.4851 r:0.7244
Current avg r:0.5545 Best avg r: 0.6061
08:23:42,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:25:00,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:30,614 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1333
en_de Dev loss: 0.9699 r:0.1391
en_zh Dev loss: 1.0266 r:0.3025
ro_en Dev loss: 0.4164 r:0.8140
et_en Dev loss: 0.4820 r:0.6582
si_en Dev loss: 1.0251 r:0.5433
ne_en Dev loss: 0.6687 r:0.7175
ru_en Dev loss: 0.5098 r:0.7272
Current avg r:0.5574 Best avg r: 0.6061
08:30:23,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:31:40,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:33:11,274 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1445
en_de Dev loss: 0.9319 r:0.1488
en_zh Dev loss: 0.9804 r:0.2948
ro_en Dev loss: 0.3578 r:0.8136
et_en Dev loss: 0.4778 r:0.6642
si_en Dev loss: 0.8298 r:0.5493
ne_en Dev loss: 0.5526 r:0.7215
ru_en Dev loss: 0.4621 r:0.7254
Current avg r:0.5596 Best avg r: 0.6061
08:37:03,709 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:38:21,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:39:51,891 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1495
en_de Dev loss: 0.9602 r:0.1402
en_zh Dev loss: 1.0355 r:0.2847
ro_en Dev loss: 0.4044 r:0.8082
et_en Dev loss: 0.4920 r:0.6466
si_en Dev loss: 0.9909 r:0.5404
ne_en Dev loss: 0.7059 r:0.7137
ru_en Dev loss: 0.5367 r:0.7058
Current avg r:0.5485 Best avg r: 0.6061
08:43:44,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:45:01,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:46:32,470 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1449
en_de Dev loss: 0.9528 r:0.1504
en_zh Dev loss: 1.0005 r:0.2921
ro_en Dev loss: 0.3984 r:0.8126
et_en Dev loss: 0.5014 r:0.6570
si_en Dev loss: 0.9641 r:0.5494
ne_en Dev loss: 0.5891 r:0.7208
ru_en Dev loss: 0.5017 r:0.7248
Current avg r:0.5581 Best avg r: 0.6061
08:50:24,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:51:42,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:53:13,204 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1461
en_de Dev loss: 0.9543 r:0.1476
en_zh Dev loss: 0.9862 r:0.2919
ro_en Dev loss: 0.3751 r:0.8137
et_en Dev loss: 0.4786 r:0.6543
si_en Dev loss: 0.9299 r:0.5500
ne_en Dev loss: 0.5827 r:0.7181
ru_en Dev loss: 0.4816 r:0.7253
Current avg r:0.5573 Best avg r: 0.6061
08:57:06,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:58:23,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:59:54,377 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1416
en_de Dev loss: 0.9580 r:0.1365
en_zh Dev loss: 0.9816 r:0.2988
ro_en Dev loss: 0.3810 r:0.8106
et_en Dev loss: 0.4542 r:0.6559
si_en Dev loss: 0.9696 r:0.5393
ne_en Dev loss: 0.6471 r:0.7172
ru_en Dev loss: 0.5054 r:0.7156
Current avg r:0.5534 Best avg r: 0.6061
09:03:47,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:05:04,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:06:35,458 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1424
en_de Dev loss: 0.9522 r:0.1473
en_zh Dev loss: 0.9431 r:0.2991
ro_en Dev loss: 0.3613 r:0.8174
et_en Dev loss: 0.4620 r:0.6668
si_en Dev loss: 0.8654 r:0.5501
ne_en Dev loss: 0.5334 r:0.7225
ru_en Dev loss: 0.4762 r:0.7295
Current avg r:0.5618 Best avg r: 0.6061
09:10:29,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:11:47,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:13:17,834 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1280
en_de Dev loss: 0.9558 r:0.1324
en_zh Dev loss: 1.0131 r:0.2900
ro_en Dev loss: 0.4390 r:0.8040
et_en Dev loss: 0.5116 r:0.6399
si_en Dev loss: 1.0481 r:0.5369
ne_en Dev loss: 0.6919 r:0.7118
ru_en Dev loss: 0.5546 r:0.7022
Current avg r:0.5453 Best avg r: 0.6061
09:17:10,683 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:28,391 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:58,955 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1338
en_de Dev loss: 0.9432 r:0.1529
en_zh Dev loss: 0.9591 r:0.3013
ro_en Dev loss: 0.3924 r:0.8126
et_en Dev loss: 0.4718 r:0.6644
si_en Dev loss: 0.8867 r:0.5562
ne_en Dev loss: 0.6481 r:0.7209
ru_en Dev loss: 0.4878 r:0.7267
Current avg r:0.5621 Best avg r: 0.6061
09:23:51,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:09,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:40,73 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1291
en_de Dev loss: 0.9756 r:0.1492
en_zh Dev loss: 0.9796 r:0.2901
ro_en Dev loss: 0.3750 r:0.8147
et_en Dev loss: 0.4944 r:0.6532
si_en Dev loss: 0.8938 r:0.5467
ne_en Dev loss: 0.5796 r:0.7141
ru_en Dev loss: 0.5057 r:0.7162
Current avg r:0.5549 Best avg r: 0.6061
09:30:32,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:31:50,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:33:21,207 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1304
en_de Dev loss: 0.9806 r:0.1426
en_zh Dev loss: 0.9956 r:0.3058
ro_en Dev loss: 0.3806 r:0.8119
et_en Dev loss: 0.5035 r:0.6542
si_en Dev loss: 0.9085 r:0.5497
ne_en Dev loss: 0.6048 r:0.7099
ru_en Dev loss: 0.5451 r:0.7160
Current avg r:0.5557 Best avg r: 0.6061
09:37:14,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:38:31,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:40:02,272 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1324
en_de Dev loss: 0.9462 r:0.1247
en_zh Dev loss: 0.9190 r:0.2936
ro_en Dev loss: 0.3693 r:0.8118
et_en Dev loss: 0.4993 r:0.6504
si_en Dev loss: 0.9434 r:0.5406
ne_en Dev loss: 0.5392 r:0.7132
ru_en Dev loss: 0.4988 r:0.7097
Current avg r:0.5491 Best avg r: 0.6061
09:43:55,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:45:12,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:46:43,401 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1346
en_de Dev loss: 0.9355 r:0.1482
en_zh Dev loss: 0.9110 r:0.3056
ro_en Dev loss: 0.3571 r:0.8169
et_en Dev loss: 0.4801 r:0.6611
si_en Dev loss: 0.9029 r:0.5512
ne_en Dev loss: 0.5746 r:0.7174
ru_en Dev loss: 0.4779 r:0.7305
Current avg r:0.5616 Best avg r: 0.6061
09:50:36,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:51:53,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:53:24,506 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1229
en_de Dev loss: 0.9623 r:0.1555
en_zh Dev loss: 0.9451 r:0.3017
ro_en Dev loss: 0.3731 r:0.8101
et_en Dev loss: 0.5018 r:0.6549
si_en Dev loss: 0.8574 r:0.5480
ne_en Dev loss: 0.5451 r:0.7121
ru_en Dev loss: 0.5072 r:0.7147
Current avg r:0.5567 Best avg r: 0.6061
09:57:17,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:34,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:05,397 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1347
en_de Dev loss: 0.9598 r:0.1442
en_zh Dev loss: 0.9185 r:0.3034
ro_en Dev loss: 0.3704 r:0.8156
et_en Dev loss: 0.4906 r:0.6626
si_en Dev loss: 0.8548 r:0.5483
ne_en Dev loss: 0.5419 r:0.7110
ru_en Dev loss: 0.4968 r:0.7224
Current avg r:0.5582 Best avg r: 0.6061
10:03:57,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:15,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:45,984 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1273
en_de Dev loss: 0.9880 r:0.1454
en_zh Dev loss: 0.9977 r:0.3042
ro_en Dev loss: 0.4439 r:0.8077
et_en Dev loss: 0.5064 r:0.6459
si_en Dev loss: 1.0756 r:0.5364
ne_en Dev loss: 0.6970 r:0.7126
ru_en Dev loss: 0.5966 r:0.7014
Current avg r:0.5505 Best avg r: 0.6061
10:10:38,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:56,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:13:26,729 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1285
en_de Dev loss: 0.9619 r:0.1425
en_zh Dev loss: 0.9695 r:0.3111
ro_en Dev loss: 0.3985 r:0.8131
et_en Dev loss: 0.4873 r:0.6596
si_en Dev loss: 1.0071 r:0.5432
ne_en Dev loss: 0.6413 r:0.7221
ru_en Dev loss: 0.5229 r:0.7224
Current avg r:0.5591 Best avg r: 0.6061
10:17:19,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:36,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:07,401 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1235
en_de Dev loss: 0.9854 r:0.1323
en_zh Dev loss: 0.9648 r:0.3115
ro_en Dev loss: 0.3917 r:0.8133
et_en Dev loss: 0.4926 r:0.6576
si_en Dev loss: 0.9575 r:0.5440
ne_en Dev loss: 0.5796 r:0.7245
ru_en Dev loss: 0.4791 r:0.7303
Current avg r:0.5591 Best avg r: 0.6061
10:24:00,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:18,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:48,646 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1317
en_de Dev loss: 0.9461 r:0.1166
en_zh Dev loss: 0.9319 r:0.3083
ro_en Dev loss: 0.3744 r:0.8132
et_en Dev loss: 0.4531 r:0.6640
si_en Dev loss: 0.9171 r:0.5467
ne_en Dev loss: 0.6188 r:0.7237
ru_en Dev loss: 0.4851 r:0.7177
Current avg r:0.5557 Best avg r: 0.6061
10:30:41,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:31:59,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:33:29,859 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1281
en_de Dev loss: 0.9635 r:0.1265
en_zh Dev loss: 0.9414 r:0.3057
ro_en Dev loss: 0.3606 r:0.8178
et_en Dev loss: 0.4594 r:0.6621
si_en Dev loss: 0.9002 r:0.5490
ne_en Dev loss: 0.6254 r:0.7155
ru_en Dev loss: 0.4600 r:0.7331
Current avg r:0.5585 Best avg r: 0.6061
10:37:22,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
