14:35:32,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:35:45,753 root INFO 
id:en_de cur r: 0.0632 best r: 0.0632
14:35:58,657 root INFO 
id:ro_en cur r: 0.5791 best r: 0.5791
14:36:11,546 root INFO 
id:et_en cur r: 0.0925 best r: 0.0925
14:36:24,436 root INFO 
id:si_en cur r: 0.3844 best r: 0.3844
14:36:37,332 root INFO 
id:ne_en cur r: 0.5360 best r: 0.5360
14:36:50,173 root INFO 
id:ru_en cur r: 0.4179 best r: 0.4179
14:36:50,174 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:38:20,221 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
14:38:20,228 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:38:20,233 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:38:20,239 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
14:38:20,245 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
14:38:20,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:38:20,257 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:38:33,120 root INFO Epoch 0 Global steps: 600 Train loss: 0.8795
en_de Dev loss: 0.8938 r:0.0737
en_zh Dev loss: 0.7920 r:0.2179
ro_en Dev loss: 0.7076 r:0.5954
et_en Dev loss: 0.5950 r:0.4661
si_en Dev loss: 0.7682 r:0.4029
ne_en Dev loss: 0.6188 r:0.5666
ru_en Dev loss: 0.6950 r:0.4256
Current avg r:0.3926 Best avg r: 0.3926
14:42:23,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:36,791 root INFO 
id:en_de cur r: 0.0981 best r: 0.0981
14:42:49,686 root INFO 
id:ro_en cur r: 0.6394 best r: 0.6394
14:43:02,578 root INFO 
id:et_en cur r: 0.4508 best r: 0.4508
14:43:15,489 root INFO 
id:si_en cur r: 0.4542 best r: 0.4542
14:43:28,381 root INFO 
id:ne_en cur r: 0.6036 best r: 0.6036
14:43:41,217 root INFO 
id:ru_en cur r: 0.5412 best r: 0.5412
14:43:41,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:11,306 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
14:45:11,312 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:45:11,317 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:45:11,323 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
14:45:11,327 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
14:45:11,334 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:45:11,339 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:45:24,189 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8714
en_de Dev loss: 0.8837 r:0.0946
en_zh Dev loss: 0.7713 r:0.2894
ro_en Dev loss: 0.6466 r:0.6833
et_en Dev loss: 0.5753 r:0.5927
si_en Dev loss: 0.6997 r:0.5123
ne_en Dev loss: 0.5720 r:0.6623
ru_en Dev loss: 0.6260 r:0.5992
Current avg r:0.4905 Best avg r: 0.4905
14:49:15,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:28,160 root INFO 
id:en_de cur r: 0.0983 best r: 0.0983
14:49:53,930 root INFO 
id:et_en cur r: 0.5970 best r: 0.5970
14:50:32,557 root INFO 
id:ru_en cur r: 0.6649 best r: 0.6649
14:50:32,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:02,626 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
14:52:02,633 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:52:02,638 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:52:02,643 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
14:52:02,647 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
14:52:02,652 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:52:02,657 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:52:15,503 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7550
en_de Dev loss: 1.0105 r:0.1016
en_zh Dev loss: 0.7928 r:0.2975
ro_en Dev loss: 0.7264 r:0.6417
et_en Dev loss: 0.4830 r:0.6403
si_en Dev loss: 0.7871 r:0.5063
ne_en Dev loss: 0.5124 r:0.6557
ru_en Dev loss: 0.6126 r:0.6869
Current avg r:0.5043 Best avg r: 0.5043
14:56:06,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:18,978 root INFO 
id:en_de cur r: 0.1238 best r: 0.1238
14:56:31,861 root INFO 
id:ro_en cur r: 0.6655 best r: 0.6655
14:56:44,749 root INFO 
id:et_en cur r: 0.6133 best r: 0.6133
14:56:57,643 root INFO 
id:si_en cur r: 0.4863 best r: 0.4863
14:57:10,534 root INFO 
id:ne_en cur r: 0.6261 best r: 0.6261
14:57:23,385 root INFO 
id:ru_en cur r: 0.6827 best r: 0.6827
14:57:23,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:53,534 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
14:58:53,541 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:58:53,545 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:58:53,550 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
14:58:53,555 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
14:58:53,560 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:58:53,564 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:59:06,423 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6751
en_de Dev loss: 0.9894 r:0.1289
en_zh Dev loss: 0.7779 r:0.3123
ro_en Dev loss: 0.6205 r:0.6917
et_en Dev loss: 0.4655 r:0.6451
si_en Dev loss: 0.8016 r:0.5107
ne_en Dev loss: 0.5043 r:0.6498
ru_en Dev loss: 0.5697 r:0.6970
Current avg r:0.5193 Best avg r: 0.5193
15:02:57,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:22,828 root INFO 
id:ro_en cur r: 0.7176 best r: 0.7176
15:03:35,733 root INFO 
id:et_en cur r: 0.6518 best r: 0.6518
15:03:48,644 root INFO 
id:si_en cur r: 0.5205 best r: 0.5205
15:04:01,551 root INFO 
id:ne_en cur r: 0.6553 best r: 0.6553
15:04:14,395 root INFO 
id:ru_en cur r: 0.7033 best r: 0.7033
15:04:14,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:44,463 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
15:05:44,470 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:05:44,474 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:05:44,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
15:05:44,486 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
15:05:44,491 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:05:44,495 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:05:57,355 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6323
en_de Dev loss: 1.0271 r:0.1369
en_zh Dev loss: 0.8093 r:0.3437
ro_en Dev loss: 0.6030 r:0.7252
et_en Dev loss: 0.4599 r:0.6789
si_en Dev loss: 0.8793 r:0.5321
ne_en Dev loss: 0.6055 r:0.6643
ru_en Dev loss: 0.5721 r:0.7149
Current avg r:0.5423 Best avg r: 0.5423
15:09:48,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:14,174 root INFO 
id:ro_en cur r: 0.7287 best r: 0.7287
15:10:27,79 root INFO 
id:et_en cur r: 0.6811 best r: 0.6811
15:10:39,996 root INFO 
id:si_en cur r: 0.5394 best r: 0.5394
15:10:52,909 root INFO 
id:ne_en cur r: 0.7119 best r: 0.7119
15:11:05,741 root INFO 
id:ru_en cur r: 0.7152 best r: 0.7152
15:11:05,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:35,857 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
15:12:35,865 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:12:35,870 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:12:35,880 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
15:12:35,884 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
15:12:35,890 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:12:35,895 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:12:48,742 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6262
en_de Dev loss: 0.9403 r:0.1313
en_zh Dev loss: 0.7276 r:0.3523
ro_en Dev loss: 0.4218 r:0.7448
et_en Dev loss: 0.3645 r:0.7012
si_en Dev loss: 0.6597 r:0.5527
ne_en Dev loss: 0.3997 r:0.7099
ru_en Dev loss: 0.4413 r:0.7254
Current avg r:0.5597 Best avg r: 0.5597
15:16:39,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:52,460 root INFO 
id:en_de cur r: 0.1272 best r: 0.1272
15:17:05,365 root INFO 
id:ro_en cur r: 0.7359 best r: 0.7359
15:17:18,276 root INFO 
id:et_en cur r: 0.6976 best r: 0.6976
15:17:31,175 root INFO 
id:si_en cur r: 0.5466 best r: 0.5466
15:17:44,84 root INFO 
id:ne_en cur r: 0.7164 best r: 0.7164
15:17:56,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:27,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
15:19:27,44 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:19:27,49 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:19:27,54 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
15:19:27,59 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
15:19:27,64 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:19:27,69 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:19:39,929 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5554
en_de Dev loss: 0.9490 r:0.1332
en_zh Dev loss: 0.7424 r:0.3538
ro_en Dev loss: 0.4312 r:0.7500
et_en Dev loss: 0.3589 r:0.7126
si_en Dev loss: 0.6444 r:0.5572
ne_en Dev loss: 0.4086 r:0.7119
ru_en Dev loss: 0.4576 r:0.7216
Current avg r:0.5629 Best avg r: 0.5629
15:23:30,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:43,712 root INFO 
id:en_de cur r: 0.1434 best r: 0.1434
15:23:56,605 root INFO 
id:ro_en cur r: 0.7436 best r: 0.7436
15:24:22,387 root INFO 
id:si_en cur r: 0.5512 best r: 0.5512
15:24:48,122 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:18,247 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
15:26:18,253 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:26:18,258 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:26:18,263 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
15:26:18,268 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
15:26:18,273 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:26:18,278 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:26:31,137 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5841
en_de Dev loss: 0.9301 r:0.1451
en_zh Dev loss: 0.7547 r:0.3553
ro_en Dev loss: 0.4187 r:0.7563
et_en Dev loss: 0.3649 r:0.7102
si_en Dev loss: 0.6635 r:0.5627
ne_en Dev loss: 0.4622 r:0.7057
ru_en Dev loss: 0.4821 r:0.7198
Current avg r:0.5650 Best avg r: 0.5650
15:30:21,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:34,700 root INFO 
id:en_de cur r: 0.1693 best r: 0.1693
15:30:47,580 root INFO 
id:ro_en cur r: 0.7488 best r: 0.7488
15:31:13,384 root INFO 
id:si_en cur r: 0.5599 best r: 0.5599
15:31:26,274 root INFO 
id:ne_en cur r: 0.7226 best r: 0.7226
15:31:39,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:09,244 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
15:33:09,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:33:09,255 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:33:09,260 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
15:33:09,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
15:33:09,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:33:09,273 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:33:22,127 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5614
en_de Dev loss: 0.9342 r:0.1601
en_zh Dev loss: 0.7692 r:0.3487
ro_en Dev loss: 0.4070 r:0.7668
et_en Dev loss: 0.3607 r:0.7126
si_en Dev loss: 0.6624 r:0.5725
ne_en Dev loss: 0.4510 r:0.7109
ru_en Dev loss: 0.5051 r:0.7034
Current avg r:0.5679 Best avg r: 0.5679
15:37:13,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:26,96 root INFO 
id:en_de cur r: 0.1695 best r: 0.1695
15:37:38,980 root INFO 
id:ro_en cur r: 0.7773 best r: 0.7773
15:37:51,875 root INFO 
id:et_en cur r: 0.7135 best r: 0.7135
15:38:04,781 root INFO 
id:si_en cur r: 0.5866 best r: 0.5866
15:38:17,677 root INFO 
id:ne_en cur r: 0.7397 best r: 0.7397
15:38:30,513 root INFO 
id:ru_en cur r: 0.7449 best r: 0.7449
15:38:30,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:00,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
15:40:00,618 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:40:00,623 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:40:00,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
15:40:00,634 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
15:40:00,639 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:40:00,644 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:40:13,492 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5541
en_de Dev loss: 0.9300 r:0.1676
en_zh Dev loss: 0.7441 r:0.3623
ro_en Dev loss: 0.3686 r:0.7849
et_en Dev loss: 0.3410 r:0.7224
si_en Dev loss: 0.6292 r:0.5927
ne_en Dev loss: 0.3995 r:0.7327
ru_en Dev loss: 0.4008 r:0.7500
Current avg r:0.5875 Best avg r: 0.5875
15:44:04,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:17,317 root INFO 
id:en_de cur r: 0.1944 best r: 0.1944
15:45:21,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:51,804 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5318
en_de Dev loss: 0.9258 r:0.1685
en_zh Dev loss: 0.7962 r:0.3424
ro_en Dev loss: 0.3932 r:0.7886
et_en Dev loss: 0.3914 r:0.6988
si_en Dev loss: 0.7706 r:0.5633
ne_en Dev loss: 0.5778 r:0.7051
ru_en Dev loss: 0.4891 r:0.7075
Current avg r:0.5678 Best avg r: 0.5875
15:50:42,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:08,292 root INFO 
id:ro_en cur r: 0.7982 best r: 0.7982
15:51:34,104 root INFO 
id:si_en cur r: 0.5936 best r: 0.5936
15:51:46,998 root INFO 
id:ne_en cur r: 0.7468 best r: 0.7468
15:51:59,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:29,900 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5671
en_de Dev loss: 0.8773 r:0.1768
en_zh Dev loss: 0.7342 r:0.3614
ro_en Dev loss: 0.3186 r:0.8025
et_en Dev loss: 0.3632 r:0.7103
si_en Dev loss: 0.6597 r:0.5981
ne_en Dev loss: 0.4353 r:0.7369
ru_en Dev loss: 0.4616 r:0.7170
Current avg r:0.5861 Best avg r: 0.5875
15:57:20,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:46,305 root INFO 
id:ro_en cur r: 0.8029 best r: 0.8029
15:57:59,200 root INFO 
id:et_en cur r: 0.7162 best r: 0.7162
15:58:25,7 root INFO 
id:ne_en cur r: 0.7553 best r: 0.7553
15:58:37,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:07,948 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
16:00:07,955 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:00:07,960 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:00:07,964 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
16:00:07,969 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
16:00:07,974 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:00:07,978 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:00:20,825 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5426
en_de Dev loss: 0.8795 r:0.1743
en_zh Dev loss: 0.7300 r:0.3615
ro_en Dev loss: 0.3208 r:0.8068
et_en Dev loss: 0.3452 r:0.7185
si_en Dev loss: 0.5906 r:0.6030
ne_en Dev loss: 0.3960 r:0.7464
ru_en Dev loss: 0.4180 r:0.7394
Current avg r:0.5928 Best avg r: 0.5928
16:04:11,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:37,361 root INFO 
id:ro_en cur r: 0.8038 best r: 0.8038
16:04:50,252 root INFO 
id:et_en cur r: 0.7207 best r: 0.7207
16:05:28,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:58,882 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5423
en_de Dev loss: 0.8848 r:0.1777
en_zh Dev loss: 0.7586 r:0.3695
ro_en Dev loss: 0.3822 r:0.8081
et_en Dev loss: 0.3685 r:0.7201
si_en Dev loss: 0.8304 r:0.5880
ne_en Dev loss: 0.4977 r:0.7394
ru_en Dev loss: 0.4677 r:0.7411
Current avg r:0.5920 Best avg r: 0.5928
16:10:49,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:15,750 root INFO 
id:ro_en cur r: 0.8077 best r: 0.8077
16:11:28,647 root INFO 
id:et_en cur r: 0.7229 best r: 0.7229
16:11:41,554 root INFO 
id:si_en cur r: 0.6009 best r: 0.6009
16:12:07,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:37,467 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
16:13:37,474 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:13:37,479 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:13:37,484 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
16:13:37,489 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
16:13:37,493 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:13:37,498 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:13:50,381 root INFO Epoch 0 Global steps: 9000 Train loss: 0.4864
en_de Dev loss: 0.8900 r:0.1863
en_zh Dev loss: 0.7485 r:0.3813
ro_en Dev loss: 0.3359 r:0.8096
et_en Dev loss: 0.3423 r:0.7225
si_en Dev loss: 0.6491 r:0.6038
ne_en Dev loss: 0.4125 r:0.7431
ru_en Dev loss: 0.4257 r:0.7470
Current avg r:0.5991 Best avg r: 0.5991
16:17:42,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:08,624 root INFO 
id:ro_en cur r: 0.8103 best r: 0.8103
16:18:21,518 root INFO 
id:et_en cur r: 0.7269 best r: 0.7269
16:19:00,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:30,177 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5297
en_de Dev loss: 0.8978 r:0.1889
en_zh Dev loss: 0.7817 r:0.3704
ro_en Dev loss: 0.3724 r:0.8070
et_en Dev loss: 0.3551 r:0.7275
si_en Dev loss: 0.7308 r:0.6042
ne_en Dev loss: 0.5105 r:0.7472
ru_en Dev loss: 0.4382 r:0.7443
Current avg r:0.5985 Best avg r: 0.5991
16:24:21,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:46,785 root INFO 
id:ro_en cur r: 0.8115 best r: 0.8115
16:25:38,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:08,332 root INFO Epoch 1 Global steps: 10200 Train loss: 0.4679
en_de Dev loss: 0.8920 r:0.1749
en_zh Dev loss: 0.7956 r:0.3604
ro_en Dev loss: 0.3615 r:0.8086
et_en Dev loss: 0.3579 r:0.7185
si_en Dev loss: 0.7606 r:0.5973
ne_en Dev loss: 0.5108 r:0.7403
ru_en Dev loss: 0.4709 r:0.7311
Current avg r:0.5901 Best avg r: 0.5991
16:30:59,522 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:12,421 root INFO 
id:en_de cur r: 0.2008 best r: 0.2008
16:32:16,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:46,945 root INFO Epoch 1 Global steps: 10800 Train loss: 0.4843
en_de Dev loss: 0.8687 r:0.1774
en_zh Dev loss: 0.7809 r:0.3324
ro_en Dev loss: 0.3217 r:0.8035
et_en Dev loss: 0.3552 r:0.7078
si_en Dev loss: 0.6231 r:0.5907
ne_en Dev loss: 0.4460 r:0.7313
ru_en Dev loss: 0.4736 r:0.6996
Current avg r:0.5775 Best avg r: 0.5991
16:37:37,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:55,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:25,296 root INFO Epoch 1 Global steps: 11400 Train loss: 0.5082
en_de Dev loss: 0.9096 r:0.1644
en_zh Dev loss: 0.8332 r:0.3394
ro_en Dev loss: 0.3939 r:0.8027
et_en Dev loss: 0.3755 r:0.7084
si_en Dev loss: 0.7778 r:0.5923
ne_en Dev loss: 0.5185 r:0.7447
ru_en Dev loss: 0.5374 r:0.7153
Current avg r:0.5810 Best avg r: 0.5991
16:44:16,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:28,986 root INFO 
id:en_de cur r: 0.2025 best r: 0.2025
16:44:41,869 root INFO 
id:ro_en cur r: 0.8146 best r: 0.8146
16:45:07,675 root INFO 
id:si_en cur r: 0.6054 best r: 0.6054
16:45:20,591 root INFO 
id:ne_en cur r: 0.7584 best r: 0.7584
16:45:33,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:03,566 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4969
en_de Dev loss: 0.8763 r:0.1777
en_zh Dev loss: 0.7508 r:0.3610
ro_en Dev loss: 0.3241 r:0.8066
et_en Dev loss: 0.3482 r:0.7168
si_en Dev loss: 0.5800 r:0.6062
ne_en Dev loss: 0.3480 r:0.7559
ru_en Dev loss: 0.4304 r:0.7356
Current avg r:0.5942 Best avg r: 0.5991
16:50:54,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:07,647 root INFO 
id:en_de cur r: 0.2164 best r: 0.2164
16:52:12,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:42,154 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4739
en_de Dev loss: 0.8552 r:0.1987
en_zh Dev loss: 0.7429 r:0.3518
ro_en Dev loss: 0.3141 r:0.8072
et_en Dev loss: 0.3512 r:0.7116
si_en Dev loss: 0.6818 r:0.5847
ne_en Dev loss: 0.4919 r:0.7369
ru_en Dev loss: 0.4153 r:0.7337
Current avg r:0.5892 Best avg r: 0.5991
16:57:33,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:37,549 root INFO 
id:ne_en cur r: 0.7591 best r: 0.7591
16:58:50,380 root INFO 
id:ru_en cur r: 0.7539 best r: 0.7539
16:58:50,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:20,500 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4888
en_de Dev loss: 0.8898 r:0.1712
en_zh Dev loss: 0.8092 r:0.3478
ro_en Dev loss: 0.3543 r:0.8080
et_en Dev loss: 0.3690 r:0.7085
si_en Dev loss: 0.7772 r:0.5863
ne_en Dev loss: 0.5454 r:0.7515
ru_en Dev loss: 0.4258 r:0.7410
Current avg r:0.5878 Best avg r: 0.5991
17:04:11,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:37,477 root INFO 
id:ro_en cur r: 0.8175 best r: 0.8175
17:05:03,262 root INFO 
id:si_en cur r: 0.6065 best r: 0.6065
17:05:16,169 root INFO 
id:ne_en cur r: 0.7674 best r: 0.7674
17:05:29,9 root INFO 
id:ru_en cur r: 0.7586 best r: 0.7586
17:05:29,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:59,73 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
17:06:59,80 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:06:59,86 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:06:59,90 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
17:06:59,95 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
17:06:59,100 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:06:59,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:07:11,962 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4506
en_de Dev loss: 0.8797 r:0.1865
en_zh Dev loss: 0.7849 r:0.3485
ro_en Dev loss: 0.3110 r:0.8117
et_en Dev loss: 0.3434 r:0.7185
si_en Dev loss: 0.6633 r:0.6068
ne_en Dev loss: 0.4100 r:0.7623
ru_en Dev loss: 0.3781 r:0.7613
Current avg r:0.5994 Best avg r: 0.5994
17:11:02,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:28,557 root INFO 
id:ro_en cur r: 0.8219 best r: 0.8219
17:12:07,250 root INFO 
id:ne_en cur r: 0.7701 best r: 0.7701
17:12:20,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:50,231 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
17:13:50,239 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:13:50,246 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:13:50,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
17:13:50,256 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
17:13:50,261 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:13:50,313 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:14:03,172 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4983
en_de Dev loss: 0.8788 r:0.1902
en_zh Dev loss: 0.7804 r:0.3684
ro_en Dev loss: 0.3263 r:0.8146
et_en Dev loss: 0.3428 r:0.7227
si_en Dev loss: 0.6351 r:0.6052
ne_en Dev loss: 0.4139 r:0.7657
ru_en Dev loss: 0.3828 r:0.7566
Current avg r:0.6033 Best avg r: 0.6033
17:17:54,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:20,184 root INFO 
id:ro_en cur r: 0.8229 best r: 0.8229
17:18:33,85 root INFO 
id:et_en cur r: 0.7298 best r: 0.7298
17:18:45,994 root INFO 
id:si_en cur r: 0.6143 best r: 0.6143
17:18:58,897 root INFO 
id:ne_en cur r: 0.7702 best r: 0.7702
17:19:11,748 root INFO 
id:ru_en cur r: 0.7764 best r: 0.7764
17:19:11,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:41,821 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
17:20:41,830 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:20:41,837 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:20:41,844 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
17:20:41,850 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
17:20:41,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:20:41,866 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:20:54,723 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4371
en_de Dev loss: 0.8727 r:0.1657
en_zh Dev loss: 0.7294 r:0.3715
ro_en Dev loss: 0.2920 r:0.8190
et_en Dev loss: 0.3384 r:0.7313
si_en Dev loss: 0.5679 r:0.6121
ne_en Dev loss: 0.3824 r:0.7676
ru_en Dev loss: 0.3419 r:0.7692
Current avg r:0.6052 Best avg r: 0.6052
17:24:45,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:02,790 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:32,850 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4613
en_de Dev loss: 0.8862 r:0.1694
en_zh Dev loss: 0.8001 r:0.3689
ro_en Dev loss: 0.3753 r:0.8099
et_en Dev loss: 0.3863 r:0.7064
si_en Dev loss: 0.7732 r:0.5915
ne_en Dev loss: 0.5614 r:0.7542
ru_en Dev loss: 0.4852 r:0.7230
Current avg r:0.5890 Best avg r: 0.6052
17:31:23,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:40,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:10,926 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4911
en_de Dev loss: 0.8849 r:0.1500
en_zh Dev loss: 0.7790 r:0.3656
ro_en Dev loss: 0.3727 r:0.8175
et_en Dev loss: 0.3687 r:0.7157
si_en Dev loss: 0.7301 r:0.6122
ne_en Dev loss: 0.4440 r:0.7623
ru_en Dev loss: 0.4796 r:0.7288
Current avg r:0.5932 Best avg r: 0.6052
17:38:01,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:53,244 root INFO 
id:si_en cur r: 0.6181 best r: 0.6181
17:39:18,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:49,26 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4236
en_de Dev loss: 0.8746 r:0.1652
en_zh Dev loss: 0.7425 r:0.3618
ro_en Dev loss: 0.3094 r:0.8188
et_en Dev loss: 0.3448 r:0.7219
si_en Dev loss: 0.5943 r:0.6193
ne_en Dev loss: 0.3919 r:0.7616
ru_en Dev loss: 0.4052 r:0.7500
Current avg r:0.5998 Best avg r: 0.6052
17:44:39,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:57,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:27,108 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4660
en_de Dev loss: 0.8852 r:0.1764
en_zh Dev loss: 0.8013 r:0.3615
ro_en Dev loss: 0.3231 r:0.8166
et_en Dev loss: 0.3513 r:0.7203
si_en Dev loss: 0.7060 r:0.6078
ne_en Dev loss: 0.4583 r:0.7611
ru_en Dev loss: 0.4233 r:0.7551
Current avg r:0.5998 Best avg r: 0.6052
17:51:17,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:35,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:05,59 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4626
en_de Dev loss: 0.8899 r:0.1684
en_zh Dev loss: 0.8034 r:0.3544
ro_en Dev loss: 0.3323 r:0.8120
et_en Dev loss: 0.3639 r:0.7127
si_en Dev loss: 0.6804 r:0.6024
ne_en Dev loss: 0.4170 r:0.7647
ru_en Dev loss: 0.4920 r:0.7143
Current avg r:0.5899 Best avg r: 0.6052
17:57:57,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:14,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:44,855 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4432
en_de Dev loss: 0.8694 r:0.1765
en_zh Dev loss: 0.8141 r:0.3671
ro_en Dev loss: 0.3548 r:0.8040
et_en Dev loss: 0.3824 r:0.6989
si_en Dev loss: 0.8165 r:0.5816
ne_en Dev loss: 0.6384 r:0.7618
ru_en Dev loss: 0.4935 r:0.7079
Current avg r:0.5854 Best avg r: 0.6052
18:04:35,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:53,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:23,267 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4074
en_de Dev loss: 0.8680 r:0.1776
en_zh Dev loss: 0.8106 r:0.3381
ro_en Dev loss: 0.3232 r:0.8116
et_en Dev loss: 0.3664 r:0.7080
si_en Dev loss: 0.6485 r:0.5998
ne_en Dev loss: 0.4534 r:0.7657
ru_en Dev loss: 0.4597 r:0.7200
Current avg r:0.5887 Best avg r: 0.6052
18:11:14,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:39,808 root INFO 
id:ro_en cur r: 0.8245 best r: 0.8245
18:12:05,613 root INFO 
id:si_en cur r: 0.6213 best r: 0.6213
18:12:31,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:01,476 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
18:14:01,484 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:14:01,490 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:14:01,495 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
18:14:01,499 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
18:14:01,504 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:14:01,509 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:14:14,359 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4308
en_de Dev loss: 0.8584 r:0.1930
en_zh Dev loss: 0.7462 r:0.3688
ro_en Dev loss: 0.3204 r:0.8192
et_en Dev loss: 0.3705 r:0.7231
si_en Dev loss: 0.5732 r:0.6240
ne_en Dev loss: 0.3352 r:0.7645
ru_en Dev loss: 0.3797 r:0.7584
Current avg r:0.6073 Best avg r: 0.6073
18:18:05,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:09,707 root INFO 
id:ne_en cur r: 0.7712 best r: 0.7712
18:19:22,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:52,621 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4108
en_de Dev loss: 0.8818 r:0.1730
en_zh Dev loss: 0.7992 r:0.3586
ro_en Dev loss: 0.3265 r:0.8147
et_en Dev loss: 0.3537 r:0.7164
si_en Dev loss: 0.7148 r:0.6076
ne_en Dev loss: 0.4439 r:0.7684
ru_en Dev loss: 0.4139 r:0.7483
Current avg r:0.5981 Best avg r: 0.6073
18:24:43,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:24:56,235 root INFO 
id:en_de cur r: 0.2251 best r: 0.2251
18:26:00,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:30,779 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4353
en_de Dev loss: 0.8666 r:0.1955
en_zh Dev loss: 0.7934 r:0.3577
ro_en Dev loss: 0.3418 r:0.8122
et_en Dev loss: 0.3679 r:0.7113
si_en Dev loss: 0.6567 r:0.6060
ne_en Dev loss: 0.4358 r:0.7616
ru_en Dev loss: 0.4107 r:0.7542
Current avg r:0.5998 Best avg r: 0.6073
18:31:21,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:34,830 root INFO 
id:en_de cur r: 0.2273 best r: 0.2273
18:32:39,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:09,215 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4207
en_de Dev loss: 0.8686 r:0.1912
en_zh Dev loss: 0.8225 r:0.3498
ro_en Dev loss: 0.3218 r:0.8144
et_en Dev loss: 0.3539 r:0.7173
si_en Dev loss: 0.7399 r:0.6049
ne_en Dev loss: 0.4009 r:0.7644
ru_en Dev loss: 0.4431 r:0.7424
Current avg r:0.5978 Best avg r: 0.6073
18:37:59,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:17,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:47,124 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4092
en_de Dev loss: 0.8612 r:0.2021
en_zh Dev loss: 0.7837 r:0.3632
ro_en Dev loss: 0.3260 r:0.8097
et_en Dev loss: 0.3628 r:0.7141
si_en Dev loss: 0.6429 r:0.6097
ne_en Dev loss: 0.3935 r:0.7592
ru_en Dev loss: 0.3973 r:0.7538
Current avg r:0.6017 Best avg r: 0.6073
18:44:37,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:03,771 root INFO 
id:ro_en cur r: 0.8254 best r: 0.8254
18:45:42,463 root INFO 
id:ne_en cur r: 0.7728 best r: 0.7728
18:45:55,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:25,348 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4190
en_de Dev loss: 0.8807 r:0.1877
en_zh Dev loss: 0.8111 r:0.3556
ro_en Dev loss: 0.3258 r:0.8169
et_en Dev loss: 0.3543 r:0.7165
si_en Dev loss: 0.6974 r:0.6086
ne_en Dev loss: 0.3880 r:0.7675
ru_en Dev loss: 0.4439 r:0.7412
Current avg r:0.5992 Best avg r: 0.6073
18:51:15,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:20,412 root INFO 
id:ne_en cur r: 0.7733 best r: 0.7733
18:52:33,236 root INFO 
id:ru_en cur r: 0.7841 best r: 0.7841
18:52:33,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:03,263 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_de.lang_agnost_mlp.dev.best.scores
18:54:03,270 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:54:03,275 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:54:03,280 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/et_en.lang_agnost_mlp.dev.best.scores
18:54:03,285 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/si_en.lang_agnost_mlp.dev.best.scores
18:54:03,290 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:54:03,295 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:54:16,140 root INFO Epoch 2 Global steps: 23400 Train loss: 0.3796
en_de Dev loss: 0.8603 r:0.1919
en_zh Dev loss: 0.7589 r:0.3612
ro_en Dev loss: 0.3067 r:0.8192
et_en Dev loss: 0.3617 r:0.7211
si_en Dev loss: 0.6218 r:0.6196
ne_en Dev loss: 0.3616 r:0.7697
ru_en Dev loss: 0.3426 r:0.7783
Current avg r:0.6087 Best avg r: 0.6087
18:58:07,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:24,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:54,612 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4004
en_de Dev loss: 0.8706 r:0.1899
en_zh Dev loss: 0.8108 r:0.3494
ro_en Dev loss: 0.3306 r:0.8160
et_en Dev loss: 0.3845 r:0.7126
si_en Dev loss: 0.6807 r:0.6129
ne_en Dev loss: 0.3855 r:0.7645
ru_en Dev loss: 0.4349 r:0.7383
Current avg r:0.5977 Best avg r: 0.6087
19:04:45,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:02,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:32,930 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4001
en_de Dev loss: 0.8703 r:0.1887
en_zh Dev loss: 0.8236 r:0.3469
ro_en Dev loss: 0.3260 r:0.8204
et_en Dev loss: 0.3595 r:0.7150
si_en Dev loss: 0.8177 r:0.5998
ne_en Dev loss: 0.5270 r:0.7636
ru_en Dev loss: 0.4427 r:0.7455
Current avg r:0.5971 Best avg r: 0.6087
19:11:23,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:40,852 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:10,881 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4253
en_de Dev loss: 0.8937 r:0.1646
en_zh Dev loss: 0.8246 r:0.3516
ro_en Dev loss: 0.3388 r:0.8149
et_en Dev loss: 0.3980 r:0.7057
si_en Dev loss: 0.6748 r:0.6008
ne_en Dev loss: 0.4230 r:0.7590
ru_en Dev loss: 0.4381 r:0.7370
Current avg r:0.5905 Best avg r: 0.6087
19:18:01,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:18,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:48,990 root INFO Epoch 2 Global steps: 25800 Train loss: 0.3827
en_de Dev loss: 0.8715 r:0.1693
en_zh Dev loss: 0.7772 r:0.3444
ro_en Dev loss: 0.3034 r:0.8203
et_en Dev loss: 0.3801 r:0.7131
si_en Dev loss: 0.6806 r:0.5989
ne_en Dev loss: 0.4097 r:0.7628
ru_en Dev loss: 0.4050 r:0.7403
Current avg r:0.5927 Best avg r: 0.6087
19:24:40,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:06,183 root INFO 
id:ro_en cur r: 0.8315 best r: 0.8315
19:25:58,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:28,981 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4305
en_de Dev loss: 0.8935 r:0.1553
en_zh Dev loss: 0.7672 r:0.3550
ro_en Dev loss: 0.3000 r:0.8270
et_en Dev loss: 0.3998 r:0.7123
si_en Dev loss: 0.6065 r:0.6090
ne_en Dev loss: 0.3437 r:0.7642
ru_en Dev loss: 0.4250 r:0.7264
Current avg r:0.5927 Best avg r: 0.6087
19:31:21,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:38,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:08,826 root INFO Epoch 2 Global steps: 27000 Train loss: 0.3747
en_de Dev loss: 0.8700 r:0.1709
en_zh Dev loss: 0.8368 r:0.3329
ro_en Dev loss: 0.3176 r:0.8222
et_en Dev loss: 0.3621 r:0.7086
si_en Dev loss: 0.7125 r:0.5951
ne_en Dev loss: 0.4347 r:0.7637
ru_en Dev loss: 0.4831 r:0.7047
Current avg r:0.5854 Best avg r: 0.6087
19:38:02,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:20,171 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:50,336 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3631
en_de Dev loss: 0.8692 r:0.1827
en_zh Dev loss: 0.8394 r:0.3254
ro_en Dev loss: 0.3286 r:0.8189
et_en Dev loss: 0.3922 r:0.6992
si_en Dev loss: 0.7094 r:0.5867
ne_en Dev loss: 0.4611 r:0.7551
ru_en Dev loss: 0.4492 r:0.7193
Current avg r:0.5839 Best avg r: 0.6087
19:44:41,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:58,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:29,135 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3443
en_de Dev loss: 0.8698 r:0.1806
en_zh Dev loss: 0.8281 r:0.3322
ro_en Dev loss: 0.3077 r:0.8274
et_en Dev loss: 0.3943 r:0.7063
si_en Dev loss: 0.7096 r:0.6000
ne_en Dev loss: 0.4124 r:0.7583
ru_en Dev loss: 0.4289 r:0.7392
Current avg r:0.5920 Best avg r: 0.6087
19:51:20,558 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:37,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:07,979 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3608
en_de Dev loss: 0.9099 r:0.1658
en_zh Dev loss: 0.8524 r:0.3344
ro_en Dev loss: 0.3219 r:0.8219
et_en Dev loss: 0.3969 r:0.6980
si_en Dev loss: 0.7299 r:0.5911
ne_en Dev loss: 0.4241 r:0.7602
ru_en Dev loss: 0.4350 r:0.7330
Current avg r:0.5863 Best avg r: 0.6087
19:57:59,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:16,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:46,725 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3938
en_de Dev loss: 0.8916 r:0.1639
en_zh Dev loss: 0.8049 r:0.3321
ro_en Dev loss: 0.3269 r:0.8172
et_en Dev loss: 0.4181 r:0.6995
si_en Dev loss: 0.6883 r:0.5963
ne_en Dev loss: 0.3801 r:0.7648
ru_en Dev loss: 0.4061 r:0.7427
Current avg r:0.5881 Best avg r: 0.6087
20:04:37,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:55,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:25,447 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3770
en_de Dev loss: 0.8769 r:0.1709
en_zh Dev loss: 0.8525 r:0.3004
ro_en Dev loss: 0.3262 r:0.8185
et_en Dev loss: 0.3972 r:0.6964
si_en Dev loss: 0.7418 r:0.5903
ne_en Dev loss: 0.3954 r:0.7583
ru_en Dev loss: 0.4284 r:0.7293
Current avg r:0.5806 Best avg r: 0.6087
20:11:16,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:34,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:04,405 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3564
en_de Dev loss: 0.8613 r:0.1967
en_zh Dev loss: 0.8332 r:0.3110
ro_en Dev loss: 0.3205 r:0.8194
et_en Dev loss: 0.3866 r:0.6953
si_en Dev loss: 0.7507 r:0.5905
ne_en Dev loss: 0.4355 r:0.7550
ru_en Dev loss: 0.4572 r:0.7166
Current avg r:0.5835 Best avg r: 0.6087
20:17:56,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:13,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:43,550 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3670
en_de Dev loss: 0.8769 r:0.1679
en_zh Dev loss: 0.8879 r:0.2965
ro_en Dev loss: 0.3465 r:0.8153
et_en Dev loss: 0.4079 r:0.6879
si_en Dev loss: 0.8732 r:0.5838
ne_en Dev loss: 0.5166 r:0.7535
ru_en Dev loss: 0.4952 r:0.7057
Current avg r:0.5729 Best avg r: 0.6087
20:24:34,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:52,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:22,319 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3429
en_de Dev loss: 0.8968 r:0.1379
en_zh Dev loss: 0.8480 r:0.3089
ro_en Dev loss: 0.3232 r:0.8272
et_en Dev loss: 0.3924 r:0.7045
si_en Dev loss: 0.6918 r:0.6040
ne_en Dev loss: 0.4016 r:0.7546
ru_en Dev loss: 0.4338 r:0.7326
Current avg r:0.5814 Best avg r: 0.6087
20:31:13,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:30,975 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:34:01,99 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3626
en_de Dev loss: 0.8731 r:0.1637
en_zh Dev loss: 0.8281 r:0.3181
ro_en Dev loss: 0.3161 r:0.8265
et_en Dev loss: 0.3943 r:0.6975
si_en Dev loss: 0.8185 r:0.5847
ne_en Dev loss: 0.4754 r:0.7585
ru_en Dev loss: 0.4350 r:0.7280
Current avg r:0.5824 Best avg r: 0.6087
20:37:52,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:09,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:39,973 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3527
en_de Dev loss: 0.9032 r:0.1337
en_zh Dev loss: 0.8051 r:0.3250
ro_en Dev loss: 0.3078 r:0.8241
et_en Dev loss: 0.3984 r:0.6893
si_en Dev loss: 0.7266 r:0.5852
ne_en Dev loss: 0.4660 r:0.7528
ru_en Dev loss: 0.4862 r:0.6957
Current avg r:0.5723 Best avg r: 0.6087
20:44:31,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:48,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:18,755 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3440
en_de Dev loss: 0.8863 r:0.1660
en_zh Dev loss: 0.8362 r:0.3132
ro_en Dev loss: 0.3030 r:0.8313
et_en Dev loss: 0.4033 r:0.7058
si_en Dev loss: 0.6665 r:0.6015
ne_en Dev loss: 0.3884 r:0.7609
ru_en Dev loss: 0.4211 r:0.7342
Current avg r:0.5876 Best avg r: 0.6087
20:51:10,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:27,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:57,771 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3624
en_de Dev loss: 0.8922 r:0.1735
en_zh Dev loss: 0.8963 r:0.2911
ro_en Dev loss: 0.3521 r:0.8201
et_en Dev loss: 0.4129 r:0.6831
si_en Dev loss: 0.8286 r:0.5717
ne_en Dev loss: 0.4955 r:0.7480
ru_en Dev loss: 0.5126 r:0.6949
Current avg r:0.5689 Best avg r: 0.6087
20:57:49,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:06,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:36,835 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3438
en_de Dev loss: 0.8791 r:0.1887
en_zh Dev loss: 0.8628 r:0.3127
ro_en Dev loss: 0.3214 r:0.8314
et_en Dev loss: 0.4025 r:0.6969
si_en Dev loss: 0.7427 r:0.5980
ne_en Dev loss: 0.4609 r:0.7584
ru_en Dev loss: 0.4520 r:0.7252
Current avg r:0.5873 Best avg r: 0.6087
21:04:28,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:45,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:15,553 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3535
en_de Dev loss: 0.8838 r:0.1841
en_zh Dev loss: 0.8571 r:0.3188
ro_en Dev loss: 0.3307 r:0.8239
et_en Dev loss: 0.4148 r:0.6845
si_en Dev loss: 0.7679 r:0.5869
ne_en Dev loss: 0.4627 r:0.7566
ru_en Dev loss: 0.5033 r:0.7037
Current avg r:0.5798 Best avg r: 0.6087
21:11:07,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:24,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:54,591 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3307
en_de Dev loss: 0.8759 r:0.1793
en_zh Dev loss: 0.8527 r:0.3185
ro_en Dev loss: 0.3234 r:0.8247
et_en Dev loss: 0.4244 r:0.6820
si_en Dev loss: 0.7602 r:0.5966
ne_en Dev loss: 0.4348 r:0.7694
ru_en Dev loss: 0.4464 r:0.7265
Current avg r:0.5853 Best avg r: 0.6087
21:17:47,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:04,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:34,807 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3129
en_de Dev loss: 0.8728 r:0.1873
en_zh Dev loss: 0.8415 r:0.3088
ro_en Dev loss: 0.3219 r:0.8219
et_en Dev loss: 0.4256 r:0.6774
si_en Dev loss: 0.7582 r:0.5861
ne_en Dev loss: 0.4823 r:0.7590
ru_en Dev loss: 0.4242 r:0.7298
Current avg r:0.5815 Best avg r: 0.6087
21:24:26,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:43,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:13,726 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3073
en_de Dev loss: 0.8776 r:0.1692
en_zh Dev loss: 0.8795 r:0.2955
ro_en Dev loss: 0.3364 r:0.8279
et_en Dev loss: 0.4141 r:0.6871
si_en Dev loss: 0.8041 r:0.5946
ne_en Dev loss: 0.5048 r:0.7603
ru_en Dev loss: 0.4714 r:0.7117
Current avg r:0.5780 Best avg r: 0.6087
21:31:05,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:22,346 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:52,524 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3035
en_de Dev loss: 0.8615 r:0.1753
en_zh Dev loss: 0.8340 r:0.2711
ro_en Dev loss: 0.3038 r:0.8203
et_en Dev loss: 0.4160 r:0.6857
si_en Dev loss: 0.6909 r:0.5913
ne_en Dev loss: 0.3971 r:0.7636
ru_en Dev loss: 0.4463 r:0.7009
Current avg r:0.5726 Best avg r: 0.6087
21:37:44,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:01,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:31,693 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3265
en_de Dev loss: 0.8693 r:0.1920
en_zh Dev loss: 0.8996 r:0.2874
ro_en Dev loss: 0.3572 r:0.8204
et_en Dev loss: 0.4369 r:0.6837
si_en Dev loss: 0.7977 r:0.5861
ne_en Dev loss: 0.4243 r:0.7501
ru_en Dev loss: 0.4903 r:0.7049
Current avg r:0.5749 Best avg r: 0.6087
21:44:23,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:40,597 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:47:10,786 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3153
en_de Dev loss: 0.8686 r:0.1784
en_zh Dev loss: 0.8375 r:0.2962
ro_en Dev loss: 0.3120 r:0.8222
et_en Dev loss: 0.4288 r:0.6816
si_en Dev loss: 0.7136 r:0.5855
ne_en Dev loss: 0.4010 r:0.7566
ru_en Dev loss: 0.4729 r:0.6912
Current avg r:0.5731 Best avg r: 0.6087
21:51:02,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:19,414 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:49,595 root INFO Epoch 4 Global steps: 39600 Train loss: 0.2924
en_de Dev loss: 0.8819 r:0.1815
en_zh Dev loss: 0.9108 r:0.2855
ro_en Dev loss: 0.3587 r:0.8226
et_en Dev loss: 0.4436 r:0.6880
si_en Dev loss: 0.8357 r:0.5757
ne_en Dev loss: 0.4487 r:0.7499
ru_en Dev loss: 0.4361 r:0.7367
Current avg r:0.5771 Best avg r: 0.6087
21:57:41,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:58,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:28,519 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3126
en_de Dev loss: 0.8823 r:0.1730
en_zh Dev loss: 0.8430 r:0.3003
ro_en Dev loss: 0.3112 r:0.8229
et_en Dev loss: 0.4300 r:0.6884
si_en Dev loss: 0.7146 r:0.5814
ne_en Dev loss: 0.4503 r:0.7503
ru_en Dev loss: 0.4358 r:0.7237
Current avg r:0.5771 Best avg r: 0.6087
22:04:19,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:37,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:07,444 root INFO Epoch 4 Global steps: 40800 Train loss: 0.2890
en_de Dev loss: 0.8814 r:0.1936
en_zh Dev loss: 0.8708 r:0.3133
ro_en Dev loss: 0.3397 r:0.8227
et_en Dev loss: 0.4368 r:0.6846
si_en Dev loss: 0.8515 r:0.5704
ne_en Dev loss: 0.5318 r:0.7519
ru_en Dev loss: 0.4400 r:0.7326
Current avg r:0.5813 Best avg r: 0.6087
22:10:58,980 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:16,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:46,579 root INFO Epoch 4 Global steps: 41400 Train loss: 0.2960
en_de Dev loss: 0.9173 r:0.1551
en_zh Dev loss: 0.9432 r:0.2852
ro_en Dev loss: 0.3803 r:0.8168
et_en Dev loss: 0.4497 r:0.6677
si_en Dev loss: 0.9330 r:0.5592
ne_en Dev loss: 0.5730 r:0.7494
ru_en Dev loss: 0.5534 r:0.6959
Current avg r:0.5613 Best avg r: 0.6087
22:17:38,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:55,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:25,693 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3059
en_de Dev loss: 0.8992 r:0.1788
en_zh Dev loss: 0.9397 r:0.2966
ro_en Dev loss: 0.3903 r:0.8139
et_en Dev loss: 0.4613 r:0.6631
si_en Dev loss: 1.0284 r:0.5557
ne_en Dev loss: 0.6336 r:0.7429
ru_en Dev loss: 0.5305 r:0.7027
Current avg r:0.5648 Best avg r: 0.6087
22:24:17,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:34,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:04,735 root INFO Epoch 4 Global steps: 42600 Train loss: 0.2906
en_de Dev loss: 0.9159 r:0.1764
en_zh Dev loss: 0.9349 r:0.2914
ro_en Dev loss: 0.3558 r:0.8212
et_en Dev loss: 0.4648 r:0.6692
si_en Dev loss: 0.9836 r:0.5549
ne_en Dev loss: 0.5279 r:0.7456
ru_en Dev loss: 0.5159 r:0.7076
Current avg r:0.5666 Best avg r: 0.6087
22:30:56,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:13,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:33:44,138 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3000
en_de Dev loss: 0.8886 r:0.1835
en_zh Dev loss: 0.8536 r:0.3037
ro_en Dev loss: 0.3086 r:0.8274
et_en Dev loss: 0.4471 r:0.6856
si_en Dev loss: 0.7479 r:0.5741
ne_en Dev loss: 0.4436 r:0.7494
ru_en Dev loss: 0.4182 r:0.7393
Current avg r:0.5804 Best avg r: 0.6087
22:37:35,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:52,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:23,91 root INFO Epoch 4 Global steps: 43800 Train loss: 0.2838
en_de Dev loss: 0.8917 r:0.1706
en_zh Dev loss: 0.8793 r:0.2983
ro_en Dev loss: 0.3338 r:0.8221
et_en Dev loss: 0.4378 r:0.6791
si_en Dev loss: 0.7934 r:0.5732
ne_en Dev loss: 0.5005 r:0.7470
ru_en Dev loss: 0.4671 r:0.7190
Current avg r:0.5728 Best avg r: 0.6087
22:44:14,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:45:31,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:02,155 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2905
en_de Dev loss: 0.8912 r:0.1769
en_zh Dev loss: 0.8899 r:0.2780
ro_en Dev loss: 0.3261 r:0.8186
et_en Dev loss: 0.4323 r:0.6762
si_en Dev loss: 0.8069 r:0.5629
ne_en Dev loss: 0.5268 r:0.7412
ru_en Dev loss: 0.4696 r:0.7100
Current avg r:0.5662 Best avg r: 0.6087
22:50:53,486 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:10,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:41,129 root INFO Epoch 4 Global steps: 45000 Train loss: 0.2975
en_de Dev loss: 0.8762 r:0.1838
en_zh Dev loss: 0.8490 r:0.2972
ro_en Dev loss: 0.3130 r:0.8267
et_en Dev loss: 0.4493 r:0.6859
si_en Dev loss: 0.7361 r:0.5778
ne_en Dev loss: 0.4336 r:0.7430
ru_en Dev loss: 0.3985 r:0.7454
Current avg r:0.5800 Best avg r: 0.6087
22:57:34,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:51,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:21,616 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2624
en_de Dev loss: 0.8734 r:0.1725
en_zh Dev loss: 0.8498 r:0.2878
ro_en Dev loss: 0.3179 r:0.8220
et_en Dev loss: 0.4198 r:0.6792
si_en Dev loss: 0.7751 r:0.5750
ne_en Dev loss: 0.4608 r:0.7451
ru_en Dev loss: 0.4349 r:0.7225
Current avg r:0.5720 Best avg r: 0.6087
23:04:13,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:31,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:02,65 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2687
en_de Dev loss: 0.8749 r:0.1891
en_zh Dev loss: 0.8947 r:0.2926
ro_en Dev loss: 0.3451 r:0.8217
et_en Dev loss: 0.4384 r:0.6836
si_en Dev loss: 0.7765 r:0.5746
ne_en Dev loss: 0.4439 r:0.7442
ru_en Dev loss: 0.4629 r:0.7238
Current avg r:0.5757 Best avg r: 0.6087
23:10:52,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:12:09,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:39,693 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2742
en_de Dev loss: 0.8824 r:0.1823
en_zh Dev loss: 0.8714 r:0.2989
ro_en Dev loss: 0.3430 r:0.8187
et_en Dev loss: 0.4544 r:0.6645
si_en Dev loss: 0.8402 r:0.5631
ne_en Dev loss: 0.6619 r:0.7326
ru_en Dev loss: 0.5092 r:0.6949
Current avg r:0.5650 Best avg r: 0.6087
23:17:30,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:47,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:17,632 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2603
en_de Dev loss: 0.9095 r:0.1897
en_zh Dev loss: 0.9269 r:0.2783
ro_en Dev loss: 0.3618 r:0.8145
et_en Dev loss: 0.4534 r:0.6683
si_en Dev loss: 0.8313 r:0.5648
ne_en Dev loss: 0.4952 r:0.7392
ru_en Dev loss: 0.4732 r:0.7221
Current avg r:0.5681 Best avg r: 0.6087
23:24:07,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:24,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:54,226 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2606
en_de Dev loss: 0.9117 r:0.1663
en_zh Dev loss: 0.9508 r:0.2820
ro_en Dev loss: 0.4120 r:0.8103
et_en Dev loss: 0.4581 r:0.6588
si_en Dev loss: 1.0151 r:0.5482
ne_en Dev loss: 0.6520 r:0.7372
ru_en Dev loss: 0.5145 r:0.7106
Current avg r:0.5591 Best avg r: 0.6087
23:30:43,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:00,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:30,718 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2601
en_de Dev loss: 0.8935 r:0.1889
en_zh Dev loss: 0.8790 r:0.2938
ro_en Dev loss: 0.3278 r:0.8224
et_en Dev loss: 0.4240 r:0.6871
si_en Dev loss: 0.7117 r:0.5826
ne_en Dev loss: 0.4201 r:0.7408
ru_en Dev loss: 0.4501 r:0.7291
Current avg r:0.5778 Best avg r: 0.6087
23:37:20,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:38:37,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:07,267 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2478
en_de Dev loss: 0.8818 r:0.1902
en_zh Dev loss: 0.8821 r:0.2760
ro_en Dev loss: 0.3287 r:0.8199
et_en Dev loss: 0.4528 r:0.6781
si_en Dev loss: 0.7782 r:0.5705
ne_en Dev loss: 0.4388 r:0.7442
ru_en Dev loss: 0.4151 r:0.7374
Current avg r:0.5738 Best avg r: 0.6087
23:43:57,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:14,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:43,777 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2401
en_de Dev loss: 0.9002 r:0.1848
en_zh Dev loss: 0.8745 r:0.3029
ro_en Dev loss: 0.3273 r:0.8247
et_en Dev loss: 0.4632 r:0.6810
si_en Dev loss: 0.7364 r:0.5755
ne_en Dev loss: 0.3998 r:0.7420
ru_en Dev loss: 0.4350 r:0.7336
Current avg r:0.5778 Best avg r: 0.6087
23:50:33,529 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:50,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:20,199 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2661
en_de Dev loss: 0.8827 r:0.1803
en_zh Dev loss: 0.8547 r:0.2994
ro_en Dev loss: 0.3253 r:0.8249
et_en Dev loss: 0.4560 r:0.6753
si_en Dev loss: 0.7355 r:0.5747
ne_en Dev loss: 0.4342 r:0.7272
ru_en Dev loss: 0.4396 r:0.7191
Current avg r:0.5716 Best avg r: 0.6087
23:57:09,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:26,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:56,635 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2503
en_de Dev loss: 0.9006 r:0.1697
en_zh Dev loss: 0.9006 r:0.2855
ro_en Dev loss: 0.3461 r:0.8210
et_en Dev loss: 0.4482 r:0.6728
si_en Dev loss: 0.7932 r:0.5729
ne_en Dev loss: 0.4678 r:0.7347
ru_en Dev loss: 0.4655 r:0.7227
Current avg r:0.5685 Best avg r: 0.6087
00:03:46,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:03,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:06:33,172 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2613
en_de Dev loss: 0.8920 r:0.1685
en_zh Dev loss: 0.8871 r:0.2769
ro_en Dev loss: 0.3227 r:0.8231
et_en Dev loss: 0.4454 r:0.6844
si_en Dev loss: 0.7872 r:0.5640
ne_en Dev loss: 0.4418 r:0.7373
ru_en Dev loss: 0.4377 r:0.7283
Current avg r:0.5689 Best avg r: 0.6087
00:10:22,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:40,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:13:09,835 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2444
en_de Dev loss: 0.9036 r:0.1656
en_zh Dev loss: 0.8855 r:0.2944
ro_en Dev loss: 0.3243 r:0.8259
et_en Dev loss: 0.4371 r:0.6834
si_en Dev loss: 0.7867 r:0.5762
ne_en Dev loss: 0.4742 r:0.7365
ru_en Dev loss: 0.4387 r:0.7379
Current avg r:0.5743 Best avg r: 0.6087
00:16:59,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:16,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:46,406 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2618
en_de Dev loss: 0.9319 r:0.1312
en_zh Dev loss: 0.9481 r:0.2777
ro_en Dev loss: 0.3776 r:0.8196
et_en Dev loss: 0.4808 r:0.6519
si_en Dev loss: 0.8865 r:0.5550
ne_en Dev loss: 0.5726 r:0.7347
ru_en Dev loss: 0.4839 r:0.7163
Current avg r:0.5552 Best avg r: 0.6087
00:23:36,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:53,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:26:23,420 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2496
en_de Dev loss: 0.9106 r:0.1555
en_zh Dev loss: 0.9391 r:0.2810
ro_en Dev loss: 0.3779 r:0.8155
et_en Dev loss: 0.4612 r:0.6615
si_en Dev loss: 0.9242 r:0.5524
ne_en Dev loss: 0.5058 r:0.7417
ru_en Dev loss: 0.5028 r:0.7139
Current avg r:0.5602 Best avg r: 0.6087
00:30:13,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:31,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:33:01,441 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2597
en_de Dev loss: 0.9005 r:0.1673
en_zh Dev loss: 0.9345 r:0.2596
ro_en Dev loss: 0.3438 r:0.8194
et_en Dev loss: 0.4576 r:0.6723
si_en Dev loss: 0.7948 r:0.5600
ne_en Dev loss: 0.4959 r:0.7308
ru_en Dev loss: 0.4675 r:0.7212
Current avg r:0.5615 Best avg r: 0.6087
00:36:53,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:38:11,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:41,590 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2332
en_de Dev loss: 0.9087 r:0.1740
en_zh Dev loss: 0.9396 r:0.2657
ro_en Dev loss: 0.3525 r:0.8190
et_en Dev loss: 0.4641 r:0.6609
si_en Dev loss: 0.8643 r:0.5546
ne_en Dev loss: 0.5615 r:0.7329
ru_en Dev loss: 0.4867 r:0.7152
Current avg r:0.5603 Best avg r: 0.6087
00:43:32,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:49,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:20,175 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2124
en_de Dev loss: 0.8999 r:0.1703
en_zh Dev loss: 0.9049 r:0.2749
ro_en Dev loss: 0.3461 r:0.8165
et_en Dev loss: 0.4754 r:0.6582
si_en Dev loss: 0.8664 r:0.5436
ne_en Dev loss: 0.5112 r:0.7318
ru_en Dev loss: 0.4615 r:0.7154
Current avg r:0.5587 Best avg r: 0.6087
00:50:10,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:28,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:57,804 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2375
en_de Dev loss: 0.9090 r:0.1863
en_zh Dev loss: 0.9480 r:0.2793
ro_en Dev loss: 0.3572 r:0.8254
et_en Dev loss: 0.4429 r:0.6647
si_en Dev loss: 0.8656 r:0.5541
ne_en Dev loss: 0.5452 r:0.7398
ru_en Dev loss: 0.5021 r:0.7126
Current avg r:0.5660 Best avg r: 0.6087
00:56:47,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:04,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:34,291 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2169
en_de Dev loss: 0.8935 r:0.1802
en_zh Dev loss: 0.9502 r:0.2682
ro_en Dev loss: 0.3599 r:0.8216
et_en Dev loss: 0.4659 r:0.6594
si_en Dev loss: 0.8797 r:0.5476
ne_en Dev loss: 0.5457 r:0.7264
ru_en Dev loss: 0.4834 r:0.7225
Current avg r:0.5608 Best avg r: 0.6087
01:03:23,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:41,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:11,63 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2209
en_de Dev loss: 0.8743 r:0.1828
en_zh Dev loss: 0.8836 r:0.2852
ro_en Dev loss: 0.3668 r:0.8182
et_en Dev loss: 0.4518 r:0.6659
si_en Dev loss: 0.8612 r:0.5555
ne_en Dev loss: 0.5238 r:0.7296
ru_en Dev loss: 0.4493 r:0.7311
Current avg r:0.5669 Best avg r: 0.6087
01:10:00,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:17,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:47,989 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2340
en_de Dev loss: 0.8816 r:0.1910
en_zh Dev loss: 0.9257 r:0.2555
ro_en Dev loss: 0.3511 r:0.8155
et_en Dev loss: 0.4690 r:0.6609
si_en Dev loss: 0.8878 r:0.5442
ne_en Dev loss: 0.4994 r:0.7296
ru_en Dev loss: 0.4744 r:0.7175
Current avg r:0.5592 Best avg r: 0.6087
01:16:37,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:54,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:24,495 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2306
en_de Dev loss: 0.9068 r:0.1759
en_zh Dev loss: 0.9629 r:0.2639
ro_en Dev loss: 0.3842 r:0.8201
et_en Dev loss: 0.4767 r:0.6597
si_en Dev loss: 0.9253 r:0.5563
ne_en Dev loss: 0.5320 r:0.7302
ru_en Dev loss: 0.4804 r:0.7339
Current avg r:0.5629 Best avg r: 0.6087
01:23:14,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:24:31,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:00,883 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2294
en_de Dev loss: 0.9168 r:0.1589
en_zh Dev loss: 0.9297 r:0.2608
ro_en Dev loss: 0.3485 r:0.8136
et_en Dev loss: 0.4628 r:0.6466
si_en Dev loss: 0.8332 r:0.5487
ne_en Dev loss: 0.5131 r:0.7238
ru_en Dev loss: 0.4848 r:0.7092
Current avg r:0.5516 Best avg r: 0.6087
01:29:50,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:07,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:37,224 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2245
en_de Dev loss: 0.9221 r:0.1537
en_zh Dev loss: 0.9267 r:0.2664
ro_en Dev loss: 0.3643 r:0.8146
et_en Dev loss: 0.4854 r:0.6584
si_en Dev loss: 0.9357 r:0.5493
ne_en Dev loss: 0.6404 r:0.7207
ru_en Dev loss: 0.4991 r:0.7017
Current avg r:0.5521 Best avg r: 0.6087
01:36:26,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:37:43,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:13,922 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2251
en_de Dev loss: 0.8954 r:0.1781
en_zh Dev loss: 0.8905 r:0.2882
ro_en Dev loss: 0.3366 r:0.8225
et_en Dev loss: 0.4753 r:0.6777
si_en Dev loss: 0.7866 r:0.5677
ne_en Dev loss: 0.4869 r:0.7257
ru_en Dev loss: 0.4460 r:0.7258
Current avg r:0.5694 Best avg r: 0.6087
01:43:03,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:20,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:50,731 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2204
en_de Dev loss: 0.8893 r:0.1942
en_zh Dev loss: 0.8797 r:0.3028
ro_en Dev loss: 0.3354 r:0.8243
et_en Dev loss: 0.5054 r:0.6838
si_en Dev loss: 0.7477 r:0.5718
ne_en Dev loss: 0.4380 r:0.7286
ru_en Dev loss: 0.4144 r:0.7415
Current avg r:0.5781 Best avg r: 0.6087
01:49:44,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:02,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:34,205 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2235
en_de Dev loss: 0.9053 r:0.1730
en_zh Dev loss: 0.9169 r:0.2925
ro_en Dev loss: 0.3315 r:0.8254
et_en Dev loss: 0.4492 r:0.6796
si_en Dev loss: 0.8754 r:0.5554
ne_en Dev loss: 0.4580 r:0.7323
ru_en Dev loss: 0.4617 r:0.7333
Current avg r:0.5702 Best avg r: 0.6087
01:56:28,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:46,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:18,91 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2287
en_de Dev loss: 0.9119 r:0.1703
en_zh Dev loss: 0.9289 r:0.2961
ro_en Dev loss: 0.3579 r:0.8231
et_en Dev loss: 0.4691 r:0.6717
si_en Dev loss: 0.9149 r:0.5507
ne_en Dev loss: 0.5356 r:0.7272
ru_en Dev loss: 0.4446 r:0.7388
Current avg r:0.5683 Best avg r: 0.6087
02:03:12,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:04:30,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:06:02,130 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2136
en_de Dev loss: 0.9265 r:0.1521
en_zh Dev loss: 0.8981 r:0.2991
ro_en Dev loss: 0.3291 r:0.8252
et_en Dev loss: 0.4772 r:0.6812
si_en Dev loss: 0.8546 r:0.5503
ne_en Dev loss: 0.4796 r:0.7279
ru_en Dev loss: 0.4403 r:0.7311
Current avg r:0.5667 Best avg r: 0.6087
02:09:56,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:11:14,852 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:12:46,21 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2108
en_de Dev loss: 0.9438 r:0.1397
en_zh Dev loss: 0.9819 r:0.2721
ro_en Dev loss: 0.3799 r:0.8163
et_en Dev loss: 0.4665 r:0.6651
si_en Dev loss: 0.9683 r:0.5371
ne_en Dev loss: 0.5667 r:0.7233
ru_en Dev loss: 0.5420 r:0.7043
Current avg r:0.5511 Best avg r: 0.6087
02:16:42,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:18:00,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:31,34 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1955
en_de Dev loss: 0.9035 r:0.1864
en_zh Dev loss: 0.9043 r:0.2878
ro_en Dev loss: 0.3283 r:0.8239
et_en Dev loss: 0.4701 r:0.6781
si_en Dev loss: 0.8843 r:0.5474
ne_en Dev loss: 0.5088 r:0.7219
ru_en Dev loss: 0.4371 r:0.7363
Current avg r:0.5688 Best avg r: 0.6087
02:23:21,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:38,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:26:08,927 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1936
en_de Dev loss: 0.9331 r:0.1500
en_zh Dev loss: 0.9449 r:0.2748
ro_en Dev loss: 0.3607 r:0.8203
et_en Dev loss: 0.4886 r:0.6689
si_en Dev loss: 0.8864 r:0.5395
ne_en Dev loss: 0.5244 r:0.7206
ru_en Dev loss: 0.4686 r:0.7289
Current avg r:0.5576 Best avg r: 0.6087
02:29:59,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:16,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:32:46,978 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1944
en_de Dev loss: 0.9304 r:0.1374
en_zh Dev loss: 0.8929 r:0.2802
ro_en Dev loss: 0.3297 r:0.8217
et_en Dev loss: 0.4876 r:0.6614
si_en Dev loss: 0.8305 r:0.5411
ne_en Dev loss: 0.5399 r:0.7145
ru_en Dev loss: 0.4662 r:0.7115
Current avg r:0.5525 Best avg r: 0.6087
02:36:37,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:54,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:39:24,953 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1872
en_de Dev loss: 0.9009 r:0.1653
en_zh Dev loss: 0.8887 r:0.3067
ro_en Dev loss: 0.3225 r:0.8254
et_en Dev loss: 0.4457 r:0.6736
si_en Dev loss: 0.8406 r:0.5523
ne_en Dev loss: 0.5281 r:0.7287
ru_en Dev loss: 0.4302 r:0.7444
Current avg r:0.5709 Best avg r: 0.6087
02:43:15,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:44:32,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:46:02,913 root INFO Epoch 7 Global steps: 66000 Train loss: 0.2064
en_de Dev loss: 0.9238 r:0.1640
en_zh Dev loss: 0.9104 r:0.2986
ro_en Dev loss: 0.3397 r:0.8234
et_en Dev loss: 0.4526 r:0.6722
si_en Dev loss: 0.8715 r:0.5507
ne_en Dev loss: 0.5828 r:0.7214
ru_en Dev loss: 0.4416 r:0.7389
Current avg r:0.5670 Best avg r: 0.6087
02:49:53,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:11,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:41,321 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1986
en_de Dev loss: 0.9464 r:0.1340
en_zh Dev loss: 0.9334 r:0.2977
ro_en Dev loss: 0.3459 r:0.8194
et_en Dev loss: 0.4484 r:0.6676
si_en Dev loss: 0.8591 r:0.5448
ne_en Dev loss: 0.5423 r:0.7289
ru_en Dev loss: 0.4617 r:0.7304
Current avg r:0.5604 Best avg r: 0.6087
02:56:34,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:57:52,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:59:23,351 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1937
en_de Dev loss: 0.9290 r:0.1529
en_zh Dev loss: 0.9248 r:0.2917
ro_en Dev loss: 0.3399 r:0.8199
et_en Dev loss: 0.4957 r:0.6721
si_en Dev loss: 0.8383 r:0.5509
ne_en Dev loss: 0.4903 r:0.7259
ru_en Dev loss: 0.4576 r:0.7284
Current avg r:0.5631 Best avg r: 0.6087
03:03:16,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:04:34,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:06:05,656 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1955
en_de Dev loss: 0.9443 r:0.1519
en_zh Dev loss: 0.9254 r:0.2935
ro_en Dev loss: 0.3287 r:0.8208
et_en Dev loss: 0.4737 r:0.6760
si_en Dev loss: 0.8467 r:0.5551
ne_en Dev loss: 0.4818 r:0.7297
ru_en Dev loss: 0.4437 r:0.7384
Current avg r:0.5665 Best avg r: 0.6087
03:09:58,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:11:16,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:12:47,503 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2037
en_de Dev loss: 0.9270 r:0.1458
en_zh Dev loss: 0.8975 r:0.2893
ro_en Dev loss: 0.3266 r:0.8193
et_en Dev loss: 0.4770 r:0.6660
si_en Dev loss: 0.8727 r:0.5354
ne_en Dev loss: 0.4815 r:0.7302
ru_en Dev loss: 0.4581 r:0.7199
Current avg r:0.5580 Best avg r: 0.6087
03:16:41,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:17:59,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:30,489 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1937
en_de Dev loss: 0.9253 r:0.1398
en_zh Dev loss: 0.9277 r:0.2827
ro_en Dev loss: 0.3577 r:0.8169
et_en Dev loss: 0.4790 r:0.6627
si_en Dev loss: 0.8975 r:0.5347
ne_en Dev loss: 0.5315 r:0.7350
ru_en Dev loss: 0.4524 r:0.7336
Current avg r:0.5579 Best avg r: 0.6087
03:23:23,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:24:41,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:26:12,683 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1871
en_de Dev loss: 0.9304 r:0.1481
en_zh Dev loss: 0.9333 r:0.2905
ro_en Dev loss: 0.3502 r:0.8194
et_en Dev loss: 0.4504 r:0.6661
si_en Dev loss: 0.8937 r:0.5383
ne_en Dev loss: 0.5484 r:0.7239
ru_en Dev loss: 0.4560 r:0.7374
Current avg r:0.5605 Best avg r: 0.6087
03:30:05,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:31:23,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:32:55,9 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1941
en_de Dev loss: 0.9197 r:0.1596
en_zh Dev loss: 0.9016 r:0.2948
ro_en Dev loss: 0.3435 r:0.8173
et_en Dev loss: 0.4690 r:0.6706
si_en Dev loss: 0.8419 r:0.5483
ne_en Dev loss: 0.5270 r:0.7243
ru_en Dev loss: 0.4350 r:0.7389
Current avg r:0.5648 Best avg r: 0.6087
03:36:48,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:38:06,42 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:39:36,533 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1928
en_de Dev loss: 0.9064 r:0.1478
en_zh Dev loss: 0.8623 r:0.3016
ro_en Dev loss: 0.3135 r:0.8221
et_en Dev loss: 0.4200 r:0.6721
si_en Dev loss: 0.7955 r:0.5507
ne_en Dev loss: 0.5115 r:0.7289
ru_en Dev loss: 0.4041 r:0.7483
Current avg r:0.5673 Best avg r: 0.6087
03:43:26,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:44,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:46:14,730 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1899
en_de Dev loss: 0.9315 r:0.1534
en_zh Dev loss: 0.9346 r:0.3002
ro_en Dev loss: 0.3758 r:0.8197
et_en Dev loss: 0.4546 r:0.6678
si_en Dev loss: 0.9264 r:0.5411
ne_en Dev loss: 0.5684 r:0.7269
ru_en Dev loss: 0.4530 r:0.7436
Current avg r:0.5647 Best avg r: 0.6087
03:50:05,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:23,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:54,359 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1916
en_de Dev loss: 0.9160 r:0.1634
en_zh Dev loss: 0.8989 r:0.3018
ro_en Dev loss: 0.3313 r:0.8219
et_en Dev loss: 0.4433 r:0.6728
si_en Dev loss: 0.8017 r:0.5445
ne_en Dev loss: 0.5033 r:0.7202
ru_en Dev loss: 0.4036 r:0.7559
Current avg r:0.5687 Best avg r: 0.6087
03:56:47,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:58:05,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:59:35,618 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1787
en_de Dev loss: 0.9199 r:0.1527
en_zh Dev loss: 0.9235 r:0.2919
ro_en Dev loss: 0.3519 r:0.8172
et_en Dev loss: 0.4622 r:0.6527
si_en Dev loss: 0.9366 r:0.5260
ne_en Dev loss: 0.6613 r:0.7101
ru_en Dev loss: 0.4823 r:0.7214
Current avg r:0.5531 Best avg r: 0.6087
04:03:27,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:44,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:06:15,457 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1785
en_de Dev loss: 0.9290 r:0.1597
en_zh Dev loss: 0.9563 r:0.2883
ro_en Dev loss: 0.3299 r:0.8251
et_en Dev loss: 0.4517 r:0.6764
si_en Dev loss: 0.8423 r:0.5435
ne_en Dev loss: 0.5143 r:0.7188
ru_en Dev loss: 0.4273 r:0.7532
Current avg r:0.5664 Best avg r: 0.6087
04:10:07,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:11:24,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:12:54,680 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1650
en_de Dev loss: 0.9073 r:0.1651
en_zh Dev loss: 0.8892 r:0.3030
ro_en Dev loss: 0.3293 r:0.8248
et_en Dev loss: 0.4770 r:0.6713
si_en Dev loss: 0.8753 r:0.5416
ne_en Dev loss: 0.5112 r:0.7229
ru_en Dev loss: 0.3856 r:0.7624
Current avg r:0.5702 Best avg r: 0.6087
04:16:47,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:18:05,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:36,490 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1685
en_de Dev loss: 0.9006 r:0.1696
en_zh Dev loss: 0.8818 r:0.3046
ro_en Dev loss: 0.3135 r:0.8251
et_en Dev loss: 0.4565 r:0.6734
si_en Dev loss: 0.8366 r:0.5468
ne_en Dev loss: 0.5242 r:0.7267
ru_en Dev loss: 0.3887 r:0.7584
Current avg r:0.5721 Best avg r: 0.6087
04:23:29,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:24:47,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:26:18,379 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1685
en_de Dev loss: 0.9171 r:0.1548
en_zh Dev loss: 0.9019 r:0.3035
ro_en Dev loss: 0.3149 r:0.8263
et_en Dev loss: 0.4399 r:0.6784
si_en Dev loss: 0.8409 r:0.5441
ne_en Dev loss: 0.5013 r:0.7181
ru_en Dev loss: 0.4113 r:0.7537
Current avg r:0.5684 Best avg r: 0.6087
04:30:11,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:31:29,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:33:00,381 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1824
en_de Dev loss: 0.9850 r:0.1547
en_zh Dev loss: 0.9677 r:0.3167
ro_en Dev loss: 0.3813 r:0.8184
et_en Dev loss: 0.4717 r:0.6790
si_en Dev loss: 0.8960 r:0.5472
ne_en Dev loss: 0.5133 r:0.7238
ru_en Dev loss: 0.4371 r:0.7656
Current avg r:0.5722 Best avg r: 0.6087
04:36:53,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:38:11,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:39:42,404 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1701
en_de Dev loss: 0.9373 r:0.1594
en_zh Dev loss: 0.9585 r:0.3006
ro_en Dev loss: 0.3569 r:0.8226
et_en Dev loss: 0.4589 r:0.6782
si_en Dev loss: 0.8175 r:0.5506
ne_en Dev loss: 0.5266 r:0.7182
ru_en Dev loss: 0.4133 r:0.7600
Current avg r:0.5699 Best avg r: 0.6087
04:43:35,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:53,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:46:24,303 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1632
en_de Dev loss: 0.9221 r:0.1507
en_zh Dev loss: 0.9143 r:0.2900
ro_en Dev loss: 0.3369 r:0.8187
et_en Dev loss: 0.4619 r:0.6685
si_en Dev loss: 0.8096 r:0.5400
ne_en Dev loss: 0.4857 r:0.7174
ru_en Dev loss: 0.4297 r:0.7398
Current avg r:0.5607 Best avg r: 0.6087
04:50:17,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:51:35,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:06,79 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1682
en_de Dev loss: 0.9397 r:0.1468
en_zh Dev loss: 0.9336 r:0.2903
ro_en Dev loss: 0.3577 r:0.8171
et_en Dev loss: 0.5112 r:0.6740
si_en Dev loss: 0.8142 r:0.5438
ne_en Dev loss: 0.5300 r:0.7150
ru_en Dev loss: 0.4348 r:0.7414
Current avg r:0.5612 Best avg r: 0.6087
04:56:58,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:58:16,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:59:47,989 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1667
en_de Dev loss: 0.9175 r:0.1641
en_zh Dev loss: 0.8928 r:0.3128
ro_en Dev loss: 0.3408 r:0.8203
et_en Dev loss: 0.4430 r:0.6723
si_en Dev loss: 0.8310 r:0.5510
ne_en Dev loss: 0.5119 r:0.7255
ru_en Dev loss: 0.4470 r:0.7422
Current avg r:0.5697 Best avg r: 0.6087
05:03:38,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:04:56,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:06:26,370 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1630
en_de Dev loss: 0.9296 r:0.1557
en_zh Dev loss: 0.9297 r:0.2919
ro_en Dev loss: 0.3637 r:0.8190
et_en Dev loss: 0.4594 r:0.6674
si_en Dev loss: 0.9256 r:0.5455
ne_en Dev loss: 0.6289 r:0.7205
ru_en Dev loss: 0.4657 r:0.7330
Current avg r:0.5619 Best avg r: 0.6087
05:10:17,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:11:35,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:13:06,237 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1712
en_de Dev loss: 0.9482 r:0.1416
en_zh Dev loss: 0.9711 r:0.2756
ro_en Dev loss: 0.3665 r:0.8180
et_en Dev loss: 0.4476 r:0.6682
si_en Dev loss: 0.9730 r:0.5359
ne_en Dev loss: 0.5818 r:0.7203
ru_en Dev loss: 0.4485 r:0.7479
Current avg r:0.5582 Best avg r: 0.6087
05:16:59,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:18:17,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:19:47,889 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1653
en_de Dev loss: 0.9092 r:0.1476
en_zh Dev loss: 0.9197 r:0.2801
ro_en Dev loss: 0.3450 r:0.8185
et_en Dev loss: 0.4737 r:0.6698
si_en Dev loss: 0.9065 r:0.5385
ne_en Dev loss: 0.5344 r:0.7218
ru_en Dev loss: 0.4088 r:0.7511
Current avg r:0.5611 Best avg r: 0.6087
05:23:40,459 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:24:58,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:29,249 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1654
en_de Dev loss: 0.9224 r:0.1513
en_zh Dev loss: 0.9248 r:0.2951
ro_en Dev loss: 0.3294 r:0.8200
et_en Dev loss: 0.4436 r:0.6815
si_en Dev loss: 0.8361 r:0.5501
ne_en Dev loss: 0.5174 r:0.7235
ru_en Dev loss: 0.4355 r:0.7500
Current avg r:0.5674 Best avg r: 0.6087
05:30:22,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:31:40,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:33:11,521 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1626
en_de Dev loss: 0.9256 r:0.1606
en_zh Dev loss: 0.9179 r:0.2959
ro_en Dev loss: 0.3303 r:0.8197
et_en Dev loss: 0.4569 r:0.6663
si_en Dev loss: 0.8206 r:0.5482
ne_en Dev loss: 0.4944 r:0.7251
ru_en Dev loss: 0.4333 r:0.7400
Current avg r:0.5651 Best avg r: 0.6087
05:37:04,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:38:21,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:39:51,849 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1579
en_de Dev loss: 0.9204 r:0.1553
en_zh Dev loss: 0.9126 r:0.2949
ro_en Dev loss: 0.3206 r:0.8251
et_en Dev loss: 0.4536 r:0.6677
si_en Dev loss: 0.8497 r:0.5425
ne_en Dev loss: 0.4751 r:0.7228
ru_en Dev loss: 0.4347 r:0.7395
Current avg r:0.5640 Best avg r: 0.6087
05:43:42,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:45:00,546 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:31,121 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1527
en_de Dev loss: 0.9433 r:0.1576
en_zh Dev loss: 0.9745 r:0.2872
ro_en Dev loss: 0.3782 r:0.8187
et_en Dev loss: 0.4595 r:0.6627
si_en Dev loss: 0.9761 r:0.5299
ne_en Dev loss: 0.6205 r:0.7205
ru_en Dev loss: 0.4926 r:0.7290
Current avg r:0.5580 Best avg r: 0.6087
05:50:22,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:40,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:10,959 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1511
en_de Dev loss: 0.9555 r:0.1410
en_zh Dev loss: 0.9413 r:0.3003
ro_en Dev loss: 0.3549 r:0.8234
et_en Dev loss: 0.4574 r:0.6738
si_en Dev loss: 0.9201 r:0.5337
ne_en Dev loss: 0.5966 r:0.7175
ru_en Dev loss: 0.4455 r:0.7450
Current avg r:0.5621 Best avg r: 0.6087
05:57:04,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:58:23,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:54,110 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1519
en_de Dev loss: 0.9300 r:0.1311
en_zh Dev loss: 0.9039 r:0.2896
ro_en Dev loss: 0.3281 r:0.8209
et_en Dev loss: 0.4584 r:0.6779
si_en Dev loss: 0.8325 r:0.5433
ne_en Dev loss: 0.5040 r:0.7119
ru_en Dev loss: 0.4028 r:0.7554
Current avg r:0.5614 Best avg r: 0.6087
06:03:48,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:05:06,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:06:37,912 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1441
en_de Dev loss: 0.9322 r:0.1505
en_zh Dev loss: 0.9421 r:0.2828
ro_en Dev loss: 0.3682 r:0.8164
et_en Dev loss: 0.4748 r:0.6592
si_en Dev loss: 0.9690 r:0.5252
ne_en Dev loss: 0.6433 r:0.7056
ru_en Dev loss: 0.4536 r:0.7380
Current avg r:0.5539 Best avg r: 0.6087
06:10:32,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:50,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:13:21,360 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1487
en_de Dev loss: 0.9368 r:0.1398
en_zh Dev loss: 0.9065 r:0.2943
ro_en Dev loss: 0.3360 r:0.8182
et_en Dev loss: 0.4659 r:0.6647
si_en Dev loss: 0.8915 r:0.5293
ne_en Dev loss: 0.5721 r:0.7084
ru_en Dev loss: 0.4370 r:0.7382
Current avg r:0.5561 Best avg r: 0.6087
06:17:15,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:18:33,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:20:04,751 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1519
en_de Dev loss: 0.9094 r:0.1681
en_zh Dev loss: 0.8523 r:0.3145
ro_en Dev loss: 0.3271 r:0.8208
et_en Dev loss: 0.4746 r:0.6769
si_en Dev loss: 0.8303 r:0.5437
ne_en Dev loss: 0.5124 r:0.7193
ru_en Dev loss: 0.3621 r:0.7690
Current avg r:0.5732 Best avg r: 0.6087
06:23:57,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:25:14,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:44,506 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1472
en_de Dev loss: 0.9371 r:0.1645
en_zh Dev loss: 0.9302 r:0.2994
ro_en Dev loss: 0.3457 r:0.8234
et_en Dev loss: 0.4860 r:0.6816
si_en Dev loss: 0.8571 r:0.5428
ne_en Dev loss: 0.4871 r:0.7213
ru_en Dev loss: 0.3921 r:0.7665
Current avg r:0.5713 Best avg r: 0.6087
06:30:35,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:31:52,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:33:22,529 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1401
en_de Dev loss: 0.9398 r:0.1531
en_zh Dev loss: 0.9345 r:0.3055
ro_en Dev loss: 0.3418 r:0.8232
et_en Dev loss: 0.4674 r:0.6818
si_en Dev loss: 0.8304 r:0.5534
ne_en Dev loss: 0.4818 r:0.7236
ru_en Dev loss: 0.4267 r:0.7552
Current avg r:0.5708 Best avg r: 0.6087
06:37:13,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:38:30,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:40:00,879 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1447
en_de Dev loss: 0.9139 r:0.1634
en_zh Dev loss: 0.9099 r:0.3016
ro_en Dev loss: 0.3498 r:0.8186
et_en Dev loss: 0.4491 r:0.6802
si_en Dev loss: 0.8712 r:0.5448
ne_en Dev loss: 0.5854 r:0.7218
ru_en Dev loss: 0.4285 r:0.7481
Current avg r:0.5684 Best avg r: 0.6087
06:43:54,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:12,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:43,118 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1485
en_de Dev loss: 0.9307 r:0.1718
en_zh Dev loss: 0.9211 r:0.2986
ro_en Dev loss: 0.3452 r:0.8219
et_en Dev loss: 0.4708 r:0.6789
si_en Dev loss: 0.8506 r:0.5467
ne_en Dev loss: 0.4953 r:0.7246
ru_en Dev loss: 0.4278 r:0.7521
Current avg r:0.5707 Best avg r: 0.6087
06:50:36,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:54,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:53:25,444 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1383
en_de Dev loss: 0.9277 r:0.1590
en_zh Dev loss: 0.9208 r:0.2956
ro_en Dev loss: 0.3406 r:0.8200
et_en Dev loss: 0.4604 r:0.6738
si_en Dev loss: 0.9029 r:0.5428
ne_en Dev loss: 0.5585 r:0.7211
ru_en Dev loss: 0.4308 r:0.7483
Current avg r:0.5658 Best avg r: 0.6087
06:57:18,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:58:36,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:00:07,868 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1445
en_de Dev loss: 0.9299 r:0.1585
en_zh Dev loss: 0.9272 r:0.2909
ro_en Dev loss: 0.3258 r:0.8235
et_en Dev loss: 0.4610 r:0.6836
si_en Dev loss: 0.7992 r:0.5464
ne_en Dev loss: 0.5225 r:0.7139
ru_en Dev loss: 0.4041 r:0.7587
Current avg r:0.5679 Best avg r: 0.6087
07:04:00,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:05:18,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:06:48,623 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1475
en_de Dev loss: 0.9373 r:0.1644
en_zh Dev loss: 0.9283 r:0.2885
ro_en Dev loss: 0.3327 r:0.8192
et_en Dev loss: 0.4749 r:0.6767
si_en Dev loss: 0.8051 r:0.5441
ne_en Dev loss: 0.4966 r:0.7133
ru_en Dev loss: 0.4219 r:0.7491
Current avg r:0.5650 Best avg r: 0.6087
07:10:39,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:11:56,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:13:27,136 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1455
en_de Dev loss: 0.9359 r:0.1504
en_zh Dev loss: 0.8985 r:0.3103
ro_en Dev loss: 0.3402 r:0.8228
et_en Dev loss: 0.4749 r:0.6832
si_en Dev loss: 0.8041 r:0.5479
ne_en Dev loss: 0.4877 r:0.7161
ru_en Dev loss: 0.3851 r:0.7651
Current avg r:0.5708 Best avg r: 0.6087
07:17:19,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:18:37,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:08,607 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1339
en_de Dev loss: 0.9440 r:0.1604
en_zh Dev loss: 0.9428 r:0.3168
ro_en Dev loss: 0.3651 r:0.8190
et_en Dev loss: 0.4524 r:0.6686
si_en Dev loss: 0.9380 r:0.5372
ne_en Dev loss: 0.5571 r:0.7208
ru_en Dev loss: 0.4258 r:0.7575
Current avg r:0.5686 Best avg r: 0.6087
07:24:01,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:19,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:50,509 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1305
en_de Dev loss: 0.9070 r:0.1747
en_zh Dev loss: 0.9165 r:0.3008
ro_en Dev loss: 0.3449 r:0.8181
et_en Dev loss: 0.4501 r:0.6796
si_en Dev loss: 0.8924 r:0.5375
ne_en Dev loss: 0.5486 r:0.7158
ru_en Dev loss: 0.4157 r:0.7536
Current avg r:0.5686 Best avg r: 0.6087
07:30:43,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:01,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:33:32,660 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1353
en_de Dev loss: 0.9293 r:0.1842
en_zh Dev loss: 0.9735 r:0.2984
ro_en Dev loss: 0.3944 r:0.8166
et_en Dev loss: 0.4952 r:0.6733
si_en Dev loss: 0.8855 r:0.5440
ne_en Dev loss: 0.5384 r:0.7153
ru_en Dev loss: 0.4743 r:0.7372
Current avg r:0.5670 Best avg r: 0.6087
07:37:26,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:44,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:40:15,219 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1356
en_de Dev loss: 0.9260 r:0.1437
en_zh Dev loss: 0.9451 r:0.2824
ro_en Dev loss: 0.3457 r:0.8152
et_en Dev loss: 0.4398 r:0.6766
si_en Dev loss: 0.8761 r:0.5337
ne_en Dev loss: 0.5663 r:0.7117
ru_en Dev loss: 0.4241 r:0.7451
Current avg r:0.5584 Best avg r: 0.6087
07:44:07,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:45:25,466 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:46:55,951 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1356
en_de Dev loss: 0.9550 r:0.1597
en_zh Dev loss: 0.9376 r:0.3068
ro_en Dev loss: 0.3465 r:0.8215
et_en Dev loss: 0.4635 r:0.6851
si_en Dev loss: 0.8452 r:0.5452
ne_en Dev loss: 0.5496 r:0.7137
ru_en Dev loss: 0.4350 r:0.7459
Current avg r:0.5683 Best avg r: 0.6087
07:50:48,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:52:05,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:53:35,295 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1347
en_de Dev loss: 0.9740 r:0.1700
en_zh Dev loss: 0.9653 r:0.3151
ro_en Dev loss: 0.3816 r:0.8177
et_en Dev loss: 0.4728 r:0.6782
si_en Dev loss: 0.9185 r:0.5417
ne_en Dev loss: 0.5871 r:0.7144
ru_en Dev loss: 0.4804 r:0.7490
Current avg r:0.5694 Best avg r: 0.6087
07:57:25,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:58:42,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:00:12,905 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1381
en_de Dev loss: 0.9593 r:0.1621
en_zh Dev loss: 0.9549 r:0.3025
ro_en Dev loss: 0.3536 r:0.8210
et_en Dev loss: 0.4687 r:0.6704
si_en Dev loss: 0.8827 r:0.5390
ne_en Dev loss: 0.5701 r:0.7137
ru_en Dev loss: 0.4550 r:0.7405
Current avg r:0.5642 Best avg r: 0.6087
08:04:03,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:05:20,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:06:50,156 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1332
en_de Dev loss: 0.9684 r:0.1494
en_zh Dev loss: 0.9716 r:0.2846
ro_en Dev loss: 0.3487 r:0.8203
et_en Dev loss: 0.4565 r:0.6709
si_en Dev loss: 0.8820 r:0.5280
ne_en Dev loss: 0.6043 r:0.7040
ru_en Dev loss: 0.4517 r:0.7356
Current avg r:0.5561 Best avg r: 0.6087
08:10:40,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:11:57,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:13:27,628 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1340
en_de Dev loss: 0.9515 r:0.1560
en_zh Dev loss: 1.0191 r:0.2787
ro_en Dev loss: 0.3969 r:0.8125
et_en Dev loss: 0.4712 r:0.6658
si_en Dev loss: 1.0109 r:0.5211
ne_en Dev loss: 0.6514 r:0.7082
ru_en Dev loss: 0.4690 r:0.7395
Current avg r:0.5545 Best avg r: 0.6087
08:17:18,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:18:35,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:20:05,271 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1353
en_de Dev loss: 0.9182 r:0.1582
en_zh Dev loss: 0.9594 r:0.2852
ro_en Dev loss: 0.3478 r:0.8212
et_en Dev loss: 0.4292 r:0.6870
si_en Dev loss: 0.8902 r:0.5376
ne_en Dev loss: 0.5147 r:0.7148
ru_en Dev loss: 0.4266 r:0.7518
Current avg r:0.5651 Best avg r: 0.6087
08:23:55,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:25:12,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:42,821 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1261
en_de Dev loss: 0.9207 r:0.1683
en_zh Dev loss: 0.9139 r:0.3036
ro_en Dev loss: 0.3352 r:0.8191
et_en Dev loss: 0.4261 r:0.6833
si_en Dev loss: 0.8493 r:0.5408
ne_en Dev loss: 0.5622 r:0.7181
ru_en Dev loss: 0.4199 r:0.7537
Current avg r:0.5696 Best avg r: 0.6087
08:30:33,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:31:50,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:33:20,726 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1260
en_de Dev loss: 0.9347 r:0.1608
en_zh Dev loss: 0.9349 r:0.3029
ro_en Dev loss: 0.3660 r:0.8167
et_en Dev loss: 0.4495 r:0.6820
si_en Dev loss: 0.8948 r:0.5452
ne_en Dev loss: 0.6403 r:0.7185
ru_en Dev loss: 0.4100 r:0.7585
Current avg r:0.5692 Best avg r: 0.6087
08:37:13,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:38:31,100 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:40:01,807 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1297
en_de Dev loss: 0.9793 r:0.1538
en_zh Dev loss: 0.9689 r:0.3168
ro_en Dev loss: 0.3707 r:0.8173
et_en Dev loss: 0.4557 r:0.6791
si_en Dev loss: 0.9460 r:0.5401
ne_en Dev loss: 0.5907 r:0.7179
ru_en Dev loss: 0.4575 r:0.7517
Current avg r:0.5681 Best avg r: 0.6087
08:43:54,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:45:12,236 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:46:43,30 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1295
en_de Dev loss: 0.9467 r:0.1471
en_zh Dev loss: 0.9000 r:0.3270
ro_en Dev loss: 0.3430 r:0.8158
et_en Dev loss: 0.4566 r:0.6778
si_en Dev loss: 0.9026 r:0.5302
ne_en Dev loss: 0.5351 r:0.7128
ru_en Dev loss: 0.4299 r:0.7441
Current avg r:0.5650 Best avg r: 0.6087
08:50:35,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:51:53,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:53:24,134 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1348
en_de Dev loss: 0.9461 r:0.1436
en_zh Dev loss: 0.9361 r:0.2983
ro_en Dev loss: 0.3409 r:0.8188
et_en Dev loss: 0.4471 r:0.6762
si_en Dev loss: 0.9327 r:0.5226
ne_en Dev loss: 0.5707 r:0.7163
ru_en Dev loss: 0.4404 r:0.7406
Current avg r:0.5595 Best avg r: 0.6087
08:57:17,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:58:34,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:00:04,769 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1176
en_de Dev loss: 0.9629 r:0.1668
en_zh Dev loss: 0.9690 r:0.3136
ro_en Dev loss: 0.3530 r:0.8210
et_en Dev loss: 0.4542 r:0.6774
si_en Dev loss: 0.9269 r:0.5381
ne_en Dev loss: 0.6357 r:0.7133
ru_en Dev loss: 0.4273 r:0.7614
Current avg r:0.5702 Best avg r: 0.6087
09:03:54,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:05:11,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:06:41,883 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1195
en_de Dev loss: 0.9368 r:0.1496
en_zh Dev loss: 0.8857 r:0.3188
ro_en Dev loss: 0.3177 r:0.8237
et_en Dev loss: 0.4340 r:0.6880
si_en Dev loss: 0.8030 r:0.5458
ne_en Dev loss: 0.5213 r:0.7142
ru_en Dev loss: 0.3947 r:0.7620
Current avg r:0.5717 Best avg r: 0.6087
09:10:32,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:11:49,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:13:19,271 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1187
en_de Dev loss: 0.9682 r:0.1491
en_zh Dev loss: 0.9531 r:0.3005
ro_en Dev loss: 0.3450 r:0.8216
et_en Dev loss: 0.4443 r:0.6772
si_en Dev loss: 0.9201 r:0.5284
ne_en Dev loss: 0.6095 r:0.7103
ru_en Dev loss: 0.4527 r:0.7425
Current avg r:0.5614 Best avg r: 0.6087
09:17:10,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:27,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:58,303 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1133
en_de Dev loss: 0.9853 r:0.1413
en_zh Dev loss: 0.9773 r:0.3051
ro_en Dev loss: 0.3621 r:0.8194
et_en Dev loss: 0.4501 r:0.6723
si_en Dev loss: 0.9214 r:0.5267
ne_en Dev loss: 0.5823 r:0.7143
ru_en Dev loss: 0.4738 r:0.7404
Current avg r:0.5599 Best avg r: 0.6087
09:23:49,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:07,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:37,517 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1183
en_de Dev loss: 0.9184 r:0.1684
en_zh Dev loss: 0.8842 r:0.3213
ro_en Dev loss: 0.3466 r:0.8190
et_en Dev loss: 0.4531 r:0.6634
si_en Dev loss: 0.9388 r:0.5292
ne_en Dev loss: 0.6528 r:0.7046
ru_en Dev loss: 0.4314 r:0.7419
Current avg r:0.5640 Best avg r: 0.6087
09:30:28,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:31:46,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:33:17,176 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1144
en_de Dev loss: 0.9386 r:0.1648
en_zh Dev loss: 0.9155 r:0.3181
ro_en Dev loss: 0.3443 r:0.8203
et_en Dev loss: 0.4671 r:0.6718
si_en Dev loss: 0.8831 r:0.5395
ne_en Dev loss: 0.5740 r:0.7108
ru_en Dev loss: 0.4135 r:0.7565
Current avg r:0.5688 Best avg r: 0.6087
09:37:07,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:38:24,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:39:54,692 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1130
en_de Dev loss: 0.9647 r:0.1471
en_zh Dev loss: 0.9491 r:0.3121
ro_en Dev loss: 0.3702 r:0.8195
et_en Dev loss: 0.4730 r:0.6592
si_en Dev loss: 0.9532 r:0.5293
ne_en Dev loss: 0.6160 r:0.7068
ru_en Dev loss: 0.4266 r:0.7572
Current avg r:0.5616 Best avg r: 0.6087
09:43:44,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:45:01,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:46:31,853 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1194
en_de Dev loss: 0.9547 r:0.1503
en_zh Dev loss: 0.8814 r:0.3221
ro_en Dev loss: 0.3320 r:0.8190
et_en Dev loss: 0.4738 r:0.6695
si_en Dev loss: 0.8217 r:0.5383
ne_en Dev loss: 0.5581 r:0.7149
ru_en Dev loss: 0.3918 r:0.7583
Current avg r:0.5675 Best avg r: 0.6087
09:50:21,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:51:38,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:53:08,479 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1251
en_de Dev loss: 1.0036 r:0.1305
en_zh Dev loss: 0.9650 r:0.3086
ro_en Dev loss: 0.3419 r:0.8201
et_en Dev loss: 0.4594 r:0.6629
si_en Dev loss: 0.8455 r:0.5367
ne_en Dev loss: 0.6128 r:0.7029
ru_en Dev loss: 0.4284 r:0.7487
Current avg r:0.5586 Best avg r: 0.6087
09:56:58,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:15,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:44,758 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1171
en_de Dev loss: 0.9453 r:0.1665
en_zh Dev loss: 0.9478 r:0.2987
ro_en Dev loss: 0.3575 r:0.8155
et_en Dev loss: 0.4940 r:0.6679
si_en Dev loss: 0.8969 r:0.5310
ne_en Dev loss: 0.5822 r:0.7073
ru_en Dev loss: 0.4300 r:0.7438
Current avg r:0.5615 Best avg r: 0.6087
10:03:34,466 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:51,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:21,41 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1149
en_de Dev loss: 0.9550 r:0.1597
en_zh Dev loss: 0.9416 r:0.3054
ro_en Dev loss: 0.3573 r:0.8135
et_en Dev loss: 0.4858 r:0.6674
si_en Dev loss: 0.8665 r:0.5351
ne_en Dev loss: 0.5571 r:0.7082
ru_en Dev loss: 0.4249 r:0.7485
Current avg r:0.5625 Best avg r: 0.6087
10:10:10,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:27,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:57,389 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1116
en_de Dev loss: 0.9153 r:0.1706
en_zh Dev loss: 0.8961 r:0.3097
ro_en Dev loss: 0.3247 r:0.8168
et_en Dev loss: 0.4509 r:0.6727
si_en Dev loss: 0.8273 r:0.5376
ne_en Dev loss: 0.5288 r:0.7088
ru_en Dev loss: 0.4053 r:0.7538
Current avg r:0.5672 Best avg r: 0.6087
10:16:47,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:04,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:33,770 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1136
en_de Dev loss: 0.9660 r:0.1564
en_zh Dev loss: 0.8971 r:0.3209
ro_en Dev loss: 0.3370 r:0.8179
et_en Dev loss: 0.4389 r:0.6811
si_en Dev loss: 0.8842 r:0.5369
ne_en Dev loss: 0.5841 r:0.7096
ru_en Dev loss: 0.3875 r:0.7646
Current avg r:0.5696 Best avg r: 0.6087
10:23:23,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:40,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:10,48 root INFO Epoch 11 Global steps: 107400 Train loss: 0.1130
en_de Dev loss: 0.9764 r:0.1461
en_zh Dev loss: 0.9526 r:0.2999
ro_en Dev loss: 0.3566 r:0.8134
et_en Dev loss: 0.4779 r:0.6717
si_en Dev loss: 0.8697 r:0.5337
ne_en Dev loss: 0.5826 r:0.7143
ru_en Dev loss: 0.4275 r:0.7473
Current avg r:0.5609 Best avg r: 0.6087
10:29:59,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:31:16,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
