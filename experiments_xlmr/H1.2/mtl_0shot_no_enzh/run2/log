14:41:50,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:16,153 root INFO 
id:ro_en cur r: 0.5121 best r: 0.5121
14:42:29,216 root INFO 
id:et_en cur r: 0.5098 best r: 0.5098
14:42:42,309 root INFO 
id:si_en cur r: 0.4213 best r: 0.4213
14:42:55,383 root INFO 
id:ne_en cur r: 0.5788 best r: 0.5788
14:43:08,376 root INFO 
id:ru_en cur r: 0.4655 best r: 0.4655
14:43:08,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:44:39,782 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
14:44:39,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:44:39,793 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:44:39,799 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
14:44:39,805 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
14:44:39,810 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:44:39,815 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:44:52,859 root INFO Epoch 0 Global steps: 600 Train loss: 0.8512
en_de Dev loss: 0.8935 r:0.0726
en_zh Dev loss: 0.8030 r:0.1993
ro_en Dev loss: 0.6562 r:0.5934
et_en Dev loss: 0.5485 r:0.5136
si_en Dev loss: 0.8047 r:0.4478
ne_en Dev loss: 0.5594 r:0.6077
ru_en Dev loss: 0.6565 r:0.4901
Current avg r:0.4178 Best avg r: 0.4178
14:48:47,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:00,756 root INFO 
id:en_de cur r: 0.0388 best r: 0.0388
14:49:13,826 root INFO 
id:ro_en cur r: 0.5622 best r: 0.5622
14:49:26,919 root INFO 
id:et_en cur r: 0.5989 best r: 0.5989
14:50:06,121 root INFO 
id:ru_en cur r: 0.6107 best r: 0.6107
14:50:06,122 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:37,657 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
14:51:37,667 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:51:37,673 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:51:37,678 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
14:51:37,683 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
14:51:37,691 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:51:37,697 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:51:50,735 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8001
en_de Dev loss: 0.9308 r:0.0882
en_zh Dev loss: 0.7638 r:0.2664
ro_en Dev loss: 0.6775 r:0.6713
et_en Dev loss: 0.5182 r:0.6079
si_en Dev loss: 0.7497 r:0.5034
ne_en Dev loss: 0.5453 r:0.6435
ru_en Dev loss: 0.6112 r:0.6315
Current avg r:0.4875 Best avg r: 0.4875
14:55:45,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:58,268 root INFO 
id:en_de cur r: 0.0853 best r: 0.0853
14:56:11,347 root INFO 
id:ro_en cur r: 0.6042 best r: 0.6042
14:56:50,598 root INFO 
id:ne_en cur r: 0.5796 best r: 0.5796
14:57:03,597 root INFO 
id:ru_en cur r: 0.6787 best r: 0.6787
14:57:03,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:34,983 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
14:58:34,990 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:58:34,996 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:58:35,2 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
14:58:35,8 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
14:58:35,16 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:58:35,21 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:58:48,72 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7753
en_de Dev loss: 0.9638 r:0.1129
en_zh Dev loss: 0.7572 r:0.2952
ro_en Dev loss: 0.6955 r:0.6717
et_en Dev loss: 0.5562 r:0.5983
si_en Dev loss: 0.8768 r:0.4995
ne_en Dev loss: 0.5619 r:0.6294
ru_en Dev loss: 0.6187 r:0.6915
Current avg r:0.4998 Best avg r: 0.4998
15:02:42,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:08,651 root INFO 
id:ro_en cur r: 0.6685 best r: 0.6685
15:03:21,726 root INFO 
id:et_en cur r: 0.6533 best r: 0.6533
15:03:47,909 root INFO 
id:ne_en cur r: 0.6220 best r: 0.6220
15:04:00,901 root INFO 
id:ru_en cur r: 0.7032 best r: 0.7032
15:04:00,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:32,320 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:05:32,329 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:05:32,333 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:05:32,338 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:05:32,344 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:05:32,350 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:05:32,355 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:05:45,393 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6800
en_de Dev loss: 0.9330 r:0.1275
en_zh Dev loss: 0.7411 r:0.3259
ro_en Dev loss: 0.5131 r:0.6987
et_en Dev loss: 0.4119 r:0.6670
si_en Dev loss: 0.6918 r:0.5187
ne_en Dev loss: 0.4722 r:0.6587
ru_en Dev loss: 0.4973 r:0.7232
Current avg r:0.5314 Best avg r: 0.5314
15:09:39,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:52,921 root INFO 
id:en_de cur r: 0.1121 best r: 0.1121
15:10:05,989 root INFO 
id:ro_en cur r: 0.6949 best r: 0.6949
15:10:32,170 root INFO 
id:si_en cur r: 0.4921 best r: 0.4921
15:10:45,276 root INFO 
id:ne_en cur r: 0.6600 best r: 0.6600
15:10:58,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:29,892 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:12:29,898 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:12:29,904 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:12:29,910 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:12:29,915 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:12:29,920 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:12:29,925 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:12:42,970 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6686
en_de Dev loss: 0.9978 r:0.1309
en_zh Dev loss: 0.7581 r:0.3334
ro_en Dev loss: 0.5818 r:0.7168
et_en Dev loss: 0.4354 r:0.6685
si_en Dev loss: 0.8154 r:0.5286
ne_en Dev loss: 0.4574 r:0.6803
ru_en Dev loss: 0.5979 r:0.7183
Current avg r:0.5396 Best avg r: 0.5396
15:16:37,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:50,422 root INFO 
id:en_de cur r: 0.1244 best r: 0.1244
15:17:03,498 root INFO 
id:ro_en cur r: 0.7151 best r: 0.7151
15:17:16,591 root INFO 
id:et_en cur r: 0.6875 best r: 0.6875
15:17:29,700 root INFO 
id:si_en cur r: 0.5147 best r: 0.5147
15:17:42,791 root INFO 
id:ne_en cur r: 0.6934 best r: 0.6934
15:17:55,788 root INFO 
id:ru_en cur r: 0.7041 best r: 0.7041
15:17:55,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:27,239 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:19:27,246 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:19:27,250 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:19:27,255 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:19:27,260 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:19:27,265 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:19:27,271 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:19:40,317 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6381
en_de Dev loss: 0.9411 r:0.1379
en_zh Dev loss: 0.7360 r:0.3432
ro_en Dev loss: 0.4900 r:0.7268
et_en Dev loss: 0.3838 r:0.7006
si_en Dev loss: 0.8107 r:0.5516
ne_en Dev loss: 0.4763 r:0.7028
ru_en Dev loss: 0.4896 r:0.7396
Current avg r:0.5575 Best avg r: 0.5575
15:23:34,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:47,910 root INFO 
id:en_de cur r: 0.1283 best r: 0.1283
15:24:00,986 root INFO 
id:ro_en cur r: 0.7410 best r: 0.7410
15:24:14,99 root INFO 
id:et_en cur r: 0.6951 best r: 0.6951
15:24:27,211 root INFO 
id:si_en cur r: 0.5412 best r: 0.5412
15:24:40,312 root INFO 
id:ne_en cur r: 0.7114 best r: 0.7114
15:24:53,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:24,787 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:26:24,794 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:26:24,810 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:26:24,816 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:26:24,821 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:26:24,826 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:26:24,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:26:37,886 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5973
en_de Dev loss: 0.9452 r:0.1331
en_zh Dev loss: 0.7426 r:0.3421
ro_en Dev loss: 0.4454 r:0.7522
et_en Dev loss: 0.3729 r:0.7077
si_en Dev loss: 0.7362 r:0.5699
ne_en Dev loss: 0.5088 r:0.7173
ru_en Dev loss: 0.4945 r:0.7365
Current avg r:0.5656 Best avg r: 0.5656
15:30:32,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:45,525 root INFO 
id:en_de cur r: 0.1286 best r: 0.1286
15:30:58,596 root INFO 
id:ro_en cur r: 0.7573 best r: 0.7573
15:31:11,688 root INFO 
id:et_en cur r: 0.7073 best r: 0.7073
15:31:24,796 root INFO 
id:si_en cur r: 0.5520 best r: 0.5520
15:31:50,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:22,382 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:33:22,389 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:33:22,394 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:33:22,400 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:33:22,405 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:33:22,410 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:33:22,414 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:33:35,484 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5525
en_de Dev loss: 0.9389 r:0.1377
en_zh Dev loss: 0.7514 r:0.3415
ro_en Dev loss: 0.4359 r:0.7663
et_en Dev loss: 0.3590 r:0.7167
si_en Dev loss: 0.7464 r:0.5736
ne_en Dev loss: 0.5136 r:0.7056
ru_en Dev loss: 0.4924 r:0.7341
Current avg r:0.5679 Best avg r: 0.5679
15:37:29,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:42,964 root INFO 
id:en_de cur r: 0.1666 best r: 0.1666
15:37:56,22 root INFO 
id:ro_en cur r: 0.7795 best r: 0.7795
15:38:09,111 root INFO 
id:et_en cur r: 0.7232 best r: 0.7232
15:38:22,207 root INFO 
id:si_en cur r: 0.5915 best r: 0.5915
15:38:35,308 root INFO 
id:ne_en cur r: 0.7354 best r: 0.7354
15:38:48,303 root INFO 
id:ru_en cur r: 0.7466 best r: 0.7466
15:38:48,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:19,717 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:40:19,723 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:40:19,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:40:19,733 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:40:19,738 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:40:19,742 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:40:19,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:40:32,801 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5858
en_de Dev loss: 0.9111 r:0.1591
en_zh Dev loss: 0.7231 r:0.3588
ro_en Dev loss: 0.3848 r:0.7882
et_en Dev loss: 0.3547 r:0.7242
si_en Dev loss: 0.6806 r:0.6005
ne_en Dev loss: 0.4603 r:0.7317
ru_en Dev loss: 0.3972 r:0.7568
Current avg r:0.5885 Best avg r: 0.5885
15:44:27,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:40,383 root INFO 
id:en_de cur r: 0.1835 best r: 0.1835
15:44:53,461 root INFO 
id:ro_en cur r: 0.7836 best r: 0.7836
15:45:45,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:17,208 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:47:17,215 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:47:17,219 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:47:17,224 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:47:17,229 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:47:17,235 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:47:17,240 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:47:30,299 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5758
en_de Dev loss: 0.8801 r:0.1780
en_zh Dev loss: 0.7251 r:0.3542
ro_en Dev loss: 0.3774 r:0.7925
et_en Dev loss: 0.3375 r:0.7277
si_en Dev loss: 0.6632 r:0.5940
ne_en Dev loss: 0.4804 r:0.7276
ru_en Dev loss: 0.4298 r:0.7521
Current avg r:0.5895 Best avg r: 0.5895
15:51:24,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:50,909 root INFO 
id:ro_en cur r: 0.7861 best r: 0.7861
15:52:30,193 root INFO 
id:ne_en cur r: 0.7356 best r: 0.7356
15:52:43,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:14,658 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5440
en_de Dev loss: 0.9058 r:0.1694
en_zh Dev loss: 0.7517 r:0.3518
ro_en Dev loss: 0.3871 r:0.7945
et_en Dev loss: 0.3575 r:0.7252
si_en Dev loss: 0.7718 r:0.5974
ne_en Dev loss: 0.4738 r:0.7313
ru_en Dev loss: 0.4805 r:0.7412
Current avg r:0.5873 Best avg r: 0.5895
15:58:09,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:35,352 root INFO 
id:ro_en cur r: 0.7934 best r: 0.7934
15:58:48,454 root INFO 
id:et_en cur r: 0.7268 best r: 0.7268
15:59:01,559 root INFO 
id:si_en cur r: 0.5935 best r: 0.5935
15:59:14,668 root INFO 
id:ne_en cur r: 0.7408 best r: 0.7408
15:59:27,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:59,154 root INFO Epoch 0 Global steps: 7200 Train loss: 0.4937
en_de Dev loss: 0.9048 r:0.1664
en_zh Dev loss: 0.7482 r:0.3439
ro_en Dev loss: 0.3560 r:0.7995
et_en Dev loss: 0.3427 r:0.7273
si_en Dev loss: 0.6634 r:0.6014
ne_en Dev loss: 0.4361 r:0.7336
ru_en Dev loss: 0.4464 r:0.7466
Current avg r:0.5884 Best avg r: 0.5895
16:04:53,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:19,913 root INFO 
id:ro_en cur r: 0.7954 best r: 0.7954
16:06:12,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:43,649 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5516
en_de Dev loss: 0.8826 r:0.1666
en_zh Dev loss: 0.7347 r:0.3518
ro_en Dev loss: 0.3504 r:0.7998
et_en Dev loss: 0.3468 r:0.7211
si_en Dev loss: 0.8169 r:0.5890
ne_en Dev loss: 0.5647 r:0.7282
ru_en Dev loss: 0.4405 r:0.7469
Current avg r:0.5862 Best avg r: 0.5895
16:11:38,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:04,344 root INFO 
id:ro_en cur r: 0.8013 best r: 0.8013
16:12:43,619 root INFO 
id:ne_en cur r: 0.7460 best r: 0.7460
16:12:56,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:28,81 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
16:14:28,87 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:14:28,92 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:14:28,97 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
16:14:28,103 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
16:14:28,108 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:14:28,112 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:14:41,171 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5175
en_de Dev loss: 0.8812 r:0.1662
en_zh Dev loss: 0.7276 r:0.3686
ro_en Dev loss: 0.3418 r:0.8034
et_en Dev loss: 0.3416 r:0.7266
si_en Dev loss: 0.6633 r:0.6027
ne_en Dev loss: 0.4484 r:0.7437
ru_en Dev loss: 0.4226 r:0.7519
Current avg r:0.5947 Best avg r: 0.5947
16:18:35,791 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:48,855 root INFO 
id:en_de cur r: 0.1896 best r: 0.1896
16:19:01,924 root INFO 
id:ro_en cur r: 0.8104 best r: 0.8104
16:19:28,107 root INFO 
id:si_en cur r: 0.6031 best r: 0.6031
16:19:41,195 root INFO 
id:ne_en cur r: 0.7604 best r: 0.7604
16:19:54,197 root INFO 
id:ru_en cur r: 0.7496 best r: 0.7496
16:19:54,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:25,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
16:21:25,720 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:21:25,725 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:21:25,730 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
16:21:25,734 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
16:21:25,740 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:21:25,744 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:21:38,783 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5492
en_de Dev loss: 0.8722 r:0.1896
en_zh Dev loss: 0.7178 r:0.3839
ro_en Dev loss: 0.3363 r:0.8093
et_en Dev loss: 0.3354 r:0.7316
si_en Dev loss: 0.6603 r:0.6112
ne_en Dev loss: 0.4100 r:0.7568
ru_en Dev loss: 0.4218 r:0.7581
Current avg r:0.6058 Best avg r: 0.6058
16:25:34,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:47,526 root INFO 
id:en_de cur r: 0.1909 best r: 0.1909
16:26:00,569 root INFO 
id:ro_en cur r: 0.8110 best r: 0.8110
16:26:13,657 root INFO 
id:et_en cur r: 0.7320 best r: 0.7320
16:26:26,767 root INFO 
id:si_en cur r: 0.6157 best r: 0.6157
16:26:52,864 root INFO 
id:ru_en cur r: 0.7662 best r: 0.7662
16:26:52,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:24,317 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
16:28:24,324 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:28:24,329 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:28:24,335 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
16:28:24,339 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
16:28:24,344 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:28:24,349 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:28:37,412 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5007
en_de Dev loss: 0.8655 r:0.1915
en_zh Dev loss: 0.7043 r:0.3931
ro_en Dev loss: 0.3145 r:0.8107
et_en Dev loss: 0.3347 r:0.7356
si_en Dev loss: 0.5447 r:0.6242
ne_en Dev loss: 0.3761 r:0.7603
ru_en Dev loss: 0.3666 r:0.7670
Current avg r:0.6118 Best avg r: 0.6118
16:32:32,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:37,436 root INFO 
id:ne_en cur r: 0.7632 best r: 0.7632
16:33:50,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:21,889 root INFO Epoch 1 Global steps: 10200 Train loss: 0.4978
en_de Dev loss: 0.8652 r:0.1888
en_zh Dev loss: 0.7140 r:0.3813
ro_en Dev loss: 0.3230 r:0.8098
et_en Dev loss: 0.3305 r:0.7352
si_en Dev loss: 0.5603 r:0.6171
ne_en Dev loss: 0.3516 r:0.7633
ru_en Dev loss: 0.3984 r:0.7563
Current avg r:0.6074 Best avg r: 0.6118
16:39:16,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:34,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:06,437 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5034
en_de Dev loss: 0.8853 r:0.1717
en_zh Dev loss: 0.7697 r:0.3725
ro_en Dev loss: 0.3760 r:0.8024
et_en Dev loss: 0.3599 r:0.7173
si_en Dev loss: 0.8121 r:0.5926
ne_en Dev loss: 0.5547 r:0.7359
ru_en Dev loss: 0.5039 r:0.7261
Current avg r:0.5884 Best avg r: 0.6118
16:46:01,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:27,201 root INFO 
id:ro_en cur r: 0.8152 best r: 0.8152
16:47:19,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:51,65 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4748
en_de Dev loss: 0.9062 r:0.1767
en_zh Dev loss: 0.7880 r:0.3717
ro_en Dev loss: 0.3534 r:0.8132
et_en Dev loss: 0.3556 r:0.7239
si_en Dev loss: 0.7856 r:0.6026
ne_en Dev loss: 0.5035 r:0.7467
ru_en Dev loss: 0.5005 r:0.7221
Current avg r:0.5938 Best avg r: 0.6118
16:52:45,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:04,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:35,832 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4671
en_de Dev loss: 0.8883 r:0.1676
en_zh Dev loss: 0.7611 r:0.3578
ro_en Dev loss: 0.3541 r:0.8074
et_en Dev loss: 0.3555 r:0.7218
si_en Dev loss: 0.7258 r:0.5973
ne_en Dev loss: 0.4702 r:0.7395
ru_en Dev loss: 0.4767 r:0.7267
Current avg r:0.5883 Best avg r: 0.6118
16:59:30,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:43,643 root INFO 
id:en_de cur r: 0.1925 best r: 0.1925
16:59:56,728 root INFO 
id:ro_en cur r: 0.8205 best r: 0.8205
17:00:22,942 root INFO 
id:si_en cur r: 0.6189 best r: 0.6189
17:00:36,59 root INFO 
id:ne_en cur r: 0.7658 best r: 0.7658
17:00:49,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:20,605 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4540
en_de Dev loss: 0.8907 r:0.1824
en_zh Dev loss: 0.7660 r:0.3760
ro_en Dev loss: 0.3308 r:0.8208
et_en Dev loss: 0.3427 r:0.7306
si_en Dev loss: 0.6629 r:0.6275
ne_en Dev loss: 0.4750 r:0.7581
ru_en Dev loss: 0.4373 r:0.7443
Current avg r:0.6057 Best avg r: 0.6118
17:06:15,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:28,400 root INFO 
id:en_de cur r: 0.1954 best r: 0.1954
17:06:41,465 root INFO 
id:ro_en cur r: 0.8209 best r: 0.8209
17:07:20,781 root INFO 
id:ne_en cur r: 0.7663 best r: 0.7663
17:07:33,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:05,309 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4510
en_de Dev loss: 0.8601 r:0.1841
en_zh Dev loss: 0.7260 r:0.3714
ro_en Dev loss: 0.2962 r:0.8197
et_en Dev loss: 0.3422 r:0.7260
si_en Dev loss: 0.6976 r:0.6133
ne_en Dev loss: 0.4193 r:0.7621
ru_en Dev loss: 0.3718 r:0.7616
Current avg r:0.6054 Best avg r: 0.6118
17:12:59,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:18,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:49,974 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4712
en_de Dev loss: 0.8633 r:0.1897
en_zh Dev loss: 0.7337 r:0.3683
ro_en Dev loss: 0.2958 r:0.8145
et_en Dev loss: 0.3543 r:0.7199
si_en Dev loss: 0.6062 r:0.6109
ne_en Dev loss: 0.3575 r:0.7606
ru_en Dev loss: 0.3867 r:0.7482
Current avg r:0.6017 Best avg r: 0.6118
17:19:44,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:03,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:34,721 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4286
en_de Dev loss: 0.8776 r:0.1569
en_zh Dev loss: 0.7792 r:0.3576
ro_en Dev loss: 0.3164 r:0.8173
et_en Dev loss: 0.3517 r:0.7204
si_en Dev loss: 0.6670 r:0.6153
ne_en Dev loss: 0.4172 r:0.7629
ru_en Dev loss: 0.4541 r:0.7240
Current avg r:0.5935 Best avg r: 0.6118
17:26:29,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:34,899 root INFO 
id:ne_en cur r: 0.7688 best r: 0.7688
17:27:47,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:19,459 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4485
en_de Dev loss: 0.8647 r:0.1716
en_zh Dev loss: 0.7284 r:0.3745
ro_en Dev loss: 0.3033 r:0.8127
et_en Dev loss: 0.3535 r:0.7175
si_en Dev loss: 0.6365 r:0.6021
ne_en Dev loss: 0.3843 r:0.7607
ru_en Dev loss: 0.3574 r:0.7610
Current avg r:0.6000 Best avg r: 0.6118
17:33:14,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:32,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:04,291 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4741
en_de Dev loss: 0.8798 r:0.1768
en_zh Dev loss: 0.7596 r:0.3741
ro_en Dev loss: 0.3205 r:0.8161
et_en Dev loss: 0.3587 r:0.7210
si_en Dev loss: 0.7274 r:0.6121
ne_en Dev loss: 0.3591 r:0.7653
ru_en Dev loss: 0.4326 r:0.7493
Current avg r:0.6021 Best avg r: 0.6118
17:39:59,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:25,211 root INFO 
id:ro_en cur r: 0.8214 best r: 0.8214
17:41:17,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:49,86 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4769
en_de Dev loss: 0.8693 r:0.1652
en_zh Dev loss: 0.7456 r:0.3726
ro_en Dev loss: 0.2991 r:0.8192
et_en Dev loss: 0.3401 r:0.7233
si_en Dev loss: 0.6842 r:0.6186
ne_en Dev loss: 0.4413 r:0.7607
ru_en Dev loss: 0.3691 r:0.7631
Current avg r:0.6033 Best avg r: 0.6118
17:46:43,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:02,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:33,871 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4643
en_de Dev loss: 0.8713 r:0.1748
en_zh Dev loss: 0.7576 r:0.3716
ro_en Dev loss: 0.3365 r:0.8084
et_en Dev loss: 0.3695 r:0.7064
si_en Dev loss: 0.7457 r:0.5990
ne_en Dev loss: 0.4947 r:0.7501
ru_en Dev loss: 0.4623 r:0.7260
Current avg r:0.5909 Best avg r: 0.6118
17:53:28,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:54,776 root INFO 
id:ro_en cur r: 0.8244 best r: 0.8244
17:54:20,977 root INFO 
id:si_en cur r: 0.6201 best r: 0.6201
17:54:34,92 root INFO 
id:ne_en cur r: 0.7709 best r: 0.7709
17:54:47,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:18,676 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4975
en_de Dev loss: 0.8920 r:0.1815
en_zh Dev loss: 0.7821 r:0.3828
ro_en Dev loss: 0.3341 r:0.8194
et_en Dev loss: 0.3654 r:0.7167
si_en Dev loss: 0.6929 r:0.6184
ne_en Dev loss: 0.4088 r:0.7658
ru_en Dev loss: 0.4540 r:0.7429
Current avg r:0.6039 Best avg r: 0.6118
18:00:13,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:26,418 root INFO 
id:en_de cur r: 0.2012 best r: 0.2012
18:00:39,485 root INFO 
id:ro_en cur r: 0.8256 best r: 0.8256
18:01:31,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:03,341 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4495
en_de Dev loss: 0.8583 r:0.1880
en_zh Dev loss: 0.7226 r:0.3746
ro_en Dev loss: 0.2954 r:0.8211
et_en Dev loss: 0.3573 r:0.7205
si_en Dev loss: 0.6378 r:0.6140
ne_en Dev loss: 0.3785 r:0.7602
ru_en Dev loss: 0.4342 r:0.7281
Current avg r:0.6009 Best avg r: 0.6118
18:06:59,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:25,663 root INFO 
id:ro_en cur r: 0.8286 best r: 0.8286
18:08:17,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:49,487 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4066
en_de Dev loss: 0.8711 r:0.1842
en_zh Dev loss: 0.7619 r:0.3755
ro_en Dev loss: 0.3046 r:0.8258
et_en Dev loss: 0.3444 r:0.7263
si_en Dev loss: 0.6713 r:0.6228
ne_en Dev loss: 0.4270 r:0.7645
ru_en Dev loss: 0.4187 r:0.7537
Current avg r:0.6076 Best avg r: 0.6118
18:13:44,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:57,304 root INFO 
id:en_de cur r: 0.2079 best r: 0.2079
18:15:02,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:34,244 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4103
en_de Dev loss: 0.8677 r:0.1982
en_zh Dev loss: 0.7414 r:0.3769
ro_en Dev loss: 0.3094 r:0.8184
et_en Dev loss: 0.3640 r:0.7195
si_en Dev loss: 0.6261 r:0.6135
ne_en Dev loss: 0.3678 r:0.7622
ru_en Dev loss: 0.3993 r:0.7529
Current avg r:0.6060 Best avg r: 0.6118
18:20:28,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:42,38 root INFO 
id:en_de cur r: 0.2090 best r: 0.2090
18:21:47,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:19,45 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4229
en_de Dev loss: 0.8635 r:0.1844
en_zh Dev loss: 0.7424 r:0.3663
ro_en Dev loss: 0.2881 r:0.8218
et_en Dev loss: 0.3611 r:0.7138
si_en Dev loss: 0.6431 r:0.6002
ne_en Dev loss: 0.3686 r:0.7623
ru_en Dev loss: 0.4219 r:0.7302
Current avg r:0.5970 Best avg r: 0.6118
18:27:13,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:26,898 root INFO 
id:en_de cur r: 0.2107 best r: 0.2107
18:28:32,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:03,858 root INFO Epoch 2 Global steps: 20400 Train loss: 0.3958
en_de Dev loss: 0.8581 r:0.1941
en_zh Dev loss: 0.7516 r:0.3790
ro_en Dev loss: 0.3178 r:0.8187
et_en Dev loss: 0.3662 r:0.7070
si_en Dev loss: 0.7377 r:0.5995
ne_en Dev loss: 0.5148 r:0.7562
ru_en Dev loss: 0.4231 r:0.7330
Current avg r:0.5982 Best avg r: 0.6118
18:33:58,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:11,639 root INFO 
id:en_de cur r: 0.2124 best r: 0.2124
18:35:17,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:48,637 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4190
en_de Dev loss: 0.8609 r:0.1969
en_zh Dev loss: 0.7537 r:0.3756
ro_en Dev loss: 0.3176 r:0.8228
et_en Dev loss: 0.3722 r:0.7201
si_en Dev loss: 0.6367 r:0.6176
ne_en Dev loss: 0.4218 r:0.7635
ru_en Dev loss: 0.3941 r:0.7547
Current avg r:0.6073 Best avg r: 0.6118
18:40:43,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:35,627 root INFO 
id:si_en cur r: 0.6275 best r: 0.6275
18:42:01,731 root INFO 
id:ru_en cur r: 0.7756 best r: 0.7756
18:42:01,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:33,242 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
18:43:33,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:43:33,256 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:43:33,261 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
18:43:33,267 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
18:43:33,272 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:43:33,277 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:43:46,350 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4143
en_de Dev loss: 0.8670 r:0.2056
en_zh Dev loss: 0.7434 r:0.3807
ro_en Dev loss: 0.2997 r:0.8242
et_en Dev loss: 0.3677 r:0.7256
si_en Dev loss: 0.6019 r:0.6291
ne_en Dev loss: 0.3637 r:0.7634
ru_en Dev loss: 0.3534 r:0.7785
Current avg r:0.6153 Best avg r: 0.6153
18:47:41,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:59,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:31,111 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4042
en_de Dev loss: 0.8702 r:0.1714
en_zh Dev loss: 0.7602 r:0.3690
ro_en Dev loss: 0.3009 r:0.8246
et_en Dev loss: 0.3812 r:0.7156
si_en Dev loss: 0.5964 r:0.6156
ne_en Dev loss: 0.3537 r:0.7637
ru_en Dev loss: 0.4071 r:0.7474
Current avg r:0.6011 Best avg r: 0.6153
18:54:25,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:44,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:15,898 root INFO Epoch 2 Global steps: 22800 Train loss: 0.3946
en_de Dev loss: 0.8684 r:0.1809
en_zh Dev loss: 0.7650 r:0.3684
ro_en Dev loss: 0.3127 r:0.8205
et_en Dev loss: 0.3642 r:0.7140
si_en Dev loss: 0.6298 r:0.6117
ne_en Dev loss: 0.3834 r:0.7661
ru_en Dev loss: 0.4079 r:0.7479
Current avg r:0.6014 Best avg r: 0.6153
19:01:10,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:23,571 root INFO 
id:en_de cur r: 0.2151 best r: 0.2151
19:02:29,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:00,827 root INFO Epoch 2 Global steps: 23400 Train loss: 0.3850
en_de Dev loss: 0.8874 r:0.2041
en_zh Dev loss: 0.8210 r:0.3644
ro_en Dev loss: 0.3395 r:0.8238
et_en Dev loss: 0.3841 r:0.7143
si_en Dev loss: 0.7610 r:0.6122
ne_en Dev loss: 0.4468 r:0.7639
ru_en Dev loss: 0.4049 r:0.7643
Current avg r:0.6067 Best avg r: 0.6153
19:07:56,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:15,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:47,21 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4047
en_de Dev loss: 0.8720 r:0.2013
en_zh Dev loss: 0.7251 r:0.3671
ro_en Dev loss: 0.3346 r:0.8188
et_en Dev loss: 0.4336 r:0.7150
si_en Dev loss: 0.5795 r:0.6160
ne_en Dev loss: 0.3480 r:0.7686
ru_en Dev loss: 0.3773 r:0.7681
Current avg r:0.6078 Best avg r: 0.6153
19:14:43,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:56,219 root INFO 
id:en_de cur r: 0.2217 best r: 0.2217
19:16:02,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:33,583 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4110
en_de Dev loss: 0.8705 r:0.2025
en_zh Dev loss: 0.8011 r:0.3527
ro_en Dev loss: 0.3496 r:0.8146
et_en Dev loss: 0.3802 r:0.7109
si_en Dev loss: 0.7412 r:0.5960
ne_en Dev loss: 0.4231 r:0.7598
ru_en Dev loss: 0.4500 r:0.7423
Current avg r:0.5970 Best avg r: 0.6153
19:21:28,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:46,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:18,377 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3615
en_de Dev loss: 0.8703 r:0.1988
en_zh Dev loss: 0.7896 r:0.3407
ro_en Dev loss: 0.3177 r:0.8182
et_en Dev loss: 0.3689 r:0.7108
si_en Dev loss: 0.6473 r:0.5972
ne_en Dev loss: 0.3854 r:0.7638
ru_en Dev loss: 0.4362 r:0.7336
Current avg r:0.5947 Best avg r: 0.6153
19:28:13,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:26,180 root INFO 
id:en_de cur r: 0.2461 best r: 0.2461
19:29:31,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:03,594 root INFO Epoch 2 Global steps: 25800 Train loss: 0.3956
en_de Dev loss: 0.8648 r:0.2167
en_zh Dev loss: 0.8198 r:0.3411
ro_en Dev loss: 0.3413 r:0.8115
et_en Dev loss: 0.3837 r:0.6964
si_en Dev loss: 0.8147 r:0.5892
ne_en Dev loss: 0.5597 r:0.7485
ru_en Dev loss: 0.4736 r:0.7172
Current avg r:0.5887 Best avg r: 0.6153
19:35:00,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:26,223 root INFO 
id:ro_en cur r: 0.8287 best r: 0.8287
19:36:18,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:50,219 root INFO Epoch 2 Global steps: 26400 Train loss: 0.3821
en_de Dev loss: 0.8530 r:0.2141
en_zh Dev loss: 0.7813 r:0.3482
ro_en Dev loss: 0.3144 r:0.8231
et_en Dev loss: 0.3810 r:0.7089
si_en Dev loss: 0.7194 r:0.6069
ne_en Dev loss: 0.4613 r:0.7612
ru_en Dev loss: 0.4056 r:0.7443
Current avg r:0.6010 Best avg r: 0.6153
19:41:45,77 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:03,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:35,137 root INFO Epoch 2 Global steps: 27000 Train loss: 0.3872
en_de Dev loss: 0.8692 r:0.1940
en_zh Dev loss: 0.8101 r:0.3540
ro_en Dev loss: 0.3234 r:0.8256
et_en Dev loss: 0.3776 r:0.7060
si_en Dev loss: 0.6998 r:0.6064
ne_en Dev loss: 0.4676 r:0.7557
ru_en Dev loss: 0.4511 r:0.7289
Current avg r:0.5958 Best avg r: 0.6153
19:48:31,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:49,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:21,215 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3379
en_de Dev loss: 0.8759 r:0.1859
en_zh Dev loss: 0.8080 r:0.3502
ro_en Dev loss: 0.3387 r:0.8212
et_en Dev loss: 0.3992 r:0.7035
si_en Dev loss: 0.7001 r:0.6052
ne_en Dev loss: 0.4391 r:0.7516
ru_en Dev loss: 0.4196 r:0.7382
Current avg r:0.5937 Best avg r: 0.6153
19:55:15,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:34,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:06,89 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3577
en_de Dev loss: 0.8593 r:0.2092
en_zh Dev loss: 0.7913 r:0.3621
ro_en Dev loss: 0.3183 r:0.8243
et_en Dev loss: 0.4058 r:0.7077
si_en Dev loss: 0.6691 r:0.6163
ne_en Dev loss: 0.3946 r:0.7522
ru_en Dev loss: 0.4059 r:0.7515
Current avg r:0.6033 Best avg r: 0.6153
20:02:00,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:19,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:50,989 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3762
en_de Dev loss: 0.8744 r:0.1853
en_zh Dev loss: 0.8142 r:0.3531
ro_en Dev loss: 0.3315 r:0.8219
et_en Dev loss: 0.3875 r:0.6963
si_en Dev loss: 0.7692 r:0.6016
ne_en Dev loss: 0.5454 r:0.7458
ru_en Dev loss: 0.4576 r:0.7253
Current avg r:0.5899 Best avg r: 0.6153
20:08:45,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:10:04,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:35,794 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3546
en_de Dev loss: 0.8510 r:0.2163
en_zh Dev loss: 0.7556 r:0.3518
ro_en Dev loss: 0.3116 r:0.8214
et_en Dev loss: 0.4065 r:0.7082
si_en Dev loss: 0.6598 r:0.6062
ne_en Dev loss: 0.4044 r:0.7498
ru_en Dev loss: 0.4299 r:0.7269
Current avg r:0.5972 Best avg r: 0.6153
20:15:30,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:48,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:20,560 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3383
en_de Dev loss: 0.8643 r:0.2018
en_zh Dev loss: 0.7797 r:0.3521
ro_en Dev loss: 0.3004 r:0.8226
et_en Dev loss: 0.3885 r:0.7064
si_en Dev loss: 0.6624 r:0.6030
ne_en Dev loss: 0.4124 r:0.7539
ru_en Dev loss: 0.4029 r:0.7430
Current avg r:0.5976 Best avg r: 0.6153
20:22:15,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:33,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:05,384 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3371
en_de Dev loss: 0.8780 r:0.2003
en_zh Dev loss: 0.8089 r:0.3416
ro_en Dev loss: 0.3224 r:0.8177
et_en Dev loss: 0.3763 r:0.7004
si_en Dev loss: 0.6895 r:0.5992
ne_en Dev loss: 0.4713 r:0.7439
ru_en Dev loss: 0.4411 r:0.7268
Current avg r:0.5900 Best avg r: 0.6153
20:29:00,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:18,688 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:50,332 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3332
en_de Dev loss: 0.8743 r:0.1754
en_zh Dev loss: 0.8530 r:0.3288
ro_en Dev loss: 0.3958 r:0.8221
et_en Dev loss: 0.3982 r:0.6980
si_en Dev loss: 0.8840 r:0.5898
ne_en Dev loss: 0.5624 r:0.7348
ru_en Dev loss: 0.4597 r:0.7292
Current avg r:0.5826 Best avg r: 0.6153
20:35:45,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:03,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:35,333 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3124
en_de Dev loss: 0.8663 r:0.1769
en_zh Dev loss: 0.7542 r:0.3402
ro_en Dev loss: 0.2946 r:0.8237
et_en Dev loss: 0.4148 r:0.7092
si_en Dev loss: 0.5593 r:0.6174
ne_en Dev loss: 0.3860 r:0.7466
ru_en Dev loss: 0.3653 r:0.7528
Current avg r:0.5953 Best avg r: 0.6153
20:42:31,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:49,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:21,285 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3267
en_de Dev loss: 0.8694 r:0.1648
en_zh Dev loss: 0.8471 r:0.3190
ro_en Dev loss: 0.3404 r:0.8145
et_en Dev loss: 0.3927 r:0.6879
si_en Dev loss: 0.8347 r:0.5836
ne_en Dev loss: 0.5818 r:0.7459
ru_en Dev loss: 0.4496 r:0.7226
Current avg r:0.5769 Best avg r: 0.6153
20:49:16,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:34,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:06,198 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3298
en_de Dev loss: 0.8703 r:0.1777
en_zh Dev loss: 0.8190 r:0.3281
ro_en Dev loss: 0.3226 r:0.8196
et_en Dev loss: 0.3976 r:0.6867
si_en Dev loss: 0.7005 r:0.5957
ne_en Dev loss: 0.4994 r:0.7462
ru_en Dev loss: 0.4500 r:0.7235
Current avg r:0.5825 Best avg r: 0.6153
20:56:01,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:27,171 root INFO 
id:ro_en cur r: 0.8288 best r: 0.8288
20:57:19,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:51,137 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3375
en_de Dev loss: 0.8662 r:0.1915
en_zh Dev loss: 0.7965 r:0.3279
ro_en Dev loss: 0.3095 r:0.8250
et_en Dev loss: 0.4299 r:0.6965
si_en Dev loss: 0.6302 r:0.6046
ne_en Dev loss: 0.4165 r:0.7508
ru_en Dev loss: 0.3876 r:0.7533
Current avg r:0.5928 Best avg r: 0.6153
21:02:45,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:04,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:36,20 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3495
en_de Dev loss: 0.8896 r:0.1851
en_zh Dev loss: 0.8564 r:0.3090
ro_en Dev loss: 0.3321 r:0.8224
et_en Dev loss: 0.4245 r:0.6980
si_en Dev loss: 0.7151 r:0.5938
ne_en Dev loss: 0.4113 r:0.7480
ru_en Dev loss: 0.4344 r:0.7427
Current avg r:0.5856 Best avg r: 0.6153
21:09:30,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:49,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:12:20,912 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3083
en_de Dev loss: 0.8747 r:0.1963
en_zh Dev loss: 0.8460 r:0.3040
ro_en Dev loss: 0.3127 r:0.8242
et_en Dev loss: 0.3872 r:0.7001
si_en Dev loss: 0.6886 r:0.6006
ne_en Dev loss: 0.4069 r:0.7619
ru_en Dev loss: 0.4382 r:0.7334
Current avg r:0.5886 Best avg r: 0.6153
21:16:15,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:34,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:05,911 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3312
en_de Dev loss: 0.8802 r:0.1738
en_zh Dev loss: 0.8509 r:0.3078
ro_en Dev loss: 0.3250 r:0.8234
et_en Dev loss: 0.3936 r:0.6932
si_en Dev loss: 0.8294 r:0.5845
ne_en Dev loss: 0.4684 r:0.7512
ru_en Dev loss: 0.4545 r:0.7279
Current avg r:0.5803 Best avg r: 0.6153
21:23:00,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:26,830 root INFO 
id:ro_en cur r: 0.8290 best r: 0.8290
21:24:19,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:50,813 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3208
en_de Dev loss: 0.8736 r:0.1990
en_zh Dev loss: 0.8482 r:0.3121
ro_en Dev loss: 0.3426 r:0.8262
et_en Dev loss: 0.4289 r:0.6993
si_en Dev loss: 0.8019 r:0.5898
ne_en Dev loss: 0.4469 r:0.7458
ru_en Dev loss: 0.4358 r:0.7431
Current avg r:0.5879 Best avg r: 0.6153
21:29:46,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:05,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:37,68 root INFO Epoch 4 Global steps: 36600 Train loss: 0.2918
en_de Dev loss: 0.8682 r:0.2150
en_zh Dev loss: 0.8100 r:0.3310
ro_en Dev loss: 0.3307 r:0.8251
et_en Dev loss: 0.3945 r:0.6937
si_en Dev loss: 0.8338 r:0.5898
ne_en Dev loss: 0.5334 r:0.7482
ru_en Dev loss: 0.4160 r:0.7474
Current avg r:0.5929 Best avg r: 0.6153
21:36:32,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:51,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:23,184 root INFO Epoch 4 Global steps: 37200 Train loss: 0.2820
en_de Dev loss: 0.8712 r:0.1945
en_zh Dev loss: 0.8224 r:0.3082
ro_en Dev loss: 0.3088 r:0.8211
et_en Dev loss: 0.4047 r:0.6991
si_en Dev loss: 0.6548 r:0.5980
ne_en Dev loss: 0.4046 r:0.7500
ru_en Dev loss: 0.4176 r:0.7344
Current avg r:0.5865 Best avg r: 0.6153
21:43:18,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:36,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:08,145 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3004
en_de Dev loss: 0.8674 r:0.2011
en_zh Dev loss: 0.8452 r:0.3024
ro_en Dev loss: 0.3175 r:0.8234
et_en Dev loss: 0.4155 r:0.6935
si_en Dev loss: 0.6687 r:0.5883
ne_en Dev loss: 0.4060 r:0.7464
ru_en Dev loss: 0.4164 r:0.7387
Current avg r:0.5848 Best avg r: 0.6153
21:50:02,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:21,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:53,103 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3117
en_de Dev loss: 0.8740 r:0.2045
en_zh Dev loss: 0.8564 r:0.3128
ro_en Dev loss: 0.3604 r:0.8193
et_en Dev loss: 0.4420 r:0.6866
si_en Dev loss: 0.8494 r:0.5790
ne_en Dev loss: 0.4896 r:0.7335
ru_en Dev loss: 0.4558 r:0.7332
Current avg r:0.5813 Best avg r: 0.6153
21:56:48,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:06,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:38,466 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3036
en_de Dev loss: 0.8602 r:0.1993
en_zh Dev loss: 0.8098 r:0.3137
ro_en Dev loss: 0.2997 r:0.8252
et_en Dev loss: 0.3934 r:0.6886
si_en Dev loss: 0.7544 r:0.5885
ne_en Dev loss: 0.4620 r:0.7442
ru_en Dev loss: 0.4365 r:0.7217
Current avg r:0.5830 Best avg r: 0.6153
22:03:33,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:51,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:23,410 root INFO Epoch 4 Global steps: 39600 Train loss: 0.2783
en_de Dev loss: 0.9027 r:0.1683
en_zh Dev loss: 0.8999 r:0.2947
ro_en Dev loss: 0.3393 r:0.8246
et_en Dev loss: 0.4139 r:0.6912
si_en Dev loss: 0.8109 r:0.5743
ne_en Dev loss: 0.4635 r:0.7360
ru_en Dev loss: 0.4731 r:0.7251
Current avg r:0.5735 Best avg r: 0.6153
22:10:18,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:44,982 root INFO 
id:ro_en cur r: 0.8306 best r: 0.8306
22:11:37,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:08,944 root INFO Epoch 4 Global steps: 40200 Train loss: 0.2889
en_de Dev loss: 0.8639 r:0.2099
en_zh Dev loss: 0.8536 r:0.3092
ro_en Dev loss: 0.3267 r:0.8259
et_en Dev loss: 0.4169 r:0.6966
si_en Dev loss: 0.7669 r:0.5908
ne_en Dev loss: 0.4197 r:0.7420
ru_en Dev loss: 0.4500 r:0.7304
Current avg r:0.5864 Best avg r: 0.6153
22:17:03,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:22,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:53,773 root INFO Epoch 4 Global steps: 40800 Train loss: 0.2787
en_de Dev loss: 0.8694 r:0.1838
en_zh Dev loss: 0.8540 r:0.3050
ro_en Dev loss: 0.3436 r:0.8220
et_en Dev loss: 0.4071 r:0.6859
si_en Dev loss: 0.7813 r:0.5808
ne_en Dev loss: 0.4890 r:0.7290
ru_en Dev loss: 0.4372 r:0.7305
Current avg r:0.5767 Best avg r: 0.6153
22:23:48,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:07,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:38,623 root INFO Epoch 4 Global steps: 41400 Train loss: 0.2878
en_de Dev loss: 0.8705 r:0.2105
en_zh Dev loss: 0.8577 r:0.3150
ro_en Dev loss: 0.3422 r:0.8203
et_en Dev loss: 0.4368 r:0.6908
si_en Dev loss: 0.7240 r:0.5822
ne_en Dev loss: 0.4733 r:0.7310
ru_en Dev loss: 0.4184 r:0.7473
Current avg r:0.5853 Best avg r: 0.6153
22:30:33,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:51,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:33:23,522 root INFO Epoch 4 Global steps: 42000 Train loss: 0.2969
en_de Dev loss: 0.8730 r:0.1815
en_zh Dev loss: 0.8431 r:0.2960
ro_en Dev loss: 0.3146 r:0.8268
et_en Dev loss: 0.4170 r:0.6953
si_en Dev loss: 0.7049 r:0.5825
ne_en Dev loss: 0.4838 r:0.7217
ru_en Dev loss: 0.3994 r:0.7493
Current avg r:0.5790 Best avg r: 0.6153
22:37:18,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:36,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:08,460 root INFO Epoch 4 Global steps: 42600 Train loss: 0.2788
en_de Dev loss: 0.8813 r:0.1790
en_zh Dev loss: 0.8528 r:0.2926
ro_en Dev loss: 0.3282 r:0.8184
et_en Dev loss: 0.4337 r:0.6850
si_en Dev loss: 0.7417 r:0.5764
ne_en Dev loss: 0.4670 r:0.7326
ru_en Dev loss: 0.4439 r:0.7249
Current avg r:0.5727 Best avg r: 0.6153
22:44:03,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:45:22,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:54,528 root INFO Epoch 4 Global steps: 43200 Train loss: 0.2563
en_de Dev loss: 0.8804 r:0.1876
en_zh Dev loss: 0.8792 r:0.2779
ro_en Dev loss: 0.3354 r:0.8131
et_en Dev loss: 0.4259 r:0.6730
si_en Dev loss: 0.9239 r:0.5483
ne_en Dev loss: 0.5711 r:0.7188
ru_en Dev loss: 0.4957 r:0.6994
Current avg r:0.5597 Best avg r: 0.6153
22:50:49,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:07,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:38,893 root INFO Epoch 4 Global steps: 43800 Train loss: 0.2813
en_de Dev loss: 0.9033 r:0.1943
en_zh Dev loss: 0.9035 r:0.2958
ro_en Dev loss: 0.3306 r:0.8257
et_en Dev loss: 0.4083 r:0.6999
si_en Dev loss: 0.8216 r:0.5838
ne_en Dev loss: 0.4956 r:0.7318
ru_en Dev loss: 0.4537 r:0.7412
Current avg r:0.5818 Best avg r: 0.6153
22:57:32,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:51,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:22,407 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2664
en_de Dev loss: 0.8942 r:0.1817
en_zh Dev loss: 0.8798 r:0.2941
ro_en Dev loss: 0.3365 r:0.8218
et_en Dev loss: 0.4412 r:0.6854
si_en Dev loss: 0.8094 r:0.5752
ne_en Dev loss: 0.5215 r:0.7282
ru_en Dev loss: 0.4665 r:0.7147
Current avg r:0.5716 Best avg r: 0.6153
23:04:16,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:34,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:05,792 root INFO Epoch 4 Global steps: 45000 Train loss: 0.2745
en_de Dev loss: 0.8784 r:0.1862
en_zh Dev loss: 0.8245 r:0.3033
ro_en Dev loss: 0.3183 r:0.8213
et_en Dev loss: 0.4372 r:0.6891
si_en Dev loss: 0.7003 r:0.5759
ne_en Dev loss: 0.4338 r:0.7350
ru_en Dev loss: 0.4047 r:0.7377
Current avg r:0.5784 Best avg r: 0.6153
23:11:01,6 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:12:19,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:51,328 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2387
en_de Dev loss: 0.8706 r:0.2158
en_zh Dev loss: 0.8884 r:0.3006
ro_en Dev loss: 0.3681 r:0.8156
et_en Dev loss: 0.4626 r:0.6641
si_en Dev loss: 0.8934 r:0.5531
ne_en Dev loss: 0.5738 r:0.7217
ru_en Dev loss: 0.4791 r:0.7205
Current avg r:0.5702 Best avg r: 0.6153
23:17:44,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:02,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:34,173 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2361
en_de Dev loss: 0.8609 r:0.2261
en_zh Dev loss: 0.8914 r:0.2820
ro_en Dev loss: 0.3374 r:0.8195
et_en Dev loss: 0.4458 r:0.6683
si_en Dev loss: 0.8334 r:0.5632
ne_en Dev loss: 0.5571 r:0.7210
ru_en Dev loss: 0.5023 r:0.7006
Current avg r:0.5687 Best avg r: 0.6153
23:24:27,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:45,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:16,830 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2375
en_de Dev loss: 0.8442 r:0.2433
en_zh Dev loss: 0.8434 r:0.3036
ro_en Dev loss: 0.3106 r:0.8263
et_en Dev loss: 0.4491 r:0.6817
si_en Dev loss: 0.7431 r:0.5765
ne_en Dev loss: 0.4623 r:0.7255
ru_en Dev loss: 0.4027 r:0.7444
Current avg r:0.5859 Best avg r: 0.6153
23:31:10,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:28,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:59,414 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2538
en_de Dev loss: 0.8711 r:0.2041
en_zh Dev loss: 0.8524 r:0.3016
ro_en Dev loss: 0.3040 r:0.8271
et_en Dev loss: 0.4259 r:0.6936
si_en Dev loss: 0.6931 r:0.5841
ne_en Dev loss: 0.4671 r:0.7187
ru_en Dev loss: 0.4042 r:0.7438
Current avg r:0.5819 Best avg r: 0.6153
23:37:52,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:10,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:42,2 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2518
en_de Dev loss: 0.8923 r:0.1897
en_zh Dev loss: 0.9155 r:0.2740
ro_en Dev loss: 0.3349 r:0.8259
et_en Dev loss: 0.4343 r:0.6885
si_en Dev loss: 0.7487 r:0.5751
ne_en Dev loss: 0.5164 r:0.7223
ru_en Dev loss: 0.4530 r:0.7265
Current avg r:0.5717 Best avg r: 0.6153
23:44:35,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:53,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:47:24,663 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2502
en_de Dev loss: 0.9022 r:0.1965
en_zh Dev loss: 0.9317 r:0.2795
ro_en Dev loss: 0.3515 r:0.8252
et_en Dev loss: 0.4462 r:0.6863
si_en Dev loss: 0.8722 r:0.5598
ne_en Dev loss: 0.5441 r:0.7195
ru_en Dev loss: 0.4749 r:0.7263
Current avg r:0.5704 Best avg r: 0.6153
23:51:17,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:36,138 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:54:07,367 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2407
en_de Dev loss: 0.9042 r:0.1820
en_zh Dev loss: 0.9586 r:0.2788
ro_en Dev loss: 0.3749 r:0.8211
et_en Dev loss: 0.4345 r:0.6821
si_en Dev loss: 1.0278 r:0.5510
ne_en Dev loss: 0.6361 r:0.7158
ru_en Dev loss: 0.5286 r:0.7080
Current avg r:0.5627 Best avg r: 0.6153
23:58:00,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:26,632 root INFO 
id:ro_en cur r: 0.8307 best r: 0.8307
23:59:18,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:50,15 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2291
en_de Dev loss: 0.8837 r:0.1571
en_zh Dev loss: 0.8441 r:0.3060
ro_en Dev loss: 0.3137 r:0.8293
et_en Dev loss: 0.4234 r:0.6960
si_en Dev loss: 0.7413 r:0.5723
ne_en Dev loss: 0.4485 r:0.7261
ru_en Dev loss: 0.4071 r:0.7476
Current avg r:0.5763 Best avg r: 0.6153
00:04:43,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:06:01,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:32,707 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2383
en_de Dev loss: 0.9016 r:0.1785
en_zh Dev loss: 0.8693 r:0.3034
ro_en Dev loss: 0.3387 r:0.8231
et_en Dev loss: 0.4587 r:0.7003
si_en Dev loss: 0.7445 r:0.5736
ne_en Dev loss: 0.4831 r:0.7232
ru_en Dev loss: 0.3936 r:0.7551
Current avg r:0.5796 Best avg r: 0.6153
00:11:25,916 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:12:44,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:15,341 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2354
en_de Dev loss: 0.8765 r:0.1786
en_zh Dev loss: 0.8491 r:0.2999
ro_en Dev loss: 0.3296 r:0.8212
et_en Dev loss: 0.4149 r:0.6856
si_en Dev loss: 0.7931 r:0.5643
ne_en Dev loss: 0.4771 r:0.7250
ru_en Dev loss: 0.4287 r:0.7279
Current avg r:0.5718 Best avg r: 0.6153
00:18:08,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:26,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:58,83 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2262
en_de Dev loss: 0.8979 r:0.1716
en_zh Dev loss: 0.8682 r:0.2921
ro_en Dev loss: 0.3227 r:0.8247
et_en Dev loss: 0.4211 r:0.6927
si_en Dev loss: 0.7402 r:0.5731
ne_en Dev loss: 0.4532 r:0.7214
ru_en Dev loss: 0.4125 r:0.7419
Current avg r:0.5739 Best avg r: 0.6153
00:24:51,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:09,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:40,832 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2351
en_de Dev loss: 0.9006 r:0.1860
en_zh Dev loss: 0.8708 r:0.3006
ro_en Dev loss: 0.3444 r:0.8181
et_en Dev loss: 0.4289 r:0.6811
si_en Dev loss: 0.8484 r:0.5472
ne_en Dev loss: 0.4971 r:0.7154
ru_en Dev loss: 0.4650 r:0.7223
Current avg r:0.5672 Best avg r: 0.6153
00:31:34,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:32:52,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:23,574 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2410
en_de Dev loss: 0.9226 r:0.1893
en_zh Dev loss: 0.9584 r:0.2782
ro_en Dev loss: 0.3838 r:0.8204
et_en Dev loss: 0.4430 r:0.6826
si_en Dev loss: 0.8960 r:0.5571
ne_en Dev loss: 0.5711 r:0.7184
ru_en Dev loss: 0.4637 r:0.7402
Current avg r:0.5694 Best avg r: 0.6153
00:38:16,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:39:35,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:06,356 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2305
en_de Dev loss: 0.8931 r:0.1945
en_zh Dev loss: 0.9003 r:0.2932
ro_en Dev loss: 0.3418 r:0.8237
et_en Dev loss: 0.4389 r:0.6754
si_en Dev loss: 0.8630 r:0.5549
ne_en Dev loss: 0.5131 r:0.7189
ru_en Dev loss: 0.4800 r:0.7190
Current avg r:0.5685 Best avg r: 0.6153
00:44:59,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:17,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:49,84 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2379
en_de Dev loss: 0.9377 r:0.1626
en_zh Dev loss: 0.9665 r:0.2764
ro_en Dev loss: 0.4080 r:0.8219
et_en Dev loss: 0.4307 r:0.6799
si_en Dev loss: 0.9639 r:0.5539
ne_en Dev loss: 0.6069 r:0.7192
ru_en Dev loss: 0.5448 r:0.7069
Current avg r:0.5601 Best avg r: 0.6153
00:51:43,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:01,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:33,115 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2080
en_de Dev loss: 0.8985 r:0.1899
en_zh Dev loss: 0.8703 r:0.3012
ro_en Dev loss: 0.3397 r:0.8264
et_en Dev loss: 0.4435 r:0.6846
si_en Dev loss: 0.8138 r:0.5691
ne_en Dev loss: 0.5065 r:0.7211
ru_en Dev loss: 0.4251 r:0.7441
Current avg r:0.5766 Best avg r: 0.6153
00:58:26,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:59:44,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:15,838 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2142
en_de Dev loss: 0.9182 r:0.1650
en_zh Dev loss: 0.9215 r:0.2803
ro_en Dev loss: 0.3500 r:0.8223
et_en Dev loss: 0.4616 r:0.6768
si_en Dev loss: 0.8493 r:0.5575
ne_en Dev loss: 0.4952 r:0.7204
ru_en Dev loss: 0.4686 r:0.7254
Current avg r:0.5639 Best avg r: 0.6153
01:05:09,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:27,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:58,548 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2107
en_de Dev loss: 0.9202 r:0.1680
en_zh Dev loss: 0.9094 r:0.2836
ro_en Dev loss: 0.3486 r:0.8242
et_en Dev loss: 0.4698 r:0.6821
si_en Dev loss: 0.8215 r:0.5649
ne_en Dev loss: 0.4888 r:0.7196
ru_en Dev loss: 0.4499 r:0.7315
Current avg r:0.5677 Best avg r: 0.6153
01:11:51,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:10,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:41,354 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2046
en_de Dev loss: 0.9052 r:0.1508
en_zh Dev loss: 0.8677 r:0.2928
ro_en Dev loss: 0.3304 r:0.8272
et_en Dev loss: 0.4319 r:0.6861
si_en Dev loss: 0.8011 r:0.5646
ne_en Dev loss: 0.4975 r:0.7231
ru_en Dev loss: 0.4144 r:0.7390
Current avg r:0.5691 Best avg r: 0.6153
01:18:35,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:53,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:21:24,827 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2122
en_de Dev loss: 0.9224 r:0.1644
en_zh Dev loss: 0.9156 r:0.2902
ro_en Dev loss: 0.3395 r:0.8286
et_en Dev loss: 0.4250 r:0.6894
si_en Dev loss: 0.7911 r:0.5641
ne_en Dev loss: 0.5004 r:0.7186
ru_en Dev loss: 0.4376 r:0.7444
Current avg r:0.5714 Best avg r: 0.6153
01:25:18,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:26:36,729 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:07,931 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2087
en_de Dev loss: 0.9274 r:0.1607
en_zh Dev loss: 0.9422 r:0.2796
ro_en Dev loss: 0.3553 r:0.8250
et_en Dev loss: 0.4589 r:0.6815
si_en Dev loss: 0.8946 r:0.5560
ne_en Dev loss: 0.5693 r:0.7131
ru_en Dev loss: 0.4726 r:0.7286
Current avg r:0.5635 Best avg r: 0.6153
01:32:01,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:33:19,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:50,753 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2130
en_de Dev loss: 0.8859 r:0.1664
en_zh Dev loss: 0.8801 r:0.2847
ro_en Dev loss: 0.3353 r:0.8211
et_en Dev loss: 0.4127 r:0.6771
si_en Dev loss: 0.8607 r:0.5533
ne_en Dev loss: 0.5736 r:0.7120
ru_en Dev loss: 0.4867 r:0.7126
Current avg r:0.5610 Best avg r: 0.6153
01:38:44,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:40:02,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:41:33,577 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2086
en_de Dev loss: 0.8873 r:0.1740
en_zh Dev loss: 0.8375 r:0.2947
ro_en Dev loss: 0.3076 r:0.8269
et_en Dev loss: 0.4214 r:0.6875
si_en Dev loss: 0.7921 r:0.5598
ne_en Dev loss: 0.5131 r:0.7152
ru_en Dev loss: 0.4283 r:0.7268
Current avg r:0.5693 Best avg r: 0.6153
01:45:26,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:46:45,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:48:16,356 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2060
en_de Dev loss: 0.9117 r:0.1762
en_zh Dev loss: 0.9147 r:0.2954
ro_en Dev loss: 0.3638 r:0.8218
et_en Dev loss: 0.4499 r:0.6781
si_en Dev loss: 0.9190 r:0.5459
ne_en Dev loss: 0.5567 r:0.7157
ru_en Dev loss: 0.4656 r:0.7268
Current avg r:0.5657 Best avg r: 0.6153
01:52:09,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:53:27,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:54:59,325 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2005
en_de Dev loss: 0.9068 r:0.1821
en_zh Dev loss: 0.8807 r:0.3001
ro_en Dev loss: 0.3348 r:0.8263
et_en Dev loss: 0.4415 r:0.6798
si_en Dev loss: 0.8054 r:0.5579
ne_en Dev loss: 0.5336 r:0.7124
ru_en Dev loss: 0.4342 r:0.7372
Current avg r:0.5708 Best avg r: 0.6153
01:58:54,791 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:00:14,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:01:46,749 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2046
en_de Dev loss: 0.9353 r:0.1684
en_zh Dev loss: 0.9090 r:0.3037
ro_en Dev loss: 0.3398 r:0.8283
et_en Dev loss: 0.4426 r:0.6797
si_en Dev loss: 0.8077 r:0.5639
ne_en Dev loss: 0.5328 r:0.7151
ru_en Dev loss: 0.4697 r:0.7293
Current avg r:0.5698 Best avg r: 0.6153
02:05:44,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:07:04,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:08:36,835 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2023
en_de Dev loss: 0.9202 r:0.1785
en_zh Dev loss: 0.9219 r:0.2811
ro_en Dev loss: 0.3605 r:0.8202
et_en Dev loss: 0.4721 r:0.6699
si_en Dev loss: 0.8584 r:0.5516
ne_en Dev loss: 0.5500 r:0.7095
ru_en Dev loss: 0.4638 r:0.7222
Current avg r:0.5619 Best avg r: 0.6153
02:12:35,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:54,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:15:27,71 root INFO Epoch 6 Global steps: 61800 Train loss: 0.1915
en_de Dev loss: 0.8700 r:0.1976
en_zh Dev loss: 0.8491 r:0.2964
ro_en Dev loss: 0.3126 r:0.8239
et_en Dev loss: 0.4411 r:0.6834
si_en Dev loss: 0.7565 r:0.5577
ne_en Dev loss: 0.4978 r:0.7109
ru_en Dev loss: 0.3913 r:0.7476
Current avg r:0.5739 Best avg r: 0.6153
02:19:25,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:45,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:17,719 root INFO Epoch 6 Global steps: 62400 Train loss: 0.1904
en_de Dev loss: 0.9222 r:0.1748
en_zh Dev loss: 0.9165 r:0.3003
ro_en Dev loss: 0.3512 r:0.8269
et_en Dev loss: 0.4680 r:0.6708
si_en Dev loss: 0.8758 r:0.5591
ne_en Dev loss: 0.5710 r:0.7113
ru_en Dev loss: 0.4602 r:0.7323
Current avg r:0.5679 Best avg r: 0.6153
02:26:16,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:26:42,626 root INFO 
id:ro_en cur r: 0.8314 best r: 0.8314
02:27:35,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:06,845 root INFO Epoch 6 Global steps: 63000 Train loss: 0.1944
en_de Dev loss: 0.9172 r:0.1847
en_zh Dev loss: 0.8738 r:0.3007
ro_en Dev loss: 0.3177 r:0.8306
et_en Dev loss: 0.4853 r:0.6845
si_en Dev loss: 0.7716 r:0.5615
ne_en Dev loss: 0.4954 r:0.7122
ru_en Dev loss: 0.4346 r:0.7273
Current avg r:0.5716 Best avg r: 0.6153
02:33:03,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:34:21,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:35:53,710 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1838
en_de Dev loss: 0.9120 r:0.1610
en_zh Dev loss: 0.8882 r:0.2850
ro_en Dev loss: 0.3116 r:0.8274
et_en Dev loss: 0.4582 r:0.6762
si_en Dev loss: 0.7995 r:0.5584
ne_en Dev loss: 0.5035 r:0.7166
ru_en Dev loss: 0.4493 r:0.7217
Current avg r:0.5638 Best avg r: 0.6153
02:39:49,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:41:08,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:42:40,287 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1733
en_de Dev loss: 0.9111 r:0.1649
en_zh Dev loss: 0.9065 r:0.3052
ro_en Dev loss: 0.3375 r:0.8272
et_en Dev loss: 0.4299 r:0.6792
si_en Dev loss: 0.8294 r:0.5621
ne_en Dev loss: 0.5696 r:0.7186
ru_en Dev loss: 0.4745 r:0.7285
Current avg r:0.5694 Best avg r: 0.6153
02:46:35,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:47:54,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:49:25,801 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1805
en_de Dev loss: 0.9049 r:0.1739
en_zh Dev loss: 0.8955 r:0.2914
ro_en Dev loss: 0.3236 r:0.8262
et_en Dev loss: 0.4429 r:0.6851
si_en Dev loss: 0.7585 r:0.5657
ne_en Dev loss: 0.4962 r:0.7123
ru_en Dev loss: 0.4337 r:0.7449
Current avg r:0.5714 Best avg r: 0.6153
02:53:20,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:54:40,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:56:12,773 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1713
en_de Dev loss: 0.9064 r:0.1692
en_zh Dev loss: 0.9147 r:0.2763
ro_en Dev loss: 0.3318 r:0.8228
et_en Dev loss: 0.4406 r:0.6771
si_en Dev loss: 0.8399 r:0.5464
ne_en Dev loss: 0.5415 r:0.7087
ru_en Dev loss: 0.4382 r:0.7351
Current avg r:0.5622 Best avg r: 0.6153
03:00:11,459 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:01:30,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:03,181 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1798
en_de Dev loss: 0.9009 r:0.1669
en_zh Dev loss: 0.9253 r:0.2762
ro_en Dev loss: 0.3831 r:0.8182
et_en Dev loss: 0.4462 r:0.6653
si_en Dev loss: 0.9729 r:0.5337
ne_en Dev loss: 0.6705 r:0.7046
ru_en Dev loss: 0.4842 r:0.7172
Current avg r:0.5546 Best avg r: 0.6153
03:07:01,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:08:20,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:09:52,962 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1880
en_de Dev loss: 0.9262 r:0.1509
en_zh Dev loss: 0.9455 r:0.2857
ro_en Dev loss: 0.3944 r:0.8215
et_en Dev loss: 0.4653 r:0.6730
si_en Dev loss: 0.8937 r:0.5473
ne_en Dev loss: 0.6598 r:0.7063
ru_en Dev loss: 0.4651 r:0.7306
Current avg r:0.5593 Best avg r: 0.6153
03:13:50,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:15:09,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:42,43 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1763
en_de Dev loss: 0.9001 r:0.1565
en_zh Dev loss: 0.8752 r:0.2927
ro_en Dev loss: 0.3292 r:0.8191
et_en Dev loss: 0.4328 r:0.6706
si_en Dev loss: 0.8503 r:0.5415
ne_en Dev loss: 0.5547 r:0.7111
ru_en Dev loss: 0.4150 r:0.7370
Current avg r:0.5612 Best avg r: 0.6153
03:20:36,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:54,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:26,487 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1817
en_de Dev loss: 0.9134 r:0.1725
en_zh Dev loss: 0.8941 r:0.3039
ro_en Dev loss: 0.3395 r:0.8245
et_en Dev loss: 0.4644 r:0.6779
si_en Dev loss: 0.7878 r:0.5581
ne_en Dev loss: 0.5098 r:0.7179
ru_en Dev loss: 0.4504 r:0.7315
Current avg r:0.5695 Best avg r: 0.6153
03:27:21,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:39,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:11,74 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1790
en_de Dev loss: 0.9082 r:0.1822
en_zh Dev loss: 0.9122 r:0.2846
ro_en Dev loss: 0.3241 r:0.8233
et_en Dev loss: 0.4335 r:0.6736
si_en Dev loss: 0.8048 r:0.5513
ne_en Dev loss: 0.5636 r:0.7133
ru_en Dev loss: 0.4355 r:0.7361
Current avg r:0.5664 Best avg r: 0.6153
03:34:05,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:24,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:55,642 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1774
en_de Dev loss: 0.9096 r:0.1645
en_zh Dev loss: 0.9339 r:0.2753
ro_en Dev loss: 0.3305 r:0.8221
et_en Dev loss: 0.4375 r:0.6730
si_en Dev loss: 0.8249 r:0.5452
ne_en Dev loss: 0.5771 r:0.7035
ru_en Dev loss: 0.4554 r:0.7307
Current avg r:0.5592 Best avg r: 0.6153
03:40:50,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:42:09,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:43:41,732 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1800
en_de Dev loss: 0.9501 r:0.1555
en_zh Dev loss: 0.9670 r:0.2847
ro_en Dev loss: 0.3495 r:0.8202
et_en Dev loss: 0.4554 r:0.6825
si_en Dev loss: 0.8737 r:0.5481
ne_en Dev loss: 0.5189 r:0.7043
ru_en Dev loss: 0.4732 r:0.7376
Current avg r:0.5619 Best avg r: 0.6153
03:47:39,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:48:58,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:50:30,883 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1802
en_de Dev loss: 0.9082 r:0.1742
en_zh Dev loss: 0.9064 r:0.2926
ro_en Dev loss: 0.3389 r:0.8238
et_en Dev loss: 0.4228 r:0.6838
si_en Dev loss: 0.8912 r:0.5470
ne_en Dev loss: 0.5562 r:0.7049
ru_en Dev loss: 0.4366 r:0.7430
Current avg r:0.5670 Best avg r: 0.6153
03:54:28,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:55:47,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:57:19,772 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1674
en_de Dev loss: 0.8804 r:0.1880
en_zh Dev loss: 0.8985 r:0.2825
ro_en Dev loss: 0.3404 r:0.8191
et_en Dev loss: 0.4415 r:0.6696
si_en Dev loss: 0.8795 r:0.5393
ne_en Dev loss: 0.5525 r:0.7066
ru_en Dev loss: 0.4428 r:0.7303
Current avg r:0.5622 Best avg r: 0.6153
04:01:17,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:02:36,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:08,856 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1749
en_de Dev loss: 0.8926 r:0.1799
en_zh Dev loss: 0.8973 r:0.2799
ro_en Dev loss: 0.3159 r:0.8253
et_en Dev loss: 0.4387 r:0.6759
si_en Dev loss: 0.8155 r:0.5469
ne_en Dev loss: 0.5320 r:0.7069
ru_en Dev loss: 0.4458 r:0.7250
Current avg r:0.5628 Best avg r: 0.6153
04:08:03,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:09:22,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:10:53,940 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1747
en_de Dev loss: 0.9033 r:0.1781
en_zh Dev loss: 0.9105 r:0.2856
ro_en Dev loss: 0.3364 r:0.8224
et_en Dev loss: 0.4625 r:0.6827
si_en Dev loss: 0.8577 r:0.5460
ne_en Dev loss: 0.5685 r:0.7070
ru_en Dev loss: 0.4283 r:0.7416
Current avg r:0.5662 Best avg r: 0.6153
04:14:50,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:16:09,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:17:40,762 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1579
en_de Dev loss: 0.8970 r:0.1792
en_zh Dev loss: 0.9191 r:0.2703
ro_en Dev loss: 0.3425 r:0.8206
et_en Dev loss: 0.4760 r:0.6756
si_en Dev loss: 0.8905 r:0.5372
ne_en Dev loss: 0.5654 r:0.7034
ru_en Dev loss: 0.4303 r:0.7373
Current avg r:0.5605 Best avg r: 0.6153
04:21:35,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:22:54,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:24:26,218 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1572
en_de Dev loss: 0.9173 r:0.1897
en_zh Dev loss: 0.9518 r:0.2686
ro_en Dev loss: 0.3352 r:0.8250
et_en Dev loss: 0.4332 r:0.6838
si_en Dev loss: 0.8395 r:0.5468
ne_en Dev loss: 0.5408 r:0.7161
ru_en Dev loss: 0.4207 r:0.7466
Current avg r:0.5681 Best avg r: 0.6153
04:28:21,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:39,812 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:11,440 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1554
en_de Dev loss: 0.9113 r:0.1642
en_zh Dev loss: 0.9155 r:0.2704
ro_en Dev loss: 0.3289 r:0.8232
et_en Dev loss: 0.4769 r:0.6860
si_en Dev loss: 0.8485 r:0.5421
ne_en Dev loss: 0.5408 r:0.7101
ru_en Dev loss: 0.4085 r:0.7487
Current avg r:0.5635 Best avg r: 0.6153
04:35:07,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:26,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:59,316 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1660
en_de Dev loss: 0.9474 r:0.1585
en_zh Dev loss: 0.8998 r:0.2908
ro_en Dev loss: 0.3344 r:0.8231
et_en Dev loss: 0.4523 r:0.6831
si_en Dev loss: 0.8402 r:0.5498
ne_en Dev loss: 0.5171 r:0.7179
ru_en Dev loss: 0.4204 r:0.7452
Current avg r:0.5669 Best avg r: 0.6153
04:41:56,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:15,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:48,408 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1488
en_de Dev loss: 0.9602 r:0.1608
en_zh Dev loss: 0.9310 r:0.2860
ro_en Dev loss: 0.3627 r:0.8184
et_en Dev loss: 0.4453 r:0.6757
si_en Dev loss: 0.8688 r:0.5449
ne_en Dev loss: 0.5798 r:0.7110
ru_en Dev loss: 0.4533 r:0.7384
Current avg r:0.5622 Best avg r: 0.6153
04:48:46,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:05,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:37,974 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1505
en_de Dev loss: 0.9511 r:0.1498
en_zh Dev loss: 0.9614 r:0.2714
ro_en Dev loss: 0.3432 r:0.8203
et_en Dev loss: 0.4431 r:0.6815
si_en Dev loss: 0.8646 r:0.5398
ne_en Dev loss: 0.5844 r:0.7028
ru_en Dev loss: 0.4127 r:0.7553
Current avg r:0.5601 Best avg r: 0.6153
04:55:36,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:56:54,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:26,144 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1523
en_de Dev loss: 0.9557 r:0.1543
en_zh Dev loss: 0.9373 r:0.2939
ro_en Dev loss: 0.3505 r:0.8214
et_en Dev loss: 0.4547 r:0.6782
si_en Dev loss: 0.8676 r:0.5480
ne_en Dev loss: 0.5236 r:0.7132
ru_en Dev loss: 0.4390 r:0.7481
Current avg r:0.5653 Best avg r: 0.6153
05:02:20,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:39,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:05:10,891 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1544
en_de Dev loss: 0.9291 r:0.1577
en_zh Dev loss: 0.9345 r:0.2700
ro_en Dev loss: 0.3369 r:0.8199
et_en Dev loss: 0.4629 r:0.6783
si_en Dev loss: 0.8422 r:0.5441
ne_en Dev loss: 0.5418 r:0.7087
ru_en Dev loss: 0.4545 r:0.7362
Current avg r:0.5593 Best avg r: 0.6153
05:09:05,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:23,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:55,499 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1623
en_de Dev loss: 0.9205 r:0.1553
en_zh Dev loss: 0.8927 r:0.2870
ro_en Dev loss: 0.3215 r:0.8219
et_en Dev loss: 0.4404 r:0.6803
si_en Dev loss: 0.7858 r:0.5505
ne_en Dev loss: 0.5300 r:0.7145
ru_en Dev loss: 0.4099 r:0.7538
Current avg r:0.5662 Best avg r: 0.6153
05:15:49,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:08,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:40,14 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1511
en_de Dev loss: 0.9493 r:0.1765
en_zh Dev loss: 0.9188 r:0.2954
ro_en Dev loss: 0.3433 r:0.8208
et_en Dev loss: 0.4659 r:0.6768
si_en Dev loss: 0.8418 r:0.5418
ne_en Dev loss: 0.5252 r:0.7128
ru_en Dev loss: 0.4085 r:0.7560
Current avg r:0.5686 Best avg r: 0.6153
05:22:36,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:23:55,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:28,353 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1558
en_de Dev loss: 0.9262 r:0.1780
en_zh Dev loss: 0.9235 r:0.2943
ro_en Dev loss: 0.3451 r:0.8220
et_en Dev loss: 0.4520 r:0.6823
si_en Dev loss: 0.8493 r:0.5491
ne_en Dev loss: 0.5508 r:0.7124
ru_en Dev loss: 0.3953 r:0.7663
Current avg r:0.5721 Best avg r: 0.6153
05:29:25,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:45,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:32:17,597 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1576
en_de Dev loss: 0.9339 r:0.1552
en_zh Dev loss: 0.9376 r:0.2814
ro_en Dev loss: 0.3532 r:0.8214
et_en Dev loss: 0.4558 r:0.6773
si_en Dev loss: 0.8478 r:0.5413
ne_en Dev loss: 0.5612 r:0.7093
ru_en Dev loss: 0.4582 r:0.7394
Current avg r:0.5608 Best avg r: 0.6153
05:36:14,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:34,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:39:06,617 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1598
en_de Dev loss: 0.9082 r:0.1653
en_zh Dev loss: 0.8726 r:0.2774
ro_en Dev loss: 0.3075 r:0.8264
et_en Dev loss: 0.4878 r:0.6918
si_en Dev loss: 0.7461 r:0.5549
ne_en Dev loss: 0.5122 r:0.7124
ru_en Dev loss: 0.3737 r:0.7571
Current avg r:0.5693 Best avg r: 0.6153
05:43:04,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:22,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:54,422 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1518
en_de Dev loss: 0.9311 r:0.1793
en_zh Dev loss: 0.9182 r:0.2929
ro_en Dev loss: 0.3276 r:0.8238
et_en Dev loss: 0.4771 r:0.6759
si_en Dev loss: 0.8369 r:0.5396
ne_en Dev loss: 0.5339 r:0.7038
ru_en Dev loss: 0.4207 r:0.7492
Current avg r:0.5664 Best avg r: 0.6153
05:49:48,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:07,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:52:39,108 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1517
en_de Dev loss: 0.9251 r:0.1651
en_zh Dev loss: 0.8890 r:0.2891
ro_en Dev loss: 0.3031 r:0.8265
et_en Dev loss: 0.4280 r:0.6806
si_en Dev loss: 0.8144 r:0.5437
ne_en Dev loss: 0.4867 r:0.7105
ru_en Dev loss: 0.4308 r:0.7425
Current avg r:0.5654 Best avg r: 0.6153
05:56:35,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:57:53,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:25,212 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1325
en_de Dev loss: 0.9612 r:0.1716
en_zh Dev loss: 0.9456 r:0.2910
ro_en Dev loss: 0.3396 r:0.8266
et_en Dev loss: 0.4715 r:0.6848
si_en Dev loss: 0.8334 r:0.5513
ne_en Dev loss: 0.5619 r:0.7125
ru_en Dev loss: 0.4504 r:0.7452
Current avg r:0.5690 Best avg r: 0.6153
06:03:19,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:38,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:06:09,706 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1451
en_de Dev loss: 0.9537 r:0.1760
en_zh Dev loss: 0.9632 r:0.2798
ro_en Dev loss: 0.3421 r:0.8259
et_en Dev loss: 0.4656 r:0.6838
si_en Dev loss: 0.8750 r:0.5464
ne_en Dev loss: 0.5954 r:0.7052
ru_en Dev loss: 0.4590 r:0.7433
Current avg r:0.5658 Best avg r: 0.6153
06:10:07,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:26,729 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:12:59,181 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1392
en_de Dev loss: 0.9239 r:0.1419
en_zh Dev loss: 0.8988 r:0.2636
ro_en Dev loss: 0.3103 r:0.8267
et_en Dev loss: 0.4416 r:0.6813
si_en Dev loss: 0.8135 r:0.5447
ne_en Dev loss: 0.5332 r:0.7080
ru_en Dev loss: 0.4107 r:0.7451
Current avg r:0.5588 Best avg r: 0.6153
06:16:56,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:18:15,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:19:48,138 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1278
en_de Dev loss: 0.9824 r:0.1500
en_zh Dev loss: 0.9903 r:0.2767
ro_en Dev loss: 0.3664 r:0.8232
et_en Dev loss: 0.4721 r:0.6730
si_en Dev loss: 0.9195 r:0.5451
ne_en Dev loss: 0.6014 r:0.7023
ru_en Dev loss: 0.4560 r:0.7490
Current avg r:0.5599 Best avg r: 0.6153
06:23:46,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:25:05,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:37,982 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1372
en_de Dev loss: 0.9417 r:0.1582
en_zh Dev loss: 0.9276 r:0.2939
ro_en Dev loss: 0.3298 r:0.8236
et_en Dev loss: 0.4692 r:0.6712
si_en Dev loss: 0.8783 r:0.5390
ne_en Dev loss: 0.5430 r:0.7031
ru_en Dev loss: 0.4126 r:0.7557
Current avg r:0.5635 Best avg r: 0.6153
06:30:33,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:31:52,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:33:24,134 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1440
en_de Dev loss: 0.9428 r:0.1561
en_zh Dev loss: 0.9169 r:0.2920
ro_en Dev loss: 0.3260 r:0.8244
et_en Dev loss: 0.4652 r:0.6813
si_en Dev loss: 0.8300 r:0.5469
ne_en Dev loss: 0.5004 r:0.7028
ru_en Dev loss: 0.4014 r:0.7603
Current avg r:0.5663 Best avg r: 0.6153
06:37:18,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:38:37,312 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:40:09,23 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1268
en_de Dev loss: 0.9389 r:0.1607
en_zh Dev loss: 0.9231 r:0.2902
ro_en Dev loss: 0.3393 r:0.8214
et_en Dev loss: 0.4573 r:0.6697
si_en Dev loss: 0.8924 r:0.5402
ne_en Dev loss: 0.5998 r:0.6977
ru_en Dev loss: 0.4324 r:0.7452
Current avg r:0.5607 Best avg r: 0.6153
06:44:03,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:22,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:53,809 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1325
en_de Dev loss: 0.9442 r:0.1345
en_zh Dev loss: 0.9213 r:0.2884
ro_en Dev loss: 0.3340 r:0.8211
et_en Dev loss: 0.4513 r:0.6758
si_en Dev loss: 0.8604 r:0.5451
ne_en Dev loss: 0.5613 r:0.7020
ru_en Dev loss: 0.4177 r:0.7506
Current avg r:0.5596 Best avg r: 0.6153
06:50:48,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:06,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:53:38,126 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1400
en_de Dev loss: 0.9516 r:0.1392
en_zh Dev loss: 0.8969 r:0.2943
ro_en Dev loss: 0.3389 r:0.8214
et_en Dev loss: 0.4717 r:0.6714
si_en Dev loss: 0.8430 r:0.5468
ne_en Dev loss: 0.5419 r:0.6994
ru_en Dev loss: 0.4062 r:0.7542
Current avg r:0.5610 Best avg r: 0.6153
06:57:31,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:58:50,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:00:21,752 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1302
en_de Dev loss: 0.9202 r:0.1595
en_zh Dev loss: 0.8691 r:0.2910
ro_en Dev loss: 0.3065 r:0.8235
et_en Dev loss: 0.4584 r:0.6815
si_en Dev loss: 0.7730 r:0.5532
ne_en Dev loss: 0.4939 r:0.7011
ru_en Dev loss: 0.3690 r:0.7651
Current avg r:0.5678 Best avg r: 0.6153
07:04:15,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:05:34,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:07:05,614 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1259
en_de Dev loss: 0.9462 r:0.1464
en_zh Dev loss: 0.9210 r:0.2964
ro_en Dev loss: 0.3372 r:0.8221
et_en Dev loss: 0.4472 r:0.6820
si_en Dev loss: 0.8467 r:0.5491
ne_en Dev loss: 0.5516 r:0.7046
ru_en Dev loss: 0.4078 r:0.7620
Current avg r:0.5661 Best avg r: 0.6153
07:10:59,709 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:12:18,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:13:49,525 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1400
en_de Dev loss: 0.9545 r:0.1501
en_zh Dev loss: 0.9340 r:0.2862
ro_en Dev loss: 0.3419 r:0.8194
et_en Dev loss: 0.4363 r:0.6842
si_en Dev loss: 0.8649 r:0.5410
ne_en Dev loss: 0.5950 r:0.6989
ru_en Dev loss: 0.4286 r:0.7521
Current avg r:0.5617 Best avg r: 0.6153
07:17:43,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:19:01,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:33,421 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1328
en_de Dev loss: 0.9508 r:0.1647
en_zh Dev loss: 0.9213 r:0.2895
ro_en Dev loss: 0.3269 r:0.8239
et_en Dev loss: 0.4486 r:0.6834
si_en Dev loss: 0.8684 r:0.5387
ne_en Dev loss: 0.5988 r:0.6960
ru_en Dev loss: 0.3972 r:0.7601
Current avg r:0.5652 Best avg r: 0.6153
07:24:27,709 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:46,80 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:27:17,509 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1304
en_de Dev loss: 0.9361 r:0.1704
en_zh Dev loss: 0.9445 r:0.2885
ro_en Dev loss: 0.3457 r:0.8190
et_en Dev loss: 0.4524 r:0.6686
si_en Dev loss: 0.9362 r:0.5263
ne_en Dev loss: 0.6187 r:0.6914
ru_en Dev loss: 0.4631 r:0.7379
Current avg r:0.5574 Best avg r: 0.6153
07:31:11,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:30,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:34:01,512 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1261
en_de Dev loss: 0.9356 r:0.1747
en_zh Dev loss: 0.9002 r:0.2999
ro_en Dev loss: 0.3270 r:0.8237
et_en Dev loss: 0.4550 r:0.6851
si_en Dev loss: 0.8232 r:0.5453
ne_en Dev loss: 0.5224 r:0.7081
ru_en Dev loss: 0.3905 r:0.7625
Current avg r:0.5713 Best avg r: 0.6153
07:37:56,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:39:15,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:40:46,573 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1201
en_de Dev loss: 0.9203 r:0.1594
en_zh Dev loss: 0.8936 r:0.2912
ro_en Dev loss: 0.3139 r:0.8238
et_en Dev loss: 0.4237 r:0.6762
si_en Dev loss: 0.8386 r:0.5450
ne_en Dev loss: 0.5405 r:0.7045
ru_en Dev loss: 0.4167 r:0.7481
Current avg r:0.5640 Best avg r: 0.6153
07:44:40,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:45:59,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:47:30,624 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1282
en_de Dev loss: 0.9413 r:0.1783
en_zh Dev loss: 0.9283 r:0.2975
ro_en Dev loss: 0.3350 r:0.8242
et_en Dev loss: 0.4539 r:0.6797
si_en Dev loss: 0.8474 r:0.5416
ne_en Dev loss: 0.5296 r:0.7066
ru_en Dev loss: 0.4117 r:0.7597
Current avg r:0.5697 Best avg r: 0.6153
07:51:24,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:52:43,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:54:14,468 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1173
en_de Dev loss: 0.9446 r:0.1822
en_zh Dev loss: 0.9497 r:0.2916
ro_en Dev loss: 0.3487 r:0.8226
et_en Dev loss: 0.4633 r:0.6761
si_en Dev loss: 0.8706 r:0.5364
ne_en Dev loss: 0.6043 r:0.6932
ru_en Dev loss: 0.4305 r:0.7550
Current avg r:0.5653 Best avg r: 0.6153
07:58:08,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:59:26,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:00:58,254 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1177
en_de Dev loss: 0.9459 r:0.1775
en_zh Dev loss: 0.9473 r:0.2812
ro_en Dev loss: 0.3584 r:0.8232
et_en Dev loss: 0.4455 r:0.6720
si_en Dev loss: 0.9169 r:0.5391
ne_en Dev loss: 0.6469 r:0.7008
ru_en Dev loss: 0.4498 r:0.7473
Current avg r:0.5630 Best avg r: 0.6153
08:04:52,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:06:10,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:07:41,885 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1132
en_de Dev loss: 0.9253 r:0.1714
en_zh Dev loss: 0.9429 r:0.2758
ro_en Dev loss: 0.3457 r:0.8224
et_en Dev loss: 0.4585 r:0.6667
si_en Dev loss: 0.8922 r:0.5374
ne_en Dev loss: 0.6262 r:0.7048
ru_en Dev loss: 0.4269 r:0.7494
Current avg r:0.5611 Best avg r: 0.6153
08:11:35,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:12:54,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:14:25,456 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1127
en_de Dev loss: 0.9430 r:0.1703
en_zh Dev loss: 0.9767 r:0.2743
ro_en Dev loss: 0.3300 r:0.8291
et_en Dev loss: 0.4711 r:0.6750
si_en Dev loss: 0.8918 r:0.5381
ne_en Dev loss: 0.5804 r:0.7024
ru_en Dev loss: 0.4591 r:0.7455
Current avg r:0.5621 Best avg r: 0.6153
08:18:19,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:19:37,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:21:09,43 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1148
en_de Dev loss: 0.9205 r:0.1734
en_zh Dev loss: 0.9031 r:0.2867
ro_en Dev loss: 0.3161 r:0.8267
et_en Dev loss: 0.4585 r:0.6848
si_en Dev loss: 0.8662 r:0.5385
ne_en Dev loss: 0.5465 r:0.7020
ru_en Dev loss: 0.4072 r:0.7569
Current avg r:0.5670 Best avg r: 0.6153
08:25:02,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:21,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:27:52,726 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1181
en_de Dev loss: 0.9282 r:0.1690
en_zh Dev loss: 0.9391 r:0.2693
ro_en Dev loss: 0.3316 r:0.8228
et_en Dev loss: 0.4400 r:0.6741
si_en Dev loss: 0.8932 r:0.5365
ne_en Dev loss: 0.5993 r:0.6985
ru_en Dev loss: 0.4575 r:0.7394
Current avg r:0.5585 Best avg r: 0.6153
08:31:46,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:33:05,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:34:36,401 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1231
en_de Dev loss: 0.9342 r:0.1662
en_zh Dev loss: 0.9337 r:0.2783
ro_en Dev loss: 0.3392 r:0.8222
et_en Dev loss: 0.4550 r:0.6758
si_en Dev loss: 0.8385 r:0.5383
ne_en Dev loss: 0.5649 r:0.6990
ru_en Dev loss: 0.4317 r:0.7482
Current avg r:0.5611 Best avg r: 0.6153
08:38:30,398 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:39:48,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:20,16 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1166
en_de Dev loss: 0.9579 r:0.1491
en_zh Dev loss: 1.0003 r:0.2767
ro_en Dev loss: 0.3602 r:0.8231
et_en Dev loss: 0.4440 r:0.6798
si_en Dev loss: 0.9292 r:0.5403
ne_en Dev loss: 0.6714 r:0.7088
ru_en Dev loss: 0.4691 r:0.7459
Current avg r:0.5605 Best avg r: 0.6153
08:45:13,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:46:31,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:48:02,975 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1146
en_de Dev loss: 0.9541 r:0.1615
en_zh Dev loss: 0.9139 r:0.3034
ro_en Dev loss: 0.3419 r:0.8214
et_en Dev loss: 0.4561 r:0.6784
si_en Dev loss: 0.8609 r:0.5387
ne_en Dev loss: 0.5229 r:0.7082
ru_en Dev loss: 0.4409 r:0.7476
Current avg r:0.5656 Best avg r: 0.6153
08:51:56,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:15,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:46,577 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1149
en_de Dev loss: 0.9701 r:0.1626
en_zh Dev loss: 0.9385 r:0.2958
ro_en Dev loss: 0.3580 r:0.8206
et_en Dev loss: 0.4557 r:0.6788
si_en Dev loss: 0.8725 r:0.5363
ne_en Dev loss: 0.5474 r:0.7034
ru_en Dev loss: 0.4428 r:0.7485
Current avg r:0.5637 Best avg r: 0.6153
08:58:40,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:59:58,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:01:30,297 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1190
en_de Dev loss: 0.9581 r:0.1664
en_zh Dev loss: 0.8763 r:0.3122
ro_en Dev loss: 0.3146 r:0.8268
et_en Dev loss: 0.4544 r:0.6880
si_en Dev loss: 0.7824 r:0.5493
ne_en Dev loss: 0.4993 r:0.7078
ru_en Dev loss: 0.3963 r:0.7575
Current avg r:0.5726 Best avg r: 0.6153
09:05:24,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:06:42,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:08:13,906 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1216
en_de Dev loss: 0.9655 r:0.1650
en_zh Dev loss: 0.9351 r:0.3036
ro_en Dev loss: 0.3563 r:0.8219
et_en Dev loss: 0.4527 r:0.6740
si_en Dev loss: 0.8772 r:0.5426
ne_en Dev loss: 0.6217 r:0.7058
ru_en Dev loss: 0.4505 r:0.7463
Current avg r:0.5656 Best avg r: 0.6153
09:12:07,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:13:26,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:14:57,522 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1185
en_de Dev loss: 0.9678 r:0.1755
en_zh Dev loss: 0.9505 r:0.2899
ro_en Dev loss: 0.3320 r:0.8238
et_en Dev loss: 0.4674 r:0.6775
si_en Dev loss: 0.8594 r:0.5346
ne_en Dev loss: 0.5329 r:0.7070
ru_en Dev loss: 0.4253 r:0.7545
Current avg r:0.5661 Best avg r: 0.6153
09:18:52,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:20:10,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:21:41,798 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1047
en_de Dev loss: 0.9697 r:0.1867
en_zh Dev loss: 0.9672 r:0.2920
ro_en Dev loss: 0.3455 r:0.8247
et_en Dev loss: 0.4645 r:0.6815
si_en Dev loss: 0.8694 r:0.5363
ne_en Dev loss: 0.5365 r:0.7028
ru_en Dev loss: 0.4226 r:0.7634
Current avg r:0.5696 Best avg r: 0.6153
09:25:35,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:26:53,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:28:24,778 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1051
en_de Dev loss: 0.9311 r:0.1839
en_zh Dev loss: 0.9307 r:0.2910
ro_en Dev loss: 0.3472 r:0.8236
et_en Dev loss: 0.4516 r:0.6796
si_en Dev loss: 0.8767 r:0.5392
ne_en Dev loss: 0.5755 r:0.7047
ru_en Dev loss: 0.4061 r:0.7604
Current avg r:0.5689 Best avg r: 0.6153
09:32:18,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:33:36,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:35:07,861 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1087
en_de Dev loss: 0.9521 r:0.1704
en_zh Dev loss: 0.9568 r:0.2788
ro_en Dev loss: 0.3518 r:0.8219
et_en Dev loss: 0.4497 r:0.6772
si_en Dev loss: 0.8592 r:0.5393
ne_en Dev loss: 0.5781 r:0.7007
ru_en Dev loss: 0.4186 r:0.7509
Current avg r:0.5627 Best avg r: 0.6153
09:39:01,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:40:19,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:41:51,370 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1060
en_de Dev loss: 0.9329 r:0.1663
en_zh Dev loss: 0.9422 r:0.2752
ro_en Dev loss: 0.3452 r:0.8201
et_en Dev loss: 0.4480 r:0.6764
si_en Dev loss: 0.9318 r:0.5264
ne_en Dev loss: 0.6528 r:0.7012
ru_en Dev loss: 0.4350 r:0.7465
Current avg r:0.5589 Best avg r: 0.6153
09:45:46,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:04,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:48:36,195 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1055
en_de Dev loss: 0.9481 r:0.1702
en_zh Dev loss: 0.9397 r:0.2871
ro_en Dev loss: 0.3358 r:0.8255
et_en Dev loss: 0.4521 r:0.6818
si_en Dev loss: 0.8649 r:0.5376
ne_en Dev loss: 0.5505 r:0.7011
ru_en Dev loss: 0.4139 r:0.7608
Current avg r:0.5663 Best avg r: 0.6153
09:52:30,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:49,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:55:20,783 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1033
en_de Dev loss: 0.9604 r:0.1690
en_zh Dev loss: 0.9066 r:0.3062
ro_en Dev loss: 0.3317 r:0.8228
et_en Dev loss: 0.4790 r:0.6791
si_en Dev loss: 0.8401 r:0.5428
ne_en Dev loss: 0.5514 r:0.6988
ru_en Dev loss: 0.4005 r:0.7649
Current avg r:0.5691 Best avg r: 0.6153
09:59:14,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:00:33,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:04,595 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1083
en_de Dev loss: 0.9459 r:0.1485
en_zh Dev loss: 0.9214 r:0.2865
ro_en Dev loss: 0.3417 r:0.8220
et_en Dev loss: 0.4605 r:0.6709
si_en Dev loss: 0.8329 r:0.5408
ne_en Dev loss: 0.5440 r:0.7027
ru_en Dev loss: 0.4406 r:0.7419
Current avg r:0.5591 Best avg r: 0.6153
10:05:58,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:07:16,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:08:47,725 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1055
en_de Dev loss: 0.9715 r:0.1454
en_zh Dev loss: 0.9163 r:0.2941
ro_en Dev loss: 0.3476 r:0.8217
et_en Dev loss: 0.4757 r:0.6750
si_en Dev loss: 0.8447 r:0.5409
ne_en Dev loss: 0.5571 r:0.7040
ru_en Dev loss: 0.4407 r:0.7414
Current avg r:0.5603 Best avg r: 0.6153
10:12:41,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:59,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:30,889 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1067
en_de Dev loss: 0.9761 r:0.1505
en_zh Dev loss: 0.9322 r:0.2940
ro_en Dev loss: 0.3474 r:0.8246
et_en Dev loss: 0.4408 r:0.6759
si_en Dev loss: 0.8863 r:0.5399
ne_en Dev loss: 0.5647 r:0.7052
ru_en Dev loss: 0.4072 r:0.7613
Current avg r:0.5645 Best avg r: 0.6153
10:19:24,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:42,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:14,36 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1073
en_de Dev loss: 0.9575 r:0.1475
en_zh Dev loss: 0.9357 r:0.2828
ro_en Dev loss: 0.3254 r:0.8228
et_en Dev loss: 0.4471 r:0.6815
si_en Dev loss: 0.8059 r:0.5496
ne_en Dev loss: 0.5528 r:0.7015
ru_en Dev loss: 0.4237 r:0.7518
Current avg r:0.5625 Best avg r: 0.6153
10:26:07,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:26,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:28:57,781 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1018
en_de Dev loss: 0.9349 r:0.1463
en_zh Dev loss: 0.9187 r:0.2796
ro_en Dev loss: 0.3289 r:0.8202
et_en Dev loss: 0.4352 r:0.6755
si_en Dev loss: 0.8686 r:0.5408
ne_en Dev loss: 0.6034 r:0.6993
ru_en Dev loss: 0.4381 r:0.7383
Current avg r:0.5571 Best avg r: 0.6153
