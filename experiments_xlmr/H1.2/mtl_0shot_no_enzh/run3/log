14:42:52,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:43:05,122 root INFO 
id:en_de cur r: 0.0176 best r: 0.0176
14:43:17,992 root INFO 
id:ro_en cur r: 0.3191 best r: 0.3191
14:43:30,869 root INFO 
id:et_en cur r: 0.0869 best r: 0.0869
14:43:43,750 root INFO 
id:si_en cur r: 0.1564 best r: 0.1564
14:44:09,445 root INFO 
id:ru_en cur r: 0.1983 best r: 0.1983
14:44:09,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:39,238 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
14:45:39,244 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:45:39,248 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:45:39,254 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
14:45:39,259 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
14:45:39,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:45:39,268 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:45:52,88 root INFO Epoch 0 Global steps: 600 Train loss: 0.9127
en_de Dev loss: 0.8877 r:0.0261
en_zh Dev loss: 0.8226 r:0.0875
ro_en Dev loss: 0.8379 r:0.4280
et_en Dev loss: 0.7308 r:0.3208
si_en Dev loss: 0.8091 r:0.2963
ne_en Dev loss: 0.7813 r:0.2878
ru_en Dev loss: 0.8259 r:0.1377
Current avg r:0.2263 Best avg r: 0.2263
14:49:42,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:55,366 root INFO 
id:en_de cur r: 0.0377 best r: 0.0377
14:50:08,239 root INFO 
id:ro_en cur r: 0.5056 best r: 0.5056
14:50:21,120 root INFO 
id:et_en cur r: 0.4273 best r: 0.4273
14:50:34,15 root INFO 
id:si_en cur r: 0.3649 best r: 0.3649
14:50:46,898 root INFO 
id:ne_en cur r: 0.4192 best r: 0.4192
14:50:59,730 root INFO 
id:ru_en cur r: 0.5138 best r: 0.5138
14:50:59,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:29,654 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
14:52:29,661 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:52:29,667 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:52:29,671 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
14:52:29,676 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
14:52:29,681 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:52:29,686 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:52:42,513 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8542
en_de Dev loss: 0.8821 r:0.0828
en_zh Dev loss: 0.7838 r:0.2449
ro_en Dev loss: 0.7646 r:0.5909
et_en Dev loss: 0.6291 r:0.5082
si_en Dev loss: 0.7514 r:0.4671
ne_en Dev loss: 0.6670 r:0.5935
ru_en Dev loss: 0.6952 r:0.5941
Current avg r:0.4402 Best avg r: 0.4402
14:56:32,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:45,809 root INFO 
id:en_de cur r: 0.1022 best r: 0.1022
14:56:58,665 root INFO 
id:ro_en cur r: 0.7030 best r: 0.7030
14:57:11,543 root INFO 
id:et_en cur r: 0.6266 best r: 0.6266
14:57:24,417 root INFO 
id:si_en cur r: 0.4609 best r: 0.4609
14:57:37,296 root INFO 
id:ne_en cur r: 0.6502 best r: 0.6502
14:57:50,119 root INFO 
id:ru_en cur r: 0.6861 best r: 0.6861
14:57:50,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:19,944 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
14:59:19,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:59:19,964 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:59:19,971 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
14:59:19,977 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
14:59:19,982 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:59:19,987 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:59:32,824 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7978
en_de Dev loss: 0.9570 r:0.1181
en_zh Dev loss: 0.7582 r:0.3089
ro_en Dev loss: 0.5120 r:0.7043
et_en Dev loss: 0.4250 r:0.6439
si_en Dev loss: 0.6283 r:0.5083
ne_en Dev loss: 0.4623 r:0.6530
ru_en Dev loss: 0.4732 r:0.6960
Current avg r:0.5189 Best avg r: 0.5189
15:03:23,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:36,51 root INFO 
id:en_de cur r: 0.1303 best r: 0.1303
15:03:48,909 root INFO 
id:ro_en cur r: 0.7333 best r: 0.7333
15:04:01,774 root INFO 
id:et_en cur r: 0.6691 best r: 0.6691
15:04:14,637 root INFO 
id:si_en cur r: 0.4884 best r: 0.4884
15:04:27,516 root INFO 
id:ne_en cur r: 0.6712 best r: 0.6712
15:04:40,334 root INFO 
id:ru_en cur r: 0.6964 best r: 0.6964
15:04:40,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:10,292 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
15:06:10,300 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:06:10,305 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:06:10,310 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
15:06:10,315 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
15:06:10,321 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:06:10,327 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:06:23,156 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6561
en_de Dev loss: 1.0155 r:0.1254
en_zh Dev loss: 0.8206 r:0.2846
ro_en Dev loss: 0.4815 r:0.7338
et_en Dev loss: 0.4155 r:0.6747
si_en Dev loss: 0.6615 r:0.5369
ne_en Dev loss: 0.4841 r:0.6752
ru_en Dev loss: 0.5688 r:0.7104
Current avg r:0.5344 Best avg r: 0.5344
15:10:14,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:27,104 root INFO 
id:en_de cur r: 0.1540 best r: 0.1540
15:10:39,954 root INFO 
id:ro_en cur r: 0.7498 best r: 0.7498
15:10:52,811 root INFO 
id:et_en cur r: 0.6824 best r: 0.6824
15:11:05,676 root INFO 
id:si_en cur r: 0.5071 best r: 0.5071
15:11:31,376 root INFO 
id:ru_en cur r: 0.7278 best r: 0.7278
15:11:31,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:01,305 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
15:13:01,311 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:13:01,316 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:13:01,321 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
15:13:01,326 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
15:13:01,330 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:13:01,335 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:13:14,161 root INFO Epoch 0 Global steps: 3000 Train loss: 0.5998
en_de Dev loss: 1.0065 r:0.1431
en_zh Dev loss: 0.8552 r:0.2918
ro_en Dev loss: 0.4473 r:0.7502
et_en Dev loss: 0.3776 r:0.6947
si_en Dev loss: 0.7612 r:0.5422
ne_en Dev loss: 0.5514 r:0.6808
ru_en Dev loss: 0.5147 r:0.7354
Current avg r:0.5483 Best avg r: 0.5483
15:17:05,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:31,8 root INFO 
id:ro_en cur r: 0.7627 best r: 0.7627
15:17:43,884 root INFO 
id:et_en cur r: 0.6985 best r: 0.6985
15:17:56,762 root INFO 
id:si_en cur r: 0.5347 best r: 0.5347
15:18:09,626 root INFO 
id:ne_en cur r: 0.6912 best r: 0.6912
15:18:22,445 root INFO 
id:ru_en cur r: 0.7278 best r: 0.7278
15:18:22,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:52,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
15:19:52,270 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:19:52,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:19:52,280 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
15:19:52,285 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
15:19:52,289 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:19:52,294 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:20:05,131 root INFO Epoch 0 Global steps: 3600 Train loss: 0.5694
en_de Dev loss: 0.9645 r:0.1456
en_zh Dev loss: 0.8109 r:0.3217
ro_en Dev loss: 0.3986 r:0.7606
et_en Dev loss: 0.3616 r:0.7069
si_en Dev loss: 0.7141 r:0.5598
ne_en Dev loss: 0.5459 r:0.6906
ru_en Dev loss: 0.4572 r:0.7365
Current avg r:0.5603 Best avg r: 0.5603
15:23:55,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:08,307 root INFO 
id:en_de cur r: 0.1664 best r: 0.1664
15:24:21,152 root INFO 
id:ro_en cur r: 0.7749 best r: 0.7749
15:24:34,38 root INFO 
id:et_en cur r: 0.7108 best r: 0.7108
15:24:46,920 root INFO 
id:si_en cur r: 0.5733 best r: 0.5733
15:24:59,799 root INFO 
id:ne_en cur r: 0.7242 best r: 0.7242
15:25:12,611 root INFO 
id:ru_en cur r: 0.7346 best r: 0.7346
15:25:12,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:42,470 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
15:26:42,476 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:26:42,480 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:26:42,485 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
15:26:42,490 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
15:26:42,495 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:26:42,500 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:26:55,328 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5591
en_de Dev loss: 0.9318 r:0.1550
en_zh Dev loss: 0.8106 r:0.3259
ro_en Dev loss: 0.3669 r:0.7742
et_en Dev loss: 0.3489 r:0.7125
si_en Dev loss: 0.5565 r:0.5952
ne_en Dev loss: 0.4077 r:0.7239
ru_en Dev loss: 0.4381 r:0.7385
Current avg r:0.5750 Best avg r: 0.5750
15:30:45,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:58,536 root INFO 
id:en_de cur r: 0.1769 best r: 0.1769
15:31:11,374 root INFO 
id:ro_en cur r: 0.7820 best r: 0.7820
15:32:02,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:32,733 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5583
en_de Dev loss: 0.9830 r:0.1519
en_zh Dev loss: 0.9407 r:0.3075
ro_en Dev loss: 0.4310 r:0.7806
et_en Dev loss: 0.3842 r:0.7076
si_en Dev loss: 0.7812 r:0.5714
ne_en Dev loss: 0.6143 r:0.7070
ru_en Dev loss: 0.5733 r:0.7239
Current avg r:0.5643 Best avg r: 0.5750
15:37:23,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:36,63 root INFO 
id:en_de cur r: 0.1776 best r: 0.1776
15:37:48,936 root INFO 
id:ro_en cur r: 0.7899 best r: 0.7899
15:38:01,807 root INFO 
id:et_en cur r: 0.7204 best r: 0.7204
15:38:14,682 root INFO 
id:si_en cur r: 0.5879 best r: 0.5879
15:38:27,548 root INFO 
id:ne_en cur r: 0.7393 best r: 0.7393
15:38:40,357 root INFO 
id:ru_en cur r: 0.7508 best r: 0.7508
15:38:40,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:10,305 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
15:40:10,311 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:40:10,316 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:40:10,321 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
15:40:10,326 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
15:40:10,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:40:10,335 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:40:23,140 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5681
en_de Dev loss: 0.9572 r:0.1612
en_zh Dev loss: 0.8670 r:0.3373
ro_en Dev loss: 0.3878 r:0.7877
et_en Dev loss: 0.3537 r:0.7189
si_en Dev loss: 0.6483 r:0.6001
ne_en Dev loss: 0.4156 r:0.7366
ru_en Dev loss: 0.4642 r:0.7511
Current avg r:0.5847 Best avg r: 0.5847
15:44:13,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:39,190 root INFO 
id:ro_en cur r: 0.7928 best r: 0.7928
15:45:30,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:00,359 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5441
en_de Dev loss: 0.9058 r:0.1558
en_zh Dev loss: 0.8431 r:0.3130
ro_en Dev loss: 0.3557 r:0.7917
et_en Dev loss: 0.3565 r:0.7148
si_en Dev loss: 0.6648 r:0.5868
ne_en Dev loss: 0.4133 r:0.7317
ru_en Dev loss: 0.4603 r:0.7446
Current avg r:0.5769 Best avg r: 0.5847
15:50:50,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:16,507 root INFO 
id:ro_en cur r: 0.7935 best r: 0.7935
15:52:07,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:37,979 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5914
en_de Dev loss: 0.9332 r:0.1429
en_zh Dev loss: 0.9147 r:0.3148
ro_en Dev loss: 0.4038 r:0.7925
et_en Dev loss: 0.3580 r:0.7189
si_en Dev loss: 0.7801 r:0.5926
ne_en Dev loss: 0.5694 r:0.7284
ru_en Dev loss: 0.5154 r:0.7285
Current avg r:0.5741 Best avg r: 0.5847
15:57:28,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:54,336 root INFO 
id:ro_en cur r: 0.7967 best r: 0.7967
15:58:45,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:15,560 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5319
en_de Dev loss: 0.9108 r:0.1330
en_zh Dev loss: 0.8552 r:0.3012
ro_en Dev loss: 0.3470 r:0.7938
et_en Dev loss: 0.3668 r:0.7069
si_en Dev loss: 0.7225 r:0.5815
ne_en Dev loss: 0.4462 r:0.7266
ru_en Dev loss: 0.5050 r:0.7041
Current avg r:0.5639 Best avg r: 0.5847
16:04:06,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:31,741 root INFO 
id:ro_en cur r: 0.8074 best r: 0.8074
16:04:44,599 root INFO 
id:et_en cur r: 0.7236 best r: 0.7236
16:04:57,493 root INFO 
id:si_en cur r: 0.6088 best r: 0.6088
16:05:10,377 root INFO 
id:ne_en cur r: 0.7512 best r: 0.7512
16:05:23,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:53,67 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
16:06:53,73 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:06:53,78 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:06:53,82 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
16:06:53,87 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
16:06:53,91 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:06:53,95 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:07:05,931 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5327
en_de Dev loss: 0.8892 r:0.1545
en_zh Dev loss: 0.7939 r:0.3425
ro_en Dev loss: 0.3133 r:0.8039
et_en Dev loss: 0.3486 r:0.7207
si_en Dev loss: 0.5522 r:0.6123
ne_en Dev loss: 0.3768 r:0.7453
ru_en Dev loss: 0.4133 r:0.7400
Current avg r:0.5885 Best avg r: 0.5885
16:10:56,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:09,260 root INFO 
id:en_de cur r: 0.1846 best r: 0.1846
16:12:13,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:43,335 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5243
en_de Dev loss: 0.9026 r:0.1555
en_zh Dev loss: 0.8709 r:0.3314
ro_en Dev loss: 0.3639 r:0.8027
et_en Dev loss: 0.3622 r:0.7209
si_en Dev loss: 0.7388 r:0.5973
ne_en Dev loss: 0.4642 r:0.7408
ru_en Dev loss: 0.4877 r:0.7406
Current avg r:0.5842 Best avg r: 0.5885
16:17:33,810 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:46,673 root INFO 
id:en_de cur r: 0.1894 best r: 0.1894
16:17:59,534 root INFO 
id:ro_en cur r: 0.8126 best r: 0.8126
16:18:12,399 root INFO 
id:et_en cur r: 0.7249 best r: 0.7249
16:18:25,272 root INFO 
id:si_en cur r: 0.6116 best r: 0.6116
16:18:38,131 root INFO 
id:ne_en cur r: 0.7578 best r: 0.7578
16:18:50,948 root INFO 
id:ru_en cur r: 0.7583 best r: 0.7583
16:18:50,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:20,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
16:20:20,861 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:20:20,867 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:20:20,872 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
16:20:20,877 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
16:20:20,884 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:20:20,889 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:20:33,715 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5216
en_de Dev loss: 0.8747 r:0.1702
en_zh Dev loss: 0.8014 r:0.3424
ro_en Dev loss: 0.3141 r:0.8078
et_en Dev loss: 0.3747 r:0.7222
si_en Dev loss: 0.6049 r:0.6124
ne_en Dev loss: 0.3535 r:0.7565
ru_en Dev loss: 0.3843 r:0.7607
Current avg r:0.5960 Best avg r: 0.5960
16:24:25,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:51,348 root INFO 
id:ro_en cur r: 0.8129 best r: 0.8129
16:25:17,63 root INFO 
id:si_en cur r: 0.6195 best r: 0.6195
16:25:42,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:12,569 root INFO Epoch 1 Global steps: 9600 Train loss: 0.4793
en_de Dev loss: 0.9001 r:0.1619
en_zh Dev loss: 0.8408 r:0.3350
ro_en Dev loss: 0.3268 r:0.8086
et_en Dev loss: 0.3728 r:0.7224
si_en Dev loss: 0.5458 r:0.6224
ne_en Dev loss: 0.3432 r:0.7550
ru_en Dev loss: 0.4138 r:0.7522
Current avg r:0.5939 Best avg r: 0.5960
16:31:02,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:28,623 root INFO 
id:ro_en cur r: 0.8135 best r: 0.8135
16:31:41,500 root INFO 
id:et_en cur r: 0.7264 best r: 0.7264
16:32:20,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:49,959 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
16:33:49,967 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:33:49,972 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:33:49,977 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
16:33:49,981 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
16:33:49,986 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:33:49,992 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:34:02,817 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5134
en_de Dev loss: 0.8712 r:0.1664
en_zh Dev loss: 0.7617 r:0.3606
ro_en Dev loss: 0.3218 r:0.8076
et_en Dev loss: 0.3611 r:0.7256
si_en Dev loss: 0.5488 r:0.6197
ne_en Dev loss: 0.3550 r:0.7558
ru_en Dev loss: 0.4075 r:0.7555
Current avg r:0.5987 Best avg r: 0.5987
16:37:54,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:32,668 root INFO 
id:et_en cur r: 0.7268 best r: 0.7268
16:38:45,533 root INFO 
id:si_en cur r: 0.6224 best r: 0.6224
16:38:58,401 root INFO 
id:ne_en cur r: 0.7630 best r: 0.7630
16:39:11,222 root INFO 
id:ru_en cur r: 0.7687 best r: 0.7687
16:39:11,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:41,151 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
16:40:41,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:40:41,162 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:40:41,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
16:40:41,171 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
16:40:41,176 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:40:41,180 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:40:53,999 root INFO Epoch 1 Global steps: 10800 Train loss: 0.4936
en_de Dev loss: 0.8835 r:0.1590
en_zh Dev loss: 0.8004 r:0.3640
ro_en Dev loss: 0.3390 r:0.8071
et_en Dev loss: 0.3465 r:0.7265
si_en Dev loss: 0.6296 r:0.6236
ne_en Dev loss: 0.4145 r:0.7645
ru_en Dev loss: 0.3949 r:0.7711
Current avg r:0.6023 Best avg r: 0.6023
16:44:44,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:23,478 root INFO 
id:et_en cur r: 0.7310 best r: 0.7310
16:46:02,52 root INFO 
id:ru_en cur r: 0.7695 best r: 0.7695
16:46:02,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:31,986 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4577
en_de Dev loss: 0.8795 r:0.1517
en_zh Dev loss: 0.7799 r:0.3616
ro_en Dev loss: 0.3132 r:0.8076
et_en Dev loss: 0.3588 r:0.7293
si_en Dev loss: 0.5701 r:0.6261
ne_en Dev loss: 0.3617 r:0.7617
ru_en Dev loss: 0.3594 r:0.7718
Current avg r:0.6014 Best avg r: 0.6023
16:51:22,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:39,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:09,761 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4979
en_de Dev loss: 0.8899 r:0.1457
en_zh Dev loss: 0.8451 r:0.3523
ro_en Dev loss: 0.3788 r:0.8014
et_en Dev loss: 0.3751 r:0.7155
si_en Dev loss: 0.7229 r:0.6003
ne_en Dev loss: 0.4741 r:0.7511
ru_en Dev loss: 0.4267 r:0.7612
Current avg r:0.5897 Best avg r: 0.6023
16:58:00,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:17,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:47,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
17:00:47,861 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:00:47,867 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:00:47,871 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
17:00:47,876 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
17:00:47,880 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:00:47,886 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:01:00,702 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5063
en_de Dev loss: 0.8700 r:0.1592
en_zh Dev loss: 0.7471 r:0.3773
ro_en Dev loss: 0.3242 r:0.8094
et_en Dev loss: 0.3797 r:0.7249
si_en Dev loss: 0.5426 r:0.6174
ne_en Dev loss: 0.3451 r:0.7637
ru_en Dev loss: 0.3669 r:0.7683
Current avg r:0.6029 Best avg r: 0.6029
17:04:50,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:08,42 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:37,878 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4724
en_de Dev loss: 0.8680 r:0.1641
en_zh Dev loss: 0.7869 r:0.3583
ro_en Dev loss: 0.3182 r:0.8107
et_en Dev loss: 0.3531 r:0.7243
si_en Dev loss: 0.6011 r:0.6045
ne_en Dev loss: 0.3923 r:0.7566
ru_en Dev loss: 0.3865 r:0.7600
Current avg r:0.5969 Best avg r: 0.6029
17:11:28,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:45,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:15,476 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4688
en_de Dev loss: 0.8717 r:0.1632
en_zh Dev loss: 0.8231 r:0.3549
ro_en Dev loss: 0.3274 r:0.8121
et_en Dev loss: 0.3651 r:0.7206
si_en Dev loss: 0.6678 r:0.6039
ne_en Dev loss: 0.3934 r:0.7610
ru_en Dev loss: 0.4040 r:0.7595
Current avg r:0.5965 Best avg r: 0.6029
17:18:06,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:32,622 root INFO 
id:ro_en cur r: 0.8188 best r: 0.8188
17:18:45,500 root INFO 
id:et_en cur r: 0.7327 best r: 0.7327
17:19:11,234 root INFO 
id:ne_en cur r: 0.7668 best r: 0.7668
17:19:24,42 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:53,922 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4914
en_de Dev loss: 0.8938 r:0.1644
en_zh Dev loss: 0.8555 r:0.3582
ro_en Dev loss: 0.3178 r:0.8178
et_en Dev loss: 0.3654 r:0.7288
si_en Dev loss: 0.6518 r:0.6147
ne_en Dev loss: 0.3785 r:0.7668
ru_en Dev loss: 0.4072 r:0.7585
Current avg r:0.6013 Best avg r: 0.6029
17:24:44,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:01,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:31,311 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4969
en_de Dev loss: 0.9029 r:0.1557
en_zh Dev loss: 0.9212 r:0.3473
ro_en Dev loss: 0.3590 r:0.8178
et_en Dev loss: 0.3885 r:0.7266
si_en Dev loss: 0.8107 r:0.6061
ne_en Dev loss: 0.4349 r:0.7586
ru_en Dev loss: 0.4959 r:0.7411
Current avg r:0.5933 Best avg r: 0.6029
17:31:21,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:38,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:08,567 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4803
en_de Dev loss: 0.8782 r:0.1648
en_zh Dev loss: 0.8439 r:0.3473
ro_en Dev loss: 0.3341 r:0.8158
et_en Dev loss: 0.3573 r:0.7242
si_en Dev loss: 0.6652 r:0.6096
ne_en Dev loss: 0.3985 r:0.7644
ru_en Dev loss: 0.4288 r:0.7482
Current avg r:0.5963 Best avg r: 0.6029
17:37:59,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:16,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:46,944 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4450
en_de Dev loss: 0.8972 r:0.1568
en_zh Dev loss: 0.9219 r:0.3435
ro_en Dev loss: 0.3578 r:0.8172
et_en Dev loss: 0.3592 r:0.7215
si_en Dev loss: 0.7350 r:0.6113
ne_en Dev loss: 0.4484 r:0.7579
ru_en Dev loss: 0.4770 r:0.7421
Current avg r:0.5929 Best avg r: 0.6029
17:44:38,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:03,964 root INFO 
id:ro_en cur r: 0.8253 best r: 0.8253
17:45:16,846 root INFO 
id:et_en cur r: 0.7384 best r: 0.7384
17:45:29,722 root INFO 
id:si_en cur r: 0.6309 best r: 0.6309
17:45:55,414 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:25,270 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_de.lang_agnost_mlp.dev.best.scores
17:47:25,277 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:47:25,282 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:47:25,287 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/et_en.lang_agnost_mlp.dev.best.scores
17:47:25,292 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/si_en.lang_agnost_mlp.dev.best.scores
17:47:25,298 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:47:25,304 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_enzh/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:47:38,144 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4653
en_de Dev loss: 0.8775 r:0.1678
en_zh Dev loss: 0.8202 r:0.3534
ro_en Dev loss: 0.3206 r:0.8226
et_en Dev loss: 0.3544 r:0.7354
si_en Dev loss: 0.5637 r:0.6294
ne_en Dev loss: 0.3431 r:0.7670
ru_en Dev loss: 0.3989 r:0.7596
Current avg r:0.6050 Best avg r: 0.6050
17:51:29,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:46,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:16,175 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4405
en_de Dev loss: 0.8776 r:0.1636
en_zh Dev loss: 0.8604 r:0.3553
ro_en Dev loss: 0.3433 r:0.8148
et_en Dev loss: 0.3580 r:0.7218
si_en Dev loss: 0.7171 r:0.6119
ne_en Dev loss: 0.4401 r:0.7522
ru_en Dev loss: 0.4728 r:0.7470
Current avg r:0.5952 Best avg r: 0.6050
17:58:07,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:20,317 root INFO 
id:en_de cur r: 0.2056 best r: 0.2056
17:59:24,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:54,395 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4452
en_de Dev loss: 0.8722 r:0.1825
en_zh Dev loss: 0.8474 r:0.3643
ro_en Dev loss: 0.3402 r:0.8203
et_en Dev loss: 0.3422 r:0.7237
si_en Dev loss: 0.6592 r:0.6134
ne_en Dev loss: 0.4213 r:0.7652
ru_en Dev loss: 0.4285 r:0.7608
Current avg r:0.6043 Best avg r: 0.6050
18:04:46,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:59,204 root INFO 
id:en_de cur r: 0.2100 best r: 0.2100
18:06:03,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:33,235 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4139
en_de Dev loss: 0.8837 r:0.1915
en_zh Dev loss: 0.8833 r:0.3641
ro_en Dev loss: 0.3522 r:0.8155
et_en Dev loss: 0.3712 r:0.7139
si_en Dev loss: 0.7401 r:0.6075
ne_en Dev loss: 0.5143 r:0.7596
ru_en Dev loss: 0.4321 r:0.7612
Current avg r:0.6019 Best avg r: 0.6050
18:11:23,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:40,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:10,663 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4274
en_de Dev loss: 0.9094 r:0.1700
en_zh Dev loss: 0.9471 r:0.3657
ro_en Dev loss: 0.3992 r:0.8111
et_en Dev loss: 0.3809 r:0.7124
si_en Dev loss: 0.8897 r:0.6019
ne_en Dev loss: 0.5307 r:0.7529
ru_en Dev loss: 0.5100 r:0.7462
Current avg r:0.5943 Best avg r: 0.6050
18:18:01,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:19,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:48,942 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4550
en_de Dev loss: 0.8949 r:0.1636
en_zh Dev loss: 0.8759 r:0.3616
ro_en Dev loss: 0.3385 r:0.8155
et_en Dev loss: 0.3695 r:0.7139
si_en Dev loss: 0.6954 r:0.6097
ne_en Dev loss: 0.3834 r:0.7617
ru_en Dev loss: 0.4368 r:0.7430
Current avg r:0.5956 Best avg r: 0.6050
18:24:40,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:57,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:27,206 root INFO Epoch 2 Global steps: 20400 Train loss: 0.3962
en_de Dev loss: 0.8736 r:0.1638
en_zh Dev loss: 0.8254 r:0.3617
ro_en Dev loss: 0.3325 r:0.8126
et_en Dev loss: 0.3520 r:0.7177
si_en Dev loss: 0.6764 r:0.6115
ne_en Dev loss: 0.4138 r:0.7586
ru_en Dev loss: 0.4439 r:0.7435
Current avg r:0.5956 Best avg r: 0.6050
18:31:18,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:35,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:05,619 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4219
en_de Dev loss: 0.8798 r:0.1625
en_zh Dev loss: 0.8373 r:0.3624
ro_en Dev loss: 0.3546 r:0.8104
et_en Dev loss: 0.3698 r:0.7212
si_en Dev loss: 0.7224 r:0.6061
ne_en Dev loss: 0.4198 r:0.7564
ru_en Dev loss: 0.4102 r:0.7577
Current avg r:0.5967 Best avg r: 0.6050
18:37:56,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:13,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:43,286 root INFO Epoch 2 Global steps: 21600 Train loss: 0.3870
en_de Dev loss: 0.8831 r:0.1470
en_zh Dev loss: 0.8365 r:0.3565
ro_en Dev loss: 0.3293 r:0.8114
et_en Dev loss: 0.3465 r:0.7204
si_en Dev loss: 0.6733 r:0.6111
ne_en Dev loss: 0.4203 r:0.7531
ru_en Dev loss: 0.4255 r:0.7464
Current avg r:0.5923 Best avg r: 0.6050
18:44:34,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:51,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:20,923 root INFO Epoch 2 Global steps: 22200 Train loss: 0.3868
en_de Dev loss: 0.8786 r:0.1606
en_zh Dev loss: 0.8715 r:0.3515
ro_en Dev loss: 0.3703 r:0.8111
et_en Dev loss: 0.3927 r:0.7200
si_en Dev loss: 0.6344 r:0.6151
ne_en Dev loss: 0.3952 r:0.7605
ru_en Dev loss: 0.4409 r:0.7456
Current avg r:0.5949 Best avg r: 0.6050
18:51:12,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:29,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:59,139 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4080
en_de Dev loss: 0.8706 r:0.1669
en_zh Dev loss: 0.8737 r:0.3558
ro_en Dev loss: 0.3194 r:0.8176
et_en Dev loss: 0.3609 r:0.7161
si_en Dev loss: 0.7589 r:0.6047
ne_en Dev loss: 0.4691 r:0.7572
ru_en Dev loss: 0.4367 r:0.7393
Current avg r:0.5939 Best avg r: 0.6050
18:57:49,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:07,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:37,87 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4378
en_de Dev loss: 0.8904 r:0.1796
en_zh Dev loss: 0.9284 r:0.3532
ro_en Dev loss: 0.3599 r:0.8185
et_en Dev loss: 0.3794 r:0.7167
si_en Dev loss: 0.7014 r:0.6169
ne_en Dev loss: 0.4593 r:0.7594
ru_en Dev loss: 0.4545 r:0.7418
Current avg r:0.5980 Best avg r: 0.6050
19:04:27,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:40,594 root INFO 
id:en_de cur r: 0.2125 best r: 0.2125
19:05:44,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:14,676 root INFO Epoch 2 Global steps: 24000 Train loss: 0.3907
en_de Dev loss: 0.8828 r:0.1819
en_zh Dev loss: 0.9171 r:0.3567
ro_en Dev loss: 0.3622 r:0.8203
et_en Dev loss: 0.4168 r:0.7196
si_en Dev loss: 0.6713 r:0.6201
ne_en Dev loss: 0.4062 r:0.7625
ru_en Dev loss: 0.4529 r:0.7447
Current avg r:0.6008 Best avg r: 0.6050
19:11:05,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:18,575 root INFO 
id:en_de cur r: 0.2189 best r: 0.2189
19:12:22,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:52,696 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4280
en_de Dev loss: 0.8726 r:0.1868
en_zh Dev loss: 0.9238 r:0.3477
ro_en Dev loss: 0.3510 r:0.8200
et_en Dev loss: 0.3973 r:0.7095
si_en Dev loss: 0.7226 r:0.6155
ne_en Dev loss: 0.4175 r:0.7606
ru_en Dev loss: 0.4952 r:0.7258
Current avg r:0.5951 Best avg r: 0.6050
19:17:43,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:01,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:31,42 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4073
en_de Dev loss: 0.8633 r:0.1801
en_zh Dev loss: 0.8924 r:0.3320
ro_en Dev loss: 0.3236 r:0.8205
et_en Dev loss: 0.3976 r:0.7003
si_en Dev loss: 0.7501 r:0.6020
ne_en Dev loss: 0.4625 r:0.7535
ru_en Dev loss: 0.5074 r:0.6975
Current avg r:0.5837 Best avg r: 0.6050
19:24:22,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:35,140 root INFO 
id:en_de cur r: 0.2307 best r: 0.2307
19:25:39,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:09,359 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4112
en_de Dev loss: 0.8637 r:0.1945
en_zh Dev loss: 0.8804 r:0.3509
ro_en Dev loss: 0.3148 r:0.8229
et_en Dev loss: 0.3799 r:0.7077
si_en Dev loss: 0.6638 r:0.6168
ne_en Dev loss: 0.4679 r:0.7608
ru_en Dev loss: 0.4633 r:0.7225
Current avg r:0.5966 Best avg r: 0.6050
19:31:00,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:17,712 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:47,642 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4254
en_de Dev loss: 0.8760 r:0.1810
en_zh Dev loss: 0.9082 r:0.3475
ro_en Dev loss: 0.3463 r:0.8192
et_en Dev loss: 0.3901 r:0.7083
si_en Dev loss: 0.7084 r:0.6114
ne_en Dev loss: 0.4357 r:0.7597
ru_en Dev loss: 0.4908 r:0.7259
Current avg r:0.5933 Best avg r: 0.6050
19:37:39,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:56,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:26,165 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4187
en_de Dev loss: 0.8636 r:0.1926
en_zh Dev loss: 0.8956 r:0.3553
ro_en Dev loss: 0.3581 r:0.8226
et_en Dev loss: 0.4042 r:0.7161
si_en Dev loss: 0.6720 r:0.6222
ne_en Dev loss: 0.4323 r:0.7600
ru_en Dev loss: 0.4518 r:0.7507
Current avg r:0.6028 Best avg r: 0.6050
19:44:18,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:35,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:05,169 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3702
en_de Dev loss: 0.8682 r:0.1908
en_zh Dev loss: 0.8981 r:0.3440
ro_en Dev loss: 0.3419 r:0.8172
et_en Dev loss: 0.3776 r:0.7008
si_en Dev loss: 0.7113 r:0.6052
ne_en Dev loss: 0.3942 r:0.7614
ru_en Dev loss: 0.4544 r:0.7343
Current avg r:0.5934 Best avg r: 0.6050
19:50:56,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:09,111 root INFO 
id:en_de cur r: 0.2407 best r: 0.2407
19:52:13,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:43,411 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3534
en_de Dev loss: 0.8608 r:0.2101
en_zh Dev loss: 0.9016 r:0.3526
ro_en Dev loss: 0.3236 r:0.8189
et_en Dev loss: 0.3854 r:0.6971
si_en Dev loss: 0.7681 r:0.6013
ne_en Dev loss: 0.4304 r:0.7609
ru_en Dev loss: 0.4550 r:0.7367
Current avg r:0.5968 Best avg r: 0.6050
19:57:34,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:51,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:21,795 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3657
en_de Dev loss: 0.8654 r:0.1945
en_zh Dev loss: 0.8639 r:0.3531
ro_en Dev loss: 0.3286 r:0.8214
et_en Dev loss: 0.4106 r:0.7022
si_en Dev loss: 0.6653 r:0.6122
ne_en Dev loss: 0.3807 r:0.7585
ru_en Dev loss: 0.4324 r:0.7413
Current avg r:0.5976 Best avg r: 0.6050
20:04:12,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:29,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:59,288 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3446
en_de Dev loss: 0.8995 r:0.1691
en_zh Dev loss: 1.0107 r:0.3306
ro_en Dev loss: 0.4035 r:0.8138
et_en Dev loss: 0.4148 r:0.6934
si_en Dev loss: 0.8260 r:0.5957
ne_en Dev loss: 0.5125 r:0.7510
ru_en Dev loss: 0.5668 r:0.6974
Current avg r:0.5787 Best avg r: 0.6050
20:10:50,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:07,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:37,775 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3696
en_de Dev loss: 0.8723 r:0.1865
en_zh Dev loss: 0.8666 r:0.3506
ro_en Dev loss: 0.3367 r:0.8202
et_en Dev loss: 0.4045 r:0.7048
si_en Dev loss: 0.6517 r:0.6162
ne_en Dev loss: 0.3921 r:0.7570
ru_en Dev loss: 0.4273 r:0.7439
Current avg r:0.5970 Best avg r: 0.6050
20:17:29,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:46,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:16,216 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3897
en_de Dev loss: 0.8687 r:0.1730
en_zh Dev loss: 0.9156 r:0.3488
ro_en Dev loss: 0.3577 r:0.8160
et_en Dev loss: 0.4076 r:0.6978
si_en Dev loss: 0.7687 r:0.6064
ne_en Dev loss: 0.4828 r:0.7516
ru_en Dev loss: 0.4593 r:0.7338
Current avg r:0.5896 Best avg r: 0.6050
20:24:07,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:24,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:54,809 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3402
en_de Dev loss: 0.8799 r:0.1700
en_zh Dev loss: 0.8839 r:0.3483
ro_en Dev loss: 0.3496 r:0.8150
et_en Dev loss: 0.4404 r:0.7087
si_en Dev loss: 0.6470 r:0.6184
ne_en Dev loss: 0.3970 r:0.7475
ru_en Dev loss: 0.4372 r:0.7398
Current avg r:0.5925 Best avg r: 0.6050
20:30:45,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:02,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:32,808 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3462
en_de Dev loss: 0.8702 r:0.1861
en_zh Dev loss: 0.8985 r:0.3306
ro_en Dev loss: 0.3545 r:0.8118
et_en Dev loss: 0.4313 r:0.7018
si_en Dev loss: 0.7067 r:0.6059
ne_en Dev loss: 0.4041 r:0.7507
ru_en Dev loss: 0.4313 r:0.7393
Current avg r:0.5895 Best avg r: 0.6050
20:37:23,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:49,671 root INFO 
id:ro_en cur r: 0.8261 best r: 0.8261
20:38:41,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:10,945 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3452
en_de Dev loss: 0.8711 r:0.1842
en_zh Dev loss: 0.8933 r:0.3325
ro_en Dev loss: 0.3060 r:0.8252
et_en Dev loss: 0.3967 r:0.7118
si_en Dev loss: 0.6129 r:0.6280
ne_en Dev loss: 0.3542 r:0.7551
ru_en Dev loss: 0.4322 r:0.7441
Current avg r:0.5973 Best avg r: 0.6050
20:44:01,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:19,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:48,964 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3712
en_de Dev loss: 0.8600 r:0.2040
en_zh Dev loss: 0.8790 r:0.3437
ro_en Dev loss: 0.3366 r:0.8191
et_en Dev loss: 0.4144 r:0.7057
si_en Dev loss: 0.6893 r:0.6123
ne_en Dev loss: 0.4020 r:0.7563
ru_en Dev loss: 0.4429 r:0.7322
Current avg r:0.5962 Best avg r: 0.6050
20:50:40,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:57,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:27,58 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3659
en_de Dev loss: 0.8619 r:0.2008
en_zh Dev loss: 0.9053 r:0.3455
ro_en Dev loss: 0.3742 r:0.8169
et_en Dev loss: 0.4639 r:0.7034
si_en Dev loss: 0.7487 r:0.6090
ne_en Dev loss: 0.4393 r:0.7558
ru_en Dev loss: 0.5007 r:0.7245
Current avg r:0.5937 Best avg r: 0.6050
20:57:17,726 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:34,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:04,690 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3349
en_de Dev loss: 0.8705 r:0.1817
en_zh Dev loss: 0.9360 r:0.3287
ro_en Dev loss: 0.3375 r:0.8168
et_en Dev loss: 0.4272 r:0.6991
si_en Dev loss: 0.6818 r:0.6086
ne_en Dev loss: 0.4278 r:0.7463
ru_en Dev loss: 0.4664 r:0.7205
Current avg r:0.5860 Best avg r: 0.6050
21:03:55,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:12,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:42,237 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3452
en_de Dev loss: 0.8659 r:0.1874
en_zh Dev loss: 0.9165 r:0.3528
ro_en Dev loss: 0.3349 r:0.8199
et_en Dev loss: 0.4052 r:0.6970
si_en Dev loss: 0.7625 r:0.6011
ne_en Dev loss: 0.5151 r:0.7505
ru_en Dev loss: 0.4694 r:0.7303
Current avg r:0.5913 Best avg r: 0.6050
21:10:32,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:49,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:19,640 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3624
en_de Dev loss: 0.9001 r:0.1755
en_zh Dev loss: 1.0179 r:0.3408
ro_en Dev loss: 0.3735 r:0.8200
et_en Dev loss: 0.4272 r:0.6986
si_en Dev loss: 0.8667 r:0.5953
ne_en Dev loss: 0.5633 r:0.7423
ru_en Dev loss: 0.5558 r:0.7186
Current avg r:0.5845 Best avg r: 0.6050
21:17:10,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:27,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:57,351 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3405
en_de Dev loss: 0.8629 r:0.1759
en_zh Dev loss: 0.8461 r:0.3456
ro_en Dev loss: 0.3147 r:0.8182
et_en Dev loss: 0.3945 r:0.7057
si_en Dev loss: 0.7208 r:0.5926
ne_en Dev loss: 0.4637 r:0.7508
ru_en Dev loss: 0.3913 r:0.7504
Current avg r:0.5913 Best avg r: 0.6050
21:23:49,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:06,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:36,188 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3008
en_de Dev loss: 0.8655 r:0.1895
en_zh Dev loss: 0.9092 r:0.3327
ro_en Dev loss: 0.3372 r:0.8170
et_en Dev loss: 0.4167 r:0.6974
si_en Dev loss: 0.7374 r:0.5957
ne_en Dev loss: 0.4611 r:0.7463
ru_en Dev loss: 0.4342 r:0.7432
Current avg r:0.5888 Best avg r: 0.6050
21:30:27,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:44,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:14,438 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3119
en_de Dev loss: 0.8823 r:0.1787
en_zh Dev loss: 0.9659 r:0.3197
ro_en Dev loss: 0.3524 r:0.8197
et_en Dev loss: 0.4434 r:0.6922
si_en Dev loss: 0.7861 r:0.5957
ne_en Dev loss: 0.5061 r:0.7414
ru_en Dev loss: 0.4811 r:0.7257
Current avg r:0.5819 Best avg r: 0.6050
21:37:05,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:22,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:52,87 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3072
en_de Dev loss: 0.8806 r:0.1877
en_zh Dev loss: 0.9376 r:0.3284
ro_en Dev loss: 0.3510 r:0.8206
et_en Dev loss: 0.4063 r:0.6979
si_en Dev loss: 0.7555 r:0.5921
ne_en Dev loss: 0.4528 r:0.7400
ru_en Dev loss: 0.4678 r:0.7329
Current avg r:0.5857 Best avg r: 0.6050
21:43:42,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:59,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:29,778 root INFO Epoch 4 Global steps: 38400 Train loss: 0.2964
en_de Dev loss: 0.8655 r:0.1995
en_zh Dev loss: 0.9300 r:0.3242
ro_en Dev loss: 0.3435 r:0.8179
et_en Dev loss: 0.4250 r:0.6899
si_en Dev loss: 0.7820 r:0.5861
ne_en Dev loss: 0.5274 r:0.7331
ru_en Dev loss: 0.4546 r:0.7274
Current avg r:0.5826 Best avg r: 0.6050
21:50:20,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:37,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:07,366 root INFO Epoch 4 Global steps: 39000 Train loss: 0.2960
en_de Dev loss: 0.8911 r:0.1849
en_zh Dev loss: 0.9590 r:0.3356
ro_en Dev loss: 0.3624 r:0.8212
et_en Dev loss: 0.4341 r:0.7014
si_en Dev loss: 0.7608 r:0.5979
ne_en Dev loss: 0.4442 r:0.7416
ru_en Dev loss: 0.4497 r:0.7502
Current avg r:0.5904 Best avg r: 0.6050
21:56:57,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:15,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:44,928 root INFO Epoch 4 Global steps: 39600 Train loss: 0.2973
en_de Dev loss: 0.8779 r:0.1944
en_zh Dev loss: 0.9291 r:0.3460
ro_en Dev loss: 0.3408 r:0.8207
et_en Dev loss: 0.4226 r:0.6950
si_en Dev loss: 0.8136 r:0.5887
ne_en Dev loss: 0.5306 r:0.7322
ru_en Dev loss: 0.4650 r:0.7434
Current avg r:0.5886 Best avg r: 0.6050
22:03:35,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:52,546 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:22,387 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3152
en_de Dev loss: 0.8776 r:0.1784
en_zh Dev loss: 0.9205 r:0.3352
ro_en Dev loss: 0.3573 r:0.8204
et_en Dev loss: 0.4567 r:0.6953
si_en Dev loss: 0.7412 r:0.5909
ne_en Dev loss: 0.4533 r:0.7348
ru_en Dev loss: 0.4642 r:0.7323
Current avg r:0.5839 Best avg r: 0.6050
22:10:12,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:30,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:59,888 root INFO Epoch 4 Global steps: 40800 Train loss: 0.2922
en_de Dev loss: 0.8930 r:0.1764
en_zh Dev loss: 0.9408 r:0.3273
ro_en Dev loss: 0.3480 r:0.8182
et_en Dev loss: 0.4466 r:0.6880
si_en Dev loss: 0.7817 r:0.5748
ne_en Dev loss: 0.4863 r:0.7284
ru_en Dev loss: 0.4886 r:0.7187
Current avg r:0.5760 Best avg r: 0.6050
22:16:50,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:08,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:37,842 root INFO Epoch 4 Global steps: 41400 Train loss: 0.2941
en_de Dev loss: 0.8848 r:0.1892
en_zh Dev loss: 0.9199 r:0.3305
ro_en Dev loss: 0.3478 r:0.8213
et_en Dev loss: 0.4459 r:0.6885
si_en Dev loss: 0.7591 r:0.5861
ne_en Dev loss: 0.4672 r:0.7344
ru_en Dev loss: 0.4644 r:0.7318
Current avg r:0.5831 Best avg r: 0.6050
22:23:28,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:45,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:15,779 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3287
en_de Dev loss: 0.8979 r:0.1953
en_zh Dev loss: 1.0238 r:0.3209
ro_en Dev loss: 0.3726 r:0.8148
et_en Dev loss: 0.4235 r:0.6882
si_en Dev loss: 0.9335 r:0.5731
ne_en Dev loss: 0.5736 r:0.7357
ru_en Dev loss: 0.5466 r:0.7193
Current avg r:0.5782 Best avg r: 0.6050
22:30:06,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:24,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:53,837 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3000
en_de Dev loss: 0.8658 r:0.1987
en_zh Dev loss: 0.9522 r:0.3364
ro_en Dev loss: 0.3478 r:0.8197
et_en Dev loss: 0.4377 r:0.6892
si_en Dev loss: 0.8107 r:0.5815
ne_en Dev loss: 0.5158 r:0.7430
ru_en Dev loss: 0.4571 r:0.7393
Current avg r:0.5868 Best avg r: 0.6050
22:36:44,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:01,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:31,800 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3004
en_de Dev loss: 0.8867 r:0.1858
en_zh Dev loss: 0.9814 r:0.3329
ro_en Dev loss: 0.3507 r:0.8209
et_en Dev loss: 0.4244 r:0.6946
si_en Dev loss: 0.8013 r:0.5913
ne_en Dev loss: 0.5471 r:0.7336
ru_en Dev loss: 0.4817 r:0.7421
Current avg r:0.5859 Best avg r: 0.6050
22:43:23,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:40,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:10,655 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3094
en_de Dev loss: 0.8760 r:0.1966
en_zh Dev loss: 0.9673 r:0.3313
ro_en Dev loss: 0.3622 r:0.8170
et_en Dev loss: 0.4761 r:0.6854
si_en Dev loss: 0.8200 r:0.5777
ne_en Dev loss: 0.5855 r:0.7271
ru_en Dev loss: 0.5018 r:0.7155
Current avg r:0.5786 Best avg r: 0.6050
22:50:02,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:19,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:49,311 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2817
en_de Dev loss: 0.8796 r:0.1916
en_zh Dev loss: 0.9354 r:0.3256
ro_en Dev loss: 0.3487 r:0.8220
et_en Dev loss: 0.5083 r:0.6958
si_en Dev loss: 0.7471 r:0.5929
ne_en Dev loss: 0.4582 r:0.7380
ru_en Dev loss: 0.4527 r:0.7413
Current avg r:0.5867 Best avg r: 0.6050
22:56:41,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:58,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:28,372 root INFO Epoch 4 Global steps: 45000 Train loss: 0.2851
en_de Dev loss: 0.8979 r:0.1641
en_zh Dev loss: 0.9984 r:0.3129
ro_en Dev loss: 0.3592 r:0.8154
et_en Dev loss: 0.4450 r:0.6826
si_en Dev loss: 0.8551 r:0.5796
ne_en Dev loss: 0.4603 r:0.7405
ru_en Dev loss: 0.5023 r:0.7256
Current avg r:0.5744 Best avg r: 0.6050
23:03:20,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:37,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:07,416 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2528
en_de Dev loss: 0.8869 r:0.1542
en_zh Dev loss: 0.9485 r:0.3141
ro_en Dev loss: 0.3568 r:0.8121
et_en Dev loss: 0.4547 r:0.6807
si_en Dev loss: 0.8701 r:0.5761
ne_en Dev loss: 0.5095 r:0.7302
ru_en Dev loss: 0.4349 r:0.7418
Current avg r:0.5727 Best avg r: 0.6050
23:09:58,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:15,458 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:45,284 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2711
en_de Dev loss: 0.9020 r:0.1470
en_zh Dev loss: 0.9729 r:0.3068
ro_en Dev loss: 0.3530 r:0.8174
et_en Dev loss: 0.4556 r:0.6839
si_en Dev loss: 0.8315 r:0.5829
ne_en Dev loss: 0.5453 r:0.7208
ru_en Dev loss: 0.4750 r:0.7285
Current avg r:0.5696 Best avg r: 0.6050
23:16:36,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:53,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:23,119 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2500
en_de Dev loss: 0.9088 r:0.1317
en_zh Dev loss: 0.9917 r:0.2968
ro_en Dev loss: 0.3540 r:0.8169
et_en Dev loss: 0.4725 r:0.6801
si_en Dev loss: 0.8621 r:0.5779
ne_en Dev loss: 0.5210 r:0.7219
ru_en Dev loss: 0.4887 r:0.7152
Current avg r:0.5630 Best avg r: 0.6050
23:23:13,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:30,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:00,596 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2571
en_de Dev loss: 0.8999 r:0.1303
en_zh Dev loss: 0.9337 r:0.3058
ro_en Dev loss: 0.3495 r:0.8139
et_en Dev loss: 0.4569 r:0.6802
si_en Dev loss: 0.8137 r:0.5753
ne_en Dev loss: 0.4397 r:0.7321
ru_en Dev loss: 0.4340 r:0.7301
Current avg r:0.5668 Best avg r: 0.6050
23:29:50,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:07,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:32:37,726 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2540
en_de Dev loss: 0.9067 r:0.1467
en_zh Dev loss: 1.0064 r:0.3071
ro_en Dev loss: 0.3667 r:0.8169
et_en Dev loss: 0.4525 r:0.6797
si_en Dev loss: 0.8860 r:0.5777
ne_en Dev loss: 0.5209 r:0.7273
ru_en Dev loss: 0.4838 r:0.7252
Current avg r:0.5687 Best avg r: 0.6050
23:36:28,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:46,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:16,166 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2618
en_de Dev loss: 0.9057 r:0.1426
en_zh Dev loss: 1.0128 r:0.3017
ro_en Dev loss: 0.3798 r:0.8121
et_en Dev loss: 0.4620 r:0.6737
si_en Dev loss: 0.9477 r:0.5748
ne_en Dev loss: 0.5904 r:0.7283
ru_en Dev loss: 0.4870 r:0.7232
Current avg r:0.5652 Best avg r: 0.6050
23:43:07,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:24,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:54,453 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2681
en_de Dev loss: 0.8941 r:0.1603
en_zh Dev loss: 1.0016 r:0.3140
ro_en Dev loss: 0.3963 r:0.8102
et_en Dev loss: 0.4802 r:0.6779
si_en Dev loss: 0.9739 r:0.5748
ne_en Dev loss: 0.6467 r:0.7291
ru_en Dev loss: 0.4901 r:0.7293
Current avg r:0.5708 Best avg r: 0.6050
23:49:44,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:02,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:31,866 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2636
en_de Dev loss: 0.9057 r:0.1577
en_zh Dev loss: 0.9905 r:0.3228
ro_en Dev loss: 0.3876 r:0.8084
et_en Dev loss: 0.4477 r:0.6824
si_en Dev loss: 0.9124 r:0.5753
ne_en Dev loss: 0.5409 r:0.7308
ru_en Dev loss: 0.4678 r:0.7361
Current avg r:0.5734 Best avg r: 0.6050
23:56:22,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:39,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:09,876 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2677
en_de Dev loss: 0.9120 r:0.1368
en_zh Dev loss: 1.0275 r:0.3030
ro_en Dev loss: 0.3694 r:0.8140
et_en Dev loss: 0.4511 r:0.6837
si_en Dev loss: 0.8653 r:0.5807
ne_en Dev loss: 0.5037 r:0.7387
ru_en Dev loss: 0.4994 r:0.7234
Current avg r:0.5686 Best avg r: 0.6050
00:03:00,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:18,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:47,944 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2525
en_de Dev loss: 0.9137 r:0.1528
en_zh Dev loss: 0.9758 r:0.3194
ro_en Dev loss: 0.3635 r:0.8152
et_en Dev loss: 0.4716 r:0.6786
si_en Dev loss: 0.8681 r:0.5740
ne_en Dev loss: 0.5254 r:0.7341
ru_en Dev loss: 0.4903 r:0.7267
Current avg r:0.5716 Best avg r: 0.6050
00:09:38,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:55,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:25,283 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2488
en_de Dev loss: 0.9194 r:0.1354
en_zh Dev loss: 0.9442 r:0.3292
ro_en Dev loss: 0.3673 r:0.8119
et_en Dev loss: 0.4837 r:0.6772
si_en Dev loss: 0.8591 r:0.5724
ne_en Dev loss: 0.5119 r:0.7288
ru_en Dev loss: 0.4524 r:0.7452
Current avg r:0.5714 Best avg r: 0.6050
00:16:16,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:33,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:03,196 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2430
en_de Dev loss: 0.9283 r:0.1403
en_zh Dev loss: 1.0122 r:0.3193
ro_en Dev loss: 0.3794 r:0.8172
et_en Dev loss: 0.4755 r:0.6792
si_en Dev loss: 0.8214 r:0.5850
ne_en Dev loss: 0.5061 r:0.7298
ru_en Dev loss: 0.4951 r:0.7331
Current avg r:0.5720 Best avg r: 0.6050
00:22:53,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:10,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:40,720 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2527
en_de Dev loss: 0.9068 r:0.1463
en_zh Dev loss: 0.9512 r:0.3220
ro_en Dev loss: 0.3915 r:0.8114
et_en Dev loss: 0.5144 r:0.6745
si_en Dev loss: 0.8533 r:0.5723
ne_en Dev loss: 0.5112 r:0.7289
ru_en Dev loss: 0.4802 r:0.7290
Current avg r:0.5692 Best avg r: 0.6050
00:29:31,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:30:48,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:18,301 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2396
en_de Dev loss: 0.9243 r:0.1327
en_zh Dev loss: 0.9736 r:0.3284
ro_en Dev loss: 0.4036 r:0.8171
et_en Dev loss: 0.5241 r:0.6751
si_en Dev loss: 0.8560 r:0.5730
ne_en Dev loss: 0.5294 r:0.7335
ru_en Dev loss: 0.4798 r:0.7352
Current avg r:0.5707 Best avg r: 0.6050
00:36:08,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:26,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:56,86 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2460
en_de Dev loss: 0.9284 r:0.1315
en_zh Dev loss: 1.0266 r:0.3195
ro_en Dev loss: 0.3831 r:0.8163
et_en Dev loss: 0.4687 r:0.6753
si_en Dev loss: 0.9111 r:0.5654
ne_en Dev loss: 0.5901 r:0.7351
ru_en Dev loss: 0.5293 r:0.7208
Current avg r:0.5663 Best avg r: 0.6050
00:42:47,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:04,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:34,822 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2175
en_de Dev loss: 0.9270 r:0.1492
en_zh Dev loss: 1.0004 r:0.3195
ro_en Dev loss: 0.3544 r:0.8189
et_en Dev loss: 0.4731 r:0.6808
si_en Dev loss: 0.8411 r:0.5675
ne_en Dev loss: 0.5070 r:0.7349
ru_en Dev loss: 0.4709 r:0.7340
Current avg r:0.5721 Best avg r: 0.6050
00:49:25,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:42,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:12,244 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2127
en_de Dev loss: 0.8873 r:0.1621
en_zh Dev loss: 0.9248 r:0.3227
ro_en Dev loss: 0.3578 r:0.8161
et_en Dev loss: 0.4758 r:0.6829
si_en Dev loss: 0.8486 r:0.5648
ne_en Dev loss: 0.5124 r:0.7333
ru_en Dev loss: 0.4227 r:0.7408
Current avg r:0.5747 Best avg r: 0.6050
00:56:02,553 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:19,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:49,492 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2253
en_de Dev loss: 0.9086 r:0.1354
en_zh Dev loss: 0.9796 r:0.3111
ro_en Dev loss: 0.3514 r:0.8166
et_en Dev loss: 0.4913 r:0.6763
si_en Dev loss: 0.7840 r:0.5676
ne_en Dev loss: 0.4927 r:0.7230
ru_en Dev loss: 0.4423 r:0.7395
Current avg r:0.5671 Best avg r: 0.6050
01:02:40,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:57,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:26,961 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2129
en_de Dev loss: 0.9100 r:0.1559
en_zh Dev loss: 0.9921 r:0.2987
ro_en Dev loss: 0.3688 r:0.8138
et_en Dev loss: 0.4684 r:0.6710
si_en Dev loss: 0.8530 r:0.5599
ne_en Dev loss: 0.5465 r:0.7200
ru_en Dev loss: 0.4666 r:0.7332
Current avg r:0.5646 Best avg r: 0.6050
01:09:17,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:34,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:04,257 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2104
en_de Dev loss: 0.9237 r:0.1544
en_zh Dev loss: 1.0315 r:0.2964
ro_en Dev loss: 0.3648 r:0.8205
et_en Dev loss: 0.4576 r:0.6781
si_en Dev loss: 0.8272 r:0.5699
ne_en Dev loss: 0.5034 r:0.7298
ru_en Dev loss: 0.4790 r:0.7368
Current avg r:0.5694 Best avg r: 0.6050
01:15:54,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:11,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:41,716 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2207
en_de Dev loss: 0.9164 r:0.1354
en_zh Dev loss: 0.9766 r:0.3068
ro_en Dev loss: 0.3520 r:0.8175
et_en Dev loss: 0.4759 r:0.6761
si_en Dev loss: 0.8149 r:0.5662
ne_en Dev loss: 0.5342 r:0.7228
ru_en Dev loss: 0.4717 r:0.7310
Current avg r:0.5651 Best avg r: 0.6050
01:22:32,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:49,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:19,66 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2292
en_de Dev loss: 0.9339 r:0.1299
en_zh Dev loss: 1.0479 r:0.2889
ro_en Dev loss: 0.3701 r:0.8156
et_en Dev loss: 0.4715 r:0.6698
si_en Dev loss: 0.8875 r:0.5678
ne_en Dev loss: 0.5791 r:0.7263
ru_en Dev loss: 0.4815 r:0.7304
Current avg r:0.5612 Best avg r: 0.6050
01:29:09,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:26,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:31:56,396 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2158
en_de Dev loss: 0.9445 r:0.1418
en_zh Dev loss: 1.0440 r:0.2931
ro_en Dev loss: 0.3680 r:0.8167
et_en Dev loss: 0.4972 r:0.6692
si_en Dev loss: 0.8934 r:0.5614
ne_en Dev loss: 0.5271 r:0.7263
ru_en Dev loss: 0.4700 r:0.7375
Current avg r:0.5637 Best avg r: 0.6050
01:35:46,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:37:03,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:33,533 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2161
en_de Dev loss: 0.8919 r:0.1603
en_zh Dev loss: 0.9597 r:0.3008
ro_en Dev loss: 0.3390 r:0.8154
et_en Dev loss: 0.4681 r:0.6731
si_en Dev loss: 0.8773 r:0.5622
ne_en Dev loss: 0.5114 r:0.7316
ru_en Dev loss: 0.4311 r:0.7415
Current avg r:0.5693 Best avg r: 0.6050
01:42:23,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:40,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:10,936 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2123
en_de Dev loss: 0.9221 r:0.1384
en_zh Dev loss: 1.0028 r:0.2991
ro_en Dev loss: 0.3599 r:0.8161
et_en Dev loss: 0.4898 r:0.6641
si_en Dev loss: 0.8643 r:0.5563
ne_en Dev loss: 0.5542 r:0.7156
ru_en Dev loss: 0.4834 r:0.7270
Current avg r:0.5595 Best avg r: 0.6050
01:49:01,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:19,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:48,877 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2188
en_de Dev loss: 0.9132 r:0.1466
en_zh Dev loss: 0.9659 r:0.3123
ro_en Dev loss: 0.3642 r:0.8169
et_en Dev loss: 0.4580 r:0.6766
si_en Dev loss: 0.8637 r:0.5643
ne_en Dev loss: 0.5363 r:0.7302
ru_en Dev loss: 0.4517 r:0.7361
Current avg r:0.5690 Best avg r: 0.6050
01:55:39,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:56:56,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:58:26,452 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2216
en_de Dev loss: 0.9413 r:0.1246
en_zh Dev loss: 1.0305 r:0.3140
ro_en Dev loss: 0.3849 r:0.8199
et_en Dev loss: 0.4811 r:0.6671
si_en Dev loss: 0.9150 r:0.5619
ne_en Dev loss: 0.5639 r:0.7258
ru_en Dev loss: 0.4800 r:0.7353
Current avg r:0.5641 Best avg r: 0.6050
02:02:21,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:03:38,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:05:09,690 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2246
en_de Dev loss: 0.9153 r:0.1407
en_zh Dev loss: 0.9417 r:0.3147
ro_en Dev loss: 0.3458 r:0.8195
et_en Dev loss: 0.4744 r:0.6715
si_en Dev loss: 0.8178 r:0.5612
ne_en Dev loss: 0.5181 r:0.7202
ru_en Dev loss: 0.4151 r:0.7489
Current avg r:0.5681 Best avg r: 0.6050
02:09:03,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:10:21,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:11:52,302 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2040
en_de Dev loss: 0.9314 r:0.1201
en_zh Dev loss: 0.9630 r:0.3106
ro_en Dev loss: 0.3603 r:0.8176
et_en Dev loss: 0.5050 r:0.6660
si_en Dev loss: 0.8018 r:0.5631
ne_en Dev loss: 0.5564 r:0.7149
ru_en Dev loss: 0.4568 r:0.7306
Current avg r:0.5604 Best avg r: 0.6050
02:15:47,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:17:05,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:18:35,813 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2089
en_de Dev loss: 0.9341 r:0.1391
en_zh Dev loss: 1.0262 r:0.3003
ro_en Dev loss: 0.3554 r:0.8200
et_en Dev loss: 0.4906 r:0.6727
si_en Dev loss: 0.8448 r:0.5592
ne_en Dev loss: 0.5364 r:0.7192
ru_en Dev loss: 0.4411 r:0.7476
Current avg r:0.5654 Best avg r: 0.6050
02:22:32,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:23:49,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:20,643 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1905
en_de Dev loss: 0.9202 r:0.1208
en_zh Dev loss: 0.9497 r:0.3011
ro_en Dev loss: 0.3491 r:0.8177
et_en Dev loss: 0.4863 r:0.6715
si_en Dev loss: 0.8026 r:0.5579
ne_en Dev loss: 0.5112 r:0.7187
ru_en Dev loss: 0.4550 r:0.7309
Current avg r:0.5598 Best avg r: 0.6050
02:29:14,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:30:31,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:32:01,313 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1865
en_de Dev loss: 0.9546 r:0.1216
en_zh Dev loss: 1.1117 r:0.2886
ro_en Dev loss: 0.4101 r:0.8163
et_en Dev loss: 0.4984 r:0.6685
si_en Dev loss: 0.8907 r:0.5550
ne_en Dev loss: 0.6630 r:0.7124
ru_en Dev loss: 0.5061 r:0.7318
Current avg r:0.5563 Best avg r: 0.6050
02:35:51,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:08,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:38,792 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1842
en_de Dev loss: 0.9307 r:0.1295
en_zh Dev loss: 1.0015 r:0.2986
ro_en Dev loss: 0.3525 r:0.8119
et_en Dev loss: 0.4687 r:0.6640
si_en Dev loss: 0.8637 r:0.5574
ne_en Dev loss: 0.5701 r:0.7241
ru_en Dev loss: 0.4761 r:0.7236
Current avg r:0.5585 Best avg r: 0.6050
02:42:29,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:46,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:16,235 root INFO Epoch 7 Global steps: 65400 Train loss: 0.2057
en_de Dev loss: 0.9067 r:0.1472
en_zh Dev loss: 0.9796 r:0.2891
ro_en Dev loss: 0.3360 r:0.8152
et_en Dev loss: 0.4706 r:0.6690
si_en Dev loss: 0.8013 r:0.5682
ne_en Dev loss: 0.5007 r:0.7244
ru_en Dev loss: 0.4313 r:0.7390
Current avg r:0.5646 Best avg r: 0.6050
02:49:06,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:23,712 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:53,553 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1774
en_de Dev loss: 0.9638 r:0.1063
en_zh Dev loss: 1.0903 r:0.2729
ro_en Dev loss: 0.3670 r:0.8174
et_en Dev loss: 0.4905 r:0.6616
si_en Dev loss: 0.9184 r:0.5568
ne_en Dev loss: 0.5641 r:0.7240
ru_en Dev loss: 0.4998 r:0.7245
Current avg r:0.5519 Best avg r: 0.6050
02:55:43,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:57:01,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:58:31,125 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1934
en_de Dev loss: 0.9266 r:0.1475
en_zh Dev loss: 0.9768 r:0.3021
ro_en Dev loss: 0.3582 r:0.8199
et_en Dev loss: 0.5271 r:0.6731
si_en Dev loss: 0.7926 r:0.5724
ne_en Dev loss: 0.5325 r:0.7204
ru_en Dev loss: 0.4615 r:0.7328
Current avg r:0.5669 Best avg r: 0.6050
03:02:22,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:39,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:05:09,635 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1910
en_de Dev loss: 0.9317 r:0.1592
en_zh Dev loss: 1.0979 r:0.2687
ro_en Dev loss: 0.3868 r:0.8153
et_en Dev loss: 0.4676 r:0.6692
si_en Dev loss: 0.9101 r:0.5525
ne_en Dev loss: 0.5792 r:0.7193
ru_en Dev loss: 0.4920 r:0.7361
Current avg r:0.5600 Best avg r: 0.6050
03:09:01,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:18,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:48,274 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1944
en_de Dev loss: 0.9094 r:0.1636
en_zh Dev loss: 1.0102 r:0.2851
ro_en Dev loss: 0.3321 r:0.8230
et_en Dev loss: 0.4750 r:0.6727
si_en Dev loss: 0.8152 r:0.5634
ne_en Dev loss: 0.4761 r:0.7243
ru_en Dev loss: 0.4403 r:0.7381
Current avg r:0.5672 Best avg r: 0.6050
03:15:39,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:16:56,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:18:26,764 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1894
en_de Dev loss: 0.9430 r:0.1375
en_zh Dev loss: 0.9945 r:0.2933
ro_en Dev loss: 0.3557 r:0.8200
et_en Dev loss: 0.4780 r:0.6739
si_en Dev loss: 0.8083 r:0.5612
ne_en Dev loss: 0.5266 r:0.7213
ru_en Dev loss: 0.4438 r:0.7450
Current avg r:0.5646 Best avg r: 0.6050
03:22:18,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:23:35,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:05,113 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1881
en_de Dev loss: 0.9338 r:0.1605
en_zh Dev loss: 0.9869 r:0.2963
ro_en Dev loss: 0.3418 r:0.8210
et_en Dev loss: 0.4724 r:0.6797
si_en Dev loss: 0.8117 r:0.5618
ne_en Dev loss: 0.5197 r:0.7177
ru_en Dev loss: 0.4356 r:0.7509
Current avg r:0.5697 Best avg r: 0.6050
03:28:55,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:30:13,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:42,980 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1840
en_de Dev loss: 0.9472 r:0.1396
en_zh Dev loss: 1.0203 r:0.2789
ro_en Dev loss: 0.3617 r:0.8215
et_en Dev loss: 0.5450 r:0.6731
si_en Dev loss: 0.8639 r:0.5546
ne_en Dev loss: 0.5307 r:0.7109
ru_en Dev loss: 0.4583 r:0.7395
Current avg r:0.5597 Best avg r: 0.6050
03:35:33,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:51,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:22,34 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1949
en_de Dev loss: 0.9446 r:0.1238
en_zh Dev loss: 1.0533 r:0.2780
ro_en Dev loss: 0.3622 r:0.8198
et_en Dev loss: 0.4836 r:0.6731
si_en Dev loss: 0.8389 r:0.5535
ne_en Dev loss: 0.5089 r:0.7182
ru_en Dev loss: 0.4732 r:0.7347
Current avg r:0.5573 Best avg r: 0.6050
03:42:16,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:34,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:05,337 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1803
en_de Dev loss: 0.9321 r:0.1425
en_zh Dev loss: 1.0089 r:0.2870
ro_en Dev loss: 0.3576 r:0.8168
et_en Dev loss: 0.4851 r:0.6631
si_en Dev loss: 0.8277 r:0.5553
ne_en Dev loss: 0.5157 r:0.7241
ru_en Dev loss: 0.4644 r:0.7301
Current avg r:0.5598 Best avg r: 0.6050
03:49:00,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:50:18,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:51:48,827 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1749
en_de Dev loss: 0.9287 r:0.1445
en_zh Dev loss: 1.0015 r:0.2867
ro_en Dev loss: 0.3552 r:0.8161
et_en Dev loss: 0.4767 r:0.6685
si_en Dev loss: 0.8843 r:0.5504
ne_en Dev loss: 0.5310 r:0.7197
ru_en Dev loss: 0.4464 r:0.7378
Current avg r:0.5605 Best avg r: 0.6050
03:55:43,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:01,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:58:32,322 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1779
en_de Dev loss: 0.9480 r:0.1391
en_zh Dev loss: 1.0329 r:0.2885
ro_en Dev loss: 0.3645 r:0.8161
et_en Dev loss: 0.4823 r:0.6603
si_en Dev loss: 0.9020 r:0.5503
ne_en Dev loss: 0.6031 r:0.7096
ru_en Dev loss: 0.4971 r:0.7226
Current avg r:0.5552 Best avg r: 0.6050
04:02:25,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:03:42,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:05:12,860 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1631
en_de Dev loss: 0.9263 r:0.1528
en_zh Dev loss: 1.0183 r:0.2920
ro_en Dev loss: 0.3555 r:0.8163
et_en Dev loss: 0.4971 r:0.6710
si_en Dev loss: 0.8879 r:0.5526
ne_en Dev loss: 0.5765 r:0.7113
ru_en Dev loss: 0.4604 r:0.7344
Current avg r:0.5615 Best avg r: 0.6050
04:09:04,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:10:21,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:11:51,245 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1725
en_de Dev loss: 0.9542 r:0.1439
en_zh Dev loss: 0.9929 r:0.3012
ro_en Dev loss: 0.3777 r:0.8144
et_en Dev loss: 0.5461 r:0.6777
si_en Dev loss: 0.8517 r:0.5591
ne_en Dev loss: 0.5353 r:0.7117
ru_en Dev loss: 0.4456 r:0.7453
Current avg r:0.5648 Best avg r: 0.6050
04:15:42,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:16:59,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:18:29,518 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1639
en_de Dev loss: 0.9262 r:0.1461
en_zh Dev loss: 0.9596 r:0.2979
ro_en Dev loss: 0.3368 r:0.8174
et_en Dev loss: 0.4725 r:0.6768
si_en Dev loss: 0.8046 r:0.5602
ne_en Dev loss: 0.5227 r:0.7144
ru_en Dev loss: 0.4539 r:0.7281
Current avg r:0.5630 Best avg r: 0.6050
04:22:20,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:23:37,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:25:07,816 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1640
en_de Dev loss: 0.9290 r:0.1189
en_zh Dev loss: 0.9974 r:0.2912
ro_en Dev loss: 0.3450 r:0.8147
et_en Dev loss: 0.4765 r:0.6668
si_en Dev loss: 0.8818 r:0.5511
ne_en Dev loss: 0.5668 r:0.7130
ru_en Dev loss: 0.4619 r:0.7308
Current avg r:0.5552 Best avg r: 0.6050
04:29:01,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:19,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:50,540 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1607
en_de Dev loss: 0.9618 r:0.1160
en_zh Dev loss: 1.0503 r:0.2864
ro_en Dev loss: 0.3479 r:0.8178
et_en Dev loss: 0.4490 r:0.6738
si_en Dev loss: 0.8623 r:0.5500
ne_en Dev loss: 0.5524 r:0.7124
ru_en Dev loss: 0.4830 r:0.7315
Current avg r:0.5554 Best avg r: 0.6050
04:35:44,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:37:02,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:33,144 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1494
en_de Dev loss: 0.9750 r:0.1295
en_zh Dev loss: 1.1004 r:0.2969
ro_en Dev loss: 0.3977 r:0.8150
et_en Dev loss: 0.4828 r:0.6744
si_en Dev loss: 0.9327 r:0.5484
ne_en Dev loss: 0.5430 r:0.7181
ru_en Dev loss: 0.5033 r:0.7363
Current avg r:0.5598 Best avg r: 0.6050
04:42:27,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:45,826 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:16,615 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1570
en_de Dev loss: 0.9281 r:0.1264
en_zh Dev loss: 1.0207 r:0.2971
ro_en Dev loss: 0.3706 r:0.8133
et_en Dev loss: 0.4739 r:0.6694
si_en Dev loss: 0.9450 r:0.5449
ne_en Dev loss: 0.6103 r:0.7158
ru_en Dev loss: 0.4723 r:0.7313
Current avg r:0.5569 Best avg r: 0.6050
04:49:09,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:27,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:57,168 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1645
en_de Dev loss: 0.9344 r:0.1402
en_zh Dev loss: 1.0186 r:0.3117
ro_en Dev loss: 0.3850 r:0.8150
et_en Dev loss: 0.4784 r:0.6637
si_en Dev loss: 0.8971 r:0.5556
ne_en Dev loss: 0.6386 r:0.7172
ru_en Dev loss: 0.4840 r:0.7383
Current avg r:0.5631 Best avg r: 0.6050
04:55:47,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:05,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:35,290 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1724
en_de Dev loss: 0.9728 r:0.1343
en_zh Dev loss: 1.0952 r:0.2751
ro_en Dev loss: 0.3675 r:0.8145
et_en Dev loss: 0.4846 r:0.6636
si_en Dev loss: 0.9514 r:0.5403
ne_en Dev loss: 0.6103 r:0.7139
ru_en Dev loss: 0.4742 r:0.7367
Current avg r:0.5541 Best avg r: 0.6050
05:02:26,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:43,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:05:13,937 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1632
en_de Dev loss: 0.9134 r:0.1229
en_zh Dev loss: 0.9988 r:0.2867
ro_en Dev loss: 0.3280 r:0.8158
et_en Dev loss: 0.4505 r:0.6633
si_en Dev loss: 0.8376 r:0.5504
ne_en Dev loss: 0.5614 r:0.7151
ru_en Dev loss: 0.4541 r:0.7257
Current avg r:0.5543 Best avg r: 0.6050
05:09:05,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:22,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:52,950 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1590
en_de Dev loss: 0.9355 r:0.1437
en_zh Dev loss: 1.0153 r:0.3148
ro_en Dev loss: 0.3769 r:0.8165
et_en Dev loss: 0.4943 r:0.6784
si_en Dev loss: 0.8591 r:0.5611
ne_en Dev loss: 0.5430 r:0.7160
ru_en Dev loss: 0.4411 r:0.7470
Current avg r:0.5682 Best avg r: 0.6050
05:15:47,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:05,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:35,998 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1669
en_de Dev loss: 0.9170 r:0.1466
en_zh Dev loss: 0.9489 r:0.3074
ro_en Dev loss: 0.3315 r:0.8194
et_en Dev loss: 0.5084 r:0.6751
si_en Dev loss: 0.8363 r:0.5575
ne_en Dev loss: 0.5455 r:0.7082
ru_en Dev loss: 0.4007 r:0.7497
Current avg r:0.5663 Best avg r: 0.6050
05:22:30,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:23:48,222 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:19,23 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1523
en_de Dev loss: 0.9370 r:0.1407
en_zh Dev loss: 1.0124 r:0.2946
ro_en Dev loss: 0.3550 r:0.8169
et_en Dev loss: 0.4829 r:0.6781
si_en Dev loss: 0.8612 r:0.5563
ne_en Dev loss: 0.5214 r:0.7149
ru_en Dev loss: 0.4395 r:0.7457
Current avg r:0.5639 Best avg r: 0.6050
05:29:13,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:31,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:32:02,318 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1605
en_de Dev loss: 0.9571 r:0.1186
en_zh Dev loss: 1.0642 r:0.2707
ro_en Dev loss: 0.3718 r:0.8168
et_en Dev loss: 0.4870 r:0.6727
si_en Dev loss: 0.9274 r:0.5463
ne_en Dev loss: 0.5345 r:0.7146
ru_en Dev loss: 0.4743 r:0.7289
Current avg r:0.5526 Best avg r: 0.6050
05:35:55,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:12,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:42,79 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1532
en_de Dev loss: 0.9802 r:0.1297
en_zh Dev loss: 1.0920 r:0.2840
ro_en Dev loss: 0.3822 r:0.8177
et_en Dev loss: 0.5079 r:0.6628
si_en Dev loss: 0.9127 r:0.5517
ne_en Dev loss: 0.5548 r:0.7099
ru_en Dev loss: 0.4834 r:0.7323
Current avg r:0.5554 Best avg r: 0.6050
05:42:34,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:51,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:21,190 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1314
en_de Dev loss: 0.9779 r:0.1341
en_zh Dev loss: 1.0697 r:0.2871
ro_en Dev loss: 0.3542 r:0.8213
et_en Dev loss: 0.4615 r:0.6745
si_en Dev loss: 0.8523 r:0.5537
ne_en Dev loss: 0.5544 r:0.7114
ru_en Dev loss: 0.4498 r:0.7448
Current avg r:0.5610 Best avg r: 0.6050
05:49:12,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:50:29,555 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:51:59,532 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1565
en_de Dev loss: 0.9672 r:0.1136
en_zh Dev loss: 1.0551 r:0.2873
ro_en Dev loss: 0.3922 r:0.8138
et_en Dev loss: 0.4859 r:0.6663
si_en Dev loss: 0.9748 r:0.5456
ne_en Dev loss: 0.6140 r:0.7090
ru_en Dev loss: 0.4853 r:0.7329
Current avg r:0.5527 Best avg r: 0.6050
05:55:50,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:57:07,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:58:37,941 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1401
en_de Dev loss: 0.9610 r:0.1399
en_zh Dev loss: 0.9887 r:0.3019
ro_en Dev loss: 0.3462 r:0.8185
et_en Dev loss: 0.4968 r:0.6734
si_en Dev loss: 0.8039 r:0.5593
ne_en Dev loss: 0.5163 r:0.7133
ru_en Dev loss: 0.4441 r:0.7455
Current avg r:0.5645 Best avg r: 0.6050
06:02:32,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:50,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:21,124 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1428
en_de Dev loss: 0.9603 r:0.1154
en_zh Dev loss: 1.0085 r:0.2850
ro_en Dev loss: 0.3395 r:0.8166
et_en Dev loss: 0.4672 r:0.6730
si_en Dev loss: 0.8544 r:0.5498
ne_en Dev loss: 0.5417 r:0.7138
ru_en Dev loss: 0.4452 r:0.7370
Current avg r:0.5558 Best avg r: 0.6050
06:09:16,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:10:33,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:12:04,718 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1449
en_de Dev loss: 0.9841 r:0.1139
en_zh Dev loss: 1.0617 r:0.2929
ro_en Dev loss: 0.3721 r:0.8188
et_en Dev loss: 0.4926 r:0.6762
si_en Dev loss: 0.8840 r:0.5558
ne_en Dev loss: 0.5915 r:0.7083
ru_en Dev loss: 0.4743 r:0.7353
Current avg r:0.5573 Best avg r: 0.6050
06:15:59,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:16,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:47,715 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1385
en_de Dev loss: 1.0047 r:0.1191
en_zh Dev loss: 1.1169 r:0.3051
ro_en Dev loss: 0.4003 r:0.8184
et_en Dev loss: 0.5104 r:0.6756
si_en Dev loss: 0.9715 r:0.5551
ne_en Dev loss: 0.5855 r:0.7130
ru_en Dev loss: 0.5385 r:0.7294
Current avg r:0.5594 Best avg r: 0.6050
06:22:42,242 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:23:59,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:25:29,759 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1498
en_de Dev loss: 0.9565 r:0.1066
en_zh Dev loss: 1.0167 r:0.2945
ro_en Dev loss: 0.3608 r:0.8182
et_en Dev loss: 0.5102 r:0.6766
si_en Dev loss: 0.8585 r:0.5548
ne_en Dev loss: 0.5438 r:0.7098
ru_en Dev loss: 0.4570 r:0.7379
Current avg r:0.5569 Best avg r: 0.6050
06:29:21,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:38,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:09,128 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1395
en_de Dev loss: 0.9326 r:0.1392
en_zh Dev loss: 0.9950 r:0.3057
ro_en Dev loss: 0.3450 r:0.8197
et_en Dev loss: 0.4786 r:0.6729
si_en Dev loss: 0.9310 r:0.5418
ne_en Dev loss: 0.6107 r:0.7139
ru_en Dev loss: 0.4482 r:0.7414
Current avg r:0.5621 Best avg r: 0.6050
06:36:00,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:17,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:38:47,916 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1374
en_de Dev loss: 0.9705 r:0.1064
en_zh Dev loss: 1.0707 r:0.2937
ro_en Dev loss: 0.3658 r:0.8167
et_en Dev loss: 0.4662 r:0.6680
si_en Dev loss: 0.9902 r:0.5405
ne_en Dev loss: 0.6663 r:0.7015
ru_en Dev loss: 0.5027 r:0.7334
Current avg r:0.5515 Best avg r: 0.6050
06:42:39,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:43:56,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:27,126 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1533
en_de Dev loss: 0.9676 r:0.1216
en_zh Dev loss: 1.0723 r:0.3064
ro_en Dev loss: 0.3761 r:0.8174
et_en Dev loss: 0.4818 r:0.6697
si_en Dev loss: 0.9870 r:0.5435
ne_en Dev loss: 0.6489 r:0.7021
ru_en Dev loss: 0.5030 r:0.7370
Current avg r:0.5568 Best avg r: 0.6050
06:49:21,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:50:39,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:52:10,509 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1414
en_de Dev loss: 0.9621 r:0.1247
en_zh Dev loss: 1.0184 r:0.3180
ro_en Dev loss: 0.3702 r:0.8155
et_en Dev loss: 0.5010 r:0.6751
si_en Dev loss: 0.9000 r:0.5535
ne_en Dev loss: 0.5791 r:0.7095
ru_en Dev loss: 0.5046 r:0.7298
Current avg r:0.5609 Best avg r: 0.6050
06:56:04,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:57:22,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:58:52,834 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1342
en_de Dev loss: 0.9561 r:0.1111
en_zh Dev loss: 1.0064 r:0.3041
ro_en Dev loss: 0.3406 r:0.8205
et_en Dev loss: 0.4776 r:0.6717
si_en Dev loss: 0.8511 r:0.5524
ne_en Dev loss: 0.5273 r:0.7162
ru_en Dev loss: 0.4342 r:0.7461
Current avg r:0.5603 Best avg r: 0.6050
07:02:47,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:04:05,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:05:36,466 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1374
en_de Dev loss: 0.9803 r:0.1053
en_zh Dev loss: 1.0607 r:0.2865
ro_en Dev loss: 0.3674 r:0.8177
et_en Dev loss: 0.4722 r:0.6735
si_en Dev loss: 0.8959 r:0.5434
ne_en Dev loss: 0.5609 r:0.7128
ru_en Dev loss: 0.4675 r:0.7386
Current avg r:0.5540 Best avg r: 0.6050
07:09:30,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:10:47,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:12:17,460 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1379
en_de Dev loss: 0.9656 r:0.1040
en_zh Dev loss: 1.0499 r:0.3074
ro_en Dev loss: 0.3830 r:0.8156
et_en Dev loss: 0.4714 r:0.6706
si_en Dev loss: 0.9513 r:0.5412
ne_en Dev loss: 0.6108 r:0.7032
ru_en Dev loss: 0.4622 r:0.7425
Current avg r:0.5549 Best avg r: 0.6050
07:16:08,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:25,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:18:55,169 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1353
en_de Dev loss: 0.9403 r:0.1157
en_zh Dev loss: 1.0563 r:0.2926
ro_en Dev loss: 0.3713 r:0.8181
et_en Dev loss: 0.4701 r:0.6667
si_en Dev loss: 0.9038 r:0.5445
ne_en Dev loss: 0.5726 r:0.7031
ru_en Dev loss: 0.4603 r:0.7386
Current avg r:0.5542 Best avg r: 0.6050
07:22:47,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:24:05,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:25:35,560 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1302
en_de Dev loss: 0.9495 r:0.1537
en_zh Dev loss: 1.0368 r:0.3124
ro_en Dev loss: 0.3827 r:0.8162
et_en Dev loss: 0.5211 r:0.6784
si_en Dev loss: 0.8619 r:0.5515
ne_en Dev loss: 0.5613 r:0.7046
ru_en Dev loss: 0.4432 r:0.7570
Current avg r:0.5677 Best avg r: 0.6050
07:29:27,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:30:44,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:14,739 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1234
en_de Dev loss: 0.9336 r:0.1408
en_zh Dev loss: 1.0183 r:0.3075
ro_en Dev loss: 0.3569 r:0.8173
et_en Dev loss: 0.4754 r:0.6730
si_en Dev loss: 0.8568 r:0.5506
ne_en Dev loss: 0.5413 r:0.7094
ru_en Dev loss: 0.4304 r:0.7534
Current avg r:0.5646 Best avg r: 0.6050
07:36:05,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:37:23,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:38:52,958 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1239
en_de Dev loss: 0.9742 r:0.1328
en_zh Dev loss: 1.0376 r:0.3089
ro_en Dev loss: 0.3740 r:0.8181
et_en Dev loss: 0.5073 r:0.6748
si_en Dev loss: 0.9067 r:0.5512
ne_en Dev loss: 0.5746 r:0.7073
ru_en Dev loss: 0.4612 r:0.7489
Current avg r:0.5631 Best avg r: 0.6050
07:42:44,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:44:01,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:31,270 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1223
en_de Dev loss: 0.9696 r:0.1204
en_zh Dev loss: 1.0003 r:0.3041
ro_en Dev loss: 0.3498 r:0.8185
et_en Dev loss: 0.4816 r:0.6735
si_en Dev loss: 0.7991 r:0.5586
ne_en Dev loss: 0.4996 r:0.7108
ru_en Dev loss: 0.4201 r:0.7544
Current avg r:0.5629 Best avg r: 0.6050
07:49:22,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:50:39,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:09,428 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1275
en_de Dev loss: 1.0071 r:0.1071
en_zh Dev loss: 1.1426 r:0.2791
ro_en Dev loss: 0.3896 r:0.8159
et_en Dev loss: 0.4965 r:0.6641
si_en Dev loss: 0.9504 r:0.5412
ne_en Dev loss: 0.6573 r:0.7001
ru_en Dev loss: 0.4769 r:0.7420
Current avg r:0.5499 Best avg r: 0.6050
07:55:59,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:57:16,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:58:46,771 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1292
en_de Dev loss: 0.9562 r:0.1044
en_zh Dev loss: 1.0489 r:0.2850
ro_en Dev loss: 0.3509 r:0.8160
et_en Dev loss: 0.4702 r:0.6685
si_en Dev loss: 0.8815 r:0.5435
ne_en Dev loss: 0.5669 r:0.7052
ru_en Dev loss: 0.4304 r:0.7508
Current avg r:0.5533 Best avg r: 0.6050
08:02:37,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:03:54,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:05:24,63 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1230
en_de Dev loss: 0.9584 r:0.1080
en_zh Dev loss: 1.0145 r:0.2999
ro_en Dev loss: 0.3669 r:0.8109
et_en Dev loss: 0.4761 r:0.6720
si_en Dev loss: 0.8815 r:0.5461
ne_en Dev loss: 0.5876 r:0.7075
ru_en Dev loss: 0.4269 r:0.7540
Current avg r:0.5569 Best avg r: 0.6050
08:09:14,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:10:31,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:12:01,342 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1272
en_de Dev loss: 0.9767 r:0.1087
en_zh Dev loss: 0.9999 r:0.3039
ro_en Dev loss: 0.3343 r:0.8227
et_en Dev loss: 0.4748 r:0.6785
si_en Dev loss: 0.7899 r:0.5551
ne_en Dev loss: 0.5369 r:0.7064
ru_en Dev loss: 0.4181 r:0.7553
Current avg r:0.5615 Best avg r: 0.6050
08:15:51,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:17:08,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:18:38,805 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1249
en_de Dev loss: 0.9687 r:0.1192
en_zh Dev loss: 1.0237 r:0.3125
ro_en Dev loss: 0.3676 r:0.8170
et_en Dev loss: 0.4994 r:0.6740
si_en Dev loss: 0.8709 r:0.5540
ne_en Dev loss: 0.5727 r:0.7059
ru_en Dev loss: 0.4746 r:0.7363
Current avg r:0.5598 Best avg r: 0.6050
08:22:29,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:23:46,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:25:16,673 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1261
en_de Dev loss: 0.9580 r:0.1259
en_zh Dev loss: 1.0740 r:0.2868
ro_en Dev loss: 0.3573 r:0.8171
et_en Dev loss: 0.4827 r:0.6699
si_en Dev loss: 0.9134 r:0.5482
ne_en Dev loss: 0.5887 r:0.7051
ru_en Dev loss: 0.4777 r:0.7305
Current avg r:0.5548 Best avg r: 0.6050
08:29:07,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:30:24,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:31:54,512 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1160
en_de Dev loss: 0.9722 r:0.1282
en_zh Dev loss: 1.0722 r:0.2977
ro_en Dev loss: 0.3806 r:0.8118
et_en Dev loss: 0.4768 r:0.6640
si_en Dev loss: 0.9543 r:0.5480
ne_en Dev loss: 0.6481 r:0.6992
ru_en Dev loss: 0.4823 r:0.7371
Current avg r:0.5551 Best avg r: 0.6050
08:35:45,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:37:02,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:38:32,113 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1168
en_de Dev loss: 0.9780 r:0.1255
en_zh Dev loss: 1.0732 r:0.3077
ro_en Dev loss: 0.3809 r:0.8144
et_en Dev loss: 0.4853 r:0.6747
si_en Dev loss: 0.9153 r:0.5561
ne_en Dev loss: 0.5869 r:0.7034
ru_en Dev loss: 0.4710 r:0.7420
Current avg r:0.5606 Best avg r: 0.6050
08:42:22,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:43:39,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:45:09,548 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1220
en_de Dev loss: 0.9956 r:0.0901
en_zh Dev loss: 1.0550 r:0.3047
ro_en Dev loss: 0.3506 r:0.8140
et_en Dev loss: 0.4640 r:0.6653
si_en Dev loss: 0.8725 r:0.5502
ne_en Dev loss: 0.5799 r:0.6958
ru_en Dev loss: 0.4396 r:0.7490
Current avg r:0.5527 Best avg r: 0.6050
08:49:00,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:50:17,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:51:47,315 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1233
en_de Dev loss: 1.0424 r:0.0970
en_zh Dev loss: 1.1302 r:0.3016
ro_en Dev loss: 0.4112 r:0.8153
et_en Dev loss: 0.4772 r:0.6736
si_en Dev loss: 0.9796 r:0.5485
ne_en Dev loss: 0.5953 r:0.6985
ru_en Dev loss: 0.4705 r:0.7518
Current avg r:0.5552 Best avg r: 0.6050
08:55:38,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:56:56,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:58:26,41 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1202
en_de Dev loss: 1.0225 r:0.0833
en_zh Dev loss: 1.0951 r:0.2812
ro_en Dev loss: 0.3742 r:0.8142
et_en Dev loss: 0.4674 r:0.6608
si_en Dev loss: 0.8918 r:0.5460
ne_en Dev loss: 0.5722 r:0.6912
ru_en Dev loss: 0.4688 r:0.7401
Current avg r:0.5453 Best avg r: 0.6050
09:02:17,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:03:34,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:05:04,612 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1133
en_de Dev loss: 1.0287 r:0.0829
en_zh Dev loss: 1.1018 r:0.2880
ro_en Dev loss: 0.3665 r:0.8144
et_en Dev loss: 0.4693 r:0.6639
si_en Dev loss: 0.9621 r:0.5433
ne_en Dev loss: 0.6312 r:0.6993
ru_en Dev loss: 0.4782 r:0.7361
Current avg r:0.5468 Best avg r: 0.6050
09:08:54,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:10:12,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:41,890 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1100
en_de Dev loss: 0.9938 r:0.1064
en_zh Dev loss: 1.0013 r:0.3076
ro_en Dev loss: 0.3444 r:0.8165
et_en Dev loss: 0.4875 r:0.6724
si_en Dev loss: 0.8517 r:0.5533
ne_en Dev loss: 0.5371 r:0.7028
ru_en Dev loss: 0.4383 r:0.7452
Current avg r:0.5577 Best avg r: 0.6050
09:15:32,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:16:49,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:18:19,241 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1171
en_de Dev loss: 0.9854 r:0.1077
en_zh Dev loss: 0.9738 r:0.3123
ro_en Dev loss: 0.3485 r:0.8129
et_en Dev loss: 0.5006 r:0.6787
si_en Dev loss: 0.8873 r:0.5457
ne_en Dev loss: 0.5646 r:0.6983
ru_en Dev loss: 0.4296 r:0.7437
Current avg r:0.5570 Best avg r: 0.6050
09:22:09,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:23:26,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:24:56,336 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1100
en_de Dev loss: 1.0041 r:0.0983
en_zh Dev loss: 1.0252 r:0.3074
ro_en Dev loss: 0.3588 r:0.8164
et_en Dev loss: 0.4749 r:0.6764
si_en Dev loss: 0.8753 r:0.5521
ne_en Dev loss: 0.6143 r:0.6957
ru_en Dev loss: 0.4363 r:0.7504
Current avg r:0.5567 Best avg r: 0.6050
09:28:47,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:04,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:31:33,982 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1147
en_de Dev loss: 0.9898 r:0.1354
en_zh Dev loss: 1.0201 r:0.3098
ro_en Dev loss: 0.3665 r:0.8173
et_en Dev loss: 0.5287 r:0.6856
si_en Dev loss: 0.8802 r:0.5508
ne_en Dev loss: 0.5567 r:0.7048
ru_en Dev loss: 0.4164 r:0.7595
Current avg r:0.5662 Best avg r: 0.6050
09:35:24,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:36:41,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:38:11,681 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1134
en_de Dev loss: 1.0334 r:0.1034
en_zh Dev loss: 1.0572 r:0.3086
ro_en Dev loss: 0.3790 r:0.8163
et_en Dev loss: 0.4985 r:0.6782
si_en Dev loss: 0.8824 r:0.5540
ne_en Dev loss: 0.6164 r:0.7040
ru_en Dev loss: 0.4492 r:0.7492
Current avg r:0.5591 Best avg r: 0.6050
09:42:02,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:19,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:44:48,912 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1077
en_de Dev loss: 1.0320 r:0.0951
en_zh Dev loss: 1.0752 r:0.3049
ro_en Dev loss: 0.3838 r:0.8124
et_en Dev loss: 0.4605 r:0.6785
si_en Dev loss: 0.8828 r:0.5555
ne_en Dev loss: 0.6318 r:0.7002
ru_en Dev loss: 0.4537 r:0.7528
Current avg r:0.5571 Best avg r: 0.6050
09:48:39,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:49:56,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:25,986 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1132
en_de Dev loss: 0.9956 r:0.0932
en_zh Dev loss: 1.0697 r:0.2879
ro_en Dev loss: 0.3455 r:0.8153
et_en Dev loss: 0.4513 r:0.6717
si_en Dev loss: 0.8981 r:0.5442
ne_en Dev loss: 0.6369 r:0.6941
ru_en Dev loss: 0.4347 r:0.7504
Current avg r:0.5510 Best avg r: 0.6050
09:55:16,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:33,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:03,128 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1149
en_de Dev loss: 1.0043 r:0.0975
en_zh Dev loss: 1.0708 r:0.2967
ro_en Dev loss: 0.3560 r:0.8121
et_en Dev loss: 0.4691 r:0.6708
si_en Dev loss: 0.8639 r:0.5506
ne_en Dev loss: 0.6124 r:0.7006
ru_en Dev loss: 0.4507 r:0.7434
Current avg r:0.5531 Best avg r: 0.6050
10:01:54,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:03:11,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:04:40,937 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1136
en_de Dev loss: 1.0236 r:0.1249
en_zh Dev loss: 1.0402 r:0.3212
ro_en Dev loss: 0.3642 r:0.8111
et_en Dev loss: 0.4710 r:0.6763
si_en Dev loss: 0.8853 r:0.5500
ne_en Dev loss: 0.5586 r:0.7060
ru_en Dev loss: 0.4270 r:0.7609
Current avg r:0.5643 Best avg r: 0.6050
10:08:31,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:09:48,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:18,748 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1144
en_de Dev loss: 1.0080 r:0.1076
en_zh Dev loss: 1.0575 r:0.3054
ro_en Dev loss: 0.3510 r:0.8135
et_en Dev loss: 0.4481 r:0.6735
si_en Dev loss: 0.9007 r:0.5440
ne_en Dev loss: 0.5804 r:0.7056
ru_en Dev loss: 0.4501 r:0.7456
Current avg r:0.5564 Best avg r: 0.6050
10:15:09,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:26,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:56,471 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1102
en_de Dev loss: 0.9995 r:0.1045
en_zh Dev loss: 1.0601 r:0.2932
ro_en Dev loss: 0.3639 r:0.8081
et_en Dev loss: 0.4644 r:0.6603
si_en Dev loss: 0.8728 r:0.5467
ne_en Dev loss: 0.5604 r:0.7072
ru_en Dev loss: 0.4626 r:0.7412
Current avg r:0.5516 Best avg r: 0.6050
10:21:47,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:23:04,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:24:34,198 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1167
en_de Dev loss: 1.0079 r:0.0967
en_zh Dev loss: 1.0696 r:0.2946
ro_en Dev loss: 0.3575 r:0.8142
et_en Dev loss: 0.4711 r:0.6691
si_en Dev loss: 0.8706 r:0.5542
ne_en Dev loss: 0.5557 r:0.7100
ru_en Dev loss: 0.4558 r:0.7471
Current avg r:0.5551 Best avg r: 0.6050
10:28:25,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:42,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:31:12,54 root INFO Epoch 11 Global steps: 107400 Train loss: 0.1082
en_de Dev loss: 1.0244 r:0.0982
en_zh Dev loss: 1.0723 r:0.3012
ro_en Dev loss: 0.3759 r:0.8088
et_en Dev loss: 0.4644 r:0.6683
si_en Dev loss: 0.8636 r:0.5508
ne_en Dev loss: 0.5938 r:0.7046
ru_en Dev loss: 0.4624 r:0.7484
Current avg r:0.5543 Best avg r: 0.6050
10:35:03,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:36:20,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:37:50,812 root INFO Epoch 11 Global steps: 108000 Train loss: 0.1115
en_de Dev loss: 1.0346 r:0.0913
en_zh Dev loss: 1.0988 r:0.2882
ro_en Dev loss: 0.3634 r:0.8112
et_en Dev loss: 0.4754 r:0.6615
si_en Dev loss: 0.8799 r:0.5484
ne_en Dev loss: 0.5612 r:0.7047
ru_en Dev loss: 0.4853 r:0.7411
Current avg r:0.5495 Best avg r: 0.6050
