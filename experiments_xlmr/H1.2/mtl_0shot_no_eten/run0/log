14:44:19,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:45,412 root INFO 
id:en_zh cur r: 0.2353 best r: 0.2353
14:44:58,471 root INFO 
id:ro_en cur r: 0.5720 best r: 0.5720
14:45:11,572 root INFO 
id:si_en cur r: 0.4093 best r: 0.4093
14:45:24,688 root INFO 
id:ne_en cur r: 0.4745 best r: 0.4745
14:45:37,689 root INFO 
id:ru_en cur r: 0.4840 best r: 0.4840
14:45:37,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:09,318 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
14:47:09,325 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:47:09,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:47:09,337 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
14:47:09,342 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
14:47:09,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:47:09,352 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:47:22,493 root INFO Epoch 0 Global steps: 600 Train loss: 0.8719
en_de Dev loss: 0.8867 r:0.0818
en_zh Dev loss: 0.8005 r:0.2485
ro_en Dev loss: 0.6728 r:0.5681
et_en Dev loss: 0.6154 r:0.4184
si_en Dev loss: 0.7212 r:0.4384
ne_en Dev loss: 0.6000 r:0.5792
ru_en Dev loss: 0.6594 r:0.5031
Current avg r:0.4054 Best avg r: 0.4054
14:51:16,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:55,739 root INFO 
id:ro_en cur r: 0.5864 best r: 0.5864
14:52:08,860 root INFO 
id:si_en cur r: 0.4241 best r: 0.4241
14:52:21,978 root INFO 
id:ne_en cur r: 0.5358 best r: 0.5358
14:52:34,990 root INFO 
id:ru_en cur r: 0.5891 best r: 0.5891
14:52:34,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:06,722 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
14:54:06,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:54:06,734 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:54:06,740 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
14:54:06,745 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
14:54:06,750 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:54:06,755 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:54:19,887 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8420
en_de Dev loss: 0.9128 r:0.1013
en_zh Dev loss: 0.7540 r:0.2875
ro_en Dev loss: 0.6976 r:0.6139
et_en Dev loss: 0.5542 r:0.5038
si_en Dev loss: 0.7511 r:0.4647
ne_en Dev loss: 0.5471 r:0.6161
ru_en Dev loss: 0.6063 r:0.6186
Current avg r:0.4580 Best avg r: 0.4580
14:58:13,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:26,745 root INFO 
id:en_de cur r: 0.0089 best r: 0.0089
14:58:52,787 root INFO 
id:ro_en cur r: 0.5955 best r: 0.5955
14:59:05,882 root INFO 
id:si_en cur r: 0.4448 best r: 0.4448
14:59:18,980 root INFO 
id:ne_en cur r: 0.5613 best r: 0.5613
14:59:31,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:01:03,490 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
15:01:03,497 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:01:03,501 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:01:03,506 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
15:01:03,510 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
15:01:03,515 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:01:03,528 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:01:16,662 root INFO Epoch 0 Global steps: 1800 Train loss: 0.6951
en_de Dev loss: 0.9242 r:0.1325
en_zh Dev loss: 0.7782 r:0.3180
ro_en Dev loss: 0.7007 r:0.6303
et_en Dev loss: 0.5535 r:0.5544
si_en Dev loss: 0.7566 r:0.4830
ne_en Dev loss: 0.5454 r:0.6167
ru_en Dev loss: 0.6574 r:0.6552
Current avg r:0.4843 Best avg r: 0.4843
15:05:10,891 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:36,941 root INFO 
id:en_zh cur r: 0.3233 best r: 0.3233
15:05:49,983 root INFO 
id:ro_en cur r: 0.6521 best r: 0.6521
15:06:03,60 root INFO 
id:si_en cur r: 0.5119 best r: 0.5119
15:06:16,143 root INFO 
id:ne_en cur r: 0.6652 best r: 0.6652
15:06:29,137 root INFO 
id:ru_en cur r: 0.7148 best r: 0.7148
15:06:29,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:00,613 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
15:08:00,619 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:08:00,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:08:00,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
15:08:00,634 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
15:08:00,638 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:08:00,643 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:08:13,778 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7238
en_de Dev loss: 0.9905 r:0.1513
en_zh Dev loss: 0.7684 r:0.3652
ro_en Dev loss: 0.6500 r:0.6808
et_en Dev loss: 0.4767 r:0.6428
si_en Dev loss: 0.7204 r:0.5390
ne_en Dev loss: 0.4398 r:0.6868
ru_en Dev loss: 0.5397 r:0.7338
Current avg r:0.5428 Best avg r: 0.5428
15:12:08,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:21,47 root INFO 
id:en_de cur r: 0.0817 best r: 0.0817
15:12:34,72 root INFO 
id:en_zh cur r: 0.3319 best r: 0.3319
15:12:47,117 root INFO 
id:ro_en cur r: 0.6883 best r: 0.6883
15:13:00,195 root INFO 
id:si_en cur r: 0.5217 best r: 0.5217
15:13:13,273 root INFO 
id:ne_en cur r: 0.6898 best r: 0.6898
15:13:26,251 root INFO 
id:ru_en cur r: 0.7286 best r: 0.7286
15:13:26,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:57,613 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
15:14:57,618 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:14:57,623 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:14:57,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
15:14:57,633 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
15:14:57,638 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:14:57,643 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:15:10,736 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6642
en_de Dev loss: 0.9176 r:0.1369
en_zh Dev loss: 0.7159 r:0.3713
ro_en Dev loss: 0.5174 r:0.7159
et_en Dev loss: 0.4114 r:0.6731
si_en Dev loss: 0.6453 r:0.5459
ne_en Dev loss: 0.3985 r:0.7093
ru_en Dev loss: 0.4448 r:0.7482
Current avg r:0.5572 Best avg r: 0.5572
15:19:05,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:18,89 root INFO 
id:en_de cur r: 0.1226 best r: 0.1226
15:19:31,120 root INFO 
id:en_zh cur r: 0.3433 best r: 0.3433
15:19:44,168 root INFO 
id:ro_en cur r: 0.7092 best r: 0.7092
15:19:57,250 root INFO 
id:si_en cur r: 0.5294 best r: 0.5294
15:20:10,321 root INFO 
id:ne_en cur r: 0.7074 best r: 0.7074
15:20:23,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:54,581 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
15:21:54,589 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:21:54,597 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:21:54,603 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
15:21:54,608 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
15:21:54,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:21:54,618 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:22:07,689 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6468
en_de Dev loss: 0.9027 r:0.1556
en_zh Dev loss: 0.7042 r:0.3804
ro_en Dev loss: 0.4736 r:0.7348
et_en Dev loss: 0.3961 r:0.6818
si_en Dev loss: 0.6505 r:0.5502
ne_en Dev loss: 0.3801 r:0.7230
ru_en Dev loss: 0.4228 r:0.7446
Current avg r:0.5672 Best avg r: 0.5672
15:26:01,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:14,892 root INFO 
id:en_de cur r: 0.1238 best r: 0.1238
15:26:27,912 root INFO 
id:en_zh cur r: 0.3556 best r: 0.3556
15:26:40,976 root INFO 
id:ro_en cur r: 0.7363 best r: 0.7363
15:26:54,76 root INFO 
id:si_en cur r: 0.5435 best r: 0.5435
15:27:07,157 root INFO 
id:ne_en cur r: 0.7133 best r: 0.7133
15:27:20,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:51,351 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
15:28:51,356 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:28:51,361 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:28:51,365 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
15:28:51,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
15:28:51,374 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:28:51,379 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:29:04,453 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6100
en_de Dev loss: 0.9218 r:0.1619
en_zh Dev loss: 0.7345 r:0.3830
ro_en Dev loss: 0.4394 r:0.7529
et_en Dev loss: 0.4168 r:0.6820
si_en Dev loss: 0.6952 r:0.5585
ne_en Dev loss: 0.4480 r:0.7179
ru_en Dev loss: 0.4609 r:0.7257
Current avg r:0.5689 Best avg r: 0.5689
15:32:58,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:11,492 root INFO 
id:en_de cur r: 0.1414 best r: 0.1414
15:33:24,556 root INFO 
id:en_zh cur r: 0.3859 best r: 0.3859
15:33:37,675 root INFO 
id:ro_en cur r: 0.7492 best r: 0.7492
15:33:50,818 root INFO 
id:si_en cur r: 0.5447 best r: 0.5447
15:34:03,944 root INFO 
id:ne_en cur r: 0.7236 best r: 0.7236
15:34:16,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:48,368 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
15:35:48,380 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:35:48,394 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:35:48,422 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
15:35:48,430 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
15:35:48,440 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:35:48,446 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:36:01,530 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5843
en_de Dev loss: 0.9172 r:0.1659
en_zh Dev loss: 0.7072 r:0.4004
ro_en Dev loss: 0.4216 r:0.7612
et_en Dev loss: 0.3967 r:0.6831
si_en Dev loss: 0.6617 r:0.5613
ne_en Dev loss: 0.4207 r:0.7281
ru_en Dev loss: 0.4471 r:0.7259
Current avg r:0.5751 Best avg r: 0.5751
15:39:55,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:34,312 root INFO 
id:ro_en cur r: 0.7599 best r: 0.7599
15:40:47,390 root INFO 
id:si_en cur r: 0.5594 best r: 0.5594
15:41:13,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:44,768 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5630
en_de Dev loss: 0.9349 r:0.1656
en_zh Dev loss: 0.7664 r:0.4024
ro_en Dev loss: 0.4139 r:0.7663
et_en Dev loss: 0.4479 r:0.6786
si_en Dev loss: 0.7621 r:0.5546
ne_en Dev loss: 0.5354 r:0.7159
ru_en Dev loss: 0.4998 r:0.7121
Current avg r:0.5708 Best avg r: 0.5751
15:46:38,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:17,949 root INFO 
id:ro_en cur r: 0.7787 best r: 0.7787
15:47:31,41 root INFO 
id:si_en cur r: 0.5683 best r: 0.5683
15:47:44,120 root INFO 
id:ne_en cur r: 0.7297 best r: 0.7297
15:47:57,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:28,375 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5787
en_de Dev loss: 0.9058 r:0.1710
en_zh Dev loss: 0.7370 r:0.3918
ro_en Dev loss: 0.3746 r:0.7801
et_en Dev loss: 0.4278 r:0.6669
si_en Dev loss: 0.6481 r:0.5687
ne_en Dev loss: 0.4619 r:0.7220
ru_en Dev loss: 0.4828 r:0.6782
Current avg r:0.5684 Best avg r: 0.5751
15:53:22,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:48,158 root INFO 
id:en_zh cur r: 0.4089 best r: 0.4089
15:54:01,212 root INFO 
id:ro_en cur r: 0.7866 best r: 0.7866
15:54:14,328 root INFO 
id:si_en cur r: 0.5922 best r: 0.5922
15:54:27,431 root INFO 
id:ne_en cur r: 0.7466 best r: 0.7466
15:54:40,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:11,860 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
15:56:11,866 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:56:11,871 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:56:11,877 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
15:56:11,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
15:56:11,887 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:56:11,892 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:56:24,985 root INFO Epoch 0 Global steps: 6600 Train loss: 0.6057
en_de Dev loss: 0.8781 r:0.1710
en_zh Dev loss: 0.6832 r:0.4164
ro_en Dev loss: 0.3241 r:0.7888
et_en Dev loss: 0.3684 r:0.6926
si_en Dev loss: 0.5514 r:0.5903
ne_en Dev loss: 0.3501 r:0.7479
ru_en Dev loss: 0.4109 r:0.7155
Current avg r:0.5889 Best avg r: 0.5889
16:00:19,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:32,84 root INFO 
id:en_de cur r: 0.1578 best r: 0.1578
16:00:58,167 root INFO 
id:ro_en cur r: 0.7961 best r: 0.7961
16:01:11,250 root INFO 
id:si_en cur r: 0.5924 best r: 0.5924
16:01:24,331 root INFO 
id:ne_en cur r: 0.7558 best r: 0.7558
16:01:37,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:08,669 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
16:03:08,677 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:03:08,684 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:03:08,689 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
16:03:08,694 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
16:03:08,699 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:03:08,705 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:03:21,799 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5764
en_de Dev loss: 0.8665 r:0.1882
en_zh Dev loss: 0.6930 r:0.4158
ro_en Dev loss: 0.3145 r:0.7988
et_en Dev loss: 0.3741 r:0.6969
si_en Dev loss: 0.5980 r:0.5896
ne_en Dev loss: 0.3399 r:0.7574
ru_en Dev loss: 0.4180 r:0.7236
Current avg r:0.5958 Best avg r: 0.5958
16:07:16,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:29,238 root INFO 
id:en_de cur r: 0.1704 best r: 0.1704
16:07:55,318 root INFO 
id:ro_en cur r: 0.7977 best r: 0.7977
16:08:34,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:05,813 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5509
en_de Dev loss: 0.8791 r:0.1964
en_zh Dev loss: 0.7227 r:0.4120
ro_en Dev loss: 0.3452 r:0.7969
et_en Dev loss: 0.4122 r:0.6849
si_en Dev loss: 0.7114 r:0.5772
ne_en Dev loss: 0.4171 r:0.7443
ru_en Dev loss: 0.4962 r:0.7033
Current avg r:0.5878 Best avg r: 0.5958
16:14:00,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:13,178 root INFO 
id:en_de cur r: 0.1722 best r: 0.1722
16:14:26,214 root INFO 
id:en_zh cur r: 0.4233 best r: 0.4233
16:14:39,266 root INFO 
id:ro_en cur r: 0.8183 best r: 0.8183
16:14:52,349 root INFO 
id:si_en cur r: 0.6145 best r: 0.6145
16:15:05,438 root INFO 
id:ne_en cur r: 0.7754 best r: 0.7754
16:15:18,424 root INFO 
id:ru_en cur r: 0.7574 best r: 0.7574
16:15:18,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:49,738 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
16:16:49,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:16:49,748 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:16:49,753 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
16:16:49,758 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
16:16:49,764 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:16:49,768 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:17:02,861 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5722
en_de Dev loss: 0.8656 r:0.2116
en_zh Dev loss: 0.6812 r:0.4282
ro_en Dev loss: 0.3037 r:0.8146
et_en Dev loss: 0.3547 r:0.7091
si_en Dev loss: 0.5957 r:0.6123
ne_en Dev loss: 0.3156 r:0.7783
ru_en Dev loss: 0.3776 r:0.7532
Current avg r:0.6153 Best avg r: 0.6153
16:20:57,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:21:10,103 root INFO 
id:en_de cur r: 0.1817 best r: 0.1817
16:22:15,312 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:46,603 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5206
en_de Dev loss: 0.8747 r:0.2050
en_zh Dev loss: 0.7251 r:0.4185
ro_en Dev loss: 0.3392 r:0.8088
et_en Dev loss: 0.3962 r:0.6971
si_en Dev loss: 0.7125 r:0.5915
ne_en Dev loss: 0.3827 r:0.7629
ru_en Dev loss: 0.4287 r:0.7415
Current avg r:0.6036 Best avg r: 0.6153
16:27:41,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:54,881 root INFO 
id:en_de cur r: 0.2034 best r: 0.2034
16:28:07,894 root INFO 
id:en_zh cur r: 0.4235 best r: 0.4235
16:29:00,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:31,275 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5262
en_de Dev loss: 0.8573 r:0.2204
en_zh Dev loss: 0.6925 r:0.4286
ro_en Dev loss: 0.3307 r:0.8130
et_en Dev loss: 0.4043 r:0.6863
si_en Dev loss: 0.7116 r:0.5901
ne_en Dev loss: 0.4922 r:0.7487
ru_en Dev loss: 0.4226 r:0.7362
Current avg r:0.6033 Best avg r: 0.6153
16:34:25,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:38,185 root INFO 
id:en_de cur r: 0.2134 best r: 0.2134
16:34:51,246 root INFO 
id:en_zh cur r: 0.4358 best r: 0.4358
16:35:43,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:15,231 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5417
en_de Dev loss: 0.8733 r:0.2260
en_zh Dev loss: 0.7099 r:0.4344
ro_en Dev loss: 0.4031 r:0.8000
et_en Dev loss: 0.3959 r:0.6945
si_en Dev loss: 0.7310 r:0.5884
ne_en Dev loss: 0.4769 r:0.7527
ru_en Dev loss: 0.4622 r:0.7326
Current avg r:0.6041 Best avg r: 0.6153
16:41:09,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:48,838 root INFO 
id:ro_en cur r: 0.8184 best r: 0.8184
16:42:28,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:59,787 root INFO Epoch 1 Global steps: 10800 Train loss: 0.4708
en_de Dev loss: 0.8724 r:0.2148
en_zh Dev loss: 0.7066 r:0.4376
ro_en Dev loss: 0.3201 r:0.8184
et_en Dev loss: 0.3944 r:0.6982
si_en Dev loss: 0.7126 r:0.6035
ne_en Dev loss: 0.4000 r:0.7649
ru_en Dev loss: 0.4415 r:0.7335
Current avg r:0.6101 Best avg r: 0.6153
16:47:53,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:11,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:43,523 root INFO Epoch 1 Global steps: 11400 Train loss: 0.5030
en_de Dev loss: 0.8775 r:0.2200
en_zh Dev loss: 0.7385 r:0.4183
ro_en Dev loss: 0.3444 r:0.8033
et_en Dev loss: 0.4219 r:0.6779
si_en Dev loss: 0.7667 r:0.5820
ne_en Dev loss: 0.4935 r:0.7467
ru_en Dev loss: 0.4350 r:0.7251
Current avg r:0.5962 Best avg r: 0.6153
16:54:37,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:50,677 root INFO 
id:en_de cur r: 0.2246 best r: 0.2246
16:55:55,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:27,495 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5259
en_de Dev loss: 0.8695 r:0.2380
en_zh Dev loss: 0.7401 r:0.4257
ro_en Dev loss: 0.3505 r:0.8057
et_en Dev loss: 0.3929 r:0.6934
si_en Dev loss: 0.7037 r:0.5938
ne_en Dev loss: 0.4212 r:0.7573
ru_en Dev loss: 0.4343 r:0.7319
Current avg r:0.6065 Best avg r: 0.6153
17:01:22,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:48,173 root INFO 
id:en_zh cur r: 0.4471 best r: 0.4471
17:02:01,225 root INFO 
id:ro_en cur r: 0.8222 best r: 0.8222
17:02:40,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:11,657 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
17:04:11,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:04:11,670 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:04:11,675 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
17:04:11,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
17:04:11,685 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:04:11,690 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:04:24,802 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5021
en_de Dev loss: 0.8405 r:0.2324
en_zh Dev loss: 0.6707 r:0.4483
ro_en Dev loss: 0.2890 r:0.8214
et_en Dev loss: 0.3680 r:0.7007
si_en Dev loss: 0.6370 r:0.6061
ne_en Dev loss: 0.3650 r:0.7693
ru_en Dev loss: 0.3822 r:0.7487
Current avg r:0.6181 Best avg r: 0.6181
17:08:19,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:37,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:08,750 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4970
en_de Dev loss: 0.8657 r:0.2338
en_zh Dev loss: 0.7325 r:0.4353
ro_en Dev loss: 0.3529 r:0.8154
et_en Dev loss: 0.3971 r:0.7009
si_en Dev loss: 0.7306 r:0.5959
ne_en Dev loss: 0.4373 r:0.7597
ru_en Dev loss: 0.4765 r:0.7238
Current avg r:0.6093 Best avg r: 0.6181
17:15:02,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:41,991 root INFO 
id:ro_en cur r: 0.8252 best r: 0.8252
17:16:21,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:52,452 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
17:17:52,458 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:17:52,464 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:17:52,469 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
17:17:52,475 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
17:17:52,480 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:17:52,485 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:18:05,559 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4799
en_de Dev loss: 0.8440 r:0.2411
en_zh Dev loss: 0.6778 r:0.4436
ro_en Dev loss: 0.2943 r:0.8241
et_en Dev loss: 0.3618 r:0.7058
si_en Dev loss: 0.6206 r:0.6108
ne_en Dev loss: 0.3402 r:0.7711
ru_en Dev loss: 0.3978 r:0.7443
Current avg r:0.6201 Best avg r: 0.6201
17:21:59,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:25,917 root INFO 
id:en_zh cur r: 0.4517 best r: 0.4517
17:22:39,19 root INFO 
id:ro_en cur r: 0.8319 best r: 0.8319
17:22:52,155 root INFO 
id:si_en cur r: 0.6192 best r: 0.6192
17:23:18,293 root INFO 
id:ru_en cur r: 0.7589 best r: 0.7589
17:23:18,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:49,672 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
17:24:49,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:24:49,685 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:24:49,689 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
17:24:49,694 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
17:24:49,698 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:24:49,703 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:25:02,793 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4844
en_de Dev loss: 0.8614 r:0.2015
en_zh Dev loss: 0.6572 r:0.4555
ro_en Dev loss: 0.2756 r:0.8289
et_en Dev loss: 0.3477 r:0.7154
si_en Dev loss: 0.5424 r:0.6206
ne_en Dev loss: 0.3221 r:0.7734
ru_en Dev loss: 0.3603 r:0.7582
Current avg r:0.6219 Best avg r: 0.6219
17:28:56,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:15,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:46,308 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4774
en_de Dev loss: 0.8685 r:0.2214
en_zh Dev loss: 0.7183 r:0.4316
ro_en Dev loss: 0.3089 r:0.8203
et_en Dev loss: 0.3779 r:0.7059
si_en Dev loss: 0.6469 r:0.6038
ne_en Dev loss: 0.4192 r:0.7660
ru_en Dev loss: 0.4392 r:0.7339
Current avg r:0.6119 Best avg r: 0.6219
17:35:40,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:58,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:29,579 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4810
en_de Dev loss: 0.8540 r:0.2139
en_zh Dev loss: 0.6905 r:0.4397
ro_en Dev loss: 0.2898 r:0.8233
et_en Dev loss: 0.3623 r:0.7056
si_en Dev loss: 0.6262 r:0.6050
ne_en Dev loss: 0.3809 r:0.7678
ru_en Dev loss: 0.3763 r:0.7548
Current avg r:0.6157 Best avg r: 0.6219
17:42:23,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:41,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:12,745 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4619
en_de Dev loss: 0.8707 r:0.2274
en_zh Dev loss: 0.7329 r:0.4318
ro_en Dev loss: 0.3369 r:0.8136
et_en Dev loss: 0.4140 r:0.6934
si_en Dev loss: 0.8305 r:0.5877
ne_en Dev loss: 0.4883 r:0.7609
ru_en Dev loss: 0.4692 r:0.7283
Current avg r:0.6062 Best avg r: 0.6219
17:49:06,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:24,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:56,61 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4628
en_de Dev loss: 0.8627 r:0.2198
en_zh Dev loss: 0.7501 r:0.4395
ro_en Dev loss: 0.3120 r:0.8206
et_en Dev loss: 0.4120 r:0.7015
si_en Dev loss: 0.7973 r:0.5947
ne_en Dev loss: 0.4849 r:0.7672
ru_en Dev loss: 0.4929 r:0.7244
Current avg r:0.6097 Best avg r: 0.6219
17:55:50,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:08,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:39,664 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4834
en_de Dev loss: 0.8669 r:0.1990
en_zh Dev loss: 0.7197 r:0.4482
ro_en Dev loss: 0.3284 r:0.8249
et_en Dev loss: 0.3867 r:0.7058
si_en Dev loss: 0.7125 r:0.6008
ne_en Dev loss: 0.4007 r:0.7689
ru_en Dev loss: 0.4381 r:0.7425
Current avg r:0.6129 Best avg r: 0.6219
18:02:33,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:51,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:23,298 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4840
en_de Dev loss: 0.8561 r:0.2042
en_zh Dev loss: 0.6924 r:0.4495
ro_en Dev loss: 0.2957 r:0.8296
et_en Dev loss: 0.3616 r:0.7110
si_en Dev loss: 0.6363 r:0.6111
ne_en Dev loss: 0.3449 r:0.7731
ru_en Dev loss: 0.3930 r:0.7542
Current avg r:0.6189 Best avg r: 0.6219
18:09:18,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:37,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:08,362 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4384
en_de Dev loss: 0.8600 r:0.2041
en_zh Dev loss: 0.7147 r:0.4399
ro_en Dev loss: 0.3116 r:0.8229
et_en Dev loss: 0.3700 r:0.7076
si_en Dev loss: 0.6449 r:0.6077
ne_en Dev loss: 0.3872 r:0.7669
ru_en Dev loss: 0.4207 r:0.7379
Current avg r:0.6124 Best avg r: 0.6219
18:16:02,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:28,541 root INFO 
id:en_zh cur r: 0.4626 best r: 0.4626
18:16:41,582 root INFO 
id:ro_en cur r: 0.8327 best r: 0.8327
18:17:20,680 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:51,964 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4658
en_de Dev loss: 0.8776 r:0.1813
en_zh Dev loss: 0.7095 r:0.4559
ro_en Dev loss: 0.2865 r:0.8307
et_en Dev loss: 0.3838 r:0.7075
si_en Dev loss: 0.6991 r:0.6113
ne_en Dev loss: 0.3682 r:0.7719
ru_en Dev loss: 0.4240 r:0.7388
Current avg r:0.6139 Best avg r: 0.6219
18:22:45,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:24:03,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:35,240 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4493
en_de Dev loss: 0.8828 r:0.1861
en_zh Dev loss: 0.7664 r:0.4318
ro_en Dev loss: 0.3512 r:0.8151
et_en Dev loss: 0.4394 r:0.6867
si_en Dev loss: 0.8752 r:0.5839
ne_en Dev loss: 0.5001 r:0.7536
ru_en Dev loss: 0.5165 r:0.6963
Current avg r:0.5934 Best avg r: 0.6219
18:29:29,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:47,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:19,453 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4607
en_de Dev loss: 0.8553 r:0.2097
en_zh Dev loss: 0.7072 r:0.4561
ro_en Dev loss: 0.3101 r:0.8272
et_en Dev loss: 0.3831 r:0.7055
si_en Dev loss: 0.6786 r:0.6131
ne_en Dev loss: 0.4485 r:0.7615
ru_en Dev loss: 0.4225 r:0.7463
Current avg r:0.6171 Best avg r: 0.6219
18:36:14,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:37:32,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:39:04,352 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4243
en_de Dev loss: 0.8628 r:0.2144
en_zh Dev loss: 0.7008 r:0.4583
ro_en Dev loss: 0.3249 r:0.8232
et_en Dev loss: 0.3896 r:0.6958
si_en Dev loss: 0.7175 r:0.6040
ne_en Dev loss: 0.4277 r:0.7578
ru_en Dev loss: 0.4534 r:0.7349
Current avg r:0.6126 Best avg r: 0.6219
18:42:59,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:17,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:49,267 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4165
en_de Dev loss: 0.8659 r:0.2108
en_zh Dev loss: 0.7150 r:0.4469
ro_en Dev loss: 0.2957 r:0.8260
et_en Dev loss: 0.3629 r:0.6990
si_en Dev loss: 0.5772 r:0.6181
ne_en Dev loss: 0.3525 r:0.7561
ru_en Dev loss: 0.3982 r:0.7481
Current avg r:0.6150 Best avg r: 0.6219
18:49:43,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:02,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:34,385 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4098
en_de Dev loss: 0.8833 r:0.1948
en_zh Dev loss: 0.7648 r:0.4273
ro_en Dev loss: 0.3294 r:0.8205
et_en Dev loss: 0.4149 r:0.6819
si_en Dev loss: 0.7013 r:0.6014
ne_en Dev loss: 0.4439 r:0.7559
ru_en Dev loss: 0.4963 r:0.7124
Current avg r:0.5992 Best avg r: 0.6219
18:56:29,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:47,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:19,414 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4192
en_de Dev loss: 0.8582 r:0.2084
en_zh Dev loss: 0.7244 r:0.4418
ro_en Dev loss: 0.3018 r:0.8224
et_en Dev loss: 0.3966 r:0.6878
si_en Dev loss: 0.7482 r:0.6031
ne_en Dev loss: 0.4752 r:0.7615
ru_en Dev loss: 0.4229 r:0.7382
Current avg r:0.6090 Best avg r: 0.6219
19:03:14,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:27,286 root INFO 
id:en_de cur r: 0.2360 best r: 0.2360
19:03:40,375 root INFO 
id:en_zh cur r: 0.4628 best r: 0.4628
19:04:32,818 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:04,603 root INFO Epoch 2 Global steps: 23400 Train loss: 0.3993
en_de Dev loss: 0.8417 r:0.2361
en_zh Dev loss: 0.7046 r:0.4560
ro_en Dev loss: 0.3079 r:0.8254
et_en Dev loss: 0.3662 r:0.6963
si_en Dev loss: 0.6043 r:0.6123
ne_en Dev loss: 0.3676 r:0.7617
ru_en Dev loss: 0.3962 r:0.7468
Current avg r:0.6192 Best avg r: 0.6219
19:09:59,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:17,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:12:49,742 root INFO Epoch 2 Global steps: 24000 Train loss: 0.3882
en_de Dev loss: 0.8476 r:0.2347
en_zh Dev loss: 0.7045 r:0.4483
ro_en Dev loss: 0.2969 r:0.8277
et_en Dev loss: 0.3788 r:0.6877
si_en Dev loss: 0.6317 r:0.6139
ne_en Dev loss: 0.3509 r:0.7689
ru_en Dev loss: 0.4288 r:0.7328
Current avg r:0.6163 Best avg r: 0.6219
19:16:44,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:10,292 root INFO 
id:en_zh cur r: 0.4630 best r: 0.4630
19:17:36,401 root INFO 
id:si_en cur r: 0.6226 best r: 0.6226
19:18:02,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:33,662 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4124
en_de Dev loss: 0.8498 r:0.2265
en_zh Dev loss: 0.6989 r:0.4628
ro_en Dev loss: 0.2982 r:0.8294
et_en Dev loss: 0.3667 r:0.6962
si_en Dev loss: 0.5641 r:0.6206
ne_en Dev loss: 0.3670 r:0.7659
ru_en Dev loss: 0.3911 r:0.7472
Current avg r:0.6212 Best avg r: 0.6219
19:23:27,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:45,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:16,837 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4135
en_de Dev loss: 0.8614 r:0.2129
en_zh Dev loss: 0.7259 r:0.4382
ro_en Dev loss: 0.3027 r:0.8220
et_en Dev loss: 0.3807 r:0.6898
si_en Dev loss: 0.6493 r:0.6008
ne_en Dev loss: 0.3905 r:0.7641
ru_en Dev loss: 0.4230 r:0.7380
Current avg r:0.6094 Best avg r: 0.6219
19:30:10,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:49,789 root INFO 
id:ro_en cur r: 0.8331 best r: 0.8331
19:31:28,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:00,166 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4267
en_de Dev loss: 0.8534 r:0.2205
en_zh Dev loss: 0.6961 r:0.4553
ro_en Dev loss: 0.2904 r:0.8291
et_en Dev loss: 0.3665 r:0.6970
si_en Dev loss: 0.5840 r:0.6166
ne_en Dev loss: 0.3448 r:0.7716
ru_en Dev loss: 0.3950 r:0.7497
Current avg r:0.6200 Best avg r: 0.6219
19:36:54,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:12,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:39:43,960 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4169
en_de Dev loss: 0.8520 r:0.2160
en_zh Dev loss: 0.7080 r:0.4550
ro_en Dev loss: 0.3019 r:0.8289
et_en Dev loss: 0.3915 r:0.6865
si_en Dev loss: 0.7307 r:0.6110
ne_en Dev loss: 0.4329 r:0.7697
ru_en Dev loss: 0.3943 r:0.7476
Current avg r:0.6164 Best avg r: 0.6219
19:43:38,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:56,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:46:27,709 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4150
en_de Dev loss: 0.8720 r:0.2098
en_zh Dev loss: 0.7703 r:0.4507
ro_en Dev loss: 0.3393 r:0.8224
et_en Dev loss: 0.4165 r:0.6799
si_en Dev loss: 0.8109 r:0.5848
ne_en Dev loss: 0.4510 r:0.7594
ru_en Dev loss: 0.4616 r:0.7262
Current avg r:0.6048 Best avg r: 0.6219
19:50:23,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:41,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:12,656 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3735
en_de Dev loss: 0.8614 r:0.2045
en_zh Dev loss: 0.7491 r:0.4242
ro_en Dev loss: 0.3067 r:0.8200
et_en Dev loss: 0.3833 r:0.6822
si_en Dev loss: 0.6453 r:0.5826
ne_en Dev loss: 0.4015 r:0.7499
ru_en Dev loss: 0.4486 r:0.7053
Current avg r:0.5955 Best avg r: 0.6219
19:57:06,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:25,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:56,924 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3705
en_de Dev loss: 0.8618 r:0.1954
en_zh Dev loss: 0.7158 r:0.4458
ro_en Dev loss: 0.2926 r:0.8254
et_en Dev loss: 0.3898 r:0.6785
si_en Dev loss: 0.6218 r:0.6021
ne_en Dev loss: 0.3735 r:0.7597
ru_en Dev loss: 0.3945 r:0.7404
Current avg r:0.6067 Best avg r: 0.6219
20:03:51,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:09,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:41,442 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3589
en_de Dev loss: 0.8709 r:0.1824
en_zh Dev loss: 0.7510 r:0.4343
ro_en Dev loss: 0.3208 r:0.8226
et_en Dev loss: 0.4307 r:0.6691
si_en Dev loss: 0.7153 r:0.5949
ne_en Dev loss: 0.5081 r:0.7585
ru_en Dev loss: 0.4723 r:0.7175
Current avg r:0.5970 Best avg r: 0.6219
20:10:35,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:54,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:25,700 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3812
en_de Dev loss: 0.8582 r:0.2173
en_zh Dev loss: 0.7669 r:0.4256
ro_en Dev loss: 0.2982 r:0.8261
et_en Dev loss: 0.3956 r:0.6803
si_en Dev loss: 0.6352 r:0.6029
ne_en Dev loss: 0.3913 r:0.7541
ru_en Dev loss: 0.4208 r:0.7384
Current avg r:0.6064 Best avg r: 0.6219
20:17:20,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:38,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:09,803 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3542
en_de Dev loss: 0.8561 r:0.2029
en_zh Dev loss: 0.7486 r:0.4281
ro_en Dev loss: 0.3129 r:0.8188
et_en Dev loss: 0.4063 r:0.6739
si_en Dev loss: 0.7247 r:0.5918
ne_en Dev loss: 0.5039 r:0.7491
ru_en Dev loss: 0.4581 r:0.7158
Current avg r:0.5972 Best avg r: 0.6219
20:24:04,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:22,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:53,673 root INFO Epoch 3 Global steps: 30600 Train loss: 0.4021
en_de Dev loss: 0.8598 r:0.2129
en_zh Dev loss: 0.7262 r:0.4506
ro_en Dev loss: 0.3031 r:0.8243
et_en Dev loss: 0.4040 r:0.6765
si_en Dev loss: 0.7560 r:0.5875
ne_en Dev loss: 0.4438 r:0.7482
ru_en Dev loss: 0.4211 r:0.7359
Current avg r:0.6051 Best avg r: 0.6219
20:30:48,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:06,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:38,291 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3500
en_de Dev loss: 0.8990 r:0.1710
en_zh Dev loss: 0.7619 r:0.4341
ro_en Dev loss: 0.3128 r:0.8209
et_en Dev loss: 0.4154 r:0.6796
si_en Dev loss: 0.7571 r:0.5877
ne_en Dev loss: 0.4715 r:0.7477
ru_en Dev loss: 0.4552 r:0.7252
Current avg r:0.5952 Best avg r: 0.6219
20:37:32,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:51,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:22,776 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3461
en_de Dev loss: 0.8733 r:0.2014
en_zh Dev loss: 0.7365 r:0.4482
ro_en Dev loss: 0.3086 r:0.8224
et_en Dev loss: 0.4053 r:0.6790
si_en Dev loss: 0.7375 r:0.5943
ne_en Dev loss: 0.4293 r:0.7597
ru_en Dev loss: 0.4234 r:0.7389
Current avg r:0.6063 Best avg r: 0.6219
20:44:16,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:35,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:06,460 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3951
en_de Dev loss: 0.9362 r:0.1626
en_zh Dev loss: 0.7759 r:0.4510
ro_en Dev loss: 0.3224 r:0.8250
et_en Dev loss: 0.4163 r:0.6737
si_en Dev loss: 0.7043 r:0.5964
ne_en Dev loss: 0.4034 r:0.7532
ru_en Dev loss: 0.4686 r:0.7219
Current avg r:0.5977 Best avg r: 0.6219
20:51:00,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:26,938 root INFO 
id:en_zh cur r: 0.4671 best r: 0.4671
20:52:19,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:50,747 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3311
en_de Dev loss: 0.8739 r:0.1718
en_zh Dev loss: 0.7070 r:0.4577
ro_en Dev loss: 0.2974 r:0.8271
et_en Dev loss: 0.3963 r:0.6783
si_en Dev loss: 0.6922 r:0.5932
ne_en Dev loss: 0.3691 r:0.7632
ru_en Dev loss: 0.4034 r:0.7413
Current avg r:0.6047 Best avg r: 0.6219
20:57:45,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:03,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:35,150 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3547
en_de Dev loss: 0.8738 r:0.1869
en_zh Dev loss: 0.7283 r:0.4498
ro_en Dev loss: 0.2999 r:0.8256
et_en Dev loss: 0.4107 r:0.6727
si_en Dev loss: 0.7513 r:0.5952
ne_en Dev loss: 0.4091 r:0.7530
ru_en Dev loss: 0.4030 r:0.7459
Current avg r:0.6042 Best avg r: 0.6219
21:04:29,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:47,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:18,614 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3552
en_de Dev loss: 0.8829 r:0.1676
en_zh Dev loss: 0.7874 r:0.4298
ro_en Dev loss: 0.3343 r:0.8255
et_en Dev loss: 0.4349 r:0.6694
si_en Dev loss: 0.8001 r:0.5880
ne_en Dev loss: 0.5116 r:0.7527
ru_en Dev loss: 0.4749 r:0.7170
Current avg r:0.5928 Best avg r: 0.6219
21:11:12,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:31,151 root INFO 
id:ru_en cur r: 0.7665 best r: 0.7665
21:12:31,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:02,782 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3548
en_de Dev loss: 0.8725 r:0.1952
en_zh Dev loss: 0.7396 r:0.4516
ro_en Dev loss: 0.3033 r:0.8234
et_en Dev loss: 0.3844 r:0.6879
si_en Dev loss: 0.5824 r:0.6061
ne_en Dev loss: 0.3827 r:0.7448
ru_en Dev loss: 0.3620 r:0.7647
Current avg r:0.6105 Best avg r: 0.6219
21:17:57,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:15,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:47,217 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3382
en_de Dev loss: 0.8593 r:0.2151
en_zh Dev loss: 0.7520 r:0.4326
ro_en Dev loss: 0.3034 r:0.8269
et_en Dev loss: 0.4184 r:0.6743
si_en Dev loss: 0.7620 r:0.5799
ne_en Dev loss: 0.4654 r:0.7502
ru_en Dev loss: 0.4339 r:0.7282
Current avg r:0.6010 Best avg r: 0.6219
21:24:41,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:59,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:31,609 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3464
en_de Dev loss: 0.8586 r:0.2167
en_zh Dev loss: 0.7620 r:0.4256
ro_en Dev loss: 0.3089 r:0.8226
et_en Dev loss: 0.4106 r:0.6699
si_en Dev loss: 0.7281 r:0.5837
ne_en Dev loss: 0.4836 r:0.7441
ru_en Dev loss: 0.4340 r:0.7259
Current avg r:0.5984 Best avg r: 0.6219
21:31:27,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:46,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:17,835 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3034
en_de Dev loss: 0.8689 r:0.2217
en_zh Dev loss: 0.7713 r:0.4324
ro_en Dev loss: 0.3128 r:0.8270
et_en Dev loss: 0.4177 r:0.6683
si_en Dev loss: 0.7736 r:0.5810
ne_en Dev loss: 0.4825 r:0.7434
ru_en Dev loss: 0.4521 r:0.7214
Current avg r:0.5993 Best avg r: 0.6219
21:38:12,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:51,755 root INFO 
id:ro_en cur r: 0.8336 best r: 0.8336
21:39:31,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:02,648 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3298
en_de Dev loss: 0.8684 r:0.2046
en_zh Dev loss: 0.7467 r:0.4419
ro_en Dev loss: 0.2964 r:0.8317
et_en Dev loss: 0.4131 r:0.6640
si_en Dev loss: 0.7026 r:0.5819
ne_en Dev loss: 0.4465 r:0.7421
ru_en Dev loss: 0.4298 r:0.7287
Current avg r:0.5993 Best avg r: 0.6219
21:44:57,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:46:15,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:47:47,462 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3056
en_de Dev loss: 0.9132 r:0.1960
en_zh Dev loss: 0.8108 r:0.4324
ro_en Dev loss: 0.3605 r:0.8236
et_en Dev loss: 0.4605 r:0.6610
si_en Dev loss: 0.8731 r:0.5619
ne_en Dev loss: 0.4963 r:0.7386
ru_en Dev loss: 0.5134 r:0.7065
Current avg r:0.5886 Best avg r: 0.6219
21:51:42,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:00,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:32,125 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3005
en_de Dev loss: 0.8792 r:0.1859
en_zh Dev loss: 0.7832 r:0.4272
ro_en Dev loss: 0.3127 r:0.8240
et_en Dev loss: 0.4293 r:0.6487
si_en Dev loss: 0.7843 r:0.5597
ne_en Dev loss: 0.5029 r:0.7358
ru_en Dev loss: 0.4465 r:0.7154
Current avg r:0.5853 Best avg r: 0.6219
21:58:26,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:45,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:16,821 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3005
en_de Dev loss: 0.9037 r:0.1795
en_zh Dev loss: 0.8395 r:0.4236
ro_en Dev loss: 0.3530 r:0.8237
et_en Dev loss: 0.4484 r:0.6598
si_en Dev loss: 0.8043 r:0.5740
ne_en Dev loss: 0.4932 r:0.7460
ru_en Dev loss: 0.4921 r:0.7253
Current avg r:0.5903 Best avg r: 0.6219
22:05:11,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:30,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:08:01,692 root INFO Epoch 4 Global steps: 39600 Train loss: 0.2904
en_de Dev loss: 0.8785 r:0.1715
en_zh Dev loss: 0.7678 r:0.4309
ro_en Dev loss: 0.3014 r:0.8281
et_en Dev loss: 0.4226 r:0.6557
si_en Dev loss: 0.7159 r:0.5863
ne_en Dev loss: 0.4853 r:0.7457
ru_en Dev loss: 0.4551 r:0.7139
Current avg r:0.5903 Best avg r: 0.6219
22:11:56,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:15,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:46,849 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3080
en_de Dev loss: 0.8771 r:0.1718
en_zh Dev loss: 0.7568 r:0.4275
ro_en Dev loss: 0.3118 r:0.8233
et_en Dev loss: 0.4307 r:0.6493
si_en Dev loss: 0.7917 r:0.5737
ne_en Dev loss: 0.5160 r:0.7455
ru_en Dev loss: 0.4540 r:0.7125
Current avg r:0.5862 Best avg r: 0.6219
22:18:41,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:00,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:21:31,986 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3180
en_de Dev loss: 0.8793 r:0.1935
en_zh Dev loss: 0.7895 r:0.4278
ro_en Dev loss: 0.3216 r:0.8267
et_en Dev loss: 0.4292 r:0.6590
si_en Dev loss: 0.7719 r:0.5835
ne_en Dev loss: 0.4738 r:0.7430
ru_en Dev loss: 0.4414 r:0.7309
Current avg r:0.5949 Best avg r: 0.6219
22:25:26,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:26:45,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:28:17,216 root INFO Epoch 4 Global steps: 41400 Train loss: 0.2792
en_de Dev loss: 0.8591 r:0.2153
en_zh Dev loss: 0.7742 r:0.4263
ro_en Dev loss: 0.2910 r:0.8281
et_en Dev loss: 0.4050 r:0.6591
si_en Dev loss: 0.7072 r:0.5776
ne_en Dev loss: 0.4532 r:0.7397
ru_en Dev loss: 0.4010 r:0.7367
Current avg r:0.5975 Best avg r: 0.6219
22:32:11,655 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:30,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:01,944 root INFO Epoch 4 Global steps: 42000 Train loss: 0.2925
en_de Dev loss: 0.8648 r:0.2103
en_zh Dev loss: 0.7918 r:0.4172
ro_en Dev loss: 0.3118 r:0.8256
et_en Dev loss: 0.4180 r:0.6596
si_en Dev loss: 0.7584 r:0.5732
ne_en Dev loss: 0.4757 r:0.7346
ru_en Dev loss: 0.4506 r:0.7240
Current avg r:0.5921 Best avg r: 0.6219
22:38:56,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:15,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:46,921 root INFO Epoch 4 Global steps: 42600 Train loss: 0.2922
en_de Dev loss: 0.8686 r:0.2165
en_zh Dev loss: 0.7717 r:0.4350
ro_en Dev loss: 0.2898 r:0.8328
et_en Dev loss: 0.3895 r:0.6797
si_en Dev loss: 0.6190 r:0.5968
ne_en Dev loss: 0.3727 r:0.7559
ru_en Dev loss: 0.4038 r:0.7453
Current avg r:0.6089 Best avg r: 0.6219
22:45:41,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:00,236 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:48:31,950 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3129
en_de Dev loss: 0.8672 r:0.2207
en_zh Dev loss: 0.7945 r:0.4395
ro_en Dev loss: 0.3235 r:0.8283
et_en Dev loss: 0.4260 r:0.6635
si_en Dev loss: 0.8286 r:0.5732
ne_en Dev loss: 0.5029 r:0.7445
ru_en Dev loss: 0.4785 r:0.7232
Current avg r:0.5990 Best avg r: 0.6219
22:52:26,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:45,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:17,8 root INFO Epoch 4 Global steps: 43800 Train loss: 0.2946
en_de Dev loss: 0.8565 r:0.2356
en_zh Dev loss: 0.7612 r:0.4496
ro_en Dev loss: 0.3264 r:0.8254
et_en Dev loss: 0.4256 r:0.6554
si_en Dev loss: 0.7860 r:0.5736
ne_en Dev loss: 0.4878 r:0.7349
ru_en Dev loss: 0.4329 r:0.7349
Current avg r:0.6013 Best avg r: 0.6219
22:59:11,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:00:30,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:02:02,222 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2853
en_de Dev loss: 0.9120 r:0.1947
en_zh Dev loss: 0.8187 r:0.4239
ro_en Dev loss: 0.3366 r:0.8271
et_en Dev loss: 0.4538 r:0.6592
si_en Dev loss: 0.8206 r:0.5684
ne_en Dev loss: 0.4858 r:0.7383
ru_en Dev loss: 0.4960 r:0.7169
Current avg r:0.5898 Best avg r: 0.6219
23:05:57,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:15,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:47,467 root INFO Epoch 4 Global steps: 45000 Train loss: 0.2842
en_de Dev loss: 0.8882 r:0.1831
en_zh Dev loss: 0.8038 r:0.4193
ro_en Dev loss: 0.3217 r:0.8275
et_en Dev loss: 0.4095 r:0.6716
si_en Dev loss: 0.7255 r:0.5774
ne_en Dev loss: 0.4356 r:0.7411
ru_en Dev loss: 0.4507 r:0.7235
Current avg r:0.5919 Best avg r: 0.6219
23:12:43,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:01,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:33,311 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2418
en_de Dev loss: 0.8965 r:0.1739
en_zh Dev loss: 0.7974 r:0.4239
ro_en Dev loss: 0.3314 r:0.8235
et_en Dev loss: 0.4239 r:0.6610
si_en Dev loss: 0.8256 r:0.5677
ne_en Dev loss: 0.5022 r:0.7345
ru_en Dev loss: 0.4515 r:0.7238
Current avg r:0.5869 Best avg r: 0.6219
23:19:27,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:46,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:17,564 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2524
en_de Dev loss: 0.9051 r:0.1685
en_zh Dev loss: 0.8043 r:0.4310
ro_en Dev loss: 0.3277 r:0.8245
et_en Dev loss: 0.4314 r:0.6624
si_en Dev loss: 0.8564 r:0.5681
ne_en Dev loss: 0.5456 r:0.7327
ru_en Dev loss: 0.4445 r:0.7342
Current avg r:0.5888 Best avg r: 0.6219
23:26:11,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:27:30,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:01,551 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2530
en_de Dev loss: 0.8993 r:0.1748
en_zh Dev loss: 0.8286 r:0.4154
ro_en Dev loss: 0.3353 r:0.8233
et_en Dev loss: 0.4257 r:0.6649
si_en Dev loss: 0.8107 r:0.5665
ne_en Dev loss: 0.4889 r:0.7337
ru_en Dev loss: 0.4886 r:0.7111
Current avg r:0.5842 Best avg r: 0.6219
23:32:55,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:34:13,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:45,502 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2553
en_de Dev loss: 0.8802 r:0.1887
en_zh Dev loss: 0.8149 r:0.4233
ro_en Dev loss: 0.3281 r:0.8251
et_en Dev loss: 0.4211 r:0.6666
si_en Dev loss: 0.8394 r:0.5714
ne_en Dev loss: 0.4544 r:0.7401
ru_en Dev loss: 0.4478 r:0.7331
Current avg r:0.5926 Best avg r: 0.6219
23:39:39,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:57,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:29,449 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2566
en_de Dev loss: 0.8961 r:0.1546
en_zh Dev loss: 0.8372 r:0.4003
ro_en Dev loss: 0.3355 r:0.8226
et_en Dev loss: 0.4553 r:0.6466
si_en Dev loss: 0.9166 r:0.5578
ne_en Dev loss: 0.5286 r:0.7318
ru_en Dev loss: 0.5105 r:0.6984
Current avg r:0.5732 Best avg r: 0.6219
23:46:23,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:42,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:13,846 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2501
en_de Dev loss: 0.8955 r:0.1727
en_zh Dev loss: 0.8007 r:0.4246
ro_en Dev loss: 0.3390 r:0.8235
et_en Dev loss: 0.4402 r:0.6523
si_en Dev loss: 0.8140 r:0.5613
ne_en Dev loss: 0.5573 r:0.7267
ru_en Dev loss: 0.4994 r:0.7073
Current avg r:0.5812 Best avg r: 0.6219
23:53:08,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:26,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:58,109 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2417
en_de Dev loss: 0.9061 r:0.1632
en_zh Dev loss: 0.7946 r:0.4168
ro_en Dev loss: 0.3104 r:0.8263
et_en Dev loss: 0.4135 r:0.6640
si_en Dev loss: 0.7662 r:0.5617
ne_en Dev loss: 0.4777 r:0.7267
ru_en Dev loss: 0.4336 r:0.7329
Current avg r:0.5845 Best avg r: 0.6219
23:59:52,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:10,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:02:42,362 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2590
en_de Dev loss: 0.9123 r:0.1948
en_zh Dev loss: 0.8374 r:0.4387
ro_en Dev loss: 0.3438 r:0.8252
et_en Dev loss: 0.4278 r:0.6642
si_en Dev loss: 0.8146 r:0.5669
ne_en Dev loss: 0.5210 r:0.7290
ru_en Dev loss: 0.4550 r:0.7272
Current avg r:0.5923 Best avg r: 0.6219
00:06:36,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:54,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:09:26,210 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2578
en_de Dev loss: 0.8739 r:0.1940
en_zh Dev loss: 0.7749 r:0.4438
ro_en Dev loss: 0.3463 r:0.8274
et_en Dev loss: 0.4168 r:0.6657
si_en Dev loss: 0.7600 r:0.5717
ne_en Dev loss: 0.4785 r:0.7304
ru_en Dev loss: 0.4239 r:0.7403
Current avg r:0.5962 Best avg r: 0.6219
00:13:20,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:38,688 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:16:10,94 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2560
en_de Dev loss: 0.9014 r:0.1905
en_zh Dev loss: 0.8316 r:0.4187
ro_en Dev loss: 0.3333 r:0.8216
et_en Dev loss: 0.4275 r:0.6636
si_en Dev loss: 0.8536 r:0.5661
ne_en Dev loss: 0.5086 r:0.7333
ru_en Dev loss: 0.4706 r:0.7227
Current avg r:0.5881 Best avg r: 0.6219
00:20:04,120 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:21:22,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:53,963 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2419
en_de Dev loss: 0.9041 r:0.1710
en_zh Dev loss: 0.8340 r:0.4236
ro_en Dev loss: 0.3692 r:0.8206
et_en Dev loss: 0.4581 r:0.6540
si_en Dev loss: 0.8964 r:0.5662
ne_en Dev loss: 0.5529 r:0.7334
ru_en Dev loss: 0.5129 r:0.7040
Current avg r:0.5818 Best avg r: 0.6219
00:26:48,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:06,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:38,463 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2451
en_de Dev loss: 0.8889 r:0.1798
en_zh Dev loss: 0.7869 r:0.4413
ro_en Dev loss: 0.3376 r:0.8249
et_en Dev loss: 0.4195 r:0.6596
si_en Dev loss: 0.7690 r:0.5713
ne_en Dev loss: 0.4632 r:0.7382
ru_en Dev loss: 0.4663 r:0.7160
Current avg r:0.5901 Best avg r: 0.6219
00:33:32,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:51,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:22,876 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2559
en_de Dev loss: 0.9060 r:0.1790
en_zh Dev loss: 0.7973 r:0.4448
ro_en Dev loss: 0.3477 r:0.8191
et_en Dev loss: 0.4273 r:0.6548
si_en Dev loss: 0.8094 r:0.5652
ne_en Dev loss: 0.4912 r:0.7211
ru_en Dev loss: 0.4797 r:0.7194
Current avg r:0.5862 Best avg r: 0.6219
00:40:17,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:43,416 root INFO 
id:en_zh cur r: 0.4759 best r: 0.4759
00:41:35,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:07,76 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2604
en_de Dev loss: 0.8890 r:0.1922
en_zh Dev loss: 0.7501 r:0.4670
ro_en Dev loss: 0.3277 r:0.8205
et_en Dev loss: 0.4145 r:0.6588
si_en Dev loss: 0.7816 r:0.5737
ne_en Dev loss: 0.5013 r:0.7319
ru_en Dev loss: 0.4469 r:0.7322
Current avg r:0.5966 Best avg r: 0.6219
00:47:01,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:19,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:51,61 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2475
en_de Dev loss: 0.9018 r:0.1771
en_zh Dev loss: 0.7770 r:0.4617
ro_en Dev loss: 0.3493 r:0.8185
et_en Dev loss: 0.4310 r:0.6546
si_en Dev loss: 0.7975 r:0.5685
ne_en Dev loss: 0.4865 r:0.7328
ru_en Dev loss: 0.4621 r:0.7260
Current avg r:0.5913 Best avg r: 0.6219
00:53:46,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:54:12,421 root INFO 
id:en_zh cur r: 0.4817 best r: 0.4817
00:55:04,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:56:36,107 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2199
en_de Dev loss: 0.8981 r:0.1919
en_zh Dev loss: 0.7515 r:0.4691
ro_en Dev loss: 0.3215 r:0.8217
et_en Dev loss: 0.4093 r:0.6659
si_en Dev loss: 0.7530 r:0.5717
ne_en Dev loss: 0.4500 r:0.7287
ru_en Dev loss: 0.4213 r:0.7401
Current avg r:0.5984 Best avg r: 0.6219
01:00:30,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:01:48,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:20,227 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2145
en_de Dev loss: 0.8900 r:0.1711
en_zh Dev loss: 0.7375 r:0.4541
ro_en Dev loss: 0.3152 r:0.8208
et_en Dev loss: 0.4109 r:0.6525
si_en Dev loss: 0.7132 r:0.5720
ne_en Dev loss: 0.4529 r:0.7298
ru_en Dev loss: 0.4295 r:0.7210
Current avg r:0.5888 Best avg r: 0.6219
01:07:14,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:32,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:03,696 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2172
en_de Dev loss: 0.9109 r:0.1696
en_zh Dev loss: 0.7787 r:0.4614
ro_en Dev loss: 0.3401 r:0.8253
et_en Dev loss: 0.4290 r:0.6534
si_en Dev loss: 0.8966 r:0.5620
ne_en Dev loss: 0.5071 r:0.7257
ru_en Dev loss: 0.4528 r:0.7266
Current avg r:0.5891 Best avg r: 0.6219
01:13:57,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:16,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:47,809 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2331
en_de Dev loss: 0.8962 r:0.1747
en_zh Dev loss: 0.7906 r:0.4474
ro_en Dev loss: 0.3401 r:0.8228
et_en Dev loss: 0.4217 r:0.6555
si_en Dev loss: 0.7734 r:0.5610
ne_en Dev loss: 0.4474 r:0.7247
ru_en Dev loss: 0.4370 r:0.7300
Current avg r:0.5880 Best avg r: 0.6219
01:20:42,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:22:00,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:31,989 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2157
en_de Dev loss: 0.8915 r:0.1765
en_zh Dev loss: 0.8020 r:0.4374
ro_en Dev loss: 0.3509 r:0.8159
et_en Dev loss: 0.4519 r:0.6358
si_en Dev loss: 0.8609 r:0.5523
ne_en Dev loss: 0.5756 r:0.7193
ru_en Dev loss: 0.4894 r:0.7006
Current avg r:0.5769 Best avg r: 0.6219
01:27:26,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:45,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:16,554 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2315
en_de Dev loss: 0.9029 r:0.1699
en_zh Dev loss: 0.8082 r:0.4403
ro_en Dev loss: 0.3241 r:0.8206
et_en Dev loss: 0.4459 r:0.6432
si_en Dev loss: 0.8304 r:0.5646
ne_en Dev loss: 0.5439 r:0.7276
ru_en Dev loss: 0.4987 r:0.7030
Current avg r:0.5813 Best avg r: 0.6219
01:34:10,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:29,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:00,794 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2183
en_de Dev loss: 0.9213 r:0.1689
en_zh Dev loss: 0.8245 r:0.4354
ro_en Dev loss: 0.3469 r:0.8201
et_en Dev loss: 0.4632 r:0.6423
si_en Dev loss: 0.9046 r:0.5553
ne_en Dev loss: 0.5909 r:0.7238
ru_en Dev loss: 0.5086 r:0.7158
Current avg r:0.5802 Best avg r: 0.6219
01:40:55,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:13,754 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:45,117 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2252
en_de Dev loss: 0.8925 r:0.1766
en_zh Dev loss: 0.7762 r:0.4458
ro_en Dev loss: 0.3325 r:0.8192
et_en Dev loss: 0.4376 r:0.6467
si_en Dev loss: 0.8238 r:0.5654
ne_en Dev loss: 0.5585 r:0.7277
ru_en Dev loss: 0.4420 r:0.7264
Current avg r:0.5868 Best avg r: 0.6219
01:47:39,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:48:57,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:50:28,995 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2062
en_de Dev loss: 0.8937 r:0.1721
en_zh Dev loss: 0.7823 r:0.4347
ro_en Dev loss: 0.3163 r:0.8204
et_en Dev loss: 0.4213 r:0.6516
si_en Dev loss: 0.7859 r:0.5670
ne_en Dev loss: 0.4851 r:0.7308
ru_en Dev loss: 0.4365 r:0.7317
Current avg r:0.5869 Best avg r: 0.6219
01:54:23,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:55:41,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:57:13,0 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2102
en_de Dev loss: 0.9658 r:0.1571
en_zh Dev loss: 0.8511 r:0.4418
ro_en Dev loss: 0.3520 r:0.8194
et_en Dev loss: 0.4443 r:0.6511
si_en Dev loss: 0.8150 r:0.5672
ne_en Dev loss: 0.4965 r:0.7225
ru_en Dev loss: 0.4860 r:0.7197
Current avg r:0.5827 Best avg r: 0.6219
02:01:09,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:02:28,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:04:00,761 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2159
en_de Dev loss: 0.8982 r:0.1788
en_zh Dev loss: 0.7941 r:0.4443
ro_en Dev loss: 0.3310 r:0.8209
et_en Dev loss: 0.4324 r:0.6556
si_en Dev loss: 0.9191 r:0.5573
ne_en Dev loss: 0.5820 r:0.7295
ru_en Dev loss: 0.4517 r:0.7334
Current avg r:0.5885 Best avg r: 0.6219
02:07:57,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:09:17,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:49,334 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2166
en_de Dev loss: 0.8838 r:0.1839
en_zh Dev loss: 0.7739 r:0.4526
ro_en Dev loss: 0.3327 r:0.8198
et_en Dev loss: 0.4232 r:0.6555
si_en Dev loss: 0.8584 r:0.5649
ne_en Dev loss: 0.5273 r:0.7314
ru_en Dev loss: 0.4601 r:0.7300
Current avg r:0.5912 Best avg r: 0.6219
02:14:46,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:05,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:17:37,823 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2073
en_de Dev loss: 0.8903 r:0.1735
en_zh Dev loss: 0.8013 r:0.4432
ro_en Dev loss: 0.3252 r:0.8193
et_en Dev loss: 0.4246 r:0.6544
si_en Dev loss: 0.8336 r:0.5626
ne_en Dev loss: 0.5048 r:0.7272
ru_en Dev loss: 0.4373 r:0.7327
Current avg r:0.5875 Best avg r: 0.6219
02:21:34,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:22:53,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:24:25,991 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2071
en_de Dev loss: 0.8938 r:0.1764
en_zh Dev loss: 0.7789 r:0.4392
ro_en Dev loss: 0.3336 r:0.8206
et_en Dev loss: 0.4341 r:0.6546
si_en Dev loss: 0.7441 r:0.5684
ne_en Dev loss: 0.4523 r:0.7284
ru_en Dev loss: 0.4100 r:0.7430
Current avg r:0.5901 Best avg r: 0.6219
02:28:22,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:40,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:31:12,192 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2128
en_de Dev loss: 0.8879 r:0.1745
en_zh Dev loss: 0.7640 r:0.4382
ro_en Dev loss: 0.3117 r:0.8196
et_en Dev loss: 0.4237 r:0.6495
si_en Dev loss: 0.7446 r:0.5604
ne_en Dev loss: 0.4542 r:0.7272
ru_en Dev loss: 0.4456 r:0.7180
Current avg r:0.5839 Best avg r: 0.6219
02:35:08,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:26,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:37:57,746 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1870
en_de Dev loss: 0.8944 r:0.1704
en_zh Dev loss: 0.8364 r:0.4359
ro_en Dev loss: 0.3328 r:0.8201
et_en Dev loss: 0.4447 r:0.6438
si_en Dev loss: 0.8654 r:0.5536
ne_en Dev loss: 0.5643 r:0.7223
ru_en Dev loss: 0.4738 r:0.7208
Current avg r:0.5810 Best avg r: 0.6219
02:41:52,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:10,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:42,186 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1857
en_de Dev loss: 0.9214 r:0.1746
en_zh Dev loss: 0.8200 r:0.4455
ro_en Dev loss: 0.3440 r:0.8204
et_en Dev loss: 0.4424 r:0.6602
si_en Dev loss: 0.8096 r:0.5673
ne_en Dev loss: 0.5092 r:0.7302
ru_en Dev loss: 0.4750 r:0.7309
Current avg r:0.5899 Best avg r: 0.6219
02:48:36,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:49:55,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:26,632 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1855
en_de Dev loss: 0.9120 r:0.1661
en_zh Dev loss: 0.8286 r:0.4302
ro_en Dev loss: 0.3340 r:0.8234
et_en Dev loss: 0.4463 r:0.6525
si_en Dev loss: 0.8741 r:0.5578
ne_en Dev loss: 0.5469 r:0.7292
ru_en Dev loss: 0.4586 r:0.7296
Current avg r:0.5841 Best avg r: 0.6219
02:55:21,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:39,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:58:11,108 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1890
en_de Dev loss: 0.9202 r:0.1798
en_zh Dev loss: 0.8489 r:0.4364
ro_en Dev loss: 0.3326 r:0.8262
et_en Dev loss: 0.4413 r:0.6568
si_en Dev loss: 0.7921 r:0.5651
ne_en Dev loss: 0.4808 r:0.7209
ru_en Dev loss: 0.4707 r:0.7303
Current avg r:0.5879 Best avg r: 0.6219
03:02:05,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:24,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:55,467 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1877
en_de Dev loss: 0.9100 r:0.1803
en_zh Dev loss: 0.8154 r:0.4323
ro_en Dev loss: 0.3322 r:0.8208
et_en Dev loss: 0.4305 r:0.6608
si_en Dev loss: 0.8067 r:0.5552
ne_en Dev loss: 0.4868 r:0.7164
ru_en Dev loss: 0.4269 r:0.7399
Current avg r:0.5865 Best avg r: 0.6219
03:08:49,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:08,267 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:39,703 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1814
en_de Dev loss: 0.8934 r:0.1782
en_zh Dev loss: 0.8042 r:0.4372
ro_en Dev loss: 0.3373 r:0.8201
et_en Dev loss: 0.4394 r:0.6483
si_en Dev loss: 0.8389 r:0.5578
ne_en Dev loss: 0.5200 r:0.7134
ru_en Dev loss: 0.4781 r:0.7120
Current avg r:0.5810 Best avg r: 0.6219
03:15:34,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:16:52,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:18:23,950 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1895
en_de Dev loss: 0.9088 r:0.1794
en_zh Dev loss: 0.8095 r:0.4437
ro_en Dev loss: 0.3377 r:0.8189
et_en Dev loss: 0.4441 r:0.6464
si_en Dev loss: 0.8204 r:0.5533
ne_en Dev loss: 0.6009 r:0.7107
ru_en Dev loss: 0.4496 r:0.7274
Current avg r:0.5829 Best avg r: 0.6219
03:22:18,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:23:36,711 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:08,77 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1971
en_de Dev loss: 0.9015 r:0.1869
en_zh Dev loss: 0.8084 r:0.4470
ro_en Dev loss: 0.3246 r:0.8213
et_en Dev loss: 0.4312 r:0.6601
si_en Dev loss: 0.8062 r:0.5597
ne_en Dev loss: 0.5111 r:0.7190
ru_en Dev loss: 0.4471 r:0.7297
Current avg r:0.5891 Best avg r: 0.6219
03:29:02,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:30:20,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:52,105 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1917
en_de Dev loss: 0.9476 r:0.1718
en_zh Dev loss: 0.8341 r:0.4489
ro_en Dev loss: 0.3731 r:0.8173
et_en Dev loss: 0.4825 r:0.6417
si_en Dev loss: 0.9193 r:0.5496
ne_en Dev loss: 0.6485 r:0.7125
ru_en Dev loss: 0.4992 r:0.7149
Current avg r:0.5795 Best avg r: 0.6219
03:35:46,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:05,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:37,448 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1817
en_de Dev loss: 0.9018 r:0.1596
en_zh Dev loss: 0.7538 r:0.4498
ro_en Dev loss: 0.3146 r:0.8206
et_en Dev loss: 0.4262 r:0.6485
si_en Dev loss: 0.7698 r:0.5557
ne_en Dev loss: 0.4827 r:0.7121
ru_en Dev loss: 0.4222 r:0.7285
Current avg r:0.5821 Best avg r: 0.6219
03:42:34,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:53,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:25,690 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1871
en_de Dev loss: 0.8948 r:0.1820
en_zh Dev loss: 0.7677 r:0.4518
ro_en Dev loss: 0.3129 r:0.8236
et_en Dev loss: 0.4166 r:0.6579
si_en Dev loss: 0.8166 r:0.5590
ne_en Dev loss: 0.5340 r:0.7191
ru_en Dev loss: 0.4330 r:0.7364
Current avg r:0.5900 Best avg r: 0.6219
03:49:23,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:50:42,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:14,226 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1840
en_de Dev loss: 0.8982 r:0.1808
en_zh Dev loss: 0.8086 r:0.4365
ro_en Dev loss: 0.3388 r:0.8190
et_en Dev loss: 0.4398 r:0.6475
si_en Dev loss: 0.8318 r:0.5584
ne_en Dev loss: 0.5414 r:0.7171
ru_en Dev loss: 0.4588 r:0.7201
Current avg r:0.5828 Best avg r: 0.6219
03:56:11,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:30,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:59:02,234 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1904
en_de Dev loss: 0.8882 r:0.1645
en_zh Dev loss: 0.7849 r:0.4276
ro_en Dev loss: 0.3493 r:0.8161
et_en Dev loss: 0.4441 r:0.6388
si_en Dev loss: 0.8704 r:0.5426
ne_en Dev loss: 0.6108 r:0.7085
ru_en Dev loss: 0.4594 r:0.7079
Current avg r:0.5723 Best avg r: 0.6219
04:02:56,581 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:14,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:05:46,293 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1849
en_de Dev loss: 0.9072 r:0.1670
en_zh Dev loss: 0.7829 r:0.4492
ro_en Dev loss: 0.3289 r:0.8212
et_en Dev loss: 0.4401 r:0.6508
si_en Dev loss: 0.8508 r:0.5484
ne_en Dev loss: 0.5332 r:0.7094
ru_en Dev loss: 0.4660 r:0.7253
Current avg r:0.5816 Best avg r: 0.6219
04:09:40,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:10:58,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:12:30,237 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1823
en_de Dev loss: 0.9354 r:0.1450
en_zh Dev loss: 0.8272 r:0.4421
ro_en Dev loss: 0.3363 r:0.8200
et_en Dev loss: 0.4501 r:0.6487
si_en Dev loss: 0.8791 r:0.5531
ne_en Dev loss: 0.5651 r:0.7116
ru_en Dev loss: 0.4684 r:0.7170
Current avg r:0.5768 Best avg r: 0.6219
04:16:25,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:17:43,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:15,303 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1662
en_de Dev loss: 0.9013 r:0.1704
en_zh Dev loss: 0.8563 r:0.4340
ro_en Dev loss: 0.3519 r:0.8175
et_en Dev loss: 0.4425 r:0.6572
si_en Dev loss: 0.8776 r:0.5504
ne_en Dev loss: 0.5511 r:0.7196
ru_en Dev loss: 0.4924 r:0.7158
Current avg r:0.5807 Best avg r: 0.6219
04:23:09,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:24:27,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:25:59,230 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1615
en_de Dev loss: 0.8923 r:0.1871
en_zh Dev loss: 0.8086 r:0.4432
ro_en Dev loss: 0.3293 r:0.8182
et_en Dev loss: 0.4330 r:0.6563
si_en Dev loss: 0.8894 r:0.5496
ne_en Dev loss: 0.5160 r:0.7246
ru_en Dev loss: 0.4891 r:0.7100
Current avg r:0.5841 Best avg r: 0.6219
04:29:56,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:31:15,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:32:47,446 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1630
en_de Dev loss: 0.9158 r:0.1816
en_zh Dev loss: 0.8150 r:0.4458
ro_en Dev loss: 0.3514 r:0.8187
et_en Dev loss: 0.4759 r:0.6394
si_en Dev loss: 0.9269 r:0.5485
ne_en Dev loss: 0.5668 r:0.7192
ru_en Dev loss: 0.4835 r:0.7239
Current avg r:0.5824 Best avg r: 0.6219
04:36:44,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:38:03,405 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:39:35,495 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1687
en_de Dev loss: 0.8874 r:0.1746
en_zh Dev loss: 0.7693 r:0.4458
ro_en Dev loss: 0.3186 r:0.8218
et_en Dev loss: 0.4289 r:0.6497
si_en Dev loss: 0.8153 r:0.5516
ne_en Dev loss: 0.4837 r:0.7237
ru_en Dev loss: 0.4603 r:0.7119
Current avg r:0.5827 Best avg r: 0.6219
04:43:32,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:51,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:46:23,280 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1636
en_de Dev loss: 0.8995 r:0.1703
en_zh Dev loss: 0.7655 r:0.4619
ro_en Dev loss: 0.3311 r:0.8213
et_en Dev loss: 0.4401 r:0.6510
si_en Dev loss: 0.8105 r:0.5570
ne_en Dev loss: 0.5007 r:0.7255
ru_en Dev loss: 0.4611 r:0.7197
Current avg r:0.5867 Best avg r: 0.6219
04:50:18,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:51:36,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:08,411 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1663
en_de Dev loss: 0.9370 r:0.1721
en_zh Dev loss: 0.7926 r:0.4610
ro_en Dev loss: 0.3522 r:0.8165
et_en Dev loss: 0.4822 r:0.6347
si_en Dev loss: 0.8789 r:0.5478
ne_en Dev loss: 0.6086 r:0.7195
ru_en Dev loss: 0.4658 r:0.7240
Current avg r:0.5822 Best avg r: 0.6219
04:57:02,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:58:21,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:59:52,517 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1600
en_de Dev loss: 0.9202 r:0.1817
en_zh Dev loss: 0.8656 r:0.4367
ro_en Dev loss: 0.3509 r:0.8176
et_en Dev loss: 0.4737 r:0.6484
si_en Dev loss: 0.9368 r:0.5458
ne_en Dev loss: 0.5582 r:0.7142
ru_en Dev loss: 0.5131 r:0.7125
Current avg r:0.5796 Best avg r: 0.6219
05:03:46,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:05:05,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:06:36,596 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1692
en_de Dev loss: 0.9611 r:0.1578
en_zh Dev loss: 0.8154 r:0.4673
ro_en Dev loss: 0.3599 r:0.8225
et_en Dev loss: 0.4799 r:0.6523
si_en Dev loss: 0.8809 r:0.5578
ne_en Dev loss: 0.5473 r:0.7212
ru_en Dev loss: 0.4760 r:0.7326
Current avg r:0.5874 Best avg r: 0.6219
05:10:30,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:11:49,250 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:13:21,458 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1549
en_de Dev loss: 0.9261 r:0.1468
en_zh Dev loss: 0.8516 r:0.4373
ro_en Dev loss: 0.3560 r:0.8157
et_en Dev loss: 0.4619 r:0.6423
si_en Dev loss: 0.8985 r:0.5361
ne_en Dev loss: 0.6504 r:0.7136
ru_en Dev loss: 0.5144 r:0.7003
Current avg r:0.5703 Best avg r: 0.6219
05:17:18,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:18:37,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:20:09,618 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1666
en_de Dev loss: 0.9134 r:0.1543
en_zh Dev loss: 0.8032 r:0.4453
ro_en Dev loss: 0.3281 r:0.8192
et_en Dev loss: 0.4446 r:0.6513
si_en Dev loss: 0.8244 r:0.5487
ne_en Dev loss: 0.5405 r:0.7205
ru_en Dev loss: 0.4650 r:0.7150
Current avg r:0.5792 Best avg r: 0.6219
05:24:06,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:25:25,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:57,447 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1701
en_de Dev loss: 0.9202 r:0.1694
en_zh Dev loss: 0.7798 r:0.4667
ro_en Dev loss: 0.3258 r:0.8232
et_en Dev loss: 0.4304 r:0.6585
si_en Dev loss: 0.7732 r:0.5533
ne_en Dev loss: 0.4874 r:0.7193
ru_en Dev loss: 0.4439 r:0.7290
Current avg r:0.5885 Best avg r: 0.6219
05:30:54,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:32:13,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:33:45,319 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1617
en_de Dev loss: 0.9047 r:0.1870
en_zh Dev loss: 0.8084 r:0.4512
ro_en Dev loss: 0.3499 r:0.8170
et_en Dev loss: 0.4541 r:0.6440
si_en Dev loss: 0.8086 r:0.5514
ne_en Dev loss: 0.5216 r:0.7188
ru_en Dev loss: 0.5006 r:0.7020
Current avg r:0.5816 Best avg r: 0.6219
05:37:40,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:38:58,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:40:29,694 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1554
en_de Dev loss: 0.9043 r:0.1683
en_zh Dev loss: 0.7865 r:0.4470
ro_en Dev loss: 0.3331 r:0.8199
et_en Dev loss: 0.4469 r:0.6424
si_en Dev loss: 0.8401 r:0.5474
ne_en Dev loss: 0.5286 r:0.7186
ru_en Dev loss: 0.4591 r:0.7227
Current avg r:0.5809 Best avg r: 0.6219
05:44:23,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:45:42,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:47:13,484 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1615
en_de Dev loss: 0.9211 r:0.1521
en_zh Dev loss: 0.7705 r:0.4505
ro_en Dev loss: 0.3229 r:0.8198
et_en Dev loss: 0.4396 r:0.6483
si_en Dev loss: 0.8004 r:0.5500
ne_en Dev loss: 0.4619 r:0.7220
ru_en Dev loss: 0.4355 r:0.7248
Current avg r:0.5811 Best avg r: 0.6219
05:51:07,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:25,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:57,28 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1639
en_de Dev loss: 0.9123 r:0.1665
en_zh Dev loss: 0.8385 r:0.4490
ro_en Dev loss: 0.3699 r:0.8154
et_en Dev loss: 0.4753 r:0.6409
si_en Dev loss: 0.9531 r:0.5372
ne_en Dev loss: 0.6054 r:0.7162
ru_en Dev loss: 0.5180 r:0.7101
Current avg r:0.5765 Best avg r: 0.6219
05:57:52,519 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:10,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:00:43,64 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1395
en_de Dev loss: 0.9080 r:0.1792
en_zh Dev loss: 0.7706 r:0.4619
ro_en Dev loss: 0.3228 r:0.8194
et_en Dev loss: 0.4301 r:0.6554
si_en Dev loss: 0.8320 r:0.5419
ne_en Dev loss: 0.4948 r:0.7233
ru_en Dev loss: 0.4159 r:0.7450
Current avg r:0.5894 Best avg r: 0.6219
06:04:39,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:05:58,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:07:30,950 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1449
en_de Dev loss: 0.9267 r:0.1653
en_zh Dev loss: 0.7959 r:0.4530
ro_en Dev loss: 0.3335 r:0.8230
et_en Dev loss: 0.4364 r:0.6581
si_en Dev loss: 0.8651 r:0.5406
ne_en Dev loss: 0.5760 r:0.7188
ru_en Dev loss: 0.4554 r:0.7287
Current avg r:0.5839 Best avg r: 0.6219
06:11:27,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:12:46,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:14:18,988 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1485
en_de Dev loss: 0.9123 r:0.1681
en_zh Dev loss: 0.7825 r:0.4587
ro_en Dev loss: 0.3398 r:0.8214
et_en Dev loss: 0.4503 r:0.6516
si_en Dev loss: 0.9157 r:0.5428
ne_en Dev loss: 0.5622 r:0.7218
ru_en Dev loss: 0.4553 r:0.7334
Current avg r:0.5854 Best avg r: 0.6219
06:18:15,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:19:34,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:21:07,110 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1476
en_de Dev loss: 0.9107 r:0.1898
en_zh Dev loss: 0.7793 r:0.4614
ro_en Dev loss: 0.3282 r:0.8221
et_en Dev loss: 0.4477 r:0.6476
si_en Dev loss: 0.8569 r:0.5463
ne_en Dev loss: 0.5691 r:0.7142
ru_en Dev loss: 0.4654 r:0.7195
Current avg r:0.5858 Best avg r: 0.6219
06:25:02,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:26:21,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:27:52,732 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1495
en_de Dev loss: 0.9125 r:0.1955
en_zh Dev loss: 0.7975 r:0.4468
ro_en Dev loss: 0.3398 r:0.8190
et_en Dev loss: 0.4459 r:0.6549
si_en Dev loss: 0.8637 r:0.5467
ne_en Dev loss: 0.5262 r:0.7232
ru_en Dev loss: 0.4751 r:0.7244
Current avg r:0.5872 Best avg r: 0.6219
06:31:47,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:33:05,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:34:37,97 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1471
en_de Dev loss: 0.9011 r:0.1960
en_zh Dev loss: 0.7666 r:0.4604
ro_en Dev loss: 0.3261 r:0.8189
et_en Dev loss: 0.4430 r:0.6414
si_en Dev loss: 0.8040 r:0.5454
ne_en Dev loss: 0.5140 r:0.7132
ru_en Dev loss: 0.4306 r:0.7309
Current avg r:0.5866 Best avg r: 0.6219
06:38:31,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:39:49,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:41:21,95 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1483
en_de Dev loss: 0.9033 r:0.1847
en_zh Dev loss: 0.7914 r:0.4548
ro_en Dev loss: 0.3175 r:0.8221
et_en Dev loss: 0.4280 r:0.6588
si_en Dev loss: 0.8729 r:0.5433
ne_en Dev loss: 0.5028 r:0.7173
ru_en Dev loss: 0.4491 r:0.7251
Current avg r:0.5866 Best avg r: 0.6219
06:45:15,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:46:34,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:48:06,959 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1471
en_de Dev loss: 0.9015 r:0.1920
en_zh Dev loss: 0.7568 r:0.4586
ro_en Dev loss: 0.3091 r:0.8213
et_en Dev loss: 0.4141 r:0.6664
si_en Dev loss: 0.8024 r:0.5441
ne_en Dev loss: 0.5027 r:0.7179
ru_en Dev loss: 0.4237 r:0.7357
Current avg r:0.5909 Best avg r: 0.6219
06:52:04,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:53:23,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:54:55,823 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1458
en_de Dev loss: 0.8995 r:0.1940
en_zh Dev loss: 0.7852 r:0.4545
ro_en Dev loss: 0.3135 r:0.8199
et_en Dev loss: 0.4253 r:0.6559
si_en Dev loss: 0.8599 r:0.5404
ne_en Dev loss: 0.5392 r:0.7107
ru_en Dev loss: 0.4419 r:0.7289
Current avg r:0.5863 Best avg r: 0.6219
06:58:53,242 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:12,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:44,678 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1376
en_de Dev loss: 0.9117 r:0.1837
en_zh Dev loss: 0.7963 r:0.4541
ro_en Dev loss: 0.3251 r:0.8179
et_en Dev loss: 0.4236 r:0.6670
si_en Dev loss: 0.8440 r:0.5461
ne_en Dev loss: 0.5063 r:0.7180
ru_en Dev loss: 0.4443 r:0.7345
Current avg r:0.5888 Best avg r: 0.6219
07:05:41,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:07:00,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:33,192 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1398
en_de Dev loss: 0.9311 r:0.1691
en_zh Dev loss: 0.7955 r:0.4622
ro_en Dev loss: 0.3604 r:0.8161
et_en Dev loss: 0.4531 r:0.6565
si_en Dev loss: 0.8601 r:0.5417
ne_en Dev loss: 0.5976 r:0.7150
ru_en Dev loss: 0.4936 r:0.7224
Current avg r:0.5833 Best avg r: 0.6219
07:12:28,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:46,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:18,428 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1397
en_de Dev loss: 0.9056 r:0.1611
en_zh Dev loss: 0.7668 r:0.4554
ro_en Dev loss: 0.3227 r:0.8179
et_en Dev loss: 0.4285 r:0.6563
si_en Dev loss: 0.8148 r:0.5401
ne_en Dev loss: 0.5225 r:0.7066
ru_en Dev loss: 0.4144 r:0.7403
Current avg r:0.5826 Best avg r: 0.6219
07:19:12,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:20:31,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:22:03,198 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1479
en_de Dev loss: 0.9335 r:0.1905
en_zh Dev loss: 0.8025 r:0.4662
ro_en Dev loss: 0.3467 r:0.8167
et_en Dev loss: 0.4516 r:0.6638
si_en Dev loss: 0.8017 r:0.5518
ne_en Dev loss: 0.5026 r:0.7085
ru_en Dev loss: 0.4370 r:0.7357
Current avg r:0.5905 Best avg r: 0.6219
07:25:58,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:27:16,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:28:48,572 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1409
en_de Dev loss: 0.9395 r:0.1739
en_zh Dev loss: 0.7932 r:0.4682
ro_en Dev loss: 0.3472 r:0.8183
et_en Dev loss: 0.4495 r:0.6598
si_en Dev loss: 0.8644 r:0.5391
ne_en Dev loss: 0.5130 r:0.7065
ru_en Dev loss: 0.4524 r:0.7395
Current avg r:0.5865 Best avg r: 0.6219
07:32:43,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:34:01,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:35:33,138 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1448
en_de Dev loss: 0.9300 r:0.1549
en_zh Dev loss: 0.7917 r:0.4621
ro_en Dev loss: 0.3482 r:0.8167
et_en Dev loss: 0.4449 r:0.6568
si_en Dev loss: 0.8766 r:0.5408
ne_en Dev loss: 0.5423 r:0.7069
ru_en Dev loss: 0.4363 r:0.7411
Current avg r:0.5827 Best avg r: 0.6219
07:39:28,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:46,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:18,356 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1325
en_de Dev loss: 0.9422 r:0.1524
en_zh Dev loss: 0.7696 r:0.4651
ro_en Dev loss: 0.3273 r:0.8200
et_en Dev loss: 0.4325 r:0.6602
si_en Dev loss: 0.7999 r:0.5447
ne_en Dev loss: 0.4779 r:0.7120
ru_en Dev loss: 0.4295 r:0.7405
Current avg r:0.5850 Best avg r: 0.6219
07:46:12,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:30,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:49:02,321 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1183
en_de Dev loss: 0.9630 r:0.1767
en_zh Dev loss: 0.8091 r:0.4704
ro_en Dev loss: 0.3362 r:0.8196
et_en Dev loss: 0.4526 r:0.6584
si_en Dev loss: 0.8860 r:0.5404
ne_en Dev loss: 0.5087 r:0.7099
ru_en Dev loss: 0.4675 r:0.7368
Current avg r:0.5874 Best avg r: 0.6219
07:52:56,558 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:54:14,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:46,558 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1323
en_de Dev loss: 0.9446 r:0.1801
en_zh Dev loss: 0.7901 r:0.4699
ro_en Dev loss: 0.3554 r:0.8161
et_en Dev loss: 0.4504 r:0.6577
si_en Dev loss: 0.8483 r:0.5451
ne_en Dev loss: 0.5158 r:0.7158
ru_en Dev loss: 0.4250 r:0.7488
Current avg r:0.5905 Best avg r: 0.6219
07:59:41,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:00:07,192 root INFO 
id:en_zh cur r: 0.4834 best r: 0.4834
08:00:59,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:30,995 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1326
en_de Dev loss: 0.9351 r:0.1448
en_zh Dev loss: 0.7601 r:0.4711
ro_en Dev loss: 0.3313 r:0.8195
et_en Dev loss: 0.4375 r:0.6575
si_en Dev loss: 0.8511 r:0.5438
ne_en Dev loss: 0.4987 r:0.7122
ru_en Dev loss: 0.4246 r:0.7403
Current avg r:0.5842 Best avg r: 0.6219
08:06:25,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:07:43,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:09:14,982 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1322
en_de Dev loss: 0.9321 r:0.1384
en_zh Dev loss: 0.8145 r:0.4541
ro_en Dev loss: 0.3526 r:0.8129
et_en Dev loss: 0.4750 r:0.6338
si_en Dev loss: 0.8653 r:0.5408
ne_en Dev loss: 0.5765 r:0.7116
ru_en Dev loss: 0.4643 r:0.7248
Current avg r:0.5738 Best avg r: 0.6219
08:13:09,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:14:27,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:15:58,938 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1266
en_de Dev loss: 0.9475 r:0.1590
en_zh Dev loss: 0.8197 r:0.4614
ro_en Dev loss: 0.3478 r:0.8173
et_en Dev loss: 0.4579 r:0.6543
si_en Dev loss: 0.8599 r:0.5433
ne_en Dev loss: 0.5353 r:0.7104
ru_en Dev loss: 0.4377 r:0.7444
Current avg r:0.5843 Best avg r: 0.6219
08:19:53,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:11,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:22:43,232 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1302
en_de Dev loss: 0.9200 r:0.1786
en_zh Dev loss: 0.7976 r:0.4588
ro_en Dev loss: 0.3392 r:0.8148
et_en Dev loss: 0.4359 r:0.6651
si_en Dev loss: 0.8415 r:0.5462
ne_en Dev loss: 0.5415 r:0.7148
ru_en Dev loss: 0.4368 r:0.7388
Current avg r:0.5882 Best avg r: 0.6219
08:26:37,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:27:55,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:27,520 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1325
en_de Dev loss: 0.9177 r:0.1815
en_zh Dev loss: 0.7678 r:0.4589
ro_en Dev loss: 0.3335 r:0.8151
et_en Dev loss: 0.4307 r:0.6639
si_en Dev loss: 0.7908 r:0.5498
ne_en Dev loss: 0.5158 r:0.7194
ru_en Dev loss: 0.4128 r:0.7431
Current avg r:0.5902 Best avg r: 0.6219
08:33:22,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:34:40,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:11,843 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1242
en_de Dev loss: 0.9383 r:0.1616
en_zh Dev loss: 0.8286 r:0.4494
ro_en Dev loss: 0.3489 r:0.8141
et_en Dev loss: 0.4522 r:0.6562
si_en Dev loss: 0.9095 r:0.5352
ne_en Dev loss: 0.5842 r:0.7094
ru_en Dev loss: 0.4889 r:0.7206
Current avg r:0.5781 Best avg r: 0.6219
08:40:06,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:41:24,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:42:55,991 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1301
en_de Dev loss: 0.9651 r:0.1604
en_zh Dev loss: 0.8190 r:0.4603
ro_en Dev loss: 0.3461 r:0.8169
et_en Dev loss: 0.4469 r:0.6590
si_en Dev loss: 0.8239 r:0.5480
ne_en Dev loss: 0.5438 r:0.7089
ru_en Dev loss: 0.4661 r:0.7315
Current avg r:0.5836 Best avg r: 0.6219
08:46:50,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:08,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:40,106 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1274
en_de Dev loss: 0.9323 r:0.1647
en_zh Dev loss: 0.7901 r:0.4625
ro_en Dev loss: 0.3358 r:0.8193
et_en Dev loss: 0.4438 r:0.6553
si_en Dev loss: 0.8554 r:0.5463
ne_en Dev loss: 0.5800 r:0.7140
ru_en Dev loss: 0.4474 r:0.7345
Current avg r:0.5852 Best avg r: 0.6219
08:53:34,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:54:52,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:24,460 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1253
en_de Dev loss: 0.9210 r:0.1945
en_zh Dev loss: 0.8168 r:0.4634
ro_en Dev loss: 0.3404 r:0.8215
et_en Dev loss: 0.4532 r:0.6609
si_en Dev loss: 0.8545 r:0.5499
ne_en Dev loss: 0.5568 r:0.7115
ru_en Dev loss: 0.4743 r:0.7360
Current avg r:0.5911 Best avg r: 0.6219
09:00:18,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:36,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:07,896 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1280
en_de Dev loss: 0.9608 r:0.1600
en_zh Dev loss: 0.8257 r:0.4657
ro_en Dev loss: 0.3465 r:0.8210
et_en Dev loss: 0.4507 r:0.6579
si_en Dev loss: 0.8247 r:0.5553
ne_en Dev loss: 0.5473 r:0.7125
ru_en Dev loss: 0.4549 r:0.7431
Current avg r:0.5879 Best avg r: 0.6219
09:07:02,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:08:20,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:51,999 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1230
en_de Dev loss: 0.9226 r:0.1522
en_zh Dev loss: 0.7673 r:0.4644
ro_en Dev loss: 0.3288 r:0.8188
et_en Dev loss: 0.4366 r:0.6561
si_en Dev loss: 0.8395 r:0.5486
ne_en Dev loss: 0.5261 r:0.7137
ru_en Dev loss: 0.4108 r:0.7446
Current avg r:0.5855 Best avg r: 0.6219
09:13:46,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:04,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:35,683 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1179
en_de Dev loss: 0.9407 r:0.1375
en_zh Dev loss: 0.7642 r:0.4609
ro_en Dev loss: 0.3337 r:0.8175
et_en Dev loss: 0.4363 r:0.6513
si_en Dev loss: 0.8286 r:0.5430
ne_en Dev loss: 0.5561 r:0.7105
ru_en Dev loss: 0.4393 r:0.7311
Current avg r:0.5788 Best avg r: 0.6219
09:20:30,772 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:21:48,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:23:20,222 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1186
en_de Dev loss: 0.9452 r:0.1661
en_zh Dev loss: 0.7594 r:0.4707
ro_en Dev loss: 0.3270 r:0.8206
et_en Dev loss: 0.4171 r:0.6717
si_en Dev loss: 0.7676 r:0.5536
ne_en Dev loss: 0.4836 r:0.7113
ru_en Dev loss: 0.4275 r:0.7489
Current avg r:0.5919 Best avg r: 0.6219
09:27:14,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:28:32,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:30:04,433 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1140
en_de Dev loss: 0.9744 r:0.1550
en_zh Dev loss: 0.8221 r:0.4620
ro_en Dev loss: 0.3798 r:0.8167
et_en Dev loss: 0.4634 r:0.6587
si_en Dev loss: 0.8914 r:0.5398
ne_en Dev loss: 0.5835 r:0.7051
ru_en Dev loss: 0.4766 r:0.7352
Current avg r:0.5818 Best avg r: 0.6219
09:33:58,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:17,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:48,268 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1164
en_de Dev loss: 0.9431 r:0.1550
en_zh Dev loss: 0.8186 r:0.4607
ro_en Dev loss: 0.3552 r:0.8161
et_en Dev loss: 0.4471 r:0.6634
si_en Dev loss: 0.9105 r:0.5442
ne_en Dev loss: 0.5656 r:0.7140
ru_en Dev loss: 0.4601 r:0.7366
Current avg r:0.5843 Best avg r: 0.6219
09:40:41,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:00,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:31,562 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1077
en_de Dev loss: 0.9521 r:0.1477
en_zh Dev loss: 0.8029 r:0.4591
ro_en Dev loss: 0.3515 r:0.8161
et_en Dev loss: 0.4440 r:0.6665
si_en Dev loss: 0.8538 r:0.5430
ne_en Dev loss: 0.5492 r:0.7107
ru_en Dev loss: 0.4654 r:0.7288
Current avg r:0.5817 Best avg r: 0.6219
09:47:25,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:43,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:50:15,190 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1202
en_de Dev loss: 0.9375 r:0.1483
en_zh Dev loss: 0.7595 r:0.4591
ro_en Dev loss: 0.3252 r:0.8161
et_en Dev loss: 0.4392 r:0.6584
si_en Dev loss: 0.8571 r:0.5400
ne_en Dev loss: 0.5457 r:0.7058
ru_en Dev loss: 0.4350 r:0.7350
Current avg r:0.5804 Best avg r: 0.6219
09:54:09,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:27,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:59,453 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1147
en_de Dev loss: 0.9517 r:0.1531
en_zh Dev loss: 0.8041 r:0.4655
ro_en Dev loss: 0.3481 r:0.8191
et_en Dev loss: 0.4546 r:0.6581
si_en Dev loss: 0.9015 r:0.5468
ne_en Dev loss: 0.6010 r:0.7095
ru_en Dev loss: 0.4758 r:0.7332
Current avg r:0.5836 Best avg r: 0.6219
10:00:54,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:12,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:44,325 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1127
en_de Dev loss: 0.9385 r:0.1449
en_zh Dev loss: 0.7993 r:0.4491
ro_en Dev loss: 0.3459 r:0.8146
et_en Dev loss: 0.4551 r:0.6448
si_en Dev loss: 0.9090 r:0.5375
ne_en Dev loss: 0.5720 r:0.7042
ru_en Dev loss: 0.4723 r:0.7210
Current avg r:0.5737 Best avg r: 0.6219
10:07:38,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:57,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:28,994 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1163
en_de Dev loss: 0.9415 r:0.1702
en_zh Dev loss: 0.7843 r:0.4668
ro_en Dev loss: 0.3417 r:0.8160
et_en Dev loss: 0.4482 r:0.6578
si_en Dev loss: 0.8420 r:0.5472
ne_en Dev loss: 0.5176 r:0.7139
ru_en Dev loss: 0.4429 r:0.7392
Current avg r:0.5873 Best avg r: 0.6219
10:14:23,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:15:42,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:13,810 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1083
en_de Dev loss: 0.9496 r:0.1690
en_zh Dev loss: 0.7934 r:0.4722
ro_en Dev loss: 0.3618 r:0.8184
et_en Dev loss: 0.4720 r:0.6534
si_en Dev loss: 0.9283 r:0.5468
ne_en Dev loss: 0.5399 r:0.7119
ru_en Dev loss: 0.4722 r:0.7377
Current avg r:0.5871 Best avg r: 0.6219
10:21:08,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:22:26,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:58,629 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1191
en_de Dev loss: 0.9361 r:0.1848
en_zh Dev loss: 0.7910 r:0.4653
ro_en Dev loss: 0.3664 r:0.8146
et_en Dev loss: 0.4759 r:0.6507
si_en Dev loss: 0.9307 r:0.5385
ne_en Dev loss: 0.5718 r:0.7103
ru_en Dev loss: 0.4647 r:0.7339
Current avg r:0.5854 Best avg r: 0.6219
10:27:53,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:11,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:43,433 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1103
en_de Dev loss: 0.9047 r:0.1828
en_zh Dev loss: 0.7288 r:0.4751
ro_en Dev loss: 0.3264 r:0.8177
et_en Dev loss: 0.4332 r:0.6584
si_en Dev loss: 0.8157 r:0.5462
ne_en Dev loss: 0.5525 r:0.7082
ru_en Dev loss: 0.3953 r:0.7546
Current avg r:0.5919 Best avg r: 0.6219
10:34:38,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:35:56,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:37:28,190 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1140
en_de Dev loss: 0.9608 r:0.1701
en_zh Dev loss: 0.7836 r:0.4719
ro_en Dev loss: 0.3413 r:0.8211
et_en Dev loss: 0.4497 r:0.6682
si_en Dev loss: 0.8665 r:0.5495
ne_en Dev loss: 0.5422 r:0.7166
ru_en Dev loss: 0.4436 r:0.7486
Current avg r:0.5923 Best avg r: 0.6219
