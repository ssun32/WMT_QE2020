14:37:17,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:30,599 root INFO 
id:en_de cur r: 0.0976 best r: 0.0976
14:37:43,503 root INFO 
id:en_zh cur r: 0.2324 best r: 0.2324
14:37:56,442 root INFO 
id:ro_en cur r: 0.5965 best r: 0.5965
14:38:09,445 root INFO 
id:si_en cur r: 0.4314 best r: 0.4314
14:38:22,452 root INFO 
id:ne_en cur r: 0.5557 best r: 0.5557
14:38:35,351 root INFO 
id:ru_en cur r: 0.6477 best r: 0.6477
14:38:35,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:06,287 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:40:06,294 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:40:06,299 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:40:06,303 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:40:06,309 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:40:06,314 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:40:06,319 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:40:19,366 root INFO Epoch 0 Global steps: 600 Train loss: 0.8523
en_de Dev loss: 0.9050 r:0.0993
en_zh Dev loss: 0.7650 r:0.2617
ro_en Dev loss: 0.5518 r:0.6474
et_en Dev loss: 0.5702 r:0.4752
si_en Dev loss: 0.6528 r:0.4718
ne_en Dev loss: 0.6008 r:0.5782
ru_en Dev loss: 0.5585 r:0.6210
Current avg r:0.4507 Best avg r: 0.4507
14:44:11,35 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:36,703 root INFO 
id:en_zh cur r: 0.2672 best r: 0.2672
14:44:49,563 root INFO 
id:ro_en cur r: 0.6454 best r: 0.6454
14:45:28,87 root INFO 
id:ru_en cur r: 0.6704 best r: 0.6704
14:45:28,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:57,930 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7614
en_de Dev loss: 0.9265 r:0.0814
en_zh Dev loss: 0.7813 r:0.2831
ro_en Dev loss: 0.5809 r:0.6644
et_en Dev loss: 0.6263 r:0.4220
si_en Dev loss: 0.7725 r:0.4472
ne_en Dev loss: 0.6204 r:0.5612
ru_en Dev loss: 0.5733 r:0.6806
Current avg r:0.4486 Best avg r: 0.4507
14:50:48,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:13,889 root INFO 
id:en_zh cur r: 0.2895 best r: 0.2895
14:51:26,740 root INFO 
id:ro_en cur r: 0.6609 best r: 0.6609
14:52:05,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:35,128 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:53:35,135 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:53:35,142 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:53:35,148 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:53:35,153 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:53:35,158 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:53:35,165 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:53:48,20 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7691
en_de Dev loss: 0.9188 r:0.1198
en_zh Dev loss: 0.7700 r:0.3180
ro_en Dev loss: 0.5140 r:0.6947
et_en Dev loss: 0.6122 r:0.4618
si_en Dev loss: 0.7544 r:0.4545
ne_en Dev loss: 0.5815 r:0.5887
ru_en Dev loss: 0.5476 r:0.6601
Current avg r:0.4711 Best avg r: 0.4711
14:57:38,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:51,191 root INFO 
id:en_de cur r: 0.1327 best r: 0.1327
14:58:04,17 root INFO 
id:en_zh cur r: 0.3386 best r: 0.3386
14:58:16,871 root INFO 
id:ro_en cur r: 0.7047 best r: 0.7047
14:58:29,736 root INFO 
id:si_en cur r: 0.4664 best r: 0.4664
14:58:42,613 root INFO 
id:ne_en cur r: 0.6328 best r: 0.6328
14:58:55,425 root INFO 
id:ru_en cur r: 0.7134 best r: 0.7134
14:58:55,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:25,319 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:00:25,325 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:00:25,330 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:00:25,335 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:00:25,339 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:00:25,345 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:00:25,350 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:00:38,216 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7103
en_de Dev loss: 0.9294 r:0.1352
en_zh Dev loss: 0.7224 r:0.3521
ro_en Dev loss: 0.4397 r:0.7168
et_en Dev loss: 0.5363 r:0.5511
si_en Dev loss: 0.6600 r:0.5005
ne_en Dev loss: 0.4737 r:0.6519
ru_en Dev loss: 0.4396 r:0.7222
Current avg r:0.5185 Best avg r: 0.5185
15:04:28,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:54,226 root INFO 
id:en_zh cur r: 0.3705 best r: 0.3705
15:05:07,97 root INFO 
id:ro_en cur r: 0.7120 best r: 0.7120
15:05:45,680 root INFO 
id:ru_en cur r: 0.7210 best r: 0.7210
15:05:45,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:15,644 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6791
en_de Dev loss: 0.9428 r:0.1371
en_zh Dev loss: 0.7631 r:0.3876
ro_en Dev loss: 0.4587 r:0.7213
et_en Dev loss: 0.6104 r:0.5178
si_en Dev loss: 0.8025 r:0.4787
ne_en Dev loss: 0.5852 r:0.5985
ru_en Dev loss: 0.4523 r:0.7227
Current avg r:0.5091 Best avg r: 0.5185
15:11:05,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:44,507 root INFO 
id:ro_en cur r: 0.7245 best r: 0.7245
15:11:57,369 root INFO 
id:si_en cur r: 0.4938 best r: 0.4938
15:12:23,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:52,842 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:13:52,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:13:52,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:13:52,859 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:13:52,863 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:13:52,868 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:13:52,872 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:14:05,733 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6701
en_de Dev loss: 0.9318 r:0.1517
en_zh Dev loss: 0.7250 r:0.3879
ro_en Dev loss: 0.4347 r:0.7412
et_en Dev loss: 0.5468 r:0.5659
si_en Dev loss: 0.6545 r:0.5177
ne_en Dev loss: 0.5303 r:0.6275
ru_en Dev loss: 0.4591 r:0.7112
Current avg r:0.5290 Best avg r: 0.5290
15:17:55,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:08,839 root INFO 
id:en_de cur r: 0.1350 best r: 0.1350
15:18:21,653 root INFO 
id:en_zh cur r: 0.3748 best r: 0.3748
15:18:34,509 root INFO 
id:ro_en cur r: 0.7332 best r: 0.7332
15:18:47,372 root INFO 
id:si_en cur r: 0.4992 best r: 0.4992
15:19:00,232 root INFO 
id:ne_en cur r: 0.6552 best r: 0.6552
15:19:13,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:42,894 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:20:42,901 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:20:42,906 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:20:42,911 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:20:42,916 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:20:42,920 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:20:42,926 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:20:55,793 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6553
en_de Dev loss: 0.9350 r:0.1648
en_zh Dev loss: 0.7350 r:0.4023
ro_en Dev loss: 0.3935 r:0.7452
et_en Dev loss: 0.4866 r:0.6114
si_en Dev loss: 0.6296 r:0.5291
ne_en Dev loss: 0.4513 r:0.6708
ru_en Dev loss: 0.4844 r:0.7118
Current avg r:0.5479 Best avg r: 0.5479
15:24:46,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:58,905 root INFO 
id:en_de cur r: 0.1439 best r: 0.1439
15:25:11,722 root INFO 
id:en_zh cur r: 0.4006 best r: 0.4006
15:25:24,579 root INFO 
id:ro_en cur r: 0.7482 best r: 0.7482
15:25:37,441 root INFO 
id:si_en cur r: 0.5398 best r: 0.5398
15:25:50,300 root INFO 
id:ne_en cur r: 0.6900 best r: 0.6900
15:26:03,101 root INFO 
id:ru_en cur r: 0.7301 best r: 0.7301
15:26:03,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:32,976 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:27:32,981 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:27:32,988 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:27:32,993 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:27:32,998 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:27:33,3 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:27:33,9 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:27:45,972 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6154
en_de Dev loss: 0.8717 r:0.1831
en_zh Dev loss: 0.6799 r:0.4184
ro_en Dev loss: 0.3713 r:0.7566
et_en Dev loss: 0.4641 r:0.6301
si_en Dev loss: 0.5887 r:0.5530
ne_en Dev loss: 0.4178 r:0.7022
ru_en Dev loss: 0.3928 r:0.7465
Current avg r:0.5700 Best avg r: 0.5700
15:31:38,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:51,278 root INFO 
id:en_de cur r: 0.1726 best r: 0.1726
15:32:17,215 root INFO 
id:ro_en cur r: 0.7541 best r: 0.7541
15:32:43,227 root INFO 
id:ne_en cur r: 0.6987 best r: 0.6987
15:32:56,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:26,591 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5733
en_de Dev loss: 0.9503 r:0.1827
en_zh Dev loss: 0.7836 r:0.4030
ro_en Dev loss: 0.4106 r:0.7639
et_en Dev loss: 0.5137 r:0.6159
si_en Dev loss: 0.6535 r:0.5475
ne_en Dev loss: 0.4337 r:0.6906
ru_en Dev loss: 0.4826 r:0.7311
Current avg r:0.5621 Best avg r: 0.5700
15:38:19,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:11,166 root INFO 
id:si_en cur r: 0.5421 best r: 0.5421
15:39:24,145 root INFO 
id:ne_en cur r: 0.7004 best r: 0.7004
15:39:36,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:07,476 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5729
en_de Dev loss: 0.8902 r:0.1761
en_zh Dev loss: 0.7658 r:0.4233
ro_en Dev loss: 0.4213 r:0.7730
et_en Dev loss: 0.5127 r:0.6160
si_en Dev loss: 0.6727 r:0.5580
ne_en Dev loss: 0.4322 r:0.6982
ru_en Dev loss: 0.4469 r:0.7286
Current avg r:0.5676 Best avg r: 0.5700
15:45:00,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:45:13,70 root INFO 
id:en_de cur r: 0.1834 best r: 0.1834
15:45:25,945 root INFO 
id:en_zh cur r: 0.4101 best r: 0.4101
15:45:38,827 root INFO 
id:ro_en cur r: 0.7727 best r: 0.7727
15:46:17,474 root INFO 
id:ru_en cur r: 0.7358 best r: 0.7358
15:46:17,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:47,960 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:47:47,967 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:47:47,971 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:47:47,976 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:47:47,981 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:47:47,985 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:47:47,990 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:48:00,970 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5343
en_de Dev loss: 0.8912 r:0.1879
en_zh Dev loss: 0.7384 r:0.4376
ro_en Dev loss: 0.3627 r:0.7782
et_en Dev loss: 0.4824 r:0.6472
si_en Dev loss: 0.6929 r:0.5516
ne_en Dev loss: 0.4327 r:0.7007
ru_en Dev loss: 0.4057 r:0.7541
Current avg r:0.5796 Best avg r: 0.5796
15:51:52,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:05,785 root INFO 
id:en_de cur r: 0.1938 best r: 0.1938
15:52:18,647 root INFO 
id:en_zh cur r: 0.4311 best r: 0.4311
15:52:31,591 root INFO 
id:ro_en cur r: 0.7780 best r: 0.7780
15:52:44,552 root INFO 
id:si_en cur r: 0.5455 best r: 0.5455
15:52:57,519 root INFO 
id:ne_en cur r: 0.7094 best r: 0.7094
15:53:10,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:40,974 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:54:40,987 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:54:40,991 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:54:40,996 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:54:41,1 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:54:41,5 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:54:41,10 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:54:53,983 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5432
en_de Dev loss: 0.8614 r:0.1872
en_zh Dev loss: 0.6769 r:0.4507
ro_en Dev loss: 0.3689 r:0.7850
et_en Dev loss: 0.4709 r:0.6504
si_en Dev loss: 0.6573 r:0.5623
ne_en Dev loss: 0.4449 r:0.7005
ru_en Dev loss: 0.4158 r:0.7537
Current avg r:0.5843 Best avg r: 0.5843
15:58:45,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:24,598 root INFO 
id:ro_en cur r: 0.7827 best r: 0.7827
15:59:37,577 root INFO 
id:si_en cur r: 0.5638 best r: 0.5638
15:59:50,549 root INFO 
id:ne_en cur r: 0.7141 best r: 0.7141
16:00:03,399 root INFO 
id:ru_en cur r: 0.7463 best r: 0.7463
16:00:03,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:34,26 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:01:34,32 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:01:34,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:01:34,44 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:01:34,50 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:01:34,55 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:01:34,60 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:01:47,37 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5543
en_de Dev loss: 0.8699 r:0.1913
en_zh Dev loss: 0.6763 r:0.4459
ro_en Dev loss: 0.3403 r:0.7870
et_en Dev loss: 0.4351 r:0.6554
si_en Dev loss: 0.5744 r:0.5828
ne_en Dev loss: 0.3940 r:0.7191
ru_en Dev loss: 0.3715 r:0.7614
Current avg r:0.5918 Best avg r: 0.5918
16:05:38,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:17,685 root INFO 
id:ro_en cur r: 0.7861 best r: 0.7861
16:06:43,643 root INFO 
id:ne_en cur r: 0.7187 best r: 0.7187
16:06:56,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:27,76 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5591
en_de Dev loss: 0.8602 r:0.1839
en_zh Dev loss: 0.6921 r:0.4468
ro_en Dev loss: 0.3458 r:0.7886
et_en Dev loss: 0.4393 r:0.6579
si_en Dev loss: 0.6368 r:0.5723
ne_en Dev loss: 0.4050 r:0.7151
ru_en Dev loss: 0.3932 r:0.7511
Current avg r:0.5880 Best avg r: 0.5918
16:12:18,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:36,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:06,714 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5381
en_de Dev loss: 0.8592 r:0.2006
en_zh Dev loss: 0.7201 r:0.4477
ro_en Dev loss: 0.3564 r:0.7883
et_en Dev loss: 0.4613 r:0.6557
si_en Dev loss: 0.7290 r:0.5620
ne_en Dev loss: 0.4324 r:0.7130
ru_en Dev loss: 0.4332 r:0.7441
Current avg r:0.5873 Best avg r: 0.5918
16:19:00,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:39,42 root INFO 
id:ro_en cur r: 0.7943 best r: 0.7943
16:19:52,4 root INFO 
id:si_en cur r: 0.5656 best r: 0.5656
16:20:17,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:47,915 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:21:47,921 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:21:47,930 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:21:47,934 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:21:47,939 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:21:47,944 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:21:47,948 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:22:00,899 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5199
en_de Dev loss: 0.8688 r:0.2047
en_zh Dev loss: 0.7327 r:0.4505
ro_en Dev loss: 0.3536 r:0.7988
et_en Dev loss: 0.4455 r:0.6704
si_en Dev loss: 0.6491 r:0.5829
ne_en Dev loss: 0.4285 r:0.7217
ru_en Dev loss: 0.4578 r:0.7466
Current avg r:0.5965 Best avg r: 0.5965
16:25:53,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:06,27 root INFO 
id:en_de cur r: 0.1947 best r: 0.1947
16:26:18,885 root INFO 
id:en_zh cur r: 0.4461 best r: 0.4461
16:26:31,761 root INFO 
id:ro_en cur r: 0.8088 best r: 0.8088
16:26:44,700 root INFO 
id:si_en cur r: 0.5881 best r: 0.5881
16:26:57,658 root INFO 
id:ne_en cur r: 0.7349 best r: 0.7349
16:27:10,511 root INFO 
id:ru_en cur r: 0.7500 best r: 0.7500
16:27:10,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:41,272 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:28:41,278 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:28:41,283 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:28:41,288 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:28:41,293 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:28:41,297 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:28:41,302 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:28:54,303 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5351
en_de Dev loss: 0.8942 r:0.2099
en_zh Dev loss: 0.7498 r:0.4605
ro_en Dev loss: 0.3354 r:0.8081
et_en Dev loss: 0.4773 r:0.6672
si_en Dev loss: 0.7173 r:0.5888
ne_en Dev loss: 0.4337 r:0.7347
ru_en Dev loss: 0.4507 r:0.7579
Current avg r:0.6039 Best avg r: 0.6039
16:32:46,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:59,860 root INFO 
id:en_de cur r: 0.1964 best r: 0.1964
16:33:12,774 root INFO 
id:en_zh cur r: 0.4486 best r: 0.4486
16:34:04,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:35,115 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5284
en_de Dev loss: 0.8977 r:0.2155
en_zh Dev loss: 0.7491 r:0.4605
ro_en Dev loss: 0.3592 r:0.8034
et_en Dev loss: 0.4655 r:0.6625
si_en Dev loss: 0.7105 r:0.5833
ne_en Dev loss: 0.4072 r:0.7306
ru_en Dev loss: 0.4727 r:0.7511
Current avg r:0.6010 Best avg r: 0.6039
16:39:27,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:39,990 root INFO 
id:en_de cur r: 0.2106 best r: 0.2106
16:39:52,903 root INFO 
id:en_zh cur r: 0.4631 best r: 0.4631
16:40:05,885 root INFO 
id:ro_en cur r: 0.8120 best r: 0.8120
16:40:18,875 root INFO 
id:si_en cur r: 0.6008 best r: 0.6008
16:40:31,852 root INFO 
id:ne_en cur r: 0.7473 best r: 0.7473
16:40:44,711 root INFO 
id:ru_en cur r: 0.7589 best r: 0.7589
16:40:44,711 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:15,464 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:42:15,470 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:42:15,474 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:42:15,479 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:42:15,484 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:42:15,489 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:42:15,493 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:42:28,482 root INFO Epoch 1 Global steps: 11400 Train loss: 0.5014
en_de Dev loss: 0.8556 r:0.2212
en_zh Dev loss: 0.6744 r:0.4665
ro_en Dev loss: 0.3155 r:0.8083
et_en Dev loss: 0.3904 r:0.6882
si_en Dev loss: 0.5525 r:0.6077
ne_en Dev loss: 0.3492 r:0.7475
ru_en Dev loss: 0.3786 r:0.7613
Current avg r:0.6144 Best avg r: 0.6144
16:46:20,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:38,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:08,986 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4909
en_de Dev loss: 0.8720 r:0.2073
en_zh Dev loss: 0.7317 r:0.4488
ro_en Dev loss: 0.3414 r:0.8049
et_en Dev loss: 0.4275 r:0.6724
si_en Dev loss: 0.7055 r:0.5793
ne_en Dev loss: 0.4104 r:0.7287
ru_en Dev loss: 0.4608 r:0.7368
Current avg r:0.5969 Best avg r: 0.6144
16:53:00,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:18,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:48,874 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4939
en_de Dev loss: 0.8725 r:0.1938
en_zh Dev loss: 0.6945 r:0.4565
ro_en Dev loss: 0.3607 r:0.8064
et_en Dev loss: 0.4228 r:0.6731
si_en Dev loss: 0.6930 r:0.5814
ne_en Dev loss: 0.4112 r:0.7342
ru_en Dev loss: 0.3963 r:0.7561
Current avg r:0.6002 Best avg r: 0.6144
16:59:41,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:54,295 root INFO 
id:en_de cur r: 0.2172 best r: 0.2172
17:00:58,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:29,121 root INFO Epoch 1 Global steps: 13200 Train loss: 0.5051
en_de Dev loss: 0.8996 r:0.2143
en_zh Dev loss: 0.7542 r:0.4596
ro_en Dev loss: 0.3861 r:0.8034
et_en Dev loss: 0.4677 r:0.6770
si_en Dev loss: 0.7427 r:0.5806
ne_en Dev loss: 0.4844 r:0.7318
ru_en Dev loss: 0.4854 r:0.7452
Current avg r:0.6017 Best avg r: 0.6144
17:06:21,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:34,306 root INFO 
id:en_de cur r: 0.2303 best r: 0.2303
17:07:25,845 root INFO 
id:ne_en cur r: 0.7527 best r: 0.7527
17:07:38,702 root INFO 
id:ru_en cur r: 0.7600 best r: 0.7600
17:07:38,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:09,208 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
17:09:09,216 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:09:09,222 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:09:09,227 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
17:09:09,232 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
17:09:09,237 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:09:09,241 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:09:22,215 root INFO Epoch 1 Global steps: 13800 Train loss: 0.5377
en_de Dev loss: 0.8548 r:0.2191
en_zh Dev loss: 0.6961 r:0.4661
ro_en Dev loss: 0.3380 r:0.8099
et_en Dev loss: 0.4004 r:0.6866
si_en Dev loss: 0.6200 r:0.6040
ne_en Dev loss: 0.3581 r:0.7529
ru_en Dev loss: 0.3914 r:0.7627
Current avg r:0.6145 Best avg r: 0.6145
17:13:14,549 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:27,516 root INFO 
id:en_de cur r: 0.2310 best r: 0.2310
17:13:40,448 root INFO 
id:en_zh cur r: 0.4647 best r: 0.4647
17:14:32,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:03,211 root INFO Epoch 1 Global steps: 14400 Train loss: 0.5003
en_de Dev loss: 0.9021 r:0.2097
en_zh Dev loss: 0.7525 r:0.4678
ro_en Dev loss: 0.3958 r:0.8065
et_en Dev loss: 0.4675 r:0.6783
si_en Dev loss: 0.7343 r:0.5967
ne_en Dev loss: 0.5620 r:0.7439
ru_en Dev loss: 0.5118 r:0.7345
Current avg r:0.6053 Best avg r: 0.6145
17:19:55,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:08,714 root INFO 
id:en_de cur r: 0.2332 best r: 0.2332
17:20:34,593 root INFO 
id:ro_en cur r: 0.8126 best r: 0.8126
17:20:47,587 root INFO 
id:si_en cur r: 0.6043 best r: 0.6043
17:21:00,603 root INFO 
id:ne_en cur r: 0.7570 best r: 0.7570
17:21:13,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:44,389 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4710
en_de Dev loss: 0.8874 r:0.2046
en_zh Dev loss: 0.7560 r:0.4710
ro_en Dev loss: 0.3309 r:0.8158
et_en Dev loss: 0.4255 r:0.6849
si_en Dev loss: 0.6653 r:0.6090
ne_en Dev loss: 0.4416 r:0.7505
ru_en Dev loss: 0.4798 r:0.7453
Current avg r:0.6116 Best avg r: 0.6145
17:26:36,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:02,874 root INFO 
id:en_zh cur r: 0.4800 best r: 0.4800
17:27:28,818 root INFO 
id:si_en cur r: 0.6142 best r: 0.6142
17:27:41,801 root INFO 
id:ne_en cur r: 0.7602 best r: 0.7602
17:27:54,666 root INFO 
id:ru_en cur r: 0.7676 best r: 0.7676
17:27:54,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:25,326 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
17:29:25,335 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:29:25,340 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:29:25,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
17:29:25,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
17:29:25,359 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:29:25,364 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:29:38,312 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4966
en_de Dev loss: 0.8468 r:0.2148
en_zh Dev loss: 0.6414 r:0.4809
ro_en Dev loss: 0.2997 r:0.8133
et_en Dev loss: 0.3803 r:0.6925
si_en Dev loss: 0.5455 r:0.6201
ne_en Dev loss: 0.3482 r:0.7551
ru_en Dev loss: 0.3515 r:0.7704
Current avg r:0.6210 Best avg r: 0.6210
17:33:30,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:43,939 root INFO 
id:en_de cur r: 0.2410 best r: 0.2410
17:34:09,886 root INFO 
id:ro_en cur r: 0.8139 best r: 0.8139
17:34:48,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:19,430 root INFO Epoch 1 Global steps: 16200 Train loss: 0.5206
en_de Dev loss: 0.8723 r:0.2211
en_zh Dev loss: 0.7217 r:0.4749
ro_en Dev loss: 0.3342 r:0.8159
et_en Dev loss: 0.4106 r:0.6838
si_en Dev loss: 0.6608 r:0.6060
ne_en Dev loss: 0.3732 r:0.7567
ru_en Dev loss: 0.4353 r:0.7535
Current avg r:0.6160 Best avg r: 0.6210
17:40:12,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:25,305 root INFO 
id:en_de cur r: 0.2779 best r: 0.2779
17:41:29,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:00,641 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4758
en_de Dev loss: 0.8869 r:0.2626
en_zh Dev loss: 0.7597 r:0.4651
ro_en Dev loss: 0.3736 r:0.8101
et_en Dev loss: 0.4436 r:0.6768
si_en Dev loss: 0.7926 r:0.5889
ne_en Dev loss: 0.4558 r:0.7436
ru_en Dev loss: 0.4990 r:0.7340
Current avg r:0.6116 Best avg r: 0.6210
17:46:52,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:31,537 root INFO 
id:ro_en cur r: 0.8177 best r: 0.8177
17:47:57,441 root INFO 
id:ne_en cur r: 0.7626 best r: 0.7626
17:48:10,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:40,925 root INFO Epoch 1 Global steps: 17400 Train loss: 0.5260
en_de Dev loss: 0.8638 r:0.2555
en_zh Dev loss: 0.7645 r:0.4634
ro_en Dev loss: 0.3116 r:0.8190
et_en Dev loss: 0.4291 r:0.6760
si_en Dev loss: 0.6688 r:0.6027
ne_en Dev loss: 0.4097 r:0.7584
ru_en Dev loss: 0.4929 r:0.7318
Current avg r:0.6153 Best avg r: 0.6210
17:53:33,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:45,927 root INFO 
id:en_de cur r: 0.2788 best r: 0.2788
17:54:50,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:21,491 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4901
en_de Dev loss: 0.8260 r:0.2727
en_zh Dev loss: 0.6572 r:0.4765
ro_en Dev loss: 0.3068 r:0.8164
et_en Dev loss: 0.4003 r:0.6811
si_en Dev loss: 0.6426 r:0.6011
ne_en Dev loss: 0.3876 r:0.7541
ru_en Dev loss: 0.4160 r:0.7401
Current avg r:0.6203 Best avg r: 0.6210
18:00:15,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:32,727 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:03,382 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4518
en_de Dev loss: 0.9115 r:0.2518
en_zh Dev loss: 0.8253 r:0.4680
ro_en Dev loss: 0.3801 r:0.8130
et_en Dev loss: 0.4536 r:0.6693
si_en Dev loss: 0.7563 r:0.5982
ne_en Dev loss: 0.4588 r:0.7489
ru_en Dev loss: 0.5450 r:0.7307
Current avg r:0.6114 Best avg r: 0.6210
18:06:55,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:34,393 root INFO 
id:ro_en cur r: 0.8234 best r: 0.8234
18:08:13,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:44,70 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4707
en_de Dev loss: 0.8535 r:0.2238
en_zh Dev loss: 0.6684 r:0.4788
ro_en Dev loss: 0.3061 r:0.8231
et_en Dev loss: 0.4169 r:0.6733
si_en Dev loss: 0.7271 r:0.6046
ne_en Dev loss: 0.4664 r:0.7513
ru_en Dev loss: 0.4002 r:0.7529
Current avg r:0.6154 Best avg r: 0.6210
18:13:36,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:41,565 root INFO 
id:ne_en cur r: 0.7675 best r: 0.7675
18:14:54,466 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:25,64 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
18:16:25,71 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:16:25,77 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:16:25,82 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
18:16:25,88 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
18:16:25,94 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:16:25,99 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:16:38,101 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4671
en_de Dev loss: 0.8536 r:0.2276
en_zh Dev loss: 0.6624 r:0.4802
ro_en Dev loss: 0.3013 r:0.8241
et_en Dev loss: 0.3881 r:0.6902
si_en Dev loss: 0.6314 r:0.6130
ne_en Dev loss: 0.3644 r:0.7645
ru_en Dev loss: 0.3874 r:0.7511
Current avg r:0.6215 Best avg r: 0.6215
18:20:31,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:48,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:19,153 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4658
en_de Dev loss: 0.8726 r:0.2359
en_zh Dev loss: 0.7938 r:0.4520
ro_en Dev loss: 0.3686 r:0.8111
et_en Dev loss: 0.4441 r:0.6803
si_en Dev loss: 0.8071 r:0.5946
ne_en Dev loss: 0.4721 r:0.7569
ru_en Dev loss: 0.4852 r:0.7273
Current avg r:0.6083 Best avg r: 0.6215
18:27:11,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:29,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:00,221 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4328
en_de Dev loss: 0.8609 r:0.2383
en_zh Dev loss: 0.7182 r:0.4675
ro_en Dev loss: 0.3101 r:0.8184
et_en Dev loss: 0.4054 r:0.6804
si_en Dev loss: 0.6115 r:0.6132
ne_en Dev loss: 0.4045 r:0.7515
ru_en Dev loss: 0.4605 r:0.7304
Current avg r:0.6142 Best avg r: 0.6215
18:33:52,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:10,270 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:40,922 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4472
en_de Dev loss: 0.8559 r:0.2352
en_zh Dev loss: 0.7319 r:0.4692
ro_en Dev loss: 0.3376 r:0.8124
et_en Dev loss: 0.4208 r:0.6717
si_en Dev loss: 0.8072 r:0.5925
ne_en Dev loss: 0.4657 r:0.7460
ru_en Dev loss: 0.4876 r:0.7277
Current avg r:0.6078 Best avg r: 0.6215
18:40:33,70 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:46,17 root INFO 
id:en_de cur r: 0.2813 best r: 0.2813
18:41:50,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:21,445 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4391
en_de Dev loss: 0.8709 r:0.2384
en_zh Dev loss: 0.7552 r:0.4692
ro_en Dev loss: 0.3597 r:0.8156
et_en Dev loss: 0.4270 r:0.6647
si_en Dev loss: 0.6720 r:0.6108
ne_en Dev loss: 0.4298 r:0.7556
ru_en Dev loss: 0.4771 r:0.7359
Current avg r:0.6129 Best avg r: 0.6215
18:47:13,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:31,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:01,926 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4334
en_de Dev loss: 0.8477 r:0.2356
en_zh Dev loss: 0.6926 r:0.4724
ro_en Dev loss: 0.3190 r:0.8205
et_en Dev loss: 0.3820 r:0.6883
si_en Dev loss: 0.6114 r:0.6190
ne_en Dev loss: 0.3478 r:0.7621
ru_en Dev loss: 0.4363 r:0.7392
Current avg r:0.6196 Best avg r: 0.6215
18:53:54,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:11,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:56:42,220 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4450
en_de Dev loss: 0.8990 r:0.2158
en_zh Dev loss: 0.7556 r:0.4520
ro_en Dev loss: 0.3715 r:0.8067
et_en Dev loss: 0.4339 r:0.6717
si_en Dev loss: 0.8165 r:0.5866
ne_en Dev loss: 0.4733 r:0.7482
ru_en Dev loss: 0.5425 r:0.7090
Current avg r:0.5986 Best avg r: 0.6215
19:00:34,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:51,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:22,498 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4589
en_de Dev loss: 0.8383 r:0.2423
en_zh Dev loss: 0.7162 r:0.4741
ro_en Dev loss: 0.3383 r:0.8119
et_en Dev loss: 0.3964 r:0.6873
si_en Dev loss: 0.7253 r:0.5999
ne_en Dev loss: 0.4153 r:0.7584
ru_en Dev loss: 0.4508 r:0.7397
Current avg r:0.6162 Best avg r: 0.6215
19:07:14,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:32,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:03,207 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4233
en_de Dev loss: 0.8704 r:0.2466
en_zh Dev loss: 0.7611 r:0.4682
ro_en Dev loss: 0.3708 r:0.8074
et_en Dev loss: 0.4495 r:0.6694
si_en Dev loss: 0.8043 r:0.5945
ne_en Dev loss: 0.4768 r:0.7474
ru_en Dev loss: 0.5229 r:0.7262
Current avg r:0.6085 Best avg r: 0.6215
19:13:55,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:12,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:43,613 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4341
en_de Dev loss: 0.8625 r:0.2547
en_zh Dev loss: 0.7397 r:0.4594
ro_en Dev loss: 0.3271 r:0.8152
et_en Dev loss: 0.3977 r:0.6802
si_en Dev loss: 0.6782 r:0.6081
ne_en Dev loss: 0.3983 r:0.7565
ru_en Dev loss: 0.4458 r:0.7354
Current avg r:0.6156 Best avg r: 0.6215
19:20:35,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:48,948 root INFO 
id:en_de cur r: 0.2823 best r: 0.2823
19:21:53,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:24,424 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4338
en_de Dev loss: 0.8490 r:0.2687
en_zh Dev loss: 0.7729 r:0.4532
ro_en Dev loss: 0.3383 r:0.8154
et_en Dev loss: 0.4043 r:0.6849
si_en Dev loss: 0.6338 r:0.6103
ne_en Dev loss: 0.4384 r:0.7529
ru_en Dev loss: 0.4654 r:0.7338
Current avg r:0.6170 Best avg r: 0.6215
19:27:16,915 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:34,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:05,163 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4138
en_de Dev loss: 0.9111 r:0.2609
en_zh Dev loss: 0.8821 r:0.4569
ro_en Dev loss: 0.4404 r:0.8112
et_en Dev loss: 0.4752 r:0.6762
si_en Dev loss: 0.8775 r:0.5975
ne_en Dev loss: 0.5305 r:0.7486
ru_en Dev loss: 0.5933 r:0.7130
Current avg r:0.6092 Best avg r: 0.6215
19:33:57,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:15,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:45,771 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4245
en_de Dev loss: 0.8365 r:0.2440
en_zh Dev loss: 0.6904 r:0.4609
ro_en Dev loss: 0.3202 r:0.8162
et_en Dev loss: 0.3816 r:0.6884
si_en Dev loss: 0.6134 r:0.6093
ne_en Dev loss: 0.3940 r:0.7533
ru_en Dev loss: 0.4218 r:0.7384
Current avg r:0.6158 Best avg r: 0.6215
19:40:38,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:56,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:27,409 root INFO Epoch 3 Global steps: 27600 Train loss: 0.4155
en_de Dev loss: 0.8382 r:0.2573
en_zh Dev loss: 0.7037 r:0.4696
ro_en Dev loss: 0.3390 r:0.8154
et_en Dev loss: 0.3701 r:0.6926
si_en Dev loss: 0.6019 r:0.6098
ne_en Dev loss: 0.3557 r:0.7563
ru_en Dev loss: 0.4099 r:0.7363
Current avg r:0.6196 Best avg r: 0.6215
19:47:19,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:37,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:07,687 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3923
en_de Dev loss: 0.8485 r:0.2506
en_zh Dev loss: 0.7514 r:0.4483
ro_en Dev loss: 0.3618 r:0.8079
et_en Dev loss: 0.4120 r:0.6813
si_en Dev loss: 0.8050 r:0.5840
ne_en Dev loss: 0.5085 r:0.7545
ru_en Dev loss: 0.4971 r:0.7174
Current avg r:0.6063 Best avg r: 0.6215
19:53:59,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:17,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:48,146 root INFO Epoch 3 Global steps: 28800 Train loss: 0.4172
en_de Dev loss: 0.8822 r:0.2116
en_zh Dev loss: 0.7754 r:0.4457
ro_en Dev loss: 0.3415 r:0.8120
et_en Dev loss: 0.4020 r:0.6750
si_en Dev loss: 0.8012 r:0.5873
ne_en Dev loss: 0.4429 r:0.7517
ru_en Dev loss: 0.4913 r:0.7214
Current avg r:0.6007 Best avg r: 0.6215
20:00:40,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:01:58,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:28,531 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3927
en_de Dev loss: 0.8761 r:0.2389
en_zh Dev loss: 0.7428 r:0.4532
ro_en Dev loss: 0.3689 r:0.8112
et_en Dev loss: 0.3873 r:0.6766
si_en Dev loss: 0.6848 r:0.5967
ne_en Dev loss: 0.3966 r:0.7528
ru_en Dev loss: 0.4350 r:0.7425
Current avg r:0.6103 Best avg r: 0.6215
20:07:20,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:38,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:08,685 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3882
en_de Dev loss: 0.8611 r:0.2243
en_zh Dev loss: 0.7569 r:0.4504
ro_en Dev loss: 0.3460 r:0.8134
et_en Dev loss: 0.3976 r:0.6758
si_en Dev loss: 0.6953 r:0.5932
ne_en Dev loss: 0.4331 r:0.7469
ru_en Dev loss: 0.4636 r:0.7277
Current avg r:0.6045 Best avg r: 0.6215
20:14:00,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:18,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:48,738 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3549
en_de Dev loss: 0.8456 r:0.2328
en_zh Dev loss: 0.7521 r:0.4359
ro_en Dev loss: 0.3382 r:0.8173
et_en Dev loss: 0.3997 r:0.6726
si_en Dev loss: 0.7853 r:0.5920
ne_en Dev loss: 0.4449 r:0.7518
ru_en Dev loss: 0.4608 r:0.7245
Current avg r:0.6038 Best avg r: 0.6215
20:20:41,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:58,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:29,551 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3983
en_de Dev loss: 0.8621 r:0.2584
en_zh Dev loss: 0.7618 r:0.4540
ro_en Dev loss: 0.3391 r:0.8175
et_en Dev loss: 0.4167 r:0.6766
si_en Dev loss: 0.8171 r:0.5985
ne_en Dev loss: 0.5290 r:0.7506
ru_en Dev loss: 0.4614 r:0.7343
Current avg r:0.6128 Best avg r: 0.6215
20:27:21,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:39,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:09,757 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3783
en_de Dev loss: 0.8585 r:0.2349
en_zh Dev loss: 0.8009 r:0.4285
ro_en Dev loss: 0.3576 r:0.8076
et_en Dev loss: 0.4304 r:0.6674
si_en Dev loss: 0.7673 r:0.5941
ne_en Dev loss: 0.5402 r:0.7510
ru_en Dev loss: 0.4703 r:0.7165
Current avg r:0.6000 Best avg r: 0.6215
20:34:02,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:19,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:50,382 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3667
en_de Dev loss: 0.8389 r:0.2516
en_zh Dev loss: 0.7402 r:0.4665
ro_en Dev loss: 0.3322 r:0.8143
et_en Dev loss: 0.3994 r:0.6734
si_en Dev loss: 0.7122 r:0.6016
ne_en Dev loss: 0.4289 r:0.7566
ru_en Dev loss: 0.4272 r:0.7411
Current avg r:0.6150 Best avg r: 0.6215
20:40:42,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:00,139 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:30,772 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3881
en_de Dev loss: 0.8358 r:0.2596
en_zh Dev loss: 0.7170 r:0.4633
ro_en Dev loss: 0.3198 r:0.8194
et_en Dev loss: 0.4015 r:0.6739
si_en Dev loss: 0.7493 r:0.5936
ne_en Dev loss: 0.4426 r:0.7599
ru_en Dev loss: 0.4518 r:0.7285
Current avg r:0.6140 Best avg r: 0.6215
20:47:23,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:40,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:11,317 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3890
en_de Dev loss: 0.8382 r:0.2518
en_zh Dev loss: 0.6999 r:0.4742
ro_en Dev loss: 0.3407 r:0.8178
et_en Dev loss: 0.3902 r:0.6759
si_en Dev loss: 0.6790 r:0.6066
ne_en Dev loss: 0.3938 r:0.7542
ru_en Dev loss: 0.4909 r:0.7124
Current avg r:0.6133 Best avg r: 0.6215
20:54:03,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:21,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:51,679 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3796
en_de Dev loss: 0.8723 r:0.2382
en_zh Dev loss: 0.7522 r:0.4576
ro_en Dev loss: 0.3706 r:0.8125
et_en Dev loss: 0.4039 r:0.6706
si_en Dev loss: 0.7120 r:0.6009
ne_en Dev loss: 0.4502 r:0.7486
ru_en Dev loss: 0.4608 r:0.7289
Current avg r:0.6082 Best avg r: 0.6215
21:00:43,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:01,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:32,49 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3743
en_de Dev loss: 0.8497 r:0.2391
en_zh Dev loss: 0.7503 r:0.4409
ro_en Dev loss: 0.3421 r:0.8179
et_en Dev loss: 0.3986 r:0.6651
si_en Dev loss: 0.7093 r:0.6002
ne_en Dev loss: 0.4047 r:0.7488
ru_en Dev loss: 0.4362 r:0.7266
Current avg r:0.6055 Best avg r: 0.6215
21:07:24,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:42,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:12,668 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3681
en_de Dev loss: 0.8638 r:0.2321
en_zh Dev loss: 0.8368 r:0.4300
ro_en Dev loss: 0.3776 r:0.8132
et_en Dev loss: 0.4439 r:0.6496
si_en Dev loss: 0.8410 r:0.5920
ne_en Dev loss: 0.5097 r:0.7428
ru_en Dev loss: 0.5442 r:0.6960
Current avg r:0.5937 Best avg r: 0.6215
21:14:04,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:43,737 root INFO 
id:ro_en cur r: 0.8242 best r: 0.8242
21:15:22,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:53,191 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3766
en_de Dev loss: 0.8404 r:0.2376
en_zh Dev loss: 0.7382 r:0.4519
ro_en Dev loss: 0.2976 r:0.8243
et_en Dev loss: 0.3899 r:0.6713
si_en Dev loss: 0.6560 r:0.6060
ne_en Dev loss: 0.3948 r:0.7527
ru_en Dev loss: 0.4403 r:0.7165
Current avg r:0.6086 Best avg r: 0.6215
21:20:47,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:04,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:35,595 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3455
en_de Dev loss: 0.8843 r:0.2195
en_zh Dev loss: 0.8107 r:0.4356
ro_en Dev loss: 0.3564 r:0.8146
et_en Dev loss: 0.4279 r:0.6595
si_en Dev loss: 0.8014 r:0.5863
ne_en Dev loss: 0.4951 r:0.7467
ru_en Dev loss: 0.4937 r:0.7158
Current avg r:0.5969 Best avg r: 0.6215
21:27:27,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:45,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:30:16,286 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3501
en_de Dev loss: 0.8772 r:0.2296
en_zh Dev loss: 0.7808 r:0.4415
ro_en Dev loss: 0.3487 r:0.8176
et_en Dev loss: 0.4107 r:0.6588
si_en Dev loss: 0.7291 r:0.5908
ne_en Dev loss: 0.4449 r:0.7485
ru_en Dev loss: 0.4756 r:0.7122
Current avg r:0.5999 Best avg r: 0.6215
21:34:08,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:26,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:57,56 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3422
en_de Dev loss: 0.9248 r:0.2414
en_zh Dev loss: 0.8836 r:0.4260
ro_en Dev loss: 0.3949 r:0.8122
et_en Dev loss: 0.4591 r:0.6576
si_en Dev loss: 0.8819 r:0.5779
ne_en Dev loss: 0.5421 r:0.7376
ru_en Dev loss: 0.5917 r:0.6854
Current avg r:0.5912 Best avg r: 0.6215
21:40:49,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:07,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:37,658 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3254
en_de Dev loss: 0.8555 r:0.2323
en_zh Dev loss: 0.8037 r:0.4360
ro_en Dev loss: 0.3486 r:0.8184
et_en Dev loss: 0.4084 r:0.6665
si_en Dev loss: 0.7920 r:0.5881
ne_en Dev loss: 0.5395 r:0.7389
ru_en Dev loss: 0.4986 r:0.7010
Current avg r:0.5973 Best avg r: 0.6215
21:47:30,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:47,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:50:18,608 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3416
en_de Dev loss: 0.8721 r:0.1972
en_zh Dev loss: 0.7940 r:0.4393
ro_en Dev loss: 0.3727 r:0.8109
et_en Dev loss: 0.4122 r:0.6611
si_en Dev loss: 0.7300 r:0.5916
ne_en Dev loss: 0.4469 r:0.7337
ru_en Dev loss: 0.4799 r:0.7099
Current avg r:0.5919 Best avg r: 0.6215
21:54:11,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:28,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:59,629 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3341
en_de Dev loss: 0.8811 r:0.2127
en_zh Dev loss: 0.8431 r:0.4291
ro_en Dev loss: 0.3983 r:0.8079
et_en Dev loss: 0.4316 r:0.6523
si_en Dev loss: 0.7865 r:0.5811
ne_en Dev loss: 0.5143 r:0.7329
ru_en Dev loss: 0.5294 r:0.6998
Current avg r:0.5880 Best avg r: 0.6215
22:00:52,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:09,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:40,199 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3375
en_de Dev loss: 0.8570 r:0.2208
en_zh Dev loss: 0.7428 r:0.4478
ro_en Dev loss: 0.3301 r:0.8158
et_en Dev loss: 0.4004 r:0.6692
si_en Dev loss: 0.7292 r:0.5873
ne_en Dev loss: 0.4753 r:0.7431
ru_en Dev loss: 0.4941 r:0.6997
Current avg r:0.5977 Best avg r: 0.6215
22:07:32,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:50,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:20,719 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3575
en_de Dev loss: 0.8879 r:0.2195
en_zh Dev loss: 0.7965 r:0.4370
ro_en Dev loss: 0.3980 r:0.8053
et_en Dev loss: 0.4500 r:0.6496
si_en Dev loss: 0.8556 r:0.5777
ne_en Dev loss: 0.6104 r:0.7313
ru_en Dev loss: 0.5816 r:0.6707
Current avg r:0.5845 Best avg r: 0.6215
22:14:13,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:30,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:01,334 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3371
en_de Dev loss: 0.8560 r:0.2306
en_zh Dev loss: 0.7434 r:0.4580
ro_en Dev loss: 0.3370 r:0.8126
et_en Dev loss: 0.3975 r:0.6653
si_en Dev loss: 0.7150 r:0.5969
ne_en Dev loss: 0.4463 r:0.7412
ru_en Dev loss: 0.4718 r:0.7059
Current avg r:0.6015 Best avg r: 0.6215
22:20:53,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:11,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:42,140 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3286
en_de Dev loss: 0.8601 r:0.2252
en_zh Dev loss: 0.7386 r:0.4753
ro_en Dev loss: 0.3253 r:0.8207
et_en Dev loss: 0.3889 r:0.6703
si_en Dev loss: 0.6325 r:0.6095
ne_en Dev loss: 0.4179 r:0.7418
ru_en Dev loss: 0.4384 r:0.7145
Current avg r:0.6082 Best avg r: 0.6215
22:27:34,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:52,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:22,914 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3279
en_de Dev loss: 0.8605 r:0.2186
en_zh Dev loss: 0.8070 r:0.4356
ro_en Dev loss: 0.3594 r:0.8124
et_en Dev loss: 0.4163 r:0.6515
si_en Dev loss: 0.7875 r:0.5867
ne_en Dev loss: 0.4656 r:0.7369
ru_en Dev loss: 0.5013 r:0.6970
Current avg r:0.5912 Best avg r: 0.6215
22:34:15,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:32,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:03,401 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3163
en_de Dev loss: 0.8543 r:0.2141
en_zh Dev loss: 0.7708 r:0.4483
ro_en Dev loss: 0.3350 r:0.8166
et_en Dev loss: 0.4025 r:0.6618
si_en Dev loss: 0.6856 r:0.6017
ne_en Dev loss: 0.4810 r:0.7421
ru_en Dev loss: 0.4749 r:0.7038
Current avg r:0.5983 Best avg r: 0.6215
22:40:55,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:13,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:43:43,948 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3313
en_de Dev loss: 0.8544 r:0.2155
en_zh Dev loss: 0.7639 r:0.4471
ro_en Dev loss: 0.3202 r:0.8188
et_en Dev loss: 0.4010 r:0.6579
si_en Dev loss: 0.6970 r:0.5918
ne_en Dev loss: 0.4271 r:0.7366
ru_en Dev loss: 0.4506 r:0.7149
Current avg r:0.5975 Best avg r: 0.6215
22:47:36,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:54,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:24,789 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3226
en_de Dev loss: 0.9062 r:0.2137
en_zh Dev loss: 0.8476 r:0.4370
ro_en Dev loss: 0.3582 r:0.8167
et_en Dev loss: 0.4475 r:0.6406
si_en Dev loss: 0.7979 r:0.5869
ne_en Dev loss: 0.4726 r:0.7401
ru_en Dev loss: 0.5052 r:0.7075
Current avg r:0.5918 Best avg r: 0.6215
22:54:16,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:34,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:05,257 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3338
en_de Dev loss: 0.8592 r:0.2084
en_zh Dev loss: 0.7591 r:0.4416
ro_en Dev loss: 0.3212 r:0.8185
et_en Dev loss: 0.4165 r:0.6454
si_en Dev loss: 0.6925 r:0.5951
ne_en Dev loss: 0.4464 r:0.7364
ru_en Dev loss: 0.4891 r:0.6927
Current avg r:0.5911 Best avg r: 0.6215
23:00:59,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:16,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:47,528 root INFO Epoch 5 Global steps: 45600 Train loss: 0.3035
en_de Dev loss: 0.8752 r:0.2002
en_zh Dev loss: 0.8146 r:0.4300
ro_en Dev loss: 0.3792 r:0.8096
et_en Dev loss: 0.4400 r:0.6458
si_en Dev loss: 0.7877 r:0.5855
ne_en Dev loss: 0.5518 r:0.7372
ru_en Dev loss: 0.4739 r:0.7127
Current avg r:0.5887 Best avg r: 0.6215
23:07:39,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:57,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:28,124 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2991
en_de Dev loss: 0.8634 r:0.1845
en_zh Dev loss: 0.7545 r:0.4442
ro_en Dev loss: 0.3107 r:0.8176
et_en Dev loss: 0.4021 r:0.6569
si_en Dev loss: 0.6809 r:0.5986
ne_en Dev loss: 0.4248 r:0.7254
ru_en Dev loss: 0.4430 r:0.7203
Current avg r:0.5925 Best avg r: 0.6215
23:14:20,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:38,250 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:17:08,878 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2996
en_de Dev loss: 0.8731 r:0.2017
en_zh Dev loss: 0.7923 r:0.4464
ro_en Dev loss: 0.3416 r:0.8196
et_en Dev loss: 0.4053 r:0.6608
si_en Dev loss: 0.7228 r:0.5939
ne_en Dev loss: 0.4512 r:0.7360
ru_en Dev loss: 0.4232 r:0.7373
Current avg r:0.5994 Best avg r: 0.6215
23:21:01,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:18,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:49,592 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2905
en_de Dev loss: 0.8744 r:0.2129
en_zh Dev loss: 0.8043 r:0.4277
ro_en Dev loss: 0.3657 r:0.8060
et_en Dev loss: 0.4336 r:0.6426
si_en Dev loss: 0.8185 r:0.5692
ne_en Dev loss: 0.5253 r:0.7297
ru_en Dev loss: 0.5085 r:0.6892
Current avg r:0.5825 Best avg r: 0.6215
23:27:41,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:59,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:30,363 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2996
en_de Dev loss: 0.8728 r:0.1864
en_zh Dev loss: 0.7571 r:0.4408
ro_en Dev loss: 0.3382 r:0.8119
et_en Dev loss: 0.3992 r:0.6604
si_en Dev loss: 0.6964 r:0.5891
ne_en Dev loss: 0.4007 r:0.7327
ru_en Dev loss: 0.4532 r:0.7183
Current avg r:0.5914 Best avg r: 0.6215
23:34:22,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:40,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:11,23 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2862
en_de Dev loss: 0.8793 r:0.2130
en_zh Dev loss: 0.8449 r:0.4095
ro_en Dev loss: 0.3747 r:0.8060
et_en Dev loss: 0.4431 r:0.6353
si_en Dev loss: 0.9028 r:0.5662
ne_en Dev loss: 0.5045 r:0.7304
ru_en Dev loss: 0.5349 r:0.6845
Current avg r:0.5778 Best avg r: 0.6215
23:41:03,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:21,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:51,520 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2938
en_de Dev loss: 0.8819 r:0.2177
en_zh Dev loss: 0.8359 r:0.4475
ro_en Dev loss: 0.3877 r:0.8148
et_en Dev loss: 0.4201 r:0.6564
si_en Dev loss: 0.8024 r:0.5875
ne_en Dev loss: 0.4803 r:0.7322
ru_en Dev loss: 0.5050 r:0.7140
Current avg r:0.5957 Best avg r: 0.6215
23:47:43,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:01,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:31,905 root INFO Epoch 5 Global steps: 49800 Train loss: 0.3047
en_de Dev loss: 0.8829 r:0.2212
en_zh Dev loss: 0.8000 r:0.4370
ro_en Dev loss: 0.3589 r:0.8142
et_en Dev loss: 0.4239 r:0.6442
si_en Dev loss: 0.7638 r:0.5786
ne_en Dev loss: 0.4409 r:0.7305
ru_en Dev loss: 0.4927 r:0.7078
Current avg r:0.5905 Best avg r: 0.6215
23:54:24,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:41,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:12,335 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2815
en_de Dev loss: 0.8815 r:0.2191
en_zh Dev loss: 0.8071 r:0.4383
ro_en Dev loss: 0.3821 r:0.8095
et_en Dev loss: 0.4269 r:0.6472
si_en Dev loss: 0.8391 r:0.5688
ne_en Dev loss: 0.5475 r:0.7360
ru_en Dev loss: 0.5125 r:0.7034
Current avg r:0.5889 Best avg r: 0.6215
00:01:04,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:22,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:52,802 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2856
en_de Dev loss: 0.8673 r:0.2194
en_zh Dev loss: 0.7711 r:0.4530
ro_en Dev loss: 0.3907 r:0.8066
et_en Dev loss: 0.4492 r:0.6369
si_en Dev loss: 0.9036 r:0.5602
ne_en Dev loss: 0.5536 r:0.7367
ru_en Dev loss: 0.5414 r:0.6916
Current avg r:0.5864 Best avg r: 0.6215
00:07:44,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:02,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:33,36 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2690
en_de Dev loss: 0.8885 r:0.2063
en_zh Dev loss: 0.8440 r:0.4277
ro_en Dev loss: 0.3828 r:0.8046
et_en Dev loss: 0.4378 r:0.6353
si_en Dev loss: 0.8511 r:0.5603
ne_en Dev loss: 0.5356 r:0.7293
ru_en Dev loss: 0.5184 r:0.6956
Current avg r:0.5799 Best avg r: 0.6215
00:14:25,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:15:42,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:17:13,189 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2904
en_de Dev loss: 0.8751 r:0.2002
en_zh Dev loss: 0.7978 r:0.4418
ro_en Dev loss: 0.3703 r:0.8107
et_en Dev loss: 0.4196 r:0.6450
si_en Dev loss: 0.8583 r:0.5622
ne_en Dev loss: 0.4579 r:0.7350
ru_en Dev loss: 0.4827 r:0.7065
Current avg r:0.5859 Best avg r: 0.6215
00:21:05,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:22,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:53,431 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2930
en_de Dev loss: 0.9192 r:0.2185
en_zh Dev loss: 0.8378 r:0.4338
ro_en Dev loss: 0.4055 r:0.8044
et_en Dev loss: 0.4343 r:0.6452
si_en Dev loss: 0.8445 r:0.5577
ne_en Dev loss: 0.5283 r:0.7263
ru_en Dev loss: 0.5252 r:0.7007
Current avg r:0.5838 Best avg r: 0.6215
00:27:45,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:03,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:33,982 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2900
en_de Dev loss: 0.8717 r:0.1982
en_zh Dev loss: 0.8327 r:0.4409
ro_en Dev loss: 0.4189 r:0.8061
et_en Dev loss: 0.4472 r:0.6476
si_en Dev loss: 1.0811 r:0.5445
ne_en Dev loss: 0.6586 r:0.7297
ru_en Dev loss: 0.5675 r:0.6922
Current avg r:0.5799 Best avg r: 0.6215
00:34:26,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:43,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:14,278 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2798
en_de Dev loss: 0.8956 r:0.1783
en_zh Dev loss: 0.7889 r:0.4437
ro_en Dev loss: 0.3543 r:0.8178
et_en Dev loss: 0.4126 r:0.6568
si_en Dev loss: 0.8491 r:0.5699
ne_en Dev loss: 0.5170 r:0.7441
ru_en Dev loss: 0.4706 r:0.7231
Current avg r:0.5905 Best avg r: 0.6215
00:41:07,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:25,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:55,809 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2868
en_de Dev loss: 0.9213 r:0.1523
en_zh Dev loss: 0.8014 r:0.4524
ro_en Dev loss: 0.3825 r:0.8110
et_en Dev loss: 0.4277 r:0.6466
si_en Dev loss: 0.8682 r:0.5589
ne_en Dev loss: 0.5301 r:0.7262
ru_en Dev loss: 0.4814 r:0.7243
Current avg r:0.5817 Best avg r: 0.6215
00:47:48,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:05,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:35,601 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2457
en_de Dev loss: 0.8918 r:0.1809
en_zh Dev loss: 0.7956 r:0.4494
ro_en Dev loss: 0.3826 r:0.8074
et_en Dev loss: 0.4270 r:0.6455
si_en Dev loss: 0.8489 r:0.5610
ne_en Dev loss: 0.5686 r:0.7332
ru_en Dev loss: 0.4705 r:0.7187
Current avg r:0.5852 Best avg r: 0.6215
00:54:27,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:45,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:15,454 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2541
en_de Dev loss: 0.9319 r:0.1644
en_zh Dev loss: 0.9036 r:0.4177
ro_en Dev loss: 0.4514 r:0.7944
et_en Dev loss: 0.4769 r:0.6252
si_en Dev loss: 1.0649 r:0.5315
ne_en Dev loss: 0.6603 r:0.7269
ru_en Dev loss: 0.5678 r:0.6869
Current avg r:0.5638 Best avg r: 0.6215
01:01:07,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:02:24,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:55,346 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2615
en_de Dev loss: 0.8811 r:0.1783
en_zh Dev loss: 0.7576 r:0.4545
ro_en Dev loss: 0.3515 r:0.8114
et_en Dev loss: 0.4106 r:0.6485
si_en Dev loss: 0.7564 r:0.5693
ne_en Dev loss: 0.4278 r:0.7294
ru_en Dev loss: 0.4648 r:0.7073
Current avg r:0.5855 Best avg r: 0.6215
01:07:47,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:04,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:35,287 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2547
en_de Dev loss: 0.8943 r:0.1865
en_zh Dev loss: 0.7654 r:0.4487
ro_en Dev loss: 0.3447 r:0.8136
et_en Dev loss: 0.4077 r:0.6535
si_en Dev loss: 0.7770 r:0.5710
ne_en Dev loss: 0.4737 r:0.7290
ru_en Dev loss: 0.4961 r:0.6996
Current avg r:0.5860 Best avg r: 0.6215
01:14:27,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:44,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:15,177 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2563
en_de Dev loss: 0.8988 r:0.1840
en_zh Dev loss: 0.8828 r:0.4277
ro_en Dev loss: 0.3991 r:0.8119
et_en Dev loss: 0.4409 r:0.6388
si_en Dev loss: 0.9504 r:0.5548
ne_en Dev loss: 0.5825 r:0.7275
ru_en Dev loss: 0.5059 r:0.7046
Current avg r:0.5785 Best avg r: 0.6215
01:21:07,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:22:24,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:54,815 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2388
en_de Dev loss: 0.9080 r:0.1829
en_zh Dev loss: 0.8080 r:0.4402
ro_en Dev loss: 0.3654 r:0.8131
et_en Dev loss: 0.4307 r:0.6488
si_en Dev loss: 0.8814 r:0.5609
ne_en Dev loss: 0.5323 r:0.7381
ru_en Dev loss: 0.4563 r:0.7235
Current avg r:0.5868 Best avg r: 0.6215
01:27:46,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:04,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:34,504 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2439
en_de Dev loss: 0.8712 r:0.1741
en_zh Dev loss: 0.7882 r:0.4340
ro_en Dev loss: 0.3583 r:0.8101
et_en Dev loss: 0.4180 r:0.6430
si_en Dev loss: 0.8185 r:0.5626
ne_en Dev loss: 0.4911 r:0.7331
ru_en Dev loss: 0.4661 r:0.7066
Current avg r:0.5805 Best avg r: 0.6215
01:34:26,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:43,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:14,113 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2556
en_de Dev loss: 0.9034 r:0.1951
en_zh Dev loss: 0.8561 r:0.4350
ro_en Dev loss: 0.3972 r:0.8077
et_en Dev loss: 0.4396 r:0.6369
si_en Dev loss: 0.9031 r:0.5637
ne_en Dev loss: 0.5647 r:0.7315
ru_en Dev loss: 0.4822 r:0.7085
Current avg r:0.5826 Best avg r: 0.6215
01:41:05,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:23,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:53,742 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2522
en_de Dev loss: 0.9220 r:0.2084
en_zh Dev loss: 0.8645 r:0.4229
ro_en Dev loss: 0.4007 r:0.8008
et_en Dev loss: 0.4485 r:0.6345
si_en Dev loss: 0.8935 r:0.5599
ne_en Dev loss: 0.5765 r:0.7315
ru_en Dev loss: 0.5375 r:0.6974
Current avg r:0.5793 Best avg r: 0.6215
01:47:45,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:49:02,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:50:33,356 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2592
en_de Dev loss: 0.8682 r:0.2048
en_zh Dev loss: 0.7705 r:0.4569
ro_en Dev loss: 0.3653 r:0.8086
et_en Dev loss: 0.4305 r:0.6366
si_en Dev loss: 0.8982 r:0.5472
ne_en Dev loss: 0.5306 r:0.7260
ru_en Dev loss: 0.4886 r:0.7100
Current avg r:0.5843 Best avg r: 0.6215
01:54:25,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:55:42,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:57:12,927 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2618
en_de Dev loss: 0.8879 r:0.2042
en_zh Dev loss: 0.8511 r:0.4331
ro_en Dev loss: 0.3734 r:0.8108
et_en Dev loss: 0.4468 r:0.6313
si_en Dev loss: 0.9788 r:0.5415
ne_en Dev loss: 0.5980 r:0.7265
ru_en Dev loss: 0.4980 r:0.7102
Current avg r:0.5797 Best avg r: 0.6215
02:01:04,980 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:02:22,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:03:52,529 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2373
en_de Dev loss: 0.9191 r:0.2040
en_zh Dev loss: 0.8398 r:0.4419
ro_en Dev loss: 0.3792 r:0.8089
et_en Dev loss: 0.4491 r:0.6355
si_en Dev loss: 0.8710 r:0.5560
ne_en Dev loss: 0.5153 r:0.7290
ru_en Dev loss: 0.5413 r:0.7041
Current avg r:0.5828 Best avg r: 0.6215
02:07:44,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:09:01,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:32,315 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2561
en_de Dev loss: 0.8942 r:0.2104
en_zh Dev loss: 0.8056 r:0.4377
ro_en Dev loss: 0.3865 r:0.8059
et_en Dev loss: 0.4378 r:0.6406
si_en Dev loss: 0.9116 r:0.5469
ne_en Dev loss: 0.5812 r:0.7253
ru_en Dev loss: 0.4945 r:0.7129
Current avg r:0.5828 Best avg r: 0.6215
02:14:24,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:15:41,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:17:12,234 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2463
en_de Dev loss: 0.8688 r:0.2232
en_zh Dev loss: 0.7660 r:0.4577
ro_en Dev loss: 0.3434 r:0.8123
et_en Dev loss: 0.4148 r:0.6461
si_en Dev loss: 0.8046 r:0.5618
ne_en Dev loss: 0.5723 r:0.7266
ru_en Dev loss: 0.4598 r:0.7161
Current avg r:0.5920 Best avg r: 0.6215
02:21:05,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:22:22,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:23:53,383 root INFO Epoch 7 Global steps: 63600 Train loss: 0.2256
en_de Dev loss: 0.8674 r:0.2242
en_zh Dev loss: 0.7559 r:0.4559
ro_en Dev loss: 0.3462 r:0.8102
et_en Dev loss: 0.4148 r:0.6456
si_en Dev loss: 0.8349 r:0.5551
ne_en Dev loss: 0.5143 r:0.7327
ru_en Dev loss: 0.4553 r:0.7203
Current avg r:0.5920 Best avg r: 0.6215
02:27:45,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:02,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:30:33,99 root INFO Epoch 7 Global steps: 64200 Train loss: 0.2185
en_de Dev loss: 0.8824 r:0.2208
en_zh Dev loss: 0.7589 r:0.4579
ro_en Dev loss: 0.3657 r:0.8054
et_en Dev loss: 0.4197 r:0.6427
si_en Dev loss: 0.8083 r:0.5525
ne_en Dev loss: 0.5059 r:0.7307
ru_en Dev loss: 0.4581 r:0.7216
Current avg r:0.5902 Best avg r: 0.6215
02:34:25,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:42,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:37:12,859 root INFO Epoch 7 Global steps: 64800 Train loss: 0.2240
en_de Dev loss: 0.8945 r:0.1991
en_zh Dev loss: 0.8010 r:0.4502
ro_en Dev loss: 0.4012 r:0.8026
et_en Dev loss: 0.4353 r:0.6374
si_en Dev loss: 0.9140 r:0.5468
ne_en Dev loss: 0.5622 r:0.7269
ru_en Dev loss: 0.4776 r:0.7197
Current avg r:0.5833 Best avg r: 0.6215
02:41:05,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:42:22,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:43:52,875 root INFO Epoch 7 Global steps: 65400 Train loss: 0.2270
en_de Dev loss: 0.8645 r:0.2157
en_zh Dev loss: 0.7711 r:0.4554
ro_en Dev loss: 0.3563 r:0.8105
et_en Dev loss: 0.4072 r:0.6566
si_en Dev loss: 0.7915 r:0.5521
ne_en Dev loss: 0.4596 r:0.7219
ru_en Dev loss: 0.4303 r:0.7337
Current avg r:0.5923 Best avg r: 0.6215
02:47:45,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:49:02,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:50:33,80 root INFO Epoch 7 Global steps: 66000 Train loss: 0.2296
en_de Dev loss: 0.8719 r:0.2191
en_zh Dev loss: 0.7821 r:0.4590
ro_en Dev loss: 0.3527 r:0.8093
et_en Dev loss: 0.4106 r:0.6527
si_en Dev loss: 0.8522 r:0.5448
ne_en Dev loss: 0.5252 r:0.7234
ru_en Dev loss: 0.4540 r:0.7278
Current avg r:0.5909 Best avg r: 0.6215
02:54:25,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:55:42,586 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:57:13,128 root INFO Epoch 7 Global steps: 66600 Train loss: 0.2128
en_de Dev loss: 0.9029 r:0.1963
en_zh Dev loss: 0.7713 r:0.4585
ro_en Dev loss: 0.3338 r:0.8099
et_en Dev loss: 0.4022 r:0.6563
si_en Dev loss: 0.7590 r:0.5492
ne_en Dev loss: 0.4315 r:0.7273
ru_en Dev loss: 0.4605 r:0.7201
Current avg r:0.5882 Best avg r: 0.6215
03:01:05,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:02:22,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:52,954 root INFO Epoch 7 Global steps: 67200 Train loss: 0.2290
en_de Dev loss: 0.9235 r:0.1963
en_zh Dev loss: 0.8780 r:0.4384
ro_en Dev loss: 0.3890 r:0.8053
et_en Dev loss: 0.4166 r:0.6581
si_en Dev loss: 0.8826 r:0.5429
ne_en Dev loss: 0.5658 r:0.7202
ru_en Dev loss: 0.4867 r:0.7213
Current avg r:0.5832 Best avg r: 0.6215
03:07:45,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:02,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:10:32,504 root INFO Epoch 7 Global steps: 67800 Train loss: 0.2187
en_de Dev loss: 0.8863 r:0.2048
en_zh Dev loss: 0.8398 r:0.4292
ro_en Dev loss: 0.3868 r:0.8008
et_en Dev loss: 0.4220 r:0.6456
si_en Dev loss: 0.9500 r:0.5327
ne_en Dev loss: 0.5981 r:0.7208
ru_en Dev loss: 0.5106 r:0.6916
Current avg r:0.5750 Best avg r: 0.6215
03:14:24,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:15:41,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:17:12,23 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2283
en_de Dev loss: 0.8865 r:0.2170
en_zh Dev loss: 0.8919 r:0.4155
ro_en Dev loss: 0.4343 r:0.7988
et_en Dev loss: 0.4352 r:0.6494
si_en Dev loss: 1.1135 r:0.5349
ne_en Dev loss: 0.6758 r:0.7152
ru_en Dev loss: 0.5544 r:0.6891
Current avg r:0.5743 Best avg r: 0.6215
03:21:04,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:22:21,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:51,738 root INFO Epoch 7 Global steps: 69000 Train loss: 0.2361
en_de Dev loss: 0.8849 r:0.2226
en_zh Dev loss: 0.8609 r:0.4354
ro_en Dev loss: 0.3955 r:0.8072
et_en Dev loss: 0.4263 r:0.6463
si_en Dev loss: 0.9543 r:0.5413
ne_en Dev loss: 0.5752 r:0.7179
ru_en Dev loss: 0.5374 r:0.6986
Current avg r:0.5813 Best avg r: 0.6215
03:27:43,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:01,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:31,630 root INFO Epoch 7 Global steps: 69600 Train loss: 0.2141
en_de Dev loss: 0.9022 r:0.2109
en_zh Dev loss: 0.8207 r:0.4476
ro_en Dev loss: 0.3748 r:0.8078
et_en Dev loss: 0.4127 r:0.6523
si_en Dev loss: 0.8289 r:0.5511
ne_en Dev loss: 0.5332 r:0.7177
ru_en Dev loss: 0.4905 r:0.7143
Current avg r:0.5860 Best avg r: 0.6215
03:34:23,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:40,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:37:11,186 root INFO Epoch 7 Global steps: 70200 Train loss: 0.2139
en_de Dev loss: 0.9034 r:0.2031
en_zh Dev loss: 0.8532 r:0.4356
ro_en Dev loss: 0.4107 r:0.8085
et_en Dev loss: 0.4301 r:0.6503
si_en Dev loss: 1.0008 r:0.5467
ne_en Dev loss: 0.7059 r:0.7211
ru_en Dev loss: 0.4877 r:0.7240
Current avg r:0.5842 Best avg r: 0.6215
03:41:03,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:42:20,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:43:50,664 root INFO Epoch 7 Global steps: 70800 Train loss: 0.2330
en_de Dev loss: 0.9154 r:0.2086
en_zh Dev loss: 0.8217 r:0.4439
ro_en Dev loss: 0.4033 r:0.8063
et_en Dev loss: 0.4221 r:0.6480
si_en Dev loss: 0.8946 r:0.5509
ne_en Dev loss: 0.5548 r:0.7204
ru_en Dev loss: 0.5383 r:0.7036
Current avg r:0.5831 Best avg r: 0.6215
03:47:42,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:49:00,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:50:30,533 root INFO Epoch 7 Global steps: 71400 Train loss: 0.2169
en_de Dev loss: 0.8787 r:0.1909
en_zh Dev loss: 0.7923 r:0.4371
ro_en Dev loss: 0.3541 r:0.8126
et_en Dev loss: 0.4268 r:0.6509
si_en Dev loss: 0.7883 r:0.5611
ne_en Dev loss: 0.4773 r:0.7242
ru_en Dev loss: 0.4604 r:0.7078
Current avg r:0.5835 Best avg r: 0.6215
03:54:22,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:55:39,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:57:10,268 root INFO Epoch 7 Global steps: 72000 Train loss: 0.2161
en_de Dev loss: 0.8875 r:0.1924
en_zh Dev loss: 0.8062 r:0.4291
ro_en Dev loss: 0.3561 r:0.8114
et_en Dev loss: 0.4158 r:0.6416
si_en Dev loss: 0.8348 r:0.5564
ne_en Dev loss: 0.5582 r:0.7303
ru_en Dev loss: 0.4495 r:0.7148
Current avg r:0.5823 Best avg r: 0.6215
04:01:03,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:02:20,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:03:51,425 root INFO Epoch 8 Global steps: 72600 Train loss: 0.2067
en_de Dev loss: 0.8974 r:0.1975
en_zh Dev loss: 0.8085 r:0.4404
ro_en Dev loss: 0.3620 r:0.8070
et_en Dev loss: 0.4227 r:0.6380
si_en Dev loss: 0.8567 r:0.5494
ne_en Dev loss: 0.5282 r:0.7260
ru_en Dev loss: 0.4505 r:0.7210
Current avg r:0.5828 Best avg r: 0.6215
04:07:43,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:09:00,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:10:31,176 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1959
en_de Dev loss: 0.8914 r:0.2047
en_zh Dev loss: 0.7968 r:0.4479
ro_en Dev loss: 0.3694 r:0.8033
et_en Dev loss: 0.4118 r:0.6525
si_en Dev loss: 0.8203 r:0.5501
ne_en Dev loss: 0.4844 r:0.7321
ru_en Dev loss: 0.4622 r:0.7133
Current avg r:0.5863 Best avg r: 0.6215
04:14:22,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:15:40,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:17:10,579 root INFO Epoch 8 Global steps: 73800 Train loss: 0.2008
en_de Dev loss: 0.8836 r:0.1968
en_zh Dev loss: 0.8140 r:0.4437
ro_en Dev loss: 0.3948 r:0.8017
et_en Dev loss: 0.4120 r:0.6498
si_en Dev loss: 0.8882 r:0.5499
ne_en Dev loss: 0.5377 r:0.7281
ru_en Dev loss: 0.4724 r:0.7179
Current avg r:0.5840 Best avg r: 0.6215
04:21:02,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:22:20,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:50,171 root INFO Epoch 8 Global steps: 74400 Train loss: 0.2037
en_de Dev loss: 0.9202 r:0.1971
en_zh Dev loss: 0.8698 r:0.4465
ro_en Dev loss: 0.4175 r:0.8074
et_en Dev loss: 0.4261 r:0.6500
si_en Dev loss: 1.0040 r:0.5519
ne_en Dev loss: 0.6344 r:0.7300
ru_en Dev loss: 0.4969 r:0.7286
Current avg r:0.5874 Best avg r: 0.6215
04:27:42,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:28:59,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:29,940 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1925
en_de Dev loss: 0.9157 r:0.2086
en_zh Dev loss: 0.7959 r:0.4516
ro_en Dev loss: 0.3620 r:0.8063
et_en Dev loss: 0.4124 r:0.6545
si_en Dev loss: 0.8315 r:0.5512
ne_en Dev loss: 0.5304 r:0.7231
ru_en Dev loss: 0.4930 r:0.7156
Current avg r:0.5873 Best avg r: 0.6215
04:34:21,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:35:39,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:09,552 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1994
en_de Dev loss: 0.8984 r:0.1806
en_zh Dev loss: 0.7836 r:0.4430
ro_en Dev loss: 0.3630 r:0.8089
et_en Dev loss: 0.4068 r:0.6529
si_en Dev loss: 0.8901 r:0.5446
ne_en Dev loss: 0.5502 r:0.7260
ru_en Dev loss: 0.4605 r:0.7255
Current avg r:0.5831 Best avg r: 0.6215
04:41:01,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:42:18,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:43:49,349 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1967
en_de Dev loss: 0.8944 r:0.1884
en_zh Dev loss: 0.7966 r:0.4373
ro_en Dev loss: 0.3889 r:0.8024
et_en Dev loss: 0.4150 r:0.6449
si_en Dev loss: 0.8991 r:0.5355
ne_en Dev loss: 0.6024 r:0.7209
ru_en Dev loss: 0.4920 r:0.7017
Current avg r:0.5759 Best avg r: 0.6215
04:47:41,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:48:58,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:50:28,839 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1886
en_de Dev loss: 0.9069 r:0.1984
en_zh Dev loss: 0.8064 r:0.4497
ro_en Dev loss: 0.3861 r:0.8057
et_en Dev loss: 0.4310 r:0.6343
si_en Dev loss: 0.9420 r:0.5406
ne_en Dev loss: 0.6144 r:0.7148
ru_en Dev loss: 0.5017 r:0.7098
Current avg r:0.5790 Best avg r: 0.6215
04:54:20,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:55:37,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:57:08,56 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1902
en_de Dev loss: 0.9004 r:0.1930
en_zh Dev loss: 0.7529 r:0.4627
ro_en Dev loss: 0.3611 r:0.8054
et_en Dev loss: 0.4110 r:0.6487
si_en Dev loss: 0.8889 r:0.5383
ne_en Dev loss: 0.5528 r:0.7196
ru_en Dev loss: 0.4415 r:0.7245
Current avg r:0.5846 Best avg r: 0.6215
05:01:00,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:02:17,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:47,713 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1848
en_de Dev loss: 0.9595 r:0.1612
en_zh Dev loss: 0.8533 r:0.4467
ro_en Dev loss: 0.3980 r:0.7994
et_en Dev loss: 0.4309 r:0.6434
si_en Dev loss: 0.9873 r:0.5337
ne_en Dev loss: 0.6824 r:0.7167
ru_en Dev loss: 0.4920 r:0.7157
Current avg r:0.5738 Best avg r: 0.6215
05:07:39,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:08:57,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:10:27,362 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1958
en_de Dev loss: 0.9080 r:0.1813
en_zh Dev loss: 0.7688 r:0.4654
ro_en Dev loss: 0.3594 r:0.8056
et_en Dev loss: 0.4108 r:0.6516
si_en Dev loss: 0.8590 r:0.5496
ne_en Dev loss: 0.5280 r:0.7212
ru_en Dev loss: 0.4505 r:0.7296
Current avg r:0.5863 Best avg r: 0.6215
05:14:19,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:15:36,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:17:06,851 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1886
en_de Dev loss: 0.9155 r:0.1691
en_zh Dev loss: 0.8262 r:0.4561
ro_en Dev loss: 0.4025 r:0.8041
et_en Dev loss: 0.4289 r:0.6499
si_en Dev loss: 0.9548 r:0.5471
ne_en Dev loss: 0.6936 r:0.7207
ru_en Dev loss: 0.5067 r:0.7175
Current avg r:0.5806 Best avg r: 0.6215
05:20:58,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:22:15,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:46,86 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1813
en_de Dev loss: 0.9225 r:0.1906
en_zh Dev loss: 0.8559 r:0.4466
ro_en Dev loss: 0.3862 r:0.8051
et_en Dev loss: 0.4324 r:0.6400
si_en Dev loss: 0.9285 r:0.5374
ne_en Dev loss: 0.5707 r:0.7124
ru_en Dev loss: 0.5483 r:0.7055
Current avg r:0.5768 Best avg r: 0.6215
05:27:37,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:55,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:25,214 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1935
en_de Dev loss: 0.9184 r:0.1878
en_zh Dev loss: 0.8527 r:0.4459
ro_en Dev loss: 0.4053 r:0.8042
et_en Dev loss: 0.4202 r:0.6485
si_en Dev loss: 0.9213 r:0.5439
ne_en Dev loss: 0.5099 r:0.7174
ru_en Dev loss: 0.4820 r:0.7234
Current avg r:0.5816 Best avg r: 0.6215
05:34:17,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:35:34,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:37:04,565 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1860
en_de Dev loss: 0.8968 r:0.1659
en_zh Dev loss: 0.7753 r:0.4494
ro_en Dev loss: 0.3548 r:0.8068
et_en Dev loss: 0.4113 r:0.6479
si_en Dev loss: 0.9049 r:0.5297
ne_en Dev loss: 0.5694 r:0.7118
ru_en Dev loss: 0.4559 r:0.7202
Current avg r:0.5760 Best avg r: 0.6215
05:40:58,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:42:15,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:43:45,745 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1654
en_de Dev loss: 0.9244 r:0.1717
en_zh Dev loss: 0.8495 r:0.4491
ro_en Dev loss: 0.3917 r:0.8092
et_en Dev loss: 0.4259 r:0.6465
si_en Dev loss: 0.9308 r:0.5416
ne_en Dev loss: 0.6170 r:0.7102
ru_en Dev loss: 0.4838 r:0.7253
Current avg r:0.5791 Best avg r: 0.6215
05:47:37,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:48:54,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:50:25,164 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1718
en_de Dev loss: 0.9350 r:0.1891
en_zh Dev loss: 0.8545 r:0.4416
ro_en Dev loss: 0.3969 r:0.8014
et_en Dev loss: 0.4354 r:0.6407
si_en Dev loss: 0.9470 r:0.5402
ne_en Dev loss: 0.6138 r:0.7116
ru_en Dev loss: 0.5173 r:0.7113
Current avg r:0.5766 Best avg r: 0.6215
05:54:16,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:55:34,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:57:04,790 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1710
en_de Dev loss: 0.9546 r:0.1808
en_zh Dev loss: 0.8452 r:0.4483
ro_en Dev loss: 0.3892 r:0.8057
et_en Dev loss: 0.4241 r:0.6485
si_en Dev loss: 0.9042 r:0.5439
ne_en Dev loss: 0.5961 r:0.7138
ru_en Dev loss: 0.4723 r:0.7334
Current avg r:0.5821 Best avg r: 0.6215
06:00:56,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:02:14,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:03:44,375 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1774
en_de Dev loss: 0.9255 r:0.2020
en_zh Dev loss: 0.8935 r:0.4385
ro_en Dev loss: 0.4183 r:0.7987
et_en Dev loss: 0.4324 r:0.6479
si_en Dev loss: 1.0641 r:0.5261
ne_en Dev loss: 0.7267 r:0.7061
ru_en Dev loss: 0.4865 r:0.7343
Current avg r:0.5791 Best avg r: 0.6215
06:07:36,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:08:53,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:10:23,598 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1749
en_de Dev loss: 0.9187 r:0.1790
en_zh Dev loss: 0.8325 r:0.4456
ro_en Dev loss: 0.3833 r:0.8062
et_en Dev loss: 0.4170 r:0.6515
si_en Dev loss: 0.9135 r:0.5423
ne_en Dev loss: 0.6138 r:0.7077
ru_en Dev loss: 0.4755 r:0.7306
Current avg r:0.5804 Best avg r: 0.6215
06:14:15,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:15:32,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:17:03,174 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1675
en_de Dev loss: 0.9229 r:0.1966
en_zh Dev loss: 0.8498 r:0.4383
ro_en Dev loss: 0.4313 r:0.7955
et_en Dev loss: 0.4344 r:0.6456
si_en Dev loss: 0.9961 r:0.5323
ne_en Dev loss: 0.6684 r:0.7010
ru_en Dev loss: 0.5378 r:0.7076
Current avg r:0.5739 Best avg r: 0.6215
06:20:55,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:22:12,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:42,974 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1818
en_de Dev loss: 0.9004 r:0.1881
en_zh Dev loss: 0.8301 r:0.4427
ro_en Dev loss: 0.4115 r:0.8007
et_en Dev loss: 0.4360 r:0.6451
si_en Dev loss: 1.0625 r:0.5321
ne_en Dev loss: 0.6542 r:0.7166
ru_en Dev loss: 0.4800 r:0.7266
Current avg r:0.5788 Best avg r: 0.6215
06:27:34,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:28:52,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:22,951 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1688
en_de Dev loss: 0.9113 r:0.1772
en_zh Dev loss: 0.8206 r:0.4453
ro_en Dev loss: 0.3758 r:0.8067
et_en Dev loss: 0.4082 r:0.6588
si_en Dev loss: 0.8623 r:0.5505
ne_en Dev loss: 0.5467 r:0.7079
ru_en Dev loss: 0.4924 r:0.7196
Current avg r:0.5809 Best avg r: 0.6215
06:34:14,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:35:32,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:02,704 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1620
en_de Dev loss: 0.9223 r:0.1920
en_zh Dev loss: 0.8521 r:0.4483
ro_en Dev loss: 0.4123 r:0.8022
et_en Dev loss: 0.4367 r:0.6480
si_en Dev loss: 0.9702 r:0.5393
ne_en Dev loss: 0.6390 r:0.7029
ru_en Dev loss: 0.5305 r:0.7127
Current avg r:0.5779 Best avg r: 0.6215
06:40:54,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:42:12,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:43:42,512 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1758
en_de Dev loss: 0.9153 r:0.1744
en_zh Dev loss: 0.8320 r:0.4402
ro_en Dev loss: 0.3978 r:0.7969
et_en Dev loss: 0.4371 r:0.6392
si_en Dev loss: 0.9763 r:0.5234
ne_en Dev loss: 0.7174 r:0.7026
ru_en Dev loss: 0.5068 r:0.7113
Current avg r:0.5697 Best avg r: 0.6215
06:47:34,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:48:52,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:50:22,562 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1665
en_de Dev loss: 0.9030 r:0.1932
en_zh Dev loss: 0.7889 r:0.4582
ro_en Dev loss: 0.3543 r:0.8103
et_en Dev loss: 0.4098 r:0.6571
si_en Dev loss: 0.8445 r:0.5499
ne_en Dev loss: 0.5686 r:0.7121
ru_en Dev loss: 0.4625 r:0.7292
Current avg r:0.5871 Best avg r: 0.6215
06:54:14,791 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:55:32,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:57:02,958 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1698
en_de Dev loss: 0.9086 r:0.1842
en_zh Dev loss: 0.8129 r:0.4530
ro_en Dev loss: 0.3877 r:0.8027
et_en Dev loss: 0.4331 r:0.6402
si_en Dev loss: 0.9405 r:0.5409
ne_en Dev loss: 0.6403 r:0.7140
ru_en Dev loss: 0.4472 r:0.7376
Current avg r:0.5818 Best avg r: 0.6215
07:00:55,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:12,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:03:43,433 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1718
en_de Dev loss: 0.8980 r:0.2078
en_zh Dev loss: 0.8123 r:0.4465
ro_en Dev loss: 0.3530 r:0.8075
et_en Dev loss: 0.4205 r:0.6421
si_en Dev loss: 0.8585 r:0.5473
ne_en Dev loss: 0.4837 r:0.7131
ru_en Dev loss: 0.4435 r:0.7257
Current avg r:0.5843 Best avg r: 0.6215
07:07:35,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:53,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:10:23,730 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1584
en_de Dev loss: 0.8947 r:0.1890
en_zh Dev loss: 0.8015 r:0.4514
ro_en Dev loss: 0.3507 r:0.8056
et_en Dev loss: 0.4064 r:0.6578
si_en Dev loss: 0.8014 r:0.5519
ne_en Dev loss: 0.4832 r:0.7213
ru_en Dev loss: 0.4230 r:0.7421
Current avg r:0.5884 Best avg r: 0.6215
07:14:16,153 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:15:33,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:03,842 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1666
en_de Dev loss: 0.9205 r:0.1820
en_zh Dev loss: 0.7658 r:0.4587
ro_en Dev loss: 0.3714 r:0.8011
et_en Dev loss: 0.4149 r:0.6508
si_en Dev loss: 0.8255 r:0.5436
ne_en Dev loss: 0.5000 r:0.7166
ru_en Dev loss: 0.4433 r:0.7250
Current avg r:0.5825 Best avg r: 0.6215
07:20:57,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:22:14,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:23:45,224 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1499
en_de Dev loss: 0.9359 r:0.1743
en_zh Dev loss: 0.8165 r:0.4602
ro_en Dev loss: 0.3985 r:0.7977
et_en Dev loss: 0.4252 r:0.6426
si_en Dev loss: 0.9598 r:0.5371
ne_en Dev loss: 0.5948 r:0.7060
ru_en Dev loss: 0.4687 r:0.7220
Current avg r:0.5771 Best avg r: 0.6215
07:27:37,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:28:54,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:25,481 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1506
en_de Dev loss: 0.9331 r:0.1867
en_zh Dev loss: 0.8335 r:0.4498
ro_en Dev loss: 0.4170 r:0.8021
et_en Dev loss: 0.4476 r:0.6368
si_en Dev loss: 1.0432 r:0.5340
ne_en Dev loss: 0.6756 r:0.7137
ru_en Dev loss: 0.5063 r:0.7239
Current avg r:0.5781 Best avg r: 0.6215
07:34:17,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:35:35,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:05,769 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1539
en_de Dev loss: 0.9329 r:0.1905
en_zh Dev loss: 0.8436 r:0.4517
ro_en Dev loss: 0.4071 r:0.8007
et_en Dev loss: 0.4475 r:0.6327
si_en Dev loss: 1.0289 r:0.5305
ne_en Dev loss: 0.6552 r:0.7165
ru_en Dev loss: 0.5078 r:0.7151
Current avg r:0.5768 Best avg r: 0.6215
07:40:57,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:42:15,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:43:45,568 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1474
en_de Dev loss: 0.9692 r:0.1848
en_zh Dev loss: 0.8877 r:0.4558
ro_en Dev loss: 0.4232 r:0.8023
et_en Dev loss: 0.4594 r:0.6377
si_en Dev loss: 1.0147 r:0.5422
ne_en Dev loss: 0.6671 r:0.7188
ru_en Dev loss: 0.5806 r:0.7067
Current avg r:0.5783 Best avg r: 0.6215
07:47:37,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:55,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:50:25,397 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1459
en_de Dev loss: 0.9279 r:0.1897
en_zh Dev loss: 0.8192 r:0.4579
ro_en Dev loss: 0.3707 r:0.8036
et_en Dev loss: 0.4208 r:0.6473
si_en Dev loss: 0.8649 r:0.5443
ne_en Dev loss: 0.5642 r:0.7167
ru_en Dev loss: 0.5062 r:0.7163
Current avg r:0.5822 Best avg r: 0.6215
07:54:17,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:55:34,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:57:05,489 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1525
en_de Dev loss: 0.9269 r:0.1853
en_zh Dev loss: 0.7873 r:0.4535
ro_en Dev loss: 0.3600 r:0.8026
et_en Dev loss: 0.4175 r:0.6463
si_en Dev loss: 0.8146 r:0.5486
ne_en Dev loss: 0.5304 r:0.7191
ru_en Dev loss: 0.4351 r:0.7371
Current avg r:0.5846 Best avg r: 0.6215
08:00:57,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:15,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:45,744 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1490
en_de Dev loss: 0.9243 r:0.1814
en_zh Dev loss: 0.7734 r:0.4593
ro_en Dev loss: 0.3719 r:0.8033
et_en Dev loss: 0.4224 r:0.6391
si_en Dev loss: 0.8282 r:0.5441
ne_en Dev loss: 0.5446 r:0.7171
ru_en Dev loss: 0.4504 r:0.7247
Current avg r:0.5813 Best avg r: 0.6215
08:07:37,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:55,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:25,926 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1616
en_de Dev loss: 0.9449 r:0.1832
en_zh Dev loss: 0.8494 r:0.4543
ro_en Dev loss: 0.4000 r:0.8030
et_en Dev loss: 0.4242 r:0.6469
si_en Dev loss: 0.8354 r:0.5551
ne_en Dev loss: 0.5766 r:0.7237
ru_en Dev loss: 0.4601 r:0.7356
Current avg r:0.5859 Best avg r: 0.6215
08:14:17,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:35,408 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:17:05,957 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1499
en_de Dev loss: 0.9582 r:0.1783
en_zh Dev loss: 0.8481 r:0.4496
ro_en Dev loss: 0.3734 r:0.8037
et_en Dev loss: 0.4230 r:0.6466
si_en Dev loss: 0.9363 r:0.5422
ne_en Dev loss: 0.5523 r:0.7237
ru_en Dev loss: 0.4340 r:0.7402
Current avg r:0.5835 Best avg r: 0.6215
08:20:58,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:22:15,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:46,40 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1550
en_de Dev loss: 0.9223 r:0.1767
en_zh Dev loss: 0.7932 r:0.4634
ro_en Dev loss: 0.3647 r:0.8035
et_en Dev loss: 0.4103 r:0.6520
si_en Dev loss: 0.8977 r:0.5432
ne_en Dev loss: 0.5831 r:0.7205
ru_en Dev loss: 0.4274 r:0.7416
Current avg r:0.5858 Best avg r: 0.6215
08:27:38,545 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:55,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:26,620 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1545
en_de Dev loss: 0.9688 r:0.1805
en_zh Dev loss: 0.8486 r:0.4635
ro_en Dev loss: 0.4014 r:0.8047
et_en Dev loss: 0.4305 r:0.6483
si_en Dev loss: 0.9027 r:0.5447
ne_en Dev loss: 0.6116 r:0.7126
ru_en Dev loss: 0.4953 r:0.7257
Current avg r:0.5829 Best avg r: 0.6215
08:34:18,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:36,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:37:07,160 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1580
en_de Dev loss: 0.9311 r:0.1827
en_zh Dev loss: 0.7803 r:0.4687
ro_en Dev loss: 0.3960 r:0.7992
et_en Dev loss: 0.4194 r:0.6489
si_en Dev loss: 0.8676 r:0.5379
ne_en Dev loss: 0.5605 r:0.7123
ru_en Dev loss: 0.4770 r:0.7181
Current avg r:0.5811 Best avg r: 0.6215
08:40:59,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:17,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:47,834 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1403
en_de Dev loss: 0.9259 r:0.1757
en_zh Dev loss: 0.7854 r:0.4690
ro_en Dev loss: 0.3745 r:0.8031
et_en Dev loss: 0.4057 r:0.6567
si_en Dev loss: 0.8833 r:0.5338
ne_en Dev loss: 0.5486 r:0.7182
ru_en Dev loss: 0.4553 r:0.7269
Current avg r:0.5834 Best avg r: 0.6215
08:47:40,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:57,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:50:27,879 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1421
en_de Dev loss: 0.9310 r:0.1797
en_zh Dev loss: 0.8176 r:0.4610
ro_en Dev loss: 0.3708 r:0.8087
et_en Dev loss: 0.4172 r:0.6508
si_en Dev loss: 0.8988 r:0.5382
ne_en Dev loss: 0.5928 r:0.7084
ru_en Dev loss: 0.4823 r:0.7220
Current avg r:0.5813 Best avg r: 0.6215
08:54:20,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:55:37,640 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:57:08,91 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1475
en_de Dev loss: 0.9326 r:0.1761
en_zh Dev loss: 0.8365 r:0.4613
ro_en Dev loss: 0.3811 r:0.8065
et_en Dev loss: 0.4305 r:0.6380
si_en Dev loss: 0.9108 r:0.5435
ne_en Dev loss: 0.6443 r:0.7044
ru_en Dev loss: 0.4883 r:0.7153
Current avg r:0.5779 Best avg r: 0.6215
09:01:01,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:19,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:49,759 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1329
en_de Dev loss: 0.9505 r:0.1824
en_zh Dev loss: 0.8511 r:0.4583
ro_en Dev loss: 0.4006 r:0.8053
et_en Dev loss: 0.4329 r:0.6482
si_en Dev loss: 0.9900 r:0.5354
ne_en Dev loss: 0.6458 r:0.7115
ru_en Dev loss: 0.4842 r:0.7308
Current avg r:0.5817 Best avg r: 0.6215
09:07:41,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:08:59,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:30,203 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1340
en_de Dev loss: 0.9621 r:0.1711
en_zh Dev loss: 0.8262 r:0.4651
ro_en Dev loss: 0.3703 r:0.8075
et_en Dev loss: 0.4254 r:0.6458
si_en Dev loss: 0.8750 r:0.5436
ne_en Dev loss: 0.5928 r:0.7113
ru_en Dev loss: 0.4672 r:0.7393
Current avg r:0.5834 Best avg r: 0.6215
09:14:22,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:40,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:17:10,475 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1360
en_de Dev loss: 0.9532 r:0.1601
en_zh Dev loss: 0.8151 r:0.4607
ro_en Dev loss: 0.3808 r:0.8037
et_en Dev loss: 0.4264 r:0.6441
si_en Dev loss: 0.9381 r:0.5334
ne_en Dev loss: 0.6258 r:0.7123
ru_en Dev loss: 0.4849 r:0.7230
Current avg r:0.5768 Best avg r: 0.6215
09:21:02,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:22:20,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:23:50,714 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1377
en_de Dev loss: 0.9722 r:0.1797
en_zh Dev loss: 0.8708 r:0.4679
ro_en Dev loss: 0.4113 r:0.8046
et_en Dev loss: 0.4416 r:0.6386
si_en Dev loss: 0.9544 r:0.5425
ne_en Dev loss: 0.6584 r:0.7086
ru_en Dev loss: 0.5284 r:0.7114
Current avg r:0.5790 Best avg r: 0.6215
09:27:43,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:29:00,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:30:31,204 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1355
en_de Dev loss: 0.9517 r:0.1625
en_zh Dev loss: 0.8231 r:0.4701
ro_en Dev loss: 0.3926 r:0.8060
et_en Dev loss: 0.4257 r:0.6478
si_en Dev loss: 0.8872 r:0.5531
ne_en Dev loss: 0.6123 r:0.7087
ru_en Dev loss: 0.4851 r:0.7251
Current avg r:0.5819 Best avg r: 0.6215
09:34:23,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:34:49,379 root INFO 
id:en_zh cur r: 0.4813 best r: 0.4813
09:35:41,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:37:11,717 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1334
en_de Dev loss: 0.9160 r:0.1891
en_zh Dev loss: 0.7806 r:0.4781
ro_en Dev loss: 0.3782 r:0.8075
et_en Dev loss: 0.4167 r:0.6546
si_en Dev loss: 0.8952 r:0.5540
ne_en Dev loss: 0.5612 r:0.7152
ru_en Dev loss: 0.4657 r:0.7309
Current avg r:0.5899 Best avg r: 0.6215
09:41:03,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:21,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:51,907 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1346
en_de Dev loss: 0.9364 r:0.1687
en_zh Dev loss: 0.7773 r:0.4743
ro_en Dev loss: 0.3785 r:0.8038
et_en Dev loss: 0.4162 r:0.6514
si_en Dev loss: 0.9348 r:0.5472
ne_en Dev loss: 0.5875 r:0.7127
ru_en Dev loss: 0.4437 r:0.7388
Current avg r:0.5853 Best avg r: 0.6215
09:47:44,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:49:01,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:50:31,994 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1321
en_de Dev loss: 0.9322 r:0.1748
en_zh Dev loss: 0.7988 r:0.4619
ro_en Dev loss: 0.3831 r:0.8007
et_en Dev loss: 0.4196 r:0.6476
si_en Dev loss: 0.8998 r:0.5436
ne_en Dev loss: 0.5368 r:0.7149
ru_en Dev loss: 0.4596 r:0.7291
Current avg r:0.5818 Best avg r: 0.6215
09:54:24,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:41,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:12,33 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1334
en_de Dev loss: 0.9804 r:0.1763
en_zh Dev loss: 0.8485 r:0.4675
ro_en Dev loss: 0.4300 r:0.7972
et_en Dev loss: 0.4599 r:0.6424
si_en Dev loss: 1.0630 r:0.5388
ne_en Dev loss: 0.7011 r:0.7108
ru_en Dev loss: 0.5243 r:0.7161
Current avg r:0.5785 Best avg r: 0.6215
10:01:04,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:21,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:52,387 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1407
en_de Dev loss: 0.9598 r:0.1646
en_zh Dev loss: 0.8086 r:0.4709
ro_en Dev loss: 0.3849 r:0.8032
et_en Dev loss: 0.4177 r:0.6555
si_en Dev loss: 0.8903 r:0.5479
ne_en Dev loss: 0.5806 r:0.7093
ru_en Dev loss: 0.4884 r:0.7193
Current avg r:0.5815 Best avg r: 0.6215
10:07:44,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:09:01,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:31,202 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1307
en_de Dev loss: 0.9378 r:0.1598
en_zh Dev loss: 0.8315 r:0.4608
ro_en Dev loss: 0.3830 r:0.8030
et_en Dev loss: 0.4265 r:0.6470
si_en Dev loss: 0.9587 r:0.5413
ne_en Dev loss: 0.6386 r:0.7042
ru_en Dev loss: 0.5100 r:0.7061
Current avg r:0.5746 Best avg r: 0.6215
10:14:21,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:15:38,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:08,185 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1347
en_de Dev loss: 0.9425 r:0.1571
en_zh Dev loss: 0.7970 r:0.4789
ro_en Dev loss: 0.3851 r:0.8039
et_en Dev loss: 0.4222 r:0.6498
si_en Dev loss: 0.8751 r:0.5465
ne_en Dev loss: 0.5875 r:0.7067
ru_en Dev loss: 0.4702 r:0.7259
Current avg r:0.5813 Best avg r: 0.6215
10:20:58,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:22:15,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:45,97 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1396
en_de Dev loss: 0.9508 r:0.1438
en_zh Dev loss: 0.7865 r:0.4684
ro_en Dev loss: 0.3792 r:0.8045
et_en Dev loss: 0.4171 r:0.6504
si_en Dev loss: 0.8894 r:0.5438
ne_en Dev loss: 0.5963 r:0.7119
ru_en Dev loss: 0.4683 r:0.7164
Current avg r:0.5770 Best avg r: 0.6215
10:27:35,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:52,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:21,907 root INFO Epoch 11 Global steps: 107400 Train loss: 0.1319
en_de Dev loss: 0.9606 r:0.1479
en_zh Dev loss: 0.8066 r:0.4655
ro_en Dev loss: 0.3774 r:0.8056
et_en Dev loss: 0.4145 r:0.6548
si_en Dev loss: 0.9668 r:0.5403
ne_en Dev loss: 0.6119 r:0.7145
ru_en Dev loss: 0.4567 r:0.7305
Current avg r:0.5799 Best avg r: 0.6215
