14:50:48,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:15,62 root INFO 
id:en_zh cur r: 0.0991 best r: 0.0991
14:51:28,476 root INFO 
id:ro_en cur r: 0.4699 best r: 0.4699
14:51:41,947 root INFO 
id:si_en cur r: 0.4382 best r: 0.4382
14:51:55,408 root INFO 
id:ne_en cur r: 0.6068 best r: 0.6068
14:52:08,763 root INFO 
id:ru_en cur r: 0.4813 best r: 0.4813
14:52:08,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:42,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
14:53:42,794 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:53:42,799 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:53:42,804 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
14:53:42,810 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
14:53:42,814 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:53:42,819 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:53:56,314 root INFO Epoch 0 Global steps: 600 Train loss: 0.8562
en_de Dev loss: 0.8882 r:0.0748
en_zh Dev loss: 0.7885 r:0.2291
ro_en Dev loss: 0.6958 r:0.5749
et_en Dev loss: 0.5836 r:0.4817
si_en Dev loss: 0.7160 r:0.4373
ne_en Dev loss: 0.5923 r:0.6202
ru_en Dev loss: 0.6580 r:0.5064
Current avg r:0.4178 Best avg r: 0.4178
14:57:56,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:23,785 root INFO 
id:en_zh cur r: 0.2461 best r: 0.2461
14:58:37,237 root INFO 
id:ro_en cur r: 0.5799 best r: 0.5799
14:59:04,193 root INFO 
id:ne_en cur r: 0.6374 best r: 0.6374
14:59:17,568 root INFO 
id:ru_en cur r: 0.5573 best r: 0.5573
14:59:17,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:51,725 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:00:51,730 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:00:51,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:00:51,742 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:00:51,746 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:00:51,752 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:00:51,756 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:01:05,254 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8217
en_de Dev loss: 0.9047 r:0.0787
en_zh Dev loss: 0.7580 r:0.2746
ro_en Dev loss: 0.6666 r:0.6478
et_en Dev loss: 0.5342 r:0.5438
si_en Dev loss: 0.7891 r:0.4529
ne_en Dev loss: 0.5245 r:0.6487
ru_en Dev loss: 0.6045 r:0.6036
Current avg r:0.4643 Best avg r: 0.4643
15:05:05,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:19,287 root INFO 
id:en_de cur r: 0.0169 best r: 0.0169
15:05:32,704 root INFO 
id:en_zh cur r: 0.3045 best r: 0.3045
15:05:46,149 root INFO 
id:ro_en cur r: 0.6198 best r: 0.6198
15:05:59,642 root INFO 
id:si_en cur r: 0.4741 best r: 0.4741
15:06:13,114 root INFO 
id:ne_en cur r: 0.6596 best r: 0.6596
15:06:26,482 root INFO 
id:ru_en cur r: 0.6012 best r: 0.6012
15:06:26,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:00,647 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:08:00,653 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:08:00,659 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:08:00,663 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:08:00,668 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:08:00,672 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:08:00,677 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:08:14,175 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7134
en_de Dev loss: 0.9309 r:0.1178
en_zh Dev loss: 0.7831 r:0.3081
ro_en Dev loss: 0.6494 r:0.6686
et_en Dev loss: 0.4975 r:0.5825
si_en Dev loss: 0.7385 r:0.4829
ne_en Dev loss: 0.4895 r:0.6655
ru_en Dev loss: 0.6110 r:0.6527
Current avg r:0.4969 Best avg r: 0.4969
15:12:14,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:28,18 root INFO 
id:en_de cur r: 0.1344 best r: 0.1344
15:12:54,882 root INFO 
id:ro_en cur r: 0.6357 best r: 0.6357
15:13:08,363 root INFO 
id:si_en cur r: 0.4892 best r: 0.4892
15:13:21,841 root INFO 
id:ne_en cur r: 0.6654 best r: 0.6654
15:13:35,191 root INFO 
id:ru_en cur r: 0.6647 best r: 0.6647
15:13:35,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:15:09,257 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:15:09,263 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:15:09,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:15:09,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:15:09,278 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:15:09,284 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:15:09,289 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:15:22,780 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7313
en_de Dev loss: 1.0272 r:0.1407
en_zh Dev loss: 0.8674 r:0.3000
ro_en Dev loss: 0.7273 r:0.6746
et_en Dev loss: 0.5443 r:0.6159
si_en Dev loss: 0.8458 r:0.4888
ne_en Dev loss: 0.5369 r:0.6615
ru_en Dev loss: 0.6666 r:0.6928
Current avg r:0.5106 Best avg r: 0.5106
15:19:23,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:36,444 root INFO 
id:en_de cur r: 0.1520 best r: 0.1520
15:19:49,852 root INFO 
id:en_zh cur r: 0.3122 best r: 0.3122
15:20:03,296 root INFO 
id:ro_en cur r: 0.6587 best r: 0.6587
15:20:16,792 root INFO 
id:si_en cur r: 0.5168 best r: 0.5168
15:20:30,260 root INFO 
id:ne_en cur r: 0.6879 best r: 0.6879
15:20:43,610 root INFO 
id:ru_en cur r: 0.6829 best r: 0.6829
15:20:43,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:17,740 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:22:17,745 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:22:17,750 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:22:17,755 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:22:17,762 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:22:17,766 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:22:17,771 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:22:31,245 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7102
en_de Dev loss: 0.9321 r:0.1631
en_zh Dev loss: 0.7978 r:0.3424
ro_en Dev loss: 0.5677 r:0.7039
et_en Dev loss: 0.4418 r:0.6612
si_en Dev loss: 0.6674 r:0.5380
ne_en Dev loss: 0.4468 r:0.6896
ru_en Dev loss: 0.5431 r:0.7132
Current avg r:0.5445 Best avg r: 0.5445
15:26:31,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:44,914 root INFO 
id:en_de cur r: 0.1623 best r: 0.1623
15:26:58,337 root INFO 
id:en_zh cur r: 0.3338 best r: 0.3338
15:27:11,786 root INFO 
id:ro_en cur r: 0.6961 best r: 0.6961
15:27:25,286 root INFO 
id:si_en cur r: 0.5311 best r: 0.5311
15:27:52,119 root INFO 
id:ru_en cur r: 0.7134 best r: 0.7134
15:27:52,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:26,203 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:29:26,209 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:29:26,215 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:29:26,220 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:29:26,225 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:29:26,230 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:29:26,234 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:29:39,706 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6305
en_de Dev loss: 0.9371 r:0.1627
en_zh Dev loss: 0.7722 r:0.3561
ro_en Dev loss: 0.5462 r:0.7258
et_en Dev loss: 0.4366 r:0.6702
si_en Dev loss: 0.7614 r:0.5584
ne_en Dev loss: 0.4592 r:0.6990
ru_en Dev loss: 0.5334 r:0.7292
Current avg r:0.5573 Best avg r: 0.5573
15:33:39,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:06,686 root INFO 
id:en_zh cur r: 0.3447 best r: 0.3447
15:34:20,154 root INFO 
id:ro_en cur r: 0.7073 best r: 0.7073
15:34:33,651 root INFO 
id:si_en cur r: 0.5322 best r: 0.5322
15:34:47,137 root INFO 
id:ne_en cur r: 0.6881 best r: 0.6881
15:35:00,488 root INFO 
id:ru_en cur r: 0.7252 best r: 0.7252
15:35:00,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:34,589 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:36:34,595 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:36:34,600 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:36:34,604 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:36:34,609 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:36:34,616 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:36:34,620 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:36:48,94 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6733
en_de Dev loss: 0.9040 r:0.1638
en_zh Dev loss: 0.7359 r:0.3669
ro_en Dev loss: 0.4854 r:0.7315
et_en Dev loss: 0.4032 r:0.6735
si_en Dev loss: 0.6451 r:0.5550
ne_en Dev loss: 0.4197 r:0.7016
ru_en Dev loss: 0.4711 r:0.7380
Current avg r:0.5615 Best avg r: 0.5615
15:40:48,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:01,743 root INFO 
id:en_de cur r: 0.1641 best r: 0.1641
15:41:15,179 root INFO 
id:en_zh cur r: 0.3659 best r: 0.3659
15:41:28,641 root INFO 
id:ro_en cur r: 0.7367 best r: 0.7367
15:41:42,143 root INFO 
id:si_en cur r: 0.5537 best r: 0.5537
15:41:55,626 root INFO 
id:ne_en cur r: 0.7048 best r: 0.7048
15:42:08,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:43,87 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:43:43,93 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:43:43,99 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:43:43,104 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:43:43,110 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:43:43,115 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:43:43,119 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:43:56,595 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6179
en_de Dev loss: 0.9132 r:0.1682
en_zh Dev loss: 0.7616 r:0.3882
ro_en Dev loss: 0.5342 r:0.7476
et_en Dev loss: 0.4382 r:0.6741
si_en Dev loss: 0.7319 r:0.5684
ne_en Dev loss: 0.5232 r:0.7108
ru_en Dev loss: 0.5344 r:0.7341
Current avg r:0.5702 Best avg r: 0.5702
15:47:56,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:10,208 root INFO 
id:en_de cur r: 0.1715 best r: 0.1715
15:48:23,636 root INFO 
id:en_zh cur r: 0.3861 best r: 0.3861
15:48:37,91 root INFO 
id:ro_en cur r: 0.7460 best r: 0.7460
15:48:50,592 root INFO 
id:si_en cur r: 0.5646 best r: 0.5646
15:49:04,83 root INFO 
id:ne_en cur r: 0.7153 best r: 0.7153
15:49:17,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:51,611 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:50:51,616 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:50:51,622 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:50:51,627 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:50:51,632 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:50:51,636 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:50:51,642 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:51:05,121 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5830
en_de Dev loss: 0.9042 r:0.1902
en_zh Dev loss: 0.7262 r:0.4055
ro_en Dev loss: 0.4772 r:0.7604
et_en Dev loss: 0.4279 r:0.6884
si_en Dev loss: 0.7543 r:0.5815
ne_en Dev loss: 0.4690 r:0.7282
ru_en Dev loss: 0.4995 r:0.7442
Current avg r:0.5855 Best avg r: 0.5855
15:55:05,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:18,806 root INFO 
id:en_de cur r: 0.2187 best r: 0.2187
15:55:32,230 root INFO 
id:en_zh cur r: 0.3981 best r: 0.3981
15:55:45,687 root INFO 
id:ro_en cur r: 0.7589 best r: 0.7589
15:55:59,178 root INFO 
id:si_en cur r: 0.5747 best r: 0.5747
15:56:12,674 root INFO 
id:ne_en cur r: 0.7239 best r: 0.7239
15:56:26,33 root INFO 
id:ru_en cur r: 0.7341 best r: 0.7341
15:56:26,34 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:00,196 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:58:00,202 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:58:00,211 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:58:00,216 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:58:00,221 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:58:00,227 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:58:00,232 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:58:13,722 root INFO Epoch 0 Global steps: 6000 Train loss: 0.6168
en_de Dev loss: 0.8775 r:0.2038
en_zh Dev loss: 0.7041 r:0.4113
ro_en Dev loss: 0.4054 r:0.7635
et_en Dev loss: 0.3738 r:0.6976
si_en Dev loss: 0.6168 r:0.5906
ne_en Dev loss: 0.3730 r:0.7330
ru_en Dev loss: 0.4202 r:0.7517
Current avg r:0.5931 Best avg r: 0.5931
16:02:13,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:02:27,368 root INFO 
id:en_de cur r: 0.2261 best r: 0.2261
16:02:40,782 root INFO 
id:en_zh cur r: 0.4197 best r: 0.4197
16:02:54,224 root INFO 
id:ro_en cur r: 0.7785 best r: 0.7785
16:03:07,719 root INFO 
id:si_en cur r: 0.5981 best r: 0.5981
16:03:21,217 root INFO 
id:ne_en cur r: 0.7464 best r: 0.7464
16:03:34,604 root INFO 
id:ru_en cur r: 0.7549 best r: 0.7549
16:03:34,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:08,820 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
16:05:08,826 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:05:08,835 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:05:08,840 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
16:05:08,846 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
16:05:08,850 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:05:08,855 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:05:22,337 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5859
en_de Dev loss: 0.8908 r:0.2109
en_zh Dev loss: 0.7049 r:0.4287
ro_en Dev loss: 0.3810 r:0.7825
et_en Dev loss: 0.3844 r:0.6985
si_en Dev loss: 0.6277 r:0.6069
ne_en Dev loss: 0.3628 r:0.7524
ru_en Dev loss: 0.4030 r:0.7578
Current avg r:0.6054 Best avg r: 0.6054
16:09:22,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:03,69 root INFO 
id:ro_en cur r: 0.7798 best r: 0.7798
16:10:43,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:17,627 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5765
en_de Dev loss: 0.8976 r:0.2025
en_zh Dev loss: 0.7512 r:0.4086
ro_en Dev loss: 0.4485 r:0.7853
et_en Dev loss: 0.4279 r:0.6909
si_en Dev loss: 0.7962 r:0.5817
ne_en Dev loss: 0.4901 r:0.7243
ru_en Dev loss: 0.5339 r:0.7297
Current avg r:0.5890 Best avg r: 0.6054
16:16:18,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:58,456 root INFO 
id:ro_en cur r: 0.7895 best r: 0.7895
16:17:25,420 root INFO 
id:ne_en cur r: 0.7499 best r: 0.7499
16:17:38,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:12,884 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5638
en_de Dev loss: 0.8682 r:0.2082
en_zh Dev loss: 0.7273 r:0.4091
ro_en Dev loss: 0.3619 r:0.7957
et_en Dev loss: 0.3778 r:0.7097
si_en Dev loss: 0.6383 r:0.6087
ne_en Dev loss: 0.3929 r:0.7537
ru_en Dev loss: 0.4523 r:0.7497
Current avg r:0.6050 Best avg r: 0.6054
16:23:13,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:34,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:08,577 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5588
en_de Dev loss: 0.8819 r:0.1916
en_zh Dev loss: 0.7260 r:0.4098
ro_en Dev loss: 0.3759 r:0.7906
et_en Dev loss: 0.3758 r:0.7047
si_en Dev loss: 0.6934 r:0.5895
ne_en Dev loss: 0.4222 r:0.7483
ru_en Dev loss: 0.4099 r:0.7559
Current avg r:0.5986 Best avg r: 0.6054
16:30:09,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:22,884 root INFO 
id:en_de cur r: 0.2323 best r: 0.2323
16:30:36,325 root INFO 
id:en_zh cur r: 0.4370 best r: 0.4370
16:30:49,804 root INFO 
id:ro_en cur r: 0.8003 best r: 0.8003
16:31:03,310 root INFO 
id:si_en cur r: 0.6040 best r: 0.6040
16:31:16,818 root INFO 
id:ne_en cur r: 0.7586 best r: 0.7586
16:31:30,195 root INFO 
id:ru_en cur r: 0.7608 best r: 0.7608
16:31:30,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:04,409 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
16:33:04,416 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:33:04,422 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:33:04,427 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
16:33:04,439 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
16:33:04,445 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:33:04,453 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:33:17,946 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5290
en_de Dev loss: 0.8526 r:0.2172
en_zh Dev loss: 0.6662 r:0.4401
ro_en Dev loss: 0.3359 r:0.8048
et_en Dev loss: 0.3559 r:0.7109
si_en Dev loss: 0.5574 r:0.6149
ne_en Dev loss: 0.3614 r:0.7618
ru_en Dev loss: 0.3737 r:0.7636
Current avg r:0.6162 Best avg r: 0.6162
16:37:20,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:33,500 root INFO 
id:en_de cur r: 0.2377 best r: 0.2377
16:37:46,945 root INFO 
id:en_zh cur r: 0.4388 best r: 0.4388
16:38:00,421 root INFO 
id:ro_en cur r: 0.8045 best r: 0.8045
16:38:40,803 root INFO 
id:ru_en cur r: 0.7627 best r: 0.7627
16:38:40,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:15,20 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5009
en_de Dev loss: 0.8533 r:0.2217
en_zh Dev loss: 0.6757 r:0.4419
ro_en Dev loss: 0.3619 r:0.8030
et_en Dev loss: 0.3643 r:0.7049
si_en Dev loss: 0.5919 r:0.6106
ne_en Dev loss: 0.3988 r:0.7542
ru_en Dev loss: 0.3694 r:0.7667
Current avg r:0.6147 Best avg r: 0.6162
16:44:15,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:36,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:10,972 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5228
en_de Dev loss: 0.8885 r:0.1999
en_zh Dev loss: 0.7908 r:0.4123
ro_en Dev loss: 0.4079 r:0.8062
et_en Dev loss: 0.4385 r:0.7023
si_en Dev loss: 0.8673 r:0.5953
ne_en Dev loss: 0.5747 r:0.7466
ru_en Dev loss: 0.4644 r:0.7440
Current avg r:0.6010 Best avg r: 0.6162
16:51:11,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:38,660 root INFO 
id:en_zh cur r: 0.4429 best r: 0.4429
16:51:52,155 root INFO 
id:ro_en cur r: 0.8070 best r: 0.8070
16:52:05,669 root INFO 
id:si_en cur r: 0.6068 best r: 0.6068
16:52:19,176 root INFO 
id:ne_en cur r: 0.7636 best r: 0.7636
16:52:32,559 root INFO 
id:ru_en cur r: 0.7708 best r: 0.7708
16:52:32,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:06,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
16:54:06,860 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:54:06,864 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:54:06,869 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
16:54:06,874 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
16:54:06,878 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:54:06,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:54:20,373 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5230
en_de Dev loss: 0.8578 r:0.2097
en_zh Dev loss: 0.7003 r:0.4395
ro_en Dev loss: 0.3268 r:0.8071
et_en Dev loss: 0.3628 r:0.7148
si_en Dev loss: 0.6766 r:0.6103
ne_en Dev loss: 0.3952 r:0.7661
ru_en Dev loss: 0.3616 r:0.7693
Current avg r:0.6167 Best avg r: 0.6167
16:58:20,832 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:01,194 root INFO 
id:ro_en cur r: 0.8122 best r: 0.8122
16:59:41,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:15,843 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4987
en_de Dev loss: 0.8690 r:0.2064
en_zh Dev loss: 0.7509 r:0.4204
ro_en Dev loss: 0.3623 r:0.8131
et_en Dev loss: 0.3787 r:0.7122
si_en Dev loss: 0.6492 r:0.6100
ne_en Dev loss: 0.3866 r:0.7628
ru_en Dev loss: 0.4268 r:0.7485
Current avg r:0.6105 Best avg r: 0.6167
17:05:16,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:10,199 root INFO 
id:si_en cur r: 0.6092 best r: 0.6092
17:06:37,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:11,177 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5164
en_de Dev loss: 0.8478 r:0.2112
en_zh Dev loss: 0.6998 r:0.4409
ro_en Dev loss: 0.3201 r:0.8096
et_en Dev loss: 0.3554 r:0.7089
si_en Dev loss: 0.5919 r:0.6175
ne_en Dev loss: 0.3421 r:0.7640
ru_en Dev loss: 0.3762 r:0.7577
Current avg r:0.6157 Best avg r: 0.6167
17:12:11,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:25,10 root INFO 
id:en_de cur r: 0.2434 best r: 0.2434
17:13:32,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:06,280 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4963
en_de Dev loss: 0.8488 r:0.2140
en_zh Dev loss: 0.7349 r:0.4301
ro_en Dev loss: 0.3414 r:0.8062
et_en Dev loss: 0.3751 r:0.7011
si_en Dev loss: 0.7379 r:0.5948
ne_en Dev loss: 0.4406 r:0.7490
ru_en Dev loss: 0.4035 r:0.7543
Current avg r:0.6071 Best avg r: 0.6167
17:19:06,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:46,923 root INFO 
id:ro_en cur r: 0.8138 best r: 0.8138
17:20:13,852 root INFO 
id:ne_en cur r: 0.7649 best r: 0.7649
17:20:27,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:01,292 root INFO Epoch 1 Global steps: 13200 Train loss: 0.5251
en_de Dev loss: 0.8638 r:0.2089
en_zh Dev loss: 0.7184 r:0.4432
ro_en Dev loss: 0.3331 r:0.8159
et_en Dev loss: 0.3627 r:0.7053
si_en Dev loss: 0.6087 r:0.6125
ne_en Dev loss: 0.3596 r:0.7681
ru_en Dev loss: 0.3976 r:0.7557
Current avg r:0.6157 Best avg r: 0.6167
17:26:01,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:42,23 root INFO 
id:ro_en cur r: 0.8169 best r: 0.8169
17:27:22,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:56,454 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4658
en_de Dev loss: 0.8619 r:0.2071
en_zh Dev loss: 0.7250 r:0.4433
ro_en Dev loss: 0.3511 r:0.8150
et_en Dev loss: 0.3617 r:0.7042
si_en Dev loss: 0.6172 r:0.6098
ne_en Dev loss: 0.3699 r:0.7589
ru_en Dev loss: 0.4030 r:0.7543
Current avg r:0.6132 Best avg r: 0.6167
17:32:56,895 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:23,798 root INFO 
id:en_zh cur r: 0.4734 best r: 0.4734
17:33:37,264 root INFO 
id:ro_en cur r: 0.8234 best r: 0.8234
17:33:50,756 root INFO 
id:si_en cur r: 0.6208 best r: 0.6208
17:34:04,248 root INFO 
id:ne_en cur r: 0.7693 best r: 0.7693
17:34:17,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:51,711 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
17:35:51,718 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:35:51,724 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:35:51,732 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
17:35:51,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
17:35:51,744 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:35:51,748 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:36:05,245 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4880
en_de Dev loss: 0.8482 r:0.2168
en_zh Dev loss: 0.6441 r:0.4726
ro_en Dev loss: 0.2957 r:0.8217
et_en Dev loss: 0.3497 r:0.7160
si_en Dev loss: 0.5848 r:0.6229
ne_en Dev loss: 0.3416 r:0.7712
ru_en Dev loss: 0.3650 r:0.7679
Current avg r:0.6270 Best avg r: 0.6270
17:40:05,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:26,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:00,556 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4557
en_de Dev loss: 0.8562 r:0.2304
en_zh Dev loss: 0.6883 r:0.4527
ro_en Dev loss: 0.2962 r:0.8203
et_en Dev loss: 0.3664 r:0.7101
si_en Dev loss: 0.6304 r:0.6168
ne_en Dev loss: 0.3805 r:0.7702
ru_en Dev loss: 0.4131 r:0.7541
Current avg r:0.6221 Best avg r: 0.6270
17:47:00,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:14,391 root INFO 
id:en_de cur r: 0.2486 best r: 0.2486
17:47:41,287 root INFO 
id:ro_en cur r: 0.8322 best r: 0.8322
17:47:54,794 root INFO 
id:si_en cur r: 0.6216 best r: 0.6216
17:48:08,286 root INFO 
id:ne_en cur r: 0.7699 best r: 0.7699
17:48:21,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:55,765 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
17:49:55,772 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:49:55,778 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:49:55,783 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
17:49:55,787 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
17:49:55,795 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:49:55,799 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:50:09,275 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4921
en_de Dev loss: 0.8487 r:0.2194
en_zh Dev loss: 0.6811 r:0.4622
ro_en Dev loss: 0.2737 r:0.8293
et_en Dev loss: 0.3601 r:0.7141
si_en Dev loss: 0.5902 r:0.6274
ne_en Dev loss: 0.3868 r:0.7732
ru_en Dev loss: 0.3745 r:0.7690
Current avg r:0.6278 Best avg r: 0.6278
17:54:09,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:30,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:04,367 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4743
en_de Dev loss: 0.8712 r:0.2262
en_zh Dev loss: 0.7548 r:0.4492
ro_en Dev loss: 0.3636 r:0.8166
et_en Dev loss: 0.4096 r:0.7001
si_en Dev loss: 0.8347 r:0.6023
ne_en Dev loss: 0.4780 r:0.7648
ru_en Dev loss: 0.4281 r:0.7568
Current avg r:0.6166 Best avg r: 0.6278
18:01:04,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:25,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:59,459 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4957
en_de Dev loss: 0.8611 r:0.2201
en_zh Dev loss: 0.7359 r:0.4414
ro_en Dev loss: 0.3274 r:0.8149
et_en Dev loss: 0.3851 r:0.6944
si_en Dev loss: 0.6644 r:0.5990
ne_en Dev loss: 0.4019 r:0.7608
ru_en Dev loss: 0.4648 r:0.7173
Current avg r:0.6068 Best avg r: 0.6278
18:07:59,791 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:20,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:54,415 root INFO Epoch 1 Global steps: 17400 Train loss: 0.5163
en_de Dev loss: 0.8481 r:0.2117
en_zh Dev loss: 0.7185 r:0.4453
ro_en Dev loss: 0.3119 r:0.8182
et_en Dev loss: 0.3626 r:0.7063
si_en Dev loss: 0.6462 r:0.6110
ne_en Dev loss: 0.4035 r:0.7639
ru_en Dev loss: 0.4449 r:0.7314
Current avg r:0.6125 Best avg r: 0.6278
18:14:54,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:01,769 root INFO 
id:ne_en cur r: 0.7731 best r: 0.7731
18:16:15,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:49,225 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4819
en_de Dev loss: 0.8398 r:0.2305
en_zh Dev loss: 0.6586 r:0.4671
ro_en Dev loss: 0.2816 r:0.8267
et_en Dev loss: 0.3589 r:0.7051
si_en Dev loss: 0.6000 r:0.6194
ne_en Dev loss: 0.3359 r:0.7754
ru_en Dev loss: 0.3842 r:0.7451
Current avg r:0.6242 Best avg r: 0.6278
18:21:50,717 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:04,125 root INFO 
id:en_de cur r: 0.2566 best r: 0.2566
18:23:11,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:45,329 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4616
en_de Dev loss: 0.8397 r:0.2464
en_zh Dev loss: 0.7284 r:0.4480
ro_en Dev loss: 0.3111 r:0.8211
et_en Dev loss: 0.3655 r:0.6993
si_en Dev loss: 0.6453 r:0.6062
ne_en Dev loss: 0.3418 r:0.7734
ru_en Dev loss: 0.3861 r:0.7500
Current avg r:0.6206 Best avg r: 0.6278
18:28:45,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:06,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:40,85 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4381
en_de Dev loss: 0.8575 r:0.2515
en_zh Dev loss: 0.7619 r:0.4551
ro_en Dev loss: 0.3507 r:0.8201
et_en Dev loss: 0.3766 r:0.7043
si_en Dev loss: 0.7390 r:0.6136
ne_en Dev loss: 0.3907 r:0.7683
ru_en Dev loss: 0.4474 r:0.7474
Current avg r:0.6229 Best avg r: 0.6278
18:35:40,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:37:00,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:34,917 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4507
en_de Dev loss: 0.8541 r:0.2287
en_zh Dev loss: 0.7733 r:0.4470
ro_en Dev loss: 0.3633 r:0.8201
et_en Dev loss: 0.4034 r:0.6919
si_en Dev loss: 0.8303 r:0.6018
ne_en Dev loss: 0.5487 r:0.7643
ru_en Dev loss: 0.4445 r:0.7371
Current avg r:0.6130 Best avg r: 0.6278
18:42:35,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:55,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:29,773 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4324
en_de Dev loss: 0.8511 r:0.2450
en_zh Dev loss: 0.7265 r:0.4423
ro_en Dev loss: 0.3092 r:0.8201
et_en Dev loss: 0.3615 r:0.7002
si_en Dev loss: 0.6624 r:0.6077
ne_en Dev loss: 0.3794 r:0.7688
ru_en Dev loss: 0.3992 r:0.7452
Current avg r:0.6185 Best avg r: 0.6278
18:49:30,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:56,937 root INFO 
id:en_zh cur r: 0.4786 best r: 0.4786
18:50:50,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:24,710 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4428
en_de Dev loss: 0.8544 r:0.2333
en_zh Dev loss: 0.6860 r:0.4689
ro_en Dev loss: 0.3242 r:0.8237
et_en Dev loss: 0.3578 r:0.7062
si_en Dev loss: 0.6382 r:0.6176
ne_en Dev loss: 0.3485 r:0.7747
ru_en Dev loss: 0.4087 r:0.7534
Current avg r:0.6254 Best avg r: 0.6278
18:56:24,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:38,386 root INFO 
id:en_de cur r: 0.2675 best r: 0.2675
18:57:45,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:19,555 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4387
en_de Dev loss: 0.8357 r:0.2498
en_zh Dev loss: 0.7029 r:0.4587
ro_en Dev loss: 0.3176 r:0.8195
et_en Dev loss: 0.3583 r:0.7037
si_en Dev loss: 0.6552 r:0.6179
ne_en Dev loss: 0.3596 r:0.7740
ru_en Dev loss: 0.4043 r:0.7453
Current avg r:0.6241 Best avg r: 0.6278
19:03:19,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:40,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:14,376 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4007
en_de Dev loss: 0.8479 r:0.2517
en_zh Dev loss: 0.7457 r:0.4422
ro_en Dev loss: 0.3336 r:0.8167
et_en Dev loss: 0.3756 r:0.6982
si_en Dev loss: 0.7484 r:0.6019
ne_en Dev loss: 0.4212 r:0.7621
ru_en Dev loss: 0.4322 r:0.7412
Current avg r:0.6163 Best avg r: 0.6278
19:10:14,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:35,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:09,157 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4395
en_de Dev loss: 0.8413 r:0.2475
en_zh Dev loss: 0.7330 r:0.4378
ro_en Dev loss: 0.3295 r:0.8158
et_en Dev loss: 0.3785 r:0.6900
si_en Dev loss: 0.7638 r:0.5953
ne_en Dev loss: 0.4449 r:0.7647
ru_en Dev loss: 0.4484 r:0.7269
Current avg r:0.6112 Best avg r: 0.6278
19:17:09,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:29,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:03,778 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4430
en_de Dev loss: 0.8637 r:0.2140
en_zh Dev loss: 0.7087 r:0.4531
ro_en Dev loss: 0.3465 r:0.8192
et_en Dev loss: 0.3857 r:0.6881
si_en Dev loss: 0.7858 r:0.6026
ne_en Dev loss: 0.4810 r:0.7662
ru_en Dev loss: 0.4398 r:0.7360
Current avg r:0.6113 Best avg r: 0.6278
19:24:03,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:44,239 root INFO 
id:ro_en cur r: 0.8359 best r: 0.8359
19:25:11,172 root INFO 
id:ne_en cur r: 0.7767 best r: 0.7767
19:25:24,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:58,581 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4309
en_de Dev loss: 0.8658 r:0.2003
en_zh Dev loss: 0.6640 r:0.4698
ro_en Dev loss: 0.2725 r:0.8316
et_en Dev loss: 0.3561 r:0.7071
si_en Dev loss: 0.6133 r:0.6136
ne_en Dev loss: 0.3343 r:0.7758
ru_en Dev loss: 0.3580 r:0.7595
Current avg r:0.6225 Best avg r: 0.6278
19:30:58,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:19,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:53,591 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4307
en_de Dev loss: 0.8532 r:0.2209
en_zh Dev loss: 0.7256 r:0.4510
ro_en Dev loss: 0.3136 r:0.8251
et_en Dev loss: 0.3670 r:0.6942
si_en Dev loss: 0.7017 r:0.5993
ne_en Dev loss: 0.4003 r:0.7618
ru_en Dev loss: 0.4667 r:0.7216
Current avg r:0.6106 Best avg r: 0.6278
19:37:54,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:14,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:48,936 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4211
en_de Dev loss: 0.8492 r:0.2365
en_zh Dev loss: 0.7023 r:0.4671
ro_en Dev loss: 0.3440 r:0.8216
et_en Dev loss: 0.3914 r:0.6969
si_en Dev loss: 0.8424 r:0.5978
ne_en Dev loss: 0.5276 r:0.7612
ru_en Dev loss: 0.4928 r:0.7271
Current avg r:0.6154 Best avg r: 0.6278
19:44:49,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:10,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:44,757 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4150
en_de Dev loss: 0.8706 r:0.2118
en_zh Dev loss: 0.6879 r:0.4746
ro_en Dev loss: 0.3233 r:0.8272
et_en Dev loss: 0.3664 r:0.7032
si_en Dev loss: 0.6765 r:0.6169
ne_en Dev loss: 0.4020 r:0.7689
ru_en Dev loss: 0.4030 r:0.7535
Current avg r:0.6223 Best avg r: 0.6278
19:51:45,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:06,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:40,626 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4517
en_de Dev loss: 0.8727 r:0.2116
en_zh Dev loss: 0.7387 r:0.4548
ro_en Dev loss: 0.3165 r:0.8252
et_en Dev loss: 0.3568 r:0.7043
si_en Dev loss: 0.6397 r:0.6079
ne_en Dev loss: 0.3911 r:0.7641
ru_en Dev loss: 0.4183 r:0.7400
Current avg r:0.6154 Best avg r: 0.6278
19:58:41,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:02,267 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:01:36,499 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4111
en_de Dev loss: 0.8722 r:0.2366
en_zh Dev loss: 0.7231 r:0.4639
ro_en Dev loss: 0.3263 r:0.8237
et_en Dev loss: 0.3740 r:0.6975
si_en Dev loss: 0.7533 r:0.5970
ne_en Dev loss: 0.4338 r:0.7625
ru_en Dev loss: 0.4264 r:0.7404
Current avg r:0.6174 Best avg r: 0.6278
20:05:38,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:59,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:33,416 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3907
en_de Dev loss: 0.8638 r:0.2229
en_zh Dev loss: 0.7104 r:0.4614
ro_en Dev loss: 0.3091 r:0.8265
et_en Dev loss: 0.3686 r:0.6998
si_en Dev loss: 0.7055 r:0.6038
ne_en Dev loss: 0.4629 r:0.7622
ru_en Dev loss: 0.4205 r:0.7366
Current avg r:0.6162 Best avg r: 0.6278
20:12:34,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:01,258 root INFO 
id:en_zh cur r: 0.4855 best r: 0.4855
20:13:55,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:29,408 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3898
en_de Dev loss: 0.8463 r:0.2424
en_zh Dev loss: 0.7000 r:0.4771
ro_en Dev loss: 0.3076 r:0.8308
et_en Dev loss: 0.3633 r:0.6982
si_en Dev loss: 0.6463 r:0.6083
ne_en Dev loss: 0.3704 r:0.7630
ru_en Dev loss: 0.4178 r:0.7411
Current avg r:0.6230 Best avg r: 0.6278
20:19:30,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:51,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:25,406 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3895
en_de Dev loss: 0.8569 r:0.2284
en_zh Dev loss: 0.7008 r:0.4712
ro_en Dev loss: 0.3158 r:0.8268
et_en Dev loss: 0.3695 r:0.6933
si_en Dev loss: 0.6283 r:0.6081
ne_en Dev loss: 0.3497 r:0.7620
ru_en Dev loss: 0.4086 r:0.7433
Current avg r:0.6190 Best avg r: 0.6278
20:26:26,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:46,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:21,201 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3683
en_de Dev loss: 0.8562 r:0.2225
en_zh Dev loss: 0.7788 r:0.4420
ro_en Dev loss: 0.3287 r:0.8269
et_en Dev loss: 0.3850 r:0.6925
si_en Dev loss: 0.7971 r:0.6013
ne_en Dev loss: 0.5207 r:0.7603
ru_en Dev loss: 0.4559 r:0.7310
Current avg r:0.6109 Best avg r: 0.6278
20:33:22,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:42,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:17,91 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3850
en_de Dev loss: 0.8510 r:0.2202
en_zh Dev loss: 0.7261 r:0.4445
ro_en Dev loss: 0.3345 r:0.8147
et_en Dev loss: 0.3918 r:0.6766
si_en Dev loss: 0.8006 r:0.5856
ne_en Dev loss: 0.4931 r:0.7510
ru_en Dev loss: 0.4898 r:0.6975
Current avg r:0.5986 Best avg r: 0.6278
20:40:18,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:38,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:13,57 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3971
en_de Dev loss: 0.8446 r:0.2235
en_zh Dev loss: 0.6911 r:0.4581
ro_en Dev loss: 0.2937 r:0.8213
et_en Dev loss: 0.3708 r:0.6906
si_en Dev loss: 0.6626 r:0.6018
ne_en Dev loss: 0.3672 r:0.7589
ru_en Dev loss: 0.4087 r:0.7313
Current avg r:0.6122 Best avg r: 0.6278
20:47:14,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:34,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:09,57 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3711
en_de Dev loss: 0.8606 r:0.2261
en_zh Dev loss: 0.7454 r:0.4469
ro_en Dev loss: 0.3029 r:0.8251
et_en Dev loss: 0.3667 r:0.6964
si_en Dev loss: 0.6707 r:0.6071
ne_en Dev loss: 0.3901 r:0.7608
ru_en Dev loss: 0.4275 r:0.7375
Current avg r:0.6143 Best avg r: 0.6278
20:54:09,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:30,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:57:04,882 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3627
en_de Dev loss: 0.8775 r:0.2147
en_zh Dev loss: 0.7775 r:0.4408
ro_en Dev loss: 0.3429 r:0.8223
et_en Dev loss: 0.3809 r:0.6909
si_en Dev loss: 0.7422 r:0.5955
ne_en Dev loss: 0.4655 r:0.7606
ru_en Dev loss: 0.4982 r:0.7144
Current avg r:0.6056 Best avg r: 0.6278
21:01:05,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:26,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:00,439 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3837
en_de Dev loss: 0.8596 r:0.2166
en_zh Dev loss: 0.7194 r:0.4674
ro_en Dev loss: 0.3208 r:0.8236
et_en Dev loss: 0.3882 r:0.6820
si_en Dev loss: 0.7624 r:0.6005
ne_en Dev loss: 0.4450 r:0.7550
ru_en Dev loss: 0.4335 r:0.7324
Current avg r:0.6111 Best avg r: 0.6278
21:08:00,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:21,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:55,967 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3680
en_de Dev loss: 0.8810 r:0.1896
en_zh Dev loss: 0.7182 r:0.4671
ro_en Dev loss: 0.3254 r:0.8219
et_en Dev loss: 0.3899 r:0.6868
si_en Dev loss: 0.8353 r:0.5929
ne_en Dev loss: 0.4906 r:0.7526
ru_en Dev loss: 0.4670 r:0.7251
Current avg r:0.6051 Best avg r: 0.6278
21:14:56,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:17,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:51,872 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3610
en_de Dev loss: 0.8810 r:0.2090
en_zh Dev loss: 0.7525 r:0.4415
ro_en Dev loss: 0.3097 r:0.8238
et_en Dev loss: 0.3740 r:0.6909
si_en Dev loss: 0.6840 r:0.6079
ne_en Dev loss: 0.3897 r:0.7553
ru_en Dev loss: 0.4603 r:0.7186
Current avg r:0.6067 Best avg r: 0.6278
21:21:52,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:13,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:48,149 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3659
en_de Dev loss: 0.8682 r:0.2127
en_zh Dev loss: 0.7260 r:0.4524
ro_en Dev loss: 0.2978 r:0.8277
et_en Dev loss: 0.3751 r:0.6903
si_en Dev loss: 0.6766 r:0.6110
ne_en Dev loss: 0.4198 r:0.7601
ru_en Dev loss: 0.4416 r:0.7291
Current avg r:0.6119 Best avg r: 0.6278
21:28:49,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:10,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:44,382 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3630
en_de Dev loss: 0.8454 r:0.2463
en_zh Dev loss: 0.7273 r:0.4499
ro_en Dev loss: 0.3002 r:0.8246
et_en Dev loss: 0.3645 r:0.6966
si_en Dev loss: 0.6786 r:0.6057
ne_en Dev loss: 0.4204 r:0.7524
ru_en Dev loss: 0.4104 r:0.7407
Current avg r:0.6166 Best avg r: 0.6278
21:35:45,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:06,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:40,714 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3723
en_de Dev loss: 0.8562 r:0.2343
en_zh Dev loss: 0.7680 r:0.4463
ro_en Dev loss: 0.3129 r:0.8241
et_en Dev loss: 0.3838 r:0.6877
si_en Dev loss: 0.7900 r:0.5939
ne_en Dev loss: 0.5123 r:0.7565
ru_en Dev loss: 0.4557 r:0.7238
Current avg r:0.6095 Best avg r: 0.6278
21:42:41,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:02,754 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:37,96 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3494
en_de Dev loss: 0.8808 r:0.2237
en_zh Dev loss: 0.7693 r:0.4676
ro_en Dev loss: 0.3398 r:0.8303
et_en Dev loss: 0.4038 r:0.6925
si_en Dev loss: 0.8690 r:0.5960
ne_en Dev loss: 0.5043 r:0.7581
ru_en Dev loss: 0.4939 r:0.7309
Current avg r:0.6141 Best avg r: 0.6278
21:49:39,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:00,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:34,707 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3201
en_de Dev loss: 0.8629 r:0.2303
en_zh Dev loss: 0.7539 r:0.4568
ro_en Dev loss: 0.3417 r:0.8186
et_en Dev loss: 0.3921 r:0.6823
si_en Dev loss: 0.7707 r:0.5936
ne_en Dev loss: 0.4482 r:0.7598
ru_en Dev loss: 0.4563 r:0.7292
Current avg r:0.6101 Best avg r: 0.6278
21:56:35,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:56,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:31,69 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3197
en_de Dev loss: 0.8446 r:0.2402
en_zh Dev loss: 0.7327 r:0.4610
ro_en Dev loss: 0.3099 r:0.8250
et_en Dev loss: 0.3720 r:0.6912
si_en Dev loss: 0.6607 r:0.6031
ne_en Dev loss: 0.3941 r:0.7621
ru_en Dev loss: 0.4415 r:0.7332
Current avg r:0.6165 Best avg r: 0.6278
22:03:32,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:53,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:27,506 root INFO Epoch 4 Global steps: 37800 Train loss: 0.2926
en_de Dev loss: 0.8542 r:0.2392
en_zh Dev loss: 0.7729 r:0.4540
ro_en Dev loss: 0.3441 r:0.8203
et_en Dev loss: 0.3945 r:0.6808
si_en Dev loss: 0.8047 r:0.5892
ne_en Dev loss: 0.4508 r:0.7572
ru_en Dev loss: 0.4626 r:0.7307
Current avg r:0.6102 Best avg r: 0.6278
22:10:28,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:49,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:23,807 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3245
en_de Dev loss: 0.8424 r:0.2352
en_zh Dev loss: 0.7335 r:0.4595
ro_en Dev loss: 0.3030 r:0.8264
et_en Dev loss: 0.3743 r:0.6887
si_en Dev loss: 0.7255 r:0.5977
ne_en Dev loss: 0.4205 r:0.7618
ru_en Dev loss: 0.4343 r:0.7361
Current avg r:0.6150 Best avg r: 0.6278
22:17:25,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:45,911 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:20,221 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3223
en_de Dev loss: 0.8400 r:0.2704
en_zh Dev loss: 0.7812 r:0.4464
ro_en Dev loss: 0.3695 r:0.8146
et_en Dev loss: 0.4242 r:0.6615
si_en Dev loss: 0.8125 r:0.5798
ne_en Dev loss: 0.5500 r:0.7568
ru_en Dev loss: 0.4978 r:0.7052
Current avg r:0.6050 Best avg r: 0.6278
22:24:21,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:42,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:16,606 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3148
en_de Dev loss: 0.8423 r:0.2512
en_zh Dev loss: 0.7416 r:0.4589
ro_en Dev loss: 0.3029 r:0.8293
et_en Dev loss: 0.3773 r:0.6857
si_en Dev loss: 0.6626 r:0.6011
ne_en Dev loss: 0.3863 r:0.7601
ru_en Dev loss: 0.4375 r:0.7309
Current avg r:0.6167 Best avg r: 0.6278
22:31:17,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:38,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:12,997 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3138
en_de Dev loss: 0.8650 r:0.2263
en_zh Dev loss: 0.7691 r:0.4563
ro_en Dev loss: 0.3479 r:0.8243
et_en Dev loss: 0.3933 r:0.6841
si_en Dev loss: 0.7582 r:0.5962
ne_en Dev loss: 0.4447 r:0.7575
ru_en Dev loss: 0.4872 r:0.7112
Current avg r:0.6080 Best avg r: 0.6278
22:38:13,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:39:34,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:08,981 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3222
en_de Dev loss: 0.8750 r:0.2125
en_zh Dev loss: 0.7722 r:0.4463
ro_en Dev loss: 0.3507 r:0.8212
et_en Dev loss: 0.3922 r:0.6793
si_en Dev loss: 0.7804 r:0.5959
ne_en Dev loss: 0.4746 r:0.7559
ru_en Dev loss: 0.4630 r:0.7136
Current avg r:0.6035 Best avg r: 0.6278
22:45:10,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:30,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:48:05,247 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3143
en_de Dev loss: 0.8699 r:0.2026
en_zh Dev loss: 0.7432 r:0.4508
ro_en Dev loss: 0.3265 r:0.8227
et_en Dev loss: 0.3814 r:0.6822
si_en Dev loss: 0.7282 r:0.5978
ne_en Dev loss: 0.4085 r:0.7577
ru_en Dev loss: 0.4242 r:0.7284
Current avg r:0.6060 Best avg r: 0.6278
22:52:06,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:27,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:01,376 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3230
en_de Dev loss: 0.8860 r:0.2006
en_zh Dev loss: 0.7849 r:0.4501
ro_en Dev loss: 0.3650 r:0.8166
et_en Dev loss: 0.3991 r:0.6758
si_en Dev loss: 0.8384 r:0.5887
ne_en Dev loss: 0.5002 r:0.7566
ru_en Dev loss: 0.4153 r:0.7457
Current avg r:0.6049 Best avg r: 0.6278
22:59:02,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:00:22,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:57,78 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3193
en_de Dev loss: 0.8805 r:0.1869
en_zh Dev loss: 0.7576 r:0.4465
ro_en Dev loss: 0.3221 r:0.8207
et_en Dev loss: 0.3816 r:0.6846
si_en Dev loss: 0.7607 r:0.5887
ne_en Dev loss: 0.4232 r:0.7554
ru_en Dev loss: 0.4568 r:0.7143
Current avg r:0.5996 Best avg r: 0.6278
23:05:57,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:18,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:52,785 root INFO Epoch 4 Global steps: 43200 Train loss: 0.2858
en_de Dev loss: 0.9050 r:0.1818
en_zh Dev loss: 0.7990 r:0.4352
ro_en Dev loss: 0.3557 r:0.8193
et_en Dev loss: 0.3982 r:0.6821
si_en Dev loss: 0.9320 r:0.5775
ne_en Dev loss: 0.4885 r:0.7528
ru_en Dev loss: 0.5075 r:0.7060
Current avg r:0.5935 Best avg r: 0.6278
23:12:53,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:14,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:48,388 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3015
en_de Dev loss: 0.8708 r:0.2043
en_zh Dev loss: 0.7204 r:0.4668
ro_en Dev loss: 0.3168 r:0.8242
et_en Dev loss: 0.3696 r:0.6959
si_en Dev loss: 0.6964 r:0.5943
ne_en Dev loss: 0.4076 r:0.7508
ru_en Dev loss: 0.4179 r:0.7396
Current avg r:0.6108 Best avg r: 0.6278
23:19:49,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:09,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:43,978 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3146
en_de Dev loss: 0.8898 r:0.1880
en_zh Dev loss: 0.8040 r:0.4403
ro_en Dev loss: 0.3378 r:0.8212
et_en Dev loss: 0.4003 r:0.6785
si_en Dev loss: 0.8534 r:0.5771
ne_en Dev loss: 0.5051 r:0.7471
ru_en Dev loss: 0.5076 r:0.7025
Current avg r:0.5935 Best avg r: 0.6278
23:26:44,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:05,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:39,474 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3265
en_de Dev loss: 0.8745 r:0.2094
en_zh Dev loss: 0.7791 r:0.4351
ro_en Dev loss: 0.3375 r:0.8262
et_en Dev loss: 0.3805 r:0.6871
si_en Dev loss: 0.7495 r:0.5789
ne_en Dev loss: 0.4013 r:0.7530
ru_en Dev loss: 0.4401 r:0.7314
Current avg r:0.6030 Best avg r: 0.6278
23:33:41,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:02,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:36,285 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2595
en_de Dev loss: 0.8772 r:0.1943
en_zh Dev loss: 0.7694 r:0.4384
ro_en Dev loss: 0.3239 r:0.8244
et_en Dev loss: 0.3844 r:0.6870
si_en Dev loss: 0.7055 r:0.5830
ne_en Dev loss: 0.3988 r:0.7465
ru_en Dev loss: 0.4488 r:0.7236
Current avg r:0.5996 Best avg r: 0.6278
23:40:37,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:58,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:32,380 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2725
en_de Dev loss: 0.8744 r:0.1922
en_zh Dev loss: 0.8286 r:0.4230
ro_en Dev loss: 0.3446 r:0.8237
et_en Dev loss: 0.3994 r:0.6821
si_en Dev loss: 0.8581 r:0.5751
ne_en Dev loss: 0.5223 r:0.7460
ru_en Dev loss: 0.5088 r:0.7054
Current avg r:0.5925 Best avg r: 0.6278
23:47:33,613 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:54,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:28,821 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2705
en_de Dev loss: 0.8604 r:0.2088
en_zh Dev loss: 0.7234 r:0.4482
ro_en Dev loss: 0.2885 r:0.8313
et_en Dev loss: 0.3785 r:0.6882
si_en Dev loss: 0.7198 r:0.5812
ne_en Dev loss: 0.4085 r:0.7501
ru_en Dev loss: 0.3974 r:0.7406
Current avg r:0.6069 Best avg r: 0.6278
23:54:30,105 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:50,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:25,294 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2700
en_de Dev loss: 0.8948 r:0.1883
en_zh Dev loss: 0.7768 r:0.4646
ro_en Dev loss: 0.3464 r:0.8261
et_en Dev loss: 0.4088 r:0.6788
si_en Dev loss: 0.8812 r:0.5719
ne_en Dev loss: 0.5021 r:0.7452
ru_en Dev loss: 0.4680 r:0.7336
Current avg r:0.6012 Best avg r: 0.6278
00:01:26,434 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:47,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:21,592 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2659
en_de Dev loss: 0.9061 r:0.2002
en_zh Dev loss: 0.7963 r:0.4634
ro_en Dev loss: 0.3754 r:0.8213
et_en Dev loss: 0.4234 r:0.6696
si_en Dev loss: 0.9283 r:0.5653
ne_en Dev loss: 0.5165 r:0.7443
ru_en Dev loss: 0.4912 r:0.7239
Current avg r:0.5983 Best avg r: 0.6278
00:08:22,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:43,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:18,12 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2545
en_de Dev loss: 0.8762 r:0.2043
en_zh Dev loss: 0.7450 r:0.4740
ro_en Dev loss: 0.3340 r:0.8235
et_en Dev loss: 0.4042 r:0.6700
si_en Dev loss: 0.8326 r:0.5686
ne_en Dev loss: 0.4948 r:0.7462
ru_en Dev loss: 0.4501 r:0.7273
Current avg r:0.6020 Best avg r: 0.6278
00:15:19,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:16:40,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:18:14,382 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2599
en_de Dev loss: 0.8726 r:0.2030
en_zh Dev loss: 0.7305 r:0.4632
ro_en Dev loss: 0.3121 r:0.8237
et_en Dev loss: 0.3857 r:0.6793
si_en Dev loss: 0.7494 r:0.5726
ne_en Dev loss: 0.4286 r:0.7505
ru_en Dev loss: 0.4105 r:0.7423
Current avg r:0.6050 Best avg r: 0.6278
00:22:15,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:36,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:10,702 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2690
en_de Dev loss: 0.8732 r:0.1979
en_zh Dev loss: 0.7483 r:0.4638
ro_en Dev loss: 0.3059 r:0.8262
et_en Dev loss: 0.3914 r:0.6776
si_en Dev loss: 0.7073 r:0.5746
ne_en Dev loss: 0.3998 r:0.7456
ru_en Dev loss: 0.4239 r:0.7275
Current avg r:0.6019 Best avg r: 0.6278
00:29:11,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:30:32,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:06,790 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2706
en_de Dev loss: 0.9078 r:0.1907
en_zh Dev loss: 0.7771 r:0.4573
ro_en Dev loss: 0.3329 r:0.8257
et_en Dev loss: 0.4075 r:0.6733
si_en Dev loss: 0.8261 r:0.5670
ne_en Dev loss: 0.4411 r:0.7403
ru_en Dev loss: 0.4307 r:0.7383
Current avg r:0.5989 Best avg r: 0.6278
00:36:07,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:28,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:02,707 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2810
en_de Dev loss: 0.8856 r:0.1982
en_zh Dev loss: 0.7647 r:0.4631
ro_en Dev loss: 0.3477 r:0.8209
et_en Dev loss: 0.4136 r:0.6658
si_en Dev loss: 0.8756 r:0.5665
ne_en Dev loss: 0.4967 r:0.7492
ru_en Dev loss: 0.4480 r:0.7256
Current avg r:0.5985 Best avg r: 0.6278
00:43:03,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:24,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:58,278 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2603
en_de Dev loss: 0.8834 r:0.1958
en_zh Dev loss: 0.7371 r:0.4630
ro_en Dev loss: 0.3233 r:0.8205
et_en Dev loss: 0.3933 r:0.6757
si_en Dev loss: 0.7630 r:0.5625
ne_en Dev loss: 0.4237 r:0.7427
ru_en Dev loss: 0.4443 r:0.7240
Current avg r:0.5977 Best avg r: 0.6278
00:49:59,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:19,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:54,139 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2709
en_de Dev loss: 0.8739 r:0.1963
en_zh Dev loss: 0.7588 r:0.4553
ro_en Dev loss: 0.3198 r:0.8209
et_en Dev loss: 0.3924 r:0.6823
si_en Dev loss: 0.7481 r:0.5614
ne_en Dev loss: 0.4151 r:0.7446
ru_en Dev loss: 0.4176 r:0.7335
Current avg r:0.5992 Best avg r: 0.6278
00:56:54,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:15,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:49,607 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2644
en_de Dev loss: 0.9288 r:0.1885
en_zh Dev loss: 0.8214 r:0.4483
ro_en Dev loss: 0.3829 r:0.8164
et_en Dev loss: 0.4284 r:0.6657
si_en Dev loss: 0.9080 r:0.5488
ne_en Dev loss: 0.5205 r:0.7428
ru_en Dev loss: 0.5020 r:0.7117
Current avg r:0.5889 Best avg r: 0.6278
01:03:50,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:10,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:44,941 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2483
en_de Dev loss: 0.9448 r:0.1704
en_zh Dev loss: 0.8294 r:0.4383
ro_en Dev loss: 0.3467 r:0.8202
et_en Dev loss: 0.4192 r:0.6718
si_en Dev loss: 0.8656 r:0.5548
ne_en Dev loss: 0.5280 r:0.7382
ru_en Dev loss: 0.4642 r:0.7289
Current avg r:0.5889 Best avg r: 0.6278
01:10:45,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:06,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:13:40,545 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2453
en_de Dev loss: 0.9134 r:0.1867
en_zh Dev loss: 0.8506 r:0.4344
ro_en Dev loss: 0.4021 r:0.8134
et_en Dev loss: 0.4629 r:0.6585
si_en Dev loss: 1.0696 r:0.5430
ne_en Dev loss: 0.6030 r:0.7321
ru_en Dev loss: 0.4816 r:0.7267
Current avg r:0.5850 Best avg r: 0.6278
01:17:42,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:03,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:20:37,359 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2347
en_de Dev loss: 0.9014 r:0.2077
en_zh Dev loss: 0.7982 r:0.4588
ro_en Dev loss: 0.3361 r:0.8204
et_en Dev loss: 0.4128 r:0.6761
si_en Dev loss: 0.8590 r:0.5607
ne_en Dev loss: 0.4574 r:0.7370
ru_en Dev loss: 0.4247 r:0.7434
Current avg r:0.6006 Best avg r: 0.6278
01:24:37,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:58,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:27:32,910 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2297
en_de Dev loss: 0.9125 r:0.1823
en_zh Dev loss: 0.8096 r:0.4634
ro_en Dev loss: 0.3488 r:0.8243
et_en Dev loss: 0.4152 r:0.6756
si_en Dev loss: 0.8594 r:0.5564
ne_en Dev loss: 0.5061 r:0.7333
ru_en Dev loss: 0.4567 r:0.7315
Current avg r:0.5953 Best avg r: 0.6278
01:31:33,454 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:32:54,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:28,381 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2497
en_de Dev loss: 0.9030 r:0.1773
en_zh Dev loss: 0.8040 r:0.4528
ro_en Dev loss: 0.3516 r:0.8196
et_en Dev loss: 0.4290 r:0.6628
si_en Dev loss: 0.8606 r:0.5552
ne_en Dev loss: 0.5373 r:0.7325
ru_en Dev loss: 0.4536 r:0.7252
Current avg r:0.5893 Best avg r: 0.6278
01:38:28,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:39:49,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:41:23,899 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2192
en_de Dev loss: 0.9153 r:0.1953
en_zh Dev loss: 0.7848 r:0.4601
ro_en Dev loss: 0.3288 r:0.8207
et_en Dev loss: 0.4109 r:0.6706
si_en Dev loss: 0.8131 r:0.5546
ne_en Dev loss: 0.4827 r:0.7319
ru_en Dev loss: 0.4084 r:0.7410
Current avg r:0.5963 Best avg r: 0.6278
01:45:24,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:46:45,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:48:19,443 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2258
en_de Dev loss: 0.8926 r:0.2041
en_zh Dev loss: 0.7907 r:0.4587
ro_en Dev loss: 0.3320 r:0.8208
et_en Dev loss: 0.4160 r:0.6683
si_en Dev loss: 0.8873 r:0.5525
ne_en Dev loss: 0.5248 r:0.7325
ru_en Dev loss: 0.4545 r:0.7274
Current avg r:0.5949 Best avg r: 0.6278
01:52:20,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:53:41,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:55:15,321 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2252
en_de Dev loss: 0.8768 r:0.2160
en_zh Dev loss: 0.7540 r:0.4676
ro_en Dev loss: 0.3286 r:0.8239
et_en Dev loss: 0.4093 r:0.6749
si_en Dev loss: 0.8805 r:0.5544
ne_en Dev loss: 0.5367 r:0.7366
ru_en Dev loss: 0.4505 r:0.7300
Current avg r:0.6005 Best avg r: 0.6278
01:59:16,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:00:37,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:02:11,540 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2216
en_de Dev loss: 0.9094 r:0.1826
en_zh Dev loss: 0.8152 r:0.4515
ro_en Dev loss: 0.3560 r:0.8176
et_en Dev loss: 0.4299 r:0.6673
si_en Dev loss: 0.8813 r:0.5508
ne_en Dev loss: 0.5113 r:0.7304
ru_en Dev loss: 0.4771 r:0.7204
Current avg r:0.5887 Best avg r: 0.6278
02:06:12,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:07:33,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:09:07,851 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2250
en_de Dev loss: 0.8898 r:0.1997
en_zh Dev loss: 0.7903 r:0.4513
ro_en Dev loss: 0.3394 r:0.8217
et_en Dev loss: 0.4198 r:0.6694
si_en Dev loss: 0.9257 r:0.5455
ne_en Dev loss: 0.5301 r:0.7316
ru_en Dev loss: 0.4382 r:0.7438
Current avg r:0.5947 Best avg r: 0.6278
02:13:09,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:14:29,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:16:04,178 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2324
en_de Dev loss: 0.8965 r:0.1835
en_zh Dev loss: 0.7515 r:0.4729
ro_en Dev loss: 0.3374 r:0.8218
et_en Dev loss: 0.4332 r:0.6578
si_en Dev loss: 0.8702 r:0.5461
ne_en Dev loss: 0.6089 r:0.7275
ru_en Dev loss: 0.4693 r:0.7292
Current avg r:0.5913 Best avg r: 0.6278
02:20:04,916 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:25,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:59,984 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2314
en_de Dev loss: 0.8977 r:0.2005
en_zh Dev loss: 0.7545 r:0.4659
ro_en Dev loss: 0.3206 r:0.8223
et_en Dev loss: 0.4209 r:0.6598
si_en Dev loss: 0.8479 r:0.5461
ne_en Dev loss: 0.4932 r:0.7301
ru_en Dev loss: 0.4305 r:0.7414
Current avg r:0.5952 Best avg r: 0.6278
02:27:00,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:28:21,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:55,422 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2185
en_de Dev loss: 0.9161 r:0.1920
en_zh Dev loss: 0.8107 r:0.4646
ro_en Dev loss: 0.3545 r:0.8209
et_en Dev loss: 0.4358 r:0.6635
si_en Dev loss: 0.8967 r:0.5492
ne_en Dev loss: 0.5385 r:0.7307
ru_en Dev loss: 0.4844 r:0.7219
Current avg r:0.5918 Best avg r: 0.6278
02:33:56,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:16,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:50,982 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2167
en_de Dev loss: 0.9175 r:0.1599
en_zh Dev loss: 0.8128 r:0.4415
ro_en Dev loss: 0.3489 r:0.8157
et_en Dev loss: 0.4294 r:0.6619
si_en Dev loss: 0.9569 r:0.5338
ne_en Dev loss: 0.5366 r:0.7339
ru_en Dev loss: 0.4807 r:0.7180
Current avg r:0.5807 Best avg r: 0.6278
02:40:51,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:42:12,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:43:46,542 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2135
en_de Dev loss: 0.9086 r:0.1938
en_zh Dev loss: 0.7733 r:0.4613
ro_en Dev loss: 0.3124 r:0.8218
et_en Dev loss: 0.4005 r:0.6707
si_en Dev loss: 0.8093 r:0.5474
ne_en Dev loss: 0.4461 r:0.7386
ru_en Dev loss: 0.4230 r:0.7376
Current avg r:0.5959 Best avg r: 0.6278
02:47:47,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:49:08,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:50:42,590 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2244
en_de Dev loss: 0.9042 r:0.1909
en_zh Dev loss: 0.8110 r:0.4547
ro_en Dev loss: 0.3211 r:0.8233
et_en Dev loss: 0.4249 r:0.6591
si_en Dev loss: 0.8565 r:0.5468
ne_en Dev loss: 0.4629 r:0.7302
ru_en Dev loss: 0.4909 r:0.7112
Current avg r:0.5880 Best avg r: 0.6278
02:54:43,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:04,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:57:38,577 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2156
en_de Dev loss: 0.9271 r:0.1733
en_zh Dev loss: 0.8130 r:0.4554
ro_en Dev loss: 0.3478 r:0.8185
et_en Dev loss: 0.4241 r:0.6680
si_en Dev loss: 0.8227 r:0.5510
ne_en Dev loss: 0.4585 r:0.7304
ru_en Dev loss: 0.4821 r:0.7239
Current avg r:0.5887 Best avg r: 0.6278
03:01:40,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:01,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:35,437 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1969
en_de Dev loss: 0.9194 r:0.1781
en_zh Dev loss: 0.8094 r:0.4589
ro_en Dev loss: 0.3560 r:0.8173
et_en Dev loss: 0.4460 r:0.6585
si_en Dev loss: 0.9278 r:0.5385
ne_en Dev loss: 0.5571 r:0.7250
ru_en Dev loss: 0.5200 r:0.7067
Current avg r:0.5833 Best avg r: 0.6278
03:08:36,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:56,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:31,158 root INFO Epoch 7 Global steps: 64200 Train loss: 0.2027
en_de Dev loss: 0.9333 r:0.1916
en_zh Dev loss: 0.7992 r:0.4592
ro_en Dev loss: 0.3615 r:0.8169
et_en Dev loss: 0.4342 r:0.6639
si_en Dev loss: 0.9333 r:0.5391
ne_en Dev loss: 0.5622 r:0.7220
ru_en Dev loss: 0.5169 r:0.7096
Current avg r:0.5860 Best avg r: 0.6278
03:15:32,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:16:52,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:18:27,283 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1930
en_de Dev loss: 0.9093 r:0.1672
en_zh Dev loss: 0.7650 r:0.4595
ro_en Dev loss: 0.3442 r:0.8184
et_en Dev loss: 0.4160 r:0.6613
si_en Dev loss: 0.8433 r:0.5421
ne_en Dev loss: 0.5445 r:0.7223
ru_en Dev loss: 0.4695 r:0.7124
Current avg r:0.5833 Best avg r: 0.6278
03:22:28,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:23:49,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:23,462 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1997
en_de Dev loss: 0.8857 r:0.2092
en_zh Dev loss: 0.7458 r:0.4724
ro_en Dev loss: 0.3254 r:0.8190
et_en Dev loss: 0.3971 r:0.6765
si_en Dev loss: 0.8259 r:0.5504
ne_en Dev loss: 0.5080 r:0.7246
ru_en Dev loss: 0.4475 r:0.7341
Current avg r:0.5980 Best avg r: 0.6278
03:29:24,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:30:45,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:32:19,677 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1932
en_de Dev loss: 0.9069 r:0.1850
en_zh Dev loss: 0.8367 r:0.4501
ro_en Dev loss: 0.3733 r:0.8147
et_en Dev loss: 0.4299 r:0.6667
si_en Dev loss: 0.9390 r:0.5378
ne_en Dev loss: 0.5805 r:0.7172
ru_en Dev loss: 0.4874 r:0.7181
Current avg r:0.5842 Best avg r: 0.6278
03:36:20,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:41,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:39:16,16 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1937
en_de Dev loss: 0.8937 r:0.1713
en_zh Dev loss: 0.7779 r:0.4593
ro_en Dev loss: 0.3470 r:0.8170
et_en Dev loss: 0.4116 r:0.6686
si_en Dev loss: 0.8876 r:0.5355
ne_en Dev loss: 0.5549 r:0.7225
ru_en Dev loss: 0.4559 r:0.7222
Current avg r:0.5852 Best avg r: 0.6278
03:43:17,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:37,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:46:12,319 root INFO Epoch 7 Global steps: 67200 Train loss: 0.2004
en_de Dev loss: 0.9153 r:0.1875
en_zh Dev loss: 0.8009 r:0.4617
ro_en Dev loss: 0.3548 r:0.8194
et_en Dev loss: 0.4234 r:0.6671
si_en Dev loss: 0.8974 r:0.5347
ne_en Dev loss: 0.5162 r:0.7217
ru_en Dev loss: 0.4863 r:0.7112
Current avg r:0.5862 Best avg r: 0.6278
03:50:13,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:33,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:53:08,50 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1934
en_de Dev loss: 0.9314 r:0.1787
en_zh Dev loss: 0.8093 r:0.4683
ro_en Dev loss: 0.3824 r:0.8216
et_en Dev loss: 0.4494 r:0.6638
si_en Dev loss: 0.9861 r:0.5413
ne_en Dev loss: 0.5743 r:0.7273
ru_en Dev loss: 0.4826 r:0.7304
Current avg r:0.5902 Best avg r: 0.6278
03:57:08,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:58:29,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:03,762 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1867
en_de Dev loss: 0.9018 r:0.1768
en_zh Dev loss: 0.7713 r:0.4595
ro_en Dev loss: 0.3312 r:0.8219
et_en Dev loss: 0.4104 r:0.6720
si_en Dev loss: 0.8581 r:0.5441
ne_en Dev loss: 0.5441 r:0.7225
ru_en Dev loss: 0.4850 r:0.7205
Current avg r:0.5882 Best avg r: 0.6278
04:04:04,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:05:25,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:06:59,619 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1948
en_de Dev loss: 0.9091 r:0.1823
en_zh Dev loss: 0.7765 r:0.4669
ro_en Dev loss: 0.3186 r:0.8218
et_en Dev loss: 0.4182 r:0.6656
si_en Dev loss: 0.8735 r:0.5413
ne_en Dev loss: 0.4922 r:0.7194
ru_en Dev loss: 0.4255 r:0.7396
Current avg r:0.5910 Best avg r: 0.6278
04:11:00,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:12:21,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:13:55,397 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1887
en_de Dev loss: 0.8927 r:0.1953
en_zh Dev loss: 0.7600 r:0.4663
ro_en Dev loss: 0.3195 r:0.8256
et_en Dev loss: 0.4101 r:0.6692
si_en Dev loss: 0.8325 r:0.5492
ne_en Dev loss: 0.4975 r:0.7232
ru_en Dev loss: 0.4315 r:0.7355
Current avg r:0.5949 Best avg r: 0.6278
04:17:55,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:19:16,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:20:50,855 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1992
en_de Dev loss: 0.9295 r:0.1921
en_zh Dev loss: 0.7890 r:0.4628
ro_en Dev loss: 0.3269 r:0.8277
et_en Dev loss: 0.4272 r:0.6615
si_en Dev loss: 0.7862 r:0.5559
ne_en Dev loss: 0.4745 r:0.7243
ru_en Dev loss: 0.4369 r:0.7307
Current avg r:0.5936 Best avg r: 0.6278
04:24:51,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:26:12,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:27:46,356 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1958
en_de Dev loss: 0.9008 r:0.1888
en_zh Dev loss: 0.7822 r:0.4582
ro_en Dev loss: 0.3298 r:0.8242
et_en Dev loss: 0.4183 r:0.6633
si_en Dev loss: 0.8499 r:0.5450
ne_en Dev loss: 0.5302 r:0.7249
ru_en Dev loss: 0.4545 r:0.7271
Current avg r:0.5902 Best avg r: 0.6278
04:31:46,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:33:07,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:34:41,703 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1921
en_de Dev loss: 0.9437 r:0.1702
en_zh Dev loss: 0.8173 r:0.4613
ro_en Dev loss: 0.3689 r:0.8159
et_en Dev loss: 0.4435 r:0.6543
si_en Dev loss: 0.9367 r:0.5279
ne_en Dev loss: 0.5876 r:0.7176
ru_en Dev loss: 0.5050 r:0.7132
Current avg r:0.5801 Best avg r: 0.6278
04:38:42,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:40:02,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:41:37,192 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1817
en_de Dev loss: 0.9262 r:0.1636
en_zh Dev loss: 0.7619 r:0.4676
ro_en Dev loss: 0.3148 r:0.8261
et_en Dev loss: 0.4027 r:0.6729
si_en Dev loss: 0.8101 r:0.5492
ne_en Dev loss: 0.4828 r:0.7260
ru_en Dev loss: 0.4196 r:0.7471
Current avg r:0.5932 Best avg r: 0.6278
04:45:38,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:46:59,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:33,933 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1848
en_de Dev loss: 0.9199 r:0.1647
en_zh Dev loss: 0.7614 r:0.4723
ro_en Dev loss: 0.3231 r:0.8251
et_en Dev loss: 0.4065 r:0.6731
si_en Dev loss: 0.8365 r:0.5439
ne_en Dev loss: 0.5038 r:0.7229
ru_en Dev loss: 0.4644 r:0.7246
Current avg r:0.5895 Best avg r: 0.6278
04:52:34,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:53:55,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:55:29,279 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1803
en_de Dev loss: 0.9649 r:0.1623
en_zh Dev loss: 0.8035 r:0.4690
ro_en Dev loss: 0.3766 r:0.8183
et_en Dev loss: 0.4544 r:0.6527
si_en Dev loss: 1.0171 r:0.5309
ne_en Dev loss: 0.6241 r:0.7171
ru_en Dev loss: 0.5129 r:0.7158
Current avg r:0.5809 Best avg r: 0.6278
04:59:29,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:00:50,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:02:24,807 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1727
en_de Dev loss: 0.9468 r:0.1617
en_zh Dev loss: 0.7718 r:0.4766
ro_en Dev loss: 0.3530 r:0.8164
et_en Dev loss: 0.4503 r:0.6458
si_en Dev loss: 0.9716 r:0.5312
ne_en Dev loss: 0.6037 r:0.7123
ru_en Dev loss: 0.4761 r:0.7184
Current avg r:0.5804 Best avg r: 0.6278
05:06:25,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:52,202 root INFO 
id:en_zh cur r: 0.4857 best r: 0.4857
05:07:46,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:09:20,267 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1654
en_de Dev loss: 0.9465 r:0.1547
en_zh Dev loss: 0.7616 r:0.4755
ro_en Dev loss: 0.3424 r:0.8205
et_en Dev loss: 0.4336 r:0.6563
si_en Dev loss: 0.8844 r:0.5408
ne_en Dev loss: 0.5476 r:0.7176
ru_en Dev loss: 0.4765 r:0.7212
Current avg r:0.5838 Best avg r: 0.6278
05:13:20,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:41,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:16:15,662 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1734
en_de Dev loss: 0.9298 r:0.1654
en_zh Dev loss: 0.7739 r:0.4706
ro_en Dev loss: 0.3443 r:0.8225
et_en Dev loss: 0.4276 r:0.6636
si_en Dev loss: 0.8835 r:0.5395
ne_en Dev loss: 0.5444 r:0.7208
ru_en Dev loss: 0.4569 r:0.7334
Current avg r:0.5880 Best avg r: 0.6278
05:20:16,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:21:37,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:11,244 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1756
en_de Dev loss: 0.9428 r:0.1795
en_zh Dev loss: 0.7715 r:0.4800
ro_en Dev loss: 0.3601 r:0.8239
et_en Dev loss: 0.4355 r:0.6637
si_en Dev loss: 0.8965 r:0.5452
ne_en Dev loss: 0.5549 r:0.7204
ru_en Dev loss: 0.4785 r:0.7280
Current avg r:0.5915 Best avg r: 0.6278
05:27:11,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:32,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:06,720 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1660
en_de Dev loss: 0.9023 r:0.1981
en_zh Dev loss: 0.7274 r:0.4749
ro_en Dev loss: 0.3246 r:0.8240
et_en Dev loss: 0.4092 r:0.6711
si_en Dev loss: 0.8926 r:0.5440
ne_en Dev loss: 0.5008 r:0.7327
ru_en Dev loss: 0.4237 r:0.7419
Current avg r:0.5981 Best avg r: 0.6278
05:34:07,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:35:27,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:37:02,162 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1795
en_de Dev loss: 0.9202 r:0.1779
en_zh Dev loss: 0.7613 r:0.4639
ro_en Dev loss: 0.3467 r:0.8171
et_en Dev loss: 0.4242 r:0.6641
si_en Dev loss: 0.8976 r:0.5309
ne_en Dev loss: 0.5339 r:0.7220
ru_en Dev loss: 0.4664 r:0.7270
Current avg r:0.5861 Best avg r: 0.6278
05:41:02,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:41:29,637 root INFO 
id:en_zh cur r: 0.4934 best r: 0.4934
05:42:23,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:43:57,725 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1666
en_de Dev loss: 0.9555 r:0.1941
en_zh Dev loss: 0.7379 r:0.4908
ro_en Dev loss: 0.3049 r:0.8265
et_en Dev loss: 0.4045 r:0.6769
si_en Dev loss: 0.7494 r:0.5522
ne_en Dev loss: 0.4347 r:0.7214
ru_en Dev loss: 0.3777 r:0.7612
Current avg r:0.6033 Best avg r: 0.6278
05:47:58,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:49:19,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:50:53,261 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1705
en_de Dev loss: 0.9102 r:0.1652
en_zh Dev loss: 0.7676 r:0.4534
ro_en Dev loss: 0.3111 r:0.8234
et_en Dev loss: 0.4070 r:0.6739
si_en Dev loss: 0.7828 r:0.5453
ne_en Dev loss: 0.4562 r:0.7258
ru_en Dev loss: 0.4146 r:0.7355
Current avg r:0.5889 Best avg r: 0.6278
05:54:53,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:56:14,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:57:48,721 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1779
en_de Dev loss: 0.9676 r:0.1530
en_zh Dev loss: 0.7883 r:0.4646
ro_en Dev loss: 0.3514 r:0.8157
et_en Dev loss: 0.4315 r:0.6636
si_en Dev loss: 0.8810 r:0.5402
ne_en Dev loss: 0.5568 r:0.7158
ru_en Dev loss: 0.4875 r:0.7210
Current avg r:0.5820 Best avg r: 0.6278
06:01:49,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:10,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:44,235 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1767
en_de Dev loss: 0.9471 r:0.1603
en_zh Dev loss: 0.7749 r:0.4713
ro_en Dev loss: 0.3385 r:0.8195
et_en Dev loss: 0.4323 r:0.6611
si_en Dev loss: 0.8991 r:0.5419
ne_en Dev loss: 0.5100 r:0.7234
ru_en Dev loss: 0.4256 r:0.7465
Current avg r:0.5891 Best avg r: 0.6278
06:08:44,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:10:05,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:39,560 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1802
en_de Dev loss: 0.9369 r:0.1581
en_zh Dev loss: 0.8023 r:0.4594
ro_en Dev loss: 0.3578 r:0.8176
et_en Dev loss: 0.4464 r:0.6547
si_en Dev loss: 0.9972 r:0.5254
ne_en Dev loss: 0.5417 r:0.7111
ru_en Dev loss: 0.5045 r:0.7137
Current avg r:0.5771 Best avg r: 0.6278
06:15:40,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:00,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:35,44 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1735
en_de Dev loss: 0.9451 r:0.1550
en_zh Dev loss: 0.8293 r:0.4510
ro_en Dev loss: 0.3562 r:0.8181
et_en Dev loss: 0.4390 r:0.6561
si_en Dev loss: 0.9077 r:0.5335
ne_en Dev loss: 0.5081 r:0.7081
ru_en Dev loss: 0.4755 r:0.7248
Current avg r:0.5781 Best avg r: 0.6278
06:22:35,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:23:56,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:25:30,605 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1722
en_de Dev loss: 0.9234 r:0.1801
en_zh Dev loss: 0.7434 r:0.4756
ro_en Dev loss: 0.3210 r:0.8215
et_en Dev loss: 0.4171 r:0.6642
si_en Dev loss: 0.8565 r:0.5416
ne_en Dev loss: 0.5204 r:0.7169
ru_en Dev loss: 0.4147 r:0.7429
Current avg r:0.5919 Best avg r: 0.6278
06:29:32,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:59,494 root INFO 
id:en_zh cur r: 0.5003 best r: 0.5003
06:30:53,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:27,451 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1531
en_de Dev loss: 0.9294 r:0.1864
en_zh Dev loss: 0.7417 r:0.4934
ro_en Dev loss: 0.3302 r:0.8194
et_en Dev loss: 0.4252 r:0.6650
si_en Dev loss: 0.8370 r:0.5463
ne_en Dev loss: 0.5112 r:0.7179
ru_en Dev loss: 0.4143 r:0.7433
Current avg r:0.5960 Best avg r: 0.6278
06:36:28,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:48,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:22,854 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1513
en_de Dev loss: 0.9373 r:0.1870
en_zh Dev loss: 0.7417 r:0.4857
ro_en Dev loss: 0.3284 r:0.8215
et_en Dev loss: 0.4170 r:0.6682
si_en Dev loss: 0.8853 r:0.5390
ne_en Dev loss: 0.5309 r:0.7154
ru_en Dev loss: 0.4014 r:0.7517
Current avg r:0.5955 Best avg r: 0.6278
06:43:23,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:44:44,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:18,376 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1614
en_de Dev loss: 0.9302 r:0.1693
en_zh Dev loss: 0.7406 r:0.4867
ro_en Dev loss: 0.3300 r:0.8212
et_en Dev loss: 0.4009 r:0.6781
si_en Dev loss: 0.8177 r:0.5504
ne_en Dev loss: 0.4715 r:0.7263
ru_en Dev loss: 0.4082 r:0.7532
Current avg r:0.5979 Best avg r: 0.6278
06:50:18,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:39,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:53:13,915 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1475
en_de Dev loss: 0.9432 r:0.1577
en_zh Dev loss: 0.8136 r:0.4638
ro_en Dev loss: 0.3418 r:0.8194
et_en Dev loss: 0.4302 r:0.6612
si_en Dev loss: 0.9436 r:0.5312
ne_en Dev loss: 0.5892 r:0.7138
ru_en Dev loss: 0.4663 r:0.7259
Current avg r:0.5819 Best avg r: 0.6278
06:57:14,459 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:58:35,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:00:09,463 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1594
en_de Dev loss: 0.9447 r:0.1543
en_zh Dev loss: 0.7976 r:0.4628
ro_en Dev loss: 0.3571 r:0.8170
et_en Dev loss: 0.4318 r:0.6637
si_en Dev loss: 0.9632 r:0.5280
ne_en Dev loss: 0.5895 r:0.7119
ru_en Dev loss: 0.5004 r:0.7197
Current avg r:0.5796 Best avg r: 0.6278
07:04:09,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:05:30,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:07:04,863 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1515
en_de Dev loss: 0.9702 r:0.1374
en_zh Dev loss: 0.7717 r:0.4584
ro_en Dev loss: 0.3439 r:0.8132
et_en Dev loss: 0.4236 r:0.6585
si_en Dev loss: 0.8927 r:0.5252
ne_en Dev loss: 0.5249 r:0.7118
ru_en Dev loss: 0.4469 r:0.7289
Current avg r:0.5762 Best avg r: 0.6278
07:11:05,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:12:26,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:14:00,252 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1543
en_de Dev loss: 0.9550 r:0.1610
en_zh Dev loss: 0.7498 r:0.4786
ro_en Dev loss: 0.3453 r:0.8201
et_en Dev loss: 0.4335 r:0.6595
si_en Dev loss: 0.9402 r:0.5390
ne_en Dev loss: 0.6251 r:0.7214
ru_en Dev loss: 0.4420 r:0.7346
Current avg r:0.5878 Best avg r: 0.6278
07:18:00,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:19:21,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:55,487 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1468
en_de Dev loss: 0.9434 r:0.1573
en_zh Dev loss: 0.7312 r:0.4725
ro_en Dev loss: 0.3192 r:0.8206
et_en Dev loss: 0.4172 r:0.6573
si_en Dev loss: 0.8417 r:0.5366
ne_en Dev loss: 0.5172 r:0.7186
ru_en Dev loss: 0.4306 r:0.7310
Current avg r:0.5848 Best avg r: 0.6278
07:24:56,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:26:16,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:27:50,926 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1584
en_de Dev loss: 0.9481 r:0.1665
en_zh Dev loss: 0.7476 r:0.4771
ro_en Dev loss: 0.3385 r:0.8234
et_en Dev loss: 0.4178 r:0.6724
si_en Dev loss: 0.9168 r:0.5390
ne_en Dev loss: 0.5595 r:0.7226
ru_en Dev loss: 0.4509 r:0.7405
Current avg r:0.5917 Best avg r: 0.6278
07:31:51,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:33:12,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:34:46,482 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1537
en_de Dev loss: 0.9656 r:0.1668
en_zh Dev loss: 0.7918 r:0.4718
ro_en Dev loss: 0.3661 r:0.8195
et_en Dev loss: 0.4420 r:0.6638
si_en Dev loss: 0.9164 r:0.5333
ne_en Dev loss: 0.5849 r:0.7166
ru_en Dev loss: 0.4771 r:0.7365
Current avg r:0.5869 Best avg r: 0.6278
07:38:47,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:07,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:41:41,956 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1565
en_de Dev loss: 0.9763 r:0.1559
en_zh Dev loss: 0.8027 r:0.4688
ro_en Dev loss: 0.3740 r:0.8178
et_en Dev loss: 0.4345 r:0.6698
si_en Dev loss: 0.8855 r:0.5404
ne_en Dev loss: 0.5666 r:0.7188
ru_en Dev loss: 0.4767 r:0.7305
Current avg r:0.5860 Best avg r: 0.6278
07:45:42,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:03,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:48:37,406 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1625
en_de Dev loss: 0.9525 r:0.1763
en_zh Dev loss: 0.8244 r:0.4606
ro_en Dev loss: 0.3640 r:0.8146
et_en Dev loss: 0.4527 r:0.6568
si_en Dev loss: 0.9342 r:0.5313
ne_en Dev loss: 0.5954 r:0.7096
ru_en Dev loss: 0.5032 r:0.7139
Current avg r:0.5804 Best avg r: 0.6278
07:52:38,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:53:58,765 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:33,0 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1440
en_de Dev loss: 0.9533 r:0.1593
en_zh Dev loss: 0.7579 r:0.4792
ro_en Dev loss: 0.3467 r:0.8191
et_en Dev loss: 0.4256 r:0.6701
si_en Dev loss: 0.8712 r:0.5443
ne_en Dev loss: 0.5376 r:0.7212
ru_en Dev loss: 0.4371 r:0.7418
Current avg r:0.5907 Best avg r: 0.6278
07:59:33,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:00:54,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:28,487 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1454
en_de Dev loss: 0.9608 r:0.1687
en_zh Dev loss: 0.7800 r:0.4816
ro_en Dev loss: 0.3528 r:0.8217
et_en Dev loss: 0.4383 r:0.6636
si_en Dev loss: 0.8589 r:0.5497
ne_en Dev loss: 0.5223 r:0.7226
ru_en Dev loss: 0.4523 r:0.7415
Current avg r:0.5928 Best avg r: 0.6278
08:06:29,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:07:49,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:09:24,37 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1504
en_de Dev loss: 0.9434 r:0.1819
en_zh Dev loss: 0.7490 r:0.4809
ro_en Dev loss: 0.3376 r:0.8203
et_en Dev loss: 0.4237 r:0.6598
si_en Dev loss: 0.8496 r:0.5420
ne_en Dev loss: 0.5204 r:0.7175
ru_en Dev loss: 0.4306 r:0.7392
Current avg r:0.5917 Best avg r: 0.6278
08:13:25,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:14:46,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:20,675 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1440
en_de Dev loss: 0.9699 r:0.1727
en_zh Dev loss: 0.8259 r:0.4661
ro_en Dev loss: 0.3712 r:0.8157
et_en Dev loss: 0.4609 r:0.6536
si_en Dev loss: 0.9632 r:0.5362
ne_en Dev loss: 0.5831 r:0.7178
ru_en Dev loss: 0.5000 r:0.7259
Current avg r:0.5840 Best avg r: 0.6278
08:20:21,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:42,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:16,532 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1364
en_de Dev loss: 0.9344 r:0.1573
en_zh Dev loss: 0.7218 r:0.4741
ro_en Dev loss: 0.3412 r:0.8124
et_en Dev loss: 0.4332 r:0.6484
si_en Dev loss: 0.9472 r:0.5214
ne_en Dev loss: 0.6310 r:0.7091
ru_en Dev loss: 0.4462 r:0.7269
Current avg r:0.5785 Best avg r: 0.6278
08:27:17,242 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:37,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:12,207 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1412
en_de Dev loss: 0.9987 r:0.1597
en_zh Dev loss: 0.8099 r:0.4835
ro_en Dev loss: 0.3842 r:0.8172
et_en Dev loss: 0.4550 r:0.6624
si_en Dev loss: 0.9430 r:0.5356
ne_en Dev loss: 0.5850 r:0.7139
ru_en Dev loss: 0.4683 r:0.7431
Current avg r:0.5879 Best avg r: 0.6278
08:34:13,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:33,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:37:08,120 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1335
en_de Dev loss: 0.9447 r:0.1709
en_zh Dev loss: 0.7605 r:0.4800
ro_en Dev loss: 0.3475 r:0.8143
et_en Dev loss: 0.4273 r:0.6582
si_en Dev loss: 0.9014 r:0.5243
ne_en Dev loss: 0.5745 r:0.7037
ru_en Dev loss: 0.4448 r:0.7356
Current avg r:0.5838 Best avg r: 0.6278
08:41:09,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:29,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:44:03,978 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1355
en_de Dev loss: 0.9344 r:0.1675
en_zh Dev loss: 0.7312 r:0.4836
ro_en Dev loss: 0.3260 r:0.8190
et_en Dev loss: 0.4117 r:0.6696
si_en Dev loss: 0.7987 r:0.5439
ne_en Dev loss: 0.4977 r:0.7178
ru_en Dev loss: 0.4205 r:0.7386
Current avg r:0.5914 Best avg r: 0.6278
08:48:04,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:49:25,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:50:59,939 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1299
en_de Dev loss: 0.9337 r:0.1751
en_zh Dev loss: 0.7502 r:0.4765
ro_en Dev loss: 0.3318 r:0.8194
et_en Dev loss: 0.4103 r:0.6690
si_en Dev loss: 0.8656 r:0.5372
ne_en Dev loss: 0.5558 r:0.7218
ru_en Dev loss: 0.4150 r:0.7454
Current avg r:0.5921 Best avg r: 0.6278
08:55:00,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:56:21,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:57:55,582 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1377
en_de Dev loss: 0.9646 r:0.1648
en_zh Dev loss: 0.7868 r:0.4685
ro_en Dev loss: 0.3545 r:0.8181
et_en Dev loss: 0.4244 r:0.6691
si_en Dev loss: 0.9184 r:0.5265
ne_en Dev loss: 0.5287 r:0.7159
ru_en Dev loss: 0.4544 r:0.7423
Current avg r:0.5865 Best avg r: 0.6278
09:01:56,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:03:16,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:04:50,819 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1335
en_de Dev loss: 0.9758 r:0.1657
en_zh Dev loss: 0.7903 r:0.4721
ro_en Dev loss: 0.3455 r:0.8231
et_en Dev loss: 0.4368 r:0.6597
si_en Dev loss: 0.9283 r:0.5277
ne_en Dev loss: 0.5698 r:0.7119
ru_en Dev loss: 0.4508 r:0.7443
Current avg r:0.5863 Best avg r: 0.6278
09:08:51,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:10:12,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:46,195 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1310
en_de Dev loss: 0.9309 r:0.1606
en_zh Dev loss: 0.7486 r:0.4649
ro_en Dev loss: 0.3223 r:0.8213
et_en Dev loss: 0.4135 r:0.6633
si_en Dev loss: 0.8855 r:0.5220
ne_en Dev loss: 0.5647 r:0.7101
ru_en Dev loss: 0.4413 r:0.7373
Current avg r:0.5828 Best avg r: 0.6278
09:15:47,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:17:07,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:18:42,86 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1344
en_de Dev loss: 0.9440 r:0.1749
en_zh Dev loss: 0.7811 r:0.4720
ro_en Dev loss: 0.3487 r:0.8221
et_en Dev loss: 0.4209 r:0.6683
si_en Dev loss: 0.9427 r:0.5296
ne_en Dev loss: 0.5920 r:0.7077
ru_en Dev loss: 0.4478 r:0.7452
Current avg r:0.5885 Best avg r: 0.6278
09:22:42,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:24:03,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:25:37,945 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1337
en_de Dev loss: 0.9403 r:0.1752
en_zh Dev loss: 0.7481 r:0.4792
ro_en Dev loss: 0.3381 r:0.8215
et_en Dev loss: 0.4240 r:0.6617
si_en Dev loss: 0.9150 r:0.5291
ne_en Dev loss: 0.5718 r:0.7068
ru_en Dev loss: 0.4386 r:0.7450
Current avg r:0.5883 Best avg r: 0.6278
09:29:38,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:59,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:32:33,678 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1354
en_de Dev loss: 0.9375 r:0.1634
en_zh Dev loss: 0.7783 r:0.4687
ro_en Dev loss: 0.3344 r:0.8221
et_en Dev loss: 0.4205 r:0.6632
si_en Dev loss: 0.8879 r:0.5314
ne_en Dev loss: 0.5495 r:0.7087
ru_en Dev loss: 0.4427 r:0.7377
Current avg r:0.5850 Best avg r: 0.6278
09:36:34,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:37:54,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:39:29,5 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1315
en_de Dev loss: 0.9251 r:0.1714
en_zh Dev loss: 0.7402 r:0.4839
ro_en Dev loss: 0.3173 r:0.8237
et_en Dev loss: 0.4043 r:0.6731
si_en Dev loss: 0.8157 r:0.5377
ne_en Dev loss: 0.4831 r:0.7084
ru_en Dev loss: 0.3947 r:0.7563
Current avg r:0.5935 Best avg r: 0.6278
09:43:29,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:44:50,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:46:24,216 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1307
en_de Dev loss: 0.9359 r:0.1620
en_zh Dev loss: 0.7693 r:0.4757
ro_en Dev loss: 0.3368 r:0.8223
et_en Dev loss: 0.4204 r:0.6714
si_en Dev loss: 0.9803 r:0.5296
ne_en Dev loss: 0.5741 r:0.7089
ru_en Dev loss: 0.4521 r:0.7392
Current avg r:0.5870 Best avg r: 0.6278
09:50:24,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:51:45,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:53:19,383 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1363
en_de Dev loss: 0.9547 r:0.1487
en_zh Dev loss: 0.7778 r:0.4728
ro_en Dev loss: 0.3292 r:0.8238
et_en Dev loss: 0.4092 r:0.6745
si_en Dev loss: 0.8722 r:0.5401
ne_en Dev loss: 0.4984 r:0.7098
ru_en Dev loss: 0.4337 r:0.7486
Current avg r:0.5883 Best avg r: 0.6278
09:57:21,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:41,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:15,833 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1235
en_de Dev loss: 0.9417 r:0.1637
en_zh Dev loss: 0.7400 r:0.4767
ro_en Dev loss: 0.3254 r:0.8205
et_en Dev loss: 0.4074 r:0.6731
si_en Dev loss: 0.8678 r:0.5365
ne_en Dev loss: 0.5362 r:0.7096
ru_en Dev loss: 0.4120 r:0.7496
Current avg r:0.5900 Best avg r: 0.6278
10:04:16,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:36,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:10,878 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1194
en_de Dev loss: 0.9892 r:0.1300
en_zh Dev loss: 0.7362 r:0.4838
ro_en Dev loss: 0.3391 r:0.8215
et_en Dev loss: 0.4107 r:0.6716
si_en Dev loss: 0.8382 r:0.5427
ne_en Dev loss: 0.5549 r:0.7126
ru_en Dev loss: 0.4108 r:0.7507
Current avg r:0.5876 Best avg r: 0.6278
10:11:11,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:12:31,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:05,954 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1182
en_de Dev loss: 0.9649 r:0.1337
en_zh Dev loss: 0.7177 r:0.4819
ro_en Dev loss: 0.3241 r:0.8207
et_en Dev loss: 0.4137 r:0.6622
si_en Dev loss: 0.8151 r:0.5403
ne_en Dev loss: 0.5158 r:0.7043
ru_en Dev loss: 0.4157 r:0.7414
Current avg r:0.5835 Best avg r: 0.6278
10:18:06,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:26,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:21:00,920 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1199
en_de Dev loss: 0.9805 r:0.1414
en_zh Dev loss: 0.7175 r:0.4925
ro_en Dev loss: 0.3331 r:0.8174
et_en Dev loss: 0.4120 r:0.6703
si_en Dev loss: 0.8274 r:0.5439
ne_en Dev loss: 0.5215 r:0.7117
ru_en Dev loss: 0.4097 r:0.7553
Current avg r:0.5903 Best avg r: 0.6278
10:25:01,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:26:21,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:55,915 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1189
en_de Dev loss: 0.9650 r:0.1524
en_zh Dev loss: 0.7331 r:0.4850
ro_en Dev loss: 0.3440 r:0.8194
et_en Dev loss: 0.4207 r:0.6673
si_en Dev loss: 0.9254 r:0.5341
ne_en Dev loss: 0.5947 r:0.7152
ru_en Dev loss: 0.4541 r:0.7345
Current avg r:0.5868 Best avg r: 0.6278
10:31:56,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:33:16,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:34:50,916 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1137
en_de Dev loss: 1.0056 r:0.1368
en_zh Dev loss: 0.7651 r:0.4808
ro_en Dev loss: 0.3502 r:0.8166
et_en Dev loss: 0.4291 r:0.6646
si_en Dev loss: 0.8975 r:0.5343
ne_en Dev loss: 0.5644 r:0.7174
ru_en Dev loss: 0.4472 r:0.7404
Current avg r:0.5844 Best avg r: 0.6278
10:38:51,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:40:11,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:41:45,820 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1215
en_de Dev loss: 1.0010 r:0.1530
en_zh Dev loss: 0.7764 r:0.4783
ro_en Dev loss: 0.3732 r:0.8148
et_en Dev loss: 0.4277 r:0.6694
si_en Dev loss: 0.9097 r:0.5291
ne_en Dev loss: 0.5685 r:0.7118
ru_en Dev loss: 0.4550 r:0.7420
Current avg r:0.5855 Best avg r: 0.6278
