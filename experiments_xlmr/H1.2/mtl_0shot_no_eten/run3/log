14:42:39,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:52,328 root INFO 
id:en_de cur r: 0.0794 best r: 0.0794
14:43:05,346 root INFO 
id:en_zh cur r: 0.1573 best r: 0.1573
14:43:18,386 root INFO 
id:ro_en cur r: 0.5869 best r: 0.5869
14:43:31,474 root INFO 
id:si_en cur r: 0.3876 best r: 0.3876
14:43:44,574 root INFO 
id:ne_en cur r: 0.5509 best r: 0.5509
14:43:57,587 root INFO 
id:ru_en cur r: 0.5893 best r: 0.5893
14:43:57,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:29,59 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
14:45:29,66 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:45:29,71 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:45:29,79 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
14:45:29,85 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
14:45:29,90 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:45:29,95 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:45:42,210 root INFO Epoch 0 Global steps: 600 Train loss: 0.8641
en_de Dev loss: 0.8970 r:0.0740
en_zh Dev loss: 0.7750 r:0.2660
ro_en Dev loss: 0.6381 r:0.6158
et_en Dev loss: 0.6338 r:0.5109
si_en Dev loss: 0.6786 r:0.4538
ne_en Dev loss: 0.6524 r:0.5398
ru_en Dev loss: 0.6230 r:0.6300
Current avg r:0.4415 Best avg r: 0.4415
14:49:36,104 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:49,101 root INFO 
id:en_de cur r: 0.0960 best r: 0.0960
14:50:02,88 root INFO 
id:en_zh cur r: 0.2404 best r: 0.2404
14:50:15,124 root INFO 
id:ro_en cur r: 0.6552 best r: 0.6552
14:50:28,189 root INFO 
id:si_en cur r: 0.4101 best r: 0.4101
14:50:41,233 root INFO 
id:ne_en cur r: 0.5965 best r: 0.5965
14:50:54,156 root INFO 
id:ru_en cur r: 0.6062 best r: 0.6062
14:50:54,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:25,40 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
14:52:25,47 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:52:25,53 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:52:25,58 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
14:52:25,64 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
14:52:25,69 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:52:25,74 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:52:38,73 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8261
en_de Dev loss: 0.8979 r:0.1023
en_zh Dev loss: 0.7732 r:0.2803
ro_en Dev loss: 0.5511 r:0.6688
et_en Dev loss: 0.5885 r:0.4757
si_en Dev loss: 0.6786 r:0.4827
ne_en Dev loss: 0.5798 r:0.5588
ru_en Dev loss: 0.5343 r:0.6668
Current avg r:0.4622 Best avg r: 0.4622
14:56:30,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:43,837 root INFO 
id:en_de cur r: 0.1114 best r: 0.1114
14:57:09,737 root INFO 
id:ro_en cur r: 0.6580 best r: 0.6580
14:57:22,737 root INFO 
id:si_en cur r: 0.4404 best r: 0.4404
14:57:48,631 root INFO 
id:ru_en cur r: 0.6067 best r: 0.6067
14:57:48,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:19,321 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
14:59:19,332 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:59:19,338 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:59:19,344 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
14:59:19,350 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
14:59:19,356 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:59:19,363 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:59:32,360 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7248
en_de Dev loss: 0.9244 r:0.1000
en_zh Dev loss: 0.7827 r:0.2884
ro_en Dev loss: 0.5422 r:0.6846
et_en Dev loss: 0.5525 r:0.5257
si_en Dev loss: 0.6790 r:0.4741
ne_en Dev loss: 0.5844 r:0.5628
ru_en Dev loss: 0.5581 r:0.6476
Current avg r:0.4690 Best avg r: 0.4690
15:03:24,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:37,775 root INFO 
id:en_de cur r: 0.1172 best r: 0.1172
15:03:50,712 root INFO 
id:en_zh cur r: 0.2873 best r: 0.2873
15:04:03,664 root INFO 
id:ro_en cur r: 0.6828 best r: 0.6828
15:04:16,664 root INFO 
id:si_en cur r: 0.4472 best r: 0.4472
15:04:29,662 root INFO 
id:ne_en cur r: 0.6124 best r: 0.6124
15:04:42,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:13,235 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:06:13,242 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:06:13,247 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:06:13,253 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:06:13,262 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:06:13,267 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:06:13,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:06:26,279 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7048
en_de Dev loss: 0.9515 r:0.1206
en_zh Dev loss: 0.7703 r:0.3123
ro_en Dev loss: 0.4927 r:0.7080
et_en Dev loss: 0.5261 r:0.5433
si_en Dev loss: 0.7361 r:0.4779
ne_en Dev loss: 0.5533 r:0.5944
ru_en Dev loss: 0.5639 r:0.6259
Current avg r:0.4832 Best avg r: 0.4832
15:10:18,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:44,804 root INFO 
id:en_zh cur r: 0.3430 best r: 0.3430
15:10:57,777 root INFO 
id:ro_en cur r: 0.7210 best r: 0.7210
15:11:10,788 root INFO 
id:si_en cur r: 0.4954 best r: 0.4954
15:11:23,788 root INFO 
id:ne_en cur r: 0.6381 best r: 0.6381
15:11:36,697 root INFO 
id:ru_en cur r: 0.6342 best r: 0.6342
15:11:36,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:07,430 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:13:07,435 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:13:07,442 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:13:07,448 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:13:07,455 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:13:07,460 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:13:07,465 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:13:20,446 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6449
en_de Dev loss: 0.9784 r:0.1355
en_zh Dev loss: 0.7777 r:0.3496
ro_en Dev loss: 0.4891 r:0.7419
et_en Dev loss: 0.5297 r:0.5646
si_en Dev loss: 0.7145 r:0.5125
ne_en Dev loss: 0.5113 r:0.6266
ru_en Dev loss: 0.5598 r:0.6482
Current avg r:0.5113 Best avg r: 0.5113
15:17:12,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:25,797 root INFO 
id:en_de cur r: 0.1682 best r: 0.1682
15:18:30,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:01,293 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6267
en_de Dev loss: 0.9817 r:0.1572
en_zh Dev loss: 0.8101 r:0.3622
ro_en Dev loss: 0.5113 r:0.7363
et_en Dev loss: 0.5477 r:0.5696
si_en Dev loss: 0.8247 r:0.4887
ne_en Dev loss: 0.6350 r:0.5957
ru_en Dev loss: 0.5760 r:0.6615
Current avg r:0.5102 Best avg r: 0.5113
15:23:53,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:19,279 root INFO 
id:en_zh cur r: 0.3894 best r: 0.3894
15:24:32,227 root INFO 
id:ro_en cur r: 0.7463 best r: 0.7463
15:24:45,219 root INFO 
id:si_en cur r: 0.5331 best r: 0.5331
15:24:58,203 root INFO 
id:ne_en cur r: 0.6950 best r: 0.6950
15:25:11,96 root INFO 
id:ru_en cur r: 0.7004 best r: 0.7004
15:25:11,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:41,834 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:26:41,843 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:26:41,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:26:41,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:26:41,859 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:26:41,864 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:26:41,868 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:26:54,860 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6233
en_de Dev loss: 0.9478 r:0.1701
en_zh Dev loss: 0.7292 r:0.3866
ro_en Dev loss: 0.3764 r:0.7603
et_en Dev loss: 0.4439 r:0.6273
si_en Dev loss: 0.6182 r:0.5387
ne_en Dev loss: 0.4279 r:0.6790
ru_en Dev loss: 0.4310 r:0.7190
Current avg r:0.5544 Best avg r: 0.5544
15:30:49,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:28,309 root INFO 
id:ro_en cur r: 0.7542 best r: 0.7542
15:32:07,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:38,756 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6286
en_de Dev loss: 0.9402 r:0.1659
en_zh Dev loss: 0.7645 r:0.3705
ro_en Dev loss: 0.3774 r:0.7647
et_en Dev loss: 0.4605 r:0.6164
si_en Dev loss: 0.7050 r:0.5260
ne_en Dev loss: 0.4683 r:0.6625
ru_en Dev loss: 0.5220 r:0.6900
Current avg r:0.5423 Best avg r: 0.5544
15:37:33,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:12,185 root INFO 
id:ro_en cur r: 0.7622 best r: 0.7622
15:38:25,245 root INFO 
id:si_en cur r: 0.5331 best r: 0.5331
15:38:38,312 root INFO 
id:ne_en cur r: 0.6961 best r: 0.6961
15:38:51,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:22,456 root INFO Epoch 0 Global steps: 5400 Train loss: 0.6008
en_de Dev loss: 0.9723 r:0.1733
en_zh Dev loss: 0.8248 r:0.3752
ro_en Dev loss: 0.4199 r:0.7731
et_en Dev loss: 0.4740 r:0.6216
si_en Dev loss: 0.7198 r:0.5408
ne_en Dev loss: 0.4948 r:0.6840
ru_en Dev loss: 0.5215 r:0.7029
Current avg r:0.5530 Best avg r: 0.5544
15:44:16,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:29,628 root INFO 
id:en_de cur r: 0.1934 best r: 0.1934
15:44:42,635 root INFO 
id:en_zh cur r: 0.4094 best r: 0.4094
15:45:21,752 root INFO 
id:ne_en cur r: 0.7052 best r: 0.7052
15:45:34,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:05,898 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:47:05,904 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:47:05,908 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:47:05,913 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:47:05,920 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:47:05,925 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:47:05,930 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:47:18,995 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5616
en_de Dev loss: 0.9731 r:0.2063
en_zh Dev loss: 0.8291 r:0.4158
ro_en Dev loss: 0.4429 r:0.7699
et_en Dev loss: 0.4797 r:0.6268
si_en Dev loss: 0.7599 r:0.5433
ne_en Dev loss: 0.4378 r:0.7013
ru_en Dev loss: 0.5777 r:0.7074
Current avg r:0.5673 Best avg r: 0.5673
15:51:13,206 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:39,221 root INFO 
id:en_zh cur r: 0.4245 best r: 0.4245
15:51:52,265 root INFO 
id:ro_en cur r: 0.7783 best r: 0.7783
15:52:05,342 root INFO 
id:si_en cur r: 0.5511 best r: 0.5511
15:52:18,416 root INFO 
id:ne_en cur r: 0.7108 best r: 0.7108
15:52:31,386 root INFO 
id:ru_en cur r: 0.7253 best r: 0.7253
15:52:31,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:02,601 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:54:02,609 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:54:02,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:54:02,619 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:54:02,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:54:02,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:54:02,633 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:54:15,694 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5852
en_de Dev loss: 0.8690 r:0.1897
en_zh Dev loss: 0.6951 r:0.4248
ro_en Dev loss: 0.3567 r:0.7850
et_en Dev loss: 0.4276 r:0.6492
si_en Dev loss: 0.7260 r:0.5492
ne_en Dev loss: 0.4234 r:0.7104
ru_en Dev loss: 0.4541 r:0.7277
Current avg r:0.5766 Best avg r: 0.5766
15:58:10,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:36,366 root INFO 
id:en_zh cur r: 0.4378 best r: 0.4378
15:58:49,384 root INFO 
id:ro_en cur r: 0.7881 best r: 0.7881
15:59:02,456 root INFO 
id:si_en cur r: 0.5740 best r: 0.5740
15:59:15,536 root INFO 
id:ne_en cur r: 0.7260 best r: 0.7260
15:59:28,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:59,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:00:59,797 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:00:59,802 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:00:59,808 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:00:59,812 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:00:59,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:00:59,824 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:01:12,872 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5847
en_de Dev loss: 0.8549 r:0.2088
en_zh Dev loss: 0.6821 r:0.4379
ro_en Dev loss: 0.3349 r:0.7937
et_en Dev loss: 0.4209 r:0.6575
si_en Dev loss: 0.6511 r:0.5765
ne_en Dev loss: 0.4210 r:0.7239
ru_en Dev loss: 0.4368 r:0.7310
Current avg r:0.5899 Best avg r: 0.5899
16:05:07,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:46,796 root INFO 
id:ro_en cur r: 0.7893 best r: 0.7893
16:05:59,859 root INFO 
id:si_en cur r: 0.5775 best r: 0.5775
16:06:25,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:57,67 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5298
en_de Dev loss: 0.9039 r:0.1955
en_zh Dev loss: 0.8195 r:0.4260
ro_en Dev loss: 0.3665 r:0.7927
et_en Dev loss: 0.4639 r:0.6448
si_en Dev loss: 0.7351 r:0.5797
ne_en Dev loss: 0.4691 r:0.7231
ru_en Dev loss: 0.5568 r:0.7116
Current avg r:0.5819 Best avg r: 0.5899
16:11:52,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:31,128 root INFO 
id:ro_en cur r: 0.7902 best r: 0.7902
16:13:10,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:41,402 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5825
en_de Dev loss: 0.8667 r:0.2151
en_zh Dev loss: 0.7835 r:0.4311
ro_en Dev loss: 0.3790 r:0.7924
et_en Dev loss: 0.4496 r:0.6563
si_en Dev loss: 0.7304 r:0.5738
ne_en Dev loss: 0.4607 r:0.7225
ru_en Dev loss: 0.5981 r:0.7027
Current avg r:0.5848 Best avg r: 0.5899
16:18:36,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:49,249 root INFO 
id:en_de cur r: 0.2122 best r: 0.2122
16:19:15,384 root INFO 
id:ro_en cur r: 0.7984 best r: 0.7984
16:19:41,618 root INFO 
id:ne_en cur r: 0.7262 best r: 0.7262
16:19:54,627 root INFO 
id:ru_en cur r: 0.7254 best r: 0.7254
16:19:54,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:25,970 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:21:25,978 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:21:25,984 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:21:25,988 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:21:25,993 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:21:25,997 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:21:26,2 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:21:39,63 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5326
en_de Dev loss: 0.8491 r:0.2364
en_zh Dev loss: 0.7284 r:0.4391
ro_en Dev loss: 0.3524 r:0.7945
et_en Dev loss: 0.4217 r:0.6655
si_en Dev loss: 0.7054 r:0.5754
ne_en Dev loss: 0.4068 r:0.7316
ru_en Dev loss: 0.4826 r:0.7335
Current avg r:0.5966 Best avg r: 0.5966
16:25:35,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:53,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:24,882 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5273
en_de Dev loss: 0.8810 r:0.2276
en_zh Dev loss: 0.8414 r:0.4320
ro_en Dev loss: 0.3702 r:0.7983
et_en Dev loss: 0.4597 r:0.6484
si_en Dev loss: 0.7578 r:0.5717
ne_en Dev loss: 0.4692 r:0.7213
ru_en Dev loss: 0.5882 r:0.7069
Current avg r:0.5866 Best avg r: 0.5966
16:32:19,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:32,482 root INFO 
id:en_de cur r: 0.2339 best r: 0.2339
16:32:45,491 root INFO 
id:en_zh cur r: 0.4392 best r: 0.4392
16:32:58,544 root INFO 
id:ro_en cur r: 0.8054 best r: 0.8054
16:33:11,600 root INFO 
id:si_en cur r: 0.5891 best r: 0.5891
16:33:24,668 root INFO 
id:ne_en cur r: 0.7398 best r: 0.7398
16:33:37,637 root INFO 
id:ru_en cur r: 0.7369 best r: 0.7369
16:33:37,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:08,930 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:35:08,936 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:35:08,941 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:35:08,946 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:35:08,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:35:08,956 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:35:08,961 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:35:22,16 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5192
en_de Dev loss: 0.8454 r:0.2323
en_zh Dev loss: 0.7092 r:0.4508
ro_en Dev loss: 0.3302 r:0.8067
et_en Dev loss: 0.4080 r:0.6768
si_en Dev loss: 0.6433 r:0.5971
ne_en Dev loss: 0.4203 r:0.7412
ru_en Dev loss: 0.4355 r:0.7431
Current avg r:0.6068 Best avg r: 0.6068
16:39:17,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:43,270 root INFO 
id:en_zh cur r: 0.4550 best r: 0.4550
16:39:56,367 root INFO 
id:ro_en cur r: 0.8113 best r: 0.8113
16:40:09,483 root INFO 
id:si_en cur r: 0.6061 best r: 0.6061
16:40:22,599 root INFO 
id:ne_en cur r: 0.7445 best r: 0.7445
16:40:35,589 root INFO 
id:ru_en cur r: 0.7526 best r: 0.7526
16:40:35,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:06,961 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:42:06,968 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:42:06,973 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:42:06,979 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:42:06,983 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:42:06,990 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:42:06,995 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:42:20,66 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5346
en_de Dev loss: 0.8492 r:0.2316
en_zh Dev loss: 0.6935 r:0.4601
ro_en Dev loss: 0.3132 r:0.8124
et_en Dev loss: 0.3929 r:0.6754
si_en Dev loss: 0.6173 r:0.6073
ne_en Dev loss: 0.3702 r:0.7454
ru_en Dev loss: 0.4141 r:0.7503
Current avg r:0.6118 Best avg r: 0.6118
16:46:15,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:33,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:04,436 root INFO Epoch 1 Global steps: 11400 Train loss: 0.5105
en_de Dev loss: 0.8634 r:0.2264
en_zh Dev loss: 0.7357 r:0.4555
ro_en Dev loss: 0.3500 r:0.8020
et_en Dev loss: 0.4335 r:0.6577
si_en Dev loss: 0.7565 r:0.5827
ne_en Dev loss: 0.4336 r:0.7354
ru_en Dev loss: 0.4689 r:0.7303
Current avg r:0.5986 Best avg r: 0.6118
16:52:59,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:25,259 root INFO 
id:en_zh cur r: 0.4717 best r: 0.4717
16:53:38,293 root INFO 
id:ro_en cur r: 0.8127 best r: 0.8127
16:54:17,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:48,629 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:55:48,635 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:55:48,640 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:55:48,644 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:55:48,649 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:55:48,654 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:55:48,658 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:56:01,709 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5139
en_de Dev loss: 0.8428 r:0.2391
en_zh Dev loss: 0.7133 r:0.4741
ro_en Dev loss: 0.3323 r:0.8095
et_en Dev loss: 0.4062 r:0.6765
si_en Dev loss: 0.6353 r:0.6010
ne_en Dev loss: 0.4166 r:0.7422
ru_en Dev loss: 0.4131 r:0.7494
Current avg r:0.6131 Best avg r: 0.6131
16:59:55,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:21,900 root INFO 
id:en_zh cur r: 0.4737 best r: 0.4737
17:00:34,935 root INFO 
id:ro_en cur r: 0.8168 best r: 0.8168
17:01:13,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:45,109 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4793
en_de Dev loss: 0.8590 r:0.2514
en_zh Dev loss: 0.7546 r:0.4704
ro_en Dev loss: 0.3292 r:0.8137
et_en Dev loss: 0.4198 r:0.6772
si_en Dev loss: 0.7650 r:0.5936
ne_en Dev loss: 0.5063 r:0.7367
ru_en Dev loss: 0.4524 r:0.7472
Current avg r:0.6129 Best avg r: 0.6131
17:06:39,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:52,58 root INFO 
id:en_de cur r: 0.2452 best r: 0.2452
17:07:57,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:28,185 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4982
en_de Dev loss: 0.8599 r:0.2412
en_zh Dev loss: 0.7403 r:0.4735
ro_en Dev loss: 0.3560 r:0.8101
et_en Dev loss: 0.4097 r:0.6797
si_en Dev loss: 0.7514 r:0.5939
ne_en Dev loss: 0.4910 r:0.7405
ru_en Dev loss: 0.4920 r:0.7220
Current avg r:0.6087 Best avg r: 0.6131
17:13:22,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:27,211 root INFO 
id:ne_en cur r: 0.7476 best r: 0.7476
17:14:40,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:11,256 root INFO Epoch 1 Global steps: 13800 Train loss: 0.5088
en_de Dev loss: 0.8726 r:0.2265
en_zh Dev loss: 0.7682 r:0.4643
ro_en Dev loss: 0.3529 r:0.8117
et_en Dev loss: 0.4230 r:0.6787
si_en Dev loss: 0.8101 r:0.5962
ne_en Dev loss: 0.4082 r:0.7463
ru_en Dev loss: 0.4593 r:0.7310
Current avg r:0.6078 Best avg r: 0.6131
17:20:05,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:23,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:54,859 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4954
en_de Dev loss: 0.8568 r:0.1932
en_zh Dev loss: 0.7568 r:0.4698
ro_en Dev loss: 0.3375 r:0.8131
et_en Dev loss: 0.4016 r:0.6736
si_en Dev loss: 0.7214 r:0.6061
ne_en Dev loss: 0.4183 r:0.7388
ru_en Dev loss: 0.4214 r:0.7392
Current avg r:0.6048 Best avg r: 0.6131
17:26:48,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:15,0 root INFO 
id:en_zh cur r: 0.4785 best r: 0.4785
17:28:07,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:38,122 root INFO Epoch 1 Global steps: 15000 Train loss: 0.5423
en_de Dev loss: 0.8709 r:0.2138
en_zh Dev loss: 0.7231 r:0.4820
ro_en Dev loss: 0.3892 r:0.8072
et_en Dev loss: 0.4561 r:0.6608
si_en Dev loss: 0.8746 r:0.5811
ne_en Dev loss: 0.6101 r:0.7267
ru_en Dev loss: 0.5507 r:0.7091
Current avg r:0.5972 Best avg r: 0.6131
17:33:32,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:11,162 root INFO 
id:ro_en cur r: 0.8201 best r: 0.8201
17:34:24,204 root INFO 
id:si_en cur r: 0.6106 best r: 0.6106
17:34:37,246 root INFO 
id:ne_en cur r: 0.7483 best r: 0.7483
17:34:50,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:21,202 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
17:36:21,209 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:36:21,213 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:36:21,218 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
17:36:21,223 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
17:36:21,227 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:36:21,232 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:36:34,271 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4721
en_de Dev loss: 0.8580 r:0.2356
en_zh Dev loss: 0.7278 r:0.4633
ro_en Dev loss: 0.3218 r:0.8175
et_en Dev loss: 0.4057 r:0.6770
si_en Dev loss: 0.6573 r:0.6151
ne_en Dev loss: 0.4372 r:0.7453
ru_en Dev loss: 0.4265 r:0.7464
Current avg r:0.6143 Best avg r: 0.6143
17:40:28,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:46,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:17,152 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
17:43:17,158 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:43:17,163 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:43:17,168 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
17:43:17,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
17:43:17,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:43:17,183 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:43:30,239 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4816
en_de Dev loss: 0.8524 r:0.2636
en_zh Dev loss: 0.7758 r:0.4790
ro_en Dev loss: 0.4152 r:0.8143
et_en Dev loss: 0.4583 r:0.6753
si_en Dev loss: 0.8724 r:0.5971
ne_en Dev loss: 0.4482 r:0.7468
ru_en Dev loss: 0.4944 r:0.7467
Current avg r:0.6175 Best avg r: 0.6175
17:47:24,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:50,580 root INFO 
id:en_zh cur r: 0.4838 best r: 0.4838
17:48:42,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:14,155 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4957
en_de Dev loss: 0.8542 r:0.2357
en_zh Dev loss: 0.7214 r:0.4858
ro_en Dev loss: 0.3541 r:0.8147
et_en Dev loss: 0.4055 r:0.6794
si_en Dev loss: 0.7185 r:0.6045
ne_en Dev loss: 0.4162 r:0.7466
ru_en Dev loss: 0.4660 r:0.7442
Current avg r:0.6158 Best avg r: 0.6175
17:54:08,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:21,277 root INFO 
id:en_de cur r: 0.2544 best r: 0.2544
17:54:47,289 root INFO 
id:ro_en cur r: 0.8204 best r: 0.8204
17:55:13,398 root INFO 
id:ne_en cur r: 0.7529 best r: 0.7529
17:55:26,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:57,419 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
17:56:57,426 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:56:57,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:56:57,435 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
17:56:57,440 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
17:56:57,444 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:56:57,449 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:57:10,482 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4714
en_de Dev loss: 0.8595 r:0.2613
en_zh Dev loss: 0.7508 r:0.4781
ro_en Dev loss: 0.3950 r:0.8138
et_en Dev loss: 0.4500 r:0.6775
si_en Dev loss: 0.7595 r:0.6024
ne_en Dev loss: 0.4887 r:0.7503
ru_en Dev loss: 0.4912 r:0.7408
Current avg r:0.6177 Best avg r: 0.6177
18:01:04,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:22,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:53,226 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4745
en_de Dev loss: 0.8525 r:0.2484
en_zh Dev loss: 0.7280 r:0.4739
ro_en Dev loss: 0.3564 r:0.8158
et_en Dev loss: 0.4100 r:0.6786
si_en Dev loss: 0.6522 r:0.6049
ne_en Dev loss: 0.4119 r:0.7488
ru_en Dev loss: 0.4612 r:0.7320
Current avg r:0.6146 Best avg r: 0.6177
18:07:49,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:07,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:38,878 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4493
en_de Dev loss: 0.9082 r:0.2484
en_zh Dev loss: 0.7965 r:0.4707
ro_en Dev loss: 0.3875 r:0.8151
et_en Dev loss: 0.4405 r:0.6745
si_en Dev loss: 0.7914 r:0.6011
ne_en Dev loss: 0.5146 r:0.7435
ru_en Dev loss: 0.5625 r:0.7179
Current avg r:0.6102 Best avg r: 0.6177
18:14:32,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:45,543 root INFO 
id:en_de cur r: 0.2547 best r: 0.2547
18:15:50,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:21,598 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4243
en_de Dev loss: 0.8623 r:0.2355
en_zh Dev loss: 0.8073 r:0.4499
ro_en Dev loss: 0.3624 r:0.8089
et_en Dev loss: 0.4355 r:0.6643
si_en Dev loss: 0.8095 r:0.5824
ne_en Dev loss: 0.5312 r:0.7369
ru_en Dev loss: 0.5766 r:0.6864
Current avg r:0.5949 Best avg r: 0.6177
18:21:15,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:33,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:04,124 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4528
en_de Dev loss: 0.8419 r:0.2385
en_zh Dev loss: 0.7476 r:0.4700
ro_en Dev loss: 0.3643 r:0.8144
et_en Dev loss: 0.3957 r:0.6749
si_en Dev loss: 0.6910 r:0.6061
ne_en Dev loss: 0.4096 r:0.7456
ru_en Dev loss: 0.4777 r:0.7365
Current avg r:0.6123 Best avg r: 0.6177
18:27:57,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:15,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:46,723 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4579
en_de Dev loss: 0.8554 r:0.2246
en_zh Dev loss: 0.7129 r:0.4697
ro_en Dev loss: 0.3268 r:0.8190
et_en Dev loss: 0.3883 r:0.6788
si_en Dev loss: 0.6569 r:0.6111
ne_en Dev loss: 0.4211 r:0.7507
ru_en Dev loss: 0.4215 r:0.7426
Current avg r:0.6138 Best avg r: 0.6177
18:34:40,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:19,887 root INFO 
id:ro_en cur r: 0.8215 best r: 0.8215
18:35:58,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:29,918 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4801
en_de Dev loss: 0.8438 r:0.2224
en_zh Dev loss: 0.6977 r:0.4811
ro_en Dev loss: 0.3328 r:0.8193
et_en Dev loss: 0.3893 r:0.6771
si_en Dev loss: 0.7335 r:0.6048
ne_en Dev loss: 0.4594 r:0.7455
ru_en Dev loss: 0.4391 r:0.7376
Current avg r:0.6125 Best avg r: 0.6177
18:41:23,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:49,16 root INFO 
id:en_zh cur r: 0.4970 best r: 0.4970
18:42:02,27 root INFO 
id:ro_en cur r: 0.8242 best r: 0.8242
18:42:15,54 root INFO 
id:si_en cur r: 0.6226 best r: 0.6226
18:42:28,105 root INFO 
id:ne_en cur r: 0.7532 best r: 0.7532
18:42:41,40 root INFO 
id:ru_en cur r: 0.7552 best r: 0.7552
18:42:41,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:11,922 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
18:44:11,929 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
18:44:11,935 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
18:44:11,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
18:44:11,945 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
18:44:11,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
18:44:11,956 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
18:44:24,947 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4404
en_de Dev loss: 0.8356 r:0.2531
en_zh Dev loss: 0.6983 r:0.4915
ro_en Dev loss: 0.3258 r:0.8227
et_en Dev loss: 0.3705 r:0.6908
si_en Dev loss: 0.5797 r:0.6255
ne_en Dev loss: 0.3720 r:0.7512
ru_en Dev loss: 0.3975 r:0.7566
Current avg r:0.6274 Best avg r: 0.6274
18:48:18,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:44,95 root INFO 
id:en_zh cur r: 0.5016 best r: 0.5016
18:49:36,56 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:06,917 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4421
en_de Dev loss: 0.8467 r:0.2363
en_zh Dev loss: 0.7140 r:0.5016
ro_en Dev loss: 0.3457 r:0.8214
et_en Dev loss: 0.3994 r:0.6856
si_en Dev loss: 0.6508 r:0.6195
ne_en Dev loss: 0.4898 r:0.7491
ru_en Dev loss: 0.4623 r:0.7396
Current avg r:0.6219 Best avg r: 0.6274
18:55:00,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:13,354 root INFO 
id:en_de cur r: 0.2550 best r: 0.2550
18:56:18,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:49,246 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4299
en_de Dev loss: 0.8381 r:0.2433
en_zh Dev loss: 0.7507 r:0.4781
ro_en Dev loss: 0.3506 r:0.8192
et_en Dev loss: 0.3974 r:0.6844
si_en Dev loss: 0.6829 r:0.6176
ne_en Dev loss: 0.4838 r:0.7421
ru_en Dev loss: 0.4153 r:0.7555
Current avg r:0.6200 Best avg r: 0.6274
19:01:42,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:00,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:31,311 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4526
en_de Dev loss: 0.8776 r:0.2341
en_zh Dev loss: 0.7818 r:0.4736
ro_en Dev loss: 0.3769 r:0.8156
et_en Dev loss: 0.4427 r:0.6745
si_en Dev loss: 0.8887 r:0.5983
ne_en Dev loss: 0.5615 r:0.7349
ru_en Dev loss: 0.5105 r:0.7260
Current avg r:0.6081 Best avg r: 0.6274
19:08:25,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:38,17 root INFO 
id:en_de cur r: 0.2594 best r: 0.2594
19:09:03,961 root INFO 
id:ro_en cur r: 0.8254 best r: 0.8254
19:09:42,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:13,932 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4311
en_de Dev loss: 0.8428 r:0.2431
en_zh Dev loss: 0.7476 r:0.4741
ro_en Dev loss: 0.3263 r:0.8220
et_en Dev loss: 0.3996 r:0.6872
si_en Dev loss: 0.8469 r:0.6102
ne_en Dev loss: 0.5533 r:0.7414
ru_en Dev loss: 0.4677 r:0.7348
Current avg r:0.6161 Best avg r: 0.6274
19:15:07,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:46,827 root INFO 
id:ro_en cur r: 0.8259 best r: 0.8259
19:16:12,870 root INFO 
id:ne_en cur r: 0.7601 best r: 0.7601
19:16:25,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:56,649 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4435
en_de Dev loss: 0.8481 r:0.2152
en_zh Dev loss: 0.6834 r:0.4854
ro_en Dev loss: 0.3139 r:0.8241
et_en Dev loss: 0.3772 r:0.6838
si_en Dev loss: 0.6488 r:0.6233
ne_en Dev loss: 0.4256 r:0.7573
ru_en Dev loss: 0.4031 r:0.7436
Current avg r:0.6190 Best avg r: 0.6274
19:21:50,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:08,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:39,266 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4246
en_de Dev loss: 0.8378 r:0.2383
en_zh Dev loss: 0.7071 r:0.4768
ro_en Dev loss: 0.3397 r:0.8184
et_en Dev loss: 0.3785 r:0.6810
si_en Dev loss: 0.6322 r:0.6207
ne_en Dev loss: 0.3799 r:0.7511
ru_en Dev loss: 0.3888 r:0.7522
Current avg r:0.6198 Best avg r: 0.6274
19:28:32,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:50,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:21,484 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4361
en_de Dev loss: 0.8506 r:0.2145
en_zh Dev loss: 0.7666 r:0.4637
ro_en Dev loss: 0.3521 r:0.8205
et_en Dev loss: 0.3982 r:0.6795
si_en Dev loss: 0.7710 r:0.6150
ne_en Dev loss: 0.5437 r:0.7501
ru_en Dev loss: 0.4703 r:0.7257
Current avg r:0.6099 Best avg r: 0.6274
19:35:15,196 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:33,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:03,965 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4166
en_de Dev loss: 0.8809 r:0.2354
en_zh Dev loss: 0.7863 r:0.4559
ro_en Dev loss: 0.3881 r:0.8185
et_en Dev loss: 0.4254 r:0.6670
si_en Dev loss: 0.7513 r:0.6176
ne_en Dev loss: 0.5232 r:0.7423
ru_en Dev loss: 0.5104 r:0.7094
Current avg r:0.6066 Best avg r: 0.6274
19:41:57,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:15,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:46,619 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4359
en_de Dev loss: 0.8673 r:0.2213
en_zh Dev loss: 0.7312 r:0.4545
ro_en Dev loss: 0.3245 r:0.8230
et_en Dev loss: 0.3961 r:0.6732
si_en Dev loss: 0.6856 r:0.6236
ne_en Dev loss: 0.4262 r:0.7516
ru_en Dev loss: 0.4560 r:0.7258
Current avg r:0.6104 Best avg r: 0.6274
19:48:42,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:00,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:31,426 root INFO Epoch 3 Global steps: 27600 Train loss: 0.4021
en_de Dev loss: 0.9076 r:0.2369
en_zh Dev loss: 0.8423 r:0.4639
ro_en Dev loss: 0.4197 r:0.8219
et_en Dev loss: 0.4591 r:0.6681
si_en Dev loss: 0.8661 r:0.6101
ne_en Dev loss: 0.5303 r:0.7441
ru_en Dev loss: 0.5662 r:0.7166
Current avg r:0.6088 Best avg r: 0.6274
19:55:25,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:43,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:14,251 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3946
en_de Dev loss: 0.8842 r:0.2195
en_zh Dev loss: 0.7436 r:0.4506
ro_en Dev loss: 0.3335 r:0.8236
et_en Dev loss: 0.4149 r:0.6634
si_en Dev loss: 0.7601 r:0.6095
ne_en Dev loss: 0.4561 r:0.7493
ru_en Dev loss: 0.5245 r:0.6907
Current avg r:0.6010 Best avg r: 0.6274
20:02:07,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:25,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:56,317 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3879
en_de Dev loss: 0.8596 r:0.2059
en_zh Dev loss: 0.8003 r:0.4414
ro_en Dev loss: 0.3361 r:0.8213
et_en Dev loss: 0.4005 r:0.6713
si_en Dev loss: 0.7104 r:0.6119
ne_en Dev loss: 0.4789 r:0.7385
ru_en Dev loss: 0.4691 r:0.7196
Current avg r:0.6014 Best avg r: 0.6274
20:08:49,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:10:07,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:38,294 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4121
en_de Dev loss: 0.8633 r:0.2063
en_zh Dev loss: 0.8080 r:0.4476
ro_en Dev loss: 0.3416 r:0.8209
et_en Dev loss: 0.4103 r:0.6666
si_en Dev loss: 0.8009 r:0.6028
ne_en Dev loss: 0.4736 r:0.7424
ru_en Dev loss: 0.5063 r:0.7063
Current avg r:0.5990 Best avg r: 0.6274
20:15:31,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:49,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:20,279 root INFO Epoch 3 Global steps: 30000 Train loss: 0.4052
en_de Dev loss: 0.8817 r:0.1859
en_zh Dev loss: 0.7834 r:0.4416
ro_en Dev loss: 0.3861 r:0.8178
et_en Dev loss: 0.4310 r:0.6534
si_en Dev loss: 0.7864 r:0.6017
ne_en Dev loss: 0.5220 r:0.7327
ru_en Dev loss: 0.5235 r:0.7023
Current avg r:0.5908 Best avg r: 0.6274
20:22:13,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:31,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:02,358 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3904
en_de Dev loss: 0.8507 r:0.2257
en_zh Dev loss: 0.7865 r:0.4501
ro_en Dev loss: 0.3518 r:0.8254
et_en Dev loss: 0.3953 r:0.6712
si_en Dev loss: 0.6571 r:0.6187
ne_en Dev loss: 0.4165 r:0.7439
ru_en Dev loss: 0.4665 r:0.7264
Current avg r:0.6088 Best avg r: 0.6274
20:28:55,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:08,528 root INFO 
id:en_de cur r: 0.2781 best r: 0.2781
20:30:13,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:44,323 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3821
en_de Dev loss: 0.8481 r:0.2645
en_zh Dev loss: 0.7369 r:0.4424
ro_en Dev loss: 0.3323 r:0.8224
et_en Dev loss: 0.3946 r:0.6691
si_en Dev loss: 0.6875 r:0.6102
ne_en Dev loss: 0.4570 r:0.7388
ru_en Dev loss: 0.4555 r:0.7215
Current avg r:0.6098 Best avg r: 0.6274
20:35:38,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:51,177 root INFO 
id:en_de cur r: 0.3252 best r: 0.3252
20:36:56,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:27,583 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3821
en_de Dev loss: 0.8788 r:0.2931
en_zh Dev loss: 0.8169 r:0.4328
ro_en Dev loss: 0.4291 r:0.8115
et_en Dev loss: 0.4590 r:0.6534
si_en Dev loss: 0.9725 r:0.5767
ne_en Dev loss: 0.6983 r:0.7312
ru_en Dev loss: 0.5903 r:0.6847
Current avg r:0.5976 Best avg r: 0.6274
20:42:21,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:39,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:10,690 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3853
en_de Dev loss: 0.8412 r:0.2588
en_zh Dev loss: 0.7621 r:0.4571
ro_en Dev loss: 0.3522 r:0.8238
et_en Dev loss: 0.3933 r:0.6752
si_en Dev loss: 0.6673 r:0.6216
ne_en Dev loss: 0.4177 r:0.7424
ru_en Dev loss: 0.4666 r:0.7259
Current avg r:0.6150 Best avg r: 0.6274
20:49:04,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:22,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:53,704 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3998
en_de Dev loss: 0.8353 r:0.2828
en_zh Dev loss: 0.7983 r:0.4374
ro_en Dev loss: 0.3637 r:0.8153
et_en Dev loss: 0.4040 r:0.6633
si_en Dev loss: 0.7121 r:0.6023
ne_en Dev loss: 0.4825 r:0.7418
ru_en Dev loss: 0.4790 r:0.7117
Current avg r:0.6078 Best avg r: 0.6274
20:55:48,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:06,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:37,722 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3998
en_de Dev loss: 0.8246 r:0.2854
en_zh Dev loss: 0.7548 r:0.4670
ro_en Dev loss: 0.3610 r:0.8251
et_en Dev loss: 0.3957 r:0.6733
si_en Dev loss: 0.6792 r:0.6154
ne_en Dev loss: 0.4489 r:0.7427
ru_en Dev loss: 0.4649 r:0.7313
Current avg r:0.6200 Best avg r: 0.6274
21:02:31,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:49,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:19,962 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3702
en_de Dev loss: 0.8248 r:0.2912
en_zh Dev loss: 0.7959 r:0.4571
ro_en Dev loss: 0.3800 r:0.8221
et_en Dev loss: 0.4042 r:0.6714
si_en Dev loss: 0.7464 r:0.6064
ne_en Dev loss: 0.5464 r:0.7389
ru_en Dev loss: 0.4819 r:0.7243
Current avg r:0.6159 Best avg r: 0.6274
21:09:13,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:26,862 root INFO 
id:en_de cur r: 0.3263 best r: 0.3263
21:10:31,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:12:02,685 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3686
en_de Dev loss: 0.8278 r:0.2900
en_zh Dev loss: 0.7808 r:0.4636
ro_en Dev loss: 0.3681 r:0.8223
et_en Dev loss: 0.4183 r:0.6696
si_en Dev loss: 0.8808 r:0.5978
ne_en Dev loss: 0.5621 r:0.7409
ru_en Dev loss: 0.5340 r:0.7147
Current avg r:0.6141 Best avg r: 0.6274
21:15:56,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:14,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:45,250 root INFO Epoch 3 Global steps: 35400 Train loss: 0.4107
en_de Dev loss: 0.8239 r:0.2780
en_zh Dev loss: 0.7054 r:0.4667
ro_en Dev loss: 0.2950 r:0.8251
et_en Dev loss: 0.3796 r:0.6801
si_en Dev loss: 0.6260 r:0.6210
ne_en Dev loss: 0.4305 r:0.7545
ru_en Dev loss: 0.4045 r:0.7435
Current avg r:0.6241 Best avg r: 0.6274
21:22:38,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:56,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:27,221 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3607
en_de Dev loss: 0.8467 r:0.2640
en_zh Dev loss: 0.8214 r:0.4451
ro_en Dev loss: 0.3754 r:0.8194
et_en Dev loss: 0.4048 r:0.6696
si_en Dev loss: 0.7684 r:0.6001
ne_en Dev loss: 0.4954 r:0.7435
ru_en Dev loss: 0.4957 r:0.7213
Current avg r:0.6090 Best avg r: 0.6274
21:29:21,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:39,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:09,966 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3454
en_de Dev loss: 0.8218 r:0.2838
en_zh Dev loss: 0.7427 r:0.4577
ro_en Dev loss: 0.3422 r:0.8218
et_en Dev loss: 0.3882 r:0.6741
si_en Dev loss: 0.6976 r:0.6100
ne_en Dev loss: 0.3916 r:0.7490
ru_en Dev loss: 0.4529 r:0.7290
Current avg r:0.6179 Best avg r: 0.6274
21:36:02,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:20,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:51,569 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3494
en_de Dev loss: 0.8273 r:0.2793
en_zh Dev loss: 0.7984 r:0.4451
ro_en Dev loss: 0.3904 r:0.8210
et_en Dev loss: 0.4091 r:0.6742
si_en Dev loss: 0.8943 r:0.5987
ne_en Dev loss: 0.5404 r:0.7386
ru_en Dev loss: 0.5104 r:0.7152
Current avg r:0.6103 Best avg r: 0.6274
21:42:44,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:02,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:33,409 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3609
en_de Dev loss: 0.8195 r:0.2841
en_zh Dev loss: 0.7362 r:0.4384
ro_en Dev loss: 0.3067 r:0.8236
et_en Dev loss: 0.3885 r:0.6730
si_en Dev loss: 0.6741 r:0.6039
ne_en Dev loss: 0.4214 r:0.7363
ru_en Dev loss: 0.4175 r:0.7254
Current avg r:0.6121 Best avg r: 0.6274
21:49:26,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:44,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:15,448 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3229
en_de Dev loss: 0.8905 r:0.2676
en_zh Dev loss: 0.9380 r:0.4165
ro_en Dev loss: 0.4432 r:0.8162
et_en Dev loss: 0.4550 r:0.6638
si_en Dev loss: 0.9898 r:0.5888
ne_en Dev loss: 0.5872 r:0.7287
ru_en Dev loss: 0.6010 r:0.6949
Current avg r:0.5966 Best avg r: 0.6274
21:56:09,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:26,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:57,823 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3323
en_de Dev loss: 0.8670 r:0.2338
en_zh Dev loss: 0.7990 r:0.4497
ro_en Dev loss: 0.3582 r:0.8200
et_en Dev loss: 0.4085 r:0.6619
si_en Dev loss: 0.7799 r:0.5989
ne_en Dev loss: 0.4852 r:0.7345
ru_en Dev loss: 0.5039 r:0.7059
Current avg r:0.6006 Best avg r: 0.6274
22:02:51,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:09,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:40,86 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3350
en_de Dev loss: 0.8499 r:0.2442
en_zh Dev loss: 0.7830 r:0.4580
ro_en Dev loss: 0.3488 r:0.8235
et_en Dev loss: 0.3998 r:0.6748
si_en Dev loss: 0.6608 r:0.6136
ne_en Dev loss: 0.4137 r:0.7403
ru_en Dev loss: 0.4327 r:0.7330
Current avg r:0.6125 Best avg r: 0.6274
22:09:33,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:51,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:22,804 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3232
en_de Dev loss: 0.8377 r:0.2808
en_zh Dev loss: 0.8006 r:0.4369
ro_en Dev loss: 0.3946 r:0.8171
et_en Dev loss: 0.4213 r:0.6640
si_en Dev loss: 0.8103 r:0.5922
ne_en Dev loss: 0.5096 r:0.7330
ru_en Dev loss: 0.5124 r:0.7136
Current avg r:0.6054 Best avg r: 0.6274
22:16:17,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:35,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:06,410 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3050
en_de Dev loss: 0.8617 r:0.2665
en_zh Dev loss: 0.8832 r:0.4194
ro_en Dev loss: 0.3913 r:0.8178
et_en Dev loss: 0.4296 r:0.6568
si_en Dev loss: 0.8462 r:0.5852
ne_en Dev loss: 0.5534 r:0.7304
ru_en Dev loss: 0.5225 r:0.7067
Current avg r:0.5975 Best avg r: 0.6274
22:23:00,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:18,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:25:49,886 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3371
en_de Dev loss: 0.8394 r:0.2621
en_zh Dev loss: 0.8367 r:0.4236
ro_en Dev loss: 0.3316 r:0.8205
et_en Dev loss: 0.3986 r:0.6682
si_en Dev loss: 0.7090 r:0.5962
ne_en Dev loss: 0.4636 r:0.7349
ru_en Dev loss: 0.4485 r:0.7194
Current avg r:0.6036 Best avg r: 0.6274
22:29:44,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:02,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:33,124 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3441
en_de Dev loss: 0.8453 r:0.2490
en_zh Dev loss: 0.8085 r:0.4342
ro_en Dev loss: 0.3347 r:0.8236
et_en Dev loss: 0.3997 r:0.6697
si_en Dev loss: 0.7996 r:0.5910
ne_en Dev loss: 0.4935 r:0.7343
ru_en Dev loss: 0.5281 r:0.6989
Current avg r:0.6001 Best avg r: 0.6274
22:36:27,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:45,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:16,458 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3308
en_de Dev loss: 0.8192 r:0.2787
en_zh Dev loss: 0.7693 r:0.4414
ro_en Dev loss: 0.3205 r:0.8258
et_en Dev loss: 0.3872 r:0.6765
si_en Dev loss: 0.6680 r:0.6058
ne_en Dev loss: 0.4105 r:0.7441
ru_en Dev loss: 0.4031 r:0.7424
Current avg r:0.6164 Best avg r: 0.6274
22:43:09,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:27,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:59,62 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3114
en_de Dev loss: 0.8337 r:0.2802
en_zh Dev loss: 0.8629 r:0.4214
ro_en Dev loss: 0.3724 r:0.8191
et_en Dev loss: 0.4114 r:0.6673
si_en Dev loss: 0.8639 r:0.5874
ne_en Dev loss: 0.5729 r:0.7331
ru_en Dev loss: 0.5144 r:0.7167
Current avg r:0.6036 Best avg r: 0.6274
22:49:52,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:11,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:42,198 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3107
en_de Dev loss: 0.8440 r:0.2705
en_zh Dev loss: 0.8742 r:0.4369
ro_en Dev loss: 0.3708 r:0.8241
et_en Dev loss: 0.4032 r:0.6789
si_en Dev loss: 0.8143 r:0.5964
ne_en Dev loss: 0.5619 r:0.7371
ru_en Dev loss: 0.4516 r:0.7463
Current avg r:0.6129 Best avg r: 0.6274
22:56:35,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:53,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:25,86 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3253
en_de Dev loss: 0.8483 r:0.2649
en_zh Dev loss: 0.8149 r:0.4495
ro_en Dev loss: 0.3606 r:0.8191
et_en Dev loss: 0.4038 r:0.6720
si_en Dev loss: 0.8304 r:0.5901
ne_en Dev loss: 0.5807 r:0.7291
ru_en Dev loss: 0.5063 r:0.7142
Current avg r:0.6056 Best avg r: 0.6274
23:03:19,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:37,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:08,555 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3118
en_de Dev loss: 0.8944 r:0.2301
en_zh Dev loss: 0.8143 r:0.4301
ro_en Dev loss: 0.3891 r:0.8169
et_en Dev loss: 0.4104 r:0.6694
si_en Dev loss: 0.8540 r:0.5866
ne_en Dev loss: 0.5179 r:0.7321
ru_en Dev loss: 0.5084 r:0.7133
Current avg r:0.5969 Best avg r: 0.6274
23:10:04,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:22,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:53,573 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2881
en_de Dev loss: 0.8585 r:0.2517
en_zh Dev loss: 0.7877 r:0.4504
ro_en Dev loss: 0.3595 r:0.8215
et_en Dev loss: 0.4080 r:0.6619
si_en Dev loss: 0.8606 r:0.5760
ne_en Dev loss: 0.5000 r:0.7358
ru_en Dev loss: 0.4955 r:0.7049
Current avg r:0.6003 Best avg r: 0.6274
23:16:47,915 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:06,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:37,119 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2826
en_de Dev loss: 0.8625 r:0.2408
en_zh Dev loss: 0.7996 r:0.4487
ro_en Dev loss: 0.3473 r:0.8264
et_en Dev loss: 0.4032 r:0.6670
si_en Dev loss: 0.7437 r:0.5893
ne_en Dev loss: 0.4612 r:0.7401
ru_en Dev loss: 0.4582 r:0.7295
Current avg r:0.6060 Best avg r: 0.6274
23:23:31,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:49,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:20,235 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2958
en_de Dev loss: 0.8715 r:0.2295
en_zh Dev loss: 0.8486 r:0.4304
ro_en Dev loss: 0.3950 r:0.8212
et_en Dev loss: 0.4301 r:0.6585
si_en Dev loss: 0.9274 r:0.5753
ne_en Dev loss: 0.6183 r:0.7325
ru_en Dev loss: 0.5119 r:0.7146
Current avg r:0.5946 Best avg r: 0.6274
23:30:14,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:32,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:03,179 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2887
en_de Dev loss: 0.8621 r:0.2583
en_zh Dev loss: 0.8314 r:0.4466
ro_en Dev loss: 0.3658 r:0.8247
et_en Dev loss: 0.4111 r:0.6672
si_en Dev loss: 0.8124 r:0.5880
ne_en Dev loss: 0.4588 r:0.7391
ru_en Dev loss: 0.4846 r:0.7221
Current avg r:0.6066 Best avg r: 0.6274
23:36:57,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:38:15,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:46,725 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2898
en_de Dev loss: 0.8593 r:0.2441
en_zh Dev loss: 0.8131 r:0.4231
ro_en Dev loss: 0.3634 r:0.8179
et_en Dev loss: 0.4097 r:0.6591
si_en Dev loss: 0.8147 r:0.5782
ne_en Dev loss: 0.4793 r:0.7363
ru_en Dev loss: 0.4900 r:0.7076
Current avg r:0.5952 Best avg r: 0.6274
23:43:40,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:58,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:29,814 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2986
en_de Dev loss: 0.8690 r:0.2238
en_zh Dev loss: 0.8436 r:0.4162
ro_en Dev loss: 0.3700 r:0.8171
et_en Dev loss: 0.4063 r:0.6624
si_en Dev loss: 0.8282 r:0.5693
ne_en Dev loss: 0.5016 r:0.7406
ru_en Dev loss: 0.4754 r:0.7157
Current avg r:0.5922 Best avg r: 0.6274
23:50:23,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:42,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:13,309 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2854
en_de Dev loss: 0.8915 r:0.2302
en_zh Dev loss: 0.8573 r:0.4334
ro_en Dev loss: 0.4032 r:0.8159
et_en Dev loss: 0.4266 r:0.6596
si_en Dev loss: 0.8669 r:0.5771
ne_en Dev loss: 0.5409 r:0.7401
ru_en Dev loss: 0.5336 r:0.7155
Current avg r:0.5960 Best avg r: 0.6274
23:57:06,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:24,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:55,851 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2802
en_de Dev loss: 0.8704 r:0.2186
en_zh Dev loss: 0.7519 r:0.4422
ro_en Dev loss: 0.3208 r:0.8229
et_en Dev loss: 0.3930 r:0.6711
si_en Dev loss: 0.6974 r:0.5947
ne_en Dev loss: 0.3930 r:0.7437
ru_en Dev loss: 0.4261 r:0.7336
Current avg r:0.6038 Best avg r: 0.6274
00:03:49,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:07,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:06:38,895 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2774
en_de Dev loss: 0.9190 r:0.1923
en_zh Dev loss: 0.9831 r:0.4292
ro_en Dev loss: 0.4472 r:0.8098
et_en Dev loss: 0.4575 r:0.6569
si_en Dev loss: 0.9641 r:0.5726
ne_en Dev loss: 0.5727 r:0.7290
ru_en Dev loss: 0.6110 r:0.7004
Current avg r:0.5843 Best avg r: 0.6274
00:10:32,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:50,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:13:21,691 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2825
en_de Dev loss: 0.8782 r:0.2316
en_zh Dev loss: 0.8477 r:0.4448
ro_en Dev loss: 0.3874 r:0.8202
et_en Dev loss: 0.4250 r:0.6654
si_en Dev loss: 0.7790 r:0.5917
ne_en Dev loss: 0.4626 r:0.7305
ru_en Dev loss: 0.4876 r:0.7331
Current avg r:0.6025 Best avg r: 0.6274
00:17:15,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:33,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:04,791 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2686
en_de Dev loss: 0.8624 r:0.2308
en_zh Dev loss: 0.8575 r:0.4470
ro_en Dev loss: 0.3794 r:0.8186
et_en Dev loss: 0.4244 r:0.6606
si_en Dev loss: 0.8517 r:0.5819
ne_en Dev loss: 0.5141 r:0.7260
ru_en Dev loss: 0.4999 r:0.7316
Current avg r:0.5995 Best avg r: 0.6274
00:23:58,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:25:17,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:26:48,201 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2641
en_de Dev loss: 0.8842 r:0.1756
en_zh Dev loss: 0.8882 r:0.4116
ro_en Dev loss: 0.3715 r:0.8135
et_en Dev loss: 0.4103 r:0.6581
si_en Dev loss: 0.7840 r:0.5820
ne_en Dev loss: 0.5149 r:0.7344
ru_en Dev loss: 0.5111 r:0.7027
Current avg r:0.5826 Best avg r: 0.6274
00:30:42,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:32:00,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:33:31,602 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2850
en_de Dev loss: 0.8697 r:0.2014
en_zh Dev loss: 0.8483 r:0.4363
ro_en Dev loss: 0.3824 r:0.8175
et_en Dev loss: 0.4168 r:0.6645
si_en Dev loss: 0.8798 r:0.5832
ne_en Dev loss: 0.5440 r:0.7330
ru_en Dev loss: 0.5157 r:0.7165
Current avg r:0.5932 Best avg r: 0.6274
00:37:26,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:38:44,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:15,108 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2713
en_de Dev loss: 0.8541 r:0.2140
en_zh Dev loss: 0.7911 r:0.4405
ro_en Dev loss: 0.3383 r:0.8242
et_en Dev loss: 0.4167 r:0.6727
si_en Dev loss: 0.7100 r:0.5904
ne_en Dev loss: 0.4200 r:0.7298
ru_en Dev loss: 0.3979 r:0.7414
Current avg r:0.6019 Best avg r: 0.6274
00:44:08,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:26,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:58,119 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2707
en_de Dev loss: 0.8587 r:0.2263
en_zh Dev loss: 0.8688 r:0.4350
ro_en Dev loss: 0.3836 r:0.8222
et_en Dev loss: 0.4174 r:0.6656
si_en Dev loss: 0.9052 r:0.5771
ne_en Dev loss: 0.5713 r:0.7313
ru_en Dev loss: 0.5047 r:0.7191
Current avg r:0.5967 Best avg r: 0.6274
00:50:53,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:11,405 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:53:42,514 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2397
en_de Dev loss: 0.8806 r:0.2316
en_zh Dev loss: 0.8783 r:0.4237
ro_en Dev loss: 0.3896 r:0.8169
et_en Dev loss: 0.4214 r:0.6651
si_en Dev loss: 0.9307 r:0.5641
ne_en Dev loss: 0.6089 r:0.7302
ru_en Dev loss: 0.4926 r:0.7264
Current avg r:0.5940 Best avg r: 0.6274
00:57:36,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:54,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:00:26,106 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2404
en_de Dev loss: 0.8479 r:0.2310
en_zh Dev loss: 0.8152 r:0.4288
ro_en Dev loss: 0.3709 r:0.8174
et_en Dev loss: 0.4128 r:0.6668
si_en Dev loss: 0.7881 r:0.5775
ne_en Dev loss: 0.5176 r:0.7303
ru_en Dev loss: 0.4563 r:0.7252
Current avg r:0.5967 Best avg r: 0.6274
01:04:19,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:37,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:09,63 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2432
en_de Dev loss: 0.8591 r:0.2595
en_zh Dev loss: 0.8651 r:0.4265
ro_en Dev loss: 0.3864 r:0.8242
et_en Dev loss: 0.4104 r:0.6718
si_en Dev loss: 0.8725 r:0.5762
ne_en Dev loss: 0.5460 r:0.7320
ru_en Dev loss: 0.5434 r:0.7087
Current avg r:0.5999 Best avg r: 0.6274
01:11:02,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:20,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:13:51,839 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2390
en_de Dev loss: 0.8793 r:0.2542
en_zh Dev loss: 0.9202 r:0.4261
ro_en Dev loss: 0.4052 r:0.8203
et_en Dev loss: 0.4437 r:0.6599
si_en Dev loss: 0.9681 r:0.5659
ne_en Dev loss: 0.6218 r:0.7250
ru_en Dev loss: 0.5318 r:0.7179
Current avg r:0.5956 Best avg r: 0.6274
01:17:45,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:03,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:20:34,689 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2497
en_de Dev loss: 0.8719 r:0.2519
en_zh Dev loss: 0.8763 r:0.4192
ro_en Dev loss: 0.3712 r:0.8180
et_en Dev loss: 0.4278 r:0.6561
si_en Dev loss: 0.9403 r:0.5615
ne_en Dev loss: 0.5665 r:0.7264
ru_en Dev loss: 0.5219 r:0.7108
Current avg r:0.5920 Best avg r: 0.6274
01:24:28,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:46,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:27:17,479 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2383
en_de Dev loss: 0.8655 r:0.2324
en_zh Dev loss: 0.8401 r:0.4206
ro_en Dev loss: 0.3568 r:0.8185
et_en Dev loss: 0.4148 r:0.6567
si_en Dev loss: 0.9199 r:0.5652
ne_en Dev loss: 0.5571 r:0.7278
ru_en Dev loss: 0.4687 r:0.7215
Current avg r:0.5918 Best avg r: 0.6274
01:31:11,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:32:29,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:00,263 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2366
en_de Dev loss: 0.9109 r:0.2081
en_zh Dev loss: 0.9480 r:0.4295
ro_en Dev loss: 0.4536 r:0.8156
et_en Dev loss: 0.4636 r:0.6558
si_en Dev loss: 1.0544 r:0.5645
ne_en Dev loss: 0.6410 r:0.7242
ru_en Dev loss: 0.5621 r:0.7169
Current avg r:0.5878 Best avg r: 0.6274
01:37:53,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:39:11,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:40:42,796 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2417
en_de Dev loss: 0.8698 r:0.2183
en_zh Dev loss: 0.9145 r:0.4226
ro_en Dev loss: 0.3925 r:0.8112
et_en Dev loss: 0.4412 r:0.6445
si_en Dev loss: 0.9524 r:0.5553
ne_en Dev loss: 0.6653 r:0.7229
ru_en Dev loss: 0.5569 r:0.6924
Current avg r:0.5810 Best avg r: 0.6274
01:44:36,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:45:54,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:47:25,733 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2438
en_de Dev loss: 0.8893 r:0.2135
en_zh Dev loss: 0.8813 r:0.4422
ro_en Dev loss: 0.4186 r:0.8196
et_en Dev loss: 0.4330 r:0.6591
si_en Dev loss: 0.8723 r:0.5721
ne_en Dev loss: 0.5509 r:0.7301
ru_en Dev loss: 0.5271 r:0.7206
Current avg r:0.5939 Best avg r: 0.6274
01:51:19,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:52:37,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:54:08,90 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2442
en_de Dev loss: 0.8738 r:0.2291
en_zh Dev loss: 0.8919 r:0.4299
ro_en Dev loss: 0.4022 r:0.8173
et_en Dev loss: 0.4409 r:0.6521
si_en Dev loss: 0.9004 r:0.5634
ne_en Dev loss: 0.5748 r:0.7232
ru_en Dev loss: 0.5219 r:0.7096
Current avg r:0.5892 Best avg r: 0.6274
01:58:01,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:59:19,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:50,946 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2507
en_de Dev loss: 0.8823 r:0.1891
en_zh Dev loss: 0.8986 r:0.4266
ro_en Dev loss: 0.4072 r:0.8152
et_en Dev loss: 0.4318 r:0.6533
si_en Dev loss: 0.8144 r:0.5739
ne_en Dev loss: 0.5400 r:0.7269
ru_en Dev loss: 0.5192 r:0.7141
Current avg r:0.5856 Best avg r: 0.6274
02:04:45,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:04,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:35,187 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2357
en_de Dev loss: 0.8672 r:0.1963
en_zh Dev loss: 0.8636 r:0.4396
ro_en Dev loss: 0.3868 r:0.8194
et_en Dev loss: 0.4368 r:0.6499
si_en Dev loss: 0.8905 r:0.5683
ne_en Dev loss: 0.5374 r:0.7240
ru_en Dev loss: 0.4866 r:0.7172
Current avg r:0.5878 Best avg r: 0.6274
02:11:30,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:48,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:19,604 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2459
en_de Dev loss: 0.8757 r:0.1825
en_zh Dev loss: 0.7860 r:0.4411
ro_en Dev loss: 0.3324 r:0.8190
et_en Dev loss: 0.4110 r:0.6672
si_en Dev loss: 0.7285 r:0.5760
ne_en Dev loss: 0.4719 r:0.7291
ru_en Dev loss: 0.4366 r:0.7285
Current avg r:0.5919 Best avg r: 0.6274
02:18:14,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:19:32,562 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:21:03,641 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2493
en_de Dev loss: 0.8859 r:0.2001
en_zh Dev loss: 0.8289 r:0.4441
ro_en Dev loss: 0.3573 r:0.8184
et_en Dev loss: 0.4290 r:0.6551
si_en Dev loss: 0.7572 r:0.5788
ne_en Dev loss: 0.4816 r:0.7256
ru_en Dev loss: 0.4675 r:0.7213
Current avg r:0.5919 Best avg r: 0.6274
02:24:57,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:26:15,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:46,843 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2510
en_de Dev loss: 0.8872 r:0.1960
en_zh Dev loss: 0.9105 r:0.4220
ro_en Dev loss: 0.3925 r:0.8135
et_en Dev loss: 0.4456 r:0.6443
si_en Dev loss: 0.9668 r:0.5562
ne_en Dev loss: 0.6601 r:0.7204
ru_en Dev loss: 0.5683 r:0.6918
Current avg r:0.5777 Best avg r: 0.6274
02:31:43,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:33:01,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:34:32,631 root INFO Epoch 7 Global steps: 63600 Train loss: 0.2077
en_de Dev loss: 0.8794 r:0.2037
en_zh Dev loss: 0.8692 r:0.4428
ro_en Dev loss: 0.3876 r:0.8171
et_en Dev loss: 0.4374 r:0.6488
si_en Dev loss: 0.9360 r:0.5626
ne_en Dev loss: 0.5472 r:0.7191
ru_en Dev loss: 0.5027 r:0.7211
Current avg r:0.5879 Best avg r: 0.6274
02:38:27,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:39:45,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:41:16,559 root INFO Epoch 7 Global steps: 64200 Train loss: 0.2270
en_de Dev loss: 0.8924 r:0.1977
en_zh Dev loss: 0.8472 r:0.4465
ro_en Dev loss: 0.3843 r:0.8174
et_en Dev loss: 0.4360 r:0.6539
si_en Dev loss: 0.8915 r:0.5699
ne_en Dev loss: 0.5680 r:0.7183
ru_en Dev loss: 0.5250 r:0.7204
Current avg r:0.5891 Best avg r: 0.6274
02:45:10,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:46:28,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:47:59,725 root INFO Epoch 7 Global steps: 64800 Train loss: 0.2079
en_de Dev loss: 0.8734 r:0.1949
en_zh Dev loss: 0.8213 r:0.4365
ro_en Dev loss: 0.3461 r:0.8192
et_en Dev loss: 0.4263 r:0.6505
si_en Dev loss: 0.7884 r:0.5655
ne_en Dev loss: 0.4898 r:0.7136
ru_en Dev loss: 0.4716 r:0.7163
Current avg r:0.5852 Best avg r: 0.6274
02:51:53,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:53:11,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:54:43,36 root INFO Epoch 7 Global steps: 65400 Train loss: 0.2230
en_de Dev loss: 0.8789 r:0.2081
en_zh Dev loss: 0.8582 r:0.4433
ro_en Dev loss: 0.3736 r:0.8154
et_en Dev loss: 0.4494 r:0.6361
si_en Dev loss: 0.9072 r:0.5604
ne_en Dev loss: 0.5869 r:0.7206
ru_en Dev loss: 0.4881 r:0.7163
Current avg r:0.5857 Best avg r: 0.6274
02:58:37,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:59:55,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:01:26,966 root INFO Epoch 7 Global steps: 66000 Train loss: 0.2174
en_de Dev loss: 0.8813 r:0.2161
en_zh Dev loss: 0.8488 r:0.4431
ro_en Dev loss: 0.3766 r:0.8144
et_en Dev loss: 0.4621 r:0.6350
si_en Dev loss: 0.8662 r:0.5667
ne_en Dev loss: 0.5575 r:0.7209
ru_en Dev loss: 0.4602 r:0.7320
Current avg r:0.5897 Best avg r: 0.6274
03:05:21,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:06:39,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:11,99 root INFO Epoch 7 Global steps: 66600 Train loss: 0.2115
en_de Dev loss: 0.8722 r:0.1992
en_zh Dev loss: 0.8497 r:0.4345
ro_en Dev loss: 0.3791 r:0.8132
et_en Dev loss: 0.4511 r:0.6410
si_en Dev loss: 0.7822 r:0.5715
ne_en Dev loss: 0.5202 r:0.7253
ru_en Dev loss: 0.4685 r:0.7213
Current avg r:0.5866 Best avg r: 0.6274
03:12:05,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:23,772 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:54,784 root INFO Epoch 7 Global steps: 67200 Train loss: 0.2219
en_de Dev loss: 0.9025 r:0.2329
en_zh Dev loss: 0.8706 r:0.4342
ro_en Dev loss: 0.4073 r:0.8031
et_en Dev loss: 0.4916 r:0.6154
si_en Dev loss: 1.0190 r:0.5381
ne_en Dev loss: 0.6982 r:0.7224
ru_en Dev loss: 0.5437 r:0.7046
Current avg r:0.5787 Best avg r: 0.6274
03:18:48,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:20:06,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:21:37,663 root INFO Epoch 7 Global steps: 67800 Train loss: 0.2073
en_de Dev loss: 0.8533 r:0.2358
en_zh Dev loss: 0.8307 r:0.4417
ro_en Dev loss: 0.3736 r:0.8135
et_en Dev loss: 0.4475 r:0.6378
si_en Dev loss: 0.9278 r:0.5609
ne_en Dev loss: 0.5249 r:0.7231
ru_en Dev loss: 0.5194 r:0.7114
Current avg r:0.5892 Best avg r: 0.6274
03:25:30,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:26:48,201 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:28:18,991 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2088
en_de Dev loss: 0.8949 r:0.2033
en_zh Dev loss: 0.9147 r:0.4282
ro_en Dev loss: 0.4095 r:0.8159
et_en Dev loss: 0.4577 r:0.6450
si_en Dev loss: 0.9639 r:0.5622
ne_en Dev loss: 0.6517 r:0.7183
ru_en Dev loss: 0.5783 r:0.7051
Current avg r:0.5826 Best avg r: 0.6274
03:32:12,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:33:29,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:35:00,791 root INFO Epoch 7 Global steps: 69000 Train loss: 0.2169
en_de Dev loss: 0.8852 r:0.2162
en_zh Dev loss: 0.9058 r:0.4378
ro_en Dev loss: 0.3997 r:0.8136
et_en Dev loss: 0.4562 r:0.6445
si_en Dev loss: 0.9796 r:0.5492
ne_en Dev loss: 0.6302 r:0.7089
ru_en Dev loss: 0.5242 r:0.7136
Current avg r:0.5834 Best avg r: 0.6274
03:38:53,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:11,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:42,630 root INFO Epoch 7 Global steps: 69600 Train loss: 0.2114
en_de Dev loss: 0.9026 r:0.2146
en_zh Dev loss: 0.8257 r:0.4480
ro_en Dev loss: 0.3410 r:0.8192
et_en Dev loss: 0.4383 r:0.6572
si_en Dev loss: 0.7137 r:0.5656
ne_en Dev loss: 0.4437 r:0.7105
ru_en Dev loss: 0.4296 r:0.7422
Current avg r:0.5939 Best avg r: 0.6274
03:45:35,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:46:53,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:48:24,365 root INFO Epoch 7 Global steps: 70200 Train loss: 0.2191
en_de Dev loss: 0.9180 r:0.1907
en_zh Dev loss: 0.8133 r:0.4589
ro_en Dev loss: 0.3739 r:0.8177
et_en Dev loss: 0.4335 r:0.6523
si_en Dev loss: 0.9098 r:0.5572
ne_en Dev loss: 0.5462 r:0.7151
ru_en Dev loss: 0.4943 r:0.7253
Current avg r:0.5882 Best avg r: 0.6274
03:52:17,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:53:35,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:55:06,11 root INFO Epoch 7 Global steps: 70800 Train loss: 0.2206
en_de Dev loss: 0.8988 r:0.1791
en_zh Dev loss: 0.9315 r:0.4223
ro_en Dev loss: 0.3946 r:0.8156
et_en Dev loss: 0.4421 r:0.6441
si_en Dev loss: 0.9009 r:0.5547
ne_en Dev loss: 0.5713 r:0.7122
ru_en Dev loss: 0.5118 r:0.7173
Current avg r:0.5779 Best avg r: 0.6274
03:58:59,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:00:16,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:01:47,712 root INFO Epoch 7 Global steps: 71400 Train loss: 0.2101
en_de Dev loss: 0.9032 r:0.1787
en_zh Dev loss: 0.8919 r:0.4297
ro_en Dev loss: 0.4212 r:0.8119
et_en Dev loss: 0.4556 r:0.6366
si_en Dev loss: 0.9583 r:0.5470
ne_en Dev loss: 0.6730 r:0.7120
ru_en Dev loss: 0.5264 r:0.7078
Current avg r:0.5748 Best avg r: 0.6274
04:05:40,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:06:58,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:29,461 root INFO Epoch 7 Global steps: 72000 Train loss: 0.2047
en_de Dev loss: 0.8968 r:0.1838
en_zh Dev loss: 0.8175 r:0.4390
ro_en Dev loss: 0.3684 r:0.8174
et_en Dev loss: 0.4319 r:0.6456
si_en Dev loss: 0.9653 r:0.5437
ne_en Dev loss: 0.6366 r:0.7165
ru_en Dev loss: 0.5120 r:0.7095
Current avg r:0.5794 Best avg r: 0.6274
04:12:23,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:13:41,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:12,209 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1859
en_de Dev loss: 0.9214 r:0.1926
en_zh Dev loss: 0.8337 r:0.4640
ro_en Dev loss: 0.3825 r:0.8185
et_en Dev loss: 0.4494 r:0.6535
si_en Dev loss: 0.8160 r:0.5702
ne_en Dev loss: 0.5028 r:0.7150
ru_en Dev loss: 0.4541 r:0.7366
Current avg r:0.5929 Best avg r: 0.6274
04:19:05,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:20:23,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:21:54,121 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1865
en_de Dev loss: 0.8802 r:0.1889
en_zh Dev loss: 0.8057 r:0.4538
ro_en Dev loss: 0.3757 r:0.8168
et_en Dev loss: 0.4274 r:0.6555
si_en Dev loss: 0.8912 r:0.5592
ne_en Dev loss: 0.5529 r:0.7160
ru_en Dev loss: 0.4662 r:0.7228
Current avg r:0.5876 Best avg r: 0.6274
04:25:47,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:27:05,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:28:35,805 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1940
en_de Dev loss: 0.8777 r:0.1896
en_zh Dev loss: 0.7956 r:0.4456
ro_en Dev loss: 0.3532 r:0.8149
et_en Dev loss: 0.4348 r:0.6462
si_en Dev loss: 0.8067 r:0.5525
ne_en Dev loss: 0.4803 r:0.7184
ru_en Dev loss: 0.4583 r:0.7093
Current avg r:0.5824 Best avg r: 0.6274
04:32:28,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:33:46,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:35:17,287 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1814
en_de Dev loss: 0.9279 r:0.1765
en_zh Dev loss: 0.9310 r:0.4420
ro_en Dev loss: 0.4113 r:0.8172
et_en Dev loss: 0.4555 r:0.6513
si_en Dev loss: 0.9021 r:0.5609
ne_en Dev loss: 0.5609 r:0.7156
ru_en Dev loss: 0.5401 r:0.7169
Current avg r:0.5829 Best avg r: 0.6274
04:39:10,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:40:28,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:41:58,732 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1846
en_de Dev loss: 0.8971 r:0.1903
en_zh Dev loss: 0.8623 r:0.4487
ro_en Dev loss: 0.3709 r:0.8157
et_en Dev loss: 0.4271 r:0.6534
si_en Dev loss: 0.8774 r:0.5530
ne_en Dev loss: 0.5554 r:0.7170
ru_en Dev loss: 0.5000 r:0.7121
Current avg r:0.5843 Best avg r: 0.6274
04:45:51,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:47:09,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:39,798 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1877
en_de Dev loss: 0.8907 r:0.2023
en_zh Dev loss: 0.8282 r:0.4519
ro_en Dev loss: 0.3672 r:0.8143
et_en Dev loss: 0.4453 r:0.6364
si_en Dev loss: 0.8601 r:0.5500
ne_en Dev loss: 0.5289 r:0.7191
ru_en Dev loss: 0.4955 r:0.7063
Current avg r:0.5829 Best avg r: 0.6274
04:52:32,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:53:50,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:55:20,947 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1876
en_de Dev loss: 0.9038 r:0.1904
en_zh Dev loss: 0.8446 r:0.4482
ro_en Dev loss: 0.3720 r:0.8163
et_en Dev loss: 0.4332 r:0.6468
si_en Dev loss: 0.9159 r:0.5569
ne_en Dev loss: 0.5403 r:0.7258
ru_en Dev loss: 0.4889 r:0.7225
Current avg r:0.5867 Best avg r: 0.6274
04:59:13,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:00:31,491 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:02:02,276 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1938
en_de Dev loss: 0.9042 r:0.1748
en_zh Dev loss: 0.8101 r:0.4621
ro_en Dev loss: 0.3621 r:0.8170
et_en Dev loss: 0.4352 r:0.6543
si_en Dev loss: 0.8294 r:0.5646
ne_en Dev loss: 0.5099 r:0.7173
ru_en Dev loss: 0.4397 r:0.7380
Current avg r:0.5897 Best avg r: 0.6274
05:05:55,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:07:12,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:43,676 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1869
en_de Dev loss: 0.9149 r:0.1774
en_zh Dev loss: 0.8487 r:0.4364
ro_en Dev loss: 0.3621 r:0.8174
et_en Dev loss: 0.4328 r:0.6483
si_en Dev loss: 0.8348 r:0.5542
ne_en Dev loss: 0.5485 r:0.7147
ru_en Dev loss: 0.4842 r:0.7157
Current avg r:0.5806 Best avg r: 0.6274
05:12:36,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:13:54,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:25,344 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1869
en_de Dev loss: 0.9144 r:0.1786
en_zh Dev loss: 0.8355 r:0.4319
ro_en Dev loss: 0.3783 r:0.8103
et_en Dev loss: 0.4430 r:0.6440
si_en Dev loss: 0.8313 r:0.5516
ne_en Dev loss: 0.5849 r:0.7136
ru_en Dev loss: 0.4821 r:0.7069
Current avg r:0.5767 Best avg r: 0.6274
05:19:18,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:36,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:22:07,12 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1847
en_de Dev loss: 0.9208 r:0.1751
en_zh Dev loss: 0.8751 r:0.4521
ro_en Dev loss: 0.3857 r:0.8118
et_en Dev loss: 0.4399 r:0.6507
si_en Dev loss: 0.9579 r:0.5528
ne_en Dev loss: 0.6023 r:0.7181
ru_en Dev loss: 0.4816 r:0.7290
Current avg r:0.5842 Best avg r: 0.6274
05:25:59,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:27:17,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:28:48,126 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1936
en_de Dev loss: 0.9334 r:0.1790
en_zh Dev loss: 0.8779 r:0.4506
ro_en Dev loss: 0.4105 r:0.8140
et_en Dev loss: 0.4445 r:0.6561
si_en Dev loss: 0.8910 r:0.5578
ne_en Dev loss: 0.5712 r:0.7228
ru_en Dev loss: 0.4981 r:0.7274
Current avg r:0.5868 Best avg r: 0.6274
05:32:40,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:33:58,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:35:29,566 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1900
en_de Dev loss: 0.9107 r:0.1693
en_zh Dev loss: 0.8258 r:0.4423
ro_en Dev loss: 0.3879 r:0.8122
et_en Dev loss: 0.4393 r:0.6429
si_en Dev loss: 0.9032 r:0.5506
ne_en Dev loss: 0.6462 r:0.7058
ru_en Dev loss: 0.4854 r:0.7088
Current avg r:0.5760 Best avg r: 0.6274
05:39:22,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:40:40,171 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:42:10,962 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1800
en_de Dev loss: 0.9148 r:0.1847
en_zh Dev loss: 0.8131 r:0.4717
ro_en Dev loss: 0.3831 r:0.8189
et_en Dev loss: 0.4357 r:0.6536
si_en Dev loss: 0.8714 r:0.5607
ne_en Dev loss: 0.5589 r:0.7177
ru_en Dev loss: 0.5030 r:0.7271
Current avg r:0.5906 Best avg r: 0.6274
05:46:03,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:47:21,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:48:52,414 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1854
en_de Dev loss: 0.9528 r:0.1892
en_zh Dev loss: 0.8764 r:0.4586
ro_en Dev loss: 0.4150 r:0.8141
et_en Dev loss: 0.4576 r:0.6560
si_en Dev loss: 0.9399 r:0.5543
ne_en Dev loss: 0.5654 r:0.7085
ru_en Dev loss: 0.5291 r:0.7221
Current avg r:0.5861 Best avg r: 0.6274
05:52:46,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:04,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:55:35,412 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1545
en_de Dev loss: 0.9230 r:0.1795
en_zh Dev loss: 0.8621 r:0.4487
ro_en Dev loss: 0.3982 r:0.8167
et_en Dev loss: 0.4450 r:0.6628
si_en Dev loss: 0.8719 r:0.5659
ne_en Dev loss: 0.5725 r:0.7179
ru_en Dev loss: 0.4802 r:0.7311
Current avg r:0.5890 Best avg r: 0.6274
05:59:28,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:00:45,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:02:16,645 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1687
en_de Dev loss: 0.9262 r:0.1865
en_zh Dev loss: 0.8860 r:0.4504
ro_en Dev loss: 0.3932 r:0.8149
et_en Dev loss: 0.4386 r:0.6585
si_en Dev loss: 0.8931 r:0.5616
ne_en Dev loss: 0.5905 r:0.7165
ru_en Dev loss: 0.5081 r:0.7253
Current avg r:0.5877 Best avg r: 0.6274
06:06:09,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:27,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:57,859 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1634
en_de Dev loss: 0.9260 r:0.1840
en_zh Dev loss: 0.8513 r:0.4508
ro_en Dev loss: 0.3876 r:0.8179
et_en Dev loss: 0.4337 r:0.6533
si_en Dev loss: 0.8914 r:0.5613
ne_en Dev loss: 0.5237 r:0.7209
ru_en Dev loss: 0.5037 r:0.7194
Current avg r:0.5868 Best avg r: 0.6274
06:12:50,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:08,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:39,649 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1713
en_de Dev loss: 0.9257 r:0.1848
en_zh Dev loss: 0.8095 r:0.4585
ro_en Dev loss: 0.3812 r:0.8194
et_en Dev loss: 0.4331 r:0.6545
si_en Dev loss: 0.8781 r:0.5573
ne_en Dev loss: 0.5330 r:0.7169
ru_en Dev loss: 0.4635 r:0.7357
Current avg r:0.5896 Best avg r: 0.6274
06:19:32,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:20:50,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:22:21,357 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1684
en_de Dev loss: 0.9102 r:0.1846
en_zh Dev loss: 0.8896 r:0.4449
ro_en Dev loss: 0.3897 r:0.8150
et_en Dev loss: 0.4386 r:0.6486
si_en Dev loss: 0.9702 r:0.5442
ne_en Dev loss: 0.6023 r:0.7108
ru_en Dev loss: 0.5047 r:0.7162
Current avg r:0.5806 Best avg r: 0.6274
06:26:14,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:27:32,139 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:29:03,49 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1699
en_de Dev loss: 0.9050 r:0.1918
en_zh Dev loss: 0.8577 r:0.4384
ro_en Dev loss: 0.4103 r:0.8099
et_en Dev loss: 0.4569 r:0.6342
si_en Dev loss: 0.9698 r:0.5459
ne_en Dev loss: 0.6096 r:0.7114
ru_en Dev loss: 0.5268 r:0.7046
Current avg r:0.5766 Best avg r: 0.6274
06:32:56,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:34:13,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:35:44,935 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1599
en_de Dev loss: 0.9204 r:0.1784
en_zh Dev loss: 0.8534 r:0.4431
ro_en Dev loss: 0.3872 r:0.8093
et_en Dev loss: 0.4512 r:0.6365
si_en Dev loss: 0.9378 r:0.5452
ne_en Dev loss: 0.6035 r:0.7138
ru_en Dev loss: 0.5013 r:0.7141
Current avg r:0.5772 Best avg r: 0.6274
06:39:38,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:40:55,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:42:26,839 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1673
en_de Dev loss: 0.9397 r:0.1716
en_zh Dev loss: 0.8636 r:0.4562
ro_en Dev loss: 0.3913 r:0.8136
et_en Dev loss: 0.4402 r:0.6515
si_en Dev loss: 0.9134 r:0.5522
ne_en Dev loss: 0.5953 r:0.7109
ru_en Dev loss: 0.4956 r:0.7278
Current avg r:0.5834 Best avg r: 0.6274
06:46:20,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:37,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:49:08,910 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1626
en_de Dev loss: 0.9357 r:0.1615
en_zh Dev loss: 0.8689 r:0.4414
ro_en Dev loss: 0.4103 r:0.8093
et_en Dev loss: 0.4538 r:0.6401
si_en Dev loss: 0.9451 r:0.5424
ne_en Dev loss: 0.5743 r:0.7070
ru_en Dev loss: 0.5443 r:0.7085
Current avg r:0.5729 Best avg r: 0.6274
06:53:02,105 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:19,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:55:51,33 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1611
en_de Dev loss: 0.9563 r:0.1574
en_zh Dev loss: 0.8967 r:0.4417
ro_en Dev loss: 0.4260 r:0.8105
et_en Dev loss: 0.4600 r:0.6410
si_en Dev loss: 0.9748 r:0.5418
ne_en Dev loss: 0.5823 r:0.7072
ru_en Dev loss: 0.5554 r:0.7166
Current avg r:0.5737 Best avg r: 0.6274
06:59:43,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:01:01,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:32,650 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1701
en_de Dev loss: 0.9357 r:0.1623
en_zh Dev loss: 0.9553 r:0.4444
ro_en Dev loss: 0.4507 r:0.8098
et_en Dev loss: 0.4653 r:0.6397
si_en Dev loss: 0.9688 r:0.5472
ne_en Dev loss: 0.6307 r:0.7104
ru_en Dev loss: 0.5485 r:0.7110
Current avg r:0.5750 Best avg r: 0.6274
07:06:25,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:07:43,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:09:14,759 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1622
en_de Dev loss: 0.9217 r:0.1751
en_zh Dev loss: 0.8175 r:0.4493
ro_en Dev loss: 0.3505 r:0.8172
et_en Dev loss: 0.4229 r:0.6556
si_en Dev loss: 0.8096 r:0.5523
ne_en Dev loss: 0.5623 r:0.7080
ru_en Dev loss: 0.4588 r:0.7249
Current avg r:0.5832 Best avg r: 0.6274
07:13:07,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:14:25,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:56,866 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1650
en_de Dev loss: 0.9361 r:0.1652
en_zh Dev loss: 0.8307 r:0.4546
ro_en Dev loss: 0.3950 r:0.8139
et_en Dev loss: 0.4289 r:0.6578
si_en Dev loss: 0.9014 r:0.5583
ne_en Dev loss: 0.5426 r:0.7182
ru_en Dev loss: 0.4620 r:0.7372
Current avg r:0.5864 Best avg r: 0.6274
07:19:50,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:21:09,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:22:41,197 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1669
en_de Dev loss: 0.9340 r:0.1977
en_zh Dev loss: 0.8027 r:0.4611
ro_en Dev loss: 0.3651 r:0.8166
et_en Dev loss: 0.4296 r:0.6541
si_en Dev loss: 0.8466 r:0.5559
ne_en Dev loss: 0.5320 r:0.7133
ru_en Dev loss: 0.4677 r:0.7299
Current avg r:0.5898 Best avg r: 0.6274
07:26:35,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:27:53,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:29:24,764 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1603
en_de Dev loss: 0.9380 r:0.1607
en_zh Dev loss: 0.8695 r:0.4344
ro_en Dev loss: 0.3916 r:0.8075
et_en Dev loss: 0.4453 r:0.6414
si_en Dev loss: 0.9797 r:0.5408
ne_en Dev loss: 0.5794 r:0.7105
ru_en Dev loss: 0.5573 r:0.7030
Current avg r:0.5712 Best avg r: 0.6274
07:33:20,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:34:38,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:36:09,433 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1469
en_de Dev loss: 0.9628 r:0.1737
en_zh Dev loss: 0.9249 r:0.4326
ro_en Dev loss: 0.4205 r:0.8098
et_en Dev loss: 0.4553 r:0.6505
si_en Dev loss: 0.9391 r:0.5530
ne_en Dev loss: 0.5740 r:0.7147
ru_en Dev loss: 0.5463 r:0.7217
Current avg r:0.5794 Best avg r: 0.6274
07:40:03,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:41:22,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:53,729 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1460
en_de Dev loss: 0.9418 r:0.1751
en_zh Dev loss: 0.8511 r:0.4452
ro_en Dev loss: 0.3771 r:0.8121
et_en Dev loss: 0.4327 r:0.6554
si_en Dev loss: 0.9315 r:0.5493
ne_en Dev loss: 0.5870 r:0.7078
ru_en Dev loss: 0.5293 r:0.7164
Current avg r:0.5802 Best avg r: 0.6274
07:46:47,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:06,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:49:37,277 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1468
en_de Dev loss: 0.9282 r:0.1725
en_zh Dev loss: 0.8751 r:0.4287
ro_en Dev loss: 0.3951 r:0.8028
et_en Dev loss: 0.4314 r:0.6511
si_en Dev loss: 0.9220 r:0.5488
ne_en Dev loss: 0.5610 r:0.7058
ru_en Dev loss: 0.5114 r:0.7098
Current avg r:0.5742 Best avg r: 0.6274
07:53:31,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:54:49,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:56:21,180 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1511
en_de Dev loss: 0.9302 r:0.1832
en_zh Dev loss: 0.8691 r:0.4390
ro_en Dev loss: 0.4148 r:0.8025
et_en Dev loss: 0.4421 r:0.6507
si_en Dev loss: 0.9375 r:0.5503
ne_en Dev loss: 0.6345 r:0.7048
ru_en Dev loss: 0.5068 r:0.7167
Current avg r:0.5782 Best avg r: 0.6274
08:00:16,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:01:34,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:05,294 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1515
en_de Dev loss: 0.9257 r:0.1822
en_zh Dev loss: 0.8075 r:0.4454
ro_en Dev loss: 0.3626 r:0.8119
et_en Dev loss: 0.4306 r:0.6487
si_en Dev loss: 0.8874 r:0.5534
ne_en Dev loss: 0.5328 r:0.7022
ru_en Dev loss: 0.4489 r:0.7355
Current avg r:0.5828 Best avg r: 0.6274
08:06:58,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:16,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:09:47,677 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1481
en_de Dev loss: 0.9299 r:0.1915
en_zh Dev loss: 0.8400 r:0.4442
ro_en Dev loss: 0.3861 r:0.8133
et_en Dev loss: 0.4427 r:0.6526
si_en Dev loss: 0.9875 r:0.5577
ne_en Dev loss: 0.6303 r:0.7035
ru_en Dev loss: 0.4966 r:0.7307
Current avg r:0.5848 Best avg r: 0.6274
08:13:40,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:14:58,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:29,769 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1576
en_de Dev loss: 0.9238 r:0.1942
en_zh Dev loss: 0.8431 r:0.4368
ro_en Dev loss: 0.3524 r:0.8165
et_en Dev loss: 0.4403 r:0.6475
si_en Dev loss: 0.8842 r:0.5602
ne_en Dev loss: 0.5317 r:0.7055
ru_en Dev loss: 0.4661 r:0.7278
Current avg r:0.5841 Best avg r: 0.6274
08:20:22,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:40,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:11,817 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1477
en_de Dev loss: 0.9274 r:0.1831
en_zh Dev loss: 0.8199 r:0.4536
ro_en Dev loss: 0.3874 r:0.8140
et_en Dev loss: 0.4633 r:0.6377
si_en Dev loss: 0.9467 r:0.5559
ne_en Dev loss: 0.5582 r:0.6986
ru_en Dev loss: 0.4950 r:0.7214
Current avg r:0.5806 Best avg r: 0.6274
08:27:04,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:22,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:53,631 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1537
en_de Dev loss: 0.9452 r:0.1808
en_zh Dev loss: 0.8874 r:0.4500
ro_en Dev loss: 0.4051 r:0.8141
et_en Dev loss: 0.4670 r:0.6400
si_en Dev loss: 1.0005 r:0.5560
ne_en Dev loss: 0.6533 r:0.7075
ru_en Dev loss: 0.5403 r:0.7169
Current avg r:0.5808 Best avg r: 0.6274
08:33:46,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:04,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:35,922 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1521
en_de Dev loss: 0.9522 r:0.1618
en_zh Dev loss: 0.8783 r:0.4366
ro_en Dev loss: 0.3822 r:0.8143
et_en Dev loss: 0.4486 r:0.6462
si_en Dev loss: 0.8729 r:0.5588
ne_en Dev loss: 0.5774 r:0.7113
ru_en Dev loss: 0.5163 r:0.7162
Current avg r:0.5779 Best avg r: 0.6274
08:40:28,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:41:46,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:17,638 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1421
en_de Dev loss: 0.9316 r:0.1767
en_zh Dev loss: 0.8112 r:0.4506
ro_en Dev loss: 0.3473 r:0.8198
et_en Dev loss: 0.4309 r:0.6566
si_en Dev loss: 0.7746 r:0.5635
ne_en Dev loss: 0.5076 r:0.7082
ru_en Dev loss: 0.4446 r:0.7372
Current avg r:0.5875 Best avg r: 0.6274
08:47:10,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:28,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:59,550 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1532
en_de Dev loss: 0.9454 r:0.1823
en_zh Dev loss: 0.8088 r:0.4592
ro_en Dev loss: 0.3768 r:0.8153
et_en Dev loss: 0.4440 r:0.6459
si_en Dev loss: 0.8611 r:0.5600
ne_en Dev loss: 0.5496 r:0.7084
ru_en Dev loss: 0.5182 r:0.7181
Current avg r:0.5842 Best avg r: 0.6274
08:53:52,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:55:10,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:41,628 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1466
en_de Dev loss: 0.9750 r:0.1482
en_zh Dev loss: 0.9027 r:0.4433
ro_en Dev loss: 0.4071 r:0.8139
et_en Dev loss: 0.4573 r:0.6448
si_en Dev loss: 0.9658 r:0.5561
ne_en Dev loss: 0.5844 r:0.7045
ru_en Dev loss: 0.4925 r:0.7355
Current avg r:0.5780 Best avg r: 0.6274
09:00:34,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:52,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:23,762 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1481
en_de Dev loss: 0.9458 r:0.1516
en_zh Dev loss: 0.8455 r:0.4505
ro_en Dev loss: 0.3765 r:0.8163
et_en Dev loss: 0.4292 r:0.6538
si_en Dev loss: 0.8733 r:0.5627
ne_en Dev loss: 0.5413 r:0.7099
ru_en Dev loss: 0.5150 r:0.7243
Current avg r:0.5813 Best avg r: 0.6274
09:07:17,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:08:35,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:06,106 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1443
en_de Dev loss: 0.9526 r:0.1658
en_zh Dev loss: 0.8466 r:0.4450
ro_en Dev loss: 0.3680 r:0.8150
et_en Dev loss: 0.4476 r:0.6442
si_en Dev loss: 0.8851 r:0.5578
ne_en Dev loss: 0.5409 r:0.7028
ru_en Dev loss: 0.4832 r:0.7299
Current avg r:0.5801 Best avg r: 0.6274
09:14:00,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:18,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:49,660 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1325
en_de Dev loss: 0.9410 r:0.1466
en_zh Dev loss: 0.8288 r:0.4404
ro_en Dev loss: 0.3506 r:0.8168
et_en Dev loss: 0.4296 r:0.6513
si_en Dev loss: 0.8584 r:0.5629
ne_en Dev loss: 0.5120 r:0.7065
ru_en Dev loss: 0.4590 r:0.7334
Current avg r:0.5797 Best avg r: 0.6274
09:20:42,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:22:00,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:23:31,692 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1303
en_de Dev loss: 0.9569 r:0.1576
en_zh Dev loss: 0.8241 r:0.4486
ro_en Dev loss: 0.3778 r:0.8127
et_en Dev loss: 0.4436 r:0.6430
si_en Dev loss: 0.9052 r:0.5551
ne_en Dev loss: 0.5593 r:0.7039
ru_en Dev loss: 0.4824 r:0.7295
Current avg r:0.5786 Best avg r: 0.6274
09:27:24,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:28:42,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:30:13,416 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1275
en_de Dev loss: 0.9686 r:0.1634
en_zh Dev loss: 0.8248 r:0.4560
ro_en Dev loss: 0.3651 r:0.8138
et_en Dev loss: 0.4446 r:0.6495
si_en Dev loss: 0.8309 r:0.5607
ne_en Dev loss: 0.5343 r:0.6987
ru_en Dev loss: 0.4881 r:0.7321
Current avg r:0.5820 Best avg r: 0.6274
09:34:06,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:24,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:55,64 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1279
en_de Dev loss: 0.9425 r:0.1504
en_zh Dev loss: 0.7877 r:0.4564
ro_en Dev loss: 0.3355 r:0.8194
et_en Dev loss: 0.4203 r:0.6583
si_en Dev loss: 0.8131 r:0.5642
ne_en Dev loss: 0.5560 r:0.6981
ru_en Dev loss: 0.4822 r:0.7284
Current avg r:0.5822 Best avg r: 0.6274
09:40:47,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:05,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:36,781 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1334
en_de Dev loss: 0.9561 r:0.1643
en_zh Dev loss: 0.8769 r:0.4468
ro_en Dev loss: 0.3729 r:0.8140
et_en Dev loss: 0.4360 r:0.6550
si_en Dev loss: 0.9593 r:0.5550
ne_en Dev loss: 0.6449 r:0.7057
ru_en Dev loss: 0.4907 r:0.7336
Current avg r:0.5820 Best avg r: 0.6274
09:47:29,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:47,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:50:18,37 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1263
en_de Dev loss: 0.9506 r:0.1420
en_zh Dev loss: 0.8316 r:0.4461
ro_en Dev loss: 0.3718 r:0.8155
et_en Dev loss: 0.4342 r:0.6523
si_en Dev loss: 0.8809 r:0.5607
ne_en Dev loss: 0.5798 r:0.7007
ru_en Dev loss: 0.4757 r:0.7289
Current avg r:0.5780 Best avg r: 0.6274
09:54:11,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:29,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:00,553 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1201
en_de Dev loss: 0.9566 r:0.1488
en_zh Dev loss: 0.9101 r:0.4426
ro_en Dev loss: 0.4269 r:0.8153
et_en Dev loss: 0.4585 r:0.6524
si_en Dev loss: 0.9285 r:0.5629
ne_en Dev loss: 0.5903 r:0.7013
ru_en Dev loss: 0.5427 r:0.7257
Current avg r:0.5784 Best avg r: 0.6274
10:00:53,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:11,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:42,775 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1255
en_de Dev loss: 0.9610 r:0.1426
en_zh Dev loss: 0.8922 r:0.4382
ro_en Dev loss: 0.4259 r:0.8114
et_en Dev loss: 0.4535 r:0.6459
si_en Dev loss: 1.0275 r:0.5397
ne_en Dev loss: 0.6788 r:0.6968
ru_en Dev loss: 0.5372 r:0.7148
Current avg r:0.5699 Best avg r: 0.6274
10:07:36,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:54,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:25,680 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1240
en_de Dev loss: 0.9290 r:0.1508
en_zh Dev loss: 0.8358 r:0.4473
ro_en Dev loss: 0.3682 r:0.8142
et_en Dev loss: 0.4309 r:0.6483
si_en Dev loss: 0.8657 r:0.5567
ne_en Dev loss: 0.5792 r:0.7017
ru_en Dev loss: 0.4446 r:0.7359
Current avg r:0.5793 Best avg r: 0.6274
10:14:18,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:15:36,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:07,624 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1298
en_de Dev loss: 0.9764 r:0.1529
en_zh Dev loss: 1.0083 r:0.4364
ro_en Dev loss: 0.4410 r:0.8078
et_en Dev loss: 0.4767 r:0.6382
si_en Dev loss: 1.0176 r:0.5465
ne_en Dev loss: 0.7204 r:0.6970
ru_en Dev loss: 0.5545 r:0.7194
Current avg r:0.5712 Best avg r: 0.6274
10:21:00,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:22:18,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:49,773 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1295
en_de Dev loss: 0.9429 r:0.1528
en_zh Dev loss: 0.8408 r:0.4458
ro_en Dev loss: 0.3673 r:0.8118
et_en Dev loss: 0.4241 r:0.6518
si_en Dev loss: 0.8292 r:0.5580
ne_en Dev loss: 0.5494 r:0.7016
ru_en Dev loss: 0.4704 r:0.7282
Current avg r:0.5786 Best avg r: 0.6274
10:27:42,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:00,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:30,816 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1299
en_de Dev loss: 0.9653 r:0.1563
en_zh Dev loss: 0.8336 r:0.4592
ro_en Dev loss: 0.3776 r:0.8158
et_en Dev loss: 0.4321 r:0.6537
si_en Dev loss: 0.8889 r:0.5605
ne_en Dev loss: 0.6034 r:0.7084
ru_en Dev loss: 0.4812 r:0.7319
Current avg r:0.5837 Best avg r: 0.6274
10:34:23,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:35:41,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:37:12,340 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1241
en_de Dev loss: 0.9418 r:0.1543
en_zh Dev loss: 0.8323 r:0.4461
ro_en Dev loss: 0.4115 r:0.8074
et_en Dev loss: 0.4442 r:0.6419
si_en Dev loss: 0.9438 r:0.5496
ne_en Dev loss: 0.6791 r:0.6955
ru_en Dev loss: 0.5349 r:0.7030
Current avg r:0.5711 Best avg r: 0.6274
