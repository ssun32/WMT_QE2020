14:35:25,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:35:38,813 root INFO 
id:en_de cur r: 0.0551 best r: 0.0551
14:35:51,624 root INFO 
id:en_zh cur r: 0.2020 best r: 0.2020
14:36:04,469 root INFO 
id:ro_en cur r: 0.5897 best r: 0.5897
14:36:17,331 root INFO 
id:si_en cur r: 0.4454 best r: 0.4454
14:36:30,192 root INFO 
id:ne_en cur r: 0.5528 best r: 0.5528
14:36:42,992 root INFO 
id:ru_en cur r: 0.5870 best r: 0.5870
14:36:42,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:38:12,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
14:38:12,781 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:38:12,787 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:38:12,791 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
14:38:12,797 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
14:38:12,801 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:38:12,806 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:38:25,667 root INFO Epoch 0 Global steps: 600 Train loss: 0.8385
en_de Dev loss: 0.8875 r:0.0794
en_zh Dev loss: 0.7874 r:0.2089
ro_en Dev loss: 0.7132 r:0.5288
et_en Dev loss: 0.6809 r:0.2976
si_en Dev loss: 0.7577 r:0.3855
ne_en Dev loss: 0.6648 r:0.4910
ru_en Dev loss: 0.6205 r:0.6062
Current avg r:0.3711 Best avg r: 0.3711
14:42:14,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:27,565 root INFO 
id:en_de cur r: 0.0687 best r: 0.0687
14:42:40,429 root INFO 
id:en_zh cur r: 0.2372 best r: 0.2372
14:42:53,295 root INFO 
id:ro_en cur r: 0.6541 best r: 0.6541
14:43:31,810 root INFO 
id:ru_en cur r: 0.6679 best r: 0.6679
14:43:31,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:01,651 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
14:45:01,657 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:45:01,665 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:45:01,670 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
14:45:01,675 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
14:45:01,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:45:01,685 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:45:14,535 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7819
en_de Dev loss: 0.9150 r:0.0699
en_zh Dev loss: 0.7855 r:0.2349
ro_en Dev loss: 0.6066 r:0.6237
et_en Dev loss: 0.6177 r:0.4048
si_en Dev loss: 0.7118 r:0.4295
ne_en Dev loss: 0.5916 r:0.5396
ru_en Dev loss: 0.5148 r:0.6730
Current avg r:0.4250 Best avg r: 0.4250
14:49:03,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:42,84 root INFO 
id:ro_en cur r: 0.6847 best r: 0.6847
14:50:07,807 root INFO 
id:ne_en cur r: 0.5535 best r: 0.5535
14:50:20,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:50,435 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
14:51:50,441 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:51:50,449 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:51:50,453 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
14:51:50,458 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
14:51:50,463 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:51:50,467 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:52:03,330 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7271
en_de Dev loss: 0.9547 r:0.0822
en_zh Dev loss: 0.8411 r:0.2425
ro_en Dev loss: 0.5660 r:0.6781
et_en Dev loss: 0.6265 r:0.4312
si_en Dev loss: 0.7764 r:0.4368
ne_en Dev loss: 0.6318 r:0.5240
ru_en Dev loss: 0.5332 r:0.6629
Current avg r:0.4368 Best avg r: 0.4368
14:55:52,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:05,268 root INFO 
id:en_de cur r: 0.0779 best r: 0.0779
14:56:18,128 root INFO 
id:en_zh cur r: 0.3045 best r: 0.3045
14:56:31,58 root INFO 
id:ro_en cur r: 0.7049 best r: 0.7049
14:56:43,955 root INFO 
id:si_en cur r: 0.4779 best r: 0.4779
14:56:56,850 root INFO 
id:ne_en cur r: 0.6043 best r: 0.6043
14:57:09,688 root INFO 
id:ru_en cur r: 0.6792 best r: 0.6792
14:57:09,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:39,761 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
14:58:39,769 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:58:39,778 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:58:39,783 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
14:58:39,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
14:58:39,794 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:58:39,799 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:58:52,691 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6510
en_de Dev loss: 0.9886 r:0.0995
en_zh Dev loss: 0.7831 r:0.3088
ro_en Dev loss: 0.4697 r:0.7152
et_en Dev loss: 0.5662 r:0.5484
si_en Dev loss: 0.6762 r:0.4937
ne_en Dev loss: 0.5549 r:0.5902
ru_en Dev loss: 0.5283 r:0.6784
Current avg r:0.4906 Best avg r: 0.4906
15:02:41,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:54,755 root INFO 
id:en_de cur r: 0.1225 best r: 0.1225
15:03:07,609 root INFO 
id:en_zh cur r: 0.3170 best r: 0.3170
15:03:20,500 root INFO 
id:ro_en cur r: 0.7116 best r: 0.7116
15:03:46,297 root INFO 
id:ne_en cur r: 0.6237 best r: 0.6237
15:03:59,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:29,224 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:05:29,230 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:05:29,236 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:05:29,241 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:05:29,246 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:05:29,250 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:05:29,255 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:05:42,159 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6444
en_de Dev loss: 0.9664 r:0.1338
en_zh Dev loss: 0.7997 r:0.3405
ro_en Dev loss: 0.4875 r:0.7295
et_en Dev loss: 0.5830 r:0.5524
si_en Dev loss: 0.7072 r:0.5031
ne_en Dev loss: 0.5364 r:0.6172
ru_en Dev loss: 0.5177 r:0.7037
Current avg r:0.5115 Best avg r: 0.5115
15:09:31,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:44,165 root INFO 
id:en_de cur r: 0.1467 best r: 0.1467
15:09:56,995 root INFO 
id:en_zh cur r: 0.3449 best r: 0.3449
15:10:09,852 root INFO 
id:ro_en cur r: 0.7294 best r: 0.7294
15:10:22,713 root INFO 
id:si_en cur r: 0.4884 best r: 0.4884
15:10:35,572 root INFO 
id:ne_en cur r: 0.6416 best r: 0.6416
15:10:48,372 root INFO 
id:ru_en cur r: 0.7032 best r: 0.7032
15:10:48,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:18,183 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:12:18,190 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:12:18,197 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:12:18,201 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:12:18,207 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:12:18,212 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:12:18,218 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:12:31,77 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6102
en_de Dev loss: 0.9395 r:0.1602
en_zh Dev loss: 0.7633 r:0.3712
ro_en Dev loss: 0.4400 r:0.7419
et_en Dev loss: 0.5523 r:0.5794
si_en Dev loss: 0.7231 r:0.5064
ne_en Dev loss: 0.4837 r:0.6445
ru_en Dev loss: 0.4498 r:0.7198
Current avg r:0.5319 Best avg r: 0.5319
15:16:20,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:58,806 root INFO 
id:ro_en cur r: 0.7403 best r: 0.7403
15:17:37,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:07,154 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:19:07,161 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:19:07,167 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:19:07,172 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:19:07,176 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:19:07,181 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:19:07,186 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:19:20,44 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6440
en_de Dev loss: 0.9317 r:0.1548
en_zh Dev loss: 0.7847 r:0.3745
ro_en Dev loss: 0.4310 r:0.7547
et_en Dev loss: 0.5582 r:0.5924
si_en Dev loss: 0.7957 r:0.5065
ne_en Dev loss: 0.5179 r:0.6352
ru_en Dev loss: 0.4890 r:0.7137
Current avg r:0.5331 Best avg r: 0.5331
15:23:09,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:34,823 root INFO 
id:en_zh cur r: 0.3826 best r: 0.3826
15:23:47,715 root INFO 
id:ro_en cur r: 0.7470 best r: 0.7470
15:24:00,613 root INFO 
id:si_en cur r: 0.5159 best r: 0.5159
15:24:13,504 root INFO 
id:ne_en cur r: 0.6453 best r: 0.6453
15:24:26,335 root INFO 
id:ru_en cur r: 0.7084 best r: 0.7084
15:24:26,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:56,378 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:25:56,384 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:25:56,390 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:25:56,395 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:25:56,400 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:25:56,404 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:25:56,409 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:26:09,296 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5833
en_de Dev loss: 0.9184 r:0.1682
en_zh Dev loss: 0.7271 r:0.3988
ro_en Dev loss: 0.4176 r:0.7557
et_en Dev loss: 0.5150 r:0.6154
si_en Dev loss: 0.6613 r:0.5353
ne_en Dev loss: 0.4743 r:0.6552
ru_en Dev loss: 0.4620 r:0.7222
Current avg r:0.5501 Best avg r: 0.5501
15:29:58,549 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:11,411 root INFO 
id:en_de cur r: 0.1629 best r: 0.1629
15:30:24,233 root INFO 
id:en_zh cur r: 0.4051 best r: 0.4051
15:30:37,86 root INFO 
id:ro_en cur r: 0.7666 best r: 0.7666
15:30:49,945 root INFO 
id:si_en cur r: 0.5199 best r: 0.5199
15:31:02,814 root INFO 
id:ne_en cur r: 0.6881 best r: 0.6881
15:31:15,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:45,424 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:32:45,430 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:32:45,437 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:32:45,441 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:32:45,446 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:32:45,451 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:32:45,455 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:32:58,320 root INFO Epoch 0 Global steps: 5400 Train loss: 0.6560
en_de Dev loss: 0.8920 r:0.1795
en_zh Dev loss: 0.7563 r:0.4132
ro_en Dev loss: 0.4054 r:0.7687
et_en Dev loss: 0.5374 r:0.6305
si_en Dev loss: 0.6670 r:0.5509
ne_en Dev loss: 0.4570 r:0.6792
ru_en Dev loss: 0.5020 r:0.7130
Current avg r:0.5621 Best avg r: 0.5621
15:36:47,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:00,392 root INFO 
id:en_de cur r: 0.1686 best r: 0.1686
15:37:13,248 root INFO 
id:en_zh cur r: 0.4124 best r: 0.4124
15:37:26,145 root INFO 
id:ro_en cur r: 0.7805 best r: 0.7805
15:37:39,43 root INFO 
id:si_en cur r: 0.5519 best r: 0.5519
15:37:51,943 root INFO 
id:ne_en cur r: 0.6977 best r: 0.6977
15:38:04,783 root INFO 
id:ru_en cur r: 0.7270 best r: 0.7270
15:38:04,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:34,838 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:39:34,843 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:39:34,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:39:34,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:39:34,858 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:39:34,862 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:39:34,866 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:39:47,756 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5723
en_de Dev loss: 0.8925 r:0.1867
en_zh Dev loss: 0.7165 r:0.4129
ro_en Dev loss: 0.3736 r:0.7767
et_en Dev loss: 0.5163 r:0.6444
si_en Dev loss: 0.7207 r:0.5515
ne_en Dev loss: 0.4732 r:0.6832
ru_en Dev loss: 0.4492 r:0.7311
Current avg r:0.5695 Best avg r: 0.5695
15:43:36,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:49,721 root INFO 
id:en_de cur r: 0.1793 best r: 0.1793
15:44:02,546 root INFO 
id:en_zh cur r: 0.4285 best r: 0.4285
15:44:41,115 root INFO 
id:ne_en cur r: 0.7107 best r: 0.7107
15:44:53,922 root INFO 
id:ru_en cur r: 0.7365 best r: 0.7365
15:44:53,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:23,753 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:46:23,760 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:46:23,766 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:46:23,771 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:46:23,776 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:46:23,781 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:46:23,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:46:36,650 root INFO Epoch 0 Global steps: 6600 Train loss: 0.6191
en_de Dev loss: 0.8731 r:0.1923
en_zh Dev loss: 0.6936 r:0.4356
ro_en Dev loss: 0.3621 r:0.7854
et_en Dev loss: 0.4951 r:0.6446
si_en Dev loss: 0.6558 r:0.5676
ne_en Dev loss: 0.4323 r:0.7018
ru_en Dev loss: 0.4116 r:0.7413
Current avg r:0.5812 Best avg r: 0.5812
15:50:25,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:38,801 root INFO 
id:en_de cur r: 0.1962 best r: 0.1962
15:51:04,496 root INFO 
id:ro_en cur r: 0.7918 best r: 0.7918
15:51:17,376 root INFO 
id:si_en cur r: 0.5602 best r: 0.5602
15:51:30,250 root INFO 
id:ne_en cur r: 0.7192 best r: 0.7192
15:51:43,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:14,392 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:53:14,400 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:53:14,405 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:53:14,410 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:53:14,414 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:53:14,419 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:53:14,424 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:53:27,321 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5806
en_de Dev loss: 0.8741 r:0.2057
en_zh Dev loss: 0.7173 r:0.4412
ro_en Dev loss: 0.3669 r:0.7913
et_en Dev loss: 0.5225 r:0.6584
si_en Dev loss: 0.7115 r:0.5758
ne_en Dev loss: 0.4728 r:0.7095
ru_en Dev loss: 0.5011 r:0.7327
Current avg r:0.5878 Best avg r: 0.5878
15:57:19,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:57,742 root INFO 
id:ro_en cur r: 0.7920 best r: 0.7920
15:58:10,648 root INFO 
id:si_en cur r: 0.5698 best r: 0.5698
15:58:23,540 root INFO 
id:ne_en cur r: 0.7241 best r: 0.7241
15:58:36,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:06,341 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:00:06,349 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:00:06,355 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:00:06,359 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:00:06,363 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:00:06,368 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:00:06,372 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:00:19,228 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5322
en_de Dev loss: 0.8958 r:0.2051
en_zh Dev loss: 0.7132 r:0.4367
ro_en Dev loss: 0.3613 r:0.7887
et_en Dev loss: 0.4813 r:0.6629
si_en Dev loss: 0.6374 r:0.5817
ne_en Dev loss: 0.3993 r:0.7192
ru_en Dev loss: 0.4934 r:0.7299
Current avg r:0.5892 Best avg r: 0.5892
16:04:08,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:46,933 root INFO 
id:ro_en cur r: 0.7922 best r: 0.7922
16:04:59,790 root INFO 
id:si_en cur r: 0.5815 best r: 0.5815
16:05:12,645 root INFO 
id:ne_en cur r: 0.7363 best r: 0.7363
16:05:25,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:55,259 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:06:55,266 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:06:55,272 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:06:55,277 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:06:55,281 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:06:55,286 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:06:55,290 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:07:08,146 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5860
en_de Dev loss: 0.8660 r:0.1979
en_zh Dev loss: 0.6926 r:0.4396
ro_en Dev loss: 0.3552 r:0.7951
et_en Dev loss: 0.4761 r:0.6553
si_en Dev loss: 0.6618 r:0.5871
ne_en Dev loss: 0.4197 r:0.7284
ru_en Dev loss: 0.4404 r:0.7324
Current avg r:0.5908 Best avg r: 0.5908
16:10:57,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:10,195 root INFO 
id:en_de cur r: 0.2130 best r: 0.2130
16:11:23,19 root INFO 
id:en_zh cur r: 0.4287 best r: 0.4287
16:11:35,863 root INFO 
id:ro_en cur r: 0.7970 best r: 0.7970
16:12:01,567 root INFO 
id:ne_en cur r: 0.7383 best r: 0.7383
16:12:14,363 root INFO 
id:ru_en cur r: 0.7369 best r: 0.7369
16:12:14,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:44,165 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:13:44,171 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:13:44,177 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:13:44,182 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:13:44,187 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:13:44,191 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:13:44,196 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:13:57,52 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5679
en_de Dev loss: 0.8819 r:0.2102
en_zh Dev loss: 0.7192 r:0.4370
ro_en Dev loss: 0.3831 r:0.7968
et_en Dev loss: 0.5303 r:0.6546
si_en Dev loss: 0.7933 r:0.5768
ne_en Dev loss: 0.5085 r:0.7272
ru_en Dev loss: 0.4518 r:0.7395
Current avg r:0.5917 Best avg r: 0.5917
16:17:47,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:00,499 root INFO 
id:en_de cur r: 0.2166 best r: 0.2166
16:18:51,871 root INFO 
id:ne_en cur r: 0.7389 best r: 0.7389
16:19:04,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:34,460 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:20:34,468 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:20:34,475 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:20:34,479 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:20:34,485 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:20:34,490 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:20:34,495 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:20:47,357 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5331
en_de Dev loss: 0.8683 r:0.2050
en_zh Dev loss: 0.7553 r:0.4410
ro_en Dev loss: 0.3962 r:0.7976
et_en Dev loss: 0.5055 r:0.6595
si_en Dev loss: 0.6955 r:0.5872
ne_en Dev loss: 0.4573 r:0.7303
ru_en Dev loss: 0.4619 r:0.7368
Current avg r:0.5939 Best avg r: 0.5939
16:24:36,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:49,183 root INFO 
id:en_de cur r: 0.2273 best r: 0.2273
16:25:02,2 root INFO 
id:en_zh cur r: 0.4448 best r: 0.4448
16:25:53,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:23,172 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:27:23,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:27:23,186 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:27:23,190 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:27:23,195 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:27:23,200 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:27:23,204 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:27:36,51 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5073
en_de Dev loss: 0.8770 r:0.2275
en_zh Dev loss: 0.7138 r:0.4547
ro_en Dev loss: 0.3578 r:0.7924
et_en Dev loss: 0.4413 r:0.6719
si_en Dev loss: 0.6011 r:0.5853
ne_en Dev loss: 0.3735 r:0.7355
ru_en Dev loss: 0.4389 r:0.7399
Current avg r:0.6010 Best avg r: 0.6010
16:31:25,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:42,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:11,899 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5747
en_de Dev loss: 0.8659 r:0.2253
en_zh Dev loss: 0.7317 r:0.4473
ro_en Dev loss: 0.3705 r:0.7971
et_en Dev loss: 0.4979 r:0.6626
si_en Dev loss: 0.7731 r:0.5892
ne_en Dev loss: 0.5191 r:0.7283
ru_en Dev loss: 0.4358 r:0.7447
Current avg r:0.5992 Best avg r: 0.6010
16:38:01,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:26,888 root INFO 
id:en_zh cur r: 0.4523 best r: 0.4523
16:38:39,766 root INFO 
id:ro_en cur r: 0.7974 best r: 0.7974
16:38:52,663 root INFO 
id:si_en cur r: 0.5867 best r: 0.5867
16:39:05,569 root INFO 
id:ne_en cur r: 0.7470 best r: 0.7470
16:39:18,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:48,151 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:40:48,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:40:48,162 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:40:48,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:40:48,171 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:40:48,176 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:40:48,180 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:41:01,28 root INFO Epoch 1 Global steps: 11400 Train loss: 0.5025
en_de Dev loss: 0.8467 r:0.2248
en_zh Dev loss: 0.7131 r:0.4634
ro_en Dev loss: 0.3430 r:0.7988
et_en Dev loss: 0.4672 r:0.6712
si_en Dev loss: 0.6676 r:0.5975
ne_en Dev loss: 0.4361 r:0.7396
ru_en Dev loss: 0.4147 r:0.7506
Current avg r:0.6066 Best avg r: 0.6066
16:44:50,286 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:16,34 root INFO 
id:en_zh cur r: 0.4716 best r: 0.4716
16:45:28,929 root INFO 
id:ro_en cur r: 0.8018 best r: 0.8018
16:45:54,659 root INFO 
id:ne_en cur r: 0.7471 best r: 0.7471
16:46:07,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:37,278 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5583
en_de Dev loss: 0.8690 r:0.2380
en_zh Dev loss: 0.7574 r:0.4737
ro_en Dev loss: 0.4462 r:0.8019
et_en Dev loss: 0.5896 r:0.6660
si_en Dev loss: 0.8732 r:0.5911
ne_en Dev loss: 0.5580 r:0.7403
ru_en Dev loss: 0.5453 r:0.7324
Current avg r:0.6062 Best avg r: 0.6066
16:51:26,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:39,299 root INFO 
id:en_de cur r: 0.2525 best r: 0.2525
16:52:06,413 root INFO 
id:ro_en cur r: 0.8050 best r: 0.8050
16:52:19,304 root INFO 
id:si_en cur r: 0.5946 best r: 0.5946
16:52:45,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:15,29 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:54:15,36 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:54:15,41 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:54:15,46 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:54:15,52 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:54:15,57 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:54:15,62 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:54:27,927 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5198
en_de Dev loss: 0.8474 r:0.2478
en_zh Dev loss: 0.7361 r:0.4630
ro_en Dev loss: 0.3451 r:0.8031
et_en Dev loss: 0.4724 r:0.6705
si_en Dev loss: 0.6695 r:0.6019
ne_en Dev loss: 0.4220 r:0.7452
ru_en Dev loss: 0.4481 r:0.7339
Current avg r:0.6093 Best avg r: 0.6093
16:58:17,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:55,504 root INFO 
id:ro_en cur r: 0.8081 best r: 0.8081
16:59:08,350 root INFO 
id:si_en cur r: 0.6092 best r: 0.6092
16:59:33,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:03,734 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4983
en_de Dev loss: 0.8824 r:0.2429
en_zh Dev loss: 0.7860 r:0.4534
ro_en Dev loss: 0.3706 r:0.8056
et_en Dev loss: 0.4972 r:0.6778
si_en Dev loss: 0.6693 r:0.6087
ne_en Dev loss: 0.3924 r:0.7440
ru_en Dev loss: 0.5267 r:0.7329
Current avg r:0.6093 Best avg r: 0.6093
17:04:52,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:31,195 root INFO 
id:ro_en cur r: 0.8093 best r: 0.8093
17:05:56,885 root INFO 
id:ne_en cur r: 0.7495 best r: 0.7495
17:06:09,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:39,414 root INFO Epoch 1 Global steps: 13800 Train loss: 0.5059
en_de Dev loss: 0.8574 r:0.2337
en_zh Dev loss: 0.8169 r:0.4559
ro_en Dev loss: 0.3793 r:0.8078
et_en Dev loss: 0.5500 r:0.6721
si_en Dev loss: 0.8181 r:0.5936
ne_en Dev loss: 0.4419 r:0.7478
ru_en Dev loss: 0.5022 r:0.7299
Current avg r:0.6058 Best avg r: 0.6093
17:11:28,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:53,891 root INFO 
id:en_zh cur r: 0.4718 best r: 0.4718
17:12:32,534 root INFO 
id:ne_en cur r: 0.7520 best r: 0.7520
17:12:45,374 root INFO 
id:ru_en cur r: 0.7398 best r: 0.7398
17:12:45,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:15,314 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
17:14:15,320 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:14:15,328 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:14:15,332 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
17:14:15,337 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
17:14:15,342 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:14:15,346 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:14:28,213 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4979
en_de Dev loss: 0.8400 r:0.2491
en_zh Dev loss: 0.7140 r:0.4732
ro_en Dev loss: 0.3708 r:0.8018
et_en Dev loss: 0.4681 r:0.6807
si_en Dev loss: 0.6874 r:0.6069
ne_en Dev loss: 0.4059 r:0.7509
ru_en Dev loss: 0.4572 r:0.7441
Current avg r:0.6152 Best avg r: 0.6152
17:18:17,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:55,863 root INFO 
id:ro_en cur r: 0.8136 best r: 0.8136
17:19:08,734 root INFO 
id:si_en cur r: 0.6103 best r: 0.6103
17:19:34,379 root INFO 
id:ru_en cur r: 0.7489 best r: 0.7489
17:19:34,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:04,151 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4635
en_de Dev loss: 0.8692 r:0.2268
en_zh Dev loss: 0.7613 r:0.4575
ro_en Dev loss: 0.3320 r:0.8162
et_en Dev loss: 0.4948 r:0.6804
si_en Dev loss: 0.7396 r:0.6030
ne_en Dev loss: 0.3933 r:0.7514
ru_en Dev loss: 0.4353 r:0.7530
Current avg r:0.6126 Best avg r: 0.6152
17:24:54,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:20,153 root INFO 
id:en_zh cur r: 0.4762 best r: 0.4762
17:25:33,12 root INFO 
id:ro_en cur r: 0.8144 best r: 0.8144
17:26:11,521 root INFO 
id:ru_en cur r: 0.7588 best r: 0.7588
17:26:11,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:41,335 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
17:27:41,341 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:27:41,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:27:41,351 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
17:27:41,355 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
17:27:41,360 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:27:41,364 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:27:54,217 root INFO Epoch 1 Global steps: 15600 Train loss: 0.5122
en_de Dev loss: 0.8457 r:0.2415
en_zh Dev loss: 0.6996 r:0.4784
ro_en Dev loss: 0.3313 r:0.8130
et_en Dev loss: 0.4784 r:0.6740
si_en Dev loss: 0.7932 r:0.5987
ne_en Dev loss: 0.3979 r:0.7504
ru_en Dev loss: 0.3863 r:0.7619
Current avg r:0.6169 Best avg r: 0.6169
17:31:43,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:08,920 root INFO 
id:en_zh cur r: 0.4778 best r: 0.4778
17:32:21,766 root INFO 
id:ro_en cur r: 0.8237 best r: 0.8237
17:32:34,628 root INFO 
id:si_en cur r: 0.6171 best r: 0.6171
17:32:47,498 root INFO 
id:ne_en cur r: 0.7608 best r: 0.7608
17:33:00,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:30,89 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
17:34:30,97 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:34:30,102 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:34:30,107 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
17:34:30,111 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
17:34:30,116 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:34:30,121 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:34:42,976 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4977
en_de Dev loss: 0.8510 r:0.2451
en_zh Dev loss: 0.6911 r:0.4748
ro_en Dev loss: 0.2998 r:0.8226
et_en Dev loss: 0.4620 r:0.6796
si_en Dev loss: 0.6997 r:0.6153
ne_en Dev loss: 0.4043 r:0.7593
ru_en Dev loss: 0.3955 r:0.7637
Current avg r:0.6229 Best avg r: 0.6229
17:38:32,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:49,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:18,856 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4739
en_de Dev loss: 0.8580 r:0.2406
en_zh Dev loss: 0.7156 r:0.4668
ro_en Dev loss: 0.3378 r:0.8158
et_en Dev loss: 0.4624 r:0.6779
si_en Dev loss: 0.6840 r:0.6044
ne_en Dev loss: 0.4102 r:0.7567
ru_en Dev loss: 0.3986 r:0.7559
Current avg r:0.6168 Best avg r: 0.6229
17:45:07,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:33,545 root INFO 
id:en_zh cur r: 0.4842 best r: 0.4842
17:46:24,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:54,621 root INFO Epoch 1 Global steps: 17400 Train loss: 0.5509
en_de Dev loss: 0.8575 r:0.2683
en_zh Dev loss: 0.6902 r:0.4825
ro_en Dev loss: 0.3426 r:0.8123
et_en Dev loss: 0.4866 r:0.6772
si_en Dev loss: 0.8058 r:0.5979
ne_en Dev loss: 0.4190 r:0.7544
ru_en Dev loss: 0.4408 r:0.7516
Current avg r:0.6206 Best avg r: 0.6229
17:51:43,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:57,754 root INFO 
id:en_de cur r: 0.2656 best r: 0.2656
17:53:02,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:33,541 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4723
en_de Dev loss: 0.8808 r:0.2507
en_zh Dev loss: 0.7731 r:0.4685
ro_en Dev loss: 0.4112 r:0.8107
et_en Dev loss: 0.5854 r:0.6708
si_en Dev loss: 0.9733 r:0.5837
ne_en Dev loss: 0.7268 r:0.7442
ru_en Dev loss: 0.5529 r:0.7255
Current avg r:0.6077 Best avg r: 0.6229
17:58:24,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:41,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:10,945 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4617
en_de Dev loss: 0.8866 r:0.2527
en_zh Dev loss: 0.8294 r:0.4623
ro_en Dev loss: 0.4104 r:0.8130
et_en Dev loss: 0.6023 r:0.6639
si_en Dev loss: 0.9767 r:0.5887
ne_en Dev loss: 0.6831 r:0.7434
ru_en Dev loss: 0.5473 r:0.7198
Current avg r:0.6062 Best avg r: 0.6229
18:05:00,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:17,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:46,881 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4190
en_de Dev loss: 0.8405 r:0.2568
en_zh Dev loss: 0.7177 r:0.4707
ro_en Dev loss: 0.3209 r:0.8203
et_en Dev loss: 0.4406 r:0.6845
si_en Dev loss: 0.6469 r:0.6136
ne_en Dev loss: 0.4264 r:0.7540
ru_en Dev loss: 0.4158 r:0.7481
Current avg r:0.6212 Best avg r: 0.6229
18:11:35,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:54,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:24,54 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4784
en_de Dev loss: 0.8620 r:0.2491
en_zh Dev loss: 0.7475 r:0.4735
ro_en Dev loss: 0.3546 r:0.8164
et_en Dev loss: 0.5181 r:0.6792
si_en Dev loss: 0.7195 r:0.6114
ne_en Dev loss: 0.4553 r:0.7532
ru_en Dev loss: 0.4684 r:0.7417
Current avg r:0.6178 Best avg r: 0.6229
18:18:14,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:31,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:01,15 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4532
en_de Dev loss: 0.8735 r:0.1996
en_zh Dev loss: 0.7704 r:0.4716
ro_en Dev loss: 0.3555 r:0.8201
et_en Dev loss: 0.5028 r:0.6790
si_en Dev loss: 0.6889 r:0.6124
ne_en Dev loss: 0.4387 r:0.7543
ru_en Dev loss: 0.4602 r:0.7416
Current avg r:0.6112 Best avg r: 0.6229
18:24:51,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:08,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:38,19 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4443
en_de Dev loss: 0.8425 r:0.2496
en_zh Dev loss: 0.7069 r:0.4791
ro_en Dev loss: 0.3773 r:0.8094
et_en Dev loss: 0.4988 r:0.6746
si_en Dev loss: 0.7983 r:0.6034
ne_en Dev loss: 0.4342 r:0.7518
ru_en Dev loss: 0.4479 r:0.7461
Current avg r:0.6163 Best avg r: 0.6229
18:31:27,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:44,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:14,28 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4496
en_de Dev loss: 0.8593 r:0.2479
en_zh Dev loss: 0.7398 r:0.4775
ro_en Dev loss: 0.3643 r:0.8093
et_en Dev loss: 0.5248 r:0.6689
si_en Dev loss: 0.7825 r:0.6035
ne_en Dev loss: 0.6288 r:0.7459
ru_en Dev loss: 0.5007 r:0.7305
Current avg r:0.6119 Best avg r: 0.6229
18:38:02,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:19,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:49,751 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4456
en_de Dev loss: 0.8374 r:0.2625
en_zh Dev loss: 0.7301 r:0.4814
ro_en Dev loss: 0.3619 r:0.8170
et_en Dev loss: 0.4916 r:0.6779
si_en Dev loss: 0.7423 r:0.6097
ne_en Dev loss: 0.3776 r:0.7527
ru_en Dev loss: 0.4442 r:0.7592
Current avg r:0.6229 Best avg r: 0.6229
18:44:38,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:51,648 root INFO 
id:en_de cur r: 0.2659 best r: 0.2659
18:45:55,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:25,533 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4699
en_de Dev loss: 0.8377 r:0.2443
en_zh Dev loss: 0.7138 r:0.4715
ro_en Dev loss: 0.3352 r:0.8141
et_en Dev loss: 0.4658 r:0.6752
si_en Dev loss: 0.7056 r:0.6006
ne_en Dev loss: 0.4528 r:0.7571
ru_en Dev loss: 0.4563 r:0.7356
Current avg r:0.6141 Best avg r: 0.6229
18:51:14,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:27,361 root INFO 
id:en_de cur r: 0.2756 best r: 0.2756
18:52:18,703 root INFO 
id:ne_en cur r: 0.7624 best r: 0.7624
18:52:31,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:01,263 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4559
en_de Dev loss: 0.8368 r:0.2627
en_zh Dev loss: 0.6909 r:0.4759
ro_en Dev loss: 0.3236 r:0.8193
et_en Dev loss: 0.4342 r:0.6791
si_en Dev loss: 0.6385 r:0.6173
ne_en Dev loss: 0.4291 r:0.7587
ru_en Dev loss: 0.4200 r:0.7431
Current avg r:0.6223 Best avg r: 0.6229
18:57:50,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:07,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:37,242 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4605
en_de Dev loss: 0.8429 r:0.2582
en_zh Dev loss: 0.7725 r:0.4592
ro_en Dev loss: 0.3496 r:0.8161
et_en Dev loss: 0.4566 r:0.6818
si_en Dev loss: 0.7548 r:0.6037
ne_en Dev loss: 0.4325 r:0.7513
ru_en Dev loss: 0.4688 r:0.7316
Current avg r:0.6145 Best avg r: 0.6229
19:04:26,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:39,11 root INFO 
id:en_de cur r: 0.2785 best r: 0.2785
19:05:44,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:14,530 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4176
en_de Dev loss: 0.8342 r:0.2663
en_zh Dev loss: 0.7281 r:0.4671
ro_en Dev loss: 0.3452 r:0.8153
et_en Dev loss: 0.4640 r:0.6749
si_en Dev loss: 0.7521 r:0.6055
ne_en Dev loss: 0.4753 r:0.7504
ru_en Dev loss: 0.4410 r:0.7312
Current avg r:0.6158 Best avg r: 0.6229
19:11:03,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:20,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:51,258 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4257
en_de Dev loss: 0.8481 r:0.2666
en_zh Dev loss: 0.7164 r:0.4738
ro_en Dev loss: 0.3215 r:0.8170
et_en Dev loss: 0.4428 r:0.6760
si_en Dev loss: 0.6676 r:0.6046
ne_en Dev loss: 0.4327 r:0.7505
ru_en Dev loss: 0.4536 r:0.7265
Current avg r:0.6164 Best avg r: 0.6229
19:17:40,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:57,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:27,426 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4603
en_de Dev loss: 0.8639 r:0.2215
en_zh Dev loss: 0.8110 r:0.4671
ro_en Dev loss: 0.4360 r:0.8124
et_en Dev loss: 0.5627 r:0.6729
si_en Dev loss: 1.0425 r:0.5912
ne_en Dev loss: 0.7226 r:0.7396
ru_en Dev loss: 0.5899 r:0.7103
Current avg r:0.6021 Best avg r: 0.6229
19:24:16,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:33,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:03,262 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4354
en_de Dev loss: 0.8415 r:0.2516
en_zh Dev loss: 0.7332 r:0.4705
ro_en Dev loss: 0.3283 r:0.8217
et_en Dev loss: 0.4403 r:0.6774
si_en Dev loss: 0.6641 r:0.6146
ne_en Dev loss: 0.4158 r:0.7549
ru_en Dev loss: 0.4473 r:0.7462
Current avg r:0.6196 Best avg r: 0.6229
19:30:52,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:09,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:39,361 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4527
en_de Dev loss: 0.8449 r:0.2573
en_zh Dev loss: 0.7919 r:0.4614
ro_en Dev loss: 0.3801 r:0.8192
et_en Dev loss: 0.5070 r:0.6715
si_en Dev loss: 0.8654 r:0.6018
ne_en Dev loss: 0.4853 r:0.7526
ru_en Dev loss: 0.5286 r:0.7163
Current avg r:0.6115 Best avg r: 0.6229
19:37:29,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:33,735 root INFO 
id:ne_en cur r: 0.7634 best r: 0.7634
19:38:46,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:16,329 root INFO Epoch 3 Global steps: 27600 Train loss: 0.4143
en_de Dev loss: 0.8454 r:0.2500
en_zh Dev loss: 0.7101 r:0.4758
ro_en Dev loss: 0.3397 r:0.8213
et_en Dev loss: 0.4377 r:0.6823
si_en Dev loss: 0.6397 r:0.6210
ne_en Dev loss: 0.3983 r:0.7574
ru_en Dev loss: 0.4445 r:0.7362
Current avg r:0.6206 Best avg r: 0.6229
19:44:05,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:22,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:46:52,37 root INFO Epoch 3 Global steps: 28200 Train loss: 0.4018
en_de Dev loss: 0.8648 r:0.2520
en_zh Dev loss: 0.7602 r:0.4551
ro_en Dev loss: 0.3501 r:0.8131
et_en Dev loss: 0.4641 r:0.6717
si_en Dev loss: 0.7725 r:0.5978
ne_en Dev loss: 0.5173 r:0.7437
ru_en Dev loss: 0.4871 r:0.7191
Current avg r:0.6075 Best avg r: 0.6229
19:50:41,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:58,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:28,182 root INFO Epoch 3 Global steps: 28800 Train loss: 0.4169
en_de Dev loss: 0.8555 r:0.2480
en_zh Dev loss: 0.7399 r:0.4600
ro_en Dev loss: 0.3673 r:0.8159
et_en Dev loss: 0.4258 r:0.6858
si_en Dev loss: 0.7029 r:0.6061
ne_en Dev loss: 0.4228 r:0.7421
ru_en Dev loss: 0.4674 r:0.7313
Current avg r:0.6128 Best avg r: 0.6229
19:57:17,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:34,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:04,23 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4154
en_de Dev loss: 0.8565 r:0.2350
en_zh Dev loss: 0.7878 r:0.4585
ro_en Dev loss: 0.3716 r:0.8175
et_en Dev loss: 0.4549 r:0.6799
si_en Dev loss: 0.7439 r:0.6116
ne_en Dev loss: 0.4459 r:0.7417
ru_en Dev loss: 0.4899 r:0.7299
Current avg r:0.6106 Best avg r: 0.6229
20:03:54,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:33,78 root INFO 
id:ro_en cur r: 0.8245 best r: 0.8245
20:05:11,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:41,763 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3815
en_de Dev loss: 0.8480 r:0.2446
en_zh Dev loss: 0.7144 r:0.4743
ro_en Dev loss: 0.3282 r:0.8230
et_en Dev loss: 0.4290 r:0.6852
si_en Dev loss: 0.6772 r:0.6187
ne_en Dev loss: 0.4319 r:0.7525
ru_en Dev loss: 0.4230 r:0.7503
Current avg r:0.6212 Best avg r: 0.6229
20:10:32,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:49,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:19,613 root INFO Epoch 3 Global steps: 30600 Train loss: 0.4044
en_de Dev loss: 0.8860 r:0.2126
en_zh Dev loss: 0.8093 r:0.4532
ro_en Dev loss: 0.3815 r:0.8211
et_en Dev loss: 0.4999 r:0.6723
si_en Dev loss: 0.8087 r:0.6057
ne_en Dev loss: 0.5244 r:0.7488
ru_en Dev loss: 0.4801 r:0.7333
Current avg r:0.6067 Best avg r: 0.6229
20:17:08,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:25,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:55,799 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3765
en_de Dev loss: 0.8761 r:0.2269
en_zh Dev loss: 0.8511 r:0.4468
ro_en Dev loss: 0.4032 r:0.8215
et_en Dev loss: 0.5016 r:0.6792
si_en Dev loss: 0.8223 r:0.6099
ne_en Dev loss: 0.4606 r:0.7522
ru_en Dev loss: 0.5053 r:0.7355
Current avg r:0.6103 Best avg r: 0.6229
20:23:45,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:02,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:31,893 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3799
en_de Dev loss: 0.8474 r:0.2338
en_zh Dev loss: 0.7475 r:0.4542
ro_en Dev loss: 0.3631 r:0.8174
et_en Dev loss: 0.4795 r:0.6675
si_en Dev loss: 0.8758 r:0.5920
ne_en Dev loss: 0.5428 r:0.7435
ru_en Dev loss: 0.4824 r:0.7252
Current avg r:0.6048 Best avg r: 0.6229
20:30:20,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:37,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:07,519 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3932
en_de Dev loss: 0.8503 r:0.2327
en_zh Dev loss: 0.7709 r:0.4562
ro_en Dev loss: 0.3262 r:0.8204
et_en Dev loss: 0.4487 r:0.6805
si_en Dev loss: 0.8248 r:0.6077
ne_en Dev loss: 0.3937 r:0.7526
ru_en Dev loss: 0.4980 r:0.7284
Current avg r:0.6112 Best avg r: 0.6229
20:36:56,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:13,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:43,343 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3964
en_de Dev loss: 0.8495 r:0.2131
en_zh Dev loss: 0.7984 r:0.4532
ro_en Dev loss: 0.3390 r:0.8211
et_en Dev loss: 0.4654 r:0.6755
si_en Dev loss: 0.7934 r:0.6041
ne_en Dev loss: 0.5414 r:0.7430
ru_en Dev loss: 0.4718 r:0.7276
Current avg r:0.6054 Best avg r: 0.6229
20:43:32,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:49,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:19,182 root INFO Epoch 3 Global steps: 33600 Train loss: 0.4054
en_de Dev loss: 0.8557 r:0.2388
en_zh Dev loss: 0.8154 r:0.4596
ro_en Dev loss: 0.3573 r:0.8163
et_en Dev loss: 0.4861 r:0.6624
si_en Dev loss: 0.8896 r:0.5945
ne_en Dev loss: 0.4914 r:0.7386
ru_en Dev loss: 0.5336 r:0.7127
Current avg r:0.6033 Best avg r: 0.6229
20:50:09,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:26,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:56,262 root INFO Epoch 3 Global steps: 34200 Train loss: 0.4085
en_de Dev loss: 0.8487 r:0.2388
en_zh Dev loss: 0.7945 r:0.4470
ro_en Dev loss: 0.3705 r:0.8132
et_en Dev loss: 0.4688 r:0.6696
si_en Dev loss: 0.8271 r:0.5965
ne_en Dev loss: 0.5706 r:0.7463
ru_en Dev loss: 0.4804 r:0.7210
Current avg r:0.6046 Best avg r: 0.6229
20:56:45,104 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:02,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:33,457 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3819
en_de Dev loss: 0.8813 r:0.2208
en_zh Dev loss: 0.8587 r:0.4337
ro_en Dev loss: 0.3627 r:0.8160
et_en Dev loss: 0.4870 r:0.6676
si_en Dev loss: 0.7723 r:0.5961
ne_en Dev loss: 0.5387 r:0.7443
ru_en Dev loss: 0.5137 r:0.7166
Current avg r:0.5993 Best avg r: 0.6229
21:03:22,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:39,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:09,490 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3793
en_de Dev loss: 0.8576 r:0.2237
en_zh Dev loss: 0.7601 r:0.4450
ro_en Dev loss: 0.3260 r:0.8178
et_en Dev loss: 0.4314 r:0.6725
si_en Dev loss: 0.6912 r:0.5976
ne_en Dev loss: 0.4444 r:0.7493
ru_en Dev loss: 0.4354 r:0.7300
Current avg r:0.6051 Best avg r: 0.6229
21:09:58,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:15,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:12:45,64 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3850
en_de Dev loss: 0.8677 r:0.2159
en_zh Dev loss: 0.7902 r:0.4571
ro_en Dev loss: 0.3697 r:0.8137
et_en Dev loss: 0.4936 r:0.6659
si_en Dev loss: 0.7877 r:0.5986
ne_en Dev loss: 0.4152 r:0.7463
ru_en Dev loss: 0.4599 r:0.7371
Current avg r:0.6049 Best avg r: 0.6229
21:16:35,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:52,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:21,964 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3531
en_de Dev loss: 0.8732 r:0.2221
en_zh Dev loss: 0.8077 r:0.4444
ro_en Dev loss: 0.3755 r:0.8106
et_en Dev loss: 0.5376 r:0.6589
si_en Dev loss: 1.0157 r:0.5764
ne_en Dev loss: 0.5703 r:0.7488
ru_en Dev loss: 0.5097 r:0.7139
Current avg r:0.5964 Best avg r: 0.6229
21:23:10,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:27,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:57,561 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3657
en_de Dev loss: 0.8688 r:0.2248
en_zh Dev loss: 0.8219 r:0.4442
ro_en Dev loss: 0.3605 r:0.8186
et_en Dev loss: 0.4959 r:0.6711
si_en Dev loss: 0.8334 r:0.5878
ne_en Dev loss: 0.4726 r:0.7512
ru_en Dev loss: 0.5010 r:0.7262
Current avg r:0.6034 Best avg r: 0.6229
21:29:46,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:03,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:33,129 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3676
en_de Dev loss: 0.8654 r:0.2094
en_zh Dev loss: 0.8292 r:0.4471
ro_en Dev loss: 0.3812 r:0.8188
et_en Dev loss: 0.5161 r:0.6705
si_en Dev loss: 0.8768 r:0.5934
ne_en Dev loss: 0.5487 r:0.7538
ru_en Dev loss: 0.4624 r:0.7397
Current avg r:0.6047 Best avg r: 0.6229
21:36:23,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:40,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:10,73 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3450
en_de Dev loss: 0.8863 r:0.1831
en_zh Dev loss: 0.7981 r:0.4444
ro_en Dev loss: 0.3172 r:0.8230
et_en Dev loss: 0.4400 r:0.6687
si_en Dev loss: 0.7837 r:0.5954
ne_en Dev loss: 0.4214 r:0.7474
ru_en Dev loss: 0.4229 r:0.7391
Current avg r:0.6002 Best avg r: 0.6229
21:42:59,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:16,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:47,255 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3600
en_de Dev loss: 0.8666 r:0.2126
en_zh Dev loss: 0.7663 r:0.4623
ro_en Dev loss: 0.3461 r:0.8199
et_en Dev loss: 0.4381 r:0.6642
si_en Dev loss: 0.7512 r:0.5958
ne_en Dev loss: 0.4446 r:0.7426
ru_en Dev loss: 0.4740 r:0.7173
Current avg r:0.6021 Best avg r: 0.6229
21:49:36,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:53,527 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:23,424 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3428
en_de Dev loss: 0.8615 r:0.2016
en_zh Dev loss: 0.8708 r:0.4335
ro_en Dev loss: 0.3846 r:0.8171
et_en Dev loss: 0.4858 r:0.6576
si_en Dev loss: 0.8427 r:0.5919
ne_en Dev loss: 0.4631 r:0.7481
ru_en Dev loss: 0.5022 r:0.7159
Current avg r:0.5951 Best avg r: 0.6229
21:56:12,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:30,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:00,383 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3318
en_de Dev loss: 0.8642 r:0.2275
en_zh Dev loss: 0.8407 r:0.4516
ro_en Dev loss: 0.4146 r:0.8153
et_en Dev loss: 0.5104 r:0.6566
si_en Dev loss: 0.9396 r:0.5860
ne_en Dev loss: 0.5813 r:0.7392
ru_en Dev loss: 0.4909 r:0.7238
Current avg r:0.6000 Best avg r: 0.6229
22:02:49,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:06,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:36,98 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3325
en_de Dev loss: 0.8591 r:0.2151
en_zh Dev loss: 0.7392 r:0.4617
ro_en Dev loss: 0.3577 r:0.8172
et_en Dev loss: 0.4343 r:0.6630
si_en Dev loss: 0.7507 r:0.5937
ne_en Dev loss: 0.4384 r:0.7457
ru_en Dev loss: 0.4091 r:0.7445
Current avg r:0.6058 Best avg r: 0.6229
22:09:24,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:41,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:11,663 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3220
en_de Dev loss: 0.9003 r:0.2098
en_zh Dev loss: 0.7842 r:0.4625
ro_en Dev loss: 0.3902 r:0.8168
et_en Dev loss: 0.4768 r:0.6591
si_en Dev loss: 0.7605 r:0.5896
ne_en Dev loss: 0.4457 r:0.7415
ru_en Dev loss: 0.4797 r:0.7318
Current avg r:0.6016 Best avg r: 0.6229
22:16:00,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:17,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:47,526 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3220
en_de Dev loss: 0.8684 r:0.2293
en_zh Dev loss: 0.8077 r:0.4549
ro_en Dev loss: 0.3779 r:0.8179
et_en Dev loss: 0.4932 r:0.6570
si_en Dev loss: 0.8530 r:0.5887
ne_en Dev loss: 0.5328 r:0.7450
ru_en Dev loss: 0.4509 r:0.7381
Current avg r:0.6044 Best avg r: 0.6229
22:22:36,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:53,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:25:23,343 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3287
en_de Dev loss: 0.8901 r:0.1830
en_zh Dev loss: 0.9255 r:0.4093
ro_en Dev loss: 0.3926 r:0.8076
et_en Dev loss: 0.5607 r:0.6440
si_en Dev loss: 1.0333 r:0.5684
ne_en Dev loss: 0.8019 r:0.7353
ru_en Dev loss: 0.5813 r:0.6934
Current avg r:0.5773 Best avg r: 0.6229
22:29:12,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:29,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:58,963 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3429
en_de Dev loss: 0.8546 r:0.2323
en_zh Dev loss: 0.8150 r:0.4425
ro_en Dev loss: 0.3581 r:0.8133
et_en Dev loss: 0.4936 r:0.6553
si_en Dev loss: 0.8239 r:0.5814
ne_en Dev loss: 0.5447 r:0.7389
ru_en Dev loss: 0.5304 r:0.7087
Current avg r:0.5961 Best avg r: 0.6229
22:35:47,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:04,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:34,729 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3348
en_de Dev loss: 0.8760 r:0.2177
en_zh Dev loss: 0.7989 r:0.4454
ro_en Dev loss: 0.3521 r:0.8132
et_en Dev loss: 0.4719 r:0.6564
si_en Dev loss: 0.8171 r:0.5761
ne_en Dev loss: 0.4805 r:0.7416
ru_en Dev loss: 0.4731 r:0.7235
Current avg r:0.5963 Best avg r: 0.6229
22:42:23,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:40,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:10,302 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3292
en_de Dev loss: 0.8840 r:0.2322
en_zh Dev loss: 0.8087 r:0.4558
ro_en Dev loss: 0.4054 r:0.8105
et_en Dev loss: 0.5156 r:0.6538
si_en Dev loss: 0.8834 r:0.5811
ne_en Dev loss: 0.6197 r:0.7343
ru_en Dev loss: 0.5226 r:0.7238
Current avg r:0.5988 Best avg r: 0.6229
22:48:59,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:17,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:48,953 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3358
en_de Dev loss: 0.8722 r:0.2254
en_zh Dev loss: 0.8476 r:0.4399
ro_en Dev loss: 0.3937 r:0.8090
et_en Dev loss: 0.5061 r:0.6528
si_en Dev loss: 0.8319 r:0.5926
ne_en Dev loss: 0.4351 r:0.7421
ru_en Dev loss: 0.4977 r:0.7263
Current avg r:0.5983 Best avg r: 0.6229
22:55:39,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:55,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:25,662 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2800
en_de Dev loss: 0.8673 r:0.2309
en_zh Dev loss: 0.8098 r:0.4320
ro_en Dev loss: 0.3782 r:0.8031
et_en Dev loss: 0.4701 r:0.6436
si_en Dev loss: 0.7536 r:0.5856
ne_en Dev loss: 0.5168 r:0.7398
ru_en Dev loss: 0.4614 r:0.7236
Current avg r:0.5941 Best avg r: 0.6229
23:02:14,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:31,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:01,371 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3100
en_de Dev loss: 0.8519 r:0.2338
en_zh Dev loss: 0.7965 r:0.4467
ro_en Dev loss: 0.3500 r:0.8141
et_en Dev loss: 0.4691 r:0.6537
si_en Dev loss: 0.8031 r:0.5809
ne_en Dev loss: 0.4953 r:0.7375
ru_en Dev loss: 0.4329 r:0.7432
Current avg r:0.6014 Best avg r: 0.6229
23:08:50,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:07,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:36,783 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2887
en_de Dev loss: 0.8612 r:0.2122
en_zh Dev loss: 0.8353 r:0.4452
ro_en Dev loss: 0.3481 r:0.8169
et_en Dev loss: 0.4787 r:0.6525
si_en Dev loss: 0.7865 r:0.5858
ne_en Dev loss: 0.5302 r:0.7374
ru_en Dev loss: 0.4617 r:0.7333
Current avg r:0.5976 Best avg r: 0.6229
23:15:25,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:42,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:12,165 root INFO Epoch 5 Global steps: 47400 Train loss: 0.3057
en_de Dev loss: 0.8667 r:0.2171
en_zh Dev loss: 0.7831 r:0.4546
ro_en Dev loss: 0.3380 r:0.8163
et_en Dev loss: 0.4262 r:0.6581
si_en Dev loss: 0.6709 r:0.5892
ne_en Dev loss: 0.4018 r:0.7379
ru_en Dev loss: 0.4325 r:0.7287
Current avg r:0.6003 Best avg r: 0.6229
23:22:00,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:23:17,906 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:24:47,606 root INFO Epoch 5 Global steps: 48000 Train loss: 0.3063
en_de Dev loss: 0.8702 r:0.2166
en_zh Dev loss: 0.8269 r:0.4438
ro_en Dev loss: 0.3797 r:0.8138
et_en Dev loss: 0.4561 r:0.6588
si_en Dev loss: 0.8338 r:0.5742
ne_en Dev loss: 0.4325 r:0.7446
ru_en Dev loss: 0.4730 r:0.7288
Current avg r:0.5972 Best avg r: 0.6229
23:28:37,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:54,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:24,211 root INFO Epoch 5 Global steps: 48600 Train loss: 0.3169
en_de Dev loss: 0.8608 r:0.2237
en_zh Dev loss: 0.7608 r:0.4625
ro_en Dev loss: 0.3294 r:0.8181
et_en Dev loss: 0.4425 r:0.6624
si_en Dev loss: 0.7524 r:0.5910
ne_en Dev loss: 0.4682 r:0.7452
ru_en Dev loss: 0.4808 r:0.7229
Current avg r:0.6037 Best avg r: 0.6229
23:35:12,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:29,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:59,555 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2810
en_de Dev loss: 0.8799 r:0.2201
en_zh Dev loss: 0.8521 r:0.4479
ro_en Dev loss: 0.3865 r:0.8137
et_en Dev loss: 0.5203 r:0.6517
si_en Dev loss: 1.0240 r:0.5694
ne_en Dev loss: 0.5800 r:0.7377
ru_en Dev loss: 0.5264 r:0.7158
Current avg r:0.5937 Best avg r: 0.6229
23:41:48,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:05,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:35,99 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2919
en_de Dev loss: 0.8898 r:0.2218
en_zh Dev loss: 0.8463 r:0.4514
ro_en Dev loss: 0.3750 r:0.8148
et_en Dev loss: 0.5163 r:0.6463
si_en Dev loss: 0.9199 r:0.5714
ne_en Dev loss: 0.5349 r:0.7314
ru_en Dev loss: 0.5086 r:0.7211
Current avg r:0.5940 Best avg r: 0.6229
23:48:23,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:40,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:51:10,525 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2883
en_de Dev loss: 0.8791 r:0.1970
en_zh Dev loss: 0.7934 r:0.4487
ro_en Dev loss: 0.3520 r:0.8121
et_en Dev loss: 0.4451 r:0.6524
si_en Dev loss: 0.7692 r:0.5793
ne_en Dev loss: 0.4559 r:0.7407
ru_en Dev loss: 0.4568 r:0.7242
Current avg r:0.5935 Best avg r: 0.6229
23:54:59,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:17,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:48,957 root INFO Epoch 5 Global steps: 51000 Train loss: 0.3010
en_de Dev loss: 0.8700 r:0.2047
en_zh Dev loss: 0.7510 r:0.4580
ro_en Dev loss: 0.3181 r:0.8208
et_en Dev loss: 0.4255 r:0.6614
si_en Dev loss: 0.7119 r:0.5943
ne_en Dev loss: 0.4399 r:0.7385
ru_en Dev loss: 0.4107 r:0.7469
Current avg r:0.6035 Best avg r: 0.6229
00:01:37,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:54,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:24,683 root INFO Epoch 5 Global steps: 51600 Train loss: 0.3143
en_de Dev loss: 0.8739 r:0.1979
en_zh Dev loss: 0.7888 r:0.4537
ro_en Dev loss: 0.3576 r:0.8163
et_en Dev loss: 0.4417 r:0.6595
si_en Dev loss: 0.7653 r:0.5880
ne_en Dev loss: 0.4504 r:0.7330
ru_en Dev loss: 0.4657 r:0.7295
Current avg r:0.5968 Best avg r: 0.6229
00:08:13,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:30,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:00,41 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2953
en_de Dev loss: 0.8910 r:0.1877
en_zh Dev loss: 0.8369 r:0.4481
ro_en Dev loss: 0.3778 r:0.8112
et_en Dev loss: 0.4750 r:0.6482
si_en Dev loss: 0.8303 r:0.5740
ne_en Dev loss: 0.4937 r:0.7356
ru_en Dev loss: 0.5052 r:0.7147
Current avg r:0.5885 Best avg r: 0.6229
00:14:48,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:16:07,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:17:37,8 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2689
en_de Dev loss: 0.8943 r:0.1702
en_zh Dev loss: 0.8213 r:0.4505
ro_en Dev loss: 0.3611 r:0.8089
et_en Dev loss: 0.4662 r:0.6483
si_en Dev loss: 0.8850 r:0.5661
ne_en Dev loss: 0.5450 r:0.7343
ru_en Dev loss: 0.4683 r:0.7216
Current avg r:0.5857 Best avg r: 0.6229
00:21:25,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:42,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:24:12,242 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2862
en_de Dev loss: 0.8896 r:0.1614
en_zh Dev loss: 0.8108 r:0.4454
ro_en Dev loss: 0.3483 r:0.8116
et_en Dev loss: 0.4476 r:0.6533
si_en Dev loss: 0.7968 r:0.5726
ne_en Dev loss: 0.5351 r:0.7334
ru_en Dev loss: 0.5111 r:0.7096
Current avg r:0.5839 Best avg r: 0.6229
00:28:02,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:20,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:49,992 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2932
en_de Dev loss: 0.9186 r:0.1477
en_zh Dev loss: 0.8455 r:0.4529
ro_en Dev loss: 0.3558 r:0.8119
et_en Dev loss: 0.4858 r:0.6489
si_en Dev loss: 0.8645 r:0.5690
ne_en Dev loss: 0.4634 r:0.7365
ru_en Dev loss: 0.4988 r:0.7209
Current avg r:0.5840 Best avg r: 0.6229
00:34:40,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:57,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:27,923 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2561
en_de Dev loss: 0.9079 r:0.1723
en_zh Dev loss: 0.9517 r:0.4294
ro_en Dev loss: 0.4609 r:0.8049
et_en Dev loss: 0.5718 r:0.6386
si_en Dev loss: 1.1178 r:0.5474
ne_en Dev loss: 0.7043 r:0.7266
ru_en Dev loss: 0.5867 r:0.7047
Current avg r:0.5749 Best avg r: 0.6229
00:41:18,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:35,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:05,848 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2668
en_de Dev loss: 0.9038 r:0.1812
en_zh Dev loss: 0.8269 r:0.4539
ro_en Dev loss: 0.3712 r:0.8148
et_en Dev loss: 0.4659 r:0.6489
si_en Dev loss: 0.8042 r:0.5741
ne_en Dev loss: 0.4562 r:0.7386
ru_en Dev loss: 0.4688 r:0.7223
Current avg r:0.5905 Best avg r: 0.6229
00:47:56,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:15,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:45,57 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2678
en_de Dev loss: 0.8817 r:0.1713
en_zh Dev loss: 0.8070 r:0.4389
ro_en Dev loss: 0.3665 r:0.8071
et_en Dev loss: 0.4600 r:0.6440
si_en Dev loss: 0.8483 r:0.5609
ne_en Dev loss: 0.5251 r:0.7318
ru_en Dev loss: 0.4549 r:0.7223
Current avg r:0.5823 Best avg r: 0.6229
00:54:33,709 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:50,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:20,424 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2618
en_de Dev loss: 0.9096 r:0.1817
en_zh Dev loss: 0.8032 r:0.4569
ro_en Dev loss: 0.3363 r:0.8140
et_en Dev loss: 0.4530 r:0.6492
si_en Dev loss: 0.7898 r:0.5714
ne_en Dev loss: 0.5054 r:0.7394
ru_en Dev loss: 0.4503 r:0.7285
Current avg r:0.5916 Best avg r: 0.6229
01:01:09,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:02:26,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:55,744 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2396
en_de Dev loss: 0.9292 r:0.1690
en_zh Dev loss: 0.9049 r:0.4444
ro_en Dev loss: 0.3895 r:0.8088
et_en Dev loss: 0.5358 r:0.6430
si_en Dev loss: 0.9586 r:0.5618
ne_en Dev loss: 0.5502 r:0.7313
ru_en Dev loss: 0.5506 r:0.7096
Current avg r:0.5811 Best avg r: 0.6229
01:07:44,355 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:01,247 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:30,922 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2664
en_de Dev loss: 0.8880 r:0.1645
en_zh Dev loss: 0.8248 r:0.4373
ro_en Dev loss: 0.3453 r:0.8116
et_en Dev loss: 0.4785 r:0.6383
si_en Dev loss: 0.9334 r:0.5543
ne_en Dev loss: 0.5073 r:0.7353
ru_en Dev loss: 0.5264 r:0.6941
Current avg r:0.5765 Best avg r: 0.6229
01:14:20,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:37,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:07,439 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2534
en_de Dev loss: 0.9132 r:0.1706
en_zh Dev loss: 0.8570 r:0.4420
ro_en Dev loss: 0.3693 r:0.8122
et_en Dev loss: 0.4752 r:0.6408
si_en Dev loss: 0.8164 r:0.5648
ne_en Dev loss: 0.4767 r:0.7381
ru_en Dev loss: 0.5378 r:0.6945
Current avg r:0.5804 Best avg r: 0.6229
01:20:56,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:22:12,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:42,808 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2589
en_de Dev loss: 0.9209 r:0.1655
en_zh Dev loss: 0.8771 r:0.4395
ro_en Dev loss: 0.4052 r:0.8082
et_en Dev loss: 0.5045 r:0.6387
si_en Dev loss: 0.9215 r:0.5619
ne_en Dev loss: 0.6304 r:0.7380
ru_en Dev loss: 0.4990 r:0.7184
Current avg r:0.5814 Best avg r: 0.6229
01:27:31,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:48,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:18,3 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2624
en_de Dev loss: 0.9057 r:0.1536
en_zh Dev loss: 0.8422 r:0.4496
ro_en Dev loss: 0.4026 r:0.8074
et_en Dev loss: 0.4994 r:0.6370
si_en Dev loss: 0.8705 r:0.5641
ne_en Dev loss: 0.6344 r:0.7262
ru_en Dev loss: 0.5107 r:0.7093
Current avg r:0.5782 Best avg r: 0.6229
01:34:06,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:23,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:53,196 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2696
en_de Dev loss: 0.9127 r:0.1535
en_zh Dev loss: 0.9215 r:0.4434
ro_en Dev loss: 0.4179 r:0.8057
et_en Dev loss: 0.5210 r:0.6315
si_en Dev loss: 1.0509 r:0.5536
ne_en Dev loss: 0.6220 r:0.7177
ru_en Dev loss: 0.5862 r:0.6851
Current avg r:0.5701 Best avg r: 0.6229
01:40:41,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:41:58,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:28,388 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2606
en_de Dev loss: 0.9069 r:0.1641
en_zh Dev loss: 0.8834 r:0.4445
ro_en Dev loss: 0.4071 r:0.8096
et_en Dev loss: 0.4882 r:0.6475
si_en Dev loss: 0.9238 r:0.5701
ne_en Dev loss: 0.5615 r:0.7253
ru_en Dev loss: 0.5739 r:0.6916
Current avg r:0.5790 Best avg r: 0.6229
01:47:18,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:48:35,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:50:06,565 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2437
en_de Dev loss: 0.9290 r:0.1705
en_zh Dev loss: 0.8816 r:0.4465
ro_en Dev loss: 0.3914 r:0.8107
et_en Dev loss: 0.4978 r:0.6358
si_en Dev loss: 0.9644 r:0.5554
ne_en Dev loss: 0.5641 r:0.7145
ru_en Dev loss: 0.5629 r:0.6889
Current avg r:0.5746 Best avg r: 0.6229
01:53:57,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:55:15,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:56:46,217 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2463
en_de Dev loss: 0.9209 r:0.1698
en_zh Dev loss: 0.8519 r:0.4507
ro_en Dev loss: 0.3891 r:0.8114
et_en Dev loss: 0.4820 r:0.6451
si_en Dev loss: 0.9230 r:0.5606
ne_en Dev loss: 0.5435 r:0.7238
ru_en Dev loss: 0.5468 r:0.7019
Current avg r:0.5805 Best avg r: 0.6229
02:00:37,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:01:55,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:03:25,823 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2425
en_de Dev loss: 0.9177 r:0.1643
en_zh Dev loss: 0.8103 r:0.4597
ro_en Dev loss: 0.3764 r:0.8079
et_en Dev loss: 0.4708 r:0.6457
si_en Dev loss: 0.9268 r:0.5579
ne_en Dev loss: 0.5607 r:0.7263
ru_en Dev loss: 0.4733 r:0.7271
Current avg r:0.5841 Best avg r: 0.6229
02:07:16,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:08:34,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:05,340 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2552
en_de Dev loss: 0.9057 r:0.1731
en_zh Dev loss: 0.7780 r:0.4592
ro_en Dev loss: 0.3475 r:0.8133
et_en Dev loss: 0.4261 r:0.6613
si_en Dev loss: 0.7941 r:0.5669
ne_en Dev loss: 0.4926 r:0.7300
ru_en Dev loss: 0.4169 r:0.7429
Current avg r:0.5924 Best avg r: 0.6229
02:13:57,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:15:15,34 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:16:44,945 root INFO Epoch 7 Global steps: 63600 Train loss: 0.2150
en_de Dev loss: 0.9037 r:0.1698
en_zh Dev loss: 0.7987 r:0.4490
ro_en Dev loss: 0.3513 r:0.8086
et_en Dev loss: 0.4398 r:0.6466
si_en Dev loss: 0.8338 r:0.5509
ne_en Dev loss: 0.4750 r:0.7298
ru_en Dev loss: 0.4385 r:0.7269
Current avg r:0.5831 Best avg r: 0.6229
02:20:34,214 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:51,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:23:21,226 root INFO Epoch 7 Global steps: 64200 Train loss: 0.2129
en_de Dev loss: 0.9176 r:0.1587
en_zh Dev loss: 0.8539 r:0.4549
ro_en Dev loss: 0.3911 r:0.8072
et_en Dev loss: 0.4890 r:0.6451
si_en Dev loss: 0.9578 r:0.5524
ne_en Dev loss: 0.7100 r:0.7245
ru_en Dev loss: 0.4914 r:0.7209
Current avg r:0.5805 Best avg r: 0.6229
02:27:10,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:28:27,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:57,463 root INFO Epoch 7 Global steps: 64800 Train loss: 0.2382
en_de Dev loss: 0.9626 r:0.1420
en_zh Dev loss: 0.8490 r:0.4658
ro_en Dev loss: 0.3950 r:0.8055
et_en Dev loss: 0.4998 r:0.6381
si_en Dev loss: 0.9513 r:0.5548
ne_en Dev loss: 0.6063 r:0.7245
ru_en Dev loss: 0.4809 r:0.7309
Current avg r:0.5802 Best avg r: 0.6229
02:33:46,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:03,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:35,102 root INFO Epoch 7 Global steps: 65400 Train loss: 0.2238
en_de Dev loss: 0.9444 r:0.1453
en_zh Dev loss: 0.9251 r:0.4494
ro_en Dev loss: 0.3949 r:0.8073
et_en Dev loss: 0.5273 r:0.6378
si_en Dev loss: 1.0057 r:0.5510
ne_en Dev loss: 0.6451 r:0.7188
ru_en Dev loss: 0.5520 r:0.7077
Current avg r:0.5739 Best avg r: 0.6229
02:40:24,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:41:41,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:43:11,204 root INFO Epoch 7 Global steps: 66000 Train loss: 0.2125
en_de Dev loss: 0.9124 r:0.1421
en_zh Dev loss: 0.8214 r:0.4524
ro_en Dev loss: 0.3596 r:0.8134
et_en Dev loss: 0.4552 r:0.6495
si_en Dev loss: 0.8816 r:0.5564
ne_en Dev loss: 0.4832 r:0.7238
ru_en Dev loss: 0.4392 r:0.7377
Current avg r:0.5822 Best avg r: 0.6229
02:47:00,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:48:17,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:49:47,494 root INFO Epoch 7 Global steps: 66600 Train loss: 0.2164
en_de Dev loss: 0.9161 r:0.1614
en_zh Dev loss: 0.8813 r:0.4612
ro_en Dev loss: 0.3956 r:0.8124
et_en Dev loss: 0.5031 r:0.6406
si_en Dev loss: 0.9863 r:0.5515
ne_en Dev loss: 0.5652 r:0.7126
ru_en Dev loss: 0.5250 r:0.7191
Current avg r:0.5798 Best avg r: 0.6229
02:53:36,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:54:53,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:56:24,965 root INFO Epoch 7 Global steps: 67200 Train loss: 0.2248
en_de Dev loss: 0.9005 r:0.1701
en_zh Dev loss: 0.7836 r:0.4563
ro_en Dev loss: 0.3418 r:0.8150
et_en Dev loss: 0.4369 r:0.6472
si_en Dev loss: 0.7667 r:0.5616
ne_en Dev loss: 0.4536 r:0.7294
ru_en Dev loss: 0.4343 r:0.7266
Current avg r:0.5866 Best avg r: 0.6229
03:00:14,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:01:32,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:02,663 root INFO Epoch 7 Global steps: 67800 Train loss: 0.2169
en_de Dev loss: 0.8928 r:0.1775
en_zh Dev loss: 0.7749 r:0.4709
ro_en Dev loss: 0.3450 r:0.8149
et_en Dev loss: 0.4507 r:0.6466
si_en Dev loss: 0.8351 r:0.5591
ne_en Dev loss: 0.5141 r:0.7287
ru_en Dev loss: 0.4711 r:0.7237
Current avg r:0.5888 Best avg r: 0.6229
03:06:53,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:08:11,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:09:42,668 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2180
en_de Dev loss: 0.9037 r:0.1649
en_zh Dev loss: 0.8241 r:0.4655
ro_en Dev loss: 0.3784 r:0.8086
et_en Dev loss: 0.4913 r:0.6387
si_en Dev loss: 0.9690 r:0.5563
ne_en Dev loss: 0.6605 r:0.7248
ru_en Dev loss: 0.5190 r:0.7031
Current avg r:0.5803 Best avg r: 0.6229
03:13:33,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:51,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:23,787 root INFO Epoch 7 Global steps: 69000 Train loss: 0.2307
en_de Dev loss: 0.9468 r:0.1700
en_zh Dev loss: 0.8088 r:0.4721
ro_en Dev loss: 0.4052 r:0.8033
et_en Dev loss: 0.4891 r:0.6410
si_en Dev loss: 0.9251 r:0.5601
ne_en Dev loss: 0.5023 r:0.7284
ru_en Dev loss: 0.5272 r:0.7152
Current avg r:0.5843 Best avg r: 0.6229
03:20:14,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:32,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:02,285 root INFO Epoch 7 Global steps: 69600 Train loss: 0.2211
en_de Dev loss: 0.9341 r:0.1611
en_zh Dev loss: 0.9333 r:0.4565
ro_en Dev loss: 0.4813 r:0.7973
et_en Dev loss: 0.6278 r:0.6292
si_en Dev loss: 1.3370 r:0.5384
ne_en Dev loss: 0.8487 r:0.7161
ru_en Dev loss: 0.6605 r:0.6876
Current avg r:0.5695 Best avg r: 0.6229
03:26:55,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:12,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:29:42,520 root INFO Epoch 7 Global steps: 70200 Train loss: 0.2271
en_de Dev loss: 0.9151 r:0.1694
en_zh Dev loss: 0.7943 r:0.4659
ro_en Dev loss: 0.3567 r:0.8120
et_en Dev loss: 0.4640 r:0.6430
si_en Dev loss: 0.8726 r:0.5601
ne_en Dev loss: 0.5086 r:0.7251
ru_en Dev loss: 0.4770 r:0.7240
Current avg r:0.5856 Best avg r: 0.6229
03:33:31,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:34:48,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:18,756 root INFO Epoch 7 Global steps: 70800 Train loss: 0.2179
en_de Dev loss: 0.9626 r:0.1595
en_zh Dev loss: 0.8800 r:0.4683
ro_en Dev loss: 0.4591 r:0.8083
et_en Dev loss: 0.5533 r:0.6425
si_en Dev loss: 0.9945 r:0.5518
ne_en Dev loss: 0.6393 r:0.7227
ru_en Dev loss: 0.5905 r:0.7095
Current avg r:0.5804 Best avg r: 0.6229
03:40:08,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:41:25,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:42:55,57 root INFO Epoch 7 Global steps: 71400 Train loss: 0.2156
en_de Dev loss: 0.9288 r:0.1734
en_zh Dev loss: 0.8133 r:0.4686
ro_en Dev loss: 0.3695 r:0.8092
et_en Dev loss: 0.4779 r:0.6373
si_en Dev loss: 0.9075 r:0.5479
ne_en Dev loss: 0.5649 r:0.7209
ru_en Dev loss: 0.5053 r:0.7103
Current avg r:0.5811 Best avg r: 0.6229
03:46:44,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:48:01,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:49:32,739 root INFO Epoch 7 Global steps: 72000 Train loss: 0.2220
en_de Dev loss: 0.9223 r:0.1827
en_zh Dev loss: 0.8517 r:0.4660
ro_en Dev loss: 0.4243 r:0.8061
et_en Dev loss: 0.5218 r:0.6334
si_en Dev loss: 0.9671 r:0.5453
ne_en Dev loss: 0.6200 r:0.7175
ru_en Dev loss: 0.5420 r:0.7148
Current avg r:0.5808 Best avg r: 0.6229
03:53:23,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:54:40,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:56:10,390 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1966
en_de Dev loss: 0.9239 r:0.1607
en_zh Dev loss: 0.8248 r:0.4560
ro_en Dev loss: 0.4017 r:0.8047
et_en Dev loss: 0.4954 r:0.6302
si_en Dev loss: 0.9962 r:0.5373
ne_en Dev loss: 0.6234 r:0.7209
ru_en Dev loss: 0.5060 r:0.7121
Current avg r:0.5745 Best avg r: 0.6229
03:59:59,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:01:16,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:02:46,473 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1895
en_de Dev loss: 0.9112 r:0.1794
en_zh Dev loss: 0.7616 r:0.4750
ro_en Dev loss: 0.3523 r:0.8122
et_en Dev loss: 0.4481 r:0.6509
si_en Dev loss: 0.7986 r:0.5677
ne_en Dev loss: 0.5076 r:0.7241
ru_en Dev loss: 0.4726 r:0.7233
Current avg r:0.5904 Best avg r: 0.6229
04:06:35,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:07:52,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:09:22,813 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1922
en_de Dev loss: 0.9349 r:0.1417
en_zh Dev loss: 0.8448 r:0.4614
ro_en Dev loss: 0.3812 r:0.8125
et_en Dev loss: 0.4907 r:0.6369
si_en Dev loss: 0.8929 r:0.5591
ne_en Dev loss: 0.5500 r:0.7208
ru_en Dev loss: 0.5006 r:0.7195
Current avg r:0.5788 Best avg r: 0.6229
04:13:12,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:29,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:59,157 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1954
en_de Dev loss: 0.9209 r:0.1498
en_zh Dev loss: 0.8288 r:0.4623
ro_en Dev loss: 0.3775 r:0.8099
et_en Dev loss: 0.4685 r:0.6386
si_en Dev loss: 0.8521 r:0.5562
ne_en Dev loss: 0.5303 r:0.7198
ru_en Dev loss: 0.4527 r:0.7293
Current avg r:0.5808 Best avg r: 0.6229
04:19:48,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:05,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:22:35,735 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1893
en_de Dev loss: 0.9299 r:0.1514
en_zh Dev loss: 0.8286 r:0.4570
ro_en Dev loss: 0.3629 r:0.8107
et_en Dev loss: 0.4643 r:0.6371
si_en Dev loss: 0.8465 r:0.5575
ne_en Dev loss: 0.5296 r:0.7244
ru_en Dev loss: 0.4687 r:0.7180
Current avg r:0.5794 Best avg r: 0.6229
04:26:26,915 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:27:44,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:29:15,67 root INFO Epoch 8 Global steps: 75600 Train loss: 0.2019
en_de Dev loss: 0.9254 r:0.1766
en_zh Dev loss: 0.8107 r:0.4668
ro_en Dev loss: 0.3573 r:0.8134
et_en Dev loss: 0.4597 r:0.6405
si_en Dev loss: 0.8057 r:0.5617
ne_en Dev loss: 0.4813 r:0.7290
ru_en Dev loss: 0.4456 r:0.7334
Current avg r:0.5888 Best avg r: 0.6229
04:33:14,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:34:32,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:36:03,121 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1983
en_de Dev loss: 0.9322 r:0.1763
en_zh Dev loss: 0.8306 r:0.4752
ro_en Dev loss: 0.3956 r:0.8078
et_en Dev loss: 0.5074 r:0.6346
si_en Dev loss: 0.9936 r:0.5505
ne_en Dev loss: 0.6442 r:0.7211
ru_en Dev loss: 0.5513 r:0.7042
Current avg r:0.5814 Best avg r: 0.6229
04:39:54,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:41:13,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:42:44,319 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1982
en_de Dev loss: 0.9222 r:0.1748
en_zh Dev loss: 0.8477 r:0.4555
ro_en Dev loss: 0.3639 r:0.8093
et_en Dev loss: 0.4650 r:0.6436
si_en Dev loss: 0.8998 r:0.5517
ne_en Dev loss: 0.5206 r:0.7236
ru_en Dev loss: 0.4764 r:0.7287
Current avg r:0.5839 Best avg r: 0.6229
04:46:34,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:47:51,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:49:21,0 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1942
en_de Dev loss: 0.9136 r:0.1704
en_zh Dev loss: 0.8590 r:0.4528
ro_en Dev loss: 0.3708 r:0.8082
et_en Dev loss: 0.4861 r:0.6375
si_en Dev loss: 0.9302 r:0.5479
ne_en Dev loss: 0.6158 r:0.7129
ru_en Dev loss: 0.5141 r:0.7126
Current avg r:0.5775 Best avg r: 0.6229
04:53:10,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:54:27,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:55:57,653 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1963
en_de Dev loss: 0.9401 r:0.1484
en_zh Dev loss: 0.8917 r:0.4461
ro_en Dev loss: 0.4123 r:0.8069
et_en Dev loss: 0.5202 r:0.6314
si_en Dev loss: 1.0274 r:0.5384
ne_en Dev loss: 0.7490 r:0.7089
ru_en Dev loss: 0.5503 r:0.7014
Current avg r:0.5688 Best avg r: 0.6229
04:59:48,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:01:05,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:02:35,615 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1930
en_de Dev loss: 0.9514 r:0.1643
en_zh Dev loss: 0.8253 r:0.4656
ro_en Dev loss: 0.3671 r:0.8112
et_en Dev loss: 0.4713 r:0.6425
si_en Dev loss: 0.8810 r:0.5495
ne_en Dev loss: 0.5453 r:0.7101
ru_en Dev loss: 0.4942 r:0.7129
Current avg r:0.5794 Best avg r: 0.6229
05:06:24,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:07:42,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:09:12,180 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1818
en_de Dev loss: 0.9211 r:0.1730
en_zh Dev loss: 0.8009 r:0.4604
ro_en Dev loss: 0.3561 r:0.8105
et_en Dev loss: 0.4487 r:0.6489
si_en Dev loss: 0.8564 r:0.5519
ne_en Dev loss: 0.5417 r:0.7187
ru_en Dev loss: 0.4455 r:0.7290
Current avg r:0.5846 Best avg r: 0.6229
05:13:01,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:18,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:48,787 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1943
en_de Dev loss: 0.9343 r:0.1744
en_zh Dev loss: 0.9230 r:0.4557
ro_en Dev loss: 0.4306 r:0.8072
et_en Dev loss: 0.5168 r:0.6411
si_en Dev loss: 1.0191 r:0.5453
ne_en Dev loss: 0.6520 r:0.7194
ru_en Dev loss: 0.5376 r:0.7160
Current avg r:0.5799 Best avg r: 0.6229
05:19:38,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:57,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:22:28,167 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1911
en_de Dev loss: 0.9273 r:0.1842
en_zh Dev loss: 0.8141 r:0.4776
ro_en Dev loss: 0.3731 r:0.8167
et_en Dev loss: 0.4703 r:0.6488
si_en Dev loss: 0.8755 r:0.5602
ne_en Dev loss: 0.5658 r:0.7218
ru_en Dev loss: 0.4825 r:0.7300
Current avg r:0.5913 Best avg r: 0.6229
05:26:20,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:27:38,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:29:09,578 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1946
en_de Dev loss: 0.9454 r:0.1621
en_zh Dev loss: 0.8826 r:0.4592
ro_en Dev loss: 0.4035 r:0.8025
et_en Dev loss: 0.5041 r:0.6337
si_en Dev loss: 1.0105 r:0.5373
ne_en Dev loss: 0.6604 r:0.7096
ru_en Dev loss: 0.5287 r:0.7136
Current avg r:0.5740 Best avg r: 0.6229
05:33:03,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:34:21,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:35:52,354 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1853
en_de Dev loss: 0.9194 r:0.1661
en_zh Dev loss: 0.8033 r:0.4651
ro_en Dev loss: 0.3583 r:0.8077
et_en Dev loss: 0.4571 r:0.6349
si_en Dev loss: 0.8395 r:0.5513
ne_en Dev loss: 0.5252 r:0.7190
ru_en Dev loss: 0.4625 r:0.7246
Current avg r:0.5812 Best avg r: 0.6229
05:39:43,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:41:01,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:42:31,584 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1771
en_de Dev loss: 0.9424 r:0.1661
en_zh Dev loss: 0.8677 r:0.4622
ro_en Dev loss: 0.3708 r:0.8117
et_en Dev loss: 0.4923 r:0.6381
si_en Dev loss: 0.9805 r:0.5426
ne_en Dev loss: 0.5502 r:0.7170
ru_en Dev loss: 0.5093 r:0.7184
Current avg r:0.5794 Best avg r: 0.6229
05:46:21,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:47:38,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:49:08,473 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1712
en_de Dev loss: 0.9286 r:0.1543
en_zh Dev loss: 0.8304 r:0.4751
ro_en Dev loss: 0.3886 r:0.8093
et_en Dev loss: 0.4929 r:0.6380
si_en Dev loss: 0.9744 r:0.5490
ne_en Dev loss: 0.5738 r:0.7175
ru_en Dev loss: 0.4995 r:0.7203
Current avg r:0.5805 Best avg r: 0.6229
05:52:57,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:15,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:55:46,715 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1781
en_de Dev loss: 0.9264 r:0.1774
en_zh Dev loss: 0.8375 r:0.4727
ro_en Dev loss: 0.4002 r:0.8123
et_en Dev loss: 0.4894 r:0.6425
si_en Dev loss: 0.9120 r:0.5540
ne_en Dev loss: 0.5411 r:0.7139
ru_en Dev loss: 0.4796 r:0.7334
Current avg r:0.5866 Best avg r: 0.6229
05:59:36,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:00:53,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:02:23,61 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1665
en_de Dev loss: 0.9292 r:0.1689
en_zh Dev loss: 0.8145 r:0.4534
ro_en Dev loss: 0.3632 r:0.8066
et_en Dev loss: 0.4636 r:0.6362
si_en Dev loss: 0.8659 r:0.5431
ne_en Dev loss: 0.5710 r:0.7039
ru_en Dev loss: 0.4940 r:0.7144
Current avg r:0.5752 Best avg r: 0.6229
06:06:13,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:30,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:09:00,876 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1788
en_de Dev loss: 0.9358 r:0.1858
en_zh Dev loss: 0.8740 r:0.4682
ro_en Dev loss: 0.4032 r:0.8074
et_en Dev loss: 0.5143 r:0.6373
si_en Dev loss: 1.0051 r:0.5490
ne_en Dev loss: 0.6771 r:0.7060
ru_en Dev loss: 0.5392 r:0.7218
Current avg r:0.5822 Best avg r: 0.6229
06:12:50,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:07,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:37,317 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1793
en_de Dev loss: 0.9223 r:0.1723
en_zh Dev loss: 0.8549 r:0.4486
ro_en Dev loss: 0.3760 r:0.8046
et_en Dev loss: 0.4809 r:0.6375
si_en Dev loss: 0.9255 r:0.5501
ne_en Dev loss: 0.6220 r:0.7084
ru_en Dev loss: 0.5162 r:0.7188
Current avg r:0.5772 Best avg r: 0.6229
06:19:28,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:20:46,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:22:16,884 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1725
en_de Dev loss: 0.9445 r:0.1898
en_zh Dev loss: 0.8383 r:0.4567
ro_en Dev loss: 0.3839 r:0.8048
et_en Dev loss: 0.4940 r:0.6308
si_en Dev loss: 0.9757 r:0.5401
ne_en Dev loss: 0.5903 r:0.7150
ru_en Dev loss: 0.4636 r:0.7388
Current avg r:0.5823 Best avg r: 0.6229
06:26:08,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:27:25,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:28:56,464 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1790
en_de Dev loss: 0.9314 r:0.1869
en_zh Dev loss: 0.8172 r:0.4704
ro_en Dev loss: 0.3742 r:0.8065
et_en Dev loss: 0.4966 r:0.6331
si_en Dev loss: 1.0048 r:0.5436
ne_en Dev loss: 0.6064 r:0.7157
ru_en Dev loss: 0.4754 r:0.7355
Current avg r:0.5845 Best avg r: 0.6229
06:32:50,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:34:08,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:35:38,722 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1722
en_de Dev loss: 0.9333 r:0.1803
en_zh Dev loss: 0.8125 r:0.4563
ro_en Dev loss: 0.3755 r:0.8025
et_en Dev loss: 0.4997 r:0.6248
si_en Dev loss: 0.9667 r:0.5378
ne_en Dev loss: 0.6098 r:0.7065
ru_en Dev loss: 0.4858 r:0.7225
Current avg r:0.5758 Best avg r: 0.6229
06:39:32,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:40:50,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:42:20,529 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1812
en_de Dev loss: 0.9331 r:0.1749
en_zh Dev loss: 0.8046 r:0.4612
ro_en Dev loss: 0.3700 r:0.8052
et_en Dev loss: 0.4717 r:0.6357
si_en Dev loss: 0.9003 r:0.5464
ne_en Dev loss: 0.6032 r:0.7115
ru_en Dev loss: 0.4607 r:0.7285
Current avg r:0.5805 Best avg r: 0.6229
06:46:10,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:27,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:48:57,310 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1650
en_de Dev loss: 0.9213 r:0.1722
en_zh Dev loss: 0.7929 r:0.4708
ro_en Dev loss: 0.3627 r:0.8098
et_en Dev loss: 0.4733 r:0.6454
si_en Dev loss: 0.9020 r:0.5582
ne_en Dev loss: 0.5829 r:0.7161
ru_en Dev loss: 0.4839 r:0.7244
Current avg r:0.5853 Best avg r: 0.6229
06:52:46,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:04,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:55:35,491 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1714
en_de Dev loss: 0.9418 r:0.2084
en_zh Dev loss: 0.8396 r:0.4683
ro_en Dev loss: 0.3934 r:0.8066
et_en Dev loss: 0.5023 r:0.6361
si_en Dev loss: 0.9320 r:0.5491
ne_en Dev loss: 0.5319 r:0.7126
ru_en Dev loss: 0.4969 r:0.7252
Current avg r:0.5866 Best avg r: 0.6229
06:59:25,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:42,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:12,178 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1744
en_de Dev loss: 0.9242 r:0.1939
en_zh Dev loss: 0.8546 r:0.4468
ro_en Dev loss: 0.3709 r:0.8058
et_en Dev loss: 0.5107 r:0.6234
si_en Dev loss: 0.9902 r:0.5401
ne_en Dev loss: 0.6329 r:0.7049
ru_en Dev loss: 0.4919 r:0.7175
Current avg r:0.5761 Best avg r: 0.6229
07:06:01,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:07:18,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:48,759 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1762
en_de Dev loss: 0.9599 r:0.1843
en_zh Dev loss: 0.8808 r:0.4557
ro_en Dev loss: 0.3966 r:0.8074
et_en Dev loss: 0.5457 r:0.6294
si_en Dev loss: 1.0570 r:0.5379
ne_en Dev loss: 0.5848 r:0.7110
ru_en Dev loss: 0.5685 r:0.7023
Current avg r:0.5754 Best avg r: 0.6229
07:12:39,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:56,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:28,533 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1656
en_de Dev loss: 0.9447 r:0.1877
en_zh Dev loss: 0.8286 r:0.4731
ro_en Dev loss: 0.3729 r:0.8153
et_en Dev loss: 0.5191 r:0.6393
si_en Dev loss: 0.9767 r:0.5535
ne_en Dev loss: 0.5421 r:0.7095
ru_en Dev loss: 0.5095 r:0.7228
Current avg r:0.5859 Best avg r: 0.6229
07:19:19,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:20:37,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:22:08,366 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1546
en_de Dev loss: 0.9812 r:0.1708
en_zh Dev loss: 0.9332 r:0.4555
ro_en Dev loss: 0.4501 r:0.8032
et_en Dev loss: 0.5658 r:0.6279
si_en Dev loss: 1.0296 r:0.5388
ne_en Dev loss: 0.6398 r:0.7068
ru_en Dev loss: 0.5781 r:0.7102
Current avg r:0.5733 Best avg r: 0.6229
07:25:59,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:27:17,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:28:47,766 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1484
en_de Dev loss: 0.9658 r:0.1740
en_zh Dev loss: 0.8768 r:0.4712
ro_en Dev loss: 0.4376 r:0.8076
et_en Dev loss: 0.5504 r:0.6364
si_en Dev loss: 1.0749 r:0.5453
ne_en Dev loss: 0.6286 r:0.7161
ru_en Dev loss: 0.5287 r:0.7269
Current avg r:0.5825 Best avg r: 0.6229
07:32:39,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:33:56,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:35:27,460 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1562
en_de Dev loss: 0.9492 r:0.1824
en_zh Dev loss: 0.8377 r:0.4696
ro_en Dev loss: 0.3704 r:0.8145
et_en Dev loss: 0.5015 r:0.6408
si_en Dev loss: 0.9267 r:0.5499
ne_en Dev loss: 0.5305 r:0.7156
ru_en Dev loss: 0.4828 r:0.7297
Current avg r:0.5861 Best avg r: 0.6229
07:39:17,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:36,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:06,874 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1514
en_de Dev loss: 0.9322 r:0.1474
en_zh Dev loss: 0.8687 r:0.4658
ro_en Dev loss: 0.3776 r:0.8098
et_en Dev loss: 0.5010 r:0.6347
si_en Dev loss: 0.9905 r:0.5402
ne_en Dev loss: 0.6366 r:0.7122
ru_en Dev loss: 0.5202 r:0.7081
Current avg r:0.5740 Best avg r: 0.6229
07:45:56,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:13,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:48:45,284 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1572
en_de Dev loss: 0.9464 r:0.1495
en_zh Dev loss: 0.8596 r:0.4629
ro_en Dev loss: 0.3970 r:0.8079
et_en Dev loss: 0.5141 r:0.6335
si_en Dev loss: 1.0301 r:0.5369
ne_en Dev loss: 0.6422 r:0.7113
ru_en Dev loss: 0.5175 r:0.7168
Current avg r:0.5741 Best avg r: 0.6229
07:52:34,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:53:52,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:24,957 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1537
en_de Dev loss: 0.9289 r:0.1420
en_zh Dev loss: 0.7631 r:0.4681
ro_en Dev loss: 0.3422 r:0.8129
et_en Dev loss: 0.4523 r:0.6432
si_en Dev loss: 0.8760 r:0.5466
ne_en Dev loss: 0.5506 r:0.7168
ru_en Dev loss: 0.4351 r:0.7331
Current avg r:0.5804 Best avg r: 0.6229
07:59:14,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:59:40,149 root INFO 
id:en_zh cur r: 0.4863 best r: 0.4863
08:00:31,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:01,940 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1580
en_de Dev loss: 0.9289 r:0.1679
en_zh Dev loss: 0.7967 r:0.4781
ro_en Dev loss: 0.3568 r:0.8115
et_en Dev loss: 0.4696 r:0.6410
si_en Dev loss: 0.9018 r:0.5522
ne_en Dev loss: 0.5243 r:0.7137
ru_en Dev loss: 0.4578 r:0.7320
Current avg r:0.5852 Best avg r: 0.6229
08:05:51,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:07:09,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:08:39,703 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1536
en_de Dev loss: 0.9471 r:0.1619
en_zh Dev loss: 0.8582 r:0.4702
ro_en Dev loss: 0.3739 r:0.8139
et_en Dev loss: 0.5148 r:0.6320
si_en Dev loss: 1.0141 r:0.5473
ne_en Dev loss: 0.6918 r:0.7084
ru_en Dev loss: 0.5207 r:0.7166
Current avg r:0.5786 Best avg r: 0.6229
08:12:28,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:13:45,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:15:15,495 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1487
en_de Dev loss: 0.9604 r:0.1417
en_zh Dev loss: 0.8191 r:0.4708
ro_en Dev loss: 0.3841 r:0.8057
et_en Dev loss: 0.4902 r:0.6289
si_en Dev loss: 0.9143 r:0.5421
ne_en Dev loss: 0.5935 r:0.7104
ru_en Dev loss: 0.4939 r:0.7163
Current avg r:0.5737 Best avg r: 0.6229
08:19:07,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:20:24,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:21:53,873 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1563
en_de Dev loss: 0.9802 r:0.1429
en_zh Dev loss: 0.8456 r:0.4720
ro_en Dev loss: 0.3877 r:0.8104
et_en Dev loss: 0.5083 r:0.6390
si_en Dev loss: 0.9458 r:0.5492
ne_en Dev loss: 0.6377 r:0.7221
ru_en Dev loss: 0.5073 r:0.7267
Current avg r:0.5803 Best avg r: 0.6229
08:25:42,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:59,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:28:30,20 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1490
en_de Dev loss: 0.9466 r:0.1678
en_zh Dev loss: 0.7972 r:0.4802
ro_en Dev loss: 0.3574 r:0.8126
et_en Dev loss: 0.4761 r:0.6415
si_en Dev loss: 0.8605 r:0.5487
ne_en Dev loss: 0.5654 r:0.7172
ru_en Dev loss: 0.4703 r:0.7322
Current avg r:0.5858 Best avg r: 0.6229
08:32:21,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:33:38,603 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:35:08,375 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1535
en_de Dev loss: 0.9799 r:0.1373
en_zh Dev loss: 0.8701 r:0.4638
ro_en Dev loss: 0.3895 r:0.8108
et_en Dev loss: 0.4882 r:0.6445
si_en Dev loss: 0.8949 r:0.5476
ne_en Dev loss: 0.5477 r:0.7211
ru_en Dev loss: 0.5112 r:0.7190
Current avg r:0.5777 Best avg r: 0.6229
08:38:57,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:40:14,346 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:44,103 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1541
en_de Dev loss: 0.9581 r:0.1375
en_zh Dev loss: 0.8266 r:0.4683
ro_en Dev loss: 0.3913 r:0.8051
et_en Dev loss: 0.4836 r:0.6488
si_en Dev loss: 0.9490 r:0.5444
ne_en Dev loss: 0.5530 r:0.7218
ru_en Dev loss: 0.5018 r:0.7215
Current avg r:0.5782 Best avg r: 0.6229
08:45:32,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:46:49,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:48:19,718 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1414
en_de Dev loss: 0.9577 r:0.1580
en_zh Dev loss: 0.8783 r:0.4532
ro_en Dev loss: 0.3640 r:0.8087
et_en Dev loss: 0.4825 r:0.6543
si_en Dev loss: 0.9460 r:0.5436
ne_en Dev loss: 0.5901 r:0.7170
ru_en Dev loss: 0.5259 r:0.7165
Current avg r:0.5788 Best avg r: 0.6229
08:52:12,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:29,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:59,371 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1387
en_de Dev loss: 0.9953 r:0.1486
en_zh Dev loss: 0.8560 r:0.4698
ro_en Dev loss: 0.3852 r:0.8102
et_en Dev loss: 0.4780 r:0.6566
si_en Dev loss: 0.8425 r:0.5528
ne_en Dev loss: 0.5071 r:0.7166
ru_en Dev loss: 0.4969 r:0.7309
Current avg r:0.5836 Best avg r: 0.6229
08:58:48,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:00:05,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:01:34,906 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1367
en_de Dev loss: 0.9970 r:0.1452
en_zh Dev loss: 0.9002 r:0.4619
ro_en Dev loss: 0.4468 r:0.7986
et_en Dev loss: 0.5528 r:0.6339
si_en Dev loss: 1.0711 r:0.5370
ne_en Dev loss: 0.7015 r:0.7094
ru_en Dev loss: 0.5512 r:0.7137
Current avg r:0.5714 Best avg r: 0.6229
09:05:25,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:06:41,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:08:11,687 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1393
en_de Dev loss: 0.9614 r:0.1426
en_zh Dev loss: 0.8128 r:0.4729
ro_en Dev loss: 0.3897 r:0.8025
et_en Dev loss: 0.4752 r:0.6485
si_en Dev loss: 0.9179 r:0.5485
ne_en Dev loss: 0.5785 r:0.7155
ru_en Dev loss: 0.4750 r:0.7301
Current avg r:0.5801 Best avg r: 0.6229
09:12:00,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:13:17,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:14:47,228 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1327
en_de Dev loss: 0.9648 r:0.1507
en_zh Dev loss: 0.8746 r:0.4746
ro_en Dev loss: 0.4073 r:0.8056
et_en Dev loss: 0.5120 r:0.6506
si_en Dev loss: 1.0836 r:0.5458
ne_en Dev loss: 0.6410 r:0.7116
ru_en Dev loss: 0.5628 r:0.7205
Current avg r:0.5799 Best avg r: 0.6229
09:18:36,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:19:52,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:21:22,687 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1368
en_de Dev loss: 1.0036 r:0.1272
en_zh Dev loss: 0.9085 r:0.4708
ro_en Dev loss: 0.4116 r:0.8028
et_en Dev loss: 0.5142 r:0.6430
si_en Dev loss: 1.0039 r:0.5412
ne_en Dev loss: 0.7047 r:0.7060
ru_en Dev loss: 0.5352 r:0.7230
Current avg r:0.5734 Best avg r: 0.6229
09:25:11,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:26:28,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:27:59,511 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1341
en_de Dev loss: 0.9903 r:0.1300
en_zh Dev loss: 0.8770 r:0.4653
ro_en Dev loss: 0.4042 r:0.8065
et_en Dev loss: 0.5042 r:0.6562
si_en Dev loss: 1.0609 r:0.5427
ne_en Dev loss: 0.6516 r:0.7061
ru_en Dev loss: 0.5485 r:0.7239
Current avg r:0.5758 Best avg r: 0.6229
09:31:48,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:32:15,272 root INFO 
id:en_zh cur r: 0.4868 best r: 0.4868
09:33:06,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:34:36,305 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1322
en_de Dev loss: 0.9630 r:0.1526
en_zh Dev loss: 0.7982 r:0.4838
ro_en Dev loss: 0.3887 r:0.8080
et_en Dev loss: 0.4792 r:0.6636
si_en Dev loss: 1.0074 r:0.5483
ne_en Dev loss: 0.6189 r:0.7099
ru_en Dev loss: 0.5131 r:0.7288
Current avg r:0.5850 Best avg r: 0.6229
09:38:26,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:39:43,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:41:13,506 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1326
en_de Dev loss: 0.9454 r:0.1584
en_zh Dev loss: 0.8057 r:0.4721
ro_en Dev loss: 0.3715 r:0.8060
et_en Dev loss: 0.4620 r:0.6557
si_en Dev loss: 0.9662 r:0.5434
ne_en Dev loss: 0.6103 r:0.7089
ru_en Dev loss: 0.5057 r:0.7220
Current avg r:0.5809 Best avg r: 0.6229
09:45:03,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:45:29,314 root INFO 
id:en_zh cur r: 0.4882 best r: 0.4882
09:46:20,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:47:50,688 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1393
en_de Dev loss: 0.9688 r:0.1589
en_zh Dev loss: 0.8171 r:0.4815
ro_en Dev loss: 0.3804 r:0.8069
et_en Dev loss: 0.4645 r:0.6559
si_en Dev loss: 0.9298 r:0.5487
ne_en Dev loss: 0.5891 r:0.7021
ru_en Dev loss: 0.4834 r:0.7327
Current avg r:0.5838 Best avg r: 0.6229
09:51:42,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:52:58,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:54:28,598 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1330
en_de Dev loss: 0.9610 r:0.1613
en_zh Dev loss: 0.8151 r:0.4679
ro_en Dev loss: 0.3713 r:0.8046
et_en Dev loss: 0.4544 r:0.6531
si_en Dev loss: 0.9080 r:0.5493
ne_en Dev loss: 0.5677 r:0.7122
ru_en Dev loss: 0.4682 r:0.7288
Current avg r:0.5825 Best avg r: 0.6229
09:58:17,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:59:34,267 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:01:03,953 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1386
en_de Dev loss: 0.9757 r:0.1477
en_zh Dev loss: 0.8532 r:0.4708
ro_en Dev loss: 0.4029 r:0.8054
et_en Dev loss: 0.4916 r:0.6497
si_en Dev loss: 1.0245 r:0.5435
ne_en Dev loss: 0.5995 r:0.7087
ru_en Dev loss: 0.4984 r:0.7298
Current avg r:0.5794 Best avg r: 0.6229
10:04:52,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:06:09,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:39,309 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1363
en_de Dev loss: 0.9588 r:0.1624
en_zh Dev loss: 0.7802 r:0.4799
ro_en Dev loss: 0.3640 r:0.8076
et_en Dev loss: 0.4586 r:0.6508
si_en Dev loss: 0.9163 r:0.5403
ne_en Dev loss: 0.5735 r:0.7106
ru_en Dev loss: 0.4664 r:0.7348
Current avg r:0.5838 Best avg r: 0.6229
10:11:28,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:12:45,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:14,745 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1292
en_de Dev loss: 0.9454 r:0.1649
en_zh Dev loss: 0.7887 r:0.4675
ro_en Dev loss: 0.3537 r:0.8087
et_en Dev loss: 0.4411 r:0.6524
si_en Dev loss: 0.8135 r:0.5431
ne_en Dev loss: 0.5155 r:0.7032
ru_en Dev loss: 0.4579 r:0.7299
Current avg r:0.5814 Best avg r: 0.6229
10:18:03,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:21,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:51,331 root INFO Epoch 11 Global steps: 107400 Train loss: 0.1338
en_de Dev loss: 0.9678 r:0.1795
en_zh Dev loss: 0.8609 r:0.4741
ro_en Dev loss: 0.4073 r:0.8104
et_en Dev loss: 0.4845 r:0.6546
si_en Dev loss: 0.9700 r:0.5437
ne_en Dev loss: 0.5532 r:0.7089
ru_en Dev loss: 0.5175 r:0.7299
Current avg r:0.5859 Best avg r: 0.6229
10:24:40,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:57,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:27,425 root INFO Epoch 11 Global steps: 108000 Train loss: 0.1270
en_de Dev loss: 0.9658 r:0.1458
en_zh Dev loss: 0.8642 r:0.4617
ro_en Dev loss: 0.3968 r:0.8058
et_en Dev loss: 0.4775 r:0.6541
si_en Dev loss: 0.9234 r:0.5443
ne_en Dev loss: 0.6465 r:0.7096
ru_en Dev loss: 0.4993 r:0.7279
Current avg r:0.5785 Best avg r: 0.6229
