14:36:57,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:10,724 root INFO 
id:en_de cur r: 0.0101 best r: 0.0101
14:37:23,684 root INFO 
id:en_zh cur r: 0.2276 best r: 0.2276
14:37:36,682 root INFO 
id:ro_en cur r: 0.2858 best r: 0.2858
14:37:49,701 root INFO 
id:et_en cur r: 0.4348 best r: 0.4348
14:38:02,720 root INFO 
id:si_en cur r: 0.3680 best r: 0.3680
14:38:15,649 root INFO 
id:ru_en cur r: 0.3647 best r: 0.3647
14:38:15,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:46,545 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:39:46,554 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:39:46,558 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:39:46,563 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:39:46,568 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:39:46,572 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:39:46,578 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:39:59,607 root INFO Epoch 0 Global steps: 600 Train loss: 0.8902
en_de Dev loss: 0.9283 r:0.0779
en_zh Dev loss: 0.7836 r:0.2231
ro_en Dev loss: 0.7914 r:0.5654
et_en Dev loss: 0.5937 r:0.4314
si_en Dev loss: 0.7658 r:0.3712
ne_en Dev loss: 0.6660 r:0.5523
ru_en Dev loss: 0.7169 r:0.4103
Current avg r:0.3759 Best avg r: 0.3759
14:43:52,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:05,303 root INFO 
id:en_de cur r: 0.0622 best r: 0.0622
14:44:18,247 root INFO 
id:en_zh cur r: 0.2840 best r: 0.2840
14:44:31,227 root INFO 
id:ro_en cur r: 0.5450 best r: 0.5450
14:44:44,224 root INFO 
id:et_en cur r: 0.4631 best r: 0.4631
14:45:10,140 root INFO 
id:ru_en cur r: 0.5521 best r: 0.5521
14:45:10,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:40,913 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:46:40,935 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:46:40,956 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:46:40,978 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:46:40,989 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:46:41,5 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:46:41,21 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:46:54,12 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8190
en_de Dev loss: 0.9024 r:0.0934
en_zh Dev loss: 0.7574 r:0.2937
ro_en Dev loss: 0.6787 r:0.5888
et_en Dev loss: 0.5440 r:0.4974
si_en Dev loss: 0.7331 r:0.4114
ne_en Dev loss: 0.6276 r:0.5839
ru_en Dev loss: 0.6152 r:0.5813
Current avg r:0.4357 Best avg r: 0.4357
14:50:46,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:50:59,642 root INFO 
id:en_de cur r: 0.0885 best r: 0.0885
14:51:12,580 root INFO 
id:en_zh cur r: 0.3089 best r: 0.3089
14:51:25,562 root INFO 
id:ro_en cur r: 0.5485 best r: 0.5485
14:51:38,554 root INFO 
id:et_en cur r: 0.5806 best r: 0.5806
14:51:51,569 root INFO 
id:si_en cur r: 0.4230 best r: 0.4230
14:52:04,482 root INFO 
id:ru_en cur r: 0.6616 best r: 0.6616
14:52:04,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:35,248 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:53:35,257 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:53:35,262 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:53:35,267 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:53:35,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:53:35,279 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:53:35,285 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:53:48,277 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7598
en_de Dev loss: 0.9009 r:0.1314
en_zh Dev loss: 0.7293 r:0.3393
ro_en Dev loss: 0.6482 r:0.6371
et_en Dev loss: 0.4954 r:0.5907
si_en Dev loss: 0.7156 r:0.4599
ne_en Dev loss: 0.5390 r:0.6473
ru_en Dev loss: 0.5455 r:0.6888
Current avg r:0.4992 Best avg r: 0.4992
14:57:42,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:55,749 root INFO 
id:en_de cur r: 0.1352 best r: 0.1352
14:58:08,711 root INFO 
id:en_zh cur r: 0.3273 best r: 0.3273
14:58:21,697 root INFO 
id:ro_en cur r: 0.6551 best r: 0.6551
14:58:34,694 root INFO 
id:et_en cur r: 0.6102 best r: 0.6102
14:58:47,706 root INFO 
id:si_en cur r: 0.4550 best r: 0.4550
14:59:00,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:31,389 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:00:31,396 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:00:31,402 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:00:31,412 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:00:31,417 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:00:31,423 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:00:31,430 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:00:44,449 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7096
en_de Dev loss: 0.9185 r:0.1486
en_zh Dev loss: 0.7658 r:0.3534
ro_en Dev loss: 0.6155 r:0.7011
et_en Dev loss: 0.4964 r:0.6376
si_en Dev loss: 0.7854 r:0.5102
ne_en Dev loss: 0.4784 r:0.6519
ru_en Dev loss: 0.5916 r:0.6759
Current avg r:0.5255 Best avg r: 0.5255
15:04:36,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:49,804 root INFO 
id:en_de cur r: 0.1504 best r: 0.1504
15:05:02,751 root INFO 
id:en_zh cur r: 0.3612 best r: 0.3612
15:05:15,734 root INFO 
id:ro_en cur r: 0.7043 best r: 0.7043
15:05:28,730 root INFO 
id:et_en cur r: 0.6779 best r: 0.6779
15:05:41,734 root INFO 
id:si_en cur r: 0.5256 best r: 0.5256
15:05:54,641 root INFO 
id:ru_en cur r: 0.7231 best r: 0.7231
15:05:54,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:25,398 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:07:25,404 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:07:25,410 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:07:25,414 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:07:25,419 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:07:25,424 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:07:25,432 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:07:38,447 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6253
en_de Dev loss: 0.9248 r:0.1641
en_zh Dev loss: 0.7941 r:0.3686
ro_en Dev loss: 0.5298 r:0.7247
et_en Dev loss: 0.4055 r:0.6941
si_en Dev loss: 0.6811 r:0.5604
ne_en Dev loss: 0.4694 r:0.6953
ru_en Dev loss: 0.5064 r:0.7282
Current avg r:0.5622 Best avg r: 0.5622
15:11:31,810 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:44,782 root INFO 
id:en_de cur r: 0.1529 best r: 0.1529
15:12:10,709 root INFO 
id:ro_en cur r: 0.7329 best r: 0.7329
15:12:23,707 root INFO 
id:et_en cur r: 0.6809 best r: 0.6809
15:12:36,713 root INFO 
id:si_en cur r: 0.5348 best r: 0.5348
15:12:49,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:20,395 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:14:20,403 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:14:20,407 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:14:20,413 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:14:20,418 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:14:20,423 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:14:20,429 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:14:33,430 root INFO Epoch 0 Global steps: 3600 Train loss: 0.5890
en_de Dev loss: 0.9245 r:0.1758
en_zh Dev loss: 0.7934 r:0.3728
ro_en Dev loss: 0.5077 r:0.7432
et_en Dev loss: 0.4024 r:0.6984
si_en Dev loss: 0.7443 r:0.5522
ne_en Dev loss: 0.4588 r:0.6933
ru_en Dev loss: 0.5210 r:0.7122
Current avg r:0.5640 Best avg r: 0.5640
15:18:25,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:38,747 root INFO 
id:en_de cur r: 0.1708 best r: 0.1708
15:19:04,662 root INFO 
id:ro_en cur r: 0.7513 best r: 0.7513
15:19:17,648 root INFO 
id:et_en cur r: 0.6917 best r: 0.6917
15:19:30,658 root INFO 
id:si_en cur r: 0.5535 best r: 0.5535
15:19:43,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:14,371 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:21:14,378 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:21:14,383 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:21:14,388 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:21:14,393 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:21:14,400 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:21:14,407 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:21:27,414 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5942
en_de Dev loss: 0.9071 r:0.1755
en_zh Dev loss: 0.7510 r:0.3759
ro_en Dev loss: 0.4238 r:0.7596
et_en Dev loss: 0.3692 r:0.7047
si_en Dev loss: 0.6414 r:0.5664
ne_en Dev loss: 0.5339 r:0.7096
ru_en Dev loss: 0.4839 r:0.7152
Current avg r:0.5724 Best avg r: 0.5724
15:25:20,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:59,101 root INFO 
id:ro_en cur r: 0.7704 best r: 0.7704
15:26:37,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:08,724 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5685
en_de Dev loss: 0.9039 r:0.1746
en_zh Dev loss: 0.7603 r:0.3610
ro_en Dev loss: 0.3848 r:0.7785
et_en Dev loss: 0.3793 r:0.6935
si_en Dev loss: 0.6918 r:0.5620
ne_en Dev loss: 0.5260 r:0.6959
ru_en Dev loss: 0.4839 r:0.7106
Current avg r:0.5680 Best avg r: 0.5724
15:32:01,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:27,27 root INFO 
id:en_zh cur r: 0.4006 best r: 0.4006
15:32:40,40 root INFO 
id:ro_en cur r: 0.7826 best r: 0.7826
15:32:53,60 root INFO 
id:et_en cur r: 0.6959 best r: 0.6959
15:33:06,64 root INFO 
id:si_en cur r: 0.5857 best r: 0.5857
15:33:18,978 root INFO 
id:ru_en cur r: 0.7393 best r: 0.7393
15:33:18,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:49,741 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:34:49,748 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:34:49,754 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:34:49,760 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:34:49,765 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:34:49,770 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:34:49,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:35:02,768 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5790
en_de Dev loss: 0.9018 r:0.1897
en_zh Dev loss: 0.7207 r:0.4071
ro_en Dev loss: 0.3722 r:0.7890
et_en Dev loss: 0.3641 r:0.7019
si_en Dev loss: 0.6679 r:0.5824
ne_en Dev loss: 0.5545 r:0.7198
ru_en Dev loss: 0.4439 r:0.7352
Current avg r:0.5893 Best avg r: 0.5893
15:38:55,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:08,192 root INFO 
id:en_de cur r: 0.1776 best r: 0.1776
15:39:21,157 root INFO 
id:en_zh cur r: 0.4184 best r: 0.4184
15:39:34,152 root INFO 
id:ro_en cur r: 0.7920 best r: 0.7920
15:40:13,53 root INFO 
id:ru_en cur r: 0.7436 best r: 0.7436
15:40:13,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:43,835 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:41:43,842 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:41:43,847 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:41:43,852 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:41:43,857 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:41:43,861 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:41:43,868 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:41:56,867 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5871
en_de Dev loss: 0.8836 r:0.1928
en_zh Dev loss: 0.6806 r:0.4308
ro_en Dev loss: 0.3375 r:0.7934
et_en Dev loss: 0.3616 r:0.7042
si_en Dev loss: 0.6248 r:0.5886
ne_en Dev loss: 0.6596 r:0.7247
ru_en Dev loss: 0.3825 r:0.7509
Current avg r:0.5979 Best avg r: 0.5979
15:45:49,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:02,234 root INFO 
id:en_de cur r: 0.2195 best r: 0.2195
15:46:28,174 root INFO 
id:ro_en cur r: 0.7954 best r: 0.7954
15:46:54,163 root INFO 
id:si_en cur r: 0.5951 best r: 0.5951
15:47:07,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:37,846 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:48:37,855 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:48:37,862 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:48:37,867 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:48:37,872 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:48:37,877 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:48:37,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:48:50,916 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5649
en_de Dev loss: 0.9144 r:0.2146
en_zh Dev loss: 0.7302 r:0.4304
ro_en Dev loss: 0.3437 r:0.8006
et_en Dev loss: 0.3634 r:0.7064
si_en Dev loss: 0.6159 r:0.5990
ne_en Dev loss: 0.6197 r:0.7293
ru_en Dev loss: 0.4322 r:0.7431
Current avg r:0.6033 Best avg r: 0.6033
15:52:43,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:09,179 root INFO 
id:en_zh cur r: 0.4210 best r: 0.4210
15:53:22,173 root INFO 
id:ro_en cur r: 0.8065 best r: 0.8065
15:53:35,169 root INFO 
id:et_en cur r: 0.7169 best r: 0.7169
15:53:48,178 root INFO 
id:si_en cur r: 0.6018 best r: 0.6018
15:54:01,102 root INFO 
id:ru_en cur r: 0.7634 best r: 0.7634
15:54:01,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:31,884 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:55:31,894 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:55:31,901 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:55:31,905 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:55:31,911 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:55:31,917 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:55:31,923 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:55:44,937 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5474
en_de Dev loss: 0.9038 r:0.2200
en_zh Dev loss: 0.7489 r:0.4317
ro_en Dev loss: 0.3661 r:0.8044
et_en Dev loss: 0.3837 r:0.7166
si_en Dev loss: 0.7119 r:0.5982
ne_en Dev loss: 0.6204 r:0.7381
ru_en Dev loss: 0.4076 r:0.7621
Current avg r:0.6101 Best avg r: 0.6101
15:59:37,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:50,234 root INFO 
id:en_de cur r: 0.2295 best r: 0.2295
16:00:55,56 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:25,819 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5312
en_de Dev loss: 0.9250 r:0.2301
en_zh Dev loss: 0.7786 r:0.4121
ro_en Dev loss: 0.3922 r:0.7942
et_en Dev loss: 0.4042 r:0.6867
si_en Dev loss: 0.7303 r:0.5685
ne_en Dev loss: 0.6227 r:0.7107
ru_en Dev loss: 0.4775 r:0.7280
Current avg r:0.5900 Best avg r: 0.6101
16:06:18,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:44,332 root INFO 
id:en_zh cur r: 0.4376 best r: 0.4376
16:06:57,297 root INFO 
id:ro_en cur r: 0.8097 best r: 0.8097
16:07:36,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:07,87 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5334
en_de Dev loss: 0.8690 r:0.2128
en_zh Dev loss: 0.6802 r:0.4405
ro_en Dev loss: 0.3295 r:0.8094
et_en Dev loss: 0.3481 r:0.7189
si_en Dev loss: 0.6266 r:0.5963
ne_en Dev loss: 0.6269 r:0.7317
ru_en Dev loss: 0.3976 r:0.7592
Current avg r:0.6098 Best avg r: 0.6101
16:12:59,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:38,315 root INFO 
id:ro_en cur r: 0.8202 best r: 0.8202
16:13:51,306 root INFO 
id:et_en cur r: 0.7202 best r: 0.7202
16:14:04,308 root INFO 
id:si_en cur r: 0.6141 best r: 0.6141
16:14:17,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:47,959 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5666
en_de Dev loss: 0.8970 r:0.2017
en_zh Dev loss: 0.7745 r:0.4226
ro_en Dev loss: 0.3480 r:0.8175
et_en Dev loss: 0.3505 r:0.7236
si_en Dev loss: 0.7531 r:0.6061
ne_en Dev loss: 0.5759 r:0.7331
ru_en Dev loss: 0.4321 r:0.7529
Current avg r:0.6082 Best avg r: 0.6101
16:19:41,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:59,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:30,434 root INFO Epoch 1 Global steps: 9600 Train loss: 0.4884
en_de Dev loss: 0.8770 r:0.1992
en_zh Dev loss: 0.7283 r:0.4201
ro_en Dev loss: 0.3351 r:0.8044
et_en Dev loss: 0.3600 r:0.7074
si_en Dev loss: 0.7257 r:0.5848
ne_en Dev loss: 0.6653 r:0.7232
ru_en Dev loss: 0.4523 r:0.7181
Current avg r:0.5939 Best avg r: 0.6101
16:26:22,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:48,883 root INFO 
id:en_zh cur r: 0.4529 best r: 0.4529
16:27:01,866 root INFO 
id:ro_en cur r: 0.8234 best r: 0.8234
16:27:40,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:11,532 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:29:11,540 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:29:11,544 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:29:11,550 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:29:11,554 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:29:11,559 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:29:11,565 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:29:24,563 root INFO Epoch 1 Global steps: 10200 Train loss: 0.4988
en_de Dev loss: 0.8639 r:0.2117
en_zh Dev loss: 0.6856 r:0.4523
ro_en Dev loss: 0.3172 r:0.8186
et_en Dev loss: 0.3749 r:0.7227
si_en Dev loss: 0.6321 r:0.6096
ne_en Dev loss: 0.8316 r:0.7411
ru_en Dev loss: 0.3849 r:0.7575
Current avg r:0.6162 Best avg r: 0.6162
16:33:17,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:56,9 root INFO 
id:ro_en cur r: 0.8252 best r: 0.8252
16:34:34,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:05,939 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5026
en_de Dev loss: 0.8540 r:0.2209
en_zh Dev loss: 0.7251 r:0.4416
ro_en Dev loss: 0.3213 r:0.8208
et_en Dev loss: 0.3563 r:0.7164
si_en Dev loss: 0.7038 r:0.6024
ne_en Dev loss: 0.5805 r:0.7343
ru_en Dev loss: 0.4162 r:0.7531
Current avg r:0.6128 Best avg r: 0.6162
16:39:58,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:11,686 root INFO 
id:en_de cur r: 0.2312 best r: 0.2312
16:41:16,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:47,342 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4786
en_de Dev loss: 0.8786 r:0.2353
en_zh Dev loss: 0.7342 r:0.4459
ro_en Dev loss: 0.3500 r:0.8138
et_en Dev loss: 0.3717 r:0.7088
si_en Dev loss: 0.6739 r:0.5945
ne_en Dev loss: 0.6821 r:0.7322
ru_en Dev loss: 0.4320 r:0.7446
Current avg r:0.6107 Best avg r: 0.6162
16:46:41,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:54,506 root INFO 
id:en_de cur r: 0.2330 best r: 0.2330
16:47:59,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:30,131 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5036
en_de Dev loss: 0.8884 r:0.2225
en_zh Dev loss: 0.7531 r:0.4321
ro_en Dev loss: 0.3786 r:0.8095
et_en Dev loss: 0.3733 r:0.7099
si_en Dev loss: 0.6881 r:0.5927
ne_en Dev loss: 0.5208 r:0.7254
ru_en Dev loss: 0.5071 r:0.7250
Current avg r:0.6025 Best avg r: 0.6162
16:53:22,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:35,657 root INFO 
id:en_de cur r: 0.2361 best r: 0.2361
16:54:14,578 root INFO 
id:et_en cur r: 0.7224 best r: 0.7224
16:54:27,594 root INFO 
id:si_en cur r: 0.6183 best r: 0.6183
16:54:40,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:11,289 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:56:11,301 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:56:11,306 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:56:11,313 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:56:11,319 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:56:11,325 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:56:11,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:56:24,335 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4717
en_de Dev loss: 0.8501 r:0.2418
en_zh Dev loss: 0.7327 r:0.4375
ro_en Dev loss: 0.3355 r:0.8186
et_en Dev loss: 0.3504 r:0.7249
si_en Dev loss: 0.6268 r:0.6203
ne_en Dev loss: 0.6384 r:0.7440
ru_en Dev loss: 0.4026 r:0.7594
Current avg r:0.6209 Best avg r: 0.6209
17:00:16,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:55,796 root INFO 
id:ro_en cur r: 0.8273 best r: 0.8273
17:01:34,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:05,471 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4732
en_de Dev loss: 0.8422 r:0.2257
en_zh Dev loss: 0.6795 r:0.4411
ro_en Dev loss: 0.2904 r:0.8232
et_en Dev loss: 0.3487 r:0.7226
si_en Dev loss: 0.5941 r:0.6118
ne_en Dev loss: 0.7857 r:0.7410
ru_en Dev loss: 0.3753 r:0.7478
Current avg r:0.6162 Best avg r: 0.6209
17:06:57,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:15,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:46,537 root INFO Epoch 1 Global steps: 13800 Train loss: 0.5046
en_de Dev loss: 0.8725 r:0.2037
en_zh Dev loss: 0.6997 r:0.4430
ro_en Dev loss: 0.3169 r:0.8159
et_en Dev loss: 0.3508 r:0.7150
si_en Dev loss: 0.6268 r:0.5988
ne_en Dev loss: 0.6556 r:0.7366
ru_en Dev loss: 0.4382 r:0.7324
Current avg r:0.6065 Best avg r: 0.6209
17:13:39,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:52,14 root INFO 
id:en_de cur r: 0.2480 best r: 0.2480
17:14:04,974 root INFO 
id:en_zh cur r: 0.4642 best r: 0.4642
17:14:17,973 root INFO 
id:ro_en cur r: 0.8276 best r: 0.8276
17:14:56,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:27,655 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4934
en_de Dev loss: 0.8370 r:0.2423
en_zh Dev loss: 0.6631 r:0.4613
ro_en Dev loss: 0.2923 r:0.8235
et_en Dev loss: 0.3506 r:0.7215
si_en Dev loss: 0.6053 r:0.6045
ne_en Dev loss: 0.7751 r:0.7404
ru_en Dev loss: 0.3863 r:0.7523
Current avg r:0.6208 Best avg r: 0.6209
17:20:20,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:37,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:08,695 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4943
en_de Dev loss: 0.8800 r:0.2147
en_zh Dev loss: 0.7342 r:0.4469
ro_en Dev loss: 0.3549 r:0.8131
et_en Dev loss: 0.3763 r:0.7084
si_en Dev loss: 0.7126 r:0.5870
ne_en Dev loss: 0.6907 r:0.7318
ru_en Dev loss: 0.5010 r:0.7132
Current avg r:0.6021 Best avg r: 0.6209
17:27:01,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:14,93 root INFO 
id:en_de cur r: 0.2640 best r: 0.2640
17:27:53,25 root INFO 
id:et_en cur r: 0.7241 best r: 0.7241
17:28:18,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:49,763 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4493
en_de Dev loss: 0.8888 r:0.2404
en_zh Dev loss: 0.8037 r:0.4239
ro_en Dev loss: 0.3261 r:0.8246
et_en Dev loss: 0.3482 r:0.7279
si_en Dev loss: 0.6217 r:0.6047
ne_en Dev loss: 0.6740 r:0.7450
ru_en Dev loss: 0.4683 r:0.7322
Current avg r:0.6141 Best avg r: 0.6209
17:33:42,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:55,124 root INFO 
id:en_de cur r: 0.2677 best r: 0.2677
17:34:08,79 root INFO 
id:en_zh cur r: 0.4704 best r: 0.4704
17:34:59,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:30,771 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4633
en_de Dev loss: 0.8331 r:0.2480
en_zh Dev loss: 0.6716 r:0.4626
ro_en Dev loss: 0.3149 r:0.8214
et_en Dev loss: 0.3474 r:0.7234
si_en Dev loss: 0.7176 r:0.5941
ne_en Dev loss: 0.6308 r:0.7269
ru_en Dev loss: 0.4371 r:0.7345
Current avg r:0.6158 Best avg r: 0.6209
17:40:23,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:49,754 root INFO 
id:en_zh cur r: 0.4761 best r: 0.4761
17:41:41,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:12,456 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:43:12,465 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:43:12,470 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:43:12,475 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:43:12,479 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:43:12,484 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:43:12,491 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:43:25,497 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4585
en_de Dev loss: 0.8379 r:0.2526
en_zh Dev loss: 0.6667 r:0.4743
ro_en Dev loss: 0.3022 r:0.8236
et_en Dev loss: 0.3775 r:0.7227
si_en Dev loss: 0.5812 r:0.6099
ne_en Dev loss: 0.8906 r:0.7416
ru_en Dev loss: 0.3864 r:0.7551
Current avg r:0.6257 Best avg r: 0.6257
17:47:18,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:36,148 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:06,911 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4487
en_de Dev loss: 0.8707 r:0.2336
en_zh Dev loss: 0.7429 r:0.4482
ro_en Dev loss: 0.3339 r:0.8205
et_en Dev loss: 0.3611 r:0.7168
si_en Dev loss: 0.7628 r:0.5962
ne_en Dev loss: 0.5273 r:0.7257
ru_en Dev loss: 0.4957 r:0.7259
Current avg r:0.6096 Best avg r: 0.6257
17:53:59,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:38,404 root INFO 
id:ro_en cur r: 0.8309 best r: 0.8309
17:55:17,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:48,82 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4846
en_de Dev loss: 0.8551 r:0.2276
en_zh Dev loss: 0.7287 r:0.4588
ro_en Dev loss: 0.3314 r:0.8262
et_en Dev loss: 0.3560 r:0.7226
si_en Dev loss: 0.7787 r:0.6012
ne_en Dev loss: 0.4994 r:0.7293
ru_en Dev loss: 0.4661 r:0.7359
Current avg r:0.6145 Best avg r: 0.6257
18:00:42,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:59,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:30,599 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4198
en_de Dev loss: 0.8763 r:0.2501
en_zh Dev loss: 0.7092 r:0.4451
ro_en Dev loss: 0.3130 r:0.8223
et_en Dev loss: 0.3718 r:0.7055
si_en Dev loss: 0.6266 r:0.5930
ne_en Dev loss: 0.7481 r:0.7303
ru_en Dev loss: 0.4262 r:0.7330
Current avg r:0.6113 Best avg r: 0.6257
18:07:23,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:02,95 root INFO 
id:ro_en cur r: 0.8367 best r: 0.8367
18:08:28,89 root INFO 
id:si_en cur r: 0.6235 best r: 0.6235
18:08:40,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:11,758 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4605
en_de Dev loss: 0.8389 r:0.2362
en_zh Dev loss: 0.6517 r:0.4718
ro_en Dev loss: 0.2796 r:0.8334
et_en Dev loss: 0.3616 r:0.7127
si_en Dev loss: 0.5846 r:0.6247
ne_en Dev loss: 0.6601 r:0.7381
ru_en Dev loss: 0.3885 r:0.7466
Current avg r:0.6234 Best avg r: 0.6257
18:14:04,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:15:22,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:52,780 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4129
en_de Dev loss: 0.8507 r:0.2200
en_zh Dev loss: 0.6767 r:0.4663
ro_en Dev loss: 0.2922 r:0.8300
et_en Dev loss: 0.3946 r:0.7144
si_en Dev loss: 0.5635 r:0.6158
ne_en Dev loss: 0.9086 r:0.7403
ru_en Dev loss: 0.3812 r:0.7515
Current avg r:0.6197 Best avg r: 0.6257
18:20:45,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:03,6 root INFO 
id:ru_en cur r: 0.7671 best r: 0.7671
18:22:03,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:33,813 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4289
en_de Dev loss: 0.8646 r:0.2150
en_zh Dev loss: 0.6986 r:0.4656
ro_en Dev loss: 0.3153 r:0.8303
et_en Dev loss: 0.3710 r:0.7135
si_en Dev loss: 0.6094 r:0.6172
ne_en Dev loss: 0.6746 r:0.7449
ru_en Dev loss: 0.4000 r:0.7637
Current avg r:0.6215 Best avg r: 0.6257
18:27:26,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:39,329 root INFO 
id:en_de cur r: 0.2708 best r: 0.2708
18:28:44,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:15,197 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4065
en_de Dev loss: 0.8472 r:0.2403
en_zh Dev loss: 0.6868 r:0.4716
ro_en Dev loss: 0.3034 r:0.8260
et_en Dev loss: 0.3880 r:0.7128
si_en Dev loss: 0.6400 r:0.6005
ne_en Dev loss: 0.8016 r:0.7286
ru_en Dev loss: 0.4387 r:0.7323
Current avg r:0.6160 Best avg r: 0.6257
18:34:08,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:21,888 root INFO 
id:en_de cur r: 0.2729 best r: 0.2729
18:35:26,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:57,698 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4054
en_de Dev loss: 0.8631 r:0.2336
en_zh Dev loss: 0.7502 r:0.4510
ro_en Dev loss: 0.3187 r:0.8244
et_en Dev loss: 0.3676 r:0.7098
si_en Dev loss: 0.6802 r:0.5897
ne_en Dev loss: 0.6470 r:0.7221
ru_en Dev loss: 0.4736 r:0.7220
Current avg r:0.6075 Best avg r: 0.6257
18:40:50,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:08,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:38,849 root INFO Epoch 2 Global steps: 22200 Train loss: 0.3903
en_de Dev loss: 0.8449 r:0.2315
en_zh Dev loss: 0.6937 r:0.4680
ro_en Dev loss: 0.3072 r:0.8278
et_en Dev loss: 0.3716 r:0.7142
si_en Dev loss: 0.6392 r:0.6027
ne_en Dev loss: 0.7562 r:0.7339
ru_en Dev loss: 0.4106 r:0.7435
Current avg r:0.6174 Best avg r: 0.6257
18:47:31,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:49,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:19,999 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4146
en_de Dev loss: 0.8537 r:0.2172
en_zh Dev loss: 0.7667 r:0.4394
ro_en Dev loss: 0.3279 r:0.8198
et_en Dev loss: 0.3686 r:0.7111
si_en Dev loss: 0.7606 r:0.5898
ne_en Dev loss: 0.6211 r:0.7214
ru_en Dev loss: 0.5187 r:0.7080
Current avg r:0.6009 Best avg r: 0.6257
18:54:12,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:30,422 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:01,249 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4478
en_de Dev loss: 0.8550 r:0.2150
en_zh Dev loss: 0.7166 r:0.4613
ro_en Dev loss: 0.3373 r:0.8215
et_en Dev loss: 0.3712 r:0.7127
si_en Dev loss: 0.7107 r:0.5937
ne_en Dev loss: 0.6607 r:0.7280
ru_en Dev loss: 0.4409 r:0.7363
Current avg r:0.6098 Best avg r: 0.6257
19:00:53,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:11,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:42,451 root INFO Epoch 2 Global steps: 24000 Train loss: 0.3851
en_de Dev loss: 0.8660 r:0.2387
en_zh Dev loss: 0.7249 r:0.4543
ro_en Dev loss: 0.3175 r:0.8199
et_en Dev loss: 0.3735 r:0.7020
si_en Dev loss: 0.6615 r:0.5889
ne_en Dev loss: 0.6815 r:0.7296
ru_en Dev loss: 0.4369 r:0.7319
Current avg r:0.6093 Best avg r: 0.6257
19:07:34,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:52,752 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:23,553 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4253
en_de Dev loss: 0.8656 r:0.2080
en_zh Dev loss: 0.7217 r:0.4631
ro_en Dev loss: 0.3372 r:0.8207
et_en Dev loss: 0.3835 r:0.7059
si_en Dev loss: 0.7332 r:0.5878
ne_en Dev loss: 0.6923 r:0.7311
ru_en Dev loss: 0.4222 r:0.7423
Current avg r:0.6084 Best avg r: 0.6257
19:14:16,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:33,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:04,608 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3977
en_de Dev loss: 0.8801 r:0.1980
en_zh Dev loss: 0.7291 r:0.4476
ro_en Dev loss: 0.3109 r:0.8217
et_en Dev loss: 0.3913 r:0.7027
si_en Dev loss: 0.6521 r:0.5956
ne_en Dev loss: 0.7502 r:0.7331
ru_en Dev loss: 0.4493 r:0.7195
Current avg r:0.6026 Best avg r: 0.6257
19:20:57,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:14,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:45,734 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4066
en_de Dev loss: 0.8525 r:0.1987
en_zh Dev loss: 0.6915 r:0.4627
ro_en Dev loss: 0.2993 r:0.8272
et_en Dev loss: 0.3639 r:0.7119
si_en Dev loss: 0.6477 r:0.6114
ne_en Dev loss: 0.6557 r:0.7353
ru_en Dev loss: 0.4110 r:0.7404
Current avg r:0.6125 Best avg r: 0.6257
19:27:38,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:04,191 root INFO 
id:en_zh cur r: 0.4779 best r: 0.4779
19:28:56,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:26,867 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4150
en_de Dev loss: 0.8452 r:0.2270
en_zh Dev loss: 0.7264 r:0.4748
ro_en Dev loss: 0.3238 r:0.8294
et_en Dev loss: 0.3637 r:0.7157
si_en Dev loss: 0.6972 r:0.6123
ne_en Dev loss: 0.5878 r:0.7298
ru_en Dev loss: 0.4133 r:0.7538
Current avg r:0.6204 Best avg r: 0.6257
19:34:19,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:37,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:08,74 root INFO Epoch 2 Global steps: 27000 Train loss: 0.3902
en_de Dev loss: 0.8394 r:0.2468
en_zh Dev loss: 0.7124 r:0.4671
ro_en Dev loss: 0.3149 r:0.8258
et_en Dev loss: 0.4168 r:0.7078
si_en Dev loss: 0.6355 r:0.6056
ne_en Dev loss: 0.8506 r:0.7307
ru_en Dev loss: 0.4333 r:0.7340
Current avg r:0.6168 Best avg r: 0.6257
19:41:02,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:19,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:50,821 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3599
en_de Dev loss: 0.8420 r:0.2471
en_zh Dev loss: 0.7246 r:0.4652
ro_en Dev loss: 0.3209 r:0.8252
et_en Dev loss: 0.4110 r:0.7049
si_en Dev loss: 0.6655 r:0.6075
ne_en Dev loss: 0.8537 r:0.7348
ru_en Dev loss: 0.4100 r:0.7481
Current avg r:0.6190 Best avg r: 0.6257
19:47:43,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:56,355 root INFO 
id:en_de cur r: 0.2736 best r: 0.2736
19:49:01,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:32,86 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3567
en_de Dev loss: 0.8472 r:0.2560
en_zh Dev loss: 0.7223 r:0.4546
ro_en Dev loss: 0.3095 r:0.8245
et_en Dev loss: 0.3852 r:0.7084
si_en Dev loss: 0.6160 r:0.6089
ne_en Dev loss: 0.7585 r:0.7362
ru_en Dev loss: 0.4086 r:0.7448
Current avg r:0.6191 Best avg r: 0.6257
19:54:24,655 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:42,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:13,322 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3668
en_de Dev loss: 0.8379 r:0.2610
en_zh Dev loss: 0.7853 r:0.4613
ro_en Dev loss: 0.3869 r:0.8197
et_en Dev loss: 0.4295 r:0.6950
si_en Dev loss: 0.8198 r:0.5923
ne_en Dev loss: 0.6552 r:0.7162
ru_en Dev loss: 0.4613 r:0.7350
Current avg r:0.6115 Best avg r: 0.6257
20:01:05,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:23,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:54,486 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3648
en_de Dev loss: 0.8446 r:0.2346
en_zh Dev loss: 0.7336 r:0.4380
ro_en Dev loss: 0.3055 r:0.8224
et_en Dev loss: 0.3910 r:0.6979
si_en Dev loss: 0.6542 r:0.5918
ne_en Dev loss: 0.7606 r:0.7135
ru_en Dev loss: 0.4518 r:0.7116
Current avg r:0.6014 Best avg r: 0.6257
20:07:47,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:05,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:36,112 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3571
en_de Dev loss: 0.8342 r:0.2467
en_zh Dev loss: 0.7375 r:0.4371
ro_en Dev loss: 0.3258 r:0.8201
et_en Dev loss: 0.3988 r:0.6932
si_en Dev loss: 0.7171 r:0.5838
ne_en Dev loss: 0.7319 r:0.7114
ru_en Dev loss: 0.4591 r:0.7177
Current avg r:0.6014 Best avg r: 0.6257
20:14:28,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:46,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:17,598 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3477
en_de Dev loss: 0.8588 r:0.2527
en_zh Dev loss: 0.7748 r:0.4442
ro_en Dev loss: 0.3734 r:0.8170
et_en Dev loss: 0.4183 r:0.6910
si_en Dev loss: 0.7400 r:0.5918
ne_en Dev loss: 0.6383 r:0.7153
ru_en Dev loss: 0.4900 r:0.7219
Current avg r:0.6048 Best avg r: 0.6257
20:21:10,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:23,84 root INFO 
id:en_de cur r: 0.2737 best r: 0.2737
20:22:28,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:58,954 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3582
en_de Dev loss: 0.8442 r:0.2477
en_zh Dev loss: 0.7634 r:0.4261
ro_en Dev loss: 0.3299 r:0.8212
et_en Dev loss: 0.4122 r:0.6939
si_en Dev loss: 0.6698 r:0.5968
ne_en Dev loss: 0.8238 r:0.7184
ru_en Dev loss: 0.4419 r:0.7219
Current avg r:0.6037 Best avg r: 0.6257
20:27:51,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:09,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:40,571 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3418
en_de Dev loss: 0.8534 r:0.2351
en_zh Dev loss: 0.7525 r:0.4397
ro_en Dev loss: 0.3336 r:0.8201
et_en Dev loss: 0.4354 r:0.6853
si_en Dev loss: 0.7042 r:0.5899
ne_en Dev loss: 0.8596 r:0.7186
ru_en Dev loss: 0.4123 r:0.7431
Current avg r:0.6045 Best avg r: 0.6257
20:34:33,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:50,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:21,648 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3468
en_de Dev loss: 0.8738 r:0.2100
en_zh Dev loss: 0.7857 r:0.4260
ro_en Dev loss: 0.3263 r:0.8235
et_en Dev loss: 0.3958 r:0.6900
si_en Dev loss: 0.7577 r:0.5868
ne_en Dev loss: 0.5973 r:0.7095
ru_en Dev loss: 0.4718 r:0.7234
Current avg r:0.5956 Best avg r: 0.6257
20:41:14,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:32,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:02,873 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3556
en_de Dev loss: 0.8568 r:0.2292
en_zh Dev loss: 0.7768 r:0.4437
ro_en Dev loss: 0.3589 r:0.8213
et_en Dev loss: 0.4305 r:0.6849
si_en Dev loss: 0.7676 r:0.5925
ne_en Dev loss: 0.6571 r:0.7117
ru_en Dev loss: 0.4882 r:0.7249
Current avg r:0.6012 Best avg r: 0.6257
20:47:55,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:13,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:44,75 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3569
en_de Dev loss: 0.8580 r:0.2241
en_zh Dev loss: 0.7650 r:0.4504
ro_en Dev loss: 0.3369 r:0.8251
et_en Dev loss: 0.4554 r:0.6940
si_en Dev loss: 0.7240 r:0.5935
ne_en Dev loss: 0.8808 r:0.7128
ru_en Dev loss: 0.4520 r:0.7349
Current avg r:0.6050 Best avg r: 0.6257
20:54:36,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:54,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:57:25,367 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3420
en_de Dev loss: 0.8748 r:0.2068
en_zh Dev loss: 0.7587 r:0.4452
ro_en Dev loss: 0.3447 r:0.8228
et_en Dev loss: 0.4408 r:0.6855
si_en Dev loss: 0.7405 r:0.5804
ne_en Dev loss: 0.8182 r:0.7071
ru_en Dev loss: 0.4763 r:0.7122
Current avg r:0.5943 Best avg r: 0.6257
21:01:18,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:35,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:06,695 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3293
en_de Dev loss: 0.8876 r:0.2166
en_zh Dev loss: 0.7696 r:0.4531
ro_en Dev loss: 0.3620 r:0.8221
et_en Dev loss: 0.4480 r:0.6885
si_en Dev loss: 0.7363 r:0.5889
ne_en Dev loss: 0.6760 r:0.7141
ru_en Dev loss: 0.4773 r:0.7290
Current avg r:0.6018 Best avg r: 0.6257
21:07:59,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:17,250 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:48,38 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3540
en_de Dev loss: 0.8456 r:0.2306
en_zh Dev loss: 0.7242 r:0.4513
ro_en Dev loss: 0.3075 r:0.8255
et_en Dev loss: 0.3963 r:0.6927
si_en Dev loss: 0.7214 r:0.5930
ne_en Dev loss: 0.6413 r:0.7094
ru_en Dev loss: 0.4464 r:0.7243
Current avg r:0.6038 Best avg r: 0.6257
21:14:40,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:58,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:29,367 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3422
en_de Dev loss: 0.8722 r:0.2444
en_zh Dev loss: 0.7850 r:0.4466
ro_en Dev loss: 0.3594 r:0.8252
et_en Dev loss: 0.4521 r:0.6922
si_en Dev loss: 0.7083 r:0.5961
ne_en Dev loss: 0.8540 r:0.7098
ru_en Dev loss: 0.4990 r:0.7190
Current avg r:0.6048 Best avg r: 0.6257
21:21:24,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:42,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:12,864 root INFO Epoch 4 Global steps: 36600 Train loss: 0.2939
en_de Dev loss: 0.8406 r:0.2433
en_zh Dev loss: 0.7545 r:0.4537
ro_en Dev loss: 0.3293 r:0.8219
et_en Dev loss: 0.4296 r:0.6920
si_en Dev loss: 0.7376 r:0.5880
ne_en Dev loss: 0.8693 r:0.7094
ru_en Dev loss: 0.4429 r:0.7263
Current avg r:0.6049 Best avg r: 0.6257
21:28:05,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:18,394 root INFO 
id:en_de cur r: 0.2814 best r: 0.2814
21:29:23,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:30:54,65 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3066
en_de Dev loss: 0.8470 r:0.2653
en_zh Dev loss: 0.7684 r:0.4480
ro_en Dev loss: 0.3298 r:0.8258
et_en Dev loss: 0.4536 r:0.6882
si_en Dev loss: 0.7207 r:0.5885
ne_en Dev loss: 0.8829 r:0.7083
ru_en Dev loss: 0.4602 r:0.7225
Current avg r:0.6067 Best avg r: 0.6257
21:34:46,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:04,342 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:35,164 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3038
en_de Dev loss: 0.8487 r:0.2562
en_zh Dev loss: 0.7881 r:0.4436
ro_en Dev loss: 0.3639 r:0.8168
et_en Dev loss: 0.4547 r:0.6733
si_en Dev loss: 0.8017 r:0.5781
ne_en Dev loss: 0.8315 r:0.6983
ru_en Dev loss: 0.4791 r:0.7127
Current avg r:0.5970 Best avg r: 0.6257
21:41:28,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:46,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:17,5 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3043
en_de Dev loss: 0.8432 r:0.2441
en_zh Dev loss: 0.7480 r:0.4365
ro_en Dev loss: 0.3100 r:0.8242
et_en Dev loss: 0.4210 r:0.6927
si_en Dev loss: 0.6933 r:0.5925
ne_en Dev loss: 0.7730 r:0.7020
ru_en Dev loss: 0.4315 r:0.7319
Current avg r:0.6034 Best avg r: 0.6257
21:48:09,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:27,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:50:58,602 root INFO Epoch 4 Global steps: 39000 Train loss: 0.2921
en_de Dev loss: 0.8478 r:0.2453
en_zh Dev loss: 0.7368 r:0.4519
ro_en Dev loss: 0.3277 r:0.8149
et_en Dev loss: 0.4391 r:0.6716
si_en Dev loss: 0.7420 r:0.5809
ne_en Dev loss: 0.7973 r:0.6985
ru_en Dev loss: 0.4555 r:0.7155
Current avg r:0.5969 Best avg r: 0.6257
21:54:51,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:56:08,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:57:39,767 root INFO Epoch 4 Global steps: 39600 Train loss: 0.2988
en_de Dev loss: 0.8562 r:0.2621
en_zh Dev loss: 0.7620 r:0.4382
ro_en Dev loss: 0.3270 r:0.8219
et_en Dev loss: 0.4436 r:0.6736
si_en Dev loss: 0.7225 r:0.5837
ne_en Dev loss: 0.7905 r:0.7060
ru_en Dev loss: 0.4745 r:0.7201
Current avg r:0.6008 Best avg r: 0.6257
22:01:33,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:01:46,443 root INFO 
id:en_de cur r: 0.2920 best r: 0.2920
22:02:51,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:22,121 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3084
en_de Dev loss: 0.8506 r:0.2680
en_zh Dev loss: 0.7568 r:0.4371
ro_en Dev loss: 0.3269 r:0.8190
et_en Dev loss: 0.4327 r:0.6754
si_en Dev loss: 0.7541 r:0.5709
ne_en Dev loss: 0.8073 r:0.7066
ru_en Dev loss: 0.4669 r:0.7157
Current avg r:0.5990 Best avg r: 0.6257
22:08:14,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:27,607 root INFO 
id:en_de cur r: 0.2937 best r: 0.2937
22:09:32,466 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:03,266 root INFO Epoch 4 Global steps: 40800 Train loss: 0.2816
en_de Dev loss: 0.8509 r:0.2747
en_zh Dev loss: 0.7972 r:0.4295
ro_en Dev loss: 0.3491 r:0.8207
et_en Dev loss: 0.4437 r:0.6748
si_en Dev loss: 0.7943 r:0.5691
ne_en Dev loss: 0.6927 r:0.7077
ru_en Dev loss: 0.4647 r:0.7326
Current avg r:0.6013 Best avg r: 0.6257
22:14:55,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:16:13,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:44,396 root INFO Epoch 4 Global steps: 41400 Train loss: 0.2946
en_de Dev loss: 0.8529 r:0.2532
en_zh Dev loss: 0.7820 r:0.4395
ro_en Dev loss: 0.3570 r:0.8196
et_en Dev loss: 0.4455 r:0.6777
si_en Dev loss: 0.8609 r:0.5726
ne_en Dev loss: 0.7431 r:0.7046
ru_en Dev loss: 0.4699 r:0.7268
Current avg r:0.5991 Best avg r: 0.6257
22:21:37,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:55,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:26,413 root INFO Epoch 4 Global steps: 42000 Train loss: 0.2937
en_de Dev loss: 0.8452 r:0.2393
en_zh Dev loss: 0.7755 r:0.4264
ro_en Dev loss: 0.3350 r:0.8207
et_en Dev loss: 0.4442 r:0.6826
si_en Dev loss: 0.7987 r:0.5746
ne_en Dev loss: 0.7867 r:0.7057
ru_en Dev loss: 0.4385 r:0.7245
Current avg r:0.5963 Best avg r: 0.6257
22:28:18,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:36,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:07,766 root INFO Epoch 4 Global steps: 42600 Train loss: 0.2822
en_de Dev loss: 0.8407 r:0.2449
en_zh Dev loss: 0.7479 r:0.4415
ro_en Dev loss: 0.3249 r:0.8241
et_en Dev loss: 0.4068 r:0.6855
si_en Dev loss: 0.8486 r:0.5707
ne_en Dev loss: 0.5994 r:0.6983
ru_en Dev loss: 0.4271 r:0.7362
Current avg r:0.6002 Best avg r: 0.6257
22:35:01,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:19,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:49,888 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3170
en_de Dev loss: 0.8511 r:0.2389
en_zh Dev loss: 0.7566 r:0.4392
ro_en Dev loss: 0.3099 r:0.8275
et_en Dev loss: 0.4590 r:0.6881
si_en Dev loss: 0.6436 r:0.5892
ne_en Dev loss: 0.9009 r:0.7110
ru_en Dev loss: 0.4084 r:0.7425
Current avg r:0.6052 Best avg r: 0.6257
22:41:42,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:00,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:31,149 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3099
en_de Dev loss: 0.8773 r:0.2290
en_zh Dev loss: 0.8486 r:0.4141
ro_en Dev loss: 0.3912 r:0.8133
et_en Dev loss: 0.4743 r:0.6682
si_en Dev loss: 0.8465 r:0.5664
ne_en Dev loss: 0.7789 r:0.6934
ru_en Dev loss: 0.5320 r:0.7029
Current avg r:0.5839 Best avg r: 0.6257
22:48:23,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:49:41,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:12,230 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2928
en_de Dev loss: 0.8792 r:0.2379
en_zh Dev loss: 0.8022 r:0.4424
ro_en Dev loss: 0.3628 r:0.8247
et_en Dev loss: 0.4598 r:0.6796
si_en Dev loss: 0.7841 r:0.5786
ne_en Dev loss: 0.7827 r:0.7085
ru_en Dev loss: 0.4559 r:0.7398
Current avg r:0.6016 Best avg r: 0.6257
22:55:04,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:22,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:53,403 root INFO Epoch 4 Global steps: 45000 Train loss: 0.2769
en_de Dev loss: 0.8722 r:0.2273
en_zh Dev loss: 0.8166 r:0.4270
ro_en Dev loss: 0.3486 r:0.8227
et_en Dev loss: 0.4307 r:0.6783
si_en Dev loss: 0.7839 r:0.5724
ne_en Dev loss: 0.6697 r:0.6988
ru_en Dev loss: 0.4646 r:0.7248
Current avg r:0.5930 Best avg r: 0.6257
23:01:47,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:05,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:36,82 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2798
en_de Dev loss: 0.8622 r:0.2102
en_zh Dev loss: 0.7923 r:0.4211
ro_en Dev loss: 0.3518 r:0.8166
et_en Dev loss: 0.4865 r:0.6636
si_en Dev loss: 0.7533 r:0.5610
ne_en Dev loss: 0.9717 r:0.6881
ru_en Dev loss: 0.4706 r:0.7054
Current avg r:0.5809 Best avg r: 0.6257
23:08:28,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:09:46,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:17,111 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2567
en_de Dev loss: 0.8496 r:0.2297
en_zh Dev loss: 0.7442 r:0.4490
ro_en Dev loss: 0.3263 r:0.8196
et_en Dev loss: 0.4247 r:0.6769
si_en Dev loss: 0.7652 r:0.5718
ne_en Dev loss: 0.7069 r:0.6946
ru_en Dev loss: 0.4269 r:0.7325
Current avg r:0.5963 Best avg r: 0.6257
23:15:09,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:27,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:17:58,32 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2578
en_de Dev loss: 0.8474 r:0.2426
en_zh Dev loss: 0.7440 r:0.4581
ro_en Dev loss: 0.3337 r:0.8213
et_en Dev loss: 0.4449 r:0.6759
si_en Dev loss: 0.7739 r:0.5712
ne_en Dev loss: 0.7819 r:0.6987
ru_en Dev loss: 0.4442 r:0.7263
Current avg r:0.5991 Best avg r: 0.6257
23:21:50,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:23:08,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:24:38,934 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2638
en_de Dev loss: 0.8829 r:0.2477
en_zh Dev loss: 0.8308 r:0.4309
ro_en Dev loss: 0.3842 r:0.8149
et_en Dev loss: 0.4833 r:0.6602
si_en Dev loss: 0.8223 r:0.5656
ne_en Dev loss: 0.8185 r:0.6893
ru_en Dev loss: 0.5257 r:0.7052
Current avg r:0.5877 Best avg r: 0.6257
23:28:31,403 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:49,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:19,859 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2512
en_de Dev loss: 0.8762 r:0.2431
en_zh Dev loss: 0.8083 r:0.4498
ro_en Dev loss: 0.3538 r:0.8229
et_en Dev loss: 0.5005 r:0.6759
si_en Dev loss: 0.7740 r:0.5720
ne_en Dev loss: 0.9757 r:0.6987
ru_en Dev loss: 0.4763 r:0.7279
Current avg r:0.5986 Best avg r: 0.6257
23:35:12,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:29,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:00,727 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2419
en_de Dev loss: 0.8547 r:0.2311
en_zh Dev loss: 0.7860 r:0.4337
ro_en Dev loss: 0.3402 r:0.8204
et_en Dev loss: 0.4511 r:0.6725
si_en Dev loss: 0.8040 r:0.5626
ne_en Dev loss: 0.7938 r:0.6929
ru_en Dev loss: 0.4453 r:0.7318
Current avg r:0.5921 Best avg r: 0.6257
23:41:53,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:11,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:41,846 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2433
en_de Dev loss: 0.8679 r:0.2448
en_zh Dev loss: 0.8103 r:0.4390
ro_en Dev loss: 0.3582 r:0.8216
et_en Dev loss: 0.4683 r:0.6811
si_en Dev loss: 0.8151 r:0.5736
ne_en Dev loss: 0.8563 r:0.7014
ru_en Dev loss: 0.4723 r:0.7284
Current avg r:0.5986 Best avg r: 0.6257
23:48:34,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:52,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:51:22,834 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2666
en_de Dev loss: 0.8837 r:0.2194
en_zh Dev loss: 0.7985 r:0.4338
ro_en Dev loss: 0.3531 r:0.8181
et_en Dev loss: 0.4495 r:0.6724
si_en Dev loss: 0.8452 r:0.5602
ne_en Dev loss: 0.7187 r:0.6951
ru_en Dev loss: 0.4678 r:0.7202
Current avg r:0.5885 Best avg r: 0.6257
23:55:15,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:33,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:03,822 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2646
en_de Dev loss: 0.8474 r:0.2375
en_zh Dev loss: 0.7729 r:0.4401
ro_en Dev loss: 0.3340 r:0.8186
et_en Dev loss: 0.4794 r:0.6762
si_en Dev loss: 0.7467 r:0.5681
ne_en Dev loss: 0.9011 r:0.7021
ru_en Dev loss: 0.4275 r:0.7281
Current avg r:0.5958 Best avg r: 0.6257
00:01:56,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:14,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:44,798 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2474
en_de Dev loss: 0.8635 r:0.2101
en_zh Dev loss: 0.7587 r:0.4497
ro_en Dev loss: 0.3335 r:0.8161
et_en Dev loss: 0.4363 r:0.6694
si_en Dev loss: 0.7973 r:0.5670
ne_en Dev loss: 0.7435 r:0.6998
ru_en Dev loss: 0.4540 r:0.7200
Current avg r:0.5903 Best avg r: 0.6257
00:08:37,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:54,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:25,815 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2610
en_de Dev loss: 0.8581 r:0.2157
en_zh Dev loss: 0.7611 r:0.4530
ro_en Dev loss: 0.3301 r:0.8181
et_en Dev loss: 0.4846 r:0.6795
si_en Dev loss: 0.7027 r:0.5833
ne_en Dev loss: 0.9223 r:0.7101
ru_en Dev loss: 0.4115 r:0.7401
Current avg r:0.6000 Best avg r: 0.6257
00:15:18,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:16:36,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:18:07,427 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2607
en_de Dev loss: 0.8742 r:0.2162
en_zh Dev loss: 0.7859 r:0.4457
ro_en Dev loss: 0.3572 r:0.8189
et_en Dev loss: 0.4378 r:0.6831
si_en Dev loss: 0.8470 r:0.5641
ne_en Dev loss: 0.7016 r:0.6997
ru_en Dev loss: 0.4643 r:0.7293
Current avg r:0.5939 Best avg r: 0.6257
00:21:59,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:17,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:24:48,431 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2535
en_de Dev loss: 0.8763 r:0.2129
en_zh Dev loss: 0.8013 r:0.4377
ro_en Dev loss: 0.3635 r:0.8174
et_en Dev loss: 0.4472 r:0.6776
si_en Dev loss: 0.8289 r:0.5697
ne_en Dev loss: 0.7473 r:0.7063
ru_en Dev loss: 0.5125 r:0.7188
Current avg r:0.5915 Best avg r: 0.6257
00:28:40,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:58,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:29,392 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2540
en_de Dev loss: 0.9089 r:0.2210
en_zh Dev loss: 0.8460 r:0.4117
ro_en Dev loss: 0.3976 r:0.8130
et_en Dev loss: 0.4786 r:0.6655
si_en Dev loss: 0.8374 r:0.5640
ne_en Dev loss: 0.8157 r:0.6964
ru_en Dev loss: 0.5254 r:0.7071
Current avg r:0.5827 Best avg r: 0.6257
00:35:21,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:39,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:10,312 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2360
en_de Dev loss: 0.8604 r:0.2246
en_zh Dev loss: 0.8129 r:0.4306
ro_en Dev loss: 0.3617 r:0.8152
et_en Dev loss: 0.4707 r:0.6652
si_en Dev loss: 0.7957 r:0.5650
ne_en Dev loss: 0.9069 r:0.6966
ru_en Dev loss: 0.4829 r:0.7105
Current avg r:0.5868 Best avg r: 0.6257
00:42:04,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:22,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:53,82 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2261
en_de Dev loss: 0.8588 r:0.2453
en_zh Dev loss: 0.8107 r:0.4495
ro_en Dev loss: 0.3766 r:0.8191
et_en Dev loss: 0.4794 r:0.6710
si_en Dev loss: 0.7965 r:0.5774
ne_en Dev loss: 0.8231 r:0.7051
ru_en Dev loss: 0.4637 r:0.7310
Current avg r:0.5998 Best avg r: 0.6257
00:48:45,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:03,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:51:33,982 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2381
en_de Dev loss: 0.8949 r:0.1919
en_zh Dev loss: 0.8043 r:0.4418
ro_en Dev loss: 0.3479 r:0.8159
et_en Dev loss: 0.4587 r:0.6599
si_en Dev loss: 0.8797 r:0.5588
ne_en Dev loss: 0.7029 r:0.6893
ru_en Dev loss: 0.5042 r:0.7075
Current avg r:0.5807 Best avg r: 0.6257
00:55:26,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:44,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:14,857 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2244
en_de Dev loss: 0.8837 r:0.1932
en_zh Dev loss: 0.8411 r:0.4104
ro_en Dev loss: 0.3664 r:0.8112
et_en Dev loss: 0.4777 r:0.6530
si_en Dev loss: 0.8545 r:0.5602
ne_en Dev loss: 0.7239 r:0.6958
ru_en Dev loss: 0.5103 r:0.7024
Current avg r:0.5752 Best avg r: 0.6257
01:02:07,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:24,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:55,752 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2362
en_de Dev loss: 0.8653 r:0.2193
en_zh Dev loss: 0.7752 r:0.4370
ro_en Dev loss: 0.3509 r:0.8150
et_en Dev loss: 0.4559 r:0.6704
si_en Dev loss: 0.8129 r:0.5638
ne_en Dev loss: 0.7406 r:0.6979
ru_en Dev loss: 0.4292 r:0.7423
Current avg r:0.5922 Best avg r: 0.6257
01:08:48,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:05,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:36,691 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2174
en_de Dev loss: 0.8667 r:0.2234
en_zh Dev loss: 0.8032 r:0.4290
ro_en Dev loss: 0.3664 r:0.8099
et_en Dev loss: 0.4940 r:0.6624
si_en Dev loss: 0.7983 r:0.5634
ne_en Dev loss: 0.8876 r:0.6967
ru_en Dev loss: 0.4629 r:0.7277
Current avg r:0.5875 Best avg r: 0.6257
01:15:29,35 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:46,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:17,457 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2252
en_de Dev loss: 0.8613 r:0.2086
en_zh Dev loss: 0.7681 r:0.4436
ro_en Dev loss: 0.3333 r:0.8179
et_en Dev loss: 0.4757 r:0.6720
si_en Dev loss: 0.7329 r:0.5712
ne_en Dev loss: 0.8425 r:0.7046
ru_en Dev loss: 0.4126 r:0.7420
Current avg r:0.5943 Best avg r: 0.6257
01:22:09,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:27,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:58,362 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2290
en_de Dev loss: 0.8613 r:0.2298
en_zh Dev loss: 0.7910 r:0.4406
ro_en Dev loss: 0.3276 r:0.8183
et_en Dev loss: 0.4527 r:0.6710
si_en Dev loss: 0.8068 r:0.5604
ne_en Dev loss: 0.7375 r:0.6986
ru_en Dev loss: 0.4333 r:0.7372
Current avg r:0.5937 Best avg r: 0.6257
01:28:50,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:08,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:31:39,291 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2282
en_de Dev loss: 0.8557 r:0.2196
en_zh Dev loss: 0.7691 r:0.4335
ro_en Dev loss: 0.3247 r:0.8156
et_en Dev loss: 0.4592 r:0.6715
si_en Dev loss: 0.7325 r:0.5653
ne_en Dev loss: 0.8377 r:0.6933
ru_en Dev loss: 0.4486 r:0.7237
Current avg r:0.5889 Best avg r: 0.6257
01:35:31,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:36:49,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:20,176 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2172
en_de Dev loss: 0.8658 r:0.2249
en_zh Dev loss: 0.7751 r:0.4501
ro_en Dev loss: 0.3515 r:0.8145
et_en Dev loss: 0.5225 r:0.6676
si_en Dev loss: 0.7817 r:0.5629
ne_en Dev loss: 0.9868 r:0.7017
ru_en Dev loss: 0.4508 r:0.7267
Current avg r:0.5926 Best avg r: 0.6257
01:42:12,522 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:30,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:01,133 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2286
en_de Dev loss: 0.8841 r:0.2244
en_zh Dev loss: 0.7907 r:0.4438
ro_en Dev loss: 0.3420 r:0.8149
et_en Dev loss: 0.4606 r:0.6621
si_en Dev loss: 0.8479 r:0.5496
ne_en Dev loss: 0.7327 r:0.6923
ru_en Dev loss: 0.4511 r:0.7314
Current avg r:0.5883 Best avg r: 0.6257
01:48:53,553 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:11,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:42,170 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2081
en_de Dev loss: 0.8705 r:0.2235
en_zh Dev loss: 0.7524 r:0.4705
ro_en Dev loss: 0.3462 r:0.8188
et_en Dev loss: 0.5100 r:0.6742
si_en Dev loss: 0.7826 r:0.5686
ne_en Dev loss: 0.9509 r:0.7014
ru_en Dev loss: 0.4325 r:0.7402
Current avg r:0.5996 Best avg r: 0.6257
01:55:35,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:56:53,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:58:24,301 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2249
en_de Dev loss: 0.8458 r:0.2447
en_zh Dev loss: 0.7983 r:0.4506
ro_en Dev loss: 0.3551 r:0.8142
et_en Dev loss: 0.4747 r:0.6691
si_en Dev loss: 0.8334 r:0.5611
ne_en Dev loss: 0.7777 r:0.6968
ru_en Dev loss: 0.4695 r:0.7270
Current avg r:0.5948 Best avg r: 0.6257
02:02:18,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:03:35,934 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:05:06,903 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2151
en_de Dev loss: 0.8606 r:0.2270
en_zh Dev loss: 0.8129 r:0.4456
ro_en Dev loss: 0.3726 r:0.8128
et_en Dev loss: 0.4748 r:0.6628
si_en Dev loss: 0.8630 r:0.5611
ne_en Dev loss: 0.7787 r:0.6874
ru_en Dev loss: 0.4882 r:0.7171
Current avg r:0.5877 Best avg r: 0.6257
02:09:00,818 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:10:18,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:11:49,675 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2222
en_de Dev loss: 0.8759 r:0.2386
en_zh Dev loss: 0.8010 r:0.4461
ro_en Dev loss: 0.3484 r:0.8134
et_en Dev loss: 0.4751 r:0.6702
si_en Dev loss: 0.7930 r:0.5605
ne_en Dev loss: 0.8266 r:0.6957
ru_en Dev loss: 0.4407 r:0.7423
Current avg r:0.5953 Best avg r: 0.6257
02:15:42,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:17:00,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:18:30,967 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2115
en_de Dev loss: 0.8720 r:0.2178
en_zh Dev loss: 0.8130 r:0.4448
ro_en Dev loss: 0.3712 r:0.8117
et_en Dev loss: 0.4452 r:0.6677
si_en Dev loss: 0.9058 r:0.5538
ne_en Dev loss: 0.6242 r:0.6867
ru_en Dev loss: 0.5037 r:0.7192
Current avg r:0.5859 Best avg r: 0.6257
02:22:24,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:23:42,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:13,374 root INFO Epoch 7 Global steps: 63600 Train loss: 0.2116
en_de Dev loss: 0.8758 r:0.2109
en_zh Dev loss: 0.8207 r:0.4490
ro_en Dev loss: 0.3650 r:0.8171
et_en Dev loss: 0.4747 r:0.6721
si_en Dev loss: 0.8535 r:0.5583
ne_en Dev loss: 0.7700 r:0.6960
ru_en Dev loss: 0.5019 r:0.7234
Current avg r:0.5895 Best avg r: 0.6257
02:29:05,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:30:23,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:31:54,502 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1860
en_de Dev loss: 0.8951 r:0.1851
en_zh Dev loss: 0.7971 r:0.4447
ro_en Dev loss: 0.3375 r:0.8176
et_en Dev loss: 0.4789 r:0.6722
si_en Dev loss: 0.8053 r:0.5534
ne_en Dev loss: 0.8315 r:0.6958
ru_en Dev loss: 0.4473 r:0.7338
Current avg r:0.5861 Best avg r: 0.6257
02:35:46,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:04,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:35,551 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1950
en_de Dev loss: 0.8988 r:0.2141
en_zh Dev loss: 0.8424 r:0.4347
ro_en Dev loss: 0.3820 r:0.8103
et_en Dev loss: 0.4785 r:0.6682
si_en Dev loss: 0.9360 r:0.5471
ne_en Dev loss: 0.7116 r:0.6824
ru_en Dev loss: 0.5205 r:0.7178
Current avg r:0.5821 Best avg r: 0.6257
02:42:28,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:45,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:16,620 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1907
en_de Dev loss: 0.8836 r:0.2235
en_zh Dev loss: 0.8018 r:0.4504
ro_en Dev loss: 0.3730 r:0.8128
et_en Dev loss: 0.4903 r:0.6616
si_en Dev loss: 0.9032 r:0.5503
ne_en Dev loss: 0.7873 r:0.6974
ru_en Dev loss: 0.4528 r:0.7402
Current avg r:0.5909 Best avg r: 0.6257
02:49:09,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:27,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:58,393 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1887
en_de Dev loss: 0.8531 r:0.2413
en_zh Dev loss: 0.7717 r:0.4564
ro_en Dev loss: 0.3453 r:0.8147
et_en Dev loss: 0.4666 r:0.6666
si_en Dev loss: 0.8619 r:0.5489
ne_en Dev loss: 0.7786 r:0.6900
ru_en Dev loss: 0.4568 r:0.7285
Current avg r:0.5923 Best avg r: 0.6257
02:55:50,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:57:08,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:58:39,337 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1861
en_de Dev loss: 0.8609 r:0.2363
en_zh Dev loss: 0.7870 r:0.4520
ro_en Dev loss: 0.3560 r:0.8170
et_en Dev loss: 0.4802 r:0.6734
si_en Dev loss: 0.7906 r:0.5638
ne_en Dev loss: 0.8249 r:0.6943
ru_en Dev loss: 0.4442 r:0.7376
Current avg r:0.5963 Best avg r: 0.6257
03:02:32,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:49,830 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:05:20,613 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1894
en_de Dev loss: 0.8592 r:0.2238
en_zh Dev loss: 0.7927 r:0.4384
ro_en Dev loss: 0.3325 r:0.8184
et_en Dev loss: 0.4611 r:0.6723
si_en Dev loss: 0.8117 r:0.5584
ne_en Dev loss: 0.7403 r:0.6942
ru_en Dev loss: 0.4320 r:0.7383
Current avg r:0.5920 Best avg r: 0.6257
03:09:13,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:30,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:12:01,589 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1952
en_de Dev loss: 0.8575 r:0.2330
en_zh Dev loss: 0.8155 r:0.4386
ro_en Dev loss: 0.3434 r:0.8167
et_en Dev loss: 0.4686 r:0.6746
si_en Dev loss: 0.8239 r:0.5547
ne_en Dev loss: 0.7959 r:0.6997
ru_en Dev loss: 0.4413 r:0.7368
Current avg r:0.5934 Best avg r: 0.6257
03:15:54,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:17:11,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:18:42,720 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2046
en_de Dev loss: 0.8948 r:0.2077
en_zh Dev loss: 0.8580 r:0.4220
ro_en Dev loss: 0.3804 r:0.8109
et_en Dev loss: 0.4938 r:0.6605
si_en Dev loss: 0.8855 r:0.5354
ne_en Dev loss: 0.8182 r:0.6783
ru_en Dev loss: 0.4896 r:0.7144
Current avg r:0.5756 Best avg r: 0.6257
03:22:36,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:23:53,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:24,583 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1861
en_de Dev loss: 0.8926 r:0.2012
en_zh Dev loss: 0.8071 r:0.4353
ro_en Dev loss: 0.3220 r:0.8202
et_en Dev loss: 0.4377 r:0.6760
si_en Dev loss: 0.8163 r:0.5518
ne_en Dev loss: 0.7017 r:0.6925
ru_en Dev loss: 0.4528 r:0.7326
Current avg r:0.5871 Best avg r: 0.6257
03:29:17,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:30:34,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:32:05,547 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1910
en_de Dev loss: 0.9146 r:0.1896
en_zh Dev loss: 0.8384 r:0.4387
ro_en Dev loss: 0.3652 r:0.8179
et_en Dev loss: 0.4758 r:0.6752
si_en Dev loss: 0.9079 r:0.5453
ne_en Dev loss: 0.7588 r:0.6938
ru_en Dev loss: 0.4651 r:0.7362
Current avg r:0.5852 Best avg r: 0.6257
03:35:59,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:16,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:47,815 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1866
en_de Dev loss: 0.9104 r:0.2048
en_zh Dev loss: 0.8403 r:0.4253
ro_en Dev loss: 0.3570 r:0.8140
et_en Dev loss: 0.4709 r:0.6678
si_en Dev loss: 0.8738 r:0.5458
ne_en Dev loss: 0.7255 r:0.6975
ru_en Dev loss: 0.4684 r:0.7333
Current avg r:0.5841 Best avg r: 0.6257
03:42:41,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:59,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:29,792 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1866
en_de Dev loss: 0.8817 r:0.2097
en_zh Dev loss: 0.7899 r:0.4431
ro_en Dev loss: 0.3416 r:0.8168
et_en Dev loss: 0.4995 r:0.6691
si_en Dev loss: 0.8657 r:0.5436
ne_en Dev loss: 0.8240 r:0.7033
ru_en Dev loss: 0.4071 r:0.7499
Current avg r:0.5908 Best avg r: 0.6257
03:49:22,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:50:40,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:10,757 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1902
en_de Dev loss: 0.8772 r:0.2017
en_zh Dev loss: 0.7976 r:0.4375
ro_en Dev loss: 0.3584 r:0.8152
et_en Dev loss: 0.4736 r:0.6685
si_en Dev loss: 0.8622 r:0.5479
ne_en Dev loss: 0.7268 r:0.6983
ru_en Dev loss: 0.4350 r:0.7396
Current avg r:0.5870 Best avg r: 0.6257
03:56:03,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:21,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:58:51,932 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1892
en_de Dev loss: 0.8770 r:0.2326
en_zh Dev loss: 0.8050 r:0.4445
ro_en Dev loss: 0.3621 r:0.8178
et_en Dev loss: 0.5011 r:0.6681
si_en Dev loss: 0.8402 r:0.5576
ne_en Dev loss: 0.8125 r:0.7074
ru_en Dev loss: 0.4265 r:0.7507
Current avg r:0.5970 Best avg r: 0.6257
04:02:48,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:05,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:05:36,855 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1667
en_de Dev loss: 0.8872 r:0.2019
en_zh Dev loss: 0.8382 r:0.4252
ro_en Dev loss: 0.3808 r:0.8123
et_en Dev loss: 0.4946 r:0.6520
si_en Dev loss: 0.9315 r:0.5384
ne_en Dev loss: 0.7317 r:0.6887
ru_en Dev loss: 0.4819 r:0.7252
Current avg r:0.5777 Best avg r: 0.6257
04:09:30,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:10:47,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:12:18,557 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1747
en_de Dev loss: 0.8748 r:0.2271
en_zh Dev loss: 0.8026 r:0.4339
ro_en Dev loss: 0.3573 r:0.8184
et_en Dev loss: 0.4364 r:0.6703
si_en Dev loss: 0.8843 r:0.5471
ne_en Dev loss: 0.6095 r:0.6831
ru_en Dev loss: 0.4799 r:0.7266
Current avg r:0.5866 Best avg r: 0.6257
04:16:11,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:17:28,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:18:59,564 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1721
en_de Dev loss: 0.8696 r:0.2381
en_zh Dev loss: 0.8237 r:0.4343
ro_en Dev loss: 0.3667 r:0.8191
et_en Dev loss: 0.4637 r:0.6604
si_en Dev loss: 0.9568 r:0.5416
ne_en Dev loss: 0.6261 r:0.6823
ru_en Dev loss: 0.5069 r:0.7120
Current avg r:0.5840 Best avg r: 0.6257
04:22:52,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:24:10,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:25:41,312 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1686
en_de Dev loss: 0.8721 r:0.2251
en_zh Dev loss: 0.8133 r:0.4282
ro_en Dev loss: 0.3829 r:0.8093
et_en Dev loss: 0.4847 r:0.6510
si_en Dev loss: 0.9187 r:0.5395
ne_en Dev loss: 0.7293 r:0.6858
ru_en Dev loss: 0.4783 r:0.7166
Current avg r:0.5794 Best avg r: 0.6257
04:29:34,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:52,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:32:22,906 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1679
en_de Dev loss: 0.8746 r:0.2216
en_zh Dev loss: 0.7924 r:0.4299
ro_en Dev loss: 0.3612 r:0.8151
et_en Dev loss: 0.4802 r:0.6595
si_en Dev loss: 0.8653 r:0.5491
ne_en Dev loss: 0.7408 r:0.6902
ru_en Dev loss: 0.4479 r:0.7304
Current avg r:0.5851 Best avg r: 0.6257
04:36:15,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:37:33,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:39:03,810 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1706
en_de Dev loss: 0.8757 r:0.2381
en_zh Dev loss: 0.7879 r:0.4446
ro_en Dev loss: 0.3580 r:0.8157
et_en Dev loss: 0.4809 r:0.6709
si_en Dev loss: 0.8533 r:0.5518
ne_en Dev loss: 0.7972 r:0.6894
ru_en Dev loss: 0.4579 r:0.7272
Current avg r:0.5911 Best avg r: 0.6257
04:42:56,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:13,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:44,674 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1754
en_de Dev loss: 0.8833 r:0.2323
en_zh Dev loss: 0.8257 r:0.4406
ro_en Dev loss: 0.3668 r:0.8173
et_en Dev loss: 0.4953 r:0.6707
si_en Dev loss: 0.8777 r:0.5489
ne_en Dev loss: 0.7846 r:0.6933
ru_en Dev loss: 0.4532 r:0.7401
Current avg r:0.5919 Best avg r: 0.6257
04:49:37,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:54,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:52:25,781 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1750
en_de Dev loss: 0.8639 r:0.2281
en_zh Dev loss: 0.7895 r:0.4391
ro_en Dev loss: 0.3323 r:0.8174
et_en Dev loss: 0.4471 r:0.6770
si_en Dev loss: 0.9129 r:0.5459
ne_en Dev loss: 0.7061 r:0.6835
ru_en Dev loss: 0.4285 r:0.7424
Current avg r:0.5905 Best avg r: 0.6257
04:56:18,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:36,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:59:07,371 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1659
en_de Dev loss: 0.8767 r:0.2265
en_zh Dev loss: 0.7759 r:0.4542
ro_en Dev loss: 0.3476 r:0.8209
et_en Dev loss: 0.4518 r:0.6790
si_en Dev loss: 0.8538 r:0.5551
ne_en Dev loss: 0.7114 r:0.6900
ru_en Dev loss: 0.4208 r:0.7485
Current avg r:0.5963 Best avg r: 0.6257
05:02:59,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:04:17,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:05:48,400 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1647
en_de Dev loss: 0.8780 r:0.2049
en_zh Dev loss: 0.8351 r:0.4275
ro_en Dev loss: 0.3661 r:0.8141
et_en Dev loss: 0.4657 r:0.6591
si_en Dev loss: 0.9426 r:0.5404
ne_en Dev loss: 0.6968 r:0.6756
ru_en Dev loss: 0.4755 r:0.7223
Current avg r:0.5777 Best avg r: 0.6257
05:09:40,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:58,729 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:12:29,499 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1615
en_de Dev loss: 0.9085 r:0.2155
en_zh Dev loss: 0.9092 r:0.4285
ro_en Dev loss: 0.3970 r:0.8157
et_en Dev loss: 0.5202 r:0.6644
si_en Dev loss: 0.9456 r:0.5495
ne_en Dev loss: 0.7718 r:0.6825
ru_en Dev loss: 0.5188 r:0.7259
Current avg r:0.5831 Best avg r: 0.6257
05:16:21,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:39,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:19:10,436 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1636
en_de Dev loss: 0.8834 r:0.2289
en_zh Dev loss: 0.8399 r:0.4468
ro_en Dev loss: 0.3646 r:0.8163
et_en Dev loss: 0.4911 r:0.6662
si_en Dev loss: 0.9048 r:0.5567
ne_en Dev loss: 0.7348 r:0.6880
ru_en Dev loss: 0.4795 r:0.7371
Current avg r:0.5914 Best avg r: 0.6257
05:23:02,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:24:20,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:51,421 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1603
en_de Dev loss: 0.8811 r:0.2091
en_zh Dev loss: 0.8179 r:0.4372
ro_en Dev loss: 0.3521 r:0.8176
et_en Dev loss: 0.5237 r:0.6663
si_en Dev loss: 0.8408 r:0.5527
ne_en Dev loss: 0.9658 r:0.6858
ru_en Dev loss: 0.4384 r:0.7363
Current avg r:0.5864 Best avg r: 0.6257
05:29:43,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:31:01,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:32:32,297 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1647
en_de Dev loss: 0.8729 r:0.2323
en_zh Dev loss: 0.8215 r:0.4320
ro_en Dev loss: 0.3635 r:0.8136
et_en Dev loss: 0.4752 r:0.6552
si_en Dev loss: 0.8954 r:0.5507
ne_en Dev loss: 0.7340 r:0.6705
ru_en Dev loss: 0.4698 r:0.7260
Current avg r:0.5829 Best avg r: 0.6257
05:36:24,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:42,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:39:13,139 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1833
en_de Dev loss: 0.8821 r:0.2195
en_zh Dev loss: 0.8404 r:0.4364
ro_en Dev loss: 0.3756 r:0.8162
et_en Dev loss: 0.4944 r:0.6553
si_en Dev loss: 0.9571 r:0.5422
ne_en Dev loss: 0.7611 r:0.6728
ru_en Dev loss: 0.4631 r:0.7338
Current avg r:0.5823 Best avg r: 0.6257
05:43:06,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:24,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:55,516 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1476
en_de Dev loss: 0.8808 r:0.2364
en_zh Dev loss: 0.8411 r:0.4409
ro_en Dev loss: 0.3803 r:0.8173
et_en Dev loss: 0.4694 r:0.6699
si_en Dev loss: 0.9397 r:0.5521
ne_en Dev loss: 0.6853 r:0.6874
ru_en Dev loss: 0.4686 r:0.7435
Current avg r:0.5925 Best avg r: 0.6257
05:49:47,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:05,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:52:36,653 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1514
en_de Dev loss: 0.8623 r:0.2427
en_zh Dev loss: 0.8194 r:0.4443
ro_en Dev loss: 0.3475 r:0.8172
et_en Dev loss: 0.4742 r:0.6646
si_en Dev loss: 0.8923 r:0.5440
ne_en Dev loss: 0.7984 r:0.6804
ru_en Dev loss: 0.4530 r:0.7360
Current avg r:0.5899 Best avg r: 0.6257
05:56:30,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:57:48,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:19,542 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1498
en_de Dev loss: 0.8793 r:0.2318
en_zh Dev loss: 0.8657 r:0.4309
ro_en Dev loss: 0.3727 r:0.8160
et_en Dev loss: 0.4822 r:0.6588
si_en Dev loss: 0.8825 r:0.5522
ne_en Dev loss: 0.7594 r:0.6848
ru_en Dev loss: 0.4583 r:0.7390
Current avg r:0.5876 Best avg r: 0.6257
06:03:11,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:29,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:06:00,543 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1488
en_de Dev loss: 0.8825 r:0.2305
en_zh Dev loss: 0.8391 r:0.4345
ro_en Dev loss: 0.3701 r:0.8125
et_en Dev loss: 0.4999 r:0.6632
si_en Dev loss: 0.8560 r:0.5486
ne_en Dev loss: 0.8847 r:0.6925
ru_en Dev loss: 0.4401 r:0.7427
Current avg r:0.5892 Best avg r: 0.6257
06:09:53,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:10,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:12:41,607 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1517
en_de Dev loss: 0.9111 r:0.2217
en_zh Dev loss: 0.8862 r:0.4341
ro_en Dev loss: 0.3904 r:0.8155
et_en Dev loss: 0.5129 r:0.6627
si_en Dev loss: 0.9206 r:0.5483
ne_en Dev loss: 0.8666 r:0.6890
ru_en Dev loss: 0.4649 r:0.7432
Current avg r:0.5878 Best avg r: 0.6257
06:16:33,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:51,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:19:22,425 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1434
en_de Dev loss: 0.8799 r:0.2344
en_zh Dev loss: 0.8099 r:0.4494
ro_en Dev loss: 0.3431 r:0.8163
et_en Dev loss: 0.4721 r:0.6732
si_en Dev loss: 0.8139 r:0.5543
ne_en Dev loss: 0.7731 r:0.6955
ru_en Dev loss: 0.4336 r:0.7493
Current avg r:0.5961 Best avg r: 0.6257
06:23:14,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:24:32,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:03,340 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1562
en_de Dev loss: 0.8930 r:0.2013
en_zh Dev loss: 0.8637 r:0.4342
ro_en Dev loss: 0.3702 r:0.8138
et_en Dev loss: 0.4587 r:0.6621
si_en Dev loss: 0.9793 r:0.5391
ne_en Dev loss: 0.6368 r:0.6821
ru_en Dev loss: 0.4983 r:0.7258
Current avg r:0.5798 Best avg r: 0.6257
06:29:55,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:31:13,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:44,328 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1445
en_de Dev loss: 0.8763 r:0.2211
en_zh Dev loss: 0.7893 r:0.4446
ro_en Dev loss: 0.3535 r:0.8128
et_en Dev loss: 0.4513 r:0.6664
si_en Dev loss: 0.8909 r:0.5370
ne_en Dev loss: 0.7447 r:0.6771
ru_en Dev loss: 0.4440 r:0.7353
Current avg r:0.5849 Best avg r: 0.6257
06:36:36,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:54,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:25,280 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1616
en_de Dev loss: 0.8784 r:0.2486
en_zh Dev loss: 0.8008 r:0.4628
ro_en Dev loss: 0.3780 r:0.8130
et_en Dev loss: 0.5042 r:0.6664
si_en Dev loss: 0.9201 r:0.5437
ne_en Dev loss: 0.8485 r:0.6792
ru_en Dev loss: 0.4607 r:0.7390
Current avg r:0.5932 Best avg r: 0.6257
06:43:17,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:44:35,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:06,181 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1442
en_de Dev loss: 0.8933 r:0.2138
en_zh Dev loss: 0.8161 r:0.4458
ro_en Dev loss: 0.3669 r:0.8165
et_en Dev loss: 0.4860 r:0.6635
si_en Dev loss: 0.8511 r:0.5414
ne_en Dev loss: 0.7952 r:0.6729
ru_en Dev loss: 0.4560 r:0.7355
Current avg r:0.5842 Best avg r: 0.6257
06:49:58,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:16,342 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:52:47,136 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1514
en_de Dev loss: 0.8908 r:0.2105
en_zh Dev loss: 0.7721 r:0.4605
ro_en Dev loss: 0.3459 r:0.8178
et_en Dev loss: 0.4834 r:0.6703
si_en Dev loss: 0.8379 r:0.5515
ne_en Dev loss: 0.7981 r:0.6869
ru_en Dev loss: 0.4203 r:0.7489
Current avg r:0.5923 Best avg r: 0.6257
06:56:39,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:57:57,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:59:28,63 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1471
en_de Dev loss: 0.8742 r:0.2329
en_zh Dev loss: 0.7908 r:0.4582
ro_en Dev loss: 0.3526 r:0.8163
et_en Dev loss: 0.4849 r:0.6710
si_en Dev loss: 0.8550 r:0.5514
ne_en Dev loss: 0.7656 r:0.6846
ru_en Dev loss: 0.4104 r:0.7568
Current avg r:0.5959 Best avg r: 0.6257
07:03:20,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:04:38,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:06:08,916 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1417
en_de Dev loss: 0.8845 r:0.2222
en_zh Dev loss: 0.8035 r:0.4423
ro_en Dev loss: 0.3555 r:0.8144
et_en Dev loss: 0.4692 r:0.6661
si_en Dev loss: 0.8643 r:0.5463
ne_en Dev loss: 0.7166 r:0.6748
ru_en Dev loss: 0.4135 r:0.7521
Current avg r:0.5883 Best avg r: 0.6257
07:10:01,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:11:19,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:12:49,753 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1484
en_de Dev loss: 0.9134 r:0.2155
en_zh Dev loss: 0.8787 r:0.4312
ro_en Dev loss: 0.3831 r:0.8163
et_en Dev loss: 0.5085 r:0.6649
si_en Dev loss: 0.9941 r:0.5442
ne_en Dev loss: 0.6929 r:0.6791
ru_en Dev loss: 0.4571 r:0.7541
Current avg r:0.5865 Best avg r: 0.6257
07:16:42,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:59,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:19:30,583 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1494
en_de Dev loss: 0.8754 r:0.2223
en_zh Dev loss: 0.8345 r:0.4263
ro_en Dev loss: 0.3778 r:0.8118
et_en Dev loss: 0.4629 r:0.6562
si_en Dev loss: 0.9673 r:0.5423
ne_en Dev loss: 0.6161 r:0.6731
ru_en Dev loss: 0.4680 r:0.7379
Current avg r:0.5814 Best avg r: 0.6257
07:23:24,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:24:42,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:12,837 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1345
en_de Dev loss: 0.8680 r:0.2278
en_zh Dev loss: 0.8175 r:0.4395
ro_en Dev loss: 0.3462 r:0.8164
et_en Dev loss: 0.4835 r:0.6729
si_en Dev loss: 0.8242 r:0.5602
ne_en Dev loss: 0.7977 r:0.6982
ru_en Dev loss: 0.4059 r:0.7592
Current avg r:0.5963 Best avg r: 0.6257
07:30:05,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:31:22,962 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:53,715 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1339
en_de Dev loss: 0.9109 r:0.2105
en_zh Dev loss: 0.8037 r:0.4465
ro_en Dev loss: 0.3631 r:0.8179
et_en Dev loss: 0.4629 r:0.6694
si_en Dev loss: 0.9200 r:0.5497
ne_en Dev loss: 0.6506 r:0.6829
ru_en Dev loss: 0.4572 r:0.7467
Current avg r:0.5891 Best avg r: 0.6257
07:36:46,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:03,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:39:34,702 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1348
en_de Dev loss: 0.8738 r:0.2196
en_zh Dev loss: 0.7861 r:0.4433
ro_en Dev loss: 0.3578 r:0.8144
et_en Dev loss: 0.4676 r:0.6684
si_en Dev loss: 0.8542 r:0.5551
ne_en Dev loss: 0.6975 r:0.6919
ru_en Dev loss: 0.4361 r:0.7404
Current avg r:0.5904 Best avg r: 0.6257
07:43:27,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:44:44,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:46:15,838 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1342
en_de Dev loss: 0.9077 r:0.1994
en_zh Dev loss: 0.7666 r:0.4594
ro_en Dev loss: 0.3323 r:0.8212
et_en Dev loss: 0.4593 r:0.6737
si_en Dev loss: 0.8032 r:0.5569
ne_en Dev loss: 0.7785 r:0.6924
ru_en Dev loss: 0.4115 r:0.7530
Current avg r:0.5937 Best avg r: 0.6257
07:50:09,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:51:27,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:58,682 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1289
en_de Dev loss: 0.9300 r:0.1930
en_zh Dev loss: 0.8130 r:0.4449
ro_en Dev loss: 0.3552 r:0.8145
et_en Dev loss: 0.4819 r:0.6637
si_en Dev loss: 0.8967 r:0.5432
ne_en Dev loss: 0.7712 r:0.6791
ru_en Dev loss: 0.4423 r:0.7420
Current avg r:0.5829 Best avg r: 0.6257
07:56:51,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:58:09,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:59:39,912 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1322
en_de Dev loss: 0.8942 r:0.2257
en_zh Dev loss: 0.8051 r:0.4478
ro_en Dev loss: 0.3560 r:0.8177
et_en Dev loss: 0.4664 r:0.6771
si_en Dev loss: 0.8706 r:0.5493
ne_en Dev loss: 0.7719 r:0.6867
ru_en Dev loss: 0.4211 r:0.7568
Current avg r:0.5944 Best avg r: 0.6257
08:03:32,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:04:50,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:06:21,210 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1287
en_de Dev loss: 0.9008 r:0.2299
en_zh Dev loss: 0.8193 r:0.4617
ro_en Dev loss: 0.3896 r:0.8163
et_en Dev loss: 0.4754 r:0.6738
si_en Dev loss: 0.9085 r:0.5501
ne_en Dev loss: 0.6979 r:0.6848
ru_en Dev loss: 0.4560 r:0.7480
Current avg r:0.5949 Best avg r: 0.6257
08:10:13,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:11:31,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:13:02,367 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1257
en_de Dev loss: 0.9564 r:0.1987
en_zh Dev loss: 0.9212 r:0.4427
ro_en Dev loss: 0.4054 r:0.8140
et_en Dev loss: 0.4943 r:0.6621
si_en Dev loss: 1.0006 r:0.5456
ne_en Dev loss: 0.6326 r:0.6825
ru_en Dev loss: 0.5174 r:0.7375
Current avg r:0.5833 Best avg r: 0.6257
08:16:54,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:18:12,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:19:43,308 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1397
en_de Dev loss: 0.9185 r:0.2212
en_zh Dev loss: 0.9134 r:0.4424
ro_en Dev loss: 0.4108 r:0.8153
et_en Dev loss: 0.4812 r:0.6599
si_en Dev loss: 0.9898 r:0.5438
ne_en Dev loss: 0.6393 r:0.6746
ru_en Dev loss: 0.5254 r:0.7326
Current avg r:0.5843 Best avg r: 0.6257
08:23:35,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:24:53,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:24,613 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1259
en_de Dev loss: 0.8839 r:0.2222
en_zh Dev loss: 0.8008 r:0.4581
ro_en Dev loss: 0.3534 r:0.8178
et_en Dev loss: 0.4637 r:0.6688
si_en Dev loss: 0.8856 r:0.5520
ne_en Dev loss: 0.7712 r:0.6894
ru_en Dev loss: 0.4529 r:0.7424
Current avg r:0.5930 Best avg r: 0.6257
08:30:17,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:31:35,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:33:06,303 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1387
en_de Dev loss: 0.8847 r:0.2174
en_zh Dev loss: 0.8322 r:0.4494
ro_en Dev loss: 0.3872 r:0.8142
et_en Dev loss: 0.4695 r:0.6598
si_en Dev loss: 1.0089 r:0.5350
ne_en Dev loss: 0.6653 r:0.6781
ru_en Dev loss: 0.4758 r:0.7359
Current avg r:0.5843 Best avg r: 0.6257
08:36:59,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:38:16,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:39:47,788 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1309
en_de Dev loss: 0.8798 r:0.2267
en_zh Dev loss: 0.8039 r:0.4604
ro_en Dev loss: 0.3556 r:0.8162
et_en Dev loss: 0.5276 r:0.6667
si_en Dev loss: 0.8159 r:0.5479
ne_en Dev loss: 0.9727 r:0.6944
ru_en Dev loss: 0.4124 r:0.7492
Current avg r:0.5945 Best avg r: 0.6257
08:43:40,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:44:58,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:46:29,273 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1256
en_de Dev loss: 0.9188 r:0.2044
en_zh Dev loss: 0.8799 r:0.4377
ro_en Dev loss: 0.3988 r:0.8144
et_en Dev loss: 0.4860 r:0.6612
si_en Dev loss: 0.9750 r:0.5282
ne_en Dev loss: 0.6842 r:0.6701
ru_en Dev loss: 0.4942 r:0.7351
Current avg r:0.5787 Best avg r: 0.6257
08:50:21,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:51:39,800 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:53:10,582 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1347
en_de Dev loss: 0.9015 r:0.2200
en_zh Dev loss: 0.8395 r:0.4617
ro_en Dev loss: 0.3715 r:0.8166
et_en Dev loss: 0.4677 r:0.6680
si_en Dev loss: 0.8810 r:0.5477
ne_en Dev loss: 0.7442 r:0.6865
ru_en Dev loss: 0.4369 r:0.7489
Current avg r:0.5928 Best avg r: 0.6257
08:57:03,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:57:29,93 root INFO 
id:en_zh cur r: 0.4807 best r: 0.4807
08:58:20,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:59:51,805 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1269
en_de Dev loss: 0.8821 r:0.2256
en_zh Dev loss: 0.7721 r:0.4777
ro_en Dev loss: 0.3342 r:0.8180
et_en Dev loss: 0.4800 r:0.6701
si_en Dev loss: 0.8350 r:0.5506
ne_en Dev loss: 0.8074 r:0.6885
ru_en Dev loss: 0.4054 r:0.7526
Current avg r:0.5976 Best avg r: 0.6257
09:03:45,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:05:03,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:06:34,243 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1235
en_de Dev loss: 0.8814 r:0.2269
en_zh Dev loss: 0.8329 r:0.4668
ro_en Dev loss: 0.3678 r:0.8146
et_en Dev loss: 0.4805 r:0.6647
si_en Dev loss: 0.9324 r:0.5395
ne_en Dev loss: 0.7802 r:0.6845
ru_en Dev loss: 0.4327 r:0.7477
Current avg r:0.5921 Best avg r: 0.6257
09:10:26,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:11:44,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:13:15,540 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1223
en_de Dev loss: 0.8907 r:0.2297
en_zh Dev loss: 0.7816 r:0.4718
ro_en Dev loss: 0.3415 r:0.8156
et_en Dev loss: 0.4644 r:0.6627
si_en Dev loss: 0.8624 r:0.5434
ne_en Dev loss: 0.7286 r:0.6872
ru_en Dev loss: 0.4190 r:0.7531
Current avg r:0.5948 Best avg r: 0.6257
09:17:08,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:26,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:56,808 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1152
en_de Dev loss: 0.8896 r:0.2135
en_zh Dev loss: 0.8474 r:0.4615
ro_en Dev loss: 0.3765 r:0.8144
et_en Dev loss: 0.4913 r:0.6570
si_en Dev loss: 0.9720 r:0.5322
ne_en Dev loss: 0.7050 r:0.6746
ru_en Dev loss: 0.4471 r:0.7475
Current avg r:0.5858 Best avg r: 0.6257
09:23:50,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:08,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:38,797 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1135
en_de Dev loss: 0.8908 r:0.1928
en_zh Dev loss: 0.7878 r:0.4618
ro_en Dev loss: 0.3555 r:0.8154
et_en Dev loss: 0.5055 r:0.6574
si_en Dev loss: 0.8825 r:0.5403
ne_en Dev loss: 0.8345 r:0.6868
ru_en Dev loss: 0.4220 r:0.7461
Current avg r:0.5858 Best avg r: 0.6257
09:30:31,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:31:49,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:33:20,140 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1186
en_de Dev loss: 0.9029 r:0.1970
en_zh Dev loss: 0.7996 r:0.4680
ro_en Dev loss: 0.3608 r:0.8156
et_en Dev loss: 0.4779 r:0.6715
si_en Dev loss: 0.8554 r:0.5446
ne_en Dev loss: 0.7366 r:0.6864
ru_en Dev loss: 0.4270 r:0.7561
Current avg r:0.5913 Best avg r: 0.6257
09:37:12,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:38:30,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:40:01,361 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1186
en_de Dev loss: 0.9365 r:0.1793
en_zh Dev loss: 0.8386 r:0.4646
ro_en Dev loss: 0.3878 r:0.8134
et_en Dev loss: 0.4977 r:0.6633
si_en Dev loss: 0.9032 r:0.5398
ne_en Dev loss: 0.7735 r:0.6914
ru_en Dev loss: 0.4639 r:0.7485
Current avg r:0.5858 Best avg r: 0.6257
09:43:53,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:45:11,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:46:42,504 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1137
en_de Dev loss: 0.9581 r:0.1858
en_zh Dev loss: 0.8316 r:0.4713
ro_en Dev loss: 0.4157 r:0.8109
et_en Dev loss: 0.4902 r:0.6576
si_en Dev loss: 0.9824 r:0.5354
ne_en Dev loss: 0.6448 r:0.6871
ru_en Dev loss: 0.4984 r:0.7467
Current avg r:0.5850 Best avg r: 0.6257
09:50:34,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:51:00,803 root INFO 
id:en_zh cur r: 0.4837 best r: 0.4837
09:51:52,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:53:23,382 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1277
en_de Dev loss: 0.8947 r:0.2187
en_zh Dev loss: 0.7569 r:0.4839
ro_en Dev loss: 0.3556 r:0.8149
et_en Dev loss: 0.4805 r:0.6644
si_en Dev loss: 0.8588 r:0.5403
ne_en Dev loss: 0.7811 r:0.6873
ru_en Dev loss: 0.4104 r:0.7607
Current avg r:0.5958 Best avg r: 0.6257
09:57:15,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:33,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:04,230 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1152
en_de Dev loss: 0.8986 r:0.2014
en_zh Dev loss: 0.7763 r:0.4736
ro_en Dev loss: 0.3549 r:0.8169
et_en Dev loss: 0.4717 r:0.6627
si_en Dev loss: 0.8690 r:0.5428
ne_en Dev loss: 0.7248 r:0.6864
ru_en Dev loss: 0.4178 r:0.7573
Current avg r:0.5916 Best avg r: 0.6257
10:03:56,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:14,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:45,119 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1153
en_de Dev loss: 0.9176 r:0.1969
en_zh Dev loss: 0.8381 r:0.4535
ro_en Dev loss: 0.3682 r:0.8154
et_en Dev loss: 0.4632 r:0.6597
si_en Dev loss: 0.9207 r:0.5346
ne_en Dev loss: 0.6730 r:0.6790
ru_en Dev loss: 0.4765 r:0.7356
Current avg r:0.5821 Best avg r: 0.6257
10:10:37,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:55,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:13:26,35 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1157
en_de Dev loss: 0.9086 r:0.2104
en_zh Dev loss: 0.7744 r:0.4656
ro_en Dev loss: 0.3562 r:0.8126
et_en Dev loss: 0.4669 r:0.6662
si_en Dev loss: 0.8522 r:0.5378
ne_en Dev loss: 0.7787 r:0.6826
ru_en Dev loss: 0.4229 r:0.7484
Current avg r:0.5891 Best avg r: 0.6257
10:17:18,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:36,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:06,955 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1212
en_de Dev loss: 0.9253 r:0.1927
en_zh Dev loss: 0.8518 r:0.4660
ro_en Dev loss: 0.3954 r:0.8143
et_en Dev loss: 0.4962 r:0.6693
si_en Dev loss: 0.9660 r:0.5406
ne_en Dev loss: 0.7386 r:0.6862
ru_en Dev loss: 0.4580 r:0.7508
Current avg r:0.5885 Best avg r: 0.6257
10:23:59,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:17,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:47,884 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1128
en_de Dev loss: 0.9103 r:0.1938
en_zh Dev loss: 0.8045 r:0.4630
ro_en Dev loss: 0.3545 r:0.8176
et_en Dev loss: 0.4697 r:0.6690
si_en Dev loss: 0.8307 r:0.5482
ne_en Dev loss: 0.7937 r:0.6875
ru_en Dev loss: 0.4285 r:0.7491
Current avg r:0.5897 Best avg r: 0.6257
10:30:40,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
