14:54:40,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:06,47 root INFO 
id:en_zh cur r: 0.2604 best r: 0.2604
14:55:19,75 root INFO 
id:ro_en cur r: 0.4997 best r: 0.4997
14:55:32,107 root INFO 
id:et_en cur r: 0.5204 best r: 0.5204
14:55:45,160 root INFO 
id:si_en cur r: 0.3447 best r: 0.3447
14:55:58,107 root INFO 
id:ru_en cur r: 0.4885 best r: 0.4885
14:55:58,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:29,181 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
14:57:29,190 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:57:29,196 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:57:29,202 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
14:57:29,209 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
14:57:29,215 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:57:29,221 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:57:42,252 root INFO Epoch 0 Global steps: 600 Train loss: 0.8684
en_de Dev loss: 0.9348 r:0.0714
en_zh Dev loss: 0.8065 r:0.2726
ro_en Dev loss: 0.6389 r:0.5864
et_en Dev loss: 0.6451 r:0.5082
si_en Dev loss: 0.6806 r:0.4310
ne_en Dev loss: 0.6881 r:0.4748
ru_en Dev loss: 0.7462 r:0.4399
Current avg r:0.3978 Best avg r: 0.3978
15:01:35,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:48,165 root INFO 
id:en_de cur r: 0.0560 best r: 0.0560
15:02:14,114 root INFO 
id:ro_en cur r: 0.5529 best r: 0.5529
15:02:53,88 root INFO 
id:ru_en cur r: 0.5986 best r: 0.5986
15:02:53,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:24,1 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:04:24,12 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:04:24,20 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:04:24,29 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:04:24,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:04:24,45 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:04:24,52 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:04:37,67 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8315
en_de Dev loss: 0.9099 r:0.0896
en_zh Dev loss: 0.7709 r:0.2736
ro_en Dev loss: 0.6475 r:0.6141
et_en Dev loss: 0.5723 r:0.5014
si_en Dev loss: 0.7566 r:0.4456
ne_en Dev loss: 0.6500 r:0.4888
ru_en Dev loss: 0.5789 r:0.6451
Current avg r:0.4369 Best avg r: 0.4369
15:08:30,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:43,259 root INFO 
id:en_de cur r: 0.1135 best r: 0.1135
15:09:09,226 root INFO 
id:ro_en cur r: 0.5879 best r: 0.5879
15:09:48,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:18,973 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7711
en_de Dev loss: 0.9434 r:0.1078
en_zh Dev loss: 0.7982 r:0.2730
ro_en Dev loss: 0.6627 r:0.6060
et_en Dev loss: 0.5667 r:0.4913
si_en Dev loss: 0.7485 r:0.4412
ne_en Dev loss: 0.6428 r:0.4730
ru_en Dev loss: 0.5482 r:0.6325
Current avg r:0.4321 Best avg r: 0.4369
15:15:11,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:37,594 root INFO 
id:en_zh cur r: 0.2928 best r: 0.2928
15:15:50,580 root INFO 
id:ro_en cur r: 0.6513 best r: 0.6513
15:16:03,584 root INFO 
id:et_en cur r: 0.5877 best r: 0.5877
15:16:16,611 root INFO 
id:si_en cur r: 0.4255 best r: 0.4255
15:16:29,535 root INFO 
id:ru_en cur r: 0.6379 best r: 0.6379
15:16:29,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:00,422 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:18:00,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:18:00,436 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:18:00,442 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:18:00,448 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:18:00,455 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:18:00,461 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:18:13,462 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7593
en_de Dev loss: 0.9334 r:0.1025
en_zh Dev loss: 0.7665 r:0.2992
ro_en Dev loss: 0.5400 r:0.6769
et_en Dev loss: 0.5052 r:0.5801
si_en Dev loss: 0.6791 r:0.4931
ne_en Dev loss: 0.5682 r:0.5855
ru_en Dev loss: 0.5240 r:0.6679
Current avg r:0.4865 Best avg r: 0.4865
15:22:06,398 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:45,351 root INFO 
id:ro_en cur r: 0.6580 best r: 0.6580
15:22:58,357 root INFO 
id:et_en cur r: 0.6087 best r: 0.6087
15:23:11,389 root INFO 
id:si_en cur r: 0.4325 best r: 0.4325
15:23:24,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:55,204 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:24:55,214 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:24:55,221 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:24:55,227 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:24:55,233 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:24:55,240 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:24:55,247 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:25:08,263 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7137
en_de Dev loss: 0.9642 r:0.1236
en_zh Dev loss: 0.8218 r:0.3008
ro_en Dev loss: 0.5432 r:0.6797
et_en Dev loss: 0.4935 r:0.5913
si_en Dev loss: 0.7363 r:0.4917
ne_en Dev loss: 0.5653 r:0.5869
ru_en Dev loss: 0.5669 r:0.6596
Current avg r:0.4905 Best avg r: 0.4905
15:29:00,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:26,829 root INFO 
id:en_zh cur r: 0.3110 best r: 0.3110
15:29:39,840 root INFO 
id:ro_en cur r: 0.6628 best r: 0.6628
15:29:52,870 root INFO 
id:et_en cur r: 0.6313 best r: 0.6313
15:30:05,908 root INFO 
id:si_en cur r: 0.4707 best r: 0.4707
15:30:18,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:49,742 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:31:49,749 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:31:49,755 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:31:49,760 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:31:49,765 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:31:49,770 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:31:49,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:32:02,799 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6854
en_de Dev loss: 0.9721 r:0.1050
en_zh Dev loss: 0.7536 r:0.3252
ro_en Dev loss: 0.4676 r:0.6767
et_en Dev loss: 0.4609 r:0.6259
si_en Dev loss: 0.6226 r:0.5002
ne_en Dev loss: 0.5489 r:0.6092
ru_en Dev loss: 0.4819 r:0.6677
Current avg r:0.5014 Best avg r: 0.5014
15:35:55,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:21,610 root INFO 
id:en_zh cur r: 0.3550 best r: 0.3550
15:36:34,605 root INFO 
id:ro_en cur r: 0.6991 best r: 0.6991
15:36:47,622 root INFO 
id:et_en cur r: 0.6474 best r: 0.6474
15:37:00,648 root INFO 
id:si_en cur r: 0.4914 best r: 0.4914
15:37:13,578 root INFO 
id:ru_en cur r: 0.6919 best r: 0.6919
15:37:13,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:44,529 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:38:44,537 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:38:44,544 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:38:44,551 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:38:44,564 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:38:44,571 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:38:44,578 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:38:57,610 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6791
en_de Dev loss: 0.9260 r:0.1312
en_zh Dev loss: 0.7172 r:0.3713
ro_en Dev loss: 0.4435 r:0.7081
et_en Dev loss: 0.4384 r:0.6521
si_en Dev loss: 0.6032 r:0.5203
ne_en Dev loss: 0.5171 r:0.6576
ru_en Dev loss: 0.4428 r:0.7043
Current avg r:0.5350 Best avg r: 0.5350
15:42:50,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:03,367 root INFO 
id:en_de cur r: 0.1613 best r: 0.1613
15:43:16,321 root INFO 
id:en_zh cur r: 0.3790 best r: 0.3790
15:43:29,316 root INFO 
id:ro_en cur r: 0.7137 best r: 0.7137
15:43:55,355 root INFO 
id:si_en cur r: 0.5073 best r: 0.5073
15:44:08,286 root INFO 
id:ru_en cur r: 0.7115 best r: 0.7115
15:44:08,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:39,100 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:45:39,109 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:45:39,115 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:45:39,121 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:45:39,128 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:45:39,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:45:39,139 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:45:52,149 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6637
en_de Dev loss: 0.9195 r:0.1658
en_zh Dev loss: 0.6929 r:0.3999
ro_en Dev loss: 0.4163 r:0.7216
et_en Dev loss: 0.4298 r:0.6536
si_en Dev loss: 0.5835 r:0.5387
ne_en Dev loss: 0.5234 r:0.6781
ru_en Dev loss: 0.4038 r:0.7247
Current avg r:0.5546 Best avg r: 0.5546
15:49:45,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:36,973 root INFO 
id:et_en cur r: 0.6548 best r: 0.6548
15:51:02,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:33,778 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5787
en_de Dev loss: 0.9890 r:0.1713
en_zh Dev loss: 0.7908 r:0.3855
ro_en Dev loss: 0.4868 r:0.7161
et_en Dev loss: 0.4155 r:0.6593
si_en Dev loss: 0.6762 r:0.5349
ne_en Dev loss: 0.4708 r:0.6615
ru_en Dev loss: 0.5068 r:0.6996
Current avg r:0.5469 Best avg r: 0.5546
15:56:26,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:39,936 root INFO 
id:en_de cur r: 0.1683 best r: 0.1683
15:56:52,899 root INFO 
id:en_zh cur r: 0.3936 best r: 0.3936
15:57:05,890 root INFO 
id:ro_en cur r: 0.7394 best r: 0.7394
15:57:18,900 root INFO 
id:et_en cur r: 0.6643 best r: 0.6643
15:57:31,915 root INFO 
id:si_en cur r: 0.5280 best r: 0.5280
15:57:44,841 root INFO 
id:ru_en cur r: 0.7139 best r: 0.7139
15:57:44,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:15,671 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:59:15,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:59:15,687 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:59:15,694 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:59:15,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:59:15,708 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:59:15,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:59:28,730 root INFO Epoch 0 Global steps: 6000 Train loss: 0.6043
en_de Dev loss: 0.9057 r:0.1893
en_zh Dev loss: 0.7018 r:0.4065
ro_en Dev loss: 0.4028 r:0.7445
et_en Dev loss: 0.3878 r:0.6757
si_en Dev loss: 0.6133 r:0.5525
ne_en Dev loss: 0.4733 r:0.6831
ru_en Dev loss: 0.4195 r:0.7305
Current avg r:0.5689 Best avg r: 0.5689
16:03:21,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:34,422 root INFO 
id:en_de cur r: 0.1719 best r: 0.1719
16:03:47,374 root INFO 
id:en_zh cur r: 0.4083 best r: 0.4083
16:04:00,366 root INFO 
id:ro_en cur r: 0.7419 best r: 0.7419
16:04:13,369 root INFO 
id:et_en cur r: 0.6719 best r: 0.6719
16:04:39,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:10,175 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:06:10,191 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:06:10,201 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:06:10,212 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:06:10,223 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:06:10,231 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:06:10,242 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:06:23,245 root INFO Epoch 0 Global steps: 6600 Train loss: 0.6284
en_de Dev loss: 0.9076 r:0.1989
en_zh Dev loss: 0.6919 r:0.4153
ro_en Dev loss: 0.3869 r:0.7549
et_en Dev loss: 0.3835 r:0.6828
si_en Dev loss: 0.6380 r:0.5570
ne_en Dev loss: 0.4743 r:0.6868
ru_en Dev loss: 0.4446 r:0.7173
Current avg r:0.5733 Best avg r: 0.5733
16:10:16,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:29,434 root INFO 
id:en_de cur r: 0.2060 best r: 0.2060
16:11:08,393 root INFO 
id:et_en cur r: 0.6722 best r: 0.6722
16:11:34,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:05,144 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5960
en_de Dev loss: 0.9553 r:0.2117
en_zh Dev loss: 0.7960 r:0.3963
ro_en Dev loss: 0.4043 r:0.7437
et_en Dev loss: 0.3858 r:0.6752
si_en Dev loss: 0.7583 r:0.5206
ne_en Dev loss: 0.4520 r:0.6785
ru_en Dev loss: 0.5044 r:0.7006
Current avg r:0.5609 Best avg r: 0.5733
16:16:57,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:36,764 root INFO 
id:ro_en cur r: 0.7455 best r: 0.7455
16:18:15,749 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:46,689 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5625
en_de Dev loss: 0.9732 r:0.1946
en_zh Dev loss: 0.7682 r:0.4119
ro_en Dev loss: 0.4294 r:0.7511
et_en Dev loss: 0.4040 r:0.6633
si_en Dev loss: 0.6836 r:0.5300
ne_en Dev loss: 0.4487 r:0.6884
ru_en Dev loss: 0.5453 r:0.6902
Current avg r:0.5614 Best avg r: 0.5733
16:23:40,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:19,266 root INFO 
id:ro_en cur r: 0.7630 best r: 0.7630
16:24:58,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:29,193 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5723
en_de Dev loss: 0.9890 r:0.1818
en_zh Dev loss: 0.7695 r:0.4106
ro_en Dev loss: 0.4401 r:0.7608
et_en Dev loss: 0.4342 r:0.6598
si_en Dev loss: 0.7979 r:0.5289
ne_en Dev loss: 0.4215 r:0.6909
ru_en Dev loss: 0.5081 r:0.7106
Current avg r:0.5633 Best avg r: 0.5733
16:30:22,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:35,224 root INFO 
id:en_de cur r: 0.2146 best r: 0.2146
16:30:48,181 root INFO 
id:en_zh cur r: 0.4352 best r: 0.4352
16:31:01,182 root INFO 
id:ro_en cur r: 0.7783 best r: 0.7783
16:31:14,181 root INFO 
id:et_en cur r: 0.6823 best r: 0.6823
16:31:27,193 root INFO 
id:si_en cur r: 0.5655 best r: 0.5655
16:31:40,106 root INFO 
id:ru_en cur r: 0.7277 best r: 0.7277
16:31:40,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:10,942 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:33:10,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:33:10,962 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:33:10,967 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:33:10,973 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:33:10,979 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:33:10,985 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:33:24,3 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5923
en_de Dev loss: 0.8864 r:0.2111
en_zh Dev loss: 0.6794 r:0.4380
ro_en Dev loss: 0.3445 r:0.7791
et_en Dev loss: 0.3765 r:0.6887
si_en Dev loss: 0.6167 r:0.5667
ne_en Dev loss: 0.5082 r:0.7124
ru_en Dev loss: 0.4357 r:0.7285
Current avg r:0.5892 Best avg r: 0.5892
16:37:18,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:31,75 root INFO 
id:en_de cur r: 0.2164 best r: 0.2164
16:37:44,32 root INFO 
id:en_zh cur r: 0.4411 best r: 0.4411
16:38:10,23 root INFO 
id:et_en cur r: 0.6940 best r: 0.6940
16:38:23,41 root INFO 
id:si_en cur r: 0.5701 best r: 0.5701
16:38:35,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:06,885 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:40:06,892 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:40:06,898 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:40:06,903 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:40:06,908 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:40:06,913 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:40:06,918 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:40:19,947 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5550
en_de Dev loss: 0.8580 r:0.2178
en_zh Dev loss: 0.6568 r:0.4507
ro_en Dev loss: 0.3475 r:0.7764
et_en Dev loss: 0.4150 r:0.6973
si_en Dev loss: 0.5373 r:0.5850
ne_en Dev loss: 0.6729 r:0.7120
ru_en Dev loss: 0.3906 r:0.7311
Current avg r:0.5958 Best avg r: 0.5958
16:44:13,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:31,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:02,15 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5504
en_de Dev loss: 0.8947 r:0.2082
en_zh Dev loss: 0.6936 r:0.4419
ro_en Dev loss: 0.3740 r:0.7754
et_en Dev loss: 0.3807 r:0.6836
si_en Dev loss: 0.6350 r:0.5682
ne_en Dev loss: 0.4680 r:0.6959
ru_en Dev loss: 0.5111 r:0.7001
Current avg r:0.5819 Best avg r: 0.5958
16:50:55,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:33,946 root INFO 
id:ro_en cur r: 0.7869 best r: 0.7869
16:51:59,951 root INFO 
id:si_en cur r: 0.5739 best r: 0.5739
16:52:12,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:43,678 root INFO Epoch 1 Global steps: 10800 Train loss: 0.6129
en_de Dev loss: 0.8539 r:0.2140
en_zh Dev loss: 0.6731 r:0.4392
ro_en Dev loss: 0.3417 r:0.7866
et_en Dev loss: 0.4322 r:0.6886
si_en Dev loss: 0.5728 r:0.5767
ne_en Dev loss: 0.6617 r:0.7047
ru_en Dev loss: 0.4102 r:0.7159
Current avg r:0.5894 Best avg r: 0.5958
16:57:36,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:54,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:25,453 root INFO Epoch 1 Global steps: 11400 Train loss: 0.5371
en_de Dev loss: 0.8635 r:0.2133
en_zh Dev loss: 0.6925 r:0.4313
ro_en Dev loss: 0.3390 r:0.7875
et_en Dev loss: 0.3845 r:0.6869
si_en Dev loss: 0.5934 r:0.5737
ne_en Dev loss: 0.5621 r:0.7108
ru_en Dev loss: 0.4244 r:0.7288
Current avg r:0.5903 Best avg r: 0.5958
17:04:18,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:31,629 root INFO 
id:en_de cur r: 0.2174 best r: 0.2174
17:04:57,585 root INFO 
id:ro_en cur r: 0.7983 best r: 0.7983
17:05:23,623 root INFO 
id:si_en cur r: 0.5878 best r: 0.5878
17:05:36,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:07,428 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:07:07,439 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:07:07,449 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:07:07,456 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:07:07,463 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:07:07,469 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:07:07,474 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:07:20,495 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5473
en_de Dev loss: 0.8879 r:0.2185
en_zh Dev loss: 0.7578 r:0.4454
ro_en Dev loss: 0.3699 r:0.8017
et_en Dev loss: 0.3823 r:0.6915
si_en Dev loss: 0.6561 r:0.5860
ne_en Dev loss: 0.4396 r:0.7147
ru_en Dev loss: 0.4748 r:0.7277
Current avg r:0.5979 Best avg r: 0.5979
17:11:13,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:26,761 root INFO 
id:en_de cur r: 0.2218 best r: 0.2218
17:11:39,748 root INFO 
id:en_zh cur r: 0.4505 best r: 0.4505
17:11:52,751 root INFO 
id:ro_en cur r: 0.8019 best r: 0.8019
17:12:31,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:02,640 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:14:02,650 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:14:02,659 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:14:02,668 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:14:02,679 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:14:02,691 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:14:02,699 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:14:15,711 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5219
en_de Dev loss: 0.8731 r:0.2240
en_zh Dev loss: 0.7108 r:0.4526
ro_en Dev loss: 0.3545 r:0.7998
et_en Dev loss: 0.3966 r:0.6885
si_en Dev loss: 0.6497 r:0.5826
ne_en Dev loss: 0.4834 r:0.7211
ru_en Dev loss: 0.4819 r:0.7261
Current avg r:0.5993 Best avg r: 0.5993
17:18:08,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:21,565 root INFO 
id:en_de cur r: 0.2348 best r: 0.2348
17:18:34,526 root INFO 
id:en_zh cur r: 0.4510 best r: 0.4510
17:18:47,532 root INFO 
id:ro_en cur r: 0.8091 best r: 0.8091
17:19:26,497 root INFO 
id:ru_en cur r: 0.7285 best r: 0.7285
17:19:26,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:57,420 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:20:57,433 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:20:57,443 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:20:57,449 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:20:57,456 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:20:57,461 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:20:57,467 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:21:10,485 root INFO Epoch 1 Global steps: 13200 Train loss: 0.5020
en_de Dev loss: 0.8672 r:0.2277
en_zh Dev loss: 0.7258 r:0.4566
ro_en Dev loss: 0.3382 r:0.8050
et_en Dev loss: 0.3735 r:0.6977
si_en Dev loss: 0.6453 r:0.5821
ne_en Dev loss: 0.4645 r:0.7204
ru_en Dev loss: 0.4559 r:0.7322
Current avg r:0.6031 Best avg r: 0.6031
17:25:03,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:16,475 root INFO 
id:en_de cur r: 0.2467 best r: 0.2467
17:25:42,425 root INFO 
id:ro_en cur r: 0.8139 best r: 0.8139
17:25:55,435 root INFO 
id:et_en cur r: 0.7012 best r: 0.7012
17:26:21,376 root INFO 
id:ru_en cur r: 0.7510 best r: 0.7510
17:26:21,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:52,280 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:27:52,292 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:27:52,300 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:27:52,306 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:27:52,314 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:27:52,325 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:27:52,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:28:05,358 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4923
en_de Dev loss: 0.8512 r:0.2291
en_zh Dev loss: 0.6841 r:0.4568
ro_en Dev loss: 0.3210 r:0.8108
et_en Dev loss: 0.3587 r:0.7037
si_en Dev loss: 0.6106 r:0.5921
ne_en Dev loss: 0.4749 r:0.7291
ru_en Dev loss: 0.3927 r:0.7542
Current avg r:0.6108 Best avg r: 0.6108
17:31:58,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:24,686 root INFO 
id:en_zh cur r: 0.4579 best r: 0.4579
17:33:16,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:47,528 root INFO Epoch 1 Global steps: 14400 Train loss: 0.5010
en_de Dev loss: 0.8679 r:0.2257
en_zh Dev loss: 0.6868 r:0.4646
ro_en Dev loss: 0.3470 r:0.8120
et_en Dev loss: 0.3672 r:0.7014
si_en Dev loss: 0.6730 r:0.5905
ne_en Dev loss: 0.4385 r:0.7249
ru_en Dev loss: 0.4655 r:0.7388
Current avg r:0.6083 Best avg r: 0.6108
17:38:40,865 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:19,813 root INFO 
id:ro_en cur r: 0.8145 best r: 0.8145
17:39:58,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:29,588 root INFO Epoch 1 Global steps: 15000 Train loss: 0.5021
en_de Dev loss: 0.9050 r:0.2227
en_zh Dev loss: 0.7458 r:0.4443
ro_en Dev loss: 0.3516 r:0.8050
et_en Dev loss: 0.3851 r:0.6860
si_en Dev loss: 0.7489 r:0.5684
ne_en Dev loss: 0.4354 r:0.7074
ru_en Dev loss: 0.5047 r:0.7282
Current avg r:0.5946 Best avg r: 0.6108
17:45:22,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:40,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:11,811 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4786
en_de Dev loss: 0.8673 r:0.2277
en_zh Dev loss: 0.7358 r:0.4445
ro_en Dev loss: 0.3531 r:0.7992
et_en Dev loss: 0.3886 r:0.6826
si_en Dev loss: 0.6920 r:0.5674
ne_en Dev loss: 0.4854 r:0.7058
ru_en Dev loss: 0.5068 r:0.7150
Current avg r:0.5917 Best avg r: 0.6108
17:52:04,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:17,627 root INFO 
id:en_de cur r: 0.2578 best r: 0.2578
17:52:30,593 root INFO 
id:en_zh cur r: 0.4743 best r: 0.4743
17:52:43,583 root INFO 
id:ro_en cur r: 0.8229 best r: 0.8229
17:53:09,590 root INFO 
id:si_en cur r: 0.6027 best r: 0.6027
17:53:22,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:53,293 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:54:53,302 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:54:53,308 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:54:53,314 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:54:53,321 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:54:53,327 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:54:53,333 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:55:06,348 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4912
en_de Dev loss: 0.8403 r:0.2438
en_zh Dev loss: 0.6626 r:0.4749
ro_en Dev loss: 0.3105 r:0.8178
et_en Dev loss: 0.3907 r:0.6952
si_en Dev loss: 0.5609 r:0.6034
ne_en Dev loss: 0.6279 r:0.7365
ru_en Dev loss: 0.3899 r:0.7518
Current avg r:0.6176 Best avg r: 0.6176
17:58:59,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:17,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:48,326 root INFO Epoch 1 Global steps: 16800 Train loss: 0.5071
en_de Dev loss: 0.8783 r:0.2534
en_zh Dev loss: 0.7162 r:0.4709
ro_en Dev loss: 0.3808 r:0.7996
et_en Dev loss: 0.4095 r:0.6773
si_en Dev loss: 0.7586 r:0.5751
ne_en Dev loss: 0.4490 r:0.7166
ru_en Dev loss: 0.5286 r:0.7081
Current avg r:0.6001 Best avg r: 0.6176
18:05:41,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:54,608 root INFO 
id:en_de cur r: 0.2604 best r: 0.2604
18:06:59,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:30,439 root INFO Epoch 1 Global steps: 17400 Train loss: 0.5237
en_de Dev loss: 0.8639 r:0.2523
en_zh Dev loss: 0.7557 r:0.4728
ro_en Dev loss: 0.3720 r:0.8068
et_en Dev loss: 0.4146 r:0.6819
si_en Dev loss: 0.7214 r:0.5864
ne_en Dev loss: 0.4520 r:0.7210
ru_en Dev loss: 0.5146 r:0.7156
Current avg r:0.6053 Best avg r: 0.6176
18:12:23,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:36,491 root INFO 
id:en_de cur r: 0.2684 best r: 0.2684
18:12:49,463 root INFO 
id:en_zh cur r: 0.4795 best r: 0.4795
18:13:28,483 root INFO 
id:si_en cur r: 0.6097 best r: 0.6097
18:13:41,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:12,309 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
18:15:12,318 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:15:12,325 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:15:12,330 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
18:15:12,335 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
18:15:12,341 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:15:12,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:15:25,381 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4882
en_de Dev loss: 0.8388 r:0.2703
en_zh Dev loss: 0.6793 r:0.4814
ro_en Dev loss: 0.2911 r:0.8199
et_en Dev loss: 0.3696 r:0.7019
si_en Dev loss: 0.5634 r:0.6101
ne_en Dev loss: 0.5441 r:0.7375
ru_en Dev loss: 0.3775 r:0.7502
Current avg r:0.6245 Best avg r: 0.6245
18:19:19,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:32,864 root INFO 
id:en_de cur r: 0.2688 best r: 0.2688
18:19:45,824 root INFO 
id:en_zh cur r: 0.4844 best r: 0.4844
18:20:37,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:08,628 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4888
en_de Dev loss: 0.8332 r:0.2772
en_zh Dev loss: 0.6600 r:0.4796
ro_en Dev loss: 0.3141 r:0.8144
et_en Dev loss: 0.3753 r:0.6997
si_en Dev loss: 0.6321 r:0.6025
ne_en Dev loss: 0.5065 r:0.7356
ru_en Dev loss: 0.4114 r:0.7363
Current avg r:0.6208 Best avg r: 0.6245
18:26:01,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:53,519 root INFO 
id:et_en cur r: 0.7103 best r: 0.7103
18:27:19,443 root INFO 
id:ru_en cur r: 0.7578 best r: 0.7578
18:27:19,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:50,358 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4844
en_de Dev loss: 0.8307 r:0.2746
en_zh Dev loss: 0.7205 r:0.4728
ro_en Dev loss: 0.3422 r:0.8117
et_en Dev loss: 0.3666 r:0.7059
si_en Dev loss: 0.6974 r:0.5894
ne_en Dev loss: 0.4839 r:0.7333
ru_en Dev loss: 0.3899 r:0.7622
Current avg r:0.6214 Best avg r: 0.6245
18:32:43,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:56,696 root INFO 
id:en_de cur r: 0.2703 best r: 0.2703
18:33:35,667 root INFO 
id:et_en cur r: 0.7113 best r: 0.7113
18:34:01,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:32,516 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4740
en_de Dev loss: 0.8406 r:0.2837
en_zh Dev loss: 0.7131 r:0.4667
ro_en Dev loss: 0.3281 r:0.8166
et_en Dev loss: 0.3642 r:0.7097
si_en Dev loss: 0.6542 r:0.5972
ne_en Dev loss: 0.4943 r:0.7329
ru_en Dev loss: 0.4391 r:0.7451
Current avg r:0.6217 Best avg r: 0.6245
18:39:25,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:43,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:14,644 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4472
en_de Dev loss: 0.8363 r:0.2609
en_zh Dev loss: 0.7126 r:0.4708
ro_en Dev loss: 0.3227 r:0.8145
et_en Dev loss: 0.3911 r:0.6982
si_en Dev loss: 0.6178 r:0.5981
ne_en Dev loss: 0.5738 r:0.7354
ru_en Dev loss: 0.4357 r:0.7465
Current avg r:0.6178 Best avg r: 0.6245
18:46:07,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:25,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:56,216 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4503
en_de Dev loss: 0.8519 r:0.2483
en_zh Dev loss: 0.7089 r:0.4572
ro_en Dev loss: 0.3379 r:0.8115
et_en Dev loss: 0.3804 r:0.6952
si_en Dev loss: 0.7121 r:0.5824
ne_en Dev loss: 0.4984 r:0.7302
ru_en Dev loss: 0.4842 r:0.7245
Current avg r:0.6071 Best avg r: 0.6245
18:52:48,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:06,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:37,740 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4382
en_de Dev loss: 0.8466 r:0.2638
en_zh Dev loss: 0.7240 r:0.4694
ro_en Dev loss: 0.3652 r:0.8081
et_en Dev loss: 0.3924 r:0.6922
si_en Dev loss: 0.6790 r:0.5929
ne_en Dev loss: 0.4390 r:0.7369
ru_en Dev loss: 0.4784 r:0.7419
Current avg r:0.6150 Best avg r: 0.6245
18:59:31,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:49,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:19,915 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4469
en_de Dev loss: 0.8662 r:0.2377
en_zh Dev loss: 0.7565 r:0.4684
ro_en Dev loss: 0.3628 r:0.8113
et_en Dev loss: 0.4012 r:0.6931
si_en Dev loss: 0.6589 r:0.5926
ne_en Dev loss: 0.5804 r:0.7340
ru_en Dev loss: 0.4894 r:0.7325
Current avg r:0.6099 Best avg r: 0.6245
19:06:13,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:39,95 root INFO 
id:en_zh cur r: 0.4897 best r: 0.4897
19:07:31,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:01,946 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4581
en_de Dev loss: 0.8331 r:0.2584
en_zh Dev loss: 0.6625 r:0.4914
ro_en Dev loss: 0.3272 r:0.8159
et_en Dev loss: 0.3884 r:0.6949
si_en Dev loss: 0.6441 r:0.6018
ne_en Dev loss: 0.5831 r:0.7426
ru_en Dev loss: 0.4237 r:0.7439
Current avg r:0.6213 Best avg r: 0.6245
19:12:55,27 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:13,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:43,941 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4432
en_de Dev loss: 0.8634 r:0.2672
en_zh Dev loss: 0.7220 r:0.4794
ro_en Dev loss: 0.3495 r:0.8109
et_en Dev loss: 0.3913 r:0.6923
si_en Dev loss: 0.6774 r:0.5951
ne_en Dev loss: 0.5180 r:0.7341
ru_en Dev loss: 0.4403 r:0.7454
Current avg r:0.6178 Best avg r: 0.6245
19:19:36,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:49,657 root INFO 
id:en_de cur r: 0.2799 best r: 0.2799
19:20:41,599 root INFO 
id:si_en cur r: 0.6103 best r: 0.6103
19:20:54,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:25,406 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4536
en_de Dev loss: 0.8467 r:0.2620
en_zh Dev loss: 0.6753 r:0.4878
ro_en Dev loss: 0.3211 r:0.8163
et_en Dev loss: 0.3736 r:0.6964
si_en Dev loss: 0.5831 r:0.6072
ne_en Dev loss: 0.5485 r:0.7383
ru_en Dev loss: 0.4539 r:0.7381
Current avg r:0.6209 Best avg r: 0.6245
19:26:18,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:36,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:07,0 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4621
en_de Dev loss: 0.8352 r:0.2633
en_zh Dev loss: 0.6932 r:0.4748
ro_en Dev loss: 0.3192 r:0.8154
et_en Dev loss: 0.3903 r:0.7003
si_en Dev loss: 0.6196 r:0.5958
ne_en Dev loss: 0.6515 r:0.7405
ru_en Dev loss: 0.4367 r:0.7421
Current avg r:0.6189 Best avg r: 0.6245
19:33:00,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:13,94 root INFO 
id:en_de cur r: 0.2893 best r: 0.2893
19:34:17,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:48,667 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4212
en_de Dev loss: 0.8565 r:0.2616
en_zh Dev loss: 0.6834 r:0.4857
ro_en Dev loss: 0.3282 r:0.8142
et_en Dev loss: 0.3847 r:0.6982
si_en Dev loss: 0.6343 r:0.5963
ne_en Dev loss: 0.5692 r:0.7369
ru_en Dev loss: 0.5006 r:0.7305
Current avg r:0.6176 Best avg r: 0.6245
19:39:41,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:59,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:30,282 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4442
en_de Dev loss: 0.8446 r:0.2447
en_zh Dev loss: 0.7243 r:0.4634
ro_en Dev loss: 0.3427 r:0.8076
et_en Dev loss: 0.3962 r:0.6879
si_en Dev loss: 0.7701 r:0.5713
ne_en Dev loss: 0.5164 r:0.7284
ru_en Dev loss: 0.5440 r:0.7076
Current avg r:0.6016 Best avg r: 0.6245
19:46:23,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:41,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:11,871 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4423
en_de Dev loss: 0.8753 r:0.2391
en_zh Dev loss: 0.7946 r:0.4583
ro_en Dev loss: 0.3942 r:0.8093
et_en Dev loss: 0.4037 r:0.6906
si_en Dev loss: 0.8360 r:0.5789
ne_en Dev loss: 0.4145 r:0.7294
ru_en Dev loss: 0.5584 r:0.7255
Current avg r:0.6044 Best avg r: 0.6245
19:53:04,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:22,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:53,310 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4732
en_de Dev loss: 0.8450 r:0.2583
en_zh Dev loss: 0.7152 r:0.4654
ro_en Dev loss: 0.3415 r:0.8119
et_en Dev loss: 0.3992 r:0.6981
si_en Dev loss: 0.7054 r:0.5964
ne_en Dev loss: 0.5559 r:0.7420
ru_en Dev loss: 0.4184 r:0.7574
Current avg r:0.6185 Best avg r: 0.6245
19:59:47,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:26,327 root INFO 
id:ro_en cur r: 0.8249 best r: 0.8249
20:00:52,367 root INFO 
id:si_en cur r: 0.6205 best r: 0.6205
20:01:05,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:36,174 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
20:02:36,188 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:02:36,195 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:02:36,203 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
20:02:36,211 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
20:02:36,220 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
20:02:36,231 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
20:02:49,231 root INFO Epoch 3 Global steps: 27600 Train loss: 0.4136
en_de Dev loss: 0.8341 r:0.2801
en_zh Dev loss: 0.7145 r:0.4671
ro_en Dev loss: 0.3140 r:0.8194
et_en Dev loss: 0.4132 r:0.7007
si_en Dev loss: 0.5867 r:0.6084
ne_en Dev loss: 0.6968 r:0.7444
ru_en Dev loss: 0.4048 r:0.7556
Current avg r:0.6251 Best avg r: 0.6251
20:06:42,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:00,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:31,102 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3973
en_de Dev loss: 0.8697 r:0.2633
en_zh Dev loss: 0.7827 r:0.4527
ro_en Dev loss: 0.3747 r:0.8104
et_en Dev loss: 0.4301 r:0.6811
si_en Dev loss: 0.7958 r:0.5802
ne_en Dev loss: 0.5252 r:0.7285
ru_en Dev loss: 0.4696 r:0.7411
Current avg r:0.6082 Best avg r: 0.6251
20:13:24,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:41,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:12,699 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3985
en_de Dev loss: 0.8399 r:0.2392
en_zh Dev loss: 0.6740 r:0.4780
ro_en Dev loss: 0.3233 r:0.8195
et_en Dev loss: 0.3971 r:0.6936
si_en Dev loss: 0.7028 r:0.6013
ne_en Dev loss: 0.5446 r:0.7392
ru_en Dev loss: 0.4168 r:0.7517
Current avg r:0.6175 Best avg r: 0.6251
20:20:05,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:23,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:53,980 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4190
en_de Dev loss: 0.8555 r:0.2156
en_zh Dev loss: 0.7117 r:0.4649
ro_en Dev loss: 0.3370 r:0.8118
et_en Dev loss: 0.4576 r:0.6869
si_en Dev loss: 0.6548 r:0.5901
ne_en Dev loss: 0.7562 r:0.7289
ru_en Dev loss: 0.4498 r:0.7168
Current avg r:0.6021 Best avg r: 0.6251
20:26:47,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:25,971 root INFO 
id:ro_en cur r: 0.8254 best r: 0.8254
20:28:04,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:35,619 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3728
en_de Dev loss: 0.8545 r:0.2346
en_zh Dev loss: 0.6989 r:0.4637
ro_en Dev loss: 0.3090 r:0.8208
et_en Dev loss: 0.3948 r:0.6993
si_en Dev loss: 0.5940 r:0.6064
ne_en Dev loss: 0.6127 r:0.7379
ru_en Dev loss: 0.4435 r:0.7315
Current avg r:0.6135 Best avg r: 0.6251
20:33:28,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:46,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:16,870 root INFO Epoch 3 Global steps: 30600 Train loss: 0.4178
en_de Dev loss: 0.8440 r:0.2406
en_zh Dev loss: 0.6970 r:0.4651
ro_en Dev loss: 0.3131 r:0.8196
et_en Dev loss: 0.3907 r:0.6937
si_en Dev loss: 0.6587 r:0.5980
ne_en Dev loss: 0.5736 r:0.7357
ru_en Dev loss: 0.4615 r:0.7267
Current avg r:0.6113 Best avg r: 0.6251
20:40:10,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:48,994 root INFO 
id:ro_en cur r: 0.8281 best r: 0.8281
20:41:27,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:58,904 root INFO Epoch 3 Global steps: 31200 Train loss: 0.4384
en_de Dev loss: 0.8399 r:0.2480
en_zh Dev loss: 0.7252 r:0.4690
ro_en Dev loss: 0.3371 r:0.8191
et_en Dev loss: 0.4086 r:0.6952
si_en Dev loss: 0.6422 r:0.5986
ne_en Dev loss: 0.6495 r:0.7379
ru_en Dev loss: 0.4918 r:0.7224
Current avg r:0.6129 Best avg r: 0.6251
20:46:51,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:09,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:40,290 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3871
en_de Dev loss: 0.8549 r:0.2039
en_zh Dev loss: 0.7159 r:0.4590
ro_en Dev loss: 0.3283 r:0.8176
et_en Dev loss: 0.4095 r:0.6890
si_en Dev loss: 0.6859 r:0.5935
ne_en Dev loss: 0.6239 r:0.7338
ru_en Dev loss: 0.4510 r:0.7170
Current avg r:0.6020 Best avg r: 0.6251
20:53:32,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:50,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:21,525 root INFO Epoch 3 Global steps: 32400 Train loss: 0.4053
en_de Dev loss: 0.8525 r:0.2248
en_zh Dev loss: 0.7106 r:0.4715
ro_en Dev loss: 0.3183 r:0.8206
et_en Dev loss: 0.4034 r:0.6888
si_en Dev loss: 0.6476 r:0.6041
ne_en Dev loss: 0.6128 r:0.7397
ru_en Dev loss: 0.4714 r:0.7221
Current avg r:0.6102 Best avg r: 0.6251
21:00:14,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:32,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:02,844 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3942
en_de Dev loss: 0.8859 r:0.2229
en_zh Dev loss: 0.8227 r:0.4447
ro_en Dev loss: 0.3815 r:0.8107
et_en Dev loss: 0.4246 r:0.6826
si_en Dev loss: 0.7606 r:0.5876
ne_en Dev loss: 0.5345 r:0.7299
ru_en Dev loss: 0.5471 r:0.7095
Current avg r:0.5983 Best avg r: 0.6251
21:06:55,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:13,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:44,1 root INFO Epoch 3 Global steps: 33600 Train loss: 0.4078
en_de Dev loss: 0.8536 r:0.2425
en_zh Dev loss: 0.7422 r:0.4537
ro_en Dev loss: 0.3412 r:0.8122
et_en Dev loss: 0.4159 r:0.6892
si_en Dev loss: 0.6293 r:0.6002
ne_en Dev loss: 0.6865 r:0.7415
ru_en Dev loss: 0.4574 r:0.7270
Current avg r:0.6095 Best avg r: 0.6251
21:13:36,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:54,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:25,629 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3831
en_de Dev loss: 0.8590 r:0.2441
en_zh Dev loss: 0.7632 r:0.4499
ro_en Dev loss: 0.3547 r:0.8170
et_en Dev loss: 0.4016 r:0.6855
si_en Dev loss: 0.7423 r:0.6011
ne_en Dev loss: 0.4896 r:0.7365
ru_en Dev loss: 0.5126 r:0.7165
Current avg r:0.6072 Best avg r: 0.6251
21:20:18,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:36,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:06,902 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3583
en_de Dev loss: 0.8573 r:0.2408
en_zh Dev loss: 0.7758 r:0.4537
ro_en Dev loss: 0.3519 r:0.8153
et_en Dev loss: 0.4265 r:0.6884
si_en Dev loss: 0.7135 r:0.5925
ne_en Dev loss: 0.6484 r:0.7337
ru_en Dev loss: 0.4643 r:0.7285
Current avg r:0.6076 Best avg r: 0.6251
21:26:59,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:38,626 root INFO 
id:ro_en cur r: 0.8290 best r: 0.8290
21:28:17,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:48,396 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3824
en_de Dev loss: 0.8416 r:0.2465
en_zh Dev loss: 0.7356 r:0.4515
ro_en Dev loss: 0.3013 r:0.8263
et_en Dev loss: 0.3911 r:0.6879
si_en Dev loss: 0.6676 r:0.6026
ne_en Dev loss: 0.5743 r:0.7344
ru_en Dev loss: 0.4739 r:0.7212
Current avg r:0.6101 Best avg r: 0.6251
21:33:41,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:59,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:30,247 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3954
en_de Dev loss: 0.8648 r:0.2380
en_zh Dev loss: 0.7797 r:0.4515
ro_en Dev loss: 0.3386 r:0.8234
et_en Dev loss: 0.4033 r:0.6888
si_en Dev loss: 0.6744 r:0.6045
ne_en Dev loss: 0.5921 r:0.7332
ru_en Dev loss: 0.4854 r:0.7295
Current avg r:0.6099 Best avg r: 0.6251
21:40:24,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:42,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:13,518 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3328
en_de Dev loss: 0.8542 r:0.2444
en_zh Dev loss: 0.7678 r:0.4430
ro_en Dev loss: 0.3522 r:0.8146
et_en Dev loss: 0.4182 r:0.6742
si_en Dev loss: 0.7994 r:0.5837
ne_en Dev loss: 0.5494 r:0.7265
ru_en Dev loss: 0.5175 r:0.7069
Current avg r:0.5990 Best avg r: 0.6251
21:47:06,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:24,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:55,597 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3842
en_de Dev loss: 0.8498 r:0.2365
en_zh Dev loss: 0.7631 r:0.4575
ro_en Dev loss: 0.3368 r:0.8155
et_en Dev loss: 0.4279 r:0.6771
si_en Dev loss: 0.7816 r:0.5741
ne_en Dev loss: 0.6409 r:0.7331
ru_en Dev loss: 0.4495 r:0.7289
Current avg r:0.6032 Best avg r: 0.6251
21:53:48,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:06,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:37,677 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3552
en_de Dev loss: 0.8316 r:0.2553
en_zh Dev loss: 0.7507 r:0.4495
ro_en Dev loss: 0.3245 r:0.8186
et_en Dev loss: 0.4156 r:0.6870
si_en Dev loss: 0.7361 r:0.5795
ne_en Dev loss: 0.6745 r:0.7262
ru_en Dev loss: 0.4501 r:0.7242
Current avg r:0.6058 Best avg r: 0.6251
22:00:30,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:43,947 root INFO 
id:en_de cur r: 0.2998 best r: 0.2998
22:01:48,830 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:19,789 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3671
en_de Dev loss: 0.8618 r:0.2775
en_zh Dev loss: 0.8533 r:0.4271
ro_en Dev loss: 0.3795 r:0.8012
et_en Dev loss: 0.4381 r:0.6686
si_en Dev loss: 0.9018 r:0.5560
ne_en Dev loss: 0.5583 r:0.7186
ru_en Dev loss: 0.5095 r:0.7148
Current avg r:0.5948 Best avg r: 0.6251
22:07:12,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:30,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:01,302 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3398
en_de Dev loss: 0.8459 r:0.2511
en_zh Dev loss: 0.7289 r:0.4663
ro_en Dev loss: 0.3134 r:0.8227
et_en Dev loss: 0.4245 r:0.6828
si_en Dev loss: 0.6222 r:0.6058
ne_en Dev loss: 0.7225 r:0.7394
ru_en Dev loss: 0.4125 r:0.7462
Current avg r:0.6163 Best avg r: 0.6251
22:13:54,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:12,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:16:42,919 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3535
en_de Dev loss: 0.8397 r:0.2529
en_zh Dev loss: 0.7597 r:0.4408
ro_en Dev loss: 0.3117 r:0.8233
et_en Dev loss: 0.4135 r:0.6719
si_en Dev loss: 0.7373 r:0.5821
ne_en Dev loss: 0.5986 r:0.7272
ru_en Dev loss: 0.4408 r:0.7226
Current avg r:0.6030 Best avg r: 0.6251
22:20:36,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:53,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:24,704 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3607
en_de Dev loss: 0.8410 r:0.2563
en_zh Dev loss: 0.7757 r:0.4500
ro_en Dev loss: 0.3239 r:0.8245
et_en Dev loss: 0.4274 r:0.6826
si_en Dev loss: 0.6827 r:0.5917
ne_en Dev loss: 0.7036 r:0.7315
ru_en Dev loss: 0.4569 r:0.7281
Current avg r:0.6092 Best avg r: 0.6251
22:27:17,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:35,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:06,371 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3225
en_de Dev loss: 0.8247 r:0.2752
en_zh Dev loss: 0.7552 r:0.4583
ro_en Dev loss: 0.3234 r:0.8223
et_en Dev loss: 0.4460 r:0.6901
si_en Dev loss: 0.6383 r:0.5996
ne_en Dev loss: 0.8506 r:0.7295
ru_en Dev loss: 0.4366 r:0.7290
Current avg r:0.6149 Best avg r: 0.6251
22:33:59,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:16,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:47,595 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3179
en_de Dev loss: 0.8261 r:0.2756
en_zh Dev loss: 0.7297 r:0.4618
ro_en Dev loss: 0.3133 r:0.8217
et_en Dev loss: 0.4349 r:0.6855
si_en Dev loss: 0.6445 r:0.5951
ne_en Dev loss: 0.7866 r:0.7334
ru_en Dev loss: 0.4006 r:0.7392
Current avg r:0.6160 Best avg r: 0.6251
22:40:40,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:58,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:43:28,737 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3367
en_de Dev loss: 0.8195 r:0.2768
en_zh Dev loss: 0.7454 r:0.4613
ro_en Dev loss: 0.3219 r:0.8243
et_en Dev loss: 0.4613 r:0.6876
si_en Dev loss: 0.6978 r:0.5893
ne_en Dev loss: 0.8026 r:0.7300
ru_en Dev loss: 0.4065 r:0.7387
Current avg r:0.6154 Best avg r: 0.6251
22:47:21,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:39,148 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:09,901 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3406
en_de Dev loss: 0.8571 r:0.2631
en_zh Dev loss: 0.8394 r:0.4361
ro_en Dev loss: 0.3753 r:0.8167
et_en Dev loss: 0.4269 r:0.6836
si_en Dev loss: 0.8045 r:0.5848
ne_en Dev loss: 0.5914 r:0.7143
ru_en Dev loss: 0.5552 r:0.7000
Current avg r:0.5998 Best avg r: 0.6251
22:54:02,683 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:20,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:51,285 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3396
en_de Dev loss: 0.8582 r:0.2313
en_zh Dev loss: 0.7910 r:0.4496
ro_en Dev loss: 0.3554 r:0.8202
et_en Dev loss: 0.4163 r:0.6787
si_en Dev loss: 0.8138 r:0.5871
ne_en Dev loss: 0.5286 r:0.7134
ru_en Dev loss: 0.5278 r:0.7090
Current avg r:0.5985 Best avg r: 0.6251
23:00:44,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:02,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:32,889 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3243
en_de Dev loss: 0.8425 r:0.2425
en_zh Dev loss: 0.7451 r:0.4554
ro_en Dev loss: 0.3250 r:0.8197
et_en Dev loss: 0.4238 r:0.6833
si_en Dev loss: 0.7256 r:0.5906
ne_en Dev loss: 0.6604 r:0.7193
ru_en Dev loss: 0.4639 r:0.7193
Current avg r:0.6043 Best avg r: 0.6251
23:07:25,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:43,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:14,542 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3638
en_de Dev loss: 0.8818 r:0.1732
en_zh Dev loss: 0.7787 r:0.4438
ro_en Dev loss: 0.3699 r:0.8114
et_en Dev loss: 0.4191 r:0.6786
si_en Dev loss: 0.7961 r:0.5730
ne_en Dev loss: 0.6141 r:0.7072
ru_en Dev loss: 0.4980 r:0.7018
Current avg r:0.5841 Best avg r: 0.6251
23:14:07,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:24,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:55,549 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3269
en_de Dev loss: 0.8336 r:0.2780
en_zh Dev loss: 0.7940 r:0.4416
ro_en Dev loss: 0.3547 r:0.8176
et_en Dev loss: 0.4308 r:0.6790
si_en Dev loss: 0.7412 r:0.5841
ne_en Dev loss: 0.6685 r:0.7150
ru_en Dev loss: 0.4671 r:0.7275
Current avg r:0.6061 Best avg r: 0.6251
23:20:49,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:07,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:38,340 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2976
en_de Dev loss: 0.8478 r:0.2702
en_zh Dev loss: 0.7622 r:0.4552
ro_en Dev loss: 0.3685 r:0.8200
et_en Dev loss: 0.4510 r:0.6779
si_en Dev loss: 0.7827 r:0.5774
ne_en Dev loss: 0.6866 r:0.7145
ru_en Dev loss: 0.4993 r:0.7219
Current avg r:0.6053 Best avg r: 0.6251
23:27:31,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:49,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:20,223 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2968
en_de Dev loss: 0.8333 r:0.2792
en_zh Dev loss: 0.7571 r:0.4585
ro_en Dev loss: 0.3520 r:0.8205
et_en Dev loss: 0.4571 r:0.6816
si_en Dev loss: 0.7771 r:0.5770
ne_en Dev loss: 0.7530 r:0.7164
ru_en Dev loss: 0.4622 r:0.7298
Current avg r:0.6090 Best avg r: 0.6251
23:34:13,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:30,962 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:01,701 root INFO Epoch 5 Global steps: 46800 Train loss: 0.3116
en_de Dev loss: 0.8259 r:0.2665
en_zh Dev loss: 0.7506 r:0.4541
ro_en Dev loss: 0.3293 r:0.8225
et_en Dev loss: 0.4275 r:0.6851
si_en Dev loss: 0.7077 r:0.5923
ne_en Dev loss: 0.7301 r:0.7197
ru_en Dev loss: 0.4270 r:0.7363
Current avg r:0.6109 Best avg r: 0.6251
23:40:54,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:12,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:43,423 root INFO Epoch 5 Global steps: 47400 Train loss: 0.3016
en_de Dev loss: 0.8457 r:0.2700
en_zh Dev loss: 0.7777 r:0.4501
ro_en Dev loss: 0.3610 r:0.8172
et_en Dev loss: 0.4273 r:0.6762
si_en Dev loss: 0.7983 r:0.5778
ne_en Dev loss: 0.6267 r:0.7141
ru_en Dev loss: 0.5011 r:0.7147
Current avg r:0.6029 Best avg r: 0.6251
23:47:36,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:54,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:24,844 root INFO Epoch 5 Global steps: 48000 Train loss: 0.3098
en_de Dev loss: 0.8480 r:0.2702
en_zh Dev loss: 0.8061 r:0.4305
ro_en Dev loss: 0.3601 r:0.8174
et_en Dev loss: 0.4382 r:0.6758
si_en Dev loss: 0.8473 r:0.5671
ne_en Dev loss: 0.7107 r:0.7064
ru_en Dev loss: 0.4986 r:0.7091
Current avg r:0.5966 Best avg r: 0.6251
23:54:17,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:56,448 root INFO 
id:ro_en cur r: 0.8302 best r: 0.8302
23:55:35,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:06,238 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2998
en_de Dev loss: 0.8313 r:0.2552
en_zh Dev loss: 0.7683 r:0.4406
ro_en Dev loss: 0.3231 r:0.8267
et_en Dev loss: 0.4086 r:0.6839
si_en Dev loss: 0.7143 r:0.5889
ne_en Dev loss: 0.6380 r:0.7126
ru_en Dev loss: 0.4641 r:0.7256
Current avg r:0.6048 Best avg r: 0.6251
00:00:59,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:17,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:48,9 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2870
en_de Dev loss: 0.8626 r:0.2565
en_zh Dev loss: 0.8024 r:0.4454
ro_en Dev loss: 0.3684 r:0.8175
et_en Dev loss: 0.4251 r:0.6722
si_en Dev loss: 0.7810 r:0.5797
ne_en Dev loss: 0.5742 r:0.7149
ru_en Dev loss: 0.5328 r:0.7047
Current avg r:0.5987 Best avg r: 0.6251
00:07:41,245 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:08:59,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:29,935 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2855
en_de Dev loss: 0.8365 r:0.2603
en_zh Dev loss: 0.7724 r:0.4548
ro_en Dev loss: 0.3526 r:0.8194
et_en Dev loss: 0.4303 r:0.6787
si_en Dev loss: 0.7991 r:0.5799
ne_en Dev loss: 0.6203 r:0.7244
ru_en Dev loss: 0.4845 r:0.7311
Current avg r:0.6069 Best avg r: 0.6251
00:14:23,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:15:40,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:17:11,789 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2840
en_de Dev loss: 0.8525 r:0.2502
en_zh Dev loss: 0.8111 r:0.4489
ro_en Dev loss: 0.3530 r:0.8189
et_en Dev loss: 0.4425 r:0.6763
si_en Dev loss: 0.8283 r:0.5749
ne_en Dev loss: 0.6541 r:0.7232
ru_en Dev loss: 0.5159 r:0.7221
Current avg r:0.6021 Best avg r: 0.6251
00:21:04,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:22,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:53,478 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2799
en_de Dev loss: 0.8675 r:0.2302
en_zh Dev loss: 0.8121 r:0.4462
ro_en Dev loss: 0.3501 r:0.8172
et_en Dev loss: 0.4411 r:0.6679
si_en Dev loss: 0.8524 r:0.5632
ne_en Dev loss: 0.6334 r:0.7161
ru_en Dev loss: 0.5330 r:0.7133
Current avg r:0.5934 Best avg r: 0.6251
00:27:46,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:04,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:34,835 root INFO Epoch 5 Global steps: 51600 Train loss: 0.3010
en_de Dev loss: 0.8439 r:0.2545
en_zh Dev loss: 0.7649 r:0.4586
ro_en Dev loss: 0.3334 r:0.8220
et_en Dev loss: 0.4402 r:0.6824
si_en Dev loss: 0.7540 r:0.5854
ne_en Dev loss: 0.6634 r:0.7284
ru_en Dev loss: 0.4690 r:0.7396
Current avg r:0.6101 Best avg r: 0.6251
00:34:27,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:45,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:16,555 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2970
en_de Dev loss: 0.8615 r:0.2433
en_zh Dev loss: 0.7868 r:0.4504
ro_en Dev loss: 0.3305 r:0.8238
et_en Dev loss: 0.4249 r:0.6831
si_en Dev loss: 0.7552 r:0.5775
ne_en Dev loss: 0.6630 r:0.7233
ru_en Dev loss: 0.4788 r:0.7304
Current avg r:0.6045 Best avg r: 0.6251
00:41:09,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:27,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:58,40 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2701
en_de Dev loss: 0.8261 r:0.2706
en_zh Dev loss: 0.7895 r:0.4418
ro_en Dev loss: 0.3394 r:0.8202
et_en Dev loss: 0.4945 r:0.6757
si_en Dev loss: 0.7272 r:0.5781
ne_en Dev loss: 0.9377 r:0.7221
ru_en Dev loss: 0.4379 r:0.7366
Current avg r:0.6065 Best avg r: 0.6251
00:47:51,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:04,9 root INFO 
id:en_de cur r: 0.3081 best r: 0.3081
00:49:08,815 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:39,567 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2884
en_de Dev loss: 0.8342 r:0.2917
en_zh Dev loss: 0.7785 r:0.4461
ro_en Dev loss: 0.3413 r:0.8177
et_en Dev loss: 0.4310 r:0.6638
si_en Dev loss: 0.8761 r:0.5524
ne_en Dev loss: 0.5919 r:0.7187
ru_en Dev loss: 0.4873 r:0.7230
Current avg r:0.6019 Best avg r: 0.6251
00:54:32,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:50,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:20,984 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2897
en_de Dev loss: 0.8528 r:0.2396
en_zh Dev loss: 0.7960 r:0.4289
ro_en Dev loss: 0.3454 r:0.8216
et_en Dev loss: 0.4645 r:0.6741
si_en Dev loss: 0.7600 r:0.5731
ne_en Dev loss: 0.7512 r:0.7224
ru_en Dev loss: 0.4560 r:0.7307
Current avg r:0.5986 Best avg r: 0.6251
01:01:14,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:02:32,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:03,144 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2572
en_de Dev loss: 0.8643 r:0.2088
en_zh Dev loss: 0.8264 r:0.4328
ro_en Dev loss: 0.3677 r:0.8155
et_en Dev loss: 0.4711 r:0.6633
si_en Dev loss: 0.8402 r:0.5639
ne_en Dev loss: 0.7114 r:0.7188
ru_en Dev loss: 0.4536 r:0.7325
Current avg r:0.5908 Best avg r: 0.6251
01:07:55,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:13,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:44,266 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2606
en_de Dev loss: 0.8774 r:0.2058
en_zh Dev loss: 0.8388 r:0.4261
ro_en Dev loss: 0.3691 r:0.8151
et_en Dev loss: 0.4713 r:0.6629
si_en Dev loss: 0.8173 r:0.5648
ne_en Dev loss: 0.7423 r:0.7158
ru_en Dev loss: 0.4735 r:0.7305
Current avg r:0.5887 Best avg r: 0.6251
01:14:37,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:55,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:25,856 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2432
en_de Dev loss: 0.8661 r:0.2166
en_zh Dev loss: 0.7989 r:0.4368
ro_en Dev loss: 0.3450 r:0.8180
et_en Dev loss: 0.4703 r:0.6676
si_en Dev loss: 0.7323 r:0.5735
ne_en Dev loss: 0.8089 r:0.7178
ru_en Dev loss: 0.4235 r:0.7449
Current avg r:0.5965 Best avg r: 0.6251
01:21:18,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:22:36,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:07,426 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2599
en_de Dev loss: 0.8374 r:0.2688
en_zh Dev loss: 0.8041 r:0.4448
ro_en Dev loss: 0.3649 r:0.8138
et_en Dev loss: 0.4687 r:0.6674
si_en Dev loss: 0.8237 r:0.5622
ne_en Dev loss: 0.7680 r:0.7165
ru_en Dev loss: 0.4517 r:0.7381
Current avg r:0.6017 Best avg r: 0.6251
01:28:00,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:18,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:48,764 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2530
en_de Dev loss: 0.8347 r:0.2562
en_zh Dev loss: 0.7657 r:0.4556
ro_en Dev loss: 0.3345 r:0.8217
et_en Dev loss: 0.4782 r:0.6713
si_en Dev loss: 0.7062 r:0.5814
ne_en Dev loss: 0.9506 r:0.7196
ru_en Dev loss: 0.4156 r:0.7397
Current avg r:0.6065 Best avg r: 0.6251
01:34:41,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:59,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:30,115 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2396
en_de Dev loss: 0.8429 r:0.2484
en_zh Dev loss: 0.7492 r:0.4605
ro_en Dev loss: 0.3213 r:0.8240
et_en Dev loss: 0.4667 r:0.6762
si_en Dev loss: 0.6939 r:0.5765
ne_en Dev loss: 0.8166 r:0.7221
ru_en Dev loss: 0.3942 r:0.7503
Current avg r:0.6083 Best avg r: 0.6251
01:41:22,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:40,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:44:11,621 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2613
en_de Dev loss: 0.8481 r:0.2414
en_zh Dev loss: 0.7676 r:0.4575
ro_en Dev loss: 0.3342 r:0.8225
et_en Dev loss: 0.4974 r:0.6711
si_en Dev loss: 0.7023 r:0.5771
ne_en Dev loss: 0.9294 r:0.7209
ru_en Dev loss: 0.4202 r:0.7386
Current avg r:0.6041 Best avg r: 0.6251
01:48:04,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:49:22,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:50:53,247 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2487
en_de Dev loss: 0.8705 r:0.2400
en_zh Dev loss: 0.8102 r:0.4542
ro_en Dev loss: 0.3552 r:0.8200
et_en Dev loss: 0.4992 r:0.6683
si_en Dev loss: 0.7424 r:0.5750
ne_en Dev loss: 0.9042 r:0.7100
ru_en Dev loss: 0.4534 r:0.7344
Current avg r:0.6003 Best avg r: 0.6251
01:54:46,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:56:04,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:57:35,97 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2419
en_de Dev loss: 0.8539 r:0.2344
en_zh Dev loss: 0.7663 r:0.4639
ro_en Dev loss: 0.3304 r:0.8177
et_en Dev loss: 0.4499 r:0.6671
si_en Dev loss: 0.7883 r:0.5676
ne_en Dev loss: 0.6672 r:0.7137
ru_en Dev loss: 0.4423 r:0.7323
Current avg r:0.5995 Best avg r: 0.6251
02:01:28,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:02:46,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:04:16,866 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2476
en_de Dev loss: 0.8748 r:0.2230
en_zh Dev loss: 0.8101 r:0.4526
ro_en Dev loss: 0.3690 r:0.8192
et_en Dev loss: 0.4659 r:0.6571
si_en Dev loss: 0.9415 r:0.5496
ne_en Dev loss: 0.5887 r:0.7046
ru_en Dev loss: 0.5329 r:0.7165
Current avg r:0.5889 Best avg r: 0.6251
02:08:09,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:09:27,812 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:58,646 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2521
en_de Dev loss: 0.8877 r:0.2239
en_zh Dev loss: 0.7696 r:0.4666
ro_en Dev loss: 0.3312 r:0.8202
et_en Dev loss: 0.4813 r:0.6701
si_en Dev loss: 0.7332 r:0.5726
ne_en Dev loss: 0.7694 r:0.7200
ru_en Dev loss: 0.4395 r:0.7453
Current avg r:0.6027 Best avg r: 0.6251
02:14:51,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:09,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:17:40,555 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2555
en_de Dev loss: 0.8778 r:0.2250
en_zh Dev loss: 0.8010 r:0.4590
ro_en Dev loss: 0.3384 r:0.8263
et_en Dev loss: 0.4341 r:0.6700
si_en Dev loss: 0.8390 r:0.5759
ne_en Dev loss: 0.5497 r:0.7172
ru_en Dev loss: 0.5133 r:0.7298
Current avg r:0.6005 Best avg r: 0.6251
02:21:33,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:22:51,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:24:22,411 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2408
en_de Dev loss: 0.8763 r:0.2328
en_zh Dev loss: 0.7501 r:0.4676
ro_en Dev loss: 0.3132 r:0.8281
et_en Dev loss: 0.4430 r:0.6715
si_en Dev loss: 0.6923 r:0.5810
ne_en Dev loss: 0.7160 r:0.7191
ru_en Dev loss: 0.4600 r:0.7333
Current avg r:0.6048 Best avg r: 0.6251
02:28:15,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:33,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:31:03,765 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2318
en_de Dev loss: 0.8707 r:0.2302
en_zh Dev loss: 0.7901 r:0.4560
ro_en Dev loss: 0.3508 r:0.8208
et_en Dev loss: 0.5308 r:0.6663
si_en Dev loss: 0.7561 r:0.5686
ne_en Dev loss: 0.9447 r:0.7153
ru_en Dev loss: 0.4399 r:0.7341
Current avg r:0.5988 Best avg r: 0.6251
02:34:56,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:14,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:37:45,48 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2419
en_de Dev loss: 0.8631 r:0.2410
en_zh Dev loss: 0.7905 r:0.4581
ro_en Dev loss: 0.3593 r:0.8216
et_en Dev loss: 0.4631 r:0.6652
si_en Dev loss: 0.8950 r:0.5572
ne_en Dev loss: 0.6668 r:0.7104
ru_en Dev loss: 0.5224 r:0.7164
Current avg r:0.5957 Best avg r: 0.6251
02:41:38,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:42:56,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:27,465 root INFO Epoch 7 Global steps: 63600 Train loss: 0.2201
en_de Dev loss: 0.8713 r:0.2273
en_zh Dev loss: 0.7679 r:0.4694
ro_en Dev loss: 0.3314 r:0.8234
et_en Dev loss: 0.4565 r:0.6684
si_en Dev loss: 0.8628 r:0.5582
ne_en Dev loss: 0.7020 r:0.7196
ru_en Dev loss: 0.4236 r:0.7464
Current avg r:0.6018 Best avg r: 0.6251
02:48:20,553 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:49:38,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:09,35 root INFO Epoch 7 Global steps: 64200 Train loss: 0.2234
en_de Dev loss: 0.8566 r:0.2398
en_zh Dev loss: 0.7709 r:0.4733
ro_en Dev loss: 0.3194 r:0.8249
et_en Dev loss: 0.4798 r:0.6685
si_en Dev loss: 0.7701 r:0.5633
ne_en Dev loss: 0.8083 r:0.7209
ru_en Dev loss: 0.4254 r:0.7370
Current avg r:0.6039 Best avg r: 0.6251
02:55:02,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:19,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:57:50,657 root INFO Epoch 7 Global steps: 64800 Train loss: 0.2291
en_de Dev loss: 0.9011 r:0.1958
en_zh Dev loss: 0.7618 r:0.4592
ro_en Dev loss: 0.3393 r:0.8195
et_en Dev loss: 0.4571 r:0.6607
si_en Dev loss: 0.8575 r:0.5535
ne_en Dev loss: 0.6404 r:0.7149
ru_en Dev loss: 0.4488 r:0.7404
Current avg r:0.5920 Best avg r: 0.6251
03:01:43,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:01,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:32,382 root INFO Epoch 7 Global steps: 65400 Train loss: 0.2026
en_de Dev loss: 0.9009 r:0.1967
en_zh Dev loss: 0.7871 r:0.4561
ro_en Dev loss: 0.3350 r:0.8249
et_en Dev loss: 0.4702 r:0.6676
si_en Dev loss: 0.7940 r:0.5690
ne_en Dev loss: 0.7220 r:0.7204
ru_en Dev loss: 0.4367 r:0.7426
Current avg r:0.5968 Best avg r: 0.6251
03:08:25,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:43,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:14,147 root INFO Epoch 7 Global steps: 66000 Train loss: 0.2184
en_de Dev loss: 0.8810 r:0.2010
en_zh Dev loss: 0.7960 r:0.4479
ro_en Dev loss: 0.3517 r:0.8176
et_en Dev loss: 0.4620 r:0.6655
si_en Dev loss: 0.8327 r:0.5580
ne_en Dev loss: 0.7117 r:0.7083
ru_en Dev loss: 0.4756 r:0.7220
Current avg r:0.5886 Best avg r: 0.6251
03:15:07,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:16:25,122 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:17:55,968 root INFO Epoch 7 Global steps: 66600 Train loss: 0.2033
en_de Dev loss: 0.8743 r:0.2168
en_zh Dev loss: 0.8044 r:0.4503
ro_en Dev loss: 0.3550 r:0.8170
et_en Dev loss: 0.4953 r:0.6590
si_en Dev loss: 0.7853 r:0.5659
ne_en Dev loss: 0.8534 r:0.7128
ru_en Dev loss: 0.4407 r:0.7335
Current avg r:0.5936 Best avg r: 0.6251
03:21:48,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:23:06,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:24:37,582 root INFO Epoch 7 Global steps: 67200 Train loss: 0.2181
en_de Dev loss: 0.8763 r:0.2297
en_zh Dev loss: 0.8141 r:0.4438
ro_en Dev loss: 0.3704 r:0.8145
et_en Dev loss: 0.4830 r:0.6564
si_en Dev loss: 0.8975 r:0.5519
ne_en Dev loss: 0.7092 r:0.7067
ru_en Dev loss: 0.4734 r:0.7226
Current avg r:0.5894 Best avg r: 0.6251
03:28:30,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:48,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:18,931 root INFO Epoch 7 Global steps: 67800 Train loss: 0.2154
en_de Dev loss: 0.8518 r:0.2489
en_zh Dev loss: 0.7880 r:0.4454
ro_en Dev loss: 0.3401 r:0.8167
et_en Dev loss: 0.4748 r:0.6573
si_en Dev loss: 0.7923 r:0.5525
ne_en Dev loss: 0.7602 r:0.7103
ru_en Dev loss: 0.4259 r:0.7356
Current avg r:0.5953 Best avg r: 0.6251
03:35:12,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:29,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:00,635 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2129
en_de Dev loss: 0.8735 r:0.2344
en_zh Dev loss: 0.8141 r:0.4425
ro_en Dev loss: 0.3600 r:0.8170
et_en Dev loss: 0.4724 r:0.6519
si_en Dev loss: 0.8648 r:0.5491
ne_en Dev loss: 0.6340 r:0.7036
ru_en Dev loss: 0.5023 r:0.7171
Current avg r:0.5880 Best avg r: 0.6251
03:41:53,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:11,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:44:42,373 root INFO Epoch 7 Global steps: 69000 Train loss: 0.2198
en_de Dev loss: 0.8695 r:0.2105
en_zh Dev loss: 0.8032 r:0.4440
ro_en Dev loss: 0.3390 r:0.8207
et_en Dev loss: 0.4957 r:0.6605
si_en Dev loss: 0.7978 r:0.5575
ne_en Dev loss: 0.8401 r:0.7111
ru_en Dev loss: 0.4437 r:0.7300
Current avg r:0.5906 Best avg r: 0.6251
03:48:35,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:49:53,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:51:24,338 root INFO Epoch 7 Global steps: 69600 Train loss: 0.2202
en_de Dev loss: 0.8706 r:0.2273
en_zh Dev loss: 0.8264 r:0.4350
ro_en Dev loss: 0.3531 r:0.8171
et_en Dev loss: 0.4709 r:0.6594
si_en Dev loss: 0.8286 r:0.5480
ne_en Dev loss: 0.7224 r:0.7014
ru_en Dev loss: 0.4805 r:0.7242
Current avg r:0.5875 Best avg r: 0.6251
03:55:17,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:55:56,255 root INFO 
id:ro_en cur r: 0.8337 best r: 0.8337
03:56:35,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:58:05,913 root INFO Epoch 7 Global steps: 70200 Train loss: 0.2047
en_de Dev loss: 0.8837 r:0.2423
en_zh Dev loss: 0.8220 r:0.4492
ro_en Dev loss: 0.3265 r:0.8282
et_en Dev loss: 0.4697 r:0.6681
si_en Dev loss: 0.8000 r:0.5588
ne_en Dev loss: 0.7729 r:0.7182
ru_en Dev loss: 0.4431 r:0.7469
Current avg r:0.6017 Best avg r: 0.6251
04:01:59,183 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:03:16,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:47,815 root INFO Epoch 7 Global steps: 70800 Train loss: 0.2209
en_de Dev loss: 0.8809 r:0.2120
en_zh Dev loss: 0.7706 r:0.4496
ro_en Dev loss: 0.3216 r:0.8211
et_en Dev loss: 0.4577 r:0.6646
si_en Dev loss: 0.7276 r:0.5667
ne_en Dev loss: 0.7693 r:0.7225
ru_en Dev loss: 0.4342 r:0.7377
Current avg r:0.5963 Best avg r: 0.6251
04:08:40,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:09:58,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:11:29,671 root INFO Epoch 7 Global steps: 71400 Train loss: 0.2196
en_de Dev loss: 0.8834 r:0.2183
en_zh Dev loss: 0.8003 r:0.4485
ro_en Dev loss: 0.3404 r:0.8202
et_en Dev loss: 0.4692 r:0.6579
si_en Dev loss: 0.8269 r:0.5527
ne_en Dev loss: 0.6595 r:0.7206
ru_en Dev loss: 0.4450 r:0.7444
Current avg r:0.5947 Best avg r: 0.6251
04:15:22,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:16:40,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:18:11,514 root INFO Epoch 7 Global steps: 72000 Train loss: 0.2018
en_de Dev loss: 0.8994 r:0.1940
en_zh Dev loss: 0.8092 r:0.4499
ro_en Dev loss: 0.3771 r:0.8154
et_en Dev loss: 0.4832 r:0.6462
si_en Dev loss: 0.9100 r:0.5479
ne_en Dev loss: 0.6385 r:0.7157
ru_en Dev loss: 0.4449 r:0.7434
Current avg r:0.5875 Best avg r: 0.6251
04:22:05,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:23:23,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:24:53,817 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1805
en_de Dev loss: 0.8978 r:0.1901
en_zh Dev loss: 0.8071 r:0.4531
ro_en Dev loss: 0.3684 r:0.8160
et_en Dev loss: 0.5060 r:0.6485
si_en Dev loss: 0.8908 r:0.5460
ne_en Dev loss: 0.7413 r:0.7118
ru_en Dev loss: 0.4495 r:0.7413
Current avg r:0.5867 Best avg r: 0.6251
04:28:46,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:04,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:34,979 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1893
en_de Dev loss: 0.9162 r:0.1838
en_zh Dev loss: 0.8763 r:0.4342
ro_en Dev loss: 0.4068 r:0.8144
et_en Dev loss: 0.5002 r:0.6407
si_en Dev loss: 0.9581 r:0.5331
ne_en Dev loss: 0.6327 r:0.6988
ru_en Dev loss: 0.5236 r:0.7207
Current avg r:0.5751 Best avg r: 0.6251
04:35:27,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:45,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:16,391 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1881
en_de Dev loss: 0.9049 r:0.2150
en_zh Dev loss: 0.8291 r:0.4492
ro_en Dev loss: 0.3742 r:0.8159
et_en Dev loss: 0.4824 r:0.6516
si_en Dev loss: 0.9229 r:0.5423
ne_en Dev loss: 0.6245 r:0.7127
ru_en Dev loss: 0.4875 r:0.7314
Current avg r:0.5883 Best avg r: 0.6251
04:42:09,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:27,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:57,957 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1906
en_de Dev loss: 0.9050 r:0.1955
en_zh Dev loss: 0.8505 r:0.4398
ro_en Dev loss: 0.3523 r:0.8195
et_en Dev loss: 0.4707 r:0.6476
si_en Dev loss: 0.8575 r:0.5462
ne_en Dev loss: 0.6337 r:0.7012
ru_en Dev loss: 0.5015 r:0.7240
Current avg r:0.5820 Best avg r: 0.6251
04:48:51,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:08,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:39,648 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1911
en_de Dev loss: 0.8954 r:0.2035
en_zh Dev loss: 0.8106 r:0.4538
ro_en Dev loss: 0.3740 r:0.8195
et_en Dev loss: 0.5134 r:0.6541
si_en Dev loss: 0.8542 r:0.5568
ne_en Dev loss: 0.7401 r:0.7060
ru_en Dev loss: 0.4563 r:0.7381
Current avg r:0.5902 Best avg r: 0.6251
04:55:32,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:56:50,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:20,881 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1819
en_de Dev loss: 0.9135 r:0.2037
en_zh Dev loss: 0.8183 r:0.4472
ro_en Dev loss: 0.3856 r:0.8171
et_en Dev loss: 0.5183 r:0.6465
si_en Dev loss: 0.9052 r:0.5506
ne_en Dev loss: 0.7349 r:0.7006
ru_en Dev loss: 0.4734 r:0.7359
Current avg r:0.5860 Best avg r: 0.6251
05:02:13,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:31,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:05:02,197 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1857
en_de Dev loss: 0.8906 r:0.2168
en_zh Dev loss: 0.7990 r:0.4514
ro_en Dev loss: 0.3550 r:0.8226
et_en Dev loss: 0.4919 r:0.6606
si_en Dev loss: 0.7928 r:0.5604
ne_en Dev loss: 0.7297 r:0.7028
ru_en Dev loss: 0.4715 r:0.7354
Current avg r:0.5928 Best avg r: 0.6251
05:08:55,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:13,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:43,834 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1796
en_de Dev loss: 0.8909 r:0.2071
en_zh Dev loss: 0.7578 r:0.4488
ro_en Dev loss: 0.3276 r:0.8245
et_en Dev loss: 0.5130 r:0.6569
si_en Dev loss: 0.7738 r:0.5595
ne_en Dev loss: 0.7785 r:0.7036
ru_en Dev loss: 0.4272 r:0.7409
Current avg r:0.5916 Best avg r: 0.6251
05:15:36,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:16:54,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:25,707 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1898
en_de Dev loss: 0.8874 r:0.2143
en_zh Dev loss: 0.7991 r:0.4428
ro_en Dev loss: 0.3356 r:0.8253
et_en Dev loss: 0.5223 r:0.6629
si_en Dev loss: 0.7604 r:0.5610
ne_en Dev loss: 0.8872 r:0.6979
ru_en Dev loss: 0.4497 r:0.7335
Current avg r:0.5911 Best avg r: 0.6251
05:22:18,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:23:36,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:06,827 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1863
en_de Dev loss: 0.8966 r:0.1992
en_zh Dev loss: 0.8108 r:0.4393
ro_en Dev loss: 0.3680 r:0.8173
et_en Dev loss: 0.4812 r:0.6455
si_en Dev loss: 0.8539 r:0.5465
ne_en Dev loss: 0.6713 r:0.6965
ru_en Dev loss: 0.5147 r:0.7122
Current avg r:0.5795 Best avg r: 0.6251
05:28:59,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:17,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:48,426 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1904
en_de Dev loss: 0.8961 r:0.2114
en_zh Dev loss: 0.8191 r:0.4476
ro_en Dev loss: 0.3400 r:0.8231
et_en Dev loss: 0.5108 r:0.6640
si_en Dev loss: 0.7581 r:0.5597
ne_en Dev loss: 0.8325 r:0.7091
ru_en Dev loss: 0.4584 r:0.7342
Current avg r:0.5927 Best avg r: 0.6251
05:35:41,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:59,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:30,21 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1810
en_de Dev loss: 0.8936 r:0.2114
en_zh Dev loss: 0.8145 r:0.4521
ro_en Dev loss: 0.3693 r:0.8172
et_en Dev loss: 0.4640 r:0.6543
si_en Dev loss: 0.9225 r:0.5394
ne_en Dev loss: 0.6004 r:0.6961
ru_en Dev loss: 0.4960 r:0.7256
Current avg r:0.5851 Best avg r: 0.6251
05:42:23,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:41,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:11,837 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1848
en_de Dev loss: 0.8813 r:0.1809
en_zh Dev loss: 0.7680 r:0.4566
ro_en Dev loss: 0.3229 r:0.8215
et_en Dev loss: 0.4526 r:0.6607
si_en Dev loss: 0.7762 r:0.5539
ne_en Dev loss: 0.7247 r:0.7008
ru_en Dev loss: 0.4174 r:0.7415
Current avg r:0.5880 Best avg r: 0.6251
05:49:04,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:50:22,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:51:53,618 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1919
en_de Dev loss: 0.8878 r:0.2039
en_zh Dev loss: 0.7795 r:0.4503
ro_en Dev loss: 0.3241 r:0.8194
et_en Dev loss: 0.4720 r:0.6662
si_en Dev loss: 0.7475 r:0.5528
ne_en Dev loss: 0.7662 r:0.7057
ru_en Dev loss: 0.4433 r:0.7341
Current avg r:0.5903 Best avg r: 0.6251
05:55:46,613 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:57:04,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:58:35,256 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1779
en_de Dev loss: 0.9102 r:0.1947
en_zh Dev loss: 0.8371 r:0.4401
ro_en Dev loss: 0.3590 r:0.8190
et_en Dev loss: 0.4693 r:0.6662
si_en Dev loss: 0.8058 r:0.5528
ne_en Dev loss: 0.7102 r:0.7077
ru_en Dev loss: 0.4643 r:0.7365
Current avg r:0.5882 Best avg r: 0.6251
06:02:29,398 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:47,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:18,94 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1692
en_de Dev loss: 0.8981 r:0.1893
en_zh Dev loss: 0.7784 r:0.4544
ro_en Dev loss: 0.3263 r:0.8229
et_en Dev loss: 0.4550 r:0.6669
si_en Dev loss: 0.7701 r:0.5515
ne_en Dev loss: 0.7217 r:0.7056
ru_en Dev loss: 0.4426 r:0.7384
Current avg r:0.5899 Best avg r: 0.6251
06:09:11,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:10:29,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:12:00,6 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1660
en_de Dev loss: 0.8971 r:0.2030
en_zh Dev loss: 0.8209 r:0.4408
ro_en Dev loss: 0.3753 r:0.8142
et_en Dev loss: 0.4683 r:0.6519
si_en Dev loss: 0.9460 r:0.5340
ne_en Dev loss: 0.6276 r:0.6922
ru_en Dev loss: 0.4807 r:0.7263
Current avg r:0.5804 Best avg r: 0.6251
06:15:53,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:11,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:41,867 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1665
en_de Dev loss: 0.9294 r:0.1792
en_zh Dev loss: 0.8962 r:0.4268
ro_en Dev loss: 0.3912 r:0.8135
et_en Dev loss: 0.4938 r:0.6544
si_en Dev loss: 0.9072 r:0.5407
ne_en Dev loss: 0.6991 r:0.6932
ru_en Dev loss: 0.5246 r:0.7172
Current avg r:0.5750 Best avg r: 0.6251
06:22:34,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:23:52,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:25:23,446 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1636
en_de Dev loss: 0.9239 r:0.1852
en_zh Dev loss: 0.8814 r:0.4385
ro_en Dev loss: 0.3846 r:0.8157
et_en Dev loss: 0.4970 r:0.6548
si_en Dev loss: 0.9325 r:0.5395
ne_en Dev loss: 0.6906 r:0.6955
ru_en Dev loss: 0.5131 r:0.7228
Current avg r:0.5789 Best avg r: 0.6251
06:29:16,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:34,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:04,872 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1650
en_de Dev loss: 0.9079 r:0.1920
en_zh Dev loss: 0.8458 r:0.4424
ro_en Dev loss: 0.3851 r:0.8111
et_en Dev loss: 0.5044 r:0.6521
si_en Dev loss: 0.8942 r:0.5386
ne_en Dev loss: 0.8000 r:0.6916
ru_en Dev loss: 0.4833 r:0.7219
Current avg r:0.5785 Best avg r: 0.6251
06:35:57,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:15,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:38:46,505 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1721
en_de Dev loss: 0.9059 r:0.1889
en_zh Dev loss: 0.7921 r:0.4551
ro_en Dev loss: 0.3450 r:0.8197
et_en Dev loss: 0.4508 r:0.6711
si_en Dev loss: 0.7889 r:0.5570
ne_en Dev loss: 0.7211 r:0.6996
ru_en Dev loss: 0.4300 r:0.7416
Current avg r:0.5904 Best avg r: 0.6251
06:42:39,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:43:57,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:28,49 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1704
en_de Dev loss: 0.8974 r:0.1953
en_zh Dev loss: 0.7789 r:0.4584
ro_en Dev loss: 0.3445 r:0.8179
et_en Dev loss: 0.4652 r:0.6662
si_en Dev loss: 0.7985 r:0.5503
ne_en Dev loss: 0.7250 r:0.7029
ru_en Dev loss: 0.4463 r:0.7351
Current avg r:0.5894 Best avg r: 0.6251
06:49:21,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:50:38,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:52:09,731 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1654
en_de Dev loss: 0.9140 r:0.1893
en_zh Dev loss: 0.8505 r:0.4354
ro_en Dev loss: 0.3642 r:0.8138
et_en Dev loss: 0.4975 r:0.6563
si_en Dev loss: 0.8157 r:0.5483
ne_en Dev loss: 0.8435 r:0.7032
ru_en Dev loss: 0.4697 r:0.7310
Current avg r:0.5825 Best avg r: 0.6251
06:56:02,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:57:20,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:58:50,931 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1588
en_de Dev loss: 0.8880 r:0.2039
en_zh Dev loss: 0.7942 r:0.4443
ro_en Dev loss: 0.3256 r:0.8221
et_en Dev loss: 0.4555 r:0.6626
si_en Dev loss: 0.7758 r:0.5496
ne_en Dev loss: 0.6714 r:0.7070
ru_en Dev loss: 0.4684 r:0.7253
Current avg r:0.5878 Best avg r: 0.6251
07:02:43,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:04:01,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:05:32,126 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1630
en_de Dev loss: 0.8822 r:0.1989
en_zh Dev loss: 0.8018 r:0.4498
ro_en Dev loss: 0.3366 r:0.8207
et_en Dev loss: 0.4793 r:0.6572
si_en Dev loss: 0.8225 r:0.5466
ne_en Dev loss: 0.7395 r:0.6988
ru_en Dev loss: 0.4410 r:0.7315
Current avg r:0.5862 Best avg r: 0.6251
07:09:24,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:10:42,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:12:13,321 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1654
en_de Dev loss: 0.8661 r:0.2161
en_zh Dev loss: 0.7970 r:0.4403
ro_en Dev loss: 0.3484 r:0.8170
et_en Dev loss: 0.5069 r:0.6597
si_en Dev loss: 0.8364 r:0.5439
ne_en Dev loss: 0.8111 r:0.7008
ru_en Dev loss: 0.4545 r:0.7276
Current avg r:0.5865 Best avg r: 0.6251
07:16:05,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:23,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:18:54,402 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1507
en_de Dev loss: 0.8926 r:0.2010
en_zh Dev loss: 0.8686 r:0.4215
ro_en Dev loss: 0.3846 r:0.8081
et_en Dev loss: 0.4999 r:0.6476
si_en Dev loss: 0.9148 r:0.5343
ne_en Dev loss: 0.7489 r:0.6929
ru_en Dev loss: 0.4748 r:0.7271
Current avg r:0.5761 Best avg r: 0.6251
07:22:47,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:24:04,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:25:35,512 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1597
en_de Dev loss: 0.8962 r:0.2057
en_zh Dev loss: 0.8305 r:0.4422
ro_en Dev loss: 0.3605 r:0.8149
et_en Dev loss: 0.4991 r:0.6529
si_en Dev loss: 0.8589 r:0.5432
ne_en Dev loss: 0.7514 r:0.6971
ru_en Dev loss: 0.4621 r:0.7327
Current avg r:0.5841 Best avg r: 0.6251
07:29:28,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:30:46,458 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:17,203 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1547
en_de Dev loss: 0.9281 r:0.1954
en_zh Dev loss: 0.8437 r:0.4464
ro_en Dev loss: 0.4001 r:0.8104
et_en Dev loss: 0.4976 r:0.6434
si_en Dev loss: 1.0186 r:0.5284
ne_en Dev loss: 0.6063 r:0.6915
ru_en Dev loss: 0.5465 r:0.7126
Current avg r:0.5754 Best avg r: 0.6251
07:36:10,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:37:27,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:38:58,574 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1561
en_de Dev loss: 0.8892 r:0.2218
en_zh Dev loss: 0.7990 r:0.4539
ro_en Dev loss: 0.3443 r:0.8171
et_en Dev loss: 0.4763 r:0.6598
si_en Dev loss: 0.8221 r:0.5506
ne_en Dev loss: 0.7191 r:0.7023
ru_en Dev loss: 0.4703 r:0.7231
Current avg r:0.5898 Best avg r: 0.6251
07:42:52,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:44:10,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:41,49 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1365
en_de Dev loss: 0.9193 r:0.1993
en_zh Dev loss: 0.8685 r:0.4390
ro_en Dev loss: 0.3782 r:0.8178
et_en Dev loss: 0.4887 r:0.6552
si_en Dev loss: 0.8726 r:0.5480
ne_en Dev loss: 0.6492 r:0.6990
ru_en Dev loss: 0.5135 r:0.7226
Current avg r:0.5830 Best avg r: 0.6251
07:49:33,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:50:51,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:22,96 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1452
en_de Dev loss: 0.9109 r:0.1980
en_zh Dev loss: 0.8107 r:0.4497
ro_en Dev loss: 0.3548 r:0.8196
et_en Dev loss: 0.4850 r:0.6593
si_en Dev loss: 0.8494 r:0.5480
ne_en Dev loss: 0.7280 r:0.7047
ru_en Dev loss: 0.4519 r:0.7392
Current avg r:0.5884 Best avg r: 0.6251
07:56:14,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:57:32,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:59:03,578 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1400
en_de Dev loss: 0.9024 r:0.1988
en_zh Dev loss: 0.8066 r:0.4582
ro_en Dev loss: 0.3533 r:0.8197
et_en Dev loss: 0.5058 r:0.6514
si_en Dev loss: 0.8485 r:0.5411
ne_en Dev loss: 0.8073 r:0.6967
ru_en Dev loss: 0.4594 r:0.7306
Current avg r:0.5852 Best avg r: 0.6251
08:02:56,707 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:04:14,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:05:45,333 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1463
en_de Dev loss: 0.9071 r:0.1929
en_zh Dev loss: 0.8046 r:0.4581
ro_en Dev loss: 0.3414 r:0.8190
et_en Dev loss: 0.4831 r:0.6618
si_en Dev loss: 0.8109 r:0.5501
ne_en Dev loss: 0.7235 r:0.7073
ru_en Dev loss: 0.4531 r:0.7381
Current avg r:0.5896 Best avg r: 0.6251
08:09:38,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:10:56,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:12:26,842 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1547
en_de Dev loss: 0.9027 r:0.2128
en_zh Dev loss: 0.8046 r:0.4604
ro_en Dev loss: 0.3483 r:0.8227
et_en Dev loss: 0.4853 r:0.6644
si_en Dev loss: 0.8294 r:0.5474
ne_en Dev loss: 0.7636 r:0.7022
ru_en Dev loss: 0.4712 r:0.7278
Current avg r:0.5911 Best avg r: 0.6251
08:16:19,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:17:37,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:19:08,190 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1372
en_de Dev loss: 0.8865 r:0.2225
en_zh Dev loss: 0.8015 r:0.4509
ro_en Dev loss: 0.3563 r:0.8160
et_en Dev loss: 0.4809 r:0.6610
si_en Dev loss: 0.8319 r:0.5496
ne_en Dev loss: 0.7042 r:0.7050
ru_en Dev loss: 0.4723 r:0.7289
Current avg r:0.5905 Best avg r: 0.6251
08:23:00,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:24:18,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:25:49,321 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1431
en_de Dev loss: 0.8786 r:0.2355
en_zh Dev loss: 0.8017 r:0.4618
ro_en Dev loss: 0.3777 r:0.8153
et_en Dev loss: 0.4805 r:0.6475
si_en Dev loss: 0.9577 r:0.5413
ne_en Dev loss: 0.6399 r:0.7020
ru_en Dev loss: 0.4781 r:0.7262
Current avg r:0.5899 Best avg r: 0.6251
08:29:42,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:30:59,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:32:30,599 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1456
en_de Dev loss: 0.8948 r:0.2153
en_zh Dev loss: 0.8308 r:0.4436
ro_en Dev loss: 0.3671 r:0.8158
et_en Dev loss: 0.4935 r:0.6487
si_en Dev loss: 0.8785 r:0.5379
ne_en Dev loss: 0.7225 r:0.7010
ru_en Dev loss: 0.4883 r:0.7279
Current avg r:0.5843 Best avg r: 0.6251
08:36:23,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:37:41,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:39:11,754 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1419
en_de Dev loss: 0.9159 r:0.2048
en_zh Dev loss: 0.8678 r:0.4441
ro_en Dev loss: 0.4096 r:0.8127
et_en Dev loss: 0.4948 r:0.6498
si_en Dev loss: 0.9292 r:0.5338
ne_en Dev loss: 0.6587 r:0.6946
ru_en Dev loss: 0.5566 r:0.7143
Current avg r:0.5792 Best avg r: 0.6251
08:43:04,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:44:22,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:45:52,937 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1523
en_de Dev loss: 0.8889 r:0.2163
en_zh Dev loss: 0.7989 r:0.4504
ro_en Dev loss: 0.3479 r:0.8190
et_en Dev loss: 0.4940 r:0.6609
si_en Dev loss: 0.8179 r:0.5455
ne_en Dev loss: 0.7769 r:0.7067
ru_en Dev loss: 0.4877 r:0.7210
Current avg r:0.5886 Best avg r: 0.6251
08:49:45,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:51:03,800 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:52:34,602 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1412
en_de Dev loss: 0.8958 r:0.2121
en_zh Dev loss: 0.8551 r:0.4439
ro_en Dev loss: 0.4227 r:0.8046
et_en Dev loss: 0.5004 r:0.6426
si_en Dev loss: 1.0086 r:0.5239
ne_en Dev loss: 0.6642 r:0.6840
ru_en Dev loss: 0.5493 r:0.7065
Current avg r:0.5739 Best avg r: 0.6251
08:56:27,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:57:45,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:59:16,418 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1388
en_de Dev loss: 0.9220 r:0.2118
en_zh Dev loss: 0.8545 r:0.4491
ro_en Dev loss: 0.4019 r:0.8142
et_en Dev loss: 0.4974 r:0.6465
si_en Dev loss: 0.9454 r:0.5320
ne_en Dev loss: 0.7002 r:0.6937
ru_en Dev loss: 0.4919 r:0.7306
Current avg r:0.5826 Best avg r: 0.6251
09:03:09,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:04:27,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:05:58,104 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1432
en_de Dev loss: 0.8938 r:0.2067
en_zh Dev loss: 0.8148 r:0.4477
ro_en Dev loss: 0.3633 r:0.8160
et_en Dev loss: 0.4817 r:0.6521
si_en Dev loss: 0.9051 r:0.5399
ne_en Dev loss: 0.7125 r:0.6953
ru_en Dev loss: 0.4919 r:0.7182
Current avg r:0.5823 Best avg r: 0.6251
09:09:51,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:11:08,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:12:39,637 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1434
en_de Dev loss: 0.9008 r:0.2014
en_zh Dev loss: 0.8504 r:0.4450
ro_en Dev loss: 0.3871 r:0.8121
et_en Dev loss: 0.4775 r:0.6465
si_en Dev loss: 0.9624 r:0.5329
ne_en Dev loss: 0.6290 r:0.6940
ru_en Dev loss: 0.5231 r:0.7109
Current avg r:0.5775 Best avg r: 0.6251
09:16:32,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:17:50,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:20,914 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1407
en_de Dev loss: 0.9043 r:0.1975
en_zh Dev loss: 0.8099 r:0.4518
ro_en Dev loss: 0.3633 r:0.8158
et_en Dev loss: 0.4797 r:0.6518
si_en Dev loss: 0.8873 r:0.5403
ne_en Dev loss: 0.6770 r:0.7022
ru_en Dev loss: 0.4943 r:0.7257
Current avg r:0.5836 Best avg r: 0.6251
09:23:15,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:24:32,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:03,839 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1276
en_de Dev loss: 0.9154 r:0.2029
en_zh Dev loss: 0.8572 r:0.4515
ro_en Dev loss: 0.3766 r:0.8194
et_en Dev loss: 0.4784 r:0.6482
si_en Dev loss: 0.9291 r:0.5339
ne_en Dev loss: 0.6313 r:0.6898
ru_en Dev loss: 0.5294 r:0.7187
Current avg r:0.5806 Best avg r: 0.6251
09:29:56,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:31:14,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:32:45,268 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1369
en_de Dev loss: 0.9101 r:0.2033
en_zh Dev loss: 0.7776 r:0.4617
ro_en Dev loss: 0.3342 r:0.8244
et_en Dev loss: 0.4758 r:0.6636
si_en Dev loss: 0.7833 r:0.5577
ne_en Dev loss: 0.7462 r:0.7097
ru_en Dev loss: 0.4391 r:0.7362
Current avg r:0.5938 Best avg r: 0.6251
09:36:38,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:37:55,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:39:26,659 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1366
en_de Dev loss: 0.9792 r:0.1838
en_zh Dev loss: 0.9036 r:0.4466
ro_en Dev loss: 0.3902 r:0.8198
et_en Dev loss: 0.5056 r:0.6497
si_en Dev loss: 0.9260 r:0.5383
ne_en Dev loss: 0.6809 r:0.6997
ru_en Dev loss: 0.5456 r:0.7182
Current avg r:0.5794 Best avg r: 0.6251
09:43:19,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:44:37,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:46:08,60 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1306
en_de Dev loss: 0.9366 r:0.1912
en_zh Dev loss: 0.8424 r:0.4494
ro_en Dev loss: 0.3636 r:0.8210
et_en Dev loss: 0.4922 r:0.6538
si_en Dev loss: 0.8781 r:0.5469
ne_en Dev loss: 0.6992 r:0.7084
ru_en Dev loss: 0.4924 r:0.7296
Current avg r:0.5858 Best avg r: 0.6251
09:50:00,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:51:18,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:52:49,515 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1329
en_de Dev loss: 0.9489 r:0.2042
en_zh Dev loss: 0.8539 r:0.4580
ro_en Dev loss: 0.3750 r:0.8237
et_en Dev loss: 0.5119 r:0.6550
si_en Dev loss: 0.8921 r:0.5526
ne_en Dev loss: 0.7626 r:0.7100
ru_en Dev loss: 0.5005 r:0.7299
Current avg r:0.5905 Best avg r: 0.6251
09:56:42,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:59,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:30,781 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1262
en_de Dev loss: 0.9398 r:0.2022
en_zh Dev loss: 0.8783 r:0.4484
ro_en Dev loss: 0.4060 r:0.8188
et_en Dev loss: 0.5214 r:0.6479
si_en Dev loss: 0.9378 r:0.5460
ne_en Dev loss: 0.7338 r:0.7014
ru_en Dev loss: 0.5398 r:0.7156
Current avg r:0.5829 Best avg r: 0.6251
10:03:23,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:41,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:12,501 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1342
en_de Dev loss: 0.9010 r:0.2356
en_zh Dev loss: 0.8415 r:0.4511
ro_en Dev loss: 0.3743 r:0.8180
et_en Dev loss: 0.4934 r:0.6546
si_en Dev loss: 0.9121 r:0.5419
ne_en Dev loss: 0.7050 r:0.7078
ru_en Dev loss: 0.4820 r:0.7305
Current avg r:0.5914 Best avg r: 0.6251
10:10:05,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:23,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:54,141 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1299
en_de Dev loss: 0.8800 r:0.2142
en_zh Dev loss: 0.7732 r:0.4564
ro_en Dev loss: 0.3484 r:0.8192
et_en Dev loss: 0.4707 r:0.6540
si_en Dev loss: 0.9216 r:0.5400
ne_en Dev loss: 0.7147 r:0.7068
ru_en Dev loss: 0.4590 r:0.7301
Current avg r:0.5887 Best avg r: 0.6251
10:16:46,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:04,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:35,319 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1293
en_de Dev loss: 0.8991 r:0.2144
en_zh Dev loss: 0.8118 r:0.4576
ro_en Dev loss: 0.3632 r:0.8182
et_en Dev loss: 0.4714 r:0.6524
si_en Dev loss: 0.8922 r:0.5464
ne_en Dev loss: 0.6362 r:0.7061
ru_en Dev loss: 0.4778 r:0.7318
Current avg r:0.5895 Best avg r: 0.6251
10:23:28,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:46,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:17,309 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1329
en_de Dev loss: 0.9333 r:0.1972
en_zh Dev loss: 0.8409 r:0.4516
ro_en Dev loss: 0.3763 r:0.8130
et_en Dev loss: 0.5017 r:0.6468
si_en Dev loss: 0.8454 r:0.5518
ne_en Dev loss: 0.7104 r:0.7045
ru_en Dev loss: 0.4941 r:0.7266
Current avg r:0.5845 Best avg r: 0.6251
10:30:10,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
