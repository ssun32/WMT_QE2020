14:44:00,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:15,596 root INFO 
id:en_de cur r: 0.0827 best r: 0.0827
14:44:30,611 root INFO 
id:en_zh cur r: 0.1332 best r: 0.1332
14:44:45,452 root INFO 
id:ro_en cur r: 0.1563 best r: 0.1563
14:45:00,308 root INFO 
id:et_en cur r: 0.3015 best r: 0.3015
14:45:29,948 root INFO 
id:ru_en cur r: 0.0334 best r: 0.0334
14:45:29,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:14,356 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
14:47:14,363 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:47:14,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:47:14,377 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
14:47:14,383 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
14:47:14,388 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:47:14,395 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:47:29,341 root INFO Epoch 0 Global steps: 600 Train loss: 0.8520
en_de Dev loss: 0.8846 r:0.0904
en_zh Dev loss: 0.8065 r:0.2381
ro_en Dev loss: 0.8414 r:0.2272
et_en Dev loss: 0.7346 r:0.3783
si_en Dev loss: 0.8280 r:0.2357
ne_en Dev loss: 0.7854 r:0.1281
ru_en Dev loss: 0.8069 r:0.2878
Current avg r:0.2265 Best avg r: 0.2265
14:51:56,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:40,758 root INFO 
id:ro_en cur r: 0.4169 best r: 0.4169
14:52:55,588 root INFO 
id:et_en cur r: 0.4058 best r: 0.4058
14:53:10,434 root INFO 
id:si_en cur r: 0.2624 best r: 0.2624
14:53:25,422 root INFO 
id:ru_en cur r: 0.3230 best r: 0.3230
14:53:25,422 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:09,684 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
14:55:09,690 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:55:09,694 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:55:09,699 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
14:55:09,703 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
14:55:09,712 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:55:09,716 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:55:24,495 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8280
en_de Dev loss: 0.8810 r:0.1175
en_zh Dev loss: 0.7942 r:0.3164
ro_en Dev loss: 0.8033 r:0.5937
et_en Dev loss: 0.6811 r:0.5610
si_en Dev loss: 0.7834 r:0.4472
ne_en Dev loss: 0.7482 r:0.4794
ru_en Dev loss: 0.7723 r:0.6065
Current avg r:0.4459 Best avg r: 0.4459
14:59:51,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:05,968 root INFO 
id:en_de cur r: 0.1292 best r: 0.1292
15:00:20,778 root INFO 
id:en_zh cur r: 0.2840 best r: 0.2840
15:00:35,602 root INFO 
id:ro_en cur r: 0.6889 best r: 0.6889
15:00:50,441 root INFO 
id:et_en cur r: 0.6428 best r: 0.6428
15:01:05,293 root INFO 
id:si_en cur r: 0.5122 best r: 0.5122
15:01:20,53 root INFO 
id:ru_en cur r: 0.6939 best r: 0.6939
15:01:20,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:04,151 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:03:04,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:03:04,161 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:03:04,165 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:03:04,169 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:03:04,174 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:03:04,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:03:18,997 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7752
en_de Dev loss: 0.9680 r:0.1195
en_zh Dev loss: 0.8342 r:0.3121
ro_en Dev loss: 0.6864 r:0.6569
et_en Dev loss: 0.4898 r:0.6561
si_en Dev loss: 0.6860 r:0.5337
ne_en Dev loss: 0.5015 r:0.6332
ru_en Dev loss: 0.5453 r:0.6885
Current avg r:0.5143 Best avg r: 0.5143
15:07:45,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:00,397 root INFO 
id:en_de cur r: 0.1371 best r: 0.1371
15:08:15,189 root INFO 
id:en_zh cur r: 0.3231 best r: 0.3231
15:08:30,76 root INFO 
id:ro_en cur r: 0.7273 best r: 0.7273
15:08:44,993 root INFO 
id:et_en cur r: 0.6803 best r: 0.6803
15:08:59,911 root INFO 
id:si_en cur r: 0.5219 best r: 0.5219
15:09:14,715 root INFO 
id:ru_en cur r: 0.7329 best r: 0.7329
15:09:14,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:58,809 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:10:58,817 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:10:58,824 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:10:58,828 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:10:58,833 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:10:58,839 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:10:58,843 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:11:13,749 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6742
en_de Dev loss: 0.9268 r:0.1460
en_zh Dev loss: 0.7978 r:0.3260
ro_en Dev loss: 0.4949 r:0.7198
et_en Dev loss: 0.3809 r:0.6791
si_en Dev loss: 0.7430 r:0.5168
ne_en Dev loss: 0.5496 r:0.6448
ru_en Dev loss: 0.4157 r:0.7309
Current avg r:0.5376 Best avg r: 0.5376
15:15:40,454 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:55,239 root INFO 
id:en_de cur r: 0.1942 best r: 0.1942
15:16:10,68 root INFO 
id:en_zh cur r: 0.3512 best r: 0.3512
15:16:24,921 root INFO 
id:ro_en cur r: 0.7580 best r: 0.7580
15:16:39,796 root INFO 
id:et_en cur r: 0.6810 best r: 0.6810
15:16:54,682 root INFO 
id:si_en cur r: 0.5349 best r: 0.5349
15:17:09,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:53,116 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:18:53,122 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:18:53,126 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:18:53,130 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:18:53,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:18:53,138 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:18:53,142 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:19:08,45 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6058
en_de Dev loss: 0.9093 r:0.1839
en_zh Dev loss: 0.7818 r:0.3602
ro_en Dev loss: 0.4474 r:0.7504
et_en Dev loss: 0.3963 r:0.6798
si_en Dev loss: 0.8350 r:0.5344
ne_en Dev loss: 0.5216 r:0.6487
ru_en Dev loss: 0.4679 r:0.7258
Current avg r:0.5547 Best avg r: 0.5547
15:23:34,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:49,101 root INFO 
id:en_de cur r: 0.2141 best r: 0.2141
15:24:03,915 root INFO 
id:en_zh cur r: 0.3818 best r: 0.3818
15:24:18,746 root INFO 
id:ro_en cur r: 0.7796 best r: 0.7796
15:24:33,586 root INFO 
id:et_en cur r: 0.6918 best r: 0.6918
15:24:48,441 root INFO 
id:si_en cur r: 0.5476 best r: 0.5476
15:25:03,199 root INFO 
id:ru_en cur r: 0.7335 best r: 0.7335
15:25:03,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:46,904 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:26:46,911 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:26:46,916 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:26:46,922 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:26:46,927 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:26:46,932 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:26:46,938 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:27:01,648 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6314
en_de Dev loss: 0.8858 r:0.2029
en_zh Dev loss: 0.7561 r:0.3786
ro_en Dev loss: 0.3832 r:0.7766
et_en Dev loss: 0.3792 r:0.6860
si_en Dev loss: 0.7429 r:0.5474
ne_en Dev loss: 0.6138 r:0.6612
ru_en Dev loss: 0.4579 r:0.7247
Current avg r:0.5682 Best avg r: 0.5682
15:31:27,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:57,408 root INFO 
id:en_zh cur r: 0.3981 best r: 0.3981
15:32:12,168 root INFO 
id:ro_en cur r: 0.7871 best r: 0.7871
15:32:27,3 root INFO 
id:et_en cur r: 0.6996 best r: 0.6996
15:32:41,981 root INFO 
id:si_en cur r: 0.5605 best r: 0.5605
15:32:56,808 root INFO 
id:ru_en cur r: 0.7410 best r: 0.7410
15:32:56,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:40,436 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:34:40,442 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:34:40,447 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:34:40,451 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:34:40,455 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:34:40,459 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:34:40,464 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:34:55,305 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5864
en_de Dev loss: 0.8802 r:0.1977
en_zh Dev loss: 0.7330 r:0.3949
ro_en Dev loss: 0.3618 r:0.7851
et_en Dev loss: 0.3787 r:0.6915
si_en Dev loss: 0.7822 r:0.5581
ne_en Dev loss: 0.5947 r:0.6908
ru_en Dev loss: 0.4204 r:0.7396
Current avg r:0.5797 Best avg r: 0.5797
15:39:21,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:51,276 root INFO 
id:en_zh cur r: 0.4213 best r: 0.4213
15:40:06,205 root INFO 
id:ro_en cur r: 0.7936 best r: 0.7936
15:40:20,967 root INFO 
id:et_en cur r: 0.7042 best r: 0.7042
15:40:35,750 root INFO 
id:si_en cur r: 0.5652 best r: 0.5652
15:40:50,430 root INFO 
id:ru_en cur r: 0.7514 best r: 0.7514
15:40:50,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:34,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:42:34,184 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:42:34,189 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:42:34,193 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:42:34,196 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:42:34,202 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:42:34,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:42:49,74 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6029
en_de Dev loss: 0.8944 r:0.2028
en_zh Dev loss: 0.7214 r:0.4226
ro_en Dev loss: 0.3700 r:0.7922
et_en Dev loss: 0.3738 r:0.6984
si_en Dev loss: 0.8529 r:0.5609
ne_en Dev loss: 0.5378 r:0.7000
ru_en Dev loss: 0.4167 r:0.7500
Current avg r:0.5895 Best avg r: 0.5895
15:47:15,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:29,748 root INFO 
id:en_de cur r: 0.2143 best r: 0.2143
15:48:29,203 root INFO 
id:si_en cur r: 0.5658 best r: 0.5658
15:48:43,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:27,549 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5612
en_de Dev loss: 0.8900 r:0.2019
en_zh Dev loss: 0.7518 r:0.4018
ro_en Dev loss: 0.3819 r:0.7921
et_en Dev loss: 0.3827 r:0.6909
si_en Dev loss: 0.7485 r:0.5617
ne_en Dev loss: 0.5485 r:0.6910
ru_en Dev loss: 0.4799 r:0.7353
Current avg r:0.5821 Best avg r: 0.5895
15:54:53,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:37,889 root INFO 
id:ro_en cur r: 0.7957 best r: 0.7957
15:56:22,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:06,5 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5464
en_de Dev loss: 0.8612 r:0.1958
en_zh Dev loss: 0.6877 r:0.4115
ro_en Dev loss: 0.3310 r:0.7910
et_en Dev loss: 0.3734 r:0.6884
si_en Dev loss: 0.6730 r:0.5592
ne_en Dev loss: 0.7044 r:0.6879
ru_en Dev loss: 0.4217 r:0.7274
Current avg r:0.5802 Best avg r: 0.5895
16:02:31,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:02:46,642 root INFO 
id:en_de cur r: 0.2174 best r: 0.2174
16:03:16,579 root INFO 
id:ro_en cur r: 0.8081 best r: 0.8081
16:03:31,578 root INFO 
id:et_en cur r: 0.7122 best r: 0.7122
16:03:46,408 root INFO 
id:si_en cur r: 0.5880 best r: 0.5880
16:04:01,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:45,143 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:05:45,149 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:05:45,153 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:05:45,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:05:45,162 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:05:45,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:05:45,170 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:06:00,47 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5252
en_de Dev loss: 0.8996 r:0.2061
en_zh Dev loss: 0.7634 r:0.4159
ro_en Dev loss: 0.3613 r:0.8048
et_en Dev loss: 0.3721 r:0.7046
si_en Dev loss: 0.7155 r:0.5800
ne_en Dev loss: 0.5797 r:0.7075
ru_en Dev loss: 0.4726 r:0.7468
Current avg r:0.5951 Best avg r: 0.5951
16:10:25,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:40,724 root INFO 
id:en_de cur r: 0.2201 best r: 0.2201
16:10:55,649 root INFO 
id:en_zh cur r: 0.4215 best r: 0.4215
16:11:25,538 root INFO 
id:et_en cur r: 0.7151 best r: 0.7151
16:11:40,499 root INFO 
id:si_en cur r: 0.5886 best r: 0.5886
16:11:55,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:39,307 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:13:39,313 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:13:39,317 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:13:39,320 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:13:39,324 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:13:39,328 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:13:39,332 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:13:54,226 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5396
en_de Dev loss: 0.8753 r:0.2127
en_zh Dev loss: 0.7335 r:0.4184
ro_en Dev loss: 0.3399 r:0.7989
et_en Dev loss: 0.3661 r:0.7094
si_en Dev loss: 0.7198 r:0.5796
ne_en Dev loss: 0.6863 r:0.7112
ru_en Dev loss: 0.4367 r:0.7461
Current avg r:0.5966 Best avg r: 0.5966
16:18:19,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:34,709 root INFO 
id:en_de cur r: 0.2414 best r: 0.2414
16:18:49,521 root INFO 
id:en_zh cur r: 0.4263 best r: 0.4263
16:19:04,341 root INFO 
id:ro_en cur r: 0.8132 best r: 0.8132
16:19:19,371 root INFO 
id:et_en cur r: 0.7163 best r: 0.7163
16:19:34,399 root INFO 
id:si_en cur r: 0.5950 best r: 0.5950
16:19:49,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:32,825 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:21:32,831 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:21:32,835 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:21:32,839 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:21:32,843 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:21:32,850 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:21:32,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:21:47,692 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5380
en_de Dev loss: 0.8596 r:0.2367
en_zh Dev loss: 0.7379 r:0.4198
ro_en Dev loss: 0.3245 r:0.8082
et_en Dev loss: 0.3597 r:0.7118
si_en Dev loss: 0.6243 r:0.5888
ne_en Dev loss: 0.6831 r:0.7137
ru_en Dev loss: 0.4667 r:0.7436
Current avg r:0.6032 Best avg r: 0.6032
16:26:13,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:28,177 root INFO 
id:en_de cur r: 0.2424 best r: 0.2424
16:26:43,144 root INFO 
id:en_zh cur r: 0.4329 best r: 0.4329
16:26:58,136 root INFO 
id:ro_en cur r: 0.8139 best r: 0.8139
16:27:12,960 root INFO 
id:et_en cur r: 0.7200 best r: 0.7200
16:27:42,566 root INFO 
id:ru_en cur r: 0.7530 best r: 0.7530
16:27:42,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:26,740 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:29:26,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:29:26,752 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:29:26,757 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:29:26,762 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:29:26,769 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:29:26,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:29:41,573 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5619
en_de Dev loss: 0.8417 r:0.2393
en_zh Dev loss: 0.6833 r:0.4312
ro_en Dev loss: 0.3006 r:0.8092
et_en Dev loss: 0.3543 r:0.7160
si_en Dev loss: 0.5914 r:0.5881
ne_en Dev loss: 0.8254 r:0.7158
ru_en Dev loss: 0.3862 r:0.7540
Current avg r:0.6077 Best avg r: 0.6077
16:34:07,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:21,974 root INFO 
id:en_de cur r: 0.2553 best r: 0.2553
16:34:36,640 root INFO 
id:en_zh cur r: 0.4477 best r: 0.4477
16:34:51,500 root INFO 
id:ro_en cur r: 0.8202 best r: 0.8202
16:35:06,421 root INFO 
id:et_en cur r: 0.7250 best r: 0.7250
16:35:21,265 root INFO 
id:si_en cur r: 0.6033 best r: 0.6033
16:35:36,0 root INFO 
id:ru_en cur r: 0.7561 best r: 0.7561
16:35:36,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:19,945 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:37:19,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:37:19,955 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:37:19,959 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:37:19,964 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:37:19,967 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:37:19,972 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:37:34,845 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5386
en_de Dev loss: 0.8524 r:0.2465
en_zh Dev loss: 0.7008 r:0.4408
ro_en Dev loss: 0.3020 r:0.8162
et_en Dev loss: 0.3525 r:0.7204
si_en Dev loss: 0.5946 r:0.5973
ne_en Dev loss: 0.7722 r:0.7247
ru_en Dev loss: 0.3878 r:0.7586
Current avg r:0.6149 Best avg r: 0.6149
16:42:01,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:15,707 root INFO 
id:si_en cur r: 0.6103 best r: 0.6103
16:43:30,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:14,185 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5225
en_de Dev loss: 0.8593 r:0.2303
en_zh Dev loss: 0.6929 r:0.4350
ro_en Dev loss: 0.3014 r:0.8135
et_en Dev loss: 0.3579 r:0.7160
si_en Dev loss: 0.5612 r:0.6036
ne_en Dev loss: 0.7681 r:0.7197
ru_en Dev loss: 0.4061 r:0.7476
Current avg r:0.6094 Best avg r: 0.6149
16:49:40,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:08,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:52,553 root INFO Epoch 1 Global steps: 10200 Train loss: 0.4862
en_de Dev loss: 0.8437 r:0.2507
en_zh Dev loss: 0.6777 r:0.4394
ro_en Dev loss: 0.3040 r:0.8099
et_en Dev loss: 0.3635 r:0.7080
si_en Dev loss: 0.6391 r:0.5901
ne_en Dev loss: 0.7429 r:0.7054
ru_en Dev loss: 0.4186 r:0.7335
Current avg r:0.6053 Best avg r: 0.6149
16:57:18,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:48,213 root INFO 
id:en_zh cur r: 0.4602 best r: 0.4602
16:58:47,627 root INFO 
id:ru_en cur r: 0.7604 best r: 0.7604
16:58:47,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:31,197 root INFO Epoch 1 Global steps: 10800 Train loss: 0.4828
en_de Dev loss: 0.8532 r:0.2440
en_zh Dev loss: 0.6777 r:0.4527
ro_en Dev loss: 0.3186 r:0.8140
et_en Dev loss: 0.3660 r:0.7101
si_en Dev loss: 0.5902 r:0.6008
ne_en Dev loss: 0.7744 r:0.7248
ru_en Dev loss: 0.3954 r:0.7574
Current avg r:0.6148 Best avg r: 0.6149
17:04:57,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:26,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:10,141 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4890
en_de Dev loss: 0.8680 r:0.2130
en_zh Dev loss: 0.7581 r:0.4485
ro_en Dev loss: 0.3929 r:0.8145
et_en Dev loss: 0.4511 r:0.6963
si_en Dev loss: 0.8739 r:0.5768
ne_en Dev loss: 0.5085 r:0.6980
ru_en Dev loss: 0.5429 r:0.7192
Current avg r:0.5952 Best avg r: 0.6149
17:12:36,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:05,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:48,881 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4655
en_de Dev loss: 0.8462 r:0.2277
en_zh Dev loss: 0.6880 r:0.4400
ro_en Dev loss: 0.3077 r:0.8158
et_en Dev loss: 0.3722 r:0.7047
si_en Dev loss: 0.6241 r:0.5949
ne_en Dev loss: 0.7669 r:0.7255
ru_en Dev loss: 0.4059 r:0.7428
Current avg r:0.6074 Best avg r: 0.6149
17:20:14,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:59,533 root INFO 
id:ro_en cur r: 0.8207 best r: 0.8207
17:21:44,96 root INFO 
id:ru_en cur r: 0.7678 best r: 0.7678
17:21:44,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:27,880 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
17:23:27,885 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:23:27,890 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:23:27,897 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
17:23:27,902 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
17:23:27,907 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:23:27,911 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:23:42,764 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4843
en_de Dev loss: 0.8418 r:0.2324
en_zh Dev loss: 0.6850 r:0.4549
ro_en Dev loss: 0.3133 r:0.8176
et_en Dev loss: 0.3612 r:0.7141
si_en Dev loss: 0.6857 r:0.5989
ne_en Dev loss: 0.6350 r:0.7362
ru_en Dev loss: 0.3759 r:0.7649
Current avg r:0.6170 Best avg r: 0.6170
17:28:08,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:38,270 root INFO 
id:en_zh cur r: 0.4607 best r: 0.4607
17:29:37,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:21,630 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4567
en_de Dev loss: 0.8690 r:0.2300
en_zh Dev loss: 0.7062 r:0.4568
ro_en Dev loss: 0.3625 r:0.8130
et_en Dev loss: 0.3903 r:0.7001
si_en Dev loss: 0.8169 r:0.5819
ne_en Dev loss: 0.5622 r:0.7245
ru_en Dev loss: 0.4454 r:0.7501
Current avg r:0.6081 Best avg r: 0.6170
17:35:47,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:16,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:00,629 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4922
en_de Dev loss: 0.8646 r:0.2409
en_zh Dev loss: 0.7223 r:0.4569
ro_en Dev loss: 0.3531 r:0.8106
et_en Dev loss: 0.3851 r:0.7013
si_en Dev loss: 0.8198 r:0.5840
ne_en Dev loss: 0.5413 r:0.7165
ru_en Dev loss: 0.4945 r:0.7388
Current avg r:0.6070 Best avg r: 0.6170
17:43:27,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:55,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:39,626 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4709
en_de Dev loss: 0.8579 r:0.2502
en_zh Dev loss: 0.7146 r:0.4596
ro_en Dev loss: 0.3387 r:0.8172
et_en Dev loss: 0.3746 r:0.7065
si_en Dev loss: 0.7679 r:0.5894
ne_en Dev loss: 0.6132 r:0.7229
ru_en Dev loss: 0.4327 r:0.7544
Current avg r:0.6143 Best avg r: 0.6170
17:51:06,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:20,915 root INFO 
id:en_de cur r: 0.2686 best r: 0.2686
17:51:35,696 root INFO 
id:en_zh cur r: 0.4817 best r: 0.4817
17:51:50,473 root INFO 
id:ro_en cur r: 0.8232 best r: 0.8232
17:52:20,82 root INFO 
id:si_en cur r: 0.6120 best r: 0.6120
17:52:34,858 root INFO 
id:ru_en cur r: 0.7699 best r: 0.7699
17:52:34,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:18,533 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
17:54:18,540 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:54:18,544 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:54:18,549 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
17:54:18,553 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
17:54:18,557 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:54:18,561 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:54:33,424 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4807
en_de Dev loss: 0.8325 r:0.2503
en_zh Dev loss: 0.6653 r:0.4784
ro_en Dev loss: 0.3165 r:0.8196
et_en Dev loss: 0.3715 r:0.7177
si_en Dev loss: 0.6267 r:0.6071
ne_en Dev loss: 0.7225 r:0.7410
ru_en Dev loss: 0.3839 r:0.7706
Current avg r:0.6264 Best avg r: 0.6264
17:59:00,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:44,430 root INFO 
id:ro_en cur r: 0.8265 best r: 0.8265
18:00:14,143 root INFO 
id:si_en cur r: 0.6161 best r: 0.6161
18:00:28,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:12,633 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4912
en_de Dev loss: 0.8513 r:0.2532
en_zh Dev loss: 0.7017 r:0.4700
ro_en Dev loss: 0.3406 r:0.8226
et_en Dev loss: 0.3787 r:0.7203
si_en Dev loss: 0.5714 r:0.6128
ne_en Dev loss: 0.8010 r:0.7422
ru_en Dev loss: 0.4324 r:0.7596
Current avg r:0.6258 Best avg r: 0.6264
18:06:39,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:53,367 root INFO 
id:si_en cur r: 0.6165 best r: 0.6165
18:08:07,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:51,957 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4778
en_de Dev loss: 0.8597 r:0.2504
en_zh Dev loss: 0.7490 r:0.4669
ro_en Dev loss: 0.3306 r:0.8230
et_en Dev loss: 0.3684 r:0.7146
si_en Dev loss: 0.6274 r:0.6099
ne_en Dev loss: 0.6493 r:0.7347
ru_en Dev loss: 0.4376 r:0.7632
Current avg r:0.6233 Best avg r: 0.6264
18:14:18,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:33,79 root INFO 
id:en_de cur r: 0.2767 best r: 0.2767
18:15:47,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:30,871 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4736
en_de Dev loss: 0.8325 r:0.2665
en_zh Dev loss: 0.7562 r:0.4408
ro_en Dev loss: 0.3271 r:0.8175
et_en Dev loss: 0.3740 r:0.6980
si_en Dev loss: 0.7289 r:0.5849
ne_en Dev loss: 0.6199 r:0.7076
ru_en Dev loss: 0.4733 r:0.7201
Current avg r:0.6051 Best avg r: 0.6264
18:21:57,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:11,887 root INFO 
id:en_de cur r: 0.2833 best r: 0.2833
18:22:26,717 root INFO 
id:en_zh cur r: 0.4868 best r: 0.4868
18:22:41,551 root INFO 
id:ro_en cur r: 0.8276 best r: 0.8276
18:23:11,261 root INFO 
id:si_en cur r: 0.6202 best r: 0.6202
18:23:26,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:09,957 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
18:25:09,963 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
18:25:09,966 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
18:25:09,971 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
18:25:09,975 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
18:25:09,983 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
18:25:09,988 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
18:25:24,750 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4459
en_de Dev loss: 0.8181 r:0.2799
en_zh Dev loss: 0.6575 r:0.4823
ro_en Dev loss: 0.3023 r:0.8237
et_en Dev loss: 0.3710 r:0.7161
si_en Dev loss: 0.6004 r:0.6126
ne_en Dev loss: 0.8179 r:0.7425
ru_en Dev loss: 0.3860 r:0.7510
Current avg r:0.6297 Best avg r: 0.6297
18:29:51,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:20,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:03,640 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4724
en_de Dev loss: 0.8502 r:0.2369
en_zh Dev loss: 0.7158 r:0.4726
ro_en Dev loss: 0.3308 r:0.8245
et_en Dev loss: 0.3884 r:0.7074
si_en Dev loss: 0.6828 r:0.6054
ne_en Dev loss: 0.7334 r:0.7312
ru_en Dev loss: 0.4531 r:0.7318
Current avg r:0.6157 Best avg r: 0.6297
18:37:30,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:59,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:43,169 root INFO Epoch 2 Global steps: 18600 Train loss: 0.3996
en_de Dev loss: 0.8438 r:0.2428
en_zh Dev loss: 0.7137 r:0.4579
ro_en Dev loss: 0.3266 r:0.8219
et_en Dev loss: 0.3769 r:0.7059
si_en Dev loss: 0.6591 r:0.5951
ne_en Dev loss: 0.7894 r:0.7227
ru_en Dev loss: 0.4706 r:0.7193
Current avg r:0.6094 Best avg r: 0.6297
18:45:09,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:53,789 root INFO 
id:ro_en cur r: 0.8291 best r: 0.8291
18:46:38,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:22,17 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4351
en_de Dev loss: 0.8477 r:0.2152
en_zh Dev loss: 0.6893 r:0.4678
ro_en Dev loss: 0.2996 r:0.8266
et_en Dev loss: 0.3872 r:0.7083
si_en Dev loss: 0.6430 r:0.5995
ne_en Dev loss: 0.8611 r:0.7297
ru_en Dev loss: 0.3809 r:0.7504
Current avg r:0.6139 Best avg r: 0.6297
18:52:47,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:16,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:56:00,494 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4091
en_de Dev loss: 0.8397 r:0.2321
en_zh Dev loss: 0.6986 r:0.4615
ro_en Dev loss: 0.3085 r:0.8256
et_en Dev loss: 0.3866 r:0.7140
si_en Dev loss: 0.6296 r:0.6089
ne_en Dev loss: 0.8028 r:0.7365
ru_en Dev loss: 0.3567 r:0.7683
Current avg r:0.6210 Best avg r: 0.6297
19:00:26,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:55,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:38,809 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4312
en_de Dev loss: 0.8463 r:0.2472
en_zh Dev loss: 0.7225 r:0.4538
ro_en Dev loss: 0.3230 r:0.8199
et_en Dev loss: 0.3778 r:0.7050
si_en Dev loss: 0.7346 r:0.5921
ne_en Dev loss: 0.7244 r:0.7204
ru_en Dev loss: 0.4051 r:0.7494
Current avg r:0.6125 Best avg r: 0.6297
19:08:04,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:33,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:17,86 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4202
en_de Dev loss: 0.8302 r:0.2615
en_zh Dev loss: 0.7116 r:0.4609
ro_en Dev loss: 0.3328 r:0.8191
et_en Dev loss: 0.3792 r:0.7069
si_en Dev loss: 0.6851 r:0.5981
ne_en Dev loss: 0.7362 r:0.7255
ru_en Dev loss: 0.3935 r:0.7521
Current avg r:0.6177 Best avg r: 0.6297
19:15:42,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:11,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:55,105 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4178
en_de Dev loss: 0.8510 r:0.2269
en_zh Dev loss: 0.7102 r:0.4654
ro_en Dev loss: 0.3338 r:0.8187
et_en Dev loss: 0.3811 r:0.7017
si_en Dev loss: 0.6708 r:0.6021
ne_en Dev loss: 0.6863 r:0.7271
ru_en Dev loss: 0.4194 r:0.7472
Current avg r:0.6127 Best avg r: 0.6297
19:23:20,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:49,812 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:33,557 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4162
en_de Dev loss: 0.8393 r:0.2419
en_zh Dev loss: 0.6962 r:0.4536
ro_en Dev loss: 0.3184 r:0.8179
et_en Dev loss: 0.4152 r:0.7000
si_en Dev loss: 0.6357 r:0.5938
ne_en Dev loss: 0.9428 r:0.7147
ru_en Dev loss: 0.4195 r:0.7285
Current avg r:0.6072 Best avg r: 0.6297
19:30:59,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:28,188 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:11,994 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4172
en_de Dev loss: 0.8411 r:0.2487
en_zh Dev loss: 0.7150 r:0.4569
ro_en Dev loss: 0.3531 r:0.8199
et_en Dev loss: 0.3927 r:0.6980
si_en Dev loss: 0.6932 r:0.6001
ne_en Dev loss: 0.7173 r:0.7222
ru_en Dev loss: 0.4202 r:0.7490
Current avg r:0.6135 Best avg r: 0.6297
19:38:37,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:06,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:49,988 root INFO Epoch 2 Global steps: 23400 Train loss: 0.3963
en_de Dev loss: 0.8487 r:0.2485
en_zh Dev loss: 0.7139 r:0.4635
ro_en Dev loss: 0.3288 r:0.8233
et_en Dev loss: 0.4095 r:0.7004
si_en Dev loss: 0.6644 r:0.6063
ne_en Dev loss: 0.7573 r:0.7187
ru_en Dev loss: 0.4688 r:0.7397
Current avg r:0.6143 Best avg r: 0.6297
19:46:15,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:44,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:27,599 root INFO Epoch 2 Global steps: 24000 Train loss: 0.3982
en_de Dev loss: 0.8426 r:0.2459
en_zh Dev loss: 0.6894 r:0.4582
ro_en Dev loss: 0.2988 r:0.8205
et_en Dev loss: 0.3830 r:0.6983
si_en Dev loss: 0.6887 r:0.6016
ne_en Dev loss: 0.7119 r:0.7228
ru_en Dev loss: 0.4259 r:0.7360
Current avg r:0.6119 Best avg r: 0.6297
19:53:53,245 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:21,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:05,462 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4320
en_de Dev loss: 0.8503 r:0.2264
en_zh Dev loss: 0.7070 r:0.4551
ro_en Dev loss: 0.3243 r:0.8195
et_en Dev loss: 0.4006 r:0.6938
si_en Dev loss: 0.6839 r:0.5918
ne_en Dev loss: 0.8761 r:0.7236
ru_en Dev loss: 0.4071 r:0.7432
Current avg r:0.6076 Best avg r: 0.6297
20:01:31,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:59,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:43,569 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3882
en_de Dev loss: 0.8459 r:0.2522
en_zh Dev loss: 0.7234 r:0.4590
ro_en Dev loss: 0.3164 r:0.8205
et_en Dev loss: 0.3824 r:0.7010
si_en Dev loss: 0.7078 r:0.5960
ne_en Dev loss: 0.6734 r:0.7245
ru_en Dev loss: 0.4078 r:0.7550
Current avg r:0.6154 Best avg r: 0.6297
20:09:09,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:10:38,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:21,446 root INFO Epoch 2 Global steps: 25800 Train loss: 0.3824
en_de Dev loss: 0.8362 r:0.2499
en_zh Dev loss: 0.6921 r:0.4637
ro_en Dev loss: 0.3233 r:0.8168
et_en Dev loss: 0.3999 r:0.7038
si_en Dev loss: 0.6913 r:0.5936
ne_en Dev loss: 0.8250 r:0.7295
ru_en Dev loss: 0.3555 r:0.7675
Current avg r:0.6178 Best avg r: 0.6297
20:16:47,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:15,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:59,452 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4096
en_de Dev loss: 0.8361 r:0.2449
en_zh Dev loss: 0.6647 r:0.4663
ro_en Dev loss: 0.2860 r:0.8236
et_en Dev loss: 0.3915 r:0.7074
si_en Dev loss: 0.5973 r:0.6111
ne_en Dev loss: 0.8030 r:0.7395
ru_en Dev loss: 0.3524 r:0.7609
Current avg r:0.6220 Best avg r: 0.6297
20:24:25,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:54,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:37,671 root INFO Epoch 2 Global steps: 27000 Train loss: 0.3834
en_de Dev loss: 0.8672 r:0.2183
en_zh Dev loss: 0.7653 r:0.4547
ro_en Dev loss: 0.3494 r:0.8204
et_en Dev loss: 0.4114 r:0.6967
si_en Dev loss: 0.7301 r:0.5967
ne_en Dev loss: 0.6484 r:0.7189
ru_en Dev loss: 0.4924 r:0.7340
Current avg r:0.6057 Best avg r: 0.6297
20:32:04,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:33:33,195 root INFO 
id:ru_en cur r: 0.7700 best r: 0.7700
20:33:33,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:16,883 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3747
en_de Dev loss: 0.8276 r:0.2614
en_zh Dev loss: 0.6818 r:0.4728
ro_en Dev loss: 0.3157 r:0.8246
et_en Dev loss: 0.4158 r:0.7014
si_en Dev loss: 0.6839 r:0.5986
ne_en Dev loss: 0.7987 r:0.7287
ru_en Dev loss: 0.3575 r:0.7653
Current avg r:0.6218 Best avg r: 0.6297
20:39:42,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:27,478 root INFO 
id:ro_en cur r: 0.8307 best r: 0.8307
20:41:11,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:55,396 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3673
en_de Dev loss: 0.8406 r:0.2373
en_zh Dev loss: 0.6948 r:0.4648
ro_en Dev loss: 0.2994 r:0.8274
et_en Dev loss: 0.3884 r:0.6933
si_en Dev loss: 0.6818 r:0.5962
ne_en Dev loss: 0.7121 r:0.7273
ru_en Dev loss: 0.4149 r:0.7401
Current avg r:0.6123 Best avg r: 0.6297
20:47:21,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:50,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:33,835 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3845
en_de Dev loss: 0.8469 r:0.2316
en_zh Dev loss: 0.7507 r:0.4450
ro_en Dev loss: 0.3298 r:0.8237
et_en Dev loss: 0.4119 r:0.6899
si_en Dev loss: 0.7213 r:0.5854
ne_en Dev loss: 0.7345 r:0.7184
ru_en Dev loss: 0.4555 r:0.7253
Current avg r:0.6028 Best avg r: 0.6297
20:54:59,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:44,44 root INFO 
id:ro_en cur r: 0.8329 best r: 0.8329
20:56:28,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:12,58 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3380
en_de Dev loss: 0.8397 r:0.2520
en_zh Dev loss: 0.7538 r:0.4708
ro_en Dev loss: 0.3241 r:0.8298
et_en Dev loss: 0.4317 r:0.6949
si_en Dev loss: 0.6934 r:0.5979
ne_en Dev loss: 0.8402 r:0.7315
ru_en Dev loss: 0.4267 r:0.7513
Current avg r:0.6183 Best avg r: 0.6297
21:02:37,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:06,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:50,189 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3403
en_de Dev loss: 0.8511 r:0.2434
en_zh Dev loss: 0.7510 r:0.4668
ro_en Dev loss: 0.3388 r:0.8249
et_en Dev loss: 0.4253 r:0.6883
si_en Dev loss: 0.8057 r:0.5816
ne_en Dev loss: 0.7263 r:0.7176
ru_en Dev loss: 0.4650 r:0.7317
Current avg r:0.6078 Best avg r: 0.6297
21:10:16,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:44,812 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:28,323 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3525
en_de Dev loss: 0.8321 r:0.2587
en_zh Dev loss: 0.7243 r:0.4585
ro_en Dev loss: 0.3254 r:0.8272
et_en Dev loss: 0.4341 r:0.6956
si_en Dev loss: 0.6640 r:0.5990
ne_en Dev loss: 0.9320 r:0.7224
ru_en Dev loss: 0.4113 r:0.7382
Current avg r:0.6142 Best avg r: 0.6297
21:17:53,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:22,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:05,827 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3563
en_de Dev loss: 0.8348 r:0.2533
en_zh Dev loss: 0.7337 r:0.4572
ro_en Dev loss: 0.3274 r:0.8251
et_en Dev loss: 0.4515 r:0.6852
si_en Dev loss: 0.6810 r:0.5976
ne_en Dev loss: 0.9773 r:0.7210
ru_en Dev loss: 0.4137 r:0.7370
Current avg r:0.6109 Best avg r: 0.6297
21:25:31,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:00,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:28:43,916 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3353
en_de Dev loss: 0.8525 r:0.2108
en_zh Dev loss: 0.7017 r:0.4667
ro_en Dev loss: 0.3029 r:0.8256
et_en Dev loss: 0.4521 r:0.6819
si_en Dev loss: 0.6769 r:0.5916
ne_en Dev loss: 0.9869 r:0.7193
ru_en Dev loss: 0.4133 r:0.7320
Current avg r:0.6040 Best avg r: 0.6297
21:33:09,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:37,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:21,590 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3390
en_de Dev loss: 0.8412 r:0.2459
en_zh Dev loss: 0.6938 r:0.4833
ro_en Dev loss: 0.3021 r:0.8252
et_en Dev loss: 0.4161 r:0.6881
si_en Dev loss: 0.7157 r:0.5923
ne_en Dev loss: 0.7394 r:0.7261
ru_en Dev loss: 0.3816 r:0.7605
Current avg r:0.6174 Best avg r: 0.6297
21:40:46,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:15,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:58,711 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3294
en_de Dev loss: 0.8591 r:0.2279
en_zh Dev loss: 0.7030 r:0.4743
ro_en Dev loss: 0.3182 r:0.8204
et_en Dev loss: 0.4251 r:0.6887
si_en Dev loss: 0.7592 r:0.5840
ne_en Dev loss: 0.7612 r:0.7234
ru_en Dev loss: 0.3925 r:0.7574
Current avg r:0.6109 Best avg r: 0.6297
21:48:24,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:52,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:36,34 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3566
en_de Dev loss: 0.8396 r:0.2361
en_zh Dev loss: 0.7070 r:0.4713
ro_en Dev loss: 0.3105 r:0.8252
et_en Dev loss: 0.4276 r:0.6941
si_en Dev loss: 0.6925 r:0.5928
ne_en Dev loss: 0.8899 r:0.7243
ru_en Dev loss: 0.4082 r:0.7418
Current avg r:0.6122 Best avg r: 0.6297
21:56:01,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:29,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:13,267 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3485
en_de Dev loss: 0.8549 r:0.2217
en_zh Dev loss: 0.7510 r:0.4494
ro_en Dev loss: 0.3187 r:0.8243
et_en Dev loss: 0.4159 r:0.6892
si_en Dev loss: 0.7563 r:0.5877
ne_en Dev loss: 0.7638 r:0.7206
ru_en Dev loss: 0.4515 r:0.7184
Current avg r:0.6016 Best avg r: 0.6297
22:03:38,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:07,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:50,435 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3490
en_de Dev loss: 0.8499 r:0.2158
en_zh Dev loss: 0.7182 r:0.4628
ro_en Dev loss: 0.2975 r:0.8272
et_en Dev loss: 0.4181 r:0.6885
si_en Dev loss: 0.6835 r:0.5910
ne_en Dev loss: 0.8061 r:0.7221
ru_en Dev loss: 0.4129 r:0.7252
Current avg r:0.6047 Best avg r: 0.6297
22:11:15,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:44,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:28,34 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3284
en_de Dev loss: 0.8690 r:0.1984
en_zh Dev loss: 0.8056 r:0.4392
ro_en Dev loss: 0.3394 r:0.8210
et_en Dev loss: 0.4415 r:0.6811
si_en Dev loss: 0.7567 r:0.5781
ne_en Dev loss: 0.8518 r:0.7148
ru_en Dev loss: 0.4460 r:0.7246
Current avg r:0.5939 Best avg r: 0.6297
22:18:53,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:22,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:05,560 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3514
en_de Dev loss: 0.8864 r:0.1890
en_zh Dev loss: 0.7857 r:0.4443
ro_en Dev loss: 0.3712 r:0.8168
et_en Dev loss: 0.4044 r:0.6830
si_en Dev loss: 0.8845 r:0.5731
ne_en Dev loss: 0.5622 r:0.7110
ru_en Dev loss: 0.4814 r:0.7200
Current avg r:0.5910 Best avg r: 0.6297
22:26:31,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:27:01,71 root INFO 
id:en_zh cur r: 0.4916 best r: 0.4916
22:28:00,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:43,829 root INFO Epoch 4 Global steps: 36600 Train loss: 0.2964
en_de Dev loss: 0.8506 r:0.2347
en_zh Dev loss: 0.7281 r:0.4854
ro_en Dev loss: 0.3399 r:0.8228
et_en Dev loss: 0.4425 r:0.6829
si_en Dev loss: 0.7529 r:0.5854
ne_en Dev loss: 0.7626 r:0.7248
ru_en Dev loss: 0.3861 r:0.7592
Current avg r:0.6136 Best avg r: 0.6297
22:34:08,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:37,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:21,204 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3001
en_de Dev loss: 0.8718 r:0.1608
en_zh Dev loss: 0.7820 r:0.4355
ro_en Dev loss: 0.3248 r:0.8163
et_en Dev loss: 0.4189 r:0.6695
si_en Dev loss: 0.8650 r:0.5628
ne_en Dev loss: 0.6372 r:0.7019
ru_en Dev loss: 0.4800 r:0.7085
Current avg r:0.5793 Best avg r: 0.6297
22:41:46,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:15,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:58,623 root INFO Epoch 4 Global steps: 37800 Train loss: 0.2928
en_de Dev loss: 0.8692 r:0.1944
en_zh Dev loss: 0.7865 r:0.4560
ro_en Dev loss: 0.3629 r:0.8202
et_en Dev loss: 0.4573 r:0.6727
si_en Dev loss: 0.9283 r:0.5696
ne_en Dev loss: 0.6800 r:0.7069
ru_en Dev loss: 0.5113 r:0.7139
Current avg r:0.5905 Best avg r: 0.6297
22:49:24,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:52,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:36,216 root INFO Epoch 4 Global steps: 38400 Train loss: 0.2914
en_de Dev loss: 0.8812 r:0.1600
en_zh Dev loss: 0.8205 r:0.4161
ro_en Dev loss: 0.3538 r:0.8181
et_en Dev loss: 0.4589 r:0.6784
si_en Dev loss: 0.8192 r:0.5702
ne_en Dev loss: 0.9190 r:0.7089
ru_en Dev loss: 0.4974 r:0.7073
Current avg r:0.5799 Best avg r: 0.6297
22:57:01,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:30,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:13,756 root INFO Epoch 4 Global steps: 39000 Train loss: 0.2923
en_de Dev loss: 0.8699 r:0.1833
en_zh Dev loss: 0.7893 r:0.4548
ro_en Dev loss: 0.3281 r:0.8197
et_en Dev loss: 0.4362 r:0.6747
si_en Dev loss: 0.7976 r:0.5724
ne_en Dev loss: 0.7539 r:0.7058
ru_en Dev loss: 0.4364 r:0.7268
Current avg r:0.5911 Best avg r: 0.6297
23:04:39,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:07,913 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:51,221 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3018
en_de Dev loss: 0.8720 r:0.2138
en_zh Dev loss: 0.7651 r:0.4561
ro_en Dev loss: 0.3424 r:0.8186
et_en Dev loss: 0.4464 r:0.6749
si_en Dev loss: 0.8550 r:0.5687
ne_en Dev loss: 0.8124 r:0.7065
ru_en Dev loss: 0.4685 r:0.7102
Current avg r:0.5927 Best avg r: 0.6297
23:12:16,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:45,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:28,856 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3055
en_de Dev loss: 0.8618 r:0.2276
en_zh Dev loss: 0.8024 r:0.4586
ro_en Dev loss: 0.3442 r:0.8230
et_en Dev loss: 0.4763 r:0.6845
si_en Dev loss: 0.7356 r:0.5776
ne_en Dev loss: 0.9817 r:0.7125
ru_en Dev loss: 0.4178 r:0.7458
Current avg r:0.6042 Best avg r: 0.6297
23:19:54,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:23,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:07,136 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3054
en_de Dev loss: 0.8555 r:0.2191
en_zh Dev loss: 0.7574 r:0.4359
ro_en Dev loss: 0.3195 r:0.8175
et_en Dev loss: 0.4132 r:0.6793
si_en Dev loss: 0.7408 r:0.5672
ne_en Dev loss: 0.7293 r:0.6935
ru_en Dev loss: 0.4397 r:0.7193
Current avg r:0.5902 Best avg r: 0.6297
23:27:33,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:01,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:45,581 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3179
en_de Dev loss: 0.8558 r:0.2291
en_zh Dev loss: 0.7379 r:0.4783
ro_en Dev loss: 0.3288 r:0.8238
et_en Dev loss: 0.4348 r:0.6888
si_en Dev loss: 0.7451 r:0.5811
ne_en Dev loss: 0.8084 r:0.7113
ru_en Dev loss: 0.3999 r:0.7537
Current avg r:0.6094 Best avg r: 0.6297
23:35:11,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:40,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:24,319 root INFO Epoch 4 Global steps: 42000 Train loss: 0.2911
en_de Dev loss: 0.8677 r:0.2003
en_zh Dev loss: 0.7779 r:0.4500
ro_en Dev loss: 0.3536 r:0.8200
et_en Dev loss: 0.4424 r:0.6800
si_en Dev loss: 0.8667 r:0.5627
ne_en Dev loss: 0.7568 r:0.7011
ru_en Dev loss: 0.4361 r:0.7429
Current avg r:0.5939 Best avg r: 0.6297
23:42:50,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:19,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:03,283 root INFO Epoch 4 Global steps: 42600 Train loss: 0.2831
en_de Dev loss: 0.8602 r:0.2205
en_zh Dev loss: 0.7469 r:0.4590
ro_en Dev loss: 0.3271 r:0.8235
et_en Dev loss: 0.4256 r:0.6826
si_en Dev loss: 0.7585 r:0.5723
ne_en Dev loss: 0.7931 r:0.7093
ru_en Dev loss: 0.4216 r:0.7467
Current avg r:0.6020 Best avg r: 0.6297
23:50:29,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:58,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:42,120 root INFO Epoch 4 Global steps: 43200 Train loss: 0.2797
en_de Dev loss: 0.8552 r:0.2269
en_zh Dev loss: 0.7508 r:0.4566
ro_en Dev loss: 0.3268 r:0.8201
et_en Dev loss: 0.4522 r:0.6804
si_en Dev loss: 0.7397 r:0.5730
ne_en Dev loss: 0.9044 r:0.7119
ru_en Dev loss: 0.4116 r:0.7468
Current avg r:0.6022 Best avg r: 0.6297
23:58:08,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:36,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:20,774 root INFO Epoch 4 Global steps: 43800 Train loss: 0.2927
en_de Dev loss: 0.8617 r:0.2213
en_zh Dev loss: 0.7612 r:0.4459
ro_en Dev loss: 0.3080 r:0.8259
et_en Dev loss: 0.4284 r:0.6785
si_en Dev loss: 0.7549 r:0.5672
ne_en Dev loss: 0.7960 r:0.6980
ru_en Dev loss: 0.4107 r:0.7496
Current avg r:0.5980 Best avg r: 0.6297
00:05:47,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:16,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:59,838 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2800
en_de Dev loss: 0.8630 r:0.2167
en_zh Dev loss: 0.7936 r:0.4547
ro_en Dev loss: 0.3732 r:0.8195
et_en Dev loss: 0.5072 r:0.6782
si_en Dev loss: 0.8069 r:0.5708
ne_en Dev loss: 0.9934 r:0.7041
ru_en Dev loss: 0.4479 r:0.7385
Current avg r:0.5975 Best avg r: 0.6297
00:13:26,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:55,34 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:16:38,735 root INFO Epoch 4 Global steps: 45000 Train loss: 0.2993
en_de Dev loss: 0.8515 r:0.2263
en_zh Dev loss: 0.7327 r:0.4598
ro_en Dev loss: 0.3534 r:0.8205
et_en Dev loss: 0.4319 r:0.6723
si_en Dev loss: 0.8609 r:0.5592
ne_en Dev loss: 0.6886 r:0.6949
ru_en Dev loss: 0.4446 r:0.7294
Current avg r:0.5946 Best avg r: 0.6297
00:21:06,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:35,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:24:18,775 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2492
en_de Dev loss: 0.8709 r:0.1885
en_zh Dev loss: 0.7909 r:0.4435
ro_en Dev loss: 0.3516 r:0.8166
et_en Dev loss: 0.4784 r:0.6674
si_en Dev loss: 0.9032 r:0.5445
ne_en Dev loss: 0.8720 r:0.6892
ru_en Dev loss: 0.4530 r:0.7241
Current avg r:0.5820 Best avg r: 0.6297
00:28:45,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:30:14,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:58,545 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2579
en_de Dev loss: 0.8827 r:0.2029
en_zh Dev loss: 0.8092 r:0.4527
ro_en Dev loss: 0.3357 r:0.8184
et_en Dev loss: 0.4997 r:0.6694
si_en Dev loss: 0.7943 r:0.5626
ne_en Dev loss: 0.9864 r:0.6991
ru_en Dev loss: 0.4988 r:0.7127
Current avg r:0.5882 Best avg r: 0.6297
00:36:24,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:54,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:38,106 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2455
en_de Dev loss: 0.8618 r:0.2182
en_zh Dev loss: 0.7660 r:0.4503
ro_en Dev loss: 0.3472 r:0.8175
et_en Dev loss: 0.4415 r:0.6730
si_en Dev loss: 0.8527 r:0.5571
ne_en Dev loss: 0.7224 r:0.6940
ru_en Dev loss: 0.4588 r:0.7238
Current avg r:0.5906 Best avg r: 0.6297
00:44:04,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:33,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:17,340 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2638
en_de Dev loss: 0.8726 r:0.1865
en_zh Dev loss: 0.7648 r:0.4438
ro_en Dev loss: 0.3428 r:0.8208
et_en Dev loss: 0.4920 r:0.6681
si_en Dev loss: 0.8135 r:0.5611
ne_en Dev loss: 0.9408 r:0.6968
ru_en Dev loss: 0.4478 r:0.7299
Current avg r:0.5867 Best avg r: 0.6297
00:51:43,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:12,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:56,973 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2499
en_de Dev loss: 0.8601 r:0.2119
en_zh Dev loss: 0.7846 r:0.4602
ro_en Dev loss: 0.3634 r:0.8142
et_en Dev loss: 0.4794 r:0.6624
si_en Dev loss: 0.8673 r:0.5529
ne_en Dev loss: 0.7744 r:0.6977
ru_en Dev loss: 0.4543 r:0.7256
Current avg r:0.5893 Best avg r: 0.6297
00:59:23,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:52,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:36,214 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2478
en_de Dev loss: 0.8599 r:0.2051
en_zh Dev loss: 0.7779 r:0.4383
ro_en Dev loss: 0.3427 r:0.8209
et_en Dev loss: 0.5530 r:0.6772
si_en Dev loss: 0.7222 r:0.5712
ne_en Dev loss: 1.1583 r:0.7092
ru_en Dev loss: 0.3995 r:0.7433
Current avg r:0.5950 Best avg r: 0.6297
01:07:02,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:31,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:14,941 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2514
en_de Dev loss: 0.8793 r:0.2212
en_zh Dev loss: 0.7755 r:0.4505
ro_en Dev loss: 0.3212 r:0.8232
et_en Dev loss: 0.4847 r:0.6724
si_en Dev loss: 0.7591 r:0.5682
ne_en Dev loss: 0.8846 r:0.7070
ru_en Dev loss: 0.4169 r:0.7446
Current avg r:0.5982 Best avg r: 0.6297
01:14:41,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:10,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:53,910 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2527
en_de Dev loss: 0.8663 r:0.2014
en_zh Dev loss: 0.7597 r:0.4503
ro_en Dev loss: 0.3284 r:0.8198
et_en Dev loss: 0.4725 r:0.6634
si_en Dev loss: 0.7926 r:0.5615
ne_en Dev loss: 0.8635 r:0.6997
ru_en Dev loss: 0.3961 r:0.7449
Current avg r:0.5916 Best avg r: 0.6297
01:22:20,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:48,880 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:32,508 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2563
en_de Dev loss: 0.8659 r:0.2151
en_zh Dev loss: 0.8231 r:0.4626
ro_en Dev loss: 0.3603 r:0.8189
et_en Dev loss: 0.5526 r:0.6716
si_en Dev loss: 0.7672 r:0.5646
ne_en Dev loss: 1.0902 r:0.7110
ru_en Dev loss: 0.4159 r:0.7428
Current avg r:0.5981 Best avg r: 0.6297
01:29:58,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:27,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:33:11,710 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2552
en_de Dev loss: 0.8807 r:0.1735
en_zh Dev loss: 0.7713 r:0.4444
ro_en Dev loss: 0.3453 r:0.8152
et_en Dev loss: 0.4681 r:0.6530
si_en Dev loss: 0.8945 r:0.5423
ne_en Dev loss: 0.7382 r:0.6875
ru_en Dev loss: 0.4294 r:0.7285
Current avg r:0.5778 Best avg r: 0.6297
01:37:37,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:39:06,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:40:50,559 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2551
en_de Dev loss: 0.8627 r:0.2114
en_zh Dev loss: 0.7526 r:0.4671
ro_en Dev loss: 0.3488 r:0.8196
et_en Dev loss: 0.4720 r:0.6693
si_en Dev loss: 0.8441 r:0.5581
ne_en Dev loss: 0.7609 r:0.7045
ru_en Dev loss: 0.4369 r:0.7376
Current avg r:0.5954 Best avg r: 0.6297
01:45:16,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:46:45,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:48:29,460 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2414
en_de Dev loss: 0.8872 r:0.2005
en_zh Dev loss: 0.8063 r:0.4443
ro_en Dev loss: 0.3583 r:0.8161
et_en Dev loss: 0.4728 r:0.6609
si_en Dev loss: 0.8661 r:0.5526
ne_en Dev loss: 0.7380 r:0.6966
ru_en Dev loss: 0.4806 r:0.7259
Current avg r:0.5853 Best avg r: 0.6297
01:52:55,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:54:24,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:56:08,241 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2475
en_de Dev loss: 0.8767 r:0.2123
en_zh Dev loss: 0.7575 r:0.4551
ro_en Dev loss: 0.3188 r:0.8190
et_en Dev loss: 0.4990 r:0.6676
si_en Dev loss: 0.7732 r:0.5628
ne_en Dev loss: 0.8382 r:0.7147
ru_en Dev loss: 0.4460 r:0.7331
Current avg r:0.5949 Best avg r: 0.6297
02:00:34,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:02:03,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:03:46,758 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2473
en_de Dev loss: 0.8819 r:0.2110
en_zh Dev loss: 0.7893 r:0.4429
ro_en Dev loss: 0.3418 r:0.8175
et_en Dev loss: 0.4766 r:0.6603
si_en Dev loss: 0.8845 r:0.5514
ne_en Dev loss: 0.7390 r:0.7024
ru_en Dev loss: 0.4485 r:0.7360
Current avg r:0.5888 Best avg r: 0.6297
02:08:12,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:09:41,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:11:25,591 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2398
en_de Dev loss: 0.8793 r:0.2188
en_zh Dev loss: 0.7422 r:0.4611
ro_en Dev loss: 0.3457 r:0.8164
et_en Dev loss: 0.4743 r:0.6598
si_en Dev loss: 0.8698 r:0.5575
ne_en Dev loss: 0.7118 r:0.7002
ru_en Dev loss: 0.4232 r:0.7501
Current avg r:0.5948 Best avg r: 0.6297
02:15:52,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:17:21,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:04,930 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2227
en_de Dev loss: 0.8595 r:0.2129
en_zh Dev loss: 0.7656 r:0.4585
ro_en Dev loss: 0.3525 r:0.8193
et_en Dev loss: 0.4916 r:0.6645
si_en Dev loss: 0.7607 r:0.5674
ne_en Dev loss: 0.8248 r:0.7003
ru_en Dev loss: 0.4040 r:0.7518
Current avg r:0.5964 Best avg r: 0.6297
02:23:31,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:59,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:26:43,438 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2201
en_de Dev loss: 0.8615 r:0.2016
en_zh Dev loss: 0.7562 r:0.4497
ro_en Dev loss: 0.3596 r:0.8155
et_en Dev loss: 0.5231 r:0.6544
si_en Dev loss: 0.7995 r:0.5582
ne_en Dev loss: 0.9053 r:0.6968
ru_en Dev loss: 0.4292 r:0.7354
Current avg r:0.5874 Best avg r: 0.6297
02:31:09,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:32:38,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:34:22,599 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2205
en_de Dev loss: 0.8745 r:0.1942
en_zh Dev loss: 0.7640 r:0.4377
ro_en Dev loss: 0.3389 r:0.8178
et_en Dev loss: 0.5308 r:0.6582
si_en Dev loss: 0.7867 r:0.5497
ne_en Dev loss: 0.9559 r:0.6976
ru_en Dev loss: 0.4004 r:0.7472
Current avg r:0.5860 Best avg r: 0.6297
02:38:49,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:40:18,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:42:02,100 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2131
en_de Dev loss: 0.8813 r:0.2104
en_zh Dev loss: 0.7931 r:0.4343
ro_en Dev loss: 0.3734 r:0.8135
et_en Dev loss: 0.5094 r:0.6506
si_en Dev loss: 0.9337 r:0.5373
ne_en Dev loss: 0.8535 r:0.6834
ru_en Dev loss: 0.4543 r:0.7317
Current avg r:0.5802 Best avg r: 0.6297
02:46:28,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:47:57,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:49:41,256 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2190
en_de Dev loss: 0.8925 r:0.2106
en_zh Dev loss: 0.7925 r:0.4407
ro_en Dev loss: 0.3670 r:0.8144
et_en Dev loss: 0.5047 r:0.6594
si_en Dev loss: 0.8390 r:0.5514
ne_en Dev loss: 0.9040 r:0.6980
ru_en Dev loss: 0.4102 r:0.7511
Current avg r:0.5894 Best avg r: 0.6297
02:54:07,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:55:36,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:57:21,241 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2206
en_de Dev loss: 0.8728 r:0.2192
en_zh Dev loss: 0.7708 r:0.4579
ro_en Dev loss: 0.3525 r:0.8162
et_en Dev loss: 0.5196 r:0.6592
si_en Dev loss: 0.7866 r:0.5591
ne_en Dev loss: 0.9815 r:0.7004
ru_en Dev loss: 0.4116 r:0.7445
Current avg r:0.5938 Best avg r: 0.6297
03:01:47,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:16,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:05:00,645 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2285
en_de Dev loss: 0.8760 r:0.2026
en_zh Dev loss: 0.8153 r:0.4358
ro_en Dev loss: 0.3532 r:0.8132
et_en Dev loss: 0.5013 r:0.6620
si_en Dev loss: 0.8249 r:0.5522
ne_en Dev loss: 0.8474 r:0.6978
ru_en Dev loss: 0.4300 r:0.7427
Current avg r:0.5866 Best avg r: 0.6297
03:09:26,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:56,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:12:39,748 root INFO Epoch 6 Global steps: 58800 Train loss: 0.1954
en_de Dev loss: 0.8735 r:0.2140
en_zh Dev loss: 0.7571 r:0.4543
ro_en Dev loss: 0.3465 r:0.8134
et_en Dev loss: 0.4953 r:0.6584
si_en Dev loss: 0.8230 r:0.5473
ne_en Dev loss: 0.8063 r:0.6916
ru_en Dev loss: 0.4188 r:0.7368
Current avg r:0.5880 Best avg r: 0.6297
03:17:05,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:18:34,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:20:18,333 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2198
en_de Dev loss: 0.8808 r:0.2214
en_zh Dev loss: 0.7811 r:0.4558
ro_en Dev loss: 0.3397 r:0.8174
et_en Dev loss: 0.5173 r:0.6655
si_en Dev loss: 0.7767 r:0.5590
ne_en Dev loss: 0.9584 r:0.7035
ru_en Dev loss: 0.3909 r:0.7519
Current avg r:0.5964 Best avg r: 0.6297
03:24:44,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:26:13,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:27:57,313 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2261
en_de Dev loss: 0.8872 r:0.1912
en_zh Dev loss: 0.7746 r:0.4473
ro_en Dev loss: 0.3407 r:0.8162
et_en Dev loss: 0.5116 r:0.6663
si_en Dev loss: 0.7852 r:0.5523
ne_en Dev loss: 0.9003 r:0.6966
ru_en Dev loss: 0.4128 r:0.7445
Current avg r:0.5878 Best avg r: 0.6297
03:32:23,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:33:52,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:35:36,100 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2119
en_de Dev loss: 0.8852 r:0.1940
en_zh Dev loss: 0.8178 r:0.4441
ro_en Dev loss: 0.3691 r:0.8132
et_en Dev loss: 0.5057 r:0.6493
si_en Dev loss: 0.9555 r:0.5348
ne_en Dev loss: 0.8119 r:0.6805
ru_en Dev loss: 0.4447 r:0.7317
Current avg r:0.5782 Best avg r: 0.6297
03:40:01,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:41:30,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:43:14,706 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2157
en_de Dev loss: 0.8897 r:0.1939
en_zh Dev loss: 0.7828 r:0.4406
ro_en Dev loss: 0.3368 r:0.8161
et_en Dev loss: 0.4763 r:0.6479
si_en Dev loss: 0.8703 r:0.5377
ne_en Dev loss: 0.7429 r:0.6835
ru_en Dev loss: 0.4278 r:0.7406
Current avg r:0.5801 Best avg r: 0.6297
03:47:40,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:49:09,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:50:53,20 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2070
en_de Dev loss: 0.8831 r:0.1847
en_zh Dev loss: 0.7884 r:0.4369
ro_en Dev loss: 0.3488 r:0.8187
et_en Dev loss: 0.5130 r:0.6496
si_en Dev loss: 0.7834 r:0.5489
ne_en Dev loss: 0.9225 r:0.6946
ru_en Dev loss: 0.4181 r:0.7410
Current avg r:0.5821 Best avg r: 0.6297
03:55:18,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:56:47,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:58:31,226 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2088
en_de Dev loss: 0.8843 r:0.1988
en_zh Dev loss: 0.7765 r:0.4534
ro_en Dev loss: 0.3474 r:0.8175
et_en Dev loss: 0.5160 r:0.6504
si_en Dev loss: 0.8522 r:0.5405
ne_en Dev loss: 0.9016 r:0.6906
ru_en Dev loss: 0.4334 r:0.7312
Current avg r:0.5832 Best avg r: 0.6297
04:02:56,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:25,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:06:09,669 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2183
en_de Dev loss: 0.8832 r:0.2127
en_zh Dev loss: 0.8087 r:0.4546
ro_en Dev loss: 0.3466 r:0.8192
et_en Dev loss: 0.5166 r:0.6543
si_en Dev loss: 0.8715 r:0.5349
ne_en Dev loss: 0.8247 r:0.6935
ru_en Dev loss: 0.4531 r:0.7334
Current avg r:0.5861 Best avg r: 0.6297
04:10:36,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:12:05,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:13:48,999 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1864
en_de Dev loss: 0.8913 r:0.2132
en_zh Dev loss: 0.8288 r:0.4486
ro_en Dev loss: 0.3718 r:0.8167
et_en Dev loss: 0.5128 r:0.6514
si_en Dev loss: 0.8767 r:0.5369
ne_en Dev loss: 0.8425 r:0.6933
ru_en Dev loss: 0.4900 r:0.7196
Current avg r:0.5828 Best avg r: 0.6297
04:18:14,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:19:43,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:21:27,75 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1966
en_de Dev loss: 0.8725 r:0.2215
en_zh Dev loss: 0.7927 r:0.4565
ro_en Dev loss: 0.4090 r:0.8144
et_en Dev loss: 0.5110 r:0.6428
si_en Dev loss: 0.9079 r:0.5378
ne_en Dev loss: 0.8121 r:0.6831
ru_en Dev loss: 0.4803 r:0.7259
Current avg r:0.5832 Best avg r: 0.6297
04:25:52,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:27:21,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:29:05,17 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1827
en_de Dev loss: 0.8994 r:0.1960
en_zh Dev loss: 0.8392 r:0.4401
ro_en Dev loss: 0.4088 r:0.8133
et_en Dev loss: 0.4952 r:0.6347
si_en Dev loss: 1.1130 r:0.5110
ne_en Dev loss: 0.6240 r:0.6620
ru_en Dev loss: 0.5429 r:0.7071
Current avg r:0.5663 Best avg r: 0.6297
04:33:30,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:34:59,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:36:43,507 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1993
en_de Dev loss: 0.8706 r:0.2175
en_zh Dev loss: 0.8360 r:0.4502
ro_en Dev loss: 0.3868 r:0.8161
et_en Dev loss: 0.5404 r:0.6577
si_en Dev loss: 0.9004 r:0.5424
ne_en Dev loss: 0.9021 r:0.6923
ru_en Dev loss: 0.4805 r:0.7321
Current avg r:0.5869 Best avg r: 0.6297
04:41:09,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:42:37,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:21,465 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1834
en_de Dev loss: 0.9075 r:0.1900
en_zh Dev loss: 0.8191 r:0.4509
ro_en Dev loss: 0.3843 r:0.8097
et_en Dev loss: 0.4980 r:0.6515
si_en Dev loss: 0.9508 r:0.5290
ne_en Dev loss: 0.7245 r:0.6789
ru_en Dev loss: 0.4995 r:0.7212
Current avg r:0.5759 Best avg r: 0.6297
04:48:46,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:16,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:59,722 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1823
en_de Dev loss: 0.8833 r:0.2244
en_zh Dev loss: 0.7532 r:0.4760
ro_en Dev loss: 0.3264 r:0.8208
et_en Dev loss: 0.5040 r:0.6645
si_en Dev loss: 0.7848 r:0.5435
ne_en Dev loss: 0.9365 r:0.6911
ru_en Dev loss: 0.3891 r:0.7525
Current avg r:0.5961 Best avg r: 0.6297
04:56:25,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:54,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:59:38,25 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1858
en_de Dev loss: 0.9058 r:0.2001
en_zh Dev loss: 0.7670 r:0.4687
ro_en Dev loss: 0.3373 r:0.8202
et_en Dev loss: 0.5212 r:0.6654
si_en Dev loss: 0.8052 r:0.5444
ne_en Dev loss: 0.9605 r:0.6962
ru_en Dev loss: 0.4076 r:0.7463
Current avg r:0.5916 Best avg r: 0.6297
05:04:03,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:05:31,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:07:15,422 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1920
en_de Dev loss: 0.8945 r:0.1944
en_zh Dev loss: 0.7456 r:0.4607
ro_en Dev loss: 0.3110 r:0.8213
et_en Dev loss: 0.4822 r:0.6574
si_en Dev loss: 0.7822 r:0.5416
ne_en Dev loss: 0.8046 r:0.6898
ru_en Dev loss: 0.3880 r:0.7501
Current avg r:0.5879 Best avg r: 0.6297
05:11:41,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:13:10,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:14:53,741 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1917
en_de Dev loss: 0.8864 r:0.1934
en_zh Dev loss: 0.8209 r:0.4426
ro_en Dev loss: 0.3496 r:0.8183
et_en Dev loss: 0.5105 r:0.6509
si_en Dev loss: 0.9338 r:0.5250
ne_en Dev loss: 0.7922 r:0.6798
ru_en Dev loss: 0.4079 r:0.7531
Current avg r:0.5804 Best avg r: 0.6297
05:19:19,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:47,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:22:31,614 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1798
en_de Dev loss: 0.8982 r:0.2112
en_zh Dev loss: 0.8416 r:0.4509
ro_en Dev loss: 0.3827 r:0.8134
et_en Dev loss: 0.5458 r:0.6562
si_en Dev loss: 0.9751 r:0.5293
ne_en Dev loss: 0.8586 r:0.6870
ru_en Dev loss: 0.4715 r:0.7415
Current avg r:0.5842 Best avg r: 0.6297
05:26:57,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:26,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:09,819 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1952
en_de Dev loss: 0.8973 r:0.2033
en_zh Dev loss: 0.8171 r:0.4513
ro_en Dev loss: 0.3458 r:0.8135
et_en Dev loss: 0.5334 r:0.6612
si_en Dev loss: 0.8810 r:0.5331
ne_en Dev loss: 0.9163 r:0.6914
ru_en Dev loss: 0.4252 r:0.7453
Current avg r:0.5856 Best avg r: 0.6297
05:34:35,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:03,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:37:47,658 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1871
en_de Dev loss: 0.8929 r:0.1814
en_zh Dev loss: 0.7440 r:0.4503
ro_en Dev loss: 0.3329 r:0.8134
et_en Dev loss: 0.5006 r:0.6525
si_en Dev loss: 0.8815 r:0.5172
ne_en Dev loss: 0.8913 r:0.6837
ru_en Dev loss: 0.3986 r:0.7412
Current avg r:0.5771 Best avg r: 0.6297
05:42:13,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:42,201 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:25,967 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1817
en_de Dev loss: 0.8862 r:0.2076
en_zh Dev loss: 0.7489 r:0.4676
ro_en Dev loss: 0.3410 r:0.8167
et_en Dev loss: 0.4894 r:0.6517
si_en Dev loss: 0.8516 r:0.5334
ne_en Dev loss: 0.8418 r:0.6876
ru_en Dev loss: 0.3867 r:0.7604
Current avg r:0.5893 Best avg r: 0.6297
05:49:52,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:20,772 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:04,488 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1850
en_de Dev loss: 0.8827 r:0.1924
en_zh Dev loss: 0.8035 r:0.4491
ro_en Dev loss: 0.3468 r:0.8156
et_en Dev loss: 0.4810 r:0.6452
si_en Dev loss: 0.9178 r:0.5211
ne_en Dev loss: 0.7559 r:0.6727
ru_en Dev loss: 0.4644 r:0.7323
Current avg r:0.5755 Best avg r: 0.6297
05:57:30,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:58:59,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:00:43,710 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1803
en_de Dev loss: 0.8800 r:0.1968
en_zh Dev loss: 0.7940 r:0.4442
ro_en Dev loss: 0.3543 r:0.8136
et_en Dev loss: 0.5101 r:0.6379
si_en Dev loss: 0.9229 r:0.5136
ne_en Dev loss: 0.8400 r:0.6714
ru_en Dev loss: 0.4348 r:0.7319
Current avg r:0.5728 Best avg r: 0.6297
06:05:10,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:06:39,785 root INFO 
id:ru_en cur r: 0.7784 best r: 0.7784
06:06:39,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:23,521 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1623
en_de Dev loss: 0.8901 r:0.2310
en_zh Dev loss: 0.7615 r:0.4637
ro_en Dev loss: 0.3298 r:0.8192
et_en Dev loss: 0.5449 r:0.6629
si_en Dev loss: 0.7937 r:0.5414
ne_en Dev loss: 0.9737 r:0.6997
ru_en Dev loss: 0.3527 r:0.7714
Current avg r:0.5985 Best avg r: 0.6297
06:12:49,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:18,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:16:02,785 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1568
en_de Dev loss: 0.8792 r:0.2533
en_zh Dev loss: 0.8274 r:0.4707
ro_en Dev loss: 0.3505 r:0.8195
et_en Dev loss: 0.5903 r:0.6720
si_en Dev loss: 0.8213 r:0.5434
ne_en Dev loss: 1.1126 r:0.7049
ru_en Dev loss: 0.3744 r:0.7678
Current avg r:0.6045 Best avg r: 0.6297
06:20:29,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:21:58,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:42,268 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1624
en_de Dev loss: 0.8774 r:0.2281
en_zh Dev loss: 0.7904 r:0.4479
ro_en Dev loss: 0.3539 r:0.8125
et_en Dev loss: 0.4919 r:0.6547
si_en Dev loss: 0.9069 r:0.5185
ne_en Dev loss: 0.8137 r:0.6876
ru_en Dev loss: 0.4238 r:0.7445
Current avg r:0.5848 Best avg r: 0.6297
06:28:08,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:37,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:21,164 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1547
en_de Dev loss: 0.8697 r:0.2133
en_zh Dev loss: 0.7956 r:0.4463
ro_en Dev loss: 0.3490 r:0.8116
et_en Dev loss: 0.5006 r:0.6491
si_en Dev loss: 0.8666 r:0.5253
ne_en Dev loss: 0.8139 r:0.6900
ru_en Dev loss: 0.4265 r:0.7376
Current avg r:0.5819 Best avg r: 0.6297
06:35:47,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:16,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:00,269 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1682
en_de Dev loss: 0.8744 r:0.2169
en_zh Dev loss: 0.8087 r:0.4395
ro_en Dev loss: 0.3620 r:0.8144
et_en Dev loss: 0.5101 r:0.6482
si_en Dev loss: 0.9401 r:0.5140
ne_en Dev loss: 0.8141 r:0.6770
ru_en Dev loss: 0.4516 r:0.7356
Current avg r:0.5779 Best avg r: 0.6297
06:43:26,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:44:55,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:39,537 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1677
en_de Dev loss: 0.9082 r:0.1758
en_zh Dev loss: 0.8474 r:0.4290
ro_en Dev loss: 0.3666 r:0.8112
et_en Dev loss: 0.5015 r:0.6418
si_en Dev loss: 0.9324 r:0.5134
ne_en Dev loss: 0.7182 r:0.6750
ru_en Dev loss: 0.4775 r:0.7265
Current avg r:0.5675 Best avg r: 0.6297
06:51:05,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:35,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:54:19,68 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1576
en_de Dev loss: 0.9051 r:0.1818
en_zh Dev loss: 0.8231 r:0.4547
ro_en Dev loss: 0.3663 r:0.8151
et_en Dev loss: 0.5554 r:0.6503
si_en Dev loss: 0.9040 r:0.5263
ne_en Dev loss: 0.9616 r:0.6992
ru_en Dev loss: 0.4270 r:0.7508
Current avg r:0.5826 Best avg r: 0.6297
06:58:45,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:14,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:58,428 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1597
en_de Dev loss: 0.9359 r:0.1996
en_zh Dev loss: 0.7761 r:0.4799
ro_en Dev loss: 0.3491 r:0.8161
et_en Dev loss: 0.5093 r:0.6460
si_en Dev loss: 0.9162 r:0.5238
ne_en Dev loss: 0.7688 r:0.6898
ru_en Dev loss: 0.4239 r:0.7543
Current avg r:0.5871 Best avg r: 0.6297
07:06:24,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:07:54,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:09:37,965 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1600
en_de Dev loss: 0.9295 r:0.1742
en_zh Dev loss: 0.8342 r:0.4526
ro_en Dev loss: 0.3706 r:0.8165
et_en Dev loss: 0.5091 r:0.6465
si_en Dev loss: 0.9158 r:0.5257
ne_en Dev loss: 0.7728 r:0.6905
ru_en Dev loss: 0.4172 r:0.7587
Current avg r:0.5807 Best avg r: 0.6297
07:14:04,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:15:33,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:17,362 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1589
en_de Dev loss: 0.8856 r:0.1847
en_zh Dev loss: 0.7557 r:0.4619
ro_en Dev loss: 0.3496 r:0.8125
et_en Dev loss: 0.5228 r:0.6405
si_en Dev loss: 0.9110 r:0.5204
ne_en Dev loss: 0.8665 r:0.6864
ru_en Dev loss: 0.4184 r:0.7384
Current avg r:0.5778 Best avg r: 0.6297
07:21:43,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:23:12,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:24:56,871 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1585
en_de Dev loss: 0.8961 r:0.1796
en_zh Dev loss: 0.7791 r:0.4509
ro_en Dev loss: 0.3607 r:0.8138
et_en Dev loss: 0.5087 r:0.6419
si_en Dev loss: 0.9598 r:0.5218
ne_en Dev loss: 0.8090 r:0.6893
ru_en Dev loss: 0.4275 r:0.7360
Current avg r:0.5762 Best avg r: 0.6297
07:29:23,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:30:52,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:36,349 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1556
en_de Dev loss: 0.8964 r:0.2034
en_zh Dev loss: 0.7832 r:0.4663
ro_en Dev loss: 0.3682 r:0.8127
et_en Dev loss: 0.5263 r:0.6449
si_en Dev loss: 0.8813 r:0.5304
ne_en Dev loss: 0.8810 r:0.6970
ru_en Dev loss: 0.3903 r:0.7575
Current avg r:0.5874 Best avg r: 0.6297
07:37:02,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:31,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:40:16,116 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1641
en_de Dev loss: 0.9173 r:0.1524
en_zh Dev loss: 0.8175 r:0.4489
ro_en Dev loss: 0.3835 r:0.8110
et_en Dev loss: 0.5352 r:0.6388
si_en Dev loss: 0.9455 r:0.5195
ne_en Dev loss: 0.8318 r:0.6834
ru_en Dev loss: 0.4302 r:0.7499
Current avg r:0.5720 Best avg r: 0.6297
07:44:42,486 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:46:11,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:47:55,440 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1626
en_de Dev loss: 0.9496 r:0.1772
en_zh Dev loss: 0.8076 r:0.4504
ro_en Dev loss: 0.3498 r:0.8132
et_en Dev loss: 0.5136 r:0.6412
si_en Dev loss: 0.9368 r:0.5170
ne_en Dev loss: 0.8357 r:0.6876
ru_en Dev loss: 0.4598 r:0.7377
Current avg r:0.5749 Best avg r: 0.6297
07:52:21,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:53:50,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:34,966 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1509
en_de Dev loss: 0.9022 r:0.1817
en_zh Dev loss: 0.7987 r:0.4534
ro_en Dev loss: 0.3670 r:0.8141
et_en Dev loss: 0.5165 r:0.6504
si_en Dev loss: 0.9070 r:0.5211
ne_en Dev loss: 0.8769 r:0.6944
ru_en Dev loss: 0.4026 r:0.7571
Current avg r:0.5817 Best avg r: 0.6297
08:00:02,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:01:31,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:15,495 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1544
en_de Dev loss: 0.9051 r:0.1650
en_zh Dev loss: 0.7921 r:0.4631
ro_en Dev loss: 0.3578 r:0.8143
et_en Dev loss: 0.4911 r:0.6530
si_en Dev loss: 0.9091 r:0.5216
ne_en Dev loss: 0.8203 r:0.6894
ru_en Dev loss: 0.4189 r:0.7543
Current avg r:0.5801 Best avg r: 0.6297
08:07:41,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:10,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:54,182 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1427
en_de Dev loss: 0.9153 r:0.1407
en_zh Dev loss: 0.7772 r:0.4633
ro_en Dev loss: 0.3673 r:0.8100
et_en Dev loss: 0.4917 r:0.6370
si_en Dev loss: 1.0083 r:0.5056
ne_en Dev loss: 0.7692 r:0.6727
ru_en Dev loss: 0.4342 r:0.7427
Current avg r:0.5674 Best avg r: 0.6297
08:15:20,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:16:49,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:18:33,446 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1456
en_de Dev loss: 0.9103 r:0.1680
en_zh Dev loss: 0.7721 r:0.4692
ro_en Dev loss: 0.3487 r:0.8107
et_en Dev loss: 0.5090 r:0.6450
si_en Dev loss: 0.8679 r:0.5238
ne_en Dev loss: 0.8612 r:0.6866
ru_en Dev loss: 0.4008 r:0.7571
Current avg r:0.5801 Best avg r: 0.6297
08:22:59,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:24:28,815 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:12,895 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1409
en_de Dev loss: 0.9021 r:0.1719
en_zh Dev loss: 0.7618 r:0.4675
ro_en Dev loss: 0.3376 r:0.8107
et_en Dev loss: 0.4912 r:0.6384
si_en Dev loss: 0.8733 r:0.5253
ne_en Dev loss: 0.8193 r:0.6804
ru_en Dev loss: 0.4292 r:0.7414
Current avg r:0.5765 Best avg r: 0.6297
08:30:39,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:32:08,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:33:52,727 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1563
en_de Dev loss: 0.8767 r:0.2004
en_zh Dev loss: 0.7625 r:0.4740
ro_en Dev loss: 0.3510 r:0.8116
et_en Dev loss: 0.4923 r:0.6444
si_en Dev loss: 0.8806 r:0.5244
ne_en Dev loss: 0.8598 r:0.6767
ru_en Dev loss: 0.4147 r:0.7433
Current avg r:0.5821 Best avg r: 0.6297
08:38:19,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:39:48,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:32,307 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1465
en_de Dev loss: 0.9074 r:0.1880
en_zh Dev loss: 0.7971 r:0.4698
ro_en Dev loss: 0.3724 r:0.8100
et_en Dev loss: 0.5059 r:0.6329
si_en Dev loss: 0.9617 r:0.5146
ne_en Dev loss: 0.6892 r:0.6719
ru_en Dev loss: 0.4640 r:0.7438
Current avg r:0.5759 Best avg r: 0.6297
08:45:58,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:27,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:11,541 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1473
en_de Dev loss: 0.9204 r:0.1923
en_zh Dev loss: 0.7924 r:0.4796
ro_en Dev loss: 0.3931 r:0.8115
et_en Dev loss: 0.5225 r:0.6406
si_en Dev loss: 0.9555 r:0.5201
ne_en Dev loss: 0.8708 r:0.6842
ru_en Dev loss: 0.4402 r:0.7461
Current avg r:0.5821 Best avg r: 0.6297
08:53:37,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:54:07,503 root INFO 
id:en_zh cur r: 0.4922 best r: 0.4922
08:55:06,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:50,601 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1423
en_de Dev loss: 0.8949 r:0.2222
en_zh Dev loss: 0.7473 r:0.4891
ro_en Dev loss: 0.3618 r:0.8097
et_en Dev loss: 0.4956 r:0.6483
si_en Dev loss: 0.8226 r:0.5331
ne_en Dev loss: 0.8142 r:0.6949
ru_en Dev loss: 0.3811 r:0.7645
Current avg r:0.5946 Best avg r: 0.6297
09:01:16,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:45,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:04:30,26 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1490
en_de Dev loss: 0.9277 r:0.1805
en_zh Dev loss: 0.7622 r:0.4723
ro_en Dev loss: 0.3679 r:0.8103
et_en Dev loss: 0.4977 r:0.6499
si_en Dev loss: 0.9068 r:0.5199
ne_en Dev loss: 0.8029 r:0.6809
ru_en Dev loss: 0.4148 r:0.7521
Current avg r:0.5809 Best avg r: 0.6297
09:08:56,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:10:25,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:12:09,310 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1426
en_de Dev loss: 0.9191 r:0.1908
en_zh Dev loss: 0.7696 r:0.4736
ro_en Dev loss: 0.3578 r:0.8150
et_en Dev loss: 0.5119 r:0.6569
si_en Dev loss: 0.8830 r:0.5270
ne_en Dev loss: 0.8796 r:0.6922
ru_en Dev loss: 0.4109 r:0.7508
Current avg r:0.5866 Best avg r: 0.6297
09:16:35,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:04,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:48,392 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1383
en_de Dev loss: 0.9307 r:0.1965
en_zh Dev loss: 0.7629 r:0.4769
ro_en Dev loss: 0.3404 r:0.8159
et_en Dev loss: 0.4880 r:0.6585
si_en Dev loss: 0.8407 r:0.5339
ne_en Dev loss: 0.8258 r:0.6912
ru_en Dev loss: 0.4094 r:0.7589
Current avg r:0.5902 Best avg r: 0.6297
09:24:14,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:43,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:27:27,929 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1366
en_de Dev loss: 0.9120 r:0.1845
en_zh Dev loss: 0.7524 r:0.4748
ro_en Dev loss: 0.3463 r:0.8160
et_en Dev loss: 0.5088 r:0.6589
si_en Dev loss: 0.8786 r:0.5287
ne_en Dev loss: 0.8836 r:0.6899
ru_en Dev loss: 0.3854 r:0.7535
Current avg r:0.5866 Best avg r: 0.6297
09:31:54,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:33:23,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:35:07,966 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1425
en_de Dev loss: 0.9249 r:0.1982
en_zh Dev loss: 0.7995 r:0.4760
ro_en Dev loss: 0.3707 r:0.8149
et_en Dev loss: 0.5187 r:0.6547
si_en Dev loss: 0.8800 r:0.5327
ne_en Dev loss: 0.9094 r:0.6879
ru_en Dev loss: 0.4261 r:0.7478
Current avg r:0.5874 Best avg r: 0.6297
09:39:34,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:03,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:42:47,855 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1353
en_de Dev loss: 0.9127 r:0.1715
en_zh Dev loss: 0.7649 r:0.4684
ro_en Dev loss: 0.3423 r:0.8127
et_en Dev loss: 0.4939 r:0.6571
si_en Dev loss: 0.8791 r:0.5287
ne_en Dev loss: 0.8565 r:0.6873
ru_en Dev loss: 0.4116 r:0.7465
Current avg r:0.5817 Best avg r: 0.6297
09:47:14,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:43,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:50:28,95 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1410
en_de Dev loss: 0.9221 r:0.1903
en_zh Dev loss: 0.7610 r:0.4839
ro_en Dev loss: 0.3394 r:0.8133
et_en Dev loss: 0.5456 r:0.6727
si_en Dev loss: 0.7946 r:0.5522
ne_en Dev loss: 1.0604 r:0.7013
ru_en Dev loss: 0.3897 r:0.7572
Current avg r:0.5958 Best avg r: 0.6297
09:54:55,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:24,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:08,992 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1304
en_de Dev loss: 0.9238 r:0.1903
en_zh Dev loss: 0.7862 r:0.4702
ro_en Dev loss: 0.3549 r:0.8107
et_en Dev loss: 0.4997 r:0.6567
si_en Dev loss: 0.8942 r:0.5344
ne_en Dev loss: 0.8047 r:0.6878
ru_en Dev loss: 0.4172 r:0.7481
Current avg r:0.5854 Best avg r: 0.6297
10:02:35,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:04,665 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:48,912 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1292
en_de Dev loss: 0.9220 r:0.2013
en_zh Dev loss: 0.7910 r:0.4737
ro_en Dev loss: 0.3584 r:0.8131
et_en Dev loss: 0.5023 r:0.6649
si_en Dev loss: 0.8241 r:0.5375
ne_en Dev loss: 0.8960 r:0.6873
ru_en Dev loss: 0.4054 r:0.7551
Current avg r:0.5904 Best avg r: 0.6297
10:10:15,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:44,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:13:29,186 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1310
en_de Dev loss: 0.9106 r:0.1760
en_zh Dev loss: 0.7685 r:0.4736
ro_en Dev loss: 0.3392 r:0.8135
et_en Dev loss: 0.4995 r:0.6609
si_en Dev loss: 0.8651 r:0.5330
ne_en Dev loss: 0.8492 r:0.6837
ru_en Dev loss: 0.4014 r:0.7534
Current avg r:0.5848 Best avg r: 0.6297
10:17:55,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:24,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:21:08,947 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1352
en_de Dev loss: 0.8877 r:0.2003
en_zh Dev loss: 0.8199 r:0.4580
ro_en Dev loss: 0.3871 r:0.8100
et_en Dev loss: 0.4913 r:0.6558
si_en Dev loss: 0.9256 r:0.5292
ne_en Dev loss: 0.7721 r:0.6692
ru_en Dev loss: 0.4630 r:0.7417
Current avg r:0.5806 Best avg r: 0.6297
10:25:35,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:04,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:28:48,756 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1217
en_de Dev loss: 0.8896 r:0.2090
en_zh Dev loss: 0.7638 r:0.4755
ro_en Dev loss: 0.3429 r:0.8145
et_en Dev loss: 0.5007 r:0.6677
si_en Dev loss: 0.7897 r:0.5411
ne_en Dev loss: 0.9682 r:0.6934
ru_en Dev loss: 0.3686 r:0.7666
Current avg r:0.5954 Best avg r: 0.6297
