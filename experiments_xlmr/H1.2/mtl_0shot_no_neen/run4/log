14:42:32,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:45,105 root INFO 
id:en_de cur r: 0.0673 best r: 0.0673
14:42:57,943 root INFO 
id:en_zh cur r: 0.2772 best r: 0.2772
14:43:10,819 root INFO 
id:ro_en cur r: 0.4862 best r: 0.4862
14:43:23,708 root INFO 
id:et_en cur r: 0.2622 best r: 0.2622
14:43:36,641 root INFO 
id:si_en cur r: 0.0109 best r: 0.0109
14:43:49,503 root INFO 
id:ru_en cur r: 0.5065 best r: 0.5065
14:43:49,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:19,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:45:19,478 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:45:19,482 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:45:19,487 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:45:19,492 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:45:19,497 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:45:19,503 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:45:32,361 root INFO Epoch 0 Global steps: 600 Train loss: 0.8815
en_de Dev loss: 0.8850 r:0.0785
en_zh Dev loss: 0.7797 r:0.2799
ro_en Dev loss: 0.6837 r:0.5922
et_en Dev loss: 0.6297 r:0.4088
si_en Dev loss: 0.7609 r:0.4153
ne_en Dev loss: 0.6953 r:0.5375
ru_en Dev loss: 0.6804 r:0.4901
Current avg r:0.4003 Best avg r: 0.4003
14:49:23,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:36,343 root INFO 
id:en_de cur r: 0.1139 best r: 0.1139
14:49:49,212 root INFO 
id:en_zh cur r: 0.3133 best r: 0.3133
14:50:02,70 root INFO 
id:ro_en cur r: 0.5869 best r: 0.5869
14:50:14,933 root INFO 
id:et_en cur r: 0.5217 best r: 0.5217
14:50:27,802 root INFO 
id:si_en cur r: 0.4382 best r: 0.4382
14:50:40,619 root INFO 
id:ru_en cur r: 0.6188 best r: 0.6188
14:50:40,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:10,558 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:52:10,563 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:52:10,568 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:52:10,573 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:52:10,578 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:52:10,582 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:52:10,587 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:52:23,528 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7965
en_de Dev loss: 0.8795 r:0.1325
en_zh Dev loss: 0.7371 r:0.3279
ro_en Dev loss: 0.7190 r:0.6330
et_en Dev loss: 0.5326 r:0.5621
si_en Dev loss: 0.8895 r:0.4080
ne_en Dev loss: 0.5840 r:0.6000
ru_en Dev loss: 0.6463 r:0.6124
Current avg r:0.4680 Best avg r: 0.4680
14:56:13,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:26,897 root INFO 
id:en_de cur r: 0.1191 best r: 0.1191
14:56:52,635 root INFO 
id:ro_en cur r: 0.6492 best r: 0.6492
14:57:05,517 root INFO 
id:et_en cur r: 0.5822 best r: 0.5822
14:57:18,411 root INFO 
id:si_en cur r: 0.4622 best r: 0.4622
14:57:31,241 root INFO 
id:ru_en cur r: 0.6613 best r: 0.6613
14:57:31,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:01,561 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:59:01,567 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:59:01,572 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:59:01,577 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:59:01,582 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:59:01,586 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:59:01,590 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:59:14,483 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7793
en_de Dev loss: 0.9375 r:0.1188
en_zh Dev loss: 0.8069 r:0.3132
ro_en Dev loss: 0.6736 r:0.6547
et_en Dev loss: 0.5113 r:0.5991
si_en Dev loss: 0.8448 r:0.4549
ne_en Dev loss: 0.5380 r:0.6412
ru_en Dev loss: 0.6313 r:0.6626
Current avg r:0.4921 Best avg r: 0.4921
15:03:05,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:17,905 root INFO 
id:en_de cur r: 0.1452 best r: 0.1452
15:03:30,752 root INFO 
id:en_zh cur r: 0.3147 best r: 0.3147
15:03:56,544 root INFO 
id:et_en cur r: 0.5864 best r: 0.5864
15:04:22,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:52,464 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:05:52,470 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:05:52,474 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:05:52,479 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:05:52,483 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:05:52,488 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:05:52,492 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:06:05,384 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6941
en_de Dev loss: 0.8974 r:0.1530
en_zh Dev loss: 0.7736 r:0.3123
ro_en Dev loss: 0.5984 r:0.6395
et_en Dev loss: 0.4539 r:0.6324
si_en Dev loss: 0.7379 r:0.4754
ne_en Dev loss: 0.4976 r:0.6203
ru_en Dev loss: 0.5533 r:0.6789
Current avg r:0.5017 Best avg r: 0.5017
15:09:55,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:08,906 root INFO 
id:en_de cur r: 0.1486 best r: 0.1486
15:10:21,756 root INFO 
id:en_zh cur r: 0.3425 best r: 0.3425
15:10:34,634 root INFO 
id:ro_en cur r: 0.6733 best r: 0.6733
15:10:47,550 root INFO 
id:et_en cur r: 0.6385 best r: 0.6385
15:11:00,450 root INFO 
id:si_en cur r: 0.4996 best r: 0.4996
15:11:13,298 root INFO 
id:ru_en cur r: 0.6858 best r: 0.6858
15:11:13,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:43,436 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:12:43,442 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:12:43,448 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:12:43,452 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:12:43,457 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:12:43,461 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:12:43,466 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:12:56,441 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7054
en_de Dev loss: 0.9058 r:0.1475
en_zh Dev loss: 0.7905 r:0.3460
ro_en Dev loss: 0.5461 r:0.6924
et_en Dev loss: 0.4370 r:0.6666
si_en Dev loss: 0.7201 r:0.5167
ne_en Dev loss: 0.4358 r:0.6867
ru_en Dev loss: 0.5466 r:0.7013
Current avg r:0.5368 Best avg r: 0.5368
15:16:47,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:25,677 root INFO 
id:ro_en cur r: 0.6975 best r: 0.6975
15:17:38,575 root INFO 
id:et_en cur r: 0.6465 best r: 0.6465
15:17:51,480 root INFO 
id:si_en cur r: 0.5259 best r: 0.5259
15:18:04,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:34,482 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:19:34,488 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:19:34,493 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:19:34,498 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:19:34,502 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:19:34,507 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:19:34,514 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:19:47,414 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6277
en_de Dev loss: 0.9135 r:0.1478
en_zh Dev loss: 0.7753 r:0.3524
ro_en Dev loss: 0.5159 r:0.7092
et_en Dev loss: 0.4126 r:0.6752
si_en Dev loss: 0.7512 r:0.5302
ne_en Dev loss: 0.4239 r:0.6873
ru_en Dev loss: 0.5345 r:0.7008
Current avg r:0.5433 Best avg r: 0.5433
15:23:37,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:50,751 root INFO 
id:en_de cur r: 0.1656 best r: 0.1656
15:24:03,638 root INFO 
id:en_zh cur r: 0.3472 best r: 0.3472
15:24:16,591 root INFO 
id:ro_en cur r: 0.7203 best r: 0.7203
15:24:29,528 root INFO 
id:et_en cur r: 0.6589 best r: 0.6589
15:24:55,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:25,300 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6181
en_de Dev loss: 0.9213 r:0.1593
en_zh Dev loss: 0.7782 r:0.3551
ro_en Dev loss: 0.5360 r:0.7217
et_en Dev loss: 0.4339 r:0.6789
si_en Dev loss: 0.8758 r:0.5215
ne_en Dev loss: 0.4401 r:0.6665
ru_en Dev loss: 0.5708 r:0.6853
Current avg r:0.5412 Best avg r: 0.5433
15:30:16,27 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:28,927 root INFO 
id:en_de cur r: 0.1673 best r: 0.1673
15:30:41,775 root INFO 
id:en_zh cur r: 0.3725 best r: 0.3725
15:30:54,658 root INFO 
id:ro_en cur r: 0.7397 best r: 0.7397
15:31:07,551 root INFO 
id:et_en cur r: 0.6900 best r: 0.6900
15:31:20,452 root INFO 
id:si_en cur r: 0.5469 best r: 0.5469
15:31:33,287 root INFO 
id:ru_en cur r: 0.7113 best r: 0.7113
15:31:33,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:03,449 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:33:03,455 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:33:03,460 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:33:03,464 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:33:03,469 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:33:03,473 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:33:03,478 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:33:16,375 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6231
en_de Dev loss: 0.8764 r:0.1645
en_zh Dev loss: 0.7259 r:0.3786
ro_en Dev loss: 0.4088 r:0.7389
et_en Dev loss: 0.3576 r:0.7037
si_en Dev loss: 0.6447 r:0.5531
ne_en Dev loss: 0.4855 r:0.6947
ru_en Dev loss: 0.4568 r:0.7228
Current avg r:0.5652 Best avg r: 0.5652
15:37:06,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:45,508 root INFO 
id:ro_en cur r: 0.7482 best r: 0.7482
15:38:24,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:54,237 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5810
en_de Dev loss: 0.9134 r:0.1555
en_zh Dev loss: 0.7838 r:0.3740
ro_en Dev loss: 0.4935 r:0.7479
et_en Dev loss: 0.4071 r:0.6924
si_en Dev loss: 0.8184 r:0.5439
ne_en Dev loss: 0.4278 r:0.6781
ru_en Dev loss: 0.5078 r:0.7094
Current avg r:0.5573 Best avg r: 0.5652
15:43:45,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:23,778 root INFO 
id:ro_en cur r: 0.7566 best r: 0.7566
15:45:02,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:32,588 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5995
en_de Dev loss: 0.9146 r:0.1735
en_zh Dev loss: 0.8110 r:0.3500
ro_en Dev loss: 0.4551 r:0.7523
et_en Dev loss: 0.4052 r:0.6831
si_en Dev loss: 0.8532 r:0.5389
ne_en Dev loss: 0.4573 r:0.6682
ru_en Dev loss: 0.5489 r:0.6916
Current avg r:0.5511 Best avg r: 0.5652
15:50:23,219 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:36,89 root INFO 
id:en_de cur r: 0.1772 best r: 0.1772
15:50:48,937 root INFO 
id:en_zh cur r: 0.4048 best r: 0.4048
15:51:01,817 root INFO 
id:ro_en cur r: 0.7806 best r: 0.7806
15:51:14,736 root INFO 
id:et_en cur r: 0.6997 best r: 0.6997
15:51:27,644 root INFO 
id:si_en cur r: 0.5711 best r: 0.5711
15:51:40,476 root INFO 
id:ru_en cur r: 0.7373 best r: 0.7373
15:51:40,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:10,622 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:53:10,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:53:10,632 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:53:10,637 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:53:10,642 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:53:10,646 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:53:10,651 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:53:23,536 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5662
en_de Dev loss: 0.8936 r:0.1859
en_zh Dev loss: 0.7254 r:0.4022
ro_en Dev loss: 0.3829 r:0.7757
et_en Dev loss: 0.3663 r:0.7053
si_en Dev loss: 0.6674 r:0.5749
ne_en Dev loss: 0.5167 r:0.7008
ru_en Dev loss: 0.4286 r:0.7423
Current avg r:0.5839 Best avg r: 0.5839
15:57:13,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:26,782 root INFO 
id:en_de cur r: 0.1981 best r: 0.1981
15:57:39,668 root INFO 
id:en_zh cur r: 0.4414 best r: 0.4414
15:57:52,616 root INFO 
id:ro_en cur r: 0.7902 best r: 0.7902
15:58:18,395 root INFO 
id:si_en cur r: 0.5834 best r: 0.5834
15:58:31,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:01,343 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:00:01,350 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:00:01,355 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:00:01,361 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:00:01,369 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:00:01,375 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:00:01,381 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:00:14,289 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5548
en_de Dev loss: 0.8622 r:0.2043
en_zh Dev loss: 0.6649 r:0.4385
ro_en Dev loss: 0.3400 r:0.7862
et_en Dev loss: 0.3590 r:0.7018
si_en Dev loss: 0.5978 r:0.5834
ne_en Dev loss: 0.5823 r:0.7099
ru_en Dev loss: 0.3984 r:0.7375
Current avg r:0.5945 Best avg r: 0.5945
16:04:04,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:43,426 root INFO 
id:ro_en cur r: 0.7919 best r: 0.7919
16:05:22,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:52,191 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5618
en_de Dev loss: 0.8802 r:0.1894
en_zh Dev loss: 0.7357 r:0.4032
ro_en Dev loss: 0.3596 r:0.7894
et_en Dev loss: 0.3488 r:0.7112
si_en Dev loss: 0.7544 r:0.5750
ne_en Dev loss: 0.4643 r:0.7102
ru_en Dev loss: 0.4552 r:0.7259
Current avg r:0.5863 Best avg r: 0.5945
16:10:42,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:21,475 root INFO 
id:ro_en cur r: 0.8022 best r: 0.8022
16:11:34,380 root INFO 
id:et_en cur r: 0.7073 best r: 0.7073
16:11:47,350 root INFO 
id:si_en cur r: 0.5978 best r: 0.5978
16:12:00,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:30,363 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5493
en_de Dev loss: 0.8858 r:0.1956
en_zh Dev loss: 0.7298 r:0.4024
ro_en Dev loss: 0.3469 r:0.7987
et_en Dev loss: 0.3483 r:0.7161
si_en Dev loss: 0.6418 r:0.5951
ne_en Dev loss: 0.5661 r:0.7219
ru_en Dev loss: 0.4578 r:0.7290
Current avg r:0.5941 Best avg r: 0.5945
16:17:21,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:59,862 root INFO 
id:ro_en cur r: 0.8081 best r: 0.8081
16:18:12,755 root INFO 
id:et_en cur r: 0.7082 best r: 0.7082
16:18:38,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:08,475 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:20:08,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:20:08,486 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:20:08,491 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:20:08,495 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:20:08,499 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:20:08,504 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:20:21,418 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5570
en_de Dev loss: 0.8885 r:0.1846
en_zh Dev loss: 0.7036 r:0.4157
ro_en Dev loss: 0.3134 r:0.8060
et_en Dev loss: 0.3436 r:0.7184
si_en Dev loss: 0.6073 r:0.5976
ne_en Dev loss: 0.5532 r:0.7247
ru_en Dev loss: 0.4374 r:0.7185
Current avg r:0.5951 Best avg r: 0.5951
16:24:13,219 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:51,813 root INFO 
id:ro_en cur r: 0.8119 best r: 0.8119
16:25:04,716 root INFO 
id:et_en cur r: 0.7129 best r: 0.7129
16:25:17,613 root INFO 
id:si_en cur r: 0.5983 best r: 0.5983
16:25:30,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:00,694 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:27:00,704 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:27:00,709 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:27:00,715 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:27:00,722 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:27:00,729 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:27:00,734 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:27:13,627 root INFO Epoch 1 Global steps: 9600 Train loss: 0.4923
en_de Dev loss: 0.8943 r:0.1863
en_zh Dev loss: 0.7497 r:0.4188
ro_en Dev loss: 0.3668 r:0.8083
et_en Dev loss: 0.3587 r:0.7200
si_en Dev loss: 0.6507 r:0.6040
ne_en Dev loss: 0.5323 r:0.7275
ru_en Dev loss: 0.4615 r:0.7372
Current avg r:0.6003 Best avg r: 0.6003
16:31:04,214 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:42,815 root INFO 
id:ro_en cur r: 0.8129 best r: 0.8129
16:32:21,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:51,646 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:33:51,652 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:33:51,658 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:33:51,662 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:33:51,667 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:33:51,672 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:33:51,677 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:34:04,557 root INFO Epoch 1 Global steps: 10200 Train loss: 0.4836
en_de Dev loss: 0.8605 r:0.1955
en_zh Dev loss: 0.6895 r:0.4338
ro_en Dev loss: 0.3110 r:0.8092
et_en Dev loss: 0.3534 r:0.7154
si_en Dev loss: 0.6329 r:0.5966
ne_en Dev loss: 0.6030 r:0.7272
ru_en Dev loss: 0.4145 r:0.7399
Current avg r:0.6025 Best avg r: 0.6025
16:37:55,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:33,795 root INFO 
id:ro_en cur r: 0.8153 best r: 0.8153
16:39:12,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:42,708 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5291
en_de Dev loss: 0.8737 r:0.1894
en_zh Dev loss: 0.7281 r:0.4230
ro_en Dev loss: 0.3456 r:0.8136
et_en Dev loss: 0.3688 r:0.7024
si_en Dev loss: 0.7104 r:0.5931
ne_en Dev loss: 0.4427 r:0.7187
ru_en Dev loss: 0.4462 r:0.7406
Current avg r:0.5973 Best avg r: 0.6025
16:44:33,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:59,525 root INFO 
id:en_zh cur r: 0.4570 best r: 0.4570
16:45:12,401 root INFO 
id:ro_en cur r: 0.8189 best r: 0.8189
16:45:51,54 root INFO 
id:ru_en cur r: 0.7495 best r: 0.7495
16:45:51,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:21,337 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:47:21,343 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:47:21,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:47:21,352 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:47:21,359 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:47:21,367 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:47:21,372 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:47:34,258 root INFO Epoch 1 Global steps: 11400 Train loss: 0.5517
en_de Dev loss: 0.8864 r:0.1770
en_zh Dev loss: 0.6864 r:0.4474
ro_en Dev loss: 0.3266 r:0.8173
et_en Dev loss: 0.3650 r:0.7144
si_en Dev loss: 0.7361 r:0.6026
ne_en Dev loss: 0.4528 r:0.7279
ru_en Dev loss: 0.4670 r:0.7544
Current avg r:0.6059 Best avg r: 0.6059
16:51:24,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:03,442 root INFO 
id:ro_en cur r: 0.8197 best r: 0.8197
16:52:42,173 root INFO 
id:ru_en cur r: 0.7535 best r: 0.7535
16:52:42,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:12,129 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5059
en_de Dev loss: 0.8735 r:0.1858
en_zh Dev loss: 0.7098 r:0.4408
ro_en Dev loss: 0.3177 r:0.8179
et_en Dev loss: 0.3589 r:0.7103
si_en Dev loss: 0.7739 r:0.5872
ne_en Dev loss: 0.4848 r:0.7143
ru_en Dev loss: 0.4088 r:0.7556
Current avg r:0.6017 Best avg r: 0.6059
16:58:02,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:20,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:50,55 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4993
en_de Dev loss: 0.8753 r:0.1832
en_zh Dev loss: 0.6994 r:0.4439
ro_en Dev loss: 0.3293 r:0.8162
et_en Dev loss: 0.3626 r:0.7112
si_en Dev loss: 0.8340 r:0.5886
ne_en Dev loss: 0.5170 r:0.7148
ru_en Dev loss: 0.4505 r:0.7365
Current avg r:0.5992 Best avg r: 0.6059
17:04:40,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:06,597 root INFO 
id:en_zh cur r: 0.4693 best r: 0.4693
17:05:19,479 root INFO 
id:ro_en cur r: 0.8224 best r: 0.8224
17:05:58,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:28,67 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:07:28,76 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:07:28,81 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:07:28,86 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:07:28,92 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:07:28,98 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:07:28,103 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:07:40,972 root INFO Epoch 1 Global steps: 13200 Train loss: 0.5322
en_de Dev loss: 0.8828 r:0.1951
en_zh Dev loss: 0.6886 r:0.4602
ro_en Dev loss: 0.3288 r:0.8213
et_en Dev loss: 0.3706 r:0.7093
si_en Dev loss: 0.7628 r:0.5976
ne_en Dev loss: 0.4763 r:0.7241
ru_en Dev loss: 0.4374 r:0.7458
Current avg r:0.6076 Best avg r: 0.6076
17:11:31,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:44,217 root INFO 
id:en_de cur r: 0.2037 best r: 0.2037
17:12:09,953 root INFO 
id:ro_en cur r: 0.8235 best r: 0.8235
17:12:22,914 root INFO 
id:et_en cur r: 0.7133 best r: 0.7133
17:12:35,792 root INFO 
id:si_en cur r: 0.6108 best r: 0.6108
17:12:48,599 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:18,436 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4997
en_de Dev loss: 0.8508 r:0.2081
en_zh Dev loss: 0.6853 r:0.4472
ro_en Dev loss: 0.3144 r:0.8184
et_en Dev loss: 0.3928 r:0.7193
si_en Dev loss: 0.5867 r:0.6073
ne_en Dev loss: 0.8274 r:0.7294
ru_en Dev loss: 0.4181 r:0.7230
Current avg r:0.6075 Best avg r: 0.6076
17:18:08,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:21,84 root INFO 
id:en_de cur r: 0.2164 best r: 0.2164
17:18:33,886 root INFO 
id:en_zh cur r: 0.4706 best r: 0.4706
17:18:59,560 root INFO 
id:et_en cur r: 0.7138 best r: 0.7138
17:19:25,220 root INFO 
id:ru_en cur r: 0.7543 best r: 0.7543
17:19:25,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:55,52 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:20:55,60 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:20:55,65 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:20:55,72 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:20:55,77 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:20:55,82 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:20:55,87 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:21:07,927 root INFO Epoch 1 Global steps: 14400 Train loss: 0.5250
en_de Dev loss: 0.8438 r:0.2212
en_zh Dev loss: 0.6537 r:0.4639
ro_en Dev loss: 0.3007 r:0.8213
et_en Dev loss: 0.3472 r:0.7187
si_en Dev loss: 0.6668 r:0.6073
ne_en Dev loss: 0.5859 r:0.7327
ru_en Dev loss: 0.3727 r:0.7495
Current avg r:0.6164 Best avg r: 0.6164
17:24:57,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:48,813 root INFO 
id:et_en cur r: 0.7153 best r: 0.7153
17:26:01,658 root INFO 
id:si_en cur r: 0.6145 best r: 0.6145
17:26:14,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:44,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:27:44,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:27:44,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:27:44,177 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:27:44,181 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:27:44,186 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:27:44,190 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:27:57,36 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4800
en_de Dev loss: 0.8710 r:0.2158
en_zh Dev loss: 0.6864 r:0.4596
ro_en Dev loss: 0.3096 r:0.8205
et_en Dev loss: 0.3505 r:0.7206
si_en Dev loss: 0.6139 r:0.6175
ne_en Dev loss: 0.6201 r:0.7376
ru_en Dev loss: 0.4056 r:0.7474
Current avg r:0.6170 Best avg r: 0.6170
17:31:46,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:59,476 root INFO 
id:en_de cur r: 0.2296 best r: 0.2296
17:33:03,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:33,262 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:34:33,272 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:34:33,278 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:34:33,283 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:34:33,288 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:34:33,292 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:34:33,297 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:34:46,154 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4961
en_de Dev loss: 0.8441 r:0.2302
en_zh Dev loss: 0.6752 r:0.4535
ro_en Dev loss: 0.3064 r:0.8214
et_en Dev loss: 0.3668 r:0.7201
si_en Dev loss: 0.5577 r:0.6136
ne_en Dev loss: 0.7398 r:0.7344
ru_en Dev loss: 0.3829 r:0.7513
Current avg r:0.6178 Best avg r: 0.6178
17:38:36,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:53,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:22,892 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4839
en_de Dev loss: 0.8486 r:0.2257
en_zh Dev loss: 0.6939 r:0.4507
ro_en Dev loss: 0.3108 r:0.8228
et_en Dev loss: 0.3435 r:0.7220
si_en Dev loss: 0.6403 r:0.6137
ne_en Dev loss: 0.5601 r:0.7334
ru_en Dev loss: 0.4268 r:0.7422
Current avg r:0.6158 Best avg r: 0.6178
17:45:12,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:51,339 root INFO 
id:ro_en cur r: 0.8253 best r: 0.8253
17:46:04,208 root INFO 
id:et_en cur r: 0.7183 best r: 0.7183
17:46:29,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:59,679 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:47:59,687 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:47:59,692 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:47:59,697 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:47:59,701 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:47:59,707 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:47:59,712 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:48:12,550 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4811
en_de Dev loss: 0.8519 r:0.2322
en_zh Dev loss: 0.6840 r:0.4534
ro_en Dev loss: 0.3022 r:0.8254
et_en Dev loss: 0.3375 r:0.7252
si_en Dev loss: 0.6754 r:0.6137
ne_en Dev loss: 0.5249 r:0.7297
ru_en Dev loss: 0.3875 r:0.7547
Current avg r:0.6192 Best avg r: 0.6192
17:52:02,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:41,47 root INFO 
id:ro_en cur r: 0.8271 best r: 0.8271
17:53:19,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:49,313 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4720
en_de Dev loss: 0.8680 r:0.2189
en_zh Dev loss: 0.7232 r:0.4477
ro_en Dev loss: 0.3198 r:0.8266
et_en Dev loss: 0.3437 r:0.7264
si_en Dev loss: 0.6989 r:0.6127
ne_en Dev loss: 0.5342 r:0.7423
ru_en Dev loss: 0.4176 r:0.7553
Current avg r:0.6185 Best avg r: 0.6192
17:58:39,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:56,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:26,65 root INFO Epoch 1 Global steps: 18000 Train loss: 0.5241
en_de Dev loss: 0.8559 r:0.1998
en_zh Dev loss: 0.6948 r:0.4522
ro_en Dev loss: 0.3279 r:0.8182
et_en Dev loss: 0.3700 r:0.7134
si_en Dev loss: 0.7405 r:0.5954
ne_en Dev loss: 0.6127 r:0.7320
ru_en Dev loss: 0.4170 r:0.7413
Current avg r:0.6075 Best avg r: 0.6192
18:05:17,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:55,659 root INFO 
id:ro_en cur r: 0.8272 best r: 0.8272
18:06:34,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:03,726 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4253
en_de Dev loss: 0.8510 r:0.2243
en_zh Dev loss: 0.6852 r:0.4587
ro_en Dev loss: 0.3038 r:0.8279
et_en Dev loss: 0.3567 r:0.7209
si_en Dev loss: 0.6825 r:0.6121
ne_en Dev loss: 0.5483 r:0.7323
ru_en Dev loss: 0.4195 r:0.7469
Current avg r:0.6176 Best avg r: 0.6192
18:11:53,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:10,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:40,233 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4308
en_de Dev loss: 0.8455 r:0.2250
en_zh Dev loss: 0.7025 r:0.4472
ro_en Dev loss: 0.3094 r:0.8238
et_en Dev loss: 0.3856 r:0.7184
si_en Dev loss: 0.5984 r:0.6108
ne_en Dev loss: 0.8306 r:0.7323
ru_en Dev loss: 0.3782 r:0.7556
Current avg r:0.6162 Best avg r: 0.6192
18:18:30,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:42,992 root INFO 
id:en_de cur r: 0.2400 best r: 0.2400
18:19:08,619 root INFO 
id:ro_en cur r: 0.8305 best r: 0.8305
18:19:47,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:16,738 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4297
en_de Dev loss: 0.8545 r:0.2200
en_zh Dev loss: 0.7176 r:0.4545
ro_en Dev loss: 0.3165 r:0.8288
et_en Dev loss: 0.3499 r:0.7209
si_en Dev loss: 0.7421 r:0.6066
ne_en Dev loss: 0.5284 r:0.7325
ru_en Dev loss: 0.4242 r:0.7523
Current avg r:0.6165 Best avg r: 0.6192
18:25:06,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:32,341 root INFO 
id:en_zh cur r: 0.4719 best r: 0.4719
18:26:23,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:53,305 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4376
en_de Dev loss: 0.8468 r:0.2298
en_zh Dev loss: 0.6916 r:0.4640
ro_en Dev loss: 0.3067 r:0.8252
et_en Dev loss: 0.3834 r:0.7160
si_en Dev loss: 0.6531 r:0.5996
ne_en Dev loss: 0.7903 r:0.7290
ru_en Dev loss: 0.3823 r:0.7587
Current avg r:0.6175 Best avg r: 0.6192
18:31:43,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:00,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:29,761 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4746
en_de Dev loss: 0.8573 r:0.2350
en_zh Dev loss: 0.7203 r:0.4492
ro_en Dev loss: 0.3159 r:0.8291
et_en Dev loss: 0.3613 r:0.7135
si_en Dev loss: 0.6843 r:0.6068
ne_en Dev loss: 0.5354 r:0.7285
ru_en Dev loss: 0.4201 r:0.7515
Current avg r:0.6162 Best avg r: 0.6192
18:38:19,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:58,99 root INFO 
id:ro_en cur r: 0.8352 best r: 0.8352
18:39:36,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:06,163 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4354
en_de Dev loss: 0.8562 r:0.2117
en_zh Dev loss: 0.6797 r:0.4635
ro_en Dev loss: 0.2876 r:0.8294
et_en Dev loss: 0.3740 r:0.7141
si_en Dev loss: 0.6105 r:0.6079
ne_en Dev loss: 0.7399 r:0.7352
ru_en Dev loss: 0.3960 r:0.7532
Current avg r:0.6164 Best avg r: 0.6192
18:44:56,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:13,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:42,626 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4378
en_de Dev loss: 0.8502 r:0.2167
en_zh Dev loss: 0.6915 r:0.4636
ro_en Dev loss: 0.3112 r:0.8223
et_en Dev loss: 0.4027 r:0.7119
si_en Dev loss: 0.5589 r:0.6107
ne_en Dev loss: 0.8718 r:0.7376
ru_en Dev loss: 0.3786 r:0.7551
Current avg r:0.6168 Best avg r: 0.6192
18:51:32,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:45,565 root INFO 
id:en_de cur r: 0.2413 best r: 0.2413
18:51:58,370 root INFO 
id:en_zh cur r: 0.4848 best r: 0.4848
18:52:49,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:19,220 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:54:19,230 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:54:19,235 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:54:19,240 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:54:19,245 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:54:19,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:54:19,257 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:54:32,90 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4359
en_de Dev loss: 0.8400 r:0.2328
en_zh Dev loss: 0.6530 r:0.4761
ro_en Dev loss: 0.2833 r:0.8320
et_en Dev loss: 0.3563 r:0.7209
si_en Dev loss: 0.5602 r:0.6202
ne_en Dev loss: 0.6537 r:0.7412
ru_en Dev loss: 0.3762 r:0.7600
Current avg r:0.6262 Best avg r: 0.6262
18:58:22,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:38,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:08,602 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4104
en_de Dev loss: 0.8605 r:0.2190
en_zh Dev loss: 0.7254 r:0.4503
ro_en Dev loss: 0.3228 r:0.8254
et_en Dev loss: 0.3649 r:0.7094
si_en Dev loss: 0.7285 r:0.6079
ne_en Dev loss: 0.5492 r:0.7305
ru_en Dev loss: 0.4512 r:0.7285
Current avg r:0.6102 Best avg r: 0.6262
19:04:58,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:11,469 root INFO 
id:en_de cur r: 0.2537 best r: 0.2537
19:06:15,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:45,202 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4548
en_de Dev loss: 0.8886 r:0.2392
en_zh Dev loss: 0.8287 r:0.4557
ro_en Dev loss: 0.4303 r:0.8175
et_en Dev loss: 0.4214 r:0.6998
si_en Dev loss: 0.9497 r:0.5844
ne_en Dev loss: 0.4209 r:0.7123
ru_en Dev loss: 0.5566 r:0.7160
Current avg r:0.6036 Best avg r: 0.6262
19:11:35,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:00,862 root INFO 
id:en_zh cur r: 0.4878 best r: 0.4878
19:12:52,106 root INFO 
id:ru_en cur r: 0.7663 best r: 0.7663
19:12:52,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:21,915 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
19:14:21,923 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
19:14:21,927 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
19:14:21,936 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
19:14:21,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
19:14:21,945 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
19:14:21,950 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
19:14:34,789 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4223
en_de Dev loss: 0.8571 r:0.2525
en_zh Dev loss: 0.7275 r:0.4793
ro_en Dev loss: 0.3181 r:0.8272
et_en Dev loss: 0.3784 r:0.7181
si_en Dev loss: 0.6302 r:0.6147
ne_en Dev loss: 0.6806 r:0.7388
ru_en Dev loss: 0.3975 r:0.7686
Current avg r:0.6284 Best avg r: 0.6284
19:18:24,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:41,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:11,402 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4539
en_de Dev loss: 0.8545 r:0.2093
en_zh Dev loss: 0.6760 r:0.4799
ro_en Dev loss: 0.2886 r:0.8279
et_en Dev loss: 0.3788 r:0.7053
si_en Dev loss: 0.6957 r:0.6108
ne_en Dev loss: 0.6278 r:0.7280
ru_en Dev loss: 0.3845 r:0.7564
Current avg r:0.6168 Best avg r: 0.6284
19:25:01,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:18,366 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:48,6 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4251
en_de Dev loss: 0.8385 r:0.2420
en_zh Dev loss: 0.6710 r:0.4746
ro_en Dev loss: 0.3068 r:0.8244
et_en Dev loss: 0.3872 r:0.7025
si_en Dev loss: 0.6811 r:0.5962
ne_en Dev loss: 0.7434 r:0.7229
ru_en Dev loss: 0.4008 r:0.7480
Current avg r:0.6158 Best avg r: 0.6284
19:31:38,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:03,646 root INFO 
id:en_zh cur r: 0.4892 best r: 0.4892
19:32:42,154 root INFO 
id:si_en cur r: 0.6174 best r: 0.6174
19:32:54,946 root INFO 
id:ru_en cur r: 0.7739 best r: 0.7739
19:32:54,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:24,584 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4152
en_de Dev loss: 0.8394 r:0.2391
en_zh Dev loss: 0.6583 r:0.4816
ro_en Dev loss: 0.2857 r:0.8315
et_en Dev loss: 0.3788 r:0.7146
si_en Dev loss: 0.5981 r:0.6186
ne_en Dev loss: 0.7476 r:0.7387
ru_en Dev loss: 0.3538 r:0.7728
Current avg r:0.6281 Best avg r: 0.6284
19:38:14,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:31,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:01,113 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4122
en_de Dev loss: 0.8395 r:0.2504
en_zh Dev loss: 0.7018 r:0.4601
ro_en Dev loss: 0.3101 r:0.8241
et_en Dev loss: 0.3804 r:0.7103
si_en Dev loss: 0.6770 r:0.6054
ne_en Dev loss: 0.6928 r:0.7255
ru_en Dev loss: 0.4301 r:0.7379
Current avg r:0.6162 Best avg r: 0.6284
19:44:52,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:09,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:38,751 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3708
en_de Dev loss: 0.8937 r:0.2252
en_zh Dev loss: 0.8489 r:0.4357
ro_en Dev loss: 0.3714 r:0.8222
et_en Dev loss: 0.4219 r:0.6988
si_en Dev loss: 0.9377 r:0.5891
ne_en Dev loss: 0.5124 r:0.7145
ru_en Dev loss: 0.5512 r:0.7133
Current avg r:0.5998 Best avg r: 0.6284
19:51:28,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:45,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:15,302 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3728
en_de Dev loss: 0.8546 r:0.2190
en_zh Dev loss: 0.7538 r:0.4553
ro_en Dev loss: 0.3265 r:0.8239
et_en Dev loss: 0.4044 r:0.6950
si_en Dev loss: 0.6782 r:0.6066
ne_en Dev loss: 0.6816 r:0.7222
ru_en Dev loss: 0.4375 r:0.7351
Current avg r:0.6082 Best avg r: 0.6284
19:58:05,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:22,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:51,808 root INFO Epoch 3 Global steps: 28800 Train loss: 0.4070
en_de Dev loss: 0.8594 r:0.2046
en_zh Dev loss: 0.7254 r:0.4737
ro_en Dev loss: 0.3107 r:0.8270
et_en Dev loss: 0.4018 r:0.6965
si_en Dev loss: 0.7441 r:0.6068
ne_en Dev loss: 0.6551 r:0.7233
ru_en Dev loss: 0.4070 r:0.7536
Current avg r:0.6122 Best avg r: 0.6284
20:04:41,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:58,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:28,285 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4046
en_de Dev loss: 0.8656 r:0.2191
en_zh Dev loss: 0.7391 r:0.4564
ro_en Dev loss: 0.3461 r:0.8167
et_en Dev loss: 0.4047 r:0.6935
si_en Dev loss: 0.7918 r:0.5899
ne_en Dev loss: 0.6720 r:0.7065
ru_en Dev loss: 0.4650 r:0.7281
Current avg r:0.6015 Best avg r: 0.6284
20:11:18,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:35,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:04,735 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3873
en_de Dev loss: 0.8725 r:0.2165
en_zh Dev loss: 0.7623 r:0.4421
ro_en Dev loss: 0.3746 r:0.8163
et_en Dev loss: 0.4118 r:0.6874
si_en Dev loss: 0.8534 r:0.5891
ne_en Dev loss: 0.5605 r:0.7087
ru_en Dev loss: 0.4608 r:0.7332
Current avg r:0.5990 Best avg r: 0.6284
20:17:54,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:11,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:41,194 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3584
en_de Dev loss: 0.8621 r:0.1996
en_zh Dev loss: 0.7569 r:0.4446
ro_en Dev loss: 0.3414 r:0.8201
et_en Dev loss: 0.4120 r:0.6899
si_en Dev loss: 0.7986 r:0.5891
ne_en Dev loss: 0.6852 r:0.7174
ru_en Dev loss: 0.4473 r:0.7330
Current avg r:0.5991 Best avg r: 0.6284
20:24:31,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:48,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:17,868 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3815
en_de Dev loss: 0.8463 r:0.2257
en_zh Dev loss: 0.6798 r:0.4790
ro_en Dev loss: 0.3039 r:0.8245
et_en Dev loss: 0.3986 r:0.6987
si_en Dev loss: 0.6608 r:0.6024
ne_en Dev loss: 0.7261 r:0.7184
ru_en Dev loss: 0.3912 r:0.7510
Current avg r:0.6142 Best avg r: 0.6284
20:31:07,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:24,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:54,465 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3666
en_de Dev loss: 0.8571 r:0.2227
en_zh Dev loss: 0.7365 r:0.4478
ro_en Dev loss: 0.3209 r:0.8239
et_en Dev loss: 0.3952 r:0.6991
si_en Dev loss: 0.6713 r:0.5973
ne_en Dev loss: 0.7629 r:0.7059
ru_en Dev loss: 0.4411 r:0.7290
Current avg r:0.6037 Best avg r: 0.6284
20:37:44,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:01,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:31,70 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3373
en_de Dev loss: 0.8782 r:0.2160
en_zh Dev loss: 0.8026 r:0.4285
ro_en Dev loss: 0.3450 r:0.8252
et_en Dev loss: 0.3949 r:0.7024
si_en Dev loss: 0.7712 r:0.5955
ne_en Dev loss: 0.6545 r:0.7128
ru_en Dev loss: 0.4862 r:0.7270
Current avg r:0.6011 Best avg r: 0.6284
20:44:21,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:37,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:07,630 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3719
en_de Dev loss: 0.8595 r:0.2034
en_zh Dev loss: 0.7410 r:0.4414
ro_en Dev loss: 0.3191 r:0.8266
et_en Dev loss: 0.3832 r:0.6988
si_en Dev loss: 0.7162 r:0.5912
ne_en Dev loss: 0.6754 r:0.7116
ru_en Dev loss: 0.4754 r:0.7128
Current avg r:0.5980 Best avg r: 0.6284
20:50:57,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:14,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:44,238 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3477
en_de Dev loss: 0.8673 r:0.2344
en_zh Dev loss: 0.7706 r:0.4342
ro_en Dev loss: 0.3317 r:0.8217
et_en Dev loss: 0.3951 r:0.6913
si_en Dev loss: 0.7517 r:0.5886
ne_en Dev loss: 0.6315 r:0.7118
ru_en Dev loss: 0.4962 r:0.7104
Current avg r:0.5989 Best avg r: 0.6284
20:57:34,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:51,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:20,820 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3362
en_de Dev loss: 0.8356 r:0.2482
en_zh Dev loss: 0.6817 r:0.4682
ro_en Dev loss: 0.2942 r:0.8264
et_en Dev loss: 0.3857 r:0.7008
si_en Dev loss: 0.6382 r:0.6032
ne_en Dev loss: 0.7392 r:0.7142
ru_en Dev loss: 0.4118 r:0.7325
Current avg r:0.6134 Best avg r: 0.6284
21:04:10,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:27,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:57,437 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3901
en_de Dev loss: 0.8610 r:0.2275
en_zh Dev loss: 0.7320 r:0.4694
ro_en Dev loss: 0.3575 r:0.8217
et_en Dev loss: 0.4281 r:0.6948
si_en Dev loss: 0.7032 r:0.5989
ne_en Dev loss: 0.7509 r:0.7101
ru_en Dev loss: 0.4289 r:0.7497
Current avg r:0.6103 Best avg r: 0.6284
21:10:47,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:04,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:34,72 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3800
en_de Dev loss: 0.8656 r:0.2069
en_zh Dev loss: 0.7417 r:0.4534
ro_en Dev loss: 0.3407 r:0.8183
et_en Dev loss: 0.4118 r:0.6809
si_en Dev loss: 0.7839 r:0.5742
ne_en Dev loss: 0.6871 r:0.7028
ru_en Dev loss: 0.4468 r:0.7301
Current avg r:0.5952 Best avg r: 0.6284
21:17:24,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:40,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:10,667 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3654
en_de Dev loss: 0.8465 r:0.2256
en_zh Dev loss: 0.7231 r:0.4390
ro_en Dev loss: 0.3107 r:0.8198
et_en Dev loss: 0.4073 r:0.6903
si_en Dev loss: 0.6414 r:0.5853
ne_en Dev loss: 0.7702 r:0.7033
ru_en Dev loss: 0.4385 r:0.7169
Current avg r:0.5972 Best avg r: 0.6284
21:24:01,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:18,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:48,457 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3511
en_de Dev loss: 0.8987 r:0.2118
en_zh Dev loss: 0.8729 r:0.4352
ro_en Dev loss: 0.3839 r:0.8218
et_en Dev loss: 0.4302 r:0.6842
si_en Dev loss: 0.9076 r:0.5768
ne_en Dev loss: 0.6109 r:0.6936
ru_en Dev loss: 0.5321 r:0.7164
Current avg r:0.5914 Best avg r: 0.6284
21:30:38,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:55,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:24,894 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3160
en_de Dev loss: 0.8387 r:0.2482
en_zh Dev loss: 0.7333 r:0.4537
ro_en Dev loss: 0.3273 r:0.8222
et_en Dev loss: 0.4423 r:0.6889
si_en Dev loss: 0.7934 r:0.5825
ne_en Dev loss: 0.8318 r:0.7032
ru_en Dev loss: 0.3999 r:0.7501
Current avg r:0.6070 Best avg r: 0.6284
21:37:14,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:31,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:01,739 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3249
en_de Dev loss: 0.8489 r:0.2471
en_zh Dev loss: 0.7663 r:0.4563
ro_en Dev loss: 0.3536 r:0.8202
et_en Dev loss: 0.4488 r:0.6845
si_en Dev loss: 0.7819 r:0.5825
ne_en Dev loss: 0.7529 r:0.7005
ru_en Dev loss: 0.4555 r:0.7327
Current avg r:0.6034 Best avg r: 0.6284
21:43:52,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:09,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:39,24 root INFO Epoch 4 Global steps: 38400 Train loss: 0.2968
en_de Dev loss: 0.8609 r:0.2437
en_zh Dev loss: 0.7702 r:0.4396
ro_en Dev loss: 0.3387 r:0.8173
et_en Dev loss: 0.4266 r:0.6799
si_en Dev loss: 0.7840 r:0.5685
ne_en Dev loss: 0.7018 r:0.6974
ru_en Dev loss: 0.4452 r:0.7318
Current avg r:0.5969 Best avg r: 0.6284
21:50:29,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:46,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:15,904 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3251
en_de Dev loss: 0.8531 r:0.2419
en_zh Dev loss: 0.7556 r:0.4403
ro_en Dev loss: 0.3240 r:0.8186
et_en Dev loss: 0.4234 r:0.6842
si_en Dev loss: 0.7252 r:0.5755
ne_en Dev loss: 0.7765 r:0.7003
ru_en Dev loss: 0.4459 r:0.7254
Current avg r:0.5980 Best avg r: 0.6284
21:57:05,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:22,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:52,506 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3162
en_de Dev loss: 0.8833 r:0.2103
en_zh Dev loss: 0.7862 r:0.4333
ro_en Dev loss: 0.3533 r:0.8141
et_en Dev loss: 0.4288 r:0.6863
si_en Dev loss: 0.7862 r:0.5666
ne_en Dev loss: 0.7781 r:0.6913
ru_en Dev loss: 0.4864 r:0.7216
Current avg r:0.5891 Best avg r: 0.6284
22:03:42,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:59,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:29,28 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3256
en_de Dev loss: 0.8857 r:0.2020
en_zh Dev loss: 0.8239 r:0.4462
ro_en Dev loss: 0.3341 r:0.8284
et_en Dev loss: 0.4053 r:0.7025
si_en Dev loss: 0.7492 r:0.5932
ne_en Dev loss: 0.6463 r:0.7066
ru_en Dev loss: 0.4403 r:0.7524
Current avg r:0.6045 Best avg r: 0.6284
22:10:18,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:35,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:05,553 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3146
en_de Dev loss: 0.8954 r:0.2095
en_zh Dev loss: 0.7878 r:0.4319
ro_en Dev loss: 0.3450 r:0.8179
et_en Dev loss: 0.4133 r:0.6846
si_en Dev loss: 0.8144 r:0.5735
ne_en Dev loss: 0.6858 r:0.6993
ru_en Dev loss: 0.4532 r:0.7332
Current avg r:0.5928 Best avg r: 0.6284
22:16:55,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:12,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:42,82 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3126
en_de Dev loss: 0.8558 r:0.2297
en_zh Dev loss: 0.7673 r:0.4392
ro_en Dev loss: 0.3520 r:0.8167
et_en Dev loss: 0.4375 r:0.6818
si_en Dev loss: 0.8165 r:0.5698
ne_en Dev loss: 0.8058 r:0.6970
ru_en Dev loss: 0.4739 r:0.7165
Current avg r:0.5930 Best avg r: 0.6284
22:23:32,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:48,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:18,539 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3300
en_de Dev loss: 0.8819 r:0.2205
en_zh Dev loss: 0.7574 r:0.4668
ro_en Dev loss: 0.3460 r:0.8214
et_en Dev loss: 0.4370 r:0.6797
si_en Dev loss: 0.7912 r:0.5728
ne_en Dev loss: 0.6245 r:0.6978
ru_en Dev loss: 0.4829 r:0.7321
Current avg r:0.5987 Best avg r: 0.6284
22:30:08,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:25,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:54,987 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3011
en_de Dev loss: 0.8619 r:0.2238
en_zh Dev loss: 0.7609 r:0.4456
ro_en Dev loss: 0.3480 r:0.8168
et_en Dev loss: 0.4300 r:0.6691
si_en Dev loss: 0.8187 r:0.5600
ne_en Dev loss: 0.6731 r:0.6872
ru_en Dev loss: 0.4430 r:0.7310
Current avg r:0.5905 Best avg r: 0.6284
22:36:45,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:01,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:31,636 root INFO Epoch 4 Global steps: 43200 Train loss: 0.2945
en_de Dev loss: 0.8726 r:0.2217
en_zh Dev loss: 0.7621 r:0.4509
ro_en Dev loss: 0.3426 r:0.8205
et_en Dev loss: 0.4406 r:0.6755
si_en Dev loss: 0.7050 r:0.5794
ne_en Dev loss: 0.7581 r:0.6955
ru_en Dev loss: 0.4730 r:0.7203
Current avg r:0.5948 Best avg r: 0.6284
22:43:21,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:38,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:08,220 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3067
en_de Dev loss: 0.8916 r:0.2029
en_zh Dev loss: 0.8011 r:0.4317
ro_en Dev loss: 0.3388 r:0.8224
et_en Dev loss: 0.4651 r:0.6779
si_en Dev loss: 0.7508 r:0.5756
ne_en Dev loss: 0.8570 r:0.6995
ru_en Dev loss: 0.4579 r:0.7301
Current avg r:0.5915 Best avg r: 0.6284
22:49:58,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:15,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:44,701 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2834
en_de Dev loss: 0.8798 r:0.2019
en_zh Dev loss: 0.7946 r:0.4345
ro_en Dev loss: 0.3519 r:0.8220
et_en Dev loss: 0.4310 r:0.6775
si_en Dev loss: 0.8284 r:0.5705
ne_en Dev loss: 0.6813 r:0.6967
ru_en Dev loss: 0.4506 r:0.7355
Current avg r:0.5912 Best avg r: 0.6284
22:56:34,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:51,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:21,176 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3027
en_de Dev loss: 0.8596 r:0.2263
en_zh Dev loss: 0.7689 r:0.4429
ro_en Dev loss: 0.3179 r:0.8236
et_en Dev loss: 0.4370 r:0.6862
si_en Dev loss: 0.7337 r:0.5732
ne_en Dev loss: 0.7960 r:0.7089
ru_en Dev loss: 0.4037 r:0.7470
Current avg r:0.6012 Best avg r: 0.6284
23:03:12,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:29,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:58,929 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2944
en_de Dev loss: 0.8658 r:0.2101
en_zh Dev loss: 0.8052 r:0.4302
ro_en Dev loss: 0.3161 r:0.8286
et_en Dev loss: 0.4116 r:0.6869
si_en Dev loss: 0.7914 r:0.5703
ne_en Dev loss: 0.6615 r:0.6949
ru_en Dev loss: 0.4739 r:0.7211
Current avg r:0.5917 Best avg r: 0.6284
23:09:48,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:05,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:35,453 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2777
en_de Dev loss: 0.8788 r:0.2045
en_zh Dev loss: 0.7961 r:0.4494
ro_en Dev loss: 0.3285 r:0.8300
et_en Dev loss: 0.4330 r:0.6876
si_en Dev loss: 0.8434 r:0.5697
ne_en Dev loss: 0.6887 r:0.6991
ru_en Dev loss: 0.4795 r:0.7240
Current avg r:0.5949 Best avg r: 0.6284
23:16:25,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:42,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:11,926 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2735
en_de Dev loss: 0.8818 r:0.2148
en_zh Dev loss: 0.8387 r:0.4433
ro_en Dev loss: 0.3519 r:0.8285
et_en Dev loss: 0.4541 r:0.6810
si_en Dev loss: 0.8279 r:0.5720
ne_en Dev loss: 0.7042 r:0.6977
ru_en Dev loss: 0.5167 r:0.7220
Current avg r:0.5942 Best avg r: 0.6284
23:23:01,791 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:18,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:48,317 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2617
en_de Dev loss: 0.8647 r:0.2267
en_zh Dev loss: 0.7831 r:0.4535
ro_en Dev loss: 0.3113 r:0.8286
et_en Dev loss: 0.4485 r:0.6907
si_en Dev loss: 0.7409 r:0.5776
ne_en Dev loss: 0.7929 r:0.7058
ru_en Dev loss: 0.4048 r:0.7605
Current avg r:0.6062 Best avg r: 0.6284
23:29:38,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:55,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:32:24,753 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2601
en_de Dev loss: 0.8647 r:0.2268
en_zh Dev loss: 0.7920 r:0.4488
ro_en Dev loss: 0.3163 r:0.8321
et_en Dev loss: 0.4482 r:0.6882
si_en Dev loss: 0.7733 r:0.5770
ne_en Dev loss: 0.7574 r:0.7049
ru_en Dev loss: 0.4241 r:0.7470
Current avg r:0.6036 Best avg r: 0.6284
23:36:14,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:31,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:01,146 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2630
en_de Dev loss: 0.8780 r:0.2337
en_zh Dev loss: 0.7916 r:0.4587
ro_en Dev loss: 0.3538 r:0.8221
et_en Dev loss: 0.4554 r:0.6839
si_en Dev loss: 0.8195 r:0.5670
ne_en Dev loss: 0.7763 r:0.7072
ru_en Dev loss: 0.4698 r:0.7396
Current avg r:0.6017 Best avg r: 0.6284
23:42:51,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:07,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:37,614 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2707
en_de Dev loss: 0.8771 r:0.1892
en_zh Dev loss: 0.7359 r:0.4707
ro_en Dev loss: 0.3110 r:0.8260
et_en Dev loss: 0.4157 r:0.6830
si_en Dev loss: 0.8178 r:0.5660
ne_en Dev loss: 0.6840 r:0.6973
ru_en Dev loss: 0.4600 r:0.7283
Current avg r:0.5944 Best avg r: 0.6284
23:49:27,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:44,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:13,970 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2564
en_de Dev loss: 0.8986 r:0.1807
en_zh Dev loss: 0.7774 r:0.4604
ro_en Dev loss: 0.3366 r:0.8257
et_en Dev loss: 0.4529 r:0.6852
si_en Dev loss: 0.7541 r:0.5749
ne_en Dev loss: 0.8230 r:0.7035
ru_en Dev loss: 0.4435 r:0.7408
Current avg r:0.5959 Best avg r: 0.6284
23:56:03,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:20,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:50,329 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2529
en_de Dev loss: 0.9014 r:0.1814
en_zh Dev loss: 0.7592 r:0.4493
ro_en Dev loss: 0.3388 r:0.8240
et_en Dev loss: 0.4331 r:0.6771
si_en Dev loss: 0.8364 r:0.5627
ne_en Dev loss: 0.6951 r:0.6966
ru_en Dev loss: 0.4399 r:0.7405
Current avg r:0.5902 Best avg r: 0.6284
00:02:40,183 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:57,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:26,765 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2573
en_de Dev loss: 0.8918 r:0.2008
en_zh Dev loss: 0.8039 r:0.4381
ro_en Dev loss: 0.3372 r:0.8218
et_en Dev loss: 0.4305 r:0.6770
si_en Dev loss: 0.8415 r:0.5619
ne_en Dev loss: 0.6764 r:0.6976
ru_en Dev loss: 0.4965 r:0.7164
Current avg r:0.5877 Best avg r: 0.6284
00:09:16,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:33,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:03,164 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2601
en_de Dev loss: 0.8835 r:0.2027
en_zh Dev loss: 0.7760 r:0.4650
ro_en Dev loss: 0.3483 r:0.8268
et_en Dev loss: 0.5503 r:0.6879
si_en Dev loss: 0.7051 r:0.5830
ne_en Dev loss: 1.2084 r:0.7073
ru_en Dev loss: 0.4042 r:0.7461
Current avg r:0.6027 Best avg r: 0.6284
00:15:52,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:09,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:18:39,580 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2641
en_de Dev loss: 0.8826 r:0.1735
en_zh Dev loss: 0.7905 r:0.4436
ro_en Dev loss: 0.3559 r:0.8174
et_en Dev loss: 0.4613 r:0.6572
si_en Dev loss: 0.8426 r:0.5491
ne_en Dev loss: 0.7343 r:0.6807
ru_en Dev loss: 0.4672 r:0.7186
Current avg r:0.5772 Best avg r: 0.6284
00:22:29,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:46,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:16,27 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2500
en_de Dev loss: 0.8911 r:0.1955
en_zh Dev loss: 0.7570 r:0.4652
ro_en Dev loss: 0.3324 r:0.8227
et_en Dev loss: 0.4542 r:0.6673
si_en Dev loss: 0.8589 r:0.5535
ne_en Dev loss: 0.7239 r:0.6891
ru_en Dev loss: 0.4202 r:0.7491
Current avg r:0.5917 Best avg r: 0.6284
00:29:06,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:30:23,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:53,183 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2641
en_de Dev loss: 0.8842 r:0.2081
en_zh Dev loss: 0.7747 r:0.4481
ro_en Dev loss: 0.3458 r:0.8263
et_en Dev loss: 0.4431 r:0.6746
si_en Dev loss: 0.8124 r:0.5584
ne_en Dev loss: 0.7166 r:0.6886
ru_en Dev loss: 0.4816 r:0.7229
Current avg r:0.5896 Best avg r: 0.6284
00:35:43,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:00,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:30,389 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2561
en_de Dev loss: 0.8705 r:0.1969
en_zh Dev loss: 0.7721 r:0.4519
ro_en Dev loss: 0.3332 r:0.8229
et_en Dev loss: 0.4400 r:0.6649
si_en Dev loss: 0.8392 r:0.5517
ne_en Dev loss: 0.7038 r:0.6942
ru_en Dev loss: 0.4287 r:0.7368
Current avg r:0.5885 Best avg r: 0.6284
00:42:21,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:38,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:08,747 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2137
en_de Dev loss: 0.8867 r:0.1929
en_zh Dev loss: 0.7798 r:0.4624
ro_en Dev loss: 0.3436 r:0.8270
et_en Dev loss: 0.4697 r:0.6794
si_en Dev loss: 0.8286 r:0.5640
ne_en Dev loss: 0.8026 r:0.7044
ru_en Dev loss: 0.4477 r:0.7409
Current avg r:0.5959 Best avg r: 0.6284
00:48:58,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:15,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:51:45,760 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2304
en_de Dev loss: 0.8649 r:0.1848
en_zh Dev loss: 0.7510 r:0.4547
ro_en Dev loss: 0.3322 r:0.8237
et_en Dev loss: 0.4399 r:0.6735
si_en Dev loss: 0.8467 r:0.5551
ne_en Dev loss: 0.7443 r:0.6946
ru_en Dev loss: 0.4103 r:0.7436
Current avg r:0.5900 Best avg r: 0.6284
00:55:35,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:52,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:22,234 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2397
en_de Dev loss: 0.8771 r:0.1891
en_zh Dev loss: 0.7853 r:0.4434
ro_en Dev loss: 0.3341 r:0.8209
et_en Dev loss: 0.4794 r:0.6812
si_en Dev loss: 0.7670 r:0.5590
ne_en Dev loss: 0.8579 r:0.6992
ru_en Dev loss: 0.4331 r:0.7383
Current avg r:0.5902 Best avg r: 0.6284
01:02:12,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:28,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:58,668 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2429
en_de Dev loss: 0.8841 r:0.1883
en_zh Dev loss: 0.7969 r:0.4387
ro_en Dev loss: 0.3426 r:0.8190
et_en Dev loss: 0.4613 r:0.6747
si_en Dev loss: 0.8651 r:0.5408
ne_en Dev loss: 0.7689 r:0.6834
ru_en Dev loss: 0.4728 r:0.7231
Current avg r:0.5811 Best avg r: 0.6284
01:08:48,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:05,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:35,114 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2396
en_de Dev loss: 0.8754 r:0.1919
en_zh Dev loss: 0.7831 r:0.4396
ro_en Dev loss: 0.3461 r:0.8154
et_en Dev loss: 0.4460 r:0.6717
si_en Dev loss: 0.8722 r:0.5362
ne_en Dev loss: 0.6923 r:0.6829
ru_en Dev loss: 0.4294 r:0.7423
Current avg r:0.5829 Best avg r: 0.6284
01:15:25,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:41,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:11,671 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2202
en_de Dev loss: 0.8700 r:0.2218
en_zh Dev loss: 0.7845 r:0.4413
ro_en Dev loss: 0.3544 r:0.8197
et_en Dev loss: 0.4477 r:0.6775
si_en Dev loss: 0.8308 r:0.5469
ne_en Dev loss: 0.7436 r:0.6940
ru_en Dev loss: 0.4534 r:0.7328
Current avg r:0.5906 Best avg r: 0.6284
01:22:01,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:18,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:48,89 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2189
en_de Dev loss: 0.8919 r:0.1917
en_zh Dev loss: 0.8308 r:0.4340
ro_en Dev loss: 0.3670 r:0.8214
et_en Dev loss: 0.4769 r:0.6766
si_en Dev loss: 0.8641 r:0.5474
ne_en Dev loss: 0.7636 r:0.6875
ru_en Dev loss: 0.4603 r:0.7365
Current avg r:0.5850 Best avg r: 0.6284
01:28:37,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:54,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:31:24,578 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2121
en_de Dev loss: 0.8901 r:0.2104
en_zh Dev loss: 0.8289 r:0.4340
ro_en Dev loss: 0.3443 r:0.8216
et_en Dev loss: 0.4820 r:0.6720
si_en Dev loss: 0.8344 r:0.5491
ne_en Dev loss: 0.8092 r:0.6872
ru_en Dev loss: 0.4599 r:0.7343
Current avg r:0.5869 Best avg r: 0.6284
01:35:14,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:36:31,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:01,24 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2246
en_de Dev loss: 0.8764 r:0.2194
en_zh Dev loss: 0.7859 r:0.4591
ro_en Dev loss: 0.3217 r:0.8249
et_en Dev loss: 0.4748 r:0.6800
si_en Dev loss: 0.8045 r:0.5576
ne_en Dev loss: 0.7969 r:0.7037
ru_en Dev loss: 0.4081 r:0.7578
Current avg r:0.6003 Best avg r: 0.6284
01:41:50,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:07,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:44:37,435 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2147
en_de Dev loss: 0.8796 r:0.2173
en_zh Dev loss: 0.8203 r:0.4364
ro_en Dev loss: 0.3571 r:0.8213
et_en Dev loss: 0.4628 r:0.6755
si_en Dev loss: 0.9039 r:0.5397
ne_en Dev loss: 0.6950 r:0.6939
ru_en Dev loss: 0.4564 r:0.7373
Current avg r:0.5888 Best avg r: 0.6284
01:48:29,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:49:47,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:18,0 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2129
en_de Dev loss: 0.8645 r:0.2192
en_zh Dev loss: 0.7542 r:0.4596
ro_en Dev loss: 0.3402 r:0.8222
et_en Dev loss: 0.4498 r:0.6739
si_en Dev loss: 0.8435 r:0.5403
ne_en Dev loss: 0.7398 r:0.6904
ru_en Dev loss: 0.4205 r:0.7430
Current avg r:0.5926 Best avg r: 0.6284
01:55:11,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:56:29,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:58:00,120 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2271
en_de Dev loss: 0.8494 r:0.2246
en_zh Dev loss: 0.7404 r:0.4488
ro_en Dev loss: 0.3096 r:0.8217
et_en Dev loss: 0.4505 r:0.6685
si_en Dev loss: 0.7976 r:0.5420
ne_en Dev loss: 0.7461 r:0.6889
ru_en Dev loss: 0.4289 r:0.7260
Current avg r:0.5886 Best avg r: 0.6284
02:01:53,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:03:11,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:04:42,331 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2199
en_de Dev loss: 0.8842 r:0.2116
en_zh Dev loss: 0.7706 r:0.4472
ro_en Dev loss: 0.3240 r:0.8242
et_en Dev loss: 0.4535 r:0.6799
si_en Dev loss: 0.8031 r:0.5481
ne_en Dev loss: 0.7762 r:0.6999
ru_en Dev loss: 0.4230 r:0.7442
Current avg r:0.5936 Best avg r: 0.6284
02:08:35,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:09:53,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:11:23,975 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2169
en_de Dev loss: 0.8795 r:0.1988
en_zh Dev loss: 0.7780 r:0.4559
ro_en Dev loss: 0.3581 r:0.8193
et_en Dev loss: 0.4871 r:0.6729
si_en Dev loss: 0.8779 r:0.5471
ne_en Dev loss: 0.7399 r:0.7028
ru_en Dev loss: 0.4516 r:0.7300
Current avg r:0.5895 Best avg r: 0.6284
02:15:16,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:34,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:18:04,759 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2120
en_de Dev loss: 0.8756 r:0.2055
en_zh Dev loss: 0.7861 r:0.4625
ro_en Dev loss: 0.3468 r:0.8198
et_en Dev loss: 0.4629 r:0.6731
si_en Dev loss: 0.8820 r:0.5515
ne_en Dev loss: 0.6555 r:0.6971
ru_en Dev loss: 0.4461 r:0.7462
Current avg r:0.5937 Best avg r: 0.6284
02:21:56,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:23:14,56 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:24:44,161 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1956
en_de Dev loss: 0.9113 r:0.1919
en_zh Dev loss: 0.8287 r:0.4658
ro_en Dev loss: 0.3532 r:0.8237
et_en Dev loss: 0.4759 r:0.6834
si_en Dev loss: 0.9331 r:0.5478
ne_en Dev loss: 0.6880 r:0.6974
ru_en Dev loss: 0.4594 r:0.7505
Current avg r:0.5944 Best avg r: 0.6284
02:28:34,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:52,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:31:23,463 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1955
en_de Dev loss: 0.8858 r:0.1907
en_zh Dev loss: 0.7757 r:0.4509
ro_en Dev loss: 0.3304 r:0.8231
et_en Dev loss: 0.4553 r:0.6806
si_en Dev loss: 0.8735 r:0.5373
ne_en Dev loss: 0.7563 r:0.6837
ru_en Dev loss: 0.4486 r:0.7343
Current avg r:0.5858 Best avg r: 0.6284
02:35:16,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:34,458 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:05,291 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1873
en_de Dev loss: 0.8786 r:0.1928
en_zh Dev loss: 0.7903 r:0.4542
ro_en Dev loss: 0.3307 r:0.8235
et_en Dev loss: 0.4347 r:0.6756
si_en Dev loss: 0.8610 r:0.5446
ne_en Dev loss: 0.6735 r:0.6875
ru_en Dev loss: 0.4361 r:0.7434
Current avg r:0.5888 Best avg r: 0.6284
02:41:58,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:16,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:47,482 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1895
en_de Dev loss: 0.8882 r:0.1650
en_zh Dev loss: 0.8216 r:0.4293
ro_en Dev loss: 0.3243 r:0.8206
et_en Dev loss: 0.4456 r:0.6816
si_en Dev loss: 0.8607 r:0.5399
ne_en Dev loss: 0.7389 r:0.6812
ru_en Dev loss: 0.4215 r:0.7458
Current avg r:0.5805 Best avg r: 0.6284
02:48:40,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:49:58,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:29,122 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1961
en_de Dev loss: 0.8949 r:0.1721
en_zh Dev loss: 0.8145 r:0.4305
ro_en Dev loss: 0.3285 r:0.8186
et_en Dev loss: 0.4529 r:0.6820
si_en Dev loss: 0.8657 r:0.5358
ne_en Dev loss: 0.7275 r:0.6896
ru_en Dev loss: 0.4191 r:0.7496
Current avg r:0.5826 Best avg r: 0.6284
02:55:20,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:37,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:58:08,47 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1868
en_de Dev loss: 0.8900 r:0.1753
en_zh Dev loss: 0.7879 r:0.4437
ro_en Dev loss: 0.3169 r:0.8250
et_en Dev loss: 0.4563 r:0.6852
si_en Dev loss: 0.7840 r:0.5477
ne_en Dev loss: 0.7090 r:0.6983
ru_en Dev loss: 0.3966 r:0.7544
Current avg r:0.5900 Best avg r: 0.6284
03:01:58,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:15,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:46,142 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1918
en_de Dev loss: 0.8836 r:0.1907
en_zh Dev loss: 0.7656 r:0.4528
ro_en Dev loss: 0.3253 r:0.8209
et_en Dev loss: 0.4346 r:0.6767
si_en Dev loss: 0.8137 r:0.5399
ne_en Dev loss: 0.6756 r:0.6881
ru_en Dev loss: 0.4439 r:0.7365
Current avg r:0.5865 Best avg r: 0.6284
03:08:39,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:57,438 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:28,261 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1856
en_de Dev loss: 0.9209 r:0.1798
en_zh Dev loss: 0.8090 r:0.4497
ro_en Dev loss: 0.3735 r:0.8184
et_en Dev loss: 0.4594 r:0.6710
si_en Dev loss: 0.8751 r:0.5373
ne_en Dev loss: 0.6417 r:0.6894
ru_en Dev loss: 0.4690 r:0.7395
Current avg r:0.5836 Best avg r: 0.6284
03:15:21,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:16:38,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:18:09,872 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1929
en_de Dev loss: 0.8921 r:0.1856
en_zh Dev loss: 0.7537 r:0.4603
ro_en Dev loss: 0.3160 r:0.8200
et_en Dev loss: 0.4420 r:0.6814
si_en Dev loss: 0.8092 r:0.5417
ne_en Dev loss: 0.6491 r:0.7012
ru_en Dev loss: 0.4064 r:0.7567
Current avg r:0.5924 Best avg r: 0.6284
03:22:03,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:23:20,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:24:51,767 root INFO Epoch 7 Global steps: 69000 Train loss: 0.2056
en_de Dev loss: 0.8992 r:0.1873
en_zh Dev loss: 0.8006 r:0.4498
ro_en Dev loss: 0.3434 r:0.8155
et_en Dev loss: 0.4587 r:0.6666
si_en Dev loss: 0.9274 r:0.5278
ne_en Dev loss: 0.6203 r:0.6882
ru_en Dev loss: 0.4528 r:0.7432
Current avg r:0.5826 Best avg r: 0.6284
03:28:44,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:30:02,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:32,187 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1832
en_de Dev loss: 0.9036 r:0.1881
en_zh Dev loss: 0.8265 r:0.4444
ro_en Dev loss: 0.3768 r:0.8139
et_en Dev loss: 0.4836 r:0.6657
si_en Dev loss: 0.9019 r:0.5354
ne_en Dev loss: 0.7165 r:0.6915
ru_en Dev loss: 0.4636 r:0.7407
Current avg r:0.5828 Best avg r: 0.6284
03:35:23,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:40,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:11,27 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1917
en_de Dev loss: 0.8813 r:0.1802
en_zh Dev loss: 0.7498 r:0.4562
ro_en Dev loss: 0.3423 r:0.8186
et_en Dev loss: 0.4953 r:0.6633
si_en Dev loss: 0.8618 r:0.5334
ne_en Dev loss: 0.7787 r:0.6892
ru_en Dev loss: 0.4130 r:0.7458
Current avg r:0.5838 Best avg r: 0.6284
03:42:03,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:20,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:44:51,697 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1791
en_de Dev loss: 0.9074 r:0.1763
en_zh Dev loss: 0.8039 r:0.4462
ro_en Dev loss: 0.3631 r:0.8151
et_en Dev loss: 0.5070 r:0.6576
si_en Dev loss: 0.9781 r:0.5248
ne_en Dev loss: 0.7488 r:0.6808
ru_en Dev loss: 0.4559 r:0.7376
Current avg r:0.5769 Best avg r: 0.6284
03:48:44,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:50:02,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:51:33,250 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1766
en_de Dev loss: 0.8740 r:0.1893
en_zh Dev loss: 0.7611 r:0.4524
ro_en Dev loss: 0.3383 r:0.8162
et_en Dev loss: 0.4584 r:0.6567
si_en Dev loss: 0.9096 r:0.5287
ne_en Dev loss: 0.6675 r:0.6786
ru_en Dev loss: 0.4582 r:0.7217
Current avg r:0.5777 Best avg r: 0.6284
03:55:26,70 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:56:43,962 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:58:14,775 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1732
en_de Dev loss: 0.9026 r:0.1826
en_zh Dev loss: 0.7935 r:0.4568
ro_en Dev loss: 0.3357 r:0.8201
et_en Dev loss: 0.4820 r:0.6699
si_en Dev loss: 0.8710 r:0.5335
ne_en Dev loss: 0.7692 r:0.6915
ru_en Dev loss: 0.4402 r:0.7386
Current avg r:0.5847 Best avg r: 0.6284
04:02:09,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:03:27,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:58,503 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1673
en_de Dev loss: 0.8947 r:0.1949
en_zh Dev loss: 0.8093 r:0.4458
ro_en Dev loss: 0.3622 r:0.8193
et_en Dev loss: 0.4790 r:0.6678
si_en Dev loss: 0.9383 r:0.5383
ne_en Dev loss: 0.7439 r:0.6906
ru_en Dev loss: 0.4543 r:0.7398
Current avg r:0.5852 Best avg r: 0.6284
04:08:50,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:10:07,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:11:37,706 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1693
en_de Dev loss: 0.9045 r:0.1763
en_zh Dev loss: 0.8150 r:0.4569
ro_en Dev loss: 0.3649 r:0.8216
et_en Dev loss: 0.4943 r:0.6697
si_en Dev loss: 0.9210 r:0.5412
ne_en Dev loss: 0.7898 r:0.6929
ru_en Dev loss: 0.4448 r:0.7502
Current avg r:0.5870 Best avg r: 0.6284
04:15:29,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:16:46,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:18:17,713 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1605
en_de Dev loss: 0.9171 r:0.1706
en_zh Dev loss: 0.7996 r:0.4565
ro_en Dev loss: 0.3254 r:0.8249
et_en Dev loss: 0.4786 r:0.6772
si_en Dev loss: 0.8129 r:0.5448
ne_en Dev loss: 0.7944 r:0.7019
ru_en Dev loss: 0.3969 r:0.7644
Current avg r:0.5915 Best avg r: 0.6284
04:22:11,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:23:28,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:24:59,746 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1619
en_de Dev loss: 0.9076 r:0.1530
en_zh Dev loss: 0.7772 r:0.4633
ro_en Dev loss: 0.3294 r:0.8255
et_en Dev loss: 0.4575 r:0.6821
si_en Dev loss: 0.8425 r:0.5412
ne_en Dev loss: 0.7359 r:0.6967
ru_en Dev loss: 0.4168 r:0.7522
Current avg r:0.5877 Best avg r: 0.6284
04:28:52,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:10,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:41,259 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1568
en_de Dev loss: 0.9186 r:0.1694
en_zh Dev loss: 0.7841 r:0.4661
ro_en Dev loss: 0.3233 r:0.8252
et_en Dev loss: 0.4521 r:0.6735
si_en Dev loss: 0.8751 r:0.5350
ne_en Dev loss: 0.6841 r:0.6919
ru_en Dev loss: 0.4477 r:0.7523
Current avg r:0.5876 Best avg r: 0.6284
04:35:34,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:52,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:22,840 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1609
en_de Dev loss: 0.9285 r:0.1614
en_zh Dev loss: 0.8229 r:0.4609
ro_en Dev loss: 0.3470 r:0.8228
et_en Dev loss: 0.4815 r:0.6776
si_en Dev loss: 0.8214 r:0.5448
ne_en Dev loss: 0.8188 r:0.6986
ru_en Dev loss: 0.4525 r:0.7472
Current avg r:0.5876 Best avg r: 0.6284
04:42:15,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:32,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:03,58 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1728
en_de Dev loss: 0.9247 r:0.1790
en_zh Dev loss: 0.7769 r:0.4736
ro_en Dev loss: 0.3553 r:0.8212
et_en Dev loss: 0.5014 r:0.6614
si_en Dev loss: 0.8221 r:0.5450
ne_en Dev loss: 0.8583 r:0.6955
ru_en Dev loss: 0.4103 r:0.7534
Current avg r:0.5899 Best avg r: 0.6284
04:48:54,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:11,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:42,366 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1743
en_de Dev loss: 0.8915 r:0.1725
en_zh Dev loss: 0.7405 r:0.4667
ro_en Dev loss: 0.3280 r:0.8292
et_en Dev loss: 0.4805 r:0.6758
si_en Dev loss: 0.8644 r:0.5409
ne_en Dev loss: 0.8251 r:0.6900
ru_en Dev loss: 0.4072 r:0.7520
Current avg r:0.5896 Best avg r: 0.6284
04:55:35,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:56:53,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:23,992 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1567
en_de Dev loss: 0.8978 r:0.1686
en_zh Dev loss: 0.7918 r:0.4603
ro_en Dev loss: 0.3440 r:0.8237
et_en Dev loss: 0.4562 r:0.6680
si_en Dev loss: 0.9148 r:0.5294
ne_en Dev loss: 0.6931 r:0.6842
ru_en Dev loss: 0.4296 r:0.7486
Current avg r:0.5833 Best avg r: 0.6284
05:02:17,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:34,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:05:05,693 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1556
en_de Dev loss: 0.9097 r:0.1791
en_zh Dev loss: 0.8096 r:0.4627
ro_en Dev loss: 0.3680 r:0.8218
et_en Dev loss: 0.4873 r:0.6741
si_en Dev loss: 0.9408 r:0.5325
ne_en Dev loss: 0.7325 r:0.6924
ru_en Dev loss: 0.4311 r:0.7587
Current avg r:0.5888 Best avg r: 0.6284
05:08:58,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:16,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:46,973 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1693
en_de Dev loss: 0.9134 r:0.1743
en_zh Dev loss: 0.8359 r:0.4535
ro_en Dev loss: 0.3774 r:0.8199
et_en Dev loss: 0.4911 r:0.6738
si_en Dev loss: 0.9111 r:0.5301
ne_en Dev loss: 0.7474 r:0.6907
ru_en Dev loss: 0.4404 r:0.7544
Current avg r:0.5852 Best avg r: 0.6284
05:15:39,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:16:56,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:26,659 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1642
en_de Dev loss: 0.8912 r:0.1853
en_zh Dev loss: 0.7574 r:0.4624
ro_en Dev loss: 0.3355 r:0.8194
et_en Dev loss: 0.4761 r:0.6700
si_en Dev loss: 0.8618 r:0.5274
ne_en Dev loss: 0.7731 r:0.6869
ru_en Dev loss: 0.4177 r:0.7462
Current avg r:0.5853 Best avg r: 0.6284
05:22:17,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:23:34,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:04,569 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1616
en_de Dev loss: 0.9111 r:0.2024
en_zh Dev loss: 0.7900 r:0.4619
ro_en Dev loss: 0.3458 r:0.8198
et_en Dev loss: 0.4708 r:0.6774
si_en Dev loss: 0.8762 r:0.5351
ne_en Dev loss: 0.7337 r:0.6950
ru_en Dev loss: 0.4595 r:0.7403
Current avg r:0.5903 Best avg r: 0.6284
05:28:54,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:11,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:40,992 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1611
en_de Dev loss: 0.8879 r:0.1926
en_zh Dev loss: 0.7912 r:0.4577
ro_en Dev loss: 0.3388 r:0.8172
et_en Dev loss: 0.4642 r:0.6684
si_en Dev loss: 0.9282 r:0.5295
ne_en Dev loss: 0.7263 r:0.6874
ru_en Dev loss: 0.4711 r:0.7275
Current avg r:0.5829 Best avg r: 0.6284
05:35:30,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:47,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:17,431 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1599
en_de Dev loss: 0.8940 r:0.1820
en_zh Dev loss: 0.7632 r:0.4681
ro_en Dev loss: 0.3411 r:0.8220
et_en Dev loss: 0.4708 r:0.6728
si_en Dev loss: 0.8907 r:0.5360
ne_en Dev loss: 0.7239 r:0.6917
ru_en Dev loss: 0.4428 r:0.7425
Current avg r:0.5879 Best avg r: 0.6284
05:42:08,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:25,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:44:55,279 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1415
en_de Dev loss: 0.9009 r:0.1641
en_zh Dev loss: 0.7472 r:0.4625
ro_en Dev loss: 0.3589 r:0.8178
et_en Dev loss: 0.4376 r:0.6629
si_en Dev loss: 0.9035 r:0.5281
ne_en Dev loss: 0.6072 r:0.6732
ru_en Dev loss: 0.4793 r:0.7283
Current avg r:0.5767 Best avg r: 0.6284
05:48:45,245 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:50:02,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:51:31,818 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1443
en_de Dev loss: 0.9109 r:0.1857
en_zh Dev loss: 0.7808 r:0.4677
ro_en Dev loss: 0.3739 r:0.8209
et_en Dev loss: 0.4783 r:0.6640
si_en Dev loss: 0.9389 r:0.5390
ne_en Dev loss: 0.6914 r:0.6917
ru_en Dev loss: 0.4530 r:0.7483
Current avg r:0.5882 Best avg r: 0.6284
05:55:21,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:56:38,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:58:08,332 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1448
en_de Dev loss: 0.8998 r:0.1812
en_zh Dev loss: 0.7749 r:0.4660
ro_en Dev loss: 0.3466 r:0.8186
et_en Dev loss: 0.4706 r:0.6693
si_en Dev loss: 0.9029 r:0.5350
ne_en Dev loss: 0.7558 r:0.6920
ru_en Dev loss: 0.4430 r:0.7459
Current avg r:0.5868 Best avg r: 0.6284
06:01:58,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:15,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:44,755 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1441
en_de Dev loss: 0.9137 r:0.1866
en_zh Dev loss: 0.7995 r:0.4663
ro_en Dev loss: 0.3617 r:0.8227
et_en Dev loss: 0.4915 r:0.6668
si_en Dev loss: 0.9219 r:0.5317
ne_en Dev loss: 0.7678 r:0.6820
ru_en Dev loss: 0.4727 r:0.7394
Current avg r:0.5851 Best avg r: 0.6284
06:08:34,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:51,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:21,223 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1459
en_de Dev loss: 0.8801 r:0.1847
en_zh Dev loss: 0.7546 r:0.4596
ro_en Dev loss: 0.3504 r:0.8127
et_en Dev loss: 0.4754 r:0.6612
si_en Dev loss: 0.9714 r:0.5204
ne_en Dev loss: 0.7338 r:0.6823
ru_en Dev loss: 0.4275 r:0.7452
Current avg r:0.5809 Best avg r: 0.6284
06:15:11,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:16:28,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:17:57,686 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1490
en_de Dev loss: 0.9024 r:0.1919
en_zh Dev loss: 0.7866 r:0.4717
ro_en Dev loss: 0.3550 r:0.8210
et_en Dev loss: 0.4823 r:0.6688
si_en Dev loss: 0.9507 r:0.5275
ne_en Dev loss: 0.7357 r:0.6942
ru_en Dev loss: 0.4596 r:0.7473
Current avg r:0.5889 Best avg r: 0.6284
06:21:47,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:23:04,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:34,97 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1501
en_de Dev loss: 0.8950 r:0.1816
en_zh Dev loss: 0.7812 r:0.4635
ro_en Dev loss: 0.3560 r:0.8192
et_en Dev loss: 0.4751 r:0.6723
si_en Dev loss: 0.8458 r:0.5398
ne_en Dev loss: 0.7828 r:0.6932
ru_en Dev loss: 0.4361 r:0.7481
Current avg r:0.5882 Best avg r: 0.6284
06:28:24,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:40,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:10,536 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1470
en_de Dev loss: 0.8979 r:0.1894
en_zh Dev loss: 0.7768 r:0.4681
ro_en Dev loss: 0.3364 r:0.8196
et_en Dev loss: 0.4712 r:0.6669
si_en Dev loss: 0.8453 r:0.5376
ne_en Dev loss: 0.7546 r:0.6955
ru_en Dev loss: 0.4277 r:0.7506
Current avg r:0.5897 Best avg r: 0.6284
06:35:00,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:17,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:46,929 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1499
en_de Dev loss: 0.9195 r:0.1901
en_zh Dev loss: 0.7946 r:0.4735
ro_en Dev loss: 0.3588 r:0.8191
et_en Dev loss: 0.4938 r:0.6627
si_en Dev loss: 0.9126 r:0.5303
ne_en Dev loss: 0.7562 r:0.6903
ru_en Dev loss: 0.4596 r:0.7449
Current avg r:0.5873 Best avg r: 0.6284
06:41:36,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:42:53,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:44:23,378 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1368
en_de Dev loss: 0.9118 r:0.1741
en_zh Dev loss: 0.7383 r:0.4775
ro_en Dev loss: 0.3246 r:0.8221
et_en Dev loss: 0.4585 r:0.6827
si_en Dev loss: 0.8531 r:0.5339
ne_en Dev loss: 0.7317 r:0.6972
ru_en Dev loss: 0.4297 r:0.7495
Current avg r:0.5910 Best avg r: 0.6284
06:48:13,206 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:49:30,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:50:59,729 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1508
en_de Dev loss: 0.9139 r:0.1688
en_zh Dev loss: 0.7831 r:0.4678
ro_en Dev loss: 0.3448 r:0.8211
et_en Dev loss: 0.4605 r:0.6631
si_en Dev loss: 0.9476 r:0.5300
ne_en Dev loss: 0.6450 r:0.6915
ru_en Dev loss: 0.4553 r:0.7363
Current avg r:0.5826 Best avg r: 0.6284
06:54:49,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:56:06,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:57:36,291 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1414
en_de Dev loss: 0.9204 r:0.1552
en_zh Dev loss: 0.7495 r:0.4806
ro_en Dev loss: 0.3424 r:0.8209
et_en Dev loss: 0.4751 r:0.6774
si_en Dev loss: 0.8894 r:0.5332
ne_en Dev loss: 0.7511 r:0.7041
ru_en Dev loss: 0.3994 r:0.7616
Current avg r:0.5904 Best avg r: 0.6284
07:01:26,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:43,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:04:12,780 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1445
en_de Dev loss: 0.9359 r:0.1364
en_zh Dev loss: 0.7990 r:0.4682
ro_en Dev loss: 0.3658 r:0.8202
et_en Dev loss: 0.4718 r:0.6585
si_en Dev loss: 0.9398 r:0.5251
ne_en Dev loss: 0.6362 r:0.6724
ru_en Dev loss: 0.4836 r:0.7318
Current avg r:0.5732 Best avg r: 0.6284
07:08:02,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:09:19,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:10:49,300 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1416
en_de Dev loss: 0.9251 r:0.1504
en_zh Dev loss: 0.7935 r:0.4651
ro_en Dev loss: 0.3586 r:0.8189
et_en Dev loss: 0.4699 r:0.6621
si_en Dev loss: 0.9723 r:0.5255
ne_en Dev loss: 0.6711 r:0.6822
ru_en Dev loss: 0.4741 r:0.7324
Current avg r:0.5767 Best avg r: 0.6284
07:14:39,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:15:56,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:25,894 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1499
en_de Dev loss: 0.9344 r:0.1401
en_zh Dev loss: 0.7417 r:0.4807
ro_en Dev loss: 0.3199 r:0.8229
et_en Dev loss: 0.4703 r:0.6733
si_en Dev loss: 0.8369 r:0.5339
ne_en Dev loss: 0.8130 r:0.7034
ru_en Dev loss: 0.4087 r:0.7502
Current avg r:0.5864 Best avg r: 0.6284
07:21:16,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:22:33,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:24:03,535 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1291
en_de Dev loss: 0.9391 r:0.1313
en_zh Dev loss: 0.7738 r:0.4746
ro_en Dev loss: 0.3432 r:0.8218
et_en Dev loss: 0.4634 r:0.6644
si_en Dev loss: 0.9029 r:0.5279
ne_en Dev loss: 0.6551 r:0.6907
ru_en Dev loss: 0.4634 r:0.7420
Current avg r:0.5790 Best avg r: 0.6284
07:27:53,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:29:10,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:40,24 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1270
en_de Dev loss: 0.9558 r:0.1528
en_zh Dev loss: 0.8169 r:0.4703
ro_en Dev loss: 0.3609 r:0.8179
et_en Dev loss: 0.4819 r:0.6657
si_en Dev loss: 0.8963 r:0.5347
ne_en Dev loss: 0.7036 r:0.6976
ru_en Dev loss: 0.4733 r:0.7381
Current avg r:0.5824 Best avg r: 0.6284
07:34:29,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:35:46,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:16,469 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1299
en_de Dev loss: 0.9364 r:0.1490
en_zh Dev loss: 0.7927 r:0.4685
ro_en Dev loss: 0.3524 r:0.8176
et_en Dev loss: 0.4574 r:0.6680
si_en Dev loss: 0.9433 r:0.5284
ne_en Dev loss: 0.6549 r:0.6898
ru_en Dev loss: 0.4497 r:0.7495
Current avg r:0.5815 Best avg r: 0.6284
07:41:06,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:42:23,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:43:53,935 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1252
en_de Dev loss: 0.9051 r:0.1484
en_zh Dev loss: 0.7528 r:0.4602
ro_en Dev loss: 0.3250 r:0.8178
et_en Dev loss: 0.4728 r:0.6730
si_en Dev loss: 0.8726 r:0.5241
ne_en Dev loss: 0.8227 r:0.6843
ru_en Dev loss: 0.4121 r:0.7421
Current avg r:0.5786 Best avg r: 0.6284
07:47:44,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:49:01,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:50:31,702 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1314
en_de Dev loss: 0.9169 r:0.1519
en_zh Dev loss: 0.7889 r:0.4681
ro_en Dev loss: 0.3491 r:0.8191
et_en Dev loss: 0.4623 r:0.6729
si_en Dev loss: 0.9487 r:0.5277
ne_en Dev loss: 0.7348 r:0.6880
ru_en Dev loss: 0.4465 r:0.7450
Current avg r:0.5818 Best avg r: 0.6284
07:54:22,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:55:39,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:57:09,416 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1274
en_de Dev loss: 0.9115 r:0.1526
en_zh Dev loss: 0.7209 r:0.4783
ro_en Dev loss: 0.3235 r:0.8166
et_en Dev loss: 0.4695 r:0.6753
si_en Dev loss: 0.8604 r:0.5316
ne_en Dev loss: 0.8172 r:0.6974
ru_en Dev loss: 0.4033 r:0.7504
Current avg r:0.5860 Best avg r: 0.6284
08:00:59,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:16,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:46,548 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1257
en_de Dev loss: 0.9135 r:0.1563
en_zh Dev loss: 0.7474 r:0.4769
ro_en Dev loss: 0.3263 r:0.8219
et_en Dev loss: 0.4539 r:0.6744
si_en Dev loss: 0.8712 r:0.5322
ne_en Dev loss: 0.7628 r:0.6934
ru_en Dev loss: 0.4196 r:0.7469
Current avg r:0.5860 Best avg r: 0.6284
08:07:36,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:53,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:22,997 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1312
en_de Dev loss: 0.9087 r:0.1610
en_zh Dev loss: 0.7388 r:0.4771
ro_en Dev loss: 0.3304 r:0.8213
et_en Dev loss: 0.4602 r:0.6756
si_en Dev loss: 0.8627 r:0.5368
ne_en Dev loss: 0.7442 r:0.6927
ru_en Dev loss: 0.4367 r:0.7444
Current avg r:0.5870 Best avg r: 0.6284
08:14:12,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:29,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:59,468 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1291
en_de Dev loss: 0.9326 r:0.1448
en_zh Dev loss: 0.7989 r:0.4656
ro_en Dev loss: 0.3670 r:0.8182
et_en Dev loss: 0.4860 r:0.6710
si_en Dev loss: 0.9377 r:0.5279
ne_en Dev loss: 0.7357 r:0.6890
ru_en Dev loss: 0.4620 r:0.7448
Current avg r:0.5802 Best avg r: 0.6284
08:20:49,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:22:06,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:35,962 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1331
en_de Dev loss: 0.9326 r:0.1358
en_zh Dev loss: 0.7975 r:0.4708
ro_en Dev loss: 0.3684 r:0.8182
et_en Dev loss: 0.4759 r:0.6715
si_en Dev loss: 0.9245 r:0.5339
ne_en Dev loss: 0.7013 r:0.6884
ru_en Dev loss: 0.4567 r:0.7450
Current avg r:0.5805 Best avg r: 0.6284
08:27:25,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:42,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:12,466 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1220
en_de Dev loss: 0.9279 r:0.1432
en_zh Dev loss: 0.7411 r:0.4810
ro_en Dev loss: 0.3344 r:0.8193
et_en Dev loss: 0.4790 r:0.6793
si_en Dev loss: 0.8059 r:0.5459
ne_en Dev loss: 0.8535 r:0.6993
ru_en Dev loss: 0.4106 r:0.7533
Current avg r:0.5888 Best avg r: 0.6284
08:34:02,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:34:28,5 root INFO 
id:en_zh cur r: 0.4961 best r: 0.4961
08:35:19,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:48,977 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1299
en_de Dev loss: 0.9462 r:0.1472
en_zh Dev loss: 0.7299 r:0.4899
ro_en Dev loss: 0.3261 r:0.8224
et_en Dev loss: 0.4696 r:0.6854
si_en Dev loss: 0.7780 r:0.5414
ne_en Dev loss: 0.8653 r:0.7021
ru_en Dev loss: 0.3931 r:0.7629
Current avg r:0.5930 Best avg r: 0.6284
08:40:38,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:41:55,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:25,426 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1261
en_de Dev loss: 0.9349 r:0.1627
en_zh Dev loss: 0.8058 r:0.4685
ro_en Dev loss: 0.3701 r:0.8162
et_en Dev loss: 0.4772 r:0.6775
si_en Dev loss: 0.8732 r:0.5337
ne_en Dev loss: 0.8565 r:0.6948
ru_en Dev loss: 0.4473 r:0.7482
Current avg r:0.5859 Best avg r: 0.6284
08:47:15,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:32,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:50:01,954 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1216
en_de Dev loss: 0.9130 r:0.1525
en_zh Dev loss: 0.7555 r:0.4736
ro_en Dev loss: 0.3302 r:0.8175
et_en Dev loss: 0.4470 r:0.6682
si_en Dev loss: 0.8689 r:0.5288
ne_en Dev loss: 0.7467 r:0.6885
ru_en Dev loss: 0.4512 r:0.7366
Current avg r:0.5808 Best avg r: 0.6284
08:53:51,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:54:17,542 root INFO 
id:en_zh cur r: 0.4965 best r: 0.4965
08:55:08,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:38,485 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1286
en_de Dev loss: 0.9181 r:0.1548
en_zh Dev loss: 0.7378 r:0.4884
ro_en Dev loss: 0.3426 r:0.8174
et_en Dev loss: 0.4618 r:0.6652
si_en Dev loss: 0.8622 r:0.5372
ne_en Dev loss: 0.7487 r:0.6912
ru_en Dev loss: 0.4349 r:0.7397
Current avg r:0.5849 Best avg r: 0.6284
09:00:29,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:46,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:16,215 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1136
en_de Dev loss: 0.9523 r:0.1308
en_zh Dev loss: 0.8089 r:0.4741
ro_en Dev loss: 0.3539 r:0.8194
et_en Dev loss: 0.4722 r:0.6655
si_en Dev loss: 0.9151 r:0.5308
ne_en Dev loss: 0.7472 r:0.6895
ru_en Dev loss: 0.4733 r:0.7379
Current avg r:0.5783 Best avg r: 0.6284
09:07:06,196 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:08:23,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:52,782 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1157
en_de Dev loss: 0.9522 r:0.1397
en_zh Dev loss: 0.7770 r:0.4812
ro_en Dev loss: 0.3452 r:0.8228
et_en Dev loss: 0.4826 r:0.6750
si_en Dev loss: 0.7948 r:0.5464
ne_en Dev loss: 0.8484 r:0.7011
ru_en Dev loss: 0.4359 r:0.7528
Current avg r:0.5884 Best avg r: 0.6284
09:13:42,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:14:59,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:29,318 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1214
en_de Dev loss: 0.9360 r:0.1459
en_zh Dev loss: 0.7795 r:0.4734
ro_en Dev loss: 0.3331 r:0.8231
et_en Dev loss: 0.4468 r:0.6713
si_en Dev loss: 0.8430 r:0.5361
ne_en Dev loss: 0.6708 r:0.6932
ru_en Dev loss: 0.4359 r:0.7528
Current avg r:0.5851 Best avg r: 0.6284
09:20:19,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:21:36,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:23:05,769 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1177
en_de Dev loss: 0.9169 r:0.1566
en_zh Dev loss: 0.7269 r:0.4856
ro_en Dev loss: 0.3188 r:0.8229
et_en Dev loss: 0.4372 r:0.6825
si_en Dev loss: 0.8161 r:0.5388
ne_en Dev loss: 0.7217 r:0.7015
ru_en Dev loss: 0.3985 r:0.7589
Current avg r:0.5924 Best avg r: 0.6284
09:26:55,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:28:12,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:29:42,246 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1157
en_de Dev loss: 0.9461 r:0.1448
en_zh Dev loss: 0.8062 r:0.4716
ro_en Dev loss: 0.3559 r:0.8187
et_en Dev loss: 0.4549 r:0.6731
si_en Dev loss: 0.9388 r:0.5247
ne_en Dev loss: 0.6814 r:0.6861
ru_en Dev loss: 0.4852 r:0.7372
Current avg r:0.5795 Best avg r: 0.6284
09:33:32,219 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:34:49,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:18,738 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1137
en_de Dev loss: 0.9496 r:0.1521
en_zh Dev loss: 0.7830 r:0.4906
ro_en Dev loss: 0.3796 r:0.8199
et_en Dev loss: 0.4787 r:0.6785
si_en Dev loss: 0.9225 r:0.5307
ne_en Dev loss: 0.7599 r:0.6910
ru_en Dev loss: 0.4567 r:0.7532
Current avg r:0.5880 Best avg r: 0.6284
09:40:08,664 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:40:34,265 root INFO 
id:en_zh cur r: 0.4989 best r: 0.4989
09:41:25,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:42:55,199 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1123
en_de Dev loss: 0.9351 r:0.1537
en_zh Dev loss: 0.7420 r:0.4936
ro_en Dev loss: 0.3447 r:0.8230
et_en Dev loss: 0.4595 r:0.6825
si_en Dev loss: 0.9078 r:0.5372
ne_en Dev loss: 0.7554 r:0.6954
ru_en Dev loss: 0.4194 r:0.7589
Current avg r:0.5920 Best avg r: 0.6284
09:46:45,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:01,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:31,637 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1111
en_de Dev loss: 0.9445 r:0.1448
en_zh Dev loss: 0.7483 r:0.4853
ro_en Dev loss: 0.3234 r:0.8223
et_en Dev loss: 0.4407 r:0.6841
si_en Dev loss: 0.8543 r:0.5368
ne_en Dev loss: 0.6996 r:0.6957
ru_en Dev loss: 0.4205 r:0.7570
Current avg r:0.5894 Best avg r: 0.6284
09:53:21,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:54:38,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:08,101 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1157
en_de Dev loss: 0.9563 r:0.1551
en_zh Dev loss: 0.7850 r:0.4830
ro_en Dev loss: 0.3188 r:0.8250
et_en Dev loss: 0.4488 r:0.6892
si_en Dev loss: 0.8180 r:0.5424
ne_en Dev loss: 0.7747 r:0.7041
ru_en Dev loss: 0.4078 r:0.7636
Current avg r:0.5946 Best avg r: 0.6284
09:59:58,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:01:14,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:44,645 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1126
en_de Dev loss: 0.9346 r:0.1524
en_zh Dev loss: 0.7611 r:0.4755
ro_en Dev loss: 0.3542 r:0.8185
et_en Dev loss: 0.4507 r:0.6706
si_en Dev loss: 0.9182 r:0.5264
ne_en Dev loss: 0.6839 r:0.6799
ru_en Dev loss: 0.4950 r:0.7299
Current avg r:0.5790 Best avg r: 0.6284
10:06:34,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:07:51,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:21,137 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1110
en_de Dev loss: 0.9158 r:0.1465
en_zh Dev loss: 0.7596 r:0.4703
ro_en Dev loss: 0.3318 r:0.8238
et_en Dev loss: 0.4389 r:0.6865
si_en Dev loss: 0.8352 r:0.5409
ne_en Dev loss: 0.7590 r:0.7013
ru_en Dev loss: 0.4104 r:0.7546
Current avg r:0.5891 Best avg r: 0.6284
10:13:10,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:27,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:57,603 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1108
en_de Dev loss: 0.9374 r:0.1465
en_zh Dev loss: 0.8014 r:0.4778
ro_en Dev loss: 0.3573 r:0.8222
et_en Dev loss: 0.4331 r:0.6802
si_en Dev loss: 0.9303 r:0.5284
ne_en Dev loss: 0.6295 r:0.6878
ru_en Dev loss: 0.4428 r:0.7523
Current avg r:0.5850 Best avg r: 0.6284
10:19:47,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:04,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:34,120 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1092
en_de Dev loss: 0.9593 r:0.1381
en_zh Dev loss: 0.8011 r:0.4727
ro_en Dev loss: 0.3344 r:0.8243
et_en Dev loss: 0.4516 r:0.6879
si_en Dev loss: 0.8959 r:0.5355
ne_en Dev loss: 0.7341 r:0.6934
ru_en Dev loss: 0.4380 r:0.7580
Current avg r:0.5871 Best avg r: 0.6284
10:26:24,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:40,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:10,640 root INFO Epoch 11 Global steps: 107400 Train loss: 0.1100
en_de Dev loss: 0.9300 r:0.1660
en_zh Dev loss: 0.7969 r:0.4720
ro_en Dev loss: 0.3579 r:0.8221
et_en Dev loss: 0.4703 r:0.6751
si_en Dev loss: 0.9163 r:0.5309
ne_en Dev loss: 0.7261 r:0.6892
ru_en Dev loss: 0.4631 r:0.7490
Current avg r:0.5863 Best avg r: 0.6284
10:33:00,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:34:17,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:35:47,158 root INFO Epoch 11 Global steps: 108000 Train loss: 0.1124
en_de Dev loss: 0.9122 r:0.1547
en_zh Dev loss: 0.7453 r:0.4720
ro_en Dev loss: 0.3197 r:0.8223
et_en Dev loss: 0.4465 r:0.6849
si_en Dev loss: 0.8558 r:0.5283
ne_en Dev loss: 0.7525 r:0.6892
ru_en Dev loss: 0.4225 r:0.7483
Current avg r:0.5857 Best avg r: 0.6284
