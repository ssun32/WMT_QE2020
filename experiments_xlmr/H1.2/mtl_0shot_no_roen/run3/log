14:41:54,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:07,643 root INFO 
id:en_de cur r: 0.0264 best r: 0.0264
14:42:33,646 root INFO 
id:et_en cur r: 0.4655 best r: 0.4655
14:42:46,710 root INFO 
id:si_en cur r: 0.4343 best r: 0.4343
14:42:59,779 root INFO 
id:ne_en cur r: 0.5792 best r: 0.5792
14:43:12,740 root INFO 
id:ru_en cur r: 0.5105 best r: 0.5105
14:43:12,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:44:43,960 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
14:44:43,969 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:44:43,975 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:44:43,980 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
14:44:43,987 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
14:44:43,994 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:44:43,999 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:44:57,60 root INFO Epoch 0 Global steps: 600 Train loss: 0.8365
en_de Dev loss: 0.8991 r:0.0823
en_zh Dev loss: 0.8057 r:0.2296
ro_en Dev loss: 0.6423 r:0.5953
et_en Dev loss: 0.5937 r:0.4773
si_en Dev loss: 0.6844 r:0.4441
ne_en Dev loss: 0.5579 r:0.6021
ru_en Dev loss: 0.6393 r:0.5151
Current avg r:0.4208 Best avg r: 0.4208
14:48:50,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:16,504 root INFO 
id:en_zh cur r: 0.2502 best r: 0.2502
14:49:29,555 root INFO 
id:et_en cur r: 0.5785 best r: 0.5785
14:49:55,677 root INFO 
id:ne_en cur r: 0.6042 best r: 0.6042
14:50:08,643 root INFO 
id:ru_en cur r: 0.5966 best r: 0.5966
14:50:08,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:39,814 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
14:51:39,825 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:51:39,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:51:39,840 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
14:51:39,846 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
14:51:39,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:51:39,859 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:51:52,921 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8186
en_de Dev loss: 0.8856 r:0.0939
en_zh Dev loss: 0.7591 r:0.2868
ro_en Dev loss: 0.7260 r:0.6311
et_en Dev loss: 0.5381 r:0.5597
si_en Dev loss: 0.8212 r:0.4473
ne_en Dev loss: 0.5488 r:0.6280
ru_en Dev loss: 0.6152 r:0.6151
Current avg r:0.4660 Best avg r: 0.4660
14:55:46,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:59,71 root INFO 
id:en_de cur r: 0.1182 best r: 0.1182
14:56:12,64 root INFO 
id:en_zh cur r: 0.2885 best r: 0.2885
14:57:04,175 root INFO 
id:ru_en cur r: 0.6248 best r: 0.6248
14:57:04,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:35,316 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7364
en_de Dev loss: 0.8930 r:0.1441
en_zh Dev loss: 0.8285 r:0.2825
ro_en Dev loss: 0.7602 r:0.5682
et_en Dev loss: 0.5715 r:0.5313
si_en Dev loss: 0.8142 r:0.4524
ne_en Dev loss: 0.5743 r:0.6006
ru_en Dev loss: 0.6317 r:0.6595
Current avg r:0.4627 Best avg r: 0.4660
15:02:28,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:54,516 root INFO 
id:en_zh cur r: 0.3492 best r: 0.3492
15:03:07,571 root INFO 
id:et_en cur r: 0.6571 best r: 0.6571
15:03:20,641 root INFO 
id:si_en cur r: 0.5271 best r: 0.5271
15:03:33,698 root INFO 
id:ne_en cur r: 0.6795 best r: 0.6795
15:03:46,667 root INFO 
id:ru_en cur r: 0.7017 best r: 0.7017
15:03:46,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:17,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:05:17,751 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:05:17,757 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:05:17,762 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:05:17,769 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:05:17,774 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:05:17,781 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:05:30,825 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7030
en_de Dev loss: 0.8836 r:0.1672
en_zh Dev loss: 0.7440 r:0.3463
ro_en Dev loss: 0.6006 r:0.6626
et_en Dev loss: 0.4042 r:0.6767
si_en Dev loss: 0.6305 r:0.5273
ne_en Dev loss: 0.4265 r:0.6895
ru_en Dev loss: 0.5494 r:0.7037
Current avg r:0.5390 Best avg r: 0.5390
15:09:23,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:36,999 root INFO 
id:en_de cur r: 0.1806 best r: 0.1806
15:10:42,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:12,480 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7137
en_de Dev loss: 0.9364 r:0.1836
en_zh Dev loss: 0.8775 r:0.3408
ro_en Dev loss: 0.7145 r:0.6177
et_en Dev loss: 0.5044 r:0.6186
si_en Dev loss: 0.8289 r:0.5114
ne_en Dev loss: 0.6102 r:0.6369
ru_en Dev loss: 0.5626 r:0.6994
Current avg r:0.5155 Best avg r: 0.5390
15:16:03,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:16,262 root INFO 
id:en_de cur r: 0.1817 best r: 0.1817
15:16:29,121 root INFO 
id:en_zh cur r: 0.3735 best r: 0.3735
15:16:42,26 root INFO 
id:et_en cur r: 0.6774 best r: 0.6774
15:16:54,952 root INFO 
id:si_en cur r: 0.5636 best r: 0.5636
15:17:07,867 root INFO 
id:ne_en cur r: 0.7006 best r: 0.7006
15:17:20,676 root INFO 
id:ru_en cur r: 0.7196 best r: 0.7196
15:17:20,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:50,877 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:18:50,887 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:18:50,893 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:18:50,897 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:18:50,903 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:18:50,909 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:18:50,913 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:19:03,813 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6765
en_de Dev loss: 0.8697 r:0.1893
en_zh Dev loss: 0.7213 r:0.3857
ro_en Dev loss: 0.5449 r:0.6868
et_en Dev loss: 0.3856 r:0.6873
si_en Dev loss: 0.5955 r:0.5713
ne_en Dev loss: 0.3964 r:0.7094
ru_en Dev loss: 0.4599 r:0.7305
Current avg r:0.5657 Best avg r: 0.5657
15:22:54,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:20,345 root INFO 
id:en_zh cur r: 0.3846 best r: 0.3846
15:23:33,234 root INFO 
id:et_en cur r: 0.7009 best r: 0.7009
15:23:46,161 root INFO 
id:si_en cur r: 0.5805 best r: 0.5805
15:23:59,77 root INFO 
id:ne_en cur r: 0.7066 best r: 0.7066
15:24:11,877 root INFO 
id:ru_en cur r: 0.7373 best r: 0.7373
15:24:11,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:42,70 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:25:42,79 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:25:42,84 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:25:42,88 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:25:42,93 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:25:42,98 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:25:42,103 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:25:55,6 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6272
en_de Dev loss: 0.8943 r:0.1942
en_zh Dev loss: 0.7341 r:0.4006
ro_en Dev loss: 0.5696 r:0.6790
et_en Dev loss: 0.3652 r:0.7046
si_en Dev loss: 0.6426 r:0.5890
ne_en Dev loss: 0.4113 r:0.7179
ru_en Dev loss: 0.4500 r:0.7434
Current avg r:0.5755 Best avg r: 0.5755
15:29:45,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:58,745 root INFO 
id:en_de cur r: 0.1994 best r: 0.1994
15:30:11,577 root INFO 
id:en_zh cur r: 0.3898 best r: 0.3898
15:31:03,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:33,171 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6287
en_de Dev loss: 0.8842 r:0.2092
en_zh Dev loss: 0.7295 r:0.4081
ro_en Dev loss: 0.5970 r:0.6715
et_en Dev loss: 0.3852 r:0.6980
si_en Dev loss: 0.7185 r:0.5681
ne_en Dev loss: 0.4769 r:0.7056
ru_en Dev loss: 0.5080 r:0.7329
Current avg r:0.5705 Best avg r: 0.5755
15:36:24,28 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:36,885 root INFO 
id:en_de cur r: 0.2009 best r: 0.2009
15:36:49,729 root INFO 
id:en_zh cur r: 0.4244 best r: 0.4244
15:37:28,394 root INFO 
id:ne_en cur r: 0.7244 best r: 0.7244
15:37:41,193 root INFO 
id:ru_en cur r: 0.7422 best r: 0.7422
15:37:41,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:11,246 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:39:11,254 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:39:11,259 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:39:11,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:39:11,268 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:39:11,273 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:39:11,278 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:39:24,179 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5961
en_de Dev loss: 0.8573 r:0.2123
en_zh Dev loss: 0.6692 r:0.4323
ro_en Dev loss: 0.4773 r:0.6951
et_en Dev loss: 0.3708 r:0.6999
si_en Dev loss: 0.5356 r:0.5926
ne_en Dev loss: 0.3733 r:0.7275
ru_en Dev loss: 0.3926 r:0.7493
Current avg r:0.5870 Best avg r: 0.5870
15:43:15,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:27,934 root INFO 
id:en_de cur r: 0.2227 best r: 0.2227
15:43:40,761 root INFO 
id:en_zh cur r: 0.4291 best r: 0.4291
15:43:53,650 root INFO 
id:et_en cur r: 0.7051 best r: 0.7051
15:44:06,552 root INFO 
id:si_en cur r: 0.5920 best r: 0.5920
15:44:19,445 root INFO 
id:ne_en cur r: 0.7358 best r: 0.7358
15:44:32,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:02,290 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:46:02,298 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:46:02,303 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:46:02,307 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:46:02,312 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:46:02,316 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:46:02,320 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:46:15,192 root INFO Epoch 0 Global steps: 6000 Train loss: 0.6037
en_de Dev loss: 0.8508 r:0.2204
en_zh Dev loss: 0.6822 r:0.4335
ro_en Dev loss: 0.5070 r:0.7190
et_en Dev loss: 0.3533 r:0.7106
si_en Dev loss: 0.6289 r:0.6031
ne_en Dev loss: 0.4373 r:0.7334
ru_en Dev loss: 0.4296 r:0.7468
Current avg r:0.5953 Best avg r: 0.5953
15:50:06,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:31,798 root INFO 
id:en_zh cur r: 0.4392 best r: 0.4392
15:50:44,692 root INFO 
id:et_en cur r: 0.7109 best r: 0.7109
15:51:10,489 root INFO 
id:ne_en cur r: 0.7428 best r: 0.7428
15:51:23,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:53,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:52:53,360 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:52:53,365 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:52:53,369 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:52:53,374 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:52:53,379 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:52:53,384 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:53:06,265 root INFO Epoch 0 Global steps: 6600 Train loss: 0.6119
en_de Dev loss: 0.8536 r:0.2262
en_zh Dev loss: 0.6653 r:0.4415
ro_en Dev loss: 0.4651 r:0.7141
et_en Dev loss: 0.3517 r:0.7119
si_en Dev loss: 0.5656 r:0.6043
ne_en Dev loss: 0.4006 r:0.7437
ru_en Dev loss: 0.4064 r:0.7425
Current avg r:0.5977 Best avg r: 0.5977
15:56:57,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:10,71 root INFO 
id:en_de cur r: 0.2240 best r: 0.2240
15:58:01,615 root INFO 
id:ne_en cur r: 0.7442 best r: 0.7442
15:58:14,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:44,461 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5751
en_de Dev loss: 0.8699 r:0.2193
en_zh Dev loss: 0.7107 r:0.4334
ro_en Dev loss: 0.5000 r:0.7179
et_en Dev loss: 0.3647 r:0.7018
si_en Dev loss: 0.6566 r:0.5948
ne_en Dev loss: 0.4218 r:0.7384
ru_en Dev loss: 0.4577 r:0.7299
Current avg r:0.5908 Best avg r: 0.5977
16:03:35,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:48,202 root INFO 
id:en_de cur r: 0.2296 best r: 0.2296
16:04:52,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:22,645 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5859
en_de Dev loss: 0.8502 r:0.2252
en_zh Dev loss: 0.6895 r:0.4204
ro_en Dev loss: 0.4407 r:0.7214
et_en Dev loss: 0.3723 r:0.7036
si_en Dev loss: 0.5783 r:0.5908
ne_en Dev loss: 0.3655 r:0.7384
ru_en Dev loss: 0.3907 r:0.7379
Current avg r:0.5911 Best avg r: 0.5977
16:10:13,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:26,294 root INFO 
id:en_de cur r: 0.2315 best r: 0.2315
16:10:52,38 root INFO 
id:et_en cur r: 0.7173 best r: 0.7173
16:11:04,958 root INFO 
id:si_en cur r: 0.5931 best r: 0.5931
16:11:17,873 root INFO 
id:ne_en cur r: 0.7554 best r: 0.7554
16:11:30,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:00,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:13:00,839 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:13:00,844 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:13:00,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:13:00,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:13:00,858 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:13:00,862 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:13:13,756 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5824
en_de Dev loss: 0.8566 r:0.2201
en_zh Dev loss: 0.6702 r:0.4452
ro_en Dev loss: 0.4380 r:0.7257
et_en Dev loss: 0.3494 r:0.7170
si_en Dev loss: 0.5961 r:0.6047
ne_en Dev loss: 0.3712 r:0.7505
ru_en Dev loss: 0.3920 r:0.7438
Current avg r:0.6010 Best avg r: 0.6010
16:17:04,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:17,443 root INFO 
id:en_de cur r: 0.2402 best r: 0.2402
16:17:56,83 root INFO 
id:si_en cur r: 0.6003 best r: 0.6003
16:18:21,802 root INFO 
id:ru_en cur r: 0.7517 best r: 0.7517
16:18:21,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:51,990 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:19:51,999 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:19:52,3 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:19:52,8 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:19:52,12 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:19:52,17 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:19:52,21 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:20:04,931 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5597
en_de Dev loss: 0.8429 r:0.2423
en_zh Dev loss: 0.6689 r:0.4420
ro_en Dev loss: 0.4562 r:0.7281
et_en Dev loss: 0.3471 r:0.7133
si_en Dev loss: 0.5883 r:0.6051
ne_en Dev loss: 0.3802 r:0.7420
ru_en Dev loss: 0.3845 r:0.7549
Current avg r:0.6039 Best avg r: 0.6039
16:23:57,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:09,950 root INFO 
id:en_de cur r: 0.2499 best r: 0.2499
16:24:22,788 root INFO 
id:en_zh cur r: 0.4406 best r: 0.4406
16:24:35,679 root INFO 
id:et_en cur r: 0.7217 best r: 0.7217
16:24:48,593 root INFO 
id:si_en cur r: 0.6117 best r: 0.6117
16:25:01,502 root INFO 
id:ne_en cur r: 0.7556 best r: 0.7556
16:25:14,307 root INFO 
id:ru_en cur r: 0.7553 best r: 0.7553
16:25:14,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:44,482 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:26:44,490 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:26:44,494 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:26:44,499 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:26:44,504 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:26:44,509 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:26:44,513 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:26:57,422 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5306
en_de Dev loss: 0.8455 r:0.2381
en_zh Dev loss: 0.6797 r:0.4416
ro_en Dev loss: 0.4310 r:0.7313
et_en Dev loss: 0.3478 r:0.7222
si_en Dev loss: 0.5910 r:0.6208
ne_en Dev loss: 0.4137 r:0.7502
ru_en Dev loss: 0.3671 r:0.7601
Current avg r:0.6092 Best avg r: 0.6092
16:30:48,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:14,79 root INFO 
id:en_zh cur r: 0.4541 best r: 0.4541
16:31:39,892 root INFO 
id:si_en cur r: 0.6196 best r: 0.6196
16:31:52,801 root INFO 
id:ne_en cur r: 0.7615 best r: 0.7615
16:32:05,603 root INFO 
id:ru_en cur r: 0.7586 best r: 0.7586
16:32:05,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:35,710 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:33:35,717 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:33:35,722 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:33:35,726 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:33:35,731 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:33:35,735 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:33:35,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:33:48,647 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5024
en_de Dev loss: 0.8646 r:0.2309
en_zh Dev loss: 0.6979 r:0.4539
ro_en Dev loss: 0.4335 r:0.7298
et_en Dev loss: 0.3665 r:0.7173
si_en Dev loss: 0.5963 r:0.6236
ne_en Dev loss: 0.3673 r:0.7574
ru_en Dev loss: 0.3738 r:0.7642
Current avg r:0.6110 Best avg r: 0.6110
16:37:39,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:56,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:26,902 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5625
en_de Dev loss: 0.8400 r:0.2340
en_zh Dev loss: 0.6889 r:0.4354
ro_en Dev loss: 0.4465 r:0.7235
et_en Dev loss: 0.3624 r:0.7013
si_en Dev loss: 0.7145 r:0.6009
ne_en Dev loss: 0.3998 r:0.7398
ru_en Dev loss: 0.4195 r:0.7321
Current avg r:0.5953 Best avg r: 0.6110
16:44:17,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:35,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:05,83 root INFO Epoch 1 Global steps: 11400 Train loss: 0.5294
en_de Dev loss: 0.8647 r:0.2310
en_zh Dev loss: 0.6915 r:0.4507
ro_en Dev loss: 0.4332 r:0.7300
et_en Dev loss: 0.3613 r:0.7115
si_en Dev loss: 0.6301 r:0.6152
ne_en Dev loss: 0.3541 r:0.7609
ru_en Dev loss: 0.3878 r:0.7491
Current avg r:0.6069 Best avg r: 0.6110
16:50:55,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:13,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:43,355 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5102
en_de Dev loss: 0.8610 r:0.2364
en_zh Dev loss: 0.7208 r:0.4375
ro_en Dev loss: 0.4639 r:0.7271
et_en Dev loss: 0.3747 r:0.6953
si_en Dev loss: 0.7048 r:0.6038
ne_en Dev loss: 0.5211 r:0.7479
ru_en Dev loss: 0.4660 r:0.7155
Current avg r:0.5948 Best avg r: 0.6110
16:57:34,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:51,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:21,628 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5395
en_de Dev loss: 0.8448 r:0.2226
en_zh Dev loss: 0.6707 r:0.4529
ro_en Dev loss: 0.4371 r:0.7476
et_en Dev loss: 0.3593 r:0.7014
si_en Dev loss: 0.7078 r:0.6064
ne_en Dev loss: 0.4481 r:0.7515
ru_en Dev loss: 0.4130 r:0.7372
Current avg r:0.6028 Best avg r: 0.6110
17:04:12,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:29,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:59,892 root INFO Epoch 1 Global steps: 13200 Train loss: 0.5247
en_de Dev loss: 0.8474 r:0.2238
en_zh Dev loss: 0.6899 r:0.4468
ro_en Dev loss: 0.4190 r:0.7545
et_en Dev loss: 0.3459 r:0.7168
si_en Dev loss: 0.6270 r:0.6147
ne_en Dev loss: 0.3816 r:0.7537
ru_en Dev loss: 0.3876 r:0.7478
Current avg r:0.6083 Best avg r: 0.6110
17:10:50,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:16,544 root INFO 
id:en_zh cur r: 0.4661 best r: 0.4661
17:11:29,430 root INFO 
id:et_en cur r: 0.7219 best r: 0.7219
17:11:55,245 root INFO 
id:ne_en cur r: 0.7664 best r: 0.7664
17:12:08,67 root INFO 
id:ru_en cur r: 0.7612 best r: 0.7612
17:12:08,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:38,226 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
17:13:38,235 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:13:38,240 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:13:38,245 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
17:13:38,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
17:13:38,256 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:13:38,260 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:13:51,168 root INFO Epoch 1 Global steps: 13800 Train loss: 0.5210
en_de Dev loss: 0.8470 r:0.2218
en_zh Dev loss: 0.6664 r:0.4641
ro_en Dev loss: 0.3955 r:0.7567
et_en Dev loss: 0.3472 r:0.7232
si_en Dev loss: 0.6049 r:0.6188
ne_en Dev loss: 0.3599 r:0.7656
ru_en Dev loss: 0.3863 r:0.7596
Current avg r:0.6157 Best avg r: 0.6157
17:17:42,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:07,796 root INFO 
id:en_zh cur r: 0.4706 best r: 0.4706
17:18:46,515 root INFO 
id:ne_en cur r: 0.7722 best r: 0.7722
17:18:59,313 root INFO 
id:ru_en cur r: 0.7628 best r: 0.7628
17:18:59,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:29,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_de.lang_agnost_mlp.dev.best.scores
17:20:29,497 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:20:29,507 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:20:29,514 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/et_en.lang_agnost_mlp.dev.best.scores
17:20:29,522 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/si_en.lang_agnost_mlp.dev.best.scores
17:20:29,529 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:20:29,538 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:20:42,440 root INFO Epoch 1 Global steps: 14400 Train loss: 0.5102
en_de Dev loss: 0.8457 r:0.2268
en_zh Dev loss: 0.6557 r:0.4718
ro_en Dev loss: 0.3860 r:0.7567
et_en Dev loss: 0.3553 r:0.7244
si_en Dev loss: 0.5318 r:0.6237
ne_en Dev loss: 0.3430 r:0.7694
ru_en Dev loss: 0.3605 r:0.7646
Current avg r:0.6197 Best avg r: 0.6197
17:24:33,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:59,200 root INFO 
id:en_zh cur r: 0.4785 best r: 0.4785
17:25:37,924 root INFO 
id:ne_en cur r: 0.7736 best r: 0.7736
17:25:50,727 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:20,872 root INFO Epoch 1 Global steps: 15000 Train loss: 0.5193
en_de Dev loss: 0.8462 r:0.2210
en_zh Dev loss: 0.6427 r:0.4769
ro_en Dev loss: 0.3973 r:0.7525
et_en Dev loss: 0.3525 r:0.7236
si_en Dev loss: 0.6176 r:0.6166
ne_en Dev loss: 0.3386 r:0.7704
ru_en Dev loss: 0.3618 r:0.7596
Current avg r:0.6172 Best avg r: 0.6197
17:31:11,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:29,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:59,293 root INFO Epoch 1 Global steps: 15600 Train loss: 0.5284
en_de Dev loss: 0.8362 r:0.2453
en_zh Dev loss: 0.6881 r:0.4537
ro_en Dev loss: 0.4193 r:0.7413
et_en Dev loss: 0.3494 r:0.7175
si_en Dev loss: 0.6489 r:0.6112
ne_en Dev loss: 0.3457 r:0.7618
ru_en Dev loss: 0.3995 r:0.7494
Current avg r:0.6114 Best avg r: 0.6197
17:37:50,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:07,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:37,596 root INFO Epoch 1 Global steps: 16200 Train loss: 0.5311
en_de Dev loss: 0.8471 r:0.2390
en_zh Dev loss: 0.6908 r:0.4611
ro_en Dev loss: 0.4600 r:0.7381
et_en Dev loss: 0.3749 r:0.7074
si_en Dev loss: 0.7599 r:0.6036
ne_en Dev loss: 0.4399 r:0.7558
ru_en Dev loss: 0.4267 r:0.7378
Current avg r:0.6061 Best avg r: 0.6197
17:44:28,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:20,116 root INFO 
id:si_en cur r: 0.6235 best r: 0.6235
17:45:45,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:15,967 root INFO Epoch 1 Global steps: 16800 Train loss: 0.5206
en_de Dev loss: 0.8425 r:0.2262
en_zh Dev loss: 0.6677 r:0.4631
ro_en Dev loss: 0.4036 r:0.7483
et_en Dev loss: 0.3692 r:0.7122
si_en Dev loss: 0.5387 r:0.6234
ne_en Dev loss: 0.3647 r:0.7668
ru_en Dev loss: 0.3958 r:0.7319
Current avg r:0.6103 Best avg r: 0.6197
17:51:06,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:24,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:54,356 root INFO Epoch 1 Global steps: 17400 Train loss: 0.5109
en_de Dev loss: 0.8592 r:0.2119
en_zh Dev loss: 0.7089 r:0.4664
ro_en Dev loss: 0.4464 r:0.7335
et_en Dev loss: 0.3658 r:0.7055
si_en Dev loss: 0.5954 r:0.6178
ne_en Dev loss: 0.3964 r:0.7657
ru_en Dev loss: 0.4730 r:0.7083
Current avg r:0.6013 Best avg r: 0.6197
17:57:45,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:49,688 root INFO 
id:ne_en cur r: 0.7749 best r: 0.7749
17:59:02,498 root INFO 
id:ru_en cur r: 0.7697 best r: 0.7697
17:59:02,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:32,683 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4973
en_de Dev loss: 0.8574 r:0.2224
en_zh Dev loss: 0.7215 r:0.4657
ro_en Dev loss: 0.4555 r:0.7419
et_en Dev loss: 0.3587 r:0.7153
si_en Dev loss: 0.6460 r:0.6228
ne_en Dev loss: 0.3873 r:0.7727
ru_en Dev loss: 0.3951 r:0.7574
Current avg r:0.6140 Best avg r: 0.6197
18:04:24,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:42,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:12,265 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4843
en_de Dev loss: 0.8435 r:0.2297
en_zh Dev loss: 0.7215 r:0.4480
ro_en Dev loss: 0.4322 r:0.7387
et_en Dev loss: 0.3743 r:0.7081
si_en Dev loss: 0.6745 r:0.6110
ne_en Dev loss: 0.3938 r:0.7593
ru_en Dev loss: 0.4268 r:0.7389
Current avg r:0.6048 Best avg r: 0.6197
18:11:03,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:20,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:50,530 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4634
en_de Dev loss: 0.8455 r:0.2254
en_zh Dev loss: 0.6718 r:0.4630
ro_en Dev loss: 0.3971 r:0.7398
et_en Dev loss: 0.3863 r:0.7066
si_en Dev loss: 0.5473 r:0.6261
ne_en Dev loss: 0.3443 r:0.7693
ru_en Dev loss: 0.3571 r:0.7594
Current avg r:0.6128 Best avg r: 0.6197
18:17:41,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:58,818 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:28,957 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4701
en_de Dev loss: 0.8430 r:0.2291
en_zh Dev loss: 0.6978 r:0.4495
ro_en Dev loss: 0.4413 r:0.7367
et_en Dev loss: 0.3656 r:0.6996
si_en Dev loss: 0.6950 r:0.6139
ne_en Dev loss: 0.4614 r:0.7608
ru_en Dev loss: 0.3935 r:0.7452
Current avg r:0.6050 Best avg r: 0.6197
18:24:20,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:37,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:07,411 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4611
en_de Dev loss: 0.8778 r:0.2263
en_zh Dev loss: 0.7408 r:0.4671
ro_en Dev loss: 0.4486 r:0.7465
et_en Dev loss: 0.3817 r:0.7079
si_en Dev loss: 0.6958 r:0.6209
ne_en Dev loss: 0.3819 r:0.7683
ru_en Dev loss: 0.4515 r:0.7399
Current avg r:0.6110 Best avg r: 0.6197
18:30:58,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:15,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:45,778 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4938
en_de Dev loss: 0.8739 r:0.2076
en_zh Dev loss: 0.7300 r:0.4598
ro_en Dev loss: 0.4521 r:0.7427
et_en Dev loss: 0.3739 r:0.7032
si_en Dev loss: 0.7219 r:0.6065
ne_en Dev loss: 0.4765 r:0.7584
ru_en Dev loss: 0.4615 r:0.7286
Current avg r:0.6010 Best avg r: 0.6197
18:37:36,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:53,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:23,918 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4407
en_de Dev loss: 0.8752 r:0.2029
en_zh Dev loss: 0.7997 r:0.4458
ro_en Dev loss: 0.4998 r:0.7341
et_en Dev loss: 0.3814 r:0.6943
si_en Dev loss: 0.8291 r:0.5935
ne_en Dev loss: 0.5509 r:0.7580
ru_en Dev loss: 0.4775 r:0.7269
Current avg r:0.5936 Best avg r: 0.6197
18:44:14,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:31,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:02,62 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4220
en_de Dev loss: 0.8668 r:0.2293
en_zh Dev loss: 0.7094 r:0.4616
ro_en Dev loss: 0.4507 r:0.7293
et_en Dev loss: 0.3793 r:0.6946
si_en Dev loss: 0.6302 r:0.6081
ne_en Dev loss: 0.3922 r:0.7679
ru_en Dev loss: 0.4516 r:0.7231
Current avg r:0.6020 Best avg r: 0.6197
18:50:52,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:10,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:40,186 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4306
en_de Dev loss: 0.8695 r:0.2305
en_zh Dev loss: 0.7051 r:0.4706
ro_en Dev loss: 0.4215 r:0.7514
et_en Dev loss: 0.3885 r:0.7044
si_en Dev loss: 0.6188 r:0.6226
ne_en Dev loss: 0.3911 r:0.7712
ru_en Dev loss: 0.4234 r:0.7510
Current avg r:0.6145 Best avg r: 0.6197
18:57:31,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:48,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:18,404 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4927
en_de Dev loss: 0.8404 r:0.2324
en_zh Dev loss: 0.6812 r:0.4668
ro_en Dev loss: 0.3972 r:0.7395
et_en Dev loss: 0.3975 r:0.7076
si_en Dev loss: 0.5835 r:0.6157
ne_en Dev loss: 0.3846 r:0.7684
ru_en Dev loss: 0.3613 r:0.7558
Current avg r:0.6123 Best avg r: 0.6197
19:04:09,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:26,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:56,651 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4634
en_de Dev loss: 0.8686 r:0.2002
en_zh Dev loss: 0.7148 r:0.4614
ro_en Dev loss: 0.4273 r:0.7394
et_en Dev loss: 0.3900 r:0.6918
si_en Dev loss: 0.7161 r:0.5948
ne_en Dev loss: 0.4842 r:0.7588
ru_en Dev loss: 0.4338 r:0.7323
Current avg r:0.5969 Best avg r: 0.6197
19:10:47,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:04,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:34,839 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4492
en_de Dev loss: 0.8464 r:0.2276
en_zh Dev loss: 0.6743 r:0.4737
ro_en Dev loss: 0.4116 r:0.7412
et_en Dev loss: 0.3850 r:0.7054
si_en Dev loss: 0.7078 r:0.5999
ne_en Dev loss: 0.3562 r:0.7687
ru_en Dev loss: 0.3681 r:0.7629
Current avg r:0.6113 Best avg r: 0.6197
19:17:25,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:42,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:12,953 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4451
en_de Dev loss: 0.8479 r:0.2224
en_zh Dev loss: 0.6847 r:0.4696
ro_en Dev loss: 0.4464 r:0.7306
et_en Dev loss: 0.3680 r:0.7045
si_en Dev loss: 0.7189 r:0.5969
ne_en Dev loss: 0.4254 r:0.7652
ru_en Dev loss: 0.3979 r:0.7512
Current avg r:0.6058 Best avg r: 0.6197
19:24:03,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:29,523 root INFO 
id:en_zh cur r: 0.4842 best r: 0.4842
19:25:08,209 root INFO 
id:ne_en cur r: 0.7749 best r: 0.7749
19:25:21,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:51,97 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4364
en_de Dev loss: 0.8542 r:0.2148
en_zh Dev loss: 0.6943 r:0.4805
ro_en Dev loss: 0.4138 r:0.7409
et_en Dev loss: 0.3916 r:0.7113
si_en Dev loss: 0.6165 r:0.6210
ne_en Dev loss: 0.3528 r:0.7749
ru_en Dev loss: 0.3945 r:0.7580
Current avg r:0.6145 Best avg r: 0.6197
19:30:42,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:31:59,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:29,357 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4227
en_de Dev loss: 0.8512 r:0.2040
en_zh Dev loss: 0.6920 r:0.4680
ro_en Dev loss: 0.4387 r:0.7256
et_en Dev loss: 0.3777 r:0.6996
si_en Dev loss: 0.6783 r:0.5988
ne_en Dev loss: 0.3830 r:0.7669
ru_en Dev loss: 0.4370 r:0.7262
Current avg r:0.5984 Best avg r: 0.6197
19:37:20,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:37,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:07,700 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4689
en_de Dev loss: 0.8444 r:0.2200
en_zh Dev loss: 0.6935 r:0.4625
ro_en Dev loss: 0.4208 r:0.7304
et_en Dev loss: 0.3762 r:0.6972
si_en Dev loss: 0.6786 r:0.6035
ne_en Dev loss: 0.3704 r:0.7640
ru_en Dev loss: 0.4262 r:0.7220
Current avg r:0.5999 Best avg r: 0.6197
19:43:59,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:16,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:46:47,86 root INFO Epoch 3 Global steps: 27600 Train loss: 0.4134
en_de Dev loss: 0.8594 r:0.2020
en_zh Dev loss: 0.7248 r:0.4681
ro_en Dev loss: 0.4388 r:0.7190
et_en Dev loss: 0.3890 r:0.6925
si_en Dev loss: 0.7121 r:0.6013
ne_en Dev loss: 0.3777 r:0.7636
ru_en Dev loss: 0.4514 r:0.7216
Current avg r:0.5954 Best avg r: 0.6197
19:50:38,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:55,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:25,532 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3989
en_de Dev loss: 0.8483 r:0.2206
en_zh Dev loss: 0.7011 r:0.4778
ro_en Dev loss: 0.4005 r:0.7364
et_en Dev loss: 0.4020 r:0.6920
si_en Dev loss: 0.7023 r:0.6055
ne_en Dev loss: 0.3797 r:0.7661
ru_en Dev loss: 0.4249 r:0.7296
Current avg r:0.6040 Best avg r: 0.6197
19:57:16,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:33,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:03,984 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3983
en_de Dev loss: 0.8564 r:0.2264
en_zh Dev loss: 0.7522 r:0.4490
ro_en Dev loss: 0.4476 r:0.7162
et_en Dev loss: 0.4134 r:0.6787
si_en Dev loss: 0.7567 r:0.5890
ne_en Dev loss: 0.4527 r:0.7544
ru_en Dev loss: 0.5106 r:0.6939
Current avg r:0.5868 Best avg r: 0.6197
20:03:54,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:12,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:42,354 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4038
en_de Dev loss: 0.8452 r:0.2326
en_zh Dev loss: 0.7166 r:0.4510
ro_en Dev loss: 0.4378 r:0.7126
et_en Dev loss: 0.4099 r:0.6834
si_en Dev loss: 0.6767 r:0.5919
ne_en Dev loss: 0.3912 r:0.7596
ru_en Dev loss: 0.4302 r:0.7261
Current avg r:0.5939 Best avg r: 0.6197
20:10:33,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:50,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:20,675 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3787
en_de Dev loss: 0.8539 r:0.2287
en_zh Dev loss: 0.7316 r:0.4502
ro_en Dev loss: 0.4319 r:0.7226
et_en Dev loss: 0.4152 r:0.6847
si_en Dev loss: 0.7453 r:0.5923
ne_en Dev loss: 0.4034 r:0.7662
ru_en Dev loss: 0.4395 r:0.7221
Current avg r:0.5953 Best avg r: 0.6197
20:17:11,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:28,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:58,899 root INFO Epoch 3 Global steps: 30600 Train loss: 0.4024
en_de Dev loss: 0.8567 r:0.2060
en_zh Dev loss: 0.6968 r:0.4711
ro_en Dev loss: 0.3958 r:0.7378
et_en Dev loss: 0.4310 r:0.6931
si_en Dev loss: 0.6588 r:0.6088
ne_en Dev loss: 0.3947 r:0.7648
ru_en Dev loss: 0.3655 r:0.7644
Current avg r:0.6066 Best avg r: 0.6197
20:23:49,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:07,10 root INFO 
id:ru_en cur r: 0.7715 best r: 0.7715
20:25:07,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:37,34 root INFO Epoch 3 Global steps: 31200 Train loss: 0.4102
en_de Dev loss: 0.8433 r:0.2370
en_zh Dev loss: 0.7154 r:0.4519
ro_en Dev loss: 0.4017 r:0.7303
et_en Dev loss: 0.4523 r:0.6944
si_en Dev loss: 0.6187 r:0.6080
ne_en Dev loss: 0.3716 r:0.7640
ru_en Dev loss: 0.3574 r:0.7722
Current avg r:0.6082 Best avg r: 0.6197
20:30:27,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:45,11 root INFO 
id:ru_en cur r: 0.7766 best r: 0.7766
20:31:45,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:15,115 root INFO Epoch 3 Global steps: 31800 Train loss: 0.4009
en_de Dev loss: 0.8466 r:0.2369
en_zh Dev loss: 0.6988 r:0.4662
ro_en Dev loss: 0.4116 r:0.7330
et_en Dev loss: 0.4009 r:0.6917
si_en Dev loss: 0.6286 r:0.6091
ne_en Dev loss: 0.3728 r:0.7587
ru_en Dev loss: 0.3511 r:0.7752
Current avg r:0.6101 Best avg r: 0.6197
20:37:05,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:23,148 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:53,314 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3864
en_de Dev loss: 0.8609 r:0.2177
en_zh Dev loss: 0.7457 r:0.4500
ro_en Dev loss: 0.4360 r:0.7172
et_en Dev loss: 0.4374 r:0.6767
si_en Dev loss: 0.6807 r:0.5994
ne_en Dev loss: 0.4020 r:0.7593
ru_en Dev loss: 0.4010 r:0.7502
Current avg r:0.5958 Best avg r: 0.6197
20:43:44,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:01,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:31,749 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3798
en_de Dev loss: 0.8595 r:0.2223
en_zh Dev loss: 0.7458 r:0.4562
ro_en Dev loss: 0.4322 r:0.7289
et_en Dev loss: 0.4237 r:0.6875
si_en Dev loss: 0.6771 r:0.6028
ne_en Dev loss: 0.4158 r:0.7545
ru_en Dev loss: 0.4149 r:0.7527
Current avg r:0.6007 Best avg r: 0.6197
20:50:22,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:39,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:10,152 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3947
en_de Dev loss: 0.8659 r:0.2081
en_zh Dev loss: 0.7361 r:0.4596
ro_en Dev loss: 0.4315 r:0.7255
et_en Dev loss: 0.4361 r:0.6754
si_en Dev loss: 0.7829 r:0.5864
ne_en Dev loss: 0.4808 r:0.7570
ru_en Dev loss: 0.4091 r:0.7460
Current avg r:0.5940 Best avg r: 0.6197
20:57:01,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:18,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:48,458 root INFO Epoch 3 Global steps: 34200 Train loss: 0.4001
en_de Dev loss: 0.8719 r:0.2074
en_zh Dev loss: 0.7511 r:0.4566
ro_en Dev loss: 0.4193 r:0.7216
et_en Dev loss: 0.4838 r:0.6801
si_en Dev loss: 0.7048 r:0.5919
ne_en Dev loss: 0.4030 r:0.7583
ru_en Dev loss: 0.4183 r:0.7375
Current avg r:0.5933 Best avg r: 0.6197
21:03:39,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:56,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:26,762 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3759
en_de Dev loss: 0.8719 r:0.2063
en_zh Dev loss: 0.7506 r:0.4484
ro_en Dev loss: 0.4719 r:0.7177
et_en Dev loss: 0.4087 r:0.6815
si_en Dev loss: 0.7858 r:0.5889
ne_en Dev loss: 0.4556 r:0.7625
ru_en Dev loss: 0.4009 r:0.7563
Current avg r:0.5945 Best avg r: 0.6197
21:10:17,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:35,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:05,167 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3988
en_de Dev loss: 0.8553 r:0.2218
en_zh Dev loss: 0.7265 r:0.4585
ro_en Dev loss: 0.4528 r:0.7208
et_en Dev loss: 0.4127 r:0.6813
si_en Dev loss: 0.7689 r:0.5861
ne_en Dev loss: 0.4679 r:0.7564
ru_en Dev loss: 0.4425 r:0.7326
Current avg r:0.5939 Best avg r: 0.6197
21:16:56,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:13,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:43,577 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3786
en_de Dev loss: 0.8523 r:0.2149
en_zh Dev loss: 0.7453 r:0.4393
ro_en Dev loss: 0.4685 r:0.7055
et_en Dev loss: 0.4096 r:0.6755
si_en Dev loss: 0.7699 r:0.5796
ne_en Dev loss: 0.4557 r:0.7493
ru_en Dev loss: 0.4709 r:0.7074
Current avg r:0.5816 Best avg r: 0.6197
21:23:35,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:53,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:23,189 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3310
en_de Dev loss: 0.8566 r:0.2153
en_zh Dev loss: 0.7510 r:0.4429
ro_en Dev loss: 0.4570 r:0.7100
et_en Dev loss: 0.4216 r:0.6884
si_en Dev loss: 0.7167 r:0.5840
ne_en Dev loss: 0.4323 r:0.7469
ru_en Dev loss: 0.4258 r:0.7414
Current avg r:0.5899 Best avg r: 0.6197
21:30:13,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:31,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:01,382 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3458
en_de Dev loss: 0.8742 r:0.2112
en_zh Dev loss: 0.7845 r:0.4351
ro_en Dev loss: 0.4597 r:0.7154
et_en Dev loss: 0.4387 r:0.6765
si_en Dev loss: 0.7875 r:0.5863
ne_en Dev loss: 0.4437 r:0.7495
ru_en Dev loss: 0.4344 r:0.7418
Current avg r:0.5880 Best avg r: 0.6197
21:36:52,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:09,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:39,719 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3352
en_de Dev loss: 0.8562 r:0.2262
en_zh Dev loss: 0.7644 r:0.4373
ro_en Dev loss: 0.4517 r:0.7063
et_en Dev loss: 0.4358 r:0.6803
si_en Dev loss: 0.7086 r:0.5858
ne_en Dev loss: 0.4225 r:0.7427
ru_en Dev loss: 0.4259 r:0.7384
Current avg r:0.5882 Best avg r: 0.6197
21:43:30,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:47,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:18,11 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3500
en_de Dev loss: 0.8543 r:0.2406
en_zh Dev loss: 0.7822 r:0.4309
ro_en Dev loss: 0.4894 r:0.6941
et_en Dev loss: 0.4202 r:0.6791
si_en Dev loss: 0.7754 r:0.5772
ne_en Dev loss: 0.5294 r:0.7385
ru_en Dev loss: 0.5131 r:0.7019
Current avg r:0.5803 Best avg r: 0.6197
21:50:08,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:26,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:56,350 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3441
en_de Dev loss: 0.8635 r:0.2324
en_zh Dev loss: 0.8029 r:0.4165
ro_en Dev loss: 0.5023 r:0.6847
et_en Dev loss: 0.4281 r:0.6690
si_en Dev loss: 0.8232 r:0.5648
ne_en Dev loss: 0.5682 r:0.7313
ru_en Dev loss: 0.4718 r:0.7149
Current avg r:0.5734 Best avg r: 0.6197
21:56:47,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:00,134 root INFO 
id:en_de cur r: 0.2506 best r: 0.2506
21:58:04,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:34,642 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3385
en_de Dev loss: 0.8399 r:0.2472
en_zh Dev loss: 0.7870 r:0.4343
ro_en Dev loss: 0.4634 r:0.6974
et_en Dev loss: 0.4625 r:0.6864
si_en Dev loss: 0.7235 r:0.5816
ne_en Dev loss: 0.4291 r:0.7405
ru_en Dev loss: 0.4122 r:0.7448
Current avg r:0.5903 Best avg r: 0.6197
22:03:25,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:42,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:12,800 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3314
en_de Dev loss: 0.8570 r:0.2154
en_zh Dev loss: 0.7986 r:0.4273
ro_en Dev loss: 0.4625 r:0.6993
et_en Dev loss: 0.4698 r:0.6780
si_en Dev loss: 0.7183 r:0.5876
ne_en Dev loss: 0.4361 r:0.7435
ru_en Dev loss: 0.4383 r:0.7351
Current avg r:0.5838 Best avg r: 0.6197
22:10:03,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:21,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:51,191 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3510
en_de Dev loss: 0.8891 r:0.2104
en_zh Dev loss: 0.8336 r:0.4161
ro_en Dev loss: 0.4844 r:0.6933
et_en Dev loss: 0.4550 r:0.6726
si_en Dev loss: 0.7512 r:0.5777
ne_en Dev loss: 0.4322 r:0.7424
ru_en Dev loss: 0.4525 r:0.7315
Current avg r:0.5777 Best avg r: 0.6197
22:16:42,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:59,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:29,486 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3175
en_de Dev loss: 0.8666 r:0.2134
en_zh Dev loss: 0.8191 r:0.4131
ro_en Dev loss: 0.5165 r:0.6736
et_en Dev loss: 0.4341 r:0.6593
si_en Dev loss: 0.8877 r:0.5532
ne_en Dev loss: 0.6383 r:0.7397
ru_en Dev loss: 0.4981 r:0.6923
Current avg r:0.5635 Best avg r: 0.6197
22:23:20,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:37,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:07,859 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3450
en_de Dev loss: 0.8500 r:0.2282
en_zh Dev loss: 0.7816 r:0.4302
ro_en Dev loss: 0.4639 r:0.7009
et_en Dev loss: 0.4377 r:0.6803
si_en Dev loss: 0.7564 r:0.5767
ne_en Dev loss: 0.4816 r:0.7420
ru_en Dev loss: 0.4523 r:0.7186
Current avg r:0.5824 Best avg r: 0.6197
22:29:58,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:16,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:46,228 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3395
en_de Dev loss: 0.8619 r:0.2176
en_zh Dev loss: 0.7625 r:0.4410
ro_en Dev loss: 0.4630 r:0.7035
et_en Dev loss: 0.4240 r:0.6727
si_en Dev loss: 0.7470 r:0.5755
ne_en Dev loss: 0.4366 r:0.7488
ru_en Dev loss: 0.4339 r:0.7251
Current avg r:0.5835 Best avg r: 0.6197
22:36:37,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:54,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:24,520 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3221
en_de Dev loss: 0.8563 r:0.2180
en_zh Dev loss: 0.7770 r:0.4274
ro_en Dev loss: 0.4934 r:0.6828
et_en Dev loss: 0.4293 r:0.6616
si_en Dev loss: 0.7950 r:0.5667
ne_en Dev loss: 0.4727 r:0.7504
ru_en Dev loss: 0.4527 r:0.7156
Current avg r:0.5746 Best avg r: 0.6197
22:43:15,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:32,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:02,803 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3227
en_de Dev loss: 0.8575 r:0.2230
en_zh Dev loss: 0.7938 r:0.4343
ro_en Dev loss: 0.4767 r:0.6902
et_en Dev loss: 0.4578 r:0.6611
si_en Dev loss: 0.7718 r:0.5696
ne_en Dev loss: 0.4582 r:0.7390
ru_en Dev loss: 0.4557 r:0.7201
Current avg r:0.5768 Best avg r: 0.6197
22:49:53,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:10,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:41,110 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3356
en_de Dev loss: 0.8656 r:0.2133
en_zh Dev loss: 0.7731 r:0.4329
ro_en Dev loss: 0.4598 r:0.6983
et_en Dev loss: 0.4638 r:0.6672
si_en Dev loss: 0.7097 r:0.5791
ne_en Dev loss: 0.4354 r:0.7509
ru_en Dev loss: 0.4282 r:0.7289
Current avg r:0.5815 Best avg r: 0.6197
22:56:32,35 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:49,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:19,387 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3174
en_de Dev loss: 0.8684 r:0.2151
en_zh Dev loss: 0.7836 r:0.4412
ro_en Dev loss: 0.4369 r:0.7115
et_en Dev loss: 0.4968 r:0.6907
si_en Dev loss: 0.6457 r:0.5905
ne_en Dev loss: 0.3798 r:0.7510
ru_en Dev loss: 0.3767 r:0.7616
Current avg r:0.5945 Best avg r: 0.6197
23:03:11,558 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:28,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:58,940 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2791
en_de Dev loss: 0.8553 r:0.2231
en_zh Dev loss: 0.7604 r:0.4429
ro_en Dev loss: 0.4582 r:0.7054
et_en Dev loss: 0.4244 r:0.6810
si_en Dev loss: 0.7638 r:0.5745
ne_en Dev loss: 0.4430 r:0.7428
ru_en Dev loss: 0.4218 r:0.7403
Current avg r:0.5871 Best avg r: 0.6197
23:09:49,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:06,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:37,121 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3055
en_de Dev loss: 0.8708 r:0.2085
en_zh Dev loss: 0.8402 r:0.4285
ro_en Dev loss: 0.4917 r:0.6986
et_en Dev loss: 0.4547 r:0.6680
si_en Dev loss: 0.9017 r:0.5586
ne_en Dev loss: 0.5206 r:0.7395
ru_en Dev loss: 0.4874 r:0.7173
Current avg r:0.5742 Best avg r: 0.6197
23:16:27,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:45,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:15,188 root INFO Epoch 5 Global steps: 46800 Train loss: 0.3071
en_de Dev loss: 0.8584 r:0.2314
en_zh Dev loss: 0.7910 r:0.4465
ro_en Dev loss: 0.4726 r:0.6995
et_en Dev loss: 0.4719 r:0.6646
si_en Dev loss: 0.7776 r:0.5704
ne_en Dev loss: 0.5109 r:0.7416
ru_en Dev loss: 0.4480 r:0.7274
Current avg r:0.5831 Best avg r: 0.6197
23:23:05,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:23,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:53,251 root INFO Epoch 5 Global steps: 47400 Train loss: 0.3009
en_de Dev loss: 0.8608 r:0.2258
en_zh Dev loss: 0.7966 r:0.4451
ro_en Dev loss: 0.4788 r:0.6968
et_en Dev loss: 0.4822 r:0.6532
si_en Dev loss: 0.7915 r:0.5743
ne_en Dev loss: 0.4837 r:0.7392
ru_en Dev loss: 0.4607 r:0.7227
Current avg r:0.5796 Best avg r: 0.6197
23:29:43,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:01,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:32:31,220 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2807
en_de Dev loss: 0.8921 r:0.2117
en_zh Dev loss: 0.8272 r:0.4352
ro_en Dev loss: 0.4972 r:0.6875
et_en Dev loss: 0.4723 r:0.6559
si_en Dev loss: 0.7852 r:0.5770
ne_en Dev loss: 0.4648 r:0.7409
ru_en Dev loss: 0.4699 r:0.7231
Current avg r:0.5759 Best avg r: 0.6197
23:36:22,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:39,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:09,270 root INFO Epoch 5 Global steps: 48600 Train loss: 0.3033
en_de Dev loss: 0.8727 r:0.2050
en_zh Dev loss: 0.7763 r:0.4401
ro_en Dev loss: 0.4679 r:0.6953
et_en Dev loss: 0.4525 r:0.6625
si_en Dev loss: 0.7550 r:0.5658
ne_en Dev loss: 0.4516 r:0.7423
ru_en Dev loss: 0.4217 r:0.7371
Current avg r:0.5783 Best avg r: 0.6197
23:43:00,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:17,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:47,296 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2831
en_de Dev loss: 0.8654 r:0.2305
en_zh Dev loss: 0.7796 r:0.4354
ro_en Dev loss: 0.4697 r:0.6958
et_en Dev loss: 0.4496 r:0.6588
si_en Dev loss: 0.7590 r:0.5687
ne_en Dev loss: 0.4579 r:0.7408
ru_en Dev loss: 0.4253 r:0.7373
Current avg r:0.5810 Best avg r: 0.6197
23:49:38,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:55,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:25,411 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2813
en_de Dev loss: 0.8728 r:0.2346
en_zh Dev loss: 0.7935 r:0.4480
ro_en Dev loss: 0.4555 r:0.7088
et_en Dev loss: 0.4767 r:0.6753
si_en Dev loss: 0.6871 r:0.5893
ne_en Dev loss: 0.4053 r:0.7420
ru_en Dev loss: 0.4151 r:0.7464
Current avg r:0.5921 Best avg r: 0.6197
23:56:16,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:33,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:03,443 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2707
en_de Dev loss: 0.8649 r:0.2236
en_zh Dev loss: 0.7964 r:0.4389
ro_en Dev loss: 0.4759 r:0.7009
et_en Dev loss: 0.4914 r:0.6585
si_en Dev loss: 0.7916 r:0.5767
ne_en Dev loss: 0.4432 r:0.7462
ru_en Dev loss: 0.4437 r:0.7313
Current avg r:0.5823 Best avg r: 0.6197
00:02:54,242 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:11,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:41,494 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2723
en_de Dev loss: 0.8590 r:0.2187
en_zh Dev loss: 0.7918 r:0.4382
ro_en Dev loss: 0.4685 r:0.6989
et_en Dev loss: 0.4953 r:0.6628
si_en Dev loss: 0.8285 r:0.5636
ne_en Dev loss: 0.4723 r:0.7378
ru_en Dev loss: 0.4300 r:0.7339
Current avg r:0.5791 Best avg r: 0.6197
00:09:32,181 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:49,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:19,528 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2650
en_de Dev loss: 0.8645 r:0.2142
en_zh Dev loss: 0.7654 r:0.4288
ro_en Dev loss: 0.4542 r:0.7012
et_en Dev loss: 0.4723 r:0.6648
si_en Dev loss: 0.7401 r:0.5683
ne_en Dev loss: 0.4419 r:0.7404
ru_en Dev loss: 0.4056 r:0.7442
Current avg r:0.5803 Best avg r: 0.6197
00:16:10,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:27,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:18:57,491 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2814
en_de Dev loss: 0.8750 r:0.1884
en_zh Dev loss: 0.7654 r:0.4334
ro_en Dev loss: 0.4538 r:0.7060
et_en Dev loss: 0.4622 r:0.6674
si_en Dev loss: 0.7559 r:0.5675
ne_en Dev loss: 0.4401 r:0.7385
ru_en Dev loss: 0.4238 r:0.7347
Current avg r:0.5765 Best avg r: 0.6197
00:22:48,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:05,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:35,474 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2566
en_de Dev loss: 0.8847 r:0.1966
en_zh Dev loss: 0.7805 r:0.4390
ro_en Dev loss: 0.4720 r:0.6954
et_en Dev loss: 0.4829 r:0.6542
si_en Dev loss: 0.8270 r:0.5563
ne_en Dev loss: 0.5172 r:0.7236
ru_en Dev loss: 0.4305 r:0.7337
Current avg r:0.5713 Best avg r: 0.6197
00:29:26,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:30:43,371 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:13,426 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2650
en_de Dev loss: 0.8950 r:0.2112
en_zh Dev loss: 0.8304 r:0.4520
ro_en Dev loss: 0.4788 r:0.7072
et_en Dev loss: 0.5145 r:0.6652
si_en Dev loss: 0.8349 r:0.5631
ne_en Dev loss: 0.4383 r:0.7359
ru_en Dev loss: 0.4221 r:0.7489
Current avg r:0.5833 Best avg r: 0.6197
00:36:04,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:21,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:51,337 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2748
en_de Dev loss: 0.8682 r:0.2122
en_zh Dev loss: 0.8208 r:0.4204
ro_en Dev loss: 0.5132 r:0.6783
et_en Dev loss: 0.4672 r:0.6444
si_en Dev loss: 0.8796 r:0.5457
ne_en Dev loss: 0.5286 r:0.7263
ru_en Dev loss: 0.4646 r:0.7164
Current avg r:0.5634 Best avg r: 0.6197
00:42:43,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:00,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:30,498 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2529
en_de Dev loss: 0.8454 r:0.2320
en_zh Dev loss: 0.7586 r:0.4330
ro_en Dev loss: 0.4536 r:0.6983
et_en Dev loss: 0.4511 r:0.6653
si_en Dev loss: 0.7332 r:0.5659
ne_en Dev loss: 0.4441 r:0.7328
ru_en Dev loss: 0.4116 r:0.7320
Current avg r:0.5799 Best avg r: 0.6197
00:49:21,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:38,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:08,344 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2480
en_de Dev loss: 0.8565 r:0.2437
en_zh Dev loss: 0.8228 r:0.4186
ro_en Dev loss: 0.4802 r:0.6938
et_en Dev loss: 0.4783 r:0.6567
si_en Dev loss: 0.7734 r:0.5615
ne_en Dev loss: 0.4648 r:0.7290
ru_en Dev loss: 0.4410 r:0.7300
Current avg r:0.5762 Best avg r: 0.6197
00:55:58,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:16,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:46,270 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2359
en_de Dev loss: 0.8521 r:0.2365
en_zh Dev loss: 0.7667 r:0.4402
ro_en Dev loss: 0.4556 r:0.7013
et_en Dev loss: 0.4779 r:0.6604
si_en Dev loss: 0.7348 r:0.5654
ne_en Dev loss: 0.4564 r:0.7306
ru_en Dev loss: 0.3841 r:0.7520
Current avg r:0.5838 Best avg r: 0.6197
01:02:36,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:54,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:24,292 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2498
en_de Dev loss: 0.8495 r:0.2363
en_zh Dev loss: 0.7847 r:0.4485
ro_en Dev loss: 0.4975 r:0.6906
et_en Dev loss: 0.4744 r:0.6533
si_en Dev loss: 0.8338 r:0.5499
ne_en Dev loss: 0.5011 r:0.7310
ru_en Dev loss: 0.4590 r:0.7328
Current avg r:0.5775 Best avg r: 0.6197
01:09:14,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:32,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:02,181 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2347
en_de Dev loss: 0.8754 r:0.2319
en_zh Dev loss: 0.8158 r:0.4341
ro_en Dev loss: 0.4891 r:0.6990
et_en Dev loss: 0.4652 r:0.6511
si_en Dev loss: 0.8794 r:0.5500
ne_en Dev loss: 0.5477 r:0.7272
ru_en Dev loss: 0.4697 r:0.7218
Current avg r:0.5736 Best avg r: 0.6197
01:15:52,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:09,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:40,74 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2624
en_de Dev loss: 0.8509 r:0.2416
en_zh Dev loss: 0.7549 r:0.4545
ro_en Dev loss: 0.4457 r:0.7083
et_en Dev loss: 0.4481 r:0.6600
si_en Dev loss: 0.7426 r:0.5606
ne_en Dev loss: 0.4407 r:0.7300
ru_en Dev loss: 0.4046 r:0.7440
Current avg r:0.5856 Best avg r: 0.6197
01:22:30,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:47,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:17,888 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2605
en_de Dev loss: 0.8591 r:0.2363
en_zh Dev loss: 0.7766 r:0.4372
ro_en Dev loss: 0.4775 r:0.6922
et_en Dev loss: 0.4762 r:0.6454
si_en Dev loss: 0.7947 r:0.5491
ne_en Dev loss: 0.4449 r:0.7239
ru_en Dev loss: 0.4697 r:0.7120
Current avg r:0.5709 Best avg r: 0.6197
01:29:08,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:25,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:31:55,854 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2459
en_de Dev loss: 0.8873 r:0.2388
en_zh Dev loss: 0.8280 r:0.4409
ro_en Dev loss: 0.4997 r:0.7063
et_en Dev loss: 0.4581 r:0.6588
si_en Dev loss: 0.8585 r:0.5587
ne_en Dev loss: 0.5222 r:0.7315
ru_en Dev loss: 0.4768 r:0.7357
Current avg r:0.5815 Best avg r: 0.6197
01:35:46,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:37:03,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:33,716 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2336
en_de Dev loss: 0.8553 r:0.2501
en_zh Dev loss: 0.7987 r:0.4538
ro_en Dev loss: 0.4679 r:0.7030
et_en Dev loss: 0.4821 r:0.6601
si_en Dev loss: 0.7795 r:0.5629
ne_en Dev loss: 0.4581 r:0.7309
ru_en Dev loss: 0.4187 r:0.7393
Current avg r:0.5857 Best avg r: 0.6197
01:42:24,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:41,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:11,573 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2295
en_de Dev loss: 0.8621 r:0.2372
en_zh Dev loss: 0.8108 r:0.4376
ro_en Dev loss: 0.4876 r:0.6930
et_en Dev loss: 0.4892 r:0.6555
si_en Dev loss: 0.7753 r:0.5587
ne_en Dev loss: 0.4798 r:0.7254
ru_en Dev loss: 0.4319 r:0.7353
Current avg r:0.5775 Best avg r: 0.6197
01:49:02,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:19,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:49,581 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2443
en_de Dev loss: 0.8549 r:0.2394
en_zh Dev loss: 0.8065 r:0.4447
ro_en Dev loss: 0.4987 r:0.6888
et_en Dev loss: 0.4684 r:0.6600
si_en Dev loss: 0.7835 r:0.5609
ne_en Dev loss: 0.4532 r:0.7255
ru_en Dev loss: 0.4524 r:0.7321
Current avg r:0.5788 Best avg r: 0.6197
01:55:40,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:56:57,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:58:27,706 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2417
en_de Dev loss: 0.8697 r:0.2341
en_zh Dev loss: 0.8009 r:0.4550
ro_en Dev loss: 0.5160 r:0.6945
et_en Dev loss: 0.4587 r:0.6547
si_en Dev loss: 0.9030 r:0.5428
ne_en Dev loss: 0.5427 r:0.7231
ru_en Dev loss: 0.4927 r:0.7226
Current avg r:0.5753 Best avg r: 0.6197
02:02:18,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:03:35,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:05:06,62 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2477
en_de Dev loss: 0.8806 r:0.2173
en_zh Dev loss: 0.8257 r:0.4244
ro_en Dev loss: 0.4833 r:0.6950
et_en Dev loss: 0.4839 r:0.6549
si_en Dev loss: 0.8397 r:0.5464
ne_en Dev loss: 0.4758 r:0.7300
ru_en Dev loss: 0.4286 r:0.7376
Current avg r:0.5722 Best avg r: 0.6197
02:08:56,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:10:14,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:11:44,196 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2336
en_de Dev loss: 0.8574 r:0.2368
en_zh Dev loss: 0.7927 r:0.4366
ro_en Dev loss: 0.4675 r:0.7015
et_en Dev loss: 0.4900 r:0.6635
si_en Dev loss: 0.7882 r:0.5591
ne_en Dev loss: 0.4832 r:0.7297
ru_en Dev loss: 0.4215 r:0.7351
Current avg r:0.5803 Best avg r: 0.6197
02:15:35,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:52,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:18:22,444 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2387
en_de Dev loss: 0.8697 r:0.2333
en_zh Dev loss: 0.8176 r:0.4313
ro_en Dev loss: 0.4911 r:0.6923
et_en Dev loss: 0.5052 r:0.6599
si_en Dev loss: 0.8475 r:0.5461
ne_en Dev loss: 0.4727 r:0.7287
ru_en Dev loss: 0.4474 r:0.7246
Current avg r:0.5738 Best avg r: 0.6197
02:22:14,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:23:31,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:01,838 root INFO Epoch 7 Global steps: 63600 Train loss: 0.2130
en_de Dev loss: 0.8771 r:0.2199
en_zh Dev loss: 0.7879 r:0.4316
ro_en Dev loss: 0.5158 r:0.6887
et_en Dev loss: 0.4612 r:0.6503
si_en Dev loss: 0.9328 r:0.5328
ne_en Dev loss: 0.5559 r:0.7235
ru_en Dev loss: 0.4813 r:0.7160
Current avg r:0.5661 Best avg r: 0.6197
02:28:52,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:30:09,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:31:40,13 root INFO Epoch 7 Global steps: 64200 Train loss: 0.2027
en_de Dev loss: 0.8900 r:0.2318
en_zh Dev loss: 0.8192 r:0.4305
ro_en Dev loss: 0.5008 r:0.6933
et_en Dev loss: 0.4804 r:0.6647
si_en Dev loss: 0.7813 r:0.5550
ne_en Dev loss: 0.4627 r:0.7249
ru_en Dev loss: 0.4529 r:0.7294
Current avg r:0.5757 Best avg r: 0.6197
02:35:30,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:48,100 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:18,283 root INFO Epoch 7 Global steps: 64800 Train loss: 0.2090
en_de Dev loss: 0.8928 r:0.2214
en_zh Dev loss: 0.8030 r:0.4410
ro_en Dev loss: 0.4884 r:0.6959
et_en Dev loss: 0.4914 r:0.6554
si_en Dev loss: 0.7986 r:0.5483
ne_en Dev loss: 0.5041 r:0.7284
ru_en Dev loss: 0.4337 r:0.7350
Current avg r:0.5751 Best avg r: 0.6197
02:42:09,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:26,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:56,579 root INFO Epoch 7 Global steps: 65400 Train loss: 0.2198
en_de Dev loss: 0.8863 r:0.2282
en_zh Dev loss: 0.8180 r:0.4388
ro_en Dev loss: 0.5052 r:0.6989
et_en Dev loss: 0.4632 r:0.6613
si_en Dev loss: 0.8950 r:0.5466
ne_en Dev loss: 0.5392 r:0.7235
ru_en Dev loss: 0.4859 r:0.7180
Current avg r:0.5736 Best avg r: 0.6197
02:48:47,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:04,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:34,866 root INFO Epoch 7 Global steps: 66000 Train loss: 0.2271
en_de Dev loss: 0.8833 r:0.2199
en_zh Dev loss: 0.7649 r:0.4480
ro_en Dev loss: 0.4676 r:0.7026
et_en Dev loss: 0.4513 r:0.6594
si_en Dev loss: 0.8264 r:0.5400
ne_en Dev loss: 0.4500 r:0.7288
ru_en Dev loss: 0.4094 r:0.7433
Current avg r:0.5774 Best avg r: 0.6197
02:55:25,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:42,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:58:13,132 root INFO Epoch 7 Global steps: 66600 Train loss: 0.2268
en_de Dev loss: 0.8667 r:0.2299
en_zh Dev loss: 0.8002 r:0.4402
ro_en Dev loss: 0.4765 r:0.6995
et_en Dev loss: 0.4785 r:0.6540
si_en Dev loss: 0.8689 r:0.5368
ne_en Dev loss: 0.5506 r:0.7196
ru_en Dev loss: 0.4274 r:0.7359
Current avg r:0.5737 Best avg r: 0.6197
03:02:03,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:21,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:51,396 root INFO Epoch 7 Global steps: 67200 Train loss: 0.2258
en_de Dev loss: 0.8785 r:0.2293
en_zh Dev loss: 0.8145 r:0.4648
ro_en Dev loss: 0.4647 r:0.7027
et_en Dev loss: 0.4935 r:0.6559
si_en Dev loss: 0.7983 r:0.5466
ne_en Dev loss: 0.5041 r:0.7211
ru_en Dev loss: 0.4372 r:0.7263
Current avg r:0.5781 Best avg r: 0.6197
03:08:42,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:59,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:29,691 root INFO Epoch 7 Global steps: 67800 Train loss: 0.2001
en_de Dev loss: 0.8904 r:0.2209
en_zh Dev loss: 0.8302 r:0.4400
ro_en Dev loss: 0.5043 r:0.6965
et_en Dev loss: 0.4821 r:0.6562
si_en Dev loss: 0.9153 r:0.5339
ne_en Dev loss: 0.5834 r:0.7188
ru_en Dev loss: 0.4817 r:0.7232
Current avg r:0.5699 Best avg r: 0.6197
03:15:20,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:16:37,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:18:08,55 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2048
en_de Dev loss: 0.9006 r:0.2120
en_zh Dev loss: 0.8476 r:0.4281
ro_en Dev loss: 0.5377 r:0.6814
et_en Dev loss: 0.4820 r:0.6437
si_en Dev loss: 0.9297 r:0.5318
ne_en Dev loss: 0.5562 r:0.7134
ru_en Dev loss: 0.5100 r:0.7069
Current avg r:0.5596 Best avg r: 0.6197
03:21:58,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:23:16,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:24:46,403 root INFO Epoch 7 Global steps: 69000 Train loss: 0.2175
en_de Dev loss: 0.8944 r:0.2077
en_zh Dev loss: 0.8695 r:0.4174
ro_en Dev loss: 0.5759 r:0.6647
et_en Dev loss: 0.5005 r:0.6291
si_en Dev loss: 1.0278 r:0.5180
ne_en Dev loss: 0.6473 r:0.7123
ru_en Dev loss: 0.5640 r:0.6841
Current avg r:0.5476 Best avg r: 0.6197
03:28:37,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:54,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:24,802 root INFO Epoch 7 Global steps: 69600 Train loss: 0.2090
en_de Dev loss: 0.8747 r:0.2232
en_zh Dev loss: 0.7953 r:0.4452
ro_en Dev loss: 0.5115 r:0.6844
et_en Dev loss: 0.4474 r:0.6592
si_en Dev loss: 0.9427 r:0.5398
ne_en Dev loss: 0.5387 r:0.7192
ru_en Dev loss: 0.4804 r:0.7179
Current avg r:0.5698 Best avg r: 0.6197
03:35:15,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:32,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:03,103 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1962
en_de Dev loss: 0.8935 r:0.2188
en_zh Dev loss: 0.7911 r:0.4492
ro_en Dev loss: 0.5066 r:0.6885
et_en Dev loss: 0.4602 r:0.6531
si_en Dev loss: 0.9235 r:0.5403
ne_en Dev loss: 0.5155 r:0.7239
ru_en Dev loss: 0.4448 r:0.7298
Current avg r:0.5719 Best avg r: 0.6197
03:41:53,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:11,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:44:41,385 root INFO Epoch 7 Global steps: 70800 Train loss: 0.2024
en_de Dev loss: 0.8739 r:0.2268
en_zh Dev loss: 0.7807 r:0.4438
ro_en Dev loss: 0.5083 r:0.6811
et_en Dev loss: 0.4658 r:0.6537
si_en Dev loss: 0.8771 r:0.5306
ne_en Dev loss: 0.4919 r:0.7180
ru_en Dev loss: 0.4634 r:0.7188
Current avg r:0.5675 Best avg r: 0.6197
03:48:32,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:49:49,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:51:19,699 root INFO Epoch 7 Global steps: 71400 Train loss: 0.2002
en_de Dev loss: 0.8714 r:0.2222
en_zh Dev loss: 0.8201 r:0.4331
ro_en Dev loss: 0.5278 r:0.6833
et_en Dev loss: 0.4683 r:0.6546
si_en Dev loss: 0.9603 r:0.5304
ne_en Dev loss: 0.6085 r:0.7180
ru_en Dev loss: 0.4831 r:0.7213
Current avg r:0.5661 Best avg r: 0.6197
03:55:10,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:56:27,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:57:58,261 root INFO Epoch 7 Global steps: 72000 Train loss: 0.2000
en_de Dev loss: 0.9050 r:0.2219
en_zh Dev loss: 0.8569 r:0.4272
ro_en Dev loss: 0.5174 r:0.6892
et_en Dev loss: 0.5078 r:0.6548
si_en Dev loss: 0.9061 r:0.5388
ne_en Dev loss: 0.5501 r:0.7173
ru_en Dev loss: 0.4677 r:0.7229
Current avg r:0.5674 Best avg r: 0.6197
04:01:50,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:03:07,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:38,200 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1809
en_de Dev loss: 0.8772 r:0.2323
en_zh Dev loss: 0.8095 r:0.4295
ro_en Dev loss: 0.4976 r:0.6945
et_en Dev loss: 0.4629 r:0.6580
si_en Dev loss: 0.8629 r:0.5434
ne_en Dev loss: 0.5507 r:0.7213
ru_en Dev loss: 0.4918 r:0.7171
Current avg r:0.5709 Best avg r: 0.6197
04:08:29,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:09:46,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:11:16,734 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1664
en_de Dev loss: 0.8943 r:0.2369
en_zh Dev loss: 0.8110 r:0.4460
ro_en Dev loss: 0.4824 r:0.6998
et_en Dev loss: 0.4822 r:0.6557
si_en Dev loss: 0.8618 r:0.5407
ne_en Dev loss: 0.5038 r:0.7186
ru_en Dev loss: 0.4411 r:0.7334
Current avg r:0.5759 Best avg r: 0.6197
04:15:07,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:16:25,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:17:55,150 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1841
en_de Dev loss: 0.8955 r:0.2177
en_zh Dev loss: 0.7959 r:0.4428
ro_en Dev loss: 0.4800 r:0.7018
et_en Dev loss: 0.4806 r:0.6569
si_en Dev loss: 0.8661 r:0.5388
ne_en Dev loss: 0.5078 r:0.7185
ru_en Dev loss: 0.4277 r:0.7421
Current avg r:0.5741 Best avg r: 0.6197
04:21:46,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:23:03,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:24:33,433 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1928
en_de Dev loss: 0.8769 r:0.2327
en_zh Dev loss: 0.8047 r:0.4408
ro_en Dev loss: 0.5085 r:0.6921
et_en Dev loss: 0.4804 r:0.6491
si_en Dev loss: 0.9272 r:0.5408
ne_en Dev loss: 0.5958 r:0.7131
ru_en Dev loss: 0.4755 r:0.7260
Current avg r:0.5707 Best avg r: 0.6197
04:28:24,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:41,599 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:11,748 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1912
en_de Dev loss: 0.9016 r:0.2213
en_zh Dev loss: 0.8014 r:0.4461
ro_en Dev loss: 0.4948 r:0.6979
et_en Dev loss: 0.4945 r:0.6458
si_en Dev loss: 0.8840 r:0.5362
ne_en Dev loss: 0.5324 r:0.7079
ru_en Dev loss: 0.4485 r:0.7352
Current avg r:0.5701 Best avg r: 0.6197
04:35:02,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:19,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:49,967 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1916
en_de Dev loss: 0.8779 r:0.2319
en_zh Dev loss: 0.8004 r:0.4426
ro_en Dev loss: 0.5371 r:0.6757
et_en Dev loss: 0.4595 r:0.6463
si_en Dev loss: 0.8952 r:0.5317
ne_en Dev loss: 0.5984 r:0.7060
ru_en Dev loss: 0.4759 r:0.7193
Current avg r:0.5648 Best avg r: 0.6197
04:41:40,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:42:57,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:28,144 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1887
en_de Dev loss: 0.9173 r:0.2256
en_zh Dev loss: 0.7956 r:0.4667
ro_en Dev loss: 0.4862 r:0.7084
et_en Dev loss: 0.5112 r:0.6690
si_en Dev loss: 0.8157 r:0.5497
ne_en Dev loss: 0.4638 r:0.7111
ru_en Dev loss: 0.4318 r:0.7496
Current avg r:0.5829 Best avg r: 0.6197
04:48:18,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:49:36,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:06,513 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1775
en_de Dev loss: 0.8907 r:0.2220
en_zh Dev loss: 0.7943 r:0.4513
ro_en Dev loss: 0.5001 r:0.6921
et_en Dev loss: 0.4501 r:0.6612
si_en Dev loss: 0.9461 r:0.5239
ne_en Dev loss: 0.5999 r:0.7014
ru_en Dev loss: 0.4464 r:0.7357
Current avg r:0.5697 Best avg r: 0.6197
04:54:57,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:56:14,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:57:44,978 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1875
en_de Dev loss: 0.9449 r:0.1918
en_zh Dev loss: 0.8322 r:0.4549
ro_en Dev loss: 0.5178 r:0.6980
et_en Dev loss: 0.4818 r:0.6539
si_en Dev loss: 0.9658 r:0.5380
ne_en Dev loss: 0.6040 r:0.7146
ru_en Dev loss: 0.4806 r:0.7322
Current avg r:0.5691 Best avg r: 0.6197
05:01:35,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:02:53,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:04:23,518 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1881
en_de Dev loss: 0.8985 r:0.2204
en_zh Dev loss: 0.8081 r:0.4458
ro_en Dev loss: 0.5103 r:0.6883
et_en Dev loss: 0.4810 r:0.6539
si_en Dev loss: 0.8724 r:0.5309
ne_en Dev loss: 0.5578 r:0.7058
ru_en Dev loss: 0.4925 r:0.7179
Current avg r:0.5661 Best avg r: 0.6197
05:08:14,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:09:31,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:02,86 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1823
en_de Dev loss: 0.9129 r:0.2334
en_zh Dev loss: 0.8160 r:0.4505
ro_en Dev loss: 0.5189 r:0.6918
et_en Dev loss: 0.4882 r:0.6677
si_en Dev loss: 0.7956 r:0.5522
ne_en Dev loss: 0.4879 r:0.7222
ru_en Dev loss: 0.4781 r:0.7310
Current avg r:0.5784 Best avg r: 0.6197
05:14:53,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:16:10,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:17:40,671 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1750
en_de Dev loss: 0.8996 r:0.2232
en_zh Dev loss: 0.7785 r:0.4586
ro_en Dev loss: 0.5089 r:0.6876
et_en Dev loss: 0.4926 r:0.6558
si_en Dev loss: 0.8399 r:0.5434
ne_en Dev loss: 0.5212 r:0.7178
ru_en Dev loss: 0.4447 r:0.7356
Current avg r:0.5746 Best avg r: 0.6197
05:21:31,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:22:49,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:24:19,318 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1629
en_de Dev loss: 0.8987 r:0.2110
en_zh Dev loss: 0.7990 r:0.4438
ro_en Dev loss: 0.5125 r:0.6790
et_en Dev loss: 0.4837 r:0.6527
si_en Dev loss: 0.8441 r:0.5311
ne_en Dev loss: 0.5097 r:0.7035
ru_en Dev loss: 0.4377 r:0.7369
Current avg r:0.5654 Best avg r: 0.6197
05:28:10,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:29:27,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:57,583 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1794
en_de Dev loss: 0.9002 r:0.1866
en_zh Dev loss: 0.7851 r:0.4463
ro_en Dev loss: 0.4892 r:0.6940
et_en Dev loss: 0.4793 r:0.6644
si_en Dev loss: 0.7909 r:0.5476
ne_en Dev loss: 0.4857 r:0.7088
ru_en Dev loss: 0.4197 r:0.7409
Current avg r:0.5698 Best avg r: 0.6197
05:34:48,403 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:05,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:37:35,800 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1948
en_de Dev loss: 0.8987 r:0.2025
en_zh Dev loss: 0.7396 r:0.4649
ro_en Dev loss: 0.4571 r:0.7038
et_en Dev loss: 0.4919 r:0.6689
si_en Dev loss: 0.8022 r:0.5426
ne_en Dev loss: 0.5048 r:0.7111
ru_en Dev loss: 0.3992 r:0.7412
Current avg r:0.5764 Best avg r: 0.6197
05:41:27,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:42:45,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:44:15,448 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1713
en_de Dev loss: 0.9167 r:0.1970
en_zh Dev loss: 0.7775 r:0.4536
ro_en Dev loss: 0.4900 r:0.6954
et_en Dev loss: 0.4671 r:0.6669
si_en Dev loss: 0.7885 r:0.5486
ne_en Dev loss: 0.5017 r:0.7153
ru_en Dev loss: 0.4317 r:0.7406
Current avg r:0.5739 Best avg r: 0.6197
05:48:06,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:49:23,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:50:53,753 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1642
en_de Dev loss: 0.9047 r:0.2070
en_zh Dev loss: 0.8161 r:0.4459
ro_en Dev loss: 0.5302 r:0.6815
et_en Dev loss: 0.5005 r:0.6508
si_en Dev loss: 1.0014 r:0.5276
ne_en Dev loss: 0.6104 r:0.7155
ru_en Dev loss: 0.4733 r:0.7237
Current avg r:0.5646 Best avg r: 0.6197
05:54:44,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:56:01,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:57:32,134 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1512
en_de Dev loss: 0.8988 r:0.2056
en_zh Dev loss: 0.7892 r:0.4471
ro_en Dev loss: 0.4981 r:0.6868
et_en Dev loss: 0.4704 r:0.6592
si_en Dev loss: 0.8826 r:0.5324
ne_en Dev loss: 0.5463 r:0.7159
ru_en Dev loss: 0.4558 r:0.7252
Current avg r:0.5675 Best avg r: 0.6197
06:01:22,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:02:40,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:10,374 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1598
en_de Dev loss: 0.9241 r:0.2059
en_zh Dev loss: 0.8500 r:0.4350
ro_en Dev loss: 0.5306 r:0.6867
et_en Dev loss: 0.4522 r:0.6623
si_en Dev loss: 0.9232 r:0.5327
ne_en Dev loss: 0.5637 r:0.7181
ru_en Dev loss: 0.4886 r:0.7282
Current avg r:0.5670 Best avg r: 0.6197
06:08:01,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:18,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:10:48,757 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1602
en_de Dev loss: 0.8845 r:0.2117
en_zh Dev loss: 0.7768 r:0.4412
ro_en Dev loss: 0.4892 r:0.6878
et_en Dev loss: 0.4590 r:0.6641
si_en Dev loss: 0.8567 r:0.5304
ne_en Dev loss: 0.5484 r:0.7142
ru_en Dev loss: 0.4809 r:0.7164
Current avg r:0.5666 Best avg r: 0.6197
06:14:39,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:15:56,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:17:27,102 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1586
en_de Dev loss: 0.9244 r:0.1981
en_zh Dev loss: 0.8194 r:0.4382
ro_en Dev loss: 0.4926 r:0.7019
et_en Dev loss: 0.4765 r:0.6694
si_en Dev loss: 0.8672 r:0.5348
ne_en Dev loss: 0.5091 r:0.7172
ru_en Dev loss: 0.4716 r:0.7345
Current avg r:0.5706 Best avg r: 0.6197
06:21:18,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:22:35,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:05,448 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1638
en_de Dev loss: 0.9085 r:0.1927
en_zh Dev loss: 0.8036 r:0.4361
ro_en Dev loss: 0.4938 r:0.6906
et_en Dev loss: 0.4620 r:0.6529
si_en Dev loss: 0.8787 r:0.5312
ne_en Dev loss: 0.5344 r:0.7116
ru_en Dev loss: 0.4586 r:0.7276
Current avg r:0.5632 Best avg r: 0.6197
06:27:56,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:13,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:43,736 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1665
en_de Dev loss: 0.9189 r:0.2065
en_zh Dev loss: 0.8059 r:0.4421
ro_en Dev loss: 0.4951 r:0.6976
et_en Dev loss: 0.4761 r:0.6635
si_en Dev loss: 0.8929 r:0.5340
ne_en Dev loss: 0.5269 r:0.7208
ru_en Dev loss: 0.4494 r:0.7380
Current avg r:0.5718 Best avg r: 0.6197
06:34:34,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:35:51,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:22,29 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1636
en_de Dev loss: 0.9097 r:0.2131
en_zh Dev loss: 0.8229 r:0.4408
ro_en Dev loss: 0.5276 r:0.6844
et_en Dev loss: 0.4813 r:0.6591
si_en Dev loss: 0.9467 r:0.5308
ne_en Dev loss: 0.5512 r:0.7136
ru_en Dev loss: 0.4498 r:0.7445
Current avg r:0.5695 Best avg r: 0.6197
06:41:12,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:42:30,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:44:00,410 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1630
en_de Dev loss: 0.8913 r:0.2290
en_zh Dev loss: 0.7796 r:0.4530
ro_en Dev loss: 0.4686 r:0.6996
et_en Dev loss: 0.4669 r:0.6630
si_en Dev loss: 0.8445 r:0.5379
ne_en Dev loss: 0.5721 r:0.7058
ru_en Dev loss: 0.4398 r:0.7307
Current avg r:0.5742 Best avg r: 0.6197
06:47:51,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:49:08,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:50:38,699 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1630
en_de Dev loss: 0.9068 r:0.1983
en_zh Dev loss: 0.8087 r:0.4386
ro_en Dev loss: 0.4861 r:0.6918
et_en Dev loss: 0.4584 r:0.6580
si_en Dev loss: 0.8102 r:0.5329
ne_en Dev loss: 0.5347 r:0.7010
ru_en Dev loss: 0.4313 r:0.7364
Current avg r:0.5653 Best avg r: 0.6197
06:54:29,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:55:46,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:57:17,22 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1638
en_de Dev loss: 0.9366 r:0.1963
en_zh Dev loss: 0.8237 r:0.4624
ro_en Dev loss: 0.5020 r:0.6964
et_en Dev loss: 0.4818 r:0.6637
si_en Dev loss: 0.9261 r:0.5343
ne_en Dev loss: 0.6457 r:0.7032
ru_en Dev loss: 0.4643 r:0.7324
Current avg r:0.5698 Best avg r: 0.6197
07:01:07,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:25,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:03:55,360 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1580
en_de Dev loss: 0.9117 r:0.1930
en_zh Dev loss: 0.7849 r:0.4574
ro_en Dev loss: 0.4892 r:0.6943
et_en Dev loss: 0.4516 r:0.6556
si_en Dev loss: 0.9175 r:0.5320
ne_en Dev loss: 0.5914 r:0.7050
ru_en Dev loss: 0.4664 r:0.7253
Current avg r:0.5661 Best avg r: 0.6197
07:07:46,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:09:03,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:10:33,651 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1646
en_de Dev loss: 0.9073 r:0.1860
en_zh Dev loss: 0.7752 r:0.4535
ro_en Dev loss: 0.4691 r:0.6946
et_en Dev loss: 0.4577 r:0.6707
si_en Dev loss: 0.8334 r:0.5383
ne_en Dev loss: 0.4876 r:0.7072
ru_en Dev loss: 0.4113 r:0.7390
Current avg r:0.5699 Best avg r: 0.6197
07:14:24,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:15:41,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:11,954 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1596
en_de Dev loss: 0.9063 r:0.1927
en_zh Dev loss: 0.7911 r:0.4583
ro_en Dev loss: 0.4920 r:0.6839
et_en Dev loss: 0.4605 r:0.6576
si_en Dev loss: 0.8753 r:0.5302
ne_en Dev loss: 0.5754 r:0.7006
ru_en Dev loss: 0.4611 r:0.7172
Current avg r:0.5629 Best avg r: 0.6197
07:21:04,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:22:21,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:23:51,435 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1439
en_de Dev loss: 0.9259 r:0.1923
en_zh Dev loss: 0.8165 r:0.4564
ro_en Dev loss: 0.5069 r:0.6904
et_en Dev loss: 0.4779 r:0.6611
si_en Dev loss: 0.9481 r:0.5356
ne_en Dev loss: 0.6103 r:0.7059
ru_en Dev loss: 0.4801 r:0.7230
Current avg r:0.5664 Best avg r: 0.6197
07:27:42,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:28:59,527 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:29,658 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1493
en_de Dev loss: 0.9008 r:0.2229
en_zh Dev loss: 0.8395 r:0.4541
ro_en Dev loss: 0.4586 r:0.7125
et_en Dev loss: 0.5017 r:0.6657
si_en Dev loss: 0.8857 r:0.5362
ne_en Dev loss: 0.6019 r:0.6949
ru_en Dev loss: 0.4088 r:0.7478
Current avg r:0.5763 Best avg r: 0.6197
07:34:20,454 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:35:37,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:07,875 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1388
en_de Dev loss: 0.9073 r:0.2020
en_zh Dev loss: 0.8044 r:0.4445
ro_en Dev loss: 0.4684 r:0.7051
et_en Dev loss: 0.4549 r:0.6636
si_en Dev loss: 0.8347 r:0.5306
ne_en Dev loss: 0.5403 r:0.6986
ru_en Dev loss: 0.4204 r:0.7417
Current avg r:0.5694 Best avg r: 0.6197
07:40:58,664 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:42:15,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:43:46,88 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1342
en_de Dev loss: 0.9069 r:0.2118
en_zh Dev loss: 0.8173 r:0.4483
ro_en Dev loss: 0.4735 r:0.7131
et_en Dev loss: 0.4689 r:0.6703
si_en Dev loss: 0.9087 r:0.5302
ne_en Dev loss: 0.5343 r:0.7094
ru_en Dev loss: 0.4607 r:0.7376
Current avg r:0.5744 Best avg r: 0.6197
07:47:36,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:54,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:50:24,366 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1421
en_de Dev loss: 0.9107 r:0.2040
en_zh Dev loss: 0.8127 r:0.4482
ro_en Dev loss: 0.4499 r:0.7185
et_en Dev loss: 0.4726 r:0.6752
si_en Dev loss: 0.8208 r:0.5434
ne_en Dev loss: 0.5892 r:0.7031
ru_en Dev loss: 0.4037 r:0.7558
Current avg r:0.5783 Best avg r: 0.6197
07:54:15,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:55:32,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:57:02,664 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1427
en_de Dev loss: 0.9096 r:0.1867
en_zh Dev loss: 0.7758 r:0.4551
ro_en Dev loss: 0.4459 r:0.7154
et_en Dev loss: 0.4636 r:0.6729
si_en Dev loss: 0.8032 r:0.5445
ne_en Dev loss: 0.5327 r:0.7068
ru_en Dev loss: 0.4137 r:0.7431
Current avg r:0.5749 Best avg r: 0.6197
08:00:53,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:10,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:40,881 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1380
en_de Dev loss: 0.9059 r:0.2043
en_zh Dev loss: 0.7833 r:0.4573
ro_en Dev loss: 0.4475 r:0.7176
et_en Dev loss: 0.4441 r:0.6760
si_en Dev loss: 0.8273 r:0.5470
ne_en Dev loss: 0.5061 r:0.7095
ru_en Dev loss: 0.3972 r:0.7557
Current avg r:0.5811 Best avg r: 0.6197
08:07:31,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:49,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:19,176 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1501
en_de Dev loss: 0.9254 r:0.1742
en_zh Dev loss: 0.8059 r:0.4565
ro_en Dev loss: 0.4819 r:0.7019
et_en Dev loss: 0.4561 r:0.6681
si_en Dev loss: 0.8923 r:0.5332
ne_en Dev loss: 0.6172 r:0.7012
ru_en Dev loss: 0.4371 r:0.7428
Current avg r:0.5683 Best avg r: 0.6197
08:14:10,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:27,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:57,441 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1470
en_de Dev loss: 0.9221 r:0.1786
en_zh Dev loss: 0.7898 r:0.4622
ro_en Dev loss: 0.4868 r:0.6962
et_en Dev loss: 0.4773 r:0.6644
si_en Dev loss: 0.8437 r:0.5319
ne_en Dev loss: 0.5157 r:0.7073
ru_en Dev loss: 0.4344 r:0.7408
Current avg r:0.5688 Best avg r: 0.6197
08:20:48,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:22:05,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:35,717 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1477
en_de Dev loss: 0.9018 r:0.2012
en_zh Dev loss: 0.7789 r:0.4674
ro_en Dev loss: 0.4709 r:0.7074
et_en Dev loss: 0.4634 r:0.6601
si_en Dev loss: 0.8999 r:0.5365
ne_en Dev loss: 0.5544 r:0.7100
ru_en Dev loss: 0.4500 r:0.7342
Current avg r:0.5738 Best avg r: 0.6197
08:27:26,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:43,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:14,8 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1535
en_de Dev loss: 0.9327 r:0.1869
en_zh Dev loss: 0.8072 r:0.4624
ro_en Dev loss: 0.4774 r:0.7053
et_en Dev loss: 0.4812 r:0.6579
si_en Dev loss: 0.8734 r:0.5279
ne_en Dev loss: 0.5553 r:0.6972
ru_en Dev loss: 0.4328 r:0.7384
Current avg r:0.5680 Best avg r: 0.6197
08:34:04,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:22,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:52,364 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1493
en_de Dev loss: 0.9080 r:0.1821
en_zh Dev loss: 0.7871 r:0.4598
ro_en Dev loss: 0.4682 r:0.7046
et_en Dev loss: 0.4437 r:0.6622
si_en Dev loss: 0.8701 r:0.5253
ne_en Dev loss: 0.5691 r:0.7040
ru_en Dev loss: 0.4533 r:0.7275
Current avg r:0.5665 Best avg r: 0.6197
08:40:43,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:00,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:30,598 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1491
en_de Dev loss: 0.9331 r:0.1885
en_zh Dev loss: 0.8118 r:0.4661
ro_en Dev loss: 0.4819 r:0.7071
et_en Dev loss: 0.4870 r:0.6549
si_en Dev loss: 0.8876 r:0.5364
ne_en Dev loss: 0.5946 r:0.7057
ru_en Dev loss: 0.4445 r:0.7358
Current avg r:0.5706 Best avg r: 0.6197
08:47:21,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:38,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:50:08,822 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1382
en_de Dev loss: 0.9114 r:0.1898
en_zh Dev loss: 0.7748 r:0.4652
ro_en Dev loss: 0.4642 r:0.7067
et_en Dev loss: 0.4578 r:0.6645
si_en Dev loss: 0.8268 r:0.5379
ne_en Dev loss: 0.5034 r:0.7109
ru_en Dev loss: 0.4315 r:0.7385
Current avg r:0.5733 Best avg r: 0.6197
08:53:59,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:55:16,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:46,949 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1454
en_de Dev loss: 0.8852 r:0.2050
en_zh Dev loss: 0.7314 r:0.4714
ro_en Dev loss: 0.4630 r:0.7042
et_en Dev loss: 0.4285 r:0.6651
si_en Dev loss: 0.8553 r:0.5272
ne_en Dev loss: 0.5193 r:0.7108
ru_en Dev loss: 0.4209 r:0.7403
Current avg r:0.5748 Best avg r: 0.6197
09:00:39,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:56,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:26,521 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1258
en_de Dev loss: 0.9366 r:0.1992
en_zh Dev loss: 0.7967 r:0.4689
ro_en Dev loss: 0.5046 r:0.7031
et_en Dev loss: 0.4626 r:0.6729
si_en Dev loss: 0.8511 r:0.5360
ne_en Dev loss: 0.5372 r:0.7075
ru_en Dev loss: 0.5060 r:0.7279
Current avg r:0.5736 Best avg r: 0.6197
09:07:17,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:08:34,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:04,763 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1308
en_de Dev loss: 0.9354 r:0.1822
en_zh Dev loss: 0.8093 r:0.4584
ro_en Dev loss: 0.4968 r:0.6965
et_en Dev loss: 0.4557 r:0.6680
si_en Dev loss: 0.8791 r:0.5373
ne_en Dev loss: 0.5542 r:0.7040
ru_en Dev loss: 0.4468 r:0.7403
Current avg r:0.5695 Best avg r: 0.6197
09:13:55,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:12,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:43,35 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1307
en_de Dev loss: 0.9182 r:0.1823
en_zh Dev loss: 0.7986 r:0.4635
ro_en Dev loss: 0.5031 r:0.6923
et_en Dev loss: 0.4566 r:0.6666
si_en Dev loss: 0.9014 r:0.5319
ne_en Dev loss: 0.6249 r:0.7035
ru_en Dev loss: 0.4805 r:0.7284
Current avg r:0.5669 Best avg r: 0.6197
09:20:33,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:21:51,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:23:21,447 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1291
en_de Dev loss: 0.9493 r:0.1824
en_zh Dev loss: 0.8261 r:0.4638
ro_en Dev loss: 0.4804 r:0.7077
et_en Dev loss: 0.4680 r:0.6771
si_en Dev loss: 0.9033 r:0.5389
ne_en Dev loss: 0.5798 r:0.7062
ru_en Dev loss: 0.4194 r:0.7589
Current avg r:0.5764 Best avg r: 0.6197
09:27:12,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:28:29,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:29:59,806 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1316
en_de Dev loss: 0.9273 r:0.1744
en_zh Dev loss: 0.7917 r:0.4655
ro_en Dev loss: 0.4744 r:0.7118
et_en Dev loss: 0.4682 r:0.6666
si_en Dev loss: 0.9162 r:0.5326
ne_en Dev loss: 0.5962 r:0.6965
ru_en Dev loss: 0.4657 r:0.7398
Current avg r:0.5696 Best avg r: 0.6197
09:33:50,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:07,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:38,68 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1330
en_de Dev loss: 0.9278 r:0.1756
en_zh Dev loss: 0.8111 r:0.4585
ro_en Dev loss: 0.4861 r:0.6990
et_en Dev loss: 0.4763 r:0.6600
si_en Dev loss: 0.8765 r:0.5322
ne_en Dev loss: 0.5680 r:0.7001
ru_en Dev loss: 0.4964 r:0.7166
Current avg r:0.5631 Best avg r: 0.6197
09:40:28,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:46,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:16,422 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1308
en_de Dev loss: 0.9288 r:0.1839
en_zh Dev loss: 0.7735 r:0.4740
ro_en Dev loss: 0.4495 r:0.7170
et_en Dev loss: 0.4730 r:0.6760
si_en Dev loss: 0.8243 r:0.5406
ne_en Dev loss: 0.5192 r:0.6983
ru_en Dev loss: 0.4109 r:0.7565
Current avg r:0.5781 Best avg r: 0.6197
09:47:07,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:24,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:54,655 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1284
en_de Dev loss: 0.9188 r:0.1771
en_zh Dev loss: 0.7989 r:0.4557
ro_en Dev loss: 0.4779 r:0.7052
et_en Dev loss: 0.4574 r:0.6657
si_en Dev loss: 0.8921 r:0.5323
ne_en Dev loss: 0.6470 r:0.7066
ru_en Dev loss: 0.4587 r:0.7327
Current avg r:0.5679 Best avg r: 0.6197
09:53:45,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:02,765 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:33,14 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1333
en_de Dev loss: 0.9440 r:0.1522
en_zh Dev loss: 0.7567 r:0.4659
ro_en Dev loss: 0.4407 r:0.7229
et_en Dev loss: 0.4494 r:0.6780
si_en Dev loss: 0.8582 r:0.5375
ne_en Dev loss: 0.4937 r:0.7111
ru_en Dev loss: 0.4378 r:0.7425
Current avg r:0.5729 Best avg r: 0.6197
10:00:23,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:01:41,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:11,273 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1277
en_de Dev loss: 0.9407 r:0.1641
en_zh Dev loss: 0.8298 r:0.4539
ro_en Dev loss: 0.4707 r:0.7129
et_en Dev loss: 0.4745 r:0.6739
si_en Dev loss: 0.8803 r:0.5381
ne_en Dev loss: 0.5466 r:0.7071
ru_en Dev loss: 0.4517 r:0.7390
Current avg r:0.5699 Best avg r: 0.6197
10:07:02,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:19,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:49,554 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1240
en_de Dev loss: 0.9337 r:0.1634
en_zh Dev loss: 0.7975 r:0.4620
ro_en Dev loss: 0.4620 r:0.7100
et_en Dev loss: 0.4590 r:0.6713
si_en Dev loss: 0.8935 r:0.5365
ne_en Dev loss: 0.5621 r:0.7036
ru_en Dev loss: 0.4403 r:0.7421
Current avg r:0.5699 Best avg r: 0.6197
10:13:40,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:57,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:16:27,823 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1271
en_de Dev loss: 0.9421 r:0.1642
en_zh Dev loss: 0.8440 r:0.4577
ro_en Dev loss: 0.5187 r:0.6926
et_en Dev loss: 0.4653 r:0.6619
si_en Dev loss: 1.0264 r:0.5191
ne_en Dev loss: 0.6527 r:0.6959
ru_en Dev loss: 0.4890 r:0.7380
Current avg r:0.5613 Best avg r: 0.6197
10:20:18,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:36,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:06,176 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1285
en_de Dev loss: 0.9494 r:0.1660
en_zh Dev loss: 0.8289 r:0.4625
ro_en Dev loss: 0.4871 r:0.7057
et_en Dev loss: 0.4510 r:0.6688
si_en Dev loss: 0.9454 r:0.5291
ne_en Dev loss: 0.5823 r:0.7035
ru_en Dev loss: 0.4453 r:0.7473
Current avg r:0.5690 Best avg r: 0.6197
10:26:57,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:14,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:44,502 root INFO Epoch 11 Global steps: 107400 Train loss: 0.1313
en_de Dev loss: 0.9468 r:0.1762
en_zh Dev loss: 0.8351 r:0.4594
ro_en Dev loss: 0.4991 r:0.6939
et_en Dev loss: 0.4782 r:0.6627
si_en Dev loss: 0.9096 r:0.5300
ne_en Dev loss: 0.5991 r:0.7053
ru_en Dev loss: 0.4673 r:0.7338
Current avg r:0.5659 Best avg r: 0.6197
