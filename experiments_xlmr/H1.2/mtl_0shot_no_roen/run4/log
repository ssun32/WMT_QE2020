14:42:31,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:44,366 root INFO 
id:en_de cur r: 0.0224 best r: 0.0224
14:42:57,323 root INFO 
id:en_zh cur r: 0.2335 best r: 0.2335
14:43:36,386 root INFO 
id:ne_en cur r: 0.4428 best r: 0.4428
14:43:49,320 root INFO 
id:ru_en cur r: 0.3090 best r: 0.3090
14:43:49,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:20,309 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:45:20,316 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:45:20,321 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:45:20,326 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:45:20,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:45:20,337 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:45:20,341 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:45:33,375 root INFO Epoch 0 Global steps: 600 Train loss: 0.8430
en_de Dev loss: 0.9344 r:0.0617
en_zh Dev loss: 0.8522 r:0.2065
ro_en Dev loss: 0.7679 r:0.3941
et_en Dev loss: 0.7238 r:0.3593
si_en Dev loss: 0.7470 r:0.3649
ne_en Dev loss: 0.7134 r:0.4365
ru_en Dev loss: 0.8037 r:0.2992
Current avg r:0.3032 Best avg r: 0.3032
14:49:28,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:41,233 root INFO 
id:en_de cur r: 0.0806 best r: 0.0806
14:49:54,226 root INFO 
id:en_zh cur r: 0.2774 best r: 0.2774
14:50:20,322 root INFO 
id:si_en cur r: 0.2176 best r: 0.2176
14:50:33,366 root INFO 
id:ne_en cur r: 0.4866 best r: 0.4866
14:50:46,326 root INFO 
id:ru_en cur r: 0.6230 best r: 0.6230
14:50:46,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:17,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:52:17,478 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:52:17,482 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:52:17,487 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:52:17,492 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:52:17,497 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:52:17,502 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:52:30,548 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8713
en_de Dev loss: 0.8798 r:0.1061
en_zh Dev loss: 0.7733 r:0.2600
ro_en Dev loss: 0.7725 r:0.4572
et_en Dev loss: 0.6665 r:0.3725
si_en Dev loss: 0.8289 r:0.3814
ne_en Dev loss: 0.6793 r:0.4590
ru_en Dev loss: 0.6129 r:0.6121
Current avg r:0.3783 Best avg r: 0.3783
14:56:23,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:49,965 root INFO 
id:en_zh cur r: 0.2986 best r: 0.2986
14:57:03,18 root INFO 
id:et_en cur r: 0.4450 best r: 0.4450
14:57:16,75 root INFO 
id:si_en cur r: 0.4158 best r: 0.4158
14:57:29,125 root INFO 
id:ne_en cur r: 0.5831 best r: 0.5831
14:57:42,72 root INFO 
id:ru_en cur r: 0.6583 best r: 0.6583
14:57:42,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:13,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:59:13,259 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:59:13,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:59:13,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:59:13,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:59:13,279 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:59:13,285 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:59:26,350 root INFO Epoch 0 Global steps: 1800 Train loss: 0.8024
en_de Dev loss: 0.8871 r:0.1257
en_zh Dev loss: 0.7685 r:0.2882
ro_en Dev loss: 0.7355 r:0.5518
et_en Dev loss: 0.6160 r:0.5000
si_en Dev loss: 0.7295 r:0.4557
ne_en Dev loss: 0.6130 r:0.5822
ru_en Dev loss: 0.5610 r:0.6627
Current avg r:0.4524 Best avg r: 0.4524
15:03:19,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:32,683 root INFO 
id:en_de cur r: 0.1371 best r: 0.1371
15:03:45,674 root INFO 
id:en_zh cur r: 0.3390 best r: 0.3390
15:03:58,729 root INFO 
id:et_en cur r: 0.4705 best r: 0.4705
15:04:37,778 root INFO 
id:ru_en cur r: 0.6837 best r: 0.6837
15:04:37,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:08,918 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:06:08,925 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:06:08,929 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:06:08,934 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:06:08,939 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:06:08,944 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:06:08,949 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:06:22,2 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7713
en_de Dev loss: 0.8996 r:0.1554
en_zh Dev loss: 0.7592 r:0.3506
ro_en Dev loss: 0.7013 r:0.5721
et_en Dev loss: 0.5511 r:0.5535
si_en Dev loss: 0.7557 r:0.4530
ne_en Dev loss: 0.5756 r:0.5801
ru_en Dev loss: 0.4845 r:0.6960
Current avg r:0.4801 Best avg r: 0.4801
15:10:19,522 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:32,545 root INFO 
id:en_de cur r: 0.1591 best r: 0.1591
15:10:45,521 root INFO 
id:en_zh cur r: 0.3542 best r: 0.3542
15:10:58,558 root INFO 
id:et_en cur r: 0.5500 best r: 0.5500
15:11:11,602 root INFO 
id:si_en cur r: 0.4478 best r: 0.4478
15:11:24,662 root INFO 
id:ne_en cur r: 0.6285 best r: 0.6285
15:11:37,604 root INFO 
id:ru_en cur r: 0.6953 best r: 0.6953
15:11:37,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:08,698 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:13:08,705 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:13:08,709 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:13:08,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:13:08,719 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:13:08,724 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:13:08,729 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:13:21,756 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7159
en_de Dev loss: 0.9260 r:0.1756
en_zh Dev loss: 0.7504 r:0.3776
ro_en Dev loss: 0.6437 r:0.6530
et_en Dev loss: 0.4795 r:0.6146
si_en Dev loss: 0.7183 r:0.4993
ne_en Dev loss: 0.5231 r:0.6305
ru_en Dev loss: 0.4878 r:0.7190
Current avg r:0.5242 Best avg r: 0.5242
15:17:15,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:41,189 root INFO 
id:en_zh cur r: 0.3804 best r: 0.3804
15:17:54,223 root INFO 
id:et_en cur r: 0.6030 best r: 0.6030
15:18:07,281 root INFO 
id:si_en cur r: 0.4877 best r: 0.4877
15:18:20,329 root INFO 
id:ne_en cur r: 0.6590 best r: 0.6590
15:18:33,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:04,405 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:20:04,411 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:20:04,416 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:20:04,421 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:20:04,426 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:20:04,430 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:20:04,435 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:20:17,474 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6949
en_de Dev loss: 0.9257 r:0.1792
en_zh Dev loss: 0.7426 r:0.3902
ro_en Dev loss: 0.6009 r:0.6576
et_en Dev loss: 0.4409 r:0.6356
si_en Dev loss: 0.6229 r:0.5194
ne_en Dev loss: 0.4733 r:0.6572
ru_en Dev loss: 0.4808 r:0.7105
Current avg r:0.5356 Best avg r: 0.5356
15:24:10,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:49,868 root INFO 
id:et_en cur r: 0.6140 best r: 0.6140
15:25:28,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:00,46 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6579
en_de Dev loss: 0.9858 r:0.1711
en_zh Dev loss: 0.8189 r:0.3822
ro_en Dev loss: 0.6947 r:0.6600
et_en Dev loss: 0.4515 r:0.6420
si_en Dev loss: 0.7562 r:0.5072
ne_en Dev loss: 0.5300 r:0.6349
ru_en Dev loss: 0.5366 r:0.7033
Current avg r:0.5287 Best avg r: 0.5356
15:30:53,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:19,310 root INFO 
id:en_zh cur r: 0.3903 best r: 0.3903
15:32:11,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:42,414 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6406
en_de Dev loss: 0.9953 r:0.1901
en_zh Dev loss: 0.8452 r:0.4024
ro_en Dev loss: 0.7488 r:0.6748
et_en Dev loss: 0.4874 r:0.6414
si_en Dev loss: 1.0013 r:0.4849
ne_en Dev loss: 0.6340 r:0.6190
ru_en Dev loss: 0.6259 r:0.6994
Current avg r:0.5303 Best avg r: 0.5356
15:37:35,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:48,920 root INFO 
id:en_de cur r: 0.1624 best r: 0.1624
15:38:01,916 root INFO 
id:en_zh cur r: 0.4031 best r: 0.4031
15:38:14,956 root INFO 
id:et_en cur r: 0.6612 best r: 0.6612
15:38:28,18 root INFO 
id:si_en cur r: 0.5171 best r: 0.5171
15:38:41,74 root INFO 
id:ne_en cur r: 0.7066 best r: 0.7066
15:38:54,25 root INFO 
id:ru_en cur r: 0.7187 best r: 0.7187
15:38:54,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:25,152 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:40:25,158 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:40:25,163 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:40:25,167 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:40:25,171 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:40:25,176 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:40:25,181 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:40:38,224 root INFO Epoch 0 Global steps: 5400 Train loss: 0.6063
en_de Dev loss: 0.9439 r:0.1940
en_zh Dev loss: 0.7837 r:0.4228
ro_en Dev loss: 0.6590 r:0.7143
et_en Dev loss: 0.4047 r:0.6783
si_en Dev loss: 0.8586 r:0.5244
ne_en Dev loss: 0.5251 r:0.6862
ru_en Dev loss: 0.5412 r:0.7295
Current avg r:0.5642 Best avg r: 0.5642
15:44:31,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:44,712 root INFO 
id:en_de cur r: 0.1790 best r: 0.1790
15:44:57,699 root INFO 
id:en_zh cur r: 0.4223 best r: 0.4223
15:45:10,741 root INFO 
id:et_en cur r: 0.6745 best r: 0.6745
15:45:23,798 root INFO 
id:si_en cur r: 0.5482 best r: 0.5482
15:45:36,853 root INFO 
id:ne_en cur r: 0.7150 best r: 0.7150
15:45:49,798 root INFO 
id:ru_en cur r: 0.7358 best r: 0.7358
15:45:49,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:20,935 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:47:20,942 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:47:20,946 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:47:20,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:47:20,956 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:47:20,961 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:47:20,967 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:47:34,18 root INFO Epoch 0 Global steps: 6000 Train loss: 0.6353
en_de Dev loss: 0.8640 r:0.2115
en_zh Dev loss: 0.6765 r:0.4383
ro_en Dev loss: 0.5279 r:0.7234
et_en Dev loss: 0.3732 r:0.6890
si_en Dev loss: 0.6134 r:0.5592
ne_en Dev loss: 0.4080 r:0.7088
ru_en Dev loss: 0.4130 r:0.7429
Current avg r:0.5819 Best avg r: 0.5819
15:51:27,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:53,476 root INFO 
id:en_zh cur r: 0.4421 best r: 0.4421
15:52:06,530 root INFO 
id:et_en cur r: 0.6863 best r: 0.6863
15:52:19,628 root INFO 
id:si_en cur r: 0.5660 best r: 0.5660
15:52:32,685 root INFO 
id:ne_en cur r: 0.7265 best r: 0.7265
15:52:45,629 root INFO 
id:ru_en cur r: 0.7390 best r: 0.7390
15:52:45,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:16,809 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:54:16,814 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:54:16,819 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:54:16,823 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:54:16,828 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:54:16,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:54:16,836 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:54:29,882 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5979
en_de Dev loss: 0.8860 r:0.2048
en_zh Dev loss: 0.6884 r:0.4550
ro_en Dev loss: 0.5560 r:0.7308
et_en Dev loss: 0.3716 r:0.6926
si_en Dev loss: 0.6265 r:0.5800
ne_en Dev loss: 0.4076 r:0.7251
ru_en Dev loss: 0.4377 r:0.7472
Current avg r:0.5908 Best avg r: 0.5908
15:58:23,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:02,500 root INFO 
id:et_en cur r: 0.6913 best r: 0.6913
15:59:15,574 root INFO 
id:si_en cur r: 0.5693 best r: 0.5693
15:59:41,560 root INFO 
id:ru_en cur r: 0.7429 best r: 0.7429
15:59:41,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:12,744 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5996
en_de Dev loss: 0.8801 r:0.2070
en_zh Dev loss: 0.7363 r:0.4325
ro_en Dev loss: 0.5828 r:0.7247
et_en Dev loss: 0.3734 r:0.6947
si_en Dev loss: 0.6672 r:0.5716
ne_en Dev loss: 0.4055 r:0.7175
ru_en Dev loss: 0.4462 r:0.7450
Current avg r:0.5847 Best avg r: 0.5908
16:05:06,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:19,280 root INFO 
id:en_de cur r: 0.1935 best r: 0.1935
16:05:58,365 root INFO 
id:si_en cur r: 0.5806 best r: 0.5806
16:06:24,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:55,509 root INFO Epoch 0 Global steps: 7800 Train loss: 0.6105
en_de Dev loss: 0.8953 r:0.2190
en_zh Dev loss: 0.7477 r:0.4480
ro_en Dev loss: 0.5604 r:0.7264
et_en Dev loss: 0.3895 r:0.6879
si_en Dev loss: 0.6518 r:0.5812
ne_en Dev loss: 0.4240 r:0.7197
ru_en Dev loss: 0.5574 r:0.7217
Current avg r:0.5863 Best avg r: 0.5908
16:11:49,6 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:14,994 root INFO 
id:en_zh cur r: 0.4462 best r: 0.4462
16:12:28,27 root INFO 
id:et_en cur r: 0.6959 best r: 0.6959
16:12:41,83 root INFO 
id:si_en cur r: 0.5854 best r: 0.5854
16:12:54,137 root INFO 
id:ne_en cur r: 0.7313 best r: 0.7313
16:13:07,80 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:38,233 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:14:38,239 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:14:38,245 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:14:38,252 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:14:38,258 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:14:38,262 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:14:38,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:14:51,310 root INFO Epoch 0 Global steps: 8400 Train loss: 0.6361
en_de Dev loss: 0.8517 r:0.2249
en_zh Dev loss: 0.6951 r:0.4505
ro_en Dev loss: 0.5286 r:0.7416
et_en Dev loss: 0.3626 r:0.6973
si_en Dev loss: 0.5842 r:0.5951
ne_en Dev loss: 0.4176 r:0.7260
ru_en Dev loss: 0.4257 r:0.7495
Current avg r:0.5979 Best avg r: 0.5979
16:18:44,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:23,801 root INFO 
id:et_en cur r: 0.6962 best r: 0.6962
16:19:49,904 root INFO 
id:ne_en cur r: 0.7317 best r: 0.7317
16:20:02,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:33,969 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5704
en_de Dev loss: 0.8602 r:0.2267
en_zh Dev loss: 0.7292 r:0.4320
ro_en Dev loss: 0.5814 r:0.7355
et_en Dev loss: 0.3753 r:0.6983
si_en Dev loss: 0.6759 r:0.5835
ne_en Dev loss: 0.4232 r:0.7267
ru_en Dev loss: 0.4501 r:0.7410
Current avg r:0.5919 Best avg r: 0.5979
16:25:28,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:41,828 root INFO 
id:en_de cur r: 0.2220 best r: 0.2220
16:25:54,816 root INFO 
id:en_zh cur r: 0.4533 best r: 0.4533
16:26:07,870 root INFO 
id:et_en cur r: 0.7020 best r: 0.7020
16:26:20,934 root INFO 
id:si_en cur r: 0.5945 best r: 0.5945
16:26:33,982 root INFO 
id:ne_en cur r: 0.7440 best r: 0.7440
16:26:46,960 root INFO 
id:ru_en cur r: 0.7430 best r: 0.7430
16:26:46,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:18,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:28:18,359 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:28:18,365 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:28:18,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:28:18,374 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:28:18,379 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:28:18,385 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:28:31,443 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5766
en_de Dev loss: 0.8603 r:0.2422
en_zh Dev loss: 0.7358 r:0.4490
ro_en Dev loss: 0.6006 r:0.7280
et_en Dev loss: 0.3767 r:0.7056
si_en Dev loss: 0.6719 r:0.5959
ne_en Dev loss: 0.4270 r:0.7359
ru_en Dev loss: 0.4376 r:0.7464
Current avg r:0.6004 Best avg r: 0.6004
16:32:27,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:40,393 root INFO 
id:en_de cur r: 0.2244 best r: 0.2244
16:33:45,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:16,650 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5723
en_de Dev loss: 0.8866 r:0.2259
en_zh Dev loss: 0.7327 r:0.4421
ro_en Dev loss: 0.5781 r:0.7356
et_en Dev loss: 0.3542 r:0.7074
si_en Dev loss: 0.6777 r:0.5967
ne_en Dev loss: 0.4685 r:0.7350
ru_en Dev loss: 0.4413 r:0.7476
Current avg r:0.5986 Best avg r: 0.6004
16:39:11,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:24,401 root INFO 
id:en_de cur r: 0.2286 best r: 0.2286
16:39:37,392 root INFO 
id:en_zh cur r: 0.4599 best r: 0.4599
16:39:50,461 root INFO 
id:et_en cur r: 0.7035 best r: 0.7035
16:40:16,585 root INFO 
id:ne_en cur r: 0.7477 best r: 0.7477
16:40:29,532 root INFO 
id:ru_en cur r: 0.7572 best r: 0.7572
16:40:29,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:00,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:42:00,689 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:42:00,693 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:42:00,698 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:42:00,703 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:42:00,709 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:42:00,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:42:13,787 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5503
en_de Dev loss: 0.8772 r:0.2434
en_zh Dev loss: 0.6828 r:0.4581
ro_en Dev loss: 0.5844 r:0.7424
et_en Dev loss: 0.3837 r:0.7055
si_en Dev loss: 0.7286 r:0.6014
ne_en Dev loss: 0.4202 r:0.7430
ru_en Dev loss: 0.4217 r:0.7662
Current avg r:0.6086 Best avg r: 0.6086
16:46:07,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:33,547 root INFO 
id:en_zh cur r: 0.4635 best r: 0.4635
16:46:46,585 root INFO 
id:et_en cur r: 0.7047 best r: 0.7047
16:47:25,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:56,789 root INFO Epoch 1 Global steps: 11400 Train loss: 0.5597
en_de Dev loss: 0.8739 r:0.2399
en_zh Dev loss: 0.7345 r:0.4612
ro_en Dev loss: 0.5755 r:0.7413
et_en Dev loss: 0.3744 r:0.7087
si_en Dev loss: 0.6850 r:0.6027
ne_en Dev loss: 0.4679 r:0.7416
ru_en Dev loss: 0.4259 r:0.7573
Current avg r:0.6075 Best avg r: 0.6086
16:52:50,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:08,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:39,555 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5669
en_de Dev loss: 0.8659 r:0.2301
en_zh Dev loss: 0.7456 r:0.4561
ro_en Dev loss: 0.5495 r:0.7432
et_en Dev loss: 0.3674 r:0.7038
si_en Dev loss: 0.6880 r:0.5986
ne_en Dev loss: 0.4697 r:0.7415
ru_en Dev loss: 0.4383 r:0.7533
Current avg r:0.6038 Best avg r: 0.6086
16:59:33,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:46,76 root INFO 
id:en_de cur r: 0.2352 best r: 0.2352
17:00:51,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:22,347 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5285
en_de Dev loss: 0.8876 r:0.2392
en_zh Dev loss: 0.7580 r:0.4555
ro_en Dev loss: 0.5756 r:0.7141
et_en Dev loss: 0.3937 r:0.6960
si_en Dev loss: 0.7412 r:0.5903
ne_en Dev loss: 0.5238 r:0.7347
ru_en Dev loss: 0.4875 r:0.7283
Current avg r:0.5940 Best avg r: 0.6086
17:06:15,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:41,846 root INFO 
id:en_zh cur r: 0.4729 best r: 0.4729
17:06:54,893 root INFO 
id:et_en cur r: 0.7095 best r: 0.7095
17:07:07,959 root INFO 
id:si_en cur r: 0.6068 best r: 0.6068
17:07:21,19 root INFO 
id:ne_en cur r: 0.7546 best r: 0.7546
17:07:33,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:05,137 root INFO Epoch 1 Global steps: 13200 Train loss: 0.5472
en_de Dev loss: 0.8466 r:0.2261
en_zh Dev loss: 0.6749 r:0.4679
ro_en Dev loss: 0.4444 r:0.7194
et_en Dev loss: 0.4225 r:0.7056
si_en Dev loss: 0.5474 r:0.6126
ne_en Dev loss: 0.3463 r:0.7541
ru_en Dev loss: 0.3935 r:0.7438
Current avg r:0.6042 Best avg r: 0.6086
17:12:59,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:04,332 root INFO 
id:ne_en cur r: 0.7588 best r: 0.7588
17:14:17,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:48,504 root INFO Epoch 1 Global steps: 13800 Train loss: 0.5043
en_de Dev loss: 0.8522 r:0.2337
en_zh Dev loss: 0.7076 r:0.4608
ro_en Dev loss: 0.5097 r:0.7415
et_en Dev loss: 0.3897 r:0.7028
si_en Dev loss: 0.6891 r:0.6097
ne_en Dev loss: 0.3934 r:0.7553
ru_en Dev loss: 0.4209 r:0.7531
Current avg r:0.6081 Best avg r: 0.6086
17:19:44,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:02,512 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:33,830 root INFO Epoch 1 Global steps: 14400 Train loss: 0.5400
en_de Dev loss: 0.8996 r:0.2335
en_zh Dev loss: 0.8619 r:0.4555
ro_en Dev loss: 0.6625 r:0.7275
et_en Dev loss: 0.4171 r:0.6978
si_en Dev loss: 0.9255 r:0.5953
ne_en Dev loss: 0.8100 r:0.7435
ru_en Dev loss: 0.5193 r:0.7309
Current avg r:0.5977 Best avg r: 0.6086
17:26:29,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:47,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:19,149 root INFO Epoch 1 Global steps: 15000 Train loss: 0.5354
en_de Dev loss: 0.8749 r:0.2359
en_zh Dev loss: 0.7103 r:0.4699
ro_en Dev loss: 0.5437 r:0.7391
et_en Dev loss: 0.3911 r:0.6972
si_en Dev loss: 0.7046 r:0.6089
ne_en Dev loss: 0.4766 r:0.7532
ru_en Dev loss: 0.4680 r:0.7451
Current avg r:0.6070 Best avg r: 0.6086
17:33:13,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:31,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:02,440 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:36:02,448 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:36:02,452 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:36:02,461 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:36:02,466 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:36:02,473 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:36:02,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:36:15,525 root INFO Epoch 1 Global steps: 15600 Train loss: 0.5276
en_de Dev loss: 0.8534 r:0.2624
en_zh Dev loss: 0.7514 r:0.4618
ro_en Dev loss: 0.5804 r:0.7448
et_en Dev loss: 0.3775 r:0.7023
si_en Dev loss: 0.7363 r:0.6061
ne_en Dev loss: 0.4508 r:0.7508
ru_en Dev loss: 0.4539 r:0.7537
Current avg r:0.6117 Best avg r: 0.6117
17:40:09,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:27,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:58,581 root INFO Epoch 1 Global steps: 16200 Train loss: 0.5364
en_de Dev loss: 0.8571 r:0.2386
en_zh Dev loss: 0.7449 r:0.4701
ro_en Dev loss: 0.5411 r:0.7450
et_en Dev loss: 0.3942 r:0.6932
si_en Dev loss: 0.7027 r:0.6001
ne_en Dev loss: 0.4279 r:0.7518
ru_en Dev loss: 0.4695 r:0.7493
Current avg r:0.6069 Best avg r: 0.6117
17:46:52,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:18,830 root INFO 
id:en_zh cur r: 0.4836 best r: 0.4836
17:47:58,42 root INFO 
id:ne_en cur r: 0.7628 best r: 0.7628
17:48:10,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:42,194 root INFO Epoch 1 Global steps: 16800 Train loss: 0.5414
en_de Dev loss: 0.8488 r:0.2324
en_zh Dev loss: 0.6803 r:0.4837
ro_en Dev loss: 0.4656 r:0.7468
et_en Dev loss: 0.3914 r:0.6969
si_en Dev loss: 0.6361 r:0.6095
ne_en Dev loss: 0.3735 r:0.7576
ru_en Dev loss: 0.4288 r:0.7498
Current avg r:0.6109 Best avg r: 0.6117
17:53:38,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:51,643 root INFO 
id:en_de cur r: 0.2411 best r: 0.2411
17:54:56,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:27,877 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4932
en_de Dev loss: 0.8834 r:0.2456
en_zh Dev loss: 0.7883 r:0.4587
ro_en Dev loss: 0.6528 r:0.7285
et_en Dev loss: 0.4343 r:0.6758
si_en Dev loss: 0.8280 r:0.5850
ne_en Dev loss: 0.6139 r:0.7397
ru_en Dev loss: 0.6807 r:0.6711
Current avg r:0.5863 Best avg r: 0.6117
18:00:22,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:48,417 root INFO 
id:en_zh cur r: 0.4891 best r: 0.4891
18:01:27,553 root INFO 
id:ne_en cur r: 0.7647 best r: 0.7647
18:01:40,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:11,702 root INFO Epoch 1 Global steps: 18000 Train loss: 0.5359
en_de Dev loss: 0.8377 r:0.2495
en_zh Dev loss: 0.6903 r:0.4837
ro_en Dev loss: 0.5218 r:0.7418
et_en Dev loss: 0.3785 r:0.6946
si_en Dev loss: 0.7440 r:0.5993
ne_en Dev loss: 0.4424 r:0.7590
ru_en Dev loss: 0.4487 r:0.7404
Current avg r:0.6098 Best avg r: 0.6117
18:07:06,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:19,887 root INFO 
id:en_de cur r: 0.2499 best r: 0.2499
18:08:24,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:56,103 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4679
en_de Dev loss: 0.8611 r:0.2486
en_zh Dev loss: 0.7665 r:0.4719
ro_en Dev loss: 0.5484 r:0.7342
et_en Dev loss: 0.4023 r:0.6885
si_en Dev loss: 0.7364 r:0.6017
ne_en Dev loss: 0.5004 r:0.7539
ru_en Dev loss: 0.4599 r:0.7414
Current avg r:0.6058 Best avg r: 0.6117
18:13:49,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:02,622 root INFO 
id:en_de cur r: 0.2542 best r: 0.2542
18:14:41,805 root INFO 
id:si_en cur r: 0.6088 best r: 0.6088
18:15:07,799 root INFO 
id:ru_en cur r: 0.7622 best r: 0.7622
18:15:07,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:38,969 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:16:38,977 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:16:38,984 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:16:38,989 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:16:38,994 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:16:39,0 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:16:39,7 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:16:52,50 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4658
en_de Dev loss: 0.8517 r:0.2497
en_zh Dev loss: 0.7330 r:0.4695
ro_en Dev loss: 0.4818 r:0.7443
et_en Dev loss: 0.3957 r:0.7012
si_en Dev loss: 0.6957 r:0.6085
ne_en Dev loss: 0.4134 r:0.7525
ru_en Dev loss: 0.3949 r:0.7655
Current avg r:0.6130 Best avg r: 0.6130
18:20:45,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:04,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:35,228 root INFO Epoch 2 Global steps: 19800 Train loss: 0.5149
en_de Dev loss: 0.8562 r:0.2482
en_zh Dev loss: 0.7535 r:0.4720
ro_en Dev loss: 0.5375 r:0.7377
et_en Dev loss: 0.4016 r:0.6971
si_en Dev loss: 0.7898 r:0.6061
ne_en Dev loss: 0.4576 r:0.7557
ru_en Dev loss: 0.4783 r:0.7458
Current avg r:0.6089 Best avg r: 0.6130
18:27:28,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:46,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:18,0 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4635
en_de Dev loss: 0.8410 r:0.2428
en_zh Dev loss: 0.7005 r:0.4786
ro_en Dev loss: 0.4970 r:0.7449
et_en Dev loss: 0.3856 r:0.7023
si_en Dev loss: 0.7435 r:0.6046
ne_en Dev loss: 0.4486 r:0.7560
ru_en Dev loss: 0.4590 r:0.7429
Current avg r:0.6103 Best avg r: 0.6130
18:34:11,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:29,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:00,824 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:37:00,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:37:00,836 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:37:00,841 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:37:00,846 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:37:00,852 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:37:00,857 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:37:13,905 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4982
en_de Dev loss: 0.8420 r:0.2366
en_zh Dev loss: 0.6956 r:0.4753
ro_en Dev loss: 0.5118 r:0.7579
et_en Dev loss: 0.4021 r:0.6978
si_en Dev loss: 0.7369 r:0.6114
ne_en Dev loss: 0.3910 r:0.7627
ru_en Dev loss: 0.4517 r:0.7538
Current avg r:0.6137 Best avg r: 0.6137
18:41:07,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:20,659 root INFO 
id:en_de cur r: 0.2548 best r: 0.2548
18:41:33,650 root INFO 
id:en_zh cur r: 0.4916 best r: 0.4916
18:41:59,738 root INFO 
id:si_en cur r: 0.6249 best r: 0.6249
18:42:12,829 root INFO 
id:ne_en cur r: 0.7653 best r: 0.7653
18:42:25,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:56,933 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:43:56,941 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:43:56,945 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:43:56,952 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:43:56,957 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:43:56,961 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:43:56,967 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:44:10,13 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4860
en_de Dev loss: 0.8467 r:0.2338
en_zh Dev loss: 0.6694 r:0.4895
ro_en Dev loss: 0.5058 r:0.7610
et_en Dev loss: 0.3623 r:0.7080
si_en Dev loss: 0.7157 r:0.6235
ne_en Dev loss: 0.3918 r:0.7675
ru_en Dev loss: 0.4475 r:0.7536
Current avg r:0.6196 Best avg r: 0.6196
18:48:04,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:23,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:54,232 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4721
en_de Dev loss: 0.8729 r:0.2194
en_zh Dev loss: 0.7480 r:0.4782
ro_en Dev loss: 0.5554 r:0.7429
et_en Dev loss: 0.3827 r:0.6916
si_en Dev loss: 0.8030 r:0.5983
ne_en Dev loss: 0.4247 r:0.7594
ru_en Dev loss: 0.4820 r:0.7419
Current avg r:0.6045 Best avg r: 0.6196
18:54:49,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:07,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:38,437 root INFO Epoch 2 Global steps: 22800 Train loss: 0.5085
en_de Dev loss: 0.8773 r:0.2195
en_zh Dev loss: 0.7236 r:0.4884
ro_en Dev loss: 0.4977 r:0.7556
et_en Dev loss: 0.3880 r:0.6932
si_en Dev loss: 0.7276 r:0.6085
ne_en Dev loss: 0.4461 r:0.7513
ru_en Dev loss: 0.4273 r:0.7569
Current avg r:0.6105 Best avg r: 0.6196
19:01:31,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:44,861 root INFO 
id:en_de cur r: 0.2604 best r: 0.2604
19:02:49,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:20,895 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4567
en_de Dev loss: 0.8710 r:0.2391
en_zh Dev loss: 0.7831 r:0.4711
ro_en Dev loss: 0.5237 r:0.7417
et_en Dev loss: 0.4073 r:0.6927
si_en Dev loss: 0.7440 r:0.5953
ne_en Dev loss: 0.5003 r:0.7512
ru_en Dev loss: 0.4474 r:0.7556
Current avg r:0.6067 Best avg r: 0.6196
19:08:21,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:39,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:11,106 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4764
en_de Dev loss: 0.8385 r:0.2424
en_zh Dev loss: 0.7326 r:0.4829
ro_en Dev loss: 0.4898 r:0.7428
et_en Dev loss: 0.3871 r:0.6983
si_en Dev loss: 0.7309 r:0.6043
ne_en Dev loss: 0.5412 r:0.7555
ru_en Dev loss: 0.4209 r:0.7579
Current avg r:0.6120 Best avg r: 0.6196
19:15:04,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:22,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:54,60 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4971
en_de Dev loss: 0.8626 r:0.2382
en_zh Dev loss: 0.7476 r:0.4878
ro_en Dev loss: 0.4927 r:0.7518
et_en Dev loss: 0.4337 r:0.6900
si_en Dev loss: 0.7530 r:0.6079
ne_en Dev loss: 0.4336 r:0.7479
ru_en Dev loss: 0.4669 r:0.7626
Current avg r:0.6123 Best avg r: 0.6196
19:21:47,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:00,714 root INFO 
id:en_de cur r: 0.2804 best r: 0.2804
19:23:05,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:36,934 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4717
en_de Dev loss: 0.8451 r:0.2548
en_zh Dev loss: 0.7607 r:0.4815
ro_en Dev loss: 0.4864 r:0.7479
et_en Dev loss: 0.3887 r:0.6975
si_en Dev loss: 0.7233 r:0.6116
ne_en Dev loss: 0.4005 r:0.7570
ru_en Dev loss: 0.4483 r:0.7513
Current avg r:0.6145 Best avg r: 0.6196
19:28:32,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:50,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:21,960 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4482
en_de Dev loss: 0.8269 r:0.2643
en_zh Dev loss: 0.6972 r:0.4729
ro_en Dev loss: 0.4684 r:0.7473
et_en Dev loss: 0.3983 r:0.6916
si_en Dev loss: 0.7194 r:0.6106
ne_en Dev loss: 0.4706 r:0.7627
ru_en Dev loss: 0.4619 r:0.7276
Current avg r:0.6110 Best avg r: 0.6196
19:35:16,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:34,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:05,905 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4619
en_de Dev loss: 0.8500 r:0.2427
en_zh Dev loss: 0.7281 r:0.4681
ro_en Dev loss: 0.5066 r:0.7317
et_en Dev loss: 0.4160 r:0.6897
si_en Dev loss: 0.7381 r:0.6038
ne_en Dev loss: 0.4214 r:0.7583
ru_en Dev loss: 0.5251 r:0.7125
Current avg r:0.6010 Best avg r: 0.6196
19:41:59,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:05,12 root INFO 
id:ne_en cur r: 0.7690 best r: 0.7690
19:43:17,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:49,127 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4680
en_de Dev loss: 0.8316 r:0.2592
en_zh Dev loss: 0.6723 r:0.4790
ro_en Dev loss: 0.4399 r:0.7520
et_en Dev loss: 0.4066 r:0.6992
si_en Dev loss: 0.6694 r:0.6130
ne_en Dev loss: 0.3551 r:0.7639
ru_en Dev loss: 0.3957 r:0.7643
Current avg r:0.6187 Best avg r: 0.6196
19:48:44,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:02,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:33,993 root INFO Epoch 3 Global steps: 27600 Train loss: 0.4019
en_de Dev loss: 0.8657 r:0.2320
en_zh Dev loss: 0.7319 r:0.4678
ro_en Dev loss: 0.4712 r:0.7423
et_en Dev loss: 0.4343 r:0.6881
si_en Dev loss: 0.6797 r:0.6108
ne_en Dev loss: 0.4275 r:0.7609
ru_en Dev loss: 0.4596 r:0.7409
Current avg r:0.6061 Best avg r: 0.6196
19:55:27,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:46,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:17,166 root INFO Epoch 3 Global steps: 28200 Train loss: 0.4095
en_de Dev loss: 0.8507 r:0.2379
en_zh Dev loss: 0.7101 r:0.4568
ro_en Dev loss: 0.4508 r:0.7437
et_en Dev loss: 0.4085 r:0.6896
si_en Dev loss: 0.6539 r:0.6102
ne_en Dev loss: 0.4101 r:0.7592
ru_en Dev loss: 0.4111 r:0.7507
Current avg r:0.6069 Best avg r: 0.6196
20:02:14,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:33,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:04,132 root INFO Epoch 3 Global steps: 28800 Train loss: 0.4391
en_de Dev loss: 0.8514 r:0.2352
en_zh Dev loss: 0.7045 r:0.4816
ro_en Dev loss: 0.4397 r:0.7494
et_en Dev loss: 0.4361 r:0.6880
si_en Dev loss: 0.6673 r:0.6123
ne_en Dev loss: 0.4225 r:0.7500
ru_en Dev loss: 0.4675 r:0.7403
Current avg r:0.6081 Best avg r: 0.6196
20:09:03,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:10:21,405 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:52,592 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4456
en_de Dev loss: 0.8700 r:0.2404
en_zh Dev loss: 0.7422 r:0.4659
ro_en Dev loss: 0.4864 r:0.7394
et_en Dev loss: 0.4317 r:0.6914
si_en Dev loss: 0.7270 r:0.6058
ne_en Dev loss: 0.4389 r:0.7536
ru_en Dev loss: 0.5210 r:0.7248
Current avg r:0.6031 Best avg r: 0.6196
20:15:46,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:04,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:35,326 root INFO Epoch 3 Global steps: 30000 Train loss: 0.4143
en_de Dev loss: 0.8470 r:0.2512
en_zh Dev loss: 0.7380 r:0.4739
ro_en Dev loss: 0.4928 r:0.7444
et_en Dev loss: 0.4260 r:0.6882
si_en Dev loss: 0.7700 r:0.6054
ne_en Dev loss: 0.4311 r:0.7556
ru_en Dev loss: 0.4747 r:0.7395
Current avg r:0.6083 Best avg r: 0.6196
20:22:28,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:46,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:18,128 root INFO Epoch 3 Global steps: 30600 Train loss: 0.4185
en_de Dev loss: 0.8499 r:0.2498
en_zh Dev loss: 0.7160 r:0.4650
ro_en Dev loss: 0.4592 r:0.7272
et_en Dev loss: 0.3996 r:0.6870
si_en Dev loss: 0.6499 r:0.5965
ne_en Dev loss: 0.4069 r:0.7573
ru_en Dev loss: 0.4171 r:0.7420
Current avg r:0.6035 Best avg r: 0.6196
20:29:11,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:24,709 root INFO 
id:en_de cur r: 0.2829 best r: 0.2829
20:30:29,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:01,76 root INFO Epoch 3 Global steps: 31200 Train loss: 0.4243
en_de Dev loss: 0.8490 r:0.2754
en_zh Dev loss: 0.7963 r:0.4446
ro_en Dev loss: 0.4896 r:0.7188
et_en Dev loss: 0.4271 r:0.6750
si_en Dev loss: 0.7775 r:0.5860
ne_en Dev loss: 0.4855 r:0.7468
ru_en Dev loss: 0.4735 r:0.7222
Current avg r:0.5956 Best avg r: 0.6196
20:35:54,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:07,886 root INFO 
id:en_de cur r: 0.2857 best r: 0.2857
20:37:12,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:44,157 root INFO Epoch 3 Global steps: 31800 Train loss: 0.4142
en_de Dev loss: 0.8375 r:0.2716
en_zh Dev loss: 0.7827 r:0.4559
ro_en Dev loss: 0.4784 r:0.7259
et_en Dev loss: 0.4701 r:0.6691
si_en Dev loss: 0.8178 r:0.5833
ne_en Dev loss: 0.5739 r:0.7483
ru_en Dev loss: 0.4859 r:0.7243
Current avg r:0.5969 Best avg r: 0.6196
20:42:39,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:57,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:29,270 root INFO Epoch 3 Global steps: 32400 Train loss: 0.4014
en_de Dev loss: 0.8615 r:0.2602
en_zh Dev loss: 0.8019 r:0.4609
ro_en Dev loss: 0.5260 r:0.7396
et_en Dev loss: 0.4263 r:0.6764
si_en Dev loss: 0.8568 r:0.5927
ne_en Dev loss: 0.4564 r:0.7515
ru_en Dev loss: 0.5632 r:0.7204
Current avg r:0.6002 Best avg r: 0.6196
20:49:23,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:41,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:12,861 root INFO Epoch 3 Global steps: 33000 Train loss: 0.4258
en_de Dev loss: 0.8583 r:0.2602
en_zh Dev loss: 0.7742 r:0.4683
ro_en Dev loss: 0.5033 r:0.7473
et_en Dev loss: 0.4167 r:0.6826
si_en Dev loss: 0.8247 r:0.5992
ne_en Dev loss: 0.4101 r:0.7515
ru_en Dev loss: 0.5188 r:0.7362
Current avg r:0.6065 Best avg r: 0.6196
20:56:08,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:25,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:56,848 root INFO Epoch 3 Global steps: 33600 Train loss: 0.4107
en_de Dev loss: 0.8340 r:0.2529
en_zh Dev loss: 0.6688 r:0.4803
ro_en Dev loss: 0.4030 r:0.7506
et_en Dev loss: 0.4169 r:0.6823
si_en Dev loss: 0.5834 r:0.6088
ne_en Dev loss: 0.3691 r:0.7545
ru_en Dev loss: 0.4050 r:0.7461
Current avg r:0.6108 Best avg r: 0.6196
21:02:49,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:07,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:38,614 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3968
en_de Dev loss: 0.8434 r:0.2691
en_zh Dev loss: 0.7282 r:0.4587
ro_en Dev loss: 0.4815 r:0.7265
et_en Dev loss: 0.4153 r:0.6768
si_en Dev loss: 0.7305 r:0.5930
ne_en Dev loss: 0.4634 r:0.7497
ru_en Dev loss: 0.4490 r:0.7364
Current avg r:0.6015 Best avg r: 0.6196
21:09:34,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:47,646 root INFO 
id:en_de cur r: 0.2888 best r: 0.2888
21:10:52,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:12:23,401 root INFO Epoch 3 Global steps: 34800 Train loss: 0.4116
en_de Dev loss: 0.8524 r:0.2776
en_zh Dev loss: 0.7552 r:0.4592
ro_en Dev loss: 0.4999 r:0.7211
et_en Dev loss: 0.4362 r:0.6713
si_en Dev loss: 0.8316 r:0.5866
ne_en Dev loss: 0.4457 r:0.7493
ru_en Dev loss: 0.5364 r:0.7120
Current avg r:0.5967 Best avg r: 0.6196
21:16:18,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:44,153 root INFO 
id:en_zh cur r: 0.4985 best r: 0.4985
21:17:36,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:07,251 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3946
en_de Dev loss: 0.8578 r:0.2310
en_zh Dev loss: 0.6887 r:0.4950
ro_en Dev loss: 0.4198 r:0.7451
et_en Dev loss: 0.4347 r:0.6807
si_en Dev loss: 0.7450 r:0.6036
ne_en Dev loss: 0.4241 r:0.7487
ru_en Dev loss: 0.4090 r:0.7562
Current avg r:0.6086 Best avg r: 0.6196
21:23:00,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:18,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:49,867 root INFO Epoch 3 Global steps: 36000 Train loss: 0.4059
en_de Dev loss: 0.8594 r:0.2486
en_zh Dev loss: 0.7580 r:0.4597
ro_en Dev loss: 0.4725 r:0.7256
et_en Dev loss: 0.4566 r:0.6750
si_en Dev loss: 0.7563 r:0.5919
ne_en Dev loss: 0.4181 r:0.7525
ru_en Dev loss: 0.4425 r:0.7458
Current avg r:0.5999 Best avg r: 0.6196
21:29:44,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:02,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:34,57 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3830
en_de Dev loss: 0.8682 r:0.2501
en_zh Dev loss: 0.7703 r:0.4516
ro_en Dev loss: 0.4983 r:0.7166
et_en Dev loss: 0.4320 r:0.6675
si_en Dev loss: 0.7616 r:0.5855
ne_en Dev loss: 0.4735 r:0.7543
ru_en Dev loss: 0.4736 r:0.7250
Current avg r:0.5929 Best avg r: 0.6196
21:36:27,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:45,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:17,7 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3481
en_de Dev loss: 0.8651 r:0.2621
en_zh Dev loss: 0.8137 r:0.4519
ro_en Dev loss: 0.5503 r:0.7198
et_en Dev loss: 0.4744 r:0.6688
si_en Dev loss: 0.9628 r:0.5760
ne_en Dev loss: 0.5486 r:0.7522
ru_en Dev loss: 0.4765 r:0.7484
Current avg r:0.5970 Best avg r: 0.6196
21:43:12,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:30,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:01,228 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3834
en_de Dev loss: 0.8350 r:0.2685
en_zh Dev loss: 0.7279 r:0.4599
ro_en Dev loss: 0.4915 r:0.7244
et_en Dev loss: 0.4398 r:0.6615
si_en Dev loss: 0.7988 r:0.5794
ne_en Dev loss: 0.4961 r:0.7452
ru_en Dev loss: 0.4498 r:0.7408
Current avg r:0.5971 Best avg r: 0.6196
21:49:54,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:12,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:43,858 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3538
en_de Dev loss: 0.8608 r:0.2349
en_zh Dev loss: 0.7989 r:0.4536
ro_en Dev loss: 0.5270 r:0.7109
et_en Dev loss: 0.5210 r:0.6625
si_en Dev loss: 0.8403 r:0.5816
ne_en Dev loss: 0.4739 r:0.7436
ru_en Dev loss: 0.5253 r:0.7255
Current avg r:0.5875 Best avg r: 0.6196
21:56:38,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:56,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:27,488 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3660
en_de Dev loss: 0.8671 r:0.2307
en_zh Dev loss: 0.7837 r:0.4536
ro_en Dev loss: 0.4917 r:0.7310
et_en Dev loss: 0.4649 r:0.6701
si_en Dev loss: 0.7307 r:0.5908
ne_en Dev loss: 0.4093 r:0.7494
ru_en Dev loss: 0.4557 r:0.7532
Current avg r:0.5970 Best avg r: 0.6196
22:03:21,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:39,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:10,627 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3479
en_de Dev loss: 0.8479 r:0.2436
en_zh Dev loss: 0.7902 r:0.4581
ro_en Dev loss: 0.5069 r:0.7209
et_en Dev loss: 0.4589 r:0.6653
si_en Dev loss: 0.8520 r:0.5800
ne_en Dev loss: 0.4870 r:0.7476
ru_en Dev loss: 0.4736 r:0.7329
Current avg r:0.5926 Best avg r: 0.6196
22:10:06,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:24,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:55,325 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3356
en_de Dev loss: 0.8624 r:0.2570
en_zh Dev loss: 0.7990 r:0.4344
ro_en Dev loss: 0.5178 r:0.7069
et_en Dev loss: 0.4707 r:0.6540
si_en Dev loss: 0.8167 r:0.5734
ne_en Dev loss: 0.4599 r:0.7446
ru_en Dev loss: 0.4690 r:0.7314
Current avg r:0.5859 Best avg r: 0.6196
22:16:49,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:07,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:38,310 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3472
en_de Dev loss: 0.8579 r:0.2508
en_zh Dev loss: 0.7826 r:0.4411
ro_en Dev loss: 0.5067 r:0.7098
et_en Dev loss: 0.4687 r:0.6545
si_en Dev loss: 0.7869 r:0.5778
ne_en Dev loss: 0.4879 r:0.7458
ru_en Dev loss: 0.4867 r:0.7193
Current avg r:0.5856 Best avg r: 0.6196
22:23:32,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:50,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:21,347 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3450
en_de Dev loss: 0.8450 r:0.2526
en_zh Dev loss: 0.8020 r:0.4372
ro_en Dev loss: 0.5017 r:0.7140
et_en Dev loss: 0.4515 r:0.6593
si_en Dev loss: 0.8267 r:0.5785
ne_en Dev loss: 0.4460 r:0.7485
ru_en Dev loss: 0.4806 r:0.7199
Current avg r:0.5871 Best avg r: 0.6196
22:30:15,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:33,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:33:04,322 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3348
en_de Dev loss: 0.8559 r:0.2704
en_zh Dev loss: 0.8143 r:0.4385
ro_en Dev loss: 0.5457 r:0.7166
et_en Dev loss: 0.4815 r:0.6546
si_en Dev loss: 0.9543 r:0.5713
ne_en Dev loss: 0.5458 r:0.7457
ru_en Dev loss: 0.5356 r:0.7170
Current avg r:0.5877 Best avg r: 0.6196
22:36:58,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:16,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:47,271 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3673
en_de Dev loss: 0.8641 r:0.2594
en_zh Dev loss: 0.7630 r:0.4390
ro_en Dev loss: 0.5079 r:0.7091
et_en Dev loss: 0.4413 r:0.6575
si_en Dev loss: 0.7566 r:0.5845
ne_en Dev loss: 0.4296 r:0.7460
ru_en Dev loss: 0.4819 r:0.7208
Current avg r:0.5881 Best avg r: 0.6196
22:43:40,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:59,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:30,182 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3669
en_de Dev loss: 0.8565 r:0.2613
en_zh Dev loss: 0.7723 r:0.4757
ro_en Dev loss: 0.4742 r:0.7232
et_en Dev loss: 0.4808 r:0.6597
si_en Dev loss: 0.7704 r:0.5842
ne_en Dev loss: 0.4530 r:0.7484
ru_en Dev loss: 0.4940 r:0.7234
Current avg r:0.5966 Best avg r: 0.6196
22:50:23,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:42,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:13,204 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3464
en_de Dev loss: 0.8451 r:0.2348
en_zh Dev loss: 0.7574 r:0.4563
ro_en Dev loss: 0.4695 r:0.7170
et_en Dev loss: 0.4602 r:0.6687
si_en Dev loss: 0.7518 r:0.5851
ne_en Dev loss: 0.4658 r:0.7484
ru_en Dev loss: 0.4451 r:0.7323
Current avg r:0.5918 Best avg r: 0.6196
22:57:06,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:24,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:56,85 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3264
en_de Dev loss: 0.8722 r:0.2147
en_zh Dev loss: 0.7994 r:0.4512
ro_en Dev loss: 0.4970 r:0.7246
et_en Dev loss: 0.4672 r:0.6683
si_en Dev loss: 0.8003 r:0.5851
ne_en Dev loss: 0.4728 r:0.7454
ru_en Dev loss: 0.4802 r:0.7346
Current avg r:0.5891 Best avg r: 0.6196
23:03:49,581 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:07,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:38,775 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3050
en_de Dev loss: 0.8497 r:0.2378
en_zh Dev loss: 0.7728 r:0.4565
ro_en Dev loss: 0.4714 r:0.7204
et_en Dev loss: 0.4619 r:0.6676
si_en Dev loss: 0.7751 r:0.5769
ne_en Dev loss: 0.4290 r:0.7453
ru_en Dev loss: 0.4552 r:0.7340
Current avg r:0.5912 Best avg r: 0.6196
23:10:35,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:53,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:24,577 root INFO Epoch 5 Global steps: 45600 Train loss: 0.3068
en_de Dev loss: 0.8571 r:0.2422
en_zh Dev loss: 0.8369 r:0.4449
ro_en Dev loss: 0.5377 r:0.7133
et_en Dev loss: 0.4818 r:0.6640
si_en Dev loss: 0.9419 r:0.5644
ne_en Dev loss: 0.5400 r:0.7392
ru_en Dev loss: 0.5226 r:0.7249
Current avg r:0.5847 Best avg r: 0.6196
23:17:21,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:39,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:10,425 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2958
en_de Dev loss: 0.8674 r:0.2211
en_zh Dev loss: 0.8130 r:0.4409
ro_en Dev loss: 0.5124 r:0.7055
et_en Dev loss: 0.4776 r:0.6524
si_en Dev loss: 0.8464 r:0.5634
ne_en Dev loss: 0.5565 r:0.7393
ru_en Dev loss: 0.4577 r:0.7307
Current avg r:0.5791 Best avg r: 0.6196
23:24:03,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:22,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:53,87 root INFO Epoch 5 Global steps: 46800 Train loss: 0.3230
en_de Dev loss: 0.8808 r:0.2110
en_zh Dev loss: 0.8320 r:0.4249
ro_en Dev loss: 0.5020 r:0.7068
et_en Dev loss: 0.5226 r:0.6423
si_en Dev loss: 0.8321 r:0.5627
ne_en Dev loss: 0.4873 r:0.7365
ru_en Dev loss: 0.4785 r:0.7200
Current avg r:0.5720 Best avg r: 0.6196
23:30:46,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:04,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:35,821 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2939
en_de Dev loss: 0.8721 r:0.2241
en_zh Dev loss: 0.8245 r:0.4398
ro_en Dev loss: 0.4986 r:0.7197
et_en Dev loss: 0.4875 r:0.6562
si_en Dev loss: 0.8185 r:0.5741
ne_en Dev loss: 0.4606 r:0.7473
ru_en Dev loss: 0.4426 r:0.7429
Current avg r:0.5863 Best avg r: 0.6196
23:37:29,916 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:38:47,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:18,952 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2898
en_de Dev loss: 0.8612 r:0.2324
en_zh Dev loss: 0.8281 r:0.4267
ro_en Dev loss: 0.5293 r:0.7062
et_en Dev loss: 0.4998 r:0.6460
si_en Dev loss: 0.8081 r:0.5701
ne_en Dev loss: 0.4943 r:0.7415
ru_en Dev loss: 0.4581 r:0.7294
Current avg r:0.5789 Best avg r: 0.6196
23:44:12,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:30,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:47:01,312 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2890
en_de Dev loss: 0.8616 r:0.2412
en_zh Dev loss: 0.8265 r:0.4429
ro_en Dev loss: 0.5230 r:0.7160
et_en Dev loss: 0.4737 r:0.6578
si_en Dev loss: 0.8400 r:0.5726
ne_en Dev loss: 0.5120 r:0.7439
ru_en Dev loss: 0.4494 r:0.7421
Current avg r:0.5881 Best avg r: 0.6196
23:50:54,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:12,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:43,231 root INFO Epoch 5 Global steps: 49200 Train loss: 0.3033
en_de Dev loss: 0.8577 r:0.2489
en_zh Dev loss: 0.8184 r:0.4487
ro_en Dev loss: 0.5363 r:0.7115
et_en Dev loss: 0.4950 r:0.6492
si_en Dev loss: 0.8586 r:0.5743
ne_en Dev loss: 0.6114 r:0.7391
ru_en Dev loss: 0.5068 r:0.7278
Current avg r:0.5856 Best avg r: 0.6196
23:57:35,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:53,749 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:24,543 root INFO Epoch 5 Global steps: 49800 Train loss: 0.3239
en_de Dev loss: 0.9042 r:0.2238
en_zh Dev loss: 0.9030 r:0.4285
ro_en Dev loss: 0.5739 r:0.7004
et_en Dev loss: 0.5077 r:0.6434
si_en Dev loss: 0.9664 r:0.5611
ne_en Dev loss: 0.6595 r:0.7365
ru_en Dev loss: 0.5278 r:0.7146
Current avg r:0.5726 Best avg r: 0.6196
00:04:17,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:35,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:05,778 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2955
en_de Dev loss: 0.8546 r:0.2481
en_zh Dev loss: 0.8288 r:0.4388
ro_en Dev loss: 0.5175 r:0.7066
et_en Dev loss: 0.4895 r:0.6463
si_en Dev loss: 0.8290 r:0.5718
ne_en Dev loss: 0.5379 r:0.7324
ru_en Dev loss: 0.5061 r:0.7153
Current avg r:0.5799 Best avg r: 0.6196
00:10:58,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:12:16,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:13:47,352 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2881
en_de Dev loss: 0.8721 r:0.2320
en_zh Dev loss: 0.8046 r:0.4522
ro_en Dev loss: 0.4900 r:0.7119
et_en Dev loss: 0.4749 r:0.6590
si_en Dev loss: 0.7829 r:0.5786
ne_en Dev loss: 0.5092 r:0.7363
ru_en Dev loss: 0.4481 r:0.7360
Current avg r:0.5866 Best avg r: 0.6196
00:17:43,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:00,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:31,671 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2960
en_de Dev loss: 0.8623 r:0.2295
en_zh Dev loss: 0.8754 r:0.4528
ro_en Dev loss: 0.5511 r:0.7164
et_en Dev loss: 0.5062 r:0.6557
si_en Dev loss: 0.9329 r:0.5715
ne_en Dev loss: 0.5365 r:0.7380
ru_en Dev loss: 0.4987 r:0.7374
Current avg r:0.5859 Best avg r: 0.6196
00:24:24,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:25:42,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:13,9 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2882
en_de Dev loss: 0.8711 r:0.2229
en_zh Dev loss: 0.7973 r:0.4571
ro_en Dev loss: 0.5110 r:0.7030
et_en Dev loss: 0.4642 r:0.6512
si_en Dev loss: 0.7964 r:0.5672
ne_en Dev loss: 0.4467 r:0.7433
ru_en Dev loss: 0.4414 r:0.7393
Current avg r:0.5834 Best avg r: 0.6196
00:31:05,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:32:23,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:33:54,299 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2946
en_de Dev loss: 0.8583 r:0.2485
en_zh Dev loss: 0.7995 r:0.4573
ro_en Dev loss: 0.4999 r:0.7073
et_en Dev loss: 0.4757 r:0.6528
si_en Dev loss: 0.7982 r:0.5633
ne_en Dev loss: 0.4714 r:0.7409
ru_en Dev loss: 0.4580 r:0.7332
Current avg r:0.5862 Best avg r: 0.6196
00:37:52,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:39:10,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:41,255 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2944
en_de Dev loss: 0.8607 r:0.2426
en_zh Dev loss: 0.8023 r:0.4501
ro_en Dev loss: 0.5094 r:0.7048
et_en Dev loss: 0.5001 r:0.6530
si_en Dev loss: 0.8272 r:0.5631
ne_en Dev loss: 0.4985 r:0.7361
ru_en Dev loss: 0.4562 r:0.7332
Current avg r:0.5833 Best avg r: 0.6196
00:44:33,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:51,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:22,548 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2892
en_de Dev loss: 0.8612 r:0.2292
en_zh Dev loss: 0.8788 r:0.4466
ro_en Dev loss: 0.5545 r:0.7080
et_en Dev loss: 0.4955 r:0.6576
si_en Dev loss: 0.9356 r:0.5579
ne_en Dev loss: 0.5817 r:0.7418
ru_en Dev loss: 0.5064 r:0.7251
Current avg r:0.5809 Best avg r: 0.6196
00:51:16,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:34,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:05,234 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2427
en_de Dev loss: 0.8584 r:0.2330
en_zh Dev loss: 0.8510 r:0.4441
ro_en Dev loss: 0.5323 r:0.7018
et_en Dev loss: 0.5196 r:0.6469
si_en Dev loss: 0.8881 r:0.5585
ne_en Dev loss: 0.5701 r:0.7376
ru_en Dev loss: 0.5090 r:0.7144
Current avg r:0.5766 Best avg r: 0.6196
00:57:58,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:59:15,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:00:46,660 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2565
en_de Dev loss: 0.8685 r:0.2325
en_zh Dev loss: 0.8548 r:0.4402
ro_en Dev loss: 0.5457 r:0.7004
et_en Dev loss: 0.5134 r:0.6459
si_en Dev loss: 0.9874 r:0.5494
ne_en Dev loss: 0.5424 r:0.7367
ru_en Dev loss: 0.5029 r:0.7262
Current avg r:0.5759 Best avg r: 0.6196
01:04:39,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:57,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:27,845 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2712
en_de Dev loss: 0.8553 r:0.2224
en_zh Dev loss: 0.8162 r:0.4435
ro_en Dev loss: 0.4987 r:0.7093
et_en Dev loss: 0.5041 r:0.6479
si_en Dev loss: 0.9039 r:0.5593
ne_en Dev loss: 0.5840 r:0.7314
ru_en Dev loss: 0.4790 r:0.7203
Current avg r:0.5763 Best avg r: 0.6196
01:11:20,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:38,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:09,353 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2543
en_de Dev loss: 0.8794 r:0.2275
en_zh Dev loss: 0.8737 r:0.4351
ro_en Dev loss: 0.5353 r:0.6984
et_en Dev loss: 0.5137 r:0.6360
si_en Dev loss: 0.9988 r:0.5436
ne_en Dev loss: 0.5748 r:0.7357
ru_en Dev loss: 0.4814 r:0.7283
Current avg r:0.5721 Best avg r: 0.6196
01:18:04,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:22,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:20:52,930 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2612
en_de Dev loss: 0.8795 r:0.2087
en_zh Dev loss: 0.8113 r:0.4367
ro_en Dev loss: 0.4670 r:0.7160
et_en Dev loss: 0.5081 r:0.6490
si_en Dev loss: 0.7911 r:0.5604
ne_en Dev loss: 0.4672 r:0.7341
ru_en Dev loss: 0.4291 r:0.7410
Current avg r:0.5780 Best avg r: 0.6196
01:24:45,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:26:03,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:27:34,83 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2763
en_de Dev loss: 0.8641 r:0.2372
en_zh Dev loss: 0.8238 r:0.4456
ro_en Dev loss: 0.4949 r:0.7113
et_en Dev loss: 0.4879 r:0.6525
si_en Dev loss: 0.8664 r:0.5579
ne_en Dev loss: 0.5252 r:0.7330
ru_en Dev loss: 0.4447 r:0.7414
Current avg r:0.5827 Best avg r: 0.6196
01:31:26,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:32:44,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:15,11 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2541
en_de Dev loss: 0.8970 r:0.2147
en_zh Dev loss: 0.8858 r:0.4377
ro_en Dev loss: 0.5760 r:0.6923
et_en Dev loss: 0.4971 r:0.6467
si_en Dev loss: 0.9727 r:0.5518
ne_en Dev loss: 0.6580 r:0.7336
ru_en Dev loss: 0.5358 r:0.7186
Current avg r:0.5708 Best avg r: 0.6196
01:38:07,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:39:25,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:40:55,974 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2638
en_de Dev loss: 0.8830 r:0.2285
en_zh Dev loss: 0.8478 r:0.4476
ro_en Dev loss: 0.5009 r:0.7160
et_en Dev loss: 0.5190 r:0.6577
si_en Dev loss: 0.8331 r:0.5702
ne_en Dev loss: 0.5087 r:0.7304
ru_en Dev loss: 0.4659 r:0.7431
Current avg r:0.5848 Best avg r: 0.6196
01:44:53,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:46:11,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:47:42,270 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2513
en_de Dev loss: 0.8753 r:0.2421
en_zh Dev loss: 0.7872 r:0.4589
ro_en Dev loss: 0.5041 r:0.7034
et_en Dev loss: 0.5184 r:0.6466
si_en Dev loss: 0.8098 r:0.5641
ne_en Dev loss: 0.4858 r:0.7299
ru_en Dev loss: 0.4583 r:0.7322
Current avg r:0.5825 Best avg r: 0.6196
01:51:34,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:52:52,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:54:23,207 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2495
en_de Dev loss: 0.8543 r:0.2549
en_zh Dev loss: 0.7709 r:0.4680
ro_en Dev loss: 0.4730 r:0.7208
et_en Dev loss: 0.4841 r:0.6523
si_en Dev loss: 0.8470 r:0.5703
ne_en Dev loss: 0.4828 r:0.7261
ru_en Dev loss: 0.4315 r:0.7450
Current avg r:0.5911 Best avg r: 0.6196
01:58:16,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:59:33,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:01:04,704 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2331
en_de Dev loss: 0.8709 r:0.2362
en_zh Dev loss: 0.9173 r:0.4417
ro_en Dev loss: 0.6040 r:0.6892
et_en Dev loss: 0.5306 r:0.6217
si_en Dev loss: 1.0674 r:0.5368
ne_en Dev loss: 0.6504 r:0.7247
ru_en Dev loss: 0.5878 r:0.6874
Current avg r:0.5625 Best avg r: 0.6196
02:04:57,895 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:15,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:46,422 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2476
en_de Dev loss: 0.9212 r:0.2296
en_zh Dev loss: 0.9512 r:0.4358
ro_en Dev loss: 0.5890 r:0.6890
et_en Dev loss: 0.5264 r:0.6238
si_en Dev loss: 0.9646 r:0.5426
ne_en Dev loss: 0.5132 r:0.7291
ru_en Dev loss: 0.5311 r:0.7163
Current avg r:0.5666 Best avg r: 0.6196
02:11:40,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:58,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:29,447 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2409
en_de Dev loss: 0.8612 r:0.2486
en_zh Dev loss: 0.7719 r:0.4638
ro_en Dev loss: 0.5057 r:0.6968
et_en Dev loss: 0.4853 r:0.6383
si_en Dev loss: 0.9060 r:0.5513
ne_en Dev loss: 0.5241 r:0.7298
ru_en Dev loss: 0.4496 r:0.7302
Current avg r:0.5798 Best avg r: 0.6196
02:18:23,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:19:41,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:21:11,801 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2543
en_de Dev loss: 0.8901 r:0.2385
en_zh Dev loss: 0.9030 r:0.4479
ro_en Dev loss: 0.5847 r:0.6933
et_en Dev loss: 0.5226 r:0.6297
si_en Dev loss: 1.0854 r:0.5436
ne_en Dev loss: 0.6733 r:0.7257
ru_en Dev loss: 0.5440 r:0.7128
Current avg r:0.5702 Best avg r: 0.6196
02:25:07,459 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:26:25,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:56,85 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2412
en_de Dev loss: 0.8799 r:0.2471
en_zh Dev loss: 0.8762 r:0.4506
ro_en Dev loss: 0.5330 r:0.7046
et_en Dev loss: 0.5390 r:0.6386
si_en Dev loss: 0.9705 r:0.5514
ne_en Dev loss: 0.5171 r:0.7274
ru_en Dev loss: 0.4757 r:0.7396
Current avg r:0.5799 Best avg r: 0.6196
02:31:50,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:33:08,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:34:39,629 root INFO Epoch 7 Global steps: 63600 Train loss: 0.2187
en_de Dev loss: 0.8699 r:0.2611
en_zh Dev loss: 0.9201 r:0.4367
ro_en Dev loss: 0.5454 r:0.7095
et_en Dev loss: 0.5123 r:0.6464
si_en Dev loss: 0.9640 r:0.5549
ne_en Dev loss: 0.5616 r:0.7348
ru_en Dev loss: 0.5274 r:0.7255
Current avg r:0.5813 Best avg r: 0.6196
02:38:34,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:39:51,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:41:22,855 root INFO Epoch 7 Global steps: 64200 Train loss: 0.2197
en_de Dev loss: 0.8604 r:0.2682
en_zh Dev loss: 0.8553 r:0.4419
ro_en Dev loss: 0.5397 r:0.6983
et_en Dev loss: 0.5240 r:0.6402
si_en Dev loss: 0.9157 r:0.5556
ne_en Dev loss: 0.5448 r:0.7327
ru_en Dev loss: 0.4703 r:0.7344
Current avg r:0.5816 Best avg r: 0.6196
02:45:20,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:46:38,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:48:09,635 root INFO Epoch 7 Global steps: 64800 Train loss: 0.2155
en_de Dev loss: 0.8741 r:0.2446
en_zh Dev loss: 0.8179 r:0.4498
ro_en Dev loss: 0.5568 r:0.6932
et_en Dev loss: 0.4852 r:0.6420
si_en Dev loss: 1.0131 r:0.5473
ne_en Dev loss: 0.6479 r:0.7239
ru_en Dev loss: 0.5239 r:0.7101
Current avg r:0.5730 Best avg r: 0.6196
02:52:02,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:53:20,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:54:51,256 root INFO Epoch 7 Global steps: 65400 Train loss: 0.2139
en_de Dev loss: 0.8702 r:0.2453
en_zh Dev loss: 0.8310 r:0.4423
ro_en Dev loss: 0.5374 r:0.6906
et_en Dev loss: 0.4954 r:0.6440
si_en Dev loss: 0.9281 r:0.5491
ne_en Dev loss: 0.5403 r:0.7305
ru_en Dev loss: 0.4782 r:0.7191
Current avg r:0.5744 Best avg r: 0.6196
02:58:46,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:00:04,138 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:01:34,993 root INFO Epoch 7 Global steps: 66000 Train loss: 0.2161
en_de Dev loss: 0.8847 r:0.2527
en_zh Dev loss: 0.8683 r:0.4471
ro_en Dev loss: 0.5416 r:0.7010
et_en Dev loss: 0.5016 r:0.6510
si_en Dev loss: 0.9155 r:0.5601
ne_en Dev loss: 0.5206 r:0.7382
ru_en Dev loss: 0.5307 r:0.7189
Current avg r:0.5813 Best avg r: 0.6196
03:05:27,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:06:45,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:16,324 root INFO Epoch 7 Global steps: 66600 Train loss: 0.2125
en_de Dev loss: 0.8708 r:0.2494
en_zh Dev loss: 0.8876 r:0.4261
ro_en Dev loss: 0.5813 r:0.6828
et_en Dev loss: 0.5071 r:0.6383
si_en Dev loss: 0.9346 r:0.5502
ne_en Dev loss: 0.5698 r:0.7332
ru_en Dev loss: 0.5420 r:0.7093
Current avg r:0.5699 Best avg r: 0.6196
03:12:09,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:27,405 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:58,202 root INFO Epoch 7 Global steps: 67200 Train loss: 0.2292
en_de Dev loss: 0.8718 r:0.2615
en_zh Dev loss: 0.8392 r:0.4414
ro_en Dev loss: 0.5535 r:0.6914
et_en Dev loss: 0.5059 r:0.6390
si_en Dev loss: 0.9436 r:0.5441
ne_en Dev loss: 0.5430 r:0.7331
ru_en Dev loss: 0.4744 r:0.7358
Current avg r:0.5780 Best avg r: 0.6196
03:18:51,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:20:09,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:21:40,184 root INFO Epoch 7 Global steps: 67800 Train loss: 0.2264
en_de Dev loss: 0.8604 r:0.2381
en_zh Dev loss: 0.8008 r:0.4563
ro_en Dev loss: 0.5197 r:0.6918
et_en Dev loss: 0.5038 r:0.6481
si_en Dev loss: 0.8644 r:0.5544
ne_en Dev loss: 0.5047 r:0.7343
ru_en Dev loss: 0.4564 r:0.7364
Current avg r:0.5799 Best avg r: 0.6196
03:25:32,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:26:50,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:28:21,561 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2198
en_de Dev loss: 0.8834 r:0.2185
en_zh Dev loss: 0.7835 r:0.4643
ro_en Dev loss: 0.4905 r:0.7048
et_en Dev loss: 0.4982 r:0.6511
si_en Dev loss: 0.8267 r:0.5591
ne_en Dev loss: 0.4948 r:0.7328
ru_en Dev loss: 0.4153 r:0.7498
Current avg r:0.5829 Best avg r: 0.6196
03:32:14,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:33:32,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:35:03,209 root INFO Epoch 7 Global steps: 69000 Train loss: 0.2142
en_de Dev loss: 0.8921 r:0.2269
en_zh Dev loss: 0.8586 r:0.4616
ro_en Dev loss: 0.5497 r:0.7093
et_en Dev loss: 0.5235 r:0.6484
si_en Dev loss: 0.9944 r:0.5539
ne_en Dev loss: 0.5591 r:0.7273
ru_en Dev loss: 0.4971 r:0.7388
Current avg r:0.5809 Best avg r: 0.6196
03:38:56,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:14,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:45,23 root INFO Epoch 7 Global steps: 69600 Train loss: 0.2199
en_de Dev loss: 0.8676 r:0.2345
en_zh Dev loss: 0.7785 r:0.4582
ro_en Dev loss: 0.4583 r:0.7170
et_en Dev loss: 0.5023 r:0.6568
si_en Dev loss: 0.7721 r:0.5681
ne_en Dev loss: 0.4571 r:0.7327
ru_en Dev loss: 0.4072 r:0.7516
Current avg r:0.5884 Best avg r: 0.6196
03:45:42,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:47:00,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:48:31,273 root INFO Epoch 7 Global steps: 70200 Train loss: 0.2162
en_de Dev loss: 0.8702 r:0.2415
en_zh Dev loss: 0.8638 r:0.4461
ro_en Dev loss: 0.5481 r:0.7000
et_en Dev loss: 0.4851 r:0.6507
si_en Dev loss: 0.9720 r:0.5574
ne_en Dev loss: 0.5455 r:0.7340
ru_en Dev loss: 0.4932 r:0.7342
Current avg r:0.5805 Best avg r: 0.6196
03:52:23,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:53:41,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:55:12,631 root INFO Epoch 7 Global steps: 70800 Train loss: 0.2011
en_de Dev loss: 0.9059 r:0.2063
en_zh Dev loss: 0.8315 r:0.4412
ro_en Dev loss: 0.5317 r:0.6909
et_en Dev loss: 0.4858 r:0.6397
si_en Dev loss: 0.8284 r:0.5616
ne_en Dev loss: 0.4939 r:0.7380
ru_en Dev loss: 0.4478 r:0.7398
Current avg r:0.5739 Best avg r: 0.6196
03:59:05,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:00:23,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:01:54,371 root INFO Epoch 7 Global steps: 71400 Train loss: 0.2239
en_de Dev loss: 0.9339 r:0.2063
en_zh Dev loss: 0.9625 r:0.4414
ro_en Dev loss: 0.6410 r:0.6861
et_en Dev loss: 0.5489 r:0.6346
si_en Dev loss: 1.0895 r:0.5461
ne_en Dev loss: 0.7026 r:0.7311
ru_en Dev loss: 0.5691 r:0.7300
Current avg r:0.5680 Best avg r: 0.6196
04:05:47,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:07:04,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:35,695 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1993
en_de Dev loss: 0.8911 r:0.2086
en_zh Dev loss: 0.8510 r:0.4415
ro_en Dev loss: 0.5355 r:0.6909
et_en Dev loss: 0.5198 r:0.6375
si_en Dev loss: 0.9251 r:0.5484
ne_en Dev loss: 0.5654 r:0.7321
ru_en Dev loss: 0.4622 r:0.7324
Current avg r:0.5702 Best avg r: 0.6196
04:12:31,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:13:49,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:19,999 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1851
en_de Dev loss: 0.9148 r:0.2064
en_zh Dev loss: 0.8598 r:0.4571
ro_en Dev loss: 0.5441 r:0.6963
et_en Dev loss: 0.5379 r:0.6483
si_en Dev loss: 0.9043 r:0.5573
ne_en Dev loss: 0.4843 r:0.7283
ru_en Dev loss: 0.4740 r:0.7391
Current avg r:0.5761 Best avg r: 0.6196
04:19:15,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:20:33,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:22:03,989 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1914
en_de Dev loss: 0.8741 r:0.2238
en_zh Dev loss: 0.8324 r:0.4588
ro_en Dev loss: 0.5293 r:0.7044
et_en Dev loss: 0.5007 r:0.6487
si_en Dev loss: 0.8870 r:0.5650
ne_en Dev loss: 0.5501 r:0.7312
ru_en Dev loss: 0.4474 r:0.7444
Current avg r:0.5823 Best avg r: 0.6196
04:25:57,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:27:14,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:28:45,760 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1949
en_de Dev loss: 0.8703 r:0.2430
en_zh Dev loss: 0.7985 r:0.4649
ro_en Dev loss: 0.4838 r:0.7095
et_en Dev loss: 0.5364 r:0.6537
si_en Dev loss: 0.8335 r:0.5631
ne_en Dev loss: 0.4825 r:0.7291
ru_en Dev loss: 0.4284 r:0.7434
Current avg r:0.5867 Best avg r: 0.6196
04:32:40,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:33:58,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:35:29,349 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1845
en_de Dev loss: 0.8843 r:0.2056
en_zh Dev loss: 0.8555 r:0.4448
ro_en Dev loss: 0.5183 r:0.6979
et_en Dev loss: 0.5256 r:0.6400
si_en Dev loss: 0.8574 r:0.5601
ne_en Dev loss: 0.4823 r:0.7317
ru_en Dev loss: 0.4351 r:0.7470
Current avg r:0.5753 Best avg r: 0.6196
04:39:21,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:40:39,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:42:10,646 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1785
en_de Dev loss: 0.9015 r:0.2261
en_zh Dev loss: 0.8201 r:0.4583
ro_en Dev loss: 0.5118 r:0.6985
et_en Dev loss: 0.5492 r:0.6395
si_en Dev loss: 0.7874 r:0.5639
ne_en Dev loss: 0.4791 r:0.7273
ru_en Dev loss: 0.4448 r:0.7412
Current avg r:0.5793 Best avg r: 0.6196
04:46:03,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:47:21,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:51,862 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1990
en_de Dev loss: 0.9030 r:0.2318
en_zh Dev loss: 0.8750 r:0.4416
ro_en Dev loss: 0.5835 r:0.6871
et_en Dev loss: 0.5441 r:0.6221
si_en Dev loss: 0.9907 r:0.5479
ne_en Dev loss: 0.5713 r:0.7273
ru_en Dev loss: 0.4828 r:0.7328
Current avg r:0.5701 Best avg r: 0.6196
04:52:44,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:54:02,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:55:33,103 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1909
en_de Dev loss: 0.9260 r:0.1958
en_zh Dev loss: 0.8998 r:0.4452
ro_en Dev loss: 0.5985 r:0.6771
et_en Dev loss: 0.5211 r:0.6304
si_en Dev loss: 0.9561 r:0.5479
ne_en Dev loss: 0.6127 r:0.7250
ru_en Dev loss: 0.5120 r:0.7233
Current avg r:0.5635 Best avg r: 0.6196
04:59:25,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:00:43,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:02:14,490 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1886
en_de Dev loss: 0.9321 r:0.2107
en_zh Dev loss: 0.8641 r:0.4588
ro_en Dev loss: 0.5872 r:0.6868
et_en Dev loss: 0.5757 r:0.6274
si_en Dev loss: 0.9100 r:0.5556
ne_en Dev loss: 0.5522 r:0.7243
ru_en Dev loss: 0.5069 r:0.7322
Current avg r:0.5708 Best avg r: 0.6196
05:06:07,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:07:25,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:55,936 root INFO Epoch 8 Global steps: 77400 Train loss: 0.2009
en_de Dev loss: 0.8960 r:0.2077
en_zh Dev loss: 0.8107 r:0.4604
ro_en Dev loss: 0.5587 r:0.6853
et_en Dev loss: 0.5094 r:0.6362
si_en Dev loss: 0.9236 r:0.5512
ne_en Dev loss: 0.6220 r:0.7299
ru_en Dev loss: 0.4856 r:0.7261
Current avg r:0.5710 Best avg r: 0.6196
05:12:48,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:06,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:37,225 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1888
en_de Dev loss: 0.9097 r:0.2043
en_zh Dev loss: 0.8650 r:0.4593
ro_en Dev loss: 0.5308 r:0.7019
et_en Dev loss: 0.5331 r:0.6421
si_en Dev loss: 0.9056 r:0.5530
ne_en Dev loss: 0.5049 r:0.7336
ru_en Dev loss: 0.5185 r:0.7194
Current avg r:0.5733 Best avg r: 0.6196
05:19:29,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:47,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:22:18,443 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1900
en_de Dev loss: 0.8945 r:0.2070
en_zh Dev loss: 0.8045 r:0.4648
ro_en Dev loss: 0.4985 r:0.6966
et_en Dev loss: 0.5019 r:0.6430
si_en Dev loss: 0.8228 r:0.5590
ne_en Dev loss: 0.5234 r:0.7316
ru_en Dev loss: 0.4255 r:0.7394
Current avg r:0.5773 Best avg r: 0.6196
05:26:11,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:27:28,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:28:59,729 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1880
en_de Dev loss: 0.9112 r:0.2058
en_zh Dev loss: 0.8989 r:0.4510
ro_en Dev loss: 0.5690 r:0.6938
et_en Dev loss: 0.5426 r:0.6379
si_en Dev loss: 0.9225 r:0.5508
ne_en Dev loss: 0.5923 r:0.7303
ru_en Dev loss: 0.4958 r:0.7291
Current avg r:0.5713 Best avg r: 0.6196
05:32:52,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:34:10,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:35:40,985 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1910
en_de Dev loss: 0.9159 r:0.2019
en_zh Dev loss: 0.8755 r:0.4511
ro_en Dev loss: 0.5620 r:0.6995
et_en Dev loss: 0.5415 r:0.6350
si_en Dev loss: 0.9672 r:0.5458
ne_en Dev loss: 0.5489 r:0.7298
ru_en Dev loss: 0.4863 r:0.7372
Current avg r:0.5715 Best avg r: 0.6196
05:39:33,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:40:51,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:42:22,410 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1915
en_de Dev loss: 0.9199 r:0.1996
en_zh Dev loss: 0.8630 r:0.4590
ro_en Dev loss: 0.5449 r:0.7130
et_en Dev loss: 0.5442 r:0.6406
si_en Dev loss: 0.9060 r:0.5561
ne_en Dev loss: 0.5345 r:0.7342
ru_en Dev loss: 0.4630 r:0.7550
Current avg r:0.5796 Best avg r: 0.6196
05:46:20,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:47:38,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:49:09,18 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1904
en_de Dev loss: 0.8930 r:0.2109
en_zh Dev loss: 0.8147 r:0.4542
ro_en Dev loss: 0.5307 r:0.6998
et_en Dev loss: 0.5275 r:0.6345
si_en Dev loss: 0.9049 r:0.5464
ne_en Dev loss: 0.5234 r:0.7284
ru_en Dev loss: 0.4605 r:0.7361
Current avg r:0.5729 Best avg r: 0.6196
05:53:03,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:20,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:55:51,769 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1764
en_de Dev loss: 0.9327 r:0.2137
en_zh Dev loss: 0.8700 r:0.4520
ro_en Dev loss: 0.5808 r:0.6923
et_en Dev loss: 0.5572 r:0.6272
si_en Dev loss: 1.0106 r:0.5390
ne_en Dev loss: 0.5556 r:0.7244
ru_en Dev loss: 0.4965 r:0.7353
Current avg r:0.5691 Best avg r: 0.6196
05:59:44,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:01:02,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:02:33,153 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1726
en_de Dev loss: 0.9161 r:0.2072
en_zh Dev loss: 0.8143 r:0.4648
ro_en Dev loss: 0.5501 r:0.7026
et_en Dev loss: 0.5103 r:0.6357
si_en Dev loss: 0.9315 r:0.5497
ne_en Dev loss: 0.5378 r:0.7314
ru_en Dev loss: 0.5059 r:0.7305
Current avg r:0.5745 Best avg r: 0.6196
06:06:25,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:43,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:09:14,456 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1717
en_de Dev loss: 0.8933 r:0.2167
en_zh Dev loss: 0.7745 r:0.4713
ro_en Dev loss: 0.5001 r:0.7111
et_en Dev loss: 0.5100 r:0.6365
si_en Dev loss: 0.8443 r:0.5546
ne_en Dev loss: 0.4953 r:0.7240
ru_en Dev loss: 0.4365 r:0.7472
Current avg r:0.5802 Best avg r: 0.6196
06:13:07,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:24,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:55,754 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1521
en_de Dev loss: 0.9051 r:0.2065
en_zh Dev loss: 0.8379 r:0.4538
ro_en Dev loss: 0.5445 r:0.7043
et_en Dev loss: 0.5039 r:0.6361
si_en Dev loss: 0.9019 r:0.5542
ne_en Dev loss: 0.5214 r:0.7290
ru_en Dev loss: 0.5099 r:0.7298
Current avg r:0.5734 Best avg r: 0.6196
06:19:48,445 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:21:06,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:22:37,58 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1676
en_de Dev loss: 0.9110 r:0.2122
en_zh Dev loss: 0.8214 r:0.4570
ro_en Dev loss: 0.5181 r:0.7020
et_en Dev loss: 0.5343 r:0.6376
si_en Dev loss: 0.8527 r:0.5584
ne_en Dev loss: 0.5067 r:0.7175
ru_en Dev loss: 0.4408 r:0.7480
Current avg r:0.5761 Best avg r: 0.6196
06:26:29,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:27:47,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:29:18,363 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1713
en_de Dev loss: 0.9255 r:0.2068
en_zh Dev loss: 0.8781 r:0.4523
ro_en Dev loss: 0.5840 r:0.6931
et_en Dev loss: 0.5474 r:0.6344
si_en Dev loss: 0.9676 r:0.5469
ne_en Dev loss: 0.6289 r:0.7225
ru_en Dev loss: 0.5107 r:0.7335
Current avg r:0.5700 Best avg r: 0.6196
06:33:11,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:34:28,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:35:59,775 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1669
en_de Dev loss: 0.9131 r:0.2195
en_zh Dev loss: 0.8778 r:0.4545
ro_en Dev loss: 0.5433 r:0.6999
et_en Dev loss: 0.5111 r:0.6435
si_en Dev loss: 0.9229 r:0.5414
ne_en Dev loss: 0.5432 r:0.7224
ru_en Dev loss: 0.5031 r:0.7301
Current avg r:0.5730 Best avg r: 0.6196
06:39:52,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:10,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:42:41,609 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1683
en_de Dev loss: 0.9118 r:0.2218
en_zh Dev loss: 0.8540 r:0.4714
ro_en Dev loss: 0.5556 r:0.7085
et_en Dev loss: 0.5063 r:0.6406
si_en Dev loss: 0.9542 r:0.5453
ne_en Dev loss: 0.6435 r:0.7276
ru_en Dev loss: 0.4645 r:0.7510
Current avg r:0.5809 Best avg r: 0.6196
06:46:34,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:52,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:49:23,276 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1689
en_de Dev loss: 0.9202 r:0.2340
en_zh Dev loss: 0.8020 r:0.4814
ro_en Dev loss: 0.5301 r:0.7043
et_en Dev loss: 0.5265 r:0.6416
si_en Dev loss: 0.9125 r:0.5416
ne_en Dev loss: 0.5428 r:0.7243
ru_en Dev loss: 0.4666 r:0.7439
Current avg r:0.5816 Best avg r: 0.6196
06:53:16,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:34,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:05,79 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1711
en_de Dev loss: 0.9147 r:0.2176
en_zh Dev loss: 0.8312 r:0.4745
ro_en Dev loss: 0.5272 r:0.7096
et_en Dev loss: 0.5530 r:0.6428
si_en Dev loss: 0.8980 r:0.5485
ne_en Dev loss: 0.5347 r:0.7242
ru_en Dev loss: 0.4801 r:0.7439
Current avg r:0.5802 Best avg r: 0.6196
06:59:59,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:01:17,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:48,163 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1637
en_de Dev loss: 0.9150 r:0.2112
en_zh Dev loss: 0.8383 r:0.4704
ro_en Dev loss: 0.5061 r:0.7087
et_en Dev loss: 0.5454 r:0.6428
si_en Dev loss: 0.8664 r:0.5484
ne_en Dev loss: 0.5153 r:0.7249
ru_en Dev loss: 0.4325 r:0.7494
Current avg r:0.5794 Best avg r: 0.6196
07:06:41,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:07:59,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:09:30,151 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1744
en_de Dev loss: 0.8864 r:0.2028
en_zh Dev loss: 0.7928 r:0.4633
ro_en Dev loss: 0.5128 r:0.7000
et_en Dev loss: 0.4917 r:0.6413
si_en Dev loss: 0.8828 r:0.5416
ne_en Dev loss: 0.5425 r:0.7225
ru_en Dev loss: 0.4611 r:0.7344
Current avg r:0.5723 Best avg r: 0.6196
07:13:23,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:14:41,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:16:12,103 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1726
en_de Dev loss: 0.8870 r:0.1938
en_zh Dev loss: 0.8187 r:0.4461
ro_en Dev loss: 0.5258 r:0.6868
et_en Dev loss: 0.5114 r:0.6261
si_en Dev loss: 0.8759 r:0.5333
ne_en Dev loss: 0.5306 r:0.7209
ru_en Dev loss: 0.4505 r:0.7341
Current avg r:0.5630 Best avg r: 0.6196
07:20:05,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:21:23,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:22:53,946 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1580
en_de Dev loss: 0.8891 r:0.1956
en_zh Dev loss: 0.7925 r:0.4648
ro_en Dev loss: 0.5042 r:0.6984
et_en Dev loss: 0.5048 r:0.6338
si_en Dev loss: 0.9227 r:0.5353
ne_en Dev loss: 0.5741 r:0.7238
ru_en Dev loss: 0.4262 r:0.7428
Current avg r:0.5706 Best avg r: 0.6196
07:26:46,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:28:04,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:29:35,752 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1617
en_de Dev loss: 0.9250 r:0.1968
en_zh Dev loss: 0.8380 r:0.4674
ro_en Dev loss: 0.5427 r:0.6894
et_en Dev loss: 0.5527 r:0.6220
si_en Dev loss: 0.9775 r:0.5282
ne_en Dev loss: 0.5509 r:0.7129
ru_en Dev loss: 0.4835 r:0.7306
Current avg r:0.5639 Best avg r: 0.6196
07:33:29,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:34:47,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:36:18,537 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1443
en_de Dev loss: 0.9245 r:0.1834
en_zh Dev loss: 0.7785 r:0.4641
ro_en Dev loss: 0.4985 r:0.6993
et_en Dev loss: 0.5170 r:0.6412
si_en Dev loss: 0.8695 r:0.5348
ne_en Dev loss: 0.5501 r:0.7120
ru_en Dev loss: 0.4466 r:0.7365
Current avg r:0.5673 Best avg r: 0.6196
07:40:11,445 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:41:29,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:43:00,100 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1474
en_de Dev loss: 0.9736 r:0.1793
en_zh Dev loss: 0.8063 r:0.4817
ro_en Dev loss: 0.5338 r:0.7020
et_en Dev loss: 0.5193 r:0.6408
si_en Dev loss: 0.9735 r:0.5400
ne_en Dev loss: 0.5956 r:0.7138
ru_en Dev loss: 0.4321 r:0.7576
Current avg r:0.5736 Best avg r: 0.6196
07:46:52,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:10,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:49:41,443 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1554
en_de Dev loss: 0.9394 r:0.1929
en_zh Dev loss: 0.8242 r:0.4705
ro_en Dev loss: 0.5278 r:0.6992
et_en Dev loss: 0.5858 r:0.6442
si_en Dev loss: 0.9452 r:0.5419
ne_en Dev loss: 0.6084 r:0.7133
ru_en Dev loss: 0.4901 r:0.7295
Current avg r:0.5702 Best avg r: 0.6196
07:53:34,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:54:51,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:56:22,753 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1596
en_de Dev loss: 0.9503 r:0.2024
en_zh Dev loss: 0.8777 r:0.4615
ro_en Dev loss: 0.6195 r:0.6880
et_en Dev loss: 0.5377 r:0.6262
si_en Dev loss: 1.0894 r:0.5292
ne_en Dev loss: 0.7223 r:0.7151
ru_en Dev loss: 0.5545 r:0.7245
Current avg r:0.5638 Best avg r: 0.6196
08:00:15,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:01:33,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:04,40 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1546
en_de Dev loss: 0.9263 r:0.2000
en_zh Dev loss: 0.7932 r:0.4733
ro_en Dev loss: 0.5146 r:0.7120
et_en Dev loss: 0.5055 r:0.6427
si_en Dev loss: 0.9610 r:0.5386
ne_en Dev loss: 0.5934 r:0.7215
ru_en Dev loss: 0.4587 r:0.7433
Current avg r:0.5759 Best avg r: 0.6196
08:06:56,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:14,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:09:45,266 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1528
en_de Dev loss: 0.9282 r:0.2015
en_zh Dev loss: 0.8422 r:0.4615
ro_en Dev loss: 0.5887 r:0.6954
et_en Dev loss: 0.5270 r:0.6374
si_en Dev loss: 1.1282 r:0.5264
ne_en Dev loss: 0.7477 r:0.7153
ru_en Dev loss: 0.5509 r:0.7208
Current avg r:0.5655 Best avg r: 0.6196
08:13:37,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:14:55,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:26,573 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1478
en_de Dev loss: 0.9299 r:0.1850
en_zh Dev loss: 0.8280 r:0.4660
ro_en Dev loss: 0.5019 r:0.7046
et_en Dev loss: 0.5105 r:0.6430
si_en Dev loss: 0.8539 r:0.5441
ne_en Dev loss: 0.5535 r:0.7127
ru_en Dev loss: 0.4463 r:0.7411
Current avg r:0.5709 Best avg r: 0.6196
08:20:19,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:37,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:07,958 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1545
en_de Dev loss: 0.9218 r:0.1771
en_zh Dev loss: 0.7590 r:0.4797
ro_en Dev loss: 0.4839 r:0.7058
et_en Dev loss: 0.5168 r:0.6486
si_en Dev loss: 0.8259 r:0.5481
ne_en Dev loss: 0.5112 r:0.7130
ru_en Dev loss: 0.3967 r:0.7548
Current avg r:0.5753 Best avg r: 0.6196
08:27:00,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:18,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:49,421 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1417
en_de Dev loss: 0.9669 r:0.1698
en_zh Dev loss: 0.8141 r:0.4755
ro_en Dev loss: 0.5184 r:0.7069
et_en Dev loss: 0.5275 r:0.6495
si_en Dev loss: 0.8343 r:0.5472
ne_en Dev loss: 0.5154 r:0.7113
ru_en Dev loss: 0.4629 r:0.7416
Current avg r:0.5717 Best avg r: 0.6196
08:33:42,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:00,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:30,898 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1436
en_de Dev loss: 0.9282 r:0.1777
en_zh Dev loss: 0.8304 r:0.4744
ro_en Dev loss: 0.5579 r:0.6908
et_en Dev loss: 0.5201 r:0.6226
si_en Dev loss: 0.9505 r:0.5393
ne_en Dev loss: 0.6479 r:0.7113
ru_en Dev loss: 0.4840 r:0.7269
Current avg r:0.5633 Best avg r: 0.6196
08:40:23,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:41:41,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:12,332 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1424
en_de Dev loss: 0.9423 r:0.1895
en_zh Dev loss: 0.8290 r:0.4812
ro_en Dev loss: 0.5426 r:0.7067
et_en Dev loss: 0.5627 r:0.6427
si_en Dev loss: 0.9428 r:0.5428
ne_en Dev loss: 0.5789 r:0.7127
ru_en Dev loss: 0.4644 r:0.7485
Current avg r:0.5749 Best avg r: 0.6196
08:47:05,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:22,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:53,654 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1457
en_de Dev loss: 0.8918 r:0.1951
en_zh Dev loss: 0.8310 r:0.4783
ro_en Dev loss: 0.5550 r:0.6997
et_en Dev loss: 0.5430 r:0.6307
si_en Dev loss: 0.9827 r:0.5321
ne_en Dev loss: 0.6114 r:0.7126
ru_en Dev loss: 0.4799 r:0.7347
Current avg r:0.5690 Best avg r: 0.6196
08:53:46,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:55:04,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:35,86 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1467
en_de Dev loss: 0.9351 r:0.1974
en_zh Dev loss: 0.8557 r:0.4800
ro_en Dev loss: 0.5709 r:0.6966
et_en Dev loss: 0.5520 r:0.6348
si_en Dev loss: 0.9555 r:0.5416
ne_en Dev loss: 0.6011 r:0.7140
ru_en Dev loss: 0.4778 r:0.7392
Current avg r:0.5719 Best avg r: 0.6196
09:00:27,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:45,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:16,593 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1407
en_de Dev loss: 0.9254 r:0.1865
en_zh Dev loss: 0.8577 r:0.4734
ro_en Dev loss: 0.5703 r:0.6948
et_en Dev loss: 0.5163 r:0.6345
si_en Dev loss: 0.9537 r:0.5332
ne_en Dev loss: 0.5749 r:0.7125
ru_en Dev loss: 0.5174 r:0.7203
Current avg r:0.5650 Best avg r: 0.6196
09:07:09,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:08:27,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:57,961 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1463
en_de Dev loss: 0.9503 r:0.1888
en_zh Dev loss: 0.8827 r:0.4697
ro_en Dev loss: 0.6090 r:0.6977
et_en Dev loss: 0.5284 r:0.6335
si_en Dev loss: 0.9783 r:0.5353
ne_en Dev loss: 0.5560 r:0.7231
ru_en Dev loss: 0.5293 r:0.7300
Current avg r:0.5683 Best avg r: 0.6196
09:14:00,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:18,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:49,400 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1394
en_de Dev loss: 0.9424 r:0.2045
en_zh Dev loss: 0.8479 r:0.4777
ro_en Dev loss: 0.5696 r:0.6943
et_en Dev loss: 0.5431 r:0.6339
si_en Dev loss: 0.9283 r:0.5382
ne_en Dev loss: 0.5715 r:0.7184
ru_en Dev loss: 0.4686 r:0.7433
Current avg r:0.5729 Best avg r: 0.6196
09:20:42,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:22:00,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:23:31,154 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1378
en_de Dev loss: 0.9659 r:0.1853
en_zh Dev loss: 0.8581 r:0.4736
ro_en Dev loss: 0.6393 r:0.6835
et_en Dev loss: 0.5473 r:0.6154
si_en Dev loss: 1.0866 r:0.5185
ne_en Dev loss: 0.7067 r:0.7086
ru_en Dev loss: 0.5302 r:0.7290
Current avg r:0.5591 Best avg r: 0.6196
09:27:26,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:28:43,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:30:14,707 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1411
en_de Dev loss: 0.9508 r:0.1772
en_zh Dev loss: 0.7861 r:0.4818
ro_en Dev loss: 0.5474 r:0.6989
et_en Dev loss: 0.5182 r:0.6311
si_en Dev loss: 0.9272 r:0.5367
ne_en Dev loss: 0.5632 r:0.7151
ru_en Dev loss: 0.4531 r:0.7416
Current avg r:0.5689 Best avg r: 0.6196
09:34:07,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:25,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:56,239 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1362
en_de Dev loss: 0.9755 r:0.1796
en_zh Dev loss: 0.7976 r:0.4879
ro_en Dev loss: 0.5441 r:0.7155
et_en Dev loss: 0.5232 r:0.6410
si_en Dev loss: 0.9902 r:0.5378
ne_en Dev loss: 0.6390 r:0.7147
ru_en Dev loss: 0.4502 r:0.7552
Current avg r:0.5760 Best avg r: 0.6196
09:40:49,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:07,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:38,696 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1337
en_de Dev loss: 0.9407 r:0.1791
en_zh Dev loss: 0.8107 r:0.4734
ro_en Dev loss: 0.5433 r:0.7080
et_en Dev loss: 0.5047 r:0.6480
si_en Dev loss: 0.9031 r:0.5435
ne_en Dev loss: 0.5650 r:0.7100
ru_en Dev loss: 0.4745 r:0.7412
Current avg r:0.5719 Best avg r: 0.6196
09:47:32,767 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:50,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:50:21,458 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1324
en_de Dev loss: 0.9434 r:0.1807
en_zh Dev loss: 0.8372 r:0.4737
ro_en Dev loss: 0.5192 r:0.7085
et_en Dev loss: 0.4999 r:0.6502
si_en Dev loss: 0.8432 r:0.5467
ne_en Dev loss: 0.5399 r:0.7099
ru_en Dev loss: 0.4633 r:0.7375
Current avg r:0.5725 Best avg r: 0.6196
09:54:14,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:32,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:03,54 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1328
en_de Dev loss: 0.9320 r:0.1855
en_zh Dev loss: 0.8644 r:0.4691
ro_en Dev loss: 0.5601 r:0.7066
et_en Dev loss: 0.4930 r:0.6488
si_en Dev loss: 0.9750 r:0.5418
ne_en Dev loss: 0.5909 r:0.7124
ru_en Dev loss: 0.4878 r:0.7385
Current avg r:0.5718 Best avg r: 0.6196
10:00:56,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:13,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:44,835 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1290
en_de Dev loss: 0.9355 r:0.1850
en_zh Dev loss: 0.7776 r:0.4785
ro_en Dev loss: 0.4996 r:0.7092
et_en Dev loss: 0.5094 r:0.6451
si_en Dev loss: 0.8285 r:0.5476
ne_en Dev loss: 0.5512 r:0.7104
ru_en Dev loss: 0.4233 r:0.7480
Current avg r:0.5748 Best avg r: 0.6196
10:07:37,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:55,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:26,673 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1329
en_de Dev loss: 0.9100 r:0.1940
en_zh Dev loss: 0.8242 r:0.4649
ro_en Dev loss: 0.5602 r:0.6944
et_en Dev loss: 0.5105 r:0.6342
si_en Dev loss: 0.9859 r:0.5347
ne_en Dev loss: 0.6098 r:0.7108
ru_en Dev loss: 0.4461 r:0.7424
Current avg r:0.5679 Best avg r: 0.6196
10:14:19,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:15:37,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:08,386 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1378
en_de Dev loss: 0.9432 r:0.1900
en_zh Dev loss: 0.8280 r:0.4712
ro_en Dev loss: 0.5503 r:0.6977
et_en Dev loss: 0.4993 r:0.6398
si_en Dev loss: 0.8890 r:0.5436
ne_en Dev loss: 0.5649 r:0.7150
ru_en Dev loss: 0.4729 r:0.7387
Current avg r:0.5709 Best avg r: 0.6196
10:21:03,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:22:21,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:52,208 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1249
en_de Dev loss: 0.9630 r:0.1780
en_zh Dev loss: 0.8052 r:0.4787
ro_en Dev loss: 0.5306 r:0.7090
et_en Dev loss: 0.5204 r:0.6462
si_en Dev loss: 0.8924 r:0.5489
ne_en Dev loss: 0.5187 r:0.7140
ru_en Dev loss: 0.4766 r:0.7389
Current avg r:0.5734 Best avg r: 0.6196
10:27:45,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:02,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:33,706 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1379
en_de Dev loss: 0.9479 r:0.1866
en_zh Dev loss: 0.7983 r:0.4735
ro_en Dev loss: 0.5506 r:0.6931
et_en Dev loss: 0.5366 r:0.6327
si_en Dev loss: 0.9566 r:0.5332
ne_en Dev loss: 0.6226 r:0.7078
ru_en Dev loss: 0.4581 r:0.7364
Current avg r:0.5662 Best avg r: 0.6196
10:34:26,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:35:44,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:37:15,491 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1254
en_de Dev loss: 0.9571 r:0.1788
en_zh Dev loss: 0.8153 r:0.4755
ro_en Dev loss: 0.5528 r:0.7063
et_en Dev loss: 0.5274 r:0.6417
si_en Dev loss: 0.9934 r:0.5447
ne_en Dev loss: 0.6503 r:0.7148
ru_en Dev loss: 0.4866 r:0.7404
Current avg r:0.5717 Best avg r: 0.6196
