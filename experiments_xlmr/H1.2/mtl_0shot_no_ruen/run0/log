14:42:11,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:24,545 root INFO 
id:en_de cur r: 0.1075 best r: 0.1075
14:42:37,457 root INFO 
id:en_zh cur r: 0.2847 best r: 0.2847
14:42:50,398 root INFO 
id:ro_en cur r: 0.5597 best r: 0.5597
14:43:03,362 root INFO 
id:et_en cur r: 0.4782 best r: 0.4782
14:43:16,333 root INFO 
id:si_en cur r: 0.3919 best r: 0.3919
14:43:29,299 root INFO 
id:ne_en cur r: 0.4400 best r: 0.4400
14:43:29,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:44:59,889 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:44:59,896 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:44:59,901 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:44:59,906 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:44:59,911 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:44:59,917 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:44:59,922 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:45:12,782 root INFO Epoch 0 Global steps: 600 Train loss: 0.8736
en_de Dev loss: 0.8945 r:0.1155
en_zh Dev loss: 0.7591 r:0.2760
ro_en Dev loss: 0.6727 r:0.5654
et_en Dev loss: 0.5839 r:0.4963
si_en Dev loss: 0.7641 r:0.4019
ne_en Dev loss: 0.6573 r:0.4594
ru_en Dev loss: 0.6900 r:0.4442
Current avg r:0.3941 Best avg r: 0.3941
14:49:03,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:16,715 root INFO 
id:en_de cur r: 0.1505 best r: 0.1505
14:49:42,525 root INFO 
id:ro_en cur r: 0.5941 best r: 0.5941
14:49:55,469 root INFO 
id:et_en cur r: 0.5526 best r: 0.5526
14:50:08,431 root INFO 
id:si_en cur r: 0.4313 best r: 0.4313
14:50:21,386 root INFO 
id:ne_en cur r: 0.5186 best r: 0.5186
14:50:21,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:51:51,729 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:51:51,735 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:51:51,740 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:51:51,745 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:51:51,751 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:51:51,756 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:51:51,761 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:52:04,622 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7988
en_de Dev loss: 0.8984 r:0.1063
en_zh Dev loss: 0.7629 r:0.2661
ro_en Dev loss: 0.6143 r:0.6267
et_en Dev loss: 0.5612 r:0.5504
si_en Dev loss: 0.7000 r:0.4689
ne_en Dev loss: 0.6125 r:0.5618
ru_en Dev loss: 0.6324 r:0.5791
Current avg r:0.4513 Best avg r: 0.4513
14:55:55,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:08,713 root INFO 
id:en_de cur r: 0.1585 best r: 0.1585
14:56:34,498 root INFO 
id:ro_en cur r: 0.6266 best r: 0.6266
14:56:47,421 root INFO 
id:et_en cur r: 0.5578 best r: 0.5578
14:57:13,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:43,558 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:58:43,564 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:58:43,569 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:58:43,575 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:58:43,580 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:58:43,585 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:58:43,591 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:58:56,430 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7459
en_de Dev loss: 0.9383 r:0.1462
en_zh Dev loss: 0.7874 r:0.2901
ro_en Dev loss: 0.5984 r:0.6564
et_en Dev loss: 0.5459 r:0.5521
si_en Dev loss: 0.7703 r:0.4518
ne_en Dev loss: 0.6226 r:0.5351
ru_en Dev loss: 0.6240 r:0.6251
Current avg r:0.4653 Best avg r: 0.4653
15:02:47,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:13,80 root INFO 
id:en_zh cur r: 0.2975 best r: 0.2975
15:03:25,996 root INFO 
id:ro_en cur r: 0.6680 best r: 0.6680
15:03:38,953 root INFO 
id:et_en cur r: 0.6150 best r: 0.6150
15:03:51,912 root INFO 
id:si_en cur r: 0.4668 best r: 0.4668
15:04:04,855 root INFO 
id:ne_en cur r: 0.6004 best r: 0.6004
15:04:04,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:35,234 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:05:35,240 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:05:35,246 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:05:35,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:05:35,256 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:05:35,261 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:05:35,266 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:05:48,111 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7537
en_de Dev loss: 0.9513 r:0.1066
en_zh Dev loss: 0.7556 r:0.3189
ro_en Dev loss: 0.5110 r:0.6771
et_en Dev loss: 0.4718 r:0.6247
si_en Dev loss: 0.6537 r:0.4978
ne_en Dev loss: 0.5205 r:0.6268
ru_en Dev loss: 0.5444 r:0.6797
Current avg r:0.5045 Best avg r: 0.5045
15:09:39,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:04,841 root INFO 
id:en_zh cur r: 0.3142 best r: 0.3142
15:10:17,756 root INFO 
id:ro_en cur r: 0.6733 best r: 0.6733
15:10:56,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:26,926 root INFO Epoch 0 Global steps: 3000 Train loss: 0.7123
en_de Dev loss: 0.9574 r:0.1243
en_zh Dev loss: 0.7555 r:0.3343
ro_en Dev loss: 0.4869 r:0.6866
et_en Dev loss: 0.4476 r:0.6157
si_en Dev loss: 0.6754 r:0.4846
ne_en Dev loss: 0.5017 r:0.6143
ru_en Dev loss: 0.5619 r:0.6465
Current avg r:0.5009 Best avg r: 0.5045
15:16:18,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:31,12 root INFO 
id:en_de cur r: 0.1621 best r: 0.1621
15:16:43,893 root INFO 
id:en_zh cur r: 0.3712 best r: 0.3712
15:16:56,800 root INFO 
id:ro_en cur r: 0.7059 best r: 0.7059
15:17:09,724 root INFO 
id:et_en cur r: 0.6321 best r: 0.6321
15:17:22,683 root INFO 
id:si_en cur r: 0.4777 best r: 0.4777
15:17:35,629 root INFO 
id:ne_en cur r: 0.6467 best r: 0.6467
15:17:35,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:05,996 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:19:06,3 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:19:06,7 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:19:06,12 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:19:06,16 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:19:06,21 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:19:06,25 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:19:18,865 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6747
en_de Dev loss: 0.9394 r:0.1488
en_zh Dev loss: 0.7591 r:0.3733
ro_en Dev loss: 0.4386 r:0.7211
et_en Dev loss: 0.4211 r:0.6364
si_en Dev loss: 0.7173 r:0.4943
ne_en Dev loss: 0.4624 r:0.6467
ru_en Dev loss: 0.5169 r:0.6636
Current avg r:0.5263 Best avg r: 0.5263
15:23:10,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:48,729 root INFO 
id:ro_en cur r: 0.7198 best r: 0.7198
15:24:01,664 root INFO 
id:et_en cur r: 0.6497 best r: 0.6497
15:24:14,628 root INFO 
id:si_en cur r: 0.4832 best r: 0.4832
15:24:27,588 root INFO 
id:ne_en cur r: 0.6642 best r: 0.6642
15:24:27,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:58,12 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:25:58,18 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:25:58,24 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:25:58,29 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:25:58,34 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:25:58,38 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:25:58,43 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:26:10,896 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6396
en_de Dev loss: 0.9937 r:0.1327
en_zh Dev loss: 0.7537 r:0.3809
ro_en Dev loss: 0.4626 r:0.7328
et_en Dev loss: 0.4068 r:0.6533
si_en Dev loss: 0.7501 r:0.5115
ne_en Dev loss: 0.4552 r:0.6674
ru_en Dev loss: 0.5193 r:0.6938
Current avg r:0.5389 Best avg r: 0.5389
15:30:02,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:40,897 root INFO 
id:ro_en cur r: 0.7330 best r: 0.7330
15:31:19,748 root INFO 
id:ne_en cur r: 0.6688 best r: 0.6688
15:31:19,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:50,166 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6168
en_de Dev loss: 0.9888 r:0.1557
en_zh Dev loss: 0.8652 r:0.3634
ro_en Dev loss: 0.4494 r:0.7390
et_en Dev loss: 0.4210 r:0.6518
si_en Dev loss: 0.7780 r:0.5022
ne_en Dev loss: 0.4752 r:0.6589
ru_en Dev loss: 0.5689 r:0.6901
Current avg r:0.5373 Best avg r: 0.5389
15:36:41,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:54,347 root INFO 
id:en_de cur r: 0.1782 best r: 0.1782
15:37:07,219 root INFO 
id:en_zh cur r: 0.3730 best r: 0.3730
15:37:20,130 root INFO 
id:ro_en cur r: 0.7518 best r: 0.7518
15:37:33,68 root INFO 
id:et_en cur r: 0.6748 best r: 0.6748
15:37:58,973 root INFO 
id:ne_en cur r: 0.6782 best r: 0.6782
15:37:58,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:29,386 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:39:29,392 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:39:29,396 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:39:29,401 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:39:29,405 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:39:29,409 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:39:29,414 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:39:42,250 root INFO Epoch 0 Global steps: 5400 Train loss: 0.6180
en_de Dev loss: 0.9263 r:0.1804
en_zh Dev loss: 0.7614 r:0.4024
ro_en Dev loss: 0.4290 r:0.7613
et_en Dev loss: 0.3943 r:0.6777
si_en Dev loss: 0.6961 r:0.5467
ne_en Dev loss: 0.4950 r:0.6688
ru_en Dev loss: 0.5405 r:0.6964
Current avg r:0.5620 Best avg r: 0.5620
15:43:33,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:46,74 root INFO 
id:en_de cur r: 0.1966 best r: 0.1966
15:43:58,951 root INFO 
id:en_zh cur r: 0.3959 best r: 0.3959
15:44:11,861 root INFO 
id:ro_en cur r: 0.7544 best r: 0.7544
15:44:24,806 root INFO 
id:et_en cur r: 0.6768 best r: 0.6768
15:44:37,766 root INFO 
id:si_en cur r: 0.5436 best r: 0.5436
15:44:50,713 root INFO 
id:ne_en cur r: 0.6868 best r: 0.6868
15:44:50,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:21,77 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:46:21,83 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:46:21,88 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:46:21,92 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:46:21,97 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:46:21,102 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:46:21,106 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:46:33,952 root INFO Epoch 0 Global steps: 6000 Train loss: 0.6059
en_de Dev loss: 0.9025 r:0.1937
en_zh Dev loss: 0.7213 r:0.4178
ro_en Dev loss: 0.3944 r:0.7561
et_en Dev loss: 0.3899 r:0.6760
si_en Dev loss: 0.6447 r:0.5473
ne_en Dev loss: 0.4446 r:0.6749
ru_en Dev loss: 0.4726 r:0.7066
Current avg r:0.5675 Best avg r: 0.5675
15:50:25,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:38,94 root INFO 
id:en_de cur r: 0.1970 best r: 0.1970
15:50:50,984 root INFO 
id:en_zh cur r: 0.4174 best r: 0.4174
15:51:03,903 root INFO 
id:ro_en cur r: 0.7684 best r: 0.7684
15:51:16,853 root INFO 
id:et_en cur r: 0.6782 best r: 0.6782
15:51:29,806 root INFO 
id:si_en cur r: 0.5449 best r: 0.5449
15:51:42,741 root INFO 
id:ne_en cur r: 0.7130 best r: 0.7130
15:51:42,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:13,139 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:53:13,145 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:53:13,150 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:53:13,155 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:53:13,159 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:53:13,164 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:53:13,168 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:53:26,7 root INFO Epoch 0 Global steps: 6600 Train loss: 0.6101
en_de Dev loss: 0.8867 r:0.2012
en_zh Dev loss: 0.7032 r:0.4251
ro_en Dev loss: 0.3800 r:0.7720
et_en Dev loss: 0.3765 r:0.6835
si_en Dev loss: 0.5994 r:0.5678
ne_en Dev loss: 0.4113 r:0.7015
ru_en Dev loss: 0.4814 r:0.6959
Current avg r:0.5781 Best avg r: 0.5781
15:57:16,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:55,632 root INFO 
id:ro_en cur r: 0.7692 best r: 0.7692
15:58:34,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:04,787 root INFO Epoch 0 Global steps: 7200 Train loss: 0.6020
en_de Dev loss: 0.9539 r:0.1979
en_zh Dev loss: 0.7929 r:0.4096
ro_en Dev loss: 0.4316 r:0.7726
et_en Dev loss: 0.4073 r:0.6794
si_en Dev loss: 0.7589 r:0.5502
ne_en Dev loss: 0.4835 r:0.6920
ru_en Dev loss: 0.6158 r:0.6796
Current avg r:0.5688 Best avg r: 0.5781
16:03:55,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:21,441 root INFO 
id:en_zh cur r: 0.4551 best r: 0.4551
16:04:34,333 root INFO 
id:ro_en cur r: 0.7874 best r: 0.7874
16:04:47,274 root INFO 
id:et_en cur r: 0.6905 best r: 0.6905
16:05:00,225 root INFO 
id:si_en cur r: 0.5852 best r: 0.5852
16:05:13,181 root INFO 
id:ne_en cur r: 0.7256 best r: 0.7256
16:05:13,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:43,543 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:06:43,549 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:06:43,557 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:06:43,565 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:06:43,570 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:06:43,575 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:06:43,580 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:06:56,423 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5731
en_de Dev loss: 0.8606 r:0.1889
en_zh Dev loss: 0.6538 r:0.4590
ro_en Dev loss: 0.3307 r:0.7859
et_en Dev loss: 0.3736 r:0.6963
si_en Dev loss: 0.5746 r:0.5849
ne_en Dev loss: 0.3714 r:0.7287
ru_en Dev loss: 0.4210 r:0.7179
Current avg r:0.5945 Best avg r: 0.5945
16:10:47,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:00,352 root INFO 
id:en_de cur r: 0.1986 best r: 0.1986
16:12:04,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:35,292 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5967
en_de Dev loss: 0.9215 r:0.2001
en_zh Dev loss: 0.8031 r:0.4340
ro_en Dev loss: 0.4207 r:0.7820
et_en Dev loss: 0.4292 r:0.6716
si_en Dev loss: 0.7845 r:0.5475
ne_en Dev loss: 0.4578 r:0.7075
ru_en Dev loss: 0.6114 r:0.6868
Current avg r:0.5757 Best avg r: 0.5945
16:17:26,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:44,425 root INFO 
id:ne_en cur r: 0.7262 best r: 0.7262
16:18:44,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:14,852 root INFO Epoch 0 Global steps: 9000 Train loss: 0.6017
en_de Dev loss: 0.8781 r:0.1955
en_zh Dev loss: 0.7526 r:0.4434
ro_en Dev loss: 0.4117 r:0.7820
et_en Dev loss: 0.4360 r:0.6723
si_en Dev loss: 0.8369 r:0.5445
ne_en Dev loss: 0.5130 r:0.7143
ru_en Dev loss: 0.5592 r:0.6936
Current avg r:0.5780 Best avg r: 0.5945
16:24:07,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:20,844 root INFO 
id:en_de cur r: 0.2083 best r: 0.2083
16:25:25,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:55,891 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5721
en_de Dev loss: 0.8722 r:0.2083
en_zh Dev loss: 0.7723 r:0.4416
ro_en Dev loss: 0.4170 r:0.7826
et_en Dev loss: 0.4272 r:0.6742
si_en Dev loss: 0.8589 r:0.5404
ne_en Dev loss: 0.5601 r:0.7088
ru_en Dev loss: 0.5431 r:0.6939
Current avg r:0.5785 Best avg r: 0.5945
16:30:47,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:00,274 root INFO 
id:en_de cur r: 0.2085 best r: 0.2085
16:31:26,70 root INFO 
id:ro_en cur r: 0.7960 best r: 0.7960
16:31:39,15 root INFO 
id:et_en cur r: 0.6927 best r: 0.6927
16:32:04,913 root INFO 
id:ne_en cur r: 0.7480 best r: 0.7480
16:32:04,913 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:35,254 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:33:35,260 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:33:35,265 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:33:35,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:33:35,273 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:33:35,277 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:33:35,281 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:33:48,124 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5234
en_de Dev loss: 0.8956 r:0.2124
en_zh Dev loss: 0.7537 r:0.4526
ro_en Dev loss: 0.3876 r:0.7991
et_en Dev loss: 0.3888 r:0.6949
si_en Dev loss: 0.6925 r:0.5897
ne_en Dev loss: 0.4346 r:0.7467
ru_en Dev loss: 0.4887 r:0.7106
Current avg r:0.6009 Best avg r: 0.6009
16:37:39,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:56,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:27,220 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5578
en_de Dev loss: 0.8947 r:0.1715
en_zh Dev loss: 0.7882 r:0.4295
ro_en Dev loss: 0.3668 r:0.7886
et_en Dev loss: 0.3926 r:0.6881
si_en Dev loss: 0.6896 r:0.5658
ne_en Dev loss: 0.4605 r:0.7281
ru_en Dev loss: 0.4734 r:0.6865
Current avg r:0.5797 Best avg r: 0.6009
16:44:18,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:31,273 root INFO 
id:en_de cur r: 0.2136 best r: 0.2136
16:44:57,96 root INFO 
id:ro_en cur r: 0.8050 best r: 0.8050
16:45:23,7 root INFO 
id:si_en cur r: 0.5988 best r: 0.5988
16:45:35,971 root INFO 
id:ne_en cur r: 0.7496 best r: 0.7496
16:45:35,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:06,343 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:47:06,349 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:47:06,354 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:47:06,358 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:47:06,362 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:47:06,367 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:47:06,371 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:47:19,218 root INFO Epoch 1 Global steps: 11400 Train loss: 0.5458
en_de Dev loss: 0.8829 r:0.2147
en_zh Dev loss: 0.7235 r:0.4481
ro_en Dev loss: 0.3570 r:0.7984
et_en Dev loss: 0.4197 r:0.6933
si_en Dev loss: 0.5693 r:0.5997
ne_en Dev loss: 0.3497 r:0.7488
ru_en Dev loss: 0.4314 r:0.7114
Current avg r:0.6021 Best avg r: 0.6021
16:51:10,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:27,989 root INFO 
id:ne_en cur r: 0.7507 best r: 0.7507
16:52:27,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:58,342 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5503
en_de Dev loss: 0.8653 r:0.2176
en_zh Dev loss: 0.6958 r:0.4509
ro_en Dev loss: 0.3445 r:0.8002
et_en Dev loss: 0.3905 r:0.6898
si_en Dev loss: 0.6585 r:0.5941
ne_en Dev loss: 0.3886 r:0.7514
ru_en Dev loss: 0.4952 r:0.7010
Current avg r:0.6007 Best avg r: 0.6021
16:57:49,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:02,768 root INFO 
id:en_de cur r: 0.2224 best r: 0.2224
16:58:28,639 root INFO 
id:ro_en cur r: 0.8081 best r: 0.8081
16:59:07,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:38,199 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:00:38,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:00:38,211 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:00:38,215 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:00:38,220 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:00:38,225 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:00:38,230 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:00:51,89 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5419
en_de Dev loss: 0.8695 r:0.2385
en_zh Dev loss: 0.7475 r:0.4469
ro_en Dev loss: 0.3380 r:0.8049
et_en Dev loss: 0.3927 r:0.6914
si_en Dev loss: 0.6886 r:0.5876
ne_en Dev loss: 0.4259 r:0.7486
ru_en Dev loss: 0.4869 r:0.7072
Current avg r:0.6036 Best avg r: 0.6036
17:04:42,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:55,821 root INFO 
id:en_de cur r: 0.2333 best r: 0.2333
17:05:21,689 root INFO 
id:ro_en cur r: 0.8101 best r: 0.8101
17:06:00,626 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:31,233 root INFO Epoch 1 Global steps: 13200 Train loss: 0.5047
en_de Dev loss: 0.8774 r:0.2484
en_zh Dev loss: 0.7993 r:0.4441
ro_en Dev loss: 0.3791 r:0.8094
et_en Dev loss: 0.4024 r:0.6877
si_en Dev loss: 0.7520 r:0.5877
ne_en Dev loss: 0.4926 r:0.7444
ru_en Dev loss: 0.5845 r:0.6962
Current avg r:0.6026 Best avg r: 0.6036
17:11:23,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:40,875 root INFO 
id:ne_en cur r: 0.7518 best r: 0.7518
17:12:40,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:11,444 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4945
en_de Dev loss: 0.8560 r:0.2162
en_zh Dev loss: 0.7213 r:0.4591
ro_en Dev loss: 0.3347 r:0.8084
et_en Dev loss: 0.3850 r:0.6892
si_en Dev loss: 0.6215 r:0.6055
ne_en Dev loss: 0.4329 r:0.7519
ru_en Dev loss: 0.5143 r:0.6937
Current avg r:0.6034 Best avg r: 0.6036
17:18:03,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:16,52 root INFO 
id:en_de cur r: 0.2350 best r: 0.2350
17:19:20,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:51,354 root INFO Epoch 1 Global steps: 14400 Train loss: 0.5608
en_de Dev loss: 0.8696 r:0.2230
en_zh Dev loss: 0.7407 r:0.4606
ro_en Dev loss: 0.3608 r:0.8038
et_en Dev loss: 0.3979 r:0.6861
si_en Dev loss: 0.6499 r:0.5903
ne_en Dev loss: 0.3762 r:0.7491
ru_en Dev loss: 0.5292 r:0.7005
Current avg r:0.6019 Best avg r: 0.6036
17:24:43,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:56,29 root INFO 
id:en_de cur r: 0.2548 best r: 0.2548
17:25:21,883 root INFO 
id:ro_en cur r: 0.8149 best r: 0.8149
17:25:47,847 root INFO 
id:si_en cur r: 0.6002 best r: 0.6002
17:26:00,837 root INFO 
id:ne_en cur r: 0.7550 best r: 0.7550
17:26:00,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:31,445 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:27:31,451 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:27:31,459 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:27:31,464 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:27:31,469 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:27:31,476 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:27:31,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:27:44,338 root INFO Epoch 1 Global steps: 15000 Train loss: 0.5025
en_de Dev loss: 0.8597 r:0.2354
en_zh Dev loss: 0.7477 r:0.4510
ro_en Dev loss: 0.3125 r:0.8149
et_en Dev loss: 0.3680 r:0.7002
si_en Dev loss: 0.6621 r:0.6056
ne_en Dev loss: 0.3726 r:0.7588
ru_en Dev loss: 0.5265 r:0.7103
Current avg r:0.6109 Best avg r: 0.6109
17:31:36,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:41,145 root INFO 
id:si_en cur r: 0.6097 best r: 0.6097
17:32:54,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:24,731 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:34:24,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:34:24,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:34:24,748 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:34:24,753 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:34:24,759 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:34:24,764 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:34:37,627 root INFO Epoch 1 Global steps: 15600 Train loss: 0.5080
en_de Dev loss: 0.8562 r:0.2342
en_zh Dev loss: 0.7131 r:0.4587
ro_en Dev loss: 0.3512 r:0.8118
et_en Dev loss: 0.3691 r:0.7013
si_en Dev loss: 0.6370 r:0.6060
ne_en Dev loss: 0.3726 r:0.7550
ru_en Dev loss: 0.5040 r:0.7101
Current avg r:0.6110 Best avg r: 0.6110
17:38:29,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:08,389 root INFO 
id:ro_en cur r: 0.8155 best r: 0.8155
17:39:47,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:17,917 root INFO Epoch 1 Global steps: 16200 Train loss: 0.5370
en_de Dev loss: 0.8538 r:0.2123
en_zh Dev loss: 0.6866 r:0.4635
ro_en Dev loss: 0.3256 r:0.8146
et_en Dev loss: 0.3798 r:0.6951
si_en Dev loss: 0.6057 r:0.6070
ne_en Dev loss: 0.4264 r:0.7501
ru_en Dev loss: 0.4867 r:0.7003
Current avg r:0.6061 Best avg r: 0.6110
17:45:09,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:35,721 root INFO 
id:en_zh cur r: 0.4627 best r: 0.4627
17:46:01,642 root INFO 
id:et_en cur r: 0.6969 best r: 0.6969
17:46:27,590 root INFO 
id:ne_en cur r: 0.7599 best r: 0.7599
17:46:27,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:58,158 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4999
en_de Dev loss: 0.8576 r:0.2233
en_zh Dev loss: 0.7207 r:0.4660
ro_en Dev loss: 0.3352 r:0.8161
et_en Dev loss: 0.3788 r:0.6994
si_en Dev loss: 0.6502 r:0.6019
ne_en Dev loss: 0.3995 r:0.7588
ru_en Dev loss: 0.5198 r:0.7005
Current avg r:0.6094 Best avg r: 0.6110
17:51:49,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:28,532 root INFO 
id:ro_en cur r: 0.8194 best r: 0.8194
17:53:07,462 root INFO 
id:ne_en cur r: 0.7611 best r: 0.7611
17:53:07,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:38,47 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:54:38,52 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:54:38,59 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:54:38,65 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:54:38,69 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:54:38,74 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:54:38,79 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:54:50,959 root INFO Epoch 1 Global steps: 17400 Train loss: 0.5048
en_de Dev loss: 0.8566 r:0.2437
en_zh Dev loss: 0.7493 r:0.4546
ro_en Dev loss: 0.3310 r:0.8191
et_en Dev loss: 0.3967 r:0.6998
si_en Dev loss: 0.6296 r:0.6098
ne_en Dev loss: 0.3427 r:0.7617
ru_en Dev loss: 0.5006 r:0.7002
Current avg r:0.6127 Best avg r: 0.6127
17:58:42,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:08,613 root INFO 
id:en_zh cur r: 0.4655 best r: 0.4655
17:59:21,572 root INFO 
id:ro_en cur r: 0.8247 best r: 0.8247
17:59:34,535 root INFO 
id:et_en cur r: 0.6997 best r: 0.6997
17:59:47,508 root INFO 
id:si_en cur r: 0.6225 best r: 0.6225
18:00:00,478 root INFO 
id:ne_en cur r: 0.7659 best r: 0.7659
18:00:00,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:31,83 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
18:01:31,89 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:01:31,93 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:01:31,97 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
18:01:31,101 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
18:01:31,106 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:01:31,110 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:01:43,965 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4945
en_de Dev loss: 0.8425 r:0.2273
en_zh Dev loss: 0.6736 r:0.4665
ro_en Dev loss: 0.2931 r:0.8246
et_en Dev loss: 0.3769 r:0.7073
si_en Dev loss: 0.5544 r:0.6230
ne_en Dev loss: 0.3407 r:0.7659
ru_en Dev loss: 0.4410 r:0.7034
Current avg r:0.6168 Best avg r: 0.6168
18:05:37,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:54,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:25,441 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4709
en_de Dev loss: 0.8417 r:0.2386
en_zh Dev loss: 0.7577 r:0.4424
ro_en Dev loss: 0.3359 r:0.8153
et_en Dev loss: 0.3959 r:0.6928
si_en Dev loss: 0.7063 r:0.5898
ne_en Dev loss: 0.4322 r:0.7548
ru_en Dev loss: 0.5309 r:0.6879
Current avg r:0.6031 Best avg r: 0.6168
18:12:17,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:35,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:05,688 root INFO Epoch 2 Global steps: 19200 Train loss: 0.5207
en_de Dev loss: 0.8742 r:0.2365
en_zh Dev loss: 0.7755 r:0.4465
ro_en Dev loss: 0.3650 r:0.8159
et_en Dev loss: 0.4271 r:0.6829
si_en Dev loss: 0.7803 r:0.5886
ne_en Dev loss: 0.5501 r:0.7522
ru_en Dev loss: 0.5846 r:0.6775
Current avg r:0.6000 Best avg r: 0.6168
18:18:57,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:23,407 root INFO 
id:en_zh cur r: 0.4770 best r: 0.4770
18:20:15,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:45,734 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4717
en_de Dev loss: 0.8484 r:0.2290
en_zh Dev loss: 0.6871 r:0.4762
ro_en Dev loss: 0.3534 r:0.8134
et_en Dev loss: 0.3924 r:0.6874
si_en Dev loss: 0.6937 r:0.6046
ne_en Dev loss: 0.4922 r:0.7494
ru_en Dev loss: 0.5459 r:0.6824
Current avg r:0.6060 Best avg r: 0.6168
18:25:37,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:54,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:25,449 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4759
en_de Dev loss: 0.8911 r:0.2162
en_zh Dev loss: 0.8134 r:0.4661
ro_en Dev loss: 0.3942 r:0.8105
et_en Dev loss: 0.4153 r:0.6836
si_en Dev loss: 0.8166 r:0.5918
ne_en Dev loss: 0.5445 r:0.7497
ru_en Dev loss: 0.6336 r:0.6656
Current avg r:0.5976 Best avg r: 0.6168
18:32:16,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:34,568 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:05,94 root INFO Epoch 2 Global steps: 21000 Train loss: 0.5002
en_de Dev loss: 0.8600 r:0.1929
en_zh Dev loss: 0.7485 r:0.4519
ro_en Dev loss: 0.3563 r:0.8129
et_en Dev loss: 0.3886 r:0.6888
si_en Dev loss: 0.7148 r:0.6000
ne_en Dev loss: 0.4069 r:0.7600
ru_en Dev loss: 0.5394 r:0.6869
Current avg r:0.5991 Best avg r: 0.6168
18:38:57,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:14,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:45,318 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4577
en_de Dev loss: 0.8588 r:0.2080
en_zh Dev loss: 0.7412 r:0.4520
ro_en Dev loss: 0.3406 r:0.8160
et_en Dev loss: 0.3862 r:0.6900
si_en Dev loss: 0.6411 r:0.6071
ne_en Dev loss: 0.4599 r:0.7546
ru_en Dev loss: 0.5593 r:0.6791
Current avg r:0.6009 Best avg r: 0.6168
18:45:37,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:54,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:25,562 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4862
en_de Dev loss: 0.8476 r:0.2336
en_zh Dev loss: 0.7146 r:0.4651
ro_en Dev loss: 0.3484 r:0.8154
et_en Dev loss: 0.3885 r:0.6902
si_en Dev loss: 0.6572 r:0.6003
ne_en Dev loss: 0.4116 r:0.7548
ru_en Dev loss: 0.5070 r:0.6995
Current avg r:0.6084 Best avg r: 0.6168
18:52:17,206 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:30,125 root INFO 
id:en_de cur r: 0.2572 best r: 0.2572
18:53:34,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:05,298 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4536
en_de Dev loss: 0.8817 r:0.2407
en_zh Dev loss: 0.7949 r:0.4618
ro_en Dev loss: 0.4035 r:0.8118
et_en Dev loss: 0.4373 r:0.6827
si_en Dev loss: 0.8854 r:0.5858
ne_en Dev loss: 0.6111 r:0.7464
ru_en Dev loss: 0.6626 r:0.6701
Current avg r:0.5999 Best avg r: 0.6168
18:58:57,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:14,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:45,383 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4453
en_de Dev loss: 0.8735 r:0.2376
en_zh Dev loss: 0.7426 r:0.4707
ro_en Dev loss: 0.3547 r:0.8146
et_en Dev loss: 0.4099 r:0.6906
si_en Dev loss: 0.8590 r:0.5980
ne_en Dev loss: 0.5466 r:0.7532
ru_en Dev loss: 0.5783 r:0.6954
Current avg r:0.6086 Best avg r: 0.6168
19:05:37,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:49,934 root INFO 
id:en_de cur r: 0.2818 best r: 0.2818
19:06:54,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:25,155 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4658
en_de Dev loss: 0.8635 r:0.2651
en_zh Dev loss: 0.8106 r:0.4645
ro_en Dev loss: 0.3877 r:0.8126
et_en Dev loss: 0.4248 r:0.6889
si_en Dev loss: 0.8409 r:0.5974
ne_en Dev loss: 0.5051 r:0.7511
ru_en Dev loss: 0.6314 r:0.6942
Current avg r:0.6105 Best avg r: 0.6168
19:12:16,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:08,459 root INFO 
id:et_en cur r: 0.7000 best r: 0.7000
19:13:34,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:05,210 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4750
en_de Dev loss: 0.8682 r:0.2487
en_zh Dev loss: 0.7362 r:0.4668
ro_en Dev loss: 0.3427 r:0.8169
et_en Dev loss: 0.4022 r:0.6995
si_en Dev loss: 0.7475 r:0.6015
ne_en Dev loss: 0.3969 r:0.7493
ru_en Dev loss: 0.5170 r:0.7141
Current avg r:0.6138 Best avg r: 0.6168
19:18:59,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:17,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:47,959 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4483
en_de Dev loss: 0.8512 r:0.2314
en_zh Dev loss: 0.7411 r:0.4671
ro_en Dev loss: 0.3324 r:0.8188
et_en Dev loss: 0.3892 r:0.6996
si_en Dev loss: 0.6835 r:0.6075
ne_en Dev loss: 0.3839 r:0.7573
ru_en Dev loss: 0.5068 r:0.7111
Current avg r:0.6132 Best avg r: 0.6168
19:25:41,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:07,962 root INFO 
id:en_zh cur r: 0.4781 best r: 0.4781
19:26:34,88 root INFO 
id:et_en cur r: 0.7010 best r: 0.7010
19:27:00,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:30,945 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
19:28:30,952 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
19:28:30,958 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
19:28:30,963 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
19:28:30,968 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
19:28:30,975 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
19:28:30,980 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
19:28:43,924 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4730
en_de Dev loss: 0.8531 r:0.2369
en_zh Dev loss: 0.6974 r:0.4753
ro_en Dev loss: 0.3231 r:0.8237
et_en Dev loss: 0.3684 r:0.7033
si_en Dev loss: 0.6995 r:0.6106
ne_en Dev loss: 0.5076 r:0.7626
ru_en Dev loss: 0.5203 r:0.7113
Current avg r:0.6177 Best avg r: 0.6177
19:32:36,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:54,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:25,648 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4521
en_de Dev loss: 0.8488 r:0.2315
en_zh Dev loss: 0.7069 r:0.4671
ro_en Dev loss: 0.3237 r:0.8223
et_en Dev loss: 0.3792 r:0.7007
si_en Dev loss: 0.6448 r:0.6127
ne_en Dev loss: 0.4421 r:0.7626
ru_en Dev loss: 0.4816 r:0.7114
Current avg r:0.6155 Best avg r: 0.6177
19:39:18,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:44,555 root INFO 
id:en_zh cur r: 0.4811 best r: 0.4811
19:40:36,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:07,642 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4584
en_de Dev loss: 0.8421 r:0.2439
en_zh Dev loss: 0.6967 r:0.4805
ro_en Dev loss: 0.3544 r:0.8169
et_en Dev loss: 0.3867 r:0.6948
si_en Dev loss: 0.7179 r:0.6104
ne_en Dev loss: 0.3876 r:0.7535
ru_en Dev loss: 0.5567 r:0.6906
Current avg r:0.6129 Best avg r: 0.6177
19:46:01,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:19,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:50,877 root INFO Epoch 3 Global steps: 27600 Train loss: 0.4216
en_de Dev loss: 0.8579 r:0.2300
en_zh Dev loss: 0.6980 r:0.4685
ro_en Dev loss: 0.3011 r:0.8231
et_en Dev loss: 0.3754 r:0.6968
si_en Dev loss: 0.7028 r:0.6134
ne_en Dev loss: 0.3687 r:0.7561
ru_en Dev loss: 0.5119 r:0.7122
Current avg r:0.6143 Best avg r: 0.6177
19:52:43,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:01,962 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:32,984 root INFO Epoch 3 Global steps: 28200 Train loss: 0.4561
en_de Dev loss: 0.8501 r:0.2310
en_zh Dev loss: 0.7332 r:0.4625
ro_en Dev loss: 0.3344 r:0.8181
et_en Dev loss: 0.3968 r:0.6875
si_en Dev loss: 0.7531 r:0.5953
ne_en Dev loss: 0.4831 r:0.7563
ru_en Dev loss: 0.5312 r:0.6980
Current avg r:0.6069 Best avg r: 0.6177
19:59:25,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:51,728 root INFO 
id:en_zh cur r: 0.4902 best r: 0.4902
20:00:43,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:14,793 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3974
en_de Dev loss: 0.8566 r:0.2451
en_zh Dev loss: 0.6999 r:0.4774
ro_en Dev loss: 0.3052 r:0.8224
et_en Dev loss: 0.3844 r:0.6902
si_en Dev loss: 0.7331 r:0.6029
ne_en Dev loss: 0.4254 r:0.7605
ru_en Dev loss: 0.4689 r:0.7138
Current avg r:0.6161 Best avg r: 0.6177
20:06:07,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:07:25,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:56,436 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4458
en_de Dev loss: 0.8440 r:0.2465
en_zh Dev loss: 0.7257 r:0.4745
ro_en Dev loss: 0.3609 r:0.8196
et_en Dev loss: 0.4014 r:0.6899
si_en Dev loss: 0.6858 r:0.6081
ne_en Dev loss: 0.4614 r:0.7574
ru_en Dev loss: 0.5378 r:0.6843
Current avg r:0.6115 Best avg r: 0.6177
20:12:49,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:07,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:38,308 root INFO Epoch 3 Global steps: 30000 Train loss: 0.4123
en_de Dev loss: 0.8783 r:0.2338
en_zh Dev loss: 0.7493 r:0.4666
ro_en Dev loss: 0.3796 r:0.8105
et_en Dev loss: 0.4094 r:0.6838
si_en Dev loss: 0.7146 r:0.5986
ne_en Dev loss: 0.4572 r:0.7483
ru_en Dev loss: 0.6452 r:0.6542
Current avg r:0.5994 Best avg r: 0.6177
20:19:31,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:49,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:20,283 root INFO Epoch 3 Global steps: 30600 Train loss: 0.4358
en_de Dev loss: 0.8663 r:0.2512
en_zh Dev loss: 0.7714 r:0.4668
ro_en Dev loss: 0.3499 r:0.8161
et_en Dev loss: 0.4062 r:0.6866
si_en Dev loss: 0.7265 r:0.6058
ne_en Dev loss: 0.4378 r:0.7519
ru_en Dev loss: 0.5907 r:0.6888
Current avg r:0.6096 Best avg r: 0.6177
20:26:13,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:31,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:02,492 root INFO Epoch 3 Global steps: 31200 Train loss: 0.4166
en_de Dev loss: 0.8548 r:0.2457
en_zh Dev loss: 0.7251 r:0.4632
ro_en Dev loss: 0.3350 r:0.8168
et_en Dev loss: 0.3878 r:0.6928
si_en Dev loss: 0.7103 r:0.6051
ne_en Dev loss: 0.4402 r:0.7488
ru_en Dev loss: 0.5464 r:0.7013
Current avg r:0.6105 Best avg r: 0.6177
20:32:55,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:13,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:44,411 root INFO Epoch 3 Global steps: 31800 Train loss: 0.4064
en_de Dev loss: 0.8388 r:0.2565
en_zh Dev loss: 0.7065 r:0.4720
ro_en Dev loss: 0.3049 r:0.8231
et_en Dev loss: 0.3797 r:0.6956
si_en Dev loss: 0.7373 r:0.6046
ne_en Dev loss: 0.4211 r:0.7546
ru_en Dev loss: 0.5088 r:0.7027
Current avg r:0.6156 Best avg r: 0.6177
20:39:37,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:55,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:26,546 root INFO Epoch 3 Global steps: 32400 Train loss: 0.4233
en_de Dev loss: 0.8550 r:0.2314
en_zh Dev loss: 0.7114 r:0.4675
ro_en Dev loss: 0.3337 r:0.8191
et_en Dev loss: 0.3989 r:0.6860
si_en Dev loss: 0.7073 r:0.6067
ne_en Dev loss: 0.4104 r:0.7524
ru_en Dev loss: 0.5680 r:0.6782
Current avg r:0.6059 Best avg r: 0.6177
20:46:19,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:37,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:08,560 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3972
en_de Dev loss: 0.8584 r:0.2330
en_zh Dev loss: 0.7911 r:0.4516
ro_en Dev loss: 0.3432 r:0.8184
et_en Dev loss: 0.4078 r:0.6847
si_en Dev loss: 0.9201 r:0.5832
ne_en Dev loss: 0.6120 r:0.7448
ru_en Dev loss: 0.5927 r:0.6830
Current avg r:0.5998 Best avg r: 0.6177
20:53:01,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:19,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:50,790 root INFO Epoch 3 Global steps: 33600 Train loss: 0.4466
en_de Dev loss: 0.8605 r:0.2218
en_zh Dev loss: 0.7550 r:0.4735
ro_en Dev loss: 0.3298 r:0.8189
et_en Dev loss: 0.4137 r:0.6799
si_en Dev loss: 0.7837 r:0.6010
ne_en Dev loss: 0.4986 r:0.7473
ru_en Dev loss: 0.5789 r:0.6735
Current avg r:0.6023 Best avg r: 0.6177
20:59:44,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:02,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:33,407 root INFO Epoch 3 Global steps: 34200 Train loss: 0.4099
en_de Dev loss: 0.8902 r:0.2150
en_zh Dev loss: 0.7908 r:0.4604
ro_en Dev loss: 0.3503 r:0.8195
et_en Dev loss: 0.4134 r:0.6835
si_en Dev loss: 0.6774 r:0.6111
ne_en Dev loss: 0.4587 r:0.7467
ru_en Dev loss: 0.5828 r:0.6898
Current avg r:0.6037 Best avg r: 0.6177
21:06:26,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:44,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:16,12 root INFO Epoch 3 Global steps: 34800 Train loss: 0.4213
en_de Dev loss: 0.8829 r:0.2087
en_zh Dev loss: 0.7450 r:0.4634
ro_en Dev loss: 0.3420 r:0.8200
et_en Dev loss: 0.4217 r:0.6763
si_en Dev loss: 0.6902 r:0.6091
ne_en Dev loss: 0.4252 r:0.7541
ru_en Dev loss: 0.5239 r:0.6872
Current avg r:0.6027 Best avg r: 0.6177
21:13:09,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:27,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:58,509 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3937
en_de Dev loss: 0.8674 r:0.2272
en_zh Dev loss: 0.7901 r:0.4600
ro_en Dev loss: 0.3758 r:0.8187
et_en Dev loss: 0.4465 r:0.6761
si_en Dev loss: 0.7491 r:0.6019
ne_en Dev loss: 0.4383 r:0.7480
ru_en Dev loss: 0.6284 r:0.6688
Current avg r:0.6001 Best avg r: 0.6177
21:19:51,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:09,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:40,755 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3823
en_de Dev loss: 0.8383 r:0.2446
en_zh Dev loss: 0.7288 r:0.4694
ro_en Dev loss: 0.3222 r:0.8231
et_en Dev loss: 0.4139 r:0.6837
si_en Dev loss: 0.7197 r:0.6037
ne_en Dev loss: 0.4017 r:0.7537
ru_en Dev loss: 0.5312 r:0.6977
Current avg r:0.6108 Best avg r: 0.6177
21:26:35,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:53,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:24,274 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3763
en_de Dev loss: 0.8557 r:0.2254
en_zh Dev loss: 0.8080 r:0.4542
ro_en Dev loss: 0.3297 r:0.8220
et_en Dev loss: 0.4247 r:0.6805
si_en Dev loss: 0.7546 r:0.5966
ne_en Dev loss: 0.4649 r:0.7494
ru_en Dev loss: 0.5607 r:0.6918
Current avg r:0.6028 Best avg r: 0.6177
21:33:17,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:33:30,335 root INFO 
id:en_de cur r: 0.2853 best r: 0.2853
21:34:35,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:06,704 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3782
en_de Dev loss: 0.8381 r:0.2682
en_zh Dev loss: 0.7629 r:0.4645
ro_en Dev loss: 0.3551 r:0.8189
et_en Dev loss: 0.4477 r:0.6687
si_en Dev loss: 0.7370 r:0.5936
ne_en Dev loss: 0.4180 r:0.7489
ru_en Dev loss: 0.5669 r:0.6850
Current avg r:0.6068 Best avg r: 0.6177
21:40:00,120 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:18,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:49,551 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3677
en_de Dev loss: 0.8564 r:0.2552
en_zh Dev loss: 0.7691 r:0.4437
ro_en Dev loss: 0.3614 r:0.8069
et_en Dev loss: 0.4407 r:0.6621
si_en Dev loss: 0.7912 r:0.5794
ne_en Dev loss: 0.5400 r:0.7422
ru_en Dev loss: 0.6208 r:0.6566
Current avg r:0.5923 Best avg r: 0.6177
21:46:43,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:01,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:32,386 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3604
en_de Dev loss: 0.8390 r:0.2498
en_zh Dev loss: 0.7421 r:0.4538
ro_en Dev loss: 0.3222 r:0.8190
et_en Dev loss: 0.4473 r:0.6759
si_en Dev loss: 0.6537 r:0.6020
ne_en Dev loss: 0.3606 r:0.7548
ru_en Dev loss: 0.5237 r:0.6885
Current avg r:0.6062 Best avg r: 0.6177
21:53:25,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:43,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:15,125 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3630
en_de Dev loss: 0.8554 r:0.2208
en_zh Dev loss: 0.8084 r:0.4300
ro_en Dev loss: 0.3380 r:0.8200
et_en Dev loss: 0.4402 r:0.6680
si_en Dev loss: 0.8600 r:0.5884
ne_en Dev loss: 0.4538 r:0.7540
ru_en Dev loss: 0.5992 r:0.6734
Current avg r:0.5935 Best avg r: 0.6177
22:00:08,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:01:26,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:57,807 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3694
en_de Dev loss: 0.8364 r:0.2407
en_zh Dev loss: 0.7542 r:0.4508
ro_en Dev loss: 0.3238 r:0.8203
et_en Dev loss: 0.4367 r:0.6686
si_en Dev loss: 0.7110 r:0.5948
ne_en Dev loss: 0.4091 r:0.7445
ru_en Dev loss: 0.5510 r:0.6769
Current avg r:0.5995 Best avg r: 0.6177
22:06:50,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:09,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:40,189 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3628
en_de Dev loss: 0.8603 r:0.2337
en_zh Dev loss: 0.7883 r:0.4484
ro_en Dev loss: 0.3724 r:0.8163
et_en Dev loss: 0.4740 r:0.6667
si_en Dev loss: 0.7399 r:0.5930
ne_en Dev loss: 0.4277 r:0.7443
ru_en Dev loss: 0.5544 r:0.6852
Current avg r:0.5982 Best avg r: 0.6177
22:13:33,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:51,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:16:22,462 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3648
en_de Dev loss: 0.8863 r:0.2277
en_zh Dev loss: 0.8810 r:0.4261
ro_en Dev loss: 0.4211 r:0.8091
et_en Dev loss: 0.4671 r:0.6559
si_en Dev loss: 0.9848 r:0.5719
ne_en Dev loss: 0.5635 r:0.7425
ru_en Dev loss: 0.7228 r:0.6458
Current avg r:0.5827 Best avg r: 0.6177
22:20:15,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:34,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:05,275 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3480
en_de Dev loss: 0.8883 r:0.2163
en_zh Dev loss: 0.8054 r:0.4398
ro_en Dev loss: 0.3940 r:0.8131
et_en Dev loss: 0.4437 r:0.6656
si_en Dev loss: 0.7816 r:0.5845
ne_en Dev loss: 0.4789 r:0.7462
ru_en Dev loss: 0.5684 r:0.6848
Current avg r:0.5929 Best avg r: 0.6177
22:26:58,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:16,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:48,133 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3729
en_de Dev loss: 0.8644 r:0.2392
en_zh Dev loss: 0.8175 r:0.4385
ro_en Dev loss: 0.3847 r:0.8156
et_en Dev loss: 0.4525 r:0.6653
si_en Dev loss: 0.8544 r:0.5821
ne_en Dev loss: 0.5499 r:0.7411
ru_en Dev loss: 0.6094 r:0.6737
Current avg r:0.5936 Best avg r: 0.6177
22:33:41,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:59,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:31,34 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3512
en_de Dev loss: 0.8580 r:0.2301
en_zh Dev loss: 0.8046 r:0.4428
ro_en Dev loss: 0.3545 r:0.8178
et_en Dev loss: 0.4320 r:0.6699
si_en Dev loss: 0.7701 r:0.5914
ne_en Dev loss: 0.4495 r:0.7457
ru_en Dev loss: 0.5896 r:0.6801
Current avg r:0.5968 Best avg r: 0.6177
22:40:24,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:42,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:43:13,910 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3544
en_de Dev loss: 0.8686 r:0.2171
en_zh Dev loss: 0.7750 r:0.4452
ro_en Dev loss: 0.3508 r:0.8150
et_en Dev loss: 0.4224 r:0.6692
si_en Dev loss: 0.7759 r:0.5827
ne_en Dev loss: 0.4362 r:0.7518
ru_en Dev loss: 0.5701 r:0.6805
Current avg r:0.5945 Best avg r: 0.6177
22:47:07,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:25,562 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:56,731 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3454
en_de Dev loss: 0.8636 r:0.2289
en_zh Dev loss: 0.7573 r:0.4536
ro_en Dev loss: 0.3434 r:0.8193
et_en Dev loss: 0.4194 r:0.6767
si_en Dev loss: 0.7288 r:0.5887
ne_en Dev loss: 0.4011 r:0.7491
ru_en Dev loss: 0.5160 r:0.7040
Current avg r:0.6029 Best avg r: 0.6177
22:53:49,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:07,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:38,674 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3373
en_de Dev loss: 0.8912 r:0.2482
en_zh Dev loss: 0.7872 r:0.4396
ro_en Dev loss: 0.3582 r:0.8146
et_en Dev loss: 0.4193 r:0.6718
si_en Dev loss: 0.7469 r:0.5899
ne_en Dev loss: 0.4590 r:0.7448
ru_en Dev loss: 0.5846 r:0.6872
Current avg r:0.5995 Best avg r: 0.6177
23:00:29,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:47,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:17,723 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3696
en_de Dev loss: 0.8943 r:0.2209
en_zh Dev loss: 0.8084 r:0.4474
ro_en Dev loss: 0.3783 r:0.8123
et_en Dev loss: 0.4790 r:0.6518
si_en Dev loss: 0.9025 r:0.5664
ne_en Dev loss: 0.5228 r:0.7384
ru_en Dev loss: 0.6252 r:0.6621
Current avg r:0.5856 Best avg r: 0.6177
23:07:10,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:27,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:09:57,915 root INFO Epoch 5 Global steps: 45600 Train loss: 0.3120
en_de Dev loss: 0.9017 r:0.2467
en_zh Dev loss: 0.8497 r:0.4511
ro_en Dev loss: 0.4093 r:0.8150
et_en Dev loss: 0.4997 r:0.6562
si_en Dev loss: 0.9000 r:0.5726
ne_en Dev loss: 0.5006 r:0.7420
ru_en Dev loss: 0.6411 r:0.6812
Current avg r:0.5950 Best avg r: 0.6177
23:13:48,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:05,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:36,133 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3417
en_de Dev loss: 0.8557 r:0.2163
en_zh Dev loss: 0.7391 r:0.4607
ro_en Dev loss: 0.3274 r:0.8226
et_en Dev loss: 0.4458 r:0.6684
si_en Dev loss: 0.7496 r:0.5889
ne_en Dev loss: 0.3961 r:0.7516
ru_en Dev loss: 0.5423 r:0.6846
Current avg r:0.5990 Best avg r: 0.6177
23:20:26,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:44,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:14,192 root INFO Epoch 5 Global steps: 46800 Train loss: 0.3036
en_de Dev loss: 0.8685 r:0.2294
en_zh Dev loss: 0.8065 r:0.4559
ro_en Dev loss: 0.4271 r:0.8144
et_en Dev loss: 0.4679 r:0.6609
si_en Dev loss: 0.9871 r:0.5711
ne_en Dev loss: 0.5386 r:0.7420
ru_en Dev loss: 0.6644 r:0.6698
Current avg r:0.5919 Best avg r: 0.6177
23:27:04,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:22,201 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:52,351 root INFO Epoch 5 Global steps: 47400 Train loss: 0.3178
en_de Dev loss: 0.8700 r:0.2254
en_zh Dev loss: 0.7614 r:0.4520
ro_en Dev loss: 0.3488 r:0.8124
et_en Dev loss: 0.4413 r:0.6576
si_en Dev loss: 0.7789 r:0.5851
ne_en Dev loss: 0.4388 r:0.7448
ru_en Dev loss: 0.5921 r:0.6719
Current avg r:0.5927 Best avg r: 0.6177
23:33:43,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:00,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:30,346 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2887
en_de Dev loss: 0.8754 r:0.2042
en_zh Dev loss: 0.7788 r:0.4450
ro_en Dev loss: 0.3685 r:0.8064
et_en Dev loss: 0.4568 r:0.6501
si_en Dev loss: 0.8341 r:0.5705
ne_en Dev loss: 0.5146 r:0.7451
ru_en Dev loss: 0.5854 r:0.6623
Current avg r:0.5834 Best avg r: 0.6177
23:40:21,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:38,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:08,392 root INFO Epoch 5 Global steps: 48600 Train loss: 0.3156
en_de Dev loss: 0.8584 r:0.2124
en_zh Dev loss: 0.8468 r:0.4225
ro_en Dev loss: 0.4163 r:0.8021
et_en Dev loss: 0.4857 r:0.6499
si_en Dev loss: 0.9553 r:0.5623
ne_en Dev loss: 0.5441 r:0.7409
ru_en Dev loss: 0.6835 r:0.6374
Current avg r:0.5754 Best avg r: 0.6177
23:46:59,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:16,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:46,494 root INFO Epoch 5 Global steps: 49200 Train loss: 0.3081
en_de Dev loss: 0.8904 r:0.2158
en_zh Dev loss: 0.8620 r:0.4335
ro_en Dev loss: 0.4105 r:0.8081
et_en Dev loss: 0.4769 r:0.6541
si_en Dev loss: 0.9311 r:0.5741
ne_en Dev loss: 0.5068 r:0.7514
ru_en Dev loss: 0.6569 r:0.6625
Current avg r:0.5856 Best avg r: 0.6177
23:53:37,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:54,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:24,491 root INFO Epoch 5 Global steps: 49800 Train loss: 0.3275
en_de Dev loss: 0.8824 r:0.2148
en_zh Dev loss: 0.8717 r:0.4214
ro_en Dev loss: 0.3969 r:0.8085
et_en Dev loss: 0.4625 r:0.6560
si_en Dev loss: 0.9014 r:0.5683
ne_en Dev loss: 0.4714 r:0.7435
ru_en Dev loss: 0.6725 r:0.6450
Current avg r:0.5796 Best avg r: 0.6177
00:00:15,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:32,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:02,412 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2984
en_de Dev loss: 0.8677 r:0.1997
en_zh Dev loss: 0.8619 r:0.4274
ro_en Dev loss: 0.4082 r:0.8094
et_en Dev loss: 0.4543 r:0.6530
si_en Dev loss: 0.8876 r:0.5664
ne_en Dev loss: 0.5257 r:0.7462
ru_en Dev loss: 0.6174 r:0.6676
Current avg r:0.5814 Best avg r: 0.6177
00:06:53,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:08:10,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:09:40,452 root INFO Epoch 5 Global steps: 51000 Train loss: 0.3004
en_de Dev loss: 0.8624 r:0.2219
en_zh Dev loss: 0.8318 r:0.4448
ro_en Dev loss: 0.4006 r:0.8102
et_en Dev loss: 0.4860 r:0.6546
si_en Dev loss: 0.9855 r:0.5642
ne_en Dev loss: 0.5223 r:0.7446
ru_en Dev loss: 0.6648 r:0.6577
Current avg r:0.5854 Best avg r: 0.6177
00:13:31,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:48,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:16:18,508 root INFO Epoch 5 Global steps: 51600 Train loss: 0.3181
en_de Dev loss: 0.8722 r:0.2191
en_zh Dev loss: 0.8427 r:0.4487
ro_en Dev loss: 0.3886 r:0.8127
et_en Dev loss: 0.4928 r:0.6626
si_en Dev loss: 0.7702 r:0.5804
ne_en Dev loss: 0.4645 r:0.7307
ru_en Dev loss: 0.6412 r:0.6629
Current avg r:0.5882 Best avg r: 0.6177
00:20:09,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:21:26,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:56,639 root INFO Epoch 5 Global steps: 52200 Train loss: 0.3160
en_de Dev loss: 0.8540 r:0.2319
en_zh Dev loss: 0.7620 r:0.4617
ro_en Dev loss: 0.3467 r:0.8147
et_en Dev loss: 0.4603 r:0.6593
si_en Dev loss: 0.8037 r:0.5792
ne_en Dev loss: 0.4455 r:0.7418
ru_en Dev loss: 0.5991 r:0.6470
Current avg r:0.5908 Best avg r: 0.6177
00:26:48,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:06,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:37,32 root INFO Epoch 5 Global steps: 52800 Train loss: 0.3004
en_de Dev loss: 0.8690 r:0.2268
en_zh Dev loss: 0.8142 r:0.4464
ro_en Dev loss: 0.3640 r:0.8127
et_en Dev loss: 0.4929 r:0.6582
si_en Dev loss: 0.7760 r:0.5829
ne_en Dev loss: 0.4522 r:0.7337
ru_en Dev loss: 0.5891 r:0.6601
Current avg r:0.5887 Best avg r: 0.6177
00:33:29,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:47,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:18,404 root INFO Epoch 5 Global steps: 53400 Train loss: 0.3013
en_de Dev loss: 0.8811 r:0.2184
en_zh Dev loss: 0.7759 r:0.4559
ro_en Dev loss: 0.3640 r:0.8118
et_en Dev loss: 0.4801 r:0.6477
si_en Dev loss: 0.8872 r:0.5704
ne_en Dev loss: 0.6264 r:0.7333
ru_en Dev loss: 0.6202 r:0.6408
Current avg r:0.5826 Best avg r: 0.6177
00:40:11,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:29,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:59,876 root INFO Epoch 5 Global steps: 54000 Train loss: 0.3170
en_de Dev loss: 0.8564 r:0.2153
en_zh Dev loss: 0.7626 r:0.4494
ro_en Dev loss: 0.3631 r:0.8079
et_en Dev loss: 0.4747 r:0.6479
si_en Dev loss: 0.8403 r:0.5683
ne_en Dev loss: 0.5460 r:0.7320
ru_en Dev loss: 0.6217 r:0.6250
Current avg r:0.5780 Best avg r: 0.6177
00:46:53,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:11,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:42,131 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2719
en_de Dev loss: 0.8648 r:0.2027
en_zh Dev loss: 0.8123 r:0.4460
ro_en Dev loss: 0.3703 r:0.8114
et_en Dev loss: 0.4894 r:0.6494
si_en Dev loss: 0.8705 r:0.5714
ne_en Dev loss: 0.5029 r:0.7266
ru_en Dev loss: 0.6434 r:0.6479
Current avg r:0.5794 Best avg r: 0.6177
00:53:33,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:54:50,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:56:20,627 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2859
en_de Dev loss: 0.9022 r:0.1908
en_zh Dev loss: 0.8114 r:0.4322
ro_en Dev loss: 0.3503 r:0.8127
et_en Dev loss: 0.4838 r:0.6542
si_en Dev loss: 0.7552 r:0.5746
ne_en Dev loss: 0.4639 r:0.7313
ru_en Dev loss: 0.6069 r:0.6519
Current avg r:0.5783 Best avg r: 0.6177
01:00:11,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:01:28,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:58,533 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2846
en_de Dev loss: 0.8722 r:0.2028
en_zh Dev loss: 0.8125 r:0.4470
ro_en Dev loss: 0.3814 r:0.8123
et_en Dev loss: 0.4658 r:0.6544
si_en Dev loss: 0.8815 r:0.5706
ne_en Dev loss: 0.5283 r:0.7317
ru_en Dev loss: 0.6309 r:0.6418
Current avg r:0.5801 Best avg r: 0.6177
01:06:49,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:06,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:09:36,465 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2871
en_de Dev loss: 0.8795 r:0.1883
en_zh Dev loss: 0.8293 r:0.4385
ro_en Dev loss: 0.3924 r:0.8097
et_en Dev loss: 0.4902 r:0.6436
si_en Dev loss: 0.9114 r:0.5621
ne_en Dev loss: 0.5351 r:0.7337
ru_en Dev loss: 0.6516 r:0.6322
Current avg r:0.5726 Best avg r: 0.6177
01:13:27,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:44,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:14,333 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2761
en_de Dev loss: 0.8775 r:0.2020
en_zh Dev loss: 0.8279 r:0.4398
ro_en Dev loss: 0.4036 r:0.8105
et_en Dev loss: 0.4741 r:0.6526
si_en Dev loss: 0.9178 r:0.5643
ne_en Dev loss: 0.5500 r:0.7349
ru_en Dev loss: 0.6437 r:0.6518
Current avg r:0.5794 Best avg r: 0.6177
01:20:04,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:22,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:22:52,360 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2643
en_de Dev loss: 0.8976 r:0.2193
en_zh Dev loss: 0.8615 r:0.4478
ro_en Dev loss: 0.4209 r:0.8120
et_en Dev loss: 0.5114 r:0.6525
si_en Dev loss: 0.8254 r:0.5691
ne_en Dev loss: 0.4613 r:0.7326
ru_en Dev loss: 0.6524 r:0.6573
Current avg r:0.5844 Best avg r: 0.6177
01:26:43,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:00,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:29:30,467 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2737
en_de Dev loss: 0.8972 r:0.1906
en_zh Dev loss: 0.8608 r:0.4309
ro_en Dev loss: 0.3803 r:0.8088
et_en Dev loss: 0.4908 r:0.6397
si_en Dev loss: 0.9085 r:0.5577
ne_en Dev loss: 0.5602 r:0.7288
ru_en Dev loss: 0.6925 r:0.6167
Current avg r:0.5676 Best avg r: 0.6177
01:33:21,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:34:38,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:08,508 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2834
en_de Dev loss: 0.9233 r:0.1837
en_zh Dev loss: 0.9122 r:0.4288
ro_en Dev loss: 0.4698 r:0.7997
et_en Dev loss: 0.5122 r:0.6356
si_en Dev loss: 0.9815 r:0.5550
ne_en Dev loss: 0.6431 r:0.7252
ru_en Dev loss: 0.7826 r:0.6117
Current avg r:0.5628 Best avg r: 0.6177
01:39:59,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:41:16,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:42:46,424 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2948
en_de Dev loss: 0.8823 r:0.2194
en_zh Dev loss: 0.8584 r:0.4266
ro_en Dev loss: 0.3724 r:0.8063
et_en Dev loss: 0.4778 r:0.6420
si_en Dev loss: 0.9508 r:0.5495
ne_en Dev loss: 0.5765 r:0.7332
ru_en Dev loss: 0.6380 r:0.6496
Current avg r:0.5752 Best avg r: 0.6177
01:46:36,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:47:54,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:49:24,285 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2619
en_de Dev loss: 0.8854 r:0.2263
en_zh Dev loss: 0.8488 r:0.4254
ro_en Dev loss: 0.3616 r:0.8057
et_en Dev loss: 0.4793 r:0.6449
si_en Dev loss: 0.9030 r:0.5500
ne_en Dev loss: 0.5177 r:0.7282
ru_en Dev loss: 0.6210 r:0.6470
Current avg r:0.5754 Best avg r: 0.6177
01:53:14,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:54:33,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:56:05,723 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2593
en_de Dev loss: 0.8583 r:0.2237
en_zh Dev loss: 0.7985 r:0.4370
ro_en Dev loss: 0.3595 r:0.8074
et_en Dev loss: 0.4580 r:0.6504
si_en Dev loss: 0.8621 r:0.5594
ne_en Dev loss: 0.5262 r:0.7373
ru_en Dev loss: 0.5989 r:0.6547
Current avg r:0.5814 Best avg r: 0.6177
02:00:03,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:01:22,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:02:54,464 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2797
en_de Dev loss: 0.8864 r:0.2490
en_zh Dev loss: 0.8227 r:0.4456
ro_en Dev loss: 0.4089 r:0.8094
et_en Dev loss: 0.4765 r:0.6561
si_en Dev loss: 0.8499 r:0.5719
ne_en Dev loss: 0.5257 r:0.7355
ru_en Dev loss: 0.6424 r:0.6658
Current avg r:0.5905 Best avg r: 0.6177
02:06:50,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:08:09,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:09:41,656 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2649
en_de Dev loss: 0.8576 r:0.2239
en_zh Dev loss: 0.7868 r:0.4473
ro_en Dev loss: 0.3654 r:0.8097
et_en Dev loss: 0.4767 r:0.6560
si_en Dev loss: 0.8592 r:0.5603
ne_en Dev loss: 0.5142 r:0.7293
ru_en Dev loss: 0.5884 r:0.6643
Current avg r:0.5844 Best avg r: 0.6177
02:13:37,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:14:56,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:16:28,607 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2761
en_de Dev loss: 0.8719 r:0.2102
en_zh Dev loss: 0.8066 r:0.4374
ro_en Dev loss: 0.3923 r:0.8068
et_en Dev loss: 0.4556 r:0.6564
si_en Dev loss: 0.8874 r:0.5565
ne_en Dev loss: 0.5738 r:0.7252
ru_en Dev loss: 0.6101 r:0.6585
Current avg r:0.5787 Best avg r: 0.6177
02:20:24,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:43,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:23:15,624 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2756
en_de Dev loss: 0.8838 r:0.1981
en_zh Dev loss: 0.8218 r:0.4349
ro_en Dev loss: 0.3758 r:0.8130
et_en Dev loss: 0.4759 r:0.6602
si_en Dev loss: 0.7768 r:0.5712
ne_en Dev loss: 0.4498 r:0.7326
ru_en Dev loss: 0.5970 r:0.6621
Current avg r:0.5817 Best avg r: 0.6177
02:27:11,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:28:29,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:59,987 root INFO Epoch 7 Global steps: 63600 Train loss: 0.2563
en_de Dev loss: 0.8783 r:0.2058
en_zh Dev loss: 0.8521 r:0.4255
ro_en Dev loss: 0.4000 r:0.8065
et_en Dev loss: 0.5143 r:0.6416
si_en Dev loss: 0.9692 r:0.5498
ne_en Dev loss: 0.5567 r:0.7281
ru_en Dev loss: 0.6367 r:0.6431
Current avg r:0.5715 Best avg r: 0.6177
02:33:51,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:09,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:40,64 root INFO Epoch 7 Global steps: 64200 Train loss: 0.2573
en_de Dev loss: 0.8764 r:0.2134
en_zh Dev loss: 0.8086 r:0.4352
ro_en Dev loss: 0.3653 r:0.8105
et_en Dev loss: 0.5207 r:0.6453
si_en Dev loss: 0.7634 r:0.5630
ne_en Dev loss: 0.4525 r:0.7273
ru_en Dev loss: 0.5596 r:0.6630
Current avg r:0.5797 Best avg r: 0.6177
02:40:31,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:41:49,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:43:20,30 root INFO Epoch 7 Global steps: 64800 Train loss: 0.2371
en_de Dev loss: 0.9167 r:0.2239
en_zh Dev loss: 0.9108 r:0.4348
ro_en Dev loss: 0.4392 r:0.8005
et_en Dev loss: 0.5261 r:0.6333
si_en Dev loss: 1.0299 r:0.5413
ne_en Dev loss: 0.5895 r:0.7184
ru_en Dev loss: 0.7715 r:0.6222
Current avg r:0.5678 Best avg r: 0.6177
02:47:11,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:48:29,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:49:59,943 root INFO Epoch 7 Global steps: 65400 Train loss: 0.2365
en_de Dev loss: 0.8999 r:0.2147
en_zh Dev loss: 0.8615 r:0.4484
ro_en Dev loss: 0.3979 r:0.8111
et_en Dev loss: 0.5108 r:0.6543
si_en Dev loss: 0.8761 r:0.5556
ne_en Dev loss: 0.4574 r:0.7281
ru_en Dev loss: 0.6221 r:0.6626
Current avg r:0.5821 Best avg r: 0.6177
02:53:51,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:55:09,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:56:39,890 root INFO Epoch 7 Global steps: 66000 Train loss: 0.2303
en_de Dev loss: 0.8786 r:0.2069
en_zh Dev loss: 0.8059 r:0.4466
ro_en Dev loss: 0.3592 r:0.8069
et_en Dev loss: 0.4902 r:0.6426
si_en Dev loss: 0.8508 r:0.5453
ne_en Dev loss: 0.5126 r:0.7270
ru_en Dev loss: 0.6024 r:0.6417
Current avg r:0.5739 Best avg r: 0.6177
03:00:31,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:01:49,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:20,436 root INFO Epoch 7 Global steps: 66600 Train loss: 0.2509
en_de Dev loss: 0.8835 r:0.2021
en_zh Dev loss: 0.8095 r:0.4522
ro_en Dev loss: 0.3501 r:0.8122
et_en Dev loss: 0.4743 r:0.6373
si_en Dev loss: 0.9148 r:0.5500
ne_en Dev loss: 0.5152 r:0.7285
ru_en Dev loss: 0.6034 r:0.6544
Current avg r:0.5767 Best avg r: 0.6177
03:07:12,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:08:30,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:10:00,853 root INFO Epoch 7 Global steps: 67200 Train loss: 0.2408
en_de Dev loss: 0.8772 r:0.2101
en_zh Dev loss: 0.8798 r:0.4355
ro_en Dev loss: 0.3737 r:0.8097
et_en Dev loss: 0.5093 r:0.6406
si_en Dev loss: 0.9598 r:0.5378
ne_en Dev loss: 0.5680 r:0.7259
ru_en Dev loss: 0.6287 r:0.6472
Current avg r:0.5724 Best avg r: 0.6177
03:13:52,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:15:10,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:41,168 root INFO Epoch 7 Global steps: 67800 Train loss: 0.2492
en_de Dev loss: 0.9006 r:0.2253
en_zh Dev loss: 0.8799 r:0.4357
ro_en Dev loss: 0.4142 r:0.8112
et_en Dev loss: 0.5170 r:0.6412
si_en Dev loss: 0.9677 r:0.5455
ne_en Dev loss: 0.5913 r:0.7206
ru_en Dev loss: 0.6587 r:0.6462
Current avg r:0.5751 Best avg r: 0.6177
03:20:33,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:50,830 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:21,475 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2368
en_de Dev loss: 0.8708 r:0.1988
en_zh Dev loss: 0.7661 r:0.4456
ro_en Dev loss: 0.3364 r:0.8174
et_en Dev loss: 0.4582 r:0.6512
si_en Dev loss: 0.8290 r:0.5546
ne_en Dev loss: 0.4778 r:0.7280
ru_en Dev loss: 0.5746 r:0.6442
Current avg r:0.5771 Best avg r: 0.6177
03:27:13,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:30,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:01,412 root INFO Epoch 7 Global steps: 69000 Train loss: 0.2326
en_de Dev loss: 0.8960 r:0.2177
en_zh Dev loss: 0.8137 r:0.4446
ro_en Dev loss: 0.3888 r:0.8102
et_en Dev loss: 0.4862 r:0.6466
si_en Dev loss: 0.9226 r:0.5572
ne_en Dev loss: 0.5005 r:0.7309
ru_en Dev loss: 0.6123 r:0.6618
Current avg r:0.5813 Best avg r: 0.6177
03:33:53,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:10,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:41,414 root INFO Epoch 7 Global steps: 69600 Train loss: 0.2284
en_de Dev loss: 0.8855 r:0.2232
en_zh Dev loss: 0.8724 r:0.4389
ro_en Dev loss: 0.4196 r:0.8063
et_en Dev loss: 0.5156 r:0.6326
si_en Dev loss: 1.1048 r:0.5449
ne_en Dev loss: 0.7294 r:0.7263
ru_en Dev loss: 0.6783 r:0.6384
Current avg r:0.5729 Best avg r: 0.6177
03:40:33,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:41:50,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:43:21,367 root INFO Epoch 7 Global steps: 70200 Train loss: 0.2421
en_de Dev loss: 0.8661 r:0.2227
en_zh Dev loss: 0.7906 r:0.4489
ro_en Dev loss: 0.3615 r:0.8109
et_en Dev loss: 0.4958 r:0.6407
si_en Dev loss: 0.8450 r:0.5562
ne_en Dev loss: 0.4910 r:0.7255
ru_en Dev loss: 0.6016 r:0.6502
Current avg r:0.5793 Best avg r: 0.6177
03:47:13,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:48:30,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:50:01,530 root INFO Epoch 7 Global steps: 70800 Train loss: 0.2351
en_de Dev loss: 0.8743 r:0.2246
en_zh Dev loss: 0.8310 r:0.4351
ro_en Dev loss: 0.3595 r:0.8124
et_en Dev loss: 0.4907 r:0.6437
si_en Dev loss: 0.9386 r:0.5525
ne_en Dev loss: 0.5685 r:0.7252
ru_en Dev loss: 0.6159 r:0.6608
Current avg r:0.5792 Best avg r: 0.6177
03:53:53,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:55:10,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:56:41,548 root INFO Epoch 7 Global steps: 71400 Train loss: 0.2348
en_de Dev loss: 0.8942 r:0.2410
en_zh Dev loss: 0.8535 r:0.4487
ro_en Dev loss: 0.3921 r:0.8139
et_en Dev loss: 0.5055 r:0.6433
si_en Dev loss: 0.9769 r:0.5565
ne_en Dev loss: 0.6185 r:0.7288
ru_en Dev loss: 0.6339 r:0.6709
Current avg r:0.5862 Best avg r: 0.6177
04:00:33,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:01:50,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:03:21,549 root INFO Epoch 7 Global steps: 72000 Train loss: 0.2330
en_de Dev loss: 0.8839 r:0.2092
en_zh Dev loss: 0.8375 r:0.4428
ro_en Dev loss: 0.3714 r:0.8125
et_en Dev loss: 0.4886 r:0.6385
si_en Dev loss: 0.8646 r:0.5569
ne_en Dev loss: 0.4852 r:0.7258
ru_en Dev loss: 0.6384 r:0.6428
Current avg r:0.5755 Best avg r: 0.6177
04:07:14,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:08:32,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:10:03,113 root INFO Epoch 8 Global steps: 72600 Train loss: 0.2102
en_de Dev loss: 0.8853 r:0.2326
en_zh Dev loss: 0.8082 r:0.4470
ro_en Dev loss: 0.3358 r:0.8139
et_en Dev loss: 0.4818 r:0.6454
si_en Dev loss: 0.7933 r:0.5615
ne_en Dev loss: 0.4279 r:0.7257
ru_en Dev loss: 0.6100 r:0.6517
Current avg r:0.5826 Best avg r: 0.6177
04:13:54,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:15:12,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:16:43,11 root INFO Epoch 8 Global steps: 73200 Train loss: 0.2105
en_de Dev loss: 0.8909 r:0.2105
en_zh Dev loss: 0.8657 r:0.4449
ro_en Dev loss: 0.4079 r:0.8042
et_en Dev loss: 0.5157 r:0.6339
si_en Dev loss: 0.9581 r:0.5466
ne_en Dev loss: 0.5196 r:0.7203
ru_en Dev loss: 0.6663 r:0.6404
Current avg r:0.5715 Best avg r: 0.6177
04:20:34,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:52,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:22,925 root INFO Epoch 8 Global steps: 73800 Train loss: 0.2084
en_de Dev loss: 0.8777 r:0.2095
en_zh Dev loss: 0.7716 r:0.4616
ro_en Dev loss: 0.3389 r:0.8156
et_en Dev loss: 0.5129 r:0.6443
si_en Dev loss: 0.8312 r:0.5541
ne_en Dev loss: 0.5034 r:0.7170
ru_en Dev loss: 0.5705 r:0.6597
Current avg r:0.5802 Best avg r: 0.6177
04:27:15,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:28:34,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:05,581 root INFO Epoch 8 Global steps: 74400 Train loss: 0.2129
en_de Dev loss: 0.9235 r:0.2089
en_zh Dev loss: 0.8497 r:0.4557
ro_en Dev loss: 0.3856 r:0.8075
et_en Dev loss: 0.5325 r:0.6222
si_en Dev loss: 0.9341 r:0.5436
ne_en Dev loss: 0.5490 r:0.7148
ru_en Dev loss: 0.6568 r:0.6413
Current avg r:0.5706 Best avg r: 0.6177
04:34:00,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:35:19,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:36:50,819 root INFO Epoch 8 Global steps: 75000 Train loss: 0.2140
en_de Dev loss: 0.9197 r:0.1795
en_zh Dev loss: 0.8241 r:0.4571
ro_en Dev loss: 0.4163 r:0.8018
et_en Dev loss: 0.5287 r:0.6224
si_en Dev loss: 0.9954 r:0.5356
ne_en Dev loss: 0.6230 r:0.7162
ru_en Dev loss: 0.6768 r:0.6372
Current avg r:0.5642 Best avg r: 0.6177
04:40:45,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:42:04,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:43:36,136 root INFO Epoch 8 Global steps: 75600 Train loss: 0.2217
en_de Dev loss: 0.8824 r:0.2076
en_zh Dev loss: 0.8033 r:0.4580
ro_en Dev loss: 0.3678 r:0.8108
et_en Dev loss: 0.4993 r:0.6394
si_en Dev loss: 0.8705 r:0.5490
ne_en Dev loss: 0.5646 r:0.7100
ru_en Dev loss: 0.6247 r:0.6419
Current avg r:0.5738 Best avg r: 0.6177
04:47:31,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:48:49,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:50:21,297 root INFO Epoch 8 Global steps: 76200 Train loss: 0.2119
en_de Dev loss: 0.8843 r:0.2199
en_zh Dev loss: 0.7985 r:0.4609
ro_en Dev loss: 0.3448 r:0.8129
et_en Dev loss: 0.5103 r:0.6446
si_en Dev loss: 0.7704 r:0.5626
ne_en Dev loss: 0.5100 r:0.7164
ru_en Dev loss: 0.5434 r:0.6777
Current avg r:0.5850 Best avg r: 0.6177
04:54:14,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:55:32,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:57:02,674 root INFO Epoch 8 Global steps: 76800 Train loss: 0.2115
en_de Dev loss: 0.8752 r:0.2245
en_zh Dev loss: 0.8538 r:0.4359
ro_en Dev loss: 0.3917 r:0.8057
et_en Dev loss: 0.5091 r:0.6434
si_en Dev loss: 0.8644 r:0.5542
ne_en Dev loss: 0.5602 r:0.7130
ru_en Dev loss: 0.6098 r:0.6696
Current avg r:0.5780 Best avg r: 0.6177
05:00:54,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:02:12,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:43,168 root INFO Epoch 8 Global steps: 77400 Train loss: 0.2024
en_de Dev loss: 0.8947 r:0.2222
en_zh Dev loss: 0.8828 r:0.4427
ro_en Dev loss: 0.3824 r:0.8133
et_en Dev loss: 0.4984 r:0.6449
si_en Dev loss: 0.9396 r:0.5461
ne_en Dev loss: 0.6023 r:0.7198
ru_en Dev loss: 0.6511 r:0.6632
Current avg r:0.5789 Best avg r: 0.6177
05:07:35,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:08:53,562 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:10:25,116 root INFO Epoch 8 Global steps: 78000 Train loss: 0.2075
en_de Dev loss: 0.8967 r:0.2253
en_zh Dev loss: 0.8855 r:0.4344
ro_en Dev loss: 0.3889 r:0.8117
et_en Dev loss: 0.4995 r:0.6364
si_en Dev loss: 0.8919 r:0.5402
ne_en Dev loss: 0.5387 r:0.7199
ru_en Dev loss: 0.6626 r:0.6511
Current avg r:0.5741 Best avg r: 0.6177
05:14:21,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:15:39,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:17:11,595 root INFO Epoch 8 Global steps: 78600 Train loss: 0.2048
en_de Dev loss: 0.9021 r:0.2301
en_zh Dev loss: 0.8983 r:0.4365
ro_en Dev loss: 0.4157 r:0.8089
et_en Dev loss: 0.5152 r:0.6319
si_en Dev loss: 1.0447 r:0.5325
ne_en Dev loss: 0.5987 r:0.7230
ru_en Dev loss: 0.6822 r:0.6494
Current avg r:0.5732 Best avg r: 0.6177
05:21:07,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:22:26,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:58,151 root INFO Epoch 8 Global steps: 79200 Train loss: 0.2035
en_de Dev loss: 0.8666 r:0.2555
en_zh Dev loss: 0.8239 r:0.4517
ro_en Dev loss: 0.3896 r:0.8138
et_en Dev loss: 0.5080 r:0.6389
si_en Dev loss: 0.9217 r:0.5501
ne_en Dev loss: 0.5976 r:0.7195
ru_en Dev loss: 0.6216 r:0.6687
Current avg r:0.5855 Best avg r: 0.6177
05:27:54,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:29:12,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:44,594 root INFO Epoch 8 Global steps: 79800 Train loss: 0.2131
en_de Dev loss: 0.8600 r:0.2589
en_zh Dev loss: 0.7854 r:0.4444
ro_en Dev loss: 0.3690 r:0.8098
et_en Dev loss: 0.4794 r:0.6363
si_en Dev loss: 0.9486 r:0.5396
ne_en Dev loss: 0.5415 r:0.7154
ru_en Dev loss: 0.6239 r:0.6530
Current avg r:0.5796 Best avg r: 0.6177
05:34:40,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:35:58,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:37:28,887 root INFO Epoch 8 Global steps: 80400 Train loss: 0.2145
en_de Dev loss: 0.8977 r:0.2364
en_zh Dev loss: 0.8324 r:0.4473
ro_en Dev loss: 0.3667 r:0.8096
et_en Dev loss: 0.4938 r:0.6363
si_en Dev loss: 0.8897 r:0.5427
ne_en Dev loss: 0.5160 r:0.7159
ru_en Dev loss: 0.5989 r:0.6698
Current avg r:0.5797 Best avg r: 0.6177
05:41:20,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:42:38,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:44:08,931 root INFO Epoch 8 Global steps: 81000 Train loss: 0.2018
en_de Dev loss: 0.8981 r:0.2282
en_zh Dev loss: 0.7964 r:0.4527
ro_en Dev loss: 0.3654 r:0.8131
et_en Dev loss: 0.4785 r:0.6454
si_en Dev loss: 0.9384 r:0.5438
ne_en Dev loss: 0.5765 r:0.7176
ru_en Dev loss: 0.6038 r:0.6770
Current avg r:0.5825 Best avg r: 0.6177
05:48:02,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:49:19,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:50:50,469 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1947
en_de Dev loss: 0.8868 r:0.2144
en_zh Dev loss: 0.7775 r:0.4562
ro_en Dev loss: 0.3501 r:0.8124
et_en Dev loss: 0.5076 r:0.6394
si_en Dev loss: 0.8556 r:0.5439
ne_en Dev loss: 0.5174 r:0.7141
ru_en Dev loss: 0.5331 r:0.6747
Current avg r:0.5793 Best avg r: 0.6177
05:54:42,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:56:00,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:57:30,941 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1919
en_de Dev loss: 0.8800 r:0.2305
en_zh Dev loss: 0.7999 r:0.4514
ro_en Dev loss: 0.3511 r:0.8119
et_en Dev loss: 0.5056 r:0.6427
si_en Dev loss: 0.8468 r:0.5456
ne_en Dev loss: 0.5088 r:0.7067
ru_en Dev loss: 0.5710 r:0.6683
Current avg r:0.5796 Best avg r: 0.6177
06:01:22,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:02:40,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:11,383 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1922
en_de Dev loss: 0.8806 r:0.2319
en_zh Dev loss: 0.8302 r:0.4476
ro_en Dev loss: 0.3643 r:0.8119
et_en Dev loss: 0.4896 r:0.6479
si_en Dev loss: 0.9056 r:0.5430
ne_en Dev loss: 0.5858 r:0.7091
ru_en Dev loss: 0.5908 r:0.6714
Current avg r:0.5804 Best avg r: 0.6177
06:08:03,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:21,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:10:51,925 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1924
en_de Dev loss: 0.9054 r:0.2390
en_zh Dev loss: 0.8513 r:0.4510
ro_en Dev loss: 0.3893 r:0.8090
et_en Dev loss: 0.4991 r:0.6392
si_en Dev loss: 1.0349 r:0.5266
ne_en Dev loss: 0.6798 r:0.7071
ru_en Dev loss: 0.6424 r:0.6604
Current avg r:0.5760 Best avg r: 0.6177
06:14:43,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:16:01,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:17:32,399 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1782
en_de Dev loss: 0.8985 r:0.2192
en_zh Dev loss: 0.8298 r:0.4623
ro_en Dev loss: 0.3778 r:0.8049
et_en Dev loss: 0.4999 r:0.6344
si_en Dev loss: 0.9614 r:0.5406
ne_en Dev loss: 0.6038 r:0.7111
ru_en Dev loss: 0.6560 r:0.6561
Current avg r:0.5755 Best avg r: 0.6177
06:21:24,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:22:42,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:12,899 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1833
en_de Dev loss: 0.9212 r:0.1946
en_zh Dev loss: 0.8233 r:0.4554
ro_en Dev loss: 0.3547 r:0.8098
et_en Dev loss: 0.4981 r:0.6392
si_en Dev loss: 0.9308 r:0.5372
ne_en Dev loss: 0.5618 r:0.7098
ru_en Dev loss: 0.6334 r:0.6427
Current avg r:0.5698 Best avg r: 0.6177
06:28:04,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:22,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:53,419 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1941
en_de Dev loss: 0.8990 r:0.1826
en_zh Dev loss: 0.8637 r:0.4372
ro_en Dev loss: 0.3887 r:0.8038
et_en Dev loss: 0.4959 r:0.6328
si_en Dev loss: 0.9574 r:0.5366
ne_en Dev loss: 0.6821 r:0.7151
ru_en Dev loss: 0.6954 r:0.6235
Current avg r:0.5617 Best avg r: 0.6177
06:34:45,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:03,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:33,978 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1932
en_de Dev loss: 0.8895 r:0.2042
en_zh Dev loss: 0.7800 r:0.4524
ro_en Dev loss: 0.3490 r:0.8143
et_en Dev loss: 0.4846 r:0.6533
si_en Dev loss: 0.8151 r:0.5502
ne_en Dev loss: 0.4643 r:0.7192
ru_en Dev loss: 0.5647 r:0.6650
Current avg r:0.5798 Best avg r: 0.6177
06:41:26,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:42:43,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:44:14,652 root INFO Epoch 9 Global steps: 86400 Train loss: 0.2000
en_de Dev loss: 0.8842 r:0.1870
en_zh Dev loss: 0.8160 r:0.4473
ro_en Dev loss: 0.3456 r:0.8151
et_en Dev loss: 0.4686 r:0.6511
si_en Dev loss: 0.9139 r:0.5421
ne_en Dev loss: 0.5233 r:0.7175
ru_en Dev loss: 0.5947 r:0.6680
Current avg r:0.5755 Best avg r: 0.6177
06:48:06,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:49:24,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:50:54,925 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1794
en_de Dev loss: 0.9028 r:0.1743
en_zh Dev loss: 0.8784 r:0.4437
ro_en Dev loss: 0.3971 r:0.8081
et_en Dev loss: 0.5057 r:0.6382
si_en Dev loss: 0.9079 r:0.5381
ne_en Dev loss: 0.5561 r:0.7128
ru_en Dev loss: 0.6634 r:0.6488
Current avg r:0.5663 Best avg r: 0.6177
06:54:46,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:56:04,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:57:35,96 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1870
en_de Dev loss: 0.9066 r:0.1884
en_zh Dev loss: 0.8690 r:0.4289
ro_en Dev loss: 0.3862 r:0.8089
et_en Dev loss: 0.5391 r:0.6488
si_en Dev loss: 0.8733 r:0.5405
ne_en Dev loss: 0.5239 r:0.7113
ru_en Dev loss: 0.6455 r:0.6486
Current avg r:0.5679 Best avg r: 0.6177
07:01:26,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:44,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:04:15,132 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1868
en_de Dev loss: 0.9537 r:0.1600
en_zh Dev loss: 0.8471 r:0.4433
ro_en Dev loss: 0.3934 r:0.8124
et_en Dev loss: 0.4970 r:0.6436
si_en Dev loss: 0.8957 r:0.5458
ne_en Dev loss: 0.5052 r:0.7158
ru_en Dev loss: 0.6262 r:0.6593
Current avg r:0.5686 Best avg r: 0.6177
07:08:06,781 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:09:24,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:10:55,62 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1795
en_de Dev loss: 0.8900 r:0.1815
en_zh Dev loss: 0.8356 r:0.4395
ro_en Dev loss: 0.3672 r:0.8074
et_en Dev loss: 0.4728 r:0.6361
si_en Dev loss: 0.9765 r:0.5234
ne_en Dev loss: 0.6136 r:0.7161
ru_en Dev loss: 0.5978 r:0.6573
Current avg r:0.5659 Best avg r: 0.6177
07:14:46,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:16:04,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:35,107 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1706
en_de Dev loss: 0.9451 r:0.1724
en_zh Dev loss: 0.8728 r:0.4431
ro_en Dev loss: 0.3934 r:0.8095
et_en Dev loss: 0.5042 r:0.6385
si_en Dev loss: 0.9863 r:0.5264
ne_en Dev loss: 0.6114 r:0.7109
ru_en Dev loss: 0.6891 r:0.6362
Current avg r:0.5624 Best avg r: 0.6177
07:21:26,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:22:44,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:24:15,193 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1818
en_de Dev loss: 0.9074 r:0.1712
en_zh Dev loss: 0.7839 r:0.4604
ro_en Dev loss: 0.3643 r:0.8132
et_en Dev loss: 0.4691 r:0.6470
si_en Dev loss: 0.9002 r:0.5381
ne_en Dev loss: 0.6175 r:0.7123
ru_en Dev loss: 0.6193 r:0.6608
Current avg r:0.5719 Best avg r: 0.6177
07:28:08,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:29:25,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:56,490 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1659
en_de Dev loss: 0.9363 r:0.1667
en_zh Dev loss: 0.8211 r:0.4617
ro_en Dev loss: 0.3647 r:0.8152
et_en Dev loss: 0.4869 r:0.6535
si_en Dev loss: 0.8994 r:0.5372
ne_en Dev loss: 0.5308 r:0.7184
ru_en Dev loss: 0.6463 r:0.6650
Current avg r:0.5739 Best avg r: 0.6177
07:34:51,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:36:09,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:41,375 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1709
en_de Dev loss: 0.9221 r:0.1823
en_zh Dev loss: 0.8106 r:0.4619
ro_en Dev loss: 0.3858 r:0.8143
et_en Dev loss: 0.4887 r:0.6448
si_en Dev loss: 0.9468 r:0.5366
ne_en Dev loss: 0.6033 r:0.7178
ru_en Dev loss: 0.6349 r:0.6590
Current avg r:0.5738 Best avg r: 0.6177
07:41:36,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:42:54,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:44:26,483 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1652
en_de Dev loss: 0.8938 r:0.1799
en_zh Dev loss: 0.7884 r:0.4488
ro_en Dev loss: 0.3472 r:0.8143
et_en Dev loss: 0.4958 r:0.6456
si_en Dev loss: 0.8854 r:0.5352
ne_en Dev loss: 0.5457 r:0.7185
ru_en Dev loss: 0.5850 r:0.6624
Current avg r:0.5721 Best avg r: 0.6177
07:48:21,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:49:40,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:51:11,966 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1630
en_de Dev loss: 0.9556 r:0.1700
en_zh Dev loss: 0.8440 r:0.4603
ro_en Dev loss: 0.3951 r:0.8079
et_en Dev loss: 0.5150 r:0.6321
si_en Dev loss: 1.0256 r:0.5249
ne_en Dev loss: 0.5806 r:0.7178
ru_en Dev loss: 0.6445 r:0.6581
Current avg r:0.5673 Best avg r: 0.6177
07:55:06,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:56:25,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:57:55,600 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1685
en_de Dev loss: 0.9249 r:0.1734
en_zh Dev loss: 0.8382 r:0.4622
ro_en Dev loss: 0.3649 r:0.8098
et_en Dev loss: 0.4838 r:0.6431
si_en Dev loss: 0.9724 r:0.5360
ne_en Dev loss: 0.5349 r:0.7167
ru_en Dev loss: 0.6506 r:0.6616
Current avg r:0.5718 Best avg r: 0.6177
08:01:47,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:03:05,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:04:36,208 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1612
en_de Dev loss: 0.9172 r:0.1699
en_zh Dev loss: 0.7904 r:0.4593
ro_en Dev loss: 0.3379 r:0.8156
et_en Dev loss: 0.4828 r:0.6389
si_en Dev loss: 0.9811 r:0.5325
ne_en Dev loss: 0.5431 r:0.7165
ru_en Dev loss: 0.5817 r:0.6771
Current avg r:0.5728 Best avg r: 0.6177
08:08:28,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:46,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:11:16,829 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1663
en_de Dev loss: 0.9538 r:0.1882
en_zh Dev loss: 0.8439 r:0.4655
ro_en Dev loss: 0.3864 r:0.8148
et_en Dev loss: 0.5371 r:0.6481
si_en Dev loss: 0.9585 r:0.5417
ne_en Dev loss: 0.5732 r:0.7205
ru_en Dev loss: 0.6223 r:0.6776
Current avg r:0.5795 Best avg r: 0.6177
08:15:08,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:16:26,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:17:58,275 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1604
en_de Dev loss: 0.9249 r:0.1914
en_zh Dev loss: 0.8406 r:0.4600
ro_en Dev loss: 0.3792 r:0.8149
et_en Dev loss: 0.4914 r:0.6399
si_en Dev loss: 0.9666 r:0.5329
ne_en Dev loss: 0.6278 r:0.7181
ru_en Dev loss: 0.6375 r:0.6736
Current avg r:0.5758 Best avg r: 0.6177
08:21:54,286 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:23:13,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:24:44,819 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1743
en_de Dev loss: 0.9001 r:0.1918
en_zh Dev loss: 0.8031 r:0.4611
ro_en Dev loss: 0.3906 r:0.8103
et_en Dev loss: 0.4811 r:0.6426
si_en Dev loss: 0.9654 r:0.5289
ne_en Dev loss: 0.6466 r:0.7169
ru_en Dev loss: 0.6414 r:0.6587
Current avg r:0.5729 Best avg r: 0.6177
08:28:40,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:29:59,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:31:31,580 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1672
en_de Dev loss: 0.9225 r:0.1838
en_zh Dev loss: 0.8282 r:0.4530
ro_en Dev loss: 0.4080 r:0.8106
et_en Dev loss: 0.5202 r:0.6364
si_en Dev loss: 0.9914 r:0.5296
ne_en Dev loss: 0.5250 r:0.7156
ru_en Dev loss: 0.6461 r:0.6636
Current avg r:0.5704 Best avg r: 0.6177
08:35:27,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:46,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:38:17,885 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1671
en_de Dev loss: 0.9129 r:0.1785
en_zh Dev loss: 0.8492 r:0.4479
ro_en Dev loss: 0.3894 r:0.8106
et_en Dev loss: 0.5180 r:0.6247
si_en Dev loss: 1.0094 r:0.5227
ne_en Dev loss: 0.6158 r:0.7151
ru_en Dev loss: 0.6869 r:0.6492
Current avg r:0.5641 Best avg r: 0.6177
08:42:14,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:43:32,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:45:02,740 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1612
en_de Dev loss: 0.9232 r:0.1929
en_zh Dev loss: 0.8399 r:0.4556
ro_en Dev loss: 0.3809 r:0.8128
et_en Dev loss: 0.5056 r:0.6498
si_en Dev loss: 0.9303 r:0.5298
ne_en Dev loss: 0.5562 r:0.7191
ru_en Dev loss: 0.6708 r:0.6593
Current avg r:0.5742 Best avg r: 0.6177
08:48:54,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:50:12,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:51:42,779 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1689
en_de Dev loss: 0.9195 r:0.1844
en_zh Dev loss: 0.8048 r:0.4614
ro_en Dev loss: 0.3592 r:0.8121
et_en Dev loss: 0.4857 r:0.6448
si_en Dev loss: 0.9522 r:0.5252
ne_en Dev loss: 0.5288 r:0.7160
ru_en Dev loss: 0.6251 r:0.6609
Current avg r:0.5721 Best avg r: 0.6177
08:55:34,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:56:52,490 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:58:23,110 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1755
en_de Dev loss: 0.9311 r:0.1648
en_zh Dev loss: 0.7825 r:0.4647
ro_en Dev loss: 0.3493 r:0.8165
et_en Dev loss: 0.4710 r:0.6502
si_en Dev loss: 0.8776 r:0.5338
ne_en Dev loss: 0.4749 r:0.7179
ru_en Dev loss: 0.6169 r:0.6497
Current avg r:0.5711 Best avg r: 0.6177
09:02:14,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:03:32,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:05:03,303 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1647
en_de Dev loss: 0.9259 r:0.1727
en_zh Dev loss: 0.8005 r:0.4671
ro_en Dev loss: 0.3591 r:0.8115
et_en Dev loss: 0.4781 r:0.6495
si_en Dev loss: 0.9259 r:0.5291
ne_en Dev loss: 0.5544 r:0.7142
ru_en Dev loss: 0.6236 r:0.6570
Current avg r:0.5716 Best avg r: 0.6177
09:08:56,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:10:14,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:44,970 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1420
en_de Dev loss: 0.9421 r:0.1617
en_zh Dev loss: 0.8732 r:0.4540
ro_en Dev loss: 0.3852 r:0.8101
et_en Dev loss: 0.5168 r:0.6363
si_en Dev loss: 1.0370 r:0.5219
ne_en Dev loss: 0.6190 r:0.7200
ru_en Dev loss: 0.6673 r:0.6565
Current avg r:0.5658 Best avg r: 0.6177
09:15:36,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:16:54,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:18:25,373 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1451
en_de Dev loss: 0.9527 r:0.1688
en_zh Dev loss: 0.8259 r:0.4565
ro_en Dev loss: 0.3540 r:0.8123
et_en Dev loss: 0.5049 r:0.6471
si_en Dev loss: 0.8749 r:0.5335
ne_en Dev loss: 0.5337 r:0.7156
ru_en Dev loss: 0.6018 r:0.6701
Current avg r:0.5720 Best avg r: 0.6177
09:22:17,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:23:34,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:25:05,448 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1500
en_de Dev loss: 0.9364 r:0.1562
en_zh Dev loss: 0.8164 r:0.4585
ro_en Dev loss: 0.3693 r:0.8095
et_en Dev loss: 0.5030 r:0.6410
si_en Dev loss: 0.9553 r:0.5279
ne_en Dev loss: 0.5716 r:0.7131
ru_en Dev loss: 0.6347 r:0.6580
Current avg r:0.5663 Best avg r: 0.6177
09:28:57,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:14,830 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:31:45,405 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1520
en_de Dev loss: 0.9537 r:0.1534
en_zh Dev loss: 0.8987 r:0.4527
ro_en Dev loss: 0.3646 r:0.8134
et_en Dev loss: 0.5072 r:0.6409
si_en Dev loss: 0.9143 r:0.5282
ne_en Dev loss: 0.5683 r:0.7144
ru_en Dev loss: 0.6642 r:0.6505
Current avg r:0.5648 Best avg r: 0.6177
09:35:37,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:36:55,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:38:25,664 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1504
en_de Dev loss: 0.9303 r:0.1530
en_zh Dev loss: 0.8561 r:0.4634
ro_en Dev loss: 0.3947 r:0.8075
et_en Dev loss: 0.5005 r:0.6336
si_en Dev loss: 1.0239 r:0.5208
ne_en Dev loss: 0.6721 r:0.7064
ru_en Dev loss: 0.6890 r:0.6527
Current avg r:0.5625 Best avg r: 0.6177
09:42:17,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:35,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:45:06,103 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1437
en_de Dev loss: 0.9212 r:0.1734
en_zh Dev loss: 0.8088 r:0.4689
ro_en Dev loss: 0.3919 r:0.8099
et_en Dev loss: 0.5045 r:0.6395
si_en Dev loss: 0.9818 r:0.5240
ne_en Dev loss: 0.6240 r:0.7099
ru_en Dev loss: 0.6262 r:0.6667
Current avg r:0.5703 Best avg r: 0.6177
09:48:58,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:50:15,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:46,391 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1570
en_de Dev loss: 0.9394 r:0.1788
en_zh Dev loss: 0.8328 r:0.4678
ro_en Dev loss: 0.3734 r:0.8153
et_en Dev loss: 0.5187 r:0.6434
si_en Dev loss: 0.8915 r:0.5355
ne_en Dev loss: 0.5530 r:0.7102
ru_en Dev loss: 0.6049 r:0.6743
Current avg r:0.5750 Best avg r: 0.6177
09:55:37,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:55,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:26,228 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1482
en_de Dev loss: 0.9360 r:0.1818
en_zh Dev loss: 0.8717 r:0.4552
ro_en Dev loss: 0.3974 r:0.8099
et_en Dev loss: 0.4980 r:0.6363
si_en Dev loss: 0.9485 r:0.5297
ne_en Dev loss: 0.6258 r:0.7108
ru_en Dev loss: 0.6791 r:0.6564
Current avg r:0.5686 Best avg r: 0.6177
10:02:18,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:03:35,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:06,287 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1466
en_de Dev loss: 0.9189 r:0.1959
en_zh Dev loss: 0.8364 r:0.4653
ro_en Dev loss: 0.3801 r:0.8160
et_en Dev loss: 0.5124 r:0.6452
si_en Dev loss: 0.9392 r:0.5356
ne_en Dev loss: 0.5792 r:0.7154
ru_en Dev loss: 0.6033 r:0.6803
Current avg r:0.5791 Best avg r: 0.6177
10:08:58,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:15,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:46,342 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1425
en_de Dev loss: 0.9188 r:0.1960
en_zh Dev loss: 0.7850 r:0.4725
ro_en Dev loss: 0.3682 r:0.8126
et_en Dev loss: 0.5064 r:0.6499
si_en Dev loss: 0.9228 r:0.5405
ne_en Dev loss: 0.5454 r:0.7199
ru_en Dev loss: 0.6053 r:0.6740
Current avg r:0.5807 Best avg r: 0.6177
10:15:37,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:55,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:18:26,169 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1411
en_de Dev loss: 0.9463 r:0.1866
en_zh Dev loss: 0.7957 r:0.4652
ro_en Dev loss: 0.3773 r:0.8116
et_en Dev loss: 0.5097 r:0.6408
si_en Dev loss: 0.8933 r:0.5341
ne_en Dev loss: 0.5998 r:0.7070
ru_en Dev loss: 0.6162 r:0.6671
Current avg r:0.5732 Best avg r: 0.6177
10:22:17,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:23:35,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:25:05,953 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1542
en_de Dev loss: 0.9285 r:0.1938
en_zh Dev loss: 0.8407 r:0.4668
ro_en Dev loss: 0.3768 r:0.8106
et_en Dev loss: 0.4921 r:0.6398
si_en Dev loss: 0.9468 r:0.5337
ne_en Dev loss: 0.5877 r:0.7159
ru_en Dev loss: 0.6423 r:0.6663
Current avg r:0.5753 Best avg r: 0.6177
10:28:57,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:30:15,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:31:46,225 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1400
en_de Dev loss: 0.9795 r:0.1811
en_zh Dev loss: 0.9067 r:0.4617
ro_en Dev loss: 0.4214 r:0.8063
et_en Dev loss: 0.5331 r:0.6314
si_en Dev loss: 1.0368 r:0.5293
ne_en Dev loss: 0.6030 r:0.7198
ru_en Dev loss: 0.6948 r:0.6658
Current avg r:0.5708 Best avg r: 0.6177
