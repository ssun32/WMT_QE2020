14:49:28,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:41,802 root INFO 
id:en_de cur r: 0.0613 best r: 0.0613
14:49:54,740 root INFO 
id:en_zh cur r: 0.2772 best r: 0.2772
14:50:07,696 root INFO 
id:ro_en cur r: 0.6378 best r: 0.6378
14:50:20,698 root INFO 
id:et_en cur r: 0.5494 best r: 0.5494
14:50:33,728 root INFO 
id:si_en cur r: 0.4205 best r: 0.4205
14:50:46,756 root INFO 
id:ne_en cur r: 0.5811 best r: 0.5811
14:50:46,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:17,699 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
14:52:17,705 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:52:17,710 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:52:17,715 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
14:52:17,719 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
14:52:17,724 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:52:17,729 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:52:30,667 root INFO Epoch 0 Global steps: 600 Train loss: 0.8582
en_de Dev loss: 0.8933 r:0.0867
en_zh Dev loss: 0.7647 r:0.2649
ro_en Dev loss: 0.6436 r:0.6071
et_en Dev loss: 0.5974 r:0.5299
si_en Dev loss: 0.7560 r:0.4310
ne_en Dev loss: 0.6424 r:0.5533
ru_en Dev loss: 0.6811 r:0.4962
Current avg r:0.4242 Best avg r: 0.4242
14:56:24,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:41,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:12,411 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7928
en_de Dev loss: 0.9011 r:0.0509
en_zh Dev loss: 0.7889 r:0.2077
ro_en Dev loss: 0.7266 r:0.4943
et_en Dev loss: 0.6571 r:0.3548
si_en Dev loss: 0.7713 r:0.3438
ne_en Dev loss: 0.6910 r:0.4582
ru_en Dev loss: 0.7526 r:0.3671
Current avg r:0.3253 Best avg r: 0.4242
15:03:05,214 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:18,154 root INFO 
id:en_de cur r: 0.0658 best r: 0.0658
15:03:44,16 root INFO 
id:ro_en cur r: 0.6429 best r: 0.6429
15:03:56,986 root INFO 
id:et_en cur r: 0.5728 best r: 0.5728
15:04:22,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:53,488 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:05:53,495 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:05:53,500 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:05:53,505 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:05:53,509 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:05:53,514 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:05:53,520 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:06:06,404 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7679
en_de Dev loss: 0.9364 r:0.0911
en_zh Dev loss: 0.7937 r:0.2458
ro_en Dev loss: 0.5839 r:0.6283
et_en Dev loss: 0.5356 r:0.5499
si_en Dev loss: 0.7278 r:0.4493
ne_en Dev loss: 0.6117 r:0.5408
ru_en Dev loss: 0.6136 r:0.5834
Current avg r:0.4412 Best avg r: 0.4412
15:09:59,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:12,25 root INFO 
id:en_de cur r: 0.0689 best r: 0.0689
15:10:24,949 root INFO 
id:en_zh cur r: 0.2794 best r: 0.2794
15:10:37,906 root INFO 
id:ro_en cur r: 0.6868 best r: 0.6868
15:10:50,874 root INFO 
id:et_en cur r: 0.6280 best r: 0.6280
15:11:03,860 root INFO 
id:si_en cur r: 0.4437 best r: 0.4437
15:11:16,826 root INFO 
id:ne_en cur r: 0.6417 best r: 0.6417
15:11:16,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:47,328 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:12:47,335 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:12:47,341 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:12:47,346 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:12:47,351 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:12:47,355 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:12:47,360 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:13:00,229 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7973
en_de Dev loss: 0.9800 r:0.0950
en_zh Dev loss: 0.8112 r:0.2849
ro_en Dev loss: 0.5496 r:0.6728
et_en Dev loss: 0.4823 r:0.6021
si_en Dev loss: 0.7707 r:0.4771
ne_en Dev loss: 0.5882 r:0.5807
ru_en Dev loss: 0.5741 r:0.6421
Current avg r:0.4792 Best avg r: 0.4792
15:16:52,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:18,737 root INFO 
id:en_zh cur r: 0.2841 best r: 0.2841
15:17:31,687 root INFO 
id:ro_en cur r: 0.6883 best r: 0.6883
15:18:10,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:41,54 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:19:41,60 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:19:41,65 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:19:41,70 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:19:41,75 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:19:41,80 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:19:41,85 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:19:53,951 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6591
en_de Dev loss: 0.9791 r:0.1268
en_zh Dev loss: 0.8293 r:0.2893
ro_en Dev loss: 0.5431 r:0.6813
et_en Dev loss: 0.4676 r:0.6100
si_en Dev loss: 0.7145 r:0.4822
ne_en Dev loss: 0.5424 r:0.6038
ru_en Dev loss: 0.5669 r:0.6500
Current avg r:0.4919 Best avg r: 0.4919
15:23:46,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:59,375 root INFO 
id:en_de cur r: 0.1064 best r: 0.1064
15:24:12,299 root INFO 
id:en_zh cur r: 0.3166 best r: 0.3166
15:24:25,264 root INFO 
id:ro_en cur r: 0.6922 best r: 0.6922
15:24:51,207 root INFO 
id:si_en cur r: 0.4539 best r: 0.4539
15:25:04,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:34,703 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:26:34,709 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:26:34,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:26:34,718 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:26:34,723 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:26:34,731 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:26:34,735 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:26:47,586 root INFO Epoch 0 Global steps: 3600 Train loss: 0.7003
en_de Dev loss: 0.9695 r:0.1280
en_zh Dev loss: 0.7744 r:0.3249
ro_en Dev loss: 0.4921 r:0.6890
et_en Dev loss: 0.4358 r:0.6300
si_en Dev loss: 0.7132 r:0.4815
ne_en Dev loss: 0.4989 r:0.6257
ru_en Dev loss: 0.5127 r:0.6584
Current avg r:0.5054 Best avg r: 0.5054
15:30:40,6 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:52,951 root INFO 
id:en_de cur r: 0.1281 best r: 0.1281
15:31:05,867 root INFO 
id:en_zh cur r: 0.3595 best r: 0.3595
15:31:18,821 root INFO 
id:ro_en cur r: 0.7006 best r: 0.7006
15:31:31,798 root INFO 
id:et_en cur r: 0.6448 best r: 0.6448
15:31:44,778 root INFO 
id:si_en cur r: 0.4681 best r: 0.4681
15:31:57,754 root INFO 
id:ne_en cur r: 0.6584 best r: 0.6584
15:31:57,754 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:28,279 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:33:28,285 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:33:28,289 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:33:28,294 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:33:28,300 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:33:28,305 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:33:28,310 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:33:41,168 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6743
en_de Dev loss: 0.9818 r:0.1454
en_zh Dev loss: 0.7809 r:0.3584
ro_en Dev loss: 0.5160 r:0.7000
et_en Dev loss: 0.4311 r:0.6456
si_en Dev loss: 0.7565 r:0.4984
ne_en Dev loss: 0.5513 r:0.6190
ru_en Dev loss: 0.5330 r:0.6807
Current avg r:0.5211 Best avg r: 0.5211
15:37:33,549 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:59,408 root INFO 
id:en_zh cur r: 0.3822 best r: 0.3822
15:38:12,354 root INFO 
id:ro_en cur r: 0.7270 best r: 0.7270
15:38:25,311 root INFO 
id:et_en cur r: 0.6613 best r: 0.6613
15:38:38,293 root INFO 
id:si_en cur r: 0.4968 best r: 0.4968
15:38:51,267 root INFO 
id:ne_en cur r: 0.6933 best r: 0.6933
15:38:51,267 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:21,810 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:40:21,817 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:40:21,822 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:40:21,826 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:40:21,831 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:40:21,836 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:40:21,842 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:40:34,726 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6556
en_de Dev loss: 0.9176 r:0.1519
en_zh Dev loss: 0.7134 r:0.3935
ro_en Dev loss: 0.4153 r:0.7246
et_en Dev loss: 0.3991 r:0.6673
si_en Dev loss: 0.6217 r:0.5258
ne_en Dev loss: 0.4377 r:0.6805
ru_en Dev loss: 0.4768 r:0.6759
Current avg r:0.5456 Best avg r: 0.5456
15:44:27,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:40,414 root INFO 
id:en_de cur r: 0.1549 best r: 0.1549
15:45:45,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:15,715 root INFO Epoch 0 Global steps: 5400 Train loss: 0.6832
en_de Dev loss: 0.9173 r:0.1787
en_zh Dev loss: 0.7252 r:0.4033
ro_en Dev loss: 0.4367 r:0.7277
et_en Dev loss: 0.3998 r:0.6601
si_en Dev loss: 0.7244 r:0.5032
ne_en Dev loss: 0.4988 r:0.6371
ru_en Dev loss: 0.4798 r:0.6925
Current avg r:0.5432 Best avg r: 0.5456
15:51:08,553 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:47,376 root INFO 
id:ro_en cur r: 0.7451 best r: 0.7451
15:52:00,332 root INFO 
id:et_en cur r: 0.6662 best r: 0.6662
15:52:26,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:56,856 root INFO Epoch 0 Global steps: 6000 Train loss: 0.6460
en_de Dev loss: 0.9493 r:0.1716
en_zh Dev loss: 0.8192 r:0.4048
ro_en Dev loss: 0.4770 r:0.7404
et_en Dev loss: 0.4158 r:0.6613
si_en Dev loss: 0.8754 r:0.5024
ne_en Dev loss: 0.5732 r:0.6376
ru_en Dev loss: 0.5063 r:0.6968
Current avg r:0.5450 Best avg r: 0.5456
15:57:49,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:15,227 root INFO 
id:en_zh cur r: 0.3928 best r: 0.3928
15:58:41,132 root INFO 
id:et_en cur r: 0.6681 best r: 0.6681
15:59:07,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:37,602 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:00:37,608 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:00:37,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:00:37,617 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:00:37,622 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:00:37,626 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:00:37,631 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:00:50,498 root INFO Epoch 0 Global steps: 6600 Train loss: 0.6415
en_de Dev loss: 0.9810 r:0.1561
en_zh Dev loss: 0.7828 r:0.4149
ro_en Dev loss: 0.4910 r:0.7418
et_en Dev loss: 0.4375 r:0.6690
si_en Dev loss: 0.8839 r:0.5077
ne_en Dev loss: 0.5839 r:0.6412
ru_en Dev loss: 0.5606 r:0.6944
Current avg r:0.5465 Best avg r: 0.5465
16:04:43,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:56,172 root INFO 
id:en_de cur r: 0.1613 best r: 0.1613
16:05:09,103 root INFO 
id:en_zh cur r: 0.4068 best r: 0.4068
16:05:22,54 root INFO 
id:ro_en cur r: 0.7569 best r: 0.7569
16:05:47,972 root INFO 
id:si_en cur r: 0.5060 best r: 0.5060
16:06:00,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:31,393 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:07:31,400 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:07:31,404 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:07:31,410 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:07:31,415 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:07:31,420 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:07:31,426 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:07:44,285 root INFO Epoch 0 Global steps: 7200 Train loss: 0.6095
en_de Dev loss: 0.9489 r:0.1855
en_zh Dev loss: 0.8302 r:0.4259
ro_en Dev loss: 0.4235 r:0.7550
et_en Dev loss: 0.4177 r:0.6704
si_en Dev loss: 0.8372 r:0.5116
ne_en Dev loss: 0.5384 r:0.6480
ru_en Dev loss: 0.5327 r:0.7043
Current avg r:0.5572 Best avg r: 0.5572
16:11:36,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:49,608 root INFO 
id:en_de cur r: 0.1766 best r: 0.1766
16:12:02,534 root INFO 
id:en_zh cur r: 0.4103 best r: 0.4103
16:12:15,491 root INFO 
id:ro_en cur r: 0.7610 best r: 0.7610
16:12:28,460 root INFO 
id:et_en cur r: 0.6696 best r: 0.6696
16:12:54,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:24,914 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:14:24,921 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:14:24,926 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:14:24,930 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:14:24,936 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:14:24,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:14:24,945 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:14:37,793 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5910
en_de Dev loss: 0.8994 r:0.1917
en_zh Dev loss: 0.7352 r:0.4345
ro_en Dev loss: 0.4168 r:0.7543
et_en Dev loss: 0.3926 r:0.6778
si_en Dev loss: 0.7298 r:0.5259
ne_en Dev loss: 0.4485 r:0.6793
ru_en Dev loss: 0.4755 r:0.7206
Current avg r:0.5691 Best avg r: 0.5691
16:18:30,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:56,585 root INFO 
id:en_zh cur r: 0.4266 best r: 0.4266
16:19:09,546 root INFO 
id:ro_en cur r: 0.7758 best r: 0.7758
16:19:22,529 root INFO 
id:et_en cur r: 0.6839 best r: 0.6839
16:19:35,524 root INFO 
id:si_en cur r: 0.5276 best r: 0.5276
16:19:48,520 root INFO 
id:ne_en cur r: 0.7097 best r: 0.7097
16:19:48,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:19,196 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:21:19,201 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:21:19,207 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:21:19,211 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:21:19,215 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:21:19,220 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:21:19,224 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:21:32,131 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5910
en_de Dev loss: 0.8887 r:0.1981
en_zh Dev loss: 0.7248 r:0.4389
ro_en Dev loss: 0.3692 r:0.7724
et_en Dev loss: 0.3770 r:0.6900
si_en Dev loss: 0.6822 r:0.5444
ne_en Dev loss: 0.4180 r:0.7002
ru_en Dev loss: 0.4441 r:0.7173
Current avg r:0.5802 Best avg r: 0.5802
16:25:25,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:38,557 root INFO 
id:en_de cur r: 0.1880 best r: 0.1880
16:25:51,526 root INFO 
id:en_zh cur r: 0.4298 best r: 0.4298
16:26:04,538 root INFO 
id:ro_en cur r: 0.7870 best r: 0.7870
16:26:30,599 root INFO 
id:si_en cur r: 0.5332 best r: 0.5332
16:26:43,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:14,482 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:28:14,488 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:28:14,493 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:28:14,498 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:28:14,503 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:28:14,508 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:28:14,513 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:28:27,437 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5625
en_de Dev loss: 0.9061 r:0.2071
en_zh Dev loss: 0.7235 r:0.4481
ro_en Dev loss: 0.3722 r:0.7790
et_en Dev loss: 0.4008 r:0.6775
si_en Dev loss: 0.7005 r:0.5496
ne_en Dev loss: 0.4586 r:0.6983
ru_en Dev loss: 0.5254 r:0.7036
Current avg r:0.5804 Best avg r: 0.5804
16:32:21,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:34,799 root INFO 
id:en_de cur r: 0.1881 best r: 0.1881
16:32:47,726 root INFO 
id:en_zh cur r: 0.4305 best r: 0.4305
16:33:13,643 root INFO 
id:et_en cur r: 0.6892 best r: 0.6892
16:33:26,611 root INFO 
id:si_en cur r: 0.5415 best r: 0.5415
16:33:39,588 root INFO 
id:ne_en cur r: 0.7161 best r: 0.7161
16:33:39,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:10,137 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:35:10,145 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:35:10,150 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:35:10,155 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:35:10,162 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:35:10,167 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:35:10,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:35:23,41 root INFO Epoch 1 Global steps: 9600 Train loss: 0.6072
en_de Dev loss: 0.8787 r:0.2094
en_zh Dev loss: 0.7421 r:0.4461
ro_en Dev loss: 0.3821 r:0.7830
et_en Dev loss: 0.3799 r:0.6893
si_en Dev loss: 0.6839 r:0.5546
ne_en Dev loss: 0.4340 r:0.7067
ru_en Dev loss: 0.4502 r:0.7163
Current avg r:0.5865 Best avg r: 0.5865
16:39:15,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:41,628 root INFO 
id:en_zh cur r: 0.4324 best r: 0.4324
16:39:54,582 root INFO 
id:ro_en cur r: 0.7880 best r: 0.7880
16:40:33,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:03,950 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5652
en_de Dev loss: 0.9055 r:0.2094
en_zh Dev loss: 0.7665 r:0.4444
ro_en Dev loss: 0.3954 r:0.7780
et_en Dev loss: 0.3916 r:0.6875
si_en Dev loss: 0.7391 r:0.5469
ne_en Dev loss: 0.4262 r:0.7065
ru_en Dev loss: 0.5156 r:0.7126
Current avg r:0.5836 Best avg r: 0.5865
16:45:56,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:09,422 root INFO 
id:en_de cur r: 0.1945 best r: 0.1945
16:46:22,344 root INFO 
id:en_zh cur r: 0.4413 best r: 0.4413
16:47:14,152 root INFO 
id:ne_en cur r: 0.7188 best r: 0.7188
16:47:14,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:44,657 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:48:44,665 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:48:44,670 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:48:44,675 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:48:44,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:48:44,685 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:48:44,689 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:48:57,562 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5706
en_de Dev loss: 0.9078 r:0.2113
en_zh Dev loss: 0.7395 r:0.4522
ro_en Dev loss: 0.3846 r:0.7796
et_en Dev loss: 0.3898 r:0.6874
si_en Dev loss: 0.6803 r:0.5576
ne_en Dev loss: 0.4314 r:0.7124
ru_en Dev loss: 0.5238 r:0.7096
Current avg r:0.5872 Best avg r: 0.5872
16:52:50,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:03,117 root INFO 
id:en_de cur r: 0.2107 best r: 0.2107
16:53:16,24 root INFO 
id:en_zh cur r: 0.4508 best r: 0.4508
16:53:28,962 root INFO 
id:ro_en cur r: 0.7986 best r: 0.7986
16:53:54,898 root INFO 
id:si_en cur r: 0.5638 best r: 0.5638
16:54:07,864 root INFO 
id:ne_en cur r: 0.7221 best r: 0.7221
16:54:07,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:38,407 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:55:38,413 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:55:38,417 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:55:38,422 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:55:38,426 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:55:38,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:55:38,435 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:55:51,307 root INFO Epoch 1 Global steps: 11400 Train loss: 0.5523
en_de Dev loss: 0.8574 r:0.2071
en_zh Dev loss: 0.6850 r:0.4600
ro_en Dev loss: 0.3399 r:0.7974
et_en Dev loss: 0.3648 r:0.6953
si_en Dev loss: 0.6329 r:0.5786
ne_en Dev loss: 0.4410 r:0.7136
ru_en Dev loss: 0.4960 r:0.7024
Current avg r:0.5935 Best avg r: 0.5935
16:59:43,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:00,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:31,260 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5582
en_de Dev loss: 0.9444 r:0.2040
en_zh Dev loss: 0.8551 r:0.4476
ro_en Dev loss: 0.4754 r:0.7880
et_en Dev loss: 0.4307 r:0.6861
si_en Dev loss: 0.9150 r:0.5531
ne_en Dev loss: 0.5198 r:0.7054
ru_en Dev loss: 0.6346 r:0.7001
Current avg r:0.5835 Best avg r: 0.5935
17:06:23,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:02,50 root INFO 
id:ro_en cur r: 0.8003 best r: 0.8003
17:07:14,997 root INFO 
id:et_en cur r: 0.6965 best r: 0.6965
17:07:27,947 root INFO 
id:si_en cur r: 0.5735 best r: 0.5735
17:07:40,902 root INFO 
id:ne_en cur r: 0.7301 best r: 0.7301
17:07:40,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:11,339 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:09:11,345 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:09:11,351 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:09:11,357 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:09:11,364 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:09:11,369 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:09:11,373 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:09:24,217 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5513
en_de Dev loss: 0.9054 r:0.2055
en_zh Dev loss: 0.7885 r:0.4545
ro_en Dev loss: 0.3845 r:0.7938
et_en Dev loss: 0.3764 r:0.7000
si_en Dev loss: 0.7338 r:0.5782
ne_en Dev loss: 0.4810 r:0.7203
ru_en Dev loss: 0.5329 r:0.7219
Current avg r:0.5963 Best avg r: 0.5963
17:13:16,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:33,918 root INFO 
id:ne_en cur r: 0.7336 best r: 0.7336
17:14:33,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:04,332 root INFO Epoch 1 Global steps: 13200 Train loss: 0.5825
en_de Dev loss: 0.9174 r:0.2148
en_zh Dev loss: 0.8392 r:0.4574
ro_en Dev loss: 0.4215 r:0.7950
et_en Dev loss: 0.4111 r:0.6915
si_en Dev loss: 0.8441 r:0.5676
ne_en Dev loss: 0.5210 r:0.7211
ru_en Dev loss: 0.5921 r:0.7030
Current avg r:0.5929 Best avg r: 0.5963
17:19:56,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:22,162 root INFO 
id:en_zh cur r: 0.4555 best r: 0.4555
17:20:35,101 root INFO 
id:ro_en cur r: 0.8029 best r: 0.8029
17:20:48,57 root INFO 
id:et_en cur r: 0.6972 best r: 0.6972
17:21:01,15 root INFO 
id:si_en cur r: 0.5781 best r: 0.5781
17:21:13,971 root INFO 
id:ne_en cur r: 0.7416 best r: 0.7416
17:21:13,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:44,413 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:22:44,419 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:22:44,424 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:22:44,429 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:22:44,433 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:22:44,439 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:22:44,444 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:22:57,284 root INFO Epoch 1 Global steps: 13800 Train loss: 0.5320
en_de Dev loss: 0.8967 r:0.2152
en_zh Dev loss: 0.7175 r:0.4572
ro_en Dev loss: 0.3742 r:0.7960
et_en Dev loss: 0.3812 r:0.7003
si_en Dev loss: 0.7691 r:0.5756
ne_en Dev loss: 0.3796 r:0.7328
ru_en Dev loss: 0.4953 r:0.7228
Current avg r:0.6000 Best avg r: 0.6000
17:26:49,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:02,464 root INFO 
id:en_de cur r: 0.2200 best r: 0.2200
17:27:28,282 root INFO 
id:ro_en cur r: 0.8065 best r: 0.8065
17:28:07,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:37,573 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:29:37,579 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:29:37,584 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:29:37,590 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:29:37,596 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:29:37,601 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:29:37,607 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:29:50,442 root INFO Epoch 1 Global steps: 14400 Train loss: 0.5401
en_de Dev loss: 0.8546 r:0.2210
en_zh Dev loss: 0.7054 r:0.4642
ro_en Dev loss: 0.3420 r:0.8032
et_en Dev loss: 0.3726 r:0.6964
si_en Dev loss: 0.7339 r:0.5813
ne_en Dev loss: 0.4020 r:0.7400
ru_en Dev loss: 0.4858 r:0.7148
Current avg r:0.6030 Best avg r: 0.6030
17:33:42,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:08,22 root INFO 
id:en_zh cur r: 0.4715 best r: 0.4715
17:34:20,957 root INFO 
id:ro_en cur r: 0.8085 best r: 0.8085
17:34:59,793 root INFO 
id:ne_en cur r: 0.7456 best r: 0.7456
17:34:59,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:30,241 root INFO Epoch 1 Global steps: 15000 Train loss: 0.5608
en_de Dev loss: 0.8751 r:0.2115
en_zh Dev loss: 0.7496 r:0.4677
ro_en Dev loss: 0.3699 r:0.8065
et_en Dev loss: 0.3963 r:0.6856
si_en Dev loss: 0.8325 r:0.5721
ne_en Dev loss: 0.4650 r:0.7314
ru_en Dev loss: 0.5149 r:0.7028
Current avg r:0.5968 Best avg r: 0.6030
17:40:22,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:48,317 root INFO 
id:en_zh cur r: 0.4928 best r: 0.4928
17:41:01,259 root INFO 
id:ro_en cur r: 0.8120 best r: 0.8120
17:41:27,157 root INFO 
id:si_en cur r: 0.5977 best r: 0.5977
17:41:40,115 root INFO 
id:ne_en cur r: 0.7528 best r: 0.7528
17:41:40,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:10,545 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:43:10,552 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:43:10,557 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:43:10,562 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:43:10,566 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:43:10,570 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:43:10,575 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:43:23,421 root INFO Epoch 1 Global steps: 15600 Train loss: 0.5492
en_de Dev loss: 0.8542 r:0.2042
en_zh Dev loss: 0.6434 r:0.4907
ro_en Dev loss: 0.3170 r:0.8100
et_en Dev loss: 0.3778 r:0.7007
si_en Dev loss: 0.6038 r:0.6020
ne_en Dev loss: 0.3794 r:0.7484
ru_en Dev loss: 0.4371 r:0.7062
Current avg r:0.6089 Best avg r: 0.6089
17:47:15,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:28,401 root INFO 
id:en_de cur r: 0.2255 best r: 0.2255
17:48:33,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:03,604 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4921
en_de Dev loss: 0.8674 r:0.2392
en_zh Dev loss: 0.7969 r:0.4499
ro_en Dev loss: 0.3948 r:0.8058
et_en Dev loss: 0.4000 r:0.6946
si_en Dev loss: 0.7560 r:0.5827
ne_en Dev loss: 0.4368 r:0.7444
ru_en Dev loss: 0.6263 r:0.6966
Current avg r:0.6019 Best avg r: 0.6089
17:53:55,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:13,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:43,430 root INFO Epoch 1 Global steps: 16800 Train loss: 0.5102
en_de Dev loss: 0.8516 r:0.2306
en_zh Dev loss: 0.6976 r:0.4576
ro_en Dev loss: 0.3464 r:0.8060
et_en Dev loss: 0.3839 r:0.6953
si_en Dev loss: 0.7871 r:0.5713
ne_en Dev loss: 0.4518 r:0.7366
ru_en Dev loss: 0.5222 r:0.6856
Current avg r:0.5976 Best avg r: 0.6089
18:00:35,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:48,436 root INFO 
id:en_de cur r: 0.2297 best r: 0.2297
18:01:14,283 root INFO 
id:ro_en cur r: 0.8142 best r: 0.8142
18:01:53,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:23,591 root INFO Epoch 1 Global steps: 17400 Train loss: 0.5243
en_de Dev loss: 0.8760 r:0.2421
en_zh Dev loss: 0.7303 r:0.4597
ro_en Dev loss: 0.3464 r:0.8114
et_en Dev loss: 0.3844 r:0.6958
si_en Dev loss: 0.7268 r:0.5850
ne_en Dev loss: 0.4134 r:0.7468
ru_en Dev loss: 0.5167 r:0.7016
Current avg r:0.6061 Best avg r: 0.6089
18:07:16,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:33,643 root INFO 
id:ne_en cur r: 0.7553 best r: 0.7553
18:08:33,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:04,68 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
18:10:04,73 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:10:04,78 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:10:04,82 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
18:10:04,87 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
18:10:04,92 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:10:04,97 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:10:16,955 root INFO Epoch 1 Global steps: 18000 Train loss: 0.5017
en_de Dev loss: 0.8769 r:0.2472
en_zh Dev loss: 0.7205 r:0.4675
ro_en Dev loss: 0.3541 r:0.8133
et_en Dev loss: 0.3774 r:0.7010
si_en Dev loss: 0.7839 r:0.5902
ne_en Dev loss: 0.4533 r:0.7554
ru_en Dev loss: 0.5138 r:0.7270
Current avg r:0.6145 Best avg r: 0.6145
18:14:10,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:23,779 root INFO 
id:en_de cur r: 0.2418 best r: 0.2418
18:15:28,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:58,803 root INFO Epoch 2 Global steps: 18600 Train loss: 0.5085
en_de Dev loss: 0.8901 r:0.2433
en_zh Dev loss: 0.8162 r:0.4634
ro_en Dev loss: 0.3918 r:0.8030
et_en Dev loss: 0.4070 r:0.6901
si_en Dev loss: 0.8227 r:0.5730
ne_en Dev loss: 0.4730 r:0.7419
ru_en Dev loss: 0.5719 r:0.7117
Current avg r:0.6038 Best avg r: 0.6145
18:20:50,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:55,288 root INFO 
id:si_en cur r: 0.5992 best r: 0.5992
18:22:08,239 root INFO 
id:ne_en cur r: 0.7581 best r: 0.7581
18:22:08,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:38,646 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
18:23:38,653 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:23:38,658 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:23:38,663 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
18:23:38,668 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
18:23:38,673 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:23:38,678 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:23:51,523 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4895
en_de Dev loss: 0.8672 r:0.2516
en_zh Dev loss: 0.7576 r:0.4689
ro_en Dev loss: 0.3631 r:0.8119
et_en Dev loss: 0.3965 r:0.6973
si_en Dev loss: 0.6907 r:0.5910
ne_en Dev loss: 0.3609 r:0.7580
ru_en Dev loss: 0.4756 r:0.7265
Current avg r:0.6150 Best avg r: 0.6150
18:27:43,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:22,570 root INFO 
id:ro_en cur r: 0.8146 best r: 0.8146
18:29:01,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:31,832 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4605
en_de Dev loss: 0.9150 r:0.2460
en_zh Dev loss: 0.8872 r:0.4480
ro_en Dev loss: 0.3809 r:0.8118
et_en Dev loss: 0.3979 r:0.6936
si_en Dev loss: 0.7699 r:0.5833
ne_en Dev loss: 0.4453 r:0.7504
ru_en Dev loss: 0.6307 r:0.6965
Current avg r:0.6042 Best avg r: 0.6150
18:34:23,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:02,471 root INFO 
id:ro_en cur r: 0.8169 best r: 0.8169
18:35:41,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:11,740 root INFO Epoch 2 Global steps: 20400 Train loss: 0.5320
en_de Dev loss: 0.8622 r:0.2395
en_zh Dev loss: 0.7479 r:0.4806
ro_en Dev loss: 0.3644 r:0.8134
et_en Dev loss: 0.4199 r:0.6897
si_en Dev loss: 0.7231 r:0.5885
ne_en Dev loss: 0.4302 r:0.7445
ru_en Dev loss: 0.5558 r:0.7080
Current avg r:0.6092 Best avg r: 0.6150
18:41:03,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:16,578 root INFO 
id:en_de cur r: 0.2696 best r: 0.2696
18:42:21,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:51,701 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4868
en_de Dev loss: 0.8494 r:0.2597
en_zh Dev loss: 0.7379 r:0.4582
ro_en Dev loss: 0.3635 r:0.8069
et_en Dev loss: 0.3926 r:0.6941
si_en Dev loss: 0.7118 r:0.5905
ne_en Dev loss: 0.4185 r:0.7484
ru_en Dev loss: 0.5844 r:0.6892
Current avg r:0.6067 Best avg r: 0.6150
18:47:43,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:01,330 root INFO 
id:ne_en cur r: 0.7599 best r: 0.7599
18:49:01,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:31,761 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4775
en_de Dev loss: 0.8527 r:0.2568
en_zh Dev loss: 0.7183 r:0.4691
ro_en Dev loss: 0.3522 r:0.8094
et_en Dev loss: 0.3812 r:0.6929
si_en Dev loss: 0.6891 r:0.5980
ne_en Dev loss: 0.5180 r:0.7576
ru_en Dev loss: 0.5435 r:0.7024
Current avg r:0.6123 Best avg r: 0.6150
18:54:23,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:41,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:11,812 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4743
en_de Dev loss: 0.8389 r:0.2528
en_zh Dev loss: 0.6993 r:0.4832
ro_en Dev loss: 0.3393 r:0.8137
et_en Dev loss: 0.4050 r:0.6918
si_en Dev loss: 0.6976 r:0.5956
ne_en Dev loss: 0.3756 r:0.7577
ru_en Dev loss: 0.4997 r:0.7087
Current avg r:0.6148 Best avg r: 0.6150
19:01:04,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:21,752 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:52,217 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4846
en_de Dev loss: 0.8748 r:0.2597
en_zh Dev loss: 0.7460 r:0.4719
ro_en Dev loss: 0.4311 r:0.7979
et_en Dev loss: 0.4229 r:0.6789
si_en Dev loss: 0.8599 r:0.5758
ne_en Dev loss: 0.4643 r:0.7564
ru_en Dev loss: 0.6499 r:0.6796
Current avg r:0.6029 Best avg r: 0.6150
19:07:44,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:10,502 root INFO 
id:en_zh cur r: 0.4942 best r: 0.4942
19:09:02,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:32,756 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_de.lang_agnost_mlp.dev.best.scores
19:10:32,763 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/en_zh.lang_agnost_mlp.dev.best.scores
19:10:32,768 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ro_en.lang_agnost_mlp.dev.best.scores
19:10:32,774 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/et_en.lang_agnost_mlp.dev.best.scores
19:10:32,778 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/si_en.lang_agnost_mlp.dev.best.scores
19:10:32,783 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ne_en.lang_agnost_mlp.dev.best.scores
19:10:32,788 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_ruen/run2/ru_en.lang_agnost_mlp.dev.best.scores
19:10:45,664 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4687
en_de Dev loss: 0.8322 r:0.2640
en_zh Dev loss: 0.6852 r:0.4875
ro_en Dev loss: 0.3260 r:0.8137
et_en Dev loss: 0.3931 r:0.6957
si_en Dev loss: 0.6688 r:0.5974
ne_en Dev loss: 0.3620 r:0.7600
ru_en Dev loss: 0.4841 r:0.7157
Current avg r:0.6192 Best avg r: 0.6192
19:14:38,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:55,595 root INFO 
id:ne_en cur r: 0.7610 best r: 0.7610
19:15:55,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:26,27 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4416
en_de Dev loss: 0.8723 r:0.2546
en_zh Dev loss: 0.7794 r:0.4733
ro_en Dev loss: 0.3561 r:0.8172
et_en Dev loss: 0.3865 r:0.6954
si_en Dev loss: 0.7823 r:0.5981
ne_en Dev loss: 0.4960 r:0.7593
ru_en Dev loss: 0.6077 r:0.7153
Current avg r:0.6162 Best avg r: 0.6192
19:21:18,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:31,203 root INFO 
id:en_de cur r: 0.2721 best r: 0.2721
19:22:35,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:06,266 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4811
en_de Dev loss: 0.8827 r:0.2520
en_zh Dev loss: 0.8206 r:0.4522
ro_en Dev loss: 0.4034 r:0.7999
et_en Dev loss: 0.4427 r:0.6699
si_en Dev loss: 0.7951 r:0.5773
ne_en Dev loss: 0.4629 r:0.7532
ru_en Dev loss: 0.6168 r:0.6868
Current avg r:0.5987 Best avg r: 0.6192
19:27:58,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:16,204 root INFO 
id:ne_en cur r: 0.7616 best r: 0.7616
19:29:16,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:46,653 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4705
en_de Dev loss: 0.8534 r:0.2501
en_zh Dev loss: 0.7164 r:0.4704
ro_en Dev loss: 0.3499 r:0.8133
et_en Dev loss: 0.4021 r:0.6833
si_en Dev loss: 0.6875 r:0.5956
ne_en Dev loss: 0.4141 r:0.7597
ru_en Dev loss: 0.5230 r:0.7059
Current avg r:0.6112 Best avg r: 0.6192
19:34:39,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:17,825 root INFO 
id:ro_en cur r: 0.8230 best r: 0.8230
19:35:43,742 root INFO 
id:si_en cur r: 0.6069 best r: 0.6069
19:35:56,688 root INFO 
id:ne_en cur r: 0.7616 best r: 0.7616
19:35:56,688 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:27,52 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4701
en_de Dev loss: 0.8681 r:0.2490
en_zh Dev loss: 0.7816 r:0.4628
ro_en Dev loss: 0.3470 r:0.8187
et_en Dev loss: 0.4267 r:0.6873
si_en Dev loss: 0.6728 r:0.6036
ne_en Dev loss: 0.4001 r:0.7594
ru_en Dev loss: 0.5629 r:0.7094
Current avg r:0.6129 Best avg r: 0.6192
19:41:18,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:36,524 root INFO 
id:ne_en cur r: 0.7643 best r: 0.7643
19:42:36,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:06,899 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4703
en_de Dev loss: 0.8641 r:0.2289
en_zh Dev loss: 0.7881 r:0.4764
ro_en Dev loss: 0.4050 r:0.8133
et_en Dev loss: 0.4563 r:0.6746
si_en Dev loss: 0.7867 r:0.5936
ne_en Dev loss: 0.4585 r:0.7600
ru_en Dev loss: 0.6377 r:0.6924
Current avg r:0.6056 Best avg r: 0.6192
19:47:58,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:16,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:47,193 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4575
en_de Dev loss: 0.8528 r:0.2258
en_zh Dev loss: 0.7052 r:0.4814
ro_en Dev loss: 0.3643 r:0.8089
et_en Dev loss: 0.4199 r:0.6790
si_en Dev loss: 0.7294 r:0.5910
ne_en Dev loss: 0.4600 r:0.7551
ru_en Dev loss: 0.5333 r:0.6976
Current avg r:0.6056 Best avg r: 0.6192
19:54:41,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:59,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:30,54 root INFO Epoch 3 Global steps: 27600 Train loss: 0.4520
en_de Dev loss: 0.8312 r:0.2629
en_zh Dev loss: 0.7070 r:0.4857
ro_en Dev loss: 0.3543 r:0.8150
et_en Dev loss: 0.4277 r:0.6854
si_en Dev loss: 0.7272 r:0.5938
ne_en Dev loss: 0.3990 r:0.7563
ru_en Dev loss: 0.5170 r:0.7128
Current avg r:0.6160 Best avg r: 0.6192
20:01:23,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:41,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:12,172 root INFO Epoch 3 Global steps: 28200 Train loss: 0.4335
en_de Dev loss: 0.8422 r:0.2465
en_zh Dev loss: 0.7292 r:0.4586
ro_en Dev loss: 0.3432 r:0.8113
et_en Dev loss: 0.4085 r:0.6753
si_en Dev loss: 0.7780 r:0.5855
ne_en Dev loss: 0.4543 r:0.7418
ru_en Dev loss: 0.5596 r:0.6889
Current avg r:0.6011 Best avg r: 0.6192
20:08:05,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:18,510 root INFO 
id:en_de cur r: 0.2742 best r: 0.2742
20:09:23,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:54,235 root INFO Epoch 3 Global steps: 28800 Train loss: 0.4589
en_de Dev loss: 0.8567 r:0.2525
en_zh Dev loss: 0.7993 r:0.4475
ro_en Dev loss: 0.3473 r:0.8096
et_en Dev loss: 0.4147 r:0.6736
si_en Dev loss: 0.8126 r:0.5838
ne_en Dev loss: 0.5914 r:0.7473
ru_en Dev loss: 0.6467 r:0.6790
Current avg r:0.5990 Best avg r: 0.6192
20:14:47,214 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:00,187 root INFO 
id:en_de cur r: 0.2950 best r: 0.2950
20:16:05,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:35,968 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4076
en_de Dev loss: 0.8589 r:0.2744
en_zh Dev loss: 0.7673 r:0.4657
ro_en Dev loss: 0.3706 r:0.8093
et_en Dev loss: 0.4541 r:0.6675
si_en Dev loss: 0.8281 r:0.5879
ne_en Dev loss: 0.4851 r:0.7505
ru_en Dev loss: 0.6147 r:0.6887
Current avg r:0.6063 Best avg r: 0.6192
20:21:28,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:22:46,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:17,604 root INFO Epoch 3 Global steps: 30000 Train loss: 0.4313
en_de Dev loss: 0.8575 r:0.2637
en_zh Dev loss: 0.7440 r:0.4620
ro_en Dev loss: 0.3432 r:0.8154
et_en Dev loss: 0.4255 r:0.6800
si_en Dev loss: 0.6935 r:0.5989
ne_en Dev loss: 0.3935 r:0.7481
ru_en Dev loss: 0.5589 r:0.7038
Current avg r:0.6103 Best avg r: 0.6192
20:28:10,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:28,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:59,369 root INFO Epoch 3 Global steps: 30600 Train loss: 0.4346
en_de Dev loss: 0.8577 r:0.2634
en_zh Dev loss: 0.7636 r:0.4544
ro_en Dev loss: 0.3374 r:0.8128
et_en Dev loss: 0.4018 r:0.6795
si_en Dev loss: 0.8042 r:0.5889
ne_en Dev loss: 0.4017 r:0.7574
ru_en Dev loss: 0.5818 r:0.6893
Current avg r:0.6065 Best avg r: 0.6192
20:34:52,219 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:10,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:41,191 root INFO Epoch 3 Global steps: 31200 Train loss: 0.4174
en_de Dev loss: 0.8656 r:0.2717
en_zh Dev loss: 0.7488 r:0.4651
ro_en Dev loss: 0.3534 r:0.8159
et_en Dev loss: 0.4233 r:0.6795
si_en Dev loss: 0.7398 r:0.5927
ne_en Dev loss: 0.4750 r:0.7558
ru_en Dev loss: 0.5365 r:0.7059
Current avg r:0.6124 Best avg r: 0.6192
20:41:34,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:52,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:23,287 root INFO Epoch 3 Global steps: 31800 Train loss: 0.4061
en_de Dev loss: 0.8376 r:0.2545
en_zh Dev loss: 0.7108 r:0.4603
ro_en Dev loss: 0.3234 r:0.8158
et_en Dev loss: 0.4109 r:0.6768
si_en Dev loss: 0.6354 r:0.5984
ne_en Dev loss: 0.3860 r:0.7565
ru_en Dev loss: 0.5152 r:0.6880
Current avg r:0.6072 Best avg r: 0.6192
20:48:16,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:34,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:05,264 root INFO Epoch 3 Global steps: 32400 Train loss: 0.4128
en_de Dev loss: 0.8743 r:0.2470
en_zh Dev loss: 0.8274 r:0.4382
ro_en Dev loss: 0.4108 r:0.8131
et_en Dev loss: 0.4306 r:0.6760
si_en Dev loss: 0.9288 r:0.5857
ne_en Dev loss: 0.4707 r:0.7547
ru_en Dev loss: 0.7329 r:0.6672
Current avg r:0.5974 Best avg r: 0.6192
20:54:58,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:15,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:57:46,775 root INFO Epoch 3 Global steps: 33000 Train loss: 0.4127
en_de Dev loss: 0.8575 r:0.2472
en_zh Dev loss: 0.7914 r:0.4500
ro_en Dev loss: 0.3798 r:0.8136
et_en Dev loss: 0.4593 r:0.6775
si_en Dev loss: 0.6758 r:0.5977
ne_en Dev loss: 0.4001 r:0.7473
ru_en Dev loss: 0.5987 r:0.6865
Current avg r:0.6029 Best avg r: 0.6192
21:01:39,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:57,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:28,648 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3966
en_de Dev loss: 0.8554 r:0.2373
en_zh Dev loss: 0.7969 r:0.4399
ro_en Dev loss: 0.3441 r:0.8139
et_en Dev loss: 0.4155 r:0.6704
si_en Dev loss: 0.7167 r:0.5939
ne_en Dev loss: 0.4427 r:0.7436
ru_en Dev loss: 0.6524 r:0.6643
Current avg r:0.5948 Best avg r: 0.6192
21:08:21,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:39,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:10,142 root INFO Epoch 3 Global steps: 34200 Train loss: 0.4173
en_de Dev loss: 0.8530 r:0.2350
en_zh Dev loss: 0.7980 r:0.4507
ro_en Dev loss: 0.3732 r:0.8173
et_en Dev loss: 0.4716 r:0.6816
si_en Dev loss: 0.6848 r:0.6021
ne_en Dev loss: 0.4114 r:0.7507
ru_en Dev loss: 0.5539 r:0.7077
Current avg r:0.6064 Best avg r: 0.6192
21:15:03,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:21,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:51,883 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3855
en_de Dev loss: 0.8417 r:0.2364
en_zh Dev loss: 0.7477 r:0.4542
ro_en Dev loss: 0.3512 r:0.8089
et_en Dev loss: 0.4295 r:0.6698
si_en Dev loss: 0.7634 r:0.5834
ne_en Dev loss: 0.4747 r:0.7447
ru_en Dev loss: 0.5710 r:0.6856
Current avg r:0.5976 Best avg r: 0.6192
21:21:44,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:02,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:33,838 root INFO Epoch 3 Global steps: 35400 Train loss: 0.4130
en_de Dev loss: 0.8495 r:0.2421
en_zh Dev loss: 0.7499 r:0.4492
ro_en Dev loss: 0.3251 r:0.8145
et_en Dev loss: 0.4045 r:0.6795
si_en Dev loss: 0.6499 r:0.6013
ne_en Dev loss: 0.4754 r:0.7445
ru_en Dev loss: 0.5965 r:0.6910
Current avg r:0.6032 Best avg r: 0.6192
21:28:26,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:29:44,680 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:15,557 root INFO Epoch 3 Global steps: 36000 Train loss: 0.4100
en_de Dev loss: 0.8888 r:0.2396
en_zh Dev loss: 0.7943 r:0.4487
ro_en Dev loss: 0.3499 r:0.8170
et_en Dev loss: 0.4270 r:0.6783
si_en Dev loss: 0.7321 r:0.5997
ne_en Dev loss: 0.4586 r:0.7442
ru_en Dev loss: 0.6477 r:0.6922
Current avg r:0.6028 Best avg r: 0.6192
21:35:09,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:27,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:58,643 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3843
en_de Dev loss: 0.8658 r:0.2229
en_zh Dev loss: 0.7773 r:0.4609
ro_en Dev loss: 0.3610 r:0.8094
et_en Dev loss: 0.4734 r:0.6664
si_en Dev loss: 0.6876 r:0.5974
ne_en Dev loss: 0.4667 r:0.7399
ru_en Dev loss: 0.6312 r:0.6689
Current avg r:0.5951 Best avg r: 0.6192
21:41:51,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:09,599 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:40,524 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3635
en_de Dev loss: 0.8926 r:0.2169
en_zh Dev loss: 0.8355 r:0.4424
ro_en Dev loss: 0.3786 r:0.8114
et_en Dev loss: 0.4546 r:0.6702
si_en Dev loss: 0.7277 r:0.5963
ne_en Dev loss: 0.4804 r:0.7439
ru_en Dev loss: 0.6253 r:0.6960
Current avg r:0.5967 Best avg r: 0.6192
21:48:33,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:51,597 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:22,490 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3821
en_de Dev loss: 0.8498 r:0.2343
en_zh Dev loss: 0.7859 r:0.4354
ro_en Dev loss: 0.3450 r:0.8120
et_en Dev loss: 0.4383 r:0.6718
si_en Dev loss: 0.7462 r:0.5929
ne_en Dev loss: 0.4711 r:0.7434
ru_en Dev loss: 0.6129 r:0.6805
Current avg r:0.5958 Best avg r: 0.6192
21:55:15,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:56:33,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:04,581 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3696
en_de Dev loss: 0.8438 r:0.2265
en_zh Dev loss: 0.7419 r:0.4566
ro_en Dev loss: 0.3250 r:0.8171
et_en Dev loss: 0.4500 r:0.6688
si_en Dev loss: 0.7309 r:0.5978
ne_en Dev loss: 0.4204 r:0.7443
ru_en Dev loss: 0.5529 r:0.6881
Current avg r:0.5999 Best avg r: 0.6192
22:01:57,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:15,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:46,575 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3627
en_de Dev loss: 0.8464 r:0.2176
en_zh Dev loss: 0.7579 r:0.4346
ro_en Dev loss: 0.3283 r:0.8118
et_en Dev loss: 0.4448 r:0.6669
si_en Dev loss: 0.6984 r:0.5931
ne_en Dev loss: 0.4106 r:0.7456
ru_en Dev loss: 0.5605 r:0.6844
Current avg r:0.5934 Best avg r: 0.6192
22:08:39,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:57,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:28,522 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3682
en_de Dev loss: 0.8467 r:0.2351
en_zh Dev loss: 0.7892 r:0.4325
ro_en Dev loss: 0.3352 r:0.8163
et_en Dev loss: 0.4440 r:0.6672
si_en Dev loss: 0.6882 r:0.5917
ne_en Dev loss: 0.3994 r:0.7420
ru_en Dev loss: 0.6068 r:0.6729
Current avg r:0.5940 Best avg r: 0.6192
22:15:21,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:16:39,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:10,290 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3936
en_de Dev loss: 0.8460 r:0.2314
en_zh Dev loss: 0.7559 r:0.4527
ro_en Dev loss: 0.3488 r:0.8093
et_en Dev loss: 0.4739 r:0.6619
si_en Dev loss: 0.7254 r:0.5891
ne_en Dev loss: 0.4394 r:0.7437
ru_en Dev loss: 0.5540 r:0.6876
Current avg r:0.5965 Best avg r: 0.6192
22:22:03,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:21,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:52,435 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3604
en_de Dev loss: 0.8858 r:0.2448
en_zh Dev loss: 0.8456 r:0.4287
ro_en Dev loss: 0.4214 r:0.8027
et_en Dev loss: 0.4926 r:0.6586
si_en Dev loss: 0.9096 r:0.5756
ne_en Dev loss: 0.5748 r:0.7451
ru_en Dev loss: 0.7541 r:0.6620
Current avg r:0.5882 Best avg r: 0.6192
22:28:45,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:03,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:34,519 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3614
en_de Dev loss: 0.8725 r:0.2129
en_zh Dev loss: 0.8390 r:0.4255
ro_en Dev loss: 0.3651 r:0.8114
et_en Dev loss: 0.4752 r:0.6660
si_en Dev loss: 0.7302 r:0.5918
ne_en Dev loss: 0.4626 r:0.7348
ru_en Dev loss: 0.6783 r:0.6750
Current avg r:0.5882 Best avg r: 0.6192
22:35:27,242 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:45,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:16,65 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3650
en_de Dev loss: 0.8750 r:0.2105
en_zh Dev loss: 0.8033 r:0.4399
ro_en Dev loss: 0.3698 r:0.8091
et_en Dev loss: 0.4731 r:0.6600
si_en Dev loss: 0.8608 r:0.5803
ne_en Dev loss: 0.5349 r:0.7413
ru_en Dev loss: 0.6994 r:0.6709
Current avg r:0.5874 Best avg r: 0.6192
22:42:08,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:26,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:57,538 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3473
en_de Dev loss: 0.8765 r:0.2072
en_zh Dev loss: 0.7887 r:0.4463
ro_en Dev loss: 0.3801 r:0.8093
et_en Dev loss: 0.4978 r:0.6618
si_en Dev loss: 0.7357 r:0.5882
ne_en Dev loss: 0.4443 r:0.7424
ru_en Dev loss: 0.5736 r:0.6892
Current avg r:0.5921 Best avg r: 0.6192
22:48:50,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:08,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:38,930 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3348
en_de Dev loss: 0.8888 r:0.2088
en_zh Dev loss: 0.8288 r:0.4306
ro_en Dev loss: 0.3864 r:0.8148
et_en Dev loss: 0.4690 r:0.6605
si_en Dev loss: 0.8754 r:0.5845
ne_en Dev loss: 0.5072 r:0.7410
ru_en Dev loss: 0.6745 r:0.6924
Current avg r:0.5904 Best avg r: 0.6192
22:55:31,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:49,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:20,296 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3647
en_de Dev loss: 0.8805 r:0.1916
en_zh Dev loss: 0.8183 r:0.4137
ro_en Dev loss: 0.3593 r:0.8082
et_en Dev loss: 0.4629 r:0.6523
si_en Dev loss: 0.8582 r:0.5762
ne_en Dev loss: 0.5486 r:0.7385
ru_en Dev loss: 0.6659 r:0.6658
Current avg r:0.5780 Best avg r: 0.6192
23:02:13,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:31,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:01,777 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3463
en_de Dev loss: 0.8873 r:0.1976
en_zh Dev loss: 0.8610 r:0.4099
ro_en Dev loss: 0.3995 r:0.8066
et_en Dev loss: 0.4805 r:0.6476
si_en Dev loss: 0.8830 r:0.5716
ne_en Dev loss: 0.5864 r:0.7278
ru_en Dev loss: 0.7035 r:0.6596
Current avg r:0.5744 Best avg r: 0.6192
23:08:54,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:12,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:43,479 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3525
en_de Dev loss: 0.8612 r:0.2182
en_zh Dev loss: 0.7783 r:0.4406
ro_en Dev loss: 0.3503 r:0.8129
et_en Dev loss: 0.4424 r:0.6616
si_en Dev loss: 0.7141 r:0.5895
ne_en Dev loss: 0.4688 r:0.7344
ru_en Dev loss: 0.6246 r:0.6730
Current avg r:0.5900 Best avg r: 0.6192
23:15:37,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:55,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:26,411 root INFO Epoch 5 Global steps: 45600 Train loss: 0.3178
en_de Dev loss: 0.8585 r:0.2051
en_zh Dev loss: 0.8130 r:0.4340
ro_en Dev loss: 0.3740 r:0.8113
et_en Dev loss: 0.4707 r:0.6614
si_en Dev loss: 0.8837 r:0.5694
ne_en Dev loss: 0.5255 r:0.7325
ru_en Dev loss: 0.6743 r:0.6684
Current avg r:0.5832 Best avg r: 0.6192
23:22:19,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:23:37,312 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:08,167 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3207
en_de Dev loss: 0.8661 r:0.2284
en_zh Dev loss: 0.8643 r:0.4278
ro_en Dev loss: 0.4200 r:0.8063
et_en Dev loss: 0.5458 r:0.6569
si_en Dev loss: 0.8588 r:0.5738
ne_en Dev loss: 0.5492 r:0.7350
ru_en Dev loss: 0.7342 r:0.6526
Current avg r:0.5830 Best avg r: 0.6192
23:29:00,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:18,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:49,428 root INFO Epoch 5 Global steps: 46800 Train loss: 0.3230
en_de Dev loss: 0.8627 r:0.2280
en_zh Dev loss: 0.7749 r:0.4496
ro_en Dev loss: 0.3503 r:0.8091
et_en Dev loss: 0.4690 r:0.6633
si_en Dev loss: 0.7258 r:0.5794
ne_en Dev loss: 0.4396 r:0.7411
ru_en Dev loss: 0.6080 r:0.6629
Current avg r:0.5905 Best avg r: 0.6192
23:35:41,980 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:59,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:30,782 root INFO Epoch 5 Global steps: 47400 Train loss: 0.3216
en_de Dev loss: 0.8750 r:0.2355
en_zh Dev loss: 0.8132 r:0.4434
ro_en Dev loss: 0.3651 r:0.8128
et_en Dev loss: 0.4545 r:0.6666
si_en Dev loss: 0.7748 r:0.5746
ne_en Dev loss: 0.4920 r:0.7433
ru_en Dev loss: 0.6558 r:0.6654
Current avg r:0.5917 Best avg r: 0.6192
23:42:23,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:41,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:12,94 root INFO Epoch 5 Global steps: 48000 Train loss: 0.3188
en_de Dev loss: 0.8606 r:0.2202
en_zh Dev loss: 0.7495 r:0.4548
ro_en Dev loss: 0.3273 r:0.8148
et_en Dev loss: 0.4472 r:0.6716
si_en Dev loss: 0.7447 r:0.5811
ne_en Dev loss: 0.4382 r:0.7412
ru_en Dev loss: 0.6060 r:0.6618
Current avg r:0.5922 Best avg r: 0.6192
23:49:04,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:22,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:51:53,519 root INFO Epoch 5 Global steps: 48600 Train loss: 0.3281
en_de Dev loss: 0.8729 r:0.2392
en_zh Dev loss: 0.8002 r:0.4378
ro_en Dev loss: 0.3894 r:0.8071
et_en Dev loss: 0.4634 r:0.6620
si_en Dev loss: 0.8503 r:0.5729
ne_en Dev loss: 0.5543 r:0.7381
ru_en Dev loss: 0.6883 r:0.6608
Current avg r:0.5883 Best avg r: 0.6192
23:55:46,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:04,139 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:34,960 root INFO Epoch 5 Global steps: 49200 Train loss: 0.3227
en_de Dev loss: 0.8953 r:0.2357
en_zh Dev loss: 0.8418 r:0.4257
ro_en Dev loss: 0.3853 r:0.8082
et_en Dev loss: 0.4701 r:0.6520
si_en Dev loss: 0.8454 r:0.5566
ne_en Dev loss: 0.5409 r:0.7372
ru_en Dev loss: 0.7168 r:0.6443
Current avg r:0.5800 Best avg r: 0.6192
00:02:27,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:45,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:16,469 root INFO Epoch 5 Global steps: 49800 Train loss: 0.3119
en_de Dev loss: 0.8889 r:0.2112
en_zh Dev loss: 0.8496 r:0.4243
ro_en Dev loss: 0.3909 r:0.8051
et_en Dev loss: 0.4782 r:0.6505
si_en Dev loss: 0.8189 r:0.5589
ne_en Dev loss: 0.5340 r:0.7317
ru_en Dev loss: 0.6780 r:0.6546
Current avg r:0.5766 Best avg r: 0.6192
00:09:09,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:27,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:57,941 root INFO Epoch 5 Global steps: 50400 Train loss: 0.3154
en_de Dev loss: 0.8697 r:0.2062
en_zh Dev loss: 0.8285 r:0.4108
ro_en Dev loss: 0.3803 r:0.8046
et_en Dev loss: 0.4590 r:0.6563
si_en Dev loss: 0.8495 r:0.5605
ne_en Dev loss: 0.5193 r:0.7365
ru_en Dev loss: 0.6735 r:0.6452
Current avg r:0.5743 Best avg r: 0.6192
00:15:50,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:08,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:18:39,22 root INFO Epoch 5 Global steps: 51000 Train loss: 0.3012
en_de Dev loss: 0.8513 r:0.2311
en_zh Dev loss: 0.8040 r:0.4311
ro_en Dev loss: 0.3571 r:0.8080
et_en Dev loss: 0.4386 r:0.6580
si_en Dev loss: 0.8402 r:0.5655
ne_en Dev loss: 0.4555 r:0.7379
ru_en Dev loss: 0.6528 r:0.6526
Current avg r:0.5835 Best avg r: 0.6192
00:22:31,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:49,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:20,292 root INFO Epoch 5 Global steps: 51600 Train loss: 0.3083
en_de Dev loss: 0.8735 r:0.2193
en_zh Dev loss: 0.8152 r:0.4322
ro_en Dev loss: 0.3781 r:0.8064
et_en Dev loss: 0.4742 r:0.6490
si_en Dev loss: 0.8684 r:0.5635
ne_en Dev loss: 0.5652 r:0.7381
ru_en Dev loss: 0.6704 r:0.6409
Current avg r:0.5785 Best avg r: 0.6192
00:29:12,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:30:30,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:01,624 root INFO Epoch 5 Global steps: 52200 Train loss: 0.3046
en_de Dev loss: 0.8770 r:0.2084
en_zh Dev loss: 0.7869 r:0.4448
ro_en Dev loss: 0.3629 r:0.8118
et_en Dev loss: 0.4597 r:0.6633
si_en Dev loss: 0.7941 r:0.5740
ne_en Dev loss: 0.4626 r:0.7395
ru_en Dev loss: 0.6134 r:0.6675
Current avg r:0.5871 Best avg r: 0.6192
00:35:54,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:12,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:42,943 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2989
en_de Dev loss: 0.8780 r:0.2114
en_zh Dev loss: 0.7888 r:0.4445
ro_en Dev loss: 0.4097 r:0.8042
et_en Dev loss: 0.4523 r:0.6554
si_en Dev loss: 0.9489 r:0.5627
ne_en Dev loss: 0.6064 r:0.7394
ru_en Dev loss: 0.7064 r:0.6495
Current avg r:0.5810 Best avg r: 0.6192
00:42:35,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:53,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:24,22 root INFO Epoch 5 Global steps: 53400 Train loss: 0.3241
en_de Dev loss: 0.8724 r:0.2222
en_zh Dev loss: 0.7764 r:0.4452
ro_en Dev loss: 0.3682 r:0.8077
et_en Dev loss: 0.4639 r:0.6565
si_en Dev loss: 0.8149 r:0.5660
ne_en Dev loss: 0.5060 r:0.7425
ru_en Dev loss: 0.6409 r:0.6602
Current avg r:0.5858 Best avg r: 0.6192
00:49:16,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:34,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:05,396 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2990
en_de Dev loss: 0.8812 r:0.2125
en_zh Dev loss: 0.8450 r:0.4265
ro_en Dev loss: 0.4009 r:0.8072
et_en Dev loss: 0.4772 r:0.6551
si_en Dev loss: 0.8690 r:0.5621
ne_en Dev loss: 0.6204 r:0.7369
ru_en Dev loss: 0.6965 r:0.6577
Current avg r:0.5797 Best avg r: 0.6192
00:55:59,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:17,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:47,895 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2628
en_de Dev loss: 0.9073 r:0.2028
en_zh Dev loss: 0.7977 r:0.4678
ro_en Dev loss: 0.3860 r:0.8088
et_en Dev loss: 0.5005 r:0.6615
si_en Dev loss: 0.7986 r:0.5694
ne_en Dev loss: 0.4723 r:0.7405
ru_en Dev loss: 0.6059 r:0.6774
Current avg r:0.5897 Best avg r: 0.6192
01:02:40,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:58,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:29,242 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2795
en_de Dev loss: 0.9072 r:0.2093
en_zh Dev loss: 0.8331 r:0.4418
ro_en Dev loss: 0.3991 r:0.8053
et_en Dev loss: 0.4829 r:0.6557
si_en Dev loss: 0.8744 r:0.5653
ne_en Dev loss: 0.5876 r:0.7394
ru_en Dev loss: 0.7411 r:0.6462
Current avg r:0.5804 Best avg r: 0.6192
01:09:21,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:39,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:10,474 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2888
en_de Dev loss: 0.9095 r:0.2115
en_zh Dev loss: 0.8245 r:0.4299
ro_en Dev loss: 0.3589 r:0.8092
et_en Dev loss: 0.4681 r:0.6599
si_en Dev loss: 0.7956 r:0.5641
ne_en Dev loss: 0.4994 r:0.7370
ru_en Dev loss: 0.6538 r:0.6600
Current avg r:0.5817 Best avg r: 0.6192
01:16:03,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:21,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:51,961 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2767
en_de Dev loss: 0.8678 r:0.2197
en_zh Dev loss: 0.7793 r:0.4394
ro_en Dev loss: 0.3352 r:0.8147
et_en Dev loss: 0.4765 r:0.6672
si_en Dev loss: 0.7723 r:0.5688
ne_en Dev loss: 0.4244 r:0.7414
ru_en Dev loss: 0.5728 r:0.6756
Current avg r:0.5895 Best avg r: 0.6192
01:22:44,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:24:02,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:33,201 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2778
en_de Dev loss: 0.8769 r:0.2235
en_zh Dev loss: 0.7631 r:0.4557
ro_en Dev loss: 0.3424 r:0.8127
et_en Dev loss: 0.4590 r:0.6615
si_en Dev loss: 0.7481 r:0.5739
ne_en Dev loss: 0.4644 r:0.7305
ru_en Dev loss: 0.6003 r:0.6769
Current avg r:0.5907 Best avg r: 0.6192
01:29:25,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:43,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:14,776 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2833
en_de Dev loss: 0.8887 r:0.2182
en_zh Dev loss: 0.8175 r:0.4422
ro_en Dev loss: 0.3857 r:0.8090
et_en Dev loss: 0.5139 r:0.6455
si_en Dev loss: 0.7797 r:0.5634
ne_en Dev loss: 0.4903 r:0.7277
ru_en Dev loss: 0.6894 r:0.6432
Current avg r:0.5785 Best avg r: 0.6192
01:36:07,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:37:25,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:56,480 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2659
en_de Dev loss: 0.8851 r:0.2114
en_zh Dev loss: 0.7891 r:0.4466
ro_en Dev loss: 0.3797 r:0.8072
et_en Dev loss: 0.4683 r:0.6516
si_en Dev loss: 0.8637 r:0.5542
ne_en Dev loss: 0.5385 r:0.7360
ru_en Dev loss: 0.7017 r:0.6375
Current avg r:0.5778 Best avg r: 0.6192
01:42:49,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:07,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:38,448 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2736
en_de Dev loss: 0.8924 r:0.2197
en_zh Dev loss: 0.8111 r:0.4522
ro_en Dev loss: 0.3911 r:0.8067
et_en Dev loss: 0.4844 r:0.6488
si_en Dev loss: 0.8499 r:0.5582
ne_en Dev loss: 0.5849 r:0.7305
ru_en Dev loss: 0.7170 r:0.6501
Current avg r:0.5809 Best avg r: 0.6192
01:49:31,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:49,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:20,497 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2619
en_de Dev loss: 0.9049 r:0.2196
en_zh Dev loss: 0.8855 r:0.4261
ro_en Dev loss: 0.4145 r:0.8070
et_en Dev loss: 0.5104 r:0.6490
si_en Dev loss: 0.9295 r:0.5499
ne_en Dev loss: 0.5334 r:0.7324
ru_en Dev loss: 0.8227 r:0.6300
Current avg r:0.5734 Best avg r: 0.6192
01:56:13,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:31,729 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:03,410 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2722
en_de Dev loss: 0.8778 r:0.2120
en_zh Dev loss: 0.7722 r:0.4419
ro_en Dev loss: 0.3453 r:0.8063
et_en Dev loss: 0.4880 r:0.6391
si_en Dev loss: 0.8124 r:0.5540
ne_en Dev loss: 0.5095 r:0.7288
ru_en Dev loss: 0.6206 r:0.6486
Current avg r:0.5758 Best avg r: 0.6192
02:03:00,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:04:19,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:05:51,961 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2615
en_de Dev loss: 0.8847 r:0.2190
en_zh Dev loss: 0.8478 r:0.4172
ro_en Dev loss: 0.3602 r:0.8065
et_en Dev loss: 0.4815 r:0.6383
si_en Dev loss: 0.9014 r:0.5413
ne_en Dev loss: 0.5978 r:0.7240
ru_en Dev loss: 0.6804 r:0.6404
Current avg r:0.5695 Best avg r: 0.6192
02:09:49,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:11:08,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:12:41,10 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2605
en_de Dev loss: 0.8931 r:0.2185
en_zh Dev loss: 0.8300 r:0.4433
ro_en Dev loss: 0.3801 r:0.8081
et_en Dev loss: 0.4984 r:0.6491
si_en Dev loss: 0.8475 r:0.5540
ne_en Dev loss: 0.5155 r:0.7288
ru_en Dev loss: 0.6754 r:0.6554
Current avg r:0.5796 Best avg r: 0.6192
02:16:39,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:17:58,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:30,225 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2918
en_de Dev loss: 0.8682 r:0.2234
en_zh Dev loss: 0.7858 r:0.4482
ro_en Dev loss: 0.3537 r:0.8134
et_en Dev loss: 0.4702 r:0.6447
si_en Dev loss: 0.8796 r:0.5543
ne_en Dev loss: 0.4857 r:0.7376
ru_en Dev loss: 0.6134 r:0.6594
Current avg r:0.5830 Best avg r: 0.6192
02:23:28,196 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:47,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:26:19,338 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2622
en_de Dev loss: 0.8594 r:0.2391
en_zh Dev loss: 0.8390 r:0.4314
ro_en Dev loss: 0.3879 r:0.8112
et_en Dev loss: 0.4755 r:0.6436
si_en Dev loss: 0.9043 r:0.5517
ne_en Dev loss: 0.5036 r:0.7366
ru_en Dev loss: 0.6355 r:0.6674
Current avg r:0.5830 Best avg r: 0.6192
02:30:16,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:34,553 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:33:05,634 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2584
en_de Dev loss: 0.8935 r:0.2200
en_zh Dev loss: 0.8481 r:0.4301
ro_en Dev loss: 0.4029 r:0.8079
et_en Dev loss: 0.4843 r:0.6354
si_en Dev loss: 0.8517 r:0.5473
ne_en Dev loss: 0.5999 r:0.7170
ru_en Dev loss: 0.7297 r:0.6410
Current avg r:0.5712 Best avg r: 0.6192
02:37:00,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:38:19,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:39:50,385 root INFO Epoch 7 Global steps: 63600 Train loss: 0.2301
en_de Dev loss: 0.8686 r:0.2414
en_zh Dev loss: 0.8063 r:0.4466
ro_en Dev loss: 0.3656 r:0.8106
et_en Dev loss: 0.5052 r:0.6443
si_en Dev loss: 0.8295 r:0.5496
ne_en Dev loss: 0.5397 r:0.7209
ru_en Dev loss: 0.6865 r:0.6445
Current avg r:0.5797 Best avg r: 0.6192
02:43:43,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:45:02,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:46:33,163 root INFO Epoch 7 Global steps: 64200 Train loss: 0.2341
en_de Dev loss: 0.9223 r:0.2208
en_zh Dev loss: 0.8651 r:0.4282
ro_en Dev loss: 0.3864 r:0.8074
et_en Dev loss: 0.5031 r:0.6406
si_en Dev loss: 0.8486 r:0.5521
ne_en Dev loss: 0.5730 r:0.7189
ru_en Dev loss: 0.7458 r:0.6365
Current avg r:0.5721 Best avg r: 0.6192
02:50:26,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:44,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:15,839 root INFO Epoch 7 Global steps: 64800 Train loss: 0.2220
en_de Dev loss: 0.9159 r:0.2003
en_zh Dev loss: 0.8190 r:0.4471
ro_en Dev loss: 0.3889 r:0.8033
et_en Dev loss: 0.5158 r:0.6389
si_en Dev loss: 0.8462 r:0.5531
ne_en Dev loss: 0.5114 r:0.7223
ru_en Dev loss: 0.6529 r:0.6520
Current avg r:0.5738 Best avg r: 0.6192
02:57:09,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:58:27,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:59:58,607 root INFO Epoch 7 Global steps: 65400 Train loss: 0.2346
en_de Dev loss: 0.9021 r:0.2048
en_zh Dev loss: 0.8268 r:0.4399
ro_en Dev loss: 0.3839 r:0.8038
et_en Dev loss: 0.5073 r:0.6423
si_en Dev loss: 0.8302 r:0.5555
ne_en Dev loss: 0.4888 r:0.7283
ru_en Dev loss: 0.6717 r:0.6500
Current avg r:0.5749 Best avg r: 0.6192
03:03:52,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:05:10,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:06:41,419 root INFO Epoch 7 Global steps: 66000 Train loss: 0.2268
en_de Dev loss: 0.9596 r:0.1894
en_zh Dev loss: 0.8911 r:0.4248
ro_en Dev loss: 0.4175 r:0.7998
et_en Dev loss: 0.5116 r:0.6310
si_en Dev loss: 0.9337 r:0.5378
ne_en Dev loss: 0.5313 r:0.7176
ru_en Dev loss: 0.7260 r:0.6339
Current avg r:0.5621 Best avg r: 0.6192
03:10:34,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:11:53,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:13:24,106 root INFO Epoch 7 Global steps: 66600 Train loss: 0.2560
en_de Dev loss: 0.8847 r:0.2119
en_zh Dev loss: 0.9084 r:0.4186
ro_en Dev loss: 0.4285 r:0.8012
et_en Dev loss: 0.5246 r:0.6349
si_en Dev loss: 1.0264 r:0.5362
ne_en Dev loss: 0.6162 r:0.7245
ru_en Dev loss: 0.7470 r:0.6345
Current avg r:0.5660 Best avg r: 0.6192
03:17:17,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:18:36,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:20:07,732 root INFO Epoch 7 Global steps: 67200 Train loss: 0.2404
en_de Dev loss: 0.8886 r:0.1825
en_zh Dev loss: 0.8286 r:0.4357
ro_en Dev loss: 0.3919 r:0.8060
et_en Dev loss: 0.5148 r:0.6484
si_en Dev loss: 0.9750 r:0.5440
ne_en Dev loss: 0.5362 r:0.7156
ru_en Dev loss: 0.7290 r:0.6355
Current avg r:0.5668 Best avg r: 0.6192
03:24:04,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:25:23,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:26:54,901 root INFO Epoch 7 Global steps: 67800 Train loss: 0.2395
en_de Dev loss: 0.9043 r:0.1793
en_zh Dev loss: 0.8860 r:0.4211
ro_en Dev loss: 0.4115 r:0.8027
et_en Dev loss: 0.5222 r:0.6227
si_en Dev loss: 1.0481 r:0.5339
ne_en Dev loss: 0.7024 r:0.7156
ru_en Dev loss: 0.8074 r:0.6142
Current avg r:0.5556 Best avg r: 0.6192
03:30:51,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:32:10,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:33:42,136 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2343
en_de Dev loss: 0.9241 r:0.1911
en_zh Dev loss: 0.8739 r:0.4375
ro_en Dev loss: 0.4275 r:0.8064
et_en Dev loss: 0.5023 r:0.6349
si_en Dev loss: 0.9776 r:0.5442
ne_en Dev loss: 0.6829 r:0.7213
ru_en Dev loss: 0.7713 r:0.6478
Current avg r:0.5690 Best avg r: 0.6192
03:37:38,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:38:57,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:40:29,36 root INFO Epoch 7 Global steps: 69000 Train loss: 0.2426
en_de Dev loss: 0.9196 r:0.1946
en_zh Dev loss: 0.8783 r:0.4388
ro_en Dev loss: 0.4144 r:0.8002
et_en Dev loss: 0.5595 r:0.6259
si_en Dev loss: 0.9092 r:0.5505
ne_en Dev loss: 0.6360 r:0.7172
ru_en Dev loss: 0.7252 r:0.6358
Current avg r:0.5661 Best avg r: 0.6192
03:44:23,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:45:41,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:47:13,199 root INFO Epoch 7 Global steps: 69600 Train loss: 0.2513
en_de Dev loss: 0.8942 r:0.2006
en_zh Dev loss: 0.8534 r:0.4341
ro_en Dev loss: 0.3850 r:0.8021
et_en Dev loss: 0.5224 r:0.6259
si_en Dev loss: 0.9742 r:0.5369
ne_en Dev loss: 0.6856 r:0.7217
ru_en Dev loss: 0.6711 r:0.6490
Current avg r:0.5672 Best avg r: 0.6192
03:51:07,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:52:25,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:53:56,410 root INFO Epoch 7 Global steps: 70200 Train loss: 0.2332
en_de Dev loss: 0.9042 r:0.2046
en_zh Dev loss: 0.8338 r:0.4428
ro_en Dev loss: 0.4111 r:0.8058
et_en Dev loss: 0.5079 r:0.6400
si_en Dev loss: 0.9387 r:0.5395
ne_en Dev loss: 0.6555 r:0.7158
ru_en Dev loss: 0.7099 r:0.6499
Current avg r:0.5712 Best avg r: 0.6192
03:57:50,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:59:08,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:39,230 root INFO Epoch 7 Global steps: 70800 Train loss: 0.2413
en_de Dev loss: 0.8867 r:0.1742
en_zh Dev loss: 0.7459 r:0.4499
ro_en Dev loss: 0.3600 r:0.8054
et_en Dev loss: 0.4715 r:0.6481
si_en Dev loss: 0.7735 r:0.5517
ne_en Dev loss: 0.4984 r:0.7209
ru_en Dev loss: 0.5594 r:0.6684
Current avg r:0.5741 Best avg r: 0.6192
04:04:32,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:05:50,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:07:21,764 root INFO Epoch 7 Global steps: 71400 Train loss: 0.2300
en_de Dev loss: 0.9117 r:0.1878
en_zh Dev loss: 0.7989 r:0.4452
ro_en Dev loss: 0.3885 r:0.8034
et_en Dev loss: 0.5071 r:0.6431
si_en Dev loss: 0.8900 r:0.5411
ne_en Dev loss: 0.4611 r:0.7283
ru_en Dev loss: 0.6832 r:0.6426
Current avg r:0.5702 Best avg r: 0.6192
04:11:15,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:12:33,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:14:04,751 root INFO Epoch 7 Global steps: 72000 Train loss: 0.2295
en_de Dev loss: 0.9097 r:0.2029
en_zh Dev loss: 0.8320 r:0.4435
ro_en Dev loss: 0.4047 r:0.7994
et_en Dev loss: 0.5235 r:0.6368
si_en Dev loss: 0.8983 r:0.5444
ne_en Dev loss: 0.5223 r:0.7104
ru_en Dev loss: 0.6970 r:0.6229
Current avg r:0.5657 Best avg r: 0.6192
04:18:00,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:19:18,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:20:49,358 root INFO Epoch 8 Global steps: 72600 Train loss: 0.2162
en_de Dev loss: 0.8945 r:0.2061
en_zh Dev loss: 0.8090 r:0.4440
ro_en Dev loss: 0.3810 r:0.8023
et_en Dev loss: 0.4949 r:0.6499
si_en Dev loss: 0.8762 r:0.5460
ne_en Dev loss: 0.6007 r:0.7206
ru_en Dev loss: 0.7070 r:0.6356
Current avg r:0.5721 Best avg r: 0.6192
04:24:42,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:26:00,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:27:31,691 root INFO Epoch 8 Global steps: 73200 Train loss: 0.2205
en_de Dev loss: 0.9195 r:0.1667
en_zh Dev loss: 0.8402 r:0.4416
ro_en Dev loss: 0.3740 r:0.8053
et_en Dev loss: 0.4917 r:0.6475
si_en Dev loss: 0.8889 r:0.5503
ne_en Dev loss: 0.5663 r:0.7269
ru_en Dev loss: 0.7161 r:0.6368
Current avg r:0.5679 Best avg r: 0.6192
04:31:25,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:32:44,491 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:34:16,520 root INFO Epoch 8 Global steps: 73800 Train loss: 0.2098
en_de Dev loss: 0.9138 r:0.1946
en_zh Dev loss: 0.8394 r:0.4425
ro_en Dev loss: 0.4098 r:0.8026
et_en Dev loss: 0.5014 r:0.6450
si_en Dev loss: 0.8953 r:0.5569
ne_en Dev loss: 0.5257 r:0.7288
ru_en Dev loss: 0.7232 r:0.6490
Current avg r:0.5742 Best avg r: 0.6192
04:38:14,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:39:33,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:41:05,88 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1995
en_de Dev loss: 0.8866 r:0.1957
en_zh Dev loss: 0.8614 r:0.4412
ro_en Dev loss: 0.4138 r:0.8048
et_en Dev loss: 0.5075 r:0.6439
si_en Dev loss: 0.9646 r:0.5476
ne_en Dev loss: 0.6127 r:0.7239
ru_en Dev loss: 0.7682 r:0.6347
Current avg r:0.5703 Best avg r: 0.6192
04:45:02,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:46:21,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:47:53,548 root INFO Epoch 8 Global steps: 75000 Train loss: 0.2192
en_de Dev loss: 0.9262 r:0.1919
en_zh Dev loss: 0.9450 r:0.4325
ro_en Dev loss: 0.4590 r:0.8046
et_en Dev loss: 0.5561 r:0.6364
si_en Dev loss: 1.0011 r:0.5466
ne_en Dev loss: 0.6274 r:0.7243
ru_en Dev loss: 0.8577 r:0.6346
Current avg r:0.5673 Best avg r: 0.6192
04:51:51,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:53:09,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:54:41,821 root INFO Epoch 8 Global steps: 75600 Train loss: 0.2024
en_de Dev loss: 0.8855 r:0.1837
en_zh Dev loss: 0.7776 r:0.4428
ro_en Dev loss: 0.3607 r:0.8046
et_en Dev loss: 0.4956 r:0.6379
si_en Dev loss: 0.9258 r:0.5387
ne_en Dev loss: 0.5278 r:0.7239
ru_en Dev loss: 0.6756 r:0.6489
Current avg r:0.5686 Best avg r: 0.6192
04:58:36,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:59:54,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:01:25,624 root INFO Epoch 8 Global steps: 76200 Train loss: 0.2066
en_de Dev loss: 0.9183 r:0.1734
en_zh Dev loss: 0.8208 r:0.4531
ro_en Dev loss: 0.3767 r:0.8019
et_en Dev loss: 0.4933 r:0.6439
si_en Dev loss: 0.9106 r:0.5407
ne_en Dev loss: 0.4983 r:0.7255
ru_en Dev loss: 0.6930 r:0.6556
Current avg r:0.5706 Best avg r: 0.6192
05:05:19,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:37,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:07,936 root INFO Epoch 8 Global steps: 76800 Train loss: 0.2132
en_de Dev loss: 0.9118 r:0.1713
en_zh Dev loss: 0.8090 r:0.4429
ro_en Dev loss: 0.4018 r:0.8004
et_en Dev loss: 0.4884 r:0.6407
si_en Dev loss: 0.9378 r:0.5371
ne_en Dev loss: 0.6580 r:0.7194
ru_en Dev loss: 0.7355 r:0.6366
Current avg r:0.5641 Best avg r: 0.6192
05:12:01,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:13:19,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:14:50,969 root INFO Epoch 8 Global steps: 77400 Train loss: 0.2042
en_de Dev loss: 0.9103 r:0.1570
en_zh Dev loss: 0.8124 r:0.4408
ro_en Dev loss: 0.3776 r:0.8039
et_en Dev loss: 0.5209 r:0.6460
si_en Dev loss: 0.8895 r:0.5337
ne_en Dev loss: 0.4940 r:0.7217
ru_en Dev loss: 0.6794 r:0.6433
Current avg r:0.5638 Best avg r: 0.6192
05:18:44,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:03,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:21:34,17 root INFO Epoch 8 Global steps: 78000 Train loss: 0.2022
en_de Dev loss: 0.9269 r:0.1720
en_zh Dev loss: 0.8938 r:0.4295
ro_en Dev loss: 0.4163 r:0.7965
et_en Dev loss: 0.5100 r:0.6255
si_en Dev loss: 0.9915 r:0.5313
ne_en Dev loss: 0.6289 r:0.7226
ru_en Dev loss: 0.7984 r:0.6237
Current avg r:0.5573 Best avg r: 0.6192
05:25:27,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:26:45,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:28:17,93 root INFO Epoch 8 Global steps: 78600 Train loss: 0.2024
en_de Dev loss: 0.9423 r:0.1697
en_zh Dev loss: 0.8178 r:0.4560
ro_en Dev loss: 0.3704 r:0.8090
et_en Dev loss: 0.5247 r:0.6514
si_en Dev loss: 0.8469 r:0.5476
ne_en Dev loss: 0.4818 r:0.7204
ru_en Dev loss: 0.6416 r:0.6609
Current avg r:0.5736 Best avg r: 0.6192
05:32:10,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:33:29,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:35:00,750 root INFO Epoch 8 Global steps: 79200 Train loss: 0.2009
en_de Dev loss: 0.9555 r:0.1809
en_zh Dev loss: 0.8466 r:0.4524
ro_en Dev loss: 0.3936 r:0.8044
et_en Dev loss: 0.5205 r:0.6448
si_en Dev loss: 0.9592 r:0.5402
ne_en Dev loss: 0.6561 r:0.7192
ru_en Dev loss: 0.7539 r:0.6431
Current avg r:0.5693 Best avg r: 0.6192
05:38:56,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:40:15,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:41:46,819 root INFO Epoch 8 Global steps: 79800 Train loss: 0.2007
en_de Dev loss: 0.9089 r:0.1635
en_zh Dev loss: 0.8042 r:0.4394
ro_en Dev loss: 0.3621 r:0.8047
et_en Dev loss: 0.4960 r:0.6405
si_en Dev loss: 0.8887 r:0.5343
ne_en Dev loss: 0.6088 r:0.7177
ru_en Dev loss: 0.6932 r:0.6396
Current avg r:0.5628 Best avg r: 0.6192
05:45:44,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:47:02,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:48:34,968 root INFO Epoch 8 Global steps: 80400 Train loss: 0.2077
en_de Dev loss: 0.9200 r:0.1744
en_zh Dev loss: 0.8064 r:0.4462
ro_en Dev loss: 0.3821 r:0.8028
et_en Dev loss: 0.5388 r:0.6445
si_en Dev loss: 0.9186 r:0.5355
ne_en Dev loss: 0.5824 r:0.7175
ru_en Dev loss: 0.6640 r:0.6621
Current avg r:0.5690 Best avg r: 0.6192
05:52:32,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:53:50,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:55:22,695 root INFO Epoch 8 Global steps: 81000 Train loss: 0.2015
en_de Dev loss: 0.9669 r:0.1829
en_zh Dev loss: 0.8169 r:0.4517
ro_en Dev loss: 0.3753 r:0.8082
et_en Dev loss: 0.5675 r:0.6417
si_en Dev loss: 0.7987 r:0.5468
ne_en Dev loss: 0.4834 r:0.7147
ru_en Dev loss: 0.6059 r:0.6699
Current avg r:0.5737 Best avg r: 0.6192
05:59:21,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:00:40,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:02:11,864 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1753
en_de Dev loss: 0.9250 r:0.1901
en_zh Dev loss: 0.8113 r:0.4524
ro_en Dev loss: 0.3665 r:0.8126
et_en Dev loss: 0.5013 r:0.6509
si_en Dev loss: 0.8444 r:0.5512
ne_en Dev loss: 0.5008 r:0.7253
ru_en Dev loss: 0.7219 r:0.6583
Current avg r:0.5773 Best avg r: 0.6192
06:06:08,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:27,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:58,76 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1812
en_de Dev loss: 0.9245 r:0.1832
en_zh Dev loss: 0.8483 r:0.4473
ro_en Dev loss: 0.4017 r:0.8114
et_en Dev loss: 0.4943 r:0.6534
si_en Dev loss: 0.9984 r:0.5464
ne_en Dev loss: 0.5483 r:0.7251
ru_en Dev loss: 0.8052 r:0.6517
Current avg r:0.5741 Best avg r: 0.6192
06:12:51,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:09,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:40,249 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1944
en_de Dev loss: 0.9466 r:0.1827
en_zh Dev loss: 0.9125 r:0.4254
ro_en Dev loss: 0.4320 r:0.8031
et_en Dev loss: 0.5086 r:0.6402
si_en Dev loss: 1.0192 r:0.5258
ne_en Dev loss: 0.6216 r:0.7176
ru_en Dev loss: 0.7899 r:0.6465
Current avg r:0.5630 Best avg r: 0.6192
06:19:33,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:20:51,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:22:22,813 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1890
en_de Dev loss: 0.9216 r:0.1946
en_zh Dev loss: 0.9019 r:0.4188
ro_en Dev loss: 0.4468 r:0.8028
et_en Dev loss: 0.5241 r:0.6358
si_en Dev loss: 1.0651 r:0.5263
ne_en Dev loss: 0.6269 r:0.7184
ru_en Dev loss: 0.8110 r:0.6348
Current avg r:0.5616 Best avg r: 0.6192
06:26:16,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:27:34,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:29:05,806 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1811
en_de Dev loss: 0.8821 r:0.1903
en_zh Dev loss: 0.8138 r:0.4223
ro_en Dev loss: 0.3631 r:0.8100
et_en Dev loss: 0.4891 r:0.6376
si_en Dev loss: 0.9104 r:0.5337
ne_en Dev loss: 0.5673 r:0.7240
ru_en Dev loss: 0.7110 r:0.6323
Current avg r:0.5643 Best avg r: 0.6192
06:32:59,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:34:17,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:35:48,633 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1759
en_de Dev loss: 0.9300 r:0.2027
en_zh Dev loss: 0.8802 r:0.4277
ro_en Dev loss: 0.3906 r:0.8122
et_en Dev loss: 0.5298 r:0.6515
si_en Dev loss: 0.8461 r:0.5465
ne_en Dev loss: 0.4985 r:0.7221
ru_en Dev loss: 0.6618 r:0.6634
Current avg r:0.5752 Best avg r: 0.6192
06:39:42,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:01,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:42:33,459 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1869
en_de Dev loss: 0.9293 r:0.1848
en_zh Dev loss: 0.8500 r:0.4274
ro_en Dev loss: 0.3772 r:0.8115
et_en Dev loss: 0.5057 r:0.6470
si_en Dev loss: 0.8789 r:0.5402
ne_en Dev loss: 0.5283 r:0.7164
ru_en Dev loss: 0.6981 r:0.6496
Current avg r:0.5681 Best avg r: 0.6192
06:46:29,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:48,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:49:20,47 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1700
en_de Dev loss: 0.9139 r:0.1648
en_zh Dev loss: 0.8564 r:0.4202
ro_en Dev loss: 0.3630 r:0.8114
et_en Dev loss: 0.4798 r:0.6426
si_en Dev loss: 0.9085 r:0.5281
ne_en Dev loss: 0.6170 r:0.7193
ru_en Dev loss: 0.7138 r:0.6379
Current avg r:0.5606 Best avg r: 0.6192
06:53:16,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:35,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:08,18 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1778
en_de Dev loss: 0.9866 r:0.1586
en_zh Dev loss: 0.9183 r:0.4179
ro_en Dev loss: 0.4011 r:0.8057
et_en Dev loss: 0.5309 r:0.6281
si_en Dev loss: 0.9494 r:0.5192
ne_en Dev loss: 0.6559 r:0.7154
ru_en Dev loss: 0.7759 r:0.6351
Current avg r:0.5543 Best avg r: 0.6192
07:00:05,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:01:24,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:56,472 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1791
en_de Dev loss: 0.9357 r:0.1928
en_zh Dev loss: 0.8064 r:0.4484
ro_en Dev loss: 0.3816 r:0.8088
et_en Dev loss: 0.5082 r:0.6504
si_en Dev loss: 0.9164 r:0.5256
ne_en Dev loss: 0.6035 r:0.7186
ru_en Dev loss: 0.6460 r:0.6704
Current avg r:0.5736 Best avg r: 0.6192
07:06:53,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:12,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:09:44,139 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1757
en_de Dev loss: 0.9604 r:0.1914
en_zh Dev loss: 0.8940 r:0.4336
ro_en Dev loss: 0.3963 r:0.8086
et_en Dev loss: 0.5665 r:0.6450
si_en Dev loss: 0.9304 r:0.5231
ne_en Dev loss: 0.5883 r:0.7208
ru_en Dev loss: 0.7185 r:0.6613
Current avg r:0.5691 Best avg r: 0.6192
07:13:41,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:14:59,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:16:31,343 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1790
en_de Dev loss: 0.9227 r:0.1761
en_zh Dev loss: 0.8218 r:0.4383
ro_en Dev loss: 0.3653 r:0.8101
et_en Dev loss: 0.4925 r:0.6370
si_en Dev loss: 0.9604 r:0.5236
ne_en Dev loss: 0.6435 r:0.7161
ru_en Dev loss: 0.7356 r:0.6338
Current avg r:0.5621 Best avg r: 0.6192
07:20:25,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:21:43,391 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:23:14,400 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1752
en_de Dev loss: 0.9390 r:0.1889
en_zh Dev loss: 0.8193 r:0.4421
ro_en Dev loss: 0.3591 r:0.8149
et_en Dev loss: 0.5154 r:0.6486
si_en Dev loss: 0.8839 r:0.5352
ne_en Dev loss: 0.4775 r:0.7226
ru_en Dev loss: 0.6911 r:0.6608
Current avg r:0.5733 Best avg r: 0.6192
07:27:08,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:28:26,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:29:57,841 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1713
en_de Dev loss: 0.9382 r:0.1703
en_zh Dev loss: 0.8296 r:0.4440
ro_en Dev loss: 0.3891 r:0.8085
et_en Dev loss: 0.5033 r:0.6433
si_en Dev loss: 0.9866 r:0.5228
ne_en Dev loss: 0.5514 r:0.7216
ru_en Dev loss: 0.7323 r:0.6476
Current avg r:0.5655 Best avg r: 0.6192
07:33:51,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:35:09,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:36:40,512 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1826
en_de Dev loss: 0.9253 r:0.1823
en_zh Dev loss: 0.8616 r:0.4315
ro_en Dev loss: 0.3961 r:0.8038
et_en Dev loss: 0.5032 r:0.6349
si_en Dev loss: 1.0206 r:0.5239
ne_en Dev loss: 0.5793 r:0.7194
ru_en Dev loss: 0.7642 r:0.6398
Current avg r:0.5622 Best avg r: 0.6192
07:40:34,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:41:53,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:43:24,824 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1580
en_de Dev loss: 0.9651 r:0.1826
en_zh Dev loss: 0.8768 r:0.4350
ro_en Dev loss: 0.3965 r:0.8068
et_en Dev loss: 0.4891 r:0.6434
si_en Dev loss: 0.9620 r:0.5347
ne_en Dev loss: 0.6278 r:0.7173
ru_en Dev loss: 0.7683 r:0.6479
Current avg r:0.5668 Best avg r: 0.6192
07:47:21,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:39,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:50:11,692 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1666
en_de Dev loss: 0.9138 r:0.1938
en_zh Dev loss: 0.8468 r:0.4439
ro_en Dev loss: 0.3786 r:0.8101
et_en Dev loss: 0.5323 r:0.6485
si_en Dev loss: 0.9341 r:0.5335
ne_en Dev loss: 0.5660 r:0.7141
ru_en Dev loss: 0.7625 r:0.6442
Current avg r:0.5697 Best avg r: 0.6192
07:54:07,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:55:26,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:56:58,169 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1563
en_de Dev loss: 0.9114 r:0.1976
en_zh Dev loss: 0.8099 r:0.4503
ro_en Dev loss: 0.3551 r:0.8144
et_en Dev loss: 0.4663 r:0.6479
si_en Dev loss: 0.8987 r:0.5373
ne_en Dev loss: 0.5721 r:0.7203
ru_en Dev loss: 0.6565 r:0.6690
Current avg r:0.5767 Best avg r: 0.6192
08:00:55,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:14,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:46,653 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1588
en_de Dev loss: 0.9539 r:0.1921
en_zh Dev loss: 0.8981 r:0.4410
ro_en Dev loss: 0.4072 r:0.8081
et_en Dev loss: 0.5195 r:0.6408
si_en Dev loss: 0.9964 r:0.5328
ne_en Dev loss: 0.6535 r:0.7210
ru_en Dev loss: 0.7703 r:0.6545
Current avg r:0.5700 Best avg r: 0.6192
08:07:44,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:02,911 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:34,677 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1637
en_de Dev loss: 0.9264 r:0.2058
en_zh Dev loss: 0.8481 r:0.4456
ro_en Dev loss: 0.3729 r:0.8045
et_en Dev loss: 0.5342 r:0.6436
si_en Dev loss: 0.9226 r:0.5245
ne_en Dev loss: 0.5710 r:0.7189
ru_en Dev loss: 0.7053 r:0.6478
Current avg r:0.5701 Best avg r: 0.6192
08:14:31,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:50,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:17:22,449 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1611
en_de Dev loss: 0.9467 r:0.1749
en_zh Dev loss: 0.8484 r:0.4485
ro_en Dev loss: 0.3897 r:0.8054
et_en Dev loss: 0.5164 r:0.6445
si_en Dev loss: 0.9585 r:0.5263
ne_en Dev loss: 0.6105 r:0.7112
ru_en Dev loss: 0.7389 r:0.6439
Current avg r:0.5650 Best avg r: 0.6192
08:21:19,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:22:37,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:24:09,40 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1674
en_de Dev loss: 0.9337 r:0.1954
en_zh Dev loss: 0.8704 r:0.4437
ro_en Dev loss: 0.4184 r:0.8036
et_en Dev loss: 0.5297 r:0.6340
si_en Dev loss: 1.0874 r:0.5220
ne_en Dev loss: 0.6238 r:0.7139
ru_en Dev loss: 0.8005 r:0.6362
Current avg r:0.5641 Best avg r: 0.6192
08:28:03,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:29:21,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:52,801 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1555
en_de Dev loss: 0.9171 r:0.2004
en_zh Dev loss: 0.8328 r:0.4495
ro_en Dev loss: 0.3636 r:0.8116
et_en Dev loss: 0.4974 r:0.6421
si_en Dev loss: 0.9829 r:0.5285
ne_en Dev loss: 0.6249 r:0.7198
ru_en Dev loss: 0.7607 r:0.6416
Current avg r:0.5705 Best avg r: 0.6192
08:34:47,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:05,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:37:36,530 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1606
en_de Dev loss: 0.9215 r:0.1957
en_zh Dev loss: 0.8338 r:0.4500
ro_en Dev loss: 0.3627 r:0.8115
et_en Dev loss: 0.5086 r:0.6500
si_en Dev loss: 0.8775 r:0.5342
ne_en Dev loss: 0.4965 r:0.7180
ru_en Dev loss: 0.6948 r:0.6611
Current avg r:0.5744 Best avg r: 0.6192
08:41:30,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:48,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:44:20,101 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1606
en_de Dev loss: 0.9315 r:0.2056
en_zh Dev loss: 0.8645 r:0.4441
ro_en Dev loss: 0.4070 r:0.8066
et_en Dev loss: 0.5389 r:0.6399
si_en Dev loss: 1.0657 r:0.5193
ne_en Dev loss: 0.6511 r:0.7170
ru_en Dev loss: 0.7885 r:0.6464
Current avg r:0.5684 Best avg r: 0.6192
08:48:14,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:49:32,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:51:03,674 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1652
en_de Dev loss: 0.9253 r:0.1868
en_zh Dev loss: 0.8777 r:0.4349
ro_en Dev loss: 0.3671 r:0.8071
et_en Dev loss: 0.4874 r:0.6436
si_en Dev loss: 1.0005 r:0.5214
ne_en Dev loss: 0.5630 r:0.7191
ru_en Dev loss: 0.7612 r:0.6410
Current avg r:0.5648 Best avg r: 0.6192
08:54:57,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:56:15,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:57:47,69 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1543
en_de Dev loss: 0.9111 r:0.2058
en_zh Dev loss: 0.7788 r:0.4551
ro_en Dev loss: 0.3594 r:0.8099
et_en Dev loss: 0.4836 r:0.6474
si_en Dev loss: 0.8876 r:0.5273
ne_en Dev loss: 0.5947 r:0.7224
ru_en Dev loss: 0.6835 r:0.6584
Current avg r:0.5752 Best avg r: 0.6192
09:01:42,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:03:00,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:04:32,800 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1626
en_de Dev loss: 0.9082 r:0.1790
en_zh Dev loss: 0.8305 r:0.4426
ro_en Dev loss: 0.3842 r:0.8073
et_en Dev loss: 0.5082 r:0.6407
si_en Dev loss: 1.0220 r:0.5164
ne_en Dev loss: 0.6607 r:0.7263
ru_en Dev loss: 0.7764 r:0.6394
Current avg r:0.5645 Best avg r: 0.6192
09:08:29,781 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:48,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:20,553 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1591
en_de Dev loss: 0.8902 r:0.2177
en_zh Dev loss: 0.7916 r:0.4603
ro_en Dev loss: 0.3592 r:0.8110
et_en Dev loss: 0.5047 r:0.6526
si_en Dev loss: 0.9360 r:0.5300
ne_en Dev loss: 0.5313 r:0.7205
ru_en Dev loss: 0.6985 r:0.6625
Current avg r:0.5792 Best avg r: 0.6192
09:15:17,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:16:36,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:18:08,113 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1562
en_de Dev loss: 0.9535 r:0.1920
en_zh Dev loss: 0.8799 r:0.4452
ro_en Dev loss: 0.4088 r:0.8069
et_en Dev loss: 0.5324 r:0.6355
si_en Dev loss: 1.0625 r:0.5155
ne_en Dev loss: 0.7463 r:0.7163
ru_en Dev loss: 0.8309 r:0.6344
Current avg r:0.5637 Best avg r: 0.6192
09:22:07,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:23:26,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:24:57,330 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1430
en_de Dev loss: 0.9515 r:0.1921
en_zh Dev loss: 0.9169 r:0.4444
ro_en Dev loss: 0.4337 r:0.8053
et_en Dev loss: 0.5122 r:0.6402
si_en Dev loss: 1.0916 r:0.5209
ne_en Dev loss: 0.7139 r:0.7232
ru_en Dev loss: 0.8320 r:0.6454
Current avg r:0.5674 Best avg r: 0.6192
09:28:51,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:09,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:31:41,1 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1436
en_de Dev loss: 0.8795 r:0.2110
en_zh Dev loss: 0.8023 r:0.4504
ro_en Dev loss: 0.3615 r:0.8110
et_en Dev loss: 0.4906 r:0.6518
si_en Dev loss: 0.9208 r:0.5295
ne_en Dev loss: 0.5772 r:0.7254
ru_en Dev loss: 0.6611 r:0.6653
Current avg r:0.5778 Best avg r: 0.6192
09:35:35,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:36:53,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:38:24,675 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1426
en_de Dev loss: 0.9180 r:0.1782
en_zh Dev loss: 0.8323 r:0.4434
ro_en Dev loss: 0.3716 r:0.8121
et_en Dev loss: 0.5382 r:0.6471
si_en Dev loss: 0.9226 r:0.5311
ne_en Dev loss: 0.5849 r:0.7164
ru_en Dev loss: 0.6778 r:0.6613
Current avg r:0.5700 Best avg r: 0.6192
09:42:18,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:37,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:45:08,278 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1469
en_de Dev loss: 0.9314 r:0.2147
en_zh Dev loss: 0.8825 r:0.4367
ro_en Dev loss: 0.3995 r:0.8110
et_en Dev loss: 0.5208 r:0.6463
si_en Dev loss: 0.9745 r:0.5307
ne_en Dev loss: 0.6231 r:0.7152
ru_en Dev loss: 0.7398 r:0.6641
Current avg r:0.5741 Best avg r: 0.6192
09:49:02,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:50:20,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:51,887 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1362
en_de Dev loss: 0.9117 r:0.2217
en_zh Dev loss: 0.8375 r:0.4438
ro_en Dev loss: 0.3857 r:0.8086
et_en Dev loss: 0.4997 r:0.6478
si_en Dev loss: 0.9465 r:0.5269
ne_en Dev loss: 0.5648 r:0.7192
ru_en Dev loss: 0.7016 r:0.6558
Current avg r:0.5748 Best avg r: 0.6192
09:55:45,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:04,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:35,388 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1437
en_de Dev loss: 0.9407 r:0.1961
en_zh Dev loss: 0.8612 r:0.4461
ro_en Dev loss: 0.3744 r:0.8119
et_en Dev loss: 0.4918 r:0.6513
si_en Dev loss: 0.9062 r:0.5343
ne_en Dev loss: 0.5664 r:0.7166
ru_en Dev loss: 0.7251 r:0.6581
Current avg r:0.5735 Best avg r: 0.6192
10:02:29,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:03:47,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:18,390 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1459
en_de Dev loss: 0.9757 r:0.1829
en_zh Dev loss: 0.8760 r:0.4391
ro_en Dev loss: 0.4046 r:0.8049
et_en Dev loss: 0.5036 r:0.6440
si_en Dev loss: 0.9971 r:0.5194
ne_en Dev loss: 0.6138 r:0.7200
ru_en Dev loss: 0.7415 r:0.6600
Current avg r:0.5672 Best avg r: 0.6192
10:09:11,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:30,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:01,43 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1530
en_de Dev loss: 0.9530 r:0.1847
en_zh Dev loss: 0.8077 r:0.4548
ro_en Dev loss: 0.3952 r:0.8058
et_en Dev loss: 0.5057 r:0.6441
si_en Dev loss: 0.9397 r:0.5206
ne_en Dev loss: 0.5886 r:0.7154
ru_en Dev loss: 0.6927 r:0.6669
Current avg r:0.5703 Best avg r: 0.6192
10:15:54,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:17:12,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:18:43,693 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1484
en_de Dev loss: 0.9159 r:0.2083
en_zh Dev loss: 0.8464 r:0.4439
ro_en Dev loss: 0.3831 r:0.8055
et_en Dev loss: 0.5014 r:0.6429
si_en Dev loss: 0.9373 r:0.5249
ne_en Dev loss: 0.6024 r:0.7130
ru_en Dev loss: 0.6884 r:0.6699
Current avg r:0.5726 Best avg r: 0.6192
10:22:36,832 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:23:54,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:25:25,867 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1427
en_de Dev loss: 0.9440 r:0.2146
en_zh Dev loss: 0.8789 r:0.4432
ro_en Dev loss: 0.3727 r:0.8097
et_en Dev loss: 0.5115 r:0.6425
si_en Dev loss: 0.9759 r:0.5258
ne_en Dev loss: 0.5819 r:0.7131
ru_en Dev loss: 0.7134 r:0.6678
Current avg r:0.5738 Best avg r: 0.6192
10:29:19,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:30:37,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:32:08,673 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1430
en_de Dev loss: 0.9229 r:0.2104
en_zh Dev loss: 0.8385 r:0.4435
ro_en Dev loss: 0.3837 r:0.8064
et_en Dev loss: 0.5075 r:0.6460
si_en Dev loss: 0.9957 r:0.5199
ne_en Dev loss: 0.5907 r:0.7195
ru_en Dev loss: 0.7060 r:0.6625
Current avg r:0.5726 Best avg r: 0.6192
10:36:02,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:37:20,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:38:51,433 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1438
en_de Dev loss: 0.9300 r:0.2106
en_zh Dev loss: 0.8846 r:0.4416
ro_en Dev loss: 0.4123 r:0.8063
et_en Dev loss: 0.5455 r:0.6430
si_en Dev loss: 1.0678 r:0.5195
ne_en Dev loss: 0.6588 r:0.7166
ru_en Dev loss: 0.8207 r:0.6450
Current avg r:0.5689 Best avg r: 0.6192
10:42:44,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:44:03,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
