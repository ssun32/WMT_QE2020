14:54:36,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:01,721 root INFO 
id:en_zh cur r: 0.2666 best r: 0.2666
14:55:14,571 root INFO 
id:ro_en cur r: 0.4217 best r: 0.4217
14:55:27,436 root INFO 
id:et_en cur r: 0.3475 best r: 0.3475
14:55:40,314 root INFO 
id:ne_en cur r: 0.5151 best r: 0.5151
14:55:53,120 root INFO 
id:ru_en cur r: 0.4270 best r: 0.4270
14:55:53,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:23,21 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
14:57:23,27 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:57:23,33 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:57:23,38 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
14:57:23,43 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
14:57:23,49 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:57:23,55 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:57:35,948 root INFO Epoch 0 Global steps: 600 Train loss: 0.8799
en_de Dev loss: 0.8946 r:0.0748
en_zh Dev loss: 0.7917 r:0.2625
ro_en Dev loss: 0.8024 r:0.4686
et_en Dev loss: 0.6569 r:0.3446
si_en Dev loss: 0.8144 r:0.3738
ne_en Dev loss: 0.7319 r:0.5040
ru_en Dev loss: 0.7577 r:0.4084
Current avg r:0.3481 Best avg r: 0.3481
15:01:27,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:40,287 root INFO 
id:en_de cur r: 0.0931 best r: 0.0931
15:01:53,106 root INFO 
id:en_zh cur r: 0.3293 best r: 0.3293
15:02:05,970 root INFO 
id:ro_en cur r: 0.6519 best r: 0.6519
15:02:18,857 root INFO 
id:et_en cur r: 0.5711 best r: 0.5711
15:02:31,732 root INFO 
id:ne_en cur r: 0.5924 best r: 0.5924
15:02:44,543 root INFO 
id:ru_en cur r: 0.6090 best r: 0.6090
15:02:44,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:14,459 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
15:04:14,466 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:04:14,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:04:14,479 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
15:04:14,484 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
15:04:14,489 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:04:14,495 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:04:27,390 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8363
en_de Dev loss: 0.9191 r:0.1013
en_zh Dev loss: 0.7342 r:0.3263
ro_en Dev loss: 0.6514 r:0.6509
et_en Dev loss: 0.5079 r:0.5799
si_en Dev loss: 0.6765 r:0.4946
ne_en Dev loss: 0.5823 r:0.5974
ru_en Dev loss: 0.6408 r:0.5869
Current avg r:0.4768 Best avg r: 0.4768
15:08:19,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:44,849 root INFO 
id:en_zh cur r: 0.3552 best r: 0.3552
15:08:57,707 root INFO 
id:ro_en cur r: 0.6810 best r: 0.6810
15:09:10,578 root INFO 
id:et_en cur r: 0.6405 best r: 0.6405
15:09:23,465 root INFO 
id:ne_en cur r: 0.6109 best r: 0.6109
15:09:36,271 root INFO 
id:ru_en cur r: 0.6869 best r: 0.6869
15:09:36,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:06,238 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
15:11:06,249 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:11:06,259 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:11:06,265 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
15:11:06,271 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
15:11:06,275 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:11:06,281 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:11:19,175 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7382
en_de Dev loss: 0.9429 r:0.1544
en_zh Dev loss: 0.7256 r:0.3756
ro_en Dev loss: 0.5613 r:0.6742
et_en Dev loss: 0.4482 r:0.6544
si_en Dev loss: 0.6117 r:0.5342
ne_en Dev loss: 0.5299 r:0.6201
ru_en Dev loss: 0.5595 r:0.7023
Current avg r:0.5307 Best avg r: 0.5307
15:15:10,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:23,738 root INFO 
id:en_de cur r: 0.1461 best r: 0.1461
15:15:49,450 root INFO 
id:ro_en cur r: 0.6969 best r: 0.6969
15:16:02,333 root INFO 
id:et_en cur r: 0.6655 best r: 0.6655
15:16:15,225 root INFO 
id:ne_en cur r: 0.6384 best r: 0.6384
15:16:28,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:58,22 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7054
en_de Dev loss: 0.9578 r:0.1468
en_zh Dev loss: 0.7899 r:0.3437
ro_en Dev loss: 0.5309 r:0.7076
et_en Dev loss: 0.4283 r:0.6759
si_en Dev loss: 0.6568 r:0.5276
ne_en Dev loss: 0.6075 r:0.6190
ru_en Dev loss: 0.5671 r:0.6921
Current avg r:0.5304 Best avg r: 0.5307
15:21:49,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:15,293 root INFO 
id:en_zh cur r: 0.3648 best r: 0.3648
15:22:28,150 root INFO 
id:ro_en cur r: 0.7244 best r: 0.7244
15:22:41,29 root INFO 
id:et_en cur r: 0.6914 best r: 0.6914
15:22:53,916 root INFO 
id:ne_en cur r: 0.6853 best r: 0.6853
15:23:06,727 root INFO 
id:ru_en cur r: 0.7026 best r: 0.7026
15:23:06,727 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:36,670 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
15:24:36,677 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:24:36,683 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:24:36,688 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
15:24:36,693 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
15:24:36,698 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:24:36,703 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:24:49,587 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6234
en_de Dev loss: 0.9158 r:0.1560
en_zh Dev loss: 0.7266 r:0.3790
ro_en Dev loss: 0.4240 r:0.7299
et_en Dev loss: 0.3724 r:0.6947
si_en Dev loss: 0.5894 r:0.5435
ne_en Dev loss: 0.4831 r:0.6781
ru_en Dev loss: 0.4809 r:0.7104
Current avg r:0.5559 Best avg r: 0.5559
15:28:40,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:19,466 root INFO 
id:ro_en cur r: 0.7432 best r: 0.7432
15:29:32,347 root INFO 
id:et_en cur r: 0.7034 best r: 0.7034
15:29:45,256 root INFO 
id:ne_en cur r: 0.7185 best r: 0.7185
15:29:58,70 root INFO 
id:ru_en cur r: 0.7101 best r: 0.7101
15:29:58,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:28,13 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
15:31:28,20 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:31:28,26 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:31:28,34 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
15:31:28,38 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
15:31:28,44 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:31:28,50 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:31:40,940 root INFO Epoch 0 Global steps: 3600 Train loss: 0.5533
en_de Dev loss: 0.9068 r:0.1531
en_zh Dev loss: 0.7258 r:0.3619
ro_en Dev loss: 0.3944 r:0.7373
et_en Dev loss: 0.3668 r:0.7105
si_en Dev loss: 0.5666 r:0.5772
ne_en Dev loss: 0.4047 r:0.7083
ru_en Dev loss: 0.4121 r:0.7131
Current avg r:0.5659 Best avg r: 0.5659
15:35:32,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:10,857 root INFO 
id:ro_en cur r: 0.7538 best r: 0.7538
15:36:49,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:19,438 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5992
en_de Dev loss: 0.9258 r:0.1445
en_zh Dev loss: 0.7880 r:0.3526
ro_en Dev loss: 0.4195 r:0.7543
et_en Dev loss: 0.3632 r:0.7043
si_en Dev loss: 0.5842 r:0.5579
ne_en Dev loss: 0.5071 r:0.6943
ru_en Dev loss: 0.5254 r:0.6733
Current avg r:0.5545 Best avg r: 0.5659
15:42:10,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:23,464 root INFO 
id:en_de cur r: 0.1609 best r: 0.1609
15:43:02,23 root INFO 
id:et_en cur r: 0.7047 best r: 0.7047
15:43:27,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:57,702 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
15:44:57,708 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:44:57,713 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:44:57,718 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
15:44:57,723 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
15:44:57,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:44:57,733 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:45:10,644 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5821
en_de Dev loss: 0.8996 r:0.1584
en_zh Dev loss: 0.7571 r:0.3737
ro_en Dev loss: 0.3963 r:0.7482
et_en Dev loss: 0.3483 r:0.7124
si_en Dev loss: 0.5571 r:0.5662
ne_en Dev loss: 0.4253 r:0.7042
ru_en Dev loss: 0.4537 r:0.7034
Current avg r:0.5666 Best avg r: 0.5666
15:49:02,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:14,873 root INFO 
id:en_de cur r: 0.1860 best r: 0.1860
15:49:27,706 root INFO 
id:en_zh cur r: 0.4085 best r: 0.4085
15:49:40,564 root INFO 
id:ro_en cur r: 0.7765 best r: 0.7765
15:49:53,442 root INFO 
id:et_en cur r: 0.7049 best r: 0.7049
15:50:06,331 root INFO 
id:ne_en cur r: 0.7238 best r: 0.7238
15:50:19,154 root INFO 
id:ru_en cur r: 0.7143 best r: 0.7143
15:50:19,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:49,118 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
15:51:49,125 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:51:49,130 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:51:49,135 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
15:51:49,140 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
15:51:49,145 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:51:49,150 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:52:02,51 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5493
en_de Dev loss: 0.8756 r:0.1773
en_zh Dev loss: 0.7021 r:0.4120
ro_en Dev loss: 0.4258 r:0.7785
et_en Dev loss: 0.3746 r:0.7067
si_en Dev loss: 0.5794 r:0.5669
ne_en Dev loss: 0.5240 r:0.7139
ru_en Dev loss: 0.4581 r:0.7298
Current avg r:0.5836 Best avg r: 0.5836
15:55:53,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:19,236 root INFO 
id:en_zh cur r: 0.4194 best r: 0.4194
15:56:32,106 root INFO 
id:ro_en cur r: 0.8021 best r: 0.8021
15:56:44,987 root INFO 
id:et_en cur r: 0.7167 best r: 0.7167
15:56:57,878 root INFO 
id:ne_en cur r: 0.7430 best r: 0.7430
15:57:10,688 root INFO 
id:ru_en cur r: 0.7279 best r: 0.7279
15:57:10,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:40,704 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
15:58:40,710 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:58:40,717 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:58:40,723 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
15:58:40,730 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
15:58:40,735 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:58:40,740 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:58:53,627 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5642
en_de Dev loss: 0.8739 r:0.1773
en_zh Dev loss: 0.6842 r:0.4193
ro_en Dev loss: 0.3237 r:0.7943
et_en Dev loss: 0.3552 r:0.7197
si_en Dev loss: 0.5386 r:0.5943
ne_en Dev loss: 0.3947 r:0.7364
ru_en Dev loss: 0.4043 r:0.7360
Current avg r:0.5968 Best avg r: 0.5968
16:02:45,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:10,750 root INFO 
id:en_zh cur r: 0.4293 best r: 0.4293
16:03:36,537 root INFO 
id:et_en cur r: 0.7185 best r: 0.7185
16:03:49,447 root INFO 
id:ne_en cur r: 0.7471 best r: 0.7471
16:04:02,271 root INFO 
id:ru_en cur r: 0.7436 best r: 0.7436
16:04:02,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:32,341 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
16:05:32,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:05:32,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:05:32,358 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
16:05:32,363 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
16:05:32,368 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:05:32,373 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:05:45,279 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5002
en_de Dev loss: 0.8794 r:0.1822
en_zh Dev loss: 0.6971 r:0.4280
ro_en Dev loss: 0.3714 r:0.7920
et_en Dev loss: 0.3649 r:0.7190
si_en Dev loss: 0.5559 r:0.5887
ne_en Dev loss: 0.3872 r:0.7420
ru_en Dev loss: 0.4070 r:0.7486
Current avg r:0.6001 Best avg r: 0.6001
16:09:36,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:53,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:23,607 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5334
en_de Dev loss: 0.8646 r:0.1827
en_zh Dev loss: 0.7248 r:0.4207
ro_en Dev loss: 0.3733 r:0.7945
et_en Dev loss: 0.3798 r:0.7070
si_en Dev loss: 0.5986 r:0.5697
ne_en Dev loss: 0.5548 r:0.7288
ru_en Dev loss: 0.5032 r:0.7193
Current avg r:0.5890 Best avg r: 0.6001
16:16:15,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:28,242 root INFO 
id:en_de cur r: 0.2039 best r: 0.2039
16:16:41,73 root INFO 
id:en_zh cur r: 0.4350 best r: 0.4350
16:17:19,717 root INFO 
id:ne_en cur r: 0.7480 best r: 0.7480
16:17:32,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:02,441 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
16:19:02,448 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:19:02,455 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:19:02,459 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
16:19:02,464 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
16:19:02,469 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:19:02,475 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:19:15,363 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5554
en_de Dev loss: 0.8555 r:0.1983
en_zh Dev loss: 0.6834 r:0.4364
ro_en Dev loss: 0.3350 r:0.7946
et_en Dev loss: 0.3511 r:0.7132
si_en Dev loss: 0.5357 r:0.5910
ne_en Dev loss: 0.4195 r:0.7416
ru_en Dev loss: 0.4204 r:0.7320
Current avg r:0.6010 Best avg r: 0.6010
16:23:07,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:20,299 root INFO 
id:en_de cur r: 0.2044 best r: 0.2044
16:23:33,132 root INFO 
id:en_zh cur r: 0.4398 best r: 0.4398
16:23:45,993 root INFO 
id:ro_en cur r: 0.8050 best r: 0.8050
16:24:11,764 root INFO 
id:ne_en cur r: 0.7583 best r: 0.7583
16:24:24,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:54,606 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
16:25:54,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:25:54,618 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:25:54,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
16:25:54,630 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
16:25:54,635 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:25:54,640 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:26:07,517 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5022
en_de Dev loss: 0.8592 r:0.1932
en_zh Dev loss: 0.6885 r:0.4404
ro_en Dev loss: 0.3274 r:0.8031
et_en Dev loss: 0.3538 r:0.7154
si_en Dev loss: 0.5508 r:0.5857
ne_en Dev loss: 0.4740 r:0.7493
ru_en Dev loss: 0.4304 r:0.7327
Current avg r:0.6028 Best avg r: 0.6028
16:29:59,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:12,235 root INFO 
id:en_de cur r: 0.2076 best r: 0.2076
16:30:37,913 root INFO 
id:ro_en cur r: 0.8112 best r: 0.8112
16:31:03,673 root INFO 
id:ne_en cur r: 0.7649 best r: 0.7649
16:31:16,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:32:46,499 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
16:32:46,507 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:32:46,514 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:32:46,520 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
16:32:46,525 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
16:32:46,531 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:32:46,540 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:32:59,417 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5363
en_de Dev loss: 0.8543 r:0.1964
en_zh Dev loss: 0.6830 r:0.4390
ro_en Dev loss: 0.3333 r:0.8056
et_en Dev loss: 0.3838 r:0.7248
si_en Dev loss: 0.5609 r:0.6049
ne_en Dev loss: 0.3503 r:0.7622
ru_en Dev loss: 0.3942 r:0.7291
Current avg r:0.6089 Best avg r: 0.6089
16:36:52,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:09,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:39,900 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5048
en_de Dev loss: 0.8754 r:0.1879
en_zh Dev loss: 0.7508 r:0.4272
ro_en Dev loss: 0.3887 r:0.8045
et_en Dev loss: 0.3727 r:0.7128
si_en Dev loss: 0.5676 r:0.5913
ne_en Dev loss: 0.4025 r:0.7565
ru_en Dev loss: 0.4741 r:0.7138
Current avg r:0.5991 Best avg r: 0.6089
16:43:31,558 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:44,408 root INFO 
id:en_de cur r: 0.2265 best r: 0.2265
16:44:10,73 root INFO 
id:ro_en cur r: 0.8134 best r: 0.8134
16:44:48,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:18,658 root INFO Epoch 1 Global steps: 10200 Train loss: 0.4936
en_de Dev loss: 0.8532 r:0.1992
en_zh Dev loss: 0.6862 r:0.4334
ro_en Dev loss: 0.3055 r:0.8092
et_en Dev loss: 0.3580 r:0.7098
si_en Dev loss: 0.5305 r:0.5960
ne_en Dev loss: 0.3896 r:0.7548
ru_en Dev loss: 0.4401 r:0.7013
Current avg r:0.6005 Best avg r: 0.6089
16:50:10,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:48,857 root INFO 
id:ro_en cur r: 0.8138 best r: 0.8138
16:51:27,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:57,363 root INFO Epoch 1 Global steps: 10800 Train loss: 0.4736
en_de Dev loss: 0.8618 r:0.1893
en_zh Dev loss: 0.6935 r:0.4437
ro_en Dev loss: 0.3464 r:0.8108
et_en Dev loss: 0.3671 r:0.7145
si_en Dev loss: 0.5563 r:0.5912
ne_en Dev loss: 0.4766 r:0.7576
ru_en Dev loss: 0.4647 r:0.7108
Current avg r:0.6025 Best avg r: 0.6089
16:56:48,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:05,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:35,818 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4762
en_de Dev loss: 0.8751 r:0.1773
en_zh Dev loss: 0.8287 r:0.4256
ro_en Dev loss: 0.3925 r:0.8080
et_en Dev loss: 0.3850 r:0.7089
si_en Dev loss: 0.6058 r:0.5803
ne_en Dev loss: 0.4814 r:0.7512
ru_en Dev loss: 0.5706 r:0.6961
Current avg r:0.5925 Best avg r: 0.6089
17:03:27,403 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:53,95 root INFO 
id:en_zh cur r: 0.4489 best r: 0.4489
17:04:05,958 root INFO 
id:ro_en cur r: 0.8244 best r: 0.8244
17:04:18,825 root INFO 
id:et_en cur r: 0.7215 best r: 0.7215
17:04:44,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:14,469 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4798
en_de Dev loss: 0.8702 r:0.1941
en_zh Dev loss: 0.7447 r:0.4466
ro_en Dev loss: 0.3215 r:0.8198
et_en Dev loss: 0.3490 r:0.7201
si_en Dev loss: 0.5340 r:0.6033
ne_en Dev loss: 0.3979 r:0.7595
ru_en Dev loss: 0.4907 r:0.6987
Current avg r:0.6060 Best avg r: 0.6089
17:10:06,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:23,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:53,570 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
17:12:53,577 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:12:53,584 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:12:53,589 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
17:12:53,594 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
17:12:53,600 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:12:53,605 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:13:06,489 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4955
en_de Dev loss: 0.8584 r:0.1954
en_zh Dev loss: 0.7275 r:0.4435
ro_en Dev loss: 0.3715 r:0.8125
et_en Dev loss: 0.3650 r:0.7242
si_en Dev loss: 0.5448 r:0.5992
ne_en Dev loss: 0.4032 r:0.7633
ru_en Dev loss: 0.4531 r:0.7290
Current avg r:0.6096 Best avg r: 0.6096
17:16:57,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:02,159 root INFO 
id:ne_en cur r: 0.7652 best r: 0.7652
17:18:14,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:44,922 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
17:19:44,929 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:19:44,935 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:19:44,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
17:19:44,947 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
17:19:44,953 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:19:44,959 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:19:57,841 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4842
en_de Dev loss: 0.8592 r:0.2032
en_zh Dev loss: 0.6938 r:0.4467
ro_en Dev loss: 0.3199 r:0.8147
et_en Dev loss: 0.3430 r:0.7216
si_en Dev loss: 0.5300 r:0.5976
ne_en Dev loss: 0.3962 r:0.7652
ru_en Dev loss: 0.4225 r:0.7306
Current avg r:0.6114 Best avg r: 0.6114
17:23:49,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:15,507 root INFO 
id:en_zh cur r: 0.4757 best r: 0.4757
17:24:54,152 root INFO 
id:ne_en cur r: 0.7694 best r: 0.7694
17:25:06,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:36,930 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
17:26:36,938 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:26:36,943 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:26:36,948 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
17:26:36,956 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
17:26:36,961 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:26:36,966 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:26:49,865 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4674
en_de Dev loss: 0.8601 r:0.1946
en_zh Dev loss: 0.6535 r:0.4777
ro_en Dev loss: 0.3292 r:0.8172
et_en Dev loss: 0.3558 r:0.7207
si_en Dev loss: 0.5268 r:0.6030
ne_en Dev loss: 0.3619 r:0.7672
ru_en Dev loss: 0.4263 r:0.7382
Current avg r:0.6170 Best avg r: 0.6170
17:30:41,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:46,207 root INFO 
id:ne_en cur r: 0.7708 best r: 0.7708
17:31:59,14 root INFO 
id:ru_en cur r: 0.7455 best r: 0.7455
17:31:59,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:28,942 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
17:33:28,988 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:33:28,993 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:33:28,998 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
17:33:29,3 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
17:33:29,8 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:33:29,13 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:33:41,895 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4725
en_de Dev loss: 0.8483 r:0.2175
en_zh Dev loss: 0.6899 r:0.4565
ro_en Dev loss: 0.2923 r:0.8201
et_en Dev loss: 0.3407 r:0.7244
si_en Dev loss: 0.5219 r:0.6005
ne_en Dev loss: 0.3439 r:0.7700
ru_en Dev loss: 0.3838 r:0.7487
Current avg r:0.6197 Best avg r: 0.6197
17:37:33,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:11,915 root INFO 
id:ro_en cur r: 0.8254 best r: 0.8254
17:38:50,499 root INFO 
id:ru_en cur r: 0.7456 best r: 0.7456
17:38:50,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:20,455 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
17:40:20,468 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:40:20,474 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:40:20,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
17:40:20,487 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
17:40:20,492 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:40:20,497 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:40:33,365 root INFO Epoch 1 Global steps: 15000 Train loss: 0.5090
en_de Dev loss: 0.8558 r:0.2178
en_zh Dev loss: 0.6961 r:0.4670
ro_en Dev loss: 0.3183 r:0.8227
et_en Dev loss: 0.3528 r:0.7248
si_en Dev loss: 0.5230 r:0.6123
ne_en Dev loss: 0.3709 r:0.7682
ru_en Dev loss: 0.4099 r:0.7530
Current avg r:0.6237 Best avg r: 0.6237
17:44:25,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:42,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:12,115 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4324
en_de Dev loss: 0.8633 r:0.2310
en_zh Dev loss: 0.7514 r:0.4495
ro_en Dev loss: 0.3588 r:0.8169
et_en Dev loss: 0.3917 r:0.7136
si_en Dev loss: 0.5744 r:0.5904
ne_en Dev loss: 0.4385 r:0.7613
ru_en Dev loss: 0.4956 r:0.7151
Current avg r:0.6111 Best avg r: 0.6237
17:51:03,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:16,689 root INFO 
id:en_de cur r: 0.2322 best r: 0.2322
17:51:42,391 root INFO 
id:ro_en cur r: 0.8257 best r: 0.8257
17:51:55,260 root INFO 
id:et_en cur r: 0.7280 best r: 0.7280
17:52:08,135 root INFO 
id:ne_en cur r: 0.7760 best r: 0.7760
17:52:20,945 root INFO 
id:ru_en cur r: 0.7464 best r: 0.7464
17:52:20,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:50,956 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_de.lang_agnost_mlp.dev.best.scores
17:53:50,963 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:53:50,968 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:53:50,974 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/et_en.lang_agnost_mlp.dev.best.scores
17:53:50,979 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/si_en.lang_agnost_mlp.dev.best.scores
17:53:50,983 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:53:50,988 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:54:03,882 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4473
en_de Dev loss: 0.8506 r:0.2301
en_zh Dev loss: 0.6797 r:0.4687
ro_en Dev loss: 0.3287 r:0.8206
et_en Dev loss: 0.3614 r:0.7280
si_en Dev loss: 0.5394 r:0.6043
ne_en Dev loss: 0.3568 r:0.7746
ru_en Dev loss: 0.4065 r:0.7446
Current avg r:0.6244 Best avg r: 0.6244
17:57:55,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:12,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:42,419 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4447
en_de Dev loss: 0.8562 r:0.1907
en_zh Dev loss: 0.7015 r:0.4512
ro_en Dev loss: 0.3223 r:0.8186
et_en Dev loss: 0.3451 r:0.7214
si_en Dev loss: 0.5454 r:0.5975
ne_en Dev loss: 0.3891 r:0.7673
ru_en Dev loss: 0.4337 r:0.7452
Current avg r:0.6131 Best avg r: 0.6244
18:04:33,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:50,813 root INFO 
id:ru_en cur r: 0.7543 best r: 0.7543
18:05:50,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:20,674 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4994
en_de Dev loss: 0.8542 r:0.1971
en_zh Dev loss: 0.7083 r:0.4542
ro_en Dev loss: 0.3225 r:0.8184
et_en Dev loss: 0.3660 r:0.7219
si_en Dev loss: 0.5355 r:0.6062
ne_en Dev loss: 0.3721 r:0.7664
ru_en Dev loss: 0.4002 r:0.7575
Current avg r:0.6174 Best avg r: 0.6244
18:11:11,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:28,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:58,783 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4531
en_de Dev loss: 0.8533 r:0.2083
en_zh Dev loss: 0.6855 r:0.4617
ro_en Dev loss: 0.3136 r:0.8193
et_en Dev loss: 0.3454 r:0.7239
si_en Dev loss: 0.5529 r:0.5950
ne_en Dev loss: 0.4334 r:0.7667
ru_en Dev loss: 0.3953 r:0.7550
Current avg r:0.6186 Best avg r: 0.6244
18:17:51,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:08,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:38,400 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4129
en_de Dev loss: 0.8580 r:0.2089
en_zh Dev loss: 0.6919 r:0.4610
ro_en Dev loss: 0.3252 r:0.8144
et_en Dev loss: 0.3579 r:0.7149
si_en Dev loss: 0.5889 r:0.5835
ne_en Dev loss: 0.4823 r:0.7582
ru_en Dev loss: 0.4743 r:0.7240
Current avg r:0.6093 Best avg r: 0.6244
18:24:29,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:46,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:16,857 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4297
en_de Dev loss: 0.8684 r:0.1921
en_zh Dev loss: 0.7065 r:0.4624
ro_en Dev loss: 0.3353 r:0.8175
et_en Dev loss: 0.3746 r:0.7101
si_en Dev loss: 0.5952 r:0.5853
ne_en Dev loss: 0.5198 r:0.7611
ru_en Dev loss: 0.4622 r:0.7278
Current avg r:0.6080 Best avg r: 0.6244
18:31:08,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:25,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:55,660 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4375
en_de Dev loss: 0.8664 r:0.2053
en_zh Dev loss: 0.8335 r:0.4174
ro_en Dev loss: 0.3947 r:0.8081
et_en Dev loss: 0.4114 r:0.7004
si_en Dev loss: 0.6926 r:0.5614
ne_en Dev loss: 0.6361 r:0.7485
ru_en Dev loss: 0.5075 r:0.7139
Current avg r:0.5936 Best avg r: 0.6244
18:37:47,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:04,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:34,386 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4246
en_de Dev loss: 0.8510 r:0.2138
en_zh Dev loss: 0.7497 r:0.4391
ro_en Dev loss: 0.3315 r:0.8182
et_en Dev loss: 0.3684 r:0.7156
si_en Dev loss: 0.5807 r:0.5862
ne_en Dev loss: 0.4120 r:0.7633
ru_en Dev loss: 0.4243 r:0.7399
Current avg r:0.6109 Best avg r: 0.6244
18:44:26,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:43,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:13,301 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4300
en_de Dev loss: 0.8631 r:0.2072
en_zh Dev loss: 0.6895 r:0.4610
ro_en Dev loss: 0.3345 r:0.8201
et_en Dev loss: 0.3589 r:0.7108
si_en Dev loss: 0.5853 r:0.5803
ne_en Dev loss: 0.5344 r:0.7602
ru_en Dev loss: 0.4389 r:0.7335
Current avg r:0.6104 Best avg r: 0.6244
18:51:05,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:22,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:52,392 root INFO Epoch 2 Global steps: 21600 Train loss: 0.3960
en_de Dev loss: 0.8591 r:0.2084
en_zh Dev loss: 0.7251 r:0.4409
ro_en Dev loss: 0.3275 r:0.8165
et_en Dev loss: 0.3822 r:0.7101
si_en Dev loss: 0.5730 r:0.5851
ne_en Dev loss: 0.4263 r:0.7614
ru_en Dev loss: 0.4297 r:0.7290
Current avg r:0.6074 Best avg r: 0.6244
18:57:44,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:22,822 root INFO 
id:ro_en cur r: 0.8275 best r: 0.8275
18:59:01,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:31,332 root INFO Epoch 2 Global steps: 22200 Train loss: 0.3994
en_de Dev loss: 0.8860 r:0.2053
en_zh Dev loss: 0.7669 r:0.4644
ro_en Dev loss: 0.3838 r:0.8214
et_en Dev loss: 0.4121 r:0.7096
si_en Dev loss: 0.6172 r:0.5857
ne_en Dev loss: 0.4220 r:0.7646
ru_en Dev loss: 0.5291 r:0.7335
Current avg r:0.6121 Best avg r: 0.6244
19:04:22,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:39,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:09,686 root INFO Epoch 2 Global steps: 22800 Train loss: 0.3888
en_de Dev loss: 0.8786 r:0.1760
en_zh Dev loss: 0.7599 r:0.4458
ro_en Dev loss: 0.3543 r:0.8187
et_en Dev loss: 0.4033 r:0.6984
si_en Dev loss: 0.6083 r:0.5750
ne_en Dev loss: 0.5034 r:0.7551
ru_en Dev loss: 0.5134 r:0.7025
Current avg r:0.5959 Best avg r: 0.6244
19:11:01,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:18,80 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:48,17 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4128
en_de Dev loss: 0.8661 r:0.1903
en_zh Dev loss: 0.7530 r:0.4494
ro_en Dev loss: 0.3338 r:0.8185
et_en Dev loss: 0.3855 r:0.7004
si_en Dev loss: 0.5760 r:0.5869
ne_en Dev loss: 0.4828 r:0.7572
ru_en Dev loss: 0.4831 r:0.7126
Current avg r:0.6022 Best avg r: 0.6244
19:17:39,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:18,484 root INFO 
id:ro_en cur r: 0.8295 best r: 0.8295
19:18:57,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:26,906 root INFO Epoch 2 Global steps: 24000 Train loss: 0.3968
en_de Dev loss: 0.8568 r:0.2001
en_zh Dev loss: 0.7074 r:0.4579
ro_en Dev loss: 0.3012 r:0.8266
et_en Dev loss: 0.3674 r:0.7142
si_en Dev loss: 0.5618 r:0.5937
ne_en Dev loss: 0.3781 r:0.7663
ru_en Dev loss: 0.4396 r:0.7219
Current avg r:0.6115 Best avg r: 0.6244
19:24:18,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:43,947 root INFO 
id:en_zh cur r: 0.4812 best r: 0.4812
19:25:35,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:05,315 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4149
en_de Dev loss: 0.8748 r:0.1937
en_zh Dev loss: 0.7567 r:0.4729
ro_en Dev loss: 0.3414 r:0.8254
et_en Dev loss: 0.3834 r:0.7107
si_en Dev loss: 0.5874 r:0.5945
ne_en Dev loss: 0.3685 r:0.7715
ru_en Dev loss: 0.4601 r:0.7396
Current avg r:0.6155 Best avg r: 0.6244
19:30:56,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:13,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:43,530 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3967
en_de Dev loss: 0.8981 r:0.1943
en_zh Dev loss: 0.8110 r:0.4487
ro_en Dev loss: 0.3766 r:0.8201
et_en Dev loss: 0.3995 r:0.7031
si_en Dev loss: 0.6294 r:0.5811
ne_en Dev loss: 0.5738 r:0.7532
ru_en Dev loss: 0.5472 r:0.7125
Current avg r:0.6018 Best avg r: 0.6244
19:37:34,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:51,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:21,771 root INFO Epoch 2 Global steps: 25800 Train loss: 0.3974
en_de Dev loss: 0.8739 r:0.1993
en_zh Dev loss: 0.7767 r:0.4513
ro_en Dev loss: 0.3457 r:0.8252
et_en Dev loss: 0.4060 r:0.6998
si_en Dev loss: 0.6157 r:0.5839
ne_en Dev loss: 0.3995 r:0.7584
ru_en Dev loss: 0.4973 r:0.7211
Current avg r:0.6056 Best avg r: 0.6244
19:44:13,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:30,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:00,30 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4104
en_de Dev loss: 0.8654 r:0.1919
en_zh Dev loss: 0.6989 r:0.4699
ro_en Dev loss: 0.2932 r:0.8270
et_en Dev loss: 0.3865 r:0.7094
si_en Dev loss: 0.5449 r:0.6063
ne_en Dev loss: 0.3546 r:0.7563
ru_en Dev loss: 0.4061 r:0.7459
Current avg r:0.6152 Best avg r: 0.6244
19:50:51,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:08,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:38,142 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4135
en_de Dev loss: 0.8490 r:0.2072
en_zh Dev loss: 0.7074 r:0.4378
ro_en Dev loss: 0.2882 r:0.8233
et_en Dev loss: 0.3789 r:0.7038
si_en Dev loss: 0.5563 r:0.5864
ne_en Dev loss: 0.4423 r:0.7590
ru_en Dev loss: 0.4312 r:0.7117
Current avg r:0.6042 Best avg r: 0.6244
19:57:31,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:48,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:18,66 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3536
en_de Dev loss: 0.8802 r:0.2008
en_zh Dev loss: 0.7488 r:0.4647
ro_en Dev loss: 0.3410 r:0.8255
et_en Dev loss: 0.4227 r:0.7085
si_en Dev loss: 0.5932 r:0.6014
ne_en Dev loss: 0.4448 r:0.7602
ru_en Dev loss: 0.4824 r:0.7217
Current avg r:0.6118 Best avg r: 0.6244
20:04:09,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:35,239 root INFO 
id:en_zh cur r: 0.4853 best r: 0.4853
20:05:26,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:56,484 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3780
en_de Dev loss: 0.8763 r:0.1837
en_zh Dev loss: 0.7607 r:0.4845
ro_en Dev loss: 0.3201 r:0.8229
et_en Dev loss: 0.4341 r:0.7042
si_en Dev loss: 0.6019 r:0.6009
ne_en Dev loss: 0.3859 r:0.7580
ru_en Dev loss: 0.4220 r:0.7260
Current avg r:0.6115 Best avg r: 0.6244
20:10:47,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:04,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:34,833 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3502
en_de Dev loss: 0.8682 r:0.1924
en_zh Dev loss: 0.7756 r:0.4351
ro_en Dev loss: 0.3257 r:0.8211
et_en Dev loss: 0.4003 r:0.7008
si_en Dev loss: 0.5872 r:0.5848
ne_en Dev loss: 0.4475 r:0.7603
ru_en Dev loss: 0.4711 r:0.7127
Current avg r:0.6010 Best avg r: 0.6244
20:17:26,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:43,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:13,142 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3473
en_de Dev loss: 0.8626 r:0.1983
en_zh Dev loss: 0.7265 r:0.4465
ro_en Dev loss: 0.3119 r:0.8190
et_en Dev loss: 0.4103 r:0.6963
si_en Dev loss: 0.5780 r:0.5933
ne_en Dev loss: 0.3825 r:0.7567
ru_en Dev loss: 0.4602 r:0.7056
Current avg r:0.6022 Best avg r: 0.6244
20:24:04,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:21,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:51,875 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3405
en_de Dev loss: 0.8608 r:0.1977
en_zh Dev loss: 0.7731 r:0.4343
ro_en Dev loss: 0.3530 r:0.8170
et_en Dev loss: 0.4130 r:0.6979
si_en Dev loss: 0.5857 r:0.5873
ne_en Dev loss: 0.4412 r:0.7599
ru_en Dev loss: 0.4508 r:0.7222
Current avg r:0.6023 Best avg r: 0.6244
20:30:43,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:00,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:30,329 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3592
en_de Dev loss: 0.8618 r:0.2154
en_zh Dev loss: 0.8221 r:0.4140
ro_en Dev loss: 0.3507 r:0.8121
et_en Dev loss: 0.4155 r:0.6886
si_en Dev loss: 0.6002 r:0.5733
ne_en Dev loss: 0.4468 r:0.7556
ru_en Dev loss: 0.5038 r:0.7040
Current avg r:0.5947 Best avg r: 0.6244
20:37:21,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:39,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:09,14 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3635
en_de Dev loss: 0.8597 r:0.2111
en_zh Dev loss: 0.7460 r:0.4487
ro_en Dev loss: 0.3366 r:0.8212
et_en Dev loss: 0.3971 r:0.6977
si_en Dev loss: 0.5728 r:0.5845
ne_en Dev loss: 0.4680 r:0.7619
ru_en Dev loss: 0.4811 r:0.7162
Current avg r:0.6059 Best avg r: 0.6244
20:44:00,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:17,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:47,396 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3565
en_de Dev loss: 0.8669 r:0.2169
en_zh Dev loss: 0.8000 r:0.4430
ro_en Dev loss: 0.3890 r:0.8202
et_en Dev loss: 0.4464 r:0.6987
si_en Dev loss: 0.5932 r:0.5906
ne_en Dev loss: 0.4924 r:0.7514
ru_en Dev loss: 0.5219 r:0.7140
Current avg r:0.6050 Best avg r: 0.6244
20:50:38,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:55,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:25,827 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3703
en_de Dev loss: 0.8687 r:0.1780
en_zh Dev loss: 0.7457 r:0.4522
ro_en Dev loss: 0.3335 r:0.8253
et_en Dev loss: 0.4216 r:0.6948
si_en Dev loss: 0.5694 r:0.5889
ne_en Dev loss: 0.5332 r:0.7567
ru_en Dev loss: 0.4531 r:0.7193
Current avg r:0.6022 Best avg r: 0.6244
20:57:17,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:34,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:04,550 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3327
en_de Dev loss: 0.8607 r:0.1940
en_zh Dev loss: 0.7295 r:0.4372
ro_en Dev loss: 0.3127 r:0.8226
et_en Dev loss: 0.3953 r:0.6921
si_en Dev loss: 0.5550 r:0.5894
ne_en Dev loss: 0.5302 r:0.7545
ru_en Dev loss: 0.4630 r:0.7064
Current avg r:0.5995 Best avg r: 0.6244
21:03:56,434 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:13,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:43,546 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3332
en_de Dev loss: 0.8645 r:0.1851
en_zh Dev loss: 0.7028 r:0.4666
ro_en Dev loss: 0.2968 r:0.8251
et_en Dev loss: 0.3957 r:0.6990
si_en Dev loss: 0.5630 r:0.6010
ne_en Dev loss: 0.3759 r:0.7569
ru_en Dev loss: 0.4265 r:0.7229
Current avg r:0.6081 Best avg r: 0.6244
21:10:35,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:52,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:22,433 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3523
en_de Dev loss: 0.8684 r:0.1842
en_zh Dev loss: 0.7010 r:0.4652
ro_en Dev loss: 0.2918 r:0.8237
et_en Dev loss: 0.3899 r:0.7009
si_en Dev loss: 0.5555 r:0.6068
ne_en Dev loss: 0.3718 r:0.7596
ru_en Dev loss: 0.4039 r:0.7349
Current avg r:0.6107 Best avg r: 0.6244
21:17:14,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:31,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:01,337 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3409
en_de Dev loss: 0.8662 r:0.1988
en_zh Dev loss: 0.7022 r:0.4711
ro_en Dev loss: 0.3232 r:0.8177
et_en Dev loss: 0.4071 r:0.6883
si_en Dev loss: 0.5714 r:0.5924
ne_en Dev loss: 0.4161 r:0.7460
ru_en Dev loss: 0.4585 r:0.7122
Current avg r:0.6038 Best avg r: 0.6244
21:23:53,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:10,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:40,255 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3426
en_de Dev loss: 0.8699 r:0.1622
en_zh Dev loss: 0.7777 r:0.4425
ro_en Dev loss: 0.3384 r:0.8173
et_en Dev loss: 0.4028 r:0.6863
si_en Dev loss: 0.5794 r:0.5810
ne_en Dev loss: 0.4598 r:0.7468
ru_en Dev loss: 0.4945 r:0.7030
Current avg r:0.5913 Best avg r: 0.6244
21:30:32,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:49,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:19,80 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3597
en_de Dev loss: 0.8806 r:0.1661
en_zh Dev loss: 0.7770 r:0.4528
ro_en Dev loss: 0.3445 r:0.8196
et_en Dev loss: 0.4185 r:0.6908
si_en Dev loss: 0.5971 r:0.5816
ne_en Dev loss: 0.4930 r:0.7443
ru_en Dev loss: 0.5030 r:0.7110
Current avg r:0.5952 Best avg r: 0.6244
21:37:11,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:29,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:59,87 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3241
en_de Dev loss: 0.8725 r:0.1780
en_zh Dev loss: 0.7615 r:0.4554
ro_en Dev loss: 0.3457 r:0.8153
et_en Dev loss: 0.4287 r:0.6930
si_en Dev loss: 0.5947 r:0.5842
ne_en Dev loss: 0.4473 r:0.7420
ru_en Dev loss: 0.4831 r:0.7119
Current avg r:0.5971 Best avg r: 0.6244
21:43:51,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:08,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:38,100 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3062
en_de Dev loss: 0.8800 r:0.1384
en_zh Dev loss: 0.7721 r:0.4319
ro_en Dev loss: 0.3373 r:0.8141
et_en Dev loss: 0.4350 r:0.6767
si_en Dev loss: 0.5934 r:0.5778
ne_en Dev loss: 0.4587 r:0.7401
ru_en Dev loss: 0.5251 r:0.6771
Current avg r:0.5795 Best avg r: 0.6244
21:50:29,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:46,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:16,547 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3079
en_de Dev loss: 0.8915 r:0.1650
en_zh Dev loss: 0.7712 r:0.4633
ro_en Dev loss: 0.3342 r:0.8191
et_en Dev loss: 0.4123 r:0.6937
si_en Dev loss: 0.5588 r:0.5999
ne_en Dev loss: 0.4158 r:0.7559
ru_en Dev loss: 0.4621 r:0.7266
Current avg r:0.6034 Best avg r: 0.6244
21:57:08,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:25,222 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:55,123 root INFO Epoch 4 Global steps: 38400 Train loss: 0.2920
en_de Dev loss: 0.9170 r:0.1594
en_zh Dev loss: 0.8173 r:0.4503
ro_en Dev loss: 0.3696 r:0.8176
et_en Dev loss: 0.4378 r:0.6874
si_en Dev loss: 0.5993 r:0.5895
ne_en Dev loss: 0.5040 r:0.7558
ru_en Dev loss: 0.5343 r:0.6974
Current avg r:0.5939 Best avg r: 0.6244
22:03:46,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:03,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:33,823 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3108
en_de Dev loss: 0.8862 r:0.1718
en_zh Dev loss: 0.7573 r:0.4442
ro_en Dev loss: 0.3487 r:0.8163
et_en Dev loss: 0.4139 r:0.6885
si_en Dev loss: 0.5799 r:0.5844
ne_en Dev loss: 0.5130 r:0.7527
ru_en Dev loss: 0.4864 r:0.7072
Current avg r:0.5950 Best avg r: 0.6244
22:10:25,797 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:42,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:12,934 root INFO Epoch 4 Global steps: 39600 Train loss: 0.2809
en_de Dev loss: 0.8864 r:0.1790
en_zh Dev loss: 0.7725 r:0.4610
ro_en Dev loss: 0.3505 r:0.8215
et_en Dev loss: 0.4257 r:0.7005
si_en Dev loss: 0.5720 r:0.6024
ne_en Dev loss: 0.4170 r:0.7523
ru_en Dev loss: 0.4701 r:0.7267
Current avg r:0.6062 Best avg r: 0.6244
22:17:04,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:21,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:51,936 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3014
en_de Dev loss: 0.8696 r:0.1920
en_zh Dev loss: 0.7850 r:0.4392
ro_en Dev loss: 0.3237 r:0.8210
et_en Dev loss: 0.4199 r:0.6898
si_en Dev loss: 0.5853 r:0.5860
ne_en Dev loss: 0.4444 r:0.7497
ru_en Dev loss: 0.4831 r:0.7013
Current avg r:0.5970 Best avg r: 0.6244
22:23:43,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:00,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:30,895 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3092
en_de Dev loss: 0.8858 r:0.1563
en_zh Dev loss: 0.8184 r:0.4467
ro_en Dev loss: 0.3680 r:0.8213
et_en Dev loss: 0.4466 r:0.6777
si_en Dev loss: 0.6139 r:0.5796
ne_en Dev loss: 0.4972 r:0.7468
ru_en Dev loss: 0.5437 r:0.6961
Current avg r:0.5892 Best avg r: 0.6244
22:30:22,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:39,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:33:10,149 root INFO Epoch 4 Global steps: 41400 Train loss: 0.2866
en_de Dev loss: 0.8630 r:0.1938
en_zh Dev loss: 0.7342 r:0.4692
ro_en Dev loss: 0.3254 r:0.8202
et_en Dev loss: 0.4127 r:0.6840
si_en Dev loss: 0.5835 r:0.5811
ne_en Dev loss: 0.5086 r:0.7441
ru_en Dev loss: 0.4754 r:0.7134
Current avg r:0.6008 Best avg r: 0.6244
22:37:02,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:19,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:49,61 root INFO Epoch 4 Global steps: 42000 Train loss: 0.2871
en_de Dev loss: 0.8701 r:0.1665
en_zh Dev loss: 0.7489 r:0.4503
ro_en Dev loss: 0.3207 r:0.8196
et_en Dev loss: 0.4215 r:0.6747
si_en Dev loss: 0.5878 r:0.5801
ne_en Dev loss: 0.4563 r:0.7467
ru_en Dev loss: 0.4709 r:0.7093
Current avg r:0.5924 Best avg r: 0.6244
22:43:40,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:57,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:27,542 root INFO Epoch 4 Global steps: 42600 Train loss: 0.2889
en_de Dev loss: 0.8861 r:0.1681
en_zh Dev loss: 0.7507 r:0.4645
ro_en Dev loss: 0.3508 r:0.8181
et_en Dev loss: 0.4139 r:0.6805
si_en Dev loss: 0.5854 r:0.5813
ne_en Dev loss: 0.5227 r:0.7497
ru_en Dev loss: 0.4909 r:0.7182
Current avg r:0.5972 Best avg r: 0.6244
22:50:19,27 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:36,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:06,70 root INFO Epoch 4 Global steps: 43200 Train loss: 0.2791
en_de Dev loss: 0.8654 r:0.1733
en_zh Dev loss: 0.7186 r:0.4525
ro_en Dev loss: 0.3122 r:0.8221
et_en Dev loss: 0.4607 r:0.6793
si_en Dev loss: 0.6086 r:0.5818
ne_en Dev loss: 0.4423 r:0.7472
ru_en Dev loss: 0.4230 r:0.7236
Current avg r:0.5971 Best avg r: 0.6244
22:56:58,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:15,188 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:45,136 root INFO Epoch 4 Global steps: 43800 Train loss: 0.2937
en_de Dev loss: 0.8851 r:0.1821
en_zh Dev loss: 0.7420 r:0.4681
ro_en Dev loss: 0.3129 r:0.8212
et_en Dev loss: 0.4572 r:0.6835
si_en Dev loss: 0.6019 r:0.5888
ne_en Dev loss: 0.4182 r:0.7476
ru_en Dev loss: 0.4284 r:0.7298
Current avg r:0.6030 Best avg r: 0.6244
23:03:37,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:54,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:24,271 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3090
en_de Dev loss: 0.8892 r:0.1835
en_zh Dev loss: 0.7574 r:0.4649
ro_en Dev loss: 0.3122 r:0.8199
et_en Dev loss: 0.4230 r:0.6890
si_en Dev loss: 0.5627 r:0.5936
ne_en Dev loss: 0.4413 r:0.7535
ru_en Dev loss: 0.4536 r:0.7289
Current avg r:0.6048 Best avg r: 0.6244
23:10:16,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:33,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:03,300 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3138
en_de Dev loss: 0.8904 r:0.1815
en_zh Dev loss: 0.8146 r:0.4552
ro_en Dev loss: 0.3854 r:0.8114
et_en Dev loss: 0.4640 r:0.6669
si_en Dev loss: 0.6322 r:0.5691
ne_en Dev loss: 0.5253 r:0.7412
ru_en Dev loss: 0.5459 r:0.7022
Current avg r:0.5896 Best avg r: 0.6244
23:16:56,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:13,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:43,523 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2623
en_de Dev loss: 0.8614 r:0.1996
en_zh Dev loss: 0.7868 r:0.4555
ro_en Dev loss: 0.3456 r:0.8141
et_en Dev loss: 0.4689 r:0.6812
si_en Dev loss: 0.6331 r:0.5783
ne_en Dev loss: 0.4450 r:0.7374
ru_en Dev loss: 0.4662 r:0.7199
Current avg r:0.5980 Best avg r: 0.6244
23:23:34,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:52,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:21,948 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2493
en_de Dev loss: 0.8838 r:0.1665
en_zh Dev loss: 0.7884 r:0.4575
ro_en Dev loss: 0.3552 r:0.8136
et_en Dev loss: 0.4505 r:0.6815
si_en Dev loss: 0.6216 r:0.5801
ne_en Dev loss: 0.5073 r:0.7366
ru_en Dev loss: 0.4943 r:0.7125
Current avg r:0.5926 Best avg r: 0.6244
23:30:13,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:30,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:00,333 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2590
en_de Dev loss: 0.8819 r:0.1913
en_zh Dev loss: 0.7615 r:0.4613
ro_en Dev loss: 0.3347 r:0.8128
et_en Dev loss: 0.4372 r:0.6787
si_en Dev loss: 0.6124 r:0.5823
ne_en Dev loss: 0.4841 r:0.7317
ru_en Dev loss: 0.4519 r:0.7228
Current avg r:0.5973 Best avg r: 0.6244
23:36:52,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:38:09,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:39,139 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2692
en_de Dev loss: 0.8735 r:0.2044
en_zh Dev loss: 0.7673 r:0.4628
ro_en Dev loss: 0.3583 r:0.8124
et_en Dev loss: 0.4606 r:0.6795
si_en Dev loss: 0.6181 r:0.5930
ne_en Dev loss: 0.4630 r:0.7350
ru_en Dev loss: 0.4711 r:0.7179
Current avg r:0.6007 Best avg r: 0.6244
23:43:31,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:48,174 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:18,104 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2803
en_de Dev loss: 0.8668 r:0.1896
en_zh Dev loss: 0.7788 r:0.4561
ro_en Dev loss: 0.3907 r:0.8120
et_en Dev loss: 0.4433 r:0.6732
si_en Dev loss: 0.5805 r:0.5914
ne_en Dev loss: 0.5214 r:0.7376
ru_en Dev loss: 0.4627 r:0.7241
Current avg r:0.5977 Best avg r: 0.6244
23:50:10,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:27,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:57,183 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2739
en_de Dev loss: 0.8606 r:0.2038
en_zh Dev loss: 0.7787 r:0.4514
ro_en Dev loss: 0.3572 r:0.8147
et_en Dev loss: 0.4197 r:0.6707
si_en Dev loss: 0.5836 r:0.5815
ne_en Dev loss: 0.5580 r:0.7433
ru_en Dev loss: 0.4341 r:0.7299
Current avg r:0.5993 Best avg r: 0.6244
23:56:49,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:06,422 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:36,345 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2634
en_de Dev loss: 0.8864 r:0.1923
en_zh Dev loss: 0.7986 r:0.4491
ro_en Dev loss: 0.3508 r:0.8130
et_en Dev loss: 0.4454 r:0.6762
si_en Dev loss: 0.6049 r:0.5836
ne_en Dev loss: 0.4784 r:0.7356
ru_en Dev loss: 0.4963 r:0.7095
Current avg r:0.5942 Best avg r: 0.6244
00:03:27,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:44,772 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:06:14,683 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2752
en_de Dev loss: 0.8754 r:0.1771
en_zh Dev loss: 0.7998 r:0.4424
ro_en Dev loss: 0.3545 r:0.8072
et_en Dev loss: 0.4463 r:0.6585
si_en Dev loss: 0.6044 r:0.5759
ne_en Dev loss: 0.4834 r:0.7353
ru_en Dev loss: 0.4869 r:0.7084
Current avg r:0.5864 Best avg r: 0.6244
00:10:05,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:22,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:52,950 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2734
en_de Dev loss: 0.8857 r:0.1827
en_zh Dev loss: 0.7823 r:0.4422
ro_en Dev loss: 0.3547 r:0.8087
et_en Dev loss: 0.4497 r:0.6669
si_en Dev loss: 0.6038 r:0.5871
ne_en Dev loss: 0.4644 r:0.7373
ru_en Dev loss: 0.4646 r:0.7191
Current avg r:0.5920 Best avg r: 0.6244
00:16:44,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:01,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:31,329 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2741
en_de Dev loss: 0.8830 r:0.1647
en_zh Dev loss: 0.7698 r:0.4507
ro_en Dev loss: 0.3763 r:0.8046
et_en Dev loss: 0.4668 r:0.6552
si_en Dev loss: 0.6337 r:0.5677
ne_en Dev loss: 0.6169 r:0.7333
ru_en Dev loss: 0.4889 r:0.7037
Current avg r:0.5828 Best avg r: 0.6244
00:23:22,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:39,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:26:09,643 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2675
en_de Dev loss: 0.8928 r:0.1478
en_zh Dev loss: 0.7566 r:0.4611
ro_en Dev loss: 0.3462 r:0.8117
et_en Dev loss: 0.4762 r:0.6707
si_en Dev loss: 0.6082 r:0.5892
ne_en Dev loss: 0.4355 r:0.7396
ru_en Dev loss: 0.4419 r:0.7224
Current avg r:0.5918 Best avg r: 0.6244
00:30:01,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:18,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:47,987 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2506
en_de Dev loss: 0.8987 r:0.1437
en_zh Dev loss: 0.7732 r:0.4555
ro_en Dev loss: 0.3566 r:0.8142
et_en Dev loss: 0.4667 r:0.6735
si_en Dev loss: 0.6165 r:0.5813
ne_en Dev loss: 0.4871 r:0.7361
ru_en Dev loss: 0.4687 r:0.7185
Current avg r:0.5890 Best avg r: 0.6244
00:36:39,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:56,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:26,328 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2510
en_de Dev loss: 0.8923 r:0.1723
en_zh Dev loss: 0.7551 r:0.4640
ro_en Dev loss: 0.3687 r:0.8113
et_en Dev loss: 0.4542 r:0.6692
si_en Dev loss: 0.6095 r:0.5792
ne_en Dev loss: 0.5035 r:0.7371
ru_en Dev loss: 0.4672 r:0.7188
Current avg r:0.5931 Best avg r: 0.6244
00:43:18,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:35,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:05,484 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2758
en_de Dev loss: 0.8846 r:0.1795
en_zh Dev loss: 0.7650 r:0.4589
ro_en Dev loss: 0.3325 r:0.8160
et_en Dev loss: 0.4497 r:0.6719
si_en Dev loss: 0.5974 r:0.5807
ne_en Dev loss: 0.4498 r:0.7361
ru_en Dev loss: 0.4868 r:0.7086
Current avg r:0.5931 Best avg r: 0.6244
00:49:57,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:14,490 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:44,395 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2517
en_de Dev loss: 0.8846 r:0.1872
en_zh Dev loss: 0.7741 r:0.4644
ro_en Dev loss: 0.3546 r:0.8186
et_en Dev loss: 0.4769 r:0.6748
si_en Dev loss: 0.6158 r:0.5998
ne_en Dev loss: 0.4416 r:0.7353
ru_en Dev loss: 0.4582 r:0.7266
Current avg r:0.6009 Best avg r: 0.6244
00:56:37,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:54,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:24,425 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2272
en_de Dev loss: 0.8857 r:0.1763
en_zh Dev loss: 0.7869 r:0.4550
ro_en Dev loss: 0.3514 r:0.8163
et_en Dev loss: 0.4606 r:0.6845
si_en Dev loss: 0.6186 r:0.5889
ne_en Dev loss: 0.5007 r:0.7383
ru_en Dev loss: 0.4850 r:0.7119
Current avg r:0.5959 Best avg r: 0.6244
01:03:16,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:33,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:03,381 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2464
en_de Dev loss: 0.8918 r:0.1588
en_zh Dev loss: 0.7560 r:0.4506
ro_en Dev loss: 0.3207 r:0.8148
et_en Dev loss: 0.4276 r:0.6781
si_en Dev loss: 0.5711 r:0.5863
ne_en Dev loss: 0.4764 r:0.7336
ru_en Dev loss: 0.4441 r:0.7202
Current avg r:0.5918 Best avg r: 0.6244
01:09:55,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:12,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:42,380 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2388
en_de Dev loss: 0.8930 r:0.1427
en_zh Dev loss: 0.7944 r:0.4330
ro_en Dev loss: 0.3655 r:0.8140
et_en Dev loss: 0.4735 r:0.6635
si_en Dev loss: 0.6068 r:0.5851
ne_en Dev loss: 0.5335 r:0.7329
ru_en Dev loss: 0.4895 r:0.7028
Current avg r:0.5820 Best avg r: 0.6244
01:16:34,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:51,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:21,405 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2373
en_de Dev loss: 0.8825 r:0.1614
en_zh Dev loss: 0.8051 r:0.4338
ro_en Dev loss: 0.3666 r:0.8128
et_en Dev loss: 0.4614 r:0.6583
si_en Dev loss: 0.6137 r:0.5801
ne_en Dev loss: 0.5638 r:0.7297
ru_en Dev loss: 0.4789 r:0.7094
Current avg r:0.5836 Best avg r: 0.6244
01:23:13,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:24:30,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:00,418 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2411
en_de Dev loss: 0.8843 r:0.1631
en_zh Dev loss: 0.7728 r:0.4552
ro_en Dev loss: 0.3364 r:0.8160
et_en Dev loss: 0.4480 r:0.6675
si_en Dev loss: 0.6019 r:0.5847
ne_en Dev loss: 0.4982 r:0.7315
ru_en Dev loss: 0.4765 r:0.7130
Current avg r:0.5902 Best avg r: 0.6244
01:29:51,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:08,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:38,868 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2249
en_de Dev loss: 0.8991 r:0.1412
en_zh Dev loss: 0.8336 r:0.4353
ro_en Dev loss: 0.3700 r:0.8163
et_en Dev loss: 0.4578 r:0.6663
si_en Dev loss: 0.6226 r:0.5784
ne_en Dev loss: 0.5058 r:0.7319
ru_en Dev loss: 0.5290 r:0.6998
Current avg r:0.5813 Best avg r: 0.6244
01:36:30,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:37:47,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:17,784 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2294
en_de Dev loss: 0.8867 r:0.1526
en_zh Dev loss: 0.7900 r:0.4434
ro_en Dev loss: 0.3463 r:0.8146
et_en Dev loss: 0.4708 r:0.6678
si_en Dev loss: 0.6306 r:0.5855
ne_en Dev loss: 0.4885 r:0.7301
ru_en Dev loss: 0.4457 r:0.7207
Current avg r:0.5878 Best avg r: 0.6244
01:43:09,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:26,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:56,737 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2216
en_de Dev loss: 0.9152 r:0.1477
en_zh Dev loss: 0.7822 r:0.4502
ro_en Dev loss: 0.3283 r:0.8205
et_en Dev loss: 0.4254 r:0.6745
si_en Dev loss: 0.5725 r:0.5901
ne_en Dev loss: 0.5127 r:0.7382
ru_en Dev loss: 0.4674 r:0.7277
Current avg r:0.5927 Best avg r: 0.6244
01:49:48,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:05,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:35,805 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2252
en_de Dev loss: 0.9680 r:0.1487
en_zh Dev loss: 0.8807 r:0.4562
ro_en Dev loss: 0.3963 r:0.8202
et_en Dev loss: 0.4774 r:0.6822
si_en Dev loss: 0.6235 r:0.5934
ne_en Dev loss: 0.5206 r:0.7372
ru_en Dev loss: 0.5179 r:0.7301
Current avg r:0.5954 Best avg r: 0.6244
01:56:27,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:44,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:14,775 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2226
en_de Dev loss: 0.9492 r:0.1548
en_zh Dev loss: 0.8457 r:0.4584
ro_en Dev loss: 0.3886 r:0.8182
et_en Dev loss: 0.4944 r:0.6709
si_en Dev loss: 0.6443 r:0.5868
ne_en Dev loss: 0.5366 r:0.7294
ru_en Dev loss: 0.4979 r:0.7303
Current avg r:0.5927 Best avg r: 0.6244
02:03:06,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:04:23,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:05:53,800 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2259
en_de Dev loss: 0.9226 r:0.1225
en_zh Dev loss: 0.7969 r:0.4401
ro_en Dev loss: 0.3527 r:0.8135
et_en Dev loss: 0.4582 r:0.6609
si_en Dev loss: 0.6444 r:0.5597
ne_en Dev loss: 0.6169 r:0.7281
ru_en Dev loss: 0.4509 r:0.7252
Current avg r:0.5786 Best avg r: 0.6244
02:09:45,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:11:02,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:12:32,955 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2262
en_de Dev loss: 0.9342 r:0.1372
en_zh Dev loss: 0.8160 r:0.4515
ro_en Dev loss: 0.3588 r:0.8171
et_en Dev loss: 0.4640 r:0.6677
si_en Dev loss: 0.6358 r:0.5717
ne_en Dev loss: 0.5480 r:0.7206
ru_en Dev loss: 0.4552 r:0.7304
Current avg r:0.5852 Best avg r: 0.6244
02:16:24,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:17:41,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:11,945 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2396
en_de Dev loss: 0.9121 r:0.1498
en_zh Dev loss: 0.7976 r:0.4616
ro_en Dev loss: 0.3946 r:0.8156
et_en Dev loss: 0.4708 r:0.6623
si_en Dev loss: 0.6415 r:0.5761
ne_en Dev loss: 0.5364 r:0.7280
ru_en Dev loss: 0.5101 r:0.7030
Current avg r:0.5852 Best avg r: 0.6244
02:23:03,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:20,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:50,725 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2303
en_de Dev loss: 0.9151 r:0.1512
en_zh Dev loss: 0.8145 r:0.4603
ro_en Dev loss: 0.3494 r:0.8169
et_en Dev loss: 0.4772 r:0.6676
si_en Dev loss: 0.6551 r:0.5825
ne_en Dev loss: 0.5449 r:0.7307
ru_en Dev loss: 0.4496 r:0.7234
Current avg r:0.5904 Best avg r: 0.6244
02:29:42,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:30:59,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:32:29,726 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2222
en_de Dev loss: 0.9402 r:0.1555
en_zh Dev loss: 0.8623 r:0.4583
ro_en Dev loss: 0.3996 r:0.8100
et_en Dev loss: 0.4761 r:0.6566
si_en Dev loss: 0.6532 r:0.5666
ne_en Dev loss: 0.6636 r:0.7197
ru_en Dev loss: 0.5510 r:0.6965
Current avg r:0.5805 Best avg r: 0.6244
02:36:22,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:39,640 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:39:09,557 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1976
en_de Dev loss: 0.9047 r:0.1730
en_zh Dev loss: 0.7854 r:0.4617
ro_en Dev loss: 0.3338 r:0.8178
et_en Dev loss: 0.4346 r:0.6849
si_en Dev loss: 0.5914 r:0.5852
ne_en Dev loss: 0.5048 r:0.7335
ru_en Dev loss: 0.4563 r:0.7308
Current avg r:0.5981 Best avg r: 0.6244
02:43:01,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:44:18,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:48,427 root INFO Epoch 7 Global steps: 64200 Train loss: 0.2037
en_de Dev loss: 0.9087 r:0.1762
en_zh Dev loss: 0.8258 r:0.4514
ro_en Dev loss: 0.3792 r:0.8095
et_en Dev loss: 0.4869 r:0.6630
si_en Dev loss: 0.6373 r:0.5799
ne_en Dev loss: 0.5448 r:0.7297
ru_en Dev loss: 0.4818 r:0.7193
Current avg r:0.5899 Best avg r: 0.6244
02:49:40,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:57,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:27,389 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1961
en_de Dev loss: 0.9210 r:0.1623
en_zh Dev loss: 0.8041 r:0.4601
ro_en Dev loss: 0.3653 r:0.8118
et_en Dev loss: 0.4755 r:0.6683
si_en Dev loss: 0.6300 r:0.5744
ne_en Dev loss: 0.5868 r:0.7167
ru_en Dev loss: 0.5142 r:0.7053
Current avg r:0.5856 Best avg r: 0.6244
02:56:19,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:57:36,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:59:06,337 root INFO Epoch 7 Global steps: 65400 Train loss: 0.2026
en_de Dev loss: 0.9142 r:0.1635
en_zh Dev loss: 0.8107 r:0.4562
ro_en Dev loss: 0.3970 r:0.8048
et_en Dev loss: 0.4783 r:0.6483
si_en Dev loss: 0.6763 r:0.5532
ne_en Dev loss: 0.7399 r:0.7123
ru_en Dev loss: 0.5043 r:0.7004
Current avg r:0.5770 Best avg r: 0.6244
03:02:58,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:04:15,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:05:45,102 root INFO Epoch 7 Global steps: 66000 Train loss: 0.2049
en_de Dev loss: 0.9265 r:0.1482
en_zh Dev loss: 0.8279 r:0.4571
ro_en Dev loss: 0.3982 r:0.8130
et_en Dev loss: 0.4807 r:0.6675
si_en Dev loss: 0.6481 r:0.5700
ne_en Dev loss: 0.5872 r:0.7197
ru_en Dev loss: 0.5220 r:0.7043
Current avg r:0.5828 Best avg r: 0.6244
03:09:37,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:54,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:12:24,237 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1983
en_de Dev loss: 0.9181 r:0.1459
en_zh Dev loss: 0.7680 r:0.4699
ro_en Dev loss: 0.3756 r:0.8136
et_en Dev loss: 0.4714 r:0.6706
si_en Dev loss: 0.6620 r:0.5688
ne_en Dev loss: 0.5667 r:0.7153
ru_en Dev loss: 0.5030 r:0.7045
Current avg r:0.5841 Best avg r: 0.6244
03:16:16,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:17:33,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:03,128 root INFO Epoch 7 Global steps: 67200 Train loss: 0.2054
en_de Dev loss: 0.9121 r:0.1417
en_zh Dev loss: 0.7681 r:0.4650
ro_en Dev loss: 0.3784 r:0.8151
et_en Dev loss: 0.4573 r:0.6733
si_en Dev loss: 0.6434 r:0.5692
ne_en Dev loss: 0.6246 r:0.7186
ru_en Dev loss: 0.4459 r:0.7313
Current avg r:0.5877 Best avg r: 0.6244
03:22:54,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:24:12,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:41,969 root INFO Epoch 7 Global steps: 67800 Train loss: 0.2159
en_de Dev loss: 0.9167 r:0.1562
en_zh Dev loss: 0.7689 r:0.4677
ro_en Dev loss: 0.3471 r:0.8175
et_en Dev loss: 0.4421 r:0.6842
si_en Dev loss: 0.6176 r:0.5815
ne_en Dev loss: 0.4897 r:0.7278
ru_en Dev loss: 0.4592 r:0.7298
Current avg r:0.5950 Best avg r: 0.6244
03:29:33,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:30:50,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:32:20,323 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1990
en_de Dev loss: 0.9213 r:0.1266
en_zh Dev loss: 0.8116 r:0.4489
ro_en Dev loss: 0.3697 r:0.8105
et_en Dev loss: 0.4640 r:0.6627
si_en Dev loss: 0.6641 r:0.5609
ne_en Dev loss: 0.6604 r:0.7155
ru_en Dev loss: 0.4971 r:0.7151
Current avg r:0.5772 Best avg r: 0.6244
03:36:11,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:28,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:58,652 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1932
en_de Dev loss: 0.9010 r:0.1396
en_zh Dev loss: 0.7714 r:0.4490
ro_en Dev loss: 0.3500 r:0.8096
et_en Dev loss: 0.4488 r:0.6619
si_en Dev loss: 0.6333 r:0.5640
ne_en Dev loss: 0.5818 r:0.7149
ru_en Dev loss: 0.4420 r:0.7276
Current avg r:0.5809 Best avg r: 0.6244
03:42:50,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:07,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:37,83 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1972
en_de Dev loss: 0.9160 r:0.1389
en_zh Dev loss: 0.8461 r:0.4473
ro_en Dev loss: 0.3765 r:0.8112
et_en Dev loss: 0.4705 r:0.6576
si_en Dev loss: 0.6663 r:0.5589
ne_en Dev loss: 0.6646 r:0.7117
ru_en Dev loss: 0.5186 r:0.7170
Current avg r:0.5775 Best avg r: 0.6244
03:49:28,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:50:45,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:15,377 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1951
en_de Dev loss: 0.9199 r:0.1491
en_zh Dev loss: 0.8122 r:0.4502
ro_en Dev loss: 0.3647 r:0.8148
et_en Dev loss: 0.4684 r:0.6661
si_en Dev loss: 0.6537 r:0.5660
ne_en Dev loss: 0.5944 r:0.7133
ru_en Dev loss: 0.4873 r:0.7232
Current avg r:0.5833 Best avg r: 0.6244
03:56:06,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:23,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:58:53,759 root INFO Epoch 7 Global steps: 70800 Train loss: 0.2050
en_de Dev loss: 0.9199 r:0.1660
en_zh Dev loss: 0.7996 r:0.4563
ro_en Dev loss: 0.3300 r:0.8187
et_en Dev loss: 0.4603 r:0.6828
si_en Dev loss: 0.6216 r:0.5850
ne_en Dev loss: 0.4790 r:0.7217
ru_en Dev loss: 0.4320 r:0.7422
Current avg r:0.5961 Best avg r: 0.6244
04:02:45,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:02,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:05:32,523 root INFO Epoch 7 Global steps: 71400 Train loss: 0.2054
en_de Dev loss: 0.9043 r:0.1403
en_zh Dev loss: 0.7788 r:0.4393
ro_en Dev loss: 0.3402 r:0.8143
et_en Dev loss: 0.4378 r:0.6679
si_en Dev loss: 0.5969 r:0.5745
ne_en Dev loss: 0.5614 r:0.7187
ru_en Dev loss: 0.4525 r:0.7236
Current avg r:0.5827 Best avg r: 0.6244
04:09:24,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:10:41,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:12:11,451 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1907
en_de Dev loss: 0.9150 r:0.1521
en_zh Dev loss: 0.7899 r:0.4526
ro_en Dev loss: 0.3475 r:0.8165
et_en Dev loss: 0.4628 r:0.6680
si_en Dev loss: 0.6254 r:0.5707
ne_en Dev loss: 0.5447 r:0.7187
ru_en Dev loss: 0.4573 r:0.7258
Current avg r:0.5863 Best avg r: 0.6244
04:16:04,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:17:21,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:18:51,413 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1830
en_de Dev loss: 0.9219 r:0.1451
en_zh Dev loss: 0.8202 r:0.4577
ro_en Dev loss: 0.3709 r:0.8175
et_en Dev loss: 0.4816 r:0.6687
si_en Dev loss: 0.6697 r:0.5650
ne_en Dev loss: 0.5660 r:0.7145
ru_en Dev loss: 0.4716 r:0.7270
Current avg r:0.5851 Best avg r: 0.6244
04:22:43,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:24:00,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:25:30,273 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1790
en_de Dev loss: 0.9504 r:0.1496
en_zh Dev loss: 0.7788 r:0.4687
ro_en Dev loss: 0.3339 r:0.8208
et_en Dev loss: 0.4348 r:0.6792
si_en Dev loss: 0.6133 r:0.5743
ne_en Dev loss: 0.5275 r:0.7190
ru_en Dev loss: 0.4533 r:0.7353
Current avg r:0.5924 Best avg r: 0.6244
04:29:22,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:39,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:32:09,213 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1855
en_de Dev loss: 0.9345 r:0.1547
en_zh Dev loss: 0.8186 r:0.4513
ro_en Dev loss: 0.3458 r:0.8153
et_en Dev loss: 0.4420 r:0.6670
si_en Dev loss: 0.6230 r:0.5686
ne_en Dev loss: 0.5764 r:0.7179
ru_en Dev loss: 0.4975 r:0.7219
Current avg r:0.5852 Best avg r: 0.6244
04:36:01,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:37:18,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:48,185 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1922
en_de Dev loss: 0.9338 r:0.1619
en_zh Dev loss: 0.8029 r:0.4663
ro_en Dev loss: 0.3709 r:0.8156
et_en Dev loss: 0.4836 r:0.6691
si_en Dev loss: 0.6668 r:0.5752
ne_en Dev loss: 0.5529 r:0.7135
ru_en Dev loss: 0.4404 r:0.7396
Current avg r:0.5916 Best avg r: 0.6244
04:42:39,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:57,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:27,60 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1743
en_de Dev loss: 0.9417 r:0.1497
en_zh Dev loss: 0.8223 r:0.4577
ro_en Dev loss: 0.3597 r:0.8154
et_en Dev loss: 0.4727 r:0.6724
si_en Dev loss: 0.6466 r:0.5802
ne_en Dev loss: 0.5069 r:0.7179
ru_en Dev loss: 0.4510 r:0.7433
Current avg r:0.5909 Best avg r: 0.6244
04:49:19,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:36,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:52:06,139 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1713
en_de Dev loss: 0.9472 r:0.1427
en_zh Dev loss: 0.8300 r:0.4556
ro_en Dev loss: 0.3630 r:0.8136
et_en Dev loss: 0.4745 r:0.6644
si_en Dev loss: 0.6545 r:0.5759
ne_en Dev loss: 0.5283 r:0.7202
ru_en Dev loss: 0.4824 r:0.7318
Current avg r:0.5863 Best avg r: 0.6244
04:55:57,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:15,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:44,946 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1764
en_de Dev loss: 0.9157 r:0.1333
en_zh Dev loss: 0.7622 r:0.4435
ro_en Dev loss: 0.3315 r:0.8155
et_en Dev loss: 0.4543 r:0.6743
si_en Dev loss: 0.6323 r:0.5798
ne_en Dev loss: 0.4838 r:0.7184
ru_en Dev loss: 0.4234 r:0.7373
Current avg r:0.5860 Best avg r: 0.6244
05:02:36,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:53,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:05:23,681 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1817
en_de Dev loss: 0.9364 r:0.1544
en_zh Dev loss: 0.7977 r:0.4653
ro_en Dev loss: 0.3576 r:0.8205
et_en Dev loss: 0.4468 r:0.6780
si_en Dev loss: 0.6242 r:0.5790
ne_en Dev loss: 0.6082 r:0.7172
ru_en Dev loss: 0.4608 r:0.7410
Current avg r:0.5936 Best avg r: 0.6244
05:09:15,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:32,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:12:02,358 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1704
en_de Dev loss: 0.9455 r:0.1225
en_zh Dev loss: 0.7885 r:0.4539
ro_en Dev loss: 0.3518 r:0.8155
et_en Dev loss: 0.4534 r:0.6593
si_en Dev loss: 0.6234 r:0.5694
ne_en Dev loss: 0.5769 r:0.7200
ru_en Dev loss: 0.5056 r:0.7185
Current avg r:0.5799 Best avg r: 0.6244
05:15:54,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:10,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:40,920 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1851
en_de Dev loss: 0.9579 r:0.1347
en_zh Dev loss: 0.8733 r:0.4440
ro_en Dev loss: 0.3894 r:0.8130
et_en Dev loss: 0.4826 r:0.6505
si_en Dev loss: 0.6580 r:0.5621
ne_en Dev loss: 0.6666 r:0.7145
ru_en Dev loss: 0.5239 r:0.7229
Current avg r:0.5774 Best avg r: 0.6244
05:22:32,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:23:49,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:19,908 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1774
en_de Dev loss: 0.9358 r:0.1319
en_zh Dev loss: 0.7747 r:0.4535
ro_en Dev loss: 0.3447 r:0.8166
et_en Dev loss: 0.4534 r:0.6777
si_en Dev loss: 0.6328 r:0.5703
ne_en Dev loss: 0.5364 r:0.7227
ru_en Dev loss: 0.4174 r:0.7423
Current avg r:0.5879 Best avg r: 0.6244
05:29:11,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:29,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:58,987 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1735
en_de Dev loss: 0.9133 r:0.1395
en_zh Dev loss: 0.7646 r:0.4546
ro_en Dev loss: 0.3306 r:0.8144
et_en Dev loss: 0.4446 r:0.6756
si_en Dev loss: 0.6043 r:0.5744
ne_en Dev loss: 0.5596 r:0.7154
ru_en Dev loss: 0.4559 r:0.7222
Current avg r:0.5852 Best avg r: 0.6244
05:35:50,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:07,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:37,920 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1712
en_de Dev loss: 0.9571 r:0.1270
en_zh Dev loss: 0.8134 r:0.4569
ro_en Dev loss: 0.3743 r:0.8157
et_en Dev loss: 0.4651 r:0.6787
si_en Dev loss: 0.6309 r:0.5747
ne_en Dev loss: 0.5754 r:0.7160
ru_en Dev loss: 0.4989 r:0.7225
Current avg r:0.5845 Best avg r: 0.6244
05:42:29,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:46,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:16,710 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1713
en_de Dev loss: 0.9620 r:0.1155
en_zh Dev loss: 0.7873 r:0.4632
ro_en Dev loss: 0.3593 r:0.8174
et_en Dev loss: 0.4487 r:0.6855
si_en Dev loss: 0.6329 r:0.5756
ne_en Dev loss: 0.5238 r:0.7184
ru_en Dev loss: 0.4583 r:0.7329
Current avg r:0.5869 Best avg r: 0.6244
05:49:08,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:50:25,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:51:55,144 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1753
en_de Dev loss: 0.9609 r:0.1140
en_zh Dev loss: 0.8078 r:0.4724
ro_en Dev loss: 0.3727 r:0.8141
et_en Dev loss: 0.4645 r:0.6641
si_en Dev loss: 0.6767 r:0.5586
ne_en Dev loss: 0.6493 r:0.7142
ru_en Dev loss: 0.4768 r:0.7313
Current avg r:0.5812 Best avg r: 0.6244
05:55:48,434 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:57:05,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:58:35,544 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1597
en_de Dev loss: 0.9619 r:0.1408
en_zh Dev loss: 0.8340 r:0.4611
ro_en Dev loss: 0.3696 r:0.8151
et_en Dev loss: 0.4588 r:0.6664
si_en Dev loss: 0.6444 r:0.5690
ne_en Dev loss: 0.5659 r:0.7133
ru_en Dev loss: 0.5172 r:0.7179
Current avg r:0.5834 Best avg r: 0.6244
06:02:27,183 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:44,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:14,265 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1661
en_de Dev loss: 0.9798 r:0.1393
en_zh Dev loss: 0.8019 r:0.4760
ro_en Dev loss: 0.3803 r:0.8115
et_en Dev loss: 0.4776 r:0.6751
si_en Dev loss: 0.6564 r:0.5770
ne_en Dev loss: 0.5606 r:0.7167
ru_en Dev loss: 0.4690 r:0.7322
Current avg r:0.5897 Best avg r: 0.6244
06:09:05,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:10:22,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:52,425 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1540
en_de Dev loss: 0.9717 r:0.1247
en_zh Dev loss: 0.8188 r:0.4667
ro_en Dev loss: 0.4270 r:0.8107
et_en Dev loss: 0.4856 r:0.6618
si_en Dev loss: 0.6922 r:0.5582
ne_en Dev loss: 0.6556 r:0.7119
ru_en Dev loss: 0.5047 r:0.7252
Current avg r:0.5799 Best avg r: 0.6244
06:15:43,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:00,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:30,545 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1540
en_de Dev loss: 0.9450 r:0.1233
en_zh Dev loss: 0.7761 r:0.4654
ro_en Dev loss: 0.3418 r:0.8128
et_en Dev loss: 0.4234 r:0.6723
si_en Dev loss: 0.6183 r:0.5609
ne_en Dev loss: 0.6082 r:0.7122
ru_en Dev loss: 0.4644 r:0.7285
Current avg r:0.5822 Best avg r: 0.6244
06:22:21,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:23:38,729 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:25:08,645 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1490
en_de Dev loss: 0.9786 r:0.1318
en_zh Dev loss: 0.8513 r:0.4566
ro_en Dev loss: 0.3788 r:0.8101
et_en Dev loss: 0.4776 r:0.6669
si_en Dev loss: 0.6619 r:0.5621
ne_en Dev loss: 0.5500 r:0.7109
ru_en Dev loss: 0.5088 r:0.7176
Current avg r:0.5794 Best avg r: 0.6244
06:28:59,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:16,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:46,820 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1510
en_de Dev loss: 0.9627 r:0.1207
en_zh Dev loss: 0.7949 r:0.4579
ro_en Dev loss: 0.3457 r:0.8156
et_en Dev loss: 0.4490 r:0.6792
si_en Dev loss: 0.6395 r:0.5645
ne_en Dev loss: 0.5750 r:0.7137
ru_en Dev loss: 0.4329 r:0.7361
Current avg r:0.5840 Best avg r: 0.6244
06:35:38,36 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:55,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:38:24,966 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1646
en_de Dev loss: 0.9581 r:0.1254
en_zh Dev loss: 0.8366 r:0.4517
ro_en Dev loss: 0.3739 r:0.8089
et_en Dev loss: 0.4585 r:0.6725
si_en Dev loss: 0.6542 r:0.5639
ne_en Dev loss: 0.5714 r:0.7117
ru_en Dev loss: 0.4598 r:0.7310
Current avg r:0.5807 Best avg r: 0.6244
06:42:16,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:43:33,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:03,114 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1550
en_de Dev loss: 0.9626 r:0.1338
en_zh Dev loss: 0.7762 r:0.4683
ro_en Dev loss: 0.3470 r:0.8111
et_en Dev loss: 0.4448 r:0.6778
si_en Dev loss: 0.6301 r:0.5666
ne_en Dev loss: 0.5386 r:0.7063
ru_en Dev loss: 0.4509 r:0.7274
Current avg r:0.5845 Best avg r: 0.6244
06:48:54,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:50:11,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:51:41,336 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1571
en_de Dev loss: 0.9402 r:0.1213
en_zh Dev loss: 0.7763 r:0.4674
ro_en Dev loss: 0.3688 r:0.8078
et_en Dev loss: 0.4738 r:0.6684
si_en Dev loss: 0.6637 r:0.5612
ne_en Dev loss: 0.6007 r:0.7117
ru_en Dev loss: 0.4615 r:0.7242
Current avg r:0.5803 Best avg r: 0.6244
06:55:32,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:56:49,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:58:19,518 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1566
en_de Dev loss: 0.9735 r:0.1264
en_zh Dev loss: 0.8149 r:0.4659
ro_en Dev loss: 0.3851 r:0.8066
et_en Dev loss: 0.4789 r:0.6658
si_en Dev loss: 0.6550 r:0.5656
ne_en Dev loss: 0.5628 r:0.7123
ru_en Dev loss: 0.5069 r:0.7193
Current avg r:0.5803 Best avg r: 0.6244
07:02:10,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:03:27,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:04:57,810 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1622
en_de Dev loss: 0.9136 r:0.1335
en_zh Dev loss: 0.7703 r:0.4657
ro_en Dev loss: 0.3447 r:0.8111
et_en Dev loss: 0.4408 r:0.6676
si_en Dev loss: 0.6297 r:0.5653
ne_en Dev loss: 0.6101 r:0.7216
ru_en Dev loss: 0.4733 r:0.7207
Current avg r:0.5836 Best avg r: 0.6244
07:08:49,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:10:06,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:11:36,533 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1521
en_de Dev loss: 0.9412 r:0.1152
en_zh Dev loss: 0.8346 r:0.4481
ro_en Dev loss: 0.3576 r:0.8084
et_en Dev loss: 0.4526 r:0.6646
si_en Dev loss: 0.6518 r:0.5531
ne_en Dev loss: 0.6874 r:0.7036
ru_en Dev loss: 0.4906 r:0.7173
Current avg r:0.5729 Best avg r: 0.6244
07:15:28,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:16:45,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:18:15,441 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1572
en_de Dev loss: 0.9329 r:0.1420
en_zh Dev loss: 0.7723 r:0.4729
ro_en Dev loss: 0.3634 r:0.8088
et_en Dev loss: 0.4573 r:0.6619
si_en Dev loss: 0.6633 r:0.5526
ne_en Dev loss: 0.7261 r:0.7021
ru_en Dev loss: 0.5111 r:0.7155
Current avg r:0.5794 Best avg r: 0.6244
07:22:07,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:23:24,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:24:54,225 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1423
en_de Dev loss: 0.9518 r:0.1354
en_zh Dev loss: 0.8347 r:0.4548
ro_en Dev loss: 0.4052 r:0.8053
et_en Dev loss: 0.4947 r:0.6526
si_en Dev loss: 0.6850 r:0.5505
ne_en Dev loss: 0.6074 r:0.7013
ru_en Dev loss: 0.5494 r:0.7060
Current avg r:0.5723 Best avg r: 0.6244
07:28:45,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:30:03,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:31:33,10 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1507
en_de Dev loss: 0.9331 r:0.1364
en_zh Dev loss: 0.7618 r:0.4592
ro_en Dev loss: 0.3421 r:0.8126
et_en Dev loss: 0.4592 r:0.6682
si_en Dev loss: 0.6306 r:0.5632
ne_en Dev loss: 0.5147 r:0.7110
ru_en Dev loss: 0.4461 r:0.7360
Current avg r:0.5838 Best avg r: 0.6244
07:35:25,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:36:42,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:38:12,419 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1439
en_de Dev loss: 0.9641 r:0.1392
en_zh Dev loss: 0.8373 r:0.4548
ro_en Dev loss: 0.3848 r:0.8104
et_en Dev loss: 0.4779 r:0.6663
si_en Dev loss: 0.6551 r:0.5602
ne_en Dev loss: 0.6104 r:0.7093
ru_en Dev loss: 0.4980 r:0.7306
Current avg r:0.5815 Best avg r: 0.6244
07:42:03,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:43:20,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:44:50,674 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1321
en_de Dev loss: 0.9557 r:0.1482
en_zh Dev loss: 0.8048 r:0.4640
ro_en Dev loss: 0.3722 r:0.8087
et_en Dev loss: 0.4737 r:0.6711
si_en Dev loss: 0.6411 r:0.5688
ne_en Dev loss: 0.5921 r:0.7093
ru_en Dev loss: 0.4510 r:0.7393
Current avg r:0.5871 Best avg r: 0.6244
07:48:41,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:49:59,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:51:29,12 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1355
en_de Dev loss: 0.9319 r:0.1379
en_zh Dev loss: 0.8292 r:0.4515
ro_en Dev loss: 0.3967 r:0.8094
et_en Dev loss: 0.4913 r:0.6656
si_en Dev loss: 0.6733 r:0.5596
ne_en Dev loss: 0.5957 r:0.7116
ru_en Dev loss: 0.4810 r:0.7295
Current avg r:0.5807 Best avg r: 0.6244
07:55:20,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:56:37,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:58:07,751 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1334
en_de Dev loss: 0.9327 r:0.1498
en_zh Dev loss: 0.8527 r:0.4611
ro_en Dev loss: 0.3673 r:0.8151
et_en Dev loss: 0.4616 r:0.6728
si_en Dev loss: 0.6520 r:0.5610
ne_en Dev loss: 0.5940 r:0.7132
ru_en Dev loss: 0.4885 r:0.7289
Current avg r:0.5860 Best avg r: 0.6244
08:01:58,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:03:15,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:04:45,909 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1442
en_de Dev loss: 0.9202 r:0.1516
en_zh Dev loss: 0.7975 r:0.4621
ro_en Dev loss: 0.3768 r:0.8112
et_en Dev loss: 0.4901 r:0.6610
si_en Dev loss: 0.6748 r:0.5557
ne_en Dev loss: 0.5926 r:0.7021
ru_en Dev loss: 0.4610 r:0.7272
Current avg r:0.5816 Best avg r: 0.6244
08:08:36,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:53,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:11:24,4 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1397
en_de Dev loss: 0.9263 r:0.1583
en_zh Dev loss: 0.7650 r:0.4640
ro_en Dev loss: 0.3496 r:0.8118
et_en Dev loss: 0.4881 r:0.6729
si_en Dev loss: 0.6641 r:0.5650
ne_en Dev loss: 0.5019 r:0.7076
ru_en Dev loss: 0.4225 r:0.7389
Current avg r:0.5884 Best avg r: 0.6244
08:15:15,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:16:32,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:18:02,836 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1415
en_de Dev loss: 0.9526 r:0.1360
en_zh Dev loss: 0.7785 r:0.4676
ro_en Dev loss: 0.3498 r:0.8114
et_en Dev loss: 0.4743 r:0.6645
si_en Dev loss: 0.6434 r:0.5599
ne_en Dev loss: 0.5509 r:0.6951
ru_en Dev loss: 0.4433 r:0.7411
Current avg r:0.5822 Best avg r: 0.6244
08:21:54,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:23:11,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:24:41,582 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1421
en_de Dev loss: 0.9319 r:0.1376
en_zh Dev loss: 0.7790 r:0.4664
ro_en Dev loss: 0.3498 r:0.8121
et_en Dev loss: 0.4757 r:0.6695
si_en Dev loss: 0.6404 r:0.5641
ne_en Dev loss: 0.5674 r:0.6989
ru_en Dev loss: 0.4223 r:0.7426
Current avg r:0.5844 Best avg r: 0.6244
08:28:33,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:29:50,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:31:20,518 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1323
en_de Dev loss: 0.9421 r:0.1375
en_zh Dev loss: 0.7901 r:0.4599
ro_en Dev loss: 0.3524 r:0.8107
et_en Dev loss: 0.4647 r:0.6658
si_en Dev loss: 0.6370 r:0.5580
ne_en Dev loss: 0.6205 r:0.7045
ru_en Dev loss: 0.4381 r:0.7443
Current avg r:0.5830 Best avg r: 0.6244
08:35:12,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:29,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:37:59,141 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1279
en_de Dev loss: 0.9634 r:0.1312
en_zh Dev loss: 0.7995 r:0.4631
ro_en Dev loss: 0.3801 r:0.8066
et_en Dev loss: 0.4870 r:0.6634
si_en Dev loss: 0.6626 r:0.5606
ne_en Dev loss: 0.6396 r:0.6997
ru_en Dev loss: 0.4642 r:0.7345
Current avg r:0.5799 Best avg r: 0.6244
08:41:50,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:43:07,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:44:37,272 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1353
en_de Dev loss: 0.9745 r:0.1143
en_zh Dev loss: 0.7951 r:0.4687
ro_en Dev loss: 0.3826 r:0.8074
et_en Dev loss: 0.4842 r:0.6647
si_en Dev loss: 0.6556 r:0.5613
ne_en Dev loss: 0.6508 r:0.7039
ru_en Dev loss: 0.4533 r:0.7425
Current avg r:0.5804 Best avg r: 0.6244
08:48:28,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:49:45,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:51:15,330 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1401
en_de Dev loss: 0.9634 r:0.1276
en_zh Dev loss: 0.7599 r:0.4676
ro_en Dev loss: 0.3321 r:0.8104
et_en Dev loss: 0.4631 r:0.6797
si_en Dev loss: 0.6246 r:0.5723
ne_en Dev loss: 0.4951 r:0.7054
ru_en Dev loss: 0.4230 r:0.7422
Current avg r:0.5865 Best avg r: 0.6244
08:55:06,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:56:23,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:57:53,399 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1345
en_de Dev loss: 0.9680 r:0.1243
en_zh Dev loss: 0.7760 r:0.4738
ro_en Dev loss: 0.3790 r:0.8100
et_en Dev loss: 0.4709 r:0.6641
si_en Dev loss: 0.6479 r:0.5606
ne_en Dev loss: 0.6455 r:0.6905
ru_en Dev loss: 0.4604 r:0.7394
Current avg r:0.5804 Best avg r: 0.6244
09:01:44,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:03:01,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:04:31,447 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1409
en_de Dev loss: 0.9656 r:0.1352
en_zh Dev loss: 0.7727 r:0.4813
ro_en Dev loss: 0.3721 r:0.8093
et_en Dev loss: 0.4718 r:0.6645
si_en Dev loss: 0.6350 r:0.5682
ne_en Dev loss: 0.6331 r:0.6987
ru_en Dev loss: 0.4656 r:0.7412
Current avg r:0.5855 Best avg r: 0.6244
09:08:22,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:39,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:09,518 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1332
en_de Dev loss: 0.9523 r:0.1395
en_zh Dev loss: 0.8026 r:0.4651
ro_en Dev loss: 0.3819 r:0.8095
et_en Dev loss: 0.4784 r:0.6481
si_en Dev loss: 0.6708 r:0.5536
ne_en Dev loss: 0.6604 r:0.7025
ru_en Dev loss: 0.4820 r:0.7329
Current avg r:0.5787 Best avg r: 0.6244
09:15:02,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:16:19,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:17:49,585 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1231
en_de Dev loss: 0.9791 r:0.1629
en_zh Dev loss: 0.7769 r:0.4826
ro_en Dev loss: 0.3761 r:0.8103
et_en Dev loss: 0.4699 r:0.6601
si_en Dev loss: 0.6401 r:0.5677
ne_en Dev loss: 0.6776 r:0.6961
ru_en Dev loss: 0.4411 r:0.7521
Current avg r:0.5903 Best avg r: 0.6244
09:21:41,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:22:06,964 root INFO 
id:en_zh cur r: 0.4853 best r: 0.4853
09:22:58,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:24:28,304 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1168
en_de Dev loss: 0.9810 r:0.1507
en_zh Dev loss: 0.8169 r:0.4848
ro_en Dev loss: 0.3913 r:0.8126
et_en Dev loss: 0.5010 r:0.6705
si_en Dev loss: 0.6575 r:0.5769
ne_en Dev loss: 0.5766 r:0.6995
ru_en Dev loss: 0.4792 r:0.7464
Current avg r:0.5916 Best avg r: 0.6244
09:28:19,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:29:37,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:31:06,955 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1255
en_de Dev loss: 0.9317 r:0.1597
en_zh Dev loss: 0.7842 r:0.4745
ro_en Dev loss: 0.3704 r:0.8106
et_en Dev loss: 0.4831 r:0.6587
si_en Dev loss: 0.6678 r:0.5562
ne_en Dev loss: 0.6682 r:0.7006
ru_en Dev loss: 0.4710 r:0.7267
Current avg r:0.5839 Best avg r: 0.6244
09:34:58,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:36:15,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:37:45,212 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1213
en_de Dev loss: 0.9373 r:0.1554
en_zh Dev loss: 0.8202 r:0.4716
ro_en Dev loss: 0.3917 r:0.8101
et_en Dev loss: 0.4893 r:0.6651
si_en Dev loss: 0.6611 r:0.5635
ne_en Dev loss: 0.6668 r:0.6982
ru_en Dev loss: 0.4905 r:0.7365
Current avg r:0.5858 Best avg r: 0.6244
09:41:36,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:53,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:44:23,341 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1238
en_de Dev loss: 0.9574 r:0.1630
en_zh Dev loss: 0.7404 r:0.4870
ro_en Dev loss: 0.3312 r:0.8178
et_en Dev loss: 0.4480 r:0.6726
si_en Dev loss: 0.6133 r:0.5683
ne_en Dev loss: 0.6023 r:0.6955
ru_en Dev loss: 0.4315 r:0.7472
Current avg r:0.5931 Best avg r: 0.6244
09:48:14,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:49:31,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:01,492 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1221
en_de Dev loss: 0.9807 r:0.1621
en_zh Dev loss: 0.8488 r:0.4798
ro_en Dev loss: 0.4033 r:0.8116
et_en Dev loss: 0.4882 r:0.6610
si_en Dev loss: 0.6979 r:0.5567
ne_en Dev loss: 0.7192 r:0.6983
ru_en Dev loss: 0.5186 r:0.7328
Current avg r:0.5861 Best avg r: 0.6244
09:54:52,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:09,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:39,693 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1183
en_de Dev loss: 0.9933 r:0.1410
en_zh Dev loss: 0.8479 r:0.4723
ro_en Dev loss: 0.4110 r:0.8078
et_en Dev loss: 0.4919 r:0.6471
si_en Dev loss: 0.6867 r:0.5523
ne_en Dev loss: 0.7049 r:0.6912
ru_en Dev loss: 0.5339 r:0.7194
Current avg r:0.5759 Best avg r: 0.6244
10:01:30,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:47,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:04:17,847 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1262
en_de Dev loss: 0.9525 r:0.1542
en_zh Dev loss: 0.7754 r:0.4797
ro_en Dev loss: 0.3790 r:0.8080
et_en Dev loss: 0.4917 r:0.6587
si_en Dev loss: 0.6526 r:0.5644
ne_en Dev loss: 0.6746 r:0.6966
ru_en Dev loss: 0.4619 r:0.7372
Current avg r:0.5855 Best avg r: 0.6244
10:08:08,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:09:26,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:55,990 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1250
en_de Dev loss: 0.9720 r:0.1546
en_zh Dev loss: 0.7978 r:0.4733
ro_en Dev loss: 0.3805 r:0.8122
et_en Dev loss: 0.4865 r:0.6592
si_en Dev loss: 0.6489 r:0.5655
ne_en Dev loss: 0.6110 r:0.7055
ru_en Dev loss: 0.4301 r:0.7544
Current avg r:0.5892 Best avg r: 0.6244
10:14:47,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:04,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:34,166 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1221
en_de Dev loss: 0.9542 r:0.1621
en_zh Dev loss: 0.7710 r:0.4735
ro_en Dev loss: 0.3553 r:0.8137
et_en Dev loss: 0.4645 r:0.6745
si_en Dev loss: 0.6258 r:0.5704
ne_en Dev loss: 0.5421 r:0.7030
ru_en Dev loss: 0.4334 r:0.7481
Current avg r:0.5922 Best avg r: 0.6244
10:21:25,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:22:42,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:24:12,360 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1189
en_de Dev loss: 0.9567 r:0.1498
en_zh Dev loss: 0.8315 r:0.4548
ro_en Dev loss: 0.3836 r:0.8106
et_en Dev loss: 0.4952 r:0.6573
si_en Dev loss: 0.6583 r:0.5607
ne_en Dev loss: 0.6336 r:0.7005
ru_en Dev loss: 0.5041 r:0.7260
Current avg r:0.5800 Best avg r: 0.6244
10:28:03,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:20,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:50,520 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1231
en_de Dev loss: 0.9583 r:0.1633
en_zh Dev loss: 0.8160 r:0.4606
ro_en Dev loss: 0.3613 r:0.8106
et_en Dev loss: 0.4721 r:0.6626
si_en Dev loss: 0.6425 r:0.5606
ne_en Dev loss: 0.6005 r:0.7020
ru_en Dev loss: 0.5082 r:0.7224
Current avg r:0.5831 Best avg r: 0.6244
