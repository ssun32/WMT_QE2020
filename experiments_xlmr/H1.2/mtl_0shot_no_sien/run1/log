14:44:01,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:30,34 root INFO 
id:en_zh cur r: 0.2568 best r: 0.2568
14:44:44,575 root INFO 
id:ro_en cur r: 0.5735 best r: 0.5735
14:44:59,185 root INFO 
id:et_en cur r: 0.5108 best r: 0.5108
14:45:13,819 root INFO 
id:ne_en cur r: 0.6155 best r: 0.6155
14:45:28,364 root INFO 
id:ru_en cur r: 0.4751 best r: 0.4751
14:45:28,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:10,419 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
14:47:10,433 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:47:10,443 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:47:10,451 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
14:47:10,459 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
14:47:10,465 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:47:10,470 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:47:24,944 root INFO Epoch 0 Global steps: 600 Train loss: 0.8509
en_de Dev loss: 0.8872 r:0.0768
en_zh Dev loss: 0.8081 r:0.2747
ro_en Dev loss: 0.6666 r:0.5775
et_en Dev loss: 0.5855 r:0.4760
si_en Dev loss: 0.7317 r:0.4499
ne_en Dev loss: 0.5673 r:0.6065
ru_en Dev loss: 0.6832 r:0.4502
Current avg r:0.4159 Best avg r: 0.4159
14:51:48,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:02,404 root INFO 
id:en_de cur r: 0.0931 best r: 0.0931
14:52:16,963 root INFO 
id:en_zh cur r: 0.2617 best r: 0.2617
14:52:31,538 root INFO 
id:ro_en cur r: 0.6151 best r: 0.6151
14:52:46,127 root INFO 
id:et_en cur r: 0.5549 best r: 0.5549
14:53:15,216 root INFO 
id:ru_en cur r: 0.6266 best r: 0.6266
14:53:15,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:57,107 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
14:54:57,114 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:54:57,119 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:54:57,124 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
14:54:57,129 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
14:54:57,135 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:54:57,141 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:55:11,692 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7834
en_de Dev loss: 0.9046 r:0.1105
en_zh Dev loss: 0.7422 r:0.3111
ro_en Dev loss: 0.6876 r:0.6368
et_en Dev loss: 0.5118 r:0.5686
si_en Dev loss: 0.8137 r:0.4696
ne_en Dev loss: 0.5800 r:0.6207
ru_en Dev loss: 0.6221 r:0.6333
Current avg r:0.4786 Best avg r: 0.4786
14:59:34,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:18,577 root INFO 
id:ro_en cur r: 0.6320 best r: 0.6320
15:00:33,183 root INFO 
id:et_en cur r: 0.6126 best r: 0.6126
15:00:47,771 root INFO 
id:ne_en cur r: 0.6280 best r: 0.6280
15:01:02,265 root INFO 
id:ru_en cur r: 0.6854 best r: 0.6854
15:01:02,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:44,374 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:02:44,380 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:02:44,387 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:02:44,391 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:02:44,396 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:02:44,400 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:02:44,405 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:02:59,60 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7577
en_de Dev loss: 0.9188 r:0.1231
en_zh Dev loss: 0.7539 r:0.3223
ro_en Dev loss: 0.6616 r:0.6747
et_en Dev loss: 0.4869 r:0.6236
si_en Dev loss: 0.7590 r:0.4875
ne_en Dev loss: 0.5371 r:0.6470
ru_en Dev loss: 0.5995 r:0.6971
Current avg r:0.5108 Best avg r: 0.5108
15:07:22,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:05,854 root INFO 
id:ro_en cur r: 0.6608 best r: 0.6608
15:08:20,439 root INFO 
id:et_en cur r: 0.6429 best r: 0.6429
15:08:35,30 root INFO 
id:ne_en cur r: 0.6476 best r: 0.6476
15:08:49,524 root INFO 
id:ru_en cur r: 0.7072 best r: 0.7072
15:08:49,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:31,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:10:31,824 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:10:31,829 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:10:31,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:10:31,837 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:10:31,841 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:10:31,846 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:10:46,396 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6977
en_de Dev loss: 0.9158 r:0.1299
en_zh Dev loss: 0.7965 r:0.3140
ro_en Dev loss: 0.6007 r:0.6815
et_en Dev loss: 0.4427 r:0.6656
si_en Dev loss: 0.7036 r:0.5238
ne_en Dev loss: 0.5385 r:0.6498
ru_en Dev loss: 0.5774 r:0.7067
Current avg r:0.5245 Best avg r: 0.5245
15:15:09,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:38,459 root INFO 
id:en_zh cur r: 0.2700 best r: 0.2700
15:15:53,42 root INFO 
id:ro_en cur r: 0.6846 best r: 0.6846
15:16:07,644 root INFO 
id:et_en cur r: 0.6479 best r: 0.6479
15:16:22,262 root INFO 
id:ne_en cur r: 0.6759 best r: 0.6759
15:16:36,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:18,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:18:18,791 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:18:18,796 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:18:18,800 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:18:18,803 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:18:18,807 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:18:18,812 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:18:33,340 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6377
en_de Dev loss: 0.9498 r:0.1273
en_zh Dev loss: 0.8176 r:0.3289
ro_en Dev loss: 0.5702 r:0.7008
et_en Dev loss: 0.4313 r:0.6700
si_en Dev loss: 0.7212 r:0.5278
ne_en Dev loss: 0.5452 r:0.6799
ru_en Dev loss: 0.5605 r:0.7027
Current avg r:0.5339 Best avg r: 0.5339
15:22:56,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:10,951 root INFO 
id:en_de cur r: 0.1042 best r: 0.1042
15:23:25,493 root INFO 
id:en_zh cur r: 0.3485 best r: 0.3485
15:23:40,53 root INFO 
id:ro_en cur r: 0.7225 best r: 0.7225
15:23:54,632 root INFO 
id:et_en cur r: 0.6905 best r: 0.6905
15:24:09,210 root INFO 
id:ne_en cur r: 0.7133 best r: 0.7133
15:24:23,676 root INFO 
id:ru_en cur r: 0.7396 best r: 0.7396
15:24:23,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:05,505 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:26:05,511 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:26:05,516 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:26:05,520 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:26:05,525 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:26:05,531 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:26:05,535 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:26:20,285 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6117
en_de Dev loss: 0.9027 r:0.1499
en_zh Dev loss: 0.7202 r:0.3783
ro_en Dev loss: 0.4460 r:0.7308
et_en Dev loss: 0.3572 r:0.7069
si_en Dev loss: 0.5584 r:0.5703
ne_en Dev loss: 0.3868 r:0.7173
ru_en Dev loss: 0.4247 r:0.7402
Current avg r:0.5705 Best avg r: 0.5705
15:30:43,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:57,910 root INFO 
id:en_de cur r: 0.1051 best r: 0.1051
15:31:12,574 root INFO 
id:en_zh cur r: 0.3584 best r: 0.3584
15:31:27,166 root INFO 
id:ro_en cur r: 0.7363 best r: 0.7363
15:31:41,774 root INFO 
id:et_en cur r: 0.6979 best r: 0.6979
15:31:56,392 root INFO 
id:ne_en cur r: 0.7183 best r: 0.7183
15:32:10,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:53,16 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:33:53,22 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:33:53,30 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:33:53,35 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:33:53,41 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:33:53,46 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:33:53,53 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:34:07,549 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5932
en_de Dev loss: 0.8796 r:0.1490
en_zh Dev loss: 0.7156 r:0.3750
ro_en Dev loss: 0.4044 r:0.7432
et_en Dev loss: 0.3618 r:0.7108
si_en Dev loss: 0.5959 r:0.5610
ne_en Dev loss: 0.4179 r:0.7174
ru_en Dev loss: 0.4365 r:0.7385
Current avg r:0.5707 Best avg r: 0.5707
15:38:30,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:44,893 root INFO 
id:en_de cur r: 0.1208 best r: 0.1208
15:38:59,399 root INFO 
id:en_zh cur r: 0.3679 best r: 0.3679
15:39:13,973 root INFO 
id:ro_en cur r: 0.7464 best r: 0.7464
15:39:28,569 root INFO 
id:et_en cur r: 0.7039 best r: 0.7039
15:39:43,163 root INFO 
id:ne_en cur r: 0.7308 best r: 0.7308
15:39:57,676 root INFO 
id:ru_en cur r: 0.7437 best r: 0.7437
15:39:57,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:39,611 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:41:39,617 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:41:39,622 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:41:39,626 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:41:39,631 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:41:39,636 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:41:39,641 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:41:54,100 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5616
en_de Dev loss: 0.9042 r:0.1578
en_zh Dev loss: 0.7382 r:0.3792
ro_en Dev loss: 0.4308 r:0.7519
et_en Dev loss: 0.3476 r:0.7155
si_en Dev loss: 0.5764 r:0.5761
ne_en Dev loss: 0.3909 r:0.7296
ru_en Dev loss: 0.4279 r:0.7455
Current avg r:0.5794 Best avg r: 0.5794
15:46:17,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:31,421 root INFO 
id:en_de cur r: 0.1697 best r: 0.1697
15:47:00,629 root INFO 
id:ro_en cur r: 0.7748 best r: 0.7748
15:47:44,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:26,247 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5943
en_de Dev loss: 0.9190 r:0.1641
en_zh Dev loss: 0.7639 r:0.3800
ro_en Dev loss: 0.4142 r:0.7781
et_en Dev loss: 0.3556 r:0.7096
si_en Dev loss: 0.5970 r:0.5791
ne_en Dev loss: 0.4252 r:0.7237
ru_en Dev loss: 0.5101 r:0.7161
Current avg r:0.5787 Best avg r: 0.5794
15:53:49,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:03,888 root INFO 
id:en_de cur r: 0.1737 best r: 0.1737
15:54:18,341 root INFO 
id:en_zh cur r: 0.4066 best r: 0.4066
15:54:33,55 root INFO 
id:ro_en cur r: 0.7767 best r: 0.7767
15:55:16,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:58,969 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:56:58,975 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:56:58,980 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:56:58,984 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:56:58,988 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:56:58,992 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:56:58,996 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:57:13,630 root INFO Epoch 0 Global steps: 6000 Train loss: 0.5581
en_de Dev loss: 0.8906 r:0.1816
en_zh Dev loss: 0.6928 r:0.4130
ro_en Dev loss: 0.3766 r:0.7818
et_en Dev loss: 0.3727 r:0.6952
si_en Dev loss: 0.5990 r:0.5739
ne_en Dev loss: 0.4722 r:0.7201
ru_en Dev loss: 0.4286 r:0.7287
Current avg r:0.5849 Best avg r: 0.5849
16:01:36,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:51,265 root INFO 
id:en_de cur r: 0.1824 best r: 0.1824
16:02:20,470 root INFO 
id:ro_en cur r: 0.7934 best r: 0.7934
16:02:49,758 root INFO 
id:ne_en cur r: 0.7429 best r: 0.7429
16:03:04,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:46,590 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
16:04:46,595 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:04:46,600 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:04:46,604 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
16:04:46,608 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
16:04:46,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:04:46,616 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:05:01,268 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5234
en_de Dev loss: 0.9458 r:0.1698
en_zh Dev loss: 0.8383 r:0.4014
ro_en Dev loss: 0.4360 r:0.7932
et_en Dev loss: 0.4016 r:0.7057
si_en Dev loss: 0.7436 r:0.5836
ne_en Dev loss: 0.6429 r:0.7321
ru_en Dev loss: 0.5699 r:0.7154
Current avg r:0.5859 Best avg r: 0.5859
16:09:24,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:38,754 root INFO 
id:en_de cur r: 0.1963 best r: 0.1963
16:10:08,88 root INFO 
id:ro_en cur r: 0.7977 best r: 0.7977
16:10:37,344 root INFO 
id:ne_en cur r: 0.7434 best r: 0.7434
16:10:51,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:33,962 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
16:12:33,967 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:12:33,972 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:12:33,977 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
16:12:33,981 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
16:12:33,986 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:12:33,990 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:12:48,580 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5159
en_de Dev loss: 0.8836 r:0.1794
en_zh Dev loss: 0.7458 r:0.3973
ro_en Dev loss: 0.3781 r:0.7927
et_en Dev loss: 0.3625 r:0.7078
si_en Dev loss: 0.6137 r:0.5890
ne_en Dev loss: 0.5379 r:0.7379
ru_en Dev loss: 0.5053 r:0.7084
Current avg r:0.5875 Best avg r: 0.5875
16:17:11,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:40,747 root INFO 
id:en_zh cur r: 0.4335 best r: 0.4335
16:17:55,446 root INFO 
id:ro_en cur r: 0.8071 best r: 0.8071
16:18:10,149 root INFO 
id:et_en cur r: 0.7117 best r: 0.7117
16:18:24,858 root INFO 
id:ne_en cur r: 0.7608 best r: 0.7608
16:18:39,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:21,267 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
16:20:21,273 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:20:21,278 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:20:21,283 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
16:20:21,288 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
16:20:21,293 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:20:21,297 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:20:35,903 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5499
en_de Dev loss: 0.8639 r:0.1829
en_zh Dev loss: 0.6683 r:0.4382
ro_en Dev loss: 0.3142 r:0.8057
et_en Dev loss: 0.3441 r:0.7164
si_en Dev loss: 0.5263 r:0.6135
ne_en Dev loss: 0.3794 r:0.7582
ru_en Dev loss: 0.4031 r:0.7309
Current avg r:0.6065 Best avg r: 0.6065
16:24:59,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:28,195 root INFO 
id:en_zh cur r: 0.4468 best r: 0.4468
16:26:26,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:09,332 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5253
en_de Dev loss: 0.8761 r:0.1972
en_zh Dev loss: 0.6801 r:0.4488
ro_en Dev loss: 0.3610 r:0.7950
et_en Dev loss: 0.3861 r:0.6939
si_en Dev loss: 0.6273 r:0.5893
ne_en Dev loss: 0.4785 r:0.7458
ru_en Dev loss: 0.4988 r:0.7133
Current avg r:0.5976 Best avg r: 0.6065
16:32:32,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:47,239 root INFO 
id:en_de cur r: 0.2027 best r: 0.2027
16:34:00,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:42,423 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5332
en_de Dev loss: 0.8784 r:0.1818
en_zh Dev loss: 0.7283 r:0.4165
ro_en Dev loss: 0.3681 r:0.8021
et_en Dev loss: 0.3569 r:0.7038
si_en Dev loss: 0.5991 r:0.5882
ne_en Dev loss: 0.5059 r:0.7448
ru_en Dev loss: 0.4435 r:0.7264
Current avg r:0.5948 Best avg r: 0.6065
16:40:06,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:36,34 root INFO 
id:en_zh cur r: 0.4549 best r: 0.4549
16:40:50,620 root INFO 
id:ro_en cur r: 0.8079 best r: 0.8079
16:41:34,348 root INFO 
id:ru_en cur r: 0.7545 best r: 0.7545
16:41:34,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:16,371 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
16:43:16,378 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:43:16,385 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:43:16,390 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
16:43:16,396 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
16:43:16,401 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:43:16,405 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:43:31,1 root INFO Epoch 1 Global steps: 9600 Train loss: 0.4983
en_de Dev loss: 0.8647 r:0.1998
en_zh Dev loss: 0.6922 r:0.4539
ro_en Dev loss: 0.3518 r:0.8096
et_en Dev loss: 0.3596 r:0.7143
si_en Dev loss: 0.5970 r:0.6026
ne_en Dev loss: 0.4049 r:0.7619
ru_en Dev loss: 0.4048 r:0.7600
Current avg r:0.6146 Best avg r: 0.6146
16:47:54,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:23,365 root INFO 
id:en_zh cur r: 0.4634 best r: 0.4634
16:48:38,57 root INFO 
id:ro_en cur r: 0.8187 best r: 0.8187
16:48:52,758 root INFO 
id:et_en cur r: 0.7178 best r: 0.7178
16:49:07,463 root INFO 
id:ne_en cur r: 0.7634 best r: 0.7634
16:49:21,902 root INFO 
id:ru_en cur r: 0.7561 best r: 0.7561
16:49:21,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:04,4 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
16:51:04,10 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:51:04,17 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:51:04,21 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
16:51:04,26 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
16:51:04,33 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:51:04,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:51:18,621 root INFO Epoch 1 Global steps: 10200 Train loss: 0.4852
en_de Dev loss: 0.8647 r:0.2061
en_zh Dev loss: 0.6772 r:0.4597
ro_en Dev loss: 0.3061 r:0.8169
et_en Dev loss: 0.3497 r:0.7146
si_en Dev loss: 0.5484 r:0.6093
ne_en Dev loss: 0.3549 r:0.7634
ru_en Dev loss: 0.3797 r:0.7571
Current avg r:0.6182 Best avg r: 0.6182
16:55:41,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:40,343 root INFO 
id:et_en cur r: 0.7187 best r: 0.7187
16:57:09,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:52,17 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5051
en_de Dev loss: 0.8610 r:0.2067
en_zh Dev loss: 0.6943 r:0.4530
ro_en Dev loss: 0.3065 r:0.8167
et_en Dev loss: 0.3587 r:0.7215
si_en Dev loss: 0.5622 r:0.6035
ne_en Dev loss: 0.3745 r:0.7575
ru_en Dev loss: 0.4062 r:0.7567
Current avg r:0.6165 Best avg r: 0.6182
17:03:15,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:29,699 root INFO 
id:en_de cur r: 0.2125 best r: 0.2125
17:04:43,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:25,434 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4573
en_de Dev loss: 0.8893 r:0.2136
en_zh Dev loss: 0.7437 r:0.4502
ro_en Dev loss: 0.3777 r:0.8126
et_en Dev loss: 0.3826 r:0.7136
si_en Dev loss: 0.6279 r:0.5931
ne_en Dev loss: 0.4316 r:0.7587
ru_en Dev loss: 0.4517 r:0.7450
Current avg r:0.6124 Best avg r: 0.6182
17:10:48,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:03,184 root INFO 
id:en_de cur r: 0.2146 best r: 0.2146
17:12:01,917 root INFO 
id:ne_en cur r: 0.7642 best r: 0.7642
17:12:16,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:59,80 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5231
en_de Dev loss: 0.8655 r:0.2066
en_zh Dev loss: 0.7027 r:0.4520
ro_en Dev loss: 0.3349 r:0.8140
et_en Dev loss: 0.3616 r:0.7114
si_en Dev loss: 0.5561 r:0.6001
ne_en Dev loss: 0.4055 r:0.7647
ru_en Dev loss: 0.4193 r:0.7375
Current avg r:0.6123 Best avg r: 0.6182
17:18:22,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:49,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:32,384 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5087
en_de Dev loss: 0.8699 r:0.1923
en_zh Dev loss: 0.6783 r:0.4554
ro_en Dev loss: 0.3462 r:0.8090
et_en Dev loss: 0.3594 r:0.7117
si_en Dev loss: 0.5672 r:0.5965
ne_en Dev loss: 0.3974 r:0.7636
ru_en Dev loss: 0.3922 r:0.7504
Current avg r:0.6113 Best avg r: 0.6182
17:25:55,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:08,859 root INFO 
id:ne_en cur r: 0.7645 best r: 0.7645
17:27:23,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:05,728 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4976
en_de Dev loss: 0.8541 r:0.1928
en_zh Dev loss: 0.6666 r:0.4484
ro_en Dev loss: 0.2904 r:0.8178
et_en Dev loss: 0.3420 r:0.7222
si_en Dev loss: 0.5559 r:0.5987
ne_en Dev loss: 0.4014 r:0.7648
ru_en Dev loss: 0.3841 r:0.7485
Current avg r:0.6133 Best avg r: 0.6182
17:33:29,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:12,954 root INFO 
id:ro_en cur r: 0.8229 best r: 0.8229
17:34:27,603 root INFO 
id:et_en cur r: 0.7275 best r: 0.7275
17:34:42,195 root INFO 
id:ne_en cur r: 0.7721 best r: 0.7721
17:34:56,681 root INFO 
id:ru_en cur r: 0.7764 best r: 0.7764
17:34:56,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:39,168 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
17:36:39,174 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:36:39,179 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:36:39,184 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
17:36:39,188 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
17:36:39,192 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:36:39,197 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:36:53,791 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4658
en_de Dev loss: 0.8620 r:0.2019
en_zh Dev loss: 0.6644 r:0.4657
ro_en Dev loss: 0.2890 r:0.8211
et_en Dev loss: 0.3283 r:0.7335
si_en Dev loss: 0.5399 r:0.6131
ne_en Dev loss: 0.3307 r:0.7771
ru_en Dev loss: 0.3496 r:0.7766
Current avg r:0.6270 Best avg r: 0.6270
17:41:17,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:44,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:27,361 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4706
en_de Dev loss: 0.8763 r:0.1939
en_zh Dev loss: 0.6783 r:0.4651
ro_en Dev loss: 0.3365 r:0.8161
et_en Dev loss: 0.3474 r:0.7208
si_en Dev loss: 0.5920 r:0.5929
ne_en Dev loss: 0.3976 r:0.7698
ru_en Dev loss: 0.4229 r:0.7491
Current avg r:0.6154 Best avg r: 0.6270
17:48:50,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:03,871 root INFO 
id:ne_en cur r: 0.7747 best r: 0.7747
17:50:18,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:01,80 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4745
en_de Dev loss: 0.8528 r:0.2028
en_zh Dev loss: 0.6531 r:0.4648
ro_en Dev loss: 0.2909 r:0.8212
et_en Dev loss: 0.3517 r:0.7265
si_en Dev loss: 0.5365 r:0.6003
ne_en Dev loss: 0.3553 r:0.7741
ru_en Dev loss: 0.3843 r:0.7473
Current avg r:0.6196 Best avg r: 0.6270
17:56:24,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:52,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:34,927 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4784
en_de Dev loss: 0.8616 r:0.2120
en_zh Dev loss: 0.6863 r:0.4648
ro_en Dev loss: 0.3516 r:0.8152
et_en Dev loss: 0.3542 r:0.7172
si_en Dev loss: 0.6213 r:0.5835
ne_en Dev loss: 0.4137 r:0.7691
ru_en Dev loss: 0.4714 r:0.7269
Current avg r:0.6127 Best avg r: 0.6270
18:03:58,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:27,358 root INFO 
id:en_zh cur r: 0.4756 best r: 0.4756
18:04:42,58 root INFO 
id:ro_en cur r: 0.8273 best r: 0.8273
18:05:26,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:08,724 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4821
en_de Dev loss: 0.8717 r:0.1896
en_zh Dev loss: 0.6577 r:0.4790
ro_en Dev loss: 0.3126 r:0.8232
et_en Dev loss: 0.3468 r:0.7183
si_en Dev loss: 0.5692 r:0.5979
ne_en Dev loss: 0.3667 r:0.7734
ru_en Dev loss: 0.4170 r:0.7439
Current avg r:0.6179 Best avg r: 0.6270
18:11:32,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:01,166 root INFO 
id:en_zh cur r: 0.4843 best r: 0.4843
18:12:15,859 root INFO 
id:ro_en cur r: 0.8332 best r: 0.8332
18:12:45,264 root INFO 
id:ne_en cur r: 0.7793 best r: 0.7793
18:12:59,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:42,521 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4284
en_de Dev loss: 0.8674 r:0.1849
en_zh Dev loss: 0.6379 r:0.4860
ro_en Dev loss: 0.2808 r:0.8292
et_en Dev loss: 0.3547 r:0.7248
si_en Dev loss: 0.5340 r:0.6036
ne_en Dev loss: 0.3635 r:0.7778
ru_en Dev loss: 0.3635 r:0.7552
Current avg r:0.6231 Best avg r: 0.6270
18:19:05,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:35,22 root INFO 
id:en_zh cur r: 0.4863 best r: 0.4863
18:20:33,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:16,230 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4366
en_de Dev loss: 0.8655 r:0.1775
en_zh Dev loss: 0.6680 r:0.4823
ro_en Dev loss: 0.3158 r:0.8225
et_en Dev loss: 0.3774 r:0.7192
si_en Dev loss: 0.5809 r:0.5937
ne_en Dev loss: 0.3615 r:0.7733
ru_en Dev loss: 0.3717 r:0.7628
Current avg r:0.6188 Best avg r: 0.6270
18:26:39,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:54,32 root INFO 
id:en_de cur r: 0.2229 best r: 0.2229
18:27:52,536 root INFO 
id:ne_en cur r: 0.7801 best r: 0.7801
18:28:07,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:49,423 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4491
en_de Dev loss: 0.8719 r:0.2009
en_zh Dev loss: 0.7018 r:0.4516
ro_en Dev loss: 0.3080 r:0.8172
et_en Dev loss: 0.3555 r:0.7183
si_en Dev loss: 0.5612 r:0.5902
ne_en Dev loss: 0.4063 r:0.7767
ru_en Dev loss: 0.4341 r:0.7187
Current avg r:0.6105 Best avg r: 0.6270
18:34:13,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:41,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:23,890 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4257
en_de Dev loss: 0.8548 r:0.1981
en_zh Dev loss: 0.6661 r:0.4653
ro_en Dev loss: 0.3097 r:0.8198
et_en Dev loss: 0.3715 r:0.7117
si_en Dev loss: 0.5552 r:0.5932
ne_en Dev loss: 0.3825 r:0.7682
ru_en Dev loss: 0.4100 r:0.7220
Current avg r:0.6112 Best avg r: 0.6270
18:41:47,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:14,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:57,337 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4468
en_de Dev loss: 0.8590 r:0.1944
en_zh Dev loss: 0.6722 r:0.4771
ro_en Dev loss: 0.3058 r:0.8267
et_en Dev loss: 0.3586 r:0.7184
si_en Dev loss: 0.5667 r:0.6036
ne_en Dev loss: 0.3961 r:0.7729
ru_en Dev loss: 0.3966 r:0.7393
Current avg r:0.6189 Best avg r: 0.6270
18:49:20,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:48,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:30,606 root INFO Epoch 2 Global steps: 19800 Train loss: 0.3987
en_de Dev loss: 0.8554 r:0.1955
en_zh Dev loss: 0.6712 r:0.4499
ro_en Dev loss: 0.2829 r:0.8229
et_en Dev loss: 0.3526 r:0.7139
si_en Dev loss: 0.5478 r:0.5930
ne_en Dev loss: 0.3818 r:0.7716
ru_en Dev loss: 0.4258 r:0.7092
Current avg r:0.6080 Best avg r: 0.6270
18:56:53,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:21,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:03,812 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4311
en_de Dev loss: 0.8964 r:0.1515
en_zh Dev loss: 0.6740 r:0.4829
ro_en Dev loss: 0.3142 r:0.8241
et_en Dev loss: 0.4141 r:0.7041
si_en Dev loss: 0.5359 r:0.6059
ne_en Dev loss: 0.3420 r:0.7727
ru_en Dev loss: 0.4575 r:0.7058
Current avg r:0.6067 Best avg r: 0.6270
19:04:27,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:41,371 root INFO 
id:en_de cur r: 0.2278 best r: 0.2278
19:05:54,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:36,653 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4073
en_de Dev loss: 0.8846 r:0.2114
en_zh Dev loss: 0.7329 r:0.4498
ro_en Dev loss: 0.3679 r:0.8131
et_en Dev loss: 0.3911 r:0.6941
si_en Dev loss: 0.6323 r:0.5790
ne_en Dev loss: 0.5091 r:0.7686
ru_en Dev loss: 0.4640 r:0.7156
Current avg r:0.6045 Best avg r: 0.6270
19:11:59,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:27,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:09,390 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4024
en_de Dev loss: 0.9041 r:0.1883
en_zh Dev loss: 0.7752 r:0.4595
ro_en Dev loss: 0.3745 r:0.8232
et_en Dev loss: 0.3992 r:0.7019
si_en Dev loss: 0.7155 r:0.5803
ne_en Dev loss: 0.5583 r:0.7722
ru_en Dev loss: 0.5082 r:0.7257
Current avg r:0.6073 Best avg r: 0.6270
19:19:32,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:00,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:42,360 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4326
en_de Dev loss: 0.8614 r:0.1965
en_zh Dev loss: 0.6621 r:0.4771
ro_en Dev loss: 0.2992 r:0.8230
et_en Dev loss: 0.3776 r:0.7027
si_en Dev loss: 0.5495 r:0.5954
ne_en Dev loss: 0.3408 r:0.7770
ru_en Dev loss: 0.4225 r:0.7257
Current avg r:0.6139 Best avg r: 0.6270
19:27:05,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:32,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:14,693 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4193
en_de Dev loss: 0.8500 r:0.2082
en_zh Dev loss: 0.6814 r:0.4677
ro_en Dev loss: 0.2989 r:0.8293
et_en Dev loss: 0.3639 r:0.7119
si_en Dev loss: 0.5643 r:0.5982
ne_en Dev loss: 0.4067 r:0.7728
ru_en Dev loss: 0.4329 r:0.7243
Current avg r:0.6161 Best avg r: 0.6270
19:34:37,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:05,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:47,102 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4210
en_de Dev loss: 0.8578 r:0.1997
en_zh Dev loss: 0.6995 r:0.4620
ro_en Dev loss: 0.3286 r:0.8237
et_en Dev loss: 0.3641 r:0.7098
si_en Dev loss: 0.6104 r:0.5857
ne_en Dev loss: 0.4384 r:0.7669
ru_en Dev loss: 0.4248 r:0.7304
Current avg r:0.6112 Best avg r: 0.6270
19:42:10,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:24,712 root INFO 
id:en_de cur r: 0.2419 best r: 0.2419
19:43:37,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:20,18 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4004
en_de Dev loss: 0.8726 r:0.2180
en_zh Dev loss: 0.7437 r:0.4442
ro_en Dev loss: 0.3578 r:0.8204
et_en Dev loss: 0.3871 r:0.6998
si_en Dev loss: 0.6478 r:0.5760
ne_en Dev loss: 0.4390 r:0.7678
ru_en Dev loss: 0.4676 r:0.7160
Current avg r:0.6060 Best avg r: 0.6270
19:49:43,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:57,681 root INFO 
id:en_de cur r: 0.2420 best r: 0.2420
19:51:10,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:53,35 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4341
en_de Dev loss: 0.8678 r:0.2232
en_zh Dev loss: 0.7527 r:0.4532
ro_en Dev loss: 0.3494 r:0.8231
et_en Dev loss: 0.4016 r:0.7078
si_en Dev loss: 0.6067 r:0.5891
ne_en Dev loss: 0.4239 r:0.7661
ru_en Dev loss: 0.4958 r:0.7032
Current avg r:0.6094 Best avg r: 0.6270
19:57:16,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:43,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:26,18 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4102
en_de Dev loss: 0.8441 r:0.2300
en_zh Dev loss: 0.6903 r:0.4662
ro_en Dev loss: 0.2887 r:0.8294
et_en Dev loss: 0.3808 r:0.7184
si_en Dev loss: 0.5537 r:0.5986
ne_en Dev loss: 0.3489 r:0.7751
ru_en Dev loss: 0.3742 r:0.7587
Current avg r:0.6252 Best avg r: 0.6270
20:04:49,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:16,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:58,871 root INFO Epoch 2 Global steps: 25800 Train loss: 0.3902
en_de Dev loss: 0.8552 r:0.2174
en_zh Dev loss: 0.7377 r:0.4455
ro_en Dev loss: 0.2996 r:0.8282
et_en Dev loss: 0.3659 r:0.7102
si_en Dev loss: 0.6387 r:0.5802
ne_en Dev loss: 0.4317 r:0.7694
ru_en Dev loss: 0.4619 r:0.7217
Current avg r:0.6104 Best avg r: 0.6270
20:12:22,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:49,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:31,824 root INFO Epoch 2 Global steps: 26400 Train loss: 0.3995
en_de Dev loss: 0.8464 r:0.2201
en_zh Dev loss: 0.6847 r:0.4596
ro_en Dev loss: 0.2950 r:0.8271
et_en Dev loss: 0.3551 r:0.7185
si_en Dev loss: 0.5728 r:0.5878
ne_en Dev loss: 0.3645 r:0.7778
ru_en Dev loss: 0.3748 r:0.7535
Current avg r:0.6206 Best avg r: 0.6270
20:19:55,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:22,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:04,436 root INFO Epoch 2 Global steps: 27000 Train loss: 0.3975
en_de Dev loss: 0.8434 r:0.2227
en_zh Dev loss: 0.6887 r:0.4603
ro_en Dev loss: 0.2950 r:0.8277
et_en Dev loss: 0.3825 r:0.7215
si_en Dev loss: 0.5659 r:0.5939
ne_en Dev loss: 0.3486 r:0.7784
ru_en Dev loss: 0.3932 r:0.7493
Current avg r:0.6220 Best avg r: 0.6270
20:27:28,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:55,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:38,55 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3437
en_de Dev loss: 0.8757 r:0.2189
en_zh Dev loss: 0.7775 r:0.4496
ro_en Dev loss: 0.3553 r:0.8232
et_en Dev loss: 0.4048 r:0.7021
si_en Dev loss: 0.7090 r:0.5739
ne_en Dev loss: 0.5432 r:0.7672
ru_en Dev loss: 0.5282 r:0.7076
Current avg r:0.6061 Best avg r: 0.6270
20:35:01,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:29,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:11,265 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3306
en_de Dev loss: 0.8635 r:0.1972
en_zh Dev loss: 0.7414 r:0.4510
ro_en Dev loss: 0.3238 r:0.8297
et_en Dev loss: 0.3901 r:0.7040
si_en Dev loss: 0.6335 r:0.5848
ne_en Dev loss: 0.3894 r:0.7725
ru_en Dev loss: 0.4430 r:0.7289
Current avg r:0.6097 Best avg r: 0.6270
20:42:34,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:01,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:44,239 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3529
en_de Dev loss: 0.8602 r:0.2065
en_zh Dev loss: 0.7420 r:0.4489
ro_en Dev loss: 0.3189 r:0.8284
et_en Dev loss: 0.3941 r:0.6960
si_en Dev loss: 0.6294 r:0.5793
ne_en Dev loss: 0.3942 r:0.7725
ru_en Dev loss: 0.4630 r:0.7140
Current avg r:0.6065 Best avg r: 0.6270
20:50:07,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:35,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:17,441 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3661
en_de Dev loss: 0.8433 r:0.2249
en_zh Dev loss: 0.7244 r:0.4434
ro_en Dev loss: 0.3125 r:0.8238
et_en Dev loss: 0.3893 r:0.7020
si_en Dev loss: 0.6006 r:0.5718
ne_en Dev loss: 0.4354 r:0.7620
ru_en Dev loss: 0.4583 r:0.7009
Current avg r:0.6041 Best avg r: 0.6270
20:57:40,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:08,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:50,507 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3773
en_de Dev loss: 0.8796 r:0.1849
en_zh Dev loss: 0.7483 r:0.4567
ro_en Dev loss: 0.3088 r:0.8274
et_en Dev loss: 0.3996 r:0.7083
si_en Dev loss: 0.5983 r:0.5909
ne_en Dev loss: 0.4008 r:0.7569
ru_en Dev loss: 0.4354 r:0.7307
Current avg r:0.6080 Best avg r: 0.6270
21:05:13,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:41,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:23,283 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3699
en_de Dev loss: 0.8575 r:0.2071
en_zh Dev loss: 0.7285 r:0.4660
ro_en Dev loss: 0.3407 r:0.8221
et_en Dev loss: 0.3969 r:0.7024
si_en Dev loss: 0.6896 r:0.5739
ne_en Dev loss: 0.4957 r:0.7545
ru_en Dev loss: 0.4722 r:0.7186
Current avg r:0.6064 Best avg r: 0.6270
21:12:46,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:13,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:56,115 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3550
en_de Dev loss: 0.8747 r:0.2026
en_zh Dev loss: 0.7893 r:0.4479
ro_en Dev loss: 0.3388 r:0.8241
et_en Dev loss: 0.3863 r:0.6976
si_en Dev loss: 0.6773 r:0.5660
ne_en Dev loss: 0.4313 r:0.7602
ru_en Dev loss: 0.4551 r:0.7235
Current avg r:0.6031 Best avg r: 0.6270
21:20:19,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:46,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:28,758 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3676
en_de Dev loss: 0.8753 r:0.2099
en_zh Dev loss: 0.7882 r:0.4472
ro_en Dev loss: 0.3865 r:0.8191
et_en Dev loss: 0.4325 r:0.7016
si_en Dev loss: 0.6507 r:0.5753
ne_en Dev loss: 0.4424 r:0.7520
ru_en Dev loss: 0.4709 r:0.7288
Current avg r:0.6049 Best avg r: 0.6270
21:27:52,5 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:29:19,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:00,980 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3245
en_de Dev loss: 0.9047 r:0.2054
en_zh Dev loss: 0.8340 r:0.4404
ro_en Dev loss: 0.4028 r:0.8196
et_en Dev loss: 0.4231 r:0.6885
si_en Dev loss: 0.7270 r:0.5624
ne_en Dev loss: 0.4501 r:0.7581
ru_en Dev loss: 0.5301 r:0.7061
Current avg r:0.5972 Best avg r: 0.6270
21:35:24,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:51,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:33,296 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3743
en_de Dev loss: 0.8712 r:0.2081
en_zh Dev loss: 0.7617 r:0.4634
ro_en Dev loss: 0.3354 r:0.8273
et_en Dev loss: 0.4239 r:0.6940
si_en Dev loss: 0.6137 r:0.5835
ne_en Dev loss: 0.4033 r:0.7554
ru_en Dev loss: 0.4165 r:0.7472
Current avg r:0.6112 Best avg r: 0.6270
21:42:56,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:23,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:05,804 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3513
en_de Dev loss: 0.8617 r:0.2040
en_zh Dev loss: 0.7495 r:0.4430
ro_en Dev loss: 0.3472 r:0.8190
et_en Dev loss: 0.4002 r:0.6841
si_en Dev loss: 0.6615 r:0.5711
ne_en Dev loss: 0.5327 r:0.7535
ru_en Dev loss: 0.4943 r:0.6991
Current avg r:0.5962 Best avg r: 0.6270
21:50:28,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:55,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:37,837 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3725
en_de Dev loss: 0.8704 r:0.2094
en_zh Dev loss: 0.7815 r:0.4481
ro_en Dev loss: 0.3652 r:0.8212
et_en Dev loss: 0.3983 r:0.6968
si_en Dev loss: 0.6220 r:0.5868
ne_en Dev loss: 0.4073 r:0.7592
ru_en Dev loss: 0.4763 r:0.7166
Current avg r:0.6054 Best avg r: 0.6270
21:58:01,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:28,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:10,0 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3515
en_de Dev loss: 0.8582 r:0.2240
en_zh Dev loss: 0.7703 r:0.4419
ro_en Dev loss: 0.3243 r:0.8232
et_en Dev loss: 0.4048 r:0.6954
si_en Dev loss: 0.6137 r:0.5831
ne_en Dev loss: 0.4426 r:0.7525
ru_en Dev loss: 0.4718 r:0.7196
Current avg r:0.6057 Best avg r: 0.6270
22:05:33,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:47,372 root INFO 
id:en_de cur r: 0.2473 best r: 0.2473
22:07:00,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:08:42,163 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3431
en_de Dev loss: 0.8603 r:0.2316
en_zh Dev loss: 0.7870 r:0.4325
ro_en Dev loss: 0.3295 r:0.8236
et_en Dev loss: 0.4138 r:0.6937
si_en Dev loss: 0.6053 r:0.5810
ne_en Dev loss: 0.4338 r:0.7527
ru_en Dev loss: 0.4817 r:0.7088
Current avg r:0.6034 Best avg r: 0.6270
22:13:05,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:32,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:16:14,580 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3438
en_de Dev loss: 0.8587 r:0.2297
en_zh Dev loss: 0.7461 r:0.4540
ro_en Dev loss: 0.3109 r:0.8288
et_en Dev loss: 0.3860 r:0.7008
si_en Dev loss: 0.5973 r:0.5850
ne_en Dev loss: 0.4055 r:0.7626
ru_en Dev loss: 0.4361 r:0.7327
Current avg r:0.6134 Best avg r: 0.6270
22:20:38,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:05,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:47,828 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3154
en_de Dev loss: 0.8424 r:0.2306
en_zh Dev loss: 0.7198 r:0.4522
ro_en Dev loss: 0.3012 r:0.8279
et_en Dev loss: 0.4148 r:0.6989
si_en Dev loss: 0.5735 r:0.5846
ne_en Dev loss: 0.3907 r:0.7631
ru_en Dev loss: 0.4051 r:0.7327
Current avg r:0.6128 Best avg r: 0.6270
22:28:11,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:54,476 root INFO 
id:ro_en cur r: 0.8334 best r: 0.8334
22:29:38,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:20,94 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3217
en_de Dev loss: 0.8497 r:0.2372
en_zh Dev loss: 0.7712 r:0.4538
ro_en Dev loss: 0.3291 r:0.8313
et_en Dev loss: 0.4490 r:0.7044
si_en Dev loss: 0.5809 r:0.5957
ne_en Dev loss: 0.3695 r:0.7637
ru_en Dev loss: 0.3986 r:0.7582
Current avg r:0.6206 Best avg r: 0.6270
22:35:43,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:10,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:52,330 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3042
en_de Dev loss: 0.8432 r:0.2347
en_zh Dev loss: 0.7311 r:0.4580
ro_en Dev loss: 0.3040 r:0.8238
et_en Dev loss: 0.4294 r:0.6857
si_en Dev loss: 0.5942 r:0.5727
ne_en Dev loss: 0.3842 r:0.7591
ru_en Dev loss: 0.4196 r:0.7215
Current avg r:0.6079 Best avg r: 0.6270
22:43:15,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:42,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:24,605 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3028
en_de Dev loss: 0.8483 r:0.2241
en_zh Dev loss: 0.7828 r:0.4419
ro_en Dev loss: 0.3550 r:0.8183
et_en Dev loss: 0.4457 r:0.6734
si_en Dev loss: 0.6997 r:0.5551
ne_en Dev loss: 0.4965 r:0.7515
ru_en Dev loss: 0.4691 r:0.7104
Current avg r:0.5964 Best avg r: 0.6270
22:50:47,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:15,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:56,982 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3024
en_de Dev loss: 0.8493 r:0.2220
en_zh Dev loss: 0.7644 r:0.4592
ro_en Dev loss: 0.3336 r:0.8264
et_en Dev loss: 0.4403 r:0.6785
si_en Dev loss: 0.6556 r:0.5704
ne_en Dev loss: 0.4319 r:0.7568
ru_en Dev loss: 0.4254 r:0.7361
Current avg r:0.6070 Best avg r: 0.6270
22:58:20,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:47,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:29,91 root INFO Epoch 4 Global steps: 39600 Train loss: 0.2982
en_de Dev loss: 0.8552 r:0.2149
en_zh Dev loss: 0.7349 r:0.4627
ro_en Dev loss: 0.3078 r:0.8264
et_en Dev loss: 0.4058 r:0.6915
si_en Dev loss: 0.6243 r:0.5836
ne_en Dev loss: 0.4014 r:0.7597
ru_en Dev loss: 0.4155 r:0.7399
Current avg r:0.6112 Best avg r: 0.6270
23:05:52,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:19,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:09:01,329 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3046
en_de Dev loss: 0.8527 r:0.2242
en_zh Dev loss: 0.7082 r:0.4817
ro_en Dev loss: 0.3075 r:0.8303
et_en Dev loss: 0.3993 r:0.6940
si_en Dev loss: 0.6198 r:0.5819
ne_en Dev loss: 0.4210 r:0.7576
ru_en Dev loss: 0.4080 r:0.7457
Current avg r:0.6165 Best avg r: 0.6270
23:13:24,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:51,438 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:33,317 root INFO Epoch 4 Global steps: 40800 Train loss: 0.2956
en_de Dev loss: 0.8589 r:0.2248
en_zh Dev loss: 0.7402 r:0.4629
ro_en Dev loss: 0.3087 r:0.8269
et_en Dev loss: 0.4167 r:0.6873
si_en Dev loss: 0.6078 r:0.5796
ne_en Dev loss: 0.4135 r:0.7537
ru_en Dev loss: 0.4173 r:0.7408
Current avg r:0.6109 Best avg r: 0.6270
23:20:56,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:23,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:24:05,957 root INFO Epoch 4 Global steps: 41400 Train loss: 0.2983
en_de Dev loss: 0.8544 r:0.2389
en_zh Dev loss: 0.7544 r:0.4626
ro_en Dev loss: 0.3108 r:0.8262
et_en Dev loss: 0.4275 r:0.6899
si_en Dev loss: 0.6202 r:0.5797
ne_en Dev loss: 0.4972 r:0.7537
ru_en Dev loss: 0.4261 r:0.7355
Current avg r:0.6124 Best avg r: 0.6270
23:28:29,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:56,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:38,684 root INFO Epoch 4 Global steps: 42000 Train loss: 0.2970
en_de Dev loss: 0.8829 r:0.2044
en_zh Dev loss: 0.7980 r:0.4499
ro_en Dev loss: 0.3514 r:0.8251
et_en Dev loss: 0.4475 r:0.6899
si_en Dev loss: 0.6252 r:0.5888
ne_en Dev loss: 0.4334 r:0.7524
ru_en Dev loss: 0.4536 r:0.7372
Current avg r:0.6068 Best avg r: 0.6270
23:36:01,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:29,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:11,377 root INFO Epoch 4 Global steps: 42600 Train loss: 0.2987
en_de Dev loss: 0.8879 r:0.1714
en_zh Dev loss: 0.8173 r:0.4382
ro_en Dev loss: 0.3294 r:0.8230
et_en Dev loss: 0.4043 r:0.6856
si_en Dev loss: 0.6553 r:0.5710
ne_en Dev loss: 0.5021 r:0.7520
ru_en Dev loss: 0.5012 r:0.7073
Current avg r:0.5926 Best avg r: 0.6270
23:43:34,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:02,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:44,82 root INFO Epoch 4 Global steps: 43200 Train loss: 0.2829
en_de Dev loss: 0.8665 r:0.2102
en_zh Dev loss: 0.8128 r:0.4378
ro_en Dev loss: 0.3507 r:0.8211
et_en Dev loss: 0.4450 r:0.6788
si_en Dev loss: 0.6700 r:0.5605
ne_en Dev loss: 0.4657 r:0.7520
ru_en Dev loss: 0.4480 r:0.7285
Current avg r:0.5984 Best avg r: 0.6270
23:51:07,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:34,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:54:16,933 root INFO Epoch 4 Global steps: 43800 Train loss: 0.2898
en_de Dev loss: 0.8484 r:0.2224
en_zh Dev loss: 0.7462 r:0.4551
ro_en Dev loss: 0.3175 r:0.8239
et_en Dev loss: 0.4385 r:0.6839
si_en Dev loss: 0.6162 r:0.5747
ne_en Dev loss: 0.4643 r:0.7508
ru_en Dev loss: 0.4391 r:0.7155
Current avg r:0.6038 Best avg r: 0.6270
23:58:40,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:00:07,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:49,827 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2930
en_de Dev loss: 0.8487 r:0.2286
en_zh Dev loss: 0.7562 r:0.4485
ro_en Dev loss: 0.3365 r:0.8185
et_en Dev loss: 0.4248 r:0.6793
si_en Dev loss: 0.6413 r:0.5702
ne_en Dev loss: 0.4404 r:0.7502
ru_en Dev loss: 0.4415 r:0.7207
Current avg r:0.6023 Best avg r: 0.6270
00:06:13,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:40,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:09:22,428 root INFO Epoch 4 Global steps: 45000 Train loss: 0.2803
en_de Dev loss: 0.8598 r:0.2077
en_zh Dev loss: 0.7697 r:0.4167
ro_en Dev loss: 0.3171 r:0.8162
et_en Dev loss: 0.4182 r:0.6767
si_en Dev loss: 0.5945 r:0.5688
ne_en Dev loss: 0.4361 r:0.7541
ru_en Dev loss: 0.4546 r:0.6999
Current avg r:0.5914 Best avg r: 0.6270
00:13:46,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:15:13,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:16:55,922 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2573
en_de Dev loss: 0.8684 r:0.2032
en_zh Dev loss: 0.8002 r:0.4290
ro_en Dev loss: 0.3458 r:0.8200
et_en Dev loss: 0.4336 r:0.6789
si_en Dev loss: 0.6382 r:0.5749
ne_en Dev loss: 0.4701 r:0.7453
ru_en Dev loss: 0.4461 r:0.7275
Current avg r:0.5970 Best avg r: 0.6270
00:21:19,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:46,401 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:24:28,542 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2705
en_de Dev loss: 0.8836 r:0.1821
en_zh Dev loss: 0.7962 r:0.4346
ro_en Dev loss: 0.3495 r:0.8171
et_en Dev loss: 0.4367 r:0.6806
si_en Dev loss: 0.6417 r:0.5746
ne_en Dev loss: 0.4885 r:0.7486
ru_en Dev loss: 0.4502 r:0.7207
Current avg r:0.5940 Best avg r: 0.6270
00:28:51,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:30:19,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:01,202 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2641
en_de Dev loss: 0.8721 r:0.1897
en_zh Dev loss: 0.7688 r:0.4458
ro_en Dev loss: 0.3230 r:0.8200
et_en Dev loss: 0.4696 r:0.6852
si_en Dev loss: 0.6332 r:0.5819
ne_en Dev loss: 0.4677 r:0.7378
ru_en Dev loss: 0.4103 r:0.7401
Current avg r:0.6001 Best avg r: 0.6270
00:36:24,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:51,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:34,78 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2556
en_de Dev loss: 0.8835 r:0.1971
en_zh Dev loss: 0.7901 r:0.4419
ro_en Dev loss: 0.3773 r:0.8151
et_en Dev loss: 0.4529 r:0.6825
si_en Dev loss: 0.6897 r:0.5690
ne_en Dev loss: 0.5380 r:0.7511
ru_en Dev loss: 0.4542 r:0.7279
Current avg r:0.5978 Best avg r: 0.6270
00:43:57,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:24,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:07,273 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2504
en_de Dev loss: 0.8815 r:0.1719
en_zh Dev loss: 0.7857 r:0.4215
ro_en Dev loss: 0.3470 r:0.8136
et_en Dev loss: 0.4322 r:0.6739
si_en Dev loss: 0.6524 r:0.5593
ne_en Dev loss: 0.4890 r:0.7440
ru_en Dev loss: 0.4817 r:0.6978
Current avg r:0.5831 Best avg r: 0.6270
00:51:30,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:57,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:39,953 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2639
en_de Dev loss: 0.8785 r:0.1979
en_zh Dev loss: 0.8358 r:0.4101
ro_en Dev loss: 0.3755 r:0.8112
et_en Dev loss: 0.4459 r:0.6734
si_en Dev loss: 0.6728 r:0.5586
ne_en Dev loss: 0.5189 r:0.7383
ru_en Dev loss: 0.5070 r:0.6939
Current avg r:0.5833 Best avg r: 0.6270
00:59:03,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:30,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:12,729 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2493
en_de Dev loss: 0.8744 r:0.2125
en_zh Dev loss: 0.7762 r:0.4686
ro_en Dev loss: 0.3214 r:0.8260
et_en Dev loss: 0.4798 r:0.6880
si_en Dev loss: 0.5999 r:0.5850
ne_en Dev loss: 0.3941 r:0.7409
ru_en Dev loss: 0.3952 r:0.7545
Current avg r:0.6108 Best avg r: 0.6270
01:06:35,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:03,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:09:44,958 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2507
en_de Dev loss: 0.8661 r:0.2147
en_zh Dev loss: 0.7526 r:0.4590
ro_en Dev loss: 0.3116 r:0.8261
et_en Dev loss: 0.4296 r:0.6789
si_en Dev loss: 0.6368 r:0.5694
ne_en Dev loss: 0.4610 r:0.7418
ru_en Dev loss: 0.4330 r:0.7309
Current avg r:0.6030 Best avg r: 0.6270
01:14:08,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:35,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:17,752 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2562
en_de Dev loss: 0.8717 r:0.2077
en_zh Dev loss: 0.8424 r:0.4300
ro_en Dev loss: 0.3693 r:0.8143
et_en Dev loss: 0.4599 r:0.6648
si_en Dev loss: 0.7198 r:0.5510
ne_en Dev loss: 0.5522 r:0.7397
ru_en Dev loss: 0.4633 r:0.7214
Current avg r:0.5898 Best avg r: 0.6270
01:21:41,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:08,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:50,534 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2520
en_de Dev loss: 0.8698 r:0.2118
en_zh Dev loss: 0.7376 r:0.4623
ro_en Dev loss: 0.3363 r:0.8176
et_en Dev loss: 0.4131 r:0.6722
si_en Dev loss: 0.6971 r:0.5566
ne_en Dev loss: 0.5624 r:0.7430
ru_en Dev loss: 0.4108 r:0.7387
Current avg r:0.6003 Best avg r: 0.6270
01:29:13,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:41,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:23,399 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2387
en_de Dev loss: 0.8853 r:0.2032
en_zh Dev loss: 0.7708 r:0.4590
ro_en Dev loss: 0.3520 r:0.8165
et_en Dev loss: 0.4572 r:0.6670
si_en Dev loss: 0.6683 r:0.5634
ne_en Dev loss: 0.5260 r:0.7406
ru_en Dev loss: 0.4645 r:0.7214
Current avg r:0.5959 Best avg r: 0.6270
01:36:46,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:38:14,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:56,314 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2409
en_de Dev loss: 0.8830 r:0.2156
en_zh Dev loss: 0.8060 r:0.4617
ro_en Dev loss: 0.3602 r:0.8158
et_en Dev loss: 0.5158 r:0.6708
si_en Dev loss: 0.6559 r:0.5711
ne_en Dev loss: 0.4461 r:0.7421
ru_en Dev loss: 0.4529 r:0.7271
Current avg r:0.6006 Best avg r: 0.6270
01:44:19,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:45:46,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:47:29,162 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2343
en_de Dev loss: 0.8801 r:0.1903
en_zh Dev loss: 0.7983 r:0.4458
ro_en Dev loss: 0.3469 r:0.8162
et_en Dev loss: 0.4851 r:0.6590
si_en Dev loss: 0.6812 r:0.5604
ne_en Dev loss: 0.4595 r:0.7335
ru_en Dev loss: 0.4895 r:0.6960
Current avg r:0.5859 Best avg r: 0.6270
01:51:52,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:53:19,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:55:01,929 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2429
en_de Dev loss: 0.8742 r:0.2030
en_zh Dev loss: 0.7617 r:0.4668
ro_en Dev loss: 0.3370 r:0.8168
et_en Dev loss: 0.4680 r:0.6689
si_en Dev loss: 0.6918 r:0.5642
ne_en Dev loss: 0.4809 r:0.7372
ru_en Dev loss: 0.4475 r:0.7274
Current avg r:0.5978 Best avg r: 0.6270
01:59:25,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:00:52,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:02:34,924 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2487
en_de Dev loss: 0.8781 r:0.2052
en_zh Dev loss: 0.7470 r:0.4616
ro_en Dev loss: 0.3157 r:0.8198
et_en Dev loss: 0.4802 r:0.6748
si_en Dev loss: 0.6214 r:0.5732
ne_en Dev loss: 0.4145 r:0.7422
ru_en Dev loss: 0.4089 r:0.7381
Current avg r:0.6021 Best avg r: 0.6270
02:06:59,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:08:26,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:08,644 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2238
en_de Dev loss: 0.8932 r:0.1819
en_zh Dev loss: 0.7425 r:0.4630
ro_en Dev loss: 0.3063 r:0.8213
et_en Dev loss: 0.4688 r:0.6758
si_en Dev loss: 0.6193 r:0.5743
ne_en Dev loss: 0.4206 r:0.7403
ru_en Dev loss: 0.3859 r:0.7536
Current avg r:0.6014 Best avg r: 0.6270
02:14:31,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:15:59,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:17:41,183 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2145
en_de Dev loss: 0.8854 r:0.2091
en_zh Dev loss: 0.7950 r:0.4562
ro_en Dev loss: 0.3246 r:0.8194
et_en Dev loss: 0.4795 r:0.6829
si_en Dev loss: 0.6342 r:0.5798
ne_en Dev loss: 0.4268 r:0.7388
ru_en Dev loss: 0.4264 r:0.7426
Current avg r:0.6041 Best avg r: 0.6270
02:22:04,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:23:32,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:14,194 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2181
en_de Dev loss: 0.8603 r:0.2036
en_zh Dev loss: 0.7889 r:0.4226
ro_en Dev loss: 0.3529 r:0.8076
et_en Dev loss: 0.4494 r:0.6577
si_en Dev loss: 0.7163 r:0.5441
ne_en Dev loss: 0.5689 r:0.7248
ru_en Dev loss: 0.4681 r:0.7066
Current avg r:0.5810 Best avg r: 0.6270
02:29:37,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:04,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:32:47,77 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2198
en_de Dev loss: 0.8940 r:0.1954
en_zh Dev loss: 0.7817 r:0.4597
ro_en Dev loss: 0.3337 r:0.8202
et_en Dev loss: 0.4519 r:0.6717
si_en Dev loss: 0.6514 r:0.5704
ne_en Dev loss: 0.4518 r:0.7340
ru_en Dev loss: 0.4848 r:0.7167
Current avg r:0.5954 Best avg r: 0.6270
02:37:10,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:38:37,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:40:19,966 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2171
en_de Dev loss: 0.8774 r:0.2164
en_zh Dev loss: 0.7518 r:0.4697
ro_en Dev loss: 0.3390 r:0.8164
et_en Dev loss: 0.4462 r:0.6752
si_en Dev loss: 0.6763 r:0.5624
ne_en Dev loss: 0.4791 r:0.7241
ru_en Dev loss: 0.4596 r:0.7318
Current avg r:0.5994 Best avg r: 0.6270
02:44:43,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:46:10,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:47:53,89 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2317
en_de Dev loss: 0.8974 r:0.1937
en_zh Dev loss: 0.7921 r:0.4621
ro_en Dev loss: 0.3759 r:0.8143
et_en Dev loss: 0.4750 r:0.6682
si_en Dev loss: 0.6837 r:0.5576
ne_en Dev loss: 0.5345 r:0.7249
ru_en Dev loss: 0.4900 r:0.7180
Current avg r:0.5913 Best avg r: 0.6270
02:52:16,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:53:43,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:55:25,845 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2155
en_de Dev loss: 0.8736 r:0.2025
en_zh Dev loss: 0.7716 r:0.4568
ro_en Dev loss: 0.3204 r:0.8236
et_en Dev loss: 0.4898 r:0.6810
si_en Dev loss: 0.6226 r:0.5774
ne_en Dev loss: 0.4423 r:0.7363
ru_en Dev loss: 0.4211 r:0.7404
Current avg r:0.6026 Best avg r: 0.6270
02:59:49,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:01:16,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:02:58,813 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2028
en_de Dev loss: 0.8906 r:0.1928
en_zh Dev loss: 0.7769 r:0.4628
ro_en Dev loss: 0.3417 r:0.8195
et_en Dev loss: 0.4698 r:0.6700
si_en Dev loss: 0.6475 r:0.5622
ne_en Dev loss: 0.5221 r:0.7228
ru_en Dev loss: 0.4784 r:0.7192
Current avg r:0.5927 Best avg r: 0.6270
03:07:22,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:08:49,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:10:31,398 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2202
en_de Dev loss: 0.8919 r:0.1950
en_zh Dev loss: 0.7915 r:0.4600
ro_en Dev loss: 0.3384 r:0.8175
et_en Dev loss: 0.4819 r:0.6730
si_en Dev loss: 0.6571 r:0.5680
ne_en Dev loss: 0.4986 r:0.7301
ru_en Dev loss: 0.4323 r:0.7377
Current avg r:0.5973 Best avg r: 0.6270
03:14:54,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:16:22,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:18:04,226 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2262
en_de Dev loss: 0.8907 r:0.1901
en_zh Dev loss: 0.7555 r:0.4767
ro_en Dev loss: 0.3340 r:0.8141
et_en Dev loss: 0.4661 r:0.6789
si_en Dev loss: 0.6160 r:0.5714
ne_en Dev loss: 0.4379 r:0.7314
ru_en Dev loss: 0.4253 r:0.7355
Current avg r:0.5997 Best avg r: 0.6270
03:22:27,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:23:54,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:36,910 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2092
en_de Dev loss: 0.8688 r:0.1980
en_zh Dev loss: 0.7467 r:0.4612
ro_en Dev loss: 0.3192 r:0.8173
et_en Dev loss: 0.4574 r:0.6698
si_en Dev loss: 0.6281 r:0.5646
ne_en Dev loss: 0.4260 r:0.7328
ru_en Dev loss: 0.4360 r:0.7175
Current avg r:0.5945 Best avg r: 0.6270
03:30:00,206 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:31:27,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:33:09,721 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2155
en_de Dev loss: 0.8790 r:0.1867
en_zh Dev loss: 0.7308 r:0.4683
ro_en Dev loss: 0.3269 r:0.8187
et_en Dev loss: 0.4265 r:0.6757
si_en Dev loss: 0.6423 r:0.5644
ne_en Dev loss: 0.4942 r:0.7309
ru_en Dev loss: 0.4327 r:0.7278
Current avg r:0.5961 Best avg r: 0.6270
03:37:32,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:39:00,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:40:42,502 root INFO Epoch 6 Global steps: 61800 Train loss: 0.1970
en_de Dev loss: 0.8764 r:0.1870
en_zh Dev loss: 0.7610 r:0.4451
ro_en Dev loss: 0.3252 r:0.8181
et_en Dev loss: 0.4589 r:0.6670
si_en Dev loss: 0.6337 r:0.5638
ne_en Dev loss: 0.4536 r:0.7344
ru_en Dev loss: 0.4158 r:0.7321
Current avg r:0.5925 Best avg r: 0.6270
03:45:05,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:46:33,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:48:15,216 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2102
en_de Dev loss: 0.8970 r:0.1905
en_zh Dev loss: 0.7730 r:0.4551
ro_en Dev loss: 0.3351 r:0.8169
et_en Dev loss: 0.4680 r:0.6632
si_en Dev loss: 0.6343 r:0.5652
ne_en Dev loss: 0.4374 r:0.7357
ru_en Dev loss: 0.4439 r:0.7228
Current avg r:0.5928 Best avg r: 0.6270
03:52:38,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:54:05,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:55:48,112 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2130
en_de Dev loss: 0.8687 r:0.2071
en_zh Dev loss: 0.7319 r:0.4627
ro_en Dev loss: 0.3177 r:0.8158
et_en Dev loss: 0.4628 r:0.6722
si_en Dev loss: 0.6320 r:0.5638
ne_en Dev loss: 0.5256 r:0.7289
ru_en Dev loss: 0.4245 r:0.7360
Current avg r:0.5981 Best avg r: 0.6270
04:00:12,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:01:39,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:03:21,630 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1906
en_de Dev loss: 0.8939 r:0.2093
en_zh Dev loss: 0.7948 r:0.4581
ro_en Dev loss: 0.3604 r:0.8184
et_en Dev loss: 0.4833 r:0.6779
si_en Dev loss: 0.6390 r:0.5736
ne_en Dev loss: 0.4560 r:0.7379
ru_en Dev loss: 0.4268 r:0.7495
Current avg r:0.6035 Best avg r: 0.6270
04:07:44,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:09:12,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:10:54,752 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1899
en_de Dev loss: 0.8766 r:0.1902
en_zh Dev loss: 0.7370 r:0.4596
ro_en Dev loss: 0.3302 r:0.8152
et_en Dev loss: 0.4509 r:0.6573
si_en Dev loss: 0.6450 r:0.5611
ne_en Dev loss: 0.4783 r:0.7331
ru_en Dev loss: 0.4546 r:0.7226
Current avg r:0.5913 Best avg r: 0.6270
04:15:18,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:16:45,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:18:28,10 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1792
en_de Dev loss: 0.8821 r:0.1989
en_zh Dev loss: 0.7976 r:0.4457
ro_en Dev loss: 0.3561 r:0.8167
et_en Dev loss: 0.4802 r:0.6668
si_en Dev loss: 0.6734 r:0.5629
ne_en Dev loss: 0.5157 r:0.7318
ru_en Dev loss: 0.4741 r:0.7199
Current avg r:0.5918 Best avg r: 0.6270
04:22:51,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:24:18,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:26:01,79 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1915
en_de Dev loss: 0.8757 r:0.2007
en_zh Dev loss: 0.7634 r:0.4560
ro_en Dev loss: 0.3277 r:0.8196
et_en Dev loss: 0.4817 r:0.6736
si_en Dev loss: 0.6328 r:0.5721
ne_en Dev loss: 0.5237 r:0.7342
ru_en Dev loss: 0.4239 r:0.7394
Current avg r:0.5994 Best avg r: 0.6270
04:30:24,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:31:51,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:33:33,840 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1907
en_de Dev loss: 0.9101 r:0.1890
en_zh Dev loss: 0.7665 r:0.4751
ro_en Dev loss: 0.3578 r:0.8132
et_en Dev loss: 0.4625 r:0.6702
si_en Dev loss: 0.6647 r:0.5664
ne_en Dev loss: 0.5375 r:0.7224
ru_en Dev loss: 0.4479 r:0.7329
Current avg r:0.5956 Best avg r: 0.6270
04:37:57,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:39:24,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:41:06,475 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1917
en_de Dev loss: 0.9051 r:0.1942
en_zh Dev loss: 0.7683 r:0.4784
ro_en Dev loss: 0.3397 r:0.8162
et_en Dev loss: 0.4785 r:0.6756
si_en Dev loss: 0.6353 r:0.5791
ne_en Dev loss: 0.4971 r:0.7207
ru_en Dev loss: 0.3954 r:0.7565
Current avg r:0.6030 Best avg r: 0.6270
04:45:29,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:45:58,676 root INFO 
id:en_zh cur r: 0.4892 best r: 0.4892
04:46:56,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:38,988 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1904
en_de Dev loss: 0.8947 r:0.1912
en_zh Dev loss: 0.7409 r:0.4854
ro_en Dev loss: 0.3287 r:0.8134
et_en Dev loss: 0.4679 r:0.6679
si_en Dev loss: 0.6607 r:0.5680
ne_en Dev loss: 0.5007 r:0.7193
ru_en Dev loss: 0.3925 r:0.7524
Current avg r:0.5997 Best avg r: 0.6270
04:53:02,242 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:54:29,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:56:11,717 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1892
en_de Dev loss: 0.8910 r:0.1776
en_zh Dev loss: 0.7435 r:0.4726
ro_en Dev loss: 0.3279 r:0.8137
et_en Dev loss: 0.4509 r:0.6735
si_en Dev loss: 0.6484 r:0.5705
ne_en Dev loss: 0.4999 r:0.7217
ru_en Dev loss: 0.4038 r:0.7458
Current avg r:0.5965 Best avg r: 0.6270
05:00:34,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:02:02,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:44,312 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2000
en_de Dev loss: 0.9025 r:0.1726
en_zh Dev loss: 0.7584 r:0.4590
ro_en Dev loss: 0.3453 r:0.8105
et_en Dev loss: 0.4511 r:0.6706
si_en Dev loss: 0.6870 r:0.5654
ne_en Dev loss: 0.5574 r:0.7181
ru_en Dev loss: 0.4197 r:0.7375
Current avg r:0.5905 Best avg r: 0.6270
05:08:07,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:09:34,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:17,39 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1964
en_de Dev loss: 0.9129 r:0.1736
en_zh Dev loss: 0.7758 r:0.4648
ro_en Dev loss: 0.3396 r:0.8158
et_en Dev loss: 0.5107 r:0.6834
si_en Dev loss: 0.6217 r:0.5808
ne_en Dev loss: 0.4492 r:0.7214
ru_en Dev loss: 0.4194 r:0.7371
Current avg r:0.5967 Best avg r: 0.6270
05:15:40,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:07,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:49,763 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1840
en_de Dev loss: 0.9030 r:0.1876
en_zh Dev loss: 0.7407 r:0.4778
ro_en Dev loss: 0.3401 r:0.8127
et_en Dev loss: 0.4659 r:0.6643
si_en Dev loss: 0.6994 r:0.5657
ne_en Dev loss: 0.5415 r:0.7218
ru_en Dev loss: 0.4334 r:0.7348
Current avg r:0.5950 Best avg r: 0.6270
05:23:12,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:24:40,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:22,439 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1926
en_de Dev loss: 0.9217 r:0.1905
en_zh Dev loss: 0.8119 r:0.4655
ro_en Dev loss: 0.3867 r:0.8092
et_en Dev loss: 0.4954 r:0.6602
si_en Dev loss: 0.7065 r:0.5665
ne_en Dev loss: 0.5068 r:0.7274
ru_en Dev loss: 0.5119 r:0.7090
Current avg r:0.5898 Best avg r: 0.6270
05:30:45,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:32:12,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:33:54,899 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1782
en_de Dev loss: 0.9015 r:0.1733
en_zh Dev loss: 0.7802 r:0.4624
ro_en Dev loss: 0.3372 r:0.8165
et_en Dev loss: 0.4920 r:0.6548
si_en Dev loss: 0.6996 r:0.5537
ne_en Dev loss: 0.5262 r:0.7235
ru_en Dev loss: 0.4653 r:0.7151
Current avg r:0.5856 Best avg r: 0.6270
05:38:18,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:39:45,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:41:27,670 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1817
en_de Dev loss: 0.9184 r:0.1841
en_zh Dev loss: 0.8093 r:0.4656
ro_en Dev loss: 0.3713 r:0.8131
et_en Dev loss: 0.4735 r:0.6659
si_en Dev loss: 0.6694 r:0.5677
ne_en Dev loss: 0.4898 r:0.7253
ru_en Dev loss: 0.4983 r:0.7160
Current avg r:0.5911 Best avg r: 0.6270
05:45:50,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:47:17,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:48:59,876 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1804
en_de Dev loss: 0.8981 r:0.1921
en_zh Dev loss: 0.7691 r:0.4789
ro_en Dev loss: 0.3533 r:0.8121
et_en Dev loss: 0.4874 r:0.6624
si_en Dev loss: 0.6687 r:0.5643
ne_en Dev loss: 0.4766 r:0.7270
ru_en Dev loss: 0.4332 r:0.7345
Current avg r:0.5959 Best avg r: 0.6270
05:53:24,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:51,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:56:33,243 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1637
en_de Dev loss: 0.8983 r:0.1752
en_zh Dev loss: 0.7639 r:0.4720
ro_en Dev loss: 0.3426 r:0.8151
et_en Dev loss: 0.4682 r:0.6730
si_en Dev loss: 0.6688 r:0.5738
ne_en Dev loss: 0.5123 r:0.7239
ru_en Dev loss: 0.4215 r:0.7412
Current avg r:0.5963 Best avg r: 0.6270
06:00:56,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:02:23,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:05,995 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1689
en_de Dev loss: 0.9115 r:0.1757
en_zh Dev loss: 0.7905 r:0.4648
ro_en Dev loss: 0.3685 r:0.8117
et_en Dev loss: 0.4824 r:0.6631
si_en Dev loss: 0.6949 r:0.5655
ne_en Dev loss: 0.5396 r:0.7200
ru_en Dev loss: 0.4591 r:0.7285
Current avg r:0.5899 Best avg r: 0.6270
06:08:29,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:56,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:38,759 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1712
en_de Dev loss: 0.8912 r:0.1838
en_zh Dev loss: 0.7586 r:0.4547
ro_en Dev loss: 0.3394 r:0.8099
et_en Dev loss: 0.4766 r:0.6603
si_en Dev loss: 0.6694 r:0.5557
ne_en Dev loss: 0.5282 r:0.7174
ru_en Dev loss: 0.4352 r:0.7223
Current avg r:0.5863 Best avg r: 0.6270
06:16:02,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:29,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:19:11,634 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1786
en_de Dev loss: 0.9036 r:0.1982
en_zh Dev loss: 0.7960 r:0.4582
ro_en Dev loss: 0.3329 r:0.8173
et_en Dev loss: 0.4649 r:0.6629
si_en Dev loss: 0.7075 r:0.5596
ne_en Dev loss: 0.5467 r:0.7143
ru_en Dev loss: 0.4485 r:0.7392
Current avg r:0.5928 Best avg r: 0.6270
06:23:34,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:25:02,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:44,663 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1573
en_de Dev loss: 0.9046 r:0.1998
en_zh Dev loss: 0.7788 r:0.4624
ro_en Dev loss: 0.3418 r:0.8145
et_en Dev loss: 0.4762 r:0.6579
si_en Dev loss: 0.7082 r:0.5583
ne_en Dev loss: 0.5466 r:0.7152
ru_en Dev loss: 0.4641 r:0.7261
Current avg r:0.5906 Best avg r: 0.6270
06:31:07,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:32:35,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:34:17,381 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1677
en_de Dev loss: 0.9044 r:0.1881
en_zh Dev loss: 0.7783 r:0.4540
ro_en Dev loss: 0.3294 r:0.8175
et_en Dev loss: 0.4759 r:0.6583
si_en Dev loss: 0.6800 r:0.5572
ne_en Dev loss: 0.5229 r:0.7151
ru_en Dev loss: 0.4338 r:0.7339
Current avg r:0.5892 Best avg r: 0.6270
06:38:40,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:40:07,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:41:50,157 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1624
en_de Dev loss: 0.8783 r:0.2037
en_zh Dev loss: 0.7370 r:0.4741
ro_en Dev loss: 0.3304 r:0.8154
et_en Dev loss: 0.4764 r:0.6551
si_en Dev loss: 0.6719 r:0.5614
ne_en Dev loss: 0.5192 r:0.7202
ru_en Dev loss: 0.4239 r:0.7355
Current avg r:0.5951 Best avg r: 0.6270
06:46:13,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:40,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:49:22,695 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1619
en_de Dev loss: 0.9351 r:0.1891
en_zh Dev loss: 0.8630 r:0.4555
ro_en Dev loss: 0.4114 r:0.8106
et_en Dev loss: 0.5153 r:0.6403
si_en Dev loss: 0.8284 r:0.5459
ne_en Dev loss: 0.6911 r:0.7132
ru_en Dev loss: 0.4955 r:0.7299
Current avg r:0.5835 Best avg r: 0.6270
06:53:45,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:55:13,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:55,878 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1728
en_de Dev loss: 0.9038 r:0.1863
en_zh Dev loss: 0.7960 r:0.4587
ro_en Dev loss: 0.3443 r:0.8157
et_en Dev loss: 0.4897 r:0.6595
si_en Dev loss: 0.7014 r:0.5620
ne_en Dev loss: 0.5638 r:0.7037
ru_en Dev loss: 0.4540 r:0.7312
Current avg r:0.5881 Best avg r: 0.6270
07:01:19,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:46,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:04:29,19 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1635
en_de Dev loss: 0.8892 r:0.2074
en_zh Dev loss: 0.7618 r:0.4783
ro_en Dev loss: 0.3346 r:0.8139
et_en Dev loss: 0.4707 r:0.6759
si_en Dev loss: 0.6558 r:0.5702
ne_en Dev loss: 0.4772 r:0.7214
ru_en Dev loss: 0.3808 r:0.7643
Current avg r:0.6045 Best avg r: 0.6270
07:08:52,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:10:19,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:12:01,932 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1627
en_de Dev loss: 0.8942 r:0.2033
en_zh Dev loss: 0.7812 r:0.4640
ro_en Dev loss: 0.3616 r:0.8136
et_en Dev loss: 0.4987 r:0.6705
si_en Dev loss: 0.6557 r:0.5643
ne_en Dev loss: 0.4757 r:0.7208
ru_en Dev loss: 0.4349 r:0.7394
Current avg r:0.5965 Best avg r: 0.6270
07:16:25,206 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:52,640 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:19:34,995 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1635
en_de Dev loss: 0.8995 r:0.2152
en_zh Dev loss: 0.8000 r:0.4599
ro_en Dev loss: 0.3653 r:0.8126
et_en Dev loss: 0.4861 r:0.6607
si_en Dev loss: 0.7277 r:0.5545
ne_en Dev loss: 0.5385 r:0.7179
ru_en Dev loss: 0.4300 r:0.7475
Current avg r:0.5955 Best avg r: 0.6270
07:23:58,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:25,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:27:07,986 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1667
en_de Dev loss: 0.8928 r:0.2271
en_zh Dev loss: 0.7584 r:0.4795
ro_en Dev loss: 0.3464 r:0.8121
et_en Dev loss: 0.4832 r:0.6614
si_en Dev loss: 0.7026 r:0.5524
ne_en Dev loss: 0.5119 r:0.7161
ru_en Dev loss: 0.4419 r:0.7380
Current avg r:0.5981 Best avg r: 0.6270
07:31:31,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:58,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:34:40,796 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1514
en_de Dev loss: 0.9256 r:0.1830
en_zh Dev loss: 0.7871 r:0.4672
ro_en Dev loss: 0.3543 r:0.8113
et_en Dev loss: 0.4665 r:0.6624
si_en Dev loss: 0.7407 r:0.5554
ne_en Dev loss: 0.5346 r:0.7116
ru_en Dev loss: 0.4682 r:0.7253
Current avg r:0.5880 Best avg r: 0.6270
07:39:04,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:31,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:13,813 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1598
en_de Dev loss: 0.9237 r:0.1999
en_zh Dev loss: 0.7999 r:0.4717
ro_en Dev loss: 0.3590 r:0.8122
et_en Dev loss: 0.4900 r:0.6760
si_en Dev loss: 0.7074 r:0.5658
ne_en Dev loss: 0.5345 r:0.7158
ru_en Dev loss: 0.4584 r:0.7317
Current avg r:0.5962 Best avg r: 0.6270
07:46:38,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:05,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:49:48,351 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1593
en_de Dev loss: 0.9203 r:0.1911
en_zh Dev loss: 0.7901 r:0.4627
ro_en Dev loss: 0.3579 r:0.8142
et_en Dev loss: 0.4773 r:0.6737
si_en Dev loss: 0.7040 r:0.5631
ne_en Dev loss: 0.5020 r:0.7180
ru_en Dev loss: 0.4393 r:0.7402
Current avg r:0.5947 Best avg r: 0.6270
07:54:11,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:55:39,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:57:21,699 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1364
en_de Dev loss: 0.9058 r:0.2016
en_zh Dev loss: 0.7441 r:0.4753
ro_en Dev loss: 0.3333 r:0.8127
et_en Dev loss: 0.4651 r:0.6733
si_en Dev loss: 0.6699 r:0.5648
ne_en Dev loss: 0.5137 r:0.7135
ru_en Dev loss: 0.4088 r:0.7482
Current avg r:0.5985 Best avg r: 0.6270
08:01:45,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:03:12,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:04:54,885 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1412
en_de Dev loss: 0.8960 r:0.2037
en_zh Dev loss: 0.7537 r:0.4682
ro_en Dev loss: 0.3302 r:0.8152
et_en Dev loss: 0.4756 r:0.6728
si_en Dev loss: 0.6802 r:0.5638
ne_en Dev loss: 0.5044 r:0.7235
ru_en Dev loss: 0.4001 r:0.7465
Current avg r:0.5991 Best avg r: 0.6270
08:09:18,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:10:45,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:12:28,33 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1496
en_de Dev loss: 0.9256 r:0.1958
en_zh Dev loss: 0.7992 r:0.4626
ro_en Dev loss: 0.3522 r:0.8163
et_en Dev loss: 0.5064 r:0.6714
si_en Dev loss: 0.6899 r:0.5649
ne_en Dev loss: 0.5187 r:0.7126
ru_en Dev loss: 0.4394 r:0.7407
Current avg r:0.5949 Best avg r: 0.6270
08:16:51,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:18:18,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:20:00,760 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1444
en_de Dev loss: 0.9115 r:0.1953
en_zh Dev loss: 0.7545 r:0.4667
ro_en Dev loss: 0.3336 r:0.8163
et_en Dev loss: 0.4751 r:0.6645
si_en Dev loss: 0.6938 r:0.5532
ne_en Dev loss: 0.5343 r:0.7049
ru_en Dev loss: 0.4450 r:0.7345
Current avg r:0.5908 Best avg r: 0.6270
08:24:24,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:25:51,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:27:34,118 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1450
en_de Dev loss: 0.9230 r:0.1988
en_zh Dev loss: 0.7852 r:0.4720
ro_en Dev loss: 0.3601 r:0.8144
et_en Dev loss: 0.5349 r:0.6602
si_en Dev loss: 0.7105 r:0.5508
ne_en Dev loss: 0.5614 r:0.7078
ru_en Dev loss: 0.4390 r:0.7357
Current avg r:0.5914 Best avg r: 0.6270
08:31:57,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:33:25,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:35:07,887 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1468
en_de Dev loss: 0.8909 r:0.2112
en_zh Dev loss: 0.7262 r:0.4760
ro_en Dev loss: 0.3234 r:0.8149
et_en Dev loss: 0.4661 r:0.6623
si_en Dev loss: 0.7192 r:0.5497
ne_en Dev loss: 0.5465 r:0.7143
ru_en Dev loss: 0.4119 r:0.7386
Current avg r:0.5953 Best avg r: 0.6270
08:39:31,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:40:59,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:42:41,609 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1481
en_de Dev loss: 0.9232 r:0.1974
en_zh Dev loss: 0.8209 r:0.4526
ro_en Dev loss: 0.3630 r:0.8123
et_en Dev loss: 0.4945 r:0.6569
si_en Dev loss: 0.6964 r:0.5517
ne_en Dev loss: 0.5134 r:0.7092
ru_en Dev loss: 0.4530 r:0.7329
Current avg r:0.5876 Best avg r: 0.6270
08:47:04,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:32,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:50:15,20 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1440
en_de Dev loss: 0.9109 r:0.2038
en_zh Dev loss: 0.7921 r:0.4731
ro_en Dev loss: 0.3646 r:0.8171
et_en Dev loss: 0.4789 r:0.6702
si_en Dev loss: 0.7425 r:0.5629
ne_en Dev loss: 0.5473 r:0.7096
ru_en Dev loss: 0.4570 r:0.7456
Current avg r:0.5975 Best avg r: 0.6270
08:54:38,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:56:05,562 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:57:47,694 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1433
en_de Dev loss: 0.8898 r:0.2101
en_zh Dev loss: 0.7636 r:0.4655
ro_en Dev loss: 0.3286 r:0.8172
et_en Dev loss: 0.4664 r:0.6685
si_en Dev loss: 0.7056 r:0.5587
ne_en Dev loss: 0.5407 r:0.7161
ru_en Dev loss: 0.4247 r:0.7444
Current avg r:0.5972 Best avg r: 0.6270
09:02:11,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:03:38,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:05:20,469 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1370
en_de Dev loss: 0.9215 r:0.1977
en_zh Dev loss: 0.7680 r:0.4777
ro_en Dev loss: 0.3423 r:0.8164
et_en Dev loss: 0.4887 r:0.6610
si_en Dev loss: 0.7384 r:0.5467
ne_en Dev loss: 0.5997 r:0.6995
ru_en Dev loss: 0.4239 r:0.7461
Current avg r:0.5922 Best avg r: 0.6270
09:09:43,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:11:11,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:12:53,22 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1473
en_de Dev loss: 0.8958 r:0.1890
en_zh Dev loss: 0.7097 r:0.4830
ro_en Dev loss: 0.3085 r:0.8195
et_en Dev loss: 0.4454 r:0.6759
si_en Dev loss: 0.6818 r:0.5613
ne_en Dev loss: 0.5109 r:0.7036
ru_en Dev loss: 0.3901 r:0.7547
Current avg r:0.5982 Best avg r: 0.6270
09:17:16,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:43,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:20:25,982 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1456
en_de Dev loss: 0.9090 r:0.1972
en_zh Dev loss: 0.7816 r:0.4818
ro_en Dev loss: 0.3566 r:0.8142
et_en Dev loss: 0.4883 r:0.6570
si_en Dev loss: 0.7829 r:0.5537
ne_en Dev loss: 0.6820 r:0.7078
ru_en Dev loss: 0.4336 r:0.7435
Current avg r:0.5936 Best avg r: 0.6270
09:24:49,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:26:16,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:27:58,818 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1402
en_de Dev loss: 0.9122 r:0.1987
en_zh Dev loss: 0.8162 r:0.4689
ro_en Dev loss: 0.3666 r:0.8157
et_en Dev loss: 0.5151 r:0.6498
si_en Dev loss: 0.7819 r:0.5545
ne_en Dev loss: 0.6230 r:0.7013
ru_en Dev loss: 0.4735 r:0.7300
Current avg r:0.5884 Best avg r: 0.6270
09:32:22,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:33:49,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:35:31,637 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1418
en_de Dev loss: 0.9107 r:0.1945
en_zh Dev loss: 0.7877 r:0.4731
ro_en Dev loss: 0.3429 r:0.8183
et_en Dev loss: 0.4654 r:0.6658
si_en Dev loss: 0.7472 r:0.5677
ne_en Dev loss: 0.5793 r:0.7076
ru_en Dev loss: 0.4410 r:0.7421
Current avg r:0.5956 Best avg r: 0.6270
09:39:55,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:23,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:05,423 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1346
en_de Dev loss: 0.8811 r:0.2000
en_zh Dev loss: 0.7406 r:0.4728
ro_en Dev loss: 0.3259 r:0.8169
et_en Dev loss: 0.4566 r:0.6654
si_en Dev loss: 0.7192 r:0.5585
ne_en Dev loss: 0.5893 r:0.7116
ru_en Dev loss: 0.4234 r:0.7359
Current avg r:0.5944 Best avg r: 0.6270
09:47:28,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:57,660 root INFO 
id:en_zh cur r: 0.4901 best r: 0.4901
09:48:56,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:50:38,434 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1282
en_de Dev loss: 0.9092 r:0.1986
en_zh Dev loss: 0.7675 r:0.4852
ro_en Dev loss: 0.3485 r:0.8125
et_en Dev loss: 0.4933 r:0.6689
si_en Dev loss: 0.7335 r:0.5645
ne_en Dev loss: 0.5931 r:0.7049
ru_en Dev loss: 0.4358 r:0.7457
Current avg r:0.5972 Best avg r: 0.6270
09:55:01,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:29,370 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:11,491 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1298
en_de Dev loss: 0.9037 r:0.1962
en_zh Dev loss: 0.7369 r:0.4808
ro_en Dev loss: 0.3248 r:0.8168
et_en Dev loss: 0.4684 r:0.6801
si_en Dev loss: 0.6507 r:0.5691
ne_en Dev loss: 0.4884 r:0.7084
ru_en Dev loss: 0.3978 r:0.7573
Current avg r:0.6012 Best avg r: 0.6270
10:02:34,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:02,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:44,514 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1308
en_de Dev loss: 0.9229 r:0.2000
en_zh Dev loss: 0.8062 r:0.4716
ro_en Dev loss: 0.3462 r:0.8147
et_en Dev loss: 0.4791 r:0.6680
si_en Dev loss: 0.7332 r:0.5616
ne_en Dev loss: 0.5774 r:0.7040
ru_en Dev loss: 0.4365 r:0.7470
Current avg r:0.5953 Best avg r: 0.6270
10:10:07,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:35,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:13:17,567 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1265
en_de Dev loss: 0.9125 r:0.1911
en_zh Dev loss: 0.7868 r:0.4694
ro_en Dev loss: 0.3341 r:0.8174
et_en Dev loss: 0.4838 r:0.6615
si_en Dev loss: 0.6899 r:0.5555
ne_en Dev loss: 0.5515 r:0.7107
ru_en Dev loss: 0.4355 r:0.7364
Current avg r:0.5917 Best avg r: 0.6270
10:17:40,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:08,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:50,714 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1259
en_de Dev loss: 0.9033 r:0.1879
en_zh Dev loss: 0.7399 r:0.4717
ro_en Dev loss: 0.3208 r:0.8179
et_en Dev loss: 0.4541 r:0.6720
si_en Dev loss: 0.7054 r:0.5542
ne_en Dev loss: 0.5431 r:0.7087
ru_en Dev loss: 0.4070 r:0.7467
Current avg r:0.5942 Best avg r: 0.6270
10:25:13,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:26:41,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:28:22,923 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1252
en_de Dev loss: 0.9512 r:0.1746
en_zh Dev loss: 0.7859 r:0.4659
ro_en Dev loss: 0.3431 r:0.8175
et_en Dev loss: 0.4696 r:0.6663
si_en Dev loss: 0.7228 r:0.5597
ne_en Dev loss: 0.5258 r:0.7133
ru_en Dev loss: 0.4445 r:0.7449
Current avg r:0.5917 Best avg r: 0.6270
10:32:46,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:34:13,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:35:54,842 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1283
en_de Dev loss: 0.9643 r:0.1559
en_zh Dev loss: 0.7842 r:0.4658
ro_en Dev loss: 0.3283 r:0.8207
et_en Dev loss: 0.5007 r:0.6678
si_en Dev loss: 0.6857 r:0.5642
ne_en Dev loss: 0.5022 r:0.7190
ru_en Dev loss: 0.4216 r:0.7467
Current avg r:0.5915 Best avg r: 0.6270
