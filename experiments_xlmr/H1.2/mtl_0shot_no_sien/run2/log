14:36:34,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:00,320 root INFO 
id:en_zh cur r: 0.2339 best r: 0.2339
14:37:13,386 root INFO 
id:ro_en cur r: 0.5727 best r: 0.5727
14:37:26,461 root INFO 
id:et_en cur r: 0.2629 best r: 0.2629
14:37:39,540 root INFO 
id:ne_en cur r: 0.5545 best r: 0.5545
14:37:52,530 root INFO 
id:ru_en cur r: 0.4869 best r: 0.4869
14:37:52,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:23,644 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
14:39:23,653 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:39:23,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:39:23,671 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
14:39:23,678 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
14:39:23,692 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:39:23,697 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:39:36,756 root INFO Epoch 0 Global steps: 600 Train loss: 0.8734
en_de Dev loss: 0.9142 r:0.0915
en_zh Dev loss: 0.7751 r:0.2530
ro_en Dev loss: 0.7754 r:0.5736
et_en Dev loss: 0.5850 r:0.4284
si_en Dev loss: 0.7517 r:0.4053
ne_en Dev loss: 0.6157 r:0.5678
ru_en Dev loss: 0.6788 r:0.5253
Current avg r:0.4064 Best avg r: 0.4064
14:43:30,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:43:56,94 root INFO 
id:en_zh cur r: 0.2694 best r: 0.2694
14:44:22,212 root INFO 
id:et_en cur r: 0.4460 best r: 0.4460
14:44:35,306 root INFO 
id:ne_en cur r: 0.5917 best r: 0.5917
14:44:48,384 root INFO 
id:ru_en cur r: 0.5704 best r: 0.5704
14:44:48,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:20,146 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
14:46:20,153 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:46:20,158 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:46:20,163 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
14:46:20,168 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
14:46:20,174 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:46:20,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:46:33,283 root INFO Epoch 0 Global steps: 1200 Train loss: 0.8392
en_de Dev loss: 0.8968 r:0.0981
en_zh Dev loss: 0.7505 r:0.2961
ro_en Dev loss: 0.7189 r:0.5769
et_en Dev loss: 0.5538 r:0.4814
si_en Dev loss: 0.7330 r:0.4364
ne_en Dev loss: 0.6328 r:0.5608
ru_en Dev loss: 0.6408 r:0.5698
Current avg r:0.4314 Best avg r: 0.4314
14:50:27,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:50:40,895 root INFO 
id:en_de cur r: 0.0494 best r: 0.0494
14:50:53,923 root INFO 
id:en_zh cur r: 0.3242 best r: 0.3242
14:51:06,986 root INFO 
id:ro_en cur r: 0.6225 best r: 0.6225
14:51:20,63 root INFO 
id:et_en cur r: 0.5464 best r: 0.5464
14:51:33,144 root INFO 
id:ne_en cur r: 0.6348 best r: 0.6348
14:51:46,137 root INFO 
id:ru_en cur r: 0.6212 best r: 0.6212
14:51:46,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:17,441 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
14:53:17,450 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:53:17,455 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:53:17,463 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
14:53:17,470 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
14:53:17,478 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:53:17,484 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:53:30,567 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7661
en_de Dev loss: 0.9005 r:0.1336
en_zh Dev loss: 0.7268 r:0.3376
ro_en Dev loss: 0.6440 r:0.6411
et_en Dev loss: 0.4914 r:0.5758
si_en Dev loss: 0.6932 r:0.4822
ne_en Dev loss: 0.4921 r:0.6657
ru_en Dev loss: 0.5761 r:0.6270
Current avg r:0.4947 Best avg r: 0.4947
14:57:24,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:38,27 root INFO 
id:en_de cur r: 0.1034 best r: 0.1034
14:58:04,115 root INFO 
id:ro_en cur r: 0.6572 best r: 0.6572
14:58:17,183 root INFO 
id:et_en cur r: 0.6133 best r: 0.6133
14:58:43,242 root INFO 
id:ru_en cur r: 0.6810 best r: 0.6810
14:58:43,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:14,546 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
15:00:14,555 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:00:14,564 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:00:14,569 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
15:00:14,576 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
15:00:14,583 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:00:14,596 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:00:27,692 root INFO Epoch 0 Global steps: 2400 Train loss: 0.6978
en_de Dev loss: 0.9155 r:0.1705
en_zh Dev loss: 0.7855 r:0.3316
ro_en Dev loss: 0.6247 r:0.6852
et_en Dev loss: 0.4835 r:0.6376
si_en Dev loss: 0.7598 r:0.5092
ne_en Dev loss: 0.5393 r:0.6669
ru_en Dev loss: 0.5968 r:0.6950
Current avg r:0.5280 Best avg r: 0.5280
15:04:21,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:34,915 root INFO 
id:en_de cur r: 0.1240 best r: 0.1240
15:04:47,958 root INFO 
id:en_zh cur r: 0.3568 best r: 0.3568
15:05:01,31 root INFO 
id:ro_en cur r: 0.6917 best r: 0.6917
15:05:14,122 root INFO 
id:et_en cur r: 0.6356 best r: 0.6356
15:05:27,207 root INFO 
id:ne_en cur r: 0.6902 best r: 0.6902
15:05:40,197 root INFO 
id:ru_en cur r: 0.6931 best r: 0.6931
15:05:40,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:11,556 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
15:07:11,562 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:07:11,566 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:07:11,571 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
15:07:11,576 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
15:07:11,580 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:07:11,585 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:07:24,676 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6736
en_de Dev loss: 0.8764 r:0.1951
en_zh Dev loss: 0.7120 r:0.3685
ro_en Dev loss: 0.4657 r:0.6986
et_en Dev loss: 0.4093 r:0.6692
si_en Dev loss: 0.5728 r:0.5491
ne_en Dev loss: 0.3976 r:0.7074
ru_en Dev loss: 0.4436 r:0.7042
Current avg r:0.5560 Best avg r: 0.5560
15:11:19,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:58,154 root INFO 
id:ro_en cur r: 0.7276 best r: 0.7276
15:12:11,235 root INFO 
id:et_en cur r: 0.6773 best r: 0.6773
15:12:24,320 root INFO 
id:ne_en cur r: 0.6937 best r: 0.6937
15:12:37,312 root INFO 
id:ru_en cur r: 0.7199 best r: 0.7199
15:12:37,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:08,705 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
15:14:08,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:14:08,720 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:14:08,726 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
15:14:08,732 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
15:14:08,739 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:14:08,746 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:14:21,835 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6201
en_de Dev loss: 0.8780 r:0.1955
en_zh Dev loss: 0.7219 r:0.3727
ro_en Dev loss: 0.4337 r:0.7385
et_en Dev loss: 0.3741 r:0.7003
si_en Dev loss: 0.6004 r:0.5799
ne_en Dev loss: 0.5178 r:0.7025
ru_en Dev loss: 0.4332 r:0.7317
Current avg r:0.5744 Best avg r: 0.5744
15:18:16,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:29,513 root INFO 
id:en_de cur r: 0.1515 best r: 0.1515
15:18:42,545 root INFO 
id:en_zh cur r: 0.3718 best r: 0.3718
15:18:55,615 root INFO 
id:ro_en cur r: 0.7528 best r: 0.7528
15:19:34,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:06,104 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
15:21:06,111 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:21:06,117 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:21:06,124 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
15:21:06,129 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
15:21:06,137 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:21:06,142 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:21:19,230 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5917
en_de Dev loss: 0.8767 r:0.1946
en_zh Dev loss: 0.7085 r:0.3875
ro_en Dev loss: 0.4007 r:0.7617
et_en Dev loss: 0.3781 r:0.6900
si_en Dev loss: 0.5967 r:0.5676
ne_en Dev loss: 0.4853 r:0.7007
ru_en Dev loss: 0.4399 r:0.7318
Current avg r:0.5763 Best avg r: 0.5763
15:25:13,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:26,752 root INFO 
id:en_de cur r: 0.1578 best r: 0.1578
15:25:39,780 root INFO 
id:en_zh cur r: 0.4015 best r: 0.4015
15:25:52,842 root INFO 
id:ro_en cur r: 0.7642 best r: 0.7642
15:26:05,916 root INFO 
id:et_en cur r: 0.6951 best r: 0.6951
15:26:19,20 root INFO 
id:ne_en cur r: 0.7109 best r: 0.7109
15:26:32,15 root INFO 
id:ru_en cur r: 0.7368 best r: 0.7368
15:26:32,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:03,469 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
15:28:03,532 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:28:03,554 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:28:03,588 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
15:28:03,598 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
15:28:03,611 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:28:03,625 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:28:16,731 root INFO Epoch 0 Global steps: 4800 Train loss: 0.5947
en_de Dev loss: 0.8838 r:0.2066
en_zh Dev loss: 0.7173 r:0.4052
ro_en Dev loss: 0.4322 r:0.7697
et_en Dev loss: 0.3691 r:0.7123
si_en Dev loss: 0.6201 r:0.5719
ne_en Dev loss: 0.4791 r:0.7170
ru_en Dev loss: 0.4131 r:0.7521
Current avg r:0.5907 Best avg r: 0.5907
15:32:11,206 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:24,256 root INFO 
id:en_de cur r: 0.1625 best r: 0.1625
15:32:50,342 root INFO 
id:ro_en cur r: 0.7664 best r: 0.7664
15:33:29,490 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:00,837 root INFO Epoch 0 Global steps: 5400 Train loss: 0.6127
en_de Dev loss: 0.8831 r:0.2082
en_zh Dev loss: 0.7354 r:0.4054
ro_en Dev loss: 0.4214 r:0.7726
et_en Dev loss: 0.3653 r:0.7000
si_en Dev loss: 0.6298 r:0.5628
ne_en Dev loss: 0.5776 r:0.7040
ru_en Dev loss: 0.4929 r:0.7100
Current avg r:0.5804 Best avg r: 0.5907
15:38:55,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:08,311 root INFO 
id:en_de cur r: 0.1659 best r: 0.1659
15:39:21,340 root INFO 
id:en_zh cur r: 0.4304 best r: 0.4304
15:39:34,408 root INFO 
id:ro_en cur r: 0.7708 best r: 0.7708
15:39:47,504 root INFO 
id:et_en cur r: 0.7114 best r: 0.7114
15:40:00,597 root INFO 
id:ne_en cur r: 0.7414 best r: 0.7414
15:40:13,575 root INFO 
id:ru_en cur r: 0.7493 best r: 0.7493
15:40:13,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:44,992 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
15:41:44,998 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:41:45,7 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:41:45,15 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
15:41:45,20 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
15:41:45,26 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:41:45,31 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:41:58,121 root INFO Epoch 0 Global steps: 6000 Train loss: 0.6051
en_de Dev loss: 0.8617 r:0.2170
en_zh Dev loss: 0.6726 r:0.4308
ro_en Dev loss: 0.3522 r:0.7738
et_en Dev loss: 0.3421 r:0.7196
si_en Dev loss: 0.5372 r:0.5877
ne_en Dev loss: 0.3616 r:0.7446
ru_en Dev loss: 0.3631 r:0.7583
Current avg r:0.6046 Best avg r: 0.6046
15:45:52,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:05,647 root INFO 
id:en_de cur r: 0.2007 best r: 0.2007
15:46:18,689 root INFO 
id:en_zh cur r: 0.4367 best r: 0.4367
15:46:31,749 root INFO 
id:ro_en cur r: 0.7834 best r: 0.7834
15:47:10,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:42,242 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5525
en_de Dev loss: 0.8896 r:0.2066
en_zh Dev loss: 0.6848 r:0.4388
ro_en Dev loss: 0.4130 r:0.7879
et_en Dev loss: 0.3589 r:0.7161
si_en Dev loss: 0.6209 r:0.5788
ne_en Dev loss: 0.4890 r:0.7346
ru_en Dev loss: 0.4373 r:0.7428
Current avg r:0.6008 Best avg r: 0.6046
15:52:36,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:02,745 root INFO 
id:en_zh cur r: 0.4380 best r: 0.4380
15:53:54,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:26,309 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5445
en_de Dev loss: 0.8899 r:0.2148
en_zh Dev loss: 0.6864 r:0.4394
ro_en Dev loss: 0.3730 r:0.7815
et_en Dev loss: 0.3582 r:0.7084
si_en Dev loss: 0.5943 r:0.5701
ne_en Dev loss: 0.3966 r:0.7343
ru_en Dev loss: 0.4121 r:0.7457
Current avg r:0.5992 Best avg r: 0.6046
15:59:20,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:33,655 root INFO 
id:en_de cur r: 0.2090 best r: 0.2090
15:59:59,745 root INFO 
id:ro_en cur r: 0.7906 best r: 0.7906
16:00:25,919 root INFO 
id:ne_en cur r: 0.7437 best r: 0.7437
16:00:38,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:10,268 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5134
en_de Dev loss: 0.8778 r:0.2115
en_zh Dev loss: 0.6836 r:0.4387
ro_en Dev loss: 0.3575 r:0.7907
et_en Dev loss: 0.3555 r:0.7093
si_en Dev loss: 0.5618 r:0.5832
ne_en Dev loss: 0.3819 r:0.7432
ru_en Dev loss: 0.4120 r:0.7426
Current avg r:0.6028 Best avg r: 0.6046
16:06:04,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:17,733 root INFO 
id:en_de cur r: 0.2243 best r: 0.2243
16:06:30,773 root INFO 
id:en_zh cur r: 0.4398 best r: 0.4398
16:06:43,845 root INFO 
id:ro_en cur r: 0.8118 best r: 0.8118
16:06:56,932 root INFO 
id:et_en cur r: 0.7153 best r: 0.7153
16:07:10,28 root INFO 
id:ne_en cur r: 0.7509 best r: 0.7509
16:07:23,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:54,398 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
16:08:54,407 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:08:54,414 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:08:54,421 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
16:08:54,426 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
16:08:54,433 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:08:54,440 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:09:07,551 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5749
en_de Dev loss: 0.8769 r:0.2218
en_zh Dev loss: 0.6995 r:0.4468
ro_en Dev loss: 0.3510 r:0.8112
et_en Dev loss: 0.3550 r:0.7186
si_en Dev loss: 0.5966 r:0.5901
ne_en Dev loss: 0.4542 r:0.7461
ru_en Dev loss: 0.4480 r:0.7447
Current avg r:0.6113 Best avg r: 0.6113
16:13:01,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:14,967 root INFO 
id:en_de cur r: 0.2300 best r: 0.2300
16:13:28,7 root INFO 
id:en_zh cur r: 0.4523 best r: 0.4523
16:14:07,217 root INFO 
id:ne_en cur r: 0.7565 best r: 0.7565
16:14:20,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:51,587 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
16:15:51,595 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:15:51,602 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:15:51,608 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
16:15:51,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
16:15:51,622 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:15:51,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:16:04,717 root INFO Epoch 0 Global steps: 9000 Train loss: 0.4821
en_de Dev loss: 0.8651 r:0.2276
en_zh Dev loss: 0.6684 r:0.4558
ro_en Dev loss: 0.3168 r:0.8080
et_en Dev loss: 0.3500 r:0.7153
si_en Dev loss: 0.5490 r:0.5907
ne_en Dev loss: 0.3714 r:0.7512
ru_en Dev loss: 0.3878 r:0.7481
Current avg r:0.6138 Best avg r: 0.6138
16:20:00,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:13,465 root INFO 
id:en_de cur r: 0.2303 best r: 0.2303
16:21:05,709 root INFO 
id:ne_en cur r: 0.7580 best r: 0.7580
16:21:18,706 root INFO 
id:ru_en cur r: 0.7612 best r: 0.7612
16:21:18,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:50,69 root INFO Epoch 1 Global steps: 9600 Train loss: 0.5119
en_de Dev loss: 0.8480 r:0.2300
en_zh Dev loss: 0.6638 r:0.4496
ro_en Dev loss: 0.3108 r:0.8063
et_en Dev loss: 0.3543 r:0.7099
si_en Dev loss: 0.5554 r:0.5882
ne_en Dev loss: 0.3824 r:0.7523
ru_en Dev loss: 0.3640 r:0.7590
Current avg r:0.6136 Best avg r: 0.6138
16:26:44,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:57,681 root INFO 
id:en_de cur r: 0.2319 best r: 0.2319
16:27:23,769 root INFO 
id:ro_en cur r: 0.8119 best r: 0.8119
16:28:02,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:34,234 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5049
en_de Dev loss: 0.8710 r:0.2222
en_zh Dev loss: 0.7076 r:0.4423
ro_en Dev loss: 0.3422 r:0.8112
et_en Dev loss: 0.3820 r:0.7076
si_en Dev loss: 0.6061 r:0.5918
ne_en Dev loss: 0.4278 r:0.7524
ru_en Dev loss: 0.4429 r:0.7481
Current avg r:0.6108 Best avg r: 0.6138
16:33:28,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:41,879 root INFO 
id:en_de cur r: 0.2389 best r: 0.2389
16:34:07,982 root INFO 
id:ro_en cur r: 0.8157 best r: 0.8157
16:34:47,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:18,482 root INFO Epoch 1 Global steps: 10800 Train loss: 0.4686
en_de Dev loss: 0.8718 r:0.2292
en_zh Dev loss: 0.7165 r:0.4497
ro_en Dev loss: 0.3241 r:0.8130
et_en Dev loss: 0.3599 r:0.7089
si_en Dev loss: 0.6040 r:0.5895
ne_en Dev loss: 0.4532 r:0.7441
ru_en Dev loss: 0.5030 r:0.7136
Current avg r:0.6069 Best avg r: 0.6138
16:40:12,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:26,51 root INFO 
id:en_de cur r: 0.2456 best r: 0.2456
16:41:18,299 root INFO 
id:ne_en cur r: 0.7641 best r: 0.7641
16:41:31,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:02,661 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
16:43:02,679 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:43:02,687 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:43:02,693 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
16:43:02,699 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
16:43:02,707 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:43:02,713 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:43:15,809 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4766
en_de Dev loss: 0.8510 r:0.2367
en_zh Dev loss: 0.6954 r:0.4512
ro_en Dev loss: 0.3226 r:0.8127
et_en Dev loss: 0.3416 r:0.7205
si_en Dev loss: 0.5735 r:0.5945
ne_en Dev loss: 0.4109 r:0.7571
ru_en Dev loss: 0.4123 r:0.7451
Current avg r:0.6168 Best avg r: 0.6168
16:47:10,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:49,567 root INFO 
id:ro_en cur r: 0.8194 best r: 0.8194
16:48:28,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:00,100 root INFO Epoch 1 Global steps: 12000 Train loss: 0.4924
en_de Dev loss: 0.8614 r:0.2217
en_zh Dev loss: 0.6831 r:0.4555
ro_en Dev loss: 0.3268 r:0.8174
et_en Dev loss: 0.3467 r:0.7200
si_en Dev loss: 0.5683 r:0.5951
ne_en Dev loss: 0.3993 r:0.7547
ru_en Dev loss: 0.4171 r:0.7474
Current avg r:0.6160 Best avg r: 0.6168
16:53:54,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:20,530 root INFO 
id:en_zh cur r: 0.4532 best r: 0.4532
16:54:46,678 root INFO 
id:et_en cur r: 0.7158 best r: 0.7158
16:55:12,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:44,125 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5085
en_de Dev loss: 0.8703 r:0.2015
en_zh Dev loss: 0.6821 r:0.4538
ro_en Dev loss: 0.3225 r:0.8191
et_en Dev loss: 0.3483 r:0.7211
si_en Dev loss: 0.5483 r:0.6041
ne_en Dev loss: 0.3870 r:0.7580
ru_en Dev loss: 0.4228 r:0.7392
Current avg r:0.6138 Best avg r: 0.6168
17:00:38,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:04,164 root INFO 
id:en_zh cur r: 0.4607 best r: 0.4607
17:01:17,201 root INFO 
id:ro_en cur r: 0.8218 best r: 0.8218
17:01:30,258 root INFO 
id:et_en cur r: 0.7197 best r: 0.7197
17:01:43,316 root INFO 
id:ne_en cur r: 0.7673 best r: 0.7673
17:01:56,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:27,456 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
17:03:27,467 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:03:27,474 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:03:27,479 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
17:03:27,485 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
17:03:27,492 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:03:27,498 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:03:40,565 root INFO Epoch 1 Global steps: 13200 Train loss: 0.4653
en_de Dev loss: 0.8506 r:0.2277
en_zh Dev loss: 0.6805 r:0.4589
ro_en Dev loss: 0.3098 r:0.8215
et_en Dev loss: 0.3437 r:0.7254
si_en Dev loss: 0.5326 r:0.6055
ne_en Dev loss: 0.3765 r:0.7648
ru_en Dev loss: 0.3924 r:0.7541
Current avg r:0.6226 Best avg r: 0.6226
17:07:34,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:39,485 root INFO 
id:ne_en cur r: 0.7727 best r: 0.7727
17:08:52,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:10:23,635 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4882
en_de Dev loss: 0.8699 r:0.2185
en_zh Dev loss: 0.7394 r:0.4443
ro_en Dev loss: 0.3545 r:0.8176
et_en Dev loss: 0.3494 r:0.7231
si_en Dev loss: 0.5669 r:0.6003
ne_en Dev loss: 0.4215 r:0.7693
ru_en Dev loss: 0.4360 r:0.7440
Current avg r:0.6167 Best avg r: 0.6226
17:14:17,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:56,824 root INFO 
id:ro_en cur r: 0.8226 best r: 0.8226
17:15:09,884 root INFO 
id:et_en cur r: 0.7230 best r: 0.7230
17:15:35,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:07,166 root INFO Epoch 1 Global steps: 14400 Train loss: 0.4591
en_de Dev loss: 0.8557 r:0.2213
en_zh Dev loss: 0.7216 r:0.4542
ro_en Dev loss: 0.3238 r:0.8202
et_en Dev loss: 0.3482 r:0.7302
si_en Dev loss: 0.5525 r:0.5996
ne_en Dev loss: 0.4523 r:0.7651
ru_en Dev loss: 0.3842 r:0.7566
Current avg r:0.6210 Best avg r: 0.6226
17:21:01,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:40,259 root INFO 
id:ro_en cur r: 0.8230 best r: 0.8230
17:21:53,313 root INFO 
id:et_en cur r: 0.7242 best r: 0.7242
17:22:06,389 root INFO 
id:ne_en cur r: 0.7736 best r: 0.7736
17:22:19,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:50,656 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4992
en_de Dev loss: 0.8698 r:0.2239
en_zh Dev loss: 0.7086 r:0.4479
ro_en Dev loss: 0.3158 r:0.8205
et_en Dev loss: 0.3381 r:0.7269
si_en Dev loss: 0.5276 r:0.6058
ne_en Dev loss: 0.3575 r:0.7673
ru_en Dev loss: 0.4128 r:0.7479
Current avg r:0.6200 Best avg r: 0.6226
17:27:44,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:57,855 root INFO 
id:en_de cur r: 0.2470 best r: 0.2470
17:28:10,883 root INFO 
id:en_zh cur r: 0.4690 best r: 0.4690
17:29:03,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:34,355 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4939
en_de Dev loss: 0.8468 r:0.2432
en_zh Dev loss: 0.6896 r:0.4611
ro_en Dev loss: 0.3235 r:0.8186
et_en Dev loss: 0.3681 r:0.7173
si_en Dev loss: 0.5632 r:0.5990
ne_en Dev loss: 0.4073 r:0.7616
ru_en Dev loss: 0.3974 r:0.7559
Current avg r:0.6224 Best avg r: 0.6226
17:34:28,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:46,597 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:17,797 root INFO Epoch 1 Global steps: 16200 Train loss: 0.4770
en_de Dev loss: 0.8709 r:0.2260
en_zh Dev loss: 0.7208 r:0.4632
ro_en Dev loss: 0.3448 r:0.8194
et_en Dev loss: 0.3633 r:0.7191
si_en Dev loss: 0.6249 r:0.5937
ne_en Dev loss: 0.4767 r:0.7644
ru_en Dev loss: 0.4738 r:0.7409
Current avg r:0.6181 Best avg r: 0.6226
17:41:11,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:29,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:00,769 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4393
en_de Dev loss: 0.9082 r:0.2266
en_zh Dev loss: 0.8518 r:0.4325
ro_en Dev loss: 0.3965 r:0.8101
et_en Dev loss: 0.3902 r:0.7112
si_en Dev loss: 0.6487 r:0.5908
ne_en Dev loss: 0.5172 r:0.7539
ru_en Dev loss: 0.5627 r:0.6951
Current avg r:0.6029 Best avg r: 0.6226
17:47:54,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:46,445 root INFO 
id:et_en cur r: 0.7252 best r: 0.7252
17:49:12,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:43,568 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4503
en_de Dev loss: 0.8509 r:0.2163
en_zh Dev loss: 0.7009 r:0.4453
ro_en Dev loss: 0.3010 r:0.8158
et_en Dev loss: 0.3561 r:0.7270
si_en Dev loss: 0.5127 r:0.6112
ne_en Dev loss: 0.3341 r:0.7669
ru_en Dev loss: 0.4066 r:0.7423
Current avg r:0.6179 Best avg r: 0.6226
17:54:37,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:16,368 root INFO 
id:ro_en cur r: 0.8284 best r: 0.8284
17:55:29,425 root INFO 
id:et_en cur r: 0.7295 best r: 0.7295
17:55:55,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:26,676 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
17:57:26,684 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:57:26,692 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:57:26,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
17:57:26,707 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
17:57:26,717 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:57:26,723 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:57:39,796 root INFO Epoch 1 Global steps: 18000 Train loss: 0.4860
en_de Dev loss: 0.8429 r:0.2240
en_zh Dev loss: 0.6792 r:0.4621
ro_en Dev loss: 0.3013 r:0.8247
et_en Dev loss: 0.3502 r:0.7319
si_en Dev loss: 0.5250 r:0.6095
ne_en Dev loss: 0.3602 r:0.7640
ru_en Dev loss: 0.3813 r:0.7566
Current avg r:0.6247 Best avg r: 0.6247
18:01:35,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:48,140 root INFO 
id:en_de cur r: 0.2523 best r: 0.2523
18:02:53,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:24,461 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4333
en_de Dev loss: 0.8371 r:0.2377
en_zh Dev loss: 0.7229 r:0.4540
ro_en Dev loss: 0.3149 r:0.8195
et_en Dev loss: 0.3592 r:0.7235
si_en Dev loss: 0.5244 r:0.6118
ne_en Dev loss: 0.3730 r:0.7663
ru_en Dev loss: 0.4151 r:0.7366
Current avg r:0.6213 Best avg r: 0.6247
18:08:18,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:31,490 root INFO 
id:en_de cur r: 0.2527 best r: 0.2527
18:09:36,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:07,712 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4592
en_de Dev loss: 0.8417 r:0.2321
en_zh Dev loss: 0.7196 r:0.4463
ro_en Dev loss: 0.3378 r:0.8194
et_en Dev loss: 0.3676 r:0.7147
si_en Dev loss: 0.5478 r:0.6054
ne_en Dev loss: 0.4526 r:0.7578
ru_en Dev loss: 0.4641 r:0.7163
Current avg r:0.6131 Best avg r: 0.6247
18:15:01,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:19,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:50,663 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4402
en_de Dev loss: 0.8676 r:0.2016
en_zh Dev loss: 0.7837 r:0.4418
ro_en Dev loss: 0.3526 r:0.8228
et_en Dev loss: 0.3730 r:0.7138
si_en Dev loss: 0.5837 r:0.6070
ne_en Dev loss: 0.4880 r:0.7546
ru_en Dev loss: 0.5086 r:0.7079
Current avg r:0.6071 Best avg r: 0.6247
18:21:44,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:02,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:33,793 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4409
en_de Dev loss: 0.8825 r:0.1710
en_zh Dev loss: 0.7142 r:0.4491
ro_en Dev loss: 0.3069 r:0.8215
et_en Dev loss: 0.3633 r:0.7108
si_en Dev loss: 0.5464 r:0.6054
ne_en Dev loss: 0.4427 r:0.7521
ru_en Dev loss: 0.4308 r:0.7229
Current avg r:0.6047 Best avg r: 0.6247
18:28:27,781 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:45,926 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:17,125 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4367
en_de Dev loss: 0.8737 r:0.1964
en_zh Dev loss: 0.7575 r:0.4410
ro_en Dev loss: 0.3478 r:0.8140
et_en Dev loss: 0.3714 r:0.7084
si_en Dev loss: 0.6368 r:0.5922
ne_en Dev loss: 0.5886 r:0.7600
ru_en Dev loss: 0.4669 r:0.7221
Current avg r:0.6049 Best avg r: 0.6247
18:35:10,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:28,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:00,138 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4336
en_de Dev loss: 0.8565 r:0.2346
en_zh Dev loss: 0.6949 r:0.4534
ro_en Dev loss: 0.3267 r:0.8188
et_en Dev loss: 0.3562 r:0.7166
si_en Dev loss: 0.5518 r:0.6006
ne_en Dev loss: 0.4506 r:0.7664
ru_en Dev loss: 0.4357 r:0.7273
Current avg r:0.6168 Best avg r: 0.6247
18:41:53,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:19,816 root INFO 
id:en_zh cur r: 0.4752 best r: 0.4752
18:42:32,856 root INFO 
id:ro_en cur r: 0.8302 best r: 0.8302
18:42:58,979 root INFO 
id:ne_en cur r: 0.7742 best r: 0.7742
18:43:11,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:43,142 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
18:44:43,155 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:44:43,163 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:44:43,168 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
18:44:43,174 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
18:44:43,181 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:44:43,187 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:44:56,255 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4068
en_de Dev loss: 0.8548 r:0.2265
en_zh Dev loss: 0.6792 r:0.4722
ro_en Dev loss: 0.3054 r:0.8250
et_en Dev loss: 0.3608 r:0.7249
si_en Dev loss: 0.5333 r:0.6122
ne_en Dev loss: 0.4273 r:0.7701
ru_en Dev loss: 0.3934 r:0.7515
Current avg r:0.6261 Best avg r: 0.6261
18:48:49,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:08,87 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:39,222 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4209
en_de Dev loss: 0.8672 r:0.2323
en_zh Dev loss: 0.7153 r:0.4537
ro_en Dev loss: 0.3286 r:0.8169
et_en Dev loss: 0.3609 r:0.7173
si_en Dev loss: 0.5768 r:0.5959
ne_en Dev loss: 0.4498 r:0.7585
ru_en Dev loss: 0.4604 r:0.7203
Current avg r:0.6136 Best avg r: 0.6261
18:55:32,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:50,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:22,148 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4076
en_de Dev loss: 0.8644 r:0.2119
en_zh Dev loss: 0.6871 r:0.4606
ro_en Dev loss: 0.3049 r:0.8192
et_en Dev loss: 0.3609 r:0.7192
si_en Dev loss: 0.5223 r:0.6106
ne_en Dev loss: 0.3526 r:0.7662
ru_en Dev loss: 0.3925 r:0.7438
Current avg r:0.6188 Best avg r: 0.6261
19:02:15,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:33,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:05,70 root INFO Epoch 2 Global steps: 24000 Train loss: 0.3844
en_de Dev loss: 0.8571 r:0.2288
en_zh Dev loss: 0.7453 r:0.4529
ro_en Dev loss: 0.3543 r:0.8183
et_en Dev loss: 0.3740 r:0.7200
si_en Dev loss: 0.6138 r:0.6003
ne_en Dev loss: 0.4415 r:0.7653
ru_en Dev loss: 0.4587 r:0.7352
Current avg r:0.6172 Best avg r: 0.6261
19:08:58,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:11,789 root INFO 
id:en_de cur r: 0.2619 best r: 0.2619
19:10:16,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:48,0 root INFO Epoch 2 Global steps: 24600 Train loss: 0.4001
en_de Dev loss: 0.8524 r:0.2458
en_zh Dev loss: 0.7380 r:0.4509
ro_en Dev loss: 0.3152 r:0.8209
et_en Dev loss: 0.3539 r:0.7203
si_en Dev loss: 0.5655 r:0.6021
ne_en Dev loss: 0.4291 r:0.7687
ru_en Dev loss: 0.4243 r:0.7323
Current avg r:0.6201 Best avg r: 0.6261
19:15:41,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:59,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:30,892 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4145
en_de Dev loss: 0.8493 r:0.2360
en_zh Dev loss: 0.6893 r:0.4635
ro_en Dev loss: 0.3050 r:0.8252
et_en Dev loss: 0.3592 r:0.7175
si_en Dev loss: 0.5681 r:0.6005
ne_en Dev loss: 0.4381 r:0.7606
ru_en Dev loss: 0.4258 r:0.7390
Current avg r:0.6203 Best avg r: 0.6261
19:22:24,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:42,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:13,707 root INFO Epoch 2 Global steps: 25800 Train loss: 0.3855
en_de Dev loss: 0.8492 r:0.2391
en_zh Dev loss: 0.7063 r:0.4690
ro_en Dev loss: 0.3107 r:0.8266
et_en Dev loss: 0.3587 r:0.7238
si_en Dev loss: 0.5833 r:0.5956
ne_en Dev loss: 0.4399 r:0.7576
ru_en Dev loss: 0.4515 r:0.7308
Current avg r:0.6204 Best avg r: 0.6261
19:29:07,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:20,409 root INFO 
id:en_de cur r: 0.2685 best r: 0.2685
19:29:33,426 root INFO 
id:en_zh cur r: 0.4820 best r: 0.4820
19:29:46,472 root INFO 
id:ro_en cur r: 0.8312 best r: 0.8312
19:30:25,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:56,701 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_de.lang_agnost_mlp.dev.best.scores
19:31:56,723 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/en_zh.lang_agnost_mlp.dev.best.scores
19:31:56,734 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ro_en.lang_agnost_mlp.dev.best.scores
19:31:56,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/et_en.lang_agnost_mlp.dev.best.scores
19:31:56,752 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/si_en.lang_agnost_mlp.dev.best.scores
19:31:56,764 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ne_en.lang_agnost_mlp.dev.best.scores
19:31:56,774 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run2/ru_en.lang_agnost_mlp.dev.best.scores
19:32:09,833 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4186
en_de Dev loss: 0.8370 r:0.2519
en_zh Dev loss: 0.6832 r:0.4751
ro_en Dev loss: 0.3006 r:0.8289
et_en Dev loss: 0.3578 r:0.7281
si_en Dev loss: 0.5436 r:0.6043
ne_en Dev loss: 0.3790 r:0.7658
ru_en Dev loss: 0.3836 r:0.7590
Current avg r:0.6304 Best avg r: 0.6304
19:36:03,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:37:21,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:52,879 root INFO Epoch 2 Global steps: 27000 Train loss: 0.3962
en_de Dev loss: 0.8503 r:0.2419
en_zh Dev loss: 0.7076 r:0.4670
ro_en Dev loss: 0.3072 r:0.8294
et_en Dev loss: 0.3550 r:0.7233
si_en Dev loss: 0.5549 r:0.6014
ne_en Dev loss: 0.3926 r:0.7670
ru_en Dev loss: 0.4248 r:0.7383
Current avg r:0.6240 Best avg r: 0.6304
19:42:48,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:06,405 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:37,641 root INFO Epoch 3 Global steps: 27600 Train loss: 0.3533
en_de Dev loss: 0.8584 r:0.2333
en_zh Dev loss: 0.7329 r:0.4660
ro_en Dev loss: 0.3276 r:0.8283
et_en Dev loss: 0.3588 r:0.7260
si_en Dev loss: 0.5705 r:0.6022
ne_en Dev loss: 0.4158 r:0.7650
ru_en Dev loss: 0.4567 r:0.7351
Current avg r:0.6223 Best avg r: 0.6304
19:49:31,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:50,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:21,257 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3823
en_de Dev loss: 0.8865 r:0.2315
en_zh Dev loss: 0.8185 r:0.4561
ro_en Dev loss: 0.3419 r:0.8300
et_en Dev loss: 0.3668 r:0.7224
si_en Dev loss: 0.6673 r:0.5912
ne_en Dev loss: 0.5322 r:0.7599
ru_en Dev loss: 0.4945 r:0.7321
Current avg r:0.6176 Best avg r: 0.6304
19:56:15,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:33,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:04,993 root INFO Epoch 3 Global steps: 28800 Train loss: 0.3865
en_de Dev loss: 0.8561 r:0.2262
en_zh Dev loss: 0.7768 r:0.4416
ro_en Dev loss: 0.3270 r:0.8219
et_en Dev loss: 0.3784 r:0.7141
si_en Dev loss: 0.5704 r:0.5934
ne_en Dev loss: 0.4013 r:0.7550
ru_en Dev loss: 0.5139 r:0.6996
Current avg r:0.6074 Best avg r: 0.6304
20:02:59,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:17,414 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:48,640 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3784
en_de Dev loss: 0.8492 r:0.2307
en_zh Dev loss: 0.7232 r:0.4596
ro_en Dev loss: 0.3131 r:0.8262
et_en Dev loss: 0.3865 r:0.7126
si_en Dev loss: 0.5588 r:0.5960
ne_en Dev loss: 0.3979 r:0.7632
ru_en Dev loss: 0.4396 r:0.7301
Current avg r:0.6169 Best avg r: 0.6304
20:09:42,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:01,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:32,274 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3485
en_de Dev loss: 0.8384 r:0.2593
en_zh Dev loss: 0.7023 r:0.4644
ro_en Dev loss: 0.3223 r:0.8253
et_en Dev loss: 0.3813 r:0.7143
si_en Dev loss: 0.5612 r:0.5972
ne_en Dev loss: 0.4103 r:0.7658
ru_en Dev loss: 0.4437 r:0.7231
Current avg r:0.6213 Best avg r: 0.6304
20:16:26,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:44,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:15,881 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3367
en_de Dev loss: 0.8378 r:0.2431
en_zh Dev loss: 0.7313 r:0.4527
ro_en Dev loss: 0.3210 r:0.8252
et_en Dev loss: 0.3661 r:0.7142
si_en Dev loss: 0.6028 r:0.5976
ne_en Dev loss: 0.4476 r:0.7672
ru_en Dev loss: 0.4262 r:0.7387
Current avg r:0.6198 Best avg r: 0.6304
20:23:09,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:28,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:59,406 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3604
en_de Dev loss: 0.8494 r:0.2426
en_zh Dev loss: 0.7273 r:0.4456
ro_en Dev loss: 0.3397 r:0.8162
et_en Dev loss: 0.3916 r:0.6943
si_en Dev loss: 0.6186 r:0.5825
ne_en Dev loss: 0.5931 r:0.7563
ru_en Dev loss: 0.4716 r:0.7100
Current avg r:0.6068 Best avg r: 0.6304
20:29:53,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:11,665 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:42,913 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3550
en_de Dev loss: 0.8543 r:0.2492
en_zh Dev loss: 0.7304 r:0.4547
ro_en Dev loss: 0.3248 r:0.8242
et_en Dev loss: 0.3914 r:0.7098
si_en Dev loss: 0.5902 r:0.5988
ne_en Dev loss: 0.4417 r:0.7643
ru_en Dev loss: 0.4212 r:0.7450
Current avg r:0.6209 Best avg r: 0.6304
20:36:37,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:50,139 root INFO 
id:en_de cur r: 0.2711 best r: 0.2711
20:37:55,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:26,503 root INFO Epoch 3 Global steps: 32400 Train loss: 0.3659
en_de Dev loss: 0.8481 r:0.2654
en_zh Dev loss: 0.7631 r:0.4496
ro_en Dev loss: 0.3302 r:0.8231
et_en Dev loss: 0.4033 r:0.7052
si_en Dev loss: 0.6082 r:0.5942
ne_en Dev loss: 0.4098 r:0.7590
ru_en Dev loss: 0.4545 r:0.7286
Current avg r:0.6179 Best avg r: 0.6304
20:43:20,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:38,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:09,812 root INFO Epoch 3 Global steps: 33000 Train loss: 0.3410
en_de Dev loss: 0.8463 r:0.2594
en_zh Dev loss: 0.7377 r:0.4372
ro_en Dev loss: 0.3035 r:0.8238
et_en Dev loss: 0.4009 r:0.7058
si_en Dev loss: 0.5947 r:0.5901
ne_en Dev loss: 0.5028 r:0.7541
ru_en Dev loss: 0.4329 r:0.7232
Current avg r:0.6134 Best avg r: 0.6304
20:50:03,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:21,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:53,20 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3483
en_de Dev loss: 0.8677 r:0.2500
en_zh Dev loss: 0.7637 r:0.4386
ro_en Dev loss: 0.3312 r:0.8186
et_en Dev loss: 0.4188 r:0.6968
si_en Dev loss: 0.5908 r:0.5987
ne_en Dev loss: 0.4343 r:0.7537
ru_en Dev loss: 0.4385 r:0.7293
Current avg r:0.6123 Best avg r: 0.6304
20:56:47,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:05,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:36,621 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3562
en_de Dev loss: 0.8490 r:0.2497
en_zh Dev loss: 0.7701 r:0.4343
ro_en Dev loss: 0.3290 r:0.8195
et_en Dev loss: 0.3988 r:0.6994
si_en Dev loss: 0.6609 r:0.5949
ne_en Dev loss: 0.5184 r:0.7555
ru_en Dev loss: 0.4494 r:0.7238
Current avg r:0.6110 Best avg r: 0.6304
21:03:30,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:48,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:20,91 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3607
en_de Dev loss: 0.8458 r:0.2488
en_zh Dev loss: 0.7363 r:0.4448
ro_en Dev loss: 0.3150 r:0.8154
et_en Dev loss: 0.3947 r:0.6977
si_en Dev loss: 0.6077 r:0.5932
ne_en Dev loss: 0.4516 r:0.7467
ru_en Dev loss: 0.4376 r:0.7241
Current avg r:0.6101 Best avg r: 0.6304
21:10:14,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:32,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:03,772 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3604
en_de Dev loss: 0.8735 r:0.2193
en_zh Dev loss: 0.7577 r:0.4412
ro_en Dev loss: 0.3190 r:0.8242
et_en Dev loss: 0.3740 r:0.7081
si_en Dev loss: 0.6038 r:0.6111
ne_en Dev loss: 0.4219 r:0.7533
ru_en Dev loss: 0.4656 r:0.7238
Current avg r:0.6116 Best avg r: 0.6304
21:16:58,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:16,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:47,752 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3726
en_de Dev loss: 0.8657 r:0.2250
en_zh Dev loss: 0.7152 r:0.4632
ro_en Dev loss: 0.3013 r:0.8263
et_en Dev loss: 0.4020 r:0.7025
si_en Dev loss: 0.5546 r:0.6068
ne_en Dev loss: 0.4013 r:0.7467
ru_en Dev loss: 0.3897 r:0.7468
Current avg r:0.6168 Best avg r: 0.6304
21:23:43,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:01,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:32,806 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3125
en_de Dev loss: 0.8747 r:0.2158
en_zh Dev loss: 0.7791 r:0.4381
ro_en Dev loss: 0.3301 r:0.8236
et_en Dev loss: 0.4076 r:0.7079
si_en Dev loss: 0.6045 r:0.6106
ne_en Dev loss: 0.4751 r:0.7439
ru_en Dev loss: 0.4439 r:0.7355
Current avg r:0.6108 Best avg r: 0.6304
21:30:26,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:45,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:16,534 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3122
en_de Dev loss: 0.8589 r:0.2218
en_zh Dev loss: 0.7567 r:0.4335
ro_en Dev loss: 0.3149 r:0.8207
et_en Dev loss: 0.4147 r:0.6990
si_en Dev loss: 0.5815 r:0.6043
ne_en Dev loss: 0.4195 r:0.7444
ru_en Dev loss: 0.4728 r:0.7102
Current avg r:0.6049 Best avg r: 0.6304
21:37:10,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:29,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:00,405 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3127
en_de Dev loss: 0.8755 r:0.2003
en_zh Dev loss: 0.7896 r:0.4294
ro_en Dev loss: 0.3463 r:0.8172
et_en Dev loss: 0.4090 r:0.6890
si_en Dev loss: 0.6628 r:0.5927
ne_en Dev loss: 0.5500 r:0.7453
ru_en Dev loss: 0.5206 r:0.6972
Current avg r:0.5959 Best avg r: 0.6304
21:43:54,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:12,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:44,141 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3042
en_de Dev loss: 0.8568 r:0.2216
en_zh Dev loss: 0.7749 r:0.4300
ro_en Dev loss: 0.3431 r:0.8160
et_en Dev loss: 0.4552 r:0.6958
si_en Dev loss: 0.5701 r:0.6088
ne_en Dev loss: 0.4160 r:0.7516
ru_en Dev loss: 0.4273 r:0.7359
Current avg r:0.6085 Best avg r: 0.6304
21:50:38,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:56,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:27,767 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3021
en_de Dev loss: 0.8615 r:0.2199
en_zh Dev loss: 0.7799 r:0.4439
ro_en Dev loss: 0.3468 r:0.8209
et_en Dev loss: 0.4078 r:0.6979
si_en Dev loss: 0.6568 r:0.6034
ne_en Dev loss: 0.4598 r:0.7528
ru_en Dev loss: 0.4711 r:0.7290
Current avg r:0.6097 Best avg r: 0.6304
21:57:21,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:40,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:11,362 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3014
en_de Dev loss: 0.8609 r:0.2227
en_zh Dev loss: 0.7713 r:0.4336
ro_en Dev loss: 0.3179 r:0.8200
et_en Dev loss: 0.4277 r:0.6910
si_en Dev loss: 0.5796 r:0.6026
ne_en Dev loss: 0.4314 r:0.7481
ru_en Dev loss: 0.4121 r:0.7366
Current avg r:0.6078 Best avg r: 0.6304
22:04:05,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:23,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:54,997 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3179
en_de Dev loss: 0.8741 r:0.2173
en_zh Dev loss: 0.7722 r:0.4318
ro_en Dev loss: 0.3388 r:0.8164
et_en Dev loss: 0.4240 r:0.6823
si_en Dev loss: 0.6149 r:0.5998
ne_en Dev loss: 0.4587 r:0.7528
ru_en Dev loss: 0.4782 r:0.7045
Current avg r:0.6007 Best avg r: 0.6304
22:10:49,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:07,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:38,702 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3151
en_de Dev loss: 0.9057 r:0.2160
en_zh Dev loss: 0.8099 r:0.4346
ro_en Dev loss: 0.3597 r:0.8180
et_en Dev loss: 0.4566 r:0.6815
si_en Dev loss: 0.6679 r:0.5958
ne_en Dev loss: 0.4889 r:0.7488
ru_en Dev loss: 0.5347 r:0.6981
Current avg r:0.5990 Best avg r: 0.6304
22:17:32,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:50,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:22,318 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3006
en_de Dev loss: 0.8733 r:0.2049
en_zh Dev loss: 0.7389 r:0.4511
ro_en Dev loss: 0.3318 r:0.8168
et_en Dev loss: 0.4221 r:0.6771
si_en Dev loss: 0.6389 r:0.5920
ne_en Dev loss: 0.4796 r:0.7511
ru_en Dev loss: 0.4774 r:0.7071
Current avg r:0.6000 Best avg r: 0.6304
22:24:16,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:34,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:05,905 root INFO Epoch 4 Global steps: 42000 Train loss: 0.2915
en_de Dev loss: 0.8617 r:0.2234
en_zh Dev loss: 0.7607 r:0.4363
ro_en Dev loss: 0.3350 r:0.8234
et_en Dev loss: 0.4337 r:0.6914
si_en Dev loss: 0.5979 r:0.6032
ne_en Dev loss: 0.4722 r:0.7509
ru_en Dev loss: 0.4619 r:0.7169
Current avg r:0.6065 Best avg r: 0.6304
22:30:59,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:18,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:33:49,518 root INFO Epoch 4 Global steps: 42600 Train loss: 0.2872
en_de Dev loss: 0.8631 r:0.2204
en_zh Dev loss: 0.7632 r:0.4495
ro_en Dev loss: 0.3402 r:0.8254
et_en Dev loss: 0.4081 r:0.6959
si_en Dev loss: 0.6676 r:0.5993
ne_en Dev loss: 0.4821 r:0.7540
ru_en Dev loss: 0.4456 r:0.7354
Current avg r:0.6114 Best avg r: 0.6304
22:37:43,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:39:01,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:33,264 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3090
en_de Dev loss: 0.8796 r:0.1885
en_zh Dev loss: 0.7937 r:0.4358
ro_en Dev loss: 0.3518 r:0.8219
et_en Dev loss: 0.4314 r:0.6886
si_en Dev loss: 0.7086 r:0.5888
ne_en Dev loss: 0.5709 r:0.7496
ru_en Dev loss: 0.4833 r:0.7230
Current avg r:0.5994 Best avg r: 0.6304
22:44:27,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:45:45,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:17,41 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3010
en_de Dev loss: 0.8791 r:0.1984
en_zh Dev loss: 0.7502 r:0.4566
ro_en Dev loss: 0.3250 r:0.8198
et_en Dev loss: 0.4477 r:0.6904
si_en Dev loss: 0.6048 r:0.5947
ne_en Dev loss: 0.4081 r:0.7513
ru_en Dev loss: 0.4359 r:0.7344
Current avg r:0.6065 Best avg r: 0.6304
22:51:11,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:29,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:00,751 root INFO Epoch 4 Global steps: 44400 Train loss: 0.2937
en_de Dev loss: 0.8706 r:0.1981
en_zh Dev loss: 0.7631 r:0.4333
ro_en Dev loss: 0.3301 r:0.8152
et_en Dev loss: 0.4190 r:0.6794
si_en Dev loss: 0.6158 r:0.5892
ne_en Dev loss: 0.4818 r:0.7466
ru_en Dev loss: 0.4622 r:0.7078
Current avg r:0.5957 Best avg r: 0.6304
22:57:54,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:13,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:44,416 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3034
en_de Dev loss: 0.8749 r:0.2217
en_zh Dev loss: 0.8057 r:0.4439
ro_en Dev loss: 0.3546 r:0.8154
et_en Dev loss: 0.4499 r:0.6877
si_en Dev loss: 0.6411 r:0.5968
ne_en Dev loss: 0.4786 r:0.7464
ru_en Dev loss: 0.4759 r:0.7215
Current avg r:0.6048 Best avg r: 0.6304
23:04:39,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:57,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:29,158 root INFO Epoch 5 Global steps: 45600 Train loss: 0.2681
en_de Dev loss: 0.8613 r:0.2405
en_zh Dev loss: 0.7669 r:0.4585
ro_en Dev loss: 0.3684 r:0.8144
et_en Dev loss: 0.4274 r:0.6820
si_en Dev loss: 0.7329 r:0.5816
ne_en Dev loss: 0.6043 r:0.7364
ru_en Dev loss: 0.4832 r:0.7203
Current avg r:0.6048 Best avg r: 0.6304
23:11:23,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:12:41,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:12,766 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2588
en_de Dev loss: 0.8709 r:0.2307
en_zh Dev loss: 0.8146 r:0.4308
ro_en Dev loss: 0.3571 r:0.8097
et_en Dev loss: 0.4446 r:0.6771
si_en Dev loss: 0.6632 r:0.5838
ne_en Dev loss: 0.5219 r:0.7354
ru_en Dev loss: 0.5026 r:0.7042
Current avg r:0.5959 Best avg r: 0.6304
23:18:06,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:25,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:56,312 root INFO Epoch 5 Global steps: 46800 Train loss: 0.2492
en_de Dev loss: 0.8545 r:0.2305
en_zh Dev loss: 0.7601 r:0.4469
ro_en Dev loss: 0.3068 r:0.8197
et_en Dev loss: 0.4108 r:0.6908
si_en Dev loss: 0.6210 r:0.5962
ne_en Dev loss: 0.4744 r:0.7398
ru_en Dev loss: 0.4087 r:0.7418
Current avg r:0.6094 Best avg r: 0.6304
23:24:50,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:08,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:39,755 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2478
en_de Dev loss: 0.8722 r:0.2298
en_zh Dev loss: 0.8073 r:0.4353
ro_en Dev loss: 0.3445 r:0.8137
et_en Dev loss: 0.4434 r:0.6803
si_en Dev loss: 0.6473 r:0.5918
ne_en Dev loss: 0.5278 r:0.7397
ru_en Dev loss: 0.4724 r:0.7241
Current avg r:0.6021 Best avg r: 0.6304
23:31:34,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:52,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:34:23,614 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2568
en_de Dev loss: 0.8645 r:0.2351
en_zh Dev loss: 0.7998 r:0.4325
ro_en Dev loss: 0.3227 r:0.8212
et_en Dev loss: 0.4146 r:0.6919
si_en Dev loss: 0.6321 r:0.6033
ne_en Dev loss: 0.4749 r:0.7353
ru_en Dev loss: 0.4471 r:0.7337
Current avg r:0.6076 Best avg r: 0.6304
23:38:17,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:36,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:07,457 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2439
en_de Dev loss: 0.8684 r:0.2332
en_zh Dev loss: 0.8151 r:0.4188
ro_en Dev loss: 0.3474 r:0.8099
et_en Dev loss: 0.4344 r:0.6695
si_en Dev loss: 0.6646 r:0.5819
ne_en Dev loss: 0.5698 r:0.7309
ru_en Dev loss: 0.4796 r:0.7045
Current avg r:0.5927 Best avg r: 0.6304
23:45:01,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:19,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:47:50,878 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2646
en_de Dev loss: 0.8819 r:0.2282
en_zh Dev loss: 0.8323 r:0.4301
ro_en Dev loss: 0.3628 r:0.8159
et_en Dev loss: 0.4537 r:0.6823
si_en Dev loss: 0.7039 r:0.5835
ne_en Dev loss: 0.5634 r:0.7305
ru_en Dev loss: 0.4797 r:0.7216
Current avg r:0.5989 Best avg r: 0.6304
23:51:44,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:53:02,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:54:34,163 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2642
en_de Dev loss: 0.8876 r:0.2281
en_zh Dev loss: 0.8308 r:0.4330
ro_en Dev loss: 0.3660 r:0.8180
et_en Dev loss: 0.4388 r:0.6841
si_en Dev loss: 0.6920 r:0.5885
ne_en Dev loss: 0.5174 r:0.7348
ru_en Dev loss: 0.5274 r:0.7047
Current avg r:0.5987 Best avg r: 0.6304
23:58:28,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:46,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:17,473 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2530
en_de Dev loss: 0.9168 r:0.2126
en_zh Dev loss: 0.8463 r:0.4321
ro_en Dev loss: 0.3843 r:0.8194
et_en Dev loss: 0.4442 r:0.6781
si_en Dev loss: 0.7607 r:0.5856
ne_en Dev loss: 0.5723 r:0.7312
ru_en Dev loss: 0.5428 r:0.6996
Current avg r:0.5941 Best avg r: 0.6304
00:05:11,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:06:29,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:00,878 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2646
en_de Dev loss: 0.8987 r:0.1997
en_zh Dev loss: 0.7623 r:0.4504
ro_en Dev loss: 0.3565 r:0.8188
et_en Dev loss: 0.4531 r:0.6757
si_en Dev loss: 0.6542 r:0.5871
ne_en Dev loss: 0.4578 r:0.7376
ru_en Dev loss: 0.4587 r:0.7243
Current avg r:0.5991 Best avg r: 0.6304
00:11:54,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:12,880 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:44,148 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2555
en_de Dev loss: 0.8974 r:0.2025
en_zh Dev loss: 0.7951 r:0.4392
ro_en Dev loss: 0.3516 r:0.8169
et_en Dev loss: 0.4700 r:0.6866
si_en Dev loss: 0.6692 r:0.5851
ne_en Dev loss: 0.4945 r:0.7353
ru_en Dev loss: 0.4684 r:0.7239
Current avg r:0.5985 Best avg r: 0.6304
00:18:38,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:56,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:21:27,551 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2478
en_de Dev loss: 0.8695 r:0.2082
en_zh Dev loss: 0.7720 r:0.4442
ro_en Dev loss: 0.3409 r:0.8162
et_en Dev loss: 0.4518 r:0.6883
si_en Dev loss: 0.6106 r:0.5926
ne_en Dev loss: 0.4479 r:0.7343
ru_en Dev loss: 0.4447 r:0.7199
Current avg r:0.6005 Best avg r: 0.6304
00:25:21,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:39,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:28:10,865 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2568
en_de Dev loss: 0.8570 r:0.2133
en_zh Dev loss: 0.7587 r:0.4433
ro_en Dev loss: 0.3166 r:0.8185
et_en Dev loss: 0.4173 r:0.6867
si_en Dev loss: 0.6131 r:0.5967
ne_en Dev loss: 0.4819 r:0.7366
ru_en Dev loss: 0.4951 r:0.6968
Current avg r:0.5988 Best avg r: 0.6304
00:32:04,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:33:22,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:54,172 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2571
en_de Dev loss: 0.8731 r:0.2080
en_zh Dev loss: 0.8098 r:0.4446
ro_en Dev loss: 0.3647 r:0.8193
et_en Dev loss: 0.4327 r:0.6836
si_en Dev loss: 0.6901 r:0.5876
ne_en Dev loss: 0.5332 r:0.7369
ru_en Dev loss: 0.4878 r:0.7147
Current avg r:0.5992 Best avg r: 0.6304
00:38:48,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:06,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:37,457 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2641
en_de Dev loss: 0.8859 r:0.2026
en_zh Dev loss: 0.7996 r:0.4591
ro_en Dev loss: 0.3477 r:0.8190
et_en Dev loss: 0.4728 r:0.6926
si_en Dev loss: 0.5970 r:0.5972
ne_en Dev loss: 0.4479 r:0.7282
ru_en Dev loss: 0.4409 r:0.7374
Current avg r:0.6052 Best avg r: 0.6304
00:45:32,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:50,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:48:21,967 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2227
en_de Dev loss: 0.8749 r:0.2296
en_zh Dev loss: 0.7965 r:0.4539
ro_en Dev loss: 0.3507 r:0.8166
et_en Dev loss: 0.4554 r:0.6873
si_en Dev loss: 0.6841 r:0.5824
ne_en Dev loss: 0.5104 r:0.7298
ru_en Dev loss: 0.4562 r:0.7324
Current avg r:0.6046 Best avg r: 0.6304
00:52:15,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:33,906 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:05,147 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2273
en_de Dev loss: 0.8646 r:0.2203
en_zh Dev loss: 0.7851 r:0.4388
ro_en Dev loss: 0.3338 r:0.8171
et_en Dev loss: 0.4597 r:0.6825
si_en Dev loss: 0.6344 r:0.5857
ne_en Dev loss: 0.4854 r:0.7283
ru_en Dev loss: 0.4310 r:0.7381
Current avg r:0.6015 Best avg r: 0.6304
00:58:58,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:17,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:48,366 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2224
en_de Dev loss: 0.8891 r:0.1915
en_zh Dev loss: 0.8346 r:0.4324
ro_en Dev loss: 0.3547 r:0.8153
et_en Dev loss: 0.4419 r:0.6849
si_en Dev loss: 0.7130 r:0.5795
ne_en Dev loss: 0.5517 r:0.7249
ru_en Dev loss: 0.5224 r:0.7085
Current avg r:0.5910 Best avg r: 0.6304
01:05:42,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:00,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:31,569 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2240
en_de Dev loss: 0.9020 r:0.1909
en_zh Dev loss: 0.8957 r:0.4271
ro_en Dev loss: 0.4186 r:0.8084
et_en Dev loss: 0.4719 r:0.6631
si_en Dev loss: 0.8540 r:0.5704
ne_en Dev loss: 0.7227 r:0.7266
ru_en Dev loss: 0.5798 r:0.6963
Current avg r:0.5833 Best avg r: 0.6304
01:12:25,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:43,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:14,775 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2096
en_de Dev loss: 0.8745 r:0.2119
en_zh Dev loss: 0.7858 r:0.4446
ro_en Dev loss: 0.3468 r:0.8148
et_en Dev loss: 0.4684 r:0.6885
si_en Dev loss: 0.6402 r:0.5925
ne_en Dev loss: 0.4938 r:0.7321
ru_en Dev loss: 0.4492 r:0.7281
Current avg r:0.6018 Best avg r: 0.6304
01:19:08,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:20:26,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:21:58,35 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2211
en_de Dev loss: 0.8669 r:0.2026
en_zh Dev loss: 0.8197 r:0.4266
ro_en Dev loss: 0.3572 r:0.8129
et_en Dev loss: 0.4451 r:0.6771
si_en Dev loss: 0.7177 r:0.5773
ne_en Dev loss: 0.5608 r:0.7288
ru_en Dev loss: 0.4859 r:0.7099
Current avg r:0.5907 Best avg r: 0.6304
01:25:51,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:27:10,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:41,398 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2471
en_de Dev loss: 0.8803 r:0.1968
en_zh Dev loss: 0.7979 r:0.4360
ro_en Dev loss: 0.3378 r:0.8159
et_en Dev loss: 0.4524 r:0.6832
si_en Dev loss: 0.6342 r:0.5897
ne_en Dev loss: 0.4632 r:0.7302
ru_en Dev loss: 0.4478 r:0.7285
Current avg r:0.5972 Best avg r: 0.6304
01:32:35,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:33:53,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:35:24,682 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2171
en_de Dev loss: 0.8754 r:0.2026
en_zh Dev loss: 0.7560 r:0.4527
ro_en Dev loss: 0.3218 r:0.8162
et_en Dev loss: 0.4363 r:0.6775
si_en Dev loss: 0.6583 r:0.5840
ne_en Dev loss: 0.4951 r:0.7338
ru_en Dev loss: 0.4555 r:0.7174
Current avg r:0.5977 Best avg r: 0.6304
01:39:18,558 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:40:36,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:42:07,915 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2240
en_de Dev loss: 0.9006 r:0.1944
en_zh Dev loss: 0.8331 r:0.4310
ro_en Dev loss: 0.3692 r:0.8098
et_en Dev loss: 0.4700 r:0.6804
si_en Dev loss: 0.6667 r:0.5801
ne_en Dev loss: 0.5096 r:0.7280
ru_en Dev loss: 0.4997 r:0.7055
Current avg r:0.5899 Best avg r: 0.6304
01:46:01,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:47:19,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:48:50,929 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2202
en_de Dev loss: 0.9017 r:0.1946
en_zh Dev loss: 0.7760 r:0.4596
ro_en Dev loss: 0.3423 r:0.8176
et_en Dev loss: 0.4249 r:0.6881
si_en Dev loss: 0.7227 r:0.5778
ne_en Dev loss: 0.5421 r:0.7284
ru_en Dev loss: 0.4435 r:0.7344
Current avg r:0.6001 Best avg r: 0.6304
01:52:44,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:54:02,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:55:33,924 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2206
en_de Dev loss: 0.9268 r:0.1826
en_zh Dev loss: 0.8425 r:0.4295
ro_en Dev loss: 0.3885 r:0.8108
et_en Dev loss: 0.4822 r:0.6689
si_en Dev loss: 0.7213 r:0.5720
ne_en Dev loss: 0.6006 r:0.7223
ru_en Dev loss: 0.4994 r:0.7122
Current avg r:0.5855 Best avg r: 0.6304
01:59:28,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:00:47,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:02:19,285 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2159
en_de Dev loss: 0.9073 r:0.2007
en_zh Dev loss: 0.7800 r:0.4469
ro_en Dev loss: 0.3546 r:0.8134
et_en Dev loss: 0.4490 r:0.6737
si_en Dev loss: 0.7288 r:0.5752
ne_en Dev loss: 0.5237 r:0.7302
ru_en Dev loss: 0.4668 r:0.7280
Current avg r:0.5954 Best avg r: 0.6304
02:06:16,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:07:34,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:09:06,911 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2120
en_de Dev loss: 0.8842 r:0.2184
en_zh Dev loss: 0.7652 r:0.4655
ro_en Dev loss: 0.3359 r:0.8177
et_en Dev loss: 0.4527 r:0.6871
si_en Dev loss: 0.6984 r:0.5878
ne_en Dev loss: 0.5145 r:0.7397
ru_en Dev loss: 0.4302 r:0.7324
Current avg r:0.6070 Best avg r: 0.6304
02:13:03,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:14:21,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:15:53,800 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2116
en_de Dev loss: 0.8950 r:0.2124
en_zh Dev loss: 0.7848 r:0.4545
ro_en Dev loss: 0.3427 r:0.8162
et_en Dev loss: 0.4463 r:0.6750
si_en Dev loss: 0.6914 r:0.5826
ne_en Dev loss: 0.5024 r:0.7348
ru_en Dev loss: 0.4622 r:0.7227
Current avg r:0.5997 Best avg r: 0.6304
02:19:50,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:08,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:40,710 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2178
en_de Dev loss: 0.9013 r:0.2128
en_zh Dev loss: 0.8059 r:0.4630
ro_en Dev loss: 0.3476 r:0.8190
et_en Dev loss: 0.4854 r:0.6801
si_en Dev loss: 0.6754 r:0.5886
ne_en Dev loss: 0.4671 r:0.7334
ru_en Dev loss: 0.4453 r:0.7419
Current avg r:0.6056 Best avg r: 0.6304
02:26:38,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:27:57,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:29,86 root INFO Epoch 7 Global steps: 63600 Train loss: 0.1904
en_de Dev loss: 0.8914 r:0.1930
en_zh Dev loss: 0.8123 r:0.4236
ro_en Dev loss: 0.3720 r:0.8085
et_en Dev loss: 0.4359 r:0.6621
si_en Dev loss: 0.8291 r:0.5573
ne_en Dev loss: 0.6091 r:0.7283
ru_en Dev loss: 0.5363 r:0.6920
Current avg r:0.5807 Best avg r: 0.6304
02:33:23,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:34:42,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:13,569 root INFO Epoch 7 Global steps: 64200 Train loss: 0.1993
en_de Dev loss: 0.9278 r:0.2064
en_zh Dev loss: 0.7951 r:0.4671
ro_en Dev loss: 0.3882 r:0.8175
et_en Dev loss: 0.4611 r:0.6799
si_en Dev loss: 0.7692 r:0.5794
ne_en Dev loss: 0.5611 r:0.7309
ru_en Dev loss: 0.4876 r:0.7282
Current avg r:0.6013 Best avg r: 0.6304
02:40:08,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:41:26,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:42:58,37 root INFO Epoch 7 Global steps: 64800 Train loss: 0.1925
en_de Dev loss: 0.8998 r:0.1942
en_zh Dev loss: 0.7990 r:0.4442
ro_en Dev loss: 0.3562 r:0.8138
et_en Dev loss: 0.4498 r:0.6758
si_en Dev loss: 0.7638 r:0.5738
ne_en Dev loss: 0.5377 r:0.7306
ru_en Dev loss: 0.4455 r:0.7353
Current avg r:0.5954 Best avg r: 0.6304
02:46:52,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:48:11,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:49:42,635 root INFO Epoch 7 Global steps: 65400 Train loss: 0.1893
en_de Dev loss: 0.8836 r:0.1946
en_zh Dev loss: 0.8422 r:0.4255
ro_en Dev loss: 0.3636 r:0.8157
et_en Dev loss: 0.4363 r:0.6646
si_en Dev loss: 0.9298 r:0.5638
ne_en Dev loss: 0.7104 r:0.7261
ru_en Dev loss: 0.4626 r:0.7280
Current avg r:0.5883 Best avg r: 0.6304
02:53:37,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:54:55,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:56:27,170 root INFO Epoch 7 Global steps: 66000 Train loss: 0.1940
en_de Dev loss: 0.8811 r:0.1936
en_zh Dev loss: 0.8292 r:0.4389
ro_en Dev loss: 0.3710 r:0.8172
et_en Dev loss: 0.4553 r:0.6695
si_en Dev loss: 0.8242 r:0.5738
ne_en Dev loss: 0.5897 r:0.7309
ru_en Dev loss: 0.4739 r:0.7195
Current avg r:0.5919 Best avg r: 0.6304
03:00:21,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:01:40,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:12,307 root INFO Epoch 7 Global steps: 66600 Train loss: 0.1927
en_de Dev loss: 0.8898 r:0.2155
en_zh Dev loss: 0.7965 r:0.4434
ro_en Dev loss: 0.3433 r:0.8135
et_en Dev loss: 0.4580 r:0.6796
si_en Dev loss: 0.7094 r:0.5756
ne_en Dev loss: 0.4637 r:0.7334
ru_en Dev loss: 0.4366 r:0.7389
Current avg r:0.6000 Best avg r: 0.6304
03:07:08,545 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:08:27,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:09:59,211 root INFO Epoch 7 Global steps: 67200 Train loss: 0.1875
en_de Dev loss: 0.8907 r:0.2158
en_zh Dev loss: 0.8010 r:0.4408
ro_en Dev loss: 0.3623 r:0.8128
et_en Dev loss: 0.4607 r:0.6732
si_en Dev loss: 0.7762 r:0.5747
ne_en Dev loss: 0.5277 r:0.7255
ru_en Dev loss: 0.4668 r:0.7323
Current avg r:0.5964 Best avg r: 0.6304
03:13:55,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:15:14,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:46,192 root INFO Epoch 7 Global steps: 67800 Train loss: 0.1885
en_de Dev loss: 0.9252 r:0.2123
en_zh Dev loss: 0.8435 r:0.4303
ro_en Dev loss: 0.3802 r:0.8125
et_en Dev loss: 0.4601 r:0.6719
si_en Dev loss: 0.8699 r:0.5680
ne_en Dev loss: 0.6074 r:0.7248
ru_en Dev loss: 0.5068 r:0.7283
Current avg r:0.5926 Best avg r: 0.6304
03:20:42,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:22:01,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:33,436 root INFO Epoch 7 Global steps: 68400 Train loss: 0.1977
en_de Dev loss: 0.8960 r:0.1960
en_zh Dev loss: 0.8458 r:0.4117
ro_en Dev loss: 0.3571 r:0.8156
et_en Dev loss: 0.4662 r:0.6794
si_en Dev loss: 0.7264 r:0.5818
ne_en Dev loss: 0.4656 r:0.7294
ru_en Dev loss: 0.4457 r:0.7391
Current avg r:0.5933 Best avg r: 0.6304
03:27:29,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:47,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:18,965 root INFO Epoch 7 Global steps: 69000 Train loss: 0.1953
en_de Dev loss: 0.9154 r:0.1829
en_zh Dev loss: 0.7858 r:0.4450
ro_en Dev loss: 0.3388 r:0.8152
et_en Dev loss: 0.4411 r:0.6766
si_en Dev loss: 0.7473 r:0.5828
ne_en Dev loss: 0.5008 r:0.7319
ru_en Dev loss: 0.4450 r:0.7362
Current avg r:0.5958 Best avg r: 0.6304
03:34:13,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:32,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:37:03,784 root INFO Epoch 7 Global steps: 69600 Train loss: 0.1969
en_de Dev loss: 0.9044 r:0.1825
en_zh Dev loss: 0.8222 r:0.4313
ro_en Dev loss: 0.3537 r:0.8135
et_en Dev loss: 0.4596 r:0.6639
si_en Dev loss: 0.7831 r:0.5725
ne_en Dev loss: 0.5858 r:0.7176
ru_en Dev loss: 0.4955 r:0.7141
Current avg r:0.5851 Best avg r: 0.6304
03:40:58,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:42:16,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:43:48,277 root INFO Epoch 7 Global steps: 70200 Train loss: 0.1930
en_de Dev loss: 0.9246 r:0.2059
en_zh Dev loss: 0.8395 r:0.4542
ro_en Dev loss: 0.3955 r:0.8162
et_en Dev loss: 0.4502 r:0.6781
si_en Dev loss: 0.9031 r:0.5754
ne_en Dev loss: 0.6828 r:0.7235
ru_en Dev loss: 0.5058 r:0.7337
Current avg r:0.5982 Best avg r: 0.6304
03:47:42,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:49:01,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:50:32,821 root INFO Epoch 7 Global steps: 70800 Train loss: 0.1970
en_de Dev loss: 0.8942 r:0.2159
en_zh Dev loss: 0.7913 r:0.4525
ro_en Dev loss: 0.3456 r:0.8192
et_en Dev loss: 0.4641 r:0.6850
si_en Dev loss: 0.7167 r:0.5828
ne_en Dev loss: 0.5234 r:0.7247
ru_en Dev loss: 0.4406 r:0.7402
Current avg r:0.6029 Best avg r: 0.6304
03:54:27,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:55:45,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:57:17,182 root INFO Epoch 7 Global steps: 71400 Train loss: 0.1750
en_de Dev loss: 0.9063 r:0.2165
en_zh Dev loss: 0.8120 r:0.4519
ro_en Dev loss: 0.3712 r:0.8168
et_en Dev loss: 0.5031 r:0.6761
si_en Dev loss: 0.7036 r:0.5851
ne_en Dev loss: 0.5257 r:0.7207
ru_en Dev loss: 0.4781 r:0.7265
Current avg r:0.5991 Best avg r: 0.6304
04:01:13,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:02:32,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:04,142 root INFO Epoch 7 Global steps: 72000 Train loss: 0.1839
en_de Dev loss: 0.9233 r:0.1984
en_zh Dev loss: 0.8586 r:0.4346
ro_en Dev loss: 0.3756 r:0.8115
et_en Dev loss: 0.4772 r:0.6618
si_en Dev loss: 0.8841 r:0.5658
ne_en Dev loss: 0.6900 r:0.7181
ru_en Dev loss: 0.5202 r:0.7109
Current avg r:0.5859 Best avg r: 0.6304
04:08:02,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:09:20,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:10:52,878 root INFO Epoch 8 Global steps: 72600 Train loss: 0.1637
en_de Dev loss: 0.9094 r:0.2072
en_zh Dev loss: 0.8079 r:0.4491
ro_en Dev loss: 0.3527 r:0.8136
et_en Dev loss: 0.5014 r:0.6630
si_en Dev loss: 0.7287 r:0.5716
ne_en Dev loss: 0.5686 r:0.7189
ru_en Dev loss: 0.4518 r:0.7227
Current avg r:0.5923 Best avg r: 0.6304
04:14:49,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:16:08,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:17:39,903 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1647
en_de Dev loss: 0.8898 r:0.2018
en_zh Dev loss: 0.7975 r:0.4384
ro_en Dev loss: 0.3595 r:0.8154
et_en Dev loss: 0.4678 r:0.6715
si_en Dev loss: 0.7927 r:0.5704
ne_en Dev loss: 0.5935 r:0.7184
ru_en Dev loss: 0.4961 r:0.7094
Current avg r:0.5893 Best avg r: 0.6304
04:21:36,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:22:54,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:24:25,977 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1649
en_de Dev loss: 0.9554 r:0.1862
en_zh Dev loss: 0.8604 r:0.4436
ro_en Dev loss: 0.3893 r:0.8146
et_en Dev loss: 0.4959 r:0.6714
si_en Dev loss: 0.8152 r:0.5812
ne_en Dev loss: 0.6044 r:0.7204
ru_en Dev loss: 0.4881 r:0.7357
Current avg r:0.5933 Best avg r: 0.6304
04:28:20,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:38,926 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:10,398 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1698
en_de Dev loss: 0.9073 r:0.1824
en_zh Dev loss: 0.7790 r:0.4386
ro_en Dev loss: 0.3392 r:0.8159
et_en Dev loss: 0.4858 r:0.6813
si_en Dev loss: 0.6374 r:0.5915
ne_en Dev loss: 0.4878 r:0.7319
ru_en Dev loss: 0.4463 r:0.7276
Current avg r:0.5956 Best avg r: 0.6304
04:35:05,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:23,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:54,906 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1698
en_de Dev loss: 0.9024 r:0.1964
en_zh Dev loss: 0.7622 r:0.4452
ro_en Dev loss: 0.3240 r:0.8159
et_en Dev loss: 0.4498 r:0.6799
si_en Dev loss: 0.6589 r:0.5894
ne_en Dev loss: 0.5041 r:0.7143
ru_en Dev loss: 0.4123 r:0.7445
Current avg r:0.5979 Best avg r: 0.6304
04:41:49,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:07,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:39,475 root INFO Epoch 8 Global steps: 75600 Train loss: 0.1616
en_de Dev loss: 0.9410 r:0.1929
en_zh Dev loss: 0.7994 r:0.4609
ro_en Dev loss: 0.3567 r:0.8186
et_en Dev loss: 0.4955 r:0.6849
si_en Dev loss: 0.6551 r:0.5919
ne_en Dev loss: 0.4841 r:0.7219
ru_en Dev loss: 0.4434 r:0.7459
Current avg r:0.6024 Best avg r: 0.6304
04:48:34,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:49:52,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:23,946 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1713
en_de Dev loss: 0.9134 r:0.2035
en_zh Dev loss: 0.8087 r:0.4487
ro_en Dev loss: 0.3769 r:0.8114
et_en Dev loss: 0.4520 r:0.6642
si_en Dev loss: 0.7515 r:0.5749
ne_en Dev loss: 0.5598 r:0.7260
ru_en Dev loss: 0.5292 r:0.7047
Current avg r:0.5905 Best avg r: 0.6304
04:55:19,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:56:38,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:10,518 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1654
en_de Dev loss: 0.9081 r:0.1968
en_zh Dev loss: 0.7929 r:0.4498
ro_en Dev loss: 0.3620 r:0.8134
et_en Dev loss: 0.4586 r:0.6788
si_en Dev loss: 0.7185 r:0.5848
ne_en Dev loss: 0.5224 r:0.7307
ru_en Dev loss: 0.4729 r:0.7235
Current avg r:0.5968 Best avg r: 0.6304
05:02:07,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:25,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:04:57,773 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1737
en_de Dev loss: 0.9401 r:0.1723
en_zh Dev loss: 0.7818 r:0.4614
ro_en Dev loss: 0.3541 r:0.8170
et_en Dev loss: 0.4586 r:0.6754
si_en Dev loss: 0.7114 r:0.5810
ne_en Dev loss: 0.5452 r:0.7275
ru_en Dev loss: 0.4296 r:0.7376
Current avg r:0.5960 Best avg r: 0.6304
05:08:53,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:12,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:44,728 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1784
en_de Dev loss: 0.9020 r:0.1923
en_zh Dev loss: 0.7719 r:0.4480
ro_en Dev loss: 0.3440 r:0.8131
et_en Dev loss: 0.4689 r:0.6806
si_en Dev loss: 0.6697 r:0.5854
ne_en Dev loss: 0.5106 r:0.7220
ru_en Dev loss: 0.4213 r:0.7391
Current avg r:0.5972 Best avg r: 0.6304
05:15:41,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:16:59,597 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:31,162 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1580
en_de Dev loss: 0.9285 r:0.1840
en_zh Dev loss: 0.7819 r:0.4520
ro_en Dev loss: 0.3664 r:0.8146
et_en Dev loss: 0.4641 r:0.6723
si_en Dev loss: 0.7375 r:0.5809
ne_en Dev loss: 0.5868 r:0.7187
ru_en Dev loss: 0.4354 r:0.7425
Current avg r:0.5950 Best avg r: 0.6304
05:22:26,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:23:44,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:16,195 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1607
en_de Dev loss: 0.9288 r:0.1849
en_zh Dev loss: 0.8017 r:0.4442
ro_en Dev loss: 0.3494 r:0.8185
et_en Dev loss: 0.4693 r:0.6765
si_en Dev loss: 0.7108 r:0.5805
ne_en Dev loss: 0.5322 r:0.7191
ru_en Dev loss: 0.4459 r:0.7376
Current avg r:0.5945 Best avg r: 0.6304
05:29:11,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:29,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:32:01,202 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1650
en_de Dev loss: 0.9042 r:0.2023
en_zh Dev loss: 0.8314 r:0.4428
ro_en Dev loss: 0.3770 r:0.8160
et_en Dev loss: 0.4888 r:0.6766
si_en Dev loss: 0.7391 r:0.5783
ne_en Dev loss: 0.6083 r:0.7177
ru_en Dev loss: 0.4844 r:0.7226
Current avg r:0.5938 Best avg r: 0.6304
05:35:55,891 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:14,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:45,779 root INFO Epoch 8 Global steps: 80400 Train loss: 0.1665
en_de Dev loss: 0.9081 r:0.2009
en_zh Dev loss: 0.8473 r:0.4366
ro_en Dev loss: 0.3764 r:0.8178
et_en Dev loss: 0.4505 r:0.6766
si_en Dev loss: 0.8301 r:0.5762
ne_en Dev loss: 0.6743 r:0.7286
ru_en Dev loss: 0.4708 r:0.7329
Current avg r:0.5956 Best avg r: 0.6304
05:42:40,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:58,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:30,394 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1587
en_de Dev loss: 0.9145 r:0.1940
en_zh Dev loss: 0.7861 r:0.4530
ro_en Dev loss: 0.3471 r:0.8203
et_en Dev loss: 0.5320 r:0.6852
si_en Dev loss: 0.6430 r:0.5888
ne_en Dev loss: 0.4828 r:0.7250
ru_en Dev loss: 0.4015 r:0.7537
Current avg r:0.6029 Best avg r: 0.6304
05:49:26,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:50:45,727 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:52:17,635 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1497
en_de Dev loss: 0.9358 r:0.1827
en_zh Dev loss: 0.8765 r:0.4371
ro_en Dev loss: 0.3942 r:0.8139
et_en Dev loss: 0.4950 r:0.6648
si_en Dev loss: 0.7824 r:0.5736
ne_en Dev loss: 0.5663 r:0.7217
ru_en Dev loss: 0.4880 r:0.7318
Current avg r:0.5894 Best avg r: 0.6304
05:56:14,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:57:33,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:05,141 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1450
en_de Dev loss: 0.8927 r:0.2026
en_zh Dev loss: 0.7784 r:0.4420
ro_en Dev loss: 0.3446 r:0.8132
et_en Dev loss: 0.4876 r:0.6697
si_en Dev loss: 0.6735 r:0.5718
ne_en Dev loss: 0.5056 r:0.7193
ru_en Dev loss: 0.4231 r:0.7407
Current avg r:0.5942 Best avg r: 0.6304
06:03:01,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:20,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:52,207 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1476
en_de Dev loss: 0.8989 r:0.1914
en_zh Dev loss: 0.7771 r:0.4501
ro_en Dev loss: 0.3575 r:0.8142
et_en Dev loss: 0.4587 r:0.6702
si_en Dev loss: 0.7403 r:0.5799
ne_en Dev loss: 0.5676 r:0.7234
ru_en Dev loss: 0.4374 r:0.7437
Current avg r:0.5961 Best avg r: 0.6304
06:09:48,772 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:07,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:12:39,274 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1436
en_de Dev loss: 0.9059 r:0.1811
en_zh Dev loss: 0.8095 r:0.4365
ro_en Dev loss: 0.3580 r:0.8130
et_en Dev loss: 0.4851 r:0.6574
si_en Dev loss: 0.7205 r:0.5747
ne_en Dev loss: 0.5360 r:0.7221
ru_en Dev loss: 0.4527 r:0.7263
Current avg r:0.5873 Best avg r: 0.6304
06:16:33,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:52,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:19:23,842 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1496
en_de Dev loss: 0.9152 r:0.1774
en_zh Dev loss: 0.8278 r:0.4295
ro_en Dev loss: 0.3759 r:0.8136
et_en Dev loss: 0.4703 r:0.6614
si_en Dev loss: 0.7264 r:0.5792
ne_en Dev loss: 0.5384 r:0.7226
ru_en Dev loss: 0.4456 r:0.7397
Current avg r:0.5891 Best avg r: 0.6304
06:23:18,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:24:36,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:08,411 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1471
en_de Dev loss: 0.9309 r:0.1848
en_zh Dev loss: 0.7902 r:0.4472
ro_en Dev loss: 0.3525 r:0.8163
et_en Dev loss: 0.4893 r:0.6758
si_en Dev loss: 0.6545 r:0.5868
ne_en Dev loss: 0.4828 r:0.7188
ru_en Dev loss: 0.4182 r:0.7522
Current avg r:0.5974 Best avg r: 0.6304
06:30:03,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:31:21,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:53,386 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1433
en_de Dev loss: 0.9522 r:0.1807
en_zh Dev loss: 0.8176 r:0.4415
ro_en Dev loss: 0.3538 r:0.8162
et_en Dev loss: 0.4781 r:0.6818
si_en Dev loss: 0.6900 r:0.5871
ne_en Dev loss: 0.5301 r:0.7143
ru_en Dev loss: 0.4329 r:0.7497
Current avg r:0.5959 Best avg r: 0.6304
06:36:48,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:38:06,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:38,316 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1460
en_de Dev loss: 0.9263 r:0.1790
en_zh Dev loss: 0.8097 r:0.4301
ro_en Dev loss: 0.3480 r:0.8122
et_en Dev loss: 0.4527 r:0.6675
si_en Dev loss: 0.7177 r:0.5802
ne_en Dev loss: 0.5449 r:0.7177
ru_en Dev loss: 0.4411 r:0.7403
Current avg r:0.5896 Best avg r: 0.6304
06:43:33,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:44:51,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:23,948 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1467
en_de Dev loss: 0.9372 r:0.2003
en_zh Dev loss: 0.8036 r:0.4453
ro_en Dev loss: 0.3524 r:0.8118
et_en Dev loss: 0.4458 r:0.6752
si_en Dev loss: 0.7559 r:0.5837
ne_en Dev loss: 0.5726 r:0.7172
ru_en Dev loss: 0.4915 r:0.7353
Current avg r:0.5955 Best avg r: 0.6304
06:50:20,445 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:39,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:53:11,106 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1412
en_de Dev loss: 0.9310 r:0.1976
en_zh Dev loss: 0.8702 r:0.4205
ro_en Dev loss: 0.3708 r:0.8084
et_en Dev loss: 0.4566 r:0.6640
si_en Dev loss: 0.7994 r:0.5797
ne_en Dev loss: 0.6284 r:0.7093
ru_en Dev loss: 0.4783 r:0.7355
Current avg r:0.5878 Best avg r: 0.6304
06:57:07,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:58:26,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:59:58,439 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1523
en_de Dev loss: 0.9481 r:0.1916
en_zh Dev loss: 0.8381 r:0.4381
ro_en Dev loss: 0.3585 r:0.8141
et_en Dev loss: 0.4691 r:0.6750
si_en Dev loss: 0.7675 r:0.5803
ne_en Dev loss: 0.6145 r:0.7081
ru_en Dev loss: 0.4728 r:0.7438
Current avg r:0.5930 Best avg r: 0.6304
07:03:54,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:05:13,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:06:45,554 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1528
en_de Dev loss: 0.9274 r:0.1956
en_zh Dev loss: 0.8278 r:0.4423
ro_en Dev loss: 0.3627 r:0.8115
et_en Dev loss: 0.4874 r:0.6679
si_en Dev loss: 0.7106 r:0.5867
ne_en Dev loss: 0.5736 r:0.7136
ru_en Dev loss: 0.4649 r:0.7421
Current avg r:0.5942 Best avg r: 0.6304
07:10:40,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:11:59,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:13:30,578 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1398
en_de Dev loss: 0.9030 r:0.1985
en_zh Dev loss: 0.8061 r:0.4336
ro_en Dev loss: 0.3537 r:0.8109
et_en Dev loss: 0.4793 r:0.6597
si_en Dev loss: 0.7342 r:0.5739
ne_en Dev loss: 0.5685 r:0.7134
ru_en Dev loss: 0.4518 r:0.7326
Current avg r:0.5889 Best avg r: 0.6304
07:17:25,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:18:43,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:15,431 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1365
en_de Dev loss: 0.9232 r:0.2015
en_zh Dev loss: 0.8514 r:0.4369
ro_en Dev loss: 0.3925 r:0.8124
et_en Dev loss: 0.4827 r:0.6652
si_en Dev loss: 0.8048 r:0.5810
ne_en Dev loss: 0.6343 r:0.7166
ru_en Dev loss: 0.4710 r:0.7460
Current avg r:0.5942 Best avg r: 0.6304
07:24:09,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:28,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:59,781 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1403
en_de Dev loss: 0.9190 r:0.2119
en_zh Dev loss: 0.8324 r:0.4413
ro_en Dev loss: 0.3597 r:0.8193
et_en Dev loss: 0.5023 r:0.6821
si_en Dev loss: 0.6772 r:0.5952
ne_en Dev loss: 0.5294 r:0.7185
ru_en Dev loss: 0.4298 r:0.7596
Current avg r:0.6040 Best avg r: 0.6304
07:30:55,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:14,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:33:45,690 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1349
en_de Dev loss: 0.9201 r:0.2124
en_zh Dev loss: 0.8538 r:0.4379
ro_en Dev loss: 0.3768 r:0.8145
et_en Dev loss: 0.4777 r:0.6753
si_en Dev loss: 0.7759 r:0.5803
ne_en Dev loss: 0.6318 r:0.7128
ru_en Dev loss: 0.5032 r:0.7340
Current avg r:0.5953 Best avg r: 0.6304
07:37:40,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:58,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:40:30,149 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1206
en_de Dev loss: 0.9099 r:0.2094
en_zh Dev loss: 0.7791 r:0.4430
ro_en Dev loss: 0.3327 r:0.8163
et_en Dev loss: 0.4679 r:0.6803
si_en Dev loss: 0.6358 r:0.5867
ne_en Dev loss: 0.5092 r:0.7079
ru_en Dev loss: 0.4135 r:0.7511
Current avg r:0.5992 Best avg r: 0.6304
07:44:24,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:45:42,384 root INFO 
id:ru_en cur r: 0.7706 best r: 0.7706
07:45:42,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:47:13,753 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1288
en_de Dev loss: 0.8940 r:0.2137
en_zh Dev loss: 0.7749 r:0.4551
ro_en Dev loss: 0.3618 r:0.8126
et_en Dev loss: 0.4669 r:0.6783
si_en Dev loss: 0.6929 r:0.5824
ne_en Dev loss: 0.5608 r:0.7219
ru_en Dev loss: 0.4129 r:0.7599
Current avg r:0.6034 Best avg r: 0.6304
07:51:07,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:52:26,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:53:57,413 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1311
en_de Dev loss: 0.9088 r:0.2019
en_zh Dev loss: 0.7891 r:0.4430
ro_en Dev loss: 0.3602 r:0.8142
et_en Dev loss: 0.4632 r:0.6704
si_en Dev loss: 0.7105 r:0.5848
ne_en Dev loss: 0.6015 r:0.7168
ru_en Dev loss: 0.4267 r:0.7506
Current avg r:0.5974 Best avg r: 0.6304
07:57:51,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:59:09,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:00:41,142 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1286
en_de Dev loss: 0.9119 r:0.2081
en_zh Dev loss: 0.8124 r:0.4351
ro_en Dev loss: 0.3619 r:0.8125
et_en Dev loss: 0.4836 r:0.6710
si_en Dev loss: 0.6964 r:0.5837
ne_en Dev loss: 0.6145 r:0.7105
ru_en Dev loss: 0.4805 r:0.7300
Current avg r:0.5930 Best avg r: 0.6304
08:04:35,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:05:53,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:07:25,154 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1278
en_de Dev loss: 0.9353 r:0.2021
en_zh Dev loss: 0.8436 r:0.4452
ro_en Dev loss: 0.3551 r:0.8181
et_en Dev loss: 0.4826 r:0.6790
si_en Dev loss: 0.6564 r:0.5893
ne_en Dev loss: 0.5196 r:0.7096
ru_en Dev loss: 0.4376 r:0.7520
Current avg r:0.5993 Best avg r: 0.6304
08:11:19,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:12:37,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:14:08,984 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1245
en_de Dev loss: 0.9021 r:0.2061
en_zh Dev loss: 0.7757 r:0.4483
ro_en Dev loss: 0.3403 r:0.8157
et_en Dev loss: 0.4800 r:0.6818
si_en Dev loss: 0.6691 r:0.5826
ne_en Dev loss: 0.5231 r:0.7186
ru_en Dev loss: 0.3915 r:0.7588
Current avg r:0.6017 Best avg r: 0.6304
08:18:03,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:19:21,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:20:52,494 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1312
en_de Dev loss: 0.9170 r:0.1823
en_zh Dev loss: 0.7955 r:0.4405
ro_en Dev loss: 0.3475 r:0.8124
et_en Dev loss: 0.4534 r:0.6782
si_en Dev loss: 0.6675 r:0.5779
ne_en Dev loss: 0.5438 r:0.7062
ru_en Dev loss: 0.4259 r:0.7463
Current avg r:0.5920 Best avg r: 0.6304
08:24:46,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:04,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:27:36,200 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1240
en_de Dev loss: 0.9254 r:0.2058
en_zh Dev loss: 0.7835 r:0.4455
ro_en Dev loss: 0.3447 r:0.8128
et_en Dev loss: 0.4558 r:0.6747
si_en Dev loss: 0.6902 r:0.5793
ne_en Dev loss: 0.5873 r:0.7058
ru_en Dev loss: 0.4449 r:0.7448
Current avg r:0.5955 Best avg r: 0.6304
08:31:30,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:32:48,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:34:19,899 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1288
en_de Dev loss: 0.9468 r:0.1804
en_zh Dev loss: 0.8309 r:0.4319
ro_en Dev loss: 0.3697 r:0.8147
et_en Dev loss: 0.4683 r:0.6773
si_en Dev loss: 0.6595 r:0.5856
ne_en Dev loss: 0.5537 r:0.7007
ru_en Dev loss: 0.4488 r:0.7454
Current avg r:0.5909 Best avg r: 0.6304
08:38:13,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:39:32,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:03,361 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1272
en_de Dev loss: 0.9128 r:0.1968
en_zh Dev loss: 0.7682 r:0.4539
ro_en Dev loss: 0.3297 r:0.8163
et_en Dev loss: 0.4757 r:0.6813
si_en Dev loss: 0.6350 r:0.5917
ne_en Dev loss: 0.5210 r:0.7082
ru_en Dev loss: 0.3784 r:0.7620
Current avg r:0.6014 Best avg r: 0.6304
08:44:57,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:46:15,568 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:47:46,763 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1275
en_de Dev loss: 0.9234 r:0.1861
en_zh Dev loss: 0.8641 r:0.4345
ro_en Dev loss: 0.3869 r:0.8122
et_en Dev loss: 0.4880 r:0.6753
si_en Dev loss: 0.7361 r:0.5852
ne_en Dev loss: 0.5979 r:0.7055
ru_en Dev loss: 0.4581 r:0.7441
Current avg r:0.5919 Best avg r: 0.6304
08:51:40,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:52:58,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:30,104 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1215
en_de Dev loss: 0.9374 r:0.1851
en_zh Dev loss: 0.8300 r:0.4388
ro_en Dev loss: 0.3930 r:0.8113
et_en Dev loss: 0.4851 r:0.6763
si_en Dev loss: 0.7213 r:0.5833
ne_en Dev loss: 0.5437 r:0.7098
ru_en Dev loss: 0.4905 r:0.7358
Current avg r:0.5915 Best avg r: 0.6304
08:58:24,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:59:42,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:01:13,459 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1190
en_de Dev loss: 0.9425 r:0.1821
en_zh Dev loss: 0.8465 r:0.4428
ro_en Dev loss: 0.3773 r:0.8149
et_en Dev loss: 0.4962 r:0.6768
si_en Dev loss: 0.7393 r:0.5814
ne_en Dev loss: 0.5674 r:0.7082
ru_en Dev loss: 0.4646 r:0.7418
Current avg r:0.5926 Best avg r: 0.6304
09:05:07,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:06:25,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:07:56,722 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1317
en_de Dev loss: 0.9521 r:0.1760
en_zh Dev loss: 0.8220 r:0.4532
ro_en Dev loss: 0.3680 r:0.8169
et_en Dev loss: 0.4886 r:0.6745
si_en Dev loss: 0.7567 r:0.5810
ne_en Dev loss: 0.6376 r:0.6991
ru_en Dev loss: 0.4687 r:0.7382
Current avg r:0.5913 Best avg r: 0.6304
09:11:52,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:13:10,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:14:41,651 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1122
en_de Dev loss: 0.9276 r:0.1688
en_zh Dev loss: 0.7780 r:0.4560
ro_en Dev loss: 0.3566 r:0.8161
et_en Dev loss: 0.4466 r:0.6790
si_en Dev loss: 0.7478 r:0.5849
ne_en Dev loss: 0.5726 r:0.7091
ru_en Dev loss: 0.4507 r:0.7412
Current avg r:0.5936 Best avg r: 0.6304
09:18:35,865 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:19:54,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:21:25,392 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1133
en_de Dev loss: 0.9448 r:0.1674
en_zh Dev loss: 0.8364 r:0.4380
ro_en Dev loss: 0.3637 r:0.8144
et_en Dev loss: 0.4626 r:0.6761
si_en Dev loss: 0.7659 r:0.5777
ne_en Dev loss: 0.5924 r:0.7013
ru_en Dev loss: 0.4404 r:0.7477
Current avg r:0.5889 Best avg r: 0.6304
09:25:19,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:26:37,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:28:09,106 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1139
en_de Dev loss: 0.9359 r:0.1599
en_zh Dev loss: 0.7754 r:0.4555
ro_en Dev loss: 0.3459 r:0.8186
et_en Dev loss: 0.4513 r:0.6755
si_en Dev loss: 0.7541 r:0.5775
ne_en Dev loss: 0.5906 r:0.7098
ru_en Dev loss: 0.4187 r:0.7484
Current avg r:0.5922 Best avg r: 0.6304
09:32:03,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:33:21,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:34:52,549 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1162
en_de Dev loss: 0.9261 r:0.1809
en_zh Dev loss: 0.7840 r:0.4473
ro_en Dev loss: 0.3289 r:0.8187
et_en Dev loss: 0.4581 r:0.6770
si_en Dev loss: 0.6741 r:0.5823
ne_en Dev loss: 0.5386 r:0.7050
ru_en Dev loss: 0.4373 r:0.7406
Current avg r:0.5931 Best avg r: 0.6304
09:38:46,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:40:04,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:41:35,872 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1160
en_de Dev loss: 0.9501 r:0.1717
en_zh Dev loss: 0.8164 r:0.4413
ro_en Dev loss: 0.3609 r:0.8146
et_en Dev loss: 0.4711 r:0.6663
si_en Dev loss: 0.7724 r:0.5692
ne_en Dev loss: 0.6145 r:0.6971
ru_en Dev loss: 0.4731 r:0.7343
Current avg r:0.5849 Best avg r: 0.6304
09:45:29,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:46:48,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:48:19,385 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1121
en_de Dev loss: 0.9307 r:0.1778
en_zh Dev loss: 0.7668 r:0.4534
ro_en Dev loss: 0.3292 r:0.8199
et_en Dev loss: 0.4535 r:0.6800
si_en Dev loss: 0.7437 r:0.5821
ne_en Dev loss: 0.6182 r:0.7023
ru_en Dev loss: 0.4150 r:0.7506
Current avg r:0.5951 Best avg r: 0.6304
09:52:13,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:31,546 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:55:02,804 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1142
en_de Dev loss: 0.9590 r:0.1720
en_zh Dev loss: 0.8486 r:0.4340
ro_en Dev loss: 0.3847 r:0.8138
et_en Dev loss: 0.4606 r:0.6729
si_en Dev loss: 0.8331 r:0.5714
ne_en Dev loss: 0.6425 r:0.7058
ru_en Dev loss: 0.4869 r:0.7367
Current avg r:0.5867 Best avg r: 0.6304
09:58:56,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:00:15,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:01:46,461 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1141
en_de Dev loss: 0.9485 r:0.1669
en_zh Dev loss: 0.7832 r:0.4424
ro_en Dev loss: 0.3352 r:0.8174
et_en Dev loss: 0.4514 r:0.6818
si_en Dev loss: 0.6824 r:0.5760
ne_en Dev loss: 0.5306 r:0.6996
ru_en Dev loss: 0.3980 r:0.7573
Current avg r:0.5916 Best avg r: 0.6304
10:05:40,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:06:58,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:08:30,24 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1173
en_de Dev loss: 0.9349 r:0.1620
en_zh Dev loss: 0.8194 r:0.4239
ro_en Dev loss: 0.3484 r:0.8146
et_en Dev loss: 0.4788 r:0.6752
si_en Dev loss: 0.7172 r:0.5766
ne_en Dev loss: 0.5756 r:0.6965
ru_en Dev loss: 0.4160 r:0.7490
Current avg r:0.5854 Best avg r: 0.6304
10:12:24,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:42,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:13,727 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1114
en_de Dev loss: 0.9612 r:0.1710
en_zh Dev loss: 0.8031 r:0.4485
ro_en Dev loss: 0.3628 r:0.8113
et_en Dev loss: 0.4988 r:0.6631
si_en Dev loss: 0.7620 r:0.5649
ne_en Dev loss: 0.6578 r:0.7011
ru_en Dev loss: 0.4519 r:0.7400
Current avg r:0.5857 Best avg r: 0.6304
10:19:08,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:26,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:21:57,616 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1113
en_de Dev loss: 0.9397 r:0.1671
en_zh Dev loss: 0.7814 r:0.4560
ro_en Dev loss: 0.3456 r:0.8151
et_en Dev loss: 0.5049 r:0.6843
si_en Dev loss: 0.6422 r:0.5890
ne_en Dev loss: 0.5270 r:0.7140
ru_en Dev loss: 0.3998 r:0.7562
Current avg r:0.5974 Best avg r: 0.6304
10:25:51,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:10,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:28:41,525 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1175
en_de Dev loss: 0.9426 r:0.1709
en_zh Dev loss: 0.8408 r:0.4428
ro_en Dev loss: 0.3863 r:0.8123
et_en Dev loss: 0.4750 r:0.6655
si_en Dev loss: 0.8113 r:0.5733
ne_en Dev loss: 0.6624 r:0.7035
ru_en Dev loss: 0.4717 r:0.7399
Current avg r:0.5869 Best avg r: 0.6304
