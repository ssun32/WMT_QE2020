14:35:31,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:35:56,829 root INFO 
id:en_zh cur r: 0.2322 best r: 0.2322
14:36:09,712 root INFO 
id:ro_en cur r: 0.6012 best r: 0.6012
14:36:22,626 root INFO 
id:et_en cur r: 0.3980 best r: 0.3980
14:36:35,581 root INFO 
id:ne_en cur r: 0.5081 best r: 0.5081
14:36:48,452 root INFO 
id:ru_en cur r: 0.5719 best r: 0.5719
14:36:48,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:38:18,799 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
14:38:18,808 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:38:18,813 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:38:18,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
14:38:18,824 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
14:38:18,829 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:38:18,834 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:38:31,783 root INFO Epoch 0 Global steps: 600 Train loss: 0.8924
en_de Dev loss: 0.8888 r:0.1038
en_zh Dev loss: 0.8164 r:0.2625
ro_en Dev loss: 0.6521 r:0.5953
et_en Dev loss: 0.6562 r:0.4880
si_en Dev loss: 0.7183 r:0.4243
ne_en Dev loss: 0.6665 r:0.5079
ru_en Dev loss: 0.6824 r:0.5438
Current avg r:0.4179 Best avg r: 0.4179
14:42:32,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:42:58,585 root INFO 
id:en_zh cur r: 0.2323 best r: 0.2323
14:43:11,484 root INFO 
id:ro_en cur r: 0.6344 best r: 0.6344
14:43:24,391 root INFO 
id:et_en cur r: 0.4558 best r: 0.4558
14:43:50,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:45:20,290 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
14:45:20,296 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:45:20,301 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:45:20,306 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
14:45:20,312 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
14:45:20,317 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:45:20,322 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:45:33,234 root INFO Epoch 0 Global steps: 1200 Train loss: 0.7627
en_de Dev loss: 0.9077 r:0.0933
en_zh Dev loss: 0.7675 r:0.2573
ro_en Dev loss: 0.5794 r:0.6329
et_en Dev loss: 0.5518 r:0.5528
si_en Dev loss: 0.7412 r:0.4362
ne_en Dev loss: 0.6247 r:0.5169
ru_en Dev loss: 0.5569 r:0.6453
Current avg r:0.4478 Best avg r: 0.4478
14:49:24,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:37,658 root INFO 
id:en_de cur r: 0.1301 best r: 0.1301
14:49:50,518 root INFO 
id:en_zh cur r: 0.2513 best r: 0.2513
14:50:16,351 root INFO 
id:et_en cur r: 0.4715 best r: 0.4715
14:50:29,271 root INFO 
id:ne_en cur r: 0.5089 best r: 0.5089
14:50:42,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:12,463 root INFO Epoch 0 Global steps: 1800 Train loss: 0.7549
en_de Dev loss: 0.9741 r:0.1276
en_zh Dev loss: 0.8181 r:0.2699
ro_en Dev loss: 0.6528 r:0.6170
et_en Dev loss: 0.5605 r:0.5335
si_en Dev loss: 0.8586 r:0.4037
ne_en Dev loss: 0.6442 r:0.5132
ru_en Dev loss: 0.5944 r:0.6341
Current avg r:0.4427 Best avg r: 0.4478
14:56:13,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:39,605 root INFO 
id:en_zh cur r: 0.3100 best r: 0.3100
14:56:52,499 root INFO 
id:ro_en cur r: 0.6714 best r: 0.6714
14:57:05,407 root INFO 
id:et_en cur r: 0.5932 best r: 0.5932
14:57:18,310 root INFO 
id:ne_en cur r: 0.5875 best r: 0.5875
14:57:31,164 root INFO 
id:ru_en cur r: 0.6899 best r: 0.6899
14:57:31,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:01,299 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
14:59:01,306 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:59:01,311 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:59:01,316 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
14:59:01,321 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
14:59:01,326 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:59:01,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:59:14,247 root INFO Epoch 0 Global steps: 2400 Train loss: 0.7127
en_de Dev loss: 0.9496 r:0.1362
en_zh Dev loss: 0.7526 r:0.3290
ro_en Dev loss: 0.4843 r:0.6809
et_en Dev loss: 0.4587 r:0.6215
si_en Dev loss: 0.7446 r:0.4533
ne_en Dev loss: 0.5365 r:0.5879
ru_en Dev loss: 0.4371 r:0.7115
Current avg r:0.5029 Best avg r: 0.5029
15:03:05,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:18,552 root INFO 
id:en_de cur r: 0.1348 best r: 0.1348
15:03:31,406 root INFO 
id:en_zh cur r: 0.3540 best r: 0.3540
15:03:44,300 root INFO 
id:ro_en cur r: 0.7037 best r: 0.7037
15:03:57,200 root INFO 
id:et_en cur r: 0.6140 best r: 0.6140
15:04:10,103 root INFO 
id:ne_en cur r: 0.6085 best r: 0.6085
15:04:22,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:53,49 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
15:05:53,56 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:05:53,61 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:05:53,66 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
15:05:53,71 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
15:05:53,76 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:05:53,82 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:06:05,985 root INFO Epoch 0 Global steps: 3000 Train loss: 0.6534
en_de Dev loss: 0.9323 r:0.1570
en_zh Dev loss: 0.7703 r:0.3650
ro_en Dev loss: 0.4834 r:0.7046
et_en Dev loss: 0.4503 r:0.6354
si_en Dev loss: 0.8041 r:0.4660
ne_en Dev loss: 0.5898 r:0.5934
ru_en Dev loss: 0.4974 r:0.7065
Current avg r:0.5183 Best avg r: 0.5183
15:09:57,206 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:10,108 root INFO 
id:en_de cur r: 0.1414 best r: 0.1414
15:10:35,850 root INFO 
id:ro_en cur r: 0.7186 best r: 0.7186
15:11:01,661 root INFO 
id:ne_en cur r: 0.6108 best r: 0.6108
15:11:14,509 root INFO 
id:ru_en cur r: 0.6900 best r: 0.6900
15:11:14,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:44,607 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
15:12:44,613 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:12:44,618 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:12:44,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
15:12:44,631 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
15:12:44,636 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:12:44,643 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:12:57,541 root INFO Epoch 0 Global steps: 3600 Train loss: 0.6212
en_de Dev loss: 0.9280 r:0.1614
en_zh Dev loss: 0.8199 r:0.3475
ro_en Dev loss: 0.4206 r:0.7221
et_en Dev loss: 0.4289 r:0.6312
si_en Dev loss: 0.7852 r:0.4523
ne_en Dev loss: 0.4861 r:0.6298
ru_en Dev loss: 0.4553 r:0.7020
Current avg r:0.5209 Best avg r: 0.5209
15:16:48,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:01,603 root INFO 
id:en_de cur r: 0.1489 best r: 0.1489
15:17:14,470 root INFO 
id:en_zh cur r: 0.3790 best r: 0.3790
15:17:27,366 root INFO 
id:ro_en cur r: 0.7398 best r: 0.7398
15:17:40,260 root INFO 
id:et_en cur r: 0.6497 best r: 0.6497
15:17:53,155 root INFO 
id:ne_en cur r: 0.6550 best r: 0.6550
15:18:05,991 root INFO 
id:ru_en cur r: 0.7150 best r: 0.7150
15:18:05,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:36,139 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
15:19:36,145 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:19:36,150 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:19:36,156 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
15:19:36,161 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
15:19:36,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:19:36,172 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:19:49,76 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6045
en_de Dev loss: 0.9049 r:0.1630
en_zh Dev loss: 0.6990 r:0.3964
ro_en Dev loss: 0.3945 r:0.7450
et_en Dev loss: 0.3985 r:0.6639
si_en Dev loss: 0.7021 r:0.5011
ne_en Dev loss: 0.4674 r:0.6640
ru_en Dev loss: 0.4355 r:0.7274
Current avg r:0.5515 Best avg r: 0.5515
15:23:40,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:53,272 root INFO 
id:en_de cur r: 0.1655 best r: 0.1655
15:24:19,5 root INFO 
id:ro_en cur r: 0.7584 best r: 0.7584
15:24:31,904 root INFO 
id:et_en cur r: 0.6636 best r: 0.6636
15:24:57,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:27,764 root INFO Epoch 0 Global steps: 4800 Train loss: 0.6145
en_de Dev loss: 0.9339 r:0.1746
en_zh Dev loss: 0.7815 r:0.3890
ro_en Dev loss: 0.3853 r:0.7582
et_en Dev loss: 0.3919 r:0.6763
si_en Dev loss: 0.7921 r:0.4867
ne_en Dev loss: 0.5119 r:0.6511
ru_en Dev loss: 0.4760 r:0.7168
Current avg r:0.5504 Best avg r: 0.5515
15:30:19,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:32,402 root INFO 
id:en_de cur r: 0.1676 best r: 0.1676
15:30:45,265 root INFO 
id:en_zh cur r: 0.3822 best r: 0.3822
15:31:23,966 root INFO 
id:ne_en cur r: 0.6773 best r: 0.6773
15:31:36,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:07,236 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
15:33:07,243 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:33:07,247 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:33:07,252 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
15:33:07,258 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
15:33:07,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:33:07,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:33:20,167 root INFO Epoch 0 Global steps: 5400 Train loss: 0.5991
en_de Dev loss: 0.9330 r:0.1735
en_zh Dev loss: 0.7460 r:0.4014
ro_en Dev loss: 0.4394 r:0.7572
et_en Dev loss: 0.3871 r:0.6773
si_en Dev loss: 0.8201 r:0.4971
ne_en Dev loss: 0.5090 r:0.6684
ru_en Dev loss: 0.5844 r:0.7103
Current avg r:0.5550 Best avg r: 0.5550
15:37:16,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:54,917 root INFO 
id:ro_en cur r: 0.7724 best r: 0.7724
15:38:07,829 root INFO 
id:et_en cur r: 0.6857 best r: 0.6857
15:38:20,747 root INFO 
id:ne_en cur r: 0.6849 best r: 0.6849
15:38:33,625 root INFO 
id:ru_en cur r: 0.7182 best r: 0.7182
15:38:33,626 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:03,802 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
15:40:03,809 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:40:03,814 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:40:03,820 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
15:40:03,825 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
15:40:03,830 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:40:03,835 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:40:16,736 root INFO Epoch 0 Global steps: 6000 Train loss: 0.6124
en_de Dev loss: 0.8995 r:0.1724
en_zh Dev loss: 0.7090 r:0.4034
ro_en Dev loss: 0.3749 r:0.7741
et_en Dev loss: 0.3725 r:0.6942
si_en Dev loss: 0.6995 r:0.5136
ne_en Dev loss: 0.4404 r:0.6861
ru_en Dev loss: 0.4585 r:0.7254
Current avg r:0.5670 Best avg r: 0.5670
15:44:08,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:21,8 root INFO 
id:en_de cur r: 0.1783 best r: 0.1783
15:44:46,775 root INFO 
id:ro_en cur r: 0.7770 best r: 0.7770
15:45:12,585 root INFO 
id:ne_en cur r: 0.6948 best r: 0.6948
15:45:25,449 root INFO 
id:ru_en cur r: 0.7193 best r: 0.7193
15:45:25,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:55,639 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
15:46:55,646 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:46:55,652 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:46:55,657 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
15:46:55,662 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
15:46:55,667 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:46:55,672 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:47:08,591 root INFO Epoch 0 Global steps: 6600 Train loss: 0.5578
en_de Dev loss: 0.8981 r:0.1664
en_zh Dev loss: 0.7547 r:0.4072
ro_en Dev loss: 0.3720 r:0.7817
et_en Dev loss: 0.3693 r:0.6972
si_en Dev loss: 0.6715 r:0.5239
ne_en Dev loss: 0.4279 r:0.7024
ru_en Dev loss: 0.4532 r:0.7386
Current avg r:0.5739 Best avg r: 0.5739
15:51:00,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:13,520 root INFO 
id:en_de cur r: 0.1783 best r: 0.1783
15:51:39,382 root INFO 
id:ro_en cur r: 0.7801 best r: 0.7801
15:51:52,340 root INFO 
id:et_en cur r: 0.6880 best r: 0.6880
15:52:05,251 root INFO 
id:ne_en cur r: 0.6995 best r: 0.6995
15:52:18,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:48,242 root INFO Epoch 0 Global steps: 7200 Train loss: 0.5581
en_de Dev loss: 0.8753 r:0.1498
en_zh Dev loss: 0.7865 r:0.4063
ro_en Dev loss: 0.3719 r:0.7807
et_en Dev loss: 0.3699 r:0.6984
si_en Dev loss: 0.7103 r:0.5226
ne_en Dev loss: 0.4619 r:0.6941
ru_en Dev loss: 0.4908 r:0.7317
Current avg r:0.5691 Best avg r: 0.5739
15:57:39,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:05,222 root INFO 
id:en_zh cur r: 0.4103 best r: 0.4103
15:58:18,147 root INFO 
id:ro_en cur r: 0.7802 best r: 0.7802
15:58:43,972 root INFO 
id:ne_en cur r: 0.7056 best r: 0.7056
15:58:56,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:26,977 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
16:00:26,984 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:00:26,988 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:00:26,993 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
16:00:26,998 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
16:00:27,4 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:00:27,8 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:00:39,921 root INFO Epoch 0 Global steps: 7800 Train loss: 0.5440
en_de Dev loss: 0.8860 r:0.1937
en_zh Dev loss: 0.7616 r:0.4281
ro_en Dev loss: 0.4232 r:0.7813
et_en Dev loss: 0.4057 r:0.6901
si_en Dev loss: 0.7275 r:0.5341
ne_en Dev loss: 0.4453 r:0.7089
ru_en Dev loss: 0.5285 r:0.7322
Current avg r:0.5812 Best avg r: 0.5812
16:04:31,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:57,231 root INFO 
id:en_zh cur r: 0.4228 best r: 0.4228
16:05:10,126 root INFO 
id:ro_en cur r: 0.7871 best r: 0.7871
16:05:35,953 root INFO 
id:ne_en cur r: 0.7091 best r: 0.7091
16:05:48,790 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:18,962 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5629
en_de Dev loss: 0.9018 r:0.1930
en_zh Dev loss: 0.7547 r:0.4213
ro_en Dev loss: 0.4134 r:0.7833
et_en Dev loss: 0.4606 r:0.6792
si_en Dev loss: 0.7723 r:0.5244
ne_en Dev loss: 0.5210 r:0.7030
ru_en Dev loss: 0.5433 r:0.7198
Current avg r:0.5749 Best avg r: 0.5812
16:11:10,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:23,186 root INFO 
id:en_de cur r: 0.1892 best r: 0.1892
16:11:36,44 root INFO 
id:en_zh cur r: 0.4359 best r: 0.4359
16:11:48,935 root INFO 
id:ro_en cur r: 0.7986 best r: 0.7986
16:12:14,725 root INFO 
id:ne_en cur r: 0.7225 best r: 0.7225
16:12:27,568 root INFO 
id:ru_en cur r: 0.7368 best r: 0.7368
16:12:27,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:57,717 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
16:13:57,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:13:57,733 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:13:57,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
16:13:57,744 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
16:13:57,749 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:13:57,755 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:14:10,654 root INFO Epoch 0 Global steps: 9000 Train loss: 0.5296
en_de Dev loss: 0.8650 r:0.2170
en_zh Dev loss: 0.6958 r:0.4399
ro_en Dev loss: 0.3341 r:0.7908
et_en Dev loss: 0.3783 r:0.6954
si_en Dev loss: 0.6221 r:0.5531
ne_en Dev loss: 0.3888 r:0.7244
ru_en Dev loss: 0.4031 r:0.7424
Current avg r:0.5947 Best avg r: 0.5947
16:18:03,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:16,220 root INFO 
id:en_de cur r: 0.1908 best r: 0.1908
16:18:29,81 root INFO 
id:en_zh cur r: 0.4428 best r: 0.4428
16:18:41,970 root INFO 
id:ro_en cur r: 0.8017 best r: 0.8017
16:18:54,880 root INFO 
id:et_en cur r: 0.6915 best r: 0.6915
16:19:07,789 root INFO 
id:ne_en cur r: 0.7366 best r: 0.7366
16:19:20,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:50,774 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
16:20:50,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:20:50,795 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:20:50,800 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
16:20:50,805 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
16:20:50,810 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:20:50,816 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:21:03,721 root INFO Epoch 1 Global steps: 9600 Train loss: 0.4792
en_de Dev loss: 0.8754 r:0.2182
en_zh Dev loss: 0.7029 r:0.4448
ro_en Dev loss: 0.3494 r:0.7966
et_en Dev loss: 0.3812 r:0.6973
si_en Dev loss: 0.6120 r:0.5613
ne_en Dev loss: 0.3594 r:0.7400
ru_en Dev loss: 0.4225 r:0.7395
Current avg r:0.5997 Best avg r: 0.5997
16:24:55,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:12,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:42,594 root INFO Epoch 1 Global steps: 10200 Train loss: 0.5301
en_de Dev loss: 0.9024 r:0.2005
en_zh Dev loss: 0.8088 r:0.4319
ro_en Dev loss: 0.3763 r:0.7951
et_en Dev loss: 0.3699 r:0.6962
si_en Dev loss: 0.6941 r:0.5463
ne_en Dev loss: 0.3946 r:0.7310
ru_en Dev loss: 0.5231 r:0.7098
Current avg r:0.5873 Best avg r: 0.5997
16:31:34,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:46,932 root INFO 
id:en_de cur r: 0.1911 best r: 0.1911
16:32:25,582 root INFO 
id:et_en cur r: 0.6961 best r: 0.6961
16:32:51,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:21,469 root INFO Epoch 1 Global steps: 10800 Train loss: 0.5214
en_de Dev loss: 0.8988 r:0.1866
en_zh Dev loss: 0.8311 r:0.4296
ro_en Dev loss: 0.4186 r:0.7913
et_en Dev loss: 0.3862 r:0.7007
si_en Dev loss: 0.7400 r:0.5458
ne_en Dev loss: 0.4916 r:0.7270
ru_en Dev loss: 0.4997 r:0.7266
Current avg r:0.5868 Best avg r: 0.5997
16:38:12,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:25,715 root INFO 
id:en_de cur r: 0.2033 best r: 0.2033
16:38:38,588 root INFO 
id:en_zh cur r: 0.4439 best r: 0.4439
16:39:04,372 root INFO 
id:et_en cur r: 0.7015 best r: 0.7015
16:39:30,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:00,231 root INFO Epoch 1 Global steps: 11400 Train loss: 0.4888
en_de Dev loss: 0.8852 r:0.2152
en_zh Dev loss: 0.7198 r:0.4475
ro_en Dev loss: 0.3784 r:0.7941
et_en Dev loss: 0.3773 r:0.7052
si_en Dev loss: 0.6883 r:0.5507
ne_en Dev loss: 0.4490 r:0.7317
ru_en Dev loss: 0.4623 r:0.7340
Current avg r:0.5969 Best avg r: 0.5997
16:44:51,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:08,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:39,137 root INFO Epoch 1 Global steps: 12000 Train loss: 0.5238
en_de Dev loss: 0.8926 r:0.1915
en_zh Dev loss: 0.7715 r:0.4354
ro_en Dev loss: 0.4220 r:0.7888
et_en Dev loss: 0.4258 r:0.6925
si_en Dev loss: 0.7541 r:0.5492
ne_en Dev loss: 0.4969 r:0.7245
ru_en Dev loss: 0.5467 r:0.7123
Current avg r:0.5849 Best avg r: 0.5997
16:51:30,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:56,568 root INFO 
id:en_zh cur r: 0.4662 best r: 0.4662
16:52:09,468 root INFO 
id:ro_en cur r: 0.8069 best r: 0.8069
16:52:48,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:18,608 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
16:54:18,616 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:54:18,621 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:54:18,625 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
16:54:18,630 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
16:54:18,635 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:54:18,641 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:54:31,605 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5220
en_de Dev loss: 0.8569 r:0.1876
en_zh Dev loss: 0.6817 r:0.4657
ro_en Dev loss: 0.3217 r:0.8047
et_en Dev loss: 0.3574 r:0.7052
si_en Dev loss: 0.6132 r:0.5682
ne_en Dev loss: 0.3968 r:0.7423
ru_en Dev loss: 0.4125 r:0.7436
Current avg r:0.6025 Best avg r: 0.6025
16:58:23,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:15,121 root INFO 
id:et_en cur r: 0.7029 best r: 0.7029
16:59:28,94 root INFO 
id:ne_en cur r: 0.7397 best r: 0.7397
16:59:40,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:11,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
17:01:11,437 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:01:11,443 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:01:11,448 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
17:01:11,452 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
17:01:11,458 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:01:11,466 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:01:24,426 root INFO Epoch 1 Global steps: 13200 Train loss: 0.5011
en_de Dev loss: 0.8533 r:0.2007
en_zh Dev loss: 0.6779 r:0.4661
ro_en Dev loss: 0.3315 r:0.8025
et_en Dev loss: 0.3580 r:0.7078
si_en Dev loss: 0.6399 r:0.5656
ne_en Dev loss: 0.4231 r:0.7447
ru_en Dev loss: 0.4264 r:0.7429
Current avg r:0.6043 Best avg r: 0.6043
17:05:16,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:33,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:03,816 root INFO Epoch 1 Global steps: 13800 Train loss: 0.4939
en_de Dev loss: 0.8829 r:0.2096
en_zh Dev loss: 0.7862 r:0.4466
ro_en Dev loss: 0.4286 r:0.7877
et_en Dev loss: 0.3868 r:0.7013
si_en Dev loss: 0.7809 r:0.5488
ne_en Dev loss: 0.4835 r:0.7391
ru_en Dev loss: 0.5557 r:0.7184
Current avg r:0.5931 Best avg r: 0.6043
17:11:55,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:08,344 root INFO 
id:en_de cur r: 0.2045 best r: 0.2045
17:12:59,954 root INFO 
id:ne_en cur r: 0.7498 best r: 0.7498
17:13:12,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:43,332 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
17:14:43,339 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:14:43,346 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:14:43,351 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
17:14:43,356 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
17:14:43,362 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:14:43,368 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:14:56,334 root INFO Epoch 1 Global steps: 14400 Train loss: 0.5112
en_de Dev loss: 0.8561 r:0.2254
en_zh Dev loss: 0.7146 r:0.4558
ro_en Dev loss: 0.3493 r:0.7999
et_en Dev loss: 0.3690 r:0.7063
si_en Dev loss: 0.6385 r:0.5609
ne_en Dev loss: 0.3591 r:0.7534
ru_en Dev loss: 0.4141 r:0.7408
Current avg r:0.6061 Best avg r: 0.6061
17:18:48,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:13,908 root INFO 
id:en_zh cur r: 0.4818 best r: 0.4818
17:19:26,859 root INFO 
id:ro_en cur r: 0.8124 best r: 0.8124
17:19:39,828 root INFO 
id:et_en cur r: 0.7090 best r: 0.7090
17:19:52,805 root INFO 
id:ne_en cur r: 0.7561 best r: 0.7561
17:20:05,684 root INFO 
id:ru_en cur r: 0.7545 best r: 0.7545
17:20:05,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:36,183 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_de.lang_agnost_mlp.dev.best.scores
17:21:36,193 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:21:36,198 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:21:36,204 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/et_en.lang_agnost_mlp.dev.best.scores
17:21:36,209 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/si_en.lang_agnost_mlp.dev.best.scores
17:21:36,214 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:21:36,219 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_0shot_no_sien/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:21:49,178 root INFO Epoch 1 Global steps: 15000 Train loss: 0.4776
en_de Dev loss: 0.8500 r:0.2252
en_zh Dev loss: 0.6582 r:0.4785
ro_en Dev loss: 0.3449 r:0.8112
et_en Dev loss: 0.3477 r:0.7168
si_en Dev loss: 0.6045 r:0.5875
ne_en Dev loss: 0.4154 r:0.7587
ru_en Dev loss: 0.3822 r:0.7610
Current avg r:0.6198 Best avg r: 0.6198
17:25:40,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:53,883 root INFO 
id:en_de cur r: 0.2221 best r: 0.2221
17:26:58,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:29,16 root INFO Epoch 1 Global steps: 15600 Train loss: 0.4782
en_de Dev loss: 0.8834 r:0.2311
en_zh Dev loss: 0.7707 r:0.4622
ro_en Dev loss: 0.3799 r:0.8075
et_en Dev loss: 0.3921 r:0.7063
si_en Dev loss: 0.7068 r:0.5672
ne_en Dev loss: 0.4408 r:0.7497
ru_en Dev loss: 0.5086 r:0.7382
Current avg r:0.6089 Best avg r: 0.6198
17:32:20,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:33,738 root INFO 
id:en_de cur r: 0.2282 best r: 0.2282
17:33:38,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:08,870 root INFO Epoch 1 Global steps: 16200 Train loss: 0.5175
en_de Dev loss: 0.8618 r:0.2195
en_zh Dev loss: 0.7351 r:0.4527
ro_en Dev loss: 0.3406 r:0.8066
et_en Dev loss: 0.3682 r:0.7047
si_en Dev loss: 0.6555 r:0.5729
ne_en Dev loss: 0.4649 r:0.7523
ru_en Dev loss: 0.4441 r:0.7409
Current avg r:0.6071 Best avg r: 0.6198
17:39:00,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:39,458 root INFO 
id:ro_en cur r: 0.8141 best r: 0.8141
17:40:18,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:48,752 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4716
en_de Dev loss: 0.8603 r:0.2102
en_zh Dev loss: 0.7183 r:0.4479
ro_en Dev loss: 0.3365 r:0.8137
et_en Dev loss: 0.3867 r:0.7017
si_en Dev loss: 0.6104 r:0.5848
ne_en Dev loss: 0.3888 r:0.7442
ru_en Dev loss: 0.4009 r:0.7508
Current avg r:0.6076 Best avg r: 0.6198
17:45:40,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:58,60 root INFO 
id:ru_en cur r: 0.7555 best r: 0.7555
17:46:58,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:28,567 root INFO Epoch 1 Global steps: 17400 Train loss: 0.4583
en_de Dev loss: 0.8652 r:0.2118
en_zh Dev loss: 0.7877 r:0.4536
ro_en Dev loss: 0.3863 r:0.8126
et_en Dev loss: 0.4038 r:0.6993
si_en Dev loss: 0.6468 r:0.5825
ne_en Dev loss: 0.3881 r:0.7473
ru_en Dev loss: 0.4211 r:0.7506
Current avg r:0.6083 Best avg r: 0.6198
17:52:20,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:37,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:08,384 root INFO Epoch 1 Global steps: 18000 Train loss: 0.5073
en_de Dev loss: 0.8726 r:0.2172
en_zh Dev loss: 0.7289 r:0.4609
ro_en Dev loss: 0.3535 r:0.8131
et_en Dev loss: 0.3834 r:0.6986
si_en Dev loss: 0.6024 r:0.5855
ne_en Dev loss: 0.4051 r:0.7469
ru_en Dev loss: 0.3992 r:0.7541
Current avg r:0.6109 Best avg r: 0.6198
17:59:01,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:18,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:49,146 root INFO Epoch 2 Global steps: 18600 Train loss: 0.4938
en_de Dev loss: 0.8491 r:0.2135
en_zh Dev loss: 0.7641 r:0.4489
ro_en Dev loss: 0.3642 r:0.8098
et_en Dev loss: 0.3998 r:0.6906
si_en Dev loss: 0.6827 r:0.5713
ne_en Dev loss: 0.5371 r:0.7381
ru_en Dev loss: 0.5139 r:0.7197
Current avg r:0.5988 Best avg r: 0.6198
18:05:40,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:19,654 root INFO 
id:ro_en cur r: 0.8172 best r: 0.8172
18:06:58,439 root INFO 
id:ru_en cur r: 0.7620 best r: 0.7620
18:06:58,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:28,942 root INFO Epoch 2 Global steps: 19200 Train loss: 0.4418
en_de Dev loss: 0.8527 r:0.2104
en_zh Dev loss: 0.6779 r:0.4774
ro_en Dev loss: 0.3104 r:0.8183
et_en Dev loss: 0.3838 r:0.6965
si_en Dev loss: 0.5888 r:0.5811
ne_en Dev loss: 0.3685 r:0.7496
ru_en Dev loss: 0.3648 r:0.7642
Current avg r:0.6140 Best avg r: 0.6198
18:12:20,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:33,528 root INFO 
id:en_de cur r: 0.2424 best r: 0.2424
18:13:38,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:08,631 root INFO Epoch 2 Global steps: 19800 Train loss: 0.4482
en_de Dev loss: 0.8517 r:0.2335
en_zh Dev loss: 0.6748 r:0.4701
ro_en Dev loss: 0.3135 r:0.8130
et_en Dev loss: 0.3689 r:0.7013
si_en Dev loss: 0.5977 r:0.5708
ne_en Dev loss: 0.4230 r:0.7546
ru_en Dev loss: 0.4131 r:0.7383
Current avg r:0.6116 Best avg r: 0.6198
18:19:00,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:13,222 root INFO 
id:en_de cur r: 0.2478 best r: 0.2478
18:19:39,85 root INFO 
id:ro_en cur r: 0.8175 best r: 0.8175
18:20:17,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:48,344 root INFO Epoch 2 Global steps: 20400 Train loss: 0.4373
en_de Dev loss: 0.8414 r:0.2445
en_zh Dev loss: 0.7427 r:0.4683
ro_en Dev loss: 0.3511 r:0.8168
et_en Dev loss: 0.3793 r:0.7033
si_en Dev loss: 0.5961 r:0.5851
ne_en Dev loss: 0.4236 r:0.7553
ru_en Dev loss: 0.4428 r:0.7436
Current avg r:0.6167 Best avg r: 0.6198
18:25:40,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:57,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:28,127 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4604
en_de Dev loss: 0.8697 r:0.2134
en_zh Dev loss: 0.7899 r:0.4393
ro_en Dev loss: 0.3994 r:0.8059
et_en Dev loss: 0.3876 r:0.6930
si_en Dev loss: 0.7148 r:0.5565
ne_en Dev loss: 0.5572 r:0.7434
ru_en Dev loss: 0.5374 r:0.7089
Current avg r:0.5943 Best avg r: 0.6198
18:32:19,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:58,394 root INFO 
id:ro_en cur r: 0.8195 best r: 0.8195
18:33:37,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:07,657 root INFO Epoch 2 Global steps: 21600 Train loss: 0.4683
en_de Dev loss: 0.8563 r:0.2147
en_zh Dev loss: 0.7332 r:0.4476
ro_en Dev loss: 0.3370 r:0.8182
et_en Dev loss: 0.3811 r:0.6907
si_en Dev loss: 0.6048 r:0.5774
ne_en Dev loss: 0.4391 r:0.7497
ru_en Dev loss: 0.4600 r:0.7242
Current avg r:0.6032 Best avg r: 0.6198
18:38:59,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:16,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:46,974 root INFO Epoch 2 Global steps: 22200 Train loss: 0.4337
en_de Dev loss: 0.8612 r:0.2261
en_zh Dev loss: 0.7427 r:0.4531
ro_en Dev loss: 0.3368 r:0.8101
et_en Dev loss: 0.4049 r:0.6825
si_en Dev loss: 0.6674 r:0.5675
ne_en Dev loss: 0.4746 r:0.7448
ru_en Dev loss: 0.5036 r:0.7233
Current avg r:0.6011 Best avg r: 0.6198
18:45:38,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:56,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:26,682 root INFO Epoch 2 Global steps: 22800 Train loss: 0.4289
en_de Dev loss: 0.8709 r:0.2231
en_zh Dev loss: 0.7417 r:0.4424
ro_en Dev loss: 0.3269 r:0.8169
et_en Dev loss: 0.3680 r:0.7015
si_en Dev loss: 0.6301 r:0.5774
ne_en Dev loss: 0.4681 r:0.7512
ru_en Dev loss: 0.4888 r:0.7300
Current avg r:0.6061 Best avg r: 0.6198
18:52:18,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:31,318 root INFO 
id:en_de cur r: 0.2517 best r: 0.2517
18:52:57,186 root INFO 
id:ro_en cur r: 0.8218 best r: 0.8218
18:53:35,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:06,462 root INFO Epoch 2 Global steps: 23400 Train loss: 0.4528
en_de Dev loss: 0.8335 r:0.2472
en_zh Dev loss: 0.7284 r:0.4542
ro_en Dev loss: 0.3201 r:0.8221
et_en Dev loss: 0.3877 r:0.7024
si_en Dev loss: 0.5895 r:0.5899
ne_en Dev loss: 0.3838 r:0.7535
ru_en Dev loss: 0.4712 r:0.7339
Current avg r:0.6147 Best avg r: 0.6198
18:58:58,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:00:15,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:46,174 root INFO Epoch 2 Global steps: 24000 Train loss: 0.4283
en_de Dev loss: 0.8807 r:0.2282
en_zh Dev loss: 0.7778 r:0.4453
ro_en Dev loss: 0.3577 r:0.8180
et_en Dev loss: 0.3987 r:0.6967
si_en Dev loss: 0.6344 r:0.5872
ne_en Dev loss: 0.4569 r:0.7546
ru_en Dev loss: 0.5297 r:0.7213
Current avg r:0.6073 Best avg r: 0.6198
19:05:38,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:56,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:26,966 root INFO Epoch 2 Global steps: 24600 Train loss: 0.3910
en_de Dev loss: 0.8552 r:0.2193
en_zh Dev loss: 0.7601 r:0.4265
ro_en Dev loss: 0.3345 r:0.8136
et_en Dev loss: 0.3936 r:0.6912
si_en Dev loss: 0.5966 r:0.5792
ne_en Dev loss: 0.4223 r:0.7539
ru_en Dev loss: 0.4337 r:0.7297
Current avg r:0.6019 Best avg r: 0.6198
19:12:29,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:47,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:18,504 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4446
en_de Dev loss: 0.8384 r:0.2440
en_zh Dev loss: 0.7249 r:0.4533
ro_en Dev loss: 0.3485 r:0.8146
et_en Dev loss: 0.3876 r:0.6999
si_en Dev loss: 0.6168 r:0.5809
ne_en Dev loss: 0.4901 r:0.7530
ru_en Dev loss: 0.4544 r:0.7375
Current avg r:0.6119 Best avg r: 0.6198
19:19:10,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:23,740 root INFO 
id:en_de cur r: 0.2520 best r: 0.2520
19:19:49,609 root INFO 
id:ro_en cur r: 0.8254 best r: 0.8254
19:20:02,565 root INFO 
id:et_en cur r: 0.7140 best r: 0.7140
19:20:28,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:58,855 root INFO Epoch 2 Global steps: 25800 Train loss: 0.4395
en_de Dev loss: 0.8614 r:0.2462
en_zh Dev loss: 0.7314 r:0.4552
ro_en Dev loss: 0.3276 r:0.8226
et_en Dev loss: 0.3753 r:0.7126
si_en Dev loss: 0.5865 r:0.5914
ne_en Dev loss: 0.4529 r:0.7527
ru_en Dev loss: 0.4686 r:0.7369
Current avg r:0.6168 Best avg r: 0.6198
19:25:59,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:17,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:47,742 root INFO Epoch 2 Global steps: 26400 Train loss: 0.4286
en_de Dev loss: 0.8539 r:0.2226
en_zh Dev loss: 0.7777 r:0.4367
ro_en Dev loss: 0.3370 r:0.8185
et_en Dev loss: 0.4133 r:0.6928
si_en Dev loss: 0.6534 r:0.5717
ne_en Dev loss: 0.5483 r:0.7547
ru_en Dev loss: 0.4624 r:0.7309
Current avg r:0.6040 Best avg r: 0.6198
19:32:40,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:58,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:29,228 root INFO Epoch 2 Global steps: 27000 Train loss: 0.4434
en_de Dev loss: 0.8569 r:0.2254
en_zh Dev loss: 0.7347 r:0.4520
ro_en Dev loss: 0.3436 r:0.8225
et_en Dev loss: 0.3752 r:0.7007
si_en Dev loss: 0.6189 r:0.5852
ne_en Dev loss: 0.5228 r:0.7512
ru_en Dev loss: 0.4241 r:0.7507
Current avg r:0.6125 Best avg r: 0.6198
19:39:22,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:39,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:10,181 root INFO Epoch 3 Global steps: 27600 Train loss: 0.4026
en_de Dev loss: 0.8446 r:0.2223
en_zh Dev loss: 0.7157 r:0.4510
ro_en Dev loss: 0.2968 r:0.8187
et_en Dev loss: 0.3972 r:0.6954
si_en Dev loss: 0.5641 r:0.5897
ne_en Dev loss: 0.4058 r:0.7491
ru_en Dev loss: 0.4171 r:0.7371
Current avg r:0.6090 Best avg r: 0.6198
19:46:02,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:19,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:50,125 root INFO Epoch 3 Global steps: 28200 Train loss: 0.3809
en_de Dev loss: 0.8873 r:0.2266
en_zh Dev loss: 0.8727 r:0.4327
ro_en Dev loss: 0.3860 r:0.8123
et_en Dev loss: 0.4259 r:0.6904
si_en Dev loss: 0.6866 r:0.5717
ne_en Dev loss: 0.4937 r:0.7455
ru_en Dev loss: 0.5150 r:0.7274
Current avg r:0.6009 Best avg r: 0.6198
19:52:41,832 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:59,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:29,981 root INFO Epoch 3 Global steps: 28800 Train loss: 0.4077
en_de Dev loss: 0.8642 r:0.2084
en_zh Dev loss: 0.7511 r:0.4347
ro_en Dev loss: 0.3457 r:0.8141
et_en Dev loss: 0.3969 r:0.6885
si_en Dev loss: 0.6316 r:0.5677
ne_en Dev loss: 0.4168 r:0.7524
ru_en Dev loss: 0.4180 r:0.7406
Current avg r:0.6009 Best avg r: 0.6198
19:59:21,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:39,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:09,933 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4082
en_de Dev loss: 0.8441 r:0.2328
en_zh Dev loss: 0.7371 r:0.4485
ro_en Dev loss: 0.3736 r:0.8078
et_en Dev loss: 0.4137 r:0.6866
si_en Dev loss: 0.6326 r:0.5715
ne_en Dev loss: 0.4340 r:0.7508
ru_en Dev loss: 0.4542 r:0.7285
Current avg r:0.6038 Best avg r: 0.6198
20:06:03,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:16,294 root INFO 
id:en_de cur r: 0.2525 best r: 0.2525
20:07:20,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:51,468 root INFO Epoch 3 Global steps: 30000 Train loss: 0.3925
en_de Dev loss: 0.8572 r:0.2335
en_zh Dev loss: 0.7379 r:0.4399
ro_en Dev loss: 0.3362 r:0.8115
et_en Dev loss: 0.3997 r:0.6885
si_en Dev loss: 0.6312 r:0.5711
ne_en Dev loss: 0.5383 r:0.7505
ru_en Dev loss: 0.4473 r:0.7245
Current avg r:0.6028 Best avg r: 0.6198
20:12:43,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:56,220 root INFO 
id:en_de cur r: 0.2544 best r: 0.2544
20:14:00,926 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:31,462 root INFO Epoch 3 Global steps: 30600 Train loss: 0.3625
en_de Dev loss: 0.8630 r:0.2201
en_zh Dev loss: 0.8210 r:0.4087
ro_en Dev loss: 0.3717 r:0.8054
et_en Dev loss: 0.4178 r:0.6828
si_en Dev loss: 0.6694 r:0.5644
ne_en Dev loss: 0.5199 r:0.7452
ru_en Dev loss: 0.4784 r:0.7152
Current avg r:0.5917 Best avg r: 0.6198
20:19:23,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:40,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:11,293 root INFO Epoch 3 Global steps: 31200 Train loss: 0.3745
en_de Dev loss: 0.8492 r:0.2289
en_zh Dev loss: 0.7612 r:0.4332
ro_en Dev loss: 0.3503 r:0.8140
et_en Dev loss: 0.4242 r:0.6828
si_en Dev loss: 0.5997 r:0.5806
ne_en Dev loss: 0.3925 r:0.7519
ru_en Dev loss: 0.4719 r:0.7215
Current avg r:0.6018 Best avg r: 0.6198
20:26:03,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:20,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:28:51,258 root INFO Epoch 3 Global steps: 31800 Train loss: 0.3871
en_de Dev loss: 0.8631 r:0.2021
en_zh Dev loss: 0.8315 r:0.4282
ro_en Dev loss: 0.3924 r:0.8126
et_en Dev loss: 0.4115 r:0.6883
si_en Dev loss: 0.6454 r:0.5776
ne_en Dev loss: 0.5252 r:0.7461
ru_en Dev loss: 0.5510 r:0.7021
Current avg r:0.5939 Best avg r: 0.6198
20:32:43,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:00,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:31,428 root INFO Epoch 3 Global steps: 32400 Train loss: 0.4080
en_de Dev loss: 0.8467 r:0.2140
en_zh Dev loss: 0.7145 r:0.4428
ro_en Dev loss: 0.3255 r:0.8138
et_en Dev loss: 0.3906 r:0.6888
si_en Dev loss: 0.5661 r:0.5803
ne_en Dev loss: 0.4174 r:0.7475
ru_en Dev loss: 0.4317 r:0.7177
Current avg r:0.6007 Best avg r: 0.6198
20:39:23,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:41,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:11,560 root INFO Epoch 3 Global steps: 33000 Train loss: 0.4007
en_de Dev loss: 0.8472 r:0.2298
en_zh Dev loss: 0.7363 r:0.4462
ro_en Dev loss: 0.3346 r:0.8177
et_en Dev loss: 0.4076 r:0.6949
si_en Dev loss: 0.5538 r:0.5916
ne_en Dev loss: 0.3948 r:0.7500
ru_en Dev loss: 0.3917 r:0.7515
Current avg r:0.6117 Best avg r: 0.6198
20:46:03,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:21,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:51,720 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3843
en_de Dev loss: 0.8450 r:0.2296
en_zh Dev loss: 0.7725 r:0.4417
ro_en Dev loss: 0.3468 r:0.8203
et_en Dev loss: 0.3997 r:0.7062
si_en Dev loss: 0.5703 r:0.5953
ne_en Dev loss: 0.4534 r:0.7476
ru_en Dev loss: 0.4344 r:0.7411
Current avg r:0.6117 Best avg r: 0.6198
20:52:43,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:01,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:31,501 root INFO Epoch 3 Global steps: 34200 Train loss: 0.3728
en_de Dev loss: 0.8756 r:0.1969
en_zh Dev loss: 0.8123 r:0.4409
ro_en Dev loss: 0.4105 r:0.8177
et_en Dev loss: 0.4150 r:0.6990
si_en Dev loss: 0.6353 r:0.5897
ne_en Dev loss: 0.5500 r:0.7480
ru_en Dev loss: 0.4844 r:0.7334
Current avg r:0.6037 Best avg r: 0.6198
20:59:23,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:40,749 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:11,246 root INFO Epoch 3 Global steps: 34800 Train loss: 0.3735
en_de Dev loss: 0.8513 r:0.2023
en_zh Dev loss: 0.6899 r:0.4618
ro_en Dev loss: 0.3194 r:0.8166
et_en Dev loss: 0.4149 r:0.6899
si_en Dev loss: 0.5662 r:0.5861
ne_en Dev loss: 0.4152 r:0.7509
ru_en Dev loss: 0.3911 r:0.7471
Current avg r:0.6078 Best avg r: 0.6198
21:06:02,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:20,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:51,44 root INFO Epoch 3 Global steps: 35400 Train loss: 0.3831
en_de Dev loss: 0.8603 r:0.2187
en_zh Dev loss: 0.7655 r:0.4361
ro_en Dev loss: 0.3444 r:0.8186
et_en Dev loss: 0.4039 r:0.6938
si_en Dev loss: 0.6172 r:0.5842
ne_en Dev loss: 0.4161 r:0.7468
ru_en Dev loss: 0.4877 r:0.7250
Current avg r:0.6033 Best avg r: 0.6198
21:12:42,781 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:00,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:30,903 root INFO Epoch 3 Global steps: 36000 Train loss: 0.3844
en_de Dev loss: 0.8766 r:0.2170
en_zh Dev loss: 0.8205 r:0.4284
ro_en Dev loss: 0.3948 r:0.8139
et_en Dev loss: 0.4228 r:0.6819
si_en Dev loss: 0.6705 r:0.5833
ne_en Dev loss: 0.4985 r:0.7386
ru_en Dev loss: 0.5394 r:0.7131
Current avg r:0.5966 Best avg r: 0.6198
21:19:34,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:52,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:22,764 root INFO Epoch 4 Global steps: 36600 Train loss: 0.3322
en_de Dev loss: 0.8895 r:0.2015
en_zh Dev loss: 0.8394 r:0.4186
ro_en Dev loss: 0.4003 r:0.8116
et_en Dev loss: 0.4582 r:0.6643
si_en Dev loss: 0.7514 r:0.5600
ne_en Dev loss: 0.5731 r:0.7456
ru_en Dev loss: 0.5218 r:0.7164
Current avg r:0.5883 Best avg r: 0.6198
21:26:14,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:32,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:02,549 root INFO Epoch 4 Global steps: 37200 Train loss: 0.3582
en_de Dev loss: 0.8515 r:0.2105
en_zh Dev loss: 0.7579 r:0.4432
ro_en Dev loss: 0.3618 r:0.8111
et_en Dev loss: 0.4217 r:0.6764
si_en Dev loss: 0.6127 r:0.5734
ne_en Dev loss: 0.4587 r:0.7469
ru_en Dev loss: 0.4272 r:0.7374
Current avg r:0.5998 Best avg r: 0.6198
21:32:54,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:11,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:42,391 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3321
en_de Dev loss: 0.9029 r:0.1897
en_zh Dev loss: 0.8522 r:0.4143
ro_en Dev loss: 0.3800 r:0.8105
et_en Dev loss: 0.4478 r:0.6681
si_en Dev loss: 0.7014 r:0.5607
ne_en Dev loss: 0.5344 r:0.7460
ru_en Dev loss: 0.5362 r:0.7122
Current avg r:0.5859 Best avg r: 0.6198
21:39:34,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:52,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:22,605 root INFO Epoch 4 Global steps: 38400 Train loss: 0.3341
en_de Dev loss: 0.8578 r:0.2020
en_zh Dev loss: 0.7803 r:0.4343
ro_en Dev loss: 0.3476 r:0.8125
et_en Dev loss: 0.4344 r:0.6692
si_en Dev loss: 0.6536 r:0.5684
ne_en Dev loss: 0.5050 r:0.7426
ru_en Dev loss: 0.4655 r:0.7247
Current avg r:0.5934 Best avg r: 0.6198
21:46:14,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:32,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:02,900 root INFO Epoch 4 Global steps: 39000 Train loss: 0.3416
en_de Dev loss: 0.8479 r:0.2289
en_zh Dev loss: 0.7672 r:0.4504
ro_en Dev loss: 0.3580 r:0.8129
et_en Dev loss: 0.4270 r:0.6703
si_en Dev loss: 0.6113 r:0.5837
ne_en Dev loss: 0.4371 r:0.7473
ru_en Dev loss: 0.4852 r:0.7236
Current avg r:0.6025 Best avg r: 0.6198
21:52:54,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:12,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:55:42,710 root INFO Epoch 4 Global steps: 39600 Train loss: 0.3318
en_de Dev loss: 0.8617 r:0.2060
en_zh Dev loss: 0.8174 r:0.4401
ro_en Dev loss: 0.3647 r:0.8243
et_en Dev loss: 0.4672 r:0.6831
si_en Dev loss: 0.5975 r:0.5921
ne_en Dev loss: 0.4641 r:0.7447
ru_en Dev loss: 0.5024 r:0.7297
Current avg r:0.6029 Best avg r: 0.6198
21:59:34,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:52,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:22,518 root INFO Epoch 4 Global steps: 40200 Train loss: 0.3424
en_de Dev loss: 0.8851 r:0.1840
en_zh Dev loss: 0.8419 r:0.4248
ro_en Dev loss: 0.3580 r:0.8262
et_en Dev loss: 0.4109 r:0.6913
si_en Dev loss: 0.6330 r:0.5890
ne_en Dev loss: 0.4545 r:0.7415
ru_en Dev loss: 0.5068 r:0.7321
Current avg r:0.5984 Best avg r: 0.6198
22:06:18,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:07:36,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:06,774 root INFO Epoch 4 Global steps: 40800 Train loss: 0.3264
en_de Dev loss: 0.8620 r:0.2055
en_zh Dev loss: 0.8124 r:0.4383
ro_en Dev loss: 0.3585 r:0.8263
et_en Dev loss: 0.4298 r:0.6849
si_en Dev loss: 0.6419 r:0.5899
ne_en Dev loss: 0.4274 r:0.7355
ru_en Dev loss: 0.4586 r:0.7410
Current avg r:0.6031 Best avg r: 0.6198
22:12:58,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:11,660 root INFO 
id:en_de cur r: 0.2613 best r: 0.2613
22:14:16,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:47,1 root INFO Epoch 4 Global steps: 41400 Train loss: 0.3442
en_de Dev loss: 0.8542 r:0.2356
en_zh Dev loss: 0.7891 r:0.4265
ro_en Dev loss: 0.3526 r:0.8186
et_en Dev loss: 0.4206 r:0.6793
si_en Dev loss: 0.6606 r:0.5838
ne_en Dev loss: 0.5542 r:0.7323
ru_en Dev loss: 0.4678 r:0.7296
Current avg r:0.6008 Best avg r: 0.6198
22:19:46,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:04,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:34,771 root INFO Epoch 4 Global steps: 42000 Train loss: 0.3480
en_de Dev loss: 0.8458 r:0.2296
en_zh Dev loss: 0.7603 r:0.4308
ro_en Dev loss: 0.3428 r:0.8187
et_en Dev loss: 0.4204 r:0.6763
si_en Dev loss: 0.6027 r:0.5825
ne_en Dev loss: 0.4254 r:0.7442
ru_en Dev loss: 0.4142 r:0.7371
Current avg r:0.6027 Best avg r: 0.6198
22:26:26,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:27:44,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:14,951 root INFO Epoch 4 Global steps: 42600 Train loss: 0.3190
en_de Dev loss: 0.8651 r:0.2298
en_zh Dev loss: 0.8034 r:0.4245
ro_en Dev loss: 0.3491 r:0.8174
et_en Dev loss: 0.4484 r:0.6798
si_en Dev loss: 0.5964 r:0.5872
ne_en Dev loss: 0.4612 r:0.7441
ru_en Dev loss: 0.4465 r:0.7292
Current avg r:0.6017 Best avg r: 0.6198
22:33:06,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:24,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:55,82 root INFO Epoch 4 Global steps: 43200 Train loss: 0.3544
en_de Dev loss: 0.8512 r:0.2274
en_zh Dev loss: 0.7828 r:0.4362
ro_en Dev loss: 0.3497 r:0.8215
et_en Dev loss: 0.4162 r:0.6799
si_en Dev loss: 0.5989 r:0.5854
ne_en Dev loss: 0.4281 r:0.7380
ru_en Dev loss: 0.4675 r:0.7254
Current avg r:0.6020 Best avg r: 0.6198
22:39:52,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:10,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:41,124 root INFO Epoch 4 Global steps: 43800 Train loss: 0.3464
en_de Dev loss: 0.8534 r:0.2201
en_zh Dev loss: 0.7890 r:0.4369
ro_en Dev loss: 0.3430 r:0.8212
et_en Dev loss: 0.4388 r:0.6843
si_en Dev loss: 0.5768 r:0.5919
ne_en Dev loss: 0.4404 r:0.7422
ru_en Dev loss: 0.4118 r:0.7446
Current avg r:0.6059 Best avg r: 0.6198
22:46:33,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:51,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:21,914 root INFO Epoch 4 Global steps: 44400 Train loss: 0.3300
en_de Dev loss: 0.8600 r:0.2307
en_zh Dev loss: 0.8208 r:0.4260
ro_en Dev loss: 0.3861 r:0.8168
et_en Dev loss: 0.4277 r:0.6779
si_en Dev loss: 0.6826 r:0.5825
ne_en Dev loss: 0.5872 r:0.7419
ru_en Dev loss: 0.4890 r:0.7273
Current avg r:0.6004 Best avg r: 0.6198
22:53:13,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:54:30,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:00,893 root INFO Epoch 4 Global steps: 45000 Train loss: 0.3210
en_de Dev loss: 0.8427 r:0.2395
en_zh Dev loss: 0.7594 r:0.4382
ro_en Dev loss: 0.3266 r:0.8168
et_en Dev loss: 0.4184 r:0.6741
si_en Dev loss: 0.6182 r:0.5803
ne_en Dev loss: 0.4531 r:0.7449
ru_en Dev loss: 0.4433 r:0.7282
Current avg r:0.6032 Best avg r: 0.6198
22:59:53,245 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:10,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:02:40,920 root INFO Epoch 5 Global steps: 45600 Train loss: 0.3022
en_de Dev loss: 0.8734 r:0.1922
en_zh Dev loss: 0.7692 r:0.4465
ro_en Dev loss: 0.3778 r:0.8156
et_en Dev loss: 0.4542 r:0.6650
si_en Dev loss: 0.6428 r:0.5806
ne_en Dev loss: 0.4825 r:0.7345
ru_en Dev loss: 0.4794 r:0.7222
Current avg r:0.5938 Best avg r: 0.6198
23:06:31,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:49,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:09:19,631 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2932
en_de Dev loss: 0.8569 r:0.2241
en_zh Dev loss: 0.8170 r:0.4335
ro_en Dev loss: 0.3532 r:0.8130
et_en Dev loss: 0.4484 r:0.6736
si_en Dev loss: 0.6325 r:0.5788
ne_en Dev loss: 0.4651 r:0.7352
ru_en Dev loss: 0.4474 r:0.7337
Current avg r:0.5988 Best avg r: 0.6198
23:13:10,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:28,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:58,784 root INFO Epoch 5 Global steps: 46800 Train loss: 0.3304
en_de Dev loss: 0.8655 r:0.2044
en_zh Dev loss: 0.8181 r:0.4313
ro_en Dev loss: 0.3730 r:0.8092
et_en Dev loss: 0.4582 r:0.6558
si_en Dev loss: 0.6763 r:0.5693
ne_en Dev loss: 0.6362 r:0.7343
ru_en Dev loss: 0.4943 r:0.7177
Current avg r:0.5889 Best avg r: 0.6198
23:19:49,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:07,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:37,161 root INFO Epoch 5 Global steps: 47400 Train loss: 0.2977
en_de Dev loss: 0.8909 r:0.2110
en_zh Dev loss: 0.8731 r:0.4321
ro_en Dev loss: 0.4092 r:0.8146
et_en Dev loss: 0.4657 r:0.6646
si_en Dev loss: 0.6955 r:0.5744
ne_en Dev loss: 0.5487 r:0.7400
ru_en Dev loss: 0.5211 r:0.7221
Current avg r:0.5941 Best avg r: 0.6198
23:26:28,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:27:45,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:15,472 root INFO Epoch 5 Global steps: 48000 Train loss: 0.2921
en_de Dev loss: 0.8669 r:0.2174
en_zh Dev loss: 0.7792 r:0.4380
ro_en Dev loss: 0.3497 r:0.8177
et_en Dev loss: 0.4556 r:0.6603
si_en Dev loss: 0.6873 r:0.5667
ne_en Dev loss: 0.5427 r:0.7344
ru_en Dev loss: 0.4499 r:0.7319
Current avg r:0.5952 Best avg r: 0.6198
23:33:06,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:34:23,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:53,773 root INFO Epoch 5 Global steps: 48600 Train loss: 0.2931
en_de Dev loss: 0.8592 r:0.2373
en_zh Dev loss: 0.8316 r:0.4373
ro_en Dev loss: 0.3594 r:0.8202
et_en Dev loss: 0.4554 r:0.6746
si_en Dev loss: 0.6222 r:0.5845
ne_en Dev loss: 0.4279 r:0.7381
ru_en Dev loss: 0.4721 r:0.7347
Current avg r:0.6038 Best avg r: 0.6198
23:39:44,654 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:01,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:32,68 root INFO Epoch 5 Global steps: 49200 Train loss: 0.2928
en_de Dev loss: 0.8944 r:0.2029
en_zh Dev loss: 0.8728 r:0.4228
ro_en Dev loss: 0.3762 r:0.8162
et_en Dev loss: 0.4628 r:0.6616
si_en Dev loss: 0.6786 r:0.5737
ne_en Dev loss: 0.4819 r:0.7354
ru_en Dev loss: 0.5339 r:0.7140
Current avg r:0.5895 Best avg r: 0.6198
23:46:22,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:40,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:10,390 root INFO Epoch 5 Global steps: 49800 Train loss: 0.2988
en_de Dev loss: 0.8635 r:0.2221
en_zh Dev loss: 0.8192 r:0.4405
ro_en Dev loss: 0.3562 r:0.8170
et_en Dev loss: 0.4624 r:0.6660
si_en Dev loss: 0.6346 r:0.5778
ne_en Dev loss: 0.4331 r:0.7421
ru_en Dev loss: 0.4481 r:0.7371
Current avg r:0.6004 Best avg r: 0.6198
23:53:01,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:18,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:48,624 root INFO Epoch 5 Global steps: 50400 Train loss: 0.2977
en_de Dev loss: 0.8595 r:0.2036
en_zh Dev loss: 0.8116 r:0.4250
ro_en Dev loss: 0.3428 r:0.8199
et_en Dev loss: 0.4537 r:0.6547
si_en Dev loss: 0.6645 r:0.5706
ne_en Dev loss: 0.5093 r:0.7348
ru_en Dev loss: 0.4631 r:0.7229
Current avg r:0.5902 Best avg r: 0.6198
23:59:39,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:00:56,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:02:26,898 root INFO Epoch 5 Global steps: 51000 Train loss: 0.2864
en_de Dev loss: 0.8672 r:0.1921
en_zh Dev loss: 0.7749 r:0.4316
ro_en Dev loss: 0.3483 r:0.8187
et_en Dev loss: 0.4345 r:0.6683
si_en Dev loss: 0.6106 r:0.5809
ne_en Dev loss: 0.4473 r:0.7412
ru_en Dev loss: 0.5040 r:0.7057
Current avg r:0.5912 Best avg r: 0.6198
00:06:17,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:35,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:09:05,185 root INFO Epoch 5 Global steps: 51600 Train loss: 0.2831
en_de Dev loss: 0.8683 r:0.2216
en_zh Dev loss: 0.8110 r:0.4229
ro_en Dev loss: 0.3541 r:0.8190
et_en Dev loss: 0.4523 r:0.6661
si_en Dev loss: 0.6306 r:0.5730
ne_en Dev loss: 0.4647 r:0.7418
ru_en Dev loss: 0.4896 r:0.7095
Current avg r:0.5934 Best avg r: 0.6198
00:12:56,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:13,312 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:43,448 root INFO Epoch 5 Global steps: 52200 Train loss: 0.2505
en_de Dev loss: 0.8640 r:0.2109
en_zh Dev loss: 0.8467 r:0.4400
ro_en Dev loss: 0.3885 r:0.8207
et_en Dev loss: 0.4338 r:0.6756
si_en Dev loss: 0.6625 r:0.5878
ne_en Dev loss: 0.4709 r:0.7442
ru_en Dev loss: 0.4916 r:0.7251
Current avg r:0.6006 Best avg r: 0.6198
00:19:34,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:51,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:21,750 root INFO Epoch 5 Global steps: 52800 Train loss: 0.2769
en_de Dev loss: 0.8482 r:0.2387
en_zh Dev loss: 0.8167 r:0.4395
ro_en Dev loss: 0.3779 r:0.8155
et_en Dev loss: 0.4631 r:0.6751
si_en Dev loss: 0.6583 r:0.5779
ne_en Dev loss: 0.5310 r:0.7384
ru_en Dev loss: 0.4862 r:0.7190
Current avg r:0.6006 Best avg r: 0.6198
00:26:12,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:27:29,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:00,73 root INFO Epoch 5 Global steps: 53400 Train loss: 0.2826
en_de Dev loss: 0.8669 r:0.2182
en_zh Dev loss: 0.7808 r:0.4309
ro_en Dev loss: 0.3593 r:0.8108
et_en Dev loss: 0.4618 r:0.6657
si_en Dev loss: 0.6339 r:0.5756
ne_en Dev loss: 0.4912 r:0.7349
ru_en Dev loss: 0.4759 r:0.7068
Current avg r:0.5918 Best avg r: 0.6198
00:32:50,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:08,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:38,397 root INFO Epoch 5 Global steps: 54000 Train loss: 0.2884
en_de Dev loss: 0.8568 r:0.2372
en_zh Dev loss: 0.8176 r:0.4330
ro_en Dev loss: 0.3848 r:0.8172
et_en Dev loss: 0.4471 r:0.6643
si_en Dev loss: 0.6795 r:0.5765
ne_en Dev loss: 0.4839 r:0.7331
ru_en Dev loss: 0.4906 r:0.7272
Current avg r:0.5983 Best avg r: 0.6198
00:39:30,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:47,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:17,708 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2641
en_de Dev loss: 0.8613 r:0.2115
en_zh Dev loss: 0.8261 r:0.4239
ro_en Dev loss: 0.3509 r:0.8174
et_en Dev loss: 0.4581 r:0.6616
si_en Dev loss: 0.6439 r:0.5733
ne_en Dev loss: 0.4776 r:0.7342
ru_en Dev loss: 0.5155 r:0.7023
Current avg r:0.5892 Best avg r: 0.6198
00:46:08,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:47:25,852 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:48:56,11 root INFO Epoch 6 Global steps: 55200 Train loss: 0.2629
en_de Dev loss: 0.8957 r:0.2147
en_zh Dev loss: 0.8851 r:0.4142
ro_en Dev loss: 0.3935 r:0.8115
et_en Dev loss: 0.4850 r:0.6509
si_en Dev loss: 0.7101 r:0.5654
ne_en Dev loss: 0.6593 r:0.7260
ru_en Dev loss: 0.5435 r:0.6998
Current avg r:0.5832 Best avg r: 0.6198
00:52:46,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:54:04,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:34,315 root INFO Epoch 6 Global steps: 55800 Train loss: 0.2760
en_de Dev loss: 0.8697 r:0.2265
en_zh Dev loss: 0.8503 r:0.4162
ro_en Dev loss: 0.4126 r:0.8129
et_en Dev loss: 0.4673 r:0.6517
si_en Dev loss: 0.7016 r:0.5707
ne_en Dev loss: 0.5594 r:0.7268
ru_en Dev loss: 0.5450 r:0.7008
Current avg r:0.5865 Best avg r: 0.6198
00:59:25,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:42,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:12,639 root INFO Epoch 6 Global steps: 56400 Train loss: 0.2565
en_de Dev loss: 0.8482 r:0.2263
en_zh Dev loss: 0.7761 r:0.4335
ro_en Dev loss: 0.3226 r:0.8218
et_en Dev loss: 0.4589 r:0.6618
si_en Dev loss: 0.5862 r:0.5841
ne_en Dev loss: 0.4210 r:0.7335
ru_en Dev loss: 0.4361 r:0.7277
Current avg r:0.5984 Best avg r: 0.6198
01:06:03,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:20,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:50,954 root INFO Epoch 6 Global steps: 57000 Train loss: 0.2569
en_de Dev loss: 0.8636 r:0.2339
en_zh Dev loss: 0.8124 r:0.4327
ro_en Dev loss: 0.3485 r:0.8180
et_en Dev loss: 0.4846 r:0.6658
si_en Dev loss: 0.6198 r:0.5848
ne_en Dev loss: 0.4918 r:0.7278
ru_en Dev loss: 0.4428 r:0.7389
Current avg r:0.6003 Best avg r: 0.6198
01:12:41,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:59,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:29,234 root INFO Epoch 6 Global steps: 57600 Train loss: 0.2471
en_de Dev loss: 0.8694 r:0.2461
en_zh Dev loss: 0.7956 r:0.4386
ro_en Dev loss: 0.3848 r:0.8110
et_en Dev loss: 0.4766 r:0.6538
si_en Dev loss: 0.6761 r:0.5668
ne_en Dev loss: 0.6204 r:0.7365
ru_en Dev loss: 0.4648 r:0.7297
Current avg r:0.5975 Best avg r: 0.6198
01:19:20,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:20:37,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:22:07,633 root INFO Epoch 6 Global steps: 58200 Train loss: 0.2625
en_de Dev loss: 0.8489 r:0.2179
en_zh Dev loss: 0.7717 r:0.4417
ro_en Dev loss: 0.3412 r:0.8202
et_en Dev loss: 0.4612 r:0.6611
si_en Dev loss: 0.6679 r:0.5778
ne_en Dev loss: 0.5921 r:0.7278
ru_en Dev loss: 0.4600 r:0.7341
Current avg r:0.5972 Best avg r: 0.6198
01:25:58,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:27:15,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:45,987 root INFO Epoch 6 Global steps: 58800 Train loss: 0.2569
en_de Dev loss: 0.8728 r:0.2267
en_zh Dev loss: 0.8416 r:0.4416
ro_en Dev loss: 0.3881 r:0.8203
et_en Dev loss: 0.4836 r:0.6684
si_en Dev loss: 0.6853 r:0.5839
ne_en Dev loss: 0.6805 r:0.7301
ru_en Dev loss: 0.5314 r:0.7228
Current avg r:0.5991 Best avg r: 0.6198
01:32:36,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:33:54,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:35:24,319 root INFO Epoch 6 Global steps: 59400 Train loss: 0.2621
en_de Dev loss: 0.8739 r:0.2129
en_zh Dev loss: 0.8649 r:0.4293
ro_en Dev loss: 0.3543 r:0.8226
et_en Dev loss: 0.4961 r:0.6648
si_en Dev loss: 0.6666 r:0.5795
ne_en Dev loss: 0.4948 r:0.7272
ru_en Dev loss: 0.4836 r:0.7319
Current avg r:0.5955 Best avg r: 0.6198
01:39:15,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:40:32,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:42:02,656 root INFO Epoch 6 Global steps: 60000 Train loss: 0.2470
en_de Dev loss: 0.8697 r:0.2153
en_zh Dev loss: 0.8472 r:0.4302
ro_en Dev loss: 0.3660 r:0.8201
et_en Dev loss: 0.4784 r:0.6652
si_en Dev loss: 0.6724 r:0.5736
ne_en Dev loss: 0.4835 r:0.7323
ru_en Dev loss: 0.4801 r:0.7284
Current avg r:0.5950 Best avg r: 0.6198
01:45:53,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:47:10,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:48:40,988 root INFO Epoch 6 Global steps: 60600 Train loss: 0.2513
en_de Dev loss: 0.8759 r:0.2294
en_zh Dev loss: 0.8138 r:0.4377
ro_en Dev loss: 0.3424 r:0.8229
et_en Dev loss: 0.4579 r:0.6699
si_en Dev loss: 0.6756 r:0.5760
ne_en Dev loss: 0.4550 r:0.7342
ru_en Dev loss: 0.4713 r:0.7355
Current avg r:0.6008 Best avg r: 0.6198
01:52:31,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:53:49,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:55:19,603 root INFO Epoch 6 Global steps: 61200 Train loss: 0.2361
en_de Dev loss: 0.8472 r:0.2440
en_zh Dev loss: 0.7474 r:0.4474
ro_en Dev loss: 0.3218 r:0.8205
et_en Dev loss: 0.4563 r:0.6638
si_en Dev loss: 0.6072 r:0.5755
ne_en Dev loss: 0.4410 r:0.7330
ru_en Dev loss: 0.4349 r:0.7335
Current avg r:0.6025 Best avg r: 0.6198
01:59:13,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:00:32,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:02:03,708 root INFO Epoch 6 Global steps: 61800 Train loss: 0.2441
en_de Dev loss: 0.8632 r:0.2419
en_zh Dev loss: 0.7937 r:0.4506
ro_en Dev loss: 0.3444 r:0.8174
et_en Dev loss: 0.4709 r:0.6715
si_en Dev loss: 0.6271 r:0.5765
ne_en Dev loss: 0.4905 r:0.7265
ru_en Dev loss: 0.4375 r:0.7413
Current avg r:0.6037 Best avg r: 0.6198
02:05:58,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:07:17,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:08:48,769 root INFO Epoch 6 Global steps: 62400 Train loss: 0.2546
en_de Dev loss: 0.8866 r:0.2028
en_zh Dev loss: 0.8722 r:0.4185
ro_en Dev loss: 0.3883 r:0.8111
et_en Dev loss: 0.4806 r:0.6483
si_en Dev loss: 0.7491 r:0.5646
ne_en Dev loss: 0.6829 r:0.7245
ru_en Dev loss: 0.5863 r:0.6974
Current avg r:0.5810 Best avg r: 0.6198
02:12:43,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:14:01,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:15:33,325 root INFO Epoch 6 Global steps: 63000 Train loss: 0.2499
en_de Dev loss: 0.9184 r:0.2205
en_zh Dev loss: 0.8277 r:0.4424
ro_en Dev loss: 0.3791 r:0.8165
et_en Dev loss: 0.4727 r:0.6628
si_en Dev loss: 0.7111 r:0.5690
ne_en Dev loss: 0.5505 r:0.7286
ru_en Dev loss: 0.4768 r:0.7365
Current avg r:0.5966 Best avg r: 0.6198
02:19:29,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:47,680 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:19,285 root INFO Epoch 7 Global steps: 63600 Train loss: 0.2488
en_de Dev loss: 0.9033 r:0.1993
en_zh Dev loss: 0.8381 r:0.4323
ro_en Dev loss: 0.3717 r:0.8187
et_en Dev loss: 0.4740 r:0.6521
si_en Dev loss: 0.7247 r:0.5669
ne_en Dev loss: 0.4959 r:0.7298
ru_en Dev loss: 0.5252 r:0.7215
Current avg r:0.5886 Best avg r: 0.6198
02:26:13,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:27:31,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:02,322 root INFO Epoch 7 Global steps: 64200 Train loss: 0.2365
en_de Dev loss: 0.8684 r:0.2240
en_zh Dev loss: 0.8340 r:0.4351
ro_en Dev loss: 0.3637 r:0.8195
et_en Dev loss: 0.4748 r:0.6503
si_en Dev loss: 0.7401 r:0.5704
ne_en Dev loss: 0.5306 r:0.7352
ru_en Dev loss: 0.4736 r:0.7385
Current avg r:0.5961 Best avg r: 0.6198
02:32:54,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:34:12,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:35:43,189 root INFO Epoch 7 Global steps: 64800 Train loss: 0.2165
en_de Dev loss: 0.8653 r:0.2280
en_zh Dev loss: 0.8408 r:0.4266
ro_en Dev loss: 0.3562 r:0.8148
et_en Dev loss: 0.4944 r:0.6495
si_en Dev loss: 0.6951 r:0.5699
ne_en Dev loss: 0.5289 r:0.7327
ru_en Dev loss: 0.4500 r:0.7382
Current avg r:0.5942 Best avg r: 0.6198
02:39:37,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:40:55,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:42:26,301 root INFO Epoch 7 Global steps: 65400 Train loss: 0.2226
en_de Dev loss: 0.8668 r:0.2104
en_zh Dev loss: 0.8124 r:0.4285
ro_en Dev loss: 0.3599 r:0.8126
et_en Dev loss: 0.4827 r:0.6508
si_en Dev loss: 0.7135 r:0.5613
ne_en Dev loss: 0.5246 r:0.7220
ru_en Dev loss: 0.4604 r:0.7252
Current avg r:0.5873 Best avg r: 0.6198
02:46:18,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:47:35,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:49:06,674 root INFO Epoch 7 Global steps: 66000 Train loss: 0.2243
en_de Dev loss: 0.8999 r:0.2246
en_zh Dev loss: 0.8874 r:0.4097
ro_en Dev loss: 0.3937 r:0.8092
et_en Dev loss: 0.5074 r:0.6390
si_en Dev loss: 0.8109 r:0.5460
ne_en Dev loss: 0.5984 r:0.7194
ru_en Dev loss: 0.5077 r:0.7210
Current avg r:0.5813 Best avg r: 0.6198
02:52:58,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:54:16,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:55:48,173 root INFO Epoch 7 Global steps: 66600 Train loss: 0.2303
en_de Dev loss: 0.8811 r:0.2172
en_zh Dev loss: 0.8543 r:0.4290
ro_en Dev loss: 0.4142 r:0.8068
et_en Dev loss: 0.5271 r:0.6406
si_en Dev loss: 0.7961 r:0.5493
ne_en Dev loss: 0.6023 r:0.7235
ru_en Dev loss: 0.5266 r:0.7130
Current avg r:0.5828 Best avg r: 0.6198
02:59:42,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:01:01,100 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:02:32,531 root INFO Epoch 7 Global steps: 67200 Train loss: 0.2151
en_de Dev loss: 0.8872 r:0.2090
en_zh Dev loss: 0.8270 r:0.4373
ro_en Dev loss: 0.3734 r:0.8117
et_en Dev loss: 0.4982 r:0.6457
si_en Dev loss: 0.7612 r:0.5542
ne_en Dev loss: 0.5141 r:0.7305
ru_en Dev loss: 0.4923 r:0.7245
Current avg r:0.5875 Best avg r: 0.6198
03:06:26,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:07:45,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:09:16,754 root INFO Epoch 7 Global steps: 67800 Train loss: 0.2212
en_de Dev loss: 0.8638 r:0.2353
en_zh Dev loss: 0.8224 r:0.4404
ro_en Dev loss: 0.3800 r:0.8160
et_en Dev loss: 0.5071 r:0.6624
si_en Dev loss: 0.6787 r:0.5763
ne_en Dev loss: 0.4515 r:0.7295
ru_en Dev loss: 0.4616 r:0.7391
Current avg r:0.5998 Best avg r: 0.6198
03:13:11,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:30,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:01,572 root INFO Epoch 7 Global steps: 68400 Train loss: 0.2297
en_de Dev loss: 0.8919 r:0.2090
en_zh Dev loss: 0.8320 r:0.4283
ro_en Dev loss: 0.3983 r:0.8066
et_en Dev loss: 0.4688 r:0.6389
si_en Dev loss: 0.7989 r:0.5494
ne_en Dev loss: 0.6126 r:0.7320
ru_en Dev loss: 0.5112 r:0.7190
Current avg r:0.5833 Best avg r: 0.6198
03:19:53,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:11,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:41,591 root INFO Epoch 7 Global steps: 69000 Train loss: 0.2091
en_de Dev loss: 0.9012 r:0.1947
en_zh Dev loss: 0.9207 r:0.4171
ro_en Dev loss: 0.4717 r:0.8013
et_en Dev loss: 0.5372 r:0.6221
si_en Dev loss: 0.9747 r:0.5313
ne_en Dev loss: 0.8135 r:0.7201
ru_en Dev loss: 0.6059 r:0.6952
Current avg r:0.5688 Best avg r: 0.6198
03:26:33,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:27:51,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:29:21,596 root INFO Epoch 7 Global steps: 69600 Train loss: 0.2142
en_de Dev loss: 0.8821 r:0.1968
en_zh Dev loss: 0.8271 r:0.4280
ro_en Dev loss: 0.3744 r:0.8074
et_en Dev loss: 0.4822 r:0.6306
si_en Dev loss: 0.8061 r:0.5458
ne_en Dev loss: 0.6373 r:0.7281
ru_en Dev loss: 0.4945 r:0.7182
Current avg r:0.5793 Best avg r: 0.6198
03:33:13,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:34:30,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:01,535 root INFO Epoch 7 Global steps: 70200 Train loss: 0.2093
en_de Dev loss: 0.9129 r:0.1898
en_zh Dev loss: 0.9416 r:0.4392
ro_en Dev loss: 0.4616 r:0.8087
et_en Dev loss: 0.5065 r:0.6368
si_en Dev loss: 0.9420 r:0.5448
ne_en Dev loss: 0.7192 r:0.7198
ru_en Dev loss: 0.6517 r:0.6952
Current avg r:0.5763 Best avg r: 0.6198
03:39:53,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:41:10,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:42:41,701 root INFO Epoch 7 Global steps: 70800 Train loss: 0.2257
en_de Dev loss: 0.9048 r:0.2060
en_zh Dev loss: 0.8650 r:0.4300
ro_en Dev loss: 0.4009 r:0.8092
et_en Dev loss: 0.5053 r:0.6315
si_en Dev loss: 0.8214 r:0.5446
ne_en Dev loss: 0.6644 r:0.7297
ru_en Dev loss: 0.5756 r:0.6894
Current avg r:0.5772 Best avg r: 0.6198
03:46:35,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:47:54,144 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:49:25,537 root INFO Epoch 7 Global steps: 71400 Train loss: 0.2236
en_de Dev loss: 0.9205 r:0.1876
en_zh Dev loss: 0.9597 r:0.4302
ro_en Dev loss: 0.4657 r:0.8047
et_en Dev loss: 0.5450 r:0.6204
si_en Dev loss: 1.0089 r:0.5325
ne_en Dev loss: 0.8368 r:0.7235
ru_en Dev loss: 0.6065 r:0.7014
Current avg r:0.5715 Best avg r: 0.6198
03:53:20,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:54:38,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:56:10,171 root INFO Epoch 7 Global steps: 72000 Train loss: 0.2278
en_de Dev loss: 0.8782 r:0.2370
en_zh Dev loss: 0.7849 r:0.4549
ro_en Dev loss: 0.3745 r:0.8123
et_en Dev loss: 0.4600 r:0.6480
si_en Dev loss: 0.7271 r:0.5583
ne_en Dev loss: 0.5006 r:0.7344
ru_en Dev loss: 0.4510 r:0.7412
Current avg r:0.5980 Best avg r: 0.6198
04:00:06,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:01:24,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:02:56,466 root INFO Epoch 8 Global steps: 72600 Train loss: 0.2028
en_de Dev loss: 0.8757 r:0.2180
en_zh Dev loss: 0.8063 r:0.4519
ro_en Dev loss: 0.3698 r:0.8124
et_en Dev loss: 0.4891 r:0.6463
si_en Dev loss: 0.7502 r:0.5585
ne_en Dev loss: 0.5691 r:0.7283
ru_en Dev loss: 0.4930 r:0.7228
Current avg r:0.5912 Best avg r: 0.6198
04:06:49,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:08:06,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:09:37,221 root INFO Epoch 8 Global steps: 73200 Train loss: 0.1994
en_de Dev loss: 0.8747 r:0.2385
en_zh Dev loss: 0.8233 r:0.4496
ro_en Dev loss: 0.3778 r:0.8133
et_en Dev loss: 0.4959 r:0.6516
si_en Dev loss: 0.7284 r:0.5669
ne_en Dev loss: 0.5083 r:0.7268
ru_en Dev loss: 0.4960 r:0.7236
Current avg r:0.5957 Best avg r: 0.6198
04:13:28,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:46,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:16:17,27 root INFO Epoch 8 Global steps: 73800 Train loss: 0.1975
en_de Dev loss: 0.8855 r:0.2448
en_zh Dev loss: 0.7680 r:0.4617
ro_en Dev loss: 0.3316 r:0.8151
et_en Dev loss: 0.4845 r:0.6520
si_en Dev loss: 0.6243 r:0.5715
ne_en Dev loss: 0.4446 r:0.7313
ru_en Dev loss: 0.3998 r:0.7485
Current avg r:0.6036 Best avg r: 0.6198
04:20:12,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:30,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:01,60 root INFO Epoch 8 Global steps: 74400 Train loss: 0.1925
en_de Dev loss: 0.8955 r:0.2535
en_zh Dev loss: 0.8593 r:0.4381
ro_en Dev loss: 0.3932 r:0.8113
et_en Dev loss: 0.5144 r:0.6466
si_en Dev loss: 0.7596 r:0.5556
ne_en Dev loss: 0.5865 r:0.7285
ru_en Dev loss: 0.5252 r:0.7201
Current avg r:0.5934 Best avg r: 0.6198
04:26:53,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:28:10,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:29:41,338 root INFO Epoch 8 Global steps: 75000 Train loss: 0.1959
en_de Dev loss: 0.8785 r:0.2384
en_zh Dev loss: 0.8237 r:0.4425
ro_en Dev loss: 0.3594 r:0.8125
et_en Dev loss: 0.5095 r:0.6434
si_en Dev loss: 0.7436 r:0.5552
ne_en Dev loss: 0.6116 r:0.7237
ru_en Dev loss: 0.4916 r:0.7167
Current avg r:0.5903 Best avg r: 0.6198
04:33:38,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:34:57,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:36:28,531 root INFO Epoch 8 Global steps: 75600 Train loss: 0.2044
en_de Dev loss: 0.8657 r:0.2260
en_zh Dev loss: 0.8150 r:0.4418
ro_en Dev loss: 0.3413 r:0.8165
et_en Dev loss: 0.4925 r:0.6386
si_en Dev loss: 0.7255 r:0.5524
ne_en Dev loss: 0.5949 r:0.7285
ru_en Dev loss: 0.4897 r:0.7176
Current avg r:0.5888 Best avg r: 0.6198
04:40:22,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:41:41,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:43:12,703 root INFO Epoch 8 Global steps: 76200 Train loss: 0.1916
en_de Dev loss: 0.8690 r:0.2180
en_zh Dev loss: 0.7948 r:0.4476
ro_en Dev loss: 0.3451 r:0.8170
et_en Dev loss: 0.4895 r:0.6395
si_en Dev loss: 0.6838 r:0.5633
ne_en Dev loss: 0.5177 r:0.7341
ru_en Dev loss: 0.4611 r:0.7286
Current avg r:0.5926 Best avg r: 0.6198
04:47:07,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:48:25,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:49:57,470 root INFO Epoch 8 Global steps: 76800 Train loss: 0.1939
en_de Dev loss: 0.8790 r:0.2019
en_zh Dev loss: 0.7764 r:0.4541
ro_en Dev loss: 0.3672 r:0.8135
et_en Dev loss: 0.4958 r:0.6446
si_en Dev loss: 0.7001 r:0.5600
ne_en Dev loss: 0.5007 r:0.7283
ru_en Dev loss: 0.4766 r:0.7251
Current avg r:0.5896 Best avg r: 0.6198
04:53:51,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:55:10,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:56:41,218 root INFO Epoch 8 Global steps: 77400 Train loss: 0.1875
en_de Dev loss: 0.8787 r:0.2040
en_zh Dev loss: 0.8007 r:0.4541
ro_en Dev loss: 0.3722 r:0.8141
et_en Dev loss: 0.4991 r:0.6459
si_en Dev loss: 0.7104 r:0.5583
ne_en Dev loss: 0.5135 r:0.7249
ru_en Dev loss: 0.4577 r:0.7331
Current avg r:0.5907 Best avg r: 0.6198
05:00:32,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:01:50,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:21,100 root INFO Epoch 8 Global steps: 78000 Train loss: 0.1966
en_de Dev loss: 0.8849 r:0.2131
en_zh Dev loss: 0.8209 r:0.4473
ro_en Dev loss: 0.3867 r:0.8155
et_en Dev loss: 0.4865 r:0.6477
si_en Dev loss: 0.7860 r:0.5516
ne_en Dev loss: 0.6401 r:0.7243
ru_en Dev loss: 0.4758 r:0.7332
Current avg r:0.5904 Best avg r: 0.6198
05:07:12,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:08:30,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:10:01,8 root INFO Epoch 8 Global steps: 78600 Train loss: 0.1981
en_de Dev loss: 0.8896 r:0.2156
en_zh Dev loss: 0.8520 r:0.4487
ro_en Dev loss: 0.3717 r:0.8170
et_en Dev loss: 0.4755 r:0.6507
si_en Dev loss: 0.7643 r:0.5545
ne_en Dev loss: 0.5441 r:0.7240
ru_en Dev loss: 0.4881 r:0.7252
Current avg r:0.5908 Best avg r: 0.6198
05:13:52,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:15:10,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:16:40,808 root INFO Epoch 8 Global steps: 79200 Train loss: 0.1885
en_de Dev loss: 0.8841 r:0.2056
en_zh Dev loss: 0.8043 r:0.4496
ro_en Dev loss: 0.3740 r:0.8128
et_en Dev loss: 0.4739 r:0.6457
si_en Dev loss: 0.7712 r:0.5464
ne_en Dev loss: 0.6037 r:0.7201
ru_en Dev loss: 0.4885 r:0.7200
Current avg r:0.5857 Best avg r: 0.6198
05:20:32,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:21:50,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:22,106 root INFO Epoch 8 Global steps: 79800 Train loss: 0.1968
en_de Dev loss: 0.8920 r:0.1889
en_zh Dev loss: 0.8007 r:0.4490
ro_en Dev loss: 0.3611 r:0.8166
et_en Dev loss: 0.4827 r:0.6572
si_en Dev loss: 0.7323 r:0.5542
ne_en Dev loss: 0.5001 r:0.7217
ru_en Dev loss: 0.4980 r:0.7204
Current avg r:0.5868 Best avg r: 0.6198
05:27:15,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:34,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:05,475 root INFO Epoch 8 Global steps: 80400 Train loss: 0.2049
en_de Dev loss: 0.8768 r:0.1966
en_zh Dev loss: 0.7860 r:0.4499
ro_en Dev loss: 0.3665 r:0.8141
et_en Dev loss: 0.4713 r:0.6468
si_en Dev loss: 0.7403 r:0.5516
ne_en Dev loss: 0.5416 r:0.7255
ru_en Dev loss: 0.4999 r:0.7104
Current avg r:0.5850 Best avg r: 0.6198
05:33:59,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:35:18,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:36:49,714 root INFO Epoch 8 Global steps: 81000 Train loss: 0.1873
en_de Dev loss: 0.9020 r:0.1878
en_zh Dev loss: 0.8014 r:0.4579
ro_en Dev loss: 0.3591 r:0.8153
et_en Dev loss: 0.4778 r:0.6527
si_en Dev loss: 0.7137 r:0.5570
ne_en Dev loss: 0.5013 r:0.7233
ru_en Dev loss: 0.4791 r:0.7271
Current avg r:0.5887 Best avg r: 0.6198
05:40:44,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:42:03,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:43:34,513 root INFO Epoch 9 Global steps: 81600 Train loss: 0.1805
en_de Dev loss: 0.9178 r:0.1945
en_zh Dev loss: 0.8499 r:0.4527
ro_en Dev loss: 0.3885 r:0.8149
et_en Dev loss: 0.4834 r:0.6513
si_en Dev loss: 0.7703 r:0.5518
ne_en Dev loss: 0.5886 r:0.7153
ru_en Dev loss: 0.5281 r:0.7207
Current avg r:0.5859 Best avg r: 0.6198
05:47:27,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:48:44,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:50:15,528 root INFO Epoch 9 Global steps: 82200 Train loss: 0.1761
en_de Dev loss: 0.9040 r:0.1859
en_zh Dev loss: 0.8531 r:0.4469
ro_en Dev loss: 0.3787 r:0.8128
et_en Dev loss: 0.4821 r:0.6442
si_en Dev loss: 0.7807 r:0.5510
ne_en Dev loss: 0.6738 r:0.7120
ru_en Dev loss: 0.5598 r:0.7046
Current avg r:0.5796 Best avg r: 0.6198
05:54:07,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:55:24,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:56:55,262 root INFO Epoch 9 Global steps: 82800 Train loss: 0.1681
en_de Dev loss: 0.9169 r:0.1992
en_zh Dev loss: 0.9041 r:0.4490
ro_en Dev loss: 0.3989 r:0.8129
et_en Dev loss: 0.5318 r:0.6455
si_en Dev loss: 0.8007 r:0.5533
ne_en Dev loss: 0.6349 r:0.7151
ru_en Dev loss: 0.5620 r:0.7101
Current avg r:0.5836 Best avg r: 0.6198
06:00:46,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:02:04,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:03:34,851 root INFO Epoch 9 Global steps: 83400 Train loss: 0.1772
en_de Dev loss: 0.8903 r:0.1911
en_zh Dev loss: 0.7742 r:0.4438
ro_en Dev loss: 0.3380 r:0.8136
et_en Dev loss: 0.4786 r:0.6567
si_en Dev loss: 0.6500 r:0.5665
ne_en Dev loss: 0.4599 r:0.7272
ru_en Dev loss: 0.4306 r:0.7357
Current avg r:0.5906 Best avg r: 0.6198
06:07:26,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:08:45,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:10:16,726 root INFO Epoch 9 Global steps: 84000 Train loss: 0.1677
en_de Dev loss: 0.8955 r:0.2124
en_zh Dev loss: 0.8141 r:0.4455
ro_en Dev loss: 0.3669 r:0.8093
et_en Dev loss: 0.5125 r:0.6462
si_en Dev loss: 0.7255 r:0.5518
ne_en Dev loss: 0.5428 r:0.7245
ru_en Dev loss: 0.4753 r:0.7249
Current avg r:0.5878 Best avg r: 0.6198
06:14:11,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:15:29,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:17:00,774 root INFO Epoch 9 Global steps: 84600 Train loss: 0.1778
en_de Dev loss: 0.9089 r:0.1952
en_zh Dev loss: 0.8222 r:0.4548
ro_en Dev loss: 0.3760 r:0.8097
et_en Dev loss: 0.5023 r:0.6412
si_en Dev loss: 0.7287 r:0.5635
ne_en Dev loss: 0.5675 r:0.7250
ru_en Dev loss: 0.5066 r:0.7154
Current avg r:0.5864 Best avg r: 0.6198
06:20:55,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:22:13,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:45,328 root INFO Epoch 9 Global steps: 85200 Train loss: 0.1728
en_de Dev loss: 0.8860 r:0.2106
en_zh Dev loss: 0.7765 r:0.4685
ro_en Dev loss: 0.3419 r:0.8204
et_en Dev loss: 0.5108 r:0.6605
si_en Dev loss: 0.6487 r:0.5719
ne_en Dev loss: 0.4785 r:0.7216
ru_en Dev loss: 0.4226 r:0.7432
Current avg r:0.5995 Best avg r: 0.6198
06:27:39,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:28:57,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:27,867 root INFO Epoch 9 Global steps: 85800 Train loss: 0.1756
en_de Dev loss: 0.9149 r:0.1992
en_zh Dev loss: 0.8610 r:0.4481
ro_en Dev loss: 0.3685 r:0.8145
et_en Dev loss: 0.4932 r:0.6420
si_en Dev loss: 0.7827 r:0.5526
ne_en Dev loss: 0.6153 r:0.7277
ru_en Dev loss: 0.4966 r:0.7222
Current avg r:0.5866 Best avg r: 0.6198
06:34:19,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:35:37,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:07,787 root INFO Epoch 9 Global steps: 86400 Train loss: 0.1730
en_de Dev loss: 0.9348 r:0.2105
en_zh Dev loss: 0.9093 r:0.4354
ro_en Dev loss: 0.4089 r:0.8121
et_en Dev loss: 0.5175 r:0.6494
si_en Dev loss: 0.7778 r:0.5552
ne_en Dev loss: 0.6192 r:0.7194
ru_en Dev loss: 0.5245 r:0.7273
Current avg r:0.5870 Best avg r: 0.6198
06:40:59,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:42:17,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:43:47,636 root INFO Epoch 9 Global steps: 87000 Train loss: 0.1720
en_de Dev loss: 0.8987 r:0.2000
en_zh Dev loss: 0.8345 r:0.4393
ro_en Dev loss: 0.3667 r:0.8153
et_en Dev loss: 0.5162 r:0.6516
si_en Dev loss: 0.6983 r:0.5623
ne_en Dev loss: 0.5337 r:0.7259
ru_en Dev loss: 0.4612 r:0.7339
Current avg r:0.5898 Best avg r: 0.6198
06:47:39,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:48:56,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:50:27,480 root INFO Epoch 9 Global steps: 87600 Train loss: 0.1767
en_de Dev loss: 0.9180 r:0.1937
en_zh Dev loss: 0.9143 r:0.4397
ro_en Dev loss: 0.4180 r:0.8119
et_en Dev loss: 0.5272 r:0.6361
si_en Dev loss: 0.7773 r:0.5585
ne_en Dev loss: 0.6082 r:0.7204
ru_en Dev loss: 0.5049 r:0.7314
Current avg r:0.5845 Best avg r: 0.6198
06:54:18,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:55:36,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:57:06,531 root INFO Epoch 9 Global steps: 88200 Train loss: 0.1734
en_de Dev loss: 0.8911 r:0.1824
en_zh Dev loss: 0.8080 r:0.4337
ro_en Dev loss: 0.3404 r:0.8136
et_en Dev loss: 0.4730 r:0.6489
si_en Dev loss: 0.6983 r:0.5613
ne_en Dev loss: 0.5720 r:0.7247
ru_en Dev loss: 0.4489 r:0.7328
Current avg r:0.5853 Best avg r: 0.6198
07:00:57,555 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:14,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:03:45,147 root INFO Epoch 9 Global steps: 88800 Train loss: 0.1654
en_de Dev loss: 0.8904 r:0.1980
en_zh Dev loss: 0.8712 r:0.4291
ro_en Dev loss: 0.3710 r:0.8153
et_en Dev loss: 0.4667 r:0.6556
si_en Dev loss: 0.7184 r:0.5643
ne_en Dev loss: 0.5934 r:0.7224
ru_en Dev loss: 0.5075 r:0.7228
Current avg r:0.5868 Best avg r: 0.6198
07:07:36,153 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:53,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:10:23,782 root INFO Epoch 9 Global steps: 89400 Train loss: 0.1597
en_de Dev loss: 0.8993 r:0.2037
en_zh Dev loss: 0.8260 r:0.4451
ro_en Dev loss: 0.3967 r:0.8093
et_en Dev loss: 0.4987 r:0.6436
si_en Dev loss: 0.7883 r:0.5514
ne_en Dev loss: 0.6203 r:0.7104
ru_en Dev loss: 0.5037 r:0.7214
Current avg r:0.5836 Best avg r: 0.6198
07:14:14,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:15:32,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:02,410 root INFO Epoch 9 Global steps: 90000 Train loss: 0.1741
en_de Dev loss: 0.8970 r:0.2111
en_zh Dev loss: 0.8487 r:0.4524
ro_en Dev loss: 0.4004 r:0.8126
et_en Dev loss: 0.5016 r:0.6477
si_en Dev loss: 0.8038 r:0.5585
ne_en Dev loss: 0.5256 r:0.7221
ru_en Dev loss: 0.5279 r:0.7256
Current avg r:0.5900 Best avg r: 0.6198
07:20:58,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:22:16,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:23:46,529 root INFO Epoch 10 Global steps: 90600 Train loss: 0.1523
en_de Dev loss: 0.9152 r:0.1941
en_zh Dev loss: 0.8859 r:0.4452
ro_en Dev loss: 0.4266 r:0.8085
et_en Dev loss: 0.5141 r:0.6413
si_en Dev loss: 0.8513 r:0.5514
ne_en Dev loss: 0.6784 r:0.7181
ru_en Dev loss: 0.5253 r:0.7287
Current avg r:0.5839 Best avg r: 0.6198
07:27:37,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:28:54,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:25,250 root INFO Epoch 10 Global steps: 91200 Train loss: 0.1611
en_de Dev loss: 0.8958 r:0.2095
en_zh Dev loss: 0.8020 r:0.4486
ro_en Dev loss: 0.3670 r:0.8117
et_en Dev loss: 0.4711 r:0.6568
si_en Dev loss: 0.7065 r:0.5647
ne_en Dev loss: 0.5349 r:0.7210
ru_en Dev loss: 0.4838 r:0.7403
Current avg r:0.5932 Best avg r: 0.6198
07:34:16,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:35:33,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:04,189 root INFO Epoch 10 Global steps: 91800 Train loss: 0.1539
en_de Dev loss: 0.9173 r:0.1892
en_zh Dev loss: 0.7761 r:0.4566
ro_en Dev loss: 0.3624 r:0.8112
et_en Dev loss: 0.4977 r:0.6446
si_en Dev loss: 0.6933 r:0.5591
ne_en Dev loss: 0.5459 r:0.7149
ru_en Dev loss: 0.4254 r:0.7476
Current avg r:0.5890 Best avg r: 0.6198
07:40:55,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:42:12,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:43:42,980 root INFO Epoch 10 Global steps: 92400 Train loss: 0.1640
en_de Dev loss: 0.9318 r:0.1683
en_zh Dev loss: 0.8310 r:0.4455
ro_en Dev loss: 0.3739 r:0.8147
et_en Dev loss: 0.5133 r:0.6432
si_en Dev loss: 0.7246 r:0.5603
ne_en Dev loss: 0.5434 r:0.7200
ru_en Dev loss: 0.4653 r:0.7382
Current avg r:0.5843 Best avg r: 0.6198
07:47:34,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:51,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:50:21,674 root INFO Epoch 10 Global steps: 93000 Train loss: 0.1584
en_de Dev loss: 0.9195 r:0.1873
en_zh Dev loss: 0.8147 r:0.4506
ro_en Dev loss: 0.3673 r:0.8151
et_en Dev loss: 0.5018 r:0.6542
si_en Dev loss: 0.6946 r:0.5679
ne_en Dev loss: 0.5510 r:0.7238
ru_en Dev loss: 0.4597 r:0.7417
Current avg r:0.5915 Best avg r: 0.6198
07:54:12,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:55:29,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:57:00,133 root INFO Epoch 10 Global steps: 93600 Train loss: 0.1524
en_de Dev loss: 0.9162 r:0.1747
en_zh Dev loss: 0.7522 r:0.4643
ro_en Dev loss: 0.3395 r:0.8158
et_en Dev loss: 0.4654 r:0.6479
si_en Dev loss: 0.7092 r:0.5638
ne_en Dev loss: 0.5480 r:0.7206
ru_en Dev loss: 0.4339 r:0.7472
Current avg r:0.5906 Best avg r: 0.6198
08:00:52,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:10,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:40,203 root INFO Epoch 10 Global steps: 94200 Train loss: 0.1531
en_de Dev loss: 0.9050 r:0.1864
en_zh Dev loss: 0.8026 r:0.4434
ro_en Dev loss: 0.3582 r:0.8098
et_en Dev loss: 0.5009 r:0.6567
si_en Dev loss: 0.6866 r:0.5642
ne_en Dev loss: 0.5189 r:0.7222
ru_en Dev loss: 0.4332 r:0.7461
Current avg r:0.5898 Best avg r: 0.6198
08:07:32,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:50,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:20,416 root INFO Epoch 10 Global steps: 94800 Train loss: 0.1563
en_de Dev loss: 0.9505 r:0.1762
en_zh Dev loss: 0.8990 r:0.4462
ro_en Dev loss: 0.4025 r:0.8095
et_en Dev loss: 0.5073 r:0.6489
si_en Dev loss: 0.8169 r:0.5474
ne_en Dev loss: 0.5821 r:0.7169
ru_en Dev loss: 0.5352 r:0.7270
Current avg r:0.5817 Best avg r: 0.6198
08:14:11,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:28,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:58,897 root INFO Epoch 10 Global steps: 95400 Train loss: 0.1512
en_de Dev loss: 0.9221 r:0.1808
en_zh Dev loss: 0.8143 r:0.4622
ro_en Dev loss: 0.3983 r:0.8091
et_en Dev loss: 0.4762 r:0.6496
si_en Dev loss: 0.7397 r:0.5616
ne_en Dev loss: 0.6548 r:0.7124
ru_en Dev loss: 0.5044 r:0.7339
Current avg r:0.5871 Best avg r: 0.6198
08:20:49,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:22:07,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:37,487 root INFO Epoch 10 Global steps: 96000 Train loss: 0.1557
en_de Dev loss: 0.9051 r:0.1802
en_zh Dev loss: 0.8347 r:0.4415
ro_en Dev loss: 0.3805 r:0.8119
et_en Dev loss: 0.4855 r:0.6543
si_en Dev loss: 0.7051 r:0.5593
ne_en Dev loss: 0.5165 r:0.7122
ru_en Dev loss: 0.4506 r:0.7387
Current avg r:0.5854 Best avg r: 0.6198
08:27:28,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:45,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:15,950 root INFO Epoch 10 Global steps: 96600 Train loss: 0.1553
en_de Dev loss: 0.9133 r:0.2010
en_zh Dev loss: 0.8220 r:0.4585
ro_en Dev loss: 0.3934 r:0.8119
et_en Dev loss: 0.5029 r:0.6497
si_en Dev loss: 0.7677 r:0.5541
ne_en Dev loss: 0.6498 r:0.7114
ru_en Dev loss: 0.4469 r:0.7456
Current avg r:0.5903 Best avg r: 0.6198
08:34:06,915 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:24,201 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:54,371 root INFO Epoch 10 Global steps: 97200 Train loss: 0.1479
en_de Dev loss: 0.9231 r:0.1849
en_zh Dev loss: 0.8722 r:0.4436
ro_en Dev loss: 0.3879 r:0.8107
et_en Dev loss: 0.4837 r:0.6517
si_en Dev loss: 0.7962 r:0.5552
ne_en Dev loss: 0.6289 r:0.7156
ru_en Dev loss: 0.5050 r:0.7270
Current avg r:0.5841 Best avg r: 0.6198
08:40:52,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:09,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:39,844 root INFO Epoch 10 Global steps: 97800 Train loss: 0.1544
en_de Dev loss: 0.9013 r:0.1849
en_zh Dev loss: 0.7934 r:0.4431
ro_en Dev loss: 0.3423 r:0.8153
et_en Dev loss: 0.4660 r:0.6454
si_en Dev loss: 0.7109 r:0.5575
ne_en Dev loss: 0.5590 r:0.7046
ru_en Dev loss: 0.4535 r:0.7314
Current avg r:0.5832 Best avg r: 0.6198
08:47:30,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:48,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:50:18,353 root INFO Epoch 10 Global steps: 98400 Train loss: 0.1548
en_de Dev loss: 0.9443 r:0.1667
en_zh Dev loss: 0.8635 r:0.4460
ro_en Dev loss: 0.3969 r:0.8121
et_en Dev loss: 0.5119 r:0.6338
si_en Dev loss: 0.7919 r:0.5487
ne_en Dev loss: 0.6204 r:0.7113
ru_en Dev loss: 0.5385 r:0.7132
Current avg r:0.5760 Best avg r: 0.6198
08:54:09,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:55:26,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:56,803 root INFO Epoch 10 Global steps: 99000 Train loss: 0.1445
en_de Dev loss: 0.9116 r:0.2010
en_zh Dev loss: 0.8660 r:0.4438
ro_en Dev loss: 0.3831 r:0.8148
et_en Dev loss: 0.4781 r:0.6495
si_en Dev loss: 0.7763 r:0.5534
ne_en Dev loss: 0.6014 r:0.7142
ru_en Dev loss: 0.5167 r:0.7212
Current avg r:0.5854 Best avg r: 0.6198
09:00:49,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:06,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:36,524 root INFO Epoch 11 Global steps: 99600 Train loss: 0.1353
en_de Dev loss: 0.9169 r:0.2039
en_zh Dev loss: 0.8394 r:0.4507
ro_en Dev loss: 0.4000 r:0.8161
et_en Dev loss: 0.4964 r:0.6521
si_en Dev loss: 0.7498 r:0.5632
ne_en Dev loss: 0.6031 r:0.7146
ru_en Dev loss: 0.4903 r:0.7380
Current avg r:0.5912 Best avg r: 0.6198
09:07:27,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:08:44,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:14,983 root INFO Epoch 11 Global steps: 100200 Train loss: 0.1430
en_de Dev loss: 0.9023 r:0.1794
en_zh Dev loss: 0.8343 r:0.4497
ro_en Dev loss: 0.3935 r:0.8157
et_en Dev loss: 0.5026 r:0.6488
si_en Dev loss: 0.7483 r:0.5596
ne_en Dev loss: 0.5973 r:0.7120
ru_en Dev loss: 0.5018 r:0.7285
Current avg r:0.5848 Best avg r: 0.6198
09:14:06,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:23,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:53,489 root INFO Epoch 11 Global steps: 100800 Train loss: 0.1403
en_de Dev loss: 0.9364 r:0.1751
en_zh Dev loss: 0.8564 r:0.4411
ro_en Dev loss: 0.4049 r:0.8099
et_en Dev loss: 0.5057 r:0.6388
si_en Dev loss: 0.7878 r:0.5584
ne_en Dev loss: 0.6419 r:0.7161
ru_en Dev loss: 0.5136 r:0.7244
Current avg r:0.5805 Best avg r: 0.6198
09:20:44,454 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:22:01,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:23:31,925 root INFO Epoch 11 Global steps: 101400 Train loss: 0.1439
en_de Dev loss: 0.9550 r:0.1745
en_zh Dev loss: 0.9268 r:0.4431
ro_en Dev loss: 0.3723 r:0.8129
et_en Dev loss: 0.5013 r:0.6431
si_en Dev loss: 0.7753 r:0.5628
ne_en Dev loss: 0.6168 r:0.7194
ru_en Dev loss: 0.4948 r:0.7343
Current avg r:0.5843 Best avg r: 0.6198
09:27:22,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:28:40,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:30:10,340 root INFO Epoch 11 Global steps: 102000 Train loss: 0.1349
en_de Dev loss: 0.9491 r:0.1872
en_zh Dev loss: 0.8477 r:0.4667
ro_en Dev loss: 0.4000 r:0.8142
et_en Dev loss: 0.4942 r:0.6499
si_en Dev loss: 0.8131 r:0.5614
ne_en Dev loss: 0.6596 r:0.7113
ru_en Dev loss: 0.5359 r:0.7325
Current avg r:0.5890 Best avg r: 0.6198
09:34:01,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:18,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:48,812 root INFO Epoch 11 Global steps: 102600 Train loss: 0.1506
en_de Dev loss: 0.9505 r:0.1804
en_zh Dev loss: 0.8339 r:0.4614
ro_en Dev loss: 0.3788 r:0.8111
et_en Dev loss: 0.5301 r:0.6469
si_en Dev loss: 0.7372 r:0.5676
ne_en Dev loss: 0.5874 r:0.7160
ru_en Dev loss: 0.4697 r:0.7412
Current avg r:0.5892 Best avg r: 0.6198
09:40:42,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:00,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:31,152 root INFO Epoch 11 Global steps: 103200 Train loss: 0.1386
en_de Dev loss: 0.9524 r:0.1634
en_zh Dev loss: 0.8110 r:0.4621
ro_en Dev loss: 0.3926 r:0.8094
et_en Dev loss: 0.5200 r:0.6360
si_en Dev loss: 0.7639 r:0.5593
ne_en Dev loss: 0.6110 r:0.7115
ru_en Dev loss: 0.4761 r:0.7394
Current avg r:0.5830 Best avg r: 0.6198
09:47:22,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:40,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:50:10,459 root INFO Epoch 11 Global steps: 103800 Train loss: 0.1405
en_de Dev loss: 0.9300 r:0.1853
en_zh Dev loss: 0.8600 r:0.4576
ro_en Dev loss: 0.3828 r:0.8091
et_en Dev loss: 0.5332 r:0.6475
si_en Dev loss: 0.7982 r:0.5562
ne_en Dev loss: 0.6401 r:0.7094
ru_en Dev loss: 0.4930 r:0.7326
Current avg r:0.5854 Best avg r: 0.6198
09:54:01,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:19,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:49,856 root INFO Epoch 11 Global steps: 104400 Train loss: 0.1411
en_de Dev loss: 0.9322 r:0.1739
en_zh Dev loss: 0.8682 r:0.4547
ro_en Dev loss: 0.3931 r:0.8127
et_en Dev loss: 0.5068 r:0.6447
si_en Dev loss: 0.8192 r:0.5610
ne_en Dev loss: 0.5876 r:0.7106
ru_en Dev loss: 0.5264 r:0.7346
Current avg r:0.5846 Best avg r: 0.6198
10:00:48,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:06,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:36,723 root INFO Epoch 11 Global steps: 105000 Train loss: 0.1347
en_de Dev loss: 0.9205 r:0.1625
en_zh Dev loss: 0.8270 r:0.4470
ro_en Dev loss: 0.3822 r:0.8099
et_en Dev loss: 0.5132 r:0.6402
si_en Dev loss: 0.7856 r:0.5521
ne_en Dev loss: 0.5946 r:0.7112
ru_en Dev loss: 0.4553 r:0.7348
Current avg r:0.5796 Best avg r: 0.6198
10:07:31,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:48,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:18,745 root INFO Epoch 11 Global steps: 105600 Train loss: 0.1383
en_de Dev loss: 0.9325 r:0.1566
en_zh Dev loss: 0.8042 r:0.4529
ro_en Dev loss: 0.3929 r:0.8090
et_en Dev loss: 0.5170 r:0.6277
si_en Dev loss: 0.8097 r:0.5482
ne_en Dev loss: 0.5961 r:0.7154
ru_en Dev loss: 0.4530 r:0.7389
Current avg r:0.5784 Best avg r: 0.6198
10:14:09,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:15:27,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:16:57,330 root INFO Epoch 11 Global steps: 106200 Train loss: 0.1391
en_de Dev loss: 0.9582 r:0.1706
en_zh Dev loss: 0.8845 r:0.4424
ro_en Dev loss: 0.4154 r:0.8081
et_en Dev loss: 0.5304 r:0.6250
si_en Dev loss: 0.8333 r:0.5529
ne_en Dev loss: 0.6086 r:0.7163
ru_en Dev loss: 0.5117 r:0.7280
Current avg r:0.5776 Best avg r: 0.6198
10:20:48,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:22:05,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:35,899 root INFO Epoch 11 Global steps: 106800 Train loss: 0.1306
en_de Dev loss: 0.9640 r:0.1579
en_zh Dev loss: 0.8546 r:0.4515
ro_en Dev loss: 0.3960 r:0.8133
et_en Dev loss: 0.5056 r:0.6372
si_en Dev loss: 0.8378 r:0.5557
ne_en Dev loss: 0.6255 r:0.7118
ru_en Dev loss: 0.5188 r:0.7246
Current avg r:0.5788 Best avg r: 0.6198
10:27:27,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:44,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:14,560 root INFO Epoch 11 Global steps: 107400 Train loss: 0.1391
en_de Dev loss: 0.8993 r:0.1768
en_zh Dev loss: 0.8251 r:0.4499
ro_en Dev loss: 0.3861 r:0.8098
et_en Dev loss: 0.5216 r:0.6363
si_en Dev loss: 0.8144 r:0.5521
ne_en Dev loss: 0.6267 r:0.7162
ru_en Dev loss: 0.5240 r:0.7180
Current avg r:0.5799 Best avg r: 0.6198
