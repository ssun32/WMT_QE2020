14:43:50,70 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:15,826 root INFO 
id:en_de cur r: 0.0667 best r: 0.0667
14:44:41,555 root INFO 
id:ro_en cur r: 0.6169 best r: 0.6169
14:44:54,440 root INFO 
id:et_en cur r: 0.4872 best r: 0.4872
14:45:07,333 root INFO 
id:si_en cur r: 0.4339 best r: 0.4339
14:45:20,233 root INFO 
id:ne_en cur r: 0.6313 best r: 0.6313
14:45:33,69 root INFO 
id:ru_en cur r: 0.5005 best r: 0.5005
14:45:33,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:03,118 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
14:47:03,124 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:47:03,129 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:47:03,133 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
14:47:03,138 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
14:47:03,144 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:47:03,151 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:47:16,42 root INFO Epoch 0 Global steps: 700 Train loss: 0.8517
en_de Dev loss: 0.9241 r:0.0684
en_zh Dev loss: 0.7705 r:0.2484
ro_en Dev loss: 0.6253 r:0.6262
et_en Dev loss: 0.5161 r:0.5238
si_en Dev loss: 0.6933 r:0.4477
ne_en Dev loss: 0.5178 r:0.6383
ru_en Dev loss: 0.6315 r:0.5653
Current avg r:0.4455 Best avg r: 0.4455
14:51:45,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:11,512 root INFO 
id:en_de cur r: 0.0934 best r: 0.0934
14:52:24,357 root INFO 
id:en_zh cur r: 0.2206 best r: 0.2206
14:52:50,123 root INFO 
id:et_en cur r: 0.5122 best r: 0.5122
14:53:28,794 root INFO 
id:ru_en cur r: 0.5132 best r: 0.5132
14:53:28,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:59,17 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
14:54:59,23 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:54:59,29 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:54:59,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
14:54:59,42 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
14:54:59,46 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:54:59,53 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:55:11,937 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8250
en_de Dev loss: 0.9020 r:0.0944
en_zh Dev loss: 0.7427 r:0.3202
ro_en Dev loss: 0.6782 r:0.6346
et_en Dev loss: 0.5385 r:0.5630
si_en Dev loss: 0.7595 r:0.4679
ne_en Dev loss: 0.5835 r:0.6220
ru_en Dev loss: 0.6475 r:0.6057
Current avg r:0.4725 Best avg r: 0.4725
14:59:41,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:33,279 root INFO 
id:et_en cur r: 0.5518 best r: 0.5518
15:00:46,224 root INFO 
id:si_en cur r: 0.4408 best r: 0.4408
15:01:11,991 root INFO 
id:ru_en cur r: 0.6512 best r: 0.6512
15:01:11,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:42,218 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:02:42,224 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:02:42,230 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:02:42,234 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:02:42,239 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:02:42,244 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:02:42,249 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:02:55,123 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7894
en_de Dev loss: 1.0209 r:0.1289
en_zh Dev loss: 0.8064 r:0.3145
ro_en Dev loss: 0.7082 r:0.6263
et_en Dev loss: 0.4996 r:0.6146
si_en Dev loss: 0.7399 r:0.4912
ne_en Dev loss: 0.5296 r:0.6421
ru_en Dev loss: 0.6323 r:0.6671
Current avg r:0.4978 Best avg r: 0.4978
15:07:24,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:50,630 root INFO 
id:en_de cur r: 0.1721 best r: 0.1721
15:08:03,492 root INFO 
id:en_zh cur r: 0.3344 best r: 0.3344
15:08:16,383 root INFO 
id:ro_en cur r: 0.6957 best r: 0.6957
15:08:29,283 root INFO 
id:et_en cur r: 0.6260 best r: 0.6260
15:08:42,198 root INFO 
id:si_en cur r: 0.5278 best r: 0.5278
15:08:55,111 root INFO 
id:ne_en cur r: 0.6870 best r: 0.6870
15:09:07,950 root INFO 
id:ru_en cur r: 0.6818 best r: 0.6818
15:09:07,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:38,18 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:10:38,27 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:10:38,32 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:10:38,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:10:38,41 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:10:38,48 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:10:38,62 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:10:50,948 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6969
en_de Dev loss: 0.9174 r:0.1645
en_zh Dev loss: 0.7094 r:0.3755
ro_en Dev loss: 0.5040 r:0.7026
et_en Dev loss: 0.4037 r:0.6643
si_en Dev loss: 0.6318 r:0.5381
ne_en Dev loss: 0.4244 r:0.6940
ru_en Dev loss: 0.5117 r:0.7040
Current avg r:0.5490 Best avg r: 0.5490
15:15:20,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:50,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:20,888 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6771
en_de Dev loss: 0.9488 r:0.1395
en_zh Dev loss: 0.7707 r:0.3369
ro_en Dev loss: 0.5542 r:0.6970
et_en Dev loss: 0.4259 r:0.6528
si_en Dev loss: 0.7533 r:0.5178
ne_en Dev loss: 0.5087 r:0.6565
ru_en Dev loss: 0.5554 r:0.6906
Current avg r:0.5273 Best avg r: 0.5490
15:22:50,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:16,440 root INFO 
id:en_zh cur r: 0.3366 best r: 0.3366
15:23:29,318 root INFO 
id:ro_en cur r: 0.7297 best r: 0.7297
15:23:42,206 root INFO 
id:et_en cur r: 0.6634 best r: 0.6634
15:23:55,104 root INFO 
id:si_en cur r: 0.5649 best r: 0.5649
15:24:08,6 root INFO 
id:ne_en cur r: 0.7063 best r: 0.7063
15:24:20,837 root INFO 
id:ru_en cur r: 0.6937 best r: 0.6937
15:24:20,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:50,900 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:25:50,907 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:25:50,912 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:25:50,917 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:25:50,921 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:25:50,926 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:25:50,930 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:26:03,815 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6138
en_de Dev loss: 0.9558 r:0.1724
en_zh Dev loss: 0.7598 r:0.3707
ro_en Dev loss: 0.4423 r:0.7412
et_en Dev loss: 0.3774 r:0.6942
si_en Dev loss: 0.6833 r:0.5809
ne_en Dev loss: 0.4448 r:0.6987
ru_en Dev loss: 0.5061 r:0.7211
Current avg r:0.5684 Best avg r: 0.5684
15:30:33,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:59,388 root INFO 
id:en_zh cur r: 0.3525 best r: 0.3525
15:32:03,774 root INFO 
id:ru_en cur r: 0.6976 best r: 0.6976
15:32:03,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:33,822 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:33:33,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:33:33,840 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:33:33,844 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:33:33,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:33:33,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:33:33,859 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:33:46,740 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6074
en_de Dev loss: 0.9252 r:0.1788
en_zh Dev loss: 0.7293 r:0.3829
ro_en Dev loss: 0.4764 r:0.7268
et_en Dev loss: 0.3787 r:0.6959
si_en Dev loss: 0.6384 r:0.5766
ne_en Dev loss: 0.5085 r:0.6917
ru_en Dev loss: 0.4666 r:0.7349
Current avg r:0.5697 Best avg r: 0.5697
15:38:16,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:42,406 root INFO 
id:en_de cur r: 0.1722 best r: 0.1722
15:38:55,258 root INFO 
id:en_zh cur r: 0.3828 best r: 0.3828
15:39:08,136 root INFO 
id:ro_en cur r: 0.7489 best r: 0.7489
15:39:21,33 root INFO 
id:et_en cur r: 0.6647 best r: 0.6647
15:39:46,818 root INFO 
id:ne_en cur r: 0.7104 best r: 0.7104
15:39:59,649 root INFO 
id:ru_en cur r: 0.7037 best r: 0.7037
15:39:59,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:29,717 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:41:29,723 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:41:29,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:41:29,733 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:41:29,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:41:29,742 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:41:29,746 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:41:42,626 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6220
en_de Dev loss: 0.9584 r:0.1731
en_zh Dev loss: 0.7004 r:0.4093
ro_en Dev loss: 0.4126 r:0.7517
et_en Dev loss: 0.3665 r:0.6960
si_en Dev loss: 0.6229 r:0.5772
ne_en Dev loss: 0.4030 r:0.7097
ru_en Dev loss: 0.4280 r:0.7336
Current avg r:0.5786 Best avg r: 0.5786
15:46:12,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:38,414 root INFO 
id:en_de cur r: 0.1939 best r: 0.1939
15:47:04,158 root INFO 
id:ro_en cur r: 0.7608 best r: 0.7608
15:47:17,56 root INFO 
id:et_en cur r: 0.6742 best r: 0.6742
15:47:42,858 root INFO 
id:ne_en cur r: 0.7244 best r: 0.7244
15:47:55,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:25,843 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:49:25,850 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:49:25,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:49:25,858 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:49:25,863 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:49:25,868 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:49:25,873 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:49:38,770 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5551
en_de Dev loss: 0.9560 r:0.1753
en_zh Dev loss: 0.7559 r:0.3988
ro_en Dev loss: 0.4238 r:0.7627
et_en Dev loss: 0.3708 r:0.6980
si_en Dev loss: 0.7334 r:0.5834
ne_en Dev loss: 0.4419 r:0.7143
ru_en Dev loss: 0.4593 r:0.7191
Current avg r:0.5788 Best avg r: 0.5788
15:54:08,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:34,599 root INFO 
id:en_de cur r: 0.1967 best r: 0.1967
15:54:47,469 root INFO 
id:en_zh cur r: 0.4054 best r: 0.4054
15:55:00,356 root INFO 
id:ro_en cur r: 0.7817 best r: 0.7817
15:55:13,256 root INFO 
id:et_en cur r: 0.7126 best r: 0.7126
15:55:26,176 root INFO 
id:si_en cur r: 0.5964 best r: 0.5964
15:55:39,97 root INFO 
id:ne_en cur r: 0.7503 best r: 0.7503
15:55:51,939 root INFO 
id:ru_en cur r: 0.7281 best r: 0.7281
15:55:51,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:22,137 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:57:22,146 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:57:22,150 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:57:22,155 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:57:22,160 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:57:22,165 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:57:22,171 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:57:35,73 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5795
en_de Dev loss: 0.9690 r:0.1933
en_zh Dev loss: 0.7358 r:0.4115
ro_en Dev loss: 0.3547 r:0.7829
et_en Dev loss: 0.3513 r:0.7202
si_en Dev loss: 0.5601 r:0.6062
ne_en Dev loss: 0.3680 r:0.7351
ru_en Dev loss: 0.4210 r:0.7373
Current avg r:0.5981 Best avg r: 0.5981
16:02:05,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:02:30,843 root INFO 
id:en_de cur r: 0.2058 best r: 0.2058
16:03:48,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:18,319 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5455
en_de Dev loss: 0.9617 r:0.1981
en_zh Dev loss: 0.7663 r:0.3980
ro_en Dev loss: 0.3990 r:0.7728
et_en Dev loss: 0.3626 r:0.7035
si_en Dev loss: 0.6663 r:0.5896
ne_en Dev loss: 0.4418 r:0.7214
ru_en Dev loss: 0.4722 r:0.7188
Current avg r:0.5860 Best avg r: 0.5981
16:09:48,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:14,56 root INFO 
id:en_de cur r: 0.2094 best r: 0.2094
16:10:26,914 root INFO 
id:en_zh cur r: 0.4082 best r: 0.4082
16:10:39,804 root INFO 
id:ro_en cur r: 0.7878 best r: 0.7878
16:11:31,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:01,506 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5084
en_de Dev loss: 0.9542 r:0.1988
en_zh Dev loss: 0.7440 r:0.4131
ro_en Dev loss: 0.3570 r:0.7868
et_en Dev loss: 0.3586 r:0.7114
si_en Dev loss: 0.7310 r:0.5912
ne_en Dev loss: 0.4085 r:0.7315
ru_en Dev loss: 0.4421 r:0.7396
Current avg r:0.5961 Best avg r: 0.5981
16:17:31,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:57,136 root INFO 
id:en_zh cur r: 0.4258 best r: 0.4258
16:18:10,17 root INFO 
id:ro_en cur r: 0.8016 best r: 0.8016
16:18:22,914 root INFO 
id:et_en cur r: 0.7287 best r: 0.7287
16:18:35,830 root INFO 
id:si_en cur r: 0.6082 best r: 0.6082
16:18:48,733 root INFO 
id:ne_en cur r: 0.7606 best r: 0.7606
16:19:01,564 root INFO 
id:ru_en cur r: 0.7576 best r: 0.7576
16:19:01,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:31,606 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
16:20:31,613 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:20:31,618 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:20:31,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
16:20:31,629 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
16:20:31,633 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:20:31,637 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:20:44,516 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5323
en_de Dev loss: 0.9382 r:0.1975
en_zh Dev loss: 0.7011 r:0.4296
ro_en Dev loss: 0.3228 r:0.8000
et_en Dev loss: 0.3478 r:0.7271
si_en Dev loss: 0.6018 r:0.6065
ne_en Dev loss: 0.3553 r:0.7462
ru_en Dev loss: 0.3685 r:0.7587
Current avg r:0.6094 Best avg r: 0.6094
16:25:14,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:44,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:14,542 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5191
en_de Dev loss: 0.9737 r:0.1899
en_zh Dev loss: 0.7625 r:0.4179
ro_en Dev loss: 0.3439 r:0.7966
et_en Dev loss: 0.3424 r:0.7179
si_en Dev loss: 0.6331 r:0.6046
ne_en Dev loss: 0.3892 r:0.7414
ru_en Dev loss: 0.4648 r:0.7346
Current avg r:0.6004 Best avg r: 0.6094
16:32:44,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:10,190 root INFO 
id:en_de cur r: 0.2110 best r: 0.2110
16:33:23,40 root INFO 
id:en_zh cur r: 0.4457 best r: 0.4457
16:33:35,921 root INFO 
id:ro_en cur r: 0.8072 best r: 0.8072
16:34:01,724 root INFO 
id:si_en cur r: 0.6170 best r: 0.6170
16:34:14,618 root INFO 
id:ne_en cur r: 0.7680 best r: 0.7680
16:34:27,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:57,509 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
16:35:57,519 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:35:57,526 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:35:57,533 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
16:35:57,537 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
16:35:57,543 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:35:57,547 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:36:10,426 root INFO Epoch 0 Global steps: 10500 Train loss: 0.4884
en_de Dev loss: 0.9210 r:0.1996
en_zh Dev loss: 0.6883 r:0.4407
ro_en Dev loss: 0.3200 r:0.8080
et_en Dev loss: 0.3359 r:0.7257
si_en Dev loss: 0.6018 r:0.6154
ne_en Dev loss: 0.3936 r:0.7553
ru_en Dev loss: 0.4073 r:0.7521
Current avg r:0.6138 Best avg r: 0.6138
16:40:42,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:12,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:42,271 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4695
en_de Dev loss: 0.9283 r:0.1924
en_zh Dev loss: 0.7090 r:0.4375
ro_en Dev loss: 0.3126 r:0.8083
et_en Dev loss: 0.3469 r:0.7133
si_en Dev loss: 0.6356 r:0.6115
ne_en Dev loss: 0.4209 r:0.7506
ru_en Dev loss: 0.4222 r:0.7380
Current avg r:0.6074 Best avg r: 0.6138
16:48:12,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:50,801 root INFO 
id:ro_en cur r: 0.8139 best r: 0.8139
16:49:42,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:12,375 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4484
en_de Dev loss: 0.9465 r:0.1994
en_zh Dev loss: 0.7080 r:0.4404
ro_en Dev loss: 0.3082 r:0.8131
et_en Dev loss: 0.3453 r:0.7177
si_en Dev loss: 0.5921 r:0.6149
ne_en Dev loss: 0.3967 r:0.7536
ru_en Dev loss: 0.4116 r:0.7406
Current avg r:0.6114 Best avg r: 0.6138
16:55:42,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:21,78 root INFO 
id:ro_en cur r: 0.8162 best r: 0.8162
16:56:46,866 root INFO 
id:si_en cur r: 0.6178 best r: 0.6178
16:57:12,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:42,721 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4674
en_de Dev loss: 0.9854 r:0.1872
en_zh Dev loss: 0.7518 r:0.4267
ro_en Dev loss: 0.3524 r:0.8102
et_en Dev loss: 0.3747 r:0.7159
si_en Dev loss: 0.5657 r:0.6201
ne_en Dev loss: 0.3572 r:0.7594
ru_en Dev loss: 0.4474 r:0.7290
Current avg r:0.6069 Best avg r: 0.6138
17:03:12,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:38,544 root INFO 
id:en_de cur r: 0.2147 best r: 0.2147
17:04:55,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:26,74 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4472
en_de Dev loss: 0.9649 r:0.2034
en_zh Dev loss: 0.7492 r:0.4330
ro_en Dev loss: 0.3510 r:0.8053
et_en Dev loss: 0.3660 r:0.7053
si_en Dev loss: 0.6724 r:0.6031
ne_en Dev loss: 0.4319 r:0.7447
ru_en Dev loss: 0.4697 r:0.7201
Current avg r:0.6021 Best avg r: 0.6138
17:10:56,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:21,919 root INFO 
id:en_zh cur r: 0.4529 best r: 0.4529
17:11:34,816 root INFO 
id:ro_en cur r: 0.8202 best r: 0.8202
17:12:00,636 root INFO 
id:si_en cur r: 0.6254 best r: 0.6254
17:12:13,552 root INFO 
id:ne_en cur r: 0.7692 best r: 0.7692
17:12:26,399 root INFO 
id:ru_en cur r: 0.7612 best r: 0.7612
17:12:26,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:56,601 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
17:13:56,607 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:13:56,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:13:56,617 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
17:13:56,622 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
17:13:56,627 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:13:56,631 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:14:09,534 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4376
en_de Dev loss: 0.9386 r:0.1997
en_zh Dev loss: 0.6736 r:0.4533
ro_en Dev loss: 0.2960 r:0.8177
et_en Dev loss: 0.3476 r:0.7227
si_en Dev loss: 0.5622 r:0.6269
ne_en Dev loss: 0.3595 r:0.7580
ru_en Dev loss: 0.3693 r:0.7600
Current avg r:0.6198 Best avg r: 0.6198
17:18:39,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:05,413 root INFO 
id:en_de cur r: 0.2308 best r: 0.2308
17:20:22,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:52,890 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4388
en_de Dev loss: 0.9166 r:0.2179
en_zh Dev loss: 0.7042 r:0.4393
ro_en Dev loss: 0.3241 r:0.8120
et_en Dev loss: 0.3488 r:0.7152
si_en Dev loss: 0.6614 r:0.6165
ne_en Dev loss: 0.4259 r:0.7502
ru_en Dev loss: 0.4448 r:0.7197
Current avg r:0.6101 Best avg r: 0.6198
17:26:22,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:27,364 root INFO 
id:si_en cur r: 0.6291 best r: 0.6291
17:27:40,273 root INFO 
id:ne_en cur r: 0.7717 best r: 0.7717
17:27:53,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:23,234 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4420
en_de Dev loss: 0.9324 r:0.2111
en_zh Dev loss: 0.6950 r:0.4496
ro_en Dev loss: 0.3266 r:0.8140
et_en Dev loss: 0.3505 r:0.7204
si_en Dev loss: 0.6120 r:0.6350
ne_en Dev loss: 0.3789 r:0.7637
ru_en Dev loss: 0.4175 r:0.7344
Current avg r:0.6183 Best avg r: 0.6198
17:33:53,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:23,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:53,605 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4178
en_de Dev loss: 0.9260 r:0.2150
en_zh Dev loss: 0.7168 r:0.4428
ro_en Dev loss: 0.3131 r:0.8150
et_en Dev loss: 0.3514 r:0.7144
si_en Dev loss: 0.6729 r:0.6188
ne_en Dev loss: 0.4210 r:0.7556
ru_en Dev loss: 0.4420 r:0.7296
Current avg r:0.6130 Best avg r: 0.6198
17:41:23,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:53,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:23,899 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4225
en_de Dev loss: 0.9591 r:0.1990
en_zh Dev loss: 0.7246 r:0.4399
ro_en Dev loss: 0.3320 r:0.8121
et_en Dev loss: 0.3591 r:0.7077
si_en Dev loss: 0.6738 r:0.6088
ne_en Dev loss: 0.4355 r:0.7498
ru_en Dev loss: 0.4516 r:0.7262
Current avg r:0.6062 Best avg r: 0.6198
17:48:53,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:24,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:54,208 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4274
en_de Dev loss: 1.0156 r:0.1937
en_zh Dev loss: 0.7365 r:0.4464
ro_en Dev loss: 0.3681 r:0.8098
et_en Dev loss: 0.3800 r:0.7116
si_en Dev loss: 0.6210 r:0.6188
ne_en Dev loss: 0.4132 r:0.7572
ru_en Dev loss: 0.4434 r:0.7391
Current avg r:0.6109 Best avg r: 0.6198
17:56:24,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:54,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:24,462 root INFO Epoch 1 Global steps: 18200 Train loss: 0.3994
en_de Dev loss: 0.9734 r:0.2006
en_zh Dev loss: 0.7181 r:0.4448
ro_en Dev loss: 0.3347 r:0.8099
et_en Dev loss: 0.3615 r:0.7074
si_en Dev loss: 0.6327 r:0.6086
ne_en Dev loss: 0.3680 r:0.7607
ru_en Dev loss: 0.4104 r:0.7472
Current avg r:0.6113 Best avg r: 0.6198
18:03:54,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:33,194 root INFO 
id:ro_en cur r: 0.8296 best r: 0.8296
18:05:11,896 root INFO 
id:ne_en cur r: 0.7763 best r: 0.7763
18:05:24,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:54,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
18:06:54,859 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:06:54,864 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:06:54,868 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
18:06:54,873 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
18:06:54,877 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:06:54,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:07:07,771 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4204
en_de Dev loss: 0.9476 r:0.2171
en_zh Dev loss: 0.7111 r:0.4469
ro_en Dev loss: 0.3106 r:0.8265
et_en Dev loss: 0.3511 r:0.7178
si_en Dev loss: 0.6413 r:0.6202
ne_en Dev loss: 0.3772 r:0.7695
ru_en Dev loss: 0.4170 r:0.7424
Current avg r:0.6201 Best avg r: 0.6201
18:11:37,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:07,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:38,9 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4247
en_de Dev loss: 0.9655 r:0.2103
en_zh Dev loss: 0.7740 r:0.4217
ro_en Dev loss: 0.3255 r:0.8225
et_en Dev loss: 0.3518 r:0.7169
si_en Dev loss: 0.7079 r:0.6096
ne_en Dev loss: 0.4312 r:0.7610
ru_en Dev loss: 0.4638 r:0.7131
Current avg r:0.6079 Best avg r: 0.6201
18:19:08,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:38,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:08,321 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4024
en_de Dev loss: 0.9962 r:0.1991
en_zh Dev loss: 0.7445 r:0.4467
ro_en Dev loss: 0.3520 r:0.8190
et_en Dev loss: 0.3786 r:0.7090
si_en Dev loss: 0.7722 r:0.6100
ne_en Dev loss: 0.5332 r:0.7534
ru_en Dev loss: 0.4909 r:0.7119
Current avg r:0.6070 Best avg r: 0.6201
18:26:38,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:08,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:38,678 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4162
en_de Dev loss: 1.0417 r:0.1903
en_zh Dev loss: 0.7995 r:0.4221
ro_en Dev loss: 0.4189 r:0.8058
et_en Dev loss: 0.3901 r:0.7054
si_en Dev loss: 0.7902 r:0.6019
ne_en Dev loss: 0.5203 r:0.7601
ru_en Dev loss: 0.4895 r:0.7133
Current avg r:0.5998 Best avg r: 0.6201
18:34:09,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:35,649 root INFO 
id:en_zh cur r: 0.4547 best r: 0.4547
18:35:40,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:10,236 root INFO Epoch 2 Global steps: 21700 Train loss: 0.3688
en_de Dev loss: 0.9352 r:0.2047
en_zh Dev loss: 0.6869 r:0.4580
ro_en Dev loss: 0.3056 r:0.8194
et_en Dev loss: 0.3570 r:0.7198
si_en Dev loss: 0.6138 r:0.6245
ne_en Dev loss: 0.3941 r:0.7689
ru_en Dev loss: 0.4013 r:0.7398
Current avg r:0.6193 Best avg r: 0.6201
18:41:40,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:05,975 root INFO 
id:en_zh cur r: 0.4619 best r: 0.4619
18:43:10,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:40,561 root INFO Epoch 2 Global steps: 22400 Train loss: 0.3730
en_de Dev loss: 0.9436 r:0.2183
en_zh Dev loss: 0.6839 r:0.4630
ro_en Dev loss: 0.3157 r:0.8176
et_en Dev loss: 0.3685 r:0.7087
si_en Dev loss: 0.6944 r:0.6152
ne_en Dev loss: 0.3692 r:0.7610
ru_en Dev loss: 0.4400 r:0.7251
Current avg r:0.6156 Best avg r: 0.6201
18:49:10,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:40,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:10,905 root INFO Epoch 2 Global steps: 23100 Train loss: 0.3820
en_de Dev loss: 0.9742 r:0.2063
en_zh Dev loss: 0.7288 r:0.4528
ro_en Dev loss: 0.3269 r:0.8178
et_en Dev loss: 0.3706 r:0.7032
si_en Dev loss: 0.6554 r:0.6213
ne_en Dev loss: 0.4334 r:0.7654
ru_en Dev loss: 0.4478 r:0.7261
Current avg r:0.6133 Best avg r: 0.6201
18:56:40,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:11,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:41,229 root INFO Epoch 2 Global steps: 23800 Train loss: 0.3757
en_de Dev loss: 0.9771 r:0.1917
en_zh Dev loss: 0.7157 r:0.4526
ro_en Dev loss: 0.3202 r:0.8202
et_en Dev loss: 0.3768 r:0.7062
si_en Dev loss: 0.6880 r:0.6175
ne_en Dev loss: 0.3952 r:0.7628
ru_en Dev loss: 0.4412 r:0.7226
Current avg r:0.6105 Best avg r: 0.6201
19:04:10,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:36,541 root INFO 
id:en_zh cur r: 0.4639 best r: 0.4639
19:05:40,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:10,958 root INFO Epoch 2 Global steps: 24500 Train loss: 0.3679
en_de Dev loss: 0.9585 r:0.1951
en_zh Dev loss: 0.6902 r:0.4592
ro_en Dev loss: 0.2967 r:0.8232
et_en Dev loss: 0.3724 r:0.7051
si_en Dev loss: 0.6433 r:0.6156
ne_en Dev loss: 0.3661 r:0.7683
ru_en Dev loss: 0.4516 r:0.7078
Current avg r:0.6106 Best avg r: 0.6201
19:11:40,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:10,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:40,961 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3678
en_de Dev loss: 1.0056 r:0.1881
en_zh Dev loss: 0.7660 r:0.4492
ro_en Dev loss: 0.3341 r:0.8211
et_en Dev loss: 0.3765 r:0.7034
si_en Dev loss: 0.6547 r:0.6294
ne_en Dev loss: 0.3914 r:0.7649
ru_en Dev loss: 0.4438 r:0.7286
Current avg r:0.6121 Best avg r: 0.6201
19:19:10,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:41,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:11,182 root INFO Epoch 2 Global steps: 25900 Train loss: 0.3693
en_de Dev loss: 1.0150 r:0.1930
en_zh Dev loss: 0.7677 r:0.4422
ro_en Dev loss: 0.3544 r:0.8096
et_en Dev loss: 0.3871 r:0.6914
si_en Dev loss: 0.7578 r:0.6020
ne_en Dev loss: 0.5038 r:0.7535
ru_en Dev loss: 0.5138 r:0.7012
Current avg r:0.5990 Best avg r: 0.6201
19:26:41,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:07,17 root INFO 
id:en_zh cur r: 0.4670 best r: 0.4670
19:28:11,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:41,589 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3705
en_de Dev loss: 0.9968 r:0.1915
en_zh Dev loss: 0.7070 r:0.4639
ro_en Dev loss: 0.3095 r:0.8220
et_en Dev loss: 0.3754 r:0.7021
si_en Dev loss: 0.6456 r:0.6215
ne_en Dev loss: 0.4475 r:0.7571
ru_en Dev loss: 0.4527 r:0.7334
Current avg r:0.6131 Best avg r: 0.6201
19:34:11,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:41,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:12,30 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3537
en_de Dev loss: 0.9521 r:0.1965
en_zh Dev loss: 0.6802 r:0.4636
ro_en Dev loss: 0.2906 r:0.8244
et_en Dev loss: 0.3583 r:0.7111
si_en Dev loss: 0.5626 r:0.6340
ne_en Dev loss: 0.3996 r:0.7618
ru_en Dev loss: 0.4133 r:0.7373
Current avg r:0.6184 Best avg r: 0.6201
19:41:42,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:07,972 root INFO 
id:en_zh cur r: 0.4703 best r: 0.4703
19:43:12,406 root INFO 
id:ru_en cur r: 0.7666 best r: 0.7666
19:43:12,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:42,585 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
19:44:42,591 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
19:44:42,608 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
19:44:42,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
19:44:42,619 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
19:44:42,626 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
19:44:42,632 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
19:44:55,554 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3464
en_de Dev loss: 1.0015 r:0.2186
en_zh Dev loss: 0.7458 r:0.4679
ro_en Dev loss: 0.3293 r:0.8242
et_en Dev loss: 0.3664 r:0.7148
si_en Dev loss: 0.7121 r:0.6215
ne_en Dev loss: 0.3862 r:0.7663
ru_en Dev loss: 0.4082 r:0.7591
Current avg r:0.6246 Best avg r: 0.6246
19:49:25,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:51,481 root INFO 
id:en_zh cur r: 0.4782 best r: 0.4782
19:50:55,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:26,132 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3626
en_de Dev loss: 1.0135 r:0.2143
en_zh Dev loss: 0.7559 r:0.4753
ro_en Dev loss: 0.3471 r:0.8246
et_en Dev loss: 0.3727 r:0.7130
si_en Dev loss: 0.7209 r:0.6213
ne_en Dev loss: 0.4551 r:0.7645
ru_en Dev loss: 0.4306 r:0.7513
Current avg r:0.6235 Best avg r: 0.6246
19:56:56,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:13,571 root INFO 
id:ne_en cur r: 0.7764 best r: 0.7764
19:58:26,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:56,583 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3478
en_de Dev loss: 0.9872 r:0.2183
en_zh Dev loss: 0.7468 r:0.4613
ro_en Dev loss: 0.3390 r:0.8227
et_en Dev loss: 0.3586 r:0.7154
si_en Dev loss: 0.7100 r:0.6238
ne_en Dev loss: 0.4311 r:0.7717
ru_en Dev loss: 0.4537 r:0.7361
Current avg r:0.6213 Best avg r: 0.6246
20:04:26,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:56,826 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:26,958 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3621
en_de Dev loss: 1.0003 r:0.2130
en_zh Dev loss: 0.7396 r:0.4660
ro_en Dev loss: 0.3711 r:0.8151
et_en Dev loss: 0.4038 r:0.6920
si_en Dev loss: 0.8181 r:0.6054
ne_en Dev loss: 0.5065 r:0.7543
ru_en Dev loss: 0.4170 r:0.7421
Current avg r:0.6126 Best avg r: 0.6246
20:11:57,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:22,931 root INFO 
id:en_zh cur r: 0.4847 best r: 0.4847
20:13:27,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:57,524 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3524
en_de Dev loss: 0.9619 r:0.2241
en_zh Dev loss: 0.6811 r:0.4843
ro_en Dev loss: 0.3351 r:0.8221
et_en Dev loss: 0.3868 r:0.6989
si_en Dev loss: 0.7915 r:0.6071
ne_en Dev loss: 0.5505 r:0.7565
ru_en Dev loss: 0.4224 r:0.7468
Current avg r:0.6200 Best avg r: 0.6246
20:19:27,510 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:53,258 root INFO 
id:en_zh cur r: 0.4893 best r: 0.4893
20:20:57,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:27,853 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3392
en_de Dev loss: 0.9485 r:0.2173
en_zh Dev loss: 0.6682 r:0.4858
ro_en Dev loss: 0.2904 r:0.8257
et_en Dev loss: 0.3913 r:0.7089
si_en Dev loss: 0.5619 r:0.6211
ne_en Dev loss: 0.3615 r:0.7614
ru_en Dev loss: 0.4073 r:0.7407
Current avg r:0.6230 Best avg r: 0.6246
20:26:59,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:29,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:59,547 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3098
en_de Dev loss: 0.9325 r:0.2125
en_zh Dev loss: 0.6781 r:0.4765
ro_en Dev loss: 0.2978 r:0.8211
et_en Dev loss: 0.3677 r:0.7032
si_en Dev loss: 0.6378 r:0.6085
ne_en Dev loss: 0.4042 r:0.7515
ru_en Dev loss: 0.4052 r:0.7390
Current avg r:0.6160 Best avg r: 0.6246
20:34:29,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:59,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:29,932 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3069
en_de Dev loss: 0.9707 r:0.2213
en_zh Dev loss: 0.7172 r:0.4785
ro_en Dev loss: 0.3054 r:0.8236
et_en Dev loss: 0.3790 r:0.7062
si_en Dev loss: 0.6746 r:0.6120
ne_en Dev loss: 0.3781 r:0.7615
ru_en Dev loss: 0.4457 r:0.7411
Current avg r:0.6206 Best avg r: 0.6246
20:42:00,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:38,758 root INFO 
id:ro_en cur r: 0.8296 best r: 0.8296
20:43:30,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:00,427 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3118
en_de Dev loss: 0.9720 r:0.2117
en_zh Dev loss: 0.7097 r:0.4720
ro_en Dev loss: 0.3036 r:0.8266
et_en Dev loss: 0.3998 r:0.7114
si_en Dev loss: 0.5933 r:0.6200
ne_en Dev loss: 0.3739 r:0.7597
ru_en Dev loss: 0.4293 r:0.7393
Current avg r:0.6201 Best avg r: 0.6246
20:49:30,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:00,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:30,849 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3099
en_de Dev loss: 1.0170 r:0.1982
en_zh Dev loss: 0.7138 r:0.4844
ro_en Dev loss: 0.3353 r:0.8255
et_en Dev loss: 0.3957 r:0.7005
si_en Dev loss: 0.7066 r:0.6163
ne_en Dev loss: 0.4015 r:0.7584
ru_en Dev loss: 0.4327 r:0.7450
Current avg r:0.6183 Best avg r: 0.6246
20:57:00,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:30,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:00,635 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3189
en_de Dev loss: 0.9445 r:0.2015
en_zh Dev loss: 0.6923 r:0.4733
ro_en Dev loss: 0.3060 r:0.8229
et_en Dev loss: 0.4121 r:0.7026
si_en Dev loss: 0.6216 r:0.6136
ne_en Dev loss: 0.3846 r:0.7609
ru_en Dev loss: 0.3975 r:0.7395
Current avg r:0.6163 Best avg r: 0.6246
21:04:29,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:00,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:30,83 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3000
en_de Dev loss: 0.9845 r:0.1964
en_zh Dev loss: 0.7117 r:0.4818
ro_en Dev loss: 0.3267 r:0.8199
et_en Dev loss: 0.3907 r:0.6985
si_en Dev loss: 0.7092 r:0.6100
ne_en Dev loss: 0.3740 r:0.7616
ru_en Dev loss: 0.4198 r:0.7455
Current avg r:0.6162 Best avg r: 0.6246
21:11:59,245 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:29,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:59,402 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3174
en_de Dev loss: 0.9830 r:0.1967
en_zh Dev loss: 0.7206 r:0.4718
ro_en Dev loss: 0.3351 r:0.8231
et_en Dev loss: 0.4136 r:0.7051
si_en Dev loss: 0.6606 r:0.6156
ne_en Dev loss: 0.3909 r:0.7629
ru_en Dev loss: 0.4331 r:0.7390
Current avg r:0.6163 Best avg r: 0.6246
21:19:28,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:59,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:29,297 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3040
en_de Dev loss: 0.9703 r:0.1880
en_zh Dev loss: 0.6908 r:0.4841
ro_en Dev loss: 0.3210 r:0.8213
et_en Dev loss: 0.4324 r:0.6960
si_en Dev loss: 0.6748 r:0.6088
ne_en Dev loss: 0.4334 r:0.7600
ru_en Dev loss: 0.3661 r:0.7640
Current avg r:0.6175 Best avg r: 0.6246
21:26:59,105 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:29,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:59,414 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3041
en_de Dev loss: 0.9738 r:0.1999
en_zh Dev loss: 0.7237 r:0.4707
ro_en Dev loss: 0.3206 r:0.8200
et_en Dev loss: 0.4014 r:0.6898
si_en Dev loss: 0.6862 r:0.6052
ne_en Dev loss: 0.4338 r:0.7553
ru_en Dev loss: 0.4174 r:0.7411
Current avg r:0.6117 Best avg r: 0.6246
21:34:29,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:59,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:29,721 root INFO Epoch 3 Global steps: 38500 Train loss: 0.2969
en_de Dev loss: 0.9408 r:0.2100
en_zh Dev loss: 0.6785 r:0.4818
ro_en Dev loss: 0.2941 r:0.8266
et_en Dev loss: 0.3831 r:0.6959
si_en Dev loss: 0.7213 r:0.6085
ne_en Dev loss: 0.4114 r:0.7633
ru_en Dev loss: 0.3831 r:0.7565
Current avg r:0.6204 Best avg r: 0.6246
21:41:59,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:29,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:59,966 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3112
en_de Dev loss: 1.0189 r:0.1931
en_zh Dev loss: 0.7632 r:0.4628
ro_en Dev loss: 0.3490 r:0.8217
et_en Dev loss: 0.3842 r:0.6960
si_en Dev loss: 0.8480 r:0.5978
ne_en Dev loss: 0.4459 r:0.7636
ru_en Dev loss: 0.4415 r:0.7488
Current avg r:0.6120 Best avg r: 0.6246
21:49:30,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:00,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:30,322 root INFO Epoch 3 Global steps: 39900 Train loss: 0.2938
en_de Dev loss: 0.9774 r:0.2184
en_zh Dev loss: 0.7036 r:0.4875
ro_en Dev loss: 0.3296 r:0.8271
et_en Dev loss: 0.4087 r:0.7009
si_en Dev loss: 0.6601 r:0.6124
ne_en Dev loss: 0.3990 r:0.7641
ru_en Dev loss: 0.4093 r:0.7553
Current avg r:0.6237 Best avg r: 0.6246
21:57:00,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:30,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:00,799 root INFO Epoch 3 Global steps: 40600 Train loss: 0.2953
en_de Dev loss: 1.0283 r:0.1965
en_zh Dev loss: 0.7939 r:0.4445
ro_en Dev loss: 0.3637 r:0.8140
et_en Dev loss: 0.4145 r:0.6869
si_en Dev loss: 0.7753 r:0.5863
ne_en Dev loss: 0.4531 r:0.7567
ru_en Dev loss: 0.4945 r:0.7159
Current avg r:0.6001 Best avg r: 0.6246
22:04:30,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:01,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:31,193 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3020
en_de Dev loss: 0.9655 r:0.2049
en_zh Dev loss: 0.6941 r:0.4819
ro_en Dev loss: 0.3289 r:0.8175
et_en Dev loss: 0.3924 r:0.6862
si_en Dev loss: 0.7853 r:0.5862
ne_en Dev loss: 0.4828 r:0.7583
ru_en Dev loss: 0.4210 r:0.7372
Current avg r:0.6103 Best avg r: 0.6246
22:12:01,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:31,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:01,565 root INFO Epoch 3 Global steps: 42000 Train loss: 0.2843
en_de Dev loss: 0.9926 r:0.2184
en_zh Dev loss: 0.7361 r:0.4708
ro_en Dev loss: 0.3266 r:0.8224
et_en Dev loss: 0.3988 r:0.7000
si_en Dev loss: 0.6583 r:0.6060
ne_en Dev loss: 0.4219 r:0.7587
ru_en Dev loss: 0.4279 r:0.7417
Current avg r:0.6168 Best avg r: 0.6246
22:19:32,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:03,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:33,289 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2752
en_de Dev loss: 0.9649 r:0.1960
en_zh Dev loss: 0.7031 r:0.4811
ro_en Dev loss: 0.3145 r:0.8252
et_en Dev loss: 0.4105 r:0.6936
si_en Dev loss: 0.6922 r:0.6010
ne_en Dev loss: 0.4175 r:0.7572
ru_en Dev loss: 0.4227 r:0.7371
Current avg r:0.6130 Best avg r: 0.6246
22:27:03,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:33,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:03,788 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2562
en_de Dev loss: 0.9937 r:0.2062
en_zh Dev loss: 0.7512 r:0.4732
ro_en Dev loss: 0.3432 r:0.8202
et_en Dev loss: 0.4242 r:0.6929
si_en Dev loss: 0.6850 r:0.5971
ne_en Dev loss: 0.4419 r:0.7550
ru_en Dev loss: 0.4621 r:0.7221
Current avg r:0.6096 Best avg r: 0.6246
22:34:33,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:59,633 root INFO 
id:en_zh cur r: 0.4920 best r: 0.4920
22:36:04,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:34,240 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2746
en_de Dev loss: 0.9601 r:0.2283
en_zh Dev loss: 0.7323 r:0.4883
ro_en Dev loss: 0.3470 r:0.8179
et_en Dev loss: 0.4123 r:0.6904
si_en Dev loss: 0.6968 r:0.5988
ne_en Dev loss: 0.4374 r:0.7525
ru_en Dev loss: 0.4261 r:0.7403
Current avg r:0.6167 Best avg r: 0.6246
22:42:04,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:34,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:04,677 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2569
en_de Dev loss: 0.9613 r:0.2273
en_zh Dev loss: 0.7416 r:0.4805
ro_en Dev loss: 0.3440 r:0.8182
et_en Dev loss: 0.4116 r:0.6871
si_en Dev loss: 0.7844 r:0.5902
ne_en Dev loss: 0.5360 r:0.7479
ru_en Dev loss: 0.4609 r:0.7266
Current avg r:0.6111 Best avg r: 0.6246
22:49:34,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:04,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:35,57 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2559
en_de Dev loss: 0.9958 r:0.2221
en_zh Dev loss: 0.7497 r:0.4884
ro_en Dev loss: 0.3500 r:0.8208
et_en Dev loss: 0.4102 r:0.6887
si_en Dev loss: 0.7022 r:0.5969
ne_en Dev loss: 0.3961 r:0.7591
ru_en Dev loss: 0.4534 r:0.7380
Current avg r:0.6163 Best avg r: 0.6246
22:57:05,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:35,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:05,354 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2494
en_de Dev loss: 0.9557 r:0.2168
en_zh Dev loss: 0.7406 r:0.4759
ro_en Dev loss: 0.3345 r:0.8140
et_en Dev loss: 0.4171 r:0.6948
si_en Dev loss: 0.7236 r:0.5903
ne_en Dev loss: 0.4045 r:0.7537
ru_en Dev loss: 0.4415 r:0.7331
Current avg r:0.6112 Best avg r: 0.6246
23:04:35,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:05,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:35,806 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2535
en_de Dev loss: 0.9791 r:0.2127
en_zh Dev loss: 0.7484 r:0.4819
ro_en Dev loss: 0.3418 r:0.8179
et_en Dev loss: 0.4127 r:0.6938
si_en Dev loss: 0.7724 r:0.5811
ne_en Dev loss: 0.4279 r:0.7515
ru_en Dev loss: 0.4381 r:0.7356
Current avg r:0.6106 Best avg r: 0.6246
23:12:05,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:36,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:06,204 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2516
en_de Dev loss: 0.9961 r:0.2025
en_zh Dev loss: 0.7537 r:0.4814
ro_en Dev loss: 0.3367 r:0.8194
et_en Dev loss: 0.4116 r:0.6928
si_en Dev loss: 0.7582 r:0.5864
ne_en Dev loss: 0.4329 r:0.7570
ru_en Dev loss: 0.4422 r:0.7318
Current avg r:0.6102 Best avg r: 0.6246
23:19:36,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:06,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:36,491 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2590
en_de Dev loss: 0.9942 r:0.1863
en_zh Dev loss: 0.7497 r:0.4662
ro_en Dev loss: 0.3189 r:0.8192
et_en Dev loss: 0.4242 r:0.6926
si_en Dev loss: 0.6401 r:0.5975
ne_en Dev loss: 0.4321 r:0.7487
ru_en Dev loss: 0.4534 r:0.7193
Current avg r:0.6043 Best avg r: 0.6246
23:27:06,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:36,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:06,587 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2636
en_de Dev loss: 0.9739 r:0.1975
en_zh Dev loss: 0.7353 r:0.4746
ro_en Dev loss: 0.3081 r:0.8216
et_en Dev loss: 0.4156 r:0.6923
si_en Dev loss: 0.6661 r:0.5894
ne_en Dev loss: 0.3959 r:0.7451
ru_en Dev loss: 0.4010 r:0.7421
Current avg r:0.6090 Best avg r: 0.6246
23:34:36,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:06,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:36,716 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2373
en_de Dev loss: 0.9697 r:0.2054
en_zh Dev loss: 0.7558 r:0.4729
ro_en Dev loss: 0.3356 r:0.8156
et_en Dev loss: 0.4426 r:0.6929
si_en Dev loss: 0.7579 r:0.5847
ne_en Dev loss: 0.4246 r:0.7453
ru_en Dev loss: 0.4256 r:0.7371
Current avg r:0.6077 Best avg r: 0.6246
23:42:06,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:36,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:06,215 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2544
en_de Dev loss: 0.9589 r:0.2057
en_zh Dev loss: 0.7376 r:0.4677
ro_en Dev loss: 0.3129 r:0.8188
et_en Dev loss: 0.4075 r:0.6978
si_en Dev loss: 0.6926 r:0.5900
ne_en Dev loss: 0.4196 r:0.7467
ru_en Dev loss: 0.4243 r:0.7306
Current avg r:0.6082 Best avg r: 0.6246
23:49:35,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:05,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:35,373 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2490
en_de Dev loss: 1.0176 r:0.1978
en_zh Dev loss: 0.7768 r:0.4711
ro_en Dev loss: 0.3352 r:0.8170
et_en Dev loss: 0.4157 r:0.6927
si_en Dev loss: 0.7592 r:0.5910
ne_en Dev loss: 0.4618 r:0.7482
ru_en Dev loss: 0.4788 r:0.7216
Current avg r:0.6056 Best avg r: 0.6246
23:57:04,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:34,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:04,510 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2489
en_de Dev loss: 0.9715 r:0.1896
en_zh Dev loss: 0.7229 r:0.4832
ro_en Dev loss: 0.3205 r:0.8177
et_en Dev loss: 0.4215 r:0.6969
si_en Dev loss: 0.6871 r:0.5938
ne_en Dev loss: 0.4313 r:0.7486
ru_en Dev loss: 0.3897 r:0.7520
Current avg r:0.6117 Best avg r: 0.6246
00:04:33,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:06:03,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:33,361 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2512
en_de Dev loss: 1.0122 r:0.1718
en_zh Dev loss: 0.7576 r:0.4655
ro_en Dev loss: 0.3474 r:0.8139
et_en Dev loss: 0.4165 r:0.6876
si_en Dev loss: 0.7001 r:0.5928
ne_en Dev loss: 0.4232 r:0.7435
ru_en Dev loss: 0.4468 r:0.7276
Current avg r:0.6004 Best avg r: 0.6246
00:12:03,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:33,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:03,901 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2329
en_de Dev loss: 1.0154 r:0.1771
en_zh Dev loss: 0.8151 r:0.4518
ro_en Dev loss: 0.3642 r:0.8133
et_en Dev loss: 0.4146 r:0.6802
si_en Dev loss: 0.8283 r:0.5722
ne_en Dev loss: 0.5651 r:0.7277
ru_en Dev loss: 0.5008 r:0.7076
Current avg r:0.5900 Best avg r: 0.6246
00:19:32,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:21:02,772 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:32,775 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2220
en_de Dev loss: 1.0335 r:0.1785
en_zh Dev loss: 0.7884 r:0.4688
ro_en Dev loss: 0.3408 r:0.8194
et_en Dev loss: 0.4710 r:0.6914
si_en Dev loss: 0.6440 r:0.6046
ne_en Dev loss: 0.4114 r:0.7429
ru_en Dev loss: 0.4435 r:0.7396
Current avg r:0.6064 Best avg r: 0.6246
00:27:01,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:31,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:01,826 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2160
en_de Dev loss: 0.9961 r:0.1900
en_zh Dev loss: 0.7634 r:0.4688
ro_en Dev loss: 0.3360 r:0.8178
et_en Dev loss: 0.4592 r:0.6864
si_en Dev loss: 0.7021 r:0.5870
ne_en Dev loss: 0.4290 r:0.7340
ru_en Dev loss: 0.4503 r:0.7259
Current avg r:0.6014 Best avg r: 0.6246
00:34:30,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:00,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:30,826 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2190
en_de Dev loss: 1.0033 r:0.1853
en_zh Dev loss: 0.7630 r:0.4786
ro_en Dev loss: 0.3393 r:0.8146
et_en Dev loss: 0.4485 r:0.6837
si_en Dev loss: 0.6973 r:0.5922
ne_en Dev loss: 0.4729 r:0.7266
ru_en Dev loss: 0.4498 r:0.7261
Current avg r:0.6010 Best avg r: 0.6246
00:41:59,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:29,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:59,762 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2099
en_de Dev loss: 1.0103 r:0.1795
en_zh Dev loss: 0.7427 r:0.4848
ro_en Dev loss: 0.3298 r:0.8188
et_en Dev loss: 0.4423 r:0.6922
si_en Dev loss: 0.6948 r:0.5926
ne_en Dev loss: 0.4283 r:0.7299
ru_en Dev loss: 0.4434 r:0.7397
Current avg r:0.6054 Best avg r: 0.6246
00:49:28,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:58,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:28,730 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2148
en_de Dev loss: 1.0488 r:0.1692
en_zh Dev loss: 0.7940 r:0.4664
ro_en Dev loss: 0.3534 r:0.8156
et_en Dev loss: 0.4365 r:0.6824
si_en Dev loss: 0.8074 r:0.5724
ne_en Dev loss: 0.5025 r:0.7323
ru_en Dev loss: 0.4941 r:0.7195
Current avg r:0.5940 Best avg r: 0.6246
00:56:57,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:27,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:57,487 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2175
en_de Dev loss: 0.9820 r:0.1715
en_zh Dev loss: 0.7770 r:0.4897
ro_en Dev loss: 0.3463 r:0.8167
et_en Dev loss: 0.4923 r:0.6883
si_en Dev loss: 0.7009 r:0.5873
ne_en Dev loss: 0.4444 r:0.7265
ru_en Dev loss: 0.4352 r:0.7290
Current avg r:0.6013 Best avg r: 0.6246
01:04:26,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:56,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:26,138 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2086
en_de Dev loss: 0.9959 r:0.1709
en_zh Dev loss: 0.7179 r:0.4940
ro_en Dev loss: 0.3753 r:0.8118
et_en Dev loss: 0.4225 r:0.6738
si_en Dev loss: 0.8300 r:0.5740
ne_en Dev loss: 0.5676 r:0.7391
ru_en Dev loss: 0.4588 r:0.7310
Current avg r:0.5992 Best avg r: 0.6246
01:11:54,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:24,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:54,796 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2156
en_de Dev loss: 1.0706 r:0.1692
en_zh Dev loss: 0.7958 r:0.4919
ro_en Dev loss: 0.4015 r:0.8130
et_en Dev loss: 0.4573 r:0.6740
si_en Dev loss: 0.8765 r:0.5711
ne_en Dev loss: 0.5186 r:0.7358
ru_en Dev loss: 0.5057 r:0.7273
Current avg r:0.5975 Best avg r: 0.6246
01:19:23,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:20:53,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:22:23,461 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2072
en_de Dev loss: 1.0065 r:0.1618
en_zh Dev loss: 0.7494 r:0.4862
ro_en Dev loss: 0.3214 r:0.8178
et_en Dev loss: 0.4301 r:0.6787
si_en Dev loss: 0.7057 r:0.5885
ne_en Dev loss: 0.4601 r:0.7323
ru_en Dev loss: 0.4176 r:0.7440
Current avg r:0.6013 Best avg r: 0.6246
01:26:52,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:22,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:29:52,274 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2111
en_de Dev loss: 1.0160 r:0.1799
en_zh Dev loss: 0.7834 r:0.4793
ro_en Dev loss: 0.3619 r:0.8128
et_en Dev loss: 0.4600 r:0.6728
si_en Dev loss: 0.8368 r:0.5680
ne_en Dev loss: 0.5294 r:0.7284
ru_en Dev loss: 0.4639 r:0.7300
Current avg r:0.5959 Best avg r: 0.6246
01:34:20,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:51,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:21,32 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2112
en_de Dev loss: 1.0270 r:0.1679
en_zh Dev loss: 0.7564 r:0.4945
ro_en Dev loss: 0.3506 r:0.8166
et_en Dev loss: 0.4526 r:0.6798
si_en Dev loss: 0.7801 r:0.5779
ne_en Dev loss: 0.4443 r:0.7324
ru_en Dev loss: 0.4656 r:0.7284
Current avg r:0.5997 Best avg r: 0.6246
01:41:49,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:19,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:44:49,832 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2040
en_de Dev loss: 0.9787 r:0.1791
en_zh Dev loss: 0.7179 r:0.4911
ro_en Dev loss: 0.3195 r:0.8202
et_en Dev loss: 0.4181 r:0.6852
si_en Dev loss: 0.7347 r:0.5739
ne_en Dev loss: 0.4260 r:0.7351
ru_en Dev loss: 0.4155 r:0.7432
Current avg r:0.6040 Best avg r: 0.6246
01:49:18,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:48,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:18,577 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2096
en_de Dev loss: 1.0276 r:0.1672
en_zh Dev loss: 0.7497 r:0.4882
ro_en Dev loss: 0.3530 r:0.8189
et_en Dev loss: 0.4392 r:0.6816
si_en Dev loss: 0.7616 r:0.5735
ne_en Dev loss: 0.5142 r:0.7389
ru_en Dev loss: 0.4421 r:0.7400
Current avg r:0.6012 Best avg r: 0.6246
01:56:47,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:58:17,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:47,424 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2016
en_de Dev loss: 1.0308 r:0.1713
en_zh Dev loss: 0.7827 r:0.4845
ro_en Dev loss: 0.3459 r:0.8190
et_en Dev loss: 0.4302 r:0.6869
si_en Dev loss: 0.7613 r:0.5742
ne_en Dev loss: 0.4573 r:0.7455
ru_en Dev loss: 0.4526 r:0.7348
Current avg r:0.6023 Best avg r: 0.6246
02:04:18,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:48,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:18,156 root INFO Epoch 6 Global steps: 63700 Train loss: 0.1827
en_de Dev loss: 1.0197 r:0.1747
en_zh Dev loss: 0.7551 r:0.4903
ro_en Dev loss: 0.3666 r:0.8162
et_en Dev loss: 0.4380 r:0.6762
si_en Dev loss: 0.8785 r:0.5614
ne_en Dev loss: 0.5658 r:0.7330
ru_en Dev loss: 0.4726 r:0.7253
Current avg r:0.5967 Best avg r: 0.6246
02:11:47,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:12,848 root INFO 
id:en_zh cur r: 0.4944 best r: 0.4944
02:13:17,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:47,317 root INFO Epoch 6 Global steps: 64400 Train loss: 0.1951
en_de Dev loss: 1.0090 r:0.1890
en_zh Dev loss: 0.7538 r:0.4940
ro_en Dev loss: 0.3815 r:0.8120
et_en Dev loss: 0.4315 r:0.6761
si_en Dev loss: 0.8362 r:0.5673
ne_en Dev loss: 0.5345 r:0.7327
ru_en Dev loss: 0.4797 r:0.7278
Current avg r:0.5999 Best avg r: 0.6246
02:19:16,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:46,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:16,547 root INFO Epoch 6 Global steps: 65100 Train loss: 0.1859
en_de Dev loss: 1.0255 r:0.1830
en_zh Dev loss: 0.7691 r:0.4883
ro_en Dev loss: 0.3675 r:0.8145
et_en Dev loss: 0.4387 r:0.6748
si_en Dev loss: 0.8688 r:0.5645
ne_en Dev loss: 0.5510 r:0.7237
ru_en Dev loss: 0.4868 r:0.7224
Current avg r:0.5959 Best avg r: 0.6246
02:26:45,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:28:15,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:45,884 root INFO Epoch 6 Global steps: 65800 Train loss: 0.1865
en_de Dev loss: 1.0183 r:0.1685
en_zh Dev loss: 0.7464 r:0.4965
ro_en Dev loss: 0.3411 r:0.8143
et_en Dev loss: 0.4432 r:0.6753
si_en Dev loss: 0.7784 r:0.5674
ne_en Dev loss: 0.4749 r:0.7269
ru_en Dev loss: 0.4346 r:0.7386
Current avg r:0.5982 Best avg r: 0.6246
02:34:14,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:34:40,552 root INFO 
id:en_zh cur r: 0.4947 best r: 0.4947
02:35:44,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:37:15,82 root INFO Epoch 6 Global steps: 66500 Train loss: 0.1771
en_de Dev loss: 1.0307 r:0.1625
en_zh Dev loss: 0.7494 r:0.4989
ro_en Dev loss: 0.3459 r:0.8181
et_en Dev loss: 0.4431 r:0.6766
si_en Dev loss: 0.7809 r:0.5689
ne_en Dev loss: 0.5109 r:0.7297
ru_en Dev loss: 0.4355 r:0.7436
Current avg r:0.5998 Best avg r: 0.6246
02:41:43,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:42:09,677 root INFO 
id:en_zh cur r: 0.4950 best r: 0.4950
02:43:14,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:44,179 root INFO Epoch 6 Global steps: 67200 Train loss: 0.1820
en_de Dev loss: 0.9994 r:0.1726
en_zh Dev loss: 0.7450 r:0.4944
ro_en Dev loss: 0.3390 r:0.8176
et_en Dev loss: 0.4321 r:0.6819
si_en Dev loss: 0.7886 r:0.5670
ne_en Dev loss: 0.4869 r:0.7319
ru_en Dev loss: 0.4190 r:0.7472
Current avg r:0.6018 Best avg r: 0.6246
02:49:13,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:43,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:13,317 root INFO Epoch 6 Global steps: 67900 Train loss: 0.1748
en_de Dev loss: 1.0250 r:0.1770
en_zh Dev loss: 0.7812 r:0.4811
ro_en Dev loss: 0.3536 r:0.8178
et_en Dev loss: 0.4473 r:0.6757
si_en Dev loss: 0.7992 r:0.5648
ne_en Dev loss: 0.5222 r:0.7198
ru_en Dev loss: 0.4663 r:0.7344
Current avg r:0.5958 Best avg r: 0.6246
02:56:42,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:58:12,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:59:42,691 root INFO Epoch 6 Global steps: 68600 Train loss: 0.1837
en_de Dev loss: 1.0067 r:0.1711
en_zh Dev loss: 0.7770 r:0.4887
ro_en Dev loss: 0.3470 r:0.8186
et_en Dev loss: 0.4619 r:0.6831
si_en Dev loss: 0.7886 r:0.5726
ne_en Dev loss: 0.4801 r:0.7306
ru_en Dev loss: 0.4170 r:0.7588
Current avg r:0.6034 Best avg r: 0.6246
03:04:11,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:05:42,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:07:12,114 root INFO Epoch 6 Global steps: 69300 Train loss: 0.1773
en_de Dev loss: 1.0246 r:0.1664
en_zh Dev loss: 0.7809 r:0.4860
ro_en Dev loss: 0.3690 r:0.8157
et_en Dev loss: 0.4392 r:0.6731
si_en Dev loss: 0.8573 r:0.5628
ne_en Dev loss: 0.5407 r:0.7257
ru_en Dev loss: 0.4664 r:0.7334
Current avg r:0.5947 Best avg r: 0.6246
03:11:41,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:11,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:41,473 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1728
en_de Dev loss: 0.9894 r:0.1860
en_zh Dev loss: 0.7369 r:0.4935
ro_en Dev loss: 0.3411 r:0.8181
et_en Dev loss: 0.4395 r:0.6812
si_en Dev loss: 0.7891 r:0.5607
ne_en Dev loss: 0.4597 r:0.7303
ru_en Dev loss: 0.4212 r:0.7475
Current avg r:0.6025 Best avg r: 0.6246
03:19:10,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:19:36,428 root INFO 
id:en_zh cur r: 0.5047 best r: 0.5047
03:20:40,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:10,946 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1746
en_de Dev loss: 0.9666 r:0.1846
en_zh Dev loss: 0.7198 r:0.5009
ro_en Dev loss: 0.3322 r:0.8173
et_en Dev loss: 0.4464 r:0.6748
si_en Dev loss: 0.7791 r:0.5584
ne_en Dev loss: 0.4934 r:0.7281
ru_en Dev loss: 0.4393 r:0.7323
Current avg r:0.5995 Best avg r: 0.6246
03:26:39,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:27:05,659 root INFO 
id:en_zh cur r: 0.5081 best r: 0.5081
03:28:10,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:29:40,174 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1696
en_de Dev loss: 0.9779 r:0.1724
en_zh Dev loss: 0.7056 r:0.5058
ro_en Dev loss: 0.3268 r:0.8208
et_en Dev loss: 0.4357 r:0.6764
si_en Dev loss: 0.8356 r:0.5558
ne_en Dev loss: 0.5116 r:0.7282
ru_en Dev loss: 0.4201 r:0.7398
Current avg r:0.5999 Best avg r: 0.6246
03:34:09,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:39,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:37:09,380 root INFO Epoch 6 Global steps: 72100 Train loss: 0.1728
en_de Dev loss: 0.9998 r:0.1854
en_zh Dev loss: 0.7700 r:0.4835
ro_en Dev loss: 0.3522 r:0.8175
et_en Dev loss: 0.4361 r:0.6697
si_en Dev loss: 0.8360 r:0.5520
ne_en Dev loss: 0.4986 r:0.7261
ru_en Dev loss: 0.4641 r:0.7276
Current avg r:0.5945 Best avg r: 0.6246
03:41:38,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:08,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:44:38,518 root INFO Epoch 6 Global steps: 72800 Train loss: 0.1664
en_de Dev loss: 1.0303 r:0.1914
en_zh Dev loss: 0.8243 r:0.4776
ro_en Dev loss: 0.3812 r:0.8148
et_en Dev loss: 0.4493 r:0.6697
si_en Dev loss: 0.9332 r:0.5421
ne_en Dev loss: 0.5842 r:0.7245
ru_en Dev loss: 0.5058 r:0.7176
Current avg r:0.5911 Best avg r: 0.6246
03:49:07,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:50:37,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:07,521 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1648
en_de Dev loss: 1.0385 r:0.1820
en_zh Dev loss: 0.8627 r:0.4682
ro_en Dev loss: 0.3976 r:0.8138
et_en Dev loss: 0.4518 r:0.6674
si_en Dev loss: 0.9429 r:0.5409
ne_en Dev loss: 0.6636 r:0.7205
ru_en Dev loss: 0.5385 r:0.7091
Current avg r:0.5860 Best avg r: 0.6246
03:56:38,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:58:08,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:59:38,292 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1515
en_de Dev loss: 1.0014 r:0.1773
en_zh Dev loss: 0.7758 r:0.4821
ro_en Dev loss: 0.3469 r:0.8175
et_en Dev loss: 0.4521 r:0.6782
si_en Dev loss: 0.8068 r:0.5593
ne_en Dev loss: 0.5044 r:0.7277
ru_en Dev loss: 0.4559 r:0.7355
Current avg r:0.5968 Best avg r: 0.6246
04:04:07,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:05:37,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:07:07,531 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1565
en_de Dev loss: 0.9590 r:0.1811
en_zh Dev loss: 0.7350 r:0.4907
ro_en Dev loss: 0.3405 r:0.8160
et_en Dev loss: 0.4824 r:0.6758
si_en Dev loss: 0.7994 r:0.5553
ne_en Dev loss: 0.4725 r:0.7292
ru_en Dev loss: 0.4169 r:0.7408
Current avg r:0.5984 Best avg r: 0.6246
04:11:36,602 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:13:06,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:14:36,857 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1548
en_de Dev loss: 0.9919 r:0.1785
en_zh Dev loss: 0.7609 r:0.4884
ro_en Dev loss: 0.3521 r:0.8186
et_en Dev loss: 0.4777 r:0.6706
si_en Dev loss: 0.8850 r:0.5495
ne_en Dev loss: 0.5242 r:0.7339
ru_en Dev loss: 0.4471 r:0.7347
Current avg r:0.5963 Best avg r: 0.6246
04:19:05,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:20:35,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:22:06,47 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1504
en_de Dev loss: 0.9902 r:0.1803
en_zh Dev loss: 0.7577 r:0.4900
ro_en Dev loss: 0.3374 r:0.8184
et_en Dev loss: 0.4458 r:0.6727
si_en Dev loss: 0.8447 r:0.5536
ne_en Dev loss: 0.4846 r:0.7306
ru_en Dev loss: 0.4432 r:0.7375
Current avg r:0.5976 Best avg r: 0.6246
04:26:35,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:28:05,298 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:29:35,380 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1480
en_de Dev loss: 0.9563 r:0.1725
en_zh Dev loss: 0.7214 r:0.4986
ro_en Dev loss: 0.3291 r:0.8199
et_en Dev loss: 0.4365 r:0.6868
si_en Dev loss: 0.8993 r:0.5504
ne_en Dev loss: 0.4986 r:0.7368
ru_en Dev loss: 0.4150 r:0.7442
Current avg r:0.6013 Best avg r: 0.6246
04:34:04,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:35:34,512 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:04,603 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1550
en_de Dev loss: 1.0328 r:0.1677
en_zh Dev loss: 0.7999 r:0.4830
ro_en Dev loss: 0.3757 r:0.8128
et_en Dev loss: 0.4692 r:0.6817
si_en Dev loss: 0.8253 r:0.5535
ne_en Dev loss: 0.5349 r:0.7226
ru_en Dev loss: 0.4794 r:0.7231
Current avg r:0.5921 Best avg r: 0.6246
04:41:33,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:03,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:33,834 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1545
en_de Dev loss: 0.9911 r:0.1777
en_zh Dev loss: 0.7590 r:0.4884
ro_en Dev loss: 0.3554 r:0.8126
et_en Dev loss: 0.4625 r:0.6824
si_en Dev loss: 0.8094 r:0.5473
ne_en Dev loss: 0.5070 r:0.7128
ru_en Dev loss: 0.4519 r:0.7278
Current avg r:0.5927 Best avg r: 0.6246
04:49:02,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:32,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:52:02,898 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1483
en_de Dev loss: 0.9461 r:0.1807
en_zh Dev loss: 0.7060 r:0.4995
ro_en Dev loss: 0.3159 r:0.8190
et_en Dev loss: 0.4672 r:0.6836
si_en Dev loss: 0.7111 r:0.5667
ne_en Dev loss: 0.4580 r:0.7198
ru_en Dev loss: 0.3810 r:0.7525
Current avg r:0.6031 Best avg r: 0.6246
04:56:32,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:58:02,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:59:32,349 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1548
en_de Dev loss: 0.9681 r:0.1965
en_zh Dev loss: 0.7473 r:0.4918
ro_en Dev loss: 0.3500 r:0.8157
et_en Dev loss: 0.4520 r:0.6740
si_en Dev loss: 0.8108 r:0.5521
ne_en Dev loss: 0.5050 r:0.7162
ru_en Dev loss: 0.4657 r:0.7257
Current avg r:0.5960 Best avg r: 0.6246
05:04:01,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:05:31,408 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:07:01,511 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1603
en_de Dev loss: 1.0001 r:0.1847
en_zh Dev loss: 0.7483 r:0.4988
ro_en Dev loss: 0.3671 r:0.8176
et_en Dev loss: 0.4567 r:0.6833
si_en Dev loss: 0.8150 r:0.5561
ne_en Dev loss: 0.5384 r:0.7098
ru_en Dev loss: 0.4501 r:0.7373
Current avg r:0.5982 Best avg r: 0.6246
05:11:30,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:13:00,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:14:30,768 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1446
en_de Dev loss: 0.9491 r:0.1810
en_zh Dev loss: 0.7193 r:0.4974
ro_en Dev loss: 0.3480 r:0.8137
et_en Dev loss: 0.4851 r:0.6838
si_en Dev loss: 0.7390 r:0.5668
ne_en Dev loss: 0.4830 r:0.7232
ru_en Dev loss: 0.4198 r:0.7382
Current avg r:0.6006 Best avg r: 0.6246
05:18:59,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:29,790 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:21:59,836 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1545
en_de Dev loss: 1.0143 r:0.1878
en_zh Dev loss: 0.8045 r:0.4782
ro_en Dev loss: 0.3850 r:0.8129
et_en Dev loss: 0.4383 r:0.6702
si_en Dev loss: 0.9763 r:0.5435
ne_en Dev loss: 0.5752 r:0.7256
ru_en Dev loss: 0.4964 r:0.7230
Current avg r:0.5916 Best avg r: 0.6246
05:26:28,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:27:58,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:29:29,44 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1464
en_de Dev loss: 0.9882 r:0.1827
en_zh Dev loss: 0.7686 r:0.4892
ro_en Dev loss: 0.3518 r:0.8187
et_en Dev loss: 0.4559 r:0.6708
si_en Dev loss: 0.8699 r:0.5509
ne_en Dev loss: 0.5603 r:0.7250
ru_en Dev loss: 0.4427 r:0.7390
Current avg r:0.5966 Best avg r: 0.6246
05:33:57,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:35:28,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:36:58,189 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1459
en_de Dev loss: 0.9796 r:0.1744
en_zh Dev loss: 0.7658 r:0.4838
ro_en Dev loss: 0.3584 r:0.8181
et_en Dev loss: 0.4703 r:0.6696
si_en Dev loss: 0.9177 r:0.5482
ne_en Dev loss: 0.6097 r:0.7266
ru_en Dev loss: 0.4551 r:0.7296
Current avg r:0.5929 Best avg r: 0.6246
05:41:27,36 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:42:57,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:44:27,226 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1471
en_de Dev loss: 0.9670 r:0.1688
en_zh Dev loss: 0.7418 r:0.4795
ro_en Dev loss: 0.3335 r:0.8193
et_en Dev loss: 0.4313 r:0.6833
si_en Dev loss: 0.8064 r:0.5637
ne_en Dev loss: 0.4839 r:0.7302
ru_en Dev loss: 0.4282 r:0.7389
Current avg r:0.5977 Best avg r: 0.6246
05:48:57,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:50:27,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:51:57,945 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1316
en_de Dev loss: 0.9647 r:0.1572
en_zh Dev loss: 0.7266 r:0.4873
ro_en Dev loss: 0.3193 r:0.8202
et_en Dev loss: 0.4514 r:0.6802
si_en Dev loss: 0.7677 r:0.5634
ne_en Dev loss: 0.4624 r:0.7262
ru_en Dev loss: 0.3938 r:0.7496
Current avg r:0.5977 Best avg r: 0.6246
05:56:26,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:57:57,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:27,129 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1312
en_de Dev loss: 0.9781 r:0.1697
en_zh Dev loss: 0.7522 r:0.4852
ro_en Dev loss: 0.3253 r:0.8229
et_en Dev loss: 0.4290 r:0.6747
si_en Dev loss: 0.8531 r:0.5541
ne_en Dev loss: 0.5075 r:0.7194
ru_en Dev loss: 0.4322 r:0.7397
Current avg r:0.5951 Best avg r: 0.6246
06:03:56,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:05:26,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:06:56,514 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1332
en_de Dev loss: 0.9792 r:0.1731
en_zh Dev loss: 0.7492 r:0.4899
ro_en Dev loss: 0.3417 r:0.8222
et_en Dev loss: 0.4397 r:0.6783
si_en Dev loss: 0.8391 r:0.5545
ne_en Dev loss: 0.5182 r:0.7263
ru_en Dev loss: 0.4183 r:0.7467
Current avg r:0.5987 Best avg r: 0.6246
06:11:25,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:12:55,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:14:25,842 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1296
en_de Dev loss: 0.9874 r:0.1729
en_zh Dev loss: 0.7722 r:0.4850
ro_en Dev loss: 0.3458 r:0.8233
et_en Dev loss: 0.4666 r:0.6730
si_en Dev loss: 0.8195 r:0.5530
ne_en Dev loss: 0.4936 r:0.7241
ru_en Dev loss: 0.4520 r:0.7361
Current avg r:0.5953 Best avg r: 0.6246
06:18:54,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:20:24,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:21:54,832 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1361
en_de Dev loss: 0.9905 r:0.1836
en_zh Dev loss: 0.7944 r:0.4795
ro_en Dev loss: 0.3446 r:0.8239
et_en Dev loss: 0.4736 r:0.6707
si_en Dev loss: 0.8339 r:0.5502
ne_en Dev loss: 0.5157 r:0.7124
ru_en Dev loss: 0.4440 r:0.7410
Current avg r:0.5945 Best avg r: 0.6246
06:26:23,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:27:53,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:29:23,956 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1270
en_de Dev loss: 0.9645 r:0.1819
en_zh Dev loss: 0.7572 r:0.4850
ro_en Dev loss: 0.3289 r:0.8204
et_en Dev loss: 0.4715 r:0.6729
si_en Dev loss: 0.7845 r:0.5561
ne_en Dev loss: 0.4813 r:0.7157
ru_en Dev loss: 0.4517 r:0.7304
Current avg r:0.5946 Best avg r: 0.6246
06:33:52,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:35:23,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:36:53,196 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1326
en_de Dev loss: 1.0068 r:0.1690
en_zh Dev loss: 0.7907 r:0.4721
ro_en Dev loss: 0.3664 r:0.8150
et_en Dev loss: 0.4592 r:0.6622
si_en Dev loss: 0.8933 r:0.5415
ne_en Dev loss: 0.5442 r:0.7160
ru_en Dev loss: 0.4908 r:0.7202
Current avg r:0.5851 Best avg r: 0.6246
06:41:22,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:42:52,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:44:22,520 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1265
en_de Dev loss: 1.0071 r:0.1749
en_zh Dev loss: 0.8072 r:0.4737
ro_en Dev loss: 0.3623 r:0.8147
et_en Dev loss: 0.4598 r:0.6709
si_en Dev loss: 0.8478 r:0.5504
ne_en Dev loss: 0.5076 r:0.7228
ru_en Dev loss: 0.4655 r:0.7381
Current avg r:0.5922 Best avg r: 0.6246
06:48:51,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:50:21,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:51:52,101 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1206
en_de Dev loss: 0.9780 r:0.1816
en_zh Dev loss: 0.7879 r:0.4714
ro_en Dev loss: 0.3673 r:0.8150
et_en Dev loss: 0.4849 r:0.6642
si_en Dev loss: 0.9096 r:0.5409
ne_en Dev loss: 0.5306 r:0.7211
ru_en Dev loss: 0.4607 r:0.7332
Current avg r:0.5896 Best avg r: 0.6246
06:56:21,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:57:51,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:59:21,514 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1281
en_de Dev loss: 0.9508 r:0.1714
en_zh Dev loss: 0.7334 r:0.4880
ro_en Dev loss: 0.3427 r:0.8175
et_en Dev loss: 0.4818 r:0.6713
si_en Dev loss: 0.8012 r:0.5540
ne_en Dev loss: 0.5099 r:0.7223
ru_en Dev loss: 0.4057 r:0.7476
Current avg r:0.5960 Best avg r: 0.6246
07:03:50,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:05:20,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:06:50,991 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1300
en_de Dev loss: 0.9706 r:0.1804
en_zh Dev loss: 0.7458 r:0.4903
ro_en Dev loss: 0.3515 r:0.8180
et_en Dev loss: 0.4669 r:0.6721
si_en Dev loss: 0.8887 r:0.5434
ne_en Dev loss: 0.5380 r:0.7197
ru_en Dev loss: 0.4335 r:0.7409
Current avg r:0.5950 Best avg r: 0.6246
07:11:20,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:12:50,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:14:20,414 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1207
en_de Dev loss: 0.9879 r:0.1725
en_zh Dev loss: 0.7684 r:0.4959
ro_en Dev loss: 0.3580 r:0.8165
et_en Dev loss: 0.4808 r:0.6775
si_en Dev loss: 0.8463 r:0.5482
ne_en Dev loss: 0.5539 r:0.7165
ru_en Dev loss: 0.4201 r:0.7494
Current avg r:0.5966 Best avg r: 0.6246
07:18:49,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:20:19,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:21:49,551 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1291
en_de Dev loss: 1.0262 r:0.1653
en_zh Dev loss: 0.8073 r:0.4910
ro_en Dev loss: 0.3812 r:0.8152
et_en Dev loss: 0.4715 r:0.6668
si_en Dev loss: 0.9051 r:0.5380
ne_en Dev loss: 0.5531 r:0.7197
ru_en Dev loss: 0.4745 r:0.7329
Current avg r:0.5899 Best avg r: 0.6246
07:26:18,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:27:48,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:29:18,848 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1290
en_de Dev loss: 0.9851 r:0.1758
en_zh Dev loss: 0.7483 r:0.4960
ro_en Dev loss: 0.3357 r:0.8202
et_en Dev loss: 0.4597 r:0.6745
si_en Dev loss: 0.8149 r:0.5492
ne_en Dev loss: 0.4723 r:0.7232
ru_en Dev loss: 0.4322 r:0.7423
Current avg r:0.5973 Best avg r: 0.6246
07:33:48,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:35:18,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:36:48,230 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1232
en_de Dev loss: 0.9438 r:0.1853
en_zh Dev loss: 0.7262 r:0.4948
ro_en Dev loss: 0.3241 r:0.8175
et_en Dev loss: 0.4598 r:0.6752
si_en Dev loss: 0.7679 r:0.5558
ne_en Dev loss: 0.4394 r:0.7251
ru_en Dev loss: 0.4006 r:0.7485
Current avg r:0.6003 Best avg r: 0.6246
07:41:18,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:42:49,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:44:19,88 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1103
en_de Dev loss: 0.9716 r:0.1824
en_zh Dev loss: 0.7468 r:0.4939
ro_en Dev loss: 0.3553 r:0.8163
et_en Dev loss: 0.4595 r:0.6672
si_en Dev loss: 0.8600 r:0.5392
ne_en Dev loss: 0.5989 r:0.7095
ru_en Dev loss: 0.4576 r:0.7250
Current avg r:0.5905 Best avg r: 0.6246
07:48:48,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:50:18,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:51:48,260 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1130
en_de Dev loss: 0.9702 r:0.1695
en_zh Dev loss: 0.7573 r:0.4930
ro_en Dev loss: 0.3443 r:0.8156
et_en Dev loss: 0.4702 r:0.6710
si_en Dev loss: 0.8832 r:0.5325
ne_en Dev loss: 0.5177 r:0.7122
ru_en Dev loss: 0.4376 r:0.7338
Current avg r:0.5896 Best avg r: 0.6246
07:56:17,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:57:47,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:59:17,506 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1122
en_de Dev loss: 1.0018 r:0.1754
en_zh Dev loss: 0.7597 r:0.5044
ro_en Dev loss: 0.3568 r:0.8177
et_en Dev loss: 0.4566 r:0.6692
si_en Dev loss: 0.8640 r:0.5421
ne_en Dev loss: 0.4954 r:0.7205
ru_en Dev loss: 0.4432 r:0.7430
Current avg r:0.5961 Best avg r: 0.6246
08:03:46,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:05:16,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:06:46,599 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1065
en_de Dev loss: 0.9795 r:0.1694
en_zh Dev loss: 0.7433 r:0.4988
ro_en Dev loss: 0.3608 r:0.8184
et_en Dev loss: 0.4813 r:0.6687
si_en Dev loss: 0.8066 r:0.5488
ne_en Dev loss: 0.5588 r:0.7154
ru_en Dev loss: 0.4465 r:0.7400
Current avg r:0.5942 Best avg r: 0.6246
08:11:15,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:12:45,688 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:14:15,690 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1121
en_de Dev loss: 0.9581 r:0.1724
en_zh Dev loss: 0.7639 r:0.4849
ro_en Dev loss: 0.3741 r:0.8093
et_en Dev loss: 0.4811 r:0.6503
si_en Dev loss: 0.9587 r:0.5339
ne_en Dev loss: 0.5951 r:0.7154
ru_en Dev loss: 0.4507 r:0.7322
Current avg r:0.5855 Best avg r: 0.6246
08:18:44,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:20:14,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:21:44,830 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1100
en_de Dev loss: 0.9579 r:0.1788
en_zh Dev loss: 0.7342 r:0.5012
ro_en Dev loss: 0.3613 r:0.8105
et_en Dev loss: 0.4755 r:0.6654
si_en Dev loss: 0.9043 r:0.5373
ne_en Dev loss: 0.5655 r:0.7149
ru_en Dev loss: 0.4151 r:0.7487
Current avg r:0.5938 Best avg r: 0.6246
08:26:13,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:27:43,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:13,984 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1171
en_de Dev loss: 0.9845 r:0.1798
en_zh Dev loss: 0.7627 r:0.4987
ro_en Dev loss: 0.3524 r:0.8166
et_en Dev loss: 0.4556 r:0.6790
si_en Dev loss: 0.8127 r:0.5519
ne_en Dev loss: 0.4722 r:0.7221
ru_en Dev loss: 0.4551 r:0.7465
Current avg r:0.5992 Best avg r: 0.6246
08:33:42,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:13,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:43,8 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1113
en_de Dev loss: 0.9448 r:0.1724
en_zh Dev loss: 0.7235 r:0.4896
ro_en Dev loss: 0.3356 r:0.8138
et_en Dev loss: 0.4435 r:0.6640
si_en Dev loss: 0.8153 r:0.5461
ne_en Dev loss: 0.5239 r:0.7168
ru_en Dev loss: 0.4276 r:0.7411
Current avg r:0.5920 Best avg r: 0.6246
08:41:11,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:41,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:44:12,4 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1128
en_de Dev loss: 0.9664 r:0.1749
en_zh Dev loss: 0.7268 r:0.4986
ro_en Dev loss: 0.3509 r:0.8167
et_en Dev loss: 0.4458 r:0.6756
si_en Dev loss: 0.8178 r:0.5522
ne_en Dev loss: 0.5745 r:0.7120
ru_en Dev loss: 0.4272 r:0.7444
Current avg r:0.5963 Best avg r: 0.6246
08:48:40,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:50:10,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:51:40,848 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1117
en_de Dev loss: 1.0006 r:0.1802
en_zh Dev loss: 0.7757 r:0.4907
ro_en Dev loss: 0.3862 r:0.8124
et_en Dev loss: 0.4654 r:0.6591
si_en Dev loss: 0.9836 r:0.5345
ne_en Dev loss: 0.6356 r:0.7112
ru_en Dev loss: 0.4804 r:0.7281
Current avg r:0.5880 Best avg r: 0.6246
08:56:09,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:57:39,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:59:09,852 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1098
en_de Dev loss: 0.9705 r:0.1762
en_zh Dev loss: 0.7243 r:0.4988
ro_en Dev loss: 0.3468 r:0.8152
et_en Dev loss: 0.4641 r:0.6651
si_en Dev loss: 0.9108 r:0.5453
ne_en Dev loss: 0.5840 r:0.7146
ru_en Dev loss: 0.4566 r:0.7302
Current avg r:0.5922 Best avg r: 0.6246
09:03:38,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:05:08,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:06:38,895 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1059
en_de Dev loss: 0.9644 r:0.1813
en_zh Dev loss: 0.7525 r:0.4851
ro_en Dev loss: 0.3523 r:0.8103
et_en Dev loss: 0.4462 r:0.6704
si_en Dev loss: 0.8235 r:0.5422
ne_en Dev loss: 0.5473 r:0.7113
ru_en Dev loss: 0.4398 r:0.7352
Current avg r:0.5908 Best avg r: 0.6246
09:11:07,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:12:37,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:14:07,955 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1035
en_de Dev loss: 0.9375 r:0.1823
en_zh Dev loss: 0.7364 r:0.4900
ro_en Dev loss: 0.3375 r:0.8163
et_en Dev loss: 0.4653 r:0.6771
si_en Dev loss: 0.7996 r:0.5549
ne_en Dev loss: 0.4980 r:0.7175
ru_en Dev loss: 0.4366 r:0.7369
Current avg r:0.5964 Best avg r: 0.6246
09:18:36,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:20:07,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:21:37,71 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1056
en_de Dev loss: 0.9622 r:0.1896
en_zh Dev loss: 0.7351 r:0.4990
ro_en Dev loss: 0.3525 r:0.8153
et_en Dev loss: 0.4530 r:0.6765
si_en Dev loss: 0.7909 r:0.5547
ne_en Dev loss: 0.5093 r:0.7143
ru_en Dev loss: 0.4426 r:0.7388
Current avg r:0.5983 Best avg r: 0.6246
09:26:06,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:27:36,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:29:06,285 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1087
en_de Dev loss: 0.9794 r:0.1834
en_zh Dev loss: 0.7801 r:0.4904
ro_en Dev loss: 0.3466 r:0.8171
et_en Dev loss: 0.4598 r:0.6783
si_en Dev loss: 0.8128 r:0.5521
ne_en Dev loss: 0.5282 r:0.7092
ru_en Dev loss: 0.4384 r:0.7447
Current avg r:0.5965 Best avg r: 0.6246
09:33:36,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:06,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:36,900 root INFO Epoch 10 Global steps: 105700 Train loss: 0.0986
en_de Dev loss: 0.9492 r:0.1770
en_zh Dev loss: 0.7329 r:0.4892
ro_en Dev loss: 0.3374 r:0.8159
et_en Dev loss: 0.4376 r:0.6765
si_en Dev loss: 0.7604 r:0.5575
ne_en Dev loss: 0.4946 r:0.7118
ru_en Dev loss: 0.4201 r:0.7411
Current avg r:0.5956 Best avg r: 0.6246
09:41:06,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:36,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:44:06,149 root INFO Epoch 10 Global steps: 106400 Train loss: 0.0990
en_de Dev loss: 0.9448 r:0.1807
en_zh Dev loss: 0.7324 r:0.4957
ro_en Dev loss: 0.3357 r:0.8163
et_en Dev loss: 0.4478 r:0.6818
si_en Dev loss: 0.7790 r:0.5563
ne_en Dev loss: 0.4768 r:0.7170
ru_en Dev loss: 0.4217 r:0.7415
Current avg r:0.5985 Best avg r: 0.6246
09:48:35,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:50:05,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:35,400 root INFO Epoch 10 Global steps: 107100 Train loss: 0.0966
en_de Dev loss: 0.9728 r:0.1700
en_zh Dev loss: 0.7466 r:0.4947
ro_en Dev loss: 0.3721 r:0.8125
et_en Dev loss: 0.4463 r:0.6665
si_en Dev loss: 0.8839 r:0.5371
ne_en Dev loss: 0.5771 r:0.7107
ru_en Dev loss: 0.4687 r:0.7322
Current avg r:0.5891 Best avg r: 0.6246
09:56:04,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:34,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:04,519 root INFO Epoch 10 Global steps: 107800 Train loss: 0.0930
en_de Dev loss: 0.9873 r:0.1895
en_zh Dev loss: 0.7983 r:0.4881
ro_en Dev loss: 0.3900 r:0.8112
et_en Dev loss: 0.4571 r:0.6661
si_en Dev loss: 0.9400 r:0.5397
ne_en Dev loss: 0.6091 r:0.7117
ru_en Dev loss: 0.4983 r:0.7235
Current avg r:0.5900 Best avg r: 0.6246
10:03:33,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:03,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:33,585 root INFO Epoch 10 Global steps: 108500 Train loss: 0.0983
en_de Dev loss: 0.9973 r:0.1794
en_zh Dev loss: 0.7708 r:0.4986
ro_en Dev loss: 0.3791 r:0.8150
et_en Dev loss: 0.4667 r:0.6716
si_en Dev loss: 0.8265 r:0.5553
ne_en Dev loss: 0.5065 r:0.7199
ru_en Dev loss: 0.4829 r:0.7370
Current avg r:0.5967 Best avg r: 0.6246
10:11:02,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:12:32,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:02,656 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1010
en_de Dev loss: 0.9572 r:0.1849
en_zh Dev loss: 0.7617 r:0.4959
ro_en Dev loss: 0.3553 r:0.8124
et_en Dev loss: 0.4529 r:0.6681
si_en Dev loss: 0.8851 r:0.5429
ne_en Dev loss: 0.5603 r:0.7212
ru_en Dev loss: 0.4665 r:0.7315
Current avg r:0.5939 Best avg r: 0.6246
10:18:31,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:01,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:21:31,792 root INFO Epoch 10 Global steps: 109900 Train loss: 0.0957
en_de Dev loss: 0.9733 r:0.1867
en_zh Dev loss: 0.7688 r:0.4914
ro_en Dev loss: 0.3617 r:0.8119
et_en Dev loss: 0.4863 r:0.6703
si_en Dev loss: 0.8744 r:0.5431
ne_en Dev loss: 0.5253 r:0.7173
ru_en Dev loss: 0.4562 r:0.7384
Current avg r:0.5942 Best avg r: 0.6246
10:26:00,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:30,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:01,13 root INFO Epoch 10 Global steps: 110600 Train loss: 0.0955
en_de Dev loss: 0.9977 r:0.1868
en_zh Dev loss: 0.7975 r:0.4900
ro_en Dev loss: 0.3718 r:0.8135
et_en Dev loss: 0.4641 r:0.6642
si_en Dev loss: 0.9057 r:0.5442
ne_en Dev loss: 0.5666 r:0.7120
ru_en Dev loss: 0.4767 r:0.7327
Current avg r:0.5919 Best avg r: 0.6246
