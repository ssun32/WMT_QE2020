14:37:33,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:46,511 root INFO 
id:en_de cur r: 0.0730 best r: 0.0730
14:38:12,569 root INFO 
id:ro_en cur r: 0.6285 best r: 0.6285
14:38:38,712 root INFO 
id:et_en cur r: 0.4722 best r: 0.4722
14:38:51,792 root INFO 
id:si_en cur r: 0.4230 best r: 0.4230
14:39:04,874 root INFO 
id:ne_en cur r: 0.4691 best r: 0.4691
14:39:17,868 root INFO 
id:ru_en cur r: 0.5262 best r: 0.5262
14:39:17,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:49,244 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:40:49,250 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:40:49,254 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:40:49,259 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:40:49,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:40:49,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:40:49,273 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:41:02,360 root INFO Epoch 0 Global steps: 700 Train loss: 0.8450
en_de Dev loss: 0.8983 r:0.0676
en_zh Dev loss: 0.7913 r:0.1987
ro_en Dev loss: 0.6848 r:0.5829
et_en Dev loss: 0.6164 r:0.4281
si_en Dev loss: 0.8062 r:0.3890
ne_en Dev loss: 0.6568 r:0.4879
ru_en Dev loss: 0.6481 r:0.5570
Current avg r:0.3873 Best avg r: 0.3873
14:45:34,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:47,333 root INFO 
id:en_de cur r: 0.1038 best r: 0.1038
14:46:00,324 root INFO 
id:en_zh cur r: 0.1430 best r: 0.1430
14:46:13,351 root INFO 
id:ro_en cur r: 0.6737 best r: 0.6737
14:46:39,433 root INFO 
id:et_en cur r: 0.5086 best r: 0.5086
14:46:52,492 root INFO 
id:si_en cur r: 0.4343 best r: 0.4343
14:47:05,550 root INFO 
id:ne_en cur r: 0.5048 best r: 0.5048
14:47:18,505 root INFO 
id:ru_en cur r: 0.6182 best r: 0.6182
14:47:18,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:49,637 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:48:49,648 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:48:49,654 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:48:49,659 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:48:49,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:48:49,669 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:48:49,675 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:49:02,729 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8076
en_de Dev loss: 0.9133 r:0.1148
en_zh Dev loss: 0.7811 r:0.2404
ro_en Dev loss: 0.5584 r:0.6570
et_en Dev loss: 0.5561 r:0.4853
si_en Dev loss: 0.7471 r:0.4256
ne_en Dev loss: 0.5774 r:0.5504
ru_en Dev loss: 0.5352 r:0.6544
Current avg r:0.4469 Best avg r: 0.4469
14:53:34,466 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:00,456 root INFO 
id:en_zh cur r: 0.2429 best r: 0.2429
14:54:13,472 root INFO 
id:ro_en cur r: 0.6875 best r: 0.6875
14:54:39,542 root INFO 
id:et_en cur r: 0.5583 best r: 0.5583
14:54:52,585 root INFO 
id:si_en cur r: 0.4548 best r: 0.4548
14:55:05,633 root INFO 
id:ne_en cur r: 0.5819 best r: 0.5819
14:55:18,586 root INFO 
id:ru_en cur r: 0.6648 best r: 0.6648
14:55:18,586 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:56:49,730 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:56:49,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:56:49,742 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:56:49,746 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:56:49,753 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:56:49,757 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:56:49,764 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:57:02,831 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7029
en_de Dev loss: 0.9409 r:0.1160
en_zh Dev loss: 0.7690 r:0.2929
ro_en Dev loss: 0.5272 r:0.6883
et_en Dev loss: 0.5027 r:0.5540
si_en Dev loss: 0.7252 r:0.4666
ne_en Dev loss: 0.5243 r:0.6115
ru_en Dev loss: 0.4806 r:0.7004
Current avg r:0.4900 Best avg r: 0.4900
15:01:34,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:47,651 root INFO 
id:en_de cur r: 0.1148 best r: 0.1148
15:02:00,638 root INFO 
id:en_zh cur r: 0.2902 best r: 0.2902
15:02:13,658 root INFO 
id:ro_en cur r: 0.7062 best r: 0.7062
15:02:39,736 root INFO 
id:et_en cur r: 0.6055 best r: 0.6055
15:02:52,792 root INFO 
id:si_en cur r: 0.4801 best r: 0.4801
15:03:05,845 root INFO 
id:ne_en cur r: 0.6404 best r: 0.6404
15:03:18,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:49,958 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:04:49,965 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:04:49,971 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:04:49,975 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:04:49,981 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:04:49,985 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:04:49,991 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:05:03,55 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6588
en_de Dev loss: 0.9557 r:0.1265
en_zh Dev loss: 0.7686 r:0.3247
ro_en Dev loss: 0.4471 r:0.7102
et_en Dev loss: 0.4573 r:0.6105
si_en Dev loss: 0.6352 r:0.5034
ne_en Dev loss: 0.4690 r:0.6601
ru_en Dev loss: 0.4852 r:0.7017
Current avg r:0.5196 Best avg r: 0.5196
15:09:34,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:47,929 root INFO 
id:en_de cur r: 0.1265 best r: 0.1265
15:10:00,915 root INFO 
id:en_zh cur r: 0.3784 best r: 0.3784
15:10:13,941 root INFO 
id:ro_en cur r: 0.7245 best r: 0.7245
15:10:40,26 root INFO 
id:et_en cur r: 0.6323 best r: 0.6323
15:10:53,85 root INFO 
id:si_en cur r: 0.5109 best r: 0.5109
15:11:06,145 root INFO 
id:ne_en cur r: 0.6678 best r: 0.6678
15:11:19,99 root INFO 
id:ru_en cur r: 0.7090 best r: 0.7090
15:11:19,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:50,253 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:12:50,259 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:12:50,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:12:50,268 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:12:50,273 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:12:50,277 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:12:50,282 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:13:03,346 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6419
en_de Dev loss: 0.9209 r:0.1626
en_zh Dev loss: 0.7242 r:0.3809
ro_en Dev loss: 0.4200 r:0.7303
et_en Dev loss: 0.4261 r:0.6315
si_en Dev loss: 0.6513 r:0.5176
ne_en Dev loss: 0.4795 r:0.6534
ru_en Dev loss: 0.4453 r:0.7291
Current avg r:0.5436 Best avg r: 0.5436
15:17:35,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:48,268 root INFO 
id:en_de cur r: 0.1565 best r: 0.1565
15:18:14,250 root INFO 
id:ro_en cur r: 0.7250 best r: 0.7250
15:18:40,329 root INFO 
id:et_en cur r: 0.6353 best r: 0.6353
15:19:19,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:50,540 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:20:50,547 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:20:50,554 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:20:50,558 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:20:50,563 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:20:50,568 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:20:50,573 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:21:03,632 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5759
en_de Dev loss: 0.8914 r:0.1865
en_zh Dev loss: 0.7147 r:0.3944
ro_en Dev loss: 0.4151 r:0.7323
et_en Dev loss: 0.4155 r:0.6433
si_en Dev loss: 0.6696 r:0.5206
ne_en Dev loss: 0.4637 r:0.6615
ru_en Dev loss: 0.4414 r:0.7345
Current avg r:0.5533 Best avg r: 0.5533
15:25:35,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:48,255 root INFO 
id:en_de cur r: 0.1840 best r: 0.1840
15:26:14,240 root INFO 
id:ro_en cur r: 0.7387 best r: 0.7387
15:27:06,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:37,350 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5624
en_de Dev loss: 0.9889 r:0.1844
en_zh Dev loss: 0.8635 r:0.3650
ro_en Dev loss: 0.4589 r:0.7400
et_en Dev loss: 0.4665 r:0.6235
si_en Dev loss: 0.8008 r:0.5192
ne_en Dev loss: 0.5409 r:0.6506
ru_en Dev loss: 0.5407 r:0.7190
Current avg r:0.5431 Best avg r: 0.5533
15:33:08,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:21,861 root INFO 
id:en_de cur r: 0.2119 best r: 0.2119
15:33:47,836 root INFO 
id:ro_en cur r: 0.7486 best r: 0.7486
15:34:13,898 root INFO 
id:si_en cur r: 0.5110 best r: 0.5110
15:34:26,932 root INFO 
id:ne_en cur r: 0.6877 best r: 0.6877
15:34:39,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:10,923 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:36:10,929 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:36:10,934 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:36:10,938 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:36:10,943 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:36:10,948 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:36:10,953 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:36:24,5 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5555
en_de Dev loss: 0.9473 r:0.1933
en_zh Dev loss: 0.7383 r:0.4110
ro_en Dev loss: 0.3996 r:0.7472
et_en Dev loss: 0.4513 r:0.6361
si_en Dev loss: 0.6707 r:0.5323
ne_en Dev loss: 0.4148 r:0.6931
ru_en Dev loss: 0.4262 r:0.7411
Current avg r:0.5649 Best avg r: 0.5649
15:40:55,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:21,592 root INFO 
id:en_zh cur r: 0.3834 best r: 0.3834
15:41:34,613 root INFO 
id:ro_en cur r: 0.7610 best r: 0.7610
15:42:00,685 root INFO 
id:si_en cur r: 0.5300 best r: 0.5300
15:42:13,733 root INFO 
id:ne_en cur r: 0.7031 best r: 0.7031
15:42:26,681 root INFO 
id:ru_en cur r: 0.7250 best r: 0.7250
15:42:26,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:57,785 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:43:57,791 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:43:57,796 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:43:57,801 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:43:57,805 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:43:57,812 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:43:57,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:44:10,874 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5292
en_de Dev loss: 0.8976 r:0.2023
en_zh Dev loss: 0.7288 r:0.4103
ro_en Dev loss: 0.3796 r:0.7650
et_en Dev loss: 0.4554 r:0.6443
si_en Dev loss: 0.6450 r:0.5557
ne_en Dev loss: 0.4066 r:0.7023
ru_en Dev loss: 0.4072 r:0.7484
Current avg r:0.5755 Best avg r: 0.5755
15:48:42,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:08,505 root INFO 
id:en_zh cur r: 0.4055 best r: 0.4055
15:49:21,517 root INFO 
id:ro_en cur r: 0.7697 best r: 0.7697
15:49:47,590 root INFO 
id:si_en cur r: 0.5397 best r: 0.5397
15:50:13,574 root INFO 
id:ru_en cur r: 0.7299 best r: 0.7299
15:50:13,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:44,685 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:51:44,692 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:51:44,696 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:51:44,701 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:51:44,706 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:51:44,710 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:51:44,716 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:51:57,770 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5449
en_de Dev loss: 0.8728 r:0.2175
en_zh Dev loss: 0.7585 r:0.4211
ro_en Dev loss: 0.3695 r:0.7688
et_en Dev loss: 0.4638 r:0.6450
si_en Dev loss: 0.6891 r:0.5530
ne_en Dev loss: 0.4598 r:0.6965
ru_en Dev loss: 0.4329 r:0.7453
Current avg r:0.5782 Best avg r: 0.5782
15:56:29,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:55,468 root INFO 
id:en_zh cur r: 0.4190 best r: 0.4190
15:57:08,484 root INFO 
id:ro_en cur r: 0.7803 best r: 0.7803
15:57:34,548 root INFO 
id:si_en cur r: 0.5481 best r: 0.5481
15:57:47,593 root INFO 
id:ne_en cur r: 0.7126 best r: 0.7126
15:58:00,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:31,648 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:59:31,654 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:59:31,659 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:59:31,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:59:31,669 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:59:31,674 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:59:31,679 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:59:44,739 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5201
en_de Dev loss: 0.8685 r:0.2211
en_zh Dev loss: 0.7163 r:0.4333
ro_en Dev loss: 0.3784 r:0.7838
et_en Dev loss: 0.4505 r:0.6495
si_en Dev loss: 0.6765 r:0.5646
ne_en Dev loss: 0.4445 r:0.7053
ru_en Dev loss: 0.4681 r:0.7380
Current avg r:0.5851 Best avg r: 0.5851
16:04:16,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:29,465 root INFO 
id:en_de cur r: 0.2224 best r: 0.2224
16:05:47,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:18,601 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5206
en_de Dev loss: 0.9205 r:0.2172
en_zh Dev loss: 0.7657 r:0.4337
ro_en Dev loss: 0.4021 r:0.7770
et_en Dev loss: 0.5017 r:0.6290
si_en Dev loss: 0.8460 r:0.5474
ne_en Dev loss: 0.5056 r:0.7115
ru_en Dev loss: 0.5057 r:0.7246
Current avg r:0.5772 Best avg r: 0.5851
16:11:50,355 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:03,351 root INFO 
id:en_de cur r: 0.2523 best r: 0.2523
16:12:29,328 root INFO 
id:ro_en cur r: 0.7924 best r: 0.7924
16:12:55,387 root INFO 
id:et_en cur r: 0.6515 best r: 0.6515
16:13:08,424 root INFO 
id:si_en cur r: 0.5481 best r: 0.5481
16:13:21,461 root INFO 
id:ne_en cur r: 0.7364 best r: 0.7364
16:13:34,395 root INFO 
id:ru_en cur r: 0.7359 best r: 0.7359
16:13:34,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:05,469 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:15:05,475 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:15:05,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:15:05,487 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:15:05,492 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:15:05,497 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:15:05,504 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:15:18,549 root INFO Epoch 0 Global steps: 9100 Train loss: 0.4881
en_de Dev loss: 0.8742 r:0.2437
en_zh Dev loss: 0.7219 r:0.4370
ro_en Dev loss: 0.3561 r:0.7886
et_en Dev loss: 0.4712 r:0.6565
si_en Dev loss: 0.6816 r:0.5636
ne_en Dev loss: 0.3850 r:0.7348
ru_en Dev loss: 0.4120 r:0.7481
Current avg r:0.5960 Best avg r: 0.5960
16:19:50,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:16,297 root INFO 
id:en_zh cur r: 0.4364 best r: 0.4364
16:20:29,311 root INFO 
id:ro_en cur r: 0.7999 best r: 0.7999
16:20:55,375 root INFO 
id:et_en cur r: 0.6523 best r: 0.6523
16:21:08,428 root INFO 
id:si_en cur r: 0.5549 best r: 0.5549
16:21:21,471 root INFO 
id:ne_en cur r: 0.7390 best r: 0.7390
16:21:34,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:05,521 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:23:05,527 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:23:05,532 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:23:05,537 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:23:05,542 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:23:05,546 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:23:05,552 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:23:18,604 root INFO Epoch 0 Global steps: 9800 Train loss: 0.4842
en_de Dev loss: 0.8533 r:0.2396
en_zh Dev loss: 0.6923 r:0.4511
ro_en Dev loss: 0.3530 r:0.7982
et_en Dev loss: 0.4491 r:0.6640
si_en Dev loss: 0.6638 r:0.5688
ne_en Dev loss: 0.4082 r:0.7346
ru_en Dev loss: 0.4205 r:0.7458
Current avg r:0.6003 Best avg r: 0.6003
16:27:50,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:16,280 root INFO 
id:en_zh cur r: 0.4527 best r: 0.4527
16:28:29,289 root INFO 
id:ro_en cur r: 0.8037 best r: 0.8037
16:28:55,368 root INFO 
id:et_en cur r: 0.6705 best r: 0.6705
16:29:08,405 root INFO 
id:si_en cur r: 0.5841 best r: 0.5841
16:29:21,455 root INFO 
id:ne_en cur r: 0.7480 best r: 0.7480
16:29:34,433 root INFO 
id:ru_en cur r: 0.7647 best r: 0.7647
16:29:34,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:05,565 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:31:05,571 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:31:05,576 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:31:05,581 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:31:05,586 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:31:05,591 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:31:05,600 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:31:18,672 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5227
en_de Dev loss: 0.8442 r:0.2304
en_zh Dev loss: 0.7129 r:0.4658
ro_en Dev loss: 0.3269 r:0.8027
et_en Dev loss: 0.4459 r:0.6800
si_en Dev loss: 0.6346 r:0.5908
ne_en Dev loss: 0.3450 r:0.7541
ru_en Dev loss: 0.3803 r:0.7646
Current avg r:0.6126 Best avg r: 0.6126
16:35:52,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:31,361 root INFO 
id:ro_en cur r: 0.8057 best r: 0.8057
16:37:10,476 root INFO 
id:ne_en cur r: 0.7519 best r: 0.7519
16:37:23,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:54,544 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4849
en_de Dev loss: 0.8676 r:0.2561
en_zh Dev loss: 0.7877 r:0.4521
ro_en Dev loss: 0.3601 r:0.8038
et_en Dev loss: 0.4870 r:0.6475
si_en Dev loss: 0.7429 r:0.5796
ne_en Dev loss: 0.4602 r:0.7471
ru_en Dev loss: 0.4805 r:0.7366
Current avg r:0.6033 Best avg r: 0.6126
16:43:26,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:52,216 root INFO 
id:en_zh cur r: 0.4733 best r: 0.4733
16:44:44,327 root INFO 
id:ne_en cur r: 0.7558 best r: 0.7558
16:44:57,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:28,509 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4890
en_de Dev loss: 0.8851 r:0.2112
en_zh Dev loss: 0.7528 r:0.4775
ro_en Dev loss: 0.3809 r:0.8015
et_en Dev loss: 0.5064 r:0.6571
si_en Dev loss: 0.7858 r:0.5774
ne_en Dev loss: 0.4512 r:0.7504
ru_en Dev loss: 0.4796 r:0.7413
Current avg r:0.6023 Best avg r: 0.6126
16:51:00,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:39,152 root INFO 
id:ro_en cur r: 0.8063 best r: 0.8063
16:52:31,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:02,211 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4378
en_de Dev loss: 0.8471 r:0.2641
en_zh Dev loss: 0.7466 r:0.4682
ro_en Dev loss: 0.3768 r:0.8047
et_en Dev loss: 0.4584 r:0.6650
si_en Dev loss: 0.8666 r:0.5757
ne_en Dev loss: 0.5485 r:0.7434
ru_en Dev loss: 0.4648 r:0.7463
Current avg r:0.6096 Best avg r: 0.6126
16:58:33,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:12,722 root INFO 
id:ro_en cur r: 0.8103 best r: 0.8103
16:59:38,771 root INFO 
id:et_en cur r: 0.6742 best r: 0.6742
17:00:17,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:48,846 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
17:01:48,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:01:48,858 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:01:48,862 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
17:01:48,866 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
17:01:48,871 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:01:48,878 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:02:01,925 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4660
en_de Dev loss: 0.8234 r:0.2744
en_zh Dev loss: 0.6504 r:0.4731
ro_en Dev loss: 0.3046 r:0.8100
et_en Dev loss: 0.4200 r:0.6805
si_en Dev loss: 0.6165 r:0.5906
ne_en Dev loss: 0.4098 r:0.7434
ru_en Dev loss: 0.3781 r:0.7583
Current avg r:0.6186 Best avg r: 0.6186
17:06:33,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:12,574 root INFO 
id:ro_en cur r: 0.8110 best r: 0.8110
17:07:38,626 root INFO 
id:et_en cur r: 0.6750 best r: 0.6750
17:07:51,663 root INFO 
id:si_en cur r: 0.5922 best r: 0.5922
17:08:17,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:48,756 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4407
en_de Dev loss: 0.8912 r:0.2674
en_zh Dev loss: 0.8047 r:0.4652
ro_en Dev loss: 0.3676 r:0.8092
et_en Dev loss: 0.4565 r:0.6802
si_en Dev loss: 0.7212 r:0.5960
ne_en Dev loss: 0.4352 r:0.7541
ru_en Dev loss: 0.5059 r:0.7471
Current avg r:0.6171 Best avg r: 0.6186
17:14:20,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:59,548 root INFO 
id:ro_en cur r: 0.8133 best r: 0.8133
17:15:25,606 root INFO 
id:et_en cur r: 0.6811 best r: 0.6811
17:15:38,641 root INFO 
id:si_en cur r: 0.5944 best r: 0.5944
17:16:04,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:35,704 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4392
en_de Dev loss: 0.8545 r:0.2466
en_zh Dev loss: 0.7336 r:0.4558
ro_en Dev loss: 0.3393 r:0.8096
et_en Dev loss: 0.4698 r:0.6824
si_en Dev loss: 0.6365 r:0.5942
ne_en Dev loss: 0.3786 r:0.7538
ru_en Dev loss: 0.4131 r:0.7506
Current avg r:0.6133 Best avg r: 0.6186
17:22:07,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:38,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:09,489 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4432
en_de Dev loss: 0.8400 r:0.2303
en_zh Dev loss: 0.7280 r:0.4653
ro_en Dev loss: 0.4063 r:0.8079
et_en Dev loss: 0.4755 r:0.6727
si_en Dev loss: 0.8452 r:0.5862
ne_en Dev loss: 0.5346 r:0.7526
ru_en Dev loss: 0.5232 r:0.7373
Current avg r:0.6075 Best avg r: 0.6186
17:29:41,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:07,206 root INFO 
id:en_zh cur r: 0.4752 best r: 0.4752
17:30:20,216 root INFO 
id:ro_en cur r: 0.8135 best r: 0.8135
17:30:46,287 root INFO 
id:si_en cur r: 0.5958 best r: 0.5958
17:31:12,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:43,295 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4406
en_de Dev loss: 0.8390 r:0.2331
en_zh Dev loss: 0.7056 r:0.4751
ro_en Dev loss: 0.3422 r:0.8122
et_en Dev loss: 0.4477 r:0.6809
si_en Dev loss: 0.7217 r:0.5959
ne_en Dev loss: 0.5408 r:0.7484
ru_en Dev loss: 0.4436 r:0.7424
Current avg r:0.6126 Best avg r: 0.6186
17:37:14,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:27,974 root INFO 
id:en_de cur r: 0.2564 best r: 0.2564
17:37:53,953 root INFO 
id:ro_en cur r: 0.8180 best r: 0.8180
17:38:33,66 root INFO 
id:ne_en cur r: 0.7575 best r: 0.7575
17:38:45,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:17,58 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4542
en_de Dev loss: 0.8322 r:0.2592
en_zh Dev loss: 0.6812 r:0.4632
ro_en Dev loss: 0.3382 r:0.8136
et_en Dev loss: 0.4587 r:0.6756
si_en Dev loss: 0.6418 r:0.5974
ne_en Dev loss: 0.3992 r:0.7562
ru_en Dev loss: 0.4787 r:0.7237
Current avg r:0.6127 Best avg r: 0.6186
17:44:48,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:01,873 root INFO 
id:en_de cur r: 0.2650 best r: 0.2650
17:45:53,903 root INFO 
id:si_en cur r: 0.5985 best r: 0.5985
17:46:19,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:50,937 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4148
en_de Dev loss: 0.8489 r:0.2616
en_zh Dev loss: 0.7366 r:0.4585
ro_en Dev loss: 0.3466 r:0.8139
et_en Dev loss: 0.4613 r:0.6773
si_en Dev loss: 0.7269 r:0.5995
ne_en Dev loss: 0.4193 r:0.7579
ru_en Dev loss: 0.4419 r:0.7455
Current avg r:0.6163 Best avg r: 0.6186
17:52:22,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:35,670 root INFO 
id:en_de cur r: 0.2839 best r: 0.2839
17:53:01,660 root INFO 
id:ro_en cur r: 0.8184 best r: 0.8184
17:53:27,711 root INFO 
id:si_en cur r: 0.6034 best r: 0.6034
17:53:40,754 root INFO 
id:ne_en cur r: 0.7589 best r: 0.7589
17:53:53,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:24,759 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4064
en_de Dev loss: 0.8513 r:0.2540
en_zh Dev loss: 0.7957 r:0.4539
ro_en Dev loss: 0.3208 r:0.8174
et_en Dev loss: 0.4409 r:0.6801
si_en Dev loss: 0.7091 r:0.6040
ne_en Dev loss: 0.4879 r:0.7607
ru_en Dev loss: 0.4696 r:0.7416
Current avg r:0.6159 Best avg r: 0.6186
17:59:56,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:09,544 root INFO 
id:en_de cur r: 0.2896 best r: 0.2896
18:01:01,606 root INFO 
id:si_en cur r: 0.6057 best r: 0.6057
18:01:27,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:58,628 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4178
en_de Dev loss: 0.8710 r:0.2658
en_zh Dev loss: 0.8124 r:0.4570
ro_en Dev loss: 0.3648 r:0.8119
et_en Dev loss: 0.4686 r:0.6667
si_en Dev loss: 0.8165 r:0.5972
ne_en Dev loss: 0.5035 r:0.7534
ru_en Dev loss: 0.4686 r:0.7517
Current avg r:0.6148 Best avg r: 0.6186
18:07:30,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:43,362 root INFO 
id:en_de cur r: 0.2920 best r: 0.2920
18:09:01,371 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:32,433 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4420
en_de Dev loss: 0.8819 r:0.2550
en_zh Dev loss: 0.9425 r:0.4427
ro_en Dev loss: 0.4670 r:0.8084
et_en Dev loss: 0.5635 r:0.6626
si_en Dev loss: 0.9926 r:0.5912
ne_en Dev loss: 0.5781 r:0.7542
ru_en Dev loss: 0.6057 r:0.7279
Current avg r:0.6060 Best avg r: 0.6186
18:15:04,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:35,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:06,337 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4357
en_de Dev loss: 0.8658 r:0.2595
en_zh Dev loss: 0.8297 r:0.4416
ro_en Dev loss: 0.3858 r:0.8080
et_en Dev loss: 0.4707 r:0.6756
si_en Dev loss: 0.8507 r:0.5872
ne_en Dev loss: 0.4440 r:0.7581
ru_en Dev loss: 0.5312 r:0.7249
Current avg r:0.6078 Best avg r: 0.6186
18:22:38,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:43,133 root INFO 
id:et_en cur r: 0.6844 best r: 0.6844
18:24:22,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:53,199 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4649
en_de Dev loss: 0.8890 r:0.2541
en_zh Dev loss: 0.9223 r:0.4465
ro_en Dev loss: 0.4621 r:0.8143
et_en Dev loss: 0.5019 r:0.6865
si_en Dev loss: 0.8730 r:0.6043
ne_en Dev loss: 0.5038 r:0.7604
ru_en Dev loss: 0.6643 r:0.7173
Current avg r:0.6119 Best avg r: 0.6186
18:30:26,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:05,236 root INFO 
id:ro_en cur r: 0.8252 best r: 0.8252
18:31:31,285 root INFO 
id:et_en cur r: 0.6934 best r: 0.6934
18:31:44,327 root INFO 
id:si_en cur r: 0.6094 best r: 0.6094
18:31:57,360 root INFO 
id:ne_en cur r: 0.7662 best r: 0.7662
18:32:10,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:41,378 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
18:33:41,384 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:33:41,389 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:33:41,394 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
18:33:41,398 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
18:33:41,402 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:33:41,407 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:33:54,452 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4098
en_de Dev loss: 0.8523 r:0.2782
en_zh Dev loss: 0.7826 r:0.4462
ro_en Dev loss: 0.3565 r:0.8216
et_en Dev loss: 0.4440 r:0.6899
si_en Dev loss: 0.8134 r:0.6004
ne_en Dev loss: 0.4873 r:0.7653
ru_en Dev loss: 0.4398 r:0.7509
Current avg r:0.6218 Best avg r: 0.6218
18:38:26,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:04,996 root INFO 
id:ro_en cur r: 0.8257 best r: 0.8257
18:39:31,57 root INFO 
id:et_en cur r: 0.6966 best r: 0.6966
18:39:44,102 root INFO 
id:si_en cur r: 0.6230 best r: 0.6230
18:40:10,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:41,180 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
18:41:41,187 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:41:41,192 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:41:41,197 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
18:41:41,204 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
18:41:41,209 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:41:41,214 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:41:54,257 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4083
en_de Dev loss: 0.8290 r:0.2686
en_zh Dev loss: 0.6938 r:0.4644
ro_en Dev loss: 0.3132 r:0.8229
et_en Dev loss: 0.4697 r:0.6959
si_en Dev loss: 0.5626 r:0.6259
ne_en Dev loss: 0.3391 r:0.7675
ru_en Dev loss: 0.3733 r:0.7636
Current avg r:0.6298 Best avg r: 0.6298
18:46:25,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:56,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:27,904 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4126
en_de Dev loss: 0.8288 r:0.2685
en_zh Dev loss: 0.7594 r:0.4526
ro_en Dev loss: 0.3396 r:0.8201
et_en Dev loss: 0.4710 r:0.6800
si_en Dev loss: 0.6442 r:0.6097
ne_en Dev loss: 0.3651 r:0.7653
ru_en Dev loss: 0.4415 r:0.7404
Current avg r:0.6195 Best avg r: 0.6298
18:53:59,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:12,379 root INFO 
id:en_de cur r: 0.3086 best r: 0.3086
18:55:30,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:01,250 root INFO Epoch 2 Global steps: 23800 Train loss: 0.3811
en_de Dev loss: 0.8373 r:0.2783
en_zh Dev loss: 0.7669 r:0.4541
ro_en Dev loss: 0.3741 r:0.8175
et_en Dev loss: 0.4784 r:0.6797
si_en Dev loss: 0.7465 r:0.6049
ne_en Dev loss: 0.4728 r:0.7624
ru_en Dev loss: 0.5009 r:0.7303
Current avg r:0.6182 Best avg r: 0.6298
19:01:32,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:11,753 root INFO 
id:ro_en cur r: 0.8261 best r: 0.8261
19:03:03,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:34,800 root INFO Epoch 2 Global steps: 24500 Train loss: 0.3806
en_de Dev loss: 0.8483 r:0.2771
en_zh Dev loss: 0.7140 r:0.4710
ro_en Dev loss: 0.3420 r:0.8216
et_en Dev loss: 0.4365 r:0.6867
si_en Dev loss: 0.8151 r:0.6077
ne_en Dev loss: 0.4570 r:0.7681
ru_en Dev loss: 0.4832 r:0.7388
Current avg r:0.6244 Best avg r: 0.6298
19:09:06,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:45,243 root INFO 
id:ro_en cur r: 0.8274 best r: 0.8274
19:10:24,340 root INFO 
id:ne_en cur r: 0.7732 best r: 0.7732
19:10:37,267 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:12:08,304 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3672
en_de Dev loss: 0.8394 r:0.2721
en_zh Dev loss: 0.6793 r:0.4726
ro_en Dev loss: 0.3042 r:0.8242
et_en Dev loss: 0.4025 r:0.6945
si_en Dev loss: 0.7388 r:0.6145
ne_en Dev loss: 0.4129 r:0.7745
ru_en Dev loss: 0.4112 r:0.7529
Current avg r:0.6293 Best avg r: 0.6298
19:16:39,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:10,752 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:41,695 root INFO Epoch 2 Global steps: 25900 Train loss: 0.3700
en_de Dev loss: 0.8401 r:0.2615
en_zh Dev loss: 0.7255 r:0.4610
ro_en Dev loss: 0.3598 r:0.8212
et_en Dev loss: 0.4489 r:0.6889
si_en Dev loss: 0.7381 r:0.6113
ne_en Dev loss: 0.4204 r:0.7689
ru_en Dev loss: 0.4409 r:0.7460
Current avg r:0.6227 Best avg r: 0.6298
19:24:13,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:52,27 root INFO 
id:ro_en cur r: 0.8277 best r: 0.8277
19:25:44,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:14,993 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3483
en_de Dev loss: 0.8443 r:0.2665
en_zh Dev loss: 0.7405 r:0.4667
ro_en Dev loss: 0.3695 r:0.8245
et_en Dev loss: 0.4572 r:0.6950
si_en Dev loss: 0.7625 r:0.6078
ne_en Dev loss: 0.3973 r:0.7716
ru_en Dev loss: 0.4422 r:0.7567
Current avg r:0.6270 Best avg r: 0.6298
19:31:46,510 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:12,458 root INFO 
id:en_zh cur r: 0.4754 best r: 0.4754
19:32:51,506 root INFO 
id:et_en cur r: 0.6988 best r: 0.6988
19:33:17,569 root INFO 
id:ne_en cur r: 0.7750 best r: 0.7750
19:33:30,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:01,511 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3723
en_de Dev loss: 0.8256 r:0.2677
en_zh Dev loss: 0.7147 r:0.4755
ro_en Dev loss: 0.3369 r:0.8230
et_en Dev loss: 0.4466 r:0.6961
si_en Dev loss: 0.6713 r:0.6124
ne_en Dev loss: 0.4244 r:0.7741
ru_en Dev loss: 0.4110 r:0.7577
Current avg r:0.6295 Best avg r: 0.6298
19:39:33,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:04,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:35,40 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3823
en_de Dev loss: 0.8437 r:0.2688
en_zh Dev loss: 0.7568 r:0.4594
ro_en Dev loss: 0.3507 r:0.8172
et_en Dev loss: 0.4691 r:0.6810
si_en Dev loss: 0.7944 r:0.5946
ne_en Dev loss: 0.5031 r:0.7621
ru_en Dev loss: 0.4580 r:0.7443
Current avg r:0.6182 Best avg r: 0.6298
19:47:06,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:32,546 root INFO 
id:en_zh cur r: 0.4766 best r: 0.4766
19:48:37,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:08,559 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3660
en_de Dev loss: 0.8384 r:0.2739
en_zh Dev loss: 0.7179 r:0.4723
ro_en Dev loss: 0.3317 r:0.8231
et_en Dev loss: 0.4245 r:0.6943
si_en Dev loss: 0.6793 r:0.6132
ne_en Dev loss: 0.4051 r:0.7730
ru_en Dev loss: 0.4235 r:0.7578
Current avg r:0.6297 Best avg r: 0.6298
19:54:40,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:11,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:42,88 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3766
en_de Dev loss: 0.8295 r:0.2582
en_zh Dev loss: 0.7324 r:0.4721
ro_en Dev loss: 0.3104 r:0.8245
et_en Dev loss: 0.4230 r:0.6918
si_en Dev loss: 0.6620 r:0.6080
ne_en Dev loss: 0.3854 r:0.7681
ru_en Dev loss: 0.4350 r:0.7441
Current avg r:0.6238 Best avg r: 0.6298
20:02:13,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:39,556 root INFO 
id:en_zh cur r: 0.4780 best r: 0.4780
20:03:44,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:15,526 root INFO Epoch 2 Global steps: 30100 Train loss: 0.4107
en_de Dev loss: 0.8294 r:0.2614
en_zh Dev loss: 0.7055 r:0.4749
ro_en Dev loss: 0.3296 r:0.8224
et_en Dev loss: 0.4221 r:0.6965
si_en Dev loss: 0.7310 r:0.6090
ne_en Dev loss: 0.5049 r:0.7635
ru_en Dev loss: 0.4483 r:0.7459
Current avg r:0.6248 Best avg r: 0.6298
20:09:46,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:17,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:48,931 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3695
en_de Dev loss: 0.8632 r:0.2314
en_zh Dev loss: 0.7713 r:0.4723
ro_en Dev loss: 0.3360 r:0.8254
et_en Dev loss: 0.4357 r:0.6917
si_en Dev loss: 0.7498 r:0.6059
ne_en Dev loss: 0.4618 r:0.7559
ru_en Dev loss: 0.4961 r:0.7339
Current avg r:0.6166 Best avg r: 0.6298
20:17:20,398 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:46,389 root INFO 
id:en_zh cur r: 0.4790 best r: 0.4790
20:18:51,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:22,436 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3420
en_de Dev loss: 0.8492 r:0.2582
en_zh Dev loss: 0.7491 r:0.4738
ro_en Dev loss: 0.3719 r:0.8206
et_en Dev loss: 0.4636 r:0.6857
si_en Dev loss: 0.8468 r:0.5955
ne_en Dev loss: 0.5738 r:0.7617
ru_en Dev loss: 0.4579 r:0.7497
Current avg r:0.6208 Best avg r: 0.6298
20:24:55,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:34,499 root INFO 
id:ro_en cur r: 0.8281 best r: 0.8281
20:26:26,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:57,573 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3185
en_de Dev loss: 0.8610 r:0.2490
en_zh Dev loss: 0.8159 r:0.4652
ro_en Dev loss: 0.3593 r:0.8268
et_en Dev loss: 0.4607 r:0.6918
si_en Dev loss: 0.7851 r:0.6034
ne_en Dev loss: 0.4626 r:0.7600
ru_en Dev loss: 0.5220 r:0.7376
Current avg r:0.6191 Best avg r: 0.6298
20:32:29,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:00,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:31,203 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3146
en_de Dev loss: 0.8614 r:0.2396
en_zh Dev loss: 0.8085 r:0.4553
ro_en Dev loss: 0.3382 r:0.8234
et_en Dev loss: 0.4367 r:0.6844
si_en Dev loss: 0.7183 r:0.6042
ne_en Dev loss: 0.4543 r:0.7636
ru_en Dev loss: 0.4682 r:0.7395
Current avg r:0.6157 Best avg r: 0.6298
20:40:02,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:41,662 root INFO 
id:ro_en cur r: 0.8316 best r: 0.8316
20:41:33,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:04,666 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3410
en_de Dev loss: 0.8365 r:0.2548
en_zh Dev loss: 0.7431 r:0.4516
ro_en Dev loss: 0.3015 r:0.8278
et_en Dev loss: 0.3958 r:0.6916
si_en Dev loss: 0.6603 r:0.6064
ne_en Dev loss: 0.4107 r:0.7632
ru_en Dev loss: 0.4208 r:0.7436
Current avg r:0.6199 Best avg r: 0.6298
20:47:36,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:07,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:38,153 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3364
en_de Dev loss: 0.8437 r:0.2487
en_zh Dev loss: 0.7532 r:0.4590
ro_en Dev loss: 0.3418 r:0.8244
et_en Dev loss: 0.4588 r:0.6827
si_en Dev loss: 0.7288 r:0.5980
ne_en Dev loss: 0.4658 r:0.7565
ru_en Dev loss: 0.4238 r:0.7488
Current avg r:0.6169 Best avg r: 0.6298
20:55:09,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:22,498 root INFO 
id:en_de cur r: 0.3153 best r: 0.3153
20:56:40,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:11,404 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3155
en_de Dev loss: 0.8326 r:0.2779
en_zh Dev loss: 0.7479 r:0.4543
ro_en Dev loss: 0.3426 r:0.8236
et_en Dev loss: 0.4244 r:0.6880
si_en Dev loss: 0.8368 r:0.5877
ne_en Dev loss: 0.4736 r:0.7606
ru_en Dev loss: 0.4187 r:0.7500
Current avg r:0.6203 Best avg r: 0.6298
21:02:42,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:13,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:44,862 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3369
en_de Dev loss: 0.8373 r:0.2676
en_zh Dev loss: 0.7154 r:0.4589
ro_en Dev loss: 0.3371 r:0.8221
et_en Dev loss: 0.4155 r:0.6917
si_en Dev loss: 0.7451 r:0.6003
ne_en Dev loss: 0.4565 r:0.7541
ru_en Dev loss: 0.4379 r:0.7484
Current avg r:0.6204 Best avg r: 0.6298
21:10:16,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:47,306 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:18,322 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3152
en_de Dev loss: 0.8499 r:0.2566
en_zh Dev loss: 0.7837 r:0.4572
ro_en Dev loss: 0.3443 r:0.8207
et_en Dev loss: 0.4267 r:0.6897
si_en Dev loss: 0.7508 r:0.6035
ne_en Dev loss: 0.4041 r:0.7601
ru_en Dev loss: 0.4240 r:0.7590
Current avg r:0.6210 Best avg r: 0.6298
21:17:49,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:20,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:51,900 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3349
en_de Dev loss: 0.8282 r:0.2700
en_zh Dev loss: 0.7684 r:0.4658
ro_en Dev loss: 0.3578 r:0.8263
et_en Dev loss: 0.4653 r:0.6943
si_en Dev loss: 0.7737 r:0.6057
ne_en Dev loss: 0.4544 r:0.7585
ru_en Dev loss: 0.4619 r:0.7510
Current avg r:0.6245 Best avg r: 0.6298
21:25:23,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:26:54,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:28:25,291 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3094
en_de Dev loss: 0.8695 r:0.2466
en_zh Dev loss: 0.8094 r:0.4482
ro_en Dev loss: 0.3842 r:0.8212
et_en Dev loss: 0.4817 r:0.6787
si_en Dev loss: 0.8597 r:0.5897
ne_en Dev loss: 0.5547 r:0.7521
ru_en Dev loss: 0.5128 r:0.7248
Current avg r:0.6088 Best avg r: 0.6298
21:32:56,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:27,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:58,793 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3485
en_de Dev loss: 0.8440 r:0.2605
en_zh Dev loss: 0.7545 r:0.4446
ro_en Dev loss: 0.3465 r:0.8215
et_en Dev loss: 0.4573 r:0.6823
si_en Dev loss: 0.8088 r:0.5890
ne_en Dev loss: 0.4967 r:0.7515
ru_en Dev loss: 0.4910 r:0.7229
Current avg r:0.6103 Best avg r: 0.6298
21:40:30,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:01,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:32,168 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3227
en_de Dev loss: 0.8787 r:0.2771
en_zh Dev loss: 0.8650 r:0.4383
ro_en Dev loss: 0.4043 r:0.8199
et_en Dev loss: 0.5082 r:0.6815
si_en Dev loss: 0.9184 r:0.5834
ne_en Dev loss: 0.5444 r:0.7568
ru_en Dev loss: 0.5748 r:0.7131
Current avg r:0.6100 Best avg r: 0.6298
21:48:03,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:16,722 root INFO 
id:en_de cur r: 0.3187 best r: 0.3187
21:49:34,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:05,711 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3205
en_de Dev loss: 0.8421 r:0.2944
en_zh Dev loss: 0.8072 r:0.4549
ro_en Dev loss: 0.3577 r:0.8247
et_en Dev loss: 0.4491 r:0.6949
si_en Dev loss: 0.7425 r:0.6086
ne_en Dev loss: 0.4671 r:0.7545
ru_en Dev loss: 0.4922 r:0.7398
Current avg r:0.6245 Best avg r: 0.6298
21:55:37,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:56:42,277 root INFO 
id:et_en cur r: 0.7018 best r: 0.7018
21:57:21,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:52,281 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3275
en_de Dev loss: 0.8316 r:0.2777
en_zh Dev loss: 0.7586 r:0.4512
ro_en Dev loss: 0.3244 r:0.8239
et_en Dev loss: 0.4277 r:0.6965
si_en Dev loss: 0.6675 r:0.6039
ne_en Dev loss: 0.4081 r:0.7595
ru_en Dev loss: 0.4435 r:0.7297
Current avg r:0.6203 Best avg r: 0.6298
22:03:23,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:54,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:25,713 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3174
en_de Dev loss: 0.8336 r:0.2692
en_zh Dev loss: 0.7122 r:0.4594
ro_en Dev loss: 0.3078 r:0.8270
et_en Dev loss: 0.3934 r:0.6995
si_en Dev loss: 0.6683 r:0.6004
ne_en Dev loss: 0.4107 r:0.7587
ru_en Dev loss: 0.4242 r:0.7331
Current avg r:0.6210 Best avg r: 0.6298
22:10:57,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:02,280 root INFO 
id:et_en cur r: 0.7030 best r: 0.7030
22:12:41,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:12,332 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3146
en_de Dev loss: 0.8208 r:0.2790
en_zh Dev loss: 0.7446 r:0.4637
ro_en Dev loss: 0.3257 r:0.8270
et_en Dev loss: 0.4184 r:0.7007
si_en Dev loss: 0.6435 r:0.6125
ne_en Dev loss: 0.3936 r:0.7608
ru_en Dev loss: 0.4193 r:0.7491
Current avg r:0.6275 Best avg r: 0.6298
22:18:45,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:16,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:21:47,488 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2825
en_de Dev loss: 0.8619 r:0.2616
en_zh Dev loss: 0.8648 r:0.4554
ro_en Dev loss: 0.3927 r:0.8229
et_en Dev loss: 0.4878 r:0.6909
si_en Dev loss: 0.8629 r:0.5914
ne_en Dev loss: 0.5306 r:0.7464
ru_en Dev loss: 0.5509 r:0.7206
Current avg r:0.6127 Best avg r: 0.6298
22:26:19,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:27:50,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:21,103 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2708
en_de Dev loss: 0.8566 r:0.2735
en_zh Dev loss: 0.7735 r:0.4556
ro_en Dev loss: 0.3252 r:0.8235
et_en Dev loss: 0.4302 r:0.6889
si_en Dev loss: 0.7998 r:0.5839
ne_en Dev loss: 0.4719 r:0.7508
ru_en Dev loss: 0.4671 r:0.7284
Current avg r:0.6150 Best avg r: 0.6298
22:33:52,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:23,640 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:54,638 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2936
en_de Dev loss: 0.8460 r:0.2653
en_zh Dev loss: 0.7522 r:0.4585
ro_en Dev loss: 0.3223 r:0.8271
et_en Dev loss: 0.4360 r:0.6913
si_en Dev loss: 0.6901 r:0.5983
ne_en Dev loss: 0.3990 r:0.7489
ru_en Dev loss: 0.4029 r:0.7574
Current avg r:0.6210 Best avg r: 0.6298
22:41:26,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:57,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:28,157 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2741
en_de Dev loss: 0.8708 r:0.2632
en_zh Dev loss: 0.8313 r:0.4418
ro_en Dev loss: 0.3559 r:0.8289
et_en Dev loss: 0.4756 r:0.6855
si_en Dev loss: 0.7521 r:0.5952
ne_en Dev loss: 0.4439 r:0.7523
ru_en Dev loss: 0.4722 r:0.7445
Current avg r:0.6159 Best avg r: 0.6298
22:48:59,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:30,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:01,646 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2730
en_de Dev loss: 0.8756 r:0.2598
en_zh Dev loss: 0.8166 r:0.4422
ro_en Dev loss: 0.3582 r:0.8264
et_en Dev loss: 0.4492 r:0.6825
si_en Dev loss: 0.7379 r:0.5865
ne_en Dev loss: 0.4532 r:0.7591
ru_en Dev loss: 0.4869 r:0.7397
Current avg r:0.6137 Best avg r: 0.6298
22:56:33,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:04,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:35,65 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2801
en_de Dev loss: 0.8420 r:0.2522
en_zh Dev loss: 0.7487 r:0.4564
ro_en Dev loss: 0.3335 r:0.8239
et_en Dev loss: 0.4310 r:0.6840
si_en Dev loss: 0.7473 r:0.5791
ne_en Dev loss: 0.4695 r:0.7485
ru_en Dev loss: 0.4216 r:0.7427
Current avg r:0.6124 Best avg r: 0.6298
23:04:06,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:37,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:08,366 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2808
en_de Dev loss: 0.8722 r:0.2245
en_zh Dev loss: 0.8015 r:0.4525
ro_en Dev loss: 0.3673 r:0.8273
et_en Dev loss: 0.4435 r:0.6926
si_en Dev loss: 0.7688 r:0.5926
ne_en Dev loss: 0.5405 r:0.7410
ru_en Dev loss: 0.5085 r:0.7335
Current avg r:0.6091 Best avg r: 0.6298
23:11:39,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:10,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:41,726 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2835
en_de Dev loss: 0.8494 r:0.2236
en_zh Dev loss: 0.7898 r:0.4608
ro_en Dev loss: 0.3444 r:0.8280
et_en Dev loss: 0.4291 r:0.6877
si_en Dev loss: 0.7852 r:0.5857
ne_en Dev loss: 0.4544 r:0.7435
ru_en Dev loss: 0.4478 r:0.7481
Current avg r:0.6111 Best avg r: 0.6298
23:19:13,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:44,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:14,987 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2819
en_de Dev loss: 0.8664 r:0.2410
en_zh Dev loss: 0.8090 r:0.4589
ro_en Dev loss: 0.3596 r:0.8238
et_en Dev loss: 0.4449 r:0.6866
si_en Dev loss: 0.8093 r:0.5834
ne_en Dev loss: 0.5253 r:0.7497
ru_en Dev loss: 0.4917 r:0.7359
Current avg r:0.6113 Best avg r: 0.6298
23:26:46,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:17,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:48,346 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2650
en_de Dev loss: 0.8395 r:0.2562
en_zh Dev loss: 0.7605 r:0.4587
ro_en Dev loss: 0.3244 r:0.8276
et_en Dev loss: 0.4268 r:0.6868
si_en Dev loss: 0.7768 r:0.5855
ne_en Dev loss: 0.4691 r:0.7473
ru_en Dev loss: 0.4586 r:0.7366
Current avg r:0.6141 Best avg r: 0.6298
23:34:19,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:50,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:21,851 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2661
en_de Dev loss: 0.8663 r:0.2449
en_zh Dev loss: 0.8539 r:0.4528
ro_en Dev loss: 0.3990 r:0.8253
et_en Dev loss: 0.4925 r:0.6850
si_en Dev loss: 0.9640 r:0.5724
ne_en Dev loss: 0.5491 r:0.7459
ru_en Dev loss: 0.5206 r:0.7403
Current avg r:0.6095 Best avg r: 0.6298
23:41:53,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:24,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:55,393 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2619
en_de Dev loss: 0.8458 r:0.2476
en_zh Dev loss: 0.7837 r:0.4513
ro_en Dev loss: 0.3288 r:0.8267
et_en Dev loss: 0.4328 r:0.6848
si_en Dev loss: 0.7489 r:0.5815
ne_en Dev loss: 0.5085 r:0.7421
ru_en Dev loss: 0.4302 r:0.7460
Current avg r:0.6114 Best avg r: 0.6298
23:49:27,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:58,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:29,103 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2751
en_de Dev loss: 0.8458 r:0.2526
en_zh Dev loss: 0.7754 r:0.4650
ro_en Dev loss: 0.3316 r:0.8317
et_en Dev loss: 0.4406 r:0.6935
si_en Dev loss: 0.7569 r:0.5891
ne_en Dev loss: 0.4451 r:0.7406
ru_en Dev loss: 0.4410 r:0.7579
Current avg r:0.6186 Best avg r: 0.6298
23:57:00,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:31,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:02,759 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2618
en_de Dev loss: 0.8617 r:0.2721
en_zh Dev loss: 0.8272 r:0.4475
ro_en Dev loss: 0.3585 r:0.8235
et_en Dev loss: 0.4675 r:0.6742
si_en Dev loss: 0.8813 r:0.5654
ne_en Dev loss: 0.5538 r:0.7365
ru_en Dev loss: 0.4845 r:0.7380
Current avg r:0.6082 Best avg r: 0.6298
00:04:34,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:06:05,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:36,500 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2642
en_de Dev loss: 0.8653 r:0.2550
en_zh Dev loss: 0.7834 r:0.4418
ro_en Dev loss: 0.3573 r:0.8249
et_en Dev loss: 0.4485 r:0.6865
si_en Dev loss: 0.7987 r:0.5790
ne_en Dev loss: 0.4368 r:0.7387
ru_en Dev loss: 0.4801 r:0.7367
Current avg r:0.6090 Best avg r: 0.6298
00:12:09,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:40,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:11,645 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2396
en_de Dev loss: 0.8566 r:0.2476
en_zh Dev loss: 0.8635 r:0.4383
ro_en Dev loss: 0.3586 r:0.8249
et_en Dev loss: 0.4689 r:0.6818
si_en Dev loss: 0.8578 r:0.5738
ne_en Dev loss: 0.5150 r:0.7409
ru_en Dev loss: 0.4622 r:0.7413
Current avg r:0.6069 Best avg r: 0.6298
00:19:42,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:21:13,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:44,855 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2292
en_de Dev loss: 0.8461 r:0.2632
en_zh Dev loss: 0.8334 r:0.4353
ro_en Dev loss: 0.3533 r:0.8259
et_en Dev loss: 0.4570 r:0.6807
si_en Dev loss: 0.8977 r:0.5687
ne_en Dev loss: 0.5125 r:0.7387
ru_en Dev loss: 0.4613 r:0.7400
Current avg r:0.6075 Best avg r: 0.6298
00:27:16,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:47,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:18,312 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2483
en_de Dev loss: 0.8586 r:0.2401
en_zh Dev loss: 0.8141 r:0.4347
ro_en Dev loss: 0.3571 r:0.8261
et_en Dev loss: 0.4395 r:0.6829
si_en Dev loss: 0.8190 r:0.5757
ne_en Dev loss: 0.5010 r:0.7380
ru_en Dev loss: 0.4886 r:0.7307
Current avg r:0.6040 Best avg r: 0.6298
00:34:49,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:20,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:51,513 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2304
en_de Dev loss: 0.8581 r:0.2282
en_zh Dev loss: 0.8237 r:0.4475
ro_en Dev loss: 0.3918 r:0.8230
et_en Dev loss: 0.4800 r:0.6800
si_en Dev loss: 1.0202 r:0.5537
ne_en Dev loss: 0.6378 r:0.7363
ru_en Dev loss: 0.5163 r:0.7274
Current avg r:0.5994 Best avg r: 0.6298
00:42:22,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:53,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:24,543 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2244
en_de Dev loss: 0.8768 r:0.2204
en_zh Dev loss: 0.7780 r:0.4573
ro_en Dev loss: 0.3229 r:0.8275
et_en Dev loss: 0.4167 r:0.6873
si_en Dev loss: 0.7526 r:0.5728
ne_en Dev loss: 0.4036 r:0.7428
ru_en Dev loss: 0.4563 r:0.7287
Current avg r:0.6053 Best avg r: 0.6298
00:49:56,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:26,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:57,859 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2282
en_de Dev loss: 0.8707 r:0.2182
en_zh Dev loss: 0.7878 r:0.4601
ro_en Dev loss: 0.3368 r:0.8208
et_en Dev loss: 0.4420 r:0.6737
si_en Dev loss: 0.8863 r:0.5558
ne_en Dev loss: 0.5513 r:0.7347
ru_en Dev loss: 0.4549 r:0.7286
Current avg r:0.5988 Best avg r: 0.6298
00:57:29,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:59,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:00:30,935 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2302
en_de Dev loss: 0.9028 r:0.2237
en_zh Dev loss: 0.9282 r:0.4501
ro_en Dev loss: 0.4295 r:0.8220
et_en Dev loss: 0.5106 r:0.6751
si_en Dev loss: 1.0367 r:0.5602
ne_en Dev loss: 0.6760 r:0.7371
ru_en Dev loss: 0.5836 r:0.7182
Current avg r:0.5980 Best avg r: 0.6298
01:05:02,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:33,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:04,165 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2340
en_de Dev loss: 0.8347 r:0.2603
en_zh Dev loss: 0.7820 r:0.4622
ro_en Dev loss: 0.3481 r:0.8284
et_en Dev loss: 0.4228 r:0.6879
si_en Dev loss: 0.7760 r:0.5806
ne_en Dev loss: 0.6062 r:0.7466
ru_en Dev loss: 0.4557 r:0.7314
Current avg r:0.6139 Best avg r: 0.6298
01:12:35,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:06,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:37,424 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2166
en_de Dev loss: 0.8474 r:0.2438
en_zh Dev loss: 0.8262 r:0.4496
ro_en Dev loss: 0.3426 r:0.8275
et_en Dev loss: 0.4274 r:0.6851
si_en Dev loss: 0.8169 r:0.5746
ne_en Dev loss: 0.5081 r:0.7448
ru_en Dev loss: 0.4922 r:0.7142
Current avg r:0.6057 Best avg r: 0.6298
01:20:08,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:39,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:10,528 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2230
en_de Dev loss: 0.8588 r:0.2486
en_zh Dev loss: 0.7760 r:0.4743
ro_en Dev loss: 0.3650 r:0.8235
et_en Dev loss: 0.4437 r:0.6865
si_en Dev loss: 0.8753 r:0.5697
ne_en Dev loss: 0.6061 r:0.7441
ru_en Dev loss: 0.4417 r:0.7428
Current avg r:0.6128 Best avg r: 0.6298
01:27:42,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:12,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:43,938 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2231
en_de Dev loss: 0.8512 r:0.2485
en_zh Dev loss: 0.7795 r:0.4569
ro_en Dev loss: 0.3640 r:0.8261
et_en Dev loss: 0.4370 r:0.6869
si_en Dev loss: 0.8090 r:0.5722
ne_en Dev loss: 0.6637 r:0.7367
ru_en Dev loss: 0.4735 r:0.7268
Current avg r:0.6077 Best avg r: 0.6298
01:35:15,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:36:46,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:17,36 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2340
en_de Dev loss: 0.8425 r:0.2651
en_zh Dev loss: 0.8048 r:0.4588
ro_en Dev loss: 0.3746 r:0.8238
et_en Dev loss: 0.4391 r:0.6890
si_en Dev loss: 0.8270 r:0.5734
ne_en Dev loss: 0.5198 r:0.7359
ru_en Dev loss: 0.4744 r:0.7335
Current avg r:0.6113 Best avg r: 0.6298
01:42:48,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:19,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:50,412 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2137
en_de Dev loss: 0.8593 r:0.2473
en_zh Dev loss: 0.7713 r:0.4687
ro_en Dev loss: 0.3356 r:0.8268
et_en Dev loss: 0.4153 r:0.6932
si_en Dev loss: 0.7661 r:0.5781
ne_en Dev loss: 0.4836 r:0.7398
ru_en Dev loss: 0.4527 r:0.7372
Current avg r:0.6130 Best avg r: 0.6298
01:50:21,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:52,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:53:23,945 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2218
en_de Dev loss: 0.8736 r:0.2371
en_zh Dev loss: 0.7682 r:0.4642
ro_en Dev loss: 0.3579 r:0.8230
et_en Dev loss: 0.4295 r:0.6814
si_en Dev loss: 0.8731 r:0.5666
ne_en Dev loss: 0.5169 r:0.7339
ru_en Dev loss: 0.4683 r:0.7304
Current avg r:0.6052 Best avg r: 0.6298
01:57:55,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:58:21,670 root INFO 
id:en_zh cur r: 0.4799 best r: 0.4799
01:59:27,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:59,449 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2285
en_de Dev loss: 0.8948 r:0.2189
en_zh Dev loss: 0.7835 r:0.4714
ro_en Dev loss: 0.3660 r:0.8251
et_en Dev loss: 0.4434 r:0.6817
si_en Dev loss: 0.9090 r:0.5660
ne_en Dev loss: 0.5302 r:0.7279
ru_en Dev loss: 0.5268 r:0.7147
Current avg r:0.6008 Best avg r: 0.6298
02:05:36,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:07:08,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:08:39,941 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2011
en_de Dev loss: 0.8790 r:0.2191
en_zh Dev loss: 0.7910 r:0.4675
ro_en Dev loss: 0.3892 r:0.8222
et_en Dev loss: 0.4558 r:0.6811
si_en Dev loss: 0.8626 r:0.5697
ne_en Dev loss: 0.5673 r:0.7261
ru_en Dev loss: 0.5052 r:0.7171
Current avg r:0.6004 Best avg r: 0.6298
02:13:14,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:14:46,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:16:18,512 root INFO Epoch 6 Global steps: 64400 Train loss: 0.1996
en_de Dev loss: 0.8984 r:0.2009
en_zh Dev loss: 0.8199 r:0.4663
ro_en Dev loss: 0.3699 r:0.8210
et_en Dev loss: 0.4375 r:0.6778
si_en Dev loss: 0.8288 r:0.5716
ne_en Dev loss: 0.5737 r:0.7280
ru_en Dev loss: 0.5177 r:0.7122
Current avg r:0.5968 Best avg r: 0.6298
02:20:53,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:22:25,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:23:57,150 root INFO Epoch 6 Global steps: 65100 Train loss: 0.1939
en_de Dev loss: 0.9146 r:0.2075
en_zh Dev loss: 0.8970 r:0.4531
ro_en Dev loss: 0.4133 r:0.8141
et_en Dev loss: 0.4935 r:0.6719
si_en Dev loss: 1.0157 r:0.5467
ne_en Dev loss: 0.7578 r:0.7227
ru_en Dev loss: 0.5394 r:0.7128
Current avg r:0.5898 Best avg r: 0.6298
02:28:30,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:30:02,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:31:33,288 root INFO Epoch 6 Global steps: 65800 Train loss: 0.1982
en_de Dev loss: 0.8865 r:0.1972
en_zh Dev loss: 0.8196 r:0.4533
ro_en Dev loss: 0.3936 r:0.8157
et_en Dev loss: 0.4456 r:0.6726
si_en Dev loss: 0.9938 r:0.5480
ne_en Dev loss: 0.6327 r:0.7219
ru_en Dev loss: 0.4839 r:0.7196
Current avg r:0.5897 Best avg r: 0.6298
02:36:05,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:36,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:39:07,906 root INFO Epoch 6 Global steps: 66500 Train loss: 0.1931
en_de Dev loss: 0.8875 r:0.1941
en_zh Dev loss: 0.8249 r:0.4645
ro_en Dev loss: 0.3469 r:0.8255
et_en Dev loss: 0.4162 r:0.6877
si_en Dev loss: 0.8388 r:0.5787
ne_en Dev loss: 0.4828 r:0.7337
ru_en Dev loss: 0.4310 r:0.7497
Current avg r:0.6048 Best avg r: 0.6298
02:43:40,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:45:11,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:46:42,617 root INFO Epoch 6 Global steps: 67200 Train loss: 0.1969
en_de Dev loss: 0.8952 r:0.2071
en_zh Dev loss: 0.8194 r:0.4699
ro_en Dev loss: 0.3806 r:0.8226
et_en Dev loss: 0.4404 r:0.6867
si_en Dev loss: 0.7980 r:0.5806
ne_en Dev loss: 0.5433 r:0.7342
ru_en Dev loss: 0.4895 r:0.7355
Current avg r:0.6052 Best avg r: 0.6298
02:51:16,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:52:47,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:54:18,844 root INFO Epoch 6 Global steps: 67900 Train loss: 0.1954
en_de Dev loss: 0.8931 r:0.2125
en_zh Dev loss: 0.8313 r:0.4494
ro_en Dev loss: 0.3726 r:0.8193
et_en Dev loss: 0.4435 r:0.6746
si_en Dev loss: 0.8920 r:0.5595
ne_en Dev loss: 0.5506 r:0.7264
ru_en Dev loss: 0.4800 r:0.7219
Current avg r:0.5948 Best avg r: 0.6298
02:58:51,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:00:22,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:01:53,563 root INFO Epoch 6 Global steps: 68600 Train loss: 0.1992
en_de Dev loss: 0.9207 r:0.1878
en_zh Dev loss: 0.8747 r:0.4567
ro_en Dev loss: 0.4061 r:0.8214
et_en Dev loss: 0.4638 r:0.6810
si_en Dev loss: 0.9329 r:0.5607
ne_en Dev loss: 0.5505 r:0.7308
ru_en Dev loss: 0.5163 r:0.7330
Current avg r:0.5959 Best avg r: 0.6298
03:06:26,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:07:57,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:09:28,432 root INFO Epoch 6 Global steps: 69300 Train loss: 0.1852
en_de Dev loss: 0.8921 r:0.1921
en_zh Dev loss: 0.8047 r:0.4457
ro_en Dev loss: 0.3693 r:0.8152
et_en Dev loss: 0.4277 r:0.6766
si_en Dev loss: 0.9563 r:0.5407
ne_en Dev loss: 0.5858 r:0.7273
ru_en Dev loss: 0.4821 r:0.7233
Current avg r:0.5887 Best avg r: 0.6298
03:14:00,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:15:32,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:17:03,257 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1975
en_de Dev loss: 0.8899 r:0.2007
en_zh Dev loss: 0.8634 r:0.4459
ro_en Dev loss: 0.3908 r:0.8220
et_en Dev loss: 0.4412 r:0.6849
si_en Dev loss: 0.8424 r:0.5623
ne_en Dev loss: 0.4845 r:0.7240
ru_en Dev loss: 0.5340 r:0.7114
Current avg r:0.5930 Best avg r: 0.6298
03:21:35,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:23:06,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:24:38,141 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1997
en_de Dev loss: 0.8985 r:0.1999
en_zh Dev loss: 0.8608 r:0.4510
ro_en Dev loss: 0.3830 r:0.8257
et_en Dev loss: 0.4322 r:0.6927
si_en Dev loss: 0.8228 r:0.5736
ne_en Dev loss: 0.5544 r:0.7296
ru_en Dev loss: 0.4904 r:0.7390
Current avg r:0.6017 Best avg r: 0.6298
03:29:10,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:30:41,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:32:12,961 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1940
en_de Dev loss: 0.8812 r:0.1886
en_zh Dev loss: 0.8211 r:0.4491
ro_en Dev loss: 0.3612 r:0.8207
et_en Dev loss: 0.4435 r:0.6796
si_en Dev loss: 0.9493 r:0.5488
ne_en Dev loss: 0.7314 r:0.7123
ru_en Dev loss: 0.5004 r:0.7198
Current avg r:0.5884 Best avg r: 0.6298
03:36:45,510 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:38:16,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:39:47,902 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2048
en_de Dev loss: 0.8892 r:0.2124
en_zh Dev loss: 0.8323 r:0.4490
ro_en Dev loss: 0.3795 r:0.8182
et_en Dev loss: 0.4308 r:0.6845
si_en Dev loss: 0.7664 r:0.5724
ne_en Dev loss: 0.5718 r:0.7254
ru_en Dev loss: 0.4698 r:0.7335
Current avg r:0.5993 Best avg r: 0.6298
03:44:20,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:45:51,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:47:22,828 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2004
en_de Dev loss: 0.9166 r:0.2035
en_zh Dev loss: 0.9264 r:0.4490
ro_en Dev loss: 0.4449 r:0.8162
et_en Dev loss: 0.5060 r:0.6820
si_en Dev loss: 1.0426 r:0.5561
ne_en Dev loss: 0.6963 r:0.7242
ru_en Dev loss: 0.5568 r:0.7303
Current avg r:0.5945 Best avg r: 0.6298
03:51:55,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:53:26,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:54:57,659 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1888
en_de Dev loss: 0.8891 r:0.2067
en_zh Dev loss: 0.8222 r:0.4535
ro_en Dev loss: 0.3326 r:0.8282
et_en Dev loss: 0.4110 r:0.6894
si_en Dev loss: 0.7453 r:0.5775
ne_en Dev loss: 0.4402 r:0.7331
ru_en Dev loss: 0.4602 r:0.7318
Current avg r:0.6029 Best avg r: 0.6298
03:59:31,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:01:02,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:02:34,154 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1845
en_de Dev loss: 0.8824 r:0.2215
en_zh Dev loss: 0.8009 r:0.4628
ro_en Dev loss: 0.3597 r:0.8231
et_en Dev loss: 0.4467 r:0.6818
si_en Dev loss: 0.9135 r:0.5539
ne_en Dev loss: 0.5596 r:0.7256
ru_en Dev loss: 0.4561 r:0.7407
Current avg r:0.6013 Best avg r: 0.6298
04:07:08,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:08:40,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:10:12,674 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1753
en_de Dev loss: 0.9106 r:0.1953
en_zh Dev loss: 0.7873 r:0.4720
ro_en Dev loss: 0.3383 r:0.8246
et_en Dev loss: 0.4176 r:0.6873
si_en Dev loss: 0.7894 r:0.5662
ne_en Dev loss: 0.4839 r:0.7330
ru_en Dev loss: 0.4444 r:0.7416
Current avg r:0.6029 Best avg r: 0.6298
04:14:47,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:16:19,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:17:51,243 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1618
en_de Dev loss: 0.9011 r:0.2043
en_zh Dev loss: 0.8211 r:0.4677
ro_en Dev loss: 0.3614 r:0.8239
et_en Dev loss: 0.4371 r:0.6796
si_en Dev loss: 0.8292 r:0.5589
ne_en Dev loss: 0.5728 r:0.7240
ru_en Dev loss: 0.4466 r:0.7385
Current avg r:0.5996 Best avg r: 0.6298
04:22:25,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:23:57,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:25:29,448 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1718
en_de Dev loss: 0.9081 r:0.2168
en_zh Dev loss: 0.8408 r:0.4550
ro_en Dev loss: 0.4159 r:0.8161
et_en Dev loss: 0.4616 r:0.6880
si_en Dev loss: 0.9484 r:0.5465
ne_en Dev loss: 0.6614 r:0.7262
ru_en Dev loss: 0.4927 r:0.7297
Current avg r:0.5969 Best avg r: 0.6298
04:30:01,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:31:32,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:33:03,814 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1689
en_de Dev loss: 0.9310 r:0.2060
en_zh Dev loss: 0.8357 r:0.4581
ro_en Dev loss: 0.4075 r:0.8188
et_en Dev loss: 0.4698 r:0.6906
si_en Dev loss: 0.9677 r:0.5527
ne_en Dev loss: 0.6065 r:0.7276
ru_en Dev loss: 0.5430 r:0.7275
Current avg r:0.5973 Best avg r: 0.6298
04:37:36,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:39:07,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:40:38,30 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1667
en_de Dev loss: 0.8992 r:0.1883
en_zh Dev loss: 0.7973 r:0.4492
ro_en Dev loss: 0.3454 r:0.8198
et_en Dev loss: 0.4083 r:0.6896
si_en Dev loss: 0.9033 r:0.5568
ne_en Dev loss: 0.6125 r:0.7238
ru_en Dev loss: 0.4806 r:0.7232
Current avg r:0.5930 Best avg r: 0.6298
04:45:10,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:46:41,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:12,233 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1756
en_de Dev loss: 0.9167 r:0.1998
en_zh Dev loss: 0.8858 r:0.4640
ro_en Dev loss: 0.3842 r:0.8216
et_en Dev loss: 0.4495 r:0.6843
si_en Dev loss: 0.9151 r:0.5660
ne_en Dev loss: 0.6121 r:0.7247
ru_en Dev loss: 0.5045 r:0.7337
Current avg r:0.5991 Best avg r: 0.6298
04:52:43,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:54:14,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:55:45,957 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1679
en_de Dev loss: 0.9153 r:0.2030
en_zh Dev loss: 0.8837 r:0.4549
ro_en Dev loss: 0.3867 r:0.8162
et_en Dev loss: 0.4614 r:0.6804
si_en Dev loss: 0.9137 r:0.5522
ne_en Dev loss: 0.5719 r:0.7208
ru_en Dev loss: 0.4836 r:0.7349
Current avg r:0.5946 Best avg r: 0.6298
05:00:17,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:01:48,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:19,991 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1705
en_de Dev loss: 0.8932 r:0.2020
en_zh Dev loss: 0.8464 r:0.4546
ro_en Dev loss: 0.3916 r:0.8138
et_en Dev loss: 0.4534 r:0.6789
si_en Dev loss: 0.9207 r:0.5513
ne_en Dev loss: 0.6180 r:0.7177
ru_en Dev loss: 0.5009 r:0.7188
Current avg r:0.5910 Best avg r: 0.6298
05:07:51,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:09:22,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:10:53,574 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1720
en_de Dev loss: 0.8891 r:0.2008
en_zh Dev loss: 0.8402 r:0.4611
ro_en Dev loss: 0.3720 r:0.8198
et_en Dev loss: 0.4464 r:0.6794
si_en Dev loss: 0.9750 r:0.5510
ne_en Dev loss: 0.6226 r:0.7162
ru_en Dev loss: 0.5181 r:0.7232
Current avg r:0.5931 Best avg r: 0.6298
05:15:25,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:16:56,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:27,439 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1814
en_de Dev loss: 0.8886 r:0.1994
en_zh Dev loss: 0.8385 r:0.4562
ro_en Dev loss: 0.3644 r:0.8197
et_en Dev loss: 0.4341 r:0.6836
si_en Dev loss: 0.9229 r:0.5502
ne_en Dev loss: 0.5904 r:0.7181
ru_en Dev loss: 0.4505 r:0.7366
Current avg r:0.5948 Best avg r: 0.6298
05:22:59,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:24:30,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:01,135 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1660
en_de Dev loss: 0.8771 r:0.2063
en_zh Dev loss: 0.7815 r:0.4571
ro_en Dev loss: 0.3410 r:0.8246
et_en Dev loss: 0.4141 r:0.6896
si_en Dev loss: 0.7821 r:0.5732
ne_en Dev loss: 0.4862 r:0.7234
ru_en Dev loss: 0.4314 r:0.7439
Current avg r:0.6026 Best avg r: 0.6298
05:30:33,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:32:04,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:33:35,192 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1709
en_de Dev loss: 0.8647 r:0.2237
en_zh Dev loss: 0.8742 r:0.4454
ro_en Dev loss: 0.3860 r:0.8129
et_en Dev loss: 0.4371 r:0.6812
si_en Dev loss: 0.9935 r:0.5524
ne_en Dev loss: 0.6521 r:0.7191
ru_en Dev loss: 0.5261 r:0.7075
Current avg r:0.5917 Best avg r: 0.6298
05:38:06,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:39:37,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:41:08,908 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1634
en_de Dev loss: 0.8936 r:0.2158
en_zh Dev loss: 0.8544 r:0.4590
ro_en Dev loss: 0.3736 r:0.8206
et_en Dev loss: 0.4426 r:0.6864
si_en Dev loss: 0.9097 r:0.5676
ne_en Dev loss: 0.6415 r:0.7195
ru_en Dev loss: 0.4917 r:0.7360
Current avg r:0.6007 Best avg r: 0.6298
05:45:41,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:47:12,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:48:43,918 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1605
en_de Dev loss: 0.8892 r:0.2132
en_zh Dev loss: 0.8246 r:0.4693
ro_en Dev loss: 0.3534 r:0.8214
et_en Dev loss: 0.4201 r:0.6839
si_en Dev loss: 0.8929 r:0.5624
ne_en Dev loss: 0.5271 r:0.7254
ru_en Dev loss: 0.4778 r:0.7335
Current avg r:0.6013 Best avg r: 0.6298
05:53:19,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:51,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:56:23,46 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1575
en_de Dev loss: 0.9130 r:0.1881
en_zh Dev loss: 0.8465 r:0.4571
ro_en Dev loss: 0.3808 r:0.8187
et_en Dev loss: 0.4433 r:0.6813
si_en Dev loss: 0.8933 r:0.5596
ne_en Dev loss: 0.6131 r:0.7244
ru_en Dev loss: 0.5141 r:0.7294
Current avg r:0.5941 Best avg r: 0.6298
06:00:57,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:02:29,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:01,40 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1523
en_de Dev loss: 0.9259 r:0.1893
en_zh Dev loss: 0.8597 r:0.4601
ro_en Dev loss: 0.3652 r:0.8210
et_en Dev loss: 0.4340 r:0.6809
si_en Dev loss: 0.8530 r:0.5640
ne_en Dev loss: 0.5075 r:0.7246
ru_en Dev loss: 0.4983 r:0.7357
Current avg r:0.5965 Best avg r: 0.6298
06:08:35,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:10:07,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:38,645 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1506
en_de Dev loss: 0.9694 r:0.1551
en_zh Dev loss: 0.9219 r:0.4618
ro_en Dev loss: 0.4115 r:0.8218
et_en Dev loss: 0.4647 r:0.6791
si_en Dev loss: 1.0471 r:0.5522
ne_en Dev loss: 0.6523 r:0.7159
ru_en Dev loss: 0.5355 r:0.7423
Current avg r:0.5897 Best avg r: 0.6298
06:16:10,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:41,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:19:12,662 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1477
en_de Dev loss: 0.9338 r:0.1771
en_zh Dev loss: 0.8684 r:0.4540
ro_en Dev loss: 0.3726 r:0.8204
et_en Dev loss: 0.4328 r:0.6800
si_en Dev loss: 0.8917 r:0.5579
ne_en Dev loss: 0.5619 r:0.7171
ru_en Dev loss: 0.4823 r:0.7345
Current avg r:0.5916 Best avg r: 0.6298
06:23:44,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:25:15,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:47,112 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1478
en_de Dev loss: 0.9025 r:0.1760
en_zh Dev loss: 0.7755 r:0.4633
ro_en Dev loss: 0.3264 r:0.8241
et_en Dev loss: 0.3958 r:0.6845
si_en Dev loss: 0.8405 r:0.5643
ne_en Dev loss: 0.5419 r:0.7261
ru_en Dev loss: 0.4143 r:0.7494
Current avg r:0.5982 Best avg r: 0.6298
06:31:19,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:32:50,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:34:21,563 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1412
en_de Dev loss: 0.9358 r:0.1737
en_zh Dev loss: 0.8935 r:0.4532
ro_en Dev loss: 0.3857 r:0.8223
et_en Dev loss: 0.4422 r:0.6848
si_en Dev loss: 0.9287 r:0.5572
ne_en Dev loss: 0.5970 r:0.7241
ru_en Dev loss: 0.4905 r:0.7414
Current avg r:0.5938 Best avg r: 0.6298
06:38:53,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:40:24,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:41:56,149 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1547
en_de Dev loss: 0.9301 r:0.1973
en_zh Dev loss: 0.8168 r:0.4697
ro_en Dev loss: 0.3500 r:0.8213
et_en Dev loss: 0.4315 r:0.6811
si_en Dev loss: 0.8176 r:0.5651
ne_en Dev loss: 0.5194 r:0.7241
ru_en Dev loss: 0.4533 r:0.7403
Current avg r:0.5998 Best avg r: 0.6298
06:46:28,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:59,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:49:30,669 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1470
en_de Dev loss: 0.9070 r:0.1747
en_zh Dev loss: 0.7672 r:0.4694
ro_en Dev loss: 0.3301 r:0.8247
et_en Dev loss: 0.4076 r:0.6855
si_en Dev loss: 0.7792 r:0.5758
ne_en Dev loss: 0.5411 r:0.7212
ru_en Dev loss: 0.4289 r:0.7506
Current avg r:0.6003 Best avg r: 0.6298
06:54:03,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:55:34,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:57:05,535 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1546
en_de Dev loss: 0.9053 r:0.1767
en_zh Dev loss: 0.8245 r:0.4613
ro_en Dev loss: 0.3654 r:0.8239
et_en Dev loss: 0.4366 r:0.6765
si_en Dev loss: 0.8116 r:0.5629
ne_en Dev loss: 0.5564 r:0.7155
ru_en Dev loss: 0.4400 r:0.7515
Current avg r:0.5955 Best avg r: 0.6298
07:01:37,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:03:09,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:04:40,442 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1466
en_de Dev loss: 0.9163 r:0.1822
en_zh Dev loss: 0.8303 r:0.4576
ro_en Dev loss: 0.3563 r:0.8266
et_en Dev loss: 0.4282 r:0.6815
si_en Dev loss: 0.8125 r:0.5515
ne_en Dev loss: 0.5842 r:0.7064
ru_en Dev loss: 0.4439 r:0.7506
Current avg r:0.5938 Best avg r: 0.6298
07:09:12,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:10:44,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:12:15,283 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1478
en_de Dev loss: 0.8904 r:0.1982
en_zh Dev loss: 0.7897 r:0.4683
ro_en Dev loss: 0.3341 r:0.8249
et_en Dev loss: 0.4168 r:0.6854
si_en Dev loss: 0.8167 r:0.5616
ne_en Dev loss: 0.5716 r:0.7173
ru_en Dev loss: 0.4476 r:0.7409
Current avg r:0.5995 Best avg r: 0.6298
07:16:47,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:18:18,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:19:49,607 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1537
en_de Dev loss: 0.8935 r:0.1939
en_zh Dev loss: 0.8431 r:0.4541
ro_en Dev loss: 0.3534 r:0.8247
et_en Dev loss: 0.4219 r:0.6795
si_en Dev loss: 0.8635 r:0.5573
ne_en Dev loss: 0.5430 r:0.7152
ru_en Dev loss: 0.4852 r:0.7257
Current avg r:0.5929 Best avg r: 0.6298
07:24:21,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:52,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:27:23,846 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1432
en_de Dev loss: 0.8873 r:0.2325
en_zh Dev loss: 0.8407 r:0.4631
ro_en Dev loss: 0.3526 r:0.8252
et_en Dev loss: 0.4304 r:0.6825
si_en Dev loss: 0.8606 r:0.5649
ne_en Dev loss: 0.5327 r:0.7163
ru_en Dev loss: 0.4468 r:0.7480
Current avg r:0.6046 Best avg r: 0.6298
07:31:55,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:33:26,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:34:57,807 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1450
en_de Dev loss: 0.8949 r:0.2293
en_zh Dev loss: 0.8542 r:0.4533
ro_en Dev loss: 0.3769 r:0.8190
et_en Dev loss: 0.4463 r:0.6720
si_en Dev loss: 0.9150 r:0.5511
ne_en Dev loss: 0.5797 r:0.7104
ru_en Dev loss: 0.4913 r:0.7302
Current avg r:0.5951 Best avg r: 0.6298
07:39:29,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:41:01,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:33,780 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1448
en_de Dev loss: 0.9009 r:0.2194
en_zh Dev loss: 0.8610 r:0.4487
ro_en Dev loss: 0.3624 r:0.8211
et_en Dev loss: 0.4380 r:0.6781
si_en Dev loss: 0.8762 r:0.5630
ne_en Dev loss: 0.5641 r:0.7160
ru_en Dev loss: 0.4603 r:0.7481
Current avg r:0.5992 Best avg r: 0.6298
07:47:09,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:41,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:50:13,752 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1321
en_de Dev loss: 0.9013 r:0.2332
en_zh Dev loss: 0.8524 r:0.4654
ro_en Dev loss: 0.3719 r:0.8243
et_en Dev loss: 0.4414 r:0.6812
si_en Dev loss: 0.8788 r:0.5666
ne_en Dev loss: 0.5462 r:0.7138
ru_en Dev loss: 0.4674 r:0.7488
Current avg r:0.6048 Best avg r: 0.6298
07:54:48,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:56:20,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:57:52,323 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1355
en_de Dev loss: 0.8875 r:0.2078
en_zh Dev loss: 0.8003 r:0.4726
ro_en Dev loss: 0.3618 r:0.8226
et_en Dev loss: 0.4305 r:0.6809
si_en Dev loss: 0.9020 r:0.5548
ne_en Dev loss: 0.6018 r:0.7147
ru_en Dev loss: 0.4542 r:0.7381
Current avg r:0.5988 Best avg r: 0.6298
08:02:26,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:03:58,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:05:29,418 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1303
en_de Dev loss: 0.8895 r:0.2015
en_zh Dev loss: 0.7881 r:0.4651
ro_en Dev loss: 0.3369 r:0.8219
et_en Dev loss: 0.4085 r:0.6810
si_en Dev loss: 0.8878 r:0.5437
ne_en Dev loss: 0.5385 r:0.7139
ru_en Dev loss: 0.4236 r:0.7404
Current avg r:0.5953 Best avg r: 0.6298
08:10:01,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:11:32,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:13:03,553 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1285
en_de Dev loss: 0.8963 r:0.2011
en_zh Dev loss: 0.8426 r:0.4639
ro_en Dev loss: 0.3705 r:0.8204
et_en Dev loss: 0.4232 r:0.6790
si_en Dev loss: 0.9334 r:0.5458
ne_en Dev loss: 0.6401 r:0.7153
ru_en Dev loss: 0.4505 r:0.7376
Current avg r:0.5947 Best avg r: 0.6298
08:17:35,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:19:06,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:20:37,997 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1282
en_de Dev loss: 0.9037 r:0.2137
en_zh Dev loss: 0.7984 r:0.4734
ro_en Dev loss: 0.3473 r:0.8236
et_en Dev loss: 0.4116 r:0.6822
si_en Dev loss: 0.8437 r:0.5550
ne_en Dev loss: 0.5701 r:0.7162
ru_en Dev loss: 0.4064 r:0.7548
Current avg r:0.6027 Best avg r: 0.6298
08:25:10,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:41,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:28:12,629 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1280
en_de Dev loss: 0.9473 r:0.1893
en_zh Dev loss: 0.8392 r:0.4751
ro_en Dev loss: 0.4011 r:0.8208
et_en Dev loss: 0.4519 r:0.6838
si_en Dev loss: 0.9374 r:0.5544
ne_en Dev loss: 0.6316 r:0.7192
ru_en Dev loss: 0.4887 r:0.7483
Current avg r:0.5987 Best avg r: 0.6298
08:32:44,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:34:16,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:35:47,270 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1291
en_de Dev loss: 0.9273 r:0.1720
en_zh Dev loss: 0.8027 r:0.4713
ro_en Dev loss: 0.3543 r:0.8228
et_en Dev loss: 0.4024 r:0.6817
si_en Dev loss: 0.8608 r:0.5584
ne_en Dev loss: 0.5274 r:0.7187
ru_en Dev loss: 0.4591 r:0.7431
Current avg r:0.5954 Best avg r: 0.6298
08:40:19,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:41:50,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:21,980 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1226
en_de Dev loss: 0.9251 r:0.1694
en_zh Dev loss: 0.7816 r:0.4732
ro_en Dev loss: 0.3396 r:0.8221
et_en Dev loss: 0.4053 r:0.6812
si_en Dev loss: 0.8973 r:0.5482
ne_en Dev loss: 0.6344 r:0.7132
ru_en Dev loss: 0.4723 r:0.7345
Current avg r:0.5917 Best avg r: 0.6298
08:47:54,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:49:25,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:50:56,787 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1308
en_de Dev loss: 0.9358 r:0.1797
en_zh Dev loss: 0.7969 r:0.4746
ro_en Dev loss: 0.3424 r:0.8201
et_en Dev loss: 0.4077 r:0.6803
si_en Dev loss: 0.9214 r:0.5425
ne_en Dev loss: 0.5712 r:0.7163
ru_en Dev loss: 0.4424 r:0.7459
Current avg r:0.5942 Best avg r: 0.6298
08:55:29,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:57:00,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:58:31,722 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1258
en_de Dev loss: 0.9630 r:0.1653
en_zh Dev loss: 0.8611 r:0.4709
ro_en Dev loss: 0.3904 r:0.8203
et_en Dev loss: 0.4462 r:0.6779
si_en Dev loss: 0.9574 r:0.5428
ne_en Dev loss: 0.5897 r:0.7087
ru_en Dev loss: 0.4990 r:0.7398
Current avg r:0.5894 Best avg r: 0.6298
09:03:04,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:04:35,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:06:06,655 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1357
en_de Dev loss: 0.9148 r:0.1841
en_zh Dev loss: 0.7623 r:0.4675
ro_en Dev loss: 0.3284 r:0.8268
et_en Dev loss: 0.4043 r:0.6820
si_en Dev loss: 0.8492 r:0.5497
ne_en Dev loss: 0.5819 r:0.7144
ru_en Dev loss: 0.4330 r:0.7466
Current avg r:0.5959 Best avg r: 0.6298
09:10:40,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:12:12,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:13:44,894 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1307
en_de Dev loss: 0.9395 r:0.1819
en_zh Dev loss: 0.8578 r:0.4611
ro_en Dev loss: 0.3770 r:0.8208
et_en Dev loss: 0.4334 r:0.6842
si_en Dev loss: 0.8914 r:0.5505
ne_en Dev loss: 0.6595 r:0.7178
ru_en Dev loss: 0.4908 r:0.7363
Current avg r:0.5932 Best avg r: 0.6298
09:18:19,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:19:51,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:21:23,527 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1245
en_de Dev loss: 0.9273 r:0.1844
en_zh Dev loss: 0.8124 r:0.4602
ro_en Dev loss: 0.3483 r:0.8233
et_en Dev loss: 0.4215 r:0.6780
si_en Dev loss: 0.9036 r:0.5450
ne_en Dev loss: 0.6036 r:0.7119
ru_en Dev loss: 0.4953 r:0.7251
Current avg r:0.5897 Best avg r: 0.6298
09:25:58,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:27:30,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:29:02,338 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1326
en_de Dev loss: 0.9491 r:0.1637
en_zh Dev loss: 0.8412 r:0.4669
ro_en Dev loss: 0.3757 r:0.8220
et_en Dev loss: 0.4473 r:0.6789
si_en Dev loss: 0.9348 r:0.5511
ne_en Dev loss: 0.5700 r:0.7134
ru_en Dev loss: 0.5357 r:0.7236
Current avg r:0.5885 Best avg r: 0.6298
09:33:35,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:06,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:37,985 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1234
en_de Dev loss: 0.9664 r:0.1610
en_zh Dev loss: 0.8496 r:0.4626
ro_en Dev loss: 0.3582 r:0.8243
et_en Dev loss: 0.4251 r:0.6858
si_en Dev loss: 0.9014 r:0.5508
ne_en Dev loss: 0.6095 r:0.7114
ru_en Dev loss: 0.4997 r:0.7348
Current avg r:0.5901 Best avg r: 0.6298
09:41:11,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:42,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:44:14,100 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1172
en_de Dev loss: 0.9696 r:0.1689
en_zh Dev loss: 0.8799 r:0.4628
ro_en Dev loss: 0.3682 r:0.8233
et_en Dev loss: 0.4426 r:0.6827
si_en Dev loss: 0.9739 r:0.5448
ne_en Dev loss: 0.7192 r:0.7098
ru_en Dev loss: 0.5156 r:0.7337
Current avg r:0.5894 Best avg r: 0.6298
09:48:46,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:50:17,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:48,985 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1055
en_de Dev loss: 0.9492 r:0.1722
en_zh Dev loss: 0.8066 r:0.4663
ro_en Dev loss: 0.3518 r:0.8252
et_en Dev loss: 0.4127 r:0.6865
si_en Dev loss: 0.8431 r:0.5542
ne_en Dev loss: 0.5559 r:0.7089
ru_en Dev loss: 0.4349 r:0.7482
Current avg r:0.5945 Best avg r: 0.6298
09:56:21,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:52,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:23,845 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1128
en_de Dev loss: 0.9243 r:0.1925
en_zh Dev loss: 0.7982 r:0.4712
ro_en Dev loss: 0.3462 r:0.8220
et_en Dev loss: 0.4038 r:0.6875
si_en Dev loss: 0.8495 r:0.5551
ne_en Dev loss: 0.5198 r:0.7167
ru_en Dev loss: 0.4255 r:0.7494
Current avg r:0.5992 Best avg r: 0.6298
10:03:56,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:27,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:58,787 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1139
en_de Dev loss: 0.9502 r:0.1770
en_zh Dev loss: 0.8564 r:0.4709
ro_en Dev loss: 0.3508 r:0.8261
et_en Dev loss: 0.4156 r:0.6858
si_en Dev loss: 0.8639 r:0.5532
ne_en Dev loss: 0.5982 r:0.7033
ru_en Dev loss: 0.4802 r:0.7400
Current avg r:0.5937 Best avg r: 0.6298
10:11:31,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:02,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:33,828 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1148
en_de Dev loss: 0.9386 r:0.1649
en_zh Dev loss: 0.7708 r:0.4752
ro_en Dev loss: 0.3387 r:0.8215
et_en Dev loss: 0.3982 r:0.6848
si_en Dev loss: 0.8698 r:0.5537
ne_en Dev loss: 0.6344 r:0.7071
ru_en Dev loss: 0.4148 r:0.7533
Current avg r:0.5944 Best avg r: 0.6298
10:19:06,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:37,555 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:08,839 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1200
en_de Dev loss: 0.9334 r:0.1759
en_zh Dev loss: 0.8061 r:0.4658
ro_en Dev loss: 0.3655 r:0.8187
et_en Dev loss: 0.4184 r:0.6812
si_en Dev loss: 0.8697 r:0.5523
ne_en Dev loss: 0.5331 r:0.7122
ru_en Dev loss: 0.4547 r:0.7433
Current avg r:0.5928 Best avg r: 0.6298
10:26:41,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:12,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:43,758 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1129
en_de Dev loss: 0.9467 r:0.1750
en_zh Dev loss: 0.8540 r:0.4591
ro_en Dev loss: 0.3663 r:0.8197
et_en Dev loss: 0.4212 r:0.6760
si_en Dev loss: 0.8927 r:0.5472
ne_en Dev loss: 0.5649 r:0.7038
ru_en Dev loss: 0.4410 r:0.7528
Current avg r:0.5905 Best avg r: 0.6298
