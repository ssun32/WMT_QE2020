14:56:35,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:01,710 root INFO 
id:en_zh cur r: 0.2741 best r: 0.2741
14:57:14,707 root INFO 
id:ro_en cur r: 0.5217 best r: 0.5217
14:57:27,719 root INFO 
id:et_en cur r: 0.5568 best r: 0.5568
14:57:40,750 root INFO 
id:si_en cur r: 0.4503 best r: 0.4503
14:58:06,778 root INFO 
id:ne_en cur r: 0.5817 best r: 0.5817
14:58:19,705 root INFO 
id:ru_en cur r: 0.5678 best r: 0.5678
14:58:19,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:50,635 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:59:50,640 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:59:50,645 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:59:50,651 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:59:50,656 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:59:50,661 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:59:50,665 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:00:03,705 root INFO Epoch 0 Global steps: 700 Train loss: 0.8409
en_de Dev loss: 0.8941 r:0.1117
en_zh Dev loss: 0.7941 r:0.2626
ro_en Dev loss: 0.6340 r:0.6272
et_en Dev loss: 0.4981 r:0.5853
si_en Dev loss: 0.7147 r:0.4432
ne_en Dev loss: 0.5366 r:0.6149
ru_en Dev loss: 0.6192 r:0.5461
Current avg r:0.4558 Best avg r: 0.4558
15:04:36,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:49,720 root INFO 
id:en_de cur r: 0.0785 best r: 0.0785
15:05:15,681 root INFO 
id:ro_en cur r: 0.5929 best r: 0.5929
15:05:28,701 root INFO 
id:et_en cur r: 0.5923 best r: 0.5923
15:06:07,793 root INFO 
id:ne_en cur r: 0.5883 best r: 0.5883
15:06:20,724 root INFO 
id:ru_en cur r: 0.6322 best r: 0.6322
15:06:20,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:51,694 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:07:51,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:07:51,705 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:07:51,710 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:07:51,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:07:51,719 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:07:51,724 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:08:04,756 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7896
en_de Dev loss: 0.9236 r:0.1245
en_zh Dev loss: 0.7670 r:0.3006
ro_en Dev loss: 0.6675 r:0.6481
et_en Dev loss: 0.4873 r:0.6262
si_en Dev loss: 0.7608 r:0.4994
ne_en Dev loss: 0.5609 r:0.6333
ru_en Dev loss: 0.5828 r:0.6903
Current avg r:0.5032 Best avg r: 0.5032
15:12:38,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:51,650 root INFO 
id:en_de cur r: 0.0914 best r: 0.0914
15:13:04,619 root INFO 
id:en_zh cur r: 0.3277 best r: 0.3277
15:13:17,614 root INFO 
id:ro_en cur r: 0.6555 best r: 0.6555
15:13:30,627 root INFO 
id:et_en cur r: 0.6380 best r: 0.6380
15:13:43,663 root INFO 
id:si_en cur r: 0.4885 best r: 0.4885
15:14:09,730 root INFO 
id:ne_en cur r: 0.6480 best r: 0.6480
15:14:22,661 root INFO 
id:ru_en cur r: 0.7151 best r: 0.7151
15:14:22,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:15:53,622 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:15:53,629 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:15:53,634 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:15:53,639 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:15:53,644 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:15:53,648 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:15:53,657 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:16:06,703 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7047
en_de Dev loss: 0.9857 r:0.1362
en_zh Dev loss: 0.8099 r:0.3481
ro_en Dev loss: 0.6310 r:0.6840
et_en Dev loss: 0.4463 r:0.6662
si_en Dev loss: 0.7832 r:0.5240
ne_en Dev loss: 0.4895 r:0.6740
ru_en Dev loss: 0.5636 r:0.7315
Current avg r:0.5377 Best avg r: 0.5377
15:20:39,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:52,813 root INFO 
id:en_de cur r: 0.1227 best r: 0.1227
15:21:05,809 root INFO 
id:en_zh cur r: 0.3400 best r: 0.3400
15:21:18,828 root INFO 
id:ro_en cur r: 0.6627 best r: 0.6627
15:22:10,911 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:42,7 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:23:42,13 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:23:42,18 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:23:42,22 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:23:42,27 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:23:42,32 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:23:42,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:23:55,82 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6554
en_de Dev loss: 0.9569 r:0.1596
en_zh Dev loss: 0.8126 r:0.3618
ro_en Dev loss: 0.5718 r:0.6956
et_en Dev loss: 0.4379 r:0.6649
si_en Dev loss: 0.8453 r:0.5088
ne_en Dev loss: 0.6240 r:0.6516
ru_en Dev loss: 0.5641 r:0.7291
Current avg r:0.5388 Best avg r: 0.5388
15:28:29,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:28:42,117 root INFO 
id:en_de cur r: 0.1324 best r: 0.1324
15:28:55,94 root INFO 
id:en_zh cur r: 0.3786 best r: 0.3786
15:29:08,114 root INFO 
id:ro_en cur r: 0.7029 best r: 0.7029
15:29:21,150 root INFO 
id:et_en cur r: 0.6796 best r: 0.6796
15:29:34,201 root INFO 
id:si_en cur r: 0.5328 best r: 0.5328
15:30:00,300 root INFO 
id:ne_en cur r: 0.6965 best r: 0.6965
15:30:13,251 root INFO 
id:ru_en cur r: 0.7378 best r: 0.7378
15:30:13,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:44,365 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:31:44,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:31:44,375 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:31:44,379 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:31:44,384 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:31:44,389 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:31:44,393 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:31:57,449 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6301
en_de Dev loss: 0.9009 r:0.1809
en_zh Dev loss: 0.7307 r:0.3828
ro_en Dev loss: 0.4727 r:0.7227
et_en Dev loss: 0.3618 r:0.7029
si_en Dev loss: 0.6543 r:0.5533
ne_en Dev loss: 0.4416 r:0.7055
ru_en Dev loss: 0.4322 r:0.7491
Current avg r:0.5710 Best avg r: 0.5710
15:36:31,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:44,456 root INFO 
id:en_de cur r: 0.1452 best r: 0.1452
15:36:57,434 root INFO 
id:en_zh cur r: 0.3810 best r: 0.3810
15:37:10,444 root INFO 
id:ro_en cur r: 0.7319 best r: 0.7319
15:37:23,485 root INFO 
id:et_en cur r: 0.6851 best r: 0.6851
15:38:02,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:33,634 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5686
en_de Dev loss: 0.9029 r:0.1724
en_zh Dev loss: 0.7372 r:0.3835
ro_en Dev loss: 0.4493 r:0.7468
et_en Dev loss: 0.3794 r:0.6994
si_en Dev loss: 0.7314 r:0.5433
ne_en Dev loss: 0.6206 r:0.6912
ru_en Dev loss: 0.5014 r:0.7321
Current avg r:0.5670 Best avg r: 0.5710
15:44:07,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:46,748 root INFO 
id:ro_en cur r: 0.7478 best r: 0.7478
15:45:12,845 root INFO 
id:si_en cur r: 0.5459 best r: 0.5459
15:45:38,939 root INFO 
id:ne_en cur r: 0.7039 best r: 0.7039
15:45:51,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:22,987 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:47:22,993 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:47:22,998 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:47:23,3 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:47:23,10 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:47:23,15 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:47:23,20 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:47:36,79 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5779
en_de Dev loss: 0.9020 r:0.1628
en_zh Dev loss: 0.7342 r:0.3812
ro_en Dev loss: 0.4083 r:0.7628
et_en Dev loss: 0.3685 r:0.7042
si_en Dev loss: 0.6888 r:0.5559
ne_en Dev loss: 0.5844 r:0.7024
ru_en Dev loss: 0.4347 r:0.7464
Current avg r:0.5737 Best avg r: 0.5737
15:52:09,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:48,905 root INFO 
id:ro_en cur r: 0.7671 best r: 0.7671
15:53:01,918 root INFO 
id:et_en cur r: 0.7051 best r: 0.7051
15:53:14,957 root INFO 
id:si_en cur r: 0.5599 best r: 0.5599
15:53:42,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:13,223 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:55:13,231 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:55:13,236 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:55:13,241 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:55:13,249 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:55:13,255 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:55:13,260 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:55:26,289 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5460
en_de Dev loss: 0.8950 r:0.1680
en_zh Dev loss: 0.7070 r:0.3859
ro_en Dev loss: 0.3682 r:0.7659
et_en Dev loss: 0.3404 r:0.7199
si_en Dev loss: 0.5799 r:0.5712
ne_en Dev loss: 0.5575 r:0.7059
ru_en Dev loss: 0.4086 r:0.7479
Current avg r:0.5807 Best avg r: 0.5807
16:00:00,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:13,225 root INFO 
id:en_de cur r: 0.1675 best r: 0.1675
16:00:26,217 root INFO 
id:en_zh cur r: 0.3884 best r: 0.3884
16:00:39,243 root INFO 
id:ro_en cur r: 0.7744 best r: 0.7744
16:01:31,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:02,388 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5561
en_de Dev loss: 0.9483 r:0.1731
en_zh Dev loss: 0.7724 r:0.3879
ro_en Dev loss: 0.4219 r:0.7767
et_en Dev loss: 0.3524 r:0.7196
si_en Dev loss: 0.7269 r:0.5609
ne_en Dev loss: 0.7994 r:0.7026
ru_en Dev loss: 0.4840 r:0.7270
Current avg r:0.5783 Best avg r: 0.5807
16:07:36,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:49,534 root INFO 
id:en_de cur r: 0.1900 best r: 0.1900
16:08:02,532 root INFO 
id:en_zh cur r: 0.3998 best r: 0.3998
16:08:15,552 root INFO 
id:ro_en cur r: 0.7877 best r: 0.7877
16:08:41,626 root INFO 
id:si_en cur r: 0.5741 best r: 0.5741
16:09:07,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:38,746 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:10:38,752 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:10:38,757 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:10:38,762 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:10:38,769 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:10:38,773 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:10:38,778 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:10:51,834 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5224
en_de Dev loss: 0.8821 r:0.1925
en_zh Dev loss: 0.7064 r:0.4022
ro_en Dev loss: 0.3607 r:0.7875
et_en Dev loss: 0.3421 r:0.7199
si_en Dev loss: 0.6305 r:0.5768
ne_en Dev loss: 0.6568 r:0.6990
ru_en Dev loss: 0.4380 r:0.7388
Current avg r:0.5881 Best avg r: 0.5881
16:15:26,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:57,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:29,626 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5074
en_de Dev loss: 0.9026 r:0.1851
en_zh Dev loss: 0.7402 r:0.3933
ro_en Dev loss: 0.4243 r:0.7819
et_en Dev loss: 0.3686 r:0.7132
si_en Dev loss: 0.7067 r:0.5719
ne_en Dev loss: 0.7726 r:0.7004
ru_en Dev loss: 0.5363 r:0.7025
Current avg r:0.5783 Best avg r: 0.5881
16:23:04,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:17,76 root INFO 
id:en_de cur r: 0.2154 best r: 0.2154
16:23:43,68 root INFO 
id:ro_en cur r: 0.7930 best r: 0.7930
16:23:56,117 root INFO 
id:et_en cur r: 0.7107 best r: 0.7107
16:24:09,175 root INFO 
id:si_en cur r: 0.5828 best r: 0.5828
16:24:35,268 root INFO 
id:ne_en cur r: 0.7127 best r: 0.7127
16:24:48,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:19,313 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:26:19,320 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:26:19,326 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:26:19,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:26:19,337 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:26:19,349 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:26:19,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:26:32,413 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5077
en_de Dev loss: 0.8874 r:0.2169
en_zh Dev loss: 0.7578 r:0.3848
ro_en Dev loss: 0.3558 r:0.7907
et_en Dev loss: 0.3479 r:0.7198
si_en Dev loss: 0.6942 r:0.5808
ne_en Dev loss: 0.5860 r:0.7180
ru_en Dev loss: 0.4486 r:0.7302
Current avg r:0.5916 Best avg r: 0.5916
16:31:06,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:19,816 root INFO 
id:en_de cur r: 0.2231 best r: 0.2231
16:31:32,794 root INFO 
id:en_zh cur r: 0.4053 best r: 0.4053
16:31:45,801 root INFO 
id:ro_en cur r: 0.8034 best r: 0.8034
16:32:11,888 root INFO 
id:si_en cur r: 0.5898 best r: 0.5898
16:32:37,968 root INFO 
id:ne_en cur r: 0.7207 best r: 0.7207
16:32:50,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:21,960 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:34:21,966 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:34:21,970 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:34:21,975 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:34:21,980 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:34:21,985 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:34:21,989 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:34:35,22 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5199
en_de Dev loss: 0.8549 r:0.1983
en_zh Dev loss: 0.6907 r:0.4006
ro_en Dev loss: 0.3179 r:0.7989
et_en Dev loss: 0.3472 r:0.7136
si_en Dev loss: 0.6061 r:0.5915
ne_en Dev loss: 0.4933 r:0.7239
ru_en Dev loss: 0.4131 r:0.7314
Current avg r:0.5940 Best avg r: 0.5940
16:39:09,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:48,317 root INFO 
id:ro_en cur r: 0.8036 best r: 0.8036
16:40:40,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:11,378 root INFO Epoch 0 Global steps: 9800 Train loss: 0.4892
en_de Dev loss: 0.8835 r:0.1916
en_zh Dev loss: 0.7835 r:0.3846
ro_en Dev loss: 0.3854 r:0.7989
et_en Dev loss: 0.3799 r:0.6999
si_en Dev loss: 0.7696 r:0.5756
ne_en Dev loss: 0.7736 r:0.7014
ru_en Dev loss: 0.5265 r:0.7009
Current avg r:0.5790 Best avg r: 0.5940
16:46:45,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:24,718 root INFO 
id:ro_en cur r: 0.8061 best r: 0.8061
16:48:16,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:47,896 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5082
en_de Dev loss: 0.8701 r:0.2012
en_zh Dev loss: 0.7836 r:0.3900
ro_en Dev loss: 0.3751 r:0.8022
et_en Dev loss: 0.3766 r:0.7065
si_en Dev loss: 0.8060 r:0.5828
ne_en Dev loss: 0.7205 r:0.7203
ru_en Dev loss: 0.4550 r:0.7327
Current avg r:0.5908 Best avg r: 0.5940
16:54:23,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:36,956 root INFO 
id:en_de cur r: 0.2363 best r: 0.2363
16:55:02,954 root INFO 
id:ro_en cur r: 0.8118 best r: 0.8118
16:55:55,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:26,69 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:57:26,75 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:57:26,79 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:57:26,84 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:57:26,88 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:57:26,93 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:57:26,98 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:57:39,145 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4782
en_de Dev loss: 0.8510 r:0.2203
en_zh Dev loss: 0.7229 r:0.4021
ro_en Dev loss: 0.3411 r:0.8069
et_en Dev loss: 0.3634 r:0.7056
si_en Dev loss: 0.6776 r:0.5907
ne_en Dev loss: 0.6891 r:0.7138
ru_en Dev loss: 0.4207 r:0.7310
Current avg r:0.5958 Best avg r: 0.5958
17:02:13,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:39,285 root INFO 
id:en_zh cur r: 0.4065 best r: 0.4065
17:03:44,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:15,453 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4310
en_de Dev loss: 0.8656 r:0.2127
en_zh Dev loss: 0.7458 r:0.4014
ro_en Dev loss: 0.3383 r:0.8034
et_en Dev loss: 0.3742 r:0.6995
si_en Dev loss: 0.6539 r:0.5909
ne_en Dev loss: 0.6509 r:0.7169
ru_en Dev loss: 0.4703 r:0.7169
Current avg r:0.5917 Best avg r: 0.5958
17:09:49,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:15,699 root INFO 
id:en_zh cur r: 0.4337 best r: 0.4337
17:10:28,717 root INFO 
id:ro_en cur r: 0.8127 best r: 0.8127
17:10:54,788 root INFO 
id:si_en cur r: 0.5919 best r: 0.5919
17:11:20,772 root INFO 
id:ru_en cur r: 0.7474 best r: 0.7474
17:11:20,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:51,811 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:12:51,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:12:51,823 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:12:51,827 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:12:51,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:12:51,836 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:12:51,841 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:13:04,888 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4468
en_de Dev loss: 0.8624 r:0.2322
en_zh Dev loss: 0.7064 r:0.4259
ro_en Dev loss: 0.3175 r:0.8083
et_en Dev loss: 0.3642 r:0.7091
si_en Dev loss: 0.6609 r:0.5912
ne_en Dev loss: 0.6054 r:0.7169
ru_en Dev loss: 0.4178 r:0.7443
Current avg r:0.6040 Best avg r: 0.6040
17:17:38,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:51,935 root INFO 
id:en_de cur r: 0.2489 best r: 0.2489
17:18:04,915 root INFO 
id:en_zh cur r: 0.4471 best r: 0.4471
17:18:43,997 root INFO 
id:si_en cur r: 0.5945 best r: 0.5945
17:19:10,78 root INFO 
id:ne_en cur r: 0.7255 best r: 0.7255
17:19:23,21 root INFO 
id:ru_en cur r: 0.7584 best r: 0.7584
17:19:23,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:54,53 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:20:54,60 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:20:54,64 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:20:54,69 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:20:54,76 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:20:54,81 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:20:54,87 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:21:07,129 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4313
en_de Dev loss: 0.8540 r:0.2416
en_zh Dev loss: 0.6788 r:0.4402
ro_en Dev loss: 0.3193 r:0.8069
et_en Dev loss: 0.3690 r:0.7118
si_en Dev loss: 0.6386 r:0.5969
ne_en Dev loss: 0.5778 r:0.7226
ru_en Dev loss: 0.3693 r:0.7615
Current avg r:0.6116 Best avg r: 0.6116
17:25:41,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:20,192 root INFO 
id:ro_en cur r: 0.8168 best r: 0.8168
17:26:33,226 root INFO 
id:et_en cur r: 0.7206 best r: 0.7206
17:26:46,270 root INFO 
id:si_en cur r: 0.6027 best r: 0.6027
17:27:12,353 root INFO 
id:ne_en cur r: 0.7285 best r: 0.7285
17:27:25,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:56,356 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:28:56,364 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:28:56,371 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:28:56,375 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:28:56,380 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:28:56,384 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:28:56,391 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:29:09,436 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4575
en_de Dev loss: 0.8577 r:0.2270
en_zh Dev loss: 0.6834 r:0.4413
ro_en Dev loss: 0.3244 r:0.8101
et_en Dev loss: 0.3550 r:0.7217
si_en Dev loss: 0.6551 r:0.6042
ne_en Dev loss: 0.5233 r:0.7283
ru_en Dev loss: 0.3804 r:0.7573
Current avg r:0.6128 Best avg r: 0.6128
17:33:43,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:56,529 root INFO 
id:en_de cur r: 0.2557 best r: 0.2557
17:34:09,503 root INFO 
id:en_zh cur r: 0.4612 best r: 0.4612
17:34:22,533 root INFO 
id:ro_en cur r: 0.8179 best r: 0.8179
17:34:35,565 root INFO 
id:et_en cur r: 0.7219 best r: 0.7219
17:34:48,606 root INFO 
id:si_en cur r: 0.6045 best r: 0.6045
17:35:14,591 root INFO 
id:ru_en cur r: 0.7607 best r: 0.7607
17:35:14,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:45,646 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:36:45,658 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:36:45,663 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:36:45,668 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:36:45,675 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:36:45,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:36:45,686 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:36:58,737 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4423
en_de Dev loss: 0.8693 r:0.2421
en_zh Dev loss: 0.6855 r:0.4549
ro_en Dev loss: 0.3299 r:0.8116
et_en Dev loss: 0.3561 r:0.7207
si_en Dev loss: 0.6481 r:0.6033
ne_en Dev loss: 0.5513 r:0.7215
ru_en Dev loss: 0.3825 r:0.7628
Current avg r:0.6167 Best avg r: 0.6167
17:41:32,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:03,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:34,875 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4264
en_de Dev loss: 0.9022 r:0.2394
en_zh Dev loss: 0.7679 r:0.4523
ro_en Dev loss: 0.3495 r:0.8078
et_en Dev loss: 0.3749 r:0.7081
si_en Dev loss: 0.8534 r:0.5875
ne_en Dev loss: 0.7378 r:0.7216
ru_en Dev loss: 0.4851 r:0.7243
Current avg r:0.6059 Best avg r: 0.6167
17:49:08,797 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:34,777 root INFO 
id:en_zh cur r: 0.4640 best r: 0.4640
17:49:47,783 root INFO 
id:ro_en cur r: 0.8214 best r: 0.8214
17:50:39,923 root INFO 
id:ne_en cur r: 0.7323 best r: 0.7323
17:50:52,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:23,893 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4638
en_de Dev loss: 0.8726 r:0.2093
en_zh Dev loss: 0.7081 r:0.4561
ro_en Dev loss: 0.3476 r:0.8145
et_en Dev loss: 0.3605 r:0.7093
si_en Dev loss: 0.6958 r:0.5934
ne_en Dev loss: 0.6269 r:0.7323
ru_en Dev loss: 0.4808 r:0.7177
Current avg r:0.6046 Best avg r: 0.6167
17:56:57,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:28,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:59,655 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4340
en_de Dev loss: 0.8821 r:0.2099
en_zh Dev loss: 0.7329 r:0.4464
ro_en Dev loss: 0.3715 r:0.8042
et_en Dev loss: 0.3870 r:0.6982
si_en Dev loss: 0.6976 r:0.5957
ne_en Dev loss: 0.6794 r:0.7279
ru_en Dev loss: 0.4728 r:0.7206
Current avg r:0.6004 Best avg r: 0.6167
18:04:33,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:12,462 root INFO 
id:ro_en cur r: 0.8251 best r: 0.8251
18:05:38,511 root INFO 
id:si_en cur r: 0.6100 best r: 0.6100
18:06:04,571 root INFO 
id:ne_en cur r: 0.7365 best r: 0.7365
18:06:17,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:48,482 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4475
en_de Dev loss: 0.8718 r:0.2059
en_zh Dev loss: 0.7136 r:0.4551
ro_en Dev loss: 0.3294 r:0.8201
et_en Dev loss: 0.3688 r:0.7138
si_en Dev loss: 0.7736 r:0.6091
ne_en Dev loss: 0.5998 r:0.7368
ru_en Dev loss: 0.4086 r:0.7594
Current avg r:0.6143 Best avg r: 0.6167
18:12:22,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:53,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:24,243 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4124
en_de Dev loss: 0.9172 r:0.2038
en_zh Dev loss: 0.8090 r:0.4231
ro_en Dev loss: 0.3848 r:0.8053
et_en Dev loss: 0.4013 r:0.6991
si_en Dev loss: 0.7624 r:0.5800
ne_en Dev loss: 0.7047 r:0.7207
ru_en Dev loss: 0.5210 r:0.7194
Current avg r:0.5931 Best avg r: 0.6167
18:19:58,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:24,129 root INFO 
id:en_zh cur r: 0.4646 best r: 0.4646
18:21:29,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:00,221 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4101
en_de Dev loss: 0.8670 r:0.2076
en_zh Dev loss: 0.6856 r:0.4560
ro_en Dev loss: 0.3147 r:0.8189
et_en Dev loss: 0.3549 r:0.7146
si_en Dev loss: 0.6311 r:0.5937
ne_en Dev loss: 0.5255 r:0.7348
ru_en Dev loss: 0.3923 r:0.7559
Current avg r:0.6116 Best avg r: 0.6167
18:27:34,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:05,372 root INFO 
id:ne_en cur r: 0.7389 best r: 0.7389
18:29:18,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:49,328 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4164
en_de Dev loss: 0.8650 r:0.2062
en_zh Dev loss: 0.7113 r:0.4517
ro_en Dev loss: 0.3005 r:0.8189
et_en Dev loss: 0.3578 r:0.7132
si_en Dev loss: 0.6327 r:0.5983
ne_en Dev loss: 0.5521 r:0.7390
ru_en Dev loss: 0.4113 r:0.7447
Current avg r:0.6103 Best avg r: 0.6167
18:35:23,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:02,286 root INFO 
id:ro_en cur r: 0.8285 best r: 0.8285
18:36:28,346 root INFO 
id:si_en cur r: 0.6132 best r: 0.6132
18:36:54,404 root INFO 
id:ne_en cur r: 0.7450 best r: 0.7450
18:37:07,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:38,319 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4220
en_de Dev loss: 0.8541 r:0.2128
en_zh Dev loss: 0.7118 r:0.4403
ro_en Dev loss: 0.2886 r:0.8241
et_en Dev loss: 0.3387 r:0.7234
si_en Dev loss: 0.5728 r:0.6094
ne_en Dev loss: 0.4772 r:0.7457
ru_en Dev loss: 0.3870 r:0.7589
Current avg r:0.6164 Best avg r: 0.6167
18:43:12,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:43,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:14,259 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4113
en_de Dev loss: 0.8648 r:0.2245
en_zh Dev loss: 0.7543 r:0.4217
ro_en Dev loss: 0.3368 r:0.8152
et_en Dev loss: 0.3525 r:0.7124
si_en Dev loss: 0.6996 r:0.5980
ne_en Dev loss: 0.5468 r:0.7373
ru_en Dev loss: 0.4797 r:0.7182
Current avg r:0.6039 Best avg r: 0.6167
18:50:49,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:20,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:51,437 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4002
en_de Dev loss: 0.8446 r:0.2538
en_zh Dev loss: 0.7442 r:0.4321
ro_en Dev loss: 0.3155 r:0.8194
et_en Dev loss: 0.3587 r:0.7196
si_en Dev loss: 0.6357 r:0.6095
ne_en Dev loss: 0.4820 r:0.7431
ru_en Dev loss: 0.4538 r:0.7287
Current avg r:0.6152 Best avg r: 0.6167
18:58:24,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:03,277 root INFO 
id:ro_en cur r: 0.8295 best r: 0.8295
18:59:55,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:26,90 root INFO Epoch 2 Global steps: 22400 Train loss: 0.3721
en_de Dev loss: 0.8370 r:0.2455
en_zh Dev loss: 0.6909 r:0.4431
ro_en Dev loss: 0.2916 r:0.8242
et_en Dev loss: 0.3522 r:0.7165
si_en Dev loss: 0.6582 r:0.6023
ne_en Dev loss: 0.5059 r:0.7409
ru_en Dev loss: 0.4119 r:0.7370
Current avg r:0.6156 Best avg r: 0.6167
19:05:58,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:24,804 root INFO 
id:en_zh cur r: 0.4767 best r: 0.4767
19:06:37,794 root INFO 
id:ro_en cur r: 0.8319 best r: 0.8319
19:07:03,831 root INFO 
id:si_en cur r: 0.6159 best r: 0.6159
19:07:29,872 root INFO 
id:ne_en cur r: 0.7512 best r: 0.7512
19:07:42,793 root INFO 
id:ru_en cur r: 0.7639 best r: 0.7639
19:07:42,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:13,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
19:09:13,670 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
19:09:13,676 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
19:09:13,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
19:09:13,685 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
19:09:13,690 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
19:09:13,696 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
19:09:26,707 root INFO Epoch 2 Global steps: 23100 Train loss: 0.3878
en_de Dev loss: 0.8324 r:0.2499
en_zh Dev loss: 0.6603 r:0.4669
ro_en Dev loss: 0.2795 r:0.8271
et_en Dev loss: 0.3455 r:0.7244
si_en Dev loss: 0.5845 r:0.6196
ne_en Dev loss: 0.4029 r:0.7508
ru_en Dev loss: 0.3631 r:0.7644
Current avg r:0.6290 Best avg r: 0.6290
19:13:59,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:30,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:01,241 root INFO Epoch 2 Global steps: 23800 Train loss: 0.3689
en_de Dev loss: 0.8381 r:0.2395
en_zh Dev loss: 0.6845 r:0.4457
ro_en Dev loss: 0.2897 r:0.8242
et_en Dev loss: 0.3593 r:0.7076
si_en Dev loss: 0.6779 r:0.6006
ne_en Dev loss: 0.5958 r:0.7374
ru_en Dev loss: 0.4064 r:0.7347
Current avg r:0.6128 Best avg r: 0.6290
19:21:34,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:05,100 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:36,87 root INFO Epoch 2 Global steps: 24500 Train loss: 0.3691
en_de Dev loss: 0.8427 r:0.2382
en_zh Dev loss: 0.7228 r:0.4447
ro_en Dev loss: 0.3080 r:0.8252
et_en Dev loss: 0.3731 r:0.7108
si_en Dev loss: 0.6911 r:0.6016
ne_en Dev loss: 0.5387 r:0.7407
ru_en Dev loss: 0.4425 r:0.7303
Current avg r:0.6131 Best avg r: 0.6290
19:29:10,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:23,79 root INFO 
id:en_de cur r: 0.2587 best r: 0.2587
19:30:41,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:12,133 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4145
en_de Dev loss: 0.8502 r:0.2398
en_zh Dev loss: 0.7310 r:0.4313
ro_en Dev loss: 0.3213 r:0.8218
et_en Dev loss: 0.3731 r:0.7048
si_en Dev loss: 0.7541 r:0.5932
ne_en Dev loss: 0.5955 r:0.7334
ru_en Dev loss: 0.4641 r:0.7183
Current avg r:0.6061 Best avg r: 0.6290
19:36:46,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:59,50 root INFO 
id:en_de cur r: 0.2692 best r: 0.2692
19:38:17,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:39:48,184 root INFO Epoch 2 Global steps: 25900 Train loss: 0.3676
en_de Dev loss: 0.8648 r:0.2418
en_zh Dev loss: 0.7364 r:0.4403
ro_en Dev loss: 0.3166 r:0.8225
et_en Dev loss: 0.3799 r:0.7042
si_en Dev loss: 0.6411 r:0.6048
ne_en Dev loss: 0.5206 r:0.7391
ru_en Dev loss: 0.4226 r:0.7368
Current avg r:0.6128 Best avg r: 0.6290
19:44:22,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:35,19 root INFO 
id:en_de cur r: 0.2864 best r: 0.2864
19:45:53,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:24,69 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3826
en_de Dev loss: 0.8380 r:0.2670
en_zh Dev loss: 0.7289 r:0.4448
ro_en Dev loss: 0.3263 r:0.8201
et_en Dev loss: 0.3824 r:0.7012
si_en Dev loss: 0.6862 r:0.5941
ne_en Dev loss: 0.5685 r:0.7335
ru_en Dev loss: 0.4456 r:0.7241
Current avg r:0.6121 Best avg r: 0.6290
19:51:57,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:28,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:59,776 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3649
en_de Dev loss: 0.8375 r:0.2692
en_zh Dev loss: 0.7303 r:0.4551
ro_en Dev loss: 0.3321 r:0.8239
et_en Dev loss: 0.4018 r:0.7066
si_en Dev loss: 0.6963 r:0.6021
ne_en Dev loss: 0.4917 r:0.7443
ru_en Dev loss: 0.4157 r:0.7442
Current avg r:0.6208 Best avg r: 0.6290
19:59:33,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:01:04,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:36,11 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3612
en_de Dev loss: 0.8452 r:0.2450
en_zh Dev loss: 0.7057 r:0.4575
ro_en Dev loss: 0.2975 r:0.8249
et_en Dev loss: 0.3620 r:0.7082
si_en Dev loss: 0.6706 r:0.6132
ne_en Dev loss: 0.4938 r:0.7456
ru_en Dev loss: 0.4141 r:0.7412
Current avg r:0.6194 Best avg r: 0.6290
20:07:10,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:41,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:12,193 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3841
en_de Dev loss: 0.8545 r:0.2538
en_zh Dev loss: 0.7462 r:0.4539
ro_en Dev loss: 0.3434 r:0.8210
et_en Dev loss: 0.3948 r:0.7005
si_en Dev loss: 0.7191 r:0.6052
ne_en Dev loss: 0.6316 r:0.7361
ru_en Dev loss: 0.5101 r:0.7108
Current avg r:0.6116 Best avg r: 0.6290
20:14:46,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:17,312 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:48,356 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3356
en_de Dev loss: 0.8546 r:0.2574
en_zh Dev loss: 0.7573 r:0.4517
ro_en Dev loss: 0.3223 r:0.8281
et_en Dev loss: 0.3777 r:0.7068
si_en Dev loss: 0.7125 r:0.5966
ne_en Dev loss: 0.5649 r:0.7358
ru_en Dev loss: 0.4489 r:0.7366
Current avg r:0.6161 Best avg r: 0.6290
20:22:22,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:53,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:24,424 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3496
en_de Dev loss: 0.8484 r:0.2502
en_zh Dev loss: 0.7275 r:0.4566
ro_en Dev loss: 0.3042 r:0.8256
et_en Dev loss: 0.3742 r:0.6993
si_en Dev loss: 0.6799 r:0.6010
ne_en Dev loss: 0.5485 r:0.7373
ru_en Dev loss: 0.4340 r:0.7377
Current avg r:0.6154 Best avg r: 0.6290
20:29:57,549 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:28,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:59,510 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3413
en_de Dev loss: 0.8644 r:0.2253
en_zh Dev loss: 0.7395 r:0.4458
ro_en Dev loss: 0.3176 r:0.8231
et_en Dev loss: 0.4096 r:0.6933
si_en Dev loss: 0.7019 r:0.5927
ne_en Dev loss: 0.5289 r:0.7369
ru_en Dev loss: 0.4612 r:0.7202
Current avg r:0.6053 Best avg r: 0.6290
20:37:32,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:03,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:34,824 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3390
en_de Dev loss: 0.8484 r:0.2301
en_zh Dev loss: 0.6936 r:0.4578
ro_en Dev loss: 0.2881 r:0.8266
et_en Dev loss: 0.3801 r:0.7034
si_en Dev loss: 0.6622 r:0.6031
ne_en Dev loss: 0.4502 r:0.7480
ru_en Dev loss: 0.4195 r:0.7364
Current avg r:0.6151 Best avg r: 0.6290
20:45:09,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:40,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:11,487 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3158
en_de Dev loss: 0.8518 r:0.2312
en_zh Dev loss: 0.6946 r:0.4618
ro_en Dev loss: 0.3205 r:0.8242
et_en Dev loss: 0.4001 r:0.6945
si_en Dev loss: 0.7098 r:0.6023
ne_en Dev loss: 0.5091 r:0.7476
ru_en Dev loss: 0.4631 r:0.7187
Current avg r:0.6115 Best avg r: 0.6290
20:52:44,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:10,774 root INFO 
id:en_zh cur r: 0.4837 best r: 0.4837
20:54:15,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:46,828 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3224
en_de Dev loss: 0.8463 r:0.2502
en_zh Dev loss: 0.6878 r:0.4753
ro_en Dev loss: 0.3019 r:0.8227
et_en Dev loss: 0.4092 r:0.6935
si_en Dev loss: 0.5973 r:0.6088
ne_en Dev loss: 0.4266 r:0.7489
ru_en Dev loss: 0.4102 r:0.7381
Current avg r:0.6197 Best avg r: 0.6290
21:00:20,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:51,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:22,192 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3296
en_de Dev loss: 0.8663 r:0.2044
en_zh Dev loss: 0.7506 r:0.4541
ro_en Dev loss: 0.3363 r:0.8188
et_en Dev loss: 0.4076 r:0.6859
si_en Dev loss: 0.7796 r:0.5828
ne_en Dev loss: 0.5409 r:0.7349
ru_en Dev loss: 0.4806 r:0.7122
Current avg r:0.5990 Best avg r: 0.6290
21:07:56,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:27,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:58,423 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3271
en_de Dev loss: 0.8739 r:0.2107
en_zh Dev loss: 0.7889 r:0.4435
ro_en Dev loss: 0.3546 r:0.8221
et_en Dev loss: 0.4203 r:0.6895
si_en Dev loss: 0.8240 r:0.5866
ne_en Dev loss: 0.5973 r:0.7442
ru_en Dev loss: 0.5481 r:0.7014
Current avg r:0.5997 Best avg r: 0.6290
21:15:32,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:03,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:34,992 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3356
en_de Dev loss: 0.8433 r:0.2436
en_zh Dev loss: 0.7137 r:0.4585
ro_en Dev loss: 0.3070 r:0.8268
et_en Dev loss: 0.4035 r:0.7049
si_en Dev loss: 0.6248 r:0.6077
ne_en Dev loss: 0.4249 r:0.7464
ru_en Dev loss: 0.4200 r:0.7391
Current avg r:0.6181 Best avg r: 0.6290
21:23:09,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:40,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:11,575 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3228
en_de Dev loss: 0.8498 r:0.2331
en_zh Dev loss: 0.7452 r:0.4498
ro_en Dev loss: 0.3321 r:0.8184
et_en Dev loss: 0.4016 r:0.6880
si_en Dev loss: 0.7437 r:0.5860
ne_en Dev loss: 0.4998 r:0.7395
ru_en Dev loss: 0.4741 r:0.7069
Current avg r:0.6031 Best avg r: 0.6290
21:30:45,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:16,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:48,87 root INFO Epoch 3 Global steps: 36400 Train loss: 0.2973
en_de Dev loss: 0.8519 r:0.2196
en_zh Dev loss: 0.7413 r:0.4428
ro_en Dev loss: 0.3202 r:0.8230
et_en Dev loss: 0.4049 r:0.6958
si_en Dev loss: 0.6989 r:0.5955
ne_en Dev loss: 0.4577 r:0.7462
ru_en Dev loss: 0.4191 r:0.7362
Current avg r:0.6085 Best avg r: 0.6290
21:38:22,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:53,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:24,581 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3110
en_de Dev loss: 0.8644 r:0.1914
en_zh Dev loss: 0.6871 r:0.4740
ro_en Dev loss: 0.2942 r:0.8255
et_en Dev loss: 0.3954 r:0.6970
si_en Dev loss: 0.6654 r:0.5965
ne_en Dev loss: 0.4292 r:0.7478
ru_en Dev loss: 0.4024 r:0.7429
Current avg r:0.6107 Best avg r: 0.6290
21:45:58,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:29,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:01,53 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3049
en_de Dev loss: 0.8621 r:0.2306
en_zh Dev loss: 0.7390 r:0.4607
ro_en Dev loss: 0.3384 r:0.8242
et_en Dev loss: 0.4285 r:0.6905
si_en Dev loss: 0.7783 r:0.5869
ne_en Dev loss: 0.4958 r:0.7392
ru_en Dev loss: 0.4445 r:0.7337
Current avg r:0.6094 Best avg r: 0.6290
21:53:35,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:14,260 root INFO 
id:ro_en cur r: 0.8320 best r: 0.8320
21:55:06,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:37,506 root INFO Epoch 3 Global steps: 38500 Train loss: 0.2962
en_de Dev loss: 0.8797 r:0.1959
en_zh Dev loss: 0.7737 r:0.4392
ro_en Dev loss: 0.3201 r:0.8277
et_en Dev loss: 0.4267 r:0.6911
si_en Dev loss: 0.7162 r:0.5943
ne_en Dev loss: 0.4475 r:0.7429
ru_en Dev loss: 0.4708 r:0.7160
Current avg r:0.6010 Best avg r: 0.6290
22:01:11,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:42,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:14,108 root INFO Epoch 3 Global steps: 39200 Train loss: 0.2849
en_de Dev loss: 0.8540 r:0.2224
en_zh Dev loss: 0.7398 r:0.4441
ro_en Dev loss: 0.3201 r:0.8226
et_en Dev loss: 0.4124 r:0.6838
si_en Dev loss: 0.7575 r:0.5825
ne_en Dev loss: 0.4822 r:0.7456
ru_en Dev loss: 0.4371 r:0.7218
Current avg r:0.6033 Best avg r: 0.6290
22:08:48,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:19,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:50,736 root INFO Epoch 3 Global steps: 39900 Train loss: 0.2934
en_de Dev loss: 0.8652 r:0.2146
en_zh Dev loss: 0.7136 r:0.4677
ro_en Dev loss: 0.3212 r:0.8275
et_en Dev loss: 0.4302 r:0.6922
si_en Dev loss: 0.6906 r:0.5884
ne_en Dev loss: 0.4277 r:0.7422
ru_en Dev loss: 0.4287 r:0.7356
Current avg r:0.6097 Best avg r: 0.6290
22:16:25,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:56,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:27,364 root INFO Epoch 3 Global steps: 40600 Train loss: 0.2934
en_de Dev loss: 0.8677 r:0.2295
en_zh Dev loss: 0.7613 r:0.4457
ro_en Dev loss: 0.3343 r:0.8239
et_en Dev loss: 0.4360 r:0.6901
si_en Dev loss: 0.7299 r:0.5839
ne_en Dev loss: 0.4630 r:0.7366
ru_en Dev loss: 0.4771 r:0.7170
Current avg r:0.6038 Best avg r: 0.6290
22:24:01,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:32,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:03,847 root INFO Epoch 3 Global steps: 41300 Train loss: 0.2973
en_de Dev loss: 0.8670 r:0.2198
en_zh Dev loss: 0.7715 r:0.4392
ro_en Dev loss: 0.3277 r:0.8244
et_en Dev loss: 0.4132 r:0.6880
si_en Dev loss: 0.8683 r:0.5773
ne_en Dev loss: 0.5303 r:0.7345
ru_en Dev loss: 0.4835 r:0.7134
Current avg r:0.5995 Best avg r: 0.6290
22:31:38,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:09,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:40,406 root INFO Epoch 3 Global steps: 42000 Train loss: 0.2924
en_de Dev loss: 0.8723 r:0.2362
en_zh Dev loss: 0.7976 r:0.4418
ro_en Dev loss: 0.3374 r:0.8246
et_en Dev loss: 0.4245 r:0.6799
si_en Dev loss: 0.7812 r:0.5807
ne_en Dev loss: 0.4898 r:0.7363
ru_en Dev loss: 0.4555 r:0.7267
Current avg r:0.6038 Best avg r: 0.6290
22:39:16,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:47,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:18,578 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2591
en_de Dev loss: 0.8553 r:0.2306
en_zh Dev loss: 0.7677 r:0.4291
ro_en Dev loss: 0.3173 r:0.8268
et_en Dev loss: 0.4288 r:0.6923
si_en Dev loss: 0.7066 r:0.5919
ne_en Dev loss: 0.4459 r:0.7372
ru_en Dev loss: 0.4478 r:0.7288
Current avg r:0.6052 Best avg r: 0.6290
22:46:53,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:24,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:55,265 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2626
en_de Dev loss: 0.8468 r:0.2375
en_zh Dev loss: 0.7777 r:0.4256
ro_en Dev loss: 0.3354 r:0.8215
et_en Dev loss: 0.4224 r:0.6754
si_en Dev loss: 0.8430 r:0.5756
ne_en Dev loss: 0.5399 r:0.7286
ru_en Dev loss: 0.5184 r:0.6963
Current avg r:0.5943 Best avg r: 0.6290
22:54:29,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:00,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:31,841 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2552
en_de Dev loss: 0.8451 r:0.2242
en_zh Dev loss: 0.7605 r:0.4323
ro_en Dev loss: 0.3083 r:0.8264
et_en Dev loss: 0.4251 r:0.6788
si_en Dev loss: 0.6993 r:0.5836
ne_en Dev loss: 0.4581 r:0.7318
ru_en Dev loss: 0.4631 r:0.7069
Current avg r:0.5977 Best avg r: 0.6290
23:02:06,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:37,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:08,406 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2517
en_de Dev loss: 0.8476 r:0.2485
en_zh Dev loss: 0.7455 r:0.4447
ro_en Dev loss: 0.3222 r:0.8239
et_en Dev loss: 0.4155 r:0.6864
si_en Dev loss: 0.7831 r:0.5786
ne_en Dev loss: 0.4458 r:0.7383
ru_en Dev loss: 0.4462 r:0.7278
Current avg r:0.6069 Best avg r: 0.6290
23:09:42,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:21,705 root INFO 
id:ro_en cur r: 0.8325 best r: 0.8325
23:11:13,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:44,949 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2559
en_de Dev loss: 0.8536 r:0.2215
en_zh Dev loss: 0.7465 r:0.4471
ro_en Dev loss: 0.3193 r:0.8297
et_en Dev loss: 0.4388 r:0.6884
si_en Dev loss: 0.7193 r:0.5854
ne_en Dev loss: 0.4490 r:0.7370
ru_en Dev loss: 0.4210 r:0.7403
Current avg r:0.6070 Best avg r: 0.6290
23:17:19,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:50,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:21,423 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2690
en_de Dev loss: 0.8680 r:0.2279
en_zh Dev loss: 0.8280 r:0.4141
ro_en Dev loss: 0.3535 r:0.8203
et_en Dev loss: 0.4299 r:0.6725
si_en Dev loss: 0.8465 r:0.5683
ne_en Dev loss: 0.5215 r:0.7301
ru_en Dev loss: 0.5104 r:0.7006
Current avg r:0.5905 Best avg r: 0.6290
23:24:55,655 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:26,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:57,827 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2842
en_de Dev loss: 0.8650 r:0.2454
en_zh Dev loss: 0.7895 r:0.4204
ro_en Dev loss: 0.3637 r:0.8223
et_en Dev loss: 0.4298 r:0.6811
si_en Dev loss: 0.7717 r:0.5903
ne_en Dev loss: 0.5057 r:0.7411
ru_en Dev loss: 0.4446 r:0.7343
Current avg r:0.6050 Best avg r: 0.6290
23:32:32,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:34:03,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:34,180 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2587
en_de Dev loss: 0.8405 r:0.2464
en_zh Dev loss: 0.7547 r:0.4353
ro_en Dev loss: 0.3490 r:0.8242
et_en Dev loss: 0.4807 r:0.6894
si_en Dev loss: 0.6945 r:0.5956
ne_en Dev loss: 0.4404 r:0.7453
ru_en Dev loss: 0.4126 r:0.7404
Current avg r:0.6109 Best avg r: 0.6290
23:40:08,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:39,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:10,634 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2623
en_de Dev loss: 0.8485 r:0.2403
en_zh Dev loss: 0.7556 r:0.4411
ro_en Dev loss: 0.3455 r:0.8280
et_en Dev loss: 0.4138 r:0.6851
si_en Dev loss: 0.8004 r:0.5944
ne_en Dev loss: 0.5285 r:0.7446
ru_en Dev loss: 0.4319 r:0.7405
Current avg r:0.6106 Best avg r: 0.6290
23:47:44,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:15,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:47,3 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2416
en_de Dev loss: 0.8788 r:0.1935
en_zh Dev loss: 0.8047 r:0.4051
ro_en Dev loss: 0.3110 r:0.8237
et_en Dev loss: 0.4222 r:0.6743
si_en Dev loss: 0.7019 r:0.5773
ne_en Dev loss: 0.4419 r:0.7289
ru_en Dev loss: 0.4938 r:0.6956
Current avg r:0.5855 Best avg r: 0.6290
23:55:21,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:52,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:23,497 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2472
en_de Dev loss: 0.8373 r:0.2589
en_zh Dev loss: 0.7651 r:0.4354
ro_en Dev loss: 0.3189 r:0.8262
et_en Dev loss: 0.4244 r:0.6738
si_en Dev loss: 0.7549 r:0.5816
ne_en Dev loss: 0.4617 r:0.7395
ru_en Dev loss: 0.4842 r:0.7036
Current avg r:0.6027 Best avg r: 0.6290
00:02:57,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:28,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:59,922 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2360
en_de Dev loss: 0.8601 r:0.2482
en_zh Dev loss: 0.8026 r:0.4279
ro_en Dev loss: 0.3441 r:0.8253
et_en Dev loss: 0.4488 r:0.6807
si_en Dev loss: 0.7881 r:0.5808
ne_en Dev loss: 0.4623 r:0.7438
ru_en Dev loss: 0.4559 r:0.7256
Current avg r:0.6046 Best avg r: 0.6290
00:10:34,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:12:05,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:13:36,302 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2465
en_de Dev loss: 0.8513 r:0.2575
en_zh Dev loss: 0.8431 r:0.4246
ro_en Dev loss: 0.3351 r:0.8248
et_en Dev loss: 0.4532 r:0.6818
si_en Dev loss: 0.7379 r:0.5825
ne_en Dev loss: 0.4319 r:0.7426
ru_en Dev loss: 0.4976 r:0.7133
Current avg r:0.6039 Best avg r: 0.6290
00:18:10,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:41,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:21:12,787 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2472
en_de Dev loss: 0.8577 r:0.2061
en_zh Dev loss: 0.7450 r:0.4328
ro_en Dev loss: 0.2928 r:0.8291
et_en Dev loss: 0.4324 r:0.6767
si_en Dev loss: 0.6988 r:0.5831
ne_en Dev loss: 0.4206 r:0.7443
ru_en Dev loss: 0.4164 r:0.7306
Current avg r:0.6004 Best avg r: 0.6290
00:25:46,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:27:18,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:28:49,209 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2641
en_de Dev loss: 0.8862 r:0.2107
en_zh Dev loss: 0.8048 r:0.4478
ro_en Dev loss: 0.3564 r:0.8245
et_en Dev loss: 0.4689 r:0.6759
si_en Dev loss: 0.8040 r:0.5734
ne_en Dev loss: 0.4821 r:0.7375
ru_en Dev loss: 0.4891 r:0.7209
Current avg r:0.5987 Best avg r: 0.6290
00:33:24,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:56,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:27,315 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2209
en_de Dev loss: 0.8521 r:0.2262
en_zh Dev loss: 0.7564 r:0.4445
ro_en Dev loss: 0.3246 r:0.8238
et_en Dev loss: 0.4435 r:0.6712
si_en Dev loss: 0.7919 r:0.5696
ne_en Dev loss: 0.4356 r:0.7372
ru_en Dev loss: 0.4318 r:0.7305
Current avg r:0.6004 Best avg r: 0.6290
00:41:01,519 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:32,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:03,843 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2231
en_de Dev loss: 0.8468 r:0.2517
en_zh Dev loss: 0.7883 r:0.4340
ro_en Dev loss: 0.3407 r:0.8243
et_en Dev loss: 0.4355 r:0.6698
si_en Dev loss: 0.8350 r:0.5672
ne_en Dev loss: 0.5035 r:0.7365
ru_en Dev loss: 0.4582 r:0.7225
Current avg r:0.6008 Best avg r: 0.6290
00:48:38,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:09,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:51:40,199 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2098
en_de Dev loss: 0.8971 r:0.2272
en_zh Dev loss: 0.7821 r:0.4468
ro_en Dev loss: 0.3614 r:0.8197
et_en Dev loss: 0.4649 r:0.6706
si_en Dev loss: 0.7837 r:0.5721
ne_en Dev loss: 0.4289 r:0.7377
ru_en Dev loss: 0.4577 r:0.7332
Current avg r:0.6010 Best avg r: 0.6290
00:56:14,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:45,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:16,612 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2211
en_de Dev loss: 0.8591 r:0.2137
en_zh Dev loss: 0.7585 r:0.4327
ro_en Dev loss: 0.3335 r:0.8207
et_en Dev loss: 0.4277 r:0.6818
si_en Dev loss: 0.7920 r:0.5706
ne_en Dev loss: 0.4420 r:0.7333
ru_en Dev loss: 0.4099 r:0.7439
Current avg r:0.5995 Best avg r: 0.6290
01:03:50,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:21,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:53,39 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2180
en_de Dev loss: 0.8578 r:0.1967
en_zh Dev loss: 0.7653 r:0.4241
ro_en Dev loss: 0.3379 r:0.8136
et_en Dev loss: 0.4329 r:0.6708
si_en Dev loss: 0.9246 r:0.5572
ne_en Dev loss: 0.5208 r:0.7344
ru_en Dev loss: 0.4465 r:0.7181
Current avg r:0.5879 Best avg r: 0.6290
01:11:27,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:58,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:29,465 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2175
en_de Dev loss: 0.8645 r:0.2219
en_zh Dev loss: 0.7563 r:0.4427
ro_en Dev loss: 0.3389 r:0.8171
et_en Dev loss: 0.4316 r:0.6775
si_en Dev loss: 0.8045 r:0.5661
ne_en Dev loss: 0.4289 r:0.7383
ru_en Dev loss: 0.4672 r:0.7151
Current avg r:0.5969 Best avg r: 0.6290
01:19:03,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:20:34,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:22:05,816 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2173
en_de Dev loss: 0.8667 r:0.2343
en_zh Dev loss: 0.8163 r:0.4371
ro_en Dev loss: 0.3665 r:0.8193
et_en Dev loss: 0.4595 r:0.6717
si_en Dev loss: 0.8205 r:0.5701
ne_en Dev loss: 0.4696 r:0.7350
ru_en Dev loss: 0.4557 r:0.7314
Current avg r:0.5999 Best avg r: 0.6290
01:26:39,980 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:11,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:29:42,124 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2142
en_de Dev loss: 0.8705 r:0.2177
en_zh Dev loss: 0.7739 r:0.4500
ro_en Dev loss: 0.3391 r:0.8240
et_en Dev loss: 0.4513 r:0.6731
si_en Dev loss: 0.8274 r:0.5716
ne_en Dev loss: 0.4405 r:0.7445
ru_en Dev loss: 0.4572 r:0.7263
Current avg r:0.6010 Best avg r: 0.6290
01:34:16,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:47,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:18,544 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2290
en_de Dev loss: 0.8873 r:0.2193
en_zh Dev loss: 0.8121 r:0.4514
ro_en Dev loss: 0.3660 r:0.8217
et_en Dev loss: 0.4773 r:0.6722
si_en Dev loss: 0.8542 r:0.5648
ne_en Dev loss: 0.4314 r:0.7429
ru_en Dev loss: 0.4904 r:0.7271
Current avg r:0.5999 Best avg r: 0.6290
01:41:52,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:23,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:44:54,871 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2161
en_de Dev loss: 0.8641 r:0.2072
en_zh Dev loss: 0.7783 r:0.4569
ro_en Dev loss: 0.3605 r:0.8197
et_en Dev loss: 0.4586 r:0.6762
si_en Dev loss: 0.7996 r:0.5691
ne_en Dev loss: 0.4249 r:0.7432
ru_en Dev loss: 0.4494 r:0.7346
Current avg r:0.6010 Best avg r: 0.6290
01:49:29,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:00,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:31,298 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2136
en_de Dev loss: 0.8892 r:0.1954
en_zh Dev loss: 0.8257 r:0.4480
ro_en Dev loss: 0.3600 r:0.8146
et_en Dev loss: 0.4453 r:0.6698
si_en Dev loss: 0.7742 r:0.5691
ne_en Dev loss: 0.4172 r:0.7394
ru_en Dev loss: 0.4786 r:0.7191
Current avg r:0.5936 Best avg r: 0.6290
01:57:05,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:58:36,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:07,832 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2121
en_de Dev loss: 0.8796 r:0.1887
en_zh Dev loss: 0.7440 r:0.4538
ro_en Dev loss: 0.3239 r:0.8202
et_en Dev loss: 0.4405 r:0.6757
si_en Dev loss: 0.7231 r:0.5662
ne_en Dev loss: 0.4162 r:0.7363
ru_en Dev loss: 0.4142 r:0.7378
Current avg r:0.5969 Best avg r: 0.6290
02:04:42,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:13,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:44,645 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2185
en_de Dev loss: 0.9055 r:0.1837
en_zh Dev loss: 0.7918 r:0.4410
ro_en Dev loss: 0.3502 r:0.8115
et_en Dev loss: 0.4646 r:0.6630
si_en Dev loss: 0.8321 r:0.5574
ne_en Dev loss: 0.4522 r:0.7307
ru_en Dev loss: 0.4827 r:0.7129
Current avg r:0.5857 Best avg r: 0.6290
02:12:19,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:50,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:15:21,432 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2028
en_de Dev loss: 0.8848 r:0.2121
en_zh Dev loss: 0.7572 r:0.4545
ro_en Dev loss: 0.3266 r:0.8162
et_en Dev loss: 0.4476 r:0.6665
si_en Dev loss: 0.7907 r:0.5630
ne_en Dev loss: 0.4390 r:0.7326
ru_en Dev loss: 0.4547 r:0.7207
Current avg r:0.5951 Best avg r: 0.6290
02:19:55,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:26,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:58,154 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2114
en_de Dev loss: 0.8830 r:0.2050
en_zh Dev loss: 0.7695 r:0.4591
ro_en Dev loss: 0.3457 r:0.8178
et_en Dev loss: 0.4520 r:0.6754
si_en Dev loss: 0.7724 r:0.5664
ne_en Dev loss: 0.4151 r:0.7394
ru_en Dev loss: 0.4598 r:0.7208
Current avg r:0.5977 Best avg r: 0.6290
02:27:34,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:05,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:30:36,391 root INFO Epoch 6 Global steps: 63700 Train loss: 0.1786
en_de Dev loss: 0.8972 r:0.2048
en_zh Dev loss: 0.7954 r:0.4610
ro_en Dev loss: 0.3517 r:0.8180
et_en Dev loss: 0.4716 r:0.6664
si_en Dev loss: 0.7975 r:0.5693
ne_en Dev loss: 0.4347 r:0.7390
ru_en Dev loss: 0.4681 r:0.7299
Current avg r:0.5984 Best avg r: 0.6290
02:35:10,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:41,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:12,799 root INFO Epoch 6 Global steps: 64400 Train loss: 0.1865
en_de Dev loss: 0.8877 r:0.1985
en_zh Dev loss: 0.8043 r:0.4518
ro_en Dev loss: 0.3759 r:0.8139
et_en Dev loss: 0.4683 r:0.6528
si_en Dev loss: 0.9551 r:0.5519
ne_en Dev loss: 0.5081 r:0.7308
ru_en Dev loss: 0.4881 r:0.7185
Current avg r:0.5883 Best avg r: 0.6290
02:42:46,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:44:17,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:48,209 root INFO Epoch 6 Global steps: 65100 Train loss: 0.1853
en_de Dev loss: 0.8963 r:0.1712
en_zh Dev loss: 0.7684 r:0.4524
ro_en Dev loss: 0.3518 r:0.8149
et_en Dev loss: 0.4394 r:0.6652
si_en Dev loss: 0.8026 r:0.5655
ne_en Dev loss: 0.4515 r:0.7328
ru_en Dev loss: 0.4832 r:0.7132
Current avg r:0.5879 Best avg r: 0.6290
02:50:21,602 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:52,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:23,622 root INFO Epoch 6 Global steps: 65800 Train loss: 0.1799
en_de Dev loss: 0.8875 r:0.1918
en_zh Dev loss: 0.7662 r:0.4507
ro_en Dev loss: 0.3398 r:0.8185
et_en Dev loss: 0.4879 r:0.6686
si_en Dev loss: 0.7972 r:0.5593
ne_en Dev loss: 0.4115 r:0.7335
ru_en Dev loss: 0.4463 r:0.7218
Current avg r:0.5920 Best avg r: 0.6290
02:57:57,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:59:28,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:59,160 root INFO Epoch 6 Global steps: 66500 Train loss: 0.1956
en_de Dev loss: 0.8968 r:0.1848
en_zh Dev loss: 0.7939 r:0.4476
ro_en Dev loss: 0.3573 r:0.8136
et_en Dev loss: 0.4512 r:0.6613
si_en Dev loss: 0.9648 r:0.5467
ne_en Dev loss: 0.5019 r:0.7328
ru_en Dev loss: 0.5002 r:0.7073
Current avg r:0.5849 Best avg r: 0.6290
03:05:32,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:07:03,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:34,199 root INFO Epoch 6 Global steps: 67200 Train loss: 0.1912
en_de Dev loss: 0.9029 r:0.1695
en_zh Dev loss: 0.7778 r:0.4514
ro_en Dev loss: 0.3461 r:0.8170
et_en Dev loss: 0.4613 r:0.6582
si_en Dev loss: 0.9113 r:0.5520
ne_en Dev loss: 0.4834 r:0.7349
ru_en Dev loss: 0.4635 r:0.7199
Current avg r:0.5861 Best avg r: 0.6290
03:13:07,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:38,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:09,691 root INFO Epoch 6 Global steps: 67900 Train loss: 0.1974
en_de Dev loss: 0.8906 r:0.1817
en_zh Dev loss: 0.7867 r:0.4443
ro_en Dev loss: 0.3392 r:0.8207
et_en Dev loss: 0.4766 r:0.6513
si_en Dev loss: 0.8991 r:0.5530
ne_en Dev loss: 0.4631 r:0.7319
ru_en Dev loss: 0.4697 r:0.7167
Current avg r:0.5857 Best avg r: 0.6290
03:20:42,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:22:13,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:44,928 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2006
en_de Dev loss: 0.9012 r:0.1688
en_zh Dev loss: 0.7698 r:0.4523
ro_en Dev loss: 0.3439 r:0.8234
et_en Dev loss: 0.4758 r:0.6581
si_en Dev loss: 0.8132 r:0.5577
ne_en Dev loss: 0.4272 r:0.7369
ru_en Dev loss: 0.4429 r:0.7298
Current avg r:0.5896 Best avg r: 0.6290
03:28:18,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:49,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:20,201 root INFO Epoch 6 Global steps: 69300 Train loss: 0.1870
en_de Dev loss: 0.9088 r:0.1672
en_zh Dev loss: 0.8156 r:0.4433
ro_en Dev loss: 0.3570 r:0.8269
et_en Dev loss: 0.4658 r:0.6699
si_en Dev loss: 0.8925 r:0.5582
ne_en Dev loss: 0.4623 r:0.7361
ru_en Dev loss: 0.4984 r:0.7149
Current avg r:0.5881 Best avg r: 0.6290
03:35:53,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:24,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:55,620 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1991
en_de Dev loss: 0.8939 r:0.1900
en_zh Dev loss: 0.7834 r:0.4558
ro_en Dev loss: 0.3303 r:0.8264
et_en Dev loss: 0.4676 r:0.6752
si_en Dev loss: 0.8266 r:0.5603
ne_en Dev loss: 0.4135 r:0.7413
ru_en Dev loss: 0.4434 r:0.7318
Current avg r:0.5973 Best avg r: 0.6290
03:43:28,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:59,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:46:30,913 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1845
en_de Dev loss: 0.9343 r:0.1353
en_zh Dev loss: 0.8979 r:0.4255
ro_en Dev loss: 0.3750 r:0.8173
et_en Dev loss: 0.4820 r:0.6436
si_en Dev loss: 0.9284 r:0.5374
ne_en Dev loss: 0.4962 r:0.7272
ru_en Dev loss: 0.5507 r:0.6858
Current avg r:0.5674 Best avg r: 0.6290
03:51:04,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:52:35,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:54:06,204 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1831
en_de Dev loss: 0.9035 r:0.1753
en_zh Dev loss: 0.8101 r:0.4480
ro_en Dev loss: 0.3689 r:0.8203
et_en Dev loss: 0.4881 r:0.6554
si_en Dev loss: 0.8770 r:0.5481
ne_en Dev loss: 0.4438 r:0.7369
ru_en Dev loss: 0.5100 r:0.7042
Current avg r:0.5840 Best avg r: 0.6290
03:58:39,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:00:10,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:01:41,566 root INFO Epoch 6 Global steps: 72100 Train loss: 0.1804
en_de Dev loss: 0.8785 r:0.2078
en_zh Dev loss: 0.7681 r:0.4600
ro_en Dev loss: 0.3431 r:0.8199
et_en Dev loss: 0.4674 r:0.6607
si_en Dev loss: 0.8249 r:0.5536
ne_en Dev loss: 0.4106 r:0.7402
ru_en Dev loss: 0.4552 r:0.7232
Current avg r:0.5950 Best avg r: 0.6290
04:06:14,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:07:45,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:09:16,887 root INFO Epoch 6 Global steps: 72800 Train loss: 0.1757
en_de Dev loss: 0.9109 r:0.1932
en_zh Dev loss: 0.8339 r:0.4575
ro_en Dev loss: 0.3986 r:0.8197
et_en Dev loss: 0.4940 r:0.6471
si_en Dev loss: 0.9346 r:0.5482
ne_en Dev loss: 0.5198 r:0.7332
ru_en Dev loss: 0.5671 r:0.6998
Current avg r:0.5855 Best avg r: 0.6290
04:13:50,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:15:21,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:16:52,343 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1713
en_de Dev loss: 0.8892 r:0.1969
en_zh Dev loss: 0.7880 r:0.4578
ro_en Dev loss: 0.3403 r:0.8207
et_en Dev loss: 0.4699 r:0.6607
si_en Dev loss: 0.8201 r:0.5543
ne_en Dev loss: 0.4149 r:0.7386
ru_en Dev loss: 0.4604 r:0.7257
Current avg r:0.5935 Best avg r: 0.6290
04:21:27,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:22:58,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:24:29,333 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1612
en_de Dev loss: 0.8836 r:0.2121
en_zh Dev loss: 0.7530 r:0.4675
ro_en Dev loss: 0.3378 r:0.8195
et_en Dev loss: 0.4599 r:0.6576
si_en Dev loss: 0.8116 r:0.5564
ne_en Dev loss: 0.4209 r:0.7373
ru_en Dev loss: 0.4417 r:0.7308
Current avg r:0.5973 Best avg r: 0.6290
04:29:02,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:33,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:32:04,641 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1615
en_de Dev loss: 0.8787 r:0.2279
en_zh Dev loss: 0.8072 r:0.4585
ro_en Dev loss: 0.3707 r:0.8210
et_en Dev loss: 0.4839 r:0.6658
si_en Dev loss: 0.8354 r:0.5627
ne_en Dev loss: 0.4331 r:0.7393
ru_en Dev loss: 0.5096 r:0.7090
Current avg r:0.5978 Best avg r: 0.6290
04:36:37,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:38:08,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:39:39,965 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1630
en_de Dev loss: 0.8835 r:0.2013
en_zh Dev loss: 0.7674 r:0.4621
ro_en Dev loss: 0.3451 r:0.8197
et_en Dev loss: 0.4698 r:0.6618
si_en Dev loss: 0.8394 r:0.5568
ne_en Dev loss: 0.4189 r:0.7401
ru_en Dev loss: 0.4456 r:0.7308
Current avg r:0.5961 Best avg r: 0.6290
04:44:13,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:39,202 root INFO 
id:en_zh cur r: 0.4870 best r: 0.4870
04:45:44,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:47:15,195 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1557
en_de Dev loss: 0.8719 r:0.2258
en_zh Dev loss: 0.7438 r:0.4771
ro_en Dev loss: 0.3452 r:0.8214
et_en Dev loss: 0.4557 r:0.6724
si_en Dev loss: 0.8227 r:0.5623
ne_en Dev loss: 0.3978 r:0.7382
ru_en Dev loss: 0.4816 r:0.7167
Current avg r:0.6020 Best avg r: 0.6290
04:51:48,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:53:19,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:54:50,493 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1578
en_de Dev loss: 0.8754 r:0.2300
en_zh Dev loss: 0.8105 r:0.4554
ro_en Dev loss: 0.3574 r:0.8216
et_en Dev loss: 0.4672 r:0.6715
si_en Dev loss: 0.8576 r:0.5578
ne_en Dev loss: 0.4073 r:0.7424
ru_en Dev loss: 0.4753 r:0.7264
Current avg r:0.6007 Best avg r: 0.6290
04:59:23,865 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:00:54,830 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:02:25,814 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1552
en_de Dev loss: 0.8815 r:0.1949
en_zh Dev loss: 0.7615 r:0.4641
ro_en Dev loss: 0.3393 r:0.8218
et_en Dev loss: 0.4571 r:0.6733
si_en Dev loss: 0.7800 r:0.5614
ne_en Dev loss: 0.3984 r:0.7413
ru_en Dev loss: 0.4366 r:0.7322
Current avg r:0.5984 Best avg r: 0.6290
05:06:59,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:08:30,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:10:01,131 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1637
en_de Dev loss: 0.8729 r:0.2258
en_zh Dev loss: 0.7600 r:0.4610
ro_en Dev loss: 0.3321 r:0.8255
et_en Dev loss: 0.4425 r:0.6761
si_en Dev loss: 0.8274 r:0.5575
ne_en Dev loss: 0.4057 r:0.7444
ru_en Dev loss: 0.4743 r:0.7207
Current avg r:0.6016 Best avg r: 0.6290
05:14:34,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:16:05,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:17:36,421 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1591
en_de Dev loss: 0.8850 r:0.2024
en_zh Dev loss: 0.7723 r:0.4576
ro_en Dev loss: 0.3418 r:0.8243
et_en Dev loss: 0.4554 r:0.6696
si_en Dev loss: 0.8493 r:0.5557
ne_en Dev loss: 0.4375 r:0.7339
ru_en Dev loss: 0.4727 r:0.7154
Current avg r:0.5941 Best avg r: 0.6290
05:22:09,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:23:40,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:11,859 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1694
en_de Dev loss: 0.9114 r:0.1772
en_zh Dev loss: 0.8308 r:0.4496
ro_en Dev loss: 0.3585 r:0.8201
et_en Dev loss: 0.4508 r:0.6769
si_en Dev loss: 0.9004 r:0.5477
ne_en Dev loss: 0.4324 r:0.7349
ru_en Dev loss: 0.5051 r:0.7117
Current avg r:0.5883 Best avg r: 0.6290
05:29:45,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:31:16,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:32:47,111 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1607
en_de Dev loss: 0.8934 r:0.1833
en_zh Dev loss: 0.7855 r:0.4458
ro_en Dev loss: 0.3492 r:0.8190
et_en Dev loss: 0.5022 r:0.6683
si_en Dev loss: 0.8290 r:0.5475
ne_en Dev loss: 0.3916 r:0.7392
ru_en Dev loss: 0.4980 r:0.7031
Current avg r:0.5866 Best avg r: 0.6290
05:37:20,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:38:51,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:40:22,414 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1523
en_de Dev loss: 0.8824 r:0.1959
en_zh Dev loss: 0.7763 r:0.4569
ro_en Dev loss: 0.3559 r:0.8200
et_en Dev loss: 0.4549 r:0.6586
si_en Dev loss: 0.8515 r:0.5438
ne_en Dev loss: 0.4326 r:0.7383
ru_en Dev loss: 0.4828 r:0.7158
Current avg r:0.5899 Best avg r: 0.6290
05:44:55,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:46:26,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:47:57,698 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1483
en_de Dev loss: 0.9076 r:0.1984
en_zh Dev loss: 0.8262 r:0.4587
ro_en Dev loss: 0.3927 r:0.8153
et_en Dev loss: 0.4805 r:0.6599
si_en Dev loss: 0.9209 r:0.5391
ne_en Dev loss: 0.4711 r:0.7329
ru_en Dev loss: 0.5306 r:0.7127
Current avg r:0.5881 Best avg r: 0.6290
05:52:30,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:01,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:55:33,26 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1498
en_de Dev loss: 0.8793 r:0.2023
en_zh Dev loss: 0.7850 r:0.4494
ro_en Dev loss: 0.3334 r:0.8204
et_en Dev loss: 0.4589 r:0.6681
si_en Dev loss: 0.8175 r:0.5493
ne_en Dev loss: 0.4214 r:0.7290
ru_en Dev loss: 0.4666 r:0.7209
Current avg r:0.5914 Best avg r: 0.6290
06:00:06,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:01:37,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:03:08,153 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1579
en_de Dev loss: 0.9029 r:0.2075
en_zh Dev loss: 0.8053 r:0.4603
ro_en Dev loss: 0.3620 r:0.8215
et_en Dev loss: 0.4763 r:0.6760
si_en Dev loss: 0.8453 r:0.5559
ne_en Dev loss: 0.4109 r:0.7345
ru_en Dev loss: 0.4634 r:0.7372
Current avg r:0.5990 Best avg r: 0.6290
06:07:41,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:12,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:10:43,283 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1577
en_de Dev loss: 0.8997 r:0.1802
en_zh Dev loss: 0.8287 r:0.4464
ro_en Dev loss: 0.3364 r:0.8245
et_en Dev loss: 0.4738 r:0.6668
si_en Dev loss: 0.7952 r:0.5501
ne_en Dev loss: 0.4070 r:0.7330
ru_en Dev loss: 0.4586 r:0.7280
Current avg r:0.5899 Best avg r: 0.6290
06:15:17,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:16:48,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:19,822 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1337
en_de Dev loss: 0.8809 r:0.2188
en_zh Dev loss: 0.7906 r:0.4475
ro_en Dev loss: 0.3295 r:0.8257
et_en Dev loss: 0.4443 r:0.6780
si_en Dev loss: 0.7937 r:0.5563
ne_en Dev loss: 0.3969 r:0.7374
ru_en Dev loss: 0.4496 r:0.7334
Current avg r:0.5996 Best avg r: 0.6290
06:22:53,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:24:24,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:25:55,81 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1387
en_de Dev loss: 0.8757 r:0.2017
en_zh Dev loss: 0.7534 r:0.4584
ro_en Dev loss: 0.3239 r:0.8230
et_en Dev loss: 0.4611 r:0.6690
si_en Dev loss: 0.8288 r:0.5456
ne_en Dev loss: 0.4204 r:0.7258
ru_en Dev loss: 0.4541 r:0.7220
Current avg r:0.5922 Best avg r: 0.6290
06:30:29,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:32:00,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:33:31,558 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1514
en_de Dev loss: 0.9160 r:0.1754
en_zh Dev loss: 0.7917 r:0.4672
ro_en Dev loss: 0.3515 r:0.8197
et_en Dev loss: 0.4682 r:0.6672
si_en Dev loss: 0.8307 r:0.5478
ne_en Dev loss: 0.4266 r:0.7281
ru_en Dev loss: 0.4589 r:0.7267
Current avg r:0.5903 Best avg r: 0.6290
06:38:05,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:39:36,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:41:07,672 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1388
en_de Dev loss: 0.9076 r:0.1635
en_zh Dev loss: 0.7794 r:0.4643
ro_en Dev loss: 0.3394 r:0.8195
et_en Dev loss: 0.4362 r:0.6685
si_en Dev loss: 0.8161 r:0.5532
ne_en Dev loss: 0.4181 r:0.7341
ru_en Dev loss: 0.4688 r:0.7220
Current avg r:0.5893 Best avg r: 0.6290
06:45:41,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:12,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:48:43,721 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1417
en_de Dev loss: 0.9341 r:0.1601
en_zh Dev loss: 0.7846 r:0.4716
ro_en Dev loss: 0.3473 r:0.8201
et_en Dev loss: 0.4582 r:0.6658
si_en Dev loss: 0.8376 r:0.5515
ne_en Dev loss: 0.4112 r:0.7317
ru_en Dev loss: 0.5013 r:0.7128
Current avg r:0.5877 Best avg r: 0.6290
06:53:18,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:49,312 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:20,434 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1332
en_de Dev loss: 0.9108 r:0.1874
en_zh Dev loss: 0.7841 r:0.4632
ro_en Dev loss: 0.3429 r:0.8188
et_en Dev loss: 0.4342 r:0.6684
si_en Dev loss: 0.8530 r:0.5439
ne_en Dev loss: 0.4221 r:0.7328
ru_en Dev loss: 0.4781 r:0.7208
Current avg r:0.5908 Best avg r: 0.6290
07:00:53,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:24,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:03:55,921 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1362
en_de Dev loss: 0.9220 r:0.1674
en_zh Dev loss: 0.7844 r:0.4577
ro_en Dev loss: 0.3308 r:0.8213
et_en Dev loss: 0.4539 r:0.6739
si_en Dev loss: 0.8646 r:0.5475
ne_en Dev loss: 0.4035 r:0.7363
ru_en Dev loss: 0.4634 r:0.7309
Current avg r:0.5907 Best avg r: 0.6290
07:08:29,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:10:00,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:11:31,335 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1341
en_de Dev loss: 0.9049 r:0.1950
en_zh Dev loss: 0.7757 r:0.4702
ro_en Dev loss: 0.3409 r:0.8235
et_en Dev loss: 0.4907 r:0.6705
si_en Dev loss: 0.8524 r:0.5495
ne_en Dev loss: 0.3905 r:0.7368
ru_en Dev loss: 0.4351 r:0.7372
Current avg r:0.5975 Best avg r: 0.6290
07:16:04,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:35,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:19:06,493 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1370
en_de Dev loss: 0.9127 r:0.2075
en_zh Dev loss: 0.7910 r:0.4705
ro_en Dev loss: 0.3404 r:0.8264
et_en Dev loss: 0.4858 r:0.6726
si_en Dev loss: 0.8557 r:0.5537
ne_en Dev loss: 0.3977 r:0.7343
ru_en Dev loss: 0.4740 r:0.7280
Current avg r:0.5990 Best avg r: 0.6290
07:23:39,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:10,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:42,51 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1399
en_de Dev loss: 0.8935 r:0.1843
en_zh Dev loss: 0.8041 r:0.4586
ro_en Dev loss: 0.3347 r:0.8241
et_en Dev loss: 0.4431 r:0.6701
si_en Dev loss: 0.9635 r:0.5463
ne_en Dev loss: 0.4538 r:0.7362
ru_en Dev loss: 0.4743 r:0.7212
Current avg r:0.5915 Best avg r: 0.6290
07:31:16,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:47,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:34:18,929 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1334
en_de Dev loss: 0.9607 r:0.1532
en_zh Dev loss: 0.8593 r:0.4520
ro_en Dev loss: 0.3849 r:0.8212
et_en Dev loss: 0.4889 r:0.6605
si_en Dev loss: 0.9940 r:0.5361
ne_en Dev loss: 0.4629 r:0.7327
ru_en Dev loss: 0.5503 r:0.7050
Current avg r:0.5801 Best avg r: 0.6290
07:38:53,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:24,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:41:55,640 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1369
en_de Dev loss: 0.9291 r:0.1709
en_zh Dev loss: 0.7971 r:0.4552
ro_en Dev loss: 0.3481 r:0.8182
et_en Dev loss: 0.4782 r:0.6654
si_en Dev loss: 0.9087 r:0.5411
ne_en Dev loss: 0.4289 r:0.7343
ru_en Dev loss: 0.4866 r:0.7163
Current avg r:0.5859 Best avg r: 0.6290
07:46:28,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:59,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:49:31,20 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1378
en_de Dev loss: 0.9206 r:0.1572
en_zh Dev loss: 0.7513 r:0.4748
ro_en Dev loss: 0.3276 r:0.8207
et_en Dev loss: 0.4576 r:0.6685
si_en Dev loss: 0.8314 r:0.5515
ne_en Dev loss: 0.4088 r:0.7392
ru_en Dev loss: 0.4493 r:0.7286
Current avg r:0.5915 Best avg r: 0.6290
07:54:04,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:55:35,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:57:06,875 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1313
en_de Dev loss: 0.9493 r:0.1455
en_zh Dev loss: 0.7978 r:0.4600
ro_en Dev loss: 0.3622 r:0.8167
et_en Dev loss: 0.4782 r:0.6567
si_en Dev loss: 0.9014 r:0.5452
ne_en Dev loss: 0.4458 r:0.7334
ru_en Dev loss: 0.5086 r:0.7162
Current avg r:0.5820 Best avg r: 0.6290
08:01:41,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:03:12,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:04:43,615 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1293
en_de Dev loss: 0.9476 r:0.1507
en_zh Dev loss: 0.8007 r:0.4567
ro_en Dev loss: 0.3449 r:0.8188
et_en Dev loss: 0.4769 r:0.6522
si_en Dev loss: 0.9061 r:0.5395
ne_en Dev loss: 0.4123 r:0.7363
ru_en Dev loss: 0.4767 r:0.7201
Current avg r:0.5820 Best avg r: 0.6290
08:09:18,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:10:49,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:12:20,970 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1294
en_de Dev loss: 0.9700 r:0.1386
en_zh Dev loss: 0.7754 r:0.4661
ro_en Dev loss: 0.3657 r:0.8166
et_en Dev loss: 0.4903 r:0.6548
si_en Dev loss: 0.9802 r:0.5377
ne_en Dev loss: 0.4348 r:0.7294
ru_en Dev loss: 0.4672 r:0.7310
Current avg r:0.5820 Best avg r: 0.6290
08:16:54,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:18:25,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:19:56,793 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1150
en_de Dev loss: 0.9291 r:0.1700
en_zh Dev loss: 0.7888 r:0.4594
ro_en Dev loss: 0.3427 r:0.8198
et_en Dev loss: 0.4683 r:0.6589
si_en Dev loss: 0.8923 r:0.5459
ne_en Dev loss: 0.4227 r:0.7373
ru_en Dev loss: 0.4524 r:0.7364
Current avg r:0.5897 Best avg r: 0.6290
08:24:30,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:01,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:27:32,495 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1163
en_de Dev loss: 0.9836 r:0.1474
en_zh Dev loss: 0.8292 r:0.4651
ro_en Dev loss: 0.3530 r:0.8233
et_en Dev loss: 0.4978 r:0.6734
si_en Dev loss: 0.8580 r:0.5562
ne_en Dev loss: 0.3933 r:0.7394
ru_en Dev loss: 0.4540 r:0.7426
Current avg r:0.5925 Best avg r: 0.6290
08:32:06,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:33:37,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:35:08,457 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1244
en_de Dev loss: 0.9333 r:0.1529
en_zh Dev loss: 0.7659 r:0.4598
ro_en Dev loss: 0.3239 r:0.8225
et_en Dev loss: 0.4626 r:0.6691
si_en Dev loss: 0.8099 r:0.5577
ne_en Dev loss: 0.3788 r:0.7393
ru_en Dev loss: 0.4337 r:0.7368
Current avg r:0.5912 Best avg r: 0.6290
08:39:41,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:41:12,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:42:43,697 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1217
en_de Dev loss: 0.9662 r:0.1433
en_zh Dev loss: 0.8351 r:0.4605
ro_en Dev loss: 0.3736 r:0.8174
et_en Dev loss: 0.4888 r:0.6632
si_en Dev loss: 0.8729 r:0.5566
ne_en Dev loss: 0.4193 r:0.7395
ru_en Dev loss: 0.5028 r:0.7269
Current avg r:0.5868 Best avg r: 0.6290
08:47:17,104 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:48,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:50:19,73 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1273
en_de Dev loss: 0.9402 r:0.1535
en_zh Dev loss: 0.7699 r:0.4649
ro_en Dev loss: 0.3264 r:0.8224
et_en Dev loss: 0.4834 r:0.6742
si_en Dev loss: 0.7966 r:0.5534
ne_en Dev loss: 0.3857 r:0.7373
ru_en Dev loss: 0.4261 r:0.7402
Current avg r:0.5923 Best avg r: 0.6290
08:54:53,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:56:24,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:57:55,638 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1236
en_de Dev loss: 0.9959 r:0.1347
en_zh Dev loss: 0.8295 r:0.4574
ro_en Dev loss: 0.3595 r:0.8197
et_en Dev loss: 0.4810 r:0.6682
si_en Dev loss: 0.9001 r:0.5449
ne_en Dev loss: 0.4183 r:0.7360
ru_en Dev loss: 0.4902 r:0.7293
Current avg r:0.5843 Best avg r: 0.6290
09:02:30,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:04:01,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:05:32,374 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1187
en_de Dev loss: 0.9323 r:0.1563
en_zh Dev loss: 0.7552 r:0.4736
ro_en Dev loss: 0.3338 r:0.8201
et_en Dev loss: 0.4702 r:0.6621
si_en Dev loss: 0.8675 r:0.5421
ne_en Dev loss: 0.3980 r:0.7392
ru_en Dev loss: 0.4730 r:0.7170
Current avg r:0.5872 Best avg r: 0.6290
09:10:05,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:11:36,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:13:07,899 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1226
en_de Dev loss: 0.9326 r:0.1674
en_zh Dev loss: 0.7364 r:0.4731
ro_en Dev loss: 0.3166 r:0.8207
et_en Dev loss: 0.4702 r:0.6842
si_en Dev loss: 0.7545 r:0.5574
ne_en Dev loss: 0.3659 r:0.7422
ru_en Dev loss: 0.4156 r:0.7412
Current avg r:0.5980 Best avg r: 0.6290
09:17:41,28 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:19:11,962 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:20:42,990 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1224
en_de Dev loss: 0.9291 r:0.1521
en_zh Dev loss: 0.7987 r:0.4618
ro_en Dev loss: 0.3609 r:0.8184
et_en Dev loss: 0.4573 r:0.6673
si_en Dev loss: 0.9570 r:0.5433
ne_en Dev loss: 0.4688 r:0.7411
ru_en Dev loss: 0.4514 r:0.7337
Current avg r:0.5882 Best avg r: 0.6290
09:25:16,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:26:47,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:28:18,77 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1208
en_de Dev loss: 0.9654 r:0.1505
en_zh Dev loss: 0.8395 r:0.4560
ro_en Dev loss: 0.3680 r:0.8207
et_en Dev loss: 0.4578 r:0.6677
si_en Dev loss: 0.9619 r:0.5336
ne_en Dev loss: 0.4485 r:0.7392
ru_en Dev loss: 0.5181 r:0.7170
Current avg r:0.5835 Best avg r: 0.6290
09:32:51,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:34:22,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:35:53,263 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1219
en_de Dev loss: 0.9392 r:0.1571
en_zh Dev loss: 0.7971 r:0.4549
ro_en Dev loss: 0.3581 r:0.8214
et_en Dev loss: 0.4626 r:0.6601
si_en Dev loss: 0.9035 r:0.5446
ne_en Dev loss: 0.4338 r:0.7416
ru_en Dev loss: 0.4775 r:0.7226
Current avg r:0.5860 Best avg r: 0.6290
09:40:26,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:57,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:28,272 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1187
en_de Dev loss: 0.9292 r:0.1848
en_zh Dev loss: 0.7909 r:0.4536
ro_en Dev loss: 0.3430 r:0.8217
et_en Dev loss: 0.4783 r:0.6613
si_en Dev loss: 0.8624 r:0.5428
ne_en Dev loss: 0.4024 r:0.7375
ru_en Dev loss: 0.4498 r:0.7307
Current avg r:0.5903 Best avg r: 0.6290
09:48:01,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:49:32,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:03,727 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1168
en_de Dev loss: 0.9359 r:0.1711
en_zh Dev loss: 0.7953 r:0.4550
ro_en Dev loss: 0.3367 r:0.8233
et_en Dev loss: 0.4537 r:0.6744
si_en Dev loss: 0.8756 r:0.5481
ne_en Dev loss: 0.4033 r:0.7421
ru_en Dev loss: 0.4869 r:0.7206
Current avg r:0.5906 Best avg r: 0.6290
09:55:37,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:09,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:40,216 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1261
en_de Dev loss: 0.9271 r:0.1742
en_zh Dev loss: 0.7905 r:0.4572
ro_en Dev loss: 0.3420 r:0.8234
et_en Dev loss: 0.4592 r:0.6748
si_en Dev loss: 0.8890 r:0.5424
ne_en Dev loss: 0.4107 r:0.7379
ru_en Dev loss: 0.4673 r:0.7262
Current avg r:0.5909 Best avg r: 0.6290
10:03:15,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:46,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:17,970 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1137
en_de Dev loss: 0.9474 r:0.1592
en_zh Dev loss: 0.8036 r:0.4552
ro_en Dev loss: 0.3369 r:0.8259
et_en Dev loss: 0.4577 r:0.6734
si_en Dev loss: 0.8615 r:0.5463
ne_en Dev loss: 0.4026 r:0.7388
ru_en Dev loss: 0.4990 r:0.7209
Current avg r:0.5885 Best avg r: 0.6290
10:10:52,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:12:23,144 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:13:54,239 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1041
en_de Dev loss: 0.9536 r:0.1744
en_zh Dev loss: 0.8499 r:0.4605
ro_en Dev loss: 0.3836 r:0.8208
et_en Dev loss: 0.4903 r:0.6749
si_en Dev loss: 0.9111 r:0.5482
ne_en Dev loss: 0.3993 r:0.7451
ru_en Dev loss: 0.5080 r:0.7305
Current avg r:0.5935 Best avg r: 0.6290
10:18:28,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:59,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:21:30,565 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1126
en_de Dev loss: 0.9610 r:0.1431
en_zh Dev loss: 0.7970 r:0.4550
ro_en Dev loss: 0.3550 r:0.8163
et_en Dev loss: 0.4651 r:0.6596
si_en Dev loss: 0.9104 r:0.5383
ne_en Dev loss: 0.4049 r:0.7421
ru_en Dev loss: 0.4698 r:0.7288
Current avg r:0.5833 Best avg r: 0.6290
10:26:04,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:35,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:06,505 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1103
en_de Dev loss: 0.9578 r:0.1588
en_zh Dev loss: 0.7861 r:0.4644
ro_en Dev loss: 0.3497 r:0.8221
et_en Dev loss: 0.4788 r:0.6629
si_en Dev loss: 0.8982 r:0.5386
ne_en Dev loss: 0.4166 r:0.7404
ru_en Dev loss: 0.4912 r:0.7199
Current avg r:0.5867 Best avg r: 0.6290
10:33:39,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:35:10,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:36:41,824 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1079
en_de Dev loss: 0.9551 r:0.1644
en_zh Dev loss: 0.7800 r:0.4733
ro_en Dev loss: 0.3360 r:0.8232
et_en Dev loss: 0.4755 r:0.6676
si_en Dev loss: 0.8310 r:0.5488
ne_en Dev loss: 0.3815 r:0.7417
ru_en Dev loss: 0.4625 r:0.7359
Current avg r:0.5936 Best avg r: 0.6290
10:41:14,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:42:45,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:44:16,784 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1095
en_de Dev loss: 0.9670 r:0.1625
en_zh Dev loss: 0.8012 r:0.4696
ro_en Dev loss: 0.3408 r:0.8238
et_en Dev loss: 0.4482 r:0.6710
si_en Dev loss: 0.8165 r:0.5560
ne_en Dev loss: 0.3915 r:0.7419
ru_en Dev loss: 0.4689 r:0.7389
Current avg r:0.5948 Best avg r: 0.6290
10:48:49,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
