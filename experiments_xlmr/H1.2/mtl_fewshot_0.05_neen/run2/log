14:44:31,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:44,872 root INFO 
id:en_de cur r: 0.0666 best r: 0.0666
14:44:57,741 root INFO 
id:en_zh cur r: 0.2401 best r: 0.2401
14:45:10,623 root INFO 
id:ro_en cur r: 0.5252 best r: 0.5252
14:45:36,413 root INFO 
id:si_en cur r: 0.4132 best r: 0.4132
14:46:02,234 root INFO 
id:ne_en cur r: 0.4695 best r: 0.4695
14:46:15,88 root INFO 
id:ru_en cur r: 0.5855 best r: 0.5855
14:46:15,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:45,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
14:47:45,257 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:47:45,261 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:47:45,266 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
14:47:45,271 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
14:47:45,276 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:47:45,281 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:47:58,188 root INFO Epoch 0 Global steps: 700 Train loss: 0.8475
en_de Dev loss: 0.9212 r:0.0853
en_zh Dev loss: 0.7606 r:0.2808
ro_en Dev loss: 0.6318 r:0.5492
et_en Dev loss: 0.6109 r:0.5288
si_en Dev loss: 0.6564 r:0.4429
ne_en Dev loss: 0.6655 r:0.5107
ru_en Dev loss: 0.6022 r:0.5799
Current avg r:0.4254 Best avg r: 0.4254
14:52:26,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:39,785 root INFO 
id:en_de cur r: 0.0810 best r: 0.0810
14:53:18,428 root INFO 
id:et_en cur r: 0.2625 best r: 0.2625
14:53:57,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:27,155 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8938
en_de Dev loss: 0.8855 r:0.0482
en_zh Dev loss: 0.8130 r:0.0908
ro_en Dev loss: 0.8305 r:0.2916
et_en Dev loss: 0.7209 r:0.3403
si_en Dev loss: 0.7864 r:0.2349
ne_en Dev loss: 0.7692 r:0.2504
ru_en Dev loss: 0.8181 r:0.1311
Current avg r:0.1982 Best avg r: 0.4254
14:59:55,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:25,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:55,934 root INFO Epoch 0 Global steps: 2100 Train loss: 0.9046
en_de Dev loss: 0.8873 r:0.0305
en_zh Dev loss: 0.8203 r:0.0148
ro_en Dev loss: 0.8575 r:0.0130
et_en Dev loss: 0.7509 r:0.0725
si_en Dev loss: 0.8276 r:0.0664
ne_en Dev loss: 0.7911 r:0.0729
ru_en Dev loss: 0.8309 r:0.0131
Current avg r:0.0404 Best avg r: 0.4254
15:07:24,519 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:54,640 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:24,776 root INFO Epoch 0 Global steps: 2800 Train loss: 0.8939
en_de Dev loss: 0.8861 r:0.0305
en_zh Dev loss: 0.8190 r:0.0165
ro_en Dev loss: 0.8591 r:-0.0224
et_en Dev loss: 0.7405 r:0.0789
si_en Dev loss: 0.8315 r:0.1538
ne_en Dev loss: 0.7871 r:0.0934
ru_en Dev loss: 0.8277 r:0.0519
Current avg r:0.0575 Best avg r: 0.4254
15:14:53,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:23,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:53,732 root INFO Epoch 0 Global steps: 3500 Train loss: 0.8817
en_de Dev loss: 0.8919 r:0.0257
en_zh Dev loss: 0.8307 r:0.0025
ro_en Dev loss: 0.8646 r:0.1482
et_en Dev loss: 0.7145 r:0.0519
si_en Dev loss: 0.8721 r:0.1264
ne_en Dev loss: 0.7964 r:0.0499
ru_en Dev loss: 0.8301 r:0.0470
Current avg r:0.0645 Best avg r: 0.4254
15:22:22,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:52,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:22,612 root INFO Epoch 0 Global steps: 4200 Train loss: 0.8884
en_de Dev loss: 0.8889 r:0.0043
en_zh Dev loss: 0.8224 r:-0.0175
ro_en Dev loss: 0.8535 r:0.0707
et_en Dev loss: 0.7433 r:-0.0199
si_en Dev loss: 0.8342 r:0.0101
ne_en Dev loss: 0.7904 r:0.0342
ru_en Dev loss: 0.8269 r:0.0474
Current avg r:0.0185 Best avg r: 0.4254
15:29:51,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:21,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:51,466 root INFO Epoch 0 Global steps: 4900 Train loss: 0.9094
en_de Dev loss: 0.8826 r:0.0699
en_zh Dev loss: 0.8126 r:0.1139
ro_en Dev loss: 0.8455 r:0.2539
et_en Dev loss: 0.7110 r:0.2734
si_en Dev loss: 0.8230 r:0.2298
ne_en Dev loss: 0.7726 r:0.2068
ru_en Dev loss: 0.8192 r:0.1899
Current avg r:0.1911 Best avg r: 0.4254
15:37:20,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:11,664 root INFO 
id:et_en cur r: 0.2830 best r: 0.2830
15:38:50,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:20,487 root INFO Epoch 0 Global steps: 5600 Train loss: 0.8733
en_de Dev loss: 0.8897 r:0.0362
en_zh Dev loss: 0.8158 r:0.0783
ro_en Dev loss: 0.8642 r:0.0245
et_en Dev loss: 0.7049 r:0.2965
si_en Dev loss: 0.8586 r:0.1508
ne_en Dev loss: 0.7807 r:0.1855
ru_en Dev loss: 0.8294 r:0.0559
Current avg r:0.1182 Best avg r: 0.4254
15:44:49,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:19,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:49,348 root INFO Epoch 0 Global steps: 6300 Train loss: 0.8950
en_de Dev loss: 0.8886 r:0.0408
en_zh Dev loss: 0.8165 r:0.0665
ro_en Dev loss: 0.8438 r:0.1863
et_en Dev loss: 0.7127 r:0.2545
si_en Dev loss: 0.8041 r:0.2397
ne_en Dev loss: 0.7562 r:0.2785
ru_en Dev loss: 0.8131 r:0.1628
Current avg r:0.1756 Best avg r: 0.4254
15:52:17,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:30,764 root INFO 
id:en_de cur r: 0.0900 best r: 0.0900
15:53:48,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:18,191 root INFO Epoch 0 Global steps: 7000 Train loss: 0.8669
en_de Dev loss: 0.8818 r:0.0797
en_zh Dev loss: 0.8173 r:0.0506
ro_en Dev loss: 0.8565 r:0.0966
et_en Dev loss: 0.7146 r:0.2030
si_en Dev loss: 0.8429 r:0.1565
ne_en Dev loss: 0.7754 r:0.2081
ru_en Dev loss: 0.8261 r:0.0697
Current avg r:0.1235 Best avg r: 0.4254
15:59:46,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:17,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:47,164 root INFO Epoch 0 Global steps: 7700 Train loss: 0.8979
en_de Dev loss: 0.8890 r:0.0478
en_zh Dev loss: 0.8186 r:0.0477
ro_en Dev loss: 0.8544 r:0.1415
et_en Dev loss: 0.7085 r:0.2196
si_en Dev loss: 0.8063 r:0.2571
ne_en Dev loss: 0.7679 r:0.2087
ru_en Dev loss: 0.8051 r:0.2512
Current avg r:0.1677 Best avg r: 0.4254
16:07:15,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:08:45,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:15,984 root INFO Epoch 0 Global steps: 8400 Train loss: 0.8689
en_de Dev loss: 0.8883 r:-0.0384
en_zh Dev loss: 0.8193 r:0.1153
ro_en Dev loss: 0.8579 r:0.0772
et_en Dev loss: 0.7286 r:0.0520
si_en Dev loss: 0.8475 r:0.0680
ne_en Dev loss: 0.7915 r:0.1094
ru_en Dev loss: 0.8283 r:0.0196
Current avg r:0.0576 Best avg r: 0.4254
16:14:44,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:14,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:17:44,703 root INFO Epoch 0 Global steps: 9100 Train loss: 0.8961
en_de Dev loss: 0.8899 r:-0.0059
en_zh Dev loss: 0.8205 r:0.0444
ro_en Dev loss: 0.8574 r:0.2287
et_en Dev loss: 0.7229 r:0.0714
si_en Dev loss: 0.8550 r:0.1064
ne_en Dev loss: 0.7906 r:0.0954
ru_en Dev loss: 0.8297 r:-0.0249
Current avg r:0.0736 Best avg r: 0.4254
16:22:13,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:04,841 root INFO 
id:et_en cur r: 0.4072 best r: 0.4072
16:23:43,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:13,670 root INFO Epoch 0 Global steps: 9800 Train loss: 0.8551
en_de Dev loss: 0.8868 r:0.0764
en_zh Dev loss: 0.8069 r:0.1674
ro_en Dev loss: 0.7915 r:0.4744
et_en Dev loss: 0.6630 r:0.4384
si_en Dev loss: 0.7844 r:0.4039
ne_en Dev loss: 0.6954 r:0.4558
ru_en Dev loss: 0.7118 r:0.5350
Current avg r:0.3645 Best avg r: 0.4254
16:29:42,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:55,156 root INFO 
id:en_de cur r: 0.0985 best r: 0.0985
16:30:08,21 root INFO 
id:en_zh cur r: 0.2759 best r: 0.2759
16:30:33,820 root INFO 
id:et_en cur r: 0.4806 best r: 0.4806
16:30:46,733 root INFO 
id:si_en cur r: 0.4206 best r: 0.4206
16:31:12,555 root INFO 
id:ne_en cur r: 0.5039 best r: 0.5039
16:31:25,410 root INFO 
id:ru_en cur r: 0.5977 best r: 0.5977
16:31:25,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:32:55,522 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:32:55,528 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:32:55,532 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:32:55,537 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:32:55,542 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:32:55,548 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:32:55,552 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:33:08,473 root INFO Epoch 0 Global steps: 10500 Train loss: 0.7951
en_de Dev loss: 0.9088 r:0.1087
en_zh Dev loss: 0.7926 r:0.2755
ro_en Dev loss: 0.7263 r:0.5418
et_en Dev loss: 0.5930 r:0.5192
si_en Dev loss: 0.7270 r:0.4658
ne_en Dev loss: 0.5967 r:0.5358
ru_en Dev loss: 0.5695 r:0.6387
Current avg r:0.4408 Best avg r: 0.4408
16:37:39,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:04,764 root INFO 
id:en_zh cur r: 0.3045 best r: 0.3045
16:38:17,634 root INFO 
id:ro_en cur r: 0.6213 best r: 0.6213
16:38:30,555 root INFO 
id:et_en cur r: 0.5725 best r: 0.5725
16:38:43,462 root INFO 
id:si_en cur r: 0.4577 best r: 0.4577
16:39:09,289 root INFO 
id:ne_en cur r: 0.5450 best r: 0.5450
16:39:22,135 root INFO 
id:ru_en cur r: 0.6512 best r: 0.6512
16:39:22,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:52,186 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:40:52,192 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:40:52,197 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:40:52,201 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:40:52,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:40:52,210 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:40:52,214 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:41:05,132 root INFO Epoch 1 Global steps: 11200 Train loss: 0.7700
en_de Dev loss: 0.9346 r:0.1316
en_zh Dev loss: 0.7986 r:0.3108
ro_en Dev loss: 0.5972 r:0.6421
et_en Dev loss: 0.4866 r:0.6118
si_en Dev loss: 0.7262 r:0.4914
ne_en Dev loss: 0.5377 r:0.5882
ru_en Dev loss: 0.5261 r:0.6698
Current avg r:0.4922 Best avg r: 0.4922
16:45:33,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:46,573 root INFO 
id:en_de cur r: 0.1613 best r: 0.1613
16:46:12,319 root INFO 
id:ro_en cur r: 0.6422 best r: 0.6422
16:46:25,199 root INFO 
id:et_en cur r: 0.5862 best r: 0.5862
16:47:03,818 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:33,953 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:48:33,960 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:48:33,964 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:48:33,969 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:48:33,974 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:48:33,979 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:48:33,985 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:48:46,920 root INFO Epoch 1 Global steps: 11900 Train loss: 0.7098
en_de Dev loss: 1.0092 r:0.1537
en_zh Dev loss: 0.8753 r:0.3057
ro_en Dev loss: 0.6397 r:0.6623
et_en Dev loss: 0.5005 r:0.6091
si_en Dev loss: 0.8073 r:0.4942
ne_en Dev loss: 0.5827 r:0.5792
ru_en Dev loss: 0.6036 r:0.6487
Current avg r:0.4933 Best avg r: 0.4933
16:53:15,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:41,250 root INFO 
id:en_zh cur r: 0.3515 best r: 0.3515
16:53:54,141 root INFO 
id:ro_en cur r: 0.6997 best r: 0.6997
16:54:07,40 root INFO 
id:et_en cur r: 0.6542 best r: 0.6542
16:54:19,940 root INFO 
id:si_en cur r: 0.5123 best r: 0.5123
16:54:45,758 root INFO 
id:ne_en cur r: 0.6176 best r: 0.6176
16:54:58,608 root INFO 
id:ru_en cur r: 0.7003 best r: 0.7003
16:54:58,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:28,727 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:56:28,733 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:56:28,739 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:56:28,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:56:28,748 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:56:28,753 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:56:28,757 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:56:41,671 root INFO Epoch 1 Global steps: 12600 Train loss: 0.6467
en_de Dev loss: 0.9877 r:0.1625
en_zh Dev loss: 0.8136 r:0.3443
ro_en Dev loss: 0.4939 r:0.7044
et_en Dev loss: 0.4100 r:0.6635
si_en Dev loss: 0.7144 r:0.5435
ne_en Dev loss: 0.4757 r:0.6429
ru_en Dev loss: 0.5015 r:0.7079
Current avg r:0.5384 Best avg r: 0.5384
17:01:10,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:35,993 root INFO 
id:en_zh cur r: 0.3695 best r: 0.3695
17:01:48,860 root INFO 
id:ro_en cur r: 0.7224 best r: 0.7224
17:02:01,742 root INFO 
id:et_en cur r: 0.6822 best r: 0.6822
17:02:14,653 root INFO 
id:si_en cur r: 0.5451 best r: 0.5451
17:02:40,424 root INFO 
id:ne_en cur r: 0.6668 best r: 0.6668
17:02:53,273 root INFO 
id:ru_en cur r: 0.7344 best r: 0.7344
17:02:53,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:23,354 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:04:23,360 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:04:23,366 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:04:23,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:04:23,375 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:04:23,381 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:04:23,387 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:04:36,282 root INFO Epoch 1 Global steps: 13300 Train loss: 0.6059
en_de Dev loss: 0.9542 r:0.1747
en_zh Dev loss: 0.7605 r:0.3641
ro_en Dev loss: 0.4515 r:0.7245
et_en Dev loss: 0.3838 r:0.6855
si_en Dev loss: 0.6665 r:0.5602
ne_en Dev loss: 0.4333 r:0.6776
ru_en Dev loss: 0.4403 r:0.7334
Current avg r:0.5600 Best avg r: 0.5600
17:09:04,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:17,682 root INFO 
id:en_de cur r: 0.1818 best r: 0.1818
17:09:30,521 root INFO 
id:en_zh cur r: 0.3735 best r: 0.3735
17:09:43,389 root INFO 
id:ro_en cur r: 0.7355 best r: 0.7355
17:10:34,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:04,972 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5682
en_de Dev loss: 0.9810 r:0.1715
en_zh Dev loss: 0.7940 r:0.3655
ro_en Dev loss: 0.4509 r:0.7388
et_en Dev loss: 0.3910 r:0.6820
si_en Dev loss: 0.6961 r:0.5543
ne_en Dev loss: 0.4410 r:0.6742
ru_en Dev loss: 0.4760 r:0.7242
Current avg r:0.5587 Best avg r: 0.5600
17:16:33,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:46,346 root INFO 
id:en_de cur r: 0.1863 best r: 0.1863
17:16:59,202 root INFO 
id:en_zh cur r: 0.3929 best r: 0.3929
17:17:12,89 root INFO 
id:ro_en cur r: 0.7512 best r: 0.7512
17:17:24,992 root INFO 
id:et_en cur r: 0.6913 best r: 0.6913
17:18:03,706 root INFO 
id:ne_en cur r: 0.6955 best r: 0.6955
17:18:16,554 root INFO 
id:ru_en cur r: 0.7354 best r: 0.7354
17:18:16,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:46,688 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:19:46,695 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:19:46,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:19:46,705 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:19:46,710 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:19:46,717 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:19:46,721 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:19:59,623 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5588
en_de Dev loss: 0.9855 r:0.1911
en_zh Dev loss: 0.8036 r:0.3891
ro_en Dev loss: 0.4315 r:0.7437
et_en Dev loss: 0.3772 r:0.6911
si_en Dev loss: 0.7513 r:0.5544
ne_en Dev loss: 0.4679 r:0.6886
ru_en Dev loss: 0.4602 r:0.7361
Current avg r:0.5706 Best avg r: 0.5706
17:24:28,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:53,826 root INFO 
id:en_zh cur r: 0.3954 best r: 0.3954
17:25:06,732 root INFO 
id:ro_en cur r: 0.7668 best r: 0.7668
17:25:19,621 root INFO 
id:et_en cur r: 0.6933 best r: 0.6933
17:25:32,507 root INFO 
id:si_en cur r: 0.5621 best r: 0.5621
17:25:58,315 root INFO 
id:ne_en cur r: 0.7007 best r: 0.7007
17:26:11,155 root INFO 
id:ru_en cur r: 0.7363 best r: 0.7363
17:26:11,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:41,237 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:27:41,243 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:27:41,247 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:27:41,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:27:41,256 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:27:41,261 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:27:41,265 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:27:54,146 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5514
en_de Dev loss: 0.9644 r:0.1819
en_zh Dev loss: 0.7810 r:0.3934
ro_en Dev loss: 0.4197 r:0.7639
et_en Dev loss: 0.3827 r:0.6926
si_en Dev loss: 0.7655 r:0.5637
ne_en Dev loss: 0.4926 r:0.6942
ru_en Dev loss: 0.5048 r:0.7317
Current avg r:0.5745 Best avg r: 0.5745
17:32:22,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:48,435 root INFO 
id:en_zh cur r: 0.4005 best r: 0.4005
17:33:01,308 root INFO 
id:ro_en cur r: 0.7809 best r: 0.7809
17:33:14,189 root INFO 
id:et_en cur r: 0.6994 best r: 0.6994
17:33:27,98 root INFO 
id:si_en cur r: 0.5650 best r: 0.5650
17:33:52,875 root INFO 
id:ne_en cur r: 0.7142 best r: 0.7142
17:34:05,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:35,782 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:35:35,788 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:35:35,794 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:35:35,798 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:35:35,803 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:35:35,808 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:35:35,813 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:35:48,698 root INFO Epoch 1 Global steps: 16100 Train loss: 0.5176
en_de Dev loss: 0.9542 r:0.1708
en_zh Dev loss: 0.7748 r:0.3955
ro_en Dev loss: 0.3910 r:0.7781
et_en Dev loss: 0.3723 r:0.6987
si_en Dev loss: 0.7222 r:0.5724
ne_en Dev loss: 0.4701 r:0.7073
ru_en Dev loss: 0.4838 r:0.7299
Current avg r:0.5790 Best avg r: 0.5790
17:40:17,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:30,158 root INFO 
id:en_de cur r: 0.1968 best r: 0.1968
17:40:43,35 root INFO 
id:en_zh cur r: 0.4148 best r: 0.4148
17:40:55,927 root INFO 
id:ro_en cur r: 0.7812 best r: 0.7812
17:41:08,827 root INFO 
id:et_en cur r: 0.7059 best r: 0.7059
17:41:21,729 root INFO 
id:si_en cur r: 0.5896 best r: 0.5896
17:41:47,544 root INFO 
id:ne_en cur r: 0.7236 best r: 0.7236
17:42:00,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:30,514 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:43:30,521 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:43:30,527 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:43:30,531 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:43:30,535 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:43:30,541 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:43:30,546 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:43:43,447 root INFO Epoch 1 Global steps: 16800 Train loss: 0.5018
en_de Dev loss: 0.9106 r:0.1913
en_zh Dev loss: 0.7023 r:0.4095
ro_en Dev loss: 0.3500 r:0.7802
et_en Dev loss: 0.3574 r:0.7071
si_en Dev loss: 0.5944 r:0.5928
ne_en Dev loss: 0.4103 r:0.7246
ru_en Dev loss: 0.4209 r:0.7185
Current avg r:0.5891 Best avg r: 0.5891
17:48:11,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:50,576 root INFO 
id:ro_en cur r: 0.7885 best r: 0.7885
17:49:42,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:12,91 root INFO Epoch 1 Global steps: 17500 Train loss: 0.5116
en_de Dev loss: 0.9327 r:0.1813
en_zh Dev loss: 0.7550 r:0.3957
ro_en Dev loss: 0.3489 r:0.7871
et_en Dev loss: 0.3615 r:0.7006
si_en Dev loss: 0.6829 r:0.5780
ne_en Dev loss: 0.5092 r:0.7089
ru_en Dev loss: 0.4510 r:0.7262
Current avg r:0.5826 Best avg r: 0.5891
17:55:40,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:53,551 root INFO 
id:en_de cur r: 0.2116 best r: 0.2116
17:56:06,397 root INFO 
id:en_zh cur r: 0.4299 best r: 0.4299
17:56:19,280 root INFO 
id:ro_en cur r: 0.7944 best r: 0.7944
17:57:10,858 root INFO 
id:ne_en cur r: 0.7253 best r: 0.7253
17:57:23,699 root INFO 
id:ru_en cur r: 0.7391 best r: 0.7391
17:57:23,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:53,763 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:58:53,770 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:58:53,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:58:53,781 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:58:53,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:58:53,791 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:58:53,796 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:59:06,729 root INFO Epoch 1 Global steps: 18200 Train loss: 0.5042
en_de Dev loss: 0.9110 r:0.2056
en_zh Dev loss: 0.7548 r:0.4233
ro_en Dev loss: 0.3630 r:0.7934
et_en Dev loss: 0.3703 r:0.7033
si_en Dev loss: 0.6792 r:0.5916
ne_en Dev loss: 0.5274 r:0.7202
ru_en Dev loss: 0.4606 r:0.7447
Current avg r:0.5974 Best avg r: 0.5974
18:03:35,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:01,104 root INFO 
id:en_zh cur r: 0.4423 best r: 0.4423
18:04:13,995 root INFO 
id:ro_en cur r: 0.8046 best r: 0.8046
18:04:26,901 root INFO 
id:et_en cur r: 0.7081 best r: 0.7081
18:04:39,805 root INFO 
id:si_en cur r: 0.6041 best r: 0.6041
18:05:05,635 root INFO 
id:ne_en cur r: 0.7302 best r: 0.7302
18:05:18,487 root INFO 
id:ru_en cur r: 0.7455 best r: 0.7455
18:05:18,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:48,608 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
18:06:48,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:06:48,619 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:06:48,623 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
18:06:48,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
18:06:48,633 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:06:48,637 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:07:01,540 root INFO Epoch 1 Global steps: 18900 Train loss: 0.5113
en_de Dev loss: 0.8790 r:0.1853
en_zh Dev loss: 0.6676 r:0.4333
ro_en Dev loss: 0.3098 r:0.8028
et_en Dev loss: 0.3541 r:0.7090
si_en Dev loss: 0.5463 r:0.6093
ne_en Dev loss: 0.4469 r:0.7317
ru_en Dev loss: 0.3855 r:0.7540
Current avg r:0.6036 Best avg r: 0.6036
18:11:30,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:00,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:30,261 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4657
en_de Dev loss: 0.9846 r:0.1950
en_zh Dev loss: 0.8208 r:0.4143
ro_en Dev loss: 0.3811 r:0.7928
et_en Dev loss: 0.3805 r:0.7056
si_en Dev loss: 0.8758 r:0.5820
ne_en Dev loss: 0.7103 r:0.7108
ru_en Dev loss: 0.4744 r:0.7460
Current avg r:0.5923 Best avg r: 0.6036
18:18:58,915 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:37,536 root INFO 
id:ro_en cur r: 0.8068 best r: 0.8068
18:20:29,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:59,125 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4858
en_de Dev loss: 0.8870 r:0.2022
en_zh Dev loss: 0.7089 r:0.4247
ro_en Dev loss: 0.3155 r:0.8028
et_en Dev loss: 0.3587 r:0.7067
si_en Dev loss: 0.6323 r:0.5956
ne_en Dev loss: 0.5406 r:0.7235
ru_en Dev loss: 0.4034 r:0.7501
Current avg r:0.6008 Best avg r: 0.6036
18:26:27,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:40,631 root INFO 
id:en_de cur r: 0.2161 best r: 0.2161
18:27:06,378 root INFO 
id:ro_en cur r: 0.8072 best r: 0.8072
18:27:19,291 root INFO 
id:et_en cur r: 0.7142 best r: 0.7142
18:27:57,943 root INFO 
id:ru_en cur r: 0.7508 best r: 0.7508
18:27:57,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:28,82 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
18:29:28,96 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:29:28,103 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:29:28,108 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
18:29:28,114 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
18:29:28,120 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:29:28,124 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:29:41,37 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4495
en_de Dev loss: 0.8692 r:0.2115
en_zh Dev loss: 0.6750 r:0.4380
ro_en Dev loss: 0.3088 r:0.8040
et_en Dev loss: 0.3516 r:0.7154
si_en Dev loss: 0.6103 r:0.5940
ne_en Dev loss: 0.4968 r:0.7229
ru_en Dev loss: 0.3691 r:0.7591
Current avg r:0.6064 Best avg r: 0.6064
18:34:11,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:24,103 root INFO 
id:en_de cur r: 0.2300 best r: 0.2300
18:35:41,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:11,393 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4483
en_de Dev loss: 0.8748 r:0.2194
en_zh Dev loss: 0.7195 r:0.4380
ro_en Dev loss: 0.3222 r:0.7975
et_en Dev loss: 0.3597 r:0.7048
si_en Dev loss: 0.6390 r:0.5970
ne_en Dev loss: 0.5764 r:0.7219
ru_en Dev loss: 0.3919 r:0.7457
Current avg r:0.6035 Best avg r: 0.6064
18:41:40,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:52,970 root INFO 
id:en_de cur r: 0.2357 best r: 0.2357
18:43:10,262 root INFO 
id:ne_en cur r: 0.7307 best r: 0.7307
18:43:23,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:53,166 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4403
en_de Dev loss: 0.9205 r:0.2232
en_zh Dev loss: 0.7716 r:0.4304
ro_en Dev loss: 0.3493 r:0.8012
et_en Dev loss: 0.3692 r:0.7070
si_en Dev loss: 0.6846 r:0.6001
ne_en Dev loss: 0.6164 r:0.7298
ru_en Dev loss: 0.4736 r:0.7290
Current avg r:0.6030 Best avg r: 0.6064
18:49:21,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:00,457 root INFO 
id:ro_en cur r: 0.8120 best r: 0.8120
18:50:13,371 root INFO 
id:et_en cur r: 0.7156 best r: 0.7156
18:50:26,275 root INFO 
id:si_en cur r: 0.6107 best r: 0.6107
18:50:52,84 root INFO 
id:ne_en cur r: 0.7384 best r: 0.7384
18:51:04,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:35,123 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
18:52:35,129 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:52:35,135 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:52:35,139 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
18:52:35,144 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
18:52:35,149 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:52:35,153 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:52:48,58 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4322
en_de Dev loss: 0.8661 r:0.2186
en_zh Dev loss: 0.6983 r:0.4292
ro_en Dev loss: 0.3098 r:0.8070
et_en Dev loss: 0.3654 r:0.7172
si_en Dev loss: 0.5533 r:0.6150
ne_en Dev loss: 0.4833 r:0.7373
ru_en Dev loss: 0.3764 r:0.7556
Current avg r:0.6114 Best avg r: 0.6114
18:57:16,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:46,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:16,773 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4216
en_de Dev loss: 0.9182 r:0.2121
en_zh Dev loss: 0.7849 r:0.4300
ro_en Dev loss: 0.3822 r:0.7937
et_en Dev loss: 0.3970 r:0.6972
si_en Dev loss: 0.8186 r:0.5854
ne_en Dev loss: 0.7596 r:0.7250
ru_en Dev loss: 0.5110 r:0.7256
Current avg r:0.5956 Best avg r: 0.6114
19:04:45,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:15,560 root INFO 
id:ne_en cur r: 0.7413 best r: 0.7413
19:06:28,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:58,474 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4478
en_de Dev loss: 0.9056 r:0.2084
en_zh Dev loss: 0.7658 r:0.4338
ro_en Dev loss: 0.3302 r:0.8067
et_en Dev loss: 0.3528 r:0.7135
si_en Dev loss: 0.6607 r:0.6121
ne_en Dev loss: 0.5699 r:0.7416
ru_en Dev loss: 0.4347 r:0.7453
Current avg r:0.6088 Best avg r: 0.6114
19:12:27,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:52,786 root INFO 
id:en_zh cur r: 0.4425 best r: 0.4425
19:13:05,670 root INFO 
id:ro_en cur r: 0.8168 best r: 0.8168
19:13:31,493 root INFO 
id:si_en cur r: 0.6150 best r: 0.6150
19:13:57,254 root INFO 
id:ru_en cur r: 0.7524 best r: 0.7524
19:13:57,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:27,364 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
19:15:27,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
19:15:27,376 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
19:15:27,381 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
19:15:27,386 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
19:15:27,390 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
19:15:27,394 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
19:15:40,294 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4051
en_de Dev loss: 0.8900 r:0.2167
en_zh Dev loss: 0.7351 r:0.4392
ro_en Dev loss: 0.3332 r:0.8091
et_en Dev loss: 0.3649 r:0.7111
si_en Dev loss: 0.6661 r:0.6167
ne_en Dev loss: 0.5476 r:0.7361
ru_en Dev loss: 0.4205 r:0.7531
Current avg r:0.6117 Best avg r: 0.6117
19:20:08,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:21,712 root INFO 
id:en_de cur r: 0.2440 best r: 0.2440
19:20:34,568 root INFO 
id:en_zh cur r: 0.4443 best r: 0.4443
19:21:13,256 root INFO 
id:si_en cur r: 0.6161 best r: 0.6161
19:21:38,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:09,20 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4192
en_de Dev loss: 0.8665 r:0.2296
en_zh Dev loss: 0.7129 r:0.4398
ro_en Dev loss: 0.3107 r:0.8108
et_en Dev loss: 0.3644 r:0.7061
si_en Dev loss: 0.6325 r:0.6148
ne_en Dev loss: 0.5198 r:0.7332
ru_en Dev loss: 0.4601 r:0.7276
Current avg r:0.6088 Best avg r: 0.6117
19:27:37,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:03,211 root INFO 
id:en_zh cur r: 0.4499 best r: 0.4499
19:29:07,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:37,625 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
19:30:37,632 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
19:30:37,639 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
19:30:37,646 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
19:30:37,652 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
19:30:37,659 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
19:30:37,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
19:30:50,567 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3907
en_de Dev loss: 0.8862 r:0.2191
en_zh Dev loss: 0.7110 r:0.4456
ro_en Dev loss: 0.3064 r:0.8097
et_en Dev loss: 0.3535 r:0.7150
si_en Dev loss: 0.6105 r:0.6136
ne_en Dev loss: 0.4874 r:0.7387
ru_en Dev loss: 0.3933 r:0.7512
Current avg r:0.6133 Best avg r: 0.6133
19:35:19,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:44,759 root INFO 
id:en_zh cur r: 0.4624 best r: 0.4624
19:35:57,666 root INFO 
id:ro_en cur r: 0.8184 best r: 0.8184
19:36:49,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:19,327 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
19:38:19,333 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
19:38:19,338 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
19:38:19,342 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
19:38:19,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
19:38:19,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
19:38:19,358 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
19:38:32,261 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4421
en_de Dev loss: 0.8770 r:0.2249
en_zh Dev loss: 0.7163 r:0.4564
ro_en Dev loss: 0.3076 r:0.8133
et_en Dev loss: 0.3574 r:0.7119
si_en Dev loss: 0.6121 r:0.6149
ne_en Dev loss: 0.5052 r:0.7391
ru_en Dev loss: 0.4473 r:0.7383
Current avg r:0.6141 Best avg r: 0.6141
19:43:00,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:26,560 root INFO 
id:en_zh cur r: 0.4703 best r: 0.4703
19:43:39,443 root INFO 
id:ro_en cur r: 0.8193 best r: 0.8193
19:44:05,247 root INFO 
id:si_en cur r: 0.6172 best r: 0.6172
19:44:30,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:46:01,122 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4142
en_de Dev loss: 0.8864 r:0.2211
en_zh Dev loss: 0.7339 r:0.4647
ro_en Dev loss: 0.3604 r:0.8145
et_en Dev loss: 0.3907 r:0.7010
si_en Dev loss: 0.6999 r:0.6131
ne_en Dev loss: 0.6358 r:0.7313
ru_en Dev loss: 0.4641 r:0.7486
Current avg r:0.6135 Best avg r: 0.6141
19:50:29,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:08,274 root INFO 
id:ro_en cur r: 0.8236 best r: 0.8236
19:51:34,87 root INFO 
id:si_en cur r: 0.6181 best r: 0.6181
19:51:59,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:29,933 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
19:53:29,939 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
19:53:29,944 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
19:53:29,948 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
19:53:29,952 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
19:53:29,957 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
19:53:29,961 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
19:53:42,862 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4192
en_de Dev loss: 0.8932 r:0.2202
en_zh Dev loss: 0.7322 r:0.4518
ro_en Dev loss: 0.3568 r:0.8169
et_en Dev loss: 0.3825 r:0.7059
si_en Dev loss: 0.6930 r:0.6170
ne_en Dev loss: 0.5858 r:0.7383
ru_en Dev loss: 0.4719 r:0.7525
Current avg r:0.6147 Best avg r: 0.6147
19:58:11,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:41,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:01:11,549 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
20:01:11,555 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:01:11,559 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:01:11,563 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
20:01:11,568 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
20:01:11,574 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
20:01:11,578 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
20:01:24,460 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3875
en_de Dev loss: 0.8807 r:0.2284
en_zh Dev loss: 0.7576 r:0.4531
ro_en Dev loss: 0.3283 r:0.8142
et_en Dev loss: 0.3749 r:0.7077
si_en Dev loss: 0.6455 r:0.6131
ne_en Dev loss: 0.5778 r:0.7393
ru_en Dev loss: 0.4468 r:0.7490
Current avg r:0.6150 Best avg r: 0.6150
20:05:53,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:31,655 root INFO 
id:ro_en cur r: 0.8238 best r: 0.8238
20:07:23,213 root INFO 
id:ru_en cur r: 0.7541 best r: 0.7541
20:07:23,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:53,332 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3980
en_de Dev loss: 0.8661 r:0.2149
en_zh Dev loss: 0.7381 r:0.4601
ro_en Dev loss: 0.3378 r:0.8154
et_en Dev loss: 0.3955 r:0.7066
si_en Dev loss: 0.7991 r:0.6115
ne_en Dev loss: 0.6134 r:0.7367
ru_en Dev loss: 0.4381 r:0.7535
Current avg r:0.6141 Best avg r: 0.6150
20:13:21,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:00,444 root INFO 
id:ro_en cur r: 0.8273 best r: 0.8273
20:14:52,21 root INFO 
id:ne_en cur r: 0.7441 best r: 0.7441
20:15:04,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:34,910 root INFO Epoch 2 Global steps: 30800 Train loss: 0.4082
en_de Dev loss: 0.8650 r:0.2206
en_zh Dev loss: 0.7427 r:0.4522
ro_en Dev loss: 0.3480 r:0.8212
et_en Dev loss: 0.3878 r:0.7051
si_en Dev loss: 0.7626 r:0.6120
ne_en Dev loss: 0.7271 r:0.7423
ru_en Dev loss: 0.5059 r:0.7279
Current avg r:0.6116 Best avg r: 0.6150
20:21:03,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:41,984 root INFO 
id:ro_en cur r: 0.8345 best r: 0.8345
20:21:54,876 root INFO 
id:et_en cur r: 0.7178 best r: 0.7178
20:22:07,807 root INFO 
id:si_en cur r: 0.6188 best r: 0.6188
20:22:33,591 root INFO 
id:ne_en cur r: 0.7535 best r: 0.7535
20:22:46,467 root INFO 
id:ru_en cur r: 0.7625 best r: 0.7625
20:22:46,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:16,606 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
20:24:16,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:24:16,617 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:24:16,621 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
20:24:16,625 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
20:24:16,633 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
20:24:16,638 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
20:24:29,518 root INFO Epoch 2 Global steps: 31500 Train loss: 0.4173
en_de Dev loss: 0.8563 r:0.2302
en_zh Dev loss: 0.6917 r:0.4592
ro_en Dev loss: 0.2943 r:0.8268
et_en Dev loss: 0.3559 r:0.7203
si_en Dev loss: 0.5986 r:0.6215
ne_en Dev loss: 0.4607 r:0.7527
ru_en Dev loss: 0.3812 r:0.7655
Current avg r:0.6252 Best avg r: 0.6252
20:28:59,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:30,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:00,137 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3663
en_de Dev loss: 0.8597 r:0.2261
en_zh Dev loss: 0.7345 r:0.4430
ro_en Dev loss: 0.3294 r:0.8154
et_en Dev loss: 0.4014 r:0.7038
si_en Dev loss: 0.6346 r:0.6094
ne_en Dev loss: 0.5289 r:0.7417
ru_en Dev loss: 0.4115 r:0.7468
Current avg r:0.6123 Best avg r: 0.6252
20:36:28,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:41,550 root INFO 
id:en_de cur r: 0.2609 best r: 0.2609
20:37:58,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:28,881 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3772
en_de Dev loss: 0.8611 r:0.2485
en_zh Dev loss: 0.7461 r:0.4399
ro_en Dev loss: 0.3402 r:0.8126
et_en Dev loss: 0.3780 r:0.6982
si_en Dev loss: 0.7968 r:0.5934
ne_en Dev loss: 0.6380 r:0.7329
ru_en Dev loss: 0.4820 r:0.7248
Current avg r:0.6072 Best avg r: 0.6252
20:43:57,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:10,243 root INFO 
id:en_de cur r: 0.2692 best r: 0.2692
20:45:27,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:57,648 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3699
en_de Dev loss: 0.8427 r:0.2564
en_zh Dev loss: 0.7156 r:0.4366
ro_en Dev loss: 0.2894 r:0.8236
et_en Dev loss: 0.3693 r:0.7136
si_en Dev loss: 0.5982 r:0.6134
ne_en Dev loss: 0.4433 r:0.7382
ru_en Dev loss: 0.3786 r:0.7611
Current avg r:0.6204 Best avg r: 0.6252
20:51:26,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:04,733 root INFO 
id:ro_en cur r: 0.8346 best r: 0.8346
20:52:56,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:26,384 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3571
en_de Dev loss: 0.8651 r:0.2287
en_zh Dev loss: 0.7606 r:0.4278
ro_en Dev loss: 0.2959 r:0.8248
et_en Dev loss: 0.3711 r:0.7110
si_en Dev loss: 0.6308 r:0.6182
ne_en Dev loss: 0.5037 r:0.7365
ru_en Dev loss: 0.4415 r:0.7457
Current avg r:0.6132 Best avg r: 0.6252
20:58:54,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:24,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:54,952 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3554
en_de Dev loss: 0.8812 r:0.2426
en_zh Dev loss: 0.7698 r:0.4249
ro_en Dev loss: 0.3500 r:0.8173
et_en Dev loss: 0.3878 r:0.7019
si_en Dev loss: 0.7032 r:0.6088
ne_en Dev loss: 0.6072 r:0.7374
ru_en Dev loss: 0.4806 r:0.7245
Current avg r:0.6082 Best avg r: 0.6252
21:06:23,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:53,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:23,634 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3458
en_de Dev loss: 0.8978 r:0.2340
en_zh Dev loss: 0.8266 r:0.4181
ro_en Dev loss: 0.3559 r:0.8219
et_en Dev loss: 0.3742 r:0.7083
si_en Dev loss: 0.7878 r:0.6054
ne_en Dev loss: 0.6861 r:0.7230
ru_en Dev loss: 0.4934 r:0.7277
Current avg r:0.6055 Best avg r: 0.6252
21:13:52,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:22,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:52,537 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3432
en_de Dev loss: 0.8534 r:0.2307
en_zh Dev loss: 0.7469 r:0.4262
ro_en Dev loss: 0.3256 r:0.8146
et_en Dev loss: 0.3845 r:0.6950
si_en Dev loss: 0.7483 r:0.5908
ne_en Dev loss: 0.6268 r:0.7289
ru_en Dev loss: 0.4765 r:0.7034
Current avg r:0.5985 Best avg r: 0.6252
21:21:21,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:59,688 root INFO 
id:ro_en cur r: 0.8352 best r: 0.8352
21:22:51,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:21,207 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3451
en_de Dev loss: 0.8613 r:0.2332
en_zh Dev loss: 0.7428 r:0.4534
ro_en Dev loss: 0.3187 r:0.8303
et_en Dev loss: 0.3914 r:0.7111
si_en Dev loss: 0.6407 r:0.6159
ne_en Dev loss: 0.5231 r:0.7378
ru_en Dev loss: 0.4380 r:0.7459
Current avg r:0.6182 Best avg r: 0.6252
21:28:49,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:19,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:49,853 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3426
en_de Dev loss: 0.8712 r:0.2313
en_zh Dev loss: 0.7996 r:0.4302
ro_en Dev loss: 0.3306 r:0.8255
et_en Dev loss: 0.3813 r:0.7085
si_en Dev loss: 0.6816 r:0.6088
ne_en Dev loss: 0.5847 r:0.7296
ru_en Dev loss: 0.4822 r:0.7308
Current avg r:0.6092 Best avg r: 0.6252
21:36:18,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:48,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:18,656 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3585
en_de Dev loss: 0.8763 r:0.2314
en_zh Dev loss: 0.7922 r:0.4366
ro_en Dev loss: 0.3180 r:0.8260
et_en Dev loss: 0.3905 r:0.7053
si_en Dev loss: 0.6612 r:0.6097
ne_en Dev loss: 0.5479 r:0.7289
ru_en Dev loss: 0.4502 r:0.7385
Current avg r:0.6109 Best avg r: 0.6252
21:43:47,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:17,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:47,403 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3470
en_de Dev loss: 0.8667 r:0.2434
en_zh Dev loss: 0.7555 r:0.4560
ro_en Dev loss: 0.3230 r:0.8234
et_en Dev loss: 0.3869 r:0.7031
si_en Dev loss: 0.7018 r:0.6062
ne_en Dev loss: 0.5253 r:0.7345
ru_en Dev loss: 0.4589 r:0.7323
Current avg r:0.6141 Best avg r: 0.6252
21:51:15,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:46,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:16,79 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3466
en_de Dev loss: 0.8599 r:0.2365
en_zh Dev loss: 0.7448 r:0.4461
ro_en Dev loss: 0.3075 r:0.8280
et_en Dev loss: 0.3771 r:0.7076
si_en Dev loss: 0.6468 r:0.6138
ne_en Dev loss: 0.4961 r:0.7444
ru_en Dev loss: 0.4558 r:0.7334
Current avg r:0.6157 Best avg r: 0.6252
21:58:44,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:14,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:44,785 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3515
en_de Dev loss: 0.8479 r:0.2515
en_zh Dev loss: 0.7331 r:0.4473
ro_en Dev loss: 0.3169 r:0.8274
et_en Dev loss: 0.3953 r:0.7117
si_en Dev loss: 0.6555 r:0.6152
ne_en Dev loss: 0.5276 r:0.7393
ru_en Dev loss: 0.4489 r:0.7347
Current avg r:0.6182 Best avg r: 0.6252
22:06:13,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:07:43,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:13,674 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3237
en_de Dev loss: 0.8569 r:0.2306
en_zh Dev loss: 0.7349 r:0.4497
ro_en Dev loss: 0.3257 r:0.8213
et_en Dev loss: 0.4065 r:0.6994
si_en Dev loss: 0.6563 r:0.6082
ne_en Dev loss: 0.5066 r:0.7365
ru_en Dev loss: 0.4265 r:0.7377
Current avg r:0.6119 Best avg r: 0.6252
22:13:42,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:12,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:16:42,502 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3330
en_de Dev loss: 0.8634 r:0.2197
en_zh Dev loss: 0.7496 r:0.4487
ro_en Dev loss: 0.3201 r:0.8261
et_en Dev loss: 0.3827 r:0.7082
si_en Dev loss: 0.6642 r:0.6111
ne_en Dev loss: 0.4869 r:0.7453
ru_en Dev loss: 0.4622 r:0.7250
Current avg r:0.6120 Best avg r: 0.6252
22:21:12,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:42,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:12,947 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3097
en_de Dev loss: 0.8651 r:0.2073
en_zh Dev loss: 0.7536 r:0.4434
ro_en Dev loss: 0.3199 r:0.8258
et_en Dev loss: 0.3862 r:0.7007
si_en Dev loss: 0.7351 r:0.6056
ne_en Dev loss: 0.5217 r:0.7347
ru_en Dev loss: 0.4656 r:0.7275
Current avg r:0.6064 Best avg r: 0.6252
22:28:41,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:11,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:41,780 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2775
en_de Dev loss: 0.8749 r:0.2230
en_zh Dev loss: 0.7657 r:0.4512
ro_en Dev loss: 0.3359 r:0.8218
et_en Dev loss: 0.3833 r:0.7037
si_en Dev loss: 0.7847 r:0.5988
ne_en Dev loss: 0.5264 r:0.7346
ru_en Dev loss: 0.4872 r:0.7292
Current avg r:0.6089 Best avg r: 0.6252
22:36:10,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:40,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:10,572 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2943
en_de Dev loss: 0.8691 r:0.2251
en_zh Dev loss: 0.7970 r:0.4383
ro_en Dev loss: 0.3361 r:0.8231
et_en Dev loss: 0.3927 r:0.7015
si_en Dev loss: 0.7505 r:0.5967
ne_en Dev loss: 0.5190 r:0.7345
ru_en Dev loss: 0.5112 r:0.7151
Current avg r:0.6049 Best avg r: 0.6252
22:43:39,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:45:09,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:39,255 root INFO Epoch 4 Global steps: 44800 Train loss: 0.3209
en_de Dev loss: 0.8647 r:0.2269
en_zh Dev loss: 0.7715 r:0.4396
ro_en Dev loss: 0.3389 r:0.8176
et_en Dev loss: 0.4021 r:0.6909
si_en Dev loss: 0.7619 r:0.5905
ne_en Dev loss: 0.5624 r:0.7285
ru_en Dev loss: 0.5653 r:0.6834
Current avg r:0.5968 Best avg r: 0.6252
22:51:07,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:37,936 root INFO 
id:ru_en cur r: 0.7630 best r: 0.7630
22:52:37,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:08,61 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2863
en_de Dev loss: 0.8648 r:0.2162
en_zh Dev loss: 0.7551 r:0.4622
ro_en Dev loss: 0.3201 r:0.8271
et_en Dev loss: 0.4092 r:0.7039
si_en Dev loss: 0.6268 r:0.6169
ne_en Dev loss: 0.4531 r:0.7389
ru_en Dev loss: 0.4131 r:0.7541
Current avg r:0.6171 Best avg r: 0.6252
22:58:36,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:00:06,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:36,772 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2993
en_de Dev loss: 0.8844 r:0.2187
en_zh Dev loss: 0.8582 r:0.4384
ro_en Dev loss: 0.3691 r:0.8217
et_en Dev loss: 0.4365 r:0.6922
si_en Dev loss: 0.8097 r:0.5957
ne_en Dev loss: 0.5924 r:0.7284
ru_en Dev loss: 0.5342 r:0.7172
Current avg r:0.6017 Best avg r: 0.6252
23:06:05,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:35,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:09:05,538 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2844
en_de Dev loss: 0.9005 r:0.2370
en_zh Dev loss: 0.8683 r:0.4208
ro_en Dev loss: 0.4017 r:0.8115
et_en Dev loss: 0.4201 r:0.6856
si_en Dev loss: 0.8541 r:0.5824
ne_en Dev loss: 0.6220 r:0.7256
ru_en Dev loss: 0.5695 r:0.6999
Current avg r:0.5947 Best avg r: 0.6252
23:13:33,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:04,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:34,222 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2943
en_de Dev loss: 0.8906 r:0.2049
en_zh Dev loss: 0.8383 r:0.4502
ro_en Dev loss: 0.3776 r:0.8267
et_en Dev loss: 0.4193 r:0.6992
si_en Dev loss: 0.8213 r:0.6007
ne_en Dev loss: 0.6052 r:0.7324
ru_en Dev loss: 0.5356 r:0.7206
Current avg r:0.6050 Best avg r: 0.6252
23:21:02,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:32,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:24:03,68 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2934
en_de Dev loss: 0.8998 r:0.2183
en_zh Dev loss: 0.8693 r:0.4207
ro_en Dev loss: 0.3768 r:0.8250
et_en Dev loss: 0.4245 r:0.6902
si_en Dev loss: 0.8358 r:0.5905
ne_en Dev loss: 0.5918 r:0.7302
ru_en Dev loss: 0.5109 r:0.7336
Current avg r:0.6012 Best avg r: 0.6252
23:28:31,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:10,142 root INFO 
id:ro_en cur r: 0.8375 best r: 0.8375
23:30:01,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:31,762 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2992
en_de Dev loss: 0.8769 r:0.2199
en_zh Dev loss: 0.7951 r:0.4405
ro_en Dev loss: 0.3096 r:0.8327
et_en Dev loss: 0.3810 r:0.7089
si_en Dev loss: 0.7214 r:0.6031
ne_en Dev loss: 0.5163 r:0.7313
ru_en Dev loss: 0.4297 r:0.7592
Current avg r:0.6137 Best avg r: 0.6252
23:36:00,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:30,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:00,388 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2935
en_de Dev loss: 0.8866 r:0.2152
en_zh Dev loss: 0.8129 r:0.4395
ro_en Dev loss: 0.3470 r:0.8281
et_en Dev loss: 0.4167 r:0.7066
si_en Dev loss: 0.7023 r:0.6030
ne_en Dev loss: 0.4865 r:0.7425
ru_en Dev loss: 0.4601 r:0.7522
Current avg r:0.6124 Best avg r: 0.6252
23:43:28,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:59,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:29,313 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2718
en_de Dev loss: 0.8847 r:0.1990
en_zh Dev loss: 0.8233 r:0.4266
ro_en Dev loss: 0.3245 r:0.8272
et_en Dev loss: 0.4036 r:0.6930
si_en Dev loss: 0.7697 r:0.5943
ne_en Dev loss: 0.5599 r:0.7325
ru_en Dev loss: 0.4645 r:0.7333
Current avg r:0.6009 Best avg r: 0.6252
23:50:57,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:27,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:57,902 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2911
en_de Dev loss: 0.8928 r:0.1990
en_zh Dev loss: 0.7903 r:0.4472
ro_en Dev loss: 0.3280 r:0.8292
et_en Dev loss: 0.3985 r:0.7028
si_en Dev loss: 0.7438 r:0.5990
ne_en Dev loss: 0.5033 r:0.7406
ru_en Dev loss: 0.4512 r:0.7450
Current avg r:0.6090 Best avg r: 0.6252
23:58:26,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:56,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:26,467 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2958
en_de Dev loss: 0.8755 r:0.2063
en_zh Dev loss: 0.7603 r:0.4572
ro_en Dev loss: 0.3273 r:0.8246
et_en Dev loss: 0.4033 r:0.6977
si_en Dev loss: 0.7637 r:0.5952
ne_en Dev loss: 0.5280 r:0.7359
ru_en Dev loss: 0.4491 r:0.7362
Current avg r:0.6076 Best avg r: 0.6252
00:05:54,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:25,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:55,130 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2802
en_de Dev loss: 0.8650 r:0.2314
en_zh Dev loss: 0.8060 r:0.4399
ro_en Dev loss: 0.3334 r:0.8214
et_en Dev loss: 0.4139 r:0.6929
si_en Dev loss: 0.8264 r:0.5865
ne_en Dev loss: 0.5296 r:0.7337
ru_en Dev loss: 0.5133 r:0.7131
Current avg r:0.6027 Best avg r: 0.6252
00:13:25,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:55,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:16:25,672 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2407
en_de Dev loss: 0.8891 r:0.2286
en_zh Dev loss: 0.8220 r:0.4373
ro_en Dev loss: 0.3590 r:0.8209
et_en Dev loss: 0.4286 r:0.6799
si_en Dev loss: 0.8469 r:0.5814
ne_en Dev loss: 0.5690 r:0.7309
ru_en Dev loss: 0.5405 r:0.7091
Current avg r:0.5983 Best avg r: 0.6252
00:20:54,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:24,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:54,352 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2339
en_de Dev loss: 0.8797 r:0.2371
en_zh Dev loss: 0.8108 r:0.4445
ro_en Dev loss: 0.3210 r:0.8255
et_en Dev loss: 0.4089 r:0.6935
si_en Dev loss: 0.7260 r:0.5941
ne_en Dev loss: 0.4467 r:0.7438
ru_en Dev loss: 0.4446 r:0.7385
Current avg r:0.6110 Best avg r: 0.6252
00:28:22,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:53,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:23,158 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2408
en_de Dev loss: 0.8786 r:0.2346
en_zh Dev loss: 0.8247 r:0.4191
ro_en Dev loss: 0.3271 r:0.8209
et_en Dev loss: 0.4015 r:0.6916
si_en Dev loss: 0.8112 r:0.5824
ne_en Dev loss: 0.5085 r:0.7336
ru_en Dev loss: 0.4931 r:0.7199
Current avg r:0.6003 Best avg r: 0.6252
00:35:51,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:21,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:51,790 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2366
en_de Dev loss: 0.8815 r:0.2174
en_zh Dev loss: 0.8048 r:0.4433
ro_en Dev loss: 0.3224 r:0.8299
et_en Dev loss: 0.4476 r:0.6955
si_en Dev loss: 0.7355 r:0.5973
ne_en Dev loss: 0.4573 r:0.7316
ru_en Dev loss: 0.4558 r:0.7409
Current avg r:0.6080 Best avg r: 0.6252
00:43:20,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:50,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:20,460 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2595
en_de Dev loss: 0.8772 r:0.2138
en_zh Dev loss: 0.8169 r:0.4266
ro_en Dev loss: 0.3235 r:0.8209
et_en Dev loss: 0.4199 r:0.6864
si_en Dev loss: 0.7506 r:0.5889
ne_en Dev loss: 0.4745 r:0.7314
ru_en Dev loss: 0.4724 r:0.7200
Current avg r:0.5983 Best avg r: 0.6252
00:50:48,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:19,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:53:49,295 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2488
en_de Dev loss: 0.9008 r:0.2295
en_zh Dev loss: 0.8782 r:0.4426
ro_en Dev loss: 0.3713 r:0.8189
et_en Dev loss: 0.4470 r:0.6873
si_en Dev loss: 0.8739 r:0.5840
ne_en Dev loss: 0.5513 r:0.7323
ru_en Dev loss: 0.5275 r:0.7211
Current avg r:0.6023 Best avg r: 0.6252
00:58:17,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:59:47,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:18,60 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2340
en_de Dev loss: 0.8625 r:0.2237
en_zh Dev loss: 0.7706 r:0.4532
ro_en Dev loss: 0.3155 r:0.8229
et_en Dev loss: 0.4286 r:0.6925
si_en Dev loss: 0.7006 r:0.5935
ne_en Dev loss: 0.4542 r:0.7393
ru_en Dev loss: 0.4391 r:0.7275
Current avg r:0.6075 Best avg r: 0.6252
01:05:46,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:16,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:46,788 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2389
en_de Dev loss: 0.8713 r:0.2440
en_zh Dev loss: 0.8955 r:0.4307
ro_en Dev loss: 0.3567 r:0.8176
et_en Dev loss: 0.4266 r:0.6828
si_en Dev loss: 0.9243 r:0.5721
ne_en Dev loss: 0.5719 r:0.7256
ru_en Dev loss: 0.5245 r:0.7062
Current avg r:0.5970 Best avg r: 0.6252
01:13:15,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:45,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:15,538 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2354
en_de Dev loss: 0.8837 r:0.2194
en_zh Dev loss: 0.8987 r:0.4345
ro_en Dev loss: 0.3932 r:0.8140
et_en Dev loss: 0.4214 r:0.6809
si_en Dev loss: 0.9566 r:0.5734
ne_en Dev loss: 0.6169 r:0.7330
ru_en Dev loss: 0.5482 r:0.6981
Current avg r:0.5933 Best avg r: 0.6252
01:20:44,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:22:14,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:44,274 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2445
en_de Dev loss: 0.8503 r:0.2309
en_zh Dev loss: 0.7633 r:0.4438
ro_en Dev loss: 0.3098 r:0.8222
et_en Dev loss: 0.4216 r:0.6945
si_en Dev loss: 0.6824 r:0.5894
ne_en Dev loss: 0.4122 r:0.7386
ru_en Dev loss: 0.4105 r:0.7389
Current avg r:0.6083 Best avg r: 0.6252
01:28:12,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:42,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:31:12,859 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2505
en_de Dev loss: 0.8745 r:0.2157
en_zh Dev loss: 0.7948 r:0.4389
ro_en Dev loss: 0.3492 r:0.8185
et_en Dev loss: 0.4283 r:0.6867
si_en Dev loss: 0.7640 r:0.5880
ne_en Dev loss: 0.4550 r:0.7369
ru_en Dev loss: 0.4334 r:0.7418
Current avg r:0.6038 Best avg r: 0.6252
01:35:41,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:37:11,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:41,676 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2390
en_de Dev loss: 0.8856 r:0.2211
en_zh Dev loss: 0.8386 r:0.4228
ro_en Dev loss: 0.3492 r:0.8128
et_en Dev loss: 0.4280 r:0.6727
si_en Dev loss: 0.8110 r:0.5772
ne_en Dev loss: 0.4830 r:0.7330
ru_en Dev loss: 0.4914 r:0.7072
Current avg r:0.5924 Best avg r: 0.6252
01:43:10,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:40,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:46:10,557 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2174
en_de Dev loss: 0.8807 r:0.2221
en_zh Dev loss: 0.8057 r:0.4417
ro_en Dev loss: 0.3445 r:0.8216
et_en Dev loss: 0.4443 r:0.6861
si_en Dev loss: 0.8304 r:0.5827
ne_en Dev loss: 0.5046 r:0.7363
ru_en Dev loss: 0.4423 r:0.7438
Current avg r:0.6049 Best avg r: 0.6252
01:50:39,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:52:09,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:53:39,250 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2244
en_de Dev loss: 0.8817 r:0.2099
en_zh Dev loss: 0.8060 r:0.4468
ro_en Dev loss: 0.3320 r:0.8231
et_en Dev loss: 0.4308 r:0.6878
si_en Dev loss: 0.7949 r:0.5857
ne_en Dev loss: 0.4725 r:0.7378
ru_en Dev loss: 0.4594 r:0.7384
Current avg r:0.6042 Best avg r: 0.6252
01:58:07,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:59:37,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:01:08,11 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2321
en_de Dev loss: 0.8909 r:0.2183
en_zh Dev loss: 0.9227 r:0.4289
ro_en Dev loss: 0.3893 r:0.8192
et_en Dev loss: 0.4431 r:0.6817
si_en Dev loss: 0.9338 r:0.5784
ne_en Dev loss: 0.5564 r:0.7329
ru_en Dev loss: 0.5345 r:0.7104
Current avg r:0.5957 Best avg r: 0.6252
02:05:38,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:07:09,34 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:08:39,328 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2062
en_de Dev loss: 0.8777 r:0.1996
en_zh Dev loss: 0.8301 r:0.4409
ro_en Dev loss: 0.3403 r:0.8233
et_en Dev loss: 0.4683 r:0.6818
si_en Dev loss: 0.8113 r:0.5811
ne_en Dev loss: 0.4798 r:0.7317
ru_en Dev loss: 0.4823 r:0.7204
Current avg r:0.5970 Best avg r: 0.6252
02:13:07,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:14:38,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:16:08,559 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2071
en_de Dev loss: 0.8877 r:0.2211
en_zh Dev loss: 0.8373 r:0.4349
ro_en Dev loss: 0.3372 r:0.8245
et_en Dev loss: 0.4401 r:0.6889
si_en Dev loss: 0.7794 r:0.5816
ne_en Dev loss: 0.4623 r:0.7301
ru_en Dev loss: 0.5234 r:0.7130
Current avg r:0.5992 Best avg r: 0.6252
02:20:37,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:22:07,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:23:37,729 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2131
en_de Dev loss: 0.8736 r:0.2050
en_zh Dev loss: 0.8206 r:0.4194
ro_en Dev loss: 0.3215 r:0.8209
et_en Dev loss: 0.4267 r:0.6834
si_en Dev loss: 0.7767 r:0.5854
ne_en Dev loss: 0.4751 r:0.7296
ru_en Dev loss: 0.4917 r:0.7069
Current avg r:0.5930 Best avg r: 0.6252
02:28:06,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:36,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:31:07,26 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2083
en_de Dev loss: 0.8813 r:0.1900
en_zh Dev loss: 0.8177 r:0.4199
ro_en Dev loss: 0.3380 r:0.8177
et_en Dev loss: 0.4417 r:0.6687
si_en Dev loss: 0.8423 r:0.5703
ne_en Dev loss: 0.5346 r:0.7248
ru_en Dev loss: 0.4963 r:0.7065
Current avg r:0.5854 Best avg r: 0.6252
02:35:35,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:05,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:35,914 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2042
en_de Dev loss: 0.8781 r:0.2038
en_zh Dev loss: 0.8381 r:0.4314
ro_en Dev loss: 0.3532 r:0.8170
et_en Dev loss: 0.4757 r:0.6758
si_en Dev loss: 0.7965 r:0.5840
ne_en Dev loss: 0.4938 r:0.7275
ru_en Dev loss: 0.4805 r:0.7134
Current avg r:0.5933 Best avg r: 0.6252
02:43:04,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:44:34,772 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:46:04,877 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2082
en_de Dev loss: 0.8748 r:0.2235
en_zh Dev loss: 0.8052 r:0.4389
ro_en Dev loss: 0.3261 r:0.8173
et_en Dev loss: 0.4517 r:0.6671
si_en Dev loss: 0.8156 r:0.5733
ne_en Dev loss: 0.5050 r:0.7282
ru_en Dev loss: 0.4427 r:0.7397
Current avg r:0.5983 Best avg r: 0.6252
02:50:33,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:52:03,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:33,727 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2093
en_de Dev loss: 0.8694 r:0.2282
en_zh Dev loss: 0.8104 r:0.4414
ro_en Dev loss: 0.3203 r:0.8232
et_en Dev loss: 0.4777 r:0.6743
si_en Dev loss: 0.7508 r:0.5839
ne_en Dev loss: 0.4463 r:0.7316
ru_en Dev loss: 0.4111 r:0.7497
Current avg r:0.6046 Best avg r: 0.6252
02:58:02,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:59:32,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:01:02,901 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2008
en_de Dev loss: 0.8939 r:0.2178
en_zh Dev loss: 0.8157 r:0.4487
ro_en Dev loss: 0.3385 r:0.8260
et_en Dev loss: 0.4631 r:0.6807
si_en Dev loss: 0.7517 r:0.5832
ne_en Dev loss: 0.4468 r:0.7371
ru_en Dev loss: 0.4851 r:0.7260
Current avg r:0.6028 Best avg r: 0.6252
03:05:31,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:07:01,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:31,957 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2032
en_de Dev loss: 0.8873 r:0.2232
en_zh Dev loss: 0.8547 r:0.4330
ro_en Dev loss: 0.3721 r:0.8191
et_en Dev loss: 0.4743 r:0.6712
si_en Dev loss: 0.8490 r:0.5730
ne_en Dev loss: 0.5038 r:0.7282
ru_en Dev loss: 0.5199 r:0.7119
Current avg r:0.5942 Best avg r: 0.6252
03:13:00,581 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:30,926 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:01,182 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2059
en_de Dev loss: 0.8921 r:0.2156
en_zh Dev loss: 0.8128 r:0.4472
ro_en Dev loss: 0.3418 r:0.8225
et_en Dev loss: 0.4675 r:0.6752
si_en Dev loss: 0.8100 r:0.5796
ne_en Dev loss: 0.4706 r:0.7323
ru_en Dev loss: 0.4457 r:0.7407
Current avg r:0.6019 Best avg r: 0.6252
03:20:29,709 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:59,934 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:30,111 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1957
en_de Dev loss: 0.8715 r:0.2316
en_zh Dev loss: 0.8049 r:0.4437
ro_en Dev loss: 0.3311 r:0.8228
et_en Dev loss: 0.4826 r:0.6803
si_en Dev loss: 0.7491 r:0.5783
ne_en Dev loss: 0.4578 r:0.7304
ru_en Dev loss: 0.4283 r:0.7444
Current avg r:0.6045 Best avg r: 0.6252
03:27:58,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:28,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:58,821 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1949
en_de Dev loss: 0.8923 r:0.2273
en_zh Dev loss: 0.8215 r:0.4499
ro_en Dev loss: 0.3559 r:0.8164
et_en Dev loss: 0.4657 r:0.6756
si_en Dev loss: 0.8051 r:0.5751
ne_en Dev loss: 0.4765 r:0.7347
ru_en Dev loss: 0.4593 r:0.7431
Current avg r:0.6032 Best avg r: 0.6252
03:35:27,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:57,491 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:27,590 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2035
en_de Dev loss: 0.8776 r:0.2373
en_zh Dev loss: 0.8514 r:0.4484
ro_en Dev loss: 0.3627 r:0.8221
et_en Dev loss: 0.4565 r:0.6811
si_en Dev loss: 0.9143 r:0.5677
ne_en Dev loss: 0.5083 r:0.7349
ru_en Dev loss: 0.5188 r:0.7268
Current avg r:0.6026 Best avg r: 0.6252
03:42:56,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:26,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:56,453 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2063
en_de Dev loss: 0.8813 r:0.2248
en_zh Dev loss: 0.8355 r:0.4369
ro_en Dev loss: 0.3409 r:0.8166
et_en Dev loss: 0.4729 r:0.6774
si_en Dev loss: 0.8517 r:0.5622
ne_en Dev loss: 0.4754 r:0.7362
ru_en Dev loss: 0.4497 r:0.7343
Current avg r:0.5983 Best avg r: 0.6252
03:50:25,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:55,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:53:25,601 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1910
en_de Dev loss: 0.8723 r:0.2198
en_zh Dev loss: 0.7987 r:0.4407
ro_en Dev loss: 0.3223 r:0.8204
et_en Dev loss: 0.4704 r:0.6802
si_en Dev loss: 0.7429 r:0.5691
ne_en Dev loss: 0.4202 r:0.7326
ru_en Dev loss: 0.4147 r:0.7442
Current avg r:0.6010 Best avg r: 0.6252
03:57:56,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:59:26,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:56,855 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1762
en_de Dev loss: 0.9192 r:0.2138
en_zh Dev loss: 0.8375 r:0.4501
ro_en Dev loss: 0.3692 r:0.8218
et_en Dev loss: 0.4647 r:0.6715
si_en Dev loss: 0.9038 r:0.5736
ne_en Dev loss: 0.5165 r:0.7312
ru_en Dev loss: 0.4669 r:0.7457
Current avg r:0.6011 Best avg r: 0.6252
04:05:25,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:06:55,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:26,20 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1679
en_de Dev loss: 0.9110 r:0.1935
en_zh Dev loss: 0.8432 r:0.4418
ro_en Dev loss: 0.3617 r:0.8182
et_en Dev loss: 0.4791 r:0.6715
si_en Dev loss: 0.8336 r:0.5783
ne_en Dev loss: 0.4801 r:0.7330
ru_en Dev loss: 0.4716 r:0.7344
Current avg r:0.5958 Best avg r: 0.6252
04:12:54,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:24,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:54,813 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1688
en_de Dev loss: 0.8871 r:0.1941
en_zh Dev loss: 0.8101 r:0.4366
ro_en Dev loss: 0.3344 r:0.8203
et_en Dev loss: 0.4592 r:0.6716
si_en Dev loss: 0.7995 r:0.5745
ne_en Dev loss: 0.4580 r:0.7308
ru_en Dev loss: 0.4435 r:0.7335
Current avg r:0.5945 Best avg r: 0.6252
04:20:23,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:53,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:23,515 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1743
en_de Dev loss: 0.8818 r:0.1930
en_zh Dev loss: 0.7732 r:0.4467
ro_en Dev loss: 0.3085 r:0.8237
et_en Dev loss: 0.4250 r:0.6825
si_en Dev loss: 0.7465 r:0.5721
ne_en Dev loss: 0.4070 r:0.7346
ru_en Dev loss: 0.4231 r:0.7365
Current avg r:0.5984 Best avg r: 0.6252
04:27:52,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:22,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:52,377 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1744
en_de Dev loss: 0.9282 r:0.1864
en_zh Dev loss: 0.8610 r:0.4345
ro_en Dev loss: 0.3559 r:0.8218
et_en Dev loss: 0.4783 r:0.6731
si_en Dev loss: 0.8305 r:0.5732
ne_en Dev loss: 0.4607 r:0.7296
ru_en Dev loss: 0.5018 r:0.7282
Current avg r:0.5924 Best avg r: 0.6252
04:35:20,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:51,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:21,405 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1640
en_de Dev loss: 0.9157 r:0.2104
en_zh Dev loss: 0.8700 r:0.4367
ro_en Dev loss: 0.3755 r:0.8209
et_en Dev loss: 0.4789 r:0.6677
si_en Dev loss: 0.8704 r:0.5773
ne_en Dev loss: 0.5012 r:0.7313
ru_en Dev loss: 0.5096 r:0.7349
Current avg r:0.5970 Best avg r: 0.6252
04:42:49,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:20,222 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:50,461 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1737
en_de Dev loss: 0.8960 r:0.2081
en_zh Dev loss: 0.8199 r:0.4475
ro_en Dev loss: 0.3242 r:0.8259
et_en Dev loss: 0.4442 r:0.6744
si_en Dev loss: 0.8533 r:0.5742
ne_en Dev loss: 0.4616 r:0.7356
ru_en Dev loss: 0.4579 r:0.7442
Current avg r:0.6014 Best avg r: 0.6252
04:50:19,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:51:49,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:19,545 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1715
en_de Dev loss: 0.8929 r:0.1936
en_zh Dev loss: 0.8028 r:0.4457
ro_en Dev loss: 0.3241 r:0.8228
et_en Dev loss: 0.4422 r:0.6796
si_en Dev loss: 0.8041 r:0.5751
ne_en Dev loss: 0.4221 r:0.7369
ru_en Dev loss: 0.4289 r:0.7480
Current avg r:0.6003 Best avg r: 0.6252
04:57:47,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:59:18,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:00:48,284 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1659
en_de Dev loss: 0.8862 r:0.2004
en_zh Dev loss: 0.8079 r:0.4479
ro_en Dev loss: 0.3293 r:0.8210
et_en Dev loss: 0.4553 r:0.6727
si_en Dev loss: 0.8060 r:0.5670
ne_en Dev loss: 0.4339 r:0.7370
ru_en Dev loss: 0.4377 r:0.7379
Current avg r:0.5977 Best avg r: 0.6252
05:05:16,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:46,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:17,34 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1799
en_de Dev loss: 0.9096 r:0.1917
en_zh Dev loss: 0.8099 r:0.4471
ro_en Dev loss: 0.3371 r:0.8249
et_en Dev loss: 0.4603 r:0.6683
si_en Dev loss: 0.8650 r:0.5643
ne_en Dev loss: 0.4773 r:0.7292
ru_en Dev loss: 0.4629 r:0.7429
Current avg r:0.5955 Best avg r: 0.6252
05:12:45,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:15,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:45,907 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1664
en_de Dev loss: 0.9058 r:0.1711
en_zh Dev loss: 0.7839 r:0.4610
ro_en Dev loss: 0.3337 r:0.8215
et_en Dev loss: 0.4454 r:0.6713
si_en Dev loss: 0.8660 r:0.5610
ne_en Dev loss: 0.4547 r:0.7362
ru_en Dev loss: 0.4615 r:0.7352
Current avg r:0.5939 Best avg r: 0.6252
05:20:14,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:21:44,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:15,56 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1594
en_de Dev loss: 0.8986 r:0.2021
en_zh Dev loss: 0.8276 r:0.4392
ro_en Dev loss: 0.3271 r:0.8231
et_en Dev loss: 0.4495 r:0.6708
si_en Dev loss: 0.8413 r:0.5553
ne_en Dev loss: 0.4478 r:0.7286
ru_en Dev loss: 0.4334 r:0.7475
Current avg r:0.5952 Best avg r: 0.6252
05:27:43,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:29:13,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:44,143 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1738
en_de Dev loss: 0.9001 r:0.1937
en_zh Dev loss: 0.8188 r:0.4529
ro_en Dev loss: 0.3576 r:0.8205
et_en Dev loss: 0.4794 r:0.6684
si_en Dev loss: 0.8480 r:0.5651
ne_en Dev loss: 0.4425 r:0.7307
ru_en Dev loss: 0.4559 r:0.7403
Current avg r:0.5959 Best avg r: 0.6252
05:35:12,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:42,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:13,184 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1652
en_de Dev loss: 0.8856 r:0.2052
en_zh Dev loss: 0.8080 r:0.4512
ro_en Dev loss: 0.3336 r:0.8242
et_en Dev loss: 0.4884 r:0.6816
si_en Dev loss: 0.7991 r:0.5720
ne_en Dev loss: 0.4369 r:0.7313
ru_en Dev loss: 0.4241 r:0.7566
Current avg r:0.6032 Best avg r: 0.6252
05:42:41,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:11,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:41,789 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1629
en_de Dev loss: 0.8830 r:0.1993
en_zh Dev loss: 0.8181 r:0.4446
ro_en Dev loss: 0.3239 r:0.8253
et_en Dev loss: 0.5089 r:0.6744
si_en Dev loss: 0.7906 r:0.5672
ne_en Dev loss: 0.4318 r:0.7252
ru_en Dev loss: 0.4193 r:0.7500
Current avg r:0.5980 Best avg r: 0.6252
05:50:12,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:42,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:12,592 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1420
en_de Dev loss: 0.9112 r:0.1939
en_zh Dev loss: 0.8647 r:0.4425
ro_en Dev loss: 0.3407 r:0.8205
et_en Dev loss: 0.4626 r:0.6648
si_en Dev loss: 0.8974 r:0.5593
ne_en Dev loss: 0.4621 r:0.7259
ru_en Dev loss: 0.4552 r:0.7471
Current avg r:0.5934 Best avg r: 0.6252
05:57:40,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:11,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:00:41,241 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1459
en_de Dev loss: 0.9216 r:0.1971
en_zh Dev loss: 0.8262 r:0.4494
ro_en Dev loss: 0.3672 r:0.8195
et_en Dev loss: 0.4849 r:0.6675
si_en Dev loss: 0.9487 r:0.5609
ne_en Dev loss: 0.4848 r:0.7267
ru_en Dev loss: 0.4820 r:0.7391
Current avg r:0.5943 Best avg r: 0.6252
06:05:09,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:06:40,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:10,368 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1509
en_de Dev loss: 0.9187 r:0.1989
en_zh Dev loss: 0.8384 r:0.4435
ro_en Dev loss: 0.3547 r:0.8190
et_en Dev loss: 0.4700 r:0.6679
si_en Dev loss: 0.8583 r:0.5694
ne_en Dev loss: 0.4766 r:0.7253
ru_en Dev loss: 0.4860 r:0.7352
Current avg r:0.5942 Best avg r: 0.6252
06:12:38,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:09,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:39,546 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1503
en_de Dev loss: 0.9192 r:0.1894
en_zh Dev loss: 0.8404 r:0.4471
ro_en Dev loss: 0.3803 r:0.8142
et_en Dev loss: 0.4829 r:0.6561
si_en Dev loss: 0.9071 r:0.5597
ne_en Dev loss: 0.4854 r:0.7201
ru_en Dev loss: 0.4893 r:0.7343
Current avg r:0.5887 Best avg r: 0.6252
06:20:08,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:21:38,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:08,667 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1617
en_de Dev loss: 0.8954 r:0.1818
en_zh Dev loss: 0.8156 r:0.4454
ro_en Dev loss: 0.3584 r:0.8146
et_en Dev loss: 0.4845 r:0.6566
si_en Dev loss: 0.8864 r:0.5570
ne_en Dev loss: 0.4628 r:0.7223
ru_en Dev loss: 0.4958 r:0.7221
Current avg r:0.5857 Best avg r: 0.6252
06:27:37,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:07,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:37,454 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1434
en_de Dev loss: 0.8933 r:0.1992
en_zh Dev loss: 0.8146 r:0.4506
ro_en Dev loss: 0.3642 r:0.8146
et_en Dev loss: 0.4963 r:0.6616
si_en Dev loss: 0.9266 r:0.5598
ne_en Dev loss: 0.4679 r:0.7282
ru_en Dev loss: 0.4401 r:0.7522
Current avg r:0.5952 Best avg r: 0.6252
06:35:05,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:36,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:38:06,223 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1447
en_de Dev loss: 0.9115 r:0.1848
en_zh Dev loss: 0.8260 r:0.4549
ro_en Dev loss: 0.3614 r:0.8182
et_en Dev loss: 0.5004 r:0.6530
si_en Dev loss: 0.8727 r:0.5657
ne_en Dev loss: 0.4443 r:0.7249
ru_en Dev loss: 0.4707 r:0.7409
Current avg r:0.5918 Best avg r: 0.6252
06:42:34,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:44:04,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:35,25 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1456
en_de Dev loss: 0.8935 r:0.1982
en_zh Dev loss: 0.8087 r:0.4440
ro_en Dev loss: 0.3408 r:0.8193
et_en Dev loss: 0.4974 r:0.6510
si_en Dev loss: 0.8463 r:0.5630
ne_en Dev loss: 0.4432 r:0.7278
ru_en Dev loss: 0.4675 r:0.7283
Current avg r:0.5902 Best avg r: 0.6252
06:50:03,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:33,599 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:53:03,648 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1485
en_de Dev loss: 0.9068 r:0.1952
en_zh Dev loss: 0.8359 r:0.4428
ro_en Dev loss: 0.3591 r:0.8147
et_en Dev loss: 0.4822 r:0.6545
si_en Dev loss: 0.8911 r:0.5558
ne_en Dev loss: 0.4691 r:0.7276
ru_en Dev loss: 0.4529 r:0.7468
Current avg r:0.5910 Best avg r: 0.6252
06:57:32,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:59:02,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:00:32,255 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1562
en_de Dev loss: 0.9151 r:0.1907
en_zh Dev loss: 0.8565 r:0.4462
ro_en Dev loss: 0.3950 r:0.8103
et_en Dev loss: 0.4757 r:0.6653
si_en Dev loss: 0.8914 r:0.5679
ne_en Dev loss: 0.4833 r:0.7270
ru_en Dev loss: 0.4927 r:0.7381
Current avg r:0.5922 Best avg r: 0.6252
07:05:00,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:06:30,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:00,946 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1470
en_de Dev loss: 0.9034 r:0.2118
en_zh Dev loss: 0.8192 r:0.4560
ro_en Dev loss: 0.3346 r:0.8216
et_en Dev loss: 0.4578 r:0.6722
si_en Dev loss: 0.8384 r:0.5715
ne_en Dev loss: 0.4248 r:0.7341
ru_en Dev loss: 0.4751 r:0.7427
Current avg r:0.6014 Best avg r: 0.6252
07:12:29,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:59,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:29,534 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1435
en_de Dev loss: 0.9133 r:0.1998
en_zh Dev loss: 0.8952 r:0.4335
ro_en Dev loss: 0.4024 r:0.8101
et_en Dev loss: 0.4831 r:0.6538
si_en Dev loss: 1.0057 r:0.5576
ne_en Dev loss: 0.5252 r:0.7251
ru_en Dev loss: 0.5226 r:0.7184
Current avg r:0.5855 Best avg r: 0.6252
07:19:57,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:21:28,139 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:22:58,228 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1425
en_de Dev loss: 0.8821 r:0.1984
en_zh Dev loss: 0.7863 r:0.4418
ro_en Dev loss: 0.3084 r:0.8219
et_en Dev loss: 0.4627 r:0.6713
si_en Dev loss: 0.7740 r:0.5742
ne_en Dev loss: 0.4037 r:0.7336
ru_en Dev loss: 0.4045 r:0.7514
Current avg r:0.5989 Best avg r: 0.6252
07:27:26,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:28:56,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:27,102 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1467
en_de Dev loss: 0.9132 r:0.1974
en_zh Dev loss: 0.8275 r:0.4610
ro_en Dev loss: 0.3594 r:0.8201
et_en Dev loss: 0.4872 r:0.6656
si_en Dev loss: 0.8856 r:0.5667
ne_en Dev loss: 0.4554 r:0.7289
ru_en Dev loss: 0.4814 r:0.7395
Current avg r:0.5970 Best avg r: 0.6252
07:34:55,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:36:25,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:55,848 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1427
en_de Dev loss: 0.9146 r:0.1818
en_zh Dev loss: 0.8309 r:0.4504
ro_en Dev loss: 0.3358 r:0.8196
et_en Dev loss: 0.4582 r:0.6748
si_en Dev loss: 0.8603 r:0.5679
ne_en Dev loss: 0.4207 r:0.7334
ru_en Dev loss: 0.4623 r:0.7416
Current avg r:0.5956 Best avg r: 0.6252
07:42:26,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:43:56,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:26,580 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1365
en_de Dev loss: 0.9000 r:0.1912
en_zh Dev loss: 0.7961 r:0.4601
ro_en Dev loss: 0.3417 r:0.8192
et_en Dev loss: 0.4817 r:0.6693
si_en Dev loss: 0.8564 r:0.5597
ne_en Dev loss: 0.4386 r:0.7224
ru_en Dev loss: 0.4456 r:0.7356
Current avg r:0.5939 Best avg r: 0.6252
07:49:55,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:50:20,808 root INFO 
id:en_zh cur r: 0.4747 best r: 0.4747
07:51:25,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:55,409 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1271
en_de Dev loss: 0.9295 r:0.1922
en_zh Dev loss: 0.7725 r:0.4722
ro_en Dev loss: 0.3194 r:0.8233
et_en Dev loss: 0.4687 r:0.6805
si_en Dev loss: 0.7835 r:0.5687
ne_en Dev loss: 0.3984 r:0.7290
ru_en Dev loss: 0.4102 r:0.7613
Current avg r:0.6039 Best avg r: 0.6252
07:57:23,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:58:54,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:00:24,82 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1340
en_de Dev loss: 0.8932 r:0.1900
en_zh Dev loss: 0.7411 r:0.4636
ro_en Dev loss: 0.2966 r:0.8234
et_en Dev loss: 0.4522 r:0.6839
si_en Dev loss: 0.7146 r:0.5676
ne_en Dev loss: 0.3815 r:0.7302
ru_en Dev loss: 0.3720 r:0.7585
Current avg r:0.6025 Best avg r: 0.6252
08:04:52,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:06:22,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:07:52,645 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1323
en_de Dev loss: 0.9098 r:0.1868
en_zh Dev loss: 0.8024 r:0.4637
ro_en Dev loss: 0.3482 r:0.8192
et_en Dev loss: 0.4692 r:0.6734
si_en Dev loss: 0.9107 r:0.5522
ne_en Dev loss: 0.4396 r:0.7265
ru_en Dev loss: 0.4605 r:0.7395
Current avg r:0.5945 Best avg r: 0.6252
08:12:21,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:13:51,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:15:21,319 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1288
en_de Dev loss: 0.9232 r:0.1755
en_zh Dev loss: 0.8283 r:0.4468
ro_en Dev loss: 0.3342 r:0.8190
et_en Dev loss: 0.4563 r:0.6738
si_en Dev loss: 0.8441 r:0.5581
ne_en Dev loss: 0.4192 r:0.7300
ru_en Dev loss: 0.4485 r:0.7453
Current avg r:0.5926 Best avg r: 0.6252
08:19:49,818 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:20,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:22:50,119 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1282
en_de Dev loss: 0.9066 r:0.1866
en_zh Dev loss: 0.7877 r:0.4553
ro_en Dev loss: 0.3404 r:0.8204
et_en Dev loss: 0.4538 r:0.6808
si_en Dev loss: 0.8074 r:0.5646
ne_en Dev loss: 0.4127 r:0.7295
ru_en Dev loss: 0.4382 r:0.7452
Current avg r:0.5975 Best avg r: 0.6252
08:27:18,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:48,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:18,755 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1214
en_de Dev loss: 0.9072 r:0.1936
en_zh Dev loss: 0.7936 r:0.4606
ro_en Dev loss: 0.3656 r:0.8143
et_en Dev loss: 0.4877 r:0.6709
si_en Dev loss: 0.8210 r:0.5625
ne_en Dev loss: 0.4173 r:0.7316
ru_en Dev loss: 0.4684 r:0.7365
Current avg r:0.5957 Best avg r: 0.6252
08:34:47,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:17,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:37:47,536 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1261
en_de Dev loss: 0.9060 r:0.2014
en_zh Dev loss: 0.7936 r:0.4572
ro_en Dev loss: 0.3473 r:0.8187
et_en Dev loss: 0.4616 r:0.6712
si_en Dev loss: 0.8244 r:0.5639
ne_en Dev loss: 0.4156 r:0.7297
ru_en Dev loss: 0.4466 r:0.7437
Current avg r:0.5980 Best avg r: 0.6252
08:42:16,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:43:46,262 root INFO 
id:ru_en cur r: 0.7633 best r: 0.7633
08:43:46,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:45:16,399 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1291
en_de Dev loss: 0.8967 r:0.1918
en_zh Dev loss: 0.8041 r:0.4517
ro_en Dev loss: 0.3252 r:0.8237
et_en Dev loss: 0.4543 r:0.6718
si_en Dev loss: 0.8465 r:0.5598
ne_en Dev loss: 0.4148 r:0.7274
ru_en Dev loss: 0.3961 r:0.7606
Current avg r:0.5981 Best avg r: 0.6252
08:49:44,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:51:15,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:52:45,139 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1330
en_de Dev loss: 0.8993 r:0.1963
en_zh Dev loss: 0.7915 r:0.4550
ro_en Dev loss: 0.3187 r:0.8235
et_en Dev loss: 0.4606 r:0.6808
si_en Dev loss: 0.7947 r:0.5640
ne_en Dev loss: 0.3869 r:0.7353
ru_en Dev loss: 0.4068 r:0.7567
Current avg r:0.6017 Best avg r: 0.6252
08:57:13,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:58:43,920 root INFO 
id:ru_en cur r: 0.7662 best r: 0.7662
08:58:43,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:00:13,965 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1208
en_de Dev loss: 0.8910 r:0.2096
en_zh Dev loss: 0.8205 r:0.4522
ro_en Dev loss: 0.3325 r:0.8223
et_en Dev loss: 0.4728 r:0.6753
si_en Dev loss: 0.8626 r:0.5608
ne_en Dev loss: 0.4155 r:0.7336
ru_en Dev loss: 0.4146 r:0.7627
Current avg r:0.6024 Best avg r: 0.6252
09:04:42,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:06:12,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:07:42,902 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1282
en_de Dev loss: 0.8930 r:0.2047
en_zh Dev loss: 0.7909 r:0.4541
ro_en Dev loss: 0.3355 r:0.8242
et_en Dev loss: 0.4972 r:0.6708
si_en Dev loss: 0.8354 r:0.5598
ne_en Dev loss: 0.4033 r:0.7323
ru_en Dev loss: 0.4227 r:0.7517
Current avg r:0.5997 Best avg r: 0.6252
09:12:11,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:13:41,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:15:11,709 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1215
en_de Dev loss: 0.9079 r:0.2018
en_zh Dev loss: 0.8027 r:0.4458
ro_en Dev loss: 0.3312 r:0.8235
et_en Dev loss: 0.4670 r:0.6662
si_en Dev loss: 0.8552 r:0.5640
ne_en Dev loss: 0.4155 r:0.7314
ru_en Dev loss: 0.4328 r:0.7527
Current avg r:0.5979 Best avg r: 0.6252
09:19:40,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:21:10,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:22:40,460 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1245
en_de Dev loss: 0.9331 r:0.1943
en_zh Dev loss: 0.8574 r:0.4506
ro_en Dev loss: 0.3641 r:0.8206
et_en Dev loss: 0.5061 r:0.6489
si_en Dev loss: 0.9868 r:0.5477
ne_en Dev loss: 0.4613 r:0.7279
ru_en Dev loss: 0.4917 r:0.7363
Current avg r:0.5895 Best avg r: 0.6252
09:27:09,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:28:39,201 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:30:09,338 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1300
en_de Dev loss: 0.9204 r:0.1927
en_zh Dev loss: 0.8265 r:0.4518
ro_en Dev loss: 0.3482 r:0.8192
et_en Dev loss: 0.5125 r:0.6548
si_en Dev loss: 0.8718 r:0.5505
ne_en Dev loss: 0.4087 r:0.7320
ru_en Dev loss: 0.4462 r:0.7449
Current avg r:0.5923 Best avg r: 0.6252
09:34:39,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:36:09,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:37:39,766 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1185
en_de Dev loss: 0.9336 r:0.1802
en_zh Dev loss: 0.8108 r:0.4571
ro_en Dev loss: 0.3388 r:0.8260
et_en Dev loss: 0.5113 r:0.6628
si_en Dev loss: 0.8575 r:0.5621
ne_en Dev loss: 0.4005 r:0.7315
ru_en Dev loss: 0.4484 r:0.7464
Current avg r:0.5952 Best avg r: 0.6252
09:42:08,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:38,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:45:08,541 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1125
en_de Dev loss: 0.9284 r:0.1822
en_zh Dev loss: 0.7862 r:0.4560
ro_en Dev loss: 0.3260 r:0.8237
et_en Dev loss: 0.4791 r:0.6672
si_en Dev loss: 0.7921 r:0.5634
ne_en Dev loss: 0.4016 r:0.7295
ru_en Dev loss: 0.4334 r:0.7466
Current avg r:0.5955 Best avg r: 0.6252
09:49:37,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:51:07,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:52:37,427 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1129
en_de Dev loss: 0.9208 r:0.2009
en_zh Dev loss: 0.8220 r:0.4552
ro_en Dev loss: 0.3395 r:0.8202
et_en Dev loss: 0.4795 r:0.6618
si_en Dev loss: 0.8291 r:0.5586
ne_en Dev loss: 0.4059 r:0.7321
ru_en Dev loss: 0.4430 r:0.7468
Current avg r:0.5965 Best avg r: 0.6252
09:57:06,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:36,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:06,331 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1066
en_de Dev loss: 0.9007 r:0.1985
en_zh Dev loss: 0.7873 r:0.4539
ro_en Dev loss: 0.3279 r:0.8220
et_en Dev loss: 0.4842 r:0.6659
si_en Dev loss: 0.8295 r:0.5610
ne_en Dev loss: 0.3980 r:0.7365
ru_en Dev loss: 0.4157 r:0.7503
Current avg r:0.5983 Best avg r: 0.6252
10:04:34,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:06:05,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:35,221 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1091
en_de Dev loss: 0.9339 r:0.1767
en_zh Dev loss: 0.7966 r:0.4610
ro_en Dev loss: 0.3377 r:0.8253
et_en Dev loss: 0.4904 r:0.6702
si_en Dev loss: 0.8228 r:0.5676
ne_en Dev loss: 0.4022 r:0.7334
ru_en Dev loss: 0.4334 r:0.7604
Current avg r:0.5992 Best avg r: 0.6252
10:12:03,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:33,912 root INFO 
id:ru_en cur r: 0.7681 best r: 0.7681
10:13:33,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:03,983 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1168
en_de Dev loss: 0.9176 r:0.1816
en_zh Dev loss: 0.8024 r:0.4561
ro_en Dev loss: 0.3372 r:0.8244
et_en Dev loss: 0.4569 r:0.6699
si_en Dev loss: 0.8404 r:0.5674
ne_en Dev loss: 0.4087 r:0.7390
ru_en Dev loss: 0.4020 r:0.7622
Current avg r:0.6001 Best avg r: 0.6252
10:19:32,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:02,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:32,962 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1191
en_de Dev loss: 0.9171 r:0.1737
en_zh Dev loss: 0.8379 r:0.4427
ro_en Dev loss: 0.3555 r:0.8137
et_en Dev loss: 0.4655 r:0.6520
si_en Dev loss: 0.9081 r:0.5452
ne_en Dev loss: 0.4250 r:0.7311
ru_en Dev loss: 0.5012 r:0.7205
Current avg r:0.5827 Best avg r: 0.6252
10:27:01,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:31,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:01,848 root INFO Epoch 10 Global steps: 110600 Train loss: 0.1133
en_de Dev loss: 0.9594 r:0.1768
en_zh Dev loss: 0.8668 r:0.4564
ro_en Dev loss: 0.3731 r:0.8216
et_en Dev loss: 0.5029 r:0.6576
si_en Dev loss: 0.9304 r:0.5534
ne_en Dev loss: 0.4246 r:0.7323
ru_en Dev loss: 0.4844 r:0.7516
Current avg r:0.5928 Best avg r: 0.6252
10:34:30,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:36:00,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:37:30,521 root INFO Epoch 10 Global steps: 111300 Train loss: 0.1127
en_de Dev loss: 0.9520 r:0.1577
en_zh Dev loss: 0.8363 r:0.4492
ro_en Dev loss: 0.3627 r:0.8223
et_en Dev loss: 0.5002 r:0.6604
si_en Dev loss: 0.8650 r:0.5593
ne_en Dev loss: 0.4132 r:0.7313
ru_en Dev loss: 0.4732 r:0.7445
Current avg r:0.5892 Best avg r: 0.6252
