14:38:37,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:39:02,930 root INFO 
id:en_zh cur r: 0.2668 best r: 0.2668
14:39:15,910 root INFO 
id:ro_en cur r: 0.4899 best r: 0.4899
14:39:28,899 root INFO 
id:et_en cur r: 0.5192 best r: 0.5192
14:39:41,895 root INFO 
id:si_en cur r: 0.4764 best r: 0.4764
14:39:56,263 root INFO 
id:ne_en cur r: 0.5697 best r: 0.5697
14:40:22,65 root INFO 
id:ru_en cur r: 0.4376 best r: 0.4376
14:40:22,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:41:52,734 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
14:41:52,741 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:41:52,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:41:52,751 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
14:41:52,756 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
14:41:52,761 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:41:52,766 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:42:05,670 root INFO Epoch 0 Global steps: 700 Train loss: 0.8070
en_de Dev loss: 0.8919 r:0.0850
en_zh Dev loss: 0.7744 r:0.2507
ro_en Dev loss: 0.6164 r:0.6031
et_en Dev loss: 0.6136 r:0.4879
si_en Dev loss: 0.6729 r:0.4932
ne_en Dev loss: 0.6047 r:0.6017
ru_en Dev loss: 0.6567 r:0.4765
Current avg r:0.4283 Best avg r: 0.4283
14:46:37,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:47:03,776 root INFO 
id:en_zh cur r: 0.2998 best r: 0.2998
14:47:16,756 root INFO 
id:ro_en cur r: 0.6166 best r: 0.6166
14:47:29,739 root INFO 
id:et_en cur r: 0.5387 best r: 0.5387
14:47:55,733 root INFO 
id:ne_en cur r: 0.5785 best r: 0.5785
14:48:21,566 root INFO 
id:ru_en cur r: 0.6220 best r: 0.6220
14:48:21,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:52,257 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
14:49:52,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:49:52,270 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:49:52,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
14:49:52,279 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
14:49:52,284 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:49:52,289 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:50:05,200 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7680
en_de Dev loss: 0.9283 r:0.1029
en_zh Dev loss: 0.7694 r:0.2986
ro_en Dev loss: 0.6729 r:0.6688
et_en Dev loss: 0.4716 r:0.6311
si_en Dev loss: 0.7836 r:0.4832
ne_en Dev loss: 0.5253 r:0.6311
ru_en Dev loss: 0.6341 r:0.6583
Current avg r:0.4963 Best avg r: 0.4963
14:54:37,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:50,254 root INFO 
id:en_de cur r: 0.0645 best r: 0.0645
14:55:03,200 root INFO 
id:en_zh cur r: 0.3079 best r: 0.3079
14:55:16,176 root INFO 
id:ro_en cur r: 0.6558 best r: 0.6558
14:55:29,176 root INFO 
id:et_en cur r: 0.6398 best r: 0.6398
14:55:42,170 root INFO 
id:si_en cur r: 0.5030 best r: 0.5030
14:55:55,163 root INFO 
id:ne_en cur r: 0.6407 best r: 0.6407
14:56:21,3 root INFO 
id:ru_en cur r: 0.6746 best r: 0.6746
14:56:21,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:51,705 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
14:57:51,713 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:57:51,720 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:57:51,726 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
14:57:51,731 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
14:57:51,736 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:57:51,744 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:58:04,664 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7224
en_de Dev loss: 0.9994 r:0.1202
en_zh Dev loss: 0.8383 r:0.3074
ro_en Dev loss: 0.6633 r:0.6887
et_en Dev loss: 0.4534 r:0.6665
si_en Dev loss: 0.8144 r:0.5168
ne_en Dev loss: 0.4857 r:0.6673
ru_en Dev loss: 0.6335 r:0.6989
Current avg r:0.5237 Best avg r: 0.5237
15:02:36,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:15,651 root INFO 
id:ro_en cur r: 0.6835 best r: 0.6835
15:03:28,637 root INFO 
id:et_en cur r: 0.6448 best r: 0.6448
15:03:41,640 root INFO 
id:si_en cur r: 0.5257 best r: 0.5257
15:03:54,634 root INFO 
id:ne_en cur r: 0.6733 best r: 0.6733
15:04:20,455 root INFO 
id:ru_en cur r: 0.6885 best r: 0.6885
15:04:20,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:51,133 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:05:51,140 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:05:51,145 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:05:51,150 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:05:51,154 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:05:51,159 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:05:51,164 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:06:04,66 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7007
en_de Dev loss: 0.9383 r:0.1342
en_zh Dev loss: 0.7512 r:0.3418
ro_en Dev loss: 0.5433 r:0.6950
et_en Dev loss: 0.4102 r:0.6773
si_en Dev loss: 0.6682 r:0.5381
ne_en Dev loss: 0.4155 r:0.6979
ru_en Dev loss: 0.5438 r:0.7176
Current avg r:0.5431 Best avg r: 0.5431
15:10:36,153 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:49,129 root INFO 
id:en_de cur r: 0.0795 best r: 0.0795
15:11:15,54 root INFO 
id:ro_en cur r: 0.7047 best r: 0.7047
15:11:28,47 root INFO 
id:et_en cur r: 0.6753 best r: 0.6753
15:11:41,34 root INFO 
id:si_en cur r: 0.5265 best r: 0.5265
15:12:06,926 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:37,608 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6376
en_de Dev loss: 0.9568 r:0.1311
en_zh Dev loss: 0.8025 r:0.3241
ro_en Dev loss: 0.5435 r:0.7182
et_en Dev loss: 0.4159 r:0.6884
si_en Dev loss: 0.7649 r:0.5400
ne_en Dev loss: 0.4848 r:0.6798
ru_en Dev loss: 0.6046 r:0.6904
Current avg r:0.5389 Best avg r: 0.5431
15:18:09,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:22,578 root INFO 
id:en_de cur r: 0.0944 best r: 0.0944
15:18:48,499 root INFO 
id:ro_en cur r: 0.7059 best r: 0.7059
15:19:01,480 root INFO 
id:et_en cur r: 0.6932 best r: 0.6932
15:19:14,466 root INFO 
id:si_en cur r: 0.5359 best r: 0.5359
15:19:27,466 root INFO 
id:ne_en cur r: 0.6871 best r: 0.6871
15:19:40,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:10,976 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:21:10,984 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:21:10,989 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:21:10,994 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:21:10,999 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:21:11,5 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:21:11,10 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:21:23,914 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6244
en_de Dev loss: 0.9564 r:0.1394
en_zh Dev loss: 0.7892 r:0.3362
ro_en Dev loss: 0.4682 r:0.7168
et_en Dev loss: 0.3660 r:0.7017
si_en Dev loss: 0.6634 r:0.5450
ne_en Dev loss: 0.4734 r:0.6843
ru_en Dev loss: 0.5403 r:0.6890
Current avg r:0.5446 Best avg r: 0.5446
15:25:55,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:08,570 root INFO 
id:en_de cur r: 0.1222 best r: 0.1222
15:26:21,517 root INFO 
id:en_zh cur r: 0.3326 best r: 0.3326
15:26:34,492 root INFO 
id:ro_en cur r: 0.7429 best r: 0.7429
15:26:47,479 root INFO 
id:et_en cur r: 0.7015 best r: 0.7015
15:27:00,475 root INFO 
id:si_en cur r: 0.5694 best r: 0.5694
15:27:13,462 root INFO 
id:ne_en cur r: 0.7219 best r: 0.7219
15:27:26,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:57,77 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:28:57,83 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:28:57,87 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:28:57,92 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:28:57,97 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:28:57,101 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:28:57,107 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:29:10,14 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5519
en_de Dev loss: 0.9108 r:0.1664
en_zh Dev loss: 0.7334 r:0.3671
ro_en Dev loss: 0.3888 r:0.7497
et_en Dev loss: 0.3544 r:0.7099
si_en Dev loss: 0.5811 r:0.5678
ne_en Dev loss: 0.3956 r:0.7174
ru_en Dev loss: 0.4395 r:0.7120
Current avg r:0.5700 Best avg r: 0.5700
15:33:42,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:07,976 root INFO 
id:en_zh cur r: 0.3497 best r: 0.3497
15:34:20,955 root INFO 
id:ro_en cur r: 0.7498 best r: 0.7498
15:35:12,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:43,581 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5382
en_de Dev loss: 0.9830 r:0.1776
en_zh Dev loss: 0.7919 r:0.3765
ro_en Dev loss: 0.4543 r:0.7559
et_en Dev loss: 0.3796 r:0.7018
si_en Dev loss: 0.7566 r:0.5555
ne_en Dev loss: 0.4947 r:0.7162
ru_en Dev loss: 0.5847 r:0.6730
Current avg r:0.5652 Best avg r: 0.5700
15:41:15,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:28,628 root INFO 
id:en_de cur r: 0.1458 best r: 0.1458
15:41:41,561 root INFO 
id:en_zh cur r: 0.4002 best r: 0.4002
15:41:54,538 root INFO 
id:ro_en cur r: 0.7789 best r: 0.7789
15:42:07,522 root INFO 
id:et_en cur r: 0.7072 best r: 0.7072
15:42:20,509 root INFO 
id:si_en cur r: 0.5705 best r: 0.5705
15:42:33,491 root INFO 
id:ne_en cur r: 0.7348 best r: 0.7348
15:42:46,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:17,194 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:44:17,201 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:44:17,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:44:17,210 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:44:17,215 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:44:17,219 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:44:17,224 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:44:30,155 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5511
en_de Dev loss: 0.9255 r:0.1764
en_zh Dev loss: 0.7212 r:0.4108
ro_en Dev loss: 0.4065 r:0.7821
et_en Dev loss: 0.3816 r:0.7126
si_en Dev loss: 0.7228 r:0.5702
ne_en Dev loss: 0.4777 r:0.7309
ru_en Dev loss: 0.5437 r:0.6985
Current avg r:0.5831 Best avg r: 0.5831
15:49:02,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:15,117 root INFO 
id:en_de cur r: 0.1606 best r: 0.1606
15:49:28,64 root INFO 
id:en_zh cur r: 0.4081 best r: 0.4081
15:50:20,75 root INFO 
id:ne_en cur r: 0.7400 best r: 0.7400
15:50:32,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:03,895 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5405
en_de Dev loss: 0.9397 r:0.1883
en_zh Dev loss: 0.7366 r:0.4147
ro_en Dev loss: 0.4127 r:0.7796
et_en Dev loss: 0.3895 r:0.7042
si_en Dev loss: 0.8292 r:0.5543
ne_en Dev loss: 0.4915 r:0.7336
ru_en Dev loss: 0.5401 r:0.6892
Current avg r:0.5806 Best avg r: 0.5831
15:56:35,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:48,702 root INFO 
id:en_de cur r: 0.1633 best r: 0.1633
15:57:14,602 root INFO 
id:ro_en cur r: 0.7857 best r: 0.7857
15:57:27,581 root INFO 
id:et_en cur r: 0.7132 best r: 0.7132
15:57:40,578 root INFO 
id:si_en cur r: 0.5765 best r: 0.5765
15:57:53,564 root INFO 
id:ne_en cur r: 0.7408 best r: 0.7408
15:58:06,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:37,90 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:59:37,97 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:59:37,102 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:59:37,106 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:59:37,112 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:59:37,116 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:59:37,121 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:59:50,4 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5577
en_de Dev loss: 0.9026 r:0.1745
en_zh Dev loss: 0.7127 r:0.4181
ro_en Dev loss: 0.3359 r:0.7897
et_en Dev loss: 0.3468 r:0.7147
si_en Dev loss: 0.6241 r:0.5739
ne_en Dev loss: 0.4016 r:0.7366
ru_en Dev loss: 0.5175 r:0.6863
Current avg r:0.5848 Best avg r: 0.5848
16:04:21,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:34,703 root INFO 
id:en_de cur r: 0.1718 best r: 0.1718
16:04:47,633 root INFO 
id:en_zh cur r: 0.4291 best r: 0.4291
16:05:00,602 root INFO 
id:ro_en cur r: 0.7993 best r: 0.7993
16:05:13,594 root INFO 
id:et_en cur r: 0.7215 best r: 0.7215
16:05:26,580 root INFO 
id:si_en cur r: 0.6043 best r: 0.6043
16:05:39,560 root INFO 
id:ne_en cur r: 0.7501 best r: 0.7501
16:06:05,327 root INFO 
id:ru_en cur r: 0.6904 best r: 0.6904
16:06:05,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:35,966 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:07:35,973 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:07:35,977 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:07:35,982 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:07:35,986 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:07:35,994 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:07:35,999 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:07:48,895 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5121
en_de Dev loss: 0.8965 r:0.1749
en_zh Dev loss: 0.6802 r:0.4382
ro_en Dev loss: 0.3280 r:0.8042
et_en Dev loss: 0.3391 r:0.7252
si_en Dev loss: 0.6154 r:0.5956
ne_en Dev loss: 0.3905 r:0.7499
ru_en Dev loss: 0.4763 r:0.7056
Current avg r:0.5991 Best avg r: 0.5991
16:12:20,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:12,577 root INFO 
id:et_en cur r: 0.7231 best r: 0.7231
16:13:38,520 root INFO 
id:ne_en cur r: 0.7544 best r: 0.7544
16:13:51,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:22,43 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5048
en_de Dev loss: 0.9008 r:0.1815
en_zh Dev loss: 0.7405 r:0.4304
ro_en Dev loss: 0.3786 r:0.7997
et_en Dev loss: 0.3563 r:0.7252
si_en Dev loss: 0.7538 r:0.5852
ne_en Dev loss: 0.5371 r:0.7477
ru_en Dev loss: 0.5511 r:0.6868
Current avg r:0.5938 Best avg r: 0.5991
16:19:53,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:08,134 root INFO 
id:en_de cur r: 0.1943 best r: 0.1943
16:20:21,71 root INFO 
id:en_zh cur r: 0.4322 best r: 0.4322
16:20:34,44 root INFO 
id:ro_en cur r: 0.8034 best r: 0.8034
16:21:25,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:56,722 root INFO Epoch 0 Global steps: 9800 Train loss: 0.4789
en_de Dev loss: 0.9021 r:0.1914
en_zh Dev loss: 0.7345 r:0.4435
ro_en Dev loss: 0.3536 r:0.8068
et_en Dev loss: 0.3484 r:0.7231
si_en Dev loss: 0.6676 r:0.5926
ne_en Dev loss: 0.4030 r:0.7522
ru_en Dev loss: 0.5644 r:0.6804
Current avg r:0.5986 Best avg r: 0.5991
16:27:28,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:41,644 root INFO 
id:en_de cur r: 0.2087 best r: 0.2087
16:28:07,605 root INFO 
id:ro_en cur r: 0.8057 best r: 0.8057
16:28:46,636 root INFO 
id:ne_en cur r: 0.7650 best r: 0.7650
16:28:59,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:30,390 root INFO Epoch 0 Global steps: 10500 Train loss: 0.4819
en_de Dev loss: 0.8692 r:0.2028
en_zh Dev loss: 0.7290 r:0.4434
ro_en Dev loss: 0.3326 r:0.8051
et_en Dev loss: 0.3468 r:0.7190
si_en Dev loss: 0.6819 r:0.5826
ne_en Dev loss: 0.4156 r:0.7530
ru_en Dev loss: 0.5074 r:0.6875
Current avg r:0.5991 Best avg r: 0.5991
16:35:04,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:30,29 root INFO 
id:en_zh cur r: 0.4380 best r: 0.4380
16:35:42,999 root INFO 
id:ro_en cur r: 0.8082 best r: 0.8082
16:36:34,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:05,634 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4736
en_de Dev loss: 0.8718 r:0.1746
en_zh Dev loss: 0.7041 r:0.4461
ro_en Dev loss: 0.3224 r:0.8085
et_en Dev loss: 0.3487 r:0.7168
si_en Dev loss: 0.6634 r:0.5860
ne_en Dev loss: 0.4105 r:0.7515
ru_en Dev loss: 0.4941 r:0.6945
Current avg r:0.5968 Best avg r: 0.5991
16:42:37,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:03,673 root INFO 
id:en_zh cur r: 0.4599 best r: 0.4599
16:43:16,669 root INFO 
id:ro_en cur r: 0.8118 best r: 0.8118
16:43:42,680 root INFO 
id:si_en cur r: 0.6120 best r: 0.6120
16:44:21,509 root INFO 
id:ru_en cur r: 0.7195 best r: 0.7195
16:44:21,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:52,402 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:45:52,408 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:45:52,415 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:45:52,420 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:45:52,426 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:45:52,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:45:52,436 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:46:05,362 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4409
en_de Dev loss: 0.8720 r:0.1972
en_zh Dev loss: 0.6626 r:0.4652
ro_en Dev loss: 0.3202 r:0.8114
et_en Dev loss: 0.3453 r:0.7246
si_en Dev loss: 0.6415 r:0.6067
ne_en Dev loss: 0.3770 r:0.7588
ru_en Dev loss: 0.4537 r:0.7244
Current avg r:0.6126 Best avg r: 0.6126
16:50:37,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:16,65 root INFO 
id:ro_en cur r: 0.8146 best r: 0.8146
16:51:29,30 root INFO 
id:et_en cur r: 0.7231 best r: 0.7231
16:52:07,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:38,566 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:53:38,573 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:53:38,578 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:53:38,583 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:53:38,588 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:53:38,592 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:53:38,597 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:53:51,503 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4623
en_de Dev loss: 0.8682 r:0.2135
en_zh Dev loss: 0.6911 r:0.4606
ro_en Dev loss: 0.3353 r:0.8131
et_en Dev loss: 0.3367 r:0.7271
si_en Dev loss: 0.6689 r:0.6045
ne_en Dev loss: 0.3719 r:0.7616
ru_en Dev loss: 0.4892 r:0.7138
Current avg r:0.6135 Best avg r: 0.6135
16:58:22,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:35,846 root INFO 
id:en_de cur r: 0.2115 best r: 0.2115
16:59:53,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:24,100 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4279
en_de Dev loss: 0.8627 r:0.2226
en_zh Dev loss: 0.7205 r:0.4593
ro_en Dev loss: 0.3365 r:0.8125
et_en Dev loss: 0.3516 r:0.7264
si_en Dev loss: 0.7306 r:0.6026
ne_en Dev loss: 0.4284 r:0.7567
ru_en Dev loss: 0.5313 r:0.7021
Current avg r:0.6117 Best avg r: 0.6135
17:05:55,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:21,315 root INFO 
id:en_zh cur r: 0.4711 best r: 0.4711
17:06:34,272 root INFO 
id:ro_en cur r: 0.8163 best r: 0.8163
17:07:00,219 root INFO 
id:si_en cur r: 0.6151 best r: 0.6151
17:07:13,193 root INFO 
id:ne_en cur r: 0.7676 best r: 0.7676
17:07:26,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:56,654 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
17:08:56,662 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:08:56,667 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:08:56,671 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
17:08:56,676 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
17:08:56,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:08:56,687 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:09:09,575 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4227
en_de Dev loss: 0.8593 r:0.2160
en_zh Dev loss: 0.6584 r:0.4702
ro_en Dev loss: 0.3003 r:0.8174
et_en Dev loss: 0.3447 r:0.7276
si_en Dev loss: 0.5975 r:0.6146
ne_en Dev loss: 0.3540 r:0.7663
ru_en Dev loss: 0.4419 r:0.7227
Current avg r:0.6193 Best avg r: 0.6193
17:13:40,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:19,761 root INFO 
id:ro_en cur r: 0.8215 best r: 0.8215
17:15:11,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:42,111 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4614
en_de Dev loss: 0.8675 r:0.2150
en_zh Dev loss: 0.6938 r:0.4625
ro_en Dev loss: 0.3095 r:0.8183
et_en Dev loss: 0.3408 r:0.7269
si_en Dev loss: 0.6600 r:0.6142
ne_en Dev loss: 0.4405 r:0.7616
ru_en Dev loss: 0.4736 r:0.7163
Current avg r:0.6164 Best avg r: 0.6193
17:21:13,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:43,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:14,141 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4473
en_de Dev loss: 0.8826 r:0.2090
en_zh Dev loss: 0.7332 r:0.4696
ro_en Dev loss: 0.3613 r:0.8138
et_en Dev loss: 0.3834 r:0.7174
si_en Dev loss: 0.8285 r:0.5942
ne_en Dev loss: 0.5242 r:0.7596
ru_en Dev loss: 0.5895 r:0.6853
Current avg r:0.6070 Best avg r: 0.6193
17:28:45,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:15,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:46,384 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4233
en_de Dev loss: 0.8515 r:0.2092
en_zh Dev loss: 0.6691 r:0.4690
ro_en Dev loss: 0.2914 r:0.8188
et_en Dev loss: 0.3404 r:0.7253
si_en Dev loss: 0.6495 r:0.5970
ne_en Dev loss: 0.3559 r:0.7616
ru_en Dev loss: 0.4627 r:0.7040
Current avg r:0.6121 Best avg r: 0.6193
17:36:17,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:56,434 root INFO 
id:ro_en cur r: 0.8294 best r: 0.8294
17:37:22,369 root INFO 
id:si_en cur r: 0.6157 best r: 0.6157
17:37:35,338 root INFO 
id:ne_en cur r: 0.7764 best r: 0.7764
17:37:48,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:18,783 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4566
en_de Dev loss: 0.8802 r:0.2174
en_zh Dev loss: 0.6990 r:0.4706
ro_en Dev loss: 0.3011 r:0.8227
et_en Dev loss: 0.3482 r:0.7219
si_en Dev loss: 0.6680 r:0.6070
ne_en Dev loss: 0.3312 r:0.7696
ru_en Dev loss: 0.4798 r:0.7148
Current avg r:0.6177 Best avg r: 0.6193
17:43:50,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:20,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:51,211 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4543
en_de Dev loss: 0.8698 r:0.2115
en_zh Dev loss: 0.7111 r:0.4724
ro_en Dev loss: 0.3458 r:0.8138
et_en Dev loss: 0.3707 r:0.7191
si_en Dev loss: 0.7433 r:0.6044
ne_en Dev loss: 0.3660 r:0.7656
ru_en Dev loss: 0.4912 r:0.7188
Current avg r:0.6151 Best avg r: 0.6193
17:51:22,486 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:48,364 root INFO 
id:en_zh cur r: 0.4795 best r: 0.4795
17:52:14,287 root INFO 
id:et_en cur r: 0.7235 best r: 0.7235
17:52:27,255 root INFO 
id:si_en cur r: 0.6292 best r: 0.6292
17:53:06,12 root INFO 
id:ru_en cur r: 0.7292 best r: 0.7292
17:53:06,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:36,597 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
17:54:36,606 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:54:36,610 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:54:36,615 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
17:54:36,622 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
17:54:36,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:54:36,634 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.05_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:54:49,521 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4228
en_de Dev loss: 0.8491 r:0.2145
en_zh Dev loss: 0.6357 r:0.4798
ro_en Dev loss: 0.2833 r:0.8253
et_en Dev loss: 0.3658 r:0.7257
si_en Dev loss: 0.5632 r:0.6185
ne_en Dev loss: 0.3305 r:0.7682
ru_en Dev loss: 0.3950 r:0.7326
Current avg r:0.6235 Best avg r: 0.6235
17:59:20,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:51,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:23,339 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4461
en_de Dev loss: 0.8423 r:0.2271
en_zh Dev loss: 0.6462 r:0.4815
ro_en Dev loss: 0.2806 r:0.8242
et_en Dev loss: 0.3436 r:0.7253
si_en Dev loss: 0.6001 r:0.6152
ne_en Dev loss: 0.3474 r:0.7646
ru_en Dev loss: 0.4343 r:0.7216
Current avg r:0.6228 Best avg r: 0.6235
18:06:54,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:07,453 root INFO 
id:en_de cur r: 0.2230 best r: 0.2230
18:07:20,378 root INFO 
id:en_zh cur r: 0.4825 best r: 0.4825
18:08:25,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:55,657 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4431
en_de Dev loss: 0.8437 r:0.2303
en_zh Dev loss: 0.6483 r:0.4863
ro_en Dev loss: 0.2964 r:0.8218
et_en Dev loss: 0.3738 r:0.7206
si_en Dev loss: 0.5717 r:0.6119
ne_en Dev loss: 0.3480 r:0.7636
ru_en Dev loss: 0.4567 r:0.7087
Current avg r:0.6204 Best avg r: 0.6235
18:14:26,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:15:57,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:27,944 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4066
en_de Dev loss: 0.8919 r:0.1942
en_zh Dev loss: 0.7209 r:0.4828
ro_en Dev loss: 0.3222 r:0.8242
et_en Dev loss: 0.3496 r:0.7238
si_en Dev loss: 0.6538 r:0.6178
ne_en Dev loss: 0.3804 r:0.7617
ru_en Dev loss: 0.5324 r:0.7052
Current avg r:0.6157 Best avg r: 0.6235
18:21:59,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:29,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:00,200 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4194
en_de Dev loss: 0.9011 r:0.1476
en_zh Dev loss: 0.7348 r:0.4769
ro_en Dev loss: 0.3360 r:0.8190
et_en Dev loss: 0.3601 r:0.7148
si_en Dev loss: 0.6927 r:0.6137
ne_en Dev loss: 0.4295 r:0.7658
ru_en Dev loss: 0.5411 r:0.6924
Current avg r:0.6043 Best avg r: 0.6235
18:29:32,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:03,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:33,937 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4014
en_de Dev loss: 0.8739 r:0.1995
en_zh Dev loss: 0.7347 r:0.4747
ro_en Dev loss: 0.3511 r:0.8155
et_en Dev loss: 0.3701 r:0.7082
si_en Dev loss: 0.7466 r:0.6067
ne_en Dev loss: 0.4327 r:0.7609
ru_en Dev loss: 0.5510 r:0.6967
Current avg r:0.6089 Best avg r: 0.6235
18:37:04,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:38:35,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:06,5 root INFO Epoch 2 Global steps: 22400 Train loss: 0.3889
en_de Dev loss: 0.8770 r:0.2125
en_zh Dev loss: 0.7466 r:0.4640
ro_en Dev loss: 0.3185 r:0.8188
et_en Dev loss: 0.3586 r:0.7152
si_en Dev loss: 0.6700 r:0.6158
ne_en Dev loss: 0.3742 r:0.7675
ru_en Dev loss: 0.5138 r:0.7021
Current avg r:0.6137 Best avg r: 0.6235
18:44:36,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:07,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:37,994 root INFO Epoch 2 Global steps: 23100 Train loss: 0.3745
en_de Dev loss: 0.8985 r:0.2200
en_zh Dev loss: 0.7375 r:0.4692
ro_en Dev loss: 0.3534 r:0.8197
et_en Dev loss: 0.3721 r:0.7162
si_en Dev loss: 0.7007 r:0.6186
ne_en Dev loss: 0.3958 r:0.7617
ru_en Dev loss: 0.5371 r:0.7081
Current avg r:0.6162 Best avg r: 0.6235
18:52:08,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:21,923 root INFO 
id:en_de cur r: 0.2360 best r: 0.2360
18:53:39,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:10,64 root INFO Epoch 2 Global steps: 23800 Train loss: 0.3956
en_de Dev loss: 0.8798 r:0.2205
en_zh Dev loss: 0.7839 r:0.4517
ro_en Dev loss: 0.3425 r:0.8101
et_en Dev loss: 0.3641 r:0.7103
si_en Dev loss: 0.7990 r:0.5989
ne_en Dev loss: 0.5025 r:0.7573
ru_en Dev loss: 0.5839 r:0.6799
Current avg r:0.6041 Best avg r: 0.6235
18:59:40,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:11,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:41,826 root INFO Epoch 2 Global steps: 24500 Train loss: 0.3652
en_de Dev loss: 0.8422 r:0.2265
en_zh Dev loss: 0.6634 r:0.4778
ro_en Dev loss: 0.2970 r:0.8209
et_en Dev loss: 0.3639 r:0.7122
si_en Dev loss: 0.6339 r:0.6130
ne_en Dev loss: 0.4165 r:0.7576
ru_en Dev loss: 0.4764 r:0.7018
Current avg r:0.6157 Best avg r: 0.6235
19:07:12,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:43,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:13,661 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4101
en_de Dev loss: 0.8875 r:0.1934
en_zh Dev loss: 0.7375 r:0.4696
ro_en Dev loss: 0.3372 r:0.8169
et_en Dev loss: 0.3892 r:0.7026
si_en Dev loss: 0.7514 r:0.6063
ne_en Dev loss: 0.3961 r:0.7615
ru_en Dev loss: 0.5179 r:0.7061
Current avg r:0.6081 Best avg r: 0.6235
19:14:44,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:15,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:45,582 root INFO Epoch 2 Global steps: 25900 Train loss: 0.3726
en_de Dev loss: 0.8575 r:0.2161
en_zh Dev loss: 0.6978 r:0.4716
ro_en Dev loss: 0.3037 r:0.8219
et_en Dev loss: 0.3748 r:0.7064
si_en Dev loss: 0.6822 r:0.5946
ne_en Dev loss: 0.3754 r:0.7594
ru_en Dev loss: 0.4734 r:0.7110
Current avg r:0.6116 Best avg r: 0.6235
19:22:16,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:47,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:17,497 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3749
en_de Dev loss: 0.8887 r:0.1912
en_zh Dev loss: 0.7535 r:0.4743
ro_en Dev loss: 0.3414 r:0.8189
et_en Dev loss: 0.3723 r:0.7055
si_en Dev loss: 0.7497 r:0.5970
ne_en Dev loss: 0.4844 r:0.7511
ru_en Dev loss: 0.5552 r:0.6944
Current avg r:0.6046 Best avg r: 0.6235
19:29:48,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:31:18,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:49,508 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3620
en_de Dev loss: 0.8909 r:0.1532
en_zh Dev loss: 0.7253 r:0.4742
ro_en Dev loss: 0.3036 r:0.8240
et_en Dev loss: 0.3720 r:0.7041
si_en Dev loss: 0.6526 r:0.6091
ne_en Dev loss: 0.3781 r:0.7596
ru_en Dev loss: 0.5112 r:0.6986
Current avg r:0.6033 Best avg r: 0.6235
19:37:20,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:50,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:21,492 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3831
en_de Dev loss: 0.8742 r:0.2022
en_zh Dev loss: 0.7745 r:0.4554
ro_en Dev loss: 0.3693 r:0.8151
et_en Dev loss: 0.3987 r:0.6954
si_en Dev loss: 0.8367 r:0.5842
ne_en Dev loss: 0.6220 r:0.7446
ru_en Dev loss: 0.6008 r:0.6831
Current avg r:0.5971 Best avg r: 0.6235
19:44:52,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:23,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:53,545 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3600
en_de Dev loss: 0.8923 r:0.1897
en_zh Dev loss: 0.7909 r:0.4602
ro_en Dev loss: 0.3430 r:0.8255
et_en Dev loss: 0.3861 r:0.7030
si_en Dev loss: 0.7184 r:0.6090
ne_en Dev loss: 0.4163 r:0.7614
ru_en Dev loss: 0.5123 r:0.7187
Current avg r:0.6096 Best avg r: 0.6235
19:52:24,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:55,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:25,558 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3730
en_de Dev loss: 0.8817 r:0.1677
en_zh Dev loss: 0.7381 r:0.4640
ro_en Dev loss: 0.3188 r:0.8250
et_en Dev loss: 0.3692 r:0.7059
si_en Dev loss: 0.6824 r:0.6129
ne_en Dev loss: 0.3933 r:0.7610
ru_en Dev loss: 0.5191 r:0.7029
Current avg r:0.6056 Best avg r: 0.6235
19:59:56,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:35,327 root INFO 
id:ro_en cur r: 0.8298 best r: 0.8298
20:01:27,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:57,586 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3457
en_de Dev loss: 0.8611 r:0.2064
en_zh Dev loss: 0.7041 r:0.4670
ro_en Dev loss: 0.2949 r:0.8290
et_en Dev loss: 0.3724 r:0.7150
si_en Dev loss: 0.6506 r:0.6146
ne_en Dev loss: 0.3833 r:0.7652
ru_en Dev loss: 0.4939 r:0.7087
Current avg r:0.6151 Best avg r: 0.6235
20:07:28,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:58,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:29,439 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3539
en_de Dev loss: 0.8419 r:0.2311
en_zh Dev loss: 0.6697 r:0.4737
ro_en Dev loss: 0.2915 r:0.8266
et_en Dev loss: 0.3899 r:0.7052
si_en Dev loss: 0.6119 r:0.6067
ne_en Dev loss: 0.3760 r:0.7636
ru_en Dev loss: 0.4575 r:0.7100
Current avg r:0.6167 Best avg r: 0.6235
20:15:00,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:31,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:01,614 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3593
en_de Dev loss: 0.8729 r:0.2029
en_zh Dev loss: 0.7637 r:0.4466
ro_en Dev loss: 0.3450 r:0.8158
et_en Dev loss: 0.3829 r:0.6916
si_en Dev loss: 0.8245 r:0.5827
ne_en Dev loss: 0.4744 r:0.7581
ru_en Dev loss: 0.5526 r:0.6837
Current avg r:0.5973 Best avg r: 0.6235
20:22:34,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:04,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:35,70 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3260
en_de Dev loss: 0.8751 r:0.2241
en_zh Dev loss: 0.7798 r:0.4340
ro_en Dev loss: 0.3527 r:0.8096
et_en Dev loss: 0.4048 r:0.6944
si_en Dev loss: 0.7470 r:0.5838
ne_en Dev loss: 0.4030 r:0.7571
ru_en Dev loss: 0.5155 r:0.7015
Current avg r:0.6006 Best avg r: 0.6235
20:30:05,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:36,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:07,65 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3195
en_de Dev loss: 0.8595 r:0.2257
en_zh Dev loss: 0.7605 r:0.4531
ro_en Dev loss: 0.3497 r:0.8148
et_en Dev loss: 0.3943 r:0.6902
si_en Dev loss: 0.8020 r:0.5849
ne_en Dev loss: 0.4809 r:0.7558
ru_en Dev loss: 0.5493 r:0.6939
Current avg r:0.6026 Best avg r: 0.6235
20:37:38,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:08,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:39,178 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3207
en_de Dev loss: 0.8714 r:0.2241
en_zh Dev loss: 0.7486 r:0.4603
ro_en Dev loss: 0.3380 r:0.8211
et_en Dev loss: 0.4091 r:0.6995
si_en Dev loss: 0.7505 r:0.5967
ne_en Dev loss: 0.4172 r:0.7577
ru_en Dev loss: 0.4964 r:0.7096
Current avg r:0.6099 Best avg r: 0.6235
20:45:10,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:53,730 root INFO 
id:ru_en cur r: 0.7333 best r: 0.7333
20:46:53,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:24,332 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3278
en_de Dev loss: 0.8478 r:0.2279
en_zh Dev loss: 0.7095 r:0.4801
ro_en Dev loss: 0.3097 r:0.8231
et_en Dev loss: 0.4156 r:0.7117
si_en Dev loss: 0.6449 r:0.6014
ne_en Dev loss: 0.3611 r:0.7634
ru_en Dev loss: 0.4252 r:0.7313
Current avg r:0.6199 Best avg r: 0.6235
20:52:55,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:25,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:56,397 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3211
en_de Dev loss: 0.8605 r:0.2097
en_zh Dev loss: 0.7247 r:0.4521
ro_en Dev loss: 0.2988 r:0.8213
et_en Dev loss: 0.3898 r:0.6940
si_en Dev loss: 0.6679 r:0.5873
ne_en Dev loss: 0.3898 r:0.7536
ru_en Dev loss: 0.4816 r:0.6999
Current avg r:0.6026 Best avg r: 0.6235
21:00:27,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:57,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:28,201 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3211
en_de Dev loss: 0.8839 r:0.2128
en_zh Dev loss: 0.7570 r:0.4531
ro_en Dev loss: 0.3454 r:0.8189
et_en Dev loss: 0.4296 r:0.6881
si_en Dev loss: 0.7190 r:0.5915
ne_en Dev loss: 0.4109 r:0.7494
ru_en Dev loss: 0.5246 r:0.7017
Current avg r:0.6022 Best avg r: 0.6235
21:07:59,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:29,553 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:00,71 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3081
en_de Dev loss: 0.8691 r:0.2216
en_zh Dev loss: 0.7321 r:0.4520
ro_en Dev loss: 0.3119 r:0.8232
et_en Dev loss: 0.3884 r:0.6990
si_en Dev loss: 0.6986 r:0.5942
ne_en Dev loss: 0.4115 r:0.7554
ru_en Dev loss: 0.4896 r:0.7100
Current avg r:0.6079 Best avg r: 0.6235
21:15:30,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:01,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:31,944 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3195
en_de Dev loss: 0.8713 r:0.2217
en_zh Dev loss: 0.7802 r:0.4471
ro_en Dev loss: 0.3617 r:0.8132
et_en Dev loss: 0.4195 r:0.6870
si_en Dev loss: 0.7441 r:0.5941
ne_en Dev loss: 0.4453 r:0.7520
ru_en Dev loss: 0.5211 r:0.7035
Current avg r:0.6027 Best avg r: 0.6235
21:23:02,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:33,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:04,38 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3183
en_de Dev loss: 0.9014 r:0.1831
en_zh Dev loss: 0.7413 r:0.4707
ro_en Dev loss: 0.3648 r:0.8163
et_en Dev loss: 0.4172 r:0.6854
si_en Dev loss: 0.8504 r:0.5834
ne_en Dev loss: 0.5935 r:0.7508
ru_en Dev loss: 0.5769 r:0.6920
Current avg r:0.5974 Best avg r: 0.6235
21:30:34,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:05,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:36,88 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3122
en_de Dev loss: 0.8688 r:0.2390
en_zh Dev loss: 0.7793 r:0.4506
ro_en Dev loss: 0.3353 r:0.8194
et_en Dev loss: 0.4115 r:0.6917
si_en Dev loss: 0.7797 r:0.5847
ne_en Dev loss: 0.4549 r:0.7546
ru_en Dev loss: 0.5208 r:0.7095
Current avg r:0.6071 Best avg r: 0.6235
21:38:07,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:37,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:08,124 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3210
en_de Dev loss: 0.8487 r:0.2325
en_zh Dev loss: 0.7361 r:0.4643
ro_en Dev loss: 0.3243 r:0.8208
et_en Dev loss: 0.4267 r:0.6977
si_en Dev loss: 0.6968 r:0.5941
ne_en Dev loss: 0.3775 r:0.7558
ru_en Dev loss: 0.4973 r:0.7049
Current avg r:0.6100 Best avg r: 0.6235
21:45:38,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:09,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:40,35 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3115
en_de Dev loss: 0.8796 r:0.1882
en_zh Dev loss: 0.7530 r:0.4586
ro_en Dev loss: 0.3301 r:0.8190
et_en Dev loss: 0.3929 r:0.6970
si_en Dev loss: 0.7893 r:0.5844
ne_en Dev loss: 0.4338 r:0.7561
ru_en Dev loss: 0.5154 r:0.7068
Current avg r:0.6014 Best avg r: 0.6235
21:53:10,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:41,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:11,951 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3031
en_de Dev loss: 0.8960 r:0.1898
en_zh Dev loss: 0.7829 r:0.4490
ro_en Dev loss: 0.3515 r:0.8156
et_en Dev loss: 0.4346 r:0.6926
si_en Dev loss: 0.8006 r:0.5776
ne_en Dev loss: 0.4586 r:0.7441
ru_en Dev loss: 0.5413 r:0.6863
Current avg r:0.5936 Best avg r: 0.6235
22:00:42,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:13,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:43,835 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3195
en_de Dev loss: 0.8613 r:0.2216
en_zh Dev loss: 0.7575 r:0.4480
ro_en Dev loss: 0.3162 r:0.8230
et_en Dev loss: 0.3949 r:0.7055
si_en Dev loss: 0.7209 r:0.5913
ne_en Dev loss: 0.4133 r:0.7550
ru_en Dev loss: 0.4929 r:0.7068
Current avg r:0.6073 Best avg r: 0.6235
22:08:14,767 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:45,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:16,38 root INFO Epoch 3 Global steps: 42000 Train loss: 0.2925
en_de Dev loss: 0.8729 r:0.1841
en_zh Dev loss: 0.7600 r:0.4530
ro_en Dev loss: 0.3289 r:0.8193
et_en Dev loss: 0.4106 r:0.6932
si_en Dev loss: 0.7595 r:0.5819
ne_en Dev loss: 0.4438 r:0.7527
ru_en Dev loss: 0.4802 r:0.7101
Current avg r:0.5992 Best avg r: 0.6235
22:15:49,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:19,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:50,473 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2537
en_de Dev loss: 0.8886 r:0.1979
en_zh Dev loss: 0.8208 r:0.4397
ro_en Dev loss: 0.3557 r:0.8165
et_en Dev loss: 0.4545 r:0.6879
si_en Dev loss: 0.7270 r:0.5828
ne_en Dev loss: 0.4498 r:0.7457
ru_en Dev loss: 0.5288 r:0.6976
Current avg r:0.5954 Best avg r: 0.6235
22:23:22,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:52,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:23,721 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2611
en_de Dev loss: 0.8854 r:0.1876
en_zh Dev loss: 0.8312 r:0.4310
ro_en Dev loss: 0.3919 r:0.8034
et_en Dev loss: 0.4509 r:0.6706
si_en Dev loss: 0.8493 r:0.5609
ne_en Dev loss: 0.5246 r:0.7389
ru_en Dev loss: 0.5930 r:0.6691
Current avg r:0.5802 Best avg r: 0.6235
22:30:55,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:26,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:33:56,830 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2631
en_de Dev loss: 0.8916 r:0.1893
en_zh Dev loss: 0.7910 r:0.4329
ro_en Dev loss: 0.3620 r:0.8105
et_en Dev loss: 0.4278 r:0.6795
si_en Dev loss: 0.8160 r:0.5776
ne_en Dev loss: 0.4393 r:0.7519
ru_en Dev loss: 0.5412 r:0.6894
Current avg r:0.5902 Best avg r: 0.6235
22:38:28,510 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:39:59,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:29,993 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2708
en_de Dev loss: 0.8645 r:0.1958
en_zh Dev loss: 0.7372 r:0.4396
ro_en Dev loss: 0.3109 r:0.8178
et_en Dev loss: 0.4019 r:0.6946
si_en Dev loss: 0.6536 r:0.5916
ne_en Dev loss: 0.4102 r:0.7394
ru_en Dev loss: 0.4686 r:0.7052
Current avg r:0.5977 Best avg r: 0.6235
22:46:01,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:32,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:03,194 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2599
en_de Dev loss: 0.8969 r:0.1952
en_zh Dev loss: 0.8098 r:0.4313
ro_en Dev loss: 0.3781 r:0.8127
et_en Dev loss: 0.4428 r:0.6849
si_en Dev loss: 0.8210 r:0.5711
ne_en Dev loss: 0.5016 r:0.7412
ru_en Dev loss: 0.5477 r:0.6905
Current avg r:0.5895 Best avg r: 0.6235
22:53:34,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:05,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:36,346 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2589
en_de Dev loss: 0.8644 r:0.2192
en_zh Dev loss: 0.7524 r:0.4413
ro_en Dev loss: 0.3251 r:0.8165
et_en Dev loss: 0.4247 r:0.6872
si_en Dev loss: 0.7745 r:0.5695
ne_en Dev loss: 0.4465 r:0.7418
ru_en Dev loss: 0.4822 r:0.6961
Current avg r:0.5960 Best avg r: 0.6235
23:01:08,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:38,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:09,679 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2564
en_de Dev loss: 0.8668 r:0.2090
en_zh Dev loss: 0.7430 r:0.4501
ro_en Dev loss: 0.3260 r:0.8158
et_en Dev loss: 0.4276 r:0.6823
si_en Dev loss: 0.7188 r:0.5750
ne_en Dev loss: 0.4187 r:0.7364
ru_en Dev loss: 0.4930 r:0.7021
Current avg r:0.5958 Best avg r: 0.6235
23:08:41,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:12,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:43,87 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2586
en_de Dev loss: 0.8803 r:0.2061
en_zh Dev loss: 0.7696 r:0.4528
ro_en Dev loss: 0.3241 r:0.8203
et_en Dev loss: 0.4227 r:0.6968
si_en Dev loss: 0.6992 r:0.5841
ne_en Dev loss: 0.4071 r:0.7433
ru_en Dev loss: 0.4694 r:0.7161
Current avg r:0.6028 Best avg r: 0.6235
23:16:14,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:45,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:16,263 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2512
en_de Dev loss: 0.8890 r:0.1694
en_zh Dev loss: 0.7713 r:0.4563
ro_en Dev loss: 0.3478 r:0.8099
et_en Dev loss: 0.4258 r:0.6707
si_en Dev loss: 0.8160 r:0.5677
ne_en Dev loss: 0.5345 r:0.7312
ru_en Dev loss: 0.5223 r:0.6860
Current avg r:0.5845 Best avg r: 0.6235
23:23:47,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:18,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:48,618 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2696
en_de Dev loss: 0.8751 r:0.1816
en_zh Dev loss: 0.7599 r:0.4474
ro_en Dev loss: 0.3306 r:0.8197
et_en Dev loss: 0.4105 r:0.6892
si_en Dev loss: 0.7590 r:0.5810
ne_en Dev loss: 0.4918 r:0.7382
ru_en Dev loss: 0.4877 r:0.7098
Current avg r:0.5953 Best avg r: 0.6235
23:31:19,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:50,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:34:20,516 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2844
en_de Dev loss: 0.8635 r:0.1903
en_zh Dev loss: 0.7337 r:0.4550
ro_en Dev loss: 0.3143 r:0.8207
et_en Dev loss: 0.4277 r:0.6864
si_en Dev loss: 0.7595 r:0.5783
ne_en Dev loss: 0.4100 r:0.7405
ru_en Dev loss: 0.4663 r:0.7090
Current avg r:0.5972 Best avg r: 0.6235
23:38:51,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:22,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:52,901 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2588
en_de Dev loss: 0.8757 r:0.1934
en_zh Dev loss: 0.8042 r:0.4316
ro_en Dev loss: 0.3598 r:0.8119
et_en Dev loss: 0.4383 r:0.6644
si_en Dev loss: 0.9259 r:0.5586
ne_en Dev loss: 0.5974 r:0.7344
ru_en Dev loss: 0.5523 r:0.6837
Current avg r:0.5826 Best avg r: 0.6235
23:46:24,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:54,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:25,141 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2574
en_de Dev loss: 0.8965 r:0.1902
en_zh Dev loss: 0.8363 r:0.4292
ro_en Dev loss: 0.3635 r:0.8122
et_en Dev loss: 0.4446 r:0.6688
si_en Dev loss: 0.9161 r:0.5530
ne_en Dev loss: 0.5257 r:0.7338
ru_en Dev loss: 0.5565 r:0.6877
Current avg r:0.5821 Best avg r: 0.6235
23:53:56,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:26,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:57,280 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2547
en_de Dev loss: 0.8751 r:0.2102
en_zh Dev loss: 0.7885 r:0.4508
ro_en Dev loss: 0.3669 r:0.8180
et_en Dev loss: 0.4472 r:0.6713
si_en Dev loss: 0.9327 r:0.5631
ne_en Dev loss: 0.5410 r:0.7347
ru_en Dev loss: 0.5464 r:0.7004
Current avg r:0.5926 Best avg r: 0.6235
00:01:28,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:58,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:29,383 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2516
en_de Dev loss: 0.8625 r:0.2005
en_zh Dev loss: 0.7773 r:0.4517
ro_en Dev loss: 0.3414 r:0.8146
et_en Dev loss: 0.4356 r:0.6631
si_en Dev loss: 0.9513 r:0.5501
ne_en Dev loss: 0.5854 r:0.7320
ru_en Dev loss: 0.5308 r:0.6851
Current avg r:0.5853 Best avg r: 0.6235
00:09:01,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:32,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:02,624 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2132
en_de Dev loss: 0.8779 r:0.1960
en_zh Dev loss: 0.8056 r:0.4415
ro_en Dev loss: 0.3468 r:0.8154
et_en Dev loss: 0.4435 r:0.6664
si_en Dev loss: 0.9601 r:0.5433
ne_en Dev loss: 0.5492 r:0.7322
ru_en Dev loss: 0.5739 r:0.6778
Current avg r:0.5818 Best avg r: 0.6235
00:16:33,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:03,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:34,343 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2222
en_de Dev loss: 0.8692 r:0.2072
en_zh Dev loss: 0.7946 r:0.4586
ro_en Dev loss: 0.3476 r:0.8224
et_en Dev loss: 0.4603 r:0.6800
si_en Dev loss: 0.8794 r:0.5634
ne_en Dev loss: 0.4949 r:0.7372
ru_en Dev loss: 0.5187 r:0.7027
Current avg r:0.5959 Best avg r: 0.6235
00:24:05,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:25:35,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:06,217 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2149
en_de Dev loss: 0.8556 r:0.2139
en_zh Dev loss: 0.7489 r:0.4525
ro_en Dev loss: 0.3103 r:0.8234
et_en Dev loss: 0.4241 r:0.6838
si_en Dev loss: 0.7196 r:0.5681
ne_en Dev loss: 0.4564 r:0.7255
ru_en Dev loss: 0.4855 r:0.7036
Current avg r:0.5958 Best avg r: 0.6235
00:31:36,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:33:07,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:37,791 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2162
en_de Dev loss: 0.8903 r:0.1817
en_zh Dev loss: 0.7816 r:0.4510
ro_en Dev loss: 0.3492 r:0.8208
et_en Dev loss: 0.4392 r:0.6779
si_en Dev loss: 0.8362 r:0.5586
ne_en Dev loss: 0.4710 r:0.7337
ru_en Dev loss: 0.4910 r:0.7088
Current avg r:0.5903 Best avg r: 0.6235
00:39:08,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:39,34 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:09,510 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2284
en_de Dev loss: 0.9033 r:0.1843
en_zh Dev loss: 0.7728 r:0.4587
ro_en Dev loss: 0.3428 r:0.8223
et_en Dev loss: 0.4342 r:0.6848
si_en Dev loss: 0.8093 r:0.5659
ne_en Dev loss: 0.4416 r:0.7370
ru_en Dev loss: 0.5096 r:0.7130
Current avg r:0.5951 Best avg r: 0.6235
00:46:40,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:10,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:41,242 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2216
en_de Dev loss: 0.9142 r:0.1775
en_zh Dev loss: 0.7722 r:0.4585
ro_en Dev loss: 0.3515 r:0.8155
et_en Dev loss: 0.4489 r:0.6688
si_en Dev loss: 0.8747 r:0.5547
ne_en Dev loss: 0.4632 r:0.7341
ru_en Dev loss: 0.5095 r:0.7089
Current avg r:0.5883 Best avg r: 0.6235
00:54:11,980 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:42,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:12,971 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2237
en_de Dev loss: 0.9094 r:0.1740
en_zh Dev loss: 0.7986 r:0.4446
ro_en Dev loss: 0.3469 r:0.8138
et_en Dev loss: 0.4403 r:0.6614
si_en Dev loss: 0.8550 r:0.5452
ne_en Dev loss: 0.5256 r:0.7306
ru_en Dev loss: 0.5305 r:0.6955
Current avg r:0.5807 Best avg r: 0.6235
01:01:43,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:14,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:44,552 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2207
en_de Dev loss: 0.8837 r:0.1891
en_zh Dev loss: 0.8063 r:0.4325
ro_en Dev loss: 0.3344 r:0.8189
et_en Dev loss: 0.4307 r:0.6789
si_en Dev loss: 0.8446 r:0.5563
ne_en Dev loss: 0.5049 r:0.7360
ru_en Dev loss: 0.5165 r:0.7011
Current avg r:0.5875 Best avg r: 0.6235
01:09:15,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:45,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:16,125 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2191
en_de Dev loss: 0.8811 r:0.1944
en_zh Dev loss: 0.7390 r:0.4618
ro_en Dev loss: 0.3185 r:0.8221
et_en Dev loss: 0.4471 r:0.6806
si_en Dev loss: 0.7233 r:0.5698
ne_en Dev loss: 0.4211 r:0.7324
ru_en Dev loss: 0.4544 r:0.7134
Current avg r:0.5963 Best avg r: 0.6235
01:16:47,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:18:17,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:48,72 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2221
en_de Dev loss: 0.8855 r:0.1962
en_zh Dev loss: 0.7659 r:0.4502
ro_en Dev loss: 0.3500 r:0.8132
et_en Dev loss: 0.4519 r:0.6484
si_en Dev loss: 0.8987 r:0.5431
ne_en Dev loss: 0.5808 r:0.7243
ru_en Dev loss: 0.5317 r:0.6901
Current avg r:0.5808 Best avg r: 0.6235
01:24:18,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:49,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:27:20,38 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2228
en_de Dev loss: 0.8868 r:0.1878
en_zh Dev loss: 0.7664 r:0.4479
ro_en Dev loss: 0.3197 r:0.8203
et_en Dev loss: 0.4748 r:0.6639
si_en Dev loss: 0.8203 r:0.5596
ne_en Dev loss: 0.4767 r:0.7369
ru_en Dev loss: 0.4842 r:0.7059
Current avg r:0.5889 Best avg r: 0.6235
01:31:50,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:33:21,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:51,587 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2074
en_de Dev loss: 0.8978 r:0.1876
en_zh Dev loss: 0.7915 r:0.4533
ro_en Dev loss: 0.3382 r:0.8183
et_en Dev loss: 0.4629 r:0.6645
si_en Dev loss: 0.8863 r:0.5565
ne_en Dev loss: 0.4928 r:0.7387
ru_en Dev loss: 0.4991 r:0.7129
Current avg r:0.5903 Best avg r: 0.6235
01:39:22,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:40:52,688 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:42:23,143 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2143
en_de Dev loss: 0.9030 r:0.1700
en_zh Dev loss: 0.7700 r:0.4596
ro_en Dev loss: 0.3344 r:0.8217
et_en Dev loss: 0.4647 r:0.6730
si_en Dev loss: 0.7722 r:0.5702
ne_en Dev loss: 0.4872 r:0.7320
ru_en Dev loss: 0.5055 r:0.7055
Current avg r:0.5903 Best avg r: 0.6235
01:46:53,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:48:24,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:49:54,649 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2108
en_de Dev loss: 0.9300 r:0.1489
en_zh Dev loss: 0.8622 r:0.4348
ro_en Dev loss: 0.3648 r:0.8121
et_en Dev loss: 0.4425 r:0.6627
si_en Dev loss: 0.9224 r:0.5417
ne_en Dev loss: 0.5571 r:0.7323
ru_en Dev loss: 0.5747 r:0.6827
Current avg r:0.5736 Best avg r: 0.6235
01:54:25,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:55:55,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:57:26,348 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2110
en_de Dev loss: 0.9454 r:0.1854
en_zh Dev loss: 0.8182 r:0.4563
ro_en Dev loss: 0.3679 r:0.8154
et_en Dev loss: 0.4936 r:0.6543
si_en Dev loss: 0.8623 r:0.5473
ne_en Dev loss: 0.4881 r:0.7329
ru_en Dev loss: 0.5214 r:0.7034
Current avg r:0.5850 Best avg r: 0.6235
02:02:00,466 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:03:31,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:05:03,242 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2009
en_de Dev loss: 0.9306 r:0.1780
en_zh Dev loss: 0.7413 r:0.4685
ro_en Dev loss: 0.3181 r:0.8179
et_en Dev loss: 0.4539 r:0.6715
si_en Dev loss: 0.7409 r:0.5570
ne_en Dev loss: 0.4469 r:0.7263
ru_en Dev loss: 0.4691 r:0.7130
Current avg r:0.5903 Best avg r: 0.6235
02:09:36,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:11:07,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:12:38,700 root INFO Epoch 6 Global steps: 64400 Train loss: 0.1888
en_de Dev loss: 0.9155 r:0.1766
en_zh Dev loss: 0.7897 r:0.4601
ro_en Dev loss: 0.3719 r:0.8129
et_en Dev loss: 0.4890 r:0.6620
si_en Dev loss: 0.9577 r:0.5376
ne_en Dev loss: 0.5591 r:0.7259
ru_en Dev loss: 0.5428 r:0.6959
Current avg r:0.5816 Best avg r: 0.6235
02:17:11,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:18:42,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:20:13,995 root INFO Epoch 6 Global steps: 65100 Train loss: 0.1895
en_de Dev loss: 0.9169 r:0.1705
en_zh Dev loss: 0.8260 r:0.4473
ro_en Dev loss: 0.3516 r:0.8126
et_en Dev loss: 0.4673 r:0.6605
si_en Dev loss: 0.8663 r:0.5427
ne_en Dev loss: 0.5315 r:0.7277
ru_en Dev loss: 0.5173 r:0.7014
Current avg r:0.5804 Best avg r: 0.6235
02:24:46,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:26:17,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:49,46 root INFO Epoch 6 Global steps: 65800 Train loss: 0.1848
en_de Dev loss: 0.8957 r:0.1807
en_zh Dev loss: 0.8161 r:0.4507
ro_en Dev loss: 0.3371 r:0.8164
et_en Dev loss: 0.4859 r:0.6684
si_en Dev loss: 0.8093 r:0.5528
ne_en Dev loss: 0.4472 r:0.7313
ru_en Dev loss: 0.5014 r:0.7030
Current avg r:0.5862 Best avg r: 0.6235
02:32:20,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:33:51,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:35:21,800 root INFO Epoch 6 Global steps: 66500 Train loss: 0.1832
en_de Dev loss: 0.8965 r:0.1842
en_zh Dev loss: 0.8302 r:0.4451
ro_en Dev loss: 0.3593 r:0.8130
et_en Dev loss: 0.4715 r:0.6774
si_en Dev loss: 0.8659 r:0.5518
ne_en Dev loss: 0.4732 r:0.7369
ru_en Dev loss: 0.5142 r:0.7069
Current avg r:0.5879 Best avg r: 0.6235
02:39:52,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:41:23,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:42:53,819 root INFO Epoch 6 Global steps: 67200 Train loss: 0.1768
en_de Dev loss: 0.8776 r:0.1762
en_zh Dev loss: 0.7768 r:0.4513
ro_en Dev loss: 0.3660 r:0.8120
et_en Dev loss: 0.4339 r:0.6713
si_en Dev loss: 0.9070 r:0.5450
ne_en Dev loss: 0.5926 r:0.7314
ru_en Dev loss: 0.5074 r:0.7028
Current avg r:0.5843 Best avg r: 0.6235
02:47:24,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:48:55,188 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:50:25,693 root INFO Epoch 6 Global steps: 67900 Train loss: 0.1887
en_de Dev loss: 0.9042 r:0.1547
en_zh Dev loss: 0.7900 r:0.4522
ro_en Dev loss: 0.3632 r:0.8121
et_en Dev loss: 0.4701 r:0.6578
si_en Dev loss: 0.9181 r:0.5385
ne_en Dev loss: 0.5182 r:0.7230
ru_en Dev loss: 0.5320 r:0.6922
Current avg r:0.5758 Best avg r: 0.6235
02:54:56,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:27,80 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:57:57,630 root INFO Epoch 6 Global steps: 68600 Train loss: 0.1835
en_de Dev loss: 0.9004 r:0.1914
en_zh Dev loss: 0.7748 r:0.4617
ro_en Dev loss: 0.3426 r:0.8162
et_en Dev loss: 0.4796 r:0.6615
si_en Dev loss: 0.8665 r:0.5446
ne_en Dev loss: 0.4821 r:0.7250
ru_en Dev loss: 0.4885 r:0.7050
Current avg r:0.5865 Best avg r: 0.6235
03:02:28,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:59,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:05:29,528 root INFO Epoch 6 Global steps: 69300 Train loss: 0.1828
en_de Dev loss: 0.9375 r:0.1571
en_zh Dev loss: 0.8301 r:0.4410
ro_en Dev loss: 0.3711 r:0.8078
et_en Dev loss: 0.4786 r:0.6476
si_en Dev loss: 0.9347 r:0.5239
ne_en Dev loss: 0.5369 r:0.7162
ru_en Dev loss: 0.5672 r:0.6870
Current avg r:0.5687 Best avg r: 0.6235
03:10:00,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:11:30,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:13:01,459 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1805
en_de Dev loss: 0.9082 r:0.1773
en_zh Dev loss: 0.7571 r:0.4637
ro_en Dev loss: 0.3307 r:0.8127
et_en Dev loss: 0.5024 r:0.6807
si_en Dev loss: 0.7500 r:0.5559
ne_en Dev loss: 0.4447 r:0.7131
ru_en Dev loss: 0.4432 r:0.7126
Current avg r:0.5880 Best avg r: 0.6235
03:17:32,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:19:02,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:20:33,416 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1843
en_de Dev loss: 0.9231 r:0.1756
en_zh Dev loss: 0.8214 r:0.4498
ro_en Dev loss: 0.3856 r:0.8128
et_en Dev loss: 0.5122 r:0.6545
si_en Dev loss: 0.9240 r:0.5425
ne_en Dev loss: 0.5073 r:0.7175
ru_en Dev loss: 0.5344 r:0.6960
Current avg r:0.5784 Best avg r: 0.6235
03:25:04,283 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:26:34,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:28:05,352 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1836
en_de Dev loss: 0.9293 r:0.1671
en_zh Dev loss: 0.8227 r:0.4425
ro_en Dev loss: 0.4035 r:0.8117
et_en Dev loss: 0.4829 r:0.6501
si_en Dev loss: 0.9855 r:0.5358
ne_en Dev loss: 0.5485 r:0.7162
ru_en Dev loss: 0.5763 r:0.6911
Current avg r:0.5735 Best avg r: 0.6235
03:32:36,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:34:06,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:35:37,215 root INFO Epoch 6 Global steps: 72100 Train loss: 0.1807
en_de Dev loss: 0.8920 r:0.1843
en_zh Dev loss: 0.7795 r:0.4474
ro_en Dev loss: 0.3382 r:0.8130
et_en Dev loss: 0.4594 r:0.6532
si_en Dev loss: 0.8941 r:0.5274
ne_en Dev loss: 0.5322 r:0.7223
ru_en Dev loss: 0.5200 r:0.6890
Current avg r:0.5767 Best avg r: 0.6235
03:40:08,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:41:38,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:43:09,160 root INFO Epoch 6 Global steps: 72800 Train loss: 0.1759
en_de Dev loss: 0.9113 r:0.1816
en_zh Dev loss: 0.7881 r:0.4570
ro_en Dev loss: 0.3369 r:0.8175
et_en Dev loss: 0.4687 r:0.6585
si_en Dev loss: 0.8836 r:0.5390
ne_en Dev loss: 0.5343 r:0.7220
ru_en Dev loss: 0.5135 r:0.6980
Current avg r:0.5819 Best avg r: 0.6235
03:47:39,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:49:10,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:50:40,824 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1736
en_de Dev loss: 0.9082 r:0.1669
en_zh Dev loss: 0.7753 r:0.4528
ro_en Dev loss: 0.3318 r:0.8160
et_en Dev loss: 0.4507 r:0.6614
si_en Dev loss: 0.8292 r:0.5474
ne_en Dev loss: 0.4990 r:0.7257
ru_en Dev loss: 0.4927 r:0.7069
Current avg r:0.5824 Best avg r: 0.6235
03:55:13,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:56:43,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:58:14,135 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1580
en_de Dev loss: 0.9189 r:0.1732
en_zh Dev loss: 0.8053 r:0.4529
ro_en Dev loss: 0.3729 r:0.8126
et_en Dev loss: 0.4668 r:0.6530
si_en Dev loss: 0.9091 r:0.5322
ne_en Dev loss: 0.5858 r:0.7128
ru_en Dev loss: 0.5449 r:0.6966
Current avg r:0.5762 Best avg r: 0.6235
04:02:44,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:15,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:05:45,858 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1589
en_de Dev loss: 0.9124 r:0.1911
en_zh Dev loss: 0.7852 r:0.4571
ro_en Dev loss: 0.3352 r:0.8165
et_en Dev loss: 0.4641 r:0.6677
si_en Dev loss: 0.9043 r:0.5416
ne_en Dev loss: 0.5249 r:0.7211
ru_en Dev loss: 0.4924 r:0.7096
Current avg r:0.5864 Best avg r: 0.6235
04:10:16,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:11:47,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:13:17,734 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1635
en_de Dev loss: 0.8992 r:0.1792
en_zh Dev loss: 0.7681 r:0.4514
ro_en Dev loss: 0.3302 r:0.8169
et_en Dev loss: 0.4661 r:0.6625
si_en Dev loss: 0.8886 r:0.5400
ne_en Dev loss: 0.5180 r:0.7158
ru_en Dev loss: 0.4829 r:0.7040
Current avg r:0.5814 Best avg r: 0.6235
04:17:48,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:19:19,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:20:49,695 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1618
en_de Dev loss: 0.9237 r:0.1684
en_zh Dev loss: 0.8447 r:0.4458
ro_en Dev loss: 0.3621 r:0.8187
et_en Dev loss: 0.5010 r:0.6667
si_en Dev loss: 0.9285 r:0.5461
ne_en Dev loss: 0.5095 r:0.7196
ru_en Dev loss: 0.5156 r:0.7063
Current avg r:0.5816 Best avg r: 0.6235
04:25:20,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:26:51,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:28:21,791 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1580
en_de Dev loss: 0.9716 r:0.1415
en_zh Dev loss: 0.8285 r:0.4498
ro_en Dev loss: 0.3734 r:0.8186
et_en Dev loss: 0.5056 r:0.6592
si_en Dev loss: 0.8981 r:0.5454
ne_en Dev loss: 0.5488 r:0.7212
ru_en Dev loss: 0.5343 r:0.6913
Current avg r:0.5753 Best avg r: 0.6235
04:32:52,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:34:23,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:35:53,615 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1524
en_de Dev loss: 0.9412 r:0.1392
en_zh Dev loss: 0.7663 r:0.4608
ro_en Dev loss: 0.3392 r:0.8151
et_en Dev loss: 0.4684 r:0.6478
si_en Dev loss: 0.9003 r:0.5388
ne_en Dev loss: 0.5351 r:0.7221
ru_en Dev loss: 0.4925 r:0.7030
Current avg r:0.5752 Best avg r: 0.6235
04:40:24,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:41:54,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:43:25,457 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1703
en_de Dev loss: 0.9739 r:0.1377
en_zh Dev loss: 0.8426 r:0.4452
ro_en Dev loss: 0.3798 r:0.8142
et_en Dev loss: 0.4903 r:0.6466
si_en Dev loss: 0.9503 r:0.5349
ne_en Dev loss: 0.6153 r:0.7148
ru_en Dev loss: 0.5603 r:0.7011
Current avg r:0.5706 Best avg r: 0.6235
04:47:56,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:49:26,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:50:57,181 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1531
en_de Dev loss: 0.9761 r:0.1461
en_zh Dev loss: 0.8097 r:0.4542
ro_en Dev loss: 0.3551 r:0.8112
et_en Dev loss: 0.4743 r:0.6575
si_en Dev loss: 0.8490 r:0.5418
ne_en Dev loss: 0.5118 r:0.7202
ru_en Dev loss: 0.5184 r:0.7034
Current avg r:0.5764 Best avg r: 0.6235
04:55:28,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:56:58,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:29,88 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1571
en_de Dev loss: 0.9477 r:0.1334
en_zh Dev loss: 0.7365 r:0.4644
ro_en Dev loss: 0.3253 r:0.8139
et_en Dev loss: 0.4668 r:0.6545
si_en Dev loss: 0.8287 r:0.5393
ne_en Dev loss: 0.4907 r:0.7185
ru_en Dev loss: 0.4651 r:0.7062
Current avg r:0.5757 Best avg r: 0.6235
05:02:59,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:04:30,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:06:00,853 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1532
en_de Dev loss: 0.9715 r:0.1318
en_zh Dev loss: 0.8190 r:0.4510
ro_en Dev loss: 0.3547 r:0.8133
et_en Dev loss: 0.4791 r:0.6574
si_en Dev loss: 0.9311 r:0.5313
ne_en Dev loss: 0.5609 r:0.7127
ru_en Dev loss: 0.4953 r:0.7083
Current avg r:0.5723 Best avg r: 0.6235
05:10:31,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:12:02,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:13:32,755 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1546
en_de Dev loss: 0.9604 r:0.1357
en_zh Dev loss: 0.7783 r:0.4539
ro_en Dev loss: 0.3475 r:0.8139
et_en Dev loss: 0.4667 r:0.6581
si_en Dev loss: 0.8419 r:0.5443
ne_en Dev loss: 0.5047 r:0.7262
ru_en Dev loss: 0.4847 r:0.7079
Current avg r:0.5771 Best avg r: 0.6235
05:18:03,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:19:34,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:21:04,795 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1551
en_de Dev loss: 0.9157 r:0.1704
en_zh Dev loss: 0.7540 r:0.4548
ro_en Dev loss: 0.3197 r:0.8142
et_en Dev loss: 0.4809 r:0.6686
si_en Dev loss: 0.7913 r:0.5449
ne_en Dev loss: 0.4812 r:0.7206
ru_en Dev loss: 0.4447 r:0.7138
Current avg r:0.5839 Best avg r: 0.6235
05:25:36,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:27:07,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:28:39,30 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1652
en_de Dev loss: 0.9381 r:0.1499
en_zh Dev loss: 0.7916 r:0.4493
ro_en Dev loss: 0.3681 r:0.8100
et_en Dev loss: 0.4829 r:0.6524
si_en Dev loss: 0.8876 r:0.5383
ne_en Dev loss: 0.5446 r:0.7169
ru_en Dev loss: 0.5149 r:0.7041
Current avg r:0.5744 Best avg r: 0.6235
05:33:11,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:34:43,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:36:14,219 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1575
en_de Dev loss: 0.9279 r:0.1383
en_zh Dev loss: 0.7635 r:0.4569
ro_en Dev loss: 0.3366 r:0.8146
et_en Dev loss: 0.4792 r:0.6595
si_en Dev loss: 0.8392 r:0.5367
ne_en Dev loss: 0.4927 r:0.7108
ru_en Dev loss: 0.4864 r:0.7000
Current avg r:0.5738 Best avg r: 0.6235
05:40:47,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:42:18,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:43:49,406 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1488
en_de Dev loss: 0.9374 r:0.1357
en_zh Dev loss: 0.7804 r:0.4635
ro_en Dev loss: 0.3375 r:0.8162
et_en Dev loss: 0.4744 r:0.6595
si_en Dev loss: 0.8651 r:0.5374
ne_en Dev loss: 0.5243 r:0.7151
ru_en Dev loss: 0.4955 r:0.7046
Current avg r:0.5760 Best avg r: 0.6235
05:48:23,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:49:54,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:51:24,876 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1434
en_de Dev loss: 0.9295 r:0.1585
en_zh Dev loss: 0.7639 r:0.4556
ro_en Dev loss: 0.3312 r:0.8159
et_en Dev loss: 0.4710 r:0.6609
si_en Dev loss: 0.8011 r:0.5407
ne_en Dev loss: 0.5232 r:0.7128
ru_en Dev loss: 0.4607 r:0.7073
Current avg r:0.5788 Best avg r: 0.6235
05:55:55,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:57:26,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:58:56,836 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1410
en_de Dev loss: 0.9345 r:0.1577
en_zh Dev loss: 0.7875 r:0.4526
ro_en Dev loss: 0.3315 r:0.8168
et_en Dev loss: 0.4627 r:0.6664
si_en Dev loss: 0.8063 r:0.5415
ne_en Dev loss: 0.4939 r:0.7146
ru_en Dev loss: 0.4892 r:0.7040
Current avg r:0.5791 Best avg r: 0.6235
06:03:27,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:58,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:06:28,833 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1366
en_de Dev loss: 0.9349 r:0.1562
en_zh Dev loss: 0.8109 r:0.4550
ro_en Dev loss: 0.3639 r:0.8132
et_en Dev loss: 0.4817 r:0.6548
si_en Dev loss: 0.9515 r:0.5295
ne_en Dev loss: 0.5717 r:0.7127
ru_en Dev loss: 0.5099 r:0.7042
Current avg r:0.5751 Best avg r: 0.6235
06:10:59,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:12:30,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:14:00,987 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1401
en_de Dev loss: 0.9379 r:0.1624
en_zh Dev loss: 0.8172 r:0.4532
ro_en Dev loss: 0.3763 r:0.8139
et_en Dev loss: 0.4853 r:0.6555
si_en Dev loss: 0.9161 r:0.5332
ne_en Dev loss: 0.6424 r:0.7129
ru_en Dev loss: 0.5326 r:0.6957
Current avg r:0.5753 Best avg r: 0.6235
06:18:32,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:20:03,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:21:33,946 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1356
en_de Dev loss: 0.9115 r:0.1650
en_zh Dev loss: 0.7854 r:0.4571
ro_en Dev loss: 0.3622 r:0.8147
et_en Dev loss: 0.4919 r:0.6620
si_en Dev loss: 0.8897 r:0.5373
ne_en Dev loss: 0.5966 r:0.7110
ru_en Dev loss: 0.4961 r:0.7044
Current avg r:0.5788 Best avg r: 0.6235
06:26:05,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:27:35,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:29:06,319 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1392
en_de Dev loss: 0.9457 r:0.1516
en_zh Dev loss: 0.7782 r:0.4567
ro_en Dev loss: 0.3372 r:0.8134
et_en Dev loss: 0.4910 r:0.6639
si_en Dev loss: 0.8339 r:0.5363
ne_en Dev loss: 0.5173 r:0.7116
ru_en Dev loss: 0.4898 r:0.7006
Current avg r:0.5763 Best avg r: 0.6235
06:33:37,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:35:08,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:36:38,816 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1372
en_de Dev loss: 0.9645 r:0.1566
en_zh Dev loss: 0.8076 r:0.4706
ro_en Dev loss: 0.3587 r:0.8119
et_en Dev loss: 0.5350 r:0.6578
si_en Dev loss: 0.8901 r:0.5372
ne_en Dev loss: 0.5284 r:0.7097
ru_en Dev loss: 0.5171 r:0.6966
Current avg r:0.5772 Best avg r: 0.6235
06:41:10,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:42:41,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:44:11,848 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1340
en_de Dev loss: 0.9663 r:0.1465
en_zh Dev loss: 0.8293 r:0.4639
ro_en Dev loss: 0.3776 r:0.8107
et_en Dev loss: 0.5068 r:0.6504
si_en Dev loss: 0.9765 r:0.5335
ne_en Dev loss: 0.6076 r:0.7064
ru_en Dev loss: 0.5291 r:0.6961
Current avg r:0.5725 Best avg r: 0.6235
06:48:43,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:50:13,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:51:44,505 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1358
en_de Dev loss: 0.9511 r:0.1415
en_zh Dev loss: 0.7955 r:0.4612
ro_en Dev loss: 0.3537 r:0.8129
et_en Dev loss: 0.4834 r:0.6633
si_en Dev loss: 0.8820 r:0.5404
ne_en Dev loss: 0.5602 r:0.7049
ru_en Dev loss: 0.5021 r:0.7030
Current avg r:0.5753 Best avg r: 0.6235
06:56:15,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:57:46,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:59:17,265 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1419
en_de Dev loss: 0.9344 r:0.1404
en_zh Dev loss: 0.7921 r:0.4552
ro_en Dev loss: 0.3484 r:0.8114
et_en Dev loss: 0.4757 r:0.6520
si_en Dev loss: 0.8483 r:0.5399
ne_en Dev loss: 0.5413 r:0.7027
ru_en Dev loss: 0.4962 r:0.7024
Current avg r:0.5720 Best avg r: 0.6235
07:03:48,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:05:19,329 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:06:49,914 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1406
en_de Dev loss: 0.9266 r:0.1488
en_zh Dev loss: 0.7825 r:0.4673
ro_en Dev loss: 0.3436 r:0.8146
et_en Dev loss: 0.4797 r:0.6619
si_en Dev loss: 0.8441 r:0.5444
ne_en Dev loss: 0.5261 r:0.7076
ru_en Dev loss: 0.4630 r:0.7182
Current avg r:0.5804 Best avg r: 0.6235
07:11:20,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:12:51,391 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:14:21,970 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1346
en_de Dev loss: 0.9370 r:0.1695
en_zh Dev loss: 0.7949 r:0.4634
ro_en Dev loss: 0.3615 r:0.8129
et_en Dev loss: 0.4978 r:0.6630
si_en Dev loss: 0.8636 r:0.5379
ne_en Dev loss: 0.5365 r:0.7112
ru_en Dev loss: 0.4662 r:0.7165
Current avg r:0.5820 Best avg r: 0.6235
07:18:53,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:20:23,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:21:54,349 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1339
en_de Dev loss: 0.9569 r:0.1447
en_zh Dev loss: 0.7994 r:0.4531
ro_en Dev loss: 0.3483 r:0.8141
et_en Dev loss: 0.4848 r:0.6464
si_en Dev loss: 0.8827 r:0.5358
ne_en Dev loss: 0.5601 r:0.7043
ru_en Dev loss: 0.4867 r:0.7093
Current avg r:0.5725 Best avg r: 0.6235
07:26:25,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:27:56,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:29:26,865 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1348
en_de Dev loss: 0.9368 r:0.1713
en_zh Dev loss: 0.7793 r:0.4637
ro_en Dev loss: 0.3372 r:0.8183
et_en Dev loss: 0.5174 r:0.6635
si_en Dev loss: 0.8169 r:0.5485
ne_en Dev loss: 0.5118 r:0.7153
ru_en Dev loss: 0.4530 r:0.7103
Current avg r:0.5844 Best avg r: 0.6235
07:33:58,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:35:29,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:36:59,628 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1319
en_de Dev loss: 0.9387 r:0.1462
en_zh Dev loss: 0.8113 r:0.4563
ro_en Dev loss: 0.3637 r:0.8129
et_en Dev loss: 0.4670 r:0.6539
si_en Dev loss: 0.9452 r:0.5305
ne_en Dev loss: 0.6255 r:0.7023
ru_en Dev loss: 0.5349 r:0.7018
Current avg r:0.5720 Best avg r: 0.6235
07:41:32,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:43:03,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:44:33,683 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1235
en_de Dev loss: 0.9372 r:0.1623
en_zh Dev loss: 0.7815 r:0.4600
ro_en Dev loss: 0.3282 r:0.8204
et_en Dev loss: 0.4554 r:0.6655
si_en Dev loss: 0.8350 r:0.5461
ne_en Dev loss: 0.5410 r:0.7152
ru_en Dev loss: 0.4891 r:0.7084
Current avg r:0.5826 Best avg r: 0.6235
07:49:04,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:50:35,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:06,177 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1259
en_de Dev loss: 0.9447 r:0.1823
en_zh Dev loss: 0.8185 r:0.4633
ro_en Dev loss: 0.3524 r:0.8173
et_en Dev loss: 0.4964 r:0.6624
si_en Dev loss: 0.8789 r:0.5435
ne_en Dev loss: 0.5404 r:0.7103
ru_en Dev loss: 0.4795 r:0.7101
Current avg r:0.5842 Best avg r: 0.6235
07:56:37,558 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:58:08,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:59:38,853 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1236
en_de Dev loss: 0.9410 r:0.1967
en_zh Dev loss: 0.7813 r:0.4706
ro_en Dev loss: 0.3324 r:0.8196
et_en Dev loss: 0.5043 r:0.6711
si_en Dev loss: 0.8439 r:0.5457
ne_en Dev loss: 0.5058 r:0.7121
ru_en Dev loss: 0.4551 r:0.7155
Current avg r:0.5902 Best avg r: 0.6235
08:04:09,916 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:05:40,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:07:11,34 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1267
en_de Dev loss: 0.9284 r:0.1810
en_zh Dev loss: 0.7998 r:0.4654
ro_en Dev loss: 0.3580 r:0.8130
et_en Dev loss: 0.4947 r:0.6584
si_en Dev loss: 0.8845 r:0.5367
ne_en Dev loss: 0.5183 r:0.7061
ru_en Dev loss: 0.4891 r:0.7093
Current avg r:0.5814 Best avg r: 0.6235
08:11:42,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:13:12,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:14:43,334 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1222
en_de Dev loss: 0.9551 r:0.1602
en_zh Dev loss: 0.7949 r:0.4625
ro_en Dev loss: 0.3776 r:0.8093
et_en Dev loss: 0.4880 r:0.6438
si_en Dev loss: 0.9661 r:0.5246
ne_en Dev loss: 0.6086 r:0.7067
ru_en Dev loss: 0.5159 r:0.7015
Current avg r:0.5726 Best avg r: 0.6235
08:19:14,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:20:44,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:22:15,426 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1203
en_de Dev loss: 0.9643 r:0.1650
en_zh Dev loss: 0.8051 r:0.4640
ro_en Dev loss: 0.3478 r:0.8174
et_en Dev loss: 0.4905 r:0.6570
si_en Dev loss: 0.9133 r:0.5344
ne_en Dev loss: 0.5534 r:0.7132
ru_en Dev loss: 0.5104 r:0.7050
Current avg r:0.5794 Best avg r: 0.6235
08:26:46,545 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:17,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:47,790 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1204
en_de Dev loss: 0.9526 r:0.1700
en_zh Dev loss: 0.8024 r:0.4591
ro_en Dev loss: 0.3530 r:0.8130
et_en Dev loss: 0.4959 r:0.6589
si_en Dev loss: 0.8588 r:0.5305
ne_en Dev loss: 0.5212 r:0.7095
ru_en Dev loss: 0.4777 r:0.7102
Current avg r:0.5787 Best avg r: 0.6235
08:34:18,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:49,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:37:19,914 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1260
en_de Dev loss: 0.9750 r:0.1562
en_zh Dev loss: 0.7768 r:0.4743
ro_en Dev loss: 0.3655 r:0.8162
et_en Dev loss: 0.4768 r:0.6682
si_en Dev loss: 0.8811 r:0.5428
ne_en Dev loss: 0.5690 r:0.7119
ru_en Dev loss: 0.4953 r:0.7051
Current avg r:0.5821 Best avg r: 0.6235
08:41:52,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:43:23,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:44:54,391 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1218
en_de Dev loss: 0.9784 r:0.1589
en_zh Dev loss: 0.8355 r:0.4571
ro_en Dev loss: 0.4045 r:0.8047
et_en Dev loss: 0.4968 r:0.6420
si_en Dev loss: 1.0269 r:0.5197
ne_en Dev loss: 0.7145 r:0.6919
ru_en Dev loss: 0.5352 r:0.6988
Current avg r:0.5676 Best avg r: 0.6235
08:49:27,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:50:58,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:52:29,502 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1236
en_de Dev loss: 0.9470 r:0.1645
en_zh Dev loss: 0.7793 r:0.4637
ro_en Dev loss: 0.3472 r:0.8162
et_en Dev loss: 0.4852 r:0.6717
si_en Dev loss: 0.8282 r:0.5438
ne_en Dev loss: 0.5239 r:0.7052
ru_en Dev loss: 0.4629 r:0.7149
Current avg r:0.5828 Best avg r: 0.6235
08:57:02,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:58:33,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:00:04,885 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1141
en_de Dev loss: 0.9793 r:0.1315
en_zh Dev loss: 0.8244 r:0.4594
ro_en Dev loss: 0.3750 r:0.8111
et_en Dev loss: 0.4882 r:0.6523
si_en Dev loss: 0.9444 r:0.5309
ne_en Dev loss: 0.5811 r:0.7107
ru_en Dev loss: 0.5410 r:0.6963
Current avg r:0.5703 Best avg r: 0.6235
09:04:36,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:06:07,139 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:07:37,705 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1163
en_de Dev loss: 0.9741 r:0.1477
en_zh Dev loss: 0.8208 r:0.4629
ro_en Dev loss: 0.3531 r:0.8135
et_en Dev loss: 0.4616 r:0.6673
si_en Dev loss: 0.8514 r:0.5381
ne_en Dev loss: 0.5174 r:0.7137
ru_en Dev loss: 0.4859 r:0.7106
Current avg r:0.5791 Best avg r: 0.6235
09:12:08,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:13:39,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:15:10,58 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1169
en_de Dev loss: 1.0201 r:0.1375
en_zh Dev loss: 0.8325 r:0.4711
ro_en Dev loss: 0.3648 r:0.8179
et_en Dev loss: 0.4713 r:0.6715
si_en Dev loss: 0.9156 r:0.5352
ne_en Dev loss: 0.5984 r:0.7047
ru_en Dev loss: 0.5144 r:0.7086
Current avg r:0.5781 Best avg r: 0.6235
09:19:41,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:21:11,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:22:42,529 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1162
en_de Dev loss: 0.9740 r:0.1217
en_zh Dev loss: 0.7912 r:0.4590
ro_en Dev loss: 0.3357 r:0.8176
et_en Dev loss: 0.4724 r:0.6636
si_en Dev loss: 0.8707 r:0.5359
ne_en Dev loss: 0.6053 r:0.7057
ru_en Dev loss: 0.4885 r:0.7008
Current avg r:0.5720 Best avg r: 0.6235
09:27:13,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:28:44,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:30:15,60 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1157
en_de Dev loss: 0.9663 r:0.1470
en_zh Dev loss: 0.7758 r:0.4658
ro_en Dev loss: 0.3265 r:0.8228
et_en Dev loss: 0.4794 r:0.6737
si_en Dev loss: 0.8579 r:0.5412
ne_en Dev loss: 0.5466 r:0.7095
ru_en Dev loss: 0.4551 r:0.7091
Current avg r:0.5813 Best avg r: 0.6235
09:34:47,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:36:18,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:37:48,738 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1094
en_de Dev loss: 0.9640 r:0.1444
en_zh Dev loss: 0.7718 r:0.4656
ro_en Dev loss: 0.3542 r:0.8145
et_en Dev loss: 0.4741 r:0.6546
si_en Dev loss: 0.9034 r:0.5342
ne_en Dev loss: 0.6055 r:0.7036
ru_en Dev loss: 0.4820 r:0.7099
Current avg r:0.5753 Best avg r: 0.6235
09:42:19,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:50,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:45:21,23 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1070
en_de Dev loss: 0.9823 r:0.1447
en_zh Dev loss: 0.8252 r:0.4569
ro_en Dev loss: 0.3838 r:0.8109
et_en Dev loss: 0.5112 r:0.6503
si_en Dev loss: 1.0599 r:0.5254
ne_en Dev loss: 0.7486 r:0.7005
ru_en Dev loss: 0.5260 r:0.7047
Current avg r:0.5705 Best avg r: 0.6235
09:49:52,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:51:22,665 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:52:53,256 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1066
en_de Dev loss: 0.9649 r:0.1420
en_zh Dev loss: 0.7494 r:0.4626
ro_en Dev loss: 0.3147 r:0.8161
et_en Dev loss: 0.4751 r:0.6664
si_en Dev loss: 0.7998 r:0.5348
ne_en Dev loss: 0.5103 r:0.7025
ru_en Dev loss: 0.4498 r:0.7098
Current avg r:0.5763 Best avg r: 0.6235
09:57:24,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:55,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:25,656 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1106
en_de Dev loss: 0.9944 r:0.1390
en_zh Dev loss: 0.8173 r:0.4685
ro_en Dev loss: 0.3582 r:0.8170
et_en Dev loss: 0.4813 r:0.6640
si_en Dev loss: 0.8487 r:0.5385
ne_en Dev loss: 0.5405 r:0.7092
ru_en Dev loss: 0.4936 r:0.7086
Current avg r:0.5778 Best avg r: 0.6235
10:04:56,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:06:27,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:59,98 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1061
en_de Dev loss: 0.9601 r:0.1722
en_zh Dev loss: 0.7802 r:0.4707
ro_en Dev loss: 0.3239 r:0.8199
et_en Dev loss: 0.4638 r:0.6750
si_en Dev loss: 0.8063 r:0.5396
ne_en Dev loss: 0.5360 r:0.7098
ru_en Dev loss: 0.4744 r:0.7107
Current avg r:0.5854 Best avg r: 0.6235
10:12:31,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:03,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:34,207 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1030
en_de Dev loss: 0.9482 r:0.1702
en_zh Dev loss: 0.8044 r:0.4621
ro_en Dev loss: 0.3466 r:0.8185
et_en Dev loss: 0.4847 r:0.6637
si_en Dev loss: 0.8834 r:0.5423
ne_en Dev loss: 0.6056 r:0.7073
ru_en Dev loss: 0.4815 r:0.7064
Current avg r:0.5815 Best avg r: 0.6235
10:20:07,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:38,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:10,7 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1029
en_de Dev loss: 0.9678 r:0.1648
en_zh Dev loss: 0.7731 r:0.4763
ro_en Dev loss: 0.3380 r:0.8190
et_en Dev loss: 0.4856 r:0.6664
si_en Dev loss: 0.8751 r:0.5374
ne_en Dev loss: 0.5390 r:0.7025
ru_en Dev loss: 0.4786 r:0.7045
Current avg r:0.5815 Best avg r: 0.6235
10:27:43,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:13,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:44,599 root INFO Epoch 10 Global steps: 110600 Train loss: 0.1058
en_de Dev loss: 0.9934 r:0.1590
en_zh Dev loss: 0.7793 r:0.4748
ro_en Dev loss: 0.3557 r:0.8159
et_en Dev loss: 0.4750 r:0.6621
si_en Dev loss: 0.9035 r:0.5337
ne_en Dev loss: 0.5942 r:0.7057
ru_en Dev loss: 0.4852 r:0.7043
Current avg r:0.5794 Best avg r: 0.6235
