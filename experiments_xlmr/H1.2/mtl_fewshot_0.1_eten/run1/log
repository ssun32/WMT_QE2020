14:43:13,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:43:26,257 root INFO 
id:en_de cur r: 0.0019 best r: 0.0019
14:43:39,321 root INFO 
id:en_zh cur r: 0.0256 best r: 0.0256
14:43:52,426 root INFO 
id:ro_en cur r: 0.1036 best r: 0.1036
14:44:18,683 root INFO 
id:et_en cur r: 0.1498 best r: 0.1498
14:44:31,822 root INFO 
id:si_en cur r: 0.0593 best r: 0.0593
14:44:44,941 root INFO 
id:ne_en cur r: 0.1781 best r: 0.1781
14:44:57,960 root INFO 
id:ru_en cur r: 0.3241 best r: 0.3241
14:44:57,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:29,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:46:29,630 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:46:29,640 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:46:29,647 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:46:29,652 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:46:29,657 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:46:29,665 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:46:42,807 root INFO Epoch 0 Global steps: 700 Train loss: 0.9085
en_de Dev loss: 0.8854 r:0.0692
en_zh Dev loss: 0.8193 r:0.1078
ro_en Dev loss: 0.8259 r:0.4221
et_en Dev loss: 0.7249 r:0.2417
si_en Dev loss: 0.7999 r:0.2925
ne_en Dev loss: 0.7739 r:0.3152
ru_en Dev loss: 0.7866 r:0.3983
Current avg r:0.2638 Best avg r: 0.2638
14:51:16,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:42,726 root INFO 
id:en_zh cur r: 0.1544 best r: 0.1544
14:51:55,835 root INFO 
id:ro_en cur r: 0.4032 best r: 0.4032
14:52:22,94 root INFO 
id:et_en cur r: 0.3514 best r: 0.3514
14:52:35,218 root INFO 
id:si_en cur r: 0.1956 best r: 0.1956
14:52:48,338 root INFO 
id:ne_en cur r: 0.4309 best r: 0.4309
14:53:01,367 root INFO 
id:ru_en cur r: 0.5247 best r: 0.5247
14:53:01,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:33,21 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:54:33,27 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:54:33,31 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:54:33,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:54:33,42 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:54:33,47 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:54:33,52 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:54:46,173 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8664
en_de Dev loss: 0.8835 r:0.0888
en_zh Dev loss: 0.7939 r:0.2024
ro_en Dev loss: 0.7509 r:0.6162
et_en Dev loss: 0.6365 r:0.4515
si_en Dev loss: 0.8372 r:0.4486
ne_en Dev loss: 0.7324 r:0.5032
ru_en Dev loss: 0.7088 r:0.5661
Current avg r:0.4110 Best avg r: 0.4110
14:59:19,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:33,52 root INFO 
id:en_de cur r: 0.0647 best r: 0.0647
14:59:46,124 root INFO 
id:en_zh cur r: 0.2638 best r: 0.2638
14:59:59,221 root INFO 
id:ro_en cur r: 0.6892 best r: 0.6892
15:00:25,485 root INFO 
id:et_en cur r: 0.5883 best r: 0.5883
15:00:38,612 root INFO 
id:si_en cur r: 0.4671 best r: 0.4671
15:00:51,728 root INFO 
id:ne_en cur r: 0.6511 best r: 0.6511
15:01:04,747 root INFO 
id:ru_en cur r: 0.6174 best r: 0.6174
15:01:04,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:36,389 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:02:36,395 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:02:36,401 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:02:36,406 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:02:36,411 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:02:36,416 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:02:36,421 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:02:49,549 root INFO Epoch 0 Global steps: 2100 Train loss: 0.8207
en_de Dev loss: 0.8974 r:0.1295
en_zh Dev loss: 0.7543 r:0.2855
ro_en Dev loss: 0.5410 r:0.6947
et_en Dev loss: 0.4752 r:0.5868
si_en Dev loss: 0.6436 r:0.5058
ne_en Dev loss: 0.5186 r:0.6466
ru_en Dev loss: 0.5236 r:0.6469
Current avg r:0.4994 Best avg r: 0.4994
15:07:23,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:36,444 root INFO 
id:en_de cur r: 0.0871 best r: 0.0871
15:07:49,517 root INFO 
id:en_zh cur r: 0.2774 best r: 0.2774
15:08:02,631 root INFO 
id:ro_en cur r: 0.7469 best r: 0.7469
15:08:28,870 root INFO 
id:et_en cur r: 0.6510 best r: 0.6510
15:08:42,7 root INFO 
id:si_en cur r: 0.5224 best r: 0.5224
15:08:55,142 root INFO 
id:ne_en cur r: 0.6879 best r: 0.6879
15:09:08,157 root INFO 
id:ru_en cur r: 0.7060 best r: 0.7060
15:09:08,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:39,827 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:10:39,837 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:10:39,842 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:10:39,846 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:10:39,851 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:10:39,855 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:10:39,860 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:10:52,988 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6549
en_de Dev loss: 0.8786 r:0.1600
en_zh Dev loss: 0.7527 r:0.3092
ro_en Dev loss: 0.4550 r:0.7353
et_en Dev loss: 0.4203 r:0.6627
si_en Dev loss: 0.6915 r:0.5264
ne_en Dev loss: 0.4609 r:0.6650
ru_en Dev loss: 0.4609 r:0.7053
Current avg r:0.5377 Best avg r: 0.5377
15:15:26,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:39,855 root INFO 
id:en_de cur r: 0.1321 best r: 0.1321
15:15:52,910 root INFO 
id:en_zh cur r: 0.3208 best r: 0.3208
15:16:06,7 root INFO 
id:ro_en cur r: 0.7632 best r: 0.7632
15:16:32,245 root INFO 
id:et_en cur r: 0.6941 best r: 0.6941
15:16:45,388 root INFO 
id:si_en cur r: 0.5503 best r: 0.5503
15:16:58,508 root INFO 
id:ne_en cur r: 0.7094 best r: 0.7094
15:17:11,537 root INFO 
id:ru_en cur r: 0.7292 best r: 0.7292
15:17:11,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:43,170 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:18:43,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:18:43,182 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:18:43,188 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:18:43,192 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:18:43,197 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:18:43,203 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:18:56,338 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6153
en_de Dev loss: 0.9080 r:0.1740
en_zh Dev loss: 0.7498 r:0.3330
ro_en Dev loss: 0.3928 r:0.7530
et_en Dev loss: 0.3668 r:0.6971
si_en Dev loss: 0.6270 r:0.5539
ne_en Dev loss: 0.4072 r:0.6973
ru_en Dev loss: 0.4208 r:0.7273
Current avg r:0.5622 Best avg r: 0.5622
15:23:30,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:43,194 root INFO 
id:en_de cur r: 0.1413 best r: 0.1413
15:23:56,266 root INFO 
id:en_zh cur r: 0.3554 best r: 0.3554
15:24:09,364 root INFO 
id:ro_en cur r: 0.7755 best r: 0.7755
15:24:35,609 root INFO 
id:et_en cur r: 0.6956 best r: 0.6956
15:24:48,739 root INFO 
id:si_en cur r: 0.5560 best r: 0.5560
15:25:01,863 root INFO 
id:ne_en cur r: 0.7118 best r: 0.7118
15:25:14,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:46,498 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:26:46,510 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:26:46,516 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:26:46,523 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:26:46,529 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:26:46,534 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:26:46,539 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:26:59,664 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6081
en_de Dev loss: 1.0011 r:0.1884
en_zh Dev loss: 0.8459 r:0.3654
ro_en Dev loss: 0.5368 r:0.7684
et_en Dev loss: 0.4665 r:0.6992
si_en Dev loss: 0.8831 r:0.5559
ne_en Dev loss: 0.4860 r:0.6965
ru_en Dev loss: 0.6103 r:0.7111
Current avg r:0.5693 Best avg r: 0.5693
15:31:33,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:46,500 root INFO 
id:en_de cur r: 0.1427 best r: 0.1427
15:31:59,566 root INFO 
id:en_zh cur r: 0.4003 best r: 0.4003
15:32:12,645 root INFO 
id:ro_en cur r: 0.7831 best r: 0.7831
15:32:38,855 root INFO 
id:et_en cur r: 0.6985 best r: 0.6985
15:32:51,997 root INFO 
id:si_en cur r: 0.5787 best r: 0.5787
15:33:05,123 root INFO 
id:ne_en cur r: 0.7259 best r: 0.7259
15:33:18,138 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:49,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:34:49,796 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:34:49,801 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:34:49,806 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:34:49,810 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:34:49,815 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:34:49,821 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:35:02,937 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5648
en_de Dev loss: 0.8935 r:0.1919
en_zh Dev loss: 0.7063 r:0.4158
ro_en Dev loss: 0.3671 r:0.7721
et_en Dev loss: 0.3634 r:0.7064
si_en Dev loss: 0.6024 r:0.5844
ne_en Dev loss: 0.4250 r:0.7035
ru_en Dev loss: 0.4208 r:0.7320
Current avg r:0.5866 Best avg r: 0.5866
15:39:36,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:49,724 root INFO 
id:en_de cur r: 0.1498 best r: 0.1498
15:40:02,792 root INFO 
id:en_zh cur r: 0.4391 best r: 0.4391
15:40:15,893 root INFO 
id:ro_en cur r: 0.7954 best r: 0.7954
15:40:42,114 root INFO 
id:et_en cur r: 0.7089 best r: 0.7089
15:40:55,242 root INFO 
id:si_en cur r: 0.6124 best r: 0.6124
15:41:08,384 root INFO 
id:ne_en cur r: 0.7482 best r: 0.7482
15:41:21,411 root INFO 
id:ru_en cur r: 0.7438 best r: 0.7438
15:41:21,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:53,42 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:42:53,50 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:42:53,55 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:42:53,60 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:42:53,64 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:42:53,68 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:42:53,73 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:43:06,215 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5541
en_de Dev loss: 0.8755 r:0.1873
en_zh Dev loss: 0.6683 r:0.4423
ro_en Dev loss: 0.3447 r:0.7889
et_en Dev loss: 0.3622 r:0.7149
si_en Dev loss: 0.6223 r:0.6044
ne_en Dev loss: 0.4102 r:0.7292
ru_en Dev loss: 0.3756 r:0.7440
Current avg r:0.6016 Best avg r: 0.6016
15:47:40,27 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:53,95 root INFO 
id:en_de cur r: 0.1671 best r: 0.1671
15:49:11,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:43,251 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5198
en_de Dev loss: 0.9091 r:0.1943
en_zh Dev loss: 0.7368 r:0.4294
ro_en Dev loss: 0.3830 r:0.7865
et_en Dev loss: 0.3838 r:0.7121
si_en Dev loss: 0.6581 r:0.5975
ne_en Dev loss: 0.4266 r:0.7216
ru_en Dev loss: 0.4944 r:0.7275
Current avg r:0.5956 Best avg r: 0.6016
15:55:16,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:30,69 root INFO 
id:en_de cur r: 0.1760 best r: 0.1760
15:55:56,236 root INFO 
id:ro_en cur r: 0.7969 best r: 0.7969
15:56:48,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:20,302 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5198
en_de Dev loss: 0.9300 r:0.1974
en_zh Dev loss: 0.7671 r:0.4372
ro_en Dev loss: 0.4059 r:0.7889
et_en Dev loss: 0.4189 r:0.7148
si_en Dev loss: 0.7083 r:0.5961
ne_en Dev loss: 0.4587 r:0.7134
ru_en Dev loss: 0.4567 r:0.7403
Current avg r:0.5983 Best avg r: 0.6016
16:02:54,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:20,373 root INFO 
id:en_zh cur r: 0.4410 best r: 0.4410
16:03:33,482 root INFO 
id:ro_en cur r: 0.7982 best r: 0.7982
16:04:25,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:57,532 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5055
en_de Dev loss: 0.9144 r:0.1872
en_zh Dev loss: 0.7328 r:0.4452
ro_en Dev loss: 0.3875 r:0.7896
et_en Dev loss: 0.4156 r:0.7196
si_en Dev loss: 0.7107 r:0.5983
ne_en Dev loss: 0.4472 r:0.7262
ru_en Dev loss: 0.4468 r:0.7385
Current avg r:0.6007 Best avg r: 0.6016
16:10:31,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:03,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:34,684 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5317
en_de Dev loss: 0.8735 r:0.1835
en_zh Dev loss: 0.6885 r:0.4258
ro_en Dev loss: 0.3444 r:0.7880
et_en Dev loss: 0.3800 r:0.7125
si_en Dev loss: 0.6171 r:0.5967
ne_en Dev loss: 0.4147 r:0.7187
ru_en Dev loss: 0.4173 r:0.7271
Current avg r:0.5932 Best avg r: 0.6016
16:18:08,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:34,639 root INFO 
id:en_zh cur r: 0.4503 best r: 0.4503
16:18:47,728 root INFO 
id:ro_en cur r: 0.8044 best r: 0.8044
16:19:40,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:11,699 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5283
en_de Dev loss: 0.8811 r:0.1879
en_zh Dev loss: 0.6872 r:0.4443
ro_en Dev loss: 0.3398 r:0.7997
et_en Dev loss: 0.3868 r:0.7090
si_en Dev loss: 0.6761 r:0.6059
ne_en Dev loss: 0.4211 r:0.7303
ru_en Dev loss: 0.4430 r:0.7309
Current avg r:0.6011 Best avg r: 0.6016
16:25:45,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:58,533 root INFO 
id:en_de cur r: 0.1795 best r: 0.1795
16:26:24,689 root INFO 
id:ro_en cur r: 0.8098 best r: 0.8098
16:27:17,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:48,608 root INFO Epoch 0 Global steps: 9800 Train loss: 0.4983
en_de Dev loss: 0.8647 r:0.2038
en_zh Dev loss: 0.7369 r:0.4277
ro_en Dev loss: 0.3660 r:0.8016
et_en Dev loss: 0.4209 r:0.7000
si_en Dev loss: 0.7694 r:0.5956
ne_en Dev loss: 0.4747 r:0.7225
ru_en Dev loss: 0.4659 r:0.7167
Current avg r:0.5954 Best avg r: 0.6016
16:33:22,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:35,408 root INFO 
id:en_de cur r: 0.1823 best r: 0.1823
16:34:01,560 root INFO 
id:ro_en cur r: 0.8160 best r: 0.8160
16:34:53,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:25,600 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5001
en_de Dev loss: 0.8820 r:0.1972
en_zh Dev loss: 0.7830 r:0.4383
ro_en Dev loss: 0.4233 r:0.8088
et_en Dev loss: 0.5127 r:0.7010
si_en Dev loss: 0.8073 r:0.6036
ne_en Dev loss: 0.4900 r:0.7312
ru_en Dev loss: 0.5831 r:0.7085
Current avg r:0.5984 Best avg r: 0.6016
16:41:01,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:14,442 root INFO 
id:en_de cur r: 0.1865 best r: 0.1865
16:42:20,8 root INFO 
id:ne_en cur r: 0.7577 best r: 0.7577
16:42:33,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:04,661 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4528
en_de Dev loss: 0.8918 r:0.2005
en_zh Dev loss: 0.7332 r:0.4344
ro_en Dev loss: 0.4050 r:0.8039
et_en Dev loss: 0.4643 r:0.6978
si_en Dev loss: 0.7823 r:0.5993
ne_en Dev loss: 0.4900 r:0.7393
ru_en Dev loss: 0.4899 r:0.7169
Current avg r:0.5989 Best avg r: 0.6016
16:48:38,717 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:51,812 root INFO 
id:en_de cur r: 0.2028 best r: 0.2028
16:49:04,874 root INFO 
id:en_zh cur r: 0.4607 best r: 0.4607
16:49:44,219 root INFO 
id:si_en cur r: 0.6232 best r: 0.6232
16:49:57,347 root INFO 
id:ne_en cur r: 0.7579 best r: 0.7579
16:50:10,357 root INFO 
id:ru_en cur r: 0.7567 best r: 0.7567
16:50:10,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:41,985 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:51:41,992 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:51:41,996 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:51:42,1 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:51:42,5 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:51:42,10 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:51:42,15 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:51:55,124 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4451
en_de Dev loss: 0.8508 r:0.2211
en_zh Dev loss: 0.6874 r:0.4560
ro_en Dev loss: 0.3459 r:0.8049
et_en Dev loss: 0.4295 r:0.7046
si_en Dev loss: 0.5681 r:0.6176
ne_en Dev loss: 0.3614 r:0.7495
ru_en Dev loss: 0.4080 r:0.7485
Current avg r:0.6146 Best avg r: 0.6146
16:56:27,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:40,68 root INFO 
id:en_de cur r: 0.2205 best r: 0.2205
16:57:57,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:28,610 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4251
en_de Dev loss: 0.8526 r:0.2291
en_zh Dev loss: 0.7484 r:0.4318
ro_en Dev loss: 0.3609 r:0.8015
et_en Dev loss: 0.4212 r:0.6935
si_en Dev loss: 0.7355 r:0.5974
ne_en Dev loss: 0.5217 r:0.7345
ru_en Dev loss: 0.4854 r:0.7218
Current avg r:0.6014 Best avg r: 0.6146
17:03:59,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:30,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:01,78 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4265
en_de Dev loss: 0.8474 r:0.2270
en_zh Dev loss: 0.7023 r:0.4556
ro_en Dev loss: 0.4017 r:0.8031
et_en Dev loss: 0.4958 r:0.6840
si_en Dev loss: 0.7734 r:0.5922
ne_en Dev loss: 0.4468 r:0.7298
ru_en Dev loss: 0.5041 r:0.7231
Current avg r:0.6021 Best avg r: 0.6146
17:11:32,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:02,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:33,391 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4189
en_de Dev loss: 0.8726 r:0.2277
en_zh Dev loss: 0.7628 r:0.4516
ro_en Dev loss: 0.4036 r:0.8039
et_en Dev loss: 0.5119 r:0.6796
si_en Dev loss: 0.8266 r:0.5811
ne_en Dev loss: 0.4818 r:0.7280
ru_en Dev loss: 0.5451 r:0.7123
Current avg r:0.5978 Best avg r: 0.6146
17:19:04,355 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:30,248 root INFO 
id:en_zh cur r: 0.4629 best r: 0.4629
17:19:43,213 root INFO 
id:ro_en cur r: 0.8203 best r: 0.8203
17:20:35,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:05,851 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4530
en_de Dev loss: 0.8608 r:0.2412
en_zh Dev loss: 0.7058 r:0.4613
ro_en Dev loss: 0.3265 r:0.8122
et_en Dev loss: 0.4361 r:0.6960
si_en Dev loss: 0.6420 r:0.6051
ne_en Dev loss: 0.4068 r:0.7449
ru_en Dev loss: 0.4468 r:0.7368
Current avg r:0.6139 Best avg r: 0.6146
17:26:39,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:52,800 root INFO 
id:en_de cur r: 0.2277 best r: 0.2277
17:27:18,972 root INFO 
id:ro_en cur r: 0.8204 best r: 0.8204
17:28:11,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:43,144 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4524
en_de Dev loss: 0.8450 r:0.2474
en_zh Dev loss: 0.7045 r:0.4498
ro_en Dev loss: 0.3217 r:0.8102
et_en Dev loss: 0.4291 r:0.6923
si_en Dev loss: 0.6993 r:0.6016
ne_en Dev loss: 0.4118 r:0.7456
ru_en Dev loss: 0.4488 r:0.7376
Current avg r:0.6121 Best avg r: 0.6146
17:34:17,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:43,843 root INFO 
id:en_zh cur r: 0.4747 best r: 0.4747
17:35:36,384 root INFO 
id:ne_en cur r: 0.7642 best r: 0.7642
17:35:49,422 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:21,179 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
17:37:21,186 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:37:21,191 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:37:21,198 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
17:37:21,203 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
17:37:21,207 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:37:21,212 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:37:34,371 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4731
en_de Dev loss: 0.8356 r:0.2487
en_zh Dev loss: 0.6588 r:0.4716
ro_en Dev loss: 0.3198 r:0.8118
et_en Dev loss: 0.4428 r:0.6953
si_en Dev loss: 0.6864 r:0.6091
ne_en Dev loss: 0.4131 r:0.7494
ru_en Dev loss: 0.3730 r:0.7539
Current avg r:0.6200 Best avg r: 0.6200
17:42:06,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:19,952 root INFO 
id:en_de cur r: 0.2316 best r: 0.2316
17:43:37,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:08,317 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4304
en_de Dev loss: 0.8602 r:0.2568
en_zh Dev loss: 0.7487 r:0.4499
ro_en Dev loss: 0.3580 r:0.8051
et_en Dev loss: 0.4703 r:0.6765
si_en Dev loss: 0.7085 r:0.6057
ne_en Dev loss: 0.4164 r:0.7503
ru_en Dev loss: 0.4989 r:0.7229
Current avg r:0.6096 Best avg r: 0.6200
17:49:39,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:52,400 root INFO 
id:en_de cur r: 0.2425 best r: 0.2425
17:50:18,295 root INFO 
id:ro_en cur r: 0.8245 best r: 0.8245
17:51:10,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:40,745 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4104
en_de Dev loss: 0.8407 r:0.2594
en_zh Dev loss: 0.7085 r:0.4495
ro_en Dev loss: 0.3214 r:0.8166
et_en Dev loss: 0.4447 r:0.6860
si_en Dev loss: 0.6460 r:0.6089
ne_en Dev loss: 0.3978 r:0.7527
ru_en Dev loss: 0.5020 r:0.7076
Current avg r:0.6115 Best avg r: 0.6200
17:57:11,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:42,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:12,976 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4221
en_de Dev loss: 0.8657 r:0.2347
en_zh Dev loss: 0.7438 r:0.4640
ro_en Dev loss: 0.3437 r:0.8142
et_en Dev loss: 0.4620 r:0.6820
si_en Dev loss: 0.8168 r:0.6008
ne_en Dev loss: 0.5286 r:0.7385
ru_en Dev loss: 0.5549 r:0.7001
Current avg r:0.6049 Best avg r: 0.6200
18:04:43,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:09,874 root INFO 
id:en_zh cur r: 0.4795 best r: 0.4795
18:05:48,789 root INFO 
id:si_en cur r: 0.6258 best r: 0.6258
18:06:14,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:45,247 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
18:07:45,253 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:07:45,258 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:07:45,262 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
18:07:45,267 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
18:07:45,271 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:07:45,277 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:07:58,255 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4450
en_de Dev loss: 0.8421 r:0.2577
en_zh Dev loss: 0.6733 r:0.4773
ro_en Dev loss: 0.3232 r:0.8175
et_en Dev loss: 0.4642 r:0.6870
si_en Dev loss: 0.6395 r:0.6271
ne_en Dev loss: 0.3850 r:0.7532
ru_en Dev loss: 0.4523 r:0.7319
Current avg r:0.6217 Best avg r: 0.6217
18:12:29,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:59,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:30,531 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4308
en_de Dev loss: 0.8848 r:0.2176
en_zh Dev loss: 0.7669 r:0.4692
ro_en Dev loss: 0.3361 r:0.8183
et_en Dev loss: 0.4792 r:0.6879
si_en Dev loss: 0.6175 r:0.6242
ne_en Dev loss: 0.3885 r:0.7537
ru_en Dev loss: 0.4988 r:0.7276
Current avg r:0.6141 Best avg r: 0.6217
18:20:01,555 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:14,518 root INFO 
id:en_de cur r: 0.2434 best r: 0.2434
18:21:32,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:02,893 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4017
en_de Dev loss: 0.8432 r:0.2647
en_zh Dev loss: 0.6817 r:0.4688
ro_en Dev loss: 0.3179 r:0.8111
et_en Dev loss: 0.4537 r:0.6831
si_en Dev loss: 0.6509 r:0.6163
ne_en Dev loss: 0.3850 r:0.7541
ru_en Dev loss: 0.4459 r:0.7191
Current avg r:0.6167 Best avg r: 0.6217
18:27:34,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:46,973 root INFO 
id:en_de cur r: 0.2484 best r: 0.2484
18:28:51,823 root INFO 
id:ne_en cur r: 0.7645 best r: 0.7645
18:29:04,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:35,314 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
18:30:35,344 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:30:35,349 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:30:35,354 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
18:30:35,364 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
18:30:35,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:30:35,376 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:30:48,368 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4419
en_de Dev loss: 0.8330 r:0.2666
en_zh Dev loss: 0.7246 r:0.4690
ro_en Dev loss: 0.3195 r:0.8204
et_en Dev loss: 0.4427 r:0.6869
si_en Dev loss: 0.6985 r:0.6148
ne_en Dev loss: 0.3805 r:0.7608
ru_en Dev loss: 0.4540 r:0.7337
Current avg r:0.6217 Best avg r: 0.6217
18:35:20,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:38,472 root INFO 
id:ne_en cur r: 0.7668 best r: 0.7668
18:36:51,368 root INFO 
id:ru_en cur r: 0.7578 best r: 0.7578
18:36:51,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:22,6 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
18:38:22,12 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:38:22,17 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:38:22,21 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
18:38:22,26 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
18:38:22,31 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:38:22,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:38:35,25 root INFO Epoch 2 Global steps: 21700 Train loss: 0.3895
en_de Dev loss: 0.8342 r:0.2493
en_zh Dev loss: 0.6852 r:0.4660
ro_en Dev loss: 0.2888 r:0.8204
et_en Dev loss: 0.4309 r:0.6912
si_en Dev loss: 0.6498 r:0.6182
ne_en Dev loss: 0.3750 r:0.7636
ru_en Dev loss: 0.3575 r:0.7619
Current avg r:0.6244 Best avg r: 0.6244
18:43:06,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:45,7 root INFO 
id:ro_en cur r: 0.8248 best r: 0.8248
18:44:36,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:07,498 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
18:46:07,504 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:46:07,510 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:46:07,516 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
18:46:07,521 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
18:46:07,527 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:46:07,533 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:46:20,519 root INFO Epoch 2 Global steps: 22400 Train loss: 0.3618
en_de Dev loss: 0.8593 r:0.2560
en_zh Dev loss: 0.7264 r:0.4659
ro_en Dev loss: 0.3326 r:0.8240
et_en Dev loss: 0.4742 r:0.6990
si_en Dev loss: 0.6608 r:0.6235
ne_en Dev loss: 0.4171 r:0.7602
ru_en Dev loss: 0.4409 r:0.7504
Current avg r:0.6256 Best avg r: 0.6256
18:50:51,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:22,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:52,863 root INFO Epoch 2 Global steps: 23100 Train loss: 0.3636
en_de Dev loss: 0.8481 r:0.2536
en_zh Dev loss: 0.7079 r:0.4655
ro_en Dev loss: 0.3125 r:0.8210
et_en Dev loss: 0.4733 r:0.6886
si_en Dev loss: 0.6168 r:0.6244
ne_en Dev loss: 0.3959 r:0.7598
ru_en Dev loss: 0.4443 r:0.7364
Current avg r:0.6213 Best avg r: 0.6256
18:58:23,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:36,848 root INFO 
id:en_de cur r: 0.2512 best r: 0.2512
18:59:54,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:25,212 root INFO Epoch 2 Global steps: 23800 Train loss: 0.3894
en_de Dev loss: 0.8345 r:0.2670
en_zh Dev loss: 0.7161 r:0.4690
ro_en Dev loss: 0.3205 r:0.8194
et_en Dev loss: 0.4579 r:0.6873
si_en Dev loss: 0.7926 r:0.6083
ne_en Dev loss: 0.4449 r:0.7566
ru_en Dev loss: 0.4587 r:0.7336
Current avg r:0.6202 Best avg r: 0.6256
19:05:56,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:09,197 root INFO 
id:en_de cur r: 0.2619 best r: 0.2619
19:07:26,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:57,514 root INFO Epoch 2 Global steps: 24500 Train loss: 0.3752
en_de Dev loss: 0.8565 r:0.2708
en_zh Dev loss: 0.7561 r:0.4488
ro_en Dev loss: 0.3258 r:0.8113
et_en Dev loss: 0.4642 r:0.6809
si_en Dev loss: 0.6321 r:0.6092
ne_en Dev loss: 0.3829 r:0.7544
ru_en Dev loss: 0.5025 r:0.7159
Current avg r:0.6130 Best avg r: 0.6256
19:13:28,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:59,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:29,848 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3616
en_de Dev loss: 0.8419 r:0.2651
en_zh Dev loss: 0.6868 r:0.4697
ro_en Dev loss: 0.3175 r:0.8141
et_en Dev loss: 0.4409 r:0.6831
si_en Dev loss: 0.7678 r:0.6044
ne_en Dev loss: 0.4042 r:0.7540
ru_en Dev loss: 0.4410 r:0.7298
Current avg r:0.6172 Best avg r: 0.6256
19:21:00,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:31,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:02,155 root INFO Epoch 2 Global steps: 25900 Train loss: 0.3758
en_de Dev loss: 0.8323 r:0.2540
en_zh Dev loss: 0.6969 r:0.4753
ro_en Dev loss: 0.3117 r:0.8179
et_en Dev loss: 0.4693 r:0.6919
si_en Dev loss: 0.6609 r:0.6143
ne_en Dev loss: 0.3683 r:0.7539
ru_en Dev loss: 0.4114 r:0.7474
Current avg r:0.6221 Best avg r: 0.6256
19:28:33,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:59,90 root INFO 
id:en_zh cur r: 0.4900 best r: 0.4900
19:29:12,59 root INFO 
id:ro_en cur r: 0.8261 best r: 0.8261
19:30:03,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:34,552 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
19:31:34,560 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
19:31:34,566 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
19:31:34,573 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
19:31:34,578 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
19:31:34,586 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
19:31:34,592 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
19:31:47,578 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3708
en_de Dev loss: 0.8362 r:0.2735
en_zh Dev loss: 0.6964 r:0.4853
ro_en Dev loss: 0.3489 r:0.8217
et_en Dev loss: 0.4664 r:0.6932
si_en Dev loss: 0.6798 r:0.6149
ne_en Dev loss: 0.3862 r:0.7574
ru_en Dev loss: 0.4427 r:0.7453
Current avg r:0.6273 Best avg r: 0.6273
19:36:18,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:44,470 root INFO 
id:en_zh cur r: 0.4920 best r: 0.4920
19:36:57,432 root INFO 
id:ro_en cur r: 0.8292 best r: 0.8292
19:37:49,254 root INFO 
id:ru_en cur r: 0.7699 best r: 0.7699
19:37:49,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:39:19,881 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
19:39:19,888 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
19:39:19,892 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
19:39:19,896 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
19:39:19,901 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
19:39:19,906 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
19:39:19,910 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
19:39:32,900 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3600
en_de Dev loss: 0.8405 r:0.2670
en_zh Dev loss: 0.6940 r:0.4841
ro_en Dev loss: 0.3111 r:0.8244
et_en Dev loss: 0.4811 r:0.7014
si_en Dev loss: 0.5729 r:0.6302
ne_en Dev loss: 0.3350 r:0.7620
ru_en Dev loss: 0.3897 r:0.7675
Current avg r:0.6338 Best avg r: 0.6338
19:44:03,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:34,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:05,285 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3485
en_de Dev loss: 0.8275 r:0.2681
en_zh Dev loss: 0.7019 r:0.4649
ro_en Dev loss: 0.3121 r:0.8246
et_en Dev loss: 0.4475 r:0.6917
si_en Dev loss: 0.6721 r:0.6177
ne_en Dev loss: 0.3755 r:0.7588
ru_en Dev loss: 0.3925 r:0.7548
Current avg r:0.6258 Best avg r: 0.6338
19:51:36,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:07,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:37,722 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3637
en_de Dev loss: 0.8234 r:0.2699
en_zh Dev loss: 0.6765 r:0.4728
ro_en Dev loss: 0.3006 r:0.8186
et_en Dev loss: 0.4375 r:0.6824
si_en Dev loss: 0.8004 r:0.5875
ne_en Dev loss: 0.4645 r:0.7433
ru_en Dev loss: 0.4207 r:0.7354
Current avg r:0.6157 Best avg r: 0.6338
19:59:08,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:39,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:10,103 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3807
en_de Dev loss: 0.8398 r:0.2448
en_zh Dev loss: 0.7055 r:0.4815
ro_en Dev loss: 0.3585 r:0.8211
et_en Dev loss: 0.4913 r:0.6869
si_en Dev loss: 0.7023 r:0.6114
ne_en Dev loss: 0.4164 r:0.7531
ru_en Dev loss: 0.4349 r:0.7469
Current avg r:0.6208 Best avg r: 0.6338
20:06:41,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:54,204 root INFO 
id:en_de cur r: 0.2722 best r: 0.2722
20:08:11,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:42,658 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3751
en_de Dev loss: 0.8320 r:0.2732
en_zh Dev loss: 0.7351 r:0.4587
ro_en Dev loss: 0.3156 r:0.8229
et_en Dev loss: 0.4390 r:0.6874
si_en Dev loss: 0.6733 r:0.6160
ne_en Dev loss: 0.4055 r:0.7520
ru_en Dev loss: 0.4384 r:0.7381
Current avg r:0.6212 Best avg r: 0.6338
20:14:13,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:44,491 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:15,502 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3603
en_de Dev loss: 0.8491 r:0.2593
en_zh Dev loss: 0.7754 r:0.4586
ro_en Dev loss: 0.3533 r:0.8190
et_en Dev loss: 0.4789 r:0.6833
si_en Dev loss: 0.7760 r:0.6095
ne_en Dev loss: 0.4729 r:0.7481
ru_en Dev loss: 0.5038 r:0.7292
Current avg r:0.6153 Best avg r: 0.6338
20:21:46,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:17,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:48,39 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3704
en_de Dev loss: 0.8409 r:0.2589
en_zh Dev loss: 0.7619 r:0.4597
ro_en Dev loss: 0.3634 r:0.8168
et_en Dev loss: 0.4837 r:0.6747
si_en Dev loss: 0.8488 r:0.5971
ne_en Dev loss: 0.5063 r:0.7455
ru_en Dev loss: 0.4888 r:0.7279
Current avg r:0.6115 Best avg r: 0.6338
20:29:20,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:51,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:22,8 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3561
en_de Dev loss: 0.8546 r:0.2537
en_zh Dev loss: 0.7526 r:0.4541
ro_en Dev loss: 0.3381 r:0.8188
et_en Dev loss: 0.4948 r:0.6821
si_en Dev loss: 0.6891 r:0.6003
ne_en Dev loss: 0.3912 r:0.7448
ru_en Dev loss: 0.4460 r:0.7262
Current avg r:0.6114 Best avg r: 0.6338
20:36:53,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:23,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:54,448 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3177
en_de Dev loss: 0.8373 r:0.2446
en_zh Dev loss: 0.7059 r:0.4557
ro_en Dev loss: 0.3137 r:0.8204
et_en Dev loss: 0.4479 r:0.6854
si_en Dev loss: 0.6561 r:0.6044
ne_en Dev loss: 0.4163 r:0.7480
ru_en Dev loss: 0.4188 r:0.7261
Current avg r:0.6121 Best avg r: 0.6338
20:44:25,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:56,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:27,48 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3194
en_de Dev loss: 0.8847 r:0.2303
en_zh Dev loss: 0.9022 r:0.4126
ro_en Dev loss: 0.3853 r:0.8117
et_en Dev loss: 0.5166 r:0.6700
si_en Dev loss: 0.9837 r:0.5769
ne_en Dev loss: 0.5870 r:0.7338
ru_en Dev loss: 0.5387 r:0.7134
Current avg r:0.5927 Best avg r: 0.6338
20:51:58,105 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:28,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:59,427 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3376
en_de Dev loss: 0.8510 r:0.2578
en_zh Dev loss: 0.7616 r:0.4520
ro_en Dev loss: 0.3128 r:0.8262
et_en Dev loss: 0.4523 r:0.6834
si_en Dev loss: 0.7162 r:0.6056
ne_en Dev loss: 0.4468 r:0.7443
ru_en Dev loss: 0.4156 r:0.7436
Current avg r:0.6161 Best avg r: 0.6338
20:59:30,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:01,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:31,881 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3250
en_de Dev loss: 0.8527 r:0.2505
en_zh Dev loss: 0.8158 r:0.4436
ro_en Dev loss: 0.3629 r:0.8205
et_en Dev loss: 0.5124 r:0.6804
si_en Dev loss: 0.7208 r:0.6061
ne_en Dev loss: 0.4185 r:0.7390
ru_en Dev loss: 0.4866 r:0.7264
Current avg r:0.6095 Best avg r: 0.6338
21:07:02,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:33,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:04,314 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3108
en_de Dev loss: 0.8344 r:0.2641
en_zh Dev loss: 0.7556 r:0.4567
ro_en Dev loss: 0.3507 r:0.8173
et_en Dev loss: 0.4737 r:0.6822
si_en Dev loss: 0.7932 r:0.5977
ne_en Dev loss: 0.4246 r:0.7474
ru_en Dev loss: 0.4476 r:0.7405
Current avg r:0.6152 Best avg r: 0.6338
21:14:35,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:06,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:36,939 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3170
en_de Dev loss: 0.8305 r:0.2748
en_zh Dev loss: 0.7314 r:0.4414
ro_en Dev loss: 0.3143 r:0.8177
et_en Dev loss: 0.4299 r:0.6687
si_en Dev loss: 0.8168 r:0.5757
ne_en Dev loss: 0.5218 r:0.7321
ru_en Dev loss: 0.4504 r:0.7198
Current avg r:0.6043 Best avg r: 0.6338
21:22:08,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:38,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:09,539 root INFO Epoch 3 Global steps: 37100 Train loss: 0.2996
en_de Dev loss: 0.8668 r:0.2423
en_zh Dev loss: 0.7954 r:0.4594
ro_en Dev loss: 0.3814 r:0.8188
et_en Dev loss: 0.4971 r:0.6779
si_en Dev loss: 0.8157 r:0.5930
ne_en Dev loss: 0.4772 r:0.7380
ru_en Dev loss: 0.5112 r:0.7295
Current avg r:0.6084 Best avg r: 0.6338
21:29:40,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:11,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:42,103 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3049
en_de Dev loss: 0.8643 r:0.2576
en_zh Dev loss: 0.8188 r:0.4529
ro_en Dev loss: 0.3409 r:0.8221
et_en Dev loss: 0.4680 r:0.6751
si_en Dev loss: 0.7197 r:0.5966
ne_en Dev loss: 0.4656 r:0.7380
ru_en Dev loss: 0.5068 r:0.7283
Current avg r:0.6101 Best avg r: 0.6338
21:37:13,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:43,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:14,544 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3144
en_de Dev loss: 0.8406 r:0.2494
en_zh Dev loss: 0.7456 r:0.4544
ro_en Dev loss: 0.3230 r:0.8225
et_en Dev loss: 0.4449 r:0.6805
si_en Dev loss: 0.6874 r:0.5973
ne_en Dev loss: 0.4783 r:0.7384
ru_en Dev loss: 0.4266 r:0.7384
Current avg r:0.6116 Best avg r: 0.6338
21:44:45,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:46:16,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:47:46,878 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3143
en_de Dev loss: 0.8501 r:0.2531
en_zh Dev loss: 0.7693 r:0.4717
ro_en Dev loss: 0.3530 r:0.8211
et_en Dev loss: 0.4561 r:0.6851
si_en Dev loss: 0.7653 r:0.5975
ne_en Dev loss: 0.4733 r:0.7401
ru_en Dev loss: 0.4639 r:0.7503
Current avg r:0.6170 Best avg r: 0.6338
21:52:18,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:48,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:55:19,465 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3188
en_de Dev loss: 0.8751 r:0.2007
en_zh Dev loss: 0.7393 r:0.4675
ro_en Dev loss: 0.3174 r:0.8256
et_en Dev loss: 0.4565 r:0.6779
si_en Dev loss: 0.7204 r:0.5977
ne_en Dev loss: 0.4323 r:0.7403
ru_en Dev loss: 0.4249 r:0.7464
Current avg r:0.6080 Best avg r: 0.6338
21:59:50,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:01:21,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:52,278 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3147
en_de Dev loss: 0.8655 r:0.2031
en_zh Dev loss: 0.7536 r:0.4533
ro_en Dev loss: 0.3390 r:0.8211
et_en Dev loss: 0.4562 r:0.6715
si_en Dev loss: 0.8450 r:0.5858
ne_en Dev loss: 0.5300 r:0.7367
ru_en Dev loss: 0.4639 r:0.7306
Current avg r:0.6003 Best avg r: 0.6338
22:07:23,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:54,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:25,105 root INFO Epoch 3 Global steps: 41300 Train loss: 0.2936
en_de Dev loss: 0.8689 r:0.2104
en_zh Dev loss: 0.7642 r:0.4514
ro_en Dev loss: 0.3160 r:0.8230
et_en Dev loss: 0.4502 r:0.6740
si_en Dev loss: 0.7082 r:0.5950
ne_en Dev loss: 0.4305 r:0.7386
ru_en Dev loss: 0.4308 r:0.7450
Current avg r:0.6053 Best avg r: 0.6338
22:14:56,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:16:27,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:57,874 root INFO Epoch 3 Global steps: 42000 Train loss: 0.2764
en_de Dev loss: 0.8742 r:0.2337
en_zh Dev loss: 0.8018 r:0.4694
ro_en Dev loss: 0.3919 r:0.8235
et_en Dev loss: 0.4884 r:0.6854
si_en Dev loss: 0.8492 r:0.5884
ne_en Dev loss: 0.4893 r:0.7412
ru_en Dev loss: 0.5113 r:0.7483
Current avg r:0.6129 Best avg r: 0.6338
22:22:30,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:01,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:25:32,17 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2602
en_de Dev loss: 0.8462 r:0.2304
en_zh Dev loss: 0.7247 r:0.4681
ro_en Dev loss: 0.3194 r:0.8223
et_en Dev loss: 0.4377 r:0.6878
si_en Dev loss: 0.7538 r:0.5836
ne_en Dev loss: 0.4449 r:0.7400
ru_en Dev loss: 0.4203 r:0.7396
Current avg r:0.6102 Best avg r: 0.6338
22:30:03,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:34,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:33:04,786 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2628
en_de Dev loss: 0.8792 r:0.2040
en_zh Dev loss: 0.7669 r:0.4584
ro_en Dev loss: 0.3266 r:0.8204
et_en Dev loss: 0.4678 r:0.6784
si_en Dev loss: 0.7177 r:0.5852
ne_en Dev loss: 0.4304 r:0.7343
ru_en Dev loss: 0.4504 r:0.7350
Current avg r:0.6022 Best avg r: 0.6338
22:37:36,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:39:06,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:37,517 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2713
en_de Dev loss: 0.8725 r:0.2180
en_zh Dev loss: 0.7983 r:0.4721
ro_en Dev loss: 0.3870 r:0.8235
et_en Dev loss: 0.4897 r:0.6875
si_en Dev loss: 0.8678 r:0.5846
ne_en Dev loss: 0.4499 r:0.7347
ru_en Dev loss: 0.4661 r:0.7495
Current avg r:0.6100 Best avg r: 0.6338
22:45:08,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:39,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:48:10,220 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2742
en_de Dev loss: 0.8890 r:0.2096
en_zh Dev loss: 0.8805 r:0.4441
ro_en Dev loss: 0.3579 r:0.8188
et_en Dev loss: 0.4829 r:0.6712
si_en Dev loss: 0.9641 r:0.5685
ne_en Dev loss: 0.6175 r:0.7299
ru_en Dev loss: 0.5696 r:0.7130
Current avg r:0.5936 Best avg r: 0.6338
22:52:41,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:54:12,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:42,871 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2719
en_de Dev loss: 0.8900 r:0.2078
en_zh Dev loss: 0.7807 r:0.4683
ro_en Dev loss: 0.3444 r:0.8227
et_en Dev loss: 0.4675 r:0.6844
si_en Dev loss: 0.8062 r:0.5723
ne_en Dev loss: 0.5266 r:0.7340
ru_en Dev loss: 0.4817 r:0.7364
Current avg r:0.6037 Best avg r: 0.6338
23:00:14,245 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:44,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:15,611 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2442
en_de Dev loss: 0.8790 r:0.1992
en_zh Dev loss: 0.7811 r:0.4425
ro_en Dev loss: 0.3499 r:0.8150
et_en Dev loss: 0.4702 r:0.6718
si_en Dev loss: 0.8845 r:0.5638
ne_en Dev loss: 0.5380 r:0.7258
ru_en Dev loss: 0.5135 r:0.7069
Current avg r:0.5893 Best avg r: 0.6338
23:07:46,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:09:17,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:48,362 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2728
en_de Dev loss: 0.8577 r:0.2244
en_zh Dev loss: 0.7835 r:0.4499
ro_en Dev loss: 0.3596 r:0.8193
et_en Dev loss: 0.4547 r:0.6774
si_en Dev loss: 0.9587 r:0.5725
ne_en Dev loss: 0.5436 r:0.7293
ru_en Dev loss: 0.4763 r:0.7264
Current avg r:0.5999 Best avg r: 0.6338
23:15:19,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:50,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:20,707 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2687
en_de Dev loss: 0.8724 r:0.2215
en_zh Dev loss: 0.7959 r:0.4591
ro_en Dev loss: 0.3475 r:0.8212
et_en Dev loss: 0.4628 r:0.6753
si_en Dev loss: 0.9014 r:0.5726
ne_en Dev loss: 0.5115 r:0.7283
ru_en Dev loss: 0.5071 r:0.7239
Current avg r:0.6003 Best avg r: 0.6338
23:22:51,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:22,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:53,332 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2777
en_de Dev loss: 0.8584 r:0.2332
en_zh Dev loss: 0.7973 r:0.4346
ro_en Dev loss: 0.3800 r:0.8136
et_en Dev loss: 0.4818 r:0.6736
si_en Dev loss: 0.9069 r:0.5670
ne_en Dev loss: 0.5512 r:0.7296
ru_en Dev loss: 0.5052 r:0.7115
Current avg r:0.5947 Best avg r: 0.6338
23:30:24,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:55,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:25,928 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2719
en_de Dev loss: 0.8940 r:0.2045
en_zh Dev loss: 0.8054 r:0.4670
ro_en Dev loss: 0.3396 r:0.8165
et_en Dev loss: 0.4578 r:0.6780
si_en Dev loss: 0.7712 r:0.5757
ne_en Dev loss: 0.4384 r:0.7302
ru_en Dev loss: 0.4434 r:0.7521
Current avg r:0.6034 Best avg r: 0.6338
23:37:57,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:27,913 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:58,598 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2495
en_de Dev loss: 0.8588 r:0.2254
en_zh Dev loss: 0.7453 r:0.4720
ro_en Dev loss: 0.3257 r:0.8215
et_en Dev loss: 0.4513 r:0.6881
si_en Dev loss: 0.6764 r:0.5945
ne_en Dev loss: 0.4004 r:0.7376
ru_en Dev loss: 0.4314 r:0.7409
Current avg r:0.6114 Best avg r: 0.6338
23:45:29,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:00,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:31,312 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2651
en_de Dev loss: 0.8893 r:0.2174
en_zh Dev loss: 0.8282 r:0.4730
ro_en Dev loss: 0.3761 r:0.8176
et_en Dev loss: 0.5017 r:0.6758
si_en Dev loss: 0.8530 r:0.5762
ne_en Dev loss: 0.4858 r:0.7285
ru_en Dev loss: 0.4807 r:0.7374
Current avg r:0.6037 Best avg r: 0.6338
23:53:02,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:33,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:03,942 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2482
en_de Dev loss: 0.8534 r:0.2198
en_zh Dev loss: 0.7560 r:0.4454
ro_en Dev loss: 0.3247 r:0.8198
et_en Dev loss: 0.4333 r:0.6766
si_en Dev loss: 0.7637 r:0.5848
ne_en Dev loss: 0.4805 r:0.7359
ru_en Dev loss: 0.4314 r:0.7295
Current avg r:0.6017 Best avg r: 0.6338
00:00:35,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:05,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:36,484 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2319
en_de Dev loss: 0.8915 r:0.2161
en_zh Dev loss: 0.8213 r:0.4636
ro_en Dev loss: 0.3529 r:0.8162
et_en Dev loss: 0.4636 r:0.6782
si_en Dev loss: 0.7663 r:0.5843
ne_en Dev loss: 0.4462 r:0.7401
ru_en Dev loss: 0.4578 r:0.7430
Current avg r:0.6059 Best avg r: 0.6338
00:08:07,726 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:38,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:09,56 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2593
en_de Dev loss: 0.8645 r:0.2178
en_zh Dev loss: 0.7375 r:0.4601
ro_en Dev loss: 0.3500 r:0.8173
et_en Dev loss: 0.4437 r:0.6737
si_en Dev loss: 0.8681 r:0.5711
ne_en Dev loss: 0.5137 r:0.7399
ru_en Dev loss: 0.4380 r:0.7337
Current avg r:0.6019 Best avg r: 0.6338
00:15:41,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:12,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:18:43,3 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2192
en_de Dev loss: 0.8676 r:0.2328
en_zh Dev loss: 0.7612 r:0.4540
ro_en Dev loss: 0.3584 r:0.8189
et_en Dev loss: 0.4502 r:0.6827
si_en Dev loss: 0.8397 r:0.5724
ne_en Dev loss: 0.5278 r:0.7370
ru_en Dev loss: 0.4557 r:0.7332
Current avg r:0.6044 Best avg r: 0.6338
00:23:14,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:40,106 root INFO 
id:en_zh cur r: 0.4927 best r: 0.4927
00:24:44,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:26:15,530 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2213
en_de Dev loss: 0.8851 r:0.2030
en_zh Dev loss: 0.7234 r:0.4891
ro_en Dev loss: 0.3106 r:0.8237
et_en Dev loss: 0.4359 r:0.6809
si_en Dev loss: 0.7038 r:0.5845
ne_en Dev loss: 0.4224 r:0.7351
ru_en Dev loss: 0.3883 r:0.7522
Current avg r:0.6098 Best avg r: 0.6338
00:30:46,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:32:17,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:33:48,67 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2327
en_de Dev loss: 0.8769 r:0.2173
en_zh Dev loss: 0.7869 r:0.4643
ro_en Dev loss: 0.3667 r:0.8175
et_en Dev loss: 0.4715 r:0.6733
si_en Dev loss: 0.8167 r:0.5785
ne_en Dev loss: 0.5239 r:0.7308
ru_en Dev loss: 0.4584 r:0.7325
Current avg r:0.6020 Best avg r: 0.6338
00:38:19,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:39:49,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:20,618 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2381
en_de Dev loss: 0.8587 r:0.2377
en_zh Dev loss: 0.8080 r:0.4539
ro_en Dev loss: 0.3537 r:0.8183
et_en Dev loss: 0.4569 r:0.6792
si_en Dev loss: 0.7813 r:0.5751
ne_en Dev loss: 0.4495 r:0.7343
ru_en Dev loss: 0.4699 r:0.7331
Current avg r:0.6045 Best avg r: 0.6338
00:45:51,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:47:22,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:48:53,209 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2220
en_de Dev loss: 0.8763 r:0.2134
en_zh Dev loss: 0.7590 r:0.4690
ro_en Dev loss: 0.3311 r:0.8203
et_en Dev loss: 0.4528 r:0.6728
si_en Dev loss: 0.8640 r:0.5660
ne_en Dev loss: 0.5014 r:0.7298
ru_en Dev loss: 0.4606 r:0.7275
Current avg r:0.5998 Best avg r: 0.6338
00:53:24,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:54:55,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:56:25,651 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2196
en_de Dev loss: 0.8923 r:0.2423
en_zh Dev loss: 0.8596 r:0.4530
ro_en Dev loss: 0.3545 r:0.8170
et_en Dev loss: 0.4756 r:0.6789
si_en Dev loss: 0.8435 r:0.5751
ne_en Dev loss: 0.4816 r:0.7354
ru_en Dev loss: 0.5537 r:0.7205
Current avg r:0.6032 Best avg r: 0.6338
01:00:56,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:02:27,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:57,938 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2210
en_de Dev loss: 0.8550 r:0.2361
en_zh Dev loss: 0.7446 r:0.4659
ro_en Dev loss: 0.3076 r:0.8199
et_en Dev loss: 0.4144 r:0.6892
si_en Dev loss: 0.7474 r:0.5723
ne_en Dev loss: 0.4388 r:0.7335
ru_en Dev loss: 0.4155 r:0.7421
Current avg r:0.6084 Best avg r: 0.6338
01:08:29,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:59,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:30,292 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2263
en_de Dev loss: 0.8791 r:0.2209
en_zh Dev loss: 0.7923 r:0.4682
ro_en Dev loss: 0.3441 r:0.8200
et_en Dev loss: 0.4515 r:0.6809
si_en Dev loss: 0.8693 r:0.5704
ne_en Dev loss: 0.5015 r:0.7270
ru_en Dev loss: 0.4763 r:0.7336
Current avg r:0.6030 Best avg r: 0.6338
01:16:01,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:31,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:02,663 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2231
en_de Dev loss: 0.8998 r:0.2238
en_zh Dev loss: 0.8255 r:0.4526
ro_en Dev loss: 0.3672 r:0.8175
et_en Dev loss: 0.4649 r:0.6862
si_en Dev loss: 0.8200 r:0.5720
ne_en Dev loss: 0.4928 r:0.7288
ru_en Dev loss: 0.4703 r:0.7362
Current avg r:0.6025 Best avg r: 0.6338
01:23:33,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:04,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:35,189 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2185
en_de Dev loss: 0.8946 r:0.2140
en_zh Dev loss: 0.7564 r:0.4666
ro_en Dev loss: 0.3201 r:0.8179
et_en Dev loss: 0.4334 r:0.6744
si_en Dev loss: 0.7742 r:0.5680
ne_en Dev loss: 0.4939 r:0.7221
ru_en Dev loss: 0.4442 r:0.7324
Current avg r:0.5993 Best avg r: 0.6338
01:31:06,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:32:37,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:07,752 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2237
en_de Dev loss: 0.8611 r:0.2232
en_zh Dev loss: 0.7691 r:0.4524
ro_en Dev loss: 0.3309 r:0.8163
et_en Dev loss: 0.4246 r:0.6808
si_en Dev loss: 0.8122 r:0.5651
ne_en Dev loss: 0.5729 r:0.7277
ru_en Dev loss: 0.4714 r:0.7133
Current avg r:0.5970 Best avg r: 0.6338
01:38:38,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:40:09,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:41:40,240 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2153
en_de Dev loss: 0.8820 r:0.2143
en_zh Dev loss: 0.7800 r:0.4690
ro_en Dev loss: 0.3426 r:0.8207
et_en Dev loss: 0.4556 r:0.6872
si_en Dev loss: 0.7333 r:0.5794
ne_en Dev loss: 0.4425 r:0.7308
ru_en Dev loss: 0.4164 r:0.7449
Current avg r:0.6066 Best avg r: 0.6338
01:46:11,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:47:42,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:49:12,773 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2166
en_de Dev loss: 0.9122 r:0.1927
en_zh Dev loss: 0.7709 r:0.4733
ro_en Dev loss: 0.3330 r:0.8187
et_en Dev loss: 0.4551 r:0.6864
si_en Dev loss: 0.7733 r:0.5727
ne_en Dev loss: 0.4577 r:0.7278
ru_en Dev loss: 0.4217 r:0.7423
Current avg r:0.6020 Best avg r: 0.6338
01:53:44,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:55:16,458 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:56:48,649 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2102
en_de Dev loss: 0.9001 r:0.1817
en_zh Dev loss: 0.7561 r:0.4700
ro_en Dev loss: 0.3362 r:0.8224
et_en Dev loss: 0.4320 r:0.6780
si_en Dev loss: 0.8354 r:0.5639
ne_en Dev loss: 0.5212 r:0.7299
ru_en Dev loss: 0.4667 r:0.7264
Current avg r:0.5961 Best avg r: 0.6338
02:01:26,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:02:58,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:04:29,889 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2195
en_de Dev loss: 0.8994 r:0.2026
en_zh Dev loss: 0.7812 r:0.4482
ro_en Dev loss: 0.3106 r:0.8215
et_en Dev loss: 0.4201 r:0.6777
si_en Dev loss: 0.7867 r:0.5679
ne_en Dev loss: 0.4611 r:0.7307
ru_en Dev loss: 0.4529 r:0.7297
Current avg r:0.5969 Best avg r: 0.6338
02:09:08,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:10:40,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:12:12,119 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2007
en_de Dev loss: 0.8970 r:0.1999
en_zh Dev loss: 0.7683 r:0.4589
ro_en Dev loss: 0.3306 r:0.8209
et_en Dev loss: 0.4406 r:0.6798
si_en Dev loss: 0.7646 r:0.5740
ne_en Dev loss: 0.4816 r:0.7276
ru_en Dev loss: 0.4658 r:0.7314
Current avg r:0.5989 Best avg r: 0.6338
02:16:48,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:18:20,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:52,586 root INFO Epoch 6 Global steps: 64400 Train loss: 0.1887
en_de Dev loss: 0.8815 r:0.2118
en_zh Dev loss: 0.7912 r:0.4527
ro_en Dev loss: 0.3443 r:0.8185
et_en Dev loss: 0.4518 r:0.6803
si_en Dev loss: 0.8595 r:0.5653
ne_en Dev loss: 0.5239 r:0.7306
ru_en Dev loss: 0.4566 r:0.7363
Current avg r:0.5993 Best avg r: 0.6338
02:24:29,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:25:59,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:30,801 root INFO Epoch 6 Global steps: 65100 Train loss: 0.1927
en_de Dev loss: 0.9060 r:0.2280
en_zh Dev loss: 0.8380 r:0.4532
ro_en Dev loss: 0.3666 r:0.8127
et_en Dev loss: 0.4798 r:0.6740
si_en Dev loss: 0.8930 r:0.5620
ne_en Dev loss: 0.5262 r:0.7316
ru_en Dev loss: 0.5048 r:0.7274
Current avg r:0.5984 Best avg r: 0.6338
02:32:02,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:33:33,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:35:04,314 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2083
en_de Dev loss: 0.9216 r:0.2163
en_zh Dev loss: 0.7932 r:0.4630
ro_en Dev loss: 0.3451 r:0.8198
et_en Dev loss: 0.4839 r:0.6869
si_en Dev loss: 0.6958 r:0.5796
ne_en Dev loss: 0.4272 r:0.7259
ru_en Dev loss: 0.4114 r:0.7549
Current avg r:0.6066 Best avg r: 0.6338
02:39:36,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:41:07,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:42:38,201 root INFO Epoch 6 Global steps: 66500 Train loss: 0.1809
en_de Dev loss: 0.9318 r:0.2186
en_zh Dev loss: 0.8011 r:0.4681
ro_en Dev loss: 0.3769 r:0.8176
et_en Dev loss: 0.4704 r:0.6685
si_en Dev loss: 0.8790 r:0.5619
ne_en Dev loss: 0.5249 r:0.7279
ru_en Dev loss: 0.4632 r:0.7320
Current avg r:0.5992 Best avg r: 0.6338
02:47:10,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:48:40,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:50:11,742 root INFO Epoch 6 Global steps: 67200 Train loss: 0.1921
en_de Dev loss: 0.8848 r:0.2075
en_zh Dev loss: 0.7906 r:0.4473
ro_en Dev loss: 0.3659 r:0.8135
et_en Dev loss: 0.4542 r:0.6710
si_en Dev loss: 0.8736 r:0.5557
ne_en Dev loss: 0.5754 r:0.7213
ru_en Dev loss: 0.4619 r:0.7216
Current avg r:0.5911 Best avg r: 0.6338
02:54:43,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:14,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:57:45,234 root INFO Epoch 6 Global steps: 67900 Train loss: 0.1797
en_de Dev loss: 0.9159 r:0.2055
en_zh Dev loss: 0.8910 r:0.4343
ro_en Dev loss: 0.3707 r:0.8112
et_en Dev loss: 0.4423 r:0.6693
si_en Dev loss: 0.9486 r:0.5476
ne_en Dev loss: 0.6061 r:0.7237
ru_en Dev loss: 0.5338 r:0.7139
Current avg r:0.5865 Best avg r: 0.6338
03:02:17,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:47,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:05:18,828 root INFO Epoch 6 Global steps: 68600 Train loss: 0.1917
en_de Dev loss: 0.8879 r:0.2105
en_zh Dev loss: 0.8091 r:0.4533
ro_en Dev loss: 0.3656 r:0.8171
et_en Dev loss: 0.4469 r:0.6796
si_en Dev loss: 0.9112 r:0.5598
ne_en Dev loss: 0.5328 r:0.7239
ru_en Dev loss: 0.4962 r:0.7265
Current avg r:0.5958 Best avg r: 0.6338
03:09:50,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:11:21,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:12:52,367 root INFO Epoch 6 Global steps: 69300 Train loss: 0.1912
en_de Dev loss: 0.8659 r:0.2303
en_zh Dev loss: 0.7813 r:0.4489
ro_en Dev loss: 0.3264 r:0.8162
et_en Dev loss: 0.4276 r:0.6812
si_en Dev loss: 0.7978 r:0.5633
ne_en Dev loss: 0.4898 r:0.7204
ru_en Dev loss: 0.4215 r:0.7423
Current avg r:0.6004 Best avg r: 0.6338
03:17:24,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:18:55,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:20:25,905 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1823
en_de Dev loss: 0.8919 r:0.2023
en_zh Dev loss: 0.8541 r:0.4117
ro_en Dev loss: 0.3762 r:0.8081
et_en Dev loss: 0.4472 r:0.6636
si_en Dev loss: 0.9161 r:0.5500
ne_en Dev loss: 0.5847 r:0.7244
ru_en Dev loss: 0.4913 r:0.7196
Current avg r:0.5828 Best avg r: 0.6338
03:24:57,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:26:28,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:27:59,518 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1918
en_de Dev loss: 0.8883 r:0.2281
en_zh Dev loss: 0.8164 r:0.4471
ro_en Dev loss: 0.3640 r:0.8113
et_en Dev loss: 0.4558 r:0.6736
si_en Dev loss: 0.8710 r:0.5557
ne_en Dev loss: 0.5085 r:0.7278
ru_en Dev loss: 0.4707 r:0.7340
Current avg r:0.5968 Best avg r: 0.6338
03:32:31,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:34:02,222 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:35:33,46 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1782
en_de Dev loss: 0.8850 r:0.2080
en_zh Dev loss: 0.7650 r:0.4562
ro_en Dev loss: 0.3448 r:0.8170
et_en Dev loss: 0.4582 r:0.6798
si_en Dev loss: 0.7642 r:0.5666
ne_en Dev loss: 0.4769 r:0.7244
ru_en Dev loss: 0.4134 r:0.7434
Current avg r:0.5994 Best avg r: 0.6338
03:40:04,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:41:35,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:43:06,569 root INFO Epoch 6 Global steps: 72100 Train loss: 0.1761
en_de Dev loss: 0.9098 r:0.2089
en_zh Dev loss: 0.8353 r:0.4506
ro_en Dev loss: 0.3803 r:0.8117
et_en Dev loss: 0.4739 r:0.6635
si_en Dev loss: 0.9548 r:0.5480
ne_en Dev loss: 0.6086 r:0.7195
ru_en Dev loss: 0.5173 r:0.7220
Current avg r:0.5892 Best avg r: 0.6338
03:47:38,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:49:09,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:50:40,386 root INFO Epoch 6 Global steps: 72800 Train loss: 0.1756
en_de Dev loss: 0.9130 r:0.2044
en_zh Dev loss: 0.8008 r:0.4564
ro_en Dev loss: 0.3622 r:0.8154
et_en Dev loss: 0.4507 r:0.6752
si_en Dev loss: 0.8532 r:0.5590
ne_en Dev loss: 0.4670 r:0.7221
ru_en Dev loss: 0.4677 r:0.7378
Current avg r:0.5958 Best avg r: 0.6338
03:55:12,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:56:43,298 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:58:14,125 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1803
en_de Dev loss: 0.8972 r:0.2009
en_zh Dev loss: 0.7931 r:0.4540
ro_en Dev loss: 0.3362 r:0.8155
et_en Dev loss: 0.4314 r:0.6695
si_en Dev loss: 0.9251 r:0.5403
ne_en Dev loss: 0.5325 r:0.7153
ru_en Dev loss: 0.4842 r:0.7229
Current avg r:0.5883 Best avg r: 0.6338
04:02:47,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:18,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:05:49,350 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1646
en_de Dev loss: 0.9025 r:0.2115
en_zh Dev loss: 0.7819 r:0.4568
ro_en Dev loss: 0.3371 r:0.8162
et_en Dev loss: 0.4447 r:0.6784
si_en Dev loss: 0.8086 r:0.5549
ne_en Dev loss: 0.4954 r:0.7199
ru_en Dev loss: 0.4261 r:0.7451
Current avg r:0.5976 Best avg r: 0.6338
04:10:21,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:11:52,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:13:23,154 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1647
en_de Dev loss: 0.8826 r:0.2022
en_zh Dev loss: 0.7922 r:0.4422
ro_en Dev loss: 0.3476 r:0.8134
et_en Dev loss: 0.4268 r:0.6752
si_en Dev loss: 0.9801 r:0.5385
ne_en Dev loss: 0.6148 r:0.7162
ru_en Dev loss: 0.5018 r:0.7109
Current avg r:0.5855 Best avg r: 0.6338
04:17:55,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:19:26,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:20:56,831 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1557
en_de Dev loss: 0.9288 r:0.2004
en_zh Dev loss: 0.8541 r:0.4480
ro_en Dev loss: 0.3674 r:0.8152
et_en Dev loss: 0.4610 r:0.6731
si_en Dev loss: 0.8762 r:0.5464
ne_en Dev loss: 0.5017 r:0.7185
ru_en Dev loss: 0.4996 r:0.7331
Current avg r:0.5907 Best avg r: 0.6338
04:25:28,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:26:59,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:28:30,664 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1652
en_de Dev loss: 0.9085 r:0.2048
en_zh Dev loss: 0.8042 r:0.4627
ro_en Dev loss: 0.3765 r:0.8161
et_en Dev loss: 0.4461 r:0.6784
si_en Dev loss: 0.9636 r:0.5430
ne_en Dev loss: 0.5350 r:0.7174
ru_en Dev loss: 0.4973 r:0.7326
Current avg r:0.5936 Best avg r: 0.6338
04:33:02,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:34:33,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:36:04,504 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1604
en_de Dev loss: 0.9583 r:0.1706
en_zh Dev loss: 0.8613 r:0.4513
ro_en Dev loss: 0.3977 r:0.8138
et_en Dev loss: 0.4875 r:0.6679
si_en Dev loss: 0.9835 r:0.5455
ne_en Dev loss: 0.6022 r:0.7177
ru_en Dev loss: 0.5274 r:0.7207
Current avg r:0.5839 Best avg r: 0.6338
04:40:36,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:42:07,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:43:38,309 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1569
en_de Dev loss: 0.9306 r:0.1855
en_zh Dev loss: 0.8104 r:0.4498
ro_en Dev loss: 0.3699 r:0.8135
et_en Dev loss: 0.4574 r:0.6684
si_en Dev loss: 0.9015 r:0.5400
ne_en Dev loss: 0.5734 r:0.7088
ru_en Dev loss: 0.5332 r:0.7045
Current avg r:0.5815 Best avg r: 0.6338
04:48:10,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:49:41,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:12,25 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1622
en_de Dev loss: 0.9181 r:0.1887
en_zh Dev loss: 0.8101 r:0.4483
ro_en Dev loss: 0.3478 r:0.8158
et_en Dev loss: 0.4287 r:0.6790
si_en Dev loss: 0.8253 r:0.5432
ne_en Dev loss: 0.4891 r:0.7115
ru_en Dev loss: 0.4735 r:0.7324
Current avg r:0.5884 Best avg r: 0.6338
04:55:44,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:15,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:45,944 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1603
en_de Dev loss: 0.9171 r:0.2025
en_zh Dev loss: 0.8236 r:0.4505
ro_en Dev loss: 0.3902 r:0.8107
et_en Dev loss: 0.4430 r:0.6703
si_en Dev loss: 0.9462 r:0.5375
ne_en Dev loss: 0.5826 r:0.7179
ru_en Dev loss: 0.5130 r:0.7218
Current avg r:0.5873 Best avg r: 0.6338
05:03:18,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:04:48,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:06:19,897 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1562
en_de Dev loss: 0.8866 r:0.2080
en_zh Dev loss: 0.7496 r:0.4600
ro_en Dev loss: 0.3276 r:0.8145
et_en Dev loss: 0.4258 r:0.6745
si_en Dev loss: 0.8136 r:0.5435
ne_en Dev loss: 0.5347 r:0.7137
ru_en Dev loss: 0.4318 r:0.7367
Current avg r:0.5930 Best avg r: 0.6338
05:10:54,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:12:26,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:13:58,191 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1684
en_de Dev loss: 0.8993 r:0.2066
en_zh Dev loss: 0.7840 r:0.4586
ro_en Dev loss: 0.3514 r:0.8132
et_en Dev loss: 0.4475 r:0.6681
si_en Dev loss: 0.8463 r:0.5471
ne_en Dev loss: 0.5443 r:0.7206
ru_en Dev loss: 0.4656 r:0.7354
Current avg r:0.5928 Best avg r: 0.6338
05:18:33,895 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:05,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:21:37,741 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1592
en_de Dev loss: 0.9128 r:0.2112
en_zh Dev loss: 0.8127 r:0.4575
ro_en Dev loss: 0.3486 r:0.8175
et_en Dev loss: 0.4424 r:0.6759
si_en Dev loss: 0.8386 r:0.5500
ne_en Dev loss: 0.4993 r:0.7207
ru_en Dev loss: 0.4744 r:0.7414
Current avg r:0.5963 Best avg r: 0.6338
05:26:14,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:27:46,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:29:18,224 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1544
en_de Dev loss: 0.9096 r:0.1992
en_zh Dev loss: 0.8488 r:0.4398
ro_en Dev loss: 0.3982 r:0.8100
et_en Dev loss: 0.4568 r:0.6671
si_en Dev loss: 0.9711 r:0.5362
ne_en Dev loss: 0.6132 r:0.7183
ru_en Dev loss: 0.4748 r:0.7329
Current avg r:0.5862 Best avg r: 0.6338
05:33:54,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:35:25,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:36:57,117 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1545
en_de Dev loss: 0.9177 r:0.2015
en_zh Dev loss: 0.8127 r:0.4537
ro_en Dev loss: 0.3804 r:0.8110
et_en Dev loss: 0.4648 r:0.6682
si_en Dev loss: 1.0477 r:0.5245
ne_en Dev loss: 0.6541 r:0.7047
ru_en Dev loss: 0.4749 r:0.7312
Current avg r:0.5850 Best avg r: 0.6338
05:41:31,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:03,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:44:34,376 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1584
en_de Dev loss: 0.9317 r:0.2084
en_zh Dev loss: 0.8282 r:0.4510
ro_en Dev loss: 0.3723 r:0.8113
et_en Dev loss: 0.4558 r:0.6792
si_en Dev loss: 0.8980 r:0.5427
ne_en Dev loss: 0.5459 r:0.7191
ru_en Dev loss: 0.5081 r:0.7377
Current avg r:0.5928 Best avg r: 0.6338
05:49:06,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:50:37,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:52:08,263 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1604
en_de Dev loss: 0.9211 r:0.2024
en_zh Dev loss: 0.8018 r:0.4547
ro_en Dev loss: 0.3473 r:0.8148
et_en Dev loss: 0.4429 r:0.6796
si_en Dev loss: 0.8802 r:0.5431
ne_en Dev loss: 0.5496 r:0.7103
ru_en Dev loss: 0.4803 r:0.7357
Current avg r:0.5915 Best avg r: 0.6338
05:56:41,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:58:12,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:43,184 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1380
en_de Dev loss: 0.9280 r:0.1785
en_zh Dev loss: 0.8243 r:0.4495
ro_en Dev loss: 0.3769 r:0.8151
et_en Dev loss: 0.4440 r:0.6759
si_en Dev loss: 0.9878 r:0.5304
ne_en Dev loss: 0.6330 r:0.7064
ru_en Dev loss: 0.4674 r:0.7331
Current avg r:0.5841 Best avg r: 0.6338
06:04:15,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:05:46,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:07:17,84 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1431
en_de Dev loss: 0.9537 r:0.1953
en_zh Dev loss: 0.8372 r:0.4508
ro_en Dev loss: 0.3682 r:0.8137
et_en Dev loss: 0.4483 r:0.6701
si_en Dev loss: 0.9266 r:0.5336
ne_en Dev loss: 0.5880 r:0.7020
ru_en Dev loss: 0.4840 r:0.7431
Current avg r:0.5869 Best avg r: 0.6338
06:11:49,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:13:20,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:14:50,984 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1389
en_de Dev loss: 0.9229 r:0.1952
en_zh Dev loss: 0.7854 r:0.4624
ro_en Dev loss: 0.3550 r:0.8175
et_en Dev loss: 0.4420 r:0.6756
si_en Dev loss: 0.9909 r:0.5340
ne_en Dev loss: 0.6572 r:0.7071
ru_en Dev loss: 0.4477 r:0.7506
Current avg r:0.5918 Best avg r: 0.6338
06:19:22,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:20:53,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:22:24,636 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1386
en_de Dev loss: 0.9391 r:0.1781
en_zh Dev loss: 0.8014 r:0.4498
ro_en Dev loss: 0.3503 r:0.8157
et_en Dev loss: 0.4250 r:0.6761
si_en Dev loss: 0.8873 r:0.5270
ne_en Dev loss: 0.6137 r:0.7002
ru_en Dev loss: 0.4376 r:0.7464
Current avg r:0.5848 Best avg r: 0.6338
06:26:56,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:28:27,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:29:58,520 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1441
en_de Dev loss: 0.9745 r:0.1772
en_zh Dev loss: 0.8658 r:0.4538
ro_en Dev loss: 0.3647 r:0.8167
et_en Dev loss: 0.4457 r:0.6731
si_en Dev loss: 0.9319 r:0.5369
ne_en Dev loss: 0.5846 r:0.7070
ru_en Dev loss: 0.5233 r:0.7305
Current avg r:0.5850 Best avg r: 0.6338
06:34:30,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:01,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:32,393 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1396
en_de Dev loss: 0.9577 r:0.1764
en_zh Dev loss: 0.8276 r:0.4559
ro_en Dev loss: 0.3567 r:0.8160
et_en Dev loss: 0.4437 r:0.6764
si_en Dev loss: 0.8835 r:0.5417
ne_en Dev loss: 0.5485 r:0.7040
ru_en Dev loss: 0.4979 r:0.7334
Current avg r:0.5863 Best avg r: 0.6338
06:42:04,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:43:35,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:06,219 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1380
en_de Dev loss: 0.9373 r:0.1655
en_zh Dev loss: 0.7675 r:0.4579
ro_en Dev loss: 0.3394 r:0.8159
et_en Dev loss: 0.4262 r:0.6775
si_en Dev loss: 0.9210 r:0.5408
ne_en Dev loss: 0.6086 r:0.7060
ru_en Dev loss: 0.4880 r:0.7290
Current avg r:0.5847 Best avg r: 0.6338
06:49:38,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:09,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:52:39,993 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1392
en_de Dev loss: 0.9627 r:0.1782
en_zh Dev loss: 0.8553 r:0.4496
ro_en Dev loss: 0.3856 r:0.8112
et_en Dev loss: 0.4640 r:0.6647
si_en Dev loss: 1.0417 r:0.5236
ne_en Dev loss: 0.6048 r:0.7066
ru_en Dev loss: 0.4997 r:0.7367
Current avg r:0.5815 Best avg r: 0.6338
06:57:12,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:58:42,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:00:13,830 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1400
en_de Dev loss: 0.9236 r:0.1720
en_zh Dev loss: 0.8066 r:0.4457
ro_en Dev loss: 0.3749 r:0.8153
et_en Dev loss: 0.4394 r:0.6738
si_en Dev loss: 0.9497 r:0.5345
ne_en Dev loss: 0.5592 r:0.7080
ru_en Dev loss: 0.4607 r:0.7385
Current avg r:0.5840 Best avg r: 0.6338
07:04:45,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:06:16,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:07:47,599 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1308
en_de Dev loss: 0.9440 r:0.1697
en_zh Dev loss: 0.8136 r:0.4469
ro_en Dev loss: 0.3510 r:0.8178
et_en Dev loss: 0.4337 r:0.6798
si_en Dev loss: 0.8482 r:0.5446
ne_en Dev loss: 0.5390 r:0.7140
ru_en Dev loss: 0.4414 r:0.7500
Current avg r:0.5890 Best avg r: 0.6338
07:12:19,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:50,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:21,99 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1361
en_de Dev loss: 0.9594 r:0.1708
en_zh Dev loss: 0.8278 r:0.4522
ro_en Dev loss: 0.3890 r:0.8112
et_en Dev loss: 0.4516 r:0.6723
si_en Dev loss: 1.0080 r:0.5298
ne_en Dev loss: 0.6869 r:0.7050
ru_en Dev loss: 0.5089 r:0.7355
Current avg r:0.5824 Best avg r: 0.6338
07:19:52,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:21:23,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:22:54,481 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1368
en_de Dev loss: 0.9513 r:0.1864
en_zh Dev loss: 0.8391 r:0.4512
ro_en Dev loss: 0.3712 r:0.8118
et_en Dev loss: 0.4458 r:0.6724
si_en Dev loss: 1.0228 r:0.5309
ne_en Dev loss: 0.5986 r:0.7061
ru_en Dev loss: 0.4936 r:0.7424
Current avg r:0.5859 Best avg r: 0.6338
07:27:26,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:28:57,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:28,8 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1361
en_de Dev loss: 0.9570 r:0.1669
en_zh Dev loss: 0.8223 r:0.4566
ro_en Dev loss: 0.3655 r:0.8160
et_en Dev loss: 0.4384 r:0.6774
si_en Dev loss: 0.9234 r:0.5392
ne_en Dev loss: 0.5220 r:0.7121
ru_en Dev loss: 0.4739 r:0.7445
Current avg r:0.5875 Best avg r: 0.6338
07:34:59,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:36:30,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:38:01,628 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1349
en_de Dev loss: 0.9318 r:0.1704
en_zh Dev loss: 0.8077 r:0.4504
ro_en Dev loss: 0.3547 r:0.8170
et_en Dev loss: 0.4251 r:0.6807
si_en Dev loss: 0.9374 r:0.5340
ne_en Dev loss: 0.5834 r:0.7043
ru_en Dev loss: 0.4494 r:0.7490
Current avg r:0.5866 Best avg r: 0.6338
07:42:33,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:44:04,371 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:35,253 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1379
en_de Dev loss: 0.9368 r:0.1630
en_zh Dev loss: 0.7872 r:0.4512
ro_en Dev loss: 0.3637 r:0.8162
et_en Dev loss: 0.4330 r:0.6765
si_en Dev loss: 0.9486 r:0.5321
ne_en Dev loss: 0.6065 r:0.7076
ru_en Dev loss: 0.4289 r:0.7516
Current avg r:0.5855 Best avg r: 0.6338
07:50:08,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:51:39,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:53:10,76 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1234
en_de Dev loss: 0.9409 r:0.1879
en_zh Dev loss: 0.8062 r:0.4660
ro_en Dev loss: 0.3675 r:0.8148
et_en Dev loss: 0.4443 r:0.6790
si_en Dev loss: 0.9565 r:0.5421
ne_en Dev loss: 0.5854 r:0.7056
ru_en Dev loss: 0.4549 r:0.7538
Current avg r:0.5928 Best avg r: 0.6338
07:57:42,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:59:12,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:00:43,780 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1188
en_de Dev loss: 0.9625 r:0.1767
en_zh Dev loss: 0.8495 r:0.4587
ro_en Dev loss: 0.4056 r:0.8117
et_en Dev loss: 0.4557 r:0.6795
si_en Dev loss: 1.0487 r:0.5379
ne_en Dev loss: 0.6422 r:0.7116
ru_en Dev loss: 0.5179 r:0.7419
Current avg r:0.5883 Best avg r: 0.6338
08:05:15,655 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:06:46,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:08:17,282 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1293
en_de Dev loss: 0.9369 r:0.1839
en_zh Dev loss: 0.7958 r:0.4583
ro_en Dev loss: 0.3678 r:0.8150
et_en Dev loss: 0.4260 r:0.6816
si_en Dev loss: 0.8966 r:0.5395
ne_en Dev loss: 0.5810 r:0.7053
ru_en Dev loss: 0.4508 r:0.7468
Current avg r:0.5901 Best avg r: 0.6338
08:12:49,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:14:20,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:15:50,893 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1203
en_de Dev loss: 0.9409 r:0.1914
en_zh Dev loss: 0.8029 r:0.4651
ro_en Dev loss: 0.3653 r:0.8146
et_en Dev loss: 0.4370 r:0.6832
si_en Dev loss: 0.9130 r:0.5436
ne_en Dev loss: 0.5602 r:0.7099
ru_en Dev loss: 0.4641 r:0.7430
Current avg r:0.5930 Best avg r: 0.6338
08:20:26,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:57,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:29,546 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1216
en_de Dev loss: 0.9274 r:0.1722
en_zh Dev loss: 0.7588 r:0.4631
ro_en Dev loss: 0.3401 r:0.8135
et_en Dev loss: 0.3987 r:0.6883
si_en Dev loss: 0.8513 r:0.5391
ne_en Dev loss: 0.5256 r:0.7100
ru_en Dev loss: 0.4280 r:0.7506
Current avg r:0.5910 Best avg r: 0.6338
08:28:05,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:29:37,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:31:08,785 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1227
en_de Dev loss: 0.9504 r:0.2062
en_zh Dev loss: 0.8014 r:0.4693
ro_en Dev loss: 0.3606 r:0.8162
et_en Dev loss: 0.4311 r:0.6848
si_en Dev loss: 0.9031 r:0.5372
ne_en Dev loss: 0.5367 r:0.7055
ru_en Dev loss: 0.4275 r:0.7583
Current avg r:0.5968 Best avg r: 0.6338
08:35:44,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:37:16,270 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:38:48,111 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1172
en_de Dev loss: 0.9193 r:0.2002
en_zh Dev loss: 0.7735 r:0.4678
ro_en Dev loss: 0.3335 r:0.8158
et_en Dev loss: 0.4095 r:0.6810
si_en Dev loss: 0.8862 r:0.5368
ne_en Dev loss: 0.5406 r:0.7061
ru_en Dev loss: 0.4022 r:0.7597
Current avg r:0.5954 Best avg r: 0.6338
08:43:23,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:44:54,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:46:26,417 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1255
en_de Dev loss: 0.9496 r:0.2075
en_zh Dev loss: 0.8175 r:0.4631
ro_en Dev loss: 0.3833 r:0.8123
et_en Dev loss: 0.4424 r:0.6766
si_en Dev loss: 0.9749 r:0.5313
ne_en Dev loss: 0.6317 r:0.6980
ru_en Dev loss: 0.4648 r:0.7411
Current avg r:0.5900 Best avg r: 0.6338
08:51:01,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:52:32,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:03,982 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1224
en_de Dev loss: 0.9716 r:0.1851
en_zh Dev loss: 0.7979 r:0.4704
ro_en Dev loss: 0.3682 r:0.8178
et_en Dev loss: 0.4212 r:0.6844
si_en Dev loss: 0.9341 r:0.5363
ne_en Dev loss: 0.6135 r:0.7050
ru_en Dev loss: 0.4673 r:0.7479
Current avg r:0.5924 Best avg r: 0.6338
08:58:38,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:00:10,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:01:41,672 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1188
en_de Dev loss: 0.9511 r:0.1768
en_zh Dev loss: 0.7714 r:0.4623
ro_en Dev loss: 0.3268 r:0.8176
et_en Dev loss: 0.4017 r:0.6797
si_en Dev loss: 0.8669 r:0.5300
ne_en Dev loss: 0.5526 r:0.6987
ru_en Dev loss: 0.4824 r:0.7239
Current avg r:0.5841 Best avg r: 0.6338
09:06:13,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:07:44,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:15,493 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1195
en_de Dev loss: 0.9329 r:0.1886
en_zh Dev loss: 0.7685 r:0.4643
ro_en Dev loss: 0.3652 r:0.8133
et_en Dev loss: 0.4174 r:0.6836
si_en Dev loss: 0.9203 r:0.5370
ne_en Dev loss: 0.5642 r:0.7059
ru_en Dev loss: 0.4156 r:0.7534
Current avg r:0.5923 Best avg r: 0.6338
09:13:47,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:18,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:49,119 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1201
en_de Dev loss: 0.9746 r:0.1744
en_zh Dev loss: 0.7962 r:0.4694
ro_en Dev loss: 0.3676 r:0.8147
et_en Dev loss: 0.4145 r:0.6860
si_en Dev loss: 0.9001 r:0.5364
ne_en Dev loss: 0.5980 r:0.7048
ru_en Dev loss: 0.4784 r:0.7369
Current avg r:0.5889 Best avg r: 0.6338
09:21:20,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:22:51,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:24:22,759 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1227
en_de Dev loss: 0.9508 r:0.1924
en_zh Dev loss: 0.8183 r:0.4673
ro_en Dev loss: 0.4094 r:0.8132
et_en Dev loss: 0.4596 r:0.6814
si_en Dev loss: 0.9785 r:0.5349
ne_en Dev loss: 0.5538 r:0.7107
ru_en Dev loss: 0.4696 r:0.7454
Current avg r:0.5922 Best avg r: 0.6338
09:28:54,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:25,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:31:56,433 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1211
en_de Dev loss: 0.9480 r:0.1953
en_zh Dev loss: 0.8030 r:0.4593
ro_en Dev loss: 0.3583 r:0.8143
et_en Dev loss: 0.4348 r:0.6888
si_en Dev loss: 0.8618 r:0.5306
ne_en Dev loss: 0.5549 r:0.7015
ru_en Dev loss: 0.4210 r:0.7551
Current avg r:0.5921 Best avg r: 0.6338
09:36:28,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:37:59,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:39:30,70 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1207
en_de Dev loss: 0.9938 r:0.1830
en_zh Dev loss: 0.8266 r:0.4709
ro_en Dev loss: 0.4019 r:0.8138
et_en Dev loss: 0.4605 r:0.6858
si_en Dev loss: 0.9519 r:0.5361
ne_en Dev loss: 0.5703 r:0.7018
ru_en Dev loss: 0.5069 r:0.7450
Current avg r:0.5909 Best avg r: 0.6338
09:44:02,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:45:33,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:47:04,396 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1112
en_de Dev loss: 0.9345 r:0.1761
en_zh Dev loss: 0.7982 r:0.4645
ro_en Dev loss: 0.3401 r:0.8175
et_en Dev loss: 0.4110 r:0.6888
si_en Dev loss: 0.8693 r:0.5416
ne_en Dev loss: 0.5159 r:0.7009
ru_en Dev loss: 0.4644 r:0.7420
Current avg r:0.5902 Best avg r: 0.6338
09:51:36,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:06,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:54:37,698 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1062
en_de Dev loss: 0.9602 r:0.1781
en_zh Dev loss: 0.7856 r:0.4657
ro_en Dev loss: 0.3704 r:0.8164
et_en Dev loss: 0.4271 r:0.6849
si_en Dev loss: 0.9590 r:0.5321
ne_en Dev loss: 0.6061 r:0.7055
ru_en Dev loss: 0.4760 r:0.7453
Current avg r:0.5897 Best avg r: 0.6338
09:59:09,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:00:40,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:11,81 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1084
en_de Dev loss: 0.9444 r:0.1848
en_zh Dev loss: 0.7904 r:0.4680
ro_en Dev loss: 0.3483 r:0.8165
et_en Dev loss: 0.4251 r:0.6816
si_en Dev loss: 0.8848 r:0.5376
ne_en Dev loss: 0.5828 r:0.7126
ru_en Dev loss: 0.4205 r:0.7600
Current avg r:0.5944 Best avg r: 0.6338
10:06:42,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:13,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:44,463 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1080
en_de Dev loss: 0.9752 r:0.1848
en_zh Dev loss: 0.8096 r:0.4696
ro_en Dev loss: 0.3738 r:0.8169
et_en Dev loss: 0.4417 r:0.6834
si_en Dev loss: 0.9265 r:0.5336
ne_en Dev loss: 0.5929 r:0.7080
ru_en Dev loss: 0.4514 r:0.7521
Current avg r:0.5926 Best avg r: 0.6338
10:14:16,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:15:47,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:17,994 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1024
en_de Dev loss: 0.9570 r:0.1876
en_zh Dev loss: 0.7961 r:0.4700
ro_en Dev loss: 0.3858 r:0.8141
et_en Dev loss: 0.4374 r:0.6821
si_en Dev loss: 1.0004 r:0.5256
ne_en Dev loss: 0.7103 r:0.7001
ru_en Dev loss: 0.4668 r:0.7480
Current avg r:0.5896 Best avg r: 0.6338
10:21:50,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:23:20,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:24:51,735 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1086
en_de Dev loss: 0.9729 r:0.1663
en_zh Dev loss: 0.8762 r:0.4547
ro_en Dev loss: 0.4206 r:0.8120
et_en Dev loss: 0.4603 r:0.6795
si_en Dev loss: 0.9964 r:0.5348
ne_en Dev loss: 0.6484 r:0.7009
ru_en Dev loss: 0.5160 r:0.7364
Current avg r:0.5835 Best avg r: 0.6338
10:29:23,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:30:54,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:32:25,333 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1026
en_de Dev loss: 0.9596 r:0.1678
en_zh Dev loss: 0.7942 r:0.4636
ro_en Dev loss: 0.3641 r:0.8148
et_en Dev loss: 0.4178 r:0.6855
si_en Dev loss: 0.8592 r:0.5461
ne_en Dev loss: 0.5449 r:0.7123
ru_en Dev loss: 0.4216 r:0.7539
Current avg r:0.5920 Best avg r: 0.6338
