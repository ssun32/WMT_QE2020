14:55:49,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:02,324 root INFO 
id:en_de cur r: 0.0715 best r: 0.0715
14:56:28,200 root INFO 
id:ro_en cur r: 0.5079 best r: 0.5079
14:56:41,168 root INFO 
id:et_en cur r: 0.3867 best r: 0.3867
14:56:54,133 root INFO 
id:si_en cur r: 0.3979 best r: 0.3979
14:57:19,922 root INFO 
id:ru_en cur r: 0.3501 best r: 0.3501
14:57:19,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:50,372 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:58:50,385 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:58:50,391 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:58:50,396 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:58:50,401 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:58:50,406 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:58:50,411 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:59:03,380 root INFO Epoch 0 Global steps: 700 Train loss: 0.8630
en_de Dev loss: 0.8837 r:0.0817
en_zh Dev loss: 0.7941 r:0.2304
ro_en Dev loss: 0.7288 r:0.5741
et_en Dev loss: 0.6048 r:0.4815
si_en Dev loss: 0.8028 r:0.4091
ne_en Dev loss: 0.7202 r:0.5415
ru_en Dev loss: 0.7242 r:0.4184
Current avg r:0.3910 Best avg r: 0.3910
15:03:34,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:47,203 root INFO 
id:en_de cur r: 0.1076 best r: 0.1076
15:04:00,105 root INFO 
id:en_zh cur r: 0.2431 best r: 0.2431
15:04:13,54 root INFO 
id:ro_en cur r: 0.5793 best r: 0.5793
15:04:26,9 root INFO 
id:et_en cur r: 0.5231 best r: 0.5231
15:05:04,946 root INFO 
id:ne_en cur r: 0.5880 best r: 0.5880
15:05:17,796 root INFO 
id:ru_en cur r: 0.5818 best r: 0.5818
15:05:17,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:48,278 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:06:48,285 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:06:48,296 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:06:48,302 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:06:48,307 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:06:48,312 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:06:48,318 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:07:01,279 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8226
en_de Dev loss: 0.9667 r:0.1094
en_zh Dev loss: 0.7616 r:0.2891
ro_en Dev loss: 0.7042 r:0.5835
et_en Dev loss: 0.5021 r:0.5604
si_en Dev loss: 0.7598 r:0.4395
ne_en Dev loss: 0.5319 r:0.6294
ru_en Dev loss: 0.5937 r:0.6130
Current avg r:0.4606 Best avg r: 0.4606
15:11:32,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:45,68 root INFO 
id:en_de cur r: 0.1087 best r: 0.1087
15:12:10,920 root INFO 
id:ro_en cur r: 0.5977 best r: 0.5977
15:12:23,895 root INFO 
id:et_en cur r: 0.5947 best r: 0.5947
15:12:36,866 root INFO 
id:si_en cur r: 0.4560 best r: 0.4560
15:13:02,674 root INFO 
id:ru_en cur r: 0.6798 best r: 0.6798
15:13:02,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:33,159 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:14:33,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:14:33,172 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:14:33,180 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:14:33,185 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:14:33,191 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:14:33,196 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:14:46,155 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7382
en_de Dev loss: 0.9416 r:0.1403
en_zh Dev loss: 0.7645 r:0.3227
ro_en Dev loss: 0.6261 r:0.6262
et_en Dev loss: 0.4674 r:0.6146
si_en Dev loss: 0.7303 r:0.4930
ne_en Dev loss: 0.5212 r:0.6100
ru_en Dev loss: 0.5507 r:0.7021
Current avg r:0.5013 Best avg r: 0.5013
15:19:16,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:29,847 root INFO 
id:en_de cur r: 0.1220 best r: 0.1220
15:19:42,768 root INFO 
id:en_zh cur r: 0.3079 best r: 0.3079
15:19:55,706 root INFO 
id:ro_en cur r: 0.6517 best r: 0.6517
15:20:08,694 root INFO 
id:et_en cur r: 0.6248 best r: 0.6248
15:20:21,653 root INFO 
id:si_en cur r: 0.5164 best r: 0.5164
15:20:47,570 root INFO 
id:ne_en cur r: 0.6341 best r: 0.6341
15:21:00,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:30,862 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:22:30,869 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:22:30,873 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:22:30,879 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:22:30,884 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:22:30,889 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:22:30,894 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:22:43,876 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6682
en_de Dev loss: 0.9872 r:0.1727
en_zh Dev loss: 0.8289 r:0.3372
ro_en Dev loss: 0.6127 r:0.6862
et_en Dev loss: 0.4847 r:0.6614
si_en Dev loss: 0.7577 r:0.5351
ne_en Dev loss: 0.5029 r:0.6600
ru_en Dev loss: 0.5874 r:0.7060
Current avg r:0.5370 Best avg r: 0.5370
15:27:14,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:40,628 root INFO 
id:en_zh cur r: 0.3300 best r: 0.3300
15:27:53,570 root INFO 
id:ro_en cur r: 0.6892 best r: 0.6892
15:28:06,533 root INFO 
id:et_en cur r: 0.6699 best r: 0.6699
15:28:19,509 root INFO 
id:si_en cur r: 0.5338 best r: 0.5338
15:28:45,425 root INFO 
id:ne_en cur r: 0.6755 best r: 0.6755
15:28:58,271 root INFO 
id:ru_en cur r: 0.7164 best r: 0.7164
15:28:58,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:28,717 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:30:28,724 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:30:28,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:30:28,733 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:30:28,738 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:30:28,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:30:28,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:30:41,735 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6171
en_de Dev loss: 0.9114 r:0.1714
en_zh Dev loss: 0.7710 r:0.3634
ro_en Dev loss: 0.4782 r:0.7171
et_en Dev loss: 0.3962 r:0.6868
si_en Dev loss: 0.6672 r:0.5500
ne_en Dev loss: 0.4288 r:0.6931
ru_en Dev loss: 0.4570 r:0.7360
Current avg r:0.5597 Best avg r: 0.5597
15:35:12,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:25,901 root INFO 
id:en_de cur r: 0.1978 best r: 0.1978
15:35:38,813 root INFO 
id:en_zh cur r: 0.3461 best r: 0.3461
15:35:51,759 root INFO 
id:ro_en cur r: 0.7316 best r: 0.7316
15:36:04,706 root INFO 
id:et_en cur r: 0.6860 best r: 0.6860
15:36:17,692 root INFO 
id:si_en cur r: 0.5465 best r: 0.5465
15:36:43,662 root INFO 
id:ne_en cur r: 0.6964 best r: 0.6964
15:36:56,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:27,25 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:38:27,33 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:38:27,40 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:38:27,46 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:38:27,51 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:38:27,59 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:38:27,66 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:38:40,30 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5855
en_de Dev loss: 0.9058 r:0.1936
en_zh Dev loss: 0.7937 r:0.3704
ro_en Dev loss: 0.4773 r:0.7546
et_en Dev loss: 0.3892 r:0.7014
si_en Dev loss: 0.7502 r:0.5573
ne_en Dev loss: 0.4379 r:0.7070
ru_en Dev loss: 0.4937 r:0.7264
Current avg r:0.5730 Best avg r: 0.5730
15:43:11,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:24,112 root INFO 
id:en_de cur r: 0.2089 best r: 0.2089
15:43:37,35 root INFO 
id:en_zh cur r: 0.3856 best r: 0.3856
15:43:50,1 root INFO 
id:ro_en cur r: 0.7607 best r: 0.7607
15:44:02,951 root INFO 
id:et_en cur r: 0.6965 best r: 0.6965
15:44:15,909 root INFO 
id:si_en cur r: 0.5549 best r: 0.5549
15:44:41,831 root INFO 
id:ne_en cur r: 0.7083 best r: 0.7083
15:44:54,679 root INFO 
id:ru_en cur r: 0.7254 best r: 0.7254
15:44:54,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:25,196 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:46:25,203 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:46:25,208 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:46:25,213 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:46:25,218 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:46:25,223 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:46:25,228 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:46:38,211 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5909
en_de Dev loss: 0.8849 r:0.1975
en_zh Dev loss: 0.7056 r:0.3982
ro_en Dev loss: 0.3778 r:0.7764
et_en Dev loss: 0.3510 r:0.7101
si_en Dev loss: 0.6559 r:0.5709
ne_en Dev loss: 0.4045 r:0.7152
ru_en Dev loss: 0.3976 r:0.7414
Current avg r:0.5871 Best avg r: 0.5871
15:51:09,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:22,494 root INFO 
id:en_de cur r: 0.2100 best r: 0.2100
15:51:35,430 root INFO 
id:en_zh cur r: 0.4039 best r: 0.4039
15:51:48,384 root INFO 
id:ro_en cur r: 0.7692 best r: 0.7692
15:52:01,354 root INFO 
id:et_en cur r: 0.7039 best r: 0.7039
15:52:14,323 root INFO 
id:si_en cur r: 0.5653 best r: 0.5653
15:52:40,253 root INFO 
id:ne_en cur r: 0.7226 best r: 0.7226
15:52:53,107 root INFO 
id:ru_en cur r: 0.7267 best r: 0.7267
15:52:53,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:23,589 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:54:23,595 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:54:23,600 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:54:23,607 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:54:23,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:54:23,617 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:54:23,623 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:54:36,591 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5718
en_de Dev loss: 0.8816 r:0.2011
en_zh Dev loss: 0.6961 r:0.4117
ro_en Dev loss: 0.3572 r:0.7811
et_en Dev loss: 0.3515 r:0.7091
si_en Dev loss: 0.6335 r:0.5804
ne_en Dev loss: 0.3958 r:0.7258
ru_en Dev loss: 0.4089 r:0.7364
Current avg r:0.5922 Best avg r: 0.5922
15:59:07,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:33,496 root INFO 
id:en_zh cur r: 0.4127 best r: 0.4127
15:59:46,442 root INFO 
id:ro_en cur r: 0.7860 best r: 0.7860
15:59:59,398 root INFO 
id:et_en cur r: 0.7163 best r: 0.7163
16:00:12,384 root INFO 
id:si_en cur r: 0.5816 best r: 0.5816
16:00:38,315 root INFO 
id:ne_en cur r: 0.7362 best r: 0.7362
16:00:51,164 root INFO 
id:ru_en cur r: 0.7385 best r: 0.7385
16:00:51,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:21,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:02:21,671 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:02:21,676 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:02:21,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:02:21,685 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:02:21,690 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:02:21,695 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:02:34,652 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5500
en_de Dev loss: 0.8905 r:0.1887
en_zh Dev loss: 0.7004 r:0.4174
ro_en Dev loss: 0.3412 r:0.7918
et_en Dev loss: 0.3442 r:0.7190
si_en Dev loss: 0.6207 r:0.5886
ne_en Dev loss: 0.4027 r:0.7375
ru_en Dev loss: 0.3895 r:0.7444
Current avg r:0.5982 Best avg r: 0.5982
16:07:05,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:08:36,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:06,502 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5498
en_de Dev loss: 0.9082 r:0.1742
en_zh Dev loss: 0.7733 r:0.3965
ro_en Dev loss: 0.4035 r:0.7923
et_en Dev loss: 0.3939 r:0.7000
si_en Dev loss: 0.8902 r:0.5573
ne_en Dev loss: 0.6404 r:0.7003
ru_en Dev loss: 0.5230 r:0.6984
Current avg r:0.5741 Best avg r: 0.5982
16:14:37,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:50,834 root INFO 
id:en_de cur r: 0.2152 best r: 0.2152
16:15:03,778 root INFO 
id:en_zh cur r: 0.4225 best r: 0.4225
16:15:16,746 root INFO 
id:ro_en cur r: 0.8019 best r: 0.8019
16:15:29,704 root INFO 
id:et_en cur r: 0.7179 best r: 0.7179
16:15:42,672 root INFO 
id:si_en cur r: 0.5889 best r: 0.5889
16:16:08,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:17:38,953 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5208
en_de Dev loss: 0.8767 r:0.1942
en_zh Dev loss: 0.7052 r:0.4214
ro_en Dev loss: 0.3286 r:0.8028
et_en Dev loss: 0.3509 r:0.7158
si_en Dev loss: 0.6982 r:0.5858
ne_en Dev loss: 0.4501 r:0.7329
ru_en Dev loss: 0.4409 r:0.7249
Current avg r:0.5968 Best avg r: 0.5982
16:22:10,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:36,412 root INFO 
id:en_zh cur r: 0.4269 best r: 0.4269
16:22:49,358 root INFO 
id:ro_en cur r: 0.8050 best r: 0.8050
16:23:41,201 root INFO 
id:ne_en cur r: 0.7450 best r: 0.7450
16:23:54,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:24,670 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:25:24,676 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:25:24,682 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:25:24,689 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:25:24,695 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:25:24,706 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:25:24,713 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:25:37,677 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5057
en_de Dev loss: 0.8706 r:0.1935
en_zh Dev loss: 0.6730 r:0.4290
ro_en Dev loss: 0.3045 r:0.8047
et_en Dev loss: 0.3457 r:0.7201
si_en Dev loss: 0.5632 r:0.5919
ne_en Dev loss: 0.3767 r:0.7445
ru_en Dev loss: 0.3810 r:0.7410
Current avg r:0.6035 Best avg r: 0.6035
16:30:08,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:34,730 root INFO 
id:en_zh cur r: 0.4380 best r: 0.4380
16:30:47,675 root INFO 
id:ro_en cur r: 0.8111 best r: 0.8111
16:31:39,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:10,51 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5084
en_de Dev loss: 0.8749 r:0.1911
en_zh Dev loss: 0.6815 r:0.4327
ro_en Dev loss: 0.3158 r:0.8120
et_en Dev loss: 0.3480 r:0.7175
si_en Dev loss: 0.6369 r:0.5902
ne_en Dev loss: 0.4516 r:0.7359
ru_en Dev loss: 0.4275 r:0.7344
Current avg r:0.6020 Best avg r: 0.6035
16:37:42,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:55,0 root INFO 
id:en_de cur r: 0.2180 best r: 0.2180
16:38:20,888 root INFO 
id:ro_en cur r: 0.8149 best r: 0.8149
16:38:46,790 root INFO 
id:si_en cur r: 0.5994 best r: 0.5994
16:39:12,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:43,25 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:40:43,32 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:40:43,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:40:43,42 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:40:43,48 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:40:43,52 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:40:43,57 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:40:56,26 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5131
en_de Dev loss: 0.8574 r:0.1937
en_zh Dev loss: 0.6661 r:0.4342
ro_en Dev loss: 0.2976 r:0.8167
et_en Dev loss: 0.3399 r:0.7213
si_en Dev loss: 0.5586 r:0.5994
ne_en Dev loss: 0.4272 r:0.7383
ru_en Dev loss: 0.4207 r:0.7290
Current avg r:0.6047 Best avg r: 0.6047
16:45:27,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:40,18 root INFO 
id:en_de cur r: 0.2187 best r: 0.2187
16:46:05,845 root INFO 
id:ro_en cur r: 0.8184 best r: 0.8184
16:46:31,755 root INFO 
id:si_en cur r: 0.6024 best r: 0.6024
16:46:57,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:28,51 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:48:28,57 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:48:28,63 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:48:28,67 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:48:28,72 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:48:28,77 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:48:28,82 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:48:41,65 root INFO Epoch 0 Global steps: 10500 Train loss: 0.4984
en_de Dev loss: 0.8791 r:0.2051
en_zh Dev loss: 0.7128 r:0.4356
ro_en Dev loss: 0.3054 r:0.8180
et_en Dev loss: 0.3433 r:0.7239
si_en Dev loss: 0.6120 r:0.6077
ne_en Dev loss: 0.4609 r:0.7436
ru_en Dev loss: 0.4214 r:0.7421
Current avg r:0.6109 Best avg r: 0.6109
16:53:14,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:27,109 root INFO 
id:en_de cur r: 0.2244 best r: 0.2244
16:53:40,18 root INFO 
id:en_zh cur r: 0.4511 best r: 0.4511
16:54:44,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:15,145 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5055
en_de Dev loss: 0.8631 r:0.2118
en_zh Dev loss: 0.6952 r:0.4462
ro_en Dev loss: 0.3292 r:0.8149
et_en Dev loss: 0.3575 r:0.7171
si_en Dev loss: 0.6297 r:0.5995
ne_en Dev loss: 0.4955 r:0.7410
ru_en Dev loss: 0.4269 r:0.7330
Current avg r:0.6091 Best avg r: 0.6109
17:00:46,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:16,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:47,367 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4672
en_de Dev loss: 0.8781 r:0.2066
en_zh Dev loss: 0.7245 r:0.4342
ro_en Dev loss: 0.3423 r:0.8128
et_en Dev loss: 0.3549 r:0.7184
si_en Dev loss: 0.6799 r:0.5992
ne_en Dev loss: 0.5072 r:0.7336
ru_en Dev loss: 0.5011 r:0.7103
Current avg r:0.6022 Best avg r: 0.6109
17:08:18,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:49,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:19,649 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4490
en_de Dev loss: 0.8937 r:0.2035
en_zh Dev loss: 0.7194 r:0.4317
ro_en Dev loss: 0.3357 r:0.8112
et_en Dev loss: 0.3599 r:0.7132
si_en Dev loss: 0.7265 r:0.5931
ne_en Dev loss: 0.5343 r:0.7341
ru_en Dev loss: 0.4464 r:0.7225
Current avg r:0.6013 Best avg r: 0.6109
17:15:51,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:43,16 root INFO 
id:et_en cur r: 0.7251 best r: 0.7251
17:17:21,775 root INFO 
id:ru_en cur r: 0.7509 best r: 0.7509
17:17:21,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:52,217 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:18:52,223 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:18:52,230 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:18:52,235 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:18:52,240 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:18:52,245 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:18:52,252 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:19:05,210 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4503
en_de Dev loss: 0.8514 r:0.2241
en_zh Dev loss: 0.6712 r:0.4432
ro_en Dev loss: 0.2978 r:0.8168
et_en Dev loss: 0.3368 r:0.7258
si_en Dev loss: 0.7014 r:0.5959
ne_en Dev loss: 0.4718 r:0.7371
ru_en Dev loss: 0.3843 r:0.7465
Current avg r:0.6128 Best avg r: 0.6128
17:23:36,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:06,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:37,8 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4586
en_de Dev loss: 0.8637 r:0.1992
en_zh Dev loss: 0.6943 r:0.4239
ro_en Dev loss: 0.3064 r:0.8161
et_en Dev loss: 0.3439 r:0.7173
si_en Dev loss: 0.6683 r:0.5939
ne_en Dev loss: 0.5276 r:0.7351
ru_en Dev loss: 0.4722 r:0.7039
Current avg r:0.5985 Best avg r: 0.6128
17:31:07,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:46,692 root INFO 
id:ro_en cur r: 0.8231 best r: 0.8231
17:32:38,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:08,849 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4304
en_de Dev loss: 0.8854 r:0.2005
en_zh Dev loss: 0.7277 r:0.4267
ro_en Dev loss: 0.3053 r:0.8227
et_en Dev loss: 0.3477 r:0.7178
si_en Dev loss: 0.7189 r:0.5957
ne_en Dev loss: 0.5687 r:0.7310
ru_en Dev loss: 0.4914 r:0.7077
Current avg r:0.6003 Best avg r: 0.6128
17:38:40,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:18,895 root INFO 
id:ro_en cur r: 0.8246 best r: 0.8246
17:39:44,816 root INFO 
id:si_en cur r: 0.6103 best r: 0.6103
17:40:10,730 root INFO 
id:ne_en cur r: 0.7470 best r: 0.7470
17:40:23,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:54,22 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4315
en_de Dev loss: 0.8562 r:0.2121
en_zh Dev loss: 0.6993 r:0.4343
ro_en Dev loss: 0.3029 r:0.8226
et_en Dev loss: 0.3559 r:0.7198
si_en Dev loss: 0.6732 r:0.6073
ne_en Dev loss: 0.4725 r:0.7501
ru_en Dev loss: 0.4196 r:0.7367
Current avg r:0.6119 Best avg r: 0.6128
17:46:25,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:55,564 root INFO 
id:ru_en cur r: 0.7523 best r: 0.7523
17:47:55,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:26,38 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:49:26,45 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:49:26,53 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:49:26,60 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:49:26,65 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:49:26,72 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:49:26,78 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:49:39,43 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4832
en_de Dev loss: 0.8628 r:0.2146
en_zh Dev loss: 0.7052 r:0.4379
ro_en Dev loss: 0.3200 r:0.8192
et_en Dev loss: 0.3474 r:0.7241
si_en Dev loss: 0.6258 r:0.6101
ne_en Dev loss: 0.4343 r:0.7451
ru_en Dev loss: 0.4064 r:0.7521
Current avg r:0.6147 Best avg r: 0.6147
17:54:10,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:40,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:10,982 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4200
en_de Dev loss: 0.8564 r:0.2139
en_zh Dev loss: 0.6882 r:0.4439
ro_en Dev loss: 0.3049 r:0.8206
et_en Dev loss: 0.3470 r:0.7204
si_en Dev loss: 0.6156 r:0.6024
ne_en Dev loss: 0.4376 r:0.7357
ru_en Dev loss: 0.4299 r:0.7298
Current avg r:0.6095 Best avg r: 0.6147
18:01:41,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:54,763 root INFO 
id:en_de cur r: 0.2272 best r: 0.2272
18:02:20,610 root INFO 
id:ro_en cur r: 0.8277 best r: 0.8277
18:03:12,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:42,764 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
18:04:42,770 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:04:42,776 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:04:42,781 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
18:04:42,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
18:04:42,792 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:04:42,797 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:04:55,764 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4056
en_de Dev loss: 0.8607 r:0.2137
en_zh Dev loss: 0.7010 r:0.4450
ro_en Dev loss: 0.3148 r:0.8251
et_en Dev loss: 0.3442 r:0.7245
si_en Dev loss: 0.6835 r:0.6101
ne_en Dev loss: 0.4655 r:0.7467
ru_en Dev loss: 0.4256 r:0.7434
Current avg r:0.6155 Best avg r: 0.6155
18:09:27,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:52,948 root INFO 
id:en_zh cur r: 0.4536 best r: 0.4536
18:10:57,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:28,0 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4202
en_de Dev loss: 0.8734 r:0.1937
en_zh Dev loss: 0.7059 r:0.4538
ro_en Dev loss: 0.3397 r:0.8252
et_en Dev loss: 0.3608 r:0.7167
si_en Dev loss: 0.7473 r:0.6005
ne_en Dev loss: 0.5091 r:0.7386
ru_en Dev loss: 0.4408 r:0.7338
Current avg r:0.6089 Best avg r: 0.6155
18:16:58,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:24,578 root INFO 
id:en_zh cur r: 0.4682 best r: 0.4682
18:17:37,516 root INFO 
id:ro_en cur r: 0.8313 best r: 0.8313
18:17:50,474 root INFO 
id:et_en cur r: 0.7291 best r: 0.7291
18:18:03,462 root INFO 
id:si_en cur r: 0.6140 best r: 0.6140
18:18:29,411 root INFO 
id:ne_en cur r: 0.7482 best r: 0.7482
18:18:42,269 root INFO 
id:ru_en cur r: 0.7603 best r: 0.7603
18:18:42,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:12,842 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
18:20:12,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:20:12,856 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:20:12,860 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
18:20:12,866 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
18:20:12,873 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:20:12,878 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:20:25,838 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4091
en_de Dev loss: 0.8650 r:0.2151
en_zh Dev loss: 0.6977 r:0.4553
ro_en Dev loss: 0.3028 r:0.8269
et_en Dev loss: 0.3484 r:0.7230
si_en Dev loss: 0.6229 r:0.6135
ne_en Dev loss: 0.4505 r:0.7514
ru_en Dev loss: 0.4092 r:0.7481
Current avg r:0.6190 Best avg r: 0.6190
18:24:56,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:09,596 root INFO 
id:en_de cur r: 0.2318 best r: 0.2318
18:26:27,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:57,772 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4174
en_de Dev loss: 0.8539 r:0.2231
en_zh Dev loss: 0.7346 r:0.4467
ro_en Dev loss: 0.3291 r:0.8244
et_en Dev loss: 0.3574 r:0.7137
si_en Dev loss: 0.7925 r:0.6000
ne_en Dev loss: 0.5759 r:0.7344
ru_en Dev loss: 0.4515 r:0.7296
Current avg r:0.6103 Best avg r: 0.6190
18:32:28,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:58,934 root INFO 
id:ru_en cur r: 0.7607 best r: 0.7607
18:33:58,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:29,417 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4300
en_de Dev loss: 0.8506 r:0.2055
en_zh Dev loss: 0.6908 r:0.4489
ro_en Dev loss: 0.2927 r:0.8244
et_en Dev loss: 0.3591 r:0.7218
si_en Dev loss: 0.5775 r:0.6112
ne_en Dev loss: 0.4645 r:0.7442
ru_en Dev loss: 0.3827 r:0.7525
Current avg r:0.6155 Best avg r: 0.6190
18:40:00,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:39,418 root INFO 
id:ro_en cur r: 0.8344 best r: 0.8344
18:41:05,389 root INFO 
id:si_en cur r: 0.6247 best r: 0.6247
18:41:31,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:01,661 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
18:43:01,668 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:43:01,673 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:43:01,678 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
18:43:01,683 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
18:43:01,688 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:43:01,693 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:43:14,663 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4177
en_de Dev loss: 0.8520 r:0.2071
en_zh Dev loss: 0.6778 r:0.4599
ro_en Dev loss: 0.2708 r:0.8322
et_en Dev loss: 0.3466 r:0.7274
si_en Dev loss: 0.5497 r:0.6254
ne_en Dev loss: 0.4044 r:0.7488
ru_en Dev loss: 0.3658 r:0.7597
Current avg r:0.6229 Best avg r: 0.6229
18:47:47,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:17,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:47,922 root INFO Epoch 2 Global steps: 21700 Train loss: 0.3751
en_de Dev loss: 0.8615 r:0.1907
en_zh Dev loss: 0.7050 r:0.4486
ro_en Dev loss: 0.2964 r:0.8239
et_en Dev loss: 0.3533 r:0.7212
si_en Dev loss: 0.6802 r:0.6116
ne_en Dev loss: 0.5281 r:0.7380
ru_en Dev loss: 0.3920 r:0.7524
Current avg r:0.6123 Best avg r: 0.6229
18:55:18,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:49,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:19,754 root INFO Epoch 2 Global steps: 22400 Train loss: 0.3758
en_de Dev loss: 0.8694 r:0.2133
en_zh Dev loss: 0.7007 r:0.4482
ro_en Dev loss: 0.3047 r:0.8229
et_en Dev loss: 0.3678 r:0.7061
si_en Dev loss: 0.6907 r:0.6044
ne_en Dev loss: 0.5448 r:0.7357
ru_en Dev loss: 0.4349 r:0.7355
Current avg r:0.6094 Best avg r: 0.6229
19:02:50,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:20,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:51,391 root INFO Epoch 2 Global steps: 23100 Train loss: 0.3842
en_de Dev loss: 0.8710 r:0.2054
en_zh Dev loss: 0.7266 r:0.4417
ro_en Dev loss: 0.3163 r:0.8212
et_en Dev loss: 0.3859 r:0.7007
si_en Dev loss: 0.6753 r:0.6094
ne_en Dev loss: 0.5150 r:0.7333
ru_en Dev loss: 0.4461 r:0.7300
Current avg r:0.6059 Best avg r: 0.6229
19:10:22,183 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:52,595 root INFO 
id:ru_en cur r: 0.7613 best r: 0.7613
19:11:52,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:23,20 root INFO Epoch 2 Global steps: 23800 Train loss: 0.3828
en_de Dev loss: 0.8824 r:0.1978
en_zh Dev loss: 0.7329 r:0.4470
ro_en Dev loss: 0.3043 r:0.8270
et_en Dev loss: 0.3729 r:0.7150
si_en Dev loss: 0.6641 r:0.6148
ne_en Dev loss: 0.4305 r:0.7418
ru_en Dev loss: 0.3871 r:0.7571
Current avg r:0.6144 Best avg r: 0.6229
19:17:54,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:24,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:54,877 root INFO Epoch 2 Global steps: 24500 Train loss: 0.3940
en_de Dev loss: 0.8631 r:0.2010
en_zh Dev loss: 0.7363 r:0.4415
ro_en Dev loss: 0.3212 r:0.8149
et_en Dev loss: 0.3659 r:0.7019
si_en Dev loss: 0.6805 r:0.5986
ne_en Dev loss: 0.5067 r:0.7348
ru_en Dev loss: 0.4686 r:0.7076
Current avg r:0.6000 Best avg r: 0.6229
19:25:25,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:56,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:26,496 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3884
en_de Dev loss: 0.8559 r:0.2007
en_zh Dev loss: 0.7484 r:0.4397
ro_en Dev loss: 0.3248 r:0.8167
et_en Dev loss: 0.3736 r:0.7041
si_en Dev loss: 0.7044 r:0.5971
ne_en Dev loss: 0.5463 r:0.7339
ru_en Dev loss: 0.4454 r:0.7153
Current avg r:0.6011 Best avg r: 0.6229
19:32:57,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:27,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:58,60 root INFO Epoch 2 Global steps: 25900 Train loss: 0.3827
en_de Dev loss: 0.8710 r:0.1858
en_zh Dev loss: 0.7242 r:0.4523
ro_en Dev loss: 0.3472 r:0.8176
et_en Dev loss: 0.3817 r:0.7042
si_en Dev loss: 0.8269 r:0.5912
ne_en Dev loss: 0.5710 r:0.7333
ru_en Dev loss: 0.4789 r:0.7088
Current avg r:0.5990 Best avg r: 0.6229
19:40:28,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:59,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:29,737 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3816
en_de Dev loss: 0.8515 r:0.2133
en_zh Dev loss: 0.7046 r:0.4605
ro_en Dev loss: 0.3148 r:0.8221
et_en Dev loss: 0.3670 r:0.7135
si_en Dev loss: 0.7279 r:0.5989
ne_en Dev loss: 0.4628 r:0.7418
ru_en Dev loss: 0.4399 r:0.7224
Current avg r:0.6103 Best avg r: 0.6229
19:48:00,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:31,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:01,533 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3609
en_de Dev loss: 0.8565 r:0.1973
en_zh Dev loss: 0.7088 r:0.4458
ro_en Dev loss: 0.3010 r:0.8204
et_en Dev loss: 0.3713 r:0.7045
si_en Dev loss: 0.6350 r:0.5983
ne_en Dev loss: 0.4827 r:0.7336
ru_en Dev loss: 0.4432 r:0.7066
Current avg r:0.6009 Best avg r: 0.6229
19:55:32,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:02,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:33,373 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3611
en_de Dev loss: 0.8699 r:0.1954
en_zh Dev loss: 0.7097 r:0.4470
ro_en Dev loss: 0.3243 r:0.8248
et_en Dev loss: 0.3690 r:0.7064
si_en Dev loss: 0.7035 r:0.6011
ne_en Dev loss: 0.4774 r:0.7440
ru_en Dev loss: 0.4772 r:0.7065
Current avg r:0.6036 Best avg r: 0.6229
20:03:04,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:34,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:05,86 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3543
en_de Dev loss: 0.8731 r:0.1799
en_zh Dev loss: 0.7074 r:0.4493
ro_en Dev loss: 0.3161 r:0.8206
et_en Dev loss: 0.3833 r:0.7026
si_en Dev loss: 0.6536 r:0.6047
ne_en Dev loss: 0.4796 r:0.7430
ru_en Dev loss: 0.4069 r:0.7308
Current avg r:0.6044 Best avg r: 0.6229
20:10:35,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:06,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:36,900 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3564
en_de Dev loss: 0.8546 r:0.1990
en_zh Dev loss: 0.7008 r:0.4406
ro_en Dev loss: 0.3043 r:0.8210
et_en Dev loss: 0.3709 r:0.7094
si_en Dev loss: 0.6018 r:0.6010
ne_en Dev loss: 0.4386 r:0.7385
ru_en Dev loss: 0.4406 r:0.7074
Current avg r:0.6024 Best avg r: 0.6229
20:18:07,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:38,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:08,702 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3521
en_de Dev loss: 0.8739 r:0.1979
en_zh Dev loss: 0.7186 r:0.4406
ro_en Dev loss: 0.3147 r:0.8171
et_en Dev loss: 0.3777 r:0.7018
si_en Dev loss: 0.6806 r:0.5923
ne_en Dev loss: 0.4620 r:0.7380
ru_en Dev loss: 0.4304 r:0.7162
Current avg r:0.6005 Best avg r: 0.6229
20:25:39,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:10,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:28:40,558 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3716
en_de Dev loss: 0.8751 r:0.2015
en_zh Dev loss: 0.7207 r:0.4505
ro_en Dev loss: 0.3136 r:0.8257
et_en Dev loss: 0.3695 r:0.7095
si_en Dev loss: 0.6576 r:0.6005
ne_en Dev loss: 0.4328 r:0.7435
ru_en Dev loss: 0.4176 r:0.7320
Current avg r:0.6090 Best avg r: 0.6229
20:33:11,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:33:37,171 root INFO 
id:en_zh cur r: 0.4724 best r: 0.4724
20:34:41,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:12,350 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3634
en_de Dev loss: 0.8490 r:0.2154
en_zh Dev loss: 0.6811 r:0.4659
ro_en Dev loss: 0.3019 r:0.8257
et_en Dev loss: 0.3894 r:0.7151
si_en Dev loss: 0.5795 r:0.6121
ne_en Dev loss: 0.4285 r:0.7387
ru_en Dev loss: 0.4100 r:0.7309
Current avg r:0.6148 Best avg r: 0.6229
20:40:44,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:15,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:45,749 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3169
en_de Dev loss: 0.8568 r:0.2188
en_zh Dev loss: 0.7253 r:0.4500
ro_en Dev loss: 0.3392 r:0.8193
et_en Dev loss: 0.4018 r:0.7064
si_en Dev loss: 0.7354 r:0.5976
ne_en Dev loss: 0.5038 r:0.7333
ru_en Dev loss: 0.4333 r:0.7329
Current avg r:0.6083 Best avg r: 0.6229
20:48:16,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:47,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:17,680 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3287
en_de Dev loss: 0.8683 r:0.1941
en_zh Dev loss: 0.7114 r:0.4405
ro_en Dev loss: 0.3161 r:0.8126
et_en Dev loss: 0.3776 r:0.7004
si_en Dev loss: 0.6644 r:0.5835
ne_en Dev loss: 0.4593 r:0.7232
ru_en Dev loss: 0.4511 r:0.7064
Current avg r:0.5944 Best avg r: 0.6229
20:55:48,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:19,188 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:49,654 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3248
en_de Dev loss: 0.9085 r:0.1399
en_zh Dev loss: 0.7240 r:0.4504
ro_en Dev loss: 0.3044 r:0.8254
et_en Dev loss: 0.3860 r:0.6999
si_en Dev loss: 0.7050 r:0.5969
ne_en Dev loss: 0.4632 r:0.7320
ru_en Dev loss: 0.4432 r:0.7239
Current avg r:0.5955 Best avg r: 0.6229
21:03:20,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:04:50,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:21,454 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3150
en_de Dev loss: 0.8797 r:0.1847
en_zh Dev loss: 0.7437 r:0.4446
ro_en Dev loss: 0.3329 r:0.8197
et_en Dev loss: 0.4265 r:0.7044
si_en Dev loss: 0.6610 r:0.5977
ne_en Dev loss: 0.4494 r:0.7376
ru_en Dev loss: 0.4584 r:0.7183
Current avg r:0.6010 Best avg r: 0.6229
21:10:52,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:22,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:53,376 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3034
en_de Dev loss: 0.8572 r:0.2062
en_zh Dev loss: 0.7260 r:0.4411
ro_en Dev loss: 0.3050 r:0.8206
et_en Dev loss: 0.3796 r:0.7047
si_en Dev loss: 0.6745 r:0.5898
ne_en Dev loss: 0.4327 r:0.7308
ru_en Dev loss: 0.4324 r:0.7227
Current avg r:0.6023 Best avg r: 0.6229
21:18:24,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:54,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:25,282 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3167
en_de Dev loss: 0.8679 r:0.1946
en_zh Dev loss: 0.7348 r:0.4465
ro_en Dev loss: 0.3326 r:0.8174
et_en Dev loss: 0.3971 r:0.6946
si_en Dev loss: 0.8281 r:0.5793
ne_en Dev loss: 0.6179 r:0.7159
ru_en Dev loss: 0.4912 r:0.7027
Current avg r:0.5930 Best avg r: 0.6229
21:25:56,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:26,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:28:57,113 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3166
en_de Dev loss: 0.8599 r:0.2071
en_zh Dev loss: 0.7292 r:0.4490
ro_en Dev loss: 0.3330 r:0.8232
et_en Dev loss: 0.3793 r:0.7114
si_en Dev loss: 0.7128 r:0.5960
ne_en Dev loss: 0.4908 r:0.7343
ru_en Dev loss: 0.4568 r:0.7269
Current avg r:0.6068 Best avg r: 0.6229
21:33:27,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:58,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:28,902 root INFO Epoch 3 Global steps: 37100 Train loss: 0.2980
en_de Dev loss: 0.8637 r:0.2011
en_zh Dev loss: 0.7431 r:0.4413
ro_en Dev loss: 0.3185 r:0.8260
et_en Dev loss: 0.3790 r:0.7059
si_en Dev loss: 0.7183 r:0.5934
ne_en Dev loss: 0.4810 r:0.7265
ru_en Dev loss: 0.4424 r:0.7277
Current avg r:0.6031 Best avg r: 0.6229
21:40:59,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:30,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:00,985 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3140
en_de Dev loss: 0.8737 r:0.1943
en_zh Dev loss: 0.7699 r:0.4390
ro_en Dev loss: 0.3486 r:0.8178
et_en Dev loss: 0.3933 r:0.6983
si_en Dev loss: 0.7951 r:0.5856
ne_en Dev loss: 0.5144 r:0.7340
ru_en Dev loss: 0.4834 r:0.7078
Current avg r:0.5967 Best avg r: 0.6229
21:48:32,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:02,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:33,468 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3152
en_de Dev loss: 0.8682 r:0.2072
en_zh Dev loss: 0.7518 r:0.4475
ro_en Dev loss: 0.3304 r:0.8188
et_en Dev loss: 0.4073 r:0.6927
si_en Dev loss: 0.7732 r:0.5898
ne_en Dev loss: 0.4903 r:0.7296
ru_en Dev loss: 0.4494 r:0.7166
Current avg r:0.6003 Best avg r: 0.6229
21:56:04,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:35,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:05,474 root INFO Epoch 3 Global steps: 39200 Train loss: 0.2945
en_de Dev loss: 0.8641 r:0.1846
en_zh Dev loss: 0.7538 r:0.4261
ro_en Dev loss: 0.3248 r:0.8136
et_en Dev loss: 0.3972 r:0.6902
si_en Dev loss: 0.8113 r:0.5787
ne_en Dev loss: 0.5006 r:0.7287
ru_en Dev loss: 0.5106 r:0.6751
Current avg r:0.5853 Best avg r: 0.6229
22:03:37,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:07,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:37,980 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3119
en_de Dev loss: 0.8650 r:0.1960
en_zh Dev loss: 0.7640 r:0.4331
ro_en Dev loss: 0.3303 r:0.8186
et_en Dev loss: 0.4060 r:0.6912
si_en Dev loss: 0.7470 r:0.5815
ne_en Dev loss: 0.4839 r:0.7335
ru_en Dev loss: 0.4529 r:0.7147
Current avg r:0.5955 Best avg r: 0.6229
22:11:08,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:39,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:09,905 root INFO Epoch 3 Global steps: 40600 Train loss: 0.2918
en_de Dev loss: 0.8923 r:0.2065
en_zh Dev loss: 0.8232 r:0.4362
ro_en Dev loss: 0.4121 r:0.8147
et_en Dev loss: 0.4171 r:0.6928
si_en Dev loss: 0.8934 r:0.5839
ne_en Dev loss: 0.5753 r:0.7304
ru_en Dev loss: 0.5052 r:0.7182
Current avg r:0.5975 Best avg r: 0.6229
22:18:40,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:11,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:21:41,642 root INFO Epoch 3 Global steps: 41300 Train loss: 0.2981
en_de Dev loss: 0.8767 r:0.1879
en_zh Dev loss: 0.7613 r:0.4457
ro_en Dev loss: 0.3392 r:0.8189
et_en Dev loss: 0.4288 r:0.6978
si_en Dev loss: 0.7407 r:0.5839
ne_en Dev loss: 0.4904 r:0.7263
ru_en Dev loss: 0.4538 r:0.7251
Current avg r:0.5979 Best avg r: 0.6229
22:26:12,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:27:43,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:13,630 root INFO Epoch 3 Global steps: 42000 Train loss: 0.2901
en_de Dev loss: 0.8587 r:0.2020
en_zh Dev loss: 0.7214 r:0.4517
ro_en Dev loss: 0.3132 r:0.8209
et_en Dev loss: 0.4034 r:0.6995
si_en Dev loss: 0.6964 r:0.5819
ne_en Dev loss: 0.4566 r:0.7305
ru_en Dev loss: 0.4288 r:0.7242
Current avg r:0.6015 Best avg r: 0.6229
22:33:46,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:16,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:47,288 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2914
en_de Dev loss: 0.8616 r:0.1977
en_zh Dev loss: 0.7432 r:0.4443
ro_en Dev loss: 0.3203 r:0.8199
et_en Dev loss: 0.4019 r:0.6970
si_en Dev loss: 0.7063 r:0.5858
ne_en Dev loss: 0.4482 r:0.7329
ru_en Dev loss: 0.4266 r:0.7288
Current avg r:0.6009 Best avg r: 0.6229
22:41:18,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:49,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:19,569 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2695
en_de Dev loss: 0.8623 r:0.1976
en_zh Dev loss: 0.7539 r:0.4356
ro_en Dev loss: 0.3141 r:0.8202
et_en Dev loss: 0.4062 r:0.7002
si_en Dev loss: 0.7132 r:0.5772
ne_en Dev loss: 0.4486 r:0.7257
ru_en Dev loss: 0.4190 r:0.7268
Current avg r:0.5976 Best avg r: 0.6229
22:48:50,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:21,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:51,798 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2351
en_de Dev loss: 0.8747 r:0.1974
en_zh Dev loss: 0.7428 r:0.4467
ro_en Dev loss: 0.3213 r:0.8226
et_en Dev loss: 0.4056 r:0.7011
si_en Dev loss: 0.7350 r:0.5841
ne_en Dev loss: 0.4579 r:0.7282
ru_en Dev loss: 0.4263 r:0.7328
Current avg r:0.6018 Best avg r: 0.6229
22:56:22,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:53,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:23,941 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2521
en_de Dev loss: 0.8637 r:0.2085
en_zh Dev loss: 0.7564 r:0.4411
ro_en Dev loss: 0.3430 r:0.8176
et_en Dev loss: 0.4713 r:0.6996
si_en Dev loss: 0.6799 r:0.5855
ne_en Dev loss: 0.4691 r:0.7287
ru_en Dev loss: 0.4297 r:0.7281
Current avg r:0.6013 Best avg r: 0.6229
23:03:54,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:25,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:55,767 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2563
en_de Dev loss: 0.8707 r:0.2102
en_zh Dev loss: 0.7523 r:0.4474
ro_en Dev loss: 0.3219 r:0.8203
et_en Dev loss: 0.4039 r:0.7018
si_en Dev loss: 0.7414 r:0.5818
ne_en Dev loss: 0.4448 r:0.7255
ru_en Dev loss: 0.4421 r:0.7240
Current avg r:0.6015 Best avg r: 0.6229
23:11:26,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:12:57,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:27,556 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2609
en_de Dev loss: 0.8925 r:0.1933
en_zh Dev loss: 0.8142 r:0.4249
ro_en Dev loss: 0.3612 r:0.8146
et_en Dev loss: 0.4400 r:0.6870
si_en Dev loss: 0.7674 r:0.5775
ne_en Dev loss: 0.4788 r:0.7267
ru_en Dev loss: 0.4655 r:0.7139
Current avg r:0.5911 Best avg r: 0.6229
23:18:58,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:28,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:21:59,400 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2499
en_de Dev loss: 0.8776 r:0.1904
en_zh Dev loss: 0.7929 r:0.4203
ro_en Dev loss: 0.3461 r:0.8124
et_en Dev loss: 0.4238 r:0.6861
si_en Dev loss: 0.7986 r:0.5710
ne_en Dev loss: 0.4786 r:0.7233
ru_en Dev loss: 0.4740 r:0.7040
Current avg r:0.5868 Best avg r: 0.6229
23:26:30,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:00,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:30,982 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2649
en_de Dev loss: 0.8599 r:0.2105
en_zh Dev loss: 0.7564 r:0.4573
ro_en Dev loss: 0.3282 r:0.8158
et_en Dev loss: 0.4369 r:0.6998
si_en Dev loss: 0.6770 r:0.5884
ne_en Dev loss: 0.4191 r:0.7341
ru_en Dev loss: 0.4211 r:0.7291
Current avg r:0.6050 Best avg r: 0.6229
23:34:01,791 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:32,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:02,739 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2478
en_de Dev loss: 0.8610 r:0.2180
en_zh Dev loss: 0.7363 r:0.4576
ro_en Dev loss: 0.3410 r:0.8197
et_en Dev loss: 0.4600 r:0.6978
si_en Dev loss: 0.6748 r:0.5918
ne_en Dev loss: 0.4395 r:0.7319
ru_en Dev loss: 0.4191 r:0.7327
Current avg r:0.6071 Best avg r: 0.6229
23:41:33,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:03,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:34,380 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2445
en_de Dev loss: 0.8633 r:0.2104
en_zh Dev loss: 0.7839 r:0.4304
ro_en Dev loss: 0.3532 r:0.8122
et_en Dev loss: 0.4310 r:0.6826
si_en Dev loss: 0.8770 r:0.5601
ne_en Dev loss: 0.4943 r:0.7206
ru_en Dev loss: 0.4934 r:0.6957
Current avg r:0.5874 Best avg r: 0.6229
23:49:05,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:31,73 root INFO 
id:en_zh cur r: 0.4780 best r: 0.4780
23:50:35,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:06,163 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2508
en_de Dev loss: 0.8715 r:0.2048
en_zh Dev loss: 0.7501 r:0.4632
ro_en Dev loss: 0.3484 r:0.8177
et_en Dev loss: 0.4344 r:0.6894
si_en Dev loss: 0.8053 r:0.5791
ne_en Dev loss: 0.4898 r:0.7253
ru_en Dev loss: 0.4438 r:0.7296
Current avg r:0.6013 Best avg r: 0.6229
23:56:37,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:50,763 root INFO 
id:en_de cur r: 0.2369 best r: 0.2369
23:58:08,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:38,883 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2585
en_de Dev loss: 0.8802 r:0.2339
en_zh Dev loss: 0.8268 r:0.4359
ro_en Dev loss: 0.3953 r:0.8107
et_en Dev loss: 0.4831 r:0.6781
si_en Dev loss: 0.8250 r:0.5677
ne_en Dev loss: 0.4934 r:0.7269
ru_en Dev loss: 0.4908 r:0.7152
Current avg r:0.5955 Best avg r: 0.6229
00:04:10,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:40,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:11,50 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2553
en_de Dev loss: 0.8831 r:0.1949
en_zh Dev loss: 0.7724 r:0.4442
ro_en Dev loss: 0.3420 r:0.8164
et_en Dev loss: 0.4295 r:0.6881
si_en Dev loss: 0.7443 r:0.5783
ne_en Dev loss: 0.4557 r:0.7262
ru_en Dev loss: 0.4451 r:0.7268
Current avg r:0.5964 Best avg r: 0.6229
00:11:41,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:12,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:42,655 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2555
en_de Dev loss: 0.8676 r:0.1997
en_zh Dev loss: 0.7629 r:0.4382
ro_en Dev loss: 0.3422 r:0.8164
et_en Dev loss: 0.4415 r:0.6879
si_en Dev loss: 0.7426 r:0.5705
ne_en Dev loss: 0.4267 r:0.7333
ru_en Dev loss: 0.4223 r:0.7339
Current avg r:0.5971 Best avg r: 0.6229
00:19:13,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:43,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:14,458 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2410
en_de Dev loss: 0.8816 r:0.1826
en_zh Dev loss: 0.8152 r:0.4212
ro_en Dev loss: 0.3603 r:0.8126
et_en Dev loss: 0.4723 r:0.6854
si_en Dev loss: 0.7568 r:0.5722
ne_en Dev loss: 0.4395 r:0.7320
ru_en Dev loss: 0.4433 r:0.7233
Current avg r:0.5899 Best avg r: 0.6229
00:26:46,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:17,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:47,957 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2302
en_de Dev loss: 0.8878 r:0.1698
en_zh Dev loss: 0.7953 r:0.4409
ro_en Dev loss: 0.3511 r:0.8177
et_en Dev loss: 0.4384 r:0.6775
si_en Dev loss: 0.7838 r:0.5733
ne_en Dev loss: 0.4606 r:0.7333
ru_en Dev loss: 0.4299 r:0.7324
Current avg r:0.5921 Best avg r: 0.6229
00:34:19,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:49,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:20,126 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2323
en_de Dev loss: 0.8999 r:0.1802
en_zh Dev loss: 0.7984 r:0.4321
ro_en Dev loss: 0.3599 r:0.8155
et_en Dev loss: 0.4414 r:0.6708
si_en Dev loss: 0.8106 r:0.5605
ne_en Dev loss: 0.4412 r:0.7308
ru_en Dev loss: 0.4944 r:0.7061
Current avg r:0.5852 Best avg r: 0.6229
00:41:51,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:21,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:51,903 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2259
en_de Dev loss: 0.8877 r:0.1896
en_zh Dev loss: 0.7714 r:0.4527
ro_en Dev loss: 0.3496 r:0.8149
et_en Dev loss: 0.4675 r:0.6822
si_en Dev loss: 0.7475 r:0.5706
ne_en Dev loss: 0.4236 r:0.7386
ru_en Dev loss: 0.4117 r:0.7446
Current avg r:0.5990 Best avg r: 0.6229
00:49:22,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:53,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:23,772 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2255
en_de Dev loss: 0.8956 r:0.1972
en_zh Dev loss: 0.7858 r:0.4493
ro_en Dev loss: 0.3820 r:0.8062
et_en Dev loss: 0.4706 r:0.6688
si_en Dev loss: 0.7847 r:0.5588
ne_en Dev loss: 0.4554 r:0.7372
ru_en Dev loss: 0.4890 r:0.7036
Current avg r:0.5887 Best avg r: 0.6229
00:56:55,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:26,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:56,936 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2217
en_de Dev loss: 0.9200 r:0.1580
en_zh Dev loss: 0.7799 r:0.4472
ro_en Dev loss: 0.3780 r:0.8101
et_en Dev loss: 0.4500 r:0.6841
si_en Dev loss: 0.7904 r:0.5651
ne_en Dev loss: 0.4415 r:0.7354
ru_en Dev loss: 0.4455 r:0.7351
Current avg r:0.5907 Best avg r: 0.6229
01:04:28,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:58,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:28,994 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2198
en_de Dev loss: 0.8823 r:0.1948
en_zh Dev loss: 0.7737 r:0.4470
ro_en Dev loss: 0.3838 r:0.8077
et_en Dev loss: 0.4436 r:0.6682
si_en Dev loss: 0.7960 r:0.5557
ne_en Dev loss: 0.4622 r:0.7277
ru_en Dev loss: 0.4528 r:0.7189
Current avg r:0.5886 Best avg r: 0.6229
01:12:00,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:31,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:01,523 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2120
en_de Dev loss: 0.9052 r:0.1922
en_zh Dev loss: 0.7899 r:0.4541
ro_en Dev loss: 0.3775 r:0.8139
et_en Dev loss: 0.4545 r:0.6730
si_en Dev loss: 0.8747 r:0.5566
ne_en Dev loss: 0.4693 r:0.7273
ru_en Dev loss: 0.4631 r:0.7258
Current avg r:0.5918 Best avg r: 0.6229
01:19:33,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:03,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:22:34,368 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2213
en_de Dev loss: 0.9049 r:0.1798
en_zh Dev loss: 0.7776 r:0.4545
ro_en Dev loss: 0.3460 r:0.8141
et_en Dev loss: 0.4450 r:0.6781
si_en Dev loss: 0.7528 r:0.5706
ne_en Dev loss: 0.4241 r:0.7349
ru_en Dev loss: 0.4694 r:0.7301
Current avg r:0.5946 Best avg r: 0.6229
01:27:05,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:35,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:06,260 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2129
en_de Dev loss: 0.8929 r:0.1950
en_zh Dev loss: 0.8146 r:0.4592
ro_en Dev loss: 0.4084 r:0.8101
et_en Dev loss: 0.4928 r:0.6606
si_en Dev loss: 0.9719 r:0.5499
ne_en Dev loss: 0.5200 r:0.7274
ru_en Dev loss: 0.5432 r:0.7035
Current avg r:0.5865 Best avg r: 0.6229
01:34:37,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:36:07,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:38,75 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2162
en_de Dev loss: 0.8940 r:0.2031
en_zh Dev loss: 0.8113 r:0.4529
ro_en Dev loss: 0.3754 r:0.8138
et_en Dev loss: 0.4576 r:0.6639
si_en Dev loss: 0.8580 r:0.5559
ne_en Dev loss: 0.4666 r:0.7266
ru_en Dev loss: 0.5035 r:0.7061
Current avg r:0.5889 Best avg r: 0.6229
01:42:09,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:39,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:10,155 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2063
en_de Dev loss: 0.8643 r:0.2081
en_zh Dev loss: 0.7741 r:0.4513
ro_en Dev loss: 0.3305 r:0.8168
et_en Dev loss: 0.4341 r:0.6704
si_en Dev loss: 0.8032 r:0.5681
ne_en Dev loss: 0.4542 r:0.7342
ru_en Dev loss: 0.4654 r:0.7161
Current avg r:0.5950 Best avg r: 0.6229
01:49:41,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:11,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:42,228 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2075
en_de Dev loss: 0.8685 r:0.2045
en_zh Dev loss: 0.7918 r:0.4505
ro_en Dev loss: 0.3672 r:0.8169
et_en Dev loss: 0.4945 r:0.6640
si_en Dev loss: 0.8902 r:0.5576
ne_en Dev loss: 0.4719 r:0.7265
ru_en Dev loss: 0.4669 r:0.7161
Current avg r:0.5909 Best avg r: 0.6229
01:57:13,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:58:43,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:14,134 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2095
en_de Dev loss: 0.8685 r:0.2240
en_zh Dev loss: 0.7781 r:0.4607
ro_en Dev loss: 0.3341 r:0.8220
et_en Dev loss: 0.4894 r:0.6783
si_en Dev loss: 0.7804 r:0.5708
ne_en Dev loss: 0.4302 r:0.7316
ru_en Dev loss: 0.4434 r:0.7304
Current avg r:0.6025 Best avg r: 0.6229
02:04:44,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:15,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:45,953 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2096
en_de Dev loss: 0.8744 r:0.2013
en_zh Dev loss: 0.7316 r:0.4658
ro_en Dev loss: 0.3122 r:0.8216
et_en Dev loss: 0.4430 r:0.6827
si_en Dev loss: 0.7497 r:0.5688
ne_en Dev loss: 0.4159 r:0.7258
ru_en Dev loss: 0.3985 r:0.7492
Current avg r:0.6022 Best avg r: 0.6229
02:12:16,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:47,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:15:17,639 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2217
en_de Dev loss: 0.8906 r:0.2079
en_zh Dev loss: 0.8125 r:0.4452
ro_en Dev loss: 0.3354 r:0.8233
et_en Dev loss: 0.4459 r:0.6754
si_en Dev loss: 0.8021 r:0.5630
ne_en Dev loss: 0.4529 r:0.7212
ru_en Dev loss: 0.4610 r:0.7284
Current avg r:0.5949 Best avg r: 0.6229
02:19:51,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:21,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:52,74 root INFO Epoch 6 Global steps: 63700 Train loss: 0.1794
en_de Dev loss: 0.8889 r:0.2014
en_zh Dev loss: 0.7844 r:0.4497
ro_en Dev loss: 0.3353 r:0.8176
et_en Dev loss: 0.4798 r:0.6794
si_en Dev loss: 0.7593 r:0.5700
ne_en Dev loss: 0.4173 r:0.7349
ru_en Dev loss: 0.4204 r:0.7448
Current avg r:0.5997 Best avg r: 0.6229
02:27:22,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:28:53,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:30:23,908 root INFO Epoch 6 Global steps: 64400 Train loss: 0.1923
en_de Dev loss: 0.9007 r:0.1943
en_zh Dev loss: 0.8099 r:0.4401
ro_en Dev loss: 0.3658 r:0.8181
et_en Dev loss: 0.4984 r:0.6685
si_en Dev loss: 0.7835 r:0.5670
ne_en Dev loss: 0.4360 r:0.7262
ru_en Dev loss: 0.4766 r:0.7201
Current avg r:0.5906 Best avg r: 0.6229
02:34:54,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:25,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:37:55,778 root INFO Epoch 6 Global steps: 65100 Train loss: 0.1743
en_de Dev loss: 0.8736 r:0.2054
en_zh Dev loss: 0.7837 r:0.4552
ro_en Dev loss: 0.3487 r:0.8150
et_en Dev loss: 0.4833 r:0.6621
si_en Dev loss: 0.8195 r:0.5601
ne_en Dev loss: 0.4362 r:0.7230
ru_en Dev loss: 0.4700 r:0.7106
Current avg r:0.5902 Best avg r: 0.6229
02:42:26,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:57,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:27,684 root INFO Epoch 6 Global steps: 65800 Train loss: 0.1829
en_de Dev loss: 0.8994 r:0.1863
en_zh Dev loss: 0.8115 r:0.4326
ro_en Dev loss: 0.3722 r:0.8119
et_en Dev loss: 0.4590 r:0.6652
si_en Dev loss: 0.8953 r:0.5447
ne_en Dev loss: 0.4569 r:0.7273
ru_en Dev loss: 0.5036 r:0.7005
Current avg r:0.5812 Best avg r: 0.6229
02:49:58,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:29,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:59,613 root INFO Epoch 6 Global steps: 66500 Train loss: 0.1801
en_de Dev loss: 0.8847 r:0.2038
en_zh Dev loss: 0.8030 r:0.4519
ro_en Dev loss: 0.3618 r:0.8165
et_en Dev loss: 0.4823 r:0.6724
si_en Dev loss: 0.8488 r:0.5553
ne_en Dev loss: 0.4467 r:0.7291
ru_en Dev loss: 0.4270 r:0.7369
Current avg r:0.5951 Best avg r: 0.6229
02:57:30,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:59:00,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:31,442 root INFO Epoch 6 Global steps: 67200 Train loss: 0.1855
en_de Dev loss: 0.8725 r:0.1860
en_zh Dev loss: 0.7664 r:0.4371
ro_en Dev loss: 0.3194 r:0.8182
et_en Dev loss: 0.4489 r:0.6798
si_en Dev loss: 0.8144 r:0.5533
ne_en Dev loss: 0.4430 r:0.7293
ru_en Dev loss: 0.4229 r:0.7322
Current avg r:0.5909 Best avg r: 0.6229
03:05:02,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:06:32,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:03,358 root INFO Epoch 6 Global steps: 67900 Train loss: 0.1888
en_de Dev loss: 0.8859 r:0.1898
en_zh Dev loss: 0.7964 r:0.4447
ro_en Dev loss: 0.3504 r:0.8199
et_en Dev loss: 0.4760 r:0.6719
si_en Dev loss: 0.8149 r:0.5575
ne_en Dev loss: 0.4305 r:0.7255
ru_en Dev loss: 0.4549 r:0.7265
Current avg r:0.5908 Best avg r: 0.6229
03:12:35,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:05,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:15:36,246 root INFO Epoch 6 Global steps: 68600 Train loss: 0.1892
en_de Dev loss: 0.8805 r:0.2057
en_zh Dev loss: 0.7807 r:0.4627
ro_en Dev loss: 0.3555 r:0.8224
et_en Dev loss: 0.4773 r:0.6801
si_en Dev loss: 0.7937 r:0.5610
ne_en Dev loss: 0.4096 r:0.7328
ru_en Dev loss: 0.4475 r:0.7367
Current avg r:0.6002 Best avg r: 0.6229
03:20:07,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:38,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:08,790 root INFO Epoch 6 Global steps: 69300 Train loss: 0.1763
en_de Dev loss: 0.8789 r:0.2145
en_zh Dev loss: 0.7757 r:0.4558
ro_en Dev loss: 0.3492 r:0.8184
et_en Dev loss: 0.4758 r:0.6702
si_en Dev loss: 0.8278 r:0.5548
ne_en Dev loss: 0.4261 r:0.7316
ru_en Dev loss: 0.4483 r:0.7284
Current avg r:0.5962 Best avg r: 0.6229
03:27:40,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:10,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:41,169 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1863
en_de Dev loss: 0.9003 r:0.2011
en_zh Dev loss: 0.8094 r:0.4526
ro_en Dev loss: 0.3553 r:0.8175
et_en Dev loss: 0.4681 r:0.6752
si_en Dev loss: 0.8575 r:0.5489
ne_en Dev loss: 0.4226 r:0.7311
ru_en Dev loss: 0.4647 r:0.7316
Current avg r:0.5940 Best avg r: 0.6229
03:35:12,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:43,370 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:13,818 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1793
en_de Dev loss: 0.8755 r:0.2081
en_zh Dev loss: 0.7651 r:0.4593
ro_en Dev loss: 0.3292 r:0.8242
et_en Dev loss: 0.5179 r:0.6821
si_en Dev loss: 0.6997 r:0.5681
ne_en Dev loss: 0.3862 r:0.7372
ru_en Dev loss: 0.3809 r:0.7542
Current avg r:0.6047 Best avg r: 0.6229
03:42:44,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:15,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:45,859 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1749
en_de Dev loss: 0.8752 r:0.2001
en_zh Dev loss: 0.7737 r:0.4565
ro_en Dev loss: 0.3254 r:0.8159
et_en Dev loss: 0.4361 r:0.6703
si_en Dev loss: 0.8203 r:0.5550
ne_en Dev loss: 0.4492 r:0.7262
ru_en Dev loss: 0.4319 r:0.7346
Current avg r:0.5941 Best avg r: 0.6229
03:50:16,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:47,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:53:17,845 root INFO Epoch 6 Global steps: 72100 Train loss: 0.1796
en_de Dev loss: 0.9108 r:0.2013
en_zh Dev loss: 0.7914 r:0.4675
ro_en Dev loss: 0.3470 r:0.8175
et_en Dev loss: 0.4747 r:0.6715
si_en Dev loss: 0.8792 r:0.5475
ne_en Dev loss: 0.4262 r:0.7224
ru_en Dev loss: 0.4341 r:0.7434
Current avg r:0.5959 Best avg r: 0.6229
03:57:48,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:59:19,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:49,742 root INFO Epoch 6 Global steps: 72800 Train loss: 0.1776
en_de Dev loss: 0.8799 r:0.2139
en_zh Dev loss: 0.7806 r:0.4468
ro_en Dev loss: 0.3268 r:0.8160
et_en Dev loss: 0.4542 r:0.6835
si_en Dev loss: 0.8105 r:0.5553
ne_en Dev loss: 0.4138 r:0.7265
ru_en Dev loss: 0.4374 r:0.7340
Current avg r:0.5966 Best avg r: 0.6229
04:05:20,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:06:51,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:21,529 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1797
en_de Dev loss: 0.9107 r:0.1961
en_zh Dev loss: 0.8413 r:0.4473
ro_en Dev loss: 0.3555 r:0.8176
et_en Dev loss: 0.4712 r:0.6776
si_en Dev loss: 0.9523 r:0.5480
ne_en Dev loss: 0.4886 r:0.7218
ru_en Dev loss: 0.5433 r:0.7102
Current avg r:0.5884 Best avg r: 0.6229
04:12:53,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:24,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:54,922 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1535
en_de Dev loss: 0.9122 r:0.1949
en_zh Dev loss: 0.8116 r:0.4514
ro_en Dev loss: 0.3528 r:0.8188
et_en Dev loss: 0.4560 r:0.6758
si_en Dev loss: 0.8836 r:0.5443
ne_en Dev loss: 0.4295 r:0.7284
ru_en Dev loss: 0.4580 r:0.7344
Current avg r:0.5926 Best avg r: 0.6229
04:20:25,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:56,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:26,510 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1618
en_de Dev loss: 0.8806 r:0.2198
en_zh Dev loss: 0.7931 r:0.4519
ro_en Dev loss: 0.3458 r:0.8156
et_en Dev loss: 0.4572 r:0.6792
si_en Dev loss: 0.8788 r:0.5452
ne_en Dev loss: 0.4330 r:0.7248
ru_en Dev loss: 0.4290 r:0.7412
Current avg r:0.5968 Best avg r: 0.6229
04:27:57,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:27,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:58,415 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1662
en_de Dev loss: 0.8665 r:0.2049
en_zh Dev loss: 0.7606 r:0.4419
ro_en Dev loss: 0.3195 r:0.8169
et_en Dev loss: 0.4415 r:0.6753
si_en Dev loss: 0.8484 r:0.5425
ne_en Dev loss: 0.4159 r:0.7262
ru_en Dev loss: 0.4119 r:0.7365
Current avg r:0.5920 Best avg r: 0.6229
04:35:30,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:37:00,599 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:31,66 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1625
en_de Dev loss: 0.8963 r:0.2175
en_zh Dev loss: 0.8367 r:0.4522
ro_en Dev loss: 0.3853 r:0.8171
et_en Dev loss: 0.5007 r:0.6622
si_en Dev loss: 0.9018 r:0.5428
ne_en Dev loss: 0.4351 r:0.7268
ru_en Dev loss: 0.4277 r:0.7518
Current avg r:0.5958 Best avg r: 0.6229
04:43:02,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:32,553 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:46:03,57 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1498
en_de Dev loss: 0.8805 r:0.2063
en_zh Dev loss: 0.8092 r:0.4403
ro_en Dev loss: 0.3434 r:0.8168
et_en Dev loss: 0.4602 r:0.6713
si_en Dev loss: 0.8679 r:0.5352
ne_en Dev loss: 0.4185 r:0.7239
ru_en Dev loss: 0.4413 r:0.7318
Current avg r:0.5894 Best avg r: 0.6229
04:50:34,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:52:04,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:35,187 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1606
en_de Dev loss: 0.8743 r:0.2225
en_zh Dev loss: 0.7917 r:0.4479
ro_en Dev loss: 0.3548 r:0.8161
et_en Dev loss: 0.4572 r:0.6702
si_en Dev loss: 0.9033 r:0.5422
ne_en Dev loss: 0.4490 r:0.7261
ru_en Dev loss: 0.4440 r:0.7287
Current avg r:0.5934 Best avg r: 0.6229
04:58:06,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:59:36,555 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:01:07,50 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1496
en_de Dev loss: 0.9006 r:0.1927
en_zh Dev loss: 0.8234 r:0.4429
ro_en Dev loss: 0.3501 r:0.8166
et_en Dev loss: 0.4552 r:0.6654
si_en Dev loss: 0.9176 r:0.5438
ne_en Dev loss: 0.4523 r:0.7251
ru_en Dev loss: 0.4824 r:0.7180
Current avg r:0.5863 Best avg r: 0.6229
05:05:37,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:07:08,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:38,815 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1560
en_de Dev loss: 0.9033 r:0.1971
en_zh Dev loss: 0.8071 r:0.4427
ro_en Dev loss: 0.3503 r:0.8190
et_en Dev loss: 0.4912 r:0.6702
si_en Dev loss: 0.8698 r:0.5473
ne_en Dev loss: 0.4116 r:0.7336
ru_en Dev loss: 0.4587 r:0.7221
Current avg r:0.5903 Best avg r: 0.6229
05:13:09,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:40,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:16:10,593 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1566
en_de Dev loss: 0.9003 r:0.1914
en_zh Dev loss: 0.7964 r:0.4463
ro_en Dev loss: 0.3535 r:0.8203
et_en Dev loss: 0.4839 r:0.6813
si_en Dev loss: 0.8656 r:0.5513
ne_en Dev loss: 0.4072 r:0.7302
ru_en Dev loss: 0.4387 r:0.7389
Current avg r:0.5943 Best avg r: 0.6229
05:20:41,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:22:11,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:42,312 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1610
en_de Dev loss: 0.9245 r:0.1865
en_zh Dev loss: 0.8194 r:0.4450
ro_en Dev loss: 0.3538 r:0.8201
et_en Dev loss: 0.4704 r:0.6836
si_en Dev loss: 0.8539 r:0.5494
ne_en Dev loss: 0.4022 r:0.7315
ru_en Dev loss: 0.4583 r:0.7399
Current avg r:0.5937 Best avg r: 0.6229
05:28:13,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:29:43,790 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:14,255 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1496
en_de Dev loss: 0.8995 r:0.1786
en_zh Dev loss: 0.7757 r:0.4423
ro_en Dev loss: 0.3405 r:0.8174
et_en Dev loss: 0.4742 r:0.6779
si_en Dev loss: 0.7959 r:0.5359
ne_en Dev loss: 0.3994 r:0.7264
ru_en Dev loss: 0.4306 r:0.7267
Current avg r:0.5865 Best avg r: 0.6229
05:35:45,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:15,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:46,8 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1487
en_de Dev loss: 0.9093 r:0.1545
en_zh Dev loss: 0.8011 r:0.4410
ro_en Dev loss: 0.3500 r:0.8132
et_en Dev loss: 0.4791 r:0.6723
si_en Dev loss: 0.8252 r:0.5509
ne_en Dev loss: 0.4142 r:0.7301
ru_en Dev loss: 0.4918 r:0.7090
Current avg r:0.5815 Best avg r: 0.6229
05:43:17,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:47,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:18,265 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1556
en_de Dev loss: 0.9029 r:0.1634
en_zh Dev loss: 0.7938 r:0.4348
ro_en Dev loss: 0.3368 r:0.8166
et_en Dev loss: 0.4680 r:0.6703
si_en Dev loss: 0.7960 r:0.5429
ne_en Dev loss: 0.3959 r:0.7305
ru_en Dev loss: 0.4508 r:0.7209
Current avg r:0.5828 Best avg r: 0.6229
05:50:49,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:19,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:50,247 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1493
en_de Dev loss: 0.9162 r:0.1842
en_zh Dev loss: 0.8081 r:0.4409
ro_en Dev loss: 0.3757 r:0.8126
et_en Dev loss: 0.4944 r:0.6625
si_en Dev loss: 0.8722 r:0.5402
ne_en Dev loss: 0.4286 r:0.7246
ru_en Dev loss: 0.4868 r:0.7142
Current avg r:0.5827 Best avg r: 0.6229
05:58:21,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:51,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:01:22,122 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1536
en_de Dev loss: 0.9357 r:0.1919
en_zh Dev loss: 0.8650 r:0.4405
ro_en Dev loss: 0.3832 r:0.8165
et_en Dev loss: 0.5129 r:0.6637
si_en Dev loss: 0.8933 r:0.5447
ne_en Dev loss: 0.4412 r:0.7237
ru_en Dev loss: 0.5119 r:0.7197
Current avg r:0.5858 Best avg r: 0.6229
06:05:55,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:25,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:56,107 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1402
en_de Dev loss: 0.9080 r:0.1671
en_zh Dev loss: 0.7957 r:0.4392
ro_en Dev loss: 0.3538 r:0.8125
et_en Dev loss: 0.5011 r:0.6549
si_en Dev loss: 0.8198 r:0.5441
ne_en Dev loss: 0.4131 r:0.7264
ru_en Dev loss: 0.4596 r:0.7190
Current avg r:0.5805 Best avg r: 0.6229
06:13:27,664 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:58,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:16:28,611 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1407
en_de Dev loss: 0.9041 r:0.1834
en_zh Dev loss: 0.7800 r:0.4484
ro_en Dev loss: 0.3252 r:0.8186
et_en Dev loss: 0.4784 r:0.6712
si_en Dev loss: 0.7733 r:0.5543
ne_en Dev loss: 0.4084 r:0.7270
ru_en Dev loss: 0.4359 r:0.7288
Current avg r:0.5902 Best avg r: 0.6229
06:20:59,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:22:30,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:00,480 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1328
en_de Dev loss: 0.9284 r:0.1758
en_zh Dev loss: 0.7805 r:0.4593
ro_en Dev loss: 0.3503 r:0.8229
et_en Dev loss: 0.4656 r:0.6747
si_en Dev loss: 0.8687 r:0.5433
ne_en Dev loss: 0.4291 r:0.7310
ru_en Dev loss: 0.4387 r:0.7422
Current avg r:0.5927 Best avg r: 0.6229
06:28:31,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:01,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:32,271 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1384
en_de Dev loss: 0.9033 r:0.1890
en_zh Dev loss: 0.7802 r:0.4475
ro_en Dev loss: 0.3308 r:0.8195
et_en Dev loss: 0.4786 r:0.6781
si_en Dev loss: 0.8214 r:0.5497
ne_en Dev loss: 0.4255 r:0.7280
ru_en Dev loss: 0.4227 r:0.7399
Current avg r:0.5931 Best avg r: 0.6229
06:36:03,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:33,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:04,101 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1466
en_de Dev loss: 0.8563 r:0.2287
en_zh Dev loss: 0.7534 r:0.4474
ro_en Dev loss: 0.3352 r:0.8179
et_en Dev loss: 0.4845 r:0.6772
si_en Dev loss: 0.8172 r:0.5468
ne_en Dev loss: 0.4060 r:0.7287
ru_en Dev loss: 0.4474 r:0.7246
Current avg r:0.5959 Best avg r: 0.6229
06:43:35,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:05,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:35,909 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1407
en_de Dev loss: 0.9127 r:0.2037
en_zh Dev loss: 0.7644 r:0.4702
ro_en Dev loss: 0.3353 r:0.8217
et_en Dev loss: 0.5013 r:0.6896
si_en Dev loss: 0.7756 r:0.5613
ne_en Dev loss: 0.3871 r:0.7349
ru_en Dev loss: 0.4070 r:0.7610
Current avg r:0.6061 Best avg r: 0.6229
06:51:06,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:37,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:54:07,769 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1410
en_de Dev loss: 0.9000 r:0.2001
en_zh Dev loss: 0.7726 r:0.4473
ro_en Dev loss: 0.3203 r:0.8195
et_en Dev loss: 0.4587 r:0.6759
si_en Dev loss: 0.7925 r:0.5516
ne_en Dev loss: 0.4022 r:0.7217
ru_en Dev loss: 0.3962 r:0.7539
Current avg r:0.5957 Best avg r: 0.6229
06:58:38,510 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:09,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:39,478 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1447
en_de Dev loss: 0.8892 r:0.2055
en_zh Dev loss: 0.7964 r:0.4410
ro_en Dev loss: 0.3508 r:0.8128
et_en Dev loss: 0.4691 r:0.6671
si_en Dev loss: 0.9272 r:0.5278
ne_en Dev loss: 0.4199 r:0.7206
ru_en Dev loss: 0.4556 r:0.7323
Current avg r:0.5867 Best avg r: 0.6229
07:06:10,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:07:41,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:09:11,706 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1271
en_de Dev loss: 0.8734 r:0.2134
en_zh Dev loss: 0.7707 r:0.4532
ro_en Dev loss: 0.3459 r:0.8124
et_en Dev loss: 0.4764 r:0.6648
si_en Dev loss: 0.8739 r:0.5367
ne_en Dev loss: 0.4177 r:0.7226
ru_en Dev loss: 0.4189 r:0.7412
Current avg r:0.5920 Best avg r: 0.6229
07:13:42,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:15:12,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:16:43,345 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1350
en_de Dev loss: 0.9129 r:0.1954
en_zh Dev loss: 0.8011 r:0.4537
ro_en Dev loss: 0.3797 r:0.8116
et_en Dev loss: 0.4863 r:0.6548
si_en Dev loss: 0.9523 r:0.5294
ne_en Dev loss: 0.4755 r:0.7176
ru_en Dev loss: 0.4824 r:0.7229
Current avg r:0.5836 Best avg r: 0.6229
07:21:14,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:22:44,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:24:15,0 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1350
en_de Dev loss: 0.9113 r:0.2045
en_zh Dev loss: 0.8180 r:0.4517
ro_en Dev loss: 0.3666 r:0.8150
et_en Dev loss: 0.4776 r:0.6686
si_en Dev loss: 0.8990 r:0.5347
ne_en Dev loss: 0.4229 r:0.7206
ru_en Dev loss: 0.4359 r:0.7441
Current avg r:0.5913 Best avg r: 0.6229
07:28:45,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:30:16,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:31:46,696 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1392
en_de Dev loss: 0.9501 r:0.1953
en_zh Dev loss: 0.7870 r:0.4720
ro_en Dev loss: 0.3540 r:0.8201
et_en Dev loss: 0.5059 r:0.6824
si_en Dev loss: 0.8446 r:0.5506
ne_en Dev loss: 0.4109 r:0.7268
ru_en Dev loss: 0.4109 r:0.7592
Current avg r:0.6009 Best avg r: 0.6229
07:36:17,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:37:48,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:39:18,614 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1346
en_de Dev loss: 0.9341 r:0.1526
en_zh Dev loss: 0.8284 r:0.4429
ro_en Dev loss: 0.3694 r:0.8117
et_en Dev loss: 0.4811 r:0.6685
si_en Dev loss: 0.8961 r:0.5368
ne_en Dev loss: 0.4312 r:0.7285
ru_en Dev loss: 0.4782 r:0.7171
Current avg r:0.5797 Best avg r: 0.6229
07:43:49,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:45:19,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:46:50,390 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1282
en_de Dev loss: 0.9035 r:0.1623
en_zh Dev loss: 0.7897 r:0.4402
ro_en Dev loss: 0.3443 r:0.8123
et_en Dev loss: 0.4652 r:0.6709
si_en Dev loss: 0.8838 r:0.5294
ne_en Dev loss: 0.4101 r:0.7256
ru_en Dev loss: 0.4493 r:0.7241
Current avg r:0.5807 Best avg r: 0.6229
07:51:21,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:52:51,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:54:22,265 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1239
en_de Dev loss: 0.9423 r:0.1743
en_zh Dev loss: 0.7997 r:0.4558
ro_en Dev loss: 0.3667 r:0.8158
et_en Dev loss: 0.4693 r:0.6775
si_en Dev loss: 0.9347 r:0.5328
ne_en Dev loss: 0.4155 r:0.7329
ru_en Dev loss: 0.4623 r:0.7361
Current avg r:0.5893 Best avg r: 0.6229
07:58:54,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:00:25,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:01:55,936 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1196
en_de Dev loss: 0.9342 r:0.1635
en_zh Dev loss: 0.8424 r:0.4408
ro_en Dev loss: 0.3494 r:0.8164
et_en Dev loss: 0.4503 r:0.6751
si_en Dev loss: 0.9602 r:0.5270
ne_en Dev loss: 0.4504 r:0.7286
ru_en Dev loss: 0.4543 r:0.7280
Current avg r:0.5827 Best avg r: 0.6229
08:06:26,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:07:57,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:09:27,539 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1231
en_de Dev loss: 0.9062 r:0.1845
en_zh Dev loss: 0.7910 r:0.4476
ro_en Dev loss: 0.3329 r:0.8164
et_en Dev loss: 0.4535 r:0.6815
si_en Dev loss: 0.8138 r:0.5423
ne_en Dev loss: 0.3940 r:0.7312
ru_en Dev loss: 0.4167 r:0.7409
Current avg r:0.5921 Best avg r: 0.6229
08:13:58,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:28,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:59,195 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1242
en_de Dev loss: 0.9360 r:0.1954
en_zh Dev loss: 0.7898 r:0.4646
ro_en Dev loss: 0.3435 r:0.8157
et_en Dev loss: 0.4772 r:0.6748
si_en Dev loss: 0.8388 r:0.5406
ne_en Dev loss: 0.3970 r:0.7308
ru_en Dev loss: 0.4317 r:0.7402
Current avg r:0.5946 Best avg r: 0.6229
08:21:29,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:23:00,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:24:30,918 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1257
en_de Dev loss: 0.9219 r:0.1868
en_zh Dev loss: 0.7690 r:0.4618
ro_en Dev loss: 0.3378 r:0.8153
et_en Dev loss: 0.4695 r:0.6750
si_en Dev loss: 0.8464 r:0.5398
ne_en Dev loss: 0.4028 r:0.7271
ru_en Dev loss: 0.4066 r:0.7433
Current avg r:0.5927 Best avg r: 0.6229
08:29:01,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:30:32,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:32:02,756 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1187
en_de Dev loss: 0.9425 r:0.1699
en_zh Dev loss: 0.7944 r:0.4530
ro_en Dev loss: 0.3560 r:0.8139
et_en Dev loss: 0.4720 r:0.6718
si_en Dev loss: 0.8958 r:0.5350
ne_en Dev loss: 0.4077 r:0.7246
ru_en Dev loss: 0.4637 r:0.7306
Current avg r:0.5855 Best avg r: 0.6229
08:36:33,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:38:04,370 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:39:34,839 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1183
en_de Dev loss: 0.9166 r:0.1886
en_zh Dev loss: 0.7812 r:0.4493
ro_en Dev loss: 0.3233 r:0.8178
et_en Dev loss: 0.4693 r:0.6797
si_en Dev loss: 0.7989 r:0.5435
ne_en Dev loss: 0.3853 r:0.7292
ru_en Dev loss: 0.3972 r:0.7554
Current avg r:0.5948 Best avg r: 0.6229
08:44:05,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:45:36,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:47:06,601 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1246
en_de Dev loss: 0.9291 r:0.1839
en_zh Dev loss: 0.8535 r:0.4489
ro_en Dev loss: 0.3966 r:0.8119
et_en Dev loss: 0.4903 r:0.6756
si_en Dev loss: 0.9307 r:0.5364
ne_en Dev loss: 0.4367 r:0.7276
ru_en Dev loss: 0.4766 r:0.7387
Current avg r:0.5890 Best avg r: 0.6229
08:51:37,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:07,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:38,76 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1196
en_de Dev loss: 0.9146 r:0.1861
en_zh Dev loss: 0.8220 r:0.4575
ro_en Dev loss: 0.3705 r:0.8181
et_en Dev loss: 0.4700 r:0.6781
si_en Dev loss: 0.8838 r:0.5389
ne_en Dev loss: 0.4130 r:0.7303
ru_en Dev loss: 0.4341 r:0.7503
Current avg r:0.5942 Best avg r: 0.6229
08:59:08,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:00:39,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:02:09,567 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1232
en_de Dev loss: 0.9111 r:0.1883
en_zh Dev loss: 0.7774 r:0.4631
ro_en Dev loss: 0.3481 r:0.8169
et_en Dev loss: 0.4607 r:0.6780
si_en Dev loss: 0.8465 r:0.5398
ne_en Dev loss: 0.3979 r:0.7266
ru_en Dev loss: 0.4244 r:0.7472
Current avg r:0.5943 Best avg r: 0.6229
09:06:40,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:08:10,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:40,924 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1202
en_de Dev loss: 0.9296 r:0.1624
en_zh Dev loss: 0.8128 r:0.4501
ro_en Dev loss: 0.3775 r:0.8103
et_en Dev loss: 0.4748 r:0.6717
si_en Dev loss: 0.9356 r:0.5335
ne_en Dev loss: 0.4123 r:0.7340
ru_en Dev loss: 0.4373 r:0.7458
Current avg r:0.5868 Best avg r: 0.6229
09:14:11,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:42,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:17:12,609 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1169
en_de Dev loss: 0.9215 r:0.1900
en_zh Dev loss: 0.7967 r:0.4633
ro_en Dev loss: 0.3428 r:0.8160
et_en Dev loss: 0.5029 r:0.6801
si_en Dev loss: 0.8310 r:0.5386
ne_en Dev loss: 0.3834 r:0.7340
ru_en Dev loss: 0.4055 r:0.7563
Current avg r:0.5969 Best avg r: 0.6229
09:21:43,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:22:09,105 root INFO 
id:en_zh cur r: 0.4787 best r: 0.4787
09:23:13,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:24:44,336 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1213
en_de Dev loss: 0.9030 r:0.1761
en_zh Dev loss: 0.7833 r:0.4688
ro_en Dev loss: 0.3476 r:0.8128
et_en Dev loss: 0.4405 r:0.6657
si_en Dev loss: 0.9229 r:0.5270
ne_en Dev loss: 0.4341 r:0.7299
ru_en Dev loss: 0.4534 r:0.7338
Current avg r:0.5877 Best avg r: 0.6229
09:29:14,980 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:45,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:32:15,802 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1144
en_de Dev loss: 0.9290 r:0.1694
en_zh Dev loss: 0.8064 r:0.4634
ro_en Dev loss: 0.3653 r:0.8127
et_en Dev loss: 0.4585 r:0.6718
si_en Dev loss: 0.9506 r:0.5245
ne_en Dev loss: 0.4201 r:0.7345
ru_en Dev loss: 0.4668 r:0.7390
Current avg r:0.5879 Best avg r: 0.6229
09:36:46,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:38:16,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:39:47,341 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1165
en_de Dev loss: 0.9019 r:0.1867
en_zh Dev loss: 0.7654 r:0.4692
ro_en Dev loss: 0.3451 r:0.8158
et_en Dev loss: 0.4697 r:0.6712
si_en Dev loss: 0.8555 r:0.5339
ne_en Dev loss: 0.4005 r:0.7332
ru_en Dev loss: 0.4567 r:0.7321
Current avg r:0.5917 Best avg r: 0.6229
09:44:18,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:45:48,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:47:18,903 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1142
en_de Dev loss: 0.9200 r:0.1934
en_zh Dev loss: 0.7814 r:0.4736
ro_en Dev loss: 0.3777 r:0.8149
et_en Dev loss: 0.4654 r:0.6788
si_en Dev loss: 0.8724 r:0.5387
ne_en Dev loss: 0.4118 r:0.7356
ru_en Dev loss: 0.4673 r:0.7388
Current avg r:0.5963 Best avg r: 0.6229
09:51:51,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:52:17,85 root INFO 
id:en_zh cur r: 0.4794 best r: 0.4794
09:53:21,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:54:52,128 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1063
en_de Dev loss: 0.9074 r:0.1913
en_zh Dev loss: 0.7336 r:0.4772
ro_en Dev loss: 0.3431 r:0.8141
et_en Dev loss: 0.4495 r:0.6826
si_en Dev loss: 0.8419 r:0.5367
ne_en Dev loss: 0.3814 r:0.7349
ru_en Dev loss: 0.4268 r:0.7417
Current avg r:0.5969 Best avg r: 0.6229
09:59:22,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:00:53,302 root INFO 
id:ru_en cur r: 0.7656 best r: 0.7656
10:00:53,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:23,725 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1082
en_de Dev loss: 0.9458 r:0.1739
en_zh Dev loss: 0.7832 r:0.4624
ro_en Dev loss: 0.3594 r:0.8173
et_en Dev loss: 0.4661 r:0.6808
si_en Dev loss: 0.8424 r:0.5439
ne_en Dev loss: 0.3925 r:0.7365
ru_en Dev loss: 0.4218 r:0.7548
Current avg r:0.5957 Best avg r: 0.6229
10:06:54,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:07:20,427 root INFO 
id:en_zh cur r: 0.4796 best r: 0.4796
10:08:25,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:55,473 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1118
en_de Dev loss: 0.9340 r:0.1727
en_zh Dev loss: 0.7472 r:0.4734
ro_en Dev loss: 0.3394 r:0.8177
et_en Dev loss: 0.4708 r:0.6758
si_en Dev loss: 0.8124 r:0.5467
ne_en Dev loss: 0.3837 r:0.7377
ru_en Dev loss: 0.4163 r:0.7510
Current avg r:0.5964 Best avg r: 0.6229
10:14:26,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:15:56,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:27,55 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1064
en_de Dev loss: 0.9174 r:0.1803
en_zh Dev loss: 0.7534 r:0.4738
ro_en Dev loss: 0.3395 r:0.8164
et_en Dev loss: 0.4682 r:0.6800
si_en Dev loss: 0.8545 r:0.5446
ne_en Dev loss: 0.3845 r:0.7400
ru_en Dev loss: 0.4039 r:0.7557
Current avg r:0.5987 Best avg r: 0.6229
10:21:57,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:23:28,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:24:58,729 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1124
en_de Dev loss: 0.9427 r:0.1548
en_zh Dev loss: 0.7567 r:0.4675
ro_en Dev loss: 0.3582 r:0.8108
et_en Dev loss: 0.4541 r:0.6711
si_en Dev loss: 0.9063 r:0.5265
ne_en Dev loss: 0.3934 r:0.7333
ru_en Dev loss: 0.4188 r:0.7473
Current avg r:0.5873 Best avg r: 0.6229
10:29:29,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:30:59,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
