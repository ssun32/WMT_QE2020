14:37:11,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:25,170 root INFO 
id:en_de cur r: 0.0780 best r: 0.0780
14:38:04,701 root INFO 
id:ro_en cur r: 0.6287 best r: 0.6287
14:38:17,910 root INFO 
id:et_en cur r: 0.5464 best r: 0.5464
14:38:31,134 root INFO 
id:si_en cur r: 0.4355 best r: 0.4355
14:38:44,365 root INFO 
id:ne_en cur r: 0.5434 best r: 0.5434
14:38:57,501 root INFO 
id:ru_en cur r: 0.6442 best r: 0.6442
14:38:57,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:29,834 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
14:40:29,844 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:40:29,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:40:29,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
14:40:29,859 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
14:40:29,864 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:40:29,869 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:40:43,75 root INFO Epoch 0 Global steps: 700 Train loss: 0.7793
en_de Dev loss: 0.9085 r:0.0856
en_zh Dev loss: 0.7649 r:0.2666
ro_en Dev loss: 0.6095 r:0.5929
et_en Dev loss: 0.5650 r:0.5149
si_en Dev loss: 0.7126 r:0.4243
ne_en Dev loss: 0.6182 r:0.5149
ru_en Dev loss: 0.5408 r:0.6520
Current avg r:0.4359 Best avg r: 0.4359
14:45:18,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:44,820 root INFO 
id:en_zh cur r: 0.2883 best r: 0.2883
14:46:11,143 root INFO 
id:ro_en cur r: 0.6541 best r: 0.6541
14:46:24,307 root INFO 
id:et_en cur r: 0.5935 best r: 0.5935
14:46:37,486 root INFO 
id:si_en cur r: 0.4410 best r: 0.4410
14:46:50,653 root INFO 
id:ne_en cur r: 0.5543 best r: 0.5543
14:47:03,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:35,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
14:48:35,619 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:48:35,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:48:35,630 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
14:48:35,635 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
14:48:35,640 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:48:35,645 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:48:48,801 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8159
en_de Dev loss: 0.9136 r:0.0881
en_zh Dev loss: 0.7449 r:0.3113
ro_en Dev loss: 0.5395 r:0.6491
et_en Dev loss: 0.5264 r:0.5895
si_en Dev loss: 0.6384 r:0.4640
ne_en Dev loss: 0.5806 r:0.5660
ru_en Dev loss: 0.5330 r:0.6620
Current avg r:0.4757 Best avg r: 0.4757
14:53:23,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:50,213 root INFO 
id:en_zh cur r: 0.2945 best r: 0.2945
14:54:16,516 root INFO 
id:ro_en cur r: 0.6578 best r: 0.6578
14:54:29,682 root INFO 
id:et_en cur r: 0.5960 best r: 0.5960
14:54:56,7 root INFO 
id:ne_en cur r: 0.6085 best r: 0.6085
14:55:09,73 root INFO 
id:ru_en cur r: 0.6787 best r: 0.6787
14:55:09,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:56:40,986 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
14:56:40,993 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:56:40,998 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:56:41,3 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
14:56:41,8 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
14:56:41,13 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:56:41,20 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:56:54,159 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7198
en_de Dev loss: 0.9474 r:0.0966
en_zh Dev loss: 0.7347 r:0.3306
ro_en Dev loss: 0.5159 r:0.6631
et_en Dev loss: 0.4805 r:0.5917
si_en Dev loss: 0.6710 r:0.4762
ne_en Dev loss: 0.5278 r:0.6143
ru_en Dev loss: 0.4890 r:0.7026
Current avg r:0.4965 Best avg r: 0.4965
15:01:29,818 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:56,105 root INFO 
id:en_zh cur r: 0.3070 best r: 0.3070
15:02:22,420 root INFO 
id:ro_en cur r: 0.6903 best r: 0.6903
15:02:35,600 root INFO 
id:et_en cur r: 0.6293 best r: 0.6293
15:02:48,791 root INFO 
id:si_en cur r: 0.4784 best r: 0.4784
15:03:01,971 root INFO 
id:ne_en cur r: 0.6628 best r: 0.6628
15:03:15,36 root INFO 
id:ru_en cur r: 0.6993 best r: 0.6993
15:03:15,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:46,976 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:04:46,983 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:04:46,988 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:04:46,995 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:04:47,1 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:04:47,5 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:04:47,11 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:05:00,171 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6776
en_de Dev loss: 1.0074 r:0.1086
en_zh Dev loss: 0.7533 r:0.3382
ro_en Dev loss: 0.4408 r:0.6986
et_en Dev loss: 0.4348 r:0.6244
si_en Dev loss: 0.6344 r:0.4955
ne_en Dev loss: 0.4586 r:0.6605
ru_en Dev loss: 0.4218 r:0.7255
Current avg r:0.5216 Best avg r: 0.5216
15:09:35,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:48,553 root INFO 
id:en_de cur r: 0.1476 best r: 0.1476
15:11:07,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:39,294 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6397
en_de Dev loss: 1.0602 r:0.1539
en_zh Dev loss: 0.8580 r:0.3204
ro_en Dev loss: 0.5635 r:0.6575
et_en Dev loss: 0.5191 r:0.5779
si_en Dev loss: 0.8565 r:0.4584
ne_en Dev loss: 0.5913 r:0.5926
ru_en Dev loss: 0.5606 r:0.6856
Current avg r:0.4923 Best avg r: 0.5216
15:17:15,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:41,295 root INFO 
id:en_zh cur r: 0.3627 best r: 0.3627
15:18:07,603 root INFO 
id:ro_en cur r: 0.7088 best r: 0.7088
15:18:20,786 root INFO 
id:et_en cur r: 0.6591 best r: 0.6591
15:18:33,974 root INFO 
id:si_en cur r: 0.5099 best r: 0.5099
15:18:47,152 root INFO 
id:ne_en cur r: 0.6703 best r: 0.6703
15:19:00,225 root INFO 
id:ru_en cur r: 0.7257 best r: 0.7257
15:19:00,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:32,183 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:20:32,190 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:20:32,195 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:20:32,200 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:20:32,204 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:20:32,209 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:20:32,214 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:20:45,381 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6216
en_de Dev loss: 0.9868 r:0.1450
en_zh Dev loss: 0.7076 r:0.4034
ro_en Dev loss: 0.4137 r:0.7213
et_en Dev loss: 0.3962 r:0.6655
si_en Dev loss: 0.6297 r:0.5330
ne_en Dev loss: 0.4430 r:0.6748
ru_en Dev loss: 0.4133 r:0.7458
Current avg r:0.5555 Best avg r: 0.5555
15:25:20,916 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:47,167 root INFO 
id:en_zh cur r: 0.3815 best r: 0.3815
15:26:13,472 root INFO 
id:ro_en cur r: 0.7108 best r: 0.7108
15:27:06,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:38,41 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6261
en_de Dev loss: 1.0019 r:0.1575
en_zh Dev loss: 0.7464 r:0.4035
ro_en Dev loss: 0.4380 r:0.7264
et_en Dev loss: 0.4176 r:0.6592
si_en Dev loss: 0.7498 r:0.5222
ne_en Dev loss: 0.5653 r:0.6426
ru_en Dev loss: 0.4643 r:0.7454
Current avg r:0.5510 Best avg r: 0.5555
15:33:13,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:26,409 root INFO 
id:en_de cur r: 0.1606 best r: 0.1606
15:33:39,537 root INFO 
id:en_zh cur r: 0.3973 best r: 0.3973
15:34:05,844 root INFO 
id:ro_en cur r: 0.7177 best r: 0.7177
15:34:19,21 root INFO 
id:et_en cur r: 0.6741 best r: 0.6741
15:34:32,202 root INFO 
id:si_en cur r: 0.5378 best r: 0.5378
15:34:45,380 root INFO 
id:ne_en cur r: 0.6982 best r: 0.6982
15:34:58,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:30,386 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:36:30,393 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:36:30,399 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:36:30,403 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:36:30,408 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:36:30,413 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:36:30,417 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:36:43,565 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5661
en_de Dev loss: 0.9353 r:0.1763
en_zh Dev loss: 0.7045 r:0.4180
ro_en Dev loss: 0.4147 r:0.7281
et_en Dev loss: 0.3856 r:0.6783
si_en Dev loss: 0.6295 r:0.5476
ne_en Dev loss: 0.4447 r:0.6778
ru_en Dev loss: 0.4411 r:0.7384
Current avg r:0.5664 Best avg r: 0.5664
15:41:18,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:50,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:22,615 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5536
en_de Dev loss: 0.9984 r:0.1784
en_zh Dev loss: 0.8270 r:0.3965
ro_en Dev loss: 0.4853 r:0.7186
et_en Dev loss: 0.4324 r:0.6579
si_en Dev loss: 0.7439 r:0.5338
ne_en Dev loss: 0.5396 r:0.6720
ru_en Dev loss: 0.4810 r:0.7284
Current avg r:0.5551 Best avg r: 0.5664
15:48:57,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:24,25 root INFO 
id:en_zh cur r: 0.4402 best r: 0.4402
15:49:50,339 root INFO 
id:ro_en cur r: 0.7375 best r: 0.7375
15:50:03,504 root INFO 
id:et_en cur r: 0.6800 best r: 0.6800
15:50:16,674 root INFO 
id:si_en cur r: 0.5839 best r: 0.5839
15:50:29,842 root INFO 
id:ne_en cur r: 0.7262 best r: 0.7262
15:50:42,910 root INFO 
id:ru_en cur r: 0.7438 best r: 0.7438
15:50:42,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:14,828 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:52:14,835 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:52:14,840 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:52:14,845 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:52:14,850 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:52:14,855 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:52:14,860 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:52:28,17 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5420
en_de Dev loss: 0.8795 r:0.1745
en_zh Dev loss: 0.6679 r:0.4491
ro_en Dev loss: 0.3982 r:0.7423
et_en Dev loss: 0.3713 r:0.6913
si_en Dev loss: 0.5620 r:0.5850
ne_en Dev loss: 0.3821 r:0.7236
ru_en Dev loss: 0.3868 r:0.7542
Current avg r:0.5886 Best avg r: 0.5886
15:57:03,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:55,777 root INFO 
id:ro_en cur r: 0.7475 best r: 0.7475
15:58:48,370 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:20,346 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:00:20,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:00:20,361 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:00:20,366 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:00:20,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:00:20,375 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:00:20,382 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:00:33,537 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5623
en_de Dev loss: 0.8825 r:0.1912
en_zh Dev loss: 0.7360 r:0.4506
ro_en Dev loss: 0.4381 r:0.7555
et_en Dev loss: 0.3935 r:0.6876
si_en Dev loss: 0.7028 r:0.5681
ne_en Dev loss: 0.4350 r:0.7202
ru_en Dev loss: 0.4667 r:0.7517
Current avg r:0.5893 Best avg r: 0.5893
16:05:08,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:22,112 root INFO 
id:en_de cur r: 0.1649 best r: 0.1649
16:05:35,225 root INFO 
id:en_zh cur r: 0.4573 best r: 0.4573
16:06:01,501 root INFO 
id:ro_en cur r: 0.7563 best r: 0.7563
16:06:14,660 root INFO 
id:et_en cur r: 0.6894 best r: 0.6894
16:06:40,981 root INFO 
id:ne_en cur r: 0.7323 best r: 0.7323
16:06:54,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:25,921 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:08:25,928 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:08:25,934 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:08:25,939 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:08:25,945 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:08:25,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:08:25,956 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:08:39,111 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5170
en_de Dev loss: 0.8859 r:0.1950
en_zh Dev loss: 0.7059 r:0.4575
ro_en Dev loss: 0.4085 r:0.7584
et_en Dev loss: 0.3648 r:0.6988
si_en Dev loss: 0.7176 r:0.5690
ne_en Dev loss: 0.4303 r:0.7209
ru_en Dev loss: 0.4549 r:0.7504
Current avg r:0.5928 Best avg r: 0.5928
16:13:14,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:27,458 root INFO 
id:en_de cur r: 0.1712 best r: 0.1712
16:14:06,871 root INFO 
id:ro_en cur r: 0.7578 best r: 0.7578
16:14:59,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:31,386 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5288
en_de Dev loss: 0.8973 r:0.1907
en_zh Dev loss: 0.7081 r:0.4650
ro_en Dev loss: 0.4360 r:0.7572
et_en Dev loss: 0.3826 r:0.6890
si_en Dev loss: 0.6726 r:0.5673
ne_en Dev loss: 0.4162 r:0.7230
ru_en Dev loss: 0.4589 r:0.7453
Current avg r:0.5911 Best avg r: 0.5928
16:21:06,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:21:59,34 root INFO 
id:ro_en cur r: 0.7730 best r: 0.7730
16:22:12,206 root INFO 
id:et_en cur r: 0.6995 best r: 0.6995
16:22:38,561 root INFO 
id:ne_en cur r: 0.7437 best r: 0.7437
16:22:51,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:24:23,627 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:24:23,635 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:24:23,640 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:24:23,645 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:24:23,652 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:24:23,657 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:24:23,662 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:24:36,810 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5544
en_de Dev loss: 0.8738 r:0.1832
en_zh Dev loss: 0.7031 r:0.4529
ro_en Dev loss: 0.3837 r:0.7753
et_en Dev loss: 0.3561 r:0.7047
si_en Dev loss: 0.6775 r:0.5856
ne_en Dev loss: 0.4472 r:0.7388
ru_en Dev loss: 0.4433 r:0.7579
Current avg r:0.5998 Best avg r: 0.5998
16:29:12,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:25,177 root INFO 
id:en_de cur r: 0.1821 best r: 0.1821
16:30:04,632 root INFO 
id:ro_en cur r: 0.7763 best r: 0.7763
16:30:57,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:32:29,188 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5085
en_de Dev loss: 0.8998 r:0.1971
en_zh Dev loss: 0.7730 r:0.4449
ro_en Dev loss: 0.4610 r:0.7696
et_en Dev loss: 0.3951 r:0.6926
si_en Dev loss: 0.7541 r:0.5696
ne_en Dev loss: 0.4675 r:0.7333
ru_en Dev loss: 0.4790 r:0.7445
Current avg r:0.5931 Best avg r: 0.5998
16:37:07,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:20,502 root INFO 
id:en_de cur r: 0.1844 best r: 0.1844
16:38:00,86 root INFO 
id:et_en cur r: 0.6995 best r: 0.6995
16:38:39,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:11,883 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4998
en_de Dev loss: 0.8743 r:0.1957
en_zh Dev loss: 0.7075 r:0.4478
ro_en Dev loss: 0.4366 r:0.7702
et_en Dev loss: 0.3764 r:0.6986
si_en Dev loss: 0.7299 r:0.5718
ne_en Dev loss: 0.5031 r:0.7348
ru_en Dev loss: 0.4386 r:0.7455
Current avg r:0.5949 Best avg r: 0.5998
16:44:47,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:00,960 root INFO 
id:en_de cur r: 0.1982 best r: 0.1982
16:46:19,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:51,774 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4952
en_de Dev loss: 0.8875 r:0.1953
en_zh Dev loss: 0.7821 r:0.4552
ro_en Dev loss: 0.4801 r:0.7634
et_en Dev loss: 0.4157 r:0.6894
si_en Dev loss: 0.7107 r:0.5813
ne_en Dev loss: 0.4503 r:0.7368
ru_en Dev loss: 0.4817 r:0.7450
Current avg r:0.5952 Best avg r: 0.5998
16:52:27,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:46,78 root INFO 
id:ne_en cur r: 0.7506 best r: 0.7506
16:53:59,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:31,166 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4908
en_de Dev loss: 0.8777 r:0.1988
en_zh Dev loss: 0.7403 r:0.4615
ro_en Dev loss: 0.4269 r:0.7693
et_en Dev loss: 0.3855 r:0.6917
si_en Dev loss: 0.7139 r:0.5798
ne_en Dev loss: 0.4243 r:0.7455
ru_en Dev loss: 0.4660 r:0.7397
Current avg r:0.5981 Best avg r: 0.5998
17:00:06,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:00:59,175 root INFO 
id:ro_en cur r: 0.7816 best r: 0.7816
17:01:25,543 root INFO 
id:si_en cur r: 0.5930 best r: 0.5930
17:01:51,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:23,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:03:23,839 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:03:23,844 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:03:23,848 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:03:23,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:03:23,860 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:03:23,865 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:03:37,31 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4882
en_de Dev loss: 0.8657 r:0.2179
en_zh Dev loss: 0.7270 r:0.4558
ro_en Dev loss: 0.3630 r:0.7795
et_en Dev loss: 0.3631 r:0.6983
si_en Dev loss: 0.6519 r:0.5912
ne_en Dev loss: 0.3666 r:0.7464
ru_en Dev loss: 0.4622 r:0.7251
Current avg r:0.6020 Best avg r: 0.6020
17:08:12,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:44,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:16,537 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4973
en_de Dev loss: 0.9104 r:0.1974
en_zh Dev loss: 0.8505 r:0.4444
ro_en Dev loss: 0.4930 r:0.7670
et_en Dev loss: 0.4084 r:0.6873
si_en Dev loss: 0.7792 r:0.5735
ne_en Dev loss: 0.4769 r:0.7340
ru_en Dev loss: 0.5776 r:0.7099
Current avg r:0.5877 Best avg r: 0.6020
17:15:51,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:23,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:55,942 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4651
en_de Dev loss: 0.8608 r:0.1886
en_zh Dev loss: 0.6914 r:0.4607
ro_en Dev loss: 0.4075 r:0.7713
et_en Dev loss: 0.3781 r:0.6887
si_en Dev loss: 0.6694 r:0.5797
ne_en Dev loss: 0.4083 r:0.7432
ru_en Dev loss: 0.4512 r:0.7275
Current avg r:0.5942 Best avg r: 0.6020
17:23:31,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:03,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:35,363 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4779
en_de Dev loss: 0.8704 r:0.1983
en_zh Dev loss: 0.7786 r:0.4553
ro_en Dev loss: 0.4909 r:0.7711
et_en Dev loss: 0.4022 r:0.6891
si_en Dev loss: 0.8248 r:0.5726
ne_en Dev loss: 0.5093 r:0.7378
ru_en Dev loss: 0.5430 r:0.7215
Current avg r:0.5923 Best avg r: 0.6020
17:31:10,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:23,940 root INFO 
id:en_de cur r: 0.1988 best r: 0.1988
17:31:37,61 root INFO 
id:en_zh cur r: 0.4693 best r: 0.4693
17:32:03,372 root INFO 
id:ro_en cur r: 0.7929 best r: 0.7929
17:32:29,719 root INFO 
id:si_en cur r: 0.5980 best r: 0.5980
17:32:42,896 root INFO 
id:ne_en cur r: 0.7524 best r: 0.7524
17:32:55,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:27,949 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:34:27,955 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:34:27,959 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:34:27,964 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:34:27,969 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:34:27,973 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:34:27,978 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:34:41,138 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4803
en_de Dev loss: 0.8659 r:0.2050
en_zh Dev loss: 0.7125 r:0.4777
ro_en Dev loss: 0.4423 r:0.7872
et_en Dev loss: 0.3793 r:0.7008
si_en Dev loss: 0.7057 r:0.5980
ne_en Dev loss: 0.4988 r:0.7498
ru_en Dev loss: 0.4574 r:0.7445
Current avg r:0.6090 Best avg r: 0.6090
17:39:16,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:48,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:20,661 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4720
en_de Dev loss: 0.8678 r:0.2023
en_zh Dev loss: 0.7642 r:0.4635
ro_en Dev loss: 0.4739 r:0.7746
et_en Dev loss: 0.4089 r:0.6894
si_en Dev loss: 0.7370 r:0.5898
ne_en Dev loss: 0.4512 r:0.7467
ru_en Dev loss: 0.4722 r:0.7337
Current avg r:0.6000 Best avg r: 0.6090
17:46:56,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:09,285 root INFO 
id:en_de cur r: 0.2156 best r: 0.2156
17:48:01,912 root INFO 
id:si_en cur r: 0.6038 best r: 0.6038
17:48:15,96 root INFO 
id:ne_en cur r: 0.7529 best r: 0.7529
17:48:28,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:00,210 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:50:00,216 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:50:00,221 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:50:00,226 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:50:00,235 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:50:00,239 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:50:00,243 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:50:13,406 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4640
en_de Dev loss: 0.8543 r:0.2377
en_zh Dev loss: 0.7303 r:0.4650
ro_en Dev loss: 0.4161 r:0.7763
et_en Dev loss: 0.3782 r:0.6967
si_en Dev loss: 0.6628 r:0.6027
ne_en Dev loss: 0.3847 r:0.7512
ru_en Dev loss: 0.4686 r:0.7350
Current avg r:0.6092 Best avg r: 0.6092
17:54:48,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:01,933 root INFO 
id:en_de cur r: 0.2271 best r: 0.2271
17:55:54,573 root INFO 
id:si_en cur r: 0.6063 best r: 0.6063
17:56:07,752 root INFO 
id:ne_en cur r: 0.7579 best r: 0.7579
17:56:20,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:52,808 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:57:52,814 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:57:52,819 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:57:52,823 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:57:52,828 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:57:52,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:57:52,837 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:58:06,8 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4806
en_de Dev loss: 0.8511 r:0.2324
en_zh Dev loss: 0.7074 r:0.4675
ro_en Dev loss: 0.4252 r:0.7861
et_en Dev loss: 0.3830 r:0.6975
si_en Dev loss: 0.6842 r:0.6025
ne_en Dev loss: 0.4499 r:0.7568
ru_en Dev loss: 0.4672 r:0.7364
Current avg r:0.6113 Best avg r: 0.6113
18:02:41,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:54,549 root INFO 
id:en_de cur r: 0.2325 best r: 0.2325
18:03:07,686 root INFO 
id:en_zh cur r: 0.4828 best r: 0.4828
18:03:34,0 root INFO 
id:ro_en cur r: 0.7949 best r: 0.7949
18:04:00,379 root INFO 
id:si_en cur r: 0.6117 best r: 0.6117
18:04:13,561 root INFO 
id:ne_en cur r: 0.7665 best r: 0.7665
18:04:26,631 root INFO 
id:ru_en cur r: 0.7529 best r: 0.7529
18:04:26,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:58,607 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
18:05:58,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:05:58,621 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:05:58,626 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
18:05:58,632 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
18:05:58,638 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:05:58,643 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:06:11,800 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4341
en_de Dev loss: 0.8722 r:0.2478
en_zh Dev loss: 0.7431 r:0.4747
ro_en Dev loss: 0.4168 r:0.7903
et_en Dev loss: 0.3782 r:0.7047
si_en Dev loss: 0.7186 r:0.6035
ne_en Dev loss: 0.4666 r:0.7641
ru_en Dev loss: 0.4393 r:0.7513
Current avg r:0.6195 Best avg r: 0.6195
18:10:47,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:19,187 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:51,130 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4508
en_de Dev loss: 0.8488 r:0.2310
en_zh Dev loss: 0.7324 r:0.4619
ro_en Dev loss: 0.4577 r:0.7768
et_en Dev loss: 0.4166 r:0.6900
si_en Dev loss: 0.7377 r:0.5804
ne_en Dev loss: 0.4460 r:0.7558
ru_en Dev loss: 0.4128 r:0.7501
Current avg r:0.6066 Best avg r: 0.6195
18:18:26,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:32,247 root INFO 
id:si_en cur r: 0.6142 best r: 0.6142
18:19:58,488 root INFO 
id:ru_en cur r: 0.7532 best r: 0.7532
18:19:58,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:30,410 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4360
en_de Dev loss: 0.8403 r:0.2326
en_zh Dev loss: 0.6719 r:0.4710
ro_en Dev loss: 0.3846 r:0.7889
et_en Dev loss: 0.3801 r:0.7005
si_en Dev loss: 0.6304 r:0.6072
ne_en Dev loss: 0.3801 r:0.7570
ru_en Dev loss: 0.3844 r:0.7582
Current avg r:0.6165 Best avg r: 0.6195
18:26:05,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:37,859 root INFO 
id:ru_en cur r: 0.7569 best r: 0.7569
18:27:37,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:10,66 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4622
en_de Dev loss: 0.8718 r:0.2242
en_zh Dev loss: 0.8407 r:0.4626
ro_en Dev loss: 0.4539 r:0.7851
et_en Dev loss: 0.3946 r:0.6946
si_en Dev loss: 0.7658 r:0.6020
ne_en Dev loss: 0.5706 r:0.7571
ru_en Dev loss: 0.4312 r:0.7546
Current avg r:0.6115 Best avg r: 0.6195
18:33:47,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:00,559 root INFO 
id:en_de cur r: 0.2347 best r: 0.2347
18:34:40,135 root INFO 
id:ro_en cur r: 0.7957 best r: 0.7957
18:35:06,593 root INFO 
id:si_en cur r: 0.6205 best r: 0.6205
18:35:32,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:05,204 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4298
en_de Dev loss: 0.8606 r:0.2187
en_zh Dev loss: 0.7267 r:0.4722
ro_en Dev loss: 0.4088 r:0.7912
et_en Dev loss: 0.3869 r:0.6943
si_en Dev loss: 0.6431 r:0.6173
ne_en Dev loss: 0.4642 r:0.7580
ru_en Dev loss: 0.4658 r:0.7369
Current avg r:0.6127 Best avg r: 0.6195
18:41:40,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:53,893 root INFO 
id:en_de cur r: 0.2432 best r: 0.2432
18:42:07,30 root INFO 
id:en_zh cur r: 0.4943 best r: 0.4943
18:43:12,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:44,754 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4082
en_de Dev loss: 0.8414 r:0.2366
en_zh Dev loss: 0.6477 r:0.4918
ro_en Dev loss: 0.3872 r:0.7903
et_en Dev loss: 0.3840 r:0.6951
si_en Dev loss: 0.6363 r:0.6154
ne_en Dev loss: 0.4391 r:0.7617
ru_en Dev loss: 0.3998 r:0.7445
Current avg r:0.6193 Best avg r: 0.6195
18:49:20,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:33,305 root INFO 
id:en_de cur r: 0.2522 best r: 0.2522
18:50:52,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:24,122 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4197
en_de Dev loss: 0.8539 r:0.2477
en_zh Dev loss: 0.6963 r:0.4815
ro_en Dev loss: 0.4279 r:0.7881
et_en Dev loss: 0.3962 r:0.6933
si_en Dev loss: 0.7887 r:0.5945
ne_en Dev loss: 0.5019 r:0.7596
ru_en Dev loss: 0.4620 r:0.7318
Current avg r:0.6138 Best avg r: 0.6195
18:56:59,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:31,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:03,321 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4190
en_de Dev loss: 0.8714 r:0.2004
en_zh Dev loss: 0.7793 r:0.4685
ro_en Dev loss: 0.4718 r:0.7809
et_en Dev loss: 0.4490 r:0.6708
si_en Dev loss: 0.8846 r:0.5762
ne_en Dev loss: 0.5251 r:0.7535
ru_en Dev loss: 0.4775 r:0.7212
Current avg r:0.5959 Best avg r: 0.6195
19:04:38,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:10,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:42,531 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4059
en_de Dev loss: 0.8555 r:0.2391
en_zh Dev loss: 0.7165 r:0.4754
ro_en Dev loss: 0.4435 r:0.7858
et_en Dev loss: 0.4085 r:0.6844
si_en Dev loss: 0.7262 r:0.5988
ne_en Dev loss: 0.5821 r:0.7545
ru_en Dev loss: 0.5190 r:0.7126
Current avg r:0.6072 Best avg r: 0.6195
19:12:17,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:49,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:21,765 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4595
en_de Dev loss: 0.8547 r:0.2085
en_zh Dev loss: 0.6912 r:0.4696
ro_en Dev loss: 0.4114 r:0.7769
et_en Dev loss: 0.4088 r:0.6808
si_en Dev loss: 0.6726 r:0.5908
ne_en Dev loss: 0.4443 r:0.7546
ru_en Dev loss: 0.4233 r:0.7322
Current avg r:0.6019 Best avg r: 0.6195
19:19:57,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:29,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:01,2 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4106
en_de Dev loss: 0.8707 r:0.2051
en_zh Dev loss: 0.7403 r:0.4801
ro_en Dev loss: 0.4244 r:0.7811
et_en Dev loss: 0.4145 r:0.6803
si_en Dev loss: 0.6370 r:0.5985
ne_en Dev loss: 0.4191 r:0.7513
ru_en Dev loss: 0.4820 r:0.7146
Current avg r:0.6016 Best avg r: 0.6195
19:27:36,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:08,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:40,400 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3993
en_de Dev loss: 0.8553 r:0.2153
en_zh Dev loss: 0.6645 r:0.4903
ro_en Dev loss: 0.4223 r:0.7818
et_en Dev loss: 0.4415 r:0.6864
si_en Dev loss: 0.6071 r:0.6030
ne_en Dev loss: 0.3948 r:0.7549
ru_en Dev loss: 0.3998 r:0.7413
Current avg r:0.6104 Best avg r: 0.6195
19:35:15,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:47,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:19,838 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3984
en_de Dev loss: 0.8742 r:0.2152
en_zh Dev loss: 0.7607 r:0.4806
ro_en Dev loss: 0.4480 r:0.7863
et_en Dev loss: 0.4043 r:0.6926
si_en Dev loss: 0.7610 r:0.5977
ne_en Dev loss: 0.4546 r:0.7606
ru_en Dev loss: 0.4570 r:0.7334
Current avg r:0.6095 Best avg r: 0.6195
19:42:55,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:08,405 root INFO 
id:en_de cur r: 0.2535 best r: 0.2535
19:43:21,536 root INFO 
id:en_zh cur r: 0.4946 best r: 0.4946
19:44:14,247 root INFO 
id:ne_en cur r: 0.7691 best r: 0.7691
19:44:27,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:59,307 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_de.lang_agnost_mlp.dev.best.scores
19:45:59,315 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/en_zh.lang_agnost_mlp.dev.best.scores
19:45:59,320 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ro_en.lang_agnost_mlp.dev.best.scores
19:45:59,326 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/et_en.lang_agnost_mlp.dev.best.scores
19:45:59,330 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/si_en.lang_agnost_mlp.dev.best.scores
19:45:59,335 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ne_en.lang_agnost_mlp.dev.best.scores
19:45:59,340 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.1_roen/run2/ru_en.lang_agnost_mlp.dev.best.scores
19:46:12,510 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3903
en_de Dev loss: 0.8360 r:0.2439
en_zh Dev loss: 0.6726 r:0.4930
ro_en Dev loss: 0.4035 r:0.7892
et_en Dev loss: 0.3970 r:0.6952
si_en Dev loss: 0.6430 r:0.6102
ne_en Dev loss: 0.3504 r:0.7654
ru_en Dev loss: 0.4219 r:0.7418
Current avg r:0.6198 Best avg r: 0.6198
19:50:47,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:19,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:51,907 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3988
en_de Dev loss: 0.8508 r:0.2430
en_zh Dev loss: 0.7011 r:0.4890
ro_en Dev loss: 0.3952 r:0.7882
et_en Dev loss: 0.3918 r:0.6918
si_en Dev loss: 0.7064 r:0.6060
ne_en Dev loss: 0.4393 r:0.7661
ru_en Dev loss: 0.4204 r:0.7389
Current avg r:0.6176 Best avg r: 0.6198
19:58:27,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:59,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:01:31,357 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3880
en_de Dev loss: 0.8712 r:0.2348
en_zh Dev loss: 0.7806 r:0.4720
ro_en Dev loss: 0.4684 r:0.7701
et_en Dev loss: 0.4230 r:0.6761
si_en Dev loss: 0.7579 r:0.5868
ne_en Dev loss: 0.5020 r:0.7511
ru_en Dev loss: 0.5426 r:0.6889
Current avg r:0.5971 Best avg r: 0.6198
20:06:06,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:07:38,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:10,892 root INFO Epoch 2 Global steps: 30100 Train loss: 0.4154
en_de Dev loss: 0.8624 r:0.2192
en_zh Dev loss: 0.7231 r:0.4775
ro_en Dev loss: 0.4574 r:0.7790
et_en Dev loss: 0.4233 r:0.6736
si_en Dev loss: 0.8360 r:0.5819
ne_en Dev loss: 0.5524 r:0.7478
ru_en Dev loss: 0.5146 r:0.6943
Current avg r:0.5962 Best avg r: 0.6198
20:13:46,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:18,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:50,336 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3695
en_de Dev loss: 0.8404 r:0.2360
en_zh Dev loss: 0.6843 r:0.4841
ro_en Dev loss: 0.3929 r:0.7886
et_en Dev loss: 0.4268 r:0.6892
si_en Dev loss: 0.6598 r:0.6023
ne_en Dev loss: 0.3462 r:0.7636
ru_en Dev loss: 0.3960 r:0.7430
Current avg r:0.6153 Best avg r: 0.6198
20:21:25,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:39,40 root INFO 
id:en_de cur r: 0.2577 best r: 0.2577
20:22:58,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:30,515 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3895
en_de Dev loss: 0.8525 r:0.2405
en_zh Dev loss: 0.6991 r:0.4837
ro_en Dev loss: 0.4342 r:0.7844
et_en Dev loss: 0.4065 r:0.6807
si_en Dev loss: 0.7322 r:0.5917
ne_en Dev loss: 0.4221 r:0.7624
ru_en Dev loss: 0.4554 r:0.7211
Current avg r:0.6092 Best avg r: 0.6198
20:29:08,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:21,762 root INFO 
id:en_de cur r: 0.2663 best r: 0.2663
20:30:01,240 root INFO 
id:ro_en cur r: 0.7967 best r: 0.7967
20:30:53,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:25,948 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3434
en_de Dev loss: 0.8697 r:0.2564
en_zh Dev loss: 0.7424 r:0.4794
ro_en Dev loss: 0.4367 r:0.7903
et_en Dev loss: 0.4286 r:0.6795
si_en Dev loss: 0.7557 r:0.5932
ne_en Dev loss: 0.5002 r:0.7559
ru_en Dev loss: 0.4622 r:0.7254
Current avg r:0.6114 Best avg r: 0.6198
20:37:01,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:33,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:05,948 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3460
en_de Dev loss: 0.8562 r:0.2386
en_zh Dev loss: 0.7485 r:0.4770
ro_en Dev loss: 0.4313 r:0.7897
et_en Dev loss: 0.4505 r:0.6702
si_en Dev loss: 0.8897 r:0.5811
ne_en Dev loss: 0.5448 r:0.7485
ru_en Dev loss: 0.4912 r:0.7204
Current avg r:0.6036 Best avg r: 0.6198
20:44:41,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:13,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:45,490 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3568
en_de Dev loss: 0.8840 r:0.2375
en_zh Dev loss: 0.7772 r:0.4763
ro_en Dev loss: 0.4330 r:0.7929
et_en Dev loss: 0.4150 r:0.6833
si_en Dev loss: 0.6920 r:0.6056
ne_en Dev loss: 0.4817 r:0.7566
ru_en Dev loss: 0.4854 r:0.7280
Current avg r:0.6115 Best avg r: 0.6198
20:52:21,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:53,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:25,692 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3796
en_de Dev loss: 0.8501 r:0.2146
en_zh Dev loss: 0.6903 r:0.4893
ro_en Dev loss: 0.3996 r:0.7863
et_en Dev loss: 0.4154 r:0.6738
si_en Dev loss: 0.7742 r:0.5862
ne_en Dev loss: 0.4955 r:0.7545
ru_en Dev loss: 0.4287 r:0.7297
Current avg r:0.6049 Best avg r: 0.6198
21:00:01,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:28,124 root INFO 
id:en_zh cur r: 0.4956 best r: 0.4956
21:01:33,915 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:06,34 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3379
en_de Dev loss: 0.8416 r:0.2279
en_zh Dev loss: 0.6791 r:0.4945
ro_en Dev loss: 0.3818 r:0.7923
et_en Dev loss: 0.4092 r:0.6773
si_en Dev loss: 0.6475 r:0.6070
ne_en Dev loss: 0.4515 r:0.7555
ru_en Dev loss: 0.4336 r:0.7287
Current avg r:0.6119 Best avg r: 0.6198
21:07:42,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:14,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:46,364 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3377
en_de Dev loss: 0.8771 r:0.2063
en_zh Dev loss: 0.7522 r:0.4745
ro_en Dev loss: 0.4532 r:0.7841
et_en Dev loss: 0.4245 r:0.6753
si_en Dev loss: 0.7183 r:0.6041
ne_en Dev loss: 0.5860 r:0.7443
ru_en Dev loss: 0.5042 r:0.7105
Current avg r:0.5999 Best avg r: 0.6198
21:15:22,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:54,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:26,760 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3747
en_de Dev loss: 0.8709 r:0.2175
en_zh Dev loss: 0.7204 r:0.4803
ro_en Dev loss: 0.4379 r:0.7827
et_en Dev loss: 0.4463 r:0.6631
si_en Dev loss: 0.7088 r:0.5947
ne_en Dev loss: 0.4975 r:0.7455
ru_en Dev loss: 0.5144 r:0.6918
Current avg r:0.5965 Best avg r: 0.6198
21:23:02,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:35,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:07,116 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3535
en_de Dev loss: 0.8575 r:0.2142
en_zh Dev loss: 0.7599 r:0.4752
ro_en Dev loss: 0.4566 r:0.7851
et_en Dev loss: 0.4520 r:0.6628
si_en Dev loss: 0.8182 r:0.5832
ne_en Dev loss: 0.5572 r:0.7432
ru_en Dev loss: 0.5307 r:0.6906
Current avg r:0.5935 Best avg r: 0.6198
21:30:43,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:15,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:47,506 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3434
en_de Dev loss: 0.8758 r:0.2087
en_zh Dev loss: 0.7671 r:0.4826
ro_en Dev loss: 0.4374 r:0.7883
et_en Dev loss: 0.4775 r:0.6691
si_en Dev loss: 0.7148 r:0.5918
ne_en Dev loss: 0.4334 r:0.7517
ru_en Dev loss: 0.4806 r:0.7193
Current avg r:0.6016 Best avg r: 0.6198
21:38:23,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:55,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:27,604 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3633
en_de Dev loss: 0.8450 r:0.2371
en_zh Dev loss: 0.7118 r:0.4841
ro_en Dev loss: 0.4276 r:0.7863
et_en Dev loss: 0.4362 r:0.6788
si_en Dev loss: 0.6867 r:0.5919
ne_en Dev loss: 0.4378 r:0.7534
ru_en Dev loss: 0.4599 r:0.7175
Current avg r:0.6070 Best avg r: 0.6198
21:46:03,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:35,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:07,776 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3851
en_de Dev loss: 0.8824 r:0.2192
en_zh Dev loss: 0.7667 r:0.4680
ro_en Dev loss: 0.4417 r:0.7877
et_en Dev loss: 0.4522 r:0.6717
si_en Dev loss: 0.7227 r:0.5923
ne_en Dev loss: 0.4560 r:0.7589
ru_en Dev loss: 0.4958 r:0.7033
Current avg r:0.6002 Best avg r: 0.6198
21:53:43,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:16,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:48,112 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3645
en_de Dev loss: 0.8515 r:0.2285
en_zh Dev loss: 0.8144 r:0.4413
ro_en Dev loss: 0.4610 r:0.7885
et_en Dev loss: 0.4401 r:0.6792
si_en Dev loss: 0.8420 r:0.5815
ne_en Dev loss: 0.5348 r:0.7516
ru_en Dev loss: 0.4719 r:0.7197
Current avg r:0.5986 Best avg r: 0.6198
22:01:24,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:56,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:28,425 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3351
en_de Dev loss: 0.8613 r:0.2468
en_zh Dev loss: 0.7749 r:0.4474
ro_en Dev loss: 0.4595 r:0.7872
et_en Dev loss: 0.4379 r:0.6768
si_en Dev loss: 0.8872 r:0.5809
ne_en Dev loss: 0.5378 r:0.7583
ru_en Dev loss: 0.4701 r:0.7257
Current avg r:0.6033 Best avg r: 0.6198
22:09:04,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:36,711 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:08,774 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3350
en_de Dev loss: 0.8452 r:0.2289
en_zh Dev loss: 0.7548 r:0.4537
ro_en Dev loss: 0.4453 r:0.7862
et_en Dev loss: 0.4416 r:0.6799
si_en Dev loss: 0.8312 r:0.5823
ne_en Dev loss: 0.5800 r:0.7483
ru_en Dev loss: 0.4886 r:0.7004
Current avg r:0.5971 Best avg r: 0.6198
22:16:44,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:16,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:48,712 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3252
en_de Dev loss: 0.8601 r:0.2220
en_zh Dev loss: 0.7951 r:0.4477
ro_en Dev loss: 0.4483 r:0.7858
et_en Dev loss: 0.4278 r:0.6829
si_en Dev loss: 0.7651 r:0.5868
ne_en Dev loss: 0.4486 r:0.7540
ru_en Dev loss: 0.5171 r:0.6997
Current avg r:0.5970 Best avg r: 0.6198
22:24:25,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:57,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:29,763 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2895
en_de Dev loss: 0.8657 r:0.2165
en_zh Dev loss: 0.7625 r:0.4574
ro_en Dev loss: 0.4326 r:0.7823
et_en Dev loss: 0.4486 r:0.6839
si_en Dev loss: 0.7008 r:0.5928
ne_en Dev loss: 0.4950 r:0.7451
ru_en Dev loss: 0.4979 r:0.7094
Current avg r:0.5982 Best avg r: 0.6198
22:32:05,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:37,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:09,411 root INFO Epoch 4 Global steps: 43400 Train loss: 0.3014
en_de Dev loss: 0.8514 r:0.2255
en_zh Dev loss: 0.7750 r:0.4502
ro_en Dev loss: 0.4226 r:0.7847
et_en Dev loss: 0.4617 r:0.6742
si_en Dev loss: 0.7168 r:0.5892
ne_en Dev loss: 0.4104 r:0.7472
ru_en Dev loss: 0.4825 r:0.7105
Current avg r:0.5974 Best avg r: 0.6198
22:39:45,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:39:58,289 root INFO 
id:en_de cur r: 0.2895 best r: 0.2895
22:41:17,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:49,275 root INFO Epoch 4 Global steps: 44100 Train loss: 0.3051
en_de Dev loss: 0.8478 r:0.2683
en_zh Dev loss: 0.8168 r:0.4375
ro_en Dev loss: 0.4391 r:0.7863
et_en Dev loss: 0.4722 r:0.6552
si_en Dev loss: 0.8501 r:0.5602
ne_en Dev loss: 0.5299 r:0.7410
ru_en Dev loss: 0.4764 r:0.7113
Current avg r:0.5942 Best avg r: 0.6198
22:47:25,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:38,520 root INFO 
id:en_de cur r: 0.3066 best r: 0.3066
22:48:57,405 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:29,466 root INFO Epoch 4 Global steps: 44800 Train loss: 0.3071
en_de Dev loss: 0.8276 r:0.2802
en_zh Dev loss: 0.8090 r:0.4553
ro_en Dev loss: 0.4212 r:0.7895
et_en Dev loss: 0.4675 r:0.6720
si_en Dev loss: 0.8441 r:0.5777
ne_en Dev loss: 0.5320 r:0.7456
ru_en Dev loss: 0.4778 r:0.7225
Current avg r:0.6061 Best avg r: 0.6198
22:55:05,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:37,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:09,637 root INFO Epoch 4 Global steps: 45500 Train loss: 0.3203
en_de Dev loss: 0.8809 r:0.2267
en_zh Dev loss: 0.8393 r:0.4449
ro_en Dev loss: 0.4584 r:0.7778
et_en Dev loss: 0.4675 r:0.6564
si_en Dev loss: 0.8135 r:0.5675
ne_en Dev loss: 0.5115 r:0.7396
ru_en Dev loss: 0.5427 r:0.6893
Current avg r:0.5860 Best avg r: 0.6198
23:02:45,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:17,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:49,269 root INFO Epoch 4 Global steps: 46200 Train loss: 0.3190
en_de Dev loss: 0.8529 r:0.2255
en_zh Dev loss: 0.7701 r:0.4629
ro_en Dev loss: 0.4293 r:0.7865
et_en Dev loss: 0.4648 r:0.6718
si_en Dev loss: 0.7781 r:0.5838
ne_en Dev loss: 0.4523 r:0.7495
ru_en Dev loss: 0.4493 r:0.7225
Current avg r:0.6003 Best avg r: 0.6198
23:10:25,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:57,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:29,404 root INFO Epoch 4 Global steps: 46900 Train loss: 0.3043
en_de Dev loss: 0.8587 r:0.2305
en_zh Dev loss: 0.8007 r:0.4612
ro_en Dev loss: 0.4511 r:0.7845
et_en Dev loss: 0.4534 r:0.6596
si_en Dev loss: 0.8958 r:0.5709
ne_en Dev loss: 0.5227 r:0.7492
ru_en Dev loss: 0.4759 r:0.7173
Current avg r:0.5962 Best avg r: 0.6198
23:18:05,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:37,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:21:09,514 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2868
en_de Dev loss: 0.8569 r:0.2370
en_zh Dev loss: 0.7741 r:0.4571
ro_en Dev loss: 0.4607 r:0.7802
et_en Dev loss: 0.4712 r:0.6507
si_en Dev loss: 0.8555 r:0.5695
ne_en Dev loss: 0.5451 r:0.7399
ru_en Dev loss: 0.4902 r:0.7084
Current avg r:0.5918 Best avg r: 0.6198
23:25:45,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:27:17,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:28:49,697 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2961
en_de Dev loss: 0.8472 r:0.2402
en_zh Dev loss: 0.7814 r:0.4632
ro_en Dev loss: 0.4741 r:0.7868
et_en Dev loss: 0.4890 r:0.6594
si_en Dev loss: 0.9136 r:0.5745
ne_en Dev loss: 0.5384 r:0.7448
ru_en Dev loss: 0.4880 r:0.7151
Current avg r:0.5977 Best avg r: 0.6198
23:33:25,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:34:57,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:29,745 root INFO Epoch 4 Global steps: 49000 Train loss: 0.3071
en_de Dev loss: 0.8985 r:0.2302
en_zh Dev loss: 0.8103 r:0.4523
ro_en Dev loss: 0.4784 r:0.7895
et_en Dev loss: 0.4605 r:0.6641
si_en Dev loss: 0.8347 r:0.5775
ne_en Dev loss: 0.5626 r:0.7466
ru_en Dev loss: 0.5177 r:0.7122
Current avg r:0.5960 Best avg r: 0.6198
23:41:06,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:58,742 root INFO 
id:ro_en cur r: 0.7973 best r: 0.7973
23:42:51,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:23,440 root INFO Epoch 4 Global steps: 49700 Train loss: 0.3011
en_de Dev loss: 0.8528 r:0.2229
en_zh Dev loss: 0.7431 r:0.4610
ro_en Dev loss: 0.4142 r:0.7926
et_en Dev loss: 0.4551 r:0.6685
si_en Dev loss: 0.7981 r:0.5824
ne_en Dev loss: 0.4970 r:0.7535
ru_en Dev loss: 0.4765 r:0.7052
Current avg r:0.5980 Best avg r: 0.6198
23:48:59,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:31,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:03,809 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2823
en_de Dev loss: 0.8706 r:0.2289
en_zh Dev loss: 0.7911 r:0.4449
ro_en Dev loss: 0.4503 r:0.7887
et_en Dev loss: 0.4767 r:0.6587
si_en Dev loss: 0.8841 r:0.5697
ne_en Dev loss: 0.5373 r:0.7506
ru_en Dev loss: 0.4966 r:0.6961
Current avg r:0.5911 Best avg r: 0.6198
23:56:40,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:12,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:44,65 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2935
en_de Dev loss: 0.8659 r:0.2083
en_zh Dev loss: 0.8232 r:0.4436
ro_en Dev loss: 0.4703 r:0.7864
et_en Dev loss: 0.4742 r:0.6536
si_en Dev loss: 0.9313 r:0.5639
ne_en Dev loss: 0.6093 r:0.7382
ru_en Dev loss: 0.5429 r:0.6884
Current avg r:0.5832 Best avg r: 0.6198
00:04:20,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:52,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:24,360 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2964
en_de Dev loss: 0.8633 r:0.2024
en_zh Dev loss: 0.7429 r:0.4490
ro_en Dev loss: 0.4024 r:0.7858
et_en Dev loss: 0.4494 r:0.6542
si_en Dev loss: 0.7177 r:0.5728
ne_en Dev loss: 0.4596 r:0.7446
ru_en Dev loss: 0.4729 r:0.7020
Current avg r:0.5873 Best avg r: 0.6198
00:12:00,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:33,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:05,507 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2885
en_de Dev loss: 0.8610 r:0.2267
en_zh Dev loss: 0.8057 r:0.4499
ro_en Dev loss: 0.4786 r:0.7913
et_en Dev loss: 0.4813 r:0.6643
si_en Dev loss: 0.8572 r:0.5709
ne_en Dev loss: 0.4931 r:0.7539
ru_en Dev loss: 0.5112 r:0.7161
Current avg r:0.5962 Best avg r: 0.6198
00:19:43,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:21:15,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:47,572 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2507
en_de Dev loss: 0.8724 r:0.2286
en_zh Dev loss: 0.8459 r:0.4443
ro_en Dev loss: 0.4720 r:0.7911
et_en Dev loss: 0.4871 r:0.6509
si_en Dev loss: 0.8777 r:0.5644
ne_en Dev loss: 0.5789 r:0.7454
ru_en Dev loss: 0.5574 r:0.6915
Current avg r:0.5880 Best avg r: 0.6198
00:27:23,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:55,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:27,775 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2453
en_de Dev loss: 0.8586 r:0.2367
en_zh Dev loss: 0.7890 r:0.4475
ro_en Dev loss: 0.4156 r:0.7946
et_en Dev loss: 0.4856 r:0.6647
si_en Dev loss: 0.8245 r:0.5698
ne_en Dev loss: 0.4959 r:0.7452
ru_en Dev loss: 0.4661 r:0.7210
Current avg r:0.5971 Best avg r: 0.6198
00:35:03,891 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:35,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:07,901 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2616
en_de Dev loss: 0.8693 r:0.2232
en_zh Dev loss: 0.7696 r:0.4602
ro_en Dev loss: 0.4490 r:0.7869
et_en Dev loss: 0.4737 r:0.6521
si_en Dev loss: 0.8324 r:0.5660
ne_en Dev loss: 0.5791 r:0.7423
ru_en Dev loss: 0.5041 r:0.6981
Current avg r:0.5898 Best avg r: 0.6198
00:42:43,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:16,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:47,960 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2642
en_de Dev loss: 0.8528 r:0.2024
en_zh Dev loss: 0.7343 r:0.4642
ro_en Dev loss: 0.4035 r:0.7896
et_en Dev loss: 0.4611 r:0.6591
si_en Dev loss: 0.8243 r:0.5666
ne_en Dev loss: 0.5123 r:0.7433
ru_en Dev loss: 0.4594 r:0.7168
Current avg r:0.5917 Best avg r: 0.6198
00:50:24,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:56,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:53:28,82 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2540
en_de Dev loss: 0.8629 r:0.2169
en_zh Dev loss: 0.7551 r:0.4667
ro_en Dev loss: 0.4039 r:0.7901
et_en Dev loss: 0.4943 r:0.6587
si_en Dev loss: 0.7623 r:0.5710
ne_en Dev loss: 0.4632 r:0.7410
ru_en Dev loss: 0.4672 r:0.7148
Current avg r:0.5942 Best avg r: 0.6198
00:58:04,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:59:36,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:08,265 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2533
en_de Dev loss: 0.8626 r:0.2215
en_zh Dev loss: 0.8169 r:0.4456
ro_en Dev loss: 0.4172 r:0.7910
et_en Dev loss: 0.5191 r:0.6576
si_en Dev loss: 0.8293 r:0.5687
ne_en Dev loss: 0.4989 r:0.7414
ru_en Dev loss: 0.4948 r:0.7013
Current avg r:0.5896 Best avg r: 0.6198
01:05:44,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:16,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:48,333 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2680
en_de Dev loss: 0.8906 r:0.1963
en_zh Dev loss: 0.7937 r:0.4566
ro_en Dev loss: 0.4202 r:0.7926
et_en Dev loss: 0.4789 r:0.6535
si_en Dev loss: 0.8266 r:0.5638
ne_en Dev loss: 0.6054 r:0.7378
ru_en Dev loss: 0.5351 r:0.6862
Current avg r:0.5838 Best avg r: 0.6198
01:13:24,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:56,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:28,396 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2436
en_de Dev loss: 0.8848 r:0.2067
en_zh Dev loss: 0.7922 r:0.4514
ro_en Dev loss: 0.4082 r:0.7948
et_en Dev loss: 0.4889 r:0.6561
si_en Dev loss: 0.7716 r:0.5665
ne_en Dev loss: 0.4676 r:0.7391
ru_en Dev loss: 0.4981 r:0.7003
Current avg r:0.5879 Best avg r: 0.6198
01:21:04,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:22:36,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:08,472 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2578
en_de Dev loss: 0.8753 r:0.1998
en_zh Dev loss: 0.7945 r:0.4563
ro_en Dev loss: 0.4322 r:0.7911
et_en Dev loss: 0.5127 r:0.6517
si_en Dev loss: 0.8472 r:0.5569
ne_en Dev loss: 0.5258 r:0.7384
ru_en Dev loss: 0.4519 r:0.7243
Current avg r:0.5884 Best avg r: 0.6198
01:28:44,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:16,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:31:48,721 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2462
en_de Dev loss: 0.8791 r:0.1968
en_zh Dev loss: 0.7979 r:0.4501
ro_en Dev loss: 0.4243 r:0.7946
et_en Dev loss: 0.4783 r:0.6581
si_en Dev loss: 0.8383 r:0.5641
ne_en Dev loss: 0.5496 r:0.7418
ru_en Dev loss: 0.4944 r:0.7127
Current avg r:0.5883 Best avg r: 0.6198
01:36:24,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:37:56,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:28,863 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2610
en_de Dev loss: 0.8741 r:0.2109
en_zh Dev loss: 0.8412 r:0.4499
ro_en Dev loss: 0.4603 r:0.7849
et_en Dev loss: 0.5493 r:0.6493
si_en Dev loss: 0.9026 r:0.5539
ne_en Dev loss: 0.5660 r:0.7393
ru_en Dev loss: 0.5319 r:0.6988
Current avg r:0.5839 Best avg r: 0.6198
01:44:04,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:45:36,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:47:08,733 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2573
en_de Dev loss: 0.8662 r:0.2260
en_zh Dev loss: 0.8072 r:0.4746
ro_en Dev loss: 0.4468 r:0.7914
et_en Dev loss: 0.5356 r:0.6598
si_en Dev loss: 0.8774 r:0.5696
ne_en Dev loss: 0.5159 r:0.7471
ru_en Dev loss: 0.4793 r:0.7266
Current avg r:0.5993 Best avg r: 0.6198
01:51:44,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:53:16,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:54:48,665 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2433
en_de Dev loss: 0.8935 r:0.2047
en_zh Dev loss: 0.8523 r:0.4564
ro_en Dev loss: 0.4640 r:0.7921
et_en Dev loss: 0.4810 r:0.6561
si_en Dev loss: 0.7863 r:0.5747
ne_en Dev loss: 0.4782 r:0.7473
ru_en Dev loss: 0.5559 r:0.6928
Current avg r:0.5892 Best avg r: 0.6198
01:59:24,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:00:56,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:02:28,603 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2432
en_de Dev loss: 0.8553 r:0.2269
en_zh Dev loss: 0.7926 r:0.4399
ro_en Dev loss: 0.4053 r:0.7858
et_en Dev loss: 0.4691 r:0.6422
si_en Dev loss: 0.8323 r:0.5574
ne_en Dev loss: 0.5403 r:0.7416
ru_en Dev loss: 0.4989 r:0.6935
Current avg r:0.5839 Best avg r: 0.6198
02:07:04,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:08:37,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:09,392 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2542
en_de Dev loss: 0.8559 r:0.2432
en_zh Dev loss: 0.7993 r:0.4596
ro_en Dev loss: 0.4614 r:0.7934
et_en Dev loss: 0.4684 r:0.6572
si_en Dev loss: 0.9231 r:0.5610
ne_en Dev loss: 0.6069 r:0.7422
ru_en Dev loss: 0.5329 r:0.7007
Current avg r:0.5939 Best avg r: 0.6198
02:14:47,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:15:39,854 root INFO 
id:ro_en cur r: 0.7989 best r: 0.7989
02:16:32,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:18:04,537 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2344
en_de Dev loss: 0.8561 r:0.2373
en_zh Dev loss: 0.7889 r:0.4601
ro_en Dev loss: 0.3908 r:0.7982
et_en Dev loss: 0.5223 r:0.6578
si_en Dev loss: 0.7890 r:0.5613
ne_en Dev loss: 0.4729 r:0.7416
ru_en Dev loss: 0.4420 r:0.7233
Current avg r:0.5971 Best avg r: 0.6198
02:22:40,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:12,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:44,817 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2236
en_de Dev loss: 0.8817 r:0.2195
en_zh Dev loss: 0.8122 r:0.4602
ro_en Dev loss: 0.4194 r:0.7936
et_en Dev loss: 0.5384 r:0.6602
si_en Dev loss: 0.7685 r:0.5717
ne_en Dev loss: 0.4840 r:0.7347
ru_en Dev loss: 0.4765 r:0.7176
Current avg r:0.5939 Best avg r: 0.6198
02:30:21,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:53,122 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:33:25,67 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2114
en_de Dev loss: 0.9115 r:0.2024
en_zh Dev loss: 0.8683 r:0.4379
ro_en Dev loss: 0.4824 r:0.7846
et_en Dev loss: 0.5128 r:0.6462
si_en Dev loss: 0.8980 r:0.5522
ne_en Dev loss: 0.5654 r:0.7341
ru_en Dev loss: 0.4976 r:0.7163
Current avg r:0.5820 Best avg r: 0.6198
02:38:01,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:38:53,943 root INFO 
id:ro_en cur r: 0.7989 best r: 0.7989
02:39:46,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:41:18,455 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2153
en_de Dev loss: 0.8967 r:0.2086
en_zh Dev loss: 0.8112 r:0.4537
ro_en Dev loss: 0.4696 r:0.7961
et_en Dev loss: 0.5196 r:0.6486
si_en Dev loss: 0.9346 r:0.5565
ne_en Dev loss: 0.6027 r:0.7322
ru_en Dev loss: 0.5070 r:0.7188
Current avg r:0.5878 Best avg r: 0.6198
02:45:54,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:47:26,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:48:57,958 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2131
en_de Dev loss: 0.8872 r:0.2012
en_zh Dev loss: 0.8293 r:0.4427
ro_en Dev loss: 0.4274 r:0.7938
et_en Dev loss: 0.4881 r:0.6485
si_en Dev loss: 0.9164 r:0.5548
ne_en Dev loss: 0.5323 r:0.7393
ru_en Dev loss: 0.4700 r:0.7282
Current avg r:0.5869 Best avg r: 0.6198
02:53:33,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:55:05,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:56:37,488 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2187
en_de Dev loss: 0.8869 r:0.2331
en_zh Dev loss: 0.8145 r:0.4491
ro_en Dev loss: 0.4204 r:0.7878
et_en Dev loss: 0.5158 r:0.6484
si_en Dev loss: 0.8485 r:0.5576
ne_en Dev loss: 0.4777 r:0.7401
ru_en Dev loss: 0.4966 r:0.7197
Current avg r:0.5908 Best avg r: 0.6198
03:01:13,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:02:45,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:16,979 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2211
en_de Dev loss: 0.8698 r:0.2216
en_zh Dev loss: 0.7561 r:0.4607
ro_en Dev loss: 0.3994 r:0.7918
et_en Dev loss: 0.4964 r:0.6511
si_en Dev loss: 0.7920 r:0.5614
ne_en Dev loss: 0.4609 r:0.7337
ru_en Dev loss: 0.4989 r:0.7051
Current avg r:0.5893 Best avg r: 0.6198
03:08:52,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:24,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:56,488 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2293
en_de Dev loss: 0.8713 r:0.2410
en_zh Dev loss: 0.7819 r:0.4671
ro_en Dev loss: 0.4009 r:0.7949
et_en Dev loss: 0.5206 r:0.6461
si_en Dev loss: 0.8679 r:0.5502
ne_en Dev loss: 0.5037 r:0.7337
ru_en Dev loss: 0.4670 r:0.7161
Current avg r:0.5927 Best avg r: 0.6198
03:16:32,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:18:04,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:36,183 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2117
en_de Dev loss: 0.8797 r:0.2169
en_zh Dev loss: 0.7999 r:0.4654
ro_en Dev loss: 0.4198 r:0.7965
et_en Dev loss: 0.5148 r:0.6439
si_en Dev loss: 0.9005 r:0.5496
ne_en Dev loss: 0.5233 r:0.7360
ru_en Dev loss: 0.4919 r:0.7168
Current avg r:0.5893 Best avg r: 0.6198
03:24:11,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:25:43,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:27:15,879 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2177
en_de Dev loss: 0.8645 r:0.2012
en_zh Dev loss: 0.7529 r:0.4587
ro_en Dev loss: 0.3674 r:0.7966
et_en Dev loss: 0.4772 r:0.6553
si_en Dev loss: 0.7431 r:0.5654
ne_en Dev loss: 0.4353 r:0.7433
ru_en Dev loss: 0.4541 r:0.7224
Current avg r:0.5918 Best avg r: 0.6198
03:31:51,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:33:23,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:34:55,383 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2058
en_de Dev loss: 0.8769 r:0.2120
en_zh Dev loss: 0.8040 r:0.4670
ro_en Dev loss: 0.4135 r:0.7953
et_en Dev loss: 0.4961 r:0.6549
si_en Dev loss: 0.8147 r:0.5657
ne_en Dev loss: 0.5030 r:0.7389
ru_en Dev loss: 0.4642 r:0.7289
Current avg r:0.5947 Best avg r: 0.6198
03:39:31,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:41:03,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:42:35,689 root INFO Epoch 6 Global steps: 71400 Train loss: 0.2051
en_de Dev loss: 0.9305 r:0.2021
en_zh Dev loss: 0.8943 r:0.4583
ro_en Dev loss: 0.5340 r:0.7859
et_en Dev loss: 0.5371 r:0.6412
si_en Dev loss: 1.0926 r:0.5483
ne_en Dev loss: 0.7257 r:0.7304
ru_en Dev loss: 0.5775 r:0.7050
Current avg r:0.5816 Best avg r: 0.6198
03:47:11,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:48:43,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:50:15,185 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2136
en_de Dev loss: 0.8939 r:0.2140
en_zh Dev loss: 0.7864 r:0.4650
ro_en Dev loss: 0.4267 r:0.7908
et_en Dev loss: 0.5034 r:0.6527
si_en Dev loss: 0.8896 r:0.5550
ne_en Dev loss: 0.5553 r:0.7340
ru_en Dev loss: 0.4449 r:0.7366
Current avg r:0.5926 Best avg r: 0.6198
03:54:50,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:56:22,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:57:54,842 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2141
en_de Dev loss: 0.8823 r:0.2248
en_zh Dev loss: 0.7951 r:0.4654
ro_en Dev loss: 0.4423 r:0.7878
et_en Dev loss: 0.4828 r:0.6458
si_en Dev loss: 0.8880 r:0.5536
ne_en Dev loss: 0.5611 r:0.7418
ru_en Dev loss: 0.4865 r:0.7199
Current avg r:0.5913 Best avg r: 0.6198
04:02:31,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:03,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:05:35,654 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2184
en_de Dev loss: 0.8700 r:0.1984
en_zh Dev loss: 0.8037 r:0.4426
ro_en Dev loss: 0.4302 r:0.7878
et_en Dev loss: 0.4512 r:0.6579
si_en Dev loss: 0.8271 r:0.5619
ne_en Dev loss: 0.5300 r:0.7356
ru_en Dev loss: 0.4877 r:0.7152
Current avg r:0.5856 Best avg r: 0.6198
04:10:13,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:11:45,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:13:17,687 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1893
en_de Dev loss: 0.8803 r:0.2188
en_zh Dev loss: 0.8427 r:0.4626
ro_en Dev loss: 0.4761 r:0.7952
et_en Dev loss: 0.5083 r:0.6483
si_en Dev loss: 0.9310 r:0.5532
ne_en Dev loss: 0.6259 r:0.7282
ru_en Dev loss: 0.5134 r:0.7213
Current avg r:0.5897 Best avg r: 0.6198
04:17:53,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:19:25,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:20:57,472 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1942
en_de Dev loss: 0.8967 r:0.2172
en_zh Dev loss: 0.8592 r:0.4494
ro_en Dev loss: 0.4610 r:0.7946
et_en Dev loss: 0.5198 r:0.6501
si_en Dev loss: 0.9024 r:0.5573
ne_en Dev loss: 0.6089 r:0.7333
ru_en Dev loss: 0.4962 r:0.7218
Current avg r:0.5891 Best avg r: 0.6198
04:25:33,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:27:05,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:28:37,446 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1898
en_de Dev loss: 0.8716 r:0.2201
en_zh Dev loss: 0.8275 r:0.4545
ro_en Dev loss: 0.4400 r:0.7936
et_en Dev loss: 0.5097 r:0.6528
si_en Dev loss: 0.9193 r:0.5481
ne_en Dev loss: 0.5935 r:0.7249
ru_en Dev loss: 0.4903 r:0.7104
Current avg r:0.5864 Best avg r: 0.6198
04:33:13,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:34:45,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:36:17,647 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1880
en_de Dev loss: 0.8771 r:0.2135
en_zh Dev loss: 0.8628 r:0.4438
ro_en Dev loss: 0.4679 r:0.7915
et_en Dev loss: 0.4994 r:0.6446
si_en Dev loss: 1.0127 r:0.5328
ne_en Dev loss: 0.7183 r:0.7194
ru_en Dev loss: 0.5211 r:0.7024
Current avg r:0.5783 Best avg r: 0.6198
04:40:53,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:42:25,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:43:57,789 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1898
en_de Dev loss: 0.8773 r:0.2078
en_zh Dev loss: 0.7830 r:0.4646
ro_en Dev loss: 0.3909 r:0.7963
et_en Dev loss: 0.4874 r:0.6566
si_en Dev loss: 0.8635 r:0.5503
ne_en Dev loss: 0.5298 r:0.7242
ru_en Dev loss: 0.4939 r:0.7096
Current avg r:0.5870 Best avg r: 0.6198
04:48:33,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:05,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:37,332 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1940
en_de Dev loss: 0.8748 r:0.2092
en_zh Dev loss: 0.8132 r:0.4629
ro_en Dev loss: 0.4372 r:0.7884
et_en Dev loss: 0.4893 r:0.6408
si_en Dev loss: 0.9888 r:0.5270
ne_en Dev loss: 0.6159 r:0.7204
ru_en Dev loss: 0.5123 r:0.6995
Current avg r:0.5783 Best avg r: 0.6198
04:56:12,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:44,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:59:17,42 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1834
en_de Dev loss: 0.8792 r:0.2171
en_zh Dev loss: 0.8081 r:0.4651
ro_en Dev loss: 0.4071 r:0.7949
et_en Dev loss: 0.5020 r:0.6501
si_en Dev loss: 0.8283 r:0.5487
ne_en Dev loss: 0.5199 r:0.7246
ru_en Dev loss: 0.5068 r:0.7014
Current avg r:0.5860 Best avg r: 0.6198
05:03:52,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:05:24,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:06:56,820 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1927
en_de Dev loss: 0.8978 r:0.2282
en_zh Dev loss: 0.7954 r:0.4712
ro_en Dev loss: 0.4179 r:0.7907
et_en Dev loss: 0.5013 r:0.6458
si_en Dev loss: 0.8361 r:0.5451
ne_en Dev loss: 0.5508 r:0.7273
ru_en Dev loss: 0.4819 r:0.7174
Current avg r:0.5894 Best avg r: 0.6198
05:11:32,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:13:05,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:14:37,143 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1870
en_de Dev loss: 0.8888 r:0.2108
en_zh Dev loss: 0.7802 r:0.4590
ro_en Dev loss: 0.4475 r:0.7878
et_en Dev loss: 0.4824 r:0.6487
si_en Dev loss: 0.8960 r:0.5459
ne_en Dev loss: 0.6114 r:0.7231
ru_en Dev loss: 0.4957 r:0.7090
Current avg r:0.5835 Best avg r: 0.6198
05:19:13,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:45,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:22:17,640 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1801
en_de Dev loss: 0.9004 r:0.2027
en_zh Dev loss: 0.7708 r:0.4576
ro_en Dev loss: 0.3980 r:0.7891
et_en Dev loss: 0.5047 r:0.6559
si_en Dev loss: 0.7667 r:0.5602
ne_en Dev loss: 0.5205 r:0.7261
ru_en Dev loss: 0.4428 r:0.7315
Current avg r:0.5890 Best avg r: 0.6198
05:26:54,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:26,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:29:58,148 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1865
en_de Dev loss: 0.8953 r:0.1881
en_zh Dev loss: 0.8048 r:0.4474
ro_en Dev loss: 0.4180 r:0.7872
et_en Dev loss: 0.4805 r:0.6508
si_en Dev loss: 0.8611 r:0.5422
ne_en Dev loss: 0.5228 r:0.7199
ru_en Dev loss: 0.5084 r:0.7017
Current avg r:0.5767 Best avg r: 0.6198
05:34:34,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:06,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:37:38,608 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1837
en_de Dev loss: 0.9117 r:0.2082
en_zh Dev loss: 0.8552 r:0.4530
ro_en Dev loss: 0.4250 r:0.7889
et_en Dev loss: 0.5063 r:0.6485
si_en Dev loss: 0.8747 r:0.5471
ne_en Dev loss: 0.5819 r:0.7261
ru_en Dev loss: 0.4977 r:0.7158
Current avg r:0.5840 Best avg r: 0.6198
05:42:15,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:47,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:19,384 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1735
en_de Dev loss: 0.8788 r:0.2096
en_zh Dev loss: 0.8256 r:0.4514
ro_en Dev loss: 0.4244 r:0.7884
et_en Dev loss: 0.4997 r:0.6504
si_en Dev loss: 0.9258 r:0.5414
ne_en Dev loss: 0.5431 r:0.7355
ru_en Dev loss: 0.4994 r:0.7127
Current avg r:0.5842 Best avg r: 0.6198
05:49:55,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:27,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:00,228 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1818
en_de Dev loss: 0.8846 r:0.2345
en_zh Dev loss: 0.7913 r:0.4608
ro_en Dev loss: 0.4255 r:0.7910
et_en Dev loss: 0.4789 r:0.6536
si_en Dev loss: 0.8839 r:0.5456
ne_en Dev loss: 0.5279 r:0.7329
ru_en Dev loss: 0.4795 r:0.7260
Current avg r:0.5921 Best avg r: 0.6198
05:57:37,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:09,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:00:41,530 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1846
en_de Dev loss: 0.8671 r:0.2337
en_zh Dev loss: 0.7930 r:0.4554
ro_en Dev loss: 0.3858 r:0.7957
et_en Dev loss: 0.5005 r:0.6545
si_en Dev loss: 0.8350 r:0.5445
ne_en Dev loss: 0.4759 r:0.7294
ru_en Dev loss: 0.4582 r:0.7250
Current avg r:0.5912 Best avg r: 0.6198
06:05:19,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:06:51,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:23,648 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1543
en_de Dev loss: 0.8858 r:0.2024
en_zh Dev loss: 0.7829 r:0.4481
ro_en Dev loss: 0.3991 r:0.7976
et_en Dev loss: 0.4774 r:0.6565
si_en Dev loss: 0.8789 r:0.5389
ne_en Dev loss: 0.5190 r:0.7297
ru_en Dev loss: 0.4644 r:0.7219
Current avg r:0.5850 Best avg r: 0.6198
06:13:00,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:32,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:16:04,409 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1628
en_de Dev loss: 0.8902 r:0.2021
en_zh Dev loss: 0.8112 r:0.4516
ro_en Dev loss: 0.4202 r:0.7941
et_en Dev loss: 0.5084 r:0.6470
si_en Dev loss: 0.8962 r:0.5377
ne_en Dev loss: 0.5604 r:0.7294
ru_en Dev loss: 0.4827 r:0.7225
Current avg r:0.5835 Best avg r: 0.6198
06:20:40,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:22:13,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:45,153 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1679
en_de Dev loss: 0.9051 r:0.2075
en_zh Dev loss: 0.7998 r:0.4639
ro_en Dev loss: 0.4105 r:0.7940
et_en Dev loss: 0.5269 r:0.6498
si_en Dev loss: 0.8997 r:0.5323
ne_en Dev loss: 0.5760 r:0.7232
ru_en Dev loss: 0.4932 r:0.7169
Current avg r:0.5839 Best avg r: 0.6198
06:28:21,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:53,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:26,43 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1715
en_de Dev loss: 0.8885 r:0.2094
en_zh Dev loss: 0.8451 r:0.4637
ro_en Dev loss: 0.4477 r:0.7938
et_en Dev loss: 0.4813 r:0.6586
si_en Dev loss: 0.9317 r:0.5361
ne_en Dev loss: 0.6251 r:0.7308
ru_en Dev loss: 0.5192 r:0.7134
Current avg r:0.5865 Best avg r: 0.6198
06:36:02,434 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:34,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:06,749 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1675
en_de Dev loss: 0.8652 r:0.2175
en_zh Dev loss: 0.8412 r:0.4635
ro_en Dev loss: 0.4465 r:0.7929
et_en Dev loss: 0.5145 r:0.6476
si_en Dev loss: 1.0102 r:0.5316
ne_en Dev loss: 0.6065 r:0.7302
ru_en Dev loss: 0.5092 r:0.7132
Current avg r:0.5852 Best avg r: 0.6198
06:43:42,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:15,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:47,394 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1620
en_de Dev loss: 0.9069 r:0.1875
en_zh Dev loss: 0.7785 r:0.4620
ro_en Dev loss: 0.3688 r:0.7980
et_en Dev loss: 0.4710 r:0.6610
si_en Dev loss: 0.8030 r:0.5512
ne_en Dev loss: 0.5042 r:0.7321
ru_en Dev loss: 0.4595 r:0.7217
Current avg r:0.5876 Best avg r: 0.6198
06:51:23,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:55,913 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:54:28,75 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1608
en_de Dev loss: 0.9040 r:0.2119
en_zh Dev loss: 0.8186 r:0.4517
ro_en Dev loss: 0.3995 r:0.7926
et_en Dev loss: 0.4838 r:0.6533
si_en Dev loss: 0.8857 r:0.5423
ne_en Dev loss: 0.5248 r:0.7332
ru_en Dev loss: 0.4890 r:0.7105
Current avg r:0.5851 Best avg r: 0.6198
06:59:04,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:36,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:08,737 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1626
en_de Dev loss: 0.9632 r:0.1850
en_zh Dev loss: 0.8751 r:0.4463
ro_en Dev loss: 0.4602 r:0.7904
et_en Dev loss: 0.5340 r:0.6373
si_en Dev loss: 1.0188 r:0.5337
ne_en Dev loss: 0.7268 r:0.7239
ru_en Dev loss: 0.5316 r:0.7006
Current avg r:0.5739 Best avg r: 0.6198
07:06:45,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:17,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:09:49,342 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1664
en_de Dev loss: 0.9439 r:0.1990
en_zh Dev loss: 0.7678 r:0.4692
ro_en Dev loss: 0.3816 r:0.7945
et_en Dev loss: 0.4637 r:0.6618
si_en Dev loss: 0.8131 r:0.5516
ne_en Dev loss: 0.4750 r:0.7286
ru_en Dev loss: 0.4563 r:0.7262
Current avg r:0.5901 Best avg r: 0.6198
07:14:25,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:15:57,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:29,815 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1813
en_de Dev loss: 0.9869 r:0.2010
en_zh Dev loss: 0.8619 r:0.4622
ro_en Dev loss: 0.4700 r:0.7953
et_en Dev loss: 0.4889 r:0.6545
si_en Dev loss: 0.9844 r:0.5332
ne_en Dev loss: 0.7037 r:0.7163
ru_en Dev loss: 0.5584 r:0.7085
Current avg r:0.5816 Best avg r: 0.6198
07:22:06,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:23:38,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:25:10,392 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1748
en_de Dev loss: 0.9098 r:0.2100
en_zh Dev loss: 0.8009 r:0.4588
ro_en Dev loss: 0.4311 r:0.7938
et_en Dev loss: 0.5163 r:0.6493
si_en Dev loss: 0.9591 r:0.5318
ne_en Dev loss: 0.6015 r:0.7219
ru_en Dev loss: 0.4873 r:0.7214
Current avg r:0.5839 Best avg r: 0.6198
07:29:46,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:31:18,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:51,99 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1697
en_de Dev loss: 0.8987 r:0.1987
en_zh Dev loss: 0.8309 r:0.4360
ro_en Dev loss: 0.4148 r:0.7948
et_en Dev loss: 0.4950 r:0.6418
si_en Dev loss: 0.8968 r:0.5343
ne_en Dev loss: 0.5723 r:0.7191
ru_en Dev loss: 0.5125 r:0.6997
Current avg r:0.5749 Best avg r: 0.6198
07:37:27,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:59,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:40:31,733 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1639
en_de Dev loss: 0.9321 r:0.2149
en_zh Dev loss: 0.8142 r:0.4629
ro_en Dev loss: 0.4314 r:0.8000
et_en Dev loss: 0.4947 r:0.6512
si_en Dev loss: 0.8855 r:0.5520
ne_en Dev loss: 0.5977 r:0.7214
ru_en Dev loss: 0.5240 r:0.7141
Current avg r:0.5881 Best avg r: 0.6198
07:45:08,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:46:40,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:48:12,693 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1693
en_de Dev loss: 0.9126 r:0.2124
en_zh Dev loss: 0.8525 r:0.4582
ro_en Dev loss: 0.4337 r:0.7991
et_en Dev loss: 0.5209 r:0.6542
si_en Dev loss: 0.9851 r:0.5431
ne_en Dev loss: 0.6151 r:0.7232
ru_en Dev loss: 0.5090 r:0.7179
Current avg r:0.5869 Best avg r: 0.6198
07:52:49,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:54:21,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:54,163 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1555
en_de Dev loss: 0.9188 r:0.2105
en_zh Dev loss: 0.8407 r:0.4500
ro_en Dev loss: 0.4155 r:0.7989
et_en Dev loss: 0.5027 r:0.6529
si_en Dev loss: 0.9246 r:0.5425
ne_en Dev loss: 0.6021 r:0.7196
ru_en Dev loss: 0.4895 r:0.7195
Current avg r:0.5848 Best avg r: 0.6198
08:00:32,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:04,298 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:36,390 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1447
en_de Dev loss: 0.9308 r:0.1882
en_zh Dev loss: 0.8558 r:0.4439
ro_en Dev loss: 0.4166 r:0.7981
et_en Dev loss: 0.4973 r:0.6512
si_en Dev loss: 0.9083 r:0.5395
ne_en Dev loss: 0.5672 r:0.7193
ru_en Dev loss: 0.4921 r:0.7228
Current avg r:0.5804 Best avg r: 0.6198
08:08:12,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:44,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:11:17,47 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1432
en_de Dev loss: 0.9334 r:0.1957
en_zh Dev loss: 0.8942 r:0.4503
ro_en Dev loss: 0.4716 r:0.7976
et_en Dev loss: 0.5224 r:0.6458
si_en Dev loss: 1.0804 r:0.5335
ne_en Dev loss: 0.7712 r:0.7235
ru_en Dev loss: 0.5478 r:0.7169
Current avg r:0.5805 Best avg r: 0.6198
08:15:53,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:17:25,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:18:57,539 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1515
en_de Dev loss: 0.8958 r:0.1952
en_zh Dev loss: 0.8263 r:0.4484
ro_en Dev loss: 0.4280 r:0.7915
et_en Dev loss: 0.5136 r:0.6499
si_en Dev loss: 0.9962 r:0.5258
ne_en Dev loss: 0.6324 r:0.7281
ru_en Dev loss: 0.4793 r:0.7163
Current avg r:0.5793 Best avg r: 0.6198
08:23:34,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:25:06,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:38,225 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1516
en_de Dev loss: 0.9001 r:0.2131
en_zh Dev loss: 0.7696 r:0.4637
ro_en Dev loss: 0.3709 r:0.7948
et_en Dev loss: 0.5020 r:0.6532
si_en Dev loss: 0.8848 r:0.5397
ne_en Dev loss: 0.5176 r:0.7235
ru_en Dev loss: 0.4352 r:0.7315
Current avg r:0.5885 Best avg r: 0.6198
08:31:14,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:32:46,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:34:18,833 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1404
en_de Dev loss: 0.9183 r:0.1891
en_zh Dev loss: 0.8115 r:0.4454
ro_en Dev loss: 0.4189 r:0.7900
et_en Dev loss: 0.4919 r:0.6431
si_en Dev loss: 0.9531 r:0.5263
ne_en Dev loss: 0.6168 r:0.7181
ru_en Dev loss: 0.5172 r:0.7063
Current avg r:0.5741 Best avg r: 0.6198
08:38:55,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:40:27,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:59,393 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1445
en_de Dev loss: 0.9416 r:0.1822
en_zh Dev loss: 0.8297 r:0.4508
ro_en Dev loss: 0.4181 r:0.7917
et_en Dev loss: 0.4988 r:0.6518
si_en Dev loss: 0.9959 r:0.5302
ne_en Dev loss: 0.6754 r:0.7183
ru_en Dev loss: 0.5365 r:0.7074
Current avg r:0.5761 Best avg r: 0.6198
08:46:35,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:08,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:40,80 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1420
en_de Dev loss: 0.9278 r:0.1585
en_zh Dev loss: 0.7848 r:0.4524
ro_en Dev loss: 0.4232 r:0.7940
et_en Dev loss: 0.4662 r:0.6584
si_en Dev loss: 0.9514 r:0.5306
ne_en Dev loss: 0.6203 r:0.7156
ru_en Dev loss: 0.4904 r:0.7209
Current avg r:0.5758 Best avg r: 0.6198
08:54:16,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:55:48,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:57:20,750 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1460
en_de Dev loss: 0.9403 r:0.1677
en_zh Dev loss: 0.7912 r:0.4593
ro_en Dev loss: 0.4035 r:0.7963
et_en Dev loss: 0.4696 r:0.6575
si_en Dev loss: 0.8820 r:0.5368
ne_en Dev loss: 0.5397 r:0.7235
ru_en Dev loss: 0.4780 r:0.7216
Current avg r:0.5804 Best avg r: 0.6198
09:01:57,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:03:29,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:05:01,341 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1464
en_de Dev loss: 0.9517 r:0.1930
en_zh Dev loss: 0.8553 r:0.4597
ro_en Dev loss: 0.4369 r:0.7933
et_en Dev loss: 0.5041 r:0.6540
si_en Dev loss: 1.0121 r:0.5260
ne_en Dev loss: 0.6054 r:0.7196
ru_en Dev loss: 0.5254 r:0.7237
Current avg r:0.5813 Best avg r: 0.6198
09:09:37,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:11:09,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:12:41,526 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1519
en_de Dev loss: 0.9572 r:0.1828
en_zh Dev loss: 0.8476 r:0.4478
ro_en Dev loss: 0.4395 r:0.7920
et_en Dev loss: 0.4986 r:0.6548
si_en Dev loss: 0.9637 r:0.5294
ne_en Dev loss: 0.5966 r:0.7161
ru_en Dev loss: 0.5315 r:0.7086
Current avg r:0.5759 Best avg r: 0.6198
09:17:17,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:49,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:20:21,310 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1403
en_de Dev loss: 0.9599 r:0.1648
en_zh Dev loss: 0.8503 r:0.4396
ro_en Dev loss: 0.4215 r:0.7993
et_en Dev loss: 0.4800 r:0.6676
si_en Dev loss: 0.9773 r:0.5311
ne_en Dev loss: 0.6049 r:0.7162
ru_en Dev loss: 0.4710 r:0.7375
Current avg r:0.5795 Best avg r: 0.6198
09:24:57,28 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:49,652 root INFO 
id:ro_en cur r: 0.7997 best r: 0.7997
09:26:42,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:28:14,303 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1522
en_de Dev loss: 0.9587 r:0.1756
en_zh Dev loss: 0.8293 r:0.4591
ro_en Dev loss: 0.4215 r:0.7997
et_en Dev loss: 0.4914 r:0.6540
si_en Dev loss: 0.9879 r:0.5271
ne_en Dev loss: 0.6347 r:0.7113
ru_en Dev loss: 0.5063 r:0.7200
Current avg r:0.5781 Best avg r: 0.6198
09:32:50,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:34:22,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:35:54,644 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1373
en_de Dev loss: 0.9783 r:0.1766
en_zh Dev loss: 0.8555 r:0.4661
ro_en Dev loss: 0.4140 r:0.7999
et_en Dev loss: 0.5537 r:0.6546
si_en Dev loss: 1.0257 r:0.5269
ne_en Dev loss: 0.6738 r:0.7173
ru_en Dev loss: 0.4938 r:0.7268
Current avg r:0.5812 Best avg r: 0.6198
09:40:30,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:23,542 root INFO 
id:ro_en cur r: 0.8041 best r: 0.8041
09:42:16,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:48,138 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1425
en_de Dev loss: 0.9531 r:0.1779
en_zh Dev loss: 0.7799 r:0.4619
ro_en Dev loss: 0.3730 r:0.8053
et_en Dev loss: 0.4765 r:0.6574
si_en Dev loss: 0.8853 r:0.5329
ne_en Dev loss: 0.5572 r:0.7206
ru_en Dev loss: 0.4756 r:0.7233
Current avg r:0.5828 Best avg r: 0.6198
09:48:23,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:49:55,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:27,921 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1390
en_de Dev loss: 0.9639 r:0.1631
en_zh Dev loss: 0.8601 r:0.4532
ro_en Dev loss: 0.4169 r:0.7986
et_en Dev loss: 0.4959 r:0.6485
si_en Dev loss: 0.8945 r:0.5366
ne_en Dev loss: 0.5489 r:0.7189
ru_en Dev loss: 0.5278 r:0.7083
Current avg r:0.5753 Best avg r: 0.6198
09:56:04,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:36,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:08,257 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1239
en_de Dev loss: 0.9721 r:0.1745
en_zh Dev loss: 0.7911 r:0.4690
ro_en Dev loss: 0.3834 r:0.7987
et_en Dev loss: 0.5069 r:0.6473
si_en Dev loss: 0.8782 r:0.5353
ne_en Dev loss: 0.5388 r:0.7187
ru_en Dev loss: 0.4845 r:0.7231
Current avg r:0.5809 Best avg r: 0.6198
10:03:43,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:15,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:47,810 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1360
en_de Dev loss: 1.0050 r:0.1564
en_zh Dev loss: 0.9035 r:0.4500
ro_en Dev loss: 0.4492 r:0.7962
et_en Dev loss: 0.5178 r:0.6375
si_en Dev loss: 1.0610 r:0.5164
ne_en Dev loss: 0.7464 r:0.7071
ru_en Dev loss: 0.5592 r:0.7069
Current avg r:0.5672 Best avg r: 0.6198
10:11:23,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:12:55,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:27,910 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1295
en_de Dev loss: 0.9899 r:0.1753
en_zh Dev loss: 0.8626 r:0.4603
ro_en Dev loss: 0.4285 r:0.8005
et_en Dev loss: 0.5086 r:0.6494
si_en Dev loss: 0.9611 r:0.5409
ne_en Dev loss: 0.6050 r:0.7227
ru_en Dev loss: 0.5201 r:0.7232
Current avg r:0.5818 Best avg r: 0.6198
10:19:03,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:35,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:07,828 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1259
en_de Dev loss: 0.9524 r:0.1682
en_zh Dev loss: 0.7797 r:0.4644
ro_en Dev loss: 0.3777 r:0.8016
et_en Dev loss: 0.4878 r:0.6576
si_en Dev loss: 0.8754 r:0.5411
ne_en Dev loss: 0.5539 r:0.7214
ru_en Dev loss: 0.4575 r:0.7276
Current avg r:0.5831 Best avg r: 0.6198
10:26:43,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:15,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:47,439 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1190
en_de Dev loss: 0.9415 r:0.1598
en_zh Dev loss: 0.7644 r:0.4645
ro_en Dev loss: 0.3766 r:0.7984
et_en Dev loss: 0.4840 r:0.6547
si_en Dev loss: 0.8732 r:0.5374
ne_en Dev loss: 0.5265 r:0.7151
ru_en Dev loss: 0.4584 r:0.7282
Current avg r:0.5797 Best avg r: 0.6198
