14:56:57,181 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:22,911 root INFO 
id:en_de cur r: 0.0256 best r: 0.0256
14:57:48,610 root INFO 
id:ro_en cur r: 0.5097 best r: 0.5097
14:58:01,507 root INFO 
id:et_en cur r: 0.3199 best r: 0.3199
14:58:40,134 root INFO 
id:ru_en cur r: 0.3288 best r: 0.3288
14:58:40,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:10,326 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:00:10,332 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:00:10,336 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:00:10,342 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:00:10,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:00:10,352 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:00:10,358 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:00:23,284 root INFO Epoch 0 Global steps: 700 Train loss: 0.8215
en_de Dev loss: 0.9171 r:0.0419
en_zh Dev loss: 0.8196 r:0.1696
ro_en Dev loss: 0.7623 r:0.4966
et_en Dev loss: 0.6431 r:0.4484
si_en Dev loss: 0.8396 r:0.3909
ne_en Dev loss: 0.7042 r:0.4157
ru_en Dev loss: 0.7612 r:0.4813
Current avg r:0.3492 Best avg r: 0.3492
15:04:54,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:19,861 root INFO 
id:en_de cur r: 0.1138 best r: 0.1138
15:05:32,715 root INFO 
id:en_zh cur r: 0.1803 best r: 0.1803
15:05:45,589 root INFO 
id:ro_en cur r: 0.6261 best r: 0.6261
15:05:58,505 root INFO 
id:et_en cur r: 0.4980 best r: 0.4980
15:06:11,447 root INFO 
id:si_en cur r: 0.3917 best r: 0.3917
15:06:24,393 root INFO 
id:ne_en cur r: 0.4769 best r: 0.4769
15:06:37,225 root INFO 
id:ru_en cur r: 0.5323 best r: 0.5323
15:06:37,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:07,557 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:08:07,564 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:08:07,569 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:08:07,574 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:08:07,585 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:08:07,592 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:08:07,599 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:08:20,533 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8121
en_de Dev loss: 0.9018 r:0.1068
en_zh Dev loss: 0.7766 r:0.2404
ro_en Dev loss: 0.5951 r:0.6535
et_en Dev loss: 0.5573 r:0.5552
si_en Dev loss: 0.6887 r:0.4754
ne_en Dev loss: 0.5914 r:0.5908
ru_en Dev loss: 0.5797 r:0.6518
Current avg r:0.4677 Best avg r: 0.4677
15:12:51,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:17,70 root INFO 
id:en_de cur r: 0.1683 best r: 0.1683
15:13:29,910 root INFO 
id:en_zh cur r: 0.2328 best r: 0.2328
15:13:42,785 root INFO 
id:ro_en cur r: 0.6626 best r: 0.6626
15:13:55,727 root INFO 
id:et_en cur r: 0.5959 best r: 0.5959
15:14:08,670 root INFO 
id:si_en cur r: 0.4248 best r: 0.4248
15:14:21,601 root INFO 
id:ne_en cur r: 0.5817 best r: 0.5817
15:14:34,423 root INFO 
id:ru_en cur r: 0.5921 best r: 0.5921
15:14:34,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:04,778 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:16:04,785 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:16:04,790 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:16:04,794 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:16:04,799 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:16:04,808 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:16:04,815 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:16:17,740 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7244
en_de Dev loss: 0.9585 r:0.1380
en_zh Dev loss: 0.8199 r:0.2915
ro_en Dev loss: 0.5287 r:0.6864
et_en Dev loss: 0.4841 r:0.6065
si_en Dev loss: 0.6923 r:0.4733
ne_en Dev loss: 0.5283 r:0.6083
ru_en Dev loss: 0.5672 r:0.6689
Current avg r:0.4961 Best avg r: 0.4961
15:20:48,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:21:14,250 root INFO 
id:en_zh cur r: 0.3276 best r: 0.3276
15:21:27,115 root INFO 
id:ro_en cur r: 0.6972 best r: 0.6972
15:21:40,26 root INFO 
id:et_en cur r: 0.6483 best r: 0.6483
15:21:52,960 root INFO 
id:si_en cur r: 0.4868 best r: 0.4868
15:22:05,885 root INFO 
id:ne_en cur r: 0.6738 best r: 0.6738
15:22:18,705 root INFO 
id:ru_en cur r: 0.6856 best r: 0.6856
15:22:18,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:49,39 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:23:49,47 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:23:49,52 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:23:49,56 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:23:49,61 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:23:49,67 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:23:49,75 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:24:02,14 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6977
en_de Dev loss: 0.9613 r:0.1620
en_zh Dev loss: 0.7592 r:0.3487
ro_en Dev loss: 0.4405 r:0.7160
et_en Dev loss: 0.4080 r:0.6548
si_en Dev loss: 0.6248 r:0.5163
ne_en Dev loss: 0.4505 r:0.6677
ru_en Dev loss: 0.4344 r:0.7174
Current avg r:0.5404 Best avg r: 0.5404
15:28:32,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:28:58,527 root INFO 
id:en_zh cur r: 0.3735 best r: 0.3735
15:29:11,394 root INFO 
id:ro_en cur r: 0.7149 best r: 0.7149
15:29:24,289 root INFO 
id:et_en cur r: 0.6548 best r: 0.6548
15:29:37,217 root INFO 
id:si_en cur r: 0.5033 best r: 0.5033
15:29:50,160 root INFO 
id:ne_en cur r: 0.6954 best r: 0.6954
15:30:02,979 root INFO 
id:ru_en cur r: 0.6942 best r: 0.6942
15:30:02,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:33,281 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:31:33,287 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:31:33,294 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:31:33,298 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:31:33,303 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:31:33,308 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:31:33,313 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:31:46,252 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6674
en_de Dev loss: 0.9956 r:0.1624
en_zh Dev loss: 0.7657 r:0.3814
ro_en Dev loss: 0.4662 r:0.7311
et_en Dev loss: 0.4029 r:0.6635
si_en Dev loss: 0.6845 r:0.5142
ne_en Dev loss: 0.4312 r:0.6804
ru_en Dev loss: 0.4936 r:0.7234
Current avg r:0.5509 Best avg r: 0.5509
15:36:17,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:55,642 root INFO 
id:ro_en cur r: 0.7226 best r: 0.7226
15:37:47,198 root INFO 
id:ru_en cur r: 0.6973 best r: 0.6973
15:37:47,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:17,485 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:39:17,491 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:39:17,496 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:39:17,500 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:39:17,505 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:39:17,509 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:39:17,514 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:39:30,464 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6512
en_de Dev loss: 0.9647 r:0.1628
en_zh Dev loss: 0.7403 r:0.3839
ro_en Dev loss: 0.4275 r:0.7367
et_en Dev loss: 0.3894 r:0.6696
si_en Dev loss: 0.6849 r:0.5192
ne_en Dev loss: 0.4479 r:0.6747
ru_en Dev loss: 0.4347 r:0.7284
Current avg r:0.5536 Best avg r: 0.5536
15:44:01,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:27,151 root INFO 
id:en_zh cur r: 0.3745 best r: 0.3745
15:44:40,23 root INFO 
id:ro_en cur r: 0.7420 best r: 0.7420
15:44:52,923 root INFO 
id:et_en cur r: 0.6562 best r: 0.6562
15:45:05,847 root INFO 
id:si_en cur r: 0.5256 best r: 0.5256
15:45:31,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:01,820 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:47:01,826 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:47:01,830 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:47:01,836 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:47:01,841 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:47:01,845 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:47:01,851 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:47:14,775 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5974
en_de Dev loss: 0.9549 r:0.1667
en_zh Dev loss: 0.7144 r:0.3925
ro_en Dev loss: 0.4019 r:0.7462
et_en Dev loss: 0.3891 r:0.6730
si_en Dev loss: 0.6715 r:0.5470
ne_en Dev loss: 0.4518 r:0.6837
ru_en Dev loss: 0.4606 r:0.7175
Current avg r:0.5609 Best avg r: 0.5609
15:51:45,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:11,441 root INFO 
id:en_de cur r: 0.1727 best r: 0.1727
15:52:24,287 root INFO 
id:en_zh cur r: 0.3756 best r: 0.3756
15:52:37,163 root INFO 
id:ro_en cur r: 0.7535 best r: 0.7535
15:52:50,66 root INFO 
id:et_en cur r: 0.6651 best r: 0.6651
15:53:03,0 root INFO 
id:si_en cur r: 0.5370 best r: 0.5370
15:53:15,931 root INFO 
id:ne_en cur r: 0.7021 best r: 0.7021
15:53:28,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:59,67 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:54:59,73 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:54:59,78 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:54:59,84 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:54:59,89 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:54:59,95 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:54:59,100 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:55:12,30 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5731
en_de Dev loss: 0.9803 r:0.1718
en_zh Dev loss: 0.7622 r:0.3991
ro_en Dev loss: 0.4132 r:0.7545
et_en Dev loss: 0.3996 r:0.6756
si_en Dev loss: 0.7291 r:0.5540
ne_en Dev loss: 0.4724 r:0.6958
ru_en Dev loss: 0.5366 r:0.7106
Current avg r:0.5659 Best avg r: 0.5659
15:59:42,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:08,650 root INFO 
id:en_de cur r: 0.1809 best r: 0.1809
16:00:34,377 root INFO 
id:ro_en cur r: 0.7636 best r: 0.7636
16:01:25,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:56,241 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5576
en_de Dev loss: 1.0133 r:0.1840
en_zh Dev loss: 0.8445 r:0.3937
ro_en Dev loss: 0.4830 r:0.7633
et_en Dev loss: 0.4812 r:0.6546
si_en Dev loss: 0.9272 r:0.5405
ne_en Dev loss: 0.6419 r:0.6760
ru_en Dev loss: 0.5990 r:0.6925
Current avg r:0.5578 Best avg r: 0.5659
16:07:27,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:52,858 root INFO 
id:en_zh cur r: 0.4102 best r: 0.4102
16:08:05,734 root INFO 
id:ro_en cur r: 0.7843 best r: 0.7843
16:08:18,640 root INFO 
id:et_en cur r: 0.6882 best r: 0.6882
16:08:31,591 root INFO 
id:si_en cur r: 0.5736 best r: 0.5736
16:08:44,510 root INFO 
id:ne_en cur r: 0.7322 best r: 0.7322
16:08:57,328 root INFO 
id:ru_en cur r: 0.7140 best r: 0.7140
16:08:57,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:27,668 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
16:10:27,674 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:10:27,683 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:10:27,688 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
16:10:27,693 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
16:10:27,699 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:10:27,706 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:10:40,649 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5591
en_de Dev loss: 0.9247 r:0.1941
en_zh Dev loss: 0.7056 r:0.4191
ro_en Dev loss: 0.3621 r:0.7824
et_en Dev loss: 0.3770 r:0.6930
si_en Dev loss: 0.6739 r:0.5758
ne_en Dev loss: 0.3871 r:0.7285
ru_en Dev loss: 0.4590 r:0.7269
Current avg r:0.5885 Best avg r: 0.5885
16:15:11,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:37,414 root INFO 
id:en_de cur r: 0.1856 best r: 0.1856
16:16:03,130 root INFO 
id:ro_en cur r: 0.7936 best r: 0.7936
16:16:28,992 root INFO 
id:si_en cur r: 0.5788 best r: 0.5788
16:16:41,923 root INFO 
id:ne_en cur r: 0.7518 best r: 0.7518
16:16:54,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:25,88 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
16:18:25,95 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:18:25,100 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:18:25,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
16:18:25,110 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
16:18:25,116 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:18:25,120 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:18:38,46 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5536
en_de Dev loss: 0.9339 r:0.2016
en_zh Dev loss: 0.7457 r:0.4198
ro_en Dev loss: 0.3692 r:0.7935
et_en Dev loss: 0.3736 r:0.7006
si_en Dev loss: 0.6894 r:0.5852
ne_en Dev loss: 0.3910 r:0.7461
ru_en Dev loss: 0.4885 r:0.7338
Current avg r:0.5972 Best avg r: 0.5972
16:23:09,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:34,760 root INFO 
id:en_de cur r: 0.1926 best r: 0.1926
16:23:47,603 root INFO 
id:en_zh cur r: 0.4465 best r: 0.4465
16:24:00,495 root INFO 
id:ro_en cur r: 0.8012 best r: 0.8012
16:24:13,432 root INFO 
id:et_en cur r: 0.7016 best r: 0.7016
16:24:26,367 root INFO 
id:si_en cur r: 0.5956 best r: 0.5956
16:24:39,295 root INFO 
id:ne_en cur r: 0.7592 best r: 0.7592
16:24:52,111 root INFO 
id:ru_en cur r: 0.7343 best r: 0.7343
16:24:52,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:22,444 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
16:26:22,452 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:26:22,458 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:26:22,464 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
16:26:22,469 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
16:26:22,476 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:26:22,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:26:35,415 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5311
en_de Dev loss: 0.8950 r:0.2048
en_zh Dev loss: 0.6769 r:0.4512
ro_en Dev loss: 0.3345 r:0.8005
et_en Dev loss: 0.3563 r:0.7118
si_en Dev loss: 0.6309 r:0.6052
ne_en Dev loss: 0.3885 r:0.7580
ru_en Dev loss: 0.4279 r:0.7495
Current avg r:0.6116 Best avg r: 0.6116
16:31:06,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:32,103 root INFO 
id:en_de cur r: 0.2118 best r: 0.2118
16:32:49,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:19,792 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5384
en_de Dev loss: 0.9448 r:0.2209
en_zh Dev loss: 0.7718 r:0.4390
ro_en Dev loss: 0.4201 r:0.7943
et_en Dev loss: 0.4025 r:0.7019
si_en Dev loss: 0.8579 r:0.5818
ne_en Dev loss: 0.5016 r:0.7494
ru_en Dev loss: 0.5092 r:0.7471
Current avg r:0.6049 Best avg r: 0.6116
16:38:50,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:20,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:51,178 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5489
en_de Dev loss: 0.9427 r:0.2126
en_zh Dev loss: 0.7619 r:0.4282
ro_en Dev loss: 0.3654 r:0.7932
et_en Dev loss: 0.3804 r:0.7013
si_en Dev loss: 0.7401 r:0.5802
ne_en Dev loss: 0.4225 r:0.7446
ru_en Dev loss: 0.4656 r:0.7309
Current avg r:0.5987 Best avg r: 0.6116
16:46:22,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:00,629 root INFO 
id:ro_en cur r: 0.8079 best r: 0.8079
16:47:13,524 root INFO 
id:et_en cur r: 0.7109 best r: 0.7109
16:47:26,440 root INFO 
id:si_en cur r: 0.6167 best r: 0.6167
16:47:39,358 root INFO 
id:ne_en cur r: 0.7624 best r: 0.7624
16:47:52,188 root INFO 
id:ru_en cur r: 0.7488 best r: 0.7488
16:47:52,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:22,459 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
16:49:22,470 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:49:22,476 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:49:22,483 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
16:49:22,492 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
16:49:22,499 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:49:22,505 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:49:35,419 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5254
en_de Dev loss: 0.9213 r:0.2070
en_zh Dev loss: 0.6867 r:0.4484
ro_en Dev loss: 0.3246 r:0.8043
et_en Dev loss: 0.3730 r:0.7171
si_en Dev loss: 0.5510 r:0.6208
ne_en Dev loss: 0.3306 r:0.7647
ru_en Dev loss: 0.3886 r:0.7578
Current avg r:0.6172 Best avg r: 0.6172
16:54:08,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:33,894 root INFO 
id:en_de cur r: 0.2301 best r: 0.2301
16:55:51,187 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:21,451 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5024
en_de Dev loss: 0.9751 r:0.2183
en_zh Dev loss: 0.7457 r:0.4447
ro_en Dev loss: 0.3883 r:0.8068
et_en Dev loss: 0.3919 r:0.7052
si_en Dev loss: 0.8701 r:0.6004
ne_en Dev loss: 0.5604 r:0.7487
ru_en Dev loss: 0.5167 r:0.7389
Current avg r:0.6090 Best avg r: 0.6172
17:01:52,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:18,55 root INFO 
id:en_zh cur r: 0.4576 best r: 0.4576
17:03:22,458 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:52,701 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4814
en_de Dev loss: 0.9437 r:0.2184
en_zh Dev loss: 0.7089 r:0.4507
ro_en Dev loss: 0.3791 r:0.7994
et_en Dev loss: 0.3996 r:0.6965
si_en Dev loss: 0.7961 r:0.5984
ne_en Dev loss: 0.4666 r:0.7523
ru_en Dev loss: 0.4558 r:0.7431
Current avg r:0.6084 Best avg r: 0.6172
17:09:23,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:02,281 root INFO 
id:ro_en cur r: 0.8086 best r: 0.8086
17:10:53,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:24,102 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4985
en_de Dev loss: 0.9326 r:0.2145
en_zh Dev loss: 0.7352 r:0.4458
ro_en Dev loss: 0.3706 r:0.8037
et_en Dev loss: 0.3914 r:0.6998
si_en Dev loss: 0.9196 r:0.5881
ne_en Dev loss: 0.5760 r:0.7492
ru_en Dev loss: 0.4614 r:0.7434
Current avg r:0.6064 Best avg r: 0.6172
17:16:55,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:20,911 root INFO 
id:en_zh cur r: 0.4589 best r: 0.4589
17:17:33,791 root INFO 
id:ro_en cur r: 0.8174 best r: 0.8174
17:18:25,346 root INFO 
id:ru_en cur r: 0.7517 best r: 0.7517
17:18:25,346 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:55,614 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4865
en_de Dev loss: 1.0073 r:0.2136
en_zh Dev loss: 0.8423 r:0.4556
ro_en Dev loss: 0.4288 r:0.8095
et_en Dev loss: 0.4145 r:0.7034
si_en Dev loss: 0.7923 r:0.6109
ne_en Dev loss: 0.5968 r:0.7515
ru_en Dev loss: 0.4891 r:0.7553
Current avg r:0.6143 Best avg r: 0.6172
17:24:26,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:52,495 root INFO 
id:en_zh cur r: 0.4652 best r: 0.4652
17:25:05,375 root INFO 
id:ro_en cur r: 0.8198 best r: 0.8198
17:25:56,925 root INFO 
id:ru_en cur r: 0.7698 best r: 0.7698
17:25:56,926 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:27,138 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
17:27:27,145 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:27:27,150 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:27:27,160 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
17:27:27,165 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
17:27:27,169 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:27:27,174 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:27:40,130 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4957
en_de Dev loss: 0.8683 r:0.2207
en_zh Dev loss: 0.6571 r:0.4666
ro_en Dev loss: 0.2967 r:0.8158
et_en Dev loss: 0.3500 r:0.7145
si_en Dev loss: 0.6188 r:0.6165
ne_en Dev loss: 0.3739 r:0.7602
ru_en Dev loss: 0.3451 r:0.7729
Current avg r:0.6239 Best avg r: 0.6239
17:32:11,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:28,596 root INFO 
id:ne_en cur r: 0.7627 best r: 0.7627
17:33:41,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:11,634 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4782
en_de Dev loss: 0.8946 r:0.2100
en_zh Dev loss: 0.7113 r:0.4514
ro_en Dev loss: 0.3441 r:0.8097
et_en Dev loss: 0.3647 r:0.7125
si_en Dev loss: 0.6460 r:0.6125
ne_en Dev loss: 0.4121 r:0.7607
ru_en Dev loss: 0.4658 r:0.7409
Current avg r:0.6140 Best avg r: 0.6239
17:39:42,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:08,629 root INFO 
id:en_de cur r: 0.2328 best r: 0.2328
17:41:25,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:56,178 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4712
en_de Dev loss: 0.8678 r:0.2247
en_zh Dev loss: 0.7178 r:0.4439
ro_en Dev loss: 0.3264 r:0.8138
et_en Dev loss: 0.3576 r:0.7095
si_en Dev loss: 0.6971 r:0.6022
ne_en Dev loss: 0.4040 r:0.7585
ru_en Dev loss: 0.4380 r:0.7346
Current avg r:0.6124 Best avg r: 0.6239
17:47:27,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:05,805 root INFO 
id:ro_en cur r: 0.8201 best r: 0.8201
17:48:44,526 root INFO 
id:ne_en cur r: 0.7633 best r: 0.7633
17:48:57,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:27,501 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4417
en_de Dev loss: 0.8989 r:0.2136
en_zh Dev loss: 0.7539 r:0.4456
ro_en Dev loss: 0.3249 r:0.8138
et_en Dev loss: 0.3525 r:0.7134
si_en Dev loss: 0.6277 r:0.6103
ne_en Dev loss: 0.3799 r:0.7656
ru_en Dev loss: 0.5057 r:0.7247
Current avg r:0.6124 Best avg r: 0.6239
17:54:58,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:24,257 root INFO 
id:en_de cur r: 0.2475 best r: 0.2475
17:56:41,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:11,861 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4668
en_de Dev loss: 0.9352 r:0.2293
en_zh Dev loss: 0.7835 r:0.4512
ro_en Dev loss: 0.4139 r:0.8085
et_en Dev loss: 0.4014 r:0.7107
si_en Dev loss: 0.7163 r:0.6093
ne_en Dev loss: 0.4173 r:0.7590
ru_en Dev loss: 0.4334 r:0.7677
Current avg r:0.6194 Best avg r: 0.6239
18:02:43,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:08,813 root INFO 
id:en_zh cur r: 0.4843 best r: 0.4843
18:03:21,692 root INFO 
id:ro_en cur r: 0.8249 best r: 0.8249
18:03:34,589 root INFO 
id:et_en cur r: 0.7167 best r: 0.7167
18:03:47,511 root INFO 
id:si_en cur r: 0.6224 best r: 0.6224
18:04:00,432 root INFO 
id:ne_en cur r: 0.7699 best r: 0.7699
18:04:13,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:43,411 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
18:05:43,419 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:05:43,423 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:05:43,428 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
18:05:43,433 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
18:05:43,439 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:05:43,444 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:05:56,374 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4599
en_de Dev loss: 0.8618 r:0.2319
en_zh Dev loss: 0.6591 r:0.4776
ro_en Dev loss: 0.2967 r:0.8215
et_en Dev loss: 0.3507 r:0.7213
si_en Dev loss: 0.5825 r:0.6203
ne_en Dev loss: 0.3317 r:0.7692
ru_en Dev loss: 0.3697 r:0.7677
Current avg r:0.6299 Best avg r: 0.6299
18:10:27,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:57,512 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:27,674 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4509
en_de Dev loss: 0.9042 r:0.2247
en_zh Dev loss: 0.7657 r:0.4310
ro_en Dev loss: 0.3822 r:0.8091
et_en Dev loss: 0.3883 r:0.7048
si_en Dev loss: 0.7745 r:0.5923
ne_en Dev loss: 0.4497 r:0.7625
ru_en Dev loss: 0.4338 r:0.7498
Current avg r:0.6106 Best avg r: 0.6299
18:17:58,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:24,338 root INFO 
id:en_de cur r: 0.2554 best r: 0.2554
18:19:41,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:11,692 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4480
en_de Dev loss: 0.8878 r:0.2319
en_zh Dev loss: 0.7286 r:0.4546
ro_en Dev loss: 0.3591 r:0.8130
et_en Dev loss: 0.3611 r:0.7128
si_en Dev loss: 0.7208 r:0.6051
ne_en Dev loss: 0.5055 r:0.7594
ru_en Dev loss: 0.4925 r:0.7393
Current avg r:0.6166 Best avg r: 0.6299
18:25:42,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:12,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:42,782 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4285
en_de Dev loss: 0.8787 r:0.2231
en_zh Dev loss: 0.7071 r:0.4596
ro_en Dev loss: 0.3427 r:0.8158
et_en Dev loss: 0.3804 r:0.7150
si_en Dev loss: 0.6652 r:0.6122
ne_en Dev loss: 0.3510 r:0.7650
ru_en Dev loss: 0.4204 r:0.7597
Current avg r:0.6215 Best avg r: 0.6299
18:33:13,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:52,340 root INFO 
id:ro_en cur r: 0.8279 best r: 0.8279
18:34:31,58 root INFO 
id:ne_en cur r: 0.7750 best r: 0.7750
18:34:43,880 root INFO 
id:ru_en cur r: 0.7768 best r: 0.7768
18:34:43,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:14,36 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4506
en_de Dev loss: 0.8738 r:0.2194
en_zh Dev loss: 0.6958 r:0.4625
ro_en Dev loss: 0.3130 r:0.8224
et_en Dev loss: 0.3724 r:0.7127
si_en Dev loss: 0.6674 r:0.6180
ne_en Dev loss: 0.3885 r:0.7727
ru_en Dev loss: 0.3627 r:0.7749
Current avg r:0.6261 Best avg r: 0.6299
18:40:45,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:15,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:45,267 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4315
en_de Dev loss: 0.9164 r:0.2172
en_zh Dev loss: 0.7444 r:0.4574
ro_en Dev loss: 0.4087 r:0.8146
et_en Dev loss: 0.3976 r:0.7054
si_en Dev loss: 0.8302 r:0.6068
ne_en Dev loss: 0.6070 r:0.7602
ru_en Dev loss: 0.4791 r:0.7663
Current avg r:0.6183 Best avg r: 0.6299
18:48:17,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:47,438 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:17,512 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4210
en_de Dev loss: 0.9254 r:0.2304
en_zh Dev loss: 0.8267 r:0.4408
ro_en Dev loss: 0.4534 r:0.8010
et_en Dev loss: 0.4070 r:0.7002
si_en Dev loss: 0.9517 r:0.5950
ne_en Dev loss: 0.5893 r:0.7567
ru_en Dev loss: 0.5438 r:0.7336
Current avg r:0.6083 Best avg r: 0.6299
18:55:48,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:14,97 root INFO 
id:en_de cur r: 0.2561 best r: 0.2561
18:57:31,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:01,398 root INFO Epoch 2 Global steps: 22400 Train loss: 0.3942
en_de Dev loss: 0.8981 r:0.2381
en_zh Dev loss: 0.7132 r:0.4681
ro_en Dev loss: 0.3581 r:0.8147
et_en Dev loss: 0.3791 r:0.7110
si_en Dev loss: 0.6792 r:0.6163
ne_en Dev loss: 0.4368 r:0.7672
ru_en Dev loss: 0.4289 r:0.7600
Current avg r:0.6251 Best avg r: 0.6299
19:03:32,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:02,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:32,254 root INFO Epoch 2 Global steps: 23100 Train loss: 0.3963
en_de Dev loss: 0.9238 r:0.2399
en_zh Dev loss: 0.7557 r:0.4673
ro_en Dev loss: 0.3651 r:0.8147
et_en Dev loss: 0.3811 r:0.7088
si_en Dev loss: 0.7202 r:0.6111
ne_en Dev loss: 0.4638 r:0.7636
ru_en Dev loss: 0.4593 r:0.7502
Current avg r:0.6222 Best avg r: 0.6299
19:11:03,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:33,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:03,171 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4143
en_de Dev loss: 0.9024 r:0.2243
en_zh Dev loss: 0.7673 r:0.4663
ro_en Dev loss: 0.3731 r:0.8216
et_en Dev loss: 0.3958 r:0.7087
si_en Dev loss: 0.7760 r:0.6162
ne_en Dev loss: 0.5317 r:0.7655
ru_en Dev loss: 0.4738 r:0.7531
Current avg r:0.6222 Best avg r: 0.6299
19:18:33,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:03,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:34,8 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4037
en_de Dev loss: 0.9113 r:0.2268
en_zh Dev loss: 0.7765 r:0.4516
ro_en Dev loss: 0.3693 r:0.8158
et_en Dev loss: 0.3732 r:0.7114
si_en Dev loss: 0.6941 r:0.6136
ne_en Dev loss: 0.5247 r:0.7626
ru_en Dev loss: 0.4858 r:0.7394
Current avg r:0.6173 Best avg r: 0.6299
19:26:04,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:34,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:04,890 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3853
en_de Dev loss: 0.8927 r:0.2129
en_zh Dev loss: 0.7207 r:0.4668
ro_en Dev loss: 0.3355 r:0.8184
et_en Dev loss: 0.3867 r:0.7053
si_en Dev loss: 0.6611 r:0.6126
ne_en Dev loss: 0.4130 r:0.7560
ru_en Dev loss: 0.3989 r:0.7581
Current avg r:0.6186 Best avg r: 0.6299
19:33:35,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:05,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:35,689 root INFO Epoch 2 Global steps: 25900 Train loss: 0.3948
en_de Dev loss: 0.8966 r:0.2161
en_zh Dev loss: 0.7326 r:0.4637
ro_en Dev loss: 0.3306 r:0.8148
et_en Dev loss: 0.3699 r:0.7081
si_en Dev loss: 0.6792 r:0.6116
ne_en Dev loss: 0.3817 r:0.7583
ru_en Dev loss: 0.4295 r:0.7423
Current avg r:0.6164 Best avg r: 0.6299
19:41:06,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:36,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:06,659 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3957
en_de Dev loss: 0.8756 r:0.2168
en_zh Dev loss: 0.6922 r:0.4709
ro_en Dev loss: 0.3165 r:0.8207
et_en Dev loss: 0.3566 r:0.7141
si_en Dev loss: 0.6779 r:0.6138
ne_en Dev loss: 0.4745 r:0.7608
ru_en Dev loss: 0.4209 r:0.7488
Current avg r:0.6208 Best avg r: 0.6299
19:48:37,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:07,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:37,597 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3791
en_de Dev loss: 0.8965 r:0.2060
en_zh Dev loss: 0.7599 r:0.4596
ro_en Dev loss: 0.3463 r:0.8183
et_en Dev loss: 0.3666 r:0.7126
si_en Dev loss: 0.7628 r:0.6056
ne_en Dev loss: 0.5078 r:0.7607
ru_en Dev loss: 0.5116 r:0.7298
Current avg r:0.6132 Best avg r: 0.6299
19:56:08,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:59,854 root INFO 
id:et_en cur r: 0.7193 best r: 0.7193
19:57:38,490 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:08,616 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3912
en_de Dev loss: 0.8747 r:0.2119
en_zh Dev loss: 0.6785 r:0.4669
ro_en Dev loss: 0.3253 r:0.8192
et_en Dev loss: 0.3841 r:0.7146
si_en Dev loss: 0.6455 r:0.6086
ne_en Dev loss: 0.3649 r:0.7671
ru_en Dev loss: 0.3969 r:0.7528
Current avg r:0.6202 Best avg r: 0.6299
20:03:39,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:09,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:39,624 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3762
en_de Dev loss: 0.9098 r:0.2091
en_zh Dev loss: 0.7270 r:0.4492
ro_en Dev loss: 0.3468 r:0.8140
et_en Dev loss: 0.3871 r:0.7059
si_en Dev loss: 0.6926 r:0.6001
ne_en Dev loss: 0.3960 r:0.7583
ru_en Dev loss: 0.4518 r:0.7411
Current avg r:0.6111 Best avg r: 0.6299
20:11:10,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:40,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:10,503 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3727
en_de Dev loss: 0.8704 r:0.2208
en_zh Dev loss: 0.6876 r:0.4750
ro_en Dev loss: 0.3208 r:0.8197
et_en Dev loss: 0.3891 r:0.7046
si_en Dev loss: 0.6708 r:0.6129
ne_en Dev loss: 0.4026 r:0.7631
ru_en Dev loss: 0.3851 r:0.7570
Current avg r:0.6219 Best avg r: 0.6299
20:18:41,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:11,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:41,340 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3739
en_de Dev loss: 0.8887 r:0.2173
en_zh Dev loss: 0.7367 r:0.4662
ro_en Dev loss: 0.3627 r:0.8140
et_en Dev loss: 0.3984 r:0.6932
si_en Dev loss: 0.8246 r:0.5979
ne_en Dev loss: 0.5263 r:0.7630
ru_en Dev loss: 0.4580 r:0.7394
Current avg r:0.6130 Best avg r: 0.6299
20:26:12,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:42,222 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:12,303 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3737
en_de Dev loss: 0.8908 r:0.2171
en_zh Dev loss: 0.7395 r:0.4705
ro_en Dev loss: 0.3524 r:0.8211
et_en Dev loss: 0.3958 r:0.7068
si_en Dev loss: 0.6873 r:0.6160
ne_en Dev loss: 0.3770 r:0.7623
ru_en Dev loss: 0.4353 r:0.7533
Current avg r:0.6210 Best avg r: 0.6299
20:33:43,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:13,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:43,361 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3756
en_de Dev loss: 0.8901 r:0.2275
en_zh Dev loss: 0.7295 r:0.4741
ro_en Dev loss: 0.3449 r:0.8200
et_en Dev loss: 0.3981 r:0.7032
si_en Dev loss: 0.6403 r:0.6172
ne_en Dev loss: 0.3840 r:0.7668
ru_en Dev loss: 0.4230 r:0.7484
Current avg r:0.6224 Best avg r: 0.6299
20:41:15,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:41,507 root INFO 
id:en_zh cur r: 0.4944 best r: 0.4944
20:41:54,394 root INFO 
id:ro_en cur r: 0.8282 best r: 0.8282
20:42:45,934 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:16,52 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3404
en_de Dev loss: 0.8771 r:0.2264
en_zh Dev loss: 0.6985 r:0.4869
ro_en Dev loss: 0.3329 r:0.8237
et_en Dev loss: 0.3896 r:0.7049
si_en Dev loss: 0.7344 r:0.6163
ne_en Dev loss: 0.3921 r:0.7639
ru_en Dev loss: 0.4146 r:0.7565
Current avg r:0.6255 Best avg r: 0.6299
20:48:46,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:17,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:47,185 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3526
en_de Dev loss: 0.9160 r:0.2035
en_zh Dev loss: 0.7884 r:0.4683
ro_en Dev loss: 0.4232 r:0.8150
et_en Dev loss: 0.4317 r:0.6943
si_en Dev loss: 0.8764 r:0.6013
ne_en Dev loss: 0.6208 r:0.7591
ru_en Dev loss: 0.5438 r:0.7263
Current avg r:0.6097 Best avg r: 0.6299
20:56:18,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:48,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:18,341 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3454
en_de Dev loss: 0.9098 r:0.2118
en_zh Dev loss: 0.7831 r:0.4520
ro_en Dev loss: 0.3423 r:0.8211
et_en Dev loss: 0.3959 r:0.6952
si_en Dev loss: 0.7939 r:0.6028
ne_en Dev loss: 0.4243 r:0.7639
ru_en Dev loss: 0.4584 r:0.7393
Current avg r:0.6123 Best avg r: 0.6299
21:03:49,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:19,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:49,397 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3275
en_de Dev loss: 0.9095 r:0.2027
en_zh Dev loss: 0.7632 r:0.4571
ro_en Dev loss: 0.3665 r:0.8144
et_en Dev loss: 0.4237 r:0.6910
si_en Dev loss: 0.7691 r:0.6033
ne_en Dev loss: 0.4239 r:0.7620
ru_en Dev loss: 0.4247 r:0.7505
Current avg r:0.6116 Best avg r: 0.6299
21:11:20,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:50,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:20,591 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3264
en_de Dev loss: 0.9012 r:0.2034
en_zh Dev loss: 0.7168 r:0.4796
ro_en Dev loss: 0.3556 r:0.8167
et_en Dev loss: 0.3910 r:0.6979
si_en Dev loss: 0.6556 r:0.6185
ne_en Dev loss: 0.3562 r:0.7686
ru_en Dev loss: 0.4278 r:0.7446
Current avg r:0.6185 Best avg r: 0.6299
21:18:51,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:21,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:51,711 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3388
en_de Dev loss: 0.9483 r:0.1996
en_zh Dev loss: 0.8787 r:0.4518
ro_en Dev loss: 0.4376 r:0.8114
et_en Dev loss: 0.4274 r:0.6904
si_en Dev loss: 0.8939 r:0.5900
ne_en Dev loss: 0.5885 r:0.7565
ru_en Dev loss: 0.6042 r:0.6998
Current avg r:0.5999 Best avg r: 0.6299
21:26:22,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:52,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:22,809 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3312
en_de Dev loss: 0.9195 r:0.1779
en_zh Dev loss: 0.8228 r:0.4322
ro_en Dev loss: 0.3523 r:0.8162
et_en Dev loss: 0.4160 r:0.6965
si_en Dev loss: 0.7665 r:0.5919
ne_en Dev loss: 0.4558 r:0.7544
ru_en Dev loss: 0.4677 r:0.7258
Current avg r:0.5993 Best avg r: 0.6299
21:33:53,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:23,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:53,845 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3452
en_de Dev loss: 0.9031 r:0.2005
en_zh Dev loss: 0.7489 r:0.4538
ro_en Dev loss: 0.3413 r:0.8190
et_en Dev loss: 0.3849 r:0.6991
si_en Dev loss: 0.6840 r:0.6053
ne_en Dev loss: 0.3910 r:0.7609
ru_en Dev loss: 0.4457 r:0.7358
Current avg r:0.6106 Best avg r: 0.6299
21:41:24,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:54,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:25,120 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3252
en_de Dev loss: 0.9167 r:0.2086
en_zh Dev loss: 0.7616 r:0.4576
ro_en Dev loss: 0.3418 r:0.8170
et_en Dev loss: 0.3924 r:0.6990
si_en Dev loss: 0.7191 r:0.6042
ne_en Dev loss: 0.4051 r:0.7662
ru_en Dev loss: 0.4824 r:0.7252
Current avg r:0.6111 Best avg r: 0.6299
21:48:55,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:26,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:56,401 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3215
en_de Dev loss: 0.8960 r:0.2065
en_zh Dev loss: 0.7352 r:0.4450
ro_en Dev loss: 0.3396 r:0.8147
et_en Dev loss: 0.4033 r:0.6913
si_en Dev loss: 0.6574 r:0.6016
ne_en Dev loss: 0.4218 r:0.7566
ru_en Dev loss: 0.4357 r:0.7293
Current avg r:0.6064 Best avg r: 0.6299
21:56:27,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:57,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:27,621 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3195
en_de Dev loss: 0.8855 r:0.2154
en_zh Dev loss: 0.6885 r:0.4710
ro_en Dev loss: 0.3000 r:0.8244
et_en Dev loss: 0.3771 r:0.7030
si_en Dev loss: 0.6150 r:0.6176
ne_en Dev loss: 0.3710 r:0.7748
ru_en Dev loss: 0.4014 r:0.7464
Current avg r:0.6218 Best avg r: 0.6299
22:03:58,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:28,680 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:58,897 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3300
en_de Dev loss: 0.9288 r:0.2144
en_zh Dev loss: 0.7759 r:0.4625
ro_en Dev loss: 0.3550 r:0.8210
et_en Dev loss: 0.3990 r:0.6991
si_en Dev loss: 0.7355 r:0.6043
ne_en Dev loss: 0.4360 r:0.7614
ru_en Dev loss: 0.4736 r:0.7433
Current avg r:0.6151 Best avg r: 0.6299
22:11:29,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:00,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:30,225 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3233
en_de Dev loss: 0.9216 r:0.2148
en_zh Dev loss: 0.7743 r:0.4551
ro_en Dev loss: 0.3607 r:0.8167
et_en Dev loss: 0.4150 r:0.6897
si_en Dev loss: 0.7628 r:0.6034
ne_en Dev loss: 0.4700 r:0.7532
ru_en Dev loss: 0.4533 r:0.7410
Current avg r:0.6106 Best avg r: 0.6299
22:19:01,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:31,422 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:01,578 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3097
en_de Dev loss: 0.8984 r:0.2263
en_zh Dev loss: 0.8460 r:0.4348
ro_en Dev loss: 0.3639 r:0.8107
et_en Dev loss: 0.4171 r:0.6820
si_en Dev loss: 0.9474 r:0.5714
ne_en Dev loss: 0.4887 r:0.7468
ru_en Dev loss: 0.5087 r:0.7145
Current avg r:0.5981 Best avg r: 0.6299
22:26:32,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:02,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:32,861 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3285
en_de Dev loss: 0.9265 r:0.2190
en_zh Dev loss: 0.7986 r:0.4640
ro_en Dev loss: 0.3673 r:0.8197
et_en Dev loss: 0.4096 r:0.6932
si_en Dev loss: 0.8352 r:0.6004
ne_en Dev loss: 0.4750 r:0.7515
ru_en Dev loss: 0.5184 r:0.7243
Current avg r:0.6103 Best avg r: 0.6299
22:34:05,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:35,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:05,914 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2933
en_de Dev loss: 0.9142 r:0.2230
en_zh Dev loss: 0.7737 r:0.4526
ro_en Dev loss: 0.3657 r:0.8163
et_en Dev loss: 0.4125 r:0.6907
si_en Dev loss: 0.8471 r:0.5913
ne_en Dev loss: 0.5051 r:0.7534
ru_en Dev loss: 0.5331 r:0.7092
Current avg r:0.6052 Best avg r: 0.6299
22:41:37,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:07,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:37,630 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2924
en_de Dev loss: 0.9149 r:0.2178
en_zh Dev loss: 0.7413 r:0.4645
ro_en Dev loss: 0.3562 r:0.8146
et_en Dev loss: 0.4272 r:0.6816
si_en Dev loss: 0.8007 r:0.5844
ne_en Dev loss: 0.4715 r:0.7542
ru_en Dev loss: 0.4884 r:0.7153
Current avg r:0.6046 Best avg r: 0.6299
22:49:08,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:39,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:09,225 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2966
en_de Dev loss: 0.9375 r:0.2138
en_zh Dev loss: 0.8475 r:0.4574
ro_en Dev loss: 0.4277 r:0.8129
et_en Dev loss: 0.4546 r:0.6818
si_en Dev loss: 1.0059 r:0.5784
ne_en Dev loss: 0.6609 r:0.7490
ru_en Dev loss: 0.5418 r:0.7263
Current avg r:0.6028 Best avg r: 0.6299
22:56:40,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:10,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:40,870 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2855
en_de Dev loss: 0.9126 r:0.2148
en_zh Dev loss: 0.7892 r:0.4659
ro_en Dev loss: 0.3686 r:0.8196
et_en Dev loss: 0.4202 r:0.6857
si_en Dev loss: 0.8170 r:0.5929
ne_en Dev loss: 0.5894 r:0.7531
ru_en Dev loss: 0.5087 r:0.7162
Current avg r:0.6069 Best avg r: 0.6299
23:04:11,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:41,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:12,86 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2789
en_de Dev loss: 0.9152 r:0.2222
en_zh Dev loss: 0.7912 r:0.4630
ro_en Dev loss: 0.3627 r:0.8203
et_en Dev loss: 0.4236 r:0.6924
si_en Dev loss: 0.7086 r:0.6030
ne_en Dev loss: 0.4562 r:0.7574
ru_en Dev loss: 0.4764 r:0.7299
Current avg r:0.6126 Best avg r: 0.6299
23:11:43,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:13,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:43,438 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2671
en_de Dev loss: 0.9255 r:0.2075
en_zh Dev loss: 0.7986 r:0.4675
ro_en Dev loss: 0.3953 r:0.8173
et_en Dev loss: 0.4696 r:0.6875
si_en Dev loss: 0.8378 r:0.5918
ne_en Dev loss: 0.4708 r:0.7486
ru_en Dev loss: 0.4894 r:0.7406
Current avg r:0.6087 Best avg r: 0.6299
23:19:14,214 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:44,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:14,520 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2772
en_de Dev loss: 0.9540 r:0.2126
en_zh Dev loss: 0.8179 r:0.4542
ro_en Dev loss: 0.3615 r:0.8150
et_en Dev loss: 0.4220 r:0.6854
si_en Dev loss: 0.8375 r:0.5807
ne_en Dev loss: 0.5115 r:0.7500
ru_en Dev loss: 0.4802 r:0.7341
Current avg r:0.6046 Best avg r: 0.6299
23:26:45,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:15,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:45,299 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2738
en_de Dev loss: 0.9260 r:0.2124
en_zh Dev loss: 0.7379 r:0.4866
ro_en Dev loss: 0.3482 r:0.8205
et_en Dev loss: 0.3978 r:0.6986
si_en Dev loss: 0.7529 r:0.6035
ne_en Dev loss: 0.4554 r:0.7622
ru_en Dev loss: 0.4560 r:0.7441
Current avg r:0.6183 Best avg r: 0.6299
23:34:16,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:46,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:16,237 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2795
en_de Dev loss: 0.9523 r:0.2195
en_zh Dev loss: 0.8268 r:0.4569
ro_en Dev loss: 0.4042 r:0.8167
et_en Dev loss: 0.4546 r:0.6785
si_en Dev loss: 1.0224 r:0.5805
ne_en Dev loss: 0.6165 r:0.7423
ru_en Dev loss: 0.5795 r:0.7035
Current avg r:0.5997 Best avg r: 0.6299
23:41:46,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:17,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:47,214 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2586
en_de Dev loss: 0.9372 r:0.2173
en_zh Dev loss: 0.7804 r:0.4641
ro_en Dev loss: 0.3661 r:0.8143
et_en Dev loss: 0.4347 r:0.6778
si_en Dev loss: 0.8118 r:0.5849
ne_en Dev loss: 0.4432 r:0.7459
ru_en Dev loss: 0.5212 r:0.7094
Current avg r:0.6020 Best avg r: 0.6299
23:49:17,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:48,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:18,172 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2819
en_de Dev loss: 0.9200 r:0.2162
en_zh Dev loss: 0.7934 r:0.4521
ro_en Dev loss: 0.3838 r:0.8139
et_en Dev loss: 0.4160 r:0.6793
si_en Dev loss: 0.9163 r:0.5747
ne_en Dev loss: 0.6022 r:0.7411
ru_en Dev loss: 0.5418 r:0.7073
Current avg r:0.5978 Best avg r: 0.6299
23:56:48,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:18,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:49,88 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2748
en_de Dev loss: 0.9107 r:0.2270
en_zh Dev loss: 0.7534 r:0.4713
ro_en Dev loss: 0.3389 r:0.8198
et_en Dev loss: 0.4158 r:0.6890
si_en Dev loss: 0.7284 r:0.5981
ne_en Dev loss: 0.4479 r:0.7489
ru_en Dev loss: 0.4310 r:0.7409
Current avg r:0.6136 Best avg r: 0.6299
00:04:19,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:49,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:20,44 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2622
en_de Dev loss: 0.9372 r:0.1942
en_zh Dev loss: 0.7732 r:0.4695
ro_en Dev loss: 0.3658 r:0.8154
et_en Dev loss: 0.4329 r:0.6784
si_en Dev loss: 0.8339 r:0.5749
ne_en Dev loss: 0.5699 r:0.7314
ru_en Dev loss: 0.4751 r:0.7333
Current avg r:0.5996 Best avg r: 0.6299
00:11:50,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:20,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:51,13 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2685
en_de Dev loss: 0.9913 r:0.2040
en_zh Dev loss: 0.8092 r:0.4664
ro_en Dev loss: 0.3923 r:0.8177
et_en Dev loss: 0.4311 r:0.6914
si_en Dev loss: 0.8918 r:0.5793
ne_en Dev loss: 0.5475 r:0.7430
ru_en Dev loss: 0.5226 r:0.7332
Current avg r:0.6050 Best avg r: 0.6299
00:19:21,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:52,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:22,191 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2735
en_de Dev loss: 0.9318 r:0.2028
en_zh Dev loss: 0.7598 r:0.4539
ro_en Dev loss: 0.3433 r:0.8156
et_en Dev loss: 0.4334 r:0.6824
si_en Dev loss: 0.7829 r:0.5750
ne_en Dev loss: 0.4695 r:0.7431
ru_en Dev loss: 0.4712 r:0.7204
Current avg r:0.5990 Best avg r: 0.6299
00:26:54,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:24,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:54,871 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2278
en_de Dev loss: 0.9490 r:0.1892
en_zh Dev loss: 0.7833 r:0.4559
ro_en Dev loss: 0.3734 r:0.8168
et_en Dev loss: 0.4513 r:0.6656
si_en Dev loss: 0.8519 r:0.5733
ne_en Dev loss: 0.5313 r:0.7406
ru_en Dev loss: 0.5054 r:0.7167
Current avg r:0.5940 Best avg r: 0.6299
00:34:25,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:55,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:25,823 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2334
en_de Dev loss: 0.9448 r:0.1883
en_zh Dev loss: 0.8018 r:0.4609
ro_en Dev loss: 0.3584 r:0.8218
et_en Dev loss: 0.4576 r:0.6774
si_en Dev loss: 0.8224 r:0.5864
ne_en Dev loss: 0.5422 r:0.7411
ru_en Dev loss: 0.5099 r:0.7212
Current avg r:0.5996 Best avg r: 0.6299
00:41:56,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:26,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:56,665 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2371
en_de Dev loss: 0.9415 r:0.1770
en_zh Dev loss: 0.7910 r:0.4476
ro_en Dev loss: 0.3508 r:0.8190
et_en Dev loss: 0.4487 r:0.6748
si_en Dev loss: 0.8831 r:0.5776
ne_en Dev loss: 0.5095 r:0.7462
ru_en Dev loss: 0.4521 r:0.7346
Current avg r:0.5967 Best avg r: 0.6299
00:49:27,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:57,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:27,556 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2449
en_de Dev loss: 0.9444 r:0.1979
en_zh Dev loss: 0.7886 r:0.4623
ro_en Dev loss: 0.3605 r:0.8202
et_en Dev loss: 0.4399 r:0.6857
si_en Dev loss: 0.7859 r:0.5899
ne_en Dev loss: 0.4859 r:0.7449
ru_en Dev loss: 0.4845 r:0.7286
Current avg r:0.6042 Best avg r: 0.6299
00:56:58,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:28,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:58,593 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2402
en_de Dev loss: 0.9174 r:0.2001
en_zh Dev loss: 0.7551 r:0.4679
ro_en Dev loss: 0.3389 r:0.8197
et_en Dev loss: 0.4392 r:0.6909
si_en Dev loss: 0.7490 r:0.5906
ne_en Dev loss: 0.4173 r:0.7469
ru_en Dev loss: 0.4347 r:0.7356
Current avg r:0.6074 Best avg r: 0.6299
01:04:29,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:59,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:29,521 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2358
en_de Dev loss: 0.9090 r:0.1963
en_zh Dev loss: 0.7369 r:0.4691
ro_en Dev loss: 0.3309 r:0.8167
et_en Dev loss: 0.4205 r:0.6799
si_en Dev loss: 0.7841 r:0.5883
ne_en Dev loss: 0.5111 r:0.7378
ru_en Dev loss: 0.4415 r:0.7295
Current avg r:0.6025 Best avg r: 0.6299
01:12:00,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:30,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:00,655 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2362
en_de Dev loss: 0.9741 r:0.1949
en_zh Dev loss: 0.8075 r:0.4594
ro_en Dev loss: 0.3927 r:0.8160
et_en Dev loss: 0.4485 r:0.6721
si_en Dev loss: 0.9523 r:0.5692
ne_en Dev loss: 0.6566 r:0.7299
ru_en Dev loss: 0.5470 r:0.7119
Current avg r:0.5933 Best avg r: 0.6299
01:19:31,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:01,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:22:31,781 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2376
en_de Dev loss: 0.9475 r:0.1909
en_zh Dev loss: 0.7878 r:0.4602
ro_en Dev loss: 0.3530 r:0.8135
et_en Dev loss: 0.4722 r:0.6851
si_en Dev loss: 0.7147 r:0.5860
ne_en Dev loss: 0.4663 r:0.7370
ru_en Dev loss: 0.4501 r:0.7310
Current avg r:0.6005 Best avg r: 0.6299
01:27:02,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:32,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:02,760 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2373
en_de Dev loss: 0.9382 r:0.1912
en_zh Dev loss: 0.7735 r:0.4664
ro_en Dev loss: 0.3536 r:0.8162
et_en Dev loss: 0.4377 r:0.6844
si_en Dev loss: 0.7494 r:0.5874
ne_en Dev loss: 0.5455 r:0.7326
ru_en Dev loss: 0.4625 r:0.7293
Current avg r:0.6011 Best avg r: 0.6299
01:34:33,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:36:03,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:33,778 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2258
en_de Dev loss: 0.9403 r:0.1980
en_zh Dev loss: 0.7620 r:0.4715
ro_en Dev loss: 0.3484 r:0.8137
et_en Dev loss: 0.4372 r:0.6754
si_en Dev loss: 0.8434 r:0.5801
ne_en Dev loss: 0.5714 r:0.7347
ru_en Dev loss: 0.4526 r:0.7382
Current avg r:0.6017 Best avg r: 0.6299
01:42:04,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:34,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:04,808 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2325
en_de Dev loss: 0.9530 r:0.1905
en_zh Dev loss: 0.8011 r:0.4660
ro_en Dev loss: 0.3702 r:0.8127
et_en Dev loss: 0.4540 r:0.6808
si_en Dev loss: 0.8472 r:0.5774
ne_en Dev loss: 0.5072 r:0.7312
ru_en Dev loss: 0.5051 r:0.7195
Current avg r:0.5969 Best avg r: 0.6299
01:49:35,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:05,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:35,836 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2216
en_de Dev loss: 0.9390 r:0.1918
en_zh Dev loss: 0.7823 r:0.4677
ro_en Dev loss: 0.3524 r:0.8147
et_en Dev loss: 0.4400 r:0.6852
si_en Dev loss: 0.7579 r:0.5862
ne_en Dev loss: 0.4730 r:0.7356
ru_en Dev loss: 0.4759 r:0.7253
Current avg r:0.6009 Best avg r: 0.6299
01:57:06,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:58:36,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:06,814 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2180
en_de Dev loss: 0.9488 r:0.1887
en_zh Dev loss: 0.7911 r:0.4639
ro_en Dev loss: 0.3740 r:0.8139
et_en Dev loss: 0.4269 r:0.6812
si_en Dev loss: 0.9129 r:0.5610
ne_en Dev loss: 0.5879 r:0.7395
ru_en Dev loss: 0.4773 r:0.7316
Current avg r:0.5971 Best avg r: 0.6299
02:04:37,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:07,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:37,901 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2277
en_de Dev loss: 0.9077 r:0.2071
en_zh Dev loss: 0.7714 r:0.4618
ro_en Dev loss: 0.3360 r:0.8166
et_en Dev loss: 0.4458 r:0.6892
si_en Dev loss: 0.7517 r:0.5822
ne_en Dev loss: 0.4777 r:0.7331
ru_en Dev loss: 0.4266 r:0.7418
Current avg r:0.6045 Best avg r: 0.6299
02:12:08,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:38,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:15:08,884 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2272
en_de Dev loss: 0.9463 r:0.2006
en_zh Dev loss: 0.8078 r:0.4658
ro_en Dev loss: 0.3705 r:0.8164
et_en Dev loss: 0.4632 r:0.6865
si_en Dev loss: 0.7799 r:0.5751
ne_en Dev loss: 0.4743 r:0.7349
ru_en Dev loss: 0.4756 r:0.7310
Current avg r:0.6015 Best avg r: 0.6299
02:19:41,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:11,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:41,331 root INFO Epoch 6 Global steps: 63700 Train loss: 0.1935
en_de Dev loss: 0.9400 r:0.2034
en_zh Dev loss: 0.7964 r:0.4625
ro_en Dev loss: 0.3561 r:0.8161
et_en Dev loss: 0.4497 r:0.6858
si_en Dev loss: 0.7751 r:0.5742
ne_en Dev loss: 0.4818 r:0.7348
ru_en Dev loss: 0.4614 r:0.7336
Current avg r:0.6015 Best avg r: 0.6299
02:27:11,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:28:42,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:30:12,141 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2070
en_de Dev loss: 0.9591 r:0.2110
en_zh Dev loss: 0.8346 r:0.4554
ro_en Dev loss: 0.3717 r:0.8142
et_en Dev loss: 0.4627 r:0.6772
si_en Dev loss: 0.8801 r:0.5599
ne_en Dev loss: 0.5594 r:0.7352
ru_en Dev loss: 0.4642 r:0.7409
Current avg r:0.5991 Best avg r: 0.6299
02:34:42,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:12,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:37:43,40 root INFO Epoch 6 Global steps: 65100 Train loss: 0.1973
en_de Dev loss: 0.9259 r:0.2080
en_zh Dev loss: 0.7986 r:0.4648
ro_en Dev loss: 0.3473 r:0.8173
et_en Dev loss: 0.4593 r:0.6905
si_en Dev loss: 0.7706 r:0.5760
ne_en Dev loss: 0.4434 r:0.7343
ru_en Dev loss: 0.4388 r:0.7450
Current avg r:0.6051 Best avg r: 0.6299
02:42:13,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:43,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:13,914 root INFO Epoch 6 Global steps: 65800 Train loss: 0.1950
en_de Dev loss: 0.9214 r:0.2119
en_zh Dev loss: 0.8036 r:0.4612
ro_en Dev loss: 0.3597 r:0.8169
et_en Dev loss: 0.4497 r:0.6787
si_en Dev loss: 0.8515 r:0.5650
ne_en Dev loss: 0.5080 r:0.7379
ru_en Dev loss: 0.4229 r:0.7535
Current avg r:0.6036 Best avg r: 0.6299
02:49:44,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:14,808 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:45,1 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2056
en_de Dev loss: 0.9560 r:0.1975
en_zh Dev loss: 0.8201 r:0.4658
ro_en Dev loss: 0.3844 r:0.8109
et_en Dev loss: 0.4656 r:0.6777
si_en Dev loss: 0.8450 r:0.5643
ne_en Dev loss: 0.6104 r:0.7279
ru_en Dev loss: 0.4796 r:0.7370
Current avg r:0.5973 Best avg r: 0.6299
02:57:15,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:58:45,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:16,114 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2106
en_de Dev loss: 0.9406 r:0.1975
en_zh Dev loss: 0.8096 r:0.4595
ro_en Dev loss: 0.3597 r:0.8131
et_en Dev loss: 0.4561 r:0.6844
si_en Dev loss: 0.8234 r:0.5706
ne_en Dev loss: 0.4816 r:0.7357
ru_en Dev loss: 0.4544 r:0.7420
Current avg r:0.6004 Best avg r: 0.6299
03:04:46,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:06:16,962 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:07:47,169 root INFO Epoch 6 Global steps: 67900 Train loss: 0.1943
en_de Dev loss: 0.9563 r:0.1973
en_zh Dev loss: 0.8094 r:0.4523
ro_en Dev loss: 0.3731 r:0.8103
et_en Dev loss: 0.4607 r:0.6739
si_en Dev loss: 0.9078 r:0.5645
ne_en Dev loss: 0.6113 r:0.7303
ru_en Dev loss: 0.4488 r:0.7395
Current avg r:0.5954 Best avg r: 0.6299
03:12:17,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:47,975 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:15:18,158 root INFO Epoch 6 Global steps: 68600 Train loss: 0.1984
en_de Dev loss: 0.9696 r:0.2028
en_zh Dev loss: 0.8058 r:0.4611
ro_en Dev loss: 0.3950 r:0.8129
et_en Dev loss: 0.4504 r:0.6695
si_en Dev loss: 0.8784 r:0.5683
ne_en Dev loss: 0.6111 r:0.7248
ru_en Dev loss: 0.4805 r:0.7457
Current avg r:0.5979 Best avg r: 0.6299
03:19:48,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:19,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:49,254 root INFO Epoch 6 Global steps: 69300 Train loss: 0.1977
en_de Dev loss: 0.9080 r:0.2065
en_zh Dev loss: 0.7780 r:0.4507
ro_en Dev loss: 0.3517 r:0.8110
et_en Dev loss: 0.4590 r:0.6699
si_en Dev loss: 0.8158 r:0.5658
ne_en Dev loss: 0.5522 r:0.7297
ru_en Dev loss: 0.4409 r:0.7363
Current avg r:0.5957 Best avg r: 0.6299
03:27:20,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:50,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:20,452 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1897
en_de Dev loss: 0.9517 r:0.2153
en_zh Dev loss: 0.8038 r:0.4579
ro_en Dev loss: 0.3856 r:0.8099
et_en Dev loss: 0.4826 r:0.6651
si_en Dev loss: 0.8402 r:0.5662
ne_en Dev loss: 0.4817 r:0.7310
ru_en Dev loss: 0.5255 r:0.7143
Current avg r:0.5942 Best avg r: 0.6299
03:34:51,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:21,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:37:51,543 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1967
en_de Dev loss: 0.9407 r:0.2100
en_zh Dev loss: 0.7866 r:0.4720
ro_en Dev loss: 0.3772 r:0.8159
et_en Dev loss: 0.4665 r:0.6755
si_en Dev loss: 0.7700 r:0.5802
ne_en Dev loss: 0.4213 r:0.7421
ru_en Dev loss: 0.4767 r:0.7411
Current avg r:0.6052 Best avg r: 0.6299
03:42:22,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:52,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:22,622 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1908
en_de Dev loss: 0.9585 r:0.1932
en_zh Dev loss: 0.8126 r:0.4601
ro_en Dev loss: 0.3769 r:0.8125
et_en Dev loss: 0.4741 r:0.6645
si_en Dev loss: 0.8081 r:0.5687
ne_en Dev loss: 0.5482 r:0.7317
ru_en Dev loss: 0.5457 r:0.7056
Current avg r:0.5909 Best avg r: 0.6299
03:49:53,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:23,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:53,767 root INFO Epoch 6 Global steps: 72100 Train loss: 0.1920
en_de Dev loss: 0.9279 r:0.1987
en_zh Dev loss: 0.7821 r:0.4619
ro_en Dev loss: 0.3575 r:0.8127
et_en Dev loss: 0.4802 r:0.6658
si_en Dev loss: 0.7972 r:0.5722
ne_en Dev loss: 0.4870 r:0.7301
ru_en Dev loss: 0.4501 r:0.7379
Current avg r:0.5971 Best avg r: 0.6299
03:57:24,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:58:54,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:24,856 root INFO Epoch 6 Global steps: 72800 Train loss: 0.1972
en_de Dev loss: 0.9699 r:0.2055
en_zh Dev loss: 0.8069 r:0.4621
ro_en Dev loss: 0.3872 r:0.8136
et_en Dev loss: 0.4647 r:0.6656
si_en Dev loss: 0.8924 r:0.5604
ne_en Dev loss: 0.6062 r:0.7291
ru_en Dev loss: 0.5569 r:0.7086
Current avg r:0.5921 Best avg r: 0.6299
04:04:55,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:06:25,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:07:55,916 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1923
en_de Dev loss: 0.9549 r:0.1992
en_zh Dev loss: 0.8121 r:0.4605
ro_en Dev loss: 0.4131 r:0.8083
et_en Dev loss: 0.4769 r:0.6532
si_en Dev loss: 1.0388 r:0.5462
ne_en Dev loss: 0.6684 r:0.7286
ru_en Dev loss: 0.4681 r:0.7371
Current avg r:0.5905 Best avg r: 0.6299
04:12:28,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:13:58,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:28,886 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1780
en_de Dev loss: 0.9302 r:0.2073
en_zh Dev loss: 0.7900 r:0.4703
ro_en Dev loss: 0.3571 r:0.8193
et_en Dev loss: 0.4766 r:0.6717
si_en Dev loss: 0.7815 r:0.5751
ne_en Dev loss: 0.4851 r:0.7321
ru_en Dev loss: 0.4594 r:0.7339
Current avg r:0.6014 Best avg r: 0.6299
04:19:59,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:29,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:22:59,999 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1767
en_de Dev loss: 0.9995 r:0.2169
en_zh Dev loss: 0.8649 r:0.4706
ro_en Dev loss: 0.4207 r:0.8146
et_en Dev loss: 0.4891 r:0.6587
si_en Dev loss: 0.9271 r:0.5607
ne_en Dev loss: 0.6131 r:0.7233
ru_en Dev loss: 0.5909 r:0.7009
Current avg r:0.5922 Best avg r: 0.6299
04:27:30,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:00,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:31,108 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1676
en_de Dev loss: 0.9333 r:0.2169
en_zh Dev loss: 0.7916 r:0.4604
ro_en Dev loss: 0.3664 r:0.8152
et_en Dev loss: 0.4647 r:0.6657
si_en Dev loss: 0.8666 r:0.5637
ne_en Dev loss: 0.4636 r:0.7284
ru_en Dev loss: 0.4311 r:0.7489
Current avg r:0.5999 Best avg r: 0.6299
04:35:01,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:32,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:02,308 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1700
en_de Dev loss: 0.9384 r:0.2160
en_zh Dev loss: 0.8256 r:0.4532
ro_en Dev loss: 0.3675 r:0.8161
et_en Dev loss: 0.4705 r:0.6608
si_en Dev loss: 0.9230 r:0.5581
ne_en Dev loss: 0.5735 r:0.7264
ru_en Dev loss: 0.4599 r:0.7407
Current avg r:0.5959 Best avg r: 0.6299
04:42:33,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:03,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:33,379 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1679
en_de Dev loss: 0.9626 r:0.2203
en_zh Dev loss: 0.8290 r:0.4507
ro_en Dev loss: 0.4186 r:0.8087
et_en Dev loss: 0.4685 r:0.6567
si_en Dev loss: 0.9551 r:0.5553
ne_en Dev loss: 0.6096 r:0.7284
ru_en Dev loss: 0.5401 r:0.7208
Current avg r:0.5916 Best avg r: 0.6299
04:50:04,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:51:34,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:04,450 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1680
en_de Dev loss: 0.9605 r:0.2173
en_zh Dev loss: 0.8346 r:0.4476
ro_en Dev loss: 0.3934 r:0.8086
et_en Dev loss: 0.4909 r:0.6521
si_en Dev loss: 0.9347 r:0.5462
ne_en Dev loss: 0.5572 r:0.7211
ru_en Dev loss: 0.5229 r:0.7214
Current avg r:0.5878 Best avg r: 0.6299
04:57:34,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:59:05,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:00:35,325 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1790
en_de Dev loss: 0.9676 r:0.2029
en_zh Dev loss: 0.8242 r:0.4526
ro_en Dev loss: 0.3772 r:0.8123
et_en Dev loss: 0.4895 r:0.6571
si_en Dev loss: 0.8674 r:0.5636
ne_en Dev loss: 0.5324 r:0.7237
ru_en Dev loss: 0.4786 r:0.7341
Current avg r:0.5923 Best avg r: 0.6299
05:05:05,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:36,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:06,317 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1725
en_de Dev loss: 0.9679 r:0.2002
en_zh Dev loss: 0.8269 r:0.4539
ro_en Dev loss: 0.4219 r:0.8085
et_en Dev loss: 0.4917 r:0.6511
si_en Dev loss: 0.9161 r:0.5489
ne_en Dev loss: 0.5369 r:0.7188
ru_en Dev loss: 0.5449 r:0.7128
Current avg r:0.5849 Best avg r: 0.6299
05:12:37,77 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:07,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:37,526 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1651
en_de Dev loss: 0.9390 r:0.2071
en_zh Dev loss: 0.8158 r:0.4523
ro_en Dev loss: 0.3686 r:0.8140
et_en Dev loss: 0.4747 r:0.6632
si_en Dev loss: 0.8430 r:0.5602
ne_en Dev loss: 0.5316 r:0.7268
ru_en Dev loss: 0.4801 r:0.7308
Current avg r:0.5935 Best avg r: 0.6299
05:20:08,196 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:21:38,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:08,641 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1679
en_de Dev loss: 0.9477 r:0.1982
en_zh Dev loss: 0.8174 r:0.4505
ro_en Dev loss: 0.3560 r:0.8117
et_en Dev loss: 0.4757 r:0.6612
si_en Dev loss: 0.8215 r:0.5597
ne_en Dev loss: 0.5171 r:0.7275
ru_en Dev loss: 0.4797 r:0.7231
Current avg r:0.5903 Best avg r: 0.6299
05:27:39,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:29:09,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:39,808 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1609
en_de Dev loss: 0.9809 r:0.2002
en_zh Dev loss: 0.8548 r:0.4557
ro_en Dev loss: 0.3802 r:0.8143
et_en Dev loss: 0.5029 r:0.6625
si_en Dev loss: 0.8686 r:0.5592
ne_en Dev loss: 0.5530 r:0.7309
ru_en Dev loss: 0.5153 r:0.7260
Current avg r:0.5927 Best avg r: 0.6299
05:35:10,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:40,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:11,55 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1713
en_de Dev loss: 0.9316 r:0.1903
en_zh Dev loss: 0.7904 r:0.4555
ro_en Dev loss: 0.3293 r:0.8177
et_en Dev loss: 0.4673 r:0.6724
si_en Dev loss: 0.7759 r:0.5693
ne_en Dev loss: 0.4906 r:0.7358
ru_en Dev loss: 0.4064 r:0.7499
Current avg r:0.5987 Best avg r: 0.6299
05:42:41,797 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:11,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:42,247 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1586
en_de Dev loss: 0.9601 r:0.1955
en_zh Dev loss: 0.8198 r:0.4626
ro_en Dev loss: 0.3584 r:0.8158
et_en Dev loss: 0.4808 r:0.6694
si_en Dev loss: 0.8339 r:0.5651
ne_en Dev loss: 0.5410 r:0.7300
ru_en Dev loss: 0.4487 r:0.7487
Current avg r:0.5982 Best avg r: 0.6299
05:50:13,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:43,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:13,494 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1661
en_de Dev loss: 1.0210 r:0.1944
en_zh Dev loss: 0.8387 r:0.4732
ro_en Dev loss: 0.4292 r:0.8134
et_en Dev loss: 0.5101 r:0.6556
si_en Dev loss: 1.0989 r:0.5395
ne_en Dev loss: 0.8277 r:0.7258
ru_en Dev loss: 0.5486 r:0.7239
Current avg r:0.5894 Best avg r: 0.6299
05:57:44,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:14,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:00:44,587 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1642
en_de Dev loss: 0.9114 r:0.1982
en_zh Dev loss: 0.7742 r:0.4603
ro_en Dev loss: 0.3281 r:0.8171
et_en Dev loss: 0.4690 r:0.6743
si_en Dev loss: 0.8069 r:0.5584
ne_en Dev loss: 0.5321 r:0.7303
ru_en Dev loss: 0.4269 r:0.7440
Current avg r:0.5975 Best avg r: 0.6299
06:05:16,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:06:46,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:17,43 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1410
en_de Dev loss: 0.9751 r:0.1941
en_zh Dev loss: 0.8437 r:0.4579
ro_en Dev loss: 0.3982 r:0.8139
et_en Dev loss: 0.4915 r:0.6674
si_en Dev loss: 0.9281 r:0.5508
ne_en Dev loss: 0.6021 r:0.7259
ru_en Dev loss: 0.5068 r:0.7399
Current avg r:0.5928 Best avg r: 0.6299
06:12:47,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:18,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:48,294 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1447
en_de Dev loss: 0.9359 r:0.1888
en_zh Dev loss: 0.7996 r:0.4662
ro_en Dev loss: 0.3494 r:0.8183
et_en Dev loss: 0.4772 r:0.6731
si_en Dev loss: 0.8288 r:0.5620
ne_en Dev loss: 0.4878 r:0.7348
ru_en Dev loss: 0.4358 r:0.7518
Current avg r:0.5993 Best avg r: 0.6299
06:20:18,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:21:48,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:18,305 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1427
en_de Dev loss: 0.9815 r:0.1939
en_zh Dev loss: 0.8521 r:0.4519
ro_en Dev loss: 0.3849 r:0.8140
et_en Dev loss: 0.4849 r:0.6720
si_en Dev loss: 0.8554 r:0.5617
ne_en Dev loss: 0.5472 r:0.7331
ru_en Dev loss: 0.4985 r:0.7347
Current avg r:0.5945 Best avg r: 0.6299
06:27:48,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:18,122 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:48,103 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1453
en_de Dev loss: 0.9626 r:0.1870
en_zh Dev loss: 0.8302 r:0.4588
ro_en Dev loss: 0.3857 r:0.8107
et_en Dev loss: 0.5209 r:0.6503
si_en Dev loss: 0.9802 r:0.5385
ne_en Dev loss: 0.5800 r:0.7249
ru_en Dev loss: 0.4973 r:0.7202
Current avg r:0.5843 Best avg r: 0.6299
06:35:17,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:47,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:38:17,925 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1522
en_de Dev loss: 0.9617 r:0.1885
en_zh Dev loss: 0.7975 r:0.4591
ro_en Dev loss: 0.3610 r:0.8126
et_en Dev loss: 0.4854 r:0.6644
si_en Dev loss: 0.8705 r:0.5466
ne_en Dev loss: 0.5278 r:0.7186
ru_en Dev loss: 0.4623 r:0.7360
Current avg r:0.5894 Best avg r: 0.6299
06:42:47,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:44:17,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:47,713 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1460
en_de Dev loss: 0.9716 r:0.1760
en_zh Dev loss: 0.7855 r:0.4695
ro_en Dev loss: 0.3745 r:0.8108
et_en Dev loss: 0.4796 r:0.6540
si_en Dev loss: 1.0137 r:0.5314
ne_en Dev loss: 0.6505 r:0.7173
ru_en Dev loss: 0.4799 r:0.7296
Current avg r:0.5841 Best avg r: 0.6299
06:50:17,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:47,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:53:17,633 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1527
en_de Dev loss: 0.9929 r:0.1850
en_zh Dev loss: 0.8186 r:0.4631
ro_en Dev loss: 0.3645 r:0.8213
et_en Dev loss: 0.4830 r:0.6600
si_en Dev loss: 0.9366 r:0.5504
ne_en Dev loss: 0.5997 r:0.7188
ru_en Dev loss: 0.4792 r:0.7348
Current avg r:0.5905 Best avg r: 0.6299
06:57:47,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:59:17,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:00:47,455 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1478
en_de Dev loss: 0.9680 r:0.1744
en_zh Dev loss: 0.7888 r:0.4700
ro_en Dev loss: 0.3542 r:0.8183
et_en Dev loss: 0.5127 r:0.6594
si_en Dev loss: 0.9010 r:0.5439
ne_en Dev loss: 0.5569 r:0.7205
ru_en Dev loss: 0.4706 r:0.7325
Current avg r:0.5884 Best avg r: 0.6299
07:05:17,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:06:47,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:17,353 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1505
en_de Dev loss: 1.0037 r:0.1713
en_zh Dev loss: 0.7956 r:0.4699
ro_en Dev loss: 0.3882 r:0.8160
et_en Dev loss: 0.4962 r:0.6582
si_en Dev loss: 0.9088 r:0.5479
ne_en Dev loss: 0.5812 r:0.7242
ru_en Dev loss: 0.4819 r:0.7340
Current avg r:0.5888 Best avg r: 0.6299
07:12:47,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:14:17,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:47,195 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1423
en_de Dev loss: 0.9675 r:0.1788
en_zh Dev loss: 0.7775 r:0.4639
ro_en Dev loss: 0.3807 r:0.8157
et_en Dev loss: 0.4751 r:0.6632
si_en Dev loss: 0.8901 r:0.5505
ne_en Dev loss: 0.5835 r:0.7219
ru_en Dev loss: 0.4480 r:0.7413
Current avg r:0.5908 Best avg r: 0.6299
07:20:16,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:21:46,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:23:16,838 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1414
en_de Dev loss: 0.9763 r:0.1823
en_zh Dev loss: 0.8119 r:0.4589
ro_en Dev loss: 0.3842 r:0.8142
et_en Dev loss: 0.4971 r:0.6629
si_en Dev loss: 0.8308 r:0.5580
ne_en Dev loss: 0.5519 r:0.7197
ru_en Dev loss: 0.5037 r:0.7219
Current avg r:0.5883 Best avg r: 0.6299
07:27:46,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:29:16,640 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:46,710 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1433
en_de Dev loss: 0.9704 r:0.1847
en_zh Dev loss: 0.7969 r:0.4639
ro_en Dev loss: 0.3548 r:0.8191
et_en Dev loss: 0.4529 r:0.6739
si_en Dev loss: 0.8214 r:0.5594
ne_en Dev loss: 0.5536 r:0.7216
ru_en Dev loss: 0.4503 r:0.7521
Current avg r:0.5964 Best avg r: 0.6299
07:35:16,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:36:46,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:38:16,710 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1466
en_de Dev loss: 0.9952 r:0.1920
en_zh Dev loss: 0.8398 r:0.4611
ro_en Dev loss: 0.4004 r:0.8167
et_en Dev loss: 0.4661 r:0.6636
si_en Dev loss: 0.9004 r:0.5518
ne_en Dev loss: 0.5756 r:0.7252
ru_en Dev loss: 0.4991 r:0.7457
Current avg r:0.5937 Best avg r: 0.6299
07:42:46,664 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:44:16,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:46,631 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1359
en_de Dev loss: 0.9934 r:0.1947
en_zh Dev loss: 0.8548 r:0.4636
ro_en Dev loss: 0.3873 r:0.8131
et_en Dev loss: 0.4941 r:0.6607
si_en Dev loss: 0.9293 r:0.5448
ne_en Dev loss: 0.5603 r:0.7252
ru_en Dev loss: 0.4665 r:0.7436
Current avg r:0.5922 Best avg r: 0.6299
07:50:16,581 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:51:46,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:53:16,630 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1414
en_de Dev loss: 1.0027 r:0.1821
en_zh Dev loss: 0.8169 r:0.4650
ro_en Dev loss: 0.3901 r:0.8127
et_en Dev loss: 0.4882 r:0.6676
si_en Dev loss: 0.9674 r:0.5473
ne_en Dev loss: 0.6280 r:0.7320
ru_en Dev loss: 0.4525 r:0.7465
Current avg r:0.5933 Best avg r: 0.6299
07:57:48,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:59:18,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:00:48,253 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1257
en_de Dev loss: 1.0038 r:0.1888
en_zh Dev loss: 0.8260 r:0.4639
ro_en Dev loss: 0.3775 r:0.8144
et_en Dev loss: 0.4681 r:0.6703
si_en Dev loss: 0.9829 r:0.5437
ne_en Dev loss: 0.6335 r:0.7296
ru_en Dev loss: 0.4577 r:0.7471
Current avg r:0.5940 Best avg r: 0.6299
08:05:18,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:06:48,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:08:18,305 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1250
en_de Dev loss: 1.0037 r:0.1794
en_zh Dev loss: 0.8004 r:0.4656
ro_en Dev loss: 0.3916 r:0.8147
et_en Dev loss: 0.4563 r:0.6733
si_en Dev loss: 0.9249 r:0.5488
ne_en Dev loss: 0.6746 r:0.7210
ru_en Dev loss: 0.4880 r:0.7395
Current avg r:0.5918 Best avg r: 0.6299
08:12:48,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:14:18,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:15:48,311 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1226
en_de Dev loss: 0.9794 r:0.1873
en_zh Dev loss: 0.8157 r:0.4682
ro_en Dev loss: 0.3959 r:0.8126
et_en Dev loss: 0.4754 r:0.6728
si_en Dev loss: 0.9159 r:0.5509
ne_en Dev loss: 0.5395 r:0.7205
ru_en Dev loss: 0.4983 r:0.7384
Current avg r:0.5930 Best avg r: 0.6299
08:20:18,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:48,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:18,92 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1272
en_de Dev loss: 0.9779 r:0.1826
en_zh Dev loss: 0.8106 r:0.4629
ro_en Dev loss: 0.3807 r:0.8132
et_en Dev loss: 0.4757 r:0.6662
si_en Dev loss: 0.9102 r:0.5437
ne_en Dev loss: 0.5328 r:0.7269
ru_en Dev loss: 0.4565 r:0.7477
Current avg r:0.5919 Best avg r: 0.6299
08:27:48,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:29:17,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:47,978 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1268
en_de Dev loss: 0.9741 r:0.1898
en_zh Dev loss: 0.8060 r:0.4582
ro_en Dev loss: 0.3628 r:0.8162
et_en Dev loss: 0.4461 r:0.6695
si_en Dev loss: 0.9345 r:0.5489
ne_en Dev loss: 0.6449 r:0.7218
ru_en Dev loss: 0.4884 r:0.7288
Current avg r:0.5905 Best avg r: 0.6299
08:35:17,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:47,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:38:17,743 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1215
en_de Dev loss: 0.9634 r:0.1854
en_zh Dev loss: 0.8076 r:0.4559
ro_en Dev loss: 0.3559 r:0.8138
et_en Dev loss: 0.4602 r:0.6669
si_en Dev loss: 0.8414 r:0.5544
ne_en Dev loss: 0.4993 r:0.7222
ru_en Dev loss: 0.4303 r:0.7489
Current avg r:0.5925 Best avg r: 0.6299
08:42:47,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:44:17,603 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:45:47,612 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1281
en_de Dev loss: 0.9472 r:0.1899
en_zh Dev loss: 0.7890 r:0.4589
ro_en Dev loss: 0.3637 r:0.8121
et_en Dev loss: 0.4918 r:0.6694
si_en Dev loss: 0.7939 r:0.5603
ne_en Dev loss: 0.5226 r:0.7239
ru_en Dev loss: 0.4542 r:0.7363
Current avg r:0.5930 Best avg r: 0.6299
08:50:17,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:51:47,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:53:17,453 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1278
en_de Dev loss: 0.9367 r:0.1975
en_zh Dev loss: 0.7736 r:0.4664
ro_en Dev loss: 0.3521 r:0.8154
et_en Dev loss: 0.4731 r:0.6700
si_en Dev loss: 0.8161 r:0.5620
ne_en Dev loss: 0.5644 r:0.7276
ru_en Dev loss: 0.4069 r:0.7584
Current avg r:0.5996 Best avg r: 0.6299
08:57:47,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:59:17,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:00:47,299 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1269
en_de Dev loss: 0.9576 r:0.1881
en_zh Dev loss: 0.7920 r:0.4581
ro_en Dev loss: 0.3562 r:0.8129
et_en Dev loss: 0.4573 r:0.6625
si_en Dev loss: 0.8780 r:0.5531
ne_en Dev loss: 0.5483 r:0.7241
ru_en Dev loss: 0.4585 r:0.7427
Current avg r:0.5916 Best avg r: 0.6299
09:05:17,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:06:47,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:08:17,127 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1237
en_de Dev loss: 1.0347 r:0.2012
en_zh Dev loss: 0.8591 r:0.4504
ro_en Dev loss: 0.3907 r:0.8095
et_en Dev loss: 0.4859 r:0.6597
si_en Dev loss: 0.9315 r:0.5492
ne_en Dev loss: 0.6143 r:0.7223
ru_en Dev loss: 0.4878 r:0.7426
Current avg r:0.5907 Best avg r: 0.6299
09:12:46,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:14:16,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:15:46,854 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1294
en_de Dev loss: 1.0023 r:0.1961
en_zh Dev loss: 0.8585 r:0.4573
ro_en Dev loss: 0.4108 r:0.8089
et_en Dev loss: 0.5013 r:0.6555
si_en Dev loss: 0.9889 r:0.5385
ne_en Dev loss: 0.5992 r:0.7143
ru_en Dev loss: 0.5434 r:0.7228
Current avg r:0.5848 Best avg r: 0.6299
09:20:16,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:21:46,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:23:16,673 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1245
en_de Dev loss: 1.0106 r:0.1972
en_zh Dev loss: 0.8645 r:0.4484
ro_en Dev loss: 0.3648 r:0.8143
et_en Dev loss: 0.4742 r:0.6680
si_en Dev loss: 0.8625 r:0.5528
ne_en Dev loss: 0.5571 r:0.7267
ru_en Dev loss: 0.4931 r:0.7371
Current avg r:0.5921 Best avg r: 0.6299
09:27:46,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:29:16,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:30:46,526 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1222
en_de Dev loss: 1.0020 r:0.2156
en_zh Dev loss: 0.8523 r:0.4495
ro_en Dev loss: 0.3727 r:0.8099
et_en Dev loss: 0.4892 r:0.6539
si_en Dev loss: 0.9311 r:0.5430
ne_en Dev loss: 0.5779 r:0.7259
ru_en Dev loss: 0.4811 r:0.7341
Current avg r:0.5902 Best avg r: 0.6299
09:35:16,545 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:36:46,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:38:16,479 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1204
en_de Dev loss: 0.9877 r:0.2028
en_zh Dev loss: 0.7971 r:0.4647
ro_en Dev loss: 0.3767 r:0.8092
et_en Dev loss: 0.4973 r:0.6651
si_en Dev loss: 0.8844 r:0.5525
ne_en Dev loss: 0.5865 r:0.7203
ru_en Dev loss: 0.4809 r:0.7382
Current avg r:0.5932 Best avg r: 0.6299
09:42:46,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:44:16,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:45:46,405 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1242
en_de Dev loss: 0.9610 r:0.1927
en_zh Dev loss: 0.8129 r:0.4515
ro_en Dev loss: 0.3476 r:0.8129
et_en Dev loss: 0.4743 r:0.6598
si_en Dev loss: 0.9201 r:0.5414
ne_en Dev loss: 0.5715 r:0.7189
ru_en Dev loss: 0.4459 r:0.7414
Current avg r:0.5884 Best avg r: 0.6299
09:50:17,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:51:47,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:53:17,839 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1113
en_de Dev loss: 1.0549 r:0.2049
en_zh Dev loss: 0.8874 r:0.4559
ro_en Dev loss: 0.4212 r:0.8144
et_en Dev loss: 0.4957 r:0.6598
si_en Dev loss: 0.9911 r:0.5475
ne_en Dev loss: 0.6479 r:0.7197
ru_en Dev loss: 0.5584 r:0.7343
Current avg r:0.5909 Best avg r: 0.6299
09:57:47,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:59:17,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:47,714 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1113
en_de Dev loss: 1.0127 r:0.1934
en_zh Dev loss: 0.8627 r:0.4491
ro_en Dev loss: 0.3657 r:0.8160
et_en Dev loss: 0.4656 r:0.6668
si_en Dev loss: 0.9222 r:0.5401
ne_en Dev loss: 0.5714 r:0.7227
ru_en Dev loss: 0.4756 r:0.7416
Current avg r:0.5900 Best avg r: 0.6299
10:05:17,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:06:47,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:08:17,612 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1132
en_de Dev loss: 1.0359 r:0.1930
en_zh Dev loss: 0.8630 r:0.4526
ro_en Dev loss: 0.4082 r:0.8102
et_en Dev loss: 0.4983 r:0.6489
si_en Dev loss: 1.0621 r:0.5339
ne_en Dev loss: 0.6748 r:0.7174
ru_en Dev loss: 0.5369 r:0.7246
Current avg r:0.5829 Best avg r: 0.6299
10:12:47,613 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:17,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:47,478 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1123
en_de Dev loss: 1.0232 r:0.1979
en_zh Dev loss: 0.9173 r:0.4429
ro_en Dev loss: 0.4179 r:0.8070
et_en Dev loss: 0.5028 r:0.6451
si_en Dev loss: 0.9937 r:0.5354
ne_en Dev loss: 0.6230 r:0.7181
ru_en Dev loss: 0.5007 r:0.7332
Current avg r:0.5828 Best avg r: 0.6299
10:20:17,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:47,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:17,428 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1066
en_de Dev loss: 0.9680 r:0.1782
en_zh Dev loss: 0.7949 r:0.4561
ro_en Dev loss: 0.3546 r:0.8139
et_en Dev loss: 0.4640 r:0.6584
si_en Dev loss: 0.8702 r:0.5440
ne_en Dev loss: 0.6789 r:0.7119
ru_en Dev loss: 0.4435 r:0.7396
Current avg r:0.5860 Best avg r: 0.6299
10:27:47,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:17,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:47,335 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1106
en_de Dev loss: 1.0177 r:0.1933
en_zh Dev loss: 0.8426 r:0.4735
ro_en Dev loss: 0.4038 r:0.8144
et_en Dev loss: 0.4943 r:0.6627
si_en Dev loss: 0.9228 r:0.5563
ne_en Dev loss: 0.6268 r:0.7227
ru_en Dev loss: 0.5100 r:0.7429
Current avg r:0.5951 Best avg r: 0.6299
