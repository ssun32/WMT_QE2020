14:54:54,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:08,83 root INFO 
id:en_de cur r: 0.0744 best r: 0.0744
14:55:21,151 root INFO 
id:en_zh cur r: 0.2409 best r: 0.2409
14:55:34,247 root INFO 
id:ro_en cur r: 0.6204 best r: 0.6204
14:56:00,507 root INFO 
id:et_en cur r: 0.4996 best r: 0.4996
14:56:13,678 root INFO 
id:si_en cur r: 0.4171 best r: 0.4171
14:56:26,838 root INFO 
id:ne_en cur r: 0.5272 best r: 0.5272
14:56:39,885 root INFO 
id:ru_en cur r: 0.6057 best r: 0.6057
14:56:39,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:11,567 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
14:58:11,578 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:58:11,585 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:58:11,591 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
14:58:11,599 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
14:58:11,607 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:58:11,613 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:58:24,772 root INFO Epoch 0 Global steps: 700 Train loss: 0.8604
en_de Dev loss: 0.9005 r:0.0942
en_zh Dev loss: 0.7492 r:0.2999
ro_en Dev loss: 0.5828 r:0.6084
et_en Dev loss: 0.5716 r:0.5452
si_en Dev loss: 0.6776 r:0.4618
ne_en Dev loss: 0.6002 r:0.5448
ru_en Dev loss: 0.5591 r:0.6246
Current avg r:0.4541 Best avg r: 0.4541
15:02:58,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:03,979 root INFO 
id:et_en cur r: 0.5154 best r: 0.5154
15:04:17,112 root INFO 
id:si_en cur r: 0.4400 best r: 0.4400
15:04:43,259 root INFO 
id:ru_en cur r: 0.6532 best r: 0.6532
15:04:43,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:14,756 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:06:14,767 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:06:14,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:06:14,782 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:06:14,792 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:06:14,803 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:06:14,810 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:06:27,930 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7629
en_de Dev loss: 0.9677 r:0.0939
en_zh Dev loss: 0.7930 r:0.3130
ro_en Dev loss: 0.6334 r:0.5837
et_en Dev loss: 0.5112 r:0.5804
si_en Dev loss: 0.6987 r:0.4695
ne_en Dev loss: 0.6034 r:0.5337
ru_en Dev loss: 0.4940 r:0.6717
Current avg r:0.4637 Best avg r: 0.4637
15:11:01,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:15,35 root INFO 
id:en_de cur r: 0.1045 best r: 0.1045
15:11:28,95 root INFO 
id:en_zh cur r: 0.2829 best r: 0.2829
15:11:41,200 root INFO 
id:ro_en cur r: 0.6305 best r: 0.6305
15:12:20,524 root INFO 
id:ne_en cur r: 0.5357 best r: 0.5357
15:12:33,540 root INFO 
id:ru_en cur r: 0.6726 best r: 0.6726
15:12:33,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:05,88 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:14:05,98 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:14:05,104 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:14:05,112 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:14:05,118 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:14:05,126 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:14:05,131 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:14:18,266 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7567
en_de Dev loss: 0.9386 r:0.1405
en_zh Dev loss: 0.7843 r:0.3312
ro_en Dev loss: 0.5748 r:0.6492
et_en Dev loss: 0.5084 r:0.6012
si_en Dev loss: 0.7114 r:0.4897
ne_en Dev loss: 0.6101 r:0.5500
ru_en Dev loss: 0.4924 r:0.6976
Current avg r:0.4942 Best avg r: 0.4942
15:18:51,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:18,103 root INFO 
id:en_zh cur r: 0.3413 best r: 0.3413
15:19:57,419 root INFO 
id:et_en cur r: 0.5237 best r: 0.5237
15:20:10,539 root INFO 
id:si_en cur r: 0.4973 best r: 0.4973
15:20:23,666 root INFO 
id:ne_en cur r: 0.6022 best r: 0.6022
15:20:36,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:08,160 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:22:08,168 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:22:08,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:22:08,180 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:22:08,188 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:22:08,194 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:22:08,200 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:22:21,310 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6843
en_de Dev loss: 0.9471 r:0.1450
en_zh Dev loss: 0.7189 r:0.3643
ro_en Dev loss: 0.5016 r:0.6508
et_en Dev loss: 0.4824 r:0.5739
si_en Dev loss: 0.6060 r:0.5174
ne_en Dev loss: 0.5003 r:0.6238
ru_en Dev loss: 0.4998 r:0.6505
Current avg r:0.5037 Best avg r: 0.5037
15:26:56,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:35,388 root INFO 
id:ro_en cur r: 0.6797 best r: 0.6797
15:28:01,615 root INFO 
id:et_en cur r: 0.6160 best r: 0.6160
15:28:27,862 root INFO 
id:ne_en cur r: 0.6276 best r: 0.6276
15:28:40,907 root INFO 
id:ru_en cur r: 0.6946 best r: 0.6946
15:28:40,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:12,527 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:30:12,536 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:30:12,542 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:30:12,548 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:30:12,554 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:30:12,559 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:30:12,564 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:30:25,705 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6951
en_de Dev loss: 0.9429 r:0.1366
en_zh Dev loss: 0.7472 r:0.3448
ro_en Dev loss: 0.4614 r:0.6922
et_en Dev loss: 0.4299 r:0.6438
si_en Dev loss: 0.7123 r:0.5001
ne_en Dev loss: 0.4825 r:0.6327
ru_en Dev loss: 0.4704 r:0.7039
Current avg r:0.5220 Best avg r: 0.5220
15:35:00,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:13,523 root INFO 
id:en_de cur r: 0.1062 best r: 0.1062
15:35:39,681 root INFO 
id:ro_en cur r: 0.6860 best r: 0.6860
15:36:19,22 root INFO 
id:ne_en cur r: 0.6376 best r: 0.6376
15:36:32,48 root INFO 
id:ru_en cur r: 0.6976 best r: 0.6976
15:36:32,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:03,551 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:38:03,559 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:38:03,567 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:38:03,573 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:38:03,580 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:38:03,587 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:38:03,592 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:38:16,716 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6500
en_de Dev loss: 0.9230 r:0.1582
en_zh Dev loss: 0.7326 r:0.3574
ro_en Dev loss: 0.4693 r:0.7049
et_en Dev loss: 0.4246 r:0.6459
si_en Dev loss: 0.7228 r:0.5100
ne_en Dev loss: 0.4925 r:0.6442
ru_en Dev loss: 0.4732 r:0.7107
Current avg r:0.5330 Best avg r: 0.5330
15:42:50,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:30,201 root INFO 
id:ro_en cur r: 0.7180 best r: 0.7180
15:43:56,414 root INFO 
id:et_en cur r: 0.6451 best r: 0.6451
15:44:22,645 root INFO 
id:ne_en cur r: 0.6554 best r: 0.6554
15:44:35,678 root INFO 
id:ru_en cur r: 0.7065 best r: 0.7065
15:44:35,680 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:07,319 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:46:07,328 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:46:07,335 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:46:07,341 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:46:07,348 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:46:07,354 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:46:07,360 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:46:20,472 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6324
en_de Dev loss: 0.9474 r:0.1461
en_zh Dev loss: 0.7885 r:0.3610
ro_en Dev loss: 0.4318 r:0.7318
et_en Dev loss: 0.4047 r:0.6617
si_en Dev loss: 0.7708 r:0.5184
ne_en Dev loss: 0.5013 r:0.6499
ru_en Dev loss: 0.4968 r:0.7143
Current avg r:0.5405 Best avg r: 0.5405
15:50:55,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:08,151 root INFO 
id:en_de cur r: 0.1180 best r: 0.1180
15:51:34,311 root INFO 
id:ro_en cur r: 0.7238 best r: 0.7238
15:52:00,544 root INFO 
id:si_en cur r: 0.4990 best r: 0.4990
15:52:13,674 root INFO 
id:ne_en cur r: 0.6630 best r: 0.6630
15:52:26,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:58,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:53:58,337 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:53:58,343 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:53:58,348 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:53:58,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:53:58,358 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:53:58,364 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:54:11,477 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6271
en_de Dev loss: 0.9665 r:0.1586
en_zh Dev loss: 0.8099 r:0.3641
ro_en Dev loss: 0.4418 r:0.7445
et_en Dev loss: 0.4164 r:0.6533
si_en Dev loss: 0.7120 r:0.5281
ne_en Dev loss: 0.4862 r:0.6560
ru_en Dev loss: 0.4722 r:0.7204
Current avg r:0.5464 Best avg r: 0.5464
15:58:46,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:59,202 root INFO 
id:en_de cur r: 0.1357 best r: 0.1357
15:59:12,267 root INFO 
id:en_zh cur r: 0.3809 best r: 0.3809
15:59:25,377 root INFO 
id:ro_en cur r: 0.7401 best r: 0.7401
15:59:51,590 root INFO 
id:et_en cur r: 0.6455 best r: 0.6455
16:00:04,707 root INFO 
id:si_en cur r: 0.5282 best r: 0.5282
16:00:17,822 root INFO 
id:ne_en cur r: 0.6805 best r: 0.6805
16:00:30,842 root INFO 
id:ru_en cur r: 0.7257 best r: 0.7257
16:00:30,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:02,321 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:02:02,329 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:02:02,335 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:02:02,341 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:02:02,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:02:02,352 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:02:02,356 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:02:15,471 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6068
en_de Dev loss: 0.8782 r:0.1791
en_zh Dev loss: 0.6948 r:0.3943
ro_en Dev loss: 0.3758 r:0.7533
et_en Dev loss: 0.3936 r:0.6689
si_en Dev loss: 0.6267 r:0.5438
ne_en Dev loss: 0.4307 r:0.6788
ru_en Dev loss: 0.3875 r:0.7340
Current avg r:0.5646 Best avg r: 0.5646
16:06:49,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:02,468 root INFO 
id:en_de cur r: 0.1467 best r: 0.1467
16:07:28,599 root INFO 
id:ro_en cur r: 0.7420 best r: 0.7420
16:07:54,825 root INFO 
id:et_en cur r: 0.6558 best r: 0.6558
16:08:07,958 root INFO 
id:si_en cur r: 0.5360 best r: 0.5360
16:08:21,66 root INFO 
id:ne_en cur r: 0.6895 best r: 0.6895
16:08:34,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:05,597 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:10:05,606 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:10:05,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:10:05,618 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:10:05,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:10:05,630 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:10:05,636 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:10:18,779 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5858
en_de Dev loss: 0.8988 r:0.1853
en_zh Dev loss: 0.7091 r:0.3982
ro_en Dev loss: 0.3795 r:0.7579
et_en Dev loss: 0.3790 r:0.6808
si_en Dev loss: 0.6255 r:0.5579
ne_en Dev loss: 0.4035 r:0.7022
ru_en Dev loss: 0.4427 r:0.7288
Current avg r:0.5730 Best avg r: 0.5730
16:14:52,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:06,60 root INFO 
id:en_de cur r: 0.1770 best r: 0.1770
16:15:19,133 root INFO 
id:en_zh cur r: 0.4170 best r: 0.4170
16:15:32,230 root INFO 
id:ro_en cur r: 0.7665 best r: 0.7665
16:15:58,450 root INFO 
id:et_en cur r: 0.6566 best r: 0.6566
16:16:11,565 root INFO 
id:si_en cur r: 0.5540 best r: 0.5540
16:16:24,674 root INFO 
id:ne_en cur r: 0.7089 best r: 0.7089
16:16:37,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:09,222 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:18:09,241 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:18:09,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:18:09,260 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:18:09,271 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:18:09,282 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:18:09,292 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:18:22,404 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5597
en_de Dev loss: 0.9064 r:0.2153
en_zh Dev loss: 0.7069 r:0.4284
ro_en Dev loss: 0.3952 r:0.7701
et_en Dev loss: 0.4148 r:0.6719
si_en Dev loss: 0.6587 r:0.5624
ne_en Dev loss: 0.4347 r:0.7057
ru_en Dev loss: 0.4842 r:0.7293
Current avg r:0.5833 Best avg r: 0.5833
16:22:56,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:09,517 root INFO 
id:en_de cur r: 0.1842 best r: 0.1842
16:23:35,683 root INFO 
id:ro_en cur r: 0.7760 best r: 0.7760
16:24:01,899 root INFO 
id:et_en cur r: 0.6711 best r: 0.6711
16:24:15,47 root INFO 
id:si_en cur r: 0.5820 best r: 0.5820
16:24:28,163 root INFO 
id:ne_en cur r: 0.7192 best r: 0.7192
16:24:41,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:12,893 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:26:12,906 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:26:12,913 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:26:12,920 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:26:12,926 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:26:12,933 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:26:12,939 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:26:26,66 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5856
en_de Dev loss: 0.8652 r:0.2175
en_zh Dev loss: 0.6789 r:0.4263
ro_en Dev loss: 0.3530 r:0.7834
et_en Dev loss: 0.3805 r:0.6878
si_en Dev loss: 0.5929 r:0.5763
ne_en Dev loss: 0.3867 r:0.7176
ru_en Dev loss: 0.4240 r:0.7347
Current avg r:0.5919 Best avg r: 0.5919
16:31:00,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:40,5 root INFO 
id:ro_en cur r: 0.7793 best r: 0.7793
16:32:19,391 root INFO 
id:ne_en cur r: 0.7244 best r: 0.7244
16:32:32,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:03,993 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5513
en_de Dev loss: 0.8770 r:0.1999
en_zh Dev loss: 0.7053 r:0.4361
ro_en Dev loss: 0.3450 r:0.7908
et_en Dev loss: 0.3778 r:0.6858
si_en Dev loss: 0.6092 r:0.5749
ne_en Dev loss: 0.3852 r:0.7205
ru_en Dev loss: 0.4686 r:0.7298
Current avg r:0.5911 Best avg r: 0.5919
16:38:38,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:51,503 root INFO 
id:en_de cur r: 0.1973 best r: 0.1973
16:40:10,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:41,558 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5521
en_de Dev loss: 0.9124 r:0.2213
en_zh Dev loss: 0.7825 r:0.4241
ro_en Dev loss: 0.4190 r:0.7766
et_en Dev loss: 0.4229 r:0.6700
si_en Dev loss: 0.7608 r:0.5593
ne_en Dev loss: 0.4672 r:0.7070
ru_en Dev loss: 0.5099 r:0.7150
Current avg r:0.5819 Best avg r: 0.5919
16:46:16,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:42,176 root INFO 
id:en_zh cur r: 0.4253 best r: 0.4253
16:46:55,285 root INFO 
id:ro_en cur r: 0.7821 best r: 0.7821
16:47:21,510 root INFO 
id:et_en cur r: 0.6764 best r: 0.6764
16:47:47,764 root INFO 
id:ne_en cur r: 0.7276 best r: 0.7276
16:48:00,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:32,346 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:49:32,358 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:49:32,366 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:49:32,373 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:49:32,378 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:49:32,385 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:49:32,391 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:49:45,504 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5444
en_de Dev loss: 0.8616 r:0.2178
en_zh Dev loss: 0.7062 r:0.4385
ro_en Dev loss: 0.3531 r:0.7862
et_en Dev loss: 0.3829 r:0.6886
si_en Dev loss: 0.6637 r:0.5734
ne_en Dev loss: 0.4031 r:0.7218
ru_en Dev loss: 0.4554 r:0.7291
Current avg r:0.5936 Best avg r: 0.5936
16:54:21,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:35,10 root INFO 
id:en_de cur r: 0.2411 best r: 0.2411
16:54:48,87 root INFO 
id:en_zh cur r: 0.4410 best r: 0.4410
16:55:01,204 root INFO 
id:ro_en cur r: 0.7998 best r: 0.7998
16:55:27,452 root INFO 
id:et_en cur r: 0.6929 best r: 0.6929
16:55:53,698 root INFO 
id:ne_en cur r: 0.7443 best r: 0.7443
16:56:06,743 root INFO 
id:ru_en cur r: 0.7339 best r: 0.7339
16:56:06,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:38,479 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:57:38,486 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:57:38,492 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:57:38,497 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:57:38,502 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:57:38,507 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:57:38,512 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:57:51,709 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5247
en_de Dev loss: 0.8421 r:0.2414
en_zh Dev loss: 0.6637 r:0.4508
ro_en Dev loss: 0.3197 r:0.8001
et_en Dev loss: 0.3866 r:0.6987
si_en Dev loss: 0.5753 r:0.5974
ne_en Dev loss: 0.3580 r:0.7424
ru_en Dev loss: 0.3878 r:0.7430
Current avg r:0.6105 Best avg r: 0.6105
17:02:25,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:51,910 root INFO 
id:en_zh cur r: 0.4478 best r: 0.4478
17:03:05,16 root INFO 
id:ro_en cur r: 0.8014 best r: 0.8014
17:03:44,343 root INFO 
id:ne_en cur r: 0.7445 best r: 0.7445
17:03:57,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:28,915 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5320
en_de Dev loss: 0.8668 r:0.2296
en_zh Dev loss: 0.7061 r:0.4482
ro_en Dev loss: 0.3528 r:0.7989
et_en Dev loss: 0.4093 r:0.6909
si_en Dev loss: 0.6324 r:0.5915
ne_en Dev loss: 0.3767 r:0.7420
ru_en Dev loss: 0.4450 r:0.7384
Current avg r:0.6056 Best avg r: 0.6105
17:10:03,28 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:42,251 root INFO 
id:ro_en cur r: 0.8014 best r: 0.8014
17:11:34,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:06,100 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5083
en_de Dev loss: 0.8802 r:0.2396
en_zh Dev loss: 0.7488 r:0.4344
ro_en Dev loss: 0.3721 r:0.7986
et_en Dev loss: 0.4077 r:0.6889
si_en Dev loss: 0.7816 r:0.5766
ne_en Dev loss: 0.4850 r:0.7265
ru_en Dev loss: 0.5134 r:0.7226
Current avg r:0.5982 Best avg r: 0.6105
17:17:39,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:19,103 root INFO 
id:ro_en cur r: 0.8054 best r: 0.8054
17:19:11,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:42,975 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4870
en_de Dev loss: 0.9020 r:0.2510
en_zh Dev loss: 0.8156 r:0.4351
ro_en Dev loss: 0.4035 r:0.7972
et_en Dev loss: 0.4236 r:0.6889
si_en Dev loss: 0.7140 r:0.5809
ne_en Dev loss: 0.4992 r:0.7241
ru_en Dev loss: 0.5232 r:0.7225
Current avg r:0.6000 Best avg r: 0.6105
17:25:16,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:35,481 root INFO 
id:ne_en cur r: 0.7491 best r: 0.7491
17:26:48,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:20,58 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4859
en_de Dev loss: 0.8388 r:0.2391
en_zh Dev loss: 0.6899 r:0.4520
ro_en Dev loss: 0.3245 r:0.8042
et_en Dev loss: 0.3955 r:0.6894
si_en Dev loss: 0.6864 r:0.5856
ne_en Dev loss: 0.4235 r:0.7424
ru_en Dev loss: 0.4074 r:0.7446
Current avg r:0.6082 Best avg r: 0.6105
17:32:53,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:06,881 root INFO 
id:en_de cur r: 0.2444 best r: 0.2444
17:33:19,934 root INFO 
id:en_zh cur r: 0.4553 best r: 0.4553
17:33:33,36 root INFO 
id:ro_en cur r: 0.8105 best r: 0.8105
17:34:12,372 root INFO 
id:ne_en cur r: 0.7512 best r: 0.7512
17:34:25,391 root INFO 
id:ru_en cur r: 0.7404 best r: 0.7404
17:34:25,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:56,933 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
17:35:56,945 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:35:56,952 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:35:56,959 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
17:35:56,966 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
17:35:56,974 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:35:56,982 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:36:10,91 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4846
en_de Dev loss: 0.8499 r:0.2589
en_zh Dev loss: 0.6850 r:0.4604
ro_en Dev loss: 0.3339 r:0.8051
et_en Dev loss: 0.4265 r:0.6855
si_en Dev loss: 0.6465 r:0.5879
ne_en Dev loss: 0.3779 r:0.7447
ru_en Dev loss: 0.4213 r:0.7453
Current avg r:0.6125 Best avg r: 0.6125
17:40:43,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:15,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:46,996 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4997
en_de Dev loss: 0.8655 r:0.2536
en_zh Dev loss: 0.7103 r:0.4483
ro_en Dev loss: 0.3601 r:0.8024
et_en Dev loss: 0.4453 r:0.6642
si_en Dev loss: 0.7479 r:0.5802
ne_en Dev loss: 0.4638 r:0.7363
ru_en Dev loss: 0.4882 r:0.7213
Current avg r:0.6009 Best avg r: 0.6125
17:48:21,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:34,380 root INFO 
id:en_de cur r: 0.2617 best r: 0.2617
17:48:47,443 root INFO 
id:en_zh cur r: 0.4723 best r: 0.4723
17:49:26,755 root INFO 
id:si_en cur r: 0.5894 best r: 0.5894
17:49:52,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:24,468 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4806
en_de Dev loss: 0.8550 r:0.2582
en_zh Dev loss: 0.7038 r:0.4715
ro_en Dev loss: 0.3293 r:0.8090
et_en Dev loss: 0.4321 r:0.6766
si_en Dev loss: 0.6703 r:0.5965
ne_en Dev loss: 0.4529 r:0.7451
ru_en Dev loss: 0.4870 r:0.7245
Current avg r:0.6116 Best avg r: 0.6125
17:55:59,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:17,877 root INFO 
id:ne_en cur r: 0.7533 best r: 0.7533
17:57:30,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:02,420 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4880
en_de Dev loss: 0.8402 r:0.2549
en_zh Dev loss: 0.7070 r:0.4565
ro_en Dev loss: 0.3616 r:0.8114
et_en Dev loss: 0.4343 r:0.6747
si_en Dev loss: 0.7348 r:0.5892
ne_en Dev loss: 0.4780 r:0.7515
ru_en Dev loss: 0.4642 r:0.7335
Current avg r:0.6103 Best avg r: 0.6125
18:03:36,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:15,972 root INFO 
id:ro_en cur r: 0.8126 best r: 0.8126
18:05:08,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:39,890 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4809
en_de Dev loss: 0.8459 r:0.2534
en_zh Dev loss: 0.7066 r:0.4665
ro_en Dev loss: 0.3391 r:0.8127
et_en Dev loss: 0.4319 r:0.6754
si_en Dev loss: 0.7365 r:0.5924
ne_en Dev loss: 0.4321 r:0.7519
ru_en Dev loss: 0.4998 r:0.7216
Current avg r:0.6105 Best avg r: 0.6125
18:11:14,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:40,198 root INFO 
id:en_zh cur r: 0.4845 best r: 0.4845
18:11:53,307 root INFO 
id:ro_en cur r: 0.8195 best r: 0.8195
18:12:19,510 root INFO 
id:si_en cur r: 0.6037 best r: 0.6037
18:12:32,629 root INFO 
id:ne_en cur r: 0.7585 best r: 0.7585
18:12:45,653 root INFO 
id:ru_en cur r: 0.7448 best r: 0.7448
18:12:45,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:17,207 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
18:14:17,218 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
18:14:17,224 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
18:14:17,232 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
18:14:17,242 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
18:14:17,249 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
18:14:17,256 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
18:14:30,374 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4742
en_de Dev loss: 0.8390 r:0.2539
en_zh Dev loss: 0.6483 r:0.4785
ro_en Dev loss: 0.2940 r:0.8192
et_en Dev loss: 0.4273 r:0.6876
si_en Dev loss: 0.6390 r:0.6090
ne_en Dev loss: 0.3615 r:0.7544
ru_en Dev loss: 0.4262 r:0.7387
Current avg r:0.6202 Best avg r: 0.6202
18:19:05,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:36,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:08,72 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4848
en_de Dev loss: 0.8483 r:0.2554
en_zh Dev loss: 0.7459 r:0.4573
ro_en Dev loss: 0.3571 r:0.8109
et_en Dev loss: 0.4547 r:0.6694
si_en Dev loss: 0.7249 r:0.5866
ne_en Dev loss: 0.4182 r:0.7510
ru_en Dev loss: 0.4964 r:0.7282
Current avg r:0.6084 Best avg r: 0.6202
18:26:42,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:22,170 root INFO 
id:ro_en cur r: 0.8210 best r: 0.8210
18:28:14,599 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:46,299 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4416
en_de Dev loss: 0.8364 r:0.2522
en_zh Dev loss: 0.6915 r:0.4705
ro_en Dev loss: 0.3313 r:0.8202
et_en Dev loss: 0.4275 r:0.6770
si_en Dev loss: 0.7301 r:0.6005
ne_en Dev loss: 0.4305 r:0.7561
ru_en Dev loss: 0.4897 r:0.7312
Current avg r:0.6154 Best avg r: 0.6202
18:34:21,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:52,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:24,161 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4809
en_de Dev loss: 0.8446 r:0.2490
en_zh Dev loss: 0.7181 r:0.4585
ro_en Dev loss: 0.3538 r:0.8105
et_en Dev loss: 0.4731 r:0.6595
si_en Dev loss: 0.7151 r:0.5898
ne_en Dev loss: 0.4804 r:0.7460
ru_en Dev loss: 0.5138 r:0.7116
Current avg r:0.6036 Best avg r: 0.6202
18:41:59,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:38,373 root INFO 
id:ro_en cur r: 0.8215 best r: 0.8215
18:43:30,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:02,253 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4284
en_de Dev loss: 0.8434 r:0.2445
en_zh Dev loss: 0.7192 r:0.4538
ro_en Dev loss: 0.3144 r:0.8184
et_en Dev loss: 0.4959 r:0.6600
si_en Dev loss: 0.7150 r:0.5907
ne_en Dev loss: 0.4498 r:0.7445
ru_en Dev loss: 0.5015 r:0.6984
Current avg r:0.6015 Best avg r: 0.6202
18:49:38,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:10,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:41,793 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4371
en_de Dev loss: 0.8372 r:0.2570
en_zh Dev loss: 0.6884 r:0.4711
ro_en Dev loss: 0.3120 r:0.8183
et_en Dev loss: 0.4689 r:0.6608
si_en Dev loss: 0.6610 r:0.5910
ne_en Dev loss: 0.3866 r:0.7520
ru_en Dev loss: 0.3982 r:0.7490
Current avg r:0.6142 Best avg r: 0.6202
18:57:15,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:54,953 root INFO 
id:ro_en cur r: 0.8233 best r: 0.8233
18:58:47,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:18,897 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4339
en_de Dev loss: 0.9039 r:0.2201
en_zh Dev loss: 0.7894 r:0.4564
ro_en Dev loss: 0.3515 r:0.8186
et_en Dev loss: 0.4998 r:0.6514
si_en Dev loss: 0.7383 r:0.5909
ne_en Dev loss: 0.3992 r:0.7503
ru_en Dev loss: 0.5410 r:0.7123
Current avg r:0.6000 Best avg r: 0.6202
19:04:52,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:24,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:55,645 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4354
en_de Dev loss: 0.8632 r:0.2382
en_zh Dev loss: 0.7430 r:0.4548
ro_en Dev loss: 0.3688 r:0.8182
et_en Dev loss: 0.4713 r:0.6527
si_en Dev loss: 0.7885 r:0.5928
ne_en Dev loss: 0.4632 r:0.7522
ru_en Dev loss: 0.5005 r:0.7302
Current avg r:0.6056 Best avg r: 0.6202
19:12:29,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:01,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:32,732 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4211
en_de Dev loss: 0.8828 r:0.2336
en_zh Dev loss: 0.7908 r:0.4415
ro_en Dev loss: 0.4322 r:0.8086
et_en Dev loss: 0.5117 r:0.6403
si_en Dev loss: 0.8900 r:0.5804
ne_en Dev loss: 0.5802 r:0.7466
ru_en Dev loss: 0.5601 r:0.7139
Current avg r:0.5950 Best avg r: 0.6202
19:20:06,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:38,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:09,618 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4104
en_de Dev loss: 0.8670 r:0.1937
en_zh Dev loss: 0.7407 r:0.4509
ro_en Dev loss: 0.3603 r:0.8108
et_en Dev loss: 0.5030 r:0.6525
si_en Dev loss: 0.6732 r:0.5942
ne_en Dev loss: 0.3828 r:0.7536
ru_en Dev loss: 0.4698 r:0.7218
Current avg r:0.5968 Best avg r: 0.6202
19:27:44,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:15,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:47,430 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4365
en_de Dev loss: 0.8685 r:0.2231
en_zh Dev loss: 0.7257 r:0.4612
ro_en Dev loss: 0.3631 r:0.8165
et_en Dev loss: 0.5006 r:0.6609
si_en Dev loss: 0.7118 r:0.5995
ne_en Dev loss: 0.4637 r:0.7430
ru_en Dev loss: 0.4433 r:0.7373
Current avg r:0.6059 Best avg r: 0.6202
19:35:22,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:53,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:25,128 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4245
en_de Dev loss: 0.8758 r:0.2038
en_zh Dev loss: 0.7242 r:0.4708
ro_en Dev loss: 0.3936 r:0.8101
et_en Dev loss: 0.5319 r:0.6498
si_en Dev loss: 0.7018 r:0.6003
ne_en Dev loss: 0.5544 r:0.7440
ru_en Dev loss: 0.5223 r:0.7106
Current avg r:0.5985 Best avg r: 0.6202
19:42:58,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:30,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:46:01,932 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4045
en_de Dev loss: 0.8516 r:0.2262
en_zh Dev loss: 0.7084 r:0.4659
ro_en Dev loss: 0.3685 r:0.8139
et_en Dev loss: 0.4613 r:0.6674
si_en Dev loss: 0.7268 r:0.6041
ne_en Dev loss: 0.4880 r:0.7479
ru_en Dev loss: 0.4664 r:0.7311
Current avg r:0.6081 Best avg r: 0.6202
19:50:35,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:41,208 root INFO 
id:si_en cur r: 0.6137 best r: 0.6137
19:51:54,326 root INFO 
id:ne_en cur r: 0.7618 best r: 0.7618
19:52:07,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:38,873 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3902
en_de Dev loss: 0.8506 r:0.2203
en_zh Dev loss: 0.6955 r:0.4593
ro_en Dev loss: 0.3237 r:0.8159
et_en Dev loss: 0.4730 r:0.6748
si_en Dev loss: 0.6238 r:0.6151
ne_en Dev loss: 0.3947 r:0.7546
ru_en Dev loss: 0.4116 r:0.7397
Current avg r:0.6114 Best avg r: 0.6202
19:58:13,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:45,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:01:16,804 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4176
en_de Dev loss: 0.8453 r:0.2218
en_zh Dev loss: 0.6902 r:0.4662
ro_en Dev loss: 0.3510 r:0.8140
et_en Dev loss: 0.4719 r:0.6700
si_en Dev loss: 0.6878 r:0.6123
ne_en Dev loss: 0.4901 r:0.7529
ru_en Dev loss: 0.4480 r:0.7360
Current avg r:0.6105 Best avg r: 0.6202
20:05:50,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:29,775 root INFO 
id:ro_en cur r: 0.8234 best r: 0.8234
20:07:09,124 root INFO 
id:ne_en cur r: 0.7636 best r: 0.7636
20:07:22,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:53,714 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4032
en_de Dev loss: 0.8520 r:0.2380
en_zh Dev loss: 0.7446 r:0.4590
ro_en Dev loss: 0.3306 r:0.8184
et_en Dev loss: 0.4415 r:0.6791
si_en Dev loss: 0.7107 r:0.6044
ne_en Dev loss: 0.4186 r:0.7608
ru_en Dev loss: 0.4303 r:0.7392
Current avg r:0.6142 Best avg r: 0.6202
20:13:28,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:59,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:31,9 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3889
en_de Dev loss: 0.8500 r:0.2325
en_zh Dev loss: 0.7116 r:0.4637
ro_en Dev loss: 0.3511 r:0.8116
et_en Dev loss: 0.4935 r:0.6648
si_en Dev loss: 0.6895 r:0.6004
ne_en Dev loss: 0.4194 r:0.7539
ru_en Dev loss: 0.4402 r:0.7346
Current avg r:0.6088 Best avg r: 0.6202
20:21:04,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:22:23,473 root INFO 
id:ne_en cur r: 0.7654 best r: 0.7654
20:22:36,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:08,7 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3982
en_de Dev loss: 0.8538 r:0.2507
en_zh Dev loss: 0.7473 r:0.4709
ro_en Dev loss: 0.3433 r:0.8157
et_en Dev loss: 0.4785 r:0.6690
si_en Dev loss: 0.7330 r:0.6090
ne_en Dev loss: 0.4257 r:0.7580
ru_en Dev loss: 0.4399 r:0.7424
Current avg r:0.6165 Best avg r: 0.6202
20:28:42,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:55,594 root INFO 
id:en_de cur r: 0.2723 best r: 0.2723
20:30:13,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:45,505 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3911
en_de Dev loss: 0.8741 r:0.2567
en_zh Dev loss: 0.7760 r:0.4658
ro_en Dev loss: 0.3932 r:0.8110
et_en Dev loss: 0.4734 r:0.6642
si_en Dev loss: 0.8839 r:0.5860
ne_en Dev loss: 0.5950 r:0.7445
ru_en Dev loss: 0.5667 r:0.7066
Current avg r:0.6050 Best avg r: 0.6202
20:36:19,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:32,236 root INFO 
id:en_de cur r: 0.2725 best r: 0.2725
20:37:50,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:22,403 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3994
en_de Dev loss: 0.8599 r:0.2555
en_zh Dev loss: 0.7647 r:0.4645
ro_en Dev loss: 0.3825 r:0.8162
et_en Dev loss: 0.4830 r:0.6767
si_en Dev loss: 0.8056 r:0.5945
ne_en Dev loss: 0.4754 r:0.7546
ru_en Dev loss: 0.5139 r:0.7344
Current avg r:0.6138 Best avg r: 0.6202
20:43:58,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:24,283 root INFO 
id:en_zh cur r: 0.4878 best r: 0.4878
20:44:37,380 root INFO 
id:ro_en cur r: 0.8237 best r: 0.8237
20:45:29,730 root INFO 
id:ru_en cur r: 0.7484 best r: 0.7484
20:45:29,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:01,210 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3617
en_de Dev loss: 0.8536 r:0.2394
en_zh Dev loss: 0.7341 r:0.4778
ro_en Dev loss: 0.3545 r:0.8205
et_en Dev loss: 0.4649 r:0.6778
si_en Dev loss: 0.8406 r:0.5997
ne_en Dev loss: 0.4872 r:0.7583
ru_en Dev loss: 0.4367 r:0.7506
Current avg r:0.6177 Best avg r: 0.6202
20:51:35,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:01,124 root INFO 
id:en_zh cur r: 0.4936 best r: 0.4936
20:52:14,210 root INFO 
id:ro_en cur r: 0.8253 best r: 0.8253
20:52:40,454 root INFO 
id:si_en cur r: 0.6139 best r: 0.6139
20:53:06,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:38,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
20:54:38,50 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
20:54:38,58 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
20:54:38,65 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
20:54:38,73 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
20:54:38,86 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
20:54:38,96 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
20:54:51,203 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3797
en_de Dev loss: 0.8372 r:0.2469
en_zh Dev loss: 0.6764 r:0.4840
ro_en Dev loss: 0.3169 r:0.8236
et_en Dev loss: 0.4703 r:0.6808
si_en Dev loss: 0.6628 r:0.6113
ne_en Dev loss: 0.4246 r:0.7580
ru_en Dev loss: 0.4123 r:0.7465
Current avg r:0.6216 Best avg r: 0.6216
20:59:25,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:56,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:28,32 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3516
en_de Dev loss: 0.8641 r:0.2326
en_zh Dev loss: 0.7470 r:0.4552
ro_en Dev loss: 0.3349 r:0.8168
et_en Dev loss: 0.5082 r:0.6690
si_en Dev loss: 0.7138 r:0.5939
ne_en Dev loss: 0.4278 r:0.7441
ru_en Dev loss: 0.5417 r:0.6961
Current avg r:0.6011 Best avg r: 0.6216
21:07:01,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:14,816 root INFO 
id:en_de cur r: 0.2766 best r: 0.2766
21:08:20,275 root INFO 
id:ne_en cur r: 0.7655 best r: 0.7655
21:08:33,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:04,882 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3490
en_de Dev loss: 0.8682 r:0.2496
en_zh Dev loss: 0.7552 r:0.4549
ro_en Dev loss: 0.3566 r:0.8233
et_en Dev loss: 0.4640 r:0.6760
si_en Dev loss: 0.8045 r:0.6039
ne_en Dev loss: 0.4711 r:0.7609
ru_en Dev loss: 0.4666 r:0.7375
Current avg r:0.6152 Best avg r: 0.6216
21:14:38,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:10,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:41,653 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3597
en_de Dev loss: 0.8489 r:0.2433
en_zh Dev loss: 0.7457 r:0.4498
ro_en Dev loss: 0.3172 r:0.8198
et_en Dev loss: 0.4470 r:0.6696
si_en Dev loss: 0.6401 r:0.6040
ne_en Dev loss: 0.3804 r:0.7621
ru_en Dev loss: 0.4309 r:0.7343
Current avg r:0.6118 Best avg r: 0.6216
21:22:15,286 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:46,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:18,350 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3536
en_de Dev loss: 0.8320 r:0.2520
en_zh Dev loss: 0.7740 r:0.4467
ro_en Dev loss: 0.3512 r:0.8170
et_en Dev loss: 0.5000 r:0.6653
si_en Dev loss: 0.7040 r:0.5998
ne_en Dev loss: 0.3725 r:0.7552
ru_en Dev loss: 0.4380 r:0.7303
Current avg r:0.6095 Best avg r: 0.6216
21:29:52,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:23,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:55,470 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3512
en_de Dev loss: 0.8631 r:0.2213
en_zh Dev loss: 0.7897 r:0.4524
ro_en Dev loss: 0.3559 r:0.8202
et_en Dev loss: 0.4719 r:0.6689
si_en Dev loss: 0.7721 r:0.5973
ne_en Dev loss: 0.4298 r:0.7496
ru_en Dev loss: 0.4988 r:0.7154
Current avg r:0.6036 Best avg r: 0.6216
21:37:29,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:00,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:32,265 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3723
en_de Dev loss: 0.8445 r:0.2400
en_zh Dev loss: 0.7174 r:0.4645
ro_en Dev loss: 0.3324 r:0.8197
et_en Dev loss: 0.4882 r:0.6575
si_en Dev loss: 0.8085 r:0.5970
ne_en Dev loss: 0.5162 r:0.7448
ru_en Dev loss: 0.4772 r:0.7224
Current avg r:0.6066 Best avg r: 0.6216
21:45:05,894 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:46:37,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:08,926 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3408
en_de Dev loss: 0.8612 r:0.2340
en_zh Dev loss: 0.7338 r:0.4641
ro_en Dev loss: 0.3618 r:0.8137
et_en Dev loss: 0.5055 r:0.6662
si_en Dev loss: 0.8134 r:0.5977
ne_en Dev loss: 0.4897 r:0.7440
ru_en Dev loss: 0.4806 r:0.7266
Current avg r:0.6066 Best avg r: 0.6216
21:52:42,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:14,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:55:45,612 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3523
en_de Dev loss: 0.8545 r:0.2203
en_zh Dev loss: 0.7577 r:0.4609
ro_en Dev loss: 0.3465 r:0.8189
et_en Dev loss: 0.4920 r:0.6599
si_en Dev loss: 0.8514 r:0.5966
ne_en Dev loss: 0.5457 r:0.7414
ru_en Dev loss: 0.5393 r:0.7080
Current avg r:0.6009 Best avg r: 0.6216
22:00:19,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:32,499 root INFO 
id:en_de cur r: 0.2780 best r: 0.2780
22:00:58,682 root INFO 
id:ro_en cur r: 0.8276 best r: 0.8276
22:01:51,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:22,882 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3300
en_de Dev loss: 0.8658 r:0.2470
en_zh Dev loss: 0.7958 r:0.4635
ro_en Dev loss: 0.3751 r:0.8231
et_en Dev loss: 0.5209 r:0.6680
si_en Dev loss: 0.8381 r:0.5947
ne_en Dev loss: 0.4049 r:0.7498
ru_en Dev loss: 0.5072 r:0.7361
Current avg r:0.6117 Best avg r: 0.6216
22:07:57,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:28,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:00,445 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3924
en_de Dev loss: 0.8480 r:0.2388
en_zh Dev loss: 0.7572 r:0.4417
ro_en Dev loss: 0.3640 r:0.8092
et_en Dev loss: 0.5164 r:0.6484
si_en Dev loss: 0.8022 r:0.5912
ne_en Dev loss: 0.4249 r:0.7507
ru_en Dev loss: 0.4857 r:0.7093
Current avg r:0.5985 Best avg r: 0.6216
22:15:35,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:06,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:38,190 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3242
en_de Dev loss: 0.8470 r:0.2381
en_zh Dev loss: 0.7459 r:0.4609
ro_en Dev loss: 0.3380 r:0.8224
et_en Dev loss: 0.5294 r:0.6633
si_en Dev loss: 0.7498 r:0.6090
ne_en Dev loss: 0.3797 r:0.7504
ru_en Dev loss: 0.4414 r:0.7418
Current avg r:0.6123 Best avg r: 0.6216
22:23:12,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:44,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:15,903 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3629
en_de Dev loss: 0.8413 r:0.2592
en_zh Dev loss: 0.7132 r:0.4748
ro_en Dev loss: 0.3434 r:0.8199
et_en Dev loss: 0.4895 r:0.6701
si_en Dev loss: 0.7563 r:0.6019
ne_en Dev loss: 0.4266 r:0.7539
ru_en Dev loss: 0.5107 r:0.7123
Current avg r:0.6132 Best avg r: 0.6216
22:30:50,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:09,16 root INFO 
id:ne_en cur r: 0.7687 best r: 0.7687
22:32:22,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:33:53,610 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3452
en_de Dev loss: 0.8459 r:0.2678
en_zh Dev loss: 0.7378 r:0.4668
ro_en Dev loss: 0.3474 r:0.8181
et_en Dev loss: 0.4877 r:0.6821
si_en Dev loss: 0.7011 r:0.6056
ne_en Dev loss: 0.3824 r:0.7596
ru_en Dev loss: 0.5122 r:0.7145
Current avg r:0.6164 Best avg r: 0.6216
22:38:29,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:00,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:31,979 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2890
en_de Dev loss: 0.8712 r:0.2350
en_zh Dev loss: 0.7584 r:0.4305
ro_en Dev loss: 0.3290 r:0.8136
et_en Dev loss: 0.4568 r:0.6618
si_en Dev loss: 0.7375 r:0.5901
ne_en Dev loss: 0.4038 r:0.7592
ru_en Dev loss: 0.4750 r:0.7132
Current avg r:0.6005 Best avg r: 0.6216
22:46:06,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:38,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:09,520 root INFO Epoch 4 Global steps: 43400 Train loss: 0.3120
en_de Dev loss: 0.8525 r:0.2479
en_zh Dev loss: 0.7714 r:0.4460
ro_en Dev loss: 0.3493 r:0.8215
et_en Dev loss: 0.4849 r:0.6701
si_en Dev loss: 0.7663 r:0.5966
ne_en Dev loss: 0.4633 r:0.7561
ru_en Dev loss: 0.4646 r:0.7304
Current avg r:0.6098 Best avg r: 0.6216
22:53:43,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:15,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:46,510 root INFO Epoch 4 Global steps: 44100 Train loss: 0.3194
en_de Dev loss: 0.8764 r:0.2381
en_zh Dev loss: 0.8020 r:0.4435
ro_en Dev loss: 0.3508 r:0.8223
et_en Dev loss: 0.5153 r:0.6654
si_en Dev loss: 0.8803 r:0.5845
ne_en Dev loss: 0.4845 r:0.7487
ru_en Dev loss: 0.5080 r:0.7196
Current avg r:0.6032 Best avg r: 0.6216
23:01:20,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:52,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:23,621 root INFO Epoch 4 Global steps: 44800 Train loss: 0.3149
en_de Dev loss: 0.9341 r:0.2261
en_zh Dev loss: 0.9175 r:0.4094
ro_en Dev loss: 0.4523 r:0.8098
et_en Dev loss: 0.5560 r:0.6492
si_en Dev loss: 1.0402 r:0.5740
ne_en Dev loss: 0.6379 r:0.7467
ru_en Dev loss: 0.6028 r:0.6994
Current avg r:0.5878 Best avg r: 0.6216
23:08:58,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:29,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:01,96 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2826
en_de Dev loss: 0.8769 r:0.2379
en_zh Dev loss: 0.8024 r:0.4364
ro_en Dev loss: 0.3889 r:0.8179
et_en Dev loss: 0.5020 r:0.6620
si_en Dev loss: 0.8494 r:0.5920
ne_en Dev loss: 0.5255 r:0.7495
ru_en Dev loss: 0.4775 r:0.7304
Current avg r:0.6037 Best avg r: 0.6216
23:16:35,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:07,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:39,37 root INFO Epoch 4 Global steps: 46200 Train loss: 0.3179
en_de Dev loss: 0.8622 r:0.2179
en_zh Dev loss: 0.7547 r:0.4310
ro_en Dev loss: 0.3281 r:0.8153
et_en Dev loss: 0.4718 r:0.6586
si_en Dev loss: 0.7849 r:0.5849
ne_en Dev loss: 0.5409 r:0.7444
ru_en Dev loss: 0.4597 r:0.7154
Current avg r:0.5954 Best avg r: 0.6216
23:24:13,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:45,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:16,871 root INFO Epoch 4 Global steps: 46900 Train loss: 0.3076
en_de Dev loss: 0.8594 r:0.2250
en_zh Dev loss: 0.7927 r:0.4169
ro_en Dev loss: 0.3296 r:0.8190
et_en Dev loss: 0.4749 r:0.6568
si_en Dev loss: 0.8064 r:0.5882
ne_en Dev loss: 0.4825 r:0.7467
ru_en Dev loss: 0.4757 r:0.7120
Current avg r:0.5949 Best avg r: 0.6216
23:31:51,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:23,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:34:54,781 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2889
en_de Dev loss: 0.8726 r:0.2276
en_zh Dev loss: 0.7954 r:0.4471
ro_en Dev loss: 0.3537 r:0.8213
et_en Dev loss: 0.5196 r:0.6630
si_en Dev loss: 0.8042 r:0.5953
ne_en Dev loss: 0.4620 r:0.7445
ru_en Dev loss: 0.4667 r:0.7352
Current avg r:0.6049 Best avg r: 0.6216
23:39:29,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:01,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:32,736 root INFO Epoch 4 Global steps: 48300 Train loss: 0.3223
en_de Dev loss: 0.8630 r:0.2312
en_zh Dev loss: 0.7924 r:0.4535
ro_en Dev loss: 0.3558 r:0.8186
et_en Dev loss: 0.5069 r:0.6565
si_en Dev loss: 0.8610 r:0.5923
ne_en Dev loss: 0.5166 r:0.7478
ru_en Dev loss: 0.4751 r:0.7266
Current avg r:0.6038 Best avg r: 0.6216
23:47:07,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:39,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:10,753 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2936
en_de Dev loss: 0.8590 r:0.2268
en_zh Dev loss: 0.7300 r:0.4618
ro_en Dev loss: 0.3381 r:0.8210
et_en Dev loss: 0.5051 r:0.6620
si_en Dev loss: 0.7444 r:0.6023
ne_en Dev loss: 0.3900 r:0.7543
ru_en Dev loss: 0.4609 r:0.7241
Current avg r:0.6075 Best avg r: 0.6216
23:54:44,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:16,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:47,486 root INFO Epoch 4 Global steps: 49700 Train loss: 0.3022
en_de Dev loss: 0.8661 r:0.2158
en_zh Dev loss: 0.7131 r:0.4709
ro_en Dev loss: 0.3414 r:0.8170
et_en Dev loss: 0.5048 r:0.6611
si_en Dev loss: 0.7491 r:0.5926
ne_en Dev loss: 0.3981 r:0.7518
ru_en Dev loss: 0.4519 r:0.7282
Current avg r:0.6053 Best avg r: 0.6216
00:02:21,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:52,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:24,144 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2962
en_de Dev loss: 0.8537 r:0.2327
en_zh Dev loss: 0.7086 r:0.4684
ro_en Dev loss: 0.3160 r:0.8244
et_en Dev loss: 0.4509 r:0.6738
si_en Dev loss: 0.7529 r:0.5941
ne_en Dev loss: 0.4401 r:0.7563
ru_en Dev loss: 0.4451 r:0.7270
Current avg r:0.6110 Best avg r: 0.6216
00:09:57,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:29,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:13:00,863 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2915
en_de Dev loss: 0.8939 r:0.2356
en_zh Dev loss: 0.7483 r:0.4600
ro_en Dev loss: 0.3449 r:0.8223
et_en Dev loss: 0.5033 r:0.6657
si_en Dev loss: 0.7721 r:0.5895
ne_en Dev loss: 0.4015 r:0.7539
ru_en Dev loss: 0.5056 r:0.7104
Current avg r:0.6054 Best avg r: 0.6216
00:17:35,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:07,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:38,572 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2888
en_de Dev loss: 0.8750 r:0.2121
en_zh Dev loss: 0.8037 r:0.4381
ro_en Dev loss: 0.3824 r:0.8157
et_en Dev loss: 0.5003 r:0.6520
si_en Dev loss: 0.9225 r:0.5821
ne_en Dev loss: 0.4816 r:0.7473
ru_en Dev loss: 0.5297 r:0.7057
Current avg r:0.5933 Best avg r: 0.6216
00:25:12,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:43,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:28:15,230 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2760
en_de Dev loss: 0.8690 r:0.2305
en_zh Dev loss: 0.7692 r:0.4635
ro_en Dev loss: 0.3582 r:0.8245
et_en Dev loss: 0.4974 r:0.6733
si_en Dev loss: 0.8508 r:0.5930
ne_en Dev loss: 0.4281 r:0.7533
ru_en Dev loss: 0.5018 r:0.7245
Current avg r:0.6089 Best avg r: 0.6216
00:32:50,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:22,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:53,793 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2485
en_de Dev loss: 0.8882 r:0.2353
en_zh Dev loss: 0.8044 r:0.4431
ro_en Dev loss: 0.3650 r:0.8164
et_en Dev loss: 0.4966 r:0.6611
si_en Dev loss: 0.7857 r:0.5841
ne_en Dev loss: 0.4519 r:0.7425
ru_en Dev loss: 0.5221 r:0.7094
Current avg r:0.5989 Best avg r: 0.6216
00:40:27,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:59,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:30,444 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2551
en_de Dev loss: 0.8714 r:0.2223
en_zh Dev loss: 0.7661 r:0.4549
ro_en Dev loss: 0.3638 r:0.8197
et_en Dev loss: 0.4729 r:0.6693
si_en Dev loss: 0.9013 r:0.5762
ne_en Dev loss: 0.5049 r:0.7410
ru_en Dev loss: 0.5526 r:0.7046
Current avg r:0.5983 Best avg r: 0.6216
00:48:04,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:35,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:51:07,72 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2426
en_de Dev loss: 0.8994 r:0.2156
en_zh Dev loss: 0.7940 r:0.4645
ro_en Dev loss: 0.3763 r:0.8222
et_en Dev loss: 0.4925 r:0.6726
si_en Dev loss: 0.8924 r:0.5865
ne_en Dev loss: 0.5048 r:0.7491
ru_en Dev loss: 0.4856 r:0.7366
Current avg r:0.6067 Best avg r: 0.6216
00:55:40,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:12,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:43,827 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2626
en_de Dev loss: 0.8579 r:0.2221
en_zh Dev loss: 0.7952 r:0.4486
ro_en Dev loss: 0.3513 r:0.8144
et_en Dev loss: 0.4710 r:0.6605
si_en Dev loss: 0.8955 r:0.5798
ne_en Dev loss: 0.4945 r:0.7482
ru_en Dev loss: 0.5105 r:0.7020
Current avg r:0.5965 Best avg r: 0.6216
01:03:17,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:49,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:20,495 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2455
en_de Dev loss: 0.8570 r:0.2318
en_zh Dev loss: 0.7890 r:0.4524
ro_en Dev loss: 0.3831 r:0.8108
et_en Dev loss: 0.4869 r:0.6529
si_en Dev loss: 0.9899 r:0.5711
ne_en Dev loss: 0.5779 r:0.7414
ru_en Dev loss: 0.5371 r:0.6968
Current avg r:0.5939 Best avg r: 0.6216
01:10:54,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:25,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:13:56,981 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2547
en_de Dev loss: 0.8430 r:0.2340
en_zh Dev loss: 0.7183 r:0.4658
ro_en Dev loss: 0.3034 r:0.8250
et_en Dev loss: 0.4579 r:0.6735
si_en Dev loss: 0.7569 r:0.5842
ne_en Dev loss: 0.4172 r:0.7453
ru_en Dev loss: 0.4512 r:0.7197
Current avg r:0.6068 Best avg r: 0.6216
01:18:30,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:09,817 root INFO 
id:ro_en cur r: 0.8277 best r: 0.8277
01:20:02,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:21:33,531 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2512
en_de Dev loss: 0.8702 r:0.2184
en_zh Dev loss: 0.7680 r:0.4545
ro_en Dev loss: 0.3421 r:0.8244
et_en Dev loss: 0.4779 r:0.6717
si_en Dev loss: 0.8166 r:0.5894
ne_en Dev loss: 0.4574 r:0.7507
ru_en Dev loss: 0.4812 r:0.7174
Current avg r:0.6038 Best avg r: 0.6216
01:26:07,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:27:38,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:29:10,135 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2362
en_de Dev loss: 0.8601 r:0.2416
en_zh Dev loss: 0.7629 r:0.4513
ro_en Dev loss: 0.3267 r:0.8204
et_en Dev loss: 0.4936 r:0.6569
si_en Dev loss: 0.8118 r:0.5767
ne_en Dev loss: 0.4454 r:0.7401
ru_en Dev loss: 0.4717 r:0.7118
Current avg r:0.5998 Best avg r: 0.6216
01:33:43,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:15,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:46,652 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2547
en_de Dev loss: 0.8580 r:0.2341
en_zh Dev loss: 0.7782 r:0.4510
ro_en Dev loss: 0.3312 r:0.8239
et_en Dev loss: 0.4824 r:0.6752
si_en Dev loss: 0.7790 r:0.5862
ne_en Dev loss: 0.4352 r:0.7446
ru_en Dev loss: 0.4616 r:0.7200
Current avg r:0.6050 Best avg r: 0.6216
01:41:20,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:51,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:44:23,222 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2489
en_de Dev loss: 0.8644 r:0.2208
en_zh Dev loss: 0.7525 r:0.4589
ro_en Dev loss: 0.3355 r:0.8214
et_en Dev loss: 0.4854 r:0.6649
si_en Dev loss: 0.8154 r:0.5885
ne_en Dev loss: 0.4669 r:0.7437
ru_en Dev loss: 0.4328 r:0.7329
Current avg r:0.6045 Best avg r: 0.6216
01:48:56,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:28,402 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:59,881 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2523
en_de Dev loss: 0.9279 r:0.2139
en_zh Dev loss: 0.8640 r:0.4475
ro_en Dev loss: 0.3964 r:0.8174
et_en Dev loss: 0.5126 r:0.6616
si_en Dev loss: 0.9175 r:0.5815
ne_en Dev loss: 0.5542 r:0.7448
ru_en Dev loss: 0.5199 r:0.7229
Current avg r:0.5985 Best avg r: 0.6216
01:56:33,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:58:05,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:36,641 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2623
en_de Dev loss: 0.9023 r:0.1973
en_zh Dev loss: 0.8482 r:0.4442
ro_en Dev loss: 0.3893 r:0.8156
et_en Dev loss: 0.5066 r:0.6635
si_en Dev loss: 0.8998 r:0.5756
ne_en Dev loss: 0.5558 r:0.7394
ru_en Dev loss: 0.5706 r:0.6975
Current avg r:0.5904 Best avg r: 0.6216
02:04:10,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:41,883 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:13,360 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2402
en_de Dev loss: 0.8878 r:0.2042
en_zh Dev loss: 0.7697 r:0.4654
ro_en Dev loss: 0.3337 r:0.8209
et_en Dev loss: 0.4817 r:0.6788
si_en Dev loss: 0.8150 r:0.5831
ne_en Dev loss: 0.4286 r:0.7433
ru_en Dev loss: 0.4461 r:0.7301
Current avg r:0.6037 Best avg r: 0.6216
02:11:47,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:18,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:50,129 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2369
en_de Dev loss: 0.8747 r:0.1800
en_zh Dev loss: 0.7620 r:0.4528
ro_en Dev loss: 0.3347 r:0.8234
et_en Dev loss: 0.4550 r:0.6755
si_en Dev loss: 0.9445 r:0.5755
ne_en Dev loss: 0.5967 r:0.7394
ru_en Dev loss: 0.4631 r:0.7241
Current avg r:0.5958 Best avg r: 0.6216
02:19:23,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:55,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:26,956 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2426
en_de Dev loss: 0.8988 r:0.2021
en_zh Dev loss: 0.7996 r:0.4577
ro_en Dev loss: 0.3691 r:0.8176
et_en Dev loss: 0.4998 r:0.6616
si_en Dev loss: 0.9436 r:0.5704
ne_en Dev loss: 0.5530 r:0.7360
ru_en Dev loss: 0.5108 r:0.7122
Current avg r:0.5940 Best avg r: 0.6216
02:27:02,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:28:34,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:30:05,979 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2180
en_de Dev loss: 0.9208 r:0.1997
en_zh Dev loss: 0.8882 r:0.4333
ro_en Dev loss: 0.3807 r:0.8132
et_en Dev loss: 0.4978 r:0.6605
si_en Dev loss: 1.0052 r:0.5566
ne_en Dev loss: 0.6408 r:0.7347
ru_en Dev loss: 0.5532 r:0.6974
Current avg r:0.5850 Best avg r: 0.6216
02:34:40,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:11,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:37:43,140 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2192
en_de Dev loss: 0.9030 r:0.2044
en_zh Dev loss: 0.8171 r:0.4411
ro_en Dev loss: 0.3869 r:0.8192
et_en Dev loss: 0.4843 r:0.6660
si_en Dev loss: 0.9404 r:0.5701
ne_en Dev loss: 0.5412 r:0.7471
ru_en Dev loss: 0.5589 r:0.6973
Current avg r:0.5922 Best avg r: 0.6216
02:42:17,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:49,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:20,508 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2133
en_de Dev loss: 0.9098 r:0.1901
en_zh Dev loss: 0.8160 r:0.4463
ro_en Dev loss: 0.3523 r:0.8220
et_en Dev loss: 0.4765 r:0.6694
si_en Dev loss: 0.8730 r:0.5727
ne_en Dev loss: 0.5260 r:0.7436
ru_en Dev loss: 0.5016 r:0.7159
Current avg r:0.5943 Best avg r: 0.6216
02:49:55,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:26,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:58,213 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2070
en_de Dev loss: 0.8796 r:0.2020
en_zh Dev loss: 0.7761 r:0.4443
ro_en Dev loss: 0.3366 r:0.8198
et_en Dev loss: 0.4607 r:0.6735
si_en Dev loss: 0.8368 r:0.5699
ne_en Dev loss: 0.4905 r:0.7341
ru_en Dev loss: 0.4655 r:0.7136
Current avg r:0.5939 Best avg r: 0.6216
02:57:32,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:59:04,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:35,600 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2104
en_de Dev loss: 0.8723 r:0.2104
en_zh Dev loss: 0.8041 r:0.4446
ro_en Dev loss: 0.3578 r:0.8191
et_en Dev loss: 0.4697 r:0.6700
si_en Dev loss: 0.9172 r:0.5733
ne_en Dev loss: 0.5107 r:0.7431
ru_en Dev loss: 0.4785 r:0.7261
Current avg r:0.5981 Best avg r: 0.6216
03:05:10,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:06:41,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:13,347 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2115
en_de Dev loss: 0.8701 r:0.2360
en_zh Dev loss: 0.7889 r:0.4530
ro_en Dev loss: 0.3682 r:0.8196
et_en Dev loss: 0.4868 r:0.6679
si_en Dev loss: 0.9141 r:0.5765
ne_en Dev loss: 0.5076 r:0.7441
ru_en Dev loss: 0.4762 r:0.7301
Current avg r:0.6039 Best avg r: 0.6216
03:12:47,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:19,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:15:50,739 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2146
en_de Dev loss: 0.8661 r:0.2326
en_zh Dev loss: 0.7820 r:0.4524
ro_en Dev loss: 0.3660 r:0.8139
et_en Dev loss: 0.4776 r:0.6590
si_en Dev loss: 0.8613 r:0.5716
ne_en Dev loss: 0.4617 r:0.7393
ru_en Dev loss: 0.5098 r:0.7031
Current avg r:0.5960 Best avg r: 0.6216
03:20:24,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:56,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:27,483 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2058
en_de Dev loss: 0.8544 r:0.2312
en_zh Dev loss: 0.7771 r:0.4466
ro_en Dev loss: 0.3451 r:0.8127
et_en Dev loss: 0.4713 r:0.6592
si_en Dev loss: 0.8924 r:0.5678
ne_en Dev loss: 0.5694 r:0.7341
ru_en Dev loss: 0.4525 r:0.7237
Current avg r:0.5965 Best avg r: 0.6216
03:28:02,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:33,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:05,432 root INFO Epoch 6 Global steps: 69300 Train loss: 0.1946
en_de Dev loss: 0.8605 r:0.2433
en_zh Dev loss: 0.7885 r:0.4401
ro_en Dev loss: 0.3286 r:0.8181
et_en Dev loss: 0.4558 r:0.6601
si_en Dev loss: 0.8156 r:0.5716
ne_en Dev loss: 0.4553 r:0.7428
ru_en Dev loss: 0.4699 r:0.7190
Current avg r:0.5993 Best avg r: 0.6216
03:35:39,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:11,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:42,836 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1975
en_de Dev loss: 0.8603 r:0.2492
en_zh Dev loss: 0.7413 r:0.4580
ro_en Dev loss: 0.3365 r:0.8209
et_en Dev loss: 0.4456 r:0.6680
si_en Dev loss: 0.8201 r:0.5807
ne_en Dev loss: 0.4421 r:0.7437
ru_en Dev loss: 0.4520 r:0.7275
Current avg r:0.6069 Best avg r: 0.6216
03:43:17,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:49,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:46:21,49 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2041
en_de Dev loss: 0.8783 r:0.2474
en_zh Dev loss: 0.8223 r:0.4429
ro_en Dev loss: 0.3520 r:0.8193
et_en Dev loss: 0.4756 r:0.6666
si_en Dev loss: 0.8704 r:0.5751
ne_en Dev loss: 0.4531 r:0.7351
ru_en Dev loss: 0.5224 r:0.7064
Current avg r:0.5990 Best avg r: 0.6216
03:50:55,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:52:27,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:53:58,869 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1947
en_de Dev loss: 0.8698 r:0.2520
en_zh Dev loss: 0.8318 r:0.4483
ro_en Dev loss: 0.3592 r:0.8209
et_en Dev loss: 0.4729 r:0.6708
si_en Dev loss: 0.8615 r:0.5710
ne_en Dev loss: 0.4933 r:0.7340
ru_en Dev loss: 0.4698 r:0.7260
Current avg r:0.6033 Best avg r: 0.6216
03:58:32,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:00:03,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:01:35,345 root INFO Epoch 6 Global steps: 72100 Train loss: 0.1872
en_de Dev loss: 0.8644 r:0.2445
en_zh Dev loss: 0.7642 r:0.4555
ro_en Dev loss: 0.3331 r:0.8210
et_en Dev loss: 0.4800 r:0.6636
si_en Dev loss: 0.8560 r:0.5643
ne_en Dev loss: 0.4805 r:0.7390
ru_en Dev loss: 0.4538 r:0.7182
Current avg r:0.6009 Best avg r: 0.6216
04:06:08,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:07:40,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:09:11,830 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2020
en_de Dev loss: 0.8628 r:0.2503
en_zh Dev loss: 0.7998 r:0.4451
ro_en Dev loss: 0.3745 r:0.8148
et_en Dev loss: 0.4890 r:0.6642
si_en Dev loss: 0.8877 r:0.5555
ne_en Dev loss: 0.4986 r:0.7375
ru_en Dev loss: 0.4851 r:0.7167
Current avg r:0.5977 Best avg r: 0.6216
04:13:45,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:15:16,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:16:48,363 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2010
en_de Dev loss: 0.8597 r:0.2391
en_zh Dev loss: 0.7948 r:0.4492
ro_en Dev loss: 0.3692 r:0.8221
et_en Dev loss: 0.4695 r:0.6647
si_en Dev loss: 0.8940 r:0.5665
ne_en Dev loss: 0.5347 r:0.7323
ru_en Dev loss: 0.5094 r:0.7065
Current avg r:0.5972 Best avg r: 0.6216
04:21:24,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:22:55,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:24:27,345 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1704
en_de Dev loss: 0.9061 r:0.2361
en_zh Dev loss: 0.8486 r:0.4462
ro_en Dev loss: 0.3748 r:0.8231
et_en Dev loss: 0.4752 r:0.6737
si_en Dev loss: 0.8848 r:0.5664
ne_en Dev loss: 0.4829 r:0.7365
ru_en Dev loss: 0.4967 r:0.7302
Current avg r:0.6017 Best avg r: 0.6216
04:29:02,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:33,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:32:04,973 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1857
en_de Dev loss: 0.8766 r:0.2149
en_zh Dev loss: 0.7999 r:0.4526
ro_en Dev loss: 0.3955 r:0.8167
et_en Dev loss: 0.4982 r:0.6627
si_en Dev loss: 0.9692 r:0.5595
ne_en Dev loss: 0.5384 r:0.7330
ru_en Dev loss: 0.5741 r:0.6982
Current avg r:0.5911 Best avg r: 0.6216
04:36:39,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:38:11,100 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:39:42,630 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1740
en_de Dev loss: 0.8919 r:0.2170
en_zh Dev loss: 0.8044 r:0.4519
ro_en Dev loss: 0.3661 r:0.8176
et_en Dev loss: 0.5132 r:0.6665
si_en Dev loss: 0.8105 r:0.5668
ne_en Dev loss: 0.4453 r:0.7372
ru_en Dev loss: 0.4608 r:0.7318
Current avg r:0.5984 Best avg r: 0.6216
04:44:17,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:45:48,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:47:20,276 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1711
en_de Dev loss: 0.8644 r:0.2311
en_zh Dev loss: 0.7882 r:0.4541
ro_en Dev loss: 0.3857 r:0.8134
et_en Dev loss: 0.4788 r:0.6593
si_en Dev loss: 0.9508 r:0.5558
ne_en Dev loss: 0.5664 r:0.7308
ru_en Dev loss: 0.4827 r:0.7263
Current avg r:0.5958 Best avg r: 0.6216
04:51:54,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:53:25,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:54:56,977 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1684
en_de Dev loss: 0.8723 r:0.2188
en_zh Dev loss: 0.8145 r:0.4505
ro_en Dev loss: 0.3783 r:0.8156
et_en Dev loss: 0.4752 r:0.6664
si_en Dev loss: 0.9456 r:0.5591
ne_en Dev loss: 0.5380 r:0.7311
ru_en Dev loss: 0.5272 r:0.7129
Current avg r:0.5935 Best avg r: 0.6216
04:59:30,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:01:02,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:02:33,787 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1705
en_de Dev loss: 0.8825 r:0.2239
en_zh Dev loss: 0.7693 r:0.4602
ro_en Dev loss: 0.3580 r:0.8161
et_en Dev loss: 0.4445 r:0.6672
si_en Dev loss: 0.8310 r:0.5592
ne_en Dev loss: 0.4935 r:0.7366
ru_en Dev loss: 0.4449 r:0.7390
Current avg r:0.6003 Best avg r: 0.6216
05:07:08,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:08:39,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:10:11,321 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1818
en_de Dev loss: 0.9033 r:0.2287
en_zh Dev loss: 0.7895 r:0.4663
ro_en Dev loss: 0.3600 r:0.8190
et_en Dev loss: 0.4747 r:0.6727
si_en Dev loss: 0.9036 r:0.5584
ne_en Dev loss: 0.5249 r:0.7307
ru_en Dev loss: 0.4672 r:0.7319
Current avg r:0.6011 Best avg r: 0.6216
05:14:45,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:16:17,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:17:48,792 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1760
en_de Dev loss: 0.8894 r:0.2182
en_zh Dev loss: 0.8431 r:0.4480
ro_en Dev loss: 0.3894 r:0.8155
et_en Dev loss: 0.5060 r:0.6590
si_en Dev loss: 0.9455 r:0.5595
ne_en Dev loss: 0.5488 r:0.7317
ru_en Dev loss: 0.5107 r:0.7120
Current avg r:0.5920 Best avg r: 0.6216
05:22:23,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:23:54,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:26,54 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1715
en_de Dev loss: 0.8812 r:0.2385
en_zh Dev loss: 0.8361 r:0.4621
ro_en Dev loss: 0.3890 r:0.8174
et_en Dev loss: 0.5023 r:0.6671
si_en Dev loss: 0.9962 r:0.5563
ne_en Dev loss: 0.6100 r:0.7286
ru_en Dev loss: 0.5123 r:0.7159
Current avg r:0.5980 Best avg r: 0.6216
05:29:59,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:31:31,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:33:02,704 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1732
en_de Dev loss: 0.9091 r:0.1927
en_zh Dev loss: 0.8029 r:0.4627
ro_en Dev loss: 0.3449 r:0.8185
et_en Dev loss: 0.4492 r:0.6702
si_en Dev loss: 0.8737 r:0.5629
ne_en Dev loss: 0.5249 r:0.7348
ru_en Dev loss: 0.4822 r:0.7240
Current avg r:0.5951 Best avg r: 0.6216
05:37:36,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:39:07,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:40:39,428 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1793
en_de Dev loss: 0.9108 r:0.2054
en_zh Dev loss: 0.7800 r:0.4715
ro_en Dev loss: 0.3504 r:0.8207
et_en Dev loss: 0.4759 r:0.6635
si_en Dev loss: 0.9097 r:0.5560
ne_en Dev loss: 0.5449 r:0.7266
ru_en Dev loss: 0.4852 r:0.7221
Current avg r:0.5951 Best avg r: 0.6216
05:45:13,120 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:46:44,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:48:16,92 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1683
en_de Dev loss: 0.8887 r:0.2304
en_zh Dev loss: 0.7971 r:0.4659
ro_en Dev loss: 0.3687 r:0.8182
et_en Dev loss: 0.4907 r:0.6641
si_en Dev loss: 0.9005 r:0.5616
ne_en Dev loss: 0.5455 r:0.7271
ru_en Dev loss: 0.4875 r:0.7203
Current avg r:0.5982 Best avg r: 0.6216
05:52:49,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:21,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:55:52,672 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1718
en_de Dev loss: 0.9148 r:0.2195
en_zh Dev loss: 0.8455 r:0.4617
ro_en Dev loss: 0.3937 r:0.8145
et_en Dev loss: 0.5063 r:0.6533
si_en Dev loss: 0.9902 r:0.5511
ne_en Dev loss: 0.5962 r:0.7287
ru_en Dev loss: 0.5642 r:0.6999
Current avg r:0.5898 Best avg r: 0.6216
06:00:26,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:01:57,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:03:29,195 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1652
en_de Dev loss: 0.8979 r:0.2152
en_zh Dev loss: 0.8352 r:0.4494
ro_en Dev loss: 0.3730 r:0.8159
et_en Dev loss: 0.4965 r:0.6594
si_en Dev loss: 0.9126 r:0.5577
ne_en Dev loss: 0.5927 r:0.7238
ru_en Dev loss: 0.4656 r:0.7347
Current avg r:0.5937 Best avg r: 0.6216
06:08:02,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:34,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:05,837 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1608
en_de Dev loss: 0.8936 r:0.2380
en_zh Dev loss: 0.7805 r:0.4726
ro_en Dev loss: 0.3517 r:0.8167
et_en Dev loss: 0.4784 r:0.6691
si_en Dev loss: 0.8641 r:0.5607
ne_en Dev loss: 0.5160 r:0.7288
ru_en Dev loss: 0.4895 r:0.7199
Current avg r:0.6008 Best avg r: 0.6216
06:15:41,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:12,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:44,457 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1526
en_de Dev loss: 0.8806 r:0.2253
en_zh Dev loss: 0.7707 r:0.4753
ro_en Dev loss: 0.3524 r:0.8175
et_en Dev loss: 0.4803 r:0.6745
si_en Dev loss: 0.8392 r:0.5655
ne_en Dev loss: 0.4813 r:0.7307
ru_en Dev loss: 0.4494 r:0.7381
Current avg r:0.6038 Best avg r: 0.6216
06:23:18,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:24:49,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:21,255 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1489
en_de Dev loss: 0.8594 r:0.2489
en_zh Dev loss: 0.7484 r:0.4751
ro_en Dev loss: 0.3406 r:0.8173
et_en Dev loss: 0.4573 r:0.6715
si_en Dev loss: 0.8213 r:0.5625
ne_en Dev loss: 0.5171 r:0.7256
ru_en Dev loss: 0.4710 r:0.7196
Current avg r:0.6029 Best avg r: 0.6216
06:30:54,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:32:26,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:33:57,711 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1436
en_de Dev loss: 0.9336 r:0.2162
en_zh Dev loss: 0.8292 r:0.4651
ro_en Dev loss: 0.3770 r:0.8132
et_en Dev loss: 0.4832 r:0.6707
si_en Dev loss: 0.9161 r:0.5594
ne_en Dev loss: 0.5781 r:0.7255
ru_en Dev loss: 0.5251 r:0.7214
Current avg r:0.5959 Best avg r: 0.6216
06:38:31,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:40:03,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:41:34,564 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1480
en_de Dev loss: 0.9111 r:0.2213
en_zh Dev loss: 0.8432 r:0.4671
ro_en Dev loss: 0.4130 r:0.8141
et_en Dev loss: 0.4925 r:0.6674
si_en Dev loss: 1.0003 r:0.5553
ne_en Dev loss: 0.6237 r:0.7269
ru_en Dev loss: 0.5529 r:0.7206
Current avg r:0.5961 Best avg r: 0.6216
06:46:08,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:40,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:49:11,896 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1501
en_de Dev loss: 0.8762 r:0.2339
en_zh Dev loss: 0.7890 r:0.4581
ro_en Dev loss: 0.3766 r:0.8084
et_en Dev loss: 0.4660 r:0.6572
si_en Dev loss: 0.9605 r:0.5387
ne_en Dev loss: 0.5636 r:0.7238
ru_en Dev loss: 0.4480 r:0.7306
Current avg r:0.5930 Best avg r: 0.6216
06:53:45,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:55:16,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:48,393 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1478
en_de Dev loss: 0.8956 r:0.2302
en_zh Dev loss: 0.8715 r:0.4641
ro_en Dev loss: 0.3771 r:0.8188
et_en Dev loss: 0.4702 r:0.6724
si_en Dev loss: 0.9043 r:0.5603
ne_en Dev loss: 0.5098 r:0.7275
ru_en Dev loss: 0.4617 r:0.7426
Current avg r:0.6023 Best avg r: 0.6216
07:01:21,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:53,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:04:24,884 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1532
en_de Dev loss: 0.9243 r:0.2098
en_zh Dev loss: 0.8956 r:0.4497
ro_en Dev loss: 0.4325 r:0.8102
et_en Dev loss: 0.5077 r:0.6621
si_en Dev loss: 1.0273 r:0.5427
ne_en Dev loss: 0.6648 r:0.7228
ru_en Dev loss: 0.5671 r:0.7125
Current avg r:0.5871 Best avg r: 0.6216
07:08:58,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:10:29,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:12:01,387 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1425
en_de Dev loss: 0.8941 r:0.2154
en_zh Dev loss: 0.8075 r:0.4602
ro_en Dev loss: 0.3679 r:0.8181
et_en Dev loss: 0.4566 r:0.6683
si_en Dev loss: 0.9344 r:0.5518
ne_en Dev loss: 0.5394 r:0.7407
ru_en Dev loss: 0.4631 r:0.7348
Current avg r:0.5985 Best avg r: 0.6216
07:16:35,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:18:07,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:19:38,793 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1443
en_de Dev loss: 0.9014 r:0.2328
en_zh Dev loss: 0.8441 r:0.4542
ro_en Dev loss: 0.3816 r:0.8147
et_en Dev loss: 0.4751 r:0.6713
si_en Dev loss: 0.9179 r:0.5560
ne_en Dev loss: 0.5583 r:0.7364
ru_en Dev loss: 0.4787 r:0.7347
Current avg r:0.6000 Best avg r: 0.6216
07:24:13,153 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:44,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:27:16,154 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1501
en_de Dev loss: 0.8985 r:0.2179
en_zh Dev loss: 0.7859 r:0.4691
ro_en Dev loss: 0.3472 r:0.8173
et_en Dev loss: 0.4714 r:0.6718
si_en Dev loss: 0.8642 r:0.5559
ne_en Dev loss: 0.4882 r:0.7294
ru_en Dev loss: 0.4580 r:0.7314
Current avg r:0.5990 Best avg r: 0.6216
07:31:50,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:33:21,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:34:53,308 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1407
en_de Dev loss: 0.9275 r:0.2058
en_zh Dev loss: 0.8404 r:0.4614
ro_en Dev loss: 0.3920 r:0.8150
et_en Dev loss: 0.4935 r:0.6614
si_en Dev loss: 1.0219 r:0.5540
ne_en Dev loss: 0.5940 r:0.7288
ru_en Dev loss: 0.4976 r:0.7296
Current avg r:0.5937 Best avg r: 0.6216
07:39:27,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:58,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:30,178 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1457
en_de Dev loss: 0.9004 r:0.2315
en_zh Dev loss: 0.8236 r:0.4705
ro_en Dev loss: 0.3779 r:0.8144
et_en Dev loss: 0.4791 r:0.6622
si_en Dev loss: 1.0063 r:0.5534
ne_en Dev loss: 0.6209 r:0.7255
ru_en Dev loss: 0.4702 r:0.7362
Current avg r:0.5991 Best avg r: 0.6216
07:47:04,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:36,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:50:07,733 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1447
en_de Dev loss: 0.8938 r:0.2178
en_zh Dev loss: 0.8138 r:0.4722
ro_en Dev loss: 0.3570 r:0.8179
et_en Dev loss: 0.4824 r:0.6645
si_en Dev loss: 0.9973 r:0.5525
ne_en Dev loss: 0.6064 r:0.7279
ru_en Dev loss: 0.4579 r:0.7335
Current avg r:0.5980 Best avg r: 0.6216
07:54:41,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:56:13,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:57:44,757 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1398
en_de Dev loss: 0.8867 r:0.2099
en_zh Dev loss: 0.7628 r:0.4720
ro_en Dev loss: 0.3175 r:0.8234
et_en Dev loss: 0.4422 r:0.6738
si_en Dev loss: 0.8206 r:0.5630
ne_en Dev loss: 0.5171 r:0.7334
ru_en Dev loss: 0.4217 r:0.7403
Current avg r:0.6022 Best avg r: 0.6216
08:02:18,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:03:49,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:05:21,378 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1470
en_de Dev loss: 0.8873 r:0.2105
en_zh Dev loss: 0.8199 r:0.4536
ro_en Dev loss: 0.3497 r:0.8185
et_en Dev loss: 0.4591 r:0.6676
si_en Dev loss: 0.9223 r:0.5530
ne_en Dev loss: 0.5595 r:0.7321
ru_en Dev loss: 0.4916 r:0.7158
Current avg r:0.5930 Best avg r: 0.6216
08:09:57,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:11:29,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:13:00,875 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1312
en_de Dev loss: 0.9067 r:0.1978
en_zh Dev loss: 0.8073 r:0.4667
ro_en Dev loss: 0.3783 r:0.8177
et_en Dev loss: 0.4836 r:0.6672
si_en Dev loss: 0.9653 r:0.5575
ne_en Dev loss: 0.5779 r:0.7303
ru_en Dev loss: 0.4867 r:0.7310
Current avg r:0.5955 Best avg r: 0.6216
08:17:34,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:19:06,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:20:37,613 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1269
en_de Dev loss: 0.9125 r:0.2002
en_zh Dev loss: 0.8338 r:0.4569
ro_en Dev loss: 0.3600 r:0.8166
et_en Dev loss: 0.4760 r:0.6696
si_en Dev loss: 0.8991 r:0.5551
ne_en Dev loss: 0.5492 r:0.7291
ru_en Dev loss: 0.4782 r:0.7278
Current avg r:0.5936 Best avg r: 0.6216
08:25:11,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:42,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:28:14,385 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1217
en_de Dev loss: 0.9208 r:0.2030
en_zh Dev loss: 0.8723 r:0.4598
ro_en Dev loss: 0.3837 r:0.8182
et_en Dev loss: 0.4812 r:0.6702
si_en Dev loss: 1.0085 r:0.5536
ne_en Dev loss: 0.7158 r:0.7231
ru_en Dev loss: 0.5491 r:0.7160
Current avg r:0.5920 Best avg r: 0.6216
08:32:48,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:34:19,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:35:50,972 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1314
en_de Dev loss: 0.8838 r:0.2235
en_zh Dev loss: 0.7886 r:0.4695
ro_en Dev loss: 0.3680 r:0.8149
et_en Dev loss: 0.4789 r:0.6678
si_en Dev loss: 0.9010 r:0.5549
ne_en Dev loss: 0.5708 r:0.7266
ru_en Dev loss: 0.4477 r:0.7348
Current avg r:0.5988 Best avg r: 0.6216
08:40:25,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:41:57,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:28,615 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1340
en_de Dev loss: 0.8880 r:0.2111
en_zh Dev loss: 0.7912 r:0.4609
ro_en Dev loss: 0.3401 r:0.8214
et_en Dev loss: 0.4645 r:0.6735
si_en Dev loss: 0.8224 r:0.5563
ne_en Dev loss: 0.5038 r:0.7232
ru_en Dev loss: 0.4588 r:0.7291
Current avg r:0.5965 Best avg r: 0.6216
08:48:03,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:49:34,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:51:06,232 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1306
en_de Dev loss: 0.9151 r:0.1996
en_zh Dev loss: 0.8380 r:0.4535
ro_en Dev loss: 0.3784 r:0.8166
et_en Dev loss: 0.4750 r:0.6682
si_en Dev loss: 0.9592 r:0.5473
ne_en Dev loss: 0.6329 r:0.7189
ru_en Dev loss: 0.5197 r:0.7156
Current avg r:0.5885 Best avg r: 0.6216
08:55:39,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:57:11,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:58:42,792 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1301
en_de Dev loss: 0.8986 r:0.2150
en_zh Dev loss: 0.7758 r:0.4735
ro_en Dev loss: 0.3460 r:0.8179
et_en Dev loss: 0.4739 r:0.6714
si_en Dev loss: 0.8283 r:0.5591
ne_en Dev loss: 0.4978 r:0.7285
ru_en Dev loss: 0.4639 r:0.7235
Current avg r:0.5984 Best avg r: 0.6216
09:03:16,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:04:47,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:06:19,454 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1243
en_de Dev loss: 0.9032 r:0.2142
en_zh Dev loss: 0.7875 r:0.4734
ro_en Dev loss: 0.3537 r:0.8229
et_en Dev loss: 0.4555 r:0.6792
si_en Dev loss: 0.8976 r:0.5559
ne_en Dev loss: 0.5888 r:0.7272
ru_en Dev loss: 0.4584 r:0.7336
Current avg r:0.6009 Best avg r: 0.6216
09:10:53,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:12:25,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:13:56,809 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1323
en_de Dev loss: 0.8941 r:0.2047
en_zh Dev loss: 0.7665 r:0.4663
ro_en Dev loss: 0.3310 r:0.8226
et_en Dev loss: 0.4513 r:0.6761
si_en Dev loss: 0.8239 r:0.5578
ne_en Dev loss: 0.4802 r:0.7297
ru_en Dev loss: 0.4519 r:0.7256
Current avg r:0.5975 Best avg r: 0.6216
09:18:30,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:20:02,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:21:33,821 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1243
en_de Dev loss: 0.9048 r:0.2024
en_zh Dev loss: 0.7936 r:0.4527
ro_en Dev loss: 0.3548 r:0.8166
et_en Dev loss: 0.4560 r:0.6701
si_en Dev loss: 0.8727 r:0.5569
ne_en Dev loss: 0.5701 r:0.7208
ru_en Dev loss: 0.4807 r:0.7181
Current avg r:0.5911 Best avg r: 0.6216
09:26:08,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:27:40,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:29:11,563 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1228
en_de Dev loss: 0.9324 r:0.1703
en_zh Dev loss: 0.8372 r:0.4518
ro_en Dev loss: 0.3862 r:0.8109
et_en Dev loss: 0.4799 r:0.6615
si_en Dev loss: 1.0327 r:0.5408
ne_en Dev loss: 0.7060 r:0.7148
ru_en Dev loss: 0.5411 r:0.6988
Current avg r:0.5784 Best avg r: 0.6216
09:33:45,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:16,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:48,264 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1243
en_de Dev loss: 0.9191 r:0.1818
en_zh Dev loss: 0.8169 r:0.4642
ro_en Dev loss: 0.3619 r:0.8187
et_en Dev loss: 0.4533 r:0.6719
si_en Dev loss: 0.8990 r:0.5557
ne_en Dev loss: 0.5899 r:0.7147
ru_en Dev loss: 0.4926 r:0.7162
Current avg r:0.5890 Best avg r: 0.6216
09:41:22,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:54,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:44:25,855 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1259
en_de Dev loss: 0.9073 r:0.1854
en_zh Dev loss: 0.7877 r:0.4623
ro_en Dev loss: 0.3520 r:0.8197
et_en Dev loss: 0.4489 r:0.6752
si_en Dev loss: 0.8677 r:0.5578
ne_en Dev loss: 0.5407 r:0.7201
ru_en Dev loss: 0.4767 r:0.7286
Current avg r:0.5927 Best avg r: 0.6216
09:48:59,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:50:31,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:52:02,695 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1222
en_de Dev loss: 0.8957 r:0.1818
en_zh Dev loss: 0.7533 r:0.4711
ro_en Dev loss: 0.3264 r:0.8215
et_en Dev loss: 0.4183 r:0.6786
si_en Dev loss: 0.8432 r:0.5640
ne_en Dev loss: 0.5442 r:0.7224
ru_en Dev loss: 0.4499 r:0.7321
Current avg r:0.5959 Best avg r: 0.6216
09:56:36,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:07,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:39,194 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1218
en_de Dev loss: 0.9051 r:0.1944
en_zh Dev loss: 0.7579 r:0.4680
ro_en Dev loss: 0.3435 r:0.8221
et_en Dev loss: 0.4297 r:0.6818
si_en Dev loss: 0.9083 r:0.5567
ne_en Dev loss: 0.5852 r:0.7263
ru_en Dev loss: 0.4716 r:0.7333
Current avg r:0.5975 Best avg r: 0.6216
10:04:15,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:46,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:18,272 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1058
en_de Dev loss: 0.9435 r:0.1642
en_zh Dev loss: 0.8169 r:0.4670
ro_en Dev loss: 0.3797 r:0.8166
et_en Dev loss: 0.4696 r:0.6729
si_en Dev loss: 0.9648 r:0.5541
ne_en Dev loss: 0.5941 r:0.7267
ru_en Dev loss: 0.5061 r:0.7295
Current avg r:0.5902 Best avg r: 0.6216
10:11:52,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:24,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:56,129 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1139
en_de Dev loss: 0.9177 r:0.1833
en_zh Dev loss: 0.7754 r:0.4638
ro_en Dev loss: 0.3401 r:0.8120
et_en Dev loss: 0.4485 r:0.6727
si_en Dev loss: 0.8568 r:0.5567
ne_en Dev loss: 0.5463 r:0.7204
ru_en Dev loss: 0.4336 r:0.7392
Current avg r:0.5926 Best avg r: 0.6216
10:19:30,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:02,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:33,725 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1121
en_de Dev loss: 0.9288 r:0.1826
en_zh Dev loss: 0.7807 r:0.4678
ro_en Dev loss: 0.3478 r:0.8189
et_en Dev loss: 0.4370 r:0.6775
si_en Dev loss: 0.8800 r:0.5594
ne_en Dev loss: 0.5407 r:0.7269
ru_en Dev loss: 0.4509 r:0.7368
Current avg r:0.5957 Best avg r: 0.6216
10:27:07,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:39,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:10,783 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1110
en_de Dev loss: 0.9073 r:0.2003
en_zh Dev loss: 0.7766 r:0.4760
ro_en Dev loss: 0.3690 r:0.8140
et_en Dev loss: 0.4480 r:0.6818
si_en Dev loss: 0.9128 r:0.5543
ne_en Dev loss: 0.6025 r:0.7228
ru_en Dev loss: 0.4497 r:0.7399
Current avg r:0.5984 Best avg r: 0.6216
10:34:44,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:36:16,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:37:47,564 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1066
en_de Dev loss: 0.9367 r:0.1952
en_zh Dev loss: 0.7789 r:0.4754
ro_en Dev loss: 0.3626 r:0.8185
et_en Dev loss: 0.4546 r:0.6830
si_en Dev loss: 0.8273 r:0.5586
ne_en Dev loss: 0.5267 r:0.7232
ru_en Dev loss: 0.4608 r:0.7393
Current avg r:0.5990 Best avg r: 0.6216
10:42:21,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:43:52,790 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:45:24,272 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1142
en_de Dev loss: 0.9146 r:0.2003
en_zh Dev loss: 0.7932 r:0.4705
ro_en Dev loss: 0.3548 r:0.8138
et_en Dev loss: 0.4337 r:0.6813
si_en Dev loss: 0.8696 r:0.5580
ne_en Dev loss: 0.5789 r:0.7265
ru_en Dev loss: 0.4626 r:0.7332
Current avg r:0.5977 Best avg r: 0.6216
