14:38:36,707 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:39:02,518 root INFO 
id:en_zh cur r: 0.2746 best r: 0.2746
14:39:15,454 root INFO 
id:ro_en cur r: 0.6529 best r: 0.6529
14:39:41,390 root INFO 
id:et_en cur r: 0.4872 best r: 0.4872
14:39:54,368 root INFO 
id:si_en cur r: 0.4373 best r: 0.4373
14:40:07,349 root INFO 
id:ne_en cur r: 0.4991 best r: 0.4991
14:40:20,249 root INFO 
id:ru_en cur r: 0.6157 best r: 0.6157
14:40:20,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:41:50,930 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
14:41:50,937 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:41:50,942 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:41:50,946 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
14:41:50,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
14:41:50,956 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:41:50,961 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:42:03,929 root INFO Epoch 0 Global steps: 700 Train loss: 0.8136
en_de Dev loss: 0.9376 r:0.1035
en_zh Dev loss: 0.7762 r:0.2941
ro_en Dev loss: 0.5134 r:0.6642
et_en Dev loss: 0.5497 r:0.5096
si_en Dev loss: 0.6671 r:0.4522
ne_en Dev loss: 0.5645 r:0.5944
ru_en Dev loss: 0.5061 r:0.6435
Current avg r:0.4659 Best avg r: 0.4659
14:46:34,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:46:47,151 root INFO 
id:en_de cur r: 0.0744 best r: 0.0744
14:47:12,970 root INFO 
id:ro_en cur r: 0.6557 best r: 0.6557
14:47:38,870 root INFO 
id:et_en cur r: 0.5208 best r: 0.5208
14:47:51,834 root INFO 
id:si_en cur r: 0.4398 best r: 0.4398
14:48:04,787 root INFO 
id:ne_en cur r: 0.5257 best r: 0.5257
14:48:17,644 root INFO 
id:ru_en cur r: 0.6777 best r: 0.6777
14:48:17,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:48,113 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
14:49:48,119 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:49:48,123 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:49:48,128 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
14:49:48,132 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
14:49:48,137 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:49:48,141 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:50:01,100 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7748
en_de Dev loss: 0.9450 r:0.1034
en_zh Dev loss: 0.7564 r:0.3092
ro_en Dev loss: 0.5495 r:0.6894
et_en Dev loss: 0.5102 r:0.5679
si_en Dev loss: 0.7280 r:0.4601
ne_en Dev loss: 0.5563 r:0.6179
ru_en Dev loss: 0.5089 r:0.6945
Current avg r:0.4918 Best avg r: 0.4918
14:54:31,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:10,50 root INFO 
id:ro_en cur r: 0.6609 best r: 0.6609
14:55:35,938 root INFO 
id:et_en cur r: 0.5563 best r: 0.5563
14:56:14,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:45,191 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7048
en_de Dev loss: 0.9896 r:0.0959
en_zh Dev loss: 0.7910 r:0.3004
ro_en Dev loss: 0.5415 r:0.6922
et_en Dev loss: 0.4942 r:0.5816
si_en Dev loss: 0.8260 r:0.4429
ne_en Dev loss: 0.6013 r:0.5783
ru_en Dev loss: 0.5659 r:0.6651
Current avg r:0.4795 Best avg r: 0.4918
15:02:15,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:28,412 root INFO 
id:en_de cur r: 0.0941 best r: 0.0941
15:03:20,106 root INFO 
id:et_en cur r: 0.5600 best r: 0.5600
15:03:46,25 root INFO 
id:ne_en cur r: 0.5393 best r: 0.5393
15:03:58,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:29,369 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7033
en_de Dev loss: 1.0142 r:0.1138
en_zh Dev loss: 0.8252 r:0.2970
ro_en Dev loss: 0.5362 r:0.6878
et_en Dev loss: 0.4805 r:0.5932
si_en Dev loss: 0.7694 r:0.4561
ne_en Dev loss: 0.5577 r:0.5928
ru_en Dev loss: 0.6192 r:0.6398
Current avg r:0.4829 Best avg r: 0.4918
15:09:59,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:12,590 root INFO 
id:en_de cur r: 0.1025 best r: 0.1025
15:10:25,483 root INFO 
id:en_zh cur r: 0.3220 best r: 0.3220
15:10:38,413 root INFO 
id:ro_en cur r: 0.6872 best r: 0.6872
15:11:04,312 root INFO 
id:et_en cur r: 0.6216 best r: 0.6216
15:11:17,276 root INFO 
id:si_en cur r: 0.4718 best r: 0.4718
15:11:30,228 root INFO 
id:ne_en cur r: 0.5979 best r: 0.5979
15:11:43,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:13:13,574 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:13:13,581 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:13:13,586 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:13:13,591 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:13:13,596 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:13:13,601 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:13:13,607 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:13:26,565 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6317
en_de Dev loss: 0.9697 r:0.1481
en_zh Dev loss: 0.7420 r:0.3632
ro_en Dev loss: 0.4667 r:0.7258
et_en Dev loss: 0.4341 r:0.6424
si_en Dev loss: 0.7297 r:0.5017
ne_en Dev loss: 0.5426 r:0.6299
ru_en Dev loss: 0.5319 r:0.6967
Current avg r:0.5297 Best avg r: 0.5297
15:17:56,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:09,627 root INFO 
id:en_de cur r: 0.1272 best r: 0.1272
15:18:22,508 root INFO 
id:en_zh cur r: 0.3611 best r: 0.3611
15:18:35,433 root INFO 
id:ro_en cur r: 0.6962 best r: 0.6962
15:19:01,310 root INFO 
id:et_en cur r: 0.6261 best r: 0.6261
15:19:14,262 root INFO 
id:si_en cur r: 0.4969 best r: 0.4969
15:19:40,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:10,504 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:21:10,511 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:21:10,516 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:21:10,522 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:21:10,527 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:21:10,532 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:21:10,538 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:21:23,496 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6359
en_de Dev loss: 0.9757 r:0.1567
en_zh Dev loss: 0.7537 r:0.3820
ro_en Dev loss: 0.4707 r:0.7281
et_en Dev loss: 0.4281 r:0.6445
si_en Dev loss: 0.7450 r:0.5040
ne_en Dev loss: 0.5558 r:0.6295
ru_en Dev loss: 0.5403 r:0.6890
Current avg r:0.5334 Best avg r: 0.5334
15:25:53,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:06,425 root INFO 
id:en_de cur r: 0.1460 best r: 0.1460
15:26:32,213 root INFO 
id:ro_en cur r: 0.7153 best r: 0.7153
15:26:58,102 root INFO 
id:si_en cur r: 0.5012 best r: 0.5012
15:27:11,52 root INFO 
id:ne_en cur r: 0.6502 best r: 0.6502
15:27:23,871 root INFO 
id:ru_en cur r: 0.6824 best r: 0.6824
15:27:23,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:54,219 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:28:54,226 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:28:54,231 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:28:54,236 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:28:54,240 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:28:54,245 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:28:54,250 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:29:07,197 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6069
en_de Dev loss: 0.9437 r:0.1887
en_zh Dev loss: 0.7926 r:0.3886
ro_en Dev loss: 0.4295 r:0.7491
et_en Dev loss: 0.4144 r:0.6558
si_en Dev loss: 0.7589 r:0.5208
ne_en Dev loss: 0.4989 r:0.6614
ru_en Dev loss: 0.5264 r:0.6999
Current avg r:0.5520 Best avg r: 0.5520
15:33:36,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:02,718 root INFO 
id:en_zh cur r: 0.3690 best r: 0.3690
15:34:15,635 root INFO 
id:ro_en cur r: 0.7284 best r: 0.7284
15:35:07,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:37,601 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5855
en_de Dev loss: 0.9620 r:0.1727
en_zh Dev loss: 0.8107 r:0.3932
ro_en Dev loss: 0.4318 r:0.7483
et_en Dev loss: 0.4381 r:0.6432
si_en Dev loss: 0.7727 r:0.5191
ne_en Dev loss: 0.5135 r:0.6615
ru_en Dev loss: 0.5819 r:0.6795
Current avg r:0.5454 Best avg r: 0.5520
15:41:07,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:20,510 root INFO 
id:en_de cur r: 0.2046 best r: 0.2046
15:41:33,390 root INFO 
id:en_zh cur r: 0.4181 best r: 0.4181
15:41:46,309 root INFO 
id:ro_en cur r: 0.7494 best r: 0.7494
15:42:12,190 root INFO 
id:et_en cur r: 0.6587 best r: 0.6587
15:42:25,151 root INFO 
id:si_en cur r: 0.5221 best r: 0.5221
15:42:38,99 root INFO 
id:ne_en cur r: 0.6876 best r: 0.6876
15:42:50,932 root INFO 
id:ru_en cur r: 0.7240 best r: 0.7240
15:42:50,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:44:21,321 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:44:21,329 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:44:21,336 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:44:21,342 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:44:21,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:44:21,351 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:44:21,359 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:44:34,305 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5943
en_de Dev loss: 0.8998 r:0.2283
en_zh Dev loss: 0.7612 r:0.4368
ro_en Dev loss: 0.4047 r:0.7693
et_en Dev loss: 0.4286 r:0.6692
si_en Dev loss: 0.7719 r:0.5421
ne_en Dev loss: 0.5156 r:0.6884
ru_en Dev loss: 0.4809 r:0.7371
Current avg r:0.5816 Best avg r: 0.5816
15:49:04,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:17,194 root INFO 
id:en_de cur r: 0.2075 best r: 0.2075
15:49:42,982 root INFO 
id:ro_en cur r: 0.7680 best r: 0.7680
15:50:08,865 root INFO 
id:et_en cur r: 0.6630 best r: 0.6630
15:50:21,820 root INFO 
id:si_en cur r: 0.5468 best r: 0.5468
15:50:34,767 root INFO 
id:ne_en cur r: 0.7102 best r: 0.7102
15:50:47,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:52:18,51 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:52:18,59 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:52:18,64 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:52:18,68 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:52:18,73 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:52:18,77 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:52:18,84 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:52:31,42 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5571
en_de Dev loss: 0.8697 r:0.2350
en_zh Dev loss: 0.7544 r:0.4217
ro_en Dev loss: 0.3741 r:0.7787
et_en Dev loss: 0.4122 r:0.6729
si_en Dev loss: 0.6554 r:0.5640
ne_en Dev loss: 0.4729 r:0.6954
ru_en Dev loss: 0.4733 r:0.7317
Current avg r:0.5856 Best avg r: 0.5856
15:57:01,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:57:39,789 root INFO 
id:ro_en cur r: 0.7764 best r: 0.7764
15:58:05,670 root INFO 
id:et_en cur r: 0.6794 best r: 0.6794
15:58:18,625 root INFO 
id:si_en cur r: 0.5739 best r: 0.5739
15:58:31,574 root INFO 
id:ne_en cur r: 0.7229 best r: 0.7229
15:58:44,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:00:14,780 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:00:14,788 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:00:14,794 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:00:14,799 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:00:14,803 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:00:14,809 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:00:14,814 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:00:27,757 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5655
en_de Dev loss: 0.8617 r:0.2443
en_zh Dev loss: 0.7045 r:0.4323
ro_en Dev loss: 0.3375 r:0.7884
et_en Dev loss: 0.3688 r:0.6941
si_en Dev loss: 0.6074 r:0.5842
ne_en Dev loss: 0.3977 r:0.7230
ru_en Dev loss: 0.4862 r:0.7283
Current avg r:0.5992 Best avg r: 0.5992
16:04:57,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:10,719 root INFO 
id:en_de cur r: 0.2108 best r: 0.2108
16:05:23,608 root INFO 
id:en_zh cur r: 0.4429 best r: 0.4429
16:05:36,529 root INFO 
id:ro_en cur r: 0.7850 best r: 0.7850
16:06:02,436 root INFO 
id:si_en cur r: 0.5811 best r: 0.5811
16:06:15,386 root INFO 
id:ne_en cur r: 0.7333 best r: 0.7333
16:06:28,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:58,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:07:58,639 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:07:58,649 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:07:58,653 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:07:58,658 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:07:58,663 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:07:58,669 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:08:11,611 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5644
en_de Dev loss: 0.8639 r:0.2382
en_zh Dev loss: 0.7081 r:0.4457
ro_en Dev loss: 0.3595 r:0.7906
et_en Dev loss: 0.3946 r:0.6866
si_en Dev loss: 0.5780 r:0.5866
ne_en Dev loss: 0.3683 r:0.7359
ru_en Dev loss: 0.4547 r:0.7371
Current avg r:0.6030 Best avg r: 0.6030
16:12:41,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:54,652 root INFO 
id:en_de cur r: 0.2188 best r: 0.2188
16:13:20,444 root INFO 
id:ro_en cur r: 0.7891 best r: 0.7891
16:14:12,98 root INFO 
id:ru_en cur r: 0.7241 best r: 0.7241
16:14:12,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:42,501 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5400
en_de Dev loss: 0.8601 r:0.2379
en_zh Dev loss: 0.7350 r:0.4451
ro_en Dev loss: 0.3790 r:0.7951
et_en Dev loss: 0.4031 r:0.6820
si_en Dev loss: 0.7504 r:0.5680
ne_en Dev loss: 0.4668 r:0.7220
ru_en Dev loss: 0.4933 r:0.7345
Current avg r:0.5978 Best avg r: 0.6030
16:20:12,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:51,247 root INFO 
id:ro_en cur r: 0.7937 best r: 0.7937
16:21:30,95 root INFO 
id:ne_en cur r: 0.7452 best r: 0.7452
16:21:42,925 root INFO 
id:ru_en cur r: 0.7468 best r: 0.7468
16:21:42,926 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:13,333 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:23:13,340 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:23:13,345 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:23:13,349 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:23:13,354 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:23:13,360 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:23:13,365 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:23:26,301 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5371
en_de Dev loss: 0.8522 r:0.2357
en_zh Dev loss: 0.6710 r:0.4481
ro_en Dev loss: 0.3455 r:0.7938
et_en Dev loss: 0.3877 r:0.6882
si_en Dev loss: 0.5986 r:0.5827
ne_en Dev loss: 0.3840 r:0.7358
ru_en Dev loss: 0.3904 r:0.7578
Current avg r:0.6060 Best avg r: 0.6060
16:27:56,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:09,182 root INFO 
id:en_de cur r: 0.2309 best r: 0.2309
16:29:26,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:57,21 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5097
en_de Dev loss: 0.8890 r:0.2451
en_zh Dev loss: 0.7561 r:0.4267
ro_en Dev loss: 0.3913 r:0.7950
et_en Dev loss: 0.4290 r:0.6708
si_en Dev loss: 0.7418 r:0.5588
ne_en Dev loss: 0.4766 r:0.7252
ru_en Dev loss: 0.4893 r:0.7353
Current avg r:0.5938 Best avg r: 0.6060
16:35:29,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:07,789 root INFO 
id:ro_en cur r: 0.8019 best r: 0.8019
16:36:59,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:29,877 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4845
en_de Dev loss: 0.8801 r:0.2444
en_zh Dev loss: 0.7690 r:0.4258
ro_en Dev loss: 0.3688 r:0.8031
et_en Dev loss: 0.4014 r:0.6864
si_en Dev loss: 0.7326 r:0.5700
ne_en Dev loss: 0.4772 r:0.7277
ru_en Dev loss: 0.5183 r:0.7314
Current avg r:0.5984 Best avg r: 0.6060
16:42:59,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:38,631 root INFO 
id:ro_en cur r: 0.8070 best r: 0.8070
16:44:30,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:00,793 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4969
en_de Dev loss: 0.8441 r:0.2424
en_zh Dev loss: 0.7017 r:0.4471
ro_en Dev loss: 0.3337 r:0.8051
et_en Dev loss: 0.3973 r:0.6825
si_en Dev loss: 0.7453 r:0.5668
ne_en Dev loss: 0.4269 r:0.7368
ru_en Dev loss: 0.4643 r:0.7309
Current avg r:0.6016 Best avg r: 0.6060
16:50:30,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:09,68 root INFO 
id:ro_en cur r: 0.8125 best r: 0.8125
16:51:34,927 root INFO 
id:si_en cur r: 0.5836 best r: 0.5836
16:51:47,860 root INFO 
id:ne_en cur r: 0.7485 best r: 0.7485
16:52:00,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:30,997 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:53:31,4 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:53:31,8 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:53:31,12 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:53:31,17 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:53:31,22 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:53:31,27 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:53:43,963 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4868
en_de Dev loss: 0.8661 r:0.2337
en_zh Dev loss: 0.7513 r:0.4395
ro_en Dev loss: 0.3129 r:0.8137
et_en Dev loss: 0.4009 r:0.6868
si_en Dev loss: 0.6342 r:0.5863
ne_en Dev loss: 0.3586 r:0.7478
ru_en Dev loss: 0.4332 r:0.7480
Current avg r:0.6080 Best avg r: 0.6080
16:58:13,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:39,239 root INFO 
id:en_zh cur r: 0.4499 best r: 0.4499
16:58:52,127 root INFO 
id:ro_en cur r: 0.8147 best r: 0.8147
16:59:17,965 root INFO 
id:si_en cur r: 0.5959 best r: 0.5959
16:59:30,889 root INFO 
id:ne_en cur r: 0.7498 best r: 0.7498
16:59:43,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:14,30 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
17:01:14,38 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:01:14,43 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:01:14,47 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
17:01:14,53 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
17:01:14,58 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:01:14,64 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:01:26,991 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5103
en_de Dev loss: 0.8479 r:0.2391
en_zh Dev loss: 0.6846 r:0.4554
ro_en Dev loss: 0.3143 r:0.8158
et_en Dev loss: 0.4020 r:0.6851
si_en Dev loss: 0.6327 r:0.5964
ne_en Dev loss: 0.4036 r:0.7481
ru_en Dev loss: 0.4262 r:0.7496
Current avg r:0.6128 Best avg r: 0.6128
17:05:56,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:22,365 root INFO 
id:en_zh cur r: 0.4505 best r: 0.4505
17:06:35,271 root INFO 
id:ro_en cur r: 0.8228 best r: 0.8228
17:07:01,137 root INFO 
id:et_en cur r: 0.6833 best r: 0.6833
17:07:14,94 root INFO 
id:si_en cur r: 0.6025 best r: 0.6025
17:07:27,36 root INFO 
id:ne_en cur r: 0.7597 best r: 0.7597
17:07:39,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:10,186 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
17:09:10,194 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:09:10,198 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:09:10,203 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
17:09:10,207 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
17:09:10,214 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:09:10,219 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:09:23,156 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4852
en_de Dev loss: 0.8662 r:0.2494
en_zh Dev loss: 0.7103 r:0.4499
ro_en Dev loss: 0.3239 r:0.8168
et_en Dev loss: 0.4101 r:0.6877
si_en Dev loss: 0.6726 r:0.5916
ne_en Dev loss: 0.3766 r:0.7557
ru_en Dev loss: 0.4524 r:0.7451
Current avg r:0.6137 Best avg r: 0.6137
17:13:52,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:18,600 root INFO 
id:en_zh cur r: 0.4585 best r: 0.4585
17:15:23,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:53,479 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4403
en_de Dev loss: 0.8834 r:0.2342
en_zh Dev loss: 0.7400 r:0.4532
ro_en Dev loss: 0.3438 r:0.8142
et_en Dev loss: 0.4262 r:0.6854
si_en Dev loss: 0.7037 r:0.5859
ne_en Dev loss: 0.4135 r:0.7502
ru_en Dev loss: 0.4480 r:0.7431
Current avg r:0.6094 Best avg r: 0.6137
17:21:23,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:53,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:23,713 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4626
en_de Dev loss: 0.8368 r:0.2409
en_zh Dev loss: 0.6829 r:0.4569
ro_en Dev loss: 0.3020 r:0.8150
et_en Dev loss: 0.4104 r:0.6858
si_en Dev loss: 0.5690 r:0.5997
ne_en Dev loss: 0.3547 r:0.7533
ru_en Dev loss: 0.4316 r:0.7352
Current avg r:0.6124 Best avg r: 0.6137
17:28:53,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:06,229 root INFO 
id:en_de cur r: 0.2343 best r: 0.2343
17:30:23,665 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:54,15 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4735
en_de Dev loss: 0.8420 r:0.2464
en_zh Dev loss: 0.7064 r:0.4546
ro_en Dev loss: 0.3067 r:0.8149
et_en Dev loss: 0.4185 r:0.6803
si_en Dev loss: 0.5971 r:0.5978
ne_en Dev loss: 0.3567 r:0.7530
ru_en Dev loss: 0.4225 r:0.7452
Current avg r:0.6132 Best avg r: 0.6137
17:36:23,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:36,610 root INFO 
id:en_de cur r: 0.2650 best r: 0.2650
17:36:49,484 root INFO 
id:en_zh cur r: 0.4621 best r: 0.4621
17:37:28,271 root INFO 
id:et_en cur r: 0.6881 best r: 0.6881
17:37:54,156 root INFO 
id:ne_en cur r: 0.7647 best r: 0.7647
17:38:06,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:37,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
17:39:37,282 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:39:37,287 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:39:37,291 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
17:39:37,296 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
17:39:37,300 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:39:37,306 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:39:50,239 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4737
en_de Dev loss: 0.8443 r:0.2557
en_zh Dev loss: 0.6925 r:0.4633
ro_en Dev loss: 0.3012 r:0.8215
et_en Dev loss: 0.3961 r:0.6935
si_en Dev loss: 0.6466 r:0.5909
ne_en Dev loss: 0.4015 r:0.7591
ru_en Dev loss: 0.3981 r:0.7520
Current avg r:0.6194 Best avg r: 0.6194
17:44:19,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:50,296 root INFO 
id:ru_en cur r: 0.7535 best r: 0.7535
17:45:50,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:20,593 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4579
en_de Dev loss: 0.8491 r:0.2431
en_zh Dev loss: 0.7359 r:0.4572
ro_en Dev loss: 0.3296 r:0.8204
et_en Dev loss: 0.4535 r:0.6784
si_en Dev loss: 0.7373 r:0.5838
ne_en Dev loss: 0.4584 r:0.7606
ru_en Dev loss: 0.4062 r:0.7603
Current avg r:0.6149 Best avg r: 0.6194
17:51:50,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:20,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:50,735 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4438
en_de Dev loss: 0.8375 r:0.2451
en_zh Dev loss: 0.6834 r:0.4671
ro_en Dev loss: 0.3123 r:0.8180
et_en Dev loss: 0.4494 r:0.6818
si_en Dev loss: 0.6019 r:0.5958
ne_en Dev loss: 0.3606 r:0.7531
ru_en Dev loss: 0.4191 r:0.7494
Current avg r:0.6158 Best avg r: 0.6194
17:59:20,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:46,156 root INFO 
id:en_zh cur r: 0.4724 best r: 0.4724
18:00:50,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:20,984 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4431
en_de Dev loss: 0.8428 r:0.2310
en_zh Dev loss: 0.6892 r:0.4732
ro_en Dev loss: 0.3304 r:0.8166
et_en Dev loss: 0.4583 r:0.6742
si_en Dev loss: 0.6819 r:0.5862
ne_en Dev loss: 0.3892 r:0.7599
ru_en Dev loss: 0.4335 r:0.7381
Current avg r:0.6113 Best avg r: 0.6194
18:06:50,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:20,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:51,228 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4575
en_de Dev loss: 0.8547 r:0.2151
en_zh Dev loss: 0.7096 r:0.4526
ro_en Dev loss: 0.3421 r:0.8122
et_en Dev loss: 0.4590 r:0.6635
si_en Dev loss: 0.6379 r:0.5938
ne_en Dev loss: 0.3850 r:0.7560
ru_en Dev loss: 0.4874 r:0.7121
Current avg r:0.6008 Best avg r: 0.6194
18:14:20,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:59,679 root INFO 
id:ro_en cur r: 0.8251 best r: 0.8251
18:15:38,492 root INFO 
id:ne_en cur r: 0.7684 best r: 0.7684
18:15:51,339 root INFO 
id:ru_en cur r: 0.7541 best r: 0.7541
18:15:51,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:21,641 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
18:17:21,649 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:17:21,653 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:17:21,658 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
18:17:21,663 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
18:17:21,669 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:17:21,675 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:17:34,609 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4687
en_de Dev loss: 0.8490 r:0.2331
en_zh Dev loss: 0.7010 r:0.4752
ro_en Dev loss: 0.3406 r:0.8247
et_en Dev loss: 0.4556 r:0.6807
si_en Dev loss: 0.6544 r:0.6041
ne_en Dev loss: 0.4107 r:0.7675
ru_en Dev loss: 0.4176 r:0.7555
Current avg r:0.6201 Best avg r: 0.6201
18:22:04,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:34,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:04,963 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4306
en_de Dev loss: 0.8610 r:0.2434
en_zh Dev loss: 0.7216 r:0.4603
ro_en Dev loss: 0.3420 r:0.8164
et_en Dev loss: 0.4422 r:0.6716
si_en Dev loss: 0.6657 r:0.5928
ne_en Dev loss: 0.3661 r:0.7638
ru_en Dev loss: 0.4449 r:0.7392
Current avg r:0.6125 Best avg r: 0.6201
18:29:36,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:48,907 root INFO 
id:en_de cur r: 0.2664 best r: 0.2664
18:30:14,704 root INFO 
id:ro_en cur r: 0.8254 best r: 0.8254
18:31:06,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:36,537 root INFO Epoch 2 Global steps: 21700 Train loss: 0.3961
en_de Dev loss: 0.8366 r:0.2470
en_zh Dev loss: 0.7147 r:0.4673
ro_en Dev loss: 0.3050 r:0.8233
et_en Dev loss: 0.4390 r:0.6764
si_en Dev loss: 0.6935 r:0.5937
ne_en Dev loss: 0.4157 r:0.7606
ru_en Dev loss: 0.4178 r:0.7455
Current avg r:0.6163 Best avg r: 0.6201
18:37:06,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:37:31,992 root INFO 
id:en_zh cur r: 0.4727 best r: 0.4727
18:37:44,906 root INFO 
id:ro_en cur r: 0.8301 best r: 0.8301
18:38:10,769 root INFO 
id:si_en cur r: 0.6170 best r: 0.6170
18:38:36,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:06,774 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
18:40:06,782 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:40:06,787 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:40:06,792 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
18:40:06,797 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
18:40:06,801 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:40:06,805 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:40:19,731 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4127
en_de Dev loss: 0.8400 r:0.2313
en_zh Dev loss: 0.6676 r:0.4695
ro_en Dev loss: 0.2908 r:0.8261
et_en Dev loss: 0.4455 r:0.6882
si_en Dev loss: 0.5260 r:0.6221
ne_en Dev loss: 0.3211 r:0.7721
ru_en Dev loss: 0.3728 r:0.7557
Current avg r:0.6236 Best avg r: 0.6236
18:44:49,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:19,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:49,973 root INFO Epoch 2 Global steps: 23100 Train loss: 0.3931
en_de Dev loss: 0.8724 r:0.2254
en_zh Dev loss: 0.7528 r:0.4549
ro_en Dev loss: 0.3625 r:0.8132
et_en Dev loss: 0.4653 r:0.6656
si_en Dev loss: 0.6741 r:0.5991
ne_en Dev loss: 0.5228 r:0.7574
ru_en Dev loss: 0.5024 r:0.7181
Current avg r:0.6048 Best avg r: 0.6236
18:52:19,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:45,428 root INFO 
id:en_zh cur r: 0.4788 best r: 0.4788
18:53:49,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:19,975 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4065
en_de Dev loss: 0.8421 r:0.2554
en_zh Dev loss: 0.7038 r:0.4760
ro_en Dev loss: 0.3465 r:0.8178
et_en Dev loss: 0.4491 r:0.6746
si_en Dev loss: 0.6869 r:0.5973
ne_en Dev loss: 0.4315 r:0.7602
ru_en Dev loss: 0.4717 r:0.7273
Current avg r:0.6155 Best avg r: 0.6236
18:59:49,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:19,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:49,901 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4140
en_de Dev loss: 0.8507 r:0.2406
en_zh Dev loss: 0.7199 r:0.4701
ro_en Dev loss: 0.3512 r:0.8223
et_en Dev loss: 0.4622 r:0.6796
si_en Dev loss: 0.7105 r:0.6017
ne_en Dev loss: 0.4450 r:0.7591
ru_en Dev loss: 0.4915 r:0.7278
Current avg r:0.6144 Best avg r: 0.6236
19:07:19,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:32,391 root INFO 
id:en_de cur r: 0.2836 best r: 0.2836
19:08:49,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:19,891 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4167
en_de Dev loss: 0.8526 r:0.2661
en_zh Dev loss: 0.7339 r:0.4524
ro_en Dev loss: 0.3244 r:0.8161
et_en Dev loss: 0.4466 r:0.6698
si_en Dev loss: 0.6885 r:0.5949
ne_en Dev loss: 0.4390 r:0.7552
ru_en Dev loss: 0.4657 r:0.7226
Current avg r:0.6110 Best avg r: 0.6236
19:14:49,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:19,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:49,796 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4191
en_de Dev loss: 0.8353 r:0.2690
en_zh Dev loss: 0.7591 r:0.4518
ro_en Dev loss: 0.3354 r:0.8198
et_en Dev loss: 0.4711 r:0.6550
si_en Dev loss: 0.7322 r:0.5966
ne_en Dev loss: 0.4356 r:0.7599
ru_en Dev loss: 0.4979 r:0.7174
Current avg r:0.6099 Best avg r: 0.6236
19:22:19,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:44,981 root INFO 
id:en_zh cur r: 0.4836 best r: 0.4836
19:23:36,577 root INFO 
id:ne_en cur r: 0.7714 best r: 0.7714
19:23:49,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:19,500 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
19:25:19,507 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
19:25:19,514 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
19:25:19,519 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
19:25:19,523 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
19:25:19,528 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
19:25:19,535 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.25_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
19:25:32,460 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3843
en_de Dev loss: 0.8453 r:0.2541
en_zh Dev loss: 0.7236 r:0.4740
ro_en Dev loss: 0.3384 r:0.8276
et_en Dev loss: 0.4411 r:0.6796
si_en Dev loss: 0.7010 r:0.6179
ne_en Dev loss: 0.4455 r:0.7694
ru_en Dev loss: 0.4358 r:0.7456
Current avg r:0.6240 Best avg r: 0.6240
19:30:02,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:14,884 root INFO 
id:en_de cur r: 0.2868 best r: 0.2868
19:31:32,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:02,268 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4173
en_de Dev loss: 0.8251 r:0.2741
en_zh Dev loss: 0.6873 r:0.4731
ro_en Dev loss: 0.3170 r:0.8199
et_en Dev loss: 0.4376 r:0.6720
si_en Dev loss: 0.8020 r:0.6020
ne_en Dev loss: 0.4029 r:0.7664
ru_en Dev loss: 0.4483 r:0.7298
Current avg r:0.6196 Best avg r: 0.6240
19:37:31,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:01,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:32,166 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3990
en_de Dev loss: 0.8774 r:0.2605
en_zh Dev loss: 0.8214 r:0.4539
ro_en Dev loss: 0.3853 r:0.8142
et_en Dev loss: 0.5122 r:0.6597
si_en Dev loss: 0.7773 r:0.5982
ne_en Dev loss: 0.4679 r:0.7540
ru_en Dev loss: 0.5519 r:0.7174
Current avg r:0.6083 Best avg r: 0.6240
19:45:01,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:31,976 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:02,150 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3932
en_de Dev loss: 0.8350 r:0.2614
en_zh Dev loss: 0.7156 r:0.4620
ro_en Dev loss: 0.3198 r:0.8194
et_en Dev loss: 0.4631 r:0.6668
si_en Dev loss: 0.6131 r:0.6083
ne_en Dev loss: 0.3624 r:0.7567
ru_en Dev loss: 0.4240 r:0.7409
Current avg r:0.6165 Best avg r: 0.6240
19:52:31,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:01,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:32,117 root INFO Epoch 2 Global steps: 29400 Train loss: 0.4151
en_de Dev loss: 0.8347 r:0.2635
en_zh Dev loss: 0.7064 r:0.4625
ro_en Dev loss: 0.3069 r:0.8236
et_en Dev loss: 0.4389 r:0.6764
si_en Dev loss: 0.6994 r:0.6026
ne_en Dev loss: 0.3560 r:0.7624
ru_en Dev loss: 0.4113 r:0.7427
Current avg r:0.6191 Best avg r: 0.6240
20:00:01,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:01:31,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:02,89 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3621
en_de Dev loss: 0.8562 r:0.2661
en_zh Dev loss: 0.7896 r:0.4455
ro_en Dev loss: 0.3536 r:0.8152
et_en Dev loss: 0.5013 r:0.6553
si_en Dev loss: 0.8343 r:0.5825
ne_en Dev loss: 0.4315 r:0.7566
ru_en Dev loss: 0.5084 r:0.7180
Current avg r:0.6056 Best avg r: 0.6240
20:07:31,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:07:44,549 root INFO 
id:en_de cur r: 0.2895 best r: 0.2895
20:09:01,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:31,921 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3599
en_de Dev loss: 0.8580 r:0.2597
en_zh Dev loss: 0.7929 r:0.4427
ro_en Dev loss: 0.3543 r:0.8208
et_en Dev loss: 0.4888 r:0.6622
si_en Dev loss: 0.7257 r:0.5984
ne_en Dev loss: 0.3749 r:0.7654
ru_en Dev loss: 0.5279 r:0.7113
Current avg r:0.6086 Best avg r: 0.6240
20:15:01,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:31,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:01,862 root INFO Epoch 2 Global steps: 31500 Train loss: 0.4015
en_de Dev loss: 0.8408 r:0.2430
en_zh Dev loss: 0.7414 r:0.4537
ro_en Dev loss: 0.3471 r:0.8177
et_en Dev loss: 0.4843 r:0.6651
si_en Dev loss: 0.7026 r:0.6065
ne_en Dev loss: 0.4205 r:0.7574
ru_en Dev loss: 0.4683 r:0.7183
Current avg r:0.6088 Best avg r: 0.6240
20:22:33,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:03,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:33,316 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3613
en_de Dev loss: 0.8649 r:0.2563
en_zh Dev loss: 0.8211 r:0.4505
ro_en Dev loss: 0.3915 r:0.8174
et_en Dev loss: 0.4952 r:0.6581
si_en Dev loss: 0.8726 r:0.5932
ne_en Dev loss: 0.5331 r:0.7582
ru_en Dev loss: 0.5388 r:0.7147
Current avg r:0.6069 Best avg r: 0.6240
20:30:03,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:15,958 root INFO 
id:en_de cur r: 0.3041 best r: 0.3041
20:31:33,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:03,537 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3625
en_de Dev loss: 0.8265 r:0.2758
en_zh Dev loss: 0.7161 r:0.4522
ro_en Dev loss: 0.3197 r:0.8203
et_en Dev loss: 0.4268 r:0.6684
si_en Dev loss: 0.7499 r:0.5932
ne_en Dev loss: 0.4998 r:0.7620
ru_en Dev loss: 0.4376 r:0.7229
Current avg r:0.6136 Best avg r: 0.6240
20:37:33,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:03,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:33,639 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3737
en_de Dev loss: 0.8367 r:0.2647
en_zh Dev loss: 0.7841 r:0.4497
ro_en Dev loss: 0.3731 r:0.8176
et_en Dev loss: 0.4833 r:0.6549
si_en Dev loss: 0.8626 r:0.5872
ne_en Dev loss: 0.5241 r:0.7543
ru_en Dev loss: 0.5224 r:0.7118
Current avg r:0.6057 Best avg r: 0.6240
20:45:03,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:33,527 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:03,712 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3454
en_de Dev loss: 0.8375 r:0.2604
en_zh Dev loss: 0.7860 r:0.4445
ro_en Dev loss: 0.3896 r:0.8140
et_en Dev loss: 0.4884 r:0.6617
si_en Dev loss: 0.7545 r:0.5969
ne_en Dev loss: 0.5238 r:0.7535
ru_en Dev loss: 0.5413 r:0.7059
Current avg r:0.6053 Best avg r: 0.6240
20:52:33,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:03,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:33,559 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3418
en_de Dev loss: 0.8459 r:0.2555
en_zh Dev loss: 0.7587 r:0.4409
ro_en Dev loss: 0.3606 r:0.8148
et_en Dev loss: 0.4907 r:0.6702
si_en Dev loss: 0.7168 r:0.5983
ne_en Dev loss: 0.4566 r:0.7504
ru_en Dev loss: 0.4991 r:0.7101
Current avg r:0.6057 Best avg r: 0.6240
21:00:03,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:33,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:03,459 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3416
en_de Dev loss: 0.8455 r:0.2389
en_zh Dev loss: 0.7978 r:0.4396
ro_en Dev loss: 0.3646 r:0.8121
et_en Dev loss: 0.4846 r:0.6484
si_en Dev loss: 0.9136 r:0.5762
ne_en Dev loss: 0.5409 r:0.7490
ru_en Dev loss: 0.5065 r:0.7087
Current avg r:0.5961 Best avg r: 0.6240
21:07:33,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:03,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:33,437 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3396
en_de Dev loss: 0.8545 r:0.2411
en_zh Dev loss: 0.7606 r:0.4351
ro_en Dev loss: 0.3457 r:0.8175
et_en Dev loss: 0.4524 r:0.6676
si_en Dev loss: 0.7731 r:0.5897
ne_en Dev loss: 0.4914 r:0.7511
ru_en Dev loss: 0.5041 r:0.7090
Current avg r:0.6016 Best avg r: 0.6240
21:15:03,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:33,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:03,416 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3701
en_de Dev loss: 0.8812 r:0.2331
en_zh Dev loss: 0.8207 r:0.4126
ro_en Dev loss: 0.3545 r:0.8105
et_en Dev loss: 0.4659 r:0.6527
si_en Dev loss: 0.7995 r:0.5743
ne_en Dev loss: 0.4791 r:0.7454
ru_en Dev loss: 0.5602 r:0.6807
Current avg r:0.5870 Best avg r: 0.6240
21:22:33,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:03,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:33,406 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3460
en_de Dev loss: 0.8487 r:0.2381
en_zh Dev loss: 0.7771 r:0.4292
ro_en Dev loss: 0.3435 r:0.8162
et_en Dev loss: 0.4655 r:0.6604
si_en Dev loss: 0.7198 r:0.5841
ne_en Dev loss: 0.4734 r:0.7555
ru_en Dev loss: 0.4399 r:0.7295
Current avg r:0.6018 Best avg r: 0.6240
21:30:03,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:33,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:03,488 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3213
en_de Dev loss: 0.8565 r:0.2589
en_zh Dev loss: 0.8001 r:0.4373
ro_en Dev loss: 0.3721 r:0.8177
et_en Dev loss: 0.4949 r:0.6562
si_en Dev loss: 0.7788 r:0.5887
ne_en Dev loss: 0.4745 r:0.7484
ru_en Dev loss: 0.5208 r:0.6902
Current avg r:0.5996 Best avg r: 0.6240
21:37:33,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:03,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:33,435 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3424
en_de Dev loss: 0.8768 r:0.2407
en_zh Dev loss: 0.8049 r:0.4327
ro_en Dev loss: 0.3552 r:0.8215
et_en Dev loss: 0.4944 r:0.6533
si_en Dev loss: 0.7905 r:0.5876
ne_en Dev loss: 0.4482 r:0.7481
ru_en Dev loss: 0.4763 r:0.7240
Current avg r:0.6011 Best avg r: 0.6240
21:45:03,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:46:33,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:03,542 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3592
en_de Dev loss: 0.8551 r:0.2341
en_zh Dev loss: 0.7788 r:0.4211
ro_en Dev loss: 0.3244 r:0.8228
et_en Dev loss: 0.4727 r:0.6531
si_en Dev loss: 0.7996 r:0.5788
ne_en Dev loss: 0.5135 r:0.7441
ru_en Dev loss: 0.5095 r:0.7018
Current avg r:0.5937 Best avg r: 0.6240
21:52:33,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:03,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:55:33,644 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3292
en_de Dev loss: 0.8697 r:0.2474
en_zh Dev loss: 0.7759 r:0.4299
ro_en Dev loss: 0.3361 r:0.8215
et_en Dev loss: 0.4802 r:0.6596
si_en Dev loss: 0.7704 r:0.5931
ne_en Dev loss: 0.4690 r:0.7499
ru_en Dev loss: 0.4729 r:0.7207
Current avg r:0.6032 Best avg r: 0.6240
22:00:03,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:42,40 root INFO 
id:ro_en cur r: 0.8306 best r: 0.8306
22:01:33,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:03,802 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3410
en_de Dev loss: 0.8439 r:0.2237
en_zh Dev loss: 0.7228 r:0.4420
ro_en Dev loss: 0.2878 r:0.8298
et_en Dev loss: 0.4567 r:0.6811
si_en Dev loss: 0.5911 r:0.6127
ne_en Dev loss: 0.3979 r:0.7527
ru_en Dev loss: 0.4837 r:0.7075
Current avg r:0.6071 Best avg r: 0.6240
22:07:33,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:03,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:34,37 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3469
en_de Dev loss: 0.8613 r:0.2471
en_zh Dev loss: 0.8080 r:0.4216
ro_en Dev loss: 0.3571 r:0.8228
et_en Dev loss: 0.4856 r:0.6648
si_en Dev loss: 0.8417 r:0.5923
ne_en Dev loss: 0.4497 r:0.7560
ru_en Dev loss: 0.4698 r:0.7318
Current avg r:0.6052 Best avg r: 0.6240
22:15:05,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:16:35,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:05,859 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3165
en_de Dev loss: 0.8748 r:0.2002
en_zh Dev loss: 0.7378 r:0.4514
ro_en Dev loss: 0.3137 r:0.8222
et_en Dev loss: 0.4666 r:0.6597
si_en Dev loss: 0.7327 r:0.5890
ne_en Dev loss: 0.4284 r:0.7514
ru_en Dev loss: 0.4321 r:0.7295
Current avg r:0.6005 Best avg r: 0.6240
22:22:35,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:24:05,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:25:36,128 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2969
en_de Dev loss: 0.8464 r:0.2414
en_zh Dev loss: 0.7458 r:0.4500
ro_en Dev loss: 0.3096 r:0.8234
et_en Dev loss: 0.4736 r:0.6618
si_en Dev loss: 0.6761 r:0.6007
ne_en Dev loss: 0.4245 r:0.7522
ru_en Dev loss: 0.4352 r:0.7273
Current avg r:0.6081 Best avg r: 0.6240
22:30:05,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:36,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:33:06,166 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2984
en_de Dev loss: 0.8358 r:0.2514
en_zh Dev loss: 0.7674 r:0.4427
ro_en Dev loss: 0.3407 r:0.8175
et_en Dev loss: 0.5001 r:0.6579
si_en Dev loss: 0.7418 r:0.5907
ne_en Dev loss: 0.4677 r:0.7506
ru_en Dev loss: 0.4812 r:0.7148
Current avg r:0.6037 Best avg r: 0.6240
22:37:35,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:39:06,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:36,122 root INFO Epoch 4 Global steps: 44800 Train loss: 0.3034
en_de Dev loss: 0.8410 r:0.2515
en_zh Dev loss: 0.7452 r:0.4532
ro_en Dev loss: 0.3521 r:0.8207
et_en Dev loss: 0.4793 r:0.6612
si_en Dev loss: 0.7729 r:0.5935
ne_en Dev loss: 0.5234 r:0.7478
ru_en Dev loss: 0.4529 r:0.7296
Current avg r:0.6082 Best avg r: 0.6240
22:45:05,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:35,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:48:06,161 root INFO Epoch 4 Global steps: 45500 Train loss: 0.3076
en_de Dev loss: 0.8575 r:0.2481
en_zh Dev loss: 0.7823 r:0.4439
ro_en Dev loss: 0.3679 r:0.8189
et_en Dev loss: 0.5018 r:0.6542
si_en Dev loss: 0.7945 r:0.5868
ne_en Dev loss: 0.5073 r:0.7490
ru_en Dev loss: 0.5127 r:0.7114
Current avg r:0.6018 Best avg r: 0.6240
22:52:35,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:54:06,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:36,186 root INFO Epoch 4 Global steps: 46200 Train loss: 0.3162
en_de Dev loss: 0.8614 r:0.2289
en_zh Dev loss: 0.8598 r:0.4197
ro_en Dev loss: 0.3949 r:0.8162
et_en Dev loss: 0.5295 r:0.6423
si_en Dev loss: 0.8563 r:0.5829
ne_en Dev loss: 0.5580 r:0.7478
ru_en Dev loss: 0.5111 r:0.7104
Current avg r:0.5926 Best avg r: 0.6240
23:00:05,915 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:35,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:06,96 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2999
en_de Dev loss: 0.8623 r:0.2232
en_zh Dev loss: 0.7859 r:0.4417
ro_en Dev loss: 0.3542 r:0.8207
et_en Dev loss: 0.4653 r:0.6594
si_en Dev loss: 0.7734 r:0.5872
ne_en Dev loss: 0.4587 r:0.7518
ru_en Dev loss: 0.4698 r:0.7214
Current avg r:0.6008 Best avg r: 0.6240
23:07:35,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:09:05,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:35,860 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2845
en_de Dev loss: 0.8541 r:0.2457
en_zh Dev loss: 0.8186 r:0.4382
ro_en Dev loss: 0.3533 r:0.8219
et_en Dev loss: 0.5208 r:0.6669
si_en Dev loss: 0.7561 r:0.5844
ne_en Dev loss: 0.4280 r:0.7371
ru_en Dev loss: 0.4917 r:0.7194
Current avg r:0.6019 Best avg r: 0.6240
23:15:05,403 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:35,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:05,569 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2860
en_de Dev loss: 0.8487 r:0.2481
en_zh Dev loss: 0.7595 r:0.4433
ro_en Dev loss: 0.3250 r:0.8254
et_en Dev loss: 0.4638 r:0.6673
si_en Dev loss: 0.7542 r:0.5863
ne_en Dev loss: 0.4632 r:0.7458
ru_en Dev loss: 0.4227 r:0.7415
Current avg r:0.6083 Best avg r: 0.6240
23:22:35,153 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:05,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:35,349 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2922
en_de Dev loss: 0.8836 r:0.2473
en_zh Dev loss: 0.8460 r:0.4265
ro_en Dev loss: 0.3829 r:0.8192
et_en Dev loss: 0.4939 r:0.6553
si_en Dev loss: 0.8478 r:0.5747
ne_en Dev loss: 0.4877 r:0.7491
ru_en Dev loss: 0.4999 r:0.7197
Current avg r:0.5988 Best avg r: 0.6240
23:30:04,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:35,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:05,144 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2981
en_de Dev loss: 0.8447 r:0.2400
en_zh Dev loss: 0.7953 r:0.4271
ro_en Dev loss: 0.3528 r:0.8187
et_en Dev loss: 0.4966 r:0.6628
si_en Dev loss: 0.7297 r:0.5822
ne_en Dev loss: 0.4148 r:0.7477
ru_en Dev loss: 0.4584 r:0.7182
Current avg r:0.5995 Best avg r: 0.6240
23:37:34,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:04,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:35,5 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2896
en_de Dev loss: 0.8671 r:0.2087
en_zh Dev loss: 0.8531 r:0.4089
ro_en Dev loss: 0.3954 r:0.8165
et_en Dev loss: 0.4980 r:0.6583
si_en Dev loss: 0.8887 r:0.5732
ne_en Dev loss: 0.5320 r:0.7463
ru_en Dev loss: 0.4880 r:0.7171
Current avg r:0.5899 Best avg r: 0.6240
23:45:04,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:35,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:05,362 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2900
en_de Dev loss: 0.8484 r:0.2302
en_zh Dev loss: 0.8073 r:0.4393
ro_en Dev loss: 0.3583 r:0.8237
et_en Dev loss: 0.4693 r:0.6716
si_en Dev loss: 0.9130 r:0.5749
ne_en Dev loss: 0.5522 r:0.7417
ru_en Dev loss: 0.4571 r:0.7317
Current avg r:0.6019 Best avg r: 0.6240
23:52:35,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:05,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:35,702 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2806
en_de Dev loss: 0.8723 r:0.2213
en_zh Dev loss: 0.7982 r:0.4468
ro_en Dev loss: 0.3777 r:0.8258
et_en Dev loss: 0.4717 r:0.6735
si_en Dev loss: 0.8873 r:0.5826
ne_en Dev loss: 0.5584 r:0.7431
ru_en Dev loss: 0.4642 r:0.7362
Current avg r:0.6042 Best avg r: 0.6240
00:00:05,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:35,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:05,806 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2810
en_de Dev loss: 0.8848 r:0.2151
en_zh Dev loss: 0.8320 r:0.4158
ro_en Dev loss: 0.3568 r:0.8222
et_en Dev loss: 0.4543 r:0.6756
si_en Dev loss: 0.8381 r:0.5870
ne_en Dev loss: 0.5655 r:0.7477
ru_en Dev loss: 0.4770 r:0.7261
Current avg r:0.5985 Best avg r: 0.6240
00:07:37,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:07,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:37,566 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2675
en_de Dev loss: 0.9135 r:0.2062
en_zh Dev loss: 0.9602 r:0.4119
ro_en Dev loss: 0.4505 r:0.8127
et_en Dev loss: 0.5360 r:0.6565
si_en Dev loss: 1.0115 r:0.5705
ne_en Dev loss: 0.6496 r:0.7338
ru_en Dev loss: 0.6073 r:0.7017
Current avg r:0.5848 Best avg r: 0.6240
00:15:07,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:16:37,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:18:07,514 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2547
en_de Dev loss: 0.8619 r:0.2058
en_zh Dev loss: 0.8022 r:0.4243
ro_en Dev loss: 0.3487 r:0.8203
et_en Dev loss: 0.4681 r:0.6672
si_en Dev loss: 0.7878 r:0.5854
ne_en Dev loss: 0.5152 r:0.7375
ru_en Dev loss: 0.4792 r:0.7141
Current avg r:0.5935 Best avg r: 0.6240
00:22:37,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:07,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:37,373 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2584
en_de Dev loss: 0.8960 r:0.1845
en_zh Dev loss: 0.9045 r:0.4102
ro_en Dev loss: 0.4111 r:0.8177
et_en Dev loss: 0.5014 r:0.6605
si_en Dev loss: 0.9815 r:0.5736
ne_en Dev loss: 0.7016 r:0.7393
ru_en Dev loss: 0.5392 r:0.7139
Current avg r:0.5857 Best avg r: 0.6240
00:30:07,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:37,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:33:07,176 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2437
en_de Dev loss: 0.9210 r:0.1857
en_zh Dev loss: 0.9403 r:0.4127
ro_en Dev loss: 0.3976 r:0.8185
et_en Dev loss: 0.5258 r:0.6499
si_en Dev loss: 0.9769 r:0.5630
ne_en Dev loss: 0.5690 r:0.7326
ru_en Dev loss: 0.5534 r:0.7006
Current avg r:0.5804 Best avg r: 0.6240
00:37:36,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:39:06,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:36,958 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2646
en_de Dev loss: 0.8874 r:0.2031
en_zh Dev loss: 0.8472 r:0.4176
ro_en Dev loss: 0.3543 r:0.8206
et_en Dev loss: 0.4783 r:0.6597
si_en Dev loss: 0.8153 r:0.5819
ne_en Dev loss: 0.4987 r:0.7390
ru_en Dev loss: 0.4810 r:0.7119
Current avg r:0.5906 Best avg r: 0.6240
00:45:06,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:36,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:48:06,540 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2533
en_de Dev loss: 0.8971 r:0.1931
en_zh Dev loss: 0.8270 r:0.4106
ro_en Dev loss: 0.3368 r:0.8226
et_en Dev loss: 0.4798 r:0.6593
si_en Dev loss: 0.8236 r:0.5772
ne_en Dev loss: 0.4809 r:0.7454
ru_en Dev loss: 0.4781 r:0.7112
Current avg r:0.5885 Best avg r: 0.6240
00:52:36,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:54:06,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:36,7 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2659
en_de Dev loss: 0.8964 r:0.1845
en_zh Dev loss: 0.8883 r:0.4061
ro_en Dev loss: 0.3728 r:0.8239
et_en Dev loss: 0.4866 r:0.6674
si_en Dev loss: 0.8277 r:0.5843
ne_en Dev loss: 0.5158 r:0.7436
ru_en Dev loss: 0.5079 r:0.7164
Current avg r:0.5895 Best avg r: 0.6240
01:00:05,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:01:35,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:05,473 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2566
en_de Dev loss: 0.8660 r:0.2181
en_zh Dev loss: 0.8200 r:0.4148
ro_en Dev loss: 0.3370 r:0.8216
et_en Dev loss: 0.4765 r:0.6629
si_en Dev loss: 0.8240 r:0.5764
ne_en Dev loss: 0.5195 r:0.7456
ru_en Dev loss: 0.4721 r:0.7227
Current avg r:0.5946 Best avg r: 0.6240
01:07:34,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:04,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:34,866 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2362
en_de Dev loss: 0.8937 r:0.1928
en_zh Dev loss: 0.8415 r:0.4091
ro_en Dev loss: 0.3594 r:0.8186
et_en Dev loss: 0.4578 r:0.6592
si_en Dev loss: 0.8449 r:0.5668
ne_en Dev loss: 0.5105 r:0.7430
ru_en Dev loss: 0.5317 r:0.7075
Current avg r:0.5853 Best avg r: 0.6240
01:15:04,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:34,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:04,477 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2532
en_de Dev loss: 0.8867 r:0.1924
en_zh Dev loss: 0.8260 r:0.4171
ro_en Dev loss: 0.3609 r:0.8188
et_en Dev loss: 0.5006 r:0.6525
si_en Dev loss: 0.8222 r:0.5646
ne_en Dev loss: 0.5387 r:0.7399
ru_en Dev loss: 0.5014 r:0.7071
Current avg r:0.5846 Best avg r: 0.6240
01:22:33,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:24:03,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:34,28 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2478
en_de Dev loss: 0.8915 r:0.1837
en_zh Dev loss: 0.8128 r:0.4163
ro_en Dev loss: 0.3527 r:0.8182
et_en Dev loss: 0.4595 r:0.6622
si_en Dev loss: 0.8175 r:0.5688
ne_en Dev loss: 0.5810 r:0.7391
ru_en Dev loss: 0.5103 r:0.7026
Current avg r:0.5844 Best avg r: 0.6240
01:30:03,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:33,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:33:03,677 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2412
en_de Dev loss: 0.8732 r:0.1956
en_zh Dev loss: 0.7726 r:0.4414
ro_en Dev loss: 0.3212 r:0.8222
et_en Dev loss: 0.4747 r:0.6735
si_en Dev loss: 0.7078 r:0.5811
ne_en Dev loss: 0.4208 r:0.7361
ru_en Dev loss: 0.4291 r:0.7367
Current avg r:0.5981 Best avg r: 0.6240
01:37:33,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:39:03,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:40:33,344 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2453
en_de Dev loss: 0.8749 r:0.1985
en_zh Dev loss: 0.7842 r:0.4243
ro_en Dev loss: 0.3419 r:0.8207
et_en Dev loss: 0.4701 r:0.6621
si_en Dev loss: 0.7987 r:0.5685
ne_en Dev loss: 0.4906 r:0.7371
ru_en Dev loss: 0.4419 r:0.7281
Current avg r:0.5913 Best avg r: 0.6240
01:45:03,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:46:33,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:48:03,311 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2583
en_de Dev loss: 0.8760 r:0.2076
en_zh Dev loss: 0.8169 r:0.4204
ro_en Dev loss: 0.3519 r:0.8197
et_en Dev loss: 0.4692 r:0.6685
si_en Dev loss: 0.8165 r:0.5661
ne_en Dev loss: 0.5117 r:0.7395
ru_en Dev loss: 0.4728 r:0.7285
Current avg r:0.5929 Best avg r: 0.6240
01:52:33,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:54:03,201 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:55:33,449 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2528
en_de Dev loss: 0.8581 r:0.2263
en_zh Dev loss: 0.7918 r:0.4346
ro_en Dev loss: 0.3340 r:0.8220
et_en Dev loss: 0.4697 r:0.6627
si_en Dev loss: 0.8504 r:0.5620
ne_en Dev loss: 0.5070 r:0.7381
ru_en Dev loss: 0.4658 r:0.7271
Current avg r:0.5961 Best avg r: 0.6240
02:00:05,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:01:35,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:03:06,488 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2330
en_de Dev loss: 0.8673 r:0.2134
en_zh Dev loss: 0.7970 r:0.4306
ro_en Dev loss: 0.3261 r:0.8201
et_en Dev loss: 0.4388 r:0.6760
si_en Dev loss: 0.7986 r:0.5709
ne_en Dev loss: 0.5104 r:0.7376
ru_en Dev loss: 0.4496 r:0.7322
Current avg r:0.5973 Best avg r: 0.6240
02:07:37,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:09:07,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:38,414 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2228
en_de Dev loss: 0.8846 r:0.2037
en_zh Dev loss: 0.8427 r:0.4285
ro_en Dev loss: 0.3781 r:0.8149
et_en Dev loss: 0.4853 r:0.6609
si_en Dev loss: 0.9271 r:0.5549
ne_en Dev loss: 0.6147 r:0.7342
ru_en Dev loss: 0.4744 r:0.7210
Current avg r:0.5883 Best avg r: 0.6240
02:15:09,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:39,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:18:10,671 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2146
en_de Dev loss: 0.8938 r:0.2059
en_zh Dev loss: 0.8483 r:0.4292
ro_en Dev loss: 0.3554 r:0.8187
et_en Dev loss: 0.4696 r:0.6690
si_en Dev loss: 0.8467 r:0.5655
ne_en Dev loss: 0.5395 r:0.7309
ru_en Dev loss: 0.5007 r:0.7140
Current avg r:0.5904 Best avg r: 0.6240
02:22:41,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:12,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:43,3 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2278
en_de Dev loss: 0.8980 r:0.2098
en_zh Dev loss: 0.8409 r:0.4247
ro_en Dev loss: 0.3555 r:0.8202
et_en Dev loss: 0.4887 r:0.6631
si_en Dev loss: 0.8377 r:0.5725
ne_en Dev loss: 0.5082 r:0.7354
ru_en Dev loss: 0.4684 r:0.7277
Current avg r:0.5933 Best avg r: 0.6240
02:30:13,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:43,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:33:14,238 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2266
en_de Dev loss: 0.8753 r:0.2071
en_zh Dev loss: 0.8063 r:0.4359
ro_en Dev loss: 0.3399 r:0.8232
et_en Dev loss: 0.4539 r:0.6762
si_en Dev loss: 0.7939 r:0.5756
ne_en Dev loss: 0.4937 r:0.7350
ru_en Dev loss: 0.4609 r:0.7272
Current avg r:0.5972 Best avg r: 0.6240
02:37:44,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:39:14,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:40:45,330 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2234
en_de Dev loss: 0.9150 r:0.1897
en_zh Dev loss: 0.8848 r:0.4181
ro_en Dev loss: 0.3801 r:0.8181
et_en Dev loss: 0.5122 r:0.6586
si_en Dev loss: 0.9427 r:0.5591
ne_en Dev loss: 0.5508 r:0.7290
ru_en Dev loss: 0.5539 r:0.7007
Current avg r:0.5819 Best avg r: 0.6240
02:45:15,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:46:45,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:48:17,823 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2201
en_de Dev loss: 0.9204 r:0.1902
en_zh Dev loss: 0.9294 r:0.4120
ro_en Dev loss: 0.4242 r:0.8113
et_en Dev loss: 0.4946 r:0.6568
si_en Dev loss: 0.9618 r:0.5563
ne_en Dev loss: 0.6921 r:0.7342
ru_en Dev loss: 0.5845 r:0.6946
Current avg r:0.5794 Best avg r: 0.6240
02:52:47,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:54:18,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:55:48,429 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2129
en_de Dev loss: 0.9100 r:0.1946
en_zh Dev loss: 0.8751 r:0.4223
ro_en Dev loss: 0.3756 r:0.8177
et_en Dev loss: 0.4739 r:0.6655
si_en Dev loss: 0.9072 r:0.5640
ne_en Dev loss: 0.5590 r:0.7299
ru_en Dev loss: 0.4941 r:0.7198
Current avg r:0.5877 Best avg r: 0.6240
03:00:18,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:01:48,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:19,384 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2154
en_de Dev loss: 0.9187 r:0.2059
en_zh Dev loss: 0.8294 r:0.4435
ro_en Dev loss: 0.3559 r:0.8205
et_en Dev loss: 0.4663 r:0.6682
si_en Dev loss: 0.8143 r:0.5671
ne_en Dev loss: 0.5002 r:0.7353
ru_en Dev loss: 0.4760 r:0.7335
Current avg r:0.5963 Best avg r: 0.6240
03:07:49,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:19,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:10:50,275 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2090
en_de Dev loss: 0.8863 r:0.2065
en_zh Dev loss: 0.7940 r:0.4331
ro_en Dev loss: 0.3583 r:0.8158
et_en Dev loss: 0.4734 r:0.6601
si_en Dev loss: 0.8759 r:0.5553
ne_en Dev loss: 0.5094 r:0.7310
ru_en Dev loss: 0.4576 r:0.7254
Current avg r:0.5896 Best avg r: 0.6240
03:15:20,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:16:50,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:18:21,152 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2106
en_de Dev loss: 0.9003 r:0.1992
en_zh Dev loss: 0.7969 r:0.4402
ro_en Dev loss: 0.3563 r:0.8202
et_en Dev loss: 0.4677 r:0.6768
si_en Dev loss: 0.8003 r:0.5645
ne_en Dev loss: 0.4577 r:0.7375
ru_en Dev loss: 0.4528 r:0.7378
Current avg r:0.5966 Best avg r: 0.6240
03:22:51,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:24:21,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:52,96 root INFO Epoch 6 Global steps: 71400 Train loss: 0.2210
en_de Dev loss: 0.9169 r:0.1970
en_zh Dev loss: 0.8702 r:0.4352
ro_en Dev loss: 0.3886 r:0.8170
et_en Dev loss: 0.4991 r:0.6581
si_en Dev loss: 1.0047 r:0.5524
ne_en Dev loss: 0.5996 r:0.7301
ru_en Dev loss: 0.5308 r:0.7109
Current avg r:0.5858 Best avg r: 0.6240
03:30:22,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:31:52,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:33:23,124 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2081
en_de Dev loss: 0.8881 r:0.2050
en_zh Dev loss: 0.8407 r:0.4320
ro_en Dev loss: 0.3769 r:0.8168
et_en Dev loss: 0.4906 r:0.6682
si_en Dev loss: 0.9089 r:0.5503
ne_en Dev loss: 0.5696 r:0.7321
ru_en Dev loss: 0.5001 r:0.7191
Current avg r:0.5891 Best avg r: 0.6240
03:37:53,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:39:23,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:40:54,216 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2038
en_de Dev loss: 0.8896 r:0.1997
en_zh Dev loss: 0.8476 r:0.4236
ro_en Dev loss: 0.3831 r:0.8164
et_en Dev loss: 0.5103 r:0.6613
si_en Dev loss: 0.9750 r:0.5426
ne_en Dev loss: 0.6226 r:0.7305
ru_en Dev loss: 0.5370 r:0.6974
Current avg r:0.5816 Best avg r: 0.6240
03:45:24,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:46:54,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:48:25,171 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2049
en_de Dev loss: 0.8994 r:0.2113
en_zh Dev loss: 0.8089 r:0.4440
ro_en Dev loss: 0.3653 r:0.8214
et_en Dev loss: 0.4744 r:0.6749
si_en Dev loss: 0.8172 r:0.5648
ne_en Dev loss: 0.5310 r:0.7342
ru_en Dev loss: 0.4924 r:0.7151
Current avg r:0.5951 Best avg r: 0.6240
03:52:56,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:54:27,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:55:57,467 root INFO Epoch 7 Global steps: 74200 Train loss: 0.2066
en_de Dev loss: 0.9002 r:0.2108
en_zh Dev loss: 0.8729 r:0.4272
ro_en Dev loss: 0.4064 r:0.8177
et_en Dev loss: 0.4820 r:0.6728
si_en Dev loss: 0.9039 r:0.5578
ne_en Dev loss: 0.5567 r:0.7369
ru_en Dev loss: 0.4844 r:0.7285
Current avg r:0.5931 Best avg r: 0.6240
04:00:27,683 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:01:58,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:03:28,788 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1800
en_de Dev loss: 0.8820 r:0.2256
en_zh Dev loss: 0.8729 r:0.4251
ro_en Dev loss: 0.3688 r:0.8166
et_en Dev loss: 0.4741 r:0.6653
si_en Dev loss: 0.8844 r:0.5571
ne_en Dev loss: 0.5395 r:0.7317
ru_en Dev loss: 0.4906 r:0.7194
Current avg r:0.5915 Best avg r: 0.6240
04:07:59,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:09:30,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:11:01,341 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1936
en_de Dev loss: 0.8618 r:0.2263
en_zh Dev loss: 0.8281 r:0.4273
ro_en Dev loss: 0.3600 r:0.8159
et_en Dev loss: 0.4778 r:0.6596
si_en Dev loss: 0.8838 r:0.5569
ne_en Dev loss: 0.5405 r:0.7323
ru_en Dev loss: 0.4770 r:0.7178
Current avg r:0.5909 Best avg r: 0.6240
04:15:32,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:17:03,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:18:33,850 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1839
en_de Dev loss: 0.8850 r:0.2101
en_zh Dev loss: 0.8639 r:0.4313
ro_en Dev loss: 0.3754 r:0.8164
et_en Dev loss: 0.4758 r:0.6612
si_en Dev loss: 0.9450 r:0.5525
ne_en Dev loss: 0.5221 r:0.7335
ru_en Dev loss: 0.4705 r:0.7347
Current avg r:0.5914 Best avg r: 0.6240
04:23:04,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:24:35,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:26:05,973 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1875
en_de Dev loss: 0.8967 r:0.2182
en_zh Dev loss: 0.8527 r:0.4296
ro_en Dev loss: 0.3561 r:0.8209
et_en Dev loss: 0.4592 r:0.6653
si_en Dev loss: 0.8899 r:0.5580
ne_en Dev loss: 0.4893 r:0.7281
ru_en Dev loss: 0.4925 r:0.7243
Current avg r:0.5921 Best avg r: 0.6240
04:30:35,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:32:06,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:33:36,573 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1979
en_de Dev loss: 0.9355 r:0.2132
en_zh Dev loss: 0.9000 r:0.4271
ro_en Dev loss: 0.4138 r:0.8156
et_en Dev loss: 0.5132 r:0.6605
si_en Dev loss: 0.9699 r:0.5576
ne_en Dev loss: 0.5969 r:0.7282
ru_en Dev loss: 0.5389 r:0.7138
Current avg r:0.5880 Best avg r: 0.6240
04:38:06,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:39:36,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:41:07,6 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1880
en_de Dev loss: 0.8956 r:0.2226
en_zh Dev loss: 0.8697 r:0.4138
ro_en Dev loss: 0.3940 r:0.8086
et_en Dev loss: 0.5094 r:0.6583
si_en Dev loss: 0.9321 r:0.5481
ne_en Dev loss: 0.6122 r:0.7257
ru_en Dev loss: 0.5386 r:0.7011
Current avg r:0.5826 Best avg r: 0.6240
04:45:36,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:47:07,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:37,513 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1856
en_de Dev loss: 0.8937 r:0.2211
en_zh Dev loss: 0.8042 r:0.4321
ro_en Dev loss: 0.3546 r:0.8148
et_en Dev loss: 0.4652 r:0.6740
si_en Dev loss: 0.8137 r:0.5640
ne_en Dev loss: 0.5265 r:0.7265
ru_en Dev loss: 0.4647 r:0.7337
Current avg r:0.5952 Best avg r: 0.6240
04:53:07,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:54:37,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:56:07,951 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1869
en_de Dev loss: 0.8973 r:0.2207
en_zh Dev loss: 0.8391 r:0.4311
ro_en Dev loss: 0.3766 r:0.8121
et_en Dev loss: 0.4791 r:0.6651
si_en Dev loss: 0.8867 r:0.5517
ne_en Dev loss: 0.5790 r:0.7255
ru_en Dev loss: 0.4637 r:0.7348
Current avg r:0.5916 Best avg r: 0.6240
05:00:37,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:02:08,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:38,505 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1791
en_de Dev loss: 0.8995 r:0.2168
en_zh Dev loss: 0.8574 r:0.4148
ro_en Dev loss: 0.3711 r:0.8136
et_en Dev loss: 0.4786 r:0.6674
si_en Dev loss: 0.8457 r:0.5582
ne_en Dev loss: 0.5258 r:0.7287
ru_en Dev loss: 0.4928 r:0.7253
Current avg r:0.5893 Best avg r: 0.6240
05:08:08,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:09:38,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:08,782 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1918
en_de Dev loss: 0.9026 r:0.2215
en_zh Dev loss: 0.8274 r:0.4301
ro_en Dev loss: 0.3599 r:0.8136
et_en Dev loss: 0.4912 r:0.6692
si_en Dev loss: 0.7922 r:0.5675
ne_en Dev loss: 0.5033 r:0.7254
ru_en Dev loss: 0.4373 r:0.7403
Current avg r:0.5954 Best avg r: 0.6240
05:15:38,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:08,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:39,144 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1852
en_de Dev loss: 0.8804 r:0.2216
en_zh Dev loss: 0.8319 r:0.4112
ro_en Dev loss: 0.3556 r:0.8155
et_en Dev loss: 0.4717 r:0.6619
si_en Dev loss: 0.8872 r:0.5543
ne_en Dev loss: 0.5474 r:0.7230
ru_en Dev loss: 0.4691 r:0.7239
Current avg r:0.5873 Best avg r: 0.6240
05:23:08,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:24:39,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:09,529 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1906
en_de Dev loss: 0.8616 r:0.2365
en_zh Dev loss: 0.8098 r:0.4167
ro_en Dev loss: 0.3418 r:0.8163
et_en Dev loss: 0.4651 r:0.6684
si_en Dev loss: 0.8521 r:0.5547
ne_en Dev loss: 0.5020 r:0.7231
ru_en Dev loss: 0.4488 r:0.7276
Current avg r:0.5919 Best avg r: 0.6240
05:30:39,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:32:09,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:33:40,29 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1768
en_de Dev loss: 0.8837 r:0.2413
en_zh Dev loss: 0.8848 r:0.4008
ro_en Dev loss: 0.4045 r:0.8080
et_en Dev loss: 0.5129 r:0.6588
si_en Dev loss: 0.9071 r:0.5548
ne_en Dev loss: 0.5988 r:0.7262
ru_en Dev loss: 0.5222 r:0.7124
Current avg r:0.5860 Best avg r: 0.6240
05:38:09,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:39:39,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:41:10,340 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1829
en_de Dev loss: 0.8674 r:0.2349
en_zh Dev loss: 0.8044 r:0.4343
ro_en Dev loss: 0.3546 r:0.8142
et_en Dev loss: 0.4641 r:0.6678
si_en Dev loss: 0.8925 r:0.5565
ne_en Dev loss: 0.5730 r:0.7244
ru_en Dev loss: 0.4816 r:0.7237
Current avg r:0.5937 Best avg r: 0.6240
05:45:41,628 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:47:11,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:48:42,412 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1616
en_de Dev loss: 0.8869 r:0.2268
en_zh Dev loss: 0.8651 r:0.4230
ro_en Dev loss: 0.3644 r:0.8122
et_en Dev loss: 0.4644 r:0.6716
si_en Dev loss: 0.8953 r:0.5600
ne_en Dev loss: 0.5893 r:0.7320
ru_en Dev loss: 0.5075 r:0.7110
Current avg r:0.5909 Best avg r: 0.6240
05:53:13,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:43,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:56:13,998 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1625
en_de Dev loss: 0.8958 r:0.2144
en_zh Dev loss: 0.8064 r:0.4355
ro_en Dev loss: 0.3286 r:0.8184
et_en Dev loss: 0.4478 r:0.6760
si_en Dev loss: 0.8055 r:0.5630
ne_en Dev loss: 0.4456 r:0.7329
ru_en Dev loss: 0.4531 r:0.7281
Current avg r:0.5955 Best avg r: 0.6240
06:00:44,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:02:15,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:03:46,28 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1628
en_de Dev loss: 0.9234 r:0.2161
en_zh Dev loss: 0.8629 r:0.4341
ro_en Dev loss: 0.3909 r:0.8126
et_en Dev loss: 0.5045 r:0.6606
si_en Dev loss: 0.9531 r:0.5494
ne_en Dev loss: 0.5608 r:0.7325
ru_en Dev loss: 0.4576 r:0.7364
Current avg r:0.5917 Best avg r: 0.6240
06:08:16,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:47,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:18,208 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1690
en_de Dev loss: 0.9216 r:0.2127
en_zh Dev loss: 0.8344 r:0.4339
ro_en Dev loss: 0.3581 r:0.8163
et_en Dev loss: 0.4935 r:0.6765
si_en Dev loss: 0.8344 r:0.5539
ne_en Dev loss: 0.4551 r:0.7282
ru_en Dev loss: 0.4345 r:0.7387
Current avg r:0.5943 Best avg r: 0.6240
06:15:48,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:18,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:48,830 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1639
en_de Dev loss: 0.9763 r:0.2006
en_zh Dev loss: 0.9213 r:0.4331
ro_en Dev loss: 0.3923 r:0.8126
et_en Dev loss: 0.4922 r:0.6629
si_en Dev loss: 0.9633 r:0.5417
ne_en Dev loss: 0.5862 r:0.7210
ru_en Dev loss: 0.5160 r:0.7280
Current avg r:0.5857 Best avg r: 0.6240
06:23:18,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:24:49,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:19,723 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1594
en_de Dev loss: 0.9080 r:0.2077
en_zh Dev loss: 0.8615 r:0.4226
ro_en Dev loss: 0.3808 r:0.8108
et_en Dev loss: 0.4730 r:0.6662
si_en Dev loss: 0.9361 r:0.5436
ne_en Dev loss: 0.5326 r:0.7252
ru_en Dev loss: 0.4586 r:0.7329
Current avg r:0.5870 Best avg r: 0.6240
06:30:49,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:32:20,201 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:33:50,653 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1693
en_de Dev loss: 0.9195 r:0.2145
en_zh Dev loss: 0.8480 r:0.4427
ro_en Dev loss: 0.3803 r:0.8114
et_en Dev loss: 0.4789 r:0.6702
si_en Dev loss: 0.8916 r:0.5530
ne_en Dev loss: 0.5278 r:0.7260
ru_en Dev loss: 0.4587 r:0.7358
Current avg r:0.5934 Best avg r: 0.6240
06:38:20,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:39:51,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:41:21,695 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1652
en_de Dev loss: 0.8990 r:0.2121
en_zh Dev loss: 0.8528 r:0.4344
ro_en Dev loss: 0.3947 r:0.8096
et_en Dev loss: 0.4769 r:0.6674
si_en Dev loss: 0.9548 r:0.5471
ne_en Dev loss: 0.6107 r:0.7194
ru_en Dev loss: 0.5049 r:0.7205
Current avg r:0.5872 Best avg r: 0.6240
06:45:51,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:22,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:48:52,725 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1638
en_de Dev loss: 0.9206 r:0.1999
en_zh Dev loss: 0.8590 r:0.4388
ro_en Dev loss: 0.3888 r:0.8119
et_en Dev loss: 0.4670 r:0.6695
si_en Dev loss: 0.9010 r:0.5499
ne_en Dev loss: 0.6588 r:0.7201
ru_en Dev loss: 0.5106 r:0.7260
Current avg r:0.5880 Best avg r: 0.6240
06:53:22,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:53,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:23,949 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1680
en_de Dev loss: 0.9142 r:0.2028
en_zh Dev loss: 0.8045 r:0.4464
ro_en Dev loss: 0.3509 r:0.8127
et_en Dev loss: 0.4526 r:0.6730
si_en Dev loss: 0.8475 r:0.5498
ne_en Dev loss: 0.5339 r:0.7291
ru_en Dev loss: 0.4643 r:0.7322
Current avg r:0.5923 Best avg r: 0.6240
07:00:54,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:24,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:03:55,162 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1677
en_de Dev loss: 0.9240 r:0.2281
en_zh Dev loss: 0.8225 r:0.4377
ro_en Dev loss: 0.3455 r:0.8153
et_en Dev loss: 0.4523 r:0.6640
si_en Dev loss: 0.8514 r:0.5495
ne_en Dev loss: 0.5173 r:0.7288
ru_en Dev loss: 0.5083 r:0.7202
Current avg r:0.5920 Best avg r: 0.6240
07:08:25,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:09:55,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:11:26,278 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1674
en_de Dev loss: 0.9000 r:0.2136
en_zh Dev loss: 0.8108 r:0.4430
ro_en Dev loss: 0.3474 r:0.8175
et_en Dev loss: 0.4726 r:0.6719
si_en Dev loss: 0.8124 r:0.5567
ne_en Dev loss: 0.4901 r:0.7300
ru_en Dev loss: 0.4663 r:0.7294
Current avg r:0.5946 Best avg r: 0.6240
07:15:56,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:26,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:18:57,157 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1575
en_de Dev loss: 0.8914 r:0.2198
en_zh Dev loss: 0.8202 r:0.4392
ro_en Dev loss: 0.3665 r:0.8125
et_en Dev loss: 0.4718 r:0.6687
si_en Dev loss: 0.8381 r:0.5559
ne_en Dev loss: 0.5146 r:0.7255
ru_en Dev loss: 0.4787 r:0.7272
Current avg r:0.5927 Best avg r: 0.6240
07:23:26,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:24:57,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:27,768 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1543
en_de Dev loss: 0.9021 r:0.1984
en_zh Dev loss: 0.8278 r:0.4326
ro_en Dev loss: 0.3591 r:0.8148
et_en Dev loss: 0.4755 r:0.6700
si_en Dev loss: 0.8556 r:0.5565
ne_en Dev loss: 0.5629 r:0.7242
ru_en Dev loss: 0.4740 r:0.7224
Current avg r:0.5884 Best avg r: 0.6240
07:30:57,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:28,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:33:58,411 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1625
en_de Dev loss: 0.9230 r:0.1878
en_zh Dev loss: 0.8635 r:0.4353
ro_en Dev loss: 0.3701 r:0.8104
et_en Dev loss: 0.4934 r:0.6713
si_en Dev loss: 0.8783 r:0.5529
ne_en Dev loss: 0.5546 r:0.7202
ru_en Dev loss: 0.4599 r:0.7321
Current avg r:0.5871 Best avg r: 0.6240
07:38:29,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:00,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:41:30,847 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1428
en_de Dev loss: 0.9027 r:0.1929
en_zh Dev loss: 0.8144 r:0.4429
ro_en Dev loss: 0.3645 r:0.8129
et_en Dev loss: 0.4555 r:0.6849
si_en Dev loss: 0.8233 r:0.5636
ne_en Dev loss: 0.4661 r:0.7297
ru_en Dev loss: 0.4593 r:0.7414
Current avg r:0.5955 Best avg r: 0.6240
07:46:01,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:32,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:49:03,476 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1471
en_de Dev loss: 0.9307 r:0.1621
en_zh Dev loss: 0.9071 r:0.4189
ro_en Dev loss: 0.4115 r:0.8088
et_en Dev loss: 0.5076 r:0.6656
si_en Dev loss: 1.0651 r:0.5331
ne_en Dev loss: 0.6701 r:0.7159
ru_en Dev loss: 0.5433 r:0.7045
Current avg r:0.5727 Best avg r: 0.6240
07:53:34,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:55:05,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:56:36,127 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1510
en_de Dev loss: 0.9355 r:0.1751
en_zh Dev loss: 0.8400 r:0.4435
ro_en Dev loss: 0.3591 r:0.8174
et_en Dev loss: 0.4644 r:0.6789
si_en Dev loss: 0.9031 r:0.5512
ne_en Dev loss: 0.5490 r:0.7200
ru_en Dev loss: 0.4777 r:0.7297
Current avg r:0.5879 Best avg r: 0.6240
08:01:07,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:37,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:04:08,242 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1469
en_de Dev loss: 0.9288 r:0.1815
en_zh Dev loss: 0.8248 r:0.4386
ro_en Dev loss: 0.3478 r:0.8147
et_en Dev loss: 0.4592 r:0.6699
si_en Dev loss: 0.8803 r:0.5510
ne_en Dev loss: 0.5580 r:0.7224
ru_en Dev loss: 0.4900 r:0.7188
Current avg r:0.5853 Best avg r: 0.6240
08:08:38,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:10:08,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:11:38,915 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1442
en_de Dev loss: 0.9191 r:0.1799
en_zh Dev loss: 0.8146 r:0.4414
ro_en Dev loss: 0.3564 r:0.8142
et_en Dev loss: 0.4628 r:0.6717
si_en Dev loss: 0.8842 r:0.5512
ne_en Dev loss: 0.5459 r:0.7273
ru_en Dev loss: 0.4777 r:0.7204
Current avg r:0.5866 Best avg r: 0.6240
08:16:08,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:17:39,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:19:09,507 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1443
en_de Dev loss: 0.9024 r:0.1901
en_zh Dev loss: 0.8070 r:0.4421
ro_en Dev loss: 0.3525 r:0.8142
et_en Dev loss: 0.4617 r:0.6697
si_en Dev loss: 0.9110 r:0.5501
ne_en Dev loss: 0.5725 r:0.7223
ru_en Dev loss: 0.4533 r:0.7312
Current avg r:0.5885 Best avg r: 0.6240
08:23:39,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:25:09,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:40,382 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1572
en_de Dev loss: 0.9162 r:0.1751
en_zh Dev loss: 0.8629 r:0.4276
ro_en Dev loss: 0.3700 r:0.8137
et_en Dev loss: 0.4626 r:0.6715
si_en Dev loss: 0.9217 r:0.5534
ne_en Dev loss: 0.5863 r:0.7152
ru_en Dev loss: 0.4885 r:0.7166
Current avg r:0.5819 Best avg r: 0.6240
08:31:10,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:32:40,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:34:11,316 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1451
en_de Dev loss: 0.9093 r:0.1988
en_zh Dev loss: 0.7973 r:0.4492
ro_en Dev loss: 0.3443 r:0.8173
et_en Dev loss: 0.4445 r:0.6751
si_en Dev loss: 0.8366 r:0.5546
ne_en Dev loss: 0.6224 r:0.7131
ru_en Dev loss: 0.4505 r:0.7311
Current avg r:0.5913 Best avg r: 0.6240
08:38:41,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:40:11,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:42,243 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1455
en_de Dev loss: 0.9240 r:0.1615
en_zh Dev loss: 0.8659 r:0.4306
ro_en Dev loss: 0.3968 r:0.8068
et_en Dev loss: 0.4799 r:0.6552
si_en Dev loss: 1.0840 r:0.5288
ne_en Dev loss: 0.8756 r:0.7036
ru_en Dev loss: 0.5749 r:0.6880
Current avg r:0.5678 Best avg r: 0.6240
08:46:12,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:42,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:13,202 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1436
en_de Dev loss: 0.9569 r:0.1769
en_zh Dev loss: 0.8757 r:0.4357
ro_en Dev loss: 0.3820 r:0.8147
et_en Dev loss: 0.4709 r:0.6711
si_en Dev loss: 0.9532 r:0.5479
ne_en Dev loss: 0.6055 r:0.7181
ru_en Dev loss: 0.5037 r:0.7152
Current avg r:0.5828 Best avg r: 0.6240
08:53:43,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:55:13,818 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:44,327 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1502
en_de Dev loss: 0.9308 r:0.1910
en_zh Dev loss: 0.8462 r:0.4450
ro_en Dev loss: 0.3907 r:0.8128
et_en Dev loss: 0.4742 r:0.6721
si_en Dev loss: 0.9487 r:0.5480
ne_en Dev loss: 0.5927 r:0.7131
ru_en Dev loss: 0.4978 r:0.7249
Current avg r:0.5867 Best avg r: 0.6240
09:01:14,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:44,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:04:15,346 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1447
en_de Dev loss: 0.9459 r:0.1803
en_zh Dev loss: 0.8381 r:0.4426
ro_en Dev loss: 0.3672 r:0.8136
et_en Dev loss: 0.4465 r:0.6782
si_en Dev loss: 0.8700 r:0.5536
ne_en Dev loss: 0.5908 r:0.7117
ru_en Dev loss: 0.5267 r:0.7133
Current avg r:0.5848 Best avg r: 0.6240
09:08:45,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:10:16,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:47,467 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1465
en_de Dev loss: 0.9122 r:0.1821
en_zh Dev loss: 0.8434 r:0.4417
ro_en Dev loss: 0.3473 r:0.8187
et_en Dev loss: 0.4435 r:0.6778
si_en Dev loss: 0.8820 r:0.5548
ne_en Dev loss: 0.4984 r:0.7251
ru_en Dev loss: 0.4764 r:0.7270
Current avg r:0.5896 Best avg r: 0.6240
09:16:18,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:17:49,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:20,89 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1453
en_de Dev loss: 0.9012 r:0.1887
en_zh Dev loss: 0.7638 r:0.4508
ro_en Dev loss: 0.3293 r:0.8177
et_en Dev loss: 0.4349 r:0.6741
si_en Dev loss: 0.8654 r:0.5513
ne_en Dev loss: 0.5352 r:0.7220
ru_en Dev loss: 0.4311 r:0.7342
Current avg r:0.5913 Best avg r: 0.6240
09:23:51,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:21,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:52,808 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1478
en_de Dev loss: 0.9225 r:0.1987
en_zh Dev loss: 0.8398 r:0.4463
ro_en Dev loss: 0.4003 r:0.8140
et_en Dev loss: 0.4868 r:0.6650
si_en Dev loss: 1.0434 r:0.5355
ne_en Dev loss: 0.6769 r:0.7162
ru_en Dev loss: 0.5571 r:0.7106
Current avg r:0.5838 Best avg r: 0.6240
09:31:24,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:32:55,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:34:26,40 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1288
en_de Dev loss: 0.9112 r:0.1934
en_zh Dev loss: 0.8019 r:0.4393
ro_en Dev loss: 0.3561 r:0.8161
et_en Dev loss: 0.4371 r:0.6736
si_en Dev loss: 0.9169 r:0.5353
ne_en Dev loss: 0.5197 r:0.7228
ru_en Dev loss: 0.4644 r:0.7276
Current avg r:0.5869 Best avg r: 0.6240
09:38:56,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:40:26,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:41:57,297 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1305
en_de Dev loss: 0.9177 r:0.1868
en_zh Dev loss: 0.8440 r:0.4412
ro_en Dev loss: 0.3702 r:0.8132
et_en Dev loss: 0.4689 r:0.6754
si_en Dev loss: 0.9486 r:0.5369
ne_en Dev loss: 0.5689 r:0.7134
ru_en Dev loss: 0.5284 r:0.7096
Current avg r:0.5824 Best avg r: 0.6240
09:46:27,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:58,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:28,576 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1252
en_de Dev loss: 0.9037 r:0.1953
en_zh Dev loss: 0.7988 r:0.4466
ro_en Dev loss: 0.3448 r:0.8192
et_en Dev loss: 0.4304 r:0.6801
si_en Dev loss: 0.8406 r:0.5496
ne_en Dev loss: 0.5414 r:0.7194
ru_en Dev loss: 0.4428 r:0.7342
Current avg r:0.5921 Best avg r: 0.6240
09:53:58,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:29,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:59,696 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1341
en_de Dev loss: 0.9671 r:0.1776
en_zh Dev loss: 0.8802 r:0.4407
ro_en Dev loss: 0.3720 r:0.8165
et_en Dev loss: 0.4780 r:0.6742
si_en Dev loss: 0.9234 r:0.5422
ne_en Dev loss: 0.5424 r:0.7209
ru_en Dev loss: 0.5224 r:0.7189
Current avg r:0.5844 Best avg r: 0.6240
10:01:29,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:03:00,391 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:04:30,956 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1306
en_de Dev loss: 0.9568 r:0.1886
en_zh Dev loss: 0.8393 r:0.4409
ro_en Dev loss: 0.3661 r:0.8163
et_en Dev loss: 0.4696 r:0.6726
si_en Dev loss: 0.9176 r:0.5388
ne_en Dev loss: 0.5644 r:0.7197
ru_en Dev loss: 0.4988 r:0.7210
Current avg r:0.5854 Best avg r: 0.6240
10:09:01,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:31,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:02,228 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1297
en_de Dev loss: 0.9223 r:0.1927
en_zh Dev loss: 0.8157 r:0.4441
ro_en Dev loss: 0.3640 r:0.8134
et_en Dev loss: 0.4514 r:0.6788
si_en Dev loss: 0.9211 r:0.5382
ne_en Dev loss: 0.6504 r:0.7148
ru_en Dev loss: 0.4832 r:0.7278
Current avg r:0.5871 Best avg r: 0.6240
10:16:32,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:02,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:33,571 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1208
en_de Dev loss: 0.9204 r:0.2033
en_zh Dev loss: 0.8173 r:0.4500
ro_en Dev loss: 0.3503 r:0.8165
et_en Dev loss: 0.4535 r:0.6784
si_en Dev loss: 0.9147 r:0.5384
ne_en Dev loss: 0.6165 r:0.7164
ru_en Dev loss: 0.4183 r:0.7522
Current avg r:0.5936 Best avg r: 0.6240
10:24:03,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:34,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:04,998 root INFO Epoch 10 Global steps: 110600 Train loss: 0.1301
en_de Dev loss: 0.9483 r:0.2008
en_zh Dev loss: 0.8217 r:0.4464
ro_en Dev loss: 0.3481 r:0.8177
et_en Dev loss: 0.4516 r:0.6796
si_en Dev loss: 0.8248 r:0.5489
ne_en Dev loss: 0.5351 r:0.7145
ru_en Dev loss: 0.4506 r:0.7370
Current avg r:0.5921 Best avg r: 0.6240
10:31:35,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
