14:45:06,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:36,796 root INFO 
id:en_de cur r: 0.0338 best r: 0.0338
14:46:06,932 root INFO 
id:ro_en cur r: 0.6000 best r: 0.6000
14:46:21,852 root INFO 
id:et_en cur r: 0.5064 best r: 0.5064
14:46:36,809 root INFO 
id:si_en cur r: 0.4022 best r: 0.4022
14:46:51,754 root INFO 
id:ne_en cur r: 0.6098 best r: 0.6098
14:47:06,808 root INFO 
id:ru_en cur r: 0.4761 best r: 0.4761
14:47:06,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:51,903 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
14:48:51,908 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:48:51,912 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:48:51,917 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
14:48:51,920 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
14:48:51,925 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:48:51,929 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:49:07,55 root INFO Epoch 0 Global steps: 700 Train loss: 0.8242
en_de Dev loss: 0.8880 r:0.0830
en_zh Dev loss: 0.7860 r:0.2436
ro_en Dev loss: 0.6742 r:0.6187
et_en Dev loss: 0.5436 r:0.5287
si_en Dev loss: 0.7421 r:0.4228
ne_en Dev loss: 0.5537 r:0.6129
ru_en Dev loss: 0.6614 r:0.4824
Current avg r:0.4274 Best avg r: 0.4274
14:54:20,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:50,281 root INFO 
id:en_de cur r: 0.1163 best r: 0.1163
14:55:20,166 root INFO 
id:ro_en cur r: 0.6061 best r: 0.6061
14:55:35,137 root INFO 
id:et_en cur r: 0.5529 best r: 0.5529
14:55:50,114 root INFO 
id:si_en cur r: 0.4291 best r: 0.4291
14:56:20,83 root INFO 
id:ru_en cur r: 0.5646 best r: 0.5646
14:56:20,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:05,256 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
14:58:05,262 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:58:05,266 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:58:05,270 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
14:58:05,275 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
14:58:05,280 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:58:05,285 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:58:20,167 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8090
en_de Dev loss: 0.8986 r:0.1326
en_zh Dev loss: 0.7667 r:0.2809
ro_en Dev loss: 0.7472 r:0.5852
et_en Dev loss: 0.5374 r:0.5866
si_en Dev loss: 0.9028 r:0.4385
ne_en Dev loss: 0.6343 r:0.5600
ru_en Dev loss: 0.6608 r:0.5822
Current avg r:0.4523 Best avg r: 0.4523
15:03:33,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:03,200 root INFO 
id:en_de cur r: 0.1252 best r: 0.1252
15:04:18,265 root INFO 
id:en_zh cur r: 0.2263 best r: 0.2263
15:04:48,404 root INFO 
id:et_en cur r: 0.5796 best r: 0.5796
15:05:03,340 root INFO 
id:si_en cur r: 0.4709 best r: 0.4709
15:05:18,272 root INFO 
id:ne_en cur r: 0.6108 best r: 0.6108
15:05:33,281 root INFO 
id:ru_en cur r: 0.6079 best r: 0.6079
15:05:33,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:18,188 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:07:18,194 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:07:18,198 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:07:18,202 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:07:18,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:07:18,211 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:07:18,216 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:07:33,173 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7663
en_de Dev loss: 0.8922 r:0.1468
en_zh Dev loss: 0.7422 r:0.3096
ro_en Dev loss: 0.6431 r:0.6235
et_en Dev loss: 0.4769 r:0.6013
si_en Dev loss: 0.7133 r:0.4999
ne_en Dev loss: 0.5093 r:0.6414
ru_en Dev loss: 0.6010 r:0.5882
Current avg r:0.4872 Best avg r: 0.4872
15:12:46,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:16,314 root INFO 
id:en_de cur r: 0.1311 best r: 0.1311
15:13:31,327 root INFO 
id:en_zh cur r: 0.2946 best r: 0.2946
15:13:46,330 root INFO 
id:ro_en cur r: 0.6435 best r: 0.6435
15:14:01,364 root INFO 
id:et_en cur r: 0.6062 best r: 0.6062
15:14:16,411 root INFO 
id:si_en cur r: 0.4762 best r: 0.4762
15:14:31,450 root INFO 
id:ne_en cur r: 0.6178 best r: 0.6178
15:14:46,380 root INFO 
id:ru_en cur r: 0.6714 best r: 0.6714
15:14:46,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:31,136 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:16:31,143 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:16:31,148 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:16:31,152 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:16:31,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:16:31,162 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:16:31,167 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:16:46,145 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7277
en_de Dev loss: 0.8899 r:0.1530
en_zh Dev loss: 0.7345 r:0.3400
ro_en Dev loss: 0.6163 r:0.6642
et_en Dev loss: 0.4590 r:0.6494
si_en Dev loss: 0.7099 r:0.5026
ne_en Dev loss: 0.4977 r:0.6446
ru_en Dev loss: 0.5492 r:0.6943
Current avg r:0.5212 Best avg r: 0.5212
15:21:58,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:58,811 root INFO 
id:et_en cur r: 0.6174 best r: 0.6174
15:23:43,543 root INFO 
id:ru_en cur r: 0.6740 best r: 0.6740
15:23:43,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:28,40 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:25:28,45 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:25:28,49 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:25:28,55 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:25:28,59 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:25:28,63 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:25:28,68 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:25:42,987 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6814
en_de Dev loss: 0.8972 r:0.1611
en_zh Dev loss: 0.7340 r:0.3413
ro_en Dev loss: 0.5847 r:0.6711
et_en Dev loss: 0.4410 r:0.6608
si_en Dev loss: 0.7258 r:0.5174
ne_en Dev loss: 0.5071 r:0.6395
ru_en Dev loss: 0.5330 r:0.7092
Current avg r:0.5286 Best avg r: 0.5286
15:30:55,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:25,582 root INFO 
id:en_de cur r: 0.1395 best r: 0.1395
15:31:55,578 root INFO 
id:ro_en cur r: 0.6474 best r: 0.6474
15:32:10,599 root INFO 
id:et_en cur r: 0.6564 best r: 0.6564
15:32:25,655 root INFO 
id:si_en cur r: 0.4891 best r: 0.4891
15:32:40,689 root INFO 
id:ne_en cur r: 0.6602 best r: 0.6602
15:32:55,613 root INFO 
id:ru_en cur r: 0.6800 best r: 0.6800
15:32:55,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:40,496 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:34:40,504 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:34:40,510 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:34:40,515 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:34:40,519 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:34:40,525 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:34:40,530 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:34:55,523 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6652
en_de Dev loss: 0.9383 r:0.1721
en_zh Dev loss: 0.7814 r:0.3350
ro_en Dev loss: 0.5812 r:0.6843
et_en Dev loss: 0.4061 r:0.6882
si_en Dev loss: 0.7568 r:0.5296
ne_en Dev loss: 0.4678 r:0.6680
ru_en Dev loss: 0.5348 r:0.7226
Current avg r:0.5428 Best avg r: 0.5428
15:40:08,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:38,267 root INFO 
id:en_de cur r: 0.1610 best r: 0.1610
15:40:53,219 root INFO 
id:en_zh cur r: 0.3041 best r: 0.3041
15:41:08,183 root INFO 
id:ro_en cur r: 0.6874 best r: 0.6874
15:41:38,157 root INFO 
id:si_en cur r: 0.5165 best r: 0.5165
15:41:53,137 root INFO 
id:ne_en cur r: 0.6658 best r: 0.6658
15:42:08,48 root INFO 
id:ru_en cur r: 0.7031 best r: 0.7031
15:42:08,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:52,688 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:43:52,694 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:43:52,698 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:43:52,702 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:43:52,706 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:43:52,710 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:43:52,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:44:07,673 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6757
en_de Dev loss: 0.8836 r:0.1650
en_zh Dev loss: 0.7400 r:0.3615
ro_en Dev loss: 0.5236 r:0.7165
et_en Dev loss: 0.4059 r:0.6927
si_en Dev loss: 0.7011 r:0.5536
ne_en Dev loss: 0.4931 r:0.6728
ru_en Dev loss: 0.4937 r:0.7274
Current avg r:0.5556 Best avg r: 0.5556
15:49:20,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:50,165 root INFO 
id:en_de cur r: 0.1867 best r: 0.1867
15:50:05,246 root INFO 
id:en_zh cur r: 0.3665 best r: 0.3665
15:50:20,73 root INFO 
id:ro_en cur r: 0.7328 best r: 0.7328
15:50:35,4 root INFO 
id:et_en cur r: 0.6891 best r: 0.6891
15:50:50,54 root INFO 
id:si_en cur r: 0.5584 best r: 0.5584
15:51:05,88 root INFO 
id:ne_en cur r: 0.7094 best r: 0.7094
15:51:20,20 root INFO 
id:ru_en cur r: 0.7306 best r: 0.7306
15:51:20,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:04,914 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:53:04,919 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:53:04,923 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:53:04,928 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:53:04,932 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:53:04,936 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:53:04,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:53:19,942 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6363
en_de Dev loss: 0.8913 r:0.1839
en_zh Dev loss: 0.7416 r:0.3790
ro_en Dev loss: 0.4585 r:0.7450
et_en Dev loss: 0.3618 r:0.7013
si_en Dev loss: 0.6905 r:0.5759
ne_en Dev loss: 0.4287 r:0.7109
ru_en Dev loss: 0.4317 r:0.7438
Current avg r:0.5771 Best avg r: 0.5771
15:58:33,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:03,713 root INFO 
id:en_de cur r: 0.1952 best r: 0.1952
15:59:18,778 root INFO 
id:en_zh cur r: 0.3765 best r: 0.3765
15:59:33,864 root INFO 
id:ro_en cur r: 0.7404 best r: 0.7404
15:59:48,953 root INFO 
id:et_en cur r: 0.7046 best r: 0.7046
16:00:04,50 root INFO 
id:si_en cur r: 0.5822 best r: 0.5822
16:00:19,148 root INFO 
id:ne_en cur r: 0.7369 best r: 0.7369
16:00:34,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:19,426 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
16:02:19,432 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:02:19,436 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:02:19,440 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
16:02:19,444 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
16:02:19,449 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:02:19,453 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:02:34,365 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6055
en_de Dev loss: 0.8988 r:0.1899
en_zh Dev loss: 0.7359 r:0.3807
ro_en Dev loss: 0.4379 r:0.7522
et_en Dev loss: 0.3427 r:0.7185
si_en Dev loss: 0.5795 r:0.5942
ne_en Dev loss: 0.3660 r:0.7333
ru_en Dev loss: 0.4294 r:0.7490
Current avg r:0.5883 Best avg r: 0.5883
16:07:48,294 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:08:18,249 root INFO 
id:en_zh cur r: 0.3912 best r: 0.3912
16:08:33,300 root INFO 
id:ro_en cur r: 0.7491 best r: 0.7491
16:08:48,374 root INFO 
id:et_en cur r: 0.7100 best r: 0.7100
16:09:18,500 root INFO 
id:ne_en cur r: 0.7432 best r: 0.7432
16:09:33,448 root INFO 
id:ru_en cur r: 0.7461 best r: 0.7461
16:09:33,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:18,582 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
16:11:18,588 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:11:18,592 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:11:18,596 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
16:11:18,600 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
16:11:18,604 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:11:18,608 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:11:33,640 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5759
en_de Dev loss: 0.8599 r:0.1975
en_zh Dev loss: 0.6923 r:0.3935
ro_en Dev loss: 0.3811 r:0.7587
et_en Dev loss: 0.3595 r:0.7178
si_en Dev loss: 0.5510 r:0.5898
ne_en Dev loss: 0.3641 r:0.7355
ru_en Dev loss: 0.3825 r:0.7584
Current avg r:0.5930 Best avg r: 0.5930
16:16:46,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:16,966 root INFO 
id:en_de cur r: 0.2008 best r: 0.2008
16:17:31,985 root INFO 
id:en_zh cur r: 0.4008 best r: 0.4008
16:17:47,9 root INFO 
id:ro_en cur r: 0.7586 best r: 0.7586
16:18:17,111 root INFO 
id:si_en cur r: 0.5910 best r: 0.5910
16:18:32,152 root INFO 
id:ne_en cur r: 0.7452 best r: 0.7452
16:18:47,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:32,151 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
16:20:32,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:20:32,161 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:20:32,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
16:20:32,170 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
16:20:32,175 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:20:32,179 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:20:47,211 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5871
en_de Dev loss: 0.9185 r:0.1989
en_zh Dev loss: 0.7212 r:0.3989
ro_en Dev loss: 0.3810 r:0.7697
et_en Dev loss: 0.3467 r:0.7165
si_en Dev loss: 0.5770 r:0.6021
ne_en Dev loss: 0.3629 r:0.7366
ru_en Dev loss: 0.4166 r:0.7465
Current avg r:0.5956 Best avg r: 0.5956
16:26:00,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:30,795 root INFO 
id:en_de cur r: 0.2110 best r: 0.2110
16:27:01,169 root INFO 
id:ro_en cur r: 0.7703 best r: 0.7703
16:28:01,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:46,665 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5722
en_de Dev loss: 0.8873 r:0.2000
en_zh Dev loss: 0.7405 r:0.3915
ro_en Dev loss: 0.4239 r:0.7797
et_en Dev loss: 0.3679 r:0.7096
si_en Dev loss: 0.6721 r:0.5798
ne_en Dev loss: 0.4027 r:0.7227
ru_en Dev loss: 0.5032 r:0.7279
Current avg r:0.5873 Best avg r: 0.5956
16:35:00,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:45,352 root INFO 
id:ro_en cur r: 0.7802 best r: 0.7802
16:36:00,426 root INFO 
id:et_en cur r: 0.7108 best r: 0.7108
16:36:45,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:30,819 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5717
en_de Dev loss: 0.8758 r:0.1997
en_zh Dev loss: 0.7238 r:0.3936
ro_en Dev loss: 0.3768 r:0.7900
et_en Dev loss: 0.3632 r:0.7160
si_en Dev loss: 0.7707 r:0.5785
ne_en Dev loss: 0.5023 r:0.7121
ru_en Dev loss: 0.4604 r:0.7395
Current avg r:0.5899 Best avg r: 0.5956
16:43:43,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:44:13,783 root INFO 
id:en_de cur r: 0.2282 best r: 0.2282
16:44:28,947 root INFO 
id:en_zh cur r: 0.4107 best r: 0.4107
16:44:44,115 root INFO 
id:ro_en cur r: 0.7904 best r: 0.7904
16:45:44,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:29,141 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
16:47:29,147 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:47:29,152 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:47:29,156 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
16:47:29,160 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
16:47:29,167 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:47:29,171 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:47:44,50 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5643
en_de Dev loss: 0.8794 r:0.2070
en_zh Dev loss: 0.6953 r:0.4183
ro_en Dev loss: 0.3704 r:0.7964
et_en Dev loss: 0.3483 r:0.7230
si_en Dev loss: 0.6483 r:0.5897
ne_en Dev loss: 0.4312 r:0.7254
ru_en Dev loss: 0.4228 r:0.7517
Current avg r:0.6016 Best avg r: 0.6016
16:52:57,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:27,348 root INFO 
id:en_de cur r: 0.2571 best r: 0.2571
16:53:42,416 root INFO 
id:en_zh cur r: 0.4198 best r: 0.4198
16:53:57,494 root INFO 
id:ro_en cur r: 0.8033 best r: 0.8033
16:54:12,590 root INFO 
id:et_en cur r: 0.7231 best r: 0.7231
16:54:27,512 root INFO 
id:si_en cur r: 0.6048 best r: 0.6048
16:54:42,503 root INFO 
id:ne_en cur r: 0.7481 best r: 0.7481
16:54:57,543 root INFO 
id:ru_en cur r: 0.7475 best r: 0.7475
16:54:57,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:42,456 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
16:56:42,463 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:56:42,468 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:56:42,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
16:56:42,477 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
16:56:42,484 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:56:42,488 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:56:57,447 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5545
en_de Dev loss: 0.8665 r:0.2337
en_zh Dev loss: 0.6967 r:0.4202
ro_en Dev loss: 0.3167 r:0.8079
et_en Dev loss: 0.3358 r:0.7314
si_en Dev loss: 0.5333 r:0.6129
ne_en Dev loss: 0.3633 r:0.7402
ru_en Dev loss: 0.4221 r:0.7466
Current avg r:0.6133 Best avg r: 0.6133
17:02:12,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:57,130 root INFO 
id:ro_en cur r: 0.8067 best r: 0.8067
17:03:42,319 root INFO 
id:ne_en cur r: 0.7491 best r: 0.7491
17:03:57,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:42,423 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
17:05:42,432 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:05:42,437 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:05:42,442 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
17:05:42,449 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
17:05:42,455 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:05:42,460 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:05:57,509 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5238
en_de Dev loss: 0.8909 r:0.2381
en_zh Dev loss: 0.7136 r:0.4259
ro_en Dev loss: 0.3120 r:0.8112
et_en Dev loss: 0.3440 r:0.7228
si_en Dev loss: 0.5519 r:0.6126
ne_en Dev loss: 0.3586 r:0.7431
ru_en Dev loss: 0.4225 r:0.7410
Current avg r:0.6135 Best avg r: 0.6135
17:11:11,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:41,191 root INFO 
id:en_zh cur r: 0.4378 best r: 0.4378
17:11:56,296 root INFO 
id:ro_en cur r: 0.8081 best r: 0.8081
17:12:11,419 root INFO 
id:et_en cur r: 0.7252 best r: 0.7252
17:12:26,545 root INFO 
id:si_en cur r: 0.6087 best r: 0.6087
17:12:41,668 root INFO 
id:ne_en cur r: 0.7540 best r: 0.7540
17:12:56,720 root INFO 
id:ru_en cur r: 0.7585 best r: 0.7585
17:12:56,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:41,763 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
17:14:41,771 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:14:41,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:14:41,781 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
17:14:41,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
17:14:41,792 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:14:41,797 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:14:56,745 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4989
en_de Dev loss: 0.9358 r:0.2298
en_zh Dev loss: 0.7429 r:0.4367
ro_en Dev loss: 0.3474 r:0.8101
et_en Dev loss: 0.3650 r:0.7273
si_en Dev loss: 0.6312 r:0.6098
ne_en Dev loss: 0.3809 r:0.7504
ru_en Dev loss: 0.4243 r:0.7606
Current avg r:0.6178 Best avg r: 0.6178
17:20:10,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:40,737 root INFO 
id:ne_en cur r: 0.7554 best r: 0.7554
17:21:55,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:40,768 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5061
en_de Dev loss: 0.8914 r:0.2186
en_zh Dev loss: 0.6980 r:0.4324
ro_en Dev loss: 0.3297 r:0.8092
et_en Dev loss: 0.3412 r:0.7254
si_en Dev loss: 0.6456 r:0.6022
ne_en Dev loss: 0.3756 r:0.7486
ru_en Dev loss: 0.4238 r:0.7416
Current avg r:0.6111 Best avg r: 0.6178
17:28:54,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:24,807 root INFO 
id:en_zh cur r: 0.4515 best r: 0.4515
17:29:39,897 root INFO 
id:ro_en cur r: 0.8112 best r: 0.8112
17:29:54,994 root INFO 
id:et_en cur r: 0.7277 best r: 0.7277
17:30:10,95 root INFO 
id:si_en cur r: 0.6105 best r: 0.6105
17:30:25,54 root INFO 
id:ne_en cur r: 0.7578 best r: 0.7578
17:30:39,941 root INFO 
id:ru_en cur r: 0.7672 best r: 0.7672
17:30:39,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:25,201 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
17:32:25,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:32:25,211 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:32:25,217 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
17:32:25,221 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
17:32:25,226 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:32:25,231 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:32:40,197 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5359
en_de Dev loss: 0.8536 r:0.2270
en_zh Dev loss: 0.6601 r:0.4545
ro_en Dev loss: 0.2911 r:0.8157
et_en Dev loss: 0.3330 r:0.7296
si_en Dev loss: 0.5661 r:0.6150
ne_en Dev loss: 0.3520 r:0.7548
ru_en Dev loss: 0.3463 r:0.7716
Current avg r:0.6240 Best avg r: 0.6240
17:37:54,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:39,561 root INFO 
id:ro_en cur r: 0.8131 best r: 0.8131
17:38:54,681 root INFO 
id:et_en cur r: 0.7294 best r: 0.7294
17:39:09,974 root INFO 
id:si_en cur r: 0.6171 best r: 0.6171
17:39:25,87 root INFO 
id:ne_en cur r: 0.7589 best r: 0.7589
17:39:39,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:25,395 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5079
en_de Dev loss: 0.8532 r:0.2382
en_zh Dev loss: 0.6889 r:0.4401
ro_en Dev loss: 0.3025 r:0.8146
et_en Dev loss: 0.3407 r:0.7279
si_en Dev loss: 0.5976 r:0.6157
ne_en Dev loss: 0.3447 r:0.7573
ru_en Dev loss: 0.3742 r:0.7619
Current avg r:0.6222 Best avg r: 0.6240
17:46:40,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:25,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:10,740 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4886
en_de Dev loss: 0.8579 r:0.2440
en_zh Dev loss: 0.7049 r:0.4345
ro_en Dev loss: 0.3240 r:0.8085
et_en Dev loss: 0.3462 r:0.7206
si_en Dev loss: 0.6055 r:0.6064
ne_en Dev loss: 0.3944 r:0.7471
ru_en Dev loss: 0.4302 r:0.7316
Current avg r:0.6133 Best avg r: 0.6240
17:55:25,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:10,329 root INFO 
id:ro_en cur r: 0.8137 best r: 0.8137
17:56:40,590 root INFO 
id:si_en cur r: 0.6181 best r: 0.6181
17:56:55,717 root INFO 
id:ne_en cur r: 0.7693 best r: 0.7693
17:57:10,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:55,946 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4786
en_de Dev loss: 0.8514 r:0.2323
en_zh Dev loss: 0.6865 r:0.4457
ro_en Dev loss: 0.3000 r:0.8158
et_en Dev loss: 0.3290 r:0.7319
si_en Dev loss: 0.6495 r:0.6170
ne_en Dev loss: 0.4274 r:0.7528
ru_en Dev loss: 0.4243 r:0.7375
Current avg r:0.6190 Best avg r: 0.6240
18:04:10,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:40,245 root INFO 
id:en_de cur r: 0.2672 best r: 0.2672
18:05:10,359 root INFO 
id:ro_en cur r: 0.8200 best r: 0.8200
18:05:25,436 root INFO 
id:et_en cur r: 0.7331 best r: 0.7331
18:05:40,533 root INFO 
id:si_en cur r: 0.6341 best r: 0.6341
18:05:55,624 root INFO 
id:ne_en cur r: 0.7721 best r: 0.7721
18:06:10,568 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:55,827 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
18:07:55,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:07:55,837 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:07:55,841 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
18:07:55,844 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
18:07:55,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:07:55,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:08:10,917 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4990
en_de Dev loss: 0.8387 r:0.2441
en_zh Dev loss: 0.7011 r:0.4378
ro_en Dev loss: 0.3105 r:0.8181
et_en Dev loss: 0.3344 r:0.7341
si_en Dev loss: 0.5662 r:0.6293
ne_en Dev loss: 0.3488 r:0.7664
ru_en Dev loss: 0.3821 r:0.7549
Current avg r:0.6264 Best avg r: 0.6264
18:13:25,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:15:11,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:56,594 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4996
en_de Dev loss: 0.8451 r:0.2277
en_zh Dev loss: 0.6944 r:0.4301
ro_en Dev loss: 0.3127 r:0.8124
et_en Dev loss: 0.3563 r:0.7220
si_en Dev loss: 0.5810 r:0.6116
ne_en Dev loss: 0.3547 r:0.7591
ru_en Dev loss: 0.4349 r:0.7217
Current avg r:0.6121 Best avg r: 0.6264
18:22:10,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:56,38 root INFO 
id:ro_en cur r: 0.8222 best r: 0.8222
18:23:56,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:41,364 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4852
en_de Dev loss: 0.8447 r:0.2182
en_zh Dev loss: 0.6751 r:0.4336
ro_en Dev loss: 0.2806 r:0.8232
et_en Dev loss: 0.3341 r:0.7284
si_en Dev loss: 0.5622 r:0.6223
ne_en Dev loss: 0.3573 r:0.7594
ru_en Dev loss: 0.4393 r:0.7215
Current avg r:0.6152 Best avg r: 0.6264
18:30:55,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:40,581 root INFO 
id:ro_en cur r: 0.8227 best r: 0.8227
18:32:26,63 root INFO 
id:ne_en cur r: 0.7732 best r: 0.7732
18:32:41,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:26,537 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4904
en_de Dev loss: 0.8408 r:0.2423
en_zh Dev loss: 0.6848 r:0.4424
ro_en Dev loss: 0.2976 r:0.8225
et_en Dev loss: 0.3465 r:0.7233
si_en Dev loss: 0.5548 r:0.6242
ne_en Dev loss: 0.3518 r:0.7649
ru_en Dev loss: 0.4004 r:0.7392
Current avg r:0.6227 Best avg r: 0.6264
18:39:40,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:25,277 root INFO 
id:ro_en cur r: 0.8261 best r: 0.8261
18:41:10,532 root INFO 
id:ne_en cur r: 0.7756 best r: 0.7756
18:41:25,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:10,815 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4682
en_de Dev loss: 0.8475 r:0.2272
en_zh Dev loss: 0.6874 r:0.4394
ro_en Dev loss: 0.2874 r:0.8251
et_en Dev loss: 0.3589 r:0.7247
si_en Dev loss: 0.5379 r:0.6312
ne_en Dev loss: 0.3256 r:0.7693
ru_en Dev loss: 0.3894 r:0.7469
Current avg r:0.6234 Best avg r: 0.6264
18:48:24,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:10,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:55,211 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4756
en_de Dev loss: 0.8665 r:0.2005
en_zh Dev loss: 0.7246 r:0.4152
ro_en Dev loss: 0.3279 r:0.8136
et_en Dev loss: 0.3657 r:0.7109
si_en Dev loss: 0.6462 r:0.5992
ne_en Dev loss: 0.3779 r:0.7531
ru_en Dev loss: 0.4864 r:0.6866
Current avg r:0.5970 Best avg r: 0.6264
18:57:08,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:53,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:39,159 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4686
en_de Dev loss: 0.8635 r:0.2013
en_zh Dev loss: 0.7221 r:0.4324
ro_en Dev loss: 0.3324 r:0.8200
et_en Dev loss: 0.3614 r:0.7159
si_en Dev loss: 0.6264 r:0.6109
ne_en Dev loss: 0.3741 r:0.7650
ru_en Dev loss: 0.4497 r:0.7220
Current avg r:0.6096 Best avg r: 0.6264
19:05:52,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:37,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:22,436 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4614
en_de Dev loss: 0.8860 r:0.2180
en_zh Dev loss: 0.7401 r:0.4445
ro_en Dev loss: 0.3285 r:0.8218
et_en Dev loss: 0.3571 r:0.7205
si_en Dev loss: 0.6878 r:0.6136
ne_en Dev loss: 0.4815 r:0.7570
ru_en Dev loss: 0.4852 r:0.7206
Current avg r:0.6137 Best avg r: 0.6264
19:14:36,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:06,245 root INFO 
id:en_zh cur r: 0.4555 best r: 0.4555
19:16:21,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:06,284 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4078
en_de Dev loss: 0.8744 r:0.2260
en_zh Dev loss: 0.7172 r:0.4475
ro_en Dev loss: 0.3378 r:0.8195
et_en Dev loss: 0.3563 r:0.7198
si_en Dev loss: 0.7338 r:0.6131
ne_en Dev loss: 0.4682 r:0.7623
ru_en Dev loss: 0.4365 r:0.7388
Current avg r:0.6181 Best avg r: 0.6264
19:23:19,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:49,158 root INFO 
id:en_zh cur r: 0.4623 best r: 0.4623
19:25:04,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:49,254 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4412
en_de Dev loss: 0.8505 r:0.2254
en_zh Dev loss: 0.6950 r:0.4498
ro_en Dev loss: 0.3126 r:0.8183
et_en Dev loss: 0.3668 r:0.7112
si_en Dev loss: 0.6484 r:0.6146
ne_en Dev loss: 0.4129 r:0.7626
ru_en Dev loss: 0.4075 r:0.7343
Current avg r:0.6166 Best avg r: 0.6264
19:32:02,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:47,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:32,416 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4094
en_de Dev loss: 0.8855 r:0.2123
en_zh Dev loss: 0.7215 r:0.4425
ro_en Dev loss: 0.3265 r:0.8234
et_en Dev loss: 0.3685 r:0.7126
si_en Dev loss: 0.6745 r:0.6184
ne_en Dev loss: 0.4207 r:0.7607
ru_en Dev loss: 0.4478 r:0.7284
Current avg r:0.6140 Best avg r: 0.6264
19:40:45,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:15,383 root INFO 
id:en_zh cur r: 0.4676 best r: 0.4676
19:42:30,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:15,225 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4434
en_de Dev loss: 0.8603 r:0.2061
en_zh Dev loss: 0.6858 r:0.4578
ro_en Dev loss: 0.3035 r:0.8220
et_en Dev loss: 0.3536 r:0.7172
si_en Dev loss: 0.6486 r:0.6134
ne_en Dev loss: 0.3879 r:0.7603
ru_en Dev loss: 0.4311 r:0.7314
Current avg r:0.6155 Best avg r: 0.6264
19:49:28,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:13,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:58,385 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4027
en_de Dev loss: 0.8656 r:0.2070
en_zh Dev loss: 0.7122 r:0.4497
ro_en Dev loss: 0.3426 r:0.8135
et_en Dev loss: 0.3741 r:0.7089
si_en Dev loss: 0.6769 r:0.6102
ne_en Dev loss: 0.4675 r:0.7497
ru_en Dev loss: 0.4525 r:0.7155
Current avg r:0.6078 Best avg r: 0.6264
19:58:11,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:56,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:01:41,205 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4261
en_de Dev loss: 0.8829 r:0.2133
en_zh Dev loss: 0.7348 r:0.4463
ro_en Dev loss: 0.3353 r:0.8179
et_en Dev loss: 0.3673 r:0.7150
si_en Dev loss: 0.6643 r:0.6136
ne_en Dev loss: 0.4106 r:0.7586
ru_en Dev loss: 0.4602 r:0.7250
Current avg r:0.6128 Best avg r: 0.6264
20:06:54,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:39,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:24,326 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4285
en_de Dev loss: 0.8813 r:0.2311
en_zh Dev loss: 0.7252 r:0.4439
ro_en Dev loss: 0.3191 r:0.8199
et_en Dev loss: 0.3526 r:0.7169
si_en Dev loss: 0.6728 r:0.6108
ne_en Dev loss: 0.3853 r:0.7615
ru_en Dev loss: 0.4640 r:0.7245
Current avg r:0.6155 Best avg r: 0.6264
20:15:37,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:22,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:07,18 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3933
en_de Dev loss: 0.8617 r:0.2263
en_zh Dev loss: 0.7317 r:0.4352
ro_en Dev loss: 0.3155 r:0.8215
et_en Dev loss: 0.3570 r:0.7159
si_en Dev loss: 0.6681 r:0.6184
ne_en Dev loss: 0.3951 r:0.7618
ru_en Dev loss: 0.4360 r:0.7290
Current avg r:0.6155 Best avg r: 0.6264
20:24:19,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:26:04,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:49,139 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3980
en_de Dev loss: 0.8696 r:0.2241
en_zh Dev loss: 0.6920 r:0.4538
ro_en Dev loss: 0.3084 r:0.8224
et_en Dev loss: 0.3635 r:0.7110
si_en Dev loss: 0.7173 r:0.6136
ne_en Dev loss: 0.3981 r:0.7607
ru_en Dev loss: 0.4165 r:0.7443
Current avg r:0.6185 Best avg r: 0.6264
20:33:02,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:33:47,518 root INFO 
id:ro_en cur r: 0.8317 best r: 0.8317
20:34:47,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:32,857 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3956
en_de Dev loss: 0.8407 r:0.2423
en_zh Dev loss: 0.6869 r:0.4555
ro_en Dev loss: 0.2872 r:0.8290
et_en Dev loss: 0.3559 r:0.7142
si_en Dev loss: 0.6602 r:0.6174
ne_en Dev loss: 0.3895 r:0.7699
ru_en Dev loss: 0.3974 r:0.7396
Current avg r:0.6240 Best avg r: 0.6264
20:41:46,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:32,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:17,306 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4024
en_de Dev loss: 0.8931 r:0.2075
en_zh Dev loss: 0.8046 r:0.4270
ro_en Dev loss: 0.3572 r:0.8194
et_en Dev loss: 0.3890 r:0.7082
si_en Dev loss: 0.7345 r:0.6082
ne_en Dev loss: 0.4519 r:0.7618
ru_en Dev loss: 0.4912 r:0.7185
Current avg r:0.6072 Best avg r: 0.6264
20:50:31,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:17,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:02,600 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3953
en_de Dev loss: 0.8559 r:0.2099
en_zh Dev loss: 0.7209 r:0.4292
ro_en Dev loss: 0.3008 r:0.8244
et_en Dev loss: 0.3605 r:0.7087
si_en Dev loss: 0.7129 r:0.6056
ne_en Dev loss: 0.4336 r:0.7624
ru_en Dev loss: 0.4437 r:0.7162
Current avg r:0.6081 Best avg r: 0.6264
20:59:16,916 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:02,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:47,694 root INFO Epoch 2 Global steps: 30100 Train loss: 0.4034
en_de Dev loss: 0.8808 r:0.2196
en_zh Dev loss: 0.7558 r:0.4208
ro_en Dev loss: 0.3116 r:0.8223
et_en Dev loss: 0.3685 r:0.7052
si_en Dev loss: 0.6742 r:0.6173
ne_en Dev loss: 0.3970 r:0.7686
ru_en Dev loss: 0.4586 r:0.7184
Current avg r:0.6103 Best avg r: 0.6264
21:08:02,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:47,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:33,54 root INFO Epoch 2 Global steps: 30800 Train loss: 0.4110
en_de Dev loss: 0.8509 r:0.2316
en_zh Dev loss: 0.7299 r:0.4324
ro_en Dev loss: 0.3017 r:0.8223
et_en Dev loss: 0.3900 r:0.7069
si_en Dev loss: 0.6110 r:0.6212
ne_en Dev loss: 0.3639 r:0.7651
ru_en Dev loss: 0.3955 r:0.7382
Current avg r:0.6168 Best avg r: 0.6264
21:16:47,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:33,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:19,107 root INFO Epoch 2 Global steps: 31500 Train loss: 0.4203
en_de Dev loss: 0.8570 r:0.2148
en_zh Dev loss: 0.7301 r:0.4306
ro_en Dev loss: 0.3139 r:0.8195
et_en Dev loss: 0.3977 r:0.7071
si_en Dev loss: 0.6108 r:0.6197
ne_en Dev loss: 0.3767 r:0.7628
ru_en Dev loss: 0.4216 r:0.7250
Current avg r:0.6113 Best avg r: 0.6264
21:25:34,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:19,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:05,79 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3560
en_de Dev loss: 0.8763 r:0.2147
en_zh Dev loss: 0.7720 r:0.4236
ro_en Dev loss: 0.3508 r:0.8143
et_en Dev loss: 0.3848 r:0.7003
si_en Dev loss: 0.7717 r:0.6025
ne_en Dev loss: 0.5008 r:0.7563
ru_en Dev loss: 0.4806 r:0.7144
Current avg r:0.6037 Best avg r: 0.6264
21:34:19,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:04,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:49,798 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3579
en_de Dev loss: 0.8632 r:0.2075
en_zh Dev loss: 0.7352 r:0.4386
ro_en Dev loss: 0.3278 r:0.8230
et_en Dev loss: 0.3762 r:0.7063
si_en Dev loss: 0.7549 r:0.6153
ne_en Dev loss: 0.4255 r:0.7636
ru_en Dev loss: 0.4795 r:0.7118
Current avg r:0.6095 Best avg r: 0.6264
21:43:03,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:49,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:34,635 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3525
en_de Dev loss: 0.8716 r:0.2198
en_zh Dev loss: 0.7405 r:0.4386
ro_en Dev loss: 0.3252 r:0.8207
et_en Dev loss: 0.3774 r:0.6981
si_en Dev loss: 0.7521 r:0.6086
ne_en Dev loss: 0.5073 r:0.7495
ru_en Dev loss: 0.4757 r:0.7199
Current avg r:0.6079 Best avg r: 0.6264
21:51:48,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:34,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:55:19,257 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3399
en_de Dev loss: 0.8683 r:0.2343
en_zh Dev loss: 0.7730 r:0.4165
ro_en Dev loss: 0.3457 r:0.8125
et_en Dev loss: 0.3972 r:0.6867
si_en Dev loss: 0.7825 r:0.5969
ne_en Dev loss: 0.4603 r:0.7477
ru_en Dev loss: 0.4731 r:0.7051
Current avg r:0.5999 Best avg r: 0.6264
22:00:33,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:18,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:03,623 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3517
en_de Dev loss: 0.8634 r:0.2264
en_zh Dev loss: 0.7245 r:0.4404
ro_en Dev loss: 0.3066 r:0.8215
et_en Dev loss: 0.3715 r:0.7023
si_en Dev loss: 0.6498 r:0.6226
ne_en Dev loss: 0.4728 r:0.7492
ru_en Dev loss: 0.4266 r:0.7310
Current avg r:0.6133 Best avg r: 0.6264
22:09:18,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:03,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:48,771 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3486
en_de Dev loss: 0.8776 r:0.2305
en_zh Dev loss: 0.7346 r:0.4617
ro_en Dev loss: 0.3336 r:0.8246
et_en Dev loss: 0.3916 r:0.7035
si_en Dev loss: 0.6827 r:0.6226
ne_en Dev loss: 0.4424 r:0.7519
ru_en Dev loss: 0.4466 r:0.7460
Current avg r:0.6201 Best avg r: 0.6264
22:18:02,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:48,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:21:33,925 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3463
en_de Dev loss: 0.8551 r:0.2172
en_zh Dev loss: 0.7211 r:0.4395
ro_en Dev loss: 0.3145 r:0.8209
et_en Dev loss: 0.4033 r:0.6945
si_en Dev loss: 0.6270 r:0.6150
ne_en Dev loss: 0.3796 r:0.7579
ru_en Dev loss: 0.4216 r:0.7281
Current avg r:0.6104 Best avg r: 0.6264
22:26:47,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:33,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:17,858 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3392
en_de Dev loss: 0.8663 r:0.2251
en_zh Dev loss: 0.7462 r:0.4242
ro_en Dev loss: 0.3194 r:0.8213
et_en Dev loss: 0.3978 r:0.6869
si_en Dev loss: 0.6976 r:0.6021
ne_en Dev loss: 0.4533 r:0.7498
ru_en Dev loss: 0.4724 r:0.7049
Current avg r:0.6020 Best avg r: 0.6264
22:35:31,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:17,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:02,21 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3201
en_de Dev loss: 0.8782 r:0.2210
en_zh Dev loss: 0.7840 r:0.4241
ro_en Dev loss: 0.3767 r:0.8175
et_en Dev loss: 0.3921 r:0.6961
si_en Dev loss: 0.7420 r:0.6047
ne_en Dev loss: 0.4846 r:0.7540
ru_en Dev loss: 0.4967 r:0.7131
Current avg r:0.6044 Best avg r: 0.6264
22:44:16,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:01,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:46,827 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3316
en_de Dev loss: 0.8617 r:0.2252
en_zh Dev loss: 0.7115 r:0.4506
ro_en Dev loss: 0.3105 r:0.8242
et_en Dev loss: 0.3795 r:0.6991
si_en Dev loss: 0.7302 r:0.6080
ne_en Dev loss: 0.4381 r:0.7556
ru_en Dev loss: 0.4076 r:0.7422
Current avg r:0.6150 Best avg r: 0.6264
22:53:01,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:54:46,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:31,728 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3306
en_de Dev loss: 0.8808 r:0.1979
en_zh Dev loss: 0.7503 r:0.4323
ro_en Dev loss: 0.3303 r:0.8251
et_en Dev loss: 0.3977 r:0.6953
si_en Dev loss: 0.7068 r:0.6042
ne_en Dev loss: 0.3997 r:0.7584
ru_en Dev loss: 0.4431 r:0.7302
Current avg r:0.6062 Best avg r: 0.6264
23:01:45,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:30,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:16,372 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3223
en_de Dev loss: 0.8799 r:0.2152
en_zh Dev loss: 0.7384 r:0.4460
ro_en Dev loss: 0.3372 r:0.8228
et_en Dev loss: 0.4134 r:0.6882
si_en Dev loss: 0.7087 r:0.6002
ne_en Dev loss: 0.4501 r:0.7536
ru_en Dev loss: 0.4408 r:0.7269
Current avg r:0.6076 Best avg r: 0.6264
23:10:30,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:12:15,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:01,368 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3217
en_de Dev loss: 0.8735 r:0.2222
en_zh Dev loss: 0.7234 r:0.4502
ro_en Dev loss: 0.3253 r:0.8274
et_en Dev loss: 0.3950 r:0.7005
si_en Dev loss: 0.6995 r:0.6037
ne_en Dev loss: 0.4324 r:0.7558
ru_en Dev loss: 0.4112 r:0.7395
Current avg r:0.6142 Best avg r: 0.6264
23:19:16,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:01,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:47,742 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3280
en_de Dev loss: 0.8815 r:0.2109
en_zh Dev loss: 0.7584 r:0.4294
ro_en Dev loss: 0.3429 r:0.8212
et_en Dev loss: 0.3904 r:0.6878
si_en Dev loss: 0.7500 r:0.5974
ne_en Dev loss: 0.5376 r:0.7533
ru_en Dev loss: 0.4492 r:0.7220
Current avg r:0.6031 Best avg r: 0.6264
23:28:02,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:49,136 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:35,688 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3324
en_de Dev loss: 0.8788 r:0.2161
en_zh Dev loss: 0.7403 r:0.4491
ro_en Dev loss: 0.3096 r:0.8243
et_en Dev loss: 0.4002 r:0.6923
si_en Dev loss: 0.6222 r:0.6091
ne_en Dev loss: 0.3797 r:0.7551
ru_en Dev loss: 0.4042 r:0.7387
Current avg r:0.6121 Best avg r: 0.6264
23:36:54,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:38:41,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:28,170 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2939
en_de Dev loss: 0.8815 r:0.2148
en_zh Dev loss: 0.7963 r:0.4308
ro_en Dev loss: 0.3477 r:0.8241
et_en Dev loss: 0.4286 r:0.6913
si_en Dev loss: 0.6741 r:0.6050
ne_en Dev loss: 0.4159 r:0.7530
ru_en Dev loss: 0.4617 r:0.7180
Current avg r:0.6053 Best avg r: 0.6264
23:45:45,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:32,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:18,579 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2965
en_de Dev loss: 0.8586 r:0.2217
en_zh Dev loss: 0.7359 r:0.4505
ro_en Dev loss: 0.3311 r:0.8208
et_en Dev loss: 0.4070 r:0.6815
si_en Dev loss: 0.7547 r:0.5968
ne_en Dev loss: 0.4956 r:0.7524
ru_en Dev loss: 0.4557 r:0.7119
Current avg r:0.6051 Best avg r: 0.6264
23:54:34,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:20,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:06,105 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2945
en_de Dev loss: 0.8862 r:0.2232
en_zh Dev loss: 0.8007 r:0.4397
ro_en Dev loss: 0.3485 r:0.8244
et_en Dev loss: 0.4028 r:0.7019
si_en Dev loss: 0.7647 r:0.5967
ne_en Dev loss: 0.4519 r:0.7516
ru_en Dev loss: 0.4584 r:0.7327
Current avg r:0.6100 Best avg r: 0.6264
00:03:21,478 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:07,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:06:52,609 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2796
en_de Dev loss: 0.9001 r:0.2305
en_zh Dev loss: 0.8024 r:0.4263
ro_en Dev loss: 0.3438 r:0.8229
et_en Dev loss: 0.3923 r:0.6981
si_en Dev loss: 0.7413 r:0.5889
ne_en Dev loss: 0.4651 r:0.7480
ru_en Dev loss: 0.4881 r:0.7142
Current avg r:0.6041 Best avg r: 0.6264
00:12:07,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:53,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:39,58 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2824
en_de Dev loss: 0.8479 r:0.2613
en_zh Dev loss: 0.7315 r:0.4565
ro_en Dev loss: 0.3081 r:0.8226
et_en Dev loss: 0.3974 r:0.6963
si_en Dev loss: 0.6820 r:0.5943
ne_en Dev loss: 0.4402 r:0.7482
ru_en Dev loss: 0.4253 r:0.7315
Current avg r:0.6158 Best avg r: 0.6264
00:20:54,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:40,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:24:26,343 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2742
en_de Dev loss: 0.9020 r:0.2397
en_zh Dev loss: 0.8153 r:0.4405
ro_en Dev loss: 0.3645 r:0.8159
et_en Dev loss: 0.4378 r:0.6942
si_en Dev loss: 0.7072 r:0.5911
ne_en Dev loss: 0.4330 r:0.7439
ru_en Dev loss: 0.4684 r:0.7243
Current avg r:0.6071 Best avg r: 0.6264
00:29:41,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:27,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:33:13,169 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2777
en_de Dev loss: 0.8649 r:0.2380
en_zh Dev loss: 0.7424 r:0.4403
ro_en Dev loss: 0.3395 r:0.8171
et_en Dev loss: 0.4019 r:0.6911
si_en Dev loss: 0.7057 r:0.5946
ne_en Dev loss: 0.4057 r:0.7526
ru_en Dev loss: 0.4350 r:0.7296
Current avg r:0.6090 Best avg r: 0.6264
00:38:28,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:13,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:59,247 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2642
en_de Dev loss: 0.8703 r:0.2341
en_zh Dev loss: 0.7739 r:0.4420
ro_en Dev loss: 0.3718 r:0.8179
et_en Dev loss: 0.4195 r:0.6872
si_en Dev loss: 0.8433 r:0.5794
ne_en Dev loss: 0.4920 r:0.7451
ru_en Dev loss: 0.4542 r:0.7264
Current avg r:0.6046 Best avg r: 0.6264
00:47:14,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:59,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:45,265 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2859
en_de Dev loss: 0.8978 r:0.2295
en_zh Dev loss: 0.7957 r:0.4261
ro_en Dev loss: 0.3242 r:0.8234
et_en Dev loss: 0.3911 r:0.6975
si_en Dev loss: 0.7890 r:0.5794
ne_en Dev loss: 0.4093 r:0.7451
ru_en Dev loss: 0.4840 r:0.7184
Current avg r:0.6028 Best avg r: 0.6264
00:56:00,245 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:45,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:31,3 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2944
en_de Dev loss: 0.8798 r:0.2296
en_zh Dev loss: 0.7675 r:0.4497
ro_en Dev loss: 0.3407 r:0.8249
et_en Dev loss: 0.3890 r:0.7002
si_en Dev loss: 0.7964 r:0.5983
ne_en Dev loss: 0.4889 r:0.7507
ru_en Dev loss: 0.4469 r:0.7389
Current avg r:0.6132 Best avg r: 0.6264
01:04:45,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:30,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:15,705 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2884
en_de Dev loss: 0.8699 r:0.2236
en_zh Dev loss: 0.7855 r:0.4283
ro_en Dev loss: 0.3283 r:0.8241
et_en Dev loss: 0.4039 r:0.7010
si_en Dev loss: 0.6878 r:0.5943
ne_en Dev loss: 0.4164 r:0.7504
ru_en Dev loss: 0.4520 r:0.7206
Current avg r:0.6061 Best avg r: 0.6264
01:13:29,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:14,830 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:59,982 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2807
en_de Dev loss: 0.8755 r:0.2292
en_zh Dev loss: 0.7562 r:0.4534
ro_en Dev loss: 0.3506 r:0.8196
et_en Dev loss: 0.4094 r:0.6921
si_en Dev loss: 0.7124 r:0.5915
ne_en Dev loss: 0.4633 r:0.7462
ru_en Dev loss: 0.4450 r:0.7259
Current avg r:0.6083 Best avg r: 0.6264
01:22:14,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:24:00,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:46,92 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2652
en_de Dev loss: 0.8944 r:0.2187
en_zh Dev loss: 0.7616 r:0.4434
ro_en Dev loss: 0.3525 r:0.8135
et_en Dev loss: 0.4111 r:0.6840
si_en Dev loss: 0.8168 r:0.5802
ne_en Dev loss: 0.4999 r:0.7392
ru_en Dev loss: 0.4750 r:0.7177
Current avg r:0.5995 Best avg r: 0.6264
01:31:00,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:32:46,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:32,342 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2868
en_de Dev loss: 0.8862 r:0.2388
en_zh Dev loss: 0.7577 r:0.4442
ro_en Dev loss: 0.3327 r:0.8158
et_en Dev loss: 0.4083 r:0.6853
si_en Dev loss: 0.7493 r:0.5820
ne_en Dev loss: 0.4754 r:0.7383
ru_en Dev loss: 0.4556 r:0.7211
Current avg r:0.6036 Best avg r: 0.6264
01:39:47,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:41:33,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:18,736 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2730
en_de Dev loss: 0.9074 r:0.2365
en_zh Dev loss: 0.7808 r:0.4382
ro_en Dev loss: 0.3556 r:0.8145
et_en Dev loss: 0.4084 r:0.6832
si_en Dev loss: 0.8496 r:0.5735
ne_en Dev loss: 0.5358 r:0.7416
ru_en Dev loss: 0.4732 r:0.7241
Current avg r:0.6016 Best avg r: 0.6264
01:48:34,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:20,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:06,174 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2409
en_de Dev loss: 0.8907 r:0.2292
en_zh Dev loss: 0.7498 r:0.4593
ro_en Dev loss: 0.3142 r:0.8200
et_en Dev loss: 0.4121 r:0.6930
si_en Dev loss: 0.6996 r:0.5909
ne_en Dev loss: 0.4393 r:0.7446
ru_en Dev loss: 0.4075 r:0.7458
Current avg r:0.6118 Best avg r: 0.6264
01:57:21,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:59:06,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:52,464 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2422
en_de Dev loss: 0.9152 r:0.2270
en_zh Dev loss: 0.8262 r:0.4394
ro_en Dev loss: 0.3557 r:0.8156
et_en Dev loss: 0.4284 r:0.6754
si_en Dev loss: 0.9260 r:0.5669
ne_en Dev loss: 0.6068 r:0.7307
ru_en Dev loss: 0.5127 r:0.7163
Current avg r:0.5959 Best avg r: 0.6264
02:06:07,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:07:52,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:09:38,572 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2351
en_de Dev loss: 0.8963 r:0.2133
en_zh Dev loss: 0.7816 r:0.4454
ro_en Dev loss: 0.3384 r:0.8190
et_en Dev loss: 0.4079 r:0.6835
si_en Dev loss: 0.8254 r:0.5845
ne_en Dev loss: 0.5160 r:0.7419
ru_en Dev loss: 0.4476 r:0.7336
Current avg r:0.6030 Best avg r: 0.6264
02:14:53,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:38,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:18:24,281 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2268
en_de Dev loss: 0.8835 r:0.2159
en_zh Dev loss: 0.7817 r:0.4364
ro_en Dev loss: 0.3596 r:0.8104
et_en Dev loss: 0.4084 r:0.6752
si_en Dev loss: 0.8739 r:0.5666
ne_en Dev loss: 0.5444 r:0.7406
ru_en Dev loss: 0.4727 r:0.7107
Current avg r:0.5937 Best avg r: 0.6264
02:23:39,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:25:25,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:10,917 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2380
en_de Dev loss: 0.8587 r:0.2369
en_zh Dev loss: 0.7723 r:0.4259
ro_en Dev loss: 0.3375 r:0.8131
et_en Dev loss: 0.4211 r:0.6811
si_en Dev loss: 0.7603 r:0.5695
ne_en Dev loss: 0.4692 r:0.7346
ru_en Dev loss: 0.4921 r:0.6998
Current avg r:0.5944 Best avg r: 0.6264
02:32:25,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:34:11,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:35:57,171 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2457
en_de Dev loss: 0.8947 r:0.2444
en_zh Dev loss: 0.7737 r:0.4513
ro_en Dev loss: 0.3473 r:0.8192
et_en Dev loss: 0.4138 r:0.6886
si_en Dev loss: 0.7727 r:0.5789
ne_en Dev loss: 0.4826 r:0.7311
ru_en Dev loss: 0.4817 r:0.7269
Current avg r:0.6058 Best avg r: 0.6264
02:41:12,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:42:58,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:43,665 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2367
en_de Dev loss: 0.8701 r:0.2401
en_zh Dev loss: 0.7720 r:0.4464
ro_en Dev loss: 0.3498 r:0.8199
et_en Dev loss: 0.4113 r:0.6823
si_en Dev loss: 0.8741 r:0.5759
ne_en Dev loss: 0.6082 r:0.7377
ru_en Dev loss: 0.4782 r:0.7231
Current avg r:0.6036 Best avg r: 0.6264
02:49:58,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:44,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:30,434 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2429
en_de Dev loss: 0.8941 r:0.2479
en_zh Dev loss: 0.8501 r:0.4258
ro_en Dev loss: 0.3621 r:0.8197
et_en Dev loss: 0.4332 r:0.6852
si_en Dev loss: 0.8178 r:0.5782
ne_en Dev loss: 0.5252 r:0.7296
ru_en Dev loss: 0.5075 r:0.7082
Current avg r:0.5992 Best avg r: 0.6264
02:58:45,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:00:31,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:02:16,690 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2343
en_de Dev loss: 0.8972 r:0.2473
en_zh Dev loss: 0.8139 r:0.4314
ro_en Dev loss: 0.3794 r:0.8145
et_en Dev loss: 0.4304 r:0.6777
si_en Dev loss: 0.8884 r:0.5659
ne_en Dev loss: 0.5415 r:0.7279
ru_en Dev loss: 0.5105 r:0.7094
Current avg r:0.5963 Best avg r: 0.6264
03:07:31,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:17,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:02,739 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2311
en_de Dev loss: 0.8752 r:0.2326
en_zh Dev loss: 0.7573 r:0.4550
ro_en Dev loss: 0.3517 r:0.8228
et_en Dev loss: 0.4406 r:0.6881
si_en Dev loss: 0.7505 r:0.5807
ne_en Dev loss: 0.4353 r:0.7367
ru_en Dev loss: 0.4427 r:0.7303
Current avg r:0.6066 Best avg r: 0.6264
03:16:17,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:18:02,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:47,901 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2345
en_de Dev loss: 0.8962 r:0.2316
en_zh Dev loss: 0.8025 r:0.4403
ro_en Dev loss: 0.3844 r:0.8135
et_en Dev loss: 0.4351 r:0.6743
si_en Dev loss: 0.8312 r:0.5665
ne_en Dev loss: 0.5514 r:0.7388
ru_en Dev loss: 0.5090 r:0.7078
Current avg r:0.5961 Best avg r: 0.6264
03:25:02,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:26:47,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:28:32,678 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2328
en_de Dev loss: 0.8903 r:0.2359
en_zh Dev loss: 0.7908 r:0.4412
ro_en Dev loss: 0.3620 r:0.8181
et_en Dev loss: 0.4282 r:0.6788
si_en Dev loss: 0.8684 r:0.5636
ne_en Dev loss: 0.5275 r:0.7320
ru_en Dev loss: 0.4900 r:0.7195
Current avg r:0.5984 Best avg r: 0.6264
03:33:47,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:32,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:37:17,880 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2342
en_de Dev loss: 0.8997 r:0.2394
en_zh Dev loss: 0.8181 r:0.4380
ro_en Dev loss: 0.3741 r:0.8173
et_en Dev loss: 0.4545 r:0.6796
si_en Dev loss: 0.7735 r:0.5740
ne_en Dev loss: 0.4566 r:0.7334
ru_en Dev loss: 0.5007 r:0.7126
Current avg r:0.5992 Best avg r: 0.6264
03:42:32,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:17,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:46:02,447 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2439
en_de Dev loss: 0.8862 r:0.2385
en_zh Dev loss: 0.7817 r:0.4406
ro_en Dev loss: 0.3517 r:0.8150
et_en Dev loss: 0.4423 r:0.6802
si_en Dev loss: 0.7391 r:0.5721
ne_en Dev loss: 0.4576 r:0.7346
ru_en Dev loss: 0.4480 r:0.7252
Current avg r:0.6009 Best avg r: 0.6264
03:51:17,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:53:02,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:54:48,94 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2255
en_de Dev loss: 0.9087 r:0.2281
en_zh Dev loss: 0.8093 r:0.4479
ro_en Dev loss: 0.3806 r:0.8179
et_en Dev loss: 0.4473 r:0.6840
si_en Dev loss: 0.8398 r:0.5756
ne_en Dev loss: 0.5619 r:0.7309
ru_en Dev loss: 0.4937 r:0.7220
Current avg r:0.6009 Best avg r: 0.6264
04:00:03,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:01:48,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:03:34,46 root INFO Epoch 6 Global steps: 63700 Train loss: 0.1964
en_de Dev loss: 0.9189 r:0.2231
en_zh Dev loss: 0.8155 r:0.4432
ro_en Dev loss: 0.3740 r:0.8167
et_en Dev loss: 0.4722 r:0.6645
si_en Dev loss: 0.8105 r:0.5710
ne_en Dev loss: 0.5213 r:0.7282
ru_en Dev loss: 0.4629 r:0.7273
Current avg r:0.5963 Best avg r: 0.6264
04:08:48,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:10:33,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:12:18,873 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2076
en_de Dev loss: 0.8911 r:0.2238
en_zh Dev loss: 0.7656 r:0.4470
ro_en Dev loss: 0.3174 r:0.8189
et_en Dev loss: 0.4228 r:0.6834
si_en Dev loss: 0.7314 r:0.5790
ne_en Dev loss: 0.4602 r:0.7343
ru_en Dev loss: 0.4072 r:0.7442
Current avg r:0.6044 Best avg r: 0.6264
04:17:32,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:19:18,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:21:03,887 root INFO Epoch 6 Global steps: 65100 Train loss: 0.1990
en_de Dev loss: 0.8869 r:0.2173
en_zh Dev loss: 0.7874 r:0.4377
ro_en Dev loss: 0.3713 r:0.8129
et_en Dev loss: 0.4445 r:0.6704
si_en Dev loss: 0.7619 r:0.5707
ne_en Dev loss: 0.5208 r:0.7268
ru_en Dev loss: 0.4500 r:0.7229
Current avg r:0.5941 Best avg r: 0.6264
04:26:17,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:28:02,913 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:29:47,868 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2075
en_de Dev loss: 0.8953 r:0.2249
en_zh Dev loss: 0.7674 r:0.4456
ro_en Dev loss: 0.3410 r:0.8176
et_en Dev loss: 0.4350 r:0.6632
si_en Dev loss: 0.8084 r:0.5735
ne_en Dev loss: 0.5057 r:0.7260
ru_en Dev loss: 0.4666 r:0.7215
Current avg r:0.5960 Best avg r: 0.6264
04:35:01,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:47,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:32,505 root INFO Epoch 6 Global steps: 66500 Train loss: 0.1943
en_de Dev loss: 0.8953 r:0.2201
en_zh Dev loss: 0.7822 r:0.4554
ro_en Dev loss: 0.3287 r:0.8211
et_en Dev loss: 0.4282 r:0.6752
si_en Dev loss: 0.7613 r:0.5818
ne_en Dev loss: 0.5191 r:0.7272
ru_en Dev loss: 0.4469 r:0.7317
Current avg r:0.6018 Best avg r: 0.6264
04:43:46,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:16,846 root INFO 
id:en_zh cur r: 0.4682 best r: 0.4682
04:45:32,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:47:17,714 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2017
en_de Dev loss: 0.8999 r:0.2262
en_zh Dev loss: 0.7747 r:0.4636
ro_en Dev loss: 0.3721 r:0.8180
et_en Dev loss: 0.4545 r:0.6774
si_en Dev loss: 0.8447 r:0.5712
ne_en Dev loss: 0.5315 r:0.7244
ru_en Dev loss: 0.4589 r:0.7320
Current avg r:0.6018 Best avg r: 0.6264
04:52:31,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:54:17,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:56:02,916 root INFO Epoch 6 Global steps: 67900 Train loss: 0.1996
en_de Dev loss: 0.9011 r:0.2302
en_zh Dev loss: 0.7906 r:0.4456
ro_en Dev loss: 0.3513 r:0.8169
et_en Dev loss: 0.4478 r:0.6696
si_en Dev loss: 0.8302 r:0.5657
ne_en Dev loss: 0.5153 r:0.7270
ru_en Dev loss: 0.4458 r:0.7279
Current avg r:0.5976 Best avg r: 0.6264
05:01:16,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:02,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:04:47,449 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2032
en_de Dev loss: 0.9050 r:0.2460
en_zh Dev loss: 0.8292 r:0.4348
ro_en Dev loss: 0.3767 r:0.8135
et_en Dev loss: 0.4349 r:0.6738
si_en Dev loss: 0.9291 r:0.5484
ne_en Dev loss: 0.6251 r:0.7161
ru_en Dev loss: 0.4946 r:0.7221
Current avg r:0.5935 Best avg r: 0.6264
05:10:01,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:11:46,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:13:32,89 root INFO Epoch 6 Global steps: 69300 Train loss: 0.1994
en_de Dev loss: 0.8992 r:0.2307
en_zh Dev loss: 0.8226 r:0.4381
ro_en Dev loss: 0.3583 r:0.8176
et_en Dev loss: 0.4416 r:0.6733
si_en Dev loss: 0.8583 r:0.5608
ne_en Dev loss: 0.5439 r:0.7251
ru_en Dev loss: 0.4573 r:0.7281
Current avg r:0.5962 Best avg r: 0.6264
05:18:45,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:30,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:22:16,43 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1987
en_de Dev loss: 0.8955 r:0.2333
en_zh Dev loss: 0.7549 r:0.4566
ro_en Dev loss: 0.3327 r:0.8178
et_en Dev loss: 0.4346 r:0.6796
si_en Dev loss: 0.7783 r:0.5630
ne_en Dev loss: 0.4659 r:0.7236
ru_en Dev loss: 0.4310 r:0.7407
Current avg r:0.6021 Best avg r: 0.6264
05:27:30,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:29:15,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:00,2 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1861
en_de Dev loss: 0.9174 r:0.2214
en_zh Dev loss: 0.8160 r:0.4400
ro_en Dev loss: 0.3503 r:0.8186
et_en Dev loss: 0.4441 r:0.6739
si_en Dev loss: 0.8680 r:0.5606
ne_en Dev loss: 0.5432 r:0.7246
ru_en Dev loss: 0.4591 r:0.7324
Current avg r:0.5959 Best avg r: 0.6264
05:36:13,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:58,814 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:39:43,853 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1978
en_de Dev loss: 0.9036 r:0.2351
en_zh Dev loss: 0.7860 r:0.4587
ro_en Dev loss: 0.3606 r:0.8146
et_en Dev loss: 0.4557 r:0.6754
si_en Dev loss: 0.8160 r:0.5624
ne_en Dev loss: 0.4839 r:0.7235
ru_en Dev loss: 0.4502 r:0.7401
Current avg r:0.6014 Best avg r: 0.6264
05:44:57,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:46:43,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:48:28,122 root INFO Epoch 6 Global steps: 72100 Train loss: 0.1964
en_de Dev loss: 0.9160 r:0.2398
en_zh Dev loss: 0.8237 r:0.4437
ro_en Dev loss: 0.3998 r:0.8117
et_en Dev loss: 0.4518 r:0.6611
si_en Dev loss: 1.0281 r:0.5504
ne_en Dev loss: 0.6504 r:0.7187
ru_en Dev loss: 0.5490 r:0.7130
Current avg r:0.5912 Best avg r: 0.6264
05:53:42,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:55:27,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:57:12,951 root INFO Epoch 6 Global steps: 72800 Train loss: 0.1948
en_de Dev loss: 0.8731 r:0.2396
en_zh Dev loss: 0.7614 r:0.4563
ro_en Dev loss: 0.3338 r:0.8181
et_en Dev loss: 0.4325 r:0.6757
si_en Dev loss: 0.7829 r:0.5658
ne_en Dev loss: 0.5125 r:0.7163
ru_en Dev loss: 0.4315 r:0.7413
Current avg r:0.6019 Best avg r: 0.6264
06:02:27,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:13,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:59,5 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2005
en_de Dev loss: 0.8850 r:0.2328
en_zh Dev loss: 0.7705 r:0.4559
ro_en Dev loss: 0.3282 r:0.8162
et_en Dev loss: 0.4300 r:0.6797
si_en Dev loss: 0.7764 r:0.5679
ne_en Dev loss: 0.4875 r:0.7257
ru_en Dev loss: 0.4399 r:0.7350
Current avg r:0.6019 Best avg r: 0.6264
06:11:15,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:13:01,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:14:47,131 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1703
en_de Dev loss: 0.9078 r:0.2330
en_zh Dev loss: 0.7964 r:0.4505
ro_en Dev loss: 0.3620 r:0.8161
et_en Dev loss: 0.4661 r:0.6673
si_en Dev loss: 0.8384 r:0.5583
ne_en Dev loss: 0.5045 r:0.7264
ru_en Dev loss: 0.4542 r:0.7344
Current avg r:0.5980 Best avg r: 0.6264
06:20:01,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:21:47,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:32,300 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1720
en_de Dev loss: 0.9145 r:0.2549
en_zh Dev loss: 0.7923 r:0.4530
ro_en Dev loss: 0.3783 r:0.8152
et_en Dev loss: 0.4463 r:0.6643
si_en Dev loss: 0.8679 r:0.5505
ne_en Dev loss: 0.5667 r:0.7148
ru_en Dev loss: 0.4942 r:0.7275
Current avg r:0.5972 Best avg r: 0.6264
06:28:45,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:30,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:15,284 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1672
en_de Dev loss: 0.8998 r:0.2424
en_zh Dev loss: 0.7834 r:0.4473
ro_en Dev loss: 0.3518 r:0.8136
et_en Dev loss: 0.4549 r:0.6628
si_en Dev loss: 0.8019 r:0.5583
ne_en Dev loss: 0.5016 r:0.7144
ru_en Dev loss: 0.5100 r:0.7126
Current avg r:0.5930 Best avg r: 0.6264
06:37:27,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:39:12,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:40:57,337 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1748
en_de Dev loss: 0.9080 r:0.2315
en_zh Dev loss: 0.7773 r:0.4541
ro_en Dev loss: 0.3515 r:0.8161
et_en Dev loss: 0.4604 r:0.6713
si_en Dev loss: 0.8071 r:0.5636
ne_en Dev loss: 0.5155 r:0.7138
ru_en Dev loss: 0.4378 r:0.7405
Current avg r:0.5987 Best avg r: 0.6264
06:46:10,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:55,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:49:40,757 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1744
en_de Dev loss: 0.8871 r:0.2287
en_zh Dev loss: 0.7614 r:0.4473
ro_en Dev loss: 0.3407 r:0.8168
et_en Dev loss: 0.4661 r:0.6579
si_en Dev loss: 0.8840 r:0.5422
ne_en Dev loss: 0.5577 r:0.7070
ru_en Dev loss: 0.4693 r:0.7190
Current avg r:0.5884 Best avg r: 0.6264
06:54:55,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:56:40,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:58:26,484 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1673
en_de Dev loss: 0.9268 r:0.2099
en_zh Dev loss: 0.8234 r:0.4483
ro_en Dev loss: 0.3739 r:0.8135
et_en Dev loss: 0.4836 r:0.6584
si_en Dev loss: 0.8473 r:0.5537
ne_en Dev loss: 0.5180 r:0.7181
ru_en Dev loss: 0.4985 r:0.7220
Current avg r:0.5891 Best avg r: 0.6264
07:03:40,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:05:26,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:07:12,131 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1741
en_de Dev loss: 0.8906 r:0.2102
en_zh Dev loss: 0.7538 r:0.4555
ro_en Dev loss: 0.3285 r:0.8152
et_en Dev loss: 0.4483 r:0.6666
si_en Dev loss: 0.8213 r:0.5584
ne_en Dev loss: 0.5219 r:0.7227
ru_en Dev loss: 0.4157 r:0.7426
Current avg r:0.5959 Best avg r: 0.6264
07:12:27,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:14:12,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:58,13 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1688
en_de Dev loss: 0.8951 r:0.2325
en_zh Dev loss: 0.7985 r:0.4512
ro_en Dev loss: 0.3547 r:0.8175
et_en Dev loss: 0.4676 r:0.6771
si_en Dev loss: 0.8081 r:0.5665
ne_en Dev loss: 0.4855 r:0.7194
ru_en Dev loss: 0.4686 r:0.7324
Current avg r:0.5995 Best avg r: 0.6264
07:21:12,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:22:58,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:24:43,825 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1657
en_de Dev loss: 0.8851 r:0.2324
en_zh Dev loss: 0.7799 r:0.4400
ro_en Dev loss: 0.3419 r:0.8150
et_en Dev loss: 0.4413 r:0.6623
si_en Dev loss: 0.8587 r:0.5508
ne_en Dev loss: 0.5285 r:0.7155
ru_en Dev loss: 0.4874 r:0.7159
Current avg r:0.5903 Best avg r: 0.6264
07:29:58,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:31:44,599 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:33:30,96 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1603
en_de Dev loss: 0.8978 r:0.2156
en_zh Dev loss: 0.7715 r:0.4466
ro_en Dev loss: 0.3597 r:0.8132
et_en Dev loss: 0.4645 r:0.6526
si_en Dev loss: 0.8569 r:0.5453
ne_en Dev loss: 0.5864 r:0.7157
ru_en Dev loss: 0.4962 r:0.7041
Current avg r:0.5847 Best avg r: 0.6264
07:38:45,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:30,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:16,659 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1761
en_de Dev loss: 0.9010 r:0.2245
en_zh Dev loss: 0.7603 r:0.4512
ro_en Dev loss: 0.3411 r:0.8180
et_en Dev loss: 0.4375 r:0.6563
si_en Dev loss: 0.8769 r:0.5553
ne_en Dev loss: 0.6063 r:0.7135
ru_en Dev loss: 0.4488 r:0.7309
Current avg r:0.5928 Best avg r: 0.6264
07:47:31,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:49:16,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:51:02,689 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1641
en_de Dev loss: 0.8889 r:0.2435
en_zh Dev loss: 0.8093 r:0.4536
ro_en Dev loss: 0.3598 r:0.8173
et_en Dev loss: 0.4884 r:0.6595
si_en Dev loss: 0.8082 r:0.5639
ne_en Dev loss: 0.5579 r:0.7153
ru_en Dev loss: 0.4704 r:0.7258
Current avg r:0.5970 Best avg r: 0.6264
07:56:17,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:58:02,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:59:48,286 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1585
en_de Dev loss: 0.9094 r:0.2267
en_zh Dev loss: 0.7889 r:0.4525
ro_en Dev loss: 0.3385 r:0.8165
et_en Dev loss: 0.4532 r:0.6625
si_en Dev loss: 0.7978 r:0.5578
ne_en Dev loss: 0.5038 r:0.7125
ru_en Dev loss: 0.4487 r:0.7371
Current avg r:0.5951 Best avg r: 0.6264
08:05:02,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:06:47,772 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:08:33,251 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1629
en_de Dev loss: 0.9140 r:0.2376
en_zh Dev loss: 0.8086 r:0.4533
ro_en Dev loss: 0.3545 r:0.8192
et_en Dev loss: 0.4566 r:0.6642
si_en Dev loss: 0.8901 r:0.5534
ne_en Dev loss: 0.5946 r:0.7140
ru_en Dev loss: 0.4650 r:0.7325
Current avg r:0.5963 Best avg r: 0.6264
08:13:47,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:33,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:17:18,380 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1630
en_de Dev loss: 0.9185 r:0.2276
en_zh Dev loss: 0.8103 r:0.4511
ro_en Dev loss: 0.3549 r:0.8170
et_en Dev loss: 0.4472 r:0.6620
si_en Dev loss: 0.8838 r:0.5540
ne_en Dev loss: 0.6288 r:0.7080
ru_en Dev loss: 0.4805 r:0.7289
Current avg r:0.5926 Best avg r: 0.6264
08:22:33,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:24:19,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:04,334 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1424
en_de Dev loss: 0.9161 r:0.2345
en_zh Dev loss: 0.8047 r:0.4468
ro_en Dev loss: 0.3449 r:0.8183
et_en Dev loss: 0.4468 r:0.6624
si_en Dev loss: 0.8824 r:0.5559
ne_en Dev loss: 0.5919 r:0.7102
ru_en Dev loss: 0.4510 r:0.7382
Current avg r:0.5952 Best avg r: 0.6264
08:31:19,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:33:04,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:34:50,514 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1431
en_de Dev loss: 0.9250 r:0.2325
en_zh Dev loss: 0.8020 r:0.4528
ro_en Dev loss: 0.3596 r:0.8173
et_en Dev loss: 0.4696 r:0.6594
si_en Dev loss: 0.8919 r:0.5480
ne_en Dev loss: 0.6281 r:0.7089
ru_en Dev loss: 0.4494 r:0.7407
Current avg r:0.5942 Best avg r: 0.6264
08:40:06,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:41:53,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:39,204 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1423
en_de Dev loss: 0.9074 r:0.2147
en_zh Dev loss: 0.7640 r:0.4618
ro_en Dev loss: 0.3366 r:0.8195
et_en Dev loss: 0.4611 r:0.6660
si_en Dev loss: 0.8212 r:0.5586
ne_en Dev loss: 0.5412 r:0.7053
ru_en Dev loss: 0.4516 r:0.7282
Current avg r:0.5934 Best avg r: 0.6264
08:48:55,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:50:41,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:52:26,862 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1473
en_de Dev loss: 0.8985 r:0.2235
en_zh Dev loss: 0.7687 r:0.4567
ro_en Dev loss: 0.3371 r:0.8158
et_en Dev loss: 0.4577 r:0.6523
si_en Dev loss: 0.7858 r:0.5554
ne_en Dev loss: 0.5282 r:0.7083
ru_en Dev loss: 0.4684 r:0.7245
Current avg r:0.5909 Best avg r: 0.6264
08:57:41,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:59:27,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:01:12,566 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1484
en_de Dev loss: 0.9196 r:0.2217
en_zh Dev loss: 0.8023 r:0.4499
ro_en Dev loss: 0.3732 r:0.8121
et_en Dev loss: 0.4650 r:0.6418
si_en Dev loss: 0.8639 r:0.5508
ne_en Dev loss: 0.6024 r:0.7085
ru_en Dev loss: 0.4832 r:0.7235
Current avg r:0.5869 Best avg r: 0.6264
09:06:27,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:08:12,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:58,484 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1467
en_de Dev loss: 0.8975 r:0.2254
en_zh Dev loss: 0.7639 r:0.4556
ro_en Dev loss: 0.3371 r:0.8143
et_en Dev loss: 0.4798 r:0.6542
si_en Dev loss: 0.7503 r:0.5596
ne_en Dev loss: 0.5089 r:0.7064
ru_en Dev loss: 0.4292 r:0.7353
Current avg r:0.5930 Best avg r: 0.6264
09:15:12,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:16:58,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:18:43,938 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1452
en_de Dev loss: 0.9507 r:0.2072
en_zh Dev loss: 0.8433 r:0.4429
ro_en Dev loss: 0.3646 r:0.8168
et_en Dev loss: 0.4517 r:0.6602
si_en Dev loss: 0.9486 r:0.5516
ne_en Dev loss: 0.5916 r:0.7124
ru_en Dev loss: 0.4663 r:0.7391
Current avg r:0.5900 Best avg r: 0.6264
09:23:58,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:44,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:27:29,577 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1389
en_de Dev loss: 0.9459 r:0.2122
en_zh Dev loss: 0.8076 r:0.4574
ro_en Dev loss: 0.3748 r:0.8172
et_en Dev loss: 0.4495 r:0.6635
si_en Dev loss: 0.9313 r:0.5480
ne_en Dev loss: 0.5873 r:0.7068
ru_en Dev loss: 0.4788 r:0.7347
Current avg r:0.5914 Best avg r: 0.6264
09:32:44,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:34:29,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:15,526 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1460
en_de Dev loss: 0.9742 r:0.2086
en_zh Dev loss: 0.8441 r:0.4400
ro_en Dev loss: 0.3752 r:0.8137
et_en Dev loss: 0.5018 r:0.6496
si_en Dev loss: 0.9391 r:0.5370
ne_en Dev loss: 0.5916 r:0.6972
ru_en Dev loss: 0.5148 r:0.7193
Current avg r:0.5808 Best avg r: 0.6264
09:41:30,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:16,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:45:01,839 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1409
en_de Dev loss: 0.9207 r:0.2155
en_zh Dev loss: 0.7706 r:0.4565
ro_en Dev loss: 0.3240 r:0.8201
et_en Dev loss: 0.4375 r:0.6680
si_en Dev loss: 0.7992 r:0.5545
ne_en Dev loss: 0.4990 r:0.7132
ru_en Dev loss: 0.4599 r:0.7329
Current avg r:0.5944 Best avg r: 0.6264
09:50:16,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:52:02,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:53:47,902 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1474
en_de Dev loss: 0.9326 r:0.2058
en_zh Dev loss: 0.8125 r:0.4413
ro_en Dev loss: 0.3620 r:0.8142
et_en Dev loss: 0.4511 r:0.6598
si_en Dev loss: 0.8918 r:0.5453
ne_en Dev loss: 0.6086 r:0.7085
ru_en Dev loss: 0.4583 r:0.7334
Current avg r:0.5869 Best avg r: 0.6264
09:59:02,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:59:32,918 root INFO 
id:en_zh cur r: 0.4790 best r: 0.4790
10:00:48,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:33,566 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1443
en_de Dev loss: 0.9247 r:0.2184
en_zh Dev loss: 0.7667 r:0.4752
ro_en Dev loss: 0.3415 r:0.8197
et_en Dev loss: 0.4849 r:0.6838
si_en Dev loss: 0.7912 r:0.5598
ne_en Dev loss: 0.5363 r:0.7096
ru_en Dev loss: 0.4182 r:0.7485
Current avg r:0.6021 Best avg r: 0.6264
10:07:47,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:09:33,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:19,73 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1433
en_de Dev loss: 0.9221 r:0.2053
en_zh Dev loss: 0.7644 r:0.4583
ro_en Dev loss: 0.3254 r:0.8197
et_en Dev loss: 0.4438 r:0.6760
si_en Dev loss: 0.8260 r:0.5535
ne_en Dev loss: 0.5151 r:0.7066
ru_en Dev loss: 0.4037 r:0.7508
Current avg r:0.5957 Best avg r: 0.6264
10:16:33,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:19,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:05,108 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1376
en_de Dev loss: 0.9020 r:0.2073
en_zh Dev loss: 0.7255 r:0.4731
ro_en Dev loss: 0.3093 r:0.8219
et_en Dev loss: 0.4440 r:0.6753
si_en Dev loss: 0.7683 r:0.5575
ne_en Dev loss: 0.4875 r:0.7048
ru_en Dev loss: 0.3903 r:0.7526
Current avg r:0.5990 Best avg r: 0.6264
10:25:19,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:05,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:28:50,267 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1401
en_de Dev loss: 0.9398 r:0.2121
en_zh Dev loss: 0.7936 r:0.4708
ro_en Dev loss: 0.3679 r:0.8170
et_en Dev loss: 0.4646 r:0.6677
si_en Dev loss: 0.8405 r:0.5558
ne_en Dev loss: 0.5431 r:0.7128
ru_en Dev loss: 0.4523 r:0.7465
Current avg r:0.5975 Best avg r: 0.6264
10:34:04,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:35:49,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:37:33,848 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1337
en_de Dev loss: 0.9458 r:0.2047
en_zh Dev loss: 0.7965 r:0.4589
ro_en Dev loss: 0.3435 r:0.8207
et_en Dev loss: 0.4694 r:0.6702
si_en Dev loss: 0.7908 r:0.5601
ne_en Dev loss: 0.4915 r:0.7079
ru_en Dev loss: 0.4414 r:0.7433
Current avg r:0.5951 Best avg r: 0.6264
