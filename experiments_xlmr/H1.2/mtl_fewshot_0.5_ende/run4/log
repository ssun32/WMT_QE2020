14:43:50,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:16,202 root INFO 
id:en_de cur r: 0.1047 best r: 0.1047
14:44:29,58 root INFO 
id:en_zh cur r: 0.2915 best r: 0.2915
14:44:41,947 root INFO 
id:ro_en cur r: 0.6117 best r: 0.6117
14:44:54,848 root INFO 
id:et_en cur r: 0.3845 best r: 0.3845
14:45:07,758 root INFO 
id:si_en cur r: 0.1793 best r: 0.1793
14:45:20,661 root INFO 
id:ne_en cur r: 0.5114 best r: 0.5114
14:45:33,498 root INFO 
id:ru_en cur r: 0.6486 best r: 0.6486
14:45:33,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:03,590 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
14:47:03,597 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:47:03,601 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:47:03,606 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
14:47:03,611 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
14:47:03,615 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:47:03,621 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:47:16,506 root INFO Epoch 0 Global steps: 700 Train loss: 0.8619
en_de Dev loss: 0.9066 r:0.1068
en_zh Dev loss: 0.7935 r:0.2826
ro_en Dev loss: 0.6476 r:0.6338
et_en Dev loss: 0.6421 r:0.5309
si_en Dev loss: 0.7097 r:0.4470
ne_en Dev loss: 0.6591 r:0.5247
ru_en Dev loss: 0.6256 r:0.6381
Current avg r:0.4520 Best avg r: 0.4520
14:51:45,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:37,388 root INFO 
id:et_en cur r: 0.4480 best r: 0.4480
14:52:50,290 root INFO 
id:si_en cur r: 0.3857 best r: 0.3857
14:53:03,173 root INFO 
id:ne_en cur r: 0.5370 best r: 0.5370
14:53:15,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:45,978 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7493
en_de Dev loss: 0.9286 r:0.0890
en_zh Dev loss: 0.7888 r:0.2479
ro_en Dev loss: 0.6297 r:0.6226
et_en Dev loss: 0.5833 r:0.4917
si_en Dev loss: 0.7232 r:0.4397
ne_en Dev loss: 0.5935 r:0.5343
ru_en Dev loss: 0.5306 r:0.6707
Current avg r:0.4423 Best avg r: 0.4520
14:59:14,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:53,288 root INFO 
id:ro_en cur r: 0.6512 best r: 0.6512
15:00:06,176 root INFO 
id:et_en cur r: 0.5645 best r: 0.5645
15:00:19,53 root INFO 
id:si_en cur r: 0.4290 best r: 0.4290
15:00:31,938 root INFO 
id:ne_en cur r: 0.5586 best r: 0.5586
15:00:44,754 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:14,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:02:14,736 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:02:14,742 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:02:14,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:02:14,752 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:02:14,758 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:02:14,766 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:02:27,632 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7390
en_de Dev loss: 0.9269 r:0.1076
en_zh Dev loss: 0.7841 r:0.2631
ro_en Dev loss: 0.5383 r:0.6832
et_en Dev loss: 0.4915 r:0.5990
si_en Dev loss: 0.6807 r:0.4757
ne_en Dev loss: 0.5502 r:0.5794
ru_en Dev loss: 0.5238 r:0.6838
Current avg r:0.4845 Best avg r: 0.4845
15:06:56,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:22,317 root INFO 
id:en_zh cur r: 0.2971 best r: 0.2971
15:07:35,190 root INFO 
id:ro_en cur r: 0.6787 best r: 0.6787
15:07:48,78 root INFO 
id:et_en cur r: 0.6199 best r: 0.6199
15:08:00,965 root INFO 
id:si_en cur r: 0.4444 best r: 0.4444
15:08:13,848 root INFO 
id:ne_en cur r: 0.6307 best r: 0.6307
15:08:26,674 root INFO 
id:ru_en cur r: 0.7071 best r: 0.7071
15:08:26,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:56,672 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:09:56,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:09:56,685 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:09:56,689 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:09:56,694 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:09:56,698 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:09:56,704 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:10:09,575 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6967
en_de Dev loss: 0.9712 r:0.1215
en_zh Dev loss: 0.7871 r:0.3224
ro_en Dev loss: 0.5217 r:0.7094
et_en Dev loss: 0.4336 r:0.6559
si_en Dev loss: 0.7613 r:0.4934
ne_en Dev loss: 0.4885 r:0.6451
ru_en Dev loss: 0.4691 r:0.7297
Current avg r:0.5253 Best avg r: 0.5253
15:14:38,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:04,448 root INFO 
id:en_de cur r: 0.1394 best r: 0.1394
15:15:17,313 root INFO 
id:en_zh cur r: 0.3065 best r: 0.3065
15:15:30,204 root INFO 
id:ro_en cur r: 0.7142 best r: 0.7142
15:15:43,102 root INFO 
id:et_en cur r: 0.6474 best r: 0.6474
15:15:55,997 root INFO 
id:si_en cur r: 0.4701 best r: 0.4701
15:16:08,902 root INFO 
id:ne_en cur r: 0.6425 best r: 0.6425
15:16:21,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:51,806 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:17:51,813 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:17:51,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:17:51,822 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:17:51,827 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:17:51,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:17:51,837 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:18:04,722 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6492
en_de Dev loss: 1.0046 r:0.1534
en_zh Dev loss: 0.8454 r:0.3455
ro_en Dev loss: 0.5173 r:0.7329
et_en Dev loss: 0.4166 r:0.6669
si_en Dev loss: 0.7912 r:0.5110
ne_en Dev loss: 0.5339 r:0.6434
ru_en Dev loss: 0.5175 r:0.7236
Current avg r:0.5395 Best avg r: 0.5395
15:22:34,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:00,26 root INFO 
id:en_de cur r: 0.1597 best r: 0.1597
15:23:12,878 root INFO 
id:en_zh cur r: 0.3276 best r: 0.3276
15:23:25,767 root INFO 
id:ro_en cur r: 0.7234 best r: 0.7234
15:23:51,566 root INFO 
id:si_en cur r: 0.4946 best r: 0.4946
15:24:04,464 root INFO 
id:ne_en cur r: 0.6568 best r: 0.6568
15:24:17,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:47,368 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:25:47,375 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:25:47,379 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:25:47,384 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:25:47,388 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:25:47,393 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:25:47,400 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:26:00,281 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6414
en_de Dev loss: 1.0400 r:0.1694
en_zh Dev loss: 0.8422 r:0.3554
ro_en Dev loss: 0.4958 r:0.7399
et_en Dev loss: 0.4322 r:0.6615
si_en Dev loss: 0.7566 r:0.5288
ne_en Dev loss: 0.5045 r:0.6583
ru_en Dev loss: 0.5326 r:0.7210
Current avg r:0.5478 Best avg r: 0.5478
15:30:29,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:55,664 root INFO 
id:en_zh cur r: 0.3887 best r: 0.3887
15:31:08,523 root INFO 
id:ro_en cur r: 0.7498 best r: 0.7498
15:31:21,413 root INFO 
id:et_en cur r: 0.6663 best r: 0.6663
15:31:34,314 root INFO 
id:si_en cur r: 0.5478 best r: 0.5478
15:31:47,212 root INFO 
id:ne_en cur r: 0.6913 best r: 0.6913
15:32:00,52 root INFO 
id:ru_en cur r: 0.7111 best r: 0.7111
15:32:00,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:30,151 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:33:30,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:33:30,161 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:33:30,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:33:30,170 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:33:30,174 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:33:30,179 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:33:43,66 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6344
en_de Dev loss: 0.9121 r:0.1859
en_zh Dev loss: 0.7341 r:0.4076
ro_en Dev loss: 0.3824 r:0.7593
et_en Dev loss: 0.3881 r:0.6810
si_en Dev loss: 0.6742 r:0.5642
ne_en Dev loss: 0.5166 r:0.6771
ru_en Dev loss: 0.4599 r:0.7299
Current avg r:0.5722 Best avg r: 0.5722
15:38:12,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:51,270 root INFO 
id:ro_en cur r: 0.7640 best r: 0.7640
15:39:04,171 root INFO 
id:et_en cur r: 0.6805 best r: 0.6805
15:39:17,72 root INFO 
id:si_en cur r: 0.5624 best r: 0.5624
15:39:29,967 root INFO 
id:ne_en cur r: 0.7133 best r: 0.7133
15:39:42,802 root INFO 
id:ru_en cur r: 0.7358 best r: 0.7358
15:39:42,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:12,874 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:41:12,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:41:12,887 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:41:12,892 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:41:12,896 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:41:12,901 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:41:12,907 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:41:25,789 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6009
en_de Dev loss: 0.9244 r:0.1865
en_zh Dev loss: 0.7671 r:0.3867
ro_en Dev loss: 0.3794 r:0.7704
et_en Dev loss: 0.3704 r:0.6923
si_en Dev loss: 0.6713 r:0.5714
ne_en Dev loss: 0.4247 r:0.7083
ru_en Dev loss: 0.4479 r:0.7461
Current avg r:0.5802 Best avg r: 0.5802
15:45:55,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:20,944 root INFO 
id:en_de cur r: 0.1817 best r: 0.1817
15:46:46,659 root INFO 
id:ro_en cur r: 0.7758 best r: 0.7758
15:47:25,312 root INFO 
id:ne_en cur r: 0.7138 best r: 0.7138
15:47:38,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:08,91 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:49:08,98 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:49:08,102 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:49:08,107 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:49:08,112 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:49:08,116 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:49:08,123 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:49:20,994 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5818
en_de Dev loss: 0.9212 r:0.1994
en_zh Dev loss: 0.7953 r:0.3927
ro_en Dev loss: 0.3585 r:0.7805
et_en Dev loss: 0.3803 r:0.6867
si_en Dev loss: 0.6484 r:0.5794
ne_en Dev loss: 0.4044 r:0.7147
ru_en Dev loss: 0.4458 r:0.7338
Current avg r:0.5839 Best avg r: 0.5839
15:53:49,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:15,600 root INFO 
id:en_de cur r: 0.1961 best r: 0.1961
15:55:19,958 root INFO 
id:ne_en cur r: 0.7141 best r: 0.7141
15:55:32,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:02,767 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
15:57:02,774 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:57:02,780 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:57:02,785 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
15:57:02,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
15:57:02,794 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:57:02,798 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:57:15,670 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5635
en_de Dev loss: 0.9420 r:0.2191
en_zh Dev loss: 0.7766 r:0.3982
ro_en Dev loss: 0.4126 r:0.7798
et_en Dev loss: 0.4053 r:0.6887
si_en Dev loss: 0.7778 r:0.5693
ne_en Dev loss: 0.4976 r:0.7159
ru_en Dev loss: 0.5038 r:0.7298
Current avg r:0.5858 Best avg r: 0.5858
16:01:44,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:02:10,355 root INFO 
id:en_zh cur r: 0.4048 best r: 0.4048
16:02:36,103 root INFO 
id:et_en cur r: 0.6888 best r: 0.6888
16:03:01,855 root INFO 
id:ne_en cur r: 0.7199 best r: 0.7199
16:03:14,678 root INFO 
id:ru_en cur r: 0.7445 best r: 0.7445
16:03:14,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:44,631 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
16:04:44,639 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:04:44,643 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:04:44,649 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
16:04:44,653 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
16:04:44,662 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:04:44,670 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:04:57,531 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5796
en_de Dev loss: 0.9401 r:0.2230
en_zh Dev loss: 0.7667 r:0.4062
ro_en Dev loss: 0.4329 r:0.7765
et_en Dev loss: 0.4281 r:0.6881
si_en Dev loss: 0.7617 r:0.5714
ne_en Dev loss: 0.4499 r:0.7187
ru_en Dev loss: 0.4948 r:0.7435
Current avg r:0.5896 Best avg r: 0.5896
16:09:26,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:52,4 root INFO 
id:en_de cur r: 0.2068 best r: 0.2068
16:11:09,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:39,118 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
16:12:39,126 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:12:39,130 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:12:39,135 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
16:12:39,139 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
16:12:39,144 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:12:39,149 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:12:52,24 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5613
en_de Dev loss: 0.8909 r:0.2208
en_zh Dev loss: 0.7448 r:0.4051
ro_en Dev loss: 0.4151 r:0.7810
et_en Dev loss: 0.3760 r:0.6959
si_en Dev loss: 0.7044 r:0.5715
ne_en Dev loss: 0.4425 r:0.7178
ru_en Dev loss: 0.4872 r:0.7353
Current avg r:0.5896 Best avg r: 0.5896
16:17:20,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:46,534 root INFO 
id:en_de cur r: 0.2092 best r: 0.2092
16:17:59,377 root INFO 
id:en_zh cur r: 0.4384 best r: 0.4384
16:18:12,254 root INFO 
id:ro_en cur r: 0.7912 best r: 0.7912
16:18:25,134 root INFO 
id:et_en cur r: 0.7061 best r: 0.7061
16:18:38,25 root INFO 
id:si_en cur r: 0.5904 best r: 0.5904
16:18:50,909 root INFO 
id:ne_en cur r: 0.7457 best r: 0.7457
16:19:03,732 root INFO 
id:ru_en cur r: 0.7539 best r: 0.7539
16:19:03,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:33,692 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
16:20:33,699 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:20:33,705 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:20:33,709 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
16:20:33,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
16:20:33,719 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:20:33,725 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:20:46,590 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5664
en_de Dev loss: 0.8546 r:0.2336
en_zh Dev loss: 0.6701 r:0.4432
ro_en Dev loss: 0.3313 r:0.7953
et_en Dev loss: 0.3619 r:0.7119
si_en Dev loss: 0.5771 r:0.6041
ne_en Dev loss: 0.3512 r:0.7460
ru_en Dev loss: 0.3639 r:0.7631
Current avg r:0.6139 Best avg r: 0.6139
16:25:15,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:41,199 root INFO 
id:en_de cur r: 0.2215 best r: 0.2215
16:26:06,906 root INFO 
id:ro_en cur r: 0.7957 best r: 0.7957
16:26:58,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:28,337 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5488
en_de Dev loss: 0.9127 r:0.2382
en_zh Dev loss: 0.7885 r:0.4336
ro_en Dev loss: 0.4340 r:0.8004
et_en Dev loss: 0.4091 r:0.7013
si_en Dev loss: 0.7888 r:0.5925
ne_en Dev loss: 0.4736 r:0.7308
ru_en Dev loss: 0.5030 r:0.7518
Current avg r:0.6069 Best avg r: 0.6139
16:32:57,717 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:23,484 root INFO 
id:en_de cur r: 0.2380 best r: 0.2380
16:33:49,232 root INFO 
id:ro_en cur r: 0.8036 best r: 0.8036
16:34:15,17 root INFO 
id:si_en cur r: 0.5955 best r: 0.5955
16:34:40,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:10,813 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5322
en_de Dev loss: 0.8407 r:0.2387
en_zh Dev loss: 0.7001 r:0.4329
ro_en Dev loss: 0.3192 r:0.8045
et_en Dev loss: 0.3686 r:0.7053
si_en Dev loss: 0.6043 r:0.6069
ne_en Dev loss: 0.4080 r:0.7420
ru_en Dev loss: 0.4148 r:0.7488
Current avg r:0.6113 Best avg r: 0.6139
16:40:42,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:08,56 root INFO 
id:en_de cur r: 0.2470 best r: 0.2470
16:41:33,759 root INFO 
id:ro_en cur r: 0.8037 best r: 0.8037
16:42:25,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:55,112 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5263
en_de Dev loss: 0.8969 r:0.2529
en_zh Dev loss: 0.8109 r:0.4280
ro_en Dev loss: 0.4009 r:0.8038
et_en Dev loss: 0.4022 r:0.7025
si_en Dev loss: 0.7545 r:0.6037
ne_en Dev loss: 0.4225 r:0.7459
ru_en Dev loss: 0.4890 r:0.7466
Current avg r:0.6119 Best avg r: 0.6139
16:48:24,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:03,432 root INFO 
id:ro_en cur r: 0.8085 best r: 0.8085
16:49:29,189 root INFO 
id:si_en cur r: 0.5959 best r: 0.5959
16:49:42,79 root INFO 
id:ne_en cur r: 0.7480 best r: 0.7480
16:49:54,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:24,858 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5296
en_de Dev loss: 0.8544 r:0.2474
en_zh Dev loss: 0.7014 r:0.4354
ro_en Dev loss: 0.3578 r:0.8071
et_en Dev loss: 0.3804 r:0.7057
si_en Dev loss: 0.7959 r:0.6011
ne_en Dev loss: 0.4489 r:0.7476
ru_en Dev loss: 0.4819 r:0.7335
Current avg r:0.6111 Best avg r: 0.6139
16:55:54,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:20,290 root INFO 
id:en_de cur r: 0.2511 best r: 0.2511
16:56:45,977 root INFO 
id:ro_en cur r: 0.8086 best r: 0.8086
16:57:11,707 root INFO 
id:si_en cur r: 0.5979 best r: 0.5979
16:57:24,585 root INFO 
id:ne_en cur r: 0.7488 best r: 0.7488
16:57:37,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:07,195 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4923
en_de Dev loss: 0.8663 r:0.2476
en_zh Dev loss: 0.7718 r:0.4345
ro_en Dev loss: 0.3723 r:0.8077
et_en Dev loss: 0.3899 r:0.7041
si_en Dev loss: 0.7057 r:0.6040
ne_en Dev loss: 0.4460 r:0.7475
ru_en Dev loss: 0.4838 r:0.7418
Current avg r:0.6125 Best avg r: 0.6139
17:03:35,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:01,501 root INFO 
id:en_de cur r: 0.2557 best r: 0.2557
17:04:14,330 root INFO 
id:en_zh cur r: 0.4432 best r: 0.4432
17:04:27,189 root INFO 
id:ro_en cur r: 0.8094 best r: 0.8094
17:04:40,55 root INFO 
id:et_en cur r: 0.7085 best r: 0.7085
17:04:52,931 root INFO 
id:si_en cur r: 0.6071 best r: 0.6071
17:05:05,802 root INFO 
id:ne_en cur r: 0.7534 best r: 0.7534
17:05:18,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:48,486 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
17:06:48,494 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:06:48,499 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:06:48,503 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
17:06:48,510 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
17:06:48,514 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:06:48,520 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:07:01,365 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5401
en_de Dev loss: 0.8900 r:0.2532
en_zh Dev loss: 0.7159 r:0.4463
ro_en Dev loss: 0.3652 r:0.8062
et_en Dev loss: 0.3686 r:0.7073
si_en Dev loss: 0.6645 r:0.6118
ne_en Dev loss: 0.4417 r:0.7521
ru_en Dev loss: 0.4842 r:0.7373
Current avg r:0.6163 Best avg r: 0.6163
17:11:30,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:56,353 root INFO 
id:en_zh cur r: 0.4450 best r: 0.4450
17:12:09,214 root INFO 
id:ro_en cur r: 0.8101 best r: 0.8101
17:12:22,79 root INFO 
id:et_en cur r: 0.7160 best r: 0.7160
17:12:34,953 root INFO 
id:si_en cur r: 0.6237 best r: 0.6237
17:12:47,821 root INFO 
id:ne_en cur r: 0.7577 best r: 0.7577
17:13:00,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:30,499 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
17:14:30,506 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:14:30,510 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:14:30,516 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
17:14:30,520 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
17:14:30,524 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:14:30,529 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:14:43,380 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5105
en_de Dev loss: 0.8898 r:0.2380
en_zh Dev loss: 0.7415 r:0.4410
ro_en Dev loss: 0.4288 r:0.8077
et_en Dev loss: 0.3795 r:0.7123
si_en Dev loss: 0.6767 r:0.6243
ne_en Dev loss: 0.4340 r:0.7565
ru_en Dev loss: 0.4767 r:0.7442
Current avg r:0.6177 Best avg r: 0.6177
17:19:12,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:38,498 root INFO 
id:en_zh cur r: 0.4528 best r: 0.4528
17:19:51,354 root INFO 
id:ro_en cur r: 0.8119 best r: 0.8119
17:20:42,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:12,637 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5099
en_de Dev loss: 0.8568 r:0.2404
en_zh Dev loss: 0.7009 r:0.4483
ro_en Dev loss: 0.3518 r:0.8073
et_en Dev loss: 0.3812 r:0.7029
si_en Dev loss: 0.6411 r:0.6175
ne_en Dev loss: 0.4083 r:0.7512
ru_en Dev loss: 0.4541 r:0.7314
Current avg r:0.6141 Best avg r: 0.6177
17:26:42,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:07,791 root INFO 
id:en_zh cur r: 0.4575 best r: 0.4575
17:27:20,646 root INFO 
id:ro_en cur r: 0.8178 best r: 0.8178
17:27:33,522 root INFO 
id:et_en cur r: 0.7201 best r: 0.7201
17:27:59,259 root INFO 
id:ne_en cur r: 0.7611 best r: 0.7611
17:28:12,67 root INFO 
id:ru_en cur r: 0.7637 best r: 0.7637
17:28:12,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:41,957 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
17:29:41,964 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:29:41,969 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:29:41,973 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
17:29:41,978 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
17:29:41,983 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:29:41,989 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:29:54,840 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4704
en_de Dev loss: 0.8546 r:0.2400
en_zh Dev loss: 0.7096 r:0.4477
ro_en Dev loss: 0.3615 r:0.8123
et_en Dev loss: 0.3653 r:0.7186
si_en Dev loss: 0.6786 r:0.6235
ne_en Dev loss: 0.4248 r:0.7601
ru_en Dev loss: 0.3762 r:0.7657
Current avg r:0.6240 Best avg r: 0.6240
17:34:24,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:49,924 root INFO 
id:en_de cur r: 0.2590 best r: 0.2590
17:36:06,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:36,811 root INFO Epoch 1 Global steps: 16100 Train loss: 0.5042
en_de Dev loss: 0.9044 r:0.2437
en_zh Dev loss: 0.7303 r:0.4488
ro_en Dev loss: 0.4519 r:0.8092
et_en Dev loss: 0.4059 r:0.7001
si_en Dev loss: 0.7936 r:0.6050
ne_en Dev loss: 0.5484 r:0.7548
ru_en Dev loss: 0.4877 r:0.7375
Current avg r:0.6142 Best avg r: 0.6240
17:42:05,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:35,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:04,854 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4637
en_de Dev loss: 0.8770 r:0.2292
en_zh Dev loss: 0.7343 r:0.4420
ro_en Dev loss: 0.3497 r:0.8100
et_en Dev loss: 0.3800 r:0.6995
si_en Dev loss: 0.6217 r:0.6173
ne_en Dev loss: 0.4215 r:0.7590
ru_en Dev loss: 0.4226 r:0.7404
Current avg r:0.6139 Best avg r: 0.6240
17:49:33,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:12,131 root INFO 
id:ro_en cur r: 0.8218 best r: 0.8218
17:50:50,701 root INFO 
id:ne_en cur r: 0.7612 best r: 0.7612
17:51:03,507 root INFO 
id:ru_en cur r: 0.7640 best r: 0.7640
17:51:03,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:33,375 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4853
en_de Dev loss: 0.8621 r:0.2293
en_zh Dev loss: 0.7119 r:0.4439
ro_en Dev loss: 0.3016 r:0.8213
et_en Dev loss: 0.3552 r:0.7138
si_en Dev loss: 0.5787 r:0.6280
ne_en Dev loss: 0.3788 r:0.7609
ru_en Dev loss: 0.4281 r:0.7535
Current avg r:0.6215 Best avg r: 0.6240
17:57:02,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:19,807 root INFO 
id:ne_en cur r: 0.7630 best r: 0.7630
17:58:32,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:02,500 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4695
en_de Dev loss: 0.8595 r:0.2331
en_zh Dev loss: 0.7076 r:0.4505
ro_en Dev loss: 0.3279 r:0.8147
et_en Dev loss: 0.3784 r:0.7109
si_en Dev loss: 0.6313 r:0.6205
ne_en Dev loss: 0.4212 r:0.7615
ru_en Dev loss: 0.4388 r:0.7461
Current avg r:0.6196 Best avg r: 0.6240
18:04:31,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:01,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:31,594 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4861
en_de Dev loss: 0.8551 r:0.2436
en_zh Dev loss: 0.7292 r:0.4517
ro_en Dev loss: 0.3272 r:0.8142
et_en Dev loss: 0.3692 r:0.7139
si_en Dev loss: 0.6604 r:0.6142
ne_en Dev loss: 0.4308 r:0.7515
ru_en Dev loss: 0.4356 r:0.7427
Current avg r:0.6188 Best avg r: 0.6240
18:12:00,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:30,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:00,698 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4891
en_de Dev loss: 0.8469 r:0.2409
en_zh Dev loss: 0.7268 r:0.4512
ro_en Dev loss: 0.3703 r:0.8152
et_en Dev loss: 0.4005 r:0.7100
si_en Dev loss: 0.7193 r:0.6112
ne_en Dev loss: 0.4196 r:0.7560
ru_en Dev loss: 0.4816 r:0.7278
Current avg r:0.6161 Best avg r: 0.6240
18:19:29,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:55,593 root INFO 
id:en_zh cur r: 0.4577 best r: 0.4577
18:20:08,448 root INFO 
id:ro_en cur r: 0.8272 best r: 0.8272
18:20:34,189 root INFO 
id:si_en cur r: 0.6261 best r: 0.6261
18:20:47,61 root INFO 
id:ne_en cur r: 0.7673 best r: 0.7673
18:20:59,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:29,739 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
18:22:29,750 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:22:29,754 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:22:29,758 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
18:22:29,763 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
18:22:29,768 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:22:29,773 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:22:42,613 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4651
en_de Dev loss: 0.8476 r:0.2492
en_zh Dev loss: 0.7273 r:0.4535
ro_en Dev loss: 0.3131 r:0.8251
et_en Dev loss: 0.3641 r:0.7211
si_en Dev loss: 0.6005 r:0.6307
ne_en Dev loss: 0.3797 r:0.7673
ru_en Dev loss: 0.4048 r:0.7547
Current avg r:0.6288 Best avg r: 0.6288
18:27:11,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:36,630 root INFO 
id:en_zh cur r: 0.4816 best r: 0.4816
18:27:49,457 root INFO 
id:ro_en cur r: 0.8274 best r: 0.8274
18:28:02,297 root INFO 
id:et_en cur r: 0.7241 best r: 0.7241
18:28:28,1 root INFO 
id:ne_en cur r: 0.7755 best r: 0.7755
18:28:40,798 root INFO 
id:ru_en cur r: 0.7644 best r: 0.7644
18:28:40,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:10,562 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_de.lang_agnost_mlp.dev.best.scores
18:30:10,569 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:30:10,573 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:30:10,579 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/et_en.lang_agnost_mlp.dev.best.scores
18:30:10,583 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/si_en.lang_agnost_mlp.dev.best.scores
18:30:10,589 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:30:10,594 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ende/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:30:23,440 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4749
en_de Dev loss: 0.8286 r:0.2650
en_zh Dev loss: 0.6819 r:0.4758
ro_en Dev loss: 0.3316 r:0.8245
et_en Dev loss: 0.3578 r:0.7252
si_en Dev loss: 0.6807 r:0.6236
ne_en Dev loss: 0.3741 r:0.7750
ru_en Dev loss: 0.3888 r:0.7658
Current avg r:0.6364 Best avg r: 0.6364
18:34:53,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:23,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:53,699 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4292
en_de Dev loss: 0.8674 r:0.2475
en_zh Dev loss: 0.7737 r:0.4511
ro_en Dev loss: 0.4023 r:0.8137
et_en Dev loss: 0.3883 r:0.7173
si_en Dev loss: 0.7672 r:0.6148
ne_en Dev loss: 0.5481 r:0.7612
ru_en Dev loss: 0.4988 r:0.7290
Current avg r:0.6192 Best avg r: 0.6364
18:42:22,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:48,513 root INFO 
id:en_de cur r: 0.2745 best r: 0.2745
18:44:05,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:35,273 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4587
en_de Dev loss: 0.8281 r:0.2589
en_zh Dev loss: 0.6812 r:0.4577
ro_en Dev loss: 0.3211 r:0.8137
et_en Dev loss: 0.3777 r:0.7123
si_en Dev loss: 0.6889 r:0.6093
ne_en Dev loss: 0.4296 r:0.7605
ru_en Dev loss: 0.4350 r:0.7208
Current avg r:0.6190 Best avg r: 0.6364
18:50:03,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:33,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:03,611 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4268
en_de Dev loss: 0.8484 r:0.2484
en_zh Dev loss: 0.7192 r:0.4584
ro_en Dev loss: 0.3366 r:0.8219
et_en Dev loss: 0.3751 r:0.7186
si_en Dev loss: 0.6731 r:0.6124
ne_en Dev loss: 0.4412 r:0.7634
ru_en Dev loss: 0.4533 r:0.7338
Current avg r:0.6224 Best avg r: 0.6364
18:57:32,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:58,412 root INFO 
id:en_de cur r: 0.2908 best r: 0.2908
18:59:15,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:45,371 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4276
en_de Dev loss: 0.8517 r:0.2707
en_zh Dev loss: 0.7485 r:0.4546
ro_en Dev loss: 0.3380 r:0.8180
et_en Dev loss: 0.3735 r:0.7117
si_en Dev loss: 0.7539 r:0.6053
ne_en Dev loss: 0.5696 r:0.7543
ru_en Dev loss: 0.4872 r:0.7160
Current avg r:0.6187 Best avg r: 0.6364
19:05:14,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:44,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:14,359 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4115
en_de Dev loss: 0.8374 r:0.2475
en_zh Dev loss: 0.7018 r:0.4642
ro_en Dev loss: 0.3343 r:0.8205
et_en Dev loss: 0.3862 r:0.7136
si_en Dev loss: 0.7264 r:0.6076
ne_en Dev loss: 0.4990 r:0.7594
ru_en Dev loss: 0.4261 r:0.7436
Current avg r:0.6223 Best avg r: 0.6364
19:12:43,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:13,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:43,422 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4060
en_de Dev loss: 0.8693 r:0.2480
en_zh Dev loss: 0.7854 r:0.4475
ro_en Dev loss: 0.3942 r:0.8201
et_en Dev loss: 0.4035 r:0.7111
si_en Dev loss: 0.7215 r:0.6073
ne_en Dev loss: 0.4607 r:0.7575
ru_en Dev loss: 0.4763 r:0.7278
Current avg r:0.6170 Best avg r: 0.6364
19:20:12,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:38,393 root INFO 
id:en_de cur r: 0.3006 best r: 0.3006
19:21:55,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:25,125 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4322
en_de Dev loss: 0.8528 r:0.2595
en_zh Dev loss: 0.7760 r:0.4388
ro_en Dev loss: 0.3454 r:0.8194
et_en Dev loss: 0.3872 r:0.7118
si_en Dev loss: 0.7695 r:0.6031
ne_en Dev loss: 0.5575 r:0.7483
ru_en Dev loss: 0.5105 r:0.7192
Current avg r:0.6143 Best avg r: 0.6364
19:27:54,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:24,201 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:54,57 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4193
en_de Dev loss: 0.8636 r:0.2357
en_zh Dev loss: 0.7697 r:0.4351
ro_en Dev loss: 0.3160 r:0.8192
et_en Dev loss: 0.3628 r:0.7110
si_en Dev loss: 0.7000 r:0.6050
ne_en Dev loss: 0.4184 r:0.7630
ru_en Dev loss: 0.4836 r:0.7164
Current avg r:0.6122 Best avg r: 0.6364
19:35:23,398 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:53,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:23,247 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4253
en_de Dev loss: 0.8555 r:0.2635
en_zh Dev loss: 0.7794 r:0.4469
ro_en Dev loss: 0.3654 r:0.8215
et_en Dev loss: 0.3905 r:0.7086
si_en Dev loss: 0.7681 r:0.6037
ne_en Dev loss: 0.3972 r:0.7670
ru_en Dev loss: 0.5249 r:0.7156
Current avg r:0.6181 Best avg r: 0.6364
19:42:52,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:18,335 root INFO 
id:en_zh cur r: 0.4816 best r: 0.4816
19:44:22,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:52,494 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4351
en_de Dev loss: 0.8694 r:0.2788
en_zh Dev loss: 0.7685 r:0.4728
ro_en Dev loss: 0.3785 r:0.8243
et_en Dev loss: 0.3837 r:0.7097
si_en Dev loss: 0.7788 r:0.6058
ne_en Dev loss: 0.4634 r:0.7662
ru_en Dev loss: 0.5397 r:0.7207
Current avg r:0.6255 Best avg r: 0.6364
19:50:21,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:51,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:21,700 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4115
en_de Dev loss: 0.8750 r:0.2533
en_zh Dev loss: 0.7672 r:0.4609
ro_en Dev loss: 0.3443 r:0.8224
et_en Dev loss: 0.3756 r:0.7071
si_en Dev loss: 0.6631 r:0.6084
ne_en Dev loss: 0.4186 r:0.7641
ru_en Dev loss: 0.4597 r:0.7347
Current avg r:0.6216 Best avg r: 0.6364
19:57:51,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:21,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:50,989 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3969
en_de Dev loss: 0.8630 r:0.2446
en_zh Dev loss: 0.7331 r:0.4681
ro_en Dev loss: 0.3512 r:0.8225
et_en Dev loss: 0.3872 r:0.7051
si_en Dev loss: 0.6875 r:0.6116
ne_en Dev loss: 0.4340 r:0.7604
ru_en Dev loss: 0.5004 r:0.7201
Current avg r:0.6189 Best avg r: 0.6364
20:05:20,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:50,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:20,358 root INFO Epoch 2 Global steps: 30100 Train loss: 0.4152
en_de Dev loss: 0.8697 r:0.2321
en_zh Dev loss: 0.6992 r:0.4719
ro_en Dev loss: 0.3372 r:0.8227
et_en Dev loss: 0.3730 r:0.7103
si_en Dev loss: 0.6528 r:0.6183
ne_en Dev loss: 0.3896 r:0.7600
ru_en Dev loss: 0.4489 r:0.7415
Current avg r:0.6224 Best avg r: 0.6364
20:12:49,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:19,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:49,637 root INFO Epoch 2 Global steps: 30800 Train loss: 0.4099
en_de Dev loss: 0.8580 r:0.2453
en_zh Dev loss: 0.7032 r:0.4712
ro_en Dev loss: 0.3483 r:0.8183
et_en Dev loss: 0.4126 r:0.7041
si_en Dev loss: 0.6359 r:0.6150
ne_en Dev loss: 0.4099 r:0.7575
ru_en Dev loss: 0.4792 r:0.7150
Current avg r:0.6180 Best avg r: 0.6364
20:20:19,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:49,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:18,958 root INFO Epoch 2 Global steps: 31500 Train loss: 0.4012
en_de Dev loss: 0.8823 r:0.2378
en_zh Dev loss: 0.7172 r:0.4776
ro_en Dev loss: 0.3593 r:0.8200
et_en Dev loss: 0.3924 r:0.7082
si_en Dev loss: 0.7060 r:0.6126
ne_en Dev loss: 0.4051 r:0.7619
ru_en Dev loss: 0.4396 r:0.7452
Current avg r:0.6233 Best avg r: 0.6364
20:27:49,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:19,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:49,697 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3772
en_de Dev loss: 0.8543 r:0.2415
en_zh Dev loss: 0.7129 r:0.4760
ro_en Dev loss: 0.3478 r:0.8228
et_en Dev loss: 0.4053 r:0.7014
si_en Dev loss: 0.7349 r:0.6033
ne_en Dev loss: 0.3997 r:0.7554
ru_en Dev loss: 0.4563 r:0.7376
Current avg r:0.6197 Best avg r: 0.6364
20:35:19,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:49,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:18,968 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3645
en_de Dev loss: 0.8635 r:0.2454
en_zh Dev loss: 0.7377 r:0.4822
ro_en Dev loss: 0.3751 r:0.8235
et_en Dev loss: 0.3988 r:0.7012
si_en Dev loss: 0.7941 r:0.6032
ne_en Dev loss: 0.4869 r:0.7554
ru_en Dev loss: 0.4638 r:0.7431
Current avg r:0.6220 Best avg r: 0.6364
20:42:48,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:18,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:48,319 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3651
en_de Dev loss: 0.8668 r:0.2294
en_zh Dev loss: 0.7088 r:0.4701
ro_en Dev loss: 0.3301 r:0.8278
et_en Dev loss: 0.3882 r:0.7042
si_en Dev loss: 0.6587 r:0.6120
ne_en Dev loss: 0.4620 r:0.7560
ru_en Dev loss: 0.4232 r:0.7506
Current avg r:0.6215 Best avg r: 0.6364
20:50:17,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:47,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:17,674 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3690
en_de Dev loss: 0.8967 r:0.2340
en_zh Dev loss: 0.7491 r:0.4773
ro_en Dev loss: 0.3739 r:0.8229
et_en Dev loss: 0.3975 r:0.6975
si_en Dev loss: 0.7092 r:0.6086
ne_en Dev loss: 0.4196 r:0.7609
ru_en Dev loss: 0.4933 r:0.7353
Current avg r:0.6195 Best avg r: 0.6364
20:57:47,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:17,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:47,105 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3567
en_de Dev loss: 0.8929 r:0.2138
en_zh Dev loss: 0.7228 r:0.4720
ro_en Dev loss: 0.3575 r:0.8238
et_en Dev loss: 0.3947 r:0.6983
si_en Dev loss: 0.7158 r:0.6110
ne_en Dev loss: 0.4490 r:0.7545
ru_en Dev loss: 0.5268 r:0.7247
Current avg r:0.6140 Best avg r: 0.6364
21:05:16,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:46,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:16,599 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3630
en_de Dev loss: 0.9149 r:0.1882
en_zh Dev loss: 0.7700 r:0.4405
ro_en Dev loss: 0.3537 r:0.8182
et_en Dev loss: 0.3973 r:0.6947
si_en Dev loss: 0.7071 r:0.6006
ne_en Dev loss: 0.4318 r:0.7549
ru_en Dev loss: 0.4720 r:0.7223
Current avg r:0.6027 Best avg r: 0.6364
21:12:46,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:16,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:46,68 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3589
en_de Dev loss: 0.8977 r:0.1985
en_zh Dev loss: 0.7893 r:0.4541
ro_en Dev loss: 0.4009 r:0.8231
et_en Dev loss: 0.4414 r:0.6903
si_en Dev loss: 0.8829 r:0.6017
ne_en Dev loss: 0.5209 r:0.7475
ru_en Dev loss: 0.5684 r:0.7165
Current avg r:0.6045 Best avg r: 0.6364
21:20:15,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:45,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:15,612 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3449
en_de Dev loss: 0.8793 r:0.2014
en_zh Dev loss: 0.7054 r:0.4718
ro_en Dev loss: 0.3319 r:0.8254
et_en Dev loss: 0.4024 r:0.6931
si_en Dev loss: 0.7026 r:0.6098
ne_en Dev loss: 0.4264 r:0.7545
ru_en Dev loss: 0.4703 r:0.7328
Current avg r:0.6127 Best avg r: 0.6364
21:27:45,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:29:15,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:30:45,172 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3567
en_de Dev loss: 0.8921 r:0.2184
en_zh Dev loss: 0.7525 r:0.4665
ro_en Dev loss: 0.3689 r:0.8250
et_en Dev loss: 0.4157 r:0.6968
si_en Dev loss: 0.7310 r:0.6085
ne_en Dev loss: 0.4409 r:0.7517
ru_en Dev loss: 0.4972 r:0.7331
Current avg r:0.6143 Best avg r: 0.6364
21:35:14,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:44,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:14,725 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3628
en_de Dev loss: 0.8838 r:0.2125
en_zh Dev loss: 0.7531 r:0.4706
ro_en Dev loss: 0.4017 r:0.8145
et_en Dev loss: 0.4292 r:0.6815
si_en Dev loss: 0.8348 r:0.5936
ne_en Dev loss: 0.5251 r:0.7529
ru_en Dev loss: 0.4935 r:0.7243
Current avg r:0.6071 Best avg r: 0.6364
21:42:44,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:14,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:44,217 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3624
en_de Dev loss: 0.8718 r:0.2281
en_zh Dev loss: 0.7632 r:0.4579
ro_en Dev loss: 0.3729 r:0.8227
et_en Dev loss: 0.4143 r:0.6930
si_en Dev loss: 0.8605 r:0.5982
ne_en Dev loss: 0.5248 r:0.7562
ru_en Dev loss: 0.4879 r:0.7237
Current avg r:0.6114 Best avg r: 0.6364
21:50:13,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:43,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:13,704 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3533
en_de Dev loss: 0.8772 r:0.2308
en_zh Dev loss: 0.7865 r:0.4456
ro_en Dev loss: 0.3400 r:0.8231
et_en Dev loss: 0.4147 r:0.6868
si_en Dev loss: 0.7247 r:0.6009
ne_en Dev loss: 0.4312 r:0.7547
ru_en Dev loss: 0.5102 r:0.7055
Current avg r:0.6068 Best avg r: 0.6364
21:57:43,454 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:13,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:43,300 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3406
en_de Dev loss: 0.8657 r:0.2297
en_zh Dev loss: 0.7889 r:0.4520
ro_en Dev loss: 0.3695 r:0.8224
et_en Dev loss: 0.4281 r:0.6898
si_en Dev loss: 0.8272 r:0.5987
ne_en Dev loss: 0.4926 r:0.7522
ru_en Dev loss: 0.4764 r:0.7264
Current avg r:0.6102 Best avg r: 0.6364
22:05:12,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:42,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:08:12,796 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3373
en_de Dev loss: 0.8740 r:0.2507
en_zh Dev loss: 0.7644 r:0.4684
ro_en Dev loss: 0.3805 r:0.8211
et_en Dev loss: 0.4424 r:0.6933
si_en Dev loss: 0.7016 r:0.6053
ne_en Dev loss: 0.4296 r:0.7512
ru_en Dev loss: 0.4455 r:0.7438
Current avg r:0.6191 Best avg r: 0.6364
22:12:42,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:12,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:42,209 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3461
en_de Dev loss: 0.8968 r:0.1968
en_zh Dev loss: 0.7806 r:0.4449
ro_en Dev loss: 0.3573 r:0.8230
et_en Dev loss: 0.4160 r:0.6944
si_en Dev loss: 0.7363 r:0.5983
ne_en Dev loss: 0.4053 r:0.7585
ru_en Dev loss: 0.4539 r:0.7370
Current avg r:0.6075 Best avg r: 0.6364
22:20:13,486 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:43,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:13,344 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3006
en_de Dev loss: 0.8908 r:0.2179
en_zh Dev loss: 0.7771 r:0.4499
ro_en Dev loss: 0.3693 r:0.8205
et_en Dev loss: 0.4271 r:0.6868
si_en Dev loss: 0.8081 r:0.5891
ne_en Dev loss: 0.5439 r:0.7542
ru_en Dev loss: 0.5002 r:0.7161
Current avg r:0.6049 Best avg r: 0.6364
22:27:43,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:13,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:42,944 root INFO Epoch 4 Global steps: 43400 Train loss: 0.3193
en_de Dev loss: 0.8816 r:0.2165
en_zh Dev loss: 0.7717 r:0.4616
ro_en Dev loss: 0.3607 r:0.8209
et_en Dev loss: 0.4401 r:0.6802
si_en Dev loss: 0.7678 r:0.5927
ne_en Dev loss: 0.4508 r:0.7530
ru_en Dev loss: 0.4791 r:0.7145
Current avg r:0.6056 Best avg r: 0.6364
22:35:12,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:42,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:12,392 root INFO Epoch 4 Global steps: 44100 Train loss: 0.3180
en_de Dev loss: 0.8728 r:0.2254
en_zh Dev loss: 0.7498 r:0.4547
ro_en Dev loss: 0.3495 r:0.8195
et_en Dev loss: 0.4194 r:0.6845
si_en Dev loss: 0.7156 r:0.5961
ne_en Dev loss: 0.4912 r:0.7534
ru_en Dev loss: 0.4647 r:0.7118
Current avg r:0.6065 Best avg r: 0.6364
22:42:42,101 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:12,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:41,935 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2991
en_de Dev loss: 0.9194 r:0.2293
en_zh Dev loss: 0.7930 r:0.4651
ro_en Dev loss: 0.3927 r:0.8206
et_en Dev loss: 0.4463 r:0.6880
si_en Dev loss: 0.8078 r:0.5990
ne_en Dev loss: 0.4228 r:0.7534
ru_en Dev loss: 0.5181 r:0.7221
Current avg r:0.6111 Best avg r: 0.6364
22:50:11,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:41,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:11,519 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2977
en_de Dev loss: 0.8958 r:0.2127
en_zh Dev loss: 0.7481 r:0.4663
ro_en Dev loss: 0.3649 r:0.8207
et_en Dev loss: 0.4315 r:0.6853
si_en Dev loss: 0.7787 r:0.5897
ne_en Dev loss: 0.4736 r:0.7487
ru_en Dev loss: 0.4561 r:0.7338
Current avg r:0.6082 Best avg r: 0.6364
22:57:41,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:11,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:40,957 root INFO Epoch 4 Global steps: 46200 Train loss: 0.3080
en_de Dev loss: 0.8796 r:0.2293
en_zh Dev loss: 0.7661 r:0.4594
ro_en Dev loss: 0.3799 r:0.8154
et_en Dev loss: 0.4922 r:0.6714
si_en Dev loss: 0.7786 r:0.5777
ne_en Dev loss: 0.4557 r:0.7414
ru_en Dev loss: 0.5471 r:0.6730
Current avg r:0.5954 Best avg r: 0.6364
23:05:10,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:40,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:10,264 root INFO Epoch 4 Global steps: 46900 Train loss: 0.3130
en_de Dev loss: 0.9032 r:0.2141
en_zh Dev loss: 0.7770 r:0.4536
ro_en Dev loss: 0.3518 r:0.8201
et_en Dev loss: 0.4300 r:0.6813
si_en Dev loss: 0.7543 r:0.5924
ne_en Dev loss: 0.4589 r:0.7465
ru_en Dev loss: 0.4679 r:0.7171
Current avg r:0.6036 Best avg r: 0.6364
23:12:39,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:09,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:39,291 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2985
en_de Dev loss: 0.9074 r:0.2121
en_zh Dev loss: 0.7913 r:0.4506
ro_en Dev loss: 0.3845 r:0.8110
et_en Dev loss: 0.4313 r:0.6697
si_en Dev loss: 0.8744 r:0.5783
ne_en Dev loss: 0.5413 r:0.7448
ru_en Dev loss: 0.5840 r:0.6783
Current avg r:0.5921 Best avg r: 0.6364
23:20:08,519 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:38,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:08,180 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2972
en_de Dev loss: 0.9252 r:0.2003
en_zh Dev loss: 0.7833 r:0.4702
ro_en Dev loss: 0.3947 r:0.8147
et_en Dev loss: 0.4576 r:0.6801
si_en Dev loss: 0.8313 r:0.5823
ne_en Dev loss: 0.4609 r:0.7475
ru_en Dev loss: 0.5198 r:0.7168
Current avg r:0.6017 Best avg r: 0.6364
23:27:37,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:07,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:37,110 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2888
en_de Dev loss: 0.8901 r:0.2073
en_zh Dev loss: 0.7813 r:0.4687
ro_en Dev loss: 0.4011 r:0.8169
et_en Dev loss: 0.4654 r:0.6773
si_en Dev loss: 0.8111 r:0.5860
ne_en Dev loss: 0.5109 r:0.7457
ru_en Dev loss: 0.4910 r:0.7208
Current avg r:0.6032 Best avg r: 0.6364
23:35:06,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:36,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:05,993 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2939
en_de Dev loss: 0.9059 r:0.1972
en_zh Dev loss: 0.8370 r:0.4538
ro_en Dev loss: 0.4120 r:0.8221
et_en Dev loss: 0.4609 r:0.6795
si_en Dev loss: 0.9560 r:0.5772
ne_en Dev loss: 0.5789 r:0.7412
ru_en Dev loss: 0.5306 r:0.7152
Current avg r:0.5980 Best avg r: 0.6364
23:42:35,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:05,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:34,926 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2937
en_de Dev loss: 0.8864 r:0.1936
en_zh Dev loss: 0.7469 r:0.4720
ro_en Dev loss: 0.3418 r:0.8254
et_en Dev loss: 0.4537 r:0.6859
si_en Dev loss: 0.7201 r:0.5963
ne_en Dev loss: 0.4300 r:0.7458
ru_en Dev loss: 0.4302 r:0.7344
Current avg r:0.6076 Best avg r: 0.6364
23:50:04,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:33,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:03,819 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2841
en_de Dev loss: 0.8987 r:0.2003
en_zh Dev loss: 0.8255 r:0.4564
ro_en Dev loss: 0.3857 r:0.8212
et_en Dev loss: 0.4599 r:0.6778
si_en Dev loss: 0.8658 r:0.5845
ne_en Dev loss: 0.6819 r:0.7376
ru_en Dev loss: 0.5132 r:0.7134
Current avg r:0.5988 Best avg r: 0.6364
23:57:33,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:02,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:32,755 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2863
en_de Dev loss: 0.9338 r:0.1872
en_zh Dev loss: 0.8558 r:0.4413
ro_en Dev loss: 0.3968 r:0.8224
et_en Dev loss: 0.4823 r:0.6830
si_en Dev loss: 0.7726 r:0.5945
ne_en Dev loss: 0.5247 r:0.7423
ru_en Dev loss: 0.4831 r:0.7273
Current avg r:0.5997 Best avg r: 0.6364
00:05:01,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:06:31,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:01,684 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2825
en_de Dev loss: 0.9076 r:0.2026
en_zh Dev loss: 0.7603 r:0.4710
ro_en Dev loss: 0.3487 r:0.8221
et_en Dev loss: 0.4527 r:0.6876
si_en Dev loss: 0.7000 r:0.5989
ne_en Dev loss: 0.4605 r:0.7462
ru_en Dev loss: 0.4237 r:0.7432
Current avg r:0.6102 Best avg r: 0.6364
00:12:32,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:01,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:31,781 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2660
en_de Dev loss: 0.9202 r:0.1987
en_zh Dev loss: 0.8136 r:0.4560
ro_en Dev loss: 0.3522 r:0.8231
et_en Dev loss: 0.4702 r:0.6817
si_en Dev loss: 0.7236 r:0.5897
ne_en Dev loss: 0.4531 r:0.7419
ru_en Dev loss: 0.4548 r:0.7323
Current avg r:0.6033 Best avg r: 0.6364
00:20:00,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:21:30,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:00,433 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2554
en_de Dev loss: 0.9312 r:0.1786
en_zh Dev loss: 0.8546 r:0.4216
ro_en Dev loss: 0.3683 r:0.8179
et_en Dev loss: 0.4858 r:0.6717
si_en Dev loss: 0.7312 r:0.5878
ne_en Dev loss: 0.4704 r:0.7409
ru_en Dev loss: 0.4967 r:0.7120
Current avg r:0.5901 Best avg r: 0.6364
00:27:29,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:59,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:29,470 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2713
en_de Dev loss: 0.9512 r:0.1813
en_zh Dev loss: 0.9635 r:0.4227
ro_en Dev loss: 0.4669 r:0.8135
et_en Dev loss: 0.5060 r:0.6622
si_en Dev loss: 0.8974 r:0.5788
ne_en Dev loss: 0.6172 r:0.7420
ru_en Dev loss: 0.5690 r:0.7099
Current avg r:0.5872 Best avg r: 0.6364
00:34:58,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:28,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:58,560 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2583
en_de Dev loss: 0.8907 r:0.1910
en_zh Dev loss: 0.8096 r:0.4299
ro_en Dev loss: 0.3433 r:0.8182
et_en Dev loss: 0.4544 r:0.6672
si_en Dev loss: 0.8008 r:0.5812
ne_en Dev loss: 0.5088 r:0.7484
ru_en Dev loss: 0.4911 r:0.7099
Current avg r:0.5923 Best avg r: 0.6364
00:42:27,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:57,753 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:27,624 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2638
en_de Dev loss: 0.8964 r:0.2057
en_zh Dev loss: 0.8248 r:0.4395
ro_en Dev loss: 0.3834 r:0.8177
et_en Dev loss: 0.4947 r:0.6669
si_en Dev loss: 0.8687 r:0.5759
ne_en Dev loss: 0.5187 r:0.7436
ru_en Dev loss: 0.4580 r:0.7341
Current avg r:0.5976 Best avg r: 0.6364
00:49:56,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:26,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:56,655 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2600
en_de Dev loss: 0.9012 r:0.2045
en_zh Dev loss: 0.8035 r:0.4374
ro_en Dev loss: 0.3658 r:0.8194
et_en Dev loss: 0.4723 r:0.6710
si_en Dev loss: 0.8005 r:0.5848
ne_en Dev loss: 0.4810 r:0.7394
ru_en Dev loss: 0.4570 r:0.7308
Current avg r:0.5982 Best avg r: 0.6364
00:57:25,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:55,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:00:25,376 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2514
en_de Dev loss: 0.9122 r:0.2048
en_zh Dev loss: 0.8326 r:0.4495
ro_en Dev loss: 0.4110 r:0.8133
et_en Dev loss: 0.4933 r:0.6685
si_en Dev loss: 0.8354 r:0.5804
ne_en Dev loss: 0.5537 r:0.7345
ru_en Dev loss: 0.5619 r:0.7005
Current avg r:0.5931 Best avg r: 0.6364
01:04:54,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:24,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:54,68 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2577
en_de Dev loss: 0.9116 r:0.1910
en_zh Dev loss: 0.7637 r:0.4696
ro_en Dev loss: 0.3664 r:0.8209
et_en Dev loss: 0.4547 r:0.6768
si_en Dev loss: 0.7525 r:0.5860
ne_en Dev loss: 0.4716 r:0.7349
ru_en Dev loss: 0.4666 r:0.7378
Current avg r:0.6024 Best avg r: 0.6364
01:12:23,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:52,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:22,703 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2503
en_de Dev loss: 0.9305 r:0.1956
en_zh Dev loss: 0.8638 r:0.4538
ro_en Dev loss: 0.4404 r:0.8083
et_en Dev loss: 0.5192 r:0.6578
si_en Dev loss: 0.9494 r:0.5598
ne_en Dev loss: 0.5942 r:0.7265
ru_en Dev loss: 0.5824 r:0.6942
Current avg r:0.5851 Best avg r: 0.6364
01:19:51,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:21,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:22:51,478 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2445
en_de Dev loss: 0.9023 r:0.2060
en_zh Dev loss: 0.7907 r:0.4669
ro_en Dev loss: 0.3744 r:0.8163
et_en Dev loss: 0.4801 r:0.6725
si_en Dev loss: 0.8056 r:0.5745
ne_en Dev loss: 0.5516 r:0.7290
ru_en Dev loss: 0.4954 r:0.7177
Current avg r:0.5976 Best avg r: 0.6364
01:27:20,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:50,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:20,103 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2495
en_de Dev loss: 0.8817 r:0.2279
en_zh Dev loss: 0.7405 r:0.4737
ro_en Dev loss: 0.3433 r:0.8181
et_en Dev loss: 0.4445 r:0.6757
si_en Dev loss: 0.7969 r:0.5696
ne_en Dev loss: 0.5265 r:0.7351
ru_en Dev loss: 0.4522 r:0.7302
Current avg r:0.6043 Best avg r: 0.6364
01:34:49,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:36:19,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:48,831 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2612
en_de Dev loss: 0.9013 r:0.2154
en_zh Dev loss: 0.7993 r:0.4607
ro_en Dev loss: 0.4168 r:0.8173
et_en Dev loss: 0.4785 r:0.6715
si_en Dev loss: 0.9524 r:0.5682
ne_en Dev loss: 0.6308 r:0.7277
ru_en Dev loss: 0.5219 r:0.7281
Current avg r:0.5984 Best avg r: 0.6364
01:42:17,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:47,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:17,301 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2484
en_de Dev loss: 0.9263 r:0.2059
en_zh Dev loss: 0.8240 r:0.4628
ro_en Dev loss: 0.4106 r:0.8197
et_en Dev loss: 0.4585 r:0.6708
si_en Dev loss: 0.9563 r:0.5672
ne_en Dev loss: 0.6098 r:0.7353
ru_en Dev loss: 0.5460 r:0.7220
Current avg r:0.5977 Best avg r: 0.6364
01:49:45,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:15,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:44,914 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2361
en_de Dev loss: 0.9122 r:0.2059
en_zh Dev loss: 0.7830 r:0.4688
ro_en Dev loss: 0.3744 r:0.8197
et_en Dev loss: 0.5038 r:0.6733
si_en Dev loss: 0.8458 r:0.5704
ne_en Dev loss: 0.5234 r:0.7320
ru_en Dev loss: 0.4549 r:0.7351
Current avg r:0.6007 Best avg r: 0.6364
01:57:15,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:58:46,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:17,639 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2400
en_de Dev loss: 0.9410 r:0.2079
en_zh Dev loss: 0.8372 r:0.4497
ro_en Dev loss: 0.3961 r:0.8166
et_en Dev loss: 0.5148 r:0.6546
si_en Dev loss: 0.9101 r:0.5594
ne_en Dev loss: 0.5839 r:0.7275
ru_en Dev loss: 0.5490 r:0.6967
Current avg r:0.5875 Best avg r: 0.6364
02:04:52,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:23,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:53,792 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2171
en_de Dev loss: 0.9218 r:0.1962
en_zh Dev loss: 0.8312 r:0.4395
ro_en Dev loss: 0.3912 r:0.8179
et_en Dev loss: 0.4884 r:0.6655
si_en Dev loss: 0.8637 r:0.5626
ne_en Dev loss: 0.5391 r:0.7339
ru_en Dev loss: 0.4937 r:0.7179
Current avg r:0.5905 Best avg r: 0.6364
02:12:26,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:57,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:15:28,12 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2134
en_de Dev loss: 0.9191 r:0.2026
en_zh Dev loss: 0.8408 r:0.4399
ro_en Dev loss: 0.3594 r:0.8240
et_en Dev loss: 0.5001 r:0.6597
si_en Dev loss: 0.9122 r:0.5543
ne_en Dev loss: 0.5286 r:0.7234
ru_en Dev loss: 0.5434 r:0.6978
Current avg r:0.5859 Best avg r: 0.6364
02:20:00,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:31,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:23:02,130 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2079
en_de Dev loss: 0.9077 r:0.2144
en_zh Dev loss: 0.8438 r:0.4335
ro_en Dev loss: 0.3735 r:0.8171
et_en Dev loss: 0.4497 r:0.6693
si_en Dev loss: 0.8676 r:0.5607
ne_en Dev loss: 0.5719 r:0.7319
ru_en Dev loss: 0.5061 r:0.7075
Current avg r:0.5906 Best avg r: 0.6364
02:27:32,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:02,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:30:32,505 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2226
en_de Dev loss: 0.9408 r:0.2056
en_zh Dev loss: 0.8982 r:0.4304
ro_en Dev loss: 0.3958 r:0.8233
et_en Dev loss: 0.4832 r:0.6717
si_en Dev loss: 0.9474 r:0.5606
ne_en Dev loss: 0.6262 r:0.7306
ru_en Dev loss: 0.5262 r:0.7219
Current avg r:0.5920 Best avg r: 0.6364
02:35:02,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:32,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:02,229 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2224
en_de Dev loss: 0.9040 r:0.2164
en_zh Dev loss: 0.8081 r:0.4449
ro_en Dev loss: 0.3581 r:0.8199
et_en Dev loss: 0.4709 r:0.6682
si_en Dev loss: 0.8043 r:0.5651
ne_en Dev loss: 0.4860 r:0.7314
ru_en Dev loss: 0.4800 r:0.7112
Current avg r:0.5939 Best avg r: 0.6364
02:42:31,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:44:01,586 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:31,416 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2185
en_de Dev loss: 0.9321 r:0.2066
en_zh Dev loss: 0.8823 r:0.4442
ro_en Dev loss: 0.4091 r:0.8186
et_en Dev loss: 0.5244 r:0.6547
si_en Dev loss: 0.9662 r:0.5565
ne_en Dev loss: 0.6522 r:0.7280
ru_en Dev loss: 0.5474 r:0.7025
Current avg r:0.5873 Best avg r: 0.6364
02:50:01,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:30,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:00,764 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2075
en_de Dev loss: 0.9068 r:0.2233
en_zh Dev loss: 0.8056 r:0.4580
ro_en Dev loss: 0.3685 r:0.8197
et_en Dev loss: 0.5137 r:0.6589
si_en Dev loss: 0.8933 r:0.5569
ne_en Dev loss: 0.5678 r:0.7325
ru_en Dev loss: 0.5113 r:0.7139
Current avg r:0.5947 Best avg r: 0.6364
02:57:29,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:58:59,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:29,505 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2111
en_de Dev loss: 0.9300 r:0.2287
en_zh Dev loss: 0.7874 r:0.4604
ro_en Dev loss: 0.3567 r:0.8215
et_en Dev loss: 0.4627 r:0.6664
si_en Dev loss: 0.8372 r:0.5634
ne_en Dev loss: 0.4768 r:0.7301
ru_en Dev loss: 0.5025 r:0.7200
Current avg r:0.5986 Best avg r: 0.6364
03:04:59,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:06:29,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:07:59,122 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2225
en_de Dev loss: 0.9718 r:0.2183
en_zh Dev loss: 0.9054 r:0.4330
ro_en Dev loss: 0.4203 r:0.8150
et_en Dev loss: 0.5048 r:0.6541
si_en Dev loss: 0.9603 r:0.5527
ne_en Dev loss: 0.6496 r:0.7128
ru_en Dev loss: 0.6484 r:0.6781
Current avg r:0.5806 Best avg r: 0.6364
03:12:28,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:12:54,505 root INFO 
id:en_zh cur r: 0.4883 best r: 0.4883
03:13:58,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:15:28,705 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2200
en_de Dev loss: 0.9240 r:0.2287
en_zh Dev loss: 0.7775 r:0.4828
ro_en Dev loss: 0.3629 r:0.8262
et_en Dev loss: 0.4882 r:0.6693
si_en Dev loss: 0.8780 r:0.5690
ne_en Dev loss: 0.5145 r:0.7189
ru_en Dev loss: 0.4688 r:0.7472
Current avg r:0.6060 Best avg r: 0.6364
03:19:58,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:28,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:58,276 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2102
en_de Dev loss: 0.8901 r:0.2248
en_zh Dev loss: 0.7891 r:0.4623
ro_en Dev loss: 0.3506 r:0.8220
et_en Dev loss: 0.4838 r:0.6563
si_en Dev loss: 0.8515 r:0.5669
ne_en Dev loss: 0.5271 r:0.7174
ru_en Dev loss: 0.4647 r:0.7249
Current avg r:0.5964 Best avg r: 0.6364
03:27:27,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:57,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:27,832 root INFO Epoch 6 Global steps: 71400 Train loss: 0.2155
en_de Dev loss: 0.9261 r:0.2239
en_zh Dev loss: 0.8216 r:0.4547
ro_en Dev loss: 0.3759 r:0.8182
et_en Dev loss: 0.5268 r:0.6499
si_en Dev loss: 0.9101 r:0.5559
ne_en Dev loss: 0.5793 r:0.7169
ru_en Dev loss: 0.5314 r:0.7119
Current avg r:0.5902 Best avg r: 0.6364
03:34:57,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:27,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:37:57,514 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2043
en_de Dev loss: 0.9401 r:0.2158
en_zh Dev loss: 0.8051 r:0.4661
ro_en Dev loss: 0.3694 r:0.8219
et_en Dev loss: 0.4885 r:0.6547
si_en Dev loss: 0.8976 r:0.5613
ne_en Dev loss: 0.5857 r:0.7183
ru_en Dev loss: 0.5412 r:0.7191
Current avg r:0.5939 Best avg r: 0.6364
03:42:27,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:57,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:26,971 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2102
en_de Dev loss: 0.8980 r:0.2292
en_zh Dev loss: 0.7800 r:0.4613
ro_en Dev loss: 0.3617 r:0.8182
et_en Dev loss: 0.5025 r:0.6548
si_en Dev loss: 0.8702 r:0.5613
ne_en Dev loss: 0.5411 r:0.7238
ru_en Dev loss: 0.4901 r:0.7254
Current avg r:0.5963 Best avg r: 0.6364
03:49:56,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:26,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:56,649 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2107
en_de Dev loss: 0.9040 r:0.2268
en_zh Dev loss: 0.7652 r:0.4624
ro_en Dev loss: 0.3221 r:0.8233
et_en Dev loss: 0.4884 r:0.6593
si_en Dev loss: 0.7895 r:0.5595
ne_en Dev loss: 0.4917 r:0.7181
ru_en Dev loss: 0.4385 r:0.7388
Current avg r:0.5983 Best avg r: 0.6364
03:57:27,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:58:57,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:27,903 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1889
en_de Dev loss: 0.9200 r:0.2214
en_zh Dev loss: 0.8114 r:0.4617
ro_en Dev loss: 0.3468 r:0.8230
et_en Dev loss: 0.5231 r:0.6589
si_en Dev loss: 0.7998 r:0.5588
ne_en Dev loss: 0.4896 r:0.7191
ru_en Dev loss: 0.4405 r:0.7416
Current avg r:0.5978 Best avg r: 0.6364
04:04:57,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:06:27,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:07:57,565 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1815
en_de Dev loss: 0.9168 r:0.2096
en_zh Dev loss: 0.7809 r:0.4653
ro_en Dev loss: 0.3703 r:0.8228
et_en Dev loss: 0.5050 r:0.6543
si_en Dev loss: 0.9289 r:0.5511
ne_en Dev loss: 0.5817 r:0.7147
ru_en Dev loss: 0.4713 r:0.7391
Current avg r:0.5938 Best avg r: 0.6364
04:12:27,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:13:05,788 root INFO 
id:ro_en cur r: 0.8280 best r: 0.8280
04:13:57,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:27,144 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1849
en_de Dev loss: 0.9512 r:0.2068
en_zh Dev loss: 0.8875 r:0.4579
ro_en Dev loss: 0.3948 r:0.8233
et_en Dev loss: 0.5449 r:0.6518
si_en Dev loss: 0.9725 r:0.5465
ne_en Dev loss: 0.5809 r:0.7198
ru_en Dev loss: 0.5157 r:0.7327
Current avg r:0.5912 Best avg r: 0.6364
04:19:56,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:26,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:22:56,516 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1877
en_de Dev loss: 0.9205 r:0.2124
en_zh Dev loss: 0.8175 r:0.4454
ro_en Dev loss: 0.3614 r:0.8213
et_en Dev loss: 0.5239 r:0.6498
si_en Dev loss: 0.8680 r:0.5468
ne_en Dev loss: 0.5366 r:0.7170
ru_en Dev loss: 0.4908 r:0.7186
Current avg r:0.5873 Best avg r: 0.6364
04:27:25,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:28:55,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:25,135 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1796
en_de Dev loss: 0.9327 r:0.2157
en_zh Dev loss: 0.8169 r:0.4597
ro_en Dev loss: 0.3710 r:0.8198
et_en Dev loss: 0.4886 r:0.6542
si_en Dev loss: 0.9087 r:0.5503
ne_en Dev loss: 0.5331 r:0.7156
ru_en Dev loss: 0.4860 r:0.7310
Current avg r:0.5923 Best avg r: 0.6364
04:34:57,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:27,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:58,593 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1857
en_de Dev loss: 0.9059 r:0.2234
en_zh Dev loss: 0.7966 r:0.4634
ro_en Dev loss: 0.3495 r:0.8205
et_en Dev loss: 0.5148 r:0.6519
si_en Dev loss: 0.8621 r:0.5567
ne_en Dev loss: 0.4822 r:0.7194
ru_en Dev loss: 0.4861 r:0.7192
Current avg r:0.5935 Best avg r: 0.6364
04:42:30,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:01,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:32,377 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1845
en_de Dev loss: 0.9017 r:0.2165
en_zh Dev loss: 0.8127 r:0.4723
ro_en Dev loss: 0.3577 r:0.8198
et_en Dev loss: 0.4996 r:0.6556
si_en Dev loss: 0.9828 r:0.5488
ne_en Dev loss: 0.5656 r:0.7145
ru_en Dev loss: 0.5061 r:0.7210
Current avg r:0.5926 Best avg r: 0.6364
04:50:04,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:51:35,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:06,227 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1796
en_de Dev loss: 0.9029 r:0.2137
en_zh Dev loss: 0.7824 r:0.4688
ro_en Dev loss: 0.3441 r:0.8182
et_en Dev loss: 0.5224 r:0.6528
si_en Dev loss: 0.8212 r:0.5487
ne_en Dev loss: 0.4849 r:0.7079
ru_en Dev loss: 0.4585 r:0.7264
Current avg r:0.5909 Best avg r: 0.6364
04:57:36,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:59:06,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:00:36,200 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1812
en_de Dev loss: 0.9253 r:0.2182
en_zh Dev loss: 0.8450 r:0.4551
ro_en Dev loss: 0.3987 r:0.8128
et_en Dev loss: 0.5171 r:0.6438
si_en Dev loss: 1.0206 r:0.5442
ne_en Dev loss: 0.6005 r:0.7186
ru_en Dev loss: 0.5126 r:0.7194
Current avg r:0.5874 Best avg r: 0.6364
05:05:05,915 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:35,911 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:05,861 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1784
en_de Dev loss: 0.9192 r:0.2224
en_zh Dev loss: 0.8368 r:0.4562
ro_en Dev loss: 0.3720 r:0.8214
et_en Dev loss: 0.4946 r:0.6513
si_en Dev loss: 0.9786 r:0.5445
ne_en Dev loss: 0.5365 r:0.7204
ru_en Dev loss: 0.4925 r:0.7296
Current avg r:0.5923 Best avg r: 0.6364
05:12:35,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:05,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:35,678 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1722
en_de Dev loss: 0.9515 r:0.2229
en_zh Dev loss: 0.8862 r:0.4580
ro_en Dev loss: 0.3999 r:0.8167
et_en Dev loss: 0.5293 r:0.6526
si_en Dev loss: 0.9367 r:0.5475
ne_en Dev loss: 0.5192 r:0.7257
ru_en Dev loss: 0.5169 r:0.7291
Current avg r:0.5932 Best avg r: 0.6364
05:20:05,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:21:35,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:05,402 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1819
en_de Dev loss: 0.8933 r:0.2238
en_zh Dev loss: 0.7626 r:0.4589
ro_en Dev loss: 0.3266 r:0.8204
et_en Dev loss: 0.4907 r:0.6485
si_en Dev loss: 0.8573 r:0.5473
ne_en Dev loss: 0.5143 r:0.7225
ru_en Dev loss: 0.4384 r:0.7310
Current avg r:0.5932 Best avg r: 0.6364
05:27:35,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:29:05,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:35,238 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1760
en_de Dev loss: 0.9044 r:0.2244
en_zh Dev loss: 0.7978 r:0.4616
ro_en Dev loss: 0.3446 r:0.8176
et_en Dev loss: 0.5088 r:0.6558
si_en Dev loss: 0.8698 r:0.5423
ne_en Dev loss: 0.4954 r:0.7169
ru_en Dev loss: 0.4607 r:0.7304
Current avg r:0.5927 Best avg r: 0.6364
05:35:05,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:35,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:04,889 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1789
en_de Dev loss: 0.9133 r:0.2373
en_zh Dev loss: 0.8319 r:0.4568
ro_en Dev loss: 0.3770 r:0.8183
et_en Dev loss: 0.5144 r:0.6508
si_en Dev loss: 0.8928 r:0.5475
ne_en Dev loss: 0.5680 r:0.7261
ru_en Dev loss: 0.4925 r:0.7232
Current avg r:0.5943 Best avg r: 0.6364
05:42:33,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:03,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:33,471 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1728
en_de Dev loss: 0.9119 r:0.2375
en_zh Dev loss: 0.8049 r:0.4794
ro_en Dev loss: 0.3816 r:0.8165
et_en Dev loss: 0.5223 r:0.6614
si_en Dev loss: 0.8880 r:0.5493
ne_en Dev loss: 0.5260 r:0.7223
ru_en Dev loss: 0.4679 r:0.7409
Current avg r:0.6010 Best avg r: 0.6364
05:50:04,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:33,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:03,709 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1475
en_de Dev loss: 0.9269 r:0.2462
en_zh Dev loss: 0.8681 r:0.4513
ro_en Dev loss: 0.4055 r:0.8143
et_en Dev loss: 0.5332 r:0.6437
si_en Dev loss: 1.0081 r:0.5353
ne_en Dev loss: 0.6045 r:0.7203
ru_en Dev loss: 0.5230 r:0.7182
Current avg r:0.5899 Best avg r: 0.6364
05:57:32,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:02,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:00:32,315 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1569
en_de Dev loss: 0.9287 r:0.2379
en_zh Dev loss: 0.8282 r:0.4599
ro_en Dev loss: 0.3788 r:0.8164
et_en Dev loss: 0.5111 r:0.6558
si_en Dev loss: 0.8988 r:0.5490
ne_en Dev loss: 0.5648 r:0.7207
ru_en Dev loss: 0.5082 r:0.7209
Current avg r:0.5944 Best avg r: 0.6364
06:05:01,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:06:31,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:00,972 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1608
en_de Dev loss: 0.9311 r:0.2205
en_zh Dev loss: 0.8394 r:0.4557
ro_en Dev loss: 0.3812 r:0.8164
et_en Dev loss: 0.4921 r:0.6597
si_en Dev loss: 0.9188 r:0.5495
ne_en Dev loss: 0.6040 r:0.7116
ru_en Dev loss: 0.5143 r:0.7236
Current avg r:0.5910 Best avg r: 0.6364
06:12:29,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:13:59,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:29,583 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1574
en_de Dev loss: 0.9333 r:0.2281
en_zh Dev loss: 0.8442 r:0.4601
ro_en Dev loss: 0.3850 r:0.8155
et_en Dev loss: 0.5203 r:0.6500
si_en Dev loss: 0.9318 r:0.5448
ne_en Dev loss: 0.5684 r:0.7200
ru_en Dev loss: 0.5072 r:0.7263
Current avg r:0.5921 Best avg r: 0.6364
06:19:58,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:21:28,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:22:58,216 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1556
en_de Dev loss: 0.8926 r:0.2190
en_zh Dev loss: 0.7747 r:0.4707
ro_en Dev loss: 0.3440 r:0.8204
et_en Dev loss: 0.4956 r:0.6574
si_en Dev loss: 0.8831 r:0.5472
ne_en Dev loss: 0.5326 r:0.7203
ru_en Dev loss: 0.4723 r:0.7282
Current avg r:0.5948 Best avg r: 0.6364
06:27:27,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:28:56,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:26,813 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1610
en_de Dev loss: 0.8865 r:0.2111
en_zh Dev loss: 0.7640 r:0.4749
ro_en Dev loss: 0.3464 r:0.8215
et_en Dev loss: 0.5032 r:0.6593
si_en Dev loss: 0.8687 r:0.5553
ne_en Dev loss: 0.5200 r:0.7235
ru_en Dev loss: 0.4743 r:0.7249
Current avg r:0.5958 Best avg r: 0.6364
06:34:55,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:25,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:55,423 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1586
en_de Dev loss: 0.9284 r:0.2101
en_zh Dev loss: 0.8116 r:0.4646
ro_en Dev loss: 0.3599 r:0.8209
et_en Dev loss: 0.5073 r:0.6645
si_en Dev loss: 0.8251 r:0.5562
ne_en Dev loss: 0.5327 r:0.7191
ru_en Dev loss: 0.5124 r:0.7188
Current avg r:0.5935 Best avg r: 0.6364
06:42:24,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:43:54,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:24,25 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1618
en_de Dev loss: 0.9190 r:0.2184
en_zh Dev loss: 0.8202 r:0.4631
ro_en Dev loss: 0.3553 r:0.8195
et_en Dev loss: 0.5177 r:0.6545
si_en Dev loss: 0.8680 r:0.5535
ne_en Dev loss: 0.5945 r:0.7139
ru_en Dev loss: 0.4819 r:0.7279
Current avg r:0.5930 Best avg r: 0.6364
06:49:52,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:22,680 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:52:52,490 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1600
en_de Dev loss: 0.9441 r:0.2197
en_zh Dev loss: 0.8178 r:0.4636
ro_en Dev loss: 0.3488 r:0.8193
et_en Dev loss: 0.5064 r:0.6559
si_en Dev loss: 0.7944 r:0.5511
ne_en Dev loss: 0.4915 r:0.7164
ru_en Dev loss: 0.4989 r:0.7225
Current avg r:0.5926 Best avg r: 0.6364
06:57:21,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:58:51,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:00:21,44 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1595
en_de Dev loss: 0.9098 r:0.2239
en_zh Dev loss: 0.7750 r:0.4566
ro_en Dev loss: 0.3479 r:0.8203
et_en Dev loss: 0.5076 r:0.6548
si_en Dev loss: 0.8276 r:0.5494
ne_en Dev loss: 0.5385 r:0.7169
ru_en Dev loss: 0.4509 r:0.7336
Current avg r:0.5936 Best avg r: 0.6364
07:04:50,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:06:19,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:07:49,647 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1475
en_de Dev loss: 0.9510 r:0.2268
en_zh Dev loss: 0.8430 r:0.4564
ro_en Dev loss: 0.4008 r:0.8155
et_en Dev loss: 0.5473 r:0.6470
si_en Dev loss: 0.9417 r:0.5459
ne_en Dev loss: 0.5864 r:0.7191
ru_en Dev loss: 0.5035 r:0.7263
Current avg r:0.5910 Best avg r: 0.6364
07:12:18,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:48,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:18,224 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1547
en_de Dev loss: 0.9409 r:0.2196
en_zh Dev loss: 0.8434 r:0.4461
ro_en Dev loss: 0.3369 r:0.8213
et_en Dev loss: 0.5059 r:0.6597
si_en Dev loss: 0.8336 r:0.5517
ne_en Dev loss: 0.4879 r:0.7217
ru_en Dev loss: 0.4494 r:0.7348
Current avg r:0.5936 Best avg r: 0.6364
07:19:47,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:21:16,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:22:46,791 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1562
en_de Dev loss: 0.9124 r:0.2082
en_zh Dev loss: 0.8202 r:0.4467
ro_en Dev loss: 0.3386 r:0.8187
et_en Dev loss: 0.4822 r:0.6518
si_en Dev loss: 0.9045 r:0.5477
ne_en Dev loss: 0.5812 r:0.7195
ru_en Dev loss: 0.4877 r:0.7182
Current avg r:0.5872 Best avg r: 0.6364
07:27:15,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:28:45,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:15,336 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1524
en_de Dev loss: 0.9401 r:0.2244
en_zh Dev loss: 0.8674 r:0.4489
ro_en Dev loss: 0.4009 r:0.8161
et_en Dev loss: 0.5270 r:0.6447
si_en Dev loss: 1.0288 r:0.5422
ne_en Dev loss: 0.6677 r:0.7154
ru_en Dev loss: 0.5336 r:0.7152
Current avg r:0.5867 Best avg r: 0.6364
07:34:45,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:36:16,665 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:47,303 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1503
en_de Dev loss: 0.9632 r:0.2157
en_zh Dev loss: 0.8327 r:0.4636
ro_en Dev loss: 0.3798 r:0.8165
et_en Dev loss: 0.5135 r:0.6504
si_en Dev loss: 0.9580 r:0.5408
ne_en Dev loss: 0.6158 r:0.7208
ru_en Dev loss: 0.4886 r:0.7335
Current avg r:0.5916 Best avg r: 0.6364
07:42:21,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:43:52,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:23,16 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1402
en_de Dev loss: 0.9422 r:0.2089
en_zh Dev loss: 0.8399 r:0.4617
ro_en Dev loss: 0.3853 r:0.8124
et_en Dev loss: 0.5059 r:0.6447
si_en Dev loss: 0.9265 r:0.5442
ne_en Dev loss: 0.6805 r:0.7142
ru_en Dev loss: 0.5210 r:0.7159
Current avg r:0.5860 Best avg r: 0.6364
07:49:55,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:51:26,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:57,558 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1346
en_de Dev loss: 0.9459 r:0.2041
en_zh Dev loss: 0.8499 r:0.4602
ro_en Dev loss: 0.3678 r:0.8195
et_en Dev loss: 0.5232 r:0.6476
si_en Dev loss: 0.9505 r:0.5503
ne_en Dev loss: 0.5945 r:0.7098
ru_en Dev loss: 0.4825 r:0.7329
Current avg r:0.5892 Best avg r: 0.6364
07:57:28,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:58:58,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:00:28,815 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1477
en_de Dev loss: 0.9512 r:0.2138
en_zh Dev loss: 0.8290 r:0.4694
ro_en Dev loss: 0.3748 r:0.8199
et_en Dev loss: 0.5284 r:0.6480
si_en Dev loss: 0.9626 r:0.5495
ne_en Dev loss: 0.6272 r:0.7107
ru_en Dev loss: 0.4742 r:0.7381
Current avg r:0.5927 Best avg r: 0.6364
08:04:58,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:06:28,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:07:58,157 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1354
en_de Dev loss: 0.9800 r:0.2117
en_zh Dev loss: 0.8512 r:0.4599
ro_en Dev loss: 0.3788 r:0.8186
et_en Dev loss: 0.5359 r:0.6489
si_en Dev loss: 0.9864 r:0.5528
ne_en Dev loss: 0.6090 r:0.7154
ru_en Dev loss: 0.4664 r:0.7397
Current avg r:0.5924 Best avg r: 0.6364
08:12:27,77 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:13:57,87 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:15:27,43 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1313
en_de Dev loss: 0.9604 r:0.2032
en_zh Dev loss: 0.8456 r:0.4571
ro_en Dev loss: 0.3685 r:0.8212
et_en Dev loss: 0.5030 r:0.6490
si_en Dev loss: 0.9217 r:0.5577
ne_en Dev loss: 0.5683 r:0.7166
ru_en Dev loss: 0.4979 r:0.7361
Current avg r:0.5916 Best avg r: 0.6364
08:19:56,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:26,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:22:56,752 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1312
en_de Dev loss: 0.9699 r:0.2141
en_zh Dev loss: 0.8271 r:0.4577
ro_en Dev loss: 0.3520 r:0.8191
et_en Dev loss: 0.5000 r:0.6447
si_en Dev loss: 0.8849 r:0.5458
ne_en Dev loss: 0.5423 r:0.7176
ru_en Dev loss: 0.5244 r:0.7134
Current avg r:0.5875 Best avg r: 0.6364
08:27:26,555 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:56,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:26,640 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1350
en_de Dev loss: 0.9205 r:0.2029
en_zh Dev loss: 0.7665 r:0.4686
ro_en Dev loss: 0.3271 r:0.8216
et_en Dev loss: 0.4781 r:0.6546
si_en Dev loss: 0.8729 r:0.5532
ne_en Dev loss: 0.5551 r:0.7203
ru_en Dev loss: 0.4225 r:0.7490
Current avg r:0.5957 Best avg r: 0.6364
08:34:55,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:25,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:37:55,935 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1375
en_de Dev loss: 0.9563 r:0.2176
en_zh Dev loss: 0.8203 r:0.4602
ro_en Dev loss: 0.3807 r:0.8168
et_en Dev loss: 0.5206 r:0.6490
si_en Dev loss: 0.9227 r:0.5493
ne_en Dev loss: 0.6185 r:0.7133
ru_en Dev loss: 0.4789 r:0.7362
Current avg r:0.5918 Best avg r: 0.6364
08:42:25,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:43:55,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:45:25,465 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1317
en_de Dev loss: 0.9216 r:0.2091
en_zh Dev loss: 0.7946 r:0.4606
ro_en Dev loss: 0.3484 r:0.8175
et_en Dev loss: 0.4961 r:0.6522
si_en Dev loss: 0.8560 r:0.5448
ne_en Dev loss: 0.5742 r:0.7080
ru_en Dev loss: 0.4784 r:0.7305
Current avg r:0.5890 Best avg r: 0.6364
08:49:55,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:51:25,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:52:55,466 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1310
en_de Dev loss: 0.9233 r:0.2105
en_zh Dev loss: 0.8089 r:0.4578
ro_en Dev loss: 0.3689 r:0.8166
et_en Dev loss: 0.5059 r:0.6565
si_en Dev loss: 0.8997 r:0.5481
ne_en Dev loss: 0.6074 r:0.7115
ru_en Dev loss: 0.4628 r:0.7393
Current avg r:0.5915 Best avg r: 0.6364
08:57:25,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:58:55,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:00:25,571 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1270
en_de Dev loss: 0.9615 r:0.2142
en_zh Dev loss: 0.8583 r:0.4477
ro_en Dev loss: 0.3782 r:0.8172
et_en Dev loss: 0.5181 r:0.6390
si_en Dev loss: 0.9553 r:0.5364
ne_en Dev loss: 0.6641 r:0.7094
ru_en Dev loss: 0.5020 r:0.7316
Current avg r:0.5851 Best avg r: 0.6364
09:04:55,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:06:25,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:07:55,627 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1282
en_de Dev loss: 0.9926 r:0.2189
en_zh Dev loss: 0.8710 r:0.4622
ro_en Dev loss: 0.4025 r:0.8193
et_en Dev loss: 0.5481 r:0.6505
si_en Dev loss: 0.9277 r:0.5461
ne_en Dev loss: 0.5916 r:0.7146
ru_en Dev loss: 0.5239 r:0.7313
Current avg r:0.5918 Best avg r: 0.6364
09:12:25,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:13:55,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:15:25,764 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1301
en_de Dev loss: 0.9812 r:0.2056
en_zh Dev loss: 0.8916 r:0.4598
ro_en Dev loss: 0.4322 r:0.8158
et_en Dev loss: 0.5479 r:0.6378
si_en Dev loss: 1.0111 r:0.5413
ne_en Dev loss: 0.7158 r:0.7119
ru_en Dev loss: 0.5577 r:0.7214
Current avg r:0.5848 Best avg r: 0.6364
09:19:55,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:21:25,729 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:22:55,821 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1330
en_de Dev loss: 0.9498 r:0.2022
en_zh Dev loss: 0.8365 r:0.4652
ro_en Dev loss: 0.3615 r:0.8213
et_en Dev loss: 0.5390 r:0.6469
si_en Dev loss: 0.8843 r:0.5480
ne_en Dev loss: 0.5809 r:0.7109
ru_en Dev loss: 0.4849 r:0.7298
Current avg r:0.5892 Best avg r: 0.6364
09:27:25,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:28:55,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:30:25,840 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1250
en_de Dev loss: 0.9344 r:0.2027
en_zh Dev loss: 0.7851 r:0.4552
ro_en Dev loss: 0.3343 r:0.8159
et_en Dev loss: 0.5007 r:0.6460
si_en Dev loss: 0.7959 r:0.5462
ne_en Dev loss: 0.5386 r:0.7074
ru_en Dev loss: 0.4578 r:0.7259
Current avg r:0.5856 Best avg r: 0.6364
09:34:56,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:36:26,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:37:56,127 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1195
en_de Dev loss: 0.9567 r:0.2040
en_zh Dev loss: 0.8041 r:0.4649
ro_en Dev loss: 0.3802 r:0.8122
et_en Dev loss: 0.5212 r:0.6432
si_en Dev loss: 0.9243 r:0.5375
ne_en Dev loss: 0.6261 r:0.7070
ru_en Dev loss: 0.4924 r:0.7242
Current avg r:0.5847 Best avg r: 0.6364
09:42:25,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:55,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:45:25,105 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1186
en_de Dev loss: 0.9998 r:0.1916
en_zh Dev loss: 0.8449 r:0.4676
ro_en Dev loss: 0.3834 r:0.8188
et_en Dev loss: 0.5174 r:0.6539
si_en Dev loss: 0.9547 r:0.5468
ne_en Dev loss: 0.6561 r:0.7068
ru_en Dev loss: 0.5298 r:0.7227
Current avg r:0.5869 Best avg r: 0.6364
09:49:54,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:51:24,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:52:54,137 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1113
en_de Dev loss: 0.9724 r:0.1932
en_zh Dev loss: 0.8131 r:0.4729
ro_en Dev loss: 0.3801 r:0.8203
et_en Dev loss: 0.5047 r:0.6514
si_en Dev loss: 0.9781 r:0.5397
ne_en Dev loss: 0.6832 r:0.7032
ru_en Dev loss: 0.5263 r:0.7215
Current avg r:0.5860 Best avg r: 0.6364
09:57:23,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:53,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:23,187 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1132
en_de Dev loss: 1.0126 r:0.1969
en_zh Dev loss: 0.8246 r:0.4616
ro_en Dev loss: 0.3636 r:0.8165
et_en Dev loss: 0.5022 r:0.6440
si_en Dev loss: 0.9147 r:0.5397
ne_en Dev loss: 0.5677 r:0.7089
ru_en Dev loss: 0.4985 r:0.7325
Current avg r:0.5857 Best avg r: 0.6364
10:04:52,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:06:22,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:53,36 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1170
en_de Dev loss: 0.9815 r:0.1850
en_zh Dev loss: 0.8553 r:0.4544
ro_en Dev loss: 0.3728 r:0.8169
et_en Dev loss: 0.5049 r:0.6457
si_en Dev loss: 0.9793 r:0.5378
ne_en Dev loss: 0.6228 r:0.7166
ru_en Dev loss: 0.5232 r:0.7204
Current avg r:0.5824 Best avg r: 0.6364
10:12:22,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:52,913 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:23,57 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1207
en_de Dev loss: 0.9633 r:0.2017
en_zh Dev loss: 0.8326 r:0.4619
ro_en Dev loss: 0.3647 r:0.8171
et_en Dev loss: 0.5001 r:0.6487
si_en Dev loss: 0.9037 r:0.5490
ne_en Dev loss: 0.6271 r:0.7124
ru_en Dev loss: 0.4788 r:0.7328
Current avg r:0.5891 Best avg r: 0.6364
10:19:52,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:22,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:52,406 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1165
en_de Dev loss: 1.0326 r:0.1912
en_zh Dev loss: 0.8492 r:0.4736
ro_en Dev loss: 0.4014 r:0.8189
et_en Dev loss: 0.5266 r:0.6520
si_en Dev loss: 1.0307 r:0.5516
ne_en Dev loss: 0.6836 r:0.7137
ru_en Dev loss: 0.4856 r:0.7525
Current avg r:0.5934 Best avg r: 0.6364
10:27:22,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:52,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:22,845 root INFO Epoch 10 Global steps: 110600 Train loss: 0.1158
en_de Dev loss: 0.9527 r:0.1840
en_zh Dev loss: 0.7995 r:0.4705
ro_en Dev loss: 0.3541 r:0.8196
et_en Dev loss: 0.4885 r:0.6588
si_en Dev loss: 0.8817 r:0.5606
ne_en Dev loss: 0.5703 r:0.7167
ru_en Dev loss: 0.4321 r:0.7527
Current avg r:0.5947 Best avg r: 0.6364
