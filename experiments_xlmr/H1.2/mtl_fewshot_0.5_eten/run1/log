14:36:47,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:00,368 root INFO 
id:en_de cur r: 0.0128 best r: 0.0128
14:37:13,235 root INFO 
id:en_zh cur r: 0.1120 best r: 0.1120
14:37:26,138 root INFO 
id:ro_en cur r: 0.3476 best r: 0.3476
14:37:51,979 root INFO 
id:et_en cur r: 0.1935 best r: 0.1935
14:38:04,894 root INFO 
id:si_en cur r: 0.1278 best r: 0.1278
14:38:17,793 root INFO 
id:ne_en cur r: 0.2225 best r: 0.2225
14:38:30,643 root INFO 
id:ru_en cur r: 0.3151 best r: 0.3151
14:38:30,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:00,553 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:40:00,562 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:40:00,567 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:40:00,573 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:40:00,581 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:40:00,588 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:40:00,595 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:40:13,493 root INFO Epoch 0 Global steps: 700 Train loss: 0.9036
en_de Dev loss: 0.8907 r:0.0474
en_zh Dev loss: 0.8150 r:0.1682
ro_en Dev loss: 0.8215 r:0.4602
et_en Dev loss: 0.6870 r:0.3497
si_en Dev loss: 0.8530 r:0.3101
ne_en Dev loss: 0.7503 r:0.4850
ru_en Dev loss: 0.8121 r:0.2590
Current avg r:0.2971 Best avg r: 0.2971
14:44:44,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:57,406 root INFO 
id:en_de cur r: 0.0306 best r: 0.0306
14:45:10,287 root INFO 
id:en_zh cur r: 0.1536 best r: 0.1536
14:45:23,190 root INFO 
id:ro_en cur r: 0.6153 best r: 0.6153
14:45:48,981 root INFO 
id:et_en cur r: 0.3631 best r: 0.3631
14:46:01,886 root INFO 
id:si_en cur r: 0.3850 best r: 0.3850
14:46:14,801 root INFO 
id:ne_en cur r: 0.2519 best r: 0.2519
14:46:27,655 root INFO 
id:ru_en cur r: 0.5634 best r: 0.5634
14:46:27,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:57,791 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:47:57,798 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:47:57,803 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:47:57,809 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:47:57,815 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:47:57,820 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:47:57,826 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:48:10,739 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8720
en_de Dev loss: 0.8942 r:0.0779
en_zh Dev loss: 0.7902 r:0.2279
ro_en Dev loss: 0.7537 r:0.6306
et_en Dev loss: 0.6323 r:0.4404
si_en Dev loss: 0.7958 r:0.4518
ne_en Dev loss: 0.6972 r:0.6026
ru_en Dev loss: 0.7066 r:0.5811
Current avg r:0.4303 Best avg r: 0.4303
14:52:41,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:54,587 root INFO 
id:en_de cur r: 0.1247 best r: 0.1247
14:53:07,445 root INFO 
id:en_zh cur r: 0.2768 best r: 0.2768
14:53:20,335 root INFO 
id:ro_en cur r: 0.7083 best r: 0.7083
14:53:46,138 root INFO 
id:et_en cur r: 0.5570 best r: 0.5570
14:53:59,39 root INFO 
id:si_en cur r: 0.4409 best r: 0.4409
14:54:11,936 root INFO 
id:ne_en cur r: 0.6115 best r: 0.6115
14:54:24,793 root INFO 
id:ru_en cur r: 0.6456 best r: 0.6456
14:54:24,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:54,957 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:55:54,969 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:55:54,974 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:55:54,979 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:55:54,985 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:55:54,989 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:55:54,995 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:56:07,909 root INFO Epoch 0 Global steps: 2100 Train loss: 0.8270
en_de Dev loss: 0.9038 r:0.0802
en_zh Dev loss: 0.7582 r:0.2778
ro_en Dev loss: 0.5451 r:0.7148
et_en Dev loss: 0.5142 r:0.5536
si_en Dev loss: 0.7349 r:0.4856
ne_en Dev loss: 0.5142 r:0.6546
ru_en Dev loss: 0.5512 r:0.6320
Current avg r:0.4855 Best avg r: 0.4855
15:00:38,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:04,370 root INFO 
id:en_zh cur r: 0.2986 best r: 0.2986
15:01:17,280 root INFO 
id:ro_en cur r: 0.7257 best r: 0.7257
15:01:43,110 root INFO 
id:et_en cur r: 0.6341 best r: 0.6341
15:01:56,10 root INFO 
id:si_en cur r: 0.5035 best r: 0.5035
15:02:08,919 root INFO 
id:ne_en cur r: 0.6647 best r: 0.6647
15:02:21,759 root INFO 
id:ru_en cur r: 0.6712 best r: 0.6712
15:02:21,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:51,819 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:03:51,825 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:03:51,829 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:03:51,835 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:03:51,840 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:03:51,845 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:03:51,851 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:04:04,759 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7426
en_de Dev loss: 1.0120 r:0.1068
en_zh Dev loss: 0.8244 r:0.2993
ro_en Dev loss: 0.5621 r:0.7259
et_en Dev loss: 0.4491 r:0.6294
si_en Dev loss: 0.8616 r:0.5086
ne_en Dev loss: 0.5079 r:0.6770
ru_en Dev loss: 0.5764 r:0.6690
Current avg r:0.5166 Best avg r: 0.5166
15:08:34,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:47,477 root INFO 
id:en_de cur r: 0.1549 best r: 0.1549
15:09:00,335 root INFO 
id:en_zh cur r: 0.3456 best r: 0.3456
15:09:13,231 root INFO 
id:ro_en cur r: 0.7634 best r: 0.7634
15:09:39,37 root INFO 
id:et_en cur r: 0.6674 best r: 0.6674
15:09:51,933 root INFO 
id:si_en cur r: 0.5373 best r: 0.5373
15:10:04,834 root INFO 
id:ne_en cur r: 0.6931 best r: 0.6931
15:10:17,670 root INFO 
id:ru_en cur r: 0.6973 best r: 0.6973
15:10:17,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:47,697 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:11:47,703 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:11:47,709 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:11:47,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:11:47,720 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:11:47,726 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:11:47,731 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:12:00,640 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6414
en_de Dev loss: 1.0760 r:0.1376
en_zh Dev loss: 0.9414 r:0.3458
ro_en Dev loss: 0.5583 r:0.7607
et_en Dev loss: 0.4891 r:0.6798
si_en Dev loss: 0.8707 r:0.5434
ne_en Dev loss: 0.5439 r:0.6987
ru_en Dev loss: 0.6887 r:0.7030
Current avg r:0.5527 Best avg r: 0.5527
15:16:30,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:43,469 root INFO 
id:en_de cur r: 0.1795 best r: 0.1795
15:16:56,322 root INFO 
id:en_zh cur r: 0.3899 best r: 0.3899
15:17:09,222 root INFO 
id:ro_en cur r: 0.7666 best r: 0.7666
15:17:35,53 root INFO 
id:et_en cur r: 0.6905 best r: 0.6905
15:17:47,962 root INFO 
id:si_en cur r: 0.5671 best r: 0.5671
15:18:00,852 root INFO 
id:ne_en cur r: 0.7209 best r: 0.7209
15:18:13,680 root INFO 
id:ru_en cur r: 0.7240 best r: 0.7240
15:18:13,680 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:43,719 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:19:43,726 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:19:43,731 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:19:43,736 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:19:43,741 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:19:43,746 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:19:43,750 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:19:56,635 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6107
en_de Dev loss: 0.9290 r:0.1671
en_zh Dev loss: 0.7763 r:0.3797
ro_en Dev loss: 0.3804 r:0.7629
et_en Dev loss: 0.3739 r:0.6923
si_en Dev loss: 0.6546 r:0.5660
ne_en Dev loss: 0.3908 r:0.7264
ru_en Dev loss: 0.4485 r:0.7259
Current avg r:0.5743 Best avg r: 0.5743
15:24:26,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:52,309 root INFO 
id:en_zh cur r: 0.3912 best r: 0.3912
15:25:05,198 root INFO 
id:ro_en cur r: 0.7809 best r: 0.7809
15:25:56,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:26,900 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6045
en_de Dev loss: 0.9933 r:0.1611
en_zh Dev loss: 0.8325 r:0.3830
ro_en Dev loss: 0.4521 r:0.7785
et_en Dev loss: 0.4296 r:0.6938
si_en Dev loss: 0.7855 r:0.5559
ne_en Dev loss: 0.5570 r:0.7054
ru_en Dev loss: 0.6418 r:0.7169
Current avg r:0.5707 Best avg r: 0.5743
15:31:57,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:10,589 root INFO 
id:en_de cur r: 0.1964 best r: 0.1964
15:32:23,457 root INFO 
id:en_zh cur r: 0.4100 best r: 0.4100
15:32:36,359 root INFO 
id:ro_en cur r: 0.7924 best r: 0.7924
15:33:02,152 root INFO 
id:et_en cur r: 0.7068 best r: 0.7068
15:33:15,42 root INFO 
id:si_en cur r: 0.5917 best r: 0.5917
15:33:27,933 root INFO 
id:ne_en cur r: 0.7291 best r: 0.7291
15:33:40,762 root INFO 
id:ru_en cur r: 0.7460 best r: 0.7460
15:33:40,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:10,827 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:35:10,833 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:35:10,838 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:35:10,843 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:35:10,847 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:35:10,852 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:35:10,857 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:35:23,763 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5888
en_de Dev loss: 0.9250 r:0.1790
en_zh Dev loss: 0.7562 r:0.4056
ro_en Dev loss: 0.3667 r:0.7898
et_en Dev loss: 0.3824 r:0.7142
si_en Dev loss: 0.6590 r:0.5910
ne_en Dev loss: 0.4190 r:0.7313
ru_en Dev loss: 0.4495 r:0.7483
Current avg r:0.5942 Best avg r: 0.5942
15:39:54,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:24,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:54,257 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5967
en_de Dev loss: 1.0301 r:0.1914
en_zh Dev loss: 0.8756 r:0.3908
ro_en Dev loss: 0.5533 r:0.7862
et_en Dev loss: 0.4866 r:0.6973
si_en Dev loss: 1.0814 r:0.5745
ne_en Dev loss: 0.5889 r:0.7286
ru_en Dev loss: 0.6366 r:0.7174
Current avg r:0.5838 Best avg r: 0.5942
15:47:24,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:37,123 root INFO 
id:en_de cur r: 0.2014 best r: 0.2014
15:48:02,889 root INFO 
id:ro_en cur r: 0.7991 best r: 0.7991
15:48:28,723 root INFO 
id:et_en cur r: 0.7152 best r: 0.7152
15:48:41,634 root INFO 
id:si_en cur r: 0.5930 best r: 0.5930
15:48:54,544 root INFO 
id:ne_en cur r: 0.7435 best r: 0.7435
15:49:07,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:37,450 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:50:37,456 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:50:37,462 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:50:37,467 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:50:37,474 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:50:37,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:50:37,486 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:50:50,402 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5615
en_de Dev loss: 0.9990 r:0.1991
en_zh Dev loss: 0.7955 r:0.3981
ro_en Dev loss: 0.4258 r:0.7958
et_en Dev loss: 0.3896 r:0.7149
si_en Dev loss: 0.7919 r:0.5930
ne_en Dev loss: 0.4230 r:0.7393
ru_en Dev loss: 0.5527 r:0.7312
Current avg r:0.5959 Best avg r: 0.5959
15:55:21,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:34,310 root INFO 
id:en_de cur r: 0.2130 best r: 0.2130
15:56:51,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:21,788 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5811
en_de Dev loss: 0.9136 r:0.2127
en_zh Dev loss: 0.7690 r:0.4037
ro_en Dev loss: 0.4707 r:0.7932
et_en Dev loss: 0.4117 r:0.7019
si_en Dev loss: 0.9065 r:0.5827
ne_en Dev loss: 0.5351 r:0.7269
ru_en Dev loss: 0.6126 r:0.7114
Current avg r:0.5904 Best avg r: 0.5959
16:02:52,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:05,825 root INFO 
id:en_de cur r: 0.2189 best r: 0.2189
16:03:18,675 root INFO 
id:en_zh cur r: 0.4171 best r: 0.4171
16:03:31,567 root INFO 
id:ro_en cur r: 0.8029 best r: 0.8029
16:03:57,398 root INFO 
id:et_en cur r: 0.7175 best r: 0.7175
16:04:10,311 root INFO 
id:si_en cur r: 0.6143 best r: 0.6143
16:04:23,226 root INFO 
id:ne_en cur r: 0.7548 best r: 0.7548
16:04:36,84 root INFO 
id:ru_en cur r: 0.7514 best r: 0.7514
16:04:36,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:06,253 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:06:06,259 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:06:06,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:06:06,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:06:06,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:06:06,279 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:06:06,284 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:06:19,194 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5667
en_de Dev loss: 0.9033 r:0.2169
en_zh Dev loss: 0.7101 r:0.4185
ro_en Dev loss: 0.3938 r:0.8002
et_en Dev loss: 0.3622 r:0.7198
si_en Dev loss: 0.6591 r:0.6143
ne_en Dev loss: 0.3765 r:0.7532
ru_en Dev loss: 0.4663 r:0.7495
Current avg r:0.6103 Best avg r: 0.6103
16:10:50,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:03,59 root INFO 
id:en_de cur r: 0.2265 best r: 0.2265
16:11:15,920 root INFO 
id:en_zh cur r: 0.4175 best r: 0.4175
16:12:20,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:50,352 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5458
en_de Dev loss: 0.9770 r:0.2199
en_zh Dev loss: 0.8154 r:0.4150
ro_en Dev loss: 0.4543 r:0.7971
et_en Dev loss: 0.4127 r:0.7138
si_en Dev loss: 0.7990 r:0.6054
ne_en Dev loss: 0.4289 r:0.7469
ru_en Dev loss: 0.5999 r:0.7369
Current avg r:0.6050 Best avg r: 0.6103
16:18:20,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:33,437 root INFO 
id:en_de cur r: 0.2305 best r: 0.2305
16:18:46,306 root INFO 
id:en_zh cur r: 0.4357 best r: 0.4357
16:18:59,222 root INFO 
id:ro_en cur r: 0.8059 best r: 0.8059
16:19:25,38 root INFO 
id:et_en cur r: 0.7194 best r: 0.7194
16:19:37,943 root INFO 
id:si_en cur r: 0.6149 best r: 0.6149
16:19:50,847 root INFO 
id:ne_en cur r: 0.7562 best r: 0.7562
16:20:03,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:33,722 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:21:33,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:21:33,733 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:21:33,738 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:21:33,742 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:21:33,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:21:33,751 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:21:46,645 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5644
en_de Dev loss: 0.8972 r:0.2255
en_zh Dev loss: 0.7486 r:0.4285
ro_en Dev loss: 0.3777 r:0.8014
et_en Dev loss: 0.3642 r:0.7203
si_en Dev loss: 0.6685 r:0.6098
ne_en Dev loss: 0.3826 r:0.7525
ru_en Dev loss: 0.5283 r:0.7396
Current avg r:0.6111 Best avg r: 0.6111
16:26:16,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:29,454 root INFO 
id:en_de cur r: 0.2455 best r: 0.2455
16:26:42,314 root INFO 
id:en_zh cur r: 0.4421 best r: 0.4421
16:27:20,979 root INFO 
id:si_en cur r: 0.6238 best r: 0.6238
16:27:33,879 root INFO 
id:ne_en cur r: 0.7617 best r: 0.7617
16:27:46,739 root INFO 
id:ru_en cur r: 0.7591 best r: 0.7591
16:27:46,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:16,899 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:29:16,905 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:29:16,910 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:29:16,914 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:29:16,919 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:29:16,923 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:29:16,928 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:29:29,838 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5372
en_de Dev loss: 0.8559 r:0.2412
en_zh Dev loss: 0.6915 r:0.4370
ro_en Dev loss: 0.3409 r:0.8008
et_en Dev loss: 0.3437 r:0.7231
si_en Dev loss: 0.5742 r:0.6266
ne_en Dev loss: 0.4299 r:0.7600
ru_en Dev loss: 0.3951 r:0.7567
Current avg r:0.6208 Best avg r: 0.6208
16:34:02,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:19,431 root INFO 
id:ne_en cur r: 0.7633 best r: 0.7633
16:35:32,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:02,184 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4947
en_de Dev loss: 0.9153 r:0.2295
en_zh Dev loss: 0.8102 r:0.4135
ro_en Dev loss: 0.4112 r:0.8007
et_en Dev loss: 0.3849 r:0.7198
si_en Dev loss: 0.7103 r:0.6166
ne_en Dev loss: 0.4222 r:0.7604
ru_en Dev loss: 0.5428 r:0.7371
Current avg r:0.6111 Best avg r: 0.6208
16:41:32,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:02,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:32,770 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5218
en_de Dev loss: 0.8690 r:0.2371
en_zh Dev loss: 0.7410 r:0.4314
ro_en Dev loss: 0.4044 r:0.7969
et_en Dev loss: 0.3949 r:0.7108
si_en Dev loss: 0.7588 r:0.6041
ne_en Dev loss: 0.4389 r:0.7571
ru_en Dev loss: 0.5019 r:0.7336
Current avg r:0.6101 Best avg r: 0.6208
16:49:02,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:15,658 root INFO 
id:en_de cur r: 0.2471 best r: 0.2471
16:50:33,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:03,198 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5030
en_de Dev loss: 0.8946 r:0.2370
en_zh Dev loss: 0.8170 r:0.4128
ro_en Dev loss: 0.4719 r:0.7933
et_en Dev loss: 0.4267 r:0.7081
si_en Dev loss: 0.8748 r:0.5843
ne_en Dev loss: 0.5246 r:0.7480
ru_en Dev loss: 0.5501 r:0.7267
Current avg r:0.6014 Best avg r: 0.6208
16:56:34,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:12,905 root INFO 
id:ro_en cur r: 0.8137 best r: 0.8137
16:58:04,466 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:34,656 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4890
en_de Dev loss: 0.8642 r:0.2413
en_zh Dev loss: 0.7619 r:0.4273
ro_en Dev loss: 0.3397 r:0.8069
et_en Dev loss: 0.3566 r:0.7235
si_en Dev loss: 0.6296 r:0.6176
ne_en Dev loss: 0.3511 r:0.7603
ru_en Dev loss: 0.4843 r:0.7485
Current avg r:0.6179 Best avg r: 0.6208
17:04:05,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:31,617 root INFO 
id:en_zh cur r: 0.4428 best r: 0.4428
17:05:36,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:06,274 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5144
en_de Dev loss: 0.8747 r:0.2477
en_zh Dev loss: 0.7944 r:0.4374
ro_en Dev loss: 0.3878 r:0.8056
et_en Dev loss: 0.4132 r:0.7151
si_en Dev loss: 0.7897 r:0.6005
ne_en Dev loss: 0.4370 r:0.7573
ru_en Dev loss: 0.5326 r:0.7449
Current avg r:0.6155 Best avg r: 0.6208
17:11:37,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:03,68 root INFO 
id:en_zh cur r: 0.4518 best r: 0.4518
17:13:07,487 root INFO 
id:ru_en cur r: 0.7635 best r: 0.7635
17:13:07,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:37,679 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5172
en_de Dev loss: 0.8744 r:0.2338
en_zh Dev loss: 0.7294 r:0.4470
ro_en Dev loss: 0.4087 r:0.8044
et_en Dev loss: 0.3836 r:0.7220
si_en Dev loss: 0.6954 r:0.6144
ne_en Dev loss: 0.4347 r:0.7526
ru_en Dev loss: 0.4621 r:0.7598
Current avg r:0.6191 Best avg r: 0.6208
17:19:08,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:21,145 root INFO 
id:en_de cur r: 0.2545 best r: 0.2545
17:19:34,1 root INFO 
id:en_zh cur r: 0.4710 best r: 0.4710
17:19:46,893 root INFO 
id:ro_en cur r: 0.8198 best r: 0.8198
17:20:12,715 root INFO 
id:et_en cur r: 0.7242 best r: 0.7242
17:20:38,545 root INFO 
id:ne_en cur r: 0.7658 best r: 0.7658
17:20:51,401 root INFO 
id:ru_en cur r: 0.7825 best r: 0.7825
17:20:51,401 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:21,574 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
17:22:21,583 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:22:21,588 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:22:21,593 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
17:22:21,597 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
17:22:21,603 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:22:21,608 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:22:34,532 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5139
en_de Dev loss: 0.8613 r:0.2468
en_zh Dev loss: 0.6759 r:0.4648
ro_en Dev loss: 0.3458 r:0.8161
et_en Dev loss: 0.3565 r:0.7311
si_en Dev loss: 0.6060 r:0.6226
ne_en Dev loss: 0.3556 r:0.7650
ru_en Dev loss: 0.3622 r:0.7823
Current avg r:0.6327 Best avg r: 0.6327
17:27:05,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:35,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:06,164 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4851
en_de Dev loss: 0.9396 r:0.2400
en_zh Dev loss: 0.8286 r:0.4384
ro_en Dev loss: 0.4258 r:0.8096
et_en Dev loss: 0.3996 r:0.7200
si_en Dev loss: 0.7809 r:0.6041
ne_en Dev loss: 0.4631 r:0.7583
ru_en Dev loss: 0.5039 r:0.7603
Current avg r:0.6187 Best avg r: 0.6327
17:34:37,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:54,599 root INFO 
id:ne_en cur r: 0.7765 best r: 0.7765
17:36:07,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:37,504 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4757
en_de Dev loss: 0.8619 r:0.2454
en_zh Dev loss: 0.7790 r:0.4511
ro_en Dev loss: 0.3716 r:0.8159
et_en Dev loss: 0.3585 r:0.7292
si_en Dev loss: 0.7046 r:0.6178
ne_en Dev loss: 0.3778 r:0.7736
ru_en Dev loss: 0.4481 r:0.7638
Current avg r:0.6281 Best avg r: 0.6327
17:42:07,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:33,514 root INFO 
id:en_zh cur r: 0.4713 best r: 0.4713
17:43:25,84 root INFO 
id:ne_en cur r: 0.7808 best r: 0.7808
17:43:37,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:07,993 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4650
en_de Dev loss: 0.8401 r:0.2413
en_zh Dev loss: 0.6684 r:0.4643
ro_en Dev loss: 0.3143 r:0.8148
et_en Dev loss: 0.3489 r:0.7254
si_en Dev loss: 0.6707 r:0.6048
ne_en Dev loss: 0.3882 r:0.7747
ru_en Dev loss: 0.3885 r:0.7594
Current avg r:0.6264 Best avg r: 0.6327
17:49:37,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:03,611 root INFO 
id:en_zh cur r: 0.4790 best r: 0.4790
17:51:08,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:38,184 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4877
en_de Dev loss: 0.8612 r:0.2484
en_zh Dev loss: 0.6818 r:0.4739
ro_en Dev loss: 0.3623 r:0.8143
et_en Dev loss: 0.3676 r:0.7285
si_en Dev loss: 0.7286 r:0.6138
ne_en Dev loss: 0.4345 r:0.7707
ru_en Dev loss: 0.5026 r:0.7605
Current avg r:0.6300 Best avg r: 0.6327
17:57:08,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:39,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:09,281 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4880
en_de Dev loss: 0.8447 r:0.2451
en_zh Dev loss: 0.7070 r:0.4717
ro_en Dev loss: 0.3702 r:0.8140
et_en Dev loss: 0.3833 r:0.7245
si_en Dev loss: 0.6996 r:0.6141
ne_en Dev loss: 0.4014 r:0.7691
ru_en Dev loss: 0.5000 r:0.7571
Current avg r:0.6279 Best avg r: 0.6327
18:04:40,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:53,328 root INFO 
id:en_de cur r: 0.2560 best r: 0.2560
18:06:10,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:40,804 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4662
en_de Dev loss: 0.8533 r:0.2485
en_zh Dev loss: 0.7793 r:0.4663
ro_en Dev loss: 0.4510 r:0.8098
et_en Dev loss: 0.4485 r:0.7163
si_en Dev loss: 0.9022 r:0.6002
ne_en Dev loss: 0.6034 r:0.7586
ru_en Dev loss: 0.6329 r:0.7298
Current avg r:0.6185 Best avg r: 0.6327
18:12:11,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:37,674 root INFO 
id:en_zh cur r: 0.4790 best r: 0.4790
18:13:42,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:12,358 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4639
en_de Dev loss: 0.8430 r:0.2508
en_zh Dev loss: 0.7039 r:0.4725
ro_en Dev loss: 0.3403 r:0.8089
et_en Dev loss: 0.3713 r:0.7170
si_en Dev loss: 0.7542 r:0.6089
ne_en Dev loss: 0.4597 r:0.7703
ru_en Dev loss: 0.4579 r:0.7483
Current avg r:0.6253 Best avg r: 0.6327
18:19:43,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:56,478 root INFO 
id:en_de cur r: 0.2566 best r: 0.2566
18:20:09,347 root INFO 
id:en_zh cur r: 0.4905 best r: 0.4905
18:21:13,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:43,943 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4674
en_de Dev loss: 0.8366 r:0.2501
en_zh Dev loss: 0.6795 r:0.4848
ro_en Dev loss: 0.3480 r:0.8158
et_en Dev loss: 0.3970 r:0.7227
si_en Dev loss: 0.6055 r:0.6177
ne_en Dev loss: 0.3616 r:0.7730
ru_en Dev loss: 0.4297 r:0.7586
Current avg r:0.6318 Best avg r: 0.6327
18:27:15,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:28,224 root INFO 
id:en_de cur r: 0.2675 best r: 0.2675
18:27:53,972 root INFO 
id:ro_en cur r: 0.8199 best r: 0.8199
18:28:19,788 root INFO 
id:si_en cur r: 0.6294 best r: 0.6294
18:28:45,555 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:15,610 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
18:30:15,619 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:30:15,625 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:30:15,630 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
18:30:15,636 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
18:30:15,641 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:30:15,647 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:30:28,528 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4432
en_de Dev loss: 0.8314 r:0.2594
en_zh Dev loss: 0.6830 r:0.4814
ro_en Dev loss: 0.3340 r:0.8157
et_en Dev loss: 0.3786 r:0.7234
si_en Dev loss: 0.6211 r:0.6241
ne_en Dev loss: 0.4029 r:0.7669
ru_en Dev loss: 0.3962 r:0.7679
Current avg r:0.6341 Best avg r: 0.6341
18:34:58,726 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:24,395 root INFO 
id:en_zh cur r: 0.5014 best r: 0.5014
18:36:02,994 root INFO 
id:si_en cur r: 0.6306 best r: 0.6306
18:36:28,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:58,671 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4470
en_de Dev loss: 0.8411 r:0.2407
en_zh Dev loss: 0.6523 r:0.4959
ro_en Dev loss: 0.3537 r:0.8112
et_en Dev loss: 0.3983 r:0.7204
si_en Dev loss: 0.6249 r:0.6263
ne_en Dev loss: 0.3880 r:0.7666
ru_en Dev loss: 0.3785 r:0.7727
Current avg r:0.6334 Best avg r: 0.6341
18:42:28,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:59,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:29,180 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4606
en_de Dev loss: 0.8373 r:0.2470
en_zh Dev loss: 0.6861 r:0.4844
ro_en Dev loss: 0.3152 r:0.8113
et_en Dev loss: 0.3626 r:0.7118
si_en Dev loss: 0.7043 r:0.6037
ne_en Dev loss: 0.5123 r:0.7679
ru_en Dev loss: 0.3665 r:0.7647
Current avg r:0.6273 Best avg r: 0.6341
18:50:00,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:38,923 root INFO 
id:ro_en cur r: 0.8253 best r: 0.8253
18:51:30,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:00,683 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4324
en_de Dev loss: 0.8534 r:0.2312
en_zh Dev loss: 0.6914 r:0.4849
ro_en Dev loss: 0.3444 r:0.8200
et_en Dev loss: 0.4156 r:0.7200
si_en Dev loss: 0.6696 r:0.6139
ne_en Dev loss: 0.3519 r:0.7755
ru_en Dev loss: 0.4407 r:0.7584
Current avg r:0.6291 Best avg r: 0.6341
18:57:31,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:01,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:31,622 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4330
en_de Dev loss: 0.8443 r:0.2379
en_zh Dev loss: 0.6833 r:0.4841
ro_en Dev loss: 0.3360 r:0.8183
et_en Dev loss: 0.4132 r:0.7183
si_en Dev loss: 0.5640 r:0.6243
ne_en Dev loss: 0.3349 r:0.7647
ru_en Dev loss: 0.3886 r:0.7689
Current avg r:0.6309 Best avg r: 0.6341
19:05:01,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:14,457 root INFO 
id:en_de cur r: 0.2677 best r: 0.2677
19:06:31,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:01,728 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4050
en_de Dev loss: 0.8436 r:0.2534
en_zh Dev loss: 0.7087 r:0.4752
ro_en Dev loss: 0.3518 r:0.8153
et_en Dev loss: 0.4114 r:0.7081
si_en Dev loss: 0.6886 r:0.6102
ne_en Dev loss: 0.3966 r:0.7643
ru_en Dev loss: 0.4520 r:0.7495
Current avg r:0.6251 Best avg r: 0.6341
19:12:32,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:02,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:32,878 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4378
en_de Dev loss: 0.8441 r:0.2209
en_zh Dev loss: 0.6911 r:0.4705
ro_en Dev loss: 0.3337 r:0.8100
et_en Dev loss: 0.4172 r:0.6995
si_en Dev loss: 0.5924 r:0.6106
ne_en Dev loss: 0.3475 r:0.7648
ru_en Dev loss: 0.4209 r:0.7370
Current avg r:0.6162 Best avg r: 0.6341
19:20:03,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:34,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:04,143 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4145
en_de Dev loss: 0.8457 r:0.2447
en_zh Dev loss: 0.7253 r:0.4811
ro_en Dev loss: 0.3646 r:0.8165
et_en Dev loss: 0.4143 r:0.7057
si_en Dev loss: 0.6699 r:0.6172
ne_en Dev loss: 0.4803 r:0.7674
ru_en Dev loss: 0.5054 r:0.7395
Current avg r:0.6246 Best avg r: 0.6341
19:27:34,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:46,962 root INFO 
id:en_de cur r: 0.2758 best r: 0.2758
19:28:12,684 root INFO 
id:ro_en cur r: 0.8254 best r: 0.8254
19:29:04,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:34,307 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4195
en_de Dev loss: 0.8428 r:0.2575
en_zh Dev loss: 0.7442 r:0.4828
ro_en Dev loss: 0.3462 r:0.8220
et_en Dev loss: 0.4008 r:0.7118
si_en Dev loss: 0.7168 r:0.6102
ne_en Dev loss: 0.4384 r:0.7659
ru_en Dev loss: 0.4757 r:0.7483
Current avg r:0.6284 Best avg r: 0.6341
19:35:05,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:18,123 root INFO 
id:en_de cur r: 0.2773 best r: 0.2773
19:35:43,890 root INFO 
id:ro_en cur r: 0.8255 best r: 0.8255
19:36:35,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:05,651 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4136
en_de Dev loss: 0.8322 r:0.2611
en_zh Dev loss: 0.6879 r:0.4853
ro_en Dev loss: 0.3334 r:0.8204
et_en Dev loss: 0.3989 r:0.7074
si_en Dev loss: 0.6927 r:0.6109
ne_en Dev loss: 0.4170 r:0.7655
ru_en Dev loss: 0.4314 r:0.7629
Current avg r:0.6305 Best avg r: 0.6341
19:42:36,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:49,110 root INFO 
id:en_de cur r: 0.2809 best r: 0.2809
19:43:01,965 root INFO 
id:en_zh cur r: 0.5036 best r: 0.5036
19:43:14,863 root INFO 
id:ro_en cur r: 0.8305 best r: 0.8305
19:44:06,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:36,555 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
19:45:36,561 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
19:45:36,565 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
19:45:36,570 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
19:45:36,574 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
19:45:36,579 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
19:45:36,584 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
19:45:49,492 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4093
en_de Dev loss: 0.8346 r:0.2684
en_zh Dev loss: 0.6891 r:0.4993
ro_en Dev loss: 0.3091 r:0.8261
et_en Dev loss: 0.3782 r:0.7127
si_en Dev loss: 0.6760 r:0.6130
ne_en Dev loss: 0.3894 r:0.7702
ru_en Dev loss: 0.4121 r:0.7631
Current avg r:0.6361 Best avg r: 0.6361
19:50:19,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:32,550 root INFO 
id:en_de cur r: 0.2903 best r: 0.2903
19:51:49,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:19,781 root INFO Epoch 2 Global steps: 29400 Train loss: 0.4072
en_de Dev loss: 0.8221 r:0.2782
en_zh Dev loss: 0.6919 r:0.4865
ro_en Dev loss: 0.3218 r:0.8179
et_en Dev loss: 0.3897 r:0.7014
si_en Dev loss: 0.7465 r:0.5946
ne_en Dev loss: 0.4785 r:0.7657
ru_en Dev loss: 0.4612 r:0.7355
Current avg r:0.6257 Best avg r: 0.6361
19:57:50,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:20,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:50,830 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3751
en_de Dev loss: 0.8529 r:0.2728
en_zh Dev loss: 0.7294 r:0.4874
ro_en Dev loss: 0.3966 r:0.8107
et_en Dev loss: 0.4351 r:0.6958
si_en Dev loss: 0.8105 r:0.5953
ne_en Dev loss: 0.4331 r:0.7667
ru_en Dev loss: 0.5203 r:0.7276
Current avg r:0.6223 Best avg r: 0.6361
20:05:21,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:51,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:21,557 root INFO Epoch 2 Global steps: 30800 Train loss: 0.4295
en_de Dev loss: 0.8316 r:0.2643
en_zh Dev loss: 0.7052 r:0.4976
ro_en Dev loss: 0.3813 r:0.8158
et_en Dev loss: 0.4309 r:0.7041
si_en Dev loss: 0.8031 r:0.6016
ne_en Dev loss: 0.3838 r:0.7709
ru_en Dev loss: 0.4953 r:0.7490
Current avg r:0.6290 Best avg r: 0.6361
20:12:51,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:17,289 root INFO 
id:en_zh cur r: 0.5085 best r: 0.5085
20:14:21,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:51,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
20:15:51,914 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
20:15:51,925 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
20:15:51,936 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
20:15:51,947 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
20:15:51,960 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
20:15:52,5 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
20:16:04,912 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3909
en_de Dev loss: 0.8256 r:0.2662
en_zh Dev loss: 0.6616 r:0.5046
ro_en Dev loss: 0.3145 r:0.8224
et_en Dev loss: 0.4024 r:0.7166
si_en Dev loss: 0.6164 r:0.6204
ne_en Dev loss: 0.3361 r:0.7739
ru_en Dev loss: 0.3875 r:0.7711
Current avg r:0.6393 Best avg r: 0.6393
20:20:37,35 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:22:07,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:37,301 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3660
en_de Dev loss: 0.8269 r:0.2648
en_zh Dev loss: 0.6757 r:0.5026
ro_en Dev loss: 0.3541 r:0.8160
et_en Dev loss: 0.4288 r:0.7076
si_en Dev loss: 0.7040 r:0.6077
ne_en Dev loss: 0.4415 r:0.7632
ru_en Dev loss: 0.4798 r:0.7426
Current avg r:0.6292 Best avg r: 0.6393
20:28:08,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:38,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:08,252 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3553
en_de Dev loss: 0.8543 r:0.2566
en_zh Dev loss: 0.7623 r:0.4819
ro_en Dev loss: 0.3621 r:0.8134
et_en Dev loss: 0.4338 r:0.6939
si_en Dev loss: 0.7989 r:0.5930
ne_en Dev loss: 0.5108 r:0.7580
ru_en Dev loss: 0.5615 r:0.7127
Current avg r:0.6157 Best avg r: 0.6393
20:35:39,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:09,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:39,336 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3723
en_de Dev loss: 0.8595 r:0.2592
en_zh Dev loss: 0.7408 r:0.4875
ro_en Dev loss: 0.3891 r:0.8134
et_en Dev loss: 0.4536 r:0.6927
si_en Dev loss: 0.7764 r:0.6031
ne_en Dev loss: 0.4896 r:0.7628
ru_en Dev loss: 0.5577 r:0.7214
Current avg r:0.6200 Best avg r: 0.6393
20:43:10,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:40,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:10,592 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3861
en_de Dev loss: 0.8332 r:0.2579
en_zh Dev loss: 0.6763 r:0.4962
ro_en Dev loss: 0.3345 r:0.8154
et_en Dev loss: 0.4233 r:0.6920
si_en Dev loss: 0.6602 r:0.6065
ne_en Dev loss: 0.4078 r:0.7680
ru_en Dev loss: 0.4007 r:0.7514
Current avg r:0.6268 Best avg r: 0.6393
20:50:41,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:11,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:41,644 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3518
en_de Dev loss: 0.8311 r:0.2623
en_zh Dev loss: 0.6966 r:0.4953
ro_en Dev loss: 0.3564 r:0.8156
et_en Dev loss: 0.4588 r:0.6827
si_en Dev loss: 0.7969 r:0.5915
ne_en Dev loss: 0.4552 r:0.7602
ru_en Dev loss: 0.4211 r:0.7561
Current avg r:0.6234 Best avg r: 0.6393
20:58:12,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:42,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:12,533 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3654
en_de Dev loss: 0.8542 r:0.2579
en_zh Dev loss: 0.7728 r:0.4837
ro_en Dev loss: 0.4026 r:0.8138
et_en Dev loss: 0.4755 r:0.6877
si_en Dev loss: 0.7843 r:0.6029
ne_en Dev loss: 0.5210 r:0.7631
ru_en Dev loss: 0.4617 r:0.7577
Current avg r:0.6238 Best avg r: 0.6393
21:05:43,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:13,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:44,146 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3637
en_de Dev loss: 0.8349 r:0.2470
en_zh Dev loss: 0.7174 r:0.4652
ro_en Dev loss: 0.3371 r:0.8111
et_en Dev loss: 0.4337 r:0.6789
si_en Dev loss: 0.7962 r:0.5897
ne_en Dev loss: 0.4894 r:0.7613
ru_en Dev loss: 0.4443 r:0.7424
Current avg r:0.6137 Best avg r: 0.6393
21:13:14,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:44,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:14,828 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3703
en_de Dev loss: 0.8353 r:0.2744
en_zh Dev loss: 0.7453 r:0.4784
ro_en Dev loss: 0.3933 r:0.8189
et_en Dev loss: 0.4754 r:0.7022
si_en Dev loss: 0.7640 r:0.6093
ne_en Dev loss: 0.4160 r:0.7646
ru_en Dev loss: 0.4614 r:0.7653
Current avg r:0.6304 Best avg r: 0.6393
21:20:45,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:15,752 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:45,927 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3507
en_de Dev loss: 0.8683 r:0.2527
en_zh Dev loss: 0.8325 r:0.4444
ro_en Dev loss: 0.4052 r:0.8100
et_en Dev loss: 0.4642 r:0.6813
si_en Dev loss: 0.8240 r:0.5903
ne_en Dev loss: 0.4922 r:0.7550
ru_en Dev loss: 0.5060 r:0.7361
Current avg r:0.6100 Best avg r: 0.6393
21:28:16,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:29:46,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:16,495 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3503
en_de Dev loss: 0.8380 r:0.2630
en_zh Dev loss: 0.7835 r:0.4596
ro_en Dev loss: 0.3657 r:0.8160
et_en Dev loss: 0.4728 r:0.6954
si_en Dev loss: 0.7337 r:0.6033
ne_en Dev loss: 0.4091 r:0.7549
ru_en Dev loss: 0.4774 r:0.7437
Current avg r:0.6194 Best avg r: 0.6393
21:35:46,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:16,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:46,744 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3589
en_de Dev loss: 0.8458 r:0.2272
en_zh Dev loss: 0.7050 r:0.4774
ro_en Dev loss: 0.3337 r:0.8101
et_en Dev loss: 0.4594 r:0.6727
si_en Dev loss: 0.7439 r:0.5982
ne_en Dev loss: 0.4370 r:0.7519
ru_en Dev loss: 0.4810 r:0.7208
Current avg r:0.6083 Best avg r: 0.6393
21:43:16,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:46,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:16,820 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3453
en_de Dev loss: 0.8265 r:0.2676
en_zh Dev loss: 0.7154 r:0.4737
ro_en Dev loss: 0.3501 r:0.8155
et_en Dev loss: 0.4711 r:0.6914
si_en Dev loss: 0.6849 r:0.6053
ne_en Dev loss: 0.3817 r:0.7559
ru_en Dev loss: 0.3933 r:0.7655
Current avg r:0.6250 Best avg r: 0.6393
21:50:46,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:59,760 root INFO 
id:en_de cur r: 0.2929 best r: 0.2929
21:52:17,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:47,253 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3249
en_de Dev loss: 0.8240 r:0.2745
en_zh Dev loss: 0.7193 r:0.4706
ro_en Dev loss: 0.3386 r:0.8159
et_en Dev loss: 0.4477 r:0.6862
si_en Dev loss: 0.8511 r:0.5973
ne_en Dev loss: 0.4222 r:0.7650
ru_en Dev loss: 0.4195 r:0.7490
Current avg r:0.6226 Best avg r: 0.6393
21:58:18,5 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:48,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:18,110 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3370
en_de Dev loss: 0.8453 r:0.2717
en_zh Dev loss: 0.7532 r:0.4665
ro_en Dev loss: 0.3741 r:0.8105
et_en Dev loss: 0.4664 r:0.6844
si_en Dev loss: 0.7532 r:0.5930
ne_en Dev loss: 0.4152 r:0.7596
ru_en Dev loss: 0.4397 r:0.7558
Current avg r:0.6202 Best avg r: 0.6393
22:05:48,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:07:18,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:08:48,121 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3239
en_de Dev loss: 0.8376 r:0.2618
en_zh Dev loss: 0.7375 r:0.4634
ro_en Dev loss: 0.3524 r:0.8157
et_en Dev loss: 0.4521 r:0.6931
si_en Dev loss: 0.7393 r:0.6011
ne_en Dev loss: 0.4047 r:0.7610
ru_en Dev loss: 0.4266 r:0.7657
Current avg r:0.6231 Best avg r: 0.6393
22:13:20,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:50,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:16:20,823 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3009
en_de Dev loss: 0.8440 r:0.2574
en_zh Dev loss: 0.7585 r:0.4599
ro_en Dev loss: 0.3428 r:0.8166
et_en Dev loss: 0.4378 r:0.6831
si_en Dev loss: 0.8220 r:0.5895
ne_en Dev loss: 0.4679 r:0.7590
ru_en Dev loss: 0.4886 r:0.7416
Current avg r:0.6153 Best avg r: 0.6393
22:20:50,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:20,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:50,853 root INFO Epoch 4 Global steps: 43400 Train loss: 0.3178
en_de Dev loss: 0.8472 r:0.2509
en_zh Dev loss: 0.7738 r:0.4572
ro_en Dev loss: 0.3792 r:0.8140
et_en Dev loss: 0.4751 r:0.6871
si_en Dev loss: 0.7832 r:0.5915
ne_en Dev loss: 0.4608 r:0.7586
ru_en Dev loss: 0.4807 r:0.7394
Current avg r:0.6141 Best avg r: 0.6393
22:28:20,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:50,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:20,937 root INFO Epoch 4 Global steps: 44100 Train loss: 0.3012
en_de Dev loss: 0.8596 r:0.2513
en_zh Dev loss: 0.8045 r:0.4599
ro_en Dev loss: 0.3625 r:0.8116
et_en Dev loss: 0.4546 r:0.6745
si_en Dev loss: 0.8263 r:0.5856
ne_en Dev loss: 0.5765 r:0.7604
ru_en Dev loss: 0.4872 r:0.7362
Current avg r:0.6114 Best avg r: 0.6393
22:35:51,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:21,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:51,70 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2953
en_de Dev loss: 0.8461 r:0.2548
en_zh Dev loss: 0.7627 r:0.4597
ro_en Dev loss: 0.3548 r:0.8136
et_en Dev loss: 0.4812 r:0.6794
si_en Dev loss: 0.7124 r:0.5914
ne_en Dev loss: 0.4280 r:0.7609
ru_en Dev loss: 0.4555 r:0.7381
Current avg r:0.6140 Best avg r: 0.6393
22:43:21,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:51,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:21,740 root INFO Epoch 4 Global steps: 45500 Train loss: 0.3065
en_de Dev loss: 0.8881 r:0.2428
en_zh Dev loss: 0.8213 r:0.4571
ro_en Dev loss: 0.4326 r:0.8130
et_en Dev loss: 0.5121 r:0.6768
si_en Dev loss: 1.0748 r:0.5757
ne_en Dev loss: 0.6175 r:0.7564
ru_en Dev loss: 0.5372 r:0.7314
Current avg r:0.6076 Best avg r: 0.6393
22:50:52,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:23,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:53,201 root INFO Epoch 4 Global steps: 46200 Train loss: 0.3007
en_de Dev loss: 0.8409 r:0.2398
en_zh Dev loss: 0.6999 r:0.4759
ro_en Dev loss: 0.3173 r:0.8186
et_en Dev loss: 0.4546 r:0.6902
si_en Dev loss: 0.6549 r:0.5980
ne_en Dev loss: 0.3693 r:0.7558
ru_en Dev loss: 0.3823 r:0.7557
Current avg r:0.6191 Best avg r: 0.6393
22:58:23,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:53,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:24,32 root INFO Epoch 4 Global steps: 46900 Train loss: 0.3138
en_de Dev loss: 0.8229 r:0.2729
en_zh Dev loss: 0.7320 r:0.4682
ro_en Dev loss: 0.3315 r:0.8204
et_en Dev loss: 0.4443 r:0.6774
si_en Dev loss: 0.8013 r:0.5865
ne_en Dev loss: 0.5709 r:0.7609
ru_en Dev loss: 0.4832 r:0.7284
Current avg r:0.6164 Best avg r: 0.6393
23:05:55,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:25,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:55,468 root INFO Epoch 4 Global steps: 47600 Train loss: 0.3048
en_de Dev loss: 0.8452 r:0.2542
en_zh Dev loss: 0.8047 r:0.4474
ro_en Dev loss: 0.3739 r:0.8146
et_en Dev loss: 0.4791 r:0.6634
si_en Dev loss: 0.8899 r:0.5737
ne_en Dev loss: 0.6335 r:0.7534
ru_en Dev loss: 0.5190 r:0.7204
Current avg r:0.6039 Best avg r: 0.6393
23:13:25,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:55,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:25,670 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2905
en_de Dev loss: 0.8432 r:0.2375
en_zh Dev loss: 0.7464 r:0.4565
ro_en Dev loss: 0.3567 r:0.8139
et_en Dev loss: 0.4728 r:0.6689
si_en Dev loss: 0.7461 r:0.5870
ne_en Dev loss: 0.4259 r:0.7627
ru_en Dev loss: 0.4450 r:0.7290
Current avg r:0.6079 Best avg r: 0.6393
23:20:55,558 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:25,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:55,705 root INFO Epoch 4 Global steps: 49000 Train loss: 0.3023
en_de Dev loss: 0.8622 r:0.2161
en_zh Dev loss: 0.7916 r:0.4462
ro_en Dev loss: 0.3153 r:0.8201
et_en Dev loss: 0.4298 r:0.6728
si_en Dev loss: 0.7641 r:0.5805
ne_en Dev loss: 0.5168 r:0.7588
ru_en Dev loss: 0.4950 r:0.7185
Current avg r:0.6019 Best avg r: 0.6393
23:28:25,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:55,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:25,327 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2943
en_de Dev loss: 0.9102 r:0.1985
en_zh Dev loss: 0.8499 r:0.4609
ro_en Dev loss: 0.4053 r:0.8080
et_en Dev loss: 0.5106 r:0.6569
si_en Dev loss: 0.9302 r:0.5825
ne_en Dev loss: 0.5289 r:0.7545
ru_en Dev loss: 0.5170 r:0.7298
Current avg r:0.5987 Best avg r: 0.6393
23:35:55,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:25,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:55,363 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2909
en_de Dev loss: 0.8608 r:0.2233
en_zh Dev loss: 0.8181 r:0.4559
ro_en Dev loss: 0.3631 r:0.8161
et_en Dev loss: 0.4758 r:0.6752
si_en Dev loss: 0.8134 r:0.5903
ne_en Dev loss: 0.4198 r:0.7554
ru_en Dev loss: 0.5069 r:0.7329
Current avg r:0.6070 Best avg r: 0.6393
23:43:25,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:56,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:26,117 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2972
en_de Dev loss: 0.8588 r:0.2173
en_zh Dev loss: 0.7704 r:0.4648
ro_en Dev loss: 0.3881 r:0.8143
et_en Dev loss: 0.4864 r:0.6672
si_en Dev loss: 0.9108 r:0.5879
ne_en Dev loss: 0.5325 r:0.7569
ru_en Dev loss: 0.4782 r:0.7420
Current avg r:0.6072 Best avg r: 0.6393
23:50:56,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:26,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:56,369 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2960
en_de Dev loss: 0.8699 r:0.2010
en_zh Dev loss: 0.8039 r:0.4506
ro_en Dev loss: 0.3751 r:0.8169
et_en Dev loss: 0.4993 r:0.6773
si_en Dev loss: 0.8005 r:0.5924
ne_en Dev loss: 0.3936 r:0.7628
ru_en Dev loss: 0.4573 r:0.7441
Current avg r:0.6064 Best avg r: 0.6393
23:58:26,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:56,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:26,507 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2943
en_de Dev loss: 0.8631 r:0.2001
en_zh Dev loss: 0.7779 r:0.4638
ro_en Dev loss: 0.3560 r:0.8201
et_en Dev loss: 0.5022 r:0.6779
si_en Dev loss: 0.7600 r:0.5922
ne_en Dev loss: 0.3718 r:0.7582
ru_en Dev loss: 0.4330 r:0.7511
Current avg r:0.6091 Best avg r: 0.6393
00:05:58,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:28,174 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:58,200 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2611
en_de Dev loss: 0.8805 r:0.1971
en_zh Dev loss: 0.8011 r:0.4558
ro_en Dev loss: 0.3941 r:0.8149
et_en Dev loss: 0.5209 r:0.6584
si_en Dev loss: 0.9427 r:0.5854
ne_en Dev loss: 0.5181 r:0.7571
ru_en Dev loss: 0.5126 r:0.7314
Current avg r:0.6000 Best avg r: 0.6393
00:13:28,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:58,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:16:28,449 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2653
en_de Dev loss: 0.8521 r:0.2394
en_zh Dev loss: 0.7795 r:0.4617
ro_en Dev loss: 0.3961 r:0.8166
et_en Dev loss: 0.5129 r:0.6726
si_en Dev loss: 0.8523 r:0.5875
ne_en Dev loss: 0.4399 r:0.7578
ru_en Dev loss: 0.4656 r:0.7475
Current avg r:0.6118 Best avg r: 0.6393
00:20:58,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:28,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:58,670 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2645
en_de Dev loss: 0.8650 r:0.2064
en_zh Dev loss: 0.7772 r:0.4525
ro_en Dev loss: 0.3835 r:0.8172
et_en Dev loss: 0.4755 r:0.6746
si_en Dev loss: 0.8623 r:0.5877
ne_en Dev loss: 0.4303 r:0.7590
ru_en Dev loss: 0.4592 r:0.7437
Current avg r:0.6059 Best avg r: 0.6393
00:28:28,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:59,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:29,331 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2650
en_de Dev loss: 0.8550 r:0.2113
en_zh Dev loss: 0.7631 r:0.4622
ro_en Dev loss: 0.3857 r:0.8143
et_en Dev loss: 0.4698 r:0.6746
si_en Dev loss: 0.8960 r:0.5889
ne_en Dev loss: 0.4653 r:0.7564
ru_en Dev loss: 0.5203 r:0.7252
Current avg r:0.6047 Best avg r: 0.6393
00:36:00,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:30,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:00,683 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2580
en_de Dev loss: 0.8703 r:0.2080
en_zh Dev loss: 0.7528 r:0.4663
ro_en Dev loss: 0.3692 r:0.8160
et_en Dev loss: 0.4948 r:0.6776
si_en Dev loss: 0.8031 r:0.5874
ne_en Dev loss: 0.4243 r:0.7454
ru_en Dev loss: 0.4166 r:0.7563
Current avg r:0.6082 Best avg r: 0.6393
00:43:31,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:01,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:31,939 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2609
en_de Dev loss: 0.8642 r:0.2211
en_zh Dev loss: 0.7701 r:0.4675
ro_en Dev loss: 0.4121 r:0.8111
et_en Dev loss: 0.5245 r:0.6737
si_en Dev loss: 0.8954 r:0.5765
ne_en Dev loss: 0.4932 r:0.7452
ru_en Dev loss: 0.4616 r:0.7458
Current avg r:0.6058 Best avg r: 0.6393
00:51:02,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:33,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:03,221 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2639
en_de Dev loss: 0.8534 r:0.2175
en_zh Dev loss: 0.7389 r:0.4790
ro_en Dev loss: 0.3398 r:0.8204
et_en Dev loss: 0.4564 r:0.6741
si_en Dev loss: 0.8221 r:0.5809
ne_en Dev loss: 0.4864 r:0.7447
ru_en Dev loss: 0.4357 r:0.7510
Current avg r:0.6097 Best avg r: 0.6393
00:58:33,121 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:03,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:33,234 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2686
en_de Dev loss: 0.8752 r:0.2073
en_zh Dev loss: 0.7264 r:0.4722
ro_en Dev loss: 0.3660 r:0.8101
et_en Dev loss: 0.4853 r:0.6553
si_en Dev loss: 0.8339 r:0.5728
ne_en Dev loss: 0.4798 r:0.7456
ru_en Dev loss: 0.4742 r:0.7226
Current avg r:0.5980 Best avg r: 0.6393
01:06:03,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:33,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:09:03,248 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2449
en_de Dev loss: 0.8799 r:0.2203
en_zh Dev loss: 0.8150 r:0.4600
ro_en Dev loss: 0.3995 r:0.8105
et_en Dev loss: 0.5007 r:0.6570
si_en Dev loss: 1.0038 r:0.5680
ne_en Dev loss: 0.5663 r:0.7373
ru_en Dev loss: 0.5425 r:0.7144
Current avg r:0.5954 Best avg r: 0.6393
01:13:33,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:03,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:33,347 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2383
en_de Dev loss: 0.8536 r:0.2294
en_zh Dev loss: 0.7399 r:0.4742
ro_en Dev loss: 0.3518 r:0.8182
et_en Dev loss: 0.4852 r:0.6809
si_en Dev loss: 0.7735 r:0.5854
ne_en Dev loss: 0.4276 r:0.7389
ru_en Dev loss: 0.4379 r:0.7440
Current avg r:0.6101 Best avg r: 0.6393
01:21:03,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:22:33,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:03,606 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2386
en_de Dev loss: 0.8632 r:0.2037
en_zh Dev loss: 0.7338 r:0.4692
ro_en Dev loss: 0.3305 r:0.8137
et_en Dev loss: 0.4450 r:0.6732
si_en Dev loss: 0.7216 r:0.5792
ne_en Dev loss: 0.4502 r:0.7440
ru_en Dev loss: 0.4265 r:0.7420
Current avg r:0.6036 Best avg r: 0.6393
01:28:33,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:03,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:31:33,702 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2645
en_de Dev loss: 0.8705 r:0.2102
en_zh Dev loss: 0.7804 r:0.4562
ro_en Dev loss: 0.3758 r:0.8106
et_en Dev loss: 0.4757 r:0.6713
si_en Dev loss: 0.8026 r:0.5723
ne_en Dev loss: 0.4391 r:0.7483
ru_en Dev loss: 0.4316 r:0.7479
Current avg r:0.6024 Best avg r: 0.6393
01:36:03,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:37:33,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:03,816 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2569
en_de Dev loss: 0.8739 r:0.2225
en_zh Dev loss: 0.7964 r:0.4584
ro_en Dev loss: 0.3713 r:0.8179
et_en Dev loss: 0.4620 r:0.6804
si_en Dev loss: 0.8690 r:0.5744
ne_en Dev loss: 0.5304 r:0.7551
ru_en Dev loss: 0.4811 r:0.7425
Current avg r:0.6073 Best avg r: 0.6393
01:43:34,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:45:04,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:46:34,740 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2579
en_de Dev loss: 0.8897 r:0.2078
en_zh Dev loss: 0.8306 r:0.4637
ro_en Dev loss: 0.3877 r:0.8129
et_en Dev loss: 0.4899 r:0.6679
si_en Dev loss: 0.8849 r:0.5711
ne_en Dev loss: 0.5426 r:0.7541
ru_en Dev loss: 0.5278 r:0.7207
Current avg r:0.5997 Best avg r: 0.6393
01:51:07,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:52:38,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:54:10,118 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2577
en_de Dev loss: 0.8808 r:0.2154
en_zh Dev loss: 0.8572 r:0.4493
ro_en Dev loss: 0.3920 r:0.8131
et_en Dev loss: 0.4994 r:0.6686
si_en Dev loss: 0.8564 r:0.5780
ne_en Dev loss: 0.4760 r:0.7491
ru_en Dev loss: 0.4813 r:0.7334
Current avg r:0.6010 Best avg r: 0.6393
01:58:45,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:00:17,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:01:47,986 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2236
en_de Dev loss: 0.8633 r:0.2223
en_zh Dev loss: 0.8229 r:0.4461
ro_en Dev loss: 0.4201 r:0.8120
et_en Dev loss: 0.5007 r:0.6692
si_en Dev loss: 0.9005 r:0.5714
ne_en Dev loss: 0.5295 r:0.7401
ru_en Dev loss: 0.5135 r:0.7298
Current avg r:0.5987 Best avg r: 0.6393
02:06:22,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:07:53,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:09:23,922 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2325
en_de Dev loss: 0.8725 r:0.2178
en_zh Dev loss: 0.8364 r:0.4403
ro_en Dev loss: 0.3848 r:0.8163
et_en Dev loss: 0.5039 r:0.6681
si_en Dev loss: 0.8588 r:0.5702
ne_en Dev loss: 0.4611 r:0.7401
ru_en Dev loss: 0.4650 r:0.7328
Current avg r:0.5979 Best avg r: 0.6393
02:13:58,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:15:29,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:17:00,45 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2252
en_de Dev loss: 0.8711 r:0.2210
en_zh Dev loss: 0.7947 r:0.4634
ro_en Dev loss: 0.3687 r:0.8182
et_en Dev loss: 0.4795 r:0.6720
si_en Dev loss: 0.8674 r:0.5761
ne_en Dev loss: 0.4523 r:0.7484
ru_en Dev loss: 0.4574 r:0.7487
Current avg r:0.6068 Best avg r: 0.6393
02:21:31,153 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:23:01,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:24:31,450 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2302
en_de Dev loss: 0.8774 r:0.2182
en_zh Dev loss: 0.8348 r:0.4543
ro_en Dev loss: 0.3703 r:0.8147
et_en Dev loss: 0.4795 r:0.6779
si_en Dev loss: 0.8478 r:0.5756
ne_en Dev loss: 0.5023 r:0.7419
ru_en Dev loss: 0.4734 r:0.7428
Current avg r:0.6036 Best avg r: 0.6393
02:29:01,564 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:30:31,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:32:01,759 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2398
en_de Dev loss: 0.8625 r:0.2073
en_zh Dev loss: 0.7509 r:0.4678
ro_en Dev loss: 0.3392 r:0.8168
et_en Dev loss: 0.4442 r:0.6746
si_en Dev loss: 0.8047 r:0.5754
ne_en Dev loss: 0.4541 r:0.7420
ru_en Dev loss: 0.4317 r:0.7472
Current avg r:0.6044 Best avg r: 0.6393
02:36:31,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:38:01,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:39:32,104 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2267
en_de Dev loss: 0.8767 r:0.2204
en_zh Dev loss: 0.7510 r:0.4753
ro_en Dev loss: 0.3490 r:0.8145
et_en Dev loss: 0.4559 r:0.6781
si_en Dev loss: 0.8066 r:0.5766
ne_en Dev loss: 0.5486 r:0.7388
ru_en Dev loss: 0.4269 r:0.7500
Current avg r:0.6077 Best avg r: 0.6393
02:44:02,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:45:32,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:47:02,445 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2272
en_de Dev loss: 0.8787 r:0.2086
en_zh Dev loss: 0.7707 r:0.4580
ro_en Dev loss: 0.3594 r:0.8147
et_en Dev loss: 0.4820 r:0.6631
si_en Dev loss: 0.8737 r:0.5660
ne_en Dev loss: 0.5340 r:0.7285
ru_en Dev loss: 0.4726 r:0.7319
Current avg r:0.5958 Best avg r: 0.6393
02:51:32,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:53:02,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:54:32,907 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2291
en_de Dev loss: 0.8874 r:0.2079
en_zh Dev loss: 0.8583 r:0.4368
ro_en Dev loss: 0.3549 r:0.8206
et_en Dev loss: 0.4479 r:0.6765
si_en Dev loss: 0.8674 r:0.5709
ne_en Dev loss: 0.5602 r:0.7453
ru_en Dev loss: 0.4737 r:0.7397
Current avg r:0.5997 Best avg r: 0.6393
02:59:02,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:00:32,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:02:03,69 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2119
en_de Dev loss: 0.8848 r:0.2287
en_zh Dev loss: 0.7936 r:0.4626
ro_en Dev loss: 0.3649 r:0.8192
et_en Dev loss: 0.4690 r:0.6805
si_en Dev loss: 0.8786 r:0.5653
ne_en Dev loss: 0.4887 r:0.7411
ru_en Dev loss: 0.5056 r:0.7416
Current avg r:0.6056 Best avg r: 0.6393
03:06:33,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:08:02,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:09:32,912 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2173
en_de Dev loss: 0.8589 r:0.2123
en_zh Dev loss: 0.7978 r:0.4655
ro_en Dev loss: 0.3870 r:0.8161
et_en Dev loss: 0.5001 r:0.6660
si_en Dev loss: 0.9308 r:0.5639
ne_en Dev loss: 0.4872 r:0.7416
ru_en Dev loss: 0.5292 r:0.7195
Current avg r:0.5978 Best avg r: 0.6393
03:14:02,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:15:33,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:17:03,125 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2027
en_de Dev loss: 0.9070 r:0.1843
en_zh Dev loss: 0.8814 r:0.4485
ro_en Dev loss: 0.4205 r:0.8168
et_en Dev loss: 0.4931 r:0.6686
si_en Dev loss: 0.9984 r:0.5646
ne_en Dev loss: 0.5750 r:0.7367
ru_en Dev loss: 0.5125 r:0.7426
Current avg r:0.5946 Best avg r: 0.6393
03:21:36,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:23:07,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:24:38,932 root INFO Epoch 6 Global steps: 71400 Train loss: 0.2210
en_de Dev loss: 0.8792 r:0.2069
en_zh Dev loss: 0.7724 r:0.4562
ro_en Dev loss: 0.3488 r:0.8178
et_en Dev loss: 0.4688 r:0.6742
si_en Dev loss: 0.7552 r:0.5788
ne_en Dev loss: 0.4502 r:0.7371
ru_en Dev loss: 0.4548 r:0.7349
Current avg r:0.6008 Best avg r: 0.6393
03:29:14,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:30:45,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:32:16,187 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2195
en_de Dev loss: 0.8821 r:0.2256
en_zh Dev loss: 0.7922 r:0.4559
ro_en Dev loss: 0.3376 r:0.8165
et_en Dev loss: 0.4444 r:0.6781
si_en Dev loss: 0.7579 r:0.5768
ne_en Dev loss: 0.5076 r:0.7336
ru_en Dev loss: 0.4485 r:0.7473
Current avg r:0.6048 Best avg r: 0.6393
03:36:51,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:38:22,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:39:53,523 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2240
en_de Dev loss: 0.8739 r:0.2512
en_zh Dev loss: 0.7949 r:0.4683
ro_en Dev loss: 0.3963 r:0.8129
et_en Dev loss: 0.4823 r:0.6653
si_en Dev loss: 0.8804 r:0.5784
ne_en Dev loss: 0.5898 r:0.7387
ru_en Dev loss: 0.4753 r:0.7448
Current avg r:0.6085 Best avg r: 0.6393
03:44:25,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:45:55,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:47:25,408 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2114
en_de Dev loss: 0.9040 r:0.2172
en_zh Dev loss: 0.8539 r:0.4477
ro_en Dev loss: 0.3879 r:0.8152
et_en Dev loss: 0.4697 r:0.6717
si_en Dev loss: 0.8265 r:0.5801
ne_en Dev loss: 0.5624 r:0.7384
ru_en Dev loss: 0.4967 r:0.7327
Current avg r:0.6004 Best avg r: 0.6393
03:51:57,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:53:28,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:54:58,273 root INFO Epoch 7 Global steps: 74200 Train loss: 0.2017
en_de Dev loss: 0.8743 r:0.2318
en_zh Dev loss: 0.7877 r:0.4677
ro_en Dev loss: 0.3747 r:0.8165
et_en Dev loss: 0.4699 r:0.6752
si_en Dev loss: 0.8856 r:0.5790
ne_en Dev loss: 0.6101 r:0.7286
ru_en Dev loss: 0.5030 r:0.7360
Current avg r:0.6050 Best avg r: 0.6393
03:59:29,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:00:59,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:02:29,492 root INFO Epoch 7 Global steps: 74900 Train loss: 0.2062
en_de Dev loss: 0.9065 r:0.2202
en_zh Dev loss: 0.8286 r:0.4583
ro_en Dev loss: 0.3567 r:0.8141
et_en Dev loss: 0.4662 r:0.6805
si_en Dev loss: 0.7880 r:0.5722
ne_en Dev loss: 0.4303 r:0.7340
ru_en Dev loss: 0.4878 r:0.7395
Current avg r:0.6027 Best avg r: 0.6393
04:07:00,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:08:30,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:10:00,672 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1974
en_de Dev loss: 0.9023 r:0.2228
en_zh Dev loss: 0.8524 r:0.4603
ro_en Dev loss: 0.4192 r:0.8129
et_en Dev loss: 0.5059 r:0.6682
si_en Dev loss: 0.9693 r:0.5659
ne_en Dev loss: 0.5767 r:0.7333
ru_en Dev loss: 0.5295 r:0.7368
Current avg r:0.6000 Best avg r: 0.6393
04:14:31,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:16:02,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:17:32,368 root INFO Epoch 7 Global steps: 76300 Train loss: 0.2026
en_de Dev loss: 0.8807 r:0.1958
en_zh Dev loss: 0.8692 r:0.4441
ro_en Dev loss: 0.4042 r:0.8093
et_en Dev loss: 0.4952 r:0.6556
si_en Dev loss: 0.9326 r:0.5559
ne_en Dev loss: 0.6109 r:0.7186
ru_en Dev loss: 0.5101 r:0.7256
Current avg r:0.5864 Best avg r: 0.6393
04:22:03,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:23:33,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:25:04,60 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1990
en_de Dev loss: 0.8710 r:0.2154
en_zh Dev loss: 0.8082 r:0.4559
ro_en Dev loss: 0.3838 r:0.8083
et_en Dev loss: 0.4770 r:0.6607
si_en Dev loss: 0.9579 r:0.5658
ne_en Dev loss: 0.7323 r:0.7246
ru_en Dev loss: 0.4905 r:0.7289
Current avg r:0.5942 Best avg r: 0.6393
04:29:35,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:31:05,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:32:35,735 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1791
en_de Dev loss: 0.9108 r:0.1818
en_zh Dev loss: 0.8246 r:0.4493
ro_en Dev loss: 0.3913 r:0.8102
et_en Dev loss: 0.4809 r:0.6573
si_en Dev loss: 0.9087 r:0.5601
ne_en Dev loss: 0.6262 r:0.7267
ru_en Dev loss: 0.4970 r:0.7312
Current avg r:0.5881 Best avg r: 0.6393
04:37:06,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:38:37,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:40:07,358 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1970
en_de Dev loss: 0.8968 r:0.1866
en_zh Dev loss: 0.8423 r:0.4454
ro_en Dev loss: 0.3828 r:0.8128
et_en Dev loss: 0.4625 r:0.6715
si_en Dev loss: 0.9391 r:0.5689
ne_en Dev loss: 0.5907 r:0.7324
ru_en Dev loss: 0.5081 r:0.7261
Current avg r:0.5920 Best avg r: 0.6393
04:44:38,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:46:08,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:47:39,49 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1996
en_de Dev loss: 0.8806 r:0.2053
en_zh Dev loss: 0.7978 r:0.4558
ro_en Dev loss: 0.3851 r:0.8163
et_en Dev loss: 0.4895 r:0.6761
si_en Dev loss: 0.8141 r:0.5715
ne_en Dev loss: 0.4549 r:0.7286
ru_en Dev loss: 0.4247 r:0.7543
Current avg r:0.6011 Best avg r: 0.6393
04:52:13,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:53:44,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:55:15,440 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1991
en_de Dev loss: 0.9089 r:0.1799
en_zh Dev loss: 0.9488 r:0.4236
ro_en Dev loss: 0.4324 r:0.8149
et_en Dev loss: 0.5181 r:0.6558
si_en Dev loss: 1.1125 r:0.5447
ne_en Dev loss: 0.6375 r:0.7222
ru_en Dev loss: 0.5294 r:0.7279
Current avg r:0.5813 Best avg r: 0.6393
04:59:49,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:01:20,597 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:02:51,556 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1848
en_de Dev loss: 0.8947 r:0.2060
en_zh Dev loss: 0.8056 r:0.4582
ro_en Dev loss: 0.3716 r:0.8192
et_en Dev loss: 0.4526 r:0.6751
si_en Dev loss: 0.9072 r:0.5613
ne_en Dev loss: 0.5829 r:0.7345
ru_en Dev loss: 0.4479 r:0.7451
Current avg r:0.5999 Best avg r: 0.6393
05:07:25,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:08:56,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:10:26,793 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1874
en_de Dev loss: 0.9003 r:0.2165
en_zh Dev loss: 0.8377 r:0.4500
ro_en Dev loss: 0.3558 r:0.8200
et_en Dev loss: 0.4534 r:0.6739
si_en Dev loss: 0.9228 r:0.5531
ne_en Dev loss: 0.5649 r:0.7282
ru_en Dev loss: 0.4962 r:0.7373
Current avg r:0.5970 Best avg r: 0.6393
05:15:00,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:16:30,391 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:00,619 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1877
en_de Dev loss: 0.8807 r:0.2193
en_zh Dev loss: 0.8089 r:0.4580
ro_en Dev loss: 0.3507 r:0.8205
et_en Dev loss: 0.4643 r:0.6785
si_en Dev loss: 0.8785 r:0.5602
ne_en Dev loss: 0.4873 r:0.7279
ru_en Dev loss: 0.4284 r:0.7529
Current avg r:0.6025 Best avg r: 0.6393
05:22:31,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:24:02,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:32,266 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1913
en_de Dev loss: 0.8982 r:0.2207
en_zh Dev loss: 0.8543 r:0.4509
ro_en Dev loss: 0.3950 r:0.8145
et_en Dev loss: 0.4887 r:0.6761
si_en Dev loss: 0.9288 r:0.5558
ne_en Dev loss: 0.5776 r:0.7279
ru_en Dev loss: 0.4628 r:0.7467
Current avg r:0.5989 Best avg r: 0.6393
05:30:02,522 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:31:32,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:33:02,819 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1855
en_de Dev loss: 0.9012 r:0.2071
en_zh Dev loss: 0.8805 r:0.4461
ro_en Dev loss: 0.3752 r:0.8157
et_en Dev loss: 0.4783 r:0.6715
si_en Dev loss: 0.9092 r:0.5531
ne_en Dev loss: 0.5566 r:0.7201
ru_en Dev loss: 0.5193 r:0.7229
Current avg r:0.5909 Best avg r: 0.6393
05:37:32,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:39:03,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:40:33,137 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1924
en_de Dev loss: 0.8839 r:0.2223
en_zh Dev loss: 0.8152 r:0.4674
ro_en Dev loss: 0.3766 r:0.8159
et_en Dev loss: 0.4615 r:0.6782
si_en Dev loss: 0.9741 r:0.5545
ne_en Dev loss: 0.5333 r:0.7320
ru_en Dev loss: 0.4816 r:0.7312
Current avg r:0.6002 Best avg r: 0.6393
05:45:05,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:46:35,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:48:06,205 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1717
en_de Dev loss: 0.8886 r:0.2180
en_zh Dev loss: 0.8382 r:0.4538
ro_en Dev loss: 0.4011 r:0.8157
et_en Dev loss: 0.4794 r:0.6727
si_en Dev loss: 0.9800 r:0.5500
ne_en Dev loss: 0.6224 r:0.7283
ru_en Dev loss: 0.5060 r:0.7326
Current avg r:0.5959 Best avg r: 0.6393
05:52:37,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:07,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:55:38,13 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1681
en_de Dev loss: 0.8978 r:0.2133
en_zh Dev loss: 0.7962 r:0.4676
ro_en Dev loss: 0.3913 r:0.8146
et_en Dev loss: 0.4573 r:0.6820
si_en Dev loss: 0.9296 r:0.5531
ne_en Dev loss: 0.5504 r:0.7300
ru_en Dev loss: 0.4648 r:0.7459
Current avg r:0.6009 Best avg r: 0.6393
06:00:08,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:01:38,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:03:09,66 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1669
en_de Dev loss: 0.8852 r:0.2017
en_zh Dev loss: 0.8186 r:0.4531
ro_en Dev loss: 0.3660 r:0.8156
et_en Dev loss: 0.4429 r:0.6813
si_en Dev loss: 0.8913 r:0.5573
ne_en Dev loss: 0.5881 r:0.7304
ru_en Dev loss: 0.4697 r:0.7440
Current avg r:0.5976 Best avg r: 0.6393
06:07:39,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:09,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:10:39,588 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1732
en_de Dev loss: 0.9103 r:0.2136
en_zh Dev loss: 0.8260 r:0.4538
ro_en Dev loss: 0.3988 r:0.8153
et_en Dev loss: 0.4684 r:0.6739
si_en Dev loss: 0.9429 r:0.5579
ne_en Dev loss: 0.6310 r:0.7290
ru_en Dev loss: 0.5133 r:0.7345
Current avg r:0.5969 Best avg r: 0.6393
06:15:09,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:16:39,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:09,865 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1717
en_de Dev loss: 0.8804 r:0.2167
en_zh Dev loss: 0.8147 r:0.4529
ro_en Dev loss: 0.3921 r:0.8139
et_en Dev loss: 0.4637 r:0.6749
si_en Dev loss: 0.9363 r:0.5599
ne_en Dev loss: 0.7028 r:0.7213
ru_en Dev loss: 0.5055 r:0.7396
Current avg r:0.5970 Best avg r: 0.6393
06:22:40,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:24:11,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:25:42,390 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1643
en_de Dev loss: 0.9045 r:0.2003
en_zh Dev loss: 0.7931 r:0.4606
ro_en Dev loss: 0.3630 r:0.8147
et_en Dev loss: 0.4564 r:0.6755
si_en Dev loss: 0.8652 r:0.5623
ne_en Dev loss: 0.6698 r:0.7247
ru_en Dev loss: 0.4593 r:0.7420
Current avg r:0.5972 Best avg r: 0.6393
06:30:17,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:31:48,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:33:19,112 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1661
en_de Dev loss: 0.8788 r:0.2193
en_zh Dev loss: 0.7908 r:0.4658
ro_en Dev loss: 0.3926 r:0.8143
et_en Dev loss: 0.4743 r:0.6729
si_en Dev loss: 0.9812 r:0.5535
ne_en Dev loss: 0.6034 r:0.7237
ru_en Dev loss: 0.5046 r:0.7350
Current avg r:0.5978 Best avg r: 0.6393
06:37:53,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:39:24,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:40:55,46 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1792
en_de Dev loss: 0.9077 r:0.2121
en_zh Dev loss: 0.8616 r:0.4651
ro_en Dev loss: 0.3995 r:0.8151
et_en Dev loss: 0.4786 r:0.6810
si_en Dev loss: 0.9810 r:0.5563
ne_en Dev loss: 0.5971 r:0.7352
ru_en Dev loss: 0.4665 r:0.7483
Current avg r:0.6019 Best avg r: 0.6393
06:45:29,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:00,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:48:30,616 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1655
en_de Dev loss: 0.9189 r:0.1960
en_zh Dev loss: 0.8136 r:0.4753
ro_en Dev loss: 0.3818 r:0.8147
et_en Dev loss: 0.4759 r:0.6733
si_en Dev loss: 0.9735 r:0.5561
ne_en Dev loss: 0.5952 r:0.7308
ru_en Dev loss: 0.4673 r:0.7475
Current avg r:0.5991 Best avg r: 0.6393
06:53:00,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:30,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:01,167 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1639
en_de Dev loss: 0.9053 r:0.2055
en_zh Dev loss: 0.7900 r:0.4754
ro_en Dev loss: 0.3525 r:0.8188
et_en Dev loss: 0.4612 r:0.6823
si_en Dev loss: 0.8193 r:0.5654
ne_en Dev loss: 0.5414 r:0.7225
ru_en Dev loss: 0.4624 r:0.7460
Current avg r:0.6023 Best avg r: 0.6393
07:00:32,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:02,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:03:32,982 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1641
en_de Dev loss: 0.9264 r:0.2108
en_zh Dev loss: 0.8846 r:0.4677
ro_en Dev loss: 0.4254 r:0.8141
et_en Dev loss: 0.5137 r:0.6610
si_en Dev loss: 0.9980 r:0.5567
ne_en Dev loss: 0.7303 r:0.7208
ru_en Dev loss: 0.5428 r:0.7428
Current avg r:0.5963 Best avg r: 0.6393
07:08:04,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:09:34,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:11:04,842 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1661
en_de Dev loss: 0.9060 r:0.2251
en_zh Dev loss: 0.8439 r:0.4690
ro_en Dev loss: 0.3550 r:0.8154
et_en Dev loss: 0.4505 r:0.6736
si_en Dev loss: 0.8761 r:0.5565
ne_en Dev loss: 0.5522 r:0.7271
ru_en Dev loss: 0.4380 r:0.7565
Current avg r:0.6033 Best avg r: 0.6393
07:15:36,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:06,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:18:36,878 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1601
en_de Dev loss: 0.9207 r:0.2168
en_zh Dev loss: 0.8468 r:0.4760
ro_en Dev loss: 0.3967 r:0.8180
et_en Dev loss: 0.4809 r:0.6769
si_en Dev loss: 0.9355 r:0.5594
ne_en Dev loss: 0.5997 r:0.7240
ru_en Dev loss: 0.5036 r:0.7430
Current avg r:0.6020 Best avg r: 0.6393
07:23:08,355 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:24:38,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:08,906 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1572
en_de Dev loss: 0.9032 r:0.2115
en_zh Dev loss: 0.8217 r:0.4775
ro_en Dev loss: 0.3880 r:0.8184
et_en Dev loss: 0.4672 r:0.6734
si_en Dev loss: 0.9379 r:0.5648
ne_en Dev loss: 0.6372 r:0.7303
ru_en Dev loss: 0.4816 r:0.7365
Current avg r:0.6017 Best avg r: 0.6393
07:30:40,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:10,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:33:41,186 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1593
en_de Dev loss: 0.9399 r:0.2010
en_zh Dev loss: 0.8608 r:0.4639
ro_en Dev loss: 0.3710 r:0.8180
et_en Dev loss: 0.4677 r:0.6702
si_en Dev loss: 0.9236 r:0.5582
ne_en Dev loss: 0.5671 r:0.7257
ru_en Dev loss: 0.4803 r:0.7433
Current avg r:0.5972 Best avg r: 0.6393
07:38:17,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:39:48,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:41:19,631 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1517
en_de Dev loss: 0.9005 r:0.1932
en_zh Dev loss: 0.8209 r:0.4652
ro_en Dev loss: 0.3620 r:0.8167
et_en Dev loss: 0.4650 r:0.6739
si_en Dev loss: 0.9304 r:0.5493
ne_en Dev loss: 0.5434 r:0.7198
ru_en Dev loss: 0.4538 r:0.7442
Current avg r:0.5946 Best avg r: 0.6393
07:45:53,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:24,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:48:55,583 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1396
en_de Dev loss: 0.8979 r:0.1929
en_zh Dev loss: 0.8302 r:0.4569
ro_en Dev loss: 0.3663 r:0.8146
et_en Dev loss: 0.4574 r:0.6714
si_en Dev loss: 0.9613 r:0.5501
ne_en Dev loss: 0.5945 r:0.7196
ru_en Dev loss: 0.4505 r:0.7445
Current avg r:0.5928 Best avg r: 0.6393
07:53:30,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:55:01,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:56:32,598 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1485
en_de Dev loss: 0.9001 r:0.2072
en_zh Dev loss: 0.8121 r:0.4693
ro_en Dev loss: 0.3655 r:0.8188
et_en Dev loss: 0.4492 r:0.6803
si_en Dev loss: 0.8695 r:0.5645
ne_en Dev loss: 0.5313 r:0.7275
ru_en Dev loss: 0.4840 r:0.7455
Current avg r:0.6019 Best avg r: 0.6393
08:01:04,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:34,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:04:04,628 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1520
en_de Dev loss: 0.8999 r:0.2048
en_zh Dev loss: 0.8222 r:0.4678
ro_en Dev loss: 0.4103 r:0.8141
et_en Dev loss: 0.4883 r:0.6636
si_en Dev loss: 1.0406 r:0.5485
ne_en Dev loss: 0.6914 r:0.7206
ru_en Dev loss: 0.5852 r:0.7145
Current avg r:0.5906 Best avg r: 0.6393
08:08:34,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:10:04,812 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:11:35,10 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1453
en_de Dev loss: 0.9231 r:0.1986
en_zh Dev loss: 0.8233 r:0.4699
ro_en Dev loss: 0.3961 r:0.8160
et_en Dev loss: 0.4674 r:0.6732
si_en Dev loss: 0.9200 r:0.5605
ne_en Dev loss: 0.6629 r:0.7232
ru_en Dev loss: 0.4750 r:0.7468
Current avg r:0.5983 Best avg r: 0.6393
08:16:05,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:17:36,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:19:06,413 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1402
en_de Dev loss: 0.9127 r:0.2078
en_zh Dev loss: 0.7813 r:0.4797
ro_en Dev loss: 0.3719 r:0.8194
et_en Dev loss: 0.4744 r:0.6887
si_en Dev loss: 0.8684 r:0.5663
ne_en Dev loss: 0.4845 r:0.7220
ru_en Dev loss: 0.4235 r:0.7634
Current avg r:0.6067 Best avg r: 0.6393
08:23:37,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:25:08,187 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:38,385 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1393
en_de Dev loss: 0.9154 r:0.2129
en_zh Dev loss: 0.8390 r:0.4629
ro_en Dev loss: 0.3894 r:0.8161
et_en Dev loss: 0.4725 r:0.6723
si_en Dev loss: 0.9382 r:0.5566
ne_en Dev loss: 0.6236 r:0.7207
ru_en Dev loss: 0.5099 r:0.7324
Current avg r:0.5963 Best avg r: 0.6393
08:31:09,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:32:40,122 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:34:10,369 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1472
en_de Dev loss: 0.9172 r:0.1901
en_zh Dev loss: 0.7843 r:0.4783
ro_en Dev loss: 0.3652 r:0.8169
et_en Dev loss: 0.4513 r:0.6841
si_en Dev loss: 0.7980 r:0.5654
ne_en Dev loss: 0.4757 r:0.7150
ru_en Dev loss: 0.4279 r:0.7609
Current avg r:0.6015 Best avg r: 0.6393
08:38:41,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:40:12,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:42,261 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1431
en_de Dev loss: 0.9292 r:0.1961
en_zh Dev loss: 0.8855 r:0.4678
ro_en Dev loss: 0.4299 r:0.8125
et_en Dev loss: 0.5008 r:0.6597
si_en Dev loss: 1.0531 r:0.5426
ne_en Dev loss: 0.6587 r:0.7226
ru_en Dev loss: 0.5590 r:0.7257
Current avg r:0.5896 Best avg r: 0.6393
08:46:13,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:44,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:15,659 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1495
en_de Dev loss: 0.8976 r:0.2092
en_zh Dev loss: 0.8012 r:0.4704
ro_en Dev loss: 0.3854 r:0.8168
et_en Dev loss: 0.4555 r:0.6754
si_en Dev loss: 0.8942 r:0.5565
ne_en Dev loss: 0.5701 r:0.7260
ru_en Dev loss: 0.4594 r:0.7478
Current avg r:0.6003 Best avg r: 0.6393
08:53:50,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:55:21,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:52,521 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1453
en_de Dev loss: 0.9083 r:0.1924
en_zh Dev loss: 0.8076 r:0.4642
ro_en Dev loss: 0.3845 r:0.8115
et_en Dev loss: 0.4680 r:0.6663
si_en Dev loss: 0.9383 r:0.5445
ne_en Dev loss: 0.5770 r:0.7176
ru_en Dev loss: 0.4922 r:0.7296
Current avg r:0.5894 Best avg r: 0.6393
09:01:27,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:58,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:04:29,169 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1389
en_de Dev loss: 0.9088 r:0.2036
en_zh Dev loss: 0.8380 r:0.4671
ro_en Dev loss: 0.3797 r:0.8163
et_en Dev loss: 0.4663 r:0.6685
si_en Dev loss: 0.9415 r:0.5525
ne_en Dev loss: 0.6745 r:0.7135
ru_en Dev loss: 0.4548 r:0.7512
Current avg r:0.5961 Best avg r: 0.6393
09:09:03,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:10:34,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:12:04,941 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1403
en_de Dev loss: 0.8864 r:0.1993
en_zh Dev loss: 0.8400 r:0.4580
ro_en Dev loss: 0.3974 r:0.8130
et_en Dev loss: 0.4845 r:0.6621
si_en Dev loss: 1.0059 r:0.5426
ne_en Dev loss: 0.5963 r:0.7194
ru_en Dev loss: 0.4748 r:0.7446
Current avg r:0.5913 Best avg r: 0.6393
09:16:35,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:06,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:36,384 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1415
en_de Dev loss: 0.9006 r:0.1915
en_zh Dev loss: 0.8060 r:0.4665
ro_en Dev loss: 0.3725 r:0.8155
et_en Dev loss: 0.4576 r:0.6742
si_en Dev loss: 0.8526 r:0.5552
ne_en Dev loss: 0.5196 r:0.7212
ru_en Dev loss: 0.4883 r:0.7370
Current avg r:0.5944 Best avg r: 0.6393
09:24:06,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:37,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:27:07,197 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1400
en_de Dev loss: 0.9248 r:0.1946
en_zh Dev loss: 0.7877 r:0.4755
ro_en Dev loss: 0.3610 r:0.8191
et_en Dev loss: 0.4538 r:0.6809
si_en Dev loss: 0.8833 r:0.5593
ne_en Dev loss: 0.5657 r:0.7242
ru_en Dev loss: 0.4128 r:0.7661
Current avg r:0.6028 Best avg r: 0.6393
09:31:39,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:33:09,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:34:39,414 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1298
en_de Dev loss: 0.9245 r:0.1988
en_zh Dev loss: 0.8068 r:0.4784
ro_en Dev loss: 0.3724 r:0.8211
et_en Dev loss: 0.4649 r:0.6839
si_en Dev loss: 0.8794 r:0.5659
ne_en Dev loss: 0.5162 r:0.7202
ru_en Dev loss: 0.4259 r:0.7696
Current avg r:0.6054 Best avg r: 0.6393
09:39:09,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:40:40,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:42:10,455 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1275
en_de Dev loss: 0.9397 r:0.1896
en_zh Dev loss: 0.8623 r:0.4589
ro_en Dev loss: 0.3974 r:0.8145
et_en Dev loss: 0.4887 r:0.6668
si_en Dev loss: 0.9902 r:0.5455
ne_en Dev loss: 0.6586 r:0.7179
ru_en Dev loss: 0.4880 r:0.7481
Current avg r:0.5916 Best avg r: 0.6393
09:46:41,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:12,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:42,182 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1370
en_de Dev loss: 0.9194 r:0.1892
en_zh Dev loss: 0.7672 r:0.4740
ro_en Dev loss: 0.3494 r:0.8174
et_en Dev loss: 0.4610 r:0.6891
si_en Dev loss: 0.8450 r:0.5675
ne_en Dev loss: 0.5113 r:0.7272
ru_en Dev loss: 0.4018 r:0.7715
Current avg r:0.6051 Best avg r: 0.6393
09:54:12,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:42,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:12,783 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1275
en_de Dev loss: 0.9236 r:0.2058
en_zh Dev loss: 0.7773 r:0.4788
ro_en Dev loss: 0.3642 r:0.8188
et_en Dev loss: 0.4458 r:0.6862
si_en Dev loss: 0.8705 r:0.5651
ne_en Dev loss: 0.5692 r:0.7303
ru_en Dev loss: 0.4456 r:0.7573
Current avg r:0.6060 Best avg r: 0.6393
10:01:42,651 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:03:12,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:04:42,746 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1322
en_de Dev loss: 0.9309 r:0.1892
en_zh Dev loss: 0.8386 r:0.4735
ro_en Dev loss: 0.4239 r:0.8104
et_en Dev loss: 0.4932 r:0.6638
si_en Dev loss: 1.0141 r:0.5441
ne_en Dev loss: 0.6623 r:0.7102
ru_en Dev loss: 0.5224 r:0.7370
Current avg r:0.5898 Best avg r: 0.6393
10:09:12,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:42,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:12,450 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1321
en_de Dev loss: 0.9247 r:0.1908
en_zh Dev loss: 0.7777 r:0.4788
ro_en Dev loss: 0.3498 r:0.8200
et_en Dev loss: 0.4304 r:0.6859
si_en Dev loss: 0.8519 r:0.5599
ne_en Dev loss: 0.5037 r:0.7223
ru_en Dev loss: 0.4194 r:0.7716
Current avg r:0.6042 Best avg r: 0.6393
10:16:42,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:12,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:43,41 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1288
en_de Dev loss: 0.9498 r:0.2057
en_zh Dev loss: 0.7947 r:0.4868
ro_en Dev loss: 0.3830 r:0.8183
et_en Dev loss: 0.4773 r:0.6780
si_en Dev loss: 0.9749 r:0.5578
ne_en Dev loss: 0.5748 r:0.7224
ru_en Dev loss: 0.4643 r:0.7572
Current avg r:0.6037 Best avg r: 0.6393
10:24:13,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:43,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:13,381 root INFO Epoch 10 Global steps: 110600 Train loss: 0.1266
en_de Dev loss: 0.9257 r:0.2090
en_zh Dev loss: 0.8110 r:0.4780
ro_en Dev loss: 0.3874 r:0.8191
et_en Dev loss: 0.4451 r:0.6820
si_en Dev loss: 0.8583 r:0.5644
ne_en Dev loss: 0.5694 r:0.7233
ru_en Dev loss: 0.5025 r:0.7406
Current avg r:0.6023 Best avg r: 0.6393
