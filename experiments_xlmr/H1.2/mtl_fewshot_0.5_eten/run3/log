14:36:08,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:36:21,94 root INFO 
id:en_de cur r: 0.0745 best r: 0.0745
14:36:34,29 root INFO 
id:en_zh cur r: 0.0903 best r: 0.0903
14:36:47,11 root INFO 
id:ro_en cur r: 0.5864 best r: 0.5864
14:37:13,19 root INFO 
id:et_en cur r: 0.5167 best r: 0.5167
14:37:26,25 root INFO 
id:si_en cur r: 0.4226 best r: 0.4226
14:37:39,20 root INFO 
id:ne_en cur r: 0.5691 best r: 0.5691
14:37:51,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:22,570 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
14:39:22,579 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:39:22,586 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:39:22,595 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
14:39:22,606 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
14:39:22,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:39:22,619 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:39:35,605 root INFO Epoch 0 Global steps: 700 Train loss: 0.8239
en_de Dev loss: 0.8956 r:0.0922
en_zh Dev loss: 0.7978 r:0.2402
ro_en Dev loss: 0.6247 r:0.6329
et_en Dev loss: 0.5433 r:0.5043
si_en Dev loss: 0.7489 r:0.4415
ne_en Dev loss: 0.5341 r:0.6074
ru_en Dev loss: 0.6437 r:0.4944
Current avg r:0.4304 Best avg r: 0.4304
14:44:07,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:33,152 root INFO 
id:en_zh cur r: 0.2819 best r: 0.2819
14:44:46,74 root INFO 
id:ro_en cur r: 0.6170 best r: 0.6170
14:45:11,981 root INFO 
id:et_en cur r: 0.5947 best r: 0.5947
14:45:24,947 root INFO 
id:si_en cur r: 0.4440 best r: 0.4440
14:45:37,917 root INFO 
id:ne_en cur r: 0.6261 best r: 0.6261
14:45:50,747 root INFO 
id:ru_en cur r: 0.5135 best r: 0.5135
14:45:50,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:21,208 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
14:47:21,215 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:47:21,220 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:47:21,267 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
14:47:21,272 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
14:47:21,277 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:47:21,284 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:47:34,244 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8167
en_de Dev loss: 0.9036 r:0.1198
en_zh Dev loss: 0.7572 r:0.2899
ro_en Dev loss: 0.6404 r:0.6691
et_en Dev loss: 0.4890 r:0.6085
si_en Dev loss: 0.8273 r:0.4811
ne_en Dev loss: 0.5105 r:0.6557
ru_en Dev loss: 0.6386 r:0.6348
Current avg r:0.4941 Best avg r: 0.4941
14:52:05,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:44,86 root INFO 
id:ro_en cur r: 0.6223 best r: 0.6223
14:53:09,967 root INFO 
id:et_en cur r: 0.6478 best r: 0.6478
14:53:22,933 root INFO 
id:si_en cur r: 0.4738 best r: 0.4738
14:53:35,894 root INFO 
id:ne_en cur r: 0.6405 best r: 0.6405
14:53:48,724 root INFO 
id:ru_en cur r: 0.6718 best r: 0.6718
14:53:48,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:19,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
14:55:19,163 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:55:19,168 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:55:19,172 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
14:55:19,177 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
14:55:19,182 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:55:19,187 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:55:32,140 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7225
en_de Dev loss: 0.9266 r:0.1390
en_zh Dev loss: 0.7535 r:0.3109
ro_en Dev loss: 0.5990 r:0.6881
et_en Dev loss: 0.4529 r:0.6615
si_en Dev loss: 0.7115 r:0.5242
ne_en Dev loss: 0.4889 r:0.6673
ru_en Dev loss: 0.5921 r:0.7078
Current avg r:0.5284 Best avg r: 0.5284
15:00:03,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:16,319 root INFO 
id:en_de cur r: 0.1617 best r: 0.1617
15:00:29,219 root INFO 
id:en_zh cur r: 0.3430 best r: 0.3430
15:00:42,143 root INFO 
id:ro_en cur r: 0.6789 best r: 0.6789
15:01:08,48 root INFO 
id:et_en cur r: 0.6866 best r: 0.6866
15:01:21,14 root INFO 
id:si_en cur r: 0.5056 best r: 0.5056
15:01:33,977 root INFO 
id:ne_en cur r: 0.6740 best r: 0.6740
15:01:46,819 root INFO 
id:ru_en cur r: 0.7095 best r: 0.7095
15:01:46,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:17,287 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:03:17,294 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:03:17,298 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:03:17,304 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:03:17,309 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:03:17,313 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:03:17,318 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:03:30,277 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7111
en_de Dev loss: 0.9218 r:0.1642
en_zh Dev loss: 0.7331 r:0.3466
ro_en Dev loss: 0.4981 r:0.7063
et_en Dev loss: 0.3753 r:0.6966
si_en Dev loss: 0.6518 r:0.5363
ne_en Dev loss: 0.4368 r:0.6831
ru_en Dev loss: 0.5343 r:0.7326
Current avg r:0.5522 Best avg r: 0.5522
15:08:01,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:40,315 root INFO 
id:ro_en cur r: 0.6862 best r: 0.6862
15:09:06,227 root INFO 
id:si_en cur r: 0.5132 best r: 0.5132
15:09:32,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:02,478 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6545
en_de Dev loss: 0.9059 r:0.1627
en_zh Dev loss: 0.7721 r:0.3328
ro_en Dev loss: 0.5019 r:0.7138
et_en Dev loss: 0.3932 r:0.6837
si_en Dev loss: 0.7095 r:0.5302
ne_en Dev loss: 0.4841 r:0.6718
ru_en Dev loss: 0.5206 r:0.7207
Current avg r:0.5451 Best avg r: 0.5522
15:15:33,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:12,402 root INFO 
id:ro_en cur r: 0.7017 best r: 0.7017
15:16:38,310 root INFO 
id:si_en cur r: 0.5241 best r: 0.5241
15:17:04,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:34,670 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:18:34,677 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:18:34,682 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:18:34,687 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:18:34,692 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:18:34,697 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:18:34,703 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:18:47,674 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6424
en_de Dev loss: 0.9107 r:0.1702
en_zh Dev loss: 0.7764 r:0.3491
ro_en Dev loss: 0.5129 r:0.7253
et_en Dev loss: 0.3817 r:0.6970
si_en Dev loss: 0.7080 r:0.5460
ne_en Dev loss: 0.5405 r:0.6728
ru_en Dev loss: 0.4817 r:0.7287
Current avg r:0.5556 Best avg r: 0.5556
15:23:18,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:57,575 root INFO 
id:ro_en cur r: 0.7328 best r: 0.7328
15:24:23,497 root INFO 
id:et_en cur r: 0.6871 best r: 0.6871
15:24:36,471 root INFO 
id:si_en cur r: 0.5319 best r: 0.5319
15:24:49,439 root INFO 
id:ne_en cur r: 0.6756 best r: 0.6756
15:25:02,267 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:32,717 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:26:32,723 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:26:32,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:26:32,739 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:26:32,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:26:32,748 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:26:32,752 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:26:45,699 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5958
en_de Dev loss: 0.9267 r:0.1908
en_zh Dev loss: 0.8184 r:0.3612
ro_en Dev loss: 0.5731 r:0.7495
et_en Dev loss: 0.4965 r:0.6983
si_en Dev loss: 0.9677 r:0.5465
ne_en Dev loss: 0.8475 r:0.6681
ru_en Dev loss: 0.5900 r:0.7113
Current avg r:0.5608 Best avg r: 0.5608
15:31:16,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:42,713 root INFO 
id:en_zh cur r: 0.3710 best r: 0.3710
15:31:55,635 root INFO 
id:ro_en cur r: 0.7500 best r: 0.7500
15:32:21,544 root INFO 
id:et_en cur r: 0.7027 best r: 0.7027
15:32:34,514 root INFO 
id:si_en cur r: 0.5647 best r: 0.5647
15:32:47,477 root INFO 
id:ne_en cur r: 0.7283 best r: 0.7283
15:33:00,318 root INFO 
id:ru_en cur r: 0.7281 best r: 0.7281
15:33:00,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:30,794 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:34:30,800 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:34:30,805 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:34:30,809 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:34:30,814 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:34:30,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:34:30,823 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:34:43,783 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5943
en_de Dev loss: 0.8909 r:0.1750
en_zh Dev loss: 0.7140 r:0.3866
ro_en Dev loss: 0.3845 r:0.7611
et_en Dev loss: 0.3437 r:0.7186
si_en Dev loss: 0.6078 r:0.5775
ne_en Dev loss: 0.3971 r:0.7256
ru_en Dev loss: 0.4068 r:0.7490
Current avg r:0.5848 Best avg r: 0.5848
15:39:14,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:53,692 root INFO 
id:ro_en cur r: 0.7630 best r: 0.7630
15:40:45,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:15,860 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6382
en_de Dev loss: 0.9204 r:0.1747
en_zh Dev loss: 0.7893 r:0.3607
ro_en Dev loss: 0.4589 r:0.7787
et_en Dev loss: 0.3964 r:0.7139
si_en Dev loss: 0.7747 r:0.5766
ne_en Dev loss: 0.6024 r:0.7081
ru_en Dev loss: 0.5624 r:0.7053
Current avg r:0.5740 Best avg r: 0.5848
15:46:47,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:59,959 root INFO 
id:en_de cur r: 0.1710 best r: 0.1710
15:47:12,868 root INFO 
id:en_zh cur r: 0.4001 best r: 0.4001
15:47:25,819 root INFO 
id:ro_en cur r: 0.7736 best r: 0.7736
15:47:51,721 root INFO 
id:et_en cur r: 0.7218 best r: 0.7218
15:48:04,685 root INFO 
id:si_en cur r: 0.5851 best r: 0.5851
15:48:17,649 root INFO 
id:ne_en cur r: 0.7459 best r: 0.7459
15:48:30,479 root INFO 
id:ru_en cur r: 0.7326 best r: 0.7326
15:48:30,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:00,945 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:50:00,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:50:00,955 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:50:00,959 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:50:00,964 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:50:00,968 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:50:00,973 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:50:13,943 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5594
en_de Dev loss: 0.9170 r:0.1869
en_zh Dev loss: 0.7163 r:0.4017
ro_en Dev loss: 0.3520 r:0.7787
et_en Dev loss: 0.3354 r:0.7300
si_en Dev loss: 0.5708 r:0.5967
ne_en Dev loss: 0.3549 r:0.7488
ru_en Dev loss: 0.4271 r:0.7482
Current avg r:0.5987 Best avg r: 0.5987
15:54:45,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:58,100 root INFO 
id:en_de cur r: 0.1845 best r: 0.1845
15:55:11,10 root INFO 
id:en_zh cur r: 0.4219 best r: 0.4219
15:55:23,931 root INFO 
id:ro_en cur r: 0.7796 best r: 0.7796
15:56:15,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:46,72 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:57:46,77 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:57:46,81 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:57:46,86 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:57:46,90 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:57:46,95 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:57:46,101 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:57:59,57 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5737
en_de Dev loss: 0.8828 r:0.1925
en_zh Dev loss: 0.6890 r:0.4183
ro_en Dev loss: 0.3556 r:0.7799
et_en Dev loss: 0.3417 r:0.7226
si_en Dev loss: 0.6194 r:0.5916
ne_en Dev loss: 0.3842 r:0.7464
ru_en Dev loss: 0.4308 r:0.7415
Current avg r:0.5990 Best avg r: 0.5990
16:02:30,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:09,92 root INFO 
id:ro_en cur r: 0.7837 best r: 0.7837
16:04:00,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:31,196 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5487
en_de Dev loss: 0.8700 r:0.1961
en_zh Dev loss: 0.7187 r:0.3946
ro_en Dev loss: 0.3523 r:0.7839
et_en Dev loss: 0.3476 r:0.7133
si_en Dev loss: 0.6093 r:0.5873
ne_en Dev loss: 0.3968 r:0.7240
ru_en Dev loss: 0.4536 r:0.7288
Current avg r:0.5897 Best avg r: 0.5990
16:10:02,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:28,195 root INFO 
id:en_zh cur r: 0.4409 best r: 0.4409
16:10:41,117 root INFO 
id:ro_en cur r: 0.8003 best r: 0.8003
16:11:07,7 root INFO 
id:et_en cur r: 0.7291 best r: 0.7291
16:11:19,965 root INFO 
id:si_en cur r: 0.6069 best r: 0.6069
16:11:32,916 root INFO 
id:ne_en cur r: 0.7583 best r: 0.7583
16:11:45,747 root INFO 
id:ru_en cur r: 0.7699 best r: 0.7699
16:11:45,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:16,151 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:13:16,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:13:16,162 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:13:16,167 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:13:16,172 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:13:16,177 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:13:16,182 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:13:29,125 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5612
en_de Dev loss: 0.8628 r:0.1875
en_zh Dev loss: 0.6647 r:0.4346
ro_en Dev loss: 0.3207 r:0.7958
et_en Dev loss: 0.3279 r:0.7352
si_en Dev loss: 0.5751 r:0.6145
ne_en Dev loss: 0.3470 r:0.7603
ru_en Dev loss: 0.3423 r:0.7723
Current avg r:0.6143 Best avg r: 0.6143
16:18:00,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:39,33 root INFO 
id:ro_en cur r: 0.8042 best r: 0.8042
16:19:17,879 root INFO 
id:ne_en cur r: 0.7602 best r: 0.7602
16:19:30,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:01,90 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5725
en_de Dev loss: 0.8758 r:0.1820
en_zh Dev loss: 0.7027 r:0.4107
ro_en Dev loss: 0.3225 r:0.8001
et_en Dev loss: 0.3362 r:0.7319
si_en Dev loss: 0.5581 r:0.6101
ne_en Dev loss: 0.3409 r:0.7602
ru_en Dev loss: 0.3783 r:0.7605
Current avg r:0.6079 Best avg r: 0.6143
16:25:32,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:10,793 root INFO 
id:ro_en cur r: 0.8059 best r: 0.8059
16:27:02,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:32,849 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5118
en_de Dev loss: 0.8727 r:0.1856
en_zh Dev loss: 0.7290 r:0.4072
ro_en Dev loss: 0.3535 r:0.8030
et_en Dev loss: 0.3531 r:0.7244
si_en Dev loss: 0.6770 r:0.5975
ne_en Dev loss: 0.4826 r:0.7424
ru_en Dev loss: 0.4479 r:0.7411
Current avg r:0.6002 Best avg r: 0.6143
16:33:05,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:18,669 root INFO 
id:en_de cur r: 0.1888 best r: 0.1888
16:33:31,588 root INFO 
id:en_zh cur r: 0.4452 best r: 0.4452
16:33:44,547 root INFO 
id:ro_en cur r: 0.8100 best r: 0.8100
16:34:23,518 root INFO 
id:ne_en cur r: 0.7609 best r: 0.7609
16:34:36,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:07,188 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5026
en_de Dev loss: 0.8960 r:0.2102
en_zh Dev loss: 0.7370 r:0.4300
ro_en Dev loss: 0.3959 r:0.8048
et_en Dev loss: 0.3786 r:0.7253
si_en Dev loss: 0.7189 r:0.6002
ne_en Dev loss: 0.4442 r:0.7549
ru_en Dev loss: 0.4585 r:0.7513
Current avg r:0.6109 Best avg r: 0.6143
16:40:38,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:51,727 root INFO 
id:en_de cur r: 0.2047 best r: 0.2047
16:41:17,583 root INFO 
id:ro_en cur r: 0.8135 best r: 0.8135
16:42:09,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:39,705 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5063
en_de Dev loss: 0.8772 r:0.2053
en_zh Dev loss: 0.7532 r:0.4084
ro_en Dev loss: 0.3450 r:0.8095
et_en Dev loss: 0.3590 r:0.7201
si_en Dev loss: 0.6880 r:0.5987
ne_en Dev loss: 0.4470 r:0.7535
ru_en Dev loss: 0.4240 r:0.7455
Current avg r:0.6059 Best avg r: 0.6143
16:48:10,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:23,800 root INFO 
id:en_de cur r: 0.2158 best r: 0.2158
16:48:49,632 root INFO 
id:ro_en cur r: 0.8214 best r: 0.8214
16:49:15,540 root INFO 
id:si_en cur r: 0.6146 best r: 0.6146
16:49:28,502 root INFO 
id:ne_en cur r: 0.7677 best r: 0.7677
16:49:41,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:11,812 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:51:11,817 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:51:11,822 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:51:11,828 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:51:11,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:51:11,837 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:51:11,841 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:51:24,797 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5280
en_de Dev loss: 0.8568 r:0.2080
en_zh Dev loss: 0.6728 r:0.4375
ro_en Dev loss: 0.2939 r:0.8180
et_en Dev loss: 0.3361 r:0.7322
si_en Dev loss: 0.5456 r:0.6187
ne_en Dev loss: 0.3321 r:0.7651
ru_en Dev loss: 0.3582 r:0.7662
Current avg r:0.6208 Best avg r: 0.6208
16:55:56,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:26,555 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:57,27 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4741
en_de Dev loss: 0.8658 r:0.1980
en_zh Dev loss: 0.7242 r:0.4265
ro_en Dev loss: 0.3328 r:0.8144
et_en Dev loss: 0.3516 r:0.7210
si_en Dev loss: 0.6515 r:0.6102
ne_en Dev loss: 0.4209 r:0.7567
ru_en Dev loss: 0.4733 r:0.7377
Current avg r:0.6092 Best avg r: 0.6208
17:03:28,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:32,933 root INFO 
id:si_en cur r: 0.6156 best r: 0.6156
17:04:58,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:29,190 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4666
en_de Dev loss: 0.8702 r:0.2023
en_zh Dev loss: 0.7225 r:0.4202
ro_en Dev loss: 0.2926 r:0.8198
et_en Dev loss: 0.3525 r:0.7257
si_en Dev loss: 0.5522 r:0.6212
ne_en Dev loss: 0.3470 r:0.7620
ru_en Dev loss: 0.3767 r:0.7615
Current avg r:0.6161 Best avg r: 0.6208
17:11:00,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:26,361 root INFO 
id:en_zh cur r: 0.4544 best r: 0.4544
17:11:39,306 root INFO 
id:ro_en cur r: 0.8223 best r: 0.8223
17:12:18,172 root INFO 
id:ne_en cur r: 0.7686 best r: 0.7686
17:12:31,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:01,513 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4852
en_de Dev loss: 0.8660 r:0.1917
en_zh Dev loss: 0.6667 r:0.4522
ro_en Dev loss: 0.2916 r:0.8212
et_en Dev loss: 0.3597 r:0.7187
si_en Dev loss: 0.5786 r:0.6165
ne_en Dev loss: 0.3269 r:0.7716
ru_en Dev loss: 0.3699 r:0.7603
Current avg r:0.6189 Best avg r: 0.6208
17:18:32,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:50,455 root INFO 
id:ne_en cur r: 0.7718 best r: 0.7718
17:20:03,298 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:33,771 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4589
en_de Dev loss: 0.8722 r:0.1987
en_zh Dev loss: 0.7201 r:0.4335
ro_en Dev loss: 0.3254 r:0.8173
et_en Dev loss: 0.3666 r:0.7173
si_en Dev loss: 0.6898 r:0.6093
ne_en Dev loss: 0.3851 r:0.7707
ru_en Dev loss: 0.3934 r:0.7563
Current avg r:0.6147 Best avg r: 0.6208
17:26:05,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:35,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:06,78 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4737
en_de Dev loss: 0.8545 r:0.2007
en_zh Dev loss: 0.6808 r:0.4380
ro_en Dev loss: 0.2947 r:0.8144
et_en Dev loss: 0.3632 r:0.7198
si_en Dev loss: 0.5881 r:0.6130
ne_en Dev loss: 0.3499 r:0.7659
ru_en Dev loss: 0.3516 r:0.7662
Current avg r:0.6169 Best avg r: 0.6208
17:33:37,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:03,222 root INFO 
id:en_zh cur r: 0.4561 best r: 0.4561
17:34:16,166 root INFO 
id:ro_en cur r: 0.8255 best r: 0.8255
17:34:42,94 root INFO 
id:si_en cur r: 0.6168 best r: 0.6168
17:35:07,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:38,382 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4615
en_de Dev loss: 0.8750 r:0.1984
en_zh Dev loss: 0.7140 r:0.4495
ro_en Dev loss: 0.3183 r:0.8210
et_en Dev loss: 0.3759 r:0.7147
si_en Dev loss: 0.7603 r:0.6147
ne_en Dev loss: 0.3955 r:0.7667
ru_en Dev loss: 0.3933 r:0.7631
Current avg r:0.6183 Best avg r: 0.6208
17:41:09,676 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:35,492 root INFO 
id:en_zh cur r: 0.4655 best r: 0.4655
17:41:48,427 root INFO 
id:ro_en cur r: 0.8294 best r: 0.8294
17:42:27,289 root INFO 
id:ne_en cur r: 0.7723 best r: 0.7723
17:42:40,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:10,585 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
17:44:10,592 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:44:10,597 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:44:10,602 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
17:44:10,607 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
17:44:10,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:44:10,618 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:44:23,575 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4875
en_de Dev loss: 0.8619 r:0.2092
en_zh Dev loss: 0.6783 r:0.4597
ro_en Dev loss: 0.3030 r:0.8285
et_en Dev loss: 0.3529 r:0.7232
si_en Dev loss: 0.6870 r:0.6196
ne_en Dev loss: 0.3806 r:0.7743
ru_en Dev loss: 0.4073 r:0.7614
Current avg r:0.6251 Best avg r: 0.6251
17:48:54,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:25,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:55,862 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4399
en_de Dev loss: 0.8953 r:0.1856
en_zh Dev loss: 0.7539 r:0.4496
ro_en Dev loss: 0.3322 r:0.8237
et_en Dev loss: 0.3907 r:0.7030
si_en Dev loss: 0.6775 r:0.6063
ne_en Dev loss: 0.3773 r:0.7682
ru_en Dev loss: 0.4288 r:0.7486
Current avg r:0.6121 Best avg r: 0.6251
17:56:27,234 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:57,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:28,125 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4864
en_de Dev loss: 0.8833 r:0.1954
en_zh Dev loss: 0.7483 r:0.4492
ro_en Dev loss: 0.3523 r:0.8195
et_en Dev loss: 0.4048 r:0.7100
si_en Dev loss: 0.7398 r:0.6037
ne_en Dev loss: 0.4552 r:0.7611
ru_en Dev loss: 0.4376 r:0.7581
Current avg r:0.6139 Best avg r: 0.6251
18:03:59,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:29,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:00,278 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4755
en_de Dev loss: 0.8575 r:0.1943
en_zh Dev loss: 0.6996 r:0.4437
ro_en Dev loss: 0.3005 r:0.8219
et_en Dev loss: 0.3766 r:0.7126
si_en Dev loss: 0.5942 r:0.6044
ne_en Dev loss: 0.3705 r:0.7686
ru_en Dev loss: 0.4178 r:0.7401
Current avg r:0.6122 Best avg r: 0.6251
18:11:31,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:02,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:32,512 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4726
en_de Dev loss: 0.8649 r:0.1801
en_zh Dev loss: 0.6885 r:0.4531
ro_en Dev loss: 0.2893 r:0.8252
et_en Dev loss: 0.3543 r:0.7105
si_en Dev loss: 0.6802 r:0.5960
ne_en Dev loss: 0.4461 r:0.7619
ru_en Dev loss: 0.4208 r:0.7384
Current avg r:0.6093 Best avg r: 0.6251
18:19:03,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:29,623 root INFO 
id:en_zh cur r: 0.4703 best r: 0.4703
18:20:34,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:04,763 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4582
en_de Dev loss: 0.8629 r:0.1903
en_zh Dev loss: 0.6623 r:0.4642
ro_en Dev loss: 0.3037 r:0.8211
et_en Dev loss: 0.3785 r:0.7089
si_en Dev loss: 0.6622 r:0.6086
ne_en Dev loss: 0.3583 r:0.7661
ru_en Dev loss: 0.3858 r:0.7522
Current avg r:0.6159 Best avg r: 0.6251
18:26:38,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:09,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:39,815 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4113
en_de Dev loss: 0.8601 r:0.1829
en_zh Dev loss: 0.6943 r:0.4572
ro_en Dev loss: 0.3014 r:0.8210
et_en Dev loss: 0.3697 r:0.6990
si_en Dev loss: 0.6866 r:0.6025
ne_en Dev loss: 0.4464 r:0.7641
ru_en Dev loss: 0.4044 r:0.7397
Current avg r:0.6095 Best avg r: 0.6251
18:34:12,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:25,186 root INFO 
id:en_de cur r: 0.2218 best r: 0.2218
18:34:38,120 root INFO 
id:en_zh cur r: 0.4753 best r: 0.4753
18:34:51,80 root INFO 
id:ro_en cur r: 0.8329 best r: 0.8329
18:35:42,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:13,468 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4121
en_de Dev loss: 0.8511 r:0.2056
en_zh Dev loss: 0.6660 r:0.4646
ro_en Dev loss: 0.2943 r:0.8250
et_en Dev loss: 0.3783 r:0.7135
si_en Dev loss: 0.6039 r:0.6130
ne_en Dev loss: 0.4026 r:0.7650
ru_en Dev loss: 0.3839 r:0.7527
Current avg r:0.6199 Best avg r: 0.6251
18:41:45,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:16,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:47,210 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4027
en_de Dev loss: 0.8528 r:0.2022
en_zh Dev loss: 0.6989 r:0.4611
ro_en Dev loss: 0.3226 r:0.8216
et_en Dev loss: 0.4117 r:0.6995
si_en Dev loss: 0.6766 r:0.5949
ne_en Dev loss: 0.3897 r:0.7617
ru_en Dev loss: 0.3994 r:0.7484
Current avg r:0.6128 Best avg r: 0.6251
18:49:19,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:50,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:21,83 root INFO Epoch 2 Global steps: 23800 Train loss: 0.3886
en_de Dev loss: 0.8578 r:0.1976
en_zh Dev loss: 0.7005 r:0.4514
ro_en Dev loss: 0.3183 r:0.8213
et_en Dev loss: 0.3989 r:0.6964
si_en Dev loss: 0.7003 r:0.5993
ne_en Dev loss: 0.4142 r:0.7595
ru_en Dev loss: 0.4339 r:0.7350
Current avg r:0.6086 Best avg r: 0.6251
18:56:53,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:06,371 root INFO 
id:en_de cur r: 0.2315 best r: 0.2315
18:58:24,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:54,673 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4242
en_de Dev loss: 0.8567 r:0.2153
en_zh Dev loss: 0.7090 r:0.4539
ro_en Dev loss: 0.3149 r:0.8252
et_en Dev loss: 0.3850 r:0.6983
si_en Dev loss: 0.7279 r:0.6031
ne_en Dev loss: 0.4548 r:0.7644
ru_en Dev loss: 0.4406 r:0.7383
Current avg r:0.6141 Best avg r: 0.6251
19:04:27,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:31,983 root INFO 
id:si_en cur r: 0.6172 best r: 0.6172
19:05:57,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:28,516 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4284
en_de Dev loss: 0.8507 r:0.2040
en_zh Dev loss: 0.6931 r:0.4575
ro_en Dev loss: 0.3016 r:0.8285
et_en Dev loss: 0.3977 r:0.7047
si_en Dev loss: 0.6091 r:0.6185
ne_en Dev loss: 0.3936 r:0.7690
ru_en Dev loss: 0.3894 r:0.7497
Current avg r:0.6188 Best avg r: 0.6251
19:12:01,35 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:31,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:02,118 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4190
en_de Dev loss: 0.8700 r:0.1916
en_zh Dev loss: 0.7311 r:0.4540
ro_en Dev loss: 0.3219 r:0.8255
et_en Dev loss: 0.4146 r:0.6946
si_en Dev loss: 0.6748 r:0.6005
ne_en Dev loss: 0.3856 r:0.7668
ru_en Dev loss: 0.4122 r:0.7516
Current avg r:0.6121 Best avg r: 0.6251
19:19:34,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:04,943 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:35,519 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3935
en_de Dev loss: 0.8581 r:0.2070
en_zh Dev loss: 0.7375 r:0.4557
ro_en Dev loss: 0.3161 r:0.8258
et_en Dev loss: 0.4052 r:0.6888
si_en Dev loss: 0.7622 r:0.6035
ne_en Dev loss: 0.4275 r:0.7641
ru_en Dev loss: 0.4146 r:0.7544
Current avg r:0.6142 Best avg r: 0.6251
19:27:07,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:20,812 root INFO 
id:en_de cur r: 0.2421 best r: 0.2421
19:28:38,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:09,51 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3948
en_de Dev loss: 0.8562 r:0.2174
en_zh Dev loss: 0.7511 r:0.4368
ro_en Dev loss: 0.3337 r:0.8209
et_en Dev loss: 0.3998 r:0.6878
si_en Dev loss: 0.7609 r:0.5929
ne_en Dev loss: 0.4951 r:0.7594
ru_en Dev loss: 0.4370 r:0.7367
Current avg r:0.6074 Best avg r: 0.6251
19:34:41,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:12,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:42,728 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4094
en_de Dev loss: 0.9007 r:0.1678
en_zh Dev loss: 0.7143 r:0.4531
ro_en Dev loss: 0.3340 r:0.8190
et_en Dev loss: 0.4394 r:0.6757
si_en Dev loss: 0.7035 r:0.5973
ne_en Dev loss: 0.4362 r:0.7541
ru_en Dev loss: 0.4563 r:0.7254
Current avg r:0.5989 Best avg r: 0.6251
19:42:15,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:45,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:16,485 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3758
en_de Dev loss: 0.8848 r:0.1832
en_zh Dev loss: 0.7814 r:0.4477
ro_en Dev loss: 0.3847 r:0.8134
et_en Dev loss: 0.4428 r:0.6685
si_en Dev loss: 0.8725 r:0.5846
ne_en Dev loss: 0.5624 r:0.7517
ru_en Dev loss: 0.5158 r:0.7074
Current avg r:0.5938 Best avg r: 0.6251
19:49:48,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:19,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:50,177 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3962
en_de Dev loss: 0.9072 r:0.1726
en_zh Dev loss: 0.7533 r:0.4574
ro_en Dev loss: 0.3501 r:0.8245
et_en Dev loss: 0.4447 r:0.6783
si_en Dev loss: 0.8150 r:0.5959
ne_en Dev loss: 0.4281 r:0.7612
ru_en Dev loss: 0.4760 r:0.7373
Current avg r:0.6039 Best avg r: 0.6251
19:57:22,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:53,342 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:24,8 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3713
en_de Dev loss: 0.8827 r:0.1955
en_zh Dev loss: 0.7487 r:0.4505
ro_en Dev loss: 0.3212 r:0.8260
et_en Dev loss: 0.4588 r:0.6864
si_en Dev loss: 0.7083 r:0.6051
ne_en Dev loss: 0.3936 r:0.7622
ru_en Dev loss: 0.4505 r:0.7408
Current avg r:0.6095 Best avg r: 0.6251
20:04:56,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:27,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:57,937 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3847
en_de Dev loss: 0.8707 r:0.2095
en_zh Dev loss: 0.7441 r:0.4351
ro_en Dev loss: 0.3247 r:0.8192
et_en Dev loss: 0.4270 r:0.6681
si_en Dev loss: 0.8334 r:0.5844
ne_en Dev loss: 0.6601 r:0.7455
ru_en Dev loss: 0.5385 r:0.6922
Current avg r:0.5934 Best avg r: 0.6251
20:12:30,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:01,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:31,841 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3817
en_de Dev loss: 0.8778 r:0.1983
en_zh Dev loss: 0.7429 r:0.4469
ro_en Dev loss: 0.3438 r:0.8230
et_en Dev loss: 0.4456 r:0.6869
si_en Dev loss: 0.6978 r:0.6088
ne_en Dev loss: 0.4596 r:0.7588
ru_en Dev loss: 0.4433 r:0.7405
Current avg r:0.6090 Best avg r: 0.6251
20:20:05,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:44,783 root INFO 
id:ro_en cur r: 0.8344 best r: 0.8344
20:21:36,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:07,236 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3368
en_de Dev loss: 0.8526 r:0.2026
en_zh Dev loss: 0.7186 r:0.4518
ro_en Dev loss: 0.3048 r:0.8302
et_en Dev loss: 0.4365 r:0.6928
si_en Dev loss: 0.6393 r:0.6123
ne_en Dev loss: 0.3673 r:0.7620
ru_en Dev loss: 0.3904 r:0.7541
Current avg r:0.6151 Best avg r: 0.6251
20:27:39,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:10,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:40,842 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3665
en_de Dev loss: 0.8490 r:0.2146
en_zh Dev loss: 0.7463 r:0.4396
ro_en Dev loss: 0.3352 r:0.8234
et_en Dev loss: 0.4211 r:0.6808
si_en Dev loss: 0.7147 r:0.6053
ne_en Dev loss: 0.4769 r:0.7554
ru_en Dev loss: 0.4767 r:0.7207
Current avg r:0.6057 Best avg r: 0.6251
20:35:13,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:43,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:14,410 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3287
en_de Dev loss: 0.8476 r:0.2248
en_zh Dev loss: 0.7490 r:0.4373
ro_en Dev loss: 0.3341 r:0.8198
et_en Dev loss: 0.4633 r:0.6789
si_en Dev loss: 0.7553 r:0.5911
ne_en Dev loss: 0.3982 r:0.7547
ru_en Dev loss: 0.4432 r:0.7271
Current avg r:0.6048 Best avg r: 0.6251
20:42:47,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:17,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:48,322 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3470
en_de Dev loss: 0.8596 r:0.2176
en_zh Dev loss: 0.7790 r:0.4271
ro_en Dev loss: 0.3477 r:0.8161
et_en Dev loss: 0.4788 r:0.6772
si_en Dev loss: 0.7096 r:0.5878
ne_en Dev loss: 0.4416 r:0.7507
ru_en Dev loss: 0.4555 r:0.7235
Current avg r:0.6000 Best avg r: 0.6251
20:50:20,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:51,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:22,211 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3510
en_de Dev loss: 0.9188 r:0.1570
en_zh Dev loss: 0.8344 r:0.4271
ro_en Dev loss: 0.3768 r:0.8168
et_en Dev loss: 0.4509 r:0.6723
si_en Dev loss: 0.8656 r:0.5798
ne_en Dev loss: 0.5948 r:0.7466
ru_en Dev loss: 0.5308 r:0.7148
Current avg r:0.5878 Best avg r: 0.6251
20:57:54,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:25,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:56,196 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3390
en_de Dev loss: 0.8611 r:0.2155
en_zh Dev loss: 0.7510 r:0.4455
ro_en Dev loss: 0.3242 r:0.8272
et_en Dev loss: 0.4763 r:0.6843
si_en Dev loss: 0.6624 r:0.5987
ne_en Dev loss: 0.4353 r:0.7476
ru_en Dev loss: 0.4302 r:0.7386
Current avg r:0.6082 Best avg r: 0.6251
21:05:28,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:59,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:30,146 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3280
en_de Dev loss: 0.8880 r:0.2141
en_zh Dev loss: 0.7940 r:0.4332
ro_en Dev loss: 0.3388 r:0.8261
et_en Dev loss: 0.4404 r:0.6730
si_en Dev loss: 0.7712 r:0.5883
ne_en Dev loss: 0.5231 r:0.7527
ru_en Dev loss: 0.4589 r:0.7359
Current avg r:0.6034 Best avg r: 0.6251
21:13:02,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:33,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:04,535 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3223
en_de Dev loss: 0.8528 r:0.2178
en_zh Dev loss: 0.7303 r:0.4418
ro_en Dev loss: 0.2964 r:0.8241
et_en Dev loss: 0.4278 r:0.6739
si_en Dev loss: 0.7051 r:0.5932
ne_en Dev loss: 0.4325 r:0.7520
ru_en Dev loss: 0.3963 r:0.7475
Current avg r:0.6072 Best avg r: 0.6251
21:20:37,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:08,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:38,910 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3535
en_de Dev loss: 0.8460 r:0.2331
en_zh Dev loss: 0.7355 r:0.4540
ro_en Dev loss: 0.3051 r:0.8265
et_en Dev loss: 0.4618 r:0.6850
si_en Dev loss: 0.6657 r:0.6006
ne_en Dev loss: 0.3796 r:0.7598
ru_en Dev loss: 0.3856 r:0.7579
Current avg r:0.6167 Best avg r: 0.6251
21:28:11,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:29:42,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:13,361 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3398
en_de Dev loss: 0.8815 r:0.1776
en_zh Dev loss: 0.8071 r:0.4310
ro_en Dev loss: 0.3310 r:0.8266
et_en Dev loss: 0.4547 r:0.6641
si_en Dev loss: 0.7794 r:0.5855
ne_en Dev loss: 0.5457 r:0.7477
ru_en Dev loss: 0.4637 r:0.7179
Current avg r:0.5929 Best avg r: 0.6251
21:35:46,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:17,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:47,883 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3280
en_de Dev loss: 0.8800 r:0.1879
en_zh Dev loss: 0.7716 r:0.4439
ro_en Dev loss: 0.3318 r:0.8266
et_en Dev loss: 0.4444 r:0.6582
si_en Dev loss: 0.7955 r:0.5805
ne_en Dev loss: 0.5534 r:0.7467
ru_en Dev loss: 0.4741 r:0.7221
Current avg r:0.5951 Best avg r: 0.6251
21:43:20,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:51,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:22,344 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3315
en_de Dev loss: 0.8502 r:0.2252
en_zh Dev loss: 0.7276 r:0.4526
ro_en Dev loss: 0.2948 r:0.8298
et_en Dev loss: 0.4616 r:0.6843
si_en Dev loss: 0.6540 r:0.5982
ne_en Dev loss: 0.4019 r:0.7560
ru_en Dev loss: 0.4246 r:0.7352
Current avg r:0.6116 Best avg r: 0.6251
21:50:55,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:25,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:56,761 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3184
en_de Dev loss: 0.8465 r:0.2251
en_zh Dev loss: 0.7393 r:0.4346
ro_en Dev loss: 0.2859 r:0.8300
et_en Dev loss: 0.4365 r:0.6770
si_en Dev loss: 0.7291 r:0.5875
ne_en Dev loss: 0.4496 r:0.7526
ru_en Dev loss: 0.4036 r:0.7377
Current avg r:0.6063 Best avg r: 0.6251
21:58:29,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:00,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:31,165 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3214
en_de Dev loss: 0.8805 r:0.1951
en_zh Dev loss: 0.7683 r:0.4458
ro_en Dev loss: 0.3035 r:0.8315
et_en Dev loss: 0.4578 r:0.6802
si_en Dev loss: 0.7822 r:0.5829
ne_en Dev loss: 0.4215 r:0.7529
ru_en Dev loss: 0.4592 r:0.7294
Current avg r:0.6025 Best avg r: 0.6251
22:06:03,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:07:33,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:04,488 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3048
en_de Dev loss: 0.8705 r:0.1941
en_zh Dev loss: 0.7481 r:0.4496
ro_en Dev loss: 0.3182 r:0.8299
et_en Dev loss: 0.4548 r:0.6790
si_en Dev loss: 0.7155 r:0.5915
ne_en Dev loss: 0.4280 r:0.7490
ru_en Dev loss: 0.4093 r:0.7534
Current avg r:0.6067 Best avg r: 0.6251
22:13:37,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:08,311 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:16:39,8 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2800
en_de Dev loss: 0.8636 r:0.1947
en_zh Dev loss: 0.7281 r:0.4461
ro_en Dev loss: 0.2893 r:0.8280
et_en Dev loss: 0.4775 r:0.6729
si_en Dev loss: 0.6603 r:0.5897
ne_en Dev loss: 0.3967 r:0.7512
ru_en Dev loss: 0.3957 r:0.7424
Current avg r:0.6036 Best avg r: 0.6251
22:21:10,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:41,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:12,95 root INFO Epoch 4 Global steps: 43400 Train loss: 0.3040
en_de Dev loss: 0.8589 r:0.2059
en_zh Dev loss: 0.7668 r:0.4355
ro_en Dev loss: 0.3317 r:0.8233
et_en Dev loss: 0.4770 r:0.6663
si_en Dev loss: 0.7516 r:0.5834
ne_en Dev loss: 0.4136 r:0.7506
ru_en Dev loss: 0.4106 r:0.7447
Current avg r:0.6014 Best avg r: 0.6251
22:28:43,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:14,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:45,245 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2929
en_de Dev loss: 0.8597 r:0.1992
en_zh Dev loss: 0.7760 r:0.4273
ro_en Dev loss: 0.3133 r:0.8282
et_en Dev loss: 0.4856 r:0.6680
si_en Dev loss: 0.7145 r:0.5844
ne_en Dev loss: 0.4071 r:0.7494
ru_en Dev loss: 0.4325 r:0.7289
Current avg r:0.5979 Best avg r: 0.6251
22:36:17,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:47,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:39:18,349 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2895
en_de Dev loss: 0.8801 r:0.1837
en_zh Dev loss: 0.7478 r:0.4433
ro_en Dev loss: 0.2957 r:0.8307
et_en Dev loss: 0.4769 r:0.6761
si_en Dev loss: 0.6592 r:0.5923
ne_en Dev loss: 0.3933 r:0.7462
ru_en Dev loss: 0.3954 r:0.7478
Current avg r:0.6029 Best avg r: 0.6251
22:43:50,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:45:20,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:51,467 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2807
en_de Dev loss: 0.8795 r:0.1686
en_zh Dev loss: 0.7431 r:0.4434
ro_en Dev loss: 0.3082 r:0.8287
et_en Dev loss: 0.4448 r:0.6679
si_en Dev loss: 0.7671 r:0.5808
ne_en Dev loss: 0.5005 r:0.7504
ru_en Dev loss: 0.4089 r:0.7464
Current avg r:0.5980 Best avg r: 0.6251
22:51:23,214 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:53,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:24,526 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2837
en_de Dev loss: 0.8586 r:0.2068
en_zh Dev loss: 0.7610 r:0.4221
ro_en Dev loss: 0.3182 r:0.8203
et_en Dev loss: 0.4708 r:0.6534
si_en Dev loss: 0.7884 r:0.5694
ne_en Dev loss: 0.4861 r:0.7426
ru_en Dev loss: 0.4736 r:0.7098
Current avg r:0.5892 Best avg r: 0.6251
22:58:56,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:00:26,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:57,526 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2794
en_de Dev loss: 0.8887 r:0.1903
en_zh Dev loss: 0.7726 r:0.4570
ro_en Dev loss: 0.3443 r:0.8261
et_en Dev loss: 0.4769 r:0.6758
si_en Dev loss: 0.8117 r:0.5828
ne_en Dev loss: 0.4527 r:0.7462
ru_en Dev loss: 0.4598 r:0.7409
Current avg r:0.6027 Best avg r: 0.6251
23:06:29,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:59,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:09:30,408 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2687
en_de Dev loss: 0.8800 r:0.1920
en_zh Dev loss: 0.7347 r:0.4618
ro_en Dev loss: 0.3209 r:0.8251
et_en Dev loss: 0.5011 r:0.6688
si_en Dev loss: 0.6576 r:0.5894
ne_en Dev loss: 0.3979 r:0.7453
ru_en Dev loss: 0.3876 r:0.7570
Current avg r:0.6056 Best avg r: 0.6251
23:14:02,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:15:33,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:17:03,720 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2800
en_de Dev loss: 0.8720 r:0.2089
en_zh Dev loss: 0.7818 r:0.4469
ro_en Dev loss: 0.3369 r:0.8280
et_en Dev loss: 0.4820 r:0.6723
si_en Dev loss: 0.7529 r:0.5878
ne_en Dev loss: 0.4551 r:0.7438
ru_en Dev loss: 0.4630 r:0.7313
Current avg r:0.6027 Best avg r: 0.6251
23:21:35,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:23:06,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:24:36,742 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2818
en_de Dev loss: 0.8582 r:0.2162
en_zh Dev loss: 0.7477 r:0.4461
ro_en Dev loss: 0.3031 r:0.8293
et_en Dev loss: 0.4574 r:0.6656
si_en Dev loss: 0.7554 r:0.5755
ne_en Dev loss: 0.4234 r:0.7383
ru_en Dev loss: 0.4370 r:0.7298
Current avg r:0.6001 Best avg r: 0.6251
23:29:08,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:30:38,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:32:09,390 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2616
en_de Dev loss: 0.9004 r:0.1892
en_zh Dev loss: 0.8039 r:0.4415
ro_en Dev loss: 0.3565 r:0.8250
et_en Dev loss: 0.4813 r:0.6591
si_en Dev loss: 0.8243 r:0.5775
ne_en Dev loss: 0.5003 r:0.7350
ru_en Dev loss: 0.4778 r:0.7305
Current avg r:0.5940 Best avg r: 0.6251
23:36:40,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:38:11,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:41,947 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2706
en_de Dev loss: 0.8695 r:0.1962
en_zh Dev loss: 0.8031 r:0.4099
ro_en Dev loss: 0.3146 r:0.8250
et_en Dev loss: 0.4801 r:0.6534
si_en Dev loss: 0.7953 r:0.5671
ne_en Dev loss: 0.4524 r:0.7358
ru_en Dev loss: 0.4584 r:0.7197
Current avg r:0.5867 Best avg r: 0.6251
23:44:14,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:44,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:47:15,350 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2836
en_de Dev loss: 0.8681 r:0.2310
en_zh Dev loss: 0.8037 r:0.4244
ro_en Dev loss: 0.3486 r:0.8195
et_en Dev loss: 0.4799 r:0.6458
si_en Dev loss: 0.9060 r:0.5588
ne_en Dev loss: 0.6489 r:0.7349
ru_en Dev loss: 0.4632 r:0.7287
Current avg r:0.5919 Best avg r: 0.6251
23:51:47,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:00,576 root INFO 
id:en_de cur r: 0.2458 best r: 0.2458
23:53:18,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:54:48,664 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2621
en_de Dev loss: 0.8486 r:0.2316
en_zh Dev loss: 0.7484 r:0.4360
ro_en Dev loss: 0.2924 r:0.8279
et_en Dev loss: 0.4702 r:0.6634
si_en Dev loss: 0.6709 r:0.5879
ne_en Dev loss: 0.4655 r:0.7354
ru_en Dev loss: 0.4000 r:0.7431
Current avg r:0.6036 Best avg r: 0.6251
23:59:20,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:33,847 root INFO 
id:en_de cur r: 0.2473 best r: 0.2473
00:00:51,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:02:21,836 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2726
en_de Dev loss: 0.8509 r:0.2387
en_zh Dev loss: 0.7501 r:0.4560
ro_en Dev loss: 0.3142 r:0.8286
et_en Dev loss: 0.4567 r:0.6726
si_en Dev loss: 0.7507 r:0.5932
ne_en Dev loss: 0.4843 r:0.7413
ru_en Dev loss: 0.4218 r:0.7540
Current avg r:0.6121 Best avg r: 0.6251
00:06:54,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:08:25,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:09:55,644 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2464
en_de Dev loss: 0.8481 r:0.2309
en_zh Dev loss: 0.7560 r:0.4331
ro_en Dev loss: 0.3146 r:0.8257
et_en Dev loss: 0.4694 r:0.6551
si_en Dev loss: 0.7739 r:0.5744
ne_en Dev loss: 0.4728 r:0.7331
ru_en Dev loss: 0.4453 r:0.7259
Current avg r:0.5969 Best avg r: 0.6251
00:14:27,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:15:57,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:17:27,848 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2551
en_de Dev loss: 0.8813 r:0.1936
en_zh Dev loss: 0.7570 r:0.4478
ro_en Dev loss: 0.3401 r:0.8246
et_en Dev loss: 0.4676 r:0.6585
si_en Dev loss: 0.8069 r:0.5741
ne_en Dev loss: 0.5184 r:0.7319
ru_en Dev loss: 0.4483 r:0.7355
Current avg r:0.5951 Best avg r: 0.6251
00:21:59,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:29,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:24:59,979 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2403
en_de Dev loss: 0.8960 r:0.1860
en_zh Dev loss: 0.8215 r:0.4437
ro_en Dev loss: 0.3743 r:0.8193
et_en Dev loss: 0.5076 r:0.6470
si_en Dev loss: 0.9919 r:0.5567
ne_en Dev loss: 0.5977 r:0.7336
ru_en Dev loss: 0.5044 r:0.7241
Current avg r:0.5872 Best avg r: 0.6251
00:29:31,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:01,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:32,195 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2433
en_de Dev loss: 0.8783 r:0.2210
en_zh Dev loss: 0.8334 r:0.4363
ro_en Dev loss: 0.3708 r:0.8234
et_en Dev loss: 0.5031 r:0.6593
si_en Dev loss: 0.9239 r:0.5624
ne_en Dev loss: 0.5744 r:0.7321
ru_en Dev loss: 0.5322 r:0.7106
Current avg r:0.5922 Best avg r: 0.6251
00:37:03,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:38:33,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:04,475 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2383
en_de Dev loss: 0.8678 r:0.1978
en_zh Dev loss: 0.7889 r:0.4394
ro_en Dev loss: 0.3310 r:0.8271
et_en Dev loss: 0.4795 r:0.6549
si_en Dev loss: 0.8186 r:0.5717
ne_en Dev loss: 0.4753 r:0.7349
ru_en Dev loss: 0.4280 r:0.7409
Current avg r:0.5953 Best avg r: 0.6251
00:44:36,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:07,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:37,637 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2316
en_de Dev loss: 0.9006 r:0.1981
en_zh Dev loss: 0.8234 r:0.4404
ro_en Dev loss: 0.3603 r:0.8277
et_en Dev loss: 0.4816 r:0.6564
si_en Dev loss: 0.8406 r:0.5771
ne_en Dev loss: 0.4896 r:0.7355
ru_en Dev loss: 0.4849 r:0.7330
Current avg r:0.5955 Best avg r: 0.6251
00:52:09,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:40,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:11,121 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2247
en_de Dev loss: 0.8979 r:0.2037
en_zh Dev loss: 0.8158 r:0.4471
ro_en Dev loss: 0.3483 r:0.8258
et_en Dev loss: 0.5116 r:0.6605
si_en Dev loss: 0.8446 r:0.5733
ne_en Dev loss: 0.4640 r:0.7338
ru_en Dev loss: 0.4261 r:0.7579
Current avg r:0.6003 Best avg r: 0.6251
00:59:43,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:01:13,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:44,222 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2355
en_de Dev loss: 0.8779 r:0.1935
en_zh Dev loss: 0.8216 r:0.4221
ro_en Dev loss: 0.3370 r:0.8254
et_en Dev loss: 0.4614 r:0.6520
si_en Dev loss: 0.8908 r:0.5706
ne_en Dev loss: 0.5398 r:0.7259
ru_en Dev loss: 0.4871 r:0.7237
Current avg r:0.5876 Best avg r: 0.6251
01:07:16,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:47,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:17,786 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2395
en_de Dev loss: 0.8654 r:0.2125
en_zh Dev loss: 0.7902 r:0.4398
ro_en Dev loss: 0.3559 r:0.8219
et_en Dev loss: 0.4883 r:0.6568
si_en Dev loss: 0.8369 r:0.5721
ne_en Dev loss: 0.5799 r:0.7277
ru_en Dev loss: 0.4695 r:0.7273
Current avg r:0.5940 Best avg r: 0.6251
01:14:49,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:20,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:51,245 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2413
en_de Dev loss: 0.8753 r:0.2136
en_zh Dev loss: 0.8064 r:0.4371
ro_en Dev loss: 0.3627 r:0.8238
et_en Dev loss: 0.4930 r:0.6554
si_en Dev loss: 0.8291 r:0.5706
ne_en Dev loss: 0.5040 r:0.7350
ru_en Dev loss: 0.4953 r:0.7161
Current avg r:0.5931 Best avg r: 0.6251
01:22:23,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:54,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:24,926 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2322
en_de Dev loss: 0.8727 r:0.2175
en_zh Dev loss: 0.8271 r:0.4268
ro_en Dev loss: 0.3534 r:0.8222
et_en Dev loss: 0.5038 r:0.6462
si_en Dev loss: 0.8901 r:0.5534
ne_en Dev loss: 0.5404 r:0.7236
ru_en Dev loss: 0.4825 r:0.7204
Current avg r:0.5872 Best avg r: 0.6251
01:29:57,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:27,826 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:58,524 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2359
en_de Dev loss: 0.8739 r:0.2037
en_zh Dev loss: 0.8133 r:0.4243
ro_en Dev loss: 0.3448 r:0.8223
et_en Dev loss: 0.5061 r:0.6442
si_en Dev loss: 0.8059 r:0.5648
ne_en Dev loss: 0.5026 r:0.7279
ru_en Dev loss: 0.4774 r:0.7136
Current avg r:0.5858 Best avg r: 0.6251
01:37:30,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:39:01,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:40:32,65 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2223
en_de Dev loss: 0.8955 r:0.1915
en_zh Dev loss: 0.8495 r:0.4282
ro_en Dev loss: 0.3791 r:0.8237
et_en Dev loss: 0.5123 r:0.6476
si_en Dev loss: 0.9325 r:0.5597
ne_en Dev loss: 0.5210 r:0.7293
ru_en Dev loss: 0.5188 r:0.7130
Current avg r:0.5847 Best avg r: 0.6251
01:45:04,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:46:34,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:48:05,411 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2279
en_de Dev loss: 0.8933 r:0.2146
en_zh Dev loss: 0.8297 r:0.4346
ro_en Dev loss: 0.3257 r:0.8286
et_en Dev loss: 0.4829 r:0.6580
si_en Dev loss: 0.8260 r:0.5693
ne_en Dev loss: 0.4995 r:0.7317
ru_en Dev loss: 0.4779 r:0.7321
Current avg r:0.5956 Best avg r: 0.6251
01:52:37,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:54:08,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:55:39,180 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2315
en_de Dev loss: 0.8705 r:0.2110
en_zh Dev loss: 0.7472 r:0.4503
ro_en Dev loss: 0.3092 r:0.8256
et_en Dev loss: 0.4783 r:0.6671
si_en Dev loss: 0.6774 r:0.5822
ne_en Dev loss: 0.4376 r:0.7326
ru_en Dev loss: 0.4430 r:0.7245
Current avg r:0.5991 Best avg r: 0.6251
02:00:13,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:01:43,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:03:14,392 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2069
en_de Dev loss: 0.9035 r:0.1931
en_zh Dev loss: 0.8403 r:0.4440
ro_en Dev loss: 0.3516 r:0.8264
et_en Dev loss: 0.4778 r:0.6607
si_en Dev loss: 0.8422 r:0.5645
ne_en Dev loss: 0.4825 r:0.7316
ru_en Dev loss: 0.4797 r:0.7319
Current avg r:0.5932 Best avg r: 0.6251
02:07:46,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:09:17,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:48,236 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2054
en_de Dev loss: 0.8830 r:0.1977
en_zh Dev loss: 0.8069 r:0.4440
ro_en Dev loss: 0.3230 r:0.8277
et_en Dev loss: 0.4652 r:0.6641
si_en Dev loss: 0.8106 r:0.5690
ne_en Dev loss: 0.4608 r:0.7333
ru_en Dev loss: 0.4552 r:0.7327
Current avg r:0.5955 Best avg r: 0.6251
02:15:20,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:51,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:18:22,84 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2053
en_de Dev loss: 0.8892 r:0.2001
en_zh Dev loss: 0.8088 r:0.4434
ro_en Dev loss: 0.3175 r:0.8263
et_en Dev loss: 0.4687 r:0.6638
si_en Dev loss: 0.8374 r:0.5654
ne_en Dev loss: 0.4983 r:0.7298
ru_en Dev loss: 0.4294 r:0.7457
Current avg r:0.5964 Best avg r: 0.6251
02:22:54,519 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:25,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:55,838 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2159
en_de Dev loss: 0.8951 r:0.1908
en_zh Dev loss: 0.7717 r:0.4589
ro_en Dev loss: 0.3447 r:0.8238
et_en Dev loss: 0.4816 r:0.6631
si_en Dev loss: 0.8279 r:0.5670
ne_en Dev loss: 0.4476 r:0.7305
ru_en Dev loss: 0.4248 r:0.7502
Current avg r:0.5978 Best avg r: 0.6251
02:30:28,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:59,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:33:29,750 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2039
en_de Dev loss: 0.8798 r:0.2061
en_zh Dev loss: 0.7901 r:0.4445
ro_en Dev loss: 0.3396 r:0.8195
et_en Dev loss: 0.4909 r:0.6480
si_en Dev loss: 0.8623 r:0.5565
ne_en Dev loss: 0.4946 r:0.7239
ru_en Dev loss: 0.4868 r:0.7194
Current avg r:0.5883 Best avg r: 0.6251
02:38:02,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:38:28,137 root INFO 
id:en_zh cur r: 0.4776 best r: 0.4776
02:39:32,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:41:03,607 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2051
en_de Dev loss: 0.8873 r:0.2064
en_zh Dev loss: 0.7593 r:0.4666
ro_en Dev loss: 0.3258 r:0.8247
et_en Dev loss: 0.4634 r:0.6661
si_en Dev loss: 0.8027 r:0.5673
ne_en Dev loss: 0.5103 r:0.7263
ru_en Dev loss: 0.4303 r:0.7488
Current avg r:0.6009 Best avg r: 0.6251
02:45:36,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:47:06,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:48:37,332 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2001
en_de Dev loss: 0.8905 r:0.1917
en_zh Dev loss: 0.7835 r:0.4525
ro_en Dev loss: 0.3449 r:0.8208
et_en Dev loss: 0.4778 r:0.6530
si_en Dev loss: 0.8966 r:0.5535
ne_en Dev loss: 0.5743 r:0.7259
ru_en Dev loss: 0.4418 r:0.7380
Current avg r:0.5908 Best avg r: 0.6251
02:53:09,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:53:35,550 root INFO 
id:en_zh cur r: 0.4878 best r: 0.4878
02:54:40,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:56:11,13 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2022
en_de Dev loss: 0.8986 r:0.1961
en_zh Dev loss: 0.7321 r:0.4793
ro_en Dev loss: 0.3196 r:0.8288
et_en Dev loss: 0.5048 r:0.6709
si_en Dev loss: 0.7371 r:0.5778
ne_en Dev loss: 0.4538 r:0.7275
ru_en Dev loss: 0.4175 r:0.7434
Current avg r:0.6034 Best avg r: 0.6251
03:00:43,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:02:13,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:44,653 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2056
en_de Dev loss: 0.8769 r:0.2056
en_zh Dev loss: 0.7798 r:0.4435
ro_en Dev loss: 0.3501 r:0.8246
et_en Dev loss: 0.5107 r:0.6601
si_en Dev loss: 0.8183 r:0.5618
ne_en Dev loss: 0.5094 r:0.7261
ru_en Dev loss: 0.4378 r:0.7356
Current avg r:0.5939 Best avg r: 0.6251
03:08:17,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:47,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:18,389 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1946
en_de Dev loss: 0.8803 r:0.2170
en_zh Dev loss: 0.7762 r:0.4548
ro_en Dev loss: 0.3218 r:0.8236
et_en Dev loss: 0.4811 r:0.6591
si_en Dev loss: 0.8436 r:0.5578
ne_en Dev loss: 0.5348 r:0.7214
ru_en Dev loss: 0.4194 r:0.7509
Current avg r:0.5978 Best avg r: 0.6251
03:15:50,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:17:21,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:18:52,272 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1887
en_de Dev loss: 0.8752 r:0.2118
en_zh Dev loss: 0.7767 r:0.4569
ro_en Dev loss: 0.3398 r:0.8232
et_en Dev loss: 0.4761 r:0.6617
si_en Dev loss: 0.8178 r:0.5555
ne_en Dev loss: 0.5293 r:0.7209
ru_en Dev loss: 0.4719 r:0.7248
Current avg r:0.5935 Best avg r: 0.6251
03:23:24,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:24:55,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:26:26,250 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1973
en_de Dev loss: 0.8696 r:0.2208
en_zh Dev loss: 0.8031 r:0.4563
ro_en Dev loss: 0.3812 r:0.8146
et_en Dev loss: 0.4902 r:0.6529
si_en Dev loss: 0.9626 r:0.5381
ne_en Dev loss: 0.6169 r:0.7207
ru_en Dev loss: 0.5187 r:0.7163
Current avg r:0.5885 Best avg r: 0.6251
03:30:58,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:32:29,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:34:00,414 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2070
en_de Dev loss: 0.8691 r:0.2184
en_zh Dev loss: 0.7509 r:0.4636
ro_en Dev loss: 0.3420 r:0.8219
et_en Dev loss: 0.4402 r:0.6705
si_en Dev loss: 0.8791 r:0.5550
ne_en Dev loss: 0.5590 r:0.7267
ru_en Dev loss: 0.4571 r:0.7377
Current avg r:0.5991 Best avg r: 0.6251
03:38:33,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:03,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:34,553 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2018
en_de Dev loss: 0.8768 r:0.2042
en_zh Dev loss: 0.7808 r:0.4530
ro_en Dev loss: 0.3555 r:0.8156
et_en Dev loss: 0.4845 r:0.6514
si_en Dev loss: 0.9417 r:0.5404
ne_en Dev loss: 0.6151 r:0.7189
ru_en Dev loss: 0.4708 r:0.7219
Current avg r:0.5865 Best avg r: 0.6251
03:46:07,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:47:37,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:49:08,611 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1870
en_de Dev loss: 0.8730 r:0.2114
en_zh Dev loss: 0.7814 r:0.4452
ro_en Dev loss: 0.3322 r:0.8219
et_en Dev loss: 0.4709 r:0.6571
si_en Dev loss: 0.7813 r:0.5609
ne_en Dev loss: 0.5063 r:0.7221
ru_en Dev loss: 0.4654 r:0.7239
Current avg r:0.5918 Best avg r: 0.6251
03:53:42,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:55:13,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:56:44,151 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1688
en_de Dev loss: 0.8554 r:0.2211
en_zh Dev loss: 0.7554 r:0.4568
ro_en Dev loss: 0.3292 r:0.8220
et_en Dev loss: 0.4711 r:0.6661
si_en Dev loss: 0.8598 r:0.5543
ne_en Dev loss: 0.5085 r:0.7178
ru_en Dev loss: 0.4488 r:0.7316
Current avg r:0.5957 Best avg r: 0.6251
04:01:16,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:02:47,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:18,267 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1835
en_de Dev loss: 0.8704 r:0.2111
en_zh Dev loss: 0.7745 r:0.4611
ro_en Dev loss: 0.3253 r:0.8226
et_en Dev loss: 0.4833 r:0.6675
si_en Dev loss: 0.8196 r:0.5574
ne_en Dev loss: 0.5111 r:0.7197
ru_en Dev loss: 0.4275 r:0.7430
Current avg r:0.5975 Best avg r: 0.6251
04:08:50,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:10:21,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:11:52,443 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1790
en_de Dev loss: 0.8718 r:0.2005
en_zh Dev loss: 0.7767 r:0.4574
ro_en Dev loss: 0.3324 r:0.8222
et_en Dev loss: 0.4637 r:0.6664
si_en Dev loss: 0.7929 r:0.5517
ne_en Dev loss: 0.4862 r:0.7246
ru_en Dev loss: 0.4439 r:0.7353
Current avg r:0.5940 Best avg r: 0.6251
04:16:24,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:17:55,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:26,364 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1735
en_de Dev loss: 0.8728 r:0.2151
en_zh Dev loss: 0.7815 r:0.4621
ro_en Dev loss: 0.3289 r:0.8222
et_en Dev loss: 0.4534 r:0.6690
si_en Dev loss: 0.8434 r:0.5565
ne_en Dev loss: 0.5168 r:0.7273
ru_en Dev loss: 0.4245 r:0.7471
Current avg r:0.5999 Best avg r: 0.6251
04:23:58,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:25:29,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:27:00,369 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1741
en_de Dev loss: 0.8711 r:0.2285
en_zh Dev loss: 0.7948 r:0.4568
ro_en Dev loss: 0.3520 r:0.8196
et_en Dev loss: 0.4910 r:0.6647
si_en Dev loss: 0.8741 r:0.5467
ne_en Dev loss: 0.5714 r:0.7130
ru_en Dev loss: 0.4629 r:0.7308
Current avg r:0.5943 Best avg r: 0.6251
04:31:32,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:33:03,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:34:34,384 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1750
en_de Dev loss: 0.8826 r:0.2073
en_zh Dev loss: 0.7831 r:0.4659
ro_en Dev loss: 0.3665 r:0.8193
et_en Dev loss: 0.4937 r:0.6556
si_en Dev loss: 0.9631 r:0.5398
ne_en Dev loss: 0.5761 r:0.7222
ru_en Dev loss: 0.4727 r:0.7210
Current avg r:0.5901 Best avg r: 0.6251
04:39:06,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:40:37,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:42:08,255 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1788
en_de Dev loss: 0.8905 r:0.2135
en_zh Dev loss: 0.8140 r:0.4569
ro_en Dev loss: 0.3806 r:0.8213
et_en Dev loss: 0.4633 r:0.6681
si_en Dev loss: 0.9000 r:0.5553
ne_en Dev loss: 0.5719 r:0.7252
ru_en Dev loss: 0.4231 r:0.7558
Current avg r:0.5994 Best avg r: 0.6251
04:46:40,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:48:11,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:49:42,82 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1691
en_de Dev loss: 0.9058 r:0.1997
en_zh Dev loss: 0.7755 r:0.4629
ro_en Dev loss: 0.3322 r:0.8222
et_en Dev loss: 0.4579 r:0.6663
si_en Dev loss: 0.8288 r:0.5494
ne_en Dev loss: 0.4822 r:0.7238
ru_en Dev loss: 0.4364 r:0.7400
Current avg r:0.5949 Best avg r: 0.6251
04:54:14,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:55:45,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:57:15,957 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1748
en_de Dev loss: 0.9160 r:0.1953
en_zh Dev loss: 0.8520 r:0.4433
ro_en Dev loss: 0.3840 r:0.8200
et_en Dev loss: 0.4641 r:0.6653
si_en Dev loss: 0.9325 r:0.5427
ne_en Dev loss: 0.6395 r:0.7129
ru_en Dev loss: 0.4826 r:0.7361
Current avg r:0.5880 Best avg r: 0.6251
05:01:47,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:18,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:04:48,845 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1770
en_de Dev loss: 0.8716 r:0.2109
en_zh Dev loss: 0.8098 r:0.4476
ro_en Dev loss: 0.3493 r:0.8187
et_en Dev loss: 0.4582 r:0.6641
si_en Dev loss: 0.9075 r:0.5501
ne_en Dev loss: 0.5736 r:0.7242
ru_en Dev loss: 0.4257 r:0.7438
Current avg r:0.5942 Best avg r: 0.6251
05:09:20,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:50,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:12:21,431 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1700
en_de Dev loss: 0.8926 r:0.1932
en_zh Dev loss: 0.7865 r:0.4473
ro_en Dev loss: 0.3366 r:0.8198
et_en Dev loss: 0.4618 r:0.6602
si_en Dev loss: 0.8829 r:0.5459
ne_en Dev loss: 0.5429 r:0.7229
ru_en Dev loss: 0.4281 r:0.7496
Current avg r:0.5913 Best avg r: 0.6251
05:16:52,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:18:23,490 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:19:54,91 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1677
en_de Dev loss: 0.9064 r:0.1847
en_zh Dev loss: 0.8008 r:0.4400
ro_en Dev loss: 0.3233 r:0.8198
et_en Dev loss: 0.4686 r:0.6551
si_en Dev loss: 0.9262 r:0.5331
ne_en Dev loss: 0.5555 r:0.7119
ru_en Dev loss: 0.4542 r:0.7346
Current avg r:0.5827 Best avg r: 0.6251
05:24:25,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:25:56,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:27:26,791 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1744
en_de Dev loss: 0.9183 r:0.1796
en_zh Dev loss: 0.7820 r:0.4515
ro_en Dev loss: 0.3230 r:0.8240
et_en Dev loss: 0.5071 r:0.6582
si_en Dev loss: 0.8771 r:0.5493
ne_en Dev loss: 0.5041 r:0.7180
ru_en Dev loss: 0.3996 r:0.7577
Current avg r:0.5912 Best avg r: 0.6251
05:31:58,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:33:28,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:34:59,448 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1702
en_de Dev loss: 0.9128 r:0.1896
en_zh Dev loss: 0.8198 r:0.4480
ro_en Dev loss: 0.3503 r:0.8259
et_en Dev loss: 0.4759 r:0.6649
si_en Dev loss: 0.8457 r:0.5592
ne_en Dev loss: 0.5585 r:0.7182
ru_en Dev loss: 0.4521 r:0.7504
Current avg r:0.5938 Best avg r: 0.6251
05:39:30,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:41:01,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:42:32,131 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1700
en_de Dev loss: 0.9101 r:0.2001
en_zh Dev loss: 0.7934 r:0.4541
ro_en Dev loss: 0.3731 r:0.8191
et_en Dev loss: 0.4721 r:0.6563
si_en Dev loss: 0.8785 r:0.5495
ne_en Dev loss: 0.5548 r:0.7170
ru_en Dev loss: 0.4696 r:0.7400
Current avg r:0.5909 Best avg r: 0.6251
05:47:05,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:48:35,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:50:06,301 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1535
en_de Dev loss: 0.8940 r:0.2053
en_zh Dev loss: 0.8270 r:0.4421
ro_en Dev loss: 0.3643 r:0.8199
et_en Dev loss: 0.4942 r:0.6567
si_en Dev loss: 0.9685 r:0.5441
ne_en Dev loss: 0.5615 r:0.7121
ru_en Dev loss: 0.4704 r:0.7342
Current avg r:0.5878 Best avg r: 0.6251
05:54:37,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:56:08,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:57:39,71 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1477
en_de Dev loss: 0.9002 r:0.1932
en_zh Dev loss: 0.8205 r:0.4515
ro_en Dev loss: 0.3531 r:0.8175
et_en Dev loss: 0.4652 r:0.6593
si_en Dev loss: 0.9545 r:0.5420
ne_en Dev loss: 0.5976 r:0.7169
ru_en Dev loss: 0.4445 r:0.7424
Current avg r:0.5890 Best avg r: 0.6251
06:02:10,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:41,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:11,653 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1522
en_de Dev loss: 0.9021 r:0.1755
en_zh Dev loss: 0.8138 r:0.4454
ro_en Dev loss: 0.3542 r:0.8189
et_en Dev loss: 0.4717 r:0.6593
si_en Dev loss: 0.8485 r:0.5511
ne_en Dev loss: 0.5643 r:0.7098
ru_en Dev loss: 0.4442 r:0.7355
Current avg r:0.5851 Best avg r: 0.6251
06:09:43,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:13,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:12:44,327 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1616
en_de Dev loss: 0.8930 r:0.1888
en_zh Dev loss: 0.7919 r:0.4499
ro_en Dev loss: 0.3360 r:0.8206
et_en Dev loss: 0.4780 r:0.6591
si_en Dev loss: 0.8641 r:0.5475
ne_en Dev loss: 0.5589 r:0.7104
ru_en Dev loss: 0.4261 r:0.7445
Current avg r:0.5887 Best avg r: 0.6251
06:17:15,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:18:46,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:20:17,8 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1529
en_de Dev loss: 0.9034 r:0.1821
en_zh Dev loss: 0.8148 r:0.4528
ro_en Dev loss: 0.3546 r:0.8178
et_en Dev loss: 0.4799 r:0.6649
si_en Dev loss: 0.9086 r:0.5481
ne_en Dev loss: 0.5355 r:0.7148
ru_en Dev loss: 0.4392 r:0.7483
Current avg r:0.5898 Best avg r: 0.6251
06:24:48,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:26:18,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:27:49,453 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1527
en_de Dev loss: 0.9171 r:0.2085
en_zh Dev loss: 0.7892 r:0.4684
ro_en Dev loss: 0.3443 r:0.8199
et_en Dev loss: 0.5261 r:0.6789
si_en Dev loss: 0.7614 r:0.5657
ne_en Dev loss: 0.4699 r:0.7145
ru_en Dev loss: 0.4016 r:0.7621
Current avg r:0.6026 Best avg r: 0.6251
06:32:20,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:33:51,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:35:22,73 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1515
en_de Dev loss: 0.9033 r:0.1988
en_zh Dev loss: 0.8131 r:0.4561
ro_en Dev loss: 0.3529 r:0.8191
et_en Dev loss: 0.4765 r:0.6637
si_en Dev loss: 0.8587 r:0.5531
ne_en Dev loss: 0.5445 r:0.7176
ru_en Dev loss: 0.4361 r:0.7529
Current avg r:0.5945 Best avg r: 0.6251
06:39:53,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:24,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:42:54,624 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1557
en_de Dev loss: 0.9174 r:0.1917
en_zh Dev loss: 0.8065 r:0.4525
ro_en Dev loss: 0.3310 r:0.8195
et_en Dev loss: 0.4791 r:0.6615
si_en Dev loss: 0.8532 r:0.5473
ne_en Dev loss: 0.5289 r:0.7211
ru_en Dev loss: 0.3981 r:0.7578
Current avg r:0.5931 Best avg r: 0.6251
06:47:26,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:48:56,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:50:27,220 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1445
en_de Dev loss: 0.8963 r:0.1884
en_zh Dev loss: 0.7961 r:0.4582
ro_en Dev loss: 0.3299 r:0.8178
et_en Dev loss: 0.4648 r:0.6668
si_en Dev loss: 0.8106 r:0.5505
ne_en Dev loss: 0.5361 r:0.7169
ru_en Dev loss: 0.4146 r:0.7501
Current avg r:0.5927 Best avg r: 0.6251
06:54:58,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:56:29,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:57:59,860 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1597
en_de Dev loss: 0.8980 r:0.2016
en_zh Dev loss: 0.8104 r:0.4560
ro_en Dev loss: 0.3572 r:0.8186
et_en Dev loss: 0.4675 r:0.6612
si_en Dev loss: 0.9435 r:0.5427
ne_en Dev loss: 0.5858 r:0.7125
ru_en Dev loss: 0.4197 r:0.7506
Current avg r:0.5919 Best avg r: 0.6251
07:02:31,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:04:01,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:05:32,433 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1535
en_de Dev loss: 0.9167 r:0.1772
en_zh Dev loss: 0.7910 r:0.4564
ro_en Dev loss: 0.3501 r:0.8181
et_en Dev loss: 0.4513 r:0.6600
si_en Dev loss: 0.8748 r:0.5477
ne_en Dev loss: 0.5469 r:0.7172
ru_en Dev loss: 0.4446 r:0.7406
Current avg r:0.5882 Best avg r: 0.6251
07:10:03,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:11:34,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:13:05,10 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1468
en_de Dev loss: 0.9205 r:0.1918
en_zh Dev loss: 0.7865 r:0.4578
ro_en Dev loss: 0.3341 r:0.8221
et_en Dev loss: 0.4692 r:0.6687
si_en Dev loss: 0.8069 r:0.5545
ne_en Dev loss: 0.4802 r:0.7225
ru_en Dev loss: 0.3989 r:0.7593
Current avg r:0.5967 Best avg r: 0.6251
07:17:36,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:19:06,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:37,565 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1525
en_de Dev loss: 0.9008 r:0.1870
en_zh Dev loss: 0.7917 r:0.4555
ro_en Dev loss: 0.3391 r:0.8211
et_en Dev loss: 0.4568 r:0.6719
si_en Dev loss: 0.8583 r:0.5540
ne_en Dev loss: 0.4920 r:0.7253
ru_en Dev loss: 0.4273 r:0.7555
Current avg r:0.5958 Best avg r: 0.6251
07:25:08,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:26:39,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:28:09,961 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1457
en_de Dev loss: 0.9144 r:0.2065
en_zh Dev loss: 0.7609 r:0.4724
ro_en Dev loss: 0.3319 r:0.8201
et_en Dev loss: 0.4604 r:0.6700
si_en Dev loss: 0.8407 r:0.5535
ne_en Dev loss: 0.5366 r:0.7120
ru_en Dev loss: 0.4232 r:0.7494
Current avg r:0.5977 Best avg r: 0.6251
07:32:41,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:34:11,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:35:42,435 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1506
en_de Dev loss: 0.8803 r:0.2022
en_zh Dev loss: 0.7626 r:0.4567
ro_en Dev loss: 0.3180 r:0.8205
et_en Dev loss: 0.4442 r:0.6577
si_en Dev loss: 0.8468 r:0.5441
ne_en Dev loss: 0.5905 r:0.7126
ru_en Dev loss: 0.4344 r:0.7301
Current avg r:0.5891 Best avg r: 0.6251
07:40:15,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:41:45,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:43:16,468 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1305
en_de Dev loss: 0.8927 r:0.1937
en_zh Dev loss: 0.7843 r:0.4628
ro_en Dev loss: 0.3449 r:0.8200
et_en Dev loss: 0.4543 r:0.6684
si_en Dev loss: 0.8267 r:0.5513
ne_en Dev loss: 0.5149 r:0.7146
ru_en Dev loss: 0.4226 r:0.7517
Current avg r:0.5946 Best avg r: 0.6251
07:47:47,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:49:18,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:50:48,936 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1398
en_de Dev loss: 0.9023 r:0.1933
en_zh Dev loss: 0.7864 r:0.4625
ro_en Dev loss: 0.3565 r:0.8154
et_en Dev loss: 0.4876 r:0.6665
si_en Dev loss: 0.8506 r:0.5508
ne_en Dev loss: 0.5361 r:0.7211
ru_en Dev loss: 0.4282 r:0.7522
Current avg r:0.5945 Best avg r: 0.6251
07:55:20,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:56:50,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:58:21,445 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1367
en_de Dev loss: 0.8940 r:0.2085
en_zh Dev loss: 0.7747 r:0.4696
ro_en Dev loss: 0.3367 r:0.8171
et_en Dev loss: 0.4539 r:0.6675
si_en Dev loss: 0.8494 r:0.5571
ne_en Dev loss: 0.5092 r:0.7200
ru_en Dev loss: 0.4150 r:0.7593
Current avg r:0.5999 Best avg r: 0.6251
08:02:52,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:04:23,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:05:54,30 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1339
en_de Dev loss: 0.8857 r:0.2158
en_zh Dev loss: 0.8025 r:0.4612
ro_en Dev loss: 0.3217 r:0.8202
et_en Dev loss: 0.4477 r:0.6731
si_en Dev loss: 0.8145 r:0.5562
ne_en Dev loss: 0.4952 r:0.7201
ru_en Dev loss: 0.4241 r:0.7571
Current avg r:0.6005 Best avg r: 0.6251
08:10:25,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:11:55,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:13:26,596 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1370
en_de Dev loss: 0.9005 r:0.2134
en_zh Dev loss: 0.8132 r:0.4655
ro_en Dev loss: 0.3444 r:0.8202
et_en Dev loss: 0.4794 r:0.6611
si_en Dev loss: 0.9097 r:0.5521
ne_en Dev loss: 0.5639 r:0.7192
ru_en Dev loss: 0.4574 r:0.7487
Current avg r:0.5972 Best avg r: 0.6251
08:17:58,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:19:28,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:20:59,122 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1285
en_de Dev loss: 0.9006 r:0.2149
en_zh Dev loss: 0.7877 r:0.4702
ro_en Dev loss: 0.3587 r:0.8167
et_en Dev loss: 0.4813 r:0.6630
si_en Dev loss: 0.8770 r:0.5545
ne_en Dev loss: 0.5632 r:0.7231
ru_en Dev loss: 0.4037 r:0.7631
Current avg r:0.6008 Best avg r: 0.6251
08:25:30,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:27:01,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:28:31,732 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1320
en_de Dev loss: 0.9017 r:0.2184
en_zh Dev loss: 0.8180 r:0.4675
ro_en Dev loss: 0.3542 r:0.8203
et_en Dev loss: 0.4823 r:0.6676
si_en Dev loss: 0.8685 r:0.5513
ne_en Dev loss: 0.5152 r:0.7157
ru_en Dev loss: 0.4167 r:0.7593
Current avg r:0.6000 Best avg r: 0.6251
08:33:03,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:33:28,989 root INFO 
id:en_zh cur r: 0.4887 best r: 0.4887
08:34:33,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:04,343 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1419
en_de Dev loss: 0.9149 r:0.2154
en_zh Dev loss: 0.7778 r:0.4828
ro_en Dev loss: 0.3423 r:0.8209
et_en Dev loss: 0.4684 r:0.6719
si_en Dev loss: 0.8356 r:0.5525
ne_en Dev loss: 0.5199 r:0.7194
ru_en Dev loss: 0.3945 r:0.7648
Current avg r:0.6040 Best avg r: 0.6251
08:40:35,797 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:06,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:36,963 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1322
en_de Dev loss: 0.8952 r:0.2136
en_zh Dev loss: 0.7951 r:0.4648
ro_en Dev loss: 0.3541 r:0.8163
et_en Dev loss: 0.4753 r:0.6589
si_en Dev loss: 0.8812 r:0.5479
ne_en Dev loss: 0.5548 r:0.7166
ru_en Dev loss: 0.4187 r:0.7495
Current avg r:0.5954 Best avg r: 0.6251
08:48:08,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:49:38,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:51:09,538 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1280
en_de Dev loss: 0.9059 r:0.2053
en_zh Dev loss: 0.8037 r:0.4721
ro_en Dev loss: 0.3623 r:0.8195
et_en Dev loss: 0.4545 r:0.6677
si_en Dev loss: 0.9096 r:0.5542
ne_en Dev loss: 0.5781 r:0.7162
ru_en Dev loss: 0.4488 r:0.7564
Current avg r:0.5988 Best avg r: 0.6251
08:55:40,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:57:11,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:58:42,3 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1351
en_de Dev loss: 0.9122 r:0.1965
en_zh Dev loss: 0.7797 r:0.4828
ro_en Dev loss: 0.3524 r:0.8202
et_en Dev loss: 0.4923 r:0.6668
si_en Dev loss: 0.8406 r:0.5560
ne_en Dev loss: 0.5246 r:0.7208
ru_en Dev loss: 0.4165 r:0.7505
Current avg r:0.5991 Best avg r: 0.6251
09:03:13,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:04:44,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:06:14,620 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1398
en_de Dev loss: 0.8861 r:0.1956
en_zh Dev loss: 0.7509 r:0.4725
ro_en Dev loss: 0.3146 r:0.8216
et_en Dev loss: 0.4503 r:0.6648
si_en Dev loss: 0.8771 r:0.5386
ne_en Dev loss: 0.5140 r:0.7060
ru_en Dev loss: 0.4108 r:0.7531
Current avg r:0.5932 Best avg r: 0.6251
09:10:46,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:12:16,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:13:47,270 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1298
en_de Dev loss: 0.9037 r:0.2022
en_zh Dev loss: 0.8210 r:0.4633
ro_en Dev loss: 0.3489 r:0.8209
et_en Dev loss: 0.4848 r:0.6662
si_en Dev loss: 0.9300 r:0.5419
ne_en Dev loss: 0.5952 r:0.7147
ru_en Dev loss: 0.4493 r:0.7418
Current avg r:0.5930 Best avg r: 0.6251
09:18:18,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:19:49,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:21:19,878 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1279
en_de Dev loss: 0.8785 r:0.2105
en_zh Dev loss: 0.7468 r:0.4707
ro_en Dev loss: 0.3128 r:0.8189
et_en Dev loss: 0.4441 r:0.6700
si_en Dev loss: 0.7942 r:0.5429
ne_en Dev loss: 0.5157 r:0.7069
ru_en Dev loss: 0.4351 r:0.7345
Current avg r:0.5935 Best avg r: 0.6251
09:25:51,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:27:21,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:28:52,528 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1260
en_de Dev loss: 0.8829 r:0.2038
en_zh Dev loss: 0.7504 r:0.4739
ro_en Dev loss: 0.3248 r:0.8164
et_en Dev loss: 0.4454 r:0.6661
si_en Dev loss: 0.8941 r:0.5345
ne_en Dev loss: 0.6028 r:0.7057
ru_en Dev loss: 0.4416 r:0.7339
Current avg r:0.5906 Best avg r: 0.6251
09:33:25,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:34:55,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:26,56 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1174
en_de Dev loss: 0.9200 r:0.2019
en_zh Dev loss: 0.8259 r:0.4785
ro_en Dev loss: 0.3728 r:0.8182
et_en Dev loss: 0.5047 r:0.6655
si_en Dev loss: 0.9442 r:0.5458
ne_en Dev loss: 0.5908 r:0.7149
ru_en Dev loss: 0.4537 r:0.7448
Current avg r:0.5957 Best avg r: 0.6251
09:40:58,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:24,241 root INFO 
id:en_zh cur r: 0.4904 best r: 0.4904
09:42:29,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:59,643 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1193
en_de Dev loss: 0.9077 r:0.1917
en_zh Dev loss: 0.7399 r:0.4845
ro_en Dev loss: 0.3271 r:0.8219
et_en Dev loss: 0.4487 r:0.6734
si_en Dev loss: 0.8368 r:0.5487
ne_en Dev loss: 0.5144 r:0.7155
ru_en Dev loss: 0.4196 r:0.7518
Current avg r:0.5982 Best avg r: 0.6251
09:48:32,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:50:02,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:33,210 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1142
en_de Dev loss: 0.9399 r:0.1917
en_zh Dev loss: 0.8212 r:0.4622
ro_en Dev loss: 0.3614 r:0.8191
et_en Dev loss: 0.4593 r:0.6627
si_en Dev loss: 0.9378 r:0.5392
ne_en Dev loss: 0.6346 r:0.7061
ru_en Dev loss: 0.4516 r:0.7480
Current avg r:0.5898 Best avg r: 0.6251
09:56:05,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:36,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:06,874 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1172
en_de Dev loss: 0.9080 r:0.1917
en_zh Dev loss: 0.7955 r:0.4658
ro_en Dev loss: 0.3442 r:0.8194
et_en Dev loss: 0.4540 r:0.6628
si_en Dev loss: 0.8933 r:0.5441
ne_en Dev loss: 0.6036 r:0.7146
ru_en Dev loss: 0.4369 r:0.7470
Current avg r:0.5922 Best avg r: 0.6251
10:03:39,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:10,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:40,649 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1163
en_de Dev loss: 0.9110 r:0.1797
en_zh Dev loss: 0.7897 r:0.4661
ro_en Dev loss: 0.3338 r:0.8181
et_en Dev loss: 0.4597 r:0.6563
si_en Dev loss: 0.8686 r:0.5445
ne_en Dev loss: 0.5603 r:0.7092
ru_en Dev loss: 0.4294 r:0.7459
Current avg r:0.5885 Best avg r: 0.6251
10:11:13,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:12:43,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:14,406 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1156
en_de Dev loss: 0.9550 r:0.1738
en_zh Dev loss: 0.8653 r:0.4608
ro_en Dev loss: 0.3544 r:0.8204
et_en Dev loss: 0.4810 r:0.6665
si_en Dev loss: 0.8878 r:0.5547
ne_en Dev loss: 0.5572 r:0.7098
ru_en Dev loss: 0.4370 r:0.7540
Current avg r:0.5914 Best avg r: 0.6251
10:18:46,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:17,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:21:48,176 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1138
en_de Dev loss: 0.9217 r:0.1791
en_zh Dev loss: 0.7470 r:0.4798
ro_en Dev loss: 0.3342 r:0.8168
et_en Dev loss: 0.4753 r:0.6714
si_en Dev loss: 0.8190 r:0.5546
ne_en Dev loss: 0.5034 r:0.7214
ru_en Dev loss: 0.3808 r:0.7693
Current avg r:0.5989 Best avg r: 0.6251
10:26:20,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:51,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:21,969 root INFO Epoch 10 Global steps: 110600 Train loss: 0.1137
en_de Dev loss: 0.9504 r:0.1773
en_zh Dev loss: 0.8227 r:0.4722
ro_en Dev loss: 0.3798 r:0.8186
et_en Dev loss: 0.4553 r:0.6693
si_en Dev loss: 0.8920 r:0.5504
ne_en Dev loss: 0.5438 r:0.7111
ru_en Dev loss: 0.4658 r:0.7523
Current avg r:0.5930 Best avg r: 0.6251
