14:43:11,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:43:24,953 root INFO 
id:en_de cur r: 0.0381 best r: 0.0381
14:43:38,101 root INFO 
id:en_zh cur r: 0.2885 best r: 0.2885
14:43:51,275 root INFO 
id:ro_en cur r: 0.5832 best r: 0.5832
14:44:17,655 root INFO 
id:et_en cur r: 0.5519 best r: 0.5519
14:44:30,870 root INFO 
id:si_en cur r: 0.4381 best r: 0.4381
14:44:44,69 root INFO 
id:ne_en cur r: 0.5105 best r: 0.5105
14:44:57,168 root INFO 
id:ru_en cur r: 0.5526 best r: 0.5526
14:44:57,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:29,180 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
14:46:29,193 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:46:29,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:46:29,217 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
14:46:29,223 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
14:46:29,231 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:46:29,243 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:46:42,418 root INFO Epoch 0 Global steps: 700 Train loss: 0.8488
en_de Dev loss: 0.9157 r:0.0735
en_zh Dev loss: 0.7648 r:0.2898
ro_en Dev loss: 0.6080 r:0.6121
et_en Dev loss: 0.5589 r:0.5383
si_en Dev loss: 0.7121 r:0.4311
ne_en Dev loss: 0.6217 r:0.5121
ru_en Dev loss: 0.5747 r:0.6236
Current avg r:0.4401 Best avg r: 0.4401
14:51:17,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:30,207 root INFO 
id:en_de cur r: 0.1248 best r: 0.1248
14:51:56,417 root INFO 
id:ro_en cur r: 0.6104 best r: 0.6104
14:52:22,716 root INFO 
id:et_en cur r: 0.5675 best r: 0.5675
14:53:02,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:33,900 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7882
en_de Dev loss: 0.9467 r:0.0778
en_zh Dev loss: 0.7826 r:0.2701
ro_en Dev loss: 0.6117 r:0.6254
et_en Dev loss: 0.5286 r:0.5444
si_en Dev loss: 0.8285 r:0.3826
ne_en Dev loss: 0.6192 r:0.4964
ru_en Dev loss: 0.5849 r:0.6352
Current avg r:0.4331 Best avg r: 0.4401
14:59:08,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:21,718 root INFO 
id:en_de cur r: 0.1340 best r: 0.1340
14:59:34,813 root INFO 
id:en_zh cur r: 0.3214 best r: 0.3214
14:59:47,936 root INFO 
id:ro_en cur r: 0.6533 best r: 0.6533
15:00:14,232 root INFO 
id:et_en cur r: 0.6194 best r: 0.6194
15:00:27,405 root INFO 
id:si_en cur r: 0.4466 best r: 0.4466
15:00:40,554 root INFO 
id:ne_en cur r: 0.5884 best r: 0.5884
15:00:53,602 root INFO 
id:ru_en cur r: 0.6812 best r: 0.6812
15:00:53,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:25,449 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:02:25,456 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:02:25,461 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:02:25,466 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:02:25,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:02:25,477 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:02:25,482 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:02:38,634 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7095
en_de Dev loss: 0.9252 r:0.1150
en_zh Dev loss: 0.7621 r:0.3180
ro_en Dev loss: 0.5303 r:0.6713
et_en Dev loss: 0.4643 r:0.6364
si_en Dev loss: 0.7336 r:0.4570
ne_en Dev loss: 0.5446 r:0.6075
ru_en Dev loss: 0.4951 r:0.7114
Current avg r:0.5024 Best avg r: 0.5024
15:07:13,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:26,536 root INFO 
id:en_de cur r: 0.1755 best r: 0.1755
15:07:39,625 root INFO 
id:en_zh cur r: 0.3637 best r: 0.3637
15:07:52,765 root INFO 
id:ro_en cur r: 0.6645 best r: 0.6645
15:08:19,73 root INFO 
id:et_en cur r: 0.6422 best r: 0.6422
15:08:45,402 root INFO 
id:ne_en cur r: 0.6056 best r: 0.6056
15:08:58,455 root INFO 
id:ru_en cur r: 0.6943 best r: 0.6943
15:08:58,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:30,341 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:10:30,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:10:30,352 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:10:30,358 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:10:30,363 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:10:30,368 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:10:30,374 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:10:43,531 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6780
en_de Dev loss: 0.9361 r:0.1422
en_zh Dev loss: 0.7347 r:0.3724
ro_en Dev loss: 0.4884 r:0.6886
et_en Dev loss: 0.4208 r:0.6604
si_en Dev loss: 0.7465 r:0.4700
ne_en Dev loss: 0.4996 r:0.6386
ru_en Dev loss: 0.4434 r:0.7243
Current avg r:0.5281 Best avg r: 0.5281
15:15:18,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:57,827 root INFO 
id:ro_en cur r: 0.6686 best r: 0.6686
15:16:24,138 root INFO 
id:et_en cur r: 0.6476 best r: 0.6476
15:16:37,301 root INFO 
id:si_en cur r: 0.4548 best r: 0.4548
15:17:03,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:35,312 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:18:35,319 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:18:35,324 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:18:35,329 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:18:35,333 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:18:35,338 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:18:35,344 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:18:48,505 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6762
en_de Dev loss: 0.9558 r:0.1548
en_zh Dev loss: 0.7442 r:0.3831
ro_en Dev loss: 0.5032 r:0.6924
et_en Dev loss: 0.4253 r:0.6548
si_en Dev loss: 0.7187 r:0.4857
ne_en Dev loss: 0.5514 r:0.6060
ru_en Dev loss: 0.4770 r:0.7242
Current avg r:0.5287 Best avg r: 0.5287
15:23:23,403 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:49,598 root INFO 
id:en_zh cur r: 0.3816 best r: 0.3816
15:24:02,720 root INFO 
id:ro_en cur r: 0.6984 best r: 0.6984
15:24:29,26 root INFO 
id:et_en cur r: 0.6629 best r: 0.6629
15:24:42,194 root INFO 
id:si_en cur r: 0.4838 best r: 0.4838
15:24:55,337 root INFO 
id:ne_en cur r: 0.6468 best r: 0.6468
15:25:08,379 root INFO 
id:ru_en cur r: 0.6999 best r: 0.6999
15:25:08,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:40,198 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:26:40,205 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:26:40,210 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:26:40,215 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:26:40,221 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:26:40,226 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:26:40,231 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:26:53,382 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6506
en_de Dev loss: 0.9108 r:0.1581
en_zh Dev loss: 0.7021 r:0.4032
ro_en Dev loss: 0.4261 r:0.7143
et_en Dev loss: 0.3883 r:0.6790
si_en Dev loss: 0.6718 r:0.5058
ne_en Dev loss: 0.4635 r:0.6522
ru_en Dev loss: 0.4253 r:0.7240
Current avg r:0.5481 Best avg r: 0.5481
15:31:27,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:54,176 root INFO 
id:en_zh cur r: 0.3881 best r: 0.3881
15:32:07,299 root INFO 
id:ro_en cur r: 0.7186 best r: 0.7186
15:32:33,592 root INFO 
id:et_en cur r: 0.6683 best r: 0.6683
15:32:46,753 root INFO 
id:si_en cur r: 0.4924 best r: 0.4924
15:33:12,949 root INFO 
id:ru_en cur r: 0.7028 best r: 0.7028
15:33:12,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:44,766 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:34:44,772 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:34:44,778 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:34:44,782 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:34:44,787 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:34:44,792 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:34:44,796 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:34:57,938 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6340
en_de Dev loss: 0.9149 r:0.1616
en_zh Dev loss: 0.7215 r:0.4050
ro_en Dev loss: 0.4114 r:0.7355
et_en Dev loss: 0.3876 r:0.6731
si_en Dev loss: 0.6575 r:0.5170
ne_en Dev loss: 0.4604 r:0.6578
ru_en Dev loss: 0.4483 r:0.7207
Current avg r:0.5530 Best avg r: 0.5530
15:39:32,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:58,539 root INFO 
id:en_zh cur r: 0.3962 best r: 0.3962
15:40:11,655 root INFO 
id:ro_en cur r: 0.7375 best r: 0.7375
15:40:37,945 root INFO 
id:si_en cur r: 0.5011 best r: 0.5011
15:40:51,87 root INFO 
id:ne_en cur r: 0.6747 best r: 0.6747
15:41:04,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:35,937 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:42:35,943 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:42:35,948 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:42:35,952 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:42:35,957 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:42:35,961 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:42:35,965 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:42:49,94 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5859
en_de Dev loss: 0.9222 r:0.1763
en_zh Dev loss: 0.8043 r:0.4044
ro_en Dev loss: 0.4465 r:0.7418
et_en Dev loss: 0.4079 r:0.6708
si_en Dev loss: 0.7399 r:0.5201
ne_en Dev loss: 0.5000 r:0.6554
ru_en Dev loss: 0.5242 r:0.7133
Current avg r:0.5546 Best avg r: 0.5546
15:47:23,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:49,733 root INFO 
id:en_zh cur r: 0.4376 best r: 0.4376
15:48:02,859 root INFO 
id:ro_en cur r: 0.7513 best r: 0.7513
15:48:29,181 root INFO 
id:et_en cur r: 0.6706 best r: 0.6706
15:48:42,339 root INFO 
id:si_en cur r: 0.5269 best r: 0.5269
15:48:55,488 root INFO 
id:ne_en cur r: 0.7008 best r: 0.7008
15:49:08,542 root INFO 
id:ru_en cur r: 0.7144 best r: 0.7144
15:49:08,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:40,339 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:50:40,345 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:50:40,349 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:50:40,357 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:50:40,365 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:50:40,369 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:50:40,374 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:50:53,526 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6334
en_de Dev loss: 0.8728 r:0.1851
en_zh Dev loss: 0.6778 r:0.4394
ro_en Dev loss: 0.3795 r:0.7556
et_en Dev loss: 0.3854 r:0.6833
si_en Dev loss: 0.6057 r:0.5470
ne_en Dev loss: 0.4037 r:0.7031
ru_en Dev loss: 0.4276 r:0.7339
Current avg r:0.5782 Best avg r: 0.5782
15:55:28,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:07,633 root INFO 
id:ro_en cur r: 0.7523 best r: 0.7523
15:56:33,952 root INFO 
id:et_en cur r: 0.6768 best r: 0.6768
15:56:47,117 root INFO 
id:si_en cur r: 0.5368 best r: 0.5368
15:57:00,275 root INFO 
id:ne_en cur r: 0.7100 best r: 0.7100
15:57:13,324 root INFO 
id:ru_en cur r: 0.7282 best r: 0.7282
15:57:13,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:45,180 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:58:45,185 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:58:45,191 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:58:45,197 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:58:45,202 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:58:45,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:58:45,211 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:58:58,362 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5751
en_de Dev loss: 0.9044 r:0.1962
en_zh Dev loss: 0.7038 r:0.4361
ro_en Dev loss: 0.3910 r:0.7616
et_en Dev loss: 0.3698 r:0.6908
si_en Dev loss: 0.6558 r:0.5574
ne_en Dev loss: 0.4393 r:0.6935
ru_en Dev loss: 0.4747 r:0.7375
Current avg r:0.5819 Best avg r: 0.5819
16:03:33,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:12,534 root INFO 
id:ro_en cur r: 0.7606 best r: 0.7606
16:04:38,816 root INFO 
id:et_en cur r: 0.6774 best r: 0.6774
16:04:51,972 root INFO 
id:si_en cur r: 0.5501 best r: 0.5501
16:05:05,137 root INFO 
id:ne_en cur r: 0.7188 best r: 0.7188
16:05:18,188 root INFO 
id:ru_en cur r: 0.7375 best r: 0.7375
16:05:18,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:49,998 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:06:50,4 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:06:50,8 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:06:50,13 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:06:50,18 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:06:50,22 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:06:50,27 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:07:03,188 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5527
en_de Dev loss: 0.8910 r:0.2034
en_zh Dev loss: 0.7051 r:0.4409
ro_en Dev loss: 0.3726 r:0.7654
et_en Dev loss: 0.3790 r:0.6853
si_en Dev loss: 0.6245 r:0.5666
ne_en Dev loss: 0.4130 r:0.7048
ru_en Dev loss: 0.4228 r:0.7436
Current avg r:0.5872 Best avg r: 0.5872
16:11:37,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:17,295 root INFO 
id:ro_en cur r: 0.7621 best r: 0.7621
16:13:09,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:41,625 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5405
en_de Dev loss: 0.8745 r:0.1829
en_zh Dev loss: 0.7165 r:0.4442
ro_en Dev loss: 0.4011 r:0.7651
et_en Dev loss: 0.3771 r:0.6855
si_en Dev loss: 0.7026 r:0.5563
ne_en Dev loss: 0.4446 r:0.6994
ru_en Dev loss: 0.4787 r:0.7380
Current avg r:0.5816 Best avg r: 0.5872
16:19:16,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:55,565 root INFO 
id:ro_en cur r: 0.7748 best r: 0.7748
16:20:21,864 root INFO 
id:et_en cur r: 0.6789 best r: 0.6789
16:21:01,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:33,31 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5904
en_de Dev loss: 0.8640 r:0.1765
en_zh Dev loss: 0.7432 r:0.4293
ro_en Dev loss: 0.3806 r:0.7776
et_en Dev loss: 0.3735 r:0.6894
si_en Dev loss: 0.6922 r:0.5648
ne_en Dev loss: 0.4190 r:0.7120
ru_en Dev loss: 0.4501 r:0.7382
Current avg r:0.5840 Best avg r: 0.5872
16:27:07,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:47,244 root INFO 
id:ro_en cur r: 0.7801 best r: 0.7801
16:28:39,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:11,555 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5542
en_de Dev loss: 0.9041 r:0.1993
en_zh Dev loss: 0.8061 r:0.4412
ro_en Dev loss: 0.4362 r:0.7773
et_en Dev loss: 0.4359 r:0.6754
si_en Dev loss: 0.8656 r:0.5476
ne_en Dev loss: 0.5150 r:0.6982
ru_en Dev loss: 0.5255 r:0.7196
Current avg r:0.5798 Best avg r: 0.5872
16:34:46,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:12,710 root INFO 
id:en_zh cur r: 0.4421 best r: 0.4421
16:35:25,842 root INFO 
id:ro_en cur r: 0.7960 best r: 0.7960
16:35:52,156 root INFO 
id:et_en cur r: 0.6921 best r: 0.6921
16:36:05,345 root INFO 
id:si_en cur r: 0.5735 best r: 0.5735
16:36:18,512 root INFO 
id:ne_en cur r: 0.7313 best r: 0.7313
16:36:31,556 root INFO 
id:ru_en cur r: 0.7551 best r: 0.7551
16:36:31,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:03,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:38:03,376 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:38:03,382 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:38:03,386 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:38:03,392 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:38:03,397 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:38:03,402 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:38:16,569 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5545
en_de Dev loss: 0.8783 r:0.1836
en_zh Dev loss: 0.6716 r:0.4590
ro_en Dev loss: 0.3375 r:0.7905
et_en Dev loss: 0.3776 r:0.6981
si_en Dev loss: 0.6155 r:0.5919
ne_en Dev loss: 0.3967 r:0.7302
ru_en Dev loss: 0.3755 r:0.7570
Current avg r:0.6015 Best avg r: 0.6015
16:42:53,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:06,256 root INFO 
id:en_de cur r: 0.1795 best r: 0.1795
16:44:24,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:56,799 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5259
en_de Dev loss: 0.9273 r:0.1947
en_zh Dev loss: 0.8055 r:0.4436
ro_en Dev loss: 0.4834 r:0.7826
et_en Dev loss: 0.4553 r:0.6785
si_en Dev loss: 0.7541 r:0.5652
ne_en Dev loss: 0.5104 r:0.7170
ru_en Dev loss: 0.6120 r:0.7177
Current avg r:0.5856 Best avg r: 0.6015
16:50:31,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:44,590 root INFO 
id:en_de cur r: 0.2028 best r: 0.2028
16:51:37,159 root INFO 
id:si_en cur r: 0.5749 best r: 0.5749
16:52:03,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:35,204 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5343
en_de Dev loss: 0.8954 r:0.1962
en_zh Dev loss: 0.7255 r:0.4520
ro_en Dev loss: 0.3838 r:0.7886
et_en Dev loss: 0.4017 r:0.6859
si_en Dev loss: 0.6889 r:0.5730
ne_en Dev loss: 0.4483 r:0.7243
ru_en Dev loss: 0.5162 r:0.7269
Current avg r:0.5924 Best avg r: 0.6015
16:58:10,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:23,337 root INFO 
id:en_de cur r: 0.2042 best r: 0.2042
16:58:36,476 root INFO 
id:en_zh cur r: 0.4437 best r: 0.4437
16:58:49,661 root INFO 
id:ro_en cur r: 0.8006 best r: 0.8006
16:59:29,244 root INFO 
id:ne_en cur r: 0.7368 best r: 0.7368
16:59:42,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:14,477 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5257
en_de Dev loss: 0.8774 r:0.1962
en_zh Dev loss: 0.7149 r:0.4581
ro_en Dev loss: 0.3495 r:0.7969
et_en Dev loss: 0.3854 r:0.6926
si_en Dev loss: 0.6581 r:0.5863
ne_en Dev loss: 0.4396 r:0.7361
ru_en Dev loss: 0.4621 r:0.7394
Current avg r:0.6008 Best avg r: 0.6015
17:05:49,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:55,352 root INFO 
id:si_en cur r: 0.5924 best r: 0.5924
17:07:08,543 root INFO 
id:ne_en cur r: 0.7472 best r: 0.7472
17:07:21,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:53,729 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
17:08:53,736 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:08:53,741 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:08:53,745 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
17:08:53,752 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
17:08:53,756 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:08:53,761 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:09:06,950 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5064
en_de Dev loss: 0.8656 r:0.2059
en_zh Dev loss: 0.7274 r:0.4489
ro_en Dev loss: 0.3504 r:0.7980
et_en Dev loss: 0.3777 r:0.6919
si_en Dev loss: 0.5871 r:0.6046
ne_en Dev loss: 0.4006 r:0.7457
ru_en Dev loss: 0.4129 r:0.7447
Current avg r:0.6057 Best avg r: 0.6057
17:13:41,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:08,173 root INFO 
id:en_zh cur r: 0.4555 best r: 0.4555
17:14:21,340 root INFO 
id:ro_en cur r: 0.8049 best r: 0.8049
17:14:47,712 root INFO 
id:et_en cur r: 0.6932 best r: 0.6932
17:15:00,914 root INFO 
id:si_en cur r: 0.5932 best r: 0.5932
17:15:27,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:59,307 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
17:16:59,314 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:16:59,318 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:16:59,323 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
17:16:59,329 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
17:16:59,333 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:16:59,338 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:17:12,526 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4991
en_de Dev loss: 0.8515 r:0.2064
en_zh Dev loss: 0.6589 r:0.4608
ro_en Dev loss: 0.3269 r:0.8020
et_en Dev loss: 0.3800 r:0.7006
si_en Dev loss: 0.5729 r:0.6033
ne_en Dev loss: 0.3547 r:0.7515
ru_en Dev loss: 0.4041 r:0.7402
Current avg r:0.6093 Best avg r: 0.6093
17:21:47,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:00,631 root INFO 
id:en_de cur r: 0.2067 best r: 0.2067
17:23:19,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:51,687 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4949
en_de Dev loss: 0.9146 r:0.2128
en_zh Dev loss: 0.7891 r:0.4575
ro_en Dev loss: 0.3920 r:0.8025
et_en Dev loss: 0.3968 r:0.6936
si_en Dev loss: 0.7255 r:0.5958
ne_en Dev loss: 0.4469 r:0.7486
ru_en Dev loss: 0.4708 r:0.7440
Current avg r:0.6078 Best avg r: 0.6093
17:29:26,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:39,757 root INFO 
id:en_de cur r: 0.2144 best r: 0.2144
17:29:52,899 root INFO 
id:en_zh cur r: 0.4715 best r: 0.4715
17:30:06,78 root INFO 
id:ro_en cur r: 0.8117 best r: 0.8117
17:30:32,458 root INFO 
id:si_en cur r: 0.6108 best r: 0.6108
17:30:45,662 root INFO 
id:ne_en cur r: 0.7516 best r: 0.7516
17:30:58,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:30,855 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
17:32:30,861 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:32:30,865 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:32:30,871 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
17:32:30,876 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
17:32:30,881 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:32:30,885 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:32:44,90 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4904
en_de Dev loss: 0.8551 r:0.2093
en_zh Dev loss: 0.6922 r:0.4692
ro_en Dev loss: 0.3217 r:0.8101
et_en Dev loss: 0.3857 r:0.6986
si_en Dev loss: 0.6486 r:0.6109
ne_en Dev loss: 0.3748 r:0.7583
ru_en Dev loss: 0.4136 r:0.7559
Current avg r:0.6160 Best avg r: 0.6160
17:37:19,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:32,592 root INFO 
id:en_de cur r: 0.2278 best r: 0.2278
17:38:25,286 root INFO 
id:et_en cur r: 0.6992 best r: 0.6992
17:38:51,682 root INFO 
id:ne_en cur r: 0.7581 best r: 0.7581
17:39:04,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:36,888 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4847
en_de Dev loss: 0.8925 r:0.2108
en_zh Dev loss: 0.7859 r:0.4571
ro_en Dev loss: 0.3823 r:0.8052
et_en Dev loss: 0.3899 r:0.7042
si_en Dev loss: 0.7033 r:0.6060
ne_en Dev loss: 0.4200 r:0.7613
ru_en Dev loss: 0.4735 r:0.7413
Current avg r:0.6123 Best avg r: 0.6160
17:45:11,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:43,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:16,33 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4876
en_de Dev loss: 0.8566 r:0.2118
en_zh Dev loss: 0.7251 r:0.4623
ro_en Dev loss: 0.3330 r:0.8048
et_en Dev loss: 0.4039 r:0.6893
si_en Dev loss: 0.7388 r:0.5994
ne_en Dev loss: 0.3755 r:0.7578
ru_en Dev loss: 0.4704 r:0.7355
Current avg r:0.6087 Best avg r: 0.6160
17:52:51,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:04,410 root INFO 
id:en_de cur r: 0.2520 best r: 0.2520
17:54:10,335 root INFO 
id:ne_en cur r: 0.7592 best r: 0.7592
17:54:23,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:55,473 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4939
en_de Dev loss: 0.8829 r:0.2470
en_zh Dev loss: 0.7560 r:0.4708
ro_en Dev loss: 0.3889 r:0.7989
et_en Dev loss: 0.4120 r:0.6872
si_en Dev loss: 0.6802 r:0.5984
ne_en Dev loss: 0.4411 r:0.7594
ru_en Dev loss: 0.5004 r:0.7305
Current avg r:0.6132 Best avg r: 0.6160
18:00:30,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:56,576 root INFO 
id:en_zh cur r: 0.4772 best r: 0.4772
18:01:49,323 root INFO 
id:ne_en cur r: 0.7615 best r: 0.7615
18:02:02,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:34,479 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4778
en_de Dev loss: 0.8528 r:0.2329
en_zh Dev loss: 0.6933 r:0.4728
ro_en Dev loss: 0.3467 r:0.8075
et_en Dev loss: 0.3912 r:0.6914
si_en Dev loss: 0.6960 r:0.6028
ne_en Dev loss: 0.4668 r:0.7626
ru_en Dev loss: 0.4856 r:0.7202
Current avg r:0.6129 Best avg r: 0.6160
18:08:09,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:41,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:13,704 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4891
en_de Dev loss: 0.8677 r:0.2102
en_zh Dev loss: 0.8090 r:0.4576
ro_en Dev loss: 0.3820 r:0.8043
et_en Dev loss: 0.4104 r:0.6857
si_en Dev loss: 0.8103 r:0.5949
ne_en Dev loss: 0.5155 r:0.7462
ru_en Dev loss: 0.5404 r:0.7163
Current avg r:0.6022 Best avg r: 0.6160
18:15:48,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:21,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:53,239 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4817
en_de Dev loss: 0.8823 r:0.2317
en_zh Dev loss: 0.7187 r:0.4650
ro_en Dev loss: 0.4004 r:0.8033
et_en Dev loss: 0.4106 r:0.6898
si_en Dev loss: 0.8397 r:0.5939
ne_en Dev loss: 0.4837 r:0.7546
ru_en Dev loss: 0.4966 r:0.7300
Current avg r:0.6098 Best avg r: 0.6160
18:23:28,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:54,396 root INFO 
id:en_zh cur r: 0.4951 best r: 0.4951
18:24:07,573 root INFO 
id:ro_en cur r: 0.8131 best r: 0.8131
18:25:00,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:32,340 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
18:26:32,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:26:32,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:26:32,358 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
18:26:32,364 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
18:26:32,369 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:26:32,373 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:26:45,559 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4976
en_de Dev loss: 0.8350 r:0.2452
en_zh Dev loss: 0.6418 r:0.4881
ro_en Dev loss: 0.3135 r:0.8096
et_en Dev loss: 0.3897 r:0.6968
si_en Dev loss: 0.6335 r:0.6103
ne_en Dev loss: 0.4042 r:0.7568
ru_en Dev loss: 0.3639 r:0.7555
Current avg r:0.6232 Best avg r: 0.6232
18:31:20,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:59,823 root INFO 
id:ro_en cur r: 0.8213 best r: 0.8213
18:32:26,198 root INFO 
id:et_en cur r: 0.7003 best r: 0.7003
18:32:39,394 root INFO 
id:si_en cur r: 0.6219 best r: 0.6219
18:32:52,604 root INFO 
id:ne_en cur r: 0.7617 best r: 0.7617
18:33:05,703 root INFO 
id:ru_en cur r: 0.7631 best r: 0.7631
18:33:05,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:37,768 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
18:34:37,774 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:34:37,779 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:34:37,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
18:34:37,791 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
18:34:37,796 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:34:37,801 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:34:50,991 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4624
en_de Dev loss: 0.8363 r:0.2509
en_zh Dev loss: 0.6520 r:0.4839
ro_en Dev loss: 0.2947 r:0.8179
et_en Dev loss: 0.3851 r:0.7086
si_en Dev loss: 0.6018 r:0.6187
ne_en Dev loss: 0.3355 r:0.7624
ru_en Dev loss: 0.3675 r:0.7628
Current avg r:0.6293 Best avg r: 0.6293
18:39:27,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:40,386 root INFO 
id:en_de cur r: 0.2612 best r: 0.2612
18:40:59,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:31,419 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4394
en_de Dev loss: 0.8506 r:0.2474
en_zh Dev loss: 0.7169 r:0.4699
ro_en Dev loss: 0.3623 r:0.8036
et_en Dev loss: 0.4080 r:0.6824
si_en Dev loss: 0.7817 r:0.5915
ne_en Dev loss: 0.5272 r:0.7546
ru_en Dev loss: 0.4825 r:0.7291
Current avg r:0.6112 Best avg r: 0.6293
18:47:06,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:38,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:10,480 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4436
en_de Dev loss: 0.8922 r:0.2235
en_zh Dev loss: 0.7902 r:0.4559
ro_en Dev loss: 0.3853 r:0.8096
et_en Dev loss: 0.4225 r:0.6861
si_en Dev loss: 0.7923 r:0.5989
ne_en Dev loss: 0.5013 r:0.7459
ru_en Dev loss: 0.5262 r:0.7273
Current avg r:0.6067 Best avg r: 0.6293
18:54:45,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:17,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:49,493 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4591
en_de Dev loss: 0.8452 r:0.2269
en_zh Dev loss: 0.6851 r:0.4542
ro_en Dev loss: 0.3340 r:0.8087
et_en Dev loss: 0.4111 r:0.6782
si_en Dev loss: 0.6384 r:0.6004
ne_en Dev loss: 0.4273 r:0.7525
ru_en Dev loss: 0.4270 r:0.7325
Current avg r:0.6076 Best avg r: 0.6293
19:02:24,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:56,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:28,509 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4358
en_de Dev loss: 0.8508 r:0.2246
en_zh Dev loss: 0.7325 r:0.4612
ro_en Dev loss: 0.3676 r:0.8126
et_en Dev loss: 0.4252 r:0.6886
si_en Dev loss: 0.6930 r:0.6049
ne_en Dev loss: 0.3899 r:0.7540
ru_en Dev loss: 0.4219 r:0.7502
Current avg r:0.6137 Best avg r: 0.6293
19:10:03,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:16,527 root INFO 
id:en_de cur r: 0.2618 best r: 0.2618
19:10:42,821 root INFO 
id:ro_en cur r: 0.8226 best r: 0.8226
19:11:35,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:07,493 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4118
en_de Dev loss: 0.8479 r:0.2482
en_zh Dev loss: 0.7197 r:0.4701
ro_en Dev loss: 0.3438 r:0.8198
et_en Dev loss: 0.4134 r:0.6827
si_en Dev loss: 0.7080 r:0.6118
ne_en Dev loss: 0.4008 r:0.7542
ru_en Dev loss: 0.4335 r:0.7515
Current avg r:0.6198 Best avg r: 0.6293
19:17:42,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:48,163 root INFO 
id:si_en cur r: 0.6251 best r: 0.6251
19:19:01,355 root INFO 
id:ne_en cur r: 0.7654 best r: 0.7654
19:19:14,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:46,475 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4466
en_de Dev loss: 0.8440 r:0.2363
en_zh Dev loss: 0.6810 r:0.4651
ro_en Dev loss: 0.3274 r:0.8171
et_en Dev loss: 0.4293 r:0.6780
si_en Dev loss: 0.5804 r:0.6212
ne_en Dev loss: 0.3573 r:0.7631
ru_en Dev loss: 0.4008 r:0.7398
Current avg r:0.6172 Best avg r: 0.6293
19:25:21,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:34,569 root INFO 
id:en_de cur r: 0.2764 best r: 0.2764
19:26:53,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:25,622 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4551
en_de Dev loss: 0.8277 r:0.2682
en_zh Dev loss: 0.7014 r:0.4637
ro_en Dev loss: 0.3286 r:0.8158
et_en Dev loss: 0.4155 r:0.6772
si_en Dev loss: 0.7849 r:0.6080
ne_en Dev loss: 0.5120 r:0.7497
ru_en Dev loss: 0.4573 r:0.7264
Current avg r:0.6156 Best avg r: 0.6293
19:33:00,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:32,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:04,832 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4270
en_de Dev loss: 0.8420 r:0.2504
en_zh Dev loss: 0.7040 r:0.4722
ro_en Dev loss: 0.3239 r:0.8177
et_en Dev loss: 0.4201 r:0.6914
si_en Dev loss: 0.6140 r:0.6168
ne_en Dev loss: 0.3892 r:0.7516
ru_en Dev loss: 0.4189 r:0.7498
Current avg r:0.6214 Best avg r: 0.6293
19:40:40,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:12,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:44,658 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4353
en_de Dev loss: 0.8799 r:0.2261
en_zh Dev loss: 0.8235 r:0.4553
ro_en Dev loss: 0.4092 r:0.8080
et_en Dev loss: 0.4515 r:0.6691
si_en Dev loss: 0.9165 r:0.5886
ne_en Dev loss: 0.5233 r:0.7480
ru_en Dev loss: 0.5148 r:0.7239
Current avg r:0.6027 Best avg r: 0.6293
19:48:20,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:52,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:24,368 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4265
en_de Dev loss: 0.8659 r:0.2361
en_zh Dev loss: 0.7269 r:0.4785
ro_en Dev loss: 0.3659 r:0.8145
et_en Dev loss: 0.4241 r:0.6817
si_en Dev loss: 0.7899 r:0.6003
ne_en Dev loss: 0.4901 r:0.7475
ru_en Dev loss: 0.4586 r:0.7434
Current avg r:0.6146 Best avg r: 0.6293
19:55:59,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:31,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:03,926 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3897
en_de Dev loss: 0.8599 r:0.2357
en_zh Dev loss: 0.7470 r:0.4533
ro_en Dev loss: 0.3406 r:0.8073
et_en Dev loss: 0.4441 r:0.6774
si_en Dev loss: 0.6650 r:0.5940
ne_en Dev loss: 0.3990 r:0.7439
ru_en Dev loss: 0.4484 r:0.7226
Current avg r:0.6049 Best avg r: 0.6293
20:03:39,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:11,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:43,970 root INFO Epoch 2 Global steps: 29400 Train loss: 0.4196
en_de Dev loss: 0.8417 r:0.2328
en_zh Dev loss: 0.7182 r:0.4715
ro_en Dev loss: 0.3659 r:0.8135
et_en Dev loss: 0.4541 r:0.6808
si_en Dev loss: 0.7206 r:0.6034
ne_en Dev loss: 0.4573 r:0.7460
ru_en Dev loss: 0.4530 r:0.7313
Current avg r:0.6113 Best avg r: 0.6293
20:11:19,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:51,342 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:23,451 root INFO Epoch 2 Global steps: 30100 Train loss: 0.4102
en_de Dev loss: 0.8366 r:0.2487
en_zh Dev loss: 0.7097 r:0.4814
ro_en Dev loss: 0.3367 r:0.8170
et_en Dev loss: 0.4091 r:0.6910
si_en Dev loss: 0.6906 r:0.6108
ne_en Dev loss: 0.4653 r:0.7607
ru_en Dev loss: 0.4560 r:0.7382
Current avg r:0.6211 Best avg r: 0.6293
20:18:58,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:30,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:03,53 root INFO Epoch 2 Global steps: 30800 Train loss: 0.4055
en_de Dev loss: 0.8606 r:0.2623
en_zh Dev loss: 0.7398 r:0.4749
ro_en Dev loss: 0.3584 r:0.8111
et_en Dev loss: 0.4595 r:0.6792
si_en Dev loss: 0.7104 r:0.5993
ne_en Dev loss: 0.4395 r:0.7576
ru_en Dev loss: 0.4642 r:0.7319
Current avg r:0.6166 Best avg r: 0.6293
20:26:38,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:10,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:42,775 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3980
en_de Dev loss: 0.8662 r:0.2486
en_zh Dev loss: 0.8068 r:0.4633
ro_en Dev loss: 0.4187 r:0.8082
et_en Dev loss: 0.4861 r:0.6678
si_en Dev loss: 0.8066 r:0.5928
ne_en Dev loss: 0.5040 r:0.7521
ru_en Dev loss: 0.5139 r:0.7281
Current avg r:0.6087 Best avg r: 0.6293
20:34:19,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:51,790 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:23,969 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3620
en_de Dev loss: 0.8747 r:0.2411
en_zh Dev loss: 0.8223 r:0.4594
ro_en Dev loss: 0.4185 r:0.8071
et_en Dev loss: 0.4796 r:0.6695
si_en Dev loss: 0.9298 r:0.5863
ne_en Dev loss: 0.5517 r:0.7488
ru_en Dev loss: 0.5612 r:0.7199
Current avg r:0.6046 Best avg r: 0.6293
20:41:59,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:31,568 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:03,764 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3885
en_de Dev loss: 0.8751 r:0.2321
en_zh Dev loss: 0.7597 r:0.4691
ro_en Dev loss: 0.4041 r:0.8067
et_en Dev loss: 0.4447 r:0.6655
si_en Dev loss: 0.8317 r:0.5908
ne_en Dev loss: 0.5561 r:0.7511
ru_en Dev loss: 0.4947 r:0.7280
Current avg r:0.6062 Best avg r: 0.6293
20:49:39,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:11,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:43,524 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3729
en_de Dev loss: 0.8509 r:0.2386
en_zh Dev loss: 0.7236 r:0.4611
ro_en Dev loss: 0.3598 r:0.8100
et_en Dev loss: 0.4553 r:0.6645
si_en Dev loss: 0.6649 r:0.6039
ne_en Dev loss: 0.3922 r:0.7606
ru_en Dev loss: 0.4486 r:0.7323
Current avg r:0.6102 Best avg r: 0.6293
20:57:18,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:51,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:23,383 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3669
en_de Dev loss: 0.8652 r:0.2318
en_zh Dev loss: 0.7272 r:0.4836
ro_en Dev loss: 0.3574 r:0.8120
et_en Dev loss: 0.4784 r:0.6716
si_en Dev loss: 0.7547 r:0.5988
ne_en Dev loss: 0.4694 r:0.7444
ru_en Dev loss: 0.4570 r:0.7443
Current avg r:0.6124 Best avg r: 0.6293
21:04:58,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:31,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:03,265 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3637
en_de Dev loss: 0.8367 r:0.2447
en_zh Dev loss: 0.6760 r:0.4764
ro_en Dev loss: 0.3131 r:0.8160
et_en Dev loss: 0.4554 r:0.6819
si_en Dev loss: 0.5954 r:0.6091
ne_en Dev loss: 0.3662 r:0.7556
ru_en Dev loss: 0.3879 r:0.7501
Current avg r:0.6191 Best avg r: 0.6293
21:12:38,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:11,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:43,237 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3427
en_de Dev loss: 0.8597 r:0.2403
en_zh Dev loss: 0.7654 r:0.4502
ro_en Dev loss: 0.3508 r:0.8131
et_en Dev loss: 0.4488 r:0.6663
si_en Dev loss: 0.7809 r:0.5884
ne_en Dev loss: 0.4768 r:0.7527
ru_en Dev loss: 0.4506 r:0.7337
Current avg r:0.6064 Best avg r: 0.6293
21:20:18,871 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:51,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:23,404 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3466
en_de Dev loss: 0.8549 r:0.2237
en_zh Dev loss: 0.7591 r:0.4598
ro_en Dev loss: 0.3942 r:0.8092
et_en Dev loss: 0.4772 r:0.6639
si_en Dev loss: 0.7570 r:0.5924
ne_en Dev loss: 0.4583 r:0.7473
ru_en Dev loss: 0.5298 r:0.7097
Current avg r:0.6008 Best avg r: 0.6293
21:27:58,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:29:31,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:03,465 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3603
en_de Dev loss: 0.9025 r:0.2137
en_zh Dev loss: 0.8009 r:0.4577
ro_en Dev loss: 0.4209 r:0.8114
et_en Dev loss: 0.4884 r:0.6707
si_en Dev loss: 0.8321 r:0.5953
ne_en Dev loss: 0.4619 r:0.7487
ru_en Dev loss: 0.5415 r:0.7262
Current avg r:0.6034 Best avg r: 0.6293
21:35:39,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:11,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:43,519 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3671
en_de Dev loss: 0.8434 r:0.2272
en_zh Dev loss: 0.7196 r:0.4711
ro_en Dev loss: 0.3394 r:0.8147
et_en Dev loss: 0.4543 r:0.6807
si_en Dev loss: 0.7189 r:0.6000
ne_en Dev loss: 0.4357 r:0.7422
ru_en Dev loss: 0.4196 r:0.7504
Current avg r:0.6123 Best avg r: 0.6293
21:43:19,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:51,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:23,571 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3626
en_de Dev loss: 0.8558 r:0.2194
en_zh Dev loss: 0.7712 r:0.4463
ro_en Dev loss: 0.3611 r:0.8099
et_en Dev loss: 0.4510 r:0.6654
si_en Dev loss: 0.7330 r:0.5936
ne_en Dev loss: 0.4718 r:0.7544
ru_en Dev loss: 0.4308 r:0.7360
Current avg r:0.6036 Best avg r: 0.6293
21:50:59,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:31,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:03,575 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3509
en_de Dev loss: 0.8705 r:0.2226
en_zh Dev loss: 0.7800 r:0.4443
ro_en Dev loss: 0.3642 r:0.8177
et_en Dev loss: 0.4544 r:0.6628
si_en Dev loss: 0.8115 r:0.5973
ne_en Dev loss: 0.4847 r:0.7482
ru_en Dev loss: 0.5027 r:0.7157
Current avg r:0.6012 Best avg r: 0.6293
21:58:39,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:11,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:43,700 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3555
en_de Dev loss: 0.8363 r:0.2430
en_zh Dev loss: 0.7086 r:0.4539
ro_en Dev loss: 0.3207 r:0.8139
et_en Dev loss: 0.4815 r:0.6678
si_en Dev loss: 0.6345 r:0.5966
ne_en Dev loss: 0.4236 r:0.7546
ru_en Dev loss: 0.4287 r:0.7208
Current avg r:0.6072 Best avg r: 0.6293
22:06:19,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:07:51,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:23,861 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3754
en_de Dev loss: 0.8289 r:0.2563
en_zh Dev loss: 0.7254 r:0.4579
ro_en Dev loss: 0.3332 r:0.8154
et_en Dev loss: 0.4716 r:0.6623
si_en Dev loss: 0.7072 r:0.5867
ne_en Dev loss: 0.4606 r:0.7412
ru_en Dev loss: 0.4416 r:0.7249
Current avg r:0.6064 Best avg r: 0.6293
22:13:59,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:12,592 root INFO 
id:en_de cur r: 0.2768 best r: 0.2768
22:15:31,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:03,938 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3639
en_de Dev loss: 0.8339 r:0.2444
en_zh Dev loss: 0.7227 r:0.4458
ro_en Dev loss: 0.3078 r:0.8213
et_en Dev loss: 0.4751 r:0.6705
si_en Dev loss: 0.6616 r:0.5955
ne_en Dev loss: 0.3946 r:0.7440
ru_en Dev loss: 0.3870 r:0.7508
Current avg r:0.6103 Best avg r: 0.6293
22:21:39,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:11,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:24:43,960 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3587
en_de Dev loss: 0.8442 r:0.2393
en_zh Dev loss: 0.7443 r:0.4441
ro_en Dev loss: 0.3436 r:0.8169
et_en Dev loss: 0.4736 r:0.6647
si_en Dev loss: 0.7058 r:0.5915
ne_en Dev loss: 0.4487 r:0.7499
ru_en Dev loss: 0.4424 r:0.7269
Current avg r:0.6048 Best avg r: 0.6293
22:29:20,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:30:53,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:25,468 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3154
en_de Dev loss: 0.8494 r:0.2428
en_zh Dev loss: 0.7457 r:0.4468
ro_en Dev loss: 0.3413 r:0.8179
et_en Dev loss: 0.4755 r:0.6747
si_en Dev loss: 0.6358 r:0.6055
ne_en Dev loss: 0.4143 r:0.7410
ru_en Dev loss: 0.4533 r:0.7244
Current avg r:0.6076 Best avg r: 0.6293
22:37:01,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:33,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:05,558 root INFO Epoch 4 Global steps: 43400 Train loss: 0.3247
en_de Dev loss: 0.8965 r:0.2055
en_zh Dev loss: 0.8685 r:0.4311
ro_en Dev loss: 0.4144 r:0.8114
et_en Dev loss: 0.5025 r:0.6600
si_en Dev loss: 0.8631 r:0.5865
ne_en Dev loss: 0.6365 r:0.7385
ru_en Dev loss: 0.5355 r:0.7153
Current avg r:0.5926 Best avg r: 0.6293
22:44:41,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:13,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:45,732 root INFO Epoch 4 Global steps: 44100 Train loss: 0.3147
en_de Dev loss: 0.8717 r:0.2170
en_zh Dev loss: 0.8263 r:0.4350
ro_en Dev loss: 0.3828 r:0.8083
et_en Dev loss: 0.5573 r:0.6587
si_en Dev loss: 0.7653 r:0.5887
ne_en Dev loss: 0.4277 r:0.7444
ru_en Dev loss: 0.4919 r:0.7155
Current avg r:0.5954 Best avg r: 0.6293
22:52:21,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:53,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:25,590 root INFO Epoch 4 Global steps: 44800 Train loss: 0.3190
en_de Dev loss: 0.8619 r:0.2084
en_zh Dev loss: 0.7775 r:0.4496
ro_en Dev loss: 0.3601 r:0.8167
et_en Dev loss: 0.5271 r:0.6493
si_en Dev loss: 0.8563 r:0.5840
ne_en Dev loss: 0.5054 r:0.7472
ru_en Dev loss: 0.4404 r:0.7288
Current avg r:0.5977 Best avg r: 0.6293
23:00:00,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:32,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:04,981 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2920
en_de Dev loss: 0.8803 r:0.2144
en_zh Dev loss: 0.7922 r:0.4522
ro_en Dev loss: 0.3729 r:0.8185
et_en Dev loss: 0.5242 r:0.6519
si_en Dev loss: 0.8687 r:0.5812
ne_en Dev loss: 0.4484 r:0.7454
ru_en Dev loss: 0.4790 r:0.7299
Current avg r:0.5991 Best avg r: 0.6293
23:07:40,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:09:12,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:44,247 root INFO Epoch 4 Global steps: 46200 Train loss: 0.3292
en_de Dev loss: 0.8640 r:0.2003
en_zh Dev loss: 0.7600 r:0.4557
ro_en Dev loss: 0.3526 r:0.8179
et_en Dev loss: 0.5137 r:0.6559
si_en Dev loss: 0.7444 r:0.5847
ne_en Dev loss: 0.4126 r:0.7366
ru_en Dev loss: 0.4198 r:0.7436
Current avg r:0.5993 Best avg r: 0.6293
23:15:19,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:51,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:23,218 root INFO Epoch 4 Global steps: 46900 Train loss: 0.3158
en_de Dev loss: 0.8749 r:0.2030
en_zh Dev loss: 0.7932 r:0.4365
ro_en Dev loss: 0.3641 r:0.8112
et_en Dev loss: 0.5388 r:0.6518
si_en Dev loss: 0.7509 r:0.5787
ne_en Dev loss: 0.4213 r:0.7415
ru_en Dev loss: 0.4491 r:0.7329
Current avg r:0.5936 Best avg r: 0.6293
23:22:57,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:30,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:02,79 root INFO Epoch 4 Global steps: 47600 Train loss: 0.3248
en_de Dev loss: 0.8442 r:0.2427
en_zh Dev loss: 0.7508 r:0.4476
ro_en Dev loss: 0.3387 r:0.8149
et_en Dev loss: 0.5134 r:0.6444
si_en Dev loss: 0.7635 r:0.5719
ne_en Dev loss: 0.4173 r:0.7458
ru_en Dev loss: 0.4222 r:0.7388
Current avg r:0.6009 Best avg r: 0.6293
23:30:37,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:09,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:41,408 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2834
en_de Dev loss: 0.8501 r:0.2330
en_zh Dev loss: 0.7885 r:0.4308
ro_en Dev loss: 0.3608 r:0.8149
et_en Dev loss: 0.5154 r:0.6436
si_en Dev loss: 0.8207 r:0.5691
ne_en Dev loss: 0.4899 r:0.7404
ru_en Dev loss: 0.4360 r:0.7350
Current avg r:0.5953 Best avg r: 0.6293
23:38:16,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:48,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:20,706 root INFO Epoch 4 Global steps: 49000 Train loss: 0.3116
en_de Dev loss: 0.8552 r:0.2232
en_zh Dev loss: 0.8012 r:0.4341
ro_en Dev loss: 0.3267 r:0.8194
et_en Dev loss: 0.4764 r:0.6530
si_en Dev loss: 0.7376 r:0.5866
ne_en Dev loss: 0.4483 r:0.7413
ru_en Dev loss: 0.4616 r:0.7143
Current avg r:0.5960 Best avg r: 0.6293
23:45:55,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:27,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:00,48 root INFO Epoch 4 Global steps: 49700 Train loss: 0.3131
en_de Dev loss: 0.8740 r:0.2276
en_zh Dev loss: 0.7780 r:0.4550
ro_en Dev loss: 0.3406 r:0.8232
et_en Dev loss: 0.5081 r:0.6621
si_en Dev loss: 0.7414 r:0.5889
ne_en Dev loss: 0.4154 r:0.7502
ru_en Dev loss: 0.4478 r:0.7319
Current avg r:0.6055 Best avg r: 0.6293
23:53:35,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:07,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:39,358 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2996
en_de Dev loss: 0.8803 r:0.2194
en_zh Dev loss: 0.7860 r:0.4497
ro_en Dev loss: 0.3751 r:0.8120
et_en Dev loss: 0.4939 r:0.6353
si_en Dev loss: 0.8037 r:0.5702
ne_en Dev loss: 0.5201 r:0.7480
ru_en Dev loss: 0.4994 r:0.7062
Current avg r:0.5915 Best avg r: 0.6293
00:01:14,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:46,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:18,694 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2947
en_de Dev loss: 0.8810 r:0.2449
en_zh Dev loss: 0.8138 r:0.4391
ro_en Dev loss: 0.4078 r:0.8098
et_en Dev loss: 0.5372 r:0.6181
si_en Dev loss: 0.8845 r:0.5640
ne_en Dev loss: 0.5547 r:0.7456
ru_en Dev loss: 0.5288 r:0.7084
Current avg r:0.5900 Best avg r: 0.6293
00:08:53,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:25,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:57,867 root INFO Epoch 4 Global steps: 51800 Train loss: 0.3091
en_de Dev loss: 0.8474 r:0.2314
en_zh Dev loss: 0.7486 r:0.4619
ro_en Dev loss: 0.3522 r:0.8204
et_en Dev loss: 0.4997 r:0.6553
si_en Dev loss: 0.7941 r:0.5841
ne_en Dev loss: 0.4655 r:0.7410
ru_en Dev loss: 0.4749 r:0.7246
Current avg r:0.6027 Best avg r: 0.6293
00:16:32,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:05,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:37,105 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2873
en_de Dev loss: 0.8637 r:0.2223
en_zh Dev loss: 0.7694 r:0.4437
ro_en Dev loss: 0.3526 r:0.8163
et_en Dev loss: 0.4973 r:0.6409
si_en Dev loss: 0.7759 r:0.5769
ne_en Dev loss: 0.4724 r:0.7485
ru_en Dev loss: 0.4769 r:0.7224
Current avg r:0.5958 Best avg r: 0.6293
00:24:13,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:25:45,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:17,489 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2658
en_de Dev loss: 0.8556 r:0.2065
en_zh Dev loss: 0.7533 r:0.4536
ro_en Dev loss: 0.3598 r:0.8124
et_en Dev loss: 0.4935 r:0.6505
si_en Dev loss: 0.8137 r:0.5706
ne_en Dev loss: 0.4825 r:0.7469
ru_en Dev loss: 0.4563 r:0.7223
Current avg r:0.5947 Best avg r: 0.6293
00:31:52,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:33:24,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:56,605 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2719
en_de Dev loss: 0.8665 r:0.2306
en_zh Dev loss: 0.8192 r:0.4403
ro_en Dev loss: 0.3973 r:0.8088
et_en Dev loss: 0.5109 r:0.6374
si_en Dev loss: 0.8384 r:0.5760
ne_en Dev loss: 0.5310 r:0.7489
ru_en Dev loss: 0.5170 r:0.7113
Current avg r:0.5933 Best avg r: 0.6293
00:39:31,558 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:03,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:35,696 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2621
en_de Dev loss: 0.8484 r:0.2172
en_zh Dev loss: 0.7547 r:0.4516
ro_en Dev loss: 0.3318 r:0.8166
et_en Dev loss: 0.4858 r:0.6650
si_en Dev loss: 0.6907 r:0.5956
ne_en Dev loss: 0.4146 r:0.7545
ru_en Dev loss: 0.4053 r:0.7426
Current avg r:0.6062 Best avg r: 0.6293
00:47:10,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:42,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:14,765 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2642
en_de Dev loss: 0.9040 r:0.2113
en_zh Dev loss: 0.8290 r:0.4572
ro_en Dev loss: 0.3969 r:0.8154
et_en Dev loss: 0.5480 r:0.6510
si_en Dev loss: 0.8848 r:0.5755
ne_en Dev loss: 0.4932 r:0.7437
ru_en Dev loss: 0.4943 r:0.7267
Current avg r:0.5973 Best avg r: 0.6293
00:54:49,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:21,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:53,557 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2665
en_de Dev loss: 0.8550 r:0.2151
en_zh Dev loss: 0.7713 r:0.4416
ro_en Dev loss: 0.3623 r:0.8134
et_en Dev loss: 0.4768 r:0.6379
si_en Dev loss: 0.8822 r:0.5704
ne_en Dev loss: 0.5025 r:0.7495
ru_en Dev loss: 0.4754 r:0.7187
Current avg r:0.5924 Best avg r: 0.6293
01:02:28,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:00,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:32,209 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2645
en_de Dev loss: 0.8708 r:0.2047
en_zh Dev loss: 0.8121 r:0.4302
ro_en Dev loss: 0.3709 r:0.8078
et_en Dev loss: 0.5199 r:0.6320
si_en Dev loss: 0.8267 r:0.5680
ne_en Dev loss: 0.5164 r:0.7420
ru_en Dev loss: 0.4873 r:0.7084
Current avg r:0.5847 Best avg r: 0.6293
01:10:06,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:38,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:13:10,944 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2548
en_de Dev loss: 0.8438 r:0.2386
en_zh Dev loss: 0.7660 r:0.4579
ro_en Dev loss: 0.3833 r:0.8100
et_en Dev loss: 0.4951 r:0.6434
si_en Dev loss: 0.9909 r:0.5634
ne_en Dev loss: 0.5896 r:0.7475
ru_en Dev loss: 0.5170 r:0.7177
Current avg r:0.5969 Best avg r: 0.6293
01:17:45,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:17,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:20:49,674 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2682
en_de Dev loss: 0.8673 r:0.2299
en_zh Dev loss: 0.8014 r:0.4548
ro_en Dev loss: 0.3693 r:0.8169
et_en Dev loss: 0.4822 r:0.6535
si_en Dev loss: 0.8914 r:0.5799
ne_en Dev loss: 0.5678 r:0.7484
ru_en Dev loss: 0.4525 r:0.7451
Current avg r:0.6041 Best avg r: 0.6293
01:25:24,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:26:56,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:28,448 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2561
en_de Dev loss: 0.8698 r:0.2334
en_zh Dev loss: 0.8164 r:0.4490
ro_en Dev loss: 0.4146 r:0.8109
et_en Dev loss: 0.5056 r:0.6422
si_en Dev loss: 1.0159 r:0.5677
ne_en Dev loss: 0.6262 r:0.7372
ru_en Dev loss: 0.5219 r:0.7191
Current avg r:0.5942 Best avg r: 0.6293
01:33:03,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:34:35,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:07,175 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2542
en_de Dev loss: 0.8629 r:0.2202
en_zh Dev loss: 0.7577 r:0.4584
ro_en Dev loss: 0.3762 r:0.8109
et_en Dev loss: 0.4785 r:0.6462
si_en Dev loss: 0.9476 r:0.5747
ne_en Dev loss: 0.5587 r:0.7396
ru_en Dev loss: 0.4694 r:0.7259
Current avg r:0.5965 Best avg r: 0.6293
01:40:41,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:13,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:45,992 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2565
en_de Dev loss: 0.8613 r:0.2273
en_zh Dev loss: 0.7547 r:0.4608
ro_en Dev loss: 0.3550 r:0.8158
et_en Dev loss: 0.4884 r:0.6546
si_en Dev loss: 0.8754 r:0.5691
ne_en Dev loss: 0.4963 r:0.7409
ru_en Dev loss: 0.4451 r:0.7313
Current avg r:0.6000 Best avg r: 0.6293
01:48:21,28 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:49:53,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:25,78 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2753
en_de Dev loss: 0.8522 r:0.2220
en_zh Dev loss: 0.7656 r:0.4556
ro_en Dev loss: 0.3424 r:0.8143
et_en Dev loss: 0.4793 r:0.6406
si_en Dev loss: 0.9561 r:0.5645
ne_en Dev loss: 0.5716 r:0.7307
ru_en Dev loss: 0.4693 r:0.7212
Current avg r:0.5927 Best avg r: 0.6293
01:56:01,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:34,370 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:07,481 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2611
en_de Dev loss: 0.8489 r:0.2373
en_zh Dev loss: 0.7412 r:0.4603
ro_en Dev loss: 0.3299 r:0.8202
et_en Dev loss: 0.4585 r:0.6596
si_en Dev loss: 0.7563 r:0.5771
ne_en Dev loss: 0.4868 r:0.7424
ru_en Dev loss: 0.4259 r:0.7397
Current avg r:0.6052 Best avg r: 0.6293
02:03:45,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:18,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:06:51,512 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2649
en_de Dev loss: 0.8660 r:0.2359
en_zh Dev loss: 0.7753 r:0.4514
ro_en Dev loss: 0.3532 r:0.8176
et_en Dev loss: 0.5302 r:0.6465
si_en Dev loss: 0.8328 r:0.5621
ne_en Dev loss: 0.5844 r:0.7461
ru_en Dev loss: 0.4433 r:0.7343
Current avg r:0.5991 Best avg r: 0.6293
02:11:29,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:02,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:35,730 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2435
en_de Dev loss: 0.8585 r:0.2186
en_zh Dev loss: 0.8024 r:0.4534
ro_en Dev loss: 0.3662 r:0.8170
et_en Dev loss: 0.5073 r:0.6510
si_en Dev loss: 0.8038 r:0.5724
ne_en Dev loss: 0.4623 r:0.7429
ru_en Dev loss: 0.4788 r:0.7259
Current avg r:0.5973 Best avg r: 0.6293
02:19:15,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:48,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:21,555 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2177
en_de Dev loss: 0.8678 r:0.2273
en_zh Dev loss: 0.8184 r:0.4534
ro_en Dev loss: 0.3590 r:0.8150
et_en Dev loss: 0.5177 r:0.6586
si_en Dev loss: 0.7780 r:0.5742
ne_en Dev loss: 0.4914 r:0.7425
ru_en Dev loss: 0.4505 r:0.7378
Current avg r:0.6013 Best avg r: 0.6293
02:26:58,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:28:30,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:30:02,628 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2307
en_de Dev loss: 0.8690 r:0.2361
en_zh Dev loss: 0.7927 r:0.4492
ro_en Dev loss: 0.3468 r:0.8189
et_en Dev loss: 0.4850 r:0.6501
si_en Dev loss: 0.8086 r:0.5605
ne_en Dev loss: 0.4676 r:0.7335
ru_en Dev loss: 0.4315 r:0.7416
Current avg r:0.5986 Best avg r: 0.6293
02:34:38,196 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:10,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:37:42,457 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2251
en_de Dev loss: 0.8602 r:0.2427
en_zh Dev loss: 0.8661 r:0.4407
ro_en Dev loss: 0.3968 r:0.8104
et_en Dev loss: 0.5122 r:0.6381
si_en Dev loss: 1.0784 r:0.5494
ne_en Dev loss: 0.6907 r:0.7199
ru_en Dev loss: 0.5574 r:0.6991
Current avg r:0.5858 Best avg r: 0.6293
02:42:17,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:49,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:22,80 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2284
en_de Dev loss: 0.8664 r:0.2284
en_zh Dev loss: 0.7937 r:0.4509
ro_en Dev loss: 0.3536 r:0.8170
et_en Dev loss: 0.4805 r:0.6526
si_en Dev loss: 0.8246 r:0.5620
ne_en Dev loss: 0.5520 r:0.7438
ru_en Dev loss: 0.5037 r:0.7151
Current avg r:0.5957 Best avg r: 0.6293
02:49:57,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:30,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:02,187 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2305
en_de Dev loss: 0.8766 r:0.2182
en_zh Dev loss: 0.8528 r:0.4521
ro_en Dev loss: 0.4222 r:0.8102
et_en Dev loss: 0.4958 r:0.6553
si_en Dev loss: 0.9710 r:0.5552
ne_en Dev loss: 0.6019 r:0.7394
ru_en Dev loss: 0.5597 r:0.7110
Current avg r:0.5916 Best avg r: 0.6293
02:57:38,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:59:10,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:42,365 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2240
en_de Dev loss: 0.8859 r:0.2121
en_zh Dev loss: 0.9131 r:0.4381
ro_en Dev loss: 0.4222 r:0.8104
et_en Dev loss: 0.4949 r:0.6502
si_en Dev loss: 1.0244 r:0.5429
ne_en Dev loss: 0.5616 r:0.7388
ru_en Dev loss: 0.5439 r:0.7188
Current avg r:0.5873 Best avg r: 0.6293
03:05:18,246 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:06:50,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:22,678 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2255
en_de Dev loss: 0.9148 r:0.2035
en_zh Dev loss: 0.8480 r:0.4476
ro_en Dev loss: 0.3781 r:0.8164
et_en Dev loss: 0.5020 r:0.6530
si_en Dev loss: 0.8566 r:0.5551
ne_en Dev loss: 0.5582 r:0.7400
ru_en Dev loss: 0.5332 r:0.7237
Current avg r:0.5913 Best avg r: 0.6293
03:12:58,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:30,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:02,940 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2208
en_de Dev loss: 0.8782 r:0.2159
en_zh Dev loss: 0.8319 r:0.4420
ro_en Dev loss: 0.3825 r:0.8115
et_en Dev loss: 0.5245 r:0.6461
si_en Dev loss: 0.8845 r:0.5482
ne_en Dev loss: 0.5566 r:0.7390
ru_en Dev loss: 0.4761 r:0.7234
Current avg r:0.5895 Best avg r: 0.6293
03:20:38,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:22:11,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:43,236 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2222
en_de Dev loss: 0.8857 r:0.1980
en_zh Dev loss: 0.7968 r:0.4562
ro_en Dev loss: 0.3558 r:0.8170
et_en Dev loss: 0.5024 r:0.6635
si_en Dev loss: 0.8184 r:0.5625
ne_en Dev loss: 0.4819 r:0.7469
ru_en Dev loss: 0.4259 r:0.7492
Current avg r:0.5990 Best avg r: 0.6293
03:28:19,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:58,666 root INFO 
id:ro_en cur r: 0.8226 best r: 0.8226
03:29:51,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:23,506 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2205
en_de Dev loss: 0.8868 r:0.1878
en_zh Dev loss: 0.7965 r:0.4497
ro_en Dev loss: 0.3410 r:0.8215
et_en Dev loss: 0.4993 r:0.6567
si_en Dev loss: 0.8129 r:0.5664
ne_en Dev loss: 0.4155 r:0.7416
ru_en Dev loss: 0.4660 r:0.7269
Current avg r:0.5929 Best avg r: 0.6293
03:35:59,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:31,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:39:03,343 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2211
en_de Dev loss: 0.8818 r:0.1793
en_zh Dev loss: 0.8132 r:0.4421
ro_en Dev loss: 0.3800 r:0.8156
et_en Dev loss: 0.4585 r:0.6559
si_en Dev loss: 0.9282 r:0.5562
ne_en Dev loss: 0.5463 r:0.7458
ru_en Dev loss: 0.4621 r:0.7372
Current avg r:0.5903 Best avg r: 0.6293
03:43:38,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:45:10,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:46:43,10 root INFO Epoch 6 Global steps: 71400 Train loss: 0.2227
en_de Dev loss: 0.8865 r:0.1917
en_zh Dev loss: 0.7871 r:0.4453
ro_en Dev loss: 0.3542 r:0.8196
et_en Dev loss: 0.4690 r:0.6627
si_en Dev loss: 0.8051 r:0.5566
ne_en Dev loss: 0.4297 r:0.7450
ru_en Dev loss: 0.4310 r:0.7439
Current avg r:0.5950 Best avg r: 0.6293
03:51:18,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:52:50,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:54:23,120 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2237
en_de Dev loss: 0.8918 r:0.1857
en_zh Dev loss: 0.8390 r:0.4266
ro_en Dev loss: 0.3920 r:0.8098
et_en Dev loss: 0.5057 r:0.6333
si_en Dev loss: 0.9581 r:0.5433
ne_en Dev loss: 0.6807 r:0.7366
ru_en Dev loss: 0.4901 r:0.7178
Current avg r:0.5790 Best avg r: 0.6293
03:58:58,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:00:30,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:02:02,769 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2161
en_de Dev loss: 0.8900 r:0.1920
en_zh Dev loss: 0.7981 r:0.4499
ro_en Dev loss: 0.3445 r:0.8159
et_en Dev loss: 0.5121 r:0.6628
si_en Dev loss: 0.8231 r:0.5618
ne_en Dev loss: 0.4541 r:0.7375
ru_en Dev loss: 0.4310 r:0.7353
Current avg r:0.5936 Best avg r: 0.6293
04:06:38,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:08:10,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:09:42,542 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2248
en_de Dev loss: 0.8803 r:0.1863
en_zh Dev loss: 0.7839 r:0.4383
ro_en Dev loss: 0.3565 r:0.8119
et_en Dev loss: 0.4867 r:0.6629
si_en Dev loss: 0.8032 r:0.5640
ne_en Dev loss: 0.4573 r:0.7338
ru_en Dev loss: 0.4405 r:0.7263
Current avg r:0.5891 Best avg r: 0.6293
04:14:20,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:15:52,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:17:24,300 root INFO Epoch 7 Global steps: 74200 Train loss: 0.2029
en_de Dev loss: 0.9075 r:0.1749
en_zh Dev loss: 0.8007 r:0.4451
ro_en Dev loss: 0.3847 r:0.8080
et_en Dev loss: 0.5030 r:0.6385
si_en Dev loss: 0.9981 r:0.5431
ne_en Dev loss: 0.6424 r:0.7318
ru_en Dev loss: 0.4810 r:0.7231
Current avg r:0.5806 Best avg r: 0.6293
04:22:00,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:23:32,490 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:25:04,703 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1972
en_de Dev loss: 0.9198 r:0.1714
en_zh Dev loss: 0.8482 r:0.4340
ro_en Dev loss: 0.3757 r:0.8101
et_en Dev loss: 0.5258 r:0.6516
si_en Dev loss: 0.8607 r:0.5546
ne_en Dev loss: 0.5048 r:0.7367
ru_en Dev loss: 0.4683 r:0.7256
Current avg r:0.5834 Best avg r: 0.6293
04:29:40,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:31:12,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:32:45,904 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1917
en_de Dev loss: 0.9138 r:0.1789
en_zh Dev loss: 0.8386 r:0.4459
ro_en Dev loss: 0.3665 r:0.8154
et_en Dev loss: 0.4890 r:0.6550
si_en Dev loss: 0.9370 r:0.5540
ne_en Dev loss: 0.4849 r:0.7370
ru_en Dev loss: 0.4841 r:0.7279
Current avg r:0.5877 Best avg r: 0.6293
04:37:23,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:38:56,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:40:29,502 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1979
en_de Dev loss: 0.8994 r:0.1770
en_zh Dev loss: 0.8416 r:0.4495
ro_en Dev loss: 0.4050 r:0.8098
et_en Dev loss: 0.5066 r:0.6500
si_en Dev loss: 0.9651 r:0.5594
ne_en Dev loss: 0.5430 r:0.7302
ru_en Dev loss: 0.5091 r:0.7106
Current avg r:0.5838 Best avg r: 0.6293
04:45:07,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:46:40,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:13,516 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1994
en_de Dev loss: 0.9059 r:0.1657
en_zh Dev loss: 0.8783 r:0.4238
ro_en Dev loss: 0.4004 r:0.8069
et_en Dev loss: 0.5069 r:0.6488
si_en Dev loss: 0.9726 r:0.5532
ne_en Dev loss: 0.6116 r:0.7289
ru_en Dev loss: 0.5660 r:0.6901
Current avg r:0.5739 Best avg r: 0.6293
04:52:51,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:54:24,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:55:56,851 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1973
en_de Dev loss: 0.9087 r:0.1740
en_zh Dev loss: 0.8372 r:0.4530
ro_en Dev loss: 0.3541 r:0.8169
et_en Dev loss: 0.5141 r:0.6565
si_en Dev loss: 0.9050 r:0.5569
ne_en Dev loss: 0.5002 r:0.7375
ru_en Dev loss: 0.4542 r:0.7398
Current avg r:0.5907 Best avg r: 0.6293
05:00:32,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:02:04,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:36,722 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1944
en_de Dev loss: 0.9033 r:0.1714
en_zh Dev loss: 0.8022 r:0.4412
ro_en Dev loss: 0.3722 r:0.8104
et_en Dev loss: 0.4927 r:0.6439
si_en Dev loss: 0.9262 r:0.5519
ne_en Dev loss: 0.5763 r:0.7316
ru_en Dev loss: 0.4498 r:0.7351
Current avg r:0.5836 Best avg r: 0.6293
05:08:12,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:09:44,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:16,755 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1970
en_de Dev loss: 0.9358 r:0.1734
en_zh Dev loss: 0.8723 r:0.4425
ro_en Dev loss: 0.4147 r:0.8087
et_en Dev loss: 0.5281 r:0.6490
si_en Dev loss: 1.0499 r:0.5420
ne_en Dev loss: 0.6368 r:0.7267
ru_en Dev loss: 0.5046 r:0.7293
Current avg r:0.5817 Best avg r: 0.6293
05:15:52,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:24,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:57,76 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1842
en_de Dev loss: 0.9175 r:0.1601
en_zh Dev loss: 0.8542 r:0.4340
ro_en Dev loss: 0.3955 r:0.8101
et_en Dev loss: 0.5267 r:0.6518
si_en Dev loss: 0.9218 r:0.5466
ne_en Dev loss: 0.5736 r:0.7230
ru_en Dev loss: 0.4992 r:0.7166
Current avg r:0.5775 Best avg r: 0.6293
05:23:32,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:25:05,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:37,509 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1950
en_de Dev loss: 0.9506 r:0.1440
en_zh Dev loss: 0.8970 r:0.4400
ro_en Dev loss: 0.4228 r:0.8087
et_en Dev loss: 0.5264 r:0.6436
si_en Dev loss: 1.0007 r:0.5482
ne_en Dev loss: 0.6256 r:0.7279
ru_en Dev loss: 0.5769 r:0.6980
Current avg r:0.5729 Best avg r: 0.6293
05:31:13,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:32:45,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:34:17,901 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1925
en_de Dev loss: 0.9107 r:0.1551
en_zh Dev loss: 0.7891 r:0.4397
ro_en Dev loss: 0.3516 r:0.8130
et_en Dev loss: 0.4867 r:0.6548
si_en Dev loss: 0.8173 r:0.5518
ne_en Dev loss: 0.4812 r:0.7304
ru_en Dev loss: 0.4884 r:0.7114
Current avg r:0.5795 Best avg r: 0.6293
05:38:53,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:40:25,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:41:57,886 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1911
en_de Dev loss: 0.9470 r:0.1533
en_zh Dev loss: 0.7852 r:0.4617
ro_en Dev loss: 0.3696 r:0.8130
et_en Dev loss: 0.4763 r:0.6534
si_en Dev loss: 0.8385 r:0.5518
ne_en Dev loss: 0.5236 r:0.7287
ru_en Dev loss: 0.4913 r:0.7237
Current avg r:0.5836 Best avg r: 0.6293
05:46:33,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:48:05,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:49:37,858 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1993
en_de Dev loss: 0.9385 r:0.1418
en_zh Dev loss: 0.8045 r:0.4574
ro_en Dev loss: 0.3661 r:0.8165
et_en Dev loss: 0.4834 r:0.6637
si_en Dev loss: 0.8519 r:0.5569
ne_en Dev loss: 0.4409 r:0.7361
ru_en Dev loss: 0.4546 r:0.7358
Current avg r:0.5869 Best avg r: 0.6293
05:54:13,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:55:45,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:57:18,214 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1795
en_de Dev loss: 0.9259 r:0.1587
en_zh Dev loss: 0.8245 r:0.4496
ro_en Dev loss: 0.3795 r:0.8137
et_en Dev loss: 0.5133 r:0.6530
si_en Dev loss: 0.9067 r:0.5469
ne_en Dev loss: 0.5295 r:0.7298
ru_en Dev loss: 0.4691 r:0.7285
Current avg r:0.5829 Best avg r: 0.6293
06:01:53,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:26,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:58,212 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1878
en_de Dev loss: 0.9266 r:0.1488
en_zh Dev loss: 0.8093 r:0.4633
ro_en Dev loss: 0.3627 r:0.8175
et_en Dev loss: 0.5095 r:0.6627
si_en Dev loss: 0.8831 r:0.5522
ne_en Dev loss: 0.5082 r:0.7305
ru_en Dev loss: 0.4668 r:0.7354
Current avg r:0.5872 Best avg r: 0.6293
06:09:35,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:07,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:12:39,744 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1666
en_de Dev loss: 0.9374 r:0.1547
en_zh Dev loss: 0.8373 r:0.4506
ro_en Dev loss: 0.4014 r:0.8109
et_en Dev loss: 0.5185 r:0.6527
si_en Dev loss: 1.0111 r:0.5428
ne_en Dev loss: 0.5848 r:0.7295
ru_en Dev loss: 0.5028 r:0.7318
Current avg r:0.5818 Best avg r: 0.6293
06:17:15,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:18:47,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:20:19,705 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1754
en_de Dev loss: 0.9335 r:0.1395
en_zh Dev loss: 0.7868 r:0.4622
ro_en Dev loss: 0.3527 r:0.8184
et_en Dev loss: 0.4678 r:0.6720
si_en Dev loss: 0.8264 r:0.5558
ne_en Dev loss: 0.5020 r:0.7297
ru_en Dev loss: 0.4205 r:0.7496
Current avg r:0.5896 Best avg r: 0.6293
06:24:55,245 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:26:27,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:27:59,589 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1825
en_de Dev loss: 0.9191 r:0.1644
en_zh Dev loss: 0.8660 r:0.4405
ro_en Dev loss: 0.3993 r:0.8123
et_en Dev loss: 0.5022 r:0.6537
si_en Dev loss: 1.0307 r:0.5404
ne_en Dev loss: 0.6570 r:0.7283
ru_en Dev loss: 0.5454 r:0.7033
Current avg r:0.5776 Best avg r: 0.6293
06:32:35,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:34:07,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:35:39,333 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1673
en_de Dev loss: 0.9312 r:0.1719
en_zh Dev loss: 0.7985 r:0.4651
ro_en Dev loss: 0.3680 r:0.8169
et_en Dev loss: 0.4829 r:0.6654
si_en Dev loss: 0.9116 r:0.5510
ne_en Dev loss: 0.5103 r:0.7308
ru_en Dev loss: 0.4571 r:0.7313
Current avg r:0.5903 Best avg r: 0.6293
06:40:14,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:47,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:43:19,239 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1716
en_de Dev loss: 0.9333 r:0.1567
en_zh Dev loss: 0.8101 r:0.4529
ro_en Dev loss: 0.3815 r:0.8135
et_en Dev loss: 0.4949 r:0.6532
si_en Dev loss: 0.9343 r:0.5407
ne_en Dev loss: 0.4965 r:0.7346
ru_en Dev loss: 0.4691 r:0.7223
Current avg r:0.5820 Best avg r: 0.6293
06:47:54,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:49:26,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:50:59,74 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1722
en_de Dev loss: 0.8998 r:0.1830
en_zh Dev loss: 0.7748 r:0.4641
ro_en Dev loss: 0.3437 r:0.8163
et_en Dev loss: 0.4750 r:0.6446
si_en Dev loss: 0.9302 r:0.5419
ne_en Dev loss: 0.5659 r:0.7265
ru_en Dev loss: 0.4613 r:0.7190
Current avg r:0.5851 Best avg r: 0.6293
06:55:34,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:57:06,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:58:38,932 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1663
en_de Dev loss: 0.9206 r:0.1690
en_zh Dev loss: 0.7938 r:0.4678
ro_en Dev loss: 0.3404 r:0.8200
et_en Dev loss: 0.4737 r:0.6550
si_en Dev loss: 0.8722 r:0.5420
ne_en Dev loss: 0.5480 r:0.7259
ru_en Dev loss: 0.4401 r:0.7375
Current avg r:0.5882 Best avg r: 0.6293
07:03:14,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:04:46,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:06:18,754 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1680
en_de Dev loss: 0.9380 r:0.1594
en_zh Dev loss: 0.8361 r:0.4537
ro_en Dev loss: 0.3572 r:0.8175
et_en Dev loss: 0.5197 r:0.6517
si_en Dev loss: 0.9195 r:0.5423
ne_en Dev loss: 0.5348 r:0.7335
ru_en Dev loss: 0.4735 r:0.7310
Current avg r:0.5841 Best avg r: 0.6293
07:10:54,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:12:26,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:13:58,545 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1657
en_de Dev loss: 0.9431 r:0.1610
en_zh Dev loss: 0.8368 r:0.4580
ro_en Dev loss: 0.3969 r:0.8133
et_en Dev loss: 0.5194 r:0.6531
si_en Dev loss: 0.9101 r:0.5499
ne_en Dev loss: 0.5578 r:0.7341
ru_en Dev loss: 0.5072 r:0.7260
Current avg r:0.5851 Best avg r: 0.6293
07:18:33,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:20:06,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:21:38,255 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1657
en_de Dev loss: 0.9348 r:0.1584
en_zh Dev loss: 0.8265 r:0.4633
ro_en Dev loss: 0.3984 r:0.8104
et_en Dev loss: 0.5106 r:0.6472
si_en Dev loss: 0.9937 r:0.5415
ne_en Dev loss: 0.6339 r:0.7347
ru_en Dev loss: 0.4939 r:0.7319
Current avg r:0.5839 Best avg r: 0.6293
07:26:13,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:27:45,800 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:29:17,936 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1677
en_de Dev loss: 0.9275 r:0.1633
en_zh Dev loss: 0.8198 r:0.4632
ro_en Dev loss: 0.3835 r:0.8115
et_en Dev loss: 0.5233 r:0.6536
si_en Dev loss: 0.8872 r:0.5453
ne_en Dev loss: 0.5649 r:0.7293
ru_en Dev loss: 0.4916 r:0.7229
Current avg r:0.5842 Best avg r: 0.6293
07:33:54,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:35:27,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:00,1 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1618
en_de Dev loss: 0.9346 r:0.1682
en_zh Dev loss: 0.8489 r:0.4619
ro_en Dev loss: 0.4208 r:0.8061
et_en Dev loss: 0.5308 r:0.6512
si_en Dev loss: 0.9248 r:0.5441
ne_en Dev loss: 0.5874 r:0.7296
ru_en Dev loss: 0.5256 r:0.7212
Current avg r:0.5832 Best avg r: 0.6293
07:41:38,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:43:11,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:44:44,127 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1645
en_de Dev loss: 0.9109 r:0.1719
en_zh Dev loss: 0.8028 r:0.4716
ro_en Dev loss: 0.3650 r:0.8139
et_en Dev loss: 0.4800 r:0.6506
si_en Dev loss: 0.9575 r:0.5386
ne_en Dev loss: 0.5579 r:0.7320
ru_en Dev loss: 0.4599 r:0.7380
Current avg r:0.5881 Best avg r: 0.6293
07:49:22,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:50:55,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:28,35 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1668
en_de Dev loss: 0.9616 r:0.1705
en_zh Dev loss: 0.8886 r:0.4496
ro_en Dev loss: 0.3991 r:0.8103
et_en Dev loss: 0.5132 r:0.6432
si_en Dev loss: 0.9938 r:0.5273
ne_en Dev loss: 0.6247 r:0.7250
ru_en Dev loss: 0.5161 r:0.7323
Current avg r:0.5798 Best avg r: 0.6293
07:57:05,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:58:37,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:00:10,173 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1615
en_de Dev loss: 0.9326 r:0.1459
en_zh Dev loss: 0.8043 r:0.4557
ro_en Dev loss: 0.3651 r:0.8132
et_en Dev loss: 0.4640 r:0.6635
si_en Dev loss: 0.8063 r:0.5473
ne_en Dev loss: 0.5515 r:0.7262
ru_en Dev loss: 0.4410 r:0.7410
Current avg r:0.5847 Best avg r: 0.6293
08:04:47,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:06:19,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:07:51,591 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1471
en_de Dev loss: 0.9240 r:0.1567
en_zh Dev loss: 0.7883 r:0.4664
ro_en Dev loss: 0.3811 r:0.8140
et_en Dev loss: 0.4743 r:0.6546
si_en Dev loss: 0.8957 r:0.5417
ne_en Dev loss: 0.6180 r:0.7275
ru_en Dev loss: 0.4817 r:0.7356
Current avg r:0.5852 Best avg r: 0.6293
08:12:26,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:13:59,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:15:31,270 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1450
en_de Dev loss: 0.9259 r:0.1477
en_zh Dev loss: 0.7937 r:0.4619
ro_en Dev loss: 0.3368 r:0.8201
et_en Dev loss: 0.4963 r:0.6614
si_en Dev loss: 0.8154 r:0.5526
ne_en Dev loss: 0.5015 r:0.7296
ru_en Dev loss: 0.4551 r:0.7291
Current avg r:0.5861 Best avg r: 0.6293
08:20:06,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:39,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:11,228 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1557
en_de Dev loss: 0.9370 r:0.1598
en_zh Dev loss: 0.8407 r:0.4667
ro_en Dev loss: 0.4075 r:0.8132
et_en Dev loss: 0.5094 r:0.6518
si_en Dev loss: 0.9362 r:0.5469
ne_en Dev loss: 0.7073 r:0.7261
ru_en Dev loss: 0.4977 r:0.7285
Current avg r:0.5847 Best avg r: 0.6293
08:27:46,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:29:18,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:51,108 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1506
en_de Dev loss: 0.9249 r:0.1419
en_zh Dev loss: 0.8129 r:0.4697
ro_en Dev loss: 0.3623 r:0.8183
et_en Dev loss: 0.4907 r:0.6507
si_en Dev loss: 0.8946 r:0.5466
ne_en Dev loss: 0.5807 r:0.7279
ru_en Dev loss: 0.4409 r:0.7427
Current avg r:0.5854 Best avg r: 0.6293
08:35:26,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:58,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:38:30,945 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1484
en_de Dev loss: 0.9184 r:0.1728
en_zh Dev loss: 0.8092 r:0.4741
ro_en Dev loss: 0.3521 r:0.8183
et_en Dev loss: 0.5008 r:0.6716
si_en Dev loss: 0.7814 r:0.5625
ne_en Dev loss: 0.4584 r:0.7302
ru_en Dev loss: 0.4446 r:0.7388
Current avg r:0.5955 Best avg r: 0.6293
08:43:06,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:44:38,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:46:10,798 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1506
en_de Dev loss: 0.9657 r:0.1575
en_zh Dev loss: 0.9004 r:0.4525
ro_en Dev loss: 0.4144 r:0.8130
et_en Dev loss: 0.5211 r:0.6579
si_en Dev loss: 0.9773 r:0.5421
ne_en Dev loss: 0.5840 r:0.7285
ru_en Dev loss: 0.5179 r:0.7343
Current avg r:0.5837 Best avg r: 0.6293
08:50:46,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:52:18,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:53:50,508 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1509
en_de Dev loss: 0.9435 r:0.1591
en_zh Dev loss: 0.8779 r:0.4467
ro_en Dev loss: 0.4027 r:0.8075
et_en Dev loss: 0.4977 r:0.6542
si_en Dev loss: 0.9656 r:0.5398
ne_en Dev loss: 0.5714 r:0.7294
ru_en Dev loss: 0.4997 r:0.7306
Current avg r:0.5810 Best avg r: 0.6293
08:58:25,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:59:58,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:01:30,253 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1517
en_de Dev loss: 0.9326 r:0.1718
en_zh Dev loss: 0.8429 r:0.4564
ro_en Dev loss: 0.4156 r:0.8111
et_en Dev loss: 0.5017 r:0.6555
si_en Dev loss: 1.0586 r:0.5290
ne_en Dev loss: 0.6790 r:0.7226
ru_en Dev loss: 0.5228 r:0.7222
Current avg r:0.5812 Best avg r: 0.6293
09:06:05,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:07:37,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:09,905 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1440
en_de Dev loss: 0.9238 r:0.1519
en_zh Dev loss: 0.8329 r:0.4468
ro_en Dev loss: 0.3587 r:0.8112
et_en Dev loss: 0.4777 r:0.6581
si_en Dev loss: 0.9195 r:0.5285
ne_en Dev loss: 0.6099 r:0.7244
ru_en Dev loss: 0.5212 r:0.7027
Current avg r:0.5748 Best avg r: 0.6293
09:13:45,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:17,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:49,545 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1436
en_de Dev loss: 0.9430 r:0.1594
en_zh Dev loss: 0.8138 r:0.4581
ro_en Dev loss: 0.3684 r:0.8140
et_en Dev loss: 0.4915 r:0.6624
si_en Dev loss: 0.9135 r:0.5373
ne_en Dev loss: 0.5515 r:0.7300
ru_en Dev loss: 0.4665 r:0.7326
Current avg r:0.5848 Best avg r: 0.6293
09:21:24,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:22:57,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:24:29,164 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1471
en_de Dev loss: 0.9264 r:0.1422
en_zh Dev loss: 0.7736 r:0.4701
ro_en Dev loss: 0.3656 r:0.8142
et_en Dev loss: 0.4708 r:0.6574
si_en Dev loss: 0.9187 r:0.5307
ne_en Dev loss: 0.5910 r:0.7229
ru_en Dev loss: 0.4654 r:0.7273
Current avg r:0.5807 Best avg r: 0.6293
09:29:04,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:36,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:32:08,794 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1447
en_de Dev loss: 0.9570 r:0.1457
en_zh Dev loss: 0.8604 r:0.4602
ro_en Dev loss: 0.4003 r:0.8133
et_en Dev loss: 0.5126 r:0.6482
si_en Dev loss: 0.9804 r:0.5316
ne_en Dev loss: 0.6550 r:0.7170
ru_en Dev loss: 0.5311 r:0.7193
Current avg r:0.5765 Best avg r: 0.6293
09:36:44,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:38:16,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:39:48,514 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1426
en_de Dev loss: 0.9343 r:0.1640
en_zh Dev loss: 0.7958 r:0.4595
ro_en Dev loss: 0.3413 r:0.8160
et_en Dev loss: 0.4834 r:0.6616
si_en Dev loss: 0.8652 r:0.5349
ne_en Dev loss: 0.5803 r:0.7232
ru_en Dev loss: 0.4337 r:0.7453
Current avg r:0.5864 Best avg r: 0.6293
09:44:23,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:45:55,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:47:28,178 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1448
en_de Dev loss: 0.9404 r:0.1570
en_zh Dev loss: 0.8177 r:0.4536
ro_en Dev loss: 0.3441 r:0.8202
et_en Dev loss: 0.4745 r:0.6672
si_en Dev loss: 0.8715 r:0.5407
ne_en Dev loss: 0.5602 r:0.7290
ru_en Dev loss: 0.4505 r:0.7431
Current avg r:0.5872 Best avg r: 0.6293
09:52:03,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:35,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:55:07,952 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1435
en_de Dev loss: 0.9445 r:0.1704
en_zh Dev loss: 0.8298 r:0.4607
ro_en Dev loss: 0.3761 r:0.8158
et_en Dev loss: 0.4773 r:0.6681
si_en Dev loss: 0.9127 r:0.5505
ne_en Dev loss: 0.5459 r:0.7265
ru_en Dev loss: 0.4625 r:0.7458
Current avg r:0.5911 Best avg r: 0.6293
09:59:44,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:01:16,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:48,992 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1321
en_de Dev loss: 0.9332 r:0.1674
en_zh Dev loss: 0.8319 r:0.4614
ro_en Dev loss: 0.3549 r:0.8159
et_en Dev loss: 0.4868 r:0.6666
si_en Dev loss: 0.9161 r:0.5389
ne_en Dev loss: 0.6079 r:0.7218
ru_en Dev loss: 0.4551 r:0.7327
Current avg r:0.5864 Best avg r: 0.6293
10:07:24,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:56,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:28,659 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1283
en_de Dev loss: 0.9384 r:0.1626
en_zh Dev loss: 0.8145 r:0.4604
ro_en Dev loss: 0.3639 r:0.8200
et_en Dev loss: 0.5034 r:0.6650
si_en Dev loss: 0.8886 r:0.5415
ne_en Dev loss: 0.5328 r:0.7159
ru_en Dev loss: 0.4592 r:0.7358
Current avg r:0.5859 Best avg r: 0.6293
10:15:04,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:36,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:18:08,360 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1365
en_de Dev loss: 0.9794 r:0.1576
en_zh Dev loss: 0.8406 r:0.4658
ro_en Dev loss: 0.3968 r:0.8149
et_en Dev loss: 0.5015 r:0.6642
si_en Dev loss: 0.9634 r:0.5385
ne_en Dev loss: 0.6243 r:0.7153
ru_en Dev loss: 0.4948 r:0.7341
Current avg r:0.5843 Best avg r: 0.6293
10:22:43,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:15,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:25:48,126 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1246
en_de Dev loss: 0.9912 r:0.1648
en_zh Dev loss: 0.8142 r:0.4674
ro_en Dev loss: 0.3471 r:0.8178
et_en Dev loss: 0.4715 r:0.6789
si_en Dev loss: 0.8458 r:0.5446
ne_en Dev loss: 0.5424 r:0.7227
ru_en Dev loss: 0.4412 r:0.7490
Current avg r:0.5922 Best avg r: 0.6293
10:30:23,707 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:31:56,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:33:29,558 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1266
en_de Dev loss: 0.9543 r:0.1629
en_zh Dev loss: 0.8052 r:0.4667
ro_en Dev loss: 0.3634 r:0.8150
et_en Dev loss: 0.4742 r:0.6598
si_en Dev loss: 0.9479 r:0.5348
ne_en Dev loss: 0.5968 r:0.7211
ru_en Dev loss: 0.4553 r:0.7434
Current avg r:0.5863 Best avg r: 0.6293
