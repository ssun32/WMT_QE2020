14:50:29,529 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:50:42,404 root INFO 
id:en_de cur r: 0.0923 best r: 0.0923
14:50:55,243 root INFO 
id:en_zh cur r: 0.2776 best r: 0.2776
14:51:08,119 root INFO 
id:ro_en cur r: 0.6173 best r: 0.6173
14:51:21,6 root INFO 
id:et_en cur r: 0.5267 best r: 0.5267
14:51:33,912 root INFO 
id:si_en cur r: 0.4581 best r: 0.4581
14:51:59,705 root INFO 
id:ne_en cur r: 0.5945 best r: 0.5945
14:52:12,560 root INFO 
id:ru_en cur r: 0.3614 best r: 0.3614
14:52:12,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:42,613 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
14:53:42,620 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:53:42,625 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:53:42,630 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
14:53:42,636 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
14:53:42,641 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:53:42,645 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:53:55,559 root INFO Epoch 0 Global steps: 700 Train loss: 0.8330
en_de Dev loss: 0.8931 r:0.0820
en_zh Dev loss: 0.7709 r:0.2633
ro_en Dev loss: 0.7047 r:0.6272
et_en Dev loss: 0.5259 r:0.5417
si_en Dev loss: 0.7213 r:0.4810
ne_en Dev loss: 0.5352 r:0.6228
ru_en Dev loss: 0.6733 r:0.4680
Current avg r:0.4409 Best avg r: 0.4409
14:58:25,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:38,112 root INFO 
id:en_de cur r: 0.1104 best r: 0.1104
14:58:50,960 root INFO 
id:en_zh cur r: 0.3078 best r: 0.3078
14:59:03,861 root INFO 
id:ro_en cur r: 0.6404 best r: 0.6404
14:59:16,743 root INFO 
id:et_en cur r: 0.5640 best r: 0.5640
14:59:55,449 root INFO 
id:ne_en cur r: 0.5980 best r: 0.5980
15:00:08,270 root INFO 
id:ru_en cur r: 0.5117 best r: 0.5117
15:00:08,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:01:38,343 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:01:38,352 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:01:38,357 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:01:38,362 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:01:38,367 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:01:38,376 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:01:38,381 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:01:51,278 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8016
en_de Dev loss: 0.9046 r:0.1113
en_zh Dev loss: 0.7562 r:0.3137
ro_en Dev loss: 0.7115 r:0.6561
et_en Dev loss: 0.5120 r:0.6068
si_en Dev loss: 0.7601 r:0.4702
ne_en Dev loss: 0.5518 r:0.6212
ru_en Dev loss: 0.6453 r:0.6202
Current avg r:0.4856 Best avg r: 0.4856
15:06:19,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:06:45,621 root INFO 
id:en_zh cur r: 0.3423 best r: 0.3423
15:06:58,454 root INFO 
id:ro_en cur r: 0.6784 best r: 0.6784
15:07:11,298 root INFO 
id:et_en cur r: 0.6441 best r: 0.6441
15:07:24,162 root INFO 
id:si_en cur r: 0.4842 best r: 0.4842
15:07:49,868 root INFO 
id:ne_en cur r: 0.6569 best r: 0.6569
15:08:02,655 root INFO 
id:ru_en cur r: 0.6207 best r: 0.6207
15:08:02,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:32,391 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:09:32,398 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:09:32,404 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:09:32,408 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:09:32,416 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:09:32,421 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:09:32,426 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:09:45,272 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7303
en_de Dev loss: 0.9164 r:0.1448
en_zh Dev loss: 0.7604 r:0.3344
ro_en Dev loss: 0.5922 r:0.6979
et_en Dev loss: 0.4354 r:0.6638
si_en Dev loss: 0.7228 r:0.5163
ne_en Dev loss: 0.4972 r:0.6640
ru_en Dev loss: 0.5849 r:0.6748
Current avg r:0.5280 Best avg r: 0.5280
15:14:15,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:27,856 root INFO 
id:en_de cur r: 0.1431 best r: 0.1431
15:15:06,357 root INFO 
id:et_en cur r: 0.6457 best r: 0.6457
15:15:44,881 root INFO 
id:ru_en cur r: 0.6273 best r: 0.6273
15:15:44,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:14,750 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6853
en_de Dev loss: 0.9260 r:0.1482
en_zh Dev loss: 0.7598 r:0.3145
ro_en Dev loss: 0.5824 r:0.6733
et_en Dev loss: 0.4280 r:0.6630
si_en Dev loss: 0.7494 r:0.5074
ne_en Dev loss: 0.5188 r:0.6278
ru_en Dev loss: 0.5707 r:0.6832
Current avg r:0.5168 Best avg r: 0.5280
15:21:45,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:23,702 root INFO 
id:ro_en cur r: 0.6991 best r: 0.6991
15:22:36,646 root INFO 
id:et_en cur r: 0.6650 best r: 0.6650
15:22:49,588 root INFO 
id:si_en cur r: 0.5133 best r: 0.5133
15:23:15,397 root INFO 
id:ru_en cur r: 0.6917 best r: 0.6917
15:23:15,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:45,562 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:24:45,569 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:24:45,573 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:24:45,578 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:24:45,582 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:24:45,587 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:24:45,591 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:24:58,502 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6297
en_de Dev loss: 0.9154 r:0.1548
en_zh Dev loss: 0.7641 r:0.3319
ro_en Dev loss: 0.4770 r:0.7195
et_en Dev loss: 0.3951 r:0.6832
si_en Dev loss: 0.7140 r:0.5298
ne_en Dev loss: 0.4708 r:0.6567
ru_en Dev loss: 0.5216 r:0.7067
Current avg r:0.5404 Best avg r: 0.5404
15:29:29,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:41,980 root INFO 
id:en_de cur r: 0.1469 best r: 0.1469
15:30:07,709 root INFO 
id:ro_en cur r: 0.7144 best r: 0.7144
15:30:20,624 root INFO 
id:et_en cur r: 0.6790 best r: 0.6790
15:30:33,547 root INFO 
id:si_en cur r: 0.5369 best r: 0.5369
15:30:59,392 root INFO 
id:ne_en cur r: 0.6715 best r: 0.6715
15:31:12,239 root INFO 
id:ru_en cur r: 0.6979 best r: 0.6979
15:31:12,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:42,426 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:32:42,432 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:32:42,437 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:32:42,443 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:32:42,448 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:32:42,452 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:32:42,456 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:32:55,383 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6547
en_de Dev loss: 0.9634 r:0.1476
en_zh Dev loss: 0.7989 r:0.3481
ro_en Dev loss: 0.5220 r:0.7375
et_en Dev loss: 0.4168 r:0.6937
si_en Dev loss: 0.9270 r:0.5502
ne_en Dev loss: 0.5437 r:0.6871
ru_en Dev loss: 0.5736 r:0.7073
Current avg r:0.5531 Best avg r: 0.5531
15:37:26,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:04,686 root INFO 
id:ro_en cur r: 0.7270 best r: 0.7270
15:38:17,587 root INFO 
id:et_en cur r: 0.6838 best r: 0.6838
15:38:30,505 root INFO 
id:si_en cur r: 0.5559 best r: 0.5559
15:38:56,328 root INFO 
id:ne_en cur r: 0.6955 best r: 0.6955
15:39:09,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:39,287 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:40:39,294 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:40:39,298 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:40:39,303 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:40:39,308 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:40:39,312 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:40:39,317 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:40:52,228 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6165
en_de Dev loss: 0.9664 r:0.1388
en_zh Dev loss: 0.7983 r:0.3598
ro_en Dev loss: 0.5228 r:0.7464
et_en Dev loss: 0.4139 r:0.6922
si_en Dev loss: 0.8650 r:0.5577
ne_en Dev loss: 0.6239 r:0.6951
ru_en Dev loss: 0.5690 r:0.6936
Current avg r:0.5548 Best avg r: 0.5548
15:45:22,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:01,243 root INFO 
id:ro_en cur r: 0.7404 best r: 0.7404
15:46:14,180 root INFO 
id:et_en cur r: 0.6894 best r: 0.6894
15:46:27,111 root INFO 
id:si_en cur r: 0.5586 best r: 0.5586
15:46:52,964 root INFO 
id:ne_en cur r: 0.7181 best r: 0.7181
15:47:05,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:36,129 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5901
en_de Dev loss: 0.9634 r:0.1410
en_zh Dev loss: 0.7958 r:0.3216
ro_en Dev loss: 0.4597 r:0.7471
et_en Dev loss: 0.3778 r:0.6895
si_en Dev loss: 0.6513 r:0.5601
ne_en Dev loss: 0.4463 r:0.7113
ru_en Dev loss: 0.5484 r:0.6531
Current avg r:0.5462 Best avg r: 0.5548
15:53:06,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:19,451 root INFO 
id:en_de cur r: 0.1535 best r: 0.1535
15:53:32,297 root INFO 
id:en_zh cur r: 0.3788 best r: 0.3788
15:53:45,192 root INFO 
id:ro_en cur r: 0.7763 best r: 0.7763
15:53:58,107 root INFO 
id:et_en cur r: 0.7084 best r: 0.7084
15:54:11,45 root INFO 
id:si_en cur r: 0.5731 best r: 0.5731
15:54:36,908 root INFO 
id:ne_en cur r: 0.7224 best r: 0.7224
15:54:49,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:19,970 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:56:19,976 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:56:19,981 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:56:19,986 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:56:19,991 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:56:19,996 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:56:20,1 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:56:32,902 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6057
en_de Dev loss: 0.9196 r:0.1624
en_zh Dev loss: 0.7519 r:0.3769
ro_en Dev loss: 0.3908 r:0.7832
et_en Dev loss: 0.3766 r:0.7032
si_en Dev loss: 0.7219 r:0.5768
ne_en Dev loss: 0.5522 r:0.7131
ru_en Dev loss: 0.5180 r:0.6973
Current avg r:0.5733 Best avg r: 0.5733
16:01:03,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:16,367 root INFO 
id:en_de cur r: 0.1627 best r: 0.1627
16:01:29,230 root INFO 
id:en_zh cur r: 0.3891 best r: 0.3891
16:01:42,115 root INFO 
id:ro_en cur r: 0.7817 best r: 0.7817
16:02:07,939 root INFO 
id:si_en cur r: 0.5899 best r: 0.5899
16:02:33,761 root INFO 
id:ne_en cur r: 0.7331 best r: 0.7331
16:02:46,592 root INFO 
id:ru_en cur r: 0.7141 best r: 0.7141
16:02:46,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:16,790 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:04:16,796 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:04:16,800 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:04:16,804 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:04:16,809 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:04:16,813 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:04:16,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:04:29,728 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5813
en_de Dev loss: 0.8830 r:0.1750
en_zh Dev loss: 0.7240 r:0.3951
ro_en Dev loss: 0.3582 r:0.7919
et_en Dev loss: 0.3625 r:0.7067
si_en Dev loss: 0.7009 r:0.5955
ne_en Dev loss: 0.5198 r:0.7270
ru_en Dev loss: 0.4559 r:0.7197
Current avg r:0.5873 Best avg r: 0.5873
16:09:00,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:26,176 root INFO 
id:en_zh cur r: 0.4048 best r: 0.4048
16:09:39,69 root INFO 
id:ro_en cur r: 0.7859 best r: 0.7859
16:09:51,976 root INFO 
id:et_en cur r: 0.7199 best r: 0.7199
16:10:04,912 root INFO 
id:si_en cur r: 0.6031 best r: 0.6031
16:10:30,747 root INFO 
id:ne_en cur r: 0.7452 best r: 0.7452
16:10:43,591 root INFO 
id:ru_en cur r: 0.7324 best r: 0.7324
16:10:43,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:13,879 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:12:13,886 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:12:13,893 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:12:13,898 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:12:13,903 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:12:13,907 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:12:13,914 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:12:26,820 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5633
en_de Dev loss: 0.8959 r:0.1730
en_zh Dev loss: 0.7135 r:0.4083
ro_en Dev loss: 0.3522 r:0.7911
et_en Dev loss: 0.3517 r:0.7204
si_en Dev loss: 0.5980 r:0.6096
ne_en Dev loss: 0.4067 r:0.7418
ru_en Dev loss: 0.4226 r:0.7426
Current avg r:0.5981 Best avg r: 0.5981
16:16:57,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:10,245 root INFO 
id:en_de cur r: 0.1834 best r: 0.1834
16:17:23,97 root INFO 
id:en_zh cur r: 0.4152 best r: 0.4152
16:17:35,983 root INFO 
id:ro_en cur r: 0.7870 best r: 0.7870
16:18:27,555 root INFO 
id:ru_en cur r: 0.7472 best r: 0.7472
16:18:27,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:57,723 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:19:57,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:19:57,732 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:19:57,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:19:57,741 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:19:57,746 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:19:57,751 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:20:10,668 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5315
en_de Dev loss: 0.8555 r:0.1993
en_zh Dev loss: 0.6752 r:0.4231
ro_en Dev loss: 0.3230 r:0.7975
et_en Dev loss: 0.3453 r:0.7159
si_en Dev loss: 0.5961 r:0.5943
ne_en Dev loss: 0.4109 r:0.7362
ru_en Dev loss: 0.3718 r:0.7549
Current avg r:0.6030 Best avg r: 0.6030
16:24:41,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:11,665 root INFO 
id:ne_en cur r: 0.7479 best r: 0.7479
16:26:24,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:54,719 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5502
en_de Dev loss: 0.8975 r:0.1961
en_zh Dev loss: 0.7406 r:0.4120
ro_en Dev loss: 0.3618 r:0.7909
et_en Dev loss: 0.3620 r:0.7118
si_en Dev loss: 0.6365 r:0.5930
ne_en Dev loss: 0.4588 r:0.7423
ru_en Dev loss: 0.4473 r:0.7363
Current avg r:0.5975 Best avg r: 0.6030
16:32:25,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:37,952 root INFO 
id:en_de cur r: 0.1838 best r: 0.1838
16:32:50,769 root INFO 
id:en_zh cur r: 0.4306 best r: 0.4306
16:33:03,615 root INFO 
id:ro_en cur r: 0.8029 best r: 0.8029
16:33:16,482 root INFO 
id:et_en cur r: 0.7260 best r: 0.7260
16:33:29,370 root INFO 
id:si_en cur r: 0.6101 best r: 0.6101
16:33:55,93 root INFO 
id:ne_en cur r: 0.7594 best r: 0.7594
16:34:07,907 root INFO 
id:ru_en cur r: 0.7550 best r: 0.7550
16:34:07,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:37,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:35:37,860 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:35:37,865 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:35:37,870 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:35:37,875 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:35:37,880 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:35:37,884 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:35:50,786 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5659
en_de Dev loss: 0.8821 r:0.2106
en_zh Dev loss: 0.7284 r:0.4358
ro_en Dev loss: 0.3542 r:0.8064
et_en Dev loss: 0.3512 r:0.7301
si_en Dev loss: 0.6258 r:0.6098
ne_en Dev loss: 0.4721 r:0.7536
ru_en Dev loss: 0.4205 r:0.7603
Current avg r:0.6152 Best avg r: 0.6152
16:40:21,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:34,187 root INFO 
id:en_de cur r: 0.2063 best r: 0.2063
16:40:47,31 root INFO 
id:en_zh cur r: 0.4560 best r: 0.4560
16:41:12,865 root INFO 
id:et_en cur r: 0.7327 best r: 0.7327
16:41:51,607 root INFO 
id:ne_en cur r: 0.7621 best r: 0.7621
16:42:04,435 root INFO 
id:ru_en cur r: 0.7678 best r: 0.7678
16:42:04,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:34,544 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:43:34,551 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:43:34,556 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:43:34,560 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:43:34,565 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:43:34,569 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:43:34,574 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:43:47,504 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5520
en_de Dev loss: 0.8528 r:0.2233
en_zh Dev loss: 0.6633 r:0.4599
ro_en Dev loss: 0.3063 r:0.8061
et_en Dev loss: 0.3445 r:0.7336
si_en Dev loss: 0.5427 r:0.6130
ne_en Dev loss: 0.3581 r:0.7600
ru_en Dev loss: 0.3449 r:0.7670
Current avg r:0.6233 Best avg r: 0.6233
16:48:19,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:50,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:20,309 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4930
en_de Dev loss: 0.8815 r:0.1959
en_zh Dev loss: 0.7416 r:0.4272
ro_en Dev loss: 0.3682 r:0.7979
et_en Dev loss: 0.3568 r:0.7188
si_en Dev loss: 0.6879 r:0.6010
ne_en Dev loss: 0.4871 r:0.7436
ru_en Dev loss: 0.4602 r:0.7412
Current avg r:0.6037 Best avg r: 0.6233
16:55:51,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:29,617 root INFO 
id:ro_en cur r: 0.8074 best r: 0.8074
16:57:21,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:51,343 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5008
en_de Dev loss: 0.8674 r:0.2024
en_zh Dev loss: 0.6954 r:0.4403
ro_en Dev loss: 0.3429 r:0.8103
et_en Dev loss: 0.3615 r:0.7249
si_en Dev loss: 0.6527 r:0.6073
ne_en Dev loss: 0.4923 r:0.7562
ru_en Dev loss: 0.3687 r:0.7682
Current avg r:0.6157 Best avg r: 0.6233
17:03:21,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:51,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:21,770 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4619
en_de Dev loss: 0.8731 r:0.1818
en_zh Dev loss: 0.7302 r:0.4246
ro_en Dev loss: 0.3501 r:0.8063
et_en Dev loss: 0.3594 r:0.7155
si_en Dev loss: 0.7099 r:0.5945
ne_en Dev loss: 0.5208 r:0.7500
ru_en Dev loss: 0.4181 r:0.7477
Current avg r:0.6029 Best avg r: 0.6233
17:10:51,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:30,356 root INFO 
id:ro_en cur r: 0.8204 best r: 0.8204
17:11:43,249 root INFO 
id:et_en cur r: 0.7341 best r: 0.7341
17:11:56,174 root INFO 
id:si_en cur r: 0.6164 best r: 0.6164
17:12:21,984 root INFO 
id:ne_en cur r: 0.7713 best r: 0.7713
17:12:34,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:04,940 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5023
en_de Dev loss: 0.8663 r:0.2111
en_zh Dev loss: 0.7301 r:0.4360
ro_en Dev loss: 0.3311 r:0.8224
et_en Dev loss: 0.3339 r:0.7314
si_en Dev loss: 0.6181 r:0.6245
ne_en Dev loss: 0.3958 r:0.7707
ru_en Dev loss: 0.4126 r:0.7617
Current avg r:0.6225 Best avg r: 0.6233
17:18:34,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:04,994 root INFO 
id:ru_en cur r: 0.7753 best r: 0.7753
17:20:04,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:35,123 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
17:21:35,129 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:21:35,133 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:21:35,138 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
17:21:35,143 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
17:21:35,147 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:21:35,151 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:21:48,56 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4871
en_de Dev loss: 0.8479 r:0.2185
en_zh Dev loss: 0.6768 r:0.4574
ro_en Dev loss: 0.3070 r:0.8184
et_en Dev loss: 0.3363 r:0.7272
si_en Dev loss: 0.6693 r:0.6138
ne_en Dev loss: 0.4378 r:0.7639
ru_en Dev loss: 0.3571 r:0.7749
Current avg r:0.6249 Best avg r: 0.6249
17:26:18,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:30,912 root INFO 
id:en_de cur r: 0.2133 best r: 0.2133
17:26:43,771 root INFO 
id:en_zh cur r: 0.4606 best r: 0.4606
17:27:48,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:18,355 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4676
en_de Dev loss: 0.8595 r:0.2269
en_zh Dev loss: 0.6985 r:0.4599
ro_en Dev loss: 0.3639 r:0.8136
et_en Dev loss: 0.3899 r:0.7092
si_en Dev loss: 0.8731 r:0.5835
ne_en Dev loss: 0.5413 r:0.7485
ru_en Dev loss: 0.4150 r:0.7609
Current avg r:0.6147 Best avg r: 0.6249
17:33:48,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:01,222 root INFO 
id:en_de cur r: 0.2144 best r: 0.2144
17:35:18,512 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:48,601 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4784
en_de Dev loss: 0.8714 r:0.2170
en_zh Dev loss: 0.7307 r:0.4478
ro_en Dev loss: 0.3784 r:0.8128
et_en Dev loss: 0.3731 r:0.7198
si_en Dev loss: 0.7983 r:0.5836
ne_en Dev loss: 0.4741 r:0.7559
ru_en Dev loss: 0.4475 r:0.7546
Current avg r:0.6131 Best avg r: 0.6249
17:41:18,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:31,355 root INFO 
id:en_de cur r: 0.2187 best r: 0.2187
17:41:44,197 root INFO 
id:en_zh cur r: 0.4689 best r: 0.4689
17:42:48,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:18,735 root INFO Epoch 1 Global steps: 16100 Train loss: 0.5210
en_de Dev loss: 0.8452 r:0.2174
en_zh Dev loss: 0.6539 r:0.4719
ro_en Dev loss: 0.3165 r:0.8159
et_en Dev loss: 0.3477 r:0.7249
si_en Dev loss: 0.6140 r:0.6007
ne_en Dev loss: 0.3469 r:0.7645
ru_en Dev loss: 0.3779 r:0.7626
Current avg r:0.6226 Best avg r: 0.6249
17:48:48,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:18,222 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:48,178 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4946
en_de Dev loss: 0.8590 r:0.2289
en_zh Dev loss: 0.7063 r:0.4584
ro_en Dev loss: 0.3437 r:0.8144
et_en Dev loss: 0.3571 r:0.7156
si_en Dev loss: 0.6911 r:0.6002
ne_en Dev loss: 0.3817 r:0.7623
ru_en Dev loss: 0.4262 r:0.7556
Current avg r:0.6193 Best avg r: 0.6249
17:56:17,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:56,456 root INFO 
id:ro_en cur r: 0.8206 best r: 0.8206
17:57:22,246 root INFO 
id:si_en cur r: 0.6195 best r: 0.6195
17:57:48,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:18,114 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_de.lang_agnost_mlp.dev.best.scores
17:59:18,123 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:59:18,133 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:59:18,139 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/et_en.lang_agnost_mlp.dev.best.scores
17:59:18,144 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/si_en.lang_agnost_mlp.dev.best.scores
17:59:18,149 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:59:18,154 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:59:31,53 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4662
en_de Dev loss: 0.8771 r:0.2269
en_zh Dev loss: 0.7022 r:0.4653
ro_en Dev loss: 0.3354 r:0.8208
et_en Dev loss: 0.3491 r:0.7260
si_en Dev loss: 0.6575 r:0.6191
ne_en Dev loss: 0.3729 r:0.7651
ru_en Dev loss: 0.3980 r:0.7674
Current avg r:0.6272 Best avg r: 0.6272
18:04:01,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:39,641 root INFO 
id:ro_en cur r: 0.8222 best r: 0.8222
18:05:31,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:01,339 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4994
en_de Dev loss: 0.8674 r:0.1909
en_zh Dev loss: 0.7138 r:0.4564
ro_en Dev loss: 0.3179 r:0.8223
et_en Dev loss: 0.3452 r:0.7243
si_en Dev loss: 0.6631 r:0.6118
ne_en Dev loss: 0.4570 r:0.7594
ru_en Dev loss: 0.4266 r:0.7435
Current avg r:0.6155 Best avg r: 0.6272
18:11:31,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:09,942 root INFO 
id:ro_en cur r: 0.8238 best r: 0.8238
18:13:01,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:31,644 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4811
en_de Dev loss: 0.8574 r:0.1973
en_zh Dev loss: 0.6712 r:0.4674
ro_en Dev loss: 0.3095 r:0.8222
et_en Dev loss: 0.3596 r:0.7233
si_en Dev loss: 0.6005 r:0.6094
ne_en Dev loss: 0.3984 r:0.7574
ru_en Dev loss: 0.3982 r:0.7484
Current avg r:0.6179 Best avg r: 0.6272
18:19:01,510 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:31,599 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:01,720 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4559
en_de Dev loss: 0.8727 r:0.1952
en_zh Dev loss: 0.7555 r:0.4482
ro_en Dev loss: 0.3236 r:0.8189
et_en Dev loss: 0.3620 r:0.7162
si_en Dev loss: 0.6358 r:0.6059
ne_en Dev loss: 0.4468 r:0.7562
ru_en Dev loss: 0.4561 r:0.7306
Current avg r:0.6102 Best avg r: 0.6272
18:26:31,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:10,158 root INFO 
id:ro_en cur r: 0.8273 best r: 0.8273
18:28:01,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:31,768 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4821
en_de Dev loss: 0.8811 r:0.1653
en_zh Dev loss: 0.6938 r:0.4596
ro_en Dev loss: 0.3092 r:0.8255
et_en Dev loss: 0.3492 r:0.7220
si_en Dev loss: 0.6897 r:0.6049
ne_en Dev loss: 0.4262 r:0.7600
ru_en Dev loss: 0.4081 r:0.7490
Current avg r:0.6123 Best avg r: 0.6272
18:34:01,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:31,772 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:01,846 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4294
en_de Dev loss: 0.8669 r:0.1789
en_zh Dev loss: 0.6906 r:0.4523
ro_en Dev loss: 0.3029 r:0.8236
et_en Dev loss: 0.3453 r:0.7238
si_en Dev loss: 0.6831 r:0.5997
ne_en Dev loss: 0.4099 r:0.7561
ru_en Dev loss: 0.4242 r:0.7355
Current avg r:0.6100 Best avg r: 0.6272
18:41:33,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:03,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:33,249 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4333
en_de Dev loss: 0.8775 r:0.1962
en_zh Dev loss: 0.7410 r:0.4403
ro_en Dev loss: 0.3274 r:0.8181
et_en Dev loss: 0.3585 r:0.7147
si_en Dev loss: 0.6984 r:0.5961
ne_en Dev loss: 0.5001 r:0.7509
ru_en Dev loss: 0.4642 r:0.7265
Current avg r:0.6061 Best avg r: 0.6272
18:49:03,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:33,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:03,409 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4497
en_de Dev loss: 0.9071 r:0.1443
en_zh Dev loss: 0.7184 r:0.4530
ro_en Dev loss: 0.3080 r:0.8223
et_en Dev loss: 0.3560 r:0.7155
si_en Dev loss: 0.7058 r:0.6010
ne_en Dev loss: 0.4926 r:0.7583
ru_en Dev loss: 0.4537 r:0.7218
Current avg r:0.6023 Best avg r: 0.6272
18:56:33,398 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:03,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:33,571 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4030
en_de Dev loss: 0.8925 r:0.1580
en_zh Dev loss: 0.7599 r:0.4456
ro_en Dev loss: 0.3097 r:0.8241
et_en Dev loss: 0.3657 r:0.7141
si_en Dev loss: 0.6866 r:0.6048
ne_en Dev loss: 0.4262 r:0.7594
ru_en Dev loss: 0.4615 r:0.7279
Current avg r:0.6048 Best avg r: 0.6272
19:04:03,549 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:42,83 root INFO 
id:ro_en cur r: 0.8284 best r: 0.8284
19:05:33,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:03,437 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4075
en_de Dev loss: 0.8755 r:0.1752
en_zh Dev loss: 0.6950 r:0.4597
ro_en Dev loss: 0.2913 r:0.8270
et_en Dev loss: 0.3604 r:0.7157
si_en Dev loss: 0.6101 r:0.6108
ne_en Dev loss: 0.4130 r:0.7512
ru_en Dev loss: 0.4396 r:0.7294
Current avg r:0.6099 Best avg r: 0.6272
19:11:32,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:58,654 root INFO 
id:en_zh cur r: 0.4723 best r: 0.4723
19:13:02,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:33,105 root INFO Epoch 2 Global steps: 24500 Train loss: 0.3903
en_de Dev loss: 0.8883 r:0.1694
en_zh Dev loss: 0.6914 r:0.4722
ro_en Dev loss: 0.3319 r:0.8240
et_en Dev loss: 0.3770 r:0.7119
si_en Dev loss: 0.7367 r:0.5992
ne_en Dev loss: 0.4888 r:0.7511
ru_en Dev loss: 0.4023 r:0.7586
Current avg r:0.6123 Best avg r: 0.6272
19:19:02,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:33,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:03,249 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4147
en_de Dev loss: 0.8832 r:0.1540
en_zh Dev loss: 0.7675 r:0.4537
ro_en Dev loss: 0.3368 r:0.8245
et_en Dev loss: 0.3731 r:0.7070
si_en Dev loss: 0.7533 r:0.5966
ne_en Dev loss: 0.5814 r:0.7495
ru_en Dev loss: 0.4483 r:0.7468
Current avg r:0.6046 Best avg r: 0.6272
19:26:33,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:59,18 root INFO 
id:en_zh cur r: 0.4750 best r: 0.4750
19:28:03,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:33,500 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4315
en_de Dev loss: 0.8612 r:0.1921
en_zh Dev loss: 0.7121 r:0.4682
ro_en Dev loss: 0.3070 r:0.8274
et_en Dev loss: 0.3643 r:0.7153
si_en Dev loss: 0.7142 r:0.6061
ne_en Dev loss: 0.4718 r:0.7500
ru_en Dev loss: 0.4375 r:0.7454
Current avg r:0.6149 Best avg r: 0.6272
19:34:03,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:33,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:03,653 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4203
en_de Dev loss: 0.8641 r:0.1807
en_zh Dev loss: 0.7230 r:0.4639
ro_en Dev loss: 0.3075 r:0.8235
et_en Dev loss: 0.3706 r:0.7064
si_en Dev loss: 0.7901 r:0.5917
ne_en Dev loss: 0.4838 r:0.7517
ru_en Dev loss: 0.4180 r:0.7486
Current avg r:0.6095 Best avg r: 0.6272
19:41:33,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:46,412 root INFO 
id:en_de cur r: 0.2224 best r: 0.2224
19:41:59,261 root INFO 
id:en_zh cur r: 0.4787 best r: 0.4787
19:43:03,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:33,707 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4137
en_de Dev loss: 0.8647 r:0.2082
en_zh Dev loss: 0.6943 r:0.4732
ro_en Dev loss: 0.3277 r:0.8229
et_en Dev loss: 0.3893 r:0.7056
si_en Dev loss: 0.7241 r:0.5984
ne_en Dev loss: 0.4667 r:0.7463
ru_en Dev loss: 0.3907 r:0.7635
Current avg r:0.6169 Best avg r: 0.6272
19:49:03,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:33,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:03,787 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3954
en_de Dev loss: 0.8939 r:0.1756
en_zh Dev loss: 0.8200 r:0.4474
ro_en Dev loss: 0.3782 r:0.8239
et_en Dev loss: 0.3970 r:0.7119
si_en Dev loss: 0.7552 r:0.6054
ne_en Dev loss: 0.4778 r:0.7511
ru_en Dev loss: 0.4752 r:0.7449
Current avg r:0.6086 Best avg r: 0.6272
19:56:33,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:46,521 root INFO 
id:en_de cur r: 0.2291 best r: 0.2291
19:56:59,388 root INFO 
id:en_zh cur r: 0.4797 best r: 0.4797
19:58:03,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:33,912 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4004
en_de Dev loss: 0.8548 r:0.2032
en_zh Dev loss: 0.6681 r:0.4745
ro_en Dev loss: 0.3020 r:0.8278
et_en Dev loss: 0.3683 r:0.7163
si_en Dev loss: 0.6413 r:0.6061
ne_en Dev loss: 0.4008 r:0.7529
ru_en Dev loss: 0.3829 r:0.7540
Current avg r:0.6193 Best avg r: 0.6272
20:04:03,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:33,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:04,94 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3905
en_de Dev loss: 0.8632 r:0.2045
en_zh Dev loss: 0.6861 r:0.4708
ro_en Dev loss: 0.3138 r:0.8218
et_en Dev loss: 0.3727 r:0.7083
si_en Dev loss: 0.6517 r:0.6040
ne_en Dev loss: 0.4160 r:0.7482
ru_en Dev loss: 0.4172 r:0.7453
Current avg r:0.6147 Best avg r: 0.6272
20:11:33,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:04,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:34,109 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3910
en_de Dev loss: 0.8639 r:0.2040
en_zh Dev loss: 0.7023 r:0.4662
ro_en Dev loss: 0.3226 r:0.8228
et_en Dev loss: 0.3715 r:0.7100
si_en Dev loss: 0.7277 r:0.5954
ne_en Dev loss: 0.5269 r:0.7480
ru_en Dev loss: 0.4381 r:0.7415
Current avg r:0.6126 Best avg r: 0.6272
20:19:04,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:34,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:04,68 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3801
en_de Dev loss: 0.8855 r:0.2089
en_zh Dev loss: 0.7551 r:0.4543
ro_en Dev loss: 0.3377 r:0.8178
et_en Dev loss: 0.3891 r:0.6999
si_en Dev loss: 0.7655 r:0.5894
ne_en Dev loss: 0.5544 r:0.7466
ru_en Dev loss: 0.4521 r:0.7386
Current avg r:0.6079 Best avg r: 0.6272
20:26:33,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:03,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:33,553 root INFO Epoch 2 Global steps: 31500 Train loss: 0.4025
en_de Dev loss: 0.8659 r:0.2120
en_zh Dev loss: 0.7079 r:0.4647
ro_en Dev loss: 0.3361 r:0.8232
et_en Dev loss: 0.3805 r:0.7035
si_en Dev loss: 0.7625 r:0.5945
ne_en Dev loss: 0.5350 r:0.7459
ru_en Dev loss: 0.4439 r:0.7391
Current avg r:0.6119 Best avg r: 0.6272
20:34:04,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:17,743 root INFO 
id:en_de cur r: 0.2368 best r: 0.2368
20:35:35,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:05,93 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3462
en_de Dev loss: 0.8488 r:0.2184
en_zh Dev loss: 0.6823 r:0.4719
ro_en Dev loss: 0.3268 r:0.8233
et_en Dev loss: 0.3831 r:0.7000
si_en Dev loss: 0.7610 r:0.5940
ne_en Dev loss: 0.5342 r:0.7516
ru_en Dev loss: 0.4188 r:0.7446
Current avg r:0.6148 Best avg r: 0.6272
20:41:35,36 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:47,893 root INFO 
id:en_de cur r: 0.2457 best r: 0.2457
20:42:13,587 root INFO 
id:ro_en cur r: 0.8285 best r: 0.8285
20:43:05,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:35,111 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3466
en_de Dev loss: 0.8548 r:0.2302
en_zh Dev loss: 0.7347 r:0.4509
ro_en Dev loss: 0.3345 r:0.8232
et_en Dev loss: 0.3932 r:0.7079
si_en Dev loss: 0.7156 r:0.5953
ne_en Dev loss: 0.4379 r:0.7467
ru_en Dev loss: 0.4698 r:0.7258
Current avg r:0.6114 Best avg r: 0.6272
20:49:04,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:34,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:05,61 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3533
en_de Dev loss: 0.8511 r:0.2050
en_zh Dev loss: 0.7328 r:0.4435
ro_en Dev loss: 0.3223 r:0.8161
et_en Dev loss: 0.3869 r:0.6963
si_en Dev loss: 0.7328 r:0.5847
ne_en Dev loss: 0.5606 r:0.7411
ru_en Dev loss: 0.4354 r:0.7225
Current avg r:0.6013 Best avg r: 0.6272
20:56:35,27 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:05,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:35,328 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3410
en_de Dev loss: 0.8546 r:0.2069
en_zh Dev loss: 0.7365 r:0.4360
ro_en Dev loss: 0.3356 r:0.8128
et_en Dev loss: 0.3908 r:0.6904
si_en Dev loss: 0.7823 r:0.5751
ne_en Dev loss: 0.5064 r:0.7396
ru_en Dev loss: 0.4661 r:0.7098
Current avg r:0.5958 Best avg r: 0.6272
21:04:05,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:35,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:05,447 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3453
en_de Dev loss: 0.8536 r:0.2026
en_zh Dev loss: 0.7668 r:0.4445
ro_en Dev loss: 0.3309 r:0.8224
et_en Dev loss: 0.4028 r:0.7046
si_en Dev loss: 0.7269 r:0.5954
ne_en Dev loss: 0.5528 r:0.7372
ru_en Dev loss: 0.4483 r:0.7303
Current avg r:0.6053 Best avg r: 0.6272
21:11:35,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:13,931 root INFO 
id:ro_en cur r: 0.8338 best r: 0.8338
21:13:05,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:35,594 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3605
en_de Dev loss: 0.8610 r:0.1922
en_zh Dev loss: 0.6906 r:0.4685
ro_en Dev loss: 0.2837 r:0.8332
et_en Dev loss: 0.4004 r:0.7187
si_en Dev loss: 0.5830 r:0.6104
ne_en Dev loss: 0.4001 r:0.7463
ru_en Dev loss: 0.3630 r:0.7590
Current avg r:0.6183 Best avg r: 0.6272
21:19:05,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:35,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:05,686 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3327
en_de Dev loss: 0.8862 r:0.2242
en_zh Dev loss: 0.7734 r:0.4544
ro_en Dev loss: 0.3451 r:0.8256
et_en Dev loss: 0.4114 r:0.7025
si_en Dev loss: 0.7479 r:0.5939
ne_en Dev loss: 0.4693 r:0.7406
ru_en Dev loss: 0.4752 r:0.7403
Current avg r:0.6116 Best avg r: 0.6272
21:26:35,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:05,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:35,726 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3349
en_de Dev loss: 0.9126 r:0.2312
en_zh Dev loss: 0.8313 r:0.4330
ro_en Dev loss: 0.3797 r:0.8146
et_en Dev loss: 0.4409 r:0.6886
si_en Dev loss: 0.8145 r:0.5783
ne_en Dev loss: 0.6069 r:0.7283
ru_en Dev loss: 0.5219 r:0.7136
Current avg r:0.5982 Best avg r: 0.6272
21:34:05,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:35,826 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:05,805 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3225
en_de Dev loss: 0.8648 r:0.2334
en_zh Dev loss: 0.7203 r:0.4638
ro_en Dev loss: 0.3112 r:0.8262
et_en Dev loss: 0.4062 r:0.7121
si_en Dev loss: 0.6309 r:0.6102
ne_en Dev loss: 0.4504 r:0.7420
ru_en Dev loss: 0.3819 r:0.7666
Current avg r:0.6220 Best avg r: 0.6272
21:41:35,459 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:05,568 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:35,566 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3200
en_de Dev loss: 0.8869 r:0.2258
en_zh Dev loss: 0.7173 r:0.4773
ro_en Dev loss: 0.3342 r:0.8260
et_en Dev loss: 0.3908 r:0.7032
si_en Dev loss: 0.7765 r:0.5963
ne_en Dev loss: 0.5532 r:0.7400
ru_en Dev loss: 0.4208 r:0.7531
Current avg r:0.6174 Best avg r: 0.6272
21:49:05,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:35,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:05,476 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3481
en_de Dev loss: 0.8750 r:0.1788
en_zh Dev loss: 0.7487 r:0.4446
ro_en Dev loss: 0.3097 r:0.8259
et_en Dev loss: 0.4250 r:0.6971
si_en Dev loss: 0.6836 r:0.6006
ne_en Dev loss: 0.4500 r:0.7388
ru_en Dev loss: 0.4028 r:0.7468
Current avg r:0.6047 Best avg r: 0.6272
21:56:35,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:05,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:35,700 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3309
en_de Dev loss: 0.8983 r:0.1688
en_zh Dev loss: 0.7485 r:0.4520
ro_en Dev loss: 0.3229 r:0.8237
et_en Dev loss: 0.3923 r:0.6968
si_en Dev loss: 0.7598 r:0.5898
ne_en Dev loss: 0.6349 r:0.7432
ru_en Dev loss: 0.4416 r:0.7317
Current avg r:0.6009 Best avg r: 0.6272
22:04:05,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:35,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:05,776 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3199
en_de Dev loss: 0.8642 r:0.2126
en_zh Dev loss: 0.7497 r:0.4595
ro_en Dev loss: 0.3192 r:0.8279
et_en Dev loss: 0.4108 r:0.7019
si_en Dev loss: 0.6932 r:0.6017
ne_en Dev loss: 0.5042 r:0.7381
ru_en Dev loss: 0.4571 r:0.7239
Current avg r:0.6094 Best avg r: 0.6272
22:11:35,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:06,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:36,167 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3512
en_de Dev loss: 0.8676 r:0.2300
en_zh Dev loss: 0.7601 r:0.4562
ro_en Dev loss: 0.3344 r:0.8227
et_en Dev loss: 0.4511 r:0.6905
si_en Dev loss: 0.7227 r:0.5925
ne_en Dev loss: 0.4376 r:0.7356
ru_en Dev loss: 0.4613 r:0.7184
Current avg r:0.6065 Best avg r: 0.6272
22:19:06,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:36,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:06,192 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3352
en_de Dev loss: 0.8873 r:0.2187
en_zh Dev loss: 0.7859 r:0.4439
ro_en Dev loss: 0.3548 r:0.8217
et_en Dev loss: 0.4349 r:0.6873
si_en Dev loss: 0.7792 r:0.5843
ne_en Dev loss: 0.5227 r:0.7321
ru_en Dev loss: 0.4842 r:0.7170
Current avg r:0.6007 Best avg r: 0.6272
22:26:37,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:07,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:37,725 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2929
en_de Dev loss: 0.8729 r:0.2271
en_zh Dev loss: 0.7644 r:0.4457
ro_en Dev loss: 0.3334 r:0.8229
et_en Dev loss: 0.4350 r:0.6828
si_en Dev loss: 0.7799 r:0.5826
ne_en Dev loss: 0.5551 r:0.7303
ru_en Dev loss: 0.4575 r:0.7200
Current avg r:0.6016 Best avg r: 0.6272
22:34:07,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:37,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:08,16 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2831
en_de Dev loss: 0.8667 r:0.2232
en_zh Dev loss: 0.7699 r:0.4567
ro_en Dev loss: 0.3207 r:0.8273
et_en Dev loss: 0.4405 r:0.6955
si_en Dev loss: 0.6529 r:0.6009
ne_en Dev loss: 0.4795 r:0.7348
ru_en Dev loss: 0.4344 r:0.7342
Current avg r:0.6104 Best avg r: 0.6272
22:41:38,5 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:08,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:38,114 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2973
en_de Dev loss: 0.8512 r:0.2363
en_zh Dev loss: 0.7538 r:0.4544
ro_en Dev loss: 0.3187 r:0.8258
et_en Dev loss: 0.4440 r:0.6918
si_en Dev loss: 0.7137 r:0.5867
ne_en Dev loss: 0.5094 r:0.7280
ru_en Dev loss: 0.4208 r:0.7305
Current avg r:0.6076 Best avg r: 0.6272
22:49:08,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:38,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:08,341 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2886
en_de Dev loss: 0.8521 r:0.2346
en_zh Dev loss: 0.7429 r:0.4462
ro_en Dev loss: 0.2958 r:0.8316
et_en Dev loss: 0.4323 r:0.7027
si_en Dev loss: 0.6473 r:0.5979
ne_en Dev loss: 0.4673 r:0.7328
ru_en Dev loss: 0.3916 r:0.7453
Current avg r:0.6130 Best avg r: 0.6272
22:56:38,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:08,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:38,412 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2920
en_de Dev loss: 0.8513 r:0.2352
en_zh Dev loss: 0.7788 r:0.4329
ro_en Dev loss: 0.3270 r:0.8243
et_en Dev loss: 0.4048 r:0.6866
si_en Dev loss: 0.8481 r:0.5821
ne_en Dev loss: 0.5917 r:0.7261
ru_en Dev loss: 0.4763 r:0.7195
Current avg r:0.6010 Best avg r: 0.6272
23:04:08,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:38,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:08,508 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2646
en_de Dev loss: 0.8771 r:0.2213
en_zh Dev loss: 0.8091 r:0.4295
ro_en Dev loss: 0.3397 r:0.8204
et_en Dev loss: 0.4545 r:0.6720
si_en Dev loss: 0.8113 r:0.5772
ne_en Dev loss: 0.5785 r:0.7214
ru_en Dev loss: 0.4693 r:0.7157
Current avg r:0.5939 Best avg r: 0.6272
23:11:38,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:08,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:38,553 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2683
en_de Dev loss: 0.8547 r:0.2405
en_zh Dev loss: 0.7886 r:0.4393
ro_en Dev loss: 0.3173 r:0.8277
et_en Dev loss: 0.4252 r:0.6903
si_en Dev loss: 0.7531 r:0.5907
ne_en Dev loss: 0.5127 r:0.7305
ru_en Dev loss: 0.4267 r:0.7432
Current avg r:0.6089 Best avg r: 0.6272
23:19:08,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:38,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:08,381 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2625
en_de Dev loss: 0.8601 r:0.2122
en_zh Dev loss: 0.7513 r:0.4478
ro_en Dev loss: 0.3112 r:0.8252
et_en Dev loss: 0.4520 r:0.6893
si_en Dev loss: 0.6876 r:0.5897
ne_en Dev loss: 0.4593 r:0.7258
ru_en Dev loss: 0.4108 r:0.7398
Current avg r:0.6042 Best avg r: 0.6272
23:26:38,181 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:08,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:38,483 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2754
en_de Dev loss: 0.8614 r:0.2165
en_zh Dev loss: 0.7547 r:0.4491
ro_en Dev loss: 0.3322 r:0.8215
et_en Dev loss: 0.4287 r:0.6761
si_en Dev loss: 0.8073 r:0.5774
ne_en Dev loss: 0.5564 r:0.7215
ru_en Dev loss: 0.4384 r:0.7257
Current avg r:0.5983 Best avg r: 0.6272
23:34:08,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:38,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:08,675 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2911
en_de Dev loss: 0.8591 r:0.2136
en_zh Dev loss: 0.7678 r:0.4407
ro_en Dev loss: 0.3187 r:0.8259
et_en Dev loss: 0.4277 r:0.6856
si_en Dev loss: 0.7995 r:0.5795
ne_en Dev loss: 0.5517 r:0.7206
ru_en Dev loss: 0.4214 r:0.7338
Current avg r:0.6000 Best avg r: 0.6272
23:41:38,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:08,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:38,914 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2840
en_de Dev loss: 0.8589 r:0.2187
en_zh Dev loss: 0.7725 r:0.4558
ro_en Dev loss: 0.3314 r:0.8294
et_en Dev loss: 0.4501 r:0.6808
si_en Dev loss: 0.9034 r:0.5783
ne_en Dev loss: 0.6640 r:0.7180
ru_en Dev loss: 0.4498 r:0.7297
Current avg r:0.6015 Best avg r: 0.6272
23:49:08,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:38,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:09,44 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2924
en_de Dev loss: 0.8672 r:0.2223
en_zh Dev loss: 0.7983 r:0.4350
ro_en Dev loss: 0.3787 r:0.8150
et_en Dev loss: 0.4484 r:0.6712
si_en Dev loss: 0.9436 r:0.5655
ne_en Dev loss: 0.7520 r:0.7173
ru_en Dev loss: 0.5007 r:0.7090
Current avg r:0.5908 Best avg r: 0.6272
23:56:38,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:09,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:39,198 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2734
en_de Dev loss: 0.8746 r:0.2513
en_zh Dev loss: 0.7834 r:0.4606
ro_en Dev loss: 0.3500 r:0.8242
et_en Dev loss: 0.4655 r:0.6779
si_en Dev loss: 0.8099 r:0.5784
ne_en Dev loss: 0.5236 r:0.7232
ru_en Dev loss: 0.4495 r:0.7402
Current avg r:0.6080 Best avg r: 0.6272
00:04:09,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:39,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:09,324 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2894
en_de Dev loss: 0.8807 r:0.2401
en_zh Dev loss: 0.8136 r:0.4430
ro_en Dev loss: 0.3685 r:0.8258
et_en Dev loss: 0.4336 r:0.6833
si_en Dev loss: 0.8120 r:0.5829
ne_en Dev loss: 0.5472 r:0.7264
ru_en Dev loss: 0.4823 r:0.7278
Current avg r:0.6042 Best avg r: 0.6272
00:11:39,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:09,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:39,418 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2563
en_de Dev loss: 0.8380 r:0.2570
en_zh Dev loss: 0.7403 r:0.4587
ro_en Dev loss: 0.3185 r:0.8282
et_en Dev loss: 0.4350 r:0.6770
si_en Dev loss: 0.8142 r:0.5742
ne_en Dev loss: 0.5598 r:0.7199
ru_en Dev loss: 0.4201 r:0.7377
Current avg r:0.6075 Best avg r: 0.6272
00:19:10,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:41,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:11,60 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2452
en_de Dev loss: 0.8539 r:0.2507
en_zh Dev loss: 0.7448 r:0.4563
ro_en Dev loss: 0.3119 r:0.8288
et_en Dev loss: 0.4437 r:0.6782
si_en Dev loss: 0.7538 r:0.5778
ne_en Dev loss: 0.4758 r:0.7245
ru_en Dev loss: 0.3997 r:0.7465
Current avg r:0.6090 Best avg r: 0.6272
00:26:40,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:11,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:41,178 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2427
en_de Dev loss: 0.8700 r:0.2448
en_zh Dev loss: 0.7971 r:0.4435
ro_en Dev loss: 0.3534 r:0.8266
et_en Dev loss: 0.4310 r:0.6758
si_en Dev loss: 0.8649 r:0.5765
ne_en Dev loss: 0.6016 r:0.7185
ru_en Dev loss: 0.4729 r:0.7256
Current avg r:0.6016 Best avg r: 0.6272
00:34:11,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:41,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:11,336 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2411
en_de Dev loss: 0.8650 r:0.2325
en_zh Dev loss: 0.7441 r:0.4575
ro_en Dev loss: 0.3130 r:0.8229
et_en Dev loss: 0.4785 r:0.6687
si_en Dev loss: 0.7573 r:0.5743
ne_en Dev loss: 0.5132 r:0.7156
ru_en Dev loss: 0.3908 r:0.7479
Current avg r:0.6028 Best avg r: 0.6272
00:41:41,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:11,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:41,466 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2383
en_de Dev loss: 0.8615 r:0.2535
en_zh Dev loss: 0.7835 r:0.4565
ro_en Dev loss: 0.3418 r:0.8267
et_en Dev loss: 0.4956 r:0.6777
si_en Dev loss: 0.7365 r:0.5856
ne_en Dev loss: 0.5006 r:0.7232
ru_en Dev loss: 0.4194 r:0.7460
Current avg r:0.6099 Best avg r: 0.6272
00:49:11,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:41,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:11,569 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2415
en_de Dev loss: 0.8745 r:0.2540
en_zh Dev loss: 0.7904 r:0.4503
ro_en Dev loss: 0.3557 r:0.8223
et_en Dev loss: 0.4540 r:0.6816
si_en Dev loss: 0.7446 r:0.5863
ne_en Dev loss: 0.5351 r:0.7116
ru_en Dev loss: 0.4413 r:0.7411
Current avg r:0.6068 Best avg r: 0.6272
00:56:41,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:11,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:41,524 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2382
en_de Dev loss: 0.8786 r:0.2309
en_zh Dev loss: 0.8212 r:0.4408
ro_en Dev loss: 0.3779 r:0.8168
et_en Dev loss: 0.4856 r:0.6680
si_en Dev loss: 0.9193 r:0.5650
ne_en Dev loss: 0.5999 r:0.7146
ru_en Dev loss: 0.4826 r:0.7222
Current avg r:0.5940 Best avg r: 0.6272
01:04:11,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:41,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:11,570 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2446
en_de Dev loss: 0.8635 r:0.2255
en_zh Dev loss: 0.7522 r:0.4571
ro_en Dev loss: 0.3261 r:0.8244
et_en Dev loss: 0.4404 r:0.6802
si_en Dev loss: 0.7844 r:0.5807
ne_en Dev loss: 0.5091 r:0.7214
ru_en Dev loss: 0.4282 r:0.7383
Current avg r:0.6040 Best avg r: 0.6272
01:11:41,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:11,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:41,628 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2314
en_de Dev loss: 0.8531 r:0.2410
en_zh Dev loss: 0.7535 r:0.4602
ro_en Dev loss: 0.3317 r:0.8201
et_en Dev loss: 0.4942 r:0.6793
si_en Dev loss: 0.7645 r:0.5755
ne_en Dev loss: 0.4776 r:0.7172
ru_en Dev loss: 0.4134 r:0.7387
Current avg r:0.6046 Best avg r: 0.6272
01:19:11,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:20:41,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:22:11,628 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2278
en_de Dev loss: 0.8810 r:0.2262
en_zh Dev loss: 0.7946 r:0.4586
ro_en Dev loss: 0.3544 r:0.8227
et_en Dev loss: 0.4803 r:0.6816
si_en Dev loss: 0.8070 r:0.5771
ne_en Dev loss: 0.4718 r:0.7267
ru_en Dev loss: 0.4432 r:0.7381
Current avg r:0.6044 Best avg r: 0.6272
01:26:41,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:11,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:29:41,472 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2250
en_de Dev loss: 0.8684 r:0.2172
en_zh Dev loss: 0.7946 r:0.4446
ro_en Dev loss: 0.3594 r:0.8160
et_en Dev loss: 0.4760 r:0.6774
si_en Dev loss: 0.8213 r:0.5677
ne_en Dev loss: 0.5397 r:0.7260
ru_en Dev loss: 0.4497 r:0.7272
Current avg r:0.5966 Best avg r: 0.6272
01:34:11,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:41,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:11,374 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2304
en_de Dev loss: 0.8609 r:0.2235
en_zh Dev loss: 0.7736 r:0.4576
ro_en Dev loss: 0.3448 r:0.8212
et_en Dev loss: 0.4786 r:0.6785
si_en Dev loss: 0.7551 r:0.5748
ne_en Dev loss: 0.5464 r:0.7224
ru_en Dev loss: 0.4389 r:0.7240
Current avg r:0.6003 Best avg r: 0.6272
01:41:40,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:11,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:44:41,184 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2326
en_de Dev loss: 0.8562 r:0.2237
en_zh Dev loss: 0.7736 r:0.4350
ro_en Dev loss: 0.3216 r:0.8247
et_en Dev loss: 0.4429 r:0.6790
si_en Dev loss: 0.7793 r:0.5664
ne_en Dev loss: 0.5354 r:0.7148
ru_en Dev loss: 0.4260 r:0.7329
Current avg r:0.5967 Best avg r: 0.6272
01:49:10,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:40,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:10,984 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2302
en_de Dev loss: 0.8648 r:0.2175
en_zh Dev loss: 0.8350 r:0.4341
ro_en Dev loss: 0.3614 r:0.8204
et_en Dev loss: 0.4929 r:0.6707
si_en Dev loss: 0.8620 r:0.5622
ne_en Dev loss: 0.6002 r:0.7136
ru_en Dev loss: 0.4843 r:0.7222
Current avg r:0.5915 Best avg r: 0.6272
01:56:40,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:58:10,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:42,219 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2300
en_de Dev loss: 0.8637 r:0.2298
en_zh Dev loss: 0.7904 r:0.4508
ro_en Dev loss: 0.3409 r:0.8251
et_en Dev loss: 0.4563 r:0.6770
si_en Dev loss: 0.7752 r:0.5675
ne_en Dev loss: 0.5536 r:0.7166
ru_en Dev loss: 0.4334 r:0.7409
Current avg r:0.6011 Best avg r: 0.6272
02:04:16,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:47,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:18,867 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2238
en_de Dev loss: 0.8518 r:0.2384
en_zh Dev loss: 0.7872 r:0.4444
ro_en Dev loss: 0.3511 r:0.8215
et_en Dev loss: 0.4396 r:0.6681
si_en Dev loss: 0.9421 r:0.5518
ne_en Dev loss: 0.6802 r:0.7143
ru_en Dev loss: 0.4807 r:0.7237
Current avg r:0.5946 Best avg r: 0.6272
02:11:54,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:26,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:57,512 root INFO Epoch 6 Global steps: 63700 Train loss: 0.1977
en_de Dev loss: 0.8510 r:0.2348
en_zh Dev loss: 0.7376 r:0.4601
ro_en Dev loss: 0.3162 r:0.8242
et_en Dev loss: 0.4718 r:0.6784
si_en Dev loss: 0.7385 r:0.5667
ne_en Dev loss: 0.4919 r:0.7152
ru_en Dev loss: 0.4113 r:0.7367
Current avg r:0.6023 Best avg r: 0.6272
02:19:31,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:03,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:34,636 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2085
en_de Dev loss: 0.8635 r:0.2351
en_zh Dev loss: 0.7905 r:0.4546
ro_en Dev loss: 0.3346 r:0.8238
et_en Dev loss: 0.4600 r:0.6687
si_en Dev loss: 0.8340 r:0.5575
ne_en Dev loss: 0.5587 r:0.7113
ru_en Dev loss: 0.4351 r:0.7391
Current avg r:0.5986 Best avg r: 0.6272
02:27:09,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:28:40,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:30:11,223 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2105
en_de Dev loss: 0.8566 r:0.2527
en_zh Dev loss: 0.7820 r:0.4624
ro_en Dev loss: 0.3333 r:0.8266
et_en Dev loss: 0.4640 r:0.6718
si_en Dev loss: 0.8640 r:0.5539
ne_en Dev loss: 0.5732 r:0.7068
ru_en Dev loss: 0.4128 r:0.7454
Current avg r:0.6028 Best avg r: 0.6272
02:34:42,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:12,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:37:43,24 root INFO Epoch 6 Global steps: 65800 Train loss: 0.1992
en_de Dev loss: 0.8516 r:0.2487
en_zh Dev loss: 0.7755 r:0.4557
ro_en Dev loss: 0.3516 r:0.8227
et_en Dev loss: 0.4868 r:0.6711
si_en Dev loss: 0.8052 r:0.5634
ne_en Dev loss: 0.5272 r:0.7152
ru_en Dev loss: 0.4512 r:0.7292
Current avg r:0.6009 Best avg r: 0.6272
02:42:13,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:42:26,613 root INFO 
id:en_de cur r: 0.2472 best r: 0.2472
02:43:44,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:14,712 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2048
en_de Dev loss: 0.8450 r:0.2657
en_zh Dev loss: 0.7948 r:0.4493
ro_en Dev loss: 0.3347 r:0.8210
et_en Dev loss: 0.4952 r:0.6802
si_en Dev loss: 0.7918 r:0.5681
ne_en Dev loss: 0.5223 r:0.7162
ru_en Dev loss: 0.4234 r:0.7466
Current avg r:0.6067 Best avg r: 0.6272
02:49:48,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:19,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:50,481 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2116
en_de Dev loss: 0.8418 r:0.2583
en_zh Dev loss: 0.7434 r:0.4662
ro_en Dev loss: 0.3147 r:0.8260
et_en Dev loss: 0.4742 r:0.6793
si_en Dev loss: 0.7496 r:0.5717
ne_en Dev loss: 0.5084 r:0.7136
ru_en Dev loss: 0.4047 r:0.7518
Current avg r:0.6096 Best avg r: 0.6272
02:57:24,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:58:55,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:27,75 root INFO Epoch 6 Global steps: 67900 Train loss: 0.1961
en_de Dev loss: 0.8587 r:0.2484
en_zh Dev loss: 0.7672 r:0.4596
ro_en Dev loss: 0.3409 r:0.8220
et_en Dev loss: 0.4765 r:0.6708
si_en Dev loss: 0.7840 r:0.5652
ne_en Dev loss: 0.5571 r:0.7113
ru_en Dev loss: 0.4690 r:0.7228
Current avg r:0.6000 Best avg r: 0.6272
03:05:00,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:06:32,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:03,349 root INFO Epoch 6 Global steps: 68600 Train loss: 0.1958
en_de Dev loss: 0.8803 r:0.2243
en_zh Dev loss: 0.8030 r:0.4557
ro_en Dev loss: 0.3402 r:0.8227
et_en Dev loss: 0.4847 r:0.6714
si_en Dev loss: 0.8841 r:0.5613
ne_en Dev loss: 0.6686 r:0.7041
ru_en Dev loss: 0.4491 r:0.7345
Current avg r:0.5963 Best avg r: 0.6272
03:12:35,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:06,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:15:36,603 root INFO Epoch 6 Global steps: 69300 Train loss: 0.1953
en_de Dev loss: 0.8780 r:0.2137
en_zh Dev loss: 0.7578 r:0.4534
ro_en Dev loss: 0.3212 r:0.8221
et_en Dev loss: 0.4447 r:0.6692
si_en Dev loss: 0.8266 r:0.5577
ne_en Dev loss: 0.5808 r:0.7106
ru_en Dev loss: 0.4471 r:0.7256
Current avg r:0.5932 Best avg r: 0.6272
03:20:07,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:37,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:08,236 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1846
en_de Dev loss: 0.8686 r:0.2302
en_zh Dev loss: 0.7849 r:0.4553
ro_en Dev loss: 0.3787 r:0.8154
et_en Dev loss: 0.4735 r:0.6675
si_en Dev loss: 1.0168 r:0.5526
ne_en Dev loss: 0.6879 r:0.7096
ru_en Dev loss: 0.4765 r:0.7212
Current avg r:0.5931 Best avg r: 0.6272
03:27:39,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:10,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:41,682 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1932
en_de Dev loss: 0.8860 r:0.2039
en_zh Dev loss: 0.7978 r:0.4546
ro_en Dev loss: 0.3862 r:0.8164
et_en Dev loss: 0.4768 r:0.6626
si_en Dev loss: 0.9805 r:0.5561
ne_en Dev loss: 0.7279 r:0.7034
ru_en Dev loss: 0.4964 r:0.7230
Current avg r:0.5886 Best avg r: 0.6272
03:35:16,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:47,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:18,913 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1856
en_de Dev loss: 0.8896 r:0.2238
en_zh Dev loss: 0.7688 r:0.4657
ro_en Dev loss: 0.3257 r:0.8232
et_en Dev loss: 0.4663 r:0.6821
si_en Dev loss: 0.8413 r:0.5622
ne_en Dev loss: 0.5613 r:0.7042
ru_en Dev loss: 0.4244 r:0.7513
Current avg r:0.6018 Best avg r: 0.6272
03:42:53,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:24,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:56,138 root INFO Epoch 6 Global steps: 72100 Train loss: 0.1946
en_de Dev loss: 0.8726 r:0.2248
en_zh Dev loss: 0.7918 r:0.4541
ro_en Dev loss: 0.3522 r:0.8195
et_en Dev loss: 0.5151 r:0.6727
si_en Dev loss: 0.8684 r:0.5600
ne_en Dev loss: 0.5822 r:0.7112
ru_en Dev loss: 0.4315 r:0.7383
Current avg r:0.5972 Best avg r: 0.6272
03:50:30,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:52:01,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:53:33,123 root INFO Epoch 6 Global steps: 72800 Train loss: 0.1901
en_de Dev loss: 0.9031 r:0.2012
en_zh Dev loss: 0.8895 r:0.4344
ro_en Dev loss: 0.4434 r:0.8102
et_en Dev loss: 0.4989 r:0.6527
si_en Dev loss: 1.1584 r:0.5409
ne_en Dev loss: 0.8559 r:0.6981
ru_en Dev loss: 0.5698 r:0.7061
Current avg r:0.5777 Best avg r: 0.6272
03:58:03,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:59:34,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:01:04,803 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1938
en_de Dev loss: 0.8953 r:0.2053
en_zh Dev loss: 0.7864 r:0.4576
ro_en Dev loss: 0.3469 r:0.8246
et_en Dev loss: 0.4721 r:0.6727
si_en Dev loss: 0.8204 r:0.5648
ne_en Dev loss: 0.5329 r:0.7111
ru_en Dev loss: 0.4697 r:0.7340
Current avg r:0.5957 Best avg r: 0.6272
04:05:37,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:07:07,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:38,822 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1815
en_de Dev loss: 0.8829 r:0.2168
en_zh Dev loss: 0.7744 r:0.4653
ro_en Dev loss: 0.3501 r:0.8193
et_en Dev loss: 0.4920 r:0.6617
si_en Dev loss: 0.8819 r:0.5577
ne_en Dev loss: 0.5868 r:0.7041
ru_en Dev loss: 0.4629 r:0.7262
Current avg r:0.5930 Best avg r: 0.6272
04:13:12,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:43,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:16:15,232 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1764
en_de Dev loss: 0.8938 r:0.2197
en_zh Dev loss: 0.7865 r:0.4664
ro_en Dev loss: 0.3537 r:0.8215
et_en Dev loss: 0.4515 r:0.6733
si_en Dev loss: 0.9350 r:0.5550
ne_en Dev loss: 0.6564 r:0.7062
ru_en Dev loss: 0.4694 r:0.7261
Current avg r:0.5955 Best avg r: 0.6272
04:20:49,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:22:20,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:51,914 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1702
en_de Dev loss: 0.8812 r:0.2196
en_zh Dev loss: 0.7898 r:0.4602
ro_en Dev loss: 0.3502 r:0.8163
et_en Dev loss: 0.4693 r:0.6692
si_en Dev loss: 0.8872 r:0.5504
ne_en Dev loss: 0.6292 r:0.7053
ru_en Dev loss: 0.4627 r:0.7302
Current avg r:0.5930 Best avg r: 0.6272
04:28:25,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:56,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:28,108 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1761
en_de Dev loss: 0.8971 r:0.2136
en_zh Dev loss: 0.7617 r:0.4764
ro_en Dev loss: 0.3337 r:0.8227
et_en Dev loss: 0.4609 r:0.6782
si_en Dev loss: 0.8300 r:0.5589
ne_en Dev loss: 0.5419 r:0.7099
ru_en Dev loss: 0.4187 r:0.7500
Current avg r:0.6014 Best avg r: 0.6272
04:35:58,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:37:29,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:59,928 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1675
en_de Dev loss: 0.9119 r:0.1882
en_zh Dev loss: 0.8509 r:0.4564
ro_en Dev loss: 0.3816 r:0.8165
et_en Dev loss: 0.4716 r:0.6644
si_en Dev loss: 0.9745 r:0.5468
ne_en Dev loss: 0.7137 r:0.7042
ru_en Dev loss: 0.4903 r:0.7316
Current avg r:0.5869 Best avg r: 0.6272
04:43:31,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:45:02,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:46:34,110 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1716
en_de Dev loss: 0.8775 r:0.2136
en_zh Dev loss: 0.7562 r:0.4696
ro_en Dev loss: 0.3297 r:0.8218
et_en Dev loss: 0.4431 r:0.6739
si_en Dev loss: 0.8617 r:0.5549
ne_en Dev loss: 0.5846 r:0.7086
ru_en Dev loss: 0.4318 r:0.7358
Current avg r:0.5969 Best avg r: 0.6272
04:51:08,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:52:39,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:54:11,191 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1720
en_de Dev loss: 0.8931 r:0.1975
en_zh Dev loss: 0.7721 r:0.4697
ro_en Dev loss: 0.3404 r:0.8178
et_en Dev loss: 0.4453 r:0.6650
si_en Dev loss: 0.8843 r:0.5523
ne_en Dev loss: 0.6163 r:0.7082
ru_en Dev loss: 0.4328 r:0.7380
Current avg r:0.5926 Best avg r: 0.6272
04:58:45,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:00:16,815 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:01:48,108 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1638
en_de Dev loss: 0.8907 r:0.1965
en_zh Dev loss: 0.7831 r:0.4576
ro_en Dev loss: 0.3491 r:0.8168
et_en Dev loss: 0.4498 r:0.6677
si_en Dev loss: 0.8365 r:0.5518
ne_en Dev loss: 0.5535 r:0.7048
ru_en Dev loss: 0.4399 r:0.7359
Current avg r:0.5902 Best avg r: 0.6272
05:06:22,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:07:53,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:09:24,664 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1755
en_de Dev loss: 0.8709 r:0.2194
en_zh Dev loss: 0.7434 r:0.4619
ro_en Dev loss: 0.3352 r:0.8174
et_en Dev loss: 0.4854 r:0.6719
si_en Dev loss: 0.7311 r:0.5649
ne_en Dev loss: 0.4944 r:0.7106
ru_en Dev loss: 0.4194 r:0.7351
Current avg r:0.5973 Best avg r: 0.6272
05:13:55,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:15:26,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:16:56,605 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1710
en_de Dev loss: 0.8894 r:0.2069
en_zh Dev loss: 0.7674 r:0.4631
ro_en Dev loss: 0.3314 r:0.8198
et_en Dev loss: 0.4948 r:0.6684
si_en Dev loss: 0.8162 r:0.5556
ne_en Dev loss: 0.5583 r:0.7099
ru_en Dev loss: 0.4295 r:0.7381
Current avg r:0.5945 Best avg r: 0.6272
05:21:29,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:23:00,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:24:32,172 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1688
en_de Dev loss: 0.8834 r:0.2098
en_zh Dev loss: 0.7626 r:0.4590
ro_en Dev loss: 0.3420 r:0.8158
et_en Dev loss: 0.4709 r:0.6619
si_en Dev loss: 0.8351 r:0.5514
ne_en Dev loss: 0.5607 r:0.7086
ru_en Dev loss: 0.4482 r:0.7313
Current avg r:0.5911 Best avg r: 0.6272
05:29:06,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:37,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:32:08,801 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1661
en_de Dev loss: 0.9036 r:0.2021
en_zh Dev loss: 0.8270 r:0.4602
ro_en Dev loss: 0.3871 r:0.8139
et_en Dev loss: 0.4855 r:0.6598
si_en Dev loss: 0.9618 r:0.5416
ne_en Dev loss: 0.6210 r:0.7083
ru_en Dev loss: 0.4634 r:0.7389
Current avg r:0.5893 Best avg r: 0.6272
05:36:42,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:38:13,904 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:39:45,119 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1710
en_de Dev loss: 0.8961 r:0.1945
en_zh Dev loss: 0.7520 r:0.4759
ro_en Dev loss: 0.3375 r:0.8199
et_en Dev loss: 0.4560 r:0.6723
si_en Dev loss: 0.8394 r:0.5541
ne_en Dev loss: 0.5770 r:0.7113
ru_en Dev loss: 0.3966 r:0.7598
Current avg r:0.5983 Best avg r: 0.6272
05:44:17,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:45:48,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:47:19,246 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1713
en_de Dev loss: 0.8993 r:0.2047
en_zh Dev loss: 0.7928 r:0.4723
ro_en Dev loss: 0.3686 r:0.8183
et_en Dev loss: 0.4698 r:0.6698
si_en Dev loss: 0.9733 r:0.5450
ne_en Dev loss: 0.6442 r:0.7094
ru_en Dev loss: 0.4702 r:0.7421
Current avg r:0.5945 Best avg r: 0.6272
05:51:50,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:53:21,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:54:51,603 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1672
en_de Dev loss: 0.9097 r:0.2039
en_zh Dev loss: 0.7899 r:0.4749
ro_en Dev loss: 0.3629 r:0.8239
et_en Dev loss: 0.4502 r:0.6799
si_en Dev loss: 0.8527 r:0.5571
ne_en Dev loss: 0.5567 r:0.7191
ru_en Dev loss: 0.4941 r:0.7367
Current avg r:0.5994 Best avg r: 0.6272
05:59:23,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:00:54,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:02:24,724 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1518
en_de Dev loss: 0.8993 r:0.1969
en_zh Dev loss: 0.7614 r:0.4761
ro_en Dev loss: 0.3276 r:0.8249
et_en Dev loss: 0.4506 r:0.6762
si_en Dev loss: 0.8029 r:0.5589
ne_en Dev loss: 0.5272 r:0.7122
ru_en Dev loss: 0.4526 r:0.7401
Current avg r:0.5979 Best avg r: 0.6272
06:06:55,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:21,27 root INFO 
id:en_zh cur r: 0.4806 best r: 0.4806
06:08:25,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:09:56,388 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1460
en_de Dev loss: 0.8997 r:0.2027
en_zh Dev loss: 0.7839 r:0.4780
ro_en Dev loss: 0.3322 r:0.8224
et_en Dev loss: 0.4758 r:0.6653
si_en Dev loss: 0.8889 r:0.5504
ne_en Dev loss: 0.5890 r:0.7124
ru_en Dev loss: 0.4489 r:0.7433
Current avg r:0.5963 Best avg r: 0.6272
06:14:26,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:15:56,298 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:17:26,480 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1532
en_de Dev loss: 0.8950 r:0.2219
en_zh Dev loss: 0.7967 r:0.4701
ro_en Dev loss: 0.3474 r:0.8202
et_en Dev loss: 0.4837 r:0.6684
si_en Dev loss: 0.9173 r:0.5509
ne_en Dev loss: 0.6293 r:0.7122
ru_en Dev loss: 0.4431 r:0.7485
Current avg r:0.5989 Best avg r: 0.6272
06:21:56,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:22:22,93 root INFO 
id:en_zh cur r: 0.4810 best r: 0.4810
06:23:26,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:56,799 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1542
en_de Dev loss: 0.8784 r:0.2334
en_zh Dev loss: 0.7865 r:0.4721
ro_en Dev loss: 0.3374 r:0.8234
et_en Dev loss: 0.4803 r:0.6629
si_en Dev loss: 0.8852 r:0.5513
ne_en Dev loss: 0.6022 r:0.7091
ru_en Dev loss: 0.4309 r:0.7475
Current avg r:0.5999 Best avg r: 0.6272
06:29:26,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:56,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:27,112 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1492
en_de Dev loss: 0.8988 r:0.2100
en_zh Dev loss: 0.8066 r:0.4692
ro_en Dev loss: 0.3678 r:0.8190
et_en Dev loss: 0.4817 r:0.6542
si_en Dev loss: 0.9759 r:0.5427
ne_en Dev loss: 0.6634 r:0.7113
ru_en Dev loss: 0.4572 r:0.7422
Current avg r:0.5927 Best avg r: 0.6272
06:36:57,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:22,977 root INFO 
id:en_zh cur r: 0.4830 best r: 0.4830
06:38:27,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:57,618 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1498
en_de Dev loss: 0.8947 r:0.2048
en_zh Dev loss: 0.7717 r:0.4766
ro_en Dev loss: 0.3256 r:0.8200
et_en Dev loss: 0.4708 r:0.6626
si_en Dev loss: 0.8169 r:0.5533
ne_en Dev loss: 0.5399 r:0.7096
ru_en Dev loss: 0.4196 r:0.7465
Current avg r:0.5962 Best avg r: 0.6272
06:44:27,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:58,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:47:29,56 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1455
en_de Dev loss: 0.8905 r:0.1943
en_zh Dev loss: 0.7689 r:0.4723
ro_en Dev loss: 0.3424 r:0.8196
et_en Dev loss: 0.4748 r:0.6562
si_en Dev loss: 0.9306 r:0.5389
ne_en Dev loss: 0.6096 r:0.7093
ru_en Dev loss: 0.4421 r:0.7396
Current avg r:0.5900 Best avg r: 0.6272
06:51:59,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:53:30,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:55:00,703 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1486
en_de Dev loss: 0.8778 r:0.2151
en_zh Dev loss: 0.7665 r:0.4723
ro_en Dev loss: 0.3418 r:0.8221
et_en Dev loss: 0.4805 r:0.6557
si_en Dev loss: 0.8688 r:0.5457
ne_en Dev loss: 0.5827 r:0.7080
ru_en Dev loss: 0.4464 r:0.7336
Current avg r:0.5932 Best avg r: 0.6272
06:59:31,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:01:01,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:32,573 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1484
en_de Dev loss: 0.8761 r:0.2176
en_zh Dev loss: 0.7550 r:0.4663
ro_en Dev loss: 0.3272 r:0.8216
et_en Dev loss: 0.4552 r:0.6594
si_en Dev loss: 0.9166 r:0.5389
ne_en Dev loss: 0.5913 r:0.7077
ru_en Dev loss: 0.4531 r:0.7280
Current avg r:0.5914 Best avg r: 0.6272
07:07:03,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:33,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:10:03,387 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1575
en_de Dev loss: 0.8742 r:0.2076
en_zh Dev loss: 0.7530 r:0.4670
ro_en Dev loss: 0.3268 r:0.8217
et_en Dev loss: 0.4485 r:0.6571
si_en Dev loss: 0.8895 r:0.5481
ne_en Dev loss: 0.5996 r:0.7017
ru_en Dev loss: 0.4280 r:0.7356
Current avg r:0.5913 Best avg r: 0.6272
07:14:33,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:14:59,323 root INFO 
id:en_zh cur r: 0.4843 best r: 0.4843
07:16:03,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:33,701 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1441
en_de Dev loss: 0.8977 r:0.2067
en_zh Dev loss: 0.7889 r:0.4781
ro_en Dev loss: 0.3769 r:0.8201
et_en Dev loss: 0.4929 r:0.6472
si_en Dev loss: 1.0136 r:0.5325
ne_en Dev loss: 0.6501 r:0.7008
ru_en Dev loss: 0.4866 r:0.7316
Current avg r:0.5881 Best avg r: 0.6272
07:22:04,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:22:30,257 root INFO 
id:en_zh cur r: 0.4928 best r: 0.4928
07:23:34,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:25:05,246 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1437
en_de Dev loss: 0.8860 r:0.2120
en_zh Dev loss: 0.7460 r:0.4897
ro_en Dev loss: 0.3284 r:0.8252
et_en Dev loss: 0.4664 r:0.6664
si_en Dev loss: 0.9029 r:0.5470
ne_en Dev loss: 0.5667 r:0.7084
ru_en Dev loss: 0.4214 r:0.7510
Current avg r:0.6000 Best avg r: 0.6272
07:29:35,219 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:31:05,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:36,89 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1446
en_de Dev loss: 0.8818 r:0.2130
en_zh Dev loss: 0.7094 r:0.4913
ro_en Dev loss: 0.3054 r:0.8273
et_en Dev loss: 0.4784 r:0.6672
si_en Dev loss: 0.8056 r:0.5475
ne_en Dev loss: 0.5063 r:0.7037
ru_en Dev loss: 0.4169 r:0.7401
Current avg r:0.5986 Best avg r: 0.6272
07:37:06,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:37,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:40:08,76 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1414
en_de Dev loss: 0.9055 r:0.2054
en_zh Dev loss: 0.7537 r:0.4839
ro_en Dev loss: 0.3351 r:0.8246
et_en Dev loss: 0.4590 r:0.6621
si_en Dev loss: 0.8325 r:0.5501
ne_en Dev loss: 0.5355 r:0.7132
ru_en Dev loss: 0.4682 r:0.7346
Current avg r:0.5963 Best avg r: 0.6272
07:44:38,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:45:04,604 root INFO 
id:en_zh cur r: 0.4947 best r: 0.4947
07:46:09,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:47:40,43 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1353
en_de Dev loss: 0.8843 r:0.2102
en_zh Dev loss: 0.7179 r:0.4889
ro_en Dev loss: 0.3196 r:0.8259
et_en Dev loss: 0.4677 r:0.6577
si_en Dev loss: 0.8382 r:0.5468
ne_en Dev loss: 0.5685 r:0.7063
ru_en Dev loss: 0.4386 r:0.7326
Current avg r:0.5955 Best avg r: 0.6272
07:52:12,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:53:43,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:13,247 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1263
en_de Dev loss: 0.8809 r:0.2178
en_zh Dev loss: 0.7606 r:0.4785
ro_en Dev loss: 0.3447 r:0.8211
et_en Dev loss: 0.4852 r:0.6584
si_en Dev loss: 0.8692 r:0.5498
ne_en Dev loss: 0.5626 r:0.7082
ru_en Dev loss: 0.4498 r:0.7338
Current avg r:0.5954 Best avg r: 0.6272
07:59:43,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:00:08,918 root INFO 
id:en_zh cur r: 0.4973 best r: 0.4973
08:01:13,366 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:43,557 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1343
en_de Dev loss: 0.8937 r:0.2228
en_zh Dev loss: 0.7489 r:0.4886
ro_en Dev loss: 0.3388 r:0.8250
et_en Dev loss: 0.4720 r:0.6697
si_en Dev loss: 0.8553 r:0.5593
ne_en Dev loss: 0.5441 r:0.7140
ru_en Dev loss: 0.4277 r:0.7518
Current avg r:0.6045 Best avg r: 0.6272
08:07:13,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:43,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:14,42 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1366
en_de Dev loss: 0.8940 r:0.1974
en_zh Dev loss: 0.7168 r:0.4839
ro_en Dev loss: 0.3100 r:0.8288
et_en Dev loss: 0.4549 r:0.6771
si_en Dev loss: 0.7447 r:0.5613
ne_en Dev loss: 0.5048 r:0.7053
ru_en Dev loss: 0.3972 r:0.7585
Current avg r:0.6018 Best avg r: 0.6272
08:14:43,707 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:16:13,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:17:43,952 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1303
en_de Dev loss: 0.9355 r:0.1857
en_zh Dev loss: 0.7909 r:0.4808
ro_en Dev loss: 0.3314 r:0.8284
et_en Dev loss: 0.4840 r:0.6679
si_en Dev loss: 0.8286 r:0.5527
ne_en Dev loss: 0.5768 r:0.7094
ru_en Dev loss: 0.4202 r:0.7604
Current avg r:0.5979 Best avg r: 0.6272
08:22:13,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:23:44,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:25:14,160 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1281
en_de Dev loss: 0.9062 r:0.1839
en_zh Dev loss: 0.7484 r:0.4835
ro_en Dev loss: 0.3185 r:0.8254
et_en Dev loss: 0.4877 r:0.6728
si_en Dev loss: 0.8053 r:0.5589
ne_en Dev loss: 0.5417 r:0.7087
ru_en Dev loss: 0.3830 r:0.7661
Current avg r:0.5999 Best avg r: 0.6272
08:29:44,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:31:14,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:32:44,332 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1282
en_de Dev loss: 0.8797 r:0.1993
en_zh Dev loss: 0.7003 r:0.4920
ro_en Dev loss: 0.3089 r:0.8248
et_en Dev loss: 0.4503 r:0.6659
si_en Dev loss: 0.8341 r:0.5542
ne_en Dev loss: 0.5509 r:0.7058
ru_en Dev loss: 0.4019 r:0.7529
Current avg r:0.5993 Best avg r: 0.6272
08:37:13,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:37:39,728 root INFO 
id:en_zh cur r: 0.4975 best r: 0.4975
08:38:44,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:40:14,307 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1272
en_de Dev loss: 0.8919 r:0.2280
en_zh Dev loss: 0.7578 r:0.4916
ro_en Dev loss: 0.3419 r:0.8225
et_en Dev loss: 0.5061 r:0.6664
si_en Dev loss: 0.8763 r:0.5536
ne_en Dev loss: 0.5511 r:0.7122
ru_en Dev loss: 0.4188 r:0.7558
Current avg r:0.6043 Best avg r: 0.6272
08:44:44,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:46:14,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:47:44,605 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1228
en_de Dev loss: 0.8833 r:0.2309
en_zh Dev loss: 0.7796 r:0.4784
ro_en Dev loss: 0.3361 r:0.8214
et_en Dev loss: 0.4778 r:0.6566
si_en Dev loss: 0.8852 r:0.5481
ne_en Dev loss: 0.5690 r:0.7123
ru_en Dev loss: 0.4493 r:0.7356
Current avg r:0.5976 Best avg r: 0.6272
08:52:14,483 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:44,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:55:14,784 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1223
en_de Dev loss: 0.9218 r:0.1995
en_zh Dev loss: 0.7545 r:0.4901
ro_en Dev loss: 0.3370 r:0.8258
et_en Dev loss: 0.4739 r:0.6640
si_en Dev loss: 0.8997 r:0.5446
ne_en Dev loss: 0.5310 r:0.7069
ru_en Dev loss: 0.4233 r:0.7541
Current avg r:0.5979 Best avg r: 0.6272
08:59:44,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:14,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:02:45,8 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1290
en_de Dev loss: 0.8879 r:0.2186
en_zh Dev loss: 0.7388 r:0.4829
ro_en Dev loss: 0.3252 r:0.8234
et_en Dev loss: 0.4661 r:0.6642
si_en Dev loss: 0.8806 r:0.5430
ne_en Dev loss: 0.5108 r:0.7125
ru_en Dev loss: 0.4288 r:0.7415
Current avg r:0.5980 Best avg r: 0.6272
09:07:15,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:08:45,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:15,463 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1242
en_de Dev loss: 0.8919 r:0.2076
en_zh Dev loss: 0.7533 r:0.4798
ro_en Dev loss: 0.3328 r:0.8216
et_en Dev loss: 0.4451 r:0.6650
si_en Dev loss: 0.8946 r:0.5315
ne_en Dev loss: 0.6037 r:0.7068
ru_en Dev loss: 0.4261 r:0.7379
Current avg r:0.5929 Best avg r: 0.6272
09:14:45,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:16:15,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:17:45,714 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1288
en_de Dev loss: 0.9214 r:0.2076
en_zh Dev loss: 0.7809 r:0.4815
ro_en Dev loss: 0.3481 r:0.8248
et_en Dev loss: 0.4594 r:0.6710
si_en Dev loss: 0.8753 r:0.5442
ne_en Dev loss: 0.5340 r:0.7120
ru_en Dev loss: 0.4318 r:0.7483
Current avg r:0.5985 Best avg r: 0.6272
09:22:15,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:23:45,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:25:16,19 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1295
en_de Dev loss: 0.9097 r:0.2055
en_zh Dev loss: 0.7899 r:0.4717
ro_en Dev loss: 0.3486 r:0.8226
et_en Dev loss: 0.4642 r:0.6662
si_en Dev loss: 0.9647 r:0.5371
ne_en Dev loss: 0.5941 r:0.7129
ru_en Dev loss: 0.4297 r:0.7505
Current avg r:0.5952 Best avg r: 0.6272
09:29:45,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:31:16,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:32:46,150 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1215
en_de Dev loss: 0.9072 r:0.2132
en_zh Dev loss: 0.7680 r:0.4749
ro_en Dev loss: 0.3322 r:0.8269
et_en Dev loss: 0.4808 r:0.6818
si_en Dev loss: 0.7979 r:0.5523
ne_en Dev loss: 0.4864 r:0.7179
ru_en Dev loss: 0.4139 r:0.7546
Current avg r:0.6031 Best avg r: 0.6272
09:37:16,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:38:46,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:40:16,501 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1218
en_de Dev loss: 0.9065 r:0.1962
en_zh Dev loss: 0.7863 r:0.4706
ro_en Dev loss: 0.3459 r:0.8227
et_en Dev loss: 0.4675 r:0.6593
si_en Dev loss: 0.9337 r:0.5301
ne_en Dev loss: 0.6314 r:0.6991
ru_en Dev loss: 0.4652 r:0.7284
Current avg r:0.5866 Best avg r: 0.6272
09:44:48,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:46:18,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:47:48,406 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1160
en_de Dev loss: 0.9005 r:0.2070
en_zh Dev loss: 0.7744 r:0.4708
ro_en Dev loss: 0.3539 r:0.8204
et_en Dev loss: 0.5029 r:0.6720
si_en Dev loss: 0.8647 r:0.5461
ne_en Dev loss: 0.5606 r:0.7208
ru_en Dev loss: 0.4247 r:0.7468
Current avg r:0.5977 Best avg r: 0.6272
09:52:18,664 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:48,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:55:18,739 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1149
en_de Dev loss: 0.8790 r:0.2233
en_zh Dev loss: 0.7720 r:0.4632
ro_en Dev loss: 0.3301 r:0.8218
et_en Dev loss: 0.4617 r:0.6699
si_en Dev loss: 0.8917 r:0.5358
ne_en Dev loss: 0.5354 r:0.7094
ru_en Dev loss: 0.4297 r:0.7378
Current avg r:0.5945 Best avg r: 0.6272
09:59:48,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:01:18,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:48,969 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1167
en_de Dev loss: 0.9012 r:0.2097
en_zh Dev loss: 0.7973 r:0.4666
ro_en Dev loss: 0.3475 r:0.8218
et_en Dev loss: 0.4395 r:0.6708
si_en Dev loss: 0.8850 r:0.5446
ne_en Dev loss: 0.5764 r:0.7108
ru_en Dev loss: 0.4609 r:0.7377
Current avg r:0.5946 Best avg r: 0.6272
10:07:18,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:49,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:19,235 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1114
en_de Dev loss: 0.9130 r:0.2139
en_zh Dev loss: 0.8169 r:0.4666
ro_en Dev loss: 0.3715 r:0.8196
et_en Dev loss: 0.4597 r:0.6767
si_en Dev loss: 0.9464 r:0.5420
ne_en Dev loss: 0.6012 r:0.7111
ru_en Dev loss: 0.4837 r:0.7324
Current avg r:0.5946 Best avg r: 0.6272
10:14:49,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:19,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:49,495 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1208
en_de Dev loss: 0.9375 r:0.2042
en_zh Dev loss: 0.8561 r:0.4712
ro_en Dev loss: 0.3675 r:0.8234
et_en Dev loss: 0.4472 r:0.6723
si_en Dev loss: 0.9483 r:0.5471
ne_en Dev loss: 0.6032 r:0.7097
ru_en Dev loss: 0.4894 r:0.7398
Current avg r:0.5954 Best avg r: 0.6272
10:22:19,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:23:49,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:25:19,788 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1108
en_de Dev loss: 0.9348 r:0.1994
en_zh Dev loss: 0.8061 r:0.4682
ro_en Dev loss: 0.3375 r:0.8243
et_en Dev loss: 0.4518 r:0.6710
si_en Dev loss: 0.9404 r:0.5405
ne_en Dev loss: 0.6076 r:0.7070
ru_en Dev loss: 0.4533 r:0.7380
Current avg r:0.5926 Best avg r: 0.6272
10:29:49,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:31:19,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:32:50,138 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1173
en_de Dev loss: 0.9173 r:0.2129
en_zh Dev loss: 0.8028 r:0.4685
ro_en Dev loss: 0.3710 r:0.8213
et_en Dev loss: 0.4618 r:0.6697
si_en Dev loss: 0.9498 r:0.5430
ne_en Dev loss: 0.6286 r:0.7132
ru_en Dev loss: 0.4667 r:0.7394
Current avg r:0.5954 Best avg r: 0.6272
10:37:20,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:38:50,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:40:20,468 root INFO Epoch 10 Global steps: 110600 Train loss: 0.1128
en_de Dev loss: 0.9165 r:0.1961
en_zh Dev loss: 0.7964 r:0.4765
ro_en Dev loss: 0.3357 r:0.8243
et_en Dev loss: 0.4556 r:0.6750
si_en Dev loss: 0.8804 r:0.5447
ne_en Dev loss: 0.6014 r:0.7104
ru_en Dev loss: 0.4372 r:0.7443
Current avg r:0.5959 Best avg r: 0.6272
