14:49:27,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:52,804 root INFO 
id:en_zh cur r: 0.2537 best r: 0.2537
14:50:05,672 root INFO 
id:ro_en cur r: 0.3648 best r: 0.3648
14:50:18,561 root INFO 
id:et_en cur r: 0.4093 best r: 0.4093
14:50:31,442 root INFO 
id:si_en cur r: 0.3649 best r: 0.3649
14:50:57,198 root INFO 
id:ne_en cur r: 0.6051 best r: 0.6051
14:51:10,21 root INFO 
id:ru_en cur r: 0.4782 best r: 0.4782
14:51:10,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:39,959 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
14:52:39,965 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:52:39,970 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:52:39,974 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
14:52:39,979 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
14:52:39,984 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:52:39,988 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:52:52,872 root INFO Epoch 0 Global steps: 700 Train loss: 0.8578
en_de Dev loss: 0.8852 r:0.0659
en_zh Dev loss: 0.7802 r:0.2603
ro_en Dev loss: 0.7188 r:0.5561
et_en Dev loss: 0.6183 r:0.4361
si_en Dev loss: 0.7810 r:0.4139
ne_en Dev loss: 0.6534 r:0.5820
ru_en Dev loss: 0.6832 r:0.4978
Current avg r:0.4017 Best avg r: 0.4017
14:57:22,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:47,946 root INFO 
id:en_zh cur r: 0.3220 best r: 0.3220
14:58:00,814 root INFO 
id:ro_en cur r: 0.5582 best r: 0.5582
14:58:13,691 root INFO 
id:et_en cur r: 0.5184 best r: 0.5184
14:58:26,558 root INFO 
id:si_en cur r: 0.4583 best r: 0.4583
14:58:52,295 root INFO 
id:ne_en cur r: 0.6415 best r: 0.6415
14:59:05,117 root INFO 
id:ru_en cur r: 0.5283 best r: 0.5283
14:59:05,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:35,2 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:00:35,10 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:00:35,14 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:00:35,19 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:00:35,24 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:00:35,29 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:00:35,35 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:00:47,894 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8020
en_de Dev loss: 0.8943 r:0.0944
en_zh Dev loss: 0.7435 r:0.3215
ro_en Dev loss: 0.6554 r:0.6380
et_en Dev loss: 0.5074 r:0.5607
si_en Dev loss: 0.8177 r:0.4806
ne_en Dev loss: 0.5519 r:0.6444
ru_en Dev loss: 0.6248 r:0.5783
Current avg r:0.4740 Best avg r: 0.4740
15:05:17,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:55,726 root INFO 
id:ro_en cur r: 0.6469 best r: 0.6469
15:06:08,603 root INFO 
id:et_en cur r: 0.6093 best r: 0.6093
15:06:21,487 root INFO 
id:si_en cur r: 0.5026 best r: 0.5026
15:06:47,174 root INFO 
id:ru_en cur r: 0.6421 best r: 0.6421
15:06:47,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:17,149 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:08:17,155 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:08:17,160 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:08:17,165 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:08:17,170 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:08:17,175 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:08:17,179 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:08:30,46 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7712
en_de Dev loss: 0.8947 r:0.1289
en_zh Dev loss: 0.7437 r:0.3380
ro_en Dev loss: 0.5888 r:0.6604
et_en Dev loss: 0.4496 r:0.6399
si_en Dev loss: 0.7629 r:0.4931
ne_en Dev loss: 0.5158 r:0.6536
ru_en Dev loss: 0.5757 r:0.6866
Current avg r:0.5143 Best avg r: 0.5143
15:12:59,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:12,131 root INFO 
id:en_de cur r: 0.0874 best r: 0.0874
15:13:24,984 root INFO 
id:en_zh cur r: 0.3223 best r: 0.3223
15:13:37,853 root INFO 
id:ro_en cur r: 0.6882 best r: 0.6882
15:13:50,732 root INFO 
id:et_en cur r: 0.6351 best r: 0.6351
15:14:03,613 root INFO 
id:si_en cur r: 0.5164 best r: 0.5164
15:14:29,370 root INFO 
id:ne_en cur r: 0.6660 best r: 0.6660
15:14:42,182 root INFO 
id:ru_en cur r: 0.6926 best r: 0.6926
15:14:42,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:12,89 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:16:12,95 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:16:12,100 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:16:12,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:16:12,109 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:16:12,113 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:16:12,118 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:16:24,985 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6757
en_de Dev loss: 0.9335 r:0.1588
en_zh Dev loss: 0.8168 r:0.3387
ro_en Dev loss: 0.5642 r:0.7020
et_en Dev loss: 0.4467 r:0.6548
si_en Dev loss: 0.8345 r:0.5211
ne_en Dev loss: 0.5016 r:0.6605
ru_en Dev loss: 0.5681 r:0.6978
Current avg r:0.5334 Best avg r: 0.5334
15:20:54,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:21:07,477 root INFO 
id:en_de cur r: 0.1304 best r: 0.1304
15:21:20,322 root INFO 
id:en_zh cur r: 0.3486 best r: 0.3486
15:21:33,198 root INFO 
id:ro_en cur r: 0.6924 best r: 0.6924
15:21:46,89 root INFO 
id:et_en cur r: 0.6615 best r: 0.6615
15:21:58,986 root INFO 
id:si_en cur r: 0.5245 best r: 0.5245
15:22:24,755 root INFO 
id:ne_en cur r: 0.6867 best r: 0.6867
15:22:37,574 root INFO 
id:ru_en cur r: 0.7041 best r: 0.7041
15:22:37,575 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:07,544 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:24:07,549 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:24:07,554 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:24:07,558 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:24:07,562 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:24:07,567 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:24:07,571 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:24:20,449 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6899
en_de Dev loss: 0.8859 r:0.1651
en_zh Dev loss: 0.7403 r:0.3516
ro_en Dev loss: 0.4948 r:0.7085
et_en Dev loss: 0.3963 r:0.6778
si_en Dev loss: 0.6909 r:0.5378
ne_en Dev loss: 0.4480 r:0.6803
ru_en Dev loss: 0.5032 r:0.7091
Current avg r:0.5472 Best avg r: 0.5472
15:28:50,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:03,171 root INFO 
id:en_de cur r: 0.1330 best r: 0.1330
15:29:28,893 root INFO 
id:ro_en cur r: 0.7197 best r: 0.7197
15:29:41,777 root INFO 
id:et_en cur r: 0.6783 best r: 0.6783
15:29:54,660 root INFO 
id:si_en cur r: 0.5483 best r: 0.5483
15:30:20,427 root INFO 
id:ne_en cur r: 0.7045 best r: 0.7045
15:30:33,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:03,205 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:32:03,211 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:32:03,216 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:32:03,221 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:32:03,225 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:32:03,230 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:32:03,234 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:32:16,118 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6115
en_de Dev loss: 0.9290 r:0.1527
en_zh Dev loss: 0.7852 r:0.3417
ro_en Dev loss: 0.4853 r:0.7303
et_en Dev loss: 0.3945 r:0.6900
si_en Dev loss: 0.7142 r:0.5620
ne_en Dev loss: 0.5360 r:0.6972
ru_en Dev loss: 0.5173 r:0.7052
Current avg r:0.5542 Best avg r: 0.5542
15:36:45,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:58,637 root INFO 
id:en_de cur r: 0.1666 best r: 0.1666
15:37:11,476 root INFO 
id:en_zh cur r: 0.3918 best r: 0.3918
15:37:24,345 root INFO 
id:ro_en cur r: 0.7493 best r: 0.7493
15:37:37,227 root INFO 
id:et_en cur r: 0.6903 best r: 0.6903
15:37:50,111 root INFO 
id:si_en cur r: 0.5738 best r: 0.5738
15:38:15,857 root INFO 
id:ne_en cur r: 0.7232 best r: 0.7232
15:38:28,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:58,603 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:39:58,609 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:39:58,615 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:39:58,619 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:39:58,623 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:39:58,629 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:39:58,634 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:40:11,501 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6217
en_de Dev loss: 0.8828 r:0.1736
en_zh Dev loss: 0.7094 r:0.3869
ro_en Dev loss: 0.4109 r:0.7537
et_en Dev loss: 0.3638 r:0.6983
si_en Dev loss: 0.6024 r:0.5823
ne_en Dev loss: 0.4094 r:0.7156
ru_en Dev loss: 0.4797 r:0.7058
Current avg r:0.5737 Best avg r: 0.5737
15:44:41,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:54,107 root INFO 
id:en_de cur r: 0.1932 best r: 0.1932
15:45:06,949 root INFO 
id:en_zh cur r: 0.3957 best r: 0.3957
15:45:19,822 root INFO 
id:ro_en cur r: 0.7647 best r: 0.7647
15:45:32,716 root INFO 
id:et_en cur r: 0.7087 best r: 0.7087
15:45:45,602 root INFO 
id:si_en cur r: 0.5875 best r: 0.5875
15:46:11,360 root INFO 
id:ne_en cur r: 0.7299 best r: 0.7299
15:46:24,185 root INFO 
id:ru_en cur r: 0.7460 best r: 0.7460
15:46:24,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:54,177 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:47:54,182 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:47:54,187 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:47:54,192 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:47:54,196 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:47:54,201 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:47:54,205 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:48:07,79 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5913
en_de Dev loss: 0.8607 r:0.2003
en_zh Dev loss: 0.6952 r:0.3912
ro_en Dev loss: 0.3540 r:0.7700
et_en Dev loss: 0.3518 r:0.7106
si_en Dev loss: 0.5511 r:0.5946
ne_en Dev loss: 0.3988 r:0.7197
ru_en Dev loss: 0.3847 r:0.7463
Current avg r:0.5904 Best avg r: 0.5904
15:52:36,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:02,96 root INFO 
id:en_zh cur r: 0.4062 best r: 0.4062
15:53:14,960 root INFO 
id:ro_en cur r: 0.7788 best r: 0.7788
15:53:40,696 root INFO 
id:si_en cur r: 0.5898 best r: 0.5898
15:54:06,447 root INFO 
id:ne_en cur r: 0.7331 best r: 0.7331
15:54:19,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:49,148 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:55:49,155 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:55:49,163 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:55:49,167 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:55:49,172 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:55:49,177 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:55:49,181 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:56:02,50 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5791
en_de Dev loss: 0.8986 r:0.1899
en_zh Dev loss: 0.7410 r:0.4017
ro_en Dev loss: 0.3975 r:0.7823
et_en Dev loss: 0.3845 r:0.7093
si_en Dev loss: 0.6318 r:0.5961
ne_en Dev loss: 0.5241 r:0.7247
ru_en Dev loss: 0.4570 r:0.7339
Current avg r:0.5911 Best avg r: 0.5911
16:00:31,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:57,219 root INFO 
id:en_zh cur r: 0.4320 best r: 0.4320
16:01:10,81 root INFO 
id:ro_en cur r: 0.7973 best r: 0.7973
16:02:01,578 root INFO 
id:ne_en cur r: 0.7341 best r: 0.7341
16:02:14,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:44,307 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:03:44,313 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:03:44,318 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:03:44,322 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:03:44,327 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:03:44,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:03:44,336 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:03:57,210 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5385
en_de Dev loss: 0.9134 r:0.1870
en_zh Dev loss: 0.7133 r:0.4270
ro_en Dev loss: 0.3801 r:0.7990
et_en Dev loss: 0.3905 r:0.7039
si_en Dev loss: 0.7111 r:0.5858
ne_en Dev loss: 0.5254 r:0.7227
ru_en Dev loss: 0.4547 r:0.7435
Current avg r:0.5955 Best avg r: 0.5955
16:08:26,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:05,253 root INFO 
id:ro_en cur r: 0.7975 best r: 0.7975
16:09:30,995 root INFO 
id:si_en cur r: 0.5989 best r: 0.5989
16:09:56,741 root INFO 
id:ne_en cur r: 0.7387 best r: 0.7387
16:10:09,553 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:39,459 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:11:39,465 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:11:39,470 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:11:39,475 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:11:39,479 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:11:39,483 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:11:39,487 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:11:52,363 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5543
en_de Dev loss: 0.8582 r:0.1897
en_zh Dev loss: 0.6776 r:0.4198
ro_en Dev loss: 0.3269 r:0.7990
et_en Dev loss: 0.3469 r:0.7135
si_en Dev loss: 0.5989 r:0.6013
ne_en Dev loss: 0.4788 r:0.7297
ru_en Dev loss: 0.4344 r:0.7383
Current avg r:0.5988 Best avg r: 0.5988
16:16:21,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:00,377 root INFO 
id:ro_en cur r: 0.8036 best r: 0.8036
16:17:13,255 root INFO 
id:et_en cur r: 0.7111 best r: 0.7111
16:17:51,874 root INFO 
id:ne_en cur r: 0.7423 best r: 0.7423
16:18:04,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:34,551 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5651
en_de Dev loss: 0.8785 r:0.1810
en_zh Dev loss: 0.7494 r:0.4112
ro_en Dev loss: 0.3455 r:0.8033
et_en Dev loss: 0.3740 r:0.7140
si_en Dev loss: 0.8269 r:0.5932
ne_en Dev loss: 0.6073 r:0.7300
ru_en Dev loss: 0.4645 r:0.7269
Current avg r:0.5942 Best avg r: 0.5988
16:24:03,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:55,415 root INFO 
id:et_en cur r: 0.7246 best r: 0.7246
16:25:08,285 root INFO 
id:si_en cur r: 0.6058 best r: 0.6058
16:25:34,41 root INFO 
id:ne_en cur r: 0.7492 best r: 0.7492
16:25:46,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:16,747 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5378
en_de Dev loss: 0.9097 r:0.1892
en_zh Dev loss: 0.7552 r:0.4102
ro_en Dev loss: 0.3926 r:0.7941
et_en Dev loss: 0.3645 r:0.7186
si_en Dev loss: 0.6729 r:0.6012
ne_en Dev loss: 0.4809 r:0.7409
ru_en Dev loss: 0.4631 r:0.7329
Current avg r:0.5982 Best avg r: 0.5988
16:31:46,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:59,34 root INFO 
id:en_de cur r: 0.1984 best r: 0.1984
16:32:24,739 root INFO 
id:ro_en cur r: 0.8043 best r: 0.8043
16:33:16,218 root INFO 
id:ne_en cur r: 0.7517 best r: 0.7517
16:33:29,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:58,943 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:34:58,949 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:34:58,954 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:34:58,959 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:34:58,963 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:34:58,968 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:34:58,973 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:35:11,841 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5241
en_de Dev loss: 0.8596 r:0.1978
en_zh Dev loss: 0.7115 r:0.4251
ro_en Dev loss: 0.3367 r:0.8029
et_en Dev loss: 0.3430 r:0.7208
si_en Dev loss: 0.7445 r:0.5904
ne_en Dev loss: 0.4226 r:0.7484
ru_en Dev loss: 0.3893 r:0.7512
Current avg r:0.6052 Best avg r: 0.6052
16:39:41,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:11,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:41,595 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5233
en_de Dev loss: 0.8707 r:0.1888
en_zh Dev loss: 0.6993 r:0.4190
ro_en Dev loss: 0.3356 r:0.7964
et_en Dev loss: 0.3481 r:0.7143
si_en Dev loss: 0.5560 r:0.5969
ne_en Dev loss: 0.4293 r:0.7421
ru_en Dev loss: 0.4362 r:0.7227
Current avg r:0.5972 Best avg r: 0.6052
16:47:12,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:38,598 root INFO 
id:en_zh cur r: 0.4415 best r: 0.4415
16:47:51,458 root INFO 
id:ro_en cur r: 0.8059 best r: 0.8059
16:48:42,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:12,772 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4979
en_de Dev loss: 0.8611 r:0.1864
en_zh Dev loss: 0.6835 r:0.4355
ro_en Dev loss: 0.3230 r:0.8054
et_en Dev loss: 0.3496 r:0.7160
si_en Dev loss: 0.6671 r:0.5920
ne_en Dev loss: 0.4691 r:0.7469
ru_en Dev loss: 0.4201 r:0.7283
Current avg r:0.6015 Best avg r: 0.6052
16:54:42,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:20,911 root INFO 
id:ro_en cur r: 0.8162 best r: 0.8162
16:56:12,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:42,235 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4699
en_de Dev loss: 0.8640 r:0.1830
en_zh Dev loss: 0.7075 r:0.4243
ro_en Dev loss: 0.3039 r:0.8125
et_en Dev loss: 0.3443 r:0.7202
si_en Dev loss: 0.6400 r:0.5866
ne_en Dev loss: 0.3918 r:0.7486
ru_en Dev loss: 0.4413 r:0.7265
Current avg r:0.6003 Best avg r: 0.6052
17:02:11,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:24,646 root INFO 
id:en_de cur r: 0.2090 best r: 0.2090
17:02:37,483 root INFO 
id:en_zh cur r: 0.4537 best r: 0.4537
17:02:50,349 root INFO 
id:ro_en cur r: 0.8185 best r: 0.8185
17:03:03,227 root INFO 
id:et_en cur r: 0.7280 best r: 0.7280
17:03:41,868 root INFO 
id:ne_en cur r: 0.7530 best r: 0.7530
17:03:54,688 root INFO 
id:ru_en cur r: 0.7568 best r: 0.7568
17:03:54,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:24,602 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
17:05:24,608 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:05:24,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:05:24,620 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
17:05:24,625 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
17:05:24,630 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:05:24,635 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:05:37,505 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4771
en_de Dev loss: 0.8505 r:0.2078
en_zh Dev loss: 0.6806 r:0.4497
ro_en Dev loss: 0.3026 r:0.8187
et_en Dev loss: 0.3427 r:0.7258
si_en Dev loss: 0.6814 r:0.6005
ne_en Dev loss: 0.3753 r:0.7529
ru_en Dev loss: 0.3669 r:0.7609
Current avg r:0.6166 Best avg r: 0.6166
17:10:07,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:37,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:07,26 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5010
en_de Dev loss: 0.8831 r:0.1897
en_zh Dev loss: 0.7463 r:0.4372
ro_en Dev loss: 0.3365 r:0.8184
et_en Dev loss: 0.3577 r:0.7156
si_en Dev loss: 0.8321 r:0.5881
ne_en Dev loss: 0.4731 r:0.7501
ru_en Dev loss: 0.4534 r:0.7380
Current avg r:0.6053 Best avg r: 0.6166
17:17:36,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:06,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:36,328 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4920
en_de Dev loss: 0.8527 r:0.1982
en_zh Dev loss: 0.6756 r:0.4443
ro_en Dev loss: 0.3010 r:0.8173
et_en Dev loss: 0.3595 r:0.7144
si_en Dev loss: 0.6322 r:0.5943
ne_en Dev loss: 0.4458 r:0.7505
ru_en Dev loss: 0.4006 r:0.7389
Current avg r:0.6083 Best avg r: 0.6166
17:25:05,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:44,462 root INFO 
id:ro_en cur r: 0.8195 best r: 0.8195
17:26:10,206 root INFO 
id:si_en cur r: 0.6083 best r: 0.6083
17:26:35,957 root INFO 
id:ne_en cur r: 0.7582 best r: 0.7582
17:26:48,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:18,679 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4706
en_de Dev loss: 0.8615 r:0.1874
en_zh Dev loss: 0.6890 r:0.4342
ro_en Dev loss: 0.2989 r:0.8209
et_en Dev loss: 0.3596 r:0.7169
si_en Dev loss: 0.5990 r:0.6066
ne_en Dev loss: 0.3895 r:0.7583
ru_en Dev loss: 0.4219 r:0.7273
Current avg r:0.6074 Best avg r: 0.6166
17:32:48,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:13,929 root INFO 
id:en_zh cur r: 0.4644 best r: 0.4644
17:33:52,536 root INFO 
id:si_en cur r: 0.6128 best r: 0.6128
17:34:18,279 root INFO 
id:ne_en cur r: 0.7613 best r: 0.7613
17:34:31,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:01,5 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5104
en_de Dev loss: 0.8661 r:0.1798
en_zh Dev loss: 0.6868 r:0.4511
ro_en Dev loss: 0.3111 r:0.8217
et_en Dev loss: 0.3654 r:0.7164
si_en Dev loss: 0.6054 r:0.6128
ne_en Dev loss: 0.3875 r:0.7622
ru_en Dev loss: 0.3795 r:0.7552
Current avg r:0.6142 Best avg r: 0.6166
17:40:30,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:09,389 root INFO 
id:ro_en cur r: 0.8239 best r: 0.8239
17:41:22,287 root INFO 
id:et_en cur r: 0.7284 best r: 0.7284
17:42:00,907 root INFO 
id:ne_en cur r: 0.7645 best r: 0.7645
17:42:13,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:43,605 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
17:43:43,611 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:43:43,616 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:43:43,622 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
17:43:43,626 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
17:43:43,631 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:43:43,637 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:43:56,507 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4690
en_de Dev loss: 0.8579 r:0.1951
en_zh Dev loss: 0.6697 r:0.4458
ro_en Dev loss: 0.2927 r:0.8239
et_en Dev loss: 0.3653 r:0.7290
si_en Dev loss: 0.5413 r:0.6094
ne_en Dev loss: 0.3561 r:0.7645
ru_en Dev loss: 0.3679 r:0.7537
Current avg r:0.6173 Best avg r: 0.6173
17:48:26,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:38,907 root INFO 
id:en_de cur r: 0.2169 best r: 0.2169
17:49:17,486 root INFO 
id:et_en cur r: 0.7295 best r: 0.7295
17:49:30,365 root INFO 
id:si_en cur r: 0.6143 best r: 0.6143
17:49:56,129 root INFO 
id:ne_en cur r: 0.7714 best r: 0.7714
17:50:08,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:38,850 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4852
en_de Dev loss: 0.8589 r:0.1985
en_zh Dev loss: 0.7404 r:0.4305
ro_en Dev loss: 0.3016 r:0.8172
et_en Dev loss: 0.3452 r:0.7257
si_en Dev loss: 0.6015 r:0.6151
ne_en Dev loss: 0.3887 r:0.7692
ru_en Dev loss: 0.3969 r:0.7491
Current avg r:0.6150 Best avg r: 0.6173
17:56:08,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:38,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:08,239 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4626
en_de Dev loss: 0.8839 r:0.1946
en_zh Dev loss: 0.7614 r:0.4264
ro_en Dev loss: 0.3528 r:0.8113
et_en Dev loss: 0.3707 r:0.7095
si_en Dev loss: 0.7077 r:0.6006
ne_en Dev loss: 0.5035 r:0.7559
ru_en Dev loss: 0.4876 r:0.7148
Current avg r:0.6019 Best avg r: 0.6173
18:03:37,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:50,617 root INFO 
id:en_de cur r: 0.2245 best r: 0.2245
18:05:07,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:37,651 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4524
en_de Dev loss: 0.8584 r:0.2116
en_zh Dev loss: 0.7280 r:0.4490
ro_en Dev loss: 0.3425 r:0.8205
et_en Dev loss: 0.3747 r:0.7154
si_en Dev loss: 0.7876 r:0.6008
ne_en Dev loss: 0.5376 r:0.7535
ru_en Dev loss: 0.4821 r:0.7276
Current avg r:0.6112 Best avg r: 0.6173
18:11:07,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:20,131 root INFO 
id:en_de cur r: 0.2300 best r: 0.2300
18:12:37,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:07,156 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4745
en_de Dev loss: 0.8457 r:0.2186
en_zh Dev loss: 0.6950 r:0.4439
ro_en Dev loss: 0.3033 r:0.8197
et_en Dev loss: 0.3442 r:0.7233
si_en Dev loss: 0.6481 r:0.6049
ne_en Dev loss: 0.4444 r:0.7583
ru_en Dev loss: 0.4267 r:0.7326
Current avg r:0.6145 Best avg r: 0.6173
18:18:36,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:49,669 root INFO 
id:en_de cur r: 0.2382 best r: 0.2382
18:19:02,502 root INFO 
id:en_zh cur r: 0.4717 best r: 0.4717
18:19:15,378 root INFO 
id:ro_en cur r: 0.8279 best r: 0.8279
18:19:28,250 root INFO 
id:et_en cur r: 0.7340 best r: 0.7340
18:19:41,126 root INFO 
id:si_en cur r: 0.6170 best r: 0.6170
18:20:06,815 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:36,727 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
18:21:36,734 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
18:21:36,739 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
18:21:36,744 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
18:21:36,750 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
18:21:36,755 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
18:21:36,759 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
18:21:49,630 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4739
en_de Dev loss: 0.8433 r:0.2282
en_zh Dev loss: 0.6865 r:0.4597
ro_en Dev loss: 0.3140 r:0.8279
et_en Dev loss: 0.3347 r:0.7316
si_en Dev loss: 0.6474 r:0.6145
ne_en Dev loss: 0.4039 r:0.7622
ru_en Dev loss: 0.4338 r:0.7337
Current avg r:0.6225 Best avg r: 0.6225
18:26:19,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:32,92 root INFO 
id:en_de cur r: 0.2448 best r: 0.2448
18:26:44,935 root INFO 
id:en_zh cur r: 0.4721 best r: 0.4721
18:26:57,797 root INFO 
id:ro_en cur r: 0.8308 best r: 0.8308
18:27:49,226 root INFO 
id:ru_en cur r: 0.7761 best r: 0.7761
18:27:49,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:19,121 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_de.lang_agnost_mlp.dev.best.scores
18:29:19,128 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/en_zh.lang_agnost_mlp.dev.best.scores
18:29:19,132 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ro_en.lang_agnost_mlp.dev.best.scores
18:29:19,137 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/et_en.lang_agnost_mlp.dev.best.scores
18:29:19,142 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/si_en.lang_agnost_mlp.dev.best.scores
18:29:19,147 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ne_en.lang_agnost_mlp.dev.best.scores
18:29:19,153 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run3/ru_en.lang_agnost_mlp.dev.best.scores
18:29:32,37 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4625
en_de Dev loss: 0.8356 r:0.2449
en_zh Dev loss: 0.6860 r:0.4635
ro_en Dev loss: 0.2948 r:0.8289
et_en Dev loss: 0.3776 r:0.7285
si_en Dev loss: 0.5346 r:0.6218
ne_en Dev loss: 0.3412 r:0.7694
ru_en Dev loss: 0.3370 r:0.7744
Current avg r:0.6331 Best avg r: 0.6331
18:34:01,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:14,420 root INFO 
id:en_de cur r: 0.2758 best r: 0.2758
18:35:31,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:01,397 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4542
en_de Dev loss: 0.8494 r:0.2322
en_zh Dev loss: 0.7329 r:0.4340
ro_en Dev loss: 0.3121 r:0.8215
et_en Dev loss: 0.3512 r:0.7200
si_en Dev loss: 0.6091 r:0.6101
ne_en Dev loss: 0.4109 r:0.7583
ru_en Dev loss: 0.4251 r:0.7395
Current avg r:0.6165 Best avg r: 0.6331
18:41:32,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:02,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:32,320 root INFO Epoch 2 Global steps: 21700 Train loss: 0.3923
en_de Dev loss: 0.8697 r:0.2473
en_zh Dev loss: 0.7290 r:0.4407
ro_en Dev loss: 0.3311 r:0.8140
et_en Dev loss: 0.3748 r:0.7121
si_en Dev loss: 0.6993 r:0.6013
ne_en Dev loss: 0.4256 r:0.7619
ru_en Dev loss: 0.4006 r:0.7531
Current avg r:0.6186 Best avg r: 0.6331
18:49:01,957 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:31,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:01,894 root INFO Epoch 2 Global steps: 22400 Train loss: 0.3989
en_de Dev loss: 0.8552 r:0.2252
en_zh Dev loss: 0.7387 r:0.4356
ro_en Dev loss: 0.3310 r:0.8133
et_en Dev loss: 0.3840 r:0.7014
si_en Dev loss: 0.7684 r:0.5949
ne_en Dev loss: 0.5190 r:0.7442
ru_en Dev loss: 0.4709 r:0.7221
Current avg r:0.6052 Best avg r: 0.6331
18:56:31,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:57,220 root INFO 
id:en_zh cur r: 0.4749 best r: 0.4749
18:58:01,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:31,324 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4428
en_de Dev loss: 0.8493 r:0.2211
en_zh Dev loss: 0.6892 r:0.4604
ro_en Dev loss: 0.3099 r:0.8248
et_en Dev loss: 0.3539 r:0.7200
si_en Dev loss: 0.7065 r:0.6057
ne_en Dev loss: 0.4218 r:0.7594
ru_en Dev loss: 0.4039 r:0.7503
Current avg r:0.6202 Best avg r: 0.6331
19:04:00,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:30,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:00,868 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4153
en_de Dev loss: 0.8697 r:0.2002
en_zh Dev loss: 0.7237 r:0.4573
ro_en Dev loss: 0.3296 r:0.8229
et_en Dev loss: 0.3664 r:0.7126
si_en Dev loss: 0.8444 r:0.5889
ne_en Dev loss: 0.4701 r:0.7571
ru_en Dev loss: 0.4150 r:0.7462
Current avg r:0.6122 Best avg r: 0.6331
19:11:30,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:56,224 root INFO 
id:en_zh cur r: 0.4819 best r: 0.4819
19:13:00,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:30,411 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4268
en_de Dev loss: 0.8698 r:0.2009
en_zh Dev loss: 0.6703 r:0.4722
ro_en Dev loss: 0.2912 r:0.8278
et_en Dev loss: 0.3810 r:0.7190
si_en Dev loss: 0.6091 r:0.6010
ne_en Dev loss: 0.3728 r:0.7603
ru_en Dev loss: 0.3643 r:0.7576
Current avg r:0.6198 Best avg r: 0.6331
19:18:59,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:29,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:59,855 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4095
en_de Dev loss: 0.8508 r:0.2125
en_zh Dev loss: 0.6967 r:0.4583
ro_en Dev loss: 0.2951 r:0.8227
et_en Dev loss: 0.3590 r:0.7154
si_en Dev loss: 0.6551 r:0.5895
ne_en Dev loss: 0.4785 r:0.7467
ru_en Dev loss: 0.4346 r:0.7290
Current avg r:0.6106 Best avg r: 0.6331
19:26:29,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:59,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:29,437 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4080
en_de Dev loss: 0.8472 r:0.2244
en_zh Dev loss: 0.6734 r:0.4674
ro_en Dev loss: 0.2985 r:0.8259
et_en Dev loss: 0.3905 r:0.7139
si_en Dev loss: 0.6157 r:0.6046
ne_en Dev loss: 0.4035 r:0.7495
ru_en Dev loss: 0.4003 r:0.7406
Current avg r:0.6181 Best avg r: 0.6331
19:33:59,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:24,828 root INFO 
id:en_zh cur r: 0.4861 best r: 0.4861
19:35:29,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:59,14 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4111
en_de Dev loss: 0.8625 r:0.2053
en_zh Dev loss: 0.6771 r:0.4749
ro_en Dev loss: 0.3162 r:0.8245
et_en Dev loss: 0.3643 r:0.7147
si_en Dev loss: 0.7357 r:0.5914
ne_en Dev loss: 0.4639 r:0.7437
ru_en Dev loss: 0.4441 r:0.7303
Current avg r:0.6121 Best avg r: 0.6331
19:41:28,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:58,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:28,525 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4167
en_de Dev loss: 0.8468 r:0.2251
en_zh Dev loss: 0.6673 r:0.4698
ro_en Dev loss: 0.2797 r:0.8292
et_en Dev loss: 0.3742 r:0.7137
si_en Dev loss: 0.6162 r:0.5991
ne_en Dev loss: 0.4243 r:0.7422
ru_en Dev loss: 0.3918 r:0.7439
Current avg r:0.6176 Best avg r: 0.6331
19:48:57,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:27,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:57,779 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4016
en_de Dev loss: 0.8433 r:0.2340
en_zh Dev loss: 0.6756 r:0.4797
ro_en Dev loss: 0.2929 r:0.8271
et_en Dev loss: 0.3815 r:0.7121
si_en Dev loss: 0.6758 r:0.5933
ne_en Dev loss: 0.4384 r:0.7456
ru_en Dev loss: 0.3809 r:0.7594
Current avg r:0.6216 Best avg r: 0.6331
19:56:27,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:57,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:27,159 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4227
en_de Dev loss: 0.8570 r:0.2227
en_zh Dev loss: 0.7397 r:0.4549
ro_en Dev loss: 0.3483 r:0.8188
et_en Dev loss: 0.3923 r:0.6982
si_en Dev loss: 0.7608 r:0.5810
ne_en Dev loss: 0.5420 r:0.7438
ru_en Dev loss: 0.4637 r:0.7268
Current avg r:0.6066 Best avg r: 0.6331
20:03:56,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:26,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:56,748 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3774
en_de Dev loss: 0.8607 r:0.2162
en_zh Dev loss: 0.7339 r:0.4531
ro_en Dev loss: 0.3105 r:0.8229
et_en Dev loss: 0.3874 r:0.7072
si_en Dev loss: 0.6683 r:0.5942
ne_en Dev loss: 0.4885 r:0.7444
ru_en Dev loss: 0.4432 r:0.7221
Current avg r:0.6086 Best avg r: 0.6331
20:11:26,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:56,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:26,319 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3995
en_de Dev loss: 0.8823 r:0.1882
en_zh Dev loss: 0.7755 r:0.4435
ro_en Dev loss: 0.3164 r:0.8247
et_en Dev loss: 0.3815 r:0.7085
si_en Dev loss: 0.7487 r:0.5955
ne_en Dev loss: 0.4719 r:0.7479
ru_en Dev loss: 0.4276 r:0.7420
Current avg r:0.6072 Best avg r: 0.6331
20:18:56,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:26,139 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:56,69 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3900
en_de Dev loss: 0.8594 r:0.1978
en_zh Dev loss: 0.7337 r:0.4378
ro_en Dev loss: 0.3264 r:0.8235
et_en Dev loss: 0.3838 r:0.7084
si_en Dev loss: 0.6833 r:0.5947
ne_en Dev loss: 0.4998 r:0.7384
ru_en Dev loss: 0.4108 r:0.7418
Current avg r:0.6061 Best avg r: 0.6331
20:26:25,655 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:55,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:25,505 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3886
en_de Dev loss: 0.8584 r:0.1962
en_zh Dev loss: 0.7113 r:0.4497
ro_en Dev loss: 0.3067 r:0.8261
et_en Dev loss: 0.3688 r:0.7110
si_en Dev loss: 0.6614 r:0.6005
ne_en Dev loss: 0.4837 r:0.7389
ru_en Dev loss: 0.4181 r:0.7417
Current avg r:0.6092 Best avg r: 0.6331
20:33:56,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:35,238 root INFO 
id:ro_en cur r: 0.8309 best r: 0.8309
20:35:26,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:56,578 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3548
en_de Dev loss: 0.8494 r:0.2229
en_zh Dev loss: 0.7063 r:0.4684
ro_en Dev loss: 0.3010 r:0.8282
et_en Dev loss: 0.3964 r:0.7114
si_en Dev loss: 0.6520 r:0.6000
ne_en Dev loss: 0.4665 r:0.7329
ru_en Dev loss: 0.3991 r:0.7492
Current avg r:0.6161 Best avg r: 0.6331
20:41:26,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:56,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:26,69 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3404
en_de Dev loss: 0.8700 r:0.2064
en_zh Dev loss: 0.7208 r:0.4689
ro_en Dev loss: 0.3110 r:0.8239
et_en Dev loss: 0.3965 r:0.7012
si_en Dev loss: 0.7015 r:0.5955
ne_en Dev loss: 0.4770 r:0.7343
ru_en Dev loss: 0.4090 r:0.7433
Current avg r:0.6105 Best avg r: 0.6331
20:48:55,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:25,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:55,965 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3698
en_de Dev loss: 0.8728 r:0.1996
en_zh Dev loss: 0.7344 r:0.4474
ro_en Dev loss: 0.3196 r:0.8180
et_en Dev loss: 0.3917 r:0.6960
si_en Dev loss: 0.7212 r:0.5882
ne_en Dev loss: 0.5151 r:0.7315
ru_en Dev loss: 0.4321 r:0.7228
Current avg r:0.6005 Best avg r: 0.6331
20:56:25,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:55,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:25,835 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3297
en_de Dev loss: 0.8800 r:0.1949
en_zh Dev loss: 0.8099 r:0.4251
ro_en Dev loss: 0.3680 r:0.8135
et_en Dev loss: 0.4253 r:0.6844
si_en Dev loss: 0.8194 r:0.5710
ne_en Dev loss: 0.6369 r:0.7247
ru_en Dev loss: 0.4806 r:0.7147
Current avg r:0.5898 Best avg r: 0.6331
21:03:55,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:25,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:55,442 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3556
en_de Dev loss: 0.8938 r:0.1766
en_zh Dev loss: 0.7812 r:0.4295
ro_en Dev loss: 0.3489 r:0.8149
et_en Dev loss: 0.4095 r:0.6820
si_en Dev loss: 0.7931 r:0.5659
ne_en Dev loss: 0.5530 r:0.7251
ru_en Dev loss: 0.4649 r:0.7163
Current avg r:0.5872 Best avg r: 0.6331
21:11:25,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:55,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:25,346 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3357
en_de Dev loss: 0.8692 r:0.1894
en_zh Dev loss: 0.7694 r:0.4374
ro_en Dev loss: 0.3283 r:0.8245
et_en Dev loss: 0.4123 r:0.6972
si_en Dev loss: 0.7088 r:0.5832
ne_en Dev loss: 0.4776 r:0.7315
ru_en Dev loss: 0.4526 r:0.7198
Current avg r:0.5976 Best avg r: 0.6331
21:18:55,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:25,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:55,377 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3301
en_de Dev loss: 0.8643 r:0.2080
en_zh Dev loss: 0.7891 r:0.4261
ro_en Dev loss: 0.3555 r:0.8171
et_en Dev loss: 0.4505 r:0.6927
si_en Dev loss: 0.6820 r:0.5794
ne_en Dev loss: 0.5024 r:0.7303
ru_en Dev loss: 0.4984 r:0.6939
Current avg r:0.5925 Best avg r: 0.6331
21:26:25,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:55,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:25,36 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3395
en_de Dev loss: 0.8571 r:0.2096
en_zh Dev loss: 0.7464 r:0.4586
ro_en Dev loss: 0.3234 r:0.8237
et_en Dev loss: 0.4108 r:0.7097
si_en Dev loss: 0.7108 r:0.5883
ne_en Dev loss: 0.4456 r:0.7379
ru_en Dev loss: 0.4215 r:0.7417
Current avg r:0.6099 Best avg r: 0.6331
21:33:54,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:24,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:54,589 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3351
en_de Dev loss: 0.8569 r:0.2057
en_zh Dev loss: 0.7654 r:0.4422
ro_en Dev loss: 0.3272 r:0.8189
et_en Dev loss: 0.3982 r:0.6980
si_en Dev loss: 0.7679 r:0.5739
ne_en Dev loss: 0.5304 r:0.7288
ru_en Dev loss: 0.4403 r:0.7280
Current avg r:0.5993 Best avg r: 0.6331
21:41:24,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:54,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:24,9 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3388
en_de Dev loss: 0.8424 r:0.2274
en_zh Dev loss: 0.7403 r:0.4423
ro_en Dev loss: 0.3168 r:0.8222
et_en Dev loss: 0.3819 r:0.6985
si_en Dev loss: 0.7486 r:0.5787
ne_en Dev loss: 0.5180 r:0.7334
ru_en Dev loss: 0.4150 r:0.7361
Current avg r:0.6055 Best avg r: 0.6331
21:48:53,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:23,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:53,501 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3102
en_de Dev loss: 0.8424 r:0.2352
en_zh Dev loss: 0.7494 r:0.4593
ro_en Dev loss: 0.3264 r:0.8185
et_en Dev loss: 0.4120 r:0.6996
si_en Dev loss: 0.6898 r:0.5861
ne_en Dev loss: 0.4836 r:0.7334
ru_en Dev loss: 0.4083 r:0.7369
Current avg r:0.6099 Best avg r: 0.6331
21:56:23,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:53,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:22,988 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3249
en_de Dev loss: 0.8497 r:0.2248
en_zh Dev loss: 0.7323 r:0.4394
ro_en Dev loss: 0.3113 r:0.8224
et_en Dev loss: 0.3927 r:0.6973
si_en Dev loss: 0.6684 r:0.5902
ne_en Dev loss: 0.4483 r:0.7332
ru_en Dev loss: 0.4013 r:0.7378
Current avg r:0.6064 Best avg r: 0.6331
22:03:52,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:22,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:52,397 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3201
en_de Dev loss: 0.8509 r:0.2292
en_zh Dev loss: 0.7713 r:0.4289
ro_en Dev loss: 0.3369 r:0.8156
et_en Dev loss: 0.4116 r:0.6828
si_en Dev loss: 0.8893 r:0.5762
ne_en Dev loss: 0.5810 r:0.7207
ru_en Dev loss: 0.4199 r:0.7320
Current avg r:0.5979 Best avg r: 0.6331
22:11:21,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:51,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:21,878 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3313
en_de Dev loss: 0.8478 r:0.2353
en_zh Dev loss: 0.7546 r:0.4256
ro_en Dev loss: 0.3242 r:0.8197
et_en Dev loss: 0.4038 r:0.6878
si_en Dev loss: 0.7677 r:0.5835
ne_en Dev loss: 0.5148 r:0.7227
ru_en Dev loss: 0.4350 r:0.7234
Current avg r:0.5997 Best avg r: 0.6331
22:18:51,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:21,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:21:51,317 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3174
en_de Dev loss: 0.8403 r:0.2570
en_zh Dev loss: 0.7626 r:0.4396
ro_en Dev loss: 0.3093 r:0.8266
et_en Dev loss: 0.4261 r:0.7020
si_en Dev loss: 0.6577 r:0.5967
ne_en Dev loss: 0.4495 r:0.7284
ru_en Dev loss: 0.3679 r:0.7675
Current avg r:0.6168 Best avg r: 0.6331
22:26:22,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:27:52,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:22,370 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2770
en_de Dev loss: 0.8422 r:0.2547
en_zh Dev loss: 0.8000 r:0.4198
ro_en Dev loss: 0.3519 r:0.8162
et_en Dev loss: 0.4538 r:0.6844
si_en Dev loss: 0.7388 r:0.5772
ne_en Dev loss: 0.5313 r:0.7162
ru_en Dev loss: 0.4324 r:0.7355
Current avg r:0.6006 Best avg r: 0.6331
22:33:52,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:22,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:52,20 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2996
en_de Dev loss: 0.8802 r:0.2224
en_zh Dev loss: 0.8065 r:0.4335
ro_en Dev loss: 0.3652 r:0.8200
et_en Dev loss: 0.4359 r:0.6765
si_en Dev loss: 0.8034 r:0.5815
ne_en Dev loss: 0.5642 r:0.7158
ru_en Dev loss: 0.4800 r:0.7186
Current avg r:0.5955 Best avg r: 0.6331
22:41:21,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:51,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:21,731 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2760
en_de Dev loss: 0.8527 r:0.2172
en_zh Dev loss: 0.7639 r:0.4172
ro_en Dev loss: 0.3151 r:0.8228
et_en Dev loss: 0.4084 r:0.6834
si_en Dev loss: 0.7877 r:0.5695
ne_en Dev loss: 0.5888 r:0.7199
ru_en Dev loss: 0.4048 r:0.7400
Current avg r:0.5957 Best avg r: 0.6331
22:48:51,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:21,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:51,266 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2850
en_de Dev loss: 0.8572 r:0.2172
en_zh Dev loss: 0.7831 r:0.4242
ro_en Dev loss: 0.3283 r:0.8216
et_en Dev loss: 0.4272 r:0.6829
si_en Dev loss: 0.8235 r:0.5690
ne_en Dev loss: 0.5247 r:0.7287
ru_en Dev loss: 0.4358 r:0.7200
Current avg r:0.5948 Best avg r: 0.6331
22:56:20,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:50,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:20,654 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2880
en_de Dev loss: 0.8482 r:0.2435
en_zh Dev loss: 0.7999 r:0.4309
ro_en Dev loss: 0.3257 r:0.8238
et_en Dev loss: 0.4057 r:0.6932
si_en Dev loss: 0.7945 r:0.5716
ne_en Dev loss: 0.5228 r:0.7315
ru_en Dev loss: 0.4614 r:0.7225
Current avg r:0.6024 Best avg r: 0.6331
23:03:50,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:20,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:50,138 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2879
en_de Dev loss: 0.8554 r:0.2592
en_zh Dev loss: 0.7983 r:0.4308
ro_en Dev loss: 0.3468 r:0.8254
et_en Dev loss: 0.4469 r:0.6870
si_en Dev loss: 0.7351 r:0.5744
ne_en Dev loss: 0.4959 r:0.7220
ru_en Dev loss: 0.4972 r:0.7064
Current avg r:0.6008 Best avg r: 0.6331
23:11:19,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:12:49,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:19,615 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2750
en_de Dev loss: 0.8620 r:0.2564
en_zh Dev loss: 0.8232 r:0.4439
ro_en Dev loss: 0.3755 r:0.8205
et_en Dev loss: 0.4417 r:0.6820
si_en Dev loss: 0.8574 r:0.5658
ne_en Dev loss: 0.5690 r:0.7188
ru_en Dev loss: 0.4658 r:0.7312
Current avg r:0.6027 Best avg r: 0.6331
23:18:49,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:19,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:21:48,937 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2754
en_de Dev loss: 0.8433 r:0.2433
en_zh Dev loss: 0.7747 r:0.4330
ro_en Dev loss: 0.3242 r:0.8234
et_en Dev loss: 0.4032 r:0.6897
si_en Dev loss: 0.8054 r:0.5630
ne_en Dev loss: 0.5687 r:0.7244
ru_en Dev loss: 0.4280 r:0.7286
Current avg r:0.6008 Best avg r: 0.6331
23:26:18,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:27:48,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:18,756 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2705
en_de Dev loss: 0.8657 r:0.2413
en_zh Dev loss: 0.8678 r:0.4182
ro_en Dev loss: 0.3668 r:0.8194
et_en Dev loss: 0.4661 r:0.6784
si_en Dev loss: 0.7895 r:0.5675
ne_en Dev loss: 0.5514 r:0.7188
ru_en Dev loss: 0.5017 r:0.7042
Current avg r:0.5925 Best avg r: 0.6331
23:33:48,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:18,719 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:48,675 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2639
en_de Dev loss: 0.8383 r:0.2444
en_zh Dev loss: 0.7450 r:0.4480
ro_en Dev loss: 0.3205 r:0.8185
et_en Dev loss: 0.4420 r:0.6802
si_en Dev loss: 0.7507 r:0.5698
ne_en Dev loss: 0.5144 r:0.7210
ru_en Dev loss: 0.4142 r:0.7211
Current avg r:0.6004 Best avg r: 0.6331
23:41:18,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:42:48,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:18,490 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2629
en_de Dev loss: 0.8623 r:0.2254
en_zh Dev loss: 0.7789 r:0.4425
ro_en Dev loss: 0.3537 r:0.8197
et_en Dev loss: 0.4234 r:0.6822
si_en Dev loss: 0.7901 r:0.5728
ne_en Dev loss: 0.5627 r:0.7200
ru_en Dev loss: 0.5061 r:0.7008
Current avg r:0.5948 Best avg r: 0.6331
23:48:48,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:18,250 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:51:48,208 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2785
en_de Dev loss: 0.8529 r:0.2351
en_zh Dev loss: 0.7591 r:0.4411
ro_en Dev loss: 0.3263 r:0.8194
et_en Dev loss: 0.4344 r:0.6890
si_en Dev loss: 0.7143 r:0.5658
ne_en Dev loss: 0.5003 r:0.7203
ru_en Dev loss: 0.4355 r:0.7335
Current avg r:0.6006 Best avg r: 0.6331
23:56:17,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:47,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:17,332 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2635
en_de Dev loss: 0.8606 r:0.2204
en_zh Dev loss: 0.7627 r:0.4448
ro_en Dev loss: 0.3661 r:0.8126
et_en Dev loss: 0.4290 r:0.6807
si_en Dev loss: 0.8437 r:0.5621
ne_en Dev loss: 0.6081 r:0.7169
ru_en Dev loss: 0.4677 r:0.7166
Current avg r:0.5935 Best avg r: 0.6331
00:03:46,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:16,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:06:46,553 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2681
en_de Dev loss: 0.8641 r:0.2130
en_zh Dev loss: 0.7547 r:0.4356
ro_en Dev loss: 0.3195 r:0.8175
et_en Dev loss: 0.4409 r:0.6953
si_en Dev loss: 0.7116 r:0.5708
ne_en Dev loss: 0.4603 r:0.7250
ru_en Dev loss: 0.4305 r:0.7258
Current avg r:0.5976 Best avg r: 0.6331
00:11:16,187 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:12:46,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:16,26 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2612
en_de Dev loss: 0.8582 r:0.2323
en_zh Dev loss: 0.7751 r:0.4476
ro_en Dev loss: 0.3457 r:0.8130
et_en Dev loss: 0.4308 r:0.6897
si_en Dev loss: 0.7421 r:0.5639
ne_en Dev loss: 0.5250 r:0.7202
ru_en Dev loss: 0.4203 r:0.7354
Current avg r:0.6003 Best avg r: 0.6331
00:18:46,707 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:16,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:21:46,593 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2334
en_de Dev loss: 0.8727 r:0.2338
en_zh Dev loss: 0.8297 r:0.4373
ro_en Dev loss: 0.3751 r:0.8129
et_en Dev loss: 0.4817 r:0.6774
si_en Dev loss: 0.8018 r:0.5653
ne_en Dev loss: 0.5511 r:0.7174
ru_en Dev loss: 0.5038 r:0.7088
Current avg r:0.5933 Best avg r: 0.6331
00:26:16,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:27:46,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:16,416 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2390
en_de Dev loss: 0.8829 r:0.2352
en_zh Dev loss: 0.8243 r:0.4187
ro_en Dev loss: 0.3932 r:0.8062
et_en Dev loss: 0.4430 r:0.6680
si_en Dev loss: 0.9003 r:0.5514
ne_en Dev loss: 0.6646 r:0.7094
ru_en Dev loss: 0.5286 r:0.6930
Current avg r:0.5831 Best avg r: 0.6331
00:33:46,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:16,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:46,328 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2342
en_de Dev loss: 0.8714 r:0.2416
en_zh Dev loss: 0.8328 r:0.4357
ro_en Dev loss: 0.3814 r:0.8133
et_en Dev loss: 0.4630 r:0.6826
si_en Dev loss: 0.8269 r:0.5660
ne_en Dev loss: 0.5434 r:0.7217
ru_en Dev loss: 0.4824 r:0.7185
Current avg r:0.5970 Best avg r: 0.6331
00:41:15,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:45,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:15,842 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2408
en_de Dev loss: 0.8781 r:0.2362
en_zh Dev loss: 0.8228 r:0.4328
ro_en Dev loss: 0.3688 r:0.8140
et_en Dev loss: 0.4595 r:0.6771
si_en Dev loss: 0.8035 r:0.5674
ne_en Dev loss: 0.5369 r:0.7280
ru_en Dev loss: 0.4857 r:0.7140
Current avg r:0.5957 Best avg r: 0.6331
00:48:45,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:15,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:51:45,797 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2260
en_de Dev loss: 0.8665 r:0.2397
en_zh Dev loss: 0.8408 r:0.4220
ro_en Dev loss: 0.3696 r:0.8181
et_en Dev loss: 0.4681 r:0.6735
si_en Dev loss: 0.8017 r:0.5643
ne_en Dev loss: 0.5537 r:0.7132
ru_en Dev loss: 0.5180 r:0.6917
Current avg r:0.5889 Best avg r: 0.6331
00:56:15,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:45,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:15,656 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2433
en_de Dev loss: 0.8648 r:0.2310
en_zh Dev loss: 0.8424 r:0.4185
ro_en Dev loss: 0.3445 r:0.8164
et_en Dev loss: 0.4338 r:0.6756
si_en Dev loss: 0.7842 r:0.5637
ne_en Dev loss: 0.5427 r:0.7175
ru_en Dev loss: 0.4650 r:0.7172
Current avg r:0.5914 Best avg r: 0.6331
01:03:45,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:15,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:45,284 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2200
en_de Dev loss: 0.8931 r:0.1997
en_zh Dev loss: 0.7845 r:0.4493
ro_en Dev loss: 0.3297 r:0.8214
et_en Dev loss: 0.4722 r:0.6853
si_en Dev loss: 0.7243 r:0.5726
ne_en Dev loss: 0.5311 r:0.7188
ru_en Dev loss: 0.4152 r:0.7356
Current avg r:0.5975 Best avg r: 0.6331
01:11:15,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:45,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:15,115 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2421
en_de Dev loss: 0.8828 r:0.2086
en_zh Dev loss: 0.8314 r:0.4325
ro_en Dev loss: 0.3702 r:0.8158
et_en Dev loss: 0.4491 r:0.6686
si_en Dev loss: 0.9451 r:0.5558
ne_en Dev loss: 0.6124 r:0.7080
ru_en Dev loss: 0.4607 r:0.7210
Current avg r:0.5872 Best avg r: 0.6331
01:18:44,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:20:14,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:21:44,284 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2287
en_de Dev loss: 0.8817 r:0.2168
en_zh Dev loss: 0.7974 r:0.4431
ro_en Dev loss: 0.3515 r:0.8199
et_en Dev loss: 0.4526 r:0.6847
si_en Dev loss: 0.8258 r:0.5608
ne_en Dev loss: 0.6144 r:0.7116
ru_en Dev loss: 0.4470 r:0.7282
Current avg r:0.5950 Best avg r: 0.6331
01:26:14,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:27:44,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:29:13,954 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2261
en_de Dev loss: 0.8848 r:0.2079
en_zh Dev loss: 0.8302 r:0.4329
ro_en Dev loss: 0.3591 r:0.8185
et_en Dev loss: 0.4516 r:0.6742
si_en Dev loss: 0.8685 r:0.5568
ne_en Dev loss: 0.5664 r:0.7092
ru_en Dev loss: 0.4890 r:0.7121
Current avg r:0.5874 Best avg r: 0.6331
01:33:43,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:13,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:43,267 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2230
en_de Dev loss: 0.8517 r:0.2198
en_zh Dev loss: 0.7642 r:0.4313
ro_en Dev loss: 0.3194 r:0.8187
et_en Dev loss: 0.4234 r:0.6799
si_en Dev loss: 0.7799 r:0.5559
ne_en Dev loss: 0.5341 r:0.7115
ru_en Dev loss: 0.4358 r:0.7223
Current avg r:0.5913 Best avg r: 0.6331
01:41:12,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:42,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:44:12,907 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2325
en_de Dev loss: 0.8758 r:0.2133
en_zh Dev loss: 0.7795 r:0.4454
ro_en Dev loss: 0.3299 r:0.8199
et_en Dev loss: 0.4558 r:0.6813
si_en Dev loss: 0.7535 r:0.5621
ne_en Dev loss: 0.4933 r:0.7141
ru_en Dev loss: 0.4418 r:0.7266
Current avg r:0.5947 Best avg r: 0.6331
01:48:42,545 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:12,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:42,429 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2202
en_de Dev loss: 0.8775 r:0.1923
en_zh Dev loss: 0.7792 r:0.4316
ro_en Dev loss: 0.3318 r:0.8210
et_en Dev loss: 0.4452 r:0.6794
si_en Dev loss: 0.7865 r:0.5595
ne_en Dev loss: 0.5041 r:0.7156
ru_en Dev loss: 0.4454 r:0.7230
Current avg r:0.5889 Best avg r: 0.6331
01:56:12,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:42,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:12,66 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2161
en_de Dev loss: 0.8827 r:0.2109
en_zh Dev loss: 0.8108 r:0.4452
ro_en Dev loss: 0.3568 r:0.8160
et_en Dev loss: 0.5049 r:0.6897
si_en Dev loss: 0.8105 r:0.5627
ne_en Dev loss: 0.5126 r:0.7228
ru_en Dev loss: 0.4507 r:0.7324
Current avg r:0.5971 Best avg r: 0.6331
02:03:41,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:11,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:06:41,231 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2141
en_de Dev loss: 0.8737 r:0.2109
en_zh Dev loss: 0.8146 r:0.4281
ro_en Dev loss: 0.3498 r:0.8133
et_en Dev loss: 0.4600 r:0.6715
si_en Dev loss: 0.8250 r:0.5539
ne_en Dev loss: 0.5903 r:0.7135
ru_en Dev loss: 0.4738 r:0.7075
Current avg r:0.5855 Best avg r: 0.6331
02:11:11,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:41,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:11,642 root INFO Epoch 6 Global steps: 63700 Train loss: 0.1998
en_de Dev loss: 0.8951 r:0.2026
en_zh Dev loss: 0.8612 r:0.4131
ro_en Dev loss: 0.3411 r:0.8169
et_en Dev loss: 0.4654 r:0.6747
si_en Dev loss: 0.7827 r:0.5622
ne_en Dev loss: 0.5438 r:0.7119
ru_en Dev loss: 0.4607 r:0.7237
Current avg r:0.5864 Best avg r: 0.6331
02:18:40,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:10,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:21:40,805 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2022
en_de Dev loss: 0.8989 r:0.2072
en_zh Dev loss: 0.8471 r:0.4164
ro_en Dev loss: 0.3561 r:0.8181
et_en Dev loss: 0.4728 r:0.6677
si_en Dev loss: 0.8294 r:0.5566
ne_en Dev loss: 0.5551 r:0.7054
ru_en Dev loss: 0.4860 r:0.7175
Current avg r:0.5841 Best avg r: 0.6331
02:26:10,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:27:40,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:09,894 root INFO Epoch 6 Global steps: 65100 Train loss: 0.1977
en_de Dev loss: 0.8778 r:0.2147
en_zh Dev loss: 0.8357 r:0.4216
ro_en Dev loss: 0.3456 r:0.8162
et_en Dev loss: 0.4852 r:0.6658
si_en Dev loss: 0.7802 r:0.5497
ne_en Dev loss: 0.5459 r:0.7101
ru_en Dev loss: 0.4724 r:0.7167
Current avg r:0.5850 Best avg r: 0.6331
02:33:39,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:09,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:38,922 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2026
en_de Dev loss: 0.8780 r:0.2144
en_zh Dev loss: 0.8254 r:0.4249
ro_en Dev loss: 0.3786 r:0.8140
et_en Dev loss: 0.4887 r:0.6615
si_en Dev loss: 0.8855 r:0.5388
ne_en Dev loss: 0.6019 r:0.7002
ru_en Dev loss: 0.5094 r:0.6987
Current avg r:0.5789 Best avg r: 0.6331
02:41:08,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:42:38,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:07,943 root INFO Epoch 6 Global steps: 66500 Train loss: 0.1988
en_de Dev loss: 0.8900 r:0.2044
en_zh Dev loss: 0.8562 r:0.4147
ro_en Dev loss: 0.3994 r:0.8090
et_en Dev loss: 0.4731 r:0.6567
si_en Dev loss: 0.9761 r:0.5344
ne_en Dev loss: 0.6778 r:0.7071
ru_en Dev loss: 0.5418 r:0.6974
Current avg r:0.5748 Best avg r: 0.6331
02:48:37,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:07,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:37,66 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2035
en_de Dev loss: 0.8936 r:0.2133
en_zh Dev loss: 0.8363 r:0.4324
ro_en Dev loss: 0.3610 r:0.8167
et_en Dev loss: 0.4459 r:0.6707
si_en Dev loss: 0.9424 r:0.5391
ne_en Dev loss: 0.6064 r:0.7103
ru_en Dev loss: 0.4959 r:0.7147
Current avg r:0.5853 Best avg r: 0.6331
02:56:06,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:57:36,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:59:06,494 root INFO Epoch 6 Global steps: 67900 Train loss: 0.1932
en_de Dev loss: 0.8967 r:0.2092
en_zh Dev loss: 0.8505 r:0.4156
ro_en Dev loss: 0.3714 r:0.8087
et_en Dev loss: 0.4931 r:0.6652
si_en Dev loss: 0.8235 r:0.5446
ne_en Dev loss: 0.5857 r:0.7052
ru_en Dev loss: 0.4812 r:0.7056
Current avg r:0.5792 Best avg r: 0.6331
03:03:36,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:05:06,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:06:36,112 root INFO Epoch 6 Global steps: 68600 Train loss: 0.1936
en_de Dev loss: 0.8938 r:0.2089
en_zh Dev loss: 0.8120 r:0.4417
ro_en Dev loss: 0.3340 r:0.8184
et_en Dev loss: 0.4807 r:0.6809
si_en Dev loss: 0.7301 r:0.5662
ne_en Dev loss: 0.4653 r:0.7212
ru_en Dev loss: 0.4578 r:0.7313
Current avg r:0.5955 Best avg r: 0.6331
03:11:05,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:12:35,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:05,936 root INFO Epoch 6 Global steps: 69300 Train loss: 0.1953
en_de Dev loss: 0.9001 r:0.2064
en_zh Dev loss: 0.8301 r:0.4392
ro_en Dev loss: 0.3711 r:0.8129
et_en Dev loss: 0.4805 r:0.6678
si_en Dev loss: 0.9194 r:0.5463
ne_en Dev loss: 0.6387 r:0.7053
ru_en Dev loss: 0.5062 r:0.7088
Current avg r:0.5838 Best avg r: 0.6331
03:18:35,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:20:05,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:21:35,680 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1952
en_de Dev loss: 0.8830 r:0.2076
en_zh Dev loss: 0.8051 r:0.4383
ro_en Dev loss: 0.3543 r:0.8154
et_en Dev loss: 0.4563 r:0.6793
si_en Dev loss: 0.8491 r:0.5545
ne_en Dev loss: 0.6627 r:0.7055
ru_en Dev loss: 0.4937 r:0.7126
Current avg r:0.5876 Best avg r: 0.6331
03:26:05,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:27:35,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:29:05,69 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1999
en_de Dev loss: 0.8910 r:0.1976
en_zh Dev loss: 0.7961 r:0.4289
ro_en Dev loss: 0.3275 r:0.8192
et_en Dev loss: 0.4536 r:0.6852
si_en Dev loss: 0.7467 r:0.5623
ne_en Dev loss: 0.5138 r:0.7112
ru_en Dev loss: 0.4293 r:0.7318
Current avg r:0.5909 Best avg r: 0.6331
03:33:34,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:04,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:34,121 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1897
en_de Dev loss: 0.8736 r:0.1979
en_zh Dev loss: 0.7536 r:0.4404
ro_en Dev loss: 0.3198 r:0.8226
et_en Dev loss: 0.4535 r:0.6901
si_en Dev loss: 0.7204 r:0.5620
ne_en Dev loss: 0.4907 r:0.7151
ru_en Dev loss: 0.4152 r:0.7314
Current avg r:0.5942 Best avg r: 0.6331
03:41:03,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:42:33,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:44:03,815 root INFO Epoch 6 Global steps: 72100 Train loss: 0.1918
en_de Dev loss: 0.8793 r:0.2113
en_zh Dev loss: 0.8243 r:0.4307
ro_en Dev loss: 0.3597 r:0.8150
et_en Dev loss: 0.4611 r:0.6760
si_en Dev loss: 0.8429 r:0.5565
ne_en Dev loss: 0.5671 r:0.7109
ru_en Dev loss: 0.4630 r:0.7190
Current avg r:0.5885 Best avg r: 0.6331
03:48:33,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:50:03,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:51:33,16 root INFO Epoch 6 Global steps: 72800 Train loss: 0.1816
en_de Dev loss: 0.8848 r:0.2034
en_zh Dev loss: 0.8879 r:0.3999
ro_en Dev loss: 0.3508 r:0.8140
et_en Dev loss: 0.4461 r:0.6752
si_en Dev loss: 0.9034 r:0.5410
ne_en Dev loss: 0.6011 r:0.7031
ru_en Dev loss: 0.4762 r:0.7140
Current avg r:0.5786 Best avg r: 0.6331
03:56:02,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:32,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:59:02,495 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1860
en_de Dev loss: 0.8789 r:0.2095
en_zh Dev loss: 0.8093 r:0.4310
ro_en Dev loss: 0.3257 r:0.8171
et_en Dev loss: 0.4546 r:0.6837
si_en Dev loss: 0.8733 r:0.5421
ne_en Dev loss: 0.5343 r:0.7117
ru_en Dev loss: 0.4369 r:0.7329
Current avg r:0.5897 Best avg r: 0.6331
04:03:32,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:05:02,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:06:32,773 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1757
en_de Dev loss: 0.9054 r:0.1810
en_zh Dev loss: 0.8078 r:0.4210
ro_en Dev loss: 0.3261 r:0.8185
et_en Dev loss: 0.4529 r:0.6765
si_en Dev loss: 0.7818 r:0.5501
ne_en Dev loss: 0.5030 r:0.7123
ru_en Dev loss: 0.4497 r:0.7222
Current avg r:0.5831 Best avg r: 0.6331
04:11:02,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:12:32,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:14:02,209 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1723
en_de Dev loss: 0.9181 r:0.2021
en_zh Dev loss: 0.8542 r:0.4314
ro_en Dev loss: 0.3640 r:0.8194
et_en Dev loss: 0.4698 r:0.6719
si_en Dev loss: 0.8557 r:0.5428
ne_en Dev loss: 0.5985 r:0.7072
ru_en Dev loss: 0.4931 r:0.7171
Current avg r:0.5845 Best avg r: 0.6331
04:18:31,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:20:01,738 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:21:31,653 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1728
en_de Dev loss: 0.8886 r:0.2036
en_zh Dev loss: 0.8187 r:0.4326
ro_en Dev loss: 0.3448 r:0.8160
et_en Dev loss: 0.4894 r:0.6605
si_en Dev loss: 0.8490 r:0.5478
ne_en Dev loss: 0.5475 r:0.7127
ru_en Dev loss: 0.4463 r:0.7220
Current avg r:0.5850 Best avg r: 0.6331
04:26:01,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:27:31,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:29:01,224 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1712
en_de Dev loss: 0.8835 r:0.2045
en_zh Dev loss: 0.7853 r:0.4431
ro_en Dev loss: 0.3471 r:0.8146
et_en Dev loss: 0.4888 r:0.6680
si_en Dev loss: 0.7985 r:0.5502
ne_en Dev loss: 0.5582 r:0.7100
ru_en Dev loss: 0.4433 r:0.7266
Current avg r:0.5881 Best avg r: 0.6331
04:33:30,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:35:00,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:36:30,855 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1700
en_de Dev loss: 0.8916 r:0.1937
en_zh Dev loss: 0.8069 r:0.4358
ro_en Dev loss: 0.3464 r:0.8160
et_en Dev loss: 0.4835 r:0.6625
si_en Dev loss: 0.8207 r:0.5468
ne_en Dev loss: 0.5314 r:0.7106
ru_en Dev loss: 0.4622 r:0.7151
Current avg r:0.5829 Best avg r: 0.6331
04:41:00,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:42:30,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:00,569 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1652
en_de Dev loss: 0.8976 r:0.1895
en_zh Dev loss: 0.8017 r:0.4461
ro_en Dev loss: 0.3628 r:0.8141
et_en Dev loss: 0.5129 r:0.6641
si_en Dev loss: 0.8643 r:0.5437
ne_en Dev loss: 0.5595 r:0.7132
ru_en Dev loss: 0.4460 r:0.7264
Current avg r:0.5853 Best avg r: 0.6331
04:48:29,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:49:59,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:29,798 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1671
en_de Dev loss: 0.9097 r:0.1929
en_zh Dev loss: 0.8107 r:0.4402
ro_en Dev loss: 0.3468 r:0.8151
et_en Dev loss: 0.4529 r:0.6675
si_en Dev loss: 0.8799 r:0.5438
ne_en Dev loss: 0.5440 r:0.7104
ru_en Dev loss: 0.4561 r:0.7314
Current avg r:0.5859 Best avg r: 0.6331
04:55:59,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:29,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:59,248 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1626
en_de Dev loss: 0.9111 r:0.1814
en_zh Dev loss: 0.8405 r:0.4329
ro_en Dev loss: 0.3615 r:0.8146
et_en Dev loss: 0.4673 r:0.6620
si_en Dev loss: 0.8803 r:0.5455
ne_en Dev loss: 0.6066 r:0.7108
ru_en Dev loss: 0.4887 r:0.7138
Current avg r:0.5802 Best avg r: 0.6331
05:03:28,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:04:58,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:06:28,904 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1726
en_de Dev loss: 0.8901 r:0.2046
en_zh Dev loss: 0.8119 r:0.4526
ro_en Dev loss: 0.3348 r:0.8190
et_en Dev loss: 0.4962 r:0.6804
si_en Dev loss: 0.7987 r:0.5579
ne_en Dev loss: 0.5201 r:0.7150
ru_en Dev loss: 0.4436 r:0.7278
Current avg r:0.5939 Best avg r: 0.6331
05:10:58,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:12:28,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:13:58,566 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1655
en_de Dev loss: 0.8994 r:0.1873
en_zh Dev loss: 0.8646 r:0.4205
ro_en Dev loss: 0.3666 r:0.8152
et_en Dev loss: 0.4603 r:0.6723
si_en Dev loss: 0.8767 r:0.5461
ne_en Dev loss: 0.5627 r:0.7082
ru_en Dev loss: 0.4960 r:0.7197
Current avg r:0.5813 Best avg r: 0.6331
05:18:28,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:19:58,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:21:27,996 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1678
en_de Dev loss: 0.8909 r:0.2074
en_zh Dev loss: 0.8108 r:0.4413
ro_en Dev loss: 0.3336 r:0.8202
et_en Dev loss: 0.4745 r:0.6784
si_en Dev loss: 0.8135 r:0.5487
ne_en Dev loss: 0.5299 r:0.7132
ru_en Dev loss: 0.4445 r:0.7263
Current avg r:0.5908 Best avg r: 0.6331
05:25:57,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:27:27,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:28:57,582 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1661
en_de Dev loss: 0.8871 r:0.1977
en_zh Dev loss: 0.8259 r:0.4310
ro_en Dev loss: 0.3491 r:0.8194
et_en Dev loss: 0.4467 r:0.6659
si_en Dev loss: 0.8632 r:0.5470
ne_en Dev loss: 0.6334 r:0.7038
ru_en Dev loss: 0.5030 r:0.7006
Current avg r:0.5808 Best avg r: 0.6331
05:33:27,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:34:57,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:36:27,113 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1646
en_de Dev loss: 0.8898 r:0.2007
en_zh Dev loss: 0.8064 r:0.4479
ro_en Dev loss: 0.3608 r:0.8137
et_en Dev loss: 0.4680 r:0.6637
si_en Dev loss: 0.8483 r:0.5480
ne_en Dev loss: 0.5810 r:0.7070
ru_en Dev loss: 0.4852 r:0.7159
Current avg r:0.5853 Best avg r: 0.6331
05:40:56,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:42:26,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:43:56,584 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1756
en_de Dev loss: 0.8870 r:0.2095
en_zh Dev loss: 0.8026 r:0.4515
ro_en Dev loss: 0.3676 r:0.8128
et_en Dev loss: 0.4693 r:0.6727
si_en Dev loss: 0.8488 r:0.5511
ne_en Dev loss: 0.5606 r:0.7121
ru_en Dev loss: 0.4818 r:0.7182
Current avg r:0.5897 Best avg r: 0.6331
05:48:25,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:49:55,754 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:51:25,730 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1606
en_de Dev loss: 0.8873 r:0.1957
en_zh Dev loss: 0.8100 r:0.4402
ro_en Dev loss: 0.3389 r:0.8176
et_en Dev loss: 0.4560 r:0.6676
si_en Dev loss: 0.8551 r:0.5448
ne_en Dev loss: 0.5507 r:0.7123
ru_en Dev loss: 0.4752 r:0.7173
Current avg r:0.5851 Best avg r: 0.6331
05:55:56,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:57:26,491 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:58:56,451 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1490
en_de Dev loss: 0.8884 r:0.2112
en_zh Dev loss: 0.8206 r:0.4418
ro_en Dev loss: 0.3535 r:0.8146
et_en Dev loss: 0.4940 r:0.6765
si_en Dev loss: 0.8507 r:0.5453
ne_en Dev loss: 0.5545 r:0.7145
ru_en Dev loss: 0.4540 r:0.7263
Current avg r:0.5900 Best avg r: 0.6331
06:03:26,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:56,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:06:26,71 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1500
en_de Dev loss: 0.8891 r:0.1948
en_zh Dev loss: 0.7668 r:0.4476
ro_en Dev loss: 0.3402 r:0.8133
et_en Dev loss: 0.4785 r:0.6707
si_en Dev loss: 0.7980 r:0.5444
ne_en Dev loss: 0.5299 r:0.7093
ru_en Dev loss: 0.4196 r:0.7338
Current avg r:0.5877 Best avg r: 0.6331
06:10:55,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:12:25,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:13:55,834 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1490
en_de Dev loss: 0.8866 r:0.1948
en_zh Dev loss: 0.7772 r:0.4417
ro_en Dev loss: 0.3425 r:0.8102
et_en Dev loss: 0.4534 r:0.6665
si_en Dev loss: 0.8563 r:0.5352
ne_en Dev loss: 0.5978 r:0.7089
ru_en Dev loss: 0.4474 r:0.7226
Current avg r:0.5828 Best avg r: 0.6331
06:18:25,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:19:55,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:21:25,415 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1527
en_de Dev loss: 0.8965 r:0.2002
en_zh Dev loss: 0.7818 r:0.4442
ro_en Dev loss: 0.3409 r:0.8158
et_en Dev loss: 0.4638 r:0.6740
si_en Dev loss: 0.7767 r:0.5523
ne_en Dev loss: 0.5231 r:0.7114
ru_en Dev loss: 0.4305 r:0.7353
Current avg r:0.5904 Best avg r: 0.6331
06:25:54,726 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:27:24,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:28:54,728 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1479
en_de Dev loss: 0.9056 r:0.1975
en_zh Dev loss: 0.8231 r:0.4444
ro_en Dev loss: 0.3849 r:0.8124
et_en Dev loss: 0.4684 r:0.6609
si_en Dev loss: 0.9048 r:0.5418
ne_en Dev loss: 0.6462 r:0.7018
ru_en Dev loss: 0.4894 r:0.7234
Current avg r:0.5832 Best avg r: 0.6331
06:33:24,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:34:54,442 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:36:24,394 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1529
en_de Dev loss: 0.9002 r:0.2031
en_zh Dev loss: 0.8353 r:0.4381
ro_en Dev loss: 0.3975 r:0.8114
et_en Dev loss: 0.4763 r:0.6656
si_en Dev loss: 0.9000 r:0.5481
ne_en Dev loss: 0.5900 r:0.7150
ru_en Dev loss: 0.4741 r:0.7330
Current avg r:0.5878 Best avg r: 0.6331
06:40:54,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:42:24,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:43:54,15 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1491
en_de Dev loss: 0.8864 r:0.2104
en_zh Dev loss: 0.7679 r:0.4562
ro_en Dev loss: 0.3269 r:0.8191
et_en Dev loss: 0.4435 r:0.6797
si_en Dev loss: 0.7923 r:0.5545
ne_en Dev loss: 0.5188 r:0.7166
ru_en Dev loss: 0.4036 r:0.7524
Current avg r:0.5984 Best avg r: 0.6331
06:48:23,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:49:53,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:51:23,91 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1456
en_de Dev loss: 0.9040 r:0.2061
en_zh Dev loss: 0.8036 r:0.4472
ro_en Dev loss: 0.3598 r:0.8142
et_en Dev loss: 0.4791 r:0.6720
si_en Dev loss: 0.8167 r:0.5544
ne_en Dev loss: 0.5046 r:0.7152
ru_en Dev loss: 0.4262 r:0.7506
Current avg r:0.5942 Best avg r: 0.6331
06:55:52,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:57:22,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:58:52,79 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1477
en_de Dev loss: 0.8951 r:0.1984
en_zh Dev loss: 0.8062 r:0.4435
ro_en Dev loss: 0.3418 r:0.8142
et_en Dev loss: 0.4666 r:0.6698
si_en Dev loss: 0.8297 r:0.5502
ne_en Dev loss: 0.5202 r:0.7104
ru_en Dev loss: 0.4182 r:0.7427
Current avg r:0.5899 Best avg r: 0.6331
07:03:21,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:04:51,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:06:21,395 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1462
en_de Dev loss: 0.8704 r:0.2185
en_zh Dev loss: 0.8051 r:0.4246
ro_en Dev loss: 0.3474 r:0.8083
et_en Dev loss: 0.4451 r:0.6641
si_en Dev loss: 0.8851 r:0.5361
ne_en Dev loss: 0.6445 r:0.7008
ru_en Dev loss: 0.4286 r:0.7303
Current avg r:0.5833 Best avg r: 0.6331
07:10:50,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:12:20,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:13:50,581 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1411
en_de Dev loss: 0.8786 r:0.2236
en_zh Dev loss: 0.7765 r:0.4500
ro_en Dev loss: 0.3372 r:0.8130
et_en Dev loss: 0.4899 r:0.6770
si_en Dev loss: 0.7593 r:0.5566
ne_en Dev loss: 0.4987 r:0.7098
ru_en Dev loss: 0.3945 r:0.7527
Current avg r:0.5975 Best avg r: 0.6331
07:18:19,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:19:49,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:21:19,853 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1432
en_de Dev loss: 0.8996 r:0.2215
en_zh Dev loss: 0.8021 r:0.4424
ro_en Dev loss: 0.3519 r:0.8132
et_en Dev loss: 0.4732 r:0.6702
si_en Dev loss: 0.8577 r:0.5447
ne_en Dev loss: 0.5622 r:0.7023
ru_en Dev loss: 0.4369 r:0.7415
Current avg r:0.5908 Best avg r: 0.6331
07:25:49,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:27:19,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:28:49,175 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1509
en_de Dev loss: 0.8732 r:0.2331
en_zh Dev loss: 0.7879 r:0.4443
ro_en Dev loss: 0.3434 r:0.8145
et_en Dev loss: 0.4608 r:0.6651
si_en Dev loss: 0.8241 r:0.5462
ne_en Dev loss: 0.5538 r:0.7065
ru_en Dev loss: 0.4731 r:0.7218
Current avg r:0.5902 Best avg r: 0.6331
07:33:18,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:34:48,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:36:18,343 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1367
en_de Dev loss: 0.8836 r:0.2292
en_zh Dev loss: 0.7757 r:0.4633
ro_en Dev loss: 0.3520 r:0.8107
et_en Dev loss: 0.4712 r:0.6756
si_en Dev loss: 0.8676 r:0.5471
ne_en Dev loss: 0.5664 r:0.7101
ru_en Dev loss: 0.4376 r:0.7427
Current avg r:0.5970 Best avg r: 0.6331
07:40:47,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:42:17,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:43:47,596 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1430
en_de Dev loss: 0.8878 r:0.2098
en_zh Dev loss: 0.7734 r:0.4554
ro_en Dev loss: 0.3351 r:0.8144
et_en Dev loss: 0.4465 r:0.6792
si_en Dev loss: 0.7647 r:0.5496
ne_en Dev loss: 0.5144 r:0.7070
ru_en Dev loss: 0.4061 r:0.7519
Current avg r:0.5953 Best avg r: 0.6331
07:48:18,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:49:48,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:51:18,444 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1308
en_de Dev loss: 0.8915 r:0.2173
en_zh Dev loss: 0.7986 r:0.4536
ro_en Dev loss: 0.3873 r:0.8087
et_en Dev loss: 0.4528 r:0.6687
si_en Dev loss: 0.9685 r:0.5326
ne_en Dev loss: 0.6545 r:0.7023
ru_en Dev loss: 0.4645 r:0.7358
Current avg r:0.5884 Best avg r: 0.6331
07:55:47,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:57:17,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:58:47,775 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1329
en_de Dev loss: 0.8944 r:0.2278
en_zh Dev loss: 0.7977 r:0.4578
ro_en Dev loss: 0.3783 r:0.8068
et_en Dev loss: 0.4571 r:0.6662
si_en Dev loss: 0.9608 r:0.5385
ne_en Dev loss: 0.6531 r:0.7063
ru_en Dev loss: 0.4831 r:0.7266
Current avg r:0.5900 Best avg r: 0.6331
08:03:17,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:04:47,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:06:17,521 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1325
en_de Dev loss: 0.8737 r:0.2234
en_zh Dev loss: 0.7316 r:0.4717
ro_en Dev loss: 0.3209 r:0.8162
et_en Dev loss: 0.4555 r:0.6921
si_en Dev loss: 0.7391 r:0.5618
ne_en Dev loss: 0.4735 r:0.7181
ru_en Dev loss: 0.4032 r:0.7447
Current avg r:0.6040 Best avg r: 0.6331
08:10:47,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:12:17,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:13:47,243 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1270
en_de Dev loss: 0.8931 r:0.2166
en_zh Dev loss: 0.7880 r:0.4590
ro_en Dev loss: 0.3432 r:0.8132
et_en Dev loss: 0.4565 r:0.6853
si_en Dev loss: 0.8005 r:0.5537
ne_en Dev loss: 0.5185 r:0.7194
ru_en Dev loss: 0.4150 r:0.7462
Current avg r:0.5991 Best avg r: 0.6331
08:18:16,767 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:19:46,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:21:16,672 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1280
en_de Dev loss: 0.9060 r:0.2121
en_zh Dev loss: 0.8078 r:0.4515
ro_en Dev loss: 0.3665 r:0.8074
et_en Dev loss: 0.4557 r:0.6695
si_en Dev loss: 0.8530 r:0.5476
ne_en Dev loss: 0.5548 r:0.7109
ru_en Dev loss: 0.4860 r:0.7253
Current avg r:0.5892 Best avg r: 0.6331
08:25:46,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:27:16,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:28:46,487 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1304
en_de Dev loss: 0.8818 r:0.2303
en_zh Dev loss: 0.7520 r:0.4684
ro_en Dev loss: 0.3371 r:0.8121
et_en Dev loss: 0.4435 r:0.6776
si_en Dev loss: 0.8518 r:0.5474
ne_en Dev loss: 0.5055 r:0.7071
ru_en Dev loss: 0.4148 r:0.7479
Current avg r:0.5987 Best avg r: 0.6331
08:33:16,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:34:46,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:16,358 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1321
en_de Dev loss: 0.9057 r:0.2191
en_zh Dev loss: 0.8387 r:0.4491
ro_en Dev loss: 0.3995 r:0.8074
et_en Dev loss: 0.5060 r:0.6671
si_en Dev loss: 0.9691 r:0.5339
ne_en Dev loss: 0.6078 r:0.7042
ru_en Dev loss: 0.4708 r:0.7311
Current avg r:0.5874 Best avg r: 0.6331
08:40:45,692 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:15,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:45,696 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1337
en_de Dev loss: 0.9247 r:0.2087
en_zh Dev loss: 0.8302 r:0.4574
ro_en Dev loss: 0.3814 r:0.8082
et_en Dev loss: 0.4612 r:0.6716
si_en Dev loss: 0.9547 r:0.5371
ne_en Dev loss: 0.5729 r:0.7074
ru_en Dev loss: 0.4461 r:0.7411
Current avg r:0.5902 Best avg r: 0.6331
08:48:15,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:49:45,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:51:14,960 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1282
en_de Dev loss: 0.9148 r:0.2126
en_zh Dev loss: 0.7919 r:0.4587
ro_en Dev loss: 0.3528 r:0.8137
et_en Dev loss: 0.4861 r:0.6776
si_en Dev loss: 0.8245 r:0.5463
ne_en Dev loss: 0.4869 r:0.7164
ru_en Dev loss: 0.4141 r:0.7510
Current avg r:0.5966 Best avg r: 0.6331
08:55:44,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:57:14,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:58:44,194 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1268
en_de Dev loss: 0.9061 r:0.2119
en_zh Dev loss: 0.8623 r:0.4282
ro_en Dev loss: 0.3857 r:0.8035
et_en Dev loss: 0.4736 r:0.6571
si_en Dev loss: 0.9270 r:0.5336
ne_en Dev loss: 0.6224 r:0.7054
ru_en Dev loss: 0.5107 r:0.7104
Current avg r:0.5786 Best avg r: 0.6331
09:03:13,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:04:43,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:06:13,394 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1273
en_de Dev loss: 0.9047 r:0.2013
en_zh Dev loss: 0.7858 r:0.4448
ro_en Dev loss: 0.3431 r:0.8117
et_en Dev loss: 0.4606 r:0.6694
si_en Dev loss: 0.8468 r:0.5461
ne_en Dev loss: 0.5344 r:0.7158
ru_en Dev loss: 0.4363 r:0.7365
Current avg r:0.5894 Best avg r: 0.6331
09:10:42,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:12:12,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:13:42,597 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1239
en_de Dev loss: 0.8866 r:0.2185
en_zh Dev loss: 0.7380 r:0.4613
ro_en Dev loss: 0.3213 r:0.8143
et_en Dev loss: 0.4726 r:0.6799
si_en Dev loss: 0.8116 r:0.5501
ne_en Dev loss: 0.4821 r:0.7119
ru_en Dev loss: 0.4001 r:0.7441
Current avg r:0.5972 Best avg r: 0.6331
09:18:12,153 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:19:42,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:21:12,102 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1236
en_de Dev loss: 0.8944 r:0.2242
en_zh Dev loss: 0.7638 r:0.4626
ro_en Dev loss: 0.3452 r:0.8153
et_en Dev loss: 0.5267 r:0.6856
si_en Dev loss: 0.7814 r:0.5473
ne_en Dev loss: 0.4814 r:0.7132
ru_en Dev loss: 0.4031 r:0.7433
Current avg r:0.5988 Best avg r: 0.6331
09:25:41,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:27:11,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:28:41,462 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1216
en_de Dev loss: 0.9319 r:0.1900
en_zh Dev loss: 0.8355 r:0.4474
ro_en Dev loss: 0.3702 r:0.8133
et_en Dev loss: 0.4676 r:0.6697
si_en Dev loss: 0.9240 r:0.5346
ne_en Dev loss: 0.6300 r:0.7038
ru_en Dev loss: 0.4705 r:0.7311
Current avg r:0.5843 Best avg r: 0.6331
09:33:10,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:34:40,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:10,741 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1212
en_de Dev loss: 0.9007 r:0.1973
en_zh Dev loss: 0.7697 r:0.4617
ro_en Dev loss: 0.3428 r:0.8133
et_en Dev loss: 0.4534 r:0.6763
si_en Dev loss: 0.8470 r:0.5417
ne_en Dev loss: 0.5556 r:0.7022
ru_en Dev loss: 0.4365 r:0.7352
Current avg r:0.5897 Best avg r: 0.6331
09:40:41,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:11,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:41,363 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1157
en_de Dev loss: 0.9183 r:0.2077
en_zh Dev loss: 0.8065 r:0.4554
ro_en Dev loss: 0.3821 r:0.8103
et_en Dev loss: 0.4556 r:0.6687
si_en Dev loss: 0.9029 r:0.5393
ne_en Dev loss: 0.6100 r:0.7045
ru_en Dev loss: 0.4809 r:0.7261
Current avg r:0.5874 Best avg r: 0.6331
09:48:10,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:49:40,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:10,720 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1121
en_de Dev loss: 0.8956 r:0.2181
en_zh Dev loss: 0.7669 r:0.4669
ro_en Dev loss: 0.3488 r:0.8139
et_en Dev loss: 0.4449 r:0.6811
si_en Dev loss: 0.8436 r:0.5461
ne_en Dev loss: 0.5384 r:0.7056
ru_en Dev loss: 0.4251 r:0.7487
Current avg r:0.5972 Best avg r: 0.6331
09:55:40,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:10,89 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:39,998 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1131
en_de Dev loss: 0.9198 r:0.1955
en_zh Dev loss: 0.7874 r:0.4640
ro_en Dev loss: 0.3542 r:0.8154
et_en Dev loss: 0.4534 r:0.6788
si_en Dev loss: 0.8536 r:0.5464
ne_en Dev loss: 0.5423 r:0.7095
ru_en Dev loss: 0.4336 r:0.7375
Current avg r:0.5925 Best avg r: 0.6331
10:03:09,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:39,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:09,818 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1105
en_de Dev loss: 0.9159 r:0.2024
en_zh Dev loss: 0.7785 r:0.4737
ro_en Dev loss: 0.3414 r:0.8174
et_en Dev loss: 0.4798 r:0.6933
si_en Dev loss: 0.8079 r:0.5452
ne_en Dev loss: 0.4801 r:0.7132
ru_en Dev loss: 0.3972 r:0.7584
Current avg r:0.6005 Best avg r: 0.6331
10:10:39,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:12:09,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:13:39,806 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1143
en_de Dev loss: 0.9043 r:0.2041
en_zh Dev loss: 0.7856 r:0.4624
ro_en Dev loss: 0.3501 r:0.8186
et_en Dev loss: 0.4435 r:0.6809
si_en Dev loss: 0.8149 r:0.5449
ne_en Dev loss: 0.4760 r:0.7115
ru_en Dev loss: 0.4480 r:0.7359
Current avg r:0.5940 Best avg r: 0.6331
10:18:09,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:39,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:21:09,709 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1113
en_de Dev loss: 0.9064 r:0.2246
en_zh Dev loss: 0.8374 r:0.4481
ro_en Dev loss: 0.3702 r:0.8120
et_en Dev loss: 0.4522 r:0.6775
si_en Dev loss: 0.8997 r:0.5393
ne_en Dev loss: 0.5631 r:0.7119
ru_en Dev loss: 0.4768 r:0.7314
Current avg r:0.5921 Best avg r: 0.6331
10:25:39,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:09,56 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:28:39,33 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1145
en_de Dev loss: 0.9157 r:0.1950
en_zh Dev loss: 0.7492 r:0.4576
ro_en Dev loss: 0.3353 r:0.8133
et_en Dev loss: 0.4430 r:0.6733
si_en Dev loss: 0.8524 r:0.5355
ne_en Dev loss: 0.5526 r:0.7077
ru_en Dev loss: 0.4183 r:0.7393
Current avg r:0.5888 Best avg r: 0.6331
10:33:09,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:34:39,139 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:36:09,121 root INFO Epoch 10 Global steps: 110600 Train loss: 0.1110
en_de Dev loss: 0.9215 r:0.1830
en_zh Dev loss: 0.7962 r:0.4548
ro_en Dev loss: 0.3529 r:0.8146
et_en Dev loss: 0.4408 r:0.6761
si_en Dev loss: 0.9063 r:0.5393
ne_en Dev loss: 0.6157 r:0.7115
ru_en Dev loss: 0.4584 r:0.7356
Current avg r:0.5879 Best avg r: 0.6331
10:40:39,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:42:09,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:43:39,11 root INFO Epoch 10 Global steps: 111300 Train loss: 0.1123
en_de Dev loss: 0.9026 r:0.2121
en_zh Dev loss: 0.8161 r:0.4571
ro_en Dev loss: 0.3564 r:0.8121
et_en Dev loss: 0.4804 r:0.6665
si_en Dev loss: 0.9085 r:0.5299
ne_en Dev loss: 0.5859 r:0.7010
ru_en Dev loss: 0.4617 r:0.7301
Current avg r:0.5870 Best avg r: 0.6331
