14:43:57,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:10,701 root INFO 
id:en_de cur r: 0.0953 best r: 0.0953
14:44:23,703 root INFO 
id:en_zh cur r: 0.2773 best r: 0.2773
14:44:36,754 root INFO 
id:ro_en cur r: 0.5449 best r: 0.5449
14:44:49,828 root INFO 
id:et_en cur r: 0.3423 best r: 0.3423
14:45:29,9 root INFO 
id:ne_en cur r: 0.3009 best r: 0.3009
14:45:42,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:13,275 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:47:13,285 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:47:13,291 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:47:13,296 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:47:13,302 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:47:13,309 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:47:13,318 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:47:26,382 root INFO Epoch 0 Global steps: 700 Train loss: 0.8434
en_de Dev loss: 0.8888 r:0.1107
en_zh Dev loss: 0.7829 r:0.2723
ro_en Dev loss: 0.7664 r:0.5480
et_en Dev loss: 0.6654 r:0.4232
si_en Dev loss: 0.7915 r:0.3951
ne_en Dev loss: 0.7161 r:0.4201
ru_en Dev loss: 0.7347 r:0.5100
Current avg r:0.3828 Best avg r: 0.3828
14:51:58,459 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:37,255 root INFO 
id:ro_en cur r: 0.6573 best r: 0.6573
14:52:50,210 root INFO 
id:et_en cur r: 0.5429 best r: 0.5429
14:53:03,182 root INFO 
id:si_en cur r: 0.3773 best r: 0.3773
14:53:29,103 root INFO 
id:ne_en cur r: 0.5139 best r: 0.5139
14:53:42,3 root INFO 
id:ru_en cur r: 0.6107 best r: 0.6107
14:53:42,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:12,576 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:55:12,584 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:55:12,591 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:55:12,597 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:55:12,603 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:55:12,608 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:55:12,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:55:25,577 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8142
en_de Dev loss: 0.9175 r:0.1175
en_zh Dev loss: 0.7626 r:0.2764
ro_en Dev loss: 0.5735 r:0.6622
et_en Dev loss: 0.5534 r:0.5470
si_en Dev loss: 0.7036 r:0.4736
ne_en Dev loss: 0.5809 r:0.5816
ru_en Dev loss: 0.5506 r:0.6691
Current avg r:0.4753 Best avg r: 0.4753
14:59:56,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:09,521 root INFO 
id:en_de cur r: 0.1033 best r: 0.1033
15:00:22,413 root INFO 
id:en_zh cur r: 0.2937 best r: 0.2937
15:00:48,275 root INFO 
id:et_en cur r: 0.5904 best r: 0.5904
15:01:01,236 root INFO 
id:si_en cur r: 0.4261 best r: 0.4261
15:01:27,151 root INFO 
id:ne_en cur r: 0.5487 best r: 0.5487
15:01:39,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:10,356 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:03:10,362 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:03:10,367 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:03:10,371 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:03:10,376 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:03:10,382 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:03:10,386 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:03:23,324 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7487
en_de Dev loss: 0.9836 r:0.1107
en_zh Dev loss: 0.7960 r:0.2851
ro_en Dev loss: 0.5132 r:0.6700
et_en Dev loss: 0.4689 r:0.6040
si_en Dev loss: 0.6741 r:0.4809
ne_en Dev loss: 0.5442 r:0.5830
ru_en Dev loss: 0.6230 r:0.6108
Current avg r:0.4778 Best avg r: 0.4778
15:07:54,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:20,186 root INFO 
id:en_zh cur r: 0.3534 best r: 0.3534
15:08:33,114 root INFO 
id:ro_en cur r: 0.6957 best r: 0.6957
15:08:46,59 root INFO 
id:et_en cur r: 0.6228 best r: 0.6228
15:08:59,28 root INFO 
id:si_en cur r: 0.4369 best r: 0.4369
15:09:24,844 root INFO 
id:ru_en cur r: 0.6848 best r: 0.6848
15:09:24,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:55,288 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:10:55,294 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:10:55,298 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:10:55,304 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:10:55,309 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:10:55,314 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:10:55,319 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:11:08,260 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6967
en_de Dev loss: 0.9950 r:0.1365
en_zh Dev loss: 0.8046 r:0.3284
ro_en Dev loss: 0.4727 r:0.7136
et_en Dev loss: 0.4418 r:0.6317
si_en Dev loss: 0.7781 r:0.4750
ne_en Dev loss: 0.6371 r:0.5742
ru_en Dev loss: 0.4652 r:0.7099
Current avg r:0.5099 Best avg r: 0.5099
15:15:39,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:09,783 root INFO 
id:ne_en cur r: 0.5926 best r: 0.5926
15:17:22,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:52,959 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:18:52,966 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:18:52,971 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:18:52,976 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:18:52,981 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:18:52,985 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:18:52,990 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:19:05,939 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6422
en_de Dev loss: 1.0165 r:0.1279
en_zh Dev loss: 0.8406 r:0.3572
ro_en Dev loss: 0.5269 r:0.7145
et_en Dev loss: 0.4738 r:0.6289
si_en Dev loss: 0.8606 r:0.4835
ne_en Dev loss: 0.6344 r:0.6135
ru_en Dev loss: 0.6254 r:0.6501
Current avg r:0.5108 Best avg r: 0.5108
15:23:37,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:50,415 root INFO 
id:en_de cur r: 0.1168 best r: 0.1168
15:24:16,200 root INFO 
id:ro_en cur r: 0.7019 best r: 0.7019
15:24:29,129 root INFO 
id:et_en cur r: 0.6256 best r: 0.6256
15:24:42,76 root INFO 
id:si_en cur r: 0.4549 best r: 0.4549
15:25:07,949 root INFO 
id:ne_en cur r: 0.6208 best r: 0.6208
15:25:20,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:51,115 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:26:51,121 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:26:51,125 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:26:51,129 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:26:51,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:26:51,138 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:26:51,143 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:27:04,89 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6188
en_de Dev loss: 0.9949 r:0.1393
en_zh Dev loss: 0.8737 r:0.3480
ro_en Dev loss: 0.5155 r:0.7175
et_en Dev loss: 0.4269 r:0.6524
si_en Dev loss: 0.8131 r:0.4969
ne_en Dev loss: 0.5433 r:0.6400
ru_en Dev loss: 0.5777 r:0.6640
Current avg r:0.5226 Best avg r: 0.5226
15:31:37,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:50,412 root INFO 
id:en_de cur r: 0.1578 best r: 0.1578
15:32:03,361 root INFO 
id:en_zh cur r: 0.3868 best r: 0.3868
15:32:16,342 root INFO 
id:ro_en cur r: 0.7271 best r: 0.7271
15:32:29,329 root INFO 
id:et_en cur r: 0.6524 best r: 0.6524
15:32:42,356 root INFO 
id:si_en cur r: 0.5073 best r: 0.5073
15:33:08,391 root INFO 
id:ne_en cur r: 0.6618 best r: 0.6618
15:33:21,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:52,122 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:34:52,128 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:34:52,133 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:34:52,137 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:34:52,142 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:34:52,147 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:34:52,152 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:35:05,159 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6524
en_de Dev loss: 0.8657 r:0.1958
en_zh Dev loss: 0.7788 r:0.3842
ro_en Dev loss: 0.4521 r:0.7427
et_en Dev loss: 0.4082 r:0.6606
si_en Dev loss: 0.7582 r:0.5220
ne_en Dev loss: 0.5348 r:0.6665
ru_en Dev loss: 0.5642 r:0.6476
Current avg r:0.5456 Best avg r: 0.5456
15:39:38,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:51,462 root INFO 
id:en_de cur r: 0.1815 best r: 0.1815
15:40:04,426 root INFO 
id:en_zh cur r: 0.4143 best r: 0.4143
15:40:17,419 root INFO 
id:ro_en cur r: 0.7494 best r: 0.7494
15:40:30,448 root INFO 
id:et_en cur r: 0.6693 best r: 0.6693
15:40:43,459 root INFO 
id:si_en cur r: 0.5216 best r: 0.5216
15:41:09,506 root INFO 
id:ne_en cur r: 0.6838 best r: 0.6838
15:41:22,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:53,284 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:42:53,290 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:42:53,296 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:42:53,300 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:42:53,305 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:42:53,310 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:42:53,315 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:43:06,334 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5976
en_de Dev loss: 0.8751 r:0.2007
en_zh Dev loss: 0.7242 r:0.4217
ro_en Dev loss: 0.4204 r:0.7529
et_en Dev loss: 0.3857 r:0.6751
si_en Dev loss: 0.7390 r:0.5416
ne_en Dev loss: 0.4605 r:0.6921
ru_en Dev loss: 0.4924 r:0.7013
Current avg r:0.5693 Best avg r: 0.5693
15:47:40,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:53,72 root INFO 
id:en_de cur r: 0.2052 best r: 0.2052
15:48:06,49 root INFO 
id:en_zh cur r: 0.4292 best r: 0.4292
15:48:19,46 root INFO 
id:ro_en cur r: 0.7688 best r: 0.7688
15:48:32,75 root INFO 
id:et_en cur r: 0.6876 best r: 0.6876
15:48:45,123 root INFO 
id:si_en cur r: 0.5721 best r: 0.5721
15:49:11,195 root INFO 
id:ne_en cur r: 0.7162 best r: 0.7162
15:49:24,114 root INFO 
id:ru_en cur r: 0.7168 best r: 0.7168
15:49:24,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:55,41 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:50:55,47 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:50:55,52 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:50:55,57 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:50:55,62 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:50:55,66 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:50:55,71 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:51:08,82 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5691
en_de Dev loss: 0.8873 r:0.2025
en_zh Dev loss: 0.7225 r:0.4230
ro_en Dev loss: 0.3868 r:0.7680
et_en Dev loss: 0.3732 r:0.6928
si_en Dev loss: 0.5912 r:0.5803
ne_en Dev loss: 0.3980 r:0.7233
ru_en Dev loss: 0.4458 r:0.7235
Current avg r:0.5876 Best avg r: 0.5876
15:55:42,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:55,693 root INFO 
id:en_de cur r: 0.2086 best r: 0.2086
15:57:13,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:44,586 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:58:44,593 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:58:44,599 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:58:44,603 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:58:44,609 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:58:44,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:58:44,619 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:58:57,634 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5744
en_de Dev loss: 0.8474 r:0.2242
en_zh Dev loss: 0.7230 r:0.4179
ro_en Dev loss: 0.3673 r:0.7743
et_en Dev loss: 0.3773 r:0.6867
si_en Dev loss: 0.6118 r:0.5704
ne_en Dev loss: 0.4164 r:0.7162
ru_en Dev loss: 0.4864 r:0.7250
Current avg r:0.5878 Best avg r: 0.5878
16:03:31,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:57,616 root INFO 
id:en_zh cur r: 0.4392 best r: 0.4392
16:04:10,598 root INFO 
id:ro_en cur r: 0.7918 best r: 0.7918
16:05:02,695 root INFO 
id:ne_en cur r: 0.7248 best r: 0.7248
16:05:15,613 root INFO 
id:ru_en cur r: 0.7346 best r: 0.7346
16:05:15,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:46,466 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:06:46,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:06:46,477 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:06:46,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:06:46,486 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:06:46,491 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:06:46,496 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:06:59,512 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5850
en_de Dev loss: 0.8826 r:0.2159
en_zh Dev loss: 0.7404 r:0.4334
ro_en Dev loss: 0.3857 r:0.7928
et_en Dev loss: 0.3822 r:0.6953
si_en Dev loss: 0.7729 r:0.5677
ne_en Dev loss: 0.5419 r:0.7212
ru_en Dev loss: 0.4347 r:0.7477
Current avg r:0.5963 Best avg r: 0.5963
16:11:33,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:46,871 root INFO 
id:en_de cur r: 0.2140 best r: 0.2140
16:12:25,826 root INFO 
id:et_en cur r: 0.6899 best r: 0.6899
16:12:38,850 root INFO 
id:si_en cur r: 0.5810 best r: 0.5810
16:13:04,874 root INFO 
id:ne_en cur r: 0.7255 best r: 0.7255
16:13:17,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:48,620 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:14:48,627 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:14:48,631 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:14:48,638 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:14:48,643 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:14:48,648 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:14:48,653 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:15:01,662 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5705
en_de Dev loss: 0.8646 r:0.2139
en_zh Dev loss: 0.7468 r:0.4321
ro_en Dev loss: 0.3931 r:0.7840
et_en Dev loss: 0.3699 r:0.6983
si_en Dev loss: 0.6086 r:0.5893
ne_en Dev loss: 0.4537 r:0.7286
ru_en Dev loss: 0.4588 r:0.7408
Current avg r:0.5981 Best avg r: 0.5981
16:19:36,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:49,900 root INFO 
id:en_de cur r: 0.2484 best r: 0.2484
16:20:02,900 root INFO 
id:en_zh cur r: 0.4400 best r: 0.4400
16:20:15,917 root INFO 
id:ro_en cur r: 0.7962 best r: 0.7962
16:20:28,952 root INFO 
id:et_en cur r: 0.7006 best r: 0.7006
16:21:08,108 root INFO 
id:ne_en cur r: 0.7342 best r: 0.7342
16:21:21,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:52,111 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:22:52,118 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:22:52,125 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:22:52,130 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:22:52,135 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:22:52,140 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:22:52,145 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:23:05,191 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5615
en_de Dev loss: 0.8590 r:0.2400
en_zh Dev loss: 0.6835 r:0.4421
ro_en Dev loss: 0.3579 r:0.8004
et_en Dev loss: 0.3639 r:0.7053
si_en Dev loss: 0.7643 r:0.5821
ne_en Dev loss: 0.4463 r:0.7370
ru_en Dev loss: 0.4837 r:0.7360
Current avg r:0.6061 Best avg r: 0.6061
16:27:40,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:11,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:42,39 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5867
en_de Dev loss: 0.8658 r:0.2343
en_zh Dev loss: 0.7991 r:0.4383
ro_en Dev loss: 0.3992 r:0.7976
et_en Dev loss: 0.4310 r:0.6787
si_en Dev loss: 0.8159 r:0.5693
ne_en Dev loss: 0.6157 r:0.7240
ru_en Dev loss: 0.5266 r:0.7125
Current avg r:0.5935 Best avg r: 0.6061
16:35:16,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:42,825 root INFO 
id:en_zh cur r: 0.4570 best r: 0.4570
16:35:55,832 root INFO 
id:ro_en cur r: 0.8041 best r: 0.8041
16:36:21,879 root INFO 
id:si_en cur r: 0.5936 best r: 0.5936
16:36:47,952 root INFO 
id:ne_en cur r: 0.7420 best r: 0.7420
16:37:00,890 root INFO 
id:ru_en cur r: 0.7396 best r: 0.7396
16:37:00,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:31,842 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:38:31,848 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:38:31,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:38:31,858 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:38:31,864 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:38:31,869 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:38:31,873 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:38:44,893 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5588
en_de Dev loss: 0.8362 r:0.2448
en_zh Dev loss: 0.6754 r:0.4638
ro_en Dev loss: 0.3248 r:0.8071
et_en Dev loss: 0.3601 r:0.7009
si_en Dev loss: 0.5946 r:0.6028
ne_en Dev loss: 0.3930 r:0.7473
ru_en Dev loss: 0.3830 r:0.7494
Current avg r:0.6166 Best avg r: 0.6166
16:43:21,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:47,324 root INFO 
id:en_zh cur r: 0.4703 best r: 0.4703
16:44:00,336 root INFO 
id:ro_en cur r: 0.8151 best r: 0.8151
16:44:13,363 root INFO 
id:et_en cur r: 0.7053 best r: 0.7053
16:44:26,387 root INFO 
id:si_en cur r: 0.5973 best r: 0.5973
16:44:52,459 root INFO 
id:ne_en cur r: 0.7478 best r: 0.7478
16:45:05,432 root INFO 
id:ru_en cur r: 0.7609 best r: 0.7609
16:45:05,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:36,382 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:46:36,388 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:46:36,393 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:46:36,398 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:46:36,403 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:46:36,409 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:46:36,414 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:46:49,436 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5490
en_de Dev loss: 0.8592 r:0.2560
en_zh Dev loss: 0.6849 r:0.4669
ro_en Dev loss: 0.3175 r:0.8120
et_en Dev loss: 0.3536 r:0.7114
si_en Dev loss: 0.6039 r:0.6011
ne_en Dev loss: 0.4140 r:0.7515
ru_en Dev loss: 0.3760 r:0.7640
Current avg r:0.6233 Best avg r: 0.6233
16:51:24,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:52:55,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:26,582 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5423
en_de Dev loss: 0.8425 r:0.2734
en_zh Dev loss: 0.7089 r:0.4630
ro_en Dev loss: 0.3333 r:0.8137
et_en Dev loss: 0.3670 r:0.6992
si_en Dev loss: 0.6862 r:0.5883
ne_en Dev loss: 0.4315 r:0.7473
ru_en Dev loss: 0.4168 r:0.7483
Current avg r:0.6190 Best avg r: 0.6233
16:58:59,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:12,88 root INFO 
id:en_de cur r: 0.2630 best r: 0.2630
17:00:29,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:59,952 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5325
en_de Dev loss: 0.8275 r:0.2872
en_zh Dev loss: 0.7268 r:0.4509
ro_en Dev loss: 0.3431 r:0.8096
et_en Dev loss: 0.3636 r:0.7038
si_en Dev loss: 0.6218 r:0.5947
ne_en Dev loss: 0.3914 r:0.7497
ru_en Dev loss: 0.4127 r:0.7593
Current avg r:0.6222 Best avg r: 0.6233
17:06:31,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:02,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:32,470 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5175
en_de Dev loss: 0.8725 r:0.2498
en_zh Dev loss: 0.7715 r:0.4712
ro_en Dev loss: 0.4251 r:0.8106
et_en Dev loss: 0.3916 r:0.6955
si_en Dev loss: 0.9423 r:0.5785
ne_en Dev loss: 0.6586 r:0.7413
ru_en Dev loss: 0.5032 r:0.7317
Current avg r:0.6112 Best avg r: 0.6233
17:14:04,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:30,694 root INFO 
id:en_zh cur r: 0.4805 best r: 0.4805
17:15:35,291 root INFO 
id:ne_en cur r: 0.7481 best r: 0.7481
17:15:48,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:18,602 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4887
en_de Dev loss: 0.8387 r:0.2708
en_zh Dev loss: 0.7098 r:0.4764
ro_en Dev loss: 0.3734 r:0.8145
et_en Dev loss: 0.3889 r:0.6973
si_en Dev loss: 0.7102 r:0.5982
ne_en Dev loss: 0.4876 r:0.7518
ru_en Dev loss: 0.5046 r:0.7305
Current avg r:0.6199 Best avg r: 0.6233
17:21:51,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:17,100 root INFO 
id:en_zh cur r: 0.4902 best r: 0.4902
17:22:29,983 root INFO 
id:ro_en cur r: 0.8268 best r: 0.8268
17:22:42,894 root INFO 
id:et_en cur r: 0.7054 best r: 0.7054
17:22:55,817 root INFO 
id:si_en cur r: 0.6210 best r: 0.6210
17:23:21,698 root INFO 
id:ne_en cur r: 0.7508 best r: 0.7508
17:23:34,584 root INFO 
id:ru_en cur r: 0.7732 best r: 0.7732
17:23:34,584 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:04,867 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:25:04,874 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:25:04,880 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:25:04,887 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:25:04,891 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:25:04,897 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:25:04,901 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:25:17,852 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4961
en_de Dev loss: 0.8346 r:0.2628
en_zh Dev loss: 0.6893 r:0.4840
ro_en Dev loss: 0.3001 r:0.8253
et_en Dev loss: 0.3688 r:0.7081
si_en Dev loss: 0.5496 r:0.6236
ne_en Dev loss: 0.3493 r:0.7516
ru_en Dev loss: 0.3598 r:0.7721
Current avg r:0.6325 Best avg r: 0.6325
17:29:48,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:19,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:49,427 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4776
en_de Dev loss: 0.8396 r:0.2548
en_zh Dev loss: 0.6672 r:0.4813
ro_en Dev loss: 0.3146 r:0.8160
et_en Dev loss: 0.3782 r:0.6909
si_en Dev loss: 0.7056 r:0.5996
ne_en Dev loss: 0.4448 r:0.7499
ru_en Dev loss: 0.4333 r:0.7446
Current avg r:0.6196 Best avg r: 0.6325
17:37:20,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:50,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:21,109 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4930
en_de Dev loss: 0.8398 r:0.2500
en_zh Dev loss: 0.6997 r:0.4832
ro_en Dev loss: 0.3148 r:0.8192
et_en Dev loss: 0.3654 r:0.7061
si_en Dev loss: 0.7131 r:0.6023
ne_en Dev loss: 0.4399 r:0.7512
ru_en Dev loss: 0.4301 r:0.7455
Current avg r:0.6225 Best avg r: 0.6325
17:44:52,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:22,527 root INFO 
id:ne_en cur r: 0.7583 best r: 0.7583
17:46:35,402 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:05,771 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4855
en_de Dev loss: 0.8443 r:0.2587
en_zh Dev loss: 0.6869 r:0.4785
ro_en Dev loss: 0.3502 r:0.8181
et_en Dev loss: 0.3657 r:0.7097
si_en Dev loss: 0.6973 r:0.6092
ne_en Dev loss: 0.4342 r:0.7592
ru_en Dev loss: 0.4509 r:0.7426
Current avg r:0.6252 Best avg r: 0.6325
17:52:37,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:02,928 root INFO 
id:en_zh cur r: 0.4976 best r: 0.4976
17:54:07,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:37,519 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4933
en_de Dev loss: 0.8299 r:0.2535
en_zh Dev loss: 0.6761 r:0.4915
ro_en Dev loss: 0.3509 r:0.8185
et_en Dev loss: 0.3887 r:0.7061
si_en Dev loss: 0.6213 r:0.6216
ne_en Dev loss: 0.4063 r:0.7588
ru_en Dev loss: 0.4072 r:0.7642
Current avg r:0.6306 Best avg r: 0.6325
18:00:08,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:38,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:09,136 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4945
en_de Dev loss: 0.8415 r:0.2331
en_zh Dev loss: 0.6632 r:0.4883
ro_en Dev loss: 0.3419 r:0.8129
et_en Dev loss: 0.3826 r:0.7002
si_en Dev loss: 0.7398 r:0.6024
ne_en Dev loss: 0.4739 r:0.7536
ru_en Dev loss: 0.4349 r:0.7414
Current avg r:0.6189 Best avg r: 0.6325
18:07:40,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:10,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:40,956 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4807
en_de Dev loss: 0.8395 r:0.2360
en_zh Dev loss: 0.6657 r:0.4846
ro_en Dev loss: 0.3214 r:0.8105
et_en Dev loss: 0.3764 r:0.6966
si_en Dev loss: 0.6696 r:0.6038
ne_en Dev loss: 0.4317 r:0.7460
ru_en Dev loss: 0.4216 r:0.7388
Current avg r:0.6166 Best avg r: 0.6325
18:15:12,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:42,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:12,693 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4693
en_de Dev loss: 0.8395 r:0.2375
en_zh Dev loss: 0.6566 r:0.4836
ro_en Dev loss: 0.3055 r:0.8207
et_en Dev loss: 0.3708 r:0.7080
si_en Dev loss: 0.5630 r:0.6180
ne_en Dev loss: 0.3739 r:0.7584
ru_en Dev loss: 0.4119 r:0.7442
Current avg r:0.6243 Best avg r: 0.6325
18:22:43,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:47,800 root INFO 
id:si_en cur r: 0.6243 best r: 0.6243
18:24:13,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:43,805 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4646
en_de Dev loss: 0.8519 r:0.2392
en_zh Dev loss: 0.6659 r:0.4801
ro_en Dev loss: 0.3186 r:0.8225
et_en Dev loss: 0.3799 r:0.7084
si_en Dev loss: 0.5933 r:0.6185
ne_en Dev loss: 0.3947 r:0.7601
ru_en Dev loss: 0.4232 r:0.7398
Current avg r:0.6241 Best avg r: 0.6325
18:30:14,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:44,599 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:14,775 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4761
en_de Dev loss: 0.8565 r:0.2172
en_zh Dev loss: 0.6682 r:0.4821
ro_en Dev loss: 0.3324 r:0.8129
et_en Dev loss: 0.3629 r:0.7065
si_en Dev loss: 0.5980 r:0.6118
ne_en Dev loss: 0.4091 r:0.7583
ru_en Dev loss: 0.4126 r:0.7342
Current avg r:0.6176 Best avg r: 0.6325
18:37:46,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:17,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:47,392 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4390
en_de Dev loss: 0.8674 r:0.2256
en_zh Dev loss: 0.7429 r:0.4850
ro_en Dev loss: 0.4112 r:0.8094
et_en Dev loss: 0.4124 r:0.6941
si_en Dev loss: 0.7455 r:0.6037
ne_en Dev loss: 0.6048 r:0.7448
ru_en Dev loss: 0.5206 r:0.7212
Current avg r:0.6120 Best avg r: 0.6325
18:45:18,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:49,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:19,154 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4755
en_de Dev loss: 0.8323 r:0.2561
en_zh Dev loss: 0.6690 r:0.4864
ro_en Dev loss: 0.3498 r:0.8168
et_en Dev loss: 0.3882 r:0.7033
si_en Dev loss: 0.6545 r:0.6165
ne_en Dev loss: 0.4115 r:0.7491
ru_en Dev loss: 0.4657 r:0.7293
Current avg r:0.6225 Best avg r: 0.6325
18:52:49,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:19,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:49,916 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4720
en_de Dev loss: 0.8501 r:0.2186
en_zh Dev loss: 0.7355 r:0.4737
ro_en Dev loss: 0.3500 r:0.8122
et_en Dev loss: 0.3845 r:0.6977
si_en Dev loss: 0.6257 r:0.6187
ne_en Dev loss: 0.4500 r:0.7507
ru_en Dev loss: 0.4556 r:0.7279
Current avg r:0.6142 Best avg r: 0.6325
19:00:21,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:51,466 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:21,714 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4511
en_de Dev loss: 0.8499 r:0.2222
en_zh Dev loss: 0.7013 r:0.4840
ro_en Dev loss: 0.3450 r:0.8175
et_en Dev loss: 0.3845 r:0.7032
si_en Dev loss: 0.6554 r:0.6132
ne_en Dev loss: 0.4470 r:0.7574
ru_en Dev loss: 0.4095 r:0.7457
Current avg r:0.6205 Best avg r: 0.6325
19:07:53,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:23,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:53,571 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4435
en_de Dev loss: 0.8503 r:0.2078
en_zh Dev loss: 0.7085 r:0.4836
ro_en Dev loss: 0.3108 r:0.8220
et_en Dev loss: 0.3845 r:0.6937
si_en Dev loss: 0.8017 r:0.6100
ne_en Dev loss: 0.4124 r:0.7494
ru_en Dev loss: 0.4500 r:0.7353
Current avg r:0.6146 Best avg r: 0.6325
19:15:24,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:54,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:24,640 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4247
en_de Dev loss: 0.8376 r:0.2407
en_zh Dev loss: 0.7167 r:0.4806
ro_en Dev loss: 0.3465 r:0.8155
et_en Dev loss: 0.3952 r:0.6963
si_en Dev loss: 0.7303 r:0.6153
ne_en Dev loss: 0.4259 r:0.7529
ru_en Dev loss: 0.4102 r:0.7493
Current avg r:0.6215 Best avg r: 0.6325
19:22:55,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:59,852 root INFO 
id:si_en cur r: 0.6260 best r: 0.6260
19:24:25,678 root INFO 
id:ne_en cur r: 0.7610 best r: 0.7610
19:24:38,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:08,729 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4164
en_de Dev loss: 0.8470 r:0.2449
en_zh Dev loss: 0.6699 r:0.4937
ro_en Dev loss: 0.3364 r:0.8221
et_en Dev loss: 0.3842 r:0.7027
si_en Dev loss: 0.6204 r:0.6232
ne_en Dev loss: 0.4059 r:0.7607
ru_en Dev loss: 0.4147 r:0.7459
Current avg r:0.6276 Best avg r: 0.6325
19:30:40,319 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:31:18,992 root INFO 
id:ro_en cur r: 0.8272 best r: 0.8272
19:31:31,908 root INFO 
id:et_en cur r: 0.7063 best r: 0.7063
19:32:10,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:40,811 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4227
en_de Dev loss: 0.8578 r:0.2490
en_zh Dev loss: 0.7220 r:0.4832
ro_en Dev loss: 0.3304 r:0.8243
et_en Dev loss: 0.3746 r:0.7073
si_en Dev loss: 0.6112 r:0.6226
ne_en Dev loss: 0.3971 r:0.7540
ru_en Dev loss: 0.4382 r:0.7428
Current avg r:0.6262 Best avg r: 0.6325
19:38:11,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:24,382 root INFO 
id:en_de cur r: 0.2776 best r: 0.2776
19:39:41,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:11,822 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4393
en_de Dev loss: 0.8310 r:0.2694
en_zh Dev loss: 0.6969 r:0.4781
ro_en Dev loss: 0.3319 r:0.8171
et_en Dev loss: 0.4024 r:0.6986
si_en Dev loss: 0.5995 r:0.6134
ne_en Dev loss: 0.4186 r:0.7541
ru_en Dev loss: 0.4101 r:0.7421
Current avg r:0.6247 Best avg r: 0.6325
19:45:42,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:12,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:42,648 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4467
en_de Dev loss: 0.8276 r:0.2689
en_zh Dev loss: 0.6955 r:0.4781
ro_en Dev loss: 0.3352 r:0.8151
et_en Dev loss: 0.4019 r:0.7002
si_en Dev loss: 0.6406 r:0.6081
ne_en Dev loss: 0.4045 r:0.7534
ru_en Dev loss: 0.4058 r:0.7445
Current avg r:0.6240 Best avg r: 0.6325
19:53:13,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:04,860 root INFO 
id:et_en cur r: 0.7068 best r: 0.7068
19:54:43,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:13,664 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4219
en_de Dev loss: 0.8581 r:0.2606
en_zh Dev loss: 0.7297 r:0.4784
ro_en Dev loss: 0.3314 r:0.8202
et_en Dev loss: 0.3690 r:0.7038
si_en Dev loss: 0.7650 r:0.6038
ne_en Dev loss: 0.4908 r:0.7541
ru_en Dev loss: 0.4687 r:0.7267
Current avg r:0.6211 Best avg r: 0.6325
20:00:44,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:56,998 root INFO 
id:en_de cur r: 0.2828 best r: 0.2828
20:02:14,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:44,447 root INFO Epoch 2 Global steps: 29400 Train loss: 0.4103
en_de Dev loss: 0.8260 r:0.2680
en_zh Dev loss: 0.6895 r:0.4852
ro_en Dev loss: 0.3298 r:0.8222
et_en Dev loss: 0.3827 r:0.7028
si_en Dev loss: 0.7193 r:0.6011
ne_en Dev loss: 0.4415 r:0.7496
ru_en Dev loss: 0.4015 r:0.7469
Current avg r:0.6251 Best avg r: 0.6325
20:08:15,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:45,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:15,894 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3991
en_de Dev loss: 0.8512 r:0.2449
en_zh Dev loss: 0.7104 r:0.4669
ro_en Dev loss: 0.3322 r:0.8187
et_en Dev loss: 0.3912 r:0.7004
si_en Dev loss: 0.6301 r:0.6075
ne_en Dev loss: 0.3826 r:0.7500
ru_en Dev loss: 0.3938 r:0.7505
Current avg r:0.6199 Best avg r: 0.6325
20:15:47,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:17,712 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:47,794 root INFO Epoch 2 Global steps: 30800 Train loss: 0.4072
en_de Dev loss: 0.8450 r:0.2310
en_zh Dev loss: 0.6848 r:0.4869
ro_en Dev loss: 0.3553 r:0.8169
et_en Dev loss: 0.4039 r:0.6943
si_en Dev loss: 0.7422 r:0.6031
ne_en Dev loss: 0.4385 r:0.7419
ru_en Dev loss: 0.4454 r:0.7297
Current avg r:0.6148 Best avg r: 0.6325
20:23:18,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:48,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:19,145 root INFO Epoch 2 Global steps: 31500 Train loss: 0.4153
en_de Dev loss: 0.8553 r:0.2050
en_zh Dev loss: 0.7110 r:0.4760
ro_en Dev loss: 0.3598 r:0.8128
et_en Dev loss: 0.4027 r:0.6872
si_en Dev loss: 0.7702 r:0.5934
ne_en Dev loss: 0.6011 r:0.7402
ru_en Dev loss: 0.5036 r:0.6976
Current avg r:0.6018 Best avg r: 0.6325
20:30:51,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:21,752 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:51,977 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3932
en_de Dev loss: 0.8590 r:0.2100
en_zh Dev loss: 0.6896 r:0.4788
ro_en Dev loss: 0.3264 r:0.8197
et_en Dev loss: 0.3882 r:0.6952
si_en Dev loss: 0.6085 r:0.6136
ne_en Dev loss: 0.4149 r:0.7356
ru_en Dev loss: 0.4708 r:0.7023
Current avg r:0.6079 Best avg r: 0.6325
20:38:23,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:53,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:23,720 root INFO Epoch 3 Global steps: 32900 Train loss: 0.4053
en_de Dev loss: 0.8466 r:0.2306
en_zh Dev loss: 0.7562 r:0.4703
ro_en Dev loss: 0.3659 r:0.8179
et_en Dev loss: 0.4120 r:0.6817
si_en Dev loss: 0.9074 r:0.5917
ne_en Dev loss: 0.7027 r:0.7347
ru_en Dev loss: 0.5514 r:0.6809
Current avg r:0.6011 Best avg r: 0.6325
20:45:54,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:24,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:54,811 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3816
en_de Dev loss: 0.8396 r:0.2459
en_zh Dev loss: 0.6766 r:0.4737
ro_en Dev loss: 0.2959 r:0.8213
et_en Dev loss: 0.3827 r:0.6933
si_en Dev loss: 0.6600 r:0.6068
ne_en Dev loss: 0.4212 r:0.7395
ru_en Dev loss: 0.4520 r:0.7180
Current avg r:0.6141 Best avg r: 0.6325
20:53:25,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:55,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:26,145 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3908
en_de Dev loss: 0.8396 r:0.2665
en_zh Dev loss: 0.7177 r:0.4774
ro_en Dev loss: 0.3488 r:0.8185
et_en Dev loss: 0.4029 r:0.6897
si_en Dev loss: 0.7890 r:0.5999
ne_en Dev loss: 0.5155 r:0.7400
ru_en Dev loss: 0.4993 r:0.7144
Current avg r:0.6152 Best avg r: 0.6325
21:00:56,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:27,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:57,290 root INFO Epoch 3 Global steps: 35000 Train loss: 0.4009
en_de Dev loss: 0.8444 r:0.2457
en_zh Dev loss: 0.6981 r:0.4879
ro_en Dev loss: 0.3466 r:0.8178
et_en Dev loss: 0.4054 r:0.6863
si_en Dev loss: 0.7053 r:0.6005
ne_en Dev loss: 0.5334 r:0.7302
ru_en Dev loss: 0.4701 r:0.7094
Current avg r:0.6111 Best avg r: 0.6325
21:08:29,56 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:59,312 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:29,561 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3959
en_de Dev loss: 0.8525 r:0.2355
en_zh Dev loss: 0.7475 r:0.4804
ro_en Dev loss: 0.3765 r:0.8118
et_en Dev loss: 0.4308 r:0.6796
si_en Dev loss: 0.7460 r:0.5924
ne_en Dev loss: 0.5439 r:0.7272
ru_en Dev loss: 0.5366 r:0.6821
Current avg r:0.6013 Best avg r: 0.6325
21:16:01,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:31,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:01,624 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3938
en_de Dev loss: 0.8443 r:0.2505
en_zh Dev loss: 0.7034 r:0.4788
ro_en Dev loss: 0.3449 r:0.8184
et_en Dev loss: 0.4159 r:0.6898
si_en Dev loss: 0.7292 r:0.5865
ne_en Dev loss: 0.4850 r:0.7387
ru_en Dev loss: 0.4297 r:0.7310
Current avg r:0.6134 Best avg r: 0.6325
21:23:32,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:02,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:32,565 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3635
en_de Dev loss: 0.8419 r:0.2585
en_zh Dev loss: 0.6864 r:0.4828
ro_en Dev loss: 0.3341 r:0.8209
et_en Dev loss: 0.4064 r:0.6850
si_en Dev loss: 0.7115 r:0.5963
ne_en Dev loss: 0.4483 r:0.7322
ru_en Dev loss: 0.4409 r:0.7349
Current avg r:0.6158 Best avg r: 0.6325
21:31:03,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:34,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:04,212 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3568
en_de Dev loss: 0.8732 r:0.1807
en_zh Dev loss: 0.7210 r:0.4791
ro_en Dev loss: 0.3495 r:0.8199
et_en Dev loss: 0.3989 r:0.6795
si_en Dev loss: 0.8255 r:0.5886
ne_en Dev loss: 0.6402 r:0.7396
ru_en Dev loss: 0.5048 r:0.7106
Current avg r:0.5997 Best avg r: 0.6325
21:38:35,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:05,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:35,879 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3549
en_de Dev loss: 0.8559 r:0.2474
en_zh Dev loss: 0.7097 r:0.4877
ro_en Dev loss: 0.3447 r:0.8190
et_en Dev loss: 0.4263 r:0.6853
si_en Dev loss: 0.6529 r:0.6086
ne_en Dev loss: 0.4824 r:0.7455
ru_en Dev loss: 0.4889 r:0.7236
Current avg r:0.6167 Best avg r: 0.6325
21:46:06,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:36,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:06,560 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3778
en_de Dev loss: 0.8610 r:0.2266
en_zh Dev loss: 0.7773 r:0.4573
ro_en Dev loss: 0.3520 r:0.8211
et_en Dev loss: 0.4383 r:0.6945
si_en Dev loss: 0.6687 r:0.6102
ne_en Dev loss: 0.4574 r:0.7424
ru_en Dev loss: 0.4476 r:0.7471
Current avg r:0.6142 Best avg r: 0.6325
21:53:37,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:49,933 root INFO 
id:en_de cur r: 0.2988 best r: 0.2988
21:55:07,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:37,233 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3660
en_de Dev loss: 0.8180 r:0.2787
en_zh Dev loss: 0.6740 r:0.4744
ro_en Dev loss: 0.3144 r:0.8160
et_en Dev loss: 0.4052 r:0.6952
si_en Dev loss: 0.6336 r:0.6108
ne_en Dev loss: 0.4229 r:0.7401
ru_en Dev loss: 0.3867 r:0.7520
Current avg r:0.6239 Best avg r: 0.6325
22:01:07,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:37,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:07,564 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3706
en_de Dev loss: 0.8683 r:0.2555
en_zh Dev loss: 0.7488 r:0.4743
ro_en Dev loss: 0.3801 r:0.8139
et_en Dev loss: 0.4463 r:0.6795
si_en Dev loss: 0.7319 r:0.6014
ne_en Dev loss: 0.5363 r:0.7366
ru_en Dev loss: 0.4226 r:0.7532
Current avg r:0.6163 Best avg r: 0.6325
22:08:37,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:08,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:38,145 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3964
en_de Dev loss: 0.8439 r:0.2633
en_zh Dev loss: 0.7342 r:0.4786
ro_en Dev loss: 0.3609 r:0.8195
et_en Dev loss: 0.4159 r:0.6859
si_en Dev loss: 0.7886 r:0.6061
ne_en Dev loss: 0.5227 r:0.7337
ru_en Dev loss: 0.4737 r:0.7351
Current avg r:0.6175 Best avg r: 0.6325
22:16:08,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:39,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:09,206 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3591
en_de Dev loss: 0.8340 r:0.2645
en_zh Dev loss: 0.7179 r:0.4776
ro_en Dev loss: 0.3541 r:0.8156
et_en Dev loss: 0.4014 r:0.6878
si_en Dev loss: 0.7331 r:0.6074
ne_en Dev loss: 0.5124 r:0.7411
ru_en Dev loss: 0.4249 r:0.7438
Current avg r:0.6197 Best avg r: 0.6325
22:23:41,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:12,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:42,197 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3238
en_de Dev loss: 0.8420 r:0.2505
en_zh Dev loss: 0.7508 r:0.4820
ro_en Dev loss: 0.3631 r:0.8173
et_en Dev loss: 0.4441 r:0.6915
si_en Dev loss: 0.6960 r:0.6063
ne_en Dev loss: 0.4574 r:0.7344
ru_en Dev loss: 0.4136 r:0.7511
Current avg r:0.6190 Best avg r: 0.6325
22:31:12,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:43,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:13,149 root INFO Epoch 4 Global steps: 43400 Train loss: 0.3231
en_de Dev loss: 0.8520 r:0.2328
en_zh Dev loss: 0.7164 r:0.4793
ro_en Dev loss: 0.3434 r:0.8167
et_en Dev loss: 0.4093 r:0.6822
si_en Dev loss: 0.7257 r:0.5940
ne_en Dev loss: 0.4671 r:0.7370
ru_en Dev loss: 0.3896 r:0.7586
Current avg r:0.6144 Best avg r: 0.6325
22:38:43,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:14,100 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:44,207 root INFO Epoch 4 Global steps: 44100 Train loss: 0.3263
en_de Dev loss: 0.8464 r:0.2371
en_zh Dev loss: 0.7691 r:0.4848
ro_en Dev loss: 0.3937 r:0.8155
et_en Dev loss: 0.4486 r:0.6807
si_en Dev loss: 0.7980 r:0.5892
ne_en Dev loss: 0.5576 r:0.7303
ru_en Dev loss: 0.4335 r:0.7512
Current avg r:0.6127 Best avg r: 0.6325
22:46:14,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:45,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:15,364 root INFO Epoch 4 Global steps: 44800 Train loss: 0.3373
en_de Dev loss: 0.8816 r:0.2155
en_zh Dev loss: 0.8439 r:0.4549
ro_en Dev loss: 0.4228 r:0.8138
et_en Dev loss: 0.4470 r:0.6690
si_en Dev loss: 0.9157 r:0.5765
ne_en Dev loss: 0.6744 r:0.7236
ru_en Dev loss: 0.5544 r:0.7096
Current avg r:0.5947 Best avg r: 0.6325
22:53:47,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:17,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:47,504 root INFO Epoch 4 Global steps: 45500 Train loss: 0.3058
en_de Dev loss: 0.8789 r:0.2445
en_zh Dev loss: 0.7682 r:0.4631
ro_en Dev loss: 0.3651 r:0.8172
et_en Dev loss: 0.4323 r:0.6722
si_en Dev loss: 0.8022 r:0.5921
ne_en Dev loss: 0.4938 r:0.7371
ru_en Dev loss: 0.4282 r:0.7512
Current avg r:0.6110 Best avg r: 0.6325
23:01:18,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:48,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:18,534 root INFO Epoch 4 Global steps: 46200 Train loss: 0.3186
en_de Dev loss: 0.9059 r:0.2308
en_zh Dev loss: 0.8034 r:0.4719
ro_en Dev loss: 0.3891 r:0.8136
et_en Dev loss: 0.4617 r:0.6643
si_en Dev loss: 0.7891 r:0.5946
ne_en Dev loss: 0.5712 r:0.7275
ru_en Dev loss: 0.5078 r:0.7325
Current avg r:0.6050 Best avg r: 0.6325
23:08:49,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:19,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:50,22 root INFO Epoch 4 Global steps: 46900 Train loss: 0.3210
en_de Dev loss: 0.8458 r:0.2454
en_zh Dev loss: 0.7530 r:0.4627
ro_en Dev loss: 0.3494 r:0.8166
et_en Dev loss: 0.4354 r:0.6828
si_en Dev loss: 0.7658 r:0.5898
ne_en Dev loss: 0.5031 r:0.7259
ru_en Dev loss: 0.4304 r:0.7400
Current avg r:0.6090 Best avg r: 0.6325
23:16:20,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:50,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:20,955 root INFO Epoch 4 Global steps: 47600 Train loss: 0.3270
en_de Dev loss: 0.8442 r:0.2461
en_zh Dev loss: 0.7463 r:0.4689
ro_en Dev loss: 0.3465 r:0.8168
et_en Dev loss: 0.4396 r:0.6728
si_en Dev loss: 0.7584 r:0.5874
ne_en Dev loss: 0.5197 r:0.7340
ru_en Dev loss: 0.4109 r:0.7459
Current avg r:0.6103 Best avg r: 0.6325
23:23:51,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:21,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:51,933 root INFO Epoch 4 Global steps: 48300 Train loss: 0.3196
en_de Dev loss: 0.8494 r:0.2407
en_zh Dev loss: 0.7557 r:0.4695
ro_en Dev loss: 0.3587 r:0.8183
et_en Dev loss: 0.4442 r:0.6729
si_en Dev loss: 0.7008 r:0.5896
ne_en Dev loss: 0.5542 r:0.7276
ru_en Dev loss: 0.4507 r:0.7243
Current avg r:0.6061 Best avg r: 0.6325
23:31:23,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:53,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:34:24,126 root INFO Epoch 4 Global steps: 49000 Train loss: 0.3301
en_de Dev loss: 0.8682 r:0.2205
en_zh Dev loss: 0.7338 r:0.4719
ro_en Dev loss: 0.3699 r:0.8062
et_en Dev loss: 0.4383 r:0.6772
si_en Dev loss: 0.8110 r:0.5829
ne_en Dev loss: 0.5971 r:0.7225
ru_en Dev loss: 0.4394 r:0.7403
Current avg r:0.6031 Best avg r: 0.6325
23:38:55,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:25,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:55,463 root INFO Epoch 4 Global steps: 49700 Train loss: 0.3224
en_de Dev loss: 0.8564 r:0.2253
en_zh Dev loss: 0.7226 r:0.4733
ro_en Dev loss: 0.3364 r:0.8162
et_en Dev loss: 0.4167 r:0.6807
si_en Dev loss: 0.6768 r:0.5972
ne_en Dev loss: 0.5076 r:0.7334
ru_en Dev loss: 0.4170 r:0.7394
Current avg r:0.6094 Best avg r: 0.6325
23:46:26,196 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:56,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:26,494 root INFO Epoch 4 Global steps: 50400 Train loss: 0.3184
en_de Dev loss: 0.8864 r:0.2051
en_zh Dev loss: 0.7918 r:0.4645
ro_en Dev loss: 0.3955 r:0.8105
et_en Dev loss: 0.4551 r:0.6815
si_en Dev loss: 0.7381 r:0.5928
ne_en Dev loss: 0.5270 r:0.7336
ru_en Dev loss: 0.4350 r:0.7496
Current avg r:0.6054 Best avg r: 0.6325
23:53:57,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:27,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:57,318 root INFO Epoch 4 Global steps: 51100 Train loss: 0.3202
en_de Dev loss: 0.8588 r:0.2003
en_zh Dev loss: 0.7839 r:0.4549
ro_en Dev loss: 0.3757 r:0.8102
et_en Dev loss: 0.4560 r:0.6823
si_en Dev loss: 0.7805 r:0.5866
ne_en Dev loss: 0.4683 r:0.7278
ru_en Dev loss: 0.4190 r:0.7466
Current avg r:0.6012 Best avg r: 0.6325
00:01:28,916 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:59,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:29,331 root INFO Epoch 4 Global steps: 51800 Train loss: 0.3175
en_de Dev loss: 0.8668 r:0.2088
en_zh Dev loss: 0.7859 r:0.4564
ro_en Dev loss: 0.3803 r:0.8107
et_en Dev loss: 0.4574 r:0.6621
si_en Dev loss: 0.8227 r:0.5818
ne_en Dev loss: 0.5888 r:0.7305
ru_en Dev loss: 0.4680 r:0.7210
Current avg r:0.5959 Best avg r: 0.6325
00:09:00,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:30,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:00,765 root INFO Epoch 4 Global steps: 52500 Train loss: 0.3200
en_de Dev loss: 0.8712 r:0.2011
en_zh Dev loss: 0.7426 r:0.4745
ro_en Dev loss: 0.3602 r:0.8149
et_en Dev loss: 0.4432 r:0.6651
si_en Dev loss: 0.7477 r:0.5890
ne_en Dev loss: 0.5408 r:0.7307
ru_en Dev loss: 0.4127 r:0.7450
Current avg r:0.6029 Best avg r: 0.6325
00:16:33,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:03,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:33,540 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2912
en_de Dev loss: 0.8830 r:0.2137
en_zh Dev loss: 0.8030 r:0.4652
ro_en Dev loss: 0.4114 r:0.8063
et_en Dev loss: 0.5061 r:0.6533
si_en Dev loss: 0.8736 r:0.5681
ne_en Dev loss: 0.5733 r:0.7190
ru_en Dev loss: 0.5030 r:0.7162
Current avg r:0.5917 Best avg r: 0.6325
00:24:04,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:25:34,438 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:04,541 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2775
en_de Dev loss: 0.8582 r:0.2374
en_zh Dev loss: 0.7597 r:0.4778
ro_en Dev loss: 0.3734 r:0.8152
et_en Dev loss: 0.4507 r:0.6685
si_en Dev loss: 0.8419 r:0.5773
ne_en Dev loss: 0.6181 r:0.7204
ru_en Dev loss: 0.4459 r:0.7365
Current avg r:0.6047 Best avg r: 0.6325
00:31:35,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:33:05,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:35,423 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2921
en_de Dev loss: 0.8562 r:0.2145
en_zh Dev loss: 0.7204 r:0.4829
ro_en Dev loss: 0.3347 r:0.8196
et_en Dev loss: 0.4591 r:0.6620
si_en Dev loss: 0.7552 r:0.5805
ne_en Dev loss: 0.5126 r:0.7254
ru_en Dev loss: 0.3953 r:0.7436
Current avg r:0.6041 Best avg r: 0.6325
00:39:06,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:36,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:06,508 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2844
en_de Dev loss: 0.8550 r:0.2345
en_zh Dev loss: 0.7486 r:0.4847
ro_en Dev loss: 0.3461 r:0.8169
et_en Dev loss: 0.4698 r:0.6632
si_en Dev loss: 0.7341 r:0.5832
ne_en Dev loss: 0.4877 r:0.7191
ru_en Dev loss: 0.4159 r:0.7459
Current avg r:0.6068 Best avg r: 0.6325
00:46:37,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:07,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:37,670 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2793
en_de Dev loss: 0.8444 r:0.2442
en_zh Dev loss: 0.7488 r:0.4815
ro_en Dev loss: 0.3296 r:0.8203
et_en Dev loss: 0.4602 r:0.6767
si_en Dev loss: 0.7129 r:0.5851
ne_en Dev loss: 0.4649 r:0.7277
ru_en Dev loss: 0.3889 r:0.7577
Current avg r:0.6133 Best avg r: 0.6325
00:54:08,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:39,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:09,404 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2726
en_de Dev loss: 0.8483 r:0.2494
en_zh Dev loss: 0.7388 r:0.4712
ro_en Dev loss: 0.3425 r:0.8167
et_en Dev loss: 0.4568 r:0.6671
si_en Dev loss: 0.8050 r:0.5636
ne_en Dev loss: 0.5662 r:0.7217
ru_en Dev loss: 0.4137 r:0.7401
Current avg r:0.6043 Best avg r: 0.6325
01:01:39,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:10,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:40,186 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2711
en_de Dev loss: 0.8537 r:0.2380
en_zh Dev loss: 0.7473 r:0.4754
ro_en Dev loss: 0.3468 r:0.8182
et_en Dev loss: 0.4364 r:0.6750
si_en Dev loss: 0.7254 r:0.5824
ne_en Dev loss: 0.5195 r:0.7252
ru_en Dev loss: 0.4418 r:0.7355
Current avg r:0.6071 Best avg r: 0.6325
01:09:10,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:41,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:11,323 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2692
en_de Dev loss: 0.8325 r:0.2566
en_zh Dev loss: 0.7402 r:0.4764
ro_en Dev loss: 0.3468 r:0.8165
et_en Dev loss: 0.4628 r:0.6690
si_en Dev loss: 0.7560 r:0.5768
ne_en Dev loss: 0.4917 r:0.7283
ru_en Dev loss: 0.4182 r:0.7395
Current avg r:0.6090 Best avg r: 0.6325
01:16:41,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:18:12,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:42,211 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2566
en_de Dev loss: 0.8482 r:0.2707
en_zh Dev loss: 0.7834 r:0.4778
ro_en Dev loss: 0.3742 r:0.8151
et_en Dev loss: 0.4696 r:0.6685
si_en Dev loss: 0.8132 r:0.5723
ne_en Dev loss: 0.5467 r:0.7245
ru_en Dev loss: 0.4732 r:0.7364
Current avg r:0.6093 Best avg r: 0.6325
01:24:12,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:43,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:27:13,196 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2767
en_de Dev loss: 0.8492 r:0.2352
en_zh Dev loss: 0.8021 r:0.4638
ro_en Dev loss: 0.3780 r:0.8131
et_en Dev loss: 0.4823 r:0.6736
si_en Dev loss: 0.7969 r:0.5772
ne_en Dev loss: 0.5765 r:0.7265
ru_en Dev loss: 0.4253 r:0.7435
Current avg r:0.6047 Best avg r: 0.6325
01:31:43,797 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:33:13,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:44,131 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2583
en_de Dev loss: 0.8861 r:0.2243
en_zh Dev loss: 0.7998 r:0.4595
ro_en Dev loss: 0.3961 r:0.8045
et_en Dev loss: 0.4770 r:0.6537
si_en Dev loss: 0.8713 r:0.5653
ne_en Dev loss: 0.6196 r:0.7250
ru_en Dev loss: 0.4516 r:0.7355
Current avg r:0.5954 Best avg r: 0.6325
01:39:14,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:40:44,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:42:14,966 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2543
en_de Dev loss: 0.8644 r:0.2387
en_zh Dev loss: 0.7751 r:0.4752
ro_en Dev loss: 0.3904 r:0.8108
et_en Dev loss: 0.4751 r:0.6657
si_en Dev loss: 0.8672 r:0.5753
ne_en Dev loss: 0.5887 r:0.7264
ru_en Dev loss: 0.4497 r:0.7388
Current avg r:0.6044 Best avg r: 0.6325
01:46:45,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:48:15,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:49:46,39 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2669
en_de Dev loss: 0.8392 r:0.2405
en_zh Dev loss: 0.7255 r:0.4757
ro_en Dev loss: 0.3475 r:0.8116
et_en Dev loss: 0.4700 r:0.6564
si_en Dev loss: 0.7762 r:0.5702
ne_en Dev loss: 0.4814 r:0.7206
ru_en Dev loss: 0.4157 r:0.7403
Current avg r:0.6022 Best avg r: 0.6325
01:54:16,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:55:47,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:57:17,366 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2645
en_de Dev loss: 0.8789 r:0.2079
en_zh Dev loss: 0.7959 r:0.4625
ro_en Dev loss: 0.3977 r:0.8157
et_en Dev loss: 0.4715 r:0.6577
si_en Dev loss: 0.8941 r:0.5680
ne_en Dev loss: 0.5926 r:0.7241
ru_en Dev loss: 0.4847 r:0.7356
Current avg r:0.5959 Best avg r: 0.6325
02:01:49,73 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:03:19,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:04:50,258 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2706
en_de Dev loss: 0.8926 r:0.1918
en_zh Dev loss: 0.7842 r:0.4734
ro_en Dev loss: 0.3743 r:0.8175
et_en Dev loss: 0.4824 r:0.6643
si_en Dev loss: 0.7633 r:0.5776
ne_en Dev loss: 0.4935 r:0.7195
ru_en Dev loss: 0.4496 r:0.7351
Current avg r:0.5970 Best avg r: 0.6325
02:09:24,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:10:55,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:12:25,369 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2387
en_de Dev loss: 0.8992 r:0.1982
en_zh Dev loss: 0.8083 r:0.4759
ro_en Dev loss: 0.3901 r:0.8107
et_en Dev loss: 0.5356 r:0.6668
si_en Dev loss: 0.8087 r:0.5684
ne_en Dev loss: 0.5399 r:0.7154
ru_en Dev loss: 0.4250 r:0.7477
Current avg r:0.5976 Best avg r: 0.6325
02:16:57,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:18:27,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:58,173 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2467
en_de Dev loss: 0.8617 r:0.2036
en_zh Dev loss: 0.7858 r:0.4548
ro_en Dev loss: 0.3817 r:0.8111
et_en Dev loss: 0.4695 r:0.6549
si_en Dev loss: 0.8626 r:0.5666
ne_en Dev loss: 0.5933 r:0.7196
ru_en Dev loss: 0.4726 r:0.7264
Current avg r:0.5910 Best avg r: 0.6325
02:24:29,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:25:59,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:30,136 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2284
en_de Dev loss: 0.8739 r:0.2174
en_zh Dev loss: 0.8045 r:0.4679
ro_en Dev loss: 0.3620 r:0.8124
et_en Dev loss: 0.5028 r:0.6538
si_en Dev loss: 0.8115 r:0.5659
ne_en Dev loss: 0.5335 r:0.7180
ru_en Dev loss: 0.4555 r:0.7353
Current avg r:0.5958 Best avg r: 0.6325
02:32:02,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:33:32,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:35:02,965 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2279
en_de Dev loss: 0.8738 r:0.2359
en_zh Dev loss: 0.8003 r:0.4655
ro_en Dev loss: 0.3467 r:0.8138
et_en Dev loss: 0.4881 r:0.6617
si_en Dev loss: 0.8364 r:0.5589
ne_en Dev loss: 0.5897 r:0.7207
ru_en Dev loss: 0.4493 r:0.7402
Current avg r:0.5995 Best avg r: 0.6325
02:39:34,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:41:04,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:42:35,73 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2410
en_de Dev loss: 0.8549 r:0.2332
en_zh Dev loss: 0.8258 r:0.4513
ro_en Dev loss: 0.3940 r:0.8103
et_en Dev loss: 0.4908 r:0.6431
si_en Dev loss: 0.9770 r:0.5505
ne_en Dev loss: 0.6744 r:0.7110
ru_en Dev loss: 0.4740 r:0.7306
Current avg r:0.5900 Best avg r: 0.6325
02:47:06,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:48:37,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:50:07,427 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2516
en_de Dev loss: 0.8985 r:0.1939
en_zh Dev loss: 0.8001 r:0.4633
ro_en Dev loss: 0.4011 r:0.8131
et_en Dev loss: 0.4953 r:0.6494
si_en Dev loss: 0.9173 r:0.5569
ne_en Dev loss: 0.5509 r:0.7143
ru_en Dev loss: 0.4737 r:0.7261
Current avg r:0.5881 Best avg r: 0.6325
02:54:39,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:09,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:57:40,125 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2328
en_de Dev loss: 0.8716 r:0.2002
en_zh Dev loss: 0.7655 r:0.4740
ro_en Dev loss: 0.3599 r:0.8145
et_en Dev loss: 0.4938 r:0.6579
si_en Dev loss: 0.7831 r:0.5667
ne_en Dev loss: 0.5253 r:0.7213
ru_en Dev loss: 0.4317 r:0.7363
Current avg r:0.5958 Best avg r: 0.6325
03:02:12,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:42,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:05:12,815 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2244
en_de Dev loss: 0.8974 r:0.1951
en_zh Dev loss: 0.8567 r:0.4461
ro_en Dev loss: 0.3962 r:0.8060
et_en Dev loss: 0.5036 r:0.6367
si_en Dev loss: 1.0398 r:0.5390
ne_en Dev loss: 0.6736 r:0.7169
ru_en Dev loss: 0.5128 r:0.7092
Current avg r:0.5784 Best avg r: 0.6325
03:09:45,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:11:15,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:12:46,169 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2185
en_de Dev loss: 0.9024 r:0.1930
en_zh Dev loss: 0.7689 r:0.4640
ro_en Dev loss: 0.3779 r:0.8065
et_en Dev loss: 0.4773 r:0.6507
si_en Dev loss: 0.8088 r:0.5567
ne_en Dev loss: 0.5672 r:0.7193
ru_en Dev loss: 0.4363 r:0.7349
Current avg r:0.5893 Best avg r: 0.6325
03:17:18,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:18:48,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:20:19,34 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2284
en_de Dev loss: 0.8624 r:0.2256
en_zh Dev loss: 0.7763 r:0.4758
ro_en Dev loss: 0.3779 r:0.8106
et_en Dev loss: 0.4635 r:0.6556
si_en Dev loss: 0.9132 r:0.5580
ne_en Dev loss: 0.5952 r:0.7151
ru_en Dev loss: 0.4285 r:0.7400
Current avg r:0.5972 Best avg r: 0.6325
03:24:48,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:26:18,401 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:27:48,240 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2415
en_de Dev loss: 0.8816 r:0.2159
en_zh Dev loss: 0.8183 r:0.4613
ro_en Dev loss: 0.4076 r:0.8045
et_en Dev loss: 0.5028 r:0.6422
si_en Dev loss: 0.8819 r:0.5548
ne_en Dev loss: 0.5688 r:0.7088
ru_en Dev loss: 0.4671 r:0.7229
Current avg r:0.5872 Best avg r: 0.6325
03:32:17,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:33:47,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:35:17,513 root INFO Epoch 6 Global steps: 71400 Train loss: 0.2340
en_de Dev loss: 0.8799 r:0.1988
en_zh Dev loss: 0.7890 r:0.4734
ro_en Dev loss: 0.3663 r:0.8140
et_en Dev loss: 0.4717 r:0.6546
si_en Dev loss: 0.8087 r:0.5686
ne_en Dev loss: 0.5668 r:0.7152
ru_en Dev loss: 0.4517 r:0.7303
Current avg r:0.5935 Best avg r: 0.6325
03:39:47,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:41:17,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:42:47,719 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2264
en_de Dev loss: 0.8961 r:0.1934
en_zh Dev loss: 0.7550 r:0.4699
ro_en Dev loss: 0.3831 r:0.8058
et_en Dev loss: 0.4671 r:0.6539
si_en Dev loss: 0.8890 r:0.5503
ne_en Dev loss: 0.6081 r:0.7142
ru_en Dev loss: 0.4964 r:0.7141
Current avg r:0.5859 Best avg r: 0.6325
03:47:17,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:48:47,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:50:17,145 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2307
en_de Dev loss: 0.8819 r:0.2019
en_zh Dev loss: 0.7868 r:0.4662
ro_en Dev loss: 0.3739 r:0.8112
et_en Dev loss: 0.4921 r:0.6575
si_en Dev loss: 0.8189 r:0.5565
ne_en Dev loss: 0.5237 r:0.7184
ru_en Dev loss: 0.4752 r:0.7164
Current avg r:0.5897 Best avg r: 0.6325
03:54:46,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:56:16,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:57:46,916 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2317
en_de Dev loss: 0.9100 r:0.2046
en_zh Dev loss: 0.8018 r:0.4681
ro_en Dev loss: 0.3822 r:0.8095
et_en Dev loss: 0.4781 r:0.6542
si_en Dev loss: 0.8531 r:0.5509
ne_en Dev loss: 0.5670 r:0.7168
ru_en Dev loss: 0.4763 r:0.7239
Current avg r:0.5897 Best avg r: 0.6325
04:02:18,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:03:48,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:05:18,146 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1971
en_de Dev loss: 0.8831 r:0.2014
en_zh Dev loss: 0.7584 r:0.4795
ro_en Dev loss: 0.3765 r:0.8106
et_en Dev loss: 0.4806 r:0.6474
si_en Dev loss: 0.9187 r:0.5403
ne_en Dev loss: 0.6036 r:0.7165
ru_en Dev loss: 0.4523 r:0.7299
Current avg r:0.5894 Best avg r: 0.6325
04:09:47,454 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:11:17,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:12:47,345 root INFO Epoch 7 Global steps: 74900 Train loss: 0.2053
en_de Dev loss: 0.9078 r:0.1949
en_zh Dev loss: 0.8182 r:0.4794
ro_en Dev loss: 0.3976 r:0.8099
et_en Dev loss: 0.4994 r:0.6573
si_en Dev loss: 0.9391 r:0.5512
ne_en Dev loss: 0.5795 r:0.7182
ru_en Dev loss: 0.4689 r:0.7376
Current avg r:0.5926 Best avg r: 0.6325
04:17:16,722 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:18:46,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:20:16,664 root INFO Epoch 7 Global steps: 75600 Train loss: 0.2033
en_de Dev loss: 0.9201 r:0.1543
en_zh Dev loss: 0.8265 r:0.4671
ro_en Dev loss: 0.3865 r:0.8095
et_en Dev loss: 0.4923 r:0.6399
si_en Dev loss: 0.9829 r:0.5357
ne_en Dev loss: 0.5861 r:0.7109
ru_en Dev loss: 0.4864 r:0.7253
Current avg r:0.5775 Best avg r: 0.6325
04:24:46,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:26:15,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:27:45,808 root INFO Epoch 7 Global steps: 76300 Train loss: 0.2029
en_de Dev loss: 0.9058 r:0.2028
en_zh Dev loss: 0.8040 r:0.4698
ro_en Dev loss: 0.3949 r:0.8070
et_en Dev loss: 0.5223 r:0.6504
si_en Dev loss: 0.9233 r:0.5412
ne_en Dev loss: 0.5796 r:0.7176
ru_en Dev loss: 0.4647 r:0.7305
Current avg r:0.5885 Best avg r: 0.6325
04:32:15,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:33:45,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:35:15,548 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1968
en_de Dev loss: 0.9044 r:0.1734
en_zh Dev loss: 0.8299 r:0.4562
ro_en Dev loss: 0.3662 r:0.8135
et_en Dev loss: 0.4777 r:0.6414
si_en Dev loss: 0.8893 r:0.5462
ne_en Dev loss: 0.5923 r:0.7029
ru_en Dev loss: 0.4769 r:0.7242
Current avg r:0.5797 Best avg r: 0.6325
04:39:45,321 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:41:15,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:42:45,151 root INFO Epoch 7 Global steps: 77700 Train loss: 0.2021
en_de Dev loss: 0.9047 r:0.1750
en_zh Dev loss: 0.7966 r:0.4572
ro_en Dev loss: 0.3599 r:0.8109
et_en Dev loss: 0.4970 r:0.6475
si_en Dev loss: 0.8653 r:0.5505
ne_en Dev loss: 0.5496 r:0.7065
ru_en Dev loss: 0.4552 r:0.7231
Current avg r:0.5815 Best avg r: 0.6325
04:47:14,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:48:44,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:50:14,123 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1964
en_de Dev loss: 0.8986 r:0.1859
en_zh Dev loss: 0.8440 r:0.4588
ro_en Dev loss: 0.3891 r:0.8109
et_en Dev loss: 0.5078 r:0.6496
si_en Dev loss: 0.9330 r:0.5442
ne_en Dev loss: 0.6151 r:0.7068
ru_en Dev loss: 0.4558 r:0.7387
Current avg r:0.5850 Best avg r: 0.6325
04:54:43,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:56:13,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:57:43,290 root INFO Epoch 7 Global steps: 79100 Train loss: 0.2110
en_de Dev loss: 0.8813 r:0.1964
en_zh Dev loss: 0.7751 r:0.4607
ro_en Dev loss: 0.3604 r:0.8049
et_en Dev loss: 0.5056 r:0.6394
si_en Dev loss: 0.8599 r:0.5374
ne_en Dev loss: 0.5338 r:0.7101
ru_en Dev loss: 0.4354 r:0.7269
Current avg r:0.5823 Best avg r: 0.6325
05:02:12,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:42,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:05:12,580 root INFO Epoch 7 Global steps: 79800 Train loss: 0.2008
en_de Dev loss: 0.9130 r:0.1932
en_zh Dev loss: 0.8050 r:0.4732
ro_en Dev loss: 0.3791 r:0.8143
et_en Dev loss: 0.5122 r:0.6500
si_en Dev loss: 0.8680 r:0.5535
ne_en Dev loss: 0.5251 r:0.7171
ru_en Dev loss: 0.4449 r:0.7437
Current avg r:0.5922 Best avg r: 0.6325
05:09:41,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:11:11,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:12:41,934 root INFO Epoch 7 Global steps: 80500 Train loss: 0.2058
en_de Dev loss: 0.9085 r:0.1922
en_zh Dev loss: 0.7813 r:0.4715
ro_en Dev loss: 0.3589 r:0.8105
et_en Dev loss: 0.5078 r:0.6505
si_en Dev loss: 0.8694 r:0.5536
ne_en Dev loss: 0.5237 r:0.7121
ru_en Dev loss: 0.4087 r:0.7453
Current avg r:0.5908 Best avg r: 0.6325
05:17:11,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:18:41,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:20:11,243 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1929
en_de Dev loss: 0.9371 r:0.1898
en_zh Dev loss: 0.8357 r:0.4639
ro_en Dev loss: 0.4130 r:0.8096
et_en Dev loss: 0.5157 r:0.6495
si_en Dev loss: 0.9841 r:0.5402
ne_en Dev loss: 0.6586 r:0.7102
ru_en Dev loss: 0.5095 r:0.7251
Current avg r:0.5840 Best avg r: 0.6325
05:24:41,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:26:11,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:27:41,102 root INFO Epoch 7 Global steps: 81900 Train loss: 0.2037
en_de Dev loss: 0.9418 r:0.1694
en_zh Dev loss: 0.8065 r:0.4645
ro_en Dev loss: 0.3890 r:0.8108
et_en Dev loss: 0.5073 r:0.6424
si_en Dev loss: 0.9790 r:0.5377
ne_en Dev loss: 0.6589 r:0.7062
ru_en Dev loss: 0.5070 r:0.7294
Current avg r:0.5801 Best avg r: 0.6325
05:32:10,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:33:40,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:35:10,460 root INFO Epoch 7 Global steps: 82600 Train loss: 0.2058
en_de Dev loss: 0.8924 r:0.2051
en_zh Dev loss: 0.7635 r:0.4749
ro_en Dev loss: 0.3711 r:0.8115
et_en Dev loss: 0.4978 r:0.6504
si_en Dev loss: 0.8713 r:0.5510
ne_en Dev loss: 0.5896 r:0.7160
ru_en Dev loss: 0.4353 r:0.7346
Current avg r:0.5919 Best avg r: 0.6325
05:39:40,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:41:09,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:42:39,881 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1989
en_de Dev loss: 0.9293 r:0.1855
en_zh Dev loss: 0.8055 r:0.4685
ro_en Dev loss: 0.3948 r:0.8106
et_en Dev loss: 0.5395 r:0.6539
si_en Dev loss: 0.8952 r:0.5482
ne_en Dev loss: 0.5505 r:0.7181
ru_en Dev loss: 0.4293 r:0.7501
Current avg r:0.5907 Best avg r: 0.6325
05:47:09,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:48:39,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:50:09,259 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1955
en_de Dev loss: 0.9259 r:0.1874
en_zh Dev loss: 0.8081 r:0.4623
ro_en Dev loss: 0.4038 r:0.8071
et_en Dev loss: 0.5096 r:0.6448
si_en Dev loss: 0.9466 r:0.5384
ne_en Dev loss: 0.6294 r:0.7194
ru_en Dev loss: 0.4424 r:0.7451
Current avg r:0.5864 Best avg r: 0.6325
05:54:40,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:56:10,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:57:40,151 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1730
en_de Dev loss: 0.9593 r:0.1862
en_zh Dev loss: 0.8481 r:0.4544
ro_en Dev loss: 0.4063 r:0.8089
et_en Dev loss: 0.5198 r:0.6396
si_en Dev loss: 0.9703 r:0.5308
ne_en Dev loss: 0.6021 r:0.7144
ru_en Dev loss: 0.5113 r:0.7294
Current avg r:0.5805 Best avg r: 0.6325
06:02:09,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:39,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:09,179 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1808
en_de Dev loss: 0.9027 r:0.2045
en_zh Dev loss: 0.7856 r:0.4549
ro_en Dev loss: 0.3450 r:0.8119
et_en Dev loss: 0.5046 r:0.6557
si_en Dev loss: 0.7758 r:0.5523
ne_en Dev loss: 0.4694 r:0.7218
ru_en Dev loss: 0.4061 r:0.7452
Current avg r:0.5923 Best avg r: 0.6325
06:09:39,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:08,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:12:38,889 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1720
en_de Dev loss: 0.9179 r:0.1892
en_zh Dev loss: 0.7837 r:0.4569
ro_en Dev loss: 0.3680 r:0.8092
et_en Dev loss: 0.4691 r:0.6507
si_en Dev loss: 0.8407 r:0.5411
ne_en Dev loss: 0.5790 r:0.7164
ru_en Dev loss: 0.4782 r:0.7214
Current avg r:0.5836 Best avg r: 0.6325
06:17:08,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:18:37,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:20:07,905 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1620
en_de Dev loss: 0.9032 r:0.2011
en_zh Dev loss: 0.7748 r:0.4583
ro_en Dev loss: 0.3682 r:0.8088
et_en Dev loss: 0.4762 r:0.6497
si_en Dev loss: 0.8865 r:0.5370
ne_en Dev loss: 0.5769 r:0.7146
ru_en Dev loss: 0.4595 r:0.7259
Current avg r:0.5850 Best avg r: 0.6325
06:24:36,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:26:06,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:27:36,548 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1796
en_de Dev loss: 0.9317 r:0.1866
en_zh Dev loss: 0.8188 r:0.4608
ro_en Dev loss: 0.3917 r:0.8108
et_en Dev loss: 0.5098 r:0.6531
si_en Dev loss: 0.8805 r:0.5498
ne_en Dev loss: 0.5428 r:0.7195
ru_en Dev loss: 0.4557 r:0.7394
Current avg r:0.5886 Best avg r: 0.6325
06:32:05,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:33:35,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:35:05,280 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1740
en_de Dev loss: 0.9102 r:0.1804
en_zh Dev loss: 0.7772 r:0.4729
ro_en Dev loss: 0.3635 r:0.8127
et_en Dev loss: 0.4853 r:0.6575
si_en Dev loss: 0.8685 r:0.5499
ne_en Dev loss: 0.5012 r:0.7207
ru_en Dev loss: 0.4012 r:0.7536
Current avg r:0.5925 Best avg r: 0.6325
06:39:34,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:04,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:42:34,148 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1781
en_de Dev loss: 0.9004 r:0.1763
en_zh Dev loss: 0.7817 r:0.4624
ro_en Dev loss: 0.3716 r:0.8068
et_en Dev loss: 0.4776 r:0.6419
si_en Dev loss: 0.9610 r:0.5323
ne_en Dev loss: 0.6674 r:0.7054
ru_en Dev loss: 0.4582 r:0.7324
Current avg r:0.5797 Best avg r: 0.6325
06:47:03,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:48:33,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:50:03,96 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1749
en_de Dev loss: 0.9290 r:0.1757
en_zh Dev loss: 0.7975 r:0.4687
ro_en Dev loss: 0.3834 r:0.8063
et_en Dev loss: 0.5279 r:0.6399
si_en Dev loss: 0.9583 r:0.5350
ne_en Dev loss: 0.6341 r:0.7097
ru_en Dev loss: 0.4550 r:0.7372
Current avg r:0.5818 Best avg r: 0.6325
06:54:32,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:56:02,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:57:32,439 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1770
en_de Dev loss: 0.9330 r:0.1741
en_zh Dev loss: 0.8372 r:0.4650
ro_en Dev loss: 0.3896 r:0.8084
et_en Dev loss: 0.5202 r:0.6525
si_en Dev loss: 0.8750 r:0.5432
ne_en Dev loss: 0.5723 r:0.7110
ru_en Dev loss: 0.4908 r:0.7240
Current avg r:0.5826 Best avg r: 0.6325
07:02:01,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:03:31,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:05:01,493 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1749
en_de Dev loss: 0.9224 r:0.1769
en_zh Dev loss: 0.8028 r:0.4688
ro_en Dev loss: 0.3944 r:0.8055
et_en Dev loss: 0.4985 r:0.6420
si_en Dev loss: 0.9407 r:0.5325
ne_en Dev loss: 0.6026 r:0.7099
ru_en Dev loss: 0.4833 r:0.7233
Current avg r:0.5799 Best avg r: 0.6325
07:09:30,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:11:00,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:12:30,630 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1726
en_de Dev loss: 0.9249 r:0.1675
en_zh Dev loss: 0.8082 r:0.4587
ro_en Dev loss: 0.3815 r:0.8067
et_en Dev loss: 0.5091 r:0.6488
si_en Dev loss: 0.9042 r:0.5417
ne_en Dev loss: 0.5639 r:0.7080
ru_en Dev loss: 0.4467 r:0.7380
Current avg r:0.5813 Best avg r: 0.6325
07:16:59,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:18:29,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:00,420 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1753
en_de Dev loss: 0.9262 r:0.1796
en_zh Dev loss: 0.8338 r:0.4587
ro_en Dev loss: 0.3986 r:0.8049
et_en Dev loss: 0.5175 r:0.6409
si_en Dev loss: 0.8746 r:0.5429
ne_en Dev loss: 0.5675 r:0.7131
ru_en Dev loss: 0.4948 r:0.7226
Current avg r:0.5804 Best avg r: 0.6325
07:24:33,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:26:03,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:27:33,131 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1774
en_de Dev loss: 0.9248 r:0.1890
en_zh Dev loss: 0.8267 r:0.4687
ro_en Dev loss: 0.4015 r:0.8049
et_en Dev loss: 0.5223 r:0.6364
si_en Dev loss: 0.9914 r:0.5324
ne_en Dev loss: 0.6120 r:0.7121
ru_en Dev loss: 0.4884 r:0.7309
Current avg r:0.5821 Best avg r: 0.6325
07:32:02,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:33:33,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:35:03,365 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1675
en_de Dev loss: 0.8991 r:0.1829
en_zh Dev loss: 0.7518 r:0.4705
ro_en Dev loss: 0.3435 r:0.8127
et_en Dev loss: 0.4774 r:0.6491
si_en Dev loss: 0.8873 r:0.5386
ne_en Dev loss: 0.6044 r:0.7146
ru_en Dev loss: 0.4229 r:0.7393
Current avg r:0.5868 Best avg r: 0.6325
07:39:34,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:41:05,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:35,888 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1718
en_de Dev loss: 0.9189 r:0.1679
en_zh Dev loss: 0.8298 r:0.4579
ro_en Dev loss: 0.4113 r:0.8069
et_en Dev loss: 0.5126 r:0.6382
si_en Dev loss: 0.9507 r:0.5374
ne_en Dev loss: 0.7191 r:0.7148
ru_en Dev loss: 0.4836 r:0.7241
Current avg r:0.5782 Best avg r: 0.6325
07:47:10,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:40,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:50:11,85 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1541
en_de Dev loss: 0.9207 r:0.1720
en_zh Dev loss: 0.8283 r:0.4585
ro_en Dev loss: 0.3982 r:0.8098
et_en Dev loss: 0.5536 r:0.6342
si_en Dev loss: 0.8807 r:0.5436
ne_en Dev loss: 0.5750 r:0.7140
ru_en Dev loss: 0.4482 r:0.7352
Current avg r:0.5810 Best avg r: 0.6325
07:54:45,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:56:15,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:57:46,531 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1593
en_de Dev loss: 0.9181 r:0.1759
en_zh Dev loss: 0.8178 r:0.4485
ro_en Dev loss: 0.3763 r:0.8055
et_en Dev loss: 0.5167 r:0.6280
si_en Dev loss: 0.9078 r:0.5441
ne_en Dev loss: 0.5756 r:0.7189
ru_en Dev loss: 0.4459 r:0.7380
Current avg r:0.5798 Best avg r: 0.6325
08:02:18,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:03:49,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:05:18,994 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1575
en_de Dev loss: 0.9689 r:0.1539
en_zh Dev loss: 0.8206 r:0.4552
ro_en Dev loss: 0.3852 r:0.8077
et_en Dev loss: 0.5330 r:0.6298
si_en Dev loss: 0.9492 r:0.5398
ne_en Dev loss: 0.6159 r:0.7029
ru_en Dev loss: 0.4734 r:0.7295
Current avg r:0.5741 Best avg r: 0.6325
08:09:48,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:11:18,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:12:48,688 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1568
en_de Dev loss: 0.9295 r:0.1497
en_zh Dev loss: 0.8234 r:0.4454
ro_en Dev loss: 0.3817 r:0.8042
et_en Dev loss: 0.5022 r:0.6251
si_en Dev loss: 0.9734 r:0.5289
ne_en Dev loss: 0.6610 r:0.6932
ru_en Dev loss: 0.5230 r:0.6958
Current avg r:0.5632 Best avg r: 0.6325
08:17:18,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:18:48,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:20:18,165 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1699
en_de Dev loss: 0.9442 r:0.1797
en_zh Dev loss: 0.8054 r:0.4702
ro_en Dev loss: 0.3712 r:0.8100
et_en Dev loss: 0.5331 r:0.6462
si_en Dev loss: 0.9332 r:0.5380
ne_en Dev loss: 0.5438 r:0.7087
ru_en Dev loss: 0.4641 r:0.7347
Current avg r:0.5839 Best avg r: 0.6325
08:24:47,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:17,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:27:47,368 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1546
en_de Dev loss: 0.9306 r:0.1800
en_zh Dev loss: 0.8009 r:0.4677
ro_en Dev loss: 0.3915 r:0.8036
et_en Dev loss: 0.5197 r:0.6287
si_en Dev loss: 0.9236 r:0.5225
ne_en Dev loss: 0.5624 r:0.7118
ru_en Dev loss: 0.4372 r:0.7441
Current avg r:0.5798 Best avg r: 0.6325
08:32:16,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:33:46,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:35:16,544 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1573
en_de Dev loss: 0.9315 r:0.1709
en_zh Dev loss: 0.7843 r:0.4761
ro_en Dev loss: 0.3727 r:0.8109
et_en Dev loss: 0.5093 r:0.6415
si_en Dev loss: 0.8813 r:0.5336
ne_en Dev loss: 0.6000 r:0.7041
ru_en Dev loss: 0.4784 r:0.7290
Current avg r:0.5809 Best avg r: 0.6325
08:39:45,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:41:15,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:42:45,240 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1459
en_de Dev loss: 0.9424 r:0.1670
en_zh Dev loss: 0.8077 r:0.4576
ro_en Dev loss: 0.3652 r:0.8056
et_en Dev loss: 0.5174 r:0.6392
si_en Dev loss: 0.8774 r:0.5356
ne_en Dev loss: 0.5409 r:0.7124
ru_en Dev loss: 0.4461 r:0.7346
Current avg r:0.5789 Best avg r: 0.6325
08:47:14,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:44,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:50:14,2 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1563
en_de Dev loss: 0.9275 r:0.1697
en_zh Dev loss: 0.8212 r:0.4647
ro_en Dev loss: 0.4085 r:0.8068
et_en Dev loss: 0.5359 r:0.6423
si_en Dev loss: 0.9467 r:0.5348
ne_en Dev loss: 0.6597 r:0.7150
ru_en Dev loss: 0.4782 r:0.7355
Current avg r:0.5813 Best avg r: 0.6325
08:54:42,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:56:12,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:57:42,711 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1514
en_de Dev loss: 0.9356 r:0.1908
en_zh Dev loss: 0.8627 r:0.4590
ro_en Dev loss: 0.4142 r:0.8084
et_en Dev loss: 0.5299 r:0.6431
si_en Dev loss: 0.9691 r:0.5286
ne_en Dev loss: 0.6349 r:0.7147
ru_en Dev loss: 0.4755 r:0.7356
Current avg r:0.5829 Best avg r: 0.6325
09:02:11,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:03:41,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:05:11,341 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1455
en_de Dev loss: 0.9509 r:0.1874
en_zh Dev loss: 0.8020 r:0.4722
ro_en Dev loss: 0.3752 r:0.8136
et_en Dev loss: 0.5008 r:0.6530
si_en Dev loss: 0.8895 r:0.5339
ne_en Dev loss: 0.5975 r:0.7125
ru_en Dev loss: 0.4440 r:0.7435
Current avg r:0.5880 Best avg r: 0.6325
09:09:40,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:11:10,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:12:40,264 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1488
en_de Dev loss: 0.9070 r:0.1758
en_zh Dev loss: 0.8057 r:0.4596
ro_en Dev loss: 0.3707 r:0.8129
et_en Dev loss: 0.5289 r:0.6461
si_en Dev loss: 0.8678 r:0.5319
ne_en Dev loss: 0.5951 r:0.7084
ru_en Dev loss: 0.4347 r:0.7403
Current avg r:0.5821 Best avg r: 0.6325
09:17:10,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:40,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:20:10,54 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1471
en_de Dev loss: 0.9184 r:0.1949
en_zh Dev loss: 0.7568 r:0.4744
ro_en Dev loss: 0.3591 r:0.8121
et_en Dev loss: 0.4918 r:0.6409
si_en Dev loss: 0.8937 r:0.5327
ne_en Dev loss: 0.5586 r:0.7174
ru_en Dev loss: 0.4492 r:0.7365
Current avg r:0.5870 Best avg r: 0.6325
09:24:39,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:26:09,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:27:39,671 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1529
en_de Dev loss: 0.9362 r:0.1874
en_zh Dev loss: 0.7730 r:0.4713
ro_en Dev loss: 0.3597 r:0.8151
et_en Dev loss: 0.5005 r:0.6544
si_en Dev loss: 0.8584 r:0.5410
ne_en Dev loss: 0.5724 r:0.7176
ru_en Dev loss: 0.4252 r:0.7514
Current avg r:0.5912 Best avg r: 0.6325
09:32:09,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:33:39,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:35:09,526 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1457
en_de Dev loss: 0.9109 r:0.1683
en_zh Dev loss: 0.7895 r:0.4585
ro_en Dev loss: 0.3695 r:0.8131
et_en Dev loss: 0.4996 r:0.6470
si_en Dev loss: 0.8708 r:0.5390
ne_en Dev loss: 0.5461 r:0.7174
ru_en Dev loss: 0.4506 r:0.7354
Current avg r:0.5826 Best avg r: 0.6325
09:39:40,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:09,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:42:39,873 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1368
en_de Dev loss: 0.9220 r:0.1790
en_zh Dev loss: 0.8424 r:0.4638
ro_en Dev loss: 0.3815 r:0.8128
et_en Dev loss: 0.5177 r:0.6517
si_en Dev loss: 0.9334 r:0.5357
ne_en Dev loss: 0.6013 r:0.7105
ru_en Dev loss: 0.4705 r:0.7357
Current avg r:0.5842 Best avg r: 0.6325
09:47:09,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:39,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:50:09,651 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1300
en_de Dev loss: 0.9172 r:0.1832
en_zh Dev loss: 0.7852 r:0.4716
ro_en Dev loss: 0.3772 r:0.8105
et_en Dev loss: 0.5069 r:0.6419
si_en Dev loss: 0.9319 r:0.5355
ne_en Dev loss: 0.5797 r:0.7133
ru_en Dev loss: 0.4506 r:0.7434
Current avg r:0.5856 Best avg r: 0.6325
09:54:39,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:09,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:39,918 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1327
en_de Dev loss: 0.9415 r:0.1913
en_zh Dev loss: 0.8269 r:0.4676
ro_en Dev loss: 0.4021 r:0.8107
et_en Dev loss: 0.5530 r:0.6380
si_en Dev loss: 0.9654 r:0.5338
ne_en Dev loss: 0.6009 r:0.7140
ru_en Dev loss: 0.4797 r:0.7318
Current avg r:0.5839 Best avg r: 0.6325
10:02:09,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:03:39,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:09,508 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1352
en_de Dev loss: 0.9538 r:0.1987
en_zh Dev loss: 0.8298 r:0.4682
ro_en Dev loss: 0.3783 r:0.8119
et_en Dev loss: 0.5214 r:0.6427
si_en Dev loss: 0.8876 r:0.5394
ne_en Dev loss: 0.5943 r:0.7171
ru_en Dev loss: 0.4579 r:0.7405
Current avg r:0.5883 Best avg r: 0.6325
10:09:39,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:09,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:39,338 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1360
en_de Dev loss: 0.9266 r:0.1828
en_zh Dev loss: 0.8003 r:0.4678
ro_en Dev loss: 0.3817 r:0.8126
et_en Dev loss: 0.5130 r:0.6482
si_en Dev loss: 0.9588 r:0.5334
ne_en Dev loss: 0.5836 r:0.7110
ru_en Dev loss: 0.4567 r:0.7390
Current avg r:0.5850 Best avg r: 0.6325
10:17:09,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:39,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:09,297 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1320
en_de Dev loss: 0.9431 r:0.1786
en_zh Dev loss: 0.7909 r:0.4734
ro_en Dev loss: 0.3836 r:0.8074
et_en Dev loss: 0.5130 r:0.6491
si_en Dev loss: 0.9712 r:0.5311
ne_en Dev loss: 0.6302 r:0.7118
ru_en Dev loss: 0.5062 r:0.7254
Current avg r:0.5824 Best avg r: 0.6325
10:24:39,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:26:09,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:39,132 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1299
en_de Dev loss: 0.9295 r:0.1745
en_zh Dev loss: 0.8102 r:0.4798
ro_en Dev loss: 0.3732 r:0.8096
et_en Dev loss: 0.5087 r:0.6374
si_en Dev loss: 0.9365 r:0.5309
ne_en Dev loss: 0.5502 r:0.7117
ru_en Dev loss: 0.4738 r:0.7310
Current avg r:0.5821 Best avg r: 0.6325
10:32:08,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
