14:44:12,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:24,934 root INFO 
id:en_de cur r: 0.0835 best r: 0.0835
14:44:37,765 root INFO 
id:en_zh cur r: 0.2759 best r: 0.2759
14:45:03,492 root INFO 
id:ro_en cur r: 0.5579 best r: 0.5579
14:45:16,364 root INFO 
id:et_en cur r: 0.5373 best r: 0.5373
14:45:29,242 root INFO 
id:si_en cur r: 0.4238 best r: 0.4238
14:45:42,121 root INFO 
id:ne_en cur r: 0.5518 best r: 0.5518
14:45:54,931 root INFO 
id:ru_en cur r: 0.6109 best r: 0.6109
14:45:54,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:24,782 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
14:47:24,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:47:24,797 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:47:24,802 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
14:47:24,806 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
14:47:24,813 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:47:24,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:47:37,683 root INFO Epoch 0 Global steps: 700 Train loss: 0.8129
en_de Dev loss: 0.9316 r:0.1080
en_zh Dev loss: 0.7782 r:0.2869
ro_en Dev loss: 0.6242 r:0.6059
et_en Dev loss: 0.5220 r:0.5666
si_en Dev loss: 0.7817 r:0.4627
ne_en Dev loss: 0.5946 r:0.5487
ru_en Dev loss: 0.5558 r:0.6358
Current avg r:0.4592 Best avg r: 0.4592
14:52:06,398 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:32,48 root INFO 
id:en_zh cur r: 0.2836 best r: 0.2836
14:52:57,747 root INFO 
id:ro_en cur r: 0.6328 best r: 0.6328
14:53:10,602 root INFO 
id:et_en cur r: 0.5944 best r: 0.5944
14:53:23,469 root INFO 
id:si_en cur r: 0.4511 best r: 0.4511
14:53:36,341 root INFO 
id:ne_en cur r: 0.5889 best r: 0.5889
14:53:49,167 root INFO 
id:ru_en cur r: 0.6699 best r: 0.6699
14:53:49,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:19,68 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
14:55:19,75 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:55:19,80 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:55:19,85 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
14:55:19,90 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
14:55:19,95 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:55:19,102 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:55:31,966 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7698
en_de Dev loss: 0.9096 r:0.1096
en_zh Dev loss: 0.7402 r:0.3106
ro_en Dev loss: 0.4947 r:0.6752
et_en Dev loss: 0.4880 r:0.6150
si_en Dev loss: 0.6396 r:0.4973
ne_en Dev loss: 0.5410 r:0.5948
ru_en Dev loss: 0.4766 r:0.6975
Current avg r:0.5000 Best avg r: 0.5000
15:00:00,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:13,381 root INFO 
id:en_de cur r: 0.0913 best r: 0.0913
15:00:51,938 root INFO 
id:ro_en cur r: 0.6445 best r: 0.6445
15:01:30,551 root INFO 
id:ne_en cur r: 0.5955 best r: 0.5955
15:01:43,368 root INFO 
id:ru_en cur r: 0.6880 best r: 0.6880
15:01:43,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:13,287 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:03:13,293 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:03:13,298 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:03:13,305 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:03:13,310 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:03:13,315 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:03:13,322 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:03:26,186 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7389
en_de Dev loss: 0.9220 r:0.1302
en_zh Dev loss: 0.7644 r:0.3273
ro_en Dev loss: 0.5030 r:0.7006
et_en Dev loss: 0.4658 r:0.6261
si_en Dev loss: 0.6866 r:0.5009
ne_en Dev loss: 0.5288 r:0.6124
ru_en Dev loss: 0.4761 r:0.7204
Current avg r:0.5168 Best avg r: 0.5168
15:07:54,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:07,777 root INFO 
id:en_de cur r: 0.1091 best r: 0.1091
15:08:20,605 root INFO 
id:en_zh cur r: 0.2890 best r: 0.2890
15:08:46,336 root INFO 
id:ro_en cur r: 0.6557 best r: 0.6557
15:09:37,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:07,656 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6824
en_de Dev loss: 0.9907 r:0.1609
en_zh Dev loss: 0.7940 r:0.3524
ro_en Dev loss: 0.5188 r:0.7006
et_en Dev loss: 0.4667 r:0.6163
si_en Dev loss: 0.8103 r:0.4710
ne_en Dev loss: 0.5774 r:0.5825
ru_en Dev loss: 0.5344 r:0.6973
Current avg r:0.5116 Best avg r: 0.5168
15:15:36,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:49,206 root INFO 
id:en_de cur r: 0.1498 best r: 0.1498
15:16:02,36 root INFO 
id:en_zh cur r: 0.3075 best r: 0.3075
15:16:27,767 root INFO 
id:ro_en cur r: 0.6849 best r: 0.6849
15:17:19,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:49,88 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:18:49,96 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:18:49,101 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:18:49,106 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:18:49,113 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:18:49,121 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:18:49,128 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:19:01,989 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6591
en_de Dev loss: 1.0103 r:0.1684
en_zh Dev loss: 0.8187 r:0.3830
ro_en Dev loss: 0.4790 r:0.7353
et_en Dev loss: 0.4362 r:0.6487
si_en Dev loss: 0.7867 r:0.5004
ne_en Dev loss: 0.5790 r:0.6115
ru_en Dev loss: 0.5663 r:0.7064
Current avg r:0.5363 Best avg r: 0.5363
15:23:30,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:43,671 root INFO 
id:en_de cur r: 0.1794 best r: 0.1794
15:23:56,489 root INFO 
id:en_zh cur r: 0.3882 best r: 0.3882
15:24:22,201 root INFO 
id:ro_en cur r: 0.7238 best r: 0.7238
15:24:35,62 root INFO 
id:et_en cur r: 0.6576 best r: 0.6576
15:24:47,921 root INFO 
id:si_en cur r: 0.5097 best r: 0.5097
15:25:00,780 root INFO 
id:ne_en cur r: 0.6768 best r: 0.6768
15:25:13,589 root INFO 
id:ru_en cur r: 0.7072 best r: 0.7072
15:25:13,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:43,415 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:26:43,425 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:26:43,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:26:43,437 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:26:43,444 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:26:43,450 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:26:43,457 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:26:56,322 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6527
en_de Dev loss: 0.9197 r:0.1849
en_zh Dev loss: 0.7182 r:0.4152
ro_en Dev loss: 0.3972 r:0.7363
et_en Dev loss: 0.3869 r:0.6804
si_en Dev loss: 0.6282 r:0.5455
ne_en Dev loss: 0.4422 r:0.6777
ru_en Dev loss: 0.4541 r:0.7377
Current avg r:0.5682 Best avg r: 0.5682
15:31:24,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:50,110 root INFO 
id:en_zh cur r: 0.4232 best r: 0.4232
15:32:15,812 root INFO 
id:ro_en cur r: 0.7310 best r: 0.7310
15:32:28,666 root INFO 
id:et_en cur r: 0.6702 best r: 0.6702
15:32:41,522 root INFO 
id:si_en cur r: 0.5524 best r: 0.5524
15:32:54,387 root INFO 
id:ne_en cur r: 0.7082 best r: 0.7082
15:33:07,188 root INFO 
id:ru_en cur r: 0.7263 best r: 0.7263
15:33:07,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:36,996 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:34:37,3 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:34:37,8 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:34:37,13 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:34:37,18 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:34:37,23 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:34:37,30 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:34:49,884 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6341
en_de Dev loss: 0.8838 r:0.1916
en_zh Dev loss: 0.6642 r:0.4357
ro_en Dev loss: 0.3758 r:0.7506
et_en Dev loss: 0.3782 r:0.6939
si_en Dev loss: 0.5584 r:0.5727
ne_en Dev loss: 0.4036 r:0.7097
ru_en Dev loss: 0.4042 r:0.7448
Current avg r:0.5856 Best avg r: 0.5856
15:39:18,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:30,871 root INFO 
id:en_de cur r: 0.1962 best r: 0.1962
15:40:47,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:17,730 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6139
en_de Dev loss: 0.9601 r:0.1954
en_zh Dev loss: 0.7604 r:0.4304
ro_en Dev loss: 0.4197 r:0.7492
et_en Dev loss: 0.4001 r:0.6716
si_en Dev loss: 0.7097 r:0.5448
ne_en Dev loss: 0.4349 r:0.6837
ru_en Dev loss: 0.5272 r:0.7252
Current avg r:0.5715 Best avg r: 0.5856
15:46:45,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:58,844 root INFO 
id:en_de cur r: 0.1975 best r: 0.1975
15:47:37,366 root INFO 
id:ro_en cur r: 0.7342 best r: 0.7342
15:48:28,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:58,550 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6022
en_de Dev loss: 0.9495 r:0.2218
en_zh Dev loss: 0.7848 r:0.4361
ro_en Dev loss: 0.4837 r:0.7577
et_en Dev loss: 0.4258 r:0.6756
si_en Dev loss: 0.7078 r:0.5602
ne_en Dev loss: 0.4619 r:0.6904
ru_en Dev loss: 0.5560 r:0.7329
Current avg r:0.5821 Best avg r: 0.5856
15:54:26,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:39,710 root INFO 
id:en_de cur r: 0.2079 best r: 0.2079
15:54:52,531 root INFO 
id:en_zh cur r: 0.4499 best r: 0.4499
15:55:18,234 root INFO 
id:ro_en cur r: 0.7594 best r: 0.7594
15:55:31,89 root INFO 
id:et_en cur r: 0.6853 best r: 0.6853
15:55:43,948 root INFO 
id:si_en cur r: 0.5571 best r: 0.5571
15:55:56,818 root INFO 
id:ne_en cur r: 0.7102 best r: 0.7102
15:56:09,623 root INFO 
id:ru_en cur r: 0.7350 best r: 0.7350
15:56:09,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:39,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:57:39,438 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:57:39,442 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:57:39,447 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:57:39,452 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:57:39,456 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:57:39,462 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:57:52,319 root INFO Epoch 0 Global steps: 7000 Train loss: 0.6010
en_de Dev loss: 0.8576 r:0.2293
en_zh Dev loss: 0.6726 r:0.4627
ro_en Dev loss: 0.3551 r:0.7759
et_en Dev loss: 0.3613 r:0.6990
si_en Dev loss: 0.6217 r:0.5740
ne_en Dev loss: 0.4185 r:0.7060
ru_en Dev loss: 0.4189 r:0.7552
Current avg r:0.6003 Best avg r: 0.6003
16:02:20,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:11,903 root INFO 
id:ro_en cur r: 0.7657 best r: 0.7657
16:03:50,470 root INFO 
id:ne_en cur r: 0.7143 best r: 0.7143
16:04:03,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:33,77 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5480
en_de Dev loss: 0.9115 r:0.2237
en_zh Dev loss: 0.7783 r:0.4446
ro_en Dev loss: 0.3935 r:0.7745
et_en Dev loss: 0.3810 r:0.6921
si_en Dev loss: 0.7134 r:0.5581
ne_en Dev loss: 0.4047 r:0.7130
ru_en Dev loss: 0.4771 r:0.7532
Current avg r:0.5942 Best avg r: 0.6003
16:10:01,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:14,100 root INFO 
id:en_de cur r: 0.2158 best r: 0.2158
16:10:26,914 root INFO 
id:en_zh cur r: 0.4531 best r: 0.4531
16:10:52,615 root INFO 
id:ro_en cur r: 0.7817 best r: 0.7817
16:11:05,474 root INFO 
id:et_en cur r: 0.7082 best r: 0.7082
16:11:18,333 root INFO 
id:si_en cur r: 0.5685 best r: 0.5685
16:11:31,197 root INFO 
id:ne_en cur r: 0.7322 best r: 0.7322
16:11:44,0 root INFO 
id:ru_en cur r: 0.7450 best r: 0.7450
16:11:44,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:13,812 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:13:13,819 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:13:13,823 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:13:13,829 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:13:13,833 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:13:13,839 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:13:13,845 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:13:26,695 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5467
en_de Dev loss: 0.8711 r:0.2350
en_zh Dev loss: 0.6669 r:0.4649
ro_en Dev loss: 0.3613 r:0.7821
et_en Dev loss: 0.3532 r:0.7106
si_en Dev loss: 0.5956 r:0.5818
ne_en Dev loss: 0.3945 r:0.7285
ru_en Dev loss: 0.4126 r:0.7592
Current avg r:0.6089 Best avg r: 0.6089
16:17:54,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:07,721 root INFO 
id:en_de cur r: 0.2269 best r: 0.2269
16:18:46,223 root INFO 
id:ro_en cur r: 0.7860 best r: 0.7860
16:19:37,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:07,373 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5358
en_de Dev loss: 0.8675 r:0.2340
en_zh Dev loss: 0.7034 r:0.4485
ro_en Dev loss: 0.3517 r:0.7928
et_en Dev loss: 0.3668 r:0.7039
si_en Dev loss: 0.6790 r:0.5729
ne_en Dev loss: 0.4131 r:0.7201
ru_en Dev loss: 0.5106 r:0.7368
Current avg r:0.6013 Best avg r: 0.6089
16:25:35,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:05,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:35,272 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5376
en_de Dev loss: 0.9265 r:0.2439
en_zh Dev loss: 0.8727 r:0.4215
ro_en Dev loss: 0.4502 r:0.7876
et_en Dev loss: 0.4358 r:0.6867
si_en Dev loss: 0.8552 r:0.5520
ne_en Dev loss: 0.5480 r:0.6942
ru_en Dev loss: 0.5331 r:0.7311
Current avg r:0.5881 Best avg r: 0.6089
16:33:03,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:16,364 root INFO 
id:en_de cur r: 0.2338 best r: 0.2338
16:33:54,902 root INFO 
id:ro_en cur r: 0.7988 best r: 0.7988
16:34:33,461 root INFO 
id:ne_en cur r: 0.7409 best r: 0.7409
16:34:46,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:16,61 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:36:16,72 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:36:16,77 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:36:16,81 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:36:16,85 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:36:16,90 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:36:16,96 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:36:28,951 root INFO Epoch 0 Global steps: 10500 Train loss: 0.4999
en_de Dev loss: 0.8852 r:0.2546
en_zh Dev loss: 0.7457 r:0.4445
ro_en Dev loss: 0.3446 r:0.8025
et_en Dev loss: 0.3668 r:0.7054
si_en Dev loss: 0.7464 r:0.5766
ne_en Dev loss: 0.4194 r:0.7362
ru_en Dev loss: 0.4430 r:0.7567
Current avg r:0.6109 Best avg r: 0.6109
16:40:58,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:24,460 root INFO 
id:en_zh cur r: 0.4563 best r: 0.4563
16:41:50,160 root INFO 
id:ro_en cur r: 0.8027 best r: 0.8027
16:42:15,867 root INFO 
id:si_en cur r: 0.5954 best r: 0.5954
16:42:28,730 root INFO 
id:ne_en cur r: 0.7458 best r: 0.7458
16:42:41,538 root INFO 
id:ru_en cur r: 0.7628 best r: 0.7628
16:42:41,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:11,364 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:44:11,372 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:44:11,377 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:44:11,382 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:44:11,387 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:44:11,392 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:44:11,398 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:44:24,251 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4875
en_de Dev loss: 0.8678 r:0.2516
en_zh Dev loss: 0.6905 r:0.4599
ro_en Dev loss: 0.3146 r:0.8069
et_en Dev loss: 0.3586 r:0.7068
si_en Dev loss: 0.6082 r:0.5906
ne_en Dev loss: 0.3772 r:0.7385
ru_en Dev loss: 0.3957 r:0.7584
Current avg r:0.6161 Best avg r: 0.6161
16:48:52,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:05,314 root INFO 
id:en_de cur r: 0.2353 best r: 0.2353
16:50:22,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:52,138 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4959
en_de Dev loss: 0.8826 r:0.2411
en_zh Dev loss: 0.7367 r:0.4538
ro_en Dev loss: 0.3536 r:0.8005
et_en Dev loss: 0.3796 r:0.7036
si_en Dev loss: 0.6836 r:0.5784
ne_en Dev loss: 0.3889 r:0.7292
ru_en Dev loss: 0.4474 r:0.7522
Current avg r:0.6084 Best avg r: 0.6161
16:56:20,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:33,229 root INFO 
id:en_de cur r: 0.2563 best r: 0.2563
16:57:50,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:20,67 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4839
en_de Dev loss: 0.8436 r:0.2522
en_zh Dev loss: 0.6786 r:0.4636
ro_en Dev loss: 0.3349 r:0.8044
et_en Dev loss: 0.3708 r:0.7027
si_en Dev loss: 0.6426 r:0.5831
ne_en Dev loss: 0.3866 r:0.7267
ru_en Dev loss: 0.4613 r:0.7312
Current avg r:0.6091 Best avg r: 0.6161
17:03:48,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:14,8 root INFO 
id:en_zh cur r: 0.4585 best r: 0.4585
17:04:52,564 root INFO 
id:si_en cur r: 0.6033 best r: 0.6033
17:05:18,227 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:48,50 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5084
en_de Dev loss: 0.8375 r:0.2542
en_zh Dev loss: 0.6893 r:0.4637
ro_en Dev loss: 0.3196 r:0.8065
et_en Dev loss: 0.3644 r:0.7007
si_en Dev loss: 0.6014 r:0.6016
ne_en Dev loss: 0.3892 r:0.7358
ru_en Dev loss: 0.4265 r:0.7376
Current avg r:0.6143 Best avg r: 0.6161
17:11:16,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:41,977 root INFO 
id:en_zh cur r: 0.4639 best r: 0.4639
17:12:46,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:15,965 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5032
en_de Dev loss: 0.8296 r:0.2575
en_zh Dev loss: 0.6793 r:0.4725
ro_en Dev loss: 0.3796 r:0.8011
et_en Dev loss: 0.3899 r:0.6974
si_en Dev loss: 0.6584 r:0.5921
ne_en Dev loss: 0.3685 r:0.7358
ru_en Dev loss: 0.4675 r:0.7223
Current avg r:0.6112 Best avg r: 0.6161
17:18:44,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:09,917 root INFO 
id:en_zh cur r: 0.4639 best r: 0.4639
17:19:35,620 root INFO 
id:ro_en cur r: 0.8066 best r: 0.8066
17:20:14,183 root INFO 
id:ne_en cur r: 0.7465 best r: 0.7465
17:20:26,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:56,803 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5148
en_de Dev loss: 0.8571 r:0.2356
en_zh Dev loss: 0.7088 r:0.4746
ro_en Dev loss: 0.3511 r:0.8094
et_en Dev loss: 0.3656 r:0.7049
si_en Dev loss: 0.6470 r:0.6023
ne_en Dev loss: 0.3936 r:0.7413
ru_en Dev loss: 0.4505 r:0.7394
Current avg r:0.6154 Best avg r: 0.6161
17:26:25,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:37,958 root INFO 
id:en_de cur r: 0.2576 best r: 0.2576
17:27:54,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:24,766 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4854
en_de Dev loss: 0.9420 r:0.2497
en_zh Dev loss: 0.7975 r:0.4616
ro_en Dev loss: 0.4171 r:0.8020
et_en Dev loss: 0.4081 r:0.6944
si_en Dev loss: 0.7951 r:0.5854
ne_en Dev loss: 0.4876 r:0.7274
ru_en Dev loss: 0.5683 r:0.7244
Current avg r:0.6064 Best avg r: 0.6161
17:33:53,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:05,952 root INFO 
id:en_de cur r: 0.2807 best r: 0.2807
17:34:18,753 root INFO 
id:en_zh cur r: 0.4651 best r: 0.4651
17:35:22,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:52,693 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4819
en_de Dev loss: 0.8513 r:0.2784
en_zh Dev loss: 0.7796 r:0.4778
ro_en Dev loss: 0.4346 r:0.8011
et_en Dev loss: 0.4224 r:0.6923
si_en Dev loss: 0.8365 r:0.5818
ne_en Dev loss: 0.5135 r:0.7256
ru_en Dev loss: 0.5420 r:0.7322
Current avg r:0.6127 Best avg r: 0.6161
17:41:20,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:46,623 root INFO 
id:en_zh cur r: 0.4730 best r: 0.4730
17:42:12,330 root INFO 
id:ro_en cur r: 0.8109 best r: 0.8109
17:42:50,903 root INFO 
id:ne_en cur r: 0.7551 best r: 0.7551
17:43:03,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:33,496 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
17:44:33,504 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:44:33,509 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:44:33,514 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
17:44:33,518 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
17:44:33,523 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:44:33,529 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:44:46,392 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4839
en_de Dev loss: 0.8572 r:0.2438
en_zh Dev loss: 0.7511 r:0.4791
ro_en Dev loss: 0.3332 r:0.8137
et_en Dev loss: 0.3658 r:0.7029
si_en Dev loss: 0.6602 r:0.5991
ne_en Dev loss: 0.3840 r:0.7462
ru_en Dev loss: 0.4888 r:0.7280
Current avg r:0.6161 Best avg r: 0.6161
17:49:14,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:44,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:14,344 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4776
en_de Dev loss: 0.8384 r:0.2598
en_zh Dev loss: 0.7307 r:0.4705
ro_en Dev loss: 0.3866 r:0.8010
et_en Dev loss: 0.3908 r:0.6897
si_en Dev loss: 0.6523 r:0.5939
ne_en Dev loss: 0.4136 r:0.7296
ru_en Dev loss: 0.4603 r:0.7292
Current avg r:0.6105 Best avg r: 0.6161
17:56:42,613 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:12,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:42,277 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4580
en_de Dev loss: 0.8600 r:0.2397
en_zh Dev loss: 0.7113 r:0.4713
ro_en Dev loss: 0.3535 r:0.8107
et_en Dev loss: 0.3732 r:0.7033
si_en Dev loss: 0.6457 r:0.6042
ne_en Dev loss: 0.4366 r:0.7416
ru_en Dev loss: 0.4970 r:0.7300
Current avg r:0.6144 Best avg r: 0.6161
18:04:10,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:40,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:10,232 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4777
en_de Dev loss: 0.8734 r:0.2630
en_zh Dev loss: 0.7915 r:0.4575
ro_en Dev loss: 0.4245 r:0.7974
et_en Dev loss: 0.4071 r:0.6890
si_en Dev loss: 0.7449 r:0.5835
ne_en Dev loss: 0.4586 r:0.7303
ru_en Dev loss: 0.5718 r:0.7034
Current avg r:0.6035 Best avg r: 0.6161
18:11:38,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:04,111 root INFO 
id:en_zh cur r: 0.4814 best r: 0.4814
18:12:55,507 root INFO 
id:ne_en cur r: 0.7576 best r: 0.7576
18:13:08,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:38,82 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
18:14:38,96 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:14:38,104 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:14:38,111 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
18:14:38,118 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
18:14:38,125 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:14:38,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:14:50,983 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4931
en_de Dev loss: 0.8644 r:0.2664
en_zh Dev loss: 0.7180 r:0.4801
ro_en Dev loss: 0.3977 r:0.8083
et_en Dev loss: 0.3951 r:0.6957
si_en Dev loss: 0.7138 r:0.5907
ne_en Dev loss: 0.4114 r:0.7429
ru_en Dev loss: 0.5060 r:0.7345
Current avg r:0.6169 Best avg r: 0.6169
18:19:19,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:49,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:18,954 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
18:22:18,963 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:22:18,968 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:22:18,973 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
18:22:18,978 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
18:22:18,982 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:22:18,988 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:22:31,839 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4626
en_de Dev loss: 0.8528 r:0.2821
en_zh Dev loss: 0.7728 r:0.4633
ro_en Dev loss: 0.3746 r:0.8100
et_en Dev loss: 0.3808 r:0.6992
si_en Dev loss: 0.6612 r:0.5934
ne_en Dev loss: 0.4342 r:0.7358
ru_en Dev loss: 0.4689 r:0.7365
Current avg r:0.6172 Best avg r: 0.6172
18:27:00,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:51,553 root INFO 
id:ro_en cur r: 0.8172 best r: 0.8172
18:28:30,121 root INFO 
id:ne_en cur r: 0.7580 best r: 0.7580
18:28:42,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:12,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
18:30:12,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:30:12,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:30:12,748 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
18:30:12,754 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
18:30:12,759 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:30:12,766 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:30:25,614 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4737
en_de Dev loss: 0.8355 r:0.2665
en_zh Dev loss: 0.6873 r:0.4747
ro_en Dev loss: 0.3271 r:0.8190
et_en Dev loss: 0.3693 r:0.7030
si_en Dev loss: 0.6526 r:0.6011
ne_en Dev loss: 0.3759 r:0.7506
ru_en Dev loss: 0.4207 r:0.7514
Current avg r:0.6238 Best avg r: 0.6238
18:34:55,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:59,314 root INFO 
id:si_en cur r: 0.6067 best r: 0.6067
18:36:12,172 root INFO 
id:ne_en cur r: 0.7637 best r: 0.7637
18:36:24,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:54,772 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_de.lang_agnost_mlp.dev.best.scores
18:37:54,781 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:37:54,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:37:54,791 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/et_en.lang_agnost_mlp.dev.best.scores
18:37:54,796 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/si_en.lang_agnost_mlp.dev.best.scores
18:37:54,800 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:37:54,807 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_roen/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:38:07,651 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4460
en_de Dev loss: 0.8390 r:0.2663
en_zh Dev loss: 0.6771 r:0.4803
ro_en Dev loss: 0.3217 r:0.8134
et_en Dev loss: 0.3756 r:0.6997
si_en Dev loss: 0.6278 r:0.6042
ne_en Dev loss: 0.3693 r:0.7577
ru_en Dev loss: 0.4135 r:0.7502
Current avg r:0.6245 Best avg r: 0.6245
18:42:35,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:48,835 root INFO 
id:en_de cur r: 0.2956 best r: 0.2956
18:44:05,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:35,669 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4392
en_de Dev loss: 0.8613 r:0.2882
en_zh Dev loss: 0.7501 r:0.4593
ro_en Dev loss: 0.3335 r:0.8141
et_en Dev loss: 0.3856 r:0.6939
si_en Dev loss: 0.7216 r:0.5956
ne_en Dev loss: 0.4007 r:0.7526
ru_en Dev loss: 0.4725 r:0.7327
Current avg r:0.6195 Best avg r: 0.6245
18:50:04,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:33,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:03,812 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4319
en_de Dev loss: 0.8710 r:0.2754
en_zh Dev loss: 0.7740 r:0.4558
ro_en Dev loss: 0.3671 r:0.8081
et_en Dev loss: 0.4096 r:0.6869
si_en Dev loss: 0.7642 r:0.5884
ne_en Dev loss: 0.4387 r:0.7457
ru_en Dev loss: 0.5486 r:0.7101
Current avg r:0.6101 Best avg r: 0.6245
18:57:32,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:01,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:31,794 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4115
en_de Dev loss: 0.8465 r:0.2767
en_zh Dev loss: 0.7218 r:0.4694
ro_en Dev loss: 0.3678 r:0.8126
et_en Dev loss: 0.4195 r:0.6910
si_en Dev loss: 0.6965 r:0.5941
ne_en Dev loss: 0.3744 r:0.7503
ru_en Dev loss: 0.4678 r:0.7357
Current avg r:0.6186 Best avg r: 0.6245
19:05:00,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:30,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:59,817 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4605
en_de Dev loss: 0.8355 r:0.2564
en_zh Dev loss: 0.7086 r:0.4713
ro_en Dev loss: 0.3690 r:0.8048
et_en Dev loss: 0.4010 r:0.6820
si_en Dev loss: 0.7759 r:0.5823
ne_en Dev loss: 0.4720 r:0.7401
ru_en Dev loss: 0.4904 r:0.7167
Current avg r:0.6077 Best avg r: 0.6245
19:12:28,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:40,999 root INFO 
id:en_de cur r: 0.3053 best r: 0.3053
19:13:58,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:27,843 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4106
en_de Dev loss: 0.8560 r:0.2886
en_zh Dev loss: 0.7851 r:0.4506
ro_en Dev loss: 0.3624 r:0.8101
et_en Dev loss: 0.3944 r:0.6827
si_en Dev loss: 0.7885 r:0.5927
ne_en Dev loss: 0.4969 r:0.7477
ru_en Dev loss: 0.5379 r:0.7083
Current avg r:0.6115 Best avg r: 0.6245
19:19:56,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:00,299 root INFO 
id:si_en cur r: 0.6067 best r: 0.6067
19:21:25,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:55,768 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4184
en_de Dev loss: 0.8359 r:0.2696
en_zh Dev loss: 0.7292 r:0.4698
ro_en Dev loss: 0.3634 r:0.8121
et_en Dev loss: 0.4004 r:0.6934
si_en Dev loss: 0.7076 r:0.6035
ne_en Dev loss: 0.4067 r:0.7559
ru_en Dev loss: 0.4737 r:0.7358
Current avg r:0.6200 Best avg r: 0.6245
19:27:23,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:36,856 root INFO 
id:en_de cur r: 0.3056 best r: 0.3056
19:28:53,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:23,679 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4053
en_de Dev loss: 0.8820 r:0.2827
en_zh Dev loss: 0.7795 r:0.4545
ro_en Dev loss: 0.3592 r:0.8164
et_en Dev loss: 0.3831 r:0.6948
si_en Dev loss: 0.7139 r:0.6011
ne_en Dev loss: 0.4448 r:0.7512
ru_en Dev loss: 0.4947 r:0.7300
Current avg r:0.6187 Best avg r: 0.6245
19:34:51,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:56,148 root INFO 
id:si_en cur r: 0.6126 best r: 0.6126
19:36:21,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:51,623 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4241
en_de Dev loss: 0.8462 r:0.2487
en_zh Dev loss: 0.6705 r:0.4710
ro_en Dev loss: 0.3104 r:0.8184
et_en Dev loss: 0.3891 r:0.6907
si_en Dev loss: 0.6374 r:0.6078
ne_en Dev loss: 0.3653 r:0.7459
ru_en Dev loss: 0.3838 r:0.7522
Current avg r:0.6193 Best avg r: 0.6245
19:42:19,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:49,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:19,544 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4198
en_de Dev loss: 0.8450 r:0.2684
en_zh Dev loss: 0.6809 r:0.4569
ro_en Dev loss: 0.3031 r:0.8131
et_en Dev loss: 0.3955 r:0.6931
si_en Dev loss: 0.6093 r:0.5985
ne_en Dev loss: 0.3484 r:0.7485
ru_en Dev loss: 0.4059 r:0.7393
Current avg r:0.6168 Best avg r: 0.6245
19:49:47,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:17,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:47,395 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4337
en_de Dev loss: 0.8655 r:0.2577
en_zh Dev loss: 0.6926 r:0.4721
ro_en Dev loss: 0.3129 r:0.8177
et_en Dev loss: 0.3814 r:0.6965
si_en Dev loss: 0.6723 r:0.6023
ne_en Dev loss: 0.3889 r:0.7494
ru_en Dev loss: 0.4241 r:0.7533
Current avg r:0.6213 Best avg r: 0.6245
19:57:15,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:32,664 root INFO 
id:ne_en cur r: 0.7644 best r: 0.7644
19:58:45,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:15,285 root INFO Epoch 2 Global steps: 29400 Train loss: 0.4351
en_de Dev loss: 0.8378 r:0.2856
en_zh Dev loss: 0.7042 r:0.4655
ro_en Dev loss: 0.3397 r:0.8167
et_en Dev loss: 0.4001 r:0.6881
si_en Dev loss: 0.7371 r:0.5966
ne_en Dev loss: 0.4155 r:0.7500
ru_en Dev loss: 0.4293 r:0.7467
Current avg r:0.6213 Best avg r: 0.6245
20:04:43,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:34,920 root INFO 
id:ro_en cur r: 0.8189 best r: 0.8189
20:06:26,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:07:56,95 root INFO Epoch 2 Global steps: 30100 Train loss: 0.4066
en_de Dev loss: 0.8663 r:0.2682
en_zh Dev loss: 0.7595 r:0.4480
ro_en Dev loss: 0.3498 r:0.8181
et_en Dev loss: 0.3899 r:0.6913
si_en Dev loss: 0.7345 r:0.6052
ne_en Dev loss: 0.4690 r:0.7477
ru_en Dev loss: 0.4562 r:0.7369
Current avg r:0.6165 Best avg r: 0.6245
20:12:24,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:41,358 root INFO 
id:ne_en cur r: 0.7680 best r: 0.7680
20:13:54,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:23,962 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3918
en_de Dev loss: 0.8346 r:0.2736
en_zh Dev loss: 0.7209 r:0.4524
ro_en Dev loss: 0.3366 r:0.8164
et_en Dev loss: 0.4091 r:0.6922
si_en Dev loss: 0.6609 r:0.6082
ne_en Dev loss: 0.3713 r:0.7528
ru_en Dev loss: 0.3974 r:0.7479
Current avg r:0.6205 Best avg r: 0.6245
20:19:52,219 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:22,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:51,889 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3943
en_de Dev loss: 0.8652 r:0.2800
en_zh Dev loss: 0.7757 r:0.4578
ro_en Dev loss: 0.3894 r:0.8145
et_en Dev loss: 0.4230 r:0.6829
si_en Dev loss: 0.7908 r:0.6006
ne_en Dev loss: 0.4238 r:0.7502
ru_en Dev loss: 0.5221 r:0.7269
Current avg r:0.6161 Best avg r: 0.6245
20:27:21,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:51,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:21,241 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3539
en_de Dev loss: 0.8414 r:0.2872
en_zh Dev loss: 0.7164 r:0.4570
ro_en Dev loss: 0.3310 r:0.8162
et_en Dev loss: 0.3993 r:0.6864
si_en Dev loss: 0.6850 r:0.6031
ne_en Dev loss: 0.3977 r:0.7445
ru_en Dev loss: 0.4594 r:0.7227
Current avg r:0.6167 Best avg r: 0.6245
20:34:49,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:36:19,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:49,70 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3666
en_de Dev loss: 0.8739 r:0.2772
en_zh Dev loss: 0.7855 r:0.4430
ro_en Dev loss: 0.3812 r:0.8126
et_en Dev loss: 0.4160 r:0.6764
si_en Dev loss: 0.8024 r:0.5900
ne_en Dev loss: 0.4463 r:0.7448
ru_en Dev loss: 0.5310 r:0.7046
Current avg r:0.6070 Best avg r: 0.6245
20:42:17,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:47,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:16,824 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3747
en_de Dev loss: 0.9230 r:0.2539
en_zh Dev loss: 0.8229 r:0.4411
ro_en Dev loss: 0.4312 r:0.8077
et_en Dev loss: 0.4688 r:0.6635
si_en Dev loss: 0.9109 r:0.5746
ne_en Dev loss: 0.5147 r:0.7257
ru_en Dev loss: 0.6186 r:0.7007
Current avg r:0.5953 Best avg r: 0.6245
20:49:45,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:14,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:44,712 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3911
en_de Dev loss: 0.8879 r:0.2415
en_zh Dev loss: 0.7730 r:0.4392
ro_en Dev loss: 0.3750 r:0.8120
et_en Dev loss: 0.4260 r:0.6767
si_en Dev loss: 0.7947 r:0.5902
ne_en Dev loss: 0.4214 r:0.7385
ru_en Dev loss: 0.4993 r:0.7270
Current avg r:0.6036 Best avg r: 0.6245
20:57:12,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:04,267 root INFO 
id:ro_en cur r: 0.8227 best r: 0.8227
20:58:55,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:25,392 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3780
en_de Dev loss: 0.8633 r:0.2265
en_zh Dev loss: 0.7149 r:0.4543
ro_en Dev loss: 0.3262 r:0.8209
et_en Dev loss: 0.3875 r:0.6917
si_en Dev loss: 0.7103 r:0.6045
ne_en Dev loss: 0.4103 r:0.7525
ru_en Dev loss: 0.4253 r:0.7375
Current avg r:0.6126 Best avg r: 0.6245
21:04:53,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:23,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:53,355 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3362
en_de Dev loss: 0.8606 r:0.2422
en_zh Dev loss: 0.7812 r:0.4477
ro_en Dev loss: 0.3485 r:0.8173
et_en Dev loss: 0.4115 r:0.6862
si_en Dev loss: 0.6987 r:0.5984
ne_en Dev loss: 0.3885 r:0.7523
ru_en Dev loss: 0.4366 r:0.7353
Current avg r:0.6114 Best avg r: 0.6245
21:12:21,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:51,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:21,196 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3456
en_de Dev loss: 0.8956 r:0.2677
en_zh Dev loss: 0.7750 r:0.4487
ro_en Dev loss: 0.3910 r:0.8118
et_en Dev loss: 0.4255 r:0.6758
si_en Dev loss: 0.8276 r:0.5904
ne_en Dev loss: 0.4861 r:0.7445
ru_en Dev loss: 0.5444 r:0.6979
Current avg r:0.6052 Best avg r: 0.6245
21:19:49,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:19,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:49,84 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3590
en_de Dev loss: 0.8397 r:0.2602
en_zh Dev loss: 0.7373 r:0.4627
ro_en Dev loss: 0.3485 r:0.8165
et_en Dev loss: 0.4530 r:0.6874
si_en Dev loss: 0.6140 r:0.6147
ne_en Dev loss: 0.3737 r:0.7510
ru_en Dev loss: 0.4031 r:0.7492
Current avg r:0.6203 Best avg r: 0.6245
21:27:17,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:47,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:30:16,876 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3623
en_de Dev loss: 0.8629 r:0.2446
en_zh Dev loss: 0.8662 r:0.4242
ro_en Dev loss: 0.4355 r:0.8027
et_en Dev loss: 0.4347 r:0.6683
si_en Dev loss: 0.9307 r:0.5806
ne_en Dev loss: 0.5918 r:0.7404
ru_en Dev loss: 0.5636 r:0.6870
Current avg r:0.5926 Best avg r: 0.6245
21:34:45,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:14,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:44,679 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3547
en_de Dev loss: 0.8286 r:0.2696
en_zh Dev loss: 0.7320 r:0.4484
ro_en Dev loss: 0.3248 r:0.8212
et_en Dev loss: 0.3957 r:0.6841
si_en Dev loss: 0.7130 r:0.6075
ne_en Dev loss: 0.4179 r:0.7493
ru_en Dev loss: 0.4459 r:0.7270
Current avg r:0.6153 Best avg r: 0.6245
21:42:12,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:42,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:12,506 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3685
en_de Dev loss: 0.8386 r:0.2784
en_zh Dev loss: 0.7719 r:0.4248
ro_en Dev loss: 0.3300 r:0.8164
et_en Dev loss: 0.4062 r:0.6788
si_en Dev loss: 0.7167 r:0.5945
ne_en Dev loss: 0.4323 r:0.7470
ru_en Dev loss: 0.4606 r:0.7143
Current avg r:0.6078 Best avg r: 0.6245
21:49:40,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:10,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:40,346 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3423
en_de Dev loss: 0.8452 r:0.2532
en_zh Dev loss: 0.7420 r:0.4309
ro_en Dev loss: 0.3365 r:0.8133
et_en Dev loss: 0.4143 r:0.6791
si_en Dev loss: 0.6674 r:0.6017
ne_en Dev loss: 0.3826 r:0.7540
ru_en Dev loss: 0.4845 r:0.7045
Current avg r:0.6052 Best avg r: 0.6245
21:57:08,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:38,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:08,270 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3848
en_de Dev loss: 0.8575 r:0.2582
en_zh Dev loss: 0.8219 r:0.4309
ro_en Dev loss: 0.4017 r:0.8101
et_en Dev loss: 0.4254 r:0.6764
si_en Dev loss: 0.7916 r:0.5930
ne_en Dev loss: 0.4594 r:0.7556
ru_en Dev loss: 0.4911 r:0.7225
Current avg r:0.6067 Best avg r: 0.6245
22:04:36,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:06,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:36,91 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3639
en_de Dev loss: 0.8932 r:0.2476
en_zh Dev loss: 0.8468 r:0.4177
ro_en Dev loss: 0.4321 r:0.8010
et_en Dev loss: 0.4579 r:0.6580
si_en Dev loss: 0.8914 r:0.5745
ne_en Dev loss: 0.5508 r:0.7401
ru_en Dev loss: 0.5975 r:0.6794
Current avg r:0.5883 Best avg r: 0.6245
22:12:04,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:34,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:03,885 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3486
en_de Dev loss: 0.8492 r:0.2602
en_zh Dev loss: 0.7738 r:0.4358
ro_en Dev loss: 0.3861 r:0.8104
et_en Dev loss: 0.4188 r:0.6803
si_en Dev loss: 0.7272 r:0.5999
ne_en Dev loss: 0.4757 r:0.7509
ru_en Dev loss: 0.4720 r:0.7204
Current avg r:0.6083 Best avg r: 0.6245
22:19:33,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:03,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:33,133 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3073
en_de Dev loss: 0.8673 r:0.2467
en_zh Dev loss: 0.7623 r:0.4410
ro_en Dev loss: 0.3743 r:0.8127
et_en Dev loss: 0.4151 r:0.6806
si_en Dev loss: 0.8062 r:0.5994
ne_en Dev loss: 0.5351 r:0.7541
ru_en Dev loss: 0.4768 r:0.7278
Current avg r:0.6089 Best avg r: 0.6245
22:27:01,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:31,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:00,995 root INFO Epoch 4 Global steps: 43400 Train loss: 0.3105
en_de Dev loss: 0.8348 r:0.2538
en_zh Dev loss: 0.7247 r:0.4425
ro_en Dev loss: 0.3411 r:0.8096
et_en Dev loss: 0.4197 r:0.6772
si_en Dev loss: 0.6963 r:0.5955
ne_en Dev loss: 0.3902 r:0.7504
ru_en Dev loss: 0.4072 r:0.7351
Current avg r:0.6092 Best avg r: 0.6245
22:34:29,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:59,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:28,830 root INFO Epoch 4 Global steps: 44100 Train loss: 0.3291
en_de Dev loss: 0.8525 r:0.2500
en_zh Dev loss: 0.7563 r:0.4359
ro_en Dev loss: 0.3433 r:0.8081
et_en Dev loss: 0.4210 r:0.6761
si_en Dev loss: 0.7032 r:0.5937
ne_en Dev loss: 0.4186 r:0.7469
ru_en Dev loss: 0.4593 r:0.7198
Current avg r:0.6044 Best avg r: 0.6245
22:41:56,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:26,806 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:56,584 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2993
en_de Dev loss: 0.8545 r:0.2461
en_zh Dev loss: 0.7839 r:0.4360
ro_en Dev loss: 0.3675 r:0.8074
et_en Dev loss: 0.4375 r:0.6650
si_en Dev loss: 0.7912 r:0.5817
ne_en Dev loss: 0.5202 r:0.7446
ru_en Dev loss: 0.5039 r:0.6964
Current avg r:0.5967 Best avg r: 0.6245
22:49:24,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:54,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:24,483 root INFO Epoch 4 Global steps: 45500 Train loss: 0.3142
en_de Dev loss: 0.8484 r:0.2296
en_zh Dev loss: 0.7362 r:0.4368
ro_en Dev loss: 0.3635 r:0.8066
et_en Dev loss: 0.4352 r:0.6648
si_en Dev loss: 0.7405 r:0.5785
ne_en Dev loss: 0.4538 r:0.7510
ru_en Dev loss: 0.4464 r:0.7136
Current avg r:0.5973 Best avg r: 0.6245
22:56:52,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:22,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:52,370 root INFO Epoch 4 Global steps: 46200 Train loss: 0.3185
en_de Dev loss: 0.8549 r:0.2389
en_zh Dev loss: 0.7786 r:0.4398
ro_en Dev loss: 0.3878 r:0.8060
et_en Dev loss: 0.4564 r:0.6721
si_en Dev loss: 0.6962 r:0.5892
ne_en Dev loss: 0.4261 r:0.7485
ru_en Dev loss: 0.4342 r:0.7297
Current avg r:0.6035 Best avg r: 0.6245
23:04:20,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:50,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:20,156 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2927
en_de Dev loss: 0.9337 r:0.2334
en_zh Dev loss: 0.8839 r:0.4307
ro_en Dev loss: 0.4320 r:0.8049
et_en Dev loss: 0.4644 r:0.6613
si_en Dev loss: 0.9203 r:0.5737
ne_en Dev loss: 0.6152 r:0.7472
ru_en Dev loss: 0.5271 r:0.7261
Current avg r:0.5968 Best avg r: 0.6245
23:11:48,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:18,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:48,20 root INFO Epoch 4 Global steps: 47600 Train loss: 0.3157
en_de Dev loss: 0.8550 r:0.2449
en_zh Dev loss: 0.7590 r:0.4440
ro_en Dev loss: 0.3517 r:0.8076
et_en Dev loss: 0.4066 r:0.6718
si_en Dev loss: 0.7248 r:0.5867
ne_en Dev loss: 0.4286 r:0.7493
ru_en Dev loss: 0.4382 r:0.7355
Current avg r:0.6057 Best avg r: 0.6245
23:19:16,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:46,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:15,868 root INFO Epoch 4 Global steps: 48300 Train loss: 0.3054
en_de Dev loss: 0.8873 r:0.2479
en_zh Dev loss: 0.8544 r:0.4443
ro_en Dev loss: 0.4068 r:0.8098
et_en Dev loss: 0.4302 r:0.6729
si_en Dev loss: 0.8203 r:0.5831
ne_en Dev loss: 0.5268 r:0.7513
ru_en Dev loss: 0.5020 r:0.7262
Current avg r:0.6051 Best avg r: 0.6245
23:26:44,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:14,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:43,792 root INFO Epoch 4 Global steps: 49000 Train loss: 0.3115
en_de Dev loss: 0.8387 r:0.2521
en_zh Dev loss: 0.7422 r:0.4532
ro_en Dev loss: 0.3577 r:0.8077
et_en Dev loss: 0.4318 r:0.6723
si_en Dev loss: 0.7105 r:0.5839
ne_en Dev loss: 0.4086 r:0.7439
ru_en Dev loss: 0.4315 r:0.7187
Current avg r:0.6045 Best avg r: 0.6245
23:34:11,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:41,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:11,639 root INFO Epoch 4 Global steps: 49700 Train loss: 0.3000
en_de Dev loss: 0.8479 r:0.2645
en_zh Dev loss: 0.7718 r:0.4341
ro_en Dev loss: 0.3499 r:0.8126
et_en Dev loss: 0.4270 r:0.6703
si_en Dev loss: 0.7350 r:0.5859
ne_en Dev loss: 0.4119 r:0.7501
ru_en Dev loss: 0.4401 r:0.7264
Current avg r:0.6063 Best avg r: 0.6245
23:41:39,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:09,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:39,612 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2998
en_de Dev loss: 0.8720 r:0.2709
en_zh Dev loss: 0.7880 r:0.4323
ro_en Dev loss: 0.3504 r:0.8121
et_en Dev loss: 0.4374 r:0.6663
si_en Dev loss: 0.7684 r:0.5850
ne_en Dev loss: 0.4176 r:0.7482
ru_en Dev loss: 0.4748 r:0.7215
Current avg r:0.6052 Best avg r: 0.6245
23:49:08,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:37,898 root INFO 
id:ru_en cur r: 0.7683 best r: 0.7683
23:50:37,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:07,693 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2777
en_de Dev loss: 0.8442 r:0.2562
en_zh Dev loss: 0.7392 r:0.4472
ro_en Dev loss: 0.3136 r:0.8135
et_en Dev loss: 0.4157 r:0.6853
si_en Dev loss: 0.6328 r:0.5945
ne_en Dev loss: 0.3756 r:0.7470
ru_en Dev loss: 0.3710 r:0.7591
Current avg r:0.6147 Best avg r: 0.6245
23:56:35,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:05,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:35,650 root INFO Epoch 4 Global steps: 51800 Train loss: 0.3010
en_de Dev loss: 0.8664 r:0.2532
en_zh Dev loss: 0.7703 r:0.4428
ro_en Dev loss: 0.3441 r:0.8133
et_en Dev loss: 0.4276 r:0.6697
si_en Dev loss: 0.7211 r:0.5848
ne_en Dev loss: 0.4298 r:0.7411
ru_en Dev loss: 0.4490 r:0.7277
Current avg r:0.6046 Best avg r: 0.6245
00:04:04,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:34,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:03,839 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2901
en_de Dev loss: 0.8794 r:0.2559
en_zh Dev loss: 0.8693 r:0.4249
ro_en Dev loss: 0.4120 r:0.8064
et_en Dev loss: 0.4399 r:0.6639
si_en Dev loss: 0.9050 r:0.5658
ne_en Dev loss: 0.6067 r:0.7410
ru_en Dev loss: 0.5199 r:0.7078
Current avg r:0.5951 Best avg r: 0.6245
00:11:33,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:03,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:33,510 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2582
en_de Dev loss: 0.8626 r:0.2506
en_zh Dev loss: 0.7924 r:0.4323
ro_en Dev loss: 0.3612 r:0.8092
et_en Dev loss: 0.4201 r:0.6646
si_en Dev loss: 0.7908 r:0.5686
ne_en Dev loss: 0.5416 r:0.7414
ru_en Dev loss: 0.4999 r:0.7002
Current avg r:0.5953 Best avg r: 0.6245
00:19:01,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:31,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:01,421 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2740
en_de Dev loss: 0.8464 r:0.2647
en_zh Dev loss: 0.7856 r:0.4413
ro_en Dev loss: 0.3755 r:0.8077
et_en Dev loss: 0.4627 r:0.6685
si_en Dev loss: 0.7386 r:0.5769
ne_en Dev loss: 0.4481 r:0.7380
ru_en Dev loss: 0.4626 r:0.7125
Current avg r:0.6014 Best avg r: 0.6245
00:26:29,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:27:59,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:29,459 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2722
en_de Dev loss: 0.8610 r:0.2575
en_zh Dev loss: 0.8117 r:0.4398
ro_en Dev loss: 0.3886 r:0.8052
et_en Dev loss: 0.4643 r:0.6687
si_en Dev loss: 0.8438 r:0.5701
ne_en Dev loss: 0.5498 r:0.7354
ru_en Dev loss: 0.4983 r:0.7151
Current avg r:0.5988 Best avg r: 0.6245
00:33:57,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:27,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:57,232 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2628
en_de Dev loss: 0.8700 r:0.2467
en_zh Dev loss: 0.8330 r:0.4372
ro_en Dev loss: 0.3770 r:0.8106
et_en Dev loss: 0.4579 r:0.6661
si_en Dev loss: 0.7766 r:0.5779
ne_en Dev loss: 0.4805 r:0.7363
ru_en Dev loss: 0.4996 r:0.7154
Current avg r:0.5986 Best avg r: 0.6245
00:41:25,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:55,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:25,87 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2584
en_de Dev loss: 0.8528 r:0.2457
en_zh Dev loss: 0.7813 r:0.4445
ro_en Dev loss: 0.3438 r:0.8129
et_en Dev loss: 0.4252 r:0.6740
si_en Dev loss: 0.7510 r:0.5772
ne_en Dev loss: 0.4298 r:0.7423
ru_en Dev loss: 0.4634 r:0.7240
Current avg r:0.6029 Best avg r: 0.6245
00:48:53,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:23,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:51:52,913 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2669
en_de Dev loss: 0.8593 r:0.2350
en_zh Dev loss: 0.7844 r:0.4438
ro_en Dev loss: 0.3569 r:0.8092
et_en Dev loss: 0.4561 r:0.6654
si_en Dev loss: 0.7104 r:0.5838
ne_en Dev loss: 0.4655 r:0.7402
ru_en Dev loss: 0.4420 r:0.7226
Current avg r:0.6000 Best avg r: 0.6245
00:56:20,936 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:50,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:20,595 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2475
en_de Dev loss: 0.8844 r:0.2499
en_zh Dev loss: 0.8166 r:0.4377
ro_en Dev loss: 0.3941 r:0.7995
et_en Dev loss: 0.4663 r:0.6616
si_en Dev loss: 0.8258 r:0.5706
ne_en Dev loss: 0.4998 r:0.7403
ru_en Dev loss: 0.4645 r:0.7258
Current avg r:0.5979 Best avg r: 0.6245
01:03:48,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:18,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:48,534 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2722
en_de Dev loss: 0.8707 r:0.2418
en_zh Dev loss: 0.7609 r:0.4600
ro_en Dev loss: 0.3665 r:0.8088
et_en Dev loss: 0.4423 r:0.6619
si_en Dev loss: 0.7852 r:0.5778
ne_en Dev loss: 0.4854 r:0.7343
ru_en Dev loss: 0.4575 r:0.7299
Current avg r:0.6021 Best avg r: 0.6245
01:11:16,516 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:46,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:16,196 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2655
en_de Dev loss: 0.8648 r:0.2433
en_zh Dev loss: 0.7745 r:0.4568
ro_en Dev loss: 0.3843 r:0.8083
et_en Dev loss: 0.4529 r:0.6636
si_en Dev loss: 0.7918 r:0.5796
ne_en Dev loss: 0.4679 r:0.7314
ru_en Dev loss: 0.4637 r:0.7299
Current avg r:0.6018 Best avg r: 0.6245
01:18:44,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:20:14,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:21:44,33 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2555
en_de Dev loss: 0.8475 r:0.2512
en_zh Dev loss: 0.7577 r:0.4558
ro_en Dev loss: 0.3578 r:0.8066
et_en Dev loss: 0.4365 r:0.6650
si_en Dev loss: 0.7805 r:0.5728
ne_en Dev loss: 0.4525 r:0.7379
ru_en Dev loss: 0.4360 r:0.7370
Current avg r:0.6037 Best avg r: 0.6245
01:26:12,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:27:42,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:29:11,795 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2477
en_de Dev loss: 0.9043 r:0.2455
en_zh Dev loss: 0.8535 r:0.4446
ro_en Dev loss: 0.4081 r:0.8088
et_en Dev loss: 0.4689 r:0.6619
si_en Dev loss: 0.8680 r:0.5686
ne_en Dev loss: 0.5506 r:0.7296
ru_en Dev loss: 0.4955 r:0.7295
Current avg r:0.5984 Best avg r: 0.6245
01:33:39,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:09,843 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:39,648 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2456
en_de Dev loss: 0.8537 r:0.2442
en_zh Dev loss: 0.7912 r:0.4474
ro_en Dev loss: 0.3644 r:0.8080
et_en Dev loss: 0.4702 r:0.6627
si_en Dev loss: 0.7711 r:0.5725
ne_en Dev loss: 0.4439 r:0.7358
ru_en Dev loss: 0.4529 r:0.7232
Current avg r:0.5991 Best avg r: 0.6245
01:41:07,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:37,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:44:07,638 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2471
en_de Dev loss: 0.8760 r:0.2180
en_zh Dev loss: 0.8057 r:0.4472
ro_en Dev loss: 0.3726 r:0.8107
et_en Dev loss: 0.4580 r:0.6569
si_en Dev loss: 0.8052 r:0.5714
ne_en Dev loss: 0.4661 r:0.7376
ru_en Dev loss: 0.5139 r:0.6992
Current avg r:0.5916 Best avg r: 0.6245
01:48:36,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:06,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:36,297 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2483
en_de Dev loss: 0.8748 r:0.2226
en_zh Dev loss: 0.8048 r:0.4363
ro_en Dev loss: 0.3880 r:0.8057
et_en Dev loss: 0.4757 r:0.6480
si_en Dev loss: 0.8323 r:0.5706
ne_en Dev loss: 0.4910 r:0.7398
ru_en Dev loss: 0.5156 r:0.6961
Current avg r:0.5884 Best avg r: 0.6245
01:56:04,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:34,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:04,528 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2465
en_de Dev loss: 0.8749 r:0.2497
en_zh Dev loss: 0.8103 r:0.4298
ro_en Dev loss: 0.3852 r:0.8064
et_en Dev loss: 0.4531 r:0.6542
si_en Dev loss: 0.8131 r:0.5740
ne_en Dev loss: 0.5167 r:0.7337
ru_en Dev loss: 0.4773 r:0.7199
Current avg r:0.5954 Best avg r: 0.6245
02:03:34,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:04,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:06:34,567 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2242
en_de Dev loss: 0.8830 r:0.2471
en_zh Dev loss: 0.8053 r:0.4346
ro_en Dev loss: 0.3889 r:0.8048
et_en Dev loss: 0.4690 r:0.6518
si_en Dev loss: 0.8045 r:0.5744
ne_en Dev loss: 0.4704 r:0.7327
ru_en Dev loss: 0.4877 r:0.7205
Current avg r:0.5951 Best avg r: 0.6245
02:11:03,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:33,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:03,38 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2260
en_de Dev loss: 0.9044 r:0.2350
en_zh Dev loss: 0.8227 r:0.4356
ro_en Dev loss: 0.3962 r:0.8038
et_en Dev loss: 0.4851 r:0.6451
si_en Dev loss: 0.8096 r:0.5725
ne_en Dev loss: 0.5162 r:0.7282
ru_en Dev loss: 0.5041 r:0.7185
Current avg r:0.5912 Best avg r: 0.6245
02:18:31,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:01,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:21:31,341 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2234
en_de Dev loss: 0.8810 r:0.2257
en_zh Dev loss: 0.7951 r:0.4504
ro_en Dev loss: 0.3917 r:0.8042
et_en Dev loss: 0.4814 r:0.6503
si_en Dev loss: 0.8451 r:0.5686
ne_en Dev loss: 0.5115 r:0.7308
ru_en Dev loss: 0.4731 r:0.7240
Current avg r:0.5935 Best avg r: 0.6245
02:26:00,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:27:29,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:28:59,876 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2282
en_de Dev loss: 0.8698 r:0.2331
en_zh Dev loss: 0.8002 r:0.4419
ro_en Dev loss: 0.3831 r:0.8072
et_en Dev loss: 0.4857 r:0.6456
si_en Dev loss: 0.8614 r:0.5620
ne_en Dev loss: 0.5256 r:0.7284
ru_en Dev loss: 0.4724 r:0.7174
Current avg r:0.5908 Best avg r: 0.6245
02:33:28,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:34:58,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:28,224 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2291
en_de Dev loss: 0.8610 r:0.2184
en_zh Dev loss: 0.7632 r:0.4490
ro_en Dev loss: 0.3425 r:0.8113
et_en Dev loss: 0.4603 r:0.6595
si_en Dev loss: 0.7217 r:0.5796
ne_en Dev loss: 0.4526 r:0.7355
ru_en Dev loss: 0.4355 r:0.7249
Current avg r:0.5969 Best avg r: 0.6245
02:40:56,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:42:26,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:43:56,610 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2173
en_de Dev loss: 0.8755 r:0.2385
en_zh Dev loss: 0.8229 r:0.4349
ro_en Dev loss: 0.3740 r:0.8119
et_en Dev loss: 0.4769 r:0.6505
si_en Dev loss: 0.8178 r:0.5739
ne_en Dev loss: 0.5370 r:0.7339
ru_en Dev loss: 0.5017 r:0.7118
Current avg r:0.5936 Best avg r: 0.6245
02:48:25,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:49:55,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:25,29 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2235
en_de Dev loss: 0.8913 r:0.2229
en_zh Dev loss: 0.8170 r:0.4401
ro_en Dev loss: 0.3789 r:0.8082
et_en Dev loss: 0.4814 r:0.6525
si_en Dev loss: 0.8605 r:0.5723
ne_en Dev loss: 0.5788 r:0.7302
ru_en Dev loss: 0.5314 r:0.7074
Current avg r:0.5905 Best avg r: 0.6245
02:55:53,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:57:23,671 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:58:53,558 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2026
en_de Dev loss: 0.8774 r:0.2313
en_zh Dev loss: 0.7691 r:0.4513
ro_en Dev loss: 0.3447 r:0.8130
et_en Dev loss: 0.4524 r:0.6595
si_en Dev loss: 0.7734 r:0.5685
ne_en Dev loss: 0.4284 r:0.7375
ru_en Dev loss: 0.4602 r:0.7355
Current avg r:0.5995 Best avg r: 0.6245
03:03:22,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:04:52,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:06:22,180 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2164
en_de Dev loss: 0.8977 r:0.2374
en_zh Dev loss: 0.8223 r:0.4373
ro_en Dev loss: 0.3803 r:0.8124
et_en Dev loss: 0.4729 r:0.6549
si_en Dev loss: 0.8624 r:0.5676
ne_en Dev loss: 0.4950 r:0.7311
ru_en Dev loss: 0.4910 r:0.7229
Current avg r:0.5948 Best avg r: 0.6245
03:10:51,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:12:20,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:13:50,756 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2136
en_de Dev loss: 0.8815 r:0.2394
en_zh Dev loss: 0.7793 r:0.4395
ro_en Dev loss: 0.3771 r:0.8095
et_en Dev loss: 0.4745 r:0.6403
si_en Dev loss: 0.8666 r:0.5631
ne_en Dev loss: 0.5337 r:0.7254
ru_en Dev loss: 0.4999 r:0.7158
Current avg r:0.5905 Best avg r: 0.6245
03:18:19,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:19:49,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:21:19,129 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2241
en_de Dev loss: 0.8801 r:0.2430
en_zh Dev loss: 0.8042 r:0.4371
ro_en Dev loss: 0.3626 r:0.8102
et_en Dev loss: 0.4844 r:0.6461
si_en Dev loss: 0.8705 r:0.5621
ne_en Dev loss: 0.5120 r:0.7298
ru_en Dev loss: 0.4899 r:0.7162
Current avg r:0.5921 Best avg r: 0.6245
03:25:47,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:27:17,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:28:47,588 root INFO Epoch 6 Global steps: 71400 Train loss: 0.2069
en_de Dev loss: 0.8784 r:0.2235
en_zh Dev loss: 0.7817 r:0.4439
ro_en Dev loss: 0.3446 r:0.8133
et_en Dev loss: 0.4781 r:0.6631
si_en Dev loss: 0.7043 r:0.5854
ne_en Dev loss: 0.4175 r:0.7354
ru_en Dev loss: 0.4384 r:0.7302
Current avg r:0.5993 Best avg r: 0.6245
03:33:16,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:34:46,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:16,29 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2121
en_de Dev loss: 0.8610 r:0.2423
en_zh Dev loss: 0.8095 r:0.4226
ro_en Dev loss: 0.3616 r:0.8082
et_en Dev loss: 0.4648 r:0.6504
si_en Dev loss: 0.8489 r:0.5640
ne_en Dev loss: 0.5446 r:0.7266
ru_en Dev loss: 0.5313 r:0.6887
Current avg r:0.5861 Best avg r: 0.6245
03:40:44,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:42:14,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:43:44,575 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2028
en_de Dev loss: 0.8765 r:0.2393
en_zh Dev loss: 0.8152 r:0.4416
ro_en Dev loss: 0.3664 r:0.8121
et_en Dev loss: 0.4821 r:0.6570
si_en Dev loss: 0.8240 r:0.5758
ne_en Dev loss: 0.4705 r:0.7341
ru_en Dev loss: 0.4768 r:0.7227
Current avg r:0.5975 Best avg r: 0.6245
03:48:13,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:49:43,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:51:13,204 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2283
en_de Dev loss: 0.8810 r:0.2049
en_zh Dev loss: 0.8288 r:0.4281
ro_en Dev loss: 0.3903 r:0.8118
et_en Dev loss: 0.4660 r:0.6470
si_en Dev loss: 0.9390 r:0.5630
ne_en Dev loss: 0.5642 r:0.7316
ru_en Dev loss: 0.4907 r:0.7127
Current avg r:0.5856 Best avg r: 0.6245
03:55:43,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:13,640 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:58:43,505 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1953
en_de Dev loss: 0.8741 r:0.2159
en_zh Dev loss: 0.7650 r:0.4442
ro_en Dev loss: 0.3541 r:0.8098
et_en Dev loss: 0.4890 r:0.6615
si_en Dev loss: 0.7755 r:0.5756
ne_en Dev loss: 0.4973 r:0.7296
ru_en Dev loss: 0.4109 r:0.7333
Current avg r:0.5957 Best avg r: 0.6245
04:03:12,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:42,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:06:12,190 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1917
en_de Dev loss: 0.8839 r:0.2229
en_zh Dev loss: 0.7911 r:0.4396
ro_en Dev loss: 0.3558 r:0.8093
et_en Dev loss: 0.4680 r:0.6610
si_en Dev loss: 0.7529 r:0.5759
ne_en Dev loss: 0.4931 r:0.7338
ru_en Dev loss: 0.4500 r:0.7281
Current avg r:0.5958 Best avg r: 0.6245
04:10:41,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:12:11,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:13:41,225 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1869
en_de Dev loss: 0.8996 r:0.2240
en_zh Dev loss: 0.8133 r:0.4337
ro_en Dev loss: 0.3879 r:0.8050
et_en Dev loss: 0.4654 r:0.6484
si_en Dev loss: 0.8333 r:0.5642
ne_en Dev loss: 0.5181 r:0.7344
ru_en Dev loss: 0.4918 r:0.7157
Current avg r:0.5893 Best avg r: 0.6245
04:18:10,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:19:40,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:21:10,216 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1937
en_de Dev loss: 0.8827 r:0.2375
en_zh Dev loss: 0.8407 r:0.4377
ro_en Dev loss: 0.3922 r:0.8024
et_en Dev loss: 0.4636 r:0.6489
si_en Dev loss: 0.9172 r:0.5634
ne_en Dev loss: 0.6161 r:0.7264
ru_en Dev loss: 0.5126 r:0.7109
Current avg r:0.5896 Best avg r: 0.6245
04:25:39,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:27:09,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:28:38,984 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1866
en_de Dev loss: 0.9148 r:0.2256
en_zh Dev loss: 0.8460 r:0.4194
ro_en Dev loss: 0.3938 r:0.8068
et_en Dev loss: 0.5009 r:0.6545
si_en Dev loss: 0.8531 r:0.5658
ne_en Dev loss: 0.4961 r:0.7364
ru_en Dev loss: 0.4800 r:0.7211
Current avg r:0.5900 Best avg r: 0.6245
04:33:07,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:34:37,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:36:07,493 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1941
en_de Dev loss: 0.9112 r:0.2263
en_zh Dev loss: 0.8375 r:0.4446
ro_en Dev loss: 0.3970 r:0.8058
et_en Dev loss: 0.4848 r:0.6474
si_en Dev loss: 0.8915 r:0.5588
ne_en Dev loss: 0.5376 r:0.7305
ru_en Dev loss: 0.5106 r:0.7250
Current avg r:0.5912 Best avg r: 0.6245
04:40:36,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:42:06,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:43:36,275 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1957
en_de Dev loss: 0.9003 r:0.2412
en_zh Dev loss: 0.8100 r:0.4254
ro_en Dev loss: 0.3768 r:0.8035
et_en Dev loss: 0.4723 r:0.6493
si_en Dev loss: 0.8045 r:0.5706
ne_en Dev loss: 0.5052 r:0.7378
ru_en Dev loss: 0.4548 r:0.7233
Current avg r:0.5930 Best avg r: 0.6245
04:48:05,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:49:35,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:05,222 root INFO Epoch 7 Global steps: 79100 Train loss: 0.2010
en_de Dev loss: 0.8643 r:0.2481
en_zh Dev loss: 0.8432 r:0.4311
ro_en Dev loss: 0.4062 r:0.7984
et_en Dev loss: 0.5234 r:0.6473
si_en Dev loss: 0.8010 r:0.5697
ne_en Dev loss: 0.4845 r:0.7333
ru_en Dev loss: 0.4703 r:0.7234
Current avg r:0.5931 Best avg r: 0.6245
04:55:33,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:03,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:58:33,391 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1888
en_de Dev loss: 0.8630 r:0.2541
en_zh Dev loss: 0.8367 r:0.4284
ro_en Dev loss: 0.3958 r:0.8017
et_en Dev loss: 0.4846 r:0.6546
si_en Dev loss: 0.8018 r:0.5640
ne_en Dev loss: 0.5039 r:0.7357
ru_en Dev loss: 0.4606 r:0.7273
Current avg r:0.5951 Best avg r: 0.6245
05:03:01,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:04:31,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:06:01,747 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1973
en_de Dev loss: 0.8975 r:0.2539
en_zh Dev loss: 0.8279 r:0.4440
ro_en Dev loss: 0.3977 r:0.8008
et_en Dev loss: 0.4849 r:0.6486
si_en Dev loss: 0.8534 r:0.5663
ne_en Dev loss: 0.5327 r:0.7333
ru_en Dev loss: 0.4840 r:0.7277
Current avg r:0.5964 Best avg r: 0.6245
05:10:30,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:12:00,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:13:29,934 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1796
en_de Dev loss: 0.8618 r:0.2401
en_zh Dev loss: 0.7840 r:0.4341
ro_en Dev loss: 0.3657 r:0.8020
et_en Dev loss: 0.4661 r:0.6471
si_en Dev loss: 0.8162 r:0.5632
ne_en Dev loss: 0.4961 r:0.7265
ru_en Dev loss: 0.4484 r:0.7255
Current avg r:0.5912 Best avg r: 0.6245
05:17:58,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:19:28,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:20:58,286 root INFO Epoch 7 Global steps: 81900 Train loss: 0.2068
en_de Dev loss: 0.8601 r:0.2375
en_zh Dev loss: 0.8098 r:0.4281
ro_en Dev loss: 0.3661 r:0.8055
et_en Dev loss: 0.4716 r:0.6575
si_en Dev loss: 0.8001 r:0.5645
ne_en Dev loss: 0.4866 r:0.7275
ru_en Dev loss: 0.4619 r:0.7177
Current avg r:0.5912 Best avg r: 0.6245
05:25:27,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:26:57,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:28:27,171 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1921
en_de Dev loss: 0.9137 r:0.1913
en_zh Dev loss: 0.8452 r:0.4359
ro_en Dev loss: 0.3915 r:0.7996
et_en Dev loss: 0.4736 r:0.6520
si_en Dev loss: 0.8681 r:0.5603
ne_en Dev loss: 0.5083 r:0.7237
ru_en Dev loss: 0.4941 r:0.7212
Current avg r:0.5834 Best avg r: 0.6245
05:32:56,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:34:26,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:35:56,426 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1929
en_de Dev loss: 0.8863 r:0.2144
en_zh Dev loss: 0.8002 r:0.4484
ro_en Dev loss: 0.3847 r:0.8001
et_en Dev loss: 0.4687 r:0.6537
si_en Dev loss: 0.8245 r:0.5583
ne_en Dev loss: 0.5071 r:0.7246
ru_en Dev loss: 0.4813 r:0.7219
Current avg r:0.5888 Best avg r: 0.6245
05:40:25,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:41:55,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:43:25,340 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1901
en_de Dev loss: 0.8736 r:0.2274
en_zh Dev loss: 0.8054 r:0.4489
ro_en Dev loss: 0.3902 r:0.8038
et_en Dev loss: 0.4732 r:0.6612
si_en Dev loss: 0.8087 r:0.5649
ne_en Dev loss: 0.4961 r:0.7261
ru_en Dev loss: 0.4505 r:0.7346
Current avg r:0.5953 Best avg r: 0.6245
05:47:55,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:49:25,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:50:55,518 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1695
en_de Dev loss: 0.8873 r:0.2152
en_zh Dev loss: 0.8171 r:0.4445
ro_en Dev loss: 0.3904 r:0.8015
et_en Dev loss: 0.4736 r:0.6566
si_en Dev loss: 0.8151 r:0.5609
ne_en Dev loss: 0.5137 r:0.7240
ru_en Dev loss: 0.5008 r:0.7142
Current avg r:0.5881 Best avg r: 0.6245
05:55:24,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:56:54,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:58:24,6 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1600
en_de Dev loss: 0.9127 r:0.2258
en_zh Dev loss: 0.8659 r:0.4434
ro_en Dev loss: 0.4461 r:0.8014
et_en Dev loss: 0.4686 r:0.6530
si_en Dev loss: 1.0062 r:0.5485
ne_en Dev loss: 0.6572 r:0.7147
ru_en Dev loss: 0.5614 r:0.7172
Current avg r:0.5863 Best avg r: 0.6245
06:02:52,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:22,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:52,865 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1681
en_de Dev loss: 0.9172 r:0.2257
en_zh Dev loss: 0.8706 r:0.4421
ro_en Dev loss: 0.4316 r:0.7991
et_en Dev loss: 0.4870 r:0.6483
si_en Dev loss: 0.9514 r:0.5602
ne_en Dev loss: 0.6056 r:0.7235
ru_en Dev loss: 0.4826 r:0.7268
Current avg r:0.5894 Best avg r: 0.6245
06:10:22,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:52,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:13:22,95 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1686
en_de Dev loss: 0.8820 r:0.2356
en_zh Dev loss: 0.8289 r:0.4439
ro_en Dev loss: 0.3695 r:0.8073
et_en Dev loss: 0.4779 r:0.6568
si_en Dev loss: 0.8483 r:0.5610
ne_en Dev loss: 0.4993 r:0.7247
ru_en Dev loss: 0.4851 r:0.7146
Current avg r:0.5920 Best avg r: 0.6245
06:17:51,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:19:21,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:20:50,911 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1640
en_de Dev loss: 0.8996 r:0.2227
en_zh Dev loss: 0.8203 r:0.4514
ro_en Dev loss: 0.3638 r:0.8097
et_en Dev loss: 0.4589 r:0.6571
si_en Dev loss: 0.7730 r:0.5704
ne_en Dev loss: 0.5039 r:0.7206
ru_en Dev loss: 0.4729 r:0.7155
Current avg r:0.5925 Best avg r: 0.6245
06:25:19,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:26:49,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:28:19,564 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1741
en_de Dev loss: 0.8851 r:0.2326
en_zh Dev loss: 0.7992 r:0.4601
ro_en Dev loss: 0.3731 r:0.8041
et_en Dev loss: 0.4780 r:0.6570
si_en Dev loss: 0.7997 r:0.5631
ne_en Dev loss: 0.4868 r:0.7258
ru_en Dev loss: 0.4659 r:0.7204
Current avg r:0.5947 Best avg r: 0.6245
06:32:48,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:34:18,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:35:48,296 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1676
en_de Dev loss: 0.8919 r:0.2277
en_zh Dev loss: 0.8244 r:0.4473
ro_en Dev loss: 0.3699 r:0.8086
et_en Dev loss: 0.4604 r:0.6544
si_en Dev loss: 0.8467 r:0.5619
ne_en Dev loss: 0.5143 r:0.7263
ru_en Dev loss: 0.4815 r:0.7174
Current avg r:0.5919 Best avg r: 0.6245
06:40:16,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:46,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:43:16,787 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1745
en_de Dev loss: 0.9236 r:0.2063
en_zh Dev loss: 0.8556 r:0.4430
ro_en Dev loss: 0.4089 r:0.8003
et_en Dev loss: 0.4766 r:0.6415
si_en Dev loss: 0.9701 r:0.5439
ne_en Dev loss: 0.6544 r:0.7195
ru_en Dev loss: 0.5024 r:0.7069
Current avg r:0.5802 Best avg r: 0.6245
06:47:45,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:49:15,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:50:45,327 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1643
en_de Dev loss: 0.8991 r:0.2215
en_zh Dev loss: 0.8141 r:0.4444
ro_en Dev loss: 0.3689 r:0.8062
et_en Dev loss: 0.5028 r:0.6572
si_en Dev loss: 0.8165 r:0.5567
ne_en Dev loss: 0.5269 r:0.7164
ru_en Dev loss: 0.4465 r:0.7240
Current avg r:0.5895 Best avg r: 0.6245
06:55:14,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:56:44,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:58:13,931 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1701
en_de Dev loss: 0.9114 r:0.2244
en_zh Dev loss: 0.8406 r:0.4365
ro_en Dev loss: 0.4010 r:0.8039
et_en Dev loss: 0.4924 r:0.6471
si_en Dev loss: 0.8860 r:0.5531
ne_en Dev loss: 0.5683 r:0.7194
ru_en Dev loss: 0.4997 r:0.7120
Current avg r:0.5852 Best avg r: 0.6245
07:02:43,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:04:13,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:05:42,999 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1728
en_de Dev loss: 0.8995 r:0.2242
en_zh Dev loss: 0.8204 r:0.4288
ro_en Dev loss: 0.3791 r:0.8042
et_en Dev loss: 0.4792 r:0.6544
si_en Dev loss: 0.8983 r:0.5512
ne_en Dev loss: 0.5450 r:0.7206
ru_en Dev loss: 0.4677 r:0.7229
Current avg r:0.5866 Best avg r: 0.6245
07:10:11,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:11:41,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:13:11,597 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1610
en_de Dev loss: 0.9097 r:0.2269
en_zh Dev loss: 0.8567 r:0.4361
ro_en Dev loss: 0.4120 r:0.8029
et_en Dev loss: 0.4975 r:0.6507
si_en Dev loss: 0.9606 r:0.5508
ne_en Dev loss: 0.5848 r:0.7269
ru_en Dev loss: 0.5106 r:0.7158
Current avg r:0.5872 Best avg r: 0.6245
07:17:40,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:19:10,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:39,872 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1700
en_de Dev loss: 0.8864 r:0.2308
en_zh Dev loss: 0.8025 r:0.4422
ro_en Dev loss: 0.3712 r:0.8043
et_en Dev loss: 0.5009 r:0.6604
si_en Dev loss: 0.8279 r:0.5578
ne_en Dev loss: 0.4867 r:0.7252
ru_en Dev loss: 0.4666 r:0.7236
Current avg r:0.5920 Best avg r: 0.6245
07:25:08,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:26:38,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:28:08,9 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1592
en_de Dev loss: 0.8876 r:0.2330
en_zh Dev loss: 0.7989 r:0.4374
ro_en Dev loss: 0.3465 r:0.8100
et_en Dev loss: 0.4497 r:0.6659
si_en Dev loss: 0.7990 r:0.5639
ne_en Dev loss: 0.5017 r:0.7276
ru_en Dev loss: 0.4529 r:0.7236
Current avg r:0.5945 Best avg r: 0.6245
07:32:36,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:34:06,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:35:36,46 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1611
en_de Dev loss: 0.9200 r:0.1990
en_zh Dev loss: 0.8051 r:0.4452
ro_en Dev loss: 0.3870 r:0.8064
et_en Dev loss: 0.4740 r:0.6473
si_en Dev loss: 0.8731 r:0.5487
ne_en Dev loss: 0.5937 r:0.7179
ru_en Dev loss: 0.5149 r:0.7109
Current avg r:0.5822 Best avg r: 0.6245
07:40:06,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:41:36,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:43:06,362 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1464
en_de Dev loss: 0.9246 r:0.1931
en_zh Dev loss: 0.8174 r:0.4490
ro_en Dev loss: 0.3527 r:0.8152
et_en Dev loss: 0.4605 r:0.6646
si_en Dev loss: 0.8039 r:0.5666
ne_en Dev loss: 0.5048 r:0.7258
ru_en Dev loss: 0.4920 r:0.7260
Current avg r:0.5915 Best avg r: 0.6245
07:47:35,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:49:05,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:50:34,892 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1444
en_de Dev loss: 0.9238 r:0.1827
en_zh Dev loss: 0.8477 r:0.4443
ro_en Dev loss: 0.3942 r:0.8084
et_en Dev loss: 0.4796 r:0.6542
si_en Dev loss: 0.9183 r:0.5506
ne_en Dev loss: 0.5749 r:0.7229
ru_en Dev loss: 0.4912 r:0.7275
Current avg r:0.5844 Best avg r: 0.6245
07:55:03,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:56:33,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:58:03,140 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1473
en_de Dev loss: 0.9326 r:0.1685
en_zh Dev loss: 0.8200 r:0.4410
ro_en Dev loss: 0.3718 r:0.8098
et_en Dev loss: 0.4725 r:0.6590
si_en Dev loss: 0.8254 r:0.5593
ne_en Dev loss: 0.5872 r:0.7181
ru_en Dev loss: 0.4860 r:0.7166
Current avg r:0.5818 Best avg r: 0.6245
08:02:31,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:04:01,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:05:31,549 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1425
en_de Dev loss: 0.9832 r:0.1804
en_zh Dev loss: 0.8979 r:0.4441
ro_en Dev loss: 0.4362 r:0.8061
et_en Dev loss: 0.5066 r:0.6489
si_en Dev loss: 0.9620 r:0.5515
ne_en Dev loss: 0.6569 r:0.7188
ru_en Dev loss: 0.5772 r:0.7085
Current avg r:0.5798 Best avg r: 0.6245
08:09:59,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:11:29,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:12:59,734 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1447
en_de Dev loss: 0.9076 r:0.2059
en_zh Dev loss: 0.8145 r:0.4438
ro_en Dev loss: 0.3794 r:0.8102
et_en Dev loss: 0.4732 r:0.6516
si_en Dev loss: 0.8905 r:0.5458
ne_en Dev loss: 0.5809 r:0.7235
ru_en Dev loss: 0.5179 r:0.7158
Current avg r:0.5852 Best avg r: 0.6245
08:17:28,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:18:58,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:20:28,294 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1493
en_de Dev loss: 0.9129 r:0.2026
en_zh Dev loss: 0.7622 r:0.4627
ro_en Dev loss: 0.3523 r:0.8098
et_en Dev loss: 0.4779 r:0.6584
si_en Dev loss: 0.8435 r:0.5510
ne_en Dev loss: 0.4893 r:0.7236
ru_en Dev loss: 0.4272 r:0.7387
Current avg r:0.5924 Best avg r: 0.6245
08:24:56,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:26,808 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:27:56,616 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1462
en_de Dev loss: 0.9198 r:0.2108
en_zh Dev loss: 0.7799 r:0.4574
ro_en Dev loss: 0.3567 r:0.8091
et_en Dev loss: 0.4927 r:0.6579
si_en Dev loss: 0.8009 r:0.5614
ne_en Dev loss: 0.4754 r:0.7239
ru_en Dev loss: 0.4670 r:0.7202
Current avg r:0.5915 Best avg r: 0.6245
08:32:25,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:33:55,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:35:24,793 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1455
en_de Dev loss: 0.9327 r:0.2035
en_zh Dev loss: 0.8245 r:0.4537
ro_en Dev loss: 0.3801 r:0.8062
et_en Dev loss: 0.4952 r:0.6536
si_en Dev loss: 0.8434 r:0.5593
ne_en Dev loss: 0.5012 r:0.7255
ru_en Dev loss: 0.4982 r:0.7129
Current avg r:0.5878 Best avg r: 0.6245
08:39:53,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:41:23,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:42:52,951 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1495
en_de Dev loss: 0.8904 r:0.2167
en_zh Dev loss: 0.7849 r:0.4518
ro_en Dev loss: 0.3667 r:0.8101
et_en Dev loss: 0.4832 r:0.6398
si_en Dev loss: 0.8936 r:0.5526
ne_en Dev loss: 0.5835 r:0.7258
ru_en Dev loss: 0.4873 r:0.7116
Current avg r:0.5869 Best avg r: 0.6245
08:47:21,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:51,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:50:21,130 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1448
en_de Dev loss: 0.9365 r:0.2026
en_zh Dev loss: 0.8458 r:0.4502
ro_en Dev loss: 0.3935 r:0.8089
et_en Dev loss: 0.5011 r:0.6438
si_en Dev loss: 0.9013 r:0.5510
ne_en Dev loss: 0.5629 r:0.7269
ru_en Dev loss: 0.4931 r:0.7255
Current avg r:0.5870 Best avg r: 0.6245
08:54:50,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:56:19,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:57:49,828 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1440
en_de Dev loss: 0.9194 r:0.1920
en_zh Dev loss: 0.7802 r:0.4577
ro_en Dev loss: 0.3523 r:0.8115
et_en Dev loss: 0.4774 r:0.6542
si_en Dev loss: 0.8332 r:0.5516
ne_en Dev loss: 0.5005 r:0.7248
ru_en Dev loss: 0.4609 r:0.7216
Current avg r:0.5876 Best avg r: 0.6245
09:02:18,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:03:48,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:05:18,623 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1471
en_de Dev loss: 0.9236 r:0.1984
en_zh Dev loss: 0.8194 r:0.4554
ro_en Dev loss: 0.3575 r:0.8073
et_en Dev loss: 0.4769 r:0.6529
si_en Dev loss: 0.8579 r:0.5479
ne_en Dev loss: 0.4862 r:0.7250
ru_en Dev loss: 0.4837 r:0.7187
Current avg r:0.5865 Best avg r: 0.6245
09:09:47,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:11:17,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:12:47,406 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1453
en_de Dev loss: 0.9440 r:0.1967
en_zh Dev loss: 0.8175 r:0.4564
ro_en Dev loss: 0.3664 r:0.8095
et_en Dev loss: 0.4859 r:0.6521
si_en Dev loss: 0.8474 r:0.5506
ne_en Dev loss: 0.5433 r:0.7229
ru_en Dev loss: 0.4810 r:0.7188
Current avg r:0.5867 Best avg r: 0.6245
09:17:16,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:45,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:20:15,762 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1388
en_de Dev loss: 0.9305 r:0.1911
en_zh Dev loss: 0.8441 r:0.4503
ro_en Dev loss: 0.3970 r:0.8061
et_en Dev loss: 0.4787 r:0.6507
si_en Dev loss: 0.8892 r:0.5500
ne_en Dev loss: 0.6126 r:0.7248
ru_en Dev loss: 0.5056 r:0.7141
Current avg r:0.5839 Best avg r: 0.6245
09:24:44,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:26:14,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:27:44,109 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1491
en_de Dev loss: 0.9292 r:0.2041
en_zh Dev loss: 0.7825 r:0.4598
ro_en Dev loss: 0.3639 r:0.8126
et_en Dev loss: 0.4814 r:0.6598
si_en Dev loss: 0.8278 r:0.5586
ne_en Dev loss: 0.5013 r:0.7302
ru_en Dev loss: 0.4329 r:0.7392
Current avg r:0.5949 Best avg r: 0.6245
09:32:14,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:33:44,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:35:13,856 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1284
en_de Dev loss: 0.9400 r:0.1782
en_zh Dev loss: 0.8178 r:0.4560
ro_en Dev loss: 0.3818 r:0.8106
et_en Dev loss: 0.4919 r:0.6472
si_en Dev loss: 0.9540 r:0.5477
ne_en Dev loss: 0.5743 r:0.7250
ru_en Dev loss: 0.4852 r:0.7183
Current avg r:0.5833 Best avg r: 0.6245
09:39:42,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:12,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:42:42,627 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1345
en_de Dev loss: 0.9827 r:0.1827
en_zh Dev loss: 0.8482 r:0.4550
ro_en Dev loss: 0.3665 r:0.8140
et_en Dev loss: 0.4800 r:0.6560
si_en Dev loss: 0.8159 r:0.5564
ne_en Dev loss: 0.4853 r:0.7213
ru_en Dev loss: 0.5140 r:0.7162
Current avg r:0.5859 Best avg r: 0.6245
09:47:11,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:41,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:50:11,666 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1295
en_de Dev loss: 0.9165 r:0.1926
en_zh Dev loss: 0.8065 r:0.4528
ro_en Dev loss: 0.3609 r:0.8115
et_en Dev loss: 0.4750 r:0.6450
si_en Dev loss: 0.8665 r:0.5525
ne_en Dev loss: 0.5650 r:0.7180
ru_en Dev loss: 0.4893 r:0.7137
Current avg r:0.5837 Best avg r: 0.6245
09:54:40,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:10,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:40,669 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1372
en_de Dev loss: 0.9428 r:0.1862
en_zh Dev loss: 0.7957 r:0.4556
ro_en Dev loss: 0.3768 r:0.8135
et_en Dev loss: 0.4804 r:0.6471
si_en Dev loss: 0.8634 r:0.5522
ne_en Dev loss: 0.5501 r:0.7209
ru_en Dev loss: 0.4772 r:0.7251
Current avg r:0.5858 Best avg r: 0.6245
10:02:09,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:03:39,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:09,599 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1224
en_de Dev loss: 0.9302 r:0.2011
en_zh Dev loss: 0.7928 r:0.4510
ro_en Dev loss: 0.3612 r:0.8101
et_en Dev loss: 0.4714 r:0.6468
si_en Dev loss: 0.8562 r:0.5506
ne_en Dev loss: 0.5116 r:0.7231
ru_en Dev loss: 0.4749 r:0.7203
Current avg r:0.5861 Best avg r: 0.6245
10:09:38,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:08,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:38,455 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1315
en_de Dev loss: 0.9260 r:0.2080
en_zh Dev loss: 0.8060 r:0.4508
ro_en Dev loss: 0.3630 r:0.8127
et_en Dev loss: 0.5006 r:0.6513
si_en Dev loss: 0.8568 r:0.5506
ne_en Dev loss: 0.5227 r:0.7255
ru_en Dev loss: 0.4761 r:0.7209
Current avg r:0.5885 Best avg r: 0.6245
10:17:07,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:37,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:07,205 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1277
en_de Dev loss: 0.9632 r:0.1896
en_zh Dev loss: 0.7972 r:0.4631
ro_en Dev loss: 0.3660 r:0.8134
et_en Dev loss: 0.5161 r:0.6523
si_en Dev loss: 0.8783 r:0.5542
ne_en Dev loss: 0.5051 r:0.7266
ru_en Dev loss: 0.4369 r:0.7431
Current avg r:0.5917 Best avg r: 0.6245
10:24:35,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:26:05,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:35,472 root INFO Epoch 10 Global steps: 110600 Train loss: 0.1294
en_de Dev loss: 0.9500 r:0.2158
en_zh Dev loss: 0.8491 r:0.4506
ro_en Dev loss: 0.3806 r:0.8119
et_en Dev loss: 0.4763 r:0.6498
si_en Dev loss: 0.8724 r:0.5553
ne_en Dev loss: 0.5747 r:0.7161
ru_en Dev loss: 0.5239 r:0.7188
Current avg r:0.5883 Best avg r: 0.6245
