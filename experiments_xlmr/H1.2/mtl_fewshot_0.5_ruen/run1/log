14:54:50,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:15,940 root INFO 
id:en_zh cur r: 0.1398 best r: 0.1398
14:55:28,884 root INFO 
id:ro_en cur r: 0.5350 best r: 0.5350
14:55:41,855 root INFO 
id:et_en cur r: 0.5480 best r: 0.5480
14:55:54,847 root INFO 
id:si_en cur r: 0.4359 best r: 0.4359
14:56:07,840 root INFO 
id:ne_en cur r: 0.5782 best r: 0.5782
14:56:33,560 root INFO 
id:ru_en cur r: 0.4511 best r: 0.4511
14:56:33,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:03,921 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
14:58:03,927 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:58:03,931 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:58:03,936 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
14:58:03,941 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
14:58:03,946 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:58:03,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:58:16,785 root INFO Epoch 0 Global steps: 700 Train loss: 0.8714
en_de Dev loss: 0.8932 r:0.0906
en_zh Dev loss: 0.8102 r:0.2278
ro_en Dev loss: 0.6556 r:0.6142
et_en Dev loss: 0.5193 r:0.5560
si_en Dev loss: 0.7167 r:0.4558
ne_en Dev loss: 0.5637 r:0.6136
ru_en Dev loss: 0.6577 r:0.4764
Current avg r:0.4335 Best avg r: 0.4335
15:02:48,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:01,499 root INFO 
id:en_de cur r: 0.0246 best r: 0.0246
15:03:14,360 root INFO 
id:en_zh cur r: 0.1794 best r: 0.1794
15:03:27,257 root INFO 
id:ro_en cur r: 0.6028 best r: 0.6028
15:03:40,156 root INFO 
id:et_en cur r: 0.6097 best r: 0.6097
15:03:53,76 root INFO 
id:si_en cur r: 0.4663 best r: 0.4663
15:04:05,992 root INFO 
id:ne_en cur r: 0.5817 best r: 0.5817
15:04:31,646 root INFO 
id:ru_en cur r: 0.6117 best r: 0.6117
15:04:31,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:01,869 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:06:01,875 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:06:01,880 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:06:01,885 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:06:01,891 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:06:01,896 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:06:01,901 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:06:14,741 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8107
en_de Dev loss: 0.8926 r:0.1131
en_zh Dev loss: 0.7626 r:0.2800
ro_en Dev loss: 0.6747 r:0.6472
et_en Dev loss: 0.4999 r:0.6250
si_en Dev loss: 0.7086 r:0.5025
ne_en Dev loss: 0.5365 r:0.6447
ru_en Dev loss: 0.6231 r:0.6183
Current avg r:0.4901 Best avg r: 0.4901
15:10:48,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:14,319 root INFO 
id:en_zh cur r: 0.2853 best r: 0.2853
15:11:27,213 root INFO 
id:ro_en cur r: 0.6530 best r: 0.6530
15:11:40,112 root INFO 
id:et_en cur r: 0.6634 best r: 0.6634
15:11:53,34 root INFO 
id:si_en cur r: 0.4939 best r: 0.4939
15:12:05,930 root INFO 
id:ne_en cur r: 0.6614 best r: 0.6614
15:12:31,610 root INFO 
id:ru_en cur r: 0.6694 best r: 0.6694
15:12:31,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:01,793 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:14:01,799 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:14:01,805 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:14:01,811 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:14:01,816 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:14:01,821 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:14:01,826 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:14:14,675 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7904
en_de Dev loss: 0.8905 r:0.1201
en_zh Dev loss: 0.7394 r:0.3247
ro_en Dev loss: 0.5813 r:0.6748
et_en Dev loss: 0.4268 r:0.6680
si_en Dev loss: 0.6395 r:0.5191
ne_en Dev loss: 0.4653 r:0.6769
ru_en Dev loss: 0.5546 r:0.6787
Current avg r:0.5232 Best avg r: 0.5232
15:18:47,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:00,108 root INFO 
id:en_de cur r: 0.1376 best r: 0.1376
15:20:30,307 root INFO 
id:ru_en cur r: 0.7161 best r: 0.7161
15:20:30,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:00,592 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:22:00,599 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:22:00,604 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:22:00,609 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:22:00,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:22:00,619 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:22:00,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:22:13,465 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6802
en_de Dev loss: 0.9930 r:0.1509
en_zh Dev loss: 0.8306 r:0.3441
ro_en Dev loss: 0.5961 r:0.6801
et_en Dev loss: 0.4427 r:0.6705
si_en Dev loss: 0.7519 r:0.5165
ne_en Dev loss: 0.4780 r:0.6479
ru_en Dev loss: 0.5596 r:0.7239
Current avg r:0.5334 Best avg r: 0.5334
15:26:46,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:58,924 root INFO 
id:en_de cur r: 0.1472 best r: 0.1472
15:27:11,800 root INFO 
id:en_zh cur r: 0.2989 best r: 0.2989
15:27:24,689 root INFO 
id:ro_en cur r: 0.6887 best r: 0.6887
15:27:37,602 root INFO 
id:et_en cur r: 0.6879 best r: 0.6879
15:27:50,532 root INFO 
id:si_en cur r: 0.5157 best r: 0.5157
15:28:03,459 root INFO 
id:ne_en cur r: 0.6660 best r: 0.6660
15:28:29,160 root INFO 
id:ru_en cur r: 0.7351 best r: 0.7351
15:28:29,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:59,388 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:29:59,394 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:29:59,399 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:29:59,404 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:29:59,408 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:29:59,414 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:29:59,421 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:30:12,260 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6852
en_de Dev loss: 0.9115 r:0.1673
en_zh Dev loss: 0.7488 r:0.3643
ro_en Dev loss: 0.4738 r:0.7067
et_en Dev loss: 0.3721 r:0.6950
si_en Dev loss: 0.7121 r:0.5254
ne_en Dev loss: 0.4311 r:0.6755
ru_en Dev loss: 0.4154 r:0.7451
Current avg r:0.5542 Best avg r: 0.5542
15:34:45,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:58,95 root INFO 
id:en_de cur r: 0.1803 best r: 0.1803
15:35:10,954 root INFO 
id:en_zh cur r: 0.3532 best r: 0.3532
15:35:23,854 root INFO 
id:ro_en cur r: 0.7196 best r: 0.7196
15:35:49,690 root INFO 
id:si_en cur r: 0.5357 best r: 0.5357
15:36:02,616 root INFO 
id:ne_en cur r: 0.6857 best r: 0.6857
15:36:15,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:37:45,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:37:45,792 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:37:45,797 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:37:45,803 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:37:45,807 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:37:45,811 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:37:45,816 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:37:58,669 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6420
en_de Dev loss: 0.9227 r:0.1862
en_zh Dev loss: 0.7399 r:0.3826
ro_en Dev loss: 0.4613 r:0.7316
et_en Dev loss: 0.3827 r:0.6937
si_en Dev loss: 0.7283 r:0.5464
ne_en Dev loss: 0.4240 r:0.6940
ru_en Dev loss: 0.4305 r:0.7497
Current avg r:0.5692 Best avg r: 0.5692
15:42:31,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:56,926 root INFO 
id:en_zh cur r: 0.3894 best r: 0.3894
15:43:09,818 root INFO 
id:ro_en cur r: 0.7440 best r: 0.7440
15:43:22,738 root INFO 
id:et_en cur r: 0.7099 best r: 0.7099
15:43:35,675 root INFO 
id:si_en cur r: 0.5626 best r: 0.5626
15:43:48,601 root INFO 
id:ne_en cur r: 0.7172 best r: 0.7172
15:44:01,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:31,724 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:45:31,730 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:45:31,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:45:31,741 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:45:31,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:45:31,751 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:45:31,756 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:45:44,600 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5769
en_de Dev loss: 0.9074 r:0.1792
en_zh Dev loss: 0.7209 r:0.3933
ro_en Dev loss: 0.4093 r:0.7528
et_en Dev loss: 0.3573 r:0.7114
si_en Dev loss: 0.7404 r:0.5648
ne_en Dev loss: 0.4291 r:0.7055
ru_en Dev loss: 0.4377 r:0.7455
Current avg r:0.5789 Best avg r: 0.5789
15:50:16,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:55,617 root INFO 
id:ro_en cur r: 0.7647 best r: 0.7647
15:51:08,513 root INFO 
id:et_en cur r: 0.7114 best r: 0.7114
15:51:21,437 root INFO 
id:si_en cur r: 0.5744 best r: 0.5744
15:51:47,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:17,439 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
15:53:17,446 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:53:17,450 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:53:17,455 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
15:53:17,460 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
15:53:17,464 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:53:17,469 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:53:31,739 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5965
en_de Dev loss: 0.9486 r:0.1898
en_zh Dev loss: 0.7846 r:0.3953
ro_en Dev loss: 0.4430 r:0.7720
et_en Dev loss: 0.3987 r:0.7171
si_en Dev loss: 0.8380 r:0.5832
ne_en Dev loss: 0.5489 r:0.7104
ru_en Dev loss: 0.5270 r:0.7361
Current avg r:0.5863 Best avg r: 0.5863
15:58:04,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:17,268 root INFO 
id:en_de cur r: 0.1912 best r: 0.1912
15:58:30,132 root INFO 
id:en_zh cur r: 0.4148 best r: 0.4148
15:58:55,935 root INFO 
id:et_en cur r: 0.7120 best r: 0.7120
15:59:08,866 root INFO 
id:si_en cur r: 0.5823 best r: 0.5823
15:59:21,779 root INFO 
id:ne_en cur r: 0.7279 best r: 0.7279
15:59:34,603 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:04,778 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:01:04,784 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:01:04,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:01:04,794 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:01:04,799 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:01:04,805 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:01:04,810 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:01:17,644 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5890
en_de Dev loss: 0.8746 r:0.1983
en_zh Dev loss: 0.6734 r:0.4243
ro_en Dev loss: 0.3491 r:0.7708
et_en Dev loss: 0.3453 r:0.7221
si_en Dev loss: 0.5941 r:0.5880
ne_en Dev loss: 0.3861 r:0.7204
ru_en Dev loss: 0.3697 r:0.7566
Current avg r:0.5972 Best avg r: 0.5972
16:05:49,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:06:02,583 root INFO 
id:en_de cur r: 0.2093 best r: 0.2093
16:06:28,334 root INFO 
id:ro_en cur r: 0.7768 best r: 0.7768
16:06:41,229 root INFO 
id:et_en cur r: 0.7250 best r: 0.7250
16:06:54,159 root INFO 
id:si_en cur r: 0.5918 best r: 0.5918
16:07:07,70 root INFO 
id:ne_en cur r: 0.7447 best r: 0.7447
16:07:32,737 root INFO 
id:ru_en cur r: 0.7406 best r: 0.7406
16:07:32,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:03,13 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:09:03,19 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:09:03,24 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:09:03,28 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:09:03,33 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:09:03,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:09:03,42 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:09:15,887 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5558
en_de Dev loss: 0.8892 r:0.2098
en_zh Dev loss: 0.7053 r:0.4074
ro_en Dev loss: 0.3590 r:0.7805
et_en Dev loss: 0.3387 r:0.7283
si_en Dev loss: 0.6559 r:0.5954
ne_en Dev loss: 0.3808 r:0.7397
ru_en Dev loss: 0.4158 r:0.7518
Current avg r:0.6019 Best avg r: 0.6019
16:13:48,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:01,595 root INFO 
id:en_de cur r: 0.2121 best r: 0.2121
16:14:27,348 root INFO 
id:ro_en cur r: 0.7791 best r: 0.7791
16:15:18,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:49,183 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5287
en_de Dev loss: 0.8867 r:0.1984
en_zh Dev loss: 0.7222 r:0.4018
ro_en Dev loss: 0.3588 r:0.7851
et_en Dev loss: 0.3512 r:0.7174
si_en Dev loss: 0.7036 r:0.5834
ne_en Dev loss: 0.4249 r:0.7243
ru_en Dev loss: 0.4471 r:0.7435
Current avg r:0.5934 Best avg r: 0.6019
16:21:23,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:02,81 root INFO 
id:ro_en cur r: 0.7921 best r: 0.7921
16:22:27,899 root INFO 
id:si_en cur r: 0.5949 best r: 0.5949
16:22:40,804 root INFO 
id:ne_en cur r: 0.7549 best r: 0.7549
16:23:06,471 root INFO 
id:ru_en cur r: 0.7503 best r: 0.7503
16:23:06,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:24:36,654 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:24:36,660 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:24:36,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:24:36,673 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:24:36,677 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:24:36,681 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:24:36,686 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:24:49,525 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5232
en_de Dev loss: 0.9156 r:0.1892
en_zh Dev loss: 0.7438 r:0.4127
ro_en Dev loss: 0.3438 r:0.7992
et_en Dev loss: 0.3332 r:0.7274
si_en Dev loss: 0.5934 r:0.6067
ne_en Dev loss: 0.3546 r:0.7494
ru_en Dev loss: 0.4101 r:0.7608
Current avg r:0.6065 Best avg r: 0.6065
16:29:21,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:47,726 root INFO 
id:en_zh cur r: 0.4386 best r: 0.4386
16:30:00,611 root INFO 
id:ro_en cur r: 0.8068 best r: 0.8068
16:30:13,519 root INFO 
id:et_en cur r: 0.7276 best r: 0.7276
16:30:26,435 root INFO 
id:si_en cur r: 0.6042 best r: 0.6042
16:31:05,26 root INFO 
id:ru_en cur r: 0.7524 best r: 0.7524
16:31:05,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:32:35,239 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
16:32:35,246 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:32:35,252 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:32:35,257 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
16:32:35,270 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
16:32:35,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:32:35,279 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:32:48,108 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5103
en_de Dev loss: 0.8671 r:0.1988
en_zh Dev loss: 0.6734 r:0.4410
ro_en Dev loss: 0.3238 r:0.8092
et_en Dev loss: 0.3295 r:0.7304
si_en Dev loss: 0.6313 r:0.6153
ne_en Dev loss: 0.3937 r:0.7516
ru_en Dev loss: 0.4060 r:0.7632
Current avg r:0.6156 Best avg r: 0.6156
16:37:20,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:46,437 root INFO 
id:en_zh cur r: 0.4408 best r: 0.4408
16:39:03,670 root INFO 
id:ru_en cur r: 0.7613 best r: 0.7613
16:39:03,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:33,895 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5352
en_de Dev loss: 0.9380 r:0.1977
en_zh Dev loss: 0.7552 r:0.4435
ro_en Dev loss: 0.4046 r:0.8075
et_en Dev loss: 0.3816 r:0.7196
si_en Dev loss: 0.7671 r:0.6069
ne_en Dev loss: 0.4281 r:0.7487
ru_en Dev loss: 0.4449 r:0.7630
Current avg r:0.6124 Best avg r: 0.6156
16:45:06,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:32,358 root INFO 
id:en_zh cur r: 0.4461 best r: 0.4461
16:45:45,253 root INFO 
id:ro_en cur r: 0.8126 best r: 0.8126
16:46:11,88 root INFO 
id:si_en cur r: 0.6092 best r: 0.6092
16:46:23,996 root INFO 
id:ne_en cur r: 0.7615 best r: 0.7615
16:46:36,826 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:07,73 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5347
en_de Dev loss: 0.8726 r:0.1856
en_zh Dev loss: 0.6870 r:0.4416
ro_en Dev loss: 0.3186 r:0.8143
et_en Dev loss: 0.3377 r:0.7277
si_en Dev loss: 0.6175 r:0.6163
ne_en Dev loss: 0.3622 r:0.7548
ru_en Dev loss: 0.4402 r:0.7495
Current avg r:0.6128 Best avg r: 0.6156
16:52:41,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:06,904 root INFO 
id:en_zh cur r: 0.4503 best r: 0.4503
16:53:19,792 root INFO 
id:ro_en cur r: 0.8183 best r: 0.8183
16:53:45,629 root INFO 
id:si_en cur r: 0.6116 best r: 0.6116
16:54:11,370 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:41,599 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4967
en_de Dev loss: 0.8690 r:0.1931
en_zh Dev loss: 0.7205 r:0.4432
ro_en Dev loss: 0.3299 r:0.8173
et_en Dev loss: 0.3413 r:0.7282
si_en Dev loss: 0.7113 r:0.6149
ne_en Dev loss: 0.4008 r:0.7521
ru_en Dev loss: 0.4232 r:0.7575
Current avg r:0.6152 Best avg r: 0.6156
17:00:13,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:44,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:14,349 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4725
en_de Dev loss: 0.8589 r:0.1881
en_zh Dev loss: 0.6932 r:0.4452
ro_en Dev loss: 0.2968 r:0.8144
et_en Dev loss: 0.3391 r:0.7221
si_en Dev loss: 0.5977 r:0.6150
ne_en Dev loss: 0.3720 r:0.7491
ru_en Dev loss: 0.3981 r:0.7510
Current avg r:0.6121 Best avg r: 0.6156
17:07:45,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:15,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:10:46,2 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4802
en_de Dev loss: 0.8768 r:0.2068
en_zh Dev loss: 0.7033 r:0.4491
ro_en Dev loss: 0.3234 r:0.8132
et_en Dev loss: 0.3408 r:0.7286
si_en Dev loss: 0.6355 r:0.6203
ne_en Dev loss: 0.4044 r:0.7491
ru_en Dev loss: 0.4713 r:0.7386
Current avg r:0.6151 Best avg r: 0.6156
17:15:17,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:47,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:17,612 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4852
en_de Dev loss: 0.8819 r:0.2060
en_zh Dev loss: 0.7282 r:0.4553
ro_en Dev loss: 0.3467 r:0.8111
et_en Dev loss: 0.3494 r:0.7221
si_en Dev loss: 0.7681 r:0.6182
ne_en Dev loss: 0.4870 r:0.7487
ru_en Dev loss: 0.4390 r:0.7471
Current avg r:0.6155 Best avg r: 0.6156
17:22:48,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:14,426 root INFO 
id:en_zh cur r: 0.4598 best r: 0.4598
17:23:27,304 root INFO 
id:ro_en cur r: 0.8229 best r: 0.8229
17:23:40,196 root INFO 
id:et_en cur r: 0.7329 best r: 0.7329
17:23:53,95 root INFO 
id:si_en cur r: 0.6187 best r: 0.6187
17:24:05,988 root INFO 
id:ne_en cur r: 0.7728 best r: 0.7728
17:24:31,625 root INFO 
id:ru_en cur r: 0.7639 best r: 0.7639
17:24:31,626 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:01,641 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_de.lang_agnost_mlp.dev.best.scores
17:26:01,647 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:26:01,652 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:26:01,657 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/et_en.lang_agnost_mlp.dev.best.scores
17:26:01,663 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/si_en.lang_agnost_mlp.dev.best.scores
17:26:01,669 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:26:01,674 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:26:14,503 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4796
en_de Dev loss: 0.8555 r:0.2063
en_zh Dev loss: 0.6767 r:0.4548
ro_en Dev loss: 0.3034 r:0.8187
et_en Dev loss: 0.3401 r:0.7326
si_en Dev loss: 0.5545 r:0.6266
ne_en Dev loss: 0.3372 r:0.7666
ru_en Dev loss: 0.3756 r:0.7654
Current avg r:0.6244 Best avg r: 0.6244
17:30:45,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:58,641 root INFO 
id:en_de cur r: 0.2215 best r: 0.2215
17:32:15,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:45,812 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4852
en_de Dev loss: 0.8484 r:0.2158
en_zh Dev loss: 0.6796 r:0.4540
ro_en Dev loss: 0.3052 r:0.8168
et_en Dev loss: 0.3461 r:0.7314
si_en Dev loss: 0.6283 r:0.6158
ne_en Dev loss: 0.3708 r:0.7628
ru_en Dev loss: 0.3839 r:0.7612
Current avg r:0.6225 Best avg r: 0.6244
17:38:16,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:42,515 root INFO 
id:en_zh cur r: 0.4708 best r: 0.4708
17:39:46,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:16,945 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4484
en_de Dev loss: 0.8620 r:0.2001
en_zh Dev loss: 0.7101 r:0.4658
ro_en Dev loss: 0.3325 r:0.8169
et_en Dev loss: 0.3483 r:0.7232
si_en Dev loss: 0.7317 r:0.6073
ne_en Dev loss: 0.4323 r:0.7547
ru_en Dev loss: 0.4073 r:0.7594
Current avg r:0.6182 Best avg r: 0.6244
17:45:48,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:27,366 root INFO 
id:ro_en cur r: 0.8257 best r: 0.8257
17:47:18,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:48,914 root INFO Epoch 1 Global steps: 16100 Train loss: 0.5022
en_de Dev loss: 0.8596 r:0.2026
en_zh Dev loss: 0.6671 r:0.4587
ro_en Dev loss: 0.2921 r:0.8194
et_en Dev loss: 0.3453 r:0.7271
si_en Dev loss: 0.5987 r:0.6134
ne_en Dev loss: 0.3536 r:0.7578
ru_en Dev loss: 0.3810 r:0.7629
Current avg r:0.6203 Best avg r: 0.6244
17:53:20,721 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:33,602 root INFO 
id:en_de cur r: 0.2314 best r: 0.2314
17:54:50,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:20,735 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4694
en_de Dev loss: 0.8541 r:0.2160
en_zh Dev loss: 0.6908 r:0.4547
ro_en Dev loss: 0.3374 r:0.8176
et_en Dev loss: 0.3520 r:0.7244
si_en Dev loss: 0.8110 r:0.6054
ne_en Dev loss: 0.4926 r:0.7463
ru_en Dev loss: 0.4421 r:0.7522
Current avg r:0.6167 Best avg r: 0.6244
18:00:51,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:21,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:51,994 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4370
en_de Dev loss: 0.8736 r:0.2170
en_zh Dev loss: 0.7084 r:0.4464
ro_en Dev loss: 0.3092 r:0.8113
et_en Dev loss: 0.3559 r:0.7172
si_en Dev loss: 0.6202 r:0.6089
ne_en Dev loss: 0.3614 r:0.7565
ru_en Dev loss: 0.4167 r:0.7419
Current avg r:0.6142 Best avg r: 0.6244
18:08:23,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:53,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:23,133 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4520
en_de Dev loss: 0.8805 r:0.2128
en_zh Dev loss: 0.7162 r:0.4522
ro_en Dev loss: 0.3242 r:0.8116
et_en Dev loss: 0.3609 r:0.7081
si_en Dev loss: 0.7309 r:0.5948
ne_en Dev loss: 0.4209 r:0.7485
ru_en Dev loss: 0.4924 r:0.7147
Current avg r:0.6061 Best avg r: 0.6244
18:15:54,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:37,799 root INFO 
id:ru_en cur r: 0.7711 best r: 0.7711
18:17:37,800 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:07,782 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4570
en_de Dev loss: 0.8650 r:0.1927
en_zh Dev loss: 0.6774 r:0.4630
ro_en Dev loss: 0.3130 r:0.8181
et_en Dev loss: 0.3558 r:0.7135
si_en Dev loss: 0.6749 r:0.6126
ne_en Dev loss: 0.3458 r:0.7652
ru_en Dev loss: 0.3754 r:0.7674
Current avg r:0.6189 Best avg r: 0.6244
18:23:39,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:24:17,676 root INFO 
id:ro_en cur r: 0.8284 best r: 0.8284
18:25:09,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:39,160 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4266
en_de Dev loss: 0.8640 r:0.1883
en_zh Dev loss: 0.6848 r:0.4639
ro_en Dev loss: 0.3037 r:0.8212
et_en Dev loss: 0.3534 r:0.7204
si_en Dev loss: 0.6691 r:0.6165
ne_en Dev loss: 0.3828 r:0.7635
ru_en Dev loss: 0.3953 r:0.7538
Current avg r:0.6182 Best avg r: 0.6244
18:31:11,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:15,519 root INFO 
id:si_en cur r: 0.6195 best r: 0.6195
18:32:41,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:11,326 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4329
en_de Dev loss: 0.8996 r:0.1680
en_zh Dev loss: 0.7197 r:0.4571
ro_en Dev loss: 0.3451 r:0.8181
et_en Dev loss: 0.3788 r:0.7234
si_en Dev loss: 0.6329 r:0.6245
ne_en Dev loss: 0.3744 r:0.7614
ru_en Dev loss: 0.4277 r:0.7524
Current avg r:0.6150 Best avg r: 0.6244
18:38:43,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:08,972 root INFO 
id:en_zh cur r: 0.4765 best r: 0.4765
18:39:47,655 root INFO 
id:si_en cur r: 0.6202 best r: 0.6202
18:40:00,552 root INFO 
id:ne_en cur r: 0.7748 best r: 0.7748
18:40:13,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:41:43,457 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4430
en_de Dev loss: 0.8666 r:0.1710
en_zh Dev loss: 0.6607 r:0.4721
ro_en Dev loss: 0.2990 r:0.8199
et_en Dev loss: 0.3725 r:0.7207
si_en Dev loss: 0.5939 r:0.6242
ne_en Dev loss: 0.3500 r:0.7670
ru_en Dev loss: 0.3805 r:0.7549
Current avg r:0.6186 Best avg r: 0.6244
18:46:16,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:46,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:16,654 root INFO Epoch 2 Global steps: 21700 Train loss: 0.3863
en_de Dev loss: 0.8721 r:0.1977
en_zh Dev loss: 0.6933 r:0.4639
ro_en Dev loss: 0.3151 r:0.8183
et_en Dev loss: 0.3767 r:0.7168
si_en Dev loss: 0.6016 r:0.6172
ne_en Dev loss: 0.3597 r:0.7661
ru_en Dev loss: 0.4473 r:0.7322
Current avg r:0.6160 Best avg r: 0.6244
18:53:47,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:13,708 root INFO 
id:en_zh cur r: 0.4818 best r: 0.4818
18:55:18,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:56:48,55 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4000
en_de Dev loss: 0.8826 r:0.2006
en_zh Dev loss: 0.6900 r:0.4783
ro_en Dev loss: 0.3439 r:0.8179
et_en Dev loss: 0.3800 r:0.7109
si_en Dev loss: 0.6908 r:0.6156
ne_en Dev loss: 0.4132 r:0.7655
ru_en Dev loss: 0.4577 r:0.7439
Current avg r:0.6189 Best avg r: 0.6244
19:01:19,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:49,281 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:19,302 root INFO Epoch 2 Global steps: 23100 Train loss: 0.3673
en_de Dev loss: 0.8573 r:0.2203
en_zh Dev loss: 0.7232 r:0.4573
ro_en Dev loss: 0.3337 r:0.8151
et_en Dev loss: 0.3785 r:0.7132
si_en Dev loss: 0.6357 r:0.6178
ne_en Dev loss: 0.3757 r:0.7692
ru_en Dev loss: 0.4368 r:0.7405
Current avg r:0.6190 Best avg r: 0.6244
19:08:50,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:20,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:11:50,873 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4139
en_de Dev loss: 0.8552 r:0.2021
en_zh Dev loss: 0.6943 r:0.4694
ro_en Dev loss: 0.3128 r:0.8205
et_en Dev loss: 0.3789 r:0.7145
si_en Dev loss: 0.6691 r:0.6174
ne_en Dev loss: 0.3664 r:0.7719
ru_en Dev loss: 0.4184 r:0.7451
Current avg r:0.6201 Best avg r: 0.6244
19:16:22,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:17:52,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:22,842 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4173
en_de Dev loss: 0.8869 r:0.1810
en_zh Dev loss: 0.7003 r:0.4746
ro_en Dev loss: 0.3179 r:0.8219
et_en Dev loss: 0.3873 r:0.7081
si_en Dev loss: 0.6351 r:0.6148
ne_en Dev loss: 0.3874 r:0.7632
ru_en Dev loss: 0.4154 r:0.7445
Current avg r:0.6154 Best avg r: 0.6244
19:23:54,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:24,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:54,796 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3880
en_de Dev loss: 0.8797 r:0.1679
en_zh Dev loss: 0.7349 r:0.4491
ro_en Dev loss: 0.3242 r:0.8146
et_en Dev loss: 0.3760 r:0.7024
si_en Dev loss: 0.7328 r:0.5992
ne_en Dev loss: 0.4183 r:0.7599
ru_en Dev loss: 0.4438 r:0.7277
Current avg r:0.6030 Best avg r: 0.6244
19:31:26,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:56,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:26,819 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4003
en_de Dev loss: 0.8776 r:0.1900
en_zh Dev loss: 0.7251 r:0.4695
ro_en Dev loss: 0.3376 r:0.8189
et_en Dev loss: 0.3728 r:0.6989
si_en Dev loss: 0.7558 r:0.6025
ne_en Dev loss: 0.4386 r:0.7606
ru_en Dev loss: 0.5048 r:0.7108
Current avg r:0.6073 Best avg r: 0.6244
19:38:58,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:37,430 root INFO 
id:ro_en cur r: 0.8285 best r: 0.8285
19:40:28,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:58,939 root INFO Epoch 2 Global steps: 26600 Train loss: 0.3816
en_de Dev loss: 0.8740 r:0.1819
en_zh Dev loss: 0.7013 r:0.4573
ro_en Dev loss: 0.3071 r:0.8229
et_en Dev loss: 0.3626 r:0.7039
si_en Dev loss: 0.6416 r:0.6058
ne_en Dev loss: 0.3535 r:0.7679
ru_en Dev loss: 0.4394 r:0.7310
Current avg r:0.6101 Best avg r: 0.6244
19:46:30,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:00,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:30,285 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3882
en_de Dev loss: 0.8692 r:0.2059
en_zh Dev loss: 0.6984 r:0.4634
ro_en Dev loss: 0.3265 r:0.8217
et_en Dev loss: 0.3774 r:0.7128
si_en Dev loss: 0.6484 r:0.6146
ne_en Dev loss: 0.3936 r:0.7656
ru_en Dev loss: 0.4265 r:0.7466
Current avg r:0.6187 Best avg r: 0.6244
19:54:02,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:32,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:02,460 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3628
en_de Dev loss: 0.8976 r:0.1871
en_zh Dev loss: 0.7608 r:0.4454
ro_en Dev loss: 0.3400 r:0.8191
et_en Dev loss: 0.3973 r:0.6972
si_en Dev loss: 0.7872 r:0.5898
ne_en Dev loss: 0.4681 r:0.7591
ru_en Dev loss: 0.5294 r:0.7015
Current avg r:0.5999 Best avg r: 0.6244
20:01:34,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:12,807 root INFO 
id:ro_en cur r: 0.8332 best r: 0.8332
20:03:04,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:34,356 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3755
en_de Dev loss: 0.8943 r:0.1816
en_zh Dev loss: 0.7003 r:0.4685
ro_en Dev loss: 0.3018 r:0.8264
et_en Dev loss: 0.4041 r:0.7029
si_en Dev loss: 0.6145 r:0.6130
ne_en Dev loss: 0.3519 r:0.7676
ru_en Dev loss: 0.4099 r:0.7442
Current avg r:0.6149 Best avg r: 0.6244
20:09:06,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:10:36,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:06,596 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3871
en_de Dev loss: 0.8601 r:0.2141
en_zh Dev loss: 0.6964 r:0.4548
ro_en Dev loss: 0.2976 r:0.8223
et_en Dev loss: 0.3731 r:0.7057
si_en Dev loss: 0.6512 r:0.6026
ne_en Dev loss: 0.3694 r:0.7657
ru_en Dev loss: 0.4361 r:0.7249
Current avg r:0.6129 Best avg r: 0.6244
20:16:38,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:08,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:38,676 root INFO Epoch 2 Global steps: 30100 Train loss: 0.4052
en_de Dev loss: 0.8753 r:0.1677
en_zh Dev loss: 0.7196 r:0.4518
ro_en Dev loss: 0.3009 r:0.8186
et_en Dev loss: 0.3782 r:0.6969
si_en Dev loss: 0.7037 r:0.5971
ne_en Dev loss: 0.3959 r:0.7628
ru_en Dev loss: 0.4738 r:0.7019
Current avg r:0.5996 Best avg r: 0.6244
20:24:10,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:40,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:10,576 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3779
en_de Dev loss: 0.8752 r:0.1810
en_zh Dev loss: 0.7025 r:0.4671
ro_en Dev loss: 0.3137 r:0.8190
et_en Dev loss: 0.3831 r:0.6919
si_en Dev loss: 0.7909 r:0.5941
ne_en Dev loss: 0.4839 r:0.7550
ru_en Dev loss: 0.4935 r:0.6946
Current avg r:0.6004 Best avg r: 0.6244
20:31:42,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:55,97 root INFO 
id:en_de cur r: 0.2397 best r: 0.2397
20:33:12,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:34:42,503 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3727
en_de Dev loss: 0.8522 r:0.2187
en_zh Dev loss: 0.7015 r:0.4607
ro_en Dev loss: 0.3283 r:0.8202
et_en Dev loss: 0.3857 r:0.6972
si_en Dev loss: 0.7718 r:0.5919
ne_en Dev loss: 0.4575 r:0.7548
ru_en Dev loss: 0.4828 r:0.7073
Current avg r:0.6073 Best avg r: 0.6244
20:39:16,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:46,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:16,669 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3287
en_de Dev loss: 0.8512 r:0.2318
en_zh Dev loss: 0.7129 r:0.4540
ro_en Dev loss: 0.3238 r:0.8157
et_en Dev loss: 0.4255 r:0.6917
si_en Dev loss: 0.6534 r:0.5963
ne_en Dev loss: 0.3921 r:0.7560
ru_en Dev loss: 0.4505 r:0.7177
Current avg r:0.6090 Best avg r: 0.6244
20:46:48,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:19,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:49,316 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3273
en_de Dev loss: 0.8673 r:0.2267
en_zh Dev loss: 0.7364 r:0.4628
ro_en Dev loss: 0.3203 r:0.8184
et_en Dev loss: 0.3931 r:0.6947
si_en Dev loss: 0.7296 r:0.5999
ne_en Dev loss: 0.4426 r:0.7531
ru_en Dev loss: 0.4839 r:0.7131
Current avg r:0.6098 Best avg r: 0.6244
20:54:21,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:51,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:57:21,842 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3250
en_de Dev loss: 0.8706 r:0.2025
en_zh Dev loss: 0.7363 r:0.4555
ro_en Dev loss: 0.3131 r:0.8216
et_en Dev loss: 0.3952 r:0.7026
si_en Dev loss: 0.7007 r:0.6076
ne_en Dev loss: 0.3744 r:0.7569
ru_en Dev loss: 0.4202 r:0.7422
Current avg r:0.6127 Best avg r: 0.6244
21:01:53,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:23,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:53,963 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3425
en_de Dev loss: 0.8647 r:0.2128
en_zh Dev loss: 0.7855 r:0.4488
ro_en Dev loss: 0.3364 r:0.8194
et_en Dev loss: 0.3918 r:0.7008
si_en Dev loss: 0.8430 r:0.5969
ne_en Dev loss: 0.4913 r:0.7518
ru_en Dev loss: 0.4735 r:0.7269
Current avg r:0.6082 Best avg r: 0.6244
21:09:26,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:56,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:12:26,551 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3382
en_de Dev loss: 0.8809 r:0.2350
en_zh Dev loss: 0.7799 r:0.4422
ro_en Dev loss: 0.3542 r:0.8152
et_en Dev loss: 0.4128 r:0.6848
si_en Dev loss: 0.8161 r:0.5887
ne_en Dev loss: 0.4974 r:0.7477
ru_en Dev loss: 0.4879 r:0.7144
Current avg r:0.6040 Best avg r: 0.6244
21:16:58,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:29,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:59,260 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3212
en_de Dev loss: 0.8574 r:0.2222
en_zh Dev loss: 0.7202 r:0.4623
ro_en Dev loss: 0.3081 r:0.8199
et_en Dev loss: 0.3998 r:0.7037
si_en Dev loss: 0.6600 r:0.6082
ne_en Dev loss: 0.3837 r:0.7557
ru_en Dev loss: 0.4399 r:0.7251
Current avg r:0.6139 Best avg r: 0.6244
21:24:31,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:26:01,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:31,516 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3412
en_de Dev loss: 0.8624 r:0.1895
en_zh Dev loss: 0.7082 r:0.4560
ro_en Dev loss: 0.3209 r:0.8135
et_en Dev loss: 0.3893 r:0.6865
si_en Dev loss: 0.7900 r:0.5857
ne_en Dev loss: 0.4589 r:0.7578
ru_en Dev loss: 0.4801 r:0.6984
Current avg r:0.5982 Best avg r: 0.6244
21:32:03,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:33:33,785 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:03,965 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3303
en_de Dev loss: 0.8679 r:0.1978
en_zh Dev loss: 0.7428 r:0.4491
ro_en Dev loss: 0.3394 r:0.8156
et_en Dev loss: 0.4230 r:0.6910
si_en Dev loss: 0.6980 r:0.5986
ne_en Dev loss: 0.3939 r:0.7544
ru_en Dev loss: 0.4661 r:0.7167
Current avg r:0.6033 Best avg r: 0.6244
21:39:36,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:06,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:36,530 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3217
en_de Dev loss: 0.8744 r:0.1924
en_zh Dev loss: 0.7662 r:0.4491
ro_en Dev loss: 0.3499 r:0.8106
et_en Dev loss: 0.4183 r:0.6818
si_en Dev loss: 0.7883 r:0.5846
ne_en Dev loss: 0.4331 r:0.7525
ru_en Dev loss: 0.5235 r:0.6927
Current avg r:0.5948 Best avg r: 0.6244
21:47:08,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:38,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:50:09,70 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3261
en_de Dev loss: 0.8628 r:0.1975
en_zh Dev loss: 0.7471 r:0.4478
ro_en Dev loss: 0.3411 r:0.8159
et_en Dev loss: 0.4257 r:0.6877
si_en Dev loss: 0.7419 r:0.5868
ne_en Dev loss: 0.4223 r:0.7518
ru_en Dev loss: 0.4692 r:0.7162
Current avg r:0.6005 Best avg r: 0.6244
21:54:41,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:56:11,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:57:41,792 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3376
en_de Dev loss: 0.8674 r:0.2006
en_zh Dev loss: 0.7458 r:0.4540
ro_en Dev loss: 0.3240 r:0.8222
et_en Dev loss: 0.4185 r:0.6997
si_en Dev loss: 0.6290 r:0.6076
ne_en Dev loss: 0.3799 r:0.7468
ru_en Dev loss: 0.4436 r:0.7278
Current avg r:0.6084 Best avg r: 0.6244
22:02:14,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:44,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:14,611 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3234
en_de Dev loss: 0.8863 r:0.2084
en_zh Dev loss: 0.7706 r:0.4686
ro_en Dev loss: 0.3542 r:0.8177
et_en Dev loss: 0.4524 r:0.6900
si_en Dev loss: 0.7174 r:0.5990
ne_en Dev loss: 0.4232 r:0.7497
ru_en Dev loss: 0.4557 r:0.7299
Current avg r:0.6090 Best avg r: 0.6244
22:09:46,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:17,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:47,312 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3186
en_de Dev loss: 0.8755 r:0.1723
en_zh Dev loss: 0.7203 r:0.4498
ro_en Dev loss: 0.3223 r:0.8136
et_en Dev loss: 0.4223 r:0.6806
si_en Dev loss: 0.7589 r:0.5815
ne_en Dev loss: 0.4433 r:0.7438
ru_en Dev loss: 0.4768 r:0.6947
Current avg r:0.5909 Best avg r: 0.6244
22:17:19,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:49,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:19,952 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3050
en_de Dev loss: 0.9013 r:0.1955
en_zh Dev loss: 0.8054 r:0.4695
ro_en Dev loss: 0.3692 r:0.8199
et_en Dev loss: 0.5053 r:0.6923
si_en Dev loss: 0.7322 r:0.5924
ne_en Dev loss: 0.4466 r:0.7442
ru_en Dev loss: 0.4620 r:0.7282
Current avg r:0.6060 Best avg r: 0.6244
22:24:52,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:26:22,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:52,510 root INFO Epoch 3 Global steps: 42000 Train loss: 0.2888
en_de Dev loss: 0.8872 r:0.2116
en_zh Dev loss: 0.7569 r:0.4528
ro_en Dev loss: 0.3491 r:0.8185
et_en Dev loss: 0.4095 r:0.6839
si_en Dev loss: 0.8081 r:0.5875
ne_en Dev loss: 0.5124 r:0.7506
ru_en Dev loss: 0.5034 r:0.7076
Current avg r:0.6018 Best avg r: 0.6244
22:32:26,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:56,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:26,859 root INFO Epoch 4 Global steps: 42700 Train loss: 0.2795
en_de Dev loss: 0.8877 r:0.1779
en_zh Dev loss: 0.7248 r:0.4559
ro_en Dev loss: 0.3079 r:0.8252
et_en Dev loss: 0.4231 r:0.6960
si_en Dev loss: 0.6468 r:0.5993
ne_en Dev loss: 0.3953 r:0.7462
ru_en Dev loss: 0.4444 r:0.7210
Current avg r:0.6031 Best avg r: 0.6244
22:39:59,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:29,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:59,582 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2903
en_de Dev loss: 0.8950 r:0.1912
en_zh Dev loss: 0.7524 r:0.4571
ro_en Dev loss: 0.3627 r:0.8143
et_en Dev loss: 0.4130 r:0.6834
si_en Dev loss: 0.8636 r:0.5738
ne_en Dev loss: 0.4954 r:0.7478
ru_en Dev loss: 0.5049 r:0.7038
Current avg r:0.5959 Best avg r: 0.6244
22:47:31,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:49:01,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:32,140 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2698
en_de Dev loss: 0.8830 r:0.1652
en_zh Dev loss: 0.7088 r:0.4579
ro_en Dev loss: 0.3179 r:0.8188
et_en Dev loss: 0.4199 r:0.6887
si_en Dev loss: 0.7045 r:0.5846
ne_en Dev loss: 0.4124 r:0.7457
ru_en Dev loss: 0.4552 r:0.7087
Current avg r:0.5956 Best avg r: 0.6244
22:55:03,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:34,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:04,249 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2690
en_de Dev loss: 0.9153 r:0.1698
en_zh Dev loss: 0.7858 r:0.4535
ro_en Dev loss: 0.3687 r:0.8189
et_en Dev loss: 0.4233 r:0.6813
si_en Dev loss: 0.8195 r:0.5789
ne_en Dev loss: 0.4689 r:0.7457
ru_en Dev loss: 0.5029 r:0.7144
Current avg r:0.5946 Best avg r: 0.6244
23:02:35,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:05,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:36,114 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2806
en_de Dev loss: 0.8892 r:0.1688
en_zh Dev loss: 0.7694 r:0.4437
ro_en Dev loss: 0.3304 r:0.8183
et_en Dev loss: 0.4391 r:0.6816
si_en Dev loss: 0.7181 r:0.5813
ne_en Dev loss: 0.4461 r:0.7384
ru_en Dev loss: 0.4880 r:0.7036
Current avg r:0.5908 Best avg r: 0.6244
23:10:08,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:38,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:08,757 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2709
en_de Dev loss: 0.8842 r:0.1706
en_zh Dev loss: 0.7617 r:0.4484
ro_en Dev loss: 0.3233 r:0.8173
et_en Dev loss: 0.4069 r:0.6828
si_en Dev loss: 0.7602 r:0.5748
ne_en Dev loss: 0.4488 r:0.7495
ru_en Dev loss: 0.4708 r:0.7163
Current avg r:0.5942 Best avg r: 0.6244
23:17:40,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:10,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:41,19 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2906
en_de Dev loss: 0.8981 r:0.1910
en_zh Dev loss: 0.7840 r:0.4373
ro_en Dev loss: 0.3514 r:0.8116
et_en Dev loss: 0.4269 r:0.6771
si_en Dev loss: 0.7835 r:0.5650
ne_en Dev loss: 0.5168 r:0.7358
ru_en Dev loss: 0.5075 r:0.7004
Current avg r:0.5883 Best avg r: 0.6244
23:25:13,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:43,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:28:13,458 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2704
en_de Dev loss: 0.8873 r:0.1967
en_zh Dev loss: 0.7262 r:0.4683
ro_en Dev loss: 0.3458 r:0.8138
et_en Dev loss: 0.4327 r:0.6706
si_en Dev loss: 0.8654 r:0.5672
ne_en Dev loss: 0.5256 r:0.7481
ru_en Dev loss: 0.4813 r:0.7139
Current avg r:0.5969 Best avg r: 0.6244
23:32:45,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:34:15,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:45,818 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2712
en_de Dev loss: 0.8911 r:0.1924
en_zh Dev loss: 0.7389 r:0.4644
ro_en Dev loss: 0.3321 r:0.8228
et_en Dev loss: 0.4225 r:0.6862
si_en Dev loss: 0.7285 r:0.5874
ne_en Dev loss: 0.4376 r:0.7458
ru_en Dev loss: 0.4648 r:0.7252
Current avg r:0.6034 Best avg r: 0.6244
23:40:17,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:48,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:18,288 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2527
en_de Dev loss: 0.8789 r:0.2178
en_zh Dev loss: 0.7374 r:0.4657
ro_en Dev loss: 0.3181 r:0.8229
et_en Dev loss: 0.4280 r:0.6904
si_en Dev loss: 0.7461 r:0.5769
ne_en Dev loss: 0.4162 r:0.7448
ru_en Dev loss: 0.4245 r:0.7420
Current avg r:0.6086 Best avg r: 0.6244
23:47:50,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:20,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:50,817 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2551
en_de Dev loss: 0.8980 r:0.1991
en_zh Dev loss: 0.7836 r:0.4680
ro_en Dev loss: 0.3478 r:0.8191
et_en Dev loss: 0.4787 r:0.6842
si_en Dev loss: 0.7222 r:0.5762
ne_en Dev loss: 0.3958 r:0.7476
ru_en Dev loss: 0.4306 r:0.7367
Current avg r:0.6044 Best avg r: 0.6244
23:55:22,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:53,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:23,227 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2696
en_de Dev loss: 0.8864 r:0.2027
en_zh Dev loss: 0.7950 r:0.4557
ro_en Dev loss: 0.3618 r:0.8225
et_en Dev loss: 0.4269 r:0.6788
si_en Dev loss: 0.8705 r:0.5718
ne_en Dev loss: 0.5164 r:0.7420
ru_en Dev loss: 0.5011 r:0.7152
Current avg r:0.5984 Best avg r: 0.6244
00:02:55,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:25,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:55,542 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2661
en_de Dev loss: 0.8837 r:0.2031
en_zh Dev loss: 0.7550 r:0.4530
ro_en Dev loss: 0.3431 r:0.8169
et_en Dev loss: 0.4220 r:0.6826
si_en Dev loss: 0.8256 r:0.5668
ne_en Dev loss: 0.4675 r:0.7447
ru_en Dev loss: 0.4457 r:0.7303
Current avg r:0.5996 Best avg r: 0.6244
00:10:27,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:57,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:13:27,853 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2630
en_de Dev loss: 0.8832 r:0.1996
en_zh Dev loss: 0.7399 r:0.4559
ro_en Dev loss: 0.3363 r:0.8141
et_en Dev loss: 0.4490 r:0.6856
si_en Dev loss: 0.7437 r:0.5711
ne_en Dev loss: 0.4477 r:0.7386
ru_en Dev loss: 0.4280 r:0.7358
Current avg r:0.6001 Best avg r: 0.6244
00:17:59,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:30,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:21:00,272 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2656
en_de Dev loss: 0.8683 r:0.2154
en_zh Dev loss: 0.7497 r:0.4400
ro_en Dev loss: 0.3424 r:0.8130
et_en Dev loss: 0.4160 r:0.6780
si_en Dev loss: 0.7963 r:0.5557
ne_en Dev loss: 0.5426 r:0.7369
ru_en Dev loss: 0.4675 r:0.7106
Current avg r:0.5928 Best avg r: 0.6244
00:25:33,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:27:03,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:28:34,114 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2304
en_de Dev loss: 0.8708 r:0.2157
en_zh Dev loss: 0.7466 r:0.4478
ro_en Dev loss: 0.3254 r:0.8179
et_en Dev loss: 0.4366 r:0.6911
si_en Dev loss: 0.6919 r:0.5786
ne_en Dev loss: 0.4292 r:0.7384
ru_en Dev loss: 0.4174 r:0.7361
Current avg r:0.6037 Best avg r: 0.6244
00:33:06,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:36,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:06,645 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2249
en_de Dev loss: 0.8749 r:0.1958
en_zh Dev loss: 0.8031 r:0.4379
ro_en Dev loss: 0.3798 r:0.8157
et_en Dev loss: 0.4492 r:0.6794
si_en Dev loss: 0.8774 r:0.5608
ne_en Dev loss: 0.5186 r:0.7323
ru_en Dev loss: 0.4837 r:0.7144
Current avg r:0.5909 Best avg r: 0.6244
00:40:38,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:42:09,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:39,191 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2439
en_de Dev loss: 0.8948 r:0.1801
en_zh Dev loss: 0.8035 r:0.4332
ro_en Dev loss: 0.3583 r:0.8108
et_en Dev loss: 0.4340 r:0.6737
si_en Dev loss: 0.8484 r:0.5465
ne_en Dev loss: 0.5194 r:0.7316
ru_en Dev loss: 0.4803 r:0.7144
Current avg r:0.5844 Best avg r: 0.6244
00:48:10,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:40,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:51:11,2 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2421
en_de Dev loss: 0.8917 r:0.1961
en_zh Dev loss: 0.7819 r:0.4339
ro_en Dev loss: 0.3333 r:0.8198
et_en Dev loss: 0.4335 r:0.6885
si_en Dev loss: 0.7781 r:0.5718
ne_en Dev loss: 0.4714 r:0.7317
ru_en Dev loss: 0.4548 r:0.7242
Current avg r:0.5951 Best avg r: 0.6244
00:55:42,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:57:12,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:42,929 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2293
en_de Dev loss: 0.8810 r:0.1767
en_zh Dev loss: 0.7755 r:0.4338
ro_en Dev loss: 0.3486 r:0.8185
et_en Dev loss: 0.4368 r:0.6880
si_en Dev loss: 0.8060 r:0.5765
ne_en Dev loss: 0.5012 r:0.7277
ru_en Dev loss: 0.4437 r:0.7317
Current avg r:0.5933 Best avg r: 0.6244
01:03:14,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:44,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:06:14,992 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2355
en_de Dev loss: 0.8800 r:0.2229
en_zh Dev loss: 0.7728 r:0.4561
ro_en Dev loss: 0.3406 r:0.8194
et_en Dev loss: 0.4781 r:0.6868
si_en Dev loss: 0.7808 r:0.5732
ne_en Dev loss: 0.4682 r:0.7293
ru_en Dev loss: 0.4176 r:0.7452
Current avg r:0.6047 Best avg r: 0.6244
01:10:46,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:16,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:13:46,649 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2404
en_de Dev loss: 0.8817 r:0.2098
en_zh Dev loss: 0.7681 r:0.4527
ro_en Dev loss: 0.3246 r:0.8226
et_en Dev loss: 0.4387 r:0.6879
si_en Dev loss: 0.7835 r:0.5681
ne_en Dev loss: 0.4706 r:0.7331
ru_en Dev loss: 0.4265 r:0.7407
Current avg r:0.6021 Best avg r: 0.6244
01:18:18,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:48,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:21:18,240 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2197
en_de Dev loss: 0.8860 r:0.1922
en_zh Dev loss: 0.7534 r:0.4465
ro_en Dev loss: 0.3383 r:0.8159
et_en Dev loss: 0.4350 r:0.6653
si_en Dev loss: 0.8862 r:0.5541
ne_en Dev loss: 0.5423 r:0.7312
ru_en Dev loss: 0.4798 r:0.7126
Current avg r:0.5883 Best avg r: 0.6244
01:25:49,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:27:20,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:50,235 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2342
en_de Dev loss: 0.8979 r:0.1826
en_zh Dev loss: 0.7616 r:0.4577
ro_en Dev loss: 0.3317 r:0.8192
et_en Dev loss: 0.4809 r:0.6774
si_en Dev loss: 0.7445 r:0.5724
ne_en Dev loss: 0.4420 r:0.7291
ru_en Dev loss: 0.4178 r:0.7427
Current avg r:0.5973 Best avg r: 0.6244
01:33:22,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:34:52,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:22,393 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2234
en_de Dev loss: 0.8878 r:0.1800
en_zh Dev loss: 0.7583 r:0.4476
ro_en Dev loss: 0.3394 r:0.8152
et_en Dev loss: 0.4273 r:0.6773
si_en Dev loss: 0.8084 r:0.5655
ne_en Dev loss: 0.4999 r:0.7328
ru_en Dev loss: 0.4548 r:0.7333
Current avg r:0.5931 Best avg r: 0.6244
01:40:54,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:24,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:54,602 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2192
en_de Dev loss: 0.8853 r:0.1970
en_zh Dev loss: 0.7613 r:0.4548
ro_en Dev loss: 0.3231 r:0.8218
et_en Dev loss: 0.4305 r:0.6814
si_en Dev loss: 0.7582 r:0.5768
ne_en Dev loss: 0.4503 r:0.7424
ru_en Dev loss: 0.4496 r:0.7319
Current avg r:0.6009 Best avg r: 0.6244
01:48:26,620 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:49:56,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:26,890 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2240
en_de Dev loss: 0.8815 r:0.1919
en_zh Dev loss: 0.7517 r:0.4587
ro_en Dev loss: 0.3282 r:0.8184
et_en Dev loss: 0.4167 r:0.6804
si_en Dev loss: 0.8060 r:0.5735
ne_en Dev loss: 0.4998 r:0.7342
ru_en Dev loss: 0.4372 r:0.7433
Current avg r:0.6001 Best avg r: 0.6244
01:55:59,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:29,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:00,53 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2246
en_de Dev loss: 0.8972 r:0.1888
en_zh Dev loss: 0.7576 r:0.4627
ro_en Dev loss: 0.3397 r:0.8195
et_en Dev loss: 0.4484 r:0.6768
si_en Dev loss: 0.7941 r:0.5656
ne_en Dev loss: 0.4617 r:0.7315
ru_en Dev loss: 0.4623 r:0.7326
Current avg r:0.5968 Best avg r: 0.6244
02:03:37,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:08,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:06:39,739 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2186
en_de Dev loss: 0.8906 r:0.1792
en_zh Dev loss: 0.7315 r:0.4554
ro_en Dev loss: 0.3151 r:0.8154
et_en Dev loss: 0.4394 r:0.6651
si_en Dev loss: 0.7616 r:0.5582
ne_en Dev loss: 0.4633 r:0.7331
ru_en Dev loss: 0.4259 r:0.7277
Current avg r:0.5906 Best avg r: 0.6244
02:11:16,877 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:48,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:19,96 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2248
en_de Dev loss: 0.8826 r:0.1760
en_zh Dev loss: 0.7493 r:0.4445
ro_en Dev loss: 0.3141 r:0.8174
et_en Dev loss: 0.4268 r:0.6613
si_en Dev loss: 0.8049 r:0.5464
ne_en Dev loss: 0.4945 r:0.7303
ru_en Dev loss: 0.4667 r:0.7118
Current avg r:0.5840 Best avg r: 0.6244
02:18:57,915 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:29,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:00,74 root INFO Epoch 6 Global steps: 63700 Train loss: 0.1916
en_de Dev loss: 0.8867 r:0.1740
en_zh Dev loss: 0.7513 r:0.4442
ro_en Dev loss: 0.3320 r:0.8161
et_en Dev loss: 0.4527 r:0.6683
si_en Dev loss: 0.8252 r:0.5577
ne_en Dev loss: 0.4724 r:0.7364
ru_en Dev loss: 0.4405 r:0.7280
Current avg r:0.5892 Best avg r: 0.6244
02:26:37,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:28:08,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:39,273 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2065
en_de Dev loss: 0.9073 r:0.1941
en_zh Dev loss: 0.8090 r:0.4452
ro_en Dev loss: 0.3535 r:0.8168
et_en Dev loss: 0.4720 r:0.6719
si_en Dev loss: 0.8335 r:0.5625
ne_en Dev loss: 0.4828 r:0.7288
ru_en Dev loss: 0.4522 r:0.7368
Current avg r:0.5937 Best avg r: 0.6244
02:34:12,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:42,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:37:13,203 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2055
en_de Dev loss: 0.9099 r:0.1919
en_zh Dev loss: 0.7827 r:0.4479
ro_en Dev loss: 0.3443 r:0.8204
et_en Dev loss: 0.4506 r:0.6668
si_en Dev loss: 0.8407 r:0.5492
ne_en Dev loss: 0.4999 r:0.7205
ru_en Dev loss: 0.4486 r:0.7340
Current avg r:0.5901 Best avg r: 0.6244
02:41:46,511 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:16,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:47,184 root INFO Epoch 6 Global steps: 65800 Train loss: 0.1907
en_de Dev loss: 0.9350 r:0.1819
en_zh Dev loss: 0.8833 r:0.4405
ro_en Dev loss: 0.3978 r:0.8196
et_en Dev loss: 0.4743 r:0.6620
si_en Dev loss: 1.0069 r:0.5413
ne_en Dev loss: 0.5977 r:0.7231
ru_en Dev loss: 0.5413 r:0.7177
Current avg r:0.5837 Best avg r: 0.6244
02:49:20,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:50,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:21,204 root INFO Epoch 6 Global steps: 66500 Train loss: 0.1986
en_de Dev loss: 0.9144 r:0.1609
en_zh Dev loss: 0.8075 r:0.4362
ro_en Dev loss: 0.3589 r:0.8181
et_en Dev loss: 0.4713 r:0.6702
si_en Dev loss: 0.8745 r:0.5504
ne_en Dev loss: 0.5152 r:0.7245
ru_en Dev loss: 0.4355 r:0.7428
Current avg r:0.5861 Best avg r: 0.6244
02:56:54,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:58:24,498 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:59:54,740 root INFO Epoch 6 Global steps: 67200 Train loss: 0.1888
en_de Dev loss: 0.9149 r:0.1705
en_zh Dev loss: 0.7962 r:0.4508
ro_en Dev loss: 0.3543 r:0.8194
et_en Dev loss: 0.4514 r:0.6747
si_en Dev loss: 0.9407 r:0.5504
ne_en Dev loss: 0.5553 r:0.7258
ru_en Dev loss: 0.4590 r:0.7421
Current avg r:0.5905 Best avg r: 0.6244
03:04:27,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:05:57,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:07:27,906 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2023
en_de Dev loss: 0.9172 r:0.1674
en_zh Dev loss: 0.8084 r:0.4525
ro_en Dev loss: 0.3550 r:0.8177
et_en Dev loss: 0.4564 r:0.6725
si_en Dev loss: 0.9222 r:0.5462
ne_en Dev loss: 0.5402 r:0.7258
ru_en Dev loss: 0.4528 r:0.7445
Current avg r:0.5895 Best avg r: 0.6244
03:12:00,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:31,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:15:02,954 root INFO Epoch 6 Global steps: 68600 Train loss: 0.1898
en_de Dev loss: 0.9223 r:0.1870
en_zh Dev loss: 0.8171 r:0.4532
ro_en Dev loss: 0.3830 r:0.8149
et_en Dev loss: 0.4920 r:0.6673
si_en Dev loss: 0.9268 r:0.5441
ne_en Dev loss: 0.5774 r:0.7221
ru_en Dev loss: 0.4714 r:0.7409
Current avg r:0.5899 Best avg r: 0.6244
03:19:40,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:11,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:42,416 root INFO Epoch 6 Global steps: 69300 Train loss: 0.1943
en_de Dev loss: 0.9042 r:0.1867
en_zh Dev loss: 0.8106 r:0.4554
ro_en Dev loss: 0.3646 r:0.8163
et_en Dev loss: 0.4716 r:0.6575
si_en Dev loss: 0.9326 r:0.5455
ne_en Dev loss: 0.5335 r:0.7331
ru_en Dev loss: 0.4810 r:0.7296
Current avg r:0.5891 Best avg r: 0.6244
03:27:19,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:50,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:21,849 root INFO Epoch 6 Global steps: 70000 Train loss: 0.1845
en_de Dev loss: 0.8934 r:0.1888
en_zh Dev loss: 0.7879 r:0.4501
ro_en Dev loss: 0.3379 r:0.8203
et_en Dev loss: 0.4405 r:0.6560
si_en Dev loss: 0.8764 r:0.5469
ne_en Dev loss: 0.5428 r:0.7273
ru_en Dev loss: 0.4857 r:0.7199
Current avg r:0.5871 Best avg r: 0.6244
03:34:59,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:30,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:00,461 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1984
en_de Dev loss: 0.9129 r:0.1690
en_zh Dev loss: 0.7656 r:0.4564
ro_en Dev loss: 0.3424 r:0.8205
et_en Dev loss: 0.4910 r:0.6662
si_en Dev loss: 0.7423 r:0.5660
ne_en Dev loss: 0.4916 r:0.7267
ru_en Dev loss: 0.4401 r:0.7275
Current avg r:0.5903 Best avg r: 0.6244
03:42:32,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:02,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:33,26 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1912
en_de Dev loss: 0.9346 r:0.1883
en_zh Dev loss: 0.7828 r:0.4555
ro_en Dev loss: 0.3603 r:0.8188
et_en Dev loss: 0.5236 r:0.6689
si_en Dev loss: 0.8015 r:0.5591
ne_en Dev loss: 0.4952 r:0.7231
ru_en Dev loss: 0.4307 r:0.7416
Current avg r:0.5936 Best avg r: 0.6244
03:50:05,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:36,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:53:06,381 root INFO Epoch 6 Global steps: 72100 Train loss: 0.1973
en_de Dev loss: 0.9248 r:0.1746
en_zh Dev loss: 0.7989 r:0.4497
ro_en Dev loss: 0.3545 r:0.8229
et_en Dev loss: 0.4751 r:0.6699
si_en Dev loss: 0.8569 r:0.5569
ne_en Dev loss: 0.5631 r:0.7191
ru_en Dev loss: 0.4505 r:0.7329
Current avg r:0.5894 Best avg r: 0.6244
03:57:39,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:59:09,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:40,142 root INFO Epoch 6 Global steps: 72800 Train loss: 0.1932
en_de Dev loss: 0.9442 r:0.1832
en_zh Dev loss: 0.8121 r:0.4490
ro_en Dev loss: 0.3483 r:0.8191
et_en Dev loss: 0.4884 r:0.6626
si_en Dev loss: 0.8747 r:0.5532
ne_en Dev loss: 0.5597 r:0.7183
ru_en Dev loss: 0.4614 r:0.7317
Current avg r:0.5882 Best avg r: 0.6244
04:05:13,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:06:43,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:13,650 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1925
en_de Dev loss: 0.9103 r:0.1526
en_zh Dev loss: 0.7425 r:0.4516
ro_en Dev loss: 0.3093 r:0.8249
et_en Dev loss: 0.4644 r:0.6752
si_en Dev loss: 0.7623 r:0.5659
ne_en Dev loss: 0.4751 r:0.7249
ru_en Dev loss: 0.4202 r:0.7364
Current avg r:0.5902 Best avg r: 0.6244
04:12:48,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:18,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:48,749 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1793
en_de Dev loss: 0.9196 r:0.1844
en_zh Dev loss: 0.7873 r:0.4638
ro_en Dev loss: 0.3654 r:0.8185
et_en Dev loss: 0.4777 r:0.6677
si_en Dev loss: 0.9066 r:0.5546
ne_en Dev loss: 0.5679 r:0.7190
ru_en Dev loss: 0.4787 r:0.7294
Current avg r:0.5911 Best avg r: 0.6244
04:20:21,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:52,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:22,364 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1745
en_de Dev loss: 0.9285 r:0.1648
en_zh Dev loss: 0.8260 r:0.4474
ro_en Dev loss: 0.3625 r:0.8139
et_en Dev loss: 0.4715 r:0.6672
si_en Dev loss: 0.8771 r:0.5503
ne_en Dev loss: 0.5388 r:0.7263
ru_en Dev loss: 0.4613 r:0.7361
Current avg r:0.5866 Best avg r: 0.6244
04:27:55,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:25,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:55,795 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1695
en_de Dev loss: 0.9043 r:0.1850
en_zh Dev loss: 0.7750 r:0.4593
ro_en Dev loss: 0.3559 r:0.8163
et_en Dev loss: 0.4780 r:0.6659
si_en Dev loss: 0.8866 r:0.5535
ne_en Dev loss: 0.5031 r:0.7247
ru_en Dev loss: 0.4389 r:0.7460
Current avg r:0.5930 Best avg r: 0.6244
04:35:28,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:58,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:29,236 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1780
en_de Dev loss: 0.9189 r:0.1535
en_zh Dev loss: 0.7784 r:0.4451
ro_en Dev loss: 0.3467 r:0.8185
et_en Dev loss: 0.4731 r:0.6635
si_en Dev loss: 0.8662 r:0.5441
ne_en Dev loss: 0.4922 r:0.7236
ru_en Dev loss: 0.4434 r:0.7352
Current avg r:0.5834 Best avg r: 0.6244
04:43:02,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:32,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:46:02,688 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1646
en_de Dev loss: 0.9294 r:0.1483
en_zh Dev loss: 0.7767 r:0.4522
ro_en Dev loss: 0.3476 r:0.8160
et_en Dev loss: 0.4727 r:0.6619
si_en Dev loss: 0.8744 r:0.5513
ne_en Dev loss: 0.5282 r:0.7233
ru_en Dev loss: 0.4253 r:0.7497
Current avg r:0.5861 Best avg r: 0.6244
04:50:35,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:52:05,694 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:35,954 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1703
en_de Dev loss: 0.9132 r:0.1745
en_zh Dev loss: 0.7478 r:0.4622
ro_en Dev loss: 0.3369 r:0.8179
et_en Dev loss: 0.4532 r:0.6675
si_en Dev loss: 0.8740 r:0.5479
ne_en Dev loss: 0.4998 r:0.7169
ru_en Dev loss: 0.4438 r:0.7389
Current avg r:0.5894 Best avg r: 0.6244
04:58:08,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:59:39,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:01:09,245 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1684
en_de Dev loss: 0.9282 r:0.1646
en_zh Dev loss: 0.7453 r:0.4684
ro_en Dev loss: 0.3413 r:0.8167
et_en Dev loss: 0.4624 r:0.6689
si_en Dev loss: 0.8373 r:0.5595
ne_en Dev loss: 0.5200 r:0.7095
ru_en Dev loss: 0.4192 r:0.7525
Current avg r:0.5914 Best avg r: 0.6244
05:05:44,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:07:15,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:46,264 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1723
en_de Dev loss: 0.9519 r:0.1818
en_zh Dev loss: 0.7933 r:0.4658
ro_en Dev loss: 0.3387 r:0.8185
et_en Dev loss: 0.5174 r:0.6724
si_en Dev loss: 0.7760 r:0.5591
ne_en Dev loss: 0.5149 r:0.7042
ru_en Dev loss: 0.4087 r:0.7498
Current avg r:0.5931 Best avg r: 0.6244
05:13:23,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:54,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:16:25,634 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1664
en_de Dev loss: 0.9277 r:0.1669
en_zh Dev loss: 0.7634 r:0.4551
ro_en Dev loss: 0.3440 r:0.8149
et_en Dev loss: 0.4625 r:0.6603
si_en Dev loss: 0.8592 r:0.5429
ne_en Dev loss: 0.5414 r:0.7112
ru_en Dev loss: 0.4444 r:0.7415
Current avg r:0.5847 Best avg r: 0.6244
05:21:02,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:22:33,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:24:04,916 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1681
en_de Dev loss: 0.9287 r:0.1755
en_zh Dev loss: 0.7665 r:0.4620
ro_en Dev loss: 0.3454 r:0.8182
et_en Dev loss: 0.4486 r:0.6587
si_en Dev loss: 0.9615 r:0.5428
ne_en Dev loss: 0.6437 r:0.7086
ru_en Dev loss: 0.4460 r:0.7423
Current avg r:0.5869 Best avg r: 0.6244
05:28:41,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:11,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:41,800 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1775
en_de Dev loss: 0.9126 r:0.1904
en_zh Dev loss: 0.7375 r:0.4713
ro_en Dev loss: 0.3223 r:0.8168
et_en Dev loss: 0.4641 r:0.6793
si_en Dev loss: 0.7870 r:0.5574
ne_en Dev loss: 0.4921 r:0.7159
ru_en Dev loss: 0.3939 r:0.7587
Current avg r:0.5986 Best avg r: 0.6244
05:36:14,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:39,980 root INFO 
id:en_zh cur r: 0.4857 best r: 0.4857
05:37:44,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:39:14,769 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1617
en_de Dev loss: 0.9252 r:0.1846
en_zh Dev loss: 0.7548 r:0.4815
ro_en Dev loss: 0.3511 r:0.8176
et_en Dev loss: 0.4666 r:0.6644
si_en Dev loss: 0.9070 r:0.5510
ne_en Dev loss: 0.5830 r:0.7129
ru_en Dev loss: 0.4595 r:0.7367
Current avg r:0.5927 Best avg r: 0.6244
05:43:47,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:45:18,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:48,236 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1584
en_de Dev loss: 0.9162 r:0.1835
en_zh Dev loss: 0.8012 r:0.4611
ro_en Dev loss: 0.3370 r:0.8195
et_en Dev loss: 0.4674 r:0.6709
si_en Dev loss: 0.8411 r:0.5514
ne_en Dev loss: 0.5311 r:0.7102
ru_en Dev loss: 0.4462 r:0.7417
Current avg r:0.5912 Best avg r: 0.6244
05:51:20,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:51,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:54:21,462 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1594
en_de Dev loss: 0.9271 r:0.1825
en_zh Dev loss: 0.7798 r:0.4671
ro_en Dev loss: 0.3432 r:0.8175
et_en Dev loss: 0.4853 r:0.6743
si_en Dev loss: 0.8430 r:0.5544
ne_en Dev loss: 0.5538 r:0.7150
ru_en Dev loss: 0.4380 r:0.7471
Current avg r:0.5940 Best avg r: 0.6244
05:58:54,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:00:24,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:01:55,281 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1701
en_de Dev loss: 0.9122 r:0.1796
en_zh Dev loss: 0.7537 r:0.4675
ro_en Dev loss: 0.3344 r:0.8148
et_en Dev loss: 0.4599 r:0.6723
si_en Dev loss: 0.8184 r:0.5519
ne_en Dev loss: 0.5267 r:0.7133
ru_en Dev loss: 0.4169 r:0.7483
Current avg r:0.5925 Best avg r: 0.6244
06:06:29,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:59,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:09:29,610 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1580
en_de Dev loss: 0.9385 r:0.1615
en_zh Dev loss: 0.7928 r:0.4731
ro_en Dev loss: 0.3520 r:0.8160
et_en Dev loss: 0.4769 r:0.6728
si_en Dev loss: 0.8478 r:0.5556
ne_en Dev loss: 0.5498 r:0.7107
ru_en Dev loss: 0.4308 r:0.7515
Current avg r:0.5916 Best avg r: 0.6244
06:14:02,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:27,957 root INFO 
id:en_zh cur r: 0.4863 best r: 0.4863
06:15:32,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:17:02,770 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1428
en_de Dev loss: 0.9254 r:0.1685
en_zh Dev loss: 0.7762 r:0.4735
ro_en Dev loss: 0.3492 r:0.8160
et_en Dev loss: 0.4512 r:0.6677
si_en Dev loss: 0.8801 r:0.5457
ne_en Dev loss: 0.5354 r:0.7167
ru_en Dev loss: 0.4349 r:0.7454
Current avg r:0.5905 Best avg r: 0.6244
06:21:40,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:23:11,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:42,291 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1484
en_de Dev loss: 0.9319 r:0.1551
en_zh Dev loss: 0.8016 r:0.4685
ro_en Dev loss: 0.3427 r:0.8195
et_en Dev loss: 0.4748 r:0.6636
si_en Dev loss: 0.9061 r:0.5435
ne_en Dev loss: 0.5393 r:0.7129
ru_en Dev loss: 0.4635 r:0.7349
Current avg r:0.5854 Best avg r: 0.6244
06:29:19,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:50,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:21,995 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1454
en_de Dev loss: 0.9484 r:0.1672
en_zh Dev loss: 0.7625 r:0.4760
ro_en Dev loss: 0.3492 r:0.8196
et_en Dev loss: 0.5131 r:0.6684
si_en Dev loss: 0.8337 r:0.5499
ne_en Dev loss: 0.5012 r:0.7134
ru_en Dev loss: 0.4180 r:0.7451
Current avg r:0.5914 Best avg r: 0.6244
06:36:59,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:38:30,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:40:01,669 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1459
en_de Dev loss: 0.9281 r:0.1690
en_zh Dev loss: 0.7390 r:0.4748
ro_en Dev loss: 0.3252 r:0.8207
et_en Dev loss: 0.4561 r:0.6714
si_en Dev loss: 0.8014 r:0.5536
ne_en Dev loss: 0.4946 r:0.7184
ru_en Dev loss: 0.4148 r:0.7469
Current avg r:0.5935 Best avg r: 0.6244
06:44:35,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:46:06,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:47:36,413 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1552
en_de Dev loss: 0.9380 r:0.1873
en_zh Dev loss: 0.7812 r:0.4822
ro_en Dev loss: 0.3530 r:0.8186
et_en Dev loss: 0.4824 r:0.6748
si_en Dev loss: 0.9076 r:0.5476
ne_en Dev loss: 0.5379 r:0.7169
ru_en Dev loss: 0.4425 r:0.7472
Current avg r:0.5963 Best avg r: 0.6244
06:52:08,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:53:39,130 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:55:09,376 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1514
en_de Dev loss: 0.9132 r:0.1799
en_zh Dev loss: 0.7660 r:0.4764
ro_en Dev loss: 0.3334 r:0.8207
et_en Dev loss: 0.4834 r:0.6731
si_en Dev loss: 0.8408 r:0.5415
ne_en Dev loss: 0.5314 r:0.7036
ru_en Dev loss: 0.4240 r:0.7463
Current avg r:0.5916 Best avg r: 0.6244
06:59:41,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:01:11,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:42,139 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1436
en_de Dev loss: 0.9329 r:0.1782
en_zh Dev loss: 0.8163 r:0.4558
ro_en Dev loss: 0.3600 r:0.8174
et_en Dev loss: 0.4760 r:0.6553
si_en Dev loss: 0.9953 r:0.5291
ne_en Dev loss: 0.6540 r:0.6961
ru_en Dev loss: 0.4817 r:0.7306
Current avg r:0.5803 Best avg r: 0.6244
07:07:15,627 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:45,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:10:16,318 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1433
en_de Dev loss: 0.9081 r:0.1853
en_zh Dev loss: 0.7723 r:0.4654
ro_en Dev loss: 0.3148 r:0.8231
et_en Dev loss: 0.4536 r:0.6794
si_en Dev loss: 0.8080 r:0.5522
ne_en Dev loss: 0.5092 r:0.7061
ru_en Dev loss: 0.3950 r:0.7611
Current avg r:0.5961 Best avg r: 0.6244
07:14:49,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:16:19,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:50,303 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1432
en_de Dev loss: 0.9138 r:0.1765
en_zh Dev loss: 0.7463 r:0.4590
ro_en Dev loss: 0.3157 r:0.8230
et_en Dev loss: 0.4358 r:0.6668
si_en Dev loss: 0.8372 r:0.5488
ne_en Dev loss: 0.5396 r:0.7098
ru_en Dev loss: 0.4111 r:0.7504
Current avg r:0.5906 Best avg r: 0.6244
07:22:23,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:23:53,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:25:24,226 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1495
en_de Dev loss: 0.9083 r:0.1874
en_zh Dev loss: 0.7913 r:0.4602
ro_en Dev loss: 0.3496 r:0.8188
et_en Dev loss: 0.4792 r:0.6513
si_en Dev loss: 0.9324 r:0.5407
ne_en Dev loss: 0.6001 r:0.7120
ru_en Dev loss: 0.4542 r:0.7414
Current avg r:0.5874 Best avg r: 0.6244
07:29:57,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:31:27,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:58,273 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1504
en_de Dev loss: 0.9080 r:0.1895
en_zh Dev loss: 0.7495 r:0.4735
ro_en Dev loss: 0.3329 r:0.8222
et_en Dev loss: 0.4780 r:0.6650
si_en Dev loss: 0.8408 r:0.5502
ne_en Dev loss: 0.5191 r:0.7127
ru_en Dev loss: 0.3984 r:0.7597
Current avg r:0.5961 Best avg r: 0.6244
07:37:31,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:39:01,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:40:32,193 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1382
en_de Dev loss: 0.9072 r:0.1866
en_zh Dev loss: 0.7577 r:0.4625
ro_en Dev loss: 0.3231 r:0.8242
et_en Dev loss: 0.4569 r:0.6641
si_en Dev loss: 0.8277 r:0.5524
ne_en Dev loss: 0.5555 r:0.7124
ru_en Dev loss: 0.4257 r:0.7510
Current avg r:0.5933 Best avg r: 0.6244
07:45:07,791 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:46:38,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:48:09,994 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1426
en_de Dev loss: 0.9315 r:0.1802
en_zh Dev loss: 0.7647 r:0.4702
ro_en Dev loss: 0.3251 r:0.8222
et_en Dev loss: 0.4820 r:0.6752
si_en Dev loss: 0.8002 r:0.5581
ne_en Dev loss: 0.5639 r:0.7107
ru_en Dev loss: 0.4038 r:0.7645
Current avg r:0.5973 Best avg r: 0.6244
07:52:47,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:54:18,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:49,658 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1470
en_de Dev loss: 0.9463 r:0.1758
en_zh Dev loss: 0.7680 r:0.4751
ro_en Dev loss: 0.3595 r:0.8195
et_en Dev loss: 0.4540 r:0.6631
si_en Dev loss: 0.8777 r:0.5498
ne_en Dev loss: 0.6168 r:0.7142
ru_en Dev loss: 0.4714 r:0.7387
Current avg r:0.5909 Best avg r: 0.6244
08:00:29,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:00,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:31,381 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1307
en_de Dev loss: 0.9367 r:0.1719
en_zh Dev loss: 0.7823 r:0.4722
ro_en Dev loss: 0.3356 r:0.8194
et_en Dev loss: 0.4624 r:0.6737
si_en Dev loss: 0.8503 r:0.5469
ne_en Dev loss: 0.5703 r:0.7157
ru_en Dev loss: 0.4368 r:0.7483
Current avg r:0.5926 Best avg r: 0.6244
08:08:08,104 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:38,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:11:08,900 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1327
en_de Dev loss: 0.9371 r:0.1648
en_zh Dev loss: 0.7707 r:0.4705
ro_en Dev loss: 0.3419 r:0.8208
et_en Dev loss: 0.4738 r:0.6675
si_en Dev loss: 0.8682 r:0.5429
ne_en Dev loss: 0.5531 r:0.7134
ru_en Dev loss: 0.4365 r:0.7506
Current avg r:0.5901 Best avg r: 0.6244
08:15:42,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:17:12,911 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:18:43,309 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1313
en_de Dev loss: 0.9178 r:0.1651
en_zh Dev loss: 0.7563 r:0.4708
ro_en Dev loss: 0.3285 r:0.8214
et_en Dev loss: 0.4582 r:0.6736
si_en Dev loss: 0.8656 r:0.5476
ne_en Dev loss: 0.5637 r:0.7085
ru_en Dev loss: 0.4119 r:0.7580
Current avg r:0.5921 Best avg r: 0.6244
08:23:16,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:24:47,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:17,579 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1366
en_de Dev loss: 0.9562 r:0.1689
en_zh Dev loss: 0.8129 r:0.4727
ro_en Dev loss: 0.3763 r:0.8184
et_en Dev loss: 0.4961 r:0.6588
si_en Dev loss: 0.9983 r:0.5305
ne_en Dev loss: 0.6192 r:0.6972
ru_en Dev loss: 0.4790 r:0.7450
Current avg r:0.5845 Best avg r: 0.6244
08:30:51,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:32:21,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:33:51,891 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1264
en_de Dev loss: 0.9250 r:0.1716
en_zh Dev loss: 0.7682 r:0.4740
ro_en Dev loss: 0.3357 r:0.8199
et_en Dev loss: 0.4591 r:0.6671
si_en Dev loss: 0.8921 r:0.5356
ne_en Dev loss: 0.5857 r:0.6989
ru_en Dev loss: 0.4321 r:0.7535
Current avg r:0.5887 Best avg r: 0.6244
08:38:25,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:39:55,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:26,180 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1233
en_de Dev loss: 0.9244 r:0.1583
en_zh Dev loss: 0.7610 r:0.4705
ro_en Dev loss: 0.3332 r:0.8179
et_en Dev loss: 0.4591 r:0.6683
si_en Dev loss: 0.8721 r:0.5446
ne_en Dev loss: 0.5815 r:0.7063
ru_en Dev loss: 0.4266 r:0.7498
Current avg r:0.5880 Best avg r: 0.6244
08:45:59,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:30,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:00,364 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1283
en_de Dev loss: 0.9528 r:0.1700
en_zh Dev loss: 0.7799 r:0.4649
ro_en Dev loss: 0.3452 r:0.8181
et_en Dev loss: 0.4719 r:0.6765
si_en Dev loss: 0.8949 r:0.5467
ne_en Dev loss: 0.6037 r:0.6935
ru_en Dev loss: 0.4357 r:0.7532
Current avg r:0.5890 Best avg r: 0.6244
08:53:36,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:55:07,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:38,580 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1366
en_de Dev loss: 0.9642 r:0.1772
en_zh Dev loss: 0.7880 r:0.4753
ro_en Dev loss: 0.3713 r:0.8151
et_en Dev loss: 0.4869 r:0.6670
si_en Dev loss: 0.9220 r:0.5418
ne_en Dev loss: 0.6079 r:0.6972
ru_en Dev loss: 0.4644 r:0.7474
Current avg r:0.5887 Best avg r: 0.6244
09:01:15,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:46,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:04:17,865 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1309
en_de Dev loss: 0.9537 r:0.1549
en_zh Dev loss: 0.7808 r:0.4686
ro_en Dev loss: 0.3494 r:0.8165
et_en Dev loss: 0.4569 r:0.6698
si_en Dev loss: 0.8581 r:0.5419
ne_en Dev loss: 0.5663 r:0.7060
ru_en Dev loss: 0.4182 r:0.7554
Current avg r:0.5876 Best avg r: 0.6244
09:08:54,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:10:25,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:56,989 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1298
en_de Dev loss: 0.9460 r:0.1674
en_zh Dev loss: 0.7782 r:0.4634
ro_en Dev loss: 0.3487 r:0.8174
et_en Dev loss: 0.4713 r:0.6706
si_en Dev loss: 0.8422 r:0.5454
ne_en Dev loss: 0.5477 r:0.7018
ru_en Dev loss: 0.4421 r:0.7427
Current avg r:0.5870 Best avg r: 0.6244
09:16:33,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:03,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:33,620 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1286
en_de Dev loss: 0.9639 r:0.1701
en_zh Dev loss: 0.7753 r:0.4773
ro_en Dev loss: 0.3859 r:0.8109
et_en Dev loss: 0.4873 r:0.6721
si_en Dev loss: 0.9426 r:0.5376
ne_en Dev loss: 0.6022 r:0.7007
ru_en Dev loss: 0.4638 r:0.7475
Current avg r:0.5880 Best avg r: 0.6244
09:24:06,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:36,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:27:07,147 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1257
en_de Dev loss: 0.9520 r:0.1558
en_zh Dev loss: 0.8134 r:0.4565
ro_en Dev loss: 0.3451 r:0.8134
et_en Dev loss: 0.4438 r:0.6621
si_en Dev loss: 0.9414 r:0.5361
ne_en Dev loss: 0.5913 r:0.7031
ru_en Dev loss: 0.4778 r:0.7305
Current avg r:0.5796 Best avg r: 0.6244
09:31:40,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:33:10,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:34:40,729 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1288
en_de Dev loss: 0.9262 r:0.1718
en_zh Dev loss: 0.7708 r:0.4626
ro_en Dev loss: 0.3406 r:0.8147
et_en Dev loss: 0.4530 r:0.6651
si_en Dev loss: 0.9346 r:0.5322
ne_en Dev loss: 0.5520 r:0.7046
ru_en Dev loss: 0.4280 r:0.7436
Current avg r:0.5849 Best avg r: 0.6244
09:39:13,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:40:43,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:42:14,263 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1239
en_de Dev loss: 0.9652 r:0.1648
en_zh Dev loss: 0.7713 r:0.4741
ro_en Dev loss: 0.3610 r:0.8175
et_en Dev loss: 0.4769 r:0.6632
si_en Dev loss: 0.8855 r:0.5388
ne_en Dev loss: 0.6151 r:0.6897
ru_en Dev loss: 0.4558 r:0.7436
Current avg r:0.5845 Best avg r: 0.6244
09:46:47,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:48:17,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:47,758 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1333
en_de Dev loss: 0.9547 r:0.1649
en_zh Dev loss: 0.7470 r:0.4767
ro_en Dev loss: 0.3298 r:0.8230
et_en Dev loss: 0.4641 r:0.6731
si_en Dev loss: 0.8464 r:0.5459
ne_en Dev loss: 0.5669 r:0.7002
ru_en Dev loss: 0.4143 r:0.7557
Current avg r:0.5913 Best avg r: 0.6244
09:54:21,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:51,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:57:21,653 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1173
en_de Dev loss: 0.9766 r:0.1663
en_zh Dev loss: 0.7629 r:0.4737
ro_en Dev loss: 0.3337 r:0.8201
et_en Dev loss: 0.4723 r:0.6791
si_en Dev loss: 0.7979 r:0.5502
ne_en Dev loss: 0.5267 r:0.7004
ru_en Dev loss: 0.4119 r:0.7561
Current avg r:0.5923 Best avg r: 0.6244
10:01:53,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:03:23,962 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:04:54,156 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1185
en_de Dev loss: 0.9368 r:0.1705
en_zh Dev loss: 0.7260 r:0.4792
ro_en Dev loss: 0.3305 r:0.8178
et_en Dev loss: 0.4420 r:0.6764
si_en Dev loss: 0.8384 r:0.5372
ne_en Dev loss: 0.5588 r:0.7083
ru_en Dev loss: 0.4191 r:0.7501
Current avg r:0.5914 Best avg r: 0.6244
10:09:26,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:56,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:26,609 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1141
en_de Dev loss: 0.9554 r:0.1654
en_zh Dev loss: 0.7612 r:0.4704
ro_en Dev loss: 0.3339 r:0.8212
et_en Dev loss: 0.4472 r:0.6727
si_en Dev loss: 0.8607 r:0.5440
ne_en Dev loss: 0.5619 r:0.7003
ru_en Dev loss: 0.4452 r:0.7449
Current avg r:0.5884 Best avg r: 0.6244
10:16:58,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:28,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:59,67 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1119
en_de Dev loss: 0.9377 r:0.1793
en_zh Dev loss: 0.7736 r:0.4731
ro_en Dev loss: 0.3301 r:0.8222
et_en Dev loss: 0.4643 r:0.6804
si_en Dev loss: 0.8594 r:0.5486
ne_en Dev loss: 0.5177 r:0.7074
ru_en Dev loss: 0.4046 r:0.7638
Current avg r:0.5964 Best avg r: 0.6244
10:24:31,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:26:01,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:32,214 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1101
en_de Dev loss: 0.9924 r:0.1485
en_zh Dev loss: 0.8146 r:0.4627
ro_en Dev loss: 0.3723 r:0.8185
et_en Dev loss: 0.4726 r:0.6747
si_en Dev loss: 0.9010 r:0.5427
ne_en Dev loss: 0.5987 r:0.7044
ru_en Dev loss: 0.4637 r:0.7467
Current avg r:0.5855 Best avg r: 0.6244
10:32:05,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
