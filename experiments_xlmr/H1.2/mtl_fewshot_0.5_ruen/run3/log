14:44:26,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:40,610 root INFO 
id:en_de cur r: 0.0321 best r: 0.0321
14:44:55,300 root INFO 
id:en_zh cur r: 0.1568 best r: 0.1568
14:45:10,11 root INFO 
id:ro_en cur r: 0.3233 best r: 0.3233
14:45:24,731 root INFO 
id:et_en cur r: 0.2518 best r: 0.2518
14:45:39,452 root INFO 
id:si_en cur r: 0.1978 best r: 0.1978
14:45:54,182 root INFO 
id:ne_en cur r: 0.1606 best r: 0.1606
14:46:23,428 root INFO 
id:ru_en cur r: 0.3206 best r: 0.3206
14:46:23,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:06,203 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
14:48:06,209 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:48:06,215 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:48:06,219 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
14:48:06,226 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
14:48:06,230 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:48:06,234 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:48:20,698 root INFO Epoch 0 Global steps: 700 Train loss: 0.8968
en_de Dev loss: 0.8850 r:0.0487
en_zh Dev loss: 0.8111 r:0.1861
ro_en Dev loss: 0.8271 r:0.4835
et_en Dev loss: 0.7305 r:0.3526
si_en Dev loss: 0.8193 r:0.3039
ne_en Dev loss: 0.7802 r:0.4234
ru_en Dev loss: 0.7849 r:0.3696
Current avg r:0.3097 Best avg r: 0.3097
14:53:29,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:43,448 root INFO 
id:en_de cur r: 0.0605 best r: 0.0605
14:53:58,61 root INFO 
id:en_zh cur r: 0.2262 best r: 0.2262
14:54:12,716 root INFO 
id:ro_en cur r: 0.5839 best r: 0.5839
14:54:27,502 root INFO 
id:et_en cur r: 0.4375 best r: 0.4375
14:54:42,288 root INFO 
id:si_en cur r: 0.2921 best r: 0.2921
14:54:56,912 root INFO 
id:ne_en cur r: 0.4914 best r: 0.4914
14:55:26,153 root INFO 
id:ru_en cur r: 0.5691 best r: 0.5691
14:55:26,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:08,998 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
14:57:09,3 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:57:09,8 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:57:09,12 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
14:57:09,16 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
14:57:09,20 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:57:09,25 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:57:23,476 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8439
en_de Dev loss: 0.8834 r:0.0977
en_zh Dev loss: 0.7854 r:0.2191
ro_en Dev loss: 0.6787 r:0.6032
et_en Dev loss: 0.6149 r:0.4345
si_en Dev loss: 0.7339 r:0.4117
ne_en Dev loss: 0.6004 r:0.5975
ru_en Dev loss: 0.6437 r:0.5600
Current avg r:0.4177 Best avg r: 0.4177
15:02:31,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:00,888 root INFO 
id:en_zh cur r: 0.2831 best r: 0.2831
15:03:15,589 root INFO 
id:ro_en cur r: 0.7098 best r: 0.7098
15:03:30,304 root INFO 
id:et_en cur r: 0.6142 best r: 0.6142
15:03:45,22 root INFO 
id:si_en cur r: 0.4941 best r: 0.4941
15:03:59,735 root INFO 
id:ne_en cur r: 0.6550 best r: 0.6550
15:04:28,908 root INFO 
id:ru_en cur r: 0.6710 best r: 0.6710
15:04:28,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:11,557 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:06:11,563 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:06:11,567 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:06:11,571 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:06:11,576 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:06:11,591 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:06:11,595 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:06:26,165 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7761
en_de Dev loss: 0.9421 r:0.1333
en_zh Dev loss: 0.8269 r:0.2785
ro_en Dev loss: 0.6186 r:0.6937
et_en Dev loss: 0.5131 r:0.5990
si_en Dev loss: 0.7285 r:0.5231
ne_en Dev loss: 0.4564 r:0.6688
ru_en Dev loss: 0.4927 r:0.6682
Current avg r:0.5092 Best avg r: 0.5092
15:11:34,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:49,94 root INFO 
id:en_de cur r: 0.0968 best r: 0.0968
15:12:03,767 root INFO 
id:en_zh cur r: 0.3443 best r: 0.3443
15:12:18,480 root INFO 
id:ro_en cur r: 0.7392 best r: 0.7392
15:12:33,203 root INFO 
id:et_en cur r: 0.6448 best r: 0.6448
15:12:47,938 root INFO 
id:si_en cur r: 0.5499 best r: 0.5499
15:13:02,663 root INFO 
id:ne_en cur r: 0.6642 best r: 0.6642
15:13:31,965 root INFO 
id:ru_en cur r: 0.7321 best r: 0.7321
15:13:31,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:15:14,801 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:15:14,807 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:15:14,813 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:15:14,817 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:15:14,821 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:15:14,825 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:15:14,829 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:15:29,336 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6848
en_de Dev loss: 0.9246 r:0.1541
en_zh Dev loss: 0.7576 r:0.3427
ro_en Dev loss: 0.5227 r:0.7238
et_en Dev loss: 0.4636 r:0.6497
si_en Dev loss: 0.8236 r:0.5329
ne_en Dev loss: 0.4707 r:0.6722
ru_en Dev loss: 0.4269 r:0.7230
Current avg r:0.5426 Best avg r: 0.5426
15:20:37,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:52,108 root INFO 
id:en_de cur r: 0.1705 best r: 0.1705
15:21:06,768 root INFO 
id:en_zh cur r: 0.3666 best r: 0.3666
15:21:21,496 root INFO 
id:ro_en cur r: 0.7669 best r: 0.7669
15:21:36,237 root INFO 
id:et_en cur r: 0.6954 best r: 0.6954
15:21:50,987 root INFO 
id:si_en cur r: 0.5661 best r: 0.5661
15:22:05,589 root INFO 
id:ne_en cur r: 0.6958 best r: 0.6958
15:22:20,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:02,631 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:24:02,637 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:24:02,641 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:24:02,645 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:24:02,649 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:24:02,654 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:24:02,658 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:24:17,301 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6481
en_de Dev loss: 0.9290 r:0.1811
en_zh Dev loss: 0.7716 r:0.3679
ro_en Dev loss: 0.4428 r:0.7550
et_en Dev loss: 0.4090 r:0.6937
si_en Dev loss: 0.8538 r:0.5536
ne_en Dev loss: 0.4910 r:0.6894
ru_en Dev loss: 0.4817 r:0.7224
Current avg r:0.5662 Best avg r: 0.5662
15:29:25,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:40,103 root INFO 
id:en_de cur r: 0.1843 best r: 0.1843
15:29:54,745 root INFO 
id:en_zh cur r: 0.3963 best r: 0.3963
15:30:09,498 root INFO 
id:ro_en cur r: 0.7675 best r: 0.7675
15:30:24,260 root INFO 
id:et_en cur r: 0.6971 best r: 0.6971
15:30:53,820 root INFO 
id:ne_en cur r: 0.6982 best r: 0.6982
15:31:08,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:51,186 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:32:51,191 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:32:51,195 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:32:51,200 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:32:51,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:32:51,209 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:32:51,213 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:33:05,764 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6176
en_de Dev loss: 0.8905 r:0.1891
en_zh Dev loss: 0.7659 r:0.3982
ro_en Dev loss: 0.4331 r:0.7564
et_en Dev loss: 0.3783 r:0.7023
si_en Dev loss: 0.7534 r:0.5618
ne_en Dev loss: 0.4696 r:0.7072
ru_en Dev loss: 0.4783 r:0.7169
Current avg r:0.5760 Best avg r: 0.5760
15:38:14,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:28,828 root INFO 
id:en_de cur r: 0.1881 best r: 0.1881
15:38:58,253 root INFO 
id:ro_en cur r: 0.7910 best r: 0.7910
15:39:12,849 root INFO 
id:et_en cur r: 0.7142 best r: 0.7142
15:39:27,470 root INFO 
id:si_en cur r: 0.5801 best r: 0.5801
15:39:42,192 root INFO 
id:ne_en cur r: 0.7258 best r: 0.7258
15:40:11,579 root INFO 
id:ru_en cur r: 0.7463 best r: 0.7463
15:40:11,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:54,1 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:41:54,8 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:41:54,13 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:41:54,19 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:41:54,26 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:41:54,30 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:41:54,34 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:42:08,603 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5785
en_de Dev loss: 0.9318 r:0.1999
en_zh Dev loss: 0.7938 r:0.3949
ro_en Dev loss: 0.4370 r:0.7787
et_en Dev loss: 0.3906 r:0.7123
si_en Dev loss: 0.6620 r:0.5866
ne_en Dev loss: 0.4212 r:0.7226
ru_en Dev loss: 0.4746 r:0.7364
Current avg r:0.5902 Best avg r: 0.5902
15:47:17,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:45,901 root INFO 
id:en_zh cur r: 0.4130 best r: 0.4130
15:48:00,662 root INFO 
id:ro_en cur r: 0.7936 best r: 0.7936
15:48:30,171 root INFO 
id:si_en cur r: 0.5817 best r: 0.5817
15:48:59,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:41,865 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:50:41,870 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:50:41,874 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:50:41,878 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:50:41,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:50:41,886 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:50:41,890 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:50:56,450 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6076
en_de Dev loss: 0.9388 r:0.1920
en_zh Dev loss: 0.7658 r:0.4156
ro_en Dev loss: 0.4648 r:0.7851
et_en Dev loss: 0.3949 r:0.7120
si_en Dev loss: 0.6881 r:0.5904
ne_en Dev loss: 0.4644 r:0.7288
ru_en Dev loss: 0.5661 r:0.7119
Current avg r:0.5908 Best avg r: 0.5908
15:56:05,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:19,522 root INFO 
id:en_de cur r: 0.1991 best r: 0.1991
15:56:34,322 root INFO 
id:en_zh cur r: 0.4288 best r: 0.4288
15:56:49,123 root INFO 
id:ro_en cur r: 0.7950 best r: 0.7950
15:57:33,197 root INFO 
id:ne_en cur r: 0.7299 best r: 0.7299
15:57:47,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:31,60 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
15:59:31,65 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:59:31,70 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:59:31,74 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
15:59:31,80 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
15:59:31,84 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:59:31,88 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:59:45,756 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5685
en_de Dev loss: 0.9297 r:0.2130
en_zh Dev loss: 0.7357 r:0.4265
ro_en Dev loss: 0.5382 r:0.7924
et_en Dev loss: 0.4274 r:0.7091
si_en Dev loss: 0.8260 r:0.5798
ne_en Dev loss: 0.5433 r:0.7248
ru_en Dev loss: 0.5615 r:0.7254
Current avg r:0.5959 Best avg r: 0.5959
16:04:54,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:05:08,925 root INFO 
id:en_de cur r: 0.2185 best r: 0.2185
16:05:23,618 root INFO 
id:en_zh cur r: 0.4466 best r: 0.4466
16:05:38,351 root INFO 
id:ro_en cur r: 0.8083 best r: 0.8083
16:06:07,867 root INFO 
id:si_en cur r: 0.5941 best r: 0.5941
16:06:22,629 root INFO 
id:ne_en cur r: 0.7499 best r: 0.7499
16:06:51,847 root INFO 
id:ru_en cur r: 0.7562 best r: 0.7562
16:06:51,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:34,867 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:08:34,873 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:08:34,877 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:08:34,881 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:08:34,887 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:08:34,894 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:08:34,899 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:08:49,425 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5287
en_de Dev loss: 0.8592 r:0.2320
en_zh Dev loss: 0.6683 r:0.4425
ro_en Dev loss: 0.3656 r:0.8000
et_en Dev loss: 0.3597 r:0.7172
si_en Dev loss: 0.6721 r:0.5906
ne_en Dev loss: 0.3909 r:0.7436
ru_en Dev loss: 0.4282 r:0.7472
Current avg r:0.6104 Best avg r: 0.6104
16:13:58,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:12,473 root INFO 
id:en_de cur r: 0.2263 best r: 0.2263
16:14:41,836 root INFO 
id:ro_en cur r: 0.8087 best r: 0.8087
16:14:56,567 root INFO 
id:et_en cur r: 0.7170 best r: 0.7170
16:15:11,306 root INFO 
id:si_en cur r: 0.6113 best r: 0.6113
16:15:26,42 root INFO 
id:ne_en cur r: 0.7536 best r: 0.7536
16:15:55,371 root INFO 
id:ru_en cur r: 0.7712 best r: 0.7712
16:15:55,371 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:17:38,249 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:17:38,255 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:17:38,259 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:17:38,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:17:38,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:17:38,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:17:38,277 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:17:52,930 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5288
en_de Dev loss: 0.8530 r:0.2456
en_zh Dev loss: 0.6690 r:0.4404
ro_en Dev loss: 0.3237 r:0.7988
et_en Dev loss: 0.3454 r:0.7219
si_en Dev loss: 0.5326 r:0.6104
ne_en Dev loss: 0.3672 r:0.7448
ru_en Dev loss: 0.3523 r:0.7672
Current avg r:0.6184 Best avg r: 0.6184
16:23:01,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:16,84 root INFO 
id:en_de cur r: 0.2317 best r: 0.2317
16:24:44,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:26,803 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5481
en_de Dev loss: 0.8584 r:0.2437
en_zh Dev loss: 0.7048 r:0.4360
ro_en Dev loss: 0.3591 r:0.8010
et_en Dev loss: 0.3720 r:0.7062
si_en Dev loss: 0.7196 r:0.5881
ne_en Dev loss: 0.4345 r:0.7400
ru_en Dev loss: 0.4207 r:0.7508
Current avg r:0.6094 Best avg r: 0.6184
16:31:35,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:04,746 root INFO 
id:en_zh cur r: 0.4580 best r: 0.4580
16:32:19,423 root INFO 
id:ro_en cur r: 0.8246 best r: 0.8246
16:32:34,134 root INFO 
id:et_en cur r: 0.7205 best r: 0.7205
16:32:48,844 root INFO 
id:si_en cur r: 0.6325 best r: 0.6325
16:33:03,549 root INFO 
id:ne_en cur r: 0.7674 best r: 0.7674
16:33:18,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:00,863 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
16:35:00,868 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:35:00,873 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:35:00,878 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
16:35:00,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
16:35:00,887 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:35:00,892 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:35:15,483 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5098
en_de Dev loss: 0.8592 r:0.2320
en_zh Dev loss: 0.6968 r:0.4511
ro_en Dev loss: 0.3169 r:0.8213
et_en Dev loss: 0.3464 r:0.7240
si_en Dev loss: 0.6396 r:0.6288
ne_en Dev loss: 0.3648 r:0.7681
ru_en Dev loss: 0.4274 r:0.7571
Current avg r:0.6261 Best avg r: 0.6261
16:40:24,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:06,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:49,340 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5312
en_de Dev loss: 0.8955 r:0.2264
en_zh Dev loss: 0.7724 r:0.4333
ro_en Dev loss: 0.4121 r:0.8069
et_en Dev loss: 0.3852 r:0.7165
si_en Dev loss: 0.7280 r:0.6163
ne_en Dev loss: 0.4318 r:0.7600
ru_en Dev loss: 0.5315 r:0.7342
Current avg r:0.6134 Best avg r: 0.6261
16:48:58,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:40,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:23,137 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5159
en_de Dev loss: 0.8509 r:0.2386
en_zh Dev loss: 0.6928 r:0.4390
ro_en Dev loss: 0.3564 r:0.8116
et_en Dev loss: 0.3708 r:0.7094
si_en Dev loss: 0.6965 r:0.6151
ne_en Dev loss: 0.4086 r:0.7550
ru_en Dev loss: 0.4438 r:0.7338
Current avg r:0.6147 Best avg r: 0.6261
16:57:33,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:15,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:58,414 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5035
en_de Dev loss: 0.8485 r:0.2448
en_zh Dev loss: 0.7194 r:0.4381
ro_en Dev loss: 0.3402 r:0.8113
et_en Dev loss: 0.3741 r:0.7090
si_en Dev loss: 0.7161 r:0.6103
ne_en Dev loss: 0.4268 r:0.7546
ru_en Dev loss: 0.4566 r:0.7322
Current avg r:0.6143 Best avg r: 0.6261
17:06:07,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:35,103 root INFO 
id:ne_en cur r: 0.7695 best r: 0.7695
17:07:49,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:32,603 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4929
en_de Dev loss: 0.8646 r:0.2448
en_zh Dev loss: 0.7259 r:0.4487
ro_en Dev loss: 0.3094 r:0.8190
et_en Dev loss: 0.3546 r:0.7175
si_en Dev loss: 0.5946 r:0.6286
ne_en Dev loss: 0.3353 r:0.7647
ru_en Dev loss: 0.4324 r:0.7545
Current avg r:0.6254 Best avg r: 0.6261
17:14:41,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:55,865 root INFO 
id:en_de cur r: 0.2349 best r: 0.2349
17:16:24,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:06,929 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4650
en_de Dev loss: 0.8721 r:0.2433
en_zh Dev loss: 0.7153 r:0.4447
ro_en Dev loss: 0.3446 r:0.8139
et_en Dev loss: 0.3753 r:0.7091
si_en Dev loss: 0.6638 r:0.6130
ne_en Dev loss: 0.4114 r:0.7527
ru_en Dev loss: 0.4751 r:0.7286
Current avg r:0.6150 Best avg r: 0.6261
17:23:15,726 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:44,840 root INFO 
id:en_zh cur r: 0.4639 best r: 0.4639
17:24:58,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:41,235 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4963
en_de Dev loss: 0.8406 r:0.2443
en_zh Dev loss: 0.6687 r:0.4531
ro_en Dev loss: 0.2979 r:0.8191
et_en Dev loss: 0.3482 r:0.7188
si_en Dev loss: 0.5857 r:0.6255
ne_en Dev loss: 0.3605 r:0.7628
ru_en Dev loss: 0.3800 r:0.7564
Current avg r:0.6257 Best avg r: 0.6261
17:31:49,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:04,386 root INFO 
id:en_de cur r: 0.2389 best r: 0.2389
17:32:19,28 root INFO 
id:en_zh cur r: 0.4759 best r: 0.4759
17:33:32,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:15,620 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
17:35:15,626 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:35:15,631 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:35:15,635 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
17:35:15,639 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
17:35:15,645 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:35:15,650 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:35:30,201 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4798
en_de Dev loss: 0.8393 r:0.2558
en_zh Dev loss: 0.6628 r:0.4650
ro_en Dev loss: 0.3212 r:0.8180
et_en Dev loss: 0.4048 r:0.7195
si_en Dev loss: 0.5522 r:0.6325
ne_en Dev loss: 0.3468 r:0.7577
ru_en Dev loss: 0.3896 r:0.7536
Current avg r:0.6289 Best avg r: 0.6289
17:40:38,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:21,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:04,682 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4821
en_de Dev loss: 0.8568 r:0.2483
en_zh Dev loss: 0.7333 r:0.4459
ro_en Dev loss: 0.3604 r:0.8168
et_en Dev loss: 0.3719 r:0.7130
si_en Dev loss: 0.7182 r:0.6147
ne_en Dev loss: 0.4676 r:0.7463
ru_en Dev loss: 0.4749 r:0.7270
Current avg r:0.6160 Best avg r: 0.6289
17:49:13,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:50:56,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:39,129 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4619
en_de Dev loss: 0.8561 r:0.2460
en_zh Dev loss: 0.7239 r:0.4654
ro_en Dev loss: 0.3599 r:0.8193
et_en Dev loss: 0.3620 r:0.7163
si_en Dev loss: 0.6792 r:0.6283
ne_en Dev loss: 0.4026 r:0.7589
ru_en Dev loss: 0.4944 r:0.7421
Current avg r:0.6252 Best avg r: 0.6289
17:57:47,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:02,445 root INFO 
id:en_de cur r: 0.2499 best r: 0.2499
17:59:30,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:13,685 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4609
en_de Dev loss: 0.8481 r:0.2492
en_zh Dev loss: 0.6959 r:0.4501
ro_en Dev loss: 0.3304 r:0.8123
et_en Dev loss: 0.3651 r:0.7088
si_en Dev loss: 0.7413 r:0.6093
ne_en Dev loss: 0.4634 r:0.7557
ru_en Dev loss: 0.4195 r:0.7365
Current avg r:0.6174 Best avg r: 0.6289
18:06:22,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:06,447 root INFO 
id:ro_en cur r: 0.8266 best r: 0.8266
18:08:05,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:48,404 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4601
en_de Dev loss: 0.8732 r:0.2495
en_zh Dev loss: 0.7628 r:0.4430
ro_en Dev loss: 0.3423 r:0.8231
et_en Dev loss: 0.3728 r:0.7081
si_en Dev loss: 0.6766 r:0.6230
ne_en Dev loss: 0.4016 r:0.7575
ru_en Dev loss: 0.5063 r:0.7182
Current avg r:0.6175 Best avg r: 0.6289
18:14:57,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:15:26,643 root INFO 
id:en_zh cur r: 0.4804 best r: 0.4804
18:16:40,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:23,64 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4538
en_de Dev loss: 0.8597 r:0.2512
en_zh Dev loss: 0.6934 r:0.4683
ro_en Dev loss: 0.3681 r:0.8230
et_en Dev loss: 0.3718 r:0.7161
si_en Dev loss: 0.7289 r:0.6222
ne_en Dev loss: 0.4061 r:0.7653
ru_en Dev loss: 0.4887 r:0.7454
Current avg r:0.6274 Best avg r: 0.6289
18:23:31,895 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:46,353 root INFO 
id:en_de cur r: 0.2519 best r: 0.2519
18:25:14,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:57,416 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4370
en_de Dev loss: 0.8366 r:0.2607
en_zh Dev loss: 0.6990 r:0.4674
ro_en Dev loss: 0.3551 r:0.8216
et_en Dev loss: 0.3814 r:0.7113
si_en Dev loss: 0.7501 r:0.6135
ne_en Dev loss: 0.4472 r:0.7593
ru_en Dev loss: 0.4604 r:0.7414
Current avg r:0.6250 Best avg r: 0.6289
18:32:06,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:49,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:32,424 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4737
en_de Dev loss: 0.8380 r:0.2551
en_zh Dev loss: 0.6744 r:0.4679
ro_en Dev loss: 0.3305 r:0.8133
et_en Dev loss: 0.3628 r:0.7201
si_en Dev loss: 0.7085 r:0.6114
ne_en Dev loss: 0.4258 r:0.7580
ru_en Dev loss: 0.3978 r:0.7488
Current avg r:0.6249 Best avg r: 0.6289
18:40:41,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:55,595 root INFO 
id:en_de cur r: 0.2573 best r: 0.2573
18:42:23,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:07,144 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4544
en_de Dev loss: 0.8604 r:0.2601
en_zh Dev loss: 0.7192 r:0.4661
ro_en Dev loss: 0.3508 r:0.8154
et_en Dev loss: 0.3705 r:0.7104
si_en Dev loss: 0.8343 r:0.6052
ne_en Dev loss: 0.5710 r:0.7546
ru_en Dev loss: 0.4944 r:0.7265
Current avg r:0.6198 Best avg r: 0.6289
18:49:15,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:45,83 root INFO 
id:en_zh cur r: 0.4847 best r: 0.4847
18:50:58,712 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:41,734 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4687
en_de Dev loss: 0.8353 r:0.2523
en_zh Dev loss: 0.6915 r:0.4757
ro_en Dev loss: 0.3158 r:0.8231
et_en Dev loss: 0.3713 r:0.7140
si_en Dev loss: 0.5722 r:0.6298
ne_en Dev loss: 0.3781 r:0.7636
ru_en Dev loss: 0.4499 r:0.7430
Current avg r:0.6288 Best avg r: 0.6289
18:57:50,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:19,528 root INFO 
id:en_zh cur r: 0.4928 best r: 0.4928
18:59:18,605 root INFO 
id:ne_en cur r: 0.7755 best r: 0.7755
18:59:33,187 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:16,140 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4699
en_de Dev loss: 0.8448 r:0.2250
en_zh Dev loss: 0.6441 r:0.4811
ro_en Dev loss: 0.3012 r:0.8218
et_en Dev loss: 0.3963 r:0.7117
si_en Dev loss: 0.5729 r:0.6240
ne_en Dev loss: 0.3403 r:0.7675
ru_en Dev loss: 0.3638 r:0.7603
Current avg r:0.6273 Best avg r: 0.6289
19:06:25,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:09,609 root INFO 
id:ro_en cur r: 0.8293 best r: 0.8293
19:08:08,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:50,862 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4158
en_de Dev loss: 0.8375 r:0.2575
en_zh Dev loss: 0.6605 r:0.4812
ro_en Dev loss: 0.3125 r:0.8253
et_en Dev loss: 0.3653 r:0.7106
si_en Dev loss: 0.6571 r:0.6125
ne_en Dev loss: 0.3911 r:0.7584
ru_en Dev loss: 0.4186 r:0.7427
Current avg r:0.6269 Best avg r: 0.6289
19:14:59,445 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:42,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:25,96 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4444
en_de Dev loss: 0.8522 r:0.2456
en_zh Dev loss: 0.6974 r:0.4821
ro_en Dev loss: 0.3212 r:0.8225
et_en Dev loss: 0.3989 r:0.7062
si_en Dev loss: 0.5994 r:0.6241
ne_en Dev loss: 0.3944 r:0.7504
ru_en Dev loss: 0.4449 r:0.7485
Current avg r:0.6256 Best avg r: 0.6289
19:23:33,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:16,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:26:58,834 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4142
en_de Dev loss: 0.8804 r:0.2448
en_zh Dev loss: 0.7223 r:0.4721
ro_en Dev loss: 0.3298 r:0.8231
et_en Dev loss: 0.3744 r:0.7108
si_en Dev loss: 0.6930 r:0.6165
ne_en Dev loss: 0.4656 r:0.7584
ru_en Dev loss: 0.5015 r:0.7250
Current avg r:0.6215 Best avg r: 0.6289
19:32:07,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:32:51,277 root INFO 
id:ro_en cur r: 0.8310 best r: 0.8310
19:33:50,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:32,898 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4124
en_de Dev loss: 0.8596 r:0.2388
en_zh Dev loss: 0.6992 r:0.4751
ro_en Dev loss: 0.3488 r:0.8267
et_en Dev loss: 0.3728 r:0.7131
si_en Dev loss: 0.6712 r:0.6242
ne_en Dev loss: 0.3994 r:0.7609
ru_en Dev loss: 0.4446 r:0.7453
Current avg r:0.6263 Best avg r: 0.6289
19:40:41,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:10,675 root INFO 
id:en_zh cur r: 0.4950 best r: 0.4950
19:42:23,910 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:06,453 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4243
en_de Dev loss: 0.8647 r:0.2127
en_zh Dev loss: 0.7065 r:0.4854
ro_en Dev loss: 0.3206 r:0.8257
et_en Dev loss: 0.4089 r:0.7156
si_en Dev loss: 0.6355 r:0.6242
ne_en Dev loss: 0.3712 r:0.7609
ru_en Dev loss: 0.4590 r:0.7326
Current avg r:0.6225 Best avg r: 0.6289
19:49:15,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:59,10 root INFO 
id:ro_en cur r: 0.8319 best r: 0.8319
19:50:57,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:40,448 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_de.lang_agnost_mlp.dev.best.scores
19:52:40,456 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/en_zh.lang_agnost_mlp.dev.best.scores
19:52:40,461 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ro_en.lang_agnost_mlp.dev.best.scores
19:52:40,466 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/et_en.lang_agnost_mlp.dev.best.scores
19:52:40,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/si_en.lang_agnost_mlp.dev.best.scores
19:52:40,477 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ne_en.lang_agnost_mlp.dev.best.scores
19:52:40,483 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.5_ruen/run3/ru_en.lang_agnost_mlp.dev.best.scores
19:52:54,982 root INFO Epoch 2 Global steps: 25200 Train loss: 0.3933
en_de Dev loss: 0.8314 r:0.2524
en_zh Dev loss: 0.6648 r:0.4760
ro_en Dev loss: 0.2843 r:0.8291
et_en Dev loss: 0.3823 r:0.7156
si_en Dev loss: 0.5913 r:0.6242
ne_en Dev loss: 0.3450 r:0.7637
ru_en Dev loss: 0.3788 r:0.7529
Current avg r:0.6305 Best avg r: 0.6305
19:58:03,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:46,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:01:28,738 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4096
en_de Dev loss: 0.8367 r:0.2466
en_zh Dev loss: 0.6798 r:0.4727
ro_en Dev loss: 0.3234 r:0.8211
et_en Dev loss: 0.3725 r:0.7084
si_en Dev loss: 0.6858 r:0.6170
ne_en Dev loss: 0.4005 r:0.7617
ru_en Dev loss: 0.4467 r:0.7324
Current avg r:0.6228 Best avg r: 0.6305
20:06:37,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:19,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:02,705 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4038
en_de Dev loss: 0.8757 r:0.2387
en_zh Dev loss: 0.7869 r:0.4497
ro_en Dev loss: 0.3569 r:0.8250
et_en Dev loss: 0.3907 r:0.7163
si_en Dev loss: 0.6921 r:0.6203
ne_en Dev loss: 0.3895 r:0.7620
ru_en Dev loss: 0.4922 r:0.7347
Current avg r:0.6209 Best avg r: 0.6305
20:15:11,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:53,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:36,185 root INFO Epoch 2 Global steps: 27300 Train loss: 0.3878
en_de Dev loss: 0.8386 r:0.2464
en_zh Dev loss: 0.7181 r:0.4599
ro_en Dev loss: 0.3352 r:0.8234
et_en Dev loss: 0.3950 r:0.7069
si_en Dev loss: 0.7773 r:0.6112
ne_en Dev loss: 0.4159 r:0.7622
ru_en Dev loss: 0.4773 r:0.7239
Current avg r:0.6191 Best avg r: 0.6305
20:23:44,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:26,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:09,127 root INFO Epoch 2 Global steps: 28000 Train loss: 0.3966
en_de Dev loss: 0.8514 r:0.2358
en_zh Dev loss: 0.7349 r:0.4568
ro_en Dev loss: 0.3472 r:0.8233
et_en Dev loss: 0.4027 r:0.7046
si_en Dev loss: 0.6345 r:0.6112
ne_en Dev loss: 0.3666 r:0.7589
ru_en Dev loss: 0.4598 r:0.7374
Current avg r:0.6183 Best avg r: 0.6305
20:32:17,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:00,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:43,523 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3888
en_de Dev loss: 0.8608 r:0.2353
en_zh Dev loss: 0.7312 r:0.4595
ro_en Dev loss: 0.3286 r:0.8263
et_en Dev loss: 0.3818 r:0.7107
si_en Dev loss: 0.8022 r:0.6017
ne_en Dev loss: 0.4336 r:0.7594
ru_en Dev loss: 0.4882 r:0.7394
Current avg r:0.6189 Best avg r: 0.6305
20:40:52,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:35,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:18,363 root INFO Epoch 2 Global steps: 29400 Train loss: 0.4138
en_de Dev loss: 0.8527 r:0.2470
en_zh Dev loss: 0.7350 r:0.4549
ro_en Dev loss: 0.3399 r:0.8205
et_en Dev loss: 0.3868 r:0.7044
si_en Dev loss: 0.7913 r:0.6010
ne_en Dev loss: 0.5163 r:0.7595
ru_en Dev loss: 0.5591 r:0.6930
Current avg r:0.6115 Best avg r: 0.6305
20:49:27,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:11,264 root INFO 
id:ro_en cur r: 0.8321 best r: 0.8321
20:51:10,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:53,300 root INFO Epoch 2 Global steps: 30100 Train loss: 0.3956
en_de Dev loss: 0.8530 r:0.2346
en_zh Dev loss: 0.7090 r:0.4567
ro_en Dev loss: 0.2909 r:0.8305
et_en Dev loss: 0.3638 r:0.7165
si_en Dev loss: 0.6331 r:0.6189
ne_en Dev loss: 0.3729 r:0.7632
ru_en Dev loss: 0.4291 r:0.7387
Current avg r:0.6227 Best avg r: 0.6305
20:58:02,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:45,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:28,282 root INFO Epoch 2 Global steps: 30800 Train loss: 0.3823
en_de Dev loss: 0.8532 r:0.2463
en_zh Dev loss: 0.7215 r:0.4580
ro_en Dev loss: 0.3181 r:0.8239
et_en Dev loss: 0.3868 r:0.7013
si_en Dev loss: 0.6261 r:0.6195
ne_en Dev loss: 0.3856 r:0.7624
ru_en Dev loss: 0.4423 r:0.7305
Current avg r:0.6203 Best avg r: 0.6305
21:06:37,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:51,569 root INFO 
id:en_de cur r: 0.2583 best r: 0.2583
21:08:20,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:03,778 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3839
en_de Dev loss: 0.8339 r:0.2639
en_zh Dev loss: 0.6951 r:0.4730
ro_en Dev loss: 0.3317 r:0.8250
et_en Dev loss: 0.3875 r:0.7059
si_en Dev loss: 0.6461 r:0.6209
ne_en Dev loss: 0.4188 r:0.7650
ru_en Dev loss: 0.4282 r:0.7392
Current avg r:0.6276 Best avg r: 0.6305
21:15:13,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:57,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:40,417 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3331
en_de Dev loss: 0.8535 r:0.2497
en_zh Dev loss: 0.7599 r:0.4493
ro_en Dev loss: 0.3649 r:0.8216
et_en Dev loss: 0.4001 r:0.7036
si_en Dev loss: 0.7328 r:0.6040
ne_en Dev loss: 0.4801 r:0.7553
ru_en Dev loss: 0.5053 r:0.7170
Current avg r:0.6144 Best avg r: 0.6305
21:23:49,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:32,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:15,129 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3576
en_de Dev loss: 0.8403 r:0.2439
en_zh Dev loss: 0.7141 r:0.4628
ro_en Dev loss: 0.2945 r:0.8286
et_en Dev loss: 0.3798 r:0.7092
si_en Dev loss: 0.6074 r:0.6227
ne_en Dev loss: 0.4187 r:0.7588
ru_en Dev loss: 0.4344 r:0.7372
Current avg r:0.6233 Best avg r: 0.6305
21:32:23,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:07,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:50,91 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3485
en_de Dev loss: 0.8454 r:0.2495
en_zh Dev loss: 0.7096 r:0.4716
ro_en Dev loss: 0.3373 r:0.8211
et_en Dev loss: 0.4197 r:0.7075
si_en Dev loss: 0.6685 r:0.6128
ne_en Dev loss: 0.4095 r:0.7608
ru_en Dev loss: 0.4554 r:0.7283
Current avg r:0.6217 Best avg r: 0.6305
21:40:58,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:41,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:24,965 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3657
en_de Dev loss: 0.8562 r:0.2310
en_zh Dev loss: 0.7488 r:0.4563
ro_en Dev loss: 0.3297 r:0.8242
et_en Dev loss: 0.4053 r:0.7009
si_en Dev loss: 0.7580 r:0.6011
ne_en Dev loss: 0.4449 r:0.7535
ru_en Dev loss: 0.4815 r:0.7246
Current avg r:0.6131 Best avg r: 0.6305
21:49:33,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:16,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:59,945 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3525
en_de Dev loss: 0.8513 r:0.2389
en_zh Dev loss: 0.6862 r:0.4758
ro_en Dev loss: 0.3154 r:0.8255
et_en Dev loss: 0.3891 r:0.7056
si_en Dev loss: 0.6677 r:0.6098
ne_en Dev loss: 0.4167 r:0.7549
ru_en Dev loss: 0.4878 r:0.7154
Current avg r:0.6180 Best avg r: 0.6305
21:58:08,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:51,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:34,929 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3486
en_de Dev loss: 0.8757 r:0.2414
en_zh Dev loss: 0.7779 r:0.4481
ro_en Dev loss: 0.3430 r:0.8188
et_en Dev loss: 0.4145 r:0.6965
si_en Dev loss: 0.7064 r:0.6028
ne_en Dev loss: 0.4709 r:0.7577
ru_en Dev loss: 0.4576 r:0.7319
Current avg r:0.6139 Best avg r: 0.6305
22:06:43,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:27,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:09,943 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3702
en_de Dev loss: 0.8581 r:0.2238
en_zh Dev loss: 0.7079 r:0.4752
ro_en Dev loss: 0.2921 r:0.8305
et_en Dev loss: 0.3670 r:0.7098
si_en Dev loss: 0.5862 r:0.6231
ne_en Dev loss: 0.3578 r:0.7599
ru_en Dev loss: 0.4132 r:0.7514
Current avg r:0.6248 Best avg r: 0.6305
22:15:18,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:01,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:18:44,930 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3346
en_de Dev loss: 0.8426 r:0.2416
en_zh Dev loss: 0.7312 r:0.4533
ro_en Dev loss: 0.3217 r:0.8255
et_en Dev loss: 0.4106 r:0.7056
si_en Dev loss: 0.6434 r:0.6152
ne_en Dev loss: 0.3808 r:0.7630
ru_en Dev loss: 0.4209 r:0.7440
Current avg r:0.6212 Best avg r: 0.6305
22:23:53,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:36,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:19,859 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3514
en_de Dev loss: 0.8585 r:0.2426
en_zh Dev loss: 0.7547 r:0.4526
ro_en Dev loss: 0.3482 r:0.8188
et_en Dev loss: 0.4033 r:0.6881
si_en Dev loss: 0.7719 r:0.5988
ne_en Dev loss: 0.5304 r:0.7500
ru_en Dev loss: 0.5185 r:0.7063
Current avg r:0.6082 Best avg r: 0.6305
22:32:28,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:11,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:54,451 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3457
en_de Dev loss: 0.8530 r:0.2218
en_zh Dev loss: 0.7145 r:0.4698
ro_en Dev loss: 0.3202 r:0.8240
et_en Dev loss: 0.4015 r:0.6994
si_en Dev loss: 0.7393 r:0.6019
ne_en Dev loss: 0.4404 r:0.7590
ru_en Dev loss: 0.4063 r:0.7606
Current avg r:0.6195 Best avg r: 0.6305
22:41:03,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:46,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:29,13 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3377
en_de Dev loss: 0.8832 r:0.2449
en_zh Dev loss: 0.7480 r:0.4609
ro_en Dev loss: 0.3480 r:0.8220
et_en Dev loss: 0.4307 r:0.6926
si_en Dev loss: 0.7121 r:0.6037
ne_en Dev loss: 0.4274 r:0.7592
ru_en Dev loss: 0.5149 r:0.7329
Current avg r:0.6166 Best avg r: 0.6305
22:49:37,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:21,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:04,262 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3409
en_de Dev loss: 0.8869 r:0.2515
en_zh Dev loss: 0.7618 r:0.4581
ro_en Dev loss: 0.3576 r:0.8227
et_en Dev loss: 0.4141 r:0.6987
si_en Dev loss: 0.7298 r:0.6051
ne_en Dev loss: 0.4356 r:0.7588
ru_en Dev loss: 0.5140 r:0.7302
Current avg r:0.6179 Best avg r: 0.6305
22:58:13,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:55,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:38,945 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3425
en_de Dev loss: 0.8401 r:0.2598
en_zh Dev loss: 0.7199 r:0.4567
ro_en Dev loss: 0.3327 r:0.8222
et_en Dev loss: 0.4100 r:0.6882
si_en Dev loss: 0.7590 r:0.5964
ne_en Dev loss: 0.4710 r:0.7558
ru_en Dev loss: 0.4911 r:0.7183
Current avg r:0.6139 Best avg r: 0.6305
23:06:47,767 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:30,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:13,943 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3738
en_de Dev loss: 0.8654 r:0.2377
en_zh Dev loss: 0.7240 r:0.4763
ro_en Dev loss: 0.3710 r:0.8219
et_en Dev loss: 0.4449 r:0.6924
si_en Dev loss: 0.7077 r:0.6078
ne_en Dev loss: 0.4068 r:0.7541
ru_en Dev loss: 0.4978 r:0.7370
Current avg r:0.6182 Best avg r: 0.6305
23:15:22,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:06,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:49,439 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3384
en_de Dev loss: 0.8319 r:0.2571
en_zh Dev loss: 0.7055 r:0.4724
ro_en Dev loss: 0.3409 r:0.8242
et_en Dev loss: 0.4639 r:0.6986
si_en Dev loss: 0.6785 r:0.6077
ne_en Dev loss: 0.3962 r:0.7553
ru_en Dev loss: 0.4135 r:0.7473
Current avg r:0.6232 Best avg r: 0.6305
23:23:59,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:43,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:26,341 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3023
en_de Dev loss: 0.8556 r:0.2445
en_zh Dev loss: 0.7564 r:0.4668
ro_en Dev loss: 0.3534 r:0.8212
et_en Dev loss: 0.4368 r:0.6882
si_en Dev loss: 0.7348 r:0.6017
ne_en Dev loss: 0.4382 r:0.7532
ru_en Dev loss: 0.4590 r:0.7404
Current avg r:0.6166 Best avg r: 0.6305
23:32:36,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:34:20,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:36:05,93 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2965
en_de Dev loss: 0.8627 r:0.2511
en_zh Dev loss: 0.7487 r:0.4652
ro_en Dev loss: 0.3553 r:0.8177
et_en Dev loss: 0.4329 r:0.6960
si_en Dev loss: 0.7627 r:0.5932
ne_en Dev loss: 0.4679 r:0.7470
ru_en Dev loss: 0.5045 r:0.7213
Current avg r:0.6131 Best avg r: 0.6305
23:41:16,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:00,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:44,859 root INFO Epoch 4 Global steps: 44100 Train loss: 0.3022
en_de Dev loss: 0.8676 r:0.2191
en_zh Dev loss: 0.7715 r:0.4553
ro_en Dev loss: 0.3574 r:0.8187
et_en Dev loss: 0.4473 r:0.6863
si_en Dev loss: 0.8348 r:0.5827
ne_en Dev loss: 0.4973 r:0.7443
ru_en Dev loss: 0.4828 r:0.7211
Current avg r:0.6039 Best avg r: 0.6305
23:49:55,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:38,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:22,297 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2958
en_de Dev loss: 0.8871 r:0.2251
en_zh Dev loss: 0.7981 r:0.4482
ro_en Dev loss: 0.3708 r:0.8202
et_en Dev loss: 0.4724 r:0.6833
si_en Dev loss: 0.7740 r:0.5876
ne_en Dev loss: 0.4703 r:0.7392
ru_en Dev loss: 0.5058 r:0.7247
Current avg r:0.6040 Best avg r: 0.6305
23:58:31,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:00:15,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:58,627 root INFO Epoch 4 Global steps: 45500 Train loss: 0.3059
en_de Dev loss: 0.8615 r:0.2301
en_zh Dev loss: 0.7538 r:0.4475
ro_en Dev loss: 0.3370 r:0.8251
et_en Dev loss: 0.4258 r:0.6963
si_en Dev loss: 0.7812 r:0.5945
ne_en Dev loss: 0.4221 r:0.7521
ru_en Dev loss: 0.4725 r:0.7323
Current avg r:0.6111 Best avg r: 0.6305
00:07:07,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:08:51,188 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:34,311 root INFO Epoch 4 Global steps: 46200 Train loss: 0.3077
en_de Dev loss: 0.8657 r:0.2392
en_zh Dev loss: 0.7653 r:0.4586
ro_en Dev loss: 0.3670 r:0.8230
et_en Dev loss: 0.4440 r:0.6895
si_en Dev loss: 0.7608 r:0.6017
ne_en Dev loss: 0.4358 r:0.7490
ru_en Dev loss: 0.5274 r:0.7213
Current avg r:0.6118 Best avg r: 0.6305
00:15:43,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:26,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:10,361 root INFO Epoch 4 Global steps: 46900 Train loss: 0.3080
en_de Dev loss: 0.8672 r:0.2357
en_zh Dev loss: 0.7879 r:0.4616
ro_en Dev loss: 0.4042 r:0.8207
et_en Dev loss: 0.4586 r:0.6902
si_en Dev loss: 0.8359 r:0.5913
ne_en Dev loss: 0.5130 r:0.7500
ru_en Dev loss: 0.4907 r:0.7339
Current avg r:0.6119 Best avg r: 0.6305
00:24:19,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:02,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:46,261 root INFO Epoch 4 Global steps: 47600 Train loss: 0.3068
en_de Dev loss: 0.8841 r:0.2162
en_zh Dev loss: 0.7660 r:0.4530
ro_en Dev loss: 0.3088 r:0.8250
et_en Dev loss: 0.4218 r:0.6965
si_en Dev loss: 0.6444 r:0.5999
ne_en Dev loss: 0.3743 r:0.7587
ru_en Dev loss: 0.4649 r:0.7302
Current avg r:0.6114 Best avg r: 0.6305
00:32:55,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:38,643 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:36:21,988 root INFO Epoch 4 Global steps: 48300 Train loss: 0.3105
en_de Dev loss: 0.8634 r:0.2213
en_zh Dev loss: 0.7551 r:0.4481
ro_en Dev loss: 0.3336 r:0.8202
et_en Dev loss: 0.3987 r:0.6813
si_en Dev loss: 0.7987 r:0.5738
ne_en Dev loss: 0.4931 r:0.7492
ru_en Dev loss: 0.5118 r:0.6921
Current avg r:0.5980 Best avg r: 0.6305
00:41:31,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:14,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:57,579 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2926
en_de Dev loss: 0.8553 r:0.2308
en_zh Dev loss: 0.7396 r:0.4622
ro_en Dev loss: 0.3184 r:0.8262
et_en Dev loss: 0.4462 r:0.6935
si_en Dev loss: 0.7111 r:0.5922
ne_en Dev loss: 0.3853 r:0.7550
ru_en Dev loss: 0.4731 r:0.7150
Current avg r:0.6107 Best avg r: 0.6305
00:50:06,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:49,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:53:33,105 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2945
en_de Dev loss: 0.8756 r:0.2197
en_zh Dev loss: 0.7533 r:0.4608
ro_en Dev loss: 0.3587 r:0.8193
et_en Dev loss: 0.4097 r:0.6912
si_en Dev loss: 0.8030 r:0.5952
ne_en Dev loss: 0.4189 r:0.7582
ru_en Dev loss: 0.4468 r:0.7421
Current avg r:0.6124 Best avg r: 0.6305
00:58:42,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:25,346 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:08,459 root INFO Epoch 4 Global steps: 50400 Train loss: 0.3042
en_de Dev loss: 0.8761 r:0.2129
en_zh Dev loss: 0.7724 r:0.4626
ro_en Dev loss: 0.3857 r:0.8184
et_en Dev loss: 0.4520 r:0.6759
si_en Dev loss: 0.8700 r:0.5817
ne_en Dev loss: 0.5153 r:0.7455
ru_en Dev loss: 0.5472 r:0.7007
Current avg r:0.5997 Best avg r: 0.6305
01:07:17,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:59,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:42,519 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2813
en_de Dev loss: 0.8643 r:0.2164
en_zh Dev loss: 0.7565 r:0.4665
ro_en Dev loss: 0.3533 r:0.8202
et_en Dev loss: 0.4333 r:0.6839
si_en Dev loss: 0.7512 r:0.5923
ne_en Dev loss: 0.4160 r:0.7541
ru_en Dev loss: 0.5041 r:0.7106
Current avg r:0.6063 Best avg r: 0.6305
01:15:51,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:34,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:17,719 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2931
en_de Dev loss: 0.8899 r:0.1873
en_zh Dev loss: 0.8023 r:0.4328
ro_en Dev loss: 0.3309 r:0.8175
et_en Dev loss: 0.4126 r:0.6759
si_en Dev loss: 0.7701 r:0.5824
ne_en Dev loss: 0.4535 r:0.7475
ru_en Dev loss: 0.5555 r:0.6918
Current avg r:0.5907 Best avg r: 0.6305
01:24:26,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:26:09,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:27:53,22 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2739
en_de Dev loss: 0.9010 r:0.1748
en_zh Dev loss: 0.8469 r:0.4324
ro_en Dev loss: 0.3626 r:0.8220
et_en Dev loss: 0.4154 r:0.6888
si_en Dev loss: 0.8271 r:0.5850
ne_en Dev loss: 0.4560 r:0.7568
ru_en Dev loss: 0.5571 r:0.7026
Current avg r:0.5946 Best avg r: 0.6305
01:33:03,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:34:46,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:29,965 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2708
en_de Dev loss: 0.8877 r:0.2019
en_zh Dev loss: 0.7998 r:0.4624
ro_en Dev loss: 0.3681 r:0.8172
et_en Dev loss: 0.4916 r:0.6894
si_en Dev loss: 0.7112 r:0.5975
ne_en Dev loss: 0.4033 r:0.7504
ru_en Dev loss: 0.4958 r:0.7093
Current avg r:0.6040 Best avg r: 0.6305
01:41:38,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:21,812 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:04,884 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2616
en_de Dev loss: 0.8632 r:0.2159
en_zh Dev loss: 0.7537 r:0.4588
ro_en Dev loss: 0.3367 r:0.8208
et_en Dev loss: 0.4382 r:0.6948
si_en Dev loss: 0.6846 r:0.6005
ne_en Dev loss: 0.3765 r:0.7579
ru_en Dev loss: 0.4573 r:0.7246
Current avg r:0.6105 Best avg r: 0.6305
01:50:13,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:57,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:53:40,800 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2661
en_de Dev loss: 0.8661 r:0.2129
en_zh Dev loss: 0.7945 r:0.4356
ro_en Dev loss: 0.3526 r:0.8167
et_en Dev loss: 0.4340 r:0.6769
si_en Dev loss: 0.8583 r:0.5857
ne_en Dev loss: 0.5502 r:0.7488
ru_en Dev loss: 0.5240 r:0.7052
Current avg r:0.5974 Best avg r: 0.6305
01:58:49,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:00:32,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:02:16,203 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2571
en_de Dev loss: 0.8891 r:0.2003
en_zh Dev loss: 0.8114 r:0.4443
ro_en Dev loss: 0.3437 r:0.8172
et_en Dev loss: 0.4497 r:0.6840
si_en Dev loss: 0.7456 r:0.5946
ne_en Dev loss: 0.4146 r:0.7537
ru_en Dev loss: 0.4810 r:0.7286
Current avg r:0.6032 Best avg r: 0.6305
02:07:25,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:09:08,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:51,822 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2648
en_de Dev loss: 0.9004 r:0.1937
en_zh Dev loss: 0.8254 r:0.4392
ro_en Dev loss: 0.3332 r:0.8193
et_en Dev loss: 0.4327 r:0.6768
si_en Dev loss: 0.8138 r:0.5800
ne_en Dev loss: 0.4470 r:0.7490
ru_en Dev loss: 0.4910 r:0.7220
Current avg r:0.5971 Best avg r: 0.6305
02:16:00,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:17:43,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:26,863 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2506
en_de Dev loss: 0.8941 r:0.2004
en_zh Dev loss: 0.8698 r:0.4330
ro_en Dev loss: 0.4142 r:0.8138
et_en Dev loss: 0.4974 r:0.6627
si_en Dev loss: 0.9901 r:0.5608
ne_en Dev loss: 0.5667 r:0.7343
ru_en Dev loss: 0.5610 r:0.6950
Current avg r:0.5857 Best avg r: 0.6305
02:24:35,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:26:19,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:28:02,399 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2577
en_de Dev loss: 0.8920 r:0.1814
en_zh Dev loss: 0.7820 r:0.4357
ro_en Dev loss: 0.3273 r:0.8185
et_en Dev loss: 0.4260 r:0.6740
si_en Dev loss: 0.7688 r:0.5795
ne_en Dev loss: 0.4355 r:0.7492
ru_en Dev loss: 0.4514 r:0.7308
Current avg r:0.5956 Best avg r: 0.6305
02:33:11,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:34:54,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:37,516 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2484
en_de Dev loss: 0.8839 r:0.1964
en_zh Dev loss: 0.7804 r:0.4544
ro_en Dev loss: 0.3794 r:0.8192
et_en Dev loss: 0.4530 r:0.6749
si_en Dev loss: 0.8012 r:0.5787
ne_en Dev loss: 0.4645 r:0.7467
ru_en Dev loss: 0.4627 r:0.7337
Current avg r:0.6006 Best avg r: 0.6305
02:41:46,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:30,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:13,224 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2417
en_de Dev loss: 0.8760 r:0.2135
en_zh Dev loss: 0.7915 r:0.4309
ro_en Dev loss: 0.3444 r:0.8225
et_en Dev loss: 0.4626 r:0.6760
si_en Dev loss: 0.7480 r:0.5814
ne_en Dev loss: 0.4852 r:0.7420
ru_en Dev loss: 0.4460 r:0.7279
Current avg r:0.5992 Best avg r: 0.6305
02:50:22,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:52:05,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:48,735 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2546
en_de Dev loss: 0.8719 r:0.2152
en_zh Dev loss: 0.7960 r:0.4409
ro_en Dev loss: 0.3629 r:0.8213
et_en Dev loss: 0.4643 r:0.6783
si_en Dev loss: 0.7412 r:0.5882
ne_en Dev loss: 0.4912 r:0.7470
ru_en Dev loss: 0.5154 r:0.7021
Current avg r:0.5990 Best avg r: 0.6305
02:58:57,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:00:41,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:02:24,774 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2452
en_de Dev loss: 0.8717 r:0.2275
en_zh Dev loss: 0.7969 r:0.4471
ro_en Dev loss: 0.4251 r:0.8121
et_en Dev loss: 0.4977 r:0.6657
si_en Dev loss: 0.9356 r:0.5669
ne_en Dev loss: 0.5762 r:0.7329
ru_en Dev loss: 0.5545 r:0.7016
Current avg r:0.5934 Best avg r: 0.6305
03:07:33,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:16,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:10:59,945 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2490
en_de Dev loss: 0.8642 r:0.2176
en_zh Dev loss: 0.7342 r:0.4516
ro_en Dev loss: 0.3095 r:0.8246
et_en Dev loss: 0.4638 r:0.6894
si_en Dev loss: 0.6468 r:0.5974
ne_en Dev loss: 0.3986 r:0.7488
ru_en Dev loss: 0.3989 r:0.7419
Current avg r:0.6102 Best avg r: 0.6305
03:16:08,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:17:51,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:35,173 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2527
en_de Dev loss: 0.8690 r:0.2180
en_zh Dev loss: 0.7690 r:0.4404
ro_en Dev loss: 0.3779 r:0.8157
et_en Dev loss: 0.4547 r:0.6764
si_en Dev loss: 0.8106 r:0.5803
ne_en Dev loss: 0.4752 r:0.7457
ru_en Dev loss: 0.4873 r:0.7263
Current avg r:0.6004 Best avg r: 0.6305
03:24:43,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:26:27,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:28:10,193 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2502
en_de Dev loss: 0.8752 r:0.2081
en_zh Dev loss: 0.7454 r:0.4535
ro_en Dev loss: 0.3566 r:0.8132
et_en Dev loss: 0.4376 r:0.6647
si_en Dev loss: 0.7985 r:0.5752
ne_en Dev loss: 0.4711 r:0.7446
ru_en Dev loss: 0.4562 r:0.7288
Current avg r:0.5983 Best avg r: 0.6305
03:33:19,79 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:02,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:45,146 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2362
en_de Dev loss: 0.8959 r:0.1891
en_zh Dev loss: 0.7638 r:0.4529
ro_en Dev loss: 0.3372 r:0.8177
et_en Dev loss: 0.4343 r:0.6806
si_en Dev loss: 0.7313 r:0.5859
ne_en Dev loss: 0.4557 r:0.7386
ru_en Dev loss: 0.4351 r:0.7388
Current avg r:0.6005 Best avg r: 0.6305
03:41:55,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:38,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:21,145 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2321
en_de Dev loss: 0.8865 r:0.2038
en_zh Dev loss: 0.7658 r:0.4584
ro_en Dev loss: 0.3525 r:0.8152
et_en Dev loss: 0.4359 r:0.6705
si_en Dev loss: 0.7949 r:0.5832
ne_en Dev loss: 0.4560 r:0.7431
ru_en Dev loss: 0.4257 r:0.7483
Current avg r:0.6032 Best avg r: 0.6305
03:50:30,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:52:12,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:53:55,841 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2171
en_de Dev loss: 0.9088 r:0.1836
en_zh Dev loss: 0.8095 r:0.4445
ro_en Dev loss: 0.3698 r:0.8168
et_en Dev loss: 0.4558 r:0.6741
si_en Dev loss: 0.7756 r:0.5769
ne_en Dev loss: 0.4646 r:0.7396
ru_en Dev loss: 0.5127 r:0.7190
Current avg r:0.5935 Best avg r: 0.6305
03:59:04,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:00:47,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:02:30,512 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2177
en_de Dev loss: 0.8994 r:0.1937
en_zh Dev loss: 0.7907 r:0.4500
ro_en Dev loss: 0.3441 r:0.8216
et_en Dev loss: 0.4640 r:0.6783
si_en Dev loss: 0.7518 r:0.5880
ne_en Dev loss: 0.4215 r:0.7441
ru_en Dev loss: 0.4461 r:0.7407
Current avg r:0.6023 Best avg r: 0.6305
04:07:39,391 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:09:22,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:11:05,239 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2176
en_de Dev loss: 0.8706 r:0.2164
en_zh Dev loss: 0.7706 r:0.4606
ro_en Dev loss: 0.3802 r:0.8211
et_en Dev loss: 0.4946 r:0.6717
si_en Dev loss: 0.8435 r:0.5722
ne_en Dev loss: 0.4732 r:0.7437
ru_en Dev loss: 0.4425 r:0.7407
Current avg r:0.6038 Best avg r: 0.6305
04:16:14,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:17:57,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:39,900 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2190
en_de Dev loss: 0.8951 r:0.2228
en_zh Dev loss: 0.8172 r:0.4405
ro_en Dev loss: 0.3454 r:0.8245
et_en Dev loss: 0.4774 r:0.6780
si_en Dev loss: 0.7153 r:0.5828
ne_en Dev loss: 0.4434 r:0.7446
ru_en Dev loss: 0.4308 r:0.7431
Current avg r:0.6052 Best avg r: 0.6305
04:24:48,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:26:31,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:28:14,613 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2150
en_de Dev loss: 0.8740 r:0.2250
en_zh Dev loss: 0.7642 r:0.4561
ro_en Dev loss: 0.3379 r:0.8209
et_en Dev loss: 0.4501 r:0.6739
si_en Dev loss: 0.7639 r:0.5707
ne_en Dev loss: 0.4499 r:0.7384
ru_en Dev loss: 0.4429 r:0.7294
Current avg r:0.6021 Best avg r: 0.6305
04:33:23,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:35:06,518 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:36:49,679 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2288
en_de Dev loss: 0.9168 r:0.2018
en_zh Dev loss: 0.8453 r:0.4463
ro_en Dev loss: 0.3859 r:0.8207
et_en Dev loss: 0.4694 r:0.6814
si_en Dev loss: 0.8467 r:0.5802
ne_en Dev loss: 0.5257 r:0.7339
ru_en Dev loss: 0.4928 r:0.7409
Current avg r:0.6008 Best avg r: 0.6305
04:41:58,602 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:41,444 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:24,541 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2072
en_de Dev loss: 0.8737 r:0.2296
en_zh Dev loss: 0.7696 r:0.4585
ro_en Dev loss: 0.3256 r:0.8242
et_en Dev loss: 0.4545 r:0.6818
si_en Dev loss: 0.7543 r:0.5821
ne_en Dev loss: 0.4391 r:0.7399
ru_en Dev loss: 0.4890 r:0.7231
Current avg r:0.6056 Best avg r: 0.6305
04:50:33,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:52:16,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:59,738 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2136
en_de Dev loss: 0.8714 r:0.2377
en_zh Dev loss: 0.7949 r:0.4443
ro_en Dev loss: 0.3463 r:0.8185
et_en Dev loss: 0.4525 r:0.6697
si_en Dev loss: 0.8301 r:0.5702
ne_en Dev loss: 0.5070 r:0.7379
ru_en Dev loss: 0.5174 r:0.7124
Current avg r:0.5987 Best avg r: 0.6305
04:59:08,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:00:51,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:02:33,815 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2235
en_de Dev loss: 0.8844 r:0.2182
en_zh Dev loss: 0.7554 r:0.4559
ro_en Dev loss: 0.3469 r:0.8224
et_en Dev loss: 0.4560 r:0.6754
si_en Dev loss: 0.8008 r:0.5831
ne_en Dev loss: 0.4900 r:0.7414
ru_en Dev loss: 0.4275 r:0.7465
Current avg r:0.6061 Best avg r: 0.6305
05:07:42,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:09:25,553 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:08,733 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2158
en_de Dev loss: 0.9046 r:0.2236
en_zh Dev loss: 0.8497 r:0.4410
ro_en Dev loss: 0.3964 r:0.8158
et_en Dev loss: 0.4941 r:0.6679
si_en Dev loss: 0.8639 r:0.5719
ne_en Dev loss: 0.5055 r:0.7422
ru_en Dev loss: 0.5380 r:0.7250
Current avg r:0.5982 Best avg r: 0.6305
05:16:17,454 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:18:00,370 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:19:43,393 root INFO Epoch 6 Global steps: 71400 Train loss: 0.1994
en_de Dev loss: 0.8778 r:0.2293
en_zh Dev loss: 0.7746 r:0.4854
ro_en Dev loss: 0.3361 r:0.8196
et_en Dev loss: 0.4749 r:0.6751
si_en Dev loss: 0.7314 r:0.5849
ne_en Dev loss: 0.4590 r:0.7417
ru_en Dev loss: 0.4021 r:0.7544
Current avg r:0.6129 Best avg r: 0.6305
05:24:52,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:26:35,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:28:18,90 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2253
en_de Dev loss: 0.8787 r:0.2158
en_zh Dev loss: 0.7939 r:0.4409
ro_en Dev loss: 0.3697 r:0.8137
et_en Dev loss: 0.4663 r:0.6578
si_en Dev loss: 0.8375 r:0.5689
ne_en Dev loss: 0.5420 r:0.7302
ru_en Dev loss: 0.4697 r:0.7306
Current avg r:0.5940 Best avg r: 0.6305
05:33:26,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:35:09,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:36:52,196 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2154
en_de Dev loss: 0.8595 r:0.2400
en_zh Dev loss: 0.7951 r:0.4453
ro_en Dev loss: 0.3704 r:0.8150
et_en Dev loss: 0.4875 r:0.6639
si_en Dev loss: 0.8393 r:0.5618
ne_en Dev loss: 0.4952 r:0.7367
ru_en Dev loss: 0.4707 r:0.7305
Current avg r:0.5990 Best avg r: 0.6305
05:42:01,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:44,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:26,857 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2080
en_de Dev loss: 0.8822 r:0.2332
en_zh Dev loss: 0.8266 r:0.4501
ro_en Dev loss: 0.3563 r:0.8172
et_en Dev loss: 0.4699 r:0.6738
si_en Dev loss: 0.8200 r:0.5672
ne_en Dev loss: 0.4693 r:0.7400
ru_en Dev loss: 0.4599 r:0.7428
Current avg r:0.6035 Best avg r: 0.6305
05:50:36,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:19,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:54:02,847 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1873
en_de Dev loss: 0.8810 r:0.2194
en_zh Dev loss: 0.7779 r:0.4628
ro_en Dev loss: 0.3599 r:0.8234
et_en Dev loss: 0.4808 r:0.6852
si_en Dev loss: 0.7445 r:0.5817
ne_en Dev loss: 0.4163 r:0.7415
ru_en Dev loss: 0.4508 r:0.7370
Current avg r:0.6073 Best avg r: 0.6305
05:59:11,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:00:54,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:02:38,146 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1884
en_de Dev loss: 0.9079 r:0.2027
en_zh Dev loss: 0.8819 r:0.4363
ro_en Dev loss: 0.4282 r:0.8105
et_en Dev loss: 0.4892 r:0.6543
si_en Dev loss: 0.9478 r:0.5514
ne_en Dev loss: 0.5805 r:0.7266
ru_en Dev loss: 0.5950 r:0.6996
Current avg r:0.5831 Best avg r: 0.6305
06:07:47,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:31,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:14,886 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1964
en_de Dev loss: 0.8920 r:0.2079
en_zh Dev loss: 0.7757 r:0.4580
ro_en Dev loss: 0.3802 r:0.8135
et_en Dev loss: 0.4686 r:0.6696
si_en Dev loss: 0.8808 r:0.5562
ne_en Dev loss: 0.5235 r:0.7343
ru_en Dev loss: 0.4793 r:0.7255
Current avg r:0.5950 Best avg r: 0.6305
06:16:24,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:18:07,370 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:19:50,572 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1845
en_de Dev loss: 0.8933 r:0.2143
en_zh Dev loss: 0.7975 r:0.4560
ro_en Dev loss: 0.3677 r:0.8150
et_en Dev loss: 0.4699 r:0.6652
si_en Dev loss: 0.8496 r:0.5582
ne_en Dev loss: 0.5561 r:0.7302
ru_en Dev loss: 0.4761 r:0.7281
Current avg r:0.5953 Best avg r: 0.6305
06:24:59,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:26:41,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:28:24,410 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1838
en_de Dev loss: 0.8976 r:0.2059
en_zh Dev loss: 0.8269 r:0.4479
ro_en Dev loss: 0.4090 r:0.8141
et_en Dev loss: 0.4624 r:0.6626
si_en Dev loss: 0.9036 r:0.5572
ne_en Dev loss: 0.5676 r:0.7376
ru_en Dev loss: 0.4940 r:0.7325
Current avg r:0.5940 Best avg r: 0.6305
06:33:32,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:35:15,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:36:57,689 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1920
en_de Dev loss: 0.8879 r:0.2107
en_zh Dev loss: 0.7766 r:0.4557
ro_en Dev loss: 0.3443 r:0.8166
et_en Dev loss: 0.4669 r:0.6679
si_en Dev loss: 0.8260 r:0.5564
ne_en Dev loss: 0.5095 r:0.7309
ru_en Dev loss: 0.4462 r:0.7368
Current avg r:0.5964 Best avg r: 0.6305
06:42:06,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:43:48,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:31,845 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1887
en_de Dev loss: 0.8857 r:0.2016
en_zh Dev loss: 0.7638 r:0.4649
ro_en Dev loss: 0.3492 r:0.8198
et_en Dev loss: 0.4849 r:0.6752
si_en Dev loss: 0.7464 r:0.5713
ne_en Dev loss: 0.4562 r:0.7337
ru_en Dev loss: 0.4400 r:0.7338
Current avg r:0.6001 Best avg r: 0.6305
06:50:40,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:23,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:54:07,126 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1839
en_de Dev loss: 0.9134 r:0.1954
en_zh Dev loss: 0.8433 r:0.4555
ro_en Dev loss: 0.3886 r:0.8120
et_en Dev loss: 0.4847 r:0.6602
si_en Dev loss: 0.9541 r:0.5442
ne_en Dev loss: 0.5629 r:0.7262
ru_en Dev loss: 0.5460 r:0.7076
Current avg r:0.5859 Best avg r: 0.6305
06:59:16,2 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:59,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:42,336 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1950
en_de Dev loss: 0.8889 r:0.2016
en_zh Dev loss: 0.7721 r:0.4631
ro_en Dev loss: 0.3428 r:0.8219
et_en Dev loss: 0.5072 r:0.6801
si_en Dev loss: 0.7353 r:0.5721
ne_en Dev loss: 0.4378 r:0.7347
ru_en Dev loss: 0.4364 r:0.7296
Current avg r:0.6005 Best avg r: 0.6305
07:07:51,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:09:34,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:11:17,951 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1934
en_de Dev loss: 0.9290 r:0.1905
en_zh Dev loss: 0.7952 r:0.4589
ro_en Dev loss: 0.3322 r:0.8188
et_en Dev loss: 0.4656 r:0.6755
si_en Dev loss: 0.7732 r:0.5648
ne_en Dev loss: 0.4479 r:0.7332
ru_en Dev loss: 0.4573 r:0.7308
Current avg r:0.5961 Best avg r: 0.6305
07:16:26,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:18:10,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:19:53,365 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1798
en_de Dev loss: 0.9251 r:0.2087
en_zh Dev loss: 0.8534 r:0.4560
ro_en Dev loss: 0.3792 r:0.8169
et_en Dev loss: 0.5042 r:0.6681
si_en Dev loss: 0.8493 r:0.5601
ne_en Dev loss: 0.5148 r:0.7269
ru_en Dev loss: 0.5088 r:0.7301
Current avg r:0.5952 Best avg r: 0.6305
07:25:02,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:26:45,727 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:28:29,39 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1875
en_de Dev loss: 0.8834 r:0.2128
en_zh Dev loss: 0.7850 r:0.4547
ro_en Dev loss: 0.3646 r:0.8163
et_en Dev loss: 0.4721 r:0.6673
si_en Dev loss: 0.8704 r:0.5569
ne_en Dev loss: 0.5480 r:0.7270
ru_en Dev loss: 0.4996 r:0.7216
Current avg r:0.5938 Best avg r: 0.6305
07:33:37,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:35:21,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:05,115 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1919
en_de Dev loss: 0.9434 r:0.1999
en_zh Dev loss: 0.8425 r:0.4611
ro_en Dev loss: 0.3657 r:0.8194
et_en Dev loss: 0.5085 r:0.6718
si_en Dev loss: 0.8179 r:0.5683
ne_en Dev loss: 0.4836 r:0.7369
ru_en Dev loss: 0.4639 r:0.7433
Current avg r:0.6001 Best avg r: 0.6305
07:42:14,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:43:57,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:41,61 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1873
en_de Dev loss: 0.8991 r:0.1869
en_zh Dev loss: 0.8023 r:0.4400
ro_en Dev loss: 0.3500 r:0.8144
et_en Dev loss: 0.4432 r:0.6664
si_en Dev loss: 0.8168 r:0.5543
ne_en Dev loss: 0.5123 r:0.7293
ru_en Dev loss: 0.4820 r:0.7163
Current avg r:0.5868 Best avg r: 0.6305
07:50:49,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:52:33,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:54:16,580 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1863
en_de Dev loss: 0.9047 r:0.2099
en_zh Dev loss: 0.8123 r:0.4527
ro_en Dev loss: 0.3686 r:0.8108
et_en Dev loss: 0.4884 r:0.6714
si_en Dev loss: 0.8133 r:0.5617
ne_en Dev loss: 0.5045 r:0.7279
ru_en Dev loss: 0.5016 r:0.7200
Current avg r:0.5935 Best avg r: 0.6305
07:59:26,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:01:09,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:53,27 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1756
en_de Dev loss: 0.8780 r:0.2234
en_zh Dev loss: 0.7814 r:0.4537
ro_en Dev loss: 0.3503 r:0.8137
et_en Dev loss: 0.4907 r:0.6738
si_en Dev loss: 0.7428 r:0.5679
ne_en Dev loss: 0.4813 r:0.7313
ru_en Dev loss: 0.4419 r:0.7361
Current avg r:0.6000 Best avg r: 0.6305
08:08:01,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:45,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:11:28,507 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1711
en_de Dev loss: 0.9072 r:0.2105
en_zh Dev loss: 0.8314 r:0.4527
ro_en Dev loss: 0.4188 r:0.8116
et_en Dev loss: 0.4932 r:0.6616
si_en Dev loss: 0.9359 r:0.5659
ne_en Dev loss: 0.5842 r:0.7331
ru_en Dev loss: 0.5514 r:0.7139
Current avg r:0.5927 Best avg r: 0.6305
08:16:37,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:18:20,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:20:03,277 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1610
en_de Dev loss: 0.9258 r:0.2031
en_zh Dev loss: 0.9096 r:0.4210
ro_en Dev loss: 0.4200 r:0.8045
et_en Dev loss: 0.5025 r:0.6600
si_en Dev loss: 0.8981 r:0.5551
ne_en Dev loss: 0.5493 r:0.7298
ru_en Dev loss: 0.5443 r:0.7185
Current avg r:0.5846 Best avg r: 0.6305
08:25:12,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:55,402 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:28:38,567 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1704
en_de Dev loss: 0.9019 r:0.2030
en_zh Dev loss: 0.8451 r:0.4367
ro_en Dev loss: 0.3886 r:0.8068
et_en Dev loss: 0.5003 r:0.6574
si_en Dev loss: 0.8688 r:0.5497
ne_en Dev loss: 0.5299 r:0.7262
ru_en Dev loss: 0.4716 r:0.7212
Current avg r:0.5859 Best avg r: 0.6305
08:33:47,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:31,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:37:15,101 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1713
en_de Dev loss: 0.9112 r:0.2089
en_zh Dev loss: 0.8483 r:0.4485
ro_en Dev loss: 0.3846 r:0.8132
et_en Dev loss: 0.4835 r:0.6721
si_en Dev loss: 0.8752 r:0.5594
ne_en Dev loss: 0.5259 r:0.7356
ru_en Dev loss: 0.5028 r:0.7314
Current avg r:0.5956 Best avg r: 0.6305
08:42:25,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:44:09,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:45:53,6 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1708
en_de Dev loss: 0.9184 r:0.1771
en_zh Dev loss: 0.8162 r:0.4398
ro_en Dev loss: 0.3882 r:0.8105
et_en Dev loss: 0.4508 r:0.6752
si_en Dev loss: 0.8718 r:0.5626
ne_en Dev loss: 0.5445 r:0.7335
ru_en Dev loss: 0.4925 r:0.7308
Current avg r:0.5899 Best avg r: 0.6305
08:51:02,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:52:46,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:29,455 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1611
en_de Dev loss: 0.9329 r:0.1892
en_zh Dev loss: 0.8423 r:0.4415
ro_en Dev loss: 0.4223 r:0.8105
et_en Dev loss: 0.5192 r:0.6645
si_en Dev loss: 0.8811 r:0.5553
ne_en Dev loss: 0.5492 r:0.7218
ru_en Dev loss: 0.5096 r:0.7289
Current avg r:0.5874 Best avg r: 0.6305
08:59:38,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:21,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:05,30 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1705
en_de Dev loss: 0.9260 r:0.1921
en_zh Dev loss: 0.8035 r:0.4638
ro_en Dev loss: 0.3811 r:0.8138
et_en Dev loss: 0.5347 r:0.6744
si_en Dev loss: 0.7549 r:0.5692
ne_en Dev loss: 0.4770 r:0.7237
ru_en Dev loss: 0.4275 r:0.7446
Current avg r:0.5974 Best avg r: 0.6305
09:08:13,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:57,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:40,619 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1673
en_de Dev loss: 0.9230 r:0.1920
en_zh Dev loss: 0.7866 r:0.4523
ro_en Dev loss: 0.3730 r:0.8165
et_en Dev loss: 0.4544 r:0.6744
si_en Dev loss: 0.8931 r:0.5614
ne_en Dev loss: 0.5839 r:0.7297
ru_en Dev loss: 0.4352 r:0.7492
Current avg r:0.5965 Best avg r: 0.6305
09:16:49,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:32,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:20:16,107 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1691
en_de Dev loss: 0.8938 r:0.1926
en_zh Dev loss: 0.7992 r:0.4537
ro_en Dev loss: 0.3662 r:0.8164
et_en Dev loss: 0.4738 r:0.6692
si_en Dev loss: 0.8637 r:0.5600
ne_en Dev loss: 0.5447 r:0.7292
ru_en Dev loss: 0.4795 r:0.7245
Current avg r:0.5922 Best avg r: 0.6305
09:25:25,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:27:08,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:28:51,788 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1572
en_de Dev loss: 0.9160 r:0.2033
en_zh Dev loss: 0.8312 r:0.4510
ro_en Dev loss: 0.3646 r:0.8162
et_en Dev loss: 0.4871 r:0.6750
si_en Dev loss: 0.8106 r:0.5703
ne_en Dev loss: 0.5363 r:0.7274
ru_en Dev loss: 0.4731 r:0.7357
Current avg r:0.5970 Best avg r: 0.6305
09:34:00,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:43,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:37:27,311 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1635
en_de Dev loss: 0.9042 r:0.1879
en_zh Dev loss: 0.8223 r:0.4496
ro_en Dev loss: 0.3825 r:0.8154
et_en Dev loss: 0.4841 r:0.6750
si_en Dev loss: 0.8360 r:0.5637
ne_en Dev loss: 0.5087 r:0.7295
ru_en Dev loss: 0.5056 r:0.7274
Current avg r:0.5926 Best avg r: 0.6305
09:42:36,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:44:19,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:46:02,897 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1584
en_de Dev loss: 0.9098 r:0.1950
en_zh Dev loss: 0.8443 r:0.4437
ro_en Dev loss: 0.3864 r:0.8124
et_en Dev loss: 0.5105 r:0.6708
si_en Dev loss: 0.9154 r:0.5529
ne_en Dev loss: 0.5659 r:0.7214
ru_en Dev loss: 0.4959 r:0.7241
Current avg r:0.5886 Best avg r: 0.6305
09:51:11,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:52:55,169 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:54:38,724 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1585
en_de Dev loss: 0.9193 r:0.1883
en_zh Dev loss: 0.8012 r:0.4571
ro_en Dev loss: 0.3691 r:0.8151
et_en Dev loss: 0.5042 r:0.6734
si_en Dev loss: 0.8816 r:0.5608
ne_en Dev loss: 0.5543 r:0.7226
ru_en Dev loss: 0.4636 r:0.7354
Current avg r:0.5932 Best avg r: 0.6305
09:59:47,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:01:30,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:13,803 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1568
en_de Dev loss: 0.9205 r:0.1798
en_zh Dev loss: 0.8006 r:0.4581
ro_en Dev loss: 0.3697 r:0.8132
et_en Dev loss: 0.4953 r:0.6684
si_en Dev loss: 0.8606 r:0.5595
ne_en Dev loss: 0.5391 r:0.7297
ru_en Dev loss: 0.4746 r:0.7391
Current avg r:0.5925 Best avg r: 0.6305
10:08:23,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:07,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:50,559 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1430
en_de Dev loss: 0.9327 r:0.1616
en_zh Dev loss: 0.8107 r:0.4464
ro_en Dev loss: 0.3612 r:0.8162
et_en Dev loss: 0.4805 r:0.6675
si_en Dev loss: 0.8774 r:0.5501
ne_en Dev loss: 0.5421 r:0.7253
ru_en Dev loss: 0.4869 r:0.7308
Current avg r:0.5854 Best avg r: 0.6305
10:16:59,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:42,626 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:25,556 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1384
en_de Dev loss: 0.9158 r:0.1727
en_zh Dev loss: 0.8208 r:0.4438
ro_en Dev loss: 0.3854 r:0.8101
et_en Dev loss: 0.4766 r:0.6673
si_en Dev loss: 0.8713 r:0.5545
ne_en Dev loss: 0.6111 r:0.7224
ru_en Dev loss: 0.4717 r:0.7299
Current avg r:0.5858 Best avg r: 0.6305
10:25:34,519 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:17,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:00,89 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1575
en_de Dev loss: 0.8995 r:0.1881
en_zh Dev loss: 0.7927 r:0.4486
ro_en Dev loss: 0.3603 r:0.8091
et_en Dev loss: 0.4784 r:0.6579
si_en Dev loss: 0.8384 r:0.5495
ne_en Dev loss: 0.5145 r:0.7215
ru_en Dev loss: 0.4656 r:0.7255
Current avg r:0.5857 Best avg r: 0.6305
