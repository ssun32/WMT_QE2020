14:37:32,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:57,865 root INFO 
id:en_de cur r: 0.0912 best r: 0.0912
14:38:10,718 root INFO 
id:en_zh cur r: 0.2097 best r: 0.2097
14:38:23,603 root INFO 
id:ro_en cur r: 0.6084 best r: 0.6084
14:38:36,511 root INFO 
id:et_en cur r: 0.5312 best r: 0.5312
14:38:49,426 root INFO 
id:si_en cur r: 0.4664 best r: 0.4664
14:39:02,344 root INFO 
id:ne_en cur r: 0.5619 best r: 0.5619
14:39:15,153 root INFO 
id:ru_en cur r: 0.5874 best r: 0.5874
14:39:15,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:45,257 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
14:40:45,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:40:45,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:40:45,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
14:40:45,279 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
14:40:45,284 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:40:45,289 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:40:58,171 root INFO Epoch 0 Global steps: 700 Train loss: 0.8831
en_de Dev loss: 0.9297 r:0.0963
en_zh Dev loss: 0.8708 r:0.2715
ro_en Dev loss: 0.5932 r:0.6214
et_en Dev loss: 0.5932 r:0.4927
si_en Dev loss: 0.7006 r:0.4337
ne_en Dev loss: 0.6102 r:0.5142
ru_en Dev loss: 0.6048 r:0.6036
Current avg r:0.4333 Best avg r: 0.4333
14:45:27,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:52,960 root INFO 
id:en_de cur r: 0.1257 best r: 0.1257
14:46:05,784 root INFO 
id:en_zh cur r: 0.2769 best r: 0.2769
14:46:18,642 root INFO 
id:ro_en cur r: 0.6525 best r: 0.6525
14:46:31,513 root INFO 
id:et_en cur r: 0.5501 best r: 0.5501
14:47:10,122 root INFO 
id:ru_en cur r: 0.6776 best r: 0.6776
14:47:10,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:40,165 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
14:48:40,172 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:48:40,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:48:40,183 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
14:48:40,188 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
14:48:40,194 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:48:40,200 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:48:53,89 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8060
en_de Dev loss: 0.8925 r:0.1194
en_zh Dev loss: 0.7517 r:0.2899
ro_en Dev loss: 0.5719 r:0.6858
et_en Dev loss: 0.5362 r:0.5699
si_en Dev loss: 0.6824 r:0.4722
ne_en Dev loss: 0.5636 r:0.5841
ru_en Dev loss: 0.5494 r:0.7003
Current avg r:0.4888 Best avg r: 0.4888
14:53:22,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:48,278 root INFO 
id:en_de cur r: 0.1260 best r: 0.1260
14:54:01,99 root INFO 
id:en_zh cur r: 0.3021 best r: 0.3021
14:54:13,955 root INFO 
id:ro_en cur r: 0.6910 best r: 0.6910
14:54:26,812 root INFO 
id:et_en cur r: 0.6356 best r: 0.6356
14:54:39,679 root INFO 
id:si_en cur r: 0.4717 best r: 0.4717
14:54:52,536 root INFO 
id:ne_en cur r: 0.6556 best r: 0.6556
14:55:05,334 root INFO 
id:ru_en cur r: 0.7089 best r: 0.7089
14:55:05,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:56:35,222 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
14:56:35,229 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:56:35,234 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:56:35,238 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
14:56:35,243 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
14:56:35,248 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:56:35,253 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:56:48,162 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7166
en_de Dev loss: 0.9393 r:0.1208
en_zh Dev loss: 0.7420 r:0.3180
ro_en Dev loss: 0.4508 r:0.7061
et_en Dev loss: 0.4551 r:0.6429
si_en Dev loss: 0.6062 r:0.5020
ne_en Dev loss: 0.4855 r:0.6443
ru_en Dev loss: 0.4303 r:0.7247
Current avg r:0.5227 Best avg r: 0.5227
15:01:17,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:43,63 root INFO 
id:en_de cur r: 0.1414 best r: 0.1414
15:01:55,882 root INFO 
id:en_zh cur r: 0.3249 best r: 0.3249
15:02:08,757 root INFO 
id:ro_en cur r: 0.7076 best r: 0.7076
15:02:34,491 root INFO 
id:si_en cur r: 0.4923 best r: 0.4923
15:03:00,242 root INFO 
id:ru_en cur r: 0.7120 best r: 0.7120
15:03:00,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:30,97 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:04:30,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:04:30,109 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:04:30,115 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:04:30,120 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:04:30,127 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:04:30,133 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:04:43,6 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6455
en_de Dev loss: 0.9959 r:0.1223
en_zh Dev loss: 0.7877 r:0.3346
ro_en Dev loss: 0.4482 r:0.7188
et_en Dev loss: 0.4097 r:0.6497
si_en Dev loss: 0.6647 r:0.5080
ne_en Dev loss: 0.4997 r:0.6347
ru_en Dev loss: 0.4622 r:0.7247
Current avg r:0.5276 Best avg r: 0.5276
15:09:12,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:38,218 root INFO 
id:en_zh cur r: 0.3772 best r: 0.3772
15:09:51,71 root INFO 
id:ro_en cur r: 0.7333 best r: 0.7333
15:10:03,939 root INFO 
id:et_en cur r: 0.6631 best r: 0.6631
15:10:16,819 root INFO 
id:si_en cur r: 0.5215 best r: 0.5215
15:10:29,709 root INFO 
id:ne_en cur r: 0.6878 best r: 0.6878
15:10:42,517 root INFO 
id:ru_en cur r: 0.7309 best r: 0.7309
15:10:42,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:12,362 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:12:12,367 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:12:12,372 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:12:12,376 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:12:12,381 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:12:12,386 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:12:12,390 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:12:25,256 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6637
en_de Dev loss: 0.9160 r:0.1642
en_zh Dev loss: 0.6952 r:0.3925
ro_en Dev loss: 0.4001 r:0.7381
et_en Dev loss: 0.3835 r:0.6802
si_en Dev loss: 0.6216 r:0.5347
ne_en Dev loss: 0.4358 r:0.6841
ru_en Dev loss: 0.3981 r:0.7436
Current avg r:0.5625 Best avg r: 0.5625
15:16:54,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:20,450 root INFO 
id:en_de cur r: 0.1624 best r: 0.1624
15:17:58,961 root INFO 
id:et_en cur r: 0.6715 best r: 0.6715
15:18:37,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:07,241 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6152
en_de Dev loss: 0.9918 r:0.1577
en_zh Dev loss: 0.7950 r:0.3862
ro_en Dev loss: 0.4432 r:0.7399
et_en Dev loss: 0.3760 r:0.6870
si_en Dev loss: 0.7719 r:0.5167
ne_en Dev loss: 0.5008 r:0.6610
ru_en Dev loss: 0.5007 r:0.7231
Current avg r:0.5531 Best avg r: 0.5625
15:24:36,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:01,968 root INFO 
id:en_de cur r: 0.1782 best r: 0.1782
15:25:14,797 root INFO 
id:en_zh cur r: 0.3910 best r: 0.3910
15:25:27,656 root INFO 
id:ro_en cur r: 0.7472 best r: 0.7472
15:25:53,375 root INFO 
id:si_en cur r: 0.5250 best r: 0.5250
15:26:06,238 root INFO 
id:ne_en cur r: 0.7120 best r: 0.7120
15:26:19,50 root INFO 
id:ru_en cur r: 0.7328 best r: 0.7328
15:26:19,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:48,877 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:27:48,884 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:27:48,888 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:27:48,893 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:27:48,899 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:27:48,906 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:27:48,911 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:28:01,771 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5976
en_de Dev loss: 0.9119 r:0.1858
en_zh Dev loss: 0.6922 r:0.4183
ro_en Dev loss: 0.3760 r:0.7557
et_en Dev loss: 0.3705 r:0.6898
si_en Dev loss: 0.6593 r:0.5415
ne_en Dev loss: 0.4025 r:0.7058
ru_en Dev loss: 0.4044 r:0.7517
Current avg r:0.5784 Best avg r: 0.5784
15:32:30,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:09,365 root INFO 
id:ro_en cur r: 0.7480 best r: 0.7480
15:34:00,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:31,62 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6174
en_de Dev loss: 0.9338 r:0.1905
en_zh Dev loss: 0.7584 r:0.4201
ro_en Dev loss: 0.4102 r:0.7703
et_en Dev loss: 0.3916 r:0.6794
si_en Dev loss: 0.8322 r:0.5146
ne_en Dev loss: 0.4879 r:0.6722
ru_en Dev loss: 0.5271 r:0.7162
Current avg r:0.5662 Best avg r: 0.5784
15:39:59,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:25,589 root INFO 
id:en_de cur r: 0.1793 best r: 0.1793
15:40:38,410 root INFO 
id:en_zh cur r: 0.4141 best r: 0.4141
15:40:51,270 root INFO 
id:ro_en cur r: 0.7645 best r: 0.7645
15:41:17,67 root INFO 
id:si_en cur r: 0.5391 best r: 0.5391
15:41:42,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:12,916 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:43:12,923 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:43:12,927 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:43:12,932 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:43:12,937 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:43:12,942 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:43:12,947 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:43:25,831 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5900
en_de Dev loss: 0.8816 r:0.1965
en_zh Dev loss: 0.6778 r:0.4341
ro_en Dev loss: 0.3661 r:0.7787
et_en Dev loss: 0.3734 r:0.6885
si_en Dev loss: 0.6685 r:0.5487
ne_en Dev loss: 0.4087 r:0.7015
ru_en Dev loss: 0.4092 r:0.7454
Current avg r:0.5848 Best avg r: 0.5848
15:47:54,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:20,577 root INFO 
id:en_de cur r: 0.1949 best r: 0.1949
15:48:46,250 root INFO 
id:ro_en cur r: 0.7705 best r: 0.7705
15:49:12,29 root INFO 
id:si_en cur r: 0.5423 best r: 0.5423
15:49:37,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:07,732 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5607
en_de Dev loss: 0.8997 r:0.1957
en_zh Dev loss: 0.7461 r:0.4120
ro_en Dev loss: 0.3605 r:0.7833
et_en Dev loss: 0.3721 r:0.6948
si_en Dev loss: 0.7372 r:0.5500
ne_en Dev loss: 0.4496 r:0.7018
ru_en Dev loss: 0.4562 r:0.7339
Current avg r:0.5817 Best avg r: 0.5848
15:55:36,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:02,495 root INFO 
id:en_de cur r: 0.2133 best r: 0.2133
15:56:28,254 root INFO 
id:ro_en cur r: 0.7836 best r: 0.7836
15:56:41,156 root INFO 
id:et_en cur r: 0.6944 best r: 0.6944
15:56:54,23 root INFO 
id:si_en cur r: 0.5683 best r: 0.5683
15:57:06,889 root INFO 
id:ne_en cur r: 0.7285 best r: 0.7285
15:57:19,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:49,515 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
15:58:49,520 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:58:49,525 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:58:49,530 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
15:58:49,535 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
15:58:49,540 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:58:49,546 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:59:02,419 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5442
en_de Dev loss: 0.9113 r:0.2038
en_zh Dev loss: 0.7384 r:0.4191
ro_en Dev loss: 0.3455 r:0.7866
et_en Dev loss: 0.3530 r:0.7085
si_en Dev loss: 0.6375 r:0.5759
ne_en Dev loss: 0.4096 r:0.7160
ru_en Dev loss: 0.4454 r:0.7388
Current avg r:0.5927 Best avg r: 0.5927
16:03:32,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:58,657 root INFO 
id:en_zh cur r: 0.4302 best r: 0.4302
16:04:11,557 root INFO 
id:ro_en cur r: 0.7943 best r: 0.7943
16:04:37,347 root INFO 
id:si_en cur r: 0.5796 best r: 0.5796
16:04:50,252 root INFO 
id:ne_en cur r: 0.7336 best r: 0.7336
16:05:03,94 root INFO 
id:ru_en cur r: 0.7377 best r: 0.7377
16:05:03,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:33,223 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
16:06:33,228 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:06:33,234 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:06:33,239 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
16:06:33,243 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
16:06:33,248 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:06:33,253 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:06:46,144 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5228
en_de Dev loss: 0.8980 r:0.1995
en_zh Dev loss: 0.7153 r:0.4361
ro_en Dev loss: 0.3385 r:0.7952
et_en Dev loss: 0.3542 r:0.7066
si_en Dev loss: 0.6365 r:0.5808
ne_en Dev loss: 0.3997 r:0.7258
ru_en Dev loss: 0.4250 r:0.7514
Current avg r:0.5993 Best avg r: 0.5993
16:11:15,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:40,769 root INFO 
id:en_de cur r: 0.2185 best r: 0.2185
16:12:58,3 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:28,78 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5656
en_de Dev loss: 0.9473 r:0.2297
en_zh Dev loss: 0.8425 r:0.4211
ro_en Dev loss: 0.4703 r:0.7806
et_en Dev loss: 0.4295 r:0.6895
si_en Dev loss: 0.8980 r:0.5475
ne_en Dev loss: 0.5998 r:0.6957
ru_en Dev loss: 0.5656 r:0.7227
Current avg r:0.5838 Best avg r: 0.5993
16:18:57,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:35,910 root INFO 
id:ro_en cur r: 0.7994 best r: 0.7994
16:19:48,825 root INFO 
id:et_en cur r: 0.7045 best r: 0.7045
16:20:01,727 root INFO 
id:si_en cur r: 0.5870 best r: 0.5870
16:20:14,625 root INFO 
id:ne_en cur r: 0.7447 best r: 0.7447
16:20:27,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:57,555 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
16:21:57,562 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:21:57,567 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:21:57,572 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
16:21:57,577 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
16:21:57,581 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:21:57,587 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:22:10,485 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5432
en_de Dev loss: 0.8476 r:0.2262
en_zh Dev loss: 0.6844 r:0.4392
ro_en Dev loss: 0.3209 r:0.8024
et_en Dev loss: 0.3505 r:0.7154
si_en Dev loss: 0.6567 r:0.5814
ne_en Dev loss: 0.3715 r:0.7418
ru_en Dev loss: 0.4517 r:0.7334
Current avg r:0.6057 Best avg r: 0.6057
16:26:39,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:43,934 root INFO 
id:si_en cur r: 0.5882 best r: 0.5882
16:28:09,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:39,839 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
16:29:39,845 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:29:39,850 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:29:39,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
16:29:39,860 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
16:29:39,865 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:29:39,871 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:29:52,789 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5119
en_de Dev loss: 0.8464 r:0.2289
en_zh Dev loss: 0.6884 r:0.4394
ro_en Dev loss: 0.3283 r:0.8033
et_en Dev loss: 0.3518 r:0.7110
si_en Dev loss: 0.6039 r:0.5916
ne_en Dev loss: 0.3957 r:0.7387
ru_en Dev loss: 0.4239 r:0.7385
Current avg r:0.6073 Best avg r: 0.6073
16:34:22,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:00,570 root INFO 
id:ro_en cur r: 0.8051 best r: 0.8051
16:35:26,311 root INFO 
id:si_en cur r: 0.5950 best r: 0.5950
16:35:39,226 root INFO 
id:ne_en cur r: 0.7478 best r: 0.7478
16:35:52,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:22,167 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
16:37:22,175 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:37:22,180 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:37:22,185 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
16:37:22,190 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
16:37:22,195 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:37:22,200 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:37:35,106 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5312
en_de Dev loss: 0.8614 r:0.2276
en_zh Dev loss: 0.7053 r:0.4404
ro_en Dev loss: 0.3185 r:0.8069
et_en Dev loss: 0.3529 r:0.7132
si_en Dev loss: 0.6319 r:0.5924
ne_en Dev loss: 0.4135 r:0.7407
ru_en Dev loss: 0.4231 r:0.7483
Current avg r:0.6099 Best avg r: 0.6099
16:42:04,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:42,784 root INFO 
id:ro_en cur r: 0.8052 best r: 0.8052
16:43:34,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:04,20 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5264
en_de Dev loss: 0.8617 r:0.2352
en_zh Dev loss: 0.7231 r:0.4412
ro_en Dev loss: 0.3245 r:0.8097
et_en Dev loss: 0.3710 r:0.7068
si_en Dev loss: 0.6205 r:0.5910
ne_en Dev loss: 0.4898 r:0.7429
ru_en Dev loss: 0.4519 r:0.7339
Current avg r:0.6087 Best avg r: 0.6099
16:49:33,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:58,883 root INFO 
id:en_de cur r: 0.2319 best r: 0.2319
16:51:15,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:45,744 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5133
en_de Dev loss: 0.8881 r:0.2348
en_zh Dev loss: 0.7362 r:0.4369
ro_en Dev loss: 0.3445 r:0.8010
et_en Dev loss: 0.3767 r:0.7013
si_en Dev loss: 0.8184 r:0.5674
ne_en Dev loss: 0.5300 r:0.7307
ru_en Dev loss: 0.4756 r:0.7322
Current avg r:0.6006 Best avg r: 0.6099
16:57:14,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:40,399 root INFO 
id:en_de cur r: 0.2452 best r: 0.2452
16:57:53,215 root INFO 
id:en_zh cur r: 0.4397 best r: 0.4397
16:58:06,66 root INFO 
id:ro_en cur r: 0.8118 best r: 0.8118
16:58:18,930 root INFO 
id:et_en cur r: 0.7051 best r: 0.7051
16:58:44,696 root INFO 
id:ne_en cur r: 0.7505 best r: 0.7505
16:58:57,533 root INFO 
id:ru_en cur r: 0.7398 best r: 0.7398
16:58:57,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:27,641 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
17:00:27,647 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:00:27,652 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:00:27,657 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
17:00:27,662 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
17:00:27,666 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:00:27,671 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:00:40,554 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4985
en_de Dev loss: 0.8797 r:0.2334
en_zh Dev loss: 0.7047 r:0.4559
ro_en Dev loss: 0.3174 r:0.8119
et_en Dev loss: 0.3550 r:0.7106
si_en Dev loss: 0.6601 r:0.5924
ne_en Dev loss: 0.4078 r:0.7499
ru_en Dev loss: 0.3934 r:0.7571
Current avg r:0.6159 Best avg r: 0.6159
17:05:09,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:35,90 root INFO 
id:en_de cur r: 0.2453 best r: 0.2453
17:05:47,910 root INFO 
id:en_zh cur r: 0.4665 best r: 0.4665
17:06:00,769 root INFO 
id:ro_en cur r: 0.8196 best r: 0.8196
17:06:39,359 root INFO 
id:ne_en cur r: 0.7604 best r: 0.7604
17:06:52,166 root INFO 
id:ru_en cur r: 0.7415 best r: 0.7415
17:06:52,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:22,15 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
17:08:22,22 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:08:22,27 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:08:22,32 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
17:08:22,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
17:08:22,42 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:08:22,47 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:08:34,893 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4833
en_de Dev loss: 0.8602 r:0.2423
en_zh Dev loss: 0.6866 r:0.4625
ro_en Dev loss: 0.3272 r:0.8123
et_en Dev loss: 0.3545 r:0.7155
si_en Dev loss: 0.7284 r:0.5840
ne_en Dev loss: 0.3819 r:0.7607
ru_en Dev loss: 0.4074 r:0.7542
Current avg r:0.6188 Best avg r: 0.6188
17:13:03,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:55,149 root INFO 
id:et_en cur r: 0.7057 best r: 0.7057
17:14:08,16 root INFO 
id:si_en cur r: 0.5974 best r: 0.5974
17:14:33,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:03,615 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4910
en_de Dev loss: 0.9609 r:0.2433
en_zh Dev loss: 0.8467 r:0.4536
ro_en Dev loss: 0.4286 r:0.8114
et_en Dev loss: 0.4006 r:0.7116
si_en Dev loss: 0.8677 r:0.5878
ne_en Dev loss: 0.5038 r:0.7570
ru_en Dev loss: 0.5532 r:0.7462
Current avg r:0.6158 Best avg r: 0.6188
17:20:32,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:58,197 root INFO 
id:en_zh cur r: 0.4689 best r: 0.4689
17:21:23,898 root INFO 
id:et_en cur r: 0.7108 best r: 0.7108
17:21:36,761 root INFO 
id:si_en cur r: 0.6077 best r: 0.6077
17:22:02,457 root INFO 
id:ru_en cur r: 0.7443 best r: 0.7443
17:22:02,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:32,398 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
17:23:32,406 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:23:32,410 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:23:32,415 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
17:23:32,420 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
17:23:32,425 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:23:32,430 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:23:45,330 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5026
en_de Dev loss: 0.8572 r:0.2386
en_zh Dev loss: 0.6632 r:0.4689
ro_en Dev loss: 0.3043 r:0.8154
et_en Dev loss: 0.3797 r:0.7161
si_en Dev loss: 0.6387 r:0.5994
ne_en Dev loss: 0.3613 r:0.7614
ru_en Dev loss: 0.3977 r:0.7561
Current avg r:0.6223 Best avg r: 0.6223
17:28:15,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:29:45,659 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:15,771 root INFO Epoch 2 Global steps: 16100 Train loss: 0.5191
en_de Dev loss: 0.8804 r:0.2307
en_zh Dev loss: 0.7315 r:0.4579
ro_en Dev loss: 0.3868 r:0.8029
et_en Dev loss: 0.3827 r:0.7014
si_en Dev loss: 0.8235 r:0.5730
ne_en Dev loss: 0.5000 r:0.7379
ru_en Dev loss: 0.5652 r:0.7153
Current avg r:0.6027 Best avg r: 0.6223
17:35:45,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:10,711 root INFO 
id:en_de cur r: 0.2459 best r: 0.2459
17:37:27,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:57,919 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4400
en_de Dev loss: 0.8549 r:0.2386
en_zh Dev loss: 0.6986 r:0.4576
ro_en Dev loss: 0.3081 r:0.8173
et_en Dev loss: 0.3649 r:0.7146
si_en Dev loss: 0.6059 r:0.5987
ne_en Dev loss: 0.3466 r:0.7616
ru_en Dev loss: 0.4079 r:0.7485
Current avg r:0.6196 Best avg r: 0.6223
17:43:26,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:52,655 root INFO 
id:en_de cur r: 0.2507 best r: 0.2507
17:44:56,959 root INFO 
id:ne_en cur r: 0.7616 best r: 0.7616
17:45:09,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:39,899 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4789
en_de Dev loss: 0.8606 r:0.2644
en_zh Dev loss: 0.7173 r:0.4630
ro_en Dev loss: 0.3417 r:0.8144
et_en Dev loss: 0.3658 r:0.7100
si_en Dev loss: 0.7402 r:0.5863
ne_en Dev loss: 0.4051 r:0.7613
ru_en Dev loss: 0.5076 r:0.7268
Current avg r:0.6180 Best avg r: 0.6223
17:51:09,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:34,680 root INFO 
id:en_zh cur r: 0.4731 best r: 0.4731
17:52:26,96 root INFO 
id:ne_en cur r: 0.7639 best r: 0.7639
17:52:38,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:08,703 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
17:54:08,710 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:54:08,716 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:54:08,721 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
17:54:08,726 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
17:54:08,730 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:54:08,735 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:54:21,584 root INFO Epoch 2 Global steps: 18200 Train loss: 0.4744
en_de Dev loss: 0.8381 r:0.2600
en_zh Dev loss: 0.6596 r:0.4745
ro_en Dev loss: 0.3130 r:0.8153
et_en Dev loss: 0.3777 r:0.7060
si_en Dev loss: 0.6209 r:0.5901
ne_en Dev loss: 0.3569 r:0.7656
ru_en Dev loss: 0.4041 r:0.7451
Current avg r:0.6224 Best avg r: 0.6224
17:58:50,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:41,804 root INFO 
id:et_en cur r: 0.7174 best r: 0.7174
17:59:54,692 root INFO 
id:si_en cur r: 0.6099 best r: 0.6099
18:00:07,595 root INFO 
id:ne_en cur r: 0.7640 best r: 0.7640
18:00:20,443 root INFO 
id:ru_en cur r: 0.7520 best r: 0.7520
18:00:20,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:50,460 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
18:01:50,466 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:01:50,473 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:01:50,478 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
18:01:50,484 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
18:01:50,491 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:01:50,496 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:02:03,345 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4738
en_de Dev loss: 0.8387 r:0.2556
en_zh Dev loss: 0.6633 r:0.4691
ro_en Dev loss: 0.3108 r:0.8164
et_en Dev loss: 0.3473 r:0.7199
si_en Dev loss: 0.6032 r:0.6099
ne_en Dev loss: 0.3505 r:0.7686
ru_en Dev loss: 0.3772 r:0.7563
Current avg r:0.6280 Best avg r: 0.6280
18:06:32,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:02,113 root INFO 
id:ru_en cur r: 0.7520 best r: 0.7520
18:08:02,114 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:32,204 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4985
en_de Dev loss: 0.8691 r:0.2599
en_zh Dev loss: 0.7120 r:0.4665
ro_en Dev loss: 0.3284 r:0.8143
et_en Dev loss: 0.3664 r:0.7107
si_en Dev loss: 0.7048 r:0.5957
ne_en Dev loss: 0.3467 r:0.7630
ru_en Dev loss: 0.4107 r:0.7555
Current avg r:0.6237 Best avg r: 0.6280
18:14:01,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:15:18,147 root INFO 
id:ne_en cur r: 0.7656 best r: 0.7656
18:15:30,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:00,927 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4442
en_de Dev loss: 0.8401 r:0.2517
en_zh Dev loss: 0.6631 r:0.4772
ro_en Dev loss: 0.3072 r:0.8162
et_en Dev loss: 0.3632 r:0.7121
si_en Dev loss: 0.6510 r:0.5974
ne_en Dev loss: 0.3765 r:0.7700
ru_en Dev loss: 0.3964 r:0.7563
Current avg r:0.6259 Best avg r: 0.6280
18:21:30,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:55,728 root INFO 
id:en_zh cur r: 0.4742 best r: 0.4742
18:22:59,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:29,851 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4536
en_de Dev loss: 0.8413 r:0.2480
en_zh Dev loss: 0.6896 r:0.4741
ro_en Dev loss: 0.3298 r:0.8162
et_en Dev loss: 0.3722 r:0.7086
si_en Dev loss: 0.7264 r:0.5936
ne_en Dev loss: 0.4197 r:0.7592
ru_en Dev loss: 0.4298 r:0.7500
Current avg r:0.6214 Best avg r: 0.6280
18:28:58,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:29:37,216 root INFO 
id:ro_en cur r: 0.8205 best r: 0.8205
18:30:28,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:58,751 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4410
en_de Dev loss: 0.8530 r:0.2456
en_zh Dev loss: 0.7222 r:0.4558
ro_en Dev loss: 0.3071 r:0.8197
et_en Dev loss: 0.3697 r:0.7132
si_en Dev loss: 0.6349 r:0.5990
ne_en Dev loss: 0.3519 r:0.7644
ru_en Dev loss: 0.4215 r:0.7502
Current avg r:0.6211 Best avg r: 0.6280
18:36:27,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:53,258 root INFO 
id:en_de cur r: 0.2559 best r: 0.2559
18:37:06,121 root INFO 
id:en_zh cur r: 0.4749 best r: 0.4749
18:37:19,11 root INFO 
id:ro_en cur r: 0.8243 best r: 0.8243
18:37:57,707 root INFO 
id:ne_en cur r: 0.7658 best r: 0.7658
18:38:10,555 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:39:40,677 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4672
en_de Dev loss: 0.8432 r:0.2472
en_zh Dev loss: 0.7112 r:0.4680
ro_en Dev loss: 0.3067 r:0.8208
et_en Dev loss: 0.3564 r:0.7119
si_en Dev loss: 0.7258 r:0.5981
ne_en Dev loss: 0.4184 r:0.7675
ru_en Dev loss: 0.4487 r:0.7437
Current avg r:0.6225 Best avg r: 0.6280
18:44:09,434 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:35,97 root INFO 
id:en_zh cur r: 0.4756 best r: 0.4756
18:45:39,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:09,496 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4651
en_de Dev loss: 0.8701 r:0.2555
en_zh Dev loss: 0.7749 r:0.4688
ro_en Dev loss: 0.4043 r:0.8107
et_en Dev loss: 0.4144 r:0.6996
si_en Dev loss: 0.8024 r:0.5852
ne_en Dev loss: 0.4790 r:0.7593
ru_en Dev loss: 0.5181 r:0.7338
Current avg r:0.6161 Best avg r: 0.6280
18:51:38,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:03,795 root INFO 
id:en_de cur r: 0.2566 best r: 0.2566
18:52:29,482 root INFO 
id:ro_en cur r: 0.8283 best r: 0.8283
18:52:55,205 root INFO 
id:si_en cur r: 0.6163 best r: 0.6163
18:53:08,73 root INFO 
id:ne_en cur r: 0.7746 best r: 0.7746
18:53:20,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:50,803 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_de.lang_agnost_mlp.dev.best.scores
18:54:50,809 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:54:50,815 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:54:50,820 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/et_en.lang_agnost_mlp.dev.best.scores
18:54:50,825 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/si_en.lang_agnost_mlp.dev.best.scores
18:54:50,830 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:54:50,836 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:55:03,741 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4531
en_de Dev loss: 0.8366 r:0.2588
en_zh Dev loss: 0.6931 r:0.4671
ro_en Dev loss: 0.2993 r:0.8253
et_en Dev loss: 0.3826 r:0.7223
si_en Dev loss: 0.5741 r:0.6109
ne_en Dev loss: 0.3255 r:0.7750
ru_en Dev loss: 0.3953 r:0.7479
Current avg r:0.6296 Best avg r: 0.6296
18:59:33,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:59,731 root INFO 
id:en_zh cur r: 0.4769 best r: 0.4769
19:00:38,421 root INFO 
id:si_en cur r: 0.6172 best r: 0.6172
19:01:04,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:34,243 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4026
en_de Dev loss: 0.8385 r:0.2519
en_zh Dev loss: 0.6962 r:0.4718
ro_en Dev loss: 0.3132 r:0.8263
et_en Dev loss: 0.3834 r:0.7191
si_en Dev loss: 0.6578 r:0.6145
ne_en Dev loss: 0.3608 r:0.7695
ru_en Dev loss: 0.4424 r:0.7407
Current avg r:0.6277 Best avg r: 0.6296
19:07:03,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:08:33,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:03,34 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4175
en_de Dev loss: 0.8455 r:0.2352
en_zh Dev loss: 0.7140 r:0.4616
ro_en Dev loss: 0.3236 r:0.8213
et_en Dev loss: 0.3976 r:0.7005
si_en Dev loss: 0.6663 r:0.6082
ne_en Dev loss: 0.4754 r:0.7678
ru_en Dev loss: 0.4394 r:0.7345
Current avg r:0.6184 Best avg r: 0.6296
19:14:32,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:57,934 root INFO 
id:en_de cur r: 0.2589 best r: 0.2589
19:15:23,606 root INFO 
id:ro_en cur r: 0.8305 best r: 0.8305
19:16:14,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:44,837 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4163
en_de Dev loss: 0.8646 r:0.2521
en_zh Dev loss: 0.7467 r:0.4658
ro_en Dev loss: 0.3123 r:0.8284
et_en Dev loss: 0.3725 r:0.7122
si_en Dev loss: 0.6661 r:0.6128
ne_en Dev loss: 0.4356 r:0.7645
ru_en Dev loss: 0.5056 r:0.7206
Current avg r:0.6223 Best avg r: 0.6296
19:22:13,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:43,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:13,264 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4241
en_de Dev loss: 0.8584 r:0.2388
en_zh Dev loss: 0.7930 r:0.4500
ro_en Dev loss: 0.3227 r:0.8252
et_en Dev loss: 0.3793 r:0.7103
si_en Dev loss: 0.7521 r:0.6033
ne_en Dev loss: 0.4525 r:0.7609
ru_en Dev loss: 0.4900 r:0.7201
Current avg r:0.6155 Best avg r: 0.6296
19:29:41,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:31:11,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:41,661 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4257
en_de Dev loss: 0.8704 r:0.2410
en_zh Dev loss: 0.7650 r:0.4626
ro_en Dev loss: 0.3256 r:0.8258
et_en Dev loss: 0.3909 r:0.7048
si_en Dev loss: 0.7492 r:0.6098
ne_en Dev loss: 0.4130 r:0.7596
ru_en Dev loss: 0.5212 r:0.7141
Current avg r:0.6168 Best avg r: 0.6296
19:37:10,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:40,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:10,622 root INFO Epoch 3 Global steps: 28000 Train loss: 0.4262
en_de Dev loss: 0.8700 r:0.2292
en_zh Dev loss: 0.7154 r:0.4657
ro_en Dev loss: 0.3117 r:0.8236
et_en Dev loss: 0.3806 r:0.7127
si_en Dev loss: 0.6545 r:0.6171
ne_en Dev loss: 0.3771 r:0.7627
ru_en Dev loss: 0.4674 r:0.7336
Current avg r:0.6207 Best avg r: 0.6296
19:44:39,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:09,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:39,375 root INFO Epoch 3 Global steps: 28700 Train loss: 0.4192
en_de Dev loss: 0.8790 r:0.2286
en_zh Dev loss: 0.7631 r:0.4580
ro_en Dev loss: 0.3495 r:0.8216
et_en Dev loss: 0.3819 r:0.7106
si_en Dev loss: 0.7722 r:0.6027
ne_en Dev loss: 0.5287 r:0.7556
ru_en Dev loss: 0.4790 r:0.7260
Current avg r:0.6147 Best avg r: 0.6296
19:52:08,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:34,257 root INFO 
id:en_de cur r: 0.2627 best r: 0.2627
19:53:51,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:21,535 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4116
en_de Dev loss: 0.8632 r:0.2371
en_zh Dev loss: 0.7465 r:0.4572
ro_en Dev loss: 0.3759 r:0.8143
et_en Dev loss: 0.3907 r:0.6983
si_en Dev loss: 0.7649 r:0.5956
ne_en Dev loss: 0.5066 r:0.7516
ru_en Dev loss: 0.5657 r:0.6802
Current avg r:0.6049 Best avg r: 0.6296
19:59:50,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:16,58 root INFO 
id:en_de cur r: 0.2645 best r: 0.2645
20:00:28,884 root INFO 
id:en_zh cur r: 0.4950 best r: 0.4950
20:01:33,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:03,289 root INFO Epoch 3 Global steps: 30100 Train loss: 0.4360
en_de Dev loss: 0.8394 r:0.2474
en_zh Dev loss: 0.6737 r:0.4826
ro_en Dev loss: 0.3064 r:0.8229
et_en Dev loss: 0.3755 r:0.7055
si_en Dev loss: 0.6290 r:0.6097
ne_en Dev loss: 0.3511 r:0.7647
ru_en Dev loss: 0.4082 r:0.7404
Current avg r:0.6247 Best avg r: 0.6296
20:07:31,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:07:57,670 root INFO 
id:en_de cur r: 0.2804 best r: 0.2804
20:09:14,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:44,614 root INFO Epoch 3 Global steps: 30800 Train loss: 0.3917
en_de Dev loss: 0.8502 r:0.2369
en_zh Dev loss: 0.7322 r:0.4672
ro_en Dev loss: 0.3194 r:0.8230
et_en Dev loss: 0.3701 r:0.7067
si_en Dev loss: 0.7820 r:0.5938
ne_en Dev loss: 0.4166 r:0.7643
ru_en Dev loss: 0.4487 r:0.7279
Current avg r:0.6171 Best avg r: 0.6296
20:15:13,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:43,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:13,125 root INFO Epoch 3 Global steps: 31500 Train loss: 0.4030
en_de Dev loss: 0.8505 r:0.2551
en_zh Dev loss: 0.6963 r:0.4880
ro_en Dev loss: 0.3368 r:0.8233
et_en Dev loss: 0.3971 r:0.7117
si_en Dev loss: 0.6885 r:0.6058
ne_en Dev loss: 0.3941 r:0.7692
ru_en Dev loss: 0.4156 r:0.7504
Current avg r:0.6291 Best avg r: 0.6296
20:22:43,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:13,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:43,232 root INFO Epoch 4 Global steps: 32200 Train loss: 0.3827
en_de Dev loss: 0.8486 r:0.2167
en_zh Dev loss: 0.7640 r:0.4693
ro_en Dev loss: 0.3372 r:0.8252
et_en Dev loss: 0.3925 r:0.7046
si_en Dev loss: 0.8603 r:0.5977
ne_en Dev loss: 0.4513 r:0.7610
ru_en Dev loss: 0.4530 r:0.7393
Current avg r:0.6163 Best avg r: 0.6296
20:30:12,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:42,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:12,697 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3765
en_de Dev loss: 0.8532 r:0.2338
en_zh Dev loss: 0.7319 r:0.4591
ro_en Dev loss: 0.3159 r:0.8213
et_en Dev loss: 0.3960 r:0.6990
si_en Dev loss: 0.8535 r:0.5886
ne_en Dev loss: 0.4280 r:0.7596
ru_en Dev loss: 0.4823 r:0.7119
Current avg r:0.6105 Best avg r: 0.6296
20:37:41,486 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:11,349 root INFO 
id:ru_en cur r: 0.7532 best r: 0.7532
20:39:11,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:41,199 root INFO Epoch 4 Global steps: 33600 Train loss: 0.3808
en_de Dev loss: 0.8377 r:0.2386
en_zh Dev loss: 0.6939 r:0.4772
ro_en Dev loss: 0.3028 r:0.8268
et_en Dev loss: 0.4035 r:0.7074
si_en Dev loss: 0.6480 r:0.6171
ne_en Dev loss: 0.3620 r:0.7716
ru_en Dev loss: 0.3956 r:0.7483
Current avg r:0.6267 Best avg r: 0.6296
20:45:10,311 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:40,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:10,563 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3679
en_de Dev loss: 0.8550 r:0.2209
en_zh Dev loss: 0.7740 r:0.4599
ro_en Dev loss: 0.3515 r:0.8163
et_en Dev loss: 0.4121 r:0.6903
si_en Dev loss: 0.8126 r:0.5884
ne_en Dev loss: 0.4514 r:0.7528
ru_en Dev loss: 0.5117 r:0.7064
Current avg r:0.6050 Best avg r: 0.6296
20:52:39,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:09,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:38,818 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3733
en_de Dev loss: 0.8585 r:0.2192
en_zh Dev loss: 0.7023 r:0.4763
ro_en Dev loss: 0.3247 r:0.8267
et_en Dev loss: 0.3908 r:0.7029
si_en Dev loss: 0.6506 r:0.6078
ne_en Dev loss: 0.4062 r:0.7622
ru_en Dev loss: 0.4381 r:0.7345
Current avg r:0.6185 Best avg r: 0.6296
21:00:07,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:37,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:07,376 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3660
en_de Dev loss: 0.8442 r:0.2223
en_zh Dev loss: 0.6812 r:0.4633
ro_en Dev loss: 0.3216 r:0.8209
et_en Dev loss: 0.3762 r:0.7033
si_en Dev loss: 0.7380 r:0.6022
ne_en Dev loss: 0.4069 r:0.7533
ru_en Dev loss: 0.4301 r:0.7315
Current avg r:0.6138 Best avg r: 0.6296
21:07:36,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:06,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:36,305 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3570
en_de Dev loss: 0.8511 r:0.2261
en_zh Dev loss: 0.6936 r:0.4687
ro_en Dev loss: 0.3247 r:0.8212
et_en Dev loss: 0.3927 r:0.7015
si_en Dev loss: 0.6825 r:0.6054
ne_en Dev loss: 0.4516 r:0.7616
ru_en Dev loss: 0.4037 r:0.7425
Current avg r:0.6182 Best avg r: 0.6296
21:15:05,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:35,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:05,236 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3930
en_de Dev loss: 0.8472 r:0.2375
en_zh Dev loss: 0.7342 r:0.4720
ro_en Dev loss: 0.3419 r:0.8221
et_en Dev loss: 0.4117 r:0.6919
si_en Dev loss: 0.7086 r:0.6025
ne_en Dev loss: 0.4305 r:0.7604
ru_en Dev loss: 0.4591 r:0.7312
Current avg r:0.6168 Best avg r: 0.6296
21:22:34,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:04,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:34,138 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3977
en_de Dev loss: 0.8633 r:0.2296
en_zh Dev loss: 0.7784 r:0.4633
ro_en Dev loss: 0.3549 r:0.8194
et_en Dev loss: 0.4198 r:0.6950
si_en Dev loss: 0.8619 r:0.5878
ne_en Dev loss: 0.4811 r:0.7429
ru_en Dev loss: 0.5450 r:0.7138
Current avg r:0.6074 Best avg r: 0.6296
21:30:03,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:31:33,173 root INFO 
id:ru_en cur r: 0.7597 best r: 0.7597
21:31:33,173 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:03,270 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3937
en_de Dev loss: 0.8574 r:0.2342
en_zh Dev loss: 0.7366 r:0.4695
ro_en Dev loss: 0.3267 r:0.8285
et_en Dev loss: 0.3898 r:0.7132
si_en Dev loss: 0.6509 r:0.6124
ne_en Dev loss: 0.4184 r:0.7589
ru_en Dev loss: 0.4156 r:0.7570
Current avg r:0.6248 Best avg r: 0.6296
21:37:32,398 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:02,371 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:40:32,450 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3541
en_de Dev loss: 0.8720 r:0.2359
en_zh Dev loss: 0.7116 r:0.4811
ro_en Dev loss: 0.3290 r:0.8269
et_en Dev loss: 0.4144 r:0.7021
si_en Dev loss: 0.6899 r:0.6073
ne_en Dev loss: 0.4246 r:0.7605
ru_en Dev loss: 0.4400 r:0.7418
Current avg r:0.6222 Best avg r: 0.6296
21:45:02,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:46:32,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:02,430 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3285
en_de Dev loss: 0.8806 r:0.2239
en_zh Dev loss: 0.8344 r:0.4491
ro_en Dev loss: 0.3640 r:0.8188
et_en Dev loss: 0.4197 r:0.6845
si_en Dev loss: 0.9094 r:0.5698
ne_en Dev loss: 0.5692 r:0.7543
ru_en Dev loss: 0.5440 r:0.7042
Current avg r:0.6007 Best avg r: 0.6296
21:52:31,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:00,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:55:30,728 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3181
en_de Dev loss: 0.8644 r:0.2253
en_zh Dev loss: 0.7646 r:0.4417
ro_en Dev loss: 0.3202 r:0.8236
et_en Dev loss: 0.4211 r:0.6957
si_en Dev loss: 0.7176 r:0.5875
ne_en Dev loss: 0.3860 r:0.7612
ru_en Dev loss: 0.4540 r:0.7255
Current avg r:0.6086 Best avg r: 0.6296
21:59:59,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:01:29,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:59,294 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3341
en_de Dev loss: 0.8786 r:0.2268
en_zh Dev loss: 0.7712 r:0.4527
ro_en Dev loss: 0.3730 r:0.8158
et_en Dev loss: 0.4139 r:0.6862
si_en Dev loss: 0.7961 r:0.5853
ne_en Dev loss: 0.5120 r:0.7542
ru_en Dev loss: 0.5029 r:0.7141
Current avg r:0.6050 Best avg r: 0.6296
22:07:28,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:58,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:28,224 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3540
en_de Dev loss: 0.8702 r:0.2356
en_zh Dev loss: 0.7312 r:0.4590
ro_en Dev loss: 0.3169 r:0.8270
et_en Dev loss: 0.4080 r:0.6941
si_en Dev loss: 0.6877 r:0.5986
ne_en Dev loss: 0.4359 r:0.7595
ru_en Dev loss: 0.4591 r:0.7266
Current avg r:0.6143 Best avg r: 0.6296
22:14:57,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:16:27,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:57,263 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3337
en_de Dev loss: 0.9019 r:0.2035
en_zh Dev loss: 0.8083 r:0.4396
ro_en Dev loss: 0.3564 r:0.8219
et_en Dev loss: 0.4212 r:0.6793
si_en Dev loss: 0.9518 r:0.5808
ne_en Dev loss: 0.6001 r:0.7396
ru_en Dev loss: 0.5353 r:0.7147
Current avg r:0.5971 Best avg r: 0.6296
22:22:26,28 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:55,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:25:25,733 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3283
en_de Dev loss: 0.8763 r:0.2162
en_zh Dev loss: 0.7897 r:0.4479
ro_en Dev loss: 0.3499 r:0.8239
et_en Dev loss: 0.4039 r:0.6927
si_en Dev loss: 0.8229 r:0.5885
ne_en Dev loss: 0.5233 r:0.7484
ru_en Dev loss: 0.5386 r:0.7125
Current avg r:0.6043 Best avg r: 0.6296
22:29:54,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:24,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:54,320 root INFO Epoch 5 Global steps: 44100 Train loss: 0.3408
en_de Dev loss: 0.8497 r:0.2167
en_zh Dev loss: 0.7452 r:0.4516
ro_en Dev loss: 0.3065 r:0.8247
et_en Dev loss: 0.3995 r:0.6961
si_en Dev loss: 0.7209 r:0.5981
ne_en Dev loss: 0.4192 r:0.7584
ru_en Dev loss: 0.3958 r:0.7512
Current avg r:0.6138 Best avg r: 0.6296
22:37:23,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:53,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:23,30 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3412
en_de Dev loss: 0.8553 r:0.2366
en_zh Dev loss: 0.7553 r:0.4611
ro_en Dev loss: 0.3328 r:0.8248
et_en Dev loss: 0.4245 r:0.6986
si_en Dev loss: 0.7002 r:0.5964
ne_en Dev loss: 0.3893 r:0.7622
ru_en Dev loss: 0.4127 r:0.7494
Current avg r:0.6184 Best avg r: 0.6296
22:44:51,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:21,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:51,731 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3366
en_de Dev loss: 0.8506 r:0.2390
en_zh Dev loss: 0.7121 r:0.4671
ro_en Dev loss: 0.3252 r:0.8223
et_en Dev loss: 0.3952 r:0.6878
si_en Dev loss: 0.7677 r:0.5880
ne_en Dev loss: 0.4833 r:0.7634
ru_en Dev loss: 0.4031 r:0.7479
Current avg r:0.6165 Best avg r: 0.6296
22:52:20,382 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:50,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:20,169 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3283
en_de Dev loss: 0.8578 r:0.2231
en_zh Dev loss: 0.7585 r:0.4613
ro_en Dev loss: 0.3314 r:0.8267
et_en Dev loss: 0.4408 r:0.6857
si_en Dev loss: 0.7651 r:0.5934
ne_en Dev loss: 0.4286 r:0.7490
ru_en Dev loss: 0.4328 r:0.7349
Current avg r:0.6106 Best avg r: 0.6296
22:59:48,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:18,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:02:48,647 root INFO Epoch 5 Global steps: 46900 Train loss: 0.3405
en_de Dev loss: 0.8692 r:0.2033
en_zh Dev loss: 0.7558 r:0.4616
ro_en Dev loss: 0.3382 r:0.8256
et_en Dev loss: 0.4167 r:0.6847
si_en Dev loss: 0.8790 r:0.5801
ne_en Dev loss: 0.5048 r:0.7517
ru_en Dev loss: 0.4907 r:0.7227
Current avg r:0.6043 Best avg r: 0.6296
23:07:17,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:47,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:16,852 root INFO Epoch 5 Global steps: 47600 Train loss: 0.3279
en_de Dev loss: 0.8557 r:0.2387
en_zh Dev loss: 0.7702 r:0.4857
ro_en Dev loss: 0.3347 r:0.8225
et_en Dev loss: 0.4817 r:0.6880
si_en Dev loss: 0.7107 r:0.5862
ne_en Dev loss: 0.3917 r:0.7552
ru_en Dev loss: 0.3993 r:0.7502
Current avg r:0.6181 Best avg r: 0.6296
23:14:47,286 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:17,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:17:47,16 root INFO Epoch 6 Global steps: 48300 Train loss: 0.2991
en_de Dev loss: 0.8465 r:0.2289
en_zh Dev loss: 0.7447 r:0.4566
ro_en Dev loss: 0.3184 r:0.8214
et_en Dev loss: 0.4133 r:0.6855
si_en Dev loss: 0.7726 r:0.5819
ne_en Dev loss: 0.4522 r:0.7563
ru_en Dev loss: 0.4293 r:0.7299
Current avg r:0.6087 Best avg r: 0.6296
23:22:16,52 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:23:46,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:16,331 root INFO Epoch 6 Global steps: 49000 Train loss: 0.3131
en_de Dev loss: 0.8889 r:0.1892
en_zh Dev loss: 0.8545 r:0.4426
ro_en Dev loss: 0.3819 r:0.8149
et_en Dev loss: 0.4324 r:0.6718
si_en Dev loss: 0.8649 r:0.5729
ne_en Dev loss: 0.5425 r:0.7445
ru_en Dev loss: 0.5450 r:0.6923
Current avg r:0.5897 Best avg r: 0.6296
23:29:45,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:15,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:32:45,307 root INFO Epoch 6 Global steps: 49700 Train loss: 0.3000
en_de Dev loss: 0.8668 r:0.2357
en_zh Dev loss: 0.7772 r:0.4537
ro_en Dev loss: 0.3581 r:0.8152
et_en Dev loss: 0.4244 r:0.6842
si_en Dev loss: 0.8225 r:0.5768
ne_en Dev loss: 0.4300 r:0.7516
ru_en Dev loss: 0.4646 r:0.7224
Current avg r:0.6056 Best avg r: 0.6296
23:37:14,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:38:43,880 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:13,744 root INFO Epoch 6 Global steps: 50400 Train loss: 0.2867
en_de Dev loss: 0.8707 r:0.2091
en_zh Dev loss: 0.7643 r:0.4525
ro_en Dev loss: 0.3280 r:0.8191
et_en Dev loss: 0.4414 r:0.6855
si_en Dev loss: 0.7001 r:0.5814
ne_en Dev loss: 0.4200 r:0.7466
ru_en Dev loss: 0.4201 r:0.7349
Current avg r:0.6042 Best avg r: 0.6296
23:44:42,818 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:12,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:47:42,663 root INFO Epoch 6 Global steps: 51100 Train loss: 0.2803
en_de Dev loss: 0.8800 r:0.1980
en_zh Dev loss: 0.7760 r:0.4496
ro_en Dev loss: 0.3430 r:0.8153
et_en Dev loss: 0.4282 r:0.6786
si_en Dev loss: 0.7940 r:0.5814
ne_en Dev loss: 0.4207 r:0.7497
ru_en Dev loss: 0.4598 r:0.7249
Current avg r:0.5996 Best avg r: 0.6296
23:52:11,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:53:41,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:11,846 root INFO Epoch 6 Global steps: 51800 Train loss: 0.2880
en_de Dev loss: 0.8904 r:0.2014
en_zh Dev loss: 0.7786 r:0.4475
ro_en Dev loss: 0.3391 r:0.8217
et_en Dev loss: 0.4445 r:0.6828
si_en Dev loss: 0.6872 r:0.5921
ne_en Dev loss: 0.4089 r:0.7578
ru_en Dev loss: 0.4437 r:0.7320
Current avg r:0.6050 Best avg r: 0.6296
23:59:40,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:10,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:02:40,648 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2961
en_de Dev loss: 0.8698 r:0.2053
en_zh Dev loss: 0.7859 r:0.4588
ro_en Dev loss: 0.3489 r:0.8217
et_en Dev loss: 0.4457 r:0.6811
si_en Dev loss: 0.7546 r:0.5897
ne_en Dev loss: 0.4193 r:0.7510
ru_en Dev loss: 0.4714 r:0.7219
Current avg r:0.6042 Best avg r: 0.6296
00:07:09,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:08:39,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:10,31 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2837
en_de Dev loss: 0.8599 r:0.1851
en_zh Dev loss: 0.7571 r:0.4395
ro_en Dev loss: 0.3070 r:0.8248
et_en Dev loss: 0.4140 r:0.6767
si_en Dev loss: 0.7257 r:0.5871
ne_en Dev loss: 0.5027 r:0.7454
ru_en Dev loss: 0.4720 r:0.7039
Current avg r:0.5946 Best avg r: 0.6296
00:14:38,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:16:09,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:17:39,110 root INFO Epoch 6 Global steps: 53900 Train loss: 0.2802
en_de Dev loss: 0.8936 r:0.1945
en_zh Dev loss: 0.8146 r:0.4387
ro_en Dev loss: 0.3666 r:0.8188
et_en Dev loss: 0.4474 r:0.6724
si_en Dev loss: 0.8158 r:0.5745
ne_en Dev loss: 0.4798 r:0.7468
ru_en Dev loss: 0.4663 r:0.7314
Current avg r:0.5967 Best avg r: 0.6296
00:22:07,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:37,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:07,505 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2899
en_de Dev loss: 0.8832 r:0.2049
en_zh Dev loss: 0.8092 r:0.4554
ro_en Dev loss: 0.3851 r:0.8180
et_en Dev loss: 0.4414 r:0.6779
si_en Dev loss: 0.9057 r:0.5805
ne_en Dev loss: 0.5938 r:0.7498
ru_en Dev loss: 0.4711 r:0.7313
Current avg r:0.6026 Best avg r: 0.6296
00:29:36,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:06,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:35,876 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2872
en_de Dev loss: 0.8722 r:0.2052
en_zh Dev loss: 0.7685 r:0.4538
ro_en Dev loss: 0.3544 r:0.8186
et_en Dev loss: 0.4338 r:0.6842
si_en Dev loss: 0.8084 r:0.5807
ne_en Dev loss: 0.3960 r:0.7508
ru_en Dev loss: 0.4311 r:0.7450
Current avg r:0.6055 Best avg r: 0.6296
00:37:06,22 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:38:35,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:05,995 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2662
en_de Dev loss: 0.8659 r:0.2056
en_zh Dev loss: 0.7490 r:0.4597
ro_en Dev loss: 0.3423 r:0.8231
et_en Dev loss: 0.4417 r:0.6817
si_en Dev loss: 0.8112 r:0.5805
ne_en Dev loss: 0.4732 r:0.7392
ru_en Dev loss: 0.4531 r:0.7270
Current avg r:0.6024 Best avg r: 0.6296
00:44:34,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:04,562 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:34,628 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2491
en_de Dev loss: 0.8784 r:0.1973
en_zh Dev loss: 0.7708 r:0.4454
ro_en Dev loss: 0.3569 r:0.8122
et_en Dev loss: 0.4674 r:0.6574
si_en Dev loss: 0.9013 r:0.5645
ne_en Dev loss: 0.4944 r:0.7400
ru_en Dev loss: 0.5030 r:0.7107
Current avg r:0.5896 Best avg r: 0.6296
00:52:03,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:33,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:03,409 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2618
en_de Dev loss: 0.8724 r:0.2100
en_zh Dev loss: 0.7815 r:0.4580
ro_en Dev loss: 0.3579 r:0.8184
et_en Dev loss: 0.4856 r:0.6715
si_en Dev loss: 0.8531 r:0.5679
ne_en Dev loss: 0.4690 r:0.7423
ru_en Dev loss: 0.4857 r:0.7271
Current avg r:0.5993 Best avg r: 0.6296
00:59:31,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:01:01,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:32,26 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2618
en_de Dev loss: 0.8826 r:0.2044
en_zh Dev loss: 0.8021 r:0.4516
ro_en Dev loss: 0.3375 r:0.8169
et_en Dev loss: 0.4549 r:0.6692
si_en Dev loss: 0.7973 r:0.5715
ne_en Dev loss: 0.4794 r:0.7439
ru_en Dev loss: 0.4717 r:0.7296
Current avg r:0.5982 Best avg r: 0.6296
01:07:00,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:30,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:00,714 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2588
en_de Dev loss: 0.8773 r:0.2087
en_zh Dev loss: 0.7894 r:0.4586
ro_en Dev loss: 0.3544 r:0.8209
et_en Dev loss: 0.4751 r:0.6693
si_en Dev loss: 0.8473 r:0.5703
ne_en Dev loss: 0.5148 r:0.7322
ru_en Dev loss: 0.4995 r:0.7186
Current avg r:0.5969 Best avg r: 0.6296
01:14:29,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:59,90 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:28,989 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2558
en_de Dev loss: 0.8908 r:0.2007
en_zh Dev loss: 0.8130 r:0.4554
ro_en Dev loss: 0.3630 r:0.8164
et_en Dev loss: 0.4571 r:0.6686
si_en Dev loss: 0.8437 r:0.5709
ne_en Dev loss: 0.5149 r:0.7417
ru_en Dev loss: 0.5195 r:0.7170
Current avg r:0.5958 Best avg r: 0.6296
01:21:57,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:27,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:57,57 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2617
en_de Dev loss: 0.8766 r:0.2058
en_zh Dev loss: 0.8214 r:0.4465
ro_en Dev loss: 0.3838 r:0.8155
et_en Dev loss: 0.4626 r:0.6693
si_en Dev loss: 0.8828 r:0.5707
ne_en Dev loss: 0.5644 r:0.7381
ru_en Dev loss: 0.5268 r:0.7163
Current avg r:0.5946 Best avg r: 0.6296
01:29:25,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:55,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:25,896 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2656
en_de Dev loss: 0.8825 r:0.2272
en_zh Dev loss: 0.7979 r:0.4621
ro_en Dev loss: 0.3707 r:0.8163
et_en Dev loss: 0.4473 r:0.6789
si_en Dev loss: 0.8792 r:0.5743
ne_en Dev loss: 0.5017 r:0.7359
ru_en Dev loss: 0.5548 r:0.7173
Current avg r:0.6017 Best avg r: 0.6296
01:36:54,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:38:24,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:54,433 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2577
en_de Dev loss: 0.8743 r:0.2112
en_zh Dev loss: 0.7683 r:0.4672
ro_en Dev loss: 0.3496 r:0.8171
et_en Dev loss: 0.4526 r:0.6759
si_en Dev loss: 0.8056 r:0.5785
ne_en Dev loss: 0.4520 r:0.7445
ru_en Dev loss: 0.4991 r:0.7256
Current avg r:0.6029 Best avg r: 0.6296
01:44:23,368 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:45:53,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:47:23,559 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2622
en_de Dev loss: 0.8886 r:0.1936
en_zh Dev loss: 0.7810 r:0.4579
ro_en Dev loss: 0.3491 r:0.8172
et_en Dev loss: 0.4438 r:0.6799
si_en Dev loss: 0.8489 r:0.5773
ne_en Dev loss: 0.4960 r:0.7492
ru_en Dev loss: 0.4585 r:0.7391
Current avg r:0.6020 Best avg r: 0.6296
01:51:52,540 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:53:22,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:54:52,514 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2502
en_de Dev loss: 0.8924 r:0.2138
en_zh Dev loss: 0.8018 r:0.4651
ro_en Dev loss: 0.3645 r:0.8170
et_en Dev loss: 0.4599 r:0.6772
si_en Dev loss: 0.8038 r:0.5822
ne_en Dev loss: 0.4740 r:0.7453
ru_en Dev loss: 0.4719 r:0.7311
Current avg r:0.6045 Best avg r: 0.6296
01:59:24,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:00:55,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:02:26,757 root INFO Epoch 8 Global steps: 63700 Train loss: 0.2280
en_de Dev loss: 0.8814 r:0.2164
en_zh Dev loss: 0.8015 r:0.4727
ro_en Dev loss: 0.3810 r:0.8161
et_en Dev loss: 0.4662 r:0.6776
si_en Dev loss: 0.8220 r:0.5767
ne_en Dev loss: 0.5180 r:0.7381
ru_en Dev loss: 0.4904 r:0.7263
Current avg r:0.6034 Best avg r: 0.6296
02:07:00,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:08:31,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:02,188 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2339
en_de Dev loss: 0.9397 r:0.1986
en_zh Dev loss: 0.9145 r:0.4550
ro_en Dev loss: 0.4427 r:0.8143
et_en Dev loss: 0.4916 r:0.6683
si_en Dev loss: 0.9860 r:0.5696
ne_en Dev loss: 0.6099 r:0.7314
ru_en Dev loss: 0.6004 r:0.7134
Current avg r:0.5929 Best avg r: 0.6296
02:14:35,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:06,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:17:37,848 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2319
en_de Dev loss: 0.8838 r:0.1981
en_zh Dev loss: 0.8317 r:0.4512
ro_en Dev loss: 0.4257 r:0.8080
et_en Dev loss: 0.4639 r:0.6689
si_en Dev loss: 0.9237 r:0.5635
ne_en Dev loss: 0.6317 r:0.7359
ru_en Dev loss: 0.5249 r:0.7115
Current avg r:0.5910 Best avg r: 0.6296
02:22:11,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:23:42,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:13,150 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2351
en_de Dev loss: 0.8951 r:0.2020
en_zh Dev loss: 0.8143 r:0.4486
ro_en Dev loss: 0.3992 r:0.8044
et_en Dev loss: 0.4693 r:0.6554
si_en Dev loss: 0.9520 r:0.5558
ne_en Dev loss: 0.6159 r:0.7300
ru_en Dev loss: 0.5310 r:0.7004
Current avg r:0.5852 Best avg r: 0.6296
02:29:44,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:14,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:32:44,615 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2245
en_de Dev loss: 0.8989 r:0.2168
en_zh Dev loss: 0.8034 r:0.4527
ro_en Dev loss: 0.3665 r:0.8106
et_en Dev loss: 0.4597 r:0.6729
si_en Dev loss: 0.7768 r:0.5673
ne_en Dev loss: 0.4625 r:0.7379
ru_en Dev loss: 0.4947 r:0.7161
Current avg r:0.5963 Best avg r: 0.6296
02:37:14,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:38:44,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:40:14,627 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2272
en_de Dev loss: 0.8751 r:0.2171
en_zh Dev loss: 0.7969 r:0.4533
ro_en Dev loss: 0.3540 r:0.8131
et_en Dev loss: 0.4883 r:0.6741
si_en Dev loss: 0.8614 r:0.5506
ne_en Dev loss: 0.4556 r:0.7371
ru_en Dev loss: 0.4354 r:0.7319
Current avg r:0.5968 Best avg r: 0.6296
02:44:44,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:46:14,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:47:44,478 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2377
en_de Dev loss: 0.9003 r:0.2002
en_zh Dev loss: 0.8404 r:0.4434
ro_en Dev loss: 0.3784 r:0.8143
et_en Dev loss: 0.4810 r:0.6702
si_en Dev loss: 0.9141 r:0.5562
ne_en Dev loss: 0.5443 r:0.7352
ru_en Dev loss: 0.4800 r:0.7289
Current avg r:0.5926 Best avg r: 0.6296
02:52:15,709 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:53:45,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:55:16,44 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2306
en_de Dev loss: 0.8956 r:0.2172
en_zh Dev loss: 0.8354 r:0.4491
ro_en Dev loss: 0.3688 r:0.8148
et_en Dev loss: 0.4977 r:0.6613
si_en Dev loss: 0.9239 r:0.5509
ne_en Dev loss: 0.5776 r:0.7338
ru_en Dev loss: 0.4717 r:0.7283
Current avg r:0.5936 Best avg r: 0.6296
02:59:45,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:01:15,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:02:45,941 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2266
en_de Dev loss: 0.8790 r:0.2260
en_zh Dev loss: 0.7840 r:0.4602
ro_en Dev loss: 0.3448 r:0.8227
et_en Dev loss: 0.4254 r:0.6818
si_en Dev loss: 0.8702 r:0.5675
ne_en Dev loss: 0.5398 r:0.7393
ru_en Dev loss: 0.4839 r:0.7354
Current avg r:0.6047 Best avg r: 0.6296
03:07:15,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:08:45,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:10:16,141 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2266
en_de Dev loss: 0.8683 r:0.2312
en_zh Dev loss: 0.7804 r:0.4571
ro_en Dev loss: 0.3398 r:0.8210
et_en Dev loss: 0.4547 r:0.6779
si_en Dev loss: 0.8474 r:0.5630
ne_en Dev loss: 0.4656 r:0.7405
ru_en Dev loss: 0.4607 r:0.7299
Current avg r:0.6029 Best avg r: 0.6296
03:14:45,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:16:15,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:17:45,718 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2230
en_de Dev loss: 0.8843 r:0.2088
en_zh Dev loss: 0.7445 r:0.4725
ro_en Dev loss: 0.3172 r:0.8234
et_en Dev loss: 0.4369 r:0.6776
si_en Dev loss: 0.8346 r:0.5666
ne_en Dev loss: 0.4462 r:0.7386
ru_en Dev loss: 0.4492 r:0.7349
Current avg r:0.6032 Best avg r: 0.6296
03:22:15,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:23:45,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:25:15,649 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2163
en_de Dev loss: 0.8992 r:0.1974
en_zh Dev loss: 0.8346 r:0.4502
ro_en Dev loss: 0.3597 r:0.8196
et_en Dev loss: 0.4704 r:0.6610
si_en Dev loss: 0.9070 r:0.5558
ne_en Dev loss: 0.5858 r:0.7345
ru_en Dev loss: 0.5152 r:0.7182
Current avg r:0.5910 Best avg r: 0.6296
03:29:46,824 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:31:16,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:32:46,835 root INFO Epoch 9 Global steps: 72100 Train loss: 0.2070
en_de Dev loss: 0.8962 r:0.2014
en_zh Dev loss: 0.7494 r:0.4650
ro_en Dev loss: 0.3285 r:0.8208
et_en Dev loss: 0.4636 r:0.6691
si_en Dev loss: 0.7906 r:0.5608
ne_en Dev loss: 0.4856 r:0.7387
ru_en Dev loss: 0.4353 r:0.7368
Current avg r:0.5989 Best avg r: 0.6296
03:37:16,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:38:46,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:40:16,729 root INFO Epoch 9 Global steps: 72800 Train loss: 0.2010
en_de Dev loss: 0.9134 r:0.1974
en_zh Dev loss: 0.8060 r:0.4645
ro_en Dev loss: 0.3578 r:0.8189
et_en Dev loss: 0.4762 r:0.6663
si_en Dev loss: 0.8965 r:0.5511
ne_en Dev loss: 0.5160 r:0.7300
ru_en Dev loss: 0.4759 r:0.7333
Current avg r:0.5945 Best avg r: 0.6296
03:44:46,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:46:16,312 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:47:46,466 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1975
en_de Dev loss: 0.9048 r:0.1940
en_zh Dev loss: 0.7568 r:0.4689
ro_en Dev loss: 0.3428 r:0.8233
et_en Dev loss: 0.4779 r:0.6786
si_en Dev loss: 0.7639 r:0.5690
ne_en Dev loss: 0.3984 r:0.7450
ru_en Dev loss: 0.4228 r:0.7466
Current avg r:0.6036 Best avg r: 0.6296
03:52:16,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:53:46,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:55:16,703 root INFO Epoch 9 Global steps: 74200 Train loss: 0.2076
en_de Dev loss: 0.9396 r:0.1940
en_zh Dev loss: 0.8715 r:0.4515
ro_en Dev loss: 0.4082 r:0.8164
et_en Dev loss: 0.5073 r:0.6621
si_en Dev loss: 0.9634 r:0.5502
ne_en Dev loss: 0.5707 r:0.7363
ru_en Dev loss: 0.5352 r:0.7167
Current avg r:0.5896 Best avg r: 0.6296
03:59:46,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:01:16,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:02:47,109 root INFO Epoch 9 Global steps: 74900 Train loss: 0.2067
en_de Dev loss: 0.9284 r:0.1881
en_zh Dev loss: 0.8428 r:0.4514
ro_en Dev loss: 0.3649 r:0.8201
et_en Dev loss: 0.4780 r:0.6647
si_en Dev loss: 0.9294 r:0.5521
ne_en Dev loss: 0.6070 r:0.7289
ru_en Dev loss: 0.4893 r:0.7281
Current avg r:0.5905 Best avg r: 0.6296
04:07:20,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:08:51,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:10:22,248 root INFO Epoch 9 Global steps: 75600 Train loss: 0.1957
en_de Dev loss: 0.9181 r:0.1656
en_zh Dev loss: 0.8058 r:0.4520
ro_en Dev loss: 0.3475 r:0.8164
et_en Dev loss: 0.4598 r:0.6550
si_en Dev loss: 0.8799 r:0.5407
ne_en Dev loss: 0.5219 r:0.7272
ru_en Dev loss: 0.4755 r:0.7109
Current avg r:0.5811 Best avg r: 0.6296
04:14:55,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:16:26,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:17:57,502 root INFO Epoch 9 Global steps: 76300 Train loss: 0.2007
en_de Dev loss: 0.9431 r:0.1813
en_zh Dev loss: 0.8552 r:0.4685
ro_en Dev loss: 0.3908 r:0.8222
et_en Dev loss: 0.4862 r:0.6711
si_en Dev loss: 0.9597 r:0.5526
ne_en Dev loss: 0.5594 r:0.7295
ru_en Dev loss: 0.4771 r:0.7469
Current avg r:0.5960 Best avg r: 0.6296
04:22:31,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:24:02,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:25:33,24 root INFO Epoch 9 Global steps: 77000 Train loss: 0.1919
en_de Dev loss: 0.9031 r:0.1901
en_zh Dev loss: 0.7922 r:0.4698
ro_en Dev loss: 0.3491 r:0.8207
et_en Dev loss: 0.4673 r:0.6760
si_en Dev loss: 0.8147 r:0.5581
ne_en Dev loss: 0.4881 r:0.7381
ru_en Dev loss: 0.4794 r:0.7276
Current avg r:0.5972 Best avg r: 0.6296
04:30:02,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:31:32,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:33:03,31 root INFO Epoch 9 Global steps: 77700 Train loss: 0.2190
en_de Dev loss: 0.9560 r:0.1825
en_zh Dev loss: 0.8472 r:0.4562
ro_en Dev loss: 0.4113 r:0.8126
et_en Dev loss: 0.4819 r:0.6609
si_en Dev loss: 0.9795 r:0.5422
ne_en Dev loss: 0.6709 r:0.7354
ru_en Dev loss: 0.5834 r:0.7037
Current avg r:0.5848 Best avg r: 0.6296
04:37:32,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:39:02,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:40:32,518 root INFO Epoch 9 Global steps: 78400 Train loss: 0.1928
en_de Dev loss: 0.9142 r:0.1773
en_zh Dev loss: 0.7921 r:0.4570
ro_en Dev loss: 0.3724 r:0.8176
et_en Dev loss: 0.5078 r:0.6720
si_en Dev loss: 0.8879 r:0.5505
ne_en Dev loss: 0.5276 r:0.7359
ru_en Dev loss: 0.4798 r:0.7266
Current avg r:0.5910 Best avg r: 0.6296
04:45:02,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:46:32,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:02,425 root INFO Epoch 9 Global steps: 79100 Train loss: 0.1964
en_de Dev loss: 0.9027 r:0.1776
en_zh Dev loss: 0.8073 r:0.4494
ro_en Dev loss: 0.3894 r:0.8130
et_en Dev loss: 0.4732 r:0.6621
si_en Dev loss: 0.9560 r:0.5411
ne_en Dev loss: 0.5738 r:0.7309
ru_en Dev loss: 0.4995 r:0.7179
Current avg r:0.5846 Best avg r: 0.6296
04:52:33,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:54:03,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:55:33,460 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1808
en_de Dev loss: 0.9312 r:0.1666
en_zh Dev loss: 0.8471 r:0.4416
ro_en Dev loss: 0.4069 r:0.8091
et_en Dev loss: 0.4896 r:0.6559
si_en Dev loss: 1.0007 r:0.5325
ne_en Dev loss: 0.6422 r:0.7301
ru_en Dev loss: 0.5464 r:0.7052
Current avg r:0.5773 Best avg r: 0.6296
05:00:03,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:01:33,830 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:04,49 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1774
en_de Dev loss: 0.9187 r:0.1773
en_zh Dev loss: 0.8663 r:0.4386
ro_en Dev loss: 0.4134 r:0.8125
et_en Dev loss: 0.4881 r:0.6630
si_en Dev loss: 0.9679 r:0.5391
ne_en Dev loss: 0.5580 r:0.7228
ru_en Dev loss: 0.5444 r:0.7112
Current avg r:0.5806 Best avg r: 0.6296
05:07:33,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:09:04,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:10:34,274 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1845
en_de Dev loss: 0.9100 r:0.1666
en_zh Dev loss: 0.7573 r:0.4509
ro_en Dev loss: 0.3459 r:0.8166
et_en Dev loss: 0.4702 r:0.6726
si_en Dev loss: 0.8104 r:0.5522
ne_en Dev loss: 0.4757 r:0.7321
ru_en Dev loss: 0.4414 r:0.7279
Current avg r:0.5884 Best avg r: 0.6296
05:15:04,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:16:34,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:04,925 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1863
en_de Dev loss: 0.9314 r:0.1841
en_zh Dev loss: 0.8354 r:0.4450
ro_en Dev loss: 0.4008 r:0.8134
et_en Dev loss: 0.4796 r:0.6654
si_en Dev loss: 0.9047 r:0.5464
ne_en Dev loss: 0.5819 r:0.7298
ru_en Dev loss: 0.4968 r:0.7339
Current avg r:0.5883 Best avg r: 0.6296
05:22:34,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:24:04,466 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:34,669 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1877
en_de Dev loss: 0.9249 r:0.1657
en_zh Dev loss: 0.8251 r:0.4313
ro_en Dev loss: 0.3773 r:0.8156
et_en Dev loss: 0.4702 r:0.6684
si_en Dev loss: 0.8104 r:0.5505
ne_en Dev loss: 0.4859 r:0.7360
ru_en Dev loss: 0.4672 r:0.7299
Current avg r:0.5854 Best avg r: 0.6296
05:30:04,325 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:31:34,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:33:04,301 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1870
en_de Dev loss: 0.9344 r:0.1671
en_zh Dev loss: 0.8201 r:0.4318
ro_en Dev loss: 0.3861 r:0.8085
et_en Dev loss: 0.5128 r:0.6513
si_en Dev loss: 0.8700 r:0.5415
ne_en Dev loss: 0.5891 r:0.7280
ru_en Dev loss: 0.5310 r:0.6942
Current avg r:0.5746 Best avg r: 0.6296
05:37:33,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:39:03,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:40:34,110 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1774
en_de Dev loss: 0.9264 r:0.1651
en_zh Dev loss: 0.8057 r:0.4513
ro_en Dev loss: 0.3633 r:0.8191
et_en Dev loss: 0.5087 r:0.6651
si_en Dev loss: 0.8845 r:0.5537
ne_en Dev loss: 0.5129 r:0.7308
ru_en Dev loss: 0.4693 r:0.7286
Current avg r:0.5877 Best avg r: 0.6296
05:45:03,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:46:33,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:48:04,539 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1719
en_de Dev loss: 0.9304 r:0.1753
en_zh Dev loss: 0.8025 r:0.4470
ro_en Dev loss: 0.3562 r:0.8175
et_en Dev loss: 0.4874 r:0.6661
si_en Dev loss: 0.8094 r:0.5546
ne_en Dev loss: 0.4955 r:0.7300
ru_en Dev loss: 0.4836 r:0.7275
Current avg r:0.5883 Best avg r: 0.6296
05:52:37,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:08,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:55:39,552 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1725
en_de Dev loss: 0.9580 r:0.1598
en_zh Dev loss: 0.8572 r:0.4404
ro_en Dev loss: 0.4014 r:0.8107
et_en Dev loss: 0.4836 r:0.6543
si_en Dev loss: 0.9667 r:0.5362
ne_en Dev loss: 0.6691 r:0.7141
ru_en Dev loss: 0.5328 r:0.7222
Current avg r:0.5768 Best avg r: 0.6296
06:00:12,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:01:43,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:03:13,954 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1789
en_de Dev loss: 0.9566 r:0.1599
en_zh Dev loss: 0.8076 r:0.4388
ro_en Dev loss: 0.3560 r:0.8174
et_en Dev loss: 0.4957 r:0.6615
si_en Dev loss: 0.9076 r:0.5371
ne_en Dev loss: 0.5532 r:0.7227
ru_en Dev loss: 0.4658 r:0.7327
Current avg r:0.5814 Best avg r: 0.6296
06:07:47,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:17,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:10:48,770 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1838
en_de Dev loss: 0.9113 r:0.1721
en_zh Dev loss: 0.7874 r:0.4495
ro_en Dev loss: 0.3536 r:0.8142
et_en Dev loss: 0.4504 r:0.6624
si_en Dev loss: 0.9337 r:0.5381
ne_en Dev loss: 0.5991 r:0.7251
ru_en Dev loss: 0.4721 r:0.7289
Current avg r:0.5843 Best avg r: 0.6296
06:15:19,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:16:49,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:19,848 root INFO Epoch 11 Global steps: 87500 Train loss: 0.1384
en_de Dev loss: 0.9203 r:0.1563
en_zh Dev loss: 0.8066 r:0.4512
ro_en Dev loss: 0.3458 r:0.8189
et_en Dev loss: 0.4613 r:0.6635
si_en Dev loss: 0.8723 r:0.5511
ne_en Dev loss: 0.5319 r:0.7298
ru_en Dev loss: 0.5064 r:0.7137
Current avg r:0.5835 Best avg r: 0.6296
06:22:49,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:24:19,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:25:49,883 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1587
en_de Dev loss: 0.9101 r:0.1743
en_zh Dev loss: 0.7530 r:0.4551
ro_en Dev loss: 0.3233 r:0.8207
et_en Dev loss: 0.4470 r:0.6611
si_en Dev loss: 0.8526 r:0.5462
ne_en Dev loss: 0.5187 r:0.7320
ru_en Dev loss: 0.4494 r:0.7336
Current avg r:0.5890 Best avg r: 0.6296
06:30:19,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:31:49,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:33:19,633 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1676
en_de Dev loss: 0.9314 r:0.1560
en_zh Dev loss: 0.8111 r:0.4513
ro_en Dev loss: 0.3391 r:0.8185
et_en Dev loss: 0.4734 r:0.6672
si_en Dev loss: 0.8820 r:0.5461
ne_en Dev loss: 0.5800 r:0.7208
ru_en Dev loss: 0.5026 r:0.7179
Current avg r:0.5826 Best avg r: 0.6296
06:37:49,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:39:19,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:40:49,137 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1650
en_de Dev loss: 0.9360 r:0.1643
en_zh Dev loss: 0.8554 r:0.4410
ro_en Dev loss: 0.3710 r:0.8216
et_en Dev loss: 0.4778 r:0.6685
si_en Dev loss: 0.8521 r:0.5506
ne_en Dev loss: 0.5330 r:0.7261
ru_en Dev loss: 0.4928 r:0.7277
Current avg r:0.5857 Best avg r: 0.6296
06:45:19,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:46:49,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:48:19,508 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1616
en_de Dev loss: 0.9382 r:0.1713
en_zh Dev loss: 0.8285 r:0.4450
ro_en Dev loss: 0.3852 r:0.8137
et_en Dev loss: 0.5039 r:0.6646
si_en Dev loss: 0.8851 r:0.5475
ne_en Dev loss: 0.6011 r:0.7164
ru_en Dev loss: 0.4734 r:0.7259
Current avg r:0.5835 Best avg r: 0.6296
06:52:49,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:19,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:55:49,423 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1598
en_de Dev loss: 0.9465 r:0.1675
en_zh Dev loss: 0.8423 r:0.4539
ro_en Dev loss: 0.4056 r:0.8096
et_en Dev loss: 0.4944 r:0.6574
si_en Dev loss: 0.9728 r:0.5389
ne_en Dev loss: 0.6010 r:0.7227
ru_en Dev loss: 0.5273 r:0.7116
Current avg r:0.5802 Best avg r: 0.6296
07:00:19,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:01:49,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:03:19,238 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1605
en_de Dev loss: 0.9262 r:0.1695
en_zh Dev loss: 0.7687 r:0.4611
ro_en Dev loss: 0.3425 r:0.8152
et_en Dev loss: 0.4614 r:0.6695
si_en Dev loss: 0.8674 r:0.5397
ne_en Dev loss: 0.5252 r:0.7232
ru_en Dev loss: 0.4658 r:0.7324
Current avg r:0.5872 Best avg r: 0.6296
07:07:48,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:09:19,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:10:49,297 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1628
en_de Dev loss: 0.9222 r:0.1661
en_zh Dev loss: 0.8347 r:0.4498
ro_en Dev loss: 0.3915 r:0.8157
et_en Dev loss: 0.4744 r:0.6644
si_en Dev loss: 0.9886 r:0.5332
ne_en Dev loss: 0.7197 r:0.7161
ru_en Dev loss: 0.5058 r:0.7219
Current avg r:0.5810 Best avg r: 0.6296
07:15:19,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:16:49,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:18:19,863 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1533
en_de Dev loss: 0.9762 r:0.1867
en_zh Dev loss: 0.8937 r:0.4553
ro_en Dev loss: 0.3950 r:0.8122
et_en Dev loss: 0.5391 r:0.6654
si_en Dev loss: 0.9191 r:0.5344
ne_en Dev loss: 0.5533 r:0.7185
ru_en Dev loss: 0.5441 r:0.7223
Current avg r:0.5850 Best avg r: 0.6296
07:22:48,832 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:24:18,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:25:49,24 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1565
en_de Dev loss: 0.9533 r:0.1899
en_zh Dev loss: 0.7956 r:0.4729
ro_en Dev loss: 0.3577 r:0.8176
et_en Dev loss: 0.4786 r:0.6747
si_en Dev loss: 0.8587 r:0.5424
ne_en Dev loss: 0.5212 r:0.7241
ru_en Dev loss: 0.4755 r:0.7424
Current avg r:0.5949 Best avg r: 0.6296
07:30:18,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:31:48,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:33:18,413 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1674
en_de Dev loss: 0.9312 r:0.1859
en_zh Dev loss: 0.8376 r:0.4635
ro_en Dev loss: 0.3790 r:0.8158
et_en Dev loss: 0.4966 r:0.6634
si_en Dev loss: 0.9402 r:0.5363
ne_en Dev loss: 0.5567 r:0.7159
ru_en Dev loss: 0.5320 r:0.7221
Current avg r:0.5861 Best avg r: 0.6296
07:37:47,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:39:17,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:40:48,462 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1595
en_de Dev loss: 0.9560 r:0.1793
en_zh Dev loss: 0.8071 r:0.4651
ro_en Dev loss: 0.3679 r:0.8166
et_en Dev loss: 0.5055 r:0.6689
si_en Dev loss: 0.8696 r:0.5429
ne_en Dev loss: 0.5566 r:0.7265
ru_en Dev loss: 0.4497 r:0.7461
Current avg r:0.5922 Best avg r: 0.6296
07:45:23,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:46:53,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:48:24,973 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1413
en_de Dev loss: 0.9451 r:0.1682
en_zh Dev loss: 0.7670 r:0.4623
ro_en Dev loss: 0.3375 r:0.8181
et_en Dev loss: 0.4941 r:0.6634
si_en Dev loss: 0.8248 r:0.5411
ne_en Dev loss: 0.5197 r:0.7285
ru_en Dev loss: 0.4237 r:0.7391
Current avg r:0.5887 Best avg r: 0.6296
07:52:58,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:54:29,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:56:00,140 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1548
en_de Dev loss: 0.9468 r:0.1644
en_zh Dev loss: 0.8102 r:0.4591
ro_en Dev loss: 0.3595 r:0.8165
et_en Dev loss: 0.5181 r:0.6609
si_en Dev loss: 0.8464 r:0.5410
ne_en Dev loss: 0.4685 r:0.7283
ru_en Dev loss: 0.4731 r:0.7301
Current avg r:0.5858 Best avg r: 0.6296
08:00:33,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:04,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:34,682 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1476
en_de Dev loss: 0.9290 r:0.1691
en_zh Dev loss: 0.8250 r:0.4528
ro_en Dev loss: 0.3574 r:0.8170
et_en Dev loss: 0.4902 r:0.6666
si_en Dev loss: 0.8371 r:0.5415
ne_en Dev loss: 0.5232 r:0.7224
ru_en Dev loss: 0.4661 r:0.7331
Current avg r:0.5861 Best avg r: 0.6296
08:08:04,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:34,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:11:05,120 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1490
en_de Dev loss: 0.9734 r:0.1602
en_zh Dev loss: 0.8839 r:0.4402
ro_en Dev loss: 0.4023 r:0.8095
et_en Dev loss: 0.5014 r:0.6591
si_en Dev loss: 0.9620 r:0.5289
ne_en Dev loss: 0.5558 r:0.7296
ru_en Dev loss: 0.5073 r:0.7254
Current avg r:0.5790 Best avg r: 0.6296
08:15:34,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:17:04,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:18:34,632 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1504
en_de Dev loss: 0.9631 r:0.1662
en_zh Dev loss: 0.8369 r:0.4516
ro_en Dev loss: 0.3736 r:0.8132
et_en Dev loss: 0.4715 r:0.6659
si_en Dev loss: 0.9292 r:0.5318
ne_en Dev loss: 0.5469 r:0.7311
ru_en Dev loss: 0.4648 r:0.7345
Current avg r:0.5849 Best avg r: 0.6296
08:23:04,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:24:34,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:04,833 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1417
en_de Dev loss: 0.9554 r:0.1554
en_zh Dev loss: 0.7929 r:0.4511
ro_en Dev loss: 0.3596 r:0.8135
et_en Dev loss: 0.4731 r:0.6572
si_en Dev loss: 0.9139 r:0.5416
ne_en Dev loss: 0.6266 r:0.7286
ru_en Dev loss: 0.4964 r:0.7276
Current avg r:0.5821 Best avg r: 0.6296
08:30:34,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:32:04,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:33:35,29 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1449
en_de Dev loss: 0.9668 r:0.1607
en_zh Dev loss: 0.8462 r:0.4389
ro_en Dev loss: 0.3788 r:0.8108
et_en Dev loss: 0.5059 r:0.6620
si_en Dev loss: 0.9506 r:0.5304
ne_en Dev loss: 0.5909 r:0.7311
ru_en Dev loss: 0.4784 r:0.7299
Current avg r:0.5806 Best avg r: 0.6296
08:38:04,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:39:34,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:04,742 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1453
en_de Dev loss: 0.9455 r:0.1509
en_zh Dev loss: 0.8156 r:0.4526
ro_en Dev loss: 0.3701 r:0.8109
et_en Dev loss: 0.4885 r:0.6626
si_en Dev loss: 0.9641 r:0.5292
ne_en Dev loss: 0.6539 r:0.7245
ru_en Dev loss: 0.4838 r:0.7266
Current avg r:0.5796 Best avg r: 0.6296
08:45:34,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:04,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:48:34,528 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1460
en_de Dev loss: 0.9428 r:0.1713
en_zh Dev loss: 0.8215 r:0.4569
ro_en Dev loss: 0.3727 r:0.8143
et_en Dev loss: 0.4685 r:0.6683
si_en Dev loss: 0.9166 r:0.5375
ne_en Dev loss: 0.5740 r:0.7252
ru_en Dev loss: 0.4939 r:0.7268
Current avg r:0.5858 Best avg r: 0.6296
08:53:04,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:54:34,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:04,531 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1379
en_de Dev loss: 0.9284 r:0.1817
en_zh Dev loss: 0.7991 r:0.4568
ro_en Dev loss: 0.3544 r:0.8137
et_en Dev loss: 0.4719 r:0.6647
si_en Dev loss: 0.8131 r:0.5448
ne_en Dev loss: 0.4983 r:0.7269
ru_en Dev loss: 0.4566 r:0.7357
Current avg r:0.5892 Best avg r: 0.6296
09:00:34,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:04,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:34,551 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1448
en_de Dev loss: 0.9770 r:0.1635
en_zh Dev loss: 0.8245 r:0.4682
ro_en Dev loss: 0.3819 r:0.8134
et_en Dev loss: 0.5136 r:0.6667
si_en Dev loss: 0.8703 r:0.5482
ne_en Dev loss: 0.5305 r:0.7321
ru_en Dev loss: 0.4904 r:0.7337
Current avg r:0.5894 Best avg r: 0.6296
09:08:06,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:37,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:08,621 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1334
en_de Dev loss: 0.9630 r:0.1687
en_zh Dev loss: 0.8618 r:0.4511
ro_en Dev loss: 0.3980 r:0.8070
et_en Dev loss: 0.4978 r:0.6538
si_en Dev loss: 0.9465 r:0.5274
ne_en Dev loss: 0.6679 r:0.7221
ru_en Dev loss: 0.5127 r:0.7287
Current avg r:0.5798 Best avg r: 0.6296
09:15:41,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:17:12,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:18:43,775 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1376
en_de Dev loss: 0.9595 r:0.1698
en_zh Dev loss: 0.8026 r:0.4669
ro_en Dev loss: 0.3567 r:0.8147
et_en Dev loss: 0.4796 r:0.6691
si_en Dev loss: 0.8236 r:0.5434
ne_en Dev loss: 0.5213 r:0.7295
ru_en Dev loss: 0.4380 r:0.7496
Current avg r:0.5919 Best avg r: 0.6296
09:23:17,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:24:48,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:19,128 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1316
en_de Dev loss: 0.9800 r:0.1613
en_zh Dev loss: 0.8496 r:0.4665
ro_en Dev loss: 0.3874 r:0.8086
et_en Dev loss: 0.4958 r:0.6628
si_en Dev loss: 0.8874 r:0.5449
ne_en Dev loss: 0.5741 r:0.7203
ru_en Dev loss: 0.4813 r:0.7364
Current avg r:0.5858 Best avg r: 0.6296
09:30:51,705 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:32:21,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:33:52,53 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1319
en_de Dev loss: 0.9404 r:0.1597
en_zh Dev loss: 0.7814 r:0.4632
ro_en Dev loss: 0.3556 r:0.8125
et_en Dev loss: 0.4762 r:0.6735
si_en Dev loss: 0.8248 r:0.5447
ne_en Dev loss: 0.5407 r:0.7257
ru_en Dev loss: 0.4382 r:0.7388
Current avg r:0.5883 Best avg r: 0.6296
09:38:21,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:39:51,934 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:41:22,136 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1344
en_de Dev loss: 0.9591 r:0.1483
en_zh Dev loss: 0.8633 r:0.4494
ro_en Dev loss: 0.3838 r:0.8124
et_en Dev loss: 0.4982 r:0.6628
si_en Dev loss: 0.9764 r:0.5314
ne_en Dev loss: 0.6203 r:0.7241
ru_en Dev loss: 0.5054 r:0.7202
Current avg r:0.5784 Best avg r: 0.6296
09:45:51,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:22,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:48:52,369 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1301
en_de Dev loss: 0.9747 r:0.1540
en_zh Dev loss: 0.8905 r:0.4562
ro_en Dev loss: 0.4224 r:0.8113
et_en Dev loss: 0.4902 r:0.6589
si_en Dev loss: 1.0037 r:0.5316
ne_en Dev loss: 0.6548 r:0.7232
ru_en Dev loss: 0.5276 r:0.7333
Current avg r:0.5812 Best avg r: 0.6296
09:53:22,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:54:52,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:22,392 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1319
en_de Dev loss: 0.9652 r:0.1596
en_zh Dev loss: 0.8303 r:0.4561
ro_en Dev loss: 0.3640 r:0.8148
et_en Dev loss: 0.4884 r:0.6720
si_en Dev loss: 0.9056 r:0.5443
ne_en Dev loss: 0.5803 r:0.7233
ru_en Dev loss: 0.4909 r:0.7265
Current avg r:0.5852 Best avg r: 0.6296
10:00:52,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:22,408 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:52,671 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1288
en_de Dev loss: 1.0018 r:0.1446
en_zh Dev loss: 0.8765 r:0.4517
ro_en Dev loss: 0.3716 r:0.8149
et_en Dev loss: 0.4908 r:0.6575
si_en Dev loss: 0.9538 r:0.5323
ne_en Dev loss: 0.6513 r:0.7116
ru_en Dev loss: 0.4774 r:0.7388
Current avg r:0.5788 Best avg r: 0.6296
10:08:23,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:09:53,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:23,595 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1344
en_de Dev loss: 0.9577 r:0.1442
en_zh Dev loss: 0.8619 r:0.4481
ro_en Dev loss: 0.3849 r:0.8136
et_en Dev loss: 0.4723 r:0.6589
si_en Dev loss: 1.0139 r:0.5288
ne_en Dev loss: 0.7178 r:0.7148
ru_en Dev loss: 0.5041 r:0.7252
Current avg r:0.5762 Best avg r: 0.6296
10:15:53,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:17:23,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:18:54,21 root INFO Epoch 13 Global steps: 109900 Train loss: 0.1343
en_de Dev loss: 0.9408 r:0.1517
en_zh Dev loss: 0.7881 r:0.4644
ro_en Dev loss: 0.3641 r:0.8154
et_en Dev loss: 0.4660 r:0.6646
si_en Dev loss: 0.9651 r:0.5302
ne_en Dev loss: 0.6064 r:0.7190
ru_en Dev loss: 0.4482 r:0.7417
Current avg r:0.5839 Best avg r: 0.6296
10:23:23,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:54,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:24,234 root INFO Epoch 13 Global steps: 110600 Train loss: 0.1308
en_de Dev loss: 0.9679 r:0.1195
en_zh Dev loss: 0.8114 r:0.4624
ro_en Dev loss: 0.3597 r:0.8160
et_en Dev loss: 0.4656 r:0.6543
si_en Dev loss: 0.9482 r:0.5274
ne_en Dev loss: 0.5963 r:0.7167
ru_en Dev loss: 0.4986 r:0.7245
Current avg r:0.5744 Best avg r: 0.6296
10:30:53,827 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:32:23,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
