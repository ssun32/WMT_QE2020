14:36:52,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:30,593 root INFO 
id:ro_en cur r: 0.5316 best r: 0.5316
14:37:43,478 root INFO 
id:et_en cur r: 0.4436 best r: 0.4436
14:37:56,362 root INFO 
id:si_en cur r: 0.3871 best r: 0.3871
14:38:09,247 root INFO 
id:ne_en cur r: 0.5288 best r: 0.5288
14:38:22,82 root INFO 
id:ru_en cur r: 0.6050 best r: 0.6050
14:38:22,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:52,26 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
14:39:52,33 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:39:52,38 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:39:52,43 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
14:39:52,47 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
14:39:52,52 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:39:52,57 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:40:06,311 root INFO Epoch 0 Global steps: 700 Train loss: 0.8614
en_de Dev loss: 0.8912 r:0.0887
en_zh Dev loss: 0.7880 r:0.2049
ro_en Dev loss: 0.6500 r:0.5613
et_en Dev loss: 0.6158 r:0.4435
si_en Dev loss: 0.6977 r:0.3996
ne_en Dev loss: 0.6258 r:0.5409
ru_en Dev loss: 0.5702 r:0.6177
Current avg r:0.4081 Best avg r: 0.4081
14:44:35,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:01,255 root INFO 
id:en_de cur r: 0.1108 best r: 0.1108
14:45:14,100 root INFO 
id:en_zh cur r: 0.0244 best r: 0.0244
14:45:26,989 root INFO 
id:ro_en cur r: 0.5686 best r: 0.5686
14:45:52,759 root INFO 
id:si_en cur r: 0.4261 best r: 0.4261
14:46:05,638 root INFO 
id:ne_en cur r: 0.6038 best r: 0.6038
14:46:18,466 root INFO 
id:ru_en cur r: 0.6444 best r: 0.6444
14:46:18,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:48,469 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
14:47:48,476 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:47:48,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:47:48,488 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
14:47:48,494 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
14:47:48,500 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:47:48,506 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:48:01,404 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8057
en_de Dev loss: 0.9333 r:0.1020
en_zh Dev loss: 0.7842 r:0.2487
ro_en Dev loss: 0.6274 r:0.6527
et_en Dev loss: 0.5928 r:0.4738
si_en Dev loss: 0.7138 r:0.4470
ne_en Dev loss: 0.5700 r:0.5496
ru_en Dev loss: 0.5421 r:0.6631
Current avg r:0.4481 Best avg r: 0.4481
14:52:31,398 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:57,133 root INFO 
id:en_zh cur r: 0.1607 best r: 0.1607
14:53:10,10 root INFO 
id:ro_en cur r: 0.6447 best r: 0.6447
14:53:22,890 root INFO 
id:et_en cur r: 0.5604 best r: 0.5604
14:53:35,786 root INFO 
id:si_en cur r: 0.4433 best r: 0.4433
14:53:48,675 root INFO 
id:ne_en cur r: 0.6380 best r: 0.6380
14:54:01,502 root INFO 
id:ru_en cur r: 0.6699 best r: 0.6699
14:54:01,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:31,513 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
14:55:31,520 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:55:31,525 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:55:31,532 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
14:55:31,537 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
14:55:31,542 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:55:31,549 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:55:44,433 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7259
en_de Dev loss: 0.9820 r:0.0659
en_zh Dev loss: 0.7814 r:0.2488
ro_en Dev loss: 0.4968 r:0.6834
et_en Dev loss: 0.4842 r:0.5905
si_en Dev loss: 0.6652 r:0.4639
ne_en Dev loss: 0.5187 r:0.6087
ru_en Dev loss: 0.4840 r:0.6714
Current avg r:0.4761 Best avg r: 0.4761
15:00:14,318 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:40,33 root INFO 
id:en_zh cur r: 0.2314 best r: 0.2314
15:00:52,914 root INFO 
id:ro_en cur r: 0.6591 best r: 0.6591
15:01:18,698 root INFO 
id:si_en cur r: 0.4551 best r: 0.4551
15:01:44,404 root INFO 
id:ru_en cur r: 0.6826 best r: 0.6826
15:01:44,405 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:14,408 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:03:14,415 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:03:14,421 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:03:14,426 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:03:14,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:03:14,442 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:03:14,447 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:03:27,313 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7018
en_de Dev loss: 1.0152 r:0.0857
en_zh Dev loss: 0.7908 r:0.2895
ro_en Dev loss: 0.5208 r:0.6964
et_en Dev loss: 0.4812 r:0.5890
si_en Dev loss: 0.6898 r:0.4814
ne_en Dev loss: 0.5182 r:0.6062
ru_en Dev loss: 0.4854 r:0.6990
Current avg r:0.4925 Best avg r: 0.4925
15:07:57,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:23,137 root INFO 
id:en_de cur r: 0.1226 best r: 0.1226
15:08:35,992 root INFO 
id:en_zh cur r: 0.2322 best r: 0.2322
15:09:40,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:10,340 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6709
en_de Dev loss: 1.0579 r:0.1309
en_zh Dev loss: 0.8629 r:0.3060
ro_en Dev loss: 0.5955 r:0.6919
et_en Dev loss: 0.5083 r:0.5875
si_en Dev loss: 0.8247 r:0.4619
ne_en Dev loss: 0.5593 r:0.5881
ru_en Dev loss: 0.6392 r:0.6430
Current avg r:0.4870 Best avg r: 0.4925
15:15:40,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:06,316 root INFO 
id:en_zh cur r: 0.3135 best r: 0.3135
15:16:19,191 root INFO 
id:ro_en cur r: 0.7108 best r: 0.7108
15:16:32,90 root INFO 
id:et_en cur r: 0.6529 best r: 0.6529
15:16:45,4 root INFO 
id:si_en cur r: 0.4885 best r: 0.4885
15:16:57,894 root INFO 
id:ne_en cur r: 0.6776 best r: 0.6776
15:17:10,717 root INFO 
id:ru_en cur r: 0.7079 best r: 0.7079
15:17:10,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:40,677 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:18:40,684 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:18:40,689 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:18:40,694 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:18:40,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:18:40,706 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:18:40,711 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:18:53,602 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6647
en_de Dev loss: 0.9508 r:0.1192
en_zh Dev loss: 0.7176 r:0.3656
ro_en Dev loss: 0.4262 r:0.7393
et_en Dev loss: 0.4167 r:0.6804
si_en Dev loss: 0.6343 r:0.5335
ne_en Dev loss: 0.4415 r:0.6921
ru_en Dev loss: 0.4349 r:0.7431
Current avg r:0.5533 Best avg r: 0.5533
15:23:23,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:28,213 root INFO 
id:si_en cur r: 0.4886 best r: 0.4886
15:24:53,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:23,847 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5938
en_de Dev loss: 1.0520 r:0.1304
en_zh Dev loss: 0.8135 r:0.3562
ro_en Dev loss: 0.4722 r:0.7341
et_en Dev loss: 0.3980 r:0.6698
si_en Dev loss: 0.7275 r:0.5151
ne_en Dev loss: 0.5442 r:0.6394
ru_en Dev loss: 0.5699 r:0.7095
Current avg r:0.5363 Best avg r: 0.5533
15:30:53,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:19,391 root INFO 
id:en_de cur r: 0.1307 best r: 0.1307
15:31:32,241 root INFO 
id:en_zh cur r: 0.3575 best r: 0.3575
15:31:45,131 root INFO 
id:ro_en cur r: 0.7345 best r: 0.7345
15:31:58,7 root INFO 
id:et_en cur r: 0.6616 best r: 0.6616
15:32:36,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:06,510 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:34:06,516 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:34:06,522 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:34:06,528 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:34:06,533 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:34:06,538 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:34:06,542 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:34:19,404 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6044
en_de Dev loss: 0.9441 r:0.1511
en_zh Dev loss: 0.7038 r:0.3968
ro_en Dev loss: 0.3986 r:0.7522
et_en Dev loss: 0.3864 r:0.6756
si_en Dev loss: 0.6956 r:0.5282
ne_en Dev loss: 0.4669 r:0.6710
ru_en Dev loss: 0.4918 r:0.7216
Current avg r:0.5566 Best avg r: 0.5566
15:38:49,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:14,807 root INFO 
id:en_zh cur r: 0.3889 best r: 0.3889
15:39:27,679 root INFO 
id:ro_en cur r: 0.7489 best r: 0.7489
15:39:40,557 root INFO 
id:et_en cur r: 0.6812 best r: 0.6812
15:39:53,463 root INFO 
id:si_en cur r: 0.5249 best r: 0.5249
15:40:06,348 root INFO 
id:ne_en cur r: 0.7027 best r: 0.7027
15:40:19,170 root INFO 
id:ru_en cur r: 0.7110 best r: 0.7110
15:40:19,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:49,188 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:41:49,194 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:41:49,199 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:41:49,203 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:41:49,211 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:41:49,216 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:41:49,221 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:42:02,85 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5857
en_de Dev loss: 0.9262 r:0.1722
en_zh Dev loss: 0.6945 r:0.4097
ro_en Dev loss: 0.3825 r:0.7599
et_en Dev loss: 0.3718 r:0.6905
si_en Dev loss: 0.6144 r:0.5513
ne_en Dev loss: 0.4083 r:0.6967
ru_en Dev loss: 0.4473 r:0.7448
Current avg r:0.5750 Best avg r: 0.5750
15:46:31,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:57,527 root INFO 
id:en_de cur r: 0.1554 best r: 0.1554
15:47:10,372 root INFO 
id:en_zh cur r: 0.4072 best r: 0.4072
15:47:23,247 root INFO 
id:ro_en cur r: 0.7635 best r: 0.7635
15:47:49,8 root INFO 
id:si_en cur r: 0.5373 best r: 0.5373
15:48:01,895 root INFO 
id:ne_en cur r: 0.7163 best r: 0.7163
15:48:14,728 root INFO 
id:ru_en cur r: 0.7466 best r: 0.7466
15:48:14,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:44,739 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:49:44,746 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:49:44,751 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:49:44,756 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:49:44,760 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:49:44,766 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:49:44,771 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:49:57,633 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5899
en_de Dev loss: 0.9347 r:0.1785
en_zh Dev loss: 0.7289 r:0.4164
ro_en Dev loss: 0.3966 r:0.7684
et_en Dev loss: 0.3768 r:0.6867
si_en Dev loss: 0.7402 r:0.5383
ne_en Dev loss: 0.4152 r:0.7021
ru_en Dev loss: 0.4375 r:0.7611
Current avg r:0.5788 Best avg r: 0.5788
15:54:27,398 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:53,145 root INFO 
id:en_de cur r: 0.1701 best r: 0.1701
15:56:10,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:57:40,277 root INFO Epoch 0 Global steps: 7700 Train loss: 0.6101
en_de Dev loss: 0.9790 r:0.1836
en_zh Dev loss: 0.8373 r:0.4136
ro_en Dev loss: 0.4338 r:0.7698
et_en Dev loss: 0.4181 r:0.6725
si_en Dev loss: 0.7746 r:0.5358
ne_en Dev loss: 0.5567 r:0.6689
ru_en Dev loss: 0.5447 r:0.7328
Current avg r:0.5681 Best avg r: 0.5788
16:02:10,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:02:36,661 root INFO 
id:en_de cur r: 0.1916 best r: 0.1916
16:03:53,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:23,841 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5155
en_de Dev loss: 0.9584 r:0.2012
en_zh Dev loss: 0.7719 r:0.4127
ro_en Dev loss: 0.4370 r:0.7705
et_en Dev loss: 0.3995 r:0.6809
si_en Dev loss: 0.7150 r:0.5465
ne_en Dev loss: 0.5412 r:0.6836
ru_en Dev loss: 0.5223 r:0.7299
Current avg r:0.5751 Best avg r: 0.5788
16:09:53,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:19,392 root INFO 
id:en_de cur r: 0.2046 best r: 0.2046
16:10:32,226 root INFO 
id:en_zh cur r: 0.4180 best r: 0.4180
16:10:45,93 root INFO 
id:ro_en cur r: 0.7809 best r: 0.7809
16:10:57,985 root INFO 
id:et_en cur r: 0.6833 best r: 0.6833
16:11:10,869 root INFO 
id:si_en cur r: 0.5466 best r: 0.5466
16:11:23,749 root INFO 
id:ne_en cur r: 0.7323 best r: 0.7323
16:11:36,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:06,519 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
16:13:06,526 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:13:06,531 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:13:06,537 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
16:13:06,542 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
16:13:06,547 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:13:06,551 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:13:19,402 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5388
en_de Dev loss: 1.0334 r:0.2149
en_zh Dev loss: 0.8466 r:0.4293
ro_en Dev loss: 0.4422 r:0.7893
et_en Dev loss: 0.3982 r:0.6971
si_en Dev loss: 0.8212 r:0.5584
ne_en Dev loss: 0.4736 r:0.7103
ru_en Dev loss: 0.5382 r:0.7498
Current avg r:0.5927 Best avg r: 0.5927
16:17:49,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:14,944 root INFO 
id:en_zh cur r: 0.4255 best r: 0.4255
16:18:27,811 root INFO 
id:ro_en cur r: 0.7874 best r: 0.7874
16:18:40,697 root INFO 
id:et_en cur r: 0.6856 best r: 0.6856
16:18:53,586 root INFO 
id:si_en cur r: 0.5694 best r: 0.5694
16:19:06,475 root INFO 
id:ne_en cur r: 0.7398 best r: 0.7398
16:19:19,298 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:50,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
16:20:50,706 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:20:50,711 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:20:50,716 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
16:20:50,721 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
16:20:50,726 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:20:50,731 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:21:03,599 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5320
en_de Dev loss: 0.9218 r:0.1858
en_zh Dev loss: 0.7345 r:0.4377
ro_en Dev loss: 0.3691 r:0.7955
et_en Dev loss: 0.3707 r:0.6972
si_en Dev loss: 0.7051 r:0.5780
ne_en Dev loss: 0.4688 r:0.7238
ru_en Dev loss: 0.4849 r:0.7532
Current avg r:0.5959 Best avg r: 0.5959
16:25:33,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:12,366 root INFO 
id:ro_en cur r: 0.7989 best r: 0.7989
16:26:25,252 root INFO 
id:et_en cur r: 0.6869 best r: 0.6869
16:26:51,32 root INFO 
id:ne_en cur r: 0.7495 best r: 0.7495
16:27:03,869 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:33,825 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
16:28:33,831 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:28:33,836 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:28:33,840 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
16:28:33,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
16:28:33,854 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:28:33,861 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:28:46,735 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5310
en_de Dev loss: 0.9443 r:0.1998
en_zh Dev loss: 0.7934 r:0.4392
ro_en Dev loss: 0.4162 r:0.8031
et_en Dev loss: 0.3902 r:0.6963
si_en Dev loss: 0.7036 r:0.5845
ne_en Dev loss: 0.4150 r:0.7375
ru_en Dev loss: 0.5441 r:0.7385
Current avg r:0.5998 Best avg r: 0.5998
16:33:16,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:08,80 root INFO 
id:et_en cur r: 0.6906 best r: 0.6906
16:34:20,962 root INFO 
id:si_en cur r: 0.5899 best r: 0.5899
16:34:46,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:36:16,609 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
16:36:16,615 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:36:16,620 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:36:16,626 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
16:36:16,631 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
16:36:16,635 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:36:16,640 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:36:29,511 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5182
en_de Dev loss: 0.8836 r:0.2069
en_zh Dev loss: 0.7032 r:0.4375
ro_en Dev loss: 0.3459 r:0.7951
et_en Dev loss: 0.3618 r:0.7004
si_en Dev loss: 0.5974 r:0.5928
ne_en Dev loss: 0.4056 r:0.7259
ru_en Dev loss: 0.4404 r:0.7510
Current avg r:0.6014 Best avg r: 0.6014
16:40:59,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:25,313 root INFO 
id:en_zh cur r: 0.4279 best r: 0.4279
16:42:29,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:59,657 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5283
en_de Dev loss: 0.8919 r:0.2034
en_zh Dev loss: 0.7408 r:0.4434
ro_en Dev loss: 0.3499 r:0.7987
et_en Dev loss: 0.3790 r:0.6934
si_en Dev loss: 0.7572 r:0.5742
ne_en Dev loss: 0.4433 r:0.7311
ru_en Dev loss: 0.4876 r:0.7371
Current avg r:0.5973 Best avg r: 0.6014
16:48:29,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:54,790 root INFO 
id:en_de cur r: 0.2060 best r: 0.2060
16:49:07,623 root INFO 
id:en_zh cur r: 0.4510 best r: 0.4510
16:49:20,486 root INFO 
id:ro_en cur r: 0.8141 best r: 0.8141
16:49:33,344 root INFO 
id:et_en cur r: 0.7082 best r: 0.7082
16:49:46,214 root INFO 
id:si_en cur r: 0.6142 best r: 0.6142
16:49:59,108 root INFO 
id:ne_en cur r: 0.7667 best r: 0.7667
16:50:11,921 root INFO 
id:ru_en cur r: 0.7572 best r: 0.7572
16:50:11,922 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:51:41,821 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
16:51:41,827 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:51:41,831 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:51:41,836 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
16:51:41,841 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
16:51:41,846 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:51:41,851 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:51:54,709 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4998
en_de Dev loss: 0.8525 r:0.2240
en_zh Dev loss: 0.6601 r:0.4521
ro_en Dev loss: 0.3051 r:0.8111
et_en Dev loss: 0.3615 r:0.7126
si_en Dev loss: 0.5562 r:0.6125
ne_en Dev loss: 0.3464 r:0.7603
ru_en Dev loss: 0.3618 r:0.7648
Current avg r:0.6196 Best avg r: 0.6196
16:56:24,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:49,877 root INFO 
id:en_de cur r: 0.2078 best r: 0.2078
16:58:06,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:59:36,787 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5103
en_de Dev loss: 0.8580 r:0.2003
en_zh Dev loss: 0.6984 r:0.4500
ro_en Dev loss: 0.3243 r:0.8048
et_en Dev loss: 0.3738 r:0.6990
si_en Dev loss: 0.5896 r:0.5896
ne_en Dev loss: 0.4057 r:0.7498
ru_en Dev loss: 0.4041 r:0.7482
Current avg r:0.6060 Best avg r: 0.6196
17:04:05,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:31,294 root INFO 
id:en_zh cur r: 0.4641 best r: 0.4641
17:04:44,147 root INFO 
id:ro_en cur r: 0.8143 best r: 0.8143
17:05:35,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:05,457 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5231
en_de Dev loss: 0.8488 r:0.2105
en_zh Dev loss: 0.6540 r:0.4657
ro_en Dev loss: 0.3062 r:0.8120
et_en Dev loss: 0.3766 r:0.7057
si_en Dev loss: 0.5469 r:0.6094
ne_en Dev loss: 0.3559 r:0.7516
ru_en Dev loss: 0.3747 r:0.7555
Current avg r:0.6158 Best avg r: 0.6196
17:11:34,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:04,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:14:34,308 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5229
en_de Dev loss: 0.9271 r:0.2024
en_zh Dev loss: 0.7707 r:0.4476
ro_en Dev loss: 0.3713 r:0.8079
et_en Dev loss: 0.3988 r:0.6975
si_en Dev loss: 0.6733 r:0.5957
ne_en Dev loss: 0.4223 r:0.7434
ru_en Dev loss: 0.5657 r:0.7205
Current avg r:0.6022 Best avg r: 0.6196
17:19:03,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:42,94 root INFO 
id:ro_en cur r: 0.8188 best r: 0.8188
17:20:33,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:03,488 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5003
en_de Dev loss: 0.9028 r:0.2056
en_zh Dev loss: 0.7408 r:0.4585
ro_en Dev loss: 0.3336 r:0.8149
et_en Dev loss: 0.3645 r:0.7068
si_en Dev loss: 0.7018 r:0.5882
ne_en Dev loss: 0.4103 r:0.7465
ru_en Dev loss: 0.4946 r:0.7385
Current avg r:0.6084 Best avg r: 0.6196
17:26:33,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:03,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:33,728 root INFO Epoch 2 Global steps: 16100 Train loss: 0.4827
en_de Dev loss: 0.8563 r:0.2125
en_zh Dev loss: 0.6881 r:0.4573
ro_en Dev loss: 0.3225 r:0.8129
et_en Dev loss: 0.3725 r:0.7016
si_en Dev loss: 0.6816 r:0.5857
ne_en Dev loss: 0.3814 r:0.7528
ru_en Dev loss: 0.4052 r:0.7485
Current avg r:0.6102 Best avg r: 0.6196
17:34:03,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:41,592 root INFO 
id:ro_en cur r: 0.8190 best r: 0.8190
17:35:32,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:02,835 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4586
en_de Dev loss: 0.8879 r:0.2054
en_zh Dev loss: 0.7518 r:0.4495
ro_en Dev loss: 0.3357 r:0.8154
et_en Dev loss: 0.3920 r:0.6978
si_en Dev loss: 0.6619 r:0.5928
ne_en Dev loss: 0.4100 r:0.7462
ru_en Dev loss: 0.4774 r:0.7377
Current avg r:0.6064 Best avg r: 0.6196
17:41:31,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:01,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:31,721 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4602
en_de Dev loss: 0.9041 r:0.2122
en_zh Dev loss: 0.7560 r:0.4478
ro_en Dev loss: 0.3562 r:0.8112
et_en Dev loss: 0.3991 r:0.6937
si_en Dev loss: 0.7421 r:0.5737
ne_en Dev loss: 0.4426 r:0.7428
ru_en Dev loss: 0.4813 r:0.7386
Current avg r:0.6029 Best avg r: 0.6196
17:49:01,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:26,738 root INFO 
id:en_de cur r: 0.2176 best r: 0.2176
17:50:43,812 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:13,717 root INFO Epoch 2 Global steps: 18200 Train loss: 0.4791
en_de Dev loss: 0.8983 r:0.2164
en_zh Dev loss: 0.7834 r:0.4470
ro_en Dev loss: 0.3857 r:0.8048
et_en Dev loss: 0.4131 r:0.6877
si_en Dev loss: 0.8808 r:0.5658
ne_en Dev loss: 0.5814 r:0.7371
ru_en Dev loss: 0.5600 r:0.7056
Current avg r:0.5949 Best avg r: 0.6196
17:56:42,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:21,480 root INFO 
id:ro_en cur r: 0.8233 best r: 0.8233
17:57:47,231 root INFO 
id:si_en cur r: 0.6158 best r: 0.6158
17:58:12,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:42,723 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4600
en_de Dev loss: 0.8591 r:0.2196
en_zh Dev loss: 0.6780 r:0.4525
ro_en Dev loss: 0.2928 r:0.8228
et_en Dev loss: 0.3603 r:0.7044
si_en Dev loss: 0.6180 r:0.6035
ne_en Dev loss: 0.3874 r:0.7610
ru_en Dev loss: 0.4134 r:0.7435
Current avg r:0.6153 Best avg r: 0.6196
18:04:13,349 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:43,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:13,149 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4597
en_de Dev loss: 0.8725 r:0.2279
en_zh Dev loss: 0.7255 r:0.4524
ro_en Dev loss: 0.3287 r:0.8161
et_en Dev loss: 0.3849 r:0.6954
si_en Dev loss: 0.6057 r:0.6107
ne_en Dev loss: 0.3719 r:0.7555
ru_en Dev loss: 0.4526 r:0.7474
Current avg r:0.6151 Best avg r: 0.6196
18:11:42,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:07,762 root INFO 
id:en_de cur r: 0.2494 best r: 0.2494
18:13:24,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:54,738 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4632
en_de Dev loss: 0.8901 r:0.2338
en_zh Dev loss: 0.7248 r:0.4556
ro_en Dev loss: 0.3469 r:0.8141
et_en Dev loss: 0.3997 r:0.6830
si_en Dev loss: 0.6671 r:0.5868
ne_en Dev loss: 0.4357 r:0.7442
ru_en Dev loss: 0.5503 r:0.7058
Current avg r:0.6033 Best avg r: 0.6196
18:19:23,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:02,151 root INFO 
id:ro_en cur r: 0.8255 best r: 0.8255
18:20:27,899 root INFO 
id:si_en cur r: 0.6169 best r: 0.6169
18:20:53,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:23,475 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4709
en_de Dev loss: 0.8639 r:0.2426
en_zh Dev loss: 0.6976 r:0.4627
ro_en Dev loss: 0.3424 r:0.8236
et_en Dev loss: 0.3833 r:0.6974
si_en Dev loss: 0.6759 r:0.6074
ne_en Dev loss: 0.3897 r:0.7588
ru_en Dev loss: 0.4590 r:0.7411
Current avg r:0.6191 Best avg r: 0.6196
18:26:52,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:22,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:52,376 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4472
en_de Dev loss: 0.8897 r:0.2147
en_zh Dev loss: 0.7440 r:0.4491
ro_en Dev loss: 0.3661 r:0.8140
et_en Dev loss: 0.4155 r:0.6849
si_en Dev loss: 0.7483 r:0.5919
ne_en Dev loss: 0.4312 r:0.7567
ru_en Dev loss: 0.4327 r:0.7525
Current avg r:0.6091 Best avg r: 0.6196
18:34:21,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:46,859 root INFO 
id:en_de cur r: 0.2553 best r: 0.2553
18:34:59,690 root INFO 
id:en_zh cur r: 0.4688 best r: 0.4688
18:36:03,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:33,859 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
18:37:33,867 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:37:33,872 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:37:33,876 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
18:37:33,881 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
18:37:33,886 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:37:33,891 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:37:46,754 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4518
en_de Dev loss: 0.8457 r:0.2415
en_zh Dev loss: 0.6680 r:0.4664
ro_en Dev loss: 0.3071 r:0.8217
et_en Dev loss: 0.3911 r:0.6981
si_en Dev loss: 0.6207 r:0.6103
ne_en Dev loss: 0.3681 r:0.7648
ru_en Dev loss: 0.3797 r:0.7578
Current avg r:0.6229 Best avg r: 0.6229
18:42:16,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:46,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:15,881 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4627
en_de Dev loss: 0.8763 r:0.2192
en_zh Dev loss: 0.7488 r:0.4591
ro_en Dev loss: 0.3492 r:0.8179
et_en Dev loss: 0.4006 r:0.6894
si_en Dev loss: 0.8032 r:0.5965
ne_en Dev loss: 0.5518 r:0.7536
ru_en Dev loss: 0.5003 r:0.7301
Current avg r:0.6094 Best avg r: 0.6229
18:49:44,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:14,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:44,289 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4676
en_de Dev loss: 0.8737 r:0.2136
en_zh Dev loss: 0.7662 r:0.4411
ro_en Dev loss: 0.3436 r:0.8145
et_en Dev loss: 0.3838 r:0.6865
si_en Dev loss: 0.7794 r:0.5952
ne_en Dev loss: 0.4976 r:0.7493
ru_en Dev loss: 0.4805 r:0.7262
Current avg r:0.6038 Best avg r: 0.6229
18:57:15,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:53,609 root INFO 
id:ro_en cur r: 0.8266 best r: 0.8266
18:58:44,994 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:14,869 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4195
en_de Dev loss: 0.8654 r:0.2300
en_zh Dev loss: 0.7214 r:0.4616
ro_en Dev loss: 0.3205 r:0.8236
et_en Dev loss: 0.3934 r:0.6948
si_en Dev loss: 0.6225 r:0.6132
ne_en Dev loss: 0.4223 r:0.7547
ru_en Dev loss: 0.4047 r:0.7565
Current avg r:0.6192 Best avg r: 0.6229
19:04:43,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:13,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:43,506 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4119
en_de Dev loss: 0.8624 r:0.2306
en_zh Dev loss: 0.7196 r:0.4667
ro_en Dev loss: 0.3643 r:0.8172
et_en Dev loss: 0.3968 r:0.6857
si_en Dev loss: 0.7298 r:0.6050
ne_en Dev loss: 0.5067 r:0.7545
ru_en Dev loss: 0.4800 r:0.7291
Current avg r:0.6127 Best avg r: 0.6229
19:12:12,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:42,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:12,67 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4247
en_de Dev loss: 0.8607 r:0.2311
en_zh Dev loss: 0.7540 r:0.4627
ro_en Dev loss: 0.3555 r:0.8185
et_en Dev loss: 0.4046 r:0.6821
si_en Dev loss: 0.7499 r:0.6006
ne_en Dev loss: 0.5112 r:0.7518
ru_en Dev loss: 0.4918 r:0.7248
Current avg r:0.6102 Best avg r: 0.6229
19:19:40,855 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:10,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:40,678 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4323
en_de Dev loss: 0.8515 r:0.2175
en_zh Dev loss: 0.7113 r:0.4568
ro_en Dev loss: 0.3168 r:0.8198
et_en Dev loss: 0.4028 r:0.6808
si_en Dev loss: 0.6568 r:0.6037
ne_en Dev loss: 0.3945 r:0.7545
ru_en Dev loss: 0.4645 r:0.7187
Current avg r:0.6074 Best avg r: 0.6229
19:27:09,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:28:39,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:09,304 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4150
en_de Dev loss: 0.9086 r:0.2273
en_zh Dev loss: 0.7867 r:0.4678
ro_en Dev loss: 0.4339 r:0.8207
et_en Dev loss: 0.4646 r:0.6809
si_en Dev loss: 0.9450 r:0.5991
ne_en Dev loss: 0.5504 r:0.7611
ru_en Dev loss: 0.5091 r:0.7407
Current avg r:0.6140 Best avg r: 0.6229
19:34:38,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:08,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:38,258 root INFO Epoch 3 Global steps: 28000 Train loss: 0.3967
en_de Dev loss: 0.8537 r:0.2162
en_zh Dev loss: 0.7208 r:0.4550
ro_en Dev loss: 0.3222 r:0.8193
et_en Dev loss: 0.4252 r:0.6830
si_en Dev loss: 0.6627 r:0.6085
ne_en Dev loss: 0.4106 r:0.7527
ru_en Dev loss: 0.4626 r:0.7185
Current avg r:0.6076 Best avg r: 0.6229
19:42:07,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:43:37,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:07,573 root INFO Epoch 3 Global steps: 28700 Train loss: 0.4207
en_de Dev loss: 0.9059 r:0.2267
en_zh Dev loss: 0.7786 r:0.4397
ro_en Dev loss: 0.3688 r:0.8221
et_en Dev loss: 0.4129 r:0.6823
si_en Dev loss: 0.7942 r:0.6077
ne_en Dev loss: 0.4999 r:0.7537
ru_en Dev loss: 0.4948 r:0.7267
Current avg r:0.6084 Best avg r: 0.6229
19:49:37,35 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:02,762 root INFO 
id:en_de cur r: 0.2604 best r: 0.2604
19:50:28,421 root INFO 
id:ro_en cur r: 0.8297 best r: 0.8297
19:51:19,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:52:49,656 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
19:52:49,665 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
19:52:49,670 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
19:52:49,675 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
19:52:49,681 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
19:52:49,686 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
19:52:49,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
19:53:02,558 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4117
en_de Dev loss: 0.8480 r:0.2427
en_zh Dev loss: 0.7099 r:0.4681
ro_en Dev loss: 0.2924 r:0.8310
et_en Dev loss: 0.3877 r:0.6964
si_en Dev loss: 0.6603 r:0.6222
ne_en Dev loss: 0.5092 r:0.7579
ru_en Dev loss: 0.4194 r:0.7553
Current avg r:0.6248 Best avg r: 0.6248
19:57:31,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:59:01,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:31,660 root INFO Epoch 3 Global steps: 30100 Train loss: 0.4252
en_de Dev loss: 0.8752 r:0.2181
en_zh Dev loss: 0.7292 r:0.4655
ro_en Dev loss: 0.3394 r:0.8235
et_en Dev loss: 0.4184 r:0.6812
si_en Dev loss: 0.7246 r:0.6065
ne_en Dev loss: 0.4362 r:0.7550
ru_en Dev loss: 0.4746 r:0.7370
Current avg r:0.6124 Best avg r: 0.6248
20:05:00,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:30,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:00,795 root INFO Epoch 3 Global steps: 30800 Train loss: 0.4180
en_de Dev loss: 0.8890 r:0.2140
en_zh Dev loss: 0.7536 r:0.4616
ro_en Dev loss: 0.3427 r:0.8252
et_en Dev loss: 0.4047 r:0.6841
si_en Dev loss: 0.6559 r:0.6168
ne_en Dev loss: 0.3832 r:0.7577
ru_en Dev loss: 0.4669 r:0.7370
Current avg r:0.6138 Best avg r: 0.6248
20:12:30,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:59,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:15:29,886 root INFO Epoch 3 Global steps: 31500 Train loss: 0.4194
en_de Dev loss: 0.8446 r:0.2322
en_zh Dev loss: 0.6949 r:0.4672
ro_en Dev loss: 0.3113 r:0.8262
et_en Dev loss: 0.3944 r:0.6868
si_en Dev loss: 0.6602 r:0.6100
ne_en Dev loss: 0.4299 r:0.7553
ru_en Dev loss: 0.4342 r:0.7376
Current avg r:0.6165 Best avg r: 0.6248
20:20:00,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:25,884 root INFO 
id:en_zh cur r: 0.4737 best r: 0.4737
20:21:04,475 root INFO 
id:si_en cur r: 0.6205 best r: 0.6205
20:21:30,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:00,55 root INFO Epoch 4 Global steps: 32200 Train loss: 0.3495
en_de Dev loss: 0.8521 r:0.2472
en_zh Dev loss: 0.7003 r:0.4746
ro_en Dev loss: 0.3189 r:0.8282
et_en Dev loss: 0.4406 r:0.6918
si_en Dev loss: 0.6605 r:0.6206
ne_en Dev loss: 0.4381 r:0.7594
ru_en Dev loss: 0.4232 r:0.7475
Current avg r:0.6242 Best avg r: 0.6248
20:27:29,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:55,121 root INFO 
id:en_de cur r: 0.2647 best r: 0.2647
20:29:12,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:30:42,46 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3492
en_de Dev loss: 0.8401 r:0.2399
en_zh Dev loss: 0.6947 r:0.4648
ro_en Dev loss: 0.3036 r:0.8238
et_en Dev loss: 0.4103 r:0.6833
si_en Dev loss: 0.6721 r:0.6129
ne_en Dev loss: 0.4200 r:0.7546
ru_en Dev loss: 0.4104 r:0.7456
Current avg r:0.6179 Best avg r: 0.6248
20:35:11,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:36,755 root INFO 
id:en_de cur r: 0.2670 best r: 0.2670
20:35:49,582 root INFO 
id:en_zh cur r: 0.4803 best r: 0.4803
20:36:02,444 root INFO 
id:ro_en cur r: 0.8304 best r: 0.8304
20:36:53,860 root INFO 
id:ru_en cur r: 0.7575 best r: 0.7575
20:36:53,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:23,792 root INFO Epoch 4 Global steps: 33600 Train loss: 0.4006
en_de Dev loss: 0.8367 r:0.2561
en_zh Dev loss: 0.6911 r:0.4825
ro_en Dev loss: 0.3051 r:0.8292
et_en Dev loss: 0.4099 r:0.6840
si_en Dev loss: 0.6923 r:0.6167
ne_en Dev loss: 0.4467 r:0.7503
ru_en Dev loss: 0.4296 r:0.7506
Current avg r:0.6242 Best avg r: 0.6248
20:42:53,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:23,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:53,246 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3778
en_de Dev loss: 0.8447 r:0.2464
en_zh Dev loss: 0.7262 r:0.4672
ro_en Dev loss: 0.3249 r:0.8232
et_en Dev loss: 0.4301 r:0.6804
si_en Dev loss: 0.6635 r:0.6085
ne_en Dev loss: 0.4469 r:0.7461
ru_en Dev loss: 0.4153 r:0.7503
Current avg r:0.6174 Best avg r: 0.6248
20:50:22,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:48,473 root INFO 
id:en_de cur r: 0.2846 best r: 0.2846
20:51:01,310 root INFO 
id:en_zh cur r: 0.4804 best r: 0.4804
20:52:05,549 root INFO 
id:ru_en cur r: 0.7576 best r: 0.7576
20:52:05,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:35,478 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
20:53:35,485 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:53:35,492 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:53:35,496 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
20:53:35,502 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
20:53:35,507 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
20:53:35,511 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
20:53:48,359 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3755
en_de Dev loss: 0.8327 r:0.2534
en_zh Dev loss: 0.6683 r:0.4807
ro_en Dev loss: 0.2876 r:0.8299
et_en Dev loss: 0.4136 r:0.6944
si_en Dev loss: 0.5786 r:0.6254
ne_en Dev loss: 0.3552 r:0.7572
ru_en Dev loss: 0.3682 r:0.7643
Current avg r:0.6293 Best avg r: 0.6293
20:58:17,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:47,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:17,458 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3801
en_de Dev loss: 0.8354 r:0.2606
en_zh Dev loss: 0.7365 r:0.4652
ro_en Dev loss: 0.3365 r:0.8243
et_en Dev loss: 0.4345 r:0.6821
si_en Dev loss: 0.6945 r:0.6093
ne_en Dev loss: 0.4490 r:0.7565
ru_en Dev loss: 0.4254 r:0.7480
Current avg r:0.6208 Best avg r: 0.6293
21:05:46,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:16,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:45,982 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3739
en_de Dev loss: 0.8685 r:0.2458
en_zh Dev loss: 0.8018 r:0.4431
ro_en Dev loss: 0.3482 r:0.8190
et_en Dev loss: 0.4277 r:0.6694
si_en Dev loss: 0.7370 r:0.6012
ne_en Dev loss: 0.4883 r:0.7544
ru_en Dev loss: 0.4731 r:0.7347
Current avg r:0.6097 Best avg r: 0.6293
21:13:15,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:45,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:15,1 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3805
en_de Dev loss: 0.8535 r:0.2607
en_zh Dev loss: 0.7923 r:0.4494
ro_en Dev loss: 0.3603 r:0.8199
et_en Dev loss: 0.4261 r:0.6736
si_en Dev loss: 0.8732 r:0.5916
ne_en Dev loss: 0.5263 r:0.7529
ru_en Dev loss: 0.4950 r:0.7249
Current avg r:0.6104 Best avg r: 0.6293
21:20:44,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:23,18 root INFO 
id:ro_en cur r: 0.8317 best r: 0.8317
21:22:14,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:44,337 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3577
en_de Dev loss: 0.8423 r:0.2445
en_zh Dev loss: 0.7417 r:0.4623
ro_en Dev loss: 0.3098 r:0.8302
et_en Dev loss: 0.4389 r:0.6856
si_en Dev loss: 0.6684 r:0.6128
ne_en Dev loss: 0.4280 r:0.7582
ru_en Dev loss: 0.4141 r:0.7469
Current avg r:0.6201 Best avg r: 0.6293
21:28:13,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:29:43,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:13,327 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3745
en_de Dev loss: 0.8842 r:0.2354
en_zh Dev loss: 0.8352 r:0.4559
ro_en Dev loss: 0.3544 r:0.8259
et_en Dev loss: 0.4318 r:0.6757
si_en Dev loss: 0.9798 r:0.5887
ne_en Dev loss: 0.5741 r:0.7555
ru_en Dev loss: 0.4740 r:0.7408
Current avg r:0.6111 Best avg r: 0.6293
21:35:42,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:12,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:42,478 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3612
en_de Dev loss: 0.8566 r:0.2415
en_zh Dev loss: 0.8019 r:0.4507
ro_en Dev loss: 0.3379 r:0.8192
et_en Dev loss: 0.4287 r:0.6717
si_en Dev loss: 0.8443 r:0.5793
ne_en Dev loss: 0.5218 r:0.7503
ru_en Dev loss: 0.4872 r:0.7182
Current avg r:0.6044 Best avg r: 0.6293
21:43:13,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:43,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:46:13,202 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3241
en_de Dev loss: 0.8399 r:0.2501
en_zh Dev loss: 0.7133 r:0.4713
ro_en Dev loss: 0.3161 r:0.8234
et_en Dev loss: 0.4274 r:0.6886
si_en Dev loss: 0.6670 r:0.6025
ne_en Dev loss: 0.3958 r:0.7590
ru_en Dev loss: 0.4350 r:0.7379
Current avg r:0.6190 Best avg r: 0.6293
21:50:42,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:52:11,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:41,813 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3445
en_de Dev loss: 0.8673 r:0.2495
en_zh Dev loss: 0.8280 r:0.4444
ro_en Dev loss: 0.3636 r:0.8169
et_en Dev loss: 0.4317 r:0.6670
si_en Dev loss: 0.8321 r:0.5898
ne_en Dev loss: 0.5337 r:0.7578
ru_en Dev loss: 0.5146 r:0.7158
Current avg r:0.6059 Best avg r: 0.6293
21:58:10,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:40,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:01:10,455 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3280
en_de Dev loss: 0.8511 r:0.2699
en_zh Dev loss: 0.8230 r:0.4519
ro_en Dev loss: 0.3829 r:0.8189
et_en Dev loss: 0.4721 r:0.6601
si_en Dev loss: 0.9223 r:0.5808
ne_en Dev loss: 0.5648 r:0.7519
ru_en Dev loss: 0.4859 r:0.7325
Current avg r:0.6094 Best avg r: 0.6293
22:05:39,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:07:09,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:08:39,490 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3385
en_de Dev loss: 0.8471 r:0.2386
en_zh Dev loss: 0.7824 r:0.4463
ro_en Dev loss: 0.3311 r:0.8251
et_en Dev loss: 0.4360 r:0.6702
si_en Dev loss: 0.7643 r:0.6005
ne_en Dev loss: 0.5388 r:0.7549
ru_en Dev loss: 0.4420 r:0.7428
Current avg r:0.6112 Best avg r: 0.6293
22:13:09,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:38,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:16:08,906 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3360
en_de Dev loss: 0.8597 r:0.2293
en_zh Dev loss: 0.8003 r:0.4397
ro_en Dev loss: 0.3637 r:0.8179
et_en Dev loss: 0.4525 r:0.6631
si_en Dev loss: 0.8435 r:0.5800
ne_en Dev loss: 0.5923 r:0.7496
ru_en Dev loss: 0.4778 r:0.7325
Current avg r:0.6017 Best avg r: 0.6293
22:20:38,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:22:07,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:37,856 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3257
en_de Dev loss: 0.8707 r:0.2329
en_zh Dev loss: 0.7738 r:0.4480
ro_en Dev loss: 0.3340 r:0.8244
et_en Dev loss: 0.4402 r:0.6748
si_en Dev loss: 0.7376 r:0.5935
ne_en Dev loss: 0.5183 r:0.7530
ru_en Dev loss: 0.4696 r:0.7365
Current avg r:0.6090 Best avg r: 0.6293
22:28:07,183 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:37,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:31:07,71 root INFO Epoch 5 Global steps: 44100 Train loss: 0.3407
en_de Dev loss: 0.8807 r:0.2175
en_zh Dev loss: 0.7900 r:0.4449
ro_en Dev loss: 0.3408 r:0.8268
et_en Dev loss: 0.4333 r:0.6753
si_en Dev loss: 0.7719 r:0.5951
ne_en Dev loss: 0.4998 r:0.7502
ru_en Dev loss: 0.4576 r:0.7381
Current avg r:0.6068 Best avg r: 0.6293
22:35:36,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:37:06,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:36,340 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3190
en_de Dev loss: 0.8670 r:0.2424
en_zh Dev loss: 0.7867 r:0.4387
ro_en Dev loss: 0.3318 r:0.8205
et_en Dev loss: 0.4405 r:0.6668
si_en Dev loss: 0.7601 r:0.5808
ne_en Dev loss: 0.5209 r:0.7406
ru_en Dev loss: 0.4816 r:0.7196
Current avg r:0.6014 Best avg r: 0.6293
22:43:05,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:35,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:05,576 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3208
en_de Dev loss: 0.8788 r:0.2367
en_zh Dev loss: 0.7865 r:0.4345
ro_en Dev loss: 0.3419 r:0.8249
et_en Dev loss: 0.4657 r:0.6727
si_en Dev loss: 0.7749 r:0.5899
ne_en Dev loss: 0.4451 r:0.7499
ru_en Dev loss: 0.4605 r:0.7415
Current avg r:0.6072 Best avg r: 0.6293
22:50:34,466 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:04,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:34,176 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3320
en_de Dev loss: 0.8736 r:0.2192
en_zh Dev loss: 0.7811 r:0.4500
ro_en Dev loss: 0.3388 r:0.8278
et_en Dev loss: 0.4508 r:0.6679
si_en Dev loss: 0.7743 r:0.5908
ne_en Dev loss: 0.4293 r:0.7518
ru_en Dev loss: 0.4777 r:0.7309
Current avg r:0.6055 Best avg r: 0.6293
22:58:03,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:33,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:02,953 root INFO Epoch 5 Global steps: 46900 Train loss: 0.3210
en_de Dev loss: 0.8544 r:0.2357
en_zh Dev loss: 0.7881 r:0.4438
ro_en Dev loss: 0.3228 r:0.8277
et_en Dev loss: 0.4461 r:0.6634
si_en Dev loss: 0.8215 r:0.5819
ne_en Dev loss: 0.4946 r:0.7517
ru_en Dev loss: 0.4692 r:0.7275
Current avg r:0.6045 Best avg r: 0.6293
23:05:31,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:01,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:31,556 root INFO Epoch 5 Global steps: 47600 Train loss: 0.3249
en_de Dev loss: 0.8731 r:0.2267
en_zh Dev loss: 0.7857 r:0.4383
ro_en Dev loss: 0.3239 r:0.8260
et_en Dev loss: 0.4367 r:0.6653
si_en Dev loss: 0.7720 r:0.5879
ne_en Dev loss: 0.4901 r:0.7521
ru_en Dev loss: 0.4691 r:0.7292
Current avg r:0.6036 Best avg r: 0.6293
23:13:02,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:32,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:02,54 root INFO Epoch 6 Global steps: 48300 Train loss: 0.2999
en_de Dev loss: 0.8886 r:0.2192
en_zh Dev loss: 0.7806 r:0.4443
ro_en Dev loss: 0.3695 r:0.8198
et_en Dev loss: 0.4664 r:0.6608
si_en Dev loss: 0.8359 r:0.5842
ne_en Dev loss: 0.4651 r:0.7528
ru_en Dev loss: 0.4664 r:0.7378
Current avg r:0.6027 Best avg r: 0.6293
23:20:31,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:01,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:31,96 root INFO Epoch 6 Global steps: 49000 Train loss: 0.3087
en_de Dev loss: 0.9085 r:0.2202
en_zh Dev loss: 0.8434 r:0.4281
ro_en Dev loss: 0.3816 r:0.8112
et_en Dev loss: 0.4593 r:0.6499
si_en Dev loss: 0.9064 r:0.5656
ne_en Dev loss: 0.6510 r:0.7382
ru_en Dev loss: 0.5501 r:0.7108
Current avg r:0.5891 Best avg r: 0.6293
23:28:00,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:30,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:00,35 root INFO Epoch 6 Global steps: 49700 Train loss: 0.2858
en_de Dev loss: 0.8846 r:0.2273
en_zh Dev loss: 0.8061 r:0.4421
ro_en Dev loss: 0.3628 r:0.8195
et_en Dev loss: 0.4730 r:0.6643
si_en Dev loss: 0.7997 r:0.5860
ne_en Dev loss: 0.5040 r:0.7463
ru_en Dev loss: 0.5195 r:0.7240
Current avg r:0.6014 Best avg r: 0.6293
23:35:29,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:59,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:28,913 root INFO Epoch 6 Global steps: 50400 Train loss: 0.2786
en_de Dev loss: 0.8775 r:0.2060
en_zh Dev loss: 0.7531 r:0.4473
ro_en Dev loss: 0.3304 r:0.8229
et_en Dev loss: 0.4537 r:0.6619
si_en Dev loss: 0.7626 r:0.5814
ne_en Dev loss: 0.4527 r:0.7475
ru_en Dev loss: 0.4547 r:0.7316
Current avg r:0.5998 Best avg r: 0.6293
23:42:57,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:27,903 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:57,770 root INFO Epoch 6 Global steps: 51100 Train loss: 0.3005
en_de Dev loss: 0.8699 r:0.2166
en_zh Dev loss: 0.7664 r:0.4313
ro_en Dev loss: 0.3302 r:0.8259
et_en Dev loss: 0.4648 r:0.6604
si_en Dev loss: 0.7736 r:0.5852
ne_en Dev loss: 0.4726 r:0.7518
ru_en Dev loss: 0.4227 r:0.7426
Current avg r:0.6020 Best avg r: 0.6293
23:50:26,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:56,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:26,363 root INFO Epoch 6 Global steps: 51800 Train loss: 0.2885
en_de Dev loss: 0.8585 r:0.2409
en_zh Dev loss: 0.7805 r:0.4587
ro_en Dev loss: 0.3362 r:0.8242
et_en Dev loss: 0.4608 r:0.6653
si_en Dev loss: 0.7983 r:0.5892
ne_en Dev loss: 0.4166 r:0.7545
ru_en Dev loss: 0.4321 r:0.7453
Current avg r:0.6111 Best avg r: 0.6293
23:57:55,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:24,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:54,808 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2773
en_de Dev loss: 0.8744 r:0.2132
en_zh Dev loss: 0.7852 r:0.4311
ro_en Dev loss: 0.3279 r:0.8254
et_en Dev loss: 0.4544 r:0.6685
si_en Dev loss: 0.7663 r:0.5877
ne_en Dev loss: 0.4453 r:0.7498
ru_en Dev loss: 0.4520 r:0.7377
Current avg r:0.6019 Best avg r: 0.6293
00:05:23,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:06:53,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:23,246 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2995
en_de Dev loss: 0.8744 r:0.2258
en_zh Dev loss: 0.8172 r:0.4351
ro_en Dev loss: 0.3574 r:0.8250
et_en Dev loss: 0.4524 r:0.6614
si_en Dev loss: 0.8237 r:0.5807
ne_en Dev loss: 0.4654 r:0.7559
ru_en Dev loss: 0.4636 r:0.7345
Current avg r:0.6026 Best avg r: 0.6293
00:12:51,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:21,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:51,670 root INFO Epoch 6 Global steps: 53900 Train loss: 0.2758
en_de Dev loss: 0.8699 r:0.2221
en_zh Dev loss: 0.8336 r:0.4253
ro_en Dev loss: 0.3333 r:0.8254
et_en Dev loss: 0.4537 r:0.6626
si_en Dev loss: 0.7832 r:0.5754
ne_en Dev loss: 0.5013 r:0.7433
ru_en Dev loss: 0.4854 r:0.7218
Current avg r:0.5966 Best avg r: 0.6293
00:20:20,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:21:50,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:20,75 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2915
en_de Dev loss: 0.8739 r:0.2275
en_zh Dev loss: 0.8272 r:0.4428
ro_en Dev loss: 0.3541 r:0.8248
et_en Dev loss: 0.4608 r:0.6655
si_en Dev loss: 0.8347 r:0.5815
ne_en Dev loss: 0.5055 r:0.7479
ru_en Dev loss: 0.4392 r:0.7460
Current avg r:0.6051 Best avg r: 0.6293
00:27:48,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:18,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:48,482 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2685
en_de Dev loss: 0.8798 r:0.2159
en_zh Dev loss: 0.7997 r:0.4429
ro_en Dev loss: 0.3414 r:0.8226
et_en Dev loss: 0.4541 r:0.6530
si_en Dev loss: 0.8437 r:0.5696
ne_en Dev loss: 0.4999 r:0.7466
ru_en Dev loss: 0.4827 r:0.7208
Current avg r:0.5959 Best avg r: 0.6293
00:35:18,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:48,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:18,585 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2650
en_de Dev loss: 0.9048 r:0.2167
en_zh Dev loss: 0.8015 r:0.4488
ro_en Dev loss: 0.3429 r:0.8247
et_en Dev loss: 0.4596 r:0.6572
si_en Dev loss: 0.7868 r:0.5839
ne_en Dev loss: 0.4803 r:0.7401
ru_en Dev loss: 0.4750 r:0.7326
Current avg r:0.6006 Best avg r: 0.6293
00:42:47,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:17,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:47,495 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2570
en_de Dev loss: 0.8943 r:0.2111
en_zh Dev loss: 0.8133 r:0.4503
ro_en Dev loss: 0.3692 r:0.8226
et_en Dev loss: 0.4585 r:0.6557
si_en Dev loss: 0.9300 r:0.5687
ne_en Dev loss: 0.6669 r:0.7429
ru_en Dev loss: 0.5028 r:0.7226
Current avg r:0.5963 Best avg r: 0.6293
00:50:16,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:45,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:53:15,818 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2513
en_de Dev loss: 0.8950 r:0.2184
en_zh Dev loss: 0.8265 r:0.4540
ro_en Dev loss: 0.3757 r:0.8216
et_en Dev loss: 0.4762 r:0.6589
si_en Dev loss: 0.8364 r:0.5836
ne_en Dev loss: 0.4932 r:0.7445
ru_en Dev loss: 0.4468 r:0.7503
Current avg r:0.6045 Best avg r: 0.6293
00:57:44,513 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:59:14,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:00:44,274 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2689
en_de Dev loss: 0.8649 r:0.2267
en_zh Dev loss: 0.7862 r:0.4518
ro_en Dev loss: 0.3973 r:0.8173
et_en Dev loss: 0.4622 r:0.6522
si_en Dev loss: 0.9826 r:0.5653
ne_en Dev loss: 0.5694 r:0.7467
ru_en Dev loss: 0.5045 r:0.7173
Current avg r:0.5967 Best avg r: 0.6293
01:05:13,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:43,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:12,901 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2432
en_de Dev loss: 0.8991 r:0.2104
en_zh Dev loss: 0.8376 r:0.4329
ro_en Dev loss: 0.3888 r:0.8168
et_en Dev loss: 0.4891 r:0.6448
si_en Dev loss: 0.8740 r:0.5687
ne_en Dev loss: 0.5134 r:0.7406
ru_en Dev loss: 0.5159 r:0.7147
Current avg r:0.5898 Best avg r: 0.6293
01:12:41,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:11,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:41,347 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2473
en_de Dev loss: 0.8930 r:0.2141
en_zh Dev loss: 0.8126 r:0.4403
ro_en Dev loss: 0.3853 r:0.8155
et_en Dev loss: 0.4709 r:0.6449
si_en Dev loss: 0.9674 r:0.5608
ne_en Dev loss: 0.5707 r:0.7462
ru_en Dev loss: 0.4885 r:0.7255
Current avg r:0.5925 Best avg r: 0.6293
01:20:10,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:40,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:10,187 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2362
en_de Dev loss: 0.8866 r:0.1987
en_zh Dev loss: 0.7586 r:0.4405
ro_en Dev loss: 0.3360 r:0.8214
et_en Dev loss: 0.4771 r:0.6556
si_en Dev loss: 0.7716 r:0.5803
ne_en Dev loss: 0.4334 r:0.7475
ru_en Dev loss: 0.4305 r:0.7338
Current avg r:0.5968 Best avg r: 0.6293
01:27:39,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:09,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:39,71 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2668
en_de Dev loss: 0.8611 r:0.2109
en_zh Dev loss: 0.7153 r:0.4550
ro_en Dev loss: 0.3113 r:0.8249
et_en Dev loss: 0.4385 r:0.6622
si_en Dev loss: 0.8122 r:0.5714
ne_en Dev loss: 0.5390 r:0.7335
ru_en Dev loss: 0.3942 r:0.7513
Current avg r:0.6013 Best avg r: 0.6293
01:35:07,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:36:37,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:07,357 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2502
en_de Dev loss: 0.8821 r:0.2275
en_zh Dev loss: 0.7858 r:0.4437
ro_en Dev loss: 0.3699 r:0.8197
et_en Dev loss: 0.4971 r:0.6535
si_en Dev loss: 0.8964 r:0.5663
ne_en Dev loss: 0.5038 r:0.7391
ru_en Dev loss: 0.4724 r:0.7364
Current avg r:0.5980 Best avg r: 0.6293
01:42:36,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:05,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:35,682 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2429
en_de Dev loss: 0.8504 r:0.2234
en_zh Dev loss: 0.7388 r:0.4438
ro_en Dev loss: 0.3065 r:0.8236
et_en Dev loss: 0.4512 r:0.6556
si_en Dev loss: 0.7673 r:0.5740
ne_en Dev loss: 0.4991 r:0.7463
ru_en Dev loss: 0.4042 r:0.7379
Current avg r:0.6007 Best avg r: 0.6293
01:50:04,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:33,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:53:03,679 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2385
en_de Dev loss: 0.8704 r:0.2248
en_zh Dev loss: 0.7743 r:0.4496
ro_en Dev loss: 0.3378 r:0.8205
et_en Dev loss: 0.4857 r:0.6510
si_en Dev loss: 0.7579 r:0.5861
ne_en Dev loss: 0.4500 r:0.7448
ru_en Dev loss: 0.4141 r:0.7458
Current avg r:0.6032 Best avg r: 0.6293
01:57:33,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:59:04,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:35,355 root INFO Epoch 8 Global steps: 63700 Train loss: 0.2043
en_de Dev loss: 0.8632 r:0.2202
en_zh Dev loss: 0.7852 r:0.4371
ro_en Dev loss: 0.3489 r:0.8201
et_en Dev loss: 0.4695 r:0.6568
si_en Dev loss: 0.8259 r:0.5741
ne_en Dev loss: 0.5290 r:0.7406
ru_en Dev loss: 0.4476 r:0.7266
Current avg r:0.5965 Best avg r: 0.6293
02:05:09,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:41,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:08:12,141 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2246
en_de Dev loss: 0.8608 r:0.2200
en_zh Dev loss: 0.8053 r:0.4319
ro_en Dev loss: 0.3196 r:0.8241
et_en Dev loss: 0.4586 r:0.6537
si_en Dev loss: 0.8503 r:0.5736
ne_en Dev loss: 0.5225 r:0.7393
ru_en Dev loss: 0.4641 r:0.7208
Current avg r:0.5948 Best avg r: 0.6293
02:12:46,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:14:17,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:15:48,918 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2267
en_de Dev loss: 0.8677 r:0.2214
en_zh Dev loss: 0.7719 r:0.4498
ro_en Dev loss: 0.3255 r:0.8263
et_en Dev loss: 0.4920 r:0.6656
si_en Dev loss: 0.7346 r:0.5940
ne_en Dev loss: 0.4341 r:0.7516
ru_en Dev loss: 0.3900 r:0.7530
Current avg r:0.6088 Best avg r: 0.6293
02:20:23,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:54,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:23:25,821 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2326
en_de Dev loss: 0.8589 r:0.2459
en_zh Dev loss: 0.7712 r:0.4500
ro_en Dev loss: 0.3495 r:0.8228
et_en Dev loss: 0.4853 r:0.6610
si_en Dev loss: 0.7916 r:0.5792
ne_en Dev loss: 0.5359 r:0.7437
ru_en Dev loss: 0.4210 r:0.7476
Current avg r:0.6072 Best avg r: 0.6293
02:28:00,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:31,728 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:31:02,726 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2303
en_de Dev loss: 0.8553 r:0.2489
en_zh Dev loss: 0.7664 r:0.4491
ro_en Dev loss: 0.3375 r:0.8229
et_en Dev loss: 0.4761 r:0.6597
si_en Dev loss: 0.8003 r:0.5768
ne_en Dev loss: 0.4522 r:0.7494
ru_en Dev loss: 0.4359 r:0.7400
Current avg r:0.6067 Best avg r: 0.6293
02:35:32,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:02,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:32,648 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2260
en_de Dev loss: 0.8917 r:0.2046
en_zh Dev loss: 0.7634 r:0.4533
ro_en Dev loss: 0.3355 r:0.8233
et_en Dev loss: 0.4877 r:0.6540
si_en Dev loss: 0.7959 r:0.5777
ne_en Dev loss: 0.4669 r:0.7435
ru_en Dev loss: 0.4335 r:0.7372
Current avg r:0.5991 Best avg r: 0.6293
02:43:02,562 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:44:32,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:46:02,686 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2262
en_de Dev loss: 0.9091 r:0.2117
en_zh Dev loss: 0.7954 r:0.4453
ro_en Dev loss: 0.3643 r:0.8185
et_en Dev loss: 0.4723 r:0.6446
si_en Dev loss: 0.8435 r:0.5695
ne_en Dev loss: 0.5690 r:0.7449
ru_en Dev loss: 0.4672 r:0.7325
Current avg r:0.5953 Best avg r: 0.6293
02:50:32,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:52:02,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:32,499 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2223
en_de Dev loss: 0.8706 r:0.2182
en_zh Dev loss: 0.7847 r:0.4514
ro_en Dev loss: 0.3814 r:0.8147
et_en Dev loss: 0.4762 r:0.6382
si_en Dev loss: 0.9042 r:0.5647
ne_en Dev loss: 0.6427 r:0.7428
ru_en Dev loss: 0.4926 r:0.7156
Current avg r:0.5922 Best avg r: 0.6293
02:58:01,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:59:31,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:01:02,37 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2258
en_de Dev loss: 0.9059 r:0.2173
en_zh Dev loss: 0.8256 r:0.4420
ro_en Dev loss: 0.3681 r:0.8198
et_en Dev loss: 0.4704 r:0.6522
si_en Dev loss: 0.8578 r:0.5727
ne_en Dev loss: 0.5432 r:0.7432
ru_en Dev loss: 0.5126 r:0.7254
Current avg r:0.5961 Best avg r: 0.6293
03:05:31,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:07:01,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:32,789 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2179
en_de Dev loss: 0.8713 r:0.2272
en_zh Dev loss: 0.7726 r:0.4478
ro_en Dev loss: 0.3281 r:0.8240
et_en Dev loss: 0.4629 r:0.6600
si_en Dev loss: 0.7725 r:0.5789
ne_en Dev loss: 0.4207 r:0.7480
ru_en Dev loss: 0.4142 r:0.7427
Current avg r:0.6041 Best avg r: 0.6293
03:13:05,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:36,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:07,107 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2140
en_de Dev loss: 0.8904 r:0.2102
en_zh Dev loss: 0.8377 r:0.4457
ro_en Dev loss: 0.3714 r:0.8187
et_en Dev loss: 0.4961 r:0.6546
si_en Dev loss: 0.8476 r:0.5678
ne_en Dev loss: 0.5665 r:0.7331
ru_en Dev loss: 0.4518 r:0.7399
Current avg r:0.5957 Best avg r: 0.6293
03:20:40,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:22:10,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:41,720 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2169
en_de Dev loss: 0.8783 r:0.2349
en_zh Dev loss: 0.7815 r:0.4571
ro_en Dev loss: 0.3470 r:0.8193
et_en Dev loss: 0.5180 r:0.6420
si_en Dev loss: 0.7432 r:0.5730
ne_en Dev loss: 0.4719 r:0.7315
ru_en Dev loss: 0.4151 r:0.7423
Current avg r:0.6000 Best avg r: 0.6293
03:28:16,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:46,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:17,451 root INFO Epoch 9 Global steps: 72100 Train loss: 0.2026
en_de Dev loss: 0.8930 r:0.2286
en_zh Dev loss: 0.8108 r:0.4586
ro_en Dev loss: 0.3791 r:0.8199
et_en Dev loss: 0.4886 r:0.6534
si_en Dev loss: 0.8395 r:0.5678
ne_en Dev loss: 0.5050 r:0.7380
ru_en Dev loss: 0.4753 r:0.7392
Current avg r:0.6008 Best avg r: 0.6293
03:35:47,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:17,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:47,499 root INFO Epoch 9 Global steps: 72800 Train loss: 0.1916
en_de Dev loss: 0.8847 r:0.2469
en_zh Dev loss: 0.8129 r:0.4595
ro_en Dev loss: 0.3883 r:0.8179
et_en Dev loss: 0.4692 r:0.6512
si_en Dev loss: 0.9617 r:0.5635
ne_en Dev loss: 0.6505 r:0.7423
ru_en Dev loss: 0.4459 r:0.7514
Current avg r:0.6047 Best avg r: 0.6293
03:43:17,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:47,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:46:17,391 root INFO Epoch 9 Global steps: 73500 Train loss: 0.2054
en_de Dev loss: 0.8673 r:0.2220
en_zh Dev loss: 0.7869 r:0.4612
ro_en Dev loss: 0.3475 r:0.8203
et_en Dev loss: 0.5160 r:0.6576
si_en Dev loss: 0.7541 r:0.5767
ne_en Dev loss: 0.4596 r:0.7391
ru_en Dev loss: 0.4168 r:0.7456
Current avg r:0.6032 Best avg r: 0.6293
03:50:47,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:52:17,247 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:53:47,296 root INFO Epoch 9 Global steps: 74200 Train loss: 0.2080
en_de Dev loss: 0.8943 r:0.2340
en_zh Dev loss: 0.8508 r:0.4413
ro_en Dev loss: 0.3757 r:0.8185
et_en Dev loss: 0.5265 r:0.6427
si_en Dev loss: 0.8548 r:0.5701
ne_en Dev loss: 0.5084 r:0.7405
ru_en Dev loss: 0.4738 r:0.7266
Current avg r:0.5962 Best avg r: 0.6293
03:58:17,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:59:47,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:01:17,293 root INFO Epoch 9 Global steps: 74900 Train loss: 0.2040
en_de Dev loss: 0.8775 r:0.2204
en_zh Dev loss: 0.7776 r:0.4518
ro_en Dev loss: 0.3514 r:0.8197
et_en Dev loss: 0.4749 r:0.6549
si_en Dev loss: 0.8343 r:0.5666
ne_en Dev loss: 0.4605 r:0.7448
ru_en Dev loss: 0.4297 r:0.7413
Current avg r:0.5999 Best avg r: 0.6293
04:05:47,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:07:17,419 root INFO 
id:ru_en cur r: 0.7584 best r: 0.7584
04:07:17,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:48,262 root INFO Epoch 9 Global steps: 75600 Train loss: 0.2000
en_de Dev loss: 0.8882 r:0.1976
en_zh Dev loss: 0.7906 r:0.4381
ro_en Dev loss: 0.3533 r:0.8194
et_en Dev loss: 0.4667 r:0.6542
si_en Dev loss: 0.7828 r:0.5662
ne_en Dev loss: 0.4578 r:0.7437
ru_en Dev loss: 0.3979 r:0.7579
Current avg r:0.5967 Best avg r: 0.6293
04:13:20,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:51,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:16:22,441 root INFO Epoch 9 Global steps: 76300 Train loss: 0.1936
en_de Dev loss: 0.9182 r:0.1973
en_zh Dev loss: 0.8710 r:0.4249
ro_en Dev loss: 0.3772 r:0.8143
et_en Dev loss: 0.4945 r:0.6341
si_en Dev loss: 0.8745 r:0.5549
ne_en Dev loss: 0.5581 r:0.7390
ru_en Dev loss: 0.4928 r:0.7245
Current avg r:0.5841 Best avg r: 0.6293
04:20:55,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:22:26,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:57,280 root INFO Epoch 9 Global steps: 77000 Train loss: 0.2068
en_de Dev loss: 0.8857 r:0.2085
en_zh Dev loss: 0.8311 r:0.4388
ro_en Dev loss: 0.3554 r:0.8143
et_en Dev loss: 0.5038 r:0.6427
si_en Dev loss: 0.8555 r:0.5569
ne_en Dev loss: 0.5392 r:0.7298
ru_en Dev loss: 0.4353 r:0.7428
Current avg r:0.5905 Best avg r: 0.6293
04:28:30,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:01,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:32,281 root INFO Epoch 9 Global steps: 77700 Train loss: 0.2034
en_de Dev loss: 0.8877 r:0.2015
en_zh Dev loss: 0.7871 r:0.4434
ro_en Dev loss: 0.3485 r:0.8185
et_en Dev loss: 0.4734 r:0.6436
si_en Dev loss: 0.9246 r:0.5533
ne_en Dev loss: 0.5530 r:0.7351
ru_en Dev loss: 0.4506 r:0.7333
Current avg r:0.5898 Best avg r: 0.6293
04:36:01,787 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:37:31,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:39:01,788 root INFO Epoch 9 Global steps: 78400 Train loss: 0.1920
en_de Dev loss: 0.8915 r:0.2038
en_zh Dev loss: 0.8130 r:0.4365
ro_en Dev loss: 0.3350 r:0.8223
et_en Dev loss: 0.4789 r:0.6407
si_en Dev loss: 0.8190 r:0.5655
ne_en Dev loss: 0.5296 r:0.7320
ru_en Dev loss: 0.4807 r:0.7153
Current avg r:0.5880 Best avg r: 0.6293
04:43:31,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:45:01,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:46:31,748 root INFO Epoch 9 Global steps: 79100 Train loss: 0.1969
en_de Dev loss: 0.9063 r:0.1997
en_zh Dev loss: 0.7882 r:0.4551
ro_en Dev loss: 0.3391 r:0.8201
et_en Dev loss: 0.4821 r:0.6559
si_en Dev loss: 0.8049 r:0.5697
ne_en Dev loss: 0.4793 r:0.7297
ru_en Dev loss: 0.4370 r:0.7462
Current avg r:0.5966 Best avg r: 0.6293
04:51:02,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:52:33,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:54:03,9 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1718
en_de Dev loss: 0.9076 r:0.2145
en_zh Dev loss: 0.8187 r:0.4501
ro_en Dev loss: 0.3629 r:0.8199
et_en Dev loss: 0.4752 r:0.6482
si_en Dev loss: 0.8312 r:0.5602
ne_en Dev loss: 0.5367 r:0.7301
ru_en Dev loss: 0.5039 r:0.7326
Current avg r:0.5937 Best avg r: 0.6293
04:58:32,655 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:00:02,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:01:32,699 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1759
en_de Dev loss: 0.8912 r:0.2212
en_zh Dev loss: 0.8348 r:0.4452
ro_en Dev loss: 0.3596 r:0.8188
et_en Dev loss: 0.4879 r:0.6490
si_en Dev loss: 0.8432 r:0.5600
ne_en Dev loss: 0.5076 r:0.7291
ru_en Dev loss: 0.4646 r:0.7432
Current avg r:0.5952 Best avg r: 0.6293
05:06:01,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:07:31,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:09:01,846 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1753
en_de Dev loss: 0.8942 r:0.2088
en_zh Dev loss: 0.7906 r:0.4413
ro_en Dev loss: 0.3418 r:0.8196
et_en Dev loss: 0.4839 r:0.6491
si_en Dev loss: 0.8297 r:0.5519
ne_en Dev loss: 0.5108 r:0.7331
ru_en Dev loss: 0.4993 r:0.7209
Current avg r:0.5892 Best avg r: 0.6293
05:13:31,6 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:15:01,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:16:32,623 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1859
en_de Dev loss: 0.9091 r:0.1971
en_zh Dev loss: 0.8250 r:0.4472
ro_en Dev loss: 0.3784 r:0.8176
et_en Dev loss: 0.4723 r:0.6493
si_en Dev loss: 0.8943 r:0.5590
ne_en Dev loss: 0.5644 r:0.7348
ru_en Dev loss: 0.4993 r:0.7373
Current avg r:0.5918 Best avg r: 0.6293
05:21:06,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:22:38,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:24:09,349 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1879
en_de Dev loss: 0.8919 r:0.2052
en_zh Dev loss: 0.8238 r:0.4383
ro_en Dev loss: 0.3617 r:0.8174
et_en Dev loss: 0.4767 r:0.6459
si_en Dev loss: 0.9390 r:0.5531
ne_en Dev loss: 0.6012 r:0.7339
ru_en Dev loss: 0.4919 r:0.7238
Current avg r:0.5882 Best avg r: 0.6293
05:28:43,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:14,818 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:45,934 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1819
en_de Dev loss: 0.8802 r:0.2195
en_zh Dev loss: 0.7848 r:0.4512
ro_en Dev loss: 0.3511 r:0.8189
et_en Dev loss: 0.4913 r:0.6556
si_en Dev loss: 0.8300 r:0.5553
ne_en Dev loss: 0.4975 r:0.7306
ru_en Dev loss: 0.4343 r:0.7445
Current avg r:0.5965 Best avg r: 0.6293
05:36:20,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:51,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:39:22,560 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1768
en_de Dev loss: 0.8882 r:0.2240
en_zh Dev loss: 0.7687 r:0.4556
ro_en Dev loss: 0.3482 r:0.8195
et_en Dev loss: 0.4607 r:0.6492
si_en Dev loss: 0.8702 r:0.5552
ne_en Dev loss: 0.5521 r:0.7364
ru_en Dev loss: 0.4634 r:0.7306
Current avg r:0.5958 Best avg r: 0.6293
05:43:55,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:45:26,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:57,13 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1756
en_de Dev loss: 0.8995 r:0.2215
en_zh Dev loss: 0.8269 r:0.4582
ro_en Dev loss: 0.3996 r:0.8169
et_en Dev loss: 0.4958 r:0.6517
si_en Dev loss: 0.9323 r:0.5551
ne_en Dev loss: 0.5475 r:0.7383
ru_en Dev loss: 0.4848 r:0.7371
Current avg r:0.5970 Best avg r: 0.6293
05:51:27,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:57,189 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:54:27,321 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1745
en_de Dev loss: 0.8842 r:0.2212
en_zh Dev loss: 0.7847 r:0.4612
ro_en Dev loss: 0.3464 r:0.8218
et_en Dev loss: 0.4930 r:0.6543
si_en Dev loss: 0.8336 r:0.5571
ne_en Dev loss: 0.5097 r:0.7364
ru_en Dev loss: 0.4309 r:0.7476
Current avg r:0.5999 Best avg r: 0.6293
05:58:57,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:00:27,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:01:57,388 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1728
en_de Dev loss: 0.9047 r:0.2138
en_zh Dev loss: 0.8289 r:0.4531
ro_en Dev loss: 0.3478 r:0.8227
et_en Dev loss: 0.4831 r:0.6602
si_en Dev loss: 0.8711 r:0.5584
ne_en Dev loss: 0.5130 r:0.7386
ru_en Dev loss: 0.4650 r:0.7424
Current avg r:0.5985 Best avg r: 0.6293
06:06:27,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:57,248 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:09:27,355 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1801
en_de Dev loss: 0.8733 r:0.2246
en_zh Dev loss: 0.7509 r:0.4668
ro_en Dev loss: 0.3274 r:0.8234
et_en Dev loss: 0.4510 r:0.6573
si_en Dev loss: 0.8340 r:0.5530
ne_en Dev loss: 0.5059 r:0.7353
ru_en Dev loss: 0.4718 r:0.7331
Current avg r:0.5991 Best avg r: 0.6293
06:13:58,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:15:29,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:17:00,327 root INFO Epoch 11 Global steps: 87500 Train loss: 0.1211
en_de Dev loss: 0.9121 r:0.2112
en_zh Dev loss: 0.7947 r:0.4494
ro_en Dev loss: 0.3689 r:0.8219
et_en Dev loss: 0.4713 r:0.6546
si_en Dev loss: 0.8909 r:0.5542
ne_en Dev loss: 0.5460 r:0.7345
ru_en Dev loss: 0.4887 r:0.7353
Current avg r:0.5945 Best avg r: 0.6293
06:21:33,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:23:04,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:35,304 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1635
en_de Dev loss: 0.8951 r:0.2055
en_zh Dev loss: 0.8152 r:0.4514
ro_en Dev loss: 0.3737 r:0.8182
et_en Dev loss: 0.4960 r:0.6491
si_en Dev loss: 0.9063 r:0.5502
ne_en Dev loss: 0.5293 r:0.7363
ru_en Dev loss: 0.4703 r:0.7410
Current avg r:0.5931 Best avg r: 0.6293
06:29:08,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:39,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:10,450 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1622
en_de Dev loss: 0.8903 r:0.2103
en_zh Dev loss: 0.7875 r:0.4633
ro_en Dev loss: 0.3454 r:0.8218
et_en Dev loss: 0.4793 r:0.6540
si_en Dev loss: 0.8529 r:0.5590
ne_en Dev loss: 0.5185 r:0.7283
ru_en Dev loss: 0.4706 r:0.7375
Current avg r:0.5963 Best avg r: 0.6293
06:36:43,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:38:14,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:45,422 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1636
en_de Dev loss: 0.8819 r:0.2005
en_zh Dev loss: 0.7315 r:0.4754
ro_en Dev loss: 0.3232 r:0.8240
et_en Dev loss: 0.5023 r:0.6675
si_en Dev loss: 0.7610 r:0.5687
ne_en Dev loss: 0.4187 r:0.7414
ru_en Dev loss: 0.4020 r:0.7528
Current avg r:0.6043 Best avg r: 0.6293
06:44:17,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:48,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:47:19,545 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1577
en_de Dev loss: 0.9011 r:0.2065
en_zh Dev loss: 0.7641 r:0.4716
ro_en Dev loss: 0.3477 r:0.8208
et_en Dev loss: 0.5176 r:0.6508
si_en Dev loss: 0.8426 r:0.5596
ne_en Dev loss: 0.4814 r:0.7315
ru_en Dev loss: 0.4422 r:0.7400
Current avg r:0.5973 Best avg r: 0.6293
06:51:52,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:53:22,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:54:53,885 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1791
en_de Dev loss: 0.8993 r:0.2052
en_zh Dev loss: 0.8116 r:0.4595
ro_en Dev loss: 0.3665 r:0.8144
et_en Dev loss: 0.5025 r:0.6373
si_en Dev loss: 0.9273 r:0.5539
ne_en Dev loss: 0.5562 r:0.7279
ru_en Dev loss: 0.4760 r:0.7306
Current avg r:0.5898 Best avg r: 0.6293
06:59:26,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:57,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:28,549 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1598
en_de Dev loss: 0.8940 r:0.1966
en_zh Dev loss: 0.7842 r:0.4661
ro_en Dev loss: 0.3476 r:0.8154
et_en Dev loss: 0.4794 r:0.6513
si_en Dev loss: 0.8868 r:0.5583
ne_en Dev loss: 0.5449 r:0.7288
ru_en Dev loss: 0.4237 r:0.7501
Current avg r:0.5952 Best avg r: 0.6293
07:06:59,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:29,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:09:59,952 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1604
en_de Dev loss: 0.9097 r:0.2104
en_zh Dev loss: 0.7891 r:0.4703
ro_en Dev loss: 0.3570 r:0.8138
et_en Dev loss: 0.5257 r:0.6470
si_en Dev loss: 0.8438 r:0.5630
ne_en Dev loss: 0.4693 r:0.7339
ru_en Dev loss: 0.4517 r:0.7350
Current avg r:0.5962 Best avg r: 0.6293
07:14:30,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:16:00,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:31,684 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1625
en_de Dev loss: 0.9063 r:0.1902
en_zh Dev loss: 0.7839 r:0.4633
ro_en Dev loss: 0.3525 r:0.8192
et_en Dev loss: 0.4899 r:0.6560
si_en Dev loss: 0.8049 r:0.5706
ne_en Dev loss: 0.5184 r:0.7328
ru_en Dev loss: 0.4547 r:0.7406
Current avg r:0.5961 Best avg r: 0.6293
07:22:04,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:23:35,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:25:06,963 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1646
en_de Dev loss: 0.9277 r:0.1782
en_zh Dev loss: 0.8356 r:0.4538
ro_en Dev loss: 0.3568 r:0.8181
et_en Dev loss: 0.5094 r:0.6348
si_en Dev loss: 0.8400 r:0.5612
ne_en Dev loss: 0.5255 r:0.7329
ru_en Dev loss: 0.4265 r:0.7540
Current avg r:0.5904 Best avg r: 0.6293
07:29:39,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:31:10,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:41,958 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1611
en_de Dev loss: 0.9430 r:0.1944
en_zh Dev loss: 0.8250 r:0.4682
ro_en Dev loss: 0.3602 r:0.8152
et_en Dev loss: 0.5016 r:0.6417
si_en Dev loss: 0.9143 r:0.5509
ne_en Dev loss: 0.6115 r:0.7269
ru_en Dev loss: 0.4613 r:0.7468
Current avg r:0.5920 Best avg r: 0.6293
07:37:15,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:46,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:40:17,18 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1622
en_de Dev loss: 0.9134 r:0.1949
en_zh Dev loss: 0.7564 r:0.4709
ro_en Dev loss: 0.3513 r:0.8169
et_en Dev loss: 0.4854 r:0.6418
si_en Dev loss: 0.8909 r:0.5515
ne_en Dev loss: 0.5876 r:0.7290
ru_en Dev loss: 0.4509 r:0.7367
Current avg r:0.5917 Best avg r: 0.6293
07:44:48,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:46:18,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:47:48,694 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1407
en_de Dev loss: 0.9617 r:0.1898
en_zh Dev loss: 0.8388 r:0.4660
ro_en Dev loss: 0.3860 r:0.8175
et_en Dev loss: 0.5003 r:0.6478
si_en Dev loss: 0.9616 r:0.5517
ne_en Dev loss: 0.5473 r:0.7297
ru_en Dev loss: 0.4866 r:0.7435
Current avg r:0.5923 Best avg r: 0.6293
07:52:18,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:53:48,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:18,858 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1539
en_de Dev loss: 0.9550 r:0.1990
en_zh Dev loss: 0.8571 r:0.4604
ro_en Dev loss: 0.3877 r:0.8113
et_en Dev loss: 0.5379 r:0.6391
si_en Dev loss: 0.9802 r:0.5431
ne_en Dev loss: 0.6053 r:0.7219
ru_en Dev loss: 0.5222 r:0.7298
Current avg r:0.5864 Best avg r: 0.6293
07:59:50,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:01:21,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:52,27 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1479
en_de Dev loss: 0.9013 r:0.2128
en_zh Dev loss: 0.7839 r:0.4626
ro_en Dev loss: 0.3401 r:0.8188
et_en Dev loss: 0.4809 r:0.6471
si_en Dev loss: 0.8285 r:0.5614
ne_en Dev loss: 0.5187 r:0.7289
ru_en Dev loss: 0.4625 r:0.7342
Current avg r:0.5951 Best avg r: 0.6293
08:07:24,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:55,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:26,390 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1457
en_de Dev loss: 0.8978 r:0.2094
en_zh Dev loss: 0.7463 r:0.4587
ro_en Dev loss: 0.3363 r:0.8175
et_en Dev loss: 0.4818 r:0.6494
si_en Dev loss: 0.8009 r:0.5596
ne_en Dev loss: 0.4886 r:0.7237
ru_en Dev loss: 0.4273 r:0.7397
Current avg r:0.5940 Best avg r: 0.6293
08:14:58,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:16:29,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:18:00,721 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1488
en_de Dev loss: 0.9084 r:0.2109
en_zh Dev loss: 0.8340 r:0.4416
ro_en Dev loss: 0.3621 r:0.8187
et_en Dev loss: 0.5035 r:0.6372
si_en Dev loss: 0.8959 r:0.5527
ne_en Dev loss: 0.5978 r:0.7241
ru_en Dev loss: 0.4819 r:0.7260
Current avg r:0.5873 Best avg r: 0.6293
08:22:32,105 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:24:02,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:25:32,345 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1436
en_de Dev loss: 0.9309 r:0.2078
en_zh Dev loss: 0.8185 r:0.4598
ro_en Dev loss: 0.3557 r:0.8216
et_en Dev loss: 0.5117 r:0.6599
si_en Dev loss: 0.8580 r:0.5608
ne_en Dev loss: 0.5458 r:0.7276
ru_en Dev loss: 0.4174 r:0.7569
Current avg r:0.5992 Best avg r: 0.6293
08:30:01,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:31:31,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:33:01,613 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1492
en_de Dev loss: 0.9476 r:0.1906
en_zh Dev loss: 0.8411 r:0.4486
ro_en Dev loss: 0.3792 r:0.8163
et_en Dev loss: 0.5368 r:0.6449
si_en Dev loss: 0.8677 r:0.5481
ne_en Dev loss: 0.5637 r:0.7217
ru_en Dev loss: 0.4521 r:0.7466
Current avg r:0.5881 Best avg r: 0.6293
08:37:30,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:39:00,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:40:31,243 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1530
en_de Dev loss: 0.9068 r:0.1954
en_zh Dev loss: 0.7831 r:0.4508
ro_en Dev loss: 0.3586 r:0.8172
et_en Dev loss: 0.5014 r:0.6441
si_en Dev loss: 0.8640 r:0.5493
ne_en Dev loss: 0.5294 r:0.7308
ru_en Dev loss: 0.4318 r:0.7491
Current avg r:0.5910 Best avg r: 0.6293
08:45:01,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:46:32,312 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:48:02,920 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1412
en_de Dev loss: 0.9170 r:0.2008
en_zh Dev loss: 0.8025 r:0.4550
ro_en Dev loss: 0.3870 r:0.8188
et_en Dev loss: 0.4932 r:0.6478
si_en Dev loss: 0.9537 r:0.5455
ne_en Dev loss: 0.6043 r:0.7270
ru_en Dev loss: 0.4751 r:0.7461
Current avg r:0.5916 Best avg r: 0.6293
08:52:33,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:54:03,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:55:34,402 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1448
en_de Dev loss: 0.9371 r:0.1888
en_zh Dev loss: 0.8175 r:0.4651
ro_en Dev loss: 0.3904 r:0.8166
et_en Dev loss: 0.5132 r:0.6423
si_en Dev loss: 0.8967 r:0.5530
ne_en Dev loss: 0.6112 r:0.7234
ru_en Dev loss: 0.4926 r:0.7343
Current avg r:0.5891 Best avg r: 0.6293
09:00:04,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:35,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:05,190 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1419
en_de Dev loss: 0.9284 r:0.1956
en_zh Dev loss: 0.8247 r:0.4548
ro_en Dev loss: 0.3746 r:0.8184
et_en Dev loss: 0.4844 r:0.6452
si_en Dev loss: 0.9436 r:0.5467
ne_en Dev loss: 0.6079 r:0.7241
ru_en Dev loss: 0.4616 r:0.7464
Current avg r:0.5902 Best avg r: 0.6293
09:07:36,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:06,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:37,722 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1411
en_de Dev loss: 0.9159 r:0.1969
en_zh Dev loss: 0.7752 r:0.4621
ro_en Dev loss: 0.3462 r:0.8227
et_en Dev loss: 0.5057 r:0.6548
si_en Dev loss: 0.8153 r:0.5613
ne_en Dev loss: 0.5009 r:0.7234
ru_en Dev loss: 0.4683 r:0.7346
Current avg r:0.5937 Best avg r: 0.6293
09:15:09,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:16:40,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:18:11,896 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1333
en_de Dev loss: 0.9350 r:0.2033
en_zh Dev loss: 0.8108 r:0.4576
ro_en Dev loss: 0.3512 r:0.8228
et_en Dev loss: 0.5040 r:0.6501
si_en Dev loss: 0.8789 r:0.5490
ne_en Dev loss: 0.5771 r:0.7183
ru_en Dev loss: 0.4966 r:0.7234
Current avg r:0.5892 Best avg r: 0.6293
09:22:44,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:24:15,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:25:46,330 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1287
en_de Dev loss: 0.9899 r:0.1832
en_zh Dev loss: 0.8502 r:0.4563
ro_en Dev loss: 0.3978 r:0.8143
et_en Dev loss: 0.5260 r:0.6425
si_en Dev loss: 1.0239 r:0.5355
ne_en Dev loss: 0.6267 r:0.7215
ru_en Dev loss: 0.5424 r:0.7233
Current avg r:0.5824 Best avg r: 0.6293
09:30:19,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:31:49,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:33:19,641 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1476
en_de Dev loss: 0.9459 r:0.1766
en_zh Dev loss: 0.7562 r:0.4675
ro_en Dev loss: 0.3539 r:0.8178
et_en Dev loss: 0.4843 r:0.6496
si_en Dev loss: 0.8821 r:0.5490
ne_en Dev loss: 0.5783 r:0.7225
ru_en Dev loss: 0.4361 r:0.7501
Current avg r:0.5904 Best avg r: 0.6293
09:37:49,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:39:19,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:40:49,494 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1349
en_de Dev loss: 0.9097 r:0.2120
en_zh Dev loss: 0.7397 r:0.4658
ro_en Dev loss: 0.3465 r:0.8184
et_en Dev loss: 0.4874 r:0.6412
si_en Dev loss: 0.9173 r:0.5409
ne_en Dev loss: 0.5597 r:0.7155
ru_en Dev loss: 0.4372 r:0.7374
Current avg r:0.5902 Best avg r: 0.6293
09:45:18,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:46:48,899 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:48:18,814 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1362
en_de Dev loss: 0.9051 r:0.2219
en_zh Dev loss: 0.7819 r:0.4621
ro_en Dev loss: 0.3563 r:0.8162
et_en Dev loss: 0.4939 r:0.6490
si_en Dev loss: 0.9014 r:0.5482
ne_en Dev loss: 0.5411 r:0.7242
ru_en Dev loss: 0.4691 r:0.7308
Current avg r:0.5932 Best avg r: 0.6293
09:52:48,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:54:18,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:55:48,105 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1327
en_de Dev loss: 0.9163 r:0.1977
en_zh Dev loss: 0.7664 r:0.4671
ro_en Dev loss: 0.3479 r:0.8177
et_en Dev loss: 0.5285 r:0.6547
si_en Dev loss: 0.8475 r:0.5500
ne_en Dev loss: 0.5502 r:0.7133
ru_en Dev loss: 0.4294 r:0.7465
Current avg r:0.5924 Best avg r: 0.6293
10:00:17,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:01:47,555 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:17,589 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1432
en_de Dev loss: 0.9173 r:0.2049
en_zh Dev loss: 0.7832 r:0.4654
ro_en Dev loss: 0.3536 r:0.8170
et_en Dev loss: 0.5349 r:0.6565
si_en Dev loss: 0.8581 r:0.5535
ne_en Dev loss: 0.5309 r:0.7188
ru_en Dev loss: 0.4282 r:0.7524
Current avg r:0.5955 Best avg r: 0.6293
10:07:47,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:09:18,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:48,487 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1434
en_de Dev loss: 0.9548 r:0.1995
en_zh Dev loss: 0.8668 r:0.4434
ro_en Dev loss: 0.3872 r:0.8113
et_en Dev loss: 0.5082 r:0.6353
si_en Dev loss: 0.9277 r:0.5467
ne_en Dev loss: 0.7042 r:0.7155
ru_en Dev loss: 0.5480 r:0.7185
Current avg r:0.5814 Best avg r: 0.6293
10:15:19,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:49,674 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:18:20,667 root INFO Epoch 13 Global steps: 109900 Train loss: 0.1319
en_de Dev loss: 0.9457 r:0.2055
en_zh Dev loss: 0.8505 r:0.4535
ro_en Dev loss: 0.3701 r:0.8136
et_en Dev loss: 0.5059 r:0.6394
si_en Dev loss: 0.8797 r:0.5502
ne_en Dev loss: 0.5318 r:0.7177
ru_en Dev loss: 0.4806 r:0.7386
Current avg r:0.5884 Best avg r: 0.6293
10:22:55,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:26,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:25:57,472 root INFO Epoch 13 Global steps: 110600 Train loss: 0.1361
en_de Dev loss: 0.9125 r:0.2151
en_zh Dev loss: 0.8089 r:0.4590
ro_en Dev loss: 0.3781 r:0.8133
et_en Dev loss: 0.5178 r:0.6436
si_en Dev loss: 0.9274 r:0.5478
ne_en Dev loss: 0.5571 r:0.7251
ru_en Dev loss: 0.4888 r:0.7346
Current avg r:0.5912 Best avg r: 0.6293
10:30:30,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
