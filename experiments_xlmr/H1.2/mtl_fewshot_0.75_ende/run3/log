14:37:36,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:38:02,480 root INFO 
id:en_de cur r: 0.1186 best r: 0.1186
14:38:15,486 root INFO 
id:en_zh cur r: 0.2744 best r: 0.2744
14:38:28,499 root INFO 
id:ro_en cur r: 0.3967 best r: 0.3967
14:38:42,981 root INFO 
id:et_en cur r: 0.2965 best r: 0.2965
14:38:56,25 root INFO 
id:si_en cur r: 0.3955 best r: 0.3955
14:39:09,67 root INFO 
id:ne_en cur r: 0.1485 best r: 0.1485
14:39:22,0 root INFO 
id:ru_en cur r: 0.6316 best r: 0.6316
14:39:22,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:40:53,73 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
14:40:53,79 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:40:53,84 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:40:53,89 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
14:40:53,94 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
14:40:53,98 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:40:53,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:41:06,154 root INFO Epoch 0 Global steps: 700 Train loss: 0.8552
en_de Dev loss: 0.8840 r:0.1071
en_zh Dev loss: 0.7636 r:0.2877
ro_en Dev loss: 0.6867 r:0.5591
et_en Dev loss: 0.6256 r:0.4338
si_en Dev loss: 0.7523 r:0.4452
ne_en Dev loss: 0.6546 r:0.4866
ru_en Dev loss: 0.5738 r:0.6365
Current avg r:0.4223 Best avg r: 0.4223
14:45:39,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:46:05,403 root INFO 
id:en_zh cur r: 0.2750 best r: 0.2750
14:46:18,419 root INFO 
id:ro_en cur r: 0.5731 best r: 0.5731
14:46:31,472 root INFO 
id:et_en cur r: 0.4974 best r: 0.4974
14:46:44,519 root INFO 
id:si_en cur r: 0.4070 best r: 0.4070
14:46:57,556 root INFO 
id:ne_en cur r: 0.4436 best r: 0.4436
14:47:10,501 root INFO 
id:ru_en cur r: 0.6540 best r: 0.6540
14:47:10,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:41,605 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
14:48:41,613 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:48:41,618 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:48:41,623 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
14:48:41,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
14:48:41,634 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:48:41,639 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:48:54,666 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7709
en_de Dev loss: 0.9433 r:0.0924
en_zh Dev loss: 0.7743 r:0.2896
ro_en Dev loss: 0.6608 r:0.6301
et_en Dev loss: 0.5707 r:0.5265
si_en Dev loss: 0.7651 r:0.4656
ne_en Dev loss: 0.6378 r:0.5247
ru_en Dev loss: 0.5466 r:0.6744
Current avg r:0.4576 Best avg r: 0.4576
14:53:29,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:55,986 root INFO 
id:en_zh cur r: 0.3045 best r: 0.3045
14:54:09,19 root INFO 
id:ro_en cur r: 0.6472 best r: 0.6472
14:54:22,67 root INFO 
id:et_en cur r: 0.5856 best r: 0.5856
14:54:35,124 root INFO 
id:si_en cur r: 0.4579 best r: 0.4579
14:54:48,171 root INFO 
id:ne_en cur r: 0.5955 best r: 0.5955
14:55:01,123 root INFO 
id:ru_en cur r: 0.6879 best r: 0.6879
14:55:01,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:56:32,194 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
14:56:32,199 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:56:32,204 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:56:32,209 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
14:56:32,214 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
14:56:32,219 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:56:32,224 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:56:45,276 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7186
en_de Dev loss: 0.9713 r:0.0757
en_zh Dev loss: 0.7433 r:0.3194
ro_en Dev loss: 0.5044 r:0.6731
et_en Dev loss: 0.4692 r:0.6065
si_en Dev loss: 0.6720 r:0.4856
ne_en Dev loss: 0.5192 r:0.6044
ru_en Dev loss: 0.4474 r:0.7075
Current avg r:0.4960 Best avg r: 0.4960
15:01:18,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:49,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:20,839 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7468
en_de Dev loss: 0.9808 r:0.0916
en_zh Dev loss: 0.7828 r:0.3122
ro_en Dev loss: 0.5814 r:0.6584
et_en Dev loss: 0.5065 r:0.5562
si_en Dev loss: 0.7960 r:0.4381
ne_en Dev loss: 0.5950 r:0.5521
ru_en Dev loss: 0.5163 r:0.6884
Current avg r:0.4710 Best avg r: 0.4960
15:08:54,181 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:20,202 root INFO 
id:en_zh cur r: 0.3304 best r: 0.3304
15:09:33,229 root INFO 
id:ro_en cur r: 0.6785 best r: 0.6785
15:09:46,262 root INFO 
id:et_en cur r: 0.6058 best r: 0.6058
15:09:59,324 root INFO 
id:si_en cur r: 0.4621 best r: 0.4621
15:10:12,374 root INFO 
id:ne_en cur r: 0.6124 best r: 0.6124
15:10:25,322 root INFO 
id:ru_en cur r: 0.7020 best r: 0.7020
15:10:25,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:56,478 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:11:56,484 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:11:56,489 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:11:56,494 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:11:56,500 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:11:56,505 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:11:56,510 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:12:09,557 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6778
en_de Dev loss: 0.9800 r:0.1160
en_zh Dev loss: 0.7633 r:0.3436
ro_en Dev loss: 0.4909 r:0.7028
et_en Dev loss: 0.4498 r:0.6227
si_en Dev loss: 0.7350 r:0.4814
ne_en Dev loss: 0.5194 r:0.6184
ru_en Dev loss: 0.4869 r:0.7037
Current avg r:0.5127 Best avg r: 0.5127
15:16:44,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:10,271 root INFO 
id:en_zh cur r: 0.3516 best r: 0.3516
15:17:23,290 root INFO 
id:ro_en cur r: 0.6930 best r: 0.6930
15:17:36,350 root INFO 
id:et_en cur r: 0.6243 best r: 0.6243
15:17:49,395 root INFO 
id:si_en cur r: 0.4916 best r: 0.4916
15:18:02,432 root INFO 
id:ne_en cur r: 0.6444 best r: 0.6444
15:18:15,363 root INFO 
id:ru_en cur r: 0.7106 best r: 0.7106
15:18:15,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:46,508 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:19:46,513 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:19:46,519 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:19:46,523 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:19:46,528 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:19:46,534 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:19:46,540 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:19:59,584 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6561
en_de Dev loss: 0.9847 r:0.1425
en_zh Dev loss: 0.7629 r:0.3730
ro_en Dev loss: 0.4740 r:0.7188
et_en Dev loss: 0.4351 r:0.6427
si_en Dev loss: 0.7195 r:0.5117
ne_en Dev loss: 0.4864 r:0.6572
ru_en Dev loss: 0.4913 r:0.7224
Current avg r:0.5383 Best avg r: 0.5383
15:24:33,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:59,216 root INFO 
id:en_de cur r: 0.1194 best r: 0.1194
15:25:25,228 root INFO 
id:ro_en cur r: 0.6973 best r: 0.6973
15:25:38,258 root INFO 
id:et_en cur r: 0.6250 best r: 0.6250
15:26:17,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:48,545 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6478
en_de Dev loss: 1.0034 r:0.1542
en_zh Dev loss: 0.7827 r:0.3648
ro_en Dev loss: 0.4714 r:0.7184
et_en Dev loss: 0.4306 r:0.6399
si_en Dev loss: 0.6962 r:0.5051
ne_en Dev loss: 0.4738 r:0.6517
ru_en Dev loss: 0.4991 r:0.7142
Current avg r:0.5355 Best avg r: 0.5383
15:32:27,322 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:53,359 root INFO 
id:en_de cur r: 0.1434 best r: 0.1434
15:33:06,346 root INFO 
id:en_zh cur r: 0.3838 best r: 0.3838
15:33:19,366 root INFO 
id:ro_en cur r: 0.7138 best r: 0.7138
15:33:32,402 root INFO 
id:et_en cur r: 0.6476 best r: 0.6476
15:33:45,472 root INFO 
id:si_en cur r: 0.5076 best r: 0.5076
15:33:58,534 root INFO 
id:ne_en cur r: 0.6777 best r: 0.6777
15:34:11,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:42,692 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:35:42,699 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:35:42,704 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:35:42,709 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:35:42,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:35:42,718 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:35:42,723 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:35:55,770 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6118
en_de Dev loss: 0.9592 r:0.1872
en_zh Dev loss: 0.7845 r:0.4061
ro_en Dev loss: 0.4696 r:0.7370
et_en Dev loss: 0.4348 r:0.6581
si_en Dev loss: 0.7133 r:0.5339
ne_en Dev loss: 0.5208 r:0.6751
ru_en Dev loss: 0.5091 r:0.7257
Current avg r:0.5604 Best avg r: 0.5604
15:40:29,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:55,636 root INFO 
id:en_de cur r: 0.1684 best r: 0.1684
15:41:08,626 root INFO 
id:en_zh cur r: 0.3840 best r: 0.3840
15:41:21,654 root INFO 
id:ro_en cur r: 0.7422 best r: 0.7422
15:41:34,708 root INFO 
id:et_en cur r: 0.6771 best r: 0.6771
15:41:47,776 root INFO 
id:si_en cur r: 0.5174 best r: 0.5174
15:42:00,826 root INFO 
id:ne_en cur r: 0.7017 best r: 0.7017
15:42:13,774 root INFO 
id:ru_en cur r: 0.7295 best r: 0.7295
15:42:13,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:44,874 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:43:44,881 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:43:44,885 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:43:44,894 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:43:44,899 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:43:44,904 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:43:44,910 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:43:57,971 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5873
en_de Dev loss: 0.9239 r:0.1899
en_zh Dev loss: 0.7351 r:0.4012
ro_en Dev loss: 0.3903 r:0.7521
et_en Dev loss: 0.3899 r:0.6766
si_en Dev loss: 0.7610 r:0.5322
ne_en Dev loss: 0.4628 r:0.6938
ru_en Dev loss: 0.4459 r:0.7383
Current avg r:0.5692 Best avg r: 0.5692
15:48:30,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:56,926 root INFO 
id:en_de cur r: 0.1839 best r: 0.1839
15:49:09,938 root INFO 
id:en_zh cur r: 0.3906 best r: 0.3906
15:49:22,960 root INFO 
id:ro_en cur r: 0.7593 best r: 0.7593
15:49:49,55 root INFO 
id:si_en cur r: 0.5234 best r: 0.5234
15:50:02,124 root INFO 
id:ne_en cur r: 0.7070 best r: 0.7070
15:50:15,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:46,290 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
15:51:46,296 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:51:46,301 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:51:46,306 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
15:51:46,317 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
15:51:46,322 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:51:46,327 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:51:59,360 root INFO Epoch 0 Global steps: 7000 Train loss: 0.6031
en_de Dev loss: 0.9980 r:0.2010
en_zh Dev loss: 0.7942 r:0.4074
ro_en Dev loss: 0.4948 r:0.7660
et_en Dev loss: 0.4542 r:0.6651
si_en Dev loss: 0.8812 r:0.5364
ne_en Dev loss: 0.5207 r:0.7022
ru_en Dev loss: 0.5534 r:0.7249
Current avg r:0.5718 Best avg r: 0.5718
15:56:32,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:03,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:34,292 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5899
en_de Dev loss: 1.0922 r:0.1998
en_zh Dev loss: 0.9439 r:0.3991
ro_en Dev loss: 0.5649 r:0.7621
et_en Dev loss: 0.5272 r:0.6514
si_en Dev loss: 0.9974 r:0.5187
ne_en Dev loss: 0.6897 r:0.6844
ru_en Dev loss: 0.6572 r:0.7090
Current avg r:0.5606 Best avg r: 0.5718
16:04:09,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:35,414 root INFO 
id:en_de cur r: 0.2146 best r: 0.2146
16:05:53,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:24,657 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
16:07:24,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:07:24,668 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:07:24,673 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
16:07:24,678 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
16:07:24,683 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:07:24,687 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:07:37,744 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5438
en_de Dev loss: 0.9575 r:0.2233
en_zh Dev loss: 0.8100 r:0.4132
ro_en Dev loss: 0.4669 r:0.7700
et_en Dev loss: 0.4523 r:0.6645
si_en Dev loss: 0.8762 r:0.5332
ne_en Dev loss: 0.5207 r:0.7019
ru_en Dev loss: 0.6285 r:0.6988
Current avg r:0.5721 Best avg r: 0.5721
16:12:10,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:36,730 root INFO 
id:en_zh cur r: 0.4303 best r: 0.4303
16:12:49,734 root INFO 
id:ro_en cur r: 0.7873 best r: 0.7873
16:13:02,756 root INFO 
id:et_en cur r: 0.6870 best r: 0.6870
16:13:15,810 root INFO 
id:si_en cur r: 0.5753 best r: 0.5753
16:13:28,850 root INFO 
id:ne_en cur r: 0.7316 best r: 0.7316
16:13:41,792 root INFO 
id:ru_en cur r: 0.7331 best r: 0.7331
16:13:41,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:12,826 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
16:15:12,833 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:15:12,838 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:15:12,843 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
16:15:12,848 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
16:15:12,852 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:15:12,858 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:15:25,882 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5549
en_de Dev loss: 0.8772 r:0.2251
en_zh Dev loss: 0.6879 r:0.4444
ro_en Dev loss: 0.3524 r:0.7904
et_en Dev loss: 0.3756 r:0.6946
si_en Dev loss: 0.5971 r:0.5814
ne_en Dev loss: 0.3741 r:0.7405
ru_en Dev loss: 0.4030 r:0.7512
Current avg r:0.6040 Best avg r: 0.6040
16:19:58,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:24,995 root INFO 
id:en_zh cur r: 0.4392 best r: 0.4392
16:20:38,26 root INFO 
id:ro_en cur r: 0.7967 best r: 0.7967
16:20:51,67 root INFO 
id:et_en cur r: 0.6920 best r: 0.6920
16:21:04,115 root INFO 
id:si_en cur r: 0.5969 best r: 0.5969
16:21:17,147 root INFO 
id:ne_en cur r: 0.7425 best r: 0.7425
16:21:30,85 root INFO 
id:ru_en cur r: 0.7467 best r: 0.7467
16:21:30,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:01,83 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
16:23:01,93 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:23:01,99 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:23:01,104 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
16:23:01,109 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
16:23:01,114 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:23:01,119 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:23:14,167 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5472
en_de Dev loss: 0.8742 r:0.2264
en_zh Dev loss: 0.6775 r:0.4508
ro_en Dev loss: 0.3212 r:0.8001
et_en Dev loss: 0.3639 r:0.7008
si_en Dev loss: 0.6117 r:0.6010
ne_en Dev loss: 0.3542 r:0.7533
ru_en Dev loss: 0.3829 r:0.7573
Current avg r:0.6128 Best avg r: 0.6128
16:27:48,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:27,620 root INFO 
id:ro_en cur r: 0.7983 best r: 0.7983
16:28:40,653 root INFO 
id:et_en cur r: 0.6936 best r: 0.6936
16:29:09,104 root INFO 
id:ne_en cur r: 0.7545 best r: 0.7545
16:29:22,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:53,174 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5255
en_de Dev loss: 0.8836 r:0.2237
en_zh Dev loss: 0.7122 r:0.4409
ro_en Dev loss: 0.3542 r:0.8031
et_en Dev loss: 0.3681 r:0.6965
si_en Dev loss: 0.6957 r:0.5858
ne_en Dev loss: 0.4539 r:0.7479
ru_en Dev loss: 0.4034 r:0.7565
Current avg r:0.6078 Best avg r: 0.6128
16:35:25,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:35:51,958 root INFO 
id:en_de cur r: 0.2250 best r: 0.2250
16:37:10,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:41,175 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5214
en_de Dev loss: 0.9556 r:0.2282
en_zh Dev loss: 0.8322 r:0.4240
ro_en Dev loss: 0.4310 r:0.7991
et_en Dev loss: 0.4026 r:0.6946
si_en Dev loss: 0.7789 r:0.5801
ne_en Dev loss: 0.4443 r:0.7479
ru_en Dev loss: 0.5533 r:0.7299
Current avg r:0.6005 Best avg r: 0.6128
16:43:18,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:44,286 root INFO 
id:en_de cur r: 0.2344 best r: 0.2344
16:45:02,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:34,738 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4990
en_de Dev loss: 0.8603 r:0.2352
en_zh Dev loss: 0.7227 r:0.4256
ro_en Dev loss: 0.3537 r:0.7999
et_en Dev loss: 0.3719 r:0.6976
si_en Dev loss: 0.6035 r:0.5982
ne_en Dev loss: 0.3748 r:0.7466
ru_en Dev loss: 0.4591 r:0.7403
Current avg r:0.6062 Best avg r: 0.6128
16:51:06,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:32,743 root INFO 
id:en_de cur r: 0.2596 best r: 0.2596
16:52:52,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:23,118 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5253
en_de Dev loss: 0.8924 r:0.2574
en_zh Dev loss: 0.8084 r:0.4367
ro_en Dev loss: 0.4253 r:0.7959
et_en Dev loss: 0.4132 r:0.6895
si_en Dev loss: 0.8417 r:0.5764
ne_en Dev loss: 0.5395 r:0.7351
ru_en Dev loss: 0.5599 r:0.7225
Current avg r:0.6019 Best avg r: 0.6128
16:58:56,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:22,743 root INFO 
id:en_zh cur r: 0.4499 best r: 0.4499
16:59:35,743 root INFO 
id:ro_en cur r: 0.7988 best r: 0.7988
16:59:48,757 root INFO 
id:et_en cur r: 0.6993 best r: 0.6993
17:00:27,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:58,808 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
17:01:58,814 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:01:58,819 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:01:58,824 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
17:01:58,829 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
17:01:58,834 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:01:58,839 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:02:11,868 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4952
en_de Dev loss: 0.8515 r:0.2460
en_zh Dev loss: 0.6837 r:0.4565
ro_en Dev loss: 0.3300 r:0.8044
et_en Dev loss: 0.3661 r:0.6994
si_en Dev loss: 0.7228 r:0.5917
ne_en Dev loss: 0.4196 r:0.7475
ru_en Dev loss: 0.4328 r:0.7456
Current avg r:0.6130 Best avg r: 0.6130
17:06:46,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:25,745 root INFO 
id:ro_en cur r: 0.8002 best r: 0.8002
17:08:17,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:51,501 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5418
en_de Dev loss: 0.8466 r:0.2546
en_zh Dev loss: 0.7113 r:0.4436
ro_en Dev loss: 0.3563 r:0.7997
et_en Dev loss: 0.3733 r:0.6969
si_en Dev loss: 0.7534 r:0.5842
ne_en Dev loss: 0.4771 r:0.7456
ru_en Dev loss: 0.4417 r:0.7473
Current avg r:0.6103 Best avg r: 0.6130
17:14:23,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:02,632 root INFO 
id:ro_en cur r: 0.8030 best r: 0.8030
17:15:54,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:25,667 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5253
en_de Dev loss: 0.8777 r:0.2413
en_zh Dev loss: 0.6932 r:0.4515
ro_en Dev loss: 0.3626 r:0.8018
et_en Dev loss: 0.3767 r:0.7003
si_en Dev loss: 0.6717 r:0.5922
ne_en Dev loss: 0.3637 r:0.7548
ru_en Dev loss: 0.4966 r:0.7390
Current avg r:0.6116 Best avg r: 0.6130
17:21:58,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:22:24,508 root INFO 
id:en_zh cur r: 0.4588 best r: 0.4588
17:23:31,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:02,486 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
17:25:02,493 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:25:02,502 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:25:02,508 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
17:25:02,512 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
17:25:02,517 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:25:02,522 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:25:15,616 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5020
en_de Dev loss: 0.8602 r:0.2557
en_zh Dev loss: 0.7036 r:0.4624
ro_en Dev loss: 0.3545 r:0.8031
et_en Dev loss: 0.3790 r:0.6967
si_en Dev loss: 0.8258 r:0.5840
ne_en Dev loss: 0.4863 r:0.7479
ru_en Dev loss: 0.4558 r:0.7442
Current avg r:0.6134 Best avg r: 0.6134
17:29:53,279 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:32,422 root INFO 
id:ro_en cur r: 0.8145 best r: 0.8145
17:30:45,512 root INFO 
id:et_en cur r: 0.7020 best r: 0.7020
17:30:58,617 root INFO 
id:si_en cur r: 0.5995 best r: 0.5995
17:31:11,716 root INFO 
id:ne_en cur r: 0.7583 best r: 0.7583
17:31:24,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:32:56,171 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
17:32:56,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
17:32:56,183 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
17:32:56,187 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
17:32:56,193 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
17:32:56,198 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
17:32:56,204 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
17:33:09,276 root INFO Epoch 2 Global steps: 16100 Train loss: 0.4821
en_de Dev loss: 0.8549 r:0.2508
en_zh Dev loss: 0.7017 r:0.4540
ro_en Dev loss: 0.3300 r:0.8115
et_en Dev loss: 0.3673 r:0.7060
si_en Dev loss: 0.6865 r:0.5986
ne_en Dev loss: 0.3720 r:0.7565
ru_en Dev loss: 0.4156 r:0.7557
Current avg r:0.6190 Best avg r: 0.6190
17:37:43,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:09,785 root INFO 
id:en_zh cur r: 0.4604 best r: 0.4604
17:38:22,863 root INFO 
id:ro_en cur r: 0.8172 best r: 0.8172
17:39:15,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:40:46,133 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4969
en_de Dev loss: 0.8512 r:0.2504
en_zh Dev loss: 0.6794 r:0.4662
ro_en Dev loss: 0.3339 r:0.8179
et_en Dev loss: 0.3799 r:0.7013
si_en Dev loss: 0.8330 r:0.5956
ne_en Dev loss: 0.4767 r:0.7511
ru_en Dev loss: 0.4721 r:0.7500
Current avg r:0.6189 Best avg r: 0.6190
17:45:19,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:50,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:48:21,168 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4750
en_de Dev loss: 0.9327 r:0.2337
en_zh Dev loss: 0.7502 r:0.4587
ro_en Dev loss: 0.3882 r:0.8131
et_en Dev loss: 0.4197 r:0.6939
si_en Dev loss: 0.7712 r:0.5951
ne_en Dev loss: 0.5038 r:0.7464
ru_en Dev loss: 0.6016 r:0.7168
Current avg r:0.6082 Best avg r: 0.6190
17:52:53,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:19,318 root INFO 
id:en_zh cur r: 0.4647 best r: 0.4647
17:54:11,396 root INFO 
id:ne_en cur r: 0.7603 best r: 0.7603
17:54:24,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:55:55,187 root INFO Epoch 2 Global steps: 18200 Train loss: 0.4478
en_de Dev loss: 0.9140 r:0.2452
en_zh Dev loss: 0.7297 r:0.4602
ro_en Dev loss: 0.3912 r:0.8122
et_en Dev loss: 0.4083 r:0.6984
si_en Dev loss: 0.7547 r:0.5966
ne_en Dev loss: 0.4245 r:0.7540
ru_en Dev loss: 0.5009 r:0.7444
Current avg r:0.6158 Best avg r: 0.6190
18:00:27,726 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:53,680 root INFO 
id:en_zh cur r: 0.4861 best r: 0.4861
18:01:06,669 root INFO 
id:ro_en cur r: 0.8211 best r: 0.8211
18:01:32,710 root INFO 
id:si_en cur r: 0.6029 best r: 0.6029
18:01:45,731 root INFO 
id:ne_en cur r: 0.7630 best r: 0.7630
18:01:58,648 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:03:29,635 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
18:03:29,644 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
18:03:29,650 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
18:03:29,655 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
18:03:29,660 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
18:03:29,666 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
18:03:29,672 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
18:03:42,688 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4668
en_de Dev loss: 0.8483 r:0.2615
en_zh Dev loss: 0.6762 r:0.4859
ro_en Dev loss: 0.3496 r:0.8183
et_en Dev loss: 0.4035 r:0.7023
si_en Dev loss: 0.6777 r:0.6049
ne_en Dev loss: 0.3715 r:0.7574
ru_en Dev loss: 0.4498 r:0.7447
Current avg r:0.6250 Best avg r: 0.6250
18:08:15,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:46,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:11:17,216 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4752
en_de Dev loss: 0.8809 r:0.2618
en_zh Dev loss: 0.7277 r:0.4713
ro_en Dev loss: 0.3771 r:0.8166
et_en Dev loss: 0.3931 r:0.7051
si_en Dev loss: 0.7294 r:0.6065
ne_en Dev loss: 0.4314 r:0.7589
ru_en Dev loss: 0.5310 r:0.7365
Current avg r:0.6224 Best avg r: 0.6250
18:15:50,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:55,353 root INFO 
id:si_en cur r: 0.6176 best r: 0.6176
18:17:08,396 root INFO 
id:ne_en cur r: 0.7638 best r: 0.7638
18:17:21,327 root INFO 
id:ru_en cur r: 0.7558 best r: 0.7558
18:17:21,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:18:53,774 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_de.lang_agnost_mlp.dev.best.scores
18:18:53,781 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/en_zh.lang_agnost_mlp.dev.best.scores
18:18:53,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ro_en.lang_agnost_mlp.dev.best.scores
18:18:53,790 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/et_en.lang_agnost_mlp.dev.best.scores
18:18:53,795 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/si_en.lang_agnost_mlp.dev.best.scores
18:18:53,800 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ne_en.lang_agnost_mlp.dev.best.scores
18:18:53,805 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ende/run3/ru_en.lang_agnost_mlp.dev.best.scores
18:19:06,858 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4406
en_de Dev loss: 0.8697 r:0.2630
en_zh Dev loss: 0.7157 r:0.4767
ro_en Dev loss: 0.3736 r:0.8174
et_en Dev loss: 0.4030 r:0.7061
si_en Dev loss: 0.6908 r:0.6176
ne_en Dev loss: 0.3680 r:0.7639
ru_en Dev loss: 0.4526 r:0.7553
Current avg r:0.6286 Best avg r: 0.6286
18:23:43,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:24:09,267 root INFO 
id:en_de cur r: 0.2602 best r: 0.2602
18:25:27,368 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:26:58,481 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4559
en_de Dev loss: 0.8889 r:0.2631
en_zh Dev loss: 0.7587 r:0.4567
ro_en Dev loss: 0.3889 r:0.8109
et_en Dev loss: 0.3949 r:0.6949
si_en Dev loss: 0.8371 r:0.5985
ne_en Dev loss: 0.4799 r:0.7573
ru_en Dev loss: 0.4863 r:0.7465
Current avg r:0.6183 Best avg r: 0.6286
18:31:30,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:56,438 root INFO 
id:en_de cur r: 0.2684 best r: 0.2684
18:33:14,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:45,371 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4689
en_de Dev loss: 0.8216 r:0.2724
en_zh Dev loss: 0.6492 r:0.4711
ro_en Dev loss: 0.3245 r:0.8128
et_en Dev loss: 0.4156 r:0.6980
si_en Dev loss: 0.5795 r:0.6031
ne_en Dev loss: 0.3493 r:0.7547
ru_en Dev loss: 0.3683 r:0.7493
Current avg r:0.6231 Best avg r: 0.6286
18:39:19,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:50,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:21,399 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4460
en_de Dev loss: 0.8728 r:0.2471
en_zh Dev loss: 0.7226 r:0.4696
ro_en Dev loss: 0.3832 r:0.8136
et_en Dev loss: 0.3916 r:0.6995
si_en Dev loss: 0.8106 r:0.5986
ne_en Dev loss: 0.4522 r:0.7530
ru_en Dev loss: 0.5326 r:0.7327
Current avg r:0.6163 Best avg r: 0.6286
18:46:53,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:24,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:55,577 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4558
en_de Dev loss: 0.8337 r:0.2596
en_zh Dev loss: 0.6613 r:0.4818
ro_en Dev loss: 0.3197 r:0.8120
et_en Dev loss: 0.3797 r:0.6972
si_en Dev loss: 0.6865 r:0.5950
ne_en Dev loss: 0.4243 r:0.7535
ru_en Dev loss: 0.4014 r:0.7541
Current avg r:0.6219 Best avg r: 0.6286
18:54:27,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:58,250 root INFO 
id:ru_en cur r: 0.7661 best r: 0.7661
18:55:58,250 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:29,201 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4522
en_de Dev loss: 0.8450 r:0.2452
en_zh Dev loss: 0.6605 r:0.4841
ro_en Dev loss: 0.3306 r:0.8126
et_en Dev loss: 0.3841 r:0.7004
si_en Dev loss: 0.6128 r:0.6096
ne_en Dev loss: 0.3667 r:0.7565
ru_en Dev loss: 0.3701 r:0.7677
Current avg r:0.6252 Best avg r: 0.6286
19:02:03,466 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:34,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:05,496 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4121
en_de Dev loss: 0.8921 r:0.2581
en_zh Dev loss: 0.7506 r:0.4772
ro_en Dev loss: 0.4074 r:0.8130
et_en Dev loss: 0.4159 r:0.6949
si_en Dev loss: 0.8632 r:0.5932
ne_en Dev loss: 0.4817 r:0.7517
ru_en Dev loss: 0.5184 r:0.7490
Current avg r:0.6196 Best avg r: 0.6286
19:09:37,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:08,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:12:39,586 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4027
en_de Dev loss: 0.9192 r:0.2515
en_zh Dev loss: 0.8080 r:0.4665
ro_en Dev loss: 0.4416 r:0.8122
et_en Dev loss: 0.4244 r:0.6959
si_en Dev loss: 0.8503 r:0.6004
ne_en Dev loss: 0.5556 r:0.7534
ru_en Dev loss: 0.5848 r:0.7359
Current avg r:0.6165 Best avg r: 0.6286
19:17:11,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:42,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:13,601 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4290
en_de Dev loss: 0.8557 r:0.2502
en_zh Dev loss: 0.7153 r:0.4797
ro_en Dev loss: 0.3743 r:0.8148
et_en Dev loss: 0.3896 r:0.6992
si_en Dev loss: 0.7788 r:0.6046
ne_en Dev loss: 0.4733 r:0.7537
ru_en Dev loss: 0.4708 r:0.7471
Current avg r:0.6213 Best avg r: 0.6286
19:24:45,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:16,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:47,538 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4064
en_de Dev loss: 0.8757 r:0.2396
en_zh Dev loss: 0.8033 r:0.4553
ro_en Dev loss: 0.3799 r:0.8143
et_en Dev loss: 0.3933 r:0.6976
si_en Dev loss: 0.8231 r:0.6028
ne_en Dev loss: 0.4827 r:0.7521
ru_en Dev loss: 0.5464 r:0.7306
Current avg r:0.6132 Best avg r: 0.6286
19:32:19,526 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:50,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:21,455 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4168
en_de Dev loss: 0.8624 r:0.2397
en_zh Dev loss: 0.7363 r:0.4529
ro_en Dev loss: 0.3290 r:0.8177
et_en Dev loss: 0.3859 r:0.6974
si_en Dev loss: 0.7075 r:0.6039
ne_en Dev loss: 0.4231 r:0.7521
ru_en Dev loss: 0.4396 r:0.7507
Current avg r:0.6163 Best avg r: 0.6286
19:39:54,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:46,208 root INFO 
id:et_en cur r: 0.7035 best r: 0.7035
19:41:25,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:56,280 root INFO Epoch 3 Global steps: 28000 Train loss: 0.4198
en_de Dev loss: 0.8524 r:0.2653
en_zh Dev loss: 0.6953 r:0.4793
ro_en Dev loss: 0.3463 r:0.8153
et_en Dev loss: 0.3821 r:0.7032
si_en Dev loss: 0.6916 r:0.6079
ne_en Dev loss: 0.4143 r:0.7591
ru_en Dev loss: 0.4338 r:0.7522
Current avg r:0.6261 Best avg r: 0.6286
19:47:28,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:59,188 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:30,149 root INFO Epoch 3 Global steps: 28700 Train loss: 0.4225
en_de Dev loss: 0.8576 r:0.2492
en_zh Dev loss: 0.6964 r:0.4792
ro_en Dev loss: 0.3208 r:0.8206
et_en Dev loss: 0.3867 r:0.6947
si_en Dev loss: 0.6853 r:0.6107
ne_en Dev loss: 0.4451 r:0.7529
ru_en Dev loss: 0.4537 r:0.7461
Current avg r:0.6219 Best avg r: 0.6286
19:55:02,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:28,286 root INFO 
id:en_de cur r: 0.2808 best r: 0.2808
19:55:41,279 root INFO 
id:en_zh cur r: 0.4886 best r: 0.4886
19:56:46,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:17,459 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4010
en_de Dev loss: 0.8420 r:0.2795
en_zh Dev loss: 0.7077 r:0.4896
ro_en Dev loss: 0.3353 r:0.8144
et_en Dev loss: 0.4049 r:0.6898
si_en Dev loss: 0.6717 r:0.6098
ne_en Dev loss: 0.4200 r:0.7477
ru_en Dev loss: 0.4398 r:0.7586
Current avg r:0.6270 Best avg r: 0.6286
20:02:50,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:21,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:52,141 root INFO Epoch 3 Global steps: 30100 Train loss: 0.4279
en_de Dev loss: 0.8374 r:0.2499
en_zh Dev loss: 0.7052 r:0.4831
ro_en Dev loss: 0.3388 r:0.8168
et_en Dev loss: 0.4093 r:0.6853
si_en Dev loss: 0.7350 r:0.6028
ne_en Dev loss: 0.4786 r:0.7551
ru_en Dev loss: 0.4556 r:0.7420
Current avg r:0.6193 Best avg r: 0.6286
20:10:24,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:55,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:27,515 root INFO Epoch 3 Global steps: 30800 Train loss: 0.3999
en_de Dev loss: 0.8430 r:0.2544
en_zh Dev loss: 0.6895 r:0.4824
ro_en Dev loss: 0.3192 r:0.8209
et_en Dev loss: 0.4003 r:0.6956
si_en Dev loss: 0.6793 r:0.6123
ne_en Dev loss: 0.3934 r:0.7503
ru_en Dev loss: 0.4461 r:0.7469
Current avg r:0.6233 Best avg r: 0.6286
20:17:59,891 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:31,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:02,381 root INFO Epoch 3 Global steps: 31500 Train loss: 0.3949
en_de Dev loss: 0.8421 r:0.2483
en_zh Dev loss: 0.7055 r:0.4708
ro_en Dev loss: 0.3089 r:0.8203
et_en Dev loss: 0.4139 r:0.6961
si_en Dev loss: 0.6129 r:0.6161
ne_en Dev loss: 0.3896 r:0.7453
ru_en Dev loss: 0.4528 r:0.7314
Current avg r:0.6183 Best avg r: 0.6286
20:25:36,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:07,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:28:38,67 root INFO Epoch 4 Global steps: 32200 Train loss: 0.3591
en_de Dev loss: 0.8974 r:0.2400
en_zh Dev loss: 0.8047 r:0.4646
ro_en Dev loss: 0.3832 r:0.8152
et_en Dev loss: 0.4230 r:0.6881
si_en Dev loss: 0.8294 r:0.6037
ne_en Dev loss: 0.5133 r:0.7501
ru_en Dev loss: 0.5942 r:0.7224
Current avg r:0.6120 Best avg r: 0.6286
20:33:10,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:41,613 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:12,658 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3483
en_de Dev loss: 0.8745 r:0.2501
en_zh Dev loss: 0.7464 r:0.4635
ro_en Dev loss: 0.3496 r:0.8172
et_en Dev loss: 0.4189 r:0.6854
si_en Dev loss: 0.7689 r:0.6066
ne_en Dev loss: 0.4239 r:0.7485
ru_en Dev loss: 0.5013 r:0.7378
Current avg r:0.6156 Best avg r: 0.6286
20:40:45,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:16,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:43:47,311 root INFO Epoch 4 Global steps: 33600 Train loss: 0.3708
en_de Dev loss: 0.8798 r:0.2369
en_zh Dev loss: 0.8088 r:0.4461
ro_en Dev loss: 0.3883 r:0.8112
et_en Dev loss: 0.4580 r:0.6811
si_en Dev loss: 0.8010 r:0.5951
ne_en Dev loss: 0.5219 r:0.7396
ru_en Dev loss: 0.5187 r:0.7248
Current avg r:0.6050 Best avg r: 0.6286
20:48:19,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:49:50,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:21,683 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3524
en_de Dev loss: 0.8492 r:0.2323
en_zh Dev loss: 0.7431 r:0.4612
ro_en Dev loss: 0.3421 r:0.8205
et_en Dev loss: 0.4189 r:0.6836
si_en Dev loss: 0.8065 r:0.5980
ne_en Dev loss: 0.4984 r:0.7430
ru_en Dev loss: 0.4564 r:0.7372
Current avg r:0.6108 Best avg r: 0.6286
20:55:54,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:25,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:58:56,694 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3785
en_de Dev loss: 0.8560 r:0.2351
en_zh Dev loss: 0.7472 r:0.4558
ro_en Dev loss: 0.3473 r:0.8196
et_en Dev loss: 0.4340 r:0.6803
si_en Dev loss: 0.7059 r:0.6048
ne_en Dev loss: 0.4533 r:0.7418
ru_en Dev loss: 0.4596 r:0.7328
Current avg r:0.6100 Best avg r: 0.6286
21:03:29,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:00,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:31,714 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3649
en_de Dev loss: 0.8595 r:0.2314
en_zh Dev loss: 0.7997 r:0.4673
ro_en Dev loss: 0.4274 r:0.8121
et_en Dev loss: 0.4578 r:0.6762
si_en Dev loss: 1.0026 r:0.5929
ne_en Dev loss: 0.6017 r:0.7411
ru_en Dev loss: 0.5835 r:0.7159
Current avg r:0.6053 Best avg r: 0.6286
21:11:04,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:37,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:08,625 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3719
en_de Dev loss: 0.8437 r:0.2530
en_zh Dev loss: 0.7276 r:0.4668
ro_en Dev loss: 0.3364 r:0.8146
et_en Dev loss: 0.4312 r:0.6793
si_en Dev loss: 0.7410 r:0.5939
ne_en Dev loss: 0.4372 r:0.7511
ru_en Dev loss: 0.4114 r:0.7508
Current avg r:0.6156 Best avg r: 0.6286
21:18:41,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:12,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:43,955 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3714
en_de Dev loss: 0.8704 r:0.2467
en_zh Dev loss: 0.8298 r:0.4521
ro_en Dev loss: 0.3979 r:0.8124
et_en Dev loss: 0.4339 r:0.6726
si_en Dev loss: 0.9759 r:0.5795
ne_en Dev loss: 0.5587 r:0.7397
ru_en Dev loss: 0.5152 r:0.7349
Current avg r:0.6054 Best avg r: 0.6286
21:26:16,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:48,11 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:19,138 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3567
en_de Dev loss: 0.8407 r:0.2436
en_zh Dev loss: 0.7553 r:0.4611
ro_en Dev loss: 0.3472 r:0.8187
et_en Dev loss: 0.4120 r:0.6848
si_en Dev loss: 0.7735 r:0.5980
ne_en Dev loss: 0.4588 r:0.7532
ru_en Dev loss: 0.4226 r:0.7590
Current avg r:0.6169 Best avg r: 0.6286
21:33:51,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:22,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:53,663 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3687
en_de Dev loss: 0.8606 r:0.2353
en_zh Dev loss: 0.7694 r:0.4606
ro_en Dev loss: 0.4165 r:0.8100
et_en Dev loss: 0.4381 r:0.6730
si_en Dev loss: 0.8138 r:0.5833
ne_en Dev loss: 0.5278 r:0.7451
ru_en Dev loss: 0.5566 r:0.7149
Current avg r:0.6032 Best avg r: 0.6286
21:41:25,832 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:56,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:27,848 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3644
en_de Dev loss: 0.8361 r:0.2644
en_zh Dev loss: 0.7521 r:0.4628
ro_en Dev loss: 0.3426 r:0.8168
et_en Dev loss: 0.4380 r:0.6779
si_en Dev loss: 0.7992 r:0.5858
ne_en Dev loss: 0.4435 r:0.7443
ru_en Dev loss: 0.4787 r:0.7311
Current avg r:0.6118 Best avg r: 0.6286
21:49:01,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:32,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:03,303 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3293
en_de Dev loss: 0.8936 r:0.2364
en_zh Dev loss: 0.7927 r:0.4749
ro_en Dev loss: 0.3573 r:0.8167
et_en Dev loss: 0.4227 r:0.6800
si_en Dev loss: 0.8845 r:0.5863
ne_en Dev loss: 0.4976 r:0.7439
ru_en Dev loss: 0.5013 r:0.7439
Current avg r:0.6117 Best avg r: 0.6286
21:56:35,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:06,401 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:37,425 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3107
en_de Dev loss: 0.8905 r:0.2320
en_zh Dev loss: 0.7950 r:0.4544
ro_en Dev loss: 0.3442 r:0.8130
et_en Dev loss: 0.4360 r:0.6737
si_en Dev loss: 0.7606 r:0.5845
ne_en Dev loss: 0.4115 r:0.7415
ru_en Dev loss: 0.5148 r:0.7258
Current avg r:0.6036 Best avg r: 0.6286
22:04:09,489 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:40,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:11,467 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3205
en_de Dev loss: 0.8607 r:0.2576
en_zh Dev loss: 0.7616 r:0.4742
ro_en Dev loss: 0.3852 r:0.8145
et_en Dev loss: 0.4630 r:0.6716
si_en Dev loss: 0.9048 r:0.5782
ne_en Dev loss: 0.5804 r:0.7371
ru_en Dev loss: 0.5205 r:0.7307
Current avg r:0.6091 Best avg r: 0.6286
22:11:43,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:14,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:45,914 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3352
en_de Dev loss: 0.8716 r:0.2476
en_zh Dev loss: 0.7741 r:0.4617
ro_en Dev loss: 0.3542 r:0.8105
et_en Dev loss: 0.4485 r:0.6644
si_en Dev loss: 0.8313 r:0.5715
ne_en Dev loss: 0.5653 r:0.7346
ru_en Dev loss: 0.5036 r:0.7265
Current avg r:0.6024 Best avg r: 0.6286
22:19:18,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:49,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:21,403 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3072
en_de Dev loss: 0.8519 r:0.2339
en_zh Dev loss: 0.7573 r:0.4645
ro_en Dev loss: 0.3659 r:0.8143
et_en Dev loss: 0.4688 r:0.6797
si_en Dev loss: 0.7824 r:0.5867
ne_en Dev loss: 0.4745 r:0.7401
ru_en Dev loss: 0.4381 r:0.7509
Current avg r:0.6100 Best avg r: 0.6286
22:26:54,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:25,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:56,612 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3070
en_de Dev loss: 0.8548 r:0.2432
en_zh Dev loss: 0.7575 r:0.4719
ro_en Dev loss: 0.3688 r:0.8131
et_en Dev loss: 0.4997 r:0.6639
si_en Dev loss: 0.8087 r:0.5778
ne_en Dev loss: 0.4911 r:0.7322
ru_en Dev loss: 0.4588 r:0.7442
Current avg r:0.6066 Best avg r: 0.6286
22:34:30,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:02,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:33,293 root INFO Epoch 5 Global steps: 44100 Train loss: 0.3291
en_de Dev loss: 0.8401 r:0.2499
en_zh Dev loss: 0.7317 r:0.4646
ro_en Dev loss: 0.3634 r:0.8102
et_en Dev loss: 0.4582 r:0.6713
si_en Dev loss: 0.8110 r:0.5771
ne_en Dev loss: 0.4602 r:0.7395
ru_en Dev loss: 0.4443 r:0.7407
Current avg r:0.6076 Best avg r: 0.6286
22:42:06,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:37,111 root INFO 
id:ru_en cur r: 0.7668 best r: 0.7668
22:43:37,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:08,100 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3245
en_de Dev loss: 0.8847 r:0.2499
en_zh Dev loss: 0.7315 r:0.4646
ro_en Dev loss: 0.3367 r:0.8136
et_en Dev loss: 0.4262 r:0.6833
si_en Dev loss: 0.6949 r:0.5944
ne_en Dev loss: 0.3913 r:0.7432
ru_en Dev loss: 0.3858 r:0.7731
Current avg r:0.6175 Best avg r: 0.6286
22:49:40,522 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:11,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:42,693 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3274
en_de Dev loss: 0.8643 r:0.2547
en_zh Dev loss: 0.7437 r:0.4647
ro_en Dev loss: 0.3628 r:0.8131
et_en Dev loss: 0.4660 r:0.6831
si_en Dev loss: 0.7698 r:0.5915
ne_en Dev loss: 0.4784 r:0.7432
ru_en Dev loss: 0.4163 r:0.7593
Current avg r:0.6157 Best avg r: 0.6286
22:57:17,131 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:48,273 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:19,395 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3432
en_de Dev loss: 0.9197 r:0.2404
en_zh Dev loss: 0.8138 r:0.4537
ro_en Dev loss: 0.4073 r:0.8086
et_en Dev loss: 0.5046 r:0.6749
si_en Dev loss: 0.8096 r:0.5847
ne_en Dev loss: 0.5144 r:0.7394
ru_en Dev loss: 0.5214 r:0.7359
Current avg r:0.6054 Best avg r: 0.6286
23:04:52,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:23,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:54,664 root INFO Epoch 5 Global steps: 46900 Train loss: 0.3274
en_de Dev loss: 0.8985 r:0.2446
en_zh Dev loss: 0.7929 r:0.4327
ro_en Dev loss: 0.3750 r:0.8072
et_en Dev loss: 0.4526 r:0.6755
si_en Dev loss: 0.7412 r:0.5872
ne_en Dev loss: 0.4276 r:0.7471
ru_en Dev loss: 0.5248 r:0.7215
Current avg r:0.6022 Best avg r: 0.6286
23:12:27,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:58,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:29,795 root INFO Epoch 5 Global steps: 47600 Train loss: 0.3373
en_de Dev loss: 0.8672 r:0.2388
en_zh Dev loss: 0.7173 r:0.4511
ro_en Dev loss: 0.3422 r:0.8099
et_en Dev loss: 0.4493 r:0.6692
si_en Dev loss: 0.7828 r:0.5825
ne_en Dev loss: 0.4752 r:0.7297
ru_en Dev loss: 0.4724 r:0.7236
Current avg r:0.6007 Best avg r: 0.6286
23:20:03,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:34,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:05,156 root INFO Epoch 6 Global steps: 48300 Train loss: 0.3045
en_de Dev loss: 0.8909 r:0.2289
en_zh Dev loss: 0.7493 r:0.4519
ro_en Dev loss: 0.3710 r:0.8131
et_en Dev loss: 0.4746 r:0.6709
si_en Dev loss: 0.8875 r:0.5815
ne_en Dev loss: 0.5456 r:0.7329
ru_en Dev loss: 0.4861 r:0.7343
Current avg r:0.6019 Best avg r: 0.6286
23:27:38,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:09,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:40,716 root INFO Epoch 6 Global steps: 49000 Train loss: 0.3111
en_de Dev loss: 0.9026 r:0.2287
en_zh Dev loss: 0.7437 r:0.4618
ro_en Dev loss: 0.3392 r:0.8156
et_en Dev loss: 0.4449 r:0.6778
si_en Dev loss: 0.7759 r:0.5895
ne_en Dev loss: 0.4720 r:0.7471
ru_en Dev loss: 0.4816 r:0.7398
Current avg r:0.6086 Best avg r: 0.6286
23:35:12,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:47,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:38:19,85 root INFO Epoch 6 Global steps: 49700 Train loss: 0.2980
en_de Dev loss: 0.8781 r:0.2340
en_zh Dev loss: 0.7914 r:0.4620
ro_en Dev loss: 0.3964 r:0.8136
et_en Dev loss: 0.4833 r:0.6710
si_en Dev loss: 1.0488 r:0.5764
ne_en Dev loss: 0.6138 r:0.7303
ru_en Dev loss: 0.4916 r:0.7481
Current avg r:0.6051 Best avg r: 0.6286
23:42:51,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:44:25,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:56,998 root INFO Epoch 6 Global steps: 50400 Train loss: 0.2812
en_de Dev loss: 0.8934 r:0.2205
en_zh Dev loss: 0.7627 r:0.4480
ro_en Dev loss: 0.3817 r:0.8160
et_en Dev loss: 0.4631 r:0.6700
si_en Dev loss: 0.7908 r:0.5837
ne_en Dev loss: 0.5110 r:0.7375
ru_en Dev loss: 0.5306 r:0.7285
Current avg r:0.6006 Best avg r: 0.6286
23:50:29,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:00,727 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:53:31,790 root INFO Epoch 6 Global steps: 51100 Train loss: 0.3045
en_de Dev loss: 0.8917 r:0.2272
en_zh Dev loss: 0.7897 r:0.4538
ro_en Dev loss: 0.4105 r:0.8098
et_en Dev loss: 0.4764 r:0.6594
si_en Dev loss: 0.8857 r:0.5722
ne_en Dev loss: 0.5433 r:0.7348
ru_en Dev loss: 0.5264 r:0.7335
Current avg r:0.5987 Best avg r: 0.6286
23:58:04,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:35,712 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:06,776 root INFO Epoch 6 Global steps: 51800 Train loss: 0.3056
en_de Dev loss: 0.8632 r:0.2434
en_zh Dev loss: 0.7299 r:0.4655
ro_en Dev loss: 0.3562 r:0.8129
et_en Dev loss: 0.4290 r:0.6723
si_en Dev loss: 0.8144 r:0.5760
ne_en Dev loss: 0.5434 r:0.7395
ru_en Dev loss: 0.4893 r:0.7319
Current avg r:0.6059 Best avg r: 0.6286
00:05:39,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:12,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:43,418 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2925
en_de Dev loss: 0.8706 r:0.2284
en_zh Dev loss: 0.7524 r:0.4668
ro_en Dev loss: 0.3869 r:0.8153
et_en Dev loss: 0.4759 r:0.6718
si_en Dev loss: 0.8445 r:0.5774
ne_en Dev loss: 0.4827 r:0.7386
ru_en Dev loss: 0.4291 r:0.7617
Current avg r:0.6086 Best avg r: 0.6286
00:13:16,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:47,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:16:18,314 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2894
en_de Dev loss: 0.8656 r:0.2194
en_zh Dev loss: 0.7781 r:0.4595
ro_en Dev loss: 0.3649 r:0.8156
et_en Dev loss: 0.4618 r:0.6688
si_en Dev loss: 0.8533 r:0.5709
ne_en Dev loss: 0.5796 r:0.7378
ru_en Dev loss: 0.5133 r:0.7156
Current avg r:0.5982 Best avg r: 0.6286
00:20:51,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:22,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:53,118 root INFO Epoch 6 Global steps: 53900 Train loss: 0.2755
en_de Dev loss: 0.8769 r:0.2234
en_zh Dev loss: 0.8036 r:0.4607
ro_en Dev loss: 0.3988 r:0.8136
et_en Dev loss: 0.4759 r:0.6670
si_en Dev loss: 0.8938 r:0.5683
ne_en Dev loss: 0.5054 r:0.7468
ru_en Dev loss: 0.4682 r:0.7506
Current avg r:0.6043 Best avg r: 0.6286
00:28:25,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:56,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:27,316 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2744
en_de Dev loss: 0.8639 r:0.2284
en_zh Dev loss: 0.8008 r:0.4504
ro_en Dev loss: 0.3898 r:0.8149
et_en Dev loss: 0.4481 r:0.6682
si_en Dev loss: 0.8717 r:0.5682
ne_en Dev loss: 0.4928 r:0.7374
ru_en Dev loss: 0.4993 r:0.7279
Current avg r:0.5993 Best avg r: 0.6286
00:36:02,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:33,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:04,710 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2631
en_de Dev loss: 0.8568 r:0.2295
en_zh Dev loss: 0.7431 r:0.4696
ro_en Dev loss: 0.3517 r:0.8139
et_en Dev loss: 0.4627 r:0.6705
si_en Dev loss: 0.7647 r:0.5724
ne_en Dev loss: 0.4323 r:0.7459
ru_en Dev loss: 0.4277 r:0.7452
Current avg r:0.6067 Best avg r: 0.6286
00:43:38,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:10,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:46:41,589 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2352
en_de Dev loss: 0.8704 r:0.2380
en_zh Dev loss: 0.8179 r:0.4539
ro_en Dev loss: 0.4073 r:0.8099
et_en Dev loss: 0.4856 r:0.6708
si_en Dev loss: 0.8787 r:0.5636
ne_en Dev loss: 0.5259 r:0.7463
ru_en Dev loss: 0.5013 r:0.7252
Current avg r:0.6011 Best avg r: 0.6286
00:51:13,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:52:44,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:15,493 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2689
en_de Dev loss: 0.9316 r:0.2026
en_zh Dev loss: 0.9237 r:0.4478
ro_en Dev loss: 0.5194 r:0.8023
et_en Dev loss: 0.5265 r:0.6524
si_en Dev loss: 1.1952 r:0.5462
ne_en Dev loss: 0.7405 r:0.7434
ru_en Dev loss: 0.6069 r:0.7086
Current avg r:0.5862 Best avg r: 0.6286
00:58:47,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:18,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:01:49,498 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2487
en_de Dev loss: 0.8854 r:0.2269
en_zh Dev loss: 0.7529 r:0.4707
ro_en Dev loss: 0.3464 r:0.8161
et_en Dev loss: 0.4316 r:0.6791
si_en Dev loss: 0.7638 r:0.5680
ne_en Dev loss: 0.4581 r:0.7511
ru_en Dev loss: 0.4293 r:0.7495
Current avg r:0.6088 Best avg r: 0.6286
01:06:21,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:07:52,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:09:23,515 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2514
en_de Dev loss: 0.8543 r:0.2321
en_zh Dev loss: 0.7291 r:0.4630
ro_en Dev loss: 0.3188 r:0.8178
et_en Dev loss: 0.4476 r:0.6822
si_en Dev loss: 0.7337 r:0.5689
ne_en Dev loss: 0.4078 r:0.7537
ru_en Dev loss: 0.4155 r:0.7381
Current avg r:0.6080 Best avg r: 0.6286
01:13:56,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:27,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:16:58,431 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2492
en_de Dev loss: 0.9218 r:0.2189
en_zh Dev loss: 0.8586 r:0.4476
ro_en Dev loss: 0.4263 r:0.8081
et_en Dev loss: 0.4876 r:0.6617
si_en Dev loss: 0.9093 r:0.5551
ne_en Dev loss: 0.5541 r:0.7367
ru_en Dev loss: 0.5566 r:0.7092
Current avg r:0.5910 Best avg r: 0.6286
01:21:31,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:02,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:24:33,526 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2489
en_de Dev loss: 0.8896 r:0.2100
en_zh Dev loss: 0.7984 r:0.4572
ro_en Dev loss: 0.3704 r:0.8171
et_en Dev loss: 0.4422 r:0.6709
si_en Dev loss: 0.8139 r:0.5704
ne_en Dev loss: 0.4865 r:0.7455
ru_en Dev loss: 0.4648 r:0.7327
Current avg r:0.6005 Best avg r: 0.6286
01:29:06,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:30:37,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:08,476 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2421
en_de Dev loss: 0.8982 r:0.2127
en_zh Dev loss: 0.8535 r:0.4591
ro_en Dev loss: 0.4215 r:0.8162
et_en Dev loss: 0.4868 r:0.6608
si_en Dev loss: 0.9235 r:0.5630
ne_en Dev loss: 0.5223 r:0.7382
ru_en Dev loss: 0.5527 r:0.7252
Current avg r:0.5965 Best avg r: 0.6286
01:36:41,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:38:12,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:39:43,420 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2546
en_de Dev loss: 0.8931 r:0.2258
en_zh Dev loss: 0.8278 r:0.4457
ro_en Dev loss: 0.4024 r:0.8068
et_en Dev loss: 0.4879 r:0.6503
si_en Dev loss: 0.9572 r:0.5454
ne_en Dev loss: 0.5734 r:0.7346
ru_en Dev loss: 0.5088 r:0.7184
Current avg r:0.5896 Best avg r: 0.6286
01:44:16,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:45:47,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:47:21,319 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2496
en_de Dev loss: 0.8709 r:0.2280
en_zh Dev loss: 0.7855 r:0.4539
ro_en Dev loss: 0.3901 r:0.8077
et_en Dev loss: 0.4774 r:0.6482
si_en Dev loss: 0.9677 r:0.5479
ne_en Dev loss: 0.6340 r:0.7352
ru_en Dev loss: 0.4806 r:0.7294
Current avg r:0.5929 Best avg r: 0.6286
01:51:54,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:53:25,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:54:57,928 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2396
en_de Dev loss: 0.8765 r:0.2236
en_zh Dev loss: 0.7954 r:0.4602
ro_en Dev loss: 0.3707 r:0.8122
et_en Dev loss: 0.4891 r:0.6601
si_en Dev loss: 0.9069 r:0.5614
ne_en Dev loss: 0.5491 r:0.7424
ru_en Dev loss: 0.4622 r:0.7469
Current avg r:0.6010 Best avg r: 0.6286
01:59:34,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:01:06,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:02:38,601 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2444
en_de Dev loss: 0.8715 r:0.2258
en_zh Dev loss: 0.7874 r:0.4673
ro_en Dev loss: 0.3644 r:0.8209
et_en Dev loss: 0.4994 r:0.6694
si_en Dev loss: 0.9086 r:0.5675
ne_en Dev loss: 0.5104 r:0.7347
ru_en Dev loss: 0.4861 r:0.7424
Current avg r:0.6040 Best avg r: 0.6286
02:07:18,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:08:50,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:22,579 root INFO Epoch 8 Global steps: 63700 Train loss: 0.1928
en_de Dev loss: 0.8852 r:0.2301
en_zh Dev loss: 0.8252 r:0.4572
ro_en Dev loss: 0.3912 r:0.8141
et_en Dev loss: 0.4884 r:0.6598
si_en Dev loss: 1.0036 r:0.5566
ne_en Dev loss: 0.5816 r:0.7389
ru_en Dev loss: 0.4658 r:0.7532
Current avg r:0.6014 Best avg r: 0.6286
02:15:00,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:32,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:18:04,612 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2209
en_de Dev loss: 0.8872 r:0.2253
en_zh Dev loss: 0.8430 r:0.4409
ro_en Dev loss: 0.3894 r:0.8085
et_en Dev loss: 0.4906 r:0.6549
si_en Dev loss: 0.9572 r:0.5535
ne_en Dev loss: 0.5946 r:0.7395
ru_en Dev loss: 0.5156 r:0.7225
Current avg r:0.5921 Best avg r: 0.6286
02:22:42,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:14,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:46,872 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2326
en_de Dev loss: 0.8986 r:0.2200
en_zh Dev loss: 0.8498 r:0.4493
ro_en Dev loss: 0.4255 r:0.8074
et_en Dev loss: 0.4888 r:0.6515
si_en Dev loss: 1.0985 r:0.5414
ne_en Dev loss: 0.6252 r:0.7391
ru_en Dev loss: 0.5481 r:0.7202
Current avg r:0.5899 Best avg r: 0.6286
02:30:25,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:59,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:33:30,356 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2146
en_de Dev loss: 0.8741 r:0.2242
en_zh Dev loss: 0.7843 r:0.4627
ro_en Dev loss: 0.3583 r:0.8159
et_en Dev loss: 0.4547 r:0.6541
si_en Dev loss: 0.8650 r:0.5545
ne_en Dev loss: 0.5093 r:0.7367
ru_en Dev loss: 0.4580 r:0.7353
Current avg r:0.5976 Best avg r: 0.6286
02:38:03,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:39:34,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:41:05,772 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2247
en_de Dev loss: 0.9091 r:0.2109
en_zh Dev loss: 0.8042 r:0.4593
ro_en Dev loss: 0.3817 r:0.8134
et_en Dev loss: 0.4868 r:0.6536
si_en Dev loss: 0.9077 r:0.5545
ne_en Dev loss: 0.4897 r:0.7376
ru_en Dev loss: 0.5039 r:0.7277
Current avg r:0.5939 Best avg r: 0.6286
02:45:42,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:47:14,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:48:48,257 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2133
en_de Dev loss: 0.8779 r:0.2333
en_zh Dev loss: 0.8145 r:0.4592
ro_en Dev loss: 0.3914 r:0.8108
et_en Dev loss: 0.4955 r:0.6487
si_en Dev loss: 0.9721 r:0.5544
ne_en Dev loss: 0.6019 r:0.7398
ru_en Dev loss: 0.5122 r:0.7211
Current avg r:0.5953 Best avg r: 0.6286
02:53:28,683 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:55:00,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:56:32,645 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2119
en_de Dev loss: 0.9071 r:0.2123
en_zh Dev loss: 0.8529 r:0.4551
ro_en Dev loss: 0.3816 r:0.8176
et_en Dev loss: 0.5028 r:0.6688
si_en Dev loss: 0.8414 r:0.5644
ne_en Dev loss: 0.4655 r:0.7426
ru_en Dev loss: 0.5129 r:0.7292
Current avg r:0.5986 Best avg r: 0.6286
03:01:10,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:02:45,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:16,823 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2314
en_de Dev loss: 0.8821 r:0.2101
en_zh Dev loss: 0.7540 r:0.4693
ro_en Dev loss: 0.3605 r:0.8138
et_en Dev loss: 0.4782 r:0.6510
si_en Dev loss: 0.8888 r:0.5494
ne_en Dev loss: 0.4924 r:0.7393
ru_en Dev loss: 0.5003 r:0.7174
Current avg r:0.5929 Best avg r: 0.6286
03:08:50,296 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:21,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:52,883 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2131
en_de Dev loss: 0.8821 r:0.2107
en_zh Dev loss: 0.7865 r:0.4536
ro_en Dev loss: 0.3393 r:0.8156
et_en Dev loss: 0.4887 r:0.6466
si_en Dev loss: 0.8747 r:0.5442
ne_en Dev loss: 0.4681 r:0.7363
ru_en Dev loss: 0.4336 r:0.7413
Current avg r:0.5926 Best avg r: 0.6286
03:16:27,294 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:17:59,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:31,47 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2181
en_de Dev loss: 0.9149 r:0.1985
en_zh Dev loss: 0.8279 r:0.4537
ro_en Dev loss: 0.4142 r:0.8054
et_en Dev loss: 0.5095 r:0.6431
si_en Dev loss: 1.0404 r:0.5354
ne_en Dev loss: 0.6143 r:0.7326
ru_en Dev loss: 0.5494 r:0.7156
Current avg r:0.5835 Best avg r: 0.6286
03:24:07,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:25:39,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:27:13,840 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2241
en_de Dev loss: 0.8768 r:0.2107
en_zh Dev loss: 0.7590 r:0.4614
ro_en Dev loss: 0.3456 r:0.8113
et_en Dev loss: 0.5037 r:0.6470
si_en Dev loss: 0.8012 r:0.5568
ne_en Dev loss: 0.4537 r:0.7419
ru_en Dev loss: 0.4656 r:0.7237
Current avg r:0.5933 Best avg r: 0.6286
03:31:49,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:33:21,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:34:53,173 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2121
en_de Dev loss: 0.8916 r:0.2143
en_zh Dev loss: 0.7890 r:0.4593
ro_en Dev loss: 0.3623 r:0.8177
et_en Dev loss: 0.5084 r:0.6580
si_en Dev loss: 0.8656 r:0.5628
ne_en Dev loss: 0.4870 r:0.7452
ru_en Dev loss: 0.4407 r:0.7525
Current avg r:0.6014 Best avg r: 0.6286
03:39:30,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:41:02,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:42:33,483 root INFO Epoch 9 Global steps: 72100 Train loss: 0.1990
en_de Dev loss: 0.8837 r:0.2238
en_zh Dev loss: 0.8003 r:0.4635
ro_en Dev loss: 0.3671 r:0.8158
et_en Dev loss: 0.5144 r:0.6584
si_en Dev loss: 0.8567 r:0.5556
ne_en Dev loss: 0.5094 r:0.7399
ru_en Dev loss: 0.4670 r:0.7369
Current avg r:0.5991 Best avg r: 0.6286
03:47:06,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:48:39,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:50:11,325 root INFO Epoch 9 Global steps: 72800 Train loss: 0.2001
en_de Dev loss: 0.8661 r:0.2280
en_zh Dev loss: 0.7861 r:0.4615
ro_en Dev loss: 0.3582 r:0.8142
et_en Dev loss: 0.4959 r:0.6514
si_en Dev loss: 0.9102 r:0.5484
ne_en Dev loss: 0.5764 r:0.7386
ru_en Dev loss: 0.4755 r:0.7326
Current avg r:0.5964 Best avg r: 0.6286
03:54:50,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:56:22,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:57:53,879 root INFO Epoch 9 Global steps: 73500 Train loss: 0.2040
en_de Dev loss: 0.8768 r:0.2224
en_zh Dev loss: 0.7739 r:0.4667
ro_en Dev loss: 0.3485 r:0.8194
et_en Dev loss: 0.4637 r:0.6591
si_en Dev loss: 0.8445 r:0.5570
ne_en Dev loss: 0.4902 r:0.7397
ru_en Dev loss: 0.4565 r:0.7408
Current avg r:0.6007 Best avg r: 0.6286
04:02:32,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:04:04,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:05:36,549 root INFO Epoch 9 Global steps: 74200 Train loss: 0.1898
en_de Dev loss: 0.9120 r:0.2310
en_zh Dev loss: 0.9069 r:0.4559
ro_en Dev loss: 0.4099 r:0.8137
et_en Dev loss: 0.5250 r:0.6507
si_en Dev loss: 0.9792 r:0.5438
ne_en Dev loss: 0.5953 r:0.7352
ru_en Dev loss: 0.5360 r:0.7210
Current avg r:0.5930 Best avg r: 0.6286
04:10:12,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:11:43,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:13:15,270 root INFO Epoch 9 Global steps: 74900 Train loss: 0.1954
en_de Dev loss: 0.9101 r:0.2285
en_zh Dev loss: 0.8172 r:0.4595
ro_en Dev loss: 0.3832 r:0.8162
et_en Dev loss: 0.4826 r:0.6547
si_en Dev loss: 0.9896 r:0.5371
ne_en Dev loss: 0.5383 r:0.7378
ru_en Dev loss: 0.4910 r:0.7352
Current avg r:0.5956 Best avg r: 0.6286
04:17:48,502 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:19:21,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:20:52,513 root INFO Epoch 9 Global steps: 75600 Train loss: 0.1899
en_de Dev loss: 0.8927 r:0.2287
en_zh Dev loss: 0.8170 r:0.4586
ro_en Dev loss: 0.3692 r:0.8150
et_en Dev loss: 0.4960 r:0.6421
si_en Dev loss: 0.9219 r:0.5383
ne_en Dev loss: 0.5063 r:0.7367
ru_en Dev loss: 0.5225 r:0.7164
Current avg r:0.5908 Best avg r: 0.6286
04:25:29,5 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:27:00,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:28:32,823 root INFO Epoch 9 Global steps: 76300 Train loss: 0.1980
en_de Dev loss: 0.8826 r:0.2438
en_zh Dev loss: 0.7976 r:0.4864
ro_en Dev loss: 0.3644 r:0.8165
et_en Dev loss: 0.5388 r:0.6557
si_en Dev loss: 0.8931 r:0.5483
ne_en Dev loss: 0.4803 r:0.7405
ru_en Dev loss: 0.4611 r:0.7374
Current avg r:0.6041 Best avg r: 0.6286
04:33:11,36 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:34:44,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:36:16,147 root INFO Epoch 9 Global steps: 77000 Train loss: 0.1954
en_de Dev loss: 0.8962 r:0.2169
en_zh Dev loss: 0.7927 r:0.4761
ro_en Dev loss: 0.3745 r:0.8142
et_en Dev loss: 0.5031 r:0.6537
si_en Dev loss: 0.8953 r:0.5493
ne_en Dev loss: 0.5227 r:0.7404
ru_en Dev loss: 0.4947 r:0.7272
Current avg r:0.5968 Best avg r: 0.6286
04:40:52,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:42:24,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:43:56,383 root INFO Epoch 9 Global steps: 77700 Train loss: 0.1905
en_de Dev loss: 0.9240 r:0.1930
en_zh Dev loss: 0.8003 r:0.4577
ro_en Dev loss: 0.3704 r:0.8153
et_en Dev loss: 0.5092 r:0.6485
si_en Dev loss: 0.9573 r:0.5401
ne_en Dev loss: 0.5207 r:0.7317
ru_en Dev loss: 0.4819 r:0.7318
Current avg r:0.5883 Best avg r: 0.6286
04:48:32,754 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:04,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:35,161 root INFO Epoch 9 Global steps: 78400 Train loss: 0.1867
en_de Dev loss: 0.8865 r:0.2035
en_zh Dev loss: 0.7679 r:0.4692
ro_en Dev loss: 0.3474 r:0.8180
et_en Dev loss: 0.4852 r:0.6497
si_en Dev loss: 0.9497 r:0.5375
ne_en Dev loss: 0.5388 r:0.7337
ru_en Dev loss: 0.4910 r:0.7235
Current avg r:0.5907 Best avg r: 0.6286
04:56:11,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:42,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:59:16,352 root INFO Epoch 9 Global steps: 79100 Train loss: 0.1829
en_de Dev loss: 0.9156 r:0.1905
en_zh Dev loss: 0.8272 r:0.4488
ro_en Dev loss: 0.3855 r:0.8109
et_en Dev loss: 0.4851 r:0.6434
si_en Dev loss: 1.0225 r:0.5256
ne_en Dev loss: 0.6713 r:0.7288
ru_en Dev loss: 0.5137 r:0.7146
Current avg r:0.5804 Best avg r: 0.6286
05:03:53,84 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:05:24,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:06:56,550 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1744
en_de Dev loss: 0.9325 r:0.1882
en_zh Dev loss: 0.8353 r:0.4615
ro_en Dev loss: 0.4012 r:0.8146
et_en Dev loss: 0.5026 r:0.6505
si_en Dev loss: 1.0336 r:0.5359
ne_en Dev loss: 0.6241 r:0.7350
ru_en Dev loss: 0.5162 r:0.7257
Current avg r:0.5873 Best avg r: 0.6286
05:11:31,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:13:03,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:14:35,135 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1798
en_de Dev loss: 0.8955 r:0.2012
en_zh Dev loss: 0.7948 r:0.4624
ro_en Dev loss: 0.3565 r:0.8158
et_en Dev loss: 0.4883 r:0.6496
si_en Dev loss: 0.9112 r:0.5425
ne_en Dev loss: 0.5052 r:0.7395
ru_en Dev loss: 0.4831 r:0.7288
Current avg r:0.5914 Best avg r: 0.6286
05:19:10,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:42,69 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:22:13,159 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1719
en_de Dev loss: 0.9090 r:0.2022
en_zh Dev loss: 0.8406 r:0.4624
ro_en Dev loss: 0.3983 r:0.8118
et_en Dev loss: 0.5106 r:0.6425
si_en Dev loss: 1.0263 r:0.5348
ne_en Dev loss: 0.5931 r:0.7358
ru_en Dev loss: 0.5233 r:0.7237
Current avg r:0.5876 Best avg r: 0.6286
05:26:46,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:18,906 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:29:50,837 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1734
en_de Dev loss: 0.9316 r:0.1854
en_zh Dev loss: 0.8305 r:0.4484
ro_en Dev loss: 0.3755 r:0.8142
et_en Dev loss: 0.5023 r:0.6363
si_en Dev loss: 0.9810 r:0.5300
ne_en Dev loss: 0.6178 r:0.7362
ru_en Dev loss: 0.5072 r:0.7183
Current avg r:0.5813 Best avg r: 0.6286
05:34:28,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:00,8 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:37:31,947 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1756
en_de Dev loss: 0.8858 r:0.2000
en_zh Dev loss: 0.7843 r:0.4640
ro_en Dev loss: 0.3238 r:0.8214
et_en Dev loss: 0.4679 r:0.6656
si_en Dev loss: 0.8055 r:0.5565
ne_en Dev loss: 0.4446 r:0.7409
ru_en Dev loss: 0.4202 r:0.7504
Current avg r:0.5998 Best avg r: 0.6286
05:42:10,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:42,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:14,369 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1732
en_de Dev loss: 0.9053 r:0.1985
en_zh Dev loss: 0.7736 r:0.4786
ro_en Dev loss: 0.3752 r:0.8140
et_en Dev loss: 0.4977 r:0.6518
si_en Dev loss: 0.9476 r:0.5422
ne_en Dev loss: 0.5647 r:0.7392
ru_en Dev loss: 0.4798 r:0.7357
Current avg r:0.5943 Best avg r: 0.6286
05:49:53,403 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:26,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:52:57,255 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1686
en_de Dev loss: 0.9376 r:0.1953
en_zh Dev loss: 0.8062 r:0.4769
ro_en Dev loss: 0.3865 r:0.8104
et_en Dev loss: 0.5114 r:0.6422
si_en Dev loss: 0.9720 r:0.5305
ne_en Dev loss: 0.5519 r:0.7333
ru_en Dev loss: 0.4735 r:0.7355
Current avg r:0.5892 Best avg r: 0.6286
05:57:32,35 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:03,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:00:34,368 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1671
en_de Dev loss: 0.9359 r:0.1755
en_zh Dev loss: 0.7979 r:0.4719
ro_en Dev loss: 0.3820 r:0.8128
et_en Dev loss: 0.4821 r:0.6534
si_en Dev loss: 0.9982 r:0.5374
ne_en Dev loss: 0.6270 r:0.7349
ru_en Dev loss: 0.5346 r:0.7109
Current avg r:0.5852 Best avg r: 0.6286
06:05:07,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:06:38,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:09,989 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1794
en_de Dev loss: 0.9230 r:0.1916
en_zh Dev loss: 0.7900 r:0.4751
ro_en Dev loss: 0.3826 r:0.8115
et_en Dev loss: 0.4882 r:0.6432
si_en Dev loss: 1.0505 r:0.5276
ne_en Dev loss: 0.6201 r:0.7347
ru_en Dev loss: 0.5061 r:0.7207
Current avg r:0.5863 Best avg r: 0.6286
06:12:43,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:15,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:48,377 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1779
en_de Dev loss: 0.8880 r:0.1870
en_zh Dev loss: 0.7425 r:0.4748
ro_en Dev loss: 0.3388 r:0.8140
et_en Dev loss: 0.5098 r:0.6568
si_en Dev loss: 0.8288 r:0.5483
ne_en Dev loss: 0.4598 r:0.7336
ru_en Dev loss: 0.4173 r:0.7348
Current avg r:0.5928 Best avg r: 0.6286
06:20:23,128 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:21:54,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:25,455 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1733
en_de Dev loss: 0.9069 r:0.1944
en_zh Dev loss: 0.8123 r:0.4637
ro_en Dev loss: 0.3923 r:0.8113
et_en Dev loss: 0.5011 r:0.6475
si_en Dev loss: 1.0290 r:0.5293
ne_en Dev loss: 0.7094 r:0.7213
ru_en Dev loss: 0.4986 r:0.7248
Current avg r:0.5846 Best avg r: 0.6286
06:27:59,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:30,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:01,996 root INFO Epoch 11 Global steps: 87500 Train loss: 0.2249
en_de Dev loss: 0.9024 r:0.1845
en_zh Dev loss: 0.7825 r:0.4633
ro_en Dev loss: 0.3679 r:0.8089
et_en Dev loss: 0.4867 r:0.6393
si_en Dev loss: 1.0012 r:0.5257
ne_en Dev loss: 0.6499 r:0.7192
ru_en Dev loss: 0.5013 r:0.7120
Current avg r:0.5790 Best avg r: 0.6286
06:35:34,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:06,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:38:38,636 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1572
en_de Dev loss: 0.9440 r:0.1711
en_zh Dev loss: 0.8522 r:0.4511
ro_en Dev loss: 0.3827 r:0.8150
et_en Dev loss: 0.4996 r:0.6523
si_en Dev loss: 0.9455 r:0.5419
ne_en Dev loss: 0.5665 r:0.7291
ru_en Dev loss: 0.5164 r:0.7273
Current avg r:0.5840 Best avg r: 0.6286
06:43:12,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:44:43,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:15,31 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1605
en_de Dev loss: 0.9082 r:0.1770
en_zh Dev loss: 0.7689 r:0.4709
ro_en Dev loss: 0.3539 r:0.8164
et_en Dev loss: 0.5104 r:0.6601
si_en Dev loss: 0.8914 r:0.5478
ne_en Dev loss: 0.4858 r:0.7341
ru_en Dev loss: 0.4259 r:0.7520
Current avg r:0.5941 Best avg r: 0.6286
06:50:47,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:18,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:53:49,549 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1454
en_de Dev loss: 0.9142 r:0.1893
en_zh Dev loss: 0.7658 r:0.4784
ro_en Dev loss: 0.3730 r:0.8123
et_en Dev loss: 0.4842 r:0.6526
si_en Dev loss: 0.9249 r:0.5373
ne_en Dev loss: 0.5585 r:0.7258
ru_en Dev loss: 0.4712 r:0.7354
Current avg r:0.5901 Best avg r: 0.6286
06:58:21,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:59:52,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:24,58 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1509
en_de Dev loss: 0.9370 r:0.1724
en_zh Dev loss: 0.8415 r:0.4735
ro_en Dev loss: 0.4087 r:0.8146
et_en Dev loss: 0.4910 r:0.6679
si_en Dev loss: 1.0052 r:0.5377
ne_en Dev loss: 0.5991 r:0.7233
ru_en Dev loss: 0.5246 r:0.7364
Current avg r:0.5894 Best avg r: 0.6286
07:05:56,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:07:27,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:58,536 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1558
en_de Dev loss: 0.9350 r:0.1737
en_zh Dev loss: 0.7783 r:0.4781
ro_en Dev loss: 0.3847 r:0.8105
et_en Dev loss: 0.4942 r:0.6606
si_en Dev loss: 0.9095 r:0.5375
ne_en Dev loss: 0.5475 r:0.7308
ru_en Dev loss: 0.5077 r:0.7182
Current avg r:0.5871 Best avg r: 0.6286
07:13:32,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:15:03,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:16:34,450 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1539
en_de Dev loss: 0.9513 r:0.1773
en_zh Dev loss: 0.8650 r:0.4739
ro_en Dev loss: 0.4452 r:0.8076
et_en Dev loss: 0.5262 r:0.6523
si_en Dev loss: 1.0963 r:0.5281
ne_en Dev loss: 0.6443 r:0.7243
ru_en Dev loss: 0.5777 r:0.7142
Current avg r:0.5825 Best avg r: 0.6286
07:21:06,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:22:39,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:24:10,316 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1503
en_de Dev loss: 0.9350 r:0.1748
en_zh Dev loss: 0.7853 r:0.4731
ro_en Dev loss: 0.3729 r:0.8121
et_en Dev loss: 0.5292 r:0.6542
si_en Dev loss: 0.8915 r:0.5402
ne_en Dev loss: 0.5376 r:0.7271
ru_en Dev loss: 0.4330 r:0.7484
Current avg r:0.5900 Best avg r: 0.6286
07:28:42,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:30:13,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:31:44,667 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1586
en_de Dev loss: 0.9290 r:0.1831
en_zh Dev loss: 0.8113 r:0.4794
ro_en Dev loss: 0.3697 r:0.8105
et_en Dev loss: 0.4790 r:0.6484
si_en Dev loss: 0.9838 r:0.5319
ne_en Dev loss: 0.5777 r:0.7258
ru_en Dev loss: 0.4828 r:0.7317
Current avg r:0.5873 Best avg r: 0.6286
07:36:16,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:37:48,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:39:19,72 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1528
en_de Dev loss: 0.9365 r:0.1726
en_zh Dev loss: 0.7985 r:0.4666
ro_en Dev loss: 0.3889 r:0.8080
et_en Dev loss: 0.4826 r:0.6620
si_en Dev loss: 0.9454 r:0.5316
ne_en Dev loss: 0.6019 r:0.7232
ru_en Dev loss: 0.5012 r:0.7208
Current avg r:0.5835 Best avg r: 0.6286
07:43:53,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:45:24,80 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:46:55,158 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1488
en_de Dev loss: 0.9187 r:0.1791
en_zh Dev loss: 0.7859 r:0.4707
ro_en Dev loss: 0.3954 r:0.8101
et_en Dev loss: 0.4636 r:0.6602
si_en Dev loss: 0.9426 r:0.5313
ne_en Dev loss: 0.6233 r:0.7265
ru_en Dev loss: 0.4883 r:0.7307
Current avg r:0.5869 Best avg r: 0.6286
07:51:28,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:52:59,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:54:30,823 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1489
en_de Dev loss: 0.9453 r:0.1783
en_zh Dev loss: 0.8297 r:0.4662
ro_en Dev loss: 0.3738 r:0.8117
et_en Dev loss: 0.5060 r:0.6541
si_en Dev loss: 0.9347 r:0.5326
ne_en Dev loss: 0.5416 r:0.7293
ru_en Dev loss: 0.5038 r:0.7177
Current avg r:0.5843 Best avg r: 0.6286
07:59:04,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:00:35,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:06,362 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1397
en_de Dev loss: 0.9328 r:0.1851
en_zh Dev loss: 0.7932 r:0.4848
ro_en Dev loss: 0.3534 r:0.8180
et_en Dev loss: 0.4974 r:0.6595
si_en Dev loss: 0.9085 r:0.5472
ne_en Dev loss: 0.4814 r:0.7299
ru_en Dev loss: 0.4832 r:0.7338
Current avg r:0.5941 Best avg r: 0.6286
08:06:38,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:09,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:09:40,577 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1382
en_de Dev loss: 0.9137 r:0.1778
en_zh Dev loss: 0.7664 r:0.4777
ro_en Dev loss: 0.3531 r:0.8168
et_en Dev loss: 0.4727 r:0.6613
si_en Dev loss: 0.9455 r:0.5365
ne_en Dev loss: 0.5326 r:0.7340
ru_en Dev loss: 0.4620 r:0.7322
Current avg r:0.5909 Best avg r: 0.6286
08:14:12,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:43,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:17:14,631 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1377
en_de Dev loss: 0.9309 r:0.1744
en_zh Dev loss: 0.7932 r:0.4833
ro_en Dev loss: 0.3880 r:0.8116
et_en Dev loss: 0.4930 r:0.6489
si_en Dev loss: 1.0385 r:0.5257
ne_en Dev loss: 0.5866 r:0.7260
ru_en Dev loss: 0.4995 r:0.7329
Current avg r:0.5861 Best avg r: 0.6286
08:21:46,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:23:17,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:24:50,362 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1375
en_de Dev loss: 0.9562 r:0.1642
en_zh Dev loss: 0.8303 r:0.4747
ro_en Dev loss: 0.4115 r:0.8121
et_en Dev loss: 0.5019 r:0.6543
si_en Dev loss: 0.9527 r:0.5415
ne_en Dev loss: 0.5556 r:0.7227
ru_en Dev loss: 0.4959 r:0.7382
Current avg r:0.5868 Best avg r: 0.6286
08:29:24,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:30:55,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:32:26,770 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1386
en_de Dev loss: 0.9251 r:0.1827
en_zh Dev loss: 0.7913 r:0.4867
ro_en Dev loss: 0.3897 r:0.8114
et_en Dev loss: 0.5038 r:0.6583
si_en Dev loss: 0.9217 r:0.5399
ne_en Dev loss: 0.6036 r:0.7301
ru_en Dev loss: 0.4475 r:0.7469
Current avg r:0.5937 Best avg r: 0.6286
08:37:00,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:38:32,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:40:05,942 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1390
en_de Dev loss: 0.9186 r:0.1795
en_zh Dev loss: 0.7662 r:0.4779
ro_en Dev loss: 0.3541 r:0.8118
et_en Dev loss: 0.4705 r:0.6537
si_en Dev loss: 0.8965 r:0.5375
ne_en Dev loss: 0.5713 r:0.7299
ru_en Dev loss: 0.4694 r:0.7292
Current avg r:0.5885 Best avg r: 0.6286
08:44:44,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:46:16,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:47:48,688 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1370
en_de Dev loss: 0.9491 r:0.1714
en_zh Dev loss: 0.8470 r:0.4627
ro_en Dev loss: 0.3875 r:0.8133
et_en Dev loss: 0.5150 r:0.6477
si_en Dev loss: 0.9737 r:0.5339
ne_en Dev loss: 0.5630 r:0.7286
ru_en Dev loss: 0.4908 r:0.7333
Current avg r:0.5844 Best avg r: 0.6286
08:52:26,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:58,986 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:55:31,53 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1386
en_de Dev loss: 0.9472 r:0.1810
en_zh Dev loss: 0.8077 r:0.4753
ro_en Dev loss: 0.3544 r:0.8158
et_en Dev loss: 0.4803 r:0.6585
si_en Dev loss: 0.8659 r:0.5412
ne_en Dev loss: 0.4941 r:0.7353
ru_en Dev loss: 0.4522 r:0.7453
Current avg r:0.5932 Best avg r: 0.6286
09:00:11,987 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:43,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:15,613 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1408
en_de Dev loss: 0.9337 r:0.1814
en_zh Dev loss: 0.8039 r:0.4724
ro_en Dev loss: 0.3862 r:0.8136
et_en Dev loss: 0.5287 r:0.6478
si_en Dev loss: 0.9606 r:0.5324
ne_en Dev loss: 0.5665 r:0.7207
ru_en Dev loss: 0.5303 r:0.7095
Current avg r:0.5825 Best avg r: 0.6286
09:07:48,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:19,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:50,959 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1370
en_de Dev loss: 0.9771 r:0.1679
en_zh Dev loss: 0.8857 r:0.4717
ro_en Dev loss: 0.4281 r:0.8114
et_en Dev loss: 0.5198 r:0.6495
si_en Dev loss: 1.0501 r:0.5328
ne_en Dev loss: 0.6750 r:0.7268
ru_en Dev loss: 0.5463 r:0.7223
Current avg r:0.5832 Best avg r: 0.6286
09:15:26,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:16:57,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:18:29,556 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1438
en_de Dev loss: 0.9545 r:0.1669
en_zh Dev loss: 0.8090 r:0.4691
ro_en Dev loss: 0.3762 r:0.8157
et_en Dev loss: 0.5220 r:0.6473
si_en Dev loss: 0.9195 r:0.5375
ne_en Dev loss: 0.5482 r:0.7282
ru_en Dev loss: 0.4559 r:0.7406
Current avg r:0.5865 Best avg r: 0.6286
09:23:03,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:24:34,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:05,598 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1246
en_de Dev loss: 0.9722 r:0.1641
en_zh Dev loss: 0.8074 r:0.4738
ro_en Dev loss: 0.3846 r:0.8129
et_en Dev loss: 0.5004 r:0.6538
si_en Dev loss: 0.9824 r:0.5365
ne_en Dev loss: 0.5617 r:0.7306
ru_en Dev loss: 0.4751 r:0.7456
Current avg r:0.5882 Best avg r: 0.6286
09:30:39,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:32:10,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:33:41,734 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1318
en_de Dev loss: 0.9576 r:0.1595
en_zh Dev loss: 0.7873 r:0.4788
ro_en Dev loss: 0.3544 r:0.8158
et_en Dev loss: 0.4844 r:0.6585
si_en Dev loss: 0.9454 r:0.5338
ne_en Dev loss: 0.5847 r:0.7221
ru_en Dev loss: 0.4481 r:0.7431
Current avg r:0.5874 Best avg r: 0.6286
09:38:15,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:39:46,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:41:17,580 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1243
en_de Dev loss: 0.9685 r:0.1623
en_zh Dev loss: 0.8432 r:0.4695
ro_en Dev loss: 0.4062 r:0.8087
et_en Dev loss: 0.5161 r:0.6484
si_en Dev loss: 1.0772 r:0.5230
ne_en Dev loss: 0.7352 r:0.7209
ru_en Dev loss: 0.5214 r:0.7224
Current avg r:0.5793 Best avg r: 0.6286
09:45:50,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:21,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:48:53,4 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1271
en_de Dev loss: 0.9536 r:0.1721
en_zh Dev loss: 0.8409 r:0.4806
ro_en Dev loss: 0.4086 r:0.8133
et_en Dev loss: 0.4866 r:0.6594
si_en Dev loss: 0.9813 r:0.5387
ne_en Dev loss: 0.5424 r:0.7283
ru_en Dev loss: 0.5379 r:0.7293
Current avg r:0.5888 Best avg r: 0.6286
09:53:27,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:54:58,545 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:29,503 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1230
en_de Dev loss: 0.9992 r:0.1644
en_zh Dev loss: 0.8442 r:0.4740
ro_en Dev loss: 0.4273 r:0.8103
et_en Dev loss: 0.5071 r:0.6580
si_en Dev loss: 1.0444 r:0.5299
ne_en Dev loss: 0.6072 r:0.7319
ru_en Dev loss: 0.5242 r:0.7332
Current avg r:0.5860 Best avg r: 0.6286
10:01:04,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:35,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:04:06,465 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1292
en_de Dev loss: 0.9568 r:0.1750
en_zh Dev loss: 0.7842 r:0.4846
ro_en Dev loss: 0.3736 r:0.8159
et_en Dev loss: 0.5037 r:0.6661
si_en Dev loss: 0.8898 r:0.5440
ne_en Dev loss: 0.5217 r:0.7271
ru_en Dev loss: 0.4478 r:0.7475
Current avg r:0.5943 Best avg r: 0.6286
10:08:38,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:09,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:40,565 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1250
en_de Dev loss: 0.9474 r:0.1720
en_zh Dev loss: 0.7834 r:0.4763
ro_en Dev loss: 0.3746 r:0.8120
et_en Dev loss: 0.4754 r:0.6560
si_en Dev loss: 0.9721 r:0.5301
ne_en Dev loss: 0.5833 r:0.7275
ru_en Dev loss: 0.4623 r:0.7397
Current avg r:0.5877 Best avg r: 0.6286
10:16:12,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:17:45,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:16,365 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1203
en_de Dev loss: 0.9495 r:0.1688
en_zh Dev loss: 0.7699 r:0.4794
ro_en Dev loss: 0.3578 r:0.8144
et_en Dev loss: 0.4746 r:0.6625
si_en Dev loss: 0.8688 r:0.5377
ne_en Dev loss: 0.5197 r:0.7247
ru_en Dev loss: 0.4501 r:0.7386
Current avg r:0.5894 Best avg r: 0.6286
10:23:48,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:19,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:50,518 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1242
en_de Dev loss: 0.9706 r:0.1670
en_zh Dev loss: 0.8268 r:0.4696
ro_en Dev loss: 0.3626 r:0.8133
et_en Dev loss: 0.4787 r:0.6507
si_en Dev loss: 0.9580 r:0.5298
ne_en Dev loss: 0.5370 r:0.7259
ru_en Dev loss: 0.4420 r:0.7430
Current avg r:0.5856 Best avg r: 0.6286
10:31:22,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
