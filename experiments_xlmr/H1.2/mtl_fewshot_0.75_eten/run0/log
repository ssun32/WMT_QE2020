14:55:50,883 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:29,816 root INFO 
id:ro_en cur r: 0.5753 best r: 0.5753
14:56:55,826 root INFO 
id:et_en cur r: 0.4556 best r: 0.4556
14:57:08,833 root INFO 
id:si_en cur r: 0.2355 best r: 0.2355
14:57:21,842 root INFO 
id:ne_en cur r: 0.4711 best r: 0.4711
14:57:34,766 root INFO 
id:ru_en cur r: 0.3925 best r: 0.3925
14:57:34,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:05,574 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
14:59:05,581 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:59:05,586 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:59:05,591 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
14:59:05,595 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
14:59:05,600 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:59:05,605 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:59:18,606 root INFO Epoch 0 Global steps: 700 Train loss: 0.8452
en_de Dev loss: 0.8864 r:0.0501
en_zh Dev loss: 0.7904 r:0.2502
ro_en Dev loss: 0.7572 r:0.5848
et_en Dev loss: 0.6565 r:0.4752
si_en Dev loss: 0.7741 r:0.4420
ne_en Dev loss: 0.7008 r:0.4913
ru_en Dev loss: 0.7483 r:0.5444
Current avg r:0.4054 Best avg r: 0.4054
15:03:51,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:17,480 root INFO 
id:en_zh cur r: 0.1940 best r: 0.1940
15:04:30,466 root INFO 
id:ro_en cur r: 0.6130 best r: 0.6130
15:04:56,468 root INFO 
id:et_en cur r: 0.5488 best r: 0.5488
15:05:09,472 root INFO 
id:si_en cur r: 0.4038 best r: 0.4038
15:05:22,474 root INFO 
id:ne_en cur r: 0.5712 best r: 0.5712
15:05:35,402 root INFO 
id:ru_en cur r: 0.6548 best r: 0.6548
15:05:35,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:06,177 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
15:07:06,184 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:07:06,190 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:07:06,196 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
15:07:06,201 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
15:07:06,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:07:06,211 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:07:19,218 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7862
en_de Dev loss: 0.9072 r:0.0844
en_zh Dev loss: 0.7650 r:0.2854
ro_en Dev loss: 0.6464 r:0.6492
et_en Dev loss: 0.5459 r:0.5344
si_en Dev loss: 0.7440 r:0.4416
ne_en Dev loss: 0.5790 r:0.5584
ru_en Dev loss: 0.5611 r:0.6583
Current avg r:0.4588 Best avg r: 0.4588
15:11:53,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:19,312 root INFO 
id:en_zh cur r: 0.2344 best r: 0.2344
15:12:32,297 root INFO 
id:ro_en cur r: 0.6368 best r: 0.6368
15:12:58,296 root INFO 
id:et_en cur r: 0.5760 best r: 0.5760
15:13:11,298 root INFO 
id:si_en cur r: 0.4106 best r: 0.4106
15:13:24,293 root INFO 
id:ne_en cur r: 0.5832 best r: 0.5832
15:13:37,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:15:07,976 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
15:15:07,983 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:15:07,987 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:15:07,992 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
15:15:07,997 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
15:15:08,2 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:15:08,7 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:15:21,0 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7615
en_de Dev loss: 0.9494 r:0.1091
en_zh Dev loss: 0.8103 r:0.2794
ro_en Dev loss: 0.5352 r:0.6795
et_en Dev loss: 0.4820 r:0.5872
si_en Dev loss: 0.7381 r:0.4534
ne_en Dev loss: 0.5348 r:0.5855
ru_en Dev loss: 0.5623 r:0.6444
Current avg r:0.4769 Best avg r: 0.4769
15:19:54,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:20:07,51 root INFO 
id:en_de cur r: 0.0367 best r: 0.0367
15:20:20,7 root INFO 
id:en_zh cur r: 0.2929 best r: 0.2929
15:20:32,992 root INFO 
id:ro_en cur r: 0.6980 best r: 0.6980
15:20:58,983 root INFO 
id:et_en cur r: 0.6413 best r: 0.6413
15:21:11,993 root INFO 
id:si_en cur r: 0.4460 best r: 0.4460
15:21:25,0 root INFO 
id:ne_en cur r: 0.6262 best r: 0.6262
15:21:37,918 root INFO 
id:ru_en cur r: 0.6645 best r: 0.6645
15:21:37,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:08,683 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
15:23:08,689 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:23:08,693 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:23:08,698 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
15:23:08,702 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
15:23:08,707 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:23:08,712 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:23:21,707 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7190
en_de Dev loss: 0.9318 r:0.1418
en_zh Dev loss: 0.7754 r:0.3352
ro_en Dev loss: 0.5056 r:0.7343
et_en Dev loss: 0.4289 r:0.6503
si_en Dev loss: 0.7455 r:0.4950
ne_en Dev loss: 0.5020 r:0.6381
ru_en Dev loss: 0.5257 r:0.6964
Current avg r:0.5273 Best avg r: 0.5273
15:27:54,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:28:07,475 root INFO 
id:en_de cur r: 0.0888 best r: 0.0888
15:29:25,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:56,57 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6287
en_de Dev loss: 0.9859 r:0.1624
en_zh Dev loss: 0.8431 r:0.3304
ro_en Dev loss: 0.5025 r:0.7228
et_en Dev loss: 0.4404 r:0.6286
si_en Dev loss: 0.8731 r:0.4775
ne_en Dev loss: 0.5913 r:0.5884
ru_en Dev loss: 0.6273 r:0.6445
Current avg r:0.5078 Best avg r: 0.5273
15:35:28,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:35:41,908 root INFO 
id:en_de cur r: 0.1521 best r: 0.1521
15:35:54,861 root INFO 
id:en_zh cur r: 0.3551 best r: 0.3551
15:36:07,852 root INFO 
id:ro_en cur r: 0.7349 best r: 0.7349
15:36:33,843 root INFO 
id:et_en cur r: 0.6620 best r: 0.6620
15:36:46,846 root INFO 
id:si_en cur r: 0.4994 best r: 0.4994
15:36:59,854 root INFO 
id:ne_en cur r: 0.6629 best r: 0.6629
15:37:12,773 root INFO 
id:ru_en cur r: 0.6668 best r: 0.6668
15:37:12,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:43,543 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
15:38:43,549 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:38:43,553 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:38:43,558 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
15:38:43,563 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
15:38:43,568 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:38:43,573 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:38:56,572 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6275
en_de Dev loss: 0.9468 r:0.1836
en_zh Dev loss: 0.7762 r:0.3828
ro_en Dev loss: 0.4365 r:0.7560
et_en Dev loss: 0.3885 r:0.6721
si_en Dev loss: 0.7233 r:0.5198
ne_en Dev loss: 0.4485 r:0.6638
ru_en Dev loss: 0.4900 r:0.7049
Current avg r:0.5547 Best avg r: 0.5547
15:43:30,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:43,485 root INFO 
id:en_de cur r: 0.1789 best r: 0.1789
15:43:56,443 root INFO 
id:en_zh cur r: 0.3942 best r: 0.3942
15:44:09,420 root INFO 
id:ro_en cur r: 0.7555 best r: 0.7555
15:44:35,423 root INFO 
id:et_en cur r: 0.6663 best r: 0.6663
15:44:48,423 root INFO 
id:si_en cur r: 0.5408 best r: 0.5408
15:45:01,418 root INFO 
id:ne_en cur r: 0.6926 best r: 0.6926
15:45:14,340 root INFO 
id:ru_en cur r: 0.7169 best r: 0.7169
15:45:14,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:45,102 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
15:46:45,107 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:46:45,112 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:46:45,117 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
15:46:45,123 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
15:46:45,127 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:46:45,132 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:46:58,136 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6042
en_de Dev loss: 0.8739 r:0.1975
en_zh Dev loss: 0.6873 r:0.4096
ro_en Dev loss: 0.3552 r:0.7705
et_en Dev loss: 0.3899 r:0.6836
si_en Dev loss: 0.5662 r:0.5650
ne_en Dev loss: 0.4182 r:0.7019
ru_en Dev loss: 0.3863 r:0.7411
Current avg r:0.5813 Best avg r: 0.5813
15:51:31,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:44,146 root INFO 
id:en_de cur r: 0.1791 best r: 0.1791
15:51:57,116 root INFO 
id:en_zh cur r: 0.3949 best r: 0.3949
15:52:10,105 root INFO 
id:ro_en cur r: 0.7633 best r: 0.7633
15:53:02,31 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:34,223 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5941
en_de Dev loss: 0.9727 r:0.2044
en_zh Dev loss: 0.8242 r:0.4161
ro_en Dev loss: 0.4772 r:0.7794
et_en Dev loss: 0.4237 r:0.6751
si_en Dev loss: 0.8037 r:0.5533
ne_en Dev loss: 0.5433 r:0.6781
ru_en Dev loss: 0.6849 r:0.6941
Current avg r:0.5715 Best avg r: 0.5813
15:59:07,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:20,288 root INFO 
id:en_de cur r: 0.1915 best r: 0.1915
15:59:46,229 root INFO 
id:ro_en cur r: 0.7717 best r: 0.7717
16:00:38,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:08,902 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5803
en_de Dev loss: 0.9141 r:0.2140
en_zh Dev loss: 0.7570 r:0.4102
ro_en Dev loss: 0.4188 r:0.7883
et_en Dev loss: 0.4194 r:0.6734
si_en Dev loss: 0.8131 r:0.5489
ne_en Dev loss: 0.4900 r:0.6972
ru_en Dev loss: 0.5686 r:0.7148
Current avg r:0.5781 Best avg r: 0.5813
16:06:42,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:08,138 root INFO 
id:en_zh cur r: 0.4268 best r: 0.4268
16:07:21,131 root INFO 
id:ro_en cur r: 0.7954 best r: 0.7954
16:07:47,154 root INFO 
id:et_en cur r: 0.6797 best r: 0.6797
16:08:00,171 root INFO 
id:si_en cur r: 0.5700 best r: 0.5700
16:08:13,174 root INFO 
id:ne_en cur r: 0.7204 best r: 0.7204
16:08:26,107 root INFO 
id:ru_en cur r: 0.7198 best r: 0.7198
16:08:26,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:09:56,921 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
16:09:56,926 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:09:56,931 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:09:56,936 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
16:09:56,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
16:09:56,945 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:09:56,950 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:10:09,958 root INFO Epoch 0 Global steps: 7000 Train loss: 0.6150
en_de Dev loss: 0.9333 r:0.2021
en_zh Dev loss: 0.7079 r:0.4310
ro_en Dev loss: 0.3979 r:0.8027
et_en Dev loss: 0.4052 r:0.6871
si_en Dev loss: 0.7697 r:0.5779
ne_en Dev loss: 0.4538 r:0.7205
ru_en Dev loss: 0.5207 r:0.7294
Current avg r:0.5930 Best avg r: 0.5930
16:14:42,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:47,869 root INFO 
id:et_en cur r: 0.6813 best r: 0.6813
16:16:00,872 root INFO 
id:si_en cur r: 0.5732 best r: 0.5732
16:16:13,871 root INFO 
id:ne_en cur r: 0.7293 best r: 0.7293
16:16:26,790 root INFO 
id:ru_en cur r: 0.7270 best r: 0.7270
16:16:26,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:17:58,949 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
16:17:58,955 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:17:58,960 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:17:58,965 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
16:17:58,969 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
16:17:58,974 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:17:58,979 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:18:11,973 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5592
en_de Dev loss: 0.8674 r:0.2027
en_zh Dev loss: 0.6952 r:0.4226
ro_en Dev loss: 0.3388 r:0.7985
et_en Dev loss: 0.3758 r:0.6889
si_en Dev loss: 0.5807 r:0.5891
ne_en Dev loss: 0.3899 r:0.7295
ru_en Dev loss: 0.4095 r:0.7340
Current avg r:0.5950 Best avg r: 0.5950
16:22:46,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:17,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:48,250 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5757
en_de Dev loss: 0.8722 r:0.2108
en_zh Dev loss: 0.7367 r:0.4297
ro_en Dev loss: 0.3540 r:0.7985
et_en Dev loss: 0.3896 r:0.6783
si_en Dev loss: 0.7175 r:0.5754
ne_en Dev loss: 0.4151 r:0.7180
ru_en Dev loss: 0.5173 r:0.7065
Current avg r:0.5882 Best avg r: 0.5950
16:30:22,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:00,911 root INFO 
id:ro_en cur r: 0.7975 best r: 0.7975
16:31:52,812 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:23,568 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5372
en_de Dev loss: 0.9566 r:0.2136
en_zh Dev loss: 0.8188 r:0.4162
ro_en Dev loss: 0.3883 r:0.8031
et_en Dev loss: 0.3927 r:0.6831
si_en Dev loss: 0.6906 r:0.5823
ne_en Dev loss: 0.4452 r:0.7237
ru_en Dev loss: 0.5876 r:0.7063
Current avg r:0.5898 Best avg r: 0.5950
16:37:56,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:35,498 root INFO 
id:ro_en cur r: 0.8041 best r: 0.8041
16:39:01,504 root INFO 
id:et_en cur r: 0.6904 best r: 0.6904
16:39:14,510 root INFO 
id:si_en cur r: 0.5756 best r: 0.5756
16:39:27,511 root INFO 
id:ne_en cur r: 0.7405 best r: 0.7405
16:39:40,430 root INFO 
id:ru_en cur r: 0.7296 best r: 0.7296
16:39:40,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:11,172 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
16:41:11,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:41:11,183 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:41:11,189 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
16:41:11,194 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
16:41:11,207 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:41:11,211 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:41:24,209 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5410
en_de Dev loss: 0.8691 r:0.2125
en_zh Dev loss: 0.6832 r:0.4376
ro_en Dev loss: 0.3150 r:0.8067
et_en Dev loss: 0.3697 r:0.6983
si_en Dev loss: 0.6704 r:0.5861
ne_en Dev loss: 0.3612 r:0.7403
ru_en Dev loss: 0.4339 r:0.7366
Current avg r:0.6026 Best avg r: 0.6026
16:45:57,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:23,126 root INFO 
id:en_zh cur r: 0.4326 best r: 0.4326
16:46:36,118 root INFO 
id:ro_en cur r: 0.8099 best r: 0.8099
16:47:02,112 root INFO 
id:et_en cur r: 0.6934 best r: 0.6934
16:47:15,116 root INFO 
id:si_en cur r: 0.5948 best r: 0.5948
16:47:41,45 root INFO 
id:ru_en cur r: 0.7378 best r: 0.7378
16:47:41,45 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:11,848 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
16:49:11,855 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:49:11,860 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:49:11,866 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
16:49:11,871 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
16:49:11,875 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:49:11,880 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:49:24,879 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5449
en_de Dev loss: 0.8863 r:0.2114
en_zh Dev loss: 0.6995 r:0.4387
ro_en Dev loss: 0.3170 r:0.8133
et_en Dev loss: 0.3661 r:0.6975
si_en Dev loss: 0.6771 r:0.5940
ne_en Dev loss: 0.3942 r:0.7365
ru_en Dev loss: 0.4606 r:0.7357
Current avg r:0.6039 Best avg r: 0.6039
16:53:57,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:10,962 root INFO 
id:en_de cur r: 0.1997 best r: 0.1997
16:54:23,915 root INFO 
id:en_zh cur r: 0.4339 best r: 0.4339
16:54:36,903 root INFO 
id:ro_en cur r: 0.8103 best r: 0.8103
16:55:02,902 root INFO 
id:et_en cur r: 0.6967 best r: 0.6967
16:55:15,903 root INFO 
id:si_en cur r: 0.6002 best r: 0.6002
16:55:41,822 root INFO 
id:ru_en cur r: 0.7399 best r: 0.7399
16:55:41,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:12,570 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
16:57:12,577 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:57:12,581 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:57:12,586 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
16:57:12,591 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
16:57:12,596 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:57:12,600 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:57:25,605 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5438
en_de Dev loss: 0.9073 r:0.2218
en_zh Dev loss: 0.7512 r:0.4347
ro_en Dev loss: 0.3751 r:0.8100
et_en Dev loss: 0.3835 r:0.6959
si_en Dev loss: 0.6810 r:0.6025
ne_en Dev loss: 0.4171 r:0.7374
ru_en Dev loss: 0.4990 r:0.7372
Current avg r:0.6056 Best avg r: 0.6056
17:01:58,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:11,657 root INFO 
id:en_de cur r: 0.2405 best r: 0.2405
17:03:29,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:00,260 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5466
en_de Dev loss: 0.8538 r:0.2453
en_zh Dev loss: 0.7572 r:0.4287
ro_en Dev loss: 0.3542 r:0.8066
et_en Dev loss: 0.3885 r:0.6894
si_en Dev loss: 0.6087 r:0.5975
ne_en Dev loss: 0.4066 r:0.7327
ru_en Dev loss: 0.5018 r:0.7265
Current avg r:0.6038 Best avg r: 0.6056
17:09:33,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:51,20 root INFO 
id:ne_en cur r: 0.7414 best r: 0.7414
17:11:03,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:34,703 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
17:12:34,709 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:12:34,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:12:34,719 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
17:12:34,724 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
17:12:34,729 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:12:34,734 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:12:47,733 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5447
en_de Dev loss: 0.8393 r:0.2591
en_zh Dev loss: 0.7226 r:0.4297
ro_en Dev loss: 0.3408 r:0.8076
et_en Dev loss: 0.3737 r:0.6966
si_en Dev loss: 0.6933 r:0.5873
ne_en Dev loss: 0.4172 r:0.7376
ru_en Dev loss: 0.4410 r:0.7350
Current avg r:0.6076 Best avg r: 0.6076
17:17:20,634 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:33,616 root INFO 
id:en_de cur r: 0.2517 best r: 0.2517
17:18:51,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:22,196 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5036
en_de Dev loss: 0.8567 r:0.2678
en_zh Dev loss: 0.7596 r:0.4278
ro_en Dev loss: 0.3679 r:0.8028
et_en Dev loss: 0.3861 r:0.6838
si_en Dev loss: 0.7686 r:0.5910
ne_en Dev loss: 0.5768 r:0.7308
ru_en Dev loss: 0.5277 r:0.7104
Current avg r:0.6021 Best avg r: 0.6076
17:24:55,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:33,921 root INFO 
id:ro_en cur r: 0.8154 best r: 0.8154
17:25:59,912 root INFO 
id:et_en cur r: 0.6985 best r: 0.6985
17:26:12,931 root INFO 
id:si_en cur r: 0.6067 best r: 0.6067
17:26:25,937 root INFO 
id:ne_en cur r: 0.7425 best r: 0.7425
17:26:38,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:09,620 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
17:28:09,625 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:28:09,630 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:28:09,636 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
17:28:09,640 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
17:28:09,645 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:28:09,649 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:28:22,645 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5263
en_de Dev loss: 0.8536 r:0.2541
en_zh Dev loss: 0.7176 r:0.4359
ro_en Dev loss: 0.3170 r:0.8137
et_en Dev loss: 0.3696 r:0.6977
si_en Dev loss: 0.6492 r:0.6096
ne_en Dev loss: 0.3710 r:0.7453
ru_en Dev loss: 0.4529 r:0.7445
Current avg r:0.6144 Best avg r: 0.6144
17:32:55,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:33:21,446 root INFO 
id:en_zh cur r: 0.4494 best r: 0.4494
17:33:34,435 root INFO 
id:ro_en cur r: 0.8173 best r: 0.8173
17:34:13,417 root INFO 
id:ne_en cur r: 0.7499 best r: 0.7499
17:34:26,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:57,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
17:35:57,110 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:35:57,115 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:35:57,120 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
17:35:57,161 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
17:35:57,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:35:57,170 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:36:10,168 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4829
en_de Dev loss: 0.8303 r:0.2582
en_zh Dev loss: 0.6883 r:0.4567
ro_en Dev loss: 0.3030 r:0.8172
et_en Dev loss: 0.3736 r:0.6933
si_en Dev loss: 0.7026 r:0.6042
ne_en Dev loss: 0.4836 r:0.7457
ru_en Dev loss: 0.4161 r:0.7386
Current avg r:0.6163 Best avg r: 0.6163
17:40:43,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:13,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:44,624 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5033
en_de Dev loss: 0.8479 r:0.2360
en_zh Dev loss: 0.7169 r:0.4419
ro_en Dev loss: 0.3193 r:0.8113
et_en Dev loss: 0.3774 r:0.6902
si_en Dev loss: 0.7135 r:0.6038
ne_en Dev loss: 0.4530 r:0.7459
ru_en Dev loss: 0.4673 r:0.7209
Current avg r:0.6071 Best avg r: 0.6163
17:48:18,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:49,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:20,192 root INFO Epoch 2 Global steps: 16100 Train loss: 0.5083
en_de Dev loss: 0.8488 r:0.2271
en_zh Dev loss: 0.7933 r:0.4335
ro_en Dev loss: 0.3572 r:0.8082
et_en Dev loss: 0.3858 r:0.6890
si_en Dev loss: 0.7616 r:0.6018
ne_en Dev loss: 0.5069 r:0.7390
ru_en Dev loss: 0.5161 r:0.7146
Current avg r:0.6019 Best avg r: 0.6163
17:55:52,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:18,717 root INFO 
id:en_zh cur r: 0.4516 best r: 0.4516
17:56:31,691 root INFO 
id:ro_en cur r: 0.8177 best r: 0.8177
17:56:57,683 root INFO 
id:et_en cur r: 0.7002 best r: 0.7002
17:57:23,663 root INFO 
id:ne_en cur r: 0.7588 best r: 0.7588
17:57:36,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:07,301 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
17:59:07,308 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:59:07,312 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:59:07,317 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
17:59:07,322 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
17:59:07,327 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:59:07,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:59:20,323 root INFO Epoch 2 Global steps: 16800 Train loss: 0.5039
en_de Dev loss: 0.8668 r:0.2444
en_zh Dev loss: 0.7781 r:0.4483
ro_en Dev loss: 0.3867 r:0.8134
et_en Dev loss: 0.3970 r:0.7008
si_en Dev loss: 0.7042 r:0.6181
ne_en Dev loss: 0.3978 r:0.7601
ru_en Dev loss: 0.4797 r:0.7363
Current avg r:0.6173 Best avg r: 0.6173
18:03:53,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:18,947 root INFO 
id:en_zh cur r: 0.4778 best r: 0.4778
18:04:31,928 root INFO 
id:ro_en cur r: 0.8226 best r: 0.8226
18:04:57,914 root INFO 
id:si_en cur r: 0.6183 best r: 0.6183
18:05:10,921 root INFO 
id:ne_en cur r: 0.7676 best r: 0.7676
18:05:23,836 root INFO 
id:ru_en cur r: 0.7455 best r: 0.7455
18:05:23,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:54,578 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
18:06:54,584 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:06:54,589 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:06:54,593 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
18:06:54,598 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
18:06:54,602 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:06:54,606 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:07:07,596 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4896
en_de Dev loss: 0.8635 r:0.2336
en_zh Dev loss: 0.7043 r:0.4727
ro_en Dev loss: 0.3401 r:0.8168
et_en Dev loss: 0.3741 r:0.7020
si_en Dev loss: 0.6770 r:0.6171
ne_en Dev loss: 0.3608 r:0.7675
ru_en Dev loss: 0.4163 r:0.7450
Current avg r:0.6221 Best avg r: 0.6221
18:11:40,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:45,109 root INFO 
id:et_en cur r: 0.7010 best r: 0.7010
18:13:24,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:14:54,740 root INFO Epoch 2 Global steps: 18200 Train loss: 0.4828
en_de Dev loss: 0.8600 r:0.2264
en_zh Dev loss: 0.7004 r:0.4630
ro_en Dev loss: 0.3556 r:0.8221
et_en Dev loss: 0.3861 r:0.7057
si_en Dev loss: 0.7410 r:0.6214
ne_en Dev loss: 0.4307 r:0.7559
ru_en Dev loss: 0.5144 r:0.7246
Current avg r:0.6170 Best avg r: 0.6221
18:19:27,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:32,398 root INFO 
id:et_en cur r: 0.7016 best r: 0.7016
18:21:11,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:42,89 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4678
en_de Dev loss: 0.8432 r:0.2263
en_zh Dev loss: 0.6928 r:0.4551
ro_en Dev loss: 0.3283 r:0.8191
et_en Dev loss: 0.3615 r:0.7046
si_en Dev loss: 0.7125 r:0.6114
ne_en Dev loss: 0.4703 r:0.7560
ru_en Dev loss: 0.4516 r:0.7241
Current avg r:0.6138 Best avg r: 0.6221
18:27:15,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:46,433 root INFO 
id:ru_en cur r: 0.7462 best r: 0.7462
18:28:46,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:17,180 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4780
en_de Dev loss: 0.8332 r:0.2495
en_zh Dev loss: 0.6733 r:0.4591
ro_en Dev loss: 0.3195 r:0.8178
et_en Dev loss: 0.3850 r:0.6874
si_en Dev loss: 0.6427 r:0.6097
ne_en Dev loss: 0.3803 r:0.7554
ru_en Dev loss: 0.4048 r:0.7440
Current avg r:0.6175 Best avg r: 0.6221
18:34:49,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:20,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:51,514 root INFO Epoch 2 Global steps: 20300 Train loss: 0.5062
en_de Dev loss: 0.8361 r:0.2497
en_zh Dev loss: 0.7135 r:0.4666
ro_en Dev loss: 0.3420 r:0.8171
et_en Dev loss: 0.3953 r:0.6924
si_en Dev loss: 0.6215 r:0.6161
ne_en Dev loss: 0.3987 r:0.7608
ru_en Dev loss: 0.4396 r:0.7360
Current avg r:0.6198 Best avg r: 0.6221
18:42:24,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:03,168 root INFO 
id:ro_en cur r: 0.8239 best r: 0.8239
18:43:29,161 root INFO 
id:et_en cur r: 0.7035 best r: 0.7035
18:44:08,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:38,866 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4606
en_de Dev loss: 0.8598 r:0.2452
en_zh Dev loss: 0.7524 r:0.4660
ro_en Dev loss: 0.3404 r:0.8214
et_en Dev loss: 0.3704 r:0.7080
si_en Dev loss: 0.6450 r:0.6252
ne_en Dev loss: 0.4856 r:0.7579
ru_en Dev loss: 0.5371 r:0.7245
Current avg r:0.6211 Best avg r: 0.6221
18:50:11,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:24,980 root INFO 
id:en_de cur r: 0.2562 best r: 0.2562
18:50:37,933 root INFO 
id:en_zh cur r: 0.4802 best r: 0.4802
18:50:50,918 root INFO 
id:ro_en cur r: 0.8266 best r: 0.8266
18:51:16,919 root INFO 
id:et_en cur r: 0.7086 best r: 0.7086
18:51:29,925 root INFO 
id:si_en cur r: 0.6222 best r: 0.6222
18:51:55,880 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:26,653 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
18:53:26,660 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:53:26,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:53:26,669 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
18:53:26,673 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
18:53:26,678 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:53:26,682 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:53:39,678 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4600
en_de Dev loss: 0.8274 r:0.2614
en_zh Dev loss: 0.6701 r:0.4760
ro_en Dev loss: 0.3108 r:0.8230
et_en Dev loss: 0.3759 r:0.7070
si_en Dev loss: 0.5861 r:0.6244
ne_en Dev loss: 0.3712 r:0.7571
ru_en Dev loss: 0.4083 r:0.7417
Current avg r:0.6272 Best avg r: 0.6272
18:58:12,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:25,331 root INFO 
id:en_de cur r: 0.2585 best r: 0.2585
18:59:43,159 root INFO 
id:ru_en cur r: 0.7465 best r: 0.7465
18:59:43,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:13,880 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4488
en_de Dev loss: 0.8441 r:0.2546
en_zh Dev loss: 0.7098 r:0.4628
ro_en Dev loss: 0.3119 r:0.8232
et_en Dev loss: 0.3621 r:0.7087
si_en Dev loss: 0.6361 r:0.6255
ne_en Dev loss: 0.4160 r:0.7617
ru_en Dev loss: 0.4207 r:0.7482
Current avg r:0.6264 Best avg r: 0.6272
19:05:49,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:20,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:51,392 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4799
en_de Dev loss: 0.9202 r:0.2555
en_zh Dev loss: 0.8258 r:0.4673
ro_en Dev loss: 0.3798 r:0.8157
et_en Dev loss: 0.4018 r:0.7035
si_en Dev loss: 0.7901 r:0.6072
ne_en Dev loss: 0.4898 r:0.7622
ru_en Dev loss: 0.5502 r:0.7253
Current avg r:0.6195 Best avg r: 0.6272
19:13:25,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:51,549 root INFO 
id:en_zh cur r: 0.4806 best r: 0.4806
19:14:30,568 root INFO 
id:et_en cur r: 0.7139 best r: 0.7139
19:15:09,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:40,262 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
19:16:40,268 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
19:16:40,273 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
19:16:40,279 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
19:16:40,284 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
19:16:40,288 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
19:16:40,293 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
19:16:53,290 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4459
en_de Dev loss: 0.8454 r:0.2628
en_zh Dev loss: 0.6893 r:0.4752
ro_en Dev loss: 0.3046 r:0.8237
et_en Dev loss: 0.3651 r:0.7110
si_en Dev loss: 0.6529 r:0.6240
ne_en Dev loss: 0.3848 r:0.7619
ru_en Dev loss: 0.4476 r:0.7357
Current avg r:0.6278 Best avg r: 0.6278
19:21:27,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:58,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:28,897 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4496
en_de Dev loss: 0.8526 r:0.2674
en_zh Dev loss: 0.7614 r:0.4596
ro_en Dev loss: 0.3268 r:0.8210
et_en Dev loss: 0.3716 r:0.7048
si_en Dev loss: 0.7170 r:0.6182
ne_en Dev loss: 0.4919 r:0.7587
ru_en Dev loss: 0.4936 r:0.7251
Current avg r:0.6221 Best avg r: 0.6278
19:29:01,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:32,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:03,230 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4483
en_de Dev loss: 0.8384 r:0.2725
en_zh Dev loss: 0.7094 r:0.4737
ro_en Dev loss: 0.3346 r:0.8205
et_en Dev loss: 0.3837 r:0.7048
si_en Dev loss: 0.7384 r:0.6200
ne_en Dev loss: 0.4025 r:0.7584
ru_en Dev loss: 0.4949 r:0.7208
Current avg r:0.6244 Best avg r: 0.6278
19:36:36,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:49,7 root INFO 
id:en_de cur r: 0.2741 best r: 0.2741
19:38:06,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:39:37,627 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4548
en_de Dev loss: 0.8315 r:0.2712
en_zh Dev loss: 0.6945 r:0.4628
ro_en Dev loss: 0.3199 r:0.8171
et_en Dev loss: 0.4065 r:0.6988
si_en Dev loss: 0.6398 r:0.6151
ne_en Dev loss: 0.3756 r:0.7635
ru_en Dev loss: 0.4057 r:0.7452
Current avg r:0.6248 Best avg r: 0.6278
19:44:11,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:42,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:13,247 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4297
en_de Dev loss: 0.8434 r:0.2509
en_zh Dev loss: 0.7513 r:0.4758
ro_en Dev loss: 0.3667 r:0.8205
et_en Dev loss: 0.4197 r:0.6976
si_en Dev loss: 0.7810 r:0.6168
ne_en Dev loss: 0.4753 r:0.7544
ru_en Dev loss: 0.4812 r:0.7337
Current avg r:0.6214 Best avg r: 0.6278
19:51:46,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:59,528 root INFO 
id:en_de cur r: 0.2764 best r: 0.2764
19:53:17,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:48,258 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_de.lang_agnost_mlp.dev.best.scores
19:54:48,265 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/en_zh.lang_agnost_mlp.dev.best.scores
19:54:48,270 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ro_en.lang_agnost_mlp.dev.best.scores
19:54:48,276 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/et_en.lang_agnost_mlp.dev.best.scores
19:54:48,283 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/si_en.lang_agnost_mlp.dev.best.scores
19:54:48,287 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ne_en.lang_agnost_mlp.dev.best.scores
19:54:48,292 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run0/ru_en.lang_agnost_mlp.dev.best.scores
19:55:01,292 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4215
en_de Dev loss: 0.8388 r:0.2813
en_zh Dev loss: 0.7413 r:0.4769
ro_en Dev loss: 0.3361 r:0.8254
et_en Dev loss: 0.3754 r:0.7022
si_en Dev loss: 0.7649 r:0.6277
ne_en Dev loss: 0.4583 r:0.7631
ru_en Dev loss: 0.4592 r:0.7343
Current avg r:0.6301 Best avg r: 0.6301
19:59:34,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:01:05,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:36,90 root INFO Epoch 3 Global steps: 28000 Train loss: 0.4384
en_de Dev loss: 0.8707 r:0.2524
en_zh Dev loss: 0.7890 r:0.4509
ro_en Dev loss: 0.3632 r:0.8157
et_en Dev loss: 0.4006 r:0.6881
si_en Dev loss: 0.8340 r:0.6024
ne_en Dev loss: 0.4899 r:0.7572
ru_en Dev loss: 0.5440 r:0.7005
Current avg r:0.6096 Best avg r: 0.6301
20:07:08,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:39,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:10:10,503 root INFO Epoch 3 Global steps: 28700 Train loss: 0.4376
en_de Dev loss: 0.8342 r:0.2712
en_zh Dev loss: 0.7123 r:0.4575
ro_en Dev loss: 0.3014 r:0.8219
et_en Dev loss: 0.3833 r:0.6944
si_en Dev loss: 0.6737 r:0.6162
ne_en Dev loss: 0.3951 r:0.7649
ru_en Dev loss: 0.4311 r:0.7313
Current avg r:0.6225 Best avg r: 0.6301
20:14:44,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:10,242 root INFO 
id:en_zh cur r: 0.4826 best r: 0.4826
20:15:23,223 root INFO 
id:ro_en cur r: 0.8296 best r: 0.8296
20:15:49,287 root INFO 
id:si_en cur r: 0.6262 best r: 0.6262
20:16:15,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:46,2 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4084
en_de Dev loss: 0.8432 r:0.2768
en_zh Dev loss: 0.6927 r:0.4779
ro_en Dev loss: 0.3145 r:0.8279
et_en Dev loss: 0.4290 r:0.6948
si_en Dev loss: 0.6053 r:0.6336
ne_en Dev loss: 0.3818 r:0.7607
ru_en Dev loss: 0.4606 r:0.7359
Current avg r:0.6297 Best avg r: 0.6301
20:22:18,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:49,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:25:20,562 root INFO Epoch 3 Global steps: 30100 Train loss: 0.4207
en_de Dev loss: 0.8235 r:0.2730
en_zh Dev loss: 0.7118 r:0.4678
ro_en Dev loss: 0.3245 r:0.8256
et_en Dev loss: 0.4293 r:0.6939
si_en Dev loss: 0.6675 r:0.6258
ne_en Dev loss: 0.4223 r:0.7635
ru_en Dev loss: 0.4300 r:0.7384
Current avg r:0.6269 Best avg r: 0.6301
20:29:53,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:06,602 root INFO 
id:en_de cur r: 0.2816 best r: 0.2816
20:31:24,454 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:55,239 root INFO Epoch 3 Global steps: 30800 Train loss: 0.4339
en_de Dev loss: 0.8230 r:0.2846
en_zh Dev loss: 0.7149 r:0.4597
ro_en Dev loss: 0.3068 r:0.8200
et_en Dev loss: 0.3913 r:0.6958
si_en Dev loss: 0.7051 r:0.6076
ne_en Dev loss: 0.4164 r:0.7615
ru_en Dev loss: 0.4484 r:0.7241
Current avg r:0.6219 Best avg r: 0.6301
20:37:28,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:59,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:40:29,870 root INFO Epoch 3 Global steps: 31500 Train loss: 0.4003
en_de Dev loss: 0.8387 r:0.2778
en_zh Dev loss: 0.7637 r:0.4602
ro_en Dev loss: 0.3241 r:0.8229
et_en Dev loss: 0.3996 r:0.6919
si_en Dev loss: 0.6709 r:0.6186
ne_en Dev loss: 0.4243 r:0.7584
ru_en Dev loss: 0.4864 r:0.7183
Current avg r:0.6212 Best avg r: 0.6301
20:45:04,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:46:35,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:06,63 root INFO Epoch 4 Global steps: 32200 Train loss: 0.3859
en_de Dev loss: 0.8549 r:0.2578
en_zh Dev loss: 0.7646 r:0.4566
ro_en Dev loss: 0.3308 r:0.8215
et_en Dev loss: 0.4060 r:0.6887
si_en Dev loss: 0.6992 r:0.6105
ne_en Dev loss: 0.4413 r:0.7506
ru_en Dev loss: 0.5198 r:0.6986
Current avg r:0.6121 Best avg r: 0.6301
20:52:39,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:05,107 root INFO 
id:en_zh cur r: 0.4833 best r: 0.4833
20:54:10,46 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:55:40,888 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3977
en_de Dev loss: 0.8265 r:0.2746
en_zh Dev loss: 0.6977 r:0.4736
ro_en Dev loss: 0.3156 r:0.8236
et_en Dev loss: 0.3849 r:0.6971
si_en Dev loss: 0.6212 r:0.6283
ne_en Dev loss: 0.3495 r:0.7662
ru_en Dev loss: 0.4254 r:0.7363
Current avg r:0.6285 Best avg r: 0.6301
21:00:14,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:01:45,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:15,885 root INFO Epoch 4 Global steps: 33600 Train loss: 0.4005
en_de Dev loss: 0.8544 r:0.2680
en_zh Dev loss: 0.7997 r:0.4522
ro_en Dev loss: 0.3825 r:0.8137
et_en Dev loss: 0.4297 r:0.6792
si_en Dev loss: 0.9035 r:0.5834
ne_en Dev loss: 0.5917 r:0.7465
ru_en Dev loss: 0.5954 r:0.6846
Current avg r:0.6039 Best avg r: 0.6301
21:07:48,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:19,680 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:10:50,481 root INFO Epoch 4 Global steps: 34300 Train loss: 0.4155
en_de Dev loss: 0.8289 r:0.2785
en_zh Dev loss: 0.7496 r:0.4605
ro_en Dev loss: 0.3485 r:0.8235
et_en Dev loss: 0.4024 r:0.6951
si_en Dev loss: 0.7011 r:0.6157
ne_en Dev loss: 0.4279 r:0.7614
ru_en Dev loss: 0.4373 r:0.7413
Current avg r:0.6251 Best avg r: 0.6301
21:15:23,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:54,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:25,138 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3835
en_de Dev loss: 0.8698 r:0.2753
en_zh Dev loss: 0.7831 r:0.4571
ro_en Dev loss: 0.3720 r:0.8190
et_en Dev loss: 0.4304 r:0.6844
si_en Dev loss: 0.8257 r:0.6007
ne_en Dev loss: 0.6502 r:0.7594
ru_en Dev loss: 0.5190 r:0.7162
Current avg r:0.6160 Best avg r: 0.6301
21:22:58,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:28,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:59,760 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3860
en_de Dev loss: 0.8600 r:0.2761
en_zh Dev loss: 0.8268 r:0.4504
ro_en Dev loss: 0.3947 r:0.8229
et_en Dev loss: 0.4442 r:0.6881
si_en Dev loss: 0.9396 r:0.6006
ne_en Dev loss: 0.5423 r:0.7458
ru_en Dev loss: 0.5804 r:0.7180
Current avg r:0.6146 Best avg r: 0.6301
21:30:38,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:08,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:39,830 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3805
en_de Dev loss: 0.8272 r:0.2641
en_zh Dev loss: 0.7501 r:0.4480
ro_en Dev loss: 0.3374 r:0.8224
et_en Dev loss: 0.4287 r:0.6859
si_en Dev loss: 0.6745 r:0.6059
ne_en Dev loss: 0.4260 r:0.7439
ru_en Dev loss: 0.4453 r:0.7342
Current avg r:0.6149 Best avg r: 0.6301
21:38:13,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:43,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:14,806 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3818
en_de Dev loss: 0.8490 r:0.2610
en_zh Dev loss: 0.8242 r:0.4349
ro_en Dev loss: 0.3834 r:0.8087
et_en Dev loss: 0.4308 r:0.6719
si_en Dev loss: 0.8649 r:0.5822
ne_en Dev loss: 0.5439 r:0.7444
ru_en Dev loss: 0.5488 r:0.6961
Current avg r:0.5999 Best avg r: 0.6301
21:45:48,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:18,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:49,802 root INFO Epoch 4 Global steps: 37800 Train loss: 0.4011
en_de Dev loss: 0.8490 r:0.2272
en_zh Dev loss: 0.7490 r:0.4505
ro_en Dev loss: 0.3254 r:0.8231
et_en Dev loss: 0.4031 r:0.6836
si_en Dev loss: 0.6879 r:0.6129
ne_en Dev loss: 0.5578 r:0.7447
ru_en Dev loss: 0.4257 r:0.7379
Current avg r:0.6114 Best avg r: 0.6301
21:53:23,67 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:53,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:24,787 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3748
en_de Dev loss: 0.8668 r:0.1965
en_zh Dev loss: 0.7430 r:0.4553
ro_en Dev loss: 0.3424 r:0.8210
et_en Dev loss: 0.4446 r:0.6711
si_en Dev loss: 0.7283 r:0.6093
ne_en Dev loss: 0.4848 r:0.7484
ru_en Dev loss: 0.4762 r:0.7185
Current avg r:0.6029 Best avg r: 0.6301
22:00:58,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:29,84 root INFO 
id:ru_en cur r: 0.7533 best r: 0.7533
22:02:29,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:59,902 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3829
en_de Dev loss: 0.8740 r:0.2137
en_zh Dev loss: 0.7664 r:0.4467
ro_en Dev loss: 0.3382 r:0.8179
et_en Dev loss: 0.4231 r:0.6740
si_en Dev loss: 0.7566 r:0.6057
ne_en Dev loss: 0.4618 r:0.7519
ru_en Dev loss: 0.4245 r:0.7458
Current avg r:0.6079 Best avg r: 0.6301
22:08:34,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:39,331 root INFO 
id:si_en cur r: 0.6275 best r: 0.6275
22:10:05,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:36,84 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3485
en_de Dev loss: 0.8505 r:0.2183
en_zh Dev loss: 0.7453 r:0.4482
ro_en Dev loss: 0.3304 r:0.8252
et_en Dev loss: 0.4327 r:0.6880
si_en Dev loss: 0.6431 r:0.6251
ne_en Dev loss: 0.3900 r:0.7585
ru_en Dev loss: 0.4234 r:0.7425
Current avg r:0.6151 Best avg r: 0.6301
22:16:09,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:39,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:10,784 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3621
en_de Dev loss: 0.8641 r:0.2300
en_zh Dev loss: 0.8409 r:0.4323
ro_en Dev loss: 0.3779 r:0.8181
et_en Dev loss: 0.4409 r:0.6767
si_en Dev loss: 0.8764 r:0.6062
ne_en Dev loss: 0.5518 r:0.7521
ru_en Dev loss: 0.5034 r:0.7244
Current avg r:0.6057 Best avg r: 0.6301
22:23:43,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:14,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:45,403 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3425
en_de Dev loss: 0.8640 r:0.2439
en_zh Dev loss: 0.7696 r:0.4463
ro_en Dev loss: 0.3553 r:0.8203
et_en Dev loss: 0.4106 r:0.6812
si_en Dev loss: 0.7318 r:0.6109
ne_en Dev loss: 0.4798 r:0.7558
ru_en Dev loss: 0.5086 r:0.7150
Current avg r:0.6105 Best avg r: 0.6301
22:31:18,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:49,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:20,163 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3472
en_de Dev loss: 0.8755 r:0.2228
en_zh Dev loss: 0.7662 r:0.4566
ro_en Dev loss: 0.3505 r:0.8190
et_en Dev loss: 0.4661 r:0.6755
si_en Dev loss: 0.7288 r:0.6054
ne_en Dev loss: 0.4051 r:0.7585
ru_en Dev loss: 0.4784 r:0.7176
Current avg r:0.6079 Best avg r: 0.6301
22:38:53,568 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:24,459 root INFO 
id:ru_en cur r: 0.7581 best r: 0.7581
22:40:24,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:55,316 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3493
en_de Dev loss: 0.8486 r:0.2555
en_zh Dev loss: 0.7778 r:0.4639
ro_en Dev loss: 0.3433 r:0.8268
et_en Dev loss: 0.4472 r:0.6855
si_en Dev loss: 0.7096 r:0.6162
ne_en Dev loss: 0.3744 r:0.7624
ru_en Dev loss: 0.4450 r:0.7451
Current avg r:0.6222 Best avg r: 0.6301
22:46:28,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:59,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:30,525 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3497
en_de Dev loss: 0.8379 r:0.2522
en_zh Dev loss: 0.7905 r:0.4510
ro_en Dev loss: 0.3333 r:0.8243
et_en Dev loss: 0.4312 r:0.6789
si_en Dev loss: 0.7468 r:0.6082
ne_en Dev loss: 0.4298 r:0.7530
ru_en Dev loss: 0.5175 r:0.7088
Current avg r:0.6109 Best avg r: 0.6301
22:54:03,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:34,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:05,574 root INFO Epoch 5 Global steps: 44100 Train loss: 0.3338
en_de Dev loss: 0.8694 r:0.2421
en_zh Dev loss: 0.8207 r:0.4299
ro_en Dev loss: 0.3678 r:0.8221
et_en Dev loss: 0.4353 r:0.6842
si_en Dev loss: 0.7462 r:0.6116
ne_en Dev loss: 0.4842 r:0.7431
ru_en Dev loss: 0.5114 r:0.7235
Current avg r:0.6081 Best avg r: 0.6301
23:01:38,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:09,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:40,637 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3468
en_de Dev loss: 0.8890 r:0.2306
en_zh Dev loss: 0.7624 r:0.4399
ro_en Dev loss: 0.3498 r:0.8204
et_en Dev loss: 0.4227 r:0.6857
si_en Dev loss: 0.6914 r:0.6173
ne_en Dev loss: 0.4158 r:0.7381
ru_en Dev loss: 0.5150 r:0.7234
Current avg r:0.6079 Best avg r: 0.6301
23:09:13,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:44,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:15,649 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3453
en_de Dev loss: 0.8467 r:0.2230
en_zh Dev loss: 0.7737 r:0.4423
ro_en Dev loss: 0.3343 r:0.8246
et_en Dev loss: 0.4169 r:0.6836
si_en Dev loss: 0.7363 r:0.6144
ne_en Dev loss: 0.4604 r:0.7501
ru_en Dev loss: 0.4686 r:0.7190
Current avg r:0.6081 Best avg r: 0.6301
23:16:48,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:19,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:50,527 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3527
en_de Dev loss: 0.8516 r:0.2340
en_zh Dev loss: 0.7999 r:0.4557
ro_en Dev loss: 0.3644 r:0.8203
et_en Dev loss: 0.4583 r:0.6734
si_en Dev loss: 0.7925 r:0.5991
ne_en Dev loss: 0.5150 r:0.7422
ru_en Dev loss: 0.5001 r:0.7223
Current avg r:0.6067 Best avg r: 0.6301
23:24:23,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:54,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:25,324 root INFO Epoch 5 Global steps: 46900 Train loss: 0.3514
en_de Dev loss: 0.8553 r:0.2210
en_zh Dev loss: 0.7806 r:0.4420
ro_en Dev loss: 0.3513 r:0.8202
et_en Dev loss: 0.4254 r:0.6837
si_en Dev loss: 0.7392 r:0.6024
ne_en Dev loss: 0.4529 r:0.7468
ru_en Dev loss: 0.4866 r:0.7183
Current avg r:0.6049 Best avg r: 0.6301
23:31:58,191 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:29,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:34:59,825 root INFO Epoch 5 Global steps: 47600 Train loss: 0.3509
en_de Dev loss: 0.8598 r:0.2324
en_zh Dev loss: 0.7537 r:0.4565
ro_en Dev loss: 0.3390 r:0.8194
et_en Dev loss: 0.4278 r:0.6796
si_en Dev loss: 0.6788 r:0.6093
ne_en Dev loss: 0.3972 r:0.7520
ru_en Dev loss: 0.4393 r:0.7344
Current avg r:0.6119 Best avg r: 0.6301
23:39:34,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:05,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:36,19 root INFO Epoch 6 Global steps: 48300 Train loss: 0.3027
en_de Dev loss: 0.8534 r:0.2352
en_zh Dev loss: 0.7940 r:0.4389
ro_en Dev loss: 0.3297 r:0.8246
et_en Dev loss: 0.4460 r:0.6889
si_en Dev loss: 0.6809 r:0.6099
ne_en Dev loss: 0.4091 r:0.7427
ru_en Dev loss: 0.4457 r:0.7335
Current avg r:0.6105 Best avg r: 0.6301
23:47:08,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:39,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:10,507 root INFO Epoch 6 Global steps: 49000 Train loss: 0.3123
en_de Dev loss: 0.8528 r:0.2173
en_zh Dev loss: 0.7523 r:0.4577
ro_en Dev loss: 0.3301 r:0.8253
et_en Dev loss: 0.4442 r:0.6810
si_en Dev loss: 0.7360 r:0.6072
ne_en Dev loss: 0.4443 r:0.7542
ru_en Dev loss: 0.4852 r:0.7239
Current avg r:0.6095 Best avg r: 0.6301
23:54:43,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:14,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:45,77 root INFO Epoch 6 Global steps: 49700 Train loss: 0.3259
en_de Dev loss: 0.8583 r:0.2236
en_zh Dev loss: 0.7890 r:0.4428
ro_en Dev loss: 0.3411 r:0.8243
et_en Dev loss: 0.4365 r:0.6763
si_en Dev loss: 0.7778 r:0.6054
ne_en Dev loss: 0.5352 r:0.7490
ru_en Dev loss: 0.4839 r:0.7265
Current avg r:0.6069 Best avg r: 0.6301
00:02:18,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:48,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:19,600 root INFO Epoch 6 Global steps: 50400 Train loss: 0.3134
en_de Dev loss: 0.8706 r:0.2145
en_zh Dev loss: 0.7751 r:0.4473
ro_en Dev loss: 0.3347 r:0.8196
et_en Dev loss: 0.4529 r:0.6721
si_en Dev loss: 0.6951 r:0.6050
ne_en Dev loss: 0.4356 r:0.7491
ru_en Dev loss: 0.4680 r:0.7271
Current avg r:0.6050 Best avg r: 0.6301
00:09:52,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:23,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:54,141 root INFO Epoch 6 Global steps: 51100 Train loss: 0.3117
en_de Dev loss: 0.8811 r:0.2156
en_zh Dev loss: 0.8311 r:0.4310
ro_en Dev loss: 0.3799 r:0.8105
et_en Dev loss: 0.4754 r:0.6599
si_en Dev loss: 0.8960 r:0.5813
ne_en Dev loss: 0.5603 r:0.7357
ru_en Dev loss: 0.5656 r:0.6834
Current avg r:0.5882 Best avg r: 0.6301
00:17:27,110 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:57,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:28,819 root INFO Epoch 6 Global steps: 51800 Train loss: 0.2888
en_de Dev loss: 0.8478 r:0.2393
en_zh Dev loss: 0.7453 r:0.4568
ro_en Dev loss: 0.3357 r:0.8169
et_en Dev loss: 0.4626 r:0.6713
si_en Dev loss: 0.7388 r:0.5965
ne_en Dev loss: 0.4082 r:0.7448
ru_en Dev loss: 0.4442 r:0.7229
Current avg r:0.6069 Best avg r: 0.6301
00:25:01,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:32,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:28:03,597 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2972
en_de Dev loss: 0.8539 r:0.2352
en_zh Dev loss: 0.7939 r:0.4362
ro_en Dev loss: 0.3509 r:0.8158
et_en Dev loss: 0.4998 r:0.6640
si_en Dev loss: 0.7523 r:0.5878
ne_en Dev loss: 0.4234 r:0.7417
ru_en Dev loss: 0.4453 r:0.7201
Current avg r:0.6001 Best avg r: 0.6301
00:32:37,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:08,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:39,696 root INFO Epoch 6 Global steps: 53200 Train loss: 0.3088
en_de Dev loss: 0.8633 r:0.2362
en_zh Dev loss: 0.7672 r:0.4470
ro_en Dev loss: 0.3410 r:0.8193
et_en Dev loss: 0.4431 r:0.6602
si_en Dev loss: 0.7506 r:0.5873
ne_en Dev loss: 0.4827 r:0.7380
ru_en Dev loss: 0.4986 r:0.6970
Current avg r:0.5979 Best avg r: 0.6301
00:40:12,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:43,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:14,640 root INFO Epoch 6 Global steps: 53900 Train loss: 0.3023
en_de Dev loss: 0.8528 r:0.2266
en_zh Dev loss: 0.8149 r:0.4383
ro_en Dev loss: 0.3662 r:0.8144
et_en Dev loss: 0.4525 r:0.6699
si_en Dev loss: 0.7680 r:0.5985
ne_en Dev loss: 0.4294 r:0.7363
ru_en Dev loss: 0.4862 r:0.7122
Current avg r:0.5995 Best avg r: 0.6301
00:47:47,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:18,414 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:49,200 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2902
en_de Dev loss: 0.8549 r:0.2696
en_zh Dev loss: 0.8273 r:0.4401
ro_en Dev loss: 0.3556 r:0.8161
et_en Dev loss: 0.4585 r:0.6634
si_en Dev loss: 0.8147 r:0.5830
ne_en Dev loss: 0.5195 r:0.7402
ru_en Dev loss: 0.4783 r:0.7223
Current avg r:0.6050 Best avg r: 0.6301
00:55:22,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:52,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:23,731 root INFO Epoch 6 Global steps: 55300 Train loss: 0.3208
en_de Dev loss: 0.8618 r:0.2408
en_zh Dev loss: 0.7979 r:0.4360
ro_en Dev loss: 0.3349 r:0.8205
et_en Dev loss: 0.4532 r:0.6652
si_en Dev loss: 0.7235 r:0.5940
ne_en Dev loss: 0.4560 r:0.7355
ru_en Dev loss: 0.4995 r:0.7034
Current avg r:0.5993 Best avg r: 0.6301
01:02:57,946 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:28,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:59,565 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2631
en_de Dev loss: 0.8704 r:0.2254
en_zh Dev loss: 0.7829 r:0.4371
ro_en Dev loss: 0.3531 r:0.8165
et_en Dev loss: 0.4483 r:0.6607
si_en Dev loss: 0.7666 r:0.5870
ne_en Dev loss: 0.4998 r:0.7424
ru_en Dev loss: 0.4705 r:0.7195
Current avg r:0.5984 Best avg r: 0.6301
01:10:32,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:12:03,239 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:13:34,40 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2743
en_de Dev loss: 0.8612 r:0.2218
en_zh Dev loss: 0.8242 r:0.4227
ro_en Dev loss: 0.3787 r:0.8163
et_en Dev loss: 0.4883 r:0.6642
si_en Dev loss: 0.8109 r:0.5851
ne_en Dev loss: 0.4669 r:0.7395
ru_en Dev loss: 0.4622 r:0.7212
Current avg r:0.5958 Best avg r: 0.6301
01:18:07,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:37,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:21:08,581 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2711
en_de Dev loss: 0.8703 r:0.2369
en_zh Dev loss: 0.8487 r:0.4289
ro_en Dev loss: 0.3860 r:0.8164
et_en Dev loss: 0.4812 r:0.6521
si_en Dev loss: 0.9384 r:0.5695
ne_en Dev loss: 0.5987 r:0.7331
ru_en Dev loss: 0.5573 r:0.6930
Current avg r:0.5900 Best avg r: 0.6301
01:25:41,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:27:12,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:43,7 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2793
en_de Dev loss: 0.8472 r:0.2598
en_zh Dev loss: 0.8499 r:0.4431
ro_en Dev loss: 0.3990 r:0.8178
et_en Dev loss: 0.4906 r:0.6621
si_en Dev loss: 0.9386 r:0.5701
ne_en Dev loss: 0.5689 r:0.7349
ru_en Dev loss: 0.5305 r:0.7046
Current avg r:0.5989 Best avg r: 0.6301
01:33:15,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:34:46,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:17,516 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2754
en_de Dev loss: 0.8795 r:0.2440
en_zh Dev loss: 0.8546 r:0.4248
ro_en Dev loss: 0.3742 r:0.8216
et_en Dev loss: 0.4660 r:0.6626
si_en Dev loss: 0.8486 r:0.5762
ne_en Dev loss: 0.5133 r:0.7403
ru_en Dev loss: 0.5178 r:0.7140
Current avg r:0.5976 Best avg r: 0.6301
01:40:50,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:21,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:51,952 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2689
en_de Dev loss: 0.8881 r:0.2253
en_zh Dev loss: 0.9236 r:0.4145
ro_en Dev loss: 0.3763 r:0.8208
et_en Dev loss: 0.4761 r:0.6530
si_en Dev loss: 0.8501 r:0.5788
ne_en Dev loss: 0.5779 r:0.7335
ru_en Dev loss: 0.5776 r:0.6946
Current avg r:0.5886 Best avg r: 0.6301
01:48:24,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:49:55,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:26,471 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2753
en_de Dev loss: 0.8647 r:0.2669
en_zh Dev loss: 0.8731 r:0.4302
ro_en Dev loss: 0.3928 r:0.8197
et_en Dev loss: 0.4793 r:0.6569
si_en Dev loss: 0.8874 r:0.5772
ne_en Dev loss: 0.5486 r:0.7439
ru_en Dev loss: 0.5715 r:0.6902
Current avg r:0.5979 Best avg r: 0.6301
01:55:59,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:30,171 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:01,51 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2748
en_de Dev loss: 0.8509 r:0.2573
en_zh Dev loss: 0.7772 r:0.4396
ro_en Dev loss: 0.3555 r:0.8238
et_en Dev loss: 0.4325 r:0.6707
si_en Dev loss: 0.8611 r:0.5866
ne_en Dev loss: 0.4966 r:0.7432
ru_en Dev loss: 0.5101 r:0.7100
Current avg r:0.6045 Best avg r: 0.6301
02:03:34,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:05,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:06:36,90 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2772
en_de Dev loss: 0.8447 r:0.2648
en_zh Dev loss: 0.8046 r:0.4341
ro_en Dev loss: 0.3535 r:0.8233
et_en Dev loss: 0.4443 r:0.6680
si_en Dev loss: 0.7329 r:0.6004
ne_en Dev loss: 0.4250 r:0.7414
ru_en Dev loss: 0.4745 r:0.7258
Current avg r:0.6083 Best avg r: 0.6301
02:11:09,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:40,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:10,867 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2653
en_de Dev loss: 0.8648 r:0.2303
en_zh Dev loss: 0.8656 r:0.4235
ro_en Dev loss: 0.3698 r:0.8219
et_en Dev loss: 0.4817 r:0.6566
si_en Dev loss: 0.8641 r:0.5770
ne_en Dev loss: 0.6181 r:0.7327
ru_en Dev loss: 0.5488 r:0.6972
Current avg r:0.5913 Best avg r: 0.6301
02:18:43,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:14,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:21:45,611 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2671
en_de Dev loss: 0.8671 r:0.2335
en_zh Dev loss: 0.8566 r:0.4295
ro_en Dev loss: 0.3753 r:0.8172
et_en Dev loss: 0.4762 r:0.6614
si_en Dev loss: 0.8301 r:0.5841
ne_en Dev loss: 0.5425 r:0.7387
ru_en Dev loss: 0.5281 r:0.7141
Current avg r:0.5969 Best avg r: 0.6301
02:26:20,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:27:50,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:21,819 root INFO Epoch 8 Global steps: 63700 Train loss: 0.2050
en_de Dev loss: 0.8719 r:0.2277
en_zh Dev loss: 0.8570 r:0.4293
ro_en Dev loss: 0.3750 r:0.8171
et_en Dev loss: 0.4874 r:0.6557
si_en Dev loss: 0.9036 r:0.5791
ne_en Dev loss: 0.5407 r:0.7354
ru_en Dev loss: 0.5322 r:0.7104
Current avg r:0.5935 Best avg r: 0.6301
02:33:55,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:25,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:56,869 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2484
en_de Dev loss: 0.8675 r:0.2364
en_zh Dev loss: 0.8646 r:0.4237
ro_en Dev loss: 0.3987 r:0.8137
et_en Dev loss: 0.5370 r:0.6557
si_en Dev loss: 0.8400 r:0.5760
ne_en Dev loss: 0.5137 r:0.7367
ru_en Dev loss: 0.4911 r:0.7196
Current avg r:0.5945 Best avg r: 0.6301
02:41:30,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:01,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:31,980 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2354
en_de Dev loss: 0.8881 r:0.2340
en_zh Dev loss: 0.8399 r:0.4300
ro_en Dev loss: 0.3890 r:0.8130
et_en Dev loss: 0.5185 r:0.6408
si_en Dev loss: 0.8679 r:0.5717
ne_en Dev loss: 0.5496 r:0.7358
ru_en Dev loss: 0.5213 r:0.7109
Current avg r:0.5909 Best avg r: 0.6301
02:49:05,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:36,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:07,248 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2518
en_de Dev loss: 0.8680 r:0.2388
en_zh Dev loss: 0.8288 r:0.4290
ro_en Dev loss: 0.3709 r:0.8200
et_en Dev loss: 0.4807 r:0.6572
si_en Dev loss: 0.9298 r:0.5671
ne_en Dev loss: 0.5178 r:0.7416
ru_en Dev loss: 0.4802 r:0.7279
Current avg r:0.5974 Best avg r: 0.6301
02:56:40,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:58:11,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:59:42,575 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2538
en_de Dev loss: 0.8522 r:0.2505
en_zh Dev loss: 0.8400 r:0.4125
ro_en Dev loss: 0.3485 r:0.8193
et_en Dev loss: 0.4716 r:0.6527
si_en Dev loss: 0.8647 r:0.5575
ne_en Dev loss: 0.5372 r:0.7381
ru_en Dev loss: 0.4358 r:0.7324
Current avg r:0.5947 Best avg r: 0.6301
03:04:15,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:05:46,840 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:07:17,609 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2401
en_de Dev loss: 0.8514 r:0.2446
en_zh Dev loss: 0.8513 r:0.4086
ro_en Dev loss: 0.3735 r:0.8180
et_en Dev loss: 0.4964 r:0.6402
si_en Dev loss: 0.8529 r:0.5627
ne_en Dev loss: 0.5298 r:0.7351
ru_en Dev loss: 0.5199 r:0.6927
Current avg r:0.5860 Best avg r: 0.6301
03:11:50,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:21,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:52,726 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2421
en_de Dev loss: 0.8580 r:0.2482
en_zh Dev loss: 0.8152 r:0.4196
ro_en Dev loss: 0.3388 r:0.8218
et_en Dev loss: 0.4820 r:0.6501
si_en Dev loss: 0.8352 r:0.5650
ne_en Dev loss: 0.4655 r:0.7397
ru_en Dev loss: 0.4758 r:0.7189
Current avg r:0.5947 Best avg r: 0.6301
03:19:26,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:20:57,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:28,180 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2307
en_de Dev loss: 0.8643 r:0.2491
en_zh Dev loss: 0.8181 r:0.4378
ro_en Dev loss: 0.3532 r:0.8211
et_en Dev loss: 0.4870 r:0.6413
si_en Dev loss: 0.8853 r:0.5582
ne_en Dev loss: 0.5150 r:0.7339
ru_en Dev loss: 0.5149 r:0.7041
Current avg r:0.5922 Best avg r: 0.6301
03:27:01,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:32,729 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:03,571 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2398
en_de Dev loss: 0.8495 r:0.2444
en_zh Dev loss: 0.8454 r:0.4316
ro_en Dev loss: 0.3901 r:0.8169
et_en Dev loss: 0.4962 r:0.6440
si_en Dev loss: 0.9725 r:0.5551
ne_en Dev loss: 0.6555 r:0.7381
ru_en Dev loss: 0.5301 r:0.7070
Current avg r:0.5910 Best avg r: 0.6301
03:34:37,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:07,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:37:38,857 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2478
en_de Dev loss: 0.8783 r:0.2293
en_zh Dev loss: 0.8595 r:0.4268
ro_en Dev loss: 0.3928 r:0.8131
et_en Dev loss: 0.4865 r:0.6491
si_en Dev loss: 0.9640 r:0.5595
ne_en Dev loss: 0.7340 r:0.7332
ru_en Dev loss: 0.5286 r:0.7071
Current avg r:0.5883 Best avg r: 0.6301
03:42:12,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:43,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:14,80 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2435
en_de Dev loss: 0.8602 r:0.2371
en_zh Dev loss: 0.8319 r:0.4304
ro_en Dev loss: 0.3553 r:0.8195
et_en Dev loss: 0.4862 r:0.6600
si_en Dev loss: 0.8647 r:0.5721
ne_en Dev loss: 0.5508 r:0.7418
ru_en Dev loss: 0.4970 r:0.7138
Current avg r:0.5964 Best avg r: 0.6301
03:49:47,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:18,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:49,117 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2394
en_de Dev loss: 0.8680 r:0.2466
en_zh Dev loss: 0.8441 r:0.4278
ro_en Dev loss: 0.3474 r:0.8176
et_en Dev loss: 0.5008 r:0.6570
si_en Dev loss: 0.8418 r:0.5650
ne_en Dev loss: 0.5323 r:0.7349
ru_en Dev loss: 0.4813 r:0.7184
Current avg r:0.5953 Best avg r: 0.6301
03:57:23,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:58:54,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:25,484 root INFO Epoch 9 Global steps: 72100 Train loss: 0.2104
en_de Dev loss: 0.8626 r:0.2389
en_zh Dev loss: 0.8175 r:0.4412
ro_en Dev loss: 0.3411 r:0.8186
et_en Dev loss: 0.4989 r:0.6597
si_en Dev loss: 0.7819 r:0.5738
ne_en Dev loss: 0.5089 r:0.7315
ru_en Dev loss: 0.4717 r:0.7218
Current avg r:0.5979 Best avg r: 0.6301
04:04:58,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:06:29,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:00,355 root INFO Epoch 9 Global steps: 72800 Train loss: 0.2286
en_de Dev loss: 0.8579 r:0.2552
en_zh Dev loss: 0.8008 r:0.4504
ro_en Dev loss: 0.3394 r:0.8226
et_en Dev loss: 0.4880 r:0.6669
si_en Dev loss: 0.8134 r:0.5766
ne_en Dev loss: 0.4911 r:0.7351
ru_en Dev loss: 0.4677 r:0.7297
Current avg r:0.6052 Best avg r: 0.6301
04:12:33,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:04,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:35,116 root INFO Epoch 9 Global steps: 73500 Train loss: 0.2271
en_de Dev loss: 0.8724 r:0.2122
en_zh Dev loss: 0.8530 r:0.4307
ro_en Dev loss: 0.3581 r:0.8221
et_en Dev loss: 0.4905 r:0.6504
si_en Dev loss: 0.9461 r:0.5633
ne_en Dev loss: 0.5448 r:0.7300
ru_en Dev loss: 0.5074 r:0.7170
Current avg r:0.5894 Best avg r: 0.6301
04:20:08,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:39,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:09,860 root INFO Epoch 9 Global steps: 74200 Train loss: 0.2261
en_de Dev loss: 0.8913 r:0.2104
en_zh Dev loss: 0.8878 r:0.4325
ro_en Dev loss: 0.3868 r:0.8167
et_en Dev loss: 0.5054 r:0.6551
si_en Dev loss: 0.9037 r:0.5635
ne_en Dev loss: 0.5785 r:0.7304
ru_en Dev loss: 0.5039 r:0.7247
Current avg r:0.5905 Best avg r: 0.6301
04:27:42,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:13,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:44,562 root INFO Epoch 9 Global steps: 74900 Train loss: 0.2324
en_de Dev loss: 0.8811 r:0.2198
en_zh Dev loss: 0.8233 r:0.4310
ro_en Dev loss: 0.3478 r:0.8184
et_en Dev loss: 0.4760 r:0.6542
si_en Dev loss: 0.7935 r:0.5708
ne_en Dev loss: 0.5028 r:0.7340
ru_en Dev loss: 0.4768 r:0.7229
Current avg r:0.5930 Best avg r: 0.6301
04:35:17,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:48,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:19,465 root INFO Epoch 9 Global steps: 75600 Train loss: 0.2180
en_de Dev loss: 0.9033 r:0.2140
en_zh Dev loss: 0.8738 r:0.4455
ro_en Dev loss: 0.3761 r:0.8188
et_en Dev loss: 0.5020 r:0.6622
si_en Dev loss: 0.8458 r:0.5706
ne_en Dev loss: 0.5136 r:0.7315
ru_en Dev loss: 0.4667 r:0.7291
Current avg r:0.5960 Best avg r: 0.6301
04:42:53,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:24,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:55,76 root INFO Epoch 9 Global steps: 76300 Train loss: 0.2209
en_de Dev loss: 0.8924 r:0.2033
en_zh Dev loss: 0.8471 r:0.4325
ro_en Dev loss: 0.3556 r:0.8163
et_en Dev loss: 0.4923 r:0.6501
si_en Dev loss: 0.8527 r:0.5626
ne_en Dev loss: 0.5001 r:0.7287
ru_en Dev loss: 0.4824 r:0.7156
Current avg r:0.5870 Best avg r: 0.6301
04:50:28,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:51:59,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:30,526 root INFO Epoch 9 Global steps: 77000 Train loss: 0.2208
en_de Dev loss: 0.8885 r:0.1930
en_zh Dev loss: 0.8078 r:0.4364
ro_en Dev loss: 0.3487 r:0.8153
et_en Dev loss: 0.5173 r:0.6462
si_en Dev loss: 0.8251 r:0.5620
ne_en Dev loss: 0.5086 r:0.7364
ru_en Dev loss: 0.4582 r:0.7198
Current avg r:0.5870 Best avg r: 0.6301
04:58:03,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:59:34,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:01:05,296 root INFO Epoch 9 Global steps: 77700 Train loss: 0.2165
en_de Dev loss: 0.9047 r:0.2117
en_zh Dev loss: 0.9036 r:0.4331
ro_en Dev loss: 0.4111 r:0.8156
et_en Dev loss: 0.5329 r:0.6451
si_en Dev loss: 1.0026 r:0.5570
ne_en Dev loss: 0.5930 r:0.7345
ru_en Dev loss: 0.5495 r:0.7115
Current avg r:0.5869 Best avg r: 0.6301
05:05:38,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:07:09,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:40,95 root INFO Epoch 9 Global steps: 78400 Train loss: 0.2209
en_de Dev loss: 0.8711 r:0.2051
en_zh Dev loss: 0.8199 r:0.4469
ro_en Dev loss: 0.3606 r:0.8188
et_en Dev loss: 0.4921 r:0.6451
si_en Dev loss: 0.8325 r:0.5685
ne_en Dev loss: 0.5391 r:0.7296
ru_en Dev loss: 0.5165 r:0.7084
Current avg r:0.5889 Best avg r: 0.6301
05:13:13,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:44,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:16:14,948 root INFO Epoch 9 Global steps: 79100 Train loss: 0.2132
en_de Dev loss: 0.8906 r:0.2090
en_zh Dev loss: 0.8531 r:0.4546
ro_en Dev loss: 0.3642 r:0.8149
et_en Dev loss: 0.5098 r:0.6553
si_en Dev loss: 0.9349 r:0.5615
ne_en Dev loss: 0.5346 r:0.7313
ru_en Dev loss: 0.4686 r:0.7363
Current avg r:0.5947 Best avg r: 0.6301
05:20:49,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:22:20,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:51,606 root INFO Epoch 10 Global steps: 79800 Train loss: 0.2076
en_de Dev loss: 0.8931 r:0.2160
en_zh Dev loss: 0.8246 r:0.4419
ro_en Dev loss: 0.3546 r:0.8146
et_en Dev loss: 0.5070 r:0.6449
si_en Dev loss: 0.8515 r:0.5560
ne_en Dev loss: 0.5031 r:0.7240
ru_en Dev loss: 0.4580 r:0.7301
Current avg r:0.5896 Best avg r: 0.6301
05:28:24,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:29:55,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:26,379 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1985
en_de Dev loss: 0.8728 r:0.2171
en_zh Dev loss: 0.7991 r:0.4343
ro_en Dev loss: 0.3340 r:0.8156
et_en Dev loss: 0.4910 r:0.6398
si_en Dev loss: 0.8606 r:0.5572
ne_en Dev loss: 0.5556 r:0.7253
ru_en Dev loss: 0.4754 r:0.7172
Current avg r:0.5866 Best avg r: 0.6301
05:35:59,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:30,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:39:01,119 root INFO Epoch 10 Global steps: 81200 Train loss: 0.2014
en_de Dev loss: 0.9019 r:0.2181
en_zh Dev loss: 0.8657 r:0.4354
ro_en Dev loss: 0.3795 r:0.8159
et_en Dev loss: 0.5133 r:0.6450
si_en Dev loss: 0.8808 r:0.5646
ne_en Dev loss: 0.5763 r:0.7284
ru_en Dev loss: 0.4718 r:0.7312
Current avg r:0.5912 Best avg r: 0.6301
05:43:34,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:45:05,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:36,2 root INFO Epoch 10 Global steps: 81900 Train loss: 0.2053
en_de Dev loss: 0.8700 r:0.2176
en_zh Dev loss: 0.8072 r:0.4393
ro_en Dev loss: 0.3473 r:0.8208
et_en Dev loss: 0.5294 r:0.6557
si_en Dev loss: 0.8574 r:0.5636
ne_en Dev loss: 0.4721 r:0.7352
ru_en Dev loss: 0.4348 r:0.7385
Current avg r:0.5958 Best avg r: 0.6301
05:51:09,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:39,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:54:10,757 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1909
en_de Dev loss: 0.8882 r:0.1973
en_zh Dev loss: 0.8384 r:0.4296
ro_en Dev loss: 0.3616 r:0.8192
et_en Dev loss: 0.5064 r:0.6462
si_en Dev loss: 0.9866 r:0.5543
ne_en Dev loss: 0.5699 r:0.7334
ru_en Dev loss: 0.4971 r:0.7183
Current avg r:0.5855 Best avg r: 0.6301
05:58:44,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:00:15,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:01:46,171 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1918
en_de Dev loss: 0.9241 r:0.2034
en_zh Dev loss: 0.8715 r:0.4295
ro_en Dev loss: 0.3844 r:0.8142
et_en Dev loss: 0.5069 r:0.6431
si_en Dev loss: 0.9963 r:0.5471
ne_en Dev loss: 0.5625 r:0.7268
ru_en Dev loss: 0.5268 r:0.7174
Current avg r:0.5831 Best avg r: 0.6301
06:06:19,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:50,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:09:21,340 root INFO Epoch 10 Global steps: 84000 Train loss: 0.2010
en_de Dev loss: 0.9207 r:0.1765
en_zh Dev loss: 0.9060 r:0.4236
ro_en Dev loss: 0.4203 r:0.8129
et_en Dev loss: 0.5186 r:0.6329
si_en Dev loss: 1.0012 r:0.5508
ne_en Dev loss: 0.6279 r:0.7245
ru_en Dev loss: 0.5896 r:0.6925
Current avg r:0.5734 Best avg r: 0.6301
06:13:54,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:15:25,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:16:56,440 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1960
en_de Dev loss: 0.8993 r:0.1788
en_zh Dev loss: 0.7788 r:0.4486
ro_en Dev loss: 0.3386 r:0.8212
et_en Dev loss: 0.4719 r:0.6605
si_en Dev loss: 0.8385 r:0.5645
ne_en Dev loss: 0.5481 r:0.7225
ru_en Dev loss: 0.4536 r:0.7364
Current avg r:0.5904 Best avg r: 0.6301
06:21:29,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:23:00,620 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:31,427 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1953
en_de Dev loss: 0.8920 r:0.1906
en_zh Dev loss: 0.7691 r:0.4546
ro_en Dev loss: 0.3287 r:0.8206
et_en Dev loss: 0.5097 r:0.6556
si_en Dev loss: 0.8057 r:0.5596
ne_en Dev loss: 0.5384 r:0.7184
ru_en Dev loss: 0.4485 r:0.7212
Current avg r:0.5886 Best avg r: 0.6301
06:29:04,510 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:35,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:06,245 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1913
en_de Dev loss: 0.9153 r:0.1553
en_zh Dev loss: 0.8919 r:0.4354
ro_en Dev loss: 0.3790 r:0.8176
et_en Dev loss: 0.5014 r:0.6386
si_en Dev loss: 0.9779 r:0.5484
ne_en Dev loss: 0.6658 r:0.7177
ru_en Dev loss: 0.5625 r:0.6997
Current avg r:0.5733 Best avg r: 0.6301
06:36:39,510 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:38:10,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:41,195 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1959
en_de Dev loss: 0.9069 r:0.1695
en_zh Dev loss: 0.8989 r:0.4325
ro_en Dev loss: 0.4032 r:0.8144
et_en Dev loss: 0.5084 r:0.6433
si_en Dev loss: 1.0844 r:0.5400
ne_en Dev loss: 0.6990 r:0.7168
ru_en Dev loss: 0.5224 r:0.7215
Current avg r:0.5769 Best avg r: 0.6301
06:44:14,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:45,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:47:16,123 root INFO Epoch 10 Global steps: 87500 Train loss: 0.1836
en_de Dev loss: 0.8994 r:0.2274
en_zh Dev loss: 0.8623 r:0.4484
ro_en Dev loss: 0.3820 r:0.8176
et_en Dev loss: 0.5016 r:0.6507
si_en Dev loss: 0.9146 r:0.5552
ne_en Dev loss: 0.5888 r:0.7235
ru_en Dev loss: 0.5381 r:0.7183
Current avg r:0.5916 Best avg r: 0.6301
06:51:50,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:53:21,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:54:52,595 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1870
en_de Dev loss: 0.9019 r:0.2084
en_zh Dev loss: 0.8610 r:0.4540
ro_en Dev loss: 0.3769 r:0.8201
et_en Dev loss: 0.4916 r:0.6454
si_en Dev loss: 1.0155 r:0.5451
ne_en Dev loss: 0.6497 r:0.7219
ru_en Dev loss: 0.5289 r:0.7159
Current avg r:0.5873 Best avg r: 0.6301
06:59:25,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:56,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:27,448 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1721
en_de Dev loss: 0.8868 r:0.2320
en_zh Dev loss: 0.8485 r:0.4443
ro_en Dev loss: 0.3632 r:0.8165
et_en Dev loss: 0.5346 r:0.6590
si_en Dev loss: 0.8853 r:0.5520
ne_en Dev loss: 0.5178 r:0.7189
ru_en Dev loss: 0.4836 r:0.7236
Current avg r:0.5923 Best avg r: 0.6301
07:07:00,587 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:31,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:10:02,329 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1803
en_de Dev loss: 0.8785 r:0.2283
en_zh Dev loss: 0.8151 r:0.4518
ro_en Dev loss: 0.3547 r:0.8175
et_en Dev loss: 0.5015 r:0.6498
si_en Dev loss: 0.8921 r:0.5469
ne_en Dev loss: 0.4672 r:0.7207
ru_en Dev loss: 0.4651 r:0.7263
Current avg r:0.5916 Best avg r: 0.6301
07:14:35,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:16:06,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:37,272 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1818
en_de Dev loss: 0.8829 r:0.2117
en_zh Dev loss: 0.8284 r:0.4464
ro_en Dev loss: 0.3463 r:0.8168
et_en Dev loss: 0.4981 r:0.6527
si_en Dev loss: 0.8594 r:0.5485
ne_en Dev loss: 0.5607 r:0.7167
ru_en Dev loss: 0.4635 r:0.7253
Current avg r:0.5883 Best avg r: 0.6301
07:22:10,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:23:41,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:25:12,159 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1800
en_de Dev loss: 0.9205 r:0.2139
en_zh Dev loss: 0.8588 r:0.4460
ro_en Dev loss: 0.4020 r:0.8118
et_en Dev loss: 0.5057 r:0.6510
si_en Dev loss: 0.9518 r:0.5408
ne_en Dev loss: 0.5995 r:0.7188
ru_en Dev loss: 0.4926 r:0.7298
Current avg r:0.5874 Best avg r: 0.6301
07:29:45,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:31:16,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:46,991 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1838
en_de Dev loss: 0.9117 r:0.2000
en_zh Dev loss: 0.8742 r:0.4436
ro_en Dev loss: 0.3863 r:0.8130
et_en Dev loss: 0.4914 r:0.6465
si_en Dev loss: 0.9872 r:0.5436
ne_en Dev loss: 0.5948 r:0.7196
ru_en Dev loss: 0.5300 r:0.7123
Current avg r:0.5827 Best avg r: 0.6301
07:37:20,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:51,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:40:21,966 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1834
en_de Dev loss: 0.9045 r:0.2188
en_zh Dev loss: 0.9011 r:0.4477
ro_en Dev loss: 0.4274 r:0.8146
et_en Dev loss: 0.5133 r:0.6477
si_en Dev loss: 1.0817 r:0.5391
ne_en Dev loss: 0.6705 r:0.7170
ru_en Dev loss: 0.5670 r:0.7080
Current avg r:0.5847 Best avg r: 0.6301
07:44:55,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:46:26,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:47:57,74 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1730
en_de Dev loss: 0.8928 r:0.2361
en_zh Dev loss: 0.8957 r:0.4372
ro_en Dev loss: 0.4168 r:0.8133
et_en Dev loss: 0.5211 r:0.6447
si_en Dev loss: 0.9549 r:0.5449
ne_en Dev loss: 0.7014 r:0.7155
ru_en Dev loss: 0.5245 r:0.7161
Current avg r:0.5868 Best avg r: 0.6301
07:52:30,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:54:01,81 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:31,916 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1710
en_de Dev loss: 0.8774 r:0.2511
en_zh Dev loss: 0.8519 r:0.4557
ro_en Dev loss: 0.3664 r:0.8178
et_en Dev loss: 0.5117 r:0.6638
si_en Dev loss: 0.8666 r:0.5482
ne_en Dev loss: 0.5331 r:0.7191
ru_en Dev loss: 0.4736 r:0.7287
Current avg r:0.5978 Best avg r: 0.6301
08:00:05,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:01:36,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:06,881 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1709
en_de Dev loss: 0.8906 r:0.2294
en_zh Dev loss: 0.8189 r:0.4556
ro_en Dev loss: 0.3500 r:0.8204
et_en Dev loss: 0.4774 r:0.6599
si_en Dev loss: 0.8949 r:0.5441
ne_en Dev loss: 0.5591 r:0.7250
ru_en Dev loss: 0.4723 r:0.7247
Current avg r:0.5942 Best avg r: 0.6301
08:07:40,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:11,122 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:42,22 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1780
en_de Dev loss: 0.9014 r:0.2079
en_zh Dev loss: 0.8576 r:0.4371
ro_en Dev loss: 0.3930 r:0.8085
et_en Dev loss: 0.5031 r:0.6455
si_en Dev loss: 0.9614 r:0.5380
ne_en Dev loss: 0.6241 r:0.7107
ru_en Dev loss: 0.5471 r:0.6980
Current avg r:0.5779 Best avg r: 0.6301
08:15:16,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:16:47,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:18:18,478 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1560
en_de Dev loss: 0.9127 r:0.1945
en_zh Dev loss: 0.8154 r:0.4531
ro_en Dev loss: 0.3729 r:0.8121
et_en Dev loss: 0.5354 r:0.6572
si_en Dev loss: 0.8716 r:0.5494
ne_en Dev loss: 0.5266 r:0.7188
ru_en Dev loss: 0.4877 r:0.7200
Current avg r:0.5864 Best avg r: 0.6301
08:22:51,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:24:22,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:25:53,197 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1615
en_de Dev loss: 0.8942 r:0.1916
en_zh Dev loss: 0.8234 r:0.4492
ro_en Dev loss: 0.3804 r:0.8156
et_en Dev loss: 0.4860 r:0.6565
si_en Dev loss: 0.9664 r:0.5424
ne_en Dev loss: 0.6076 r:0.7169
ru_en Dev loss: 0.5056 r:0.7174
Current avg r:0.5842 Best avg r: 0.6301
08:30:26,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:31:57,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:33:27,992 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1599
en_de Dev loss: 0.9204 r:0.1975
en_zh Dev loss: 0.8897 r:0.4462
ro_en Dev loss: 0.4081 r:0.8129
et_en Dev loss: 0.5011 r:0.6525
si_en Dev loss: 1.0337 r:0.5398
ne_en Dev loss: 0.6999 r:0.7190
ru_en Dev loss: 0.5284 r:0.7208
Current avg r:0.5841 Best avg r: 0.6301
08:38:01,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:39:32,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:03,30 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1666
en_de Dev loss: 0.9083 r:0.2034
en_zh Dev loss: 0.8542 r:0.4497
ro_en Dev loss: 0.3767 r:0.8124
et_en Dev loss: 0.5193 r:0.6446
si_en Dev loss: 0.9765 r:0.5377
ne_en Dev loss: 0.6409 r:0.7092
ru_en Dev loss: 0.4850 r:0.7214
Current avg r:0.5826 Best avg r: 0.6301
08:45:36,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:07,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:48:37,845 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1569
en_de Dev loss: 0.8846 r:0.2195
en_zh Dev loss: 0.8198 r:0.4526
ro_en Dev loss: 0.3348 r:0.8168
et_en Dev loss: 0.5159 r:0.6657
si_en Dev loss: 0.7918 r:0.5560
ne_en Dev loss: 0.5016 r:0.7208
ru_en Dev loss: 0.3965 r:0.7518
Current avg r:0.5976 Best avg r: 0.6301
08:53:10,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:54:41,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:12,656 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1633
en_de Dev loss: 0.8964 r:0.2134
en_zh Dev loss: 0.8420 r:0.4410
ro_en Dev loss: 0.3585 r:0.8162
et_en Dev loss: 0.4895 r:0.6526
si_en Dev loss: 0.8905 r:0.5485
ne_en Dev loss: 0.5633 r:0.7125
ru_en Dev loss: 0.4699 r:0.7313
Current avg r:0.5879 Best avg r: 0.6301
09:00:45,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:16,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:47,466 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1626
en_de Dev loss: 0.8807 r:0.2152
en_zh Dev loss: 0.8337 r:0.4462
ro_en Dev loss: 0.3483 r:0.8128
et_en Dev loss: 0.5016 r:0.6636
si_en Dev loss: 0.8723 r:0.5545
ne_en Dev loss: 0.5668 r:0.7200
ru_en Dev loss: 0.4407 r:0.7381
Current avg r:0.5929 Best avg r: 0.6301
09:08:20,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:51,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:22,386 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1553
en_de Dev loss: 0.9108 r:0.2014
en_zh Dev loss: 0.9193 r:0.4359
ro_en Dev loss: 0.4265 r:0.8021
et_en Dev loss: 0.5380 r:0.6301
si_en Dev loss: 1.0625 r:0.5312
ne_en Dev loss: 0.7045 r:0.7140
ru_en Dev loss: 0.5274 r:0.7152
Current avg r:0.5757 Best avg r: 0.6301
09:15:55,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:17:26,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:18:57,27 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1604
en_de Dev loss: 0.8741 r:0.2275
en_zh Dev loss: 0.8302 r:0.4553
ro_en Dev loss: 0.3726 r:0.8116
et_en Dev loss: 0.5058 r:0.6477
si_en Dev loss: 0.9042 r:0.5433
ne_en Dev loss: 0.5017 r:0.7185
ru_en Dev loss: 0.4684 r:0.7282
Current avg r:0.5903 Best avg r: 0.6301
09:23:29,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:00,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:31,600 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1649
en_de Dev loss: 0.8795 r:0.2166
en_zh Dev loss: 0.8216 r:0.4427
ro_en Dev loss: 0.3544 r:0.8164
et_en Dev loss: 0.4587 r:0.6610
si_en Dev loss: 0.8519 r:0.5518
ne_en Dev loss: 0.5512 r:0.7168
ru_en Dev loss: 0.4506 r:0.7338
Current avg r:0.5913 Best avg r: 0.6301
09:31:04,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:32:35,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:34:06,259 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1638
en_de Dev loss: 0.9193 r:0.1899
en_zh Dev loss: 0.8499 r:0.4493
ro_en Dev loss: 0.4067 r:0.8139
et_en Dev loss: 0.4934 r:0.6475
si_en Dev loss: 1.0261 r:0.5407
ne_en Dev loss: 0.6756 r:0.7132
ru_en Dev loss: 0.5297 r:0.7165
Current avg r:0.5816 Best avg r: 0.6301
09:38:40,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:40:11,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:41:42,338 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1597
en_de Dev loss: 0.9125 r:0.2146
en_zh Dev loss: 0.8478 r:0.4557
ro_en Dev loss: 0.3947 r:0.8161
et_en Dev loss: 0.4976 r:0.6627
si_en Dev loss: 0.9316 r:0.5552
ne_en Dev loss: 0.5628 r:0.7192
ru_en Dev loss: 0.4819 r:0.7305
Current avg r:0.5934 Best avg r: 0.6301
09:46:15,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:46,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:17,91 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1494
en_de Dev loss: 0.8960 r:0.1894
en_zh Dev loss: 0.8472 r:0.4408
ro_en Dev loss: 0.3771 r:0.8146
et_en Dev loss: 0.4874 r:0.6503
si_en Dev loss: 0.9246 r:0.5500
ne_en Dev loss: 0.6104 r:0.7164
ru_en Dev loss: 0.4709 r:0.7267
Current avg r:0.5840 Best avg r: 0.6301
09:53:50,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:20,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:51,774 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1494
en_de Dev loss: 0.8889 r:0.2048
en_zh Dev loss: 0.8276 r:0.4511
ro_en Dev loss: 0.3625 r:0.8185
et_en Dev loss: 0.4687 r:0.6619
si_en Dev loss: 0.9217 r:0.5489
ne_en Dev loss: 0.5835 r:0.7113
ru_en Dev loss: 0.4727 r:0.7266
Current avg r:0.5890 Best avg r: 0.6301
10:01:24,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:55,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:04:26,355 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1433
en_de Dev loss: 0.9356 r:0.1958
en_zh Dev loss: 0.8917 r:0.4481
ro_en Dev loss: 0.3855 r:0.8164
et_en Dev loss: 0.4849 r:0.6524
si_en Dev loss: 1.0447 r:0.5373
ne_en Dev loss: 0.5998 r:0.7122
ru_en Dev loss: 0.5426 r:0.7167
Current avg r:0.5827 Best avg r: 0.6301
10:08:59,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:30,190 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:12:00,997 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1470
en_de Dev loss: 0.9067 r:0.1911
en_zh Dev loss: 0.8135 r:0.4473
ro_en Dev loss: 0.3759 r:0.8112
et_en Dev loss: 0.4872 r:0.6415
si_en Dev loss: 1.0047 r:0.5344
ne_en Dev loss: 0.6727 r:0.7123
ru_en Dev loss: 0.4987 r:0.7167
Current avg r:0.5792 Best avg r: 0.6301
10:16:38,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:18:08,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:39,752 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1461
en_de Dev loss: 0.9244 r:0.1933
en_zh Dev loss: 0.8986 r:0.4490
ro_en Dev loss: 0.3968 r:0.8164
et_en Dev loss: 0.4876 r:0.6560
si_en Dev loss: 1.0202 r:0.5406
ne_en Dev loss: 0.5500 r:0.7217
ru_en Dev loss: 0.5459 r:0.7111
Current avg r:0.5840 Best avg r: 0.6301
10:24:12,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:43,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:27:14,337 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1447
en_de Dev loss: 0.8895 r:0.2132
en_zh Dev loss: 0.7916 r:0.4526
ro_en Dev loss: 0.3691 r:0.8133
et_en Dev loss: 0.4713 r:0.6564
si_en Dev loss: 0.8840 r:0.5446
ne_en Dev loss: 0.5992 r:0.7143
ru_en Dev loss: 0.4539 r:0.7283
Current avg r:0.5889 Best avg r: 0.6301
10:31:52,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
