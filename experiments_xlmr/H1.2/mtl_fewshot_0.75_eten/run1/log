14:37:37,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:37:51,411 root INFO 
id:en_de cur r: 0.0449 best r: 0.0449
14:38:05,102 root INFO 
id:en_zh cur r: 0.0223 best r: 0.0223
14:38:18,822 root INFO 
id:ro_en cur r: 0.3721 best r: 0.3721
14:38:46,308 root INFO 
id:et_en cur r: 0.4221 best r: 0.4221
14:39:00,175 root INFO 
id:si_en cur r: 0.3132 best r: 0.3132
14:39:13,986 root INFO 
id:ne_en cur r: 0.5040 best r: 0.5040
14:39:27,801 root INFO 
id:ru_en cur r: 0.5388 best r: 0.5388
14:39:27,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:41:04,925 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:41:04,933 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:41:04,937 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:41:04,942 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:41:04,946 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:41:04,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:41:04,958 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:41:18,830 root INFO Epoch 0 Global steps: 700 Train loss: 0.8869
en_de Dev loss: 0.9657 r:0.0566
en_zh Dev loss: 0.8072 r:0.2443
ro_en Dev loss: 0.7091 r:0.5365
et_en Dev loss: 0.6457 r:0.4907
si_en Dev loss: 0.6900 r:0.4174
ne_en Dev loss: 0.6764 r:0.5224
ru_en Dev loss: 0.6345 r:0.5714
Current avg r:0.4056 Best avg r: 0.4056
14:45:59,772 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:46:27,616 root INFO 
id:en_zh cur r: 0.2559 best r: 0.2559
14:46:41,574 root INFO 
id:ro_en cur r: 0.6123 best r: 0.6123
14:47:09,494 root INFO 
id:et_en cur r: 0.5437 best r: 0.5437
14:47:23,476 root INFO 
id:si_en cur r: 0.3931 best r: 0.3931
14:47:37,452 root INFO 
id:ne_en cur r: 0.5726 best r: 0.5726
14:47:51,379 root INFO 
id:ru_en cur r: 0.6573 best r: 0.6573
14:47:51,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:29,262 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:49:29,270 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:49:29,275 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:49:29,280 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:49:29,285 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:49:29,290 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:49:29,299 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:49:43,279 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8185
en_de Dev loss: 0.9001 r:0.1158
en_zh Dev loss: 0.7766 r:0.2834
ro_en Dev loss: 0.6363 r:0.6269
et_en Dev loss: 0.5675 r:0.5034
si_en Dev loss: 0.7857 r:0.4412
ne_en Dev loss: 0.6292 r:0.5340
ru_en Dev loss: 0.5572 r:0.6479
Current avg r:0.4504 Best avg r: 0.4504
14:54:24,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:38,781 root INFO 
id:en_de cur r: 0.0640 best r: 0.0640
14:54:52,752 root INFO 
id:en_zh cur r: 0.2905 best r: 0.2905
14:55:06,758 root INFO 
id:ro_en cur r: 0.6379 best r: 0.6379
14:55:34,788 root INFO 
id:et_en cur r: 0.5571 best r: 0.5571
14:56:02,811 root INFO 
id:ne_en cur r: 0.5873 best r: 0.5873
14:56:16,766 root INFO 
id:ru_en cur r: 0.6785 best r: 0.6785
14:56:16,766 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:54,536 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
14:57:54,545 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:57:54,549 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:57:54,554 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
14:57:54,558 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
14:57:54,563 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:57:54,570 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:58:08,427 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7709
en_de Dev loss: 0.9372 r:0.0918
en_zh Dev loss: 0.7631 r:0.2843
ro_en Dev loss: 0.5450 r:0.6665
et_en Dev loss: 0.5104 r:0.5581
si_en Dev loss: 0.6947 r:0.4649
ne_en Dev loss: 0.5562 r:0.5897
ru_en Dev loss: 0.5065 r:0.6738
Current avg r:0.4756 Best avg r: 0.4756
15:02:50,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:04,238 root INFO 
id:en_de cur r: 0.0857 best r: 0.0857
15:03:18,205 root INFO 
id:en_zh cur r: 0.3175 best r: 0.3175
15:03:32,216 root INFO 
id:ro_en cur r: 0.6669 best r: 0.6669
15:04:00,237 root INFO 
id:et_en cur r: 0.5887 best r: 0.5887
15:04:14,253 root INFO 
id:si_en cur r: 0.4563 best r: 0.4563
15:04:28,294 root INFO 
id:ne_en cur r: 0.6291 best r: 0.6291
15:04:42,269 root INFO 
id:ru_en cur r: 0.6840 best r: 0.6840
15:04:42,270 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:20,137 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:06:20,147 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:06:20,152 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:06:20,156 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:06:20,161 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:06:20,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:06:20,175 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:06:34,27 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7608
en_de Dev loss: 0.9959 r:0.1152
en_zh Dev loss: 0.8050 r:0.3154
ro_en Dev loss: 0.5380 r:0.6943
et_en Dev loss: 0.4955 r:0.5918
si_en Dev loss: 0.7584 r:0.4915
ne_en Dev loss: 0.5376 r:0.6272
ru_en Dev loss: 0.5422 r:0.6846
Current avg r:0.5029 Best avg r: 0.5029
15:11:16,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:58,303 root INFO 
id:ro_en cur r: 0.6943 best r: 0.6943
15:12:26,326 root INFO 
id:et_en cur r: 0.6286 best r: 0.6286
15:12:40,452 root INFO 
id:si_en cur r: 0.4829 best r: 0.4829
15:12:54,606 root INFO 
id:ne_en cur r: 0.6615 best r: 0.6615
15:13:08,652 root INFO 
id:ru_en cur r: 0.7074 best r: 0.7074
15:13:08,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:46,382 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:14:46,390 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:14:46,397 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:14:46,401 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:14:46,407 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:14:46,411 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:14:46,417 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:15:00,315 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6960
en_de Dev loss: 0.9927 r:0.1086
en_zh Dev loss: 0.7732 r:0.3210
ro_en Dev loss: 0.4661 r:0.7082
et_en Dev loss: 0.4318 r:0.6301
si_en Dev loss: 0.6404 r:0.5206
ne_en Dev loss: 0.4586 r:0.6576
ru_en Dev loss: 0.4722 r:0.7084
Current avg r:0.5221 Best avg r: 0.5221
15:19:42,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:57,11 root INFO 
id:en_de cur r: 0.1144 best r: 0.1144
15:20:11,5 root INFO 
id:en_zh cur r: 0.3508 best r: 0.3508
15:20:25,16 root INFO 
id:ro_en cur r: 0.7015 best r: 0.7015
15:20:53,51 root INFO 
id:et_en cur r: 0.6456 best r: 0.6456
15:21:07,81 root INFO 
id:si_en cur r: 0.5117 best r: 0.5117
15:21:21,99 root INFO 
id:ne_en cur r: 0.6852 best r: 0.6852
15:21:35,58 root INFO 
id:ru_en cur r: 0.7098 best r: 0.7098
15:21:35,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:23:12,392 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:23:12,401 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:23:12,406 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:23:12,410 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:23:12,415 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:23:12,423 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:23:12,428 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:23:26,323 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6586
en_de Dev loss: 0.9314 r:0.1488
en_zh Dev loss: 0.7462 r:0.3547
ro_en Dev loss: 0.4510 r:0.7178
et_en Dev loss: 0.4199 r:0.6522
si_en Dev loss: 0.6315 r:0.5406
ne_en Dev loss: 0.4560 r:0.6689
ru_en Dev loss: 0.4698 r:0.7149
Current avg r:0.5426 Best avg r: 0.5426
15:28:08,790 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:28:50,725 root INFO 
id:ro_en cur r: 0.7084 best r: 0.7084
15:29:46,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:31:24,104 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6327
en_de Dev loss: 1.0288 r:0.1421
en_zh Dev loss: 0.8540 r:0.3436
ro_en Dev loss: 0.4947 r:0.7270
et_en Dev loss: 0.4543 r:0.6375
si_en Dev loss: 0.8514 r:0.5144
ne_en Dev loss: 0.6046 r:0.6188
ru_en Dev loss: 0.5803 r:0.6971
Current avg r:0.5258 Best avg r: 0.5426
15:36:06,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:20,631 root INFO 
id:en_de cur r: 0.1531 best r: 0.1531
15:36:34,606 root INFO 
id:en_zh cur r: 0.3924 best r: 0.3924
15:36:48,609 root INFO 
id:ro_en cur r: 0.7341 best r: 0.7341
15:37:16,644 root INFO 
id:et_en cur r: 0.6748 best r: 0.6748
15:37:30,654 root INFO 
id:si_en cur r: 0.5494 best r: 0.5494
15:37:44,674 root INFO 
id:ne_en cur r: 0.7156 best r: 0.7156
15:37:58,598 root INFO 
id:ru_en cur r: 0.7385 best r: 0.7385
15:37:58,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:36,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:39:36,113 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:39:36,118 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:39:36,122 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:39:36,127 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:39:36,132 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:39:36,137 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:39:49,995 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6271
en_de Dev loss: 0.9187 r:0.1606
en_zh Dev loss: 0.7086 r:0.3851
ro_en Dev loss: 0.3863 r:0.7450
et_en Dev loss: 0.3788 r:0.6815
si_en Dev loss: 0.6524 r:0.5601
ne_en Dev loss: 0.4043 r:0.7033
ru_en Dev loss: 0.4329 r:0.7413
Current avg r:0.5681 Best avg r: 0.5681
15:44:33,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:10,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:47,516 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6114
en_de Dev loss: 0.9560 r:0.1789
en_zh Dev loss: 0.7555 r:0.3915
ro_en Dev loss: 0.4680 r:0.7526
et_en Dev loss: 0.3953 r:0.6732
si_en Dev loss: 0.7237 r:0.5526
ne_en Dev loss: 0.4714 r:0.6811
ru_en Dev loss: 0.4682 r:0.7351
Current avg r:0.5664 Best avg r: 0.5681
15:52:30,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:44,293 root INFO 
id:en_de cur r: 0.1601 best r: 0.1601
15:52:58,269 root INFO 
id:en_zh cur r: 0.4084 best r: 0.4084
15:53:12,278 root INFO 
id:ro_en cur r: 0.7570 best r: 0.7570
15:53:40,337 root INFO 
id:si_en cur r: 0.5635 best r: 0.5635
15:54:08,213 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:45,513 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
15:55:45,521 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:55:45,526 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:55:45,531 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
15:55:45,536 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
15:55:45,543 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:55:45,548 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:55:59,398 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5842
en_de Dev loss: 0.9223 r:0.1825
en_zh Dev loss: 0.7194 r:0.4055
ro_en Dev loss: 0.4367 r:0.7674
et_en Dev loss: 0.3882 r:0.6828
si_en Dev loss: 0.6198 r:0.5774
ne_en Dev loss: 0.4632 r:0.6982
ru_en Dev loss: 0.4701 r:0.7389
Current avg r:0.5789 Best avg r: 0.5789
16:00:42,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:56,516 root INFO 
id:en_de cur r: 0.1739 best r: 0.1739
16:01:10,567 root INFO 
id:en_zh cur r: 0.4199 best r: 0.4199
16:01:24,649 root INFO 
id:ro_en cur r: 0.7599 best r: 0.7599
16:02:20,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:57,439 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:03:57,446 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:03:57,451 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:03:57,455 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:03:57,461 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:03:57,465 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:03:57,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:04:11,321 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5560
en_de Dev loss: 0.9245 r:0.1999
en_zh Dev loss: 0.7423 r:0.4224
ro_en Dev loss: 0.4561 r:0.7732
et_en Dev loss: 0.4183 r:0.6855
si_en Dev loss: 0.7511 r:0.5716
ne_en Dev loss: 0.5202 r:0.6973
ru_en Dev loss: 0.5038 r:0.7378
Current avg r:0.5840 Best avg r: 0.5840
16:08:55,916 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:09,916 root INFO 
id:en_de cur r: 0.1923 best r: 0.1923
16:09:23,901 root INFO 
id:en_zh cur r: 0.4307 best r: 0.4307
16:09:37,907 root INFO 
id:ro_en cur r: 0.7723 best r: 0.7723
16:10:05,795 root INFO 
id:et_en cur r: 0.6937 best r: 0.6937
16:10:19,706 root INFO 
id:si_en cur r: 0.5669 best r: 0.5669
16:10:33,646 root INFO 
id:ne_en cur r: 0.7307 best r: 0.7307
16:10:47,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:24,746 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:12:24,755 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:12:24,760 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:12:24,764 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:12:24,770 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:12:24,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:12:24,780 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:12:38,638 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5882
en_de Dev loss: 0.9276 r:0.1978
en_zh Dev loss: 0.7361 r:0.4189
ro_en Dev loss: 0.3921 r:0.7778
et_en Dev loss: 0.3636 r:0.7031
si_en Dev loss: 0.6786 r:0.5805
ne_en Dev loss: 0.3956 r:0.7225
ru_en Dev loss: 0.4518 r:0.7415
Current avg r:0.5917 Best avg r: 0.5917
16:17:22,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:36,637 root INFO 
id:en_de cur r: 0.2014 best r: 0.2014
16:19:00,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:37,502 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5879
en_de Dev loss: 0.9543 r:0.2082
en_zh Dev loss: 0.8269 r:0.4314
ro_en Dev loss: 0.5411 r:0.7720
et_en Dev loss: 0.4873 r:0.6777
si_en Dev loss: 0.9651 r:0.5504
ne_en Dev loss: 0.6352 r:0.6858
ru_en Dev loss: 0.6523 r:0.7094
Current avg r:0.5764 Best avg r: 0.5917
16:25:21,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:35,570 root INFO 
id:en_de cur r: 0.2099 best r: 0.2099
16:25:49,585 root INFO 
id:en_zh cur r: 0.4480 best r: 0.4480
16:26:03,632 root INFO 
id:ro_en cur r: 0.7875 best r: 0.7875
16:26:31,636 root INFO 
id:et_en cur r: 0.6942 best r: 0.6942
16:26:45,635 root INFO 
id:si_en cur r: 0.5881 best r: 0.5881
16:26:59,635 root INFO 
id:ne_en cur r: 0.7431 best r: 0.7431
16:27:13,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:28:50,932 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
16:28:50,941 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:28:50,948 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:28:50,953 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
16:28:50,957 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
16:28:50,962 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:28:50,969 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:29:04,846 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5591
en_de Dev loss: 0.8554 r:0.2098
en_zh Dev loss: 0.6667 r:0.4509
ro_en Dev loss: 0.3340 r:0.7909
et_en Dev loss: 0.3546 r:0.7055
si_en Dev loss: 0.5553 r:0.6032
ne_en Dev loss: 0.3725 r:0.7397
ru_en Dev loss: 0.3916 r:0.7466
Current avg r:0.6067 Best avg r: 0.6067
16:33:48,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:16,86 root INFO 
id:en_zh cur r: 0.4520 best r: 0.4520
16:34:29,964 root INFO 
id:ro_en cur r: 0.7898 best r: 0.7898
16:34:57,842 root INFO 
id:et_en cur r: 0.6945 best r: 0.6945
16:35:11,736 root INFO 
id:si_en cur r: 0.5927 best r: 0.5927
16:35:39,360 root INFO 
id:ru_en cur r: 0.7448 best r: 0.7448
16:35:39,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:16,597 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5519
en_de Dev loss: 0.8645 r:0.1988
en_zh Dev loss: 0.6796 r:0.4450
ro_en Dev loss: 0.3268 r:0.7960
et_en Dev loss: 0.3557 r:0.7055
si_en Dev loss: 0.6139 r:0.5968
ne_en Dev loss: 0.3625 r:0.7388
ru_en Dev loss: 0.4159 r:0.7476
Current avg r:0.6041 Best avg r: 0.6067
16:42:00,581 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:14,536 root INFO 
id:en_de cur r: 0.2188 best r: 0.2188
16:43:38,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:15,551 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5165
en_de Dev loss: 0.8960 r:0.2165
en_zh Dev loss: 0.7765 r:0.4324
ro_en Dev loss: 0.3625 r:0.7916
et_en Dev loss: 0.3696 r:0.6987
si_en Dev loss: 0.7326 r:0.5842
ne_en Dev loss: 0.4056 r:0.7292
ru_en Dev loss: 0.4735 r:0.7435
Current avg r:0.5994 Best avg r: 0.6067
16:49:59,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:13,535 root INFO 
id:en_de cur r: 0.2295 best r: 0.2295
16:51:37,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:14,663 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5240
en_de Dev loss: 0.8950 r:0.2294
en_zh Dev loss: 0.7561 r:0.4347
ro_en Dev loss: 0.3728 r:0.7879
et_en Dev loss: 0.3803 r:0.6927
si_en Dev loss: 0.6466 r:0.5870
ne_en Dev loss: 0.4137 r:0.7303
ru_en Dev loss: 0.4909 r:0.7256
Current avg r:0.5982 Best avg r: 0.6067
16:57:58,355 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:12,200 root INFO 
id:en_de cur r: 0.2331 best r: 0.2331
16:58:26,101 root INFO 
id:en_zh cur r: 0.4595 best r: 0.4595
16:58:40,86 root INFO 
id:ro_en cur r: 0.8030 best r: 0.8030
16:59:07,908 root INFO 
id:et_en cur r: 0.6949 best r: 0.6949
16:59:21,766 root INFO 
id:si_en cur r: 0.6197 best r: 0.6197
16:59:35,777 root INFO 
id:ne_en cur r: 0.7560 best r: 0.7560
16:59:49,635 root INFO 
id:ru_en cur r: 0.7451 best r: 0.7451
16:59:49,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:26,813 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
17:01:26,820 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:01:26,825 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:01:26,830 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
17:01:26,835 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
17:01:26,841 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:01:26,847 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:01:40,833 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5503
en_de Dev loss: 0.8506 r:0.2325
en_zh Dev loss: 0.6682 r:0.4586
ro_en Dev loss: 0.3290 r:0.8033
et_en Dev loss: 0.3894 r:0.7032
si_en Dev loss: 0.5220 r:0.6197
ne_en Dev loss: 0.3464 r:0.7530
ru_en Dev loss: 0.3889 r:0.7503
Current avg r:0.6172 Best avg r: 0.6172
17:06:24,256 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:38,157 root INFO 
id:en_de cur r: 0.2382 best r: 0.2382
17:07:05,832 root INFO 
id:ro_en cur r: 0.8070 best r: 0.8070
17:08:01,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:38,4 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5053
en_de Dev loss: 0.9019 r:0.2410
en_zh Dev loss: 0.7634 r:0.4516
ro_en Dev loss: 0.3302 r:0.8098
et_en Dev loss: 0.3755 r:0.7004
si_en Dev loss: 0.6860 r:0.5962
ne_en Dev loss: 0.4491 r:0.7381
ru_en Dev loss: 0.4728 r:0.7364
Current avg r:0.6105 Best avg r: 0.6172
17:14:21,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:34,941 root INFO 
id:en_de cur r: 0.2408 best r: 0.2408
17:14:48,810 root INFO 
id:en_zh cur r: 0.4651 best r: 0.4651
17:15:02,709 root INFO 
id:ro_en cur r: 0.8115 best r: 0.8115
17:15:30,564 root INFO 
id:et_en cur r: 0.7097 best r: 0.7097
17:15:44,484 root INFO 
id:si_en cur r: 0.6247 best r: 0.6247
17:15:58,372 root INFO 
id:ne_en cur r: 0.7575 best r: 0.7575
17:16:12,226 root INFO 
id:ru_en cur r: 0.7538 best r: 0.7538
17:16:12,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:17:49,683 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
17:17:49,690 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:17:49,695 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:17:49,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
17:17:49,705 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
17:17:49,711 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:17:49,717 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:18:03,688 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5083
en_de Dev loss: 0.8653 r:0.2412
en_zh Dev loss: 0.7106 r:0.4614
ro_en Dev loss: 0.3055 r:0.8155
et_en Dev loss: 0.3459 r:0.7183
si_en Dev loss: 0.5542 r:0.6273
ne_en Dev loss: 0.3373 r:0.7595
ru_en Dev loss: 0.4001 r:0.7609
Current avg r:0.6263 Best avg r: 0.6263
17:22:46,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:23,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:01,488 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5244
en_de Dev loss: 0.8897 r:0.2375
en_zh Dev loss: 0.7771 r:0.4559
ro_en Dev loss: 0.3460 r:0.8137
et_en Dev loss: 0.3747 r:0.7078
si_en Dev loss: 0.6854 r:0.6067
ne_en Dev loss: 0.4118 r:0.7518
ru_en Dev loss: 0.5009 r:0.7374
Current avg r:0.6158 Best avg r: 0.6263
17:30:44,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:12,471 root INFO 
id:en_zh cur r: 0.4673 best r: 0.4673
17:32:22,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:59,777 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5091
en_de Dev loss: 0.8635 r:0.2378
en_zh Dev loss: 0.7404 r:0.4635
ro_en Dev loss: 0.3334 r:0.8112
et_en Dev loss: 0.3771 r:0.7060
si_en Dev loss: 0.6973 r:0.6058
ne_en Dev loss: 0.4541 r:0.7513
ru_en Dev loss: 0.4551 r:0.7472
Current avg r:0.6176 Best avg r: 0.6263
17:38:44,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:58,383 root INFO 
id:en_de cur r: 0.2536 best r: 0.2536
17:39:26,275 root INFO 
id:ro_en cur r: 0.8144 best r: 0.8144
17:40:21,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:59,737 root INFO Epoch 2 Global steps: 16100 Train loss: 0.4863
en_de Dev loss: 0.8337 r:0.2561
en_zh Dev loss: 0.6787 r:0.4643
ro_en Dev loss: 0.3189 r:0.8129
et_en Dev loss: 0.3710 r:0.7102
si_en Dev loss: 0.5502 r:0.6173
ne_en Dev loss: 0.3510 r:0.7561
ru_en Dev loss: 0.4262 r:0.7422
Current avg r:0.6227 Best avg r: 0.6263
17:46:42,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:56,627 root INFO 
id:en_de cur r: 0.2547 best r: 0.2547
17:48:19,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:57,503 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4465
en_de Dev loss: 0.8785 r:0.2560
en_zh Dev loss: 0.7823 r:0.4549
ro_en Dev loss: 0.3872 r:0.8062
et_en Dev loss: 0.4096 r:0.6938
si_en Dev loss: 0.7559 r:0.5925
ne_en Dev loss: 0.4330 r:0.7427
ru_en Dev loss: 0.5241 r:0.7259
Current avg r:0.6103 Best avg r: 0.6263
17:54:39,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:03,156 root INFO 
id:ne_en cur r: 0.7580 best r: 0.7580
17:56:16,967 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:54,648 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4910
en_de Dev loss: 0.8749 r:0.2523
en_zh Dev loss: 0.7689 r:0.4631
ro_en Dev loss: 0.3692 r:0.8130
et_en Dev loss: 0.3918 r:0.7017
si_en Dev loss: 0.6509 r:0.6118
ne_en Dev loss: 0.3767 r:0.7544
ru_en Dev loss: 0.5101 r:0.7278
Current avg r:0.6177 Best avg r: 0.6263
18:02:36,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:18,180 root INFO 
id:ro_en cur r: 0.8192 best r: 0.8192
18:04:13,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:50,982 root INFO Epoch 2 Global steps: 18200 Train loss: 0.4376
en_de Dev loss: 0.8499 r:0.2448
en_zh Dev loss: 0.7521 r:0.4577
ro_en Dev loss: 0.3226 r:0.8156
et_en Dev loss: 0.3732 r:0.6993
si_en Dev loss: 0.7256 r:0.5935
ne_en Dev loss: 0.4083 r:0.7485
ru_en Dev loss: 0.4645 r:0.7276
Current avg r:0.6124 Best avg r: 0.6263
18:10:32,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:09,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:47,145 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4645
en_de Dev loss: 0.8855 r:0.2301
en_zh Dev loss: 0.7654 r:0.4533
ro_en Dev loss: 0.3714 r:0.8078
et_en Dev loss: 0.3898 r:0.6965
si_en Dev loss: 0.7004 r:0.5990
ne_en Dev loss: 0.4423 r:0.7421
ru_en Dev loss: 0.5643 r:0.7106
Current avg r:0.6056 Best avg r: 0.6263
18:18:28,941 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:05,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:43,560 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4899
en_de Dev loss: 0.8418 r:0.2344
en_zh Dev loss: 0.6869 r:0.4617
ro_en Dev loss: 0.3235 r:0.8154
et_en Dev loss: 0.3626 r:0.7053
si_en Dev loss: 0.6147 r:0.6107
ne_en Dev loss: 0.3646 r:0.7541
ru_en Dev loss: 0.4597 r:0.7322
Current avg r:0.6162 Best avg r: 0.6263
18:26:25,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:39,279 root INFO 
id:en_de cur r: 0.2566 best r: 0.2566
18:28:02,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:40,91 root INFO Epoch 2 Global steps: 20300 Train loss: 0.5001
en_de Dev loss: 0.8483 r:0.2406
en_zh Dev loss: 0.7351 r:0.4452
ro_en Dev loss: 0.3403 r:0.8136
et_en Dev loss: 0.3696 r:0.7004
si_en Dev loss: 0.6784 r:0.5998
ne_en Dev loss: 0.4847 r:0.7531
ru_en Dev loss: 0.4982 r:0.7251
Current avg r:0.6111 Best avg r: 0.6263
18:34:21,656 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:03,134 root INFO 
id:ro_en cur r: 0.8234 best r: 0.8234
18:35:44,864 root INFO 
id:ne_en cur r: 0.7634 best r: 0.7634
18:35:58,682 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:36,512 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4898
en_de Dev loss: 0.8668 r:0.2356
en_zh Dev loss: 0.7669 r:0.4589
ro_en Dev loss: 0.3274 r:0.8223
et_en Dev loss: 0.3661 r:0.7121
si_en Dev loss: 0.7626 r:0.6116
ne_en Dev loss: 0.4330 r:0.7625
ru_en Dev loss: 0.4685 r:0.7457
Current avg r:0.6212 Best avg r: 0.6263
18:42:18,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:55,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:33,27 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4611
en_de Dev loss: 0.8530 r:0.2257
en_zh Dev loss: 0.7598 r:0.4419
ro_en Dev loss: 0.3262 r:0.8142
et_en Dev loss: 0.3730 r:0.6989
si_en Dev loss: 0.6763 r:0.5999
ne_en Dev loss: 0.3799 r:0.7526
ru_en Dev loss: 0.4313 r:0.7380
Current avg r:0.6102 Best avg r: 0.6263
18:50:14,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:42,11 root INFO 
id:en_zh cur r: 0.4698 best r: 0.4698
18:51:51,543 root INFO 
id:ru_en cur r: 0.7546 best r: 0.7546
18:51:51,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:29,153 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4622
en_de Dev loss: 0.8571 r:0.2476
en_zh Dev loss: 0.7117 r:0.4643
ro_en Dev loss: 0.3224 r:0.8174
et_en Dev loss: 0.3719 r:0.7054
si_en Dev loss: 0.7033 r:0.6114
ne_en Dev loss: 0.4086 r:0.7563
ru_en Dev loss: 0.4080 r:0.7591
Current avg r:0.6231 Best avg r: 0.6263
18:58:10,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:52,132 root INFO 
id:ro_en cur r: 0.8236 best r: 0.8236
18:59:33,867 root INFO 
id:ne_en cur r: 0.7638 best r: 0.7638
18:59:47,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:25,403 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4523
en_de Dev loss: 0.8394 r:0.2324
en_zh Dev loss: 0.6718 r:0.4583
ro_en Dev loss: 0.2976 r:0.8206
et_en Dev loss: 0.3925 r:0.7128
si_en Dev loss: 0.5418 r:0.6239
ne_en Dev loss: 0.3356 r:0.7619
ru_en Dev loss: 0.3967 r:0.7431
Current avg r:0.6219 Best avg r: 0.6263
19:06:06,190 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:43,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:21,23 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4320
en_de Dev loss: 0.8600 r:0.2351
en_zh Dev loss: 0.7481 r:0.4539
ro_en Dev loss: 0.3395 r:0.8171
et_en Dev loss: 0.3859 r:0.6982
si_en Dev loss: 0.7293 r:0.6013
ne_en Dev loss: 0.4470 r:0.7515
ru_en Dev loss: 0.4844 r:0.7275
Current avg r:0.6121 Best avg r: 0.6263
19:14:02,893 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:40,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:17,400 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4180
en_de Dev loss: 0.8639 r:0.2555
en_zh Dev loss: 0.7649 r:0.4527
ro_en Dev loss: 0.3663 r:0.8132
et_en Dev loss: 0.3979 r:0.7005
si_en Dev loss: 0.7096 r:0.6118
ne_en Dev loss: 0.4023 r:0.7518
ru_en Dev loss: 0.5069 r:0.7320
Current avg r:0.6168 Best avg r: 0.6263
19:21:57,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:11,733 root INFO 
id:en_de cur r: 0.2765 best r: 0.2765
19:23:35,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:12,302 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4333
en_de Dev loss: 0.8373 r:0.2725
en_zh Dev loss: 0.7468 r:0.4455
ro_en Dev loss: 0.3287 r:0.8153
et_en Dev loss: 0.3849 r:0.7047
si_en Dev loss: 0.6296 r:0.6208
ne_en Dev loss: 0.3703 r:0.7515
ru_en Dev loss: 0.4239 r:0.7456
Current avg r:0.6223 Best avg r: 0.6263
19:29:53,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:31:30,830 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:08,561 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4199
en_de Dev loss: 0.8408 r:0.2523
en_zh Dev loss: 0.7508 r:0.4634
ro_en Dev loss: 0.3731 r:0.8187
et_en Dev loss: 0.4042 r:0.7008
si_en Dev loss: 0.6848 r:0.6227
ne_en Dev loss: 0.4414 r:0.7515
ru_en Dev loss: 0.4568 r:0.7426
Current avg r:0.6217 Best avg r: 0.6263
19:37:50,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:38:04,602 root INFO 
id:en_de cur r: 0.2841 best r: 0.2841
19:39:28,555 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:06,594 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4109
en_de Dev loss: 0.8385 r:0.2658
en_zh Dev loss: 0.7532 r:0.4578
ro_en Dev loss: 0.3236 r:0.8212
et_en Dev loss: 0.3888 r:0.6931
si_en Dev loss: 0.7838 r:0.6064
ne_en Dev loss: 0.5431 r:0.7459
ru_en Dev loss: 0.5078 r:0.7159
Current avg r:0.6151 Best avg r: 0.6263
19:45:49,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:27,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:05,174 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4021
en_de Dev loss: 0.8525 r:0.2665
en_zh Dev loss: 0.8174 r:0.4369
ro_en Dev loss: 0.3581 r:0.8143
et_en Dev loss: 0.3958 r:0.6890
si_en Dev loss: 0.7446 r:0.6096
ne_en Dev loss: 0.4938 r:0.7512
ru_en Dev loss: 0.5033 r:0.7139
Current avg r:0.6116 Best avg r: 0.6263
19:53:48,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:12,440 root INFO 
id:ne_en cur r: 0.7645 best r: 0.7645
19:55:26,402 root INFO 
id:ru_en cur r: 0.7548 best r: 0.7548
19:55:26,402 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:04,110 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_de.lang_agnost_mlp.dev.best.scores
19:57:04,117 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/en_zh.lang_agnost_mlp.dev.best.scores
19:57:04,121 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ro_en.lang_agnost_mlp.dev.best.scores
19:57:04,126 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/et_en.lang_agnost_mlp.dev.best.scores
19:57:04,130 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/si_en.lang_agnost_mlp.dev.best.scores
19:57:04,135 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ne_en.lang_agnost_mlp.dev.best.scores
19:57:04,140 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run1/ru_en.lang_agnost_mlp.dev.best.scores
19:57:17,985 root INFO Epoch 3 Global steps: 28000 Train loss: 0.4484
en_de Dev loss: 0.8387 r:0.2716
en_zh Dev loss: 0.7453 r:0.4593
ro_en Dev loss: 0.3383 r:0.8211
et_en Dev loss: 0.3916 r:0.7017
si_en Dev loss: 0.6533 r:0.6226
ne_en Dev loss: 0.4286 r:0.7581
ru_en Dev loss: 0.4283 r:0.7503
Current avg r:0.6264 Best avg r: 0.6264
20:02:01,432 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:15,399 root INFO 
id:en_de cur r: 0.2896 best r: 0.2896
20:02:43,399 root INFO 
id:ro_en cur r: 0.8262 best r: 0.8262
20:03:39,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:17,525 root INFO Epoch 3 Global steps: 28700 Train loss: 0.4254
en_de Dev loss: 0.8227 r:0.2765
en_zh Dev loss: 0.7259 r:0.4522
ro_en Dev loss: 0.3050 r:0.8245
et_en Dev loss: 0.3926 r:0.6972
si_en Dev loss: 0.6584 r:0.6192
ne_en Dev loss: 0.4151 r:0.7582
ru_en Dev loss: 0.4415 r:0.7381
Current avg r:0.6237 Best avg r: 0.6264
20:10:01,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:39,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:17,557 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4084
en_de Dev loss: 0.8564 r:0.2747
en_zh Dev loss: 0.8019 r:0.4477
ro_en Dev loss: 0.3844 r:0.8169
et_en Dev loss: 0.4304 r:0.6964
si_en Dev loss: 0.8046 r:0.6118
ne_en Dev loss: 0.5735 r:0.7519
ru_en Dev loss: 0.5449 r:0.7202
Current avg r:0.6171 Best avg r: 0.6264
20:18:01,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:39,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:16,662 root INFO Epoch 3 Global steps: 30100 Train loss: 0.4196
en_de Dev loss: 0.8617 r:0.2494
en_zh Dev loss: 0.7661 r:0.4544
ro_en Dev loss: 0.3364 r:0.8200
et_en Dev loss: 0.4143 r:0.6883
si_en Dev loss: 0.7766 r:0.6107
ne_en Dev loss: 0.4968 r:0.7519
ru_en Dev loss: 0.5022 r:0.7256
Current avg r:0.6143 Best avg r: 0.6264
20:26:01,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:26:29,30 root INFO 
id:en_zh cur r: 0.4709 best r: 0.4709
20:27:39,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:16,735 root INFO Epoch 3 Global steps: 30800 Train loss: 0.4247
en_de Dev loss: 0.8545 r:0.2214
en_zh Dev loss: 0.7225 r:0.4606
ro_en Dev loss: 0.3139 r:0.8207
et_en Dev loss: 0.4147 r:0.6890
si_en Dev loss: 0.6767 r:0.6098
ne_en Dev loss: 0.4015 r:0.7506
ru_en Dev loss: 0.4352 r:0.7367
Current avg r:0.6127 Best avg r: 0.6264
20:34:01,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:39,858 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:17,744 root INFO Epoch 3 Global steps: 31500 Train loss: 0.3971
en_de Dev loss: 0.8336 r:0.2602
en_zh Dev loss: 0.6927 r:0.4603
ro_en Dev loss: 0.3050 r:0.8246
et_en Dev loss: 0.4148 r:0.6990
si_en Dev loss: 0.5815 r:0.6201
ne_en Dev loss: 0.3672 r:0.7552
ru_en Dev loss: 0.4284 r:0.7353
Current avg r:0.6221 Best avg r: 0.6264
20:42:04,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:32,855 root INFO 
id:en_zh cur r: 0.4723 best r: 0.4723
20:43:43,369 root INFO 
id:ru_en cur r: 0.7675 best r: 0.7675
20:43:43,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:45:21,516 root INFO Epoch 4 Global steps: 32200 Train loss: 0.3934
en_de Dev loss: 0.8316 r:0.2516
en_zh Dev loss: 0.6865 r:0.4643
ro_en Dev loss: 0.3160 r:0.8224
et_en Dev loss: 0.4020 r:0.6922
si_en Dev loss: 0.6791 r:0.6115
ne_en Dev loss: 0.4198 r:0.7546
ru_en Dev loss: 0.3739 r:0.7620
Current avg r:0.6227 Best avg r: 0.6264
20:50:08,66 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:51:46,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:24,906 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3744
en_de Dev loss: 0.8261 r:0.2628
en_zh Dev loss: 0.7422 r:0.4467
ro_en Dev loss: 0.3371 r:0.8151
et_en Dev loss: 0.4366 r:0.6838
si_en Dev loss: 0.7255 r:0.5995
ne_en Dev loss: 0.4459 r:0.7444
ru_en Dev loss: 0.4693 r:0.7212
Current avg r:0.6105 Best avg r: 0.6264
20:58:11,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:50,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:29,166 root INFO Epoch 4 Global steps: 33600 Train loss: 0.4095
en_de Dev loss: 0.8448 r:0.2806
en_zh Dev loss: 0.7708 r:0.4453
ro_en Dev loss: 0.3183 r:0.8202
et_en Dev loss: 0.4151 r:0.6826
si_en Dev loss: 0.7666 r:0.5938
ne_en Dev loss: 0.4044 r:0.7525
ru_en Dev loss: 0.5059 r:0.7108
Current avg r:0.6123 Best avg r: 0.6264
21:06:16,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:56,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:35,218 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3732
en_de Dev loss: 0.8695 r:0.2659
en_zh Dev loss: 0.8222 r:0.4508
ro_en Dev loss: 0.3596 r:0.8225
et_en Dev loss: 0.4171 r:0.6860
si_en Dev loss: 0.8136 r:0.6029
ne_en Dev loss: 0.4959 r:0.7519
ru_en Dev loss: 0.5727 r:0.7099
Current avg r:0.6128 Best avg r: 0.6264
21:14:23,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:02,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:41,688 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3800
en_de Dev loss: 0.8557 r:0.2730
en_zh Dev loss: 0.7895 r:0.4440
ro_en Dev loss: 0.3314 r:0.8194
et_en Dev loss: 0.4220 r:0.6843
si_en Dev loss: 0.7040 r:0.6005
ne_en Dev loss: 0.3810 r:0.7502
ru_en Dev loss: 0.4972 r:0.7175
Current avg r:0.6127 Best avg r: 0.6264
21:22:29,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:08,185 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:25:47,479 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3552
en_de Dev loss: 0.8791 r:0.2583
en_zh Dev loss: 0.8538 r:0.4287
ro_en Dev loss: 0.3784 r:0.8214
et_en Dev loss: 0.4305 r:0.6920
si_en Dev loss: 0.8105 r:0.6062
ne_en Dev loss: 0.4349 r:0.7506
ru_en Dev loss: 0.5452 r:0.7175
Current avg r:0.6107 Best avg r: 0.6264
21:30:34,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:13,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:53,570 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3644
en_de Dev loss: 0.8399 r:0.2586
en_zh Dev loss: 0.7826 r:0.4311
ro_en Dev loss: 0.3327 r:0.8234
et_en Dev loss: 0.4159 r:0.6972
si_en Dev loss: 0.7120 r:0.6063
ne_en Dev loss: 0.4074 r:0.7532
ru_en Dev loss: 0.4424 r:0.7353
Current avg r:0.6150 Best avg r: 0.6264
21:38:40,712 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:19,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:59,185 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3581
en_de Dev loss: 0.8362 r:0.2675
en_zh Dev loss: 0.7691 r:0.4305
ro_en Dev loss: 0.3138 r:0.8240
et_en Dev loss: 0.4180 r:0.6874
si_en Dev loss: 0.6912 r:0.6072
ne_en Dev loss: 0.3812 r:0.7531
ru_en Dev loss: 0.4457 r:0.7304
Current avg r:0.6143 Best avg r: 0.6264
21:46:46,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:25,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:50:05,98 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3687
en_de Dev loss: 0.8672 r:0.2582
en_zh Dev loss: 0.7541 r:0.4415
ro_en Dev loss: 0.3287 r:0.8236
et_en Dev loss: 0.4137 r:0.6824
si_en Dev loss: 0.7465 r:0.6078
ne_en Dev loss: 0.4735 r:0.7553
ru_en Dev loss: 0.4375 r:0.7412
Current avg r:0.6157 Best avg r: 0.6264
21:54:51,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:56:30,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:10,125 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3869
en_de Dev loss: 0.8627 r:0.2650
en_zh Dev loss: 0.8309 r:0.4093
ro_en Dev loss: 0.3501 r:0.8205
et_en Dev loss: 0.4270 r:0.6714
si_en Dev loss: 0.8370 r:0.5954
ne_en Dev loss: 0.5380 r:0.7433
ru_en Dev loss: 0.5021 r:0.7155
Current avg r:0.6029 Best avg r: 0.6264
22:02:55,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:34,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:14,362 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3551
en_de Dev loss: 0.8762 r:0.2486
en_zh Dev loss: 0.7733 r:0.4450
ro_en Dev loss: 0.3533 r:0.8234
et_en Dev loss: 0.4446 r:0.6824
si_en Dev loss: 0.7024 r:0.6193
ne_en Dev loss: 0.4168 r:0.7501
ru_en Dev loss: 0.4733 r:0.7459
Current avg r:0.6164 Best avg r: 0.6264
22:11:00,707 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:39,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:19,622 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3781
en_de Dev loss: 0.8818 r:0.2525
en_zh Dev loss: 0.7958 r:0.4347
ro_en Dev loss: 0.3550 r:0.8187
et_en Dev loss: 0.4582 r:0.6652
si_en Dev loss: 0.8317 r:0.5950
ne_en Dev loss: 0.5529 r:0.7389
ru_en Dev loss: 0.5348 r:0.7100
Current avg r:0.6021 Best avg r: 0.6264
22:19:05,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:44,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:23,637 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3336
en_de Dev loss: 0.8664 r:0.2559
en_zh Dev loss: 0.7761 r:0.4390
ro_en Dev loss: 0.3546 r:0.8170
et_en Dev loss: 0.4385 r:0.6691
si_en Dev loss: 0.8388 r:0.5992
ne_en Dev loss: 0.5614 r:0.7430
ru_en Dev loss: 0.5175 r:0.7152
Current avg r:0.6055 Best avg r: 0.6264
22:27:09,155 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:48,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:27,964 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3061
en_de Dev loss: 0.8884 r:0.2500
en_zh Dev loss: 0.8255 r:0.4085
ro_en Dev loss: 0.3527 r:0.8132
et_en Dev loss: 0.4650 r:0.6682
si_en Dev loss: 0.7460 r:0.6009
ne_en Dev loss: 0.4827 r:0.7416
ru_en Dev loss: 0.4619 r:0.7357
Current avg r:0.6026 Best avg r: 0.6264
22:35:14,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:54,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:33,171 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3193
en_de Dev loss: 0.8810 r:0.2450
en_zh Dev loss: 0.8348 r:0.4206
ro_en Dev loss: 0.3646 r:0.8150
et_en Dev loss: 0.4612 r:0.6649
si_en Dev loss: 0.8843 r:0.5923
ne_en Dev loss: 0.5381 r:0.7404
ru_en Dev loss: 0.5875 r:0.6952
Current avg r:0.5962 Best avg r: 0.6264
22:43:19,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:58,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:37,878 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3259
en_de Dev loss: 0.8721 r:0.2353
en_zh Dev loss: 0.8079 r:0.4241
ro_en Dev loss: 0.3369 r:0.8193
et_en Dev loss: 0.4475 r:0.6705
si_en Dev loss: 0.7872 r:0.6017
ne_en Dev loss: 0.4974 r:0.7430
ru_en Dev loss: 0.5040 r:0.7199
Current avg r:0.6020 Best avg r: 0.6264
22:51:24,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:03,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:54:42,509 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3410
en_de Dev loss: 0.8349 r:0.2772
en_zh Dev loss: 0.8164 r:0.4338
ro_en Dev loss: 0.3461 r:0.8205
et_en Dev loss: 0.4512 r:0.6726
si_en Dev loss: 0.8390 r:0.6017
ne_en Dev loss: 0.4749 r:0.7441
ru_en Dev loss: 0.4607 r:0.7358
Current avg r:0.6123 Best avg r: 0.6264
22:59:28,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:07,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:02:45,820 root INFO Epoch 5 Global steps: 44100 Train loss: 0.3319
en_de Dev loss: 0.8660 r:0.2761
en_zh Dev loss: 0.8696 r:0.4296
ro_en Dev loss: 0.3856 r:0.8218
et_en Dev loss: 0.4677 r:0.6721
si_en Dev loss: 0.8802 r:0.6026
ne_en Dev loss: 0.5703 r:0.7426
ru_en Dev loss: 0.5332 r:0.7243
Current avg r:0.6099 Best avg r: 0.6264
23:07:32,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:09:11,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:49,527 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3358
en_de Dev loss: 0.8890 r:0.2425
en_zh Dev loss: 0.8910 r:0.4105
ro_en Dev loss: 0.3676 r:0.8200
et_en Dev loss: 0.4461 r:0.6667
si_en Dev loss: 0.8622 r:0.6012
ne_en Dev loss: 0.5409 r:0.7424
ru_en Dev loss: 0.5286 r:0.7151
Current avg r:0.5998 Best avg r: 0.6264
23:15:35,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:14,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:52,12 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3221
en_de Dev loss: 0.8491 r:0.2705
en_zh Dev loss: 0.8173 r:0.4346
ro_en Dev loss: 0.3384 r:0.8245
et_en Dev loss: 0.4667 r:0.6679
si_en Dev loss: 0.7738 r:0.6048
ne_en Dev loss: 0.4437 r:0.7407
ru_en Dev loss: 0.4877 r:0.7251
Current avg r:0.6097 Best avg r: 0.6264
23:23:37,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:15,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:52,648 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3215
en_de Dev loss: 0.8667 r:0.2653
en_zh Dev loss: 0.8303 r:0.4235
ro_en Dev loss: 0.3479 r:0.8229
et_en Dev loss: 0.4588 r:0.6620
si_en Dev loss: 0.8157 r:0.5924
ne_en Dev loss: 0.5067 r:0.7438
ru_en Dev loss: 0.4939 r:0.7193
Current avg r:0.6042 Best avg r: 0.6264
23:31:37,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:15,247 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:34:52,945 root INFO Epoch 5 Global steps: 46900 Train loss: 0.3259
en_de Dev loss: 0.8521 r:0.2728
en_zh Dev loss: 0.8455 r:0.4293
ro_en Dev loss: 0.3722 r:0.8251
et_en Dev loss: 0.4676 r:0.6614
si_en Dev loss: 0.8127 r:0.5930
ne_en Dev loss: 0.4952 r:0.7463
ru_en Dev loss: 0.5390 r:0.7105
Current avg r:0.6055 Best avg r: 0.6264
23:39:38,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:20,384 root INFO 
id:ro_en cur r: 0.8276 best r: 0.8276
23:41:16,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:54,133 root INFO Epoch 5 Global steps: 47600 Train loss: 0.3075
en_de Dev loss: 0.8401 r:0.2821
en_zh Dev loss: 0.8403 r:0.4237
ro_en Dev loss: 0.3464 r:0.8270
et_en Dev loss: 0.4687 r:0.6716
si_en Dev loss: 0.7464 r:0.5983
ne_en Dev loss: 0.4389 r:0.7459
ru_en Dev loss: 0.4594 r:0.7364
Current avg r:0.6121 Best avg r: 0.6264
23:47:40,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:22,318 root INFO 
id:ro_en cur r: 0.8293 best r: 0.8293
23:49:18,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:56,113 root INFO Epoch 6 Global steps: 48300 Train loss: 0.2644
en_de Dev loss: 0.8242 r:0.2877
en_zh Dev loss: 0.7711 r:0.4346
ro_en Dev loss: 0.3193 r:0.8289
et_en Dev loss: 0.4685 r:0.6733
si_en Dev loss: 0.6949 r:0.6018
ne_en Dev loss: 0.4377 r:0.7436
ru_en Dev loss: 0.4591 r:0.7225
Current avg r:0.6132 Best avg r: 0.6264
23:55:41,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:57:19,438 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:57,510 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2813
en_de Dev loss: 0.8271 r:0.2728
en_zh Dev loss: 0.7861 r:0.4425
ro_en Dev loss: 0.3253 r:0.8317
et_en Dev loss: 0.4753 r:0.6794
si_en Dev loss: 0.7012 r:0.6053
ne_en Dev loss: 0.4346 r:0.7456
ru_en Dev loss: 0.4399 r:0.7397
Current avg r:0.6167 Best avg r: 0.6264
00:03:42,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:20,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:06:58,754 root INFO Epoch 6 Global steps: 49700 Train loss: 0.2804
en_de Dev loss: 0.8437 r:0.2724
en_zh Dev loss: 0.7967 r:0.4445
ro_en Dev loss: 0.3387 r:0.8251
et_en Dev loss: 0.4685 r:0.6639
si_en Dev loss: 0.7908 r:0.5917
ne_en Dev loss: 0.4734 r:0.7438
ru_en Dev loss: 0.4768 r:0.7286
Current avg r:0.6100 Best avg r: 0.6264
00:11:43,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:21,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:59,341 root INFO Epoch 6 Global steps: 50400 Train loss: 0.2825
en_de Dev loss: 0.8392 r:0.2740
en_zh Dev loss: 0.7599 r:0.4501
ro_en Dev loss: 0.3604 r:0.8210
et_en Dev loss: 0.4591 r:0.6600
si_en Dev loss: 0.9068 r:0.5852
ne_en Dev loss: 0.5776 r:0.7421
ru_en Dev loss: 0.4856 r:0.7252
Current avg r:0.6082 Best avg r: 0.6264
00:19:43,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:21:21,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:00,461 root INFO Epoch 6 Global steps: 51100 Train loss: 0.2901
en_de Dev loss: 0.8793 r:0.2504
en_zh Dev loss: 0.8574 r:0.4264
ro_en Dev loss: 0.3856 r:0.8206
et_en Dev loss: 0.4575 r:0.6616
si_en Dev loss: 0.9654 r:0.5790
ne_en Dev loss: 0.6330 r:0.7472
ru_en Dev loss: 0.5146 r:0.7223
Current avg r:0.6011 Best avg r: 0.6264
00:27:44,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:22,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:31:01,173 root INFO Epoch 6 Global steps: 51800 Train loss: 0.2737
en_de Dev loss: 0.8520 r:0.2313
en_zh Dev loss: 0.7681 r:0.4337
ro_en Dev loss: 0.3032 r:0.8264
et_en Dev loss: 0.4651 r:0.6704
si_en Dev loss: 0.7237 r:0.5835
ne_en Dev loss: 0.4067 r:0.7492
ru_en Dev loss: 0.4315 r:0.7315
Current avg r:0.6037 Best avg r: 0.6264
00:35:45,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:37:23,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:01,933 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2917
en_de Dev loss: 0.8976 r:0.2561
en_zh Dev loss: 0.9131 r:0.4402
ro_en Dev loss: 0.4546 r:0.8160
et_en Dev loss: 0.5449 r:0.6604
si_en Dev loss: 0.9949 r:0.5749
ne_en Dev loss: 0.6039 r:0.7442
ru_en Dev loss: 0.6027 r:0.7157
Current avg r:0.6011 Best avg r: 0.6264
00:43:45,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:23,716 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:02,546 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2786
en_de Dev loss: 0.8575 r:0.2685
en_zh Dev loss: 0.8028 r:0.4616
ro_en Dev loss: 0.3949 r:0.8231
et_en Dev loss: 0.4545 r:0.6722
si_en Dev loss: 0.8857 r:0.5917
ne_en Dev loss: 0.5456 r:0.7487
ru_en Dev loss: 0.4857 r:0.7441
Current avg r:0.6157 Best avg r: 0.6264
00:51:46,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:24,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:03,521 root INFO Epoch 6 Global steps: 53900 Train loss: 0.2839
en_de Dev loss: 0.8309 r:0.2774
en_zh Dev loss: 0.8002 r:0.4429
ro_en Dev loss: 0.3418 r:0.8195
et_en Dev loss: 0.4672 r:0.6597
si_en Dev loss: 0.8505 r:0.5738
ne_en Dev loss: 0.5112 r:0.7426
ru_en Dev loss: 0.4695 r:0.7279
Current avg r:0.6063 Best avg r: 0.6264
00:59:46,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:01:25,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:03,758 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2662
en_de Dev loss: 0.8822 r:0.2595
en_zh Dev loss: 0.8681 r:0.4339
ro_en Dev loss: 0.3564 r:0.8219
et_en Dev loss: 0.4892 r:0.6713
si_en Dev loss: 0.7957 r:0.5902
ne_en Dev loss: 0.4522 r:0.7433
ru_en Dev loss: 0.5133 r:0.7216
Current avg r:0.6060 Best avg r: 0.6264
01:07:46,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:24,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:03,453 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2757
en_de Dev loss: 0.8703 r:0.2480
en_zh Dev loss: 0.8165 r:0.4337
ro_en Dev loss: 0.3328 r:0.8230
et_en Dev loss: 0.4438 r:0.6715
si_en Dev loss: 0.8099 r:0.5816
ne_en Dev loss: 0.4508 r:0.7451
ru_en Dev loss: 0.4699 r:0.7281
Current avg r:0.6044 Best avg r: 0.6264
01:15:47,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:26,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:04,986 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2578
en_de Dev loss: 0.8484 r:0.2454
en_zh Dev loss: 0.8176 r:0.4296
ro_en Dev loss: 0.3423 r:0.8180
et_en Dev loss: 0.4581 r:0.6625
si_en Dev loss: 0.8983 r:0.5690
ne_en Dev loss: 0.5149 r:0.7380
ru_en Dev loss: 0.4905 r:0.7123
Current avg r:0.5964 Best avg r: 0.6264
01:23:48,558 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:27,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:27:05,459 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2515
en_de Dev loss: 0.8708 r:0.2399
en_zh Dev loss: 0.8338 r:0.4353
ro_en Dev loss: 0.3594 r:0.8197
et_en Dev loss: 0.4870 r:0.6614
si_en Dev loss: 0.7727 r:0.5864
ne_en Dev loss: 0.4875 r:0.7372
ru_en Dev loss: 0.5011 r:0.7225
Current avg r:0.6003 Best avg r: 0.6264
01:31:48,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:33:27,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:35:05,114 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2310
en_de Dev loss: 0.8853 r:0.2435
en_zh Dev loss: 0.8598 r:0.4347
ro_en Dev loss: 0.3712 r:0.8206
et_en Dev loss: 0.4713 r:0.6619
si_en Dev loss: 0.8342 r:0.5873
ne_en Dev loss: 0.5324 r:0.7405
ru_en Dev loss: 0.5234 r:0.7189
Current avg r:0.6011 Best avg r: 0.6264
01:39:48,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:41:27,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:04,926 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2477
en_de Dev loss: 0.8890 r:0.2192
en_zh Dev loss: 0.8777 r:0.4210
ro_en Dev loss: 0.3586 r:0.8193
et_en Dev loss: 0.4910 r:0.6595
si_en Dev loss: 0.8467 r:0.5816
ne_en Dev loss: 0.5033 r:0.7414
ru_en Dev loss: 0.5019 r:0.7181
Current avg r:0.5943 Best avg r: 0.6264
01:47:48,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:49:26,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:04,742 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2498
en_de Dev loss: 0.8489 r:0.2442
en_zh Dev loss: 0.7801 r:0.4407
ro_en Dev loss: 0.3378 r:0.8225
et_en Dev loss: 0.4887 r:0.6650
si_en Dev loss: 0.7747 r:0.5858
ne_en Dev loss: 0.4444 r:0.7444
ru_en Dev loss: 0.4373 r:0.7335
Current avg r:0.6051 Best avg r: 0.6264
01:55:49,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:27,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:05,451 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2414
en_de Dev loss: 0.8978 r:0.2329
en_zh Dev loss: 0.8204 r:0.4359
ro_en Dev loss: 0.3599 r:0.8242
et_en Dev loss: 0.4678 r:0.6639
si_en Dev loss: 0.8184 r:0.5887
ne_en Dev loss: 0.4633 r:0.7418
ru_en Dev loss: 0.4647 r:0.7385
Current avg r:0.6037 Best avg r: 0.6264
02:03:50,831 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:29,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:07,405 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2599
en_de Dev loss: 0.8718 r:0.2194
en_zh Dev loss: 0.7790 r:0.4335
ro_en Dev loss: 0.3242 r:0.8258
et_en Dev loss: 0.4695 r:0.6629
si_en Dev loss: 0.7270 r:0.5882
ne_en Dev loss: 0.4407 r:0.7453
ru_en Dev loss: 0.4287 r:0.7364
Current avg r:0.6016 Best avg r: 0.6264
02:11:52,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:30,754 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:15:08,542 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2457
en_de Dev loss: 0.8985 r:0.2226
en_zh Dev loss: 0.8722 r:0.4243
ro_en Dev loss: 0.3707 r:0.8223
et_en Dev loss: 0.4900 r:0.6531
si_en Dev loss: 0.8379 r:0.5710
ne_en Dev loss: 0.5373 r:0.7331
ru_en Dev loss: 0.5007 r:0.7259
Current avg r:0.5932 Best avg r: 0.6264
02:19:53,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:31,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:23:09,605 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2437
en_de Dev loss: 0.8932 r:0.2215
en_zh Dev loss: 0.8871 r:0.4198
ro_en Dev loss: 0.3793 r:0.8220
et_en Dev loss: 0.4706 r:0.6602
si_en Dev loss: 0.8747 r:0.5775
ne_en Dev loss: 0.5713 r:0.7365
ru_en Dev loss: 0.5346 r:0.7162
Current avg r:0.5934 Best avg r: 0.6264
02:27:54,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:31,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:31:09,300 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2403
en_de Dev loss: 0.8831 r:0.2301
en_zh Dev loss: 0.8515 r:0.4183
ro_en Dev loss: 0.3412 r:0.8219
et_en Dev loss: 0.4617 r:0.6550
si_en Dev loss: 0.8349 r:0.5714
ne_en Dev loss: 0.5305 r:0.7356
ru_en Dev loss: 0.4970 r:0.7207
Current avg r:0.5933 Best avg r: 0.6264
02:35:53,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:31,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:39:08,645 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2557
en_de Dev loss: 0.8993 r:0.2078
en_zh Dev loss: 0.8631 r:0.4316
ro_en Dev loss: 0.3733 r:0.8225
et_en Dev loss: 0.5147 r:0.6552
si_en Dev loss: 0.8532 r:0.5747
ne_en Dev loss: 0.5157 r:0.7401
ru_en Dev loss: 0.4956 r:0.7214
Current avg r:0.5933 Best avg r: 0.6264
02:43:54,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:45:31,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:47:08,934 root INFO Epoch 8 Global steps: 63700 Train loss: 0.2124
en_de Dev loss: 0.8981 r:0.2074
en_zh Dev loss: 0.8153 r:0.4442
ro_en Dev loss: 0.3462 r:0.8244
et_en Dev loss: 0.4886 r:0.6613
si_en Dev loss: 0.9063 r:0.5709
ne_en Dev loss: 0.5536 r:0.7296
ru_en Dev loss: 0.4923 r:0.7282
Current avg r:0.5951 Best avg r: 0.6264
02:51:54,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:53:31,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:55:09,19 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2300
en_de Dev loss: 0.9125 r:0.2016
en_zh Dev loss: 0.8891 r:0.4211
ro_en Dev loss: 0.3802 r:0.8144
et_en Dev loss: 0.5016 r:0.6469
si_en Dev loss: 0.8878 r:0.5603
ne_en Dev loss: 0.5695 r:0.7285
ru_en Dev loss: 0.5167 r:0.7143
Current avg r:0.5839 Best avg r: 0.6264
02:59:53,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:01:31,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:09,265 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2274
en_de Dev loss: 0.8871 r:0.2196
en_zh Dev loss: 0.7998 r:0.4519
ro_en Dev loss: 0.3499 r:0.8212
et_en Dev loss: 0.4670 r:0.6575
si_en Dev loss: 0.9341 r:0.5657
ne_en Dev loss: 0.5510 r:0.7329
ru_en Dev loss: 0.4667 r:0.7358
Current avg r:0.5978 Best avg r: 0.6264
03:07:54,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:31,790 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:09,899 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2068
en_de Dev loss: 0.8792 r:0.2171
en_zh Dev loss: 0.7799 r:0.4558
ro_en Dev loss: 0.3593 r:0.8208
et_en Dev loss: 0.4884 r:0.6622
si_en Dev loss: 0.8910 r:0.5738
ne_en Dev loss: 0.5450 r:0.7295
ru_en Dev loss: 0.4498 r:0.7406
Current avg r:0.6000 Best avg r: 0.6264
03:15:54,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:17:32,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:10,778 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2179
en_de Dev loss: 0.8842 r:0.2104
en_zh Dev loss: 0.8039 r:0.4336
ro_en Dev loss: 0.3398 r:0.8224
et_en Dev loss: 0.4726 r:0.6502
si_en Dev loss: 0.8803 r:0.5691
ne_en Dev loss: 0.5672 r:0.7284
ru_en Dev loss: 0.5015 r:0.7141
Current avg r:0.5898 Best avg r: 0.6264
03:23:55,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:25:33,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:27:11,996 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2262
en_de Dev loss: 0.9112 r:0.2079
en_zh Dev loss: 0.8226 r:0.4508
ro_en Dev loss: 0.3635 r:0.8222
et_en Dev loss: 0.5040 r:0.6534
si_en Dev loss: 0.9018 r:0.5676
ne_en Dev loss: 0.5264 r:0.7227
ru_en Dev loss: 0.4967 r:0.7269
Current avg r:0.5931 Best avg r: 0.6264
03:31:56,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:33:34,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:35:13,186 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2191
en_de Dev loss: 0.8631 r:0.2184
en_zh Dev loss: 0.7654 r:0.4419
ro_en Dev loss: 0.3093 r:0.8232
et_en Dev loss: 0.4658 r:0.6597
si_en Dev loss: 0.8224 r:0.5650
ne_en Dev loss: 0.4958 r:0.7255
ru_en Dev loss: 0.4342 r:0.7339
Current avg r:0.5954 Best avg r: 0.6264
03:39:57,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:41:36,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:43:14,908 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2055
en_de Dev loss: 0.9042 r:0.2168
en_zh Dev loss: 0.8849 r:0.4320
ro_en Dev loss: 0.3790 r:0.8196
et_en Dev loss: 0.5045 r:0.6534
si_en Dev loss: 0.9648 r:0.5568
ne_en Dev loss: 0.5745 r:0.7243
ru_en Dev loss: 0.4958 r:0.7318
Current avg r:0.5907 Best avg r: 0.6264
03:47:59,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:49:37,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:51:16,701 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2135
en_de Dev loss: 0.9191 r:0.2125
en_zh Dev loss: 0.8641 r:0.4409
ro_en Dev loss: 0.3587 r:0.8220
et_en Dev loss: 0.4811 r:0.6658
si_en Dev loss: 0.8662 r:0.5700
ne_en Dev loss: 0.4940 r:0.7278
ru_en Dev loss: 0.4742 r:0.7395
Current avg r:0.5969 Best avg r: 0.6264
03:56:00,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:39,562 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:59:18,359 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2217
en_de Dev loss: 0.9041 r:0.2141
en_zh Dev loss: 0.8298 r:0.4408
ro_en Dev loss: 0.3606 r:0.8219
et_en Dev loss: 0.4771 r:0.6580
si_en Dev loss: 0.8958 r:0.5638
ne_en Dev loss: 0.5785 r:0.7220
ru_en Dev loss: 0.5573 r:0.6991
Current avg r:0.5885 Best avg r: 0.6264
04:04:01,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:05:40,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:07:19,18 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2178
en_de Dev loss: 0.8968 r:0.1999
en_zh Dev loss: 0.8545 r:0.4362
ro_en Dev loss: 0.3559 r:0.8254
et_en Dev loss: 0.5047 r:0.6582
si_en Dev loss: 0.9152 r:0.5689
ne_en Dev loss: 0.5007 r:0.7261
ru_en Dev loss: 0.4594 r:0.7385
Current avg r:0.5933 Best avg r: 0.6264
04:12:01,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:13:40,148 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:18,643 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2186
en_de Dev loss: 0.9183 r:0.1967
en_zh Dev loss: 0.9089 r:0.4296
ro_en Dev loss: 0.3830 r:0.8203
et_en Dev loss: 0.5125 r:0.6491
si_en Dev loss: 0.9404 r:0.5639
ne_en Dev loss: 0.5622 r:0.7288
ru_en Dev loss: 0.5042 r:0.7339
Current avg r:0.5889 Best avg r: 0.6264
04:20:02,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:41,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:19,505 root INFO Epoch 9 Global steps: 72100 Train loss: 0.2000
en_de Dev loss: 0.9106 r:0.2051
en_zh Dev loss: 0.8766 r:0.4326
ro_en Dev loss: 0.3775 r:0.8180
et_en Dev loss: 0.5105 r:0.6453
si_en Dev loss: 0.9620 r:0.5548
ne_en Dev loss: 0.5444 r:0.7239
ru_en Dev loss: 0.5309 r:0.7194
Current avg r:0.5856 Best avg r: 0.6264
04:28:02,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:40,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:18,706 root INFO Epoch 9 Global steps: 72800 Train loss: 0.2062
en_de Dev loss: 0.9055 r:0.2073
en_zh Dev loss: 0.8325 r:0.4378
ro_en Dev loss: 0.3510 r:0.8206
et_en Dev loss: 0.4903 r:0.6563
si_en Dev loss: 0.8516 r:0.5619
ne_en Dev loss: 0.4833 r:0.7298
ru_en Dev loss: 0.4961 r:0.7179
Current avg r:0.5902 Best avg r: 0.6264
04:36:01,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:37:40,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:39:18,397 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1901
en_de Dev loss: 0.9072 r:0.1899
en_zh Dev loss: 0.8140 r:0.4359
ro_en Dev loss: 0.3404 r:0.8246
et_en Dev loss: 0.4862 r:0.6626
si_en Dev loss: 0.7987 r:0.5718
ne_en Dev loss: 0.4532 r:0.7261
ru_en Dev loss: 0.4696 r:0.7307
Current avg r:0.5916 Best avg r: 0.6264
04:44:01,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:45:40,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:47:17,960 root INFO Epoch 9 Global steps: 74200 Train loss: 0.1996
en_de Dev loss: 0.8825 r:0.2114
en_zh Dev loss: 0.8022 r:0.4389
ro_en Dev loss: 0.3296 r:0.8204
et_en Dev loss: 0.4699 r:0.6678
si_en Dev loss: 0.8049 r:0.5702
ne_en Dev loss: 0.4542 r:0.7352
ru_en Dev loss: 0.4259 r:0.7433
Current avg r:0.5982 Best avg r: 0.6264
04:52:01,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:53:40,18 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:55:17,921 root INFO Epoch 9 Global steps: 74900 Train loss: 0.1970
en_de Dev loss: 0.9012 r:0.1844
en_zh Dev loss: 0.7957 r:0.4414
ro_en Dev loss: 0.3225 r:0.8215
et_en Dev loss: 0.5008 r:0.6599
si_en Dev loss: 0.7779 r:0.5707
ne_en Dev loss: 0.4367 r:0.7300
ru_en Dev loss: 0.4253 r:0.7381
Current avg r:0.5923 Best avg r: 0.6264
05:00:01,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:01:39,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:17,246 root INFO Epoch 9 Global steps: 75600 Train loss: 0.1907
en_de Dev loss: 0.9332 r:0.1862
en_zh Dev loss: 0.8553 r:0.4522
ro_en Dev loss: 0.3606 r:0.8213
et_en Dev loss: 0.5286 r:0.6554
si_en Dev loss: 0.7961 r:0.5722
ne_en Dev loss: 0.4728 r:0.7316
ru_en Dev loss: 0.4489 r:0.7386
Current avg r:0.5939 Best avg r: 0.6264
05:08:01,104 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:09:39,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:17,101 root INFO Epoch 9 Global steps: 76300 Train loss: 0.1910
en_de Dev loss: 0.9382 r:0.1821
en_zh Dev loss: 0.8392 r:0.4437
ro_en Dev loss: 0.3690 r:0.8199
et_en Dev loss: 0.4973 r:0.6484
si_en Dev loss: 0.9109 r:0.5597
ne_en Dev loss: 0.5655 r:0.7290
ru_en Dev loss: 0.4680 r:0.7375
Current avg r:0.5886 Best avg r: 0.6264
05:16:01,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:39,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:19:17,381 root INFO Epoch 9 Global steps: 77000 Train loss: 0.1891
en_de Dev loss: 0.9259 r:0.1946
en_zh Dev loss: 0.8462 r:0.4394
ro_en Dev loss: 0.3633 r:0.8161
et_en Dev loss: 0.4924 r:0.6487
si_en Dev loss: 0.8860 r:0.5510
ne_en Dev loss: 0.5418 r:0.7208
ru_en Dev loss: 0.5173 r:0.7143
Current avg r:0.5836 Best avg r: 0.6264
05:24:02,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:25:39,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:27:17,624 root INFO Epoch 9 Global steps: 77700 Train loss: 0.1910
en_de Dev loss: 0.9235 r:0.1684
en_zh Dev loss: 0.8661 r:0.4421
ro_en Dev loss: 0.3495 r:0.8245
et_en Dev loss: 0.4932 r:0.6560
si_en Dev loss: 0.9342 r:0.5613
ne_en Dev loss: 0.5895 r:0.7216
ru_en Dev loss: 0.4923 r:0.7281
Current avg r:0.5860 Best avg r: 0.6264
05:32:02,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:33:40,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:35:17,518 root INFO Epoch 9 Global steps: 78400 Train loss: 0.1904
en_de Dev loss: 0.9119 r:0.1788
en_zh Dev loss: 0.7998 r:0.4493
ro_en Dev loss: 0.3366 r:0.8203
et_en Dev loss: 0.4835 r:0.6590
si_en Dev loss: 0.7979 r:0.5634
ne_en Dev loss: 0.4689 r:0.7263
ru_en Dev loss: 0.4737 r:0.7321
Current avg r:0.5899 Best avg r: 0.6264
05:40:02,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:41:39,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:43:17,460 root INFO Epoch 9 Global steps: 79100 Train loss: 0.1978
en_de Dev loss: 0.8991 r:0.2005
en_zh Dev loss: 0.8341 r:0.4362
ro_en Dev loss: 0.3820 r:0.8125
et_en Dev loss: 0.4981 r:0.6376
si_en Dev loss: 0.9615 r:0.5411
ne_en Dev loss: 0.7169 r:0.7166
ru_en Dev loss: 0.5163 r:0.7151
Current avg r:0.5799 Best avg r: 0.6264
05:48:03,772 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:49:41,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:51:19,117 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1908
en_de Dev loss: 0.9025 r:0.2067
en_zh Dev loss: 0.8165 r:0.4559
ro_en Dev loss: 0.3709 r:0.8229
et_en Dev loss: 0.5119 r:0.6597
si_en Dev loss: 0.8478 r:0.5648
ne_en Dev loss: 0.5207 r:0.7243
ru_en Dev loss: 0.4456 r:0.7488
Current avg r:0.5976 Best avg r: 0.6264
05:56:03,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:57:41,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:18,789 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1757
en_de Dev loss: 0.9298 r:0.1994
en_zh Dev loss: 0.8716 r:0.4456
ro_en Dev loss: 0.3923 r:0.8159
et_en Dev loss: 0.5135 r:0.6397
si_en Dev loss: 0.9994 r:0.5472
ne_en Dev loss: 0.6683 r:0.7153
ru_en Dev loss: 0.4953 r:0.7323
Current avg r:0.5851 Best avg r: 0.6264
06:04:03,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:05:40,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:07:17,856 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1735
en_de Dev loss: 0.9171 r:0.2131
en_zh Dev loss: 0.7970 r:0.4613
ro_en Dev loss: 0.3560 r:0.8211
et_en Dev loss: 0.5341 r:0.6530
si_en Dev loss: 0.8926 r:0.5521
ne_en Dev loss: 0.5313 r:0.7220
ru_en Dev loss: 0.4163 r:0.7570
Current avg r:0.5971 Best avg r: 0.6264
06:12:02,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:13:40,86 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:17,938 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1751
en_de Dev loss: 0.9178 r:0.2212
en_zh Dev loss: 0.8364 r:0.4458
ro_en Dev loss: 0.3682 r:0.8182
et_en Dev loss: 0.5026 r:0.6492
si_en Dev loss: 0.9749 r:0.5445
ne_en Dev loss: 0.5897 r:0.7141
ru_en Dev loss: 0.5000 r:0.7394
Current avg r:0.5903 Best avg r: 0.6264
06:20:02,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:21:40,390 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:18,360 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1737
en_de Dev loss: 0.9266 r:0.2270
en_zh Dev loss: 0.8414 r:0.4400
ro_en Dev loss: 0.3575 r:0.8174
et_en Dev loss: 0.5101 r:0.6383
si_en Dev loss: 0.9285 r:0.5386
ne_en Dev loss: 0.6223 r:0.7130
ru_en Dev loss: 0.4852 r:0.7367
Current avg r:0.5873 Best avg r: 0.6264
06:28:02,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:40,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:17,932 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1733
en_de Dev loss: 0.9233 r:0.1950
en_zh Dev loss: 0.8201 r:0.4507
ro_en Dev loss: 0.3634 r:0.8190
et_en Dev loss: 0.5246 r:0.6521
si_en Dev loss: 0.8902 r:0.5523
ne_en Dev loss: 0.5516 r:0.7199
ru_en Dev loss: 0.5106 r:0.7279
Current avg r:0.5881 Best avg r: 0.6264
06:36:01,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:39,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:17,513 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1745
en_de Dev loss: 0.9078 r:0.1800
en_zh Dev loss: 0.7733 r:0.4648
ro_en Dev loss: 0.3488 r:0.8224
et_en Dev loss: 0.4626 r:0.6549
si_en Dev loss: 0.8467 r:0.5645
ne_en Dev loss: 0.5342 r:0.7205
ru_en Dev loss: 0.4784 r:0.7399
Current avg r:0.5924 Best avg r: 0.6264
06:44:01,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:39,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:47:17,758 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1686
en_de Dev loss: 0.9285 r:0.1968
en_zh Dev loss: 0.8405 r:0.4530
ro_en Dev loss: 0.3692 r:0.8169
et_en Dev loss: 0.5071 r:0.6505
si_en Dev loss: 0.9297 r:0.5479
ne_en Dev loss: 0.5412 r:0.7226
ru_en Dev loss: 0.4972 r:0.7280
Current avg r:0.5880 Best avg r: 0.6264
06:52:01,608 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:53:39,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:55:18,206 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1738
en_de Dev loss: 0.8997 r:0.2061
en_zh Dev loss: 0.8353 r:0.4395
ro_en Dev loss: 0.3532 r:0.8181
et_en Dev loss: 0.4978 r:0.6552
si_en Dev loss: 0.9021 r:0.5468
ne_en Dev loss: 0.5360 r:0.7224
ru_en Dev loss: 0.4525 r:0.7399
Current avg r:0.5897 Best avg r: 0.6264
07:00:01,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:01:39,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:03:18,424 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1696
en_de Dev loss: 0.9021 r:0.1896
en_zh Dev loss: 0.7854 r:0.4569
ro_en Dev loss: 0.3515 r:0.8200
et_en Dev loss: 0.4762 r:0.6503
si_en Dev loss: 0.9310 r:0.5515
ne_en Dev loss: 0.5732 r:0.7210
ru_en Dev loss: 0.4563 r:0.7367
Current avg r:0.5894 Best avg r: 0.6264
07:08:01,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:09:39,501 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:11:18,309 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1669
en_de Dev loss: 0.9206 r:0.1793
en_zh Dev loss: 0.8466 r:0.4481
ro_en Dev loss: 0.3602 r:0.8207
et_en Dev loss: 0.4876 r:0.6520
si_en Dev loss: 0.9626 r:0.5495
ne_en Dev loss: 0.5547 r:0.7285
ru_en Dev loss: 0.4900 r:0.7319
Current avg r:0.5871 Best avg r: 0.6264
07:16:01,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:39,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:19:18,193 root INFO Epoch 10 Global steps: 87500 Train loss: 0.1703
en_de Dev loss: 0.9106 r:0.1989
en_zh Dev loss: 0.8052 r:0.4477
ro_en Dev loss: 0.3401 r:0.8230
et_en Dev loss: 0.4934 r:0.6545
si_en Dev loss: 0.8107 r:0.5527
ne_en Dev loss: 0.4979 r:0.7245
ru_en Dev loss: 0.4621 r:0.7311
Current avg r:0.5904 Best avg r: 0.6264
07:24:02,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:41,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:27:20,176 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1504
en_de Dev loss: 0.9350 r:0.1916
en_zh Dev loss: 0.8589 r:0.4568
ro_en Dev loss: 0.3850 r:0.8187
et_en Dev loss: 0.4911 r:0.6664
si_en Dev loss: 0.9405 r:0.5542
ne_en Dev loss: 0.5405 r:0.7320
ru_en Dev loss: 0.5012 r:0.7394
Current avg r:0.5942 Best avg r: 0.6264
07:32:03,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:33:42,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:35:21,30 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1634
en_de Dev loss: 0.9075 r:0.1973
en_zh Dev loss: 0.8171 r:0.4452
ro_en Dev loss: 0.3648 r:0.8198
et_en Dev loss: 0.4889 r:0.6558
si_en Dev loss: 0.9768 r:0.5428
ne_en Dev loss: 0.5917 r:0.7249
ru_en Dev loss: 0.4667 r:0.7390
Current avg r:0.5892 Best avg r: 0.6264
07:40:04,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:41:43,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:43:22,97 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1595
en_de Dev loss: 0.9284 r:0.2033
en_zh Dev loss: 0.8661 r:0.4543
ro_en Dev loss: 0.3772 r:0.8209
et_en Dev loss: 0.5033 r:0.6570
si_en Dev loss: 0.9601 r:0.5477
ne_en Dev loss: 0.5775 r:0.7236
ru_en Dev loss: 0.5318 r:0.7279
Current avg r:0.5907 Best avg r: 0.6264
07:48:05,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:49:44,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:51:23,126 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1591
en_de Dev loss: 0.8992 r:0.2020
en_zh Dev loss: 0.8177 r:0.4458
ro_en Dev loss: 0.3369 r:0.8236
et_en Dev loss: 0.4788 r:0.6619
si_en Dev loss: 0.8698 r:0.5512
ne_en Dev loss: 0.5765 r:0.7221
ru_en Dev loss: 0.4544 r:0.7362
Current avg r:0.5918 Best avg r: 0.6264
07:56:07,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:57:46,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:59:24,428 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1505
en_de Dev loss: 0.9032 r:0.2105
en_zh Dev loss: 0.8129 r:0.4522
ro_en Dev loss: 0.3496 r:0.8226
et_en Dev loss: 0.5137 r:0.6698
si_en Dev loss: 0.8447 r:0.5538
ne_en Dev loss: 0.5370 r:0.7191
ru_en Dev loss: 0.4660 r:0.7426
Current avg r:0.5958 Best avg r: 0.6264
08:04:08,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:05:47,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:07:25,406 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1570
en_de Dev loss: 0.9388 r:0.1932
en_zh Dev loss: 0.8988 r:0.4387
ro_en Dev loss: 0.3915 r:0.8220
et_en Dev loss: 0.4892 r:0.6586
si_en Dev loss: 0.9504 r:0.5480
ne_en Dev loss: 0.6608 r:0.7137
ru_en Dev loss: 0.5286 r:0.7312
Current avg r:0.5865 Best avg r: 0.6264
08:12:10,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:13:48,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:15:27,113 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1505
en_de Dev loss: 0.9227 r:0.1968
en_zh Dev loss: 0.8295 r:0.4533
ro_en Dev loss: 0.3740 r:0.8156
et_en Dev loss: 0.5193 r:0.6622
si_en Dev loss: 0.8580 r:0.5524
ne_en Dev loss: 0.5192 r:0.7144
ru_en Dev loss: 0.4861 r:0.7352
Current avg r:0.5900 Best avg r: 0.6264
08:20:12,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:50,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:28,615 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1582
en_de Dev loss: 0.9255 r:0.1935
en_zh Dev loss: 0.8341 r:0.4495
ro_en Dev loss: 0.3680 r:0.8199
et_en Dev loss: 0.5145 r:0.6560
si_en Dev loss: 0.8817 r:0.5517
ne_en Dev loss: 0.5066 r:0.7227
ru_en Dev loss: 0.4628 r:0.7390
Current avg r:0.5903 Best avg r: 0.6264
08:28:13,825 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:29:51,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:31:29,179 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1534
en_de Dev loss: 0.9425 r:0.1947
en_zh Dev loss: 0.8767 r:0.4414
ro_en Dev loss: 0.3917 r:0.8193
et_en Dev loss: 0.5226 r:0.6456
si_en Dev loss: 0.9420 r:0.5478
ne_en Dev loss: 0.6121 r:0.7238
ru_en Dev loss: 0.4945 r:0.7307
Current avg r:0.5862 Best avg r: 0.6264
08:36:13,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:37:51,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:39:29,385 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1442
en_de Dev loss: 0.8979 r:0.2069
en_zh Dev loss: 0.8143 r:0.4473
ro_en Dev loss: 0.3636 r:0.8187
et_en Dev loss: 0.5029 r:0.6406
si_en Dev loss: 1.0144 r:0.5362
ne_en Dev loss: 0.6459 r:0.7113
ru_en Dev loss: 0.4884 r:0.7297
Current avg r:0.5844 Best avg r: 0.6264
08:44:14,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:45:51,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:47:29,227 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1460
en_de Dev loss: 0.9345 r:0.2081
en_zh Dev loss: 0.8476 r:0.4364
ro_en Dev loss: 0.3493 r:0.8178
et_en Dev loss: 0.5138 r:0.6512
si_en Dev loss: 0.8461 r:0.5477
ne_en Dev loss: 0.5212 r:0.7183
ru_en Dev loss: 0.4793 r:0.7276
Current avg r:0.5867 Best avg r: 0.6264
08:52:14,865 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:52,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:55:29,831 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1439
en_de Dev loss: 0.9036 r:0.2099
en_zh Dev loss: 0.7976 r:0.4422
ro_en Dev loss: 0.3533 r:0.8186
et_en Dev loss: 0.5229 r:0.6493
si_en Dev loss: 0.8047 r:0.5536
ne_en Dev loss: 0.4948 r:0.7225
ru_en Dev loss: 0.4359 r:0.7393
Current avg r:0.5908 Best avg r: 0.6264
09:00:13,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:51,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:28,374 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1359
en_de Dev loss: 0.9064 r:0.1948
en_zh Dev loss: 0.7955 r:0.4582
ro_en Dev loss: 0.3551 r:0.8211
et_en Dev loss: 0.5189 r:0.6597
si_en Dev loss: 0.8488 r:0.5592
ne_en Dev loss: 0.5243 r:0.7233
ru_en Dev loss: 0.4681 r:0.7331
Current avg r:0.5928 Best avg r: 0.6264
09:08:12,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:50,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:27,157 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1431
en_de Dev loss: 0.9097 r:0.1803
en_zh Dev loss: 0.7758 r:0.4607
ro_en Dev loss: 0.3358 r:0.8226
et_en Dev loss: 0.4851 r:0.6533
si_en Dev loss: 0.8223 r:0.5581
ne_en Dev loss: 0.5094 r:0.7205
ru_en Dev loss: 0.4713 r:0.7306
Current avg r:0.5894 Best avg r: 0.6264
09:16:11,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:17:48,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:25,722 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1410
en_de Dev loss: 0.9144 r:0.1864
en_zh Dev loss: 0.8430 r:0.4482
ro_en Dev loss: 0.3743 r:0.8132
et_en Dev loss: 0.5147 r:0.6451
si_en Dev loss: 0.9490 r:0.5453
ne_en Dev loss: 0.6317 r:0.7118
ru_en Dev loss: 0.4924 r:0.7295
Current avg r:0.5828 Best avg r: 0.6264
09:24:09,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:46,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:27:24,8 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1345
en_de Dev loss: 0.9266 r:0.1727
en_zh Dev loss: 0.8531 r:0.4451
ro_en Dev loss: 0.3826 r:0.8129
et_en Dev loss: 0.5037 r:0.6464
si_en Dev loss: 0.8854 r:0.5491
ne_en Dev loss: 0.5860 r:0.7188
ru_en Dev loss: 0.5066 r:0.7232
Current avg r:0.5812 Best avg r: 0.6264
09:32:07,456 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:33:44,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:35:22,330 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1401
en_de Dev loss: 0.9249 r:0.1952
en_zh Dev loss: 0.8082 r:0.4596
ro_en Dev loss: 0.3478 r:0.8156
et_en Dev loss: 0.4785 r:0.6599
si_en Dev loss: 0.8500 r:0.5481
ne_en Dev loss: 0.5321 r:0.7143
ru_en Dev loss: 0.4574 r:0.7384
Current avg r:0.5902 Best avg r: 0.6264
09:40:05,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:42,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:20,467 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1365
en_de Dev loss: 0.9580 r:0.1634
en_zh Dev loss: 0.8333 r:0.4492
ro_en Dev loss: 0.3405 r:0.8186
et_en Dev loss: 0.4923 r:0.6575
si_en Dev loss: 0.8457 r:0.5491
ne_en Dev loss: 0.5177 r:0.7109
ru_en Dev loss: 0.4608 r:0.7398
Current avg r:0.5841 Best avg r: 0.6264
09:48:03,413 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:49:40,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:18,554 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1447
en_de Dev loss: 0.9565 r:0.1944
en_zh Dev loss: 0.8873 r:0.4483
ro_en Dev loss: 0.3751 r:0.8128
et_en Dev loss: 0.5071 r:0.6586
si_en Dev loss: 0.9224 r:0.5488
ne_en Dev loss: 0.6253 r:0.7105
ru_en Dev loss: 0.4844 r:0.7386
Current avg r:0.5874 Best avg r: 0.6264
09:56:01,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:38,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:16,403 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1356
en_de Dev loss: 0.9261 r:0.1809
en_zh Dev loss: 0.8078 r:0.4557
ro_en Dev loss: 0.3589 r:0.8138
et_en Dev loss: 0.4902 r:0.6549
si_en Dev loss: 0.9447 r:0.5442
ne_en Dev loss: 0.6254 r:0.7135
ru_en Dev loss: 0.4435 r:0.7507
Current avg r:0.5877 Best avg r: 0.6264
10:03:58,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:35,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:13,835 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1363
en_de Dev loss: 0.9171 r:0.1865
en_zh Dev loss: 0.7969 r:0.4590
ro_en Dev loss: 0.3517 r:0.8161
et_en Dev loss: 0.4727 r:0.6662
si_en Dev loss: 0.9041 r:0.5517
ne_en Dev loss: 0.5918 r:0.7154
ru_en Dev loss: 0.4688 r:0.7317
Current avg r:0.5895 Best avg r: 0.6264
10:11:55,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:32,854 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:10,748 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1335
en_de Dev loss: 0.9718 r:0.1792
en_zh Dev loss: 0.8846 r:0.4566
ro_en Dev loss: 0.4093 r:0.8154
et_en Dev loss: 0.5165 r:0.6626
si_en Dev loss: 1.0078 r:0.5532
ne_en Dev loss: 0.6728 r:0.7134
ru_en Dev loss: 0.5564 r:0.7210
Current avg r:0.5859 Best avg r: 0.6264
10:19:53,529 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:30,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:08,686 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1173
en_de Dev loss: 0.9209 r:0.1942
en_zh Dev loss: 0.7932 r:0.4604
ro_en Dev loss: 0.3507 r:0.8203
et_en Dev loss: 0.4994 r:0.6705
si_en Dev loss: 0.8510 r:0.5564
ne_en Dev loss: 0.5163 r:0.7160
ru_en Dev loss: 0.4539 r:0.7386
Current avg r:0.5938 Best avg r: 0.6264
10:27:50,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:27,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:31:05,780 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1327
en_de Dev loss: 0.9549 r:0.1826
en_zh Dev loss: 0.8388 r:0.4504
ro_en Dev loss: 0.3589 r:0.8180
et_en Dev loss: 0.4966 r:0.6649
si_en Dev loss: 0.8750 r:0.5529
ne_en Dev loss: 0.5785 r:0.7124
ru_en Dev loss: 0.4896 r:0.7327
Current avg r:0.5877 Best avg r: 0.6264
