14:44:00,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:13,671 root INFO 
id:en_de cur r: 0.1155 best r: 0.1155
14:44:26,681 root INFO 
id:en_zh cur r: 0.2866 best r: 0.2866
14:44:39,732 root INFO 
id:ro_en cur r: 0.4615 best r: 0.4615
14:45:05,846 root INFO 
id:et_en cur r: 0.4245 best r: 0.4245
14:45:18,924 root INFO 
id:si_en cur r: 0.4435 best r: 0.4435
14:45:31,989 root INFO 
id:ne_en cur r: 0.6038 best r: 0.6038
14:45:44,969 root INFO 
id:ru_en cur r: 0.5022 best r: 0.5022
14:45:44,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:16,145 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
14:47:16,152 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:47:16,159 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:47:16,164 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
14:47:16,169 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
14:47:16,174 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:47:16,179 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:47:29,213 root INFO Epoch 0 Global steps: 700 Train loss: 0.8767
en_de Dev loss: 0.9191 r:0.1133
en_zh Dev loss: 0.7766 r:0.2793
ro_en Dev loss: 0.8030 r:0.5135
et_en Dev loss: 0.5659 r:0.4682
si_en Dev loss: 0.7584 r:0.4442
ne_en Dev loss: 0.5700 r:0.6059
ru_en Dev loss: 0.6484 r:0.5153
Current avg r:0.4200 Best avg r: 0.4200
14:52:03,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:29,515 root INFO 
id:en_zh cur r: 0.3009 best r: 0.3009
14:53:08,678 root INFO 
id:et_en cur r: 0.4556 best r: 0.4556
14:53:47,736 root INFO 
id:ru_en cur r: 0.5413 best r: 0.5413
14:53:47,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:18,933 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8322
en_de Dev loss: 0.9123 r:0.0756
en_zh Dev loss: 0.7680 r:0.2931
ro_en Dev loss: 0.7558 r:0.5083
et_en Dev loss: 0.5687 r:0.5162
si_en Dev loss: 0.7917 r:0.4074
ne_en Dev loss: 0.6648 r:0.5117
ru_en Dev loss: 0.6559 r:0.5542
Current avg r:0.4095 Best avg r: 0.4200
14:59:53,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:19,307 root INFO 
id:en_zh cur r: 0.3428 best r: 0.3428
15:00:32,350 root INFO 
id:ro_en cur r: 0.5529 best r: 0.5529
15:00:58,476 root INFO 
id:et_en cur r: 0.5263 best r: 0.5263
15:01:37,600 root INFO 
id:ru_en cur r: 0.6155 best r: 0.6155
15:01:37,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:08,855 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:03:08,862 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:03:08,867 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:03:08,872 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:03:08,877 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:03:08,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:03:08,887 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:03:21,958 root INFO Epoch 0 Global steps: 2100 Train loss: 0.8022
en_de Dev loss: 0.8912 r:0.1175
en_zh Dev loss: 0.7367 r:0.3241
ro_en Dev loss: 0.6572 r:0.5990
et_en Dev loss: 0.5286 r:0.5690
si_en Dev loss: 0.7690 r:0.4637
ne_en Dev loss: 0.5880 r:0.5855
ru_en Dev loss: 0.6015 r:0.6133
Current avg r:0.4674 Best avg r: 0.4674
15:07:56,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:10,32 root INFO 
id:en_de cur r: 0.1355 best r: 0.1355
15:08:36,74 root INFO 
id:ro_en cur r: 0.6339 best r: 0.6339
15:09:02,205 root INFO 
id:et_en cur r: 0.5635 best r: 0.5635
15:09:15,280 root INFO 
id:si_en cur r: 0.4832 best r: 0.4832
15:09:41,342 root INFO 
id:ru_en cur r: 0.6667 best r: 0.6667
15:09:41,342 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:12,578 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:11:12,586 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:11:12,591 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:11:12,597 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:11:12,604 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:11:12,610 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:11:12,617 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:11:25,690 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7649
en_de Dev loss: 0.9234 r:0.1276
en_zh Dev loss: 0.7546 r:0.3393
ro_en Dev loss: 0.6360 r:0.6590
et_en Dev loss: 0.4906 r:0.6045
si_en Dev loss: 0.7899 r:0.4963
ne_en Dev loss: 0.5794 r:0.5929
ru_en Dev loss: 0.5941 r:0.6784
Current avg r:0.4997 Best avg r: 0.4997
15:16:00,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:13,360 root INFO 
id:en_de cur r: 0.1387 best r: 0.1387
15:16:39,394 root INFO 
id:ro_en cur r: 0.6402 best r: 0.6402
15:17:05,532 root INFO 
id:et_en cur r: 0.5811 best r: 0.5811
15:17:18,608 root INFO 
id:si_en cur r: 0.4874 best r: 0.4874
15:17:44,649 root INFO 
id:ru_en cur r: 0.6688 best r: 0.6688
15:17:44,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:15,826 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6934
en_de Dev loss: 0.9968 r:0.1179
en_zh Dev loss: 0.8867 r:0.3023
ro_en Dev loss: 0.7091 r:0.6632
et_en Dev loss: 0.5568 r:0.5943
si_en Dev loss: 0.8602 r:0.5047
ne_en Dev loss: 0.6964 r:0.5729
ru_en Dev loss: 0.6537 r:0.6649
Current avg r:0.4886 Best avg r: 0.4997
15:23:50,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:03,249 root INFO 
id:en_de cur r: 0.1432 best r: 0.1432
15:24:16,251 root INFO 
id:en_zh cur r: 0.3596 best r: 0.3596
15:24:29,297 root INFO 
id:ro_en cur r: 0.6852 best r: 0.6852
15:24:55,413 root INFO 
id:et_en cur r: 0.6436 best r: 0.6436
15:25:08,481 root INFO 
id:si_en cur r: 0.5354 best r: 0.5354
15:25:21,556 root INFO 
id:ne_en cur r: 0.6393 best r: 0.6393
15:25:34,542 root INFO 
id:ru_en cur r: 0.7291 best r: 0.7291
15:25:34,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:05,754 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:27:05,762 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:27:05,768 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:27:05,773 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:27:05,778 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:27:05,784 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:27:05,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:27:18,855 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6985
en_de Dev loss: 0.9635 r:0.1492
en_zh Dev loss: 0.7844 r:0.3589
ro_en Dev loss: 0.5898 r:0.7079
et_en Dev loss: 0.4633 r:0.6635
si_en Dev loss: 0.8081 r:0.5507
ne_en Dev loss: 0.5103 r:0.6575
ru_en Dev loss: 0.5566 r:0.7313
Current avg r:0.5456 Best avg r: 0.5456
15:31:53,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:06,415 root INFO 
id:en_de cur r: 0.1584 best r: 0.1584
15:32:32,460 root INFO 
id:ro_en cur r: 0.6955 best r: 0.6955
15:32:58,597 root INFO 
id:et_en cur r: 0.6466 best r: 0.6466
15:33:37,707 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:08,914 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:35:08,920 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:35:08,925 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:35:08,930 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:35:08,935 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:35:08,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:35:08,946 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:35:22,12 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6467
en_de Dev loss: 0.8811 r:0.1763
en_zh Dev loss: 0.7465 r:0.3667
ro_en Dev loss: 0.4922 r:0.7181
et_en Dev loss: 0.3954 r:0.6810
si_en Dev loss: 0.7532 r:0.5593
ne_en Dev loss: 0.4878 r:0.6610
ru_en Dev loss: 0.4568 r:0.7420
Current avg r:0.5578 Best avg r: 0.5578
15:39:56,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:09,614 root INFO 
id:en_de cur r: 0.1720 best r: 0.1720
15:40:22,626 root INFO 
id:en_zh cur r: 0.3877 best r: 0.3877
15:40:35,674 root INFO 
id:ro_en cur r: 0.7213 best r: 0.7213
15:41:01,771 root INFO 
id:et_en cur r: 0.7025 best r: 0.7025
15:41:14,858 root INFO 
id:si_en cur r: 0.5667 best r: 0.5667
15:41:27,937 root INFO 
id:ne_en cur r: 0.7012 best r: 0.7012
15:41:40,915 root INFO 
id:ru_en cur r: 0.7470 best r: 0.7470
15:41:40,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:12,147 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:43:12,153 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:43:12,158 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:43:12,163 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:43:12,168 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:43:12,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:43:12,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:43:25,251 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6431
en_de Dev loss: 0.8886 r:0.1722
en_zh Dev loss: 0.7359 r:0.3837
ro_en Dev loss: 0.4587 r:0.7363
et_en Dev loss: 0.3635 r:0.7059
si_en Dev loss: 0.6258 r:0.5781
ne_en Dev loss: 0.3971 r:0.7083
ru_en Dev loss: 0.4419 r:0.7441
Current avg r:0.5755 Best avg r: 0.5755
15:47:59,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:25,573 root INFO 
id:en_zh cur r: 0.3906 best r: 0.3906
15:48:38,484 root INFO 
id:ro_en cur r: 0.7341 best r: 0.7341
15:49:04,343 root INFO 
id:si_en cur r: 0.5673 best r: 0.5673
15:49:30,87 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:00,282 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:51:00,291 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:51:00,296 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:51:00,305 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:51:00,310 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:51:00,315 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:51:00,320 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:51:13,251 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6169
en_de Dev loss: 0.8646 r:0.1971
en_zh Dev loss: 0.7245 r:0.3901
ro_en Dev loss: 0.4343 r:0.7577
et_en Dev loss: 0.3771 r:0.6939
si_en Dev loss: 0.6453 r:0.5809
ne_en Dev loss: 0.5124 r:0.6917
ru_en Dev loss: 0.4335 r:0.7322
Current avg r:0.5777 Best avg r: 0.5777
15:55:44,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:10,424 root INFO 
id:en_zh cur r: 0.4051 best r: 0.4051
15:56:23,334 root INFO 
id:ro_en cur r: 0.7664 best r: 0.7664
15:56:50,503 root INFO 
id:et_en cur r: 0.7086 best r: 0.7086
15:57:03,431 root INFO 
id:si_en cur r: 0.6005 best r: 0.6005
15:57:16,341 root INFO 
id:ne_en cur r: 0.7142 best r: 0.7142
15:57:29,179 root INFO 
id:ru_en cur r: 0.7502 best r: 0.7502
15:57:29,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:59,408 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
15:58:59,416 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:58:59,421 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:58:59,426 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
15:58:59,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
15:58:59,435 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:58:59,440 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:59:12,353 root INFO Epoch 0 Global steps: 7000 Train loss: 0.6175
en_de Dev loss: 0.8802 r:0.1917
en_zh Dev loss: 0.7241 r:0.3974
ro_en Dev loss: 0.4058 r:0.7749
et_en Dev loss: 0.3582 r:0.7079
si_en Dev loss: 0.6282 r:0.6017
ne_en Dev loss: 0.4423 r:0.7081
ru_en Dev loss: 0.4482 r:0.7404
Current avg r:0.5889 Best avg r: 0.5889
16:03:43,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:47,757 root INFO 
id:et_en cur r: 0.7171 best r: 0.7171
16:05:13,620 root INFO 
id:ne_en cur r: 0.7240 best r: 0.7240
16:05:26,467 root INFO 
id:ru_en cur r: 0.7542 best r: 0.7542
16:05:26,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:56,722 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
16:06:56,728 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:06:56,733 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:06:56,738 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
16:06:56,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
16:06:56,748 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:06:56,753 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:07:09,699 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5749
en_de Dev loss: 0.9146 r:0.1881
en_zh Dev loss: 0.7509 r:0.4020
ro_en Dev loss: 0.4271 r:0.7702
et_en Dev loss: 0.3642 r:0.7133
si_en Dev loss: 0.7043 r:0.5857
ne_en Dev loss: 0.4549 r:0.7158
ru_en Dev loss: 0.4355 r:0.7490
Current avg r:0.5891 Best avg r: 0.5891
16:11:41,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:54,665 root INFO 
id:en_de cur r: 0.1784 best r: 0.1784
16:12:07,525 root INFO 
id:en_zh cur r: 0.4273 best r: 0.4273
16:12:20,417 root INFO 
id:ro_en cur r: 0.7809 best r: 0.7809
16:12:46,254 root INFO 
id:si_en cur r: 0.6014 best r: 0.6014
16:12:59,180 root INFO 
id:ne_en cur r: 0.7418 best r: 0.7418
16:13:12,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:42,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
16:14:42,215 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:14:42,220 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:14:42,226 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
16:14:42,231 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
16:14:42,235 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:14:42,241 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:14:55,163 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5638
en_de Dev loss: 0.8678 r:0.2009
en_zh Dev loss: 0.6818 r:0.4240
ro_en Dev loss: 0.3356 r:0.7871
et_en Dev loss: 0.3451 r:0.7164
si_en Dev loss: 0.6160 r:0.5991
ne_en Dev loss: 0.3833 r:0.7393
ru_en Dev loss: 0.3954 r:0.7515
Current avg r:0.6026 Best avg r: 0.6026
16:19:25,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:04,537 root INFO 
id:ro_en cur r: 0.7833 best r: 0.7833
16:20:56,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:26,304 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5262
en_de Dev loss: 0.9153 r:0.1907
en_zh Dev loss: 0.7897 r:0.4180
ro_en Dev loss: 0.4444 r:0.7905
et_en Dev loss: 0.4052 r:0.7081
si_en Dev loss: 0.8745 r:0.5825
ne_en Dev loss: 0.6463 r:0.7261
ru_en Dev loss: 0.5443 r:0.7131
Current avg r:0.5899 Best avg r: 0.6026
16:27:00,895 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:13,790 root INFO 
id:en_de cur r: 0.1900 best r: 0.1900
16:27:39,576 root INFO 
id:ro_en cur r: 0.7897 best r: 0.7897
16:28:31,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:01,551 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5537
en_de Dev loss: 0.9054 r:0.1880
en_zh Dev loss: 0.7619 r:0.4048
ro_en Dev loss: 0.3873 r:0.7918
et_en Dev loss: 0.4072 r:0.7010
si_en Dev loss: 0.8011 r:0.5915
ne_en Dev loss: 0.5136 r:0.7310
ru_en Dev loss: 0.5490 r:0.6947
Current avg r:0.5861 Best avg r: 0.6026
16:34:32,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:02,718 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:32,924 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5518
en_de Dev loss: 0.8894 r:0.1870
en_zh Dev loss: 0.7486 r:0.4166
ro_en Dev loss: 0.3991 r:0.7944
et_en Dev loss: 0.3988 r:0.6981
si_en Dev loss: 0.9045 r:0.5765
ne_en Dev loss: 0.7513 r:0.7179
ru_en Dev loss: 0.5135 r:0.7016
Current avg r:0.5846 Best avg r: 0.6026
16:42:04,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:43,235 root INFO 
id:ro_en cur r: 0.7987 best r: 0.7987
16:43:22,7 root INFO 
id:ne_en cur r: 0.7438 best r: 0.7438
16:43:34,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:05,54 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5524
en_de Dev loss: 0.8591 r:0.1866
en_zh Dev loss: 0.6914 r:0.4101
ro_en Dev loss: 0.3232 r:0.8002
et_en Dev loss: 0.3584 r:0.7045
si_en Dev loss: 0.6921 r:0.5848
ne_en Dev loss: 0.5346 r:0.7314
ru_en Dev loss: 0.4387 r:0.7183
Current avg r:0.5909 Best avg r: 0.6026
16:49:35,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:14,532 root INFO 
id:ro_en cur r: 0.8067 best r: 0.8067
16:50:40,368 root INFO 
id:si_en cur r: 0.6102 best r: 0.6102
16:50:53,307 root INFO 
id:ne_en cur r: 0.7494 best r: 0.7494
16:51:06,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:36,446 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5275
en_de Dev loss: 0.9005 r:0.1821
en_zh Dev loss: 0.8046 r:0.3716
ro_en Dev loss: 0.4081 r:0.8015
et_en Dev loss: 0.3716 r:0.7113
si_en Dev loss: 0.7153 r:0.6037
ne_en Dev loss: 0.4848 r:0.7433
ru_en Dev loss: 0.5290 r:0.6992
Current avg r:0.5875 Best avg r: 0.6026
16:57:07,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:46,488 root INFO 
id:ro_en cur r: 0.8075 best r: 0.8075
16:58:25,251 root INFO 
id:ne_en cur r: 0.7504 best r: 0.7504
16:58:38,80 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:08,283 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5122
en_de Dev loss: 0.8791 r:0.1792
en_zh Dev loss: 0.7558 r:0.3818
ro_en Dev loss: 0.3496 r:0.8054
et_en Dev loss: 0.3503 r:0.7166
si_en Dev loss: 0.6959 r:0.6010
ne_en Dev loss: 0.4114 r:0.7456
ru_en Dev loss: 0.4670 r:0.7007
Current avg r:0.5900 Best avg r: 0.6026
17:04:38,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:51,816 root INFO 
id:en_de cur r: 0.2191 best r: 0.2191
17:05:17,566 root INFO 
id:ro_en cur r: 0.8076 best r: 0.8076
17:05:56,303 root INFO 
id:ne_en cur r: 0.7541 best r: 0.7541
17:06:09,130 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:39,336 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5362
en_de Dev loss: 0.8501 r:0.2092
en_zh Dev loss: 0.6997 r:0.4124
ro_en Dev loss: 0.3058 r:0.8071
et_en Dev loss: 0.3524 r:0.7160
si_en Dev loss: 0.5887 r:0.6025
ne_en Dev loss: 0.3853 r:0.7486
ru_en Dev loss: 0.4356 r:0.7103
Current avg r:0.6009 Best avg r: 0.6026
17:12:09,891 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:12:35,628 root INFO 
id:en_zh cur r: 0.4538 best r: 0.4538
17:12:48,514 root INFO 
id:ro_en cur r: 0.8118 best r: 0.8118
17:13:14,335 root INFO 
id:et_en cur r: 0.7277 best r: 0.7277
17:13:27,255 root INFO 
id:si_en cur r: 0.6235 best r: 0.6235
17:13:40,163 root INFO 
id:ne_en cur r: 0.7676 best r: 0.7676
17:13:53,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:23,276 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
17:15:23,284 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:15:23,290 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:15:23,295 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
17:15:23,299 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
17:15:23,304 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:15:23,309 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:15:36,225 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5175
en_de Dev loss: 0.8590 r:0.2027
en_zh Dev loss: 0.6707 r:0.4515
ro_en Dev loss: 0.3121 r:0.8107
et_en Dev loss: 0.3816 r:0.7248
si_en Dev loss: 0.5184 r:0.6233
ne_en Dev loss: 0.3282 r:0.7660
ru_en Dev loss: 0.3659 r:0.7500
Current avg r:0.6184 Best avg r: 0.6184
17:20:06,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:32,455 root INFO 
id:en_zh cur r: 0.4576 best r: 0.4576
17:20:45,343 root INFO 
id:ro_en cur r: 0.8186 best r: 0.8186
17:21:11,181 root INFO 
id:si_en cur r: 0.6241 best r: 0.6241
17:21:24,105 root INFO 
id:ne_en cur r: 0.7710 best r: 0.7710
17:21:36,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:07,162 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
17:23:07,168 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:23:07,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:23:07,179 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
17:23:07,184 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
17:23:07,188 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:23:07,193 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:23:20,114 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5337
en_de Dev loss: 0.8533 r:0.2243
en_zh Dev loss: 0.7004 r:0.4549
ro_en Dev loss: 0.3030 r:0.8205
et_en Dev loss: 0.3368 r:0.7263
si_en Dev loss: 0.6637 r:0.6214
ne_en Dev loss: 0.4247 r:0.7662
ru_en Dev loss: 0.4014 r:0.7497
Current avg r:0.6233 Best avg r: 0.6233
17:27:50,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:29,533 root INFO 
id:ro_en cur r: 0.8189 best r: 0.8189
17:28:55,380 root INFO 
id:et_en cur r: 0.7281 best r: 0.7281
17:29:21,246 root INFO 
id:ne_en cur r: 0.7718 best r: 0.7718
17:29:34,106 root INFO 
id:ru_en cur r: 0.7582 best r: 0.7582
17:29:34,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:04,410 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4874
en_de Dev loss: 0.8567 r:0.2004
en_zh Dev loss: 0.6884 r:0.4444
ro_en Dev loss: 0.2900 r:0.8205
et_en Dev loss: 0.3396 r:0.7264
si_en Dev loss: 0.5962 r:0.6181
ne_en Dev loss: 0.3260 r:0.7716
ru_en Dev loss: 0.3692 r:0.7620
Current avg r:0.6205 Best avg r: 0.6233
17:35:36,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:06,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:37,180 root INFO Epoch 2 Global steps: 16100 Train loss: 0.4260
en_de Dev loss: 0.8791 r:0.1953
en_zh Dev loss: 0.6927 r:0.4414
ro_en Dev loss: 0.3061 r:0.8163
et_en Dev loss: 0.3486 r:0.7194
si_en Dev loss: 0.6324 r:0.6186
ne_en Dev loss: 0.3806 r:0.7664
ru_en Dev loss: 0.3815 r:0.7604
Current avg r:0.6168 Best avg r: 0.6233
17:43:07,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:37,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:08,50 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4563
en_de Dev loss: 0.8585 r:0.1972
en_zh Dev loss: 0.6912 r:0.4398
ro_en Dev loss: 0.2968 r:0.8158
et_en Dev loss: 0.3451 r:0.7193
si_en Dev loss: 0.6065 r:0.6195
ne_en Dev loss: 0.3898 r:0.7635
ru_en Dev loss: 0.4239 r:0.7421
Current avg r:0.6139 Best avg r: 0.6233
17:50:38,532 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:52:08,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:53:38,862 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4904
en_de Dev loss: 0.8674 r:0.2229
en_zh Dev loss: 0.7490 r:0.4398
ro_en Dev loss: 0.3475 r:0.8105
et_en Dev loss: 0.3686 r:0.7178
si_en Dev loss: 0.7693 r:0.6021
ne_en Dev loss: 0.4305 r:0.7586
ru_en Dev loss: 0.4263 r:0.7508
Current avg r:0.6146 Best avg r: 0.6233
17:58:09,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:59:39,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:09,701 root INFO Epoch 2 Global steps: 18200 Train loss: 0.5000
en_de Dev loss: 0.8660 r:0.2169
en_zh Dev loss: 0.7203 r:0.4510
ro_en Dev loss: 0.3181 r:0.8146
et_en Dev loss: 0.3714 r:0.7134
si_en Dev loss: 0.6969 r:0.6029
ne_en Dev loss: 0.3936 r:0.7583
ru_en Dev loss: 0.4540 r:0.7308
Current avg r:0.6126 Best avg r: 0.6233
18:05:40,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:18,935 root INFO 
id:ro_en cur r: 0.8217 best r: 0.8217
18:06:44,755 root INFO 
id:si_en cur r: 0.6285 best r: 0.6285
18:07:10,492 root INFO 
id:ru_en cur r: 0.7626 best r: 0.7626
18:07:10,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:08:40,631 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
18:08:40,639 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:08:40,645 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:08:40,649 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
18:08:40,656 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
18:08:40,662 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:08:40,667 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:08:53,570 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4494
en_de Dev loss: 0.8473 r:0.2199
en_zh Dev loss: 0.6811 r:0.4493
ro_en Dev loss: 0.2876 r:0.8218
et_en Dev loss: 0.3673 r:0.7185
si_en Dev loss: 0.5669 r:0.6282
ne_en Dev loss: 0.3385 r:0.7666
ru_en Dev loss: 0.3595 r:0.7605
Current avg r:0.6235 Best avg r: 0.6235
18:13:24,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:49,823 root INFO 
id:en_zh cur r: 0.4578 best r: 0.4578
18:14:54,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:24,400 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4813
en_de Dev loss: 0.8549 r:0.2022
en_zh Dev loss: 0.7202 r:0.4537
ro_en Dev loss: 0.3526 r:0.8168
et_en Dev loss: 0.3808 r:0.7092
si_en Dev loss: 0.7572 r:0.6078
ne_en Dev loss: 0.5613 r:0.7575
ru_en Dev loss: 0.4518 r:0.7315
Current avg r:0.6112 Best avg r: 0.6235
18:20:54,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:20,722 root INFO 
id:en_zh cur r: 0.4651 best r: 0.4651
18:21:33,613 root INFO 
id:ro_en cur r: 0.8219 best r: 0.8219
18:21:59,443 root INFO 
id:si_en cur r: 0.6348 best r: 0.6348
18:22:25,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:23:55,342 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4502
en_de Dev loss: 0.8511 r:0.2122
en_zh Dev loss: 0.6834 r:0.4623
ro_en Dev loss: 0.3089 r:0.8209
et_en Dev loss: 0.3790 r:0.7179
si_en Dev loss: 0.5667 r:0.6321
ne_en Dev loss: 0.3500 r:0.7669
ru_en Dev loss: 0.3992 r:0.7436
Current avg r:0.6223 Best avg r: 0.6235
18:28:25,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:38,800 root INFO 
id:en_de cur r: 0.2200 best r: 0.2200
18:29:56,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:26,260 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4792
en_de Dev loss: 0.8547 r:0.2175
en_zh Dev loss: 0.7085 r:0.4471
ro_en Dev loss: 0.3426 r:0.8094
et_en Dev loss: 0.3671 r:0.7049
si_en Dev loss: 0.7404 r:0.6065
ne_en Dev loss: 0.5117 r:0.7559
ru_en Dev loss: 0.4420 r:0.7250
Current avg r:0.6095 Best avg r: 0.6235
18:35:57,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:36:23,237 root INFO 
id:en_zh cur r: 0.4689 best r: 0.4689
18:36:36,135 root INFO 
id:ro_en cur r: 0.8220 best r: 0.8220
18:37:27,756 root INFO 
id:ru_en cur r: 0.7627 best r: 0.7627
18:37:27,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:57,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
18:38:57,947 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:38:57,953 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:38:57,958 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
18:38:57,963 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
18:38:57,968 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:38:57,973 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:39:10,891 root INFO Epoch 2 Global steps: 21700 Train loss: 0.5145
en_de Dev loss: 0.8561 r:0.2186
en_zh Dev loss: 0.6698 r:0.4653
ro_en Dev loss: 0.2986 r:0.8203
et_en Dev loss: 0.3558 r:0.7165
si_en Dev loss: 0.6032 r:0.6217
ne_en Dev loss: 0.3446 r:0.7651
ru_en Dev loss: 0.3720 r:0.7632
Current avg r:0.6244 Best avg r: 0.6244
18:43:41,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:54,361 root INFO 
id:en_de cur r: 0.2365 best r: 0.2365
18:45:11,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:46:41,834 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4589
en_de Dev loss: 0.8401 r:0.2304
en_zh Dev loss: 0.7195 r:0.4554
ro_en Dev loss: 0.3102 r:0.8196
et_en Dev loss: 0.3546 r:0.7161
si_en Dev loss: 0.7810 r:0.5977
ne_en Dev loss: 0.4547 r:0.7656
ru_en Dev loss: 0.4121 r:0.7472
Current avg r:0.6189 Best avg r: 0.6244
18:51:12,429 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:38,163 root INFO 
id:en_zh cur r: 0.4735 best r: 0.4735
18:51:51,64 root INFO 
id:ro_en cur r: 0.8223 best r: 0.8223
18:52:42,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:12,785 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4985
en_de Dev loss: 0.8554 r:0.2188
en_zh Dev loss: 0.7072 r:0.4683
ro_en Dev loss: 0.3481 r:0.8188
et_en Dev loss: 0.3802 r:0.7114
si_en Dev loss: 0.6908 r:0.6069
ne_en Dev loss: 0.3755 r:0.7699
ru_en Dev loss: 0.4230 r:0.7415
Current avg r:0.6194 Best avg r: 0.6244
18:58:43,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:56,116 root INFO 
id:en_de cur r: 0.2382 best r: 0.2382
18:59:21,886 root INFO 
id:ro_en cur r: 0.8237 best r: 0.8237
19:00:00,664 root INFO 
id:ne_en cur r: 0.7767 best r: 0.7767
19:00:13,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:01:43,683 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_de.lang_agnost_mlp.dev.best.scores
19:01:43,695 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/en_zh.lang_agnost_mlp.dev.best.scores
19:01:43,699 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ro_en.lang_agnost_mlp.dev.best.scores
19:01:43,704 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/et_en.lang_agnost_mlp.dev.best.scores
19:01:43,709 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/si_en.lang_agnost_mlp.dev.best.scores
19:01:43,715 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ne_en.lang_agnost_mlp.dev.best.scores
19:01:43,720 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run2/ru_en.lang_agnost_mlp.dev.best.scores
19:01:56,635 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4652
en_de Dev loss: 0.8519 r:0.2400
en_zh Dev loss: 0.6940 r:0.4633
ro_en Dev loss: 0.3200 r:0.8212
et_en Dev loss: 0.3444 r:0.7218
si_en Dev loss: 0.7177 r:0.6132
ne_en Dev loss: 0.3900 r:0.7777
ru_en Dev loss: 0.4076 r:0.7434
Current avg r:0.6258 Best avg r: 0.6258
19:06:28,654 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:54,392 root INFO 
id:en_zh cur r: 0.4816 best r: 0.4816
19:07:58,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:09:29,119 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4112
en_de Dev loss: 0.8634 r:0.2078
en_zh Dev loss: 0.7110 r:0.4709
ro_en Dev loss: 0.3336 r:0.8166
et_en Dev loss: 0.3878 r:0.7097
si_en Dev loss: 0.6583 r:0.6184
ne_en Dev loss: 0.4261 r:0.7729
ru_en Dev loss: 0.4877 r:0.6955
Current avg r:0.6131 Best avg r: 0.6258
19:14:00,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:39,180 root INFO 
id:ro_en cur r: 0.8244 best r: 0.8244
19:15:30,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:00,981 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4276
en_de Dev loss: 0.8533 r:0.2072
en_zh Dev loss: 0.7041 r:0.4523
ro_en Dev loss: 0.2999 r:0.8200
et_en Dev loss: 0.3699 r:0.7176
si_en Dev loss: 0.6187 r:0.6179
ne_en Dev loss: 0.3325 r:0.7761
ru_en Dev loss: 0.4132 r:0.7265
Current avg r:0.6168 Best avg r: 0.6258
19:21:31,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:10,179 root INFO 
id:ro_en cur r: 0.8257 best r: 0.8257
19:23:01,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:24:31,924 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4183
en_de Dev loss: 0.8441 r:0.2336
en_zh Dev loss: 0.7145 r:0.4514
ro_en Dev loss: 0.3102 r:0.8202
et_en Dev loss: 0.3907 r:0.7104
si_en Dev loss: 0.5965 r:0.6135
ne_en Dev loss: 0.3413 r:0.7675
ru_en Dev loss: 0.4379 r:0.7148
Current avg r:0.6159 Best avg r: 0.6258
19:29:03,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:16,148 root INFO 
id:en_de cur r: 0.2479 best r: 0.2479
19:30:33,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:32:03,584 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4395
en_de Dev loss: 0.8547 r:0.2357
en_zh Dev loss: 0.7813 r:0.4372
ro_en Dev loss: 0.3530 r:0.8172
et_en Dev loss: 0.3879 r:0.7073
si_en Dev loss: 0.7588 r:0.6078
ne_en Dev loss: 0.4295 r:0.7678
ru_en Dev loss: 0.4892 r:0.7175
Current avg r:0.6129 Best avg r: 0.6258
19:36:34,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:46,978 root INFO 
id:en_de cur r: 0.2639 best r: 0.2639
19:38:04,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:39:34,494 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4010
en_de Dev loss: 0.8475 r:0.2591
en_zh Dev loss: 0.7671 r:0.4452
ro_en Dev loss: 0.3477 r:0.8108
et_en Dev loss: 0.3902 r:0.6985
si_en Dev loss: 0.7550 r:0.5978
ne_en Dev loss: 0.4616 r:0.7554
ru_en Dev loss: 0.4789 r:0.7198
Current avg r:0.6124 Best avg r: 0.6258
19:44:05,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:45:35,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:47:05,568 root INFO Epoch 3 Global steps: 28000 Train loss: 0.4164
en_de Dev loss: 0.8507 r:0.2245
en_zh Dev loss: 0.6989 r:0.4713
ro_en Dev loss: 0.3410 r:0.8195
et_en Dev loss: 0.3702 r:0.7082
si_en Dev loss: 0.7514 r:0.6036
ne_en Dev loss: 0.4158 r:0.7611
ru_en Dev loss: 0.4314 r:0.7422
Current avg r:0.6186 Best avg r: 0.6258
19:51:36,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:06,304 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:54:36,454 root INFO Epoch 3 Global steps: 28700 Train loss: 0.4103
en_de Dev loss: 0.8385 r:0.2500
en_zh Dev loss: 0.6907 r:0.4641
ro_en Dev loss: 0.3187 r:0.8152
et_en Dev loss: 0.3768 r:0.7093
si_en Dev loss: 0.6024 r:0.6127
ne_en Dev loss: 0.3529 r:0.7724
ru_en Dev loss: 0.3999 r:0.7407
Current avg r:0.6235 Best avg r: 0.6258
19:59:06,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:36,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:02:07,122 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4091
en_de Dev loss: 0.8555 r:0.2468
en_zh Dev loss: 0.7080 r:0.4706
ro_en Dev loss: 0.3204 r:0.8213
et_en Dev loss: 0.3633 r:0.7123
si_en Dev loss: 0.6769 r:0.6114
ne_en Dev loss: 0.3835 r:0.7691
ru_en Dev loss: 0.4626 r:0.7352
Current avg r:0.6238 Best avg r: 0.6258
20:06:37,664 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:07,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:09:37,923 root INFO Epoch 3 Global steps: 30100 Train loss: 0.4111
en_de Dev loss: 0.8432 r:0.2435
en_zh Dev loss: 0.6936 r:0.4689
ro_en Dev loss: 0.3382 r:0.8152
et_en Dev loss: 0.3790 r:0.7010
si_en Dev loss: 0.7148 r:0.6050
ne_en Dev loss: 0.3987 r:0.7619
ru_en Dev loss: 0.4286 r:0.7341
Current avg r:0.6185 Best avg r: 0.6258
20:14:08,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:15:38,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:17:08,750 root INFO Epoch 3 Global steps: 30800 Train loss: 0.4314
en_de Dev loss: 0.8529 r:0.2398
en_zh Dev loss: 0.7146 r:0.4598
ro_en Dev loss: 0.3467 r:0.8105
et_en Dev loss: 0.3760 r:0.6996
si_en Dev loss: 0.7811 r:0.5984
ne_en Dev loss: 0.4917 r:0.7616
ru_en Dev loss: 0.4522 r:0.7152
Current avg r:0.6121 Best avg r: 0.6258
20:21:39,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:23:09,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:39,671 root INFO Epoch 3 Global steps: 31500 Train loss: 0.4240
en_de Dev loss: 0.8708 r:0.2233
en_zh Dev loss: 0.7531 r:0.4538
ro_en Dev loss: 0.3484 r:0.8126
et_en Dev loss: 0.3963 r:0.6997
si_en Dev loss: 0.7609 r:0.5956
ne_en Dev loss: 0.4176 r:0.7592
ru_en Dev loss: 0.4615 r:0.7234
Current avg r:0.6097 Best avg r: 0.6258
20:29:11,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:37,378 root INFO 
id:en_zh cur r: 0.4849 best r: 0.4849
20:30:41,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:32:11,984 root INFO Epoch 4 Global steps: 32200 Train loss: 0.4015
en_de Dev loss: 0.8453 r:0.2316
en_zh Dev loss: 0.6801 r:0.4801
ro_en Dev loss: 0.3303 r:0.8166
et_en Dev loss: 0.3879 r:0.6973
si_en Dev loss: 0.8298 r:0.5981
ne_en Dev loss: 0.4634 r:0.7676
ru_en Dev loss: 0.3998 r:0.7422
Current avg r:0.6191 Best avg r: 0.6258
20:36:43,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:38:13,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:43,371 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3680
en_de Dev loss: 0.8485 r:0.2418
en_zh Dev loss: 0.7221 r:0.4698
ro_en Dev loss: 0.3530 r:0.8100
et_en Dev loss: 0.4101 r:0.6926
si_en Dev loss: 0.7360 r:0.5932
ne_en Dev loss: 0.4200 r:0.7635
ru_en Dev loss: 0.4105 r:0.7443
Current avg r:0.6165 Best avg r: 0.6258
20:44:14,36 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:45:44,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:47:14,367 root INFO Epoch 4 Global steps: 33600 Train loss: 0.3664
en_de Dev loss: 0.8776 r:0.2106
en_zh Dev loss: 0.7683 r:0.4460
ro_en Dev loss: 0.3570 r:0.8067
et_en Dev loss: 0.4080 r:0.6915
si_en Dev loss: 0.7172 r:0.5954
ne_en Dev loss: 0.4753 r:0.7604
ru_en Dev loss: 0.4485 r:0.7263
Current avg r:0.6053 Best avg r: 0.6258
20:51:45,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:53:15,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:45,450 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3615
en_de Dev loss: 0.8677 r:0.2162
en_zh Dev loss: 0.7390 r:0.4665
ro_en Dev loss: 0.3216 r:0.8203
et_en Dev loss: 0.3862 r:0.7047
si_en Dev loss: 0.6287 r:0.6124
ne_en Dev loss: 0.3780 r:0.7615
ru_en Dev loss: 0.4236 r:0.7463
Current avg r:0.6183 Best avg r: 0.6258
20:59:16,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:00:46,603 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:16,784 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3585
en_de Dev loss: 0.8516 r:0.2199
en_zh Dev loss: 0.7181 r:0.4667
ro_en Dev loss: 0.3232 r:0.8181
et_en Dev loss: 0.4235 r:0.7116
si_en Dev loss: 0.5833 r:0.6189
ne_en Dev loss: 0.3503 r:0.7634
ru_en Dev loss: 0.3923 r:0.7470
Current avg r:0.6208 Best avg r: 0.6258
21:06:47,588 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:17,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:47,911 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3867
en_de Dev loss: 0.8545 r:0.2298
en_zh Dev loss: 0.7697 r:0.4490
ro_en Dev loss: 0.3634 r:0.8125
et_en Dev loss: 0.4021 r:0.6982
si_en Dev loss: 0.8348 r:0.5885
ne_en Dev loss: 0.4130 r:0.7552
ru_en Dev loss: 0.4452 r:0.7366
Current avg r:0.6100 Best avg r: 0.6258
21:14:18,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:48,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:18,951 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3712
en_de Dev loss: 0.8604 r:0.2161
en_zh Dev loss: 0.7359 r:0.4636
ro_en Dev loss: 0.3355 r:0.8144
et_en Dev loss: 0.3842 r:0.7014
si_en Dev loss: 0.6942 r:0.6010
ne_en Dev loss: 0.4076 r:0.7574
ru_en Dev loss: 0.4277 r:0.7468
Current avg r:0.6144 Best avg r: 0.6258
21:21:49,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:19,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:49,975 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3859
en_de Dev loss: 0.8638 r:0.1973
en_zh Dev loss: 0.7110 r:0.4672
ro_en Dev loss: 0.3163 r:0.8190
et_en Dev loss: 0.4195 r:0.7047
si_en Dev loss: 0.6269 r:0.6089
ne_en Dev loss: 0.4122 r:0.7643
ru_en Dev loss: 0.3921 r:0.7480
Current avg r:0.6156 Best avg r: 0.6258
21:29:20,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:50,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:20,926 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3608
en_de Dev loss: 0.8692 r:0.2108
en_zh Dev loss: 0.7314 r:0.4583
ro_en Dev loss: 0.3328 r:0.8174
et_en Dev loss: 0.3973 r:0.6979
si_en Dev loss: 0.8503 r:0.5866
ne_en Dev loss: 0.4739 r:0.7583
ru_en Dev loss: 0.4419 r:0.7362
Current avg r:0.6093 Best avg r: 0.6258
21:36:51,553 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:21,739 root INFO 
id:ru_en cur r: 0.7642 best r: 0.7642
21:38:21,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:51,943 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3465
en_de Dev loss: 0.8586 r:0.2066
en_zh Dev loss: 0.7141 r:0.4436
ro_en Dev loss: 0.3196 r:0.8174
et_en Dev loss: 0.4343 r:0.7093
si_en Dev loss: 0.5968 r:0.6100
ne_en Dev loss: 0.3440 r:0.7644
ru_en Dev loss: 0.3786 r:0.7541
Current avg r:0.6151 Best avg r: 0.6258
21:44:22,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:01,244 root INFO 
id:ro_en cur r: 0.8269 best r: 0.8269
21:45:52,800 root INFO 
id:ru_en cur r: 0.7734 best r: 0.7734
21:45:52,801 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:47:22,971 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3696
en_de Dev loss: 0.8523 r:0.2285
en_zh Dev loss: 0.7273 r:0.4573
ro_en Dev loss: 0.3293 r:0.8215
et_en Dev loss: 0.4588 r:0.6999
si_en Dev loss: 0.6301 r:0.6033
ne_en Dev loss: 0.3652 r:0.7617
ru_en Dev loss: 0.3626 r:0.7637
Current avg r:0.6194 Best avg r: 0.6258
21:51:54,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:25,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:55,233 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3627
en_de Dev loss: 0.8444 r:0.2275
en_zh Dev loss: 0.7433 r:0.4418
ro_en Dev loss: 0.3393 r:0.8187
et_en Dev loss: 0.4202 r:0.6922
si_en Dev loss: 0.6819 r:0.6009
ne_en Dev loss: 0.3920 r:0.7600
ru_en Dev loss: 0.4206 r:0.7356
Current avg r:0.6110 Best avg r: 0.6258
21:59:25,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:00:56,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:26,319 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3211
en_de Dev loss: 0.8578 r:0.2110
en_zh Dev loss: 0.7476 r:0.4438
ro_en Dev loss: 0.3513 r:0.8158
et_en Dev loss: 0.4330 r:0.6930
si_en Dev loss: 0.6809 r:0.6014
ne_en Dev loss: 0.3947 r:0.7578
ru_en Dev loss: 0.3933 r:0.7540
Current avg r:0.6110 Best avg r: 0.6258
22:06:57,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:27,230 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:09:57,411 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3323
en_de Dev loss: 0.8806 r:0.1868
en_zh Dev loss: 0.7778 r:0.4347
ro_en Dev loss: 0.3625 r:0.8127
et_en Dev loss: 0.4407 r:0.6819
si_en Dev loss: 0.7172 r:0.5940
ne_en Dev loss: 0.4498 r:0.7526
ru_en Dev loss: 0.4386 r:0.7288
Current avg r:0.5988 Best avg r: 0.6258
22:14:28,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:15:58,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:28,507 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3264
en_de Dev loss: 0.8739 r:0.1809
en_zh Dev loss: 0.7602 r:0.4269
ro_en Dev loss: 0.3501 r:0.8111
et_en Dev loss: 0.4254 r:0.6853
si_en Dev loss: 0.7282 r:0.5942
ne_en Dev loss: 0.4137 r:0.7592
ru_en Dev loss: 0.4515 r:0.7169
Current avg r:0.5963 Best avg r: 0.6258
22:21:59,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:29,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:25:00,175 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3131
en_de Dev loss: 0.8762 r:0.2009
en_zh Dev loss: 0.7758 r:0.4461
ro_en Dev loss: 0.3499 r:0.8156
et_en Dev loss: 0.4243 r:0.6888
si_en Dev loss: 0.7188 r:0.6035
ne_en Dev loss: 0.3955 r:0.7630
ru_en Dev loss: 0.4314 r:0.7439
Current avg r:0.6088 Best avg r: 0.6258
22:29:30,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:01,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:31,280 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3235
en_de Dev loss: 0.8839 r:0.1894
en_zh Dev loss: 0.7426 r:0.4588
ro_en Dev loss: 0.3339 r:0.8170
et_en Dev loss: 0.4217 r:0.6885
si_en Dev loss: 0.7126 r:0.5969
ne_en Dev loss: 0.4056 r:0.7536
ru_en Dev loss: 0.4054 r:0.7512
Current avg r:0.6079 Best avg r: 0.6258
22:37:02,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:32,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:02,712 root INFO Epoch 5 Global steps: 44100 Train loss: 0.3321
en_de Dev loss: 0.8711 r:0.2091
en_zh Dev loss: 0.7573 r:0.4590
ro_en Dev loss: 0.3597 r:0.8151
et_en Dev loss: 0.4335 r:0.6922
si_en Dev loss: 0.7158 r:0.5995
ne_en Dev loss: 0.4198 r:0.7561
ru_en Dev loss: 0.4497 r:0.7327
Current avg r:0.6091 Best avg r: 0.6258
22:44:34,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:04,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:34,796 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3272
en_de Dev loss: 0.8690 r:0.2119
en_zh Dev loss: 0.7756 r:0.4399
ro_en Dev loss: 0.3608 r:0.8115
et_en Dev loss: 0.4268 r:0.6966
si_en Dev loss: 0.7549 r:0.5890
ne_en Dev loss: 0.4019 r:0.7606
ru_en Dev loss: 0.4690 r:0.7249
Current avg r:0.6049 Best avg r: 0.6258
22:52:06,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:36,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:06,928 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3502
en_de Dev loss: 0.8544 r:0.2177
en_zh Dev loss: 0.7402 r:0.4565
ro_en Dev loss: 0.3318 r:0.8163
et_en Dev loss: 0.4351 r:0.6975
si_en Dev loss: 0.6984 r:0.5847
ne_en Dev loss: 0.4094 r:0.7534
ru_en Dev loss: 0.4409 r:0.7213
Current avg r:0.6068 Best avg r: 0.6258
22:59:38,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:08,541 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:02:38,764 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3155
en_de Dev loss: 0.8695 r:0.2271
en_zh Dev loss: 0.7769 r:0.4491
ro_en Dev loss: 0.3571 r:0.8095
et_en Dev loss: 0.4240 r:0.6818
si_en Dev loss: 0.8125 r:0.5748
ne_en Dev loss: 0.5031 r:0.7404
ru_en Dev loss: 0.4930 r:0.7034
Current avg r:0.5980 Best avg r: 0.6258
23:07:09,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:08:39,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:09,908 root INFO Epoch 5 Global steps: 46900 Train loss: 0.3299
en_de Dev loss: 0.8854 r:0.2358
en_zh Dev loss: 0.8117 r:0.4393
ro_en Dev loss: 0.3486 r:0.8141
et_en Dev loss: 0.4112 r:0.6935
si_en Dev loss: 0.6957 r:0.5917
ne_en Dev loss: 0.4599 r:0.7456
ru_en Dev loss: 0.4847 r:0.7190
Current avg r:0.6056 Best avg r: 0.6258
23:14:40,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:10,754 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:17:40,926 root INFO Epoch 5 Global steps: 47600 Train loss: 0.3396
en_de Dev loss: 0.8798 r:0.2023
en_zh Dev loss: 0.8055 r:0.4391
ro_en Dev loss: 0.3678 r:0.8058
et_en Dev loss: 0.4144 r:0.6888
si_en Dev loss: 0.8093 r:0.5854
ne_en Dev loss: 0.5445 r:0.7419
ru_en Dev loss: 0.5010 r:0.7089
Current avg r:0.5960 Best avg r: 0.6258
23:22:12,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:23:42,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:13,157 root INFO Epoch 6 Global steps: 48300 Train loss: 0.2924
en_de Dev loss: 0.8786 r:0.2024
en_zh Dev loss: 0.7955 r:0.4497
ro_en Dev loss: 0.3661 r:0.8090
et_en Dev loss: 0.4231 r:0.6779
si_en Dev loss: 0.8363 r:0.5851
ne_en Dev loss: 0.5022 r:0.7421
ru_en Dev loss: 0.4941 r:0.7124
Current avg r:0.5969 Best avg r: 0.6258
23:29:43,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:13,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:32:44,38 root INFO Epoch 6 Global steps: 49000 Train loss: 0.3049
en_de Dev loss: 0.8634 r:0.2045
en_zh Dev loss: 0.7280 r:0.4695
ro_en Dev loss: 0.3347 r:0.8128
et_en Dev loss: 0.4434 r:0.6825
si_en Dev loss: 0.7050 r:0.5894
ne_en Dev loss: 0.4174 r:0.7429
ru_en Dev loss: 0.4229 r:0.7297
Current avg r:0.6045 Best avg r: 0.6258
23:37:14,956 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:38:45,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:15,594 root INFO Epoch 6 Global steps: 49700 Train loss: 0.2954
en_de Dev loss: 0.8996 r:0.1847
en_zh Dev loss: 0.8120 r:0.4323
ro_en Dev loss: 0.3487 r:0.8112
et_en Dev loss: 0.4394 r:0.6902
si_en Dev loss: 0.7593 r:0.5886
ne_en Dev loss: 0.4314 r:0.7553
ru_en Dev loss: 0.4608 r:0.7250
Current avg r:0.5982 Best avg r: 0.6258
23:44:46,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:17,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:47:47,382 root INFO Epoch 6 Global steps: 50400 Train loss: 0.2840
en_de Dev loss: 0.9022 r:0.1886
en_zh Dev loss: 0.8095 r:0.4290
ro_en Dev loss: 0.3700 r:0.8072
et_en Dev loss: 0.4419 r:0.6731
si_en Dev loss: 0.8616 r:0.5719
ne_en Dev loss: 0.5246 r:0.7362
ru_en Dev loss: 0.5165 r:0.7024
Current avg r:0.5869 Best avg r: 0.6258
23:52:18,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:53:48,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:19,210 root INFO Epoch 6 Global steps: 51100 Train loss: 0.2795
en_de Dev loss: 0.8781 r:0.2079
en_zh Dev loss: 0.7654 r:0.4598
ro_en Dev loss: 0.3328 r:0.8180
et_en Dev loss: 0.4344 r:0.6913
si_en Dev loss: 0.6738 r:0.5945
ne_en Dev loss: 0.3968 r:0.7506
ru_en Dev loss: 0.4395 r:0.7338
Current avg r:0.6080 Best avg r: 0.6258
23:59:50,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:20,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:02:50,733 root INFO Epoch 6 Global steps: 51800 Train loss: 0.2882
en_de Dev loss: 0.8660 r:0.2131
en_zh Dev loss: 0.7876 r:0.4427
ro_en Dev loss: 0.3571 r:0.8160
et_en Dev loss: 0.4639 r:0.6795
si_en Dev loss: 0.7913 r:0.5813
ne_en Dev loss: 0.4722 r:0.7445
ru_en Dev loss: 0.4396 r:0.7300
Current avg r:0.6010 Best avg r: 0.6258
00:07:21,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:08:51,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:10:21,605 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2865
en_de Dev loss: 0.8955 r:0.1877
en_zh Dev loss: 0.8089 r:0.4296
ro_en Dev loss: 0.3645 r:0.8121
et_en Dev loss: 0.4415 r:0.6812
si_en Dev loss: 0.7961 r:0.5760
ne_en Dev loss: 0.4809 r:0.7378
ru_en Dev loss: 0.4996 r:0.7131
Current avg r:0.5911 Best avg r: 0.6258
00:14:52,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:16:22,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:17:52,394 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2821
en_de Dev loss: 0.8581 r:0.2060
en_zh Dev loss: 0.7457 r:0.4537
ro_en Dev loss: 0.3196 r:0.8180
et_en Dev loss: 0.4291 r:0.6924
si_en Dev loss: 0.7321 r:0.5830
ne_en Dev loss: 0.4217 r:0.7391
ru_en Dev loss: 0.3902 r:0.7483
Current avg r:0.6058 Best avg r: 0.6258
00:22:22,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:23:53,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:25:23,212 root INFO Epoch 6 Global steps: 53900 Train loss: 0.2859
en_de Dev loss: 0.8685 r:0.1968
en_zh Dev loss: 0.8007 r:0.4330
ro_en Dev loss: 0.3112 r:0.8205
et_en Dev loss: 0.4172 r:0.6856
si_en Dev loss: 0.7297 r:0.5788
ne_en Dev loss: 0.4351 r:0.7371
ru_en Dev loss: 0.4139 r:0.7398
Current avg r:0.5988 Best avg r: 0.6258
00:29:53,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:31:23,774 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:53,903 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2769
en_de Dev loss: 0.8699 r:0.1951
en_zh Dev loss: 0.7733 r:0.4342
ro_en Dev loss: 0.3567 r:0.8075
et_en Dev loss: 0.4294 r:0.6731
si_en Dev loss: 0.8665 r:0.5607
ne_en Dev loss: 0.4841 r:0.7355
ru_en Dev loss: 0.4625 r:0.7095
Current avg r:0.5880 Best avg r: 0.6258
00:37:24,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:38:54,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:40:24,928 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2655
en_de Dev loss: 0.8880 r:0.1928
en_zh Dev loss: 0.8018 r:0.4346
ro_en Dev loss: 0.3634 r:0.8072
et_en Dev loss: 0.4571 r:0.6667
si_en Dev loss: 0.9227 r:0.5549
ne_en Dev loss: 0.4959 r:0.7323
ru_en Dev loss: 0.4838 r:0.7131
Current avg r:0.5859 Best avg r: 0.6258
00:44:56,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:46:26,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:57,25 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2425
en_de Dev loss: 0.8710 r:0.1953
en_zh Dev loss: 0.7594 r:0.4459
ro_en Dev loss: 0.3292 r:0.8149
et_en Dev loss: 0.4293 r:0.6791
si_en Dev loss: 0.7654 r:0.5762
ne_en Dev loss: 0.4920 r:0.7350
ru_en Dev loss: 0.4365 r:0.7226
Current avg r:0.5956 Best avg r: 0.6258
00:52:27,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:57,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:55:27,835 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2517
en_de Dev loss: 0.8825 r:0.1969
en_zh Dev loss: 0.8235 r:0.4352
ro_en Dev loss: 0.4144 r:0.8078
et_en Dev loss: 0.4726 r:0.6775
si_en Dev loss: 0.9536 r:0.5622
ne_en Dev loss: 0.5400 r:0.7295
ru_en Dev loss: 0.5002 r:0.7134
Current avg r:0.5889 Best avg r: 0.6258
00:59:59,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:01:29,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:59,531 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2484
en_de Dev loss: 0.8789 r:0.1931
en_zh Dev loss: 0.7713 r:0.4453
ro_en Dev loss: 0.3435 r:0.8158
et_en Dev loss: 0.4558 r:0.6839
si_en Dev loss: 0.8026 r:0.5674
ne_en Dev loss: 0.4783 r:0.7307
ru_en Dev loss: 0.4838 r:0.7049
Current avg r:0.5916 Best avg r: 0.6258
01:07:30,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:09:00,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:10:30,299 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2722
en_de Dev loss: 0.8919 r:0.1868
en_zh Dev loss: 0.8023 r:0.4481
ro_en Dev loss: 0.3513 r:0.8196
et_en Dev loss: 0.4425 r:0.6985
si_en Dev loss: 0.7796 r:0.5795
ne_en Dev loss: 0.4878 r:0.7385
ru_en Dev loss: 0.4732 r:0.7202
Current avg r:0.5987 Best avg r: 0.6258
01:15:00,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:16:30,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:18:01,114 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2550
en_de Dev loss: 0.9437 r:0.1649
en_zh Dev loss: 0.8631 r:0.4201
ro_en Dev loss: 0.3797 r:0.8130
et_en Dev loss: 0.4858 r:0.6840
si_en Dev loss: 0.8081 r:0.5651
ne_en Dev loss: 0.4747 r:0.7264
ru_en Dev loss: 0.4925 r:0.7220
Current avg r:0.5851 Best avg r: 0.6258
01:22:31,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:24:01,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:32,20 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2509
en_de Dev loss: 0.8962 r:0.1747
en_zh Dev loss: 0.7921 r:0.4295
ro_en Dev loss: 0.3297 r:0.8153
et_en Dev loss: 0.4689 r:0.6952
si_en Dev loss: 0.7113 r:0.5725
ne_en Dev loss: 0.4165 r:0.7333
ru_en Dev loss: 0.3915 r:0.7511
Current avg r:0.5959 Best avg r: 0.6258
01:30:02,533 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:32,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:33:02,842 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2386
en_de Dev loss: 0.9130 r:0.1737
en_zh Dev loss: 0.8516 r:0.4272
ro_en Dev loss: 0.3862 r:0.8089
et_en Dev loss: 0.4511 r:0.6810
si_en Dev loss: 0.8531 r:0.5673
ne_en Dev loss: 0.4889 r:0.7302
ru_en Dev loss: 0.4942 r:0.7272
Current avg r:0.5879 Best avg r: 0.6258
01:37:33,453 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:39:03,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:40:33,817 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2502
en_de Dev loss: 0.9176 r:0.1785
en_zh Dev loss: 0.8626 r:0.4386
ro_en Dev loss: 0.3815 r:0.8135
et_en Dev loss: 0.4569 r:0.6880
si_en Dev loss: 0.8531 r:0.5726
ne_en Dev loss: 0.5384 r:0.7294
ru_en Dev loss: 0.4861 r:0.7361
Current avg r:0.5938 Best avg r: 0.6258
01:45:04,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:46:34,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:48:04,801 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2395
en_de Dev loss: 0.8757 r:0.1894
en_zh Dev loss: 0.7861 r:0.4449
ro_en Dev loss: 0.3425 r:0.8136
et_en Dev loss: 0.4235 r:0.6898
si_en Dev loss: 0.8209 r:0.5691
ne_en Dev loss: 0.4837 r:0.7313
ru_en Dev loss: 0.4113 r:0.7458
Current avg r:0.5977 Best avg r: 0.6258
01:52:35,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:54:05,491 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:55:36,555 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2583
en_de Dev loss: 0.8909 r:0.1715
en_zh Dev loss: 0.7795 r:0.4487
ro_en Dev loss: 0.3523 r:0.8076
et_en Dev loss: 0.4406 r:0.6826
si_en Dev loss: 0.8511 r:0.5660
ne_en Dev loss: 0.5141 r:0.7327
ru_en Dev loss: 0.4297 r:0.7270
Current avg r:0.5909 Best avg r: 0.6258
02:00:11,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:01:42,709 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:03:13,952 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2582
en_de Dev loss: 0.9166 r:0.1737
en_zh Dev loss: 0.8157 r:0.4538
ro_en Dev loss: 0.3720 r:0.8122
et_en Dev loss: 0.4949 r:0.6900
si_en Dev loss: 0.7549 r:0.5794
ne_en Dev loss: 0.4717 r:0.7297
ru_en Dev loss: 0.4416 r:0.7388
Current avg r:0.5968 Best avg r: 0.6258
02:07:50,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:09:21,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:52,872 root INFO Epoch 8 Global steps: 63700 Train loss: 0.2030
en_de Dev loss: 0.9056 r:0.1746
en_zh Dev loss: 0.8089 r:0.4467
ro_en Dev loss: 0.3560 r:0.8121
et_en Dev loss: 0.4540 r:0.6802
si_en Dev loss: 0.8440 r:0.5629
ne_en Dev loss: 0.5270 r:0.7335
ru_en Dev loss: 0.4734 r:0.7211
Current avg r:0.5902 Best avg r: 0.6258
02:15:27,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:58,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:18:30,177 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2305
en_de Dev loss: 0.9001 r:0.1787
en_zh Dev loss: 0.8240 r:0.4389
ro_en Dev loss: 0.3613 r:0.8160
et_en Dev loss: 0.4804 r:0.6928
si_en Dev loss: 0.7110 r:0.5823
ne_en Dev loss: 0.4465 r:0.7284
ru_en Dev loss: 0.4582 r:0.7303
Current avg r:0.5954 Best avg r: 0.6258
02:23:04,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:35,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:26:05,843 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2358
en_de Dev loss: 0.8753 r:0.2092
en_zh Dev loss: 0.8166 r:0.4480
ro_en Dev loss: 0.3768 r:0.8139
et_en Dev loss: 0.4913 r:0.6845
si_en Dev loss: 0.7718 r:0.5769
ne_en Dev loss: 0.4618 r:0.7291
ru_en Dev loss: 0.4602 r:0.7252
Current avg r:0.5981 Best avg r: 0.6258
02:30:38,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:32:08,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:33:39,3 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2170
en_de Dev loss: 0.8907 r:0.1881
en_zh Dev loss: 0.7971 r:0.4235
ro_en Dev loss: 0.3356 r:0.8110
et_en Dev loss: 0.4272 r:0.6814
si_en Dev loss: 0.8068 r:0.5586
ne_en Dev loss: 0.5194 r:0.7246
ru_en Dev loss: 0.4468 r:0.7209
Current avg r:0.5869 Best avg r: 0.6258
02:38:10,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:39:41,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:41:11,523 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2173
en_de Dev loss: 0.8861 r:0.1924
en_zh Dev loss: 0.7978 r:0.4348
ro_en Dev loss: 0.3575 r:0.8081
et_en Dev loss: 0.4439 r:0.6758
si_en Dev loss: 0.8340 r:0.5620
ne_en Dev loss: 0.5289 r:0.7233
ru_en Dev loss: 0.4360 r:0.7312
Current avg r:0.5896 Best avg r: 0.6258
02:45:42,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:47:13,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:48:43,553 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2193
en_de Dev loss: 0.9094 r:0.1872
en_zh Dev loss: 0.8451 r:0.4206
ro_en Dev loss: 0.3760 r:0.8084
et_en Dev loss: 0.4351 r:0.6800
si_en Dev loss: 0.9295 r:0.5590
ne_en Dev loss: 0.4843 r:0.7221
ru_en Dev loss: 0.4575 r:0.7310
Current avg r:0.5869 Best avg r: 0.6258
02:53:14,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:54:45,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:56:15,330 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2217
en_de Dev loss: 0.8825 r:0.1891
en_zh Dev loss: 0.8025 r:0.4361
ro_en Dev loss: 0.3609 r:0.8101
et_en Dev loss: 0.4482 r:0.6762
si_en Dev loss: 0.8927 r:0.5577
ne_en Dev loss: 0.5206 r:0.7190
ru_en Dev loss: 0.4581 r:0.7205
Current avg r:0.5869 Best avg r: 0.6258
03:00:46,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:02:16,795 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:47,51 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2315
en_de Dev loss: 0.8833 r:0.1688
en_zh Dev loss: 0.8138 r:0.4274
ro_en Dev loss: 0.3462 r:0.8114
et_en Dev loss: 0.4238 r:0.6821
si_en Dev loss: 0.8832 r:0.5525
ne_en Dev loss: 0.5127 r:0.7175
ru_en Dev loss: 0.4202 r:0.7374
Current avg r:0.5853 Best avg r: 0.6258
03:08:18,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:48,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:18,859 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2169
en_de Dev loss: 0.8659 r:0.2064
en_zh Dev loss: 0.7454 r:0.4551
ro_en Dev loss: 0.3336 r:0.8166
et_en Dev loss: 0.4407 r:0.6823
si_en Dev loss: 0.7411 r:0.5696
ne_en Dev loss: 0.4738 r:0.7243
ru_en Dev loss: 0.3969 r:0.7468
Current avg r:0.6002 Best avg r: 0.6258
03:15:49,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:17:20,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:18:50,622 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2123
en_de Dev loss: 0.9039 r:0.1921
en_zh Dev loss: 0.7769 r:0.4572
ro_en Dev loss: 0.3507 r:0.8205
et_en Dev loss: 0.4425 r:0.6883
si_en Dev loss: 0.8086 r:0.5759
ne_en Dev loss: 0.4941 r:0.7267
ru_en Dev loss: 0.4308 r:0.7462
Current avg r:0.6010 Best avg r: 0.6258
03:23:22,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:24:52,358 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:26:22,687 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2196
en_de Dev loss: 0.8946 r:0.2137
en_zh Dev loss: 0.7882 r:0.4529
ro_en Dev loss: 0.3580 r:0.8135
et_en Dev loss: 0.4555 r:0.6836
si_en Dev loss: 0.8085 r:0.5714
ne_en Dev loss: 0.4801 r:0.7214
ru_en Dev loss: 0.4361 r:0.7420
Current avg r:0.5998 Best avg r: 0.6258
03:30:53,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:32:24,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:33:54,257 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2326
en_de Dev loss: 0.8996 r:0.1835
en_zh Dev loss: 0.7693 r:0.4510
ro_en Dev loss: 0.3481 r:0.8133
et_en Dev loss: 0.4428 r:0.6802
si_en Dev loss: 0.8282 r:0.5680
ne_en Dev loss: 0.4615 r:0.7237
ru_en Dev loss: 0.4759 r:0.7254
Current avg r:0.5922 Best avg r: 0.6258
03:38:26,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:39:57,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:27,383 root INFO Epoch 9 Global steps: 72100 Train loss: 0.2072
en_de Dev loss: 0.9059 r:0.1863
en_zh Dev loss: 0.8356 r:0.4404
ro_en Dev loss: 0.3972 r:0.8067
et_en Dev loss: 0.4641 r:0.6699
si_en Dev loss: 0.9087 r:0.5591
ne_en Dev loss: 0.5841 r:0.7149
ru_en Dev loss: 0.4841 r:0.7259
Current avg r:0.5862 Best avg r: 0.6258
03:45:58,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:47:28,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:48:58,947 root INFO Epoch 9 Global steps: 72800 Train loss: 0.1992
en_de Dev loss: 0.9057 r:0.1774
en_zh Dev loss: 0.7865 r:0.4422
ro_en Dev loss: 0.3448 r:0.8130
et_en Dev loss: 0.4704 r:0.6825
si_en Dev loss: 0.8090 r:0.5627
ne_en Dev loss: 0.4752 r:0.7257
ru_en Dev loss: 0.4129 r:0.7511
Current avg r:0.5935 Best avg r: 0.6258
03:53:30,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:55:00,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:56:30,628 root INFO Epoch 9 Global steps: 73500 Train loss: 0.2022
en_de Dev loss: 0.9087 r:0.1750
en_zh Dev loss: 0.7868 r:0.4437
ro_en Dev loss: 0.3441 r:0.8123
et_en Dev loss: 0.4563 r:0.6788
si_en Dev loss: 0.7953 r:0.5585
ne_en Dev loss: 0.4563 r:0.7238
ru_en Dev loss: 0.4269 r:0.7404
Current avg r:0.5904 Best avg r: 0.6258
04:01:03,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:02:33,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:03,640 root INFO Epoch 9 Global steps: 74200 Train loss: 0.1924
en_de Dev loss: 0.9109 r:0.1683
en_zh Dev loss: 0.7978 r:0.4407
ro_en Dev loss: 0.3796 r:0.8095
et_en Dev loss: 0.4653 r:0.6726
si_en Dev loss: 0.8754 r:0.5566
ne_en Dev loss: 0.5676 r:0.7217
ru_en Dev loss: 0.4642 r:0.7248
Current avg r:0.5849 Best avg r: 0.6258
04:08:34,717 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:10:04,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:11:35,217 root INFO Epoch 9 Global steps: 74900 Train loss: 0.1978
en_de Dev loss: 0.9091 r:0.1958
en_zh Dev loss: 0.7961 r:0.4427
ro_en Dev loss: 0.3625 r:0.8146
et_en Dev loss: 0.4792 r:0.6758
si_en Dev loss: 0.7827 r:0.5635
ne_en Dev loss: 0.4743 r:0.7209
ru_en Dev loss: 0.4268 r:0.7423
Current avg r:0.5937 Best avg r: 0.6258
04:16:06,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:17:36,528 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:06,773 root INFO Epoch 9 Global steps: 75600 Train loss: 0.1897
en_de Dev loss: 0.8968 r:0.1915
en_zh Dev loss: 0.7899 r:0.4551
ro_en Dev loss: 0.3469 r:0.8131
et_en Dev loss: 0.4631 r:0.6812
si_en Dev loss: 0.8009 r:0.5651
ne_en Dev loss: 0.4993 r:0.7205
ru_en Dev loss: 0.4258 r:0.7386
Current avg r:0.5950 Best avg r: 0.6258
04:23:37,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:25:08,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:26:38,477 root INFO Epoch 9 Global steps: 76300 Train loss: 0.1952
en_de Dev loss: 0.8845 r:0.1696
en_zh Dev loss: 0.7492 r:0.4515
ro_en Dev loss: 0.3239 r:0.8149
et_en Dev loss: 0.4391 r:0.6875
si_en Dev loss: 0.7332 r:0.5688
ne_en Dev loss: 0.4421 r:0.7278
ru_en Dev loss: 0.4058 r:0.7417
Current avg r:0.5946 Best avg r: 0.6258
04:31:09,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:32:39,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:34:10,64 root INFO Epoch 9 Global steps: 77000 Train loss: 0.1923
en_de Dev loss: 0.9042 r:0.1653
en_zh Dev loss: 0.7826 r:0.4503
ro_en Dev loss: 0.3402 r:0.8103
et_en Dev loss: 0.4708 r:0.6848
si_en Dev loss: 0.7774 r:0.5618
ne_en Dev loss: 0.4593 r:0.7142
ru_en Dev loss: 0.4274 r:0.7377
Current avg r:0.5892 Best avg r: 0.6258
04:38:41,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:40:11,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:41:42,24 root INFO Epoch 9 Global steps: 77700 Train loss: 0.1927
en_de Dev loss: 0.8929 r:0.1918
en_zh Dev loss: 0.8055 r:0.4428
ro_en Dev loss: 0.3718 r:0.8105
et_en Dev loss: 0.4621 r:0.6652
si_en Dev loss: 0.9240 r:0.5550
ne_en Dev loss: 0.6045 r:0.7150
ru_en Dev loss: 0.4693 r:0.7304
Current avg r:0.5872 Best avg r: 0.6258
04:46:13,242 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:47:43,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:49:13,845 root INFO Epoch 9 Global steps: 78400 Train loss: 0.1960
en_de Dev loss: 0.9233 r:0.1824
en_zh Dev loss: 0.8130 r:0.4492
ro_en Dev loss: 0.3620 r:0.8119
et_en Dev loss: 0.4732 r:0.6772
si_en Dev loss: 0.8345 r:0.5666
ne_en Dev loss: 0.4908 r:0.7258
ru_en Dev loss: 0.4607 r:0.7381
Current avg r:0.5930 Best avg r: 0.6258
04:53:44,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:55:15,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:56:45,603 root INFO Epoch 9 Global steps: 79100 Train loss: 0.1958
en_de Dev loss: 0.8843 r:0.2037
en_zh Dev loss: 0.7916 r:0.4383
ro_en Dev loss: 0.3436 r:0.8124
et_en Dev loss: 0.4535 r:0.6690
si_en Dev loss: 0.8608 r:0.5461
ne_en Dev loss: 0.5475 r:0.7144
ru_en Dev loss: 0.4726 r:0.7194
Current avg r:0.5862 Best avg r: 0.6258
05:01:18,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:02:48,799 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:04:19,68 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1705
en_de Dev loss: 0.8940 r:0.2008
en_zh Dev loss: 0.7660 r:0.4612
ro_en Dev loss: 0.3418 r:0.8112
et_en Dev loss: 0.4656 r:0.6738
si_en Dev loss: 0.8009 r:0.5620
ne_en Dev loss: 0.4621 r:0.7249
ru_en Dev loss: 0.4163 r:0.7488
Current avg r:0.5975 Best avg r: 0.6258
05:08:50,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:20,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:50,979 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1782
en_de Dev loss: 0.9090 r:0.1812
en_zh Dev loss: 0.7992 r:0.4491
ro_en Dev loss: 0.3549 r:0.8121
et_en Dev loss: 0.4592 r:0.6708
si_en Dev loss: 0.8475 r:0.5509
ne_en Dev loss: 0.6031 r:0.7171
ru_en Dev loss: 0.4723 r:0.7264
Current avg r:0.5868 Best avg r: 0.6258
05:16:22,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:53,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:19:23,853 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1817
en_de Dev loss: 0.9137 r:0.1590
en_zh Dev loss: 0.8124 r:0.4446
ro_en Dev loss: 0.3675 r:0.8160
et_en Dev loss: 0.4726 r:0.6751
si_en Dev loss: 0.7902 r:0.5659
ne_en Dev loss: 0.4856 r:0.7264
ru_en Dev loss: 0.4392 r:0.7373
Current avg r:0.5892 Best avg r: 0.6258
05:23:58,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:25:29,962 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:27:01,97 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1757
en_de Dev loss: 0.9373 r:0.1686
en_zh Dev loss: 0.8127 r:0.4560
ro_en Dev loss: 0.3639 r:0.8164
et_en Dev loss: 0.4677 r:0.6709
si_en Dev loss: 0.8567 r:0.5550
ne_en Dev loss: 0.5065 r:0.7194
ru_en Dev loss: 0.4562 r:0.7377
Current avg r:0.5892 Best avg r: 0.6258
05:31:35,726 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:33:06,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:34:38,72 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1725
en_de Dev loss: 0.9107 r:0.1656
en_zh Dev loss: 0.7838 r:0.4551
ro_en Dev loss: 0.3495 r:0.8192
et_en Dev loss: 0.4706 r:0.6794
si_en Dev loss: 0.7443 r:0.5673
ne_en Dev loss: 0.4554 r:0.7171
ru_en Dev loss: 0.4247 r:0.7461
Current avg r:0.5928 Best avg r: 0.6258
05:39:12,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:40:43,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:42:14,908 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1735
en_de Dev loss: 0.9237 r:0.1406
en_zh Dev loss: 0.7980 r:0.4438
ro_en Dev loss: 0.3535 r:0.8132
et_en Dev loss: 0.4661 r:0.6741
si_en Dev loss: 0.8770 r:0.5446
ne_en Dev loss: 0.4832 r:0.7200
ru_en Dev loss: 0.4497 r:0.7329
Current avg r:0.5813 Best avg r: 0.6258
05:46:46,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:48:17,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:49:47,526 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1775
en_de Dev loss: 0.9035 r:0.1664
en_zh Dev loss: 0.7891 r:0.4472
ro_en Dev loss: 0.3566 r:0.8154
et_en Dev loss: 0.4543 r:0.6808
si_en Dev loss: 0.8421 r:0.5575
ne_en Dev loss: 0.5097 r:0.7232
ru_en Dev loss: 0.4276 r:0.7445
Current avg r:0.5907 Best avg r: 0.6258
05:54:19,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:55:49,400 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:57:19,707 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1721
en_de Dev loss: 0.9200 r:0.1740
en_zh Dev loss: 0.7952 r:0.4451
ro_en Dev loss: 0.3869 r:0.8082
et_en Dev loss: 0.4670 r:0.6591
si_en Dev loss: 0.9011 r:0.5376
ne_en Dev loss: 0.5847 r:0.7065
ru_en Dev loss: 0.5016 r:0.7172
Current avg r:0.5782 Best avg r: 0.6258
06:01:51,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:21,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:51,920 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1830
en_de Dev loss: 0.9385 r:0.1514
en_zh Dev loss: 0.8088 r:0.4474
ro_en Dev loss: 0.3675 r:0.8107
et_en Dev loss: 0.4370 r:0.6734
si_en Dev loss: 0.9762 r:0.5349
ne_en Dev loss: 0.6168 r:0.7133
ru_en Dev loss: 0.4993 r:0.7209
Current avg r:0.5788 Best avg r: 0.6258
06:09:23,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:10:54,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:12:24,658 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1721
en_de Dev loss: 0.9185 r:0.1695
en_zh Dev loss: 0.7707 r:0.4521
ro_en Dev loss: 0.3460 r:0.8106
et_en Dev loss: 0.4385 r:0.6865
si_en Dev loss: 0.8028 r:0.5549
ne_en Dev loss: 0.5040 r:0.7184
ru_en Dev loss: 0.4369 r:0.7328
Current avg r:0.5893 Best avg r: 0.6258
06:16:56,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:18:26,612 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:19:56,951 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1783
en_de Dev loss: 0.9212 r:0.1720
en_zh Dev loss: 0.8068 r:0.4444
ro_en Dev loss: 0.3749 r:0.8085
et_en Dev loss: 0.4467 r:0.6697
si_en Dev loss: 0.9486 r:0.5301
ne_en Dev loss: 0.5978 r:0.7132
ru_en Dev loss: 0.4724 r:0.7245
Current avg r:0.5803 Best avg r: 0.6258
06:24:28,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:25:58,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:27:28,824 root INFO Epoch 10 Global steps: 87500 Train loss: 0.1850
en_de Dev loss: 0.8910 r:0.1796
en_zh Dev loss: 0.7918 r:0.4426
ro_en Dev loss: 0.3557 r:0.8112
et_en Dev loss: 0.4400 r:0.6677
si_en Dev loss: 0.9061 r:0.5338
ne_en Dev loss: 0.5686 r:0.7095
ru_en Dev loss: 0.4647 r:0.7188
Current avg r:0.5805 Best avg r: 0.6258
06:32:01,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:33:31,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:35:02,195 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1623
en_de Dev loss: 0.9093 r:0.1871
en_zh Dev loss: 0.8820 r:0.4304
ro_en Dev loss: 0.3924 r:0.8115
et_en Dev loss: 0.4792 r:0.6630
si_en Dev loss: 0.9419 r:0.5358
ne_en Dev loss: 0.6000 r:0.7077
ru_en Dev loss: 0.4979 r:0.7202
Current avg r:0.5794 Best avg r: 0.6258
06:39:34,553 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:05,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:42:35,413 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1649
en_de Dev loss: 0.9227 r:0.1820
en_zh Dev loss: 0.8196 r:0.4493
ro_en Dev loss: 0.3702 r:0.8113
et_en Dev loss: 0.4728 r:0.6646
si_en Dev loss: 0.8623 r:0.5394
ne_en Dev loss: 0.5204 r:0.7160
ru_en Dev loss: 0.4672 r:0.7368
Current avg r:0.5856 Best avg r: 0.6258
06:47:06,865 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:48:37,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:50:07,866 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1661
en_de Dev loss: 0.9017 r:0.1833
en_zh Dev loss: 0.7928 r:0.4572
ro_en Dev loss: 0.3477 r:0.8141
et_en Dev loss: 0.4977 r:0.6733
si_en Dev loss: 0.7842 r:0.5556
ne_en Dev loss: 0.4789 r:0.7223
ru_en Dev loss: 0.4015 r:0.7481
Current avg r:0.5934 Best avg r: 0.6258
06:54:40,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:56:10,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:57:41,203 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1660
en_de Dev loss: 0.8816 r:0.1903
en_zh Dev loss: 0.7809 r:0.4517
ro_en Dev loss: 0.3620 r:0.8130
et_en Dev loss: 0.4641 r:0.6696
si_en Dev loss: 0.8906 r:0.5395
ne_en Dev loss: 0.5357 r:0.7185
ru_en Dev loss: 0.4199 r:0.7452
Current avg r:0.5897 Best avg r: 0.6258
07:02:13,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:03:43,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:05:14,69 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1714
en_de Dev loss: 0.9133 r:0.1756
en_zh Dev loss: 0.8261 r:0.4399
ro_en Dev loss: 0.3776 r:0.8104
et_en Dev loss: 0.4642 r:0.6672
si_en Dev loss: 0.9854 r:0.5320
ne_en Dev loss: 0.6321 r:0.7152
ru_en Dev loss: 0.4682 r:0.7362
Current avg r:0.5824 Best avg r: 0.6258
07:09:45,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:11:15,599 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:12:45,891 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1529
en_de Dev loss: 0.9302 r:0.1784
en_zh Dev loss: 0.8012 r:0.4553
ro_en Dev loss: 0.3593 r:0.8132
et_en Dev loss: 0.4702 r:0.6702
si_en Dev loss: 0.8601 r:0.5471
ne_en Dev loss: 0.4891 r:0.7209
ru_en Dev loss: 0.4258 r:0.7487
Current avg r:0.5906 Best avg r: 0.6258
07:17:17,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:18:47,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:18,59 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1528
en_de Dev loss: 0.9373 r:0.1693
en_zh Dev loss: 0.7931 r:0.4621
ro_en Dev loss: 0.3592 r:0.8129
et_en Dev loss: 0.4585 r:0.6774
si_en Dev loss: 0.8923 r:0.5419
ne_en Dev loss: 0.5623 r:0.7127
ru_en Dev loss: 0.4411 r:0.7521
Current avg r:0.5898 Best avg r: 0.6258
07:24:49,289 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:26:19,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:27:49,875 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1540
en_de Dev loss: 0.9046 r:0.1843
en_zh Dev loss: 0.7665 r:0.4654
ro_en Dev loss: 0.3459 r:0.8141
et_en Dev loss: 0.4544 r:0.6760
si_en Dev loss: 0.8889 r:0.5381
ne_en Dev loss: 0.4964 r:0.7162
ru_en Dev loss: 0.4456 r:0.7420
Current avg r:0.5909 Best avg r: 0.6258
07:32:21,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:33:52,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:35:22,510 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1698
en_de Dev loss: 0.8892 r:0.1961
en_zh Dev loss: 0.7750 r:0.4593
ro_en Dev loss: 0.3500 r:0.8131
et_en Dev loss: 0.4534 r:0.6685
si_en Dev loss: 0.8964 r:0.5328
ne_en Dev loss: 0.5712 r:0.7076
ru_en Dev loss: 0.4397 r:0.7383
Current avg r:0.5879 Best avg r: 0.6258
07:39:54,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:41:25,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:42:55,314 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1579
en_de Dev loss: 0.9209 r:0.2109
en_zh Dev loss: 0.8467 r:0.4466
ro_en Dev loss: 0.3738 r:0.8112
et_en Dev loss: 0.4696 r:0.6690
si_en Dev loss: 0.9309 r:0.5211
ne_en Dev loss: 0.6059 r:0.7010
ru_en Dev loss: 0.4461 r:0.7468
Current avg r:0.5866 Best avg r: 0.6258
07:47:26,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:48:56,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:50:26,914 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1519
en_de Dev loss: 0.9302 r:0.1848
en_zh Dev loss: 0.8088 r:0.4465
ro_en Dev loss: 0.3735 r:0.8081
et_en Dev loss: 0.4509 r:0.6695
si_en Dev loss: 0.9186 r:0.5243
ne_en Dev loss: 0.5590 r:0.7132
ru_en Dev loss: 0.4707 r:0.7348
Current avg r:0.5830 Best avg r: 0.6258
07:54:59,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:56:29,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:58:00,44 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1367
en_de Dev loss: 0.9059 r:0.1669
en_zh Dev loss: 0.7991 r:0.4464
ro_en Dev loss: 0.3530 r:0.8132
et_en Dev loss: 0.4528 r:0.6660
si_en Dev loss: 0.8551 r:0.5373
ne_en Dev loss: 0.5267 r:0.7064
ru_en Dev loss: 0.4476 r:0.7349
Current avg r:0.5816 Best avg r: 0.6258
08:02:32,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:04:02,711 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:05:33,82 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1482
en_de Dev loss: 0.9329 r:0.1653
en_zh Dev loss: 0.7961 r:0.4644
ro_en Dev loss: 0.3766 r:0.8102
et_en Dev loss: 0.4880 r:0.6660
si_en Dev loss: 0.9119 r:0.5480
ne_en Dev loss: 0.5495 r:0.7091
ru_en Dev loss: 0.4468 r:0.7446
Current avg r:0.5868 Best avg r: 0.6258
08:10:05,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:11:35,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:13:06,308 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1484
en_de Dev loss: 0.9500 r:0.1611
en_zh Dev loss: 0.7825 r:0.4639
ro_en Dev loss: 0.3559 r:0.8112
et_en Dev loss: 0.4700 r:0.6720
si_en Dev loss: 0.8902 r:0.5500
ne_en Dev loss: 0.5286 r:0.7133
ru_en Dev loss: 0.4518 r:0.7399
Current avg r:0.5873 Best avg r: 0.6258
08:17:37,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:19:08,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:20:38,505 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1481
en_de Dev loss: 0.9643 r:0.1499
en_zh Dev loss: 0.7883 r:0.4636
ro_en Dev loss: 0.3671 r:0.8106
et_en Dev loss: 0.4742 r:0.6734
si_en Dev loss: 0.8851 r:0.5531
ne_en Dev loss: 0.5152 r:0.7197
ru_en Dev loss: 0.4326 r:0.7492
Current avg r:0.5885 Best avg r: 0.6258
08:25:09,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:26:40,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:28:10,642 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1427
en_de Dev loss: 0.9436 r:0.1674
en_zh Dev loss: 0.7616 r:0.4747
ro_en Dev loss: 0.3460 r:0.8124
et_en Dev loss: 0.4724 r:0.6788
si_en Dev loss: 0.8334 r:0.5474
ne_en Dev loss: 0.4959 r:0.7217
ru_en Dev loss: 0.3932 r:0.7650
Current avg r:0.5953 Best avg r: 0.6258
08:32:41,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:34:12,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:35:44,140 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1434
en_de Dev loss: 0.9515 r:0.1533
en_zh Dev loss: 0.8154 r:0.4569
ro_en Dev loss: 0.3881 r:0.8079
et_en Dev loss: 0.4975 r:0.6653
si_en Dev loss: 0.9515 r:0.5340
ne_en Dev loss: 0.5323 r:0.7125
ru_en Dev loss: 0.4351 r:0.7491
Current avg r:0.5827 Best avg r: 0.6258
08:40:19,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:41:50,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:43:21,592 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1453
en_de Dev loss: 0.9484 r:0.1532
en_zh Dev loss: 0.7852 r:0.4660
ro_en Dev loss: 0.3679 r:0.8089
et_en Dev loss: 0.4610 r:0.6798
si_en Dev loss: 0.9480 r:0.5448
ne_en Dev loss: 0.5322 r:0.7213
ru_en Dev loss: 0.4382 r:0.7527
Current avg r:0.5895 Best avg r: 0.6258
08:47:56,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:49:27,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:50:59,97 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1438
en_de Dev loss: 0.9351 r:0.1558
en_zh Dev loss: 0.7306 r:0.4742
ro_en Dev loss: 0.3248 r:0.8139
et_en Dev loss: 0.4676 r:0.6840
si_en Dev loss: 0.7405 r:0.5558
ne_en Dev loss: 0.4558 r:0.7189
ru_en Dev loss: 0.3696 r:0.7636
Current avg r:0.5952 Best avg r: 0.6258
08:55:34,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:57:05,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:58:35,676 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1443
en_de Dev loss: 0.9507 r:0.1584
en_zh Dev loss: 0.8176 r:0.4635
ro_en Dev loss: 0.3696 r:0.8089
et_en Dev loss: 0.4873 r:0.6774
si_en Dev loss: 0.8843 r:0.5517
ne_en Dev loss: 0.5534 r:0.7051
ru_en Dev loss: 0.4393 r:0.7507
Current avg r:0.5880 Best avg r: 0.6258
09:03:06,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:04:37,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:06:07,573 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1488
en_de Dev loss: 0.9339 r:0.1682
en_zh Dev loss: 0.7724 r:0.4616
ro_en Dev loss: 0.3463 r:0.8097
et_en Dev loss: 0.4606 r:0.6738
si_en Dev loss: 0.8479 r:0.5464
ne_en Dev loss: 0.5028 r:0.7116
ru_en Dev loss: 0.3879 r:0.7661
Current avg r:0.5911 Best avg r: 0.6258
09:10:38,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:12:09,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:13:39,342 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1355
en_de Dev loss: 0.9407 r:0.1618
en_zh Dev loss: 0.8364 r:0.4530
ro_en Dev loss: 0.3760 r:0.8110
et_en Dev loss: 0.4696 r:0.6626
si_en Dev loss: 0.9273 r:0.5393
ne_en Dev loss: 0.7038 r:0.6951
ru_en Dev loss: 0.5015 r:0.7264
Current avg r:0.5785 Best avg r: 0.6258
09:18:12,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:19:42,587 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:21:12,949 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1227
en_de Dev loss: 0.9329 r:0.1769
en_zh Dev loss: 0.8226 r:0.4561
ro_en Dev loss: 0.3893 r:0.8069
et_en Dev loss: 0.4731 r:0.6587
si_en Dev loss: 1.0112 r:0.5381
ne_en Dev loss: 0.6322 r:0.7124
ru_en Dev loss: 0.4858 r:0.7354
Current avg r:0.5835 Best avg r: 0.6258
09:25:44,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:27:14,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:28:44,790 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1283
en_de Dev loss: 0.9189 r:0.1767
en_zh Dev loss: 0.7580 r:0.4624
ro_en Dev loss: 0.3521 r:0.8124
et_en Dev loss: 0.4619 r:0.6714
si_en Dev loss: 0.8401 r:0.5502
ne_en Dev loss: 0.5521 r:0.7085
ru_en Dev loss: 0.4258 r:0.7461
Current avg r:0.5897 Best avg r: 0.6258
09:33:15,963 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:34:46,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:36:16,703 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1359
en_de Dev loss: 0.9256 r:0.1819
en_zh Dev loss: 0.8230 r:0.4440
ro_en Dev loss: 0.3820 r:0.8072
et_en Dev loss: 0.4617 r:0.6690
si_en Dev loss: 0.9209 r:0.5419
ne_en Dev loss: 0.5642 r:0.7068
ru_en Dev loss: 0.4885 r:0.7313
Current avg r:0.5832 Best avg r: 0.6258
09:40:48,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:42:18,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:48,905 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1319
en_de Dev loss: 0.9258 r:0.1724
en_zh Dev loss: 0.7700 r:0.4582
ro_en Dev loss: 0.3559 r:0.8105
et_en Dev loss: 0.4732 r:0.6773
si_en Dev loss: 0.8185 r:0.5497
ne_en Dev loss: 0.5134 r:0.7121
ru_en Dev loss: 0.4284 r:0.7444
Current avg r:0.5892 Best avg r: 0.6258
09:48:20,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:49:51,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:51:21,600 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1275
en_de Dev loss: 0.9284 r:0.1652
en_zh Dev loss: 0.7516 r:0.4693
ro_en Dev loss: 0.3489 r:0.8120
et_en Dev loss: 0.4946 r:0.6775
si_en Dev loss: 0.7509 r:0.5639
ne_en Dev loss: 0.5015 r:0.7090
ru_en Dev loss: 0.3909 r:0.7511
Current avg r:0.5925 Best avg r: 0.6258
09:55:53,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:57:23,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:53,853 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1327
en_de Dev loss: 0.9342 r:0.1600
en_zh Dev loss: 0.7879 r:0.4461
ro_en Dev loss: 0.3572 r:0.8093
et_en Dev loss: 0.4641 r:0.6747
si_en Dev loss: 0.8453 r:0.5525
ne_en Dev loss: 0.5678 r:0.7057
ru_en Dev loss: 0.4093 r:0.7548
Current avg r:0.5862 Best avg r: 0.6258
10:03:25,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:55,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:06:25,540 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1288
en_de Dev loss: 0.9422 r:0.1446
en_zh Dev loss: 0.8294 r:0.4430
ro_en Dev loss: 0.3822 r:0.8048
et_en Dev loss: 0.4619 r:0.6774
si_en Dev loss: 0.9151 r:0.5428
ne_en Dev loss: 0.5609 r:0.7087
ru_en Dev loss: 0.4505 r:0.7508
Current avg r:0.5817 Best avg r: 0.6258
10:10:56,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:12:27,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:13:57,509 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1311
en_de Dev loss: 0.9502 r:0.1334
en_zh Dev loss: 0.7778 r:0.4527
ro_en Dev loss: 0.3456 r:0.8118
et_en Dev loss: 0.4768 r:0.6867
si_en Dev loss: 0.7952 r:0.5531
ne_en Dev loss: 0.4718 r:0.7094
ru_en Dev loss: 0.3679 r:0.7751
Current avg r:0.5889 Best avg r: 0.6258
10:18:28,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:59,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:21:29,572 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1218
en_de Dev loss: 0.9862 r:0.1273
en_zh Dev loss: 0.8302 r:0.4458
ro_en Dev loss: 0.3688 r:0.8099
et_en Dev loss: 0.4797 r:0.6814
si_en Dev loss: 0.7945 r:0.5602
ne_en Dev loss: 0.4943 r:0.7089
ru_en Dev loss: 0.4298 r:0.7606
Current avg r:0.5849 Best avg r: 0.6258
10:26:00,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:31,299 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:01,690 root INFO Epoch 13 Global steps: 109900 Train loss: 0.1313
en_de Dev loss: 0.9694 r:0.1548
en_zh Dev loss: 0.7936 r:0.4571
ro_en Dev loss: 0.3629 r:0.8130
et_en Dev loss: 0.4858 r:0.6819
si_en Dev loss: 0.8747 r:0.5509
ne_en Dev loss: 0.5608 r:0.7087
ru_en Dev loss: 0.4093 r:0.7625
Current avg r:0.5898 Best avg r: 0.6258
