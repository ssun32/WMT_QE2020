14:38:37,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:39:03,383 root INFO 
id:en_zh cur r: 0.1965 best r: 0.1965
14:39:16,254 root INFO 
id:ro_en cur r: 0.5430 best r: 0.5430
14:39:41,998 root INFO 
id:si_en cur r: 0.0689 best r: 0.0689
14:39:54,873 root INFO 
id:ne_en cur r: 0.3850 best r: 0.3850
14:40:07,693 root INFO 
id:ru_en cur r: 0.3810 best r: 0.3810
14:40:07,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:41:37,712 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
14:41:37,725 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:41:37,730 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:41:37,739 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
14:41:37,745 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
14:41:37,752 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:41:37,759 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:41:50,647 root INFO Epoch 0 Global steps: 700 Train loss: 0.8926
en_de Dev loss: 0.8864 r:0.1251
en_zh Dev loss: 0.8055 r:0.2168
ro_en Dev loss: 0.7750 r:0.5246
et_en Dev loss: 0.6322 r:0.4311
si_en Dev loss: 0.8356 r:0.3362
ne_en Dev loss: 0.7275 r:0.4645
ru_en Dev loss: 0.7696 r:0.3628
Current avg r:0.3516 Best avg r: 0.3516
14:46:18,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:46:31,804 root INFO 
id:en_de cur r: 0.1306 best r: 0.1306
14:46:44,615 root INFO 
id:en_zh cur r: 0.2925 best r: 0.2925
14:46:57,468 root INFO 
id:ro_en cur r: 0.6186 best r: 0.6186
14:47:23,176 root INFO 
id:et_en cur r: 0.5256 best r: 0.5256
14:47:36,38 root INFO 
id:si_en cur r: 0.4277 best r: 0.4277
14:47:48,909 root INFO 
id:ne_en cur r: 0.5888 best r: 0.5888
14:48:01,697 root INFO 
id:ru_en cur r: 0.5548 best r: 0.5548
14:48:01,698 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:49:31,389 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
14:49:31,396 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:49:31,401 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:49:31,406 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
14:49:31,411 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
14:49:31,416 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:49:31,423 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:49:44,279 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8375
en_de Dev loss: 0.9290 r:0.1270
en_zh Dev loss: 0.7536 r:0.3033
ro_en Dev loss: 0.7299 r:0.6521
et_en Dev loss: 0.5272 r:0.5769
si_en Dev loss: 0.8511 r:0.4622
ne_en Dev loss: 0.5981 r:0.6354
ru_en Dev loss: 0.6689 r:0.5735
Current avg r:0.4758 Best avg r: 0.4758
14:54:12,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:54:38,248 root INFO 
id:en_zh cur r: 0.3207 best r: 0.3207
14:54:51,81 root INFO 
id:ro_en cur r: 0.6873 best r: 0.6873
14:55:16,772 root INFO 
id:et_en cur r: 0.6146 best r: 0.6146
14:55:29,626 root INFO 
id:si_en cur r: 0.4750 best r: 0.4750
14:55:42,484 root INFO 
id:ne_en cur r: 0.6222 best r: 0.6222
14:55:55,284 root INFO 
id:ru_en cur r: 0.6516 best r: 0.6516
14:55:55,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:57:25,92 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
14:57:25,99 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
14:57:25,103 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
14:57:25,107 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
14:57:25,113 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
14:57:25,118 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
14:57:25,123 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
14:57:37,975 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7693
en_de Dev loss: 1.1243 r:0.1421
en_zh Dev loss: 0.9400 r:0.3052
ro_en Dev loss: 0.7395 r:0.6814
et_en Dev loss: 0.5607 r:0.6194
si_en Dev loss: 0.9317 r:0.4888
ne_en Dev loss: 0.6142 r:0.6398
ru_en Dev loss: 0.7514 r:0.6409
Current avg r:0.5025 Best avg r: 0.5025
15:02:06,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:02:19,186 root INFO 
id:en_de cur r: 0.1422 best r: 0.1422
15:03:10,554 root INFO 
id:si_en cur r: 0.4854 best r: 0.4854
15:03:23,412 root INFO 
id:ne_en cur r: 0.6439 best r: 0.6439
15:03:36,207 root INFO 
id:ru_en cur r: 0.6611 best r: 0.6611
15:03:36,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:05:06,1 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:05:06,7 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:05:06,12 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:05:06,17 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:05:06,22 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:05:06,27 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:05:06,34 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:05:18,886 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6886
en_de Dev loss: 0.9355 r:0.1435
en_zh Dev loss: 0.7741 r:0.3139
ro_en Dev loss: 0.4853 r:0.7169
et_en Dev loss: 0.4047 r:0.6660
si_en Dev loss: 0.6747 r:0.5179
ne_en Dev loss: 0.4571 r:0.6586
ru_en Dev loss: 0.5038 r:0.6727
Current avg r:0.5271 Best avg r: 0.5271
15:09:47,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:10:00,156 root INFO 
id:en_de cur r: 0.1558 best r: 0.1558
15:10:12,982 root INFO 
id:en_zh cur r: 0.3630 best r: 0.3630
15:10:25,851 root INFO 
id:ro_en cur r: 0.7282 best r: 0.7282
15:10:51,572 root INFO 
id:et_en cur r: 0.6856 best r: 0.6856
15:11:04,432 root INFO 
id:si_en cur r: 0.5467 best r: 0.5467
15:11:17,296 root INFO 
id:ne_en cur r: 0.6969 best r: 0.6969
15:11:30,101 root INFO 
id:ru_en cur r: 0.7024 best r: 0.7024
15:11:30,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:59,903 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:12:59,909 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:12:59,913 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:12:59,918 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:12:59,922 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:12:59,928 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:12:59,936 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:13:12,791 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6218
en_de Dev loss: 0.9112 r:0.1624
en_zh Dev loss: 0.7361 r:0.3571
ro_en Dev loss: 0.4392 r:0.7357
et_en Dev loss: 0.3682 r:0.6982
si_en Dev loss: 0.6100 r:0.5567
ne_en Dev loss: 0.4403 r:0.6958
ru_en Dev loss: 0.4554 r:0.7053
Current avg r:0.5587 Best avg r: 0.5587
15:17:41,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:54,50 root INFO 
id:en_de cur r: 0.1940 best r: 0.1940
15:18:06,878 root INFO 
id:en_zh cur r: 0.3732 best r: 0.3732
15:18:19,732 root INFO 
id:ro_en cur r: 0.7464 best r: 0.7464
15:18:45,448 root INFO 
id:si_en cur r: 0.5557 best r: 0.5557
15:18:58,329 root INFO 
id:ne_en cur r: 0.7070 best r: 0.7070
15:19:11,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:41,41 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:20:41,46 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:20:41,51 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:20:41,56 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:20:41,61 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:20:41,66 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:20:41,71 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:20:53,946 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6138
en_de Dev loss: 0.8892 r:0.1860
en_zh Dev loss: 0.7582 r:0.3660
ro_en Dev loss: 0.3973 r:0.7580
et_en Dev loss: 0.3694 r:0.7009
si_en Dev loss: 0.6753 r:0.5569
ne_en Dev loss: 0.5013 r:0.7015
ru_en Dev loss: 0.4803 r:0.6962
Current avg r:0.5665 Best avg r: 0.5665
15:25:23,181 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:48,881 root INFO 
id:en_zh cur r: 0.3733 best r: 0.3733
15:26:40,344 root INFO 
id:ne_en cur r: 0.7126 best r: 0.7126
15:26:53,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:22,993 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5953
en_de Dev loss: 0.9090 r:0.1807
en_zh Dev loss: 0.7617 r:0.3675
ro_en Dev loss: 0.4115 r:0.7599
et_en Dev loss: 0.3641 r:0.6988
si_en Dev loss: 0.7105 r:0.5560
ne_en Dev loss: 0.5451 r:0.7063
ru_en Dev loss: 0.5039 r:0.6958
Current avg r:0.5664 Best avg r: 0.5665
15:32:52,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:04,968 root INFO 
id:en_de cur r: 0.1954 best r: 0.1954
15:33:17,812 root INFO 
id:en_zh cur r: 0.4040 best r: 0.4040
15:33:30,672 root INFO 
id:ro_en cur r: 0.7741 best r: 0.7741
15:33:56,415 root INFO 
id:et_en cur r: 0.7047 best r: 0.7047
15:34:09,298 root INFO 
id:si_en cur r: 0.5754 best r: 0.5754
15:34:22,154 root INFO 
id:ne_en cur r: 0.7352 best r: 0.7352
15:34:34,950 root INFO 
id:ru_en cur r: 0.7283 best r: 0.7283
15:34:34,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:04,691 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:36:04,698 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:36:04,703 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:36:04,707 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:36:04,712 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:36:04,716 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:36:04,721 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:36:17,577 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5785
en_de Dev loss: 0.8636 r:0.1927
en_zh Dev loss: 0.6888 r:0.4020
ro_en Dev loss: 0.3463 r:0.7828
et_en Dev loss: 0.3616 r:0.7144
si_en Dev loss: 0.6616 r:0.5762
ne_en Dev loss: 0.4461 r:0.7250
ru_en Dev loss: 0.4058 r:0.7399
Current avg r:0.5904 Best avg r: 0.5904
15:40:45,640 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:58,495 root INFO 
id:en_de cur r: 0.2074 best r: 0.2074
15:41:11,334 root INFO 
id:en_zh cur r: 0.4066 best r: 0.4066
15:41:24,188 root INFO 
id:ro_en cur r: 0.7824 best r: 0.7824
15:41:49,936 root INFO 
id:et_en cur r: 0.7125 best r: 0.7125
15:42:02,797 root INFO 
id:si_en cur r: 0.5930 best r: 0.5930
15:42:15,651 root INFO 
id:ne_en cur r: 0.7471 best r: 0.7471
15:42:28,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:58,230 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:43:58,236 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:43:58,241 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:43:58,246 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:43:58,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:43:58,255 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:43:58,260 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:44:11,111 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5846
en_de Dev loss: 0.8965 r:0.1938
en_zh Dev loss: 0.7216 r:0.4068
ro_en Dev loss: 0.3566 r:0.7880
et_en Dev loss: 0.3422 r:0.7223
si_en Dev loss: 0.6087 r:0.5945
ne_en Dev loss: 0.3830 r:0.7410
ru_en Dev loss: 0.4214 r:0.7336
Current avg r:0.5971 Best avg r: 0.5971
15:48:39,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:49:04,829 root INFO 
id:en_zh cur r: 0.4144 best r: 0.4144
15:49:17,671 root INFO 
id:ro_en cur r: 0.7871 best r: 0.7871
15:50:08,973 root INFO 
id:ru_en cur r: 0.7411 best r: 0.7411
15:50:08,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:38,690 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
15:51:38,697 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
15:51:38,702 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
15:51:38,707 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
15:51:38,711 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
15:51:38,716 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
15:51:38,721 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
15:51:51,563 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5510
en_de Dev loss: 0.8937 r:0.1891
en_zh Dev loss: 0.7279 r:0.4148
ro_en Dev loss: 0.3526 r:0.7899
et_en Dev loss: 0.3440 r:0.7159
si_en Dev loss: 0.6772 r:0.5924
ne_en Dev loss: 0.4526 r:0.7381
ru_en Dev loss: 0.4030 r:0.7461
Current avg r:0.5980 Best avg r: 0.5980
15:56:19,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:58,321 root INFO 
id:ro_en cur r: 0.7909 best r: 0.7909
15:57:24,34 root INFO 
id:si_en cur r: 0.5965 best r: 0.5965
15:57:36,893 root INFO 
id:ne_en cur r: 0.7540 best r: 0.7540
15:57:49,693 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:19,499 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5460
en_de Dev loss: 0.8905 r:0.1793
en_zh Dev loss: 0.8119 r:0.3950
ro_en Dev loss: 0.3896 r:0.7912
et_en Dev loss: 0.3524 r:0.7132
si_en Dev loss: 0.7514 r:0.5937
ne_en Dev loss: 0.4449 r:0.7452
ru_en Dev loss: 0.4541 r:0.7387
Current avg r:0.5938 Best avg r: 0.5980
16:03:48,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:01,802 root INFO 
id:en_de cur r: 0.2191 best r: 0.2191
16:04:27,438 root INFO 
id:ro_en cur r: 0.7925 best r: 0.7925
16:05:18,749 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:48,453 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5270
en_de Dev loss: 0.8635 r:0.1987
en_zh Dev loss: 0.7668 r:0.4119
ro_en Dev loss: 0.3761 r:0.7941
et_en Dev loss: 0.3538 r:0.7106
si_en Dev loss: 0.8739 r:0.5805
ne_en Dev loss: 0.5720 r:0.7300
ru_en Dev loss: 0.4420 r:0.7368
Current avg r:0.5947 Best avg r: 0.5980
16:11:16,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:42,392 root INFO 
id:en_zh cur r: 0.4217 best r: 0.4217
16:11:55,224 root INFO 
id:ro_en cur r: 0.7947 best r: 0.7947
16:12:20,958 root INFO 
id:et_en cur r: 0.7171 best r: 0.7171
16:12:33,804 root INFO 
id:si_en cur r: 0.5982 best r: 0.5982
16:12:46,646 root INFO 
id:ne_en cur r: 0.7563 best r: 0.7563
16:12:59,427 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:29,117 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:14:29,123 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:14:29,127 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:14:29,132 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:14:29,137 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:14:29,142 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:14:29,147 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:14:41,982 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5062
en_de Dev loss: 0.8880 r:0.2030
en_zh Dev loss: 0.7295 r:0.4218
ro_en Dev loss: 0.3430 r:0.7948
et_en Dev loss: 0.3445 r:0.7212
si_en Dev loss: 0.6277 r:0.6042
ne_en Dev loss: 0.4294 r:0.7483
ru_en Dev loss: 0.4205 r:0.7385
Current avg r:0.6045 Best avg r: 0.6045
16:19:10,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:35,859 root INFO 
id:en_zh cur r: 0.4295 best r: 0.4295
16:19:48,710 root INFO 
id:ro_en cur r: 0.8048 best r: 0.8048
16:20:40,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:09,855 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5337
en_de Dev loss: 0.8784 r:0.1981
en_zh Dev loss: 0.7333 r:0.4216
ro_en Dev loss: 0.3398 r:0.8013
et_en Dev loss: 0.3406 r:0.7206
si_en Dev loss: 0.6597 r:0.5970
ne_en Dev loss: 0.4283 r:0.7447
ru_en Dev loss: 0.4512 r:0.7213
Current avg r:0.6007 Best avg r: 0.6045
16:26:39,294 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:04,983 root INFO 
id:en_zh cur r: 0.4589 best r: 0.4589
16:27:43,601 root INFO 
id:si_en cur r: 0.6085 best r: 0.6085
16:27:56,460 root INFO 
id:ne_en cur r: 0.7584 best r: 0.7584
16:28:09,265 root INFO 
id:ru_en cur r: 0.7600 best r: 0.7600
16:28:09,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:39,63 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:29:39,69 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:29:39,74 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:29:39,79 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:29:39,84 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:29:39,89 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:29:39,93 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:29:51,947 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5003
en_de Dev loss: 0.8667 r:0.1935
en_zh Dev loss: 0.7346 r:0.4516
ro_en Dev loss: 0.3845 r:0.8028
et_en Dev loss: 0.3758 r:0.7158
si_en Dev loss: 0.8070 r:0.6016
ne_en Dev loss: 0.5331 r:0.7512
ru_en Dev loss: 0.3976 r:0.7586
Current avg r:0.6107 Best avg r: 0.6107
16:34:20,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:33,56 root INFO 
id:en_de cur r: 0.2248 best r: 0.2248
16:34:58,703 root INFO 
id:ro_en cur r: 0.8117 best r: 0.8117
16:35:24,397 root INFO 
id:et_en cur r: 0.7183 best r: 0.7183
16:35:37,240 root INFO 
id:si_en cur r: 0.6098 best r: 0.6098
16:35:50,93 root INFO 
id:ne_en cur r: 0.7622 best r: 0.7622
16:36:02,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:32,591 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:37:32,597 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:37:32,601 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:37:32,605 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:37:32,610 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:37:32,617 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:37:32,621 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:37:45,466 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5544
en_de Dev loss: 0.8527 r:0.2086
en_zh Dev loss: 0.6927 r:0.4360
ro_en Dev loss: 0.3007 r:0.8092
et_en Dev loss: 0.3376 r:0.7235
si_en Dev loss: 0.6315 r:0.6059
ne_en Dev loss: 0.3945 r:0.7566
ru_en Dev loss: 0.4020 r:0.7472
Current avg r:0.6124 Best avg r: 0.6124
16:42:13,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:26,487 root INFO 
id:en_de cur r: 0.2267 best r: 0.2267
16:42:52,145 root INFO 
id:ro_en cur r: 0.8124 best r: 0.8124
16:43:43,491 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:13,293 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4838
en_de Dev loss: 0.9241 r:0.2033
en_zh Dev loss: 0.8722 r:0.4109
ro_en Dev loss: 0.3692 r:0.8041
et_en Dev loss: 0.3686 r:0.7141
si_en Dev loss: 0.6897 r:0.6006
ne_en Dev loss: 0.4671 r:0.7522
ru_en Dev loss: 0.5328 r:0.7134
Current avg r:0.5998 Best avg r: 0.6124
16:49:41,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:53,925 root INFO 
id:en_de cur r: 0.2274 best r: 0.2274
16:50:06,737 root INFO 
id:en_zh cur r: 0.4743 best r: 0.4743
16:50:19,575 root INFO 
id:ro_en cur r: 0.8221 best r: 0.8221
16:50:45,258 root INFO 
id:et_en cur r: 0.7285 best r: 0.7285
16:50:58,105 root INFO 
id:si_en cur r: 0.6316 best r: 0.6316
16:51:10,959 root INFO 
id:ne_en cur r: 0.7731 best r: 0.7731
16:51:23,746 root INFO 
id:ru_en cur r: 0.7770 best r: 0.7770
16:51:23,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:53,452 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_de.lang_agnost_mlp.dev.best.scores
16:52:53,458 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/en_zh.lang_agnost_mlp.dev.best.scores
16:52:53,463 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ro_en.lang_agnost_mlp.dev.best.scores
16:52:53,468 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/et_en.lang_agnost_mlp.dev.best.scores
16:52:53,473 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/si_en.lang_agnost_mlp.dev.best.scores
16:52:53,479 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ne_en.lang_agnost_mlp.dev.best.scores
16:52:53,483 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run3/ru_en.lang_agnost_mlp.dev.best.scores
16:53:06,332 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4916
en_de Dev loss: 0.8505 r:0.2187
en_zh Dev loss: 0.6600 r:0.4657
ro_en Dev loss: 0.2949 r:0.8196
et_en Dev loss: 0.3561 r:0.7303
si_en Dev loss: 0.5485 r:0.6294
ne_en Dev loss: 0.3227 r:0.7713
ru_en Dev loss: 0.3398 r:0.7726
Current avg r:0.6297 Best avg r: 0.6297
16:57:34,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:59,643 root INFO 
id:en_zh cur r: 0.4798 best r: 0.4798
16:58:12,491 root INFO 
id:ro_en cur r: 0.8230 best r: 0.8230
16:58:50,978 root INFO 
id:ne_en cur r: 0.7763 best r: 0.7763
16:59:03,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:33,446 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4976
en_de Dev loss: 0.8536 r:0.2073
en_zh Dev loss: 0.6556 r:0.4750
ro_en Dev loss: 0.3029 r:0.8203
et_en Dev loss: 0.3463 r:0.7235
si_en Dev loss: 0.5979 r:0.6236
ne_en Dev loss: 0.3427 r:0.7722
ru_en Dev loss: 0.3566 r:0.7683
Current avg r:0.6272 Best avg r: 0.6297
17:05:01,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:13,946 root INFO 
id:en_de cur r: 0.2305 best r: 0.2305
17:06:30,881 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:00,597 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5052
en_de Dev loss: 0.8475 r:0.2168
en_zh Dev loss: 0.6692 r:0.4571
ro_en Dev loss: 0.3128 r:0.8163
et_en Dev loss: 0.3383 r:0.7220
si_en Dev loss: 0.7305 r:0.6054
ne_en Dev loss: 0.3969 r:0.7552
ru_en Dev loss: 0.4080 r:0.7490
Current avg r:0.6174 Best avg r: 0.6297
17:12:28,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:06,708 root INFO 
id:ro_en cur r: 0.8273 best r: 0.8273
17:13:57,975 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:27,639 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4776
en_de Dev loss: 0.8649 r:0.2097
en_zh Dev loss: 0.7287 r:0.4552
ro_en Dev loss: 0.3132 r:0.8229
et_en Dev loss: 0.3427 r:0.7280
si_en Dev loss: 0.6401 r:0.6249
ne_en Dev loss: 0.3663 r:0.7635
ru_en Dev loss: 0.4261 r:0.7495
Current avg r:0.6219 Best avg r: 0.6297
17:19:55,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:24,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:22:54,679 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4816
en_de Dev loss: 0.8650 r:0.1992
en_zh Dev loss: 0.6708 r:0.4659
ro_en Dev loss: 0.3157 r:0.8184
et_en Dev loss: 0.3528 r:0.7235
si_en Dev loss: 0.6098 r:0.6222
ne_en Dev loss: 0.4005 r:0.7635
ru_en Dev loss: 0.4012 r:0.7553
Current avg r:0.6211 Best avg r: 0.6297
17:27:23,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:53,527 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:23,136 root INFO Epoch 2 Global steps: 16100 Train loss: 0.4337
en_de Dev loss: 0.8689 r:0.1914
en_zh Dev loss: 0.7176 r:0.4520
ro_en Dev loss: 0.3677 r:0.8096
et_en Dev loss: 0.3677 r:0.7117
si_en Dev loss: 0.7888 r:0.6063
ne_en Dev loss: 0.5244 r:0.7573
ru_en Dev loss: 0.4764 r:0.7228
Current avg r:0.6073 Best avg r: 0.6297
17:34:50,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:20,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:50,287 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4363
en_de Dev loss: 0.8744 r:0.1948
en_zh Dev loss: 0.7497 r:0.4408
ro_en Dev loss: 0.3621 r:0.8056
et_en Dev loss: 0.3811 r:0.7059
si_en Dev loss: 0.8508 r:0.6022
ne_en Dev loss: 0.5177 r:0.7511
ru_en Dev loss: 0.5216 r:0.6945
Current avg r:0.5993 Best avg r: 0.6297
17:42:17,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:42:30,774 root INFO 
id:en_de cur r: 0.2357 best r: 0.2357
17:43:47,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:45:17,299 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4786
en_de Dev loss: 0.8663 r:0.2021
en_zh Dev loss: 0.7316 r:0.4553
ro_en Dev loss: 0.3222 r:0.8151
et_en Dev loss: 0.3635 r:0.7131
si_en Dev loss: 0.6886 r:0.6182
ne_en Dev loss: 0.4207 r:0.7530
ru_en Dev loss: 0.4510 r:0.7269
Current avg r:0.6120 Best avg r: 0.6297
17:49:44,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:14,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:44,382 root INFO Epoch 2 Global steps: 18200 Train loss: 0.4504
en_de Dev loss: 0.8726 r:0.1949
en_zh Dev loss: 0.7373 r:0.4569
ro_en Dev loss: 0.3486 r:0.8111
et_en Dev loss: 0.3810 r:0.7051
si_en Dev loss: 0.7545 r:0.6057
ne_en Dev loss: 0.4280 r:0.7520
ru_en Dev loss: 0.4866 r:0.7149
Current avg r:0.6058 Best avg r: 0.6297
17:57:12,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:57:24,876 root INFO 
id:en_de cur r: 0.2503 best r: 0.2503
17:58:41,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:11,535 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4429
en_de Dev loss: 0.8530 r:0.2008
en_zh Dev loss: 0.7052 r:0.4410
ro_en Dev loss: 0.3149 r:0.8146
et_en Dev loss: 0.3799 r:0.7093
si_en Dev loss: 0.6165 r:0.6129
ne_en Dev loss: 0.4089 r:0.7463
ru_en Dev loss: 0.4607 r:0.7006
Current avg r:0.6036 Best avg r: 0.6297
18:04:39,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:04,828 root INFO 
id:en_zh cur r: 0.4824 best r: 0.4824
18:05:17,667 root INFO 
id:ro_en cur r: 0.8289 best r: 0.8289
18:06:08,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:38,684 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4656
en_de Dev loss: 0.8675 r:0.1921
en_zh Dev loss: 0.6808 r:0.4677
ro_en Dev loss: 0.2921 r:0.8225
et_en Dev loss: 0.3579 r:0.7067
si_en Dev loss: 0.6186 r:0.6197
ne_en Dev loss: 0.4069 r:0.7642
ru_en Dev loss: 0.4418 r:0.7216
Current avg r:0.6135 Best avg r: 0.6297
18:12:06,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:36,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:05,736 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4638
en_de Dev loss: 0.8589 r:0.1969
en_zh Dev loss: 0.7004 r:0.4671
ro_en Dev loss: 0.3025 r:0.8209
et_en Dev loss: 0.3724 r:0.7022
si_en Dev loss: 0.7253 r:0.6059
ne_en Dev loss: 0.4553 r:0.7489
ru_en Dev loss: 0.4771 r:0.7125
Current avg r:0.6078 Best avg r: 0.6297
18:19:33,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:03,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:32,914 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4550
en_de Dev loss: 0.8738 r:0.2197
en_zh Dev loss: 0.7334 r:0.4514
ro_en Dev loss: 0.3570 r:0.8158
et_en Dev loss: 0.3860 r:0.7084
si_en Dev loss: 0.8069 r:0.5998
ne_en Dev loss: 0.5204 r:0.7479
ru_en Dev loss: 0.4830 r:0.7266
Current avg r:0.6100 Best avg r: 0.6297
18:27:00,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:13,413 root INFO 
id:en_de cur r: 0.2587 best r: 0.2587
18:27:39,59 root INFO 
id:ro_en cur r: 0.8318 best r: 0.8318
18:28:30,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:00,115 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4315
en_de Dev loss: 0.8536 r:0.2342
en_zh Dev loss: 0.6844 r:0.4649
ro_en Dev loss: 0.2868 r:0.8270
et_en Dev loss: 0.3472 r:0.7259
si_en Dev loss: 0.6299 r:0.6183
ne_en Dev loss: 0.3970 r:0.7603
ru_en Dev loss: 0.4122 r:0.7418
Current avg r:0.6246 Best avg r: 0.6297
18:34:27,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:57,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:37:27,189 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4454
en_de Dev loss: 0.8664 r:0.2174
en_zh Dev loss: 0.7582 r:0.4451
ro_en Dev loss: 0.3431 r:0.8138
et_en Dev loss: 0.3666 r:0.7064
si_en Dev loss: 0.8191 r:0.5908
ne_en Dev loss: 0.5116 r:0.7472
ru_en Dev loss: 0.4690 r:0.7196
Current avg r:0.6058 Best avg r: 0.6297
18:41:54,734 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:24,465 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:54,198 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4343
en_de Dev loss: 0.8566 r:0.2233
en_zh Dev loss: 0.7150 r:0.4493
ro_en Dev loss: 0.3252 r:0.8136
et_en Dev loss: 0.3612 r:0.7111
si_en Dev loss: 0.7219 r:0.6061
ne_en Dev loss: 0.4749 r:0.7533
ru_en Dev loss: 0.4127 r:0.7332
Current avg r:0.6128 Best avg r: 0.6297
18:49:21,767 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:51,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:52:21,197 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4638
en_de Dev loss: 0.8618 r:0.2030
en_zh Dev loss: 0.7130 r:0.4712
ro_en Dev loss: 0.3013 r:0.8283
et_en Dev loss: 0.3608 r:0.7263
si_en Dev loss: 0.6424 r:0.6206
ne_en Dev loss: 0.3765 r:0.7604
ru_en Dev loss: 0.4230 r:0.7435
Current avg r:0.6219 Best avg r: 0.6297
18:56:50,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:58:19,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:49,641 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4454
en_de Dev loss: 0.8552 r:0.2037
en_zh Dev loss: 0.7131 r:0.4480
ro_en Dev loss: 0.2876 r:0.8253
et_en Dev loss: 0.3600 r:0.7155
si_en Dev loss: 0.6820 r:0.6128
ne_en Dev loss: 0.4709 r:0.7490
ru_en Dev loss: 0.4108 r:0.7352
Current avg r:0.6128 Best avg r: 0.6297
19:04:17,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:47,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:07:16,741 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4139
en_de Dev loss: 0.8609 r:0.2076
en_zh Dev loss: 0.7495 r:0.4433
ro_en Dev loss: 0.3379 r:0.8150
et_en Dev loss: 0.3890 r:0.7082
si_en Dev loss: 0.7188 r:0.5989
ne_en Dev loss: 0.4754 r:0.7537
ru_en Dev loss: 0.4373 r:0.7259
Current avg r:0.6075 Best avg r: 0.6297
19:11:44,341 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:13:14,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:43,858 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4064
en_de Dev loss: 0.8758 r:0.1885
en_zh Dev loss: 0.7816 r:0.4111
ro_en Dev loss: 0.3284 r:0.8184
et_en Dev loss: 0.3868 r:0.7154
si_en Dev loss: 0.6832 r:0.6035
ne_en Dev loss: 0.4218 r:0.7490
ru_en Dev loss: 0.4519 r:0.7295
Current avg r:0.6022 Best avg r: 0.6297
19:19:11,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:20:41,122 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:22:10,849 root INFO Epoch 3 Global steps: 26600 Train loss: 0.3826
en_de Dev loss: 0.8567 r:0.2182
en_zh Dev loss: 0.7080 r:0.4435
ro_en Dev loss: 0.3142 r:0.8227
et_en Dev loss: 0.3698 r:0.7126
si_en Dev loss: 0.6994 r:0.5971
ne_en Dev loss: 0.4479 r:0.7462
ru_en Dev loss: 0.4549 r:0.7263
Current avg r:0.6095 Best avg r: 0.6297
19:26:38,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:26:51,218 root INFO 
id:en_de cur r: 0.2679 best r: 0.2679
19:28:08,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:37,872 root INFO Epoch 3 Global steps: 27300 Train loss: 0.3933
en_de Dev loss: 0.8419 r:0.2421
en_zh Dev loss: 0.7270 r:0.4556
ro_en Dev loss: 0.3318 r:0.8244
et_en Dev loss: 0.3826 r:0.7139
si_en Dev loss: 0.7082 r:0.6124
ne_en Dev loss: 0.4197 r:0.7581
ru_en Dev loss: 0.3962 r:0.7621
Current avg r:0.6241 Best avg r: 0.6297
19:34:05,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:35,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:37:04,774 root INFO Epoch 3 Global steps: 28000 Train loss: 0.4220
en_de Dev loss: 0.8716 r:0.2284
en_zh Dev loss: 0.7494 r:0.4393
ro_en Dev loss: 0.3393 r:0.8178
et_en Dev loss: 0.3879 r:0.6963
si_en Dev loss: 0.8644 r:0.5821
ne_en Dev loss: 0.4962 r:0.7463
ru_en Dev loss: 0.4331 r:0.7374
Current avg r:0.6068 Best avg r: 0.6297
19:41:32,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:57,981 root INFO 
id:en_zh cur r: 0.4854 best r: 0.4854
19:42:10,822 root INFO 
id:ro_en cur r: 0.8335 best r: 0.8335
19:43:02,138 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:31,848 root INFO Epoch 3 Global steps: 28700 Train loss: 0.4042
en_de Dev loss: 0.8501 r:0.2226
en_zh Dev loss: 0.6810 r:0.4724
ro_en Dev loss: 0.3058 r:0.8286
et_en Dev loss: 0.4117 r:0.7203
si_en Dev loss: 0.5993 r:0.6209
ne_en Dev loss: 0.3554 r:0.7589
ru_en Dev loss: 0.3674 r:0.7624
Current avg r:0.6266 Best avg r: 0.6297
19:48:59,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:29,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:58,801 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3775
en_de Dev loss: 0.8566 r:0.2101
en_zh Dev loss: 0.7422 r:0.4534
ro_en Dev loss: 0.3409 r:0.8196
et_en Dev loss: 0.3901 r:0.7070
si_en Dev loss: 0.7172 r:0.6088
ne_en Dev loss: 0.4287 r:0.7576
ru_en Dev loss: 0.4382 r:0.7434
Current avg r:0.6143 Best avg r: 0.6297
19:56:26,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:56,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:25,743 root INFO Epoch 3 Global steps: 30100 Train loss: 0.3939
en_de Dev loss: 0.8657 r:0.2191
en_zh Dev loss: 0.7259 r:0.4609
ro_en Dev loss: 0.3354 r:0.8201
et_en Dev loss: 0.3801 r:0.6985
si_en Dev loss: 0.8400 r:0.5913
ne_en Dev loss: 0.6066 r:0.7561
ru_en Dev loss: 0.4796 r:0.7256
Current avg r:0.6102 Best avg r: 0.6297
20:03:54,104 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:23,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:53,645 root INFO Epoch 3 Global steps: 30800 Train loss: 0.3764
en_de Dev loss: 0.8705 r:0.2025
en_zh Dev loss: 0.6868 r:0.4744
ro_en Dev loss: 0.3029 r:0.8293
et_en Dev loss: 0.3679 r:0.7156
si_en Dev loss: 0.6534 r:0.6138
ne_en Dev loss: 0.4076 r:0.7592
ru_en Dev loss: 0.4126 r:0.7434
Current avg r:0.6198 Best avg r: 0.6297
20:11:22,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:52,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:21,890 root INFO Epoch 3 Global steps: 31500 Train loss: 0.3721
en_de Dev loss: 0.8572 r:0.2067
en_zh Dev loss: 0.7210 r:0.4556
ro_en Dev loss: 0.3177 r:0.8239
et_en Dev loss: 0.3746 r:0.7110
si_en Dev loss: 0.7392 r:0.5977
ne_en Dev loss: 0.4460 r:0.7610
ru_en Dev loss: 0.4294 r:0.7339
Current avg r:0.6128 Best avg r: 0.6297
20:18:50,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:20,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:50,250 root INFO Epoch 4 Global steps: 32200 Train loss: 0.3650
en_de Dev loss: 0.8969 r:0.2014
en_zh Dev loss: 0.7864 r:0.4341
ro_en Dev loss: 0.3672 r:0.8191
et_en Dev loss: 0.4146 r:0.6910
si_en Dev loss: 0.8034 r:0.5938
ne_en Dev loss: 0.5238 r:0.7451
ru_en Dev loss: 0.5166 r:0.7107
Current avg r:0.5993 Best avg r: 0.6297
20:26:17,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:47,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:17,245 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3623
en_de Dev loss: 0.8770 r:0.2090
en_zh Dev loss: 0.7900 r:0.4323
ro_en Dev loss: 0.3459 r:0.8163
et_en Dev loss: 0.4093 r:0.6944
si_en Dev loss: 0.8348 r:0.5811
ne_en Dev loss: 0.4812 r:0.7505
ru_en Dev loss: 0.4873 r:0.7087
Current avg r:0.5989 Best avg r: 0.6297
20:33:44,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:14,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:44,295 root INFO Epoch 4 Global steps: 33600 Train loss: 0.3444
en_de Dev loss: 0.8547 r:0.2113
en_zh Dev loss: 0.7399 r:0.4268
ro_en Dev loss: 0.3119 r:0.8224
et_en Dev loss: 0.4147 r:0.6956
si_en Dev loss: 0.6959 r:0.5846
ne_en Dev loss: 0.4168 r:0.7460
ru_en Dev loss: 0.4164 r:0.7289
Current avg r:0.6022 Best avg r: 0.6297
20:41:11,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:41,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:11,186 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3341
en_de Dev loss: 0.8677 r:0.2131
en_zh Dev loss: 0.7597 r:0.4448
ro_en Dev loss: 0.3341 r:0.8213
et_en Dev loss: 0.4293 r:0.7032
si_en Dev loss: 0.6453 r:0.6092
ne_en Dev loss: 0.4052 r:0.7482
ru_en Dev loss: 0.4408 r:0.7308
Current avg r:0.6101 Best avg r: 0.6297
20:48:38,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:08,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:38,162 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3568
en_de Dev loss: 0.8678 r:0.1927
en_zh Dev loss: 0.7291 r:0.4721
ro_en Dev loss: 0.3387 r:0.8222
et_en Dev loss: 0.4321 r:0.6996
si_en Dev loss: 0.6308 r:0.6145
ne_en Dev loss: 0.3719 r:0.7560
ru_en Dev loss: 0.3927 r:0.7541
Current avg r:0.6159 Best avg r: 0.6297
20:56:05,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:35,457 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:05,182 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3487
en_de Dev loss: 0.8732 r:0.1759
en_zh Dev loss: 0.7491 r:0.4405
ro_en Dev loss: 0.3379 r:0.8173
et_en Dev loss: 0.4664 r:0.6933
si_en Dev loss: 0.6243 r:0.6059
ne_en Dev loss: 0.3919 r:0.7477
ru_en Dev loss: 0.4130 r:0.7310
Current avg r:0.6017 Best avg r: 0.6297
21:03:32,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:02,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:32,210 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3499
en_de Dev loss: 0.8688 r:0.1963
en_zh Dev loss: 0.8220 r:0.4352
ro_en Dev loss: 0.3636 r:0.8174
et_en Dev loss: 0.4156 r:0.6865
si_en Dev loss: 0.7958 r:0.5940
ne_en Dev loss: 0.5025 r:0.7514
ru_en Dev loss: 0.5104 r:0.7074
Current avg r:0.5983 Best avg r: 0.6297
21:10:59,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:29,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:13:59,148 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3474
en_de Dev loss: 0.8943 r:0.1666
en_zh Dev loss: 0.7627 r:0.4514
ro_en Dev loss: 0.3323 r:0.8264
et_en Dev loss: 0.4155 r:0.6948
si_en Dev loss: 0.7725 r:0.6035
ne_en Dev loss: 0.6055 r:0.7378
ru_en Dev loss: 0.4718 r:0.7296
Current avg r:0.6014 Best avg r: 0.6297
21:18:26,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:19:56,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:26,161 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3705
en_de Dev loss: 0.8904 r:0.1768
en_zh Dev loss: 0.7477 r:0.4508
ro_en Dev loss: 0.3294 r:0.8270
et_en Dev loss: 0.4195 r:0.7055
si_en Dev loss: 0.7182 r:0.6096
ne_en Dev loss: 0.4225 r:0.7525
ru_en Dev loss: 0.4307 r:0.7439
Current avg r:0.6094 Best avg r: 0.6297
21:25:53,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:23,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:28:53,181 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3397
en_de Dev loss: 0.8761 r:0.1834
en_zh Dev loss: 0.7497 r:0.4404
ro_en Dev loss: 0.3212 r:0.8201
et_en Dev loss: 0.4076 r:0.6890
si_en Dev loss: 0.7613 r:0.5953
ne_en Dev loss: 0.5054 r:0.7440
ru_en Dev loss: 0.4441 r:0.7198
Current avg r:0.5989 Best avg r: 0.6297
21:33:20,704 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:34:50,421 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:20,86 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3477
en_de Dev loss: 0.8673 r:0.1884
en_zh Dev loss: 0.7317 r:0.4439
ro_en Dev loss: 0.3266 r:0.8238
et_en Dev loss: 0.3958 r:0.6997
si_en Dev loss: 0.7121 r:0.5983
ne_en Dev loss: 0.4475 r:0.7502
ru_en Dev loss: 0.4312 r:0.7354
Current avg r:0.6057 Best avg r: 0.6297
21:40:48,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:18,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:43:48,252 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3107
en_de Dev loss: 0.8748 r:0.1818
en_zh Dev loss: 0.8038 r:0.4434
ro_en Dev loss: 0.3651 r:0.8222
et_en Dev loss: 0.4230 r:0.6970
si_en Dev loss: 0.7460 r:0.5999
ne_en Dev loss: 0.4249 r:0.7484
ru_en Dev loss: 0.4652 r:0.7321
Current avg r:0.6035 Best avg r: 0.6297
21:48:15,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:45,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:15,281 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3312
en_de Dev loss: 0.8598 r:0.1897
en_zh Dev loss: 0.7273 r:0.4494
ro_en Dev loss: 0.3053 r:0.8248
et_en Dev loss: 0.4079 r:0.7004
si_en Dev loss: 0.6647 r:0.6080
ne_en Dev loss: 0.4126 r:0.7435
ru_en Dev loss: 0.4339 r:0.7282
Current avg r:0.6063 Best avg r: 0.6297
21:55:42,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:12,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:58:42,243 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3145
en_de Dev loss: 0.8778 r:0.1712
en_zh Dev loss: 0.7425 r:0.4497
ro_en Dev loss: 0.3285 r:0.8233
et_en Dev loss: 0.4044 r:0.6892
si_en Dev loss: 0.7343 r:0.6026
ne_en Dev loss: 0.5033 r:0.7439
ru_en Dev loss: 0.4508 r:0.7304
Current avg r:0.6015 Best avg r: 0.6297
22:03:10,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:04:40,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:10,23 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3152
en_de Dev loss: 0.8757 r:0.1855
en_zh Dev loss: 0.7995 r:0.4336
ro_en Dev loss: 0.3465 r:0.8206
et_en Dev loss: 0.4347 r:0.6888
si_en Dev loss: 0.7766 r:0.5888
ne_en Dev loss: 0.4989 r:0.7361
ru_en Dev loss: 0.4802 r:0.7230
Current avg r:0.5966 Best avg r: 0.6297
22:10:38,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:08,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:13:38,432 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3305
en_de Dev loss: 0.8641 r:0.1751
en_zh Dev loss: 0.7398 r:0.4291
ro_en Dev loss: 0.3242 r:0.8193
et_en Dev loss: 0.4018 r:0.6819
si_en Dev loss: 0.8397 r:0.5703
ne_en Dev loss: 0.5685 r:0.7299
ru_en Dev loss: 0.4541 r:0.7113
Current avg r:0.5881 Best avg r: 0.6297
22:18:06,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:19:36,739 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:21:06,519 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3152
en_de Dev loss: 0.8748 r:0.1870
en_zh Dev loss: 0.7986 r:0.4249
ro_en Dev loss: 0.3564 r:0.8133
et_en Dev loss: 0.4238 r:0.6774
si_en Dev loss: 0.7794 r:0.5822
ne_en Dev loss: 0.4784 r:0.7367
ru_en Dev loss: 0.5143 r:0.6911
Current avg r:0.5875 Best avg r: 0.6297
22:25:34,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:27:04,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:28:34,612 root INFO Epoch 5 Global steps: 44100 Train loss: 0.2925
en_de Dev loss: 0.8793 r:0.1796
en_zh Dev loss: 0.7798 r:0.4199
ro_en Dev loss: 0.3443 r:0.8133
et_en Dev loss: 0.4390 r:0.6713
si_en Dev loss: 0.8303 r:0.5776
ne_en Dev loss: 0.5122 r:0.7364
ru_en Dev loss: 0.4790 r:0.7029
Current avg r:0.5859 Best avg r: 0.6297
22:33:03,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:34:32,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:02,624 root INFO Epoch 5 Global steps: 44800 Train loss: 0.2959
en_de Dev loss: 0.8700 r:0.1860
en_zh Dev loss: 0.7697 r:0.4330
ro_en Dev loss: 0.3262 r:0.8201
et_en Dev loss: 0.4305 r:0.6727
si_en Dev loss: 0.8104 r:0.5848
ne_en Dev loss: 0.4860 r:0.7406
ru_en Dev loss: 0.4655 r:0.7075
Current avg r:0.5921 Best avg r: 0.6297
22:40:30,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:00,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:43:30,698 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3235
en_de Dev loss: 0.8613 r:0.2005
en_zh Dev loss: 0.7613 r:0.4423
ro_en Dev loss: 0.3444 r:0.8185
et_en Dev loss: 0.4372 r:0.6836
si_en Dev loss: 0.8165 r:0.5884
ne_en Dev loss: 0.5286 r:0.7366
ru_en Dev loss: 0.4800 r:0.7105
Current avg r:0.5972 Best avg r: 0.6297
22:47:59,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:49:29,29 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:58,807 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3090
en_de Dev loss: 0.8683 r:0.1997
en_zh Dev loss: 0.7459 r:0.4503
ro_en Dev loss: 0.3278 r:0.8236
et_en Dev loss: 0.4533 r:0.6851
si_en Dev loss: 0.7138 r:0.5905
ne_en Dev loss: 0.5167 r:0.7322
ru_en Dev loss: 0.4319 r:0.7306
Current avg r:0.6017 Best avg r: 0.6297
22:55:27,331 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:57,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:58:26,914 root INFO Epoch 5 Global steps: 46900 Train loss: 0.2878
en_de Dev loss: 0.8933 r:0.1796
en_zh Dev loss: 0.7840 r:0.4263
ro_en Dev loss: 0.3420 r:0.8204
et_en Dev loss: 0.4429 r:0.6802
si_en Dev loss: 0.7636 r:0.5774
ne_en Dev loss: 0.5358 r:0.7347
ru_en Dev loss: 0.5113 r:0.6935
Current avg r:0.5874 Best avg r: 0.6297
23:02:55,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:04:25,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:55,1 root INFO Epoch 5 Global steps: 47600 Train loss: 0.2929
en_de Dev loss: 0.8780 r:0.1957
en_zh Dev loss: 0.8092 r:0.4300
ro_en Dev loss: 0.3492 r:0.8201
et_en Dev loss: 0.4606 r:0.6776
si_en Dev loss: 0.7063 r:0.5926
ne_en Dev loss: 0.4750 r:0.7351
ru_en Dev loss: 0.4712 r:0.7153
Current avg r:0.5952 Best avg r: 0.6297
23:10:24,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:54,636 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:13:24,470 root INFO Epoch 6 Global steps: 48300 Train loss: 0.2802
en_de Dev loss: 0.8666 r:0.1986
en_zh Dev loss: 0.7901 r:0.4369
ro_en Dev loss: 0.3258 r:0.8216
et_en Dev loss: 0.4391 r:0.6816
si_en Dev loss: 0.7473 r:0.5800
ne_en Dev loss: 0.5166 r:0.7378
ru_en Dev loss: 0.4547 r:0.7188
Current avg r:0.5965 Best avg r: 0.6297
23:17:52,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:19:22,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:52,429 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2724
en_de Dev loss: 0.8879 r:0.1675
en_zh Dev loss: 0.8189 r:0.4327
ro_en Dev loss: 0.3686 r:0.8211
et_en Dev loss: 0.4757 r:0.6744
si_en Dev loss: 0.8737 r:0.5778
ne_en Dev loss: 0.6093 r:0.7362
ru_en Dev loss: 0.4985 r:0.7181
Current avg r:0.5897 Best avg r: 0.6297
23:25:20,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:50,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:28:20,528 root INFO Epoch 6 Global steps: 49700 Train loss: 0.2714
en_de Dev loss: 0.8732 r:0.1821
en_zh Dev loss: 0.7873 r:0.4330
ro_en Dev loss: 0.3493 r:0.8240
et_en Dev loss: 0.4664 r:0.6756
si_en Dev loss: 0.7514 r:0.5833
ne_en Dev loss: 0.4733 r:0.7378
ru_en Dev loss: 0.4816 r:0.7122
Current avg r:0.5926 Best avg r: 0.6297
23:32:48,951 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:34:18,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:48,672 root INFO Epoch 6 Global steps: 50400 Train loss: 0.2824
en_de Dev loss: 0.9176 r:0.1604
en_zh Dev loss: 0.9063 r:0.3947
ro_en Dev loss: 0.4046 r:0.8112
et_en Dev loss: 0.4783 r:0.6641
si_en Dev loss: 1.0253 r:0.5555
ne_en Dev loss: 0.6466 r:0.7277
ru_en Dev loss: 0.5790 r:0.6840
Current avg r:0.5711 Best avg r: 0.6297
23:40:17,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:46,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:43:16,681 root INFO Epoch 6 Global steps: 51100 Train loss: 0.2942
en_de Dev loss: 0.8741 r:0.1852
en_zh Dev loss: 0.7877 r:0.4374
ro_en Dev loss: 0.3647 r:0.8175
et_en Dev loss: 0.4861 r:0.6765
si_en Dev loss: 0.7847 r:0.5825
ne_en Dev loss: 0.4648 r:0.7346
ru_en Dev loss: 0.5012 r:0.7041
Current avg r:0.5911 Best avg r: 0.6297
23:47:45,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:49:14,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:44,754 root INFO Epoch 6 Global steps: 51800 Train loss: 0.2636
en_de Dev loss: 0.8822 r:0.1580
en_zh Dev loss: 0.7986 r:0.4070
ro_en Dev loss: 0.3433 r:0.8126
et_en Dev loss: 0.4554 r:0.6603
si_en Dev loss: 0.7867 r:0.5626
ne_en Dev loss: 0.5867 r:0.7220
ru_en Dev loss: 0.4788 r:0.6935
Current avg r:0.5737 Best avg r: 0.6297
23:55:13,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:43,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:12,983 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2785
en_de Dev loss: 0.8711 r:0.1843
en_zh Dev loss: 0.7847 r:0.4391
ro_en Dev loss: 0.3440 r:0.8230
et_en Dev loss: 0.5051 r:0.6712
si_en Dev loss: 0.7313 r:0.5837
ne_en Dev loss: 0.4713 r:0.7251
ru_en Dev loss: 0.4404 r:0.7240
Current avg r:0.5929 Best avg r: 0.6297
00:02:41,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:11,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:41,158 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2650
en_de Dev loss: 0.8760 r:0.1774
en_zh Dev loss: 0.7968 r:0.4399
ro_en Dev loss: 0.3448 r:0.8208
et_en Dev loss: 0.4915 r:0.6699
si_en Dev loss: 0.8047 r:0.5667
ne_en Dev loss: 0.4860 r:0.7271
ru_en Dev loss: 0.4508 r:0.7219
Current avg r:0.5891 Best avg r: 0.6297
00:10:09,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:39,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:13:09,239 root INFO Epoch 6 Global steps: 53900 Train loss: 0.2803
en_de Dev loss: 0.8662 r:0.1857
en_zh Dev loss: 0.7711 r:0.4475
ro_en Dev loss: 0.3278 r:0.8215
et_en Dev loss: 0.4593 r:0.6714
si_en Dev loss: 0.7528 r:0.5810
ne_en Dev loss: 0.4957 r:0.7277
ru_en Dev loss: 0.4687 r:0.7164
Current avg r:0.5930 Best avg r: 0.6297
00:17:37,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:06,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:36,633 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2704
en_de Dev loss: 0.8891 r:0.1692
en_zh Dev loss: 0.7775 r:0.4479
ro_en Dev loss: 0.3289 r:0.8217
et_en Dev loss: 0.4631 r:0.6693
si_en Dev loss: 0.7971 r:0.5754
ne_en Dev loss: 0.5037 r:0.7249
ru_en Dev loss: 0.4589 r:0.7254
Current avg r:0.5905 Best avg r: 0.6297
00:25:04,781 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:34,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:28:04,383 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2662
en_de Dev loss: 0.8858 r:0.1955
en_zh Dev loss: 0.7823 r:0.4261
ro_en Dev loss: 0.3204 r:0.8221
et_en Dev loss: 0.4446 r:0.6748
si_en Dev loss: 0.6857 r:0.5832
ne_en Dev loss: 0.4710 r:0.7260
ru_en Dev loss: 0.4692 r:0.7174
Current avg r:0.5921 Best avg r: 0.6297
00:32:34,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:04,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:33,973 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2405
en_de Dev loss: 0.8854 r:0.1744
en_zh Dev loss: 0.8037 r:0.4221
ro_en Dev loss: 0.3540 r:0.8162
et_en Dev loss: 0.4570 r:0.6667
si_en Dev loss: 0.8319 r:0.5680
ne_en Dev loss: 0.5850 r:0.7243
ru_en Dev loss: 0.4896 r:0.7089
Current avg r:0.5829 Best avg r: 0.6297
00:40:02,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:32,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:02,83 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2337
en_de Dev loss: 0.8800 r:0.1968
en_zh Dev loss: 0.7988 r:0.4417
ro_en Dev loss: 0.3596 r:0.8167
et_en Dev loss: 0.5078 r:0.6648
si_en Dev loss: 0.7678 r:0.5770
ne_en Dev loss: 0.5132 r:0.7170
ru_en Dev loss: 0.4850 r:0.7141
Current avg r:0.5897 Best avg r: 0.6297
00:47:30,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:00,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:30,41 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2596
en_de Dev loss: 0.8732 r:0.1816
en_zh Dev loss: 0.7639 r:0.4460
ro_en Dev loss: 0.3421 r:0.8208
et_en Dev loss: 0.4739 r:0.6652
si_en Dev loss: 0.7784 r:0.5681
ne_en Dev loss: 0.4777 r:0.7262
ru_en Dev loss: 0.4618 r:0.7159
Current avg r:0.5891 Best avg r: 0.6297
00:54:58,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:28,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:58,92 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2497
en_de Dev loss: 0.8742 r:0.1679
en_zh Dev loss: 0.7807 r:0.4345
ro_en Dev loss: 0.3356 r:0.8193
et_en Dev loss: 0.4818 r:0.6670
si_en Dev loss: 0.7909 r:0.5680
ne_en Dev loss: 0.5344 r:0.7168
ru_en Dev loss: 0.4645 r:0.7128
Current avg r:0.5838 Best avg r: 0.6297
01:02:26,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:56,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:26,175 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2345
en_de Dev loss: 0.8861 r:0.1841
en_zh Dev loss: 0.7738 r:0.4461
ro_en Dev loss: 0.3337 r:0.8226
et_en Dev loss: 0.4628 r:0.6717
si_en Dev loss: 0.7613 r:0.5812
ne_en Dev loss: 0.4613 r:0.7264
ru_en Dev loss: 0.4688 r:0.7180
Current avg r:0.5929 Best avg r: 0.6297
01:09:54,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:24,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:54,198 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2503
en_de Dev loss: 0.8976 r:0.1724
en_zh Dev loss: 0.8088 r:0.4268
ro_en Dev loss: 0.3509 r:0.8173
et_en Dev loss: 0.4507 r:0.6620
si_en Dev loss: 0.8766 r:0.5609
ne_en Dev loss: 0.5854 r:0.7173
ru_en Dev loss: 0.4890 r:0.7125
Current avg r:0.5813 Best avg r: 0.6297
01:17:22,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:18:52,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:20:22,192 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2380
en_de Dev loss: 0.8930 r:0.1769
en_zh Dev loss: 0.7990 r:0.4368
ro_en Dev loss: 0.3529 r:0.8200
et_en Dev loss: 0.4969 r:0.6713
si_en Dev loss: 0.7879 r:0.5757
ne_en Dev loss: 0.5149 r:0.7196
ru_en Dev loss: 0.4485 r:0.7317
Current avg r:0.5903 Best avg r: 0.6297
01:24:49,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:26:19,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:27:49,165 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2446
en_de Dev loss: 0.8962 r:0.1715
en_zh Dev loss: 0.8144 r:0.4361
ro_en Dev loss: 0.3604 r:0.8170
et_en Dev loss: 0.4718 r:0.6647
si_en Dev loss: 0.8787 r:0.5658
ne_en Dev loss: 0.5906 r:0.7138
ru_en Dev loss: 0.5073 r:0.7047
Current avg r:0.5819 Best avg r: 0.6297
01:32:16,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:33:46,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:35:16,113 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2494
en_de Dev loss: 0.8810 r:0.1685
en_zh Dev loss: 0.7701 r:0.4380
ro_en Dev loss: 0.3479 r:0.8174
et_en Dev loss: 0.4642 r:0.6647
si_en Dev loss: 0.7906 r:0.5748
ne_en Dev loss: 0.5032 r:0.7158
ru_en Dev loss: 0.4716 r:0.7118
Current avg r:0.5844 Best avg r: 0.6297
01:39:43,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:41:13,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:42:42,859 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2413
en_de Dev loss: 0.8770 r:0.1853
en_zh Dev loss: 0.7538 r:0.4471
ro_en Dev loss: 0.3453 r:0.8168
et_en Dev loss: 0.4609 r:0.6578
si_en Dev loss: 0.7919 r:0.5599
ne_en Dev loss: 0.5153 r:0.7163
ru_en Dev loss: 0.4862 r:0.7035
Current avg r:0.5838 Best avg r: 0.6297
01:47:10,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:48:40,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:50:09,960 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2356
en_de Dev loss: 0.8895 r:0.1841
en_zh Dev loss: 0.7688 r:0.4585
ro_en Dev loss: 0.3316 r:0.8305
et_en Dev loss: 0.4822 r:0.6783
si_en Dev loss: 0.7428 r:0.5824
ne_en Dev loss: 0.4719 r:0.7224
ru_en Dev loss: 0.4221 r:0.7425
Current avg r:0.5998 Best avg r: 0.6297
01:54:38,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:56:08,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:57:38,142 root INFO Epoch 8 Global steps: 63700 Train loss: 0.2073
en_de Dev loss: 0.9045 r:0.1674
en_zh Dev loss: 0.7844 r:0.4598
ro_en Dev loss: 0.3398 r:0.8255
et_en Dev loss: 0.4742 r:0.6770
si_en Dev loss: 0.8141 r:0.5729
ne_en Dev loss: 0.5273 r:0.7168
ru_en Dev loss: 0.4535 r:0.7362
Current avg r:0.5937 Best avg r: 0.6297
02:02:06,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:03:36,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:05:07,30 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2173
en_de Dev loss: 0.8821 r:0.1903
en_zh Dev loss: 0.7528 r:0.4569
ro_en Dev loss: 0.3244 r:0.8230
et_en Dev loss: 0.4697 r:0.6625
si_en Dev loss: 0.8159 r:0.5548
ne_en Dev loss: 0.5584 r:0.7087
ru_en Dev loss: 0.4574 r:0.7170
Current avg r:0.5876 Best avg r: 0.6297
02:09:36,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:11:07,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:12:37,114 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2172
en_de Dev loss: 0.8914 r:0.2086
en_zh Dev loss: 0.7767 r:0.4685
ro_en Dev loss: 0.3503 r:0.8280
et_en Dev loss: 0.4689 r:0.6820
si_en Dev loss: 0.8365 r:0.5671
ne_en Dev loss: 0.5525 r:0.7070
ru_en Dev loss: 0.4642 r:0.7438
Current avg r:0.6007 Best avg r: 0.6297
02:17:07,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:18:37,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:20:07,478 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2362
en_de Dev loss: 0.8877 r:0.1709
en_zh Dev loss: 0.7952 r:0.4419
ro_en Dev loss: 0.3435 r:0.8247
et_en Dev loss: 0.4503 r:0.6701
si_en Dev loss: 0.8135 r:0.5609
ne_en Dev loss: 0.6207 r:0.7098
ru_en Dev loss: 0.5119 r:0.7112
Current avg r:0.5842 Best avg r: 0.6297
02:24:37,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:25:15,750 root INFO 
id:ro_en cur r: 0.8337 best r: 0.8337
02:26:07,250 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:37,287 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2093
en_de Dev loss: 0.8994 r:0.1716
en_zh Dev loss: 0.7926 r:0.4433
ro_en Dev loss: 0.3378 r:0.8261
et_en Dev loss: 0.4721 r:0.6698
si_en Dev loss: 0.8640 r:0.5452
ne_en Dev loss: 0.6018 r:0.6974
ru_en Dev loss: 0.4670 r:0.7266
Current avg r:0.5829 Best avg r: 0.6297
02:32:05,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:33:35,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:35:05,691 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2154
en_de Dev loss: 0.8920 r:0.1761
en_zh Dev loss: 0.7783 r:0.4555
ro_en Dev loss: 0.3509 r:0.8239
et_en Dev loss: 0.4624 r:0.6735
si_en Dev loss: 0.7799 r:0.5600
ne_en Dev loss: 0.4983 r:0.7148
ru_en Dev loss: 0.4525 r:0.7346
Current avg r:0.5912 Best avg r: 0.6297
02:39:34,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:41:04,66 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:42:33,844 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2158
en_de Dev loss: 0.8882 r:0.2234
en_zh Dev loss: 0.7730 r:0.4629
ro_en Dev loss: 0.3589 r:0.8207
et_en Dev loss: 0.4611 r:0.6649
si_en Dev loss: 0.8891 r:0.5534
ne_en Dev loss: 0.5869 r:0.7089
ru_en Dev loss: 0.4911 r:0.7190
Current avg r:0.5933 Best avg r: 0.6297
02:47:01,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:48:33,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:50:03,141 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2142
en_de Dev loss: 0.8795 r:0.2194
en_zh Dev loss: 0.8004 r:0.4592
ro_en Dev loss: 0.3681 r:0.8204
et_en Dev loss: 0.4943 r:0.6641
si_en Dev loss: 0.9157 r:0.5512
ne_en Dev loss: 0.5621 r:0.7203
ru_en Dev loss: 0.4711 r:0.7270
Current avg r:0.5945 Best avg r: 0.6297
02:54:30,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:00,745 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:57:30,513 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2186
en_de Dev loss: 0.8788 r:0.2056
en_zh Dev loss: 0.7465 r:0.4651
ro_en Dev loss: 0.3187 r:0.8264
et_en Dev loss: 0.4525 r:0.6734
si_en Dev loss: 0.8085 r:0.5718
ne_en Dev loss: 0.4970 r:0.7176
ru_en Dev loss: 0.4318 r:0.7385
Current avg r:0.5998 Best avg r: 0.6297
03:01:58,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:28,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:57,874 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2073
en_de Dev loss: 0.8990 r:0.1790
en_zh Dev loss: 0.8145 r:0.4428
ro_en Dev loss: 0.3800 r:0.8172
et_en Dev loss: 0.4855 r:0.6561
si_en Dev loss: 0.8723 r:0.5570
ne_en Dev loss: 0.5550 r:0.7184
ru_en Dev loss: 0.5111 r:0.7087
Current avg r:0.5828 Best avg r: 0.6297
03:09:25,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:55,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:12:25,85 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2114
en_de Dev loss: 0.9002 r:0.1801
en_zh Dev loss: 0.7840 r:0.4573
ro_en Dev loss: 0.3420 r:0.8229
et_en Dev loss: 0.4754 r:0.6539
si_en Dev loss: 0.9066 r:0.5563
ne_en Dev loss: 0.6204 r:0.7087
ru_en Dev loss: 0.4710 r:0.7300
Current avg r:0.5870 Best avg r: 0.6297
03:16:52,924 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:18:22,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:52,677 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2140
en_de Dev loss: 0.8910 r:0.1836
en_zh Dev loss: 0.7958 r:0.4570
ro_en Dev loss: 0.3388 r:0.8252
et_en Dev loss: 0.4719 r:0.6726
si_en Dev loss: 0.8508 r:0.5622
ne_en Dev loss: 0.5396 r:0.7152
ru_en Dev loss: 0.4640 r:0.7337
Current avg r:0.5928 Best avg r: 0.6297
03:24:22,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:25:52,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:27:22,59 root INFO Epoch 9 Global steps: 72100 Train loss: 0.1984
en_de Dev loss: 0.9252 r:0.1367
en_zh Dev loss: 0.8193 r:0.4354
ro_en Dev loss: 0.3953 r:0.8100
et_en Dev loss: 0.4997 r:0.6354
si_en Dev loss: 0.9262 r:0.5390
ne_en Dev loss: 0.6606 r:0.7004
ru_en Dev loss: 0.5433 r:0.6860
Current avg r:0.5633 Best avg r: 0.6297
03:31:50,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:33:20,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:34:50,34 root INFO Epoch 9 Global steps: 72800 Train loss: 0.2056
en_de Dev loss: 0.9106 r:0.1652
en_zh Dev loss: 0.7845 r:0.4576
ro_en Dev loss: 0.3597 r:0.8211
et_en Dev loss: 0.5015 r:0.6580
si_en Dev loss: 0.8619 r:0.5558
ne_en Dev loss: 0.5501 r:0.7069
ru_en Dev loss: 0.5091 r:0.7103
Current avg r:0.5821 Best avg r: 0.6297
03:39:18,160 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:48,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:42:17,931 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1985
en_de Dev loss: 0.9230 r:0.1565
en_zh Dev loss: 0.8332 r:0.4472
ro_en Dev loss: 0.3946 r:0.8208
et_en Dev loss: 0.5231 r:0.6523
si_en Dev loss: 0.8981 r:0.5552
ne_en Dev loss: 0.6296 r:0.7000
ru_en Dev loss: 0.5258 r:0.7080
Current avg r:0.5771 Best avg r: 0.6297
03:46:45,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:48:15,790 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:49:45,714 root INFO Epoch 9 Global steps: 74200 Train loss: 0.1923
en_de Dev loss: 0.9104 r:0.1654
en_zh Dev loss: 0.7763 r:0.4572
ro_en Dev loss: 0.3452 r:0.8195
et_en Dev loss: 0.5219 r:0.6587
si_en Dev loss: 0.8202 r:0.5531
ne_en Dev loss: 0.5526 r:0.7041
ru_en Dev loss: 0.4623 r:0.7210
Current avg r:0.5827 Best avg r: 0.6297
03:54:13,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:55:43,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:57:13,294 root INFO Epoch 9 Global steps: 74900 Train loss: 0.1876
en_de Dev loss: 0.9106 r:0.1854
en_zh Dev loss: 0.7405 r:0.4711
ro_en Dev loss: 0.3159 r:0.8214
et_en Dev loss: 0.4793 r:0.6700
si_en Dev loss: 0.7795 r:0.5625
ne_en Dev loss: 0.4728 r:0.7102
ru_en Dev loss: 0.4373 r:0.7324
Current avg r:0.5933 Best avg r: 0.6297
04:01:41,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:03:12,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:42,138 root INFO Epoch 9 Global steps: 75600 Train loss: 0.1947
en_de Dev loss: 0.9219 r:0.1681
en_zh Dev loss: 0.8075 r:0.4506
ro_en Dev loss: 0.3710 r:0.8178
et_en Dev loss: 0.5048 r:0.6436
si_en Dev loss: 0.9230 r:0.5438
ne_en Dev loss: 0.6080 r:0.7118
ru_en Dev loss: 0.5273 r:0.6955
Current avg r:0.5759 Best avg r: 0.6297
04:09:12,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:10:42,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:12:12,831 root INFO Epoch 9 Global steps: 76300 Train loss: 0.1896
en_de Dev loss: 0.9130 r:0.1663
en_zh Dev loss: 0.8055 r:0.4688
ro_en Dev loss: 0.3605 r:0.8234
et_en Dev loss: 0.5165 r:0.6724
si_en Dev loss: 0.8087 r:0.5705
ne_en Dev loss: 0.4876 r:0.7223
ru_en Dev loss: 0.4583 r:0.7385
Current avg r:0.5946 Best avg r: 0.6297
04:16:43,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:18:13,418 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:43,678 root INFO Epoch 9 Global steps: 77000 Train loss: 0.1896
en_de Dev loss: 0.9294 r:0.1502
en_zh Dev loss: 0.8061 r:0.4574
ro_en Dev loss: 0.3533 r:0.8192
et_en Dev loss: 0.4701 r:0.6631
si_en Dev loss: 0.8188 r:0.5521
ne_en Dev loss: 0.5643 r:0.7172
ru_en Dev loss: 0.4748 r:0.7331
Current avg r:0.5846 Best avg r: 0.6297
04:24:13,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:25:43,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:27:13,422 root INFO Epoch 9 Global steps: 77700 Train loss: 0.1957
en_de Dev loss: 0.9131 r:0.1720
en_zh Dev loss: 0.7450 r:0.4726
ro_en Dev loss: 0.3383 r:0.8202
et_en Dev loss: 0.4839 r:0.6593
si_en Dev loss: 0.7818 r:0.5507
ne_en Dev loss: 0.5280 r:0.7112
ru_en Dev loss: 0.4361 r:0.7279
Current avg r:0.5877 Best avg r: 0.6297
04:31:41,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:33:11,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:34:41,384 root INFO Epoch 9 Global steps: 78400 Train loss: 0.1820
en_de Dev loss: 0.9090 r:0.1507
en_zh Dev loss: 0.7733 r:0.4551
ro_en Dev loss: 0.3550 r:0.8189
et_en Dev loss: 0.4877 r:0.6558
si_en Dev loss: 0.8577 r:0.5497
ne_en Dev loss: 0.5538 r:0.7124
ru_en Dev loss: 0.4257 r:0.7436
Current avg r:0.5837 Best avg r: 0.6297
04:39:09,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:40:39,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:42:09,294 root INFO Epoch 9 Global steps: 79100 Train loss: 0.1894
en_de Dev loss: 0.9155 r:0.1558
en_zh Dev loss: 0.7945 r:0.4558
ro_en Dev loss: 0.3398 r:0.8206
et_en Dev loss: 0.4784 r:0.6559
si_en Dev loss: 0.9094 r:0.5526
ne_en Dev loss: 0.6721 r:0.7077
ru_en Dev loss: 0.4707 r:0.7239
Current avg r:0.5818 Best avg r: 0.6297
04:46:38,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:48:08,174 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:49:37,917 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1801
en_de Dev loss: 0.9248 r:0.1452
en_zh Dev loss: 0.8174 r:0.4512
ro_en Dev loss: 0.3573 r:0.8167
et_en Dev loss: 0.5032 r:0.6484
si_en Dev loss: 0.9138 r:0.5489
ne_en Dev loss: 0.5684 r:0.7103
ru_en Dev loss: 0.4998 r:0.7145
Current avg r:0.5765 Best avg r: 0.6297
04:54:06,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:55:35,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:57:05,761 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1682
en_de Dev loss: 0.9068 r:0.1755
en_zh Dev loss: 0.7728 r:0.4612
ro_en Dev loss: 0.3335 r:0.8274
et_en Dev loss: 0.5053 r:0.6707
si_en Dev loss: 0.7961 r:0.5607
ne_en Dev loss: 0.4946 r:0.7122
ru_en Dev loss: 0.4127 r:0.7475
Current avg r:0.5936 Best avg r: 0.6297
05:01:33,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:03,506 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:04:33,277 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1718
en_de Dev loss: 0.9153 r:0.1474
en_zh Dev loss: 0.8483 r:0.4332
ro_en Dev loss: 0.3764 r:0.8171
et_en Dev loss: 0.5127 r:0.6494
si_en Dev loss: 0.9468 r:0.5440
ne_en Dev loss: 0.6219 r:0.7036
ru_en Dev loss: 0.5172 r:0.7031
Current avg r:0.5711 Best avg r: 0.6297
05:09:01,781 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:31,644 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:12:01,511 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1732
en_de Dev loss: 0.9261 r:0.1737
en_zh Dev loss: 0.7573 r:0.4670
ro_en Dev loss: 0.3250 r:0.8242
et_en Dev loss: 0.4737 r:0.6781
si_en Dev loss: 0.7845 r:0.5661
ne_en Dev loss: 0.4917 r:0.7159
ru_en Dev loss: 0.4299 r:0.7419
Current avg r:0.5953 Best avg r: 0.6297
05:16:30,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:18:00,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:19:30,33 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1776
en_de Dev loss: 0.9169 r:0.1726
en_zh Dev loss: 0.7854 r:0.4484
ro_en Dev loss: 0.3532 r:0.8168
et_en Dev loss: 0.4993 r:0.6556
si_en Dev loss: 0.8148 r:0.5500
ne_en Dev loss: 0.5636 r:0.7095
ru_en Dev loss: 0.4529 r:0.7279
Current avg r:0.5830 Best avg r: 0.6297
05:23:58,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:25:27,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:57,741 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1762
en_de Dev loss: 0.9242 r:0.1589
en_zh Dev loss: 0.7724 r:0.4613
ro_en Dev loss: 0.3387 r:0.8208
et_en Dev loss: 0.5107 r:0.6726
si_en Dev loss: 0.7776 r:0.5537
ne_en Dev loss: 0.5426 r:0.7054
ru_en Dev loss: 0.4357 r:0.7358
Current avg r:0.5869 Best avg r: 0.6297
05:31:25,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:32:55,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:34:25,786 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1623
en_de Dev loss: 0.9182 r:0.1491
en_zh Dev loss: 0.8624 r:0.4362
ro_en Dev loss: 0.3519 r:0.8177
et_en Dev loss: 0.4732 r:0.6637
si_en Dev loss: 0.8441 r:0.5508
ne_en Dev loss: 0.5664 r:0.7041
ru_en Dev loss: 0.4631 r:0.7316
Current avg r:0.5790 Best avg r: 0.6297
05:38:54,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:40:24,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:41:54,58 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1758
en_de Dev loss: 0.9139 r:0.1462
en_zh Dev loss: 0.7643 r:0.4584
ro_en Dev loss: 0.3330 r:0.8204
et_en Dev loss: 0.5092 r:0.6658
si_en Dev loss: 0.7659 r:0.5549
ne_en Dev loss: 0.5159 r:0.7046
ru_en Dev loss: 0.4312 r:0.7330
Current avg r:0.5833 Best avg r: 0.6297
05:46:22,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:47:52,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:49:22,825 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1702
en_de Dev loss: 0.9231 r:0.1621
en_zh Dev loss: 0.8056 r:0.4583
ro_en Dev loss: 0.3558 r:0.8174
et_en Dev loss: 0.4837 r:0.6674
si_en Dev loss: 0.8918 r:0.5454
ne_en Dev loss: 0.5407 r:0.7070
ru_en Dev loss: 0.4567 r:0.7363
Current avg r:0.5849 Best avg r: 0.6297
05:53:52,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:55:23,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:56:53,244 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1725
en_de Dev loss: 0.9393 r:0.1463
en_zh Dev loss: 0.8060 r:0.4521
ro_en Dev loss: 0.3569 r:0.8190
et_en Dev loss: 0.4840 r:0.6634
si_en Dev loss: 0.8381 r:0.5527
ne_en Dev loss: 0.5287 r:0.7067
ru_en Dev loss: 0.4738 r:0.7343
Current avg r:0.5821 Best avg r: 0.6297
06:01:22,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:02:52,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:22,670 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1694
en_de Dev loss: 0.9206 r:0.1707
en_zh Dev loss: 0.8169 r:0.4639
ro_en Dev loss: 0.3728 r:0.8138
et_en Dev loss: 0.4857 r:0.6594
si_en Dev loss: 0.8914 r:0.5443
ne_en Dev loss: 0.5755 r:0.7105
ru_en Dev loss: 0.4898 r:0.7258
Current avg r:0.5841 Best avg r: 0.6297
06:08:52,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:10:22,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:52,136 root INFO Epoch 10 Global steps: 87500 Train loss: 0.1660
en_de Dev loss: 0.9103 r:0.1679
en_zh Dev loss: 0.7645 r:0.4655
ro_en Dev loss: 0.3442 r:0.8169
et_en Dev loss: 0.4727 r:0.6667
si_en Dev loss: 0.8273 r:0.5503
ne_en Dev loss: 0.5539 r:0.7097
ru_en Dev loss: 0.4475 r:0.7337
Current avg r:0.5872 Best avg r: 0.6297
06:16:21,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:51,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:19:21,25 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1508
en_de Dev loss: 0.8983 r:0.1651
en_zh Dev loss: 0.7917 r:0.4564
ro_en Dev loss: 0.3574 r:0.8189
et_en Dev loss: 0.5218 r:0.6705
si_en Dev loss: 0.7954 r:0.5592
ne_en Dev loss: 0.5426 r:0.7049
ru_en Dev loss: 0.4359 r:0.7400
Current avg r:0.5879 Best avg r: 0.6297
06:23:49,196 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:25:19,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:48,845 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1572
en_de Dev loss: 0.9055 r:0.1653
en_zh Dev loss: 0.7844 r:0.4569
ro_en Dev loss: 0.3680 r:0.8126
et_en Dev loss: 0.4846 r:0.6614
si_en Dev loss: 0.8625 r:0.5505
ne_en Dev loss: 0.6349 r:0.7010
ru_en Dev loss: 0.4688 r:0.7304
Current avg r:0.5826 Best avg r: 0.6297
06:31:17,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:32:47,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:34:17,179 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1504
en_de Dev loss: 0.9211 r:0.1924
en_zh Dev loss: 0.8194 r:0.4556
ro_en Dev loss: 0.3773 r:0.8179
et_en Dev loss: 0.5244 r:0.6727
si_en Dev loss: 0.8599 r:0.5583
ne_en Dev loss: 0.5476 r:0.7061
ru_en Dev loss: 0.4541 r:0.7464
Current avg r:0.5928 Best avg r: 0.6297
06:38:46,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:40:15,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:41:45,749 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1482
en_de Dev loss: 0.9167 r:0.1827
en_zh Dev loss: 0.7762 r:0.4660
ro_en Dev loss: 0.3454 r:0.8219
et_en Dev loss: 0.4782 r:0.6755
si_en Dev loss: 0.8163 r:0.5630
ne_en Dev loss: 0.5414 r:0.7093
ru_en Dev loss: 0.4694 r:0.7380
Current avg r:0.5938 Best avg r: 0.6297
06:46:14,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:44,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:49:14,208 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1659
en_de Dev loss: 0.8952 r:0.1681
en_zh Dev loss: 0.7614 r:0.4700
ro_en Dev loss: 0.3586 r:0.8161
et_en Dev loss: 0.4806 r:0.6581
si_en Dev loss: 0.8844 r:0.5439
ne_en Dev loss: 0.6127 r:0.6989
ru_en Dev loss: 0.4389 r:0.7315
Current avg r:0.5838 Best avg r: 0.6297
06:53:43,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:55:12,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:42,847 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1547
en_de Dev loss: 0.9208 r:0.1650
en_zh Dev loss: 0.8001 r:0.4531
ro_en Dev loss: 0.3492 r:0.8195
et_en Dev loss: 0.4801 r:0.6680
si_en Dev loss: 0.8433 r:0.5509
ne_en Dev loss: 0.5722 r:0.7019
ru_en Dev loss: 0.4742 r:0.7271
Current avg r:0.5836 Best avg r: 0.6297
07:01:11,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:41,653 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:04:11,548 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1575
en_de Dev loss: 0.9023 r:0.1700
en_zh Dev loss: 0.7319 r:0.4658
ro_en Dev loss: 0.3160 r:0.8198
et_en Dev loss: 0.4617 r:0.6739
si_en Dev loss: 0.7820 r:0.5530
ne_en Dev loss: 0.5389 r:0.7022
ru_en Dev loss: 0.3987 r:0.7427
Current avg r:0.5896 Best avg r: 0.6297
07:08:40,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:10:10,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:11:40,294 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1590
en_de Dev loss: 0.9487 r:0.1610
en_zh Dev loss: 0.8316 r:0.4531
ro_en Dev loss: 0.3646 r:0.8171
et_en Dev loss: 0.4757 r:0.6640
si_en Dev loss: 0.8888 r:0.5515
ne_en Dev loss: 0.5617 r:0.7038
ru_en Dev loss: 0.4724 r:0.7342
Current avg r:0.5835 Best avg r: 0.6297
07:16:09,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:39,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:19:08,925 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1599
en_de Dev loss: 0.9041 r:0.1940
en_zh Dev loss: 0.7801 r:0.4723
ro_en Dev loss: 0.3436 r:0.8195
et_en Dev loss: 0.4792 r:0.6714
si_en Dev loss: 0.8655 r:0.5494
ne_en Dev loss: 0.5487 r:0.7033
ru_en Dev loss: 0.4283 r:0.7487
Current avg r:0.5941 Best avg r: 0.6297
07:23:37,717 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:07,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:37,353 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1542
en_de Dev loss: 0.9258 r:0.1753
en_zh Dev loss: 0.7664 r:0.4721
ro_en Dev loss: 0.3249 r:0.8210
et_en Dev loss: 0.4791 r:0.6756
si_en Dev loss: 0.7970 r:0.5498
ne_en Dev loss: 0.5083 r:0.7024
ru_en Dev loss: 0.4049 r:0.7466
Current avg r:0.5918 Best avg r: 0.6297
07:31:06,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:36,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:34:05,988 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1586
en_de Dev loss: 0.9327 r:0.1609
en_zh Dev loss: 0.7855 r:0.4655
ro_en Dev loss: 0.3301 r:0.8235
et_en Dev loss: 0.4649 r:0.6732
si_en Dev loss: 0.8627 r:0.5478
ne_en Dev loss: 0.5563 r:0.7031
ru_en Dev loss: 0.4275 r:0.7410
Current avg r:0.5878 Best avg r: 0.6297
07:38:36,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:06,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:41:36,262 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1466
en_de Dev loss: 0.9155 r:0.1646
en_zh Dev loss: 0.7576 r:0.4744
ro_en Dev loss: 0.3383 r:0.8176
et_en Dev loss: 0.4830 r:0.6754
si_en Dev loss: 0.8429 r:0.5557
ne_en Dev loss: 0.5358 r:0.7071
ru_en Dev loss: 0.4295 r:0.7408
Current avg r:0.5908 Best avg r: 0.6297
07:46:05,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:35,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:49:05,676 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1431
en_de Dev loss: 0.9296 r:0.1579
en_zh Dev loss: 0.8129 r:0.4540
ro_en Dev loss: 0.3476 r:0.8209
et_en Dev loss: 0.5064 r:0.6746
si_en Dev loss: 0.8074 r:0.5649
ne_en Dev loss: 0.5391 r:0.7018
ru_en Dev loss: 0.4422 r:0.7370
Current avg r:0.5873 Best avg r: 0.6297
07:53:35,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:55:06,93 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:56:36,235 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1323
en_de Dev loss: 0.9180 r:0.1715
en_zh Dev loss: 0.8070 r:0.4508
ro_en Dev loss: 0.3385 r:0.8196
et_en Dev loss: 0.4741 r:0.6690
si_en Dev loss: 0.8489 r:0.5534
ne_en Dev loss: 0.5477 r:0.7026
ru_en Dev loss: 0.4604 r:0.7345
Current avg r:0.5859 Best avg r: 0.6297
08:01:05,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:35,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:04:05,472 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1413
en_de Dev loss: 0.9113 r:0.1721
en_zh Dev loss: 0.7623 r:0.4543
ro_en Dev loss: 0.3193 r:0.8222
et_en Dev loss: 0.4530 r:0.6752
si_en Dev loss: 0.8392 r:0.5546
ne_en Dev loss: 0.5368 r:0.7075
ru_en Dev loss: 0.4316 r:0.7419
Current avg r:0.5897 Best avg r: 0.6297
08:08:34,282 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:10:04,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:11:34,54 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1394
en_de Dev loss: 0.9414 r:0.1777
en_zh Dev loss: 0.7831 r:0.4721
ro_en Dev loss: 0.3469 r:0.8201
et_en Dev loss: 0.4849 r:0.6664
si_en Dev loss: 0.8118 r:0.5572
ne_en Dev loss: 0.5274 r:0.7011
ru_en Dev loss: 0.4389 r:0.7461
Current avg r:0.5915 Best avg r: 0.6297
08:16:02,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:17:32,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:19:02,393 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1406
en_de Dev loss: 0.9052 r:0.1783
en_zh Dev loss: 0.7880 r:0.4614
ro_en Dev loss: 0.3839 r:0.8131
et_en Dev loss: 0.4800 r:0.6503
si_en Dev loss: 0.9628 r:0.5303
ne_en Dev loss: 0.7105 r:0.6915
ru_en Dev loss: 0.4905 r:0.7224
Current avg r:0.5782 Best avg r: 0.6297
08:23:31,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:25:01,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:30,923 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1367
en_de Dev loss: 0.9098 r:0.1716
en_zh Dev loss: 0.7734 r:0.4687
ro_en Dev loss: 0.3337 r:0.8227
et_en Dev loss: 0.4812 r:0.6684
si_en Dev loss: 0.8328 r:0.5512
ne_en Dev loss: 0.5828 r:0.6939
ru_en Dev loss: 0.4364 r:0.7366
Current avg r:0.5876 Best avg r: 0.6297
08:30:59,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:32:29,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:33:59,450 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1376
en_de Dev loss: 0.9271 r:0.1547
en_zh Dev loss: 0.8080 r:0.4592
ro_en Dev loss: 0.3558 r:0.8205
et_en Dev loss: 0.4911 r:0.6658
si_en Dev loss: 0.8800 r:0.5500
ne_en Dev loss: 0.6229 r:0.6977
ru_en Dev loss: 0.4615 r:0.7350
Current avg r:0.5833 Best avg r: 0.6297
08:38:28,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:39:58,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:28,28 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1457
en_de Dev loss: 0.9238 r:0.1594
en_zh Dev loss: 0.8507 r:0.4499
ro_en Dev loss: 0.3540 r:0.8207
et_en Dev loss: 0.4647 r:0.6691
si_en Dev loss: 0.8768 r:0.5454
ne_en Dev loss: 0.6323 r:0.7041
ru_en Dev loss: 0.4689 r:0.7360
Current avg r:0.5835 Best avg r: 0.6297
08:45:56,895 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:26,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:48:56,514 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1490
en_de Dev loss: 0.9261 r:0.1746
en_zh Dev loss: 0.7907 r:0.4737
ro_en Dev loss: 0.3549 r:0.8247
et_en Dev loss: 0.4725 r:0.6768
si_en Dev loss: 0.9138 r:0.5488
ne_en Dev loss: 0.6497 r:0.6954
ru_en Dev loss: 0.4350 r:0.7532
Current avg r:0.5925 Best avg r: 0.6297
08:53:25,452 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:54:55,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:25,286 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1432
en_de Dev loss: 0.9237 r:0.1622
en_zh Dev loss: 0.7713 r:0.4716
ro_en Dev loss: 0.3440 r:0.8189
et_en Dev loss: 0.4705 r:0.6667
si_en Dev loss: 0.8754 r:0.5494
ne_en Dev loss: 0.6219 r:0.7020
ru_en Dev loss: 0.4469 r:0.7384
Current avg r:0.5870 Best avg r: 0.6297
09:00:55,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:25,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:54,960 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1415
en_de Dev loss: 0.9301 r:0.1454
en_zh Dev loss: 0.7774 r:0.4610
ro_en Dev loss: 0.3346 r:0.8190
et_en Dev loss: 0.4599 r:0.6653
si_en Dev loss: 0.8974 r:0.5463
ne_en Dev loss: 0.5983 r:0.6967
ru_en Dev loss: 0.4501 r:0.7376
Current avg r:0.5816 Best avg r: 0.6297
09:08:24,266 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:54,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:24,700 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1276
en_de Dev loss: 0.9260 r:0.1738
en_zh Dev loss: 0.7648 r:0.4634
ro_en Dev loss: 0.3318 r:0.8209
et_en Dev loss: 0.4663 r:0.6808
si_en Dev loss: 0.8139 r:0.5586
ne_en Dev loss: 0.5125 r:0.7083
ru_en Dev loss: 0.3941 r:0.7609
Current avg r:0.5953 Best avg r: 0.6297
09:15:55,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:17:25,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:18:55,282 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1295
en_de Dev loss: 0.9470 r:0.1583
en_zh Dev loss: 0.7851 r:0.4608
ro_en Dev loss: 0.3266 r:0.8219
et_en Dev loss: 0.4532 r:0.6810
si_en Dev loss: 0.8090 r:0.5578
ne_en Dev loss: 0.5539 r:0.7036
ru_en Dev loss: 0.4285 r:0.7470
Current avg r:0.5901 Best avg r: 0.6297
09:23:25,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:24:55,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:25,339 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1289
en_de Dev loss: 0.9531 r:0.1655
en_zh Dev loss: 0.7904 r:0.4731
ro_en Dev loss: 0.3644 r:0.8199
et_en Dev loss: 0.4721 r:0.6644
si_en Dev loss: 0.9123 r:0.5460
ne_en Dev loss: 0.6271 r:0.6932
ru_en Dev loss: 0.4503 r:0.7451
Current avg r:0.5867 Best avg r: 0.6297
09:30:54,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:32:24,199 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:33:53,883 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1283
en_de Dev loss: 0.9800 r:0.1547
en_zh Dev loss: 0.7991 r:0.4698
ro_en Dev loss: 0.3720 r:0.8201
et_en Dev loss: 0.5002 r:0.6709
si_en Dev loss: 0.8625 r:0.5554
ne_en Dev loss: 0.5901 r:0.7016
ru_en Dev loss: 0.4471 r:0.7501
Current avg r:0.5890 Best avg r: 0.6297
09:38:22,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:39:52,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:41:22,20 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1285
en_de Dev loss: 0.9308 r:0.1455
en_zh Dev loss: 0.7620 r:0.4710
ro_en Dev loss: 0.3428 r:0.8200
et_en Dev loss: 0.4593 r:0.6673
si_en Dev loss: 0.8458 r:0.5474
ne_en Dev loss: 0.6434 r:0.6942
ru_en Dev loss: 0.4449 r:0.7362
Current avg r:0.5831 Best avg r: 0.6297
09:45:50,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:20,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:48:49,727 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1268
en_de Dev loss: 0.9282 r:0.1779
en_zh Dev loss: 0.7605 r:0.4785
ro_en Dev loss: 0.3427 r:0.8219
et_en Dev loss: 0.4771 r:0.6805
si_en Dev loss: 0.7939 r:0.5605
ne_en Dev loss: 0.5063 r:0.7056
ru_en Dev loss: 0.3971 r:0.7621
Current avg r:0.5981 Best avg r: 0.6297
09:53:18,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:54:48,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:18,5 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1306
en_de Dev loss: 0.9106 r:0.1634
en_zh Dev loss: 0.7528 r:0.4672
ro_en Dev loss: 0.3342 r:0.8191
et_en Dev loss: 0.4565 r:0.6645
si_en Dev loss: 0.8624 r:0.5395
ne_en Dev loss: 0.5799 r:0.6971
ru_en Dev loss: 0.4252 r:0.7399
Current avg r:0.5844 Best avg r: 0.6297
10:00:46,480 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:16,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:45,906 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1286
en_de Dev loss: 0.9266 r:0.1467
en_zh Dev loss: 0.8301 r:0.4478
ro_en Dev loss: 0.3748 r:0.8116
et_en Dev loss: 0.4618 r:0.6609
si_en Dev loss: 0.9206 r:0.5399
ne_en Dev loss: 0.5828 r:0.6998
ru_en Dev loss: 0.4832 r:0.7308
Current avg r:0.5768 Best avg r: 0.6297
10:08:14,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:09:44,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:14,68 root INFO Epoch 13 Global steps: 109900 Train loss: 0.1292
en_de Dev loss: 0.9155 r:0.1466
en_zh Dev loss: 0.7448 r:0.4755
ro_en Dev loss: 0.3273 r:0.8212
et_en Dev loss: 0.4495 r:0.6698
si_en Dev loss: 0.8038 r:0.5574
ne_en Dev loss: 0.5688 r:0.6947
ru_en Dev loss: 0.3903 r:0.7592
Current avg r:0.5892 Best avg r: 0.6297
10:15:43,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:17:12,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:18:42,659 root INFO Epoch 13 Global steps: 110600 Train loss: 0.1230
en_de Dev loss: 0.9408 r:0.1493
en_zh Dev loss: 0.8080 r:0.4611
ro_en Dev loss: 0.3505 r:0.8192
et_en Dev loss: 0.4820 r:0.6624
si_en Dev loss: 0.9005 r:0.5466
ne_en Dev loss: 0.6117 r:0.6966
ru_en Dev loss: 0.4472 r:0.7409
Current avg r:0.5823 Best avg r: 0.6297
10:23:11,577 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:24:41,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:11,246 root INFO Epoch 13 Global steps: 111300 Train loss: 0.1316
en_de Dev loss: 0.9171 r:0.1541
en_zh Dev loss: 0.7599 r:0.4656
ro_en Dev loss: 0.3414 r:0.8166
et_en Dev loss: 0.4900 r:0.6716
si_en Dev loss: 0.7632 r:0.5574
ne_en Dev loss: 0.5209 r:0.6960
ru_en Dev loss: 0.4377 r:0.7350
Current avg r:0.5852 Best avg r: 0.6297
10:30:41,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
