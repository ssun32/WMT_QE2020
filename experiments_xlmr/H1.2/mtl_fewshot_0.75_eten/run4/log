14:55:55,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:07,994 root INFO 
id:en_de cur r: 0.0823 best r: 0.0823
14:56:20,846 root INFO 
id:en_zh cur r: 0.2685 best r: 0.2685
14:56:33,725 root INFO 
id:ro_en cur r: 0.6048 best r: 0.6048
14:56:59,590 root INFO 
id:et_en cur r: 0.5266 best r: 0.5266
14:57:12,548 root INFO 
id:si_en cur r: 0.4508 best r: 0.4508
14:57:25,475 root INFO 
id:ne_en cur r: 0.6131 best r: 0.6131
14:57:38,299 root INFO 
id:ru_en cur r: 0.4356 best r: 0.4356
14:57:38,300 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:08,296 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
14:59:08,307 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:59:08,316 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:59:08,322 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
14:59:08,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
14:59:08,340 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:59:08,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:59:21,245 root INFO Epoch 0 Global steps: 700 Train loss: 0.8125
en_de Dev loss: 0.8971 r:0.0819
en_zh Dev loss: 0.7823 r:0.2601
ro_en Dev loss: 0.6551 r:0.6201
et_en Dev loss: 0.5194 r:0.5271
si_en Dev loss: 0.7210 r:0.4408
ne_en Dev loss: 0.5240 r:0.6210
ru_en Dev loss: 0.6335 r:0.5265
Current avg r:0.4397 Best avg r: 0.4397
15:03:50,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:03,779 root INFO 
id:en_de cur r: 0.1087 best r: 0.1087
15:04:29,470 root INFO 
id:ro_en cur r: 0.6555 best r: 0.6555
15:04:55,207 root INFO 
id:et_en cur r: 0.5689 best r: 0.5689
15:05:08,88 root INFO 
id:si_en cur r: 0.4705 best r: 0.4705
15:05:33,775 root INFO 
id:ru_en cur r: 0.6151 best r: 0.6151
15:05:33,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:03,666 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:07:03,677 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:07:03,684 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:07:03,692 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:07:03,698 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:07:03,706 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:07:03,713 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:07:16,590 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8027
en_de Dev loss: 0.9785 r:0.1161
en_zh Dev loss: 0.8802 r:0.2514
ro_en Dev loss: 0.7235 r:0.6289
et_en Dev loss: 0.5325 r:0.5820
si_en Dev loss: 0.8896 r:0.4470
ne_en Dev loss: 0.5662 r:0.6004
ru_en Dev loss: 0.6862 r:0.6300
Current avg r:0.4651 Best avg r: 0.4651
15:11:46,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:59,195 root INFO 
id:en_de cur r: 0.1157 best r: 0.1157
15:12:50,606 root INFO 
id:et_en cur r: 0.6209 best r: 0.6209
15:13:03,482 root INFO 
id:si_en cur r: 0.4797 best r: 0.4797
15:13:29,152 root INFO 
id:ru_en cur r: 0.6607 best r: 0.6607
15:13:29,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:59,38 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:14:59,50 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:14:59,58 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:14:59,65 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:14:59,71 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:14:59,77 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:14:59,84 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:15:11,963 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7238
en_de Dev loss: 0.9914 r:0.1581
en_zh Dev loss: 0.8790 r:0.2742
ro_en Dev loss: 0.6792 r:0.6571
et_en Dev loss: 0.4892 r:0.6434
si_en Dev loss: 0.7960 r:0.4953
ne_en Dev loss: 0.5118 r:0.6363
ru_en Dev loss: 0.6983 r:0.6827
Current avg r:0.5067 Best avg r: 0.5067
15:19:41,671 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:54,523 root INFO 
id:en_de cur r: 0.1630 best r: 0.1630
15:20:07,350 root INFO 
id:en_zh cur r: 0.2853 best r: 0.2853
15:20:20,209 root INFO 
id:ro_en cur r: 0.6910 best r: 0.6910
15:20:45,959 root INFO 
id:et_en cur r: 0.6579 best r: 0.6579
15:20:58,836 root INFO 
id:si_en cur r: 0.5047 best r: 0.5047
15:21:11,709 root INFO 
id:ne_en cur r: 0.6500 best r: 0.6500
15:21:24,525 root INFO 
id:ru_en cur r: 0.6950 best r: 0.6950
15:21:24,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:54,443 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:22:54,459 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:22:54,469 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:22:54,478 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:22:54,487 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:22:54,496 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:22:54,505 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:23:07,387 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6906
en_de Dev loss: 0.9821 r:0.1572
en_zh Dev loss: 0.8232 r:0.3405
ro_en Dev loss: 0.5538 r:0.6957
et_en Dev loss: 0.4019 r:0.6833
si_en Dev loss: 0.8463 r:0.5238
ne_en Dev loss: 0.4653 r:0.6853
ru_en Dev loss: 0.5173 r:0.7226
Current avg r:0.5441 Best avg r: 0.5441
15:27:37,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:28:02,802 root INFO 
id:en_zh cur r: 0.3653 best r: 0.3653
15:28:15,667 root INFO 
id:ro_en cur r: 0.7072 best r: 0.7072
15:28:41,400 root INFO 
id:et_en cur r: 0.6697 best r: 0.6697
15:28:54,305 root INFO 
id:si_en cur r: 0.5374 best r: 0.5374
15:29:07,211 root INFO 
id:ne_en cur r: 0.6996 best r: 0.6996
15:29:20,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:50,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:30:50,142 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:30:50,149 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:30:50,156 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:30:50,163 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:30:50,169 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:30:50,175 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:31:03,68 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6891
en_de Dev loss: 0.9093 r:0.1768
en_zh Dev loss: 0.7327 r:0.3823
ro_en Dev loss: 0.4837 r:0.7202
et_en Dev loss: 0.3871 r:0.6882
si_en Dev loss: 0.7018 r:0.5481
ne_en Dev loss: 0.4184 r:0.7118
ru_en Dev loss: 0.4750 r:0.7085
Current avg r:0.5623 Best avg r: 0.5623
15:35:32,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:11,454 root INFO 
id:ro_en cur r: 0.7332 best r: 0.7332
15:36:37,216 root INFO 
id:et_en cur r: 0.6930 best r: 0.6930
15:36:50,94 root INFO 
id:si_en cur r: 0.5500 best r: 0.5500
15:37:02,973 root INFO 
id:ne_en cur r: 0.7058 best r: 0.7058
15:37:15,790 root INFO 
id:ru_en cur r: 0.7201 best r: 0.7201
15:37:15,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:45,701 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:38:45,712 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:38:45,718 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:38:45,726 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:38:45,735 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:38:45,742 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:38:45,748 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:38:58,622 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6322
en_de Dev loss: 0.8917 r:0.1728
en_zh Dev loss: 0.7151 r:0.3829
ro_en Dev loss: 0.4290 r:0.7356
et_en Dev loss: 0.3525 r:0.7127
si_en Dev loss: 0.6013 r:0.5676
ne_en Dev loss: 0.3947 r:0.7153
ru_en Dev loss: 0.4265 r:0.7342
Current avg r:0.5744 Best avg r: 0.5744
15:43:28,361 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:54,43 root INFO 
id:en_zh cur r: 0.4021 best r: 0.4021
15:44:06,906 root INFO 
id:ro_en cur r: 0.7528 best r: 0.7528
15:44:32,656 root INFO 
id:et_en cur r: 0.7072 best r: 0.7072
15:44:45,531 root INFO 
id:si_en cur r: 0.5668 best r: 0.5668
15:44:58,402 root INFO 
id:ne_en cur r: 0.7084 best r: 0.7084
15:45:11,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:41,119 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:46:41,128 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:46:41,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:46:41,143 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:46:41,151 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:46:41,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:46:41,162 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:46:54,49 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6107
en_de Dev loss: 0.8876 r:0.1835
en_zh Dev loss: 0.7166 r:0.4095
ro_en Dev loss: 0.4532 r:0.7552
et_en Dev loss: 0.3664 r:0.7200
si_en Dev loss: 0.7140 r:0.5896
ne_en Dev loss: 0.4920 r:0.7264
ru_en Dev loss: 0.5414 r:0.7289
Current avg r:0.5876 Best avg r: 0.5876
15:51:23,860 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:36,720 root INFO 
id:en_de cur r: 0.1788 best r: 0.1788
15:52:02,404 root INFO 
id:ro_en cur r: 0.7807 best r: 0.7807
15:52:28,139 root INFO 
id:et_en cur r: 0.7133 best r: 0.7133
15:52:41,25 root INFO 
id:si_en cur r: 0.5760 best r: 0.5760
15:52:53,896 root INFO 
id:ne_en cur r: 0.7424 best r: 0.7424
15:53:06,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:36,608 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
15:54:36,618 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:54:36,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:54:36,629 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
15:54:36,635 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
15:54:36,641 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:54:36,647 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:54:49,524 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5815
en_de Dev loss: 0.8686 r:0.1789
en_zh Dev loss: 0.7228 r:0.3883
ro_en Dev loss: 0.3541 r:0.7796
et_en Dev loss: 0.3369 r:0.7258
si_en Dev loss: 0.6765 r:0.5822
ne_en Dev loss: 0.4098 r:0.7358
ru_en Dev loss: 0.4187 r:0.7428
Current avg r:0.5905 Best avg r: 0.5905
15:59:19,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:57,750 root INFO 
id:ro_en cur r: 0.7822 best r: 0.7822
16:00:23,491 root INFO 
id:et_en cur r: 0.7205 best r: 0.7205
16:00:36,356 root INFO 
id:si_en cur r: 0.5858 best r: 0.5858
16:01:02,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:31,929 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:02:31,935 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:02:31,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:02:31,945 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:02:31,949 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:02:31,954 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:02:31,959 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:02:44,831 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5882
en_de Dev loss: 0.8815 r:0.1852
en_zh Dev loss: 0.7303 r:0.3932
ro_en Dev loss: 0.3467 r:0.7836
et_en Dev loss: 0.3314 r:0.7299
si_en Dev loss: 0.6188 r:0.5941
ne_en Dev loss: 0.3874 r:0.7424
ru_en Dev loss: 0.4318 r:0.7314
Current avg r:0.5943 Best avg r: 0.5943
16:07:14,495 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:27,369 root INFO 
id:en_de cur r: 0.1793 best r: 0.1793
16:07:53,75 root INFO 
id:ro_en cur r: 0.7893 best r: 0.7893
16:08:18,852 root INFO 
id:et_en cur r: 0.7235 best r: 0.7235
16:08:57,410 root INFO 
id:ru_en cur r: 0.7234 best r: 0.7234
16:08:57,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:27,413 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5638
en_de Dev loss: 0.8936 r:0.1723
en_zh Dev loss: 0.7596 r:0.3856
ro_en Dev loss: 0.3905 r:0.7894
et_en Dev loss: 0.3447 r:0.7332
si_en Dev loss: 0.7062 r:0.5874
ne_en Dev loss: 0.4625 r:0.7371
ru_en Dev loss: 0.4668 r:0.7355
Current avg r:0.5915 Best avg r: 0.5943
16:14:56,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:22,670 root INFO 
id:en_zh cur r: 0.4131 best r: 0.4131
16:15:35,530 root INFO 
id:ro_en cur r: 0.8025 best r: 0.8025
16:16:01,272 root INFO 
id:si_en cur r: 0.5950 best r: 0.5950
16:16:14,144 root INFO 
id:ne_en cur r: 0.7522 best r: 0.7522
16:16:26,953 root INFO 
id:ru_en cur r: 0.7658 best r: 0.7658
16:16:26,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:17:56,862 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:17:56,871 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:17:56,876 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:17:56,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:17:56,888 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:17:56,894 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:17:56,899 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:18:09,779 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5542
en_de Dev loss: 0.9192 r:0.1818
en_zh Dev loss: 0.7334 r:0.4173
ro_en Dev loss: 0.3815 r:0.7993
et_en Dev loss: 0.3616 r:0.7290
si_en Dev loss: 0.7365 r:0.5915
ne_en Dev loss: 0.5042 r:0.7442
ru_en Dev loss: 0.4145 r:0.7665
Current avg r:0.6042 Best avg r: 0.6042
16:22:41,273 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:22:54,168 root INFO 
id:en_de cur r: 0.1828 best r: 0.1828
16:23:07,71 root INFO 
id:en_zh cur r: 0.4390 best r: 0.4390
16:23:19,990 root INFO 
id:ro_en cur r: 0.8103 best r: 0.8103
16:23:45,847 root INFO 
id:si_en cur r: 0.6049 best r: 0.6049
16:24:11,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:41,613 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:25:41,622 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:25:41,627 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:25:41,633 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:25:41,639 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:25:41,645 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:25:41,651 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:25:54,540 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5176
en_de Dev loss: 0.8592 r:0.1958
en_zh Dev loss: 0.6585 r:0.4499
ro_en Dev loss: 0.3169 r:0.8021
et_en Dev loss: 0.3364 r:0.7245
si_en Dev loss: 0.5789 r:0.6044
ne_en Dev loss: 0.4217 r:0.7461
ru_en Dev loss: 0.3636 r:0.7682
Current avg r:0.6130 Best avg r: 0.6130
16:30:24,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:37,310 root INFO 
id:en_de cur r: 0.2075 best r: 0.2075
16:31:02,991 root INFO 
id:ro_en cur r: 0.8110 best r: 0.8110
16:31:41,598 root INFO 
id:ne_en cur r: 0.7549 best r: 0.7549
16:31:54,402 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:24,367 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5139
en_de Dev loss: 0.8696 r:0.1968
en_zh Dev loss: 0.6805 r:0.4392
ro_en Dev loss: 0.3179 r:0.8024
et_en Dev loss: 0.3342 r:0.7291
si_en Dev loss: 0.5534 r:0.6006
ne_en Dev loss: 0.3750 r:0.7546
ru_en Dev loss: 0.3851 r:0.7531
Current avg r:0.6108 Best avg r: 0.6130
16:37:54,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:32,918 root INFO 
id:ro_en cur r: 0.8129 best r: 0.8129
16:39:11,525 root INFO 
id:ne_en cur r: 0.7588 best r: 0.7588
16:39:24,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:54,320 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5210
en_de Dev loss: 0.8693 r:0.1823
en_zh Dev loss: 0.6970 r:0.4210
ro_en Dev loss: 0.3333 r:0.8050
et_en Dev loss: 0.3379 r:0.7284
si_en Dev loss: 0.6287 r:0.5856
ne_en Dev loss: 0.4107 r:0.7516
ru_en Dev loss: 0.4308 r:0.7312
Current avg r:0.6007 Best avg r: 0.6130
16:45:24,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:54,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:24,488 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5130
en_de Dev loss: 0.8946 r:0.1773
en_zh Dev loss: 0.7497 r:0.4178
ro_en Dev loss: 0.3562 r:0.8040
et_en Dev loss: 0.3619 r:0.7250
si_en Dev loss: 0.7479 r:0.5808
ne_en Dev loss: 0.4688 r:0.7495
ru_en Dev loss: 0.4569 r:0.7418
Current avg r:0.5995 Best avg r: 0.6130
16:52:54,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:33,63 root INFO 
id:ro_en cur r: 0.8200 best r: 0.8200
16:53:58,803 root INFO 
id:et_en cur r: 0.7330 best r: 0.7330
16:54:11,682 root INFO 
id:si_en cur r: 0.6111 best r: 0.6111
16:54:37,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:07,435 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
16:56:07,446 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:56:07,452 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:56:07,459 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
16:56:07,465 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
16:56:07,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:56:07,478 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:56:20,371 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5003
en_de Dev loss: 0.8685 r:0.1950
en_zh Dev loss: 0.6933 r:0.4393
ro_en Dev loss: 0.3209 r:0.8151
et_en Dev loss: 0.3312 r:0.7362
si_en Dev loss: 0.6078 r:0.6062
ne_en Dev loss: 0.3644 r:0.7593
ru_en Dev loss: 0.3780 r:0.7610
Current avg r:0.6160 Best avg r: 0.6160
17:00:50,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:15,932 root INFO 
id:en_zh cur r: 0.4458 best r: 0.4458
17:01:54,503 root INFO 
id:si_en cur r: 0.6116 best r: 0.6116
17:02:20,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:50,159 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
17:03:50,170 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:03:50,176 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:03:50,183 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
17:03:50,189 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
17:03:50,196 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:03:50,202 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:04:03,97 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4868
en_de Dev loss: 0.8605 r:0.1995
en_zh Dev loss: 0.7015 r:0.4531
ro_en Dev loss: 0.3313 r:0.8167
et_en Dev loss: 0.3340 r:0.7344
si_en Dev loss: 0.7051 r:0.6030
ne_en Dev loss: 0.4423 r:0.7523
ru_en Dev loss: 0.4017 r:0.7566
Current avg r:0.6165 Best avg r: 0.6165
17:08:32,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:45,810 root INFO 
id:en_de cur r: 0.2085 best r: 0.2085
17:10:02,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:32,885 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5128
en_de Dev loss: 0.8589 r:0.1814
en_zh Dev loss: 0.7137 r:0.4230
ro_en Dev loss: 0.3550 r:0.8117
et_en Dev loss: 0.3592 r:0.7224
si_en Dev loss: 0.7478 r:0.5886
ne_en Dev loss: 0.6112 r:0.7427
ru_en Dev loss: 0.4832 r:0.7134
Current avg r:0.5976 Best avg r: 0.6165
17:16:02,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:15,506 root INFO 
id:en_de cur r: 0.2124 best r: 0.2124
17:17:06,916 root INFO 
id:si_en cur r: 0.6145 best r: 0.6145
17:17:19,791 root INFO 
id:ne_en cur r: 0.7673 best r: 0.7673
17:17:32,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:02,597 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5195
en_de Dev loss: 0.8638 r:0.1868
en_zh Dev loss: 0.6995 r:0.4439
ro_en Dev loss: 0.3395 r:0.8127
et_en Dev loss: 0.3455 r:0.7246
si_en Dev loss: 0.5718 r:0.6055
ne_en Dev loss: 0.3755 r:0.7654
ru_en Dev loss: 0.4648 r:0.7209
Current avg r:0.6085 Best avg r: 0.6165
17:23:32,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:45,395 root INFO 
id:en_de cur r: 0.2193 best r: 0.2193
17:24:11,91 root INFO 
id:ro_en cur r: 0.8232 best r: 0.8232
17:25:02,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:32,619 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4978
en_de Dev loss: 0.8578 r:0.1888
en_zh Dev loss: 0.6696 r:0.4451
ro_en Dev loss: 0.2888 r:0.8175
et_en Dev loss: 0.3365 r:0.7294
si_en Dev loss: 0.5768 r:0.6012
ne_en Dev loss: 0.3666 r:0.7626
ru_en Dev loss: 0.4025 r:0.7365
Current avg r:0.6116 Best avg r: 0.6165
17:31:02,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:31:28,248 root INFO 
id:en_zh cur r: 0.4695 best r: 0.4695
17:31:41,119 root INFO 
id:ro_en cur r: 0.8299 best r: 0.8299
17:32:06,899 root INFO 
id:et_en cur r: 0.7346 best r: 0.7346
17:32:19,791 root INFO 
id:si_en cur r: 0.6193 best r: 0.6193
17:32:32,679 root INFO 
id:ne_en cur r: 0.7739 best r: 0.7739
17:32:45,495 root INFO 
id:ru_en cur r: 0.7668 best r: 0.7668
17:32:45,496 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:15,556 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_de.lang_agnost_mlp.dev.best.scores
17:34:15,567 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:34:15,577 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:34:15,583 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/et_en.lang_agnost_mlp.dev.best.scores
17:34:15,589 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/si_en.lang_agnost_mlp.dev.best.scores
17:34:15,596 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:34:15,603 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_eten/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:34:28,509 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4893
en_de Dev loss: 0.8582 r:0.2129
en_zh Dev loss: 0.6672 r:0.4682
ro_en Dev loss: 0.3013 r:0.8241
et_en Dev loss: 0.3509 r:0.7348
si_en Dev loss: 0.5501 r:0.6166
ne_en Dev loss: 0.3248 r:0.7751
ru_en Dev loss: 0.3703 r:0.7663
Current avg r:0.6283 Best avg r: 0.6283
17:38:58,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:24,291 root INFO 
id:en_zh cur r: 0.4734 best r: 0.4734
17:40:02,883 root INFO 
id:si_en cur r: 0.6196 best r: 0.6196
17:40:28,562 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:58,552 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4825
en_de Dev loss: 0.8590 r:0.2072
en_zh Dev loss: 0.6584 r:0.4728
ro_en Dev loss: 0.3221 r:0.8165
et_en Dev loss: 0.3564 r:0.7198
si_en Dev loss: 0.6140 r:0.6117
ne_en Dev loss: 0.3514 r:0.7667
ru_en Dev loss: 0.4354 r:0.7463
Current avg r:0.6201 Best avg r: 0.6283
17:46:30,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:42,893 root INFO 
id:en_de cur r: 0.2232 best r: 0.2232
17:48:00,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:30,384 root INFO Epoch 2 Global steps: 16100 Train loss: 0.4562
en_de Dev loss: 0.8531 r:0.2021
en_zh Dev loss: 0.6640 r:0.4653
ro_en Dev loss: 0.2963 r:0.8208
et_en Dev loss: 0.3477 r:0.7274
si_en Dev loss: 0.6464 r:0.5989
ne_en Dev loss: 0.3655 r:0.7664
ru_en Dev loss: 0.3960 r:0.7473
Current avg r:0.6183 Best avg r: 0.6283
17:54:00,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:13,210 root INFO 
id:en_de cur r: 0.2302 best r: 0.2302
17:55:30,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:00,352 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4444
en_de Dev loss: 0.8584 r:0.2057
en_zh Dev loss: 0.6773 r:0.4709
ro_en Dev loss: 0.3138 r:0.8247
et_en Dev loss: 0.3297 r:0.7330
si_en Dev loss: 0.7167 r:0.6066
ne_en Dev loss: 0.4336 r:0.7594
ru_en Dev loss: 0.4275 r:0.7495
Current avg r:0.6214 Best avg r: 0.6283
18:01:30,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:00,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:30,324 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4445
en_de Dev loss: 0.8599 r:0.1978
en_zh Dev loss: 0.6764 r:0.4544
ro_en Dev loss: 0.3093 r:0.8190
et_en Dev loss: 0.3940 r:0.7197
si_en Dev loss: 0.6014 r:0.6016
ne_en Dev loss: 0.3453 r:0.7646
ru_en Dev loss: 0.3919 r:0.7419
Current avg r:0.6141 Best avg r: 0.6283
18:09:00,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:38,919 root INFO 
id:ro_en cur r: 0.8324 best r: 0.8324
18:10:30,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:00,334 root INFO Epoch 2 Global steps: 18200 Train loss: 0.4325
en_de Dev loss: 0.8553 r:0.2105
en_zh Dev loss: 0.6794 r:0.4642
ro_en Dev loss: 0.2983 r:0.8245
et_en Dev loss: 0.3444 r:0.7248
si_en Dev loss: 0.6853 r:0.5997
ne_en Dev loss: 0.3682 r:0.7696
ru_en Dev loss: 0.4184 r:0.7392
Current avg r:0.6189 Best avg r: 0.6283
18:16:30,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:00,397 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:30,385 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4770
en_de Dev loss: 0.8713 r:0.2075
en_zh Dev loss: 0.7465 r:0.4454
ro_en Dev loss: 0.3209 r:0.8200
et_en Dev loss: 0.3517 r:0.7227
si_en Dev loss: 0.6544 r:0.6041
ne_en Dev loss: 0.3939 r:0.7699
ru_en Dev loss: 0.4660 r:0.7211
Current avg r:0.6129 Best avg r: 0.6283
18:24:00,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:30,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:00,811 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4464
en_de Dev loss: 0.8551 r:0.1988
en_zh Dev loss: 0.6621 r:0.4618
ro_en Dev loss: 0.2893 r:0.8245
et_en Dev loss: 0.3388 r:0.7239
si_en Dev loss: 0.6364 r:0.6029
ne_en Dev loss: 0.4206 r:0.7729
ru_en Dev loss: 0.4191 r:0.7318
Current avg r:0.6166 Best avg r: 0.6283
18:31:31,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:32:09,686 root INFO 
id:ro_en cur r: 0.8336 best r: 0.8336
18:33:01,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:31,192 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4552
en_de Dev loss: 0.8577 r:0.1928
en_zh Dev loss: 0.7204 r:0.4525
ro_en Dev loss: 0.2845 r:0.8308
et_en Dev loss: 0.3446 r:0.7292
si_en Dev loss: 0.5953 r:0.6159
ne_en Dev loss: 0.3490 r:0.7722
ru_en Dev loss: 0.4286 r:0.7442
Current avg r:0.6197 Best avg r: 0.6283
18:39:01,329 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:39,908 root INFO 
id:ro_en cur r: 0.8358 best r: 0.8358
18:40:31,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:01,384 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4340
en_de Dev loss: 0.8587 r:0.1803
en_zh Dev loss: 0.6671 r:0.4623
ro_en Dev loss: 0.2658 r:0.8333
et_en Dev loss: 0.3348 r:0.7315
si_en Dev loss: 0.5964 r:0.6147
ne_en Dev loss: 0.3352 r:0.7684
ru_en Dev loss: 0.4040 r:0.7430
Current avg r:0.6191 Best avg r: 0.6283
18:46:31,439 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:57,148 root INFO 
id:en_zh cur r: 0.4824 best r: 0.4824
18:48:01,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:49:31,447 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4608
en_de Dev loss: 0.8967 r:0.1605
en_zh Dev loss: 0.6602 r:0.4785
ro_en Dev loss: 0.2792 r:0.8308
et_en Dev loss: 0.3464 r:0.7278
si_en Dev loss: 0.5620 r:0.6202
ne_en Dev loss: 0.3485 r:0.7668
ru_en Dev loss: 0.3952 r:0.7443
Current avg r:0.6184 Best avg r: 0.6283
18:54:01,551 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:31,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:01,548 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4440
en_de Dev loss: 0.8630 r:0.1851
en_zh Dev loss: 0.6993 r:0.4629
ro_en Dev loss: 0.2948 r:0.8291
et_en Dev loss: 0.3531 r:0.7304
si_en Dev loss: 0.5953 r:0.6171
ne_en Dev loss: 0.3559 r:0.7658
ru_en Dev loss: 0.4333 r:0.7380
Current avg r:0.6183 Best avg r: 0.6283
19:01:31,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:01,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:04:31,572 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4645
en_de Dev loss: 0.8930 r:0.1684
en_zh Dev loss: 0.7215 r:0.4612
ro_en Dev loss: 0.3477 r:0.8156
et_en Dev loss: 0.3689 r:0.7142
si_en Dev loss: 0.9126 r:0.5895
ne_en Dev loss: 0.5125 r:0.7591
ru_en Dev loss: 0.4629 r:0.7266
Current avg r:0.6049 Best avg r: 0.6283
19:09:01,261 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:31,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:12:01,40 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4257
en_de Dev loss: 0.8663 r:0.2045
en_zh Dev loss: 0.7002 r:0.4673
ro_en Dev loss: 0.3165 r:0.8204
et_en Dev loss: 0.3595 r:0.7236
si_en Dev loss: 0.7268 r:0.6091
ne_en Dev loss: 0.4361 r:0.7638
ru_en Dev loss: 0.4500 r:0.7342
Current avg r:0.6176 Best avg r: 0.6283
19:16:32,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:02,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:19:32,354 root INFO Epoch 3 Global steps: 24500 Train loss: 0.3989
en_de Dev loss: 0.9091 r:0.1540
en_zh Dev loss: 0.6945 r:0.4704
ro_en Dev loss: 0.3173 r:0.8210
et_en Dev loss: 0.3898 r:0.7180
si_en Dev loss: 0.6994 r:0.6107
ne_en Dev loss: 0.3915 r:0.7578
ru_en Dev loss: 0.4212 r:0.7367
Current avg r:0.6098 Best avg r: 0.6283
19:24:02,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:32,174 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:02,66 root INFO Epoch 3 Global steps: 25200 Train loss: 0.3857
en_de Dev loss: 0.8752 r:0.1739
en_zh Dev loss: 0.6838 r:0.4693
ro_en Dev loss: 0.3093 r:0.8222
et_en Dev loss: 0.3699 r:0.7188
si_en Dev loss: 0.6941 r:0.6141
ne_en Dev loss: 0.4584 r:0.7561
ru_en Dev loss: 0.3994 r:0.7432
Current avg r:0.6139 Best avg r: 0.6283
19:31:31,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:01,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:34:31,775 root INFO Epoch 3 Global steps: 25900 Train loss: 0.3947
en_de Dev loss: 0.8819 r:0.1942
en_zh Dev loss: 0.7207 r:0.4634
ro_en Dev loss: 0.3348 r:0.8207
et_en Dev loss: 0.3921 r:0.7136
si_en Dev loss: 0.7076 r:0.6125
ne_en Dev loss: 0.4568 r:0.7565
ru_en Dev loss: 0.4532 r:0.7279
Current avg r:0.6127 Best avg r: 0.6283
19:39:01,500 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:31,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:01,341 root INFO Epoch 3 Global steps: 26600 Train loss: 0.3993
en_de Dev loss: 0.8837 r:0.1905
en_zh Dev loss: 0.7589 r:0.4598
ro_en Dev loss: 0.3534 r:0.8209
et_en Dev loss: 0.3665 r:0.7185
si_en Dev loss: 0.6951 r:0.6151
ne_en Dev loss: 0.4779 r:0.7670
ru_en Dev loss: 0.4796 r:0.7287
Current avg r:0.6144 Best avg r: 0.6283
19:46:31,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:01,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:49:30,972 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4233
en_de Dev loss: 0.8752 r:0.1815
en_zh Dev loss: 0.7180 r:0.4446
ro_en Dev loss: 0.3123 r:0.8155
et_en Dev loss: 0.3865 r:0.7066
si_en Dev loss: 0.6685 r:0.5922
ne_en Dev loss: 0.4042 r:0.7572
ru_en Dev loss: 0.4414 r:0.7128
Current avg r:0.6015 Best avg r: 0.6283
19:54:00,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:55:30,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:00,548 root INFO Epoch 3 Global steps: 28000 Train loss: 0.4163
en_de Dev loss: 0.8790 r:0.1877
en_zh Dev loss: 0.7560 r:0.4571
ro_en Dev loss: 0.3486 r:0.8179
et_en Dev loss: 0.3983 r:0.7056
si_en Dev loss: 0.7246 r:0.6012
ne_en Dev loss: 0.4585 r:0.7654
ru_en Dev loss: 0.5065 r:0.7102
Current avg r:0.6064 Best avg r: 0.6283
20:01:30,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:00,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:04:30,157 root INFO Epoch 3 Global steps: 28700 Train loss: 0.3934
en_de Dev loss: 0.8730 r:0.1981
en_zh Dev loss: 0.7303 r:0.4723
ro_en Dev loss: 0.3699 r:0.8162
et_en Dev loss: 0.4104 r:0.7052
si_en Dev loss: 0.6960 r:0.6046
ne_en Dev loss: 0.4350 r:0.7673
ru_en Dev loss: 0.4584 r:0.7351
Current avg r:0.6141 Best avg r: 0.6283
20:08:59,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:12,806 root INFO 
id:en_de cur r: 0.2350 best r: 0.2350
20:09:25,637 root INFO 
id:en_zh cur r: 0.4907 best r: 0.4907
20:10:17,113 root INFO 
id:ne_en cur r: 0.7767 best r: 0.7767
20:10:29,913 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:59,813 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3722
en_de Dev loss: 0.8583 r:0.2149
en_zh Dev loss: 0.6712 r:0.4866
ro_en Dev loss: 0.3014 r:0.8282
et_en Dev loss: 0.3754 r:0.7173
si_en Dev loss: 0.5953 r:0.6209
ne_en Dev loss: 0.3505 r:0.7735
ru_en Dev loss: 0.4008 r:0.7556
Current avg r:0.6281 Best avg r: 0.6283
20:16:29,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:42,495 root INFO 
id:en_de cur r: 0.2374 best r: 0.2374
20:17:59,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:19:29,489 root INFO Epoch 3 Global steps: 30100 Train loss: 0.3973
en_de Dev loss: 0.8469 r:0.2181
en_zh Dev loss: 0.7016 r:0.4715
ro_en Dev loss: 0.3241 r:0.8186
et_en Dev loss: 0.3803 r:0.7006
si_en Dev loss: 0.7714 r:0.5876
ne_en Dev loss: 0.4522 r:0.7612
ru_en Dev loss: 0.4255 r:0.7391
Current avg r:0.6138 Best avg r: 0.6283
20:23:59,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:29,138 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:59,44 root INFO Epoch 3 Global steps: 30800 Train loss: 0.3797
en_de Dev loss: 0.8621 r:0.1853
en_zh Dev loss: 0.7085 r:0.4686
ro_en Dev loss: 0.3245 r:0.8259
et_en Dev loss: 0.3959 r:0.7060
si_en Dev loss: 0.7224 r:0.6001
ne_en Dev loss: 0.4074 r:0.7636
ru_en Dev loss: 0.4215 r:0.7431
Current avg r:0.6132 Best avg r: 0.6283
20:31:28,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:58,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:34:28,454 root INFO Epoch 3 Global steps: 31500 Train loss: 0.3830
en_de Dev loss: 0.8708 r:0.1967
en_zh Dev loss: 0.7171 r:0.4774
ro_en Dev loss: 0.3151 r:0.8269
et_en Dev loss: 0.3941 r:0.7054
si_en Dev loss: 0.6826 r:0.6063
ne_en Dev loss: 0.3973 r:0.7594
ru_en Dev loss: 0.4211 r:0.7485
Current avg r:0.6172 Best avg r: 0.6283
20:38:59,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:29,913 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:00,179 root INFO Epoch 4 Global steps: 32200 Train loss: 0.3530
en_de Dev loss: 0.8781 r:0.1666
en_zh Dev loss: 0.7181 r:0.4595
ro_en Dev loss: 0.2994 r:0.8234
et_en Dev loss: 0.3921 r:0.6973
si_en Dev loss: 0.6877 r:0.5930
ne_en Dev loss: 0.4484 r:0.7598
ru_en Dev loss: 0.3935 r:0.7463
Current avg r:0.6066 Best avg r: 0.6283
20:46:30,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:00,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:30,144 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3610
en_de Dev loss: 0.8899 r:0.1660
en_zh Dev loss: 0.7587 r:0.4487
ro_en Dev loss: 0.3316 r:0.8197
et_en Dev loss: 0.3976 r:0.6948
si_en Dev loss: 0.7261 r:0.5872
ne_en Dev loss: 0.4741 r:0.7553
ru_en Dev loss: 0.4670 r:0.7178
Current avg r:0.5985 Best avg r: 0.6283
20:53:59,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:29,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:59,704 root INFO Epoch 4 Global steps: 33600 Train loss: 0.3508
en_de Dev loss: 0.8810 r:0.1820
en_zh Dev loss: 0.7725 r:0.4447
ro_en Dev loss: 0.3418 r:0.8166
et_en Dev loss: 0.4104 r:0.6920
si_en Dev loss: 0.7159 r:0.5840
ne_en Dev loss: 0.4486 r:0.7570
ru_en Dev loss: 0.4483 r:0.7316
Current avg r:0.6011 Best avg r: 0.6283
21:01:29,466 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:59,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:29,334 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3317
en_de Dev loss: 0.8843 r:0.1830
en_zh Dev loss: 0.7546 r:0.4504
ro_en Dev loss: 0.3084 r:0.8287
et_en Dev loss: 0.3928 r:0.6989
si_en Dev loss: 0.7742 r:0.5937
ne_en Dev loss: 0.4909 r:0.7608
ru_en Dev loss: 0.4590 r:0.7273
Current avg r:0.6061 Best avg r: 0.6283
21:08:59,206 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:29,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:59,16 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3387
en_de Dev loss: 0.8823 r:0.1999
en_zh Dev loss: 0.7510 r:0.4579
ro_en Dev loss: 0.3341 r:0.8261
et_en Dev loss: 0.4091 r:0.7073
si_en Dev loss: 0.7245 r:0.6031
ne_en Dev loss: 0.4083 r:0.7654
ru_en Dev loss: 0.4679 r:0.7321
Current avg r:0.6131 Best avg r: 0.6283
21:16:28,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:58,826 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:28,726 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3328
en_de Dev loss: 0.8746 r:0.2001
en_zh Dev loss: 0.7377 r:0.4590
ro_en Dev loss: 0.3077 r:0.8305
et_en Dev loss: 0.3938 r:0.7069
si_en Dev loss: 0.7061 r:0.6074
ne_en Dev loss: 0.4004 r:0.7681
ru_en Dev loss: 0.3977 r:0.7551
Current avg r:0.6182 Best avg r: 0.6283
21:23:58,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:28,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:58,357 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3496
en_de Dev loss: 0.8653 r:0.2059
en_zh Dev loss: 0.7787 r:0.4458
ro_en Dev loss: 0.3445 r:0.8242
et_en Dev loss: 0.4260 r:0.7024
si_en Dev loss: 0.8217 r:0.5893
ne_en Dev loss: 0.4469 r:0.7580
ru_en Dev loss: 0.4181 r:0.7512
Current avg r:0.6110 Best avg r: 0.6283
21:31:28,112 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:58,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:28,41 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3520
en_de Dev loss: 0.8591 r:0.2034
en_zh Dev loss: 0.7067 r:0.4650
ro_en Dev loss: 0.3011 r:0.8254
et_en Dev loss: 0.4197 r:0.6906
si_en Dev loss: 0.6773 r:0.5906
ne_en Dev loss: 0.4164 r:0.7566
ru_en Dev loss: 0.3898 r:0.7419
Current avg r:0.6105 Best avg r: 0.6283
21:38:57,854 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:27,823 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:57,743 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3525
en_de Dev loss: 0.8668 r:0.1766
en_zh Dev loss: 0.7659 r:0.4272
ro_en Dev loss: 0.3479 r:0.8158
et_en Dev loss: 0.4091 r:0.6828
si_en Dev loss: 0.7874 r:0.5794
ne_en Dev loss: 0.5056 r:0.7533
ru_en Dev loss: 0.4462 r:0.7231
Current avg r:0.5940 Best avg r: 0.6283
21:46:27,569 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:57,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:27,497 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3361
en_de Dev loss: 0.8859 r:0.1767
en_zh Dev loss: 0.8174 r:0.4282
ro_en Dev loss: 0.3664 r:0.8131
et_en Dev loss: 0.4320 r:0.6796
si_en Dev loss: 0.8182 r:0.5774
ne_en Dev loss: 0.5115 r:0.7523
ru_en Dev loss: 0.5050 r:0.7076
Current avg r:0.5907 Best avg r: 0.6283
21:53:57,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:27,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:57,137 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3314
en_de Dev loss: 0.8797 r:0.1938
en_zh Dev loss: 0.7827 r:0.4229
ro_en Dev loss: 0.3574 r:0.8136
et_en Dev loss: 0.4305 r:0.6731
si_en Dev loss: 0.7781 r:0.5782
ne_en Dev loss: 0.4796 r:0.7565
ru_en Dev loss: 0.4499 r:0.7260
Current avg r:0.5949 Best avg r: 0.6283
22:01:28,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:02:58,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:28,837 root INFO Epoch 5 Global steps: 39900 Train loss: 0.2987
en_de Dev loss: 0.8704 r:0.1960
en_zh Dev loss: 0.7307 r:0.4548
ro_en Dev loss: 0.3349 r:0.8206
et_en Dev loss: 0.4535 r:0.6930
si_en Dev loss: 0.6859 r:0.5934
ne_en Dev loss: 0.3876 r:0.7612
ru_en Dev loss: 0.4128 r:0.7437
Current avg r:0.6090 Best avg r: 0.6283
22:08:58,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:29,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:59,12 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3281
en_de Dev loss: 0.8741 r:0.1812
en_zh Dev loss: 0.7452 r:0.4474
ro_en Dev loss: 0.3342 r:0.8159
et_en Dev loss: 0.4315 r:0.6722
si_en Dev loss: 0.7504 r:0.5761
ne_en Dev loss: 0.4757 r:0.7533
ru_en Dev loss: 0.4885 r:0.6996
Current avg r:0.5922 Best avg r: 0.6283
22:16:28,991 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:58,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:28,980 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3032
en_de Dev loss: 0.8740 r:0.1790
en_zh Dev loss: 0.7577 r:0.4480
ro_en Dev loss: 0.3299 r:0.8185
et_en Dev loss: 0.4327 r:0.6818
si_en Dev loss: 0.7132 r:0.5893
ne_en Dev loss: 0.4507 r:0.7548
ru_en Dev loss: 0.4274 r:0.7344
Current avg r:0.6008 Best avg r: 0.6283
22:23:58,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:28,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:58,891 root INFO Epoch 5 Global steps: 42000 Train loss: 0.2989
en_de Dev loss: 0.8885 r:0.1972
en_zh Dev loss: 0.8049 r:0.4522
ro_en Dev loss: 0.3829 r:0.8148
et_en Dev loss: 0.4437 r:0.6816
si_en Dev loss: 0.8504 r:0.5794
ne_en Dev loss: 0.4781 r:0.7524
ru_en Dev loss: 0.4716 r:0.7316
Current avg r:0.6013 Best avg r: 0.6283
22:31:28,696 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:58,740 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:28,730 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3109
en_de Dev loss: 0.8822 r:0.1996
en_zh Dev loss: 0.7382 r:0.4785
ro_en Dev loss: 0.3190 r:0.8267
et_en Dev loss: 0.4459 r:0.6987
si_en Dev loss: 0.6513 r:0.6037
ne_en Dev loss: 0.3910 r:0.7526
ru_en Dev loss: 0.3852 r:0.7602
Current avg r:0.6171 Best avg r: 0.6283
22:38:58,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:28,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:58,511 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3154
en_de Dev loss: 0.8678 r:0.1978
en_zh Dev loss: 0.7321 r:0.4555
ro_en Dev loss: 0.3192 r:0.8243
et_en Dev loss: 0.4232 r:0.6893
si_en Dev loss: 0.6974 r:0.5859
ne_en Dev loss: 0.4574 r:0.7570
ru_en Dev loss: 0.4200 r:0.7352
Current avg r:0.6064 Best avg r: 0.6283
22:46:28,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:58,493 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:28,498 root INFO Epoch 5 Global steps: 44100 Train loss: 0.3155
en_de Dev loss: 0.8833 r:0.2138
en_zh Dev loss: 0.7695 r:0.4607
ro_en Dev loss: 0.4066 r:0.8074
et_en Dev loss: 0.4517 r:0.6664
si_en Dev loss: 0.9749 r:0.5613
ne_en Dev loss: 0.6801 r:0.7460
ru_en Dev loss: 0.5199 r:0.7112
Current avg r:0.5953 Best avg r: 0.6283
22:53:58,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:28,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:58,451 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3052
en_de Dev loss: 0.8648 r:0.2175
en_zh Dev loss: 0.7402 r:0.4653
ro_en Dev loss: 0.3544 r:0.8169
et_en Dev loss: 0.4348 r:0.6804
si_en Dev loss: 0.8384 r:0.5772
ne_en Dev loss: 0.5066 r:0.7519
ru_en Dev loss: 0.4225 r:0.7433
Current avg r:0.6075 Best avg r: 0.6283
23:01:28,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:58,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:28,517 root INFO Epoch 5 Global steps: 45500 Train loss: 0.2953
en_de Dev loss: 0.8714 r:0.2025
en_zh Dev loss: 0.7512 r:0.4583
ro_en Dev loss: 0.3367 r:0.8206
et_en Dev loss: 0.4400 r:0.6912
si_en Dev loss: 0.7362 r:0.5868
ne_en Dev loss: 0.4478 r:0.7526
ru_en Dev loss: 0.4225 r:0.7420
Current avg r:0.6077 Best avg r: 0.6283
23:08:58,557 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:28,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:58,582 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2850
en_de Dev loss: 0.9109 r:0.1916
en_zh Dev loss: 0.8120 r:0.4490
ro_en Dev loss: 0.3618 r:0.8193
et_en Dev loss: 0.4428 r:0.6905
si_en Dev loss: 0.7429 r:0.5867
ne_en Dev loss: 0.4521 r:0.7504
ru_en Dev loss: 0.4592 r:0.7459
Current avg r:0.6048 Best avg r: 0.6283
23:16:28,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:58,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:28,514 root INFO Epoch 5 Global steps: 46900 Train loss: 0.2933
en_de Dev loss: 0.8713 r:0.2076
en_zh Dev loss: 0.7623 r:0.4566
ro_en Dev loss: 0.3309 r:0.8208
et_en Dev loss: 0.4380 r:0.6884
si_en Dev loss: 0.7417 r:0.5823
ne_en Dev loss: 0.4558 r:0.7481
ru_en Dev loss: 0.4209 r:0.7480
Current avg r:0.6074 Best avg r: 0.6283
23:23:58,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:28,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:58,317 root INFO Epoch 5 Global steps: 47600 Train loss: 0.2766
en_de Dev loss: 0.8751 r:0.2146
en_zh Dev loss: 0.7961 r:0.4510
ro_en Dev loss: 0.3807 r:0.8150
et_en Dev loss: 0.4474 r:0.6813
si_en Dev loss: 0.8357 r:0.5778
ne_en Dev loss: 0.4880 r:0.7492
ru_en Dev loss: 0.4969 r:0.7244
Current avg r:0.6019 Best avg r: 0.6283
23:31:29,707 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:59,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:34:29,641 root INFO Epoch 6 Global steps: 48300 Train loss: 0.2813
en_de Dev loss: 0.8594 r:0.2105
en_zh Dev loss: 0.7605 r:0.4487
ro_en Dev loss: 0.3259 r:0.8178
et_en Dev loss: 0.4533 r:0.6842
si_en Dev loss: 0.7496 r:0.5807
ne_en Dev loss: 0.4191 r:0.7473
ru_en Dev loss: 0.4036 r:0.7484
Current avg r:0.6054 Best avg r: 0.6283
23:38:59,586 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:29,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:59,641 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2771
en_de Dev loss: 0.8767 r:0.1924
en_zh Dev loss: 0.7662 r:0.4553
ro_en Dev loss: 0.3504 r:0.8152
et_en Dev loss: 0.4322 r:0.6690
si_en Dev loss: 0.8531 r:0.5788
ne_en Dev loss: 0.5029 r:0.7435
ru_en Dev loss: 0.4427 r:0.7341
Current avg r:0.5983 Best avg r: 0.6283
23:46:29,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:59,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:29,704 root INFO Epoch 6 Global steps: 49700 Train loss: 0.2714
en_de Dev loss: 0.8644 r:0.2310
en_zh Dev loss: 0.7602 r:0.4661
ro_en Dev loss: 0.3607 r:0.8144
et_en Dev loss: 0.4447 r:0.6636
si_en Dev loss: 0.8597 r:0.5743
ne_en Dev loss: 0.5258 r:0.7368
ru_en Dev loss: 0.4735 r:0.7225
Current avg r:0.6013 Best avg r: 0.6283
23:53:59,573 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:29,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:59,547 root INFO Epoch 6 Global steps: 50400 Train loss: 0.2673
en_de Dev loss: 0.8731 r:0.2161
en_zh Dev loss: 0.7789 r:0.4576
ro_en Dev loss: 0.3601 r:0.8119
et_en Dev loss: 0.4913 r:0.6586
si_en Dev loss: 0.7802 r:0.5687
ne_en Dev loss: 0.4900 r:0.7323
ru_en Dev loss: 0.4842 r:0.7036
Current avg r:0.5927 Best avg r: 0.6283
00:01:29,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:59,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:29,331 root INFO Epoch 6 Global steps: 51100 Train loss: 0.2773
en_de Dev loss: 0.8773 r:0.1973
en_zh Dev loss: 0.7629 r:0.4568
ro_en Dev loss: 0.3403 r:0.8197
et_en Dev loss: 0.4320 r:0.6821
si_en Dev loss: 0.8265 r:0.5788
ne_en Dev loss: 0.4544 r:0.7399
ru_en Dev loss: 0.4466 r:0.7357
Current avg r:0.6015 Best avg r: 0.6283
00:08:59,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:29,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:59,362 root INFO Epoch 6 Global steps: 51800 Train loss: 0.2577
en_de Dev loss: 0.8766 r:0.2109
en_zh Dev loss: 0.7781 r:0.4641
ro_en Dev loss: 0.3506 r:0.8179
et_en Dev loss: 0.4753 r:0.6744
si_en Dev loss: 0.7920 r:0.5780
ne_en Dev loss: 0.4687 r:0.7345
ru_en Dev loss: 0.4723 r:0.7175
Current avg r:0.5996 Best avg r: 0.6283
00:16:29,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:59,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:29,239 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2731
en_de Dev loss: 0.8832 r:0.2077
en_zh Dev loss: 0.7495 r:0.4750
ro_en Dev loss: 0.3282 r:0.8196
et_en Dev loss: 0.4386 r:0.6853
si_en Dev loss: 0.6785 r:0.5943
ne_en Dev loss: 0.4207 r:0.7376
ru_en Dev loss: 0.4406 r:0.7379
Current avg r:0.6082 Best avg r: 0.6283
00:23:59,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:25:29,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:26:59,201 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2724
en_de Dev loss: 0.8752 r:0.1943
en_zh Dev loss: 0.8009 r:0.4559
ro_en Dev loss: 0.3658 r:0.8201
et_en Dev loss: 0.4538 r:0.6694
si_en Dev loss: 0.8920 r:0.5714
ne_en Dev loss: 0.5322 r:0.7376
ru_en Dev loss: 0.5272 r:0.7084
Current avg r:0.5939 Best avg r: 0.6283
00:31:29,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:32:59,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:29,54 root INFO Epoch 6 Global steps: 53900 Train loss: 0.2650
en_de Dev loss: 0.8895 r:0.1972
en_zh Dev loss: 0.7345 r:0.4875
ro_en Dev loss: 0.3358 r:0.8284
et_en Dev loss: 0.4322 r:0.6935
si_en Dev loss: 0.7572 r:0.5860
ne_en Dev loss: 0.4457 r:0.7464
ru_en Dev loss: 0.4536 r:0.7402
Current avg r:0.6113 Best avg r: 0.6283
00:38:58,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:28,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:58,905 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2441
en_de Dev loss: 0.8936 r:0.1950
en_zh Dev loss: 0.7839 r:0.4650
ro_en Dev loss: 0.3432 r:0.8198
et_en Dev loss: 0.4750 r:0.6751
si_en Dev loss: 0.7325 r:0.5830
ne_en Dev loss: 0.4033 r:0.7426
ru_en Dev loss: 0.4500 r:0.7286
Current avg r:0.6013 Best avg r: 0.6283
00:46:28,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:47:59,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:28,989 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2629
en_de Dev loss: 0.8826 r:0.1781
en_zh Dev loss: 0.7244 r:0.4718
ro_en Dev loss: 0.3054 r:0.8266
et_en Dev loss: 0.4085 r:0.6853
si_en Dev loss: 0.7558 r:0.5775
ne_en Dev loss: 0.4298 r:0.7456
ru_en Dev loss: 0.4236 r:0.7405
Current avg r:0.6036 Best avg r: 0.6283
00:54:00,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:30,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:00,291 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2466
en_de Dev loss: 0.9128 r:0.1922
en_zh Dev loss: 0.8186 r:0.4535
ro_en Dev loss: 0.3739 r:0.8185
et_en Dev loss: 0.4656 r:0.6696
si_en Dev loss: 0.8677 r:0.5711
ne_en Dev loss: 0.5886 r:0.7413
ru_en Dev loss: 0.5553 r:0.7079
Current avg r:0.5934 Best avg r: 0.6283
01:01:30,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:00,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:30,162 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2560
en_de Dev loss: 0.8683 r:0.2060
en_zh Dev loss: 0.7907 r:0.4544
ro_en Dev loss: 0.3504 r:0.8198
et_en Dev loss: 0.4283 r:0.6808
si_en Dev loss: 0.8403 r:0.5681
ne_en Dev loss: 0.5280 r:0.7472
ru_en Dev loss: 0.4538 r:0.7345
Current avg r:0.6015 Best avg r: 0.6283
01:09:00,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:30,48 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:00,30 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2330
en_de Dev loss: 0.8771 r:0.2115
en_zh Dev loss: 0.7921 r:0.4650
ro_en Dev loss: 0.3394 r:0.8222
et_en Dev loss: 0.4481 r:0.6785
si_en Dev loss: 0.7949 r:0.5686
ne_en Dev loss: 0.4963 r:0.7467
ru_en Dev loss: 0.4671 r:0.7296
Current avg r:0.6032 Best avg r: 0.6283
01:16:30,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:59,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:29,930 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2436
en_de Dev loss: 0.8752 r:0.2141
en_zh Dev loss: 0.8138 r:0.4636
ro_en Dev loss: 0.3584 r:0.8186
et_en Dev loss: 0.4608 r:0.6717
si_en Dev loss: 0.8870 r:0.5595
ne_en Dev loss: 0.5631 r:0.7374
ru_en Dev loss: 0.5143 r:0.7243
Current avg r:0.5985 Best avg r: 0.6283
01:23:59,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:29,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:59,929 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2296
en_de Dev loss: 0.8748 r:0.1973
en_zh Dev loss: 0.7982 r:0.4574
ro_en Dev loss: 0.3656 r:0.8158
et_en Dev loss: 0.4532 r:0.6640
si_en Dev loss: 0.8419 r:0.5595
ne_en Dev loss: 0.4873 r:0.7407
ru_en Dev loss: 0.4777 r:0.7259
Current avg r:0.5944 Best avg r: 0.6283
01:31:29,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:32:59,829 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:29,810 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2380
en_de Dev loss: 0.8942 r:0.1863
en_zh Dev loss: 0.8224 r:0.4491
ro_en Dev loss: 0.3616 r:0.8196
et_en Dev loss: 0.4724 r:0.6676
si_en Dev loss: 0.8485 r:0.5602
ne_en Dev loss: 0.4988 r:0.7401
ru_en Dev loss: 0.5029 r:0.7187
Current avg r:0.5917 Best avg r: 0.6283
01:38:59,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:40:29,564 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:41:59,560 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2369
en_de Dev loss: 0.8687 r:0.2005
en_zh Dev loss: 0.7707 r:0.4420
ro_en Dev loss: 0.3085 r:0.8238
et_en Dev loss: 0.4609 r:0.6819
si_en Dev loss: 0.7378 r:0.5780
ne_en Dev loss: 0.4128 r:0.7474
ru_en Dev loss: 0.4048 r:0.7463
Current avg r:0.6029 Best avg r: 0.6283
01:46:29,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:47:59,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:49:29,354 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2311
en_de Dev loss: 0.8875 r:0.1969
en_zh Dev loss: 0.7407 r:0.4710
ro_en Dev loss: 0.3041 r:0.8292
et_en Dev loss: 0.4271 r:0.6874
si_en Dev loss: 0.7637 r:0.5805
ne_en Dev loss: 0.4113 r:0.7524
ru_en Dev loss: 0.4205 r:0.7533
Current avg r:0.6101 Best avg r: 0.6283
01:53:59,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:55:29,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:56:59,308 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2300
en_de Dev loss: 0.8736 r:0.1982
en_zh Dev loss: 0.7266 r:0.4686
ro_en Dev loss: 0.3019 r:0.8245
et_en Dev loss: 0.4436 r:0.6771
si_en Dev loss: 0.7902 r:0.5680
ne_en Dev loss: 0.4967 r:0.7418
ru_en Dev loss: 0.4056 r:0.7490
Current avg r:0.6039 Best avg r: 0.6283
02:01:29,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:02:59,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:04:29,233 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2262
en_de Dev loss: 0.8846 r:0.1907
en_zh Dev loss: 0.8032 r:0.4549
ro_en Dev loss: 0.3653 r:0.8197
et_en Dev loss: 0.4639 r:0.6709
si_en Dev loss: 0.8419 r:0.5696
ne_en Dev loss: 0.5351 r:0.7444
ru_en Dev loss: 0.4630 r:0.7359
Current avg r:0.5980 Best avg r: 0.6283
02:08:59,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:10:29,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:11:59,402 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2225
en_de Dev loss: 0.8739 r:0.2004
en_zh Dev loss: 0.7605 r:0.4579
ro_en Dev loss: 0.3269 r:0.8220
et_en Dev loss: 0.4375 r:0.6740
si_en Dev loss: 0.7963 r:0.5670
ne_en Dev loss: 0.4921 r:0.7397
ru_en Dev loss: 0.4663 r:0.7234
Current avg r:0.5978 Best avg r: 0.6283
02:16:30,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:18:00,800 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:30,776 root INFO Epoch 8 Global steps: 63700 Train loss: 0.1709
en_de Dev loss: 0.8807 r:0.1958
en_zh Dev loss: 0.7638 r:0.4610
ro_en Dev loss: 0.3480 r:0.8207
et_en Dev loss: 0.4723 r:0.6776
si_en Dev loss: 0.7860 r:0.5661
ne_en Dev loss: 0.5080 r:0.7336
ru_en Dev loss: 0.4551 r:0.7283
Current avg r:0.5976 Best avg r: 0.6283
02:24:00,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:25:30,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:00,953 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2152
en_de Dev loss: 0.8888 r:0.1999
en_zh Dev loss: 0.7788 r:0.4761
ro_en Dev loss: 0.3552 r:0.8241
et_en Dev loss: 0.4558 r:0.6838
si_en Dev loss: 0.8445 r:0.5736
ne_en Dev loss: 0.5597 r:0.7374
ru_en Dev loss: 0.4427 r:0.7481
Current avg r:0.6062 Best avg r: 0.6283
02:31:30,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:33:00,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:34:30,948 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2066
en_de Dev loss: 0.8874 r:0.1992
en_zh Dev loss: 0.7924 r:0.4600
ro_en Dev loss: 0.3372 r:0.8175
et_en Dev loss: 0.4707 r:0.6708
si_en Dev loss: 0.7875 r:0.5662
ne_en Dev loss: 0.5119 r:0.7357
ru_en Dev loss: 0.4412 r:0.7348
Current avg r:0.5977 Best avg r: 0.6283
02:39:01,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:40:30,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:42:00,924 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2080
en_de Dev loss: 0.9036 r:0.1880
en_zh Dev loss: 0.8407 r:0.4560
ro_en Dev loss: 0.3615 r:0.8183
et_en Dev loss: 0.4653 r:0.6714
si_en Dev loss: 0.8779 r:0.5530
ne_en Dev loss: 0.5371 r:0.7381
ru_en Dev loss: 0.4833 r:0.7281
Current avg r:0.5933 Best avg r: 0.6283
02:46:30,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:48:00,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:49:30,769 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2125
en_de Dev loss: 0.8896 r:0.1839
en_zh Dev loss: 0.7638 r:0.4627
ro_en Dev loss: 0.3206 r:0.8192
et_en Dev loss: 0.4800 r:0.6706
si_en Dev loss: 0.7928 r:0.5610
ne_en Dev loss: 0.4852 r:0.7305
ru_en Dev loss: 0.4421 r:0.7304
Current avg r:0.5941 Best avg r: 0.6283
02:54:00,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:55:30,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:57:00,552 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2156
en_de Dev loss: 0.8969 r:0.1943
en_zh Dev loss: 0.7512 r:0.4733
ro_en Dev loss: 0.3271 r:0.8229
et_en Dev loss: 0.4725 r:0.6842
si_en Dev loss: 0.7526 r:0.5754
ne_en Dev loss: 0.4231 r:0.7381
ru_en Dev loss: 0.4219 r:0.7467
Current avg r:0.6050 Best avg r: 0.6283
03:01:30,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:00,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:30,474 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2013
en_de Dev loss: 0.8969 r:0.1926
en_zh Dev loss: 0.7304 r:0.4820
ro_en Dev loss: 0.3115 r:0.8242
et_en Dev loss: 0.4578 r:0.6893
si_en Dev loss: 0.7483 r:0.5776
ne_en Dev loss: 0.4496 r:0.7306
ru_en Dev loss: 0.3956 r:0.7563
Current avg r:0.6075 Best avg r: 0.6283
03:09:00,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:30,270 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:12:00,260 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2050
en_de Dev loss: 0.9164 r:0.1730
en_zh Dev loss: 0.7871 r:0.4703
ro_en Dev loss: 0.3516 r:0.8189
et_en Dev loss: 0.4752 r:0.6776
si_en Dev loss: 0.8318 r:0.5621
ne_en Dev loss: 0.5401 r:0.7224
ru_en Dev loss: 0.4714 r:0.7302
Current avg r:0.5935 Best avg r: 0.6283
03:16:30,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:18:00,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:30,118 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2127
en_de Dev loss: 0.9017 r:0.1993
en_zh Dev loss: 0.7754 r:0.4770
ro_en Dev loss: 0.3384 r:0.8238
et_en Dev loss: 0.4884 r:0.6851
si_en Dev loss: 0.7797 r:0.5725
ne_en Dev loss: 0.4904 r:0.7230
ru_en Dev loss: 0.4187 r:0.7518
Current avg r:0.6046 Best avg r: 0.6283
03:24:00,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:25:30,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:27:00,12 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2085
en_de Dev loss: 0.8940 r:0.1877
en_zh Dev loss: 0.7862 r:0.4672
ro_en Dev loss: 0.3500 r:0.8177
et_en Dev loss: 0.4478 r:0.6788
si_en Dev loss: 0.8789 r:0.5618
ne_en Dev loss: 0.5552 r:0.7258
ru_en Dev loss: 0.4842 r:0.7294
Current avg r:0.5955 Best avg r: 0.6283
03:31:29,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:32:59,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:34:29,724 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2097
en_de Dev loss: 0.8850 r:0.1922
en_zh Dev loss: 0.8007 r:0.4702
ro_en Dev loss: 0.3763 r:0.8150
et_en Dev loss: 0.4819 r:0.6652
si_en Dev loss: 0.9931 r:0.5490
ne_en Dev loss: 0.6918 r:0.7208
ru_en Dev loss: 0.5124 r:0.7197
Current avg r:0.5903 Best avg r: 0.6283
03:38:59,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:29,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:59,643 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2054
en_de Dev loss: 0.8838 r:0.1882
en_zh Dev loss: 0.7706 r:0.4677
ro_en Dev loss: 0.3195 r:0.8234
et_en Dev loss: 0.4794 r:0.6746
si_en Dev loss: 0.8244 r:0.5608
ne_en Dev loss: 0.5100 r:0.7284
ru_en Dev loss: 0.4101 r:0.7461
Current avg r:0.5984 Best avg r: 0.6283
03:46:31,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:46:56,848 root INFO 
id:en_zh cur r: 0.4988 best r: 0.4988
03:48:01,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:49:31,205 root INFO Epoch 9 Global steps: 72100 Train loss: 0.1874
en_de Dev loss: 0.8917 r:0.2072
en_zh Dev loss: 0.7365 r:0.4911
ro_en Dev loss: 0.3147 r:0.8218
et_en Dev loss: 0.4838 r:0.6838
si_en Dev loss: 0.7233 r:0.5728
ne_en Dev loss: 0.4636 r:0.7250
ru_en Dev loss: 0.3883 r:0.7574
Current avg r:0.6085 Best avg r: 0.6283
03:54:01,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:55:31,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:57:01,159 root INFO Epoch 9 Global steps: 72800 Train loss: 0.1839
en_de Dev loss: 0.8828 r:0.2030
en_zh Dev loss: 0.7903 r:0.4644
ro_en Dev loss: 0.3526 r:0.8206
et_en Dev loss: 0.4802 r:0.6653
si_en Dev loss: 0.8768 r:0.5507
ne_en Dev loss: 0.5661 r:0.7263
ru_en Dev loss: 0.4611 r:0.7329
Current avg r:0.5947 Best avg r: 0.6283
04:01:31,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:03:01,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:30,969 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1923
en_de Dev loss: 0.9029 r:0.1960
en_zh Dev loss: 0.7533 r:0.4767
ro_en Dev loss: 0.3413 r:0.8183
et_en Dev loss: 0.4618 r:0.6697
si_en Dev loss: 0.8996 r:0.5515
ne_en Dev loss: 0.5683 r:0.7247
ru_en Dev loss: 0.4487 r:0.7407
Current avg r:0.5968 Best avg r: 0.6283
04:09:00,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:10:30,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:12:00,774 root INFO Epoch 9 Global steps: 74200 Train loss: 0.1922
en_de Dev loss: 0.8896 r:0.1885
en_zh Dev loss: 0.7649 r:0.4654
ro_en Dev loss: 0.3395 r:0.8182
et_en Dev loss: 0.4403 r:0.6674
si_en Dev loss: 0.9180 r:0.5353
ne_en Dev loss: 0.6337 r:0.7131
ru_en Dev loss: 0.4704 r:0.7296
Current avg r:0.5882 Best avg r: 0.6283
04:16:30,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:18:00,667 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:30,669 root INFO Epoch 9 Global steps: 74900 Train loss: 0.1899
en_de Dev loss: 0.9123 r:0.1805
en_zh Dev loss: 0.8182 r:0.4574
ro_en Dev loss: 0.3467 r:0.8171
et_en Dev loss: 0.4424 r:0.6758
si_en Dev loss: 0.9168 r:0.5540
ne_en Dev loss: 0.6097 r:0.7198
ru_en Dev loss: 0.4635 r:0.7402
Current avg r:0.5921 Best avg r: 0.6283
04:24:00,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:25:30,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:27:00,410 root INFO Epoch 9 Global steps: 75600 Train loss: 0.2002
en_de Dev loss: 0.9045 r:0.1835
en_zh Dev loss: 0.7839 r:0.4663
ro_en Dev loss: 0.3379 r:0.8177
et_en Dev loss: 0.4328 r:0.6764
si_en Dev loss: 0.8363 r:0.5674
ne_en Dev loss: 0.5519 r:0.7116
ru_en Dev loss: 0.4553 r:0.7388
Current avg r:0.5945 Best avg r: 0.6283
04:31:30,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:33:00,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:34:30,289 root INFO Epoch 9 Global steps: 76300 Train loss: 0.1986
en_de Dev loss: 0.8944 r:0.1907
en_zh Dev loss: 0.7940 r:0.4723
ro_en Dev loss: 0.3573 r:0.8150
et_en Dev loss: 0.4625 r:0.6680
si_en Dev loss: 0.9159 r:0.5603
ne_en Dev loss: 0.6356 r:0.7178
ru_en Dev loss: 0.4627 r:0.7343
Current avg r:0.5940 Best avg r: 0.6283
04:38:59,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:40:30,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:41:59,997 root INFO Epoch 9 Global steps: 77000 Train loss: 0.1966
en_de Dev loss: 0.9021 r:0.1755
en_zh Dev loss: 0.7885 r:0.4563
ro_en Dev loss: 0.3409 r:0.8127
et_en Dev loss: 0.4432 r:0.6594
si_en Dev loss: 0.9084 r:0.5500
ne_en Dev loss: 0.5904 r:0.7203
ru_en Dev loss: 0.4883 r:0.7124
Current avg r:0.5838 Best avg r: 0.6283
04:46:29,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:47:59,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:49:29,657 root INFO Epoch 9 Global steps: 77700 Train loss: 0.1883
en_de Dev loss: 0.9304 r:0.1947
en_zh Dev loss: 0.8178 r:0.4675
ro_en Dev loss: 0.3595 r:0.8204
et_en Dev loss: 0.4765 r:0.6589
si_en Dev loss: 0.9205 r:0.5434
ne_en Dev loss: 0.5768 r:0.7231
ru_en Dev loss: 0.4909 r:0.7315
Current avg r:0.5913 Best avg r: 0.6283
04:53:59,501 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:55:29,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:56:59,535 root INFO Epoch 9 Global steps: 78400 Train loss: 0.1831
en_de Dev loss: 0.9092 r:0.1820
en_zh Dev loss: 0.8200 r:0.4647
ro_en Dev loss: 0.3522 r:0.8173
et_en Dev loss: 0.4629 r:0.6653
si_en Dev loss: 0.9064 r:0.5462
ne_en Dev loss: 0.5275 r:0.7242
ru_en Dev loss: 0.4666 r:0.7387
Current avg r:0.5912 Best avg r: 0.6283
05:01:29,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:02:59,401 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:04:29,389 root INFO Epoch 9 Global steps: 79100 Train loss: 0.1862
en_de Dev loss: 0.9051 r:0.1866
en_zh Dev loss: 0.8034 r:0.4660
ro_en Dev loss: 0.3614 r:0.8149
et_en Dev loss: 0.4959 r:0.6687
si_en Dev loss: 0.8821 r:0.5478
ne_en Dev loss: 0.5364 r:0.7254
ru_en Dev loss: 0.4319 r:0.7430
Current avg r:0.5932 Best avg r: 0.6283
05:09:00,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:30,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:12:00,721 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1799
en_de Dev loss: 0.8975 r:0.1791
en_zh Dev loss: 0.7391 r:0.4749
ro_en Dev loss: 0.3261 r:0.8197
et_en Dev loss: 0.4599 r:0.6652
si_en Dev loss: 0.7941 r:0.5490
ne_en Dev loss: 0.4957 r:0.7304
ru_en Dev loss: 0.4070 r:0.7415
Current avg r:0.5943 Best avg r: 0.6283
05:16:30,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:18:00,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:19:30,568 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1640
en_de Dev loss: 0.8934 r:0.1890
en_zh Dev loss: 0.7567 r:0.4796
ro_en Dev loss: 0.3289 r:0.8214
et_en Dev loss: 0.4785 r:0.6744
si_en Dev loss: 0.7749 r:0.5605
ne_en Dev loss: 0.4541 r:0.7325
ru_en Dev loss: 0.4194 r:0.7465
Current avg r:0.6005 Best avg r: 0.6283
05:24:00,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:25:30,410 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:27:00,375 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1714
en_de Dev loss: 0.9069 r:0.1898
en_zh Dev loss: 0.7535 r:0.4833
ro_en Dev loss: 0.3402 r:0.8219
et_en Dev loss: 0.4575 r:0.6740
si_en Dev loss: 0.8599 r:0.5549
ne_en Dev loss: 0.4827 r:0.7283
ru_en Dev loss: 0.4238 r:0.7531
Current avg r:0.6007 Best avg r: 0.6283
05:31:30,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:33:00,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:34:29,999 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1654
en_de Dev loss: 0.9082 r:0.1975
en_zh Dev loss: 0.7552 r:0.4852
ro_en Dev loss: 0.3535 r:0.8172
et_en Dev loss: 0.4714 r:0.6767
si_en Dev loss: 0.8754 r:0.5530
ne_en Dev loss: 0.5174 r:0.7266
ru_en Dev loss: 0.4270 r:0.7558
Current avg r:0.6017 Best avg r: 0.6283
05:38:59,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:40:29,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:41:59,773 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1719
en_de Dev loss: 0.9363 r:0.1732
en_zh Dev loss: 0.7742 r:0.4763
ro_en Dev loss: 0.3589 r:0.8136
et_en Dev loss: 0.4971 r:0.6655
si_en Dev loss: 0.8389 r:0.5521
ne_en Dev loss: 0.5136 r:0.7167
ru_en Dev loss: 0.4416 r:0.7477
Current avg r:0.5922 Best avg r: 0.6283
05:46:29,553 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:47:59,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:49:29,578 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1733
en_de Dev loss: 0.9157 r:0.1856
en_zh Dev loss: 0.7743 r:0.4708
ro_en Dev loss: 0.3408 r:0.8193
et_en Dev loss: 0.4991 r:0.6714
si_en Dev loss: 0.8509 r:0.5496
ne_en Dev loss: 0.5349 r:0.7202
ru_en Dev loss: 0.4161 r:0.7505
Current avg r:0.5953 Best avg r: 0.6283
05:53:59,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:55:29,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:56:59,424 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1692
en_de Dev loss: 0.9210 r:0.1541
en_zh Dev loss: 0.7635 r:0.4610
ro_en Dev loss: 0.3401 r:0.8143
et_en Dev loss: 0.4667 r:0.6574
si_en Dev loss: 0.8224 r:0.5529
ne_en Dev loss: 0.5372 r:0.7140
ru_en Dev loss: 0.4237 r:0.7416
Current avg r:0.5850 Best avg r: 0.6283
06:01:29,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:02:59,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:04:29,214 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1650
en_de Dev loss: 0.9218 r:0.1578
en_zh Dev loss: 0.7673 r:0.4719
ro_en Dev loss: 0.3470 r:0.8172
et_en Dev loss: 0.4678 r:0.6604
si_en Dev loss: 0.8971 r:0.5492
ne_en Dev loss: 0.5566 r:0.7167
ru_en Dev loss: 0.4234 r:0.7452
Current avg r:0.5883 Best avg r: 0.6283
06:08:59,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:10:29,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:59,158 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1651
en_de Dev loss: 0.9371 r:0.1412
en_zh Dev loss: 0.8109 r:0.4541
ro_en Dev loss: 0.3517 r:0.8165
et_en Dev loss: 0.4564 r:0.6669
si_en Dev loss: 0.8440 r:0.5489
ne_en Dev loss: 0.5390 r:0.7191
ru_en Dev loss: 0.4343 r:0.7451
Current avg r:0.5845 Best avg r: 0.6283
06:16:28,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:58,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:19:28,905 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1667
en_de Dev loss: 0.9375 r:0.1503
en_zh Dev loss: 0.8332 r:0.4518
ro_en Dev loss: 0.3591 r:0.8153
et_en Dev loss: 0.4784 r:0.6599
si_en Dev loss: 0.8310 r:0.5559
ne_en Dev loss: 0.5144 r:0.7176
ru_en Dev loss: 0.4608 r:0.7349
Current avg r:0.5837 Best avg r: 0.6283
06:23:58,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:25:28,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:58,885 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1696
en_de Dev loss: 0.9258 r:0.1487
en_zh Dev loss: 0.8130 r:0.4468
ro_en Dev loss: 0.3499 r:0.8152
et_en Dev loss: 0.4530 r:0.6553
si_en Dev loss: 0.9270 r:0.5353
ne_en Dev loss: 0.5552 r:0.7181
ru_en Dev loss: 0.4563 r:0.7293
Current avg r:0.5784 Best avg r: 0.6283
06:31:28,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:32:58,495 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:34:28,474 root INFO Epoch 10 Global steps: 87500 Train loss: 0.1711
en_de Dev loss: 0.9552 r:0.1527
en_zh Dev loss: 0.7849 r:0.4713
ro_en Dev loss: 0.3550 r:0.8170
et_en Dev loss: 0.4641 r:0.6681
si_en Dev loss: 0.8459 r:0.5523
ne_en Dev loss: 0.5028 r:0.7240
ru_en Dev loss: 0.4003 r:0.7581
Current avg r:0.5919 Best avg r: 0.6283
06:38:59,997 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:40:30,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:42:00,93 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1610
en_de Dev loss: 0.9534 r:0.1508
en_zh Dev loss: 0.7481 r:0.4763
ro_en Dev loss: 0.3273 r:0.8188
et_en Dev loss: 0.4623 r:0.6735
si_en Dev loss: 0.7891 r:0.5526
ne_en Dev loss: 0.4817 r:0.7169
ru_en Dev loss: 0.4070 r:0.7524
Current avg r:0.5916 Best avg r: 0.6283
06:46:29,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:59,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:49:29,739 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1529
en_de Dev loss: 0.9365 r:0.1562
en_zh Dev loss: 0.7705 r:0.4683
ro_en Dev loss: 0.3429 r:0.8154
et_en Dev loss: 0.4495 r:0.6612
si_en Dev loss: 0.8306 r:0.5466
ne_en Dev loss: 0.5795 r:0.7186
ru_en Dev loss: 0.4385 r:0.7427
Current avg r:0.5870 Best avg r: 0.6283
06:53:59,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:55:29,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:59,430 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1537
en_de Dev loss: 0.9230 r:0.1577
en_zh Dev loss: 0.7753 r:0.4671
ro_en Dev loss: 0.3446 r:0.8135
et_en Dev loss: 0.4705 r:0.6636
si_en Dev loss: 0.8877 r:0.5430
ne_en Dev loss: 0.5769 r:0.7157
ru_en Dev loss: 0.4277 r:0.7488
Current avg r:0.5871 Best avg r: 0.6283
07:01:29,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:59,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:04:29,238 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1528
en_de Dev loss: 0.9280 r:0.1432
en_zh Dev loss: 0.7741 r:0.4629
ro_en Dev loss: 0.3242 r:0.8176
et_en Dev loss: 0.4484 r:0.6712
si_en Dev loss: 0.8315 r:0.5483
ne_en Dev loss: 0.5049 r:0.7215
ru_en Dev loss: 0.4226 r:0.7511
Current avg r:0.5880 Best avg r: 0.6283
07:08:58,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:10:28,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:11:58,960 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1510
en_de Dev loss: 0.9311 r:0.1600
en_zh Dev loss: 0.7911 r:0.4593
ro_en Dev loss: 0.3315 r:0.8157
et_en Dev loss: 0.4706 r:0.6689
si_en Dev loss: 0.8071 r:0.5521
ne_en Dev loss: 0.4820 r:0.7126
ru_en Dev loss: 0.4440 r:0.7479
Current avg r:0.5881 Best avg r: 0.6283
07:16:28,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:58,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:19:28,389 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1538
en_de Dev loss: 0.9126 r:0.1502
en_zh Dev loss: 0.7420 r:0.4621
ro_en Dev loss: 0.3136 r:0.8196
et_en Dev loss: 0.4435 r:0.6628
si_en Dev loss: 0.8356 r:0.5472
ne_en Dev loss: 0.5380 r:0.7195
ru_en Dev loss: 0.4131 r:0.7453
Current avg r:0.5867 Best avg r: 0.6283
07:23:57,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:27,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:57,955 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1487
en_de Dev loss: 0.9201 r:0.1722
en_zh Dev loss: 0.7842 r:0.4668
ro_en Dev loss: 0.3480 r:0.8204
et_en Dev loss: 0.4663 r:0.6618
si_en Dev loss: 0.9192 r:0.5462
ne_en Dev loss: 0.5714 r:0.7124
ru_en Dev loss: 0.4255 r:0.7542
Current avg r:0.5906 Best avg r: 0.6283
07:31:27,445 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:57,469 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:34:27,437 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1495
en_de Dev loss: 0.9183 r:0.1637
en_zh Dev loss: 0.8216 r:0.4659
ro_en Dev loss: 0.3495 r:0.8175
et_en Dev loss: 0.4959 r:0.6504
si_en Dev loss: 0.9503 r:0.5364
ne_en Dev loss: 0.5895 r:0.7059
ru_en Dev loss: 0.4506 r:0.7481
Current avg r:0.5840 Best avg r: 0.6283
07:38:57,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:27,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:41:56,989 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1526
en_de Dev loss: 0.9084 r:0.1735
en_zh Dev loss: 0.7860 r:0.4656
ro_en Dev loss: 0.3213 r:0.8189
et_en Dev loss: 0.4670 r:0.6649
si_en Dev loss: 0.8827 r:0.5429
ne_en Dev loss: 0.5307 r:0.7195
ru_en Dev loss: 0.4314 r:0.7479
Current avg r:0.5905 Best avg r: 0.6283
07:46:26,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:56,574 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:49:26,462 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1486
en_de Dev loss: 0.9394 r:0.1813
en_zh Dev loss: 0.8146 r:0.4713
ro_en Dev loss: 0.3721 r:0.8159
et_en Dev loss: 0.4776 r:0.6697
si_en Dev loss: 0.8649 r:0.5507
ne_en Dev loss: 0.5474 r:0.7167
ru_en Dev loss: 0.4443 r:0.7580
Current avg r:0.5948 Best avg r: 0.6283
07:53:56,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:55:26,140 root INFO 
id:ru_en cur r: 0.7673 best r: 0.7673
07:55:26,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:56:56,104 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1414
en_de Dev loss: 0.9153 r:0.1901
en_zh Dev loss: 0.7561 r:0.4732
ro_en Dev loss: 0.3225 r:0.8229
et_en Dev loss: 0.4884 r:0.6741
si_en Dev loss: 0.7635 r:0.5557
ne_en Dev loss: 0.4948 r:0.7145
ru_en Dev loss: 0.3848 r:0.7659
Current avg r:0.5995 Best avg r: 0.6283
08:01:27,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:57,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:04:27,476 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1374
en_de Dev loss: 0.9103 r:0.1679
en_zh Dev loss: 0.7808 r:0.4557
ro_en Dev loss: 0.3229 r:0.8221
et_en Dev loss: 0.4649 r:0.6546
si_en Dev loss: 0.8786 r:0.5418
ne_en Dev loss: 0.5284 r:0.7125
ru_en Dev loss: 0.4172 r:0.7430
Current avg r:0.5854 Best avg r: 0.6283
08:08:57,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:10:27,234 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:11:57,242 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1325
en_de Dev loss: 0.9471 r:0.1651
en_zh Dev loss: 0.8085 r:0.4603
ro_en Dev loss: 0.3672 r:0.8177
et_en Dev loss: 0.4821 r:0.6648
si_en Dev loss: 0.8677 r:0.5474
ne_en Dev loss: 0.5525 r:0.7167
ru_en Dev loss: 0.4624 r:0.7394
Current avg r:0.5873 Best avg r: 0.6283
08:16:27,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:17:57,108 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:19:27,95 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1363
en_de Dev loss: 0.9447 r:0.1714
en_zh Dev loss: 0.8061 r:0.4610
ro_en Dev loss: 0.3785 r:0.8139
et_en Dev loss: 0.4856 r:0.6577
si_en Dev loss: 1.0369 r:0.5285
ne_en Dev loss: 0.6956 r:0.7116
ru_en Dev loss: 0.4974 r:0.7343
Current avg r:0.5826 Best avg r: 0.6283
08:23:57,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:25:27,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:57,168 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1329
en_de Dev loss: 0.9283 r:0.1502
en_zh Dev loss: 0.8271 r:0.4479
ro_en Dev loss: 0.3644 r:0.8109
et_en Dev loss: 0.4760 r:0.6505
si_en Dev loss: 0.9308 r:0.5344
ne_en Dev loss: 0.5788 r:0.7149
ru_en Dev loss: 0.4732 r:0.7294
Current avg r:0.5769 Best avg r: 0.6283
08:31:27,97 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:32:57,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:34:27,149 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1392
en_de Dev loss: 0.9706 r:0.1469
en_zh Dev loss: 0.7920 r:0.4603
ro_en Dev loss: 0.3489 r:0.8168
et_en Dev loss: 0.4554 r:0.6702
si_en Dev loss: 0.8421 r:0.5481
ne_en Dev loss: 0.5230 r:0.7158
ru_en Dev loss: 0.4387 r:0.7512
Current avg r:0.5870 Best avg r: 0.6283
08:38:57,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:40:27,155 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:57,172 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1519
en_de Dev loss: 0.9275 r:0.1580
en_zh Dev loss: 0.7796 r:0.4621
ro_en Dev loss: 0.3477 r:0.8151
et_en Dev loss: 0.4560 r:0.6704
si_en Dev loss: 0.8517 r:0.5499
ne_en Dev loss: 0.5254 r:0.7126
ru_en Dev loss: 0.4131 r:0.7514
Current avg r:0.5885 Best avg r: 0.6283
08:46:27,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:57,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:27,118 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1391
en_de Dev loss: 0.9628 r:0.1518
en_zh Dev loss: 0.8498 r:0.4454
ro_en Dev loss: 0.3786 r:0.8109
et_en Dev loss: 0.4726 r:0.6669
si_en Dev loss: 0.8994 r:0.5468
ne_en Dev loss: 0.5919 r:0.7190
ru_en Dev loss: 0.4503 r:0.7500
Current avg r:0.5844 Best avg r: 0.6283
08:53:57,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:55:27,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:57,177 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1359
en_de Dev loss: 0.9788 r:0.1514
en_zh Dev loss: 0.8686 r:0.4508
ro_en Dev loss: 0.3918 r:0.8124
et_en Dev loss: 0.4670 r:0.6698
si_en Dev loss: 0.8842 r:0.5519
ne_en Dev loss: 0.5794 r:0.7069
ru_en Dev loss: 0.4546 r:0.7483
Current avg r:0.5845 Best avg r: 0.6283
09:01:27,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:57,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:04:27,134 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1338
en_de Dev loss: 0.9111 r:0.1871
en_zh Dev loss: 0.8159 r:0.4534
ro_en Dev loss: 0.3665 r:0.8093
et_en Dev loss: 0.4513 r:0.6692
si_en Dev loss: 0.9164 r:0.5454
ne_en Dev loss: 0.6091 r:0.7066
ru_en Dev loss: 0.4502 r:0.7406
Current avg r:0.5874 Best avg r: 0.6283
09:08:57,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:10:27,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:57,102 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1393
en_de Dev loss: 0.9105 r:0.1957
en_zh Dev loss: 0.8099 r:0.4594
ro_en Dev loss: 0.3461 r:0.8173
et_en Dev loss: 0.4695 r:0.6761
si_en Dev loss: 0.8241 r:0.5496
ne_en Dev loss: 0.5534 r:0.7099
ru_en Dev loss: 0.4177 r:0.7545
Current avg r:0.5946 Best avg r: 0.6283
09:16:26,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:17:56,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:26,947 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1320
en_de Dev loss: 0.9283 r:0.1902
en_zh Dev loss: 0.7756 r:0.4770
ro_en Dev loss: 0.3207 r:0.8222
et_en Dev loss: 0.4430 r:0.6869
si_en Dev loss: 0.7706 r:0.5605
ne_en Dev loss: 0.5120 r:0.7108
ru_en Dev loss: 0.3964 r:0.7622
Current avg r:0.6014 Best avg r: 0.6283
09:23:58,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:28,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:58,524 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1303
en_de Dev loss: 0.9177 r:0.1819
en_zh Dev loss: 0.7842 r:0.4772
ro_en Dev loss: 0.3362 r:0.8194
et_en Dev loss: 0.4509 r:0.6763
si_en Dev loss: 0.8506 r:0.5529
ne_en Dev loss: 0.5761 r:0.7093
ru_en Dev loss: 0.4258 r:0.7533
Current avg r:0.5958 Best avg r: 0.6283
09:31:28,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:32:58,500 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:34:28,526 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1274
en_de Dev loss: 0.9724 r:0.1575
en_zh Dev loss: 0.7927 r:0.4718
ro_en Dev loss: 0.3437 r:0.8168
et_en Dev loss: 0.4762 r:0.6767
si_en Dev loss: 0.8222 r:0.5524
ne_en Dev loss: 0.5325 r:0.7099
ru_en Dev loss: 0.4247 r:0.7475
Current avg r:0.5904 Best avg r: 0.6283
09:38:58,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:40:28,422 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:41:58,445 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1296
en_de Dev loss: 0.9507 r:0.1664
en_zh Dev loss: 0.7537 r:0.4714
ro_en Dev loss: 0.3275 r:0.8172
et_en Dev loss: 0.4396 r:0.6845
si_en Dev loss: 0.8023 r:0.5593
ne_en Dev loss: 0.5304 r:0.7149
ru_en Dev loss: 0.4040 r:0.7567
Current avg r:0.5958 Best avg r: 0.6283
09:46:28,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:58,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:28,338 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1258
en_de Dev loss: 0.9835 r:0.1330
en_zh Dev loss: 0.8220 r:0.4508
ro_en Dev loss: 0.3802 r:0.8153
et_en Dev loss: 0.4849 r:0.6659
si_en Dev loss: 0.9495 r:0.5462
ne_en Dev loss: 0.6584 r:0.7043
ru_en Dev loss: 0.4568 r:0.7450
Current avg r:0.5801 Best avg r: 0.6283
09:53:58,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:28,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:58,124 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1265
en_de Dev loss: 0.9436 r:0.1546
en_zh Dev loss: 0.7849 r:0.4612
ro_en Dev loss: 0.3569 r:0.8147
et_en Dev loss: 0.4944 r:0.6744
si_en Dev loss: 0.8606 r:0.5534
ne_en Dev loss: 0.5728 r:0.7177
ru_en Dev loss: 0.4173 r:0.7496
Current avg r:0.5894 Best avg r: 0.6283
10:01:27,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:57,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:04:27,898 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1281
en_de Dev loss: 0.9703 r:0.1301
en_zh Dev loss: 0.7943 r:0.4636
ro_en Dev loss: 0.3524 r:0.8157
et_en Dev loss: 0.4500 r:0.6695
si_en Dev loss: 0.8775 r:0.5516
ne_en Dev loss: 0.6301 r:0.7043
ru_en Dev loss: 0.4646 r:0.7436
Current avg r:0.5826 Best avg r: 0.6283
10:08:57,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:27,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:57,924 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1214
en_de Dev loss: 0.9857 r:0.1432
en_zh Dev loss: 0.8525 r:0.4526
ro_en Dev loss: 0.4074 r:0.8117
et_en Dev loss: 0.4870 r:0.6661
si_en Dev loss: 0.9123 r:0.5482
ne_en Dev loss: 0.6388 r:0.7085
ru_en Dev loss: 0.4915 r:0.7402
Current avg r:0.5815 Best avg r: 0.6283
10:16:27,791 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:17:57,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:27,887 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1236
en_de Dev loss: 0.9496 r:0.1434
en_zh Dev loss: 0.8116 r:0.4544
ro_en Dev loss: 0.3529 r:0.8136
et_en Dev loss: 0.4706 r:0.6664
si_en Dev loss: 0.9327 r:0.5407
ne_en Dev loss: 0.5923 r:0.7198
ru_en Dev loss: 0.4425 r:0.7453
Current avg r:0.5834 Best avg r: 0.6283
10:23:57,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:28,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:58,126 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1319
en_de Dev loss: 0.9506 r:0.1481
en_zh Dev loss: 0.7627 r:0.4720
ro_en Dev loss: 0.3515 r:0.8136
et_en Dev loss: 0.4697 r:0.6795
si_en Dev loss: 0.8277 r:0.5515
ne_en Dev loss: 0.5493 r:0.7120
ru_en Dev loss: 0.4090 r:0.7583
Current avg r:0.5907 Best avg r: 0.6283
10:31:28,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
