14:36:19,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:36:32,416 root INFO 
id:en_de cur r: 0.0925 best r: 0.0925
14:36:45,416 root INFO 
id:en_zh cur r: 0.2419 best r: 0.2419
14:36:58,455 root INFO 
id:ro_en cur r: 0.6065 best r: 0.6065
14:37:11,520 root INFO 
id:et_en cur r: 0.3883 best r: 0.3883
14:37:24,583 root INFO 
id:si_en cur r: 0.4530 best r: 0.4530
14:37:50,676 root INFO 
id:ne_en cur r: 0.5913 best r: 0.5913
14:38:03,677 root INFO 
id:ru_en cur r: 0.4864 best r: 0.4864
14:38:03,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:34,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
14:39:34,889 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:39:34,894 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:39:34,899 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
14:39:34,904 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
14:39:34,909 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:39:34,914 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:39:47,975 root INFO Epoch 0 Global steps: 700 Train loss: 0.8620
en_de Dev loss: 0.8905 r:0.0699
en_zh Dev loss: 0.7938 r:0.2368
ro_en Dev loss: 0.6828 r:0.5945
et_en Dev loss: 0.5926 r:0.4599
si_en Dev loss: 0.7313 r:0.4483
ne_en Dev loss: 0.5627 r:0.6137
ru_en Dev loss: 0.6899 r:0.4398
Current avg r:0.4090 Best avg r: 0.4090
14:44:23,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:36,665 root INFO 
id:en_de cur r: 0.1122 best r: 0.1122
14:44:49,660 root INFO 
id:en_zh cur r: 0.2499 best r: 0.2499
14:45:02,721 root INFO 
id:ro_en cur r: 0.6766 best r: 0.6766
14:45:15,787 root INFO 
id:et_en cur r: 0.5592 best r: 0.5592
14:45:54,960 root INFO 
id:ne_en cur r: 0.6271 best r: 0.6271
14:46:07,971 root INFO 
id:ru_en cur r: 0.6187 best r: 0.6187
14:46:07,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:39,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
14:47:39,141 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:47:39,148 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:47:39,154 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
14:47:39,160 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
14:47:39,165 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:47:39,171 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:47:52,242 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7924
en_de Dev loss: 0.8923 r:0.1096
en_zh Dev loss: 0.7750 r:0.2744
ro_en Dev loss: 0.6571 r:0.6920
et_en Dev loss: 0.5051 r:0.5865
si_en Dev loss: 0.7851 r:0.4713
ne_en Dev loss: 0.5010 r:0.6712
ru_en Dev loss: 0.6306 r:0.6199
Current avg r:0.4893 Best avg r: 0.4893
14:52:27,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:53,717 root INFO 
id:en_zh cur r: 0.3000 best r: 0.3000
14:53:19,821 root INFO 
id:et_en cur r: 0.5756 best r: 0.5756
14:53:58,943 root INFO 
id:ru_en cur r: 0.6738 best r: 0.6738
14:53:58,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:30,131 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
14:55:30,139 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:55:30,144 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:55:30,150 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
14:55:30,155 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
14:55:30,161 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:55:30,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:55:43,231 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7626
en_de Dev loss: 0.9014 r:0.1335
en_zh Dev loss: 0.7590 r:0.3311
ro_en Dev loss: 0.6478 r:0.6931
et_en Dev loss: 0.4811 r:0.6275
si_en Dev loss: 0.7724 r:0.4910
ne_en Dev loss: 0.5212 r:0.6585
ru_en Dev loss: 0.5985 r:0.6797
Current avg r:0.5163 Best avg r: 0.5163
15:00:18,980 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:32,13 root INFO 
id:en_de cur r: 0.1142 best r: 0.1142
15:00:45,30 root INFO 
id:en_zh cur r: 0.3112 best r: 0.3112
15:00:58,88 root INFO 
id:ro_en cur r: 0.6776 best r: 0.6776
15:01:11,158 root INFO 
id:et_en cur r: 0.6145 best r: 0.6145
15:01:24,216 root INFO 
id:si_en cur r: 0.4667 best r: 0.4667
15:01:50,363 root INFO 
id:ne_en cur r: 0.6430 best r: 0.6430
15:02:03,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:34,595 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:03:34,603 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:03:34,609 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:03:34,614 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:03:34,619 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:03:34,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:03:34,629 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:03:47,694 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6982
en_de Dev loss: 0.9041 r:0.1532
en_zh Dev loss: 0.7460 r:0.3312
ro_en Dev loss: 0.5708 r:0.6864
et_en Dev loss: 0.4318 r:0.6564
si_en Dev loss: 0.6842 r:0.5001
ne_en Dev loss: 0.4523 r:0.6683
ru_en Dev loss: 0.5523 r:0.6831
Current avg r:0.5255 Best avg r: 0.5255
15:08:23,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:36,628 root INFO 
id:en_de cur r: 0.1397 best r: 0.1397
15:09:02,672 root INFO 
id:ro_en cur r: 0.7188 best r: 0.7188
15:09:15,726 root INFO 
id:et_en cur r: 0.6618 best r: 0.6618
15:09:28,786 root INFO 
id:si_en cur r: 0.5066 best r: 0.5066
15:09:54,912 root INFO 
id:ne_en cur r: 0.6859 best r: 0.6859
15:10:07,901 root INFO 
id:ru_en cur r: 0.7127 best r: 0.7127
15:10:07,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:11:39,79 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:11:39,87 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:11:39,93 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:11:39,98 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:11:39,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:11:39,111 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:11:39,121 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:11:52,190 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6675
en_de Dev loss: 0.9161 r:0.1764
en_zh Dev loss: 0.7694 r:0.3430
ro_en Dev loss: 0.5245 r:0.7220
et_en Dev loss: 0.3942 r:0.6870
si_en Dev loss: 0.6496 r:0.5298
ne_en Dev loss: 0.4141 r:0.6983
ru_en Dev loss: 0.4852 r:0.7179
Current avg r:0.5535 Best avg r: 0.5535
15:16:27,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:40,792 root INFO 
id:en_de cur r: 0.1915 best r: 0.1915
15:17:06,844 root INFO 
id:ro_en cur r: 0.7227 best r: 0.7227
15:17:32,975 root INFO 
id:si_en cur r: 0.5101 best r: 0.5101
15:17:58,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:19:30,216 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6356
en_de Dev loss: 0.9281 r:0.1701
en_zh Dev loss: 0.7851 r:0.3470
ro_en Dev loss: 0.5540 r:0.7327
et_en Dev loss: 0.4383 r:0.6743
si_en Dev loss: 0.7585 r:0.5310
ne_en Dev loss: 0.4659 r:0.6919
ru_en Dev loss: 0.5388 r:0.7127
Current avg r:0.5514 Best avg r: 0.5535
15:24:03,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:29,435 root INFO 
id:en_zh cur r: 0.3475 best r: 0.3475
15:24:42,362 root INFO 
id:ro_en cur r: 0.7526 best r: 0.7526
15:24:55,299 root INFO 
id:et_en cur r: 0.6998 best r: 0.6998
15:25:08,244 root INFO 
id:si_en cur r: 0.5672 best r: 0.5672
15:25:34,111 root INFO 
id:ne_en cur r: 0.7253 best r: 0.7253
15:25:46,979 root INFO 
id:ru_en cur r: 0.7153 best r: 0.7153
15:25:46,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:17,232 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:27:17,239 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:27:17,244 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:27:17,249 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:27:17,255 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:27:17,260 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:27:17,265 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:27:30,185 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6134
en_de Dev loss: 0.9284 r:0.1786
en_zh Dev loss: 0.7407 r:0.3746
ro_en Dev loss: 0.4304 r:0.7494
et_en Dev loss: 0.3484 r:0.7166
si_en Dev loss: 0.6036 r:0.5892
ne_en Dev loss: 0.3854 r:0.7282
ru_en Dev loss: 0.4685 r:0.7342
Current avg r:0.5815 Best avg r: 0.5815
15:32:01,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:27,581 root INFO 
id:en_zh cur r: 0.3894 best r: 0.3894
15:33:32,135 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:02,429 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5927
en_de Dev loss: 0.9028 r:0.1756
en_zh Dev loss: 0.6917 r:0.4034
ro_en Dev loss: 0.4136 r:0.7490
et_en Dev loss: 0.3601 r:0.7024
si_en Dev loss: 0.6372 r:0.5706
ne_en Dev loss: 0.4047 r:0.7156
ru_en Dev loss: 0.4744 r:0.7269
Current avg r:0.5776 Best avg r: 0.5815
15:39:34,57 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:12,758 root INFO 
id:ro_en cur r: 0.7644 best r: 0.7644
15:40:38,609 root INFO 
id:si_en cur r: 0.5684 best r: 0.5684
15:41:04,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:34,637 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:42:34,644 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:42:34,649 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:42:34,654 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:42:34,658 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:42:34,663 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:42:34,668 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:42:47,584 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5991
en_de Dev loss: 0.9077 r:0.1922
en_zh Dev loss: 0.7181 r:0.3974
ro_en Dev loss: 0.4384 r:0.7623
et_en Dev loss: 0.3876 r:0.7069
si_en Dev loss: 0.7035 r:0.5779
ne_en Dev loss: 0.4754 r:0.7194
ru_en Dev loss: 0.5106 r:0.7243
Current avg r:0.5829 Best avg r: 0.5829
15:47:19,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:23,616 root INFO 
id:si_en cur r: 0.5689 best r: 0.5689
15:48:49,462 root INFO 
id:ne_en cur r: 0.7261 best r: 0.7261
15:49:02,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:32,615 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5846
en_de Dev loss: 0.9306 r:0.1909
en_zh Dev loss: 0.7468 r:0.3936
ro_en Dev loss: 0.4159 r:0.7645
et_en Dev loss: 0.3602 r:0.7138
si_en Dev loss: 0.6877 r:0.5814
ne_en Dev loss: 0.5412 r:0.7178
ru_en Dev loss: 0.5280 r:0.6975
Current avg r:0.5799 Best avg r: 0.5829
15:55:04,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:42,842 root INFO 
id:ro_en cur r: 0.7723 best r: 0.7723
15:56:08,691 root INFO 
id:si_en cur r: 0.5737 best r: 0.5737
15:56:34,539 root INFO 
id:ne_en cur r: 0.7302 best r: 0.7302
15:56:47,409 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:17,668 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
15:58:17,675 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:58:17,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:58:17,685 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
15:58:17,690 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
15:58:17,695 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:58:17,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:58:30,629 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5636
en_de Dev loss: 0.9017 r:0.1939
en_zh Dev loss: 0.7173 r:0.4084
ro_en Dev loss: 0.3954 r:0.7724
et_en Dev loss: 0.3534 r:0.7134
si_en Dev loss: 0.6182 r:0.5830
ne_en Dev loss: 0.4000 r:0.7329
ru_en Dev loss: 0.4674 r:0.7143
Current avg r:0.5883 Best avg r: 0.5883
16:03:04,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:17,591 root INFO 
id:en_de cur r: 0.1964 best r: 0.1964
16:03:30,483 root INFO 
id:en_zh cur r: 0.3908 best r: 0.3908
16:03:43,409 root INFO 
id:ro_en cur r: 0.7828 best r: 0.7828
16:03:56,340 root INFO 
id:et_en cur r: 0.7084 best r: 0.7084
16:04:09,275 root INFO 
id:si_en cur r: 0.5835 best r: 0.5835
16:04:35,149 root INFO 
id:ne_en cur r: 0.7325 best r: 0.7325
16:04:48,24 root INFO 
id:ru_en cur r: 0.7201 best r: 0.7201
16:04:48,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:18,341 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:06:18,351 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:06:18,358 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:06:18,363 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:06:18,369 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:06:18,377 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:06:18,384 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:06:31,318 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5407
en_de Dev loss: 0.9566 r:0.2034
en_zh Dev loss: 0.7872 r:0.4090
ro_en Dev loss: 0.4616 r:0.7806
et_en Dev loss: 0.4000 r:0.7158
si_en Dev loss: 0.7806 r:0.5842
ne_en Dev loss: 0.5015 r:0.7334
ru_en Dev loss: 0.5061 r:0.7274
Current avg r:0.5934 Best avg r: 0.5934
16:11:03,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:16,528 root INFO 
id:en_de cur r: 0.1986 best r: 0.1986
16:11:29,413 root INFO 
id:en_zh cur r: 0.4036 best r: 0.4036
16:11:42,341 root INFO 
id:ro_en cur r: 0.7952 best r: 0.7952
16:11:55,269 root INFO 
id:et_en cur r: 0.7122 best r: 0.7122
16:12:08,207 root INFO 
id:si_en cur r: 0.5975 best r: 0.5975
16:12:34,67 root INFO 
id:ne_en cur r: 0.7459 best r: 0.7459
16:12:46,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:17,280 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:14:17,287 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:14:17,291 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:14:17,296 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:14:17,301 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:14:17,306 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:14:17,311 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:14:30,234 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5335
en_de Dev loss: 0.8932 r:0.2086
en_zh Dev loss: 0.7007 r:0.4158
ro_en Dev loss: 0.3514 r:0.7855
et_en Dev loss: 0.3434 r:0.7217
si_en Dev loss: 0.6052 r:0.5989
ne_en Dev loss: 0.3702 r:0.7463
ru_en Dev loss: 0.4340 r:0.7213
Current avg r:0.5997 Best avg r: 0.5997
16:19:02,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:19:15,399 root INFO 
id:en_de cur r: 0.2028 best r: 0.2028
16:20:32,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:03,142 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5235
en_de Dev loss: 0.8657 r:0.2107
en_zh Dev loss: 0.7012 r:0.4043
ro_en Dev loss: 0.3465 r:0.7816
et_en Dev loss: 0.3544 r:0.7105
si_en Dev loss: 0.6238 r:0.5814
ne_en Dev loss: 0.4286 r:0.7306
ru_en Dev loss: 0.4410 r:0.7065
Current avg r:0.5894 Best avg r: 0.5997
16:26:35,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:48,274 root INFO 
id:en_de cur r: 0.2179 best r: 0.2179
16:28:05,714 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:36,49 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5516
en_de Dev loss: 0.8993 r:0.2230
en_zh Dev loss: 0.7339 r:0.4114
ro_en Dev loss: 0.4097 r:0.7897
et_en Dev loss: 0.3974 r:0.7090
si_en Dev loss: 0.8024 r:0.5824
ne_en Dev loss: 0.6138 r:0.7355
ru_en Dev loss: 0.4990 r:0.7145
Current avg r:0.5951 Best avg r: 0.5997
16:34:08,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:34,182 root INFO 
id:en_zh cur r: 0.4273 best r: 0.4273
16:34:47,100 root INFO 
id:ro_en cur r: 0.8043 best r: 0.8043
16:35:00,45 root INFO 
id:et_en cur r: 0.7171 best r: 0.7171
16:35:12,976 root INFO 
id:si_en cur r: 0.6065 best r: 0.6065
16:35:38,847 root INFO 
id:ne_en cur r: 0.7585 best r: 0.7585
16:35:51,730 root INFO 
id:ru_en cur r: 0.7436 best r: 0.7436
16:35:51,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:22,31 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
16:37:22,44 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:37:22,52 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:37:22,59 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
16:37:22,66 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
16:37:22,71 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:37:22,78 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:37:35,4 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5236
en_de Dev loss: 0.8587 r:0.2159
en_zh Dev loss: 0.6718 r:0.4328
ro_en Dev loss: 0.3229 r:0.7940
et_en Dev loss: 0.3590 r:0.7263
si_en Dev loss: 0.5388 r:0.6075
ne_en Dev loss: 0.3381 r:0.7571
ru_en Dev loss: 0.3627 r:0.7515
Current avg r:0.6122 Best avg r: 0.6122
16:42:07,188 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:20,108 root INFO 
id:en_de cur r: 0.2269 best r: 0.2269
16:42:45,911 root INFO 
id:ro_en cur r: 0.8062 best r: 0.8062
16:43:37,568 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:07,860 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5151
en_de Dev loss: 0.9242 r:0.2191
en_zh Dev loss: 0.8289 r:0.4009
ro_en Dev loss: 0.4253 r:0.7967
et_en Dev loss: 0.3764 r:0.7170
si_en Dev loss: 0.7529 r:0.5930
ne_en Dev loss: 0.5173 r:0.7491
ru_en Dev loss: 0.5504 r:0.7154
Current avg r:0.5987 Best avg r: 0.6122
16:49:40,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:50:05,909 root INFO 
id:en_zh cur r: 0.4388 best r: 0.4388
16:51:10,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:40,825 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5575
en_de Dev loss: 0.8905 r:0.2164
en_zh Dev loss: 0.7215 r:0.4378
ro_en Dev loss: 0.4105 r:0.7967
et_en Dev loss: 0.3906 r:0.7082
si_en Dev loss: 0.8097 r:0.5881
ne_en Dev loss: 0.4978 r:0.7564
ru_en Dev loss: 0.4425 r:0.7429
Current avg r:0.6067 Best avg r: 0.6122
16:57:12,866 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:43,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:13,584 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5081
en_de Dev loss: 1.0018 r:0.2326
en_zh Dev loss: 0.9305 r:0.3987
ro_en Dev loss: 0.5148 r:0.7911
et_en Dev loss: 0.4726 r:0.6996
si_en Dev loss: 0.9281 r:0.5777
ne_en Dev loss: 0.6566 r:0.7431
ru_en Dev loss: 0.6166 r:0.6988
Current avg r:0.5917 Best avg r: 0.6122
17:04:45,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:24,573 root INFO 
id:ro_en cur r: 0.8155 best r: 0.8155
17:05:37,510 root INFO 
id:et_en cur r: 0.7192 best r: 0.7192
17:06:16,252 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:07:46,588 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:07:46,596 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:07:46,600 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:07:46,606 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:07:46,611 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:07:46,616 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:07:46,621 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:07:59,547 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5245
en_de Dev loss: 0.8741 r:0.2110
en_zh Dev loss: 0.6992 r:0.4320
ro_en Dev loss: 0.3452 r:0.8113
et_en Dev loss: 0.3429 r:0.7268
si_en Dev loss: 0.6477 r:0.6092
ne_en Dev loss: 0.4128 r:0.7569
ru_en Dev loss: 0.4341 r:0.7455
Current avg r:0.6132 Best avg r: 0.6132
17:12:31,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:23,330 root INFO 
id:et_en cur r: 0.7203 best r: 0.7203
17:13:36,283 root INFO 
id:si_en cur r: 0.6080 best r: 0.6080
17:14:02,199 root INFO 
id:ne_en cur r: 0.7613 best r: 0.7613
17:14:15,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:45,505 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5304
en_de Dev loss: 0.8833 r:0.2202
en_zh Dev loss: 0.7500 r:0.4282
ro_en Dev loss: 0.4125 r:0.8119
et_en Dev loss: 0.3795 r:0.7258
si_en Dev loss: 0.8068 r:0.6042
ne_en Dev loss: 0.5896 r:0.7584
ru_en Dev loss: 0.5076 r:0.7363
Current avg r:0.6121 Best avg r: 0.6132
17:20:18,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:44,665 root INFO 
id:en_zh cur r: 0.4413 best r: 0.4413
17:21:10,512 root INFO 
id:et_en cur r: 0.7265 best r: 0.7265
17:21:49,364 root INFO 
id:ne_en cur r: 0.7660 best r: 0.7660
17:22:02,232 root INFO 
id:ru_en cur r: 0.7653 best r: 0.7653
17:22:02,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:32,554 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:23:32,564 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:23:32,571 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:23:32,579 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:23:32,585 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:23:32,590 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:23:32,596 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:23:45,528 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5115
en_de Dev loss: 0.8490 r:0.2206
en_zh Dev loss: 0.6785 r:0.4426
ro_en Dev loss: 0.3117 r:0.8136
et_en Dev loss: 0.3291 r:0.7356
si_en Dev loss: 0.6335 r:0.6131
ne_en Dev loss: 0.3843 r:0.7679
ru_en Dev loss: 0.3599 r:0.7682
Current avg r:0.6231 Best avg r: 0.6231
17:28:18,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:44,686 root INFO 
id:en_zh cur r: 0.4566 best r: 0.4566
17:28:57,609 root INFO 
id:ro_en cur r: 0.8190 best r: 0.8190
17:29:23,480 root INFO 
id:si_en cur r: 0.6080 best r: 0.6080
17:29:49,347 root INFO 
id:ne_en cur r: 0.7711 best r: 0.7711
17:30:02,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:32,484 root INFO Epoch 2 Global steps: 16100 Train loss: 0.4922
en_de Dev loss: 0.8601 r:0.2154
en_zh Dev loss: 0.6707 r:0.4601
ro_en Dev loss: 0.3343 r:0.8171
et_en Dev loss: 0.3410 r:0.7333
si_en Dev loss: 0.6453 r:0.6156
ne_en Dev loss: 0.4195 r:0.7696
ru_en Dev loss: 0.4281 r:0.7422
Current avg r:0.6219 Best avg r: 0.6231
17:36:05,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:35,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:06,299 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4655
en_de Dev loss: 0.9059 r:0.2087
en_zh Dev loss: 0.8070 r:0.4233
ro_en Dev loss: 0.3872 r:0.8076
et_en Dev loss: 0.3774 r:0.7181
si_en Dev loss: 0.7947 r:0.6004
ne_en Dev loss: 0.4158 r:0.7633
ru_en Dev loss: 0.5297 r:0.7131
Current avg r:0.6049 Best avg r: 0.6231
17:43:38,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:17,354 root INFO 
id:ro_en cur r: 0.8241 best r: 0.8241
17:44:43,220 root INFO 
id:si_en cur r: 0.6138 best r: 0.6138
17:45:09,92 root INFO 
id:ne_en cur r: 0.7724 best r: 0.7724
17:45:21,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:52,339 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4871
en_de Dev loss: 0.8722 r:0.2125
en_zh Dev loss: 0.7066 r:0.4472
ro_en Dev loss: 0.3324 r:0.8182
et_en Dev loss: 0.3462 r:0.7322
si_en Dev loss: 0.6181 r:0.6187
ne_en Dev loss: 0.3840 r:0.7712
ru_en Dev loss: 0.3975 r:0.7537
Current avg r:0.6220 Best avg r: 0.6231
17:51:24,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:50,450 root INFO 
id:en_zh cur r: 0.4880 best r: 0.4880
17:52:29,255 root INFO 
id:si_en cur r: 0.6191 best r: 0.6191
17:52:55,145 root INFO 
id:ne_en cur r: 0.7742 best r: 0.7742
17:53:08,22 root INFO 
id:ru_en cur r: 0.7794 best r: 0.7794
17:53:08,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:38,345 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_de.lang_agnost_mlp.dev.best.scores
17:54:38,352 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:54:38,357 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:54:38,363 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/et_en.lang_agnost_mlp.dev.best.scores
17:54:38,368 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/si_en.lang_agnost_mlp.dev.best.scores
17:54:38,374 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:54:38,379 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:54:51,323 root INFO Epoch 2 Global steps: 18200 Train loss: 0.4810
en_de Dev loss: 0.8746 r:0.1887
en_zh Dev loss: 0.6380 r:0.4878
ro_en Dev loss: 0.3042 r:0.8181
et_en Dev loss: 0.3437 r:0.7322
si_en Dev loss: 0.5702 r:0.6252
ne_en Dev loss: 0.3705 r:0.7709
ru_en Dev loss: 0.3303 r:0.7783
Current avg r:0.6287 Best avg r: 0.6287
17:59:23,698 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:28,299 root INFO 
id:si_en cur r: 0.6234 best r: 0.6234
18:00:54,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:24,441 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4492
en_de Dev loss: 0.8850 r:0.2070
en_zh Dev loss: 0.7195 r:0.4596
ro_en Dev loss: 0.3486 r:0.8142
et_en Dev loss: 0.3568 r:0.7275
si_en Dev loss: 0.6667 r:0.6220
ne_en Dev loss: 0.3669 r:0.7670
ru_en Dev loss: 0.4138 r:0.7511
Current avg r:0.6212 Best avg r: 0.6287
18:06:56,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:09,611 root INFO 
id:en_de cur r: 0.2280 best r: 0.2280
18:08:27,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:57,405 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4794
en_de Dev loss: 0.8809 r:0.2143
en_zh Dev loss: 0.7750 r:0.4373
ro_en Dev loss: 0.3589 r:0.8111
et_en Dev loss: 0.3658 r:0.7180
si_en Dev loss: 0.7680 r:0.6116
ne_en Dev loss: 0.4362 r:0.7579
ru_en Dev loss: 0.4693 r:0.7301
Current avg r:0.6115 Best avg r: 0.6287
18:14:29,740 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:00,134 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:30,472 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4773
en_de Dev loss: 0.8626 r:0.2048
en_zh Dev loss: 0.6766 r:0.4674
ro_en Dev loss: 0.3271 r:0.8169
et_en Dev loss: 0.3510 r:0.7261
si_en Dev loss: 0.5908 r:0.6212
ne_en Dev loss: 0.3964 r:0.7631
ru_en Dev loss: 0.3751 r:0.7643
Current avg r:0.6234 Best avg r: 0.6287
18:22:02,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:15,655 root INFO 
id:en_de cur r: 0.2403 best r: 0.2403
18:23:33,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:03,439 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4556
en_de Dev loss: 0.8497 r:0.2174
en_zh Dev loss: 0.6938 r:0.4519
ro_en Dev loss: 0.3252 r:0.8159
et_en Dev loss: 0.3763 r:0.7226
si_en Dev loss: 0.6063 r:0.6147
ne_en Dev loss: 0.3703 r:0.7676
ru_en Dev loss: 0.3953 r:0.7506
Current avg r:0.6201 Best avg r: 0.6287
18:29:35,612 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:05,995 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:36,316 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4188
en_de Dev loss: 0.8531 r:0.2258
en_zh Dev loss: 0.6707 r:0.4622
ro_en Dev loss: 0.3125 r:0.8167
et_en Dev loss: 0.3653 r:0.7231
si_en Dev loss: 0.6044 r:0.6118
ne_en Dev loss: 0.3459 r:0.7601
ru_en Dev loss: 0.4200 r:0.7438
Current avg r:0.6205 Best avg r: 0.6287
18:37:08,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:37:47,106 root INFO 
id:ro_en cur r: 0.8245 best r: 0.8245
18:38:12,973 root INFO 
id:si_en cur r: 0.6277 best r: 0.6277
18:38:38,856 root INFO 
id:ne_en cur r: 0.7745 best r: 0.7745
18:38:51,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:22,190 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4717
en_de Dev loss: 0.8525 r:0.2214
en_zh Dev loss: 0.6864 r:0.4557
ro_en Dev loss: 0.3056 r:0.8207
et_en Dev loss: 0.3393 r:0.7252
si_en Dev loss: 0.6328 r:0.6224
ne_en Dev loss: 0.3480 r:0.7711
ru_en Dev loss: 0.4286 r:0.7434
Current avg r:0.6228 Best avg r: 0.6287
18:44:55,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:26,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:56,558 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4304
en_de Dev loss: 0.8507 r:0.2276
en_zh Dev loss: 0.7123 r:0.4467
ro_en Dev loss: 0.3315 r:0.8109
et_en Dev loss: 0.3826 r:0.7161
si_en Dev loss: 0.6978 r:0.5971
ne_en Dev loss: 0.4404 r:0.7537
ru_en Dev loss: 0.4172 r:0.7377
Current avg r:0.6128 Best avg r: 0.6287
18:52:28,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:41,685 root INFO 
id:en_de cur r: 0.2645 best r: 0.2645
18:53:59,171 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:29,487 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4593
en_de Dev loss: 0.8466 r:0.2311
en_zh Dev loss: 0.6648 r:0.4757
ro_en Dev loss: 0.3108 r:0.8163
et_en Dev loss: 0.3766 r:0.7187
si_en Dev loss: 0.6119 r:0.6107
ne_en Dev loss: 0.3805 r:0.7605
ru_en Dev loss: 0.4471 r:0.7236
Current avg r:0.6195 Best avg r: 0.6287
19:00:02,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:33,334 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:03,682 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4730
en_de Dev loss: 0.8560 r:0.2222
en_zh Dev loss: 0.6799 r:0.4664
ro_en Dev loss: 0.3197 r:0.8175
et_en Dev loss: 0.3626 r:0.7148
si_en Dev loss: 0.7385 r:0.5996
ne_en Dev loss: 0.5135 r:0.7611
ru_en Dev loss: 0.4527 r:0.7250
Current avg r:0.6152 Best avg r: 0.6287
19:07:35,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:06,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:36,448 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4343
en_de Dev loss: 0.8555 r:0.2322
en_zh Dev loss: 0.7555 r:0.4360
ro_en Dev loss: 0.3264 r:0.8161
et_en Dev loss: 0.3729 r:0.7132
si_en Dev loss: 0.7379 r:0.5999
ne_en Dev loss: 0.4081 r:0.7657
ru_en Dev loss: 0.4651 r:0.7203
Current avg r:0.6119 Best avg r: 0.6287
19:15:08,457 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:38,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:09,119 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4105
en_de Dev loss: 0.8750 r:0.2145
en_zh Dev loss: 0.7435 r:0.4395
ro_en Dev loss: 0.3418 r:0.8155
et_en Dev loss: 0.3867 r:0.7120
si_en Dev loss: 0.7241 r:0.5993
ne_en Dev loss: 0.4260 r:0.7581
ru_en Dev loss: 0.4758 r:0.7219
Current avg r:0.6087 Best avg r: 0.6287
19:22:41,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:19,784 root INFO 
id:ro_en cur r: 0.8269 best r: 0.8269
19:24:11,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:41,785 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4254
en_de Dev loss: 0.8633 r:0.2066
en_zh Dev loss: 0.6985 r:0.4550
ro_en Dev loss: 0.3280 r:0.8216
et_en Dev loss: 0.3904 r:0.7198
si_en Dev loss: 0.6721 r:0.6138
ne_en Dev loss: 0.4255 r:0.7580
ru_en Dev loss: 0.4066 r:0.7508
Current avg r:0.6179 Best avg r: 0.6287
19:30:13,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:31:44,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:14,586 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4351
en_de Dev loss: 0.8590 r:0.2126
en_zh Dev loss: 0.6991 r:0.4557
ro_en Dev loss: 0.3385 r:0.8208
et_en Dev loss: 0.3801 r:0.7170
si_en Dev loss: 0.6953 r:0.6104
ne_en Dev loss: 0.4217 r:0.7592
ru_en Dev loss: 0.4454 r:0.7276
Current avg r:0.6147 Best avg r: 0.6287
19:37:46,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:16,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:47,200 root INFO Epoch 3 Global steps: 28000 Train loss: 0.3976
en_de Dev loss: 0.8509 r:0.2221
en_zh Dev loss: 0.7092 r:0.4429
ro_en Dev loss: 0.3107 r:0.8202
et_en Dev loss: 0.3581 r:0.7177
si_en Dev loss: 0.6369 r:0.6046
ne_en Dev loss: 0.4095 r:0.7594
ru_en Dev loss: 0.4549 r:0.7132
Current avg r:0.6114 Best avg r: 0.6287
19:45:20,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:50,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:21,345 root INFO Epoch 3 Global steps: 28700 Train loss: 0.3989
en_de Dev loss: 0.8602 r:0.2201
en_zh Dev loss: 0.6843 r:0.4689
ro_en Dev loss: 0.3279 r:0.8230
et_en Dev loss: 0.3679 r:0.7139
si_en Dev loss: 0.6759 r:0.6117
ne_en Dev loss: 0.4260 r:0.7551
ru_en Dev loss: 0.3943 r:0.7544
Current avg r:0.6210 Best avg r: 0.6287
19:52:54,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:25,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:55,371 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4041
en_de Dev loss: 0.8586 r:0.2301
en_zh Dev loss: 0.7137 r:0.4513
ro_en Dev loss: 0.3331 r:0.8210
et_en Dev loss: 0.3876 r:0.7197
si_en Dev loss: 0.6640 r:0.6131
ne_en Dev loss: 0.3874 r:0.7552
ru_en Dev loss: 0.4433 r:0.7321
Current avg r:0.6175 Best avg r: 0.6287
20:00:28,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:01:58,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:28,886 root INFO Epoch 3 Global steps: 30100 Train loss: 0.4056
en_de Dev loss: 0.8852 r:0.2279
en_zh Dev loss: 0.7705 r:0.4460
ro_en Dev loss: 0.3726 r:0.8179
et_en Dev loss: 0.4077 r:0.6988
si_en Dev loss: 0.7351 r:0.6024
ne_en Dev loss: 0.5023 r:0.7482
ru_en Dev loss: 0.5143 r:0.7135
Current avg r:0.6078 Best avg r: 0.6287
20:08:01,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:31,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:02,127 root INFO Epoch 3 Global steps: 30800 Train loss: 0.3989
en_de Dev loss: 0.8514 r:0.2441
en_zh Dev loss: 0.7280 r:0.4445
ro_en Dev loss: 0.3358 r:0.8177
et_en Dev loss: 0.3826 r:0.7035
si_en Dev loss: 0.7640 r:0.5965
ne_en Dev loss: 0.4820 r:0.7513
ru_en Dev loss: 0.4498 r:0.7233
Current avg r:0.6116 Best avg r: 0.6287
20:15:34,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:04,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:34,898 root INFO Epoch 3 Global steps: 31500 Train loss: 0.4285
en_de Dev loss: 0.8451 r:0.2337
en_zh Dev loss: 0.6990 r:0.4560
ro_en Dev loss: 0.3223 r:0.8200
et_en Dev loss: 0.3920 r:0.7147
si_en Dev loss: 0.6517 r:0.6093
ne_en Dev loss: 0.4135 r:0.7525
ru_en Dev loss: 0.4265 r:0.7324
Current avg r:0.6169 Best avg r: 0.6287
20:23:09,71 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:39,440 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:09,770 root INFO Epoch 4 Global steps: 32200 Train loss: 0.4145
en_de Dev loss: 0.8504 r:0.2230
en_zh Dev loss: 0.7053 r:0.4455
ro_en Dev loss: 0.3222 r:0.8192
et_en Dev loss: 0.3608 r:0.7092
si_en Dev loss: 0.7582 r:0.5993
ne_en Dev loss: 0.4959 r:0.7478
ru_en Dev loss: 0.4836 r:0.7103
Current avg r:0.6078 Best avg r: 0.6287
20:30:42,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:12,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:42,954 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3813
en_de Dev loss: 0.8631 r:0.2170
en_zh Dev loss: 0.7900 r:0.4230
ro_en Dev loss: 0.3354 r:0.8165
et_en Dev loss: 0.3881 r:0.7041
si_en Dev loss: 0.7436 r:0.5900
ne_en Dev loss: 0.4723 r:0.7394
ru_en Dev loss: 0.5495 r:0.6787
Current avg r:0.5955 Best avg r: 0.6287
20:38:16,206 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:46,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:17,138 root INFO Epoch 4 Global steps: 33600 Train loss: 0.3732
en_de Dev loss: 0.8581 r:0.2157
en_zh Dev loss: 0.7505 r:0.4300
ro_en Dev loss: 0.3375 r:0.8135
et_en Dev loss: 0.3878 r:0.6941
si_en Dev loss: 0.7548 r:0.5791
ne_en Dev loss: 0.4395 r:0.7419
ru_en Dev loss: 0.5120 r:0.6901
Current avg r:0.5949 Best avg r: 0.6287
20:45:50,399 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:20,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:51,245 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3480
en_de Dev loss: 0.8664 r:0.2096
en_zh Dev loss: 0.7406 r:0.4501
ro_en Dev loss: 0.3584 r:0.8120
et_en Dev loss: 0.4370 r:0.6949
si_en Dev loss: 0.7829 r:0.5895
ne_en Dev loss: 0.4543 r:0.7518
ru_en Dev loss: 0.5143 r:0.6964
Current avg r:0.6006 Best avg r: 0.6287
20:53:23,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:54,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:24,367 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3838
en_de Dev loss: 0.8540 r:0.2167
en_zh Dev loss: 0.7271 r:0.4271
ro_en Dev loss: 0.3174 r:0.8162
et_en Dev loss: 0.3985 r:0.6981
si_en Dev loss: 0.6938 r:0.5860
ne_en Dev loss: 0.4318 r:0.7376
ru_en Dev loss: 0.4413 r:0.7157
Current avg r:0.5996 Best avg r: 0.6287
21:00:57,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:27,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:58,5 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3748
en_de Dev loss: 0.8776 r:0.2025
en_zh Dev loss: 0.8093 r:0.4208
ro_en Dev loss: 0.3812 r:0.8124
et_en Dev loss: 0.4042 r:0.6950
si_en Dev loss: 0.8116 r:0.5784
ne_en Dev loss: 0.5566 r:0.7453
ru_en Dev loss: 0.5098 r:0.7020
Current avg r:0.5938 Best avg r: 0.6287
21:08:31,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:01,936 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:32,333 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3547
en_de Dev loss: 0.8661 r:0.2116
en_zh Dev loss: 0.7673 r:0.4254
ro_en Dev loss: 0.3449 r:0.8135
et_en Dev loss: 0.3933 r:0.6903
si_en Dev loss: 0.7886 r:0.5810
ne_en Dev loss: 0.4680 r:0.7470
ru_en Dev loss: 0.4808 r:0.7085
Current avg r:0.5968 Best avg r: 0.6287
21:16:05,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:36,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:06,799 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3685
en_de Dev loss: 0.8736 r:0.2004
en_zh Dev loss: 0.8113 r:0.4315
ro_en Dev loss: 0.3902 r:0.8148
et_en Dev loss: 0.4144 r:0.6900
si_en Dev loss: 0.8555 r:0.5789
ne_en Dev loss: 0.6085 r:0.7446
ru_en Dev loss: 0.5051 r:0.7158
Current avg r:0.5966 Best avg r: 0.6287
21:23:39,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:10,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:40,384 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3527
en_de Dev loss: 0.8485 r:0.2307
en_zh Dev loss: 0.7262 r:0.4551
ro_en Dev loss: 0.3242 r:0.8216
et_en Dev loss: 0.4338 r:0.7025
si_en Dev loss: 0.6248 r:0.6030
ne_en Dev loss: 0.4211 r:0.7452
ru_en Dev loss: 0.4068 r:0.7446
Current avg r:0.6147 Best avg r: 0.6287
21:31:12,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:43,141 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:13,478 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3770
en_de Dev loss: 0.8630 r:0.2157
en_zh Dev loss: 0.7432 r:0.4422
ro_en Dev loss: 0.3246 r:0.8229
et_en Dev loss: 0.3771 r:0.7006
si_en Dev loss: 0.6697 r:0.5934
ne_en Dev loss: 0.4562 r:0.7489
ru_en Dev loss: 0.4363 r:0.7303
Current avg r:0.6077 Best avg r: 0.6287
21:38:45,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:16,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:46,634 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3495
en_de Dev loss: 0.8835 r:0.2138
en_zh Dev loss: 0.7963 r:0.4188
ro_en Dev loss: 0.3715 r:0.8161
et_en Dev loss: 0.4015 r:0.7031
si_en Dev loss: 0.7697 r:0.5923
ne_en Dev loss: 0.4633 r:0.7540
ru_en Dev loss: 0.4925 r:0.7146
Current avg r:0.6018 Best avg r: 0.6287
21:46:21,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:51,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:22,107 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3283
en_de Dev loss: 0.8573 r:0.2378
en_zh Dev loss: 0.7742 r:0.4142
ro_en Dev loss: 0.3362 r:0.8157
et_en Dev loss: 0.4231 r:0.6954
si_en Dev loss: 0.6678 r:0.5941
ne_en Dev loss: 0.4388 r:0.7438
ru_en Dev loss: 0.4724 r:0.7061
Current avg r:0.6010 Best avg r: 0.6287
21:53:55,510 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:25,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:56,440 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3179
en_de Dev loss: 0.8666 r:0.2356
en_zh Dev loss: 0.7596 r:0.4400
ro_en Dev loss: 0.3456 r:0.8168
et_en Dev loss: 0.3974 r:0.6953
si_en Dev loss: 0.7508 r:0.5928
ne_en Dev loss: 0.5621 r:0.7361
ru_en Dev loss: 0.4768 r:0.7140
Current avg r:0.6044 Best avg r: 0.6287
22:01:29,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:00,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:30,698 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3157
en_de Dev loss: 0.8670 r:0.2239
en_zh Dev loss: 0.7925 r:0.4186
ro_en Dev loss: 0.3635 r:0.8121
et_en Dev loss: 0.4320 r:0.6858
si_en Dev loss: 0.8094 r:0.5803
ne_en Dev loss: 0.5185 r:0.7347
ru_en Dev loss: 0.4863 r:0.7079
Current avg r:0.5948 Best avg r: 0.6287
22:09:04,147 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:34,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:05,46 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3241
en_de Dev loss: 0.8645 r:0.2387
en_zh Dev loss: 0.7949 r:0.4364
ro_en Dev loss: 0.3669 r:0.8133
et_en Dev loss: 0.4248 r:0.6887
si_en Dev loss: 0.7735 r:0.5951
ne_en Dev loss: 0.5470 r:0.7412
ru_en Dev loss: 0.4342 r:0.7419
Current avg r:0.6079 Best avg r: 0.6287
22:16:38,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:08,438 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:38,770 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3318
en_de Dev loss: 0.8606 r:0.2486
en_zh Dev loss: 0.7951 r:0.4211
ro_en Dev loss: 0.3366 r:0.8178
et_en Dev loss: 0.3956 r:0.6969
si_en Dev loss: 0.6446 r:0.6086
ne_en Dev loss: 0.4232 r:0.7444
ru_en Dev loss: 0.4946 r:0.7054
Current avg r:0.6061 Best avg r: 0.6287
22:24:12,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:42,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:13,38 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3299
en_de Dev loss: 0.8451 r:0.2428
en_zh Dev loss: 0.7926 r:0.4170
ro_en Dev loss: 0.3282 r:0.8179
et_en Dev loss: 0.4185 r:0.6927
si_en Dev loss: 0.6796 r:0.5935
ne_en Dev loss: 0.4899 r:0.7363
ru_en Dev loss: 0.4623 r:0.7103
Current avg r:0.6015 Best avg r: 0.6287
22:31:46,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:16,877 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:47,236 root INFO Epoch 5 Global steps: 44100 Train loss: 0.3268
en_de Dev loss: 0.8553 r:0.2171
en_zh Dev loss: 0.7801 r:0.4316
ro_en Dev loss: 0.3489 r:0.8183
et_en Dev loss: 0.4238 r:0.6910
si_en Dev loss: 0.6865 r:0.5998
ne_en Dev loss: 0.4751 r:0.7351
ru_en Dev loss: 0.4436 r:0.7291
Current avg r:0.6031 Best avg r: 0.6287
22:39:20,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:50,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:21,130 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3262
en_de Dev loss: 0.8655 r:0.2095
en_zh Dev loss: 0.7573 r:0.4401
ro_en Dev loss: 0.3225 r:0.8213
et_en Dev loss: 0.4171 r:0.6838
si_en Dev loss: 0.8014 r:0.5823
ne_en Dev loss: 0.5773 r:0.7363
ru_en Dev loss: 0.4524 r:0.7226
Current avg r:0.5994 Best avg r: 0.6287
22:46:53,140 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:23,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:53,766 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3192
en_de Dev loss: 0.8780 r:0.1936
en_zh Dev loss: 0.7568 r:0.4565
ro_en Dev loss: 0.3410 r:0.8184
et_en Dev loss: 0.4358 r:0.6849
si_en Dev loss: 0.7286 r:0.5910
ne_en Dev loss: 0.4756 r:0.7381
ru_en Dev loss: 0.4623 r:0.7222
Current avg r:0.6007 Best avg r: 0.6287
22:54:26,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:56,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:26,585 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3174
en_de Dev loss: 0.8804 r:0.1904
en_zh Dev loss: 0.7413 r:0.4522
ro_en Dev loss: 0.3313 r:0.8147
et_en Dev loss: 0.4068 r:0.6812
si_en Dev loss: 0.6971 r:0.5823
ne_en Dev loss: 0.4887 r:0.7367
ru_en Dev loss: 0.4743 r:0.7002
Current avg r:0.5940 Best avg r: 0.6287
23:01:58,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:29,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:59,347 root INFO Epoch 5 Global steps: 46900 Train loss: 0.3177
en_de Dev loss: 0.8614 r:0.2112
en_zh Dev loss: 0.7839 r:0.4281
ro_en Dev loss: 0.3418 r:0.8172
et_en Dev loss: 0.4262 r:0.6846
si_en Dev loss: 0.7457 r:0.5804
ne_en Dev loss: 0.4652 r:0.7319
ru_en Dev loss: 0.5039 r:0.6909
Current avg r:0.5920 Best avg r: 0.6287
23:09:31,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:01,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:31,948 root INFO Epoch 5 Global steps: 47600 Train loss: 0.3260
en_de Dev loss: 0.8657 r:0.1898
en_zh Dev loss: 0.7193 r:0.4461
ro_en Dev loss: 0.3004 r:0.8262
et_en Dev loss: 0.4332 r:0.6915
si_en Dev loss: 0.6493 r:0.5961
ne_en Dev loss: 0.4261 r:0.7371
ru_en Dev loss: 0.4144 r:0.7280
Current avg r:0.6021 Best avg r: 0.6287
23:17:06,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:36,812 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:07,171 root INFO Epoch 6 Global steps: 48300 Train loss: 0.2888
en_de Dev loss: 0.8653 r:0.2036
en_zh Dev loss: 0.7540 r:0.4397
ro_en Dev loss: 0.3401 r:0.8196
et_en Dev loss: 0.4325 r:0.6774
si_en Dev loss: 0.7545 r:0.5860
ne_en Dev loss: 0.4446 r:0.7389
ru_en Dev loss: 0.4378 r:0.7313
Current avg r:0.5995 Best avg r: 0.6287
23:24:40,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:10,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:41,163 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2989
en_de Dev loss: 0.8686 r:0.1901
en_zh Dev loss: 0.7614 r:0.4271
ro_en Dev loss: 0.3518 r:0.8193
et_en Dev loss: 0.4384 r:0.6805
si_en Dev loss: 0.7861 r:0.5845
ne_en Dev loss: 0.5066 r:0.7417
ru_en Dev loss: 0.4506 r:0.7183
Current avg r:0.5945 Best avg r: 0.6287
23:32:14,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:44,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:14,960 root INFO Epoch 6 Global steps: 49700 Train loss: 0.2900
en_de Dev loss: 0.8583 r:0.1952
en_zh Dev loss: 0.7311 r:0.4332
ro_en Dev loss: 0.3219 r:0.8158
et_en Dev loss: 0.4289 r:0.6784
si_en Dev loss: 0.7237 r:0.5814
ne_en Dev loss: 0.4551 r:0.7418
ru_en Dev loss: 0.4377 r:0.7130
Current avg r:0.5941 Best avg r: 0.6287
23:39:46,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:17,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:47,382 root INFO Epoch 6 Global steps: 50400 Train loss: 0.2910
en_de Dev loss: 0.8683 r:0.2063
en_zh Dev loss: 0.7435 r:0.4374
ro_en Dev loss: 0.3413 r:0.8159
et_en Dev loss: 0.4250 r:0.6780
si_en Dev loss: 0.7975 r:0.5802
ne_en Dev loss: 0.4789 r:0.7423
ru_en Dev loss: 0.4318 r:0.7298
Current avg r:0.5986 Best avg r: 0.6287
23:47:19,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:49,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:19,927 root INFO Epoch 6 Global steps: 51100 Train loss: 0.2781
en_de Dev loss: 0.8809 r:0.2047
en_zh Dev loss: 0.8274 r:0.4132
ro_en Dev loss: 0.3868 r:0.8041
et_en Dev loss: 0.4651 r:0.6537
si_en Dev loss: 0.9372 r:0.5454
ne_en Dev loss: 0.6663 r:0.7196
ru_en Dev loss: 0.5142 r:0.6923
Current avg r:0.5761 Best avg r: 0.6287
23:54:51,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:22,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:52,433 root INFO Epoch 6 Global steps: 51800 Train loss: 0.3047
en_de Dev loss: 0.8837 r:0.1872
en_zh Dev loss: 0.8118 r:0.4236
ro_en Dev loss: 0.3747 r:0.8088
et_en Dev loss: 0.4649 r:0.6601
si_en Dev loss: 0.8451 r:0.5639
ne_en Dev loss: 0.5357 r:0.7287
ru_en Dev loss: 0.5198 r:0.6873
Current avg r:0.5799 Best avg r: 0.6287
00:02:24,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:54,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:25,174 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2891
en_de Dev loss: 0.8950 r:0.1896
en_zh Dev loss: 0.8323 r:0.4368
ro_en Dev loss: 0.3662 r:0.8209
et_en Dev loss: 0.4573 r:0.6767
si_en Dev loss: 0.7929 r:0.5838
ne_en Dev loss: 0.4955 r:0.7357
ru_en Dev loss: 0.5214 r:0.7072
Current avg r:0.5929 Best avg r: 0.6287
00:09:58,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:28,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:59,316 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2921
en_de Dev loss: 0.8784 r:0.1923
en_zh Dev loss: 0.7840 r:0.4404
ro_en Dev loss: 0.3355 r:0.8194
et_en Dev loss: 0.4411 r:0.6695
si_en Dev loss: 0.8104 r:0.5748
ne_en Dev loss: 0.5647 r:0.7278
ru_en Dev loss: 0.4641 r:0.7158
Current avg r:0.5914 Best avg r: 0.6287
00:17:31,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:01,720 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:32,5 root INFO Epoch 6 Global steps: 53900 Train loss: 0.3080
en_de Dev loss: 0.9001 r:0.1978
en_zh Dev loss: 0.7933 r:0.4493
ro_en Dev loss: 0.3593 r:0.8176
et_en Dev loss: 0.4545 r:0.6772
si_en Dev loss: 0.7934 r:0.5806
ne_en Dev loss: 0.5359 r:0.7301
ru_en Dev loss: 0.4705 r:0.7260
Current avg r:0.5969 Best avg r: 0.6287
00:25:04,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:34,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:28:04,600 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2633
en_de Dev loss: 0.9190 r:0.1767
en_zh Dev loss: 0.8155 r:0.4441
ro_en Dev loss: 0.3623 r:0.8195
et_en Dev loss: 0.4629 r:0.6738
si_en Dev loss: 0.8092 r:0.5740
ne_en Dev loss: 0.4599 r:0.7341
ru_en Dev loss: 0.4669 r:0.7313
Current avg r:0.5934 Best avg r: 0.6287
00:32:36,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:07,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:37,470 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2696
en_de Dev loss: 0.8863 r:0.1847
en_zh Dev loss: 0.7821 r:0.4503
ro_en Dev loss: 0.3416 r:0.8209
et_en Dev loss: 0.4606 r:0.6767
si_en Dev loss: 0.7431 r:0.5844
ne_en Dev loss: 0.4512 r:0.7364
ru_en Dev loss: 0.4309 r:0.7346
Current avg r:0.5983 Best avg r: 0.6287
00:40:11,86 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:41,438 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:11,724 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2515
en_de Dev loss: 0.9100 r:0.1625
en_zh Dev loss: 0.8042 r:0.4411
ro_en Dev loss: 0.3592 r:0.8209
et_en Dev loss: 0.4680 r:0.6668
si_en Dev loss: 0.8025 r:0.5764
ne_en Dev loss: 0.4849 r:0.7265
ru_en Dev loss: 0.4997 r:0.7085
Current avg r:0.5861 Best avg r: 0.6287
00:47:43,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:14,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:44,675 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2657
en_de Dev loss: 0.9028 r:0.1765
en_zh Dev loss: 0.8317 r:0.4225
ro_en Dev loss: 0.3886 r:0.8190
et_en Dev loss: 0.4791 r:0.6673
si_en Dev loss: 0.8286 r:0.5746
ne_en Dev loss: 0.5774 r:0.7248
ru_en Dev loss: 0.4877 r:0.7154
Current avg r:0.5857 Best avg r: 0.6287
00:55:17,756 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:48,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:18,552 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2519
en_de Dev loss: 0.8704 r:0.1955
en_zh Dev loss: 0.7753 r:0.4218
ro_en Dev loss: 0.3289 r:0.8236
et_en Dev loss: 0.4344 r:0.6773
si_en Dev loss: 0.7409 r:0.5801
ne_en Dev loss: 0.5667 r:0.7243
ru_en Dev loss: 0.4633 r:0.7126
Current avg r:0.5908 Best avg r: 0.6287
01:02:51,746 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:22,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:52,528 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2465
en_de Dev loss: 0.8904 r:0.1861
en_zh Dev loss: 0.8173 r:0.4310
ro_en Dev loss: 0.3738 r:0.8205
et_en Dev loss: 0.4790 r:0.6757
si_en Dev loss: 0.7841 r:0.5816
ne_en Dev loss: 0.5210 r:0.7253
ru_en Dev loss: 0.5212 r:0.6981
Current avg r:0.5883 Best avg r: 0.6287
01:10:24,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:55,219 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:13:25,500 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2513
en_de Dev loss: 0.9094 r:0.1609
en_zh Dev loss: 0.8354 r:0.4167
ro_en Dev loss: 0.3806 r:0.8144
et_en Dev loss: 0.4700 r:0.6581
si_en Dev loss: 0.8908 r:0.5634
ne_en Dev loss: 0.5379 r:0.7268
ru_en Dev loss: 0.4969 r:0.7061
Current avg r:0.5781 Best avg r: 0.6287
01:17:58,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:28,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:20:58,936 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2581
en_de Dev loss: 0.9004 r:0.1839
en_zh Dev loss: 0.8097 r:0.4434
ro_en Dev loss: 0.3536 r:0.8205
et_en Dev loss: 0.4809 r:0.6713
si_en Dev loss: 0.8176 r:0.5776
ne_en Dev loss: 0.5392 r:0.7308
ru_en Dev loss: 0.4754 r:0.7202
Current avg r:0.5925 Best avg r: 0.6287
01:25:32,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:27:02,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:32,900 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2467
en_de Dev loss: 0.8980 r:0.1718
en_zh Dev loss: 0.8110 r:0.4338
ro_en Dev loss: 0.3540 r:0.8202
et_en Dev loss: 0.4735 r:0.6734
si_en Dev loss: 0.7977 r:0.5759
ne_en Dev loss: 0.4885 r:0.7252
ru_en Dev loss: 0.4784 r:0.7156
Current avg r:0.5880 Best avg r: 0.6287
01:33:06,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:34:36,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:06,938 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2446
en_de Dev loss: 0.8928 r:0.1572
en_zh Dev loss: 0.8098 r:0.4284
ro_en Dev loss: 0.3669 r:0.8162
et_en Dev loss: 0.4518 r:0.6612
si_en Dev loss: 0.9222 r:0.5564
ne_en Dev loss: 0.6204 r:0.7188
ru_en Dev loss: 0.5405 r:0.6815
Current avg r:0.5743 Best avg r: 0.6287
01:40:40,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:10,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:40,971 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2560
en_de Dev loss: 0.8771 r:0.1711
en_zh Dev loss: 0.7928 r:0.4281
ro_en Dev loss: 0.3409 r:0.8169
et_en Dev loss: 0.4313 r:0.6653
si_en Dev loss: 0.9234 r:0.5502
ne_en Dev loss: 0.6102 r:0.7175
ru_en Dev loss: 0.4943 r:0.7038
Current avg r:0.5790 Best avg r: 0.6287
01:48:14,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:49:45,617 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:16,254 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2495
en_de Dev loss: 0.9049 r:0.1843
en_zh Dev loss: 0.8309 r:0.4410
ro_en Dev loss: 0.3830 r:0.8166
et_en Dev loss: 0.4791 r:0.6617
si_en Dev loss: 0.8810 r:0.5661
ne_en Dev loss: 0.5325 r:0.7226
ru_en Dev loss: 0.4985 r:0.7122
Current avg r:0.5864 Best avg r: 0.6287
01:55:50,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:21,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:58:52,327 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2506
en_de Dev loss: 0.8783 r:0.2032
en_zh Dev loss: 0.7525 r:0.4493
ro_en Dev loss: 0.3254 r:0.8218
et_en Dev loss: 0.4218 r:0.6824
si_en Dev loss: 0.7725 r:0.5788
ne_en Dev loss: 0.5130 r:0.7250
ru_en Dev loss: 0.4440 r:0.7208
Current avg r:0.5973 Best avg r: 0.6287
02:03:26,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:04:57,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:06:27,946 root INFO Epoch 7 Global steps: 63700 Train loss: 0.2480
en_de Dev loss: 0.9098 r:0.1834
en_zh Dev loss: 0.8193 r:0.4378
ro_en Dev loss: 0.3727 r:0.8147
et_en Dev loss: 0.4616 r:0.6703
si_en Dev loss: 0.8674 r:0.5686
ne_en Dev loss: 0.5412 r:0.7267
ru_en Dev loss: 0.4962 r:0.7128
Current avg r:0.5878 Best avg r: 0.6287
02:11:03,797 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:34,649 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:05,421 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2317
en_de Dev loss: 0.9312 r:0.1841
en_zh Dev loss: 0.8326 r:0.4481
ro_en Dev loss: 0.3911 r:0.8171
et_en Dev loss: 0.4754 r:0.6801
si_en Dev loss: 0.8303 r:0.5797
ne_en Dev loss: 0.5113 r:0.7286
ru_en Dev loss: 0.4792 r:0.7320
Current avg r:0.5957 Best avg r: 0.6287
02:18:38,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:09,52 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:21:39,344 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2274
en_de Dev loss: 0.8756 r:0.1877
en_zh Dev loss: 0.7553 r:0.4509
ro_en Dev loss: 0.3303 r:0.8205
et_en Dev loss: 0.4544 r:0.6790
si_en Dev loss: 0.7622 r:0.5767
ne_en Dev loss: 0.4717 r:0.7296
ru_en Dev loss: 0.4117 r:0.7386
Current avg r:0.5976 Best avg r: 0.6287
02:26:12,528 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:27:42,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:13,389 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2295
en_de Dev loss: 0.8976 r:0.1822
en_zh Dev loss: 0.7770 r:0.4528
ro_en Dev loss: 0.3456 r:0.8184
et_en Dev loss: 0.4671 r:0.6693
si_en Dev loss: 0.8359 r:0.5653
ne_en Dev loss: 0.4830 r:0.7230
ru_en Dev loss: 0.4510 r:0.7205
Current avg r:0.5902 Best avg r: 0.6287
02:33:46,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:17,250 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:47,664 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2231
en_de Dev loss: 0.9198 r:0.1729
en_zh Dev loss: 0.8318 r:0.4407
ro_en Dev loss: 0.3845 r:0.8158
et_en Dev loss: 0.4865 r:0.6661
si_en Dev loss: 0.9151 r:0.5592
ne_en Dev loss: 0.5581 r:0.7197
ru_en Dev loss: 0.5102 r:0.7088
Current avg r:0.5833 Best avg r: 0.6287
02:41:21,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:42:51,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:22,19 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2305
en_de Dev loss: 0.9004 r:0.1945
en_zh Dev loss: 0.8019 r:0.4597
ro_en Dev loss: 0.3727 r:0.8228
et_en Dev loss: 0.4712 r:0.6819
si_en Dev loss: 0.8344 r:0.5793
ne_en Dev loss: 0.5037 r:0.7374
ru_en Dev loss: 0.4584 r:0.7461
Current avg r:0.6031 Best avg r: 0.6287
02:48:55,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:25,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:55,990 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2205
en_de Dev loss: 0.8874 r:0.1917
en_zh Dev loss: 0.8023 r:0.4454
ro_en Dev loss: 0.3770 r:0.8145
et_en Dev loss: 0.4830 r:0.6674
si_en Dev loss: 1.0044 r:0.5460
ne_en Dev loss: 0.6063 r:0.7238
ru_en Dev loss: 0.5358 r:0.6954
Current avg r:0.5835 Best avg r: 0.6287
02:56:28,301 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:57:58,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:59:29,253 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2227
en_de Dev loss: 0.8862 r:0.1919
en_zh Dev loss: 0.8050 r:0.4441
ro_en Dev loss: 0.3748 r:0.8149
et_en Dev loss: 0.4716 r:0.6696
si_en Dev loss: 0.8807 r:0.5573
ne_en Dev loss: 0.5749 r:0.7253
ru_en Dev loss: 0.5172 r:0.7037
Current avg r:0.5867 Best avg r: 0.6287
03:04:02,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:05:33,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:07:03,741 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2235
en_de Dev loss: 0.8825 r:0.2115
en_zh Dev loss: 0.7859 r:0.4556
ro_en Dev loss: 0.3649 r:0.8195
et_en Dev loss: 0.4721 r:0.6768
si_en Dev loss: 0.8270 r:0.5713
ne_en Dev loss: 0.4393 r:0.7297
ru_en Dev loss: 0.4611 r:0.7314
Current avg r:0.5994 Best avg r: 0.6287
03:11:37,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:07,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:38,316 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2348
en_de Dev loss: 0.8900 r:0.1726
en_zh Dev loss: 0.8282 r:0.4431
ro_en Dev loss: 0.3986 r:0.8115
et_en Dev loss: 0.4862 r:0.6544
si_en Dev loss: 0.9985 r:0.5464
ne_en Dev loss: 0.6592 r:0.7178
ru_en Dev loss: 0.5267 r:0.7027
Current avg r:0.5783 Best avg r: 0.6287
03:19:11,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:20:41,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:12,208 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2208
en_de Dev loss: 0.8823 r:0.2054
en_zh Dev loss: 0.7707 r:0.4571
ro_en Dev loss: 0.3574 r:0.8180
et_en Dev loss: 0.4795 r:0.6717
si_en Dev loss: 0.8442 r:0.5628
ne_en Dev loss: 0.5278 r:0.7262
ru_en Dev loss: 0.4600 r:0.7264
Current avg r:0.5954 Best avg r: 0.6287
03:26:45,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:15,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:29:46,245 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2257
en_de Dev loss: 0.8890 r:0.1798
en_zh Dev loss: 0.7274 r:0.4570
ro_en Dev loss: 0.3321 r:0.8194
et_en Dev loss: 0.4605 r:0.6700
si_en Dev loss: 0.7606 r:0.5626
ne_en Dev loss: 0.4922 r:0.7275
ru_en Dev loss: 0.4393 r:0.7231
Current avg r:0.5913 Best avg r: 0.6287
03:34:20,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:50,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:37:21,2 root INFO Epoch 9 Global steps: 72100 Train loss: 0.2009
en_de Dev loss: 0.8839 r:0.2023
en_zh Dev loss: 0.7780 r:0.4537
ro_en Dev loss: 0.3431 r:0.8185
et_en Dev loss: 0.4717 r:0.6788
si_en Dev loss: 0.7622 r:0.5733
ne_en Dev loss: 0.4444 r:0.7311
ru_en Dev loss: 0.4382 r:0.7369
Current avg r:0.5992 Best avg r: 0.6287
03:41:55,271 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:26,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:44:56,886 root INFO Epoch 9 Global steps: 72800 Train loss: 0.2053
en_de Dev loss: 0.8968 r:0.1977
en_zh Dev loss: 0.8305 r:0.4293
ro_en Dev loss: 0.3695 r:0.8153
et_en Dev loss: 0.4868 r:0.6747
si_en Dev loss: 0.7971 r:0.5612
ne_en Dev loss: 0.4931 r:0.7308
ru_en Dev loss: 0.4555 r:0.7300
Current avg r:0.5913 Best avg r: 0.6287
03:49:30,596 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:01,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:32,236 root INFO Epoch 9 Global steps: 73500 Train loss: 0.2075
en_de Dev loss: 0.9071 r:0.1709
en_zh Dev loss: 0.7924 r:0.4501
ro_en Dev loss: 0.3591 r:0.8180
et_en Dev loss: 0.4941 r:0.6738
si_en Dev loss: 0.7883 r:0.5687
ne_en Dev loss: 0.4787 r:0.7292
ru_en Dev loss: 0.4663 r:0.7216
Current avg r:0.5903 Best avg r: 0.6287
03:57:06,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:58:37,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:08,241 root INFO Epoch 9 Global steps: 74200 Train loss: 0.2129
en_de Dev loss: 0.9067 r:0.1669
en_zh Dev loss: 0.8155 r:0.4394
ro_en Dev loss: 0.3688 r:0.8124
et_en Dev loss: 0.4710 r:0.6729
si_en Dev loss: 0.8603 r:0.5609
ne_en Dev loss: 0.5592 r:0.7270
ru_en Dev loss: 0.4777 r:0.7234
Current avg r:0.5861 Best avg r: 0.6287
04:04:41,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:06:11,441 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:07:41,806 root INFO Epoch 9 Global steps: 74900 Train loss: 0.2090
en_de Dev loss: 0.9241 r:0.1614
en_zh Dev loss: 0.8204 r:0.4496
ro_en Dev loss: 0.4240 r:0.8060
et_en Dev loss: 0.4823 r:0.6500
si_en Dev loss: 0.9425 r:0.5480
ne_en Dev loss: 0.6484 r:0.7264
ru_en Dev loss: 0.5135 r:0.7091
Current avg r:0.5786 Best avg r: 0.6287
04:12:13,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:13:44,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:14,662 root INFO Epoch 9 Global steps: 75600 Train loss: 0.2070
en_de Dev loss: 0.9011 r:0.1758
en_zh Dev loss: 0.7680 r:0.4549
ro_en Dev loss: 0.3455 r:0.8149
et_en Dev loss: 0.4959 r:0.6730
si_en Dev loss: 0.7774 r:0.5658
ne_en Dev loss: 0.5152 r:0.7164
ru_en Dev loss: 0.4275 r:0.7337
Current avg r:0.5906 Best avg r: 0.6287
04:19:47,113 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:17,640 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:22:48,116 root INFO Epoch 9 Global steps: 76300 Train loss: 0.2082
en_de Dev loss: 0.8916 r:0.1886
en_zh Dev loss: 0.7622 r:0.4572
ro_en Dev loss: 0.3322 r:0.8192
et_en Dev loss: 0.4451 r:0.6796
si_en Dev loss: 0.7797 r:0.5729
ne_en Dev loss: 0.4758 r:0.7296
ru_en Dev loss: 0.4337 r:0.7365
Current avg r:0.5977 Best avg r: 0.6287
04:27:20,830 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:28:51,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:21,588 root INFO Epoch 9 Global steps: 77000 Train loss: 0.1941
en_de Dev loss: 0.8761 r:0.1979
en_zh Dev loss: 0.7444 r:0.4530
ro_en Dev loss: 0.3165 r:0.8196
et_en Dev loss: 0.4581 r:0.6722
si_en Dev loss: 0.7624 r:0.5671
ne_en Dev loss: 0.5191 r:0.7300
ru_en Dev loss: 0.3987 r:0.7457
Current avg r:0.5979 Best avg r: 0.6287
04:34:54,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:25,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:55,969 root INFO Epoch 9 Global steps: 77700 Train loss: 0.1962
en_de Dev loss: 0.9213 r:0.1902
en_zh Dev loss: 0.8649 r:0.4491
ro_en Dev loss: 0.4099 r:0.8151
et_en Dev loss: 0.5063 r:0.6709
si_en Dev loss: 0.8698 r:0.5731
ne_en Dev loss: 0.5866 r:0.7293
ru_en Dev loss: 0.5343 r:0.7195
Current avg r:0.5924 Best avg r: 0.6287
04:42:28,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:58,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:29,306 root INFO Epoch 9 Global steps: 78400 Train loss: 0.1896
en_de Dev loss: 0.9114 r:0.1837
en_zh Dev loss: 0.8056 r:0.4495
ro_en Dev loss: 0.3804 r:0.8114
et_en Dev loss: 0.4896 r:0.6663
si_en Dev loss: 0.8802 r:0.5570
ne_en Dev loss: 0.5680 r:0.7251
ru_en Dev loss: 0.4522 r:0.7351
Current avg r:0.5897 Best avg r: 0.6287
04:50:01,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:51:32,120 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:02,517 root INFO Epoch 9 Global steps: 79100 Train loss: 0.1977
en_de Dev loss: 0.9370 r:0.1579
en_zh Dev loss: 0.7841 r:0.4650
ro_en Dev loss: 0.3874 r:0.8140
et_en Dev loss: 0.4711 r:0.6643
si_en Dev loss: 0.9784 r:0.5582
ne_en Dev loss: 0.6702 r:0.7246
ru_en Dev loss: 0.4869 r:0.7287
Current avg r:0.5875 Best avg r: 0.6287
04:57:36,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:59:06,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:00:36,978 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1660
en_de Dev loss: 0.9481 r:0.1580
en_zh Dev loss: 0.8392 r:0.4394
ro_en Dev loss: 0.4044 r:0.8158
et_en Dev loss: 0.4776 r:0.6747
si_en Dev loss: 0.8964 r:0.5678
ne_en Dev loss: 0.5958 r:0.7258
ru_en Dev loss: 0.5042 r:0.7227
Current avg r:0.5863 Best avg r: 0.6287
05:05:09,194 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:39,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:09,911 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1880
en_de Dev loss: 0.9243 r:0.1590
en_zh Dev loss: 0.7860 r:0.4410
ro_en Dev loss: 0.3516 r:0.8147
et_en Dev loss: 0.4421 r:0.6715
si_en Dev loss: 0.8948 r:0.5582
ne_en Dev loss: 0.6928 r:0.7126
ru_en Dev loss: 0.4597 r:0.7298
Current avg r:0.5838 Best avg r: 0.6287
05:12:42,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:12,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:42,923 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1936
en_de Dev loss: 0.9477 r:0.1678
en_zh Dev loss: 0.8668 r:0.4290
ro_en Dev loss: 0.4213 r:0.8087
et_en Dev loss: 0.4920 r:0.6582
si_en Dev loss: 0.9660 r:0.5581
ne_en Dev loss: 0.6710 r:0.7170
ru_en Dev loss: 0.5077 r:0.7211
Current avg r:0.5800 Best avg r: 0.6287
05:20:15,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:21:45,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:16,70 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1890
en_de Dev loss: 0.9184 r:0.1869
en_zh Dev loss: 0.7969 r:0.4492
ro_en Dev loss: 0.3620 r:0.8132
et_en Dev loss: 0.5318 r:0.6713
si_en Dev loss: 0.7335 r:0.5786
ne_en Dev loss: 0.4970 r:0.7129
ru_en Dev loss: 0.4215 r:0.7408
Current avg r:0.5933 Best avg r: 0.6287
05:27:48,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:29:19,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:49,626 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1805
en_de Dev loss: 0.9378 r:0.1605
en_zh Dev loss: 0.8329 r:0.4389
ro_en Dev loss: 0.3815 r:0.8129
et_en Dev loss: 0.4478 r:0.6714
si_en Dev loss: 0.8954 r:0.5588
ne_en Dev loss: 0.5720 r:0.7119
ru_en Dev loss: 0.4763 r:0.7361
Current avg r:0.5843 Best avg r: 0.6287
05:35:23,242 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:54,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:24,893 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1783
en_de Dev loss: 0.9156 r:0.1781
en_zh Dev loss: 0.7913 r:0.4426
ro_en Dev loss: 0.3441 r:0.8158
et_en Dev loss: 0.4546 r:0.6771
si_en Dev loss: 0.8070 r:0.5659
ne_en Dev loss: 0.5305 r:0.7280
ru_en Dev loss: 0.4420 r:0.7358
Current avg r:0.5919 Best avg r: 0.6287
05:42:59,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:30,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:01,124 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1995
en_de Dev loss: 0.9395 r:0.1748
en_zh Dev loss: 0.8446 r:0.4355
ro_en Dev loss: 0.3674 r:0.8155
et_en Dev loss: 0.4676 r:0.6670
si_en Dev loss: 0.8899 r:0.5535
ne_en Dev loss: 0.5995 r:0.7143
ru_en Dev loss: 0.4757 r:0.7324
Current avg r:0.5847 Best avg r: 0.6287
05:50:35,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:06,749 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:37,566 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1861
en_de Dev loss: 0.9393 r:0.1785
en_zh Dev loss: 0.8311 r:0.4425
ro_en Dev loss: 0.3843 r:0.8098
et_en Dev loss: 0.4769 r:0.6618
si_en Dev loss: 0.8759 r:0.5606
ne_en Dev loss: 0.5399 r:0.7245
ru_en Dev loss: 0.4636 r:0.7364
Current avg r:0.5877 Best avg r: 0.6287
05:58:10,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:40,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:01:11,234 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1804
en_de Dev loss: 0.9263 r:0.1713
en_zh Dev loss: 0.7682 r:0.4558
ro_en Dev loss: 0.3565 r:0.8114
et_en Dev loss: 0.4582 r:0.6677
si_en Dev loss: 0.8592 r:0.5516
ne_en Dev loss: 0.5760 r:0.7184
ru_en Dev loss: 0.4291 r:0.7363
Current avg r:0.5875 Best avg r: 0.6287
06:05:44,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:15,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:45,580 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1853
en_de Dev loss: 0.9272 r:0.1466
en_zh Dev loss: 0.7848 r:0.4464
ro_en Dev loss: 0.3468 r:0.8152
et_en Dev loss: 0.4518 r:0.6710
si_en Dev loss: 0.7956 r:0.5616
ne_en Dev loss: 0.5044 r:0.7231
ru_en Dev loss: 0.4356 r:0.7393
Current avg r:0.5862 Best avg r: 0.6287
06:13:18,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:49,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:16:19,780 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1906
en_de Dev loss: 0.8838 r:0.1752
en_zh Dev loss: 0.7618 r:0.4580
ro_en Dev loss: 0.3482 r:0.8121
et_en Dev loss: 0.4676 r:0.6723
si_en Dev loss: 0.8172 r:0.5580
ne_en Dev loss: 0.4800 r:0.7195
ru_en Dev loss: 0.4480 r:0.7307
Current avg r:0.5894 Best avg r: 0.6287
06:20:53,303 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:22:23,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:54,262 root INFO Epoch 10 Global steps: 87500 Train loss: 0.1820
en_de Dev loss: 0.9245 r:0.1540
en_zh Dev loss: 0.8285 r:0.4508
ro_en Dev loss: 0.4133 r:0.8092
et_en Dev loss: 0.4738 r:0.6609
si_en Dev loss: 0.9892 r:0.5472
ne_en Dev loss: 0.6833 r:0.7106
ru_en Dev loss: 0.5264 r:0.7155
Current avg r:0.5783 Best avg r: 0.6287
06:28:29,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:59,497 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:29,835 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1714
en_de Dev loss: 0.9188 r:0.1485
en_zh Dev loss: 0.7937 r:0.4525
ro_en Dev loss: 0.3925 r:0.8082
et_en Dev loss: 0.4744 r:0.6594
si_en Dev loss: 0.9587 r:0.5415
ne_en Dev loss: 0.6514 r:0.7040
ru_en Dev loss: 0.5008 r:0.7126
Current avg r:0.5753 Best avg r: 0.6287
06:36:01,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:32,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:02,675 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1788
en_de Dev loss: 0.9183 r:0.1677
en_zh Dev loss: 0.7929 r:0.4680
ro_en Dev loss: 0.3842 r:0.8102
et_en Dev loss: 0.4578 r:0.6748
si_en Dev loss: 0.9983 r:0.5456
ne_en Dev loss: 0.6882 r:0.7072
ru_en Dev loss: 0.4582 r:0.7412
Current avg r:0.5878 Best avg r: 0.6287
06:43:36,248 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:06,765 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:37,249 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1665
en_de Dev loss: 0.8972 r:0.1798
en_zh Dev loss: 0.7780 r:0.4624
ro_en Dev loss: 0.3718 r:0.8090
et_en Dev loss: 0.4611 r:0.6578
si_en Dev loss: 0.9861 r:0.5392
ne_en Dev loss: 0.6580 r:0.7066
ru_en Dev loss: 0.4803 r:0.7224
Current avg r:0.5824 Best avg r: 0.6287
06:51:10,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:41,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:54:11,760 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1700
en_de Dev loss: 0.9192 r:0.1664
en_zh Dev loss: 0.8038 r:0.4569
ro_en Dev loss: 0.3747 r:0.8096
et_en Dev loss: 0.4527 r:0.6670
si_en Dev loss: 0.9388 r:0.5409
ne_en Dev loss: 0.6121 r:0.7146
ru_en Dev loss: 0.4755 r:0.7266
Current avg r:0.5832 Best avg r: 0.6287
06:58:44,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:14,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:45,687 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1654
en_de Dev loss: 0.9408 r:0.1564
en_zh Dev loss: 0.8086 r:0.4632
ro_en Dev loss: 0.3728 r:0.8124
et_en Dev loss: 0.4589 r:0.6778
si_en Dev loss: 0.8968 r:0.5508
ne_en Dev loss: 0.5901 r:0.7146
ru_en Dev loss: 0.4550 r:0.7434
Current avg r:0.5884 Best avg r: 0.6287
07:06:19,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:07:50,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:09:20,949 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1572
en_de Dev loss: 0.9055 r:0.1698
en_zh Dev loss: 0.7657 r:0.4687
ro_en Dev loss: 0.3406 r:0.8155
et_en Dev loss: 0.4440 r:0.6687
si_en Dev loss: 0.8641 r:0.5438
ne_en Dev loss: 0.6012 r:0.7092
ru_en Dev loss: 0.4375 r:0.7364
Current avg r:0.5874 Best avg r: 0.6287
07:13:55,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:15:26,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:16:56,929 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1681
en_de Dev loss: 0.9257 r:0.1602
en_zh Dev loss: 0.7778 r:0.4606
ro_en Dev loss: 0.3509 r:0.8145
et_en Dev loss: 0.4620 r:0.6742
si_en Dev loss: 0.8671 r:0.5570
ne_en Dev loss: 0.5423 r:0.7207
ru_en Dev loss: 0.4335 r:0.7409
Current avg r:0.5897 Best avg r: 0.6287
07:21:31,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:23:01,725 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:24:32,94 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1635
en_de Dev loss: 0.9503 r:0.1626
en_zh Dev loss: 0.8652 r:0.4531
ro_en Dev loss: 0.4164 r:0.8090
et_en Dev loss: 0.5091 r:0.6579
si_en Dev loss: 1.0151 r:0.5425
ne_en Dev loss: 0.6876 r:0.7066
ru_en Dev loss: 0.5102 r:0.7254
Current avg r:0.5796 Best avg r: 0.6287
07:29:04,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:30:34,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:05,314 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1589
en_de Dev loss: 0.9205 r:0.1664
en_zh Dev loss: 0.8246 r:0.4430
ro_en Dev loss: 0.3842 r:0.8083
et_en Dev loss: 0.4836 r:0.6621
si_en Dev loss: 0.9139 r:0.5373
ne_en Dev loss: 0.5814 r:0.7140
ru_en Dev loss: 0.4921 r:0.7162
Current avg r:0.5782 Best avg r: 0.6287
07:36:37,971 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:08,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:39:38,997 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1673
en_de Dev loss: 0.9212 r:0.1841
en_zh Dev loss: 0.7874 r:0.4717
ro_en Dev loss: 0.3653 r:0.8144
et_en Dev loss: 0.4849 r:0.6760
si_en Dev loss: 0.8579 r:0.5492
ne_en Dev loss: 0.5043 r:0.7113
ru_en Dev loss: 0.4461 r:0.7443
Current avg r:0.5930 Best avg r: 0.6287
07:44:12,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:45:43,310 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:47:13,785 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1601
en_de Dev loss: 0.9444 r:0.1739
en_zh Dev loss: 0.8269 r:0.4623
ro_en Dev loss: 0.3833 r:0.8168
et_en Dev loss: 0.4832 r:0.6736
si_en Dev loss: 0.9283 r:0.5488
ne_en Dev loss: 0.5885 r:0.7093
ru_en Dev loss: 0.4561 r:0.7448
Current avg r:0.5899 Best avg r: 0.6287
07:51:48,181 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:53:18,591 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:54:49,47 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1550
en_de Dev loss: 0.9114 r:0.1731
en_zh Dev loss: 0.7615 r:0.4674
ro_en Dev loss: 0.3435 r:0.8140
et_en Dev loss: 0.4848 r:0.6679
si_en Dev loss: 0.8953 r:0.5406
ne_en Dev loss: 0.5786 r:0.7155
ru_en Dev loss: 0.4056 r:0.7483
Current avg r:0.5895 Best avg r: 0.6287
07:59:21,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:00:52,520 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:23,212 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1453
en_de Dev loss: 0.9351 r:0.1739
en_zh Dev loss: 0.8142 r:0.4635
ro_en Dev loss: 0.3952 r:0.8121
et_en Dev loss: 0.4851 r:0.6634
si_en Dev loss: 0.9611 r:0.5384
ne_en Dev loss: 0.5899 r:0.7155
ru_en Dev loss: 0.4627 r:0.7412
Current avg r:0.5869 Best avg r: 0.6287
08:06:56,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:27,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:09:57,799 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1469
en_de Dev loss: 0.9246 r:0.1708
en_zh Dev loss: 0.8018 r:0.4580
ro_en Dev loss: 0.3650 r:0.8117
et_en Dev loss: 0.4507 r:0.6695
si_en Dev loss: 0.9239 r:0.5424
ne_en Dev loss: 0.6476 r:0.7135
ru_en Dev loss: 0.4710 r:0.7322
Current avg r:0.5855 Best avg r: 0.6287
08:14:31,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:16:01,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:17:32,460 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1455
en_de Dev loss: 0.9161 r:0.1749
en_zh Dev loss: 0.7752 r:0.4604
ro_en Dev loss: 0.3489 r:0.8137
et_en Dev loss: 0.4575 r:0.6688
si_en Dev loss: 0.8900 r:0.5444
ne_en Dev loss: 0.5431 r:0.7174
ru_en Dev loss: 0.4259 r:0.7419
Current avg r:0.5888 Best avg r: 0.6287
08:22:06,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:23:36,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:25:06,987 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1487
en_de Dev loss: 0.9339 r:0.1589
en_zh Dev loss: 0.7981 r:0.4571
ro_en Dev loss: 0.3895 r:0.8089
et_en Dev loss: 0.4795 r:0.6610
si_en Dev loss: 0.9441 r:0.5395
ne_en Dev loss: 0.5475 r:0.7115
ru_en Dev loss: 0.4787 r:0.7227
Current avg r:0.5799 Best avg r: 0.6287
08:29:39,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:31:10,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:32:40,680 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1444
en_de Dev loss: 0.9387 r:0.1610
en_zh Dev loss: 0.7909 r:0.4495
ro_en Dev loss: 0.3709 r:0.8089
et_en Dev loss: 0.4799 r:0.6644
si_en Dev loss: 0.9109 r:0.5344
ne_en Dev loss: 0.6516 r:0.7080
ru_en Dev loss: 0.4531 r:0.7316
Current avg r:0.5797 Best avg r: 0.6287
08:37:14,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:38:45,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:40:16,294 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1576
en_de Dev loss: 0.9194 r:0.1485
en_zh Dev loss: 0.7735 r:0.4546
ro_en Dev loss: 0.3802 r:0.8142
et_en Dev loss: 0.4709 r:0.6631
si_en Dev loss: 0.8801 r:0.5464
ne_en Dev loss: 0.5886 r:0.7142
ru_en Dev loss: 0.4874 r:0.7248
Current avg r:0.5808 Best avg r: 0.6287
08:44:50,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:46:21,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:47:52,377 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1605
en_de Dev loss: 0.9392 r:0.1576
en_zh Dev loss: 0.8324 r:0.4430
ro_en Dev loss: 0.3720 r:0.8118
et_en Dev loss: 0.4935 r:0.6578
si_en Dev loss: 0.9012 r:0.5372
ne_en Dev loss: 0.6253 r:0.7097
ru_en Dev loss: 0.4520 r:0.7419
Current avg r:0.5799 Best avg r: 0.6287
08:52:26,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:57,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:55:27,935 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1426
en_de Dev loss: 0.9195 r:0.1645
en_zh Dev loss: 0.8072 r:0.4411
ro_en Dev loss: 0.3693 r:0.8070
et_en Dev loss: 0.4718 r:0.6535
si_en Dev loss: 0.9182 r:0.5288
ne_en Dev loss: 0.6181 r:0.7096
ru_en Dev loss: 0.4388 r:0.7400
Current avg r:0.5778 Best avg r: 0.6287
09:00:01,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:32,433 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:02,971 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1420
en_de Dev loss: 0.9138 r:0.1521
en_zh Dev loss: 0.8046 r:0.4605
ro_en Dev loss: 0.3899 r:0.8075
et_en Dev loss: 0.4879 r:0.6495
si_en Dev loss: 0.9721 r:0.5330
ne_en Dev loss: 0.6331 r:0.7129
ru_en Dev loss: 0.4709 r:0.7245
Current avg r:0.5771 Best avg r: 0.6287
09:07:36,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:07,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:37,890 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1525
en_de Dev loss: 0.9663 r:0.1633
en_zh Dev loss: 0.7876 r:0.4768
ro_en Dev loss: 0.3906 r:0.8085
et_en Dev loss: 0.5260 r:0.6591
si_en Dev loss: 0.8590 r:0.5461
ne_en Dev loss: 0.6259 r:0.7124
ru_en Dev loss: 0.4796 r:0.7325
Current avg r:0.5855 Best avg r: 0.6287
09:15:12,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:16:43,412 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:18:13,907 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1321
en_de Dev loss: 0.9478 r:0.1586
en_zh Dev loss: 0.8093 r:0.4558
ro_en Dev loss: 0.3882 r:0.8050
et_en Dev loss: 0.4833 r:0.6607
si_en Dev loss: 0.9000 r:0.5318
ne_en Dev loss: 0.5744 r:0.7148
ru_en Dev loss: 0.4838 r:0.7285
Current avg r:0.5793 Best avg r: 0.6287
09:22:47,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:24:17,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:25:48,477 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1323
en_de Dev loss: 0.9236 r:0.1787
en_zh Dev loss: 0.7942 r:0.4575
ro_en Dev loss: 0.3699 r:0.8108
et_en Dev loss: 0.4646 r:0.6722
si_en Dev loss: 0.9148 r:0.5394
ne_en Dev loss: 0.6065 r:0.7125
ru_en Dev loss: 0.4294 r:0.7539
Current avg r:0.5893 Best avg r: 0.6287
09:30:22,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:31:52,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:33:23,325 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1331
en_de Dev loss: 0.9223 r:0.1734
en_zh Dev loss: 0.8130 r:0.4455
ro_en Dev loss: 0.3940 r:0.8066
et_en Dev loss: 0.4891 r:0.6607
si_en Dev loss: 0.9080 r:0.5409
ne_en Dev loss: 0.6216 r:0.7092
ru_en Dev loss: 0.4827 r:0.7320
Current avg r:0.5812 Best avg r: 0.6287
09:37:57,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:39:27,661 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:40:58,146 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1441
en_de Dev loss: 0.9287 r:0.1732
en_zh Dev loss: 0.8267 r:0.4471
ro_en Dev loss: 0.3951 r:0.8079
et_en Dev loss: 0.4888 r:0.6627
si_en Dev loss: 0.9859 r:0.5321
ne_en Dev loss: 0.6239 r:0.7087
ru_en Dev loss: 0.5021 r:0.7353
Current avg r:0.5810 Best avg r: 0.6287
09:45:31,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:02,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:48:32,797 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1303
en_de Dev loss: 0.9500 r:0.1678
en_zh Dev loss: 0.8136 r:0.4576
ro_en Dev loss: 0.3955 r:0.8113
et_en Dev loss: 0.4737 r:0.6726
si_en Dev loss: 0.8933 r:0.5451
ne_en Dev loss: 0.6200 r:0.7115
ru_en Dev loss: 0.5024 r:0.7331
Current avg r:0.5856 Best avg r: 0.6287
09:53:05,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:54:36,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:06,735 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1340
en_de Dev loss: 0.9376 r:0.1776
en_zh Dev loss: 0.7992 r:0.4580
ro_en Dev loss: 0.3811 r:0.8073
et_en Dev loss: 0.4713 r:0.6659
si_en Dev loss: 0.9237 r:0.5324
ne_en Dev loss: 0.5956 r:0.7078
ru_en Dev loss: 0.4568 r:0.7443
Current avg r:0.5847 Best avg r: 0.6287
10:00:40,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:11,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:42,550 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1380
en_de Dev loss: 0.9523 r:0.1661
en_zh Dev loss: 0.8720 r:0.4508
ro_en Dev loss: 0.4127 r:0.8051
et_en Dev loss: 0.4958 r:0.6589
si_en Dev loss: 0.9562 r:0.5362
ne_en Dev loss: 0.6268 r:0.7123
ru_en Dev loss: 0.4872 r:0.7374
Current avg r:0.5810 Best avg r: 0.6287
10:08:16,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:09:47,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:18,447 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1359
en_de Dev loss: 0.9426 r:0.1620
en_zh Dev loss: 0.8378 r:0.4357
ro_en Dev loss: 0.3801 r:0.8075
et_en Dev loss: 0.4707 r:0.6647
si_en Dev loss: 0.9088 r:0.5354
ne_en Dev loss: 0.6123 r:0.7073
ru_en Dev loss: 0.4671 r:0.7347
Current avg r:0.5782 Best avg r: 0.6287
10:15:53,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:17:23,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:18:54,972 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1328
en_de Dev loss: 0.9400 r:0.1637
en_zh Dev loss: 0.7712 r:0.4648
ro_en Dev loss: 0.3510 r:0.8144
et_en Dev loss: 0.4576 r:0.6785
si_en Dev loss: 0.8852 r:0.5417
ne_en Dev loss: 0.5396 r:0.7184
ru_en Dev loss: 0.4098 r:0.7531
Current avg r:0.5906 Best avg r: 0.6287
10:23:29,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:00,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:30,900 root INFO Epoch 13 Global steps: 109900 Train loss: 0.1304
en_de Dev loss: 0.9515 r:0.1521
en_zh Dev loss: 0.7777 r:0.4675
ro_en Dev loss: 0.3650 r:0.8109
et_en Dev loss: 0.4619 r:0.6730
si_en Dev loss: 0.8579 r:0.5431
ne_en Dev loss: 0.5375 r:0.7144
ru_en Dev loss: 0.4404 r:0.7435
Current avg r:0.5864 Best avg r: 0.6287
