14:36:26,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:36:52,378 root INFO 
id:en_zh cur r: 0.2584 best r: 0.2584
14:37:05,266 root INFO 
id:ro_en cur r: 0.5982 best r: 0.5982
14:37:18,165 root INFO 
id:et_en cur r: 0.4898 best r: 0.4898
14:37:31,39 root INFO 
id:si_en cur r: 0.4766 best r: 0.4766
14:37:56,734 root INFO 
id:ne_en cur r: 0.5648 best r: 0.5648
14:38:09,533 root INFO 
id:ru_en cur r: 0.6412 best r: 0.6412
14:38:09,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:39:39,345 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:39:39,351 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:39:39,355 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:39:39,360 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:39:39,365 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:39:39,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:39:39,374 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:39:52,214 root INFO Epoch 0 Global steps: 700 Train loss: 0.8548
en_de Dev loss: 0.8990 r:0.0836
en_zh Dev loss: 0.7738 r:0.2526
ro_en Dev loss: 0.6407 r:0.5969
et_en Dev loss: 0.6600 r:0.4292
si_en Dev loss: 0.6614 r:0.4622
ne_en Dev loss: 0.6514 r:0.5461
ru_en Dev loss: 0.5995 r:0.6313
Current avg r:0.4288 Best avg r: 0.4288
14:44:19,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:45,120 root INFO 
id:en_zh cur r: 0.2587 best r: 0.2587
14:45:49,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:19,442 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8066
en_de Dev loss: 0.9144 r:0.0969
en_zh Dev loss: 0.8064 r:0.2367
ro_en Dev loss: 0.7183 r:0.5956
et_en Dev loss: 0.6137 r:0.4395
si_en Dev loss: 0.7771 r:0.4257
ne_en Dev loss: 0.6557 r:0.4910
ru_en Dev loss: 0.6245 r:0.6125
Current avg r:0.4140 Best avg r: 0.4288
14:51:46,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:12,425 root INFO 
id:en_zh cur r: 0.2666 best r: 0.2666
14:52:25,277 root INFO 
id:ro_en cur r: 0.6446 best r: 0.6446
14:52:38,123 root INFO 
id:et_en cur r: 0.5427 best r: 0.5427
14:53:16,689 root INFO 
id:ne_en cur r: 0.5756 best r: 0.5756
14:53:29,489 root INFO 
id:ru_en cur r: 0.6749 best r: 0.6749
14:53:29,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:59,278 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:54:59,285 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:54:59,289 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:54:59,294 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:54:59,298 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:54:59,304 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:54:59,309 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:55:12,151 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7407
en_de Dev loss: 0.9618 r:0.0919
en_zh Dev loss: 0.8110 r:0.2750
ro_en Dev loss: 0.5709 r:0.6644
et_en Dev loss: 0.5291 r:0.5488
si_en Dev loss: 0.7793 r:0.4376
ne_en Dev loss: 0.5765 r:0.5558
ru_en Dev loss: 0.5353 r:0.6621
Current avg r:0.4622 Best avg r: 0.4622
14:59:39,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:52,481 root INFO 
id:en_de cur r: 0.0757 best r: 0.0757
15:00:05,301 root INFO 
id:en_zh cur r: 0.3310 best r: 0.3310
15:00:18,147 root INFO 
id:ro_en cur r: 0.7013 best r: 0.7013
15:00:31,11 root INFO 
id:et_en cur r: 0.6294 best r: 0.6294
15:00:43,868 root INFO 
id:si_en cur r: 0.4879 best r: 0.4879
15:01:09,565 root INFO 
id:ne_en cur r: 0.6357 best r: 0.6357
15:01:22,378 root INFO 
id:ru_en cur r: 0.6985 best r: 0.6985
15:01:22,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:52,195 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:02:52,206 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:02:52,212 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:02:52,217 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:02:52,222 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:02:52,230 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:02:52,234 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:03:05,77 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7126
en_de Dev loss: 0.9189 r:0.1496
en_zh Dev loss: 0.7290 r:0.3475
ro_en Dev loss: 0.4386 r:0.7233
et_en Dev loss: 0.4405 r:0.6435
si_en Dev loss: 0.6517 r:0.5005
ne_en Dev loss: 0.4879 r:0.6478
ru_en Dev loss: 0.4497 r:0.7007
Current avg r:0.5304 Best avg r: 0.5304
15:07:32,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:11,140 root INFO 
id:ro_en cur r: 0.7025 best r: 0.7025
15:08:23,994 root INFO 
id:et_en cur r: 0.6305 best r: 0.6305
15:09:02,477 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:32,234 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6160
en_de Dev loss: 1.0378 r:0.1371
en_zh Dev loss: 0.8648 r:0.3391
ro_en Dev loss: 0.5096 r:0.7285
et_en Dev loss: 0.4495 r:0.6507
si_en Dev loss: 0.7942 r:0.4992
ne_en Dev loss: 0.5978 r:0.6126
ru_en Dev loss: 0.6084 r:0.6742
Current avg r:0.5202 Best avg r: 0.5304
15:14:59,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:12,78 root INFO 
id:en_de cur r: 0.1409 best r: 0.1409
15:15:24,898 root INFO 
id:en_zh cur r: 0.3754 best r: 0.3754
15:15:37,751 root INFO 
id:ro_en cur r: 0.7460 best r: 0.7460
15:15:50,613 root INFO 
id:et_en cur r: 0.6654 best r: 0.6654
15:16:03,473 root INFO 
id:si_en cur r: 0.5481 best r: 0.5481
15:16:29,175 root INFO 
id:ne_en cur r: 0.6868 best r: 0.6868
15:16:41,979 root INFO 
id:ru_en cur r: 0.7364 best r: 0.7364
15:16:41,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:11,801 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:18:11,807 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:18:11,812 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:18:11,817 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:18:11,822 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:18:11,826 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:18:11,831 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:18:24,690 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6265
en_de Dev loss: 0.9468 r:0.1552
en_zh Dev loss: 0.7269 r:0.3897
ro_en Dev loss: 0.4071 r:0.7541
et_en Dev loss: 0.3879 r:0.6851
si_en Dev loss: 0.6817 r:0.5405
ne_en Dev loss: 0.4792 r:0.6716
ru_en Dev loss: 0.4489 r:0.7377
Current avg r:0.5620 Best avg r: 0.5620
15:22:54,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:07,96 root INFO 
id:en_de cur r: 0.1500 best r: 0.1500
15:23:19,953 root INFO 
id:en_zh cur r: 0.4099 best r: 0.4099
15:23:32,841 root INFO 
id:ro_en cur r: 0.7519 best r: 0.7519
15:24:24,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:54,11 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:25:54,17 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:25:54,22 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:25:54,27 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:25:54,31 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:25:54,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:25:54,42 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:26:06,895 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6169
en_de Dev loss: 0.9081 r:0.1632
en_zh Dev loss: 0.7081 r:0.4172
ro_en Dev loss: 0.3810 r:0.7662
et_en Dev loss: 0.3922 r:0.6775
si_en Dev loss: 0.6596 r:0.5454
ne_en Dev loss: 0.4530 r:0.6845
ru_en Dev loss: 0.4341 r:0.7439
Current avg r:0.5711 Best avg r: 0.5711
15:30:34,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:47,309 root INFO 
id:en_de cur r: 0.1628 best r: 0.1628
15:31:12,981 root INFO 
id:ro_en cur r: 0.7625 best r: 0.7625
15:31:25,845 root INFO 
id:et_en cur r: 0.6795 best r: 0.6795
15:32:04,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:34,26 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:33:34,32 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:33:34,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:33:34,41 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:33:34,46 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:33:34,54 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:33:34,58 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:33:46,924 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5983
en_de Dev loss: 0.8975 r:0.1862
en_zh Dev loss: 0.7253 r:0.4119
ro_en Dev loss: 0.4165 r:0.7815
et_en Dev loss: 0.3966 r:0.6901
si_en Dev loss: 0.6269 r:0.5678
ne_en Dev loss: 0.4913 r:0.6868
ru_en Dev loss: 0.4793 r:0.7348
Current avg r:0.5799 Best avg r: 0.5799
15:38:14,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:27,440 root INFO 
id:en_de cur r: 0.1806 best r: 0.1806
15:38:53,114 root INFO 
id:ro_en cur r: 0.7683 best r: 0.7683
15:39:05,968 root INFO 
id:et_en cur r: 0.6852 best r: 0.6852
15:39:44,536 root INFO 
id:ne_en cur r: 0.6966 best r: 0.6966
15:39:57,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:27,69 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6110
en_de Dev loss: 0.9631 r:0.1757
en_zh Dev loss: 0.8128 r:0.4054
ro_en Dev loss: 0.4335 r:0.7800
et_en Dev loss: 0.3951 r:0.6882
si_en Dev loss: 0.7566 r:0.5435
ne_en Dev loss: 0.4815 r:0.6724
ru_en Dev loss: 0.5136 r:0.7292
Current avg r:0.5706 Best avg r: 0.5799
15:45:53,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:19,643 root INFO 
id:en_zh cur r: 0.4121 best r: 0.4121
15:47:23,867 root INFO 
id:ne_en cur r: 0.7093 best r: 0.7093
15:47:36,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:06,482 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5944
en_de Dev loss: 0.9229 r:0.1980
en_zh Dev loss: 0.7810 r:0.4265
ro_en Dev loss: 0.4252 r:0.7806
et_en Dev loss: 0.4306 r:0.6835
si_en Dev loss: 0.7982 r:0.5527
ne_en Dev loss: 0.5312 r:0.6819
ru_en Dev loss: 0.6209 r:0.7090
Current avg r:0.5760 Best avg r: 0.5799
15:53:33,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:59,638 root INFO 
id:en_zh cur r: 0.4152 best r: 0.4152
15:54:12,471 root INFO 
id:ro_en cur r: 0.7734 best r: 0.7734
15:54:38,178 root INFO 
id:si_en cur r: 0.5538 best r: 0.5538
15:55:03,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:33,666 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:56:33,673 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:56:33,679 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:56:33,687 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:56:33,692 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:56:33,697 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:56:33,703 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:56:46,558 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5679
en_de Dev loss: 0.8687 r:0.2083
en_zh Dev loss: 0.7383 r:0.4240
ro_en Dev loss: 0.3584 r:0.7872
et_en Dev loss: 0.3844 r:0.6863
si_en Dev loss: 0.7070 r:0.5562
ne_en Dev loss: 0.4381 r:0.6888
ru_en Dev loss: 0.4645 r:0.7327
Current avg r:0.5833 Best avg r: 0.5833
16:01:16,856 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:42,538 root INFO 
id:en_zh cur r: 0.4205 best r: 0.4205
16:01:55,382 root INFO 
id:ro_en cur r: 0.7854 best r: 0.7854
16:02:21,121 root INFO 
id:si_en cur r: 0.5665 best r: 0.5665
16:02:46,827 root INFO 
id:ne_en cur r: 0.7164 best r: 0.7164
16:02:59,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:29,415 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:04:29,422 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:04:29,430 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:04:29,434 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:04:29,439 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:04:29,443 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:04:29,448 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:04:42,294 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5677
en_de Dev loss: 0.8942 r:0.1872
en_zh Dev loss: 0.7187 r:0.4229
ro_en Dev loss: 0.3448 r:0.7975
et_en Dev loss: 0.3774 r:0.6932
si_en Dev loss: 0.6661 r:0.5709
ne_en Dev loss: 0.4312 r:0.7000
ru_en Dev loss: 0.4890 r:0.7312
Current avg r:0.5861 Best avg r: 0.5861
16:09:09,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:47,818 root INFO 
id:ro_en cur r: 0.7906 best r: 0.7906
16:10:39,243 root INFO 
id:ne_en cur r: 0.7168 best r: 0.7168
16:10:52,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:21,807 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:12:21,813 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:12:21,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:12:21,823 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:12:21,828 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:12:21,833 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:12:21,839 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:12:34,698 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5216
en_de Dev loss: 0.8881 r:0.2103
en_zh Dev loss: 0.7702 r:0.4230
ro_en Dev loss: 0.3540 r:0.8009
et_en Dev loss: 0.3682 r:0.7011
si_en Dev loss: 0.6876 r:0.5712
ne_en Dev loss: 0.4052 r:0.7103
ru_en Dev loss: 0.4403 r:0.7476
Current avg r:0.5949 Best avg r: 0.5949
16:17:02,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:15,116 root INFO 
id:en_de cur r: 0.1828 best r: 0.1828
16:17:27,944 root INFO 
id:en_zh cur r: 0.4299 best r: 0.4299
16:17:40,795 root INFO 
id:ro_en cur r: 0.8086 best r: 0.8086
16:17:53,647 root INFO 
id:et_en cur r: 0.6884 best r: 0.6884
16:18:06,509 root INFO 
id:si_en cur r: 0.5770 best r: 0.5770
16:18:32,247 root INFO 
id:ne_en cur r: 0.7342 best r: 0.7342
16:18:45,53 root INFO 
id:ru_en cur r: 0.7441 best r: 0.7441
16:18:45,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:20:16,255 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:20:16,262 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:20:16,267 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:20:16,271 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:20:16,276 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:20:16,281 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:20:16,285 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:20:29,144 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5314
en_de Dev loss: 0.8832 r:0.1946
en_zh Dev loss: 0.7415 r:0.4365
ro_en Dev loss: 0.3355 r:0.8090
et_en Dev loss: 0.3775 r:0.7030
si_en Dev loss: 0.6825 r:0.5808
ne_en Dev loss: 0.4016 r:0.7205
ru_en Dev loss: 0.4518 r:0.7516
Current avg r:0.5994 Best avg r: 0.5994
16:24:56,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:09,753 root INFO 
id:en_de cur r: 0.2016 best r: 0.2016
16:26:28,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:58,41 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5105
en_de Dev loss: 0.8910 r:0.1985
en_zh Dev loss: 0.7491 r:0.4402
ro_en Dev loss: 0.3609 r:0.8089
et_en Dev loss: 0.4042 r:0.6917
si_en Dev loss: 0.8016 r:0.5732
ne_en Dev loss: 0.5138 r:0.7091
ru_en Dev loss: 0.4856 r:0.7435
Current avg r:0.5950 Best avg r: 0.5994
16:32:25,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:51,333 root INFO 
id:en_zh cur r: 0.4374 best r: 0.4374
16:33:04,192 root INFO 
id:ro_en cur r: 0.8145 best r: 0.8145
16:33:17,36 root INFO 
id:et_en cur r: 0.6899 best r: 0.6899
16:33:29,897 root INFO 
id:si_en cur r: 0.5890 best r: 0.5890
16:33:55,554 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:25,388 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:35:25,395 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:35:25,400 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:35:25,405 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:35:25,410 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:35:25,414 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:35:25,419 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:35:38,278 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5362
en_de Dev loss: 0.8950 r:0.2092
en_zh Dev loss: 0.7013 r:0.4478
ro_en Dev loss: 0.3304 r:0.8127
et_en Dev loss: 0.3692 r:0.7034
si_en Dev loss: 0.6647 r:0.5893
ne_en Dev loss: 0.3813 r:0.7280
ru_en Dev loss: 0.4528 r:0.7464
Current avg r:0.6052 Best avg r: 0.6052
16:40:07,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:20,183 root INFO 
id:en_de cur r: 0.2025 best r: 0.2025
16:40:58,706 root INFO 
id:et_en cur r: 0.6985 best r: 0.6985
16:41:11,567 root INFO 
id:si_en cur r: 0.5954 best r: 0.5954
16:41:37,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:06,965 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4812
en_de Dev loss: 0.9590 r:0.2063
en_zh Dev loss: 0.7868 r:0.4202
ro_en Dev loss: 0.3592 r:0.8058
et_en Dev loss: 0.3734 r:0.6989
si_en Dev loss: 0.7012 r:0.5875
ne_en Dev loss: 0.4043 r:0.7285
ru_en Dev loss: 0.4819 r:0.7413
Current avg r:0.5983 Best avg r: 0.6052
16:47:35,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:48:26,922 root INFO 
id:et_en cur r: 0.7000 best r: 0.7000
16:49:05,480 root INFO 
id:ne_en cur r: 0.7357 best r: 0.7357
16:49:18,270 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:48,31 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5223
en_de Dev loss: 0.8647 r:0.1933
en_zh Dev loss: 0.7195 r:0.4277
ro_en Dev loss: 0.3348 r:0.8057
et_en Dev loss: 0.3856 r:0.7007
si_en Dev loss: 0.5758 r:0.5987
ne_en Dev loss: 0.3686 r:0.7317
ru_en Dev loss: 0.4266 r:0.7258
Current avg r:0.5976 Best avg r: 0.6052
16:55:15,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:45,470 root INFO 
id:ne_en cur r: 0.7377 best r: 0.7377
16:56:58,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:27,969 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5235
en_de Dev loss: 0.9318 r:0.1817
en_zh Dev loss: 0.8355 r:0.4284
ro_en Dev loss: 0.4370 r:0.7982
et_en Dev loss: 0.4173 r:0.6888
si_en Dev loss: 0.7975 r:0.5712
ne_en Dev loss: 0.5120 r:0.7258
ru_en Dev loss: 0.5429 r:0.7245
Current avg r:0.5884 Best avg r: 0.6052
17:02:56,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:22,416 root INFO 
id:en_zh cur r: 0.4406 best r: 0.4406
17:03:48,86 root INFO 
id:et_en cur r: 0.7011 best r: 0.7011
17:04:26,605 root INFO 
id:ne_en cur r: 0.7385 best r: 0.7385
17:04:39,403 root INFO 
id:ru_en cur r: 0.7507 best r: 0.7507
17:04:39,403 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:09,180 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5225
en_de Dev loss: 0.8646 r:0.1963
en_zh Dev loss: 0.7222 r:0.4423
ro_en Dev loss: 0.3439 r:0.8104
et_en Dev loss: 0.3641 r:0.7000
si_en Dev loss: 0.6928 r:0.5903
ne_en Dev loss: 0.3985 r:0.7337
ru_en Dev loss: 0.4173 r:0.7536
Current avg r:0.6038 Best avg r: 0.6052
17:10:36,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:49,601 root INFO 
id:en_de cur r: 0.2167 best r: 0.2167
17:11:02,412 root INFO 
id:en_zh cur r: 0.4423 best r: 0.4423
17:12:06,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:36,323 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:13:36,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:13:36,335 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:13:36,339 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:13:36,344 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:13:36,349 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:13:36,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:13:49,190 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5240
en_de Dev loss: 0.8493 r:0.2227
en_zh Dev loss: 0.7098 r:0.4420
ro_en Dev loss: 0.3366 r:0.8119
et_en Dev loss: 0.3800 r:0.6974
si_en Dev loss: 0.6483 r:0.5899
ne_en Dev loss: 0.3864 r:0.7379
ru_en Dev loss: 0.4014 r:0.7500
Current avg r:0.6074 Best avg r: 0.6074
17:18:16,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:18:41,783 root INFO 
id:en_zh cur r: 0.4606 best r: 0.4606
17:18:54,623 root INFO 
id:ro_en cur r: 0.8151 best r: 0.8151
17:19:45,999 root INFO 
id:ne_en cur r: 0.7387 best r: 0.7387
17:19:58,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:28,580 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4882
en_de Dev loss: 0.8801 r:0.2090
en_zh Dev loss: 0.6993 r:0.4490
ro_en Dev loss: 0.3431 r:0.8104
et_en Dev loss: 0.3825 r:0.6936
si_en Dev loss: 0.7049 r:0.5822
ne_en Dev loss: 0.3674 r:0.7374
ru_en Dev loss: 0.4321 r:0.7411
Current avg r:0.6032 Best avg r: 0.6074
17:25:57,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:27:01,822 root INFO 
id:si_en cur r: 0.5963 best r: 0.5963
17:27:27,529 root INFO 
id:ne_en cur r: 0.7475 best r: 0.7475
17:27:40,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:10,70 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:29:10,76 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:29:10,81 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:29:10,86 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:29:10,91 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:29:10,95 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:29:10,100 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:29:22,958 root INFO Epoch 2 Global steps: 16100 Train loss: 0.5019
en_de Dev loss: 0.8875 r:0.2155
en_zh Dev loss: 0.7547 r:0.4410
ro_en Dev loss: 0.3241 r:0.8163
et_en Dev loss: 0.3914 r:0.7002
si_en Dev loss: 0.7247 r:0.5924
ne_en Dev loss: 0.3666 r:0.7458
ru_en Dev loss: 0.4439 r:0.7419
Current avg r:0.6076 Best avg r: 0.6076
17:33:50,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:34:29,78 root INFO 
id:ro_en cur r: 0.8185 best r: 0.8185
17:34:41,928 root INFO 
id:et_en cur r: 0.7012 best r: 0.7012
17:34:54,777 root INFO 
id:si_en cur r: 0.5991 best r: 0.5991
17:35:20,422 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:36:50,193 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4716
en_de Dev loss: 0.9069 r:0.2081
en_zh Dev loss: 0.7654 r:0.4422
ro_en Dev loss: 0.3528 r:0.8186
et_en Dev loss: 0.3930 r:0.7008
si_en Dev loss: 0.7182 r:0.5948
ne_en Dev loss: 0.4342 r:0.7379
ru_en Dev loss: 0.5255 r:0.7306
Current avg r:0.6047 Best avg r: 0.6076
17:41:17,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:41:30,638 root INFO 
id:en_de cur r: 0.2237 best r: 0.2237
17:42:09,107 root INFO 
id:et_en cur r: 0.7046 best r: 0.7046
17:42:47,645 root INFO 
id:ne_en cur r: 0.7497 best r: 0.7497
17:43:00,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:30,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:44:30,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:44:30,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:44:30,182 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:44:30,187 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:44:30,193 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:44:30,199 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:44:43,54 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4593
en_de Dev loss: 0.8627 r:0.2119
en_zh Dev loss: 0.7124 r:0.4345
ro_en Dev loss: 0.3198 r:0.8175
et_en Dev loss: 0.3698 r:0.7041
si_en Dev loss: 0.6149 r:0.5996
ne_en Dev loss: 0.3641 r:0.7427
ru_en Dev loss: 0.3977 r:0.7547
Current avg r:0.6093 Best avg r: 0.6093
17:49:10,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:23,453 root INFO 
id:en_de cur r: 0.2254 best r: 0.2254
17:50:40,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:10,39 root INFO Epoch 2 Global steps: 18200 Train loss: 0.4926
en_de Dev loss: 0.9316 r:0.2141
en_zh Dev loss: 0.7743 r:0.4422
ro_en Dev loss: 0.3996 r:0.8037
et_en Dev loss: 0.4177 r:0.6877
si_en Dev loss: 0.8000 r:0.5705
ne_en Dev loss: 0.4667 r:0.7198
ru_en Dev loss: 0.5440 r:0.7272
Current avg r:0.5950 Best avg r: 0.6093
17:56:38,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:51,135 root INFO 
id:en_de cur r: 0.2382 best r: 0.2382
17:58:08,215 root INFO 
id:ne_en cur r: 0.7512 best r: 0.7512
17:58:21,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:59:50,779 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4464
en_de Dev loss: 0.8802 r:0.2289
en_zh Dev loss: 0.7275 r:0.4499
ro_en Dev loss: 0.3314 r:0.8146
et_en Dev loss: 0.3831 r:0.6963
si_en Dev loss: 0.7028 r:0.5812
ne_en Dev loss: 0.3923 r:0.7425
ru_en Dev loss: 0.4410 r:0.7461
Current avg r:0.6085 Best avg r: 0.6093
18:04:18,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:48,308 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:18,79 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4693
en_de Dev loss: 0.9474 r:0.2297
en_zh Dev loss: 0.8647 r:0.4438
ro_en Dev loss: 0.3992 r:0.8099
et_en Dev loss: 0.4225 r:0.6873
si_en Dev loss: 0.8535 r:0.5724
ne_en Dev loss: 0.5717 r:0.7324
ru_en Dev loss: 0.5486 r:0.7334
Current avg r:0.6013 Best avg r: 0.6093
18:11:45,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:12:11,241 root INFO 
id:en_zh cur r: 0.4613 best r: 0.4613
18:12:24,78 root INFO 
id:ro_en cur r: 0.8253 best r: 0.8253
18:12:49,752 root INFO 
id:si_en cur r: 0.6057 best r: 0.6057
18:13:15,474 root INFO 
id:ne_en cur r: 0.7536 best r: 0.7536
18:13:28,270 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:01,38 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:15:01,45 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:15:01,50 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:15:01,55 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:15:01,60 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:15:01,64 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:15:01,69 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:15:13,922 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4755
en_de Dev loss: 0.8672 r:0.2207
en_zh Dev loss: 0.7117 r:0.4605
ro_en Dev loss: 0.3283 r:0.8208
et_en Dev loss: 0.3805 r:0.7027
si_en Dev loss: 0.6724 r:0.5924
ne_en Dev loss: 0.4097 r:0.7496
ru_en Dev loss: 0.4707 r:0.7382
Current avg r:0.6121 Best avg r: 0.6121
18:19:41,416 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:19,908 root INFO 
id:ro_en cur r: 0.8303 best r: 0.8303
18:20:45,614 root INFO 
id:si_en cur r: 0.6097 best r: 0.6097
18:21:11,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:41,13 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:22:41,20 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:22:41,25 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:22:41,29 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:22:41,34 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:22:41,38 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:22:41,43 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:22:56,891 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4517
en_de Dev loss: 0.8508 r:0.2270
en_zh Dev loss: 0.7227 r:0.4556
ro_en Dev loss: 0.3260 r:0.8225
et_en Dev loss: 0.3795 r:0.7061
si_en Dev loss: 0.6552 r:0.5955
ne_en Dev loss: 0.3797 r:0.7479
ru_en Dev loss: 0.4593 r:0.7352
Current avg r:0.6128 Best avg r: 0.6128
18:27:26,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:27:52,385 root INFO 
id:en_zh cur r: 0.4749 best r: 0.4749
18:28:56,582 root INFO 
id:ru_en cur r: 0.7614 best r: 0.7614
18:28:56,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:26,383 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4661
en_de Dev loss: 0.9064 r:0.2095
en_zh Dev loss: 0.7429 r:0.4653
ro_en Dev loss: 0.3417 r:0.8179
et_en Dev loss: 0.3992 r:0.6975
si_en Dev loss: 0.7289 r:0.5898
ne_en Dev loss: 0.4163 r:0.7473
ru_en Dev loss: 0.4112 r:0.7620
Current avg r:0.6128 Best avg r: 0.6128
18:34:53,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:57,816 root INFO 
id:si_en cur r: 0.6152 best r: 0.6152
18:36:23,519 root INFO 
id:ne_en cur r: 0.7540 best r: 0.7540
18:36:36,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:06,59 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:38:06,66 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:38:06,71 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:38:06,75 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:38:06,80 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:38:06,85 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:38:06,90 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:38:18,938 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4668
en_de Dev loss: 0.8612 r:0.2167
en_zh Dev loss: 0.7076 r:0.4653
ro_en Dev loss: 0.3044 r:0.8220
et_en Dev loss: 0.3584 r:0.7079
si_en Dev loss: 0.6548 r:0.6027
ne_en Dev loss: 0.4083 r:0.7501
ru_en Dev loss: 0.4128 r:0.7511
Current avg r:0.6165 Best avg r: 0.6165
18:42:47,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:43:00,754 root INFO 
id:en_de cur r: 0.2503 best r: 0.2503
18:44:17,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:47,519 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4391
en_de Dev loss: 0.8940 r:0.2266
en_zh Dev loss: 0.7845 r:0.4605
ro_en Dev loss: 0.3553 r:0.8184
et_en Dev loss: 0.4014 r:0.6988
si_en Dev loss: 0.8258 r:0.5820
ne_en Dev loss: 0.4609 r:0.7440
ru_en Dev loss: 0.4981 r:0.7295
Current avg r:0.6085 Best avg r: 0.6165
18:50:15,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:44,892 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:14,683 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4910
en_de Dev loss: 0.8739 r:0.2080
en_zh Dev loss: 0.7059 r:0.4725
ro_en Dev loss: 0.3522 r:0.8081
et_en Dev loss: 0.3910 r:0.6918
si_en Dev loss: 0.7278 r:0.5867
ne_en Dev loss: 0.4448 r:0.7405
ru_en Dev loss: 0.4072 r:0.7555
Current avg r:0.6090 Best avg r: 0.6165
18:57:43,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:12,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:42,557 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4408
en_de Dev loss: 0.8597 r:0.2169
en_zh Dev loss: 0.6898 r:0.4792
ro_en Dev loss: 0.3206 r:0.8213
et_en Dev loss: 0.3755 r:0.7018
si_en Dev loss: 0.7562 r:0.5915
ne_en Dev loss: 0.4426 r:0.7444
ru_en Dev loss: 0.4257 r:0.7495
Current avg r:0.6149 Best avg r: 0.6165
19:05:11,733 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:06:41,658 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:11,437 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4414
en_de Dev loss: 0.8616 r:0.2153
en_zh Dev loss: 0.7116 r:0.4706
ro_en Dev loss: 0.3303 r:0.8175
et_en Dev loss: 0.3944 r:0.6976
si_en Dev loss: 0.7624 r:0.5860
ne_en Dev loss: 0.3937 r:0.7413
ru_en Dev loss: 0.4012 r:0.7548
Current avg r:0.6119 Best avg r: 0.6165
19:12:39,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:08,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:15:39,86 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4354
en_de Dev loss: 0.8611 r:0.2405
en_zh Dev loss: 0.7277 r:0.4590
ro_en Dev loss: 0.3491 r:0.8189
et_en Dev loss: 0.4011 r:0.6963
si_en Dev loss: 0.6869 r:0.5969
ne_en Dev loss: 0.3787 r:0.7475
ru_en Dev loss: 0.4497 r:0.7339
Current avg r:0.6133 Best avg r: 0.6165
19:20:06,898 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:21:36,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:06,605 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4220
en_de Dev loss: 0.8696 r:0.2306
en_zh Dev loss: 0.7265 r:0.4503
ro_en Dev loss: 0.3191 r:0.8215
et_en Dev loss: 0.3744 r:0.6997
si_en Dev loss: 0.7461 r:0.5964
ne_en Dev loss: 0.4261 r:0.7475
ru_en Dev loss: 0.3989 r:0.7536
Current avg r:0.6142 Best avg r: 0.6165
19:27:34,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:04,238 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:30:34,25 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4235
en_de Dev loss: 0.9096 r:0.2363
en_zh Dev loss: 0.8084 r:0.4401
ro_en Dev loss: 0.3552 r:0.8148
et_en Dev loss: 0.4118 r:0.6893
si_en Dev loss: 0.7929 r:0.5869
ne_en Dev loss: 0.5076 r:0.7374
ru_en Dev loss: 0.5182 r:0.7219
Current avg r:0.6038 Best avg r: 0.6165
19:35:03,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:16,22 root INFO 
id:en_de cur r: 0.2543 best r: 0.2543
19:36:33,105 root INFO 
id:ne_en cur r: 0.7569 best r: 0.7569
19:36:45,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:15,687 root INFO Epoch 3 Global steps: 28000 Train loss: 0.4155
en_de Dev loss: 0.8662 r:0.2463
en_zh Dev loss: 0.7528 r:0.4498
ro_en Dev loss: 0.3428 r:0.8176
et_en Dev loss: 0.3915 r:0.6944
si_en Dev loss: 0.6963 r:0.5962
ne_en Dev loss: 0.4487 r:0.7515
ru_en Dev loss: 0.5034 r:0.7184
Current avg r:0.6106 Best avg r: 0.6165
19:42:43,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:13,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:45:42,988 root INFO Epoch 3 Global steps: 28700 Train loss: 0.4450
en_de Dev loss: 0.8596 r:0.2277
en_zh Dev loss: 0.7343 r:0.4555
ro_en Dev loss: 0.3404 r:0.8179
et_en Dev loss: 0.4047 r:0.6988
si_en Dev loss: 0.6815 r:0.6018
ne_en Dev loss: 0.4197 r:0.7493
ru_en Dev loss: 0.4021 r:0.7521
Current avg r:0.6147 Best avg r: 0.6165
19:50:10,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:51:39,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:09,658 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4147
en_de Dev loss: 0.8734 r:0.2183
en_zh Dev loss: 0.7687 r:0.4430
ro_en Dev loss: 0.3638 r:0.8135
et_en Dev loss: 0.4196 r:0.6883
si_en Dev loss: 0.7597 r:0.5884
ne_en Dev loss: 0.4457 r:0.7486
ru_en Dev loss: 0.4444 r:0.7378
Current avg r:0.6054 Best avg r: 0.6165
19:57:36,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:28,199 root INFO 
id:et_en cur r: 0.7065 best r: 0.7065
19:58:41,58 root INFO 
id:si_en cur r: 0.6224 best r: 0.6224
19:59:06,747 root INFO 
id:ne_en cur r: 0.7594 best r: 0.7594
19:59:19,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:00:49,265 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
20:00:49,272 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
20:00:49,277 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
20:00:49,282 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
20:00:49,291 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
20:00:49,296 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
20:00:49,301 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
20:01:02,156 root INFO Epoch 3 Global steps: 30100 Train loss: 0.3987
en_de Dev loss: 0.8618 r:0.2325
en_zh Dev loss: 0.7137 r:0.4666
ro_en Dev loss: 0.3218 r:0.8216
et_en Dev loss: 0.4131 r:0.7051
si_en Dev loss: 0.6181 r:0.6139
ne_en Dev loss: 0.3783 r:0.7525
ru_en Dev loss: 0.3992 r:0.7554
Current avg r:0.6211 Best avg r: 0.6211
20:05:29,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:59,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:31,45 root INFO Epoch 3 Global steps: 30800 Train loss: 0.4086
en_de Dev loss: 0.8685 r:0.2227
en_zh Dev loss: 0.7632 r:0.4498
ro_en Dev loss: 0.3509 r:0.8155
et_en Dev loss: 0.4157 r:0.6821
si_en Dev loss: 0.7830 r:0.5909
ne_en Dev loss: 0.5068 r:0.7410
ru_en Dev loss: 0.4759 r:0.7346
Current avg r:0.6052 Best avg r: 0.6211
20:12:58,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:14:28,736 root INFO 
id:ne_en cur r: 0.7596 best r: 0.7596
20:14:41,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:11,303 root INFO Epoch 3 Global steps: 31500 Train loss: 0.4138
en_de Dev loss: 0.8524 r:0.2174
en_zh Dev loss: 0.7428 r:0.4544
ro_en Dev loss: 0.3212 r:0.8224
et_en Dev loss: 0.3789 r:0.6947
si_en Dev loss: 0.7217 r:0.6023
ne_en Dev loss: 0.4382 r:0.7570
ru_en Dev loss: 0.3993 r:0.7524
Current avg r:0.6144 Best avg r: 0.6211
20:20:39,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:21:05,525 root INFO 
id:en_zh cur r: 0.4787 best r: 0.4787
20:21:18,370 root INFO 
id:ro_en cur r: 0.8321 best r: 0.8321
20:22:09,717 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:23:39,492 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
20:23:39,498 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
20:23:39,503 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
20:23:39,508 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
20:23:39,513 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
20:23:39,518 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
20:23:39,523 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
20:23:52,362 root INFO Epoch 4 Global steps: 32200 Train loss: 0.3643
en_de Dev loss: 0.8499 r:0.2367
en_zh Dev loss: 0.6881 r:0.4741
ro_en Dev loss: 0.3028 r:0.8272
et_en Dev loss: 0.3941 r:0.7024
si_en Dev loss: 0.5979 r:0.6148
ne_en Dev loss: 0.3718 r:0.7566
ru_en Dev loss: 0.3880 r:0.7547
Current avg r:0.6238 Best avg r: 0.6238
20:28:20,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:29:49,988 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:19,749 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3788
en_de Dev loss: 0.8774 r:0.2224
en_zh Dev loss: 0.7645 r:0.4463
ro_en Dev loss: 0.3412 r:0.8259
et_en Dev loss: 0.4267 r:0.6949
si_en Dev loss: 0.6866 r:0.6045
ne_en Dev loss: 0.4001 r:0.7508
ru_en Dev loss: 0.4585 r:0.7316
Current avg r:0.6109 Best avg r: 0.6238
20:35:49,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:19,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:38:48,941 root INFO Epoch 4 Global steps: 33600 Train loss: 0.3897
en_de Dev loss: 0.8832 r:0.2222
en_zh Dev loss: 0.7904 r:0.4367
ro_en Dev loss: 0.3511 r:0.8201
et_en Dev loss: 0.4107 r:0.6906
si_en Dev loss: 0.7881 r:0.5902
ne_en Dev loss: 0.4028 r:0.7542
ru_en Dev loss: 0.4645 r:0.7314
Current avg r:0.6065 Best avg r: 0.6238
20:43:18,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:48,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:18,442 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3731
en_de Dev loss: 0.8651 r:0.2110
en_zh Dev loss: 0.7282 r:0.4474
ro_en Dev loss: 0.3007 r:0.8255
et_en Dev loss: 0.4082 r:0.6928
si_en Dev loss: 0.6254 r:0.6069
ne_en Dev loss: 0.3731 r:0.7487
ru_en Dev loss: 0.4037 r:0.7441
Current avg r:0.6109 Best avg r: 0.6238
20:50:46,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:16,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:53:45,726 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3683
en_de Dev loss: 0.8678 r:0.2236
en_zh Dev loss: 0.7775 r:0.4486
ro_en Dev loss: 0.3268 r:0.8231
et_en Dev loss: 0.4190 r:0.6907
si_en Dev loss: 0.7228 r:0.5998
ne_en Dev loss: 0.4643 r:0.7459
ru_en Dev loss: 0.4301 r:0.7430
Current avg r:0.6107 Best avg r: 0.6238
20:58:14,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:43,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:01:13,677 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3725
en_de Dev loss: 0.8524 r:0.2195
en_zh Dev loss: 0.7142 r:0.4566
ro_en Dev loss: 0.3140 r:0.8244
et_en Dev loss: 0.4109 r:0.6880
si_en Dev loss: 0.6785 r:0.6080
ne_en Dev loss: 0.4391 r:0.7495
ru_en Dev loss: 0.4307 r:0.7404
Current avg r:0.6123 Best avg r: 0.6238
21:05:42,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:07:12,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:08:41,701 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3875
en_de Dev loss: 0.8781 r:0.2025
en_zh Dev loss: 0.7743 r:0.4469
ro_en Dev loss: 0.3339 r:0.8267
et_en Dev loss: 0.4273 r:0.6785
si_en Dev loss: 0.8869 r:0.5880
ne_en Dev loss: 0.5171 r:0.7465
ru_en Dev loss: 0.4933 r:0.7248
Current avg r:0.6020 Best avg r: 0.6238
21:13:08,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:14:38,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:16:08,353 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3760
en_de Dev loss: 0.8717 r:0.2158
en_zh Dev loss: 0.7671 r:0.4362
ro_en Dev loss: 0.3316 r:0.8230
et_en Dev loss: 0.4247 r:0.6721
si_en Dev loss: 0.8462 r:0.5826
ne_en Dev loss: 0.5620 r:0.7470
ru_en Dev loss: 0.4904 r:0.7226
Current avg r:0.5999 Best avg r: 0.6238
21:20:35,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:22:05,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:23:34,927 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3583
en_de Dev loss: 0.8743 r:0.2114
en_zh Dev loss: 0.7565 r:0.4525
ro_en Dev loss: 0.3427 r:0.8208
et_en Dev loss: 0.4373 r:0.6716
si_en Dev loss: 0.7289 r:0.5863
ne_en Dev loss: 0.4646 r:0.7474
ru_en Dev loss: 0.4823 r:0.7177
Current avg r:0.6011 Best avg r: 0.6238
21:28:03,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:29:33,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:31:03,194 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3806
en_de Dev loss: 0.8585 r:0.2130
en_zh Dev loss: 0.7330 r:0.4453
ro_en Dev loss: 0.3313 r:0.8225
et_en Dev loss: 0.4469 r:0.6743
si_en Dev loss: 0.6765 r:0.5911
ne_en Dev loss: 0.4030 r:0.7421
ru_en Dev loss: 0.4272 r:0.7362
Current avg r:0.6035 Best avg r: 0.6238
21:35:31,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:37:00,852 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:38:30,660 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3622
en_de Dev loss: 0.8515 r:0.2223
en_zh Dev loss: 0.7225 r:0.4583
ro_en Dev loss: 0.3195 r:0.8260
et_en Dev loss: 0.4259 r:0.6815
si_en Dev loss: 0.7164 r:0.5891
ne_en Dev loss: 0.3921 r:0.7525
ru_en Dev loss: 0.4022 r:0.7518
Current avg r:0.6116 Best avg r: 0.6238
21:42:59,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:44:29,491 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:59,249 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3412
en_de Dev loss: 0.8559 r:0.2216
en_zh Dev loss: 0.7768 r:0.4424
ro_en Dev loss: 0.3582 r:0.8286
et_en Dev loss: 0.4215 r:0.6867
si_en Dev loss: 0.7072 r:0.6043
ne_en Dev loss: 0.4153 r:0.7521
ru_en Dev loss: 0.4586 r:0.7390
Current avg r:0.6106 Best avg r: 0.6238
21:50:26,960 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:56,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:26,566 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3233
en_de Dev loss: 0.8543 r:0.2334
en_zh Dev loss: 0.7665 r:0.4396
ro_en Dev loss: 0.3367 r:0.8271
et_en Dev loss: 0.4363 r:0.6822
si_en Dev loss: 0.7484 r:0.5967
ne_en Dev loss: 0.4278 r:0.7461
ru_en Dev loss: 0.4596 r:0.7316
Current avg r:0.6081 Best avg r: 0.6238
21:57:54,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:24,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:53,939 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3295
en_de Dev loss: 0.8610 r:0.2369
en_zh Dev loss: 0.7942 r:0.4218
ro_en Dev loss: 0.3384 r:0.8208
et_en Dev loss: 0.4129 r:0.6725
si_en Dev loss: 0.8700 r:0.5730
ne_en Dev loss: 0.4823 r:0.7435
ru_en Dev loss: 0.4874 r:0.7138
Current avg r:0.5974 Best avg r: 0.6238
22:05:21,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:51,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:08:21,209 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3530
en_de Dev loss: 0.8912 r:0.1935
en_zh Dev loss: 0.7749 r:0.4470
ro_en Dev loss: 0.3452 r:0.8213
et_en Dev loss: 0.4588 r:0.6695
si_en Dev loss: 0.8168 r:0.5790
ne_en Dev loss: 0.4450 r:0.7384
ru_en Dev loss: 0.4940 r:0.7098
Current avg r:0.5941 Best avg r: 0.6238
22:12:48,328 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:18,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:47,791 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3234
en_de Dev loss: 0.8559 r:0.2116
en_zh Dev loss: 0.7921 r:0.4388
ro_en Dev loss: 0.3349 r:0.8224
et_en Dev loss: 0.4955 r:0.6814
si_en Dev loss: 0.6988 r:0.5902
ne_en Dev loss: 0.4621 r:0.7434
ru_en Dev loss: 0.4461 r:0.7204
Current avg r:0.6012 Best avg r: 0.6238
22:20:15,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:46,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:16,394 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3317
en_de Dev loss: 0.8739 r:0.2132
en_zh Dev loss: 0.8284 r:0.3999
ro_en Dev loss: 0.3475 r:0.8192
et_en Dev loss: 0.4513 r:0.6696
si_en Dev loss: 0.7709 r:0.5766
ne_en Dev loss: 0.4751 r:0.7456
ru_en Dev loss: 0.4992 r:0.7022
Current avg r:0.5895 Best avg r: 0.6238
22:27:44,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:14,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:45,264 root INFO Epoch 5 Global steps: 44100 Train loss: 0.3312
en_de Dev loss: 0.8686 r:0.2158
en_zh Dev loss: 0.7836 r:0.4135
ro_en Dev loss: 0.3158 r:0.8269
et_en Dev loss: 0.4099 r:0.6800
si_en Dev loss: 0.7094 r:0.5928
ne_en Dev loss: 0.4010 r:0.7486
ru_en Dev loss: 0.4650 r:0.7195
Current avg r:0.5996 Best avg r: 0.6238
22:35:13,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:43,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:13,582 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3214
en_de Dev loss: 0.8705 r:0.1781
en_zh Dev loss: 0.7804 r:0.4228
ro_en Dev loss: 0.3221 r:0.8221
et_en Dev loss: 0.4645 r:0.6716
si_en Dev loss: 0.7026 r:0.5883
ne_en Dev loss: 0.4176 r:0.7373
ru_en Dev loss: 0.4614 r:0.7116
Current avg r:0.5903 Best avg r: 0.6238
22:42:41,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:11,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:41,143 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3286
en_de Dev loss: 0.9216 r:0.1819
en_zh Dev loss: 0.8511 r:0.4203
ro_en Dev loss: 0.3645 r:0.8244
et_en Dev loss: 0.4607 r:0.6696
si_en Dev loss: 0.7929 r:0.5856
ne_en Dev loss: 0.4996 r:0.7320
ru_en Dev loss: 0.4885 r:0.7241
Current avg r:0.5911 Best avg r: 0.6238
22:50:09,521 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:39,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:08,809 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3411
en_de Dev loss: 0.8994 r:0.2139
en_zh Dev loss: 0.8608 r:0.4004
ro_en Dev loss: 0.3961 r:0.8176
et_en Dev loss: 0.4756 r:0.6540
si_en Dev loss: 0.9536 r:0.5711
ne_en Dev loss: 0.6472 r:0.7377
ru_en Dev loss: 0.5694 r:0.6830
Current avg r:0.5825 Best avg r: 0.6238
22:57:35,685 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:06,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:37,947 root INFO Epoch 5 Global steps: 46900 Train loss: 0.3254
en_de Dev loss: 0.8689 r:0.2116
en_zh Dev loss: 0.7716 r:0.4466
ro_en Dev loss: 0.3383 r:0.8225
et_en Dev loss: 0.4512 r:0.6721
si_en Dev loss: 0.7565 r:0.5904
ne_en Dev loss: 0.4624 r:0.7435
ru_en Dev loss: 0.4316 r:0.7341
Current avg r:0.6030 Best avg r: 0.6238
23:05:04,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:34,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:03,991 root INFO Epoch 5 Global steps: 47600 Train loss: 0.2916
en_de Dev loss: 0.8890 r:0.2172
en_zh Dev loss: 0.7989 r:0.4371
ro_en Dev loss: 0.3675 r:0.8161
et_en Dev loss: 0.4795 r:0.6588
si_en Dev loss: 0.7675 r:0.5800
ne_en Dev loss: 0.4585 r:0.7405
ru_en Dev loss: 0.4818 r:0.7167
Current avg r:0.5952 Best avg r: 0.6238
23:12:31,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:01,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:30,991 root INFO Epoch 6 Global steps: 48300 Train loss: 0.2972
en_de Dev loss: 0.8786 r:0.2063
en_zh Dev loss: 0.7963 r:0.4324
ro_en Dev loss: 0.3528 r:0.8240
et_en Dev loss: 0.4787 r:0.6717
si_en Dev loss: 0.7906 r:0.5828
ne_en Dev loss: 0.4126 r:0.7450
ru_en Dev loss: 0.4601 r:0.7223
Current avg r:0.5978 Best avg r: 0.6238
23:20:00,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:29,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:59,511 root INFO Epoch 6 Global steps: 49000 Train loss: 0.3047
en_de Dev loss: 0.8943 r:0.2052
en_zh Dev loss: 0.8088 r:0.4373
ro_en Dev loss: 0.3796 r:0.8208
et_en Dev loss: 0.4972 r:0.6640
si_en Dev loss: 0.8525 r:0.5766
ne_en Dev loss: 0.4937 r:0.7368
ru_en Dev loss: 0.4892 r:0.7180
Current avg r:0.5941 Best avg r: 0.6238
23:27:26,104 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:55,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:25,372 root INFO Epoch 6 Global steps: 49700 Train loss: 0.3032
en_de Dev loss: 0.8701 r:0.1967
en_zh Dev loss: 0.7857 r:0.4210
ro_en Dev loss: 0.3024 r:0.8238
et_en Dev loss: 0.4257 r:0.6782
si_en Dev loss: 0.7223 r:0.5849
ne_en Dev loss: 0.4221 r:0.7298
ru_en Dev loss: 0.4451 r:0.7297
Current avg r:0.5949 Best avg r: 0.6238
23:34:52,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:21,798 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:51,420 root INFO Epoch 6 Global steps: 50400 Train loss: 0.2740
en_de Dev loss: 0.8773 r:0.1970
en_zh Dev loss: 0.7891 r:0.4370
ro_en Dev loss: 0.3568 r:0.8225
et_en Dev loss: 0.4612 r:0.6722
si_en Dev loss: 0.8124 r:0.5783
ne_en Dev loss: 0.4975 r:0.7357
ru_en Dev loss: 0.4556 r:0.7313
Current avg r:0.5963 Best avg r: 0.6238
23:42:18,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:47,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:17,500 root INFO Epoch 6 Global steps: 51100 Train loss: 0.2740
en_de Dev loss: 0.9267 r:0.1689
en_zh Dev loss: 0.8455 r:0.4223
ro_en Dev loss: 0.3639 r:0.8241
et_en Dev loss: 0.4864 r:0.6683
si_en Dev loss: 0.8324 r:0.5791
ne_en Dev loss: 0.5128 r:0.7325
ru_en Dev loss: 0.4843 r:0.7271
Current avg r:0.5889 Best avg r: 0.6238
23:49:45,613 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:15,250 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:44,873 root INFO Epoch 6 Global steps: 51800 Train loss: 0.2810
en_de Dev loss: 0.8900 r:0.1816
en_zh Dev loss: 0.8260 r:0.4123
ro_en Dev loss: 0.3617 r:0.8203
et_en Dev loss: 0.4823 r:0.6545
si_en Dev loss: 0.8878 r:0.5594
ne_en Dev loss: 0.5153 r:0.7332
ru_en Dev loss: 0.4916 r:0.7120
Current avg r:0.5819 Best avg r: 0.6238
23:57:11,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:41,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:11,35 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2872
en_de Dev loss: 0.9007 r:0.1909
en_zh Dev loss: 0.8359 r:0.4307
ro_en Dev loss: 0.3817 r:0.8161
et_en Dev loss: 0.4960 r:0.6549
si_en Dev loss: 0.9080 r:0.5537
ne_en Dev loss: 0.5761 r:0.7231
ru_en Dev loss: 0.5141 r:0.7130
Current avg r:0.5832 Best avg r: 0.6238
00:04:37,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:06:07,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:37,147 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2894
en_de Dev loss: 0.8757 r:0.2059
en_zh Dev loss: 0.7843 r:0.4407
ro_en Dev loss: 0.3724 r:0.8171
et_en Dev loss: 0.4634 r:0.6651
si_en Dev loss: 0.8328 r:0.5751
ne_en Dev loss: 0.5213 r:0.7309
ru_en Dev loss: 0.4900 r:0.7241
Current avg r:0.5941 Best avg r: 0.6238
00:12:03,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:33,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:02,758 root INFO Epoch 6 Global steps: 53900 Train loss: 0.2796
en_de Dev loss: 0.8932 r:0.1829
en_zh Dev loss: 0.8199 r:0.4216
ro_en Dev loss: 0.3409 r:0.8206
et_en Dev loss: 0.4644 r:0.6689
si_en Dev loss: 0.8381 r:0.5691
ne_en Dev loss: 0.4831 r:0.7336
ru_en Dev loss: 0.4781 r:0.7173
Current avg r:0.5877 Best avg r: 0.6238
00:19:30,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:59,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:29,493 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2895
en_de Dev loss: 0.8810 r:0.1886
en_zh Dev loss: 0.7934 r:0.4266
ro_en Dev loss: 0.3334 r:0.8205
et_en Dev loss: 0.4629 r:0.6723
si_en Dev loss: 0.7788 r:0.5815
ne_en Dev loss: 0.4625 r:0.7358
ru_en Dev loss: 0.4536 r:0.7299
Current avg r:0.5936 Best avg r: 0.6238
00:26:57,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:29,205 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:59,63 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2732
en_de Dev loss: 0.8842 r:0.1888
en_zh Dev loss: 0.7594 r:0.4429
ro_en Dev loss: 0.3386 r:0.8187
et_en Dev loss: 0.4503 r:0.6766
si_en Dev loss: 0.7602 r:0.5808
ne_en Dev loss: 0.4698 r:0.7299
ru_en Dev loss: 0.4271 r:0.7324
Current avg r:0.5957 Best avg r: 0.6238
00:34:28,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:58,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:28,211 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2594
en_de Dev loss: 0.8892 r:0.1809
en_zh Dev loss: 0.7819 r:0.4414
ro_en Dev loss: 0.3489 r:0.8234
et_en Dev loss: 0.4664 r:0.6656
si_en Dev loss: 0.8552 r:0.5719
ne_en Dev loss: 0.5030 r:0.7301
ru_en Dev loss: 0.4243 r:0.7403
Current avg r:0.5934 Best avg r: 0.6238
00:41:56,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:26,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:56,193 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2480
en_de Dev loss: 0.9021 r:0.1803
en_zh Dev loss: 0.8126 r:0.4330
ro_en Dev loss: 0.3536 r:0.8223
et_en Dev loss: 0.4804 r:0.6676
si_en Dev loss: 0.8374 r:0.5728
ne_en Dev loss: 0.5167 r:0.7311
ru_en Dev loss: 0.4497 r:0.7391
Current avg r:0.5923 Best avg r: 0.6238
00:49:24,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:54,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:23,513 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2624
en_de Dev loss: 0.8823 r:0.1832
en_zh Dev loss: 0.7915 r:0.4281
ro_en Dev loss: 0.3401 r:0.8203
et_en Dev loss: 0.4722 r:0.6630
si_en Dev loss: 0.7633 r:0.5722
ne_en Dev loss: 0.4385 r:0.7317
ru_en Dev loss: 0.4495 r:0.7297
Current avg r:0.5897 Best avg r: 0.6238
00:56:49,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:19,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:48,607 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2696
en_de Dev loss: 0.8825 r:0.1826
en_zh Dev loss: 0.8033 r:0.4130
ro_en Dev loss: 0.3598 r:0.8131
et_en Dev loss: 0.4784 r:0.6439
si_en Dev loss: 0.8718 r:0.5504
ne_en Dev loss: 0.5593 r:0.7245
ru_en Dev loss: 0.4866 r:0.7050
Current avg r:0.5761 Best avg r: 0.6238
01:04:14,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:44,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:13,659 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2740
en_de Dev loss: 0.9392 r:0.1674
en_zh Dev loss: 0.8614 r:0.4084
ro_en Dev loss: 0.4068 r:0.8136
et_en Dev loss: 0.5289 r:0.6455
si_en Dev loss: 0.9118 r:0.5574
ne_en Dev loss: 0.5366 r:0.7284
ru_en Dev loss: 0.5416 r:0.7023
Current avg r:0.5747 Best avg r: 0.6238
01:11:39,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:09,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:38,653 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2463
en_de Dev loss: 0.9389 r:0.1530
en_zh Dev loss: 0.9070 r:0.3994
ro_en Dev loss: 0.4015 r:0.8157
et_en Dev loss: 0.5072 r:0.6519
si_en Dev loss: 0.9618 r:0.5621
ne_en Dev loss: 0.6063 r:0.7268
ru_en Dev loss: 0.5480 r:0.7055
Current avg r:0.5735 Best avg r: 0.6238
01:19:04,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:20:34,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:22:03,641 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2531
en_de Dev loss: 0.8942 r:0.1724
en_zh Dev loss: 0.8058 r:0.4265
ro_en Dev loss: 0.3544 r:0.8198
et_en Dev loss: 0.4581 r:0.6621
si_en Dev loss: 0.8437 r:0.5712
ne_en Dev loss: 0.5809 r:0.7286
ru_en Dev loss: 0.4240 r:0.7423
Current avg r:0.5890 Best avg r: 0.6238
01:26:29,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:27:59,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:29:28,688 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2362
en_de Dev loss: 0.8917 r:0.1942
en_zh Dev loss: 0.8184 r:0.4341
ro_en Dev loss: 0.3618 r:0.8186
et_en Dev loss: 0.4652 r:0.6683
si_en Dev loss: 0.7776 r:0.5744
ne_en Dev loss: 0.5455 r:0.7241
ru_en Dev loss: 0.4502 r:0.7328
Current avg r:0.5923 Best avg r: 0.6238
01:33:54,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:24,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:36:53,769 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2428
en_de Dev loss: 0.9258 r:0.1744
en_zh Dev loss: 0.8804 r:0.4203
ro_en Dev loss: 0.4195 r:0.8178
et_en Dev loss: 0.4937 r:0.6540
si_en Dev loss: 0.9312 r:0.5646
ne_en Dev loss: 0.5932 r:0.7260
ru_en Dev loss: 0.5051 r:0.7271
Current avg r:0.5835 Best avg r: 0.6238
01:41:20,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:42:49,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:44:18,841 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2464
en_de Dev loss: 0.8960 r:0.1664
en_zh Dev loss: 0.8671 r:0.4054
ro_en Dev loss: 0.3868 r:0.8175
et_en Dev loss: 0.4951 r:0.6477
si_en Dev loss: 0.9320 r:0.5556
ne_en Dev loss: 0.5448 r:0.7245
ru_en Dev loss: 0.4996 r:0.7138
Current avg r:0.5758 Best avg r: 0.6238
01:48:52,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:23,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:51:54,659 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2485
en_de Dev loss: 0.8858 r:0.1973
en_zh Dev loss: 0.8257 r:0.4129
ro_en Dev loss: 0.3592 r:0.8194
et_en Dev loss: 0.4648 r:0.6548
si_en Dev loss: 0.8011 r:0.5680
ne_en Dev loss: 0.4817 r:0.7226
ru_en Dev loss: 0.4728 r:0.7207
Current avg r:0.5851 Best avg r: 0.6238
01:56:27,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:58,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:29,908 root INFO Epoch 7 Global steps: 63700 Train loss: 0.2401
en_de Dev loss: 0.8938 r:0.1734
en_zh Dev loss: 0.8086 r:0.4303
ro_en Dev loss: 0.3530 r:0.8202
et_en Dev loss: 0.4497 r:0.6621
si_en Dev loss: 0.9116 r:0.5631
ne_en Dev loss: 0.5532 r:0.7256
ru_en Dev loss: 0.4813 r:0.7224
Current avg r:0.5853 Best avg r: 0.6238
02:04:04,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:36,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:08,505 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2301
en_de Dev loss: 0.9028 r:0.1626
en_zh Dev loss: 0.7877 r:0.4259
ro_en Dev loss: 0.3338 r:0.8224
et_en Dev loss: 0.4874 r:0.6577
si_en Dev loss: 0.8053 r:0.5642
ne_en Dev loss: 0.4856 r:0.7237
ru_en Dev loss: 0.4308 r:0.7360
Current avg r:0.5846 Best avg r: 0.6238
02:11:41,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:12,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:43,802 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2278
en_de Dev loss: 0.9171 r:0.1456
en_zh Dev loss: 0.8439 r:0.3988
ro_en Dev loss: 0.3546 r:0.8152
et_en Dev loss: 0.4763 r:0.6490
si_en Dev loss: 0.8576 r:0.5521
ne_en Dev loss: 0.5406 r:0.7189
ru_en Dev loss: 0.4549 r:0.7292
Current avg r:0.5727 Best avg r: 0.6238
02:19:15,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:45,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:14,887 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2289
en_de Dev loss: 0.9115 r:0.1755
en_zh Dev loss: 0.8391 r:0.4153
ro_en Dev loss: 0.3645 r:0.8217
et_en Dev loss: 0.4959 r:0.6573
si_en Dev loss: 0.8229 r:0.5579
ne_en Dev loss: 0.4740 r:0.7166
ru_en Dev loss: 0.4704 r:0.7276
Current avg r:0.5817 Best avg r: 0.6238
02:26:44,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:28:14,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:43,925 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2423
en_de Dev loss: 0.9130 r:0.1813
en_zh Dev loss: 0.8752 r:0.4069
ro_en Dev loss: 0.3777 r:0.8122
et_en Dev loss: 0.4950 r:0.6512
si_en Dev loss: 0.8409 r:0.5547
ne_en Dev loss: 0.5377 r:0.7176
ru_en Dev loss: 0.5031 r:0.7125
Current avg r:0.5766 Best avg r: 0.6238
02:34:14,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:47,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:37:17,420 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2246
en_de Dev loss: 0.9179 r:0.1847
en_zh Dev loss: 0.8580 r:0.4120
ro_en Dev loss: 0.3737 r:0.8127
et_en Dev loss: 0.4976 r:0.6451
si_en Dev loss: 0.9455 r:0.5506
ne_en Dev loss: 0.5990 r:0.7201
ru_en Dev loss: 0.4573 r:0.7306
Current avg r:0.5794 Best avg r: 0.6238
02:41:46,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:16,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:46,816 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2168
en_de Dev loss: 0.9120 r:0.1948
en_zh Dev loss: 0.8291 r:0.4317
ro_en Dev loss: 0.3809 r:0.8169
et_en Dev loss: 0.5049 r:0.6517
si_en Dev loss: 0.8399 r:0.5634
ne_en Dev loss: 0.4918 r:0.7175
ru_en Dev loss: 0.4756 r:0.7298
Current avg r:0.5866 Best avg r: 0.6238
02:49:15,702 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:45,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:15,816 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2217
en_de Dev loss: 0.9200 r:0.1802
en_zh Dev loss: 0.8445 r:0.4149
ro_en Dev loss: 0.3810 r:0.8135
et_en Dev loss: 0.4768 r:0.6521
si_en Dev loss: 0.8958 r:0.5555
ne_en Dev loss: 0.5556 r:0.7190
ru_en Dev loss: 0.4823 r:0.7249
Current avg r:0.5800 Best avg r: 0.6238
02:56:46,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:58:16,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:59:46,325 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2172
en_de Dev loss: 0.8879 r:0.1806
en_zh Dev loss: 0.7645 r:0.4424
ro_en Dev loss: 0.3310 r:0.8207
et_en Dev loss: 0.5046 r:0.6617
si_en Dev loss: 0.7192 r:0.5732
ne_en Dev loss: 0.4827 r:0.7150
ru_en Dev loss: 0.4244 r:0.7326
Current avg r:0.5895 Best avg r: 0.6238
03:04:16,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:05:46,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:07:16,605 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2211
en_de Dev loss: 0.9235 r:0.1699
en_zh Dev loss: 0.8525 r:0.4267
ro_en Dev loss: 0.3758 r:0.8172
et_en Dev loss: 0.5124 r:0.6518
si_en Dev loss: 0.9028 r:0.5573
ne_en Dev loss: 0.5751 r:0.7101
ru_en Dev loss: 0.5064 r:0.7212
Current avg r:0.5792 Best avg r: 0.6238
03:11:46,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:16,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:45,957 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2320
en_de Dev loss: 0.9204 r:0.1713
en_zh Dev loss: 0.8114 r:0.4296
ro_en Dev loss: 0.3462 r:0.8176
et_en Dev loss: 0.4837 r:0.6514
si_en Dev loss: 0.8664 r:0.5595
ne_en Dev loss: 0.5524 r:0.7126
ru_en Dev loss: 0.4803 r:0.7126
Current avg r:0.5792 Best avg r: 0.6238
03:19:14,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:20:44,172 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:13,925 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2283
en_de Dev loss: 0.9260 r:0.1781
en_zh Dev loss: 0.8135 r:0.4359
ro_en Dev loss: 0.3418 r:0.8193
et_en Dev loss: 0.5268 r:0.6614
si_en Dev loss: 0.7375 r:0.5719
ne_en Dev loss: 0.4929 r:0.7049
ru_en Dev loss: 0.4575 r:0.7220
Current avg r:0.5848 Best avg r: 0.6238
03:26:42,603 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:12,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:29:42,274 root INFO Epoch 9 Global steps: 72100 Train loss: 0.2104
en_de Dev loss: 0.9075 r:0.1744
en_zh Dev loss: 0.8224 r:0.4275
ro_en Dev loss: 0.3566 r:0.8187
et_en Dev loss: 0.5189 r:0.6521
si_en Dev loss: 0.8203 r:0.5605
ne_en Dev loss: 0.5165 r:0.7124
ru_en Dev loss: 0.4554 r:0.7294
Current avg r:0.5821 Best avg r: 0.6238
03:34:13,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:43,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:37:14,483 root INFO Epoch 9 Global steps: 72800 Train loss: 0.1983
en_de Dev loss: 0.8991 r:0.1824
en_zh Dev loss: 0.8382 r:0.4145
ro_en Dev loss: 0.3473 r:0.8163
et_en Dev loss: 0.4802 r:0.6454
si_en Dev loss: 0.8036 r:0.5544
ne_en Dev loss: 0.5344 r:0.7149
ru_en Dev loss: 0.5022 r:0.7083
Current avg r:0.5766 Best avg r: 0.6238
03:41:47,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:18,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:44:49,565 root INFO Epoch 9 Global steps: 73500 Train loss: 0.2096
en_de Dev loss: 0.8973 r:0.1780
en_zh Dev loss: 0.7966 r:0.4366
ro_en Dev loss: 0.3479 r:0.8182
et_en Dev loss: 0.5075 r:0.6440
si_en Dev loss: 0.7913 r:0.5627
ne_en Dev loss: 0.5207 r:0.7164
ru_en Dev loss: 0.4776 r:0.7190
Current avg r:0.5821 Best avg r: 0.6238
03:49:23,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:50:55,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:26,58 root INFO Epoch 9 Global steps: 74200 Train loss: 0.2073
en_de Dev loss: 0.8958 r:0.1561
en_zh Dev loss: 0.7956 r:0.4262
ro_en Dev loss: 0.3457 r:0.8205
et_en Dev loss: 0.4818 r:0.6513
si_en Dev loss: 0.8515 r:0.5531
ne_en Dev loss: 0.5804 r:0.7102
ru_en Dev loss: 0.4797 r:0.7154
Current avg r:0.5761 Best avg r: 0.6238
03:56:58,642 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:58:29,336 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:59:59,939 root INFO Epoch 9 Global steps: 74900 Train loss: 0.2065
en_de Dev loss: 0.9318 r:0.1686
en_zh Dev loss: 0.8215 r:0.4277
ro_en Dev loss: 0.3608 r:0.8206
et_en Dev loss: 0.5036 r:0.6453
si_en Dev loss: 0.8861 r:0.5560
ne_en Dev loss: 0.5311 r:0.7114
ru_en Dev loss: 0.4855 r:0.7175
Current avg r:0.5782 Best avg r: 0.6238
04:04:30,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:06:00,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:07:31,336 root INFO Epoch 9 Global steps: 75600 Train loss: 0.2033
en_de Dev loss: 0.8922 r:0.1903
en_zh Dev loss: 0.7942 r:0.4292
ro_en Dev loss: 0.3239 r:0.8242
et_en Dev loss: 0.4958 r:0.6415
si_en Dev loss: 0.7774 r:0.5591
ne_en Dev loss: 0.5068 r:0.7143
ru_en Dev loss: 0.4264 r:0.7349
Current avg r:0.5848 Best avg r: 0.6238
04:11:58,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:13:28,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:14:58,496 root INFO Epoch 9 Global steps: 76300 Train loss: 0.1925
en_de Dev loss: 0.9053 r:0.1957
en_zh Dev loss: 0.8231 r:0.4369
ro_en Dev loss: 0.3472 r:0.8202
et_en Dev loss: 0.5074 r:0.6488
si_en Dev loss: 0.8569 r:0.5453
ne_en Dev loss: 0.5377 r:0.7107
ru_en Dev loss: 0.4791 r:0.7269
Current avg r:0.5835 Best avg r: 0.6238
04:19:25,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:20:55,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:22:25,550 root INFO Epoch 9 Global steps: 77000 Train loss: 0.2072
en_de Dev loss: 0.8963 r:0.1739
en_zh Dev loss: 0.7797 r:0.4412
ro_en Dev loss: 0.3495 r:0.8190
et_en Dev loss: 0.4957 r:0.6387
si_en Dev loss: 0.9012 r:0.5431
ne_en Dev loss: 0.5363 r:0.7110
ru_en Dev loss: 0.4679 r:0.7288
Current avg r:0.5794 Best avg r: 0.6238
04:26:54,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:28:24,119 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:29:53,978 root INFO Epoch 9 Global steps: 77700 Train loss: 0.2070
en_de Dev loss: 0.9332 r:0.1706
en_zh Dev loss: 0.8148 r:0.4495
ro_en Dev loss: 0.3738 r:0.8202
et_en Dev loss: 0.5329 r:0.6501
si_en Dev loss: 0.8439 r:0.5543
ne_en Dev loss: 0.5220 r:0.7102
ru_en Dev loss: 0.4763 r:0.7313
Current avg r:0.5837 Best avg r: 0.6238
04:34:21,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:35:51,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:22,278 root INFO Epoch 9 Global steps: 78400 Train loss: 0.1969
en_de Dev loss: 0.9204 r:0.1834
en_zh Dev loss: 0.7992 r:0.4555
ro_en Dev loss: 0.3674 r:0.8198
et_en Dev loss: 0.5236 r:0.6499
si_en Dev loss: 0.8937 r:0.5424
ne_en Dev loss: 0.5461 r:0.7144
ru_en Dev loss: 0.4525 r:0.7321
Current avg r:0.5854 Best avg r: 0.6238
04:41:54,700 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:26,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:57,516 root INFO Epoch 9 Global steps: 79100 Train loss: 0.2018
en_de Dev loss: 0.9139 r:0.1821
en_zh Dev loss: 0.8228 r:0.4415
ro_en Dev loss: 0.3721 r:0.8192
et_en Dev loss: 0.5141 r:0.6382
si_en Dev loss: 0.8681 r:0.5488
ne_en Dev loss: 0.5511 r:0.7159
ru_en Dev loss: 0.4852 r:0.7287
Current avg r:0.5820 Best avg r: 0.6238
04:49:32,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:51:03,232 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:52:34,247 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1857
en_de Dev loss: 0.8888 r:0.1891
en_zh Dev loss: 0.7791 r:0.4524
ro_en Dev loss: 0.3515 r:0.8221
et_en Dev loss: 0.4911 r:0.6511
si_en Dev loss: 0.8361 r:0.5632
ne_en Dev loss: 0.5014 r:0.7183
ru_en Dev loss: 0.4633 r:0.7333
Current avg r:0.5899 Best avg r: 0.6238
04:57:07,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:58:38,537 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:00:10,719 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1760
en_de Dev loss: 0.8798 r:0.2017
en_zh Dev loss: 0.8419 r:0.4346
ro_en Dev loss: 0.3560 r:0.8223
et_en Dev loss: 0.4921 r:0.6512
si_en Dev loss: 0.9034 r:0.5494
ne_en Dev loss: 0.5913 r:0.7094
ru_en Dev loss: 0.5114 r:0.7138
Current avg r:0.5832 Best avg r: 0.6238
05:04:41,845 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:12,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:07:43,200 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1813
en_de Dev loss: 0.9235 r:0.1896
en_zh Dev loss: 0.8835 r:0.4407
ro_en Dev loss: 0.3990 r:0.8182
et_en Dev loss: 0.5515 r:0.6426
si_en Dev loss: 0.9720 r:0.5411
ne_en Dev loss: 0.5924 r:0.7039
ru_en Dev loss: 0.5239 r:0.7235
Current avg r:0.5800 Best avg r: 0.6238
05:12:11,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:13:41,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:11,692 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1845
en_de Dev loss: 0.9463 r:0.2012
en_zh Dev loss: 0.9496 r:0.4210
ro_en Dev loss: 0.4230 r:0.8127
et_en Dev loss: 0.5573 r:0.6261
si_en Dev loss: 1.0040 r:0.5327
ne_en Dev loss: 0.7236 r:0.6938
ru_en Dev loss: 0.5752 r:0.7017
Current avg r:0.5699 Best avg r: 0.6238
05:19:39,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:21:08,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:22:38,759 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1811
en_de Dev loss: 0.9204 r:0.1763
en_zh Dev loss: 0.8438 r:0.4225
ro_en Dev loss: 0.3552 r:0.8204
et_en Dev loss: 0.5128 r:0.6481
si_en Dev loss: 0.9004 r:0.5381
ne_en Dev loss: 0.5812 r:0.6987
ru_en Dev loss: 0.4561 r:0.7356
Current avg r:0.5771 Best avg r: 0.6238
05:27:06,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:35,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:05,777 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1830
en_de Dev loss: 0.8996 r:0.1825
en_zh Dev loss: 0.7912 r:0.4414
ro_en Dev loss: 0.3491 r:0.8181
et_en Dev loss: 0.5208 r:0.6403
si_en Dev loss: 0.8825 r:0.5423
ne_en Dev loss: 0.5760 r:0.7006
ru_en Dev loss: 0.4587 r:0.7278
Current avg r:0.5790 Best avg r: 0.6238
05:34:33,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:03,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:37:33,738 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1808
en_de Dev loss: 0.9268 r:0.1679
en_zh Dev loss: 0.7601 r:0.4599
ro_en Dev loss: 0.3449 r:0.8204
et_en Dev loss: 0.4941 r:0.6486
si_en Dev loss: 0.8403 r:0.5476
ne_en Dev loss: 0.5486 r:0.7062
ru_en Dev loss: 0.4599 r:0.7331
Current avg r:0.5834 Best avg r: 0.6238
05:42:04,788 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:35,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:06,374 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1816
en_de Dev loss: 0.9293 r:0.1799
en_zh Dev loss: 0.7773 r:0.4613
ro_en Dev loss: 0.3370 r:0.8224
et_en Dev loss: 0.5135 r:0.6559
si_en Dev loss: 0.7767 r:0.5596
ne_en Dev loss: 0.4938 r:0.7132
ru_en Dev loss: 0.4368 r:0.7351
Current avg r:0.5896 Best avg r: 0.6238
05:49:37,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:08,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:52:38,754 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1790
en_de Dev loss: 0.9006 r:0.1676
en_zh Dev loss: 0.7838 r:0.4527
ro_en Dev loss: 0.3366 r:0.8224
et_en Dev loss: 0.4713 r:0.6576
si_en Dev loss: 0.8057 r:0.5618
ne_en Dev loss: 0.5450 r:0.7109
ru_en Dev loss: 0.4588 r:0.7344
Current avg r:0.5868 Best avg r: 0.6238
05:57:09,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:58:40,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:00:10,391 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1762
en_de Dev loss: 0.9329 r:0.1527
en_zh Dev loss: 0.8308 r:0.4402
ro_en Dev loss: 0.3456 r:0.8218
et_en Dev loss: 0.5159 r:0.6422
si_en Dev loss: 0.8576 r:0.5515
ne_en Dev loss: 0.6295 r:0.7084
ru_en Dev loss: 0.4888 r:0.7214
Current avg r:0.5769 Best avg r: 0.6238
06:04:40,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:06:10,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:07:41,669 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1791
en_de Dev loss: 0.9303 r:0.1431
en_zh Dev loss: 0.8104 r:0.4365
ro_en Dev loss: 0.3265 r:0.8244
et_en Dev loss: 0.4765 r:0.6447
si_en Dev loss: 0.8200 r:0.5524
ne_en Dev loss: 0.5649 r:0.7012
ru_en Dev loss: 0.4546 r:0.7336
Current avg r:0.5766 Best avg r: 0.6238
06:12:11,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:13:42,669 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:13,339 root INFO Epoch 10 Global steps: 87500 Train loss: 0.1762
en_de Dev loss: 0.9329 r:0.1502
en_zh Dev loss: 0.8131 r:0.4449
ro_en Dev loss: 0.3383 r:0.8232
et_en Dev loss: 0.4698 r:0.6586
si_en Dev loss: 0.8587 r:0.5550
ne_en Dev loss: 0.5939 r:0.7066
ru_en Dev loss: 0.4558 r:0.7385
Current avg r:0.5824 Best avg r: 0.6238
06:19:45,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:21:16,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:22:47,104 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1625
en_de Dev loss: 0.9352 r:0.1692
en_zh Dev loss: 0.8499 r:0.4365
ro_en Dev loss: 0.3610 r:0.8213
et_en Dev loss: 0.4983 r:0.6535
si_en Dev loss: 0.8894 r:0.5499
ne_en Dev loss: 0.5995 r:0.6974
ru_en Dev loss: 0.4705 r:0.7346
Current avg r:0.5803 Best avg r: 0.6238
06:27:16,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:28:47,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:18,216 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1685
en_de Dev loss: 0.9198 r:0.1523
en_zh Dev loss: 0.7938 r:0.4354
ro_en Dev loss: 0.3621 r:0.8160
et_en Dev loss: 0.4772 r:0.6464
si_en Dev loss: 0.9390 r:0.5422
ne_en Dev loss: 0.6601 r:0.7042
ru_en Dev loss: 0.4612 r:0.7291
Current avg r:0.5751 Best avg r: 0.6238
06:34:48,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:19,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:50,5 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1657
en_de Dev loss: 0.9351 r:0.1765
en_zh Dev loss: 0.8298 r:0.4424
ro_en Dev loss: 0.3643 r:0.8197
et_en Dev loss: 0.5208 r:0.6512
si_en Dev loss: 0.8602 r:0.5540
ne_en Dev loss: 0.5723 r:0.7044
ru_en Dev loss: 0.4544 r:0.7456
Current avg r:0.5848 Best avg r: 0.6238
06:42:20,550 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:43:51,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:21,915 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1565
en_de Dev loss: 0.9451 r:0.1554
en_zh Dev loss: 0.8076 r:0.4369
ro_en Dev loss: 0.3555 r:0.8227
et_en Dev loss: 0.5012 r:0.6450
si_en Dev loss: 0.9197 r:0.5485
ne_en Dev loss: 0.6068 r:0.7046
ru_en Dev loss: 0.4946 r:0.7286
Current avg r:0.5774 Best avg r: 0.6238
06:49:51,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:21,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:52:51,602 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1596
en_de Dev loss: 0.9184 r:0.1512
en_zh Dev loss: 0.7994 r:0.4374
ro_en Dev loss: 0.3273 r:0.8227
et_en Dev loss: 0.4981 r:0.6466
si_en Dev loss: 0.8068 r:0.5525
ne_en Dev loss: 0.5210 r:0.7084
ru_en Dev loss: 0.4842 r:0.7223
Current avg r:0.5773 Best avg r: 0.6238
06:57:19,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:58:48,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:00:18,898 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1564
en_de Dev loss: 0.9578 r:0.1545
en_zh Dev loss: 0.8097 r:0.4465
ro_en Dev loss: 0.3449 r:0.8232
et_en Dev loss: 0.5203 r:0.6522
si_en Dev loss: 0.7484 r:0.5623
ne_en Dev loss: 0.5100 r:0.7057
ru_en Dev loss: 0.4561 r:0.7381
Current avg r:0.5832 Best avg r: 0.6238
07:04:46,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:06:16,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:07:46,393 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1574
en_de Dev loss: 0.9577 r:0.1493
en_zh Dev loss: 0.8232 r:0.4431
ro_en Dev loss: 0.3799 r:0.8140
et_en Dev loss: 0.5311 r:0.6319
si_en Dev loss: 0.9467 r:0.5346
ne_en Dev loss: 0.6593 r:0.7052
ru_en Dev loss: 0.4753 r:0.7340
Current avg r:0.5732 Best avg r: 0.6238
07:12:17,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:48,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:19,312 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1639
en_de Dev loss: 0.9665 r:0.1650
en_zh Dev loss: 0.8416 r:0.4379
ro_en Dev loss: 0.3611 r:0.8188
et_en Dev loss: 0.5396 r:0.6420
si_en Dev loss: 0.8244 r:0.5528
ne_en Dev loss: 0.5532 r:0.7043
ru_en Dev loss: 0.4404 r:0.7483
Current avg r:0.5813 Best avg r: 0.6238
07:19:52,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:21:23,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:22:54,771 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1574
en_de Dev loss: 0.9453 r:0.1396
en_zh Dev loss: 0.8429 r:0.4226
ro_en Dev loss: 0.3512 r:0.8160
et_en Dev loss: 0.5215 r:0.6412
si_en Dev loss: 0.8757 r:0.5471
ne_en Dev loss: 0.5238 r:0.7060
ru_en Dev loss: 0.4971 r:0.7222
Current avg r:0.5707 Best avg r: 0.6238
07:27:28,288 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:28:59,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:30,322 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1579
en_de Dev loss: 0.9320 r:0.1519
en_zh Dev loss: 0.8305 r:0.4326
ro_en Dev loss: 0.3596 r:0.8161
et_en Dev loss: 0.4935 r:0.6355
si_en Dev loss: 0.9520 r:0.5388
ne_en Dev loss: 0.6035 r:0.7099
ru_en Dev loss: 0.4643 r:0.7358
Current avg r:0.5744 Best avg r: 0.6238
07:35:03,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:36:34,210 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:38:05,44 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1656
en_de Dev loss: 0.9497 r:0.1304
en_zh Dev loss: 0.8449 r:0.4263
ro_en Dev loss: 0.3685 r:0.8199
et_en Dev loss: 0.5177 r:0.6451
si_en Dev loss: 0.9532 r:0.5432
ne_en Dev loss: 0.5981 r:0.7083
ru_en Dev loss: 0.4696 r:0.7343
Current avg r:0.5725 Best avg r: 0.6238
07:42:35,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:44:06,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:36,408 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1551
en_de Dev loss: 0.9520 r:0.1502
en_zh Dev loss: 0.7890 r:0.4528
ro_en Dev loss: 0.3405 r:0.8208
et_en Dev loss: 0.5125 r:0.6505
si_en Dev loss: 0.8274 r:0.5518
ne_en Dev loss: 0.4922 r:0.7148
ru_en Dev loss: 0.4160 r:0.7555
Current avg r:0.5852 Best avg r: 0.6238
07:50:04,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:51:35,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:53:05,141 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1494
en_de Dev loss: 0.9494 r:0.1476
en_zh Dev loss: 0.8463 r:0.4416
ro_en Dev loss: 0.3482 r:0.8234
et_en Dev loss: 0.5112 r:0.6473
si_en Dev loss: 0.8823 r:0.5512
ne_en Dev loss: 0.5098 r:0.7059
ru_en Dev loss: 0.4667 r:0.7417
Current avg r:0.5798 Best avg r: 0.6238
07:57:33,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:59:04,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:00:34,210 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1491
en_de Dev loss: 0.9490 r:0.1409
en_zh Dev loss: 0.7854 r:0.4451
ro_en Dev loss: 0.3303 r:0.8240
et_en Dev loss: 0.5533 r:0.6476
si_en Dev loss: 0.8190 r:0.5542
ne_en Dev loss: 0.5168 r:0.7134
ru_en Dev loss: 0.4270 r:0.7398
Current avg r:0.5807 Best avg r: 0.6238
08:05:02,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:06:32,401 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:08:02,350 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1416
en_de Dev loss: 0.9712 r:0.1354
en_zh Dev loss: 0.8200 r:0.4424
ro_en Dev loss: 0.3711 r:0.8196
et_en Dev loss: 0.5094 r:0.6415
si_en Dev loss: 0.9376 r:0.5450
ne_en Dev loss: 0.5891 r:0.7119
ru_en Dev loss: 0.4530 r:0.7402
Current avg r:0.5766 Best avg r: 0.6238
08:12:29,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:13:59,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:15:29,727 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1436
en_de Dev loss: 0.9839 r:0.1262
en_zh Dev loss: 0.8571 r:0.4349
ro_en Dev loss: 0.3772 r:0.8196
et_en Dev loss: 0.5061 r:0.6420
si_en Dev loss: 0.9311 r:0.5459
ne_en Dev loss: 0.6492 r:0.7094
ru_en Dev loss: 0.4918 r:0.7229
Current avg r:0.5716 Best avg r: 0.6238
08:20:02,393 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:33,278 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:03,973 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1476
en_de Dev loss: 0.9546 r:0.1451
en_zh Dev loss: 0.8720 r:0.4384
ro_en Dev loss: 0.3852 r:0.8188
et_en Dev loss: 0.4933 r:0.6484
si_en Dev loss: 0.9048 r:0.5477
ne_en Dev loss: 0.6058 r:0.7000
ru_en Dev loss: 0.5068 r:0.7160
Current avg r:0.5735 Best avg r: 0.6238
08:27:35,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:29:05,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:36,484 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1472
en_de Dev loss: 0.9359 r:0.1620
en_zh Dev loss: 0.8156 r:0.4504
ro_en Dev loss: 0.3509 r:0.8206
et_en Dev loss: 0.5157 r:0.6573
si_en Dev loss: 0.8203 r:0.5573
ne_en Dev loss: 0.5062 r:0.7074
ru_en Dev loss: 0.4284 r:0.7476
Current avg r:0.5861 Best avg r: 0.6238
08:35:06,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:36,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:38:07,462 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1476
en_de Dev loss: 0.9374 r:0.1607
en_zh Dev loss: 0.8342 r:0.4460
ro_en Dev loss: 0.3733 r:0.8188
et_en Dev loss: 0.5284 r:0.6408
si_en Dev loss: 0.8738 r:0.5475
ne_en Dev loss: 0.5841 r:0.7003
ru_en Dev loss: 0.4515 r:0.7438
Current avg r:0.5797 Best avg r: 0.6238
08:42:35,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:44:05,188 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:45:34,913 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1473
en_de Dev loss: 0.9422 r:0.1545
en_zh Dev loss: 0.7845 r:0.4479
ro_en Dev loss: 0.3525 r:0.8174
et_en Dev loss: 0.5085 r:0.6464
si_en Dev loss: 0.8551 r:0.5469
ne_en Dev loss: 0.5515 r:0.7017
ru_en Dev loss: 0.4270 r:0.7505
Current avg r:0.5808 Best avg r: 0.6238
08:50:01,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:51:31,463 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:53:01,131 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1446
en_de Dev loss: 0.9894 r:0.1502
en_zh Dev loss: 0.9182 r:0.4425
ro_en Dev loss: 0.4483 r:0.8127
et_en Dev loss: 0.5548 r:0.6388
si_en Dev loss: 1.0017 r:0.5428
ne_en Dev loss: 0.7020 r:0.7019
ru_en Dev loss: 0.5456 r:0.7392
Current avg r:0.5755 Best avg r: 0.6238
08:57:27,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:58:57,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:00:27,304 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1475
en_de Dev loss: 0.9380 r:0.1626
en_zh Dev loss: 0.7945 r:0.4514
ro_en Dev loss: 0.3671 r:0.8141
et_en Dev loss: 0.5190 r:0.6369
si_en Dev loss: 0.8853 r:0.5388
ne_en Dev loss: 0.5773 r:0.6967
ru_en Dev loss: 0.4660 r:0.7353
Current avg r:0.5765 Best avg r: 0.6238
09:04:55,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:06:25,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:07:54,901 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1225
en_de Dev loss: 0.9255 r:0.1695
en_zh Dev loss: 0.7924 r:0.4516
ro_en Dev loss: 0.3575 r:0.8168
et_en Dev loss: 0.4950 r:0.6469
si_en Dev loss: 0.8833 r:0.5469
ne_en Dev loss: 0.6199 r:0.6995
ru_en Dev loss: 0.4530 r:0.7365
Current avg r:0.5811 Best avg r: 0.6238
09:12:21,975 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:13:51,697 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:15:21,356 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1325
en_de Dev loss: 0.9259 r:0.1738
en_zh Dev loss: 0.7852 r:0.4619
ro_en Dev loss: 0.3517 r:0.8205
et_en Dev loss: 0.5165 r:0.6459
si_en Dev loss: 0.8470 r:0.5545
ne_en Dev loss: 0.5642 r:0.7037
ru_en Dev loss: 0.4355 r:0.7463
Current avg r:0.5867 Best avg r: 0.6238
09:19:48,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:21:17,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:22:47,336 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1353
en_de Dev loss: 0.9575 r:0.1689
en_zh Dev loss: 0.8370 r:0.4511
ro_en Dev loss: 0.3947 r:0.8131
et_en Dev loss: 0.5094 r:0.6379
si_en Dev loss: 0.9522 r:0.5432
ne_en Dev loss: 0.6655 r:0.7035
ru_en Dev loss: 0.4964 r:0.7318
Current avg r:0.5785 Best avg r: 0.6238
09:27:13,869 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:28:43,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:30:12,711 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1316
en_de Dev loss: 0.9518 r:0.1608
en_zh Dev loss: 0.8072 r:0.4516
ro_en Dev loss: 0.3936 r:0.8123
et_en Dev loss: 0.5284 r:0.6385
si_en Dev loss: 0.9512 r:0.5407
ne_en Dev loss: 0.6412 r:0.7049
ru_en Dev loss: 0.4765 r:0.7320
Current avg r:0.5773 Best avg r: 0.6238
09:34:39,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:36:08,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:37:38,100 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1363
en_de Dev loss: 0.9411 r:0.1663
en_zh Dev loss: 0.7791 r:0.4541
ro_en Dev loss: 0.3539 r:0.8183
et_en Dev loss: 0.5030 r:0.6445
si_en Dev loss: 0.8903 r:0.5410
ne_en Dev loss: 0.5941 r:0.7019
ru_en Dev loss: 0.4620 r:0.7295
Current avg r:0.5794 Best avg r: 0.6238
09:42:04,835 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:34,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:45:03,860 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1429
en_de Dev loss: 0.9828 r:0.1507
en_zh Dev loss: 0.7960 r:0.4593
ro_en Dev loss: 0.3761 r:0.8167
et_en Dev loss: 0.5080 r:0.6416
si_en Dev loss: 0.9090 r:0.5410
ne_en Dev loss: 0.5901 r:0.7031
ru_en Dev loss: 0.4753 r:0.7429
Current avg r:0.5793 Best avg r: 0.6238
09:49:30,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:50:59,953 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:52:29,447 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1310
en_de Dev loss: 0.9730 r:0.1537
en_zh Dev loss: 0.8318 r:0.4446
ro_en Dev loss: 0.3655 r:0.8171
et_en Dev loss: 0.5162 r:0.6532
si_en Dev loss: 0.9249 r:0.5393
ne_en Dev loss: 0.5553 r:0.6972
ru_en Dev loss: 0.4638 r:0.7447
Current avg r:0.5785 Best avg r: 0.6238
09:56:56,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:25,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:55,48 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1398
en_de Dev loss: 0.9747 r:0.1596
en_zh Dev loss: 0.8659 r:0.4494
ro_en Dev loss: 0.3924 r:0.8186
et_en Dev loss: 0.5126 r:0.6457
si_en Dev loss: 0.9102 r:0.5449
ne_en Dev loss: 0.6208 r:0.7032
ru_en Dev loss: 0.4919 r:0.7413
Current avg r:0.5804 Best avg r: 0.6238
10:04:21,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:51,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:20,705 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1287
en_de Dev loss: 0.9724 r:0.1468
en_zh Dev loss: 0.8389 r:0.4477
ro_en Dev loss: 0.3700 r:0.8181
et_en Dev loss: 0.5105 r:0.6378
si_en Dev loss: 0.9527 r:0.5330
ne_en Dev loss: 0.6820 r:0.6989
ru_en Dev loss: 0.4817 r:0.7382
Current avg r:0.5743 Best avg r: 0.6238
10:11:47,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:16,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:46,346 root INFO Epoch 13 Global steps: 109900 Train loss: 0.1385
en_de Dev loss: 0.9266 r:0.1358
en_zh Dev loss: 0.7427 r:0.4635
ro_en Dev loss: 0.3296 r:0.8218
et_en Dev loss: 0.4696 r:0.6523
si_en Dev loss: 0.8248 r:0.5413
ne_en Dev loss: 0.6121 r:0.6986
ru_en Dev loss: 0.4372 r:0.7397
Current avg r:0.5790 Best avg r: 0.6238
10:19:13,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:42,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:12,499 root INFO Epoch 13 Global steps: 110600 Train loss: 0.1306
en_de Dev loss: 0.9650 r:0.1303
en_zh Dev loss: 0.8066 r:0.4573
ro_en Dev loss: 0.3667 r:0.8192
et_en Dev loss: 0.5178 r:0.6526
si_en Dev loss: 0.8746 r:0.5444
ne_en Dev loss: 0.5472 r:0.7058
ru_en Dev loss: 0.4406 r:0.7496
Current avg r:0.5799 Best avg r: 0.6238
10:26:39,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:09,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:38,509 root INFO Epoch 13 Global steps: 111300 Train loss: 0.1265
en_de Dev loss: 0.9374 r:0.1400
en_zh Dev loss: 0.7517 r:0.4520
ro_en Dev loss: 0.3157 r:0.8230
et_en Dev loss: 0.4686 r:0.6545
si_en Dev loss: 0.7952 r:0.5484
ne_en Dev loss: 0.5024 r:0.6966
ru_en Dev loss: 0.4163 r:0.7408
Current avg r:0.5793 Best avg r: 0.6238
