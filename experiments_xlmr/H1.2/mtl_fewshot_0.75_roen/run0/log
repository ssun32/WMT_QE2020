14:35:44,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:35:57,173 root INFO 
id:en_de cur r: 0.0488 best r: 0.0488
14:36:10,113 root INFO 
id:en_zh cur r: 0.1600 best r: 0.1600
14:36:36,51 root INFO 
id:ro_en cur r: 0.4468 best r: 0.4468
14:37:02,67 root INFO 
id:si_en cur r: 0.1928 best r: 0.1928
14:37:15,82 root INFO 
id:ne_en cur r: 0.2274 best r: 0.2274
14:37:27,977 root INFO 
id:ru_en cur r: 0.3393 best r: 0.3393
14:37:27,978 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:38:58,656 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:38:58,661 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:38:58,666 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:38:58,671 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:38:58,675 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:38:58,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:38:58,685 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:39:11,621 root INFO Epoch 0 Global steps: 700 Train loss: 0.8713
en_de Dev loss: 0.8935 r:0.0432
en_zh Dev loss: 0.8077 r:0.1762
ro_en Dev loss: 0.8063 r:0.4523
et_en Dev loss: 0.7049 r:0.3646
si_en Dev loss: 0.8683 r:0.3579
ne_en Dev loss: 0.7619 r:0.3977
ru_en Dev loss: 0.7868 r:0.3922
Current avg r:0.3120 Best avg r: 0.3120
14:43:42,565 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:44:08,369 root INFO 
id:en_zh cur r: 0.2628 best r: 0.2628
14:44:34,241 root INFO 
id:ro_en cur r: 0.6023 best r: 0.6023
14:44:47,176 root INFO 
id:et_en cur r: 0.4445 best r: 0.4445
14:45:00,134 root INFO 
id:si_en cur r: 0.4028 best r: 0.4028
14:45:13,103 root INFO 
id:ne_en cur r: 0.5538 best r: 0.5538
14:45:25,956 root INFO 
id:ru_en cur r: 0.4975 best r: 0.4975
14:45:25,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:56,423 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:46:56,432 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:46:56,436 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:46:56,441 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:46:56,446 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:46:56,451 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:46:56,456 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:47:09,396 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8513
en_de Dev loss: 0.8918 r:0.0808
en_zh Dev loss: 0.7547 r:0.2857
ro_en Dev loss: 0.6758 r:0.5950
et_en Dev loss: 0.5907 r:0.4385
si_en Dev loss: 0.7461 r:0.4525
ne_en Dev loss: 0.6376 r:0.5846
ru_en Dev loss: 0.6598 r:0.5077
Current avg r:0.4207 Best avg r: 0.4207
14:51:40,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:53,528 root INFO 
id:en_de cur r: 0.1223 best r: 0.1223
14:52:06,469 root INFO 
id:en_zh cur r: 0.3494 best r: 0.3494
14:52:32,428 root INFO 
id:ro_en cur r: 0.6553 best r: 0.6553
14:52:45,433 root INFO 
id:et_en cur r: 0.5752 best r: 0.5752
14:52:58,435 root INFO 
id:si_en cur r: 0.4669 best r: 0.4669
14:53:11,424 root INFO 
id:ne_en cur r: 0.5764 best r: 0.5764
14:53:24,339 root INFO 
id:ru_en cur r: 0.6130 best r: 0.6130
14:53:24,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:55,74 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:54:55,80 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:54:55,84 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:54:55,89 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:54:55,94 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:54:55,99 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:54:55,104 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:55:08,81 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7789
en_de Dev loss: 0.8997 r:0.1144
en_zh Dev loss: 0.7208 r:0.3521
ro_en Dev loss: 0.5959 r:0.6529
et_en Dev loss: 0.4792 r:0.5979
si_en Dev loss: 0.6562 r:0.5038
ne_en Dev loss: 0.5270 r:0.6385
ru_en Dev loss: 0.5816 r:0.6442
Current avg r:0.5006 Best avg r: 0.5006
14:59:40,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:06,47 root INFO 
id:en_zh cur r: 0.3534 best r: 0.3534
15:00:32,18 root INFO 
id:ro_en cur r: 0.6823 best r: 0.6823
15:00:45,17 root INFO 
id:et_en cur r: 0.6544 best r: 0.6544
15:00:58,31 root INFO 
id:si_en cur r: 0.5104 best r: 0.5104
15:01:11,34 root INFO 
id:ne_en cur r: 0.6698 best r: 0.6698
15:01:23,956 root INFO 
id:ru_en cur r: 0.6493 best r: 0.6493
15:01:23,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:54,745 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:02:54,763 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:02:54,769 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:02:54,774 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:02:54,785 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:02:54,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:02:54,794 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:03:07,788 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7001
en_de Dev loss: 0.9265 r:0.1644
en_zh Dev loss: 0.7996 r:0.3492
ro_en Dev loss: 0.5517 r:0.6854
et_en Dev loss: 0.4270 r:0.6598
si_en Dev loss: 0.6420 r:0.5366
ne_en Dev loss: 0.4789 r:0.6622
ru_en Dev loss: 0.5361 r:0.6840
Current avg r:0.5345 Best avg r: 0.5345
15:07:39,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:52,894 root INFO 
id:en_de cur r: 0.1306 best r: 0.1306
15:08:05,839 root INFO 
id:en_zh cur r: 0.3733 best r: 0.3733
15:08:31,819 root INFO 
id:ro_en cur r: 0.7066 best r: 0.7066
15:08:44,820 root INFO 
id:et_en cur r: 0.6748 best r: 0.6748
15:08:57,833 root INFO 
id:si_en cur r: 0.5559 best r: 0.5559
15:09:10,833 root INFO 
id:ne_en cur r: 0.7097 best r: 0.7097
15:09:23,766 root INFO 
id:ru_en cur r: 0.6790 best r: 0.6790
15:09:23,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:54,525 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:10:54,530 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:10:54,537 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:10:54,542 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:10:54,547 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:10:54,553 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:10:54,557 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:11:07,554 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6449
en_de Dev loss: 0.8814 r:0.1795
en_zh Dev loss: 0.7037 r:0.3800
ro_en Dev loss: 0.4463 r:0.7134
et_en Dev loss: 0.3864 r:0.6827
si_en Dev loss: 0.5571 r:0.5779
ne_en Dev loss: 0.4103 r:0.7084
ru_en Dev loss: 0.4512 r:0.6973
Current avg r:0.5628 Best avg r: 0.5628
15:15:39,623 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:31,497 root INFO 
id:ro_en cur r: 0.7129 best r: 0.7129
15:17:23,404 root INFO 
id:ru_en cur r: 0.6829 best r: 0.6829
15:17:23,404 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:54,162 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6531
en_de Dev loss: 0.9309 r:0.1580
en_zh Dev loss: 0.8100 r:0.3577
ro_en Dev loss: 0.5222 r:0.7305
et_en Dev loss: 0.4305 r:0.6569
si_en Dev loss: 0.7769 r:0.5458
ne_en Dev loss: 0.5240 r:0.6693
ru_en Dev loss: 0.5262 r:0.6939
Current avg r:0.5446 Best avg r: 0.5628
15:23:26,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:52,186 root INFO 
id:en_zh cur r: 0.3882 best r: 0.3882
15:24:18,164 root INFO 
id:ro_en cur r: 0.7478 best r: 0.7478
15:24:31,161 root INFO 
id:et_en cur r: 0.6773 best r: 0.6773
15:24:44,155 root INFO 
id:si_en cur r: 0.5652 best r: 0.5652
15:24:57,165 root INFO 
id:ne_en cur r: 0.7170 best r: 0.7170
15:25:10,96 root INFO 
id:ru_en cur r: 0.7115 best r: 0.7115
15:25:10,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:40,919 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:26:40,925 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:26:40,933 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:26:40,937 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:26:40,942 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:26:40,948 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:26:40,954 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:26:53,941 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6156
en_de Dev loss: 0.8906 r:0.1630
en_zh Dev loss: 0.7056 r:0.4033
ro_en Dev loss: 0.3958 r:0.7603
et_en Dev loss: 0.3787 r:0.6884
si_en Dev loss: 0.7148 r:0.5703
ne_en Dev loss: 0.4899 r:0.6986
ru_en Dev loss: 0.4357 r:0.7231
Current avg r:0.5724 Best avg r: 0.5724
15:31:26,163 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:39,145 root INFO 
id:en_de cur r: 0.1625 best r: 0.1625
15:31:52,87 root INFO 
id:en_zh cur r: 0.4148 best r: 0.4148
15:32:18,45 root INFO 
id:ro_en cur r: 0.7607 best r: 0.7607
15:32:31,43 root INFO 
id:et_en cur r: 0.7028 best r: 0.7028
15:32:44,48 root INFO 
id:si_en cur r: 0.5920 best r: 0.5920
15:32:57,41 root INFO 
id:ne_en cur r: 0.7296 best r: 0.7296
15:33:09,964 root INFO 
id:ru_en cur r: 0.7187 best r: 0.7187
15:33:09,965 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:40,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:34:40,781 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:34:40,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:34:40,791 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:34:40,796 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:34:40,800 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:34:40,805 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:34:53,789 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6154
en_de Dev loss: 0.9013 r:0.1746
en_zh Dev loss: 0.6891 r:0.4286
ro_en Dev loss: 0.3640 r:0.7728
et_en Dev loss: 0.3546 r:0.7055
si_en Dev loss: 0.6269 r:0.5974
ne_en Dev loss: 0.4396 r:0.7199
ru_en Dev loss: 0.4193 r:0.7238
Current avg r:0.5889 Best avg r: 0.5889
15:39:25,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:17,815 root INFO 
id:ro_en cur r: 0.7678 best r: 0.7678
15:40:56,824 root INFO 
id:ne_en cur r: 0.7325 best r: 0.7325
15:41:09,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:40,563 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5894
en_de Dev loss: 0.9237 r:0.1661
en_zh Dev loss: 0.7501 r:0.4101
ro_en Dev loss: 0.3947 r:0.7769
et_en Dev loss: 0.3516 r:0.7112
si_en Dev loss: 0.6289 r:0.5977
ne_en Dev loss: 0.4314 r:0.7186
ru_en Dev loss: 0.4530 r:0.7358
Current avg r:0.5881 Best avg r: 0.5889
15:47:12,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:04,615 root INFO 
id:ro_en cur r: 0.7801 best r: 0.7801
15:48:17,617 root INFO 
id:et_en cur r: 0.7071 best r: 0.7071
15:48:43,629 root INFO 
id:ne_en cur r: 0.7423 best r: 0.7423
15:48:56,557 root INFO 
id:ru_en cur r: 0.7278 best r: 0.7278
15:48:56,557 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:27,347 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:50:27,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:50:27,358 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:50:27,363 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:50:27,367 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:50:27,372 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:50:27,376 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:50:40,363 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5825
en_de Dev loss: 0.9154 r:0.1703
en_zh Dev loss: 0.7128 r:0.4297
ro_en Dev loss: 0.3851 r:0.7876
et_en Dev loss: 0.3500 r:0.7118
si_en Dev loss: 0.7073 r:0.5913
ne_en Dev loss: 0.4452 r:0.7277
ru_en Dev loss: 0.4260 r:0.7512
Current avg r:0.5957 Best avg r: 0.5957
15:55:12,594 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:38,524 root INFO 
id:en_zh cur r: 0.4184 best r: 0.4184
15:56:04,505 root INFO 
id:ro_en cur r: 0.7844 best r: 0.7844
15:56:17,497 root INFO 
id:et_en cur r: 0.7133 best r: 0.7133
15:56:30,507 root INFO 
id:si_en cur r: 0.5952 best r: 0.5952
15:56:43,521 root INFO 
id:ne_en cur r: 0.7517 best r: 0.7517
15:56:56,445 root INFO 
id:ru_en cur r: 0.7413 best r: 0.7413
15:56:56,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:27,237 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:58:27,244 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:58:27,249 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:58:27,253 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:58:27,259 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:58:27,263 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:58:27,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:58:40,266 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5495
en_de Dev loss: 0.8763 r:0.1762
en_zh Dev loss: 0.6762 r:0.4320
ro_en Dev loss: 0.3357 r:0.7873
et_en Dev loss: 0.3529 r:0.7175
si_en Dev loss: 0.5704 r:0.6039
ne_en Dev loss: 0.3634 r:0.7449
ru_en Dev loss: 0.3610 r:0.7597
Current avg r:0.6031 Best avg r: 0.6031
16:03:13,861 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:03:39,794 root INFO 
id:en_zh cur r: 0.4275 best r: 0.4275
16:04:05,741 root INFO 
id:ro_en cur r: 0.7890 best r: 0.7890
16:04:57,603 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:06:28,264 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5339
en_de Dev loss: 0.9059 r:0.1705
en_zh Dev loss: 0.7136 r:0.4385
ro_en Dev loss: 0.3901 r:0.7912
et_en Dev loss: 0.3760 r:0.7119
si_en Dev loss: 0.7582 r:0.5995
ne_en Dev loss: 0.5348 r:0.7350
ru_en Dev loss: 0.4792 r:0.7388
Current avg r:0.5979 Best avg r: 0.6031
16:10:59,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:11:12,691 root INFO 
id:en_de cur r: 0.1674 best r: 0.1674
16:11:51,553 root INFO 
id:ro_en cur r: 0.7957 best r: 0.7957
16:12:43,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:14:13,992 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5583
en_de Dev loss: 0.8944 r:0.1843
en_zh Dev loss: 0.7313 r:0.4224
ro_en Dev loss: 0.3415 r:0.7948
et_en Dev loss: 0.3694 r:0.7073
si_en Dev loss: 0.6886 r:0.6003
ne_en Dev loss: 0.4635 r:0.7369
ru_en Dev loss: 0.4669 r:0.7312
Current avg r:0.5967 Best avg r: 0.6031
16:18:45,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:58,430 root INFO 
id:en_de cur r: 0.1900 best r: 0.1900
16:19:37,315 root INFO 
id:ro_en cur r: 0.7967 best r: 0.7967
16:20:03,284 root INFO 
id:si_en cur r: 0.6044 best r: 0.6044
16:20:29,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:59,792 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:21:59,798 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:21:59,802 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:21:59,807 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:21:59,812 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:21:59,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:21:59,822 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:22:12,797 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5339
en_de Dev loss: 0.8548 r:0.2008
en_zh Dev loss: 0.6692 r:0.4417
ro_en Dev loss: 0.3238 r:0.7944
et_en Dev loss: 0.3632 r:0.7044
si_en Dev loss: 0.5765 r:0.6098
ne_en Dev loss: 0.3919 r:0.7388
ru_en Dev loss: 0.3810 r:0.7462
Current avg r:0.6052 Best avg r: 0.6052
16:26:44,142 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:35,986 root INFO 
id:ro_en cur r: 0.7972 best r: 0.7972
16:28:27,823 root INFO 
id:ru_en cur r: 0.7436 best r: 0.7436
16:28:27,824 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:58,480 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5093
en_de Dev loss: 0.8606 r:0.1926
en_zh Dev loss: 0.6820 r:0.4407
ro_en Dev loss: 0.3355 r:0.7922
et_en Dev loss: 0.3560 r:0.7079
si_en Dev loss: 0.6604 r:0.5931
ne_en Dev loss: 0.4204 r:0.7396
ru_en Dev loss: 0.3870 r:0.7471
Current avg r:0.6019 Best avg r: 0.6052
16:34:30,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:56,225 root INFO 
id:en_zh cur r: 0.4482 best r: 0.4482
16:35:22,192 root INFO 
id:ro_en cur r: 0.8138 best r: 0.8138
16:35:35,190 root INFO 
id:et_en cur r: 0.7160 best r: 0.7160
16:35:48,214 root INFO 
id:si_en cur r: 0.6139 best r: 0.6139
16:36:01,221 root INFO 
id:ne_en cur r: 0.7653 best r: 0.7653
16:36:14,147 root INFO 
id:ru_en cur r: 0.7581 best r: 0.7581
16:36:14,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:44,897 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:37:44,904 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:37:44,909 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:37:44,914 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:37:44,918 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:37:44,923 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:37:44,928 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:37:57,906 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5072
en_de Dev loss: 0.8702 r:0.1988
en_zh Dev loss: 0.7007 r:0.4565
ro_en Dev loss: 0.3369 r:0.8060
et_en Dev loss: 0.3507 r:0.7193
si_en Dev loss: 0.6365 r:0.6251
ne_en Dev loss: 0.3576 r:0.7653
ru_en Dev loss: 0.3923 r:0.7582
Current avg r:0.6185 Best avg r: 0.6185
16:42:29,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:21,739 root INFO 
id:ro_en cur r: 0.8159 best r: 0.8159
16:43:34,732 root INFO 
id:et_en cur r: 0.7202 best r: 0.7202
16:44:13,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:45:44,416 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5128
en_de Dev loss: 0.8622 r:0.1956
en_zh Dev loss: 0.6945 r:0.4481
ro_en Dev loss: 0.3159 r:0.8098
et_en Dev loss: 0.3559 r:0.7222
si_en Dev loss: 0.6830 r:0.6160
ne_en Dev loss: 0.3665 r:0.7570
ru_en Dev loss: 0.4092 r:0.7506
Current avg r:0.6142 Best avg r: 0.6185
16:50:16,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:08,402 root INFO 
id:ro_en cur r: 0.8206 best r: 0.8206
16:52:00,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:31,43 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4926
en_de Dev loss: 0.8562 r:0.2043
en_zh Dev loss: 0.6781 r:0.4497
ro_en Dev loss: 0.3138 r:0.8135
et_en Dev loss: 0.3411 r:0.7222
si_en Dev loss: 0.6377 r:0.6180
ne_en Dev loss: 0.4399 r:0.7572
ru_en Dev loss: 0.4185 r:0.7407
Current avg r:0.6151 Best avg r: 0.6185
16:58:03,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:29,73 root INFO 
id:en_zh cur r: 0.4492 best r: 0.4492
16:59:33,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:04,705 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5348
en_de Dev loss: 0.8558 r:0.1981
en_zh Dev loss: 0.6758 r:0.4598
ro_en Dev loss: 0.3085 r:0.8119
et_en Dev loss: 0.3544 r:0.7087
si_en Dev loss: 0.6841 r:0.6082
ne_en Dev loss: 0.4557 r:0.7577
ru_en Dev loss: 0.4034 r:0.7414
Current avg r:0.6123 Best avg r: 0.6185
17:05:36,763 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:06:41,673 root INFO 
id:si_en cur r: 0.6169 best r: 0.6169
17:06:54,677 root INFO 
id:ne_en cur r: 0.7661 best r: 0.7661
17:07:07,610 root INFO 
id:ru_en cur r: 0.7595 best r: 0.7595
17:07:07,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:38,368 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4684
en_de Dev loss: 0.8748 r:0.1817
en_zh Dev loss: 0.7145 r:0.4396
ro_en Dev loss: 0.3099 r:0.8113
et_en Dev loss: 0.3455 r:0.7195
si_en Dev loss: 0.6927 r:0.6178
ne_en Dev loss: 0.3897 r:0.7658
ru_en Dev loss: 0.3977 r:0.7511
Current avg r:0.6124 Best avg r: 0.6185
17:13:10,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:36,347 root INFO 
id:en_zh cur r: 0.4537 best r: 0.4537
17:14:28,326 root INFO 
id:ne_en cur r: 0.7706 best r: 0.7706
17:14:41,261 root INFO 
id:ru_en cur r: 0.7606 best r: 0.7606
17:14:41,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:11,977 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4930
en_de Dev loss: 0.8612 r:0.1844
en_zh Dev loss: 0.6667 r:0.4573
ro_en Dev loss: 0.3043 r:0.8132
et_en Dev loss: 0.3773 r:0.7127
si_en Dev loss: 0.5883 r:0.6216
ne_en Dev loss: 0.3320 r:0.7705
ru_en Dev loss: 0.3671 r:0.7575
Current avg r:0.6167 Best avg r: 0.6185
17:20:44,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:57,72 root INFO 
id:en_de cur r: 0.1948 best r: 0.1948
17:21:10,18 root INFO 
id:en_zh cur r: 0.4679 best r: 0.4679
17:21:35,982 root INFO 
id:ro_en cur r: 0.8253 best r: 0.8253
17:22:01,983 root INFO 
id:si_en cur r: 0.6215 best r: 0.6215
17:22:27,907 root INFO 
id:ru_en cur r: 0.7624 best r: 0.7624
17:22:27,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:58,654 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:23:58,659 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:23:58,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:23:58,668 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:23:58,673 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:23:58,679 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:23:58,683 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:24:11,660 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5344
en_de Dev loss: 0.8651 r:0.1953
en_zh Dev loss: 0.6573 r:0.4727
ro_en Dev loss: 0.3022 r:0.8193
et_en Dev loss: 0.3726 r:0.7120
si_en Dev loss: 0.5426 r:0.6277
ne_en Dev loss: 0.3334 r:0.7628
ru_en Dev loss: 0.3647 r:0.7618
Current avg r:0.6217 Best avg r: 0.6217
17:28:45,111 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:58,98 root INFO 
id:en_de cur r: 0.2206 best r: 0.2206
17:30:15,940 root INFO 
id:ru_en cur r: 0.7695 best r: 0.7695
17:30:15,941 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:46,707 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:31:46,715 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:31:46,720 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:31:46,727 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:31:46,736 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:31:46,741 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:31:46,746 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:31:59,734 root INFO Epoch 2 Global steps: 16100 Train loss: 0.5107
en_de Dev loss: 0.8412 r:0.2326
en_zh Dev loss: 0.6749 r:0.4609
ro_en Dev loss: 0.3266 r:0.8136
et_en Dev loss: 0.3868 r:0.7147
si_en Dev loss: 0.5808 r:0.6160
ne_en Dev loss: 0.3615 r:0.7646
ru_en Dev loss: 0.3801 r:0.7606
Current avg r:0.6233 Best avg r: 0.6233
17:36:32,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:37:49,891 root INFO 
id:ne_en cur r: 0.7728 best r: 0.7728
17:38:02,813 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:33,586 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4875
en_de Dev loss: 0.8560 r:0.2173
en_zh Dev loss: 0.6792 r:0.4649
ro_en Dev loss: 0.2925 r:0.8159
et_en Dev loss: 0.3657 r:0.7017
si_en Dev loss: 0.6047 r:0.6119
ne_en Dev loss: 0.3462 r:0.7701
ru_en Dev loss: 0.4070 r:0.7457
Current avg r:0.6182 Best avg r: 0.6233
17:44:05,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:57,554 root INFO 
id:ro_en cur r: 0.8278 best r: 0.8278
17:45:49,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:20,213 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4613
en_de Dev loss: 0.8493 r:0.2182
en_zh Dev loss: 0.6682 r:0.4565
ro_en Dev loss: 0.2983 r:0.8219
et_en Dev loss: 0.4133 r:0.7082
si_en Dev loss: 0.5607 r:0.6196
ne_en Dev loss: 0.3387 r:0.7702
ru_en Dev loss: 0.3542 r:0.7612
Current avg r:0.6222 Best avg r: 0.6233
17:51:52,481 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:23,277 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:54,32 root INFO Epoch 2 Global steps: 18200 Train loss: 0.4540
en_de Dev loss: 0.8472 r:0.2179
en_zh Dev loss: 0.6698 r:0.4714
ro_en Dev loss: 0.3225 r:0.8151
et_en Dev loss: 0.3888 r:0.7055
si_en Dev loss: 0.6261 r:0.6110
ne_en Dev loss: 0.3823 r:0.7650
ru_en Dev loss: 0.4095 r:0.7413
Current avg r:0.6182 Best avg r: 0.6233
17:59:26,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:56,920 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:27,696 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4996
en_de Dev loss: 0.8611 r:0.2018
en_zh Dev loss: 0.6913 r:0.4556
ro_en Dev loss: 0.3087 r:0.8153
et_en Dev loss: 0.3816 r:0.6988
si_en Dev loss: 0.6347 r:0.6138
ne_en Dev loss: 0.3948 r:0.7590
ru_en Dev loss: 0.3813 r:0.7466
Current avg r:0.6130 Best avg r: 0.6233
18:06:59,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:07:51,599 root INFO 
id:ro_en cur r: 0.8339 best r: 0.8339
18:08:30,598 root INFO 
id:ne_en cur r: 0.7745 best r: 0.7745
18:08:43,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:10:14,298 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4607
en_de Dev loss: 0.8694 r:0.2045
en_zh Dev loss: 0.6889 r:0.4617
ro_en Dev loss: 0.2865 r:0.8270
et_en Dev loss: 0.3651 r:0.7174
si_en Dev loss: 0.6223 r:0.6264
ne_en Dev loss: 0.3417 r:0.7724
ru_en Dev loss: 0.3963 r:0.7461
Current avg r:0.6222 Best avg r: 0.6233
18:14:46,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:16:17,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:47,973 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4291
en_de Dev loss: 0.9008 r:0.1984
en_zh Dev loss: 0.7610 r:0.4307
ro_en Dev loss: 0.3480 r:0.8030
et_en Dev loss: 0.3934 r:0.6874
si_en Dev loss: 0.7353 r:0.5937
ne_en Dev loss: 0.4651 r:0.7581
ru_en Dev loss: 0.4452 r:0.7256
Current avg r:0.5995 Best avg r: 0.6233
18:22:19,743 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:22:45,649 root INFO 
id:en_zh cur r: 0.4691 best r: 0.4691
18:23:37,569 root INFO 
id:ne_en cur r: 0.7790 best r: 0.7790
18:23:50,471 root INFO 
id:ru_en cur r: 0.7735 best r: 0.7735
18:23:50,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:21,139 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_de.lang_agnost_mlp.dev.best.scores
18:25:21,146 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:25:21,151 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:25:21,156 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/et_en.lang_agnost_mlp.dev.best.scores
18:25:21,161 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/si_en.lang_agnost_mlp.dev.best.scores
18:25:21,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:25:21,172 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:25:34,155 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4665
en_de Dev loss: 0.8527 r:0.2226
en_zh Dev loss: 0.6607 r:0.4749
ro_en Dev loss: 0.3004 r:0.8211
et_en Dev loss: 0.3668 r:0.7190
si_en Dev loss: 0.6140 r:0.6151
ne_en Dev loss: 0.3617 r:0.7763
ru_en Dev loss: 0.3528 r:0.7727
Current avg r:0.6288 Best avg r: 0.6288
18:30:05,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:31:36,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:33:07,31 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4643
en_de Dev loss: 0.8710 r:0.2088
en_zh Dev loss: 0.6862 r:0.4652
ro_en Dev loss: 0.3204 r:0.8194
et_en Dev loss: 0.3750 r:0.7038
si_en Dev loss: 0.7259 r:0.6018
ne_en Dev loss: 0.4207 r:0.7649
ru_en Dev loss: 0.4155 r:0.7539
Current avg r:0.6168 Best avg r: 0.6288
18:37:39,26 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:09,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:40,607 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4524
en_de Dev loss: 0.8674 r:0.2083
en_zh Dev loss: 0.6767 r:0.4647
ro_en Dev loss: 0.3186 r:0.8179
et_en Dev loss: 0.3716 r:0.7102
si_en Dev loss: 0.7516 r:0.6089
ne_en Dev loss: 0.4078 r:0.7660
ru_en Dev loss: 0.4004 r:0.7471
Current avg r:0.6176 Best avg r: 0.6288
18:45:12,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:43,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:14,375 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4445
en_de Dev loss: 0.8556 r:0.2038
en_zh Dev loss: 0.6791 r:0.4695
ro_en Dev loss: 0.3284 r:0.8153
et_en Dev loss: 0.3702 r:0.7035
si_en Dev loss: 0.7161 r:0.6030
ne_en Dev loss: 0.4688 r:0.7603
ru_en Dev loss: 0.3860 r:0.7535
Current avg r:0.6156 Best avg r: 0.6288
18:52:46,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:52:59,248 root INFO 
id:en_de cur r: 0.2241 best r: 0.2241
18:54:17,0 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:47,690 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4489
en_de Dev loss: 0.8565 r:0.2258
en_zh Dev loss: 0.7041 r:0.4660
ro_en Dev loss: 0.3194 r:0.8233
et_en Dev loss: 0.3617 r:0.7195
si_en Dev loss: 0.6396 r:0.6144
ne_en Dev loss: 0.3968 r:0.7726
ru_en Dev loss: 0.3879 r:0.7600
Current avg r:0.6260 Best avg r: 0.6288
19:00:20,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:50,998 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:21,464 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4204
en_de Dev loss: 0.8477 r:0.2131
en_zh Dev loss: 0.6828 r:0.4602
ro_en Dev loss: 0.2999 r:0.8183
et_en Dev loss: 0.3826 r:0.7163
si_en Dev loss: 0.6000 r:0.6140
ne_en Dev loss: 0.3718 r:0.7647
ru_en Dev loss: 0.3642 r:0.7575
Current avg r:0.6206 Best avg r: 0.6288
19:07:52,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:09:23,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:53,875 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4114
en_de Dev loss: 0.8592 r:0.2159
en_zh Dev loss: 0.7426 r:0.4535
ro_en Dev loss: 0.3534 r:0.8178
et_en Dev loss: 0.3764 r:0.7100
si_en Dev loss: 0.7356 r:0.6036
ne_en Dev loss: 0.4202 r:0.7692
ru_en Dev loss: 0.4503 r:0.7367
Current avg r:0.6152 Best avg r: 0.6288
19:15:25,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:55,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:26,83 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4221
en_de Dev loss: 0.8545 r:0.2020
en_zh Dev loss: 0.7050 r:0.4544
ro_en Dev loss: 0.2949 r:0.8266
et_en Dev loss: 0.3685 r:0.7132
si_en Dev loss: 0.6434 r:0.6082
ne_en Dev loss: 0.3463 r:0.7699
ru_en Dev loss: 0.3826 r:0.7540
Current avg r:0.6183 Best avg r: 0.6288
19:22:57,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:24:27,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:58,395 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4300
en_de Dev loss: 0.8741 r:0.2027
en_zh Dev loss: 0.7327 r:0.4585
ro_en Dev loss: 0.3260 r:0.8297
et_en Dev loss: 0.3685 r:0.7126
si_en Dev loss: 0.7752 r:0.5986
ne_en Dev loss: 0.4608 r:0.7626
ru_en Dev loss: 0.4374 r:0.7443
Current avg r:0.6156 Best avg r: 0.6288
19:30:31,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:57,304 root INFO 
id:en_zh cur r: 0.4705 best r: 0.4705
19:32:01,997 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:32,477 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4475
en_de Dev loss: 0.8626 r:0.2017
en_zh Dev loss: 0.6973 r:0.4724
ro_en Dev loss: 0.3189 r:0.8208
et_en Dev loss: 0.3845 r:0.7094
si_en Dev loss: 0.6301 r:0.6064
ne_en Dev loss: 0.4007 r:0.7620
ru_en Dev loss: 0.3993 r:0.7489
Current avg r:0.6174 Best avg r: 0.6288
19:38:04,120 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:35,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:41:06,471 root INFO Epoch 3 Global steps: 28000 Train loss: 0.4112
en_de Dev loss: 0.8844 r:0.1910
en_zh Dev loss: 0.8062 r:0.4383
ro_en Dev loss: 0.3735 r:0.8079
et_en Dev loss: 0.4099 r:0.6902
si_en Dev loss: 0.8642 r:0.5804
ne_en Dev loss: 0.5924 r:0.7502
ru_en Dev loss: 0.5760 r:0.6817
Current avg r:0.5914 Best avg r: 0.6288
19:45:38,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:47:09,257 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:40,22 root INFO Epoch 3 Global steps: 28700 Train loss: 0.4066
en_de Dev loss: 0.8758 r:0.2106
en_zh Dev loss: 0.7560 r:0.4589
ro_en Dev loss: 0.3312 r:0.8231
et_en Dev loss: 0.4005 r:0.6985
si_en Dev loss: 0.7224 r:0.6054
ne_en Dev loss: 0.4143 r:0.7583
ru_en Dev loss: 0.5029 r:0.7165
Current avg r:0.6102 Best avg r: 0.6288
19:53:12,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:53:25,588 root INFO 
id:en_de cur r: 0.2285 best r: 0.2285
19:53:38,546 root INFO 
id:en_zh cur r: 0.4833 best r: 0.4833
19:54:43,478 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:14,299 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4009
en_de Dev loss: 0.8466 r:0.2264
en_zh Dev loss: 0.6670 r:0.4832
ro_en Dev loss: 0.2953 r:0.8255
et_en Dev loss: 0.4261 r:0.7047
si_en Dev loss: 0.6072 r:0.6017
ne_en Dev loss: 0.3562 r:0.7664
ru_en Dev loss: 0.3678 r:0.7548
Current avg r:0.6232 Best avg r: 0.6288
20:00:46,992 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:00:59,972 root INFO 
id:en_de cur r: 0.2322 best r: 0.2322
20:02:17,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:48,720 root INFO Epoch 3 Global steps: 30100 Train loss: 0.3905
en_de Dev loss: 0.8713 r:0.2106
en_zh Dev loss: 0.7529 r:0.4354
ro_en Dev loss: 0.3081 r:0.8207
et_en Dev loss: 0.3882 r:0.6917
si_en Dev loss: 0.7282 r:0.6020
ne_en Dev loss: 0.4084 r:0.7625
ru_en Dev loss: 0.4674 r:0.7122
Current avg r:0.6050 Best avg r: 0.6288
20:08:21,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:08:34,113 root INFO 
id:en_de cur r: 0.2399 best r: 0.2399
20:09:51,962 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:22,776 root INFO Epoch 3 Global steps: 30800 Train loss: 0.3858
en_de Dev loss: 0.8676 r:0.2273
en_zh Dev loss: 0.7106 r:0.4670
ro_en Dev loss: 0.3252 r:0.8252
et_en Dev loss: 0.4108 r:0.7011
si_en Dev loss: 0.7269 r:0.6102
ne_en Dev loss: 0.4208 r:0.7619
ru_en Dev loss: 0.4599 r:0.7328
Current avg r:0.6179 Best avg r: 0.6288
20:15:55,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:08,318 root INFO 
id:en_de cur r: 0.2442 best r: 0.2442
20:17:26,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:57,58 root INFO Epoch 3 Global steps: 31500 Train loss: 0.3792
en_de Dev loss: 0.8845 r:0.2362
en_zh Dev loss: 0.7078 r:0.4656
ro_en Dev loss: 0.3651 r:0.8162
et_en Dev loss: 0.4061 r:0.6979
si_en Dev loss: 0.8058 r:0.5962
ne_en Dev loss: 0.4519 r:0.7544
ru_en Dev loss: 0.4724 r:0.7386
Current avg r:0.6150 Best avg r: 0.6288
20:23:30,851 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:01,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:32,506 root INFO Epoch 4 Global steps: 32200 Train loss: 0.3448
en_de Dev loss: 0.8881 r:0.2208
en_zh Dev loss: 0.7349 r:0.4571
ro_en Dev loss: 0.3555 r:0.8139
et_en Dev loss: 0.4036 r:0.6933
si_en Dev loss: 0.8162 r:0.5902
ne_en Dev loss: 0.4785 r:0.7602
ru_en Dev loss: 0.4731 r:0.7197
Current avg r:0.6079 Best avg r: 0.6288
20:31:05,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:36,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:34:06,836 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3866
en_de Dev loss: 0.8492 r:0.2316
en_zh Dev loss: 0.6959 r:0.4700
ro_en Dev loss: 0.3177 r:0.8211
et_en Dev loss: 0.3953 r:0.6996
si_en Dev loss: 0.6895 r:0.6039
ne_en Dev loss: 0.4213 r:0.7576
ru_en Dev loss: 0.4092 r:0.7439
Current avg r:0.6182 Best avg r: 0.6288
20:38:39,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:09,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:40,539 root INFO Epoch 4 Global steps: 33600 Train loss: 0.3818
en_de Dev loss: 0.8626 r:0.2204
en_zh Dev loss: 0.7269 r:0.4546
ro_en Dev loss: 0.3262 r:0.8199
et_en Dev loss: 0.3877 r:0.6895
si_en Dev loss: 0.8894 r:0.5801
ne_en Dev loss: 0.5852 r:0.7500
ru_en Dev loss: 0.4943 r:0.7044
Current avg r:0.6027 Best avg r: 0.6288
20:46:12,228 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:42,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:13,342 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3669
en_de Dev loss: 0.8553 r:0.2031
en_zh Dev loss: 0.7015 r:0.4729
ro_en Dev loss: 0.3038 r:0.8269
et_en Dev loss: 0.4326 r:0.6953
si_en Dev loss: 0.6685 r:0.6007
ne_en Dev loss: 0.3932 r:0.7539
ru_en Dev loss: 0.3778 r:0.7472
Current avg r:0.6143 Best avg r: 0.6288
20:53:45,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:15,567 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:46,149 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3413
en_de Dev loss: 0.8618 r:0.1994
en_zh Dev loss: 0.7203 r:0.4603
ro_en Dev loss: 0.3225 r:0.8199
et_en Dev loss: 0.4168 r:0.6907
si_en Dev loss: 0.7013 r:0.5929
ne_en Dev loss: 0.4448 r:0.7534
ru_en Dev loss: 0.4413 r:0.7258
Current avg r:0.6061 Best avg r: 0.6288
21:01:17,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:48,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:18,878 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3695
en_de Dev loss: 0.8629 r:0.1933
en_zh Dev loss: 0.7162 r:0.4552
ro_en Dev loss: 0.3219 r:0.8194
et_en Dev loss: 0.4532 r:0.6904
si_en Dev loss: 0.6423 r:0.6055
ne_en Dev loss: 0.4050 r:0.7467
ru_en Dev loss: 0.4205 r:0.7296
Current avg r:0.6057 Best avg r: 0.6288
21:08:50,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:21,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:51,653 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3736
en_de Dev loss: 0.9047 r:0.1483
en_zh Dev loss: 0.7238 r:0.4712
ro_en Dev loss: 0.3275 r:0.8244
et_en Dev loss: 0.4316 r:0.6856
si_en Dev loss: 0.7089 r:0.6040
ne_en Dev loss: 0.4628 r:0.7520
ru_en Dev loss: 0.4250 r:0.7337
Current avg r:0.6027 Best avg r: 0.6288
21:16:23,348 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:53,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:24,508 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3487
en_de Dev loss: 0.8671 r:0.1828
en_zh Dev loss: 0.7082 r:0.4582
ro_en Dev loss: 0.2972 r:0.8232
et_en Dev loss: 0.4151 r:0.6883
si_en Dev loss: 0.6182 r:0.6037
ne_en Dev loss: 0.4236 r:0.7479
ru_en Dev loss: 0.4473 r:0.7079
Current avg r:0.6017 Best avg r: 0.6288
21:23:56,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:25:26,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:57,350 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3577
en_de Dev loss: 0.8696 r:0.1895
en_zh Dev loss: 0.7080 r:0.4711
ro_en Dev loss: 0.3146 r:0.8216
et_en Dev loss: 0.4164 r:0.6951
si_en Dev loss: 0.6233 r:0.6067
ne_en Dev loss: 0.3821 r:0.7618
ru_en Dev loss: 0.4092 r:0.7427
Current avg r:0.6126 Best avg r: 0.6288
21:31:29,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:59,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:30,132 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3623
en_de Dev loss: 0.8875 r:0.1697
en_zh Dev loss: 0.7434 r:0.4503
ro_en Dev loss: 0.3495 r:0.8147
et_en Dev loss: 0.4160 r:0.6784
si_en Dev loss: 0.7637 r:0.5951
ne_en Dev loss: 0.4641 r:0.7549
ru_en Dev loss: 0.4982 r:0.7023
Current avg r:0.5951 Best avg r: 0.6288
21:39:01,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:32,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:02,758 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3533
en_de Dev loss: 0.8640 r:0.1970
en_zh Dev loss: 0.7127 r:0.4635
ro_en Dev loss: 0.3300 r:0.8180
et_en Dev loss: 0.4516 r:0.6943
si_en Dev loss: 0.6583 r:0.6033
ne_en Dev loss: 0.4369 r:0.7483
ru_en Dev loss: 0.4201 r:0.7334
Current avg r:0.6083 Best avg r: 0.6288
21:46:35,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:06,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:36,797 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3171
en_de Dev loss: 0.8900 r:0.1896
en_zh Dev loss: 0.7715 r:0.4456
ro_en Dev loss: 0.3676 r:0.8112
et_en Dev loss: 0.4311 r:0.6793
si_en Dev loss: 0.8113 r:0.5888
ne_en Dev loss: 0.4749 r:0.7548
ru_en Dev loss: 0.4669 r:0.7287
Current avg r:0.5997 Best avg r: 0.6288
21:54:08,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:38,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:57:09,558 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3135
en_de Dev loss: 0.8659 r:0.1952
en_zh Dev loss: 0.7486 r:0.4394
ro_en Dev loss: 0.3345 r:0.8144
et_en Dev loss: 0.4335 r:0.6830
si_en Dev loss: 0.7413 r:0.5935
ne_en Dev loss: 0.4588 r:0.7493
ru_en Dev loss: 0.4434 r:0.7271
Current avg r:0.6003 Best avg r: 0.6288
22:01:41,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:11,811 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:42,354 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3155
en_de Dev loss: 0.9008 r:0.1780
en_zh Dev loss: 0.8022 r:0.4311
ro_en Dev loss: 0.3548 r:0.8136
et_en Dev loss: 0.4231 r:0.6736
si_en Dev loss: 0.7909 r:0.5881
ne_en Dev loss: 0.4814 r:0.7442
ru_en Dev loss: 0.5026 r:0.7129
Current avg r:0.5916 Best avg r: 0.6288
22:09:14,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:44,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:15,473 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3183
en_de Dev loss: 0.8683 r:0.1699
en_zh Dev loss: 0.7106 r:0.4602
ro_en Dev loss: 0.3134 r:0.8218
et_en Dev loss: 0.4412 r:0.6814
si_en Dev loss: 0.7034 r:0.5890
ne_en Dev loss: 0.4056 r:0.7456
ru_en Dev loss: 0.3964 r:0.7446
Current avg r:0.6018 Best avg r: 0.6288
22:16:47,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:17,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:48,488 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3209
en_de Dev loss: 0.8808 r:0.1661
en_zh Dev loss: 0.7609 r:0.4377
ro_en Dev loss: 0.3286 r:0.8224
et_en Dev loss: 0.4370 r:0.6761
si_en Dev loss: 0.7276 r:0.5910
ne_en Dev loss: 0.4433 r:0.7526
ru_en Dev loss: 0.4342 r:0.7356
Current avg r:0.5974 Best avg r: 0.6288
22:24:20,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:50,711 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:21,405 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3350
en_de Dev loss: 0.8797 r:0.1535
en_zh Dev loss: 0.7510 r:0.4469
ro_en Dev loss: 0.3413 r:0.8191
et_en Dev loss: 0.4278 r:0.6795
si_en Dev loss: 0.7575 r:0.5848
ne_en Dev loss: 0.4171 r:0.7511
ru_en Dev loss: 0.4077 r:0.7512
Current avg r:0.5980 Best avg r: 0.6288
22:31:53,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:23,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:54,557 root INFO Epoch 5 Global steps: 44100 Train loss: 0.2975
en_de Dev loss: 0.8767 r:0.1755
en_zh Dev loss: 0.7318 r:0.4566
ro_en Dev loss: 0.3404 r:0.8194
et_en Dev loss: 0.4359 r:0.6688
si_en Dev loss: 0.8428 r:0.5724
ne_en Dev loss: 0.5326 r:0.7444
ru_en Dev loss: 0.4628 r:0.7239
Current avg r:0.5944 Best avg r: 0.6288
22:39:26,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:56,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:27,595 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3166
en_de Dev loss: 0.8690 r:0.1845
en_zh Dev loss: 0.7132 r:0.4509
ro_en Dev loss: 0.3078 r:0.8265
et_en Dev loss: 0.4653 r:0.6956
si_en Dev loss: 0.6436 r:0.5918
ne_en Dev loss: 0.3641 r:0.7560
ru_en Dev loss: 0.3809 r:0.7485
Current avg r:0.6077 Best avg r: 0.6288
22:46:59,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:29,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:00,563 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3018
en_de Dev loss: 0.9195 r:0.1785
en_zh Dev loss: 0.7773 r:0.4434
ro_en Dev loss: 0.3576 r:0.8163
et_en Dev loss: 0.4447 r:0.6790
si_en Dev loss: 0.7193 r:0.5848
ne_en Dev loss: 0.4122 r:0.7459
ru_en Dev loss: 0.4788 r:0.7192
Current avg r:0.5953 Best avg r: 0.6288
22:54:32,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:02,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:33,459 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3206
en_de Dev loss: 0.8888 r:0.1828
en_zh Dev loss: 0.7824 r:0.4390
ro_en Dev loss: 0.3568 r:0.8180
et_en Dev loss: 0.4709 r:0.6856
si_en Dev loss: 0.7228 r:0.5844
ne_en Dev loss: 0.4158 r:0.7506
ru_en Dev loss: 0.4337 r:0.7425
Current avg r:0.6004 Best avg r: 0.6288
23:02:05,120 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:35,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:06,303 root INFO Epoch 5 Global steps: 46900 Train loss: 0.3072
en_de Dev loss: 0.8949 r:0.1727
en_zh Dev loss: 0.7480 r:0.4513
ro_en Dev loss: 0.3386 r:0.8147
et_en Dev loss: 0.4416 r:0.6716
si_en Dev loss: 0.7344 r:0.5797
ne_en Dev loss: 0.4602 r:0.7461
ru_en Dev loss: 0.4217 r:0.7338
Current avg r:0.5957 Best avg r: 0.6288
23:09:38,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:09,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:40,27 root INFO Epoch 5 Global steps: 47600 Train loss: 0.3277
en_de Dev loss: 0.8921 r:0.1629
en_zh Dev loss: 0.7993 r:0.4428
ro_en Dev loss: 0.3745 r:0.8163
et_en Dev loss: 0.4440 r:0.6647
si_en Dev loss: 0.8687 r:0.5699
ne_en Dev loss: 0.5532 r:0.7432
ru_en Dev loss: 0.4741 r:0.7272
Current avg r:0.5896 Best avg r: 0.6288
23:17:12,467 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:43,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:13,646 root INFO Epoch 6 Global steps: 48300 Train loss: 0.2740
en_de Dev loss: 0.8646 r:0.1975
en_zh Dev loss: 0.7745 r:0.4378
ro_en Dev loss: 0.3472 r:0.8173
et_en Dev loss: 0.4725 r:0.6767
si_en Dev loss: 0.7812 r:0.5653
ne_en Dev loss: 0.4727 r:0.7422
ru_en Dev loss: 0.4355 r:0.7302
Current avg r:0.5953 Best avg r: 0.6288
23:24:45,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:16,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:46,671 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2916
en_de Dev loss: 0.8993 r:0.1968
en_zh Dev loss: 0.8025 r:0.4293
ro_en Dev loss: 0.3760 r:0.8115
et_en Dev loss: 0.4604 r:0.6689
si_en Dev loss: 0.8271 r:0.5619
ne_en Dev loss: 0.4935 r:0.7398
ru_en Dev loss: 0.4882 r:0.7167
Current avg r:0.5893 Best avg r: 0.6288
23:32:16,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:47,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:17,798 root INFO Epoch 6 Global steps: 49700 Train loss: 0.2832
en_de Dev loss: 0.8853 r:0.1820
en_zh Dev loss: 0.8221 r:0.4353
ro_en Dev loss: 0.3682 r:0.8157
et_en Dev loss: 0.4869 r:0.6731
si_en Dev loss: 0.8198 r:0.5693
ne_en Dev loss: 0.4653 r:0.7380
ru_en Dev loss: 0.4445 r:0.7324
Current avg r:0.5923 Best avg r: 0.6288
23:39:48,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:18,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:48,933 root INFO Epoch 6 Global steps: 50400 Train loss: 0.2884
en_de Dev loss: 0.9115 r:0.1455
en_zh Dev loss: 0.8075 r:0.4361
ro_en Dev loss: 0.3483 r:0.8155
et_en Dev loss: 0.4605 r:0.6580
si_en Dev loss: 0.8415 r:0.5593
ne_en Dev loss: 0.5551 r:0.7323
ru_en Dev loss: 0.5117 r:0.6926
Current avg r:0.5770 Best avg r: 0.6288
23:47:19,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:49,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:20,127 root INFO Epoch 6 Global steps: 51100 Train loss: 0.2794
en_de Dev loss: 0.8788 r:0.1834
en_zh Dev loss: 0.7761 r:0.4560
ro_en Dev loss: 0.3472 r:0.8161
et_en Dev loss: 0.4964 r:0.6742
si_en Dev loss: 0.7097 r:0.5791
ne_en Dev loss: 0.4282 r:0.7419
ru_en Dev loss: 0.4149 r:0.7405
Current avg r:0.5987 Best avg r: 0.6288
23:54:50,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:21,327 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:51,863 root INFO Epoch 6 Global steps: 51800 Train loss: 0.2771
en_de Dev loss: 0.8711 r:0.1989
en_zh Dev loss: 0.7900 r:0.4257
ro_en Dev loss: 0.3552 r:0.8097
et_en Dev loss: 0.4303 r:0.6660
si_en Dev loss: 0.8361 r:0.5626
ne_en Dev loss: 0.5346 r:0.7392
ru_en Dev loss: 0.4650 r:0.7124
Current avg r:0.5878 Best avg r: 0.6288
00:02:22,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:53,71 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:23,600 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2749
en_de Dev loss: 0.8958 r:0.1908
en_zh Dev loss: 0.7972 r:0.4512
ro_en Dev loss: 0.3619 r:0.8199
et_en Dev loss: 0.4501 r:0.6780
si_en Dev loss: 0.7372 r:0.5841
ne_en Dev loss: 0.4576 r:0.7340
ru_en Dev loss: 0.4635 r:0.7334
Current avg r:0.5988 Best avg r: 0.6288
00:09:54,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:24,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:55,333 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2896
en_de Dev loss: 0.8670 r:0.1997
en_zh Dev loss: 0.7903 r:0.4329
ro_en Dev loss: 0.3707 r:0.8158
et_en Dev loss: 0.4466 r:0.6655
si_en Dev loss: 0.8891 r:0.5596
ne_en Dev loss: 0.5178 r:0.7323
ru_en Dev loss: 0.4784 r:0.7173
Current avg r:0.5890 Best avg r: 0.6288
00:17:26,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:56,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:27,121 root INFO Epoch 6 Global steps: 53900 Train loss: 0.2734
en_de Dev loss: 0.9191 r:0.1705
en_zh Dev loss: 0.8461 r:0.4233
ro_en Dev loss: 0.3777 r:0.8182
et_en Dev loss: 0.4604 r:0.6682
si_en Dev loss: 0.8251 r:0.5735
ne_en Dev loss: 0.5018 r:0.7409
ru_en Dev loss: 0.4628 r:0.7332
Current avg r:0.5897 Best avg r: 0.6288
00:24:57,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:28,432 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:58,982 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2777
en_de Dev loss: 0.8701 r:0.2080
en_zh Dev loss: 0.8030 r:0.4379
ro_en Dev loss: 0.3748 r:0.8119
et_en Dev loss: 0.4940 r:0.6700
si_en Dev loss: 0.7987 r:0.5720
ne_en Dev loss: 0.5108 r:0.7414
ru_en Dev loss: 0.4342 r:0.7378
Current avg r:0.5970 Best avg r: 0.6288
00:32:29,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:00,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:30,834 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2692
en_de Dev loss: 0.8701 r:0.1889
en_zh Dev loss: 0.7332 r:0.4412
ro_en Dev loss: 0.3163 r:0.8169
et_en Dev loss: 0.4256 r:0.6783
si_en Dev loss: 0.7361 r:0.5708
ne_en Dev loss: 0.4523 r:0.7413
ru_en Dev loss: 0.4138 r:0.7335
Current avg r:0.5958 Best avg r: 0.6288
00:40:02,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:33,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:03,885 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2499
en_de Dev loss: 0.8886 r:0.1857
en_zh Dev loss: 0.7708 r:0.4481
ro_en Dev loss: 0.3466 r:0.8182
et_en Dev loss: 0.4801 r:0.6698
si_en Dev loss: 0.7354 r:0.5775
ne_en Dev loss: 0.4584 r:0.7394
ru_en Dev loss: 0.4175 r:0.7418
Current avg r:0.5972 Best avg r: 0.6288
00:47:34,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:05,187 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:35,712 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2448
en_de Dev loss: 0.8782 r:0.1769
en_zh Dev loss: 0.7554 r:0.4418
ro_en Dev loss: 0.3314 r:0.8125
et_en Dev loss: 0.4316 r:0.6673
si_en Dev loss: 0.7865 r:0.5584
ne_en Dev loss: 0.5035 r:0.7371
ru_en Dev loss: 0.4378 r:0.7287
Current avg r:0.5890 Best avg r: 0.6288
00:55:06,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:36,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:07,430 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2308
en_de Dev loss: 0.8842 r:0.1867
en_zh Dev loss: 0.7764 r:0.4339
ro_en Dev loss: 0.3458 r:0.8117
et_en Dev loss: 0.4642 r:0.6593
si_en Dev loss: 0.9213 r:0.5473
ne_en Dev loss: 0.5246 r:0.7329
ru_en Dev loss: 0.4557 r:0.7202
Current avg r:0.5846 Best avg r: 0.6288
01:02:38,171 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:08,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:39,123 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2527
en_de Dev loss: 0.8805 r:0.1840
en_zh Dev loss: 0.7683 r:0.4424
ro_en Dev loss: 0.3284 r:0.8117
et_en Dev loss: 0.4418 r:0.6609
si_en Dev loss: 0.8727 r:0.5507
ne_en Dev loss: 0.5432 r:0.7388
ru_en Dev loss: 0.4703 r:0.7144
Current avg r:0.5861 Best avg r: 0.6288
01:10:09,706 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:40,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:13:10,617 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2530
en_de Dev loss: 0.8878 r:0.1785
en_zh Dev loss: 0.8011 r:0.4457
ro_en Dev loss: 0.3334 r:0.8185
et_en Dev loss: 0.4669 r:0.6738
si_en Dev loss: 0.7754 r:0.5722
ne_en Dev loss: 0.4223 r:0.7363
ru_en Dev loss: 0.4309 r:0.7314
Current avg r:0.5938 Best avg r: 0.6288
01:17:41,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:11,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:20:42,234 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2531
en_de Dev loss: 0.9103 r:0.1630
en_zh Dev loss: 0.8355 r:0.4335
ro_en Dev loss: 0.3551 r:0.8204
et_en Dev loss: 0.4611 r:0.6730
si_en Dev loss: 0.8648 r:0.5671
ne_en Dev loss: 0.5394 r:0.7389
ru_en Dev loss: 0.5007 r:0.7152
Current avg r:0.5873 Best avg r: 0.6288
01:25:12,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:26:43,305 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:13,755 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2419
en_de Dev loss: 0.9015 r:0.1881
en_zh Dev loss: 0.8409 r:0.4263
ro_en Dev loss: 0.3593 r:0.8158
et_en Dev loss: 0.4781 r:0.6661
si_en Dev loss: 0.8460 r:0.5609
ne_en Dev loss: 0.4432 r:0.7412
ru_en Dev loss: 0.4789 r:0.7230
Current avg r:0.5888 Best avg r: 0.6288
01:32:44,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:34:14,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:35:45,189 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2371
en_de Dev loss: 0.8918 r:0.1824
en_zh Dev loss: 0.8013 r:0.4436
ro_en Dev loss: 0.3713 r:0.8133
et_en Dev loss: 0.4945 r:0.6589
si_en Dev loss: 0.8604 r:0.5600
ne_en Dev loss: 0.5158 r:0.7335
ru_en Dev loss: 0.4604 r:0.7285
Current avg r:0.5886 Best avg r: 0.6288
01:40:15,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:41:46,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:16,472 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2534
en_de Dev loss: 0.8808 r:0.1830
en_zh Dev loss: 0.7724 r:0.4525
ro_en Dev loss: 0.3213 r:0.8229
et_en Dev loss: 0.4767 r:0.6677
si_en Dev loss: 0.7333 r:0.5733
ne_en Dev loss: 0.4397 r:0.7279
ru_en Dev loss: 0.4049 r:0.7444
Current avg r:0.5960 Best avg r: 0.6288
01:47:49,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:49:21,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:50:53,346 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2413
en_de Dev loss: 0.8558 r:0.2037
en_zh Dev loss: 0.7418 r:0.4388
ro_en Dev loss: 0.3019 r:0.8192
et_en Dev loss: 0.4585 r:0.6541
si_en Dev loss: 0.7692 r:0.5569
ne_en Dev loss: 0.4365 r:0.7249
ru_en Dev loss: 0.3842 r:0.7415
Current avg r:0.5913 Best avg r: 0.6288
01:55:30,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:02,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:58:34,513 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2424
en_de Dev loss: 0.8598 r:0.2075
en_zh Dev loss: 0.7895 r:0.4448
ro_en Dev loss: 0.3546 r:0.8163
et_en Dev loss: 0.4828 r:0.6641
si_en Dev loss: 0.7894 r:0.5653
ne_en Dev loss: 0.4551 r:0.7325
ru_en Dev loss: 0.4141 r:0.7430
Current avg r:0.5962 Best avg r: 0.6288
02:03:13,308 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:04:44,963 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:06:16,646 root INFO Epoch 8 Global steps: 63700 Train loss: 0.2229
en_de Dev loss: 0.8684 r:0.1943
en_zh Dev loss: 0.8013 r:0.4385
ro_en Dev loss: 0.3446 r:0.8171
et_en Dev loss: 0.4881 r:0.6599
si_en Dev loss: 0.7823 r:0.5624
ne_en Dev loss: 0.4762 r:0.7325
ru_en Dev loss: 0.4250 r:0.7362
Current avg r:0.5916 Best avg r: 0.6288
02:10:53,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:12:25,54 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:13:56,661 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2064
en_de Dev loss: 0.8969 r:0.1781
en_zh Dev loss: 0.8404 r:0.4384
ro_en Dev loss: 0.3861 r:0.8135
et_en Dev loss: 0.4983 r:0.6509
si_en Dev loss: 0.9181 r:0.5520
ne_en Dev loss: 0.5750 r:0.7229
ru_en Dev loss: 0.4738 r:0.7278
Current avg r:0.5834 Best avg r: 0.6288
02:18:33,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:04,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:21:34,913 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2245
en_de Dev loss: 0.8803 r:0.1810
en_zh Dev loss: 0.7529 r:0.4586
ro_en Dev loss: 0.3475 r:0.8167
et_en Dev loss: 0.4996 r:0.6748
si_en Dev loss: 0.7487 r:0.5732
ne_en Dev loss: 0.4566 r:0.7333
ru_en Dev loss: 0.4087 r:0.7436
Current avg r:0.5973 Best avg r: 0.6288
02:26:09,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:27:40,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:11,119 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2296
en_de Dev loss: 0.8849 r:0.1797
en_zh Dev loss: 0.7814 r:0.4344
ro_en Dev loss: 0.3367 r:0.8185
et_en Dev loss: 0.4591 r:0.6638
si_en Dev loss: 0.8665 r:0.5523
ne_en Dev loss: 0.5438 r:0.7333
ru_en Dev loss: 0.4331 r:0.7324
Current avg r:0.5878 Best avg r: 0.6288
02:33:45,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:16,502 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:47,363 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2216
en_de Dev loss: 0.9104 r:0.1761
en_zh Dev loss: 0.8485 r:0.4180
ro_en Dev loss: 0.4005 r:0.8064
et_en Dev loss: 0.5062 r:0.6440
si_en Dev loss: 0.9429 r:0.5369
ne_en Dev loss: 0.5900 r:0.7269
ru_en Dev loss: 0.4926 r:0.7168
Current avg r:0.5750 Best avg r: 0.6288
02:41:21,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:42:52,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:23,514 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2251
en_de Dev loss: 0.9070 r:0.1867
en_zh Dev loss: 0.8288 r:0.4425
ro_en Dev loss: 0.3807 r:0.8139
et_en Dev loss: 0.5067 r:0.6618
si_en Dev loss: 0.9083 r:0.5561
ne_en Dev loss: 0.4864 r:0.7366
ru_en Dev loss: 0.4428 r:0.7478
Current avg r:0.5922 Best avg r: 0.6288
02:48:57,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:28,826 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:59,609 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2270
en_de Dev loss: 0.8952 r:0.1860
en_zh Dev loss: 0.8542 r:0.4160
ro_en Dev loss: 0.3773 r:0.8137
et_en Dev loss: 0.5131 r:0.6566
si_en Dev loss: 0.8534 r:0.5528
ne_en Dev loss: 0.4770 r:0.7356
ru_en Dev loss: 0.4366 r:0.7372
Current avg r:0.5854 Best avg r: 0.6288
02:56:33,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:58:04,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:59:35,239 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2249
en_de Dev loss: 0.8878 r:0.1857
en_zh Dev loss: 0.8399 r:0.4263
ro_en Dev loss: 0.3774 r:0.8101
et_en Dev loss: 0.4845 r:0.6544
si_en Dev loss: 0.8847 r:0.5503
ne_en Dev loss: 0.5286 r:0.7314
ru_en Dev loss: 0.4524 r:0.7269
Current avg r:0.5836 Best avg r: 0.6288
03:04:09,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:05:40,53 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:07:10,704 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2185
en_de Dev loss: 0.8930 r:0.1768
en_zh Dev loss: 0.8348 r:0.4321
ro_en Dev loss: 0.3653 r:0.8088
et_en Dev loss: 0.4743 r:0.6461
si_en Dev loss: 0.8953 r:0.5408
ne_en Dev loss: 0.5247 r:0.7274
ru_en Dev loss: 0.4948 r:0.7113
Current avg r:0.5776 Best avg r: 0.6288
03:11:43,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:14,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:14:44,728 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2098
en_de Dev loss: 0.8827 r:0.1931
en_zh Dev loss: 0.7741 r:0.4452
ro_en Dev loss: 0.3405 r:0.8128
et_en Dev loss: 0.4804 r:0.6583
si_en Dev loss: 0.7284 r:0.5617
ne_en Dev loss: 0.4396 r:0.7371
ru_en Dev loss: 0.4080 r:0.7421
Current avg r:0.5929 Best avg r: 0.6288
03:19:15,978 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:20:47,255 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:18,463 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2108
en_de Dev loss: 0.8636 r:0.1957
en_zh Dev loss: 0.7646 r:0.4382
ro_en Dev loss: 0.3398 r:0.8108
et_en Dev loss: 0.4868 r:0.6522
si_en Dev loss: 0.8315 r:0.5457
ne_en Dev loss: 0.5272 r:0.7304
ru_en Dev loss: 0.4083 r:0.7378
Current avg r:0.5873 Best avg r: 0.6288
03:26:52,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:24,162 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:29:55,432 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2251
en_de Dev loss: 0.8910 r:0.1904
en_zh Dev loss: 0.7892 r:0.4516
ro_en Dev loss: 0.3574 r:0.8117
et_en Dev loss: 0.4960 r:0.6555
si_en Dev loss: 0.8017 r:0.5502
ne_en Dev loss: 0.5014 r:0.7290
ru_en Dev loss: 0.4551 r:0.7247
Current avg r:0.5876 Best avg r: 0.6288
03:34:31,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:02,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:37:33,713 root INFO Epoch 9 Global steps: 72100 Train loss: 0.1920
en_de Dev loss: 0.8706 r:0.1966
en_zh Dev loss: 0.7353 r:0.4490
ro_en Dev loss: 0.3336 r:0.8113
et_en Dev loss: 0.4481 r:0.6459
si_en Dev loss: 0.8629 r:0.5408
ne_en Dev loss: 0.5740 r:0.7216
ru_en Dev loss: 0.4437 r:0.7228
Current avg r:0.5840 Best avg r: 0.6288
03:42:08,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:38,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:08,919 root INFO Epoch 9 Global steps: 72800 Train loss: 0.2039
en_de Dev loss: 0.8937 r:0.2107
en_zh Dev loss: 0.7895 r:0.4573
ro_en Dev loss: 0.3651 r:0.8117
et_en Dev loss: 0.4933 r:0.6626
si_en Dev loss: 0.8408 r:0.5567
ne_en Dev loss: 0.5139 r:0.7304
ru_en Dev loss: 0.4483 r:0.7396
Current avg r:0.5956 Best avg r: 0.6288
03:49:43,33 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:14,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:45,581 root INFO Epoch 9 Global steps: 73500 Train loss: 0.2005
en_de Dev loss: 0.8932 r:0.1865
en_zh Dev loss: 0.8095 r:0.4518
ro_en Dev loss: 0.3627 r:0.8151
et_en Dev loss: 0.5093 r:0.6626
si_en Dev loss: 0.8529 r:0.5520
ne_en Dev loss: 0.5190 r:0.7241
ru_en Dev loss: 0.4555 r:0.7329
Current avg r:0.5893 Best avg r: 0.6288
03:57:20,179 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:58:51,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:22,798 root INFO Epoch 9 Global steps: 74200 Train loss: 0.2005
en_de Dev loss: 0.8930 r:0.1839
en_zh Dev loss: 0.7979 r:0.4559
ro_en Dev loss: 0.3598 r:0.8139
et_en Dev loss: 0.4867 r:0.6584
si_en Dev loss: 0.8665 r:0.5430
ne_en Dev loss: 0.4824 r:0.7232
ru_en Dev loss: 0.4666 r:0.7222
Current avg r:0.5858 Best avg r: 0.6288
04:04:57,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:06:28,807 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:00,98 root INFO Epoch 9 Global steps: 74900 Train loss: 0.1998
en_de Dev loss: 0.8762 r:0.1949
en_zh Dev loss: 0.7405 r:0.4792
ro_en Dev loss: 0.3254 r:0.8173
et_en Dev loss: 0.4817 r:0.6771
si_en Dev loss: 0.7287 r:0.5652
ne_en Dev loss: 0.4452 r:0.7227
ru_en Dev loss: 0.4061 r:0.7467
Current avg r:0.6005 Best avg r: 0.6288
04:12:32,214 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:02,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:33,149 root INFO Epoch 9 Global steps: 75600 Train loss: 0.1918
en_de Dev loss: 0.8944 r:0.1790
en_zh Dev loss: 0.7889 r:0.4566
ro_en Dev loss: 0.3549 r:0.8136
et_en Dev loss: 0.4794 r:0.6621
si_en Dev loss: 0.8200 r:0.5518
ne_en Dev loss: 0.4891 r:0.7256
ru_en Dev loss: 0.4234 r:0.7469
Current avg r:0.5908 Best avg r: 0.6288
04:20:04,405 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:34,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:05,276 root INFO Epoch 9 Global steps: 76300 Train loss: 0.1977
en_de Dev loss: 0.8889 r:0.1962
en_zh Dev loss: 0.8197 r:0.4460
ro_en Dev loss: 0.3709 r:0.8103
et_en Dev loss: 0.5111 r:0.6431
si_en Dev loss: 0.9086 r:0.5380
ne_en Dev loss: 0.6259 r:0.7232
ru_en Dev loss: 0.4375 r:0.7374
Current avg r:0.5849 Best avg r: 0.6288
04:27:36,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:06,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:37,316 root INFO Epoch 9 Global steps: 77000 Train loss: 0.1958
en_de Dev loss: 0.8976 r:0.1777
en_zh Dev loss: 0.7910 r:0.4446
ro_en Dev loss: 0.3648 r:0.8102
et_en Dev loss: 0.4723 r:0.6381
si_en Dev loss: 1.0086 r:0.5302
ne_en Dev loss: 0.6018 r:0.7257
ru_en Dev loss: 0.4756 r:0.7242
Current avg r:0.5787 Best avg r: 0.6288
04:35:08,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:38,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:09,495 root INFO Epoch 9 Global steps: 77700 Train loss: 0.1920
en_de Dev loss: 0.9094 r:0.1832
en_zh Dev loss: 0.7923 r:0.4456
ro_en Dev loss: 0.3737 r:0.8078
et_en Dev loss: 0.4788 r:0.6401
si_en Dev loss: 0.8988 r:0.5352
ne_en Dev loss: 0.6086 r:0.7212
ru_en Dev loss: 0.4548 r:0.7325
Current avg r:0.5808 Best avg r: 0.6288
04:42:44,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:15,335 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:46,602 root INFO Epoch 9 Global steps: 78400 Train loss: 0.1908
en_de Dev loss: 0.8946 r:0.1858
en_zh Dev loss: 0.8029 r:0.4491
ro_en Dev loss: 0.3614 r:0.8134
et_en Dev loss: 0.5019 r:0.6585
si_en Dev loss: 0.8386 r:0.5485
ne_en Dev loss: 0.5022 r:0.7296
ru_en Dev loss: 0.4430 r:0.7366
Current avg r:0.5888 Best avg r: 0.6288
04:50:20,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:51:52,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:23,529 root INFO Epoch 9 Global steps: 79100 Train loss: 0.1965
en_de Dev loss: 0.8836 r:0.1885
en_zh Dev loss: 0.7802 r:0.4559
ro_en Dev loss: 0.3542 r:0.8136
et_en Dev loss: 0.4504 r:0.6571
si_en Dev loss: 0.8671 r:0.5403
ne_en Dev loss: 0.5590 r:0.7231
ru_en Dev loss: 0.4250 r:0.7450
Current avg r:0.5891 Best avg r: 0.6288
04:57:59,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:59:30,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:01:02,176 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1687
en_de Dev loss: 0.9067 r:0.1958
en_zh Dev loss: 0.8033 r:0.4587
ro_en Dev loss: 0.3736 r:0.8149
et_en Dev loss: 0.5232 r:0.6585
si_en Dev loss: 0.8439 r:0.5409
ne_en Dev loss: 0.5019 r:0.7242
ru_en Dev loss: 0.4253 r:0.7458
Current avg r:0.5912 Best avg r: 0.6288
05:05:33,636 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:07:04,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:36,230 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1839
en_de Dev loss: 0.8827 r:0.1887
en_zh Dev loss: 0.7747 r:0.4615
ro_en Dev loss: 0.3501 r:0.8181
et_en Dev loss: 0.5289 r:0.6629
si_en Dev loss: 0.8111 r:0.5471
ne_en Dev loss: 0.4514 r:0.7283
ru_en Dev loss: 0.4398 r:0.7308
Current avg r:0.5911 Best avg r: 0.6288
05:13:10,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:42,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:16:13,505 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1741
en_de Dev loss: 0.8716 r:0.1997
en_zh Dev loss: 0.7915 r:0.4519
ro_en Dev loss: 0.3487 r:0.8168
et_en Dev loss: 0.5139 r:0.6620
si_en Dev loss: 0.8136 r:0.5458
ne_en Dev loss: 0.4603 r:0.7243
ru_en Dev loss: 0.4088 r:0.7474
Current avg r:0.5926 Best avg r: 0.6288
05:20:48,126 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:22:19,452 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:50,755 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1806
en_de Dev loss: 0.8785 r:0.1864
en_zh Dev loss: 0.8216 r:0.4536
ro_en Dev loss: 0.4109 r:0.8121
et_en Dev loss: 0.4977 r:0.6488
si_en Dev loss: 1.0007 r:0.5336
ne_en Dev loss: 0.6659 r:0.7224
ru_en Dev loss: 0.5106 r:0.7188
Current avg r:0.5822 Best avg r: 0.6288
05:28:25,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:29:55,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:26,409 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1853
en_de Dev loss: 0.8863 r:0.2021
en_zh Dev loss: 0.7772 r:0.4696
ro_en Dev loss: 0.3647 r:0.8147
et_en Dev loss: 0.4859 r:0.6572
si_en Dev loss: 0.8549 r:0.5444
ne_en Dev loss: 0.5103 r:0.7236
ru_en Dev loss: 0.4415 r:0.7404
Current avg r:0.5931 Best avg r: 0.6288
05:35:57,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:28,236 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:58,703 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1805
en_de Dev loss: 0.8995 r:0.1973
en_zh Dev loss: 0.7997 r:0.4636
ro_en Dev loss: 0.3659 r:0.8104
et_en Dev loss: 0.5127 r:0.6682
si_en Dev loss: 0.8327 r:0.5492
ne_en Dev loss: 0.4693 r:0.7254
ru_en Dev loss: 0.4418 r:0.7388
Current avg r:0.5933 Best avg r: 0.6288
05:43:30,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:45:02,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:33,523 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1737
en_de Dev loss: 0.8957 r:0.1842
en_zh Dev loss: 0.7926 r:0.4456
ro_en Dev loss: 0.3376 r:0.8128
et_en Dev loss: 0.5071 r:0.6656
si_en Dev loss: 0.7485 r:0.5500
ne_en Dev loss: 0.4578 r:0.7200
ru_en Dev loss: 0.4081 r:0.7436
Current avg r:0.5888 Best avg r: 0.6288
05:51:08,152 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:39,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:54:10,816 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1718
en_de Dev loss: 0.9130 r:0.1709
en_zh Dev loss: 0.7640 r:0.4651
ro_en Dev loss: 0.3546 r:0.8139
et_en Dev loss: 0.4963 r:0.6604
si_en Dev loss: 0.7931 r:0.5490
ne_en Dev loss: 0.4825 r:0.7186
ru_en Dev loss: 0.3969 r:0.7552
Current avg r:0.5904 Best avg r: 0.6288
05:58:45,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:00:16,808 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:01:48,113 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1706
en_de Dev loss: 0.9117 r:0.1717
en_zh Dev loss: 0.8054 r:0.4458
ro_en Dev loss: 0.3560 r:0.8109
et_en Dev loss: 0.4772 r:0.6544
si_en Dev loss: 0.8626 r:0.5358
ne_en Dev loss: 0.5420 r:0.7206
ru_en Dev loss: 0.4562 r:0.7272
Current avg r:0.5809 Best avg r: 0.6288
06:06:22,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:52,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:09:23,18 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1831
en_de Dev loss: 0.9122 r:0.1622
en_zh Dev loss: 0.8167 r:0.4448
ro_en Dev loss: 0.3612 r:0.8149
et_en Dev loss: 0.4800 r:0.6624
si_en Dev loss: 0.8906 r:0.5387
ne_en Dev loss: 0.5658 r:0.7199
ru_en Dev loss: 0.4486 r:0.7381
Current avg r:0.5830 Best avg r: 0.6288
06:13:54,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:15:24,848 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:16:55,328 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1756
en_de Dev loss: 0.9319 r:0.1553
en_zh Dev loss: 0.8520 r:0.4495
ro_en Dev loss: 0.3919 r:0.8168
et_en Dev loss: 0.5021 r:0.6627
si_en Dev loss: 0.9409 r:0.5380
ne_en Dev loss: 0.6009 r:0.7205
ru_en Dev loss: 0.4549 r:0.7452
Current avg r:0.5840 Best avg r: 0.6288
06:21:26,482 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:22:57,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:28,699 root INFO Epoch 10 Global steps: 87500 Train loss: 0.1718
en_de Dev loss: 0.9363 r:0.1582
en_zh Dev loss: 0.8359 r:0.4445
ro_en Dev loss: 0.3823 r:0.8156
et_en Dev loss: 0.4822 r:0.6600
si_en Dev loss: 0.9080 r:0.5337
ne_en Dev loss: 0.5642 r:0.7160
ru_en Dev loss: 0.4329 r:0.7524
Current avg r:0.5829 Best avg r: 0.6288
06:29:04,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:36,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:32:07,570 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1606
en_de Dev loss: 0.9384 r:0.1737
en_zh Dev loss: 0.8332 r:0.4574
ro_en Dev loss: 0.3998 r:0.8127
et_en Dev loss: 0.5025 r:0.6588
si_en Dev loss: 0.9550 r:0.5338
ne_en Dev loss: 0.6409 r:0.7194
ru_en Dev loss: 0.4962 r:0.7354
Current avg r:0.5844 Best avg r: 0.6288
06:36:42,255 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:38:13,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:44,891 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1592
en_de Dev loss: 0.9089 r:0.1708
en_zh Dev loss: 0.7558 r:0.4709
ro_en Dev loss: 0.3392 r:0.8177
et_en Dev loss: 0.5044 r:0.6727
si_en Dev loss: 0.8098 r:0.5412
ne_en Dev loss: 0.4531 r:0.7212
ru_en Dev loss: 0.3996 r:0.7498
Current avg r:0.5920 Best avg r: 0.6288
06:44:20,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:52,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:47:23,725 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1625
en_de Dev loss: 0.9180 r:0.1661
en_zh Dev loss: 0.8095 r:0.4500
ro_en Dev loss: 0.3752 r:0.8163
et_en Dev loss: 0.4809 r:0.6638
si_en Dev loss: 0.9076 r:0.5410
ne_en Dev loss: 0.5529 r:0.7232
ru_en Dev loss: 0.4733 r:0.7360
Current avg r:0.5852 Best avg r: 0.6288
06:51:58,83 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:53:29,369 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:55:00,652 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1668
en_de Dev loss: 0.9088 r:0.1650
en_zh Dev loss: 0.7945 r:0.4488
ro_en Dev loss: 0.3392 r:0.8189
et_en Dev loss: 0.4854 r:0.6661
si_en Dev loss: 0.8191 r:0.5377
ne_en Dev loss: 0.5509 r:0.7147
ru_en Dev loss: 0.4391 r:0.7384
Current avg r:0.5842 Best avg r: 0.6288
06:59:35,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:01:06,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:37,634 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1622
en_de Dev loss: 0.9002 r:0.1782
en_zh Dev loss: 0.7905 r:0.4543
ro_en Dev loss: 0.3724 r:0.8175
et_en Dev loss: 0.5583 r:0.6726
si_en Dev loss: 0.8253 r:0.5434
ne_en Dev loss: 0.4987 r:0.7227
ru_en Dev loss: 0.3959 r:0.7520
Current avg r:0.5915 Best avg r: 0.6288
07:07:10,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:41,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:10:11,711 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1638
en_de Dev loss: 0.9007 r:0.1713
en_zh Dev loss: 0.7789 r:0.4544
ro_en Dev loss: 0.3480 r:0.8204
et_en Dev loss: 0.5200 r:0.6590
si_en Dev loss: 0.8312 r:0.5392
ne_en Dev loss: 0.4876 r:0.7186
ru_en Dev loss: 0.4303 r:0.7349
Current avg r:0.5854 Best avg r: 0.6288
07:14:43,96 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:16:13,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:44,227 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1552
en_de Dev loss: 0.9375 r:0.1877
en_zh Dev loss: 0.8028 r:0.4617
ro_en Dev loss: 0.3698 r:0.8155
et_en Dev loss: 0.4713 r:0.6608
si_en Dev loss: 0.8752 r:0.5418
ne_en Dev loss: 0.5537 r:0.7201
ru_en Dev loss: 0.4439 r:0.7455
Current avg r:0.5904 Best avg r: 0.6288
07:22:16,926 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:23:47,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:25:18,377 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1597
en_de Dev loss: 0.8958 r:0.1920
en_zh Dev loss: 0.8289 r:0.4475
ro_en Dev loss: 0.3558 r:0.8163
et_en Dev loss: 0.5100 r:0.6538
si_en Dev loss: 0.9304 r:0.5294
ne_en Dev loss: 0.5994 r:0.7134
ru_en Dev loss: 0.4770 r:0.7201
Current avg r:0.5818 Best avg r: 0.6288
07:29:49,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:31:20,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:50,538 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1611
en_de Dev loss: 0.8915 r:0.1787
en_zh Dev loss: 0.7737 r:0.4561
ro_en Dev loss: 0.3335 r:0.8162
et_en Dev loss: 0.4836 r:0.6583
si_en Dev loss: 0.8520 r:0.5301
ne_en Dev loss: 0.5403 r:0.7156
ru_en Dev loss: 0.4395 r:0.7316
Current avg r:0.5838 Best avg r: 0.6288
07:37:24,717 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:56,36 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:40:27,428 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1627
en_de Dev loss: 0.8894 r:0.2019
en_zh Dev loss: 0.7713 r:0.4635
ro_en Dev loss: 0.3399 r:0.8151
et_en Dev loss: 0.5062 r:0.6696
si_en Dev loss: 0.8198 r:0.5439
ne_en Dev loss: 0.5141 r:0.7158
ru_en Dev loss: 0.4117 r:0.7463
Current avg r:0.5937 Best avg r: 0.6288
07:45:04,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:46:35,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:48:07,334 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1519
en_de Dev loss: 0.8867 r:0.2048
en_zh Dev loss: 0.7958 r:0.4475
ro_en Dev loss: 0.3470 r:0.8119
et_en Dev loss: 0.5049 r:0.6681
si_en Dev loss: 0.8156 r:0.5448
ne_en Dev loss: 0.5057 r:0.7191
ru_en Dev loss: 0.4144 r:0.7468
Current avg r:0.5918 Best avg r: 0.6288
07:52:45,554 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:54:17,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:55:48,814 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1539
en_de Dev loss: 0.9103 r:0.1849
en_zh Dev loss: 0.8388 r:0.4418
ro_en Dev loss: 0.3864 r:0.8113
et_en Dev loss: 0.5021 r:0.6652
si_en Dev loss: 0.8801 r:0.5445
ne_en Dev loss: 0.5465 r:0.7099
ru_en Dev loss: 0.4549 r:0.7429
Current avg r:0.5858 Best avg r: 0.6288
08:00:24,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:01:55,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:27,54 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1470
en_de Dev loss: 0.9118 r:0.1543
en_zh Dev loss: 0.7701 r:0.4607
ro_en Dev loss: 0.3455 r:0.8149
et_en Dev loss: 0.4742 r:0.6588
si_en Dev loss: 0.8192 r:0.5413
ne_en Dev loss: 0.5512 r:0.6987
ru_en Dev loss: 0.4166 r:0.7499
Current avg r:0.5827 Best avg r: 0.6288
08:08:01,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:32,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:11:02,615 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1463
en_de Dev loss: 0.9158 r:0.1659
en_zh Dev loss: 0.7902 r:0.4568
ro_en Dev loss: 0.3596 r:0.8105
et_en Dev loss: 0.4864 r:0.6605
si_en Dev loss: 0.8533 r:0.5386
ne_en Dev loss: 0.5219 r:0.7099
ru_en Dev loss: 0.4433 r:0.7387
Current avg r:0.5830 Best avg r: 0.6288
08:15:33,850 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:17:04,371 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:18:34,929 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1430
en_de Dev loss: 0.9198 r:0.1657
en_zh Dev loss: 0.7574 r:0.4725
ro_en Dev loss: 0.3493 r:0.8132
et_en Dev loss: 0.4917 r:0.6613
si_en Dev loss: 0.8159 r:0.5472
ne_en Dev loss: 0.5028 r:0.7139
ru_en Dev loss: 0.3939 r:0.7547
Current avg r:0.5898 Best avg r: 0.6288
08:23:06,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:24:36,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:26:07,375 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1440
en_de Dev loss: 0.9322 r:0.1684
en_zh Dev loss: 0.7934 r:0.4565
ro_en Dev loss: 0.3635 r:0.8122
et_en Dev loss: 0.4941 r:0.6661
si_en Dev loss: 0.8680 r:0.5402
ne_en Dev loss: 0.5553 r:0.7148
ru_en Dev loss: 0.4317 r:0.7463
Current avg r:0.5863 Best avg r: 0.6288
08:30:38,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:32:09,225 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:33:39,765 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1451
en_de Dev loss: 0.9585 r:0.1652
en_zh Dev loss: 0.7829 r:0.4620
ro_en Dev loss: 0.3608 r:0.8134
et_en Dev loss: 0.4834 r:0.6614
si_en Dev loss: 0.8876 r:0.5411
ne_en Dev loss: 0.5884 r:0.7146
ru_en Dev loss: 0.4617 r:0.7354
Current avg r:0.5847 Best avg r: 0.6288
08:38:11,95 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:39:41,588 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:41:12,111 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1439
en_de Dev loss: 0.9287 r:0.1822
en_zh Dev loss: 0.7693 r:0.4793
ro_en Dev loss: 0.3553 r:0.8112
et_en Dev loss: 0.5134 r:0.6678
si_en Dev loss: 0.7920 r:0.5429
ne_en Dev loss: 0.5015 r:0.7150
ru_en Dev loss: 0.3972 r:0.7529
Current avg r:0.5930 Best avg r: 0.6288
08:45:44,958 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:47:16,195 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:48:47,419 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1450
en_de Dev loss: 0.9225 r:0.1594
en_zh Dev loss: 0.8063 r:0.4516
ro_en Dev loss: 0.3619 r:0.8142
et_en Dev loss: 0.4812 r:0.6572
si_en Dev loss: 0.9336 r:0.5277
ne_en Dev loss: 0.6256 r:0.7094
ru_en Dev loss: 0.4599 r:0.7356
Current avg r:0.5793 Best avg r: 0.6288
08:53:21,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:54:52,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:56:23,774 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1470
en_de Dev loss: 0.9037 r:0.1709
en_zh Dev loss: 0.7687 r:0.4659
ro_en Dev loss: 0.3405 r:0.8146
et_en Dev loss: 0.4942 r:0.6715
si_en Dev loss: 0.7953 r:0.5391
ne_en Dev loss: 0.5244 r:0.7138
ru_en Dev loss: 0.3855 r:0.7616
Current avg r:0.5910 Best avg r: 0.6288
09:00:57,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:02:28,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:04:00,121 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1403
en_de Dev loss: 0.9455 r:0.1483
en_zh Dev loss: 0.8371 r:0.4388
ro_en Dev loss: 0.3511 r:0.8159
et_en Dev loss: 0.4744 r:0.6582
si_en Dev loss: 0.9155 r:0.5292
ne_en Dev loss: 0.5712 r:0.7108
ru_en Dev loss: 0.4558 r:0.7377
Current avg r:0.5770 Best avg r: 0.6288
09:08:31,844 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:10:02,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:11:32,491 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1471
en_de Dev loss: 0.9216 r:0.1730
en_zh Dev loss: 0.8179 r:0.4515
ro_en Dev loss: 0.3638 r:0.8146
et_en Dev loss: 0.4638 r:0.6625
si_en Dev loss: 0.9096 r:0.5302
ne_en Dev loss: 0.6272 r:0.7081
ru_en Dev loss: 0.4485 r:0.7410
Current avg r:0.5830 Best avg r: 0.6288
09:16:04,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:17:34,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:19:04,967 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1277
en_de Dev loss: 0.9736 r:0.1467
en_zh Dev loss: 0.8196 r:0.4620
ro_en Dev loss: 0.3747 r:0.8153
et_en Dev loss: 0.4706 r:0.6697
si_en Dev loss: 0.8826 r:0.5371
ne_en Dev loss: 0.5988 r:0.7146
ru_en Dev loss: 0.4665 r:0.7416
Current avg r:0.5839 Best avg r: 0.6288
09:23:35,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:25:05,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:26:36,289 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1325
en_de Dev loss: 0.9633 r:0.1568
en_zh Dev loss: 0.8150 r:0.4637
ro_en Dev loss: 0.3852 r:0.8144
et_en Dev loss: 0.4900 r:0.6663
si_en Dev loss: 0.8973 r:0.5413
ne_en Dev loss: 0.5729 r:0.7131
ru_en Dev loss: 0.4669 r:0.7435
Current avg r:0.5856 Best avg r: 0.6288
09:31:06,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:32:37,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:34:07,748 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1319
en_de Dev loss: 0.9570 r:0.1392
en_zh Dev loss: 0.7847 r:0.4673
ro_en Dev loss: 0.3622 r:0.8141
et_en Dev loss: 0.4836 r:0.6656
si_en Dev loss: 0.8626 r:0.5369
ne_en Dev loss: 0.5375 r:0.7176
ru_en Dev loss: 0.4531 r:0.7402
Current avg r:0.5830 Best avg r: 0.6288
09:38:38,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:40:08,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:41:39,159 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1325
en_de Dev loss: 0.9303 r:0.1672
en_zh Dev loss: 0.7808 r:0.4620
ro_en Dev loss: 0.3540 r:0.8159
et_en Dev loss: 0.4707 r:0.6643
si_en Dev loss: 0.8569 r:0.5391
ne_en Dev loss: 0.5199 r:0.7144
ru_en Dev loss: 0.4284 r:0.7506
Current avg r:0.5876 Best avg r: 0.6288
09:46:09,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:47:39,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:49:09,968 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1310
en_de Dev loss: 0.9419 r:0.1626
en_zh Dev loss: 0.8020 r:0.4515
ro_en Dev loss: 0.3427 r:0.8158
et_en Dev loss: 0.4775 r:0.6628
si_en Dev loss: 0.8470 r:0.5301
ne_en Dev loss: 0.5125 r:0.7054
ru_en Dev loss: 0.4161 r:0.7479
Current avg r:0.5823 Best avg r: 0.6288
09:53:39,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:55:09,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:56:40,92 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1335
en_de Dev loss: 0.9445 r:0.1750
en_zh Dev loss: 0.8096 r:0.4589
ro_en Dev loss: 0.3841 r:0.8101
et_en Dev loss: 0.4878 r:0.6589
si_en Dev loss: 0.9704 r:0.5279
ne_en Dev loss: 0.6276 r:0.7136
ru_en Dev loss: 0.4705 r:0.7347
Current avg r:0.5827 Best avg r: 0.6288
10:01:10,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:02:40,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:04:10,247 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1361
en_de Dev loss: 0.9265 r:0.1617
en_zh Dev loss: 0.8208 r:0.4464
ro_en Dev loss: 0.3580 r:0.8119
et_en Dev loss: 0.4607 r:0.6573
si_en Dev loss: 0.9627 r:0.5252
ne_en Dev loss: 0.6386 r:0.7070
ru_en Dev loss: 0.4792 r:0.7247
Current avg r:0.5763 Best avg r: 0.6288
10:08:40,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:10:10,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:11:40,315 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1306
en_de Dev loss: 0.9096 r:0.1720
en_zh Dev loss: 0.7633 r:0.4709
ro_en Dev loss: 0.3472 r:0.8113
et_en Dev loss: 0.4765 r:0.6674
si_en Dev loss: 0.8193 r:0.5363
ne_en Dev loss: 0.5551 r:0.7071
ru_en Dev loss: 0.4267 r:0.7398
Current avg r:0.5864 Best avg r: 0.6288
10:16:10,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:17:40,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:19:11,1 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1269
en_de Dev loss: 0.9412 r:0.1588
en_zh Dev loss: 0.8648 r:0.4506
ro_en Dev loss: 0.3993 r:0.8077
et_en Dev loss: 0.5090 r:0.6470
si_en Dev loss: 0.9969 r:0.5283
ne_en Dev loss: 0.6831 r:0.7064
ru_en Dev loss: 0.5010 r:0.7268
Current avg r:0.5751 Best avg r: 0.6288
10:23:41,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:25:11,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:26:41,917 root INFO Epoch 13 Global steps: 109900 Train loss: 0.1315
en_de Dev loss: 0.9171 r:0.1693
en_zh Dev loss: 0.7768 r:0.4738
ro_en Dev loss: 0.3496 r:0.8169
et_en Dev loss: 0.4832 r:0.6638
si_en Dev loss: 0.8613 r:0.5384
ne_en Dev loss: 0.5498 r:0.7056
ru_en Dev loss: 0.4453 r:0.7431
Current avg r:0.5873 Best avg r: 0.6288
