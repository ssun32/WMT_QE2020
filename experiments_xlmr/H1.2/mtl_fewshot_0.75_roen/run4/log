14:44:54,43 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:20,8 root INFO 
id:en_zh cur r: 0.2304 best r: 0.2304
14:45:45,990 root INFO 
id:ro_en cur r: 0.5778 best r: 0.5778
14:45:58,987 root INFO 
id:et_en cur r: 0.4868 best r: 0.4868
14:46:12,6 root INFO 
id:si_en cur r: 0.4518 best r: 0.4518
14:46:25,19 root INFO 
id:ne_en cur r: 0.5800 best r: 0.5800
14:46:37,952 root INFO 
id:ru_en cur r: 0.4985 best r: 0.4985
14:46:37,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:08,812 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:48:08,817 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:48:08,823 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:48:08,827 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:48:08,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:48:08,837 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:48:08,850 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:48:21,843 root INFO Epoch 0 Global steps: 700 Train loss: 0.8188
en_de Dev loss: 0.9062 r:0.0902
en_zh Dev loss: 0.7790 r:0.2439
ro_en Dev loss: 0.6084 r:0.5993
et_en Dev loss: 0.5827 r:0.5313
si_en Dev loss: 0.6979 r:0.4433
ne_en Dev loss: 0.6128 r:0.5636
ru_en Dev loss: 0.6237 r:0.5600
Current avg r:0.4331 Best avg r: 0.4331
14:52:54,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:07,222 root INFO 
id:en_de cur r: 0.0700 best r: 0.0700
14:53:46,173 root INFO 
id:ro_en cur r: 0.5952 best r: 0.5952
14:54:38,118 root INFO 
id:ru_en cur r: 0.5034 best r: 0.5034
14:54:38,118 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:56:08,979 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:56:08,987 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:56:08,993 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:56:08,999 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:56:09,4 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:56:09,11 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:56:09,19 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:56:22,25 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8368
en_de Dev loss: 0.9330 r:0.0873
en_zh Dev loss: 0.7917 r:0.2435
ro_en Dev loss: 0.6240 r:0.6364
et_en Dev loss: 0.5699 r:0.5351
si_en Dev loss: 0.7422 r:0.4438
ne_en Dev loss: 0.6102 r:0.5498
ru_en Dev loss: 0.6256 r:0.6365
Current avg r:0.4475 Best avg r: 0.4475
15:00:54,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:20,419 root INFO 
id:en_zh cur r: 0.2571 best r: 0.2571
15:01:46,388 root INFO 
id:ro_en cur r: 0.6440 best r: 0.6440
15:01:59,404 root INFO 
id:et_en cur r: 0.5172 best r: 0.5172
15:02:12,419 root INFO 
id:si_en cur r: 0.4596 best r: 0.4596
15:02:25,432 root INFO 
id:ne_en cur r: 0.6145 best r: 0.6145
15:02:38,362 root INFO 
id:ru_en cur r: 0.6468 best r: 0.6468
15:02:38,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:09,294 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:04:09,301 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:04:09,306 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:04:09,310 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:04:09,316 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:04:09,320 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:04:09,325 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:04:22,322 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7449
en_de Dev loss: 0.9758 r:0.0758
en_zh Dev loss: 0.7808 r:0.2878
ro_en Dev loss: 0.5315 r:0.6774
et_en Dev loss: 0.4766 r:0.5959
si_en Dev loss: 0.7311 r:0.4779
ne_en Dev loss: 0.5269 r:0.6042
ru_en Dev loss: 0.5309 r:0.6941
Current avg r:0.4876 Best avg r: 0.4876
15:08:54,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:07,752 root INFO 
id:en_de cur r: 0.0738 best r: 0.0738
15:09:20,723 root INFO 
id:en_zh cur r: 0.3302 best r: 0.3302
15:09:46,696 root INFO 
id:ro_en cur r: 0.6882 best r: 0.6882
15:09:59,694 root INFO 
id:et_en cur r: 0.6166 best r: 0.6166
15:10:12,718 root INFO 
id:si_en cur r: 0.4711 best r: 0.4711
15:10:25,735 root INFO 
id:ne_en cur r: 0.6592 best r: 0.6592
15:10:38,877 root INFO 
id:ru_en cur r: 0.6865 best r: 0.6865
15:10:38,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:09,786 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:12:09,791 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:12:09,798 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:12:09,802 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:12:09,810 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:12:09,814 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:12:09,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:12:22,807 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6732
en_de Dev loss: 0.9629 r:0.1118
en_zh Dev loss: 0.7532 r:0.3432
ro_en Dev loss: 0.4556 r:0.7072
et_en Dev loss: 0.4234 r:0.6525
si_en Dev loss: 0.6533 r:0.5102
ne_en Dev loss: 0.4631 r:0.6656
ru_en Dev loss: 0.4773 r:0.7176
Current avg r:0.5297 Best avg r: 0.5297
15:16:55,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:47,75 root INFO 
id:ro_en cur r: 0.7048 best r: 0.7048
15:18:38,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:09,902 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6451
en_de Dev loss: 1.0375 r:0.1427
en_zh Dev loss: 0.8686 r:0.3490
ro_en Dev loss: 0.4935 r:0.7107
et_en Dev loss: 0.4234 r:0.6441
si_en Dev loss: 0.8608 r:0.4864
ne_en Dev loss: 0.5353 r:0.6223
ru_en Dev loss: 0.5702 r:0.6998
Current avg r:0.5221 Best avg r: 0.5297
15:24:42,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:24:55,262 root INFO 
id:en_de cur r: 0.1061 best r: 0.1061
15:25:08,236 root INFO 
id:en_zh cur r: 0.4041 best r: 0.4041
15:25:34,216 root INFO 
id:ro_en cur r: 0.7179 best r: 0.7179
15:25:47,224 root INFO 
id:et_en cur r: 0.6516 best r: 0.6516
15:26:00,262 root INFO 
id:si_en cur r: 0.5153 best r: 0.5153
15:26:13,284 root INFO 
id:ne_en cur r: 0.6806 best r: 0.6806
15:26:26,223 root INFO 
id:ru_en cur r: 0.7219 best r: 0.7219
15:26:26,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:27:57,131 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:27:57,136 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:27:57,141 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:27:57,145 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:27:57,150 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:27:57,154 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:27:57,159 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:28:10,149 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6587
en_de Dev loss: 0.9382 r:0.1574
en_zh Dev loss: 0.7320 r:0.4061
ro_en Dev loss: 0.4562 r:0.7256
et_en Dev loss: 0.3954 r:0.6689
si_en Dev loss: 0.6453 r:0.5313
ne_en Dev loss: 0.4267 r:0.6833
ru_en Dev loss: 0.4784 r:0.7337
Current avg r:0.5581 Best avg r: 0.5581
15:32:42,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:32:55,602 root INFO 
id:en_de cur r: 0.1747 best r: 0.1747
15:33:08,563 root INFO 
id:en_zh cur r: 0.4202 best r: 0.4202
15:33:34,539 root INFO 
id:ro_en cur r: 0.7273 best r: 0.7273
15:33:47,552 root INFO 
id:et_en cur r: 0.6641 best r: 0.6641
15:34:00,574 root INFO 
id:si_en cur r: 0.5351 best r: 0.5351
15:34:13,603 root INFO 
id:ne_en cur r: 0.6980 best r: 0.6980
15:34:26,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:35:57,406 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:35:57,412 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:35:57,416 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:35:57,420 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:35:57,425 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:35:57,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:35:57,435 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:36:10,425 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6112
en_de Dev loss: 0.8718 r:0.1791
en_zh Dev loss: 0.6776 r:0.4156
ro_en Dev loss: 0.4047 r:0.7354
et_en Dev loss: 0.3895 r:0.6811
si_en Dev loss: 0.6180 r:0.5451
ne_en Dev loss: 0.4135 r:0.6966
ru_en Dev loss: 0.4375 r:0.7243
Current avg r:0.5682 Best avg r: 0.5682
15:40:42,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:41:08,818 root INFO 
id:en_zh cur r: 0.4233 best r: 0.4233
15:41:34,858 root INFO 
id:ro_en cur r: 0.7337 best r: 0.7337
15:42:26,853 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:57,735 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:43:57,741 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:43:57,745 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:43:57,749 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:43:57,754 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:43:57,758 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:43:57,762 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:44:10,760 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6070
en_de Dev loss: 0.8921 r:0.2005
en_zh Dev loss: 0.6902 r:0.4288
ro_en Dev loss: 0.4332 r:0.7442
et_en Dev loss: 0.3779 r:0.6836
si_en Dev loss: 0.6947 r:0.5390
ne_en Dev loss: 0.4470 r:0.6835
ru_en Dev loss: 0.4683 r:0.7249
Current avg r:0.5721 Best avg r: 0.5721
15:48:43,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:56,96 root INFO 
id:en_de cur r: 0.1813 best r: 0.1813
15:49:35,58 root INFO 
id:ro_en cur r: 0.7451 best r: 0.7451
15:49:48,67 root INFO 
id:et_en cur r: 0.6829 best r: 0.6829
15:50:01,97 root INFO 
id:si_en cur r: 0.5445 best r: 0.5445
15:50:14,103 root INFO 
id:ne_en cur r: 0.7006 best r: 0.7006
15:50:27,35 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:57,842 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:51:57,847 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:51:57,851 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:51:57,855 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:51:57,859 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:51:57,864 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:51:57,867 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:52:10,843 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6113
en_de Dev loss: 0.9138 r:0.2049
en_zh Dev loss: 0.7628 r:0.4114
ro_en Dev loss: 0.4381 r:0.7589
et_en Dev loss: 0.3740 r:0.6973
si_en Dev loss: 0.6680 r:0.5576
ne_en Dev loss: 0.4532 r:0.6910
ru_en Dev loss: 0.5210 r:0.7187
Current avg r:0.5771 Best avg r: 0.5771
15:56:43,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:58:01,161 root INFO 
id:ne_en cur r: 0.7048 best r: 0.7048
15:58:14,103 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:44,962 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5643
en_de Dev loss: 0.9521 r:0.1994
en_zh Dev loss: 0.8013 r:0.4169
ro_en Dev loss: 0.4535 r:0.7499
et_en Dev loss: 0.3996 r:0.6851
si_en Dev loss: 0.7756 r:0.5442
ne_en Dev loss: 0.4717 r:0.6891
ru_en Dev loss: 0.5264 r:0.7280
Current avg r:0.5732 Best avg r: 0.5771
16:04:17,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:43,270 root INFO 
id:en_zh cur r: 0.4248 best r: 0.4248
16:05:09,241 root INFO 
id:ro_en cur r: 0.7558 best r: 0.7558
16:05:48,285 root INFO 
id:ne_en cur r: 0.7085 best r: 0.7085
16:06:01,221 root INFO 
id:ru_en cur r: 0.7283 best r: 0.7283
16:06:01,222 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:32,103 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:07:32,109 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:07:32,114 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:07:32,119 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:07:32,123 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:07:32,128 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:07:32,133 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:07:45,124 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5801
en_de Dev loss: 0.8968 r:0.2008
en_zh Dev loss: 0.7118 r:0.4324
ro_en Dev loss: 0.3930 r:0.7611
et_en Dev loss: 0.3709 r:0.6945
si_en Dev loss: 0.6643 r:0.5626
ne_en Dev loss: 0.4232 r:0.7010
ru_en Dev loss: 0.4270 r:0.7456
Current avg r:0.5854 Best avg r: 0.5854
16:12:18,661 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:12:31,647 root INFO 
id:en_de cur r: 0.1873 best r: 0.1873
16:12:44,618 root INFO 
id:en_zh cur r: 0.4333 best r: 0.4333
16:13:10,617 root INFO 
id:ro_en cur r: 0.7646 best r: 0.7646
16:13:23,633 root INFO 
id:et_en cur r: 0.6936 best r: 0.6936
16:13:36,640 root INFO 
id:si_en cur r: 0.5666 best r: 0.5666
16:13:49,646 root INFO 
id:ne_en cur r: 0.7253 best r: 0.7253
16:14:02,570 root INFO 
id:ru_en cur r: 0.7351 best r: 0.7351
16:14:02,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:33,410 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:15:33,415 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:15:33,420 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:15:33,424 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:15:33,429 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:15:33,433 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:15:33,438 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:15:46,435 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5334
en_de Dev loss: 0.8814 r:0.2135
en_zh Dev loss: 0.7049 r:0.4455
ro_en Dev loss: 0.3627 r:0.7688
et_en Dev loss: 0.3541 r:0.7078
si_en Dev loss: 0.6180 r:0.5769
ne_en Dev loss: 0.3906 r:0.7158
ru_en Dev loss: 0.4199 r:0.7509
Current avg r:0.5970 Best avg r: 0.5970
16:20:18,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:31,829 root INFO 
id:en_de cur r: 0.1917 best r: 0.1917
16:21:10,795 root INFO 
id:ro_en cur r: 0.7683 best r: 0.7683
16:21:36,832 root INFO 
id:si_en cur r: 0.5684 best r: 0.5684
16:22:02,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:23:33,668 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5603
en_de Dev loss: 0.9056 r:0.2153
en_zh Dev loss: 0.7452 r:0.4383
ro_en Dev loss: 0.3847 r:0.7737
et_en Dev loss: 0.3674 r:0.6969
si_en Dev loss: 0.7035 r:0.5687
ne_en Dev loss: 0.4333 r:0.7068
ru_en Dev loss: 0.4432 r:0.7497
Current avg r:0.5928 Best avg r: 0.5970
16:28:06,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:28:19,170 root INFO 
id:en_de cur r: 0.1932 best r: 0.1932
16:28:32,145 root INFO 
id:en_zh cur r: 0.4387 best r: 0.4387
16:28:58,144 root INFO 
id:ro_en cur r: 0.7786 best r: 0.7786
16:29:11,148 root INFO 
id:et_en cur r: 0.6945 best r: 0.6945
16:29:24,177 root INFO 
id:si_en cur r: 0.5970 best r: 0.5970
16:29:37,209 root INFO 
id:ne_en cur r: 0.7354 best r: 0.7354
16:29:50,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:31:21,28 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:31:21,33 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:31:21,37 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:31:21,42 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:31:21,46 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:31:21,50 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:31:21,55 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:31:34,29 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5243
en_de Dev loss: 0.8905 r:0.2200
en_zh Dev loss: 0.7225 r:0.4447
ro_en Dev loss: 0.3781 r:0.7794
et_en Dev loss: 0.3583 r:0.7063
si_en Dev loss: 0.6389 r:0.5850
ne_en Dev loss: 0.4324 r:0.7133
ru_en Dev loss: 0.4451 r:0.7491
Current avg r:0.5997 Best avg r: 0.5997
16:36:06,470 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:19,471 root INFO 
id:en_de cur r: 0.1959 best r: 0.1959
16:36:32,447 root INFO 
id:en_zh cur r: 0.4560 best r: 0.4560
16:36:58,454 root INFO 
id:ro_en cur r: 0.7904 best r: 0.7904
16:37:11,476 root INFO 
id:et_en cur r: 0.6950 best r: 0.6950
16:37:24,518 root INFO 
id:si_en cur r: 0.5998 best r: 0.5998
16:37:37,550 root INFO 
id:ne_en cur r: 0.7430 best r: 0.7430
16:37:50,503 root INFO 
id:ru_en cur r: 0.7439 best r: 0.7439
16:37:50,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:21,393 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:39:21,398 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:39:21,403 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:39:21,407 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:39:21,411 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:39:21,415 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:39:21,420 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:39:34,418 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5312
en_de Dev loss: 0.8931 r:0.2315
en_zh Dev loss: 0.7149 r:0.4551
ro_en Dev loss: 0.3388 r:0.7888
et_en Dev loss: 0.3755 r:0.7026
si_en Dev loss: 0.6122 r:0.5992
ne_en Dev loss: 0.4015 r:0.7305
ru_en Dev loss: 0.4191 r:0.7552
Current avg r:0.6090 Best avg r: 0.6090
16:44:06,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:37,844 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:08,718 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5427
en_de Dev loss: 0.8660 r:0.2331
en_zh Dev loss: 0.7277 r:0.4465
ro_en Dev loss: 0.3528 r:0.7878
et_en Dev loss: 0.3903 r:0.6928
si_en Dev loss: 0.7002 r:0.5868
ne_en Dev loss: 0.4433 r:0.7248
ru_en Dev loss: 0.4470 r:0.7448
Current avg r:0.6024 Best avg r: 0.6090
16:51:41,195 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:54,195 root INFO 
id:en_de cur r: 0.1979 best r: 0.1979
16:52:59,184 root INFO 
id:ne_en cur r: 0.7452 best r: 0.7452
16:53:12,115 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:54:42,977 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5763
en_de Dev loss: 0.8893 r:0.2302
en_zh Dev loss: 0.7425 r:0.4494
ro_en Dev loss: 0.4046 r:0.7868
et_en Dev loss: 0.3991 r:0.6993
si_en Dev loss: 0.6891 r:0.5979
ne_en Dev loss: 0.4301 r:0.7364
ru_en Dev loss: 0.4977 r:0.7526
Current avg r:0.6075 Best avg r: 0.6090
16:59:15,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:59:28,393 root INFO 
id:en_de cur r: 0.1995 best r: 0.1995
17:00:46,386 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:17,302 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:02:17,308 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:02:17,314 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:02:17,318 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:02:17,322 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:02:17,326 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:02:17,331 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:02:30,324 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5556
en_de Dev loss: 0.8570 r:0.2199
en_zh Dev loss: 0.7168 r:0.4595
ro_en Dev loss: 0.3574 r:0.7923
et_en Dev loss: 0.3651 r:0.7047
si_en Dev loss: 0.6598 r:0.5983
ne_en Dev loss: 0.3963 r:0.7405
ru_en Dev loss: 0.4198 r:0.7548
Current avg r:0.6100 Best avg r: 0.6100
17:07:02,709 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:15,701 root INFO 
id:en_de cur r: 0.2246 best r: 0.2246
17:07:54,674 root INFO 
id:ro_en cur r: 0.8061 best r: 0.8061
17:08:07,686 root INFO 
id:et_en cur r: 0.7082 best r: 0.7082
17:08:20,723 root INFO 
id:si_en cur r: 0.6087 best r: 0.6087
17:08:33,744 root INFO 
id:ne_en cur r: 0.7585 best r: 0.7585
17:08:46,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:10:17,542 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:10:17,548 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:10:17,552 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:10:17,557 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:10:17,561 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:10:17,567 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:10:17,571 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:10:30,564 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5245
en_de Dev loss: 0.8793 r:0.2452
en_zh Dev loss: 0.7247 r:0.4519
ro_en Dev loss: 0.3610 r:0.8010
et_en Dev loss: 0.3590 r:0.7134
si_en Dev loss: 0.6187 r:0.6080
ne_en Dev loss: 0.4119 r:0.7492
ru_en Dev loss: 0.4395 r:0.7558
Current avg r:0.6178 Best avg r: 0.6178
17:15:02,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:15:28,904 root INFO 
id:en_zh cur r: 0.4644 best r: 0.4644
17:16:33,865 root INFO 
id:ru_en cur r: 0.7440 best r: 0.7440
17:16:33,866 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:04,675 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:18:04,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:18:04,685 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:18:04,689 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:18:04,693 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:18:04,697 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:18:04,701 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:18:17,692 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5071
en_de Dev loss: 0.8427 r:0.2416
en_zh Dev loss: 0.6869 r:0.4647
ro_en Dev loss: 0.3348 r:0.7957
et_en Dev loss: 0.3580 r:0.7150
si_en Dev loss: 0.5918 r:0.6040
ne_en Dev loss: 0.3418 r:0.7542
ru_en Dev loss: 0.4150 r:0.7557
Current avg r:0.6187 Best avg r: 0.6187
17:22:50,46 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:03,47 root INFO 
id:en_de cur r: 0.2322 best r: 0.2322
17:23:16,18 root INFO 
id:en_zh cur r: 0.4648 best r: 0.4648
17:24:20,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:51,882 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5286
en_de Dev loss: 0.8551 r:0.2563
en_zh Dev loss: 0.6889 r:0.4609
ro_en Dev loss: 0.3675 r:0.7916
et_en Dev loss: 0.3603 r:0.7055
si_en Dev loss: 0.6742 r:0.5914
ne_en Dev loss: 0.4071 r:0.7427
ru_en Dev loss: 0.4536 r:0.7420
Current avg r:0.6129 Best avg r: 0.6187
17:30:24,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:50,180 root INFO 
id:en_zh cur r: 0.4848 best r: 0.4848
17:31:29,204 root INFO 
id:si_en cur r: 0.6136 best r: 0.6136
17:31:55,159 root INFO 
id:ru_en cur r: 0.7489 best r: 0.7489
17:31:55,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:25,974 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:33:25,980 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:33:25,985 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:33:25,988 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:33:25,993 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:33:25,996 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:33:26,1 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:33:38,991 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5255
en_de Dev loss: 0.8548 r:0.2132
en_zh Dev loss: 0.6366 r:0.4850
ro_en Dev loss: 0.3246 r:0.7966
et_en Dev loss: 0.3641 r:0.7135
si_en Dev loss: 0.5400 r:0.6152
ne_en Dev loss: 0.3396 r:0.7555
ru_en Dev loss: 0.3741 r:0.7610
Current avg r:0.6200 Best avg r: 0.6200
17:38:12,631 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:04,584 root INFO 
id:et_en cur r: 0.7106 best r: 0.7106
17:39:17,604 root INFO 
id:si_en cur r: 0.6219 best r: 0.6219
17:39:30,617 root INFO 
id:ne_en cur r: 0.7588 best r: 0.7588
17:39:43,553 root INFO 
id:ru_en cur r: 0.7574 best r: 0.7574
17:39:43,553 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:14,363 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:41:14,369 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:41:14,373 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:41:14,378 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:41:14,384 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:41:14,388 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:41:14,392 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:41:27,391 root INFO Epoch 2 Global steps: 16100 Train loss: 0.5363
en_de Dev loss: 0.8459 r:0.2242
en_zh Dev loss: 0.6785 r:0.4808
ro_en Dev loss: 0.3249 r:0.8029
et_en Dev loss: 0.3581 r:0.7180
si_en Dev loss: 0.5770 r:0.6139
ne_en Dev loss: 0.3566 r:0.7542
ru_en Dev loss: 0.3737 r:0.7628
Current avg r:0.6224 Best avg r: 0.6224
17:45:59,797 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:30,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:01,589 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4629
en_de Dev loss: 0.8946 r:0.2486
en_zh Dev loss: 0.7400 r:0.4651
ro_en Dev loss: 0.3933 r:0.7937
et_en Dev loss: 0.4097 r:0.6942
si_en Dev loss: 0.8017 r:0.5832
ne_en Dev loss: 0.4619 r:0.7361
ru_en Dev loss: 0.5456 r:0.7282
Current avg r:0.6070 Best avg r: 0.6224
17:53:33,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:55:04,873 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:35,721 root INFO Epoch 2 Global steps: 17500 Train loss: 0.5026
en_de Dev loss: 0.9124 r:0.2383
en_zh Dev loss: 0.8783 r:0.4453
ro_en Dev loss: 0.4700 r:0.7882
et_en Dev loss: 0.4527 r:0.6873
si_en Dev loss: 0.9798 r:0.5675
ne_en Dev loss: 0.5857 r:0.7258
ru_en Dev loss: 0.5991 r:0.7130
Current avg r:0.5951 Best avg r: 0.6224
18:01:08,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:01:59,937 root INFO 
id:ro_en cur r: 0.8085 best r: 0.8085
18:02:38,987 root INFO 
id:ne_en cur r: 0.7590 best r: 0.7590
18:02:51,918 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:22,756 root INFO Epoch 2 Global steps: 18200 Train loss: 0.4911
en_de Dev loss: 0.8430 r:0.2461
en_zh Dev loss: 0.6654 r:0.4740
ro_en Dev loss: 0.3251 r:0.8061
et_en Dev loss: 0.3622 r:0.7082
si_en Dev loss: 0.6019 r:0.6106
ne_en Dev loss: 0.3703 r:0.7538
ru_en Dev loss: 0.4037 r:0.7545
Current avg r:0.6219 Best avg r: 0.6224
18:08:55,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:47,91 root INFO 
id:ro_en cur r: 0.8098 best r: 0.8098
18:10:00,107 root INFO 
id:et_en cur r: 0.7125 best r: 0.7125
18:10:26,163 root INFO 
id:ne_en cur r: 0.7605 best r: 0.7605
18:10:39,97 root INFO 
id:ru_en cur r: 0.7660 best r: 0.7660
18:10:39,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:09,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:12:09,956 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:12:09,960 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:12:09,965 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:12:09,969 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:12:09,972 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:12:09,976 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:12:22,959 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4688
en_de Dev loss: 0.8589 r:0.2486
en_zh Dev loss: 0.7148 r:0.4648
ro_en Dev loss: 0.3729 r:0.8019
et_en Dev loss: 0.3679 r:0.7142
si_en Dev loss: 0.6691 r:0.6078
ne_en Dev loss: 0.3660 r:0.7577
ru_en Dev loss: 0.3996 r:0.7698
Current avg r:0.6235 Best avg r: 0.6235
18:16:55,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:08,366 root INFO 
id:en_de cur r: 0.2439 best r: 0.2439
18:17:47,323 root INFO 
id:ro_en cur r: 0.8127 best r: 0.8127
18:18:00,334 root INFO 
id:et_en cur r: 0.7183 best r: 0.7183
18:18:26,375 root INFO 
id:ne_en cur r: 0.7639 best r: 0.7639
18:18:39,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:10,114 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:20:10,119 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:20:10,124 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:20:10,129 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:20:10,135 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:20:10,139 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:20:10,143 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:20:23,135 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4899
en_de Dev loss: 0.8579 r:0.2650
en_zh Dev loss: 0.7542 r:0.4490
ro_en Dev loss: 0.3326 r:0.8091
et_en Dev loss: 0.3413 r:0.7240
si_en Dev loss: 0.6385 r:0.6167
ne_en Dev loss: 0.3561 r:0.7612
ru_en Dev loss: 0.4237 r:0.7525
Current avg r:0.6253 Best avg r: 0.6253
18:24:55,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:26,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:57,385 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4689
en_de Dev loss: 0.9031 r:0.2506
en_zh Dev loss: 0.7484 r:0.4658
ro_en Dev loss: 0.3806 r:0.8040
et_en Dev loss: 0.3799 r:0.7082
si_en Dev loss: 0.6857 r:0.6173
ne_en Dev loss: 0.4165 r:0.7587
ru_en Dev loss: 0.4442 r:0.7609
Current avg r:0.6237 Best avg r: 0.6253
18:32:29,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:00,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:31,597 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4721
en_de Dev loss: 0.8390 r:0.2374
en_zh Dev loss: 0.6723 r:0.4582
ro_en Dev loss: 0.3231 r:0.8049
et_en Dev loss: 0.3614 r:0.7056
si_en Dev loss: 0.6543 r:0.6003
ne_en Dev loss: 0.4057 r:0.7515
ru_en Dev loss: 0.4161 r:0.7386
Current avg r:0.6138 Best avg r: 0.6253
18:40:04,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:40:56,82 root INFO 
id:ro_en cur r: 0.8160 best r: 0.8160
18:41:48,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:18,888 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4974
en_de Dev loss: 0.8719 r:0.2445
en_zh Dev loss: 0.7727 r:0.4634
ro_en Dev loss: 0.3726 r:0.8095
et_en Dev loss: 0.3703 r:0.7117
si_en Dev loss: 0.7351 r:0.6125
ne_en Dev loss: 0.4604 r:0.7597
ru_en Dev loss: 0.5126 r:0.7431
Current avg r:0.6206 Best avg r: 0.6253
18:47:51,367 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:56,306 root INFO 
id:si_en cur r: 0.6225 best r: 0.6225
18:49:22,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:53,23 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4580
en_de Dev loss: 0.8798 r:0.2511
en_zh Dev loss: 0.7804 r:0.4614
ro_en Dev loss: 0.3915 r:0.8064
et_en Dev loss: 0.3905 r:0.7036
si_en Dev loss: 0.6790 r:0.6123
ne_en Dev loss: 0.3994 r:0.7592
ru_en Dev loss: 0.5234 r:0.7327
Current avg r:0.6181 Best avg r: 0.6253
18:55:25,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:56,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:27,204 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4639
en_de Dev loss: 0.8600 r:0.2551
en_zh Dev loss: 0.7145 r:0.4728
ro_en Dev loss: 0.4001 r:0.8006
et_en Dev loss: 0.3988 r:0.6973
si_en Dev loss: 0.8137 r:0.5979
ne_en Dev loss: 0.5387 r:0.7487
ru_en Dev loss: 0.5011 r:0.7350
Current avg r:0.6154 Best avg r: 0.6253
19:02:59,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:12,537 root INFO 
id:en_de cur r: 0.2460 best r: 0.2460
19:04:17,563 root INFO 
id:ne_en cur r: 0.7673 best r: 0.7673
19:04:30,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:01,328 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4332
en_de Dev loss: 0.8697 r:0.2622
en_zh Dev loss: 0.7389 r:0.4733
ro_en Dev loss: 0.3506 r:0.8093
et_en Dev loss: 0.3689 r:0.7046
si_en Dev loss: 0.7690 r:0.6082
ne_en Dev loss: 0.4338 r:0.7656
ru_en Dev loss: 0.4745 r:0.7431
Current avg r:0.6237 Best avg r: 0.6253
19:10:35,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:48,79 root INFO 
id:en_de cur r: 0.2589 best r: 0.2589
19:12:05,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:36,822 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4246
en_de Dev loss: 0.8575 r:0.2707
en_zh Dev loss: 0.7471 r:0.4543
ro_en Dev loss: 0.3657 r:0.8061
et_en Dev loss: 0.3740 r:0.7050
si_en Dev loss: 0.7253 r:0.6072
ne_en Dev loss: 0.4144 r:0.7552
ru_en Dev loss: 0.5412 r:0.7157
Current avg r:0.6163 Best avg r: 0.6253
19:18:09,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:27,240 root INFO 
id:ne_en cur r: 0.7688 best r: 0.7688
19:19:40,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:11,3 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4364
en_de Dev loss: 0.8535 r:0.2472
en_zh Dev loss: 0.7035 r:0.4652
ro_en Dev loss: 0.3433 r:0.8094
et_en Dev loss: 0.3732 r:0.7034
si_en Dev loss: 0.6254 r:0.6198
ne_en Dev loss: 0.4058 r:0.7636
ru_en Dev loss: 0.4162 r:0.7507
Current avg r:0.6228 Best avg r: 0.6253
19:25:43,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:14,301 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:45,144 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4274
en_de Dev loss: 0.8679 r:0.2677
en_zh Dev loss: 0.7229 r:0.4582
ro_en Dev loss: 0.3663 r:0.8020
et_en Dev loss: 0.3877 r:0.6968
si_en Dev loss: 0.7008 r:0.6076
ne_en Dev loss: 0.4317 r:0.7570
ru_en Dev loss: 0.5295 r:0.7045
Current avg r:0.6134 Best avg r: 0.6253
19:33:17,555 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:48,487 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:19,356 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4353
en_de Dev loss: 0.8328 r:0.2562
en_zh Dev loss: 0.6925 r:0.4663
ro_en Dev loss: 0.3434 r:0.8064
et_en Dev loss: 0.3650 r:0.7066
si_en Dev loss: 0.7069 r:0.6155
ne_en Dev loss: 0.4526 r:0.7613
ru_en Dev loss: 0.4329 r:0.7400
Current avg r:0.6218 Best avg r: 0.6253
19:40:51,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:04,829 root INFO 
id:en_de cur r: 0.2630 best r: 0.2630
19:42:22,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:53,590 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4505
en_de Dev loss: 0.8330 r:0.2697
en_zh Dev loss: 0.7191 r:0.4639
ro_en Dev loss: 0.3338 r:0.8090
et_en Dev loss: 0.3647 r:0.7070
si_en Dev loss: 0.6058 r:0.6191
ne_en Dev loss: 0.4162 r:0.7573
ru_en Dev loss: 0.4334 r:0.7441
Current avg r:0.6243 Best avg r: 0.6253
19:48:26,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:39,58 root INFO 
id:en_de cur r: 0.2674 best r: 0.2674
19:49:56,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:27,827 root INFO Epoch 3 Global steps: 28000 Train loss: 0.4356
en_de Dev loss: 0.8627 r:0.2719
en_zh Dev loss: 0.7769 r:0.4561
ro_en Dev loss: 0.3980 r:0.7991
et_en Dev loss: 0.4059 r:0.6931
si_en Dev loss: 0.7705 r:0.6068
ne_en Dev loss: 0.4815 r:0.7546
ru_en Dev loss: 0.5056 r:0.7239
Current avg r:0.6151 Best avg r: 0.6253
19:56:00,200 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:13,205 root INFO 
id:en_de cur r: 0.2860 best r: 0.2860
19:57:31,130 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:01,999 root INFO Epoch 3 Global steps: 28700 Train loss: 0.4134
en_de Dev loss: 0.8436 r:0.2800
en_zh Dev loss: 0.7701 r:0.4581
ro_en Dev loss: 0.3750 r:0.8065
et_en Dev loss: 0.3798 r:0.7001
si_en Dev loss: 0.7704 r:0.6158
ne_en Dev loss: 0.5220 r:0.7574
ru_en Dev loss: 0.4661 r:0.7331
Current avg r:0.6216 Best avg r: 0.6253
20:03:34,426 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:05,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:36,154 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_de.lang_agnost_mlp.dev.best.scores
20:06:36,160 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/en_zh.lang_agnost_mlp.dev.best.scores
20:06:36,165 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ro_en.lang_agnost_mlp.dev.best.scores
20:06:36,169 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/et_en.lang_agnost_mlp.dev.best.scores
20:06:36,174 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/si_en.lang_agnost_mlp.dev.best.scores
20:06:36,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ne_en.lang_agnost_mlp.dev.best.scores
20:06:36,183 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_roen/run4/ru_en.lang_agnost_mlp.dev.best.scores
20:06:49,173 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4048
en_de Dev loss: 0.8321 r:0.2656
en_zh Dev loss: 0.7427 r:0.4672
ro_en Dev loss: 0.3971 r:0.8052
et_en Dev loss: 0.4524 r:0.7046
si_en Dev loss: 0.5840 r:0.6235
ne_en Dev loss: 0.3679 r:0.7606
ru_en Dev loss: 0.4053 r:0.7557
Current avg r:0.6261 Best avg r: 0.6261
20:11:21,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:13,490 root INFO 
id:ro_en cur r: 0.8173 best r: 0.8173
20:12:39,494 root INFO 
id:si_en cur r: 0.6235 best r: 0.6235
20:13:05,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:36,284 root INFO Epoch 3 Global steps: 30100 Train loss: 0.4619
en_de Dev loss: 0.8711 r:0.2074
en_zh Dev loss: 0.6880 r:0.4739
ro_en Dev loss: 0.3400 r:0.8103
et_en Dev loss: 0.4024 r:0.6930
si_en Dev loss: 0.5727 r:0.6221
ne_en Dev loss: 0.3600 r:0.7594
ru_en Dev loss: 0.4001 r:0.7393
Current avg r:0.6151 Best avg r: 0.6261
20:19:08,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:20:39,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:22:10,505 root INFO Epoch 3 Global steps: 30800 Train loss: 0.4151
en_de Dev loss: 0.8432 r:0.2556
en_zh Dev loss: 0.7193 r:0.4650
ro_en Dev loss: 0.3511 r:0.8095
et_en Dev loss: 0.3851 r:0.6974
si_en Dev loss: 0.7027 r:0.6155
ne_en Dev loss: 0.3864 r:0.7583
ru_en Dev loss: 0.4523 r:0.7377
Current avg r:0.6199 Best avg r: 0.6261
20:26:42,961 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:13,822 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:44,692 root INFO Epoch 3 Global steps: 31500 Train loss: 0.4137
en_de Dev loss: 0.8351 r:0.2475
en_zh Dev loss: 0.6774 r:0.4801
ro_en Dev loss: 0.3364 r:0.8116
et_en Dev loss: 0.3904 r:0.6997
si_en Dev loss: 0.6391 r:0.6144
ne_en Dev loss: 0.3591 r:0.7644
ru_en Dev loss: 0.3911 r:0.7550
Current avg r:0.6247 Best avg r: 0.6261
20:34:18,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:49,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:20,48 root INFO Epoch 4 Global steps: 32200 Train loss: 0.4289
en_de Dev loss: 0.8593 r:0.2372
en_zh Dev loss: 0.7141 r:0.4705
ro_en Dev loss: 0.3464 r:0.8103
et_en Dev loss: 0.3904 r:0.6928
si_en Dev loss: 0.7937 r:0.6020
ne_en Dev loss: 0.4024 r:0.7610
ru_en Dev loss: 0.5229 r:0.7121
Current avg r:0.6123 Best avg r: 0.6261
20:41:52,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:23,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:54,77 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3921
en_de Dev loss: 0.8702 r:0.2580
en_zh Dev loss: 0.7433 r:0.4552
ro_en Dev loss: 0.3581 r:0.8073
et_en Dev loss: 0.4011 r:0.6924
si_en Dev loss: 0.7606 r:0.6032
ne_en Dev loss: 0.4264 r:0.7588
ru_en Dev loss: 0.5145 r:0.7136
Current avg r:0.6127 Best avg r: 0.6261
20:49:26,487 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:57,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:28,182 root INFO Epoch 4 Global steps: 33600 Train loss: 0.4037
en_de Dev loss: 0.8529 r:0.2448
en_zh Dev loss: 0.6895 r:0.4759
ro_en Dev loss: 0.3464 r:0.8117
et_en Dev loss: 0.3887 r:0.6954
si_en Dev loss: 0.7048 r:0.6121
ne_en Dev loss: 0.4230 r:0.7533
ru_en Dev loss: 0.4677 r:0.7242
Current avg r:0.6168 Best avg r: 0.6261
20:57:00,593 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:31,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:00:02,219 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3705
en_de Dev loss: 0.8545 r:0.2329
en_zh Dev loss: 0.7318 r:0.4652
ro_en Dev loss: 0.3499 r:0.8065
et_en Dev loss: 0.4008 r:0.6872
si_en Dev loss: 0.7228 r:0.6057
ne_en Dev loss: 0.4349 r:0.7522
ru_en Dev loss: 0.4483 r:0.7330
Current avg r:0.6118 Best avg r: 0.6261
21:04:34,748 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:06:05,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:36,448 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3904
en_de Dev loss: 0.8463 r:0.2476
en_zh Dev loss: 0.7297 r:0.4511
ro_en Dev loss: 0.3329 r:0.8094
et_en Dev loss: 0.4044 r:0.6891
si_en Dev loss: 0.6839 r:0.6083
ne_en Dev loss: 0.4667 r:0.7521
ru_en Dev loss: 0.4717 r:0.7196
Current avg r:0.6110 Best avg r: 0.6261
21:12:08,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:39,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:15:10,713 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3927
en_de Dev loss: 0.8543 r:0.2686
en_zh Dev loss: 0.7433 r:0.4564
ro_en Dev loss: 0.3747 r:0.8102
et_en Dev loss: 0.4155 r:0.6862
si_en Dev loss: 0.7902 r:0.6082
ne_en Dev loss: 0.4466 r:0.7538
ru_en Dev loss: 0.5341 r:0.7111
Current avg r:0.6135 Best avg r: 0.6261
21:19:43,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:21:14,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:44,837 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3711
en_de Dev loss: 0.8488 r:0.2475
en_zh Dev loss: 0.7924 r:0.4399
ro_en Dev loss: 0.3652 r:0.8070
et_en Dev loss: 0.4081 r:0.6863
si_en Dev loss: 0.7322 r:0.6086
ne_en Dev loss: 0.4114 r:0.7514
ru_en Dev loss: 0.4956 r:0.7163
Current avg r:0.6082 Best avg r: 0.6261
21:27:17,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:48,152 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:30:18,978 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3812
en_de Dev loss: 0.8355 r:0.2492
en_zh Dev loss: 0.7422 r:0.4390
ro_en Dev loss: 0.3492 r:0.8058
et_en Dev loss: 0.4066 r:0.6870
si_en Dev loss: 0.6901 r:0.6090
ne_en Dev loss: 0.4287 r:0.7445
ru_en Dev loss: 0.4565 r:0.7192
Current avg r:0.6077 Best avg r: 0.6261
21:34:51,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:36:22,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:53,100 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3791
en_de Dev loss: 0.8369 r:0.2629
en_zh Dev loss: 0.7233 r:0.4530
ro_en Dev loss: 0.3599 r:0.8098
et_en Dev loss: 0.4098 r:0.6831
si_en Dev loss: 0.6787 r:0.6069
ne_en Dev loss: 0.4456 r:0.7463
ru_en Dev loss: 0.4543 r:0.7228
Current avg r:0.6121 Best avg r: 0.6261
21:42:25,560 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:56,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:45:27,287 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3881
en_de Dev loss: 0.8533 r:0.2636
en_zh Dev loss: 0.7897 r:0.4361
ro_en Dev loss: 0.3860 r:0.8040
et_en Dev loss: 0.4250 r:0.6760
si_en Dev loss: 0.7626 r:0.5956
ne_en Dev loss: 0.4904 r:0.7482
ru_en Dev loss: 0.4503 r:0.7312
Current avg r:0.6078 Best avg r: 0.6261
21:49:59,766 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:51:30,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:53:01,458 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3886
en_de Dev loss: 0.8432 r:0.2779
en_zh Dev loss: 0.7481 r:0.4504
ro_en Dev loss: 0.3431 r:0.8104
et_en Dev loss: 0.4055 r:0.6744
si_en Dev loss: 0.6678 r:0.6121
ne_en Dev loss: 0.4663 r:0.7480
ru_en Dev loss: 0.4464 r:0.7314
Current avg r:0.6149 Best avg r: 0.6261
21:57:35,125 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:59:06,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:00:36,855 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3429
en_de Dev loss: 0.8315 r:0.2889
en_zh Dev loss: 0.7285 r:0.4573
ro_en Dev loss: 0.3563 r:0.8117
et_en Dev loss: 0.4179 r:0.6739
si_en Dev loss: 0.6849 r:0.6131
ne_en Dev loss: 0.4465 r:0.7457
ru_en Dev loss: 0.4656 r:0.7229
Current avg r:0.6162 Best avg r: 0.6261
22:05:09,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:06:40,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:08:10,998 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3459
en_de Dev loss: 0.8961 r:0.2742
en_zh Dev loss: 0.8615 r:0.4429
ro_en Dev loss: 0.4444 r:0.7994
et_en Dev loss: 0.4665 r:0.6623
si_en Dev loss: 0.8963 r:0.5900
ne_en Dev loss: 0.5729 r:0.7401
ru_en Dev loss: 0.5864 r:0.6930
Current avg r:0.6003 Best avg r: 0.6261
22:12:43,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:14:14,323 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:45,175 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3401
en_de Dev loss: 0.8334 r:0.2570
en_zh Dev loss: 0.6990 r:0.4653
ro_en Dev loss: 0.3532 r:0.8100
et_en Dev loss: 0.4287 r:0.6827
si_en Dev loss: 0.6606 r:0.6132
ne_en Dev loss: 0.4165 r:0.7488
ru_en Dev loss: 0.4468 r:0.7288
Current avg r:0.6151 Best avg r: 0.6261
22:20:17,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:48,532 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:23:19,363 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3415
en_de Dev loss: 0.8395 r:0.2591
en_zh Dev loss: 0.7329 r:0.4518
ro_en Dev loss: 0.3812 r:0.8014
et_en Dev loss: 0.4581 r:0.6792
si_en Dev loss: 0.6933 r:0.6040
ne_en Dev loss: 0.4162 r:0.7437
ru_en Dev loss: 0.4470 r:0.7277
Current avg r:0.6096 Best avg r: 0.6261
22:27:51,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:29:22,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:53,474 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3524
en_de Dev loss: 0.8413 r:0.2444
en_zh Dev loss: 0.7249 r:0.4547
ro_en Dev loss: 0.3690 r:0.8054
et_en Dev loss: 0.4338 r:0.6786
si_en Dev loss: 0.6871 r:0.6016
ne_en Dev loss: 0.4394 r:0.7482
ru_en Dev loss: 0.4332 r:0.7349
Current avg r:0.6097 Best avg r: 0.6261
22:35:25,885 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:56,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:38:27,664 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3767
en_de Dev loss: 0.8365 r:0.2441
en_zh Dev loss: 0.7356 r:0.4521
ro_en Dev loss: 0.3555 r:0.8074
et_en Dev loss: 0.4374 r:0.6827
si_en Dev loss: 0.6454 r:0.6097
ne_en Dev loss: 0.3764 r:0.7456
ru_en Dev loss: 0.4286 r:0.7351
Current avg r:0.6110 Best avg r: 0.6261
22:43:00,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:44:30,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:46:01,823 root INFO Epoch 5 Global steps: 44100 Train loss: 0.3501
en_de Dev loss: 0.8570 r:0.2352
en_zh Dev loss: 0.7662 r:0.4400
ro_en Dev loss: 0.3782 r:0.8019
et_en Dev loss: 0.4268 r:0.6817
si_en Dev loss: 0.7980 r:0.5949
ne_en Dev loss: 0.4338 r:0.7505
ru_en Dev loss: 0.4545 r:0.7326
Current avg r:0.6053 Best avg r: 0.6261
22:50:34,306 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:52:05,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:53:36,57 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3466
en_de Dev loss: 0.8573 r:0.2338
en_zh Dev loss: 0.7709 r:0.4402
ro_en Dev loss: 0.3513 r:0.8017
et_en Dev loss: 0.4123 r:0.6741
si_en Dev loss: 0.7677 r:0.5955
ne_en Dev loss: 0.4843 r:0.7457
ru_en Dev loss: 0.4365 r:0.7277
Current avg r:0.6027 Best avg r: 0.6261
22:58:08,555 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:59:39,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:01:10,294 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3754
en_de Dev loss: 0.8939 r:0.1854
en_zh Dev loss: 0.7607 r:0.4583
ro_en Dev loss: 0.3917 r:0.8051
et_en Dev loss: 0.4234 r:0.6734
si_en Dev loss: 0.8609 r:0.5992
ne_en Dev loss: 0.4705 r:0.7479
ru_en Dev loss: 0.5051 r:0.7117
Current avg r:0.5973 Best avg r: 0.6261
23:05:42,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:07:13,578 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:08:44,458 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3379
en_de Dev loss: 0.8775 r:0.2348
en_zh Dev loss: 0.7956 r:0.4401
ro_en Dev loss: 0.3814 r:0.8069
et_en Dev loss: 0.4240 r:0.6863
si_en Dev loss: 0.7180 r:0.6064
ne_en Dev loss: 0.4491 r:0.7430
ru_en Dev loss: 0.4790 r:0.7270
Current avg r:0.6064 Best avg r: 0.6261
23:13:16,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:14:47,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:16:18,505 root INFO Epoch 5 Global steps: 46900 Train loss: 0.3354
en_de Dev loss: 0.8643 r:0.2348
en_zh Dev loss: 0.7747 r:0.4441
ro_en Dev loss: 0.4112 r:0.7998
et_en Dev loss: 0.4299 r:0.6757
si_en Dev loss: 0.7843 r:0.5917
ne_en Dev loss: 0.4663 r:0.7430
ru_en Dev loss: 0.4934 r:0.7163
Current avg r:0.6008 Best avg r: 0.6261
23:20:50,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:22:21,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:23:52,711 root INFO Epoch 5 Global steps: 47600 Train loss: 0.3297
en_de Dev loss: 0.8763 r:0.2120
en_zh Dev loss: 0.7988 r:0.4295
ro_en Dev loss: 0.3737 r:0.8021
et_en Dev loss: 0.4268 r:0.6722
si_en Dev loss: 0.9241 r:0.5784
ne_en Dev loss: 0.5106 r:0.7354
ru_en Dev loss: 0.5107 r:0.7042
Current avg r:0.5905 Best avg r: 0.6261
23:28:26,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:29:57,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:31:28,214 root INFO Epoch 6 Global steps: 48300 Train loss: 0.3139
en_de Dev loss: 0.8582 r:0.2396
en_zh Dev loss: 0.7761 r:0.4438
ro_en Dev loss: 0.3858 r:0.8026
et_en Dev loss: 0.4276 r:0.6785
si_en Dev loss: 0.8133 r:0.5811
ne_en Dev loss: 0.5197 r:0.7412
ru_en Dev loss: 0.4915 r:0.7072
Current avg r:0.5991 Best avg r: 0.6261
23:36:00,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:37:31,491 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:39:02,351 root INFO Epoch 6 Global steps: 49000 Train loss: 0.3243
en_de Dev loss: 0.8887 r:0.2320
en_zh Dev loss: 0.8600 r:0.4352
ro_en Dev loss: 0.4083 r:0.8020
et_en Dev loss: 0.4260 r:0.6733
si_en Dev loss: 0.8964 r:0.5789
ne_en Dev loss: 0.5400 r:0.7411
ru_en Dev loss: 0.5389 r:0.7084
Current avg r:0.5959 Best avg r: 0.6261
23:43:34,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:45:05,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:46:36,670 root INFO Epoch 6 Global steps: 49700 Train loss: 0.2961
en_de Dev loss: 0.8509 r:0.2434
en_zh Dev loss: 0.7831 r:0.4568
ro_en Dev loss: 0.4055 r:0.8017
et_en Dev loss: 0.4359 r:0.6771
si_en Dev loss: 0.7998 r:0.5883
ne_en Dev loss: 0.4615 r:0.7451
ru_en Dev loss: 0.4965 r:0.7157
Current avg r:0.6040 Best avg r: 0.6261
23:51:09,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:52:39,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:54:10,870 root INFO Epoch 6 Global steps: 50400 Train loss: 0.3078
en_de Dev loss: 0.8849 r:0.2154
en_zh Dev loss: 0.8341 r:0.4458
ro_en Dev loss: 0.4335 r:0.8026
et_en Dev loss: 0.4360 r:0.6702
si_en Dev loss: 0.8354 r:0.5876
ne_en Dev loss: 0.5374 r:0.7451
ru_en Dev loss: 0.5420 r:0.7093
Current avg r:0.5966 Best avg r: 0.6261
23:58:43,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:00:14,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:01:45,197 root INFO Epoch 6 Global steps: 51100 Train loss: 0.3125
en_de Dev loss: 0.8612 r:0.2453
en_zh Dev loss: 0.7558 r:0.4665
ro_en Dev loss: 0.3730 r:0.8070
et_en Dev loss: 0.4196 r:0.6769
si_en Dev loss: 0.7142 r:0.5976
ne_en Dev loss: 0.4524 r:0.7432
ru_en Dev loss: 0.4668 r:0.7287
Current avg r:0.6093 Best avg r: 0.6261
00:06:17,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:07:48,558 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:09:19,430 root INFO Epoch 6 Global steps: 51800 Train loss: 0.3045
en_de Dev loss: 0.8702 r:0.2517
en_zh Dev loss: 0.7741 r:0.4606
ro_en Dev loss: 0.3796 r:0.8085
et_en Dev loss: 0.4217 r:0.6779
si_en Dev loss: 0.7676 r:0.5959
ne_en Dev loss: 0.4286 r:0.7482
ru_en Dev loss: 0.4966 r:0.7221
Current avg r:0.6093 Best avg r: 0.6261
00:13:51,862 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:15:22,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:16:53,671 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2955
en_de Dev loss: 0.8757 r:0.2121
en_zh Dev loss: 0.7586 r:0.4548
ro_en Dev loss: 0.3459 r:0.8086
et_en Dev loss: 0.4214 r:0.6736
si_en Dev loss: 0.7476 r:0.5969
ne_en Dev loss: 0.4476 r:0.7383
ru_en Dev loss: 0.4331 r:0.7320
Current avg r:0.6023 Best avg r: 0.6261
00:21:26,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:22:57,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:24:27,947 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2923
en_de Dev loss: 0.8523 r:0.2188
en_zh Dev loss: 0.7184 r:0.4651
ro_en Dev loss: 0.3379 r:0.8089
et_en Dev loss: 0.4306 r:0.6780
si_en Dev loss: 0.6893 r:0.6024
ne_en Dev loss: 0.4038 r:0.7330
ru_en Dev loss: 0.4099 r:0.7384
Current avg r:0.6064 Best avg r: 0.6261
00:29:00,350 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:30:31,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:32:02,145 root INFO Epoch 6 Global steps: 53900 Train loss: 0.3047
en_de Dev loss: 0.8592 r:0.2199
en_zh Dev loss: 0.7785 r:0.4554
ro_en Dev loss: 0.3728 r:0.8024
et_en Dev loss: 0.4498 r:0.6597
si_en Dev loss: 0.7911 r:0.5851
ne_en Dev loss: 0.4830 r:0.7365
ru_en Dev loss: 0.5149 r:0.6956
Current avg r:0.5935 Best avg r: 0.6261
00:36:34,613 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:38:05,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:39:36,374 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2878
en_de Dev loss: 0.8545 r:0.2423
en_zh Dev loss: 0.7990 r:0.4567
ro_en Dev loss: 0.4034 r:0.8068
et_en Dev loss: 0.4617 r:0.6680
si_en Dev loss: 0.7988 r:0.5866
ne_en Dev loss: 0.5106 r:0.7421
ru_en Dev loss: 0.4747 r:0.7252
Current avg r:0.6040 Best avg r: 0.6261
00:44:08,737 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:45:39,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:47:10,350 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2969
en_de Dev loss: 0.8738 r:0.2168
en_zh Dev loss: 0.7948 r:0.4640
ro_en Dev loss: 0.3937 r:0.8053
et_en Dev loss: 0.4637 r:0.6696
si_en Dev loss: 0.8042 r:0.5838
ne_en Dev loss: 0.4532 r:0.7376
ru_en Dev loss: 0.4860 r:0.7227
Current avg r:0.6000 Best avg r: 0.6261
00:51:44,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:53:14,907 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:54:45,720 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2686
en_de Dev loss: 0.8781 r:0.2195
en_zh Dev loss: 0.7737 r:0.4591
ro_en Dev loss: 0.4140 r:0.8025
et_en Dev loss: 0.4654 r:0.6584
si_en Dev loss: 0.8367 r:0.5810
ne_en Dev loss: 0.4696 r:0.7402
ru_en Dev loss: 0.5157 r:0.7089
Current avg r:0.5957 Best avg r: 0.6261
00:59:18,144 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:00:49,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:02:19,805 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2806
en_de Dev loss: 0.8789 r:0.2240
en_zh Dev loss: 0.8028 r:0.4507
ro_en Dev loss: 0.4115 r:0.8053
et_en Dev loss: 0.4575 r:0.6658
si_en Dev loss: 0.8011 r:0.5861
ne_en Dev loss: 0.4895 r:0.7374
ru_en Dev loss: 0.5247 r:0.7077
Current avg r:0.5967 Best avg r: 0.6261
01:06:52,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:08:23,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:09:53,887 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2691
en_de Dev loss: 0.8572 r:0.2408
en_zh Dev loss: 0.7784 r:0.4470
ro_en Dev loss: 0.3787 r:0.8026
et_en Dev loss: 0.4798 r:0.6692
si_en Dev loss: 0.6990 r:0.5961
ne_en Dev loss: 0.4089 r:0.7397
ru_en Dev loss: 0.4348 r:0.7335
Current avg r:0.6041 Best avg r: 0.6261
01:14:26,232 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:15:57,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:17:27,910 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2798
en_de Dev loss: 0.8285 r:0.2644
en_zh Dev loss: 0.7508 r:0.4546
ro_en Dev loss: 0.3629 r:0.8102
et_en Dev loss: 0.4793 r:0.6707
si_en Dev loss: 0.6958 r:0.5978
ne_en Dev loss: 0.4714 r:0.7327
ru_en Dev loss: 0.4123 r:0.7378
Current avg r:0.6098 Best avg r: 0.6261
01:22:00,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:23:31,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:25:01,888 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2730
en_de Dev loss: 0.8790 r:0.2595
en_zh Dev loss: 0.7850 r:0.4526
ro_en Dev loss: 0.3940 r:0.8044
et_en Dev loss: 0.4554 r:0.6693
si_en Dev loss: 0.7665 r:0.5831
ne_en Dev loss: 0.4758 r:0.7357
ru_en Dev loss: 0.4646 r:0.7295
Current avg r:0.6049 Best avg r: 0.6261
01:29:34,196 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:31:05,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:32:35,855 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2831
en_de Dev loss: 0.8569 r:0.2684
en_zh Dev loss: 0.8545 r:0.4347
ro_en Dev loss: 0.3897 r:0.8051
et_en Dev loss: 0.4661 r:0.6558
si_en Dev loss: 0.8479 r:0.5771
ne_en Dev loss: 0.5474 r:0.7309
ru_en Dev loss: 0.5272 r:0.6976
Current avg r:0.5957 Best avg r: 0.6261
01:37:08,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:38:39,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:40:09,881 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2653
en_de Dev loss: 0.8489 r:0.2743
en_zh Dev loss: 0.7863 r:0.4531
ro_en Dev loss: 0.3543 r:0.8110
et_en Dev loss: 0.4731 r:0.6722
si_en Dev loss: 0.7307 r:0.5885
ne_en Dev loss: 0.4265 r:0.7308
ru_en Dev loss: 0.4392 r:0.7348
Current avg r:0.6092 Best avg r: 0.6261
01:44:42,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:46:13,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:47:43,896 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2859
en_de Dev loss: 0.8614 r:0.2485
en_zh Dev loss: 0.8182 r:0.4451
ro_en Dev loss: 0.4016 r:0.8091
et_en Dev loss: 0.4607 r:0.6712
si_en Dev loss: 0.8846 r:0.5822
ne_en Dev loss: 0.4990 r:0.7326
ru_en Dev loss: 0.5333 r:0.7146
Current avg r:0.6005 Best avg r: 0.6261
01:52:16,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:53:47,80 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:55:17,904 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2710
en_de Dev loss: 0.8479 r:0.2507
en_zh Dev loss: 0.8039 r:0.4530
ro_en Dev loss: 0.3875 r:0.8122
et_en Dev loss: 0.4592 r:0.6718
si_en Dev loss: 0.8599 r:0.5888
ne_en Dev loss: 0.5352 r:0.7364
ru_en Dev loss: 0.4718 r:0.7314
Current avg r:0.6063 Best avg r: 0.6261
01:59:50,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:01:21,175 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:02:51,969 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2742
en_de Dev loss: 0.8625 r:0.2535
en_zh Dev loss: 0.8077 r:0.4488
ro_en Dev loss: 0.4014 r:0.8092
et_en Dev loss: 0.4485 r:0.6744
si_en Dev loss: 0.7957 r:0.5932
ne_en Dev loss: 0.4734 r:0.7360
ru_en Dev loss: 0.5161 r:0.7142
Current avg r:0.6042 Best avg r: 0.6261
02:07:24,434 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:08:55,337 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:10:26,163 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2606
en_de Dev loss: 0.8468 r:0.2615
en_zh Dev loss: 0.7837 r:0.4488
ro_en Dev loss: 0.3878 r:0.8070
et_en Dev loss: 0.4358 r:0.6734
si_en Dev loss: 0.8274 r:0.5827
ne_en Dev loss: 0.5255 r:0.7353
ru_en Dev loss: 0.4655 r:0.7238
Current avg r:0.6046 Best avg r: 0.6261
02:14:59,886 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:30,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:18:01,589 root INFO Epoch 8 Global steps: 63700 Train loss: 0.2236
en_de Dev loss: 0.8737 r:0.2479
en_zh Dev loss: 0.8540 r:0.4473
ro_en Dev loss: 0.4293 r:0.7995
et_en Dev loss: 0.4893 r:0.6566
si_en Dev loss: 0.8308 r:0.5785
ne_en Dev loss: 0.5298 r:0.7290
ru_en Dev loss: 0.5435 r:0.6995
Current avg r:0.5940 Best avg r: 0.6261
02:22:34,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:24:04,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:25:35,755 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2552
en_de Dev loss: 0.8708 r:0.2431
en_zh Dev loss: 0.8676 r:0.4445
ro_en Dev loss: 0.4299 r:0.7988
et_en Dev loss: 0.4992 r:0.6479
si_en Dev loss: 0.8758 r:0.5728
ne_en Dev loss: 0.5205 r:0.7266
ru_en Dev loss: 0.5385 r:0.6963
Current avg r:0.5900 Best avg r: 0.6261
02:30:08,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:31:39,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:33:09,860 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2611
en_de Dev loss: 0.8491 r:0.2524
en_zh Dev loss: 0.7969 r:0.4494
ro_en Dev loss: 0.3944 r:0.8031
et_en Dev loss: 0.4620 r:0.6609
si_en Dev loss: 0.7751 r:0.5798
ne_en Dev loss: 0.4986 r:0.7277
ru_en Dev loss: 0.4837 r:0.7151
Current avg r:0.5983 Best avg r: 0.6261
02:37:42,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:39:13,144 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:40:43,982 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2413
en_de Dev loss: 0.8715 r:0.2502
en_zh Dev loss: 0.8751 r:0.4299
ro_en Dev loss: 0.4518 r:0.7958
et_en Dev loss: 0.4918 r:0.6465
si_en Dev loss: 1.0364 r:0.5544
ne_en Dev loss: 0.6192 r:0.7211
ru_en Dev loss: 0.5817 r:0.6917
Current avg r:0.5842 Best avg r: 0.6261
02:45:16,462 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:46:47,345 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:48:18,173 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2496
en_de Dev loss: 0.8448 r:0.2508
en_zh Dev loss: 0.7842 r:0.4373
ro_en Dev loss: 0.4085 r:0.7952
et_en Dev loss: 0.4702 r:0.6541
si_en Dev loss: 0.8668 r:0.5604
ne_en Dev loss: 0.5190 r:0.7319
ru_en Dev loss: 0.4870 r:0.7055
Current avg r:0.5907 Best avg r: 0.6261
02:52:50,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:54:21,508 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:55:52,340 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2576
en_de Dev loss: 0.8774 r:0.2261
en_zh Dev loss: 0.8935 r:0.4274
ro_en Dev loss: 0.4561 r:0.7994
et_en Dev loss: 0.4825 r:0.6589
si_en Dev loss: 0.9505 r:0.5614
ne_en Dev loss: 0.5706 r:0.7326
ru_en Dev loss: 0.5477 r:0.6969
Current avg r:0.5861 Best avg r: 0.6261
03:00:24,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:01:55,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:03:26,471 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2504
en_de Dev loss: 0.8677 r:0.2341
en_zh Dev loss: 0.8310 r:0.4407
ro_en Dev loss: 0.4385 r:0.7986
et_en Dev loss: 0.4813 r:0.6536
si_en Dev loss: 0.9218 r:0.5605
ne_en Dev loss: 0.5217 r:0.7336
ru_en Dev loss: 0.5044 r:0.7108
Current avg r:0.5903 Best avg r: 0.6261
03:07:58,980 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:09:29,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:00,551 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2432
en_de Dev loss: 0.8929 r:0.2323
en_zh Dev loss: 0.8812 r:0.4298
ro_en Dev loss: 0.4319 r:0.8006
et_en Dev loss: 0.4860 r:0.6534
si_en Dev loss: 0.9093 r:0.5672
ne_en Dev loss: 0.5333 r:0.7370
ru_en Dev loss: 0.5227 r:0.7142
Current avg r:0.5906 Best avg r: 0.6261
03:15:33,41 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:17:03,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:18:34,632 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2307
en_de Dev loss: 0.8803 r:0.2339
en_zh Dev loss: 0.8301 r:0.4536
ro_en Dev loss: 0.3988 r:0.8045
et_en Dev loss: 0.4692 r:0.6557
si_en Dev loss: 0.8242 r:0.5722
ne_en Dev loss: 0.5117 r:0.7340
ru_en Dev loss: 0.5090 r:0.7133
Current avg r:0.5953 Best avg r: 0.6261
03:23:07,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:24:37,945 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:26:08,751 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2442
en_de Dev loss: 0.8464 r:0.2392
en_zh Dev loss: 0.7779 r:0.4444
ro_en Dev loss: 0.3772 r:0.8014
et_en Dev loss: 0.4806 r:0.6595
si_en Dev loss: 0.8212 r:0.5619
ne_en Dev loss: 0.5371 r:0.7255
ru_en Dev loss: 0.4438 r:0.7240
Current avg r:0.5937 Best avg r: 0.6261
03:30:41,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:32:11,975 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:33:42,830 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2416
en_de Dev loss: 0.8865 r:0.2241
en_zh Dev loss: 0.8297 r:0.4455
ro_en Dev loss: 0.3815 r:0.8100
et_en Dev loss: 0.5157 r:0.6587
si_en Dev loss: 0.8284 r:0.5745
ne_en Dev loss: 0.4956 r:0.7180
ru_en Dev loss: 0.5217 r:0.7096
Current avg r:0.5915 Best avg r: 0.6261
03:38:15,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:39:46,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:16,983 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2417
en_de Dev loss: 0.8745 r:0.2318
en_zh Dev loss: 0.7894 r:0.4477
ro_en Dev loss: 0.3666 r:0.8053
et_en Dev loss: 0.4533 r:0.6631
si_en Dev loss: 0.8309 r:0.5634
ne_en Dev loss: 0.5377 r:0.7322
ru_en Dev loss: 0.5008 r:0.7060
Current avg r:0.5928 Best avg r: 0.6261
03:45:50,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:47:21,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:48:52,469 root INFO Epoch 9 Global steps: 72100 Train loss: 0.2314
en_de Dev loss: 0.9023 r:0.2055
en_zh Dev loss: 0.7788 r:0.4658
ro_en Dev loss: 0.4008 r:0.8013
et_en Dev loss: 0.5119 r:0.6498
si_en Dev loss: 0.8317 r:0.5639
ne_en Dev loss: 0.4594 r:0.7306
ru_en Dev loss: 0.4998 r:0.7097
Current avg r:0.5895 Best avg r: 0.6261
03:53:24,980 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:54:55,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:56:26,699 root INFO Epoch 9 Global steps: 72800 Train loss: 0.2136
en_de Dev loss: 0.8830 r:0.2119
en_zh Dev loss: 0.7811 r:0.4589
ro_en Dev loss: 0.3922 r:0.8048
et_en Dev loss: 0.4775 r:0.6621
si_en Dev loss: 0.8189 r:0.5737
ne_en Dev loss: 0.4869 r:0.7308
ru_en Dev loss: 0.4979 r:0.7110
Current avg r:0.5933 Best avg r: 0.6261
04:00:59,214 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:02:30,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:01,4 root INFO Epoch 9 Global steps: 73500 Train loss: 0.2341
en_de Dev loss: 0.8720 r:0.2098
en_zh Dev loss: 0.7605 r:0.4603
ro_en Dev loss: 0.3933 r:0.7986
et_en Dev loss: 0.5149 r:0.6548
si_en Dev loss: 0.7955 r:0.5662
ne_en Dev loss: 0.5227 r:0.7237
ru_en Dev loss: 0.4454 r:0.7241
Current avg r:0.5911 Best avg r: 0.6261
04:08:33,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:10:04,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:11:35,356 root INFO Epoch 9 Global steps: 74200 Train loss: 0.2161
en_de Dev loss: 0.8819 r:0.2186
en_zh Dev loss: 0.8192 r:0.4514
ro_en Dev loss: 0.4341 r:0.7935
et_en Dev loss: 0.5001 r:0.6524
si_en Dev loss: 0.9304 r:0.5560
ne_en Dev loss: 0.5608 r:0.7257
ru_en Dev loss: 0.5161 r:0.7069
Current avg r:0.5864 Best avg r: 0.6261
04:16:07,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:17:38,862 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:09,691 root INFO Epoch 9 Global steps: 74900 Train loss: 0.2205
en_de Dev loss: 0.8783 r:0.2172
en_zh Dev loss: 0.8119 r:0.4386
ro_en Dev loss: 0.3926 r:0.7958
et_en Dev loss: 0.4930 r:0.6475
si_en Dev loss: 0.8028 r:0.5542
ne_en Dev loss: 0.5060 r:0.7215
ru_en Dev loss: 0.4703 r:0.7149
Current avg r:0.5843 Best avg r: 0.6261
04:23:42,151 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:25:13,70 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:26:43,997 root INFO Epoch 9 Global steps: 75600 Train loss: 0.2093
en_de Dev loss: 0.8725 r:0.2151
en_zh Dev loss: 0.8090 r:0.4505
ro_en Dev loss: 0.4107 r:0.7988
et_en Dev loss: 0.5111 r:0.6470
si_en Dev loss: 0.9197 r:0.5557
ne_en Dev loss: 0.5652 r:0.7227
ru_en Dev loss: 0.4706 r:0.7249
Current avg r:0.5878 Best avg r: 0.6261
04:31:16,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:32:47,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:34:18,269 root INFO Epoch 9 Global steps: 76300 Train loss: 0.2207
en_de Dev loss: 0.8735 r:0.2081
en_zh Dev loss: 0.8336 r:0.4425
ro_en Dev loss: 0.3823 r:0.8030
et_en Dev loss: 0.4796 r:0.6574
si_en Dev loss: 0.8401 r:0.5634
ne_en Dev loss: 0.5595 r:0.7240
ru_en Dev loss: 0.4487 r:0.7286
Current avg r:0.5896 Best avg r: 0.6261
04:38:50,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:40:21,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:41:52,563 root INFO Epoch 9 Global steps: 77000 Train loss: 0.2199
en_de Dev loss: 0.9154 r:0.1965
en_zh Dev loss: 0.8408 r:0.4409
ro_en Dev loss: 0.4211 r:0.7994
et_en Dev loss: 0.5095 r:0.6570
si_en Dev loss: 0.8830 r:0.5593
ne_en Dev loss: 0.5755 r:0.7246
ru_en Dev loss: 0.5004 r:0.7166
Current avg r:0.5849 Best avg r: 0.6261
04:46:25,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:47:56,74 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:49:27,64 root INFO Epoch 9 Global steps: 77700 Train loss: 0.2267
en_de Dev loss: 0.8784 r:0.2271
en_zh Dev loss: 0.7797 r:0.4466
ro_en Dev loss: 0.3535 r:0.8044
et_en Dev loss: 0.4600 r:0.6566
si_en Dev loss: 0.7799 r:0.5603
ne_en Dev loss: 0.4614 r:0.7315
ru_en Dev loss: 0.4444 r:0.7245
Current avg r:0.5930 Best avg r: 0.6261
04:53:59,646 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:55:30,562 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:57:01,477 root INFO Epoch 9 Global steps: 78400 Train loss: 0.2197
en_de Dev loss: 0.9059 r:0.2096
en_zh Dev loss: 0.8198 r:0.4648
ro_en Dev loss: 0.4011 r:0.8050
et_en Dev loss: 0.4568 r:0.6615
si_en Dev loss: 0.8827 r:0.5673
ne_en Dev loss: 0.5488 r:0.7380
ru_en Dev loss: 0.4654 r:0.7375
Current avg r:0.5977 Best avg r: 0.6261
05:01:33,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:03:04,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:04:35,789 root INFO Epoch 9 Global steps: 79100 Train loss: 0.2251
en_de Dev loss: 0.9015 r:0.2204
en_zh Dev loss: 0.7701 r:0.4702
ro_en Dev loss: 0.3798 r:0.8034
et_en Dev loss: 0.4725 r:0.6590
si_en Dev loss: 0.8443 r:0.5663
ne_en Dev loss: 0.5000 r:0.7321
ru_en Dev loss: 0.4775 r:0.7167
Current avg r:0.5954 Best avg r: 0.6261
05:09:09,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:10:40,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:12:11,158 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1918
en_de Dev loss: 0.9018 r:0.2080
en_zh Dev loss: 0.8026 r:0.4499
ro_en Dev loss: 0.3881 r:0.8021
et_en Dev loss: 0.4764 r:0.6561
si_en Dev loss: 0.8418 r:0.5641
ne_en Dev loss: 0.4977 r:0.7318
ru_en Dev loss: 0.4763 r:0.7263
Current avg r:0.5912 Best avg r: 0.6261
05:16:43,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:18:14,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:19:45,217 root INFO Epoch 10 Global steps: 80500 Train loss: 0.2037
en_de Dev loss: 0.8905 r:0.2205
en_zh Dev loss: 0.7910 r:0.4571
ro_en Dev loss: 0.3931 r:0.8041
et_en Dev loss: 0.5067 r:0.6650
si_en Dev loss: 0.8408 r:0.5714
ne_en Dev loss: 0.4655 r:0.7363
ru_en Dev loss: 0.4222 r:0.7469
Current avg r:0.6002 Best avg r: 0.6261
05:24:17,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:25:48,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:27:19,345 root INFO Epoch 10 Global steps: 81200 Train loss: 0.2076
en_de Dev loss: 0.9030 r:0.2211
en_zh Dev loss: 0.8552 r:0.4547
ro_en Dev loss: 0.4494 r:0.7990
et_en Dev loss: 0.5205 r:0.6458
si_en Dev loss: 1.0063 r:0.5521
ne_en Dev loss: 0.6428 r:0.7290
ru_en Dev loss: 0.5399 r:0.7098
Current avg r:0.5874 Best avg r: 0.6261
05:31:51,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:33:22,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:34:53,518 root INFO Epoch 10 Global steps: 81900 Train loss: 0.2025
en_de Dev loss: 0.8994 r:0.2172
en_zh Dev loss: 0.8017 r:0.4500
ro_en Dev loss: 0.4101 r:0.7995
et_en Dev loss: 0.4842 r:0.6555
si_en Dev loss: 0.9362 r:0.5531
ne_en Dev loss: 0.5090 r:0.7345
ru_en Dev loss: 0.4615 r:0.7319
Current avg r:0.5917 Best avg r: 0.6261
05:39:25,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:40:56,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:42:27,641 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1997
en_de Dev loss: 0.8818 r:0.2171
en_zh Dev loss: 0.8119 r:0.4467
ro_en Dev loss: 0.4129 r:0.8028
et_en Dev loss: 0.4953 r:0.6552
si_en Dev loss: 0.8855 r:0.5639
ne_en Dev loss: 0.5310 r:0.7320
ru_en Dev loss: 0.4947 r:0.7072
Current avg r:0.5893 Best avg r: 0.6261
05:46:59,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:48:30,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:50:01,554 root INFO Epoch 10 Global steps: 83300 Train loss: 0.2028
en_de Dev loss: 0.8878 r:0.2229
en_zh Dev loss: 0.7925 r:0.4561
ro_en Dev loss: 0.3813 r:0.8074
et_en Dev loss: 0.4934 r:0.6551
si_en Dev loss: 0.8660 r:0.5609
ne_en Dev loss: 0.5010 r:0.7374
ru_en Dev loss: 0.4698 r:0.7211
Current avg r:0.5944 Best avg r: 0.6261
05:54:33,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:56:04,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:57:35,574 root INFO Epoch 10 Global steps: 84000 Train loss: 0.2036
en_de Dev loss: 0.8999 r:0.2338
en_zh Dev loss: 0.8330 r:0.4547
ro_en Dev loss: 0.4383 r:0.7998
et_en Dev loss: 0.5131 r:0.6404
si_en Dev loss: 0.9382 r:0.5547
ne_en Dev loss: 0.5348 r:0.7379
ru_en Dev loss: 0.5013 r:0.7222
Current avg r:0.5919 Best avg r: 0.6261
06:02:07,882 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:03:38,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:09,663 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1952
en_de Dev loss: 0.8778 r:0.2265
en_zh Dev loss: 0.8091 r:0.4500
ro_en Dev loss: 0.4090 r:0.7980
et_en Dev loss: 0.4975 r:0.6493
si_en Dev loss: 0.9053 r:0.5522
ne_en Dev loss: 0.5027 r:0.7333
ru_en Dev loss: 0.4537 r:0.7304
Current avg r:0.5914 Best avg r: 0.6261
06:09:42,106 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:12,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:12:43,853 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1964
en_de Dev loss: 0.9180 r:0.2029
en_zh Dev loss: 0.8924 r:0.4475
ro_en Dev loss: 0.4574 r:0.7951
et_en Dev loss: 0.4838 r:0.6507
si_en Dev loss: 0.9695 r:0.5565
ne_en Dev loss: 0.5780 r:0.7333
ru_en Dev loss: 0.5768 r:0.7000
Current avg r:0.5837 Best avg r: 0.6261
06:17:16,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:18:47,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:20:17,989 root INFO Epoch 10 Global steps: 86100 Train loss: 0.2021
en_de Dev loss: 0.9145 r:0.2016
en_zh Dev loss: 0.7877 r:0.4636
ro_en Dev loss: 0.4137 r:0.8014
et_en Dev loss: 0.4708 r:0.6566
si_en Dev loss: 0.9370 r:0.5620
ne_en Dev loss: 0.5429 r:0.7299
ru_en Dev loss: 0.4840 r:0.7247
Current avg r:0.5914 Best avg r: 0.6261
06:24:50,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:26:21,307 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:27:52,162 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1950
en_de Dev loss: 0.9567 r:0.1739
en_zh Dev loss: 0.8978 r:0.4447
ro_en Dev loss: 0.4734 r:0.7932
et_en Dev loss: 0.4981 r:0.6488
si_en Dev loss: 0.9727 r:0.5538
ne_en Dev loss: 0.6283 r:0.7260
ru_en Dev loss: 0.5451 r:0.7144
Current avg r:0.5793 Best avg r: 0.6261
06:32:24,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:33:55,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:35:26,129 root INFO Epoch 10 Global steps: 87500 Train loss: 0.2078
en_de Dev loss: 0.9397 r:0.1803
en_zh Dev loss: 0.8191 r:0.4509
ro_en Dev loss: 0.4077 r:0.7989
et_en Dev loss: 0.4756 r:0.6579
si_en Dev loss: 0.7869 r:0.5691
ne_en Dev loss: 0.4531 r:0.7288
ru_en Dev loss: 0.4979 r:0.7185
Current avg r:0.5863 Best avg r: 0.6261
06:39:59,870 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:41:30,748 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:43:01,563 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1830
en_de Dev loss: 0.9264 r:0.1853
en_zh Dev loss: 0.8302 r:0.4528
ro_en Dev loss: 0.4148 r:0.7995
et_en Dev loss: 0.4903 r:0.6539
si_en Dev loss: 0.8629 r:0.5578
ne_en Dev loss: 0.5285 r:0.7301
ru_en Dev loss: 0.4628 r:0.7303
Current avg r:0.5871 Best avg r: 0.6261
06:47:33,889 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:49:04,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:50:35,511 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1820
en_de Dev loss: 0.9379 r:0.1751
en_zh Dev loss: 0.8583 r:0.4455
ro_en Dev loss: 0.4272 r:0.8015
et_en Dev loss: 0.5109 r:0.6401
si_en Dev loss: 0.9950 r:0.5527
ne_en Dev loss: 0.6455 r:0.7173
ru_en Dev loss: 0.5528 r:0.7043
Current avg r:0.5766 Best avg r: 0.6261
06:55:07,803 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:56:38,673 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:58:09,499 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1853
en_de Dev loss: 0.9085 r:0.2095
en_zh Dev loss: 0.8570 r:0.4352
ro_en Dev loss: 0.4220 r:0.7985
et_en Dev loss: 0.4791 r:0.6460
si_en Dev loss: 0.9604 r:0.5537
ne_en Dev loss: 0.6404 r:0.7191
ru_en Dev loss: 0.5449 r:0.7058
Current avg r:0.5811 Best avg r: 0.6261
07:02:41,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:04:12,632 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:05:43,454 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1872
en_de Dev loss: 0.9038 r:0.2015
en_zh Dev loss: 0.8227 r:0.4541
ro_en Dev loss: 0.3716 r:0.8036
et_en Dev loss: 0.4663 r:0.6424
si_en Dev loss: 0.8936 r:0.5503
ne_en Dev loss: 0.5538 r:0.7221
ru_en Dev loss: 0.5000 r:0.7166
Current avg r:0.5844 Best avg r: 0.6261
07:10:15,758 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:11:46,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:13:17,423 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1793
en_de Dev loss: 0.8998 r:0.2086
en_zh Dev loss: 0.7699 r:0.4602
ro_en Dev loss: 0.3845 r:0.8012
et_en Dev loss: 0.4695 r:0.6510
si_en Dev loss: 0.8798 r:0.5533
ne_en Dev loss: 0.5520 r:0.7224
ru_en Dev loss: 0.4715 r:0.7267
Current avg r:0.5890 Best avg r: 0.6261
07:17:49,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:19:20,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:20:51,362 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1830
en_de Dev loss: 0.8899 r:0.2155
en_zh Dev loss: 0.7923 r:0.4401
ro_en Dev loss: 0.4009 r:0.7987
et_en Dev loss: 0.4711 r:0.6524
si_en Dev loss: 0.9235 r:0.5430
ne_en Dev loss: 0.5913 r:0.7153
ru_en Dev loss: 0.5165 r:0.7009
Current avg r:0.5808 Best avg r: 0.6261
07:25:23,687 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:26:54,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:28:25,371 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1751
en_de Dev loss: 0.9128 r:0.2116
en_zh Dev loss: 0.8177 r:0.4598
ro_en Dev loss: 0.3861 r:0.8065
et_en Dev loss: 0.4647 r:0.6656
si_en Dev loss: 0.8670 r:0.5532
ne_en Dev loss: 0.5409 r:0.7262
ru_en Dev loss: 0.4809 r:0.7291
Current avg r:0.5931 Best avg r: 0.6261
07:32:57,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:34:28,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:35:59,334 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1823
en_de Dev loss: 0.8991 r:0.2067
en_zh Dev loss: 0.7841 r:0.4623
ro_en Dev loss: 0.3792 r:0.8113
et_en Dev loss: 0.5154 r:0.6635
si_en Dev loss: 0.7544 r:0.5778
ne_en Dev loss: 0.4786 r:0.7304
ru_en Dev loss: 0.4459 r:0.7297
Current avg r:0.5974 Best avg r: 0.6261
07:40:31,626 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:42:02,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:43:33,332 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1769
en_de Dev loss: 0.9251 r:0.1976
en_zh Dev loss: 0.8181 r:0.4598
ro_en Dev loss: 0.3997 r:0.8087
et_en Dev loss: 0.4878 r:0.6563
si_en Dev loss: 0.8130 r:0.5710
ne_en Dev loss: 0.4914 r:0.7325
ru_en Dev loss: 0.4901 r:0.7292
Current avg r:0.5936 Best avg r: 0.6261
07:48:05,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:49:36,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:51:07,264 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1838
en_de Dev loss: 0.9104 r:0.2012
en_zh Dev loss: 0.8160 r:0.4490
ro_en Dev loss: 0.4161 r:0.8020
et_en Dev loss: 0.5022 r:0.6421
si_en Dev loss: 0.9202 r:0.5513
ne_en Dev loss: 0.5487 r:0.7258
ru_en Dev loss: 0.4613 r:0.7371
Current avg r:0.5869 Best avg r: 0.6261
07:55:39,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:57:10,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:58:41,169 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1741
en_de Dev loss: 0.9205 r:0.1850
en_zh Dev loss: 0.8068 r:0.4449
ro_en Dev loss: 0.4079 r:0.8008
et_en Dev loss: 0.4911 r:0.6459
si_en Dev loss: 0.9545 r:0.5409
ne_en Dev loss: 0.5599 r:0.7216
ru_en Dev loss: 0.4569 r:0.7359
Current avg r:0.5822 Best avg r: 0.6261
08:03:14,645 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:04:45,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:06:16,284 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1666
en_de Dev loss: 0.9179 r:0.2030
en_zh Dev loss: 0.7847 r:0.4605
ro_en Dev loss: 0.3894 r:0.8051
et_en Dev loss: 0.4923 r:0.6534
si_en Dev loss: 0.8936 r:0.5592
ne_en Dev loss: 0.5072 r:0.7280
ru_en Dev loss: 0.4608 r:0.7450
Current avg r:0.5935 Best avg r: 0.6261
08:10:48,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:12:19,385 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:13:50,194 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1653
en_de Dev loss: 0.9241 r:0.1934
en_zh Dev loss: 0.8147 r:0.4598
ro_en Dev loss: 0.4085 r:0.8017
et_en Dev loss: 0.4774 r:0.6529
si_en Dev loss: 0.8837 r:0.5562
ne_en Dev loss: 0.5273 r:0.7245
ru_en Dev loss: 0.5093 r:0.7255
Current avg r:0.5877 Best avg r: 0.6261
08:18:22,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:19:53,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:21:24,117 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1654
en_de Dev loss: 0.8978 r:0.1973
en_zh Dev loss: 0.7723 r:0.4607
ro_en Dev loss: 0.3742 r:0.8038
et_en Dev loss: 0.4803 r:0.6487
si_en Dev loss: 0.8239 r:0.5601
ne_en Dev loss: 0.5075 r:0.7252
ru_en Dev loss: 0.4433 r:0.7320
Current avg r:0.5897 Best avg r: 0.6261
08:25:56,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:27:27,221 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:28:58,12 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1687
en_de Dev loss: 0.9420 r:0.1848
en_zh Dev loss: 0.8093 r:0.4613
ro_en Dev loss: 0.4014 r:0.8041
et_en Dev loss: 0.5295 r:0.6584
si_en Dev loss: 0.8599 r:0.5519
ne_en Dev loss: 0.4860 r:0.7283
ru_en Dev loss: 0.4482 r:0.7386
Current avg r:0.5896 Best avg r: 0.6261
08:33:30,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:01,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:31,972 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1724
en_de Dev loss: 0.9026 r:0.1881
en_zh Dev loss: 0.7853 r:0.4546
ro_en Dev loss: 0.3680 r:0.8056
et_en Dev loss: 0.4991 r:0.6630
si_en Dev loss: 0.8304 r:0.5492
ne_en Dev loss: 0.4781 r:0.7266
ru_en Dev loss: 0.4397 r:0.7321
Current avg r:0.5884 Best avg r: 0.6261
08:41:04,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:35,151 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:44:05,950 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1593
en_de Dev loss: 0.9131 r:0.2084
en_zh Dev loss: 0.8770 r:0.4368
ro_en Dev loss: 0.4356 r:0.8005
et_en Dev loss: 0.5134 r:0.6486
si_en Dev loss: 0.9172 r:0.5433
ne_en Dev loss: 0.5881 r:0.7192
ru_en Dev loss: 0.5470 r:0.7000
Current avg r:0.5795 Best avg r: 0.6261
08:48:38,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:50:09,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:51:39,822 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1660
en_de Dev loss: 0.8997 r:0.2135
en_zh Dev loss: 0.8056 r:0.4566
ro_en Dev loss: 0.3795 r:0.8070
et_en Dev loss: 0.4731 r:0.6565
si_en Dev loss: 0.7933 r:0.5512
ne_en Dev loss: 0.5460 r:0.7220
ru_en Dev loss: 0.4801 r:0.7182
Current avg r:0.5893 Best avg r: 0.6261
08:56:12,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:57:42,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:59:13,733 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1578
en_de Dev loss: 0.9307 r:0.2111
en_zh Dev loss: 0.8820 r:0.4512
ro_en Dev loss: 0.4555 r:0.8008
et_en Dev loss: 0.5314 r:0.6417
si_en Dev loss: 0.9629 r:0.5373
ne_en Dev loss: 0.6319 r:0.7212
ru_en Dev loss: 0.5474 r:0.7073
Current avg r:0.5815 Best avg r: 0.6261
09:03:46,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:05:16,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:06:47,679 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1551
en_de Dev loss: 0.9295 r:0.2004
en_zh Dev loss: 0.8264 r:0.4654
ro_en Dev loss: 0.3952 r:0.8078
et_en Dev loss: 0.4996 r:0.6499
si_en Dev loss: 0.9245 r:0.5420
ne_en Dev loss: 0.5426 r:0.7232
ru_en Dev loss: 0.4800 r:0.7329
Current avg r:0.5888 Best avg r: 0.6261
09:11:19,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:12:50,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:14:21,533 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1585
en_de Dev loss: 0.9155 r:0.1949
en_zh Dev loss: 0.7826 r:0.4627
ro_en Dev loss: 0.3603 r:0.8081
et_en Dev loss: 0.4917 r:0.6486
si_en Dev loss: 0.8267 r:0.5477
ne_en Dev loss: 0.4820 r:0.7236
ru_en Dev loss: 0.4437 r:0.7358
Current avg r:0.5888 Best avg r: 0.6261
09:18:53,809 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:20:24,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:21:55,468 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1562
en_de Dev loss: 0.9316 r:0.1960
en_zh Dev loss: 0.8403 r:0.4565
ro_en Dev loss: 0.3956 r:0.8098
et_en Dev loss: 0.5081 r:0.6566
si_en Dev loss: 0.8770 r:0.5529
ne_en Dev loss: 0.4976 r:0.7219
ru_en Dev loss: 0.4730 r:0.7328
Current avg r:0.5895 Best avg r: 0.6261
09:26:29,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:27:59,919 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:29:30,719 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1322
en_de Dev loss: 0.9372 r:0.2079
en_zh Dev loss: 0.8701 r:0.4619
ro_en Dev loss: 0.4393 r:0.8097
et_en Dev loss: 0.5055 r:0.6567
si_en Dev loss: 0.9332 r:0.5533
ne_en Dev loss: 0.5825 r:0.7213
ru_en Dev loss: 0.5093 r:0.7350
Current avg r:0.5923 Best avg r: 0.6261
09:34:03,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:33,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:37:04,718 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1465
en_de Dev loss: 0.8850 r:0.2152
en_zh Dev loss: 0.8088 r:0.4575
ro_en Dev loss: 0.3951 r:0.8089
et_en Dev loss: 0.4800 r:0.6488
si_en Dev loss: 0.9143 r:0.5473
ne_en Dev loss: 0.6092 r:0.7190
ru_en Dev loss: 0.4767 r:0.7279
Current avg r:0.5892 Best avg r: 0.6261
09:41:37,17 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:07,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:44:38,603 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1470
en_de Dev loss: 0.8823 r:0.2278
en_zh Dev loss: 0.7655 r:0.4590
ro_en Dev loss: 0.3577 r:0.8100
et_en Dev loss: 0.4605 r:0.6556
si_en Dev loss: 0.8310 r:0.5485
ne_en Dev loss: 0.5029 r:0.7152
ru_en Dev loss: 0.4389 r:0.7324
Current avg r:0.5926 Best avg r: 0.6261
09:49:10,905 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:50:41,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:52:12,578 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1552
en_de Dev loss: 0.8830 r:0.2245
en_zh Dev loss: 0.8195 r:0.4555
ro_en Dev loss: 0.3716 r:0.8125
et_en Dev loss: 0.4958 r:0.6635
si_en Dev loss: 0.8250 r:0.5623
ne_en Dev loss: 0.4867 r:0.7173
ru_en Dev loss: 0.4392 r:0.7383
Current avg r:0.5963 Best avg r: 0.6261
09:56:44,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:15,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:46,475 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1500
en_de Dev loss: 0.9605 r:0.2188
en_zh Dev loss: 0.8700 r:0.4629
ro_en Dev loss: 0.4363 r:0.8077
et_en Dev loss: 0.5323 r:0.6493
si_en Dev loss: 0.9297 r:0.5493
ne_en Dev loss: 0.5573 r:0.7154
ru_en Dev loss: 0.5455 r:0.7174
Current avg r:0.5887 Best avg r: 0.6261
10:04:18,810 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:49,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:20,507 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1515
en_de Dev loss: 0.9012 r:0.2158
en_zh Dev loss: 0.7889 r:0.4586
ro_en Dev loss: 0.3756 r:0.8078
et_en Dev loss: 0.4783 r:0.6534
si_en Dev loss: 0.9210 r:0.5532
ne_en Dev loss: 0.5936 r:0.7127
ru_en Dev loss: 0.4775 r:0.7284
Current avg r:0.5900 Best avg r: 0.6261
10:11:52,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:23,703 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:54,505 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1474
en_de Dev loss: 0.9025 r:0.2188
en_zh Dev loss: 0.7595 r:0.4698
ro_en Dev loss: 0.3633 r:0.8112
et_en Dev loss: 0.4933 r:0.6609
si_en Dev loss: 0.8286 r:0.5557
ne_en Dev loss: 0.4953 r:0.7146
ru_en Dev loss: 0.4462 r:0.7377
Current avg r:0.5955 Best avg r: 0.6261
10:19:26,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:57,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:28,484 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1380
en_de Dev loss: 0.8798 r:0.2282
en_zh Dev loss: 0.7959 r:0.4560
ro_en Dev loss: 0.3947 r:0.8033
et_en Dev loss: 0.4757 r:0.6499
si_en Dev loss: 0.9076 r:0.5459
ne_en Dev loss: 0.5297 r:0.7203
ru_en Dev loss: 0.4937 r:0.7170
Current avg r:0.5887 Best avg r: 0.6261
10:27:00,806 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:31,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:30:02,474 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1442
en_de Dev loss: 0.9123 r:0.2039
en_zh Dev loss: 0.8008 r:0.4609
ro_en Dev loss: 0.3830 r:0.8051
et_en Dev loss: 0.5049 r:0.6442
si_en Dev loss: 0.8942 r:0.5458
ne_en Dev loss: 0.5324 r:0.7186
ru_en Dev loss: 0.4795 r:0.7225
Current avg r:0.5859 Best avg r: 0.6261
