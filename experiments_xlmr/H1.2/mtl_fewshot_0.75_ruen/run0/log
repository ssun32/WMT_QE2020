14:42:52,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:43:18,464 root INFO 
id:en_zh cur r: 0.1795 best r: 0.1795
14:43:31,282 root INFO 
id:ro_en cur r: 0.3922 best r: 0.3922
14:43:44,102 root INFO 
id:et_en cur r: 0.4316 best r: 0.4316
14:43:56,927 root INFO 
id:si_en cur r: 0.4042 best r: 0.4042
14:44:09,762 root INFO 
id:ne_en cur r: 0.4737 best r: 0.4737
14:44:35,340 root INFO 
id:ru_en cur r: 0.5817 best r: 0.5817
14:44:35,341 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:04,983 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:46:04,990 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:46:04,995 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:46:04,999 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:46:05,4 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:46:05,9 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:46:05,13 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:46:17,782 root INFO Epoch 0 Global steps: 700 Train loss: 0.8871
en_de Dev loss: 0.8821 r:0.0971
en_zh Dev loss: 0.7887 r:0.2055
ro_en Dev loss: 0.7546 r:0.4387
et_en Dev loss: 0.6437 r:0.4233
si_en Dev loss: 0.8013 r:0.3618
ne_en Dev loss: 0.6702 r:0.4543
ru_en Dev loss: 0.6306 r:0.5829
Current avg r:0.3662 Best avg r: 0.3662
14:50:46,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:12,186 root INFO 
id:en_zh cur r: 0.2176 best r: 0.2176
14:51:24,984 root INFO 
id:ro_en cur r: 0.5096 best r: 0.5096
14:51:37,836 root INFO 
id:et_en cur r: 0.5373 best r: 0.5373
14:52:03,533 root INFO 
id:ne_en cur r: 0.5797 best r: 0.5797
14:52:29,85 root INFO 
id:ru_en cur r: 0.6306 best r: 0.6306
14:52:29,85 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:58,712 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:53:58,719 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:53:58,726 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:53:58,731 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:53:58,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:53:58,742 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:53:58,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:54:11,522 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8069
en_de Dev loss: 0.9044 r:0.0997
en_zh Dev loss: 0.7793 r:0.2630
ro_en Dev loss: 0.6290 r:0.5433
et_en Dev loss: 0.5321 r:0.5511
si_en Dev loss: 0.7379 r:0.4104
ne_en Dev loss: 0.5720 r:0.5563
ru_en Dev loss: 0.5442 r:0.6428
Current avg r:0.4381 Best avg r: 0.4381
14:58:40,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:05,856 root INFO 
id:en_zh cur r: 0.2674 best r: 0.2674
14:59:18,666 root INFO 
id:ro_en cur r: 0.5211 best r: 0.5211
15:00:22,646 root INFO 
id:ru_en cur r: 0.6607 best r: 0.6607
15:00:22,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:01:52,244 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:01:52,250 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:01:52,255 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:01:52,259 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:01:52,263 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:01:52,268 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:01:52,272 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:02:05,34 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7630
en_de Dev loss: 0.9438 r:0.1267
en_zh Dev loss: 0.8082 r:0.3132
ro_en Dev loss: 0.6752 r:0.5585
et_en Dev loss: 0.5302 r:0.5575
si_en Dev loss: 0.8157 r:0.4184
ne_en Dev loss: 0.6318 r:0.5018
ru_en Dev loss: 0.5468 r:0.6635
Current avg r:0.4485 Best avg r: 0.4485
15:06:33,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:06:46,579 root INFO 
id:en_de cur r: 0.0378 best r: 0.0378
15:06:59,352 root INFO 
id:en_zh cur r: 0.2704 best r: 0.2704
15:07:12,162 root INFO 
id:ro_en cur r: 0.6141 best r: 0.6141
15:07:24,977 root INFO 
id:et_en cur r: 0.5828 best r: 0.5828
15:07:37,794 root INFO 
id:si_en cur r: 0.4153 best r: 0.4153
15:08:16,127 root INFO 
id:ru_en cur r: 0.6724 best r: 0.6724
15:08:16,127 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:45,731 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:09:45,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:09:45,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:09:45,747 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:09:45,752 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:09:45,756 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:09:45,760 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:09:58,527 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7194
en_de Dev loss: 0.9449 r:0.1158
en_zh Dev loss: 0.7589 r:0.3304
ro_en Dev loss: 0.5290 r:0.6604
et_en Dev loss: 0.4542 r:0.6188
si_en Dev loss: 0.7353 r:0.4465
ne_en Dev loss: 0.5349 r:0.5892
ru_en Dev loss: 0.5050 r:0.6897
Current avg r:0.4930 Best avg r: 0.4930
15:14:27,330 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:40,144 root INFO 
id:en_de cur r: 0.0751 best r: 0.0751
15:14:52,920 root INFO 
id:en_zh cur r: 0.2789 best r: 0.2789
15:15:31,360 root INFO 
id:si_en cur r: 0.4183 best r: 0.4183
15:15:44,203 root INFO 
id:ne_en cur r: 0.5800 best r: 0.5800
15:15:56,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:26,611 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6676
en_de Dev loss: 1.0084 r:0.1347
en_zh Dev loss: 0.8489 r:0.3228
ro_en Dev loss: 0.6078 r:0.6628
et_en Dev loss: 0.4675 r:0.6142
si_en Dev loss: 0.8267 r:0.4569
ne_en Dev loss: 0.6814 r:0.5651
ru_en Dev loss: 0.6074 r:0.6629
Current avg r:0.4885 Best avg r: 0.4930
15:21:55,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:08,227 root INFO 
id:en_de cur r: 0.0995 best r: 0.0995
15:22:21,3 root INFO 
id:en_zh cur r: 0.3336 best r: 0.3336
15:22:33,806 root INFO 
id:ro_en cur r: 0.7039 best r: 0.7039
15:22:46,622 root INFO 
id:et_en cur r: 0.6262 best r: 0.6262
15:22:59,446 root INFO 
id:si_en cur r: 0.4827 best r: 0.4827
15:23:12,259 root INFO 
id:ne_en cur r: 0.6474 best r: 0.6474
15:23:37,776 root INFO 
id:ru_en cur r: 0.7170 best r: 0.7170
15:23:37,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:07,366 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:25:07,372 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:25:07,377 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:25:07,381 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:25:07,385 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:25:07,391 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:25:07,395 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:25:20,154 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6616
en_de Dev loss: 0.9603 r:0.1733
en_zh Dev loss: 0.8268 r:0.3562
ro_en Dev loss: 0.5107 r:0.7233
et_en Dev loss: 0.4488 r:0.6487
si_en Dev loss: 0.7926 r:0.5063
ne_en Dev loss: 0.5647 r:0.6445
ru_en Dev loss: 0.5411 r:0.7122
Current avg r:0.5378 Best avg r: 0.5378
15:29:51,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:04,679 root INFO 
id:en_de cur r: 0.1551 best r: 0.1551
15:30:17,595 root INFO 
id:en_zh cur r: 0.3818 best r: 0.3818
15:30:30,493 root INFO 
id:ro_en cur r: 0.7302 best r: 0.7302
15:30:43,406 root INFO 
id:et_en cur r: 0.6596 best r: 0.6596
15:30:56,328 root INFO 
id:si_en cur r: 0.5228 best r: 0.5228
15:31:09,262 root INFO 
id:ne_en cur r: 0.6936 best r: 0.6936
15:31:35,49 root INFO 
id:ru_en cur r: 0.7338 best r: 0.7338
15:31:35,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:05,434 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:33:05,439 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:33:05,444 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:33:05,449 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:33:05,454 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:33:05,459 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:33:05,464 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:33:18,301 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6423
en_de Dev loss: 0.9087 r:0.1800
en_zh Dev loss: 0.7074 r:0.3879
ro_en Dev loss: 0.4193 r:0.7362
et_en Dev loss: 0.3939 r:0.6780
si_en Dev loss: 0.6277 r:0.5378
ne_en Dev loss: 0.4339 r:0.6860
ru_en Dev loss: 0.4122 r:0.7350
Current avg r:0.5630 Best avg r: 0.5630
15:37:52,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:31,572 root INFO 
id:ro_en cur r: 0.7306 best r: 0.7306
15:38:44,557 root INFO 
id:et_en cur r: 0.6646 best r: 0.6646
15:38:57,488 root INFO 
id:si_en cur r: 0.5292 best r: 0.5292
15:39:23,235 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:53,612 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:40:53,619 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:40:53,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:40:53,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:40:53,634 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:40:53,638 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:40:53,643 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:41:06,497 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6136
en_de Dev loss: 0.8897 r:0.1869
en_zh Dev loss: 0.7078 r:0.3935
ro_en Dev loss: 0.4066 r:0.7408
et_en Dev loss: 0.3935 r:0.6804
si_en Dev loss: 0.6052 r:0.5423
ne_en Dev loss: 0.4410 r:0.6799
ru_en Dev loss: 0.4254 r:0.7349
Current avg r:0.5655 Best avg r: 0.5655
15:45:39,714 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:10,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:40,474 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6125
en_de Dev loss: 0.9278 r:0.1763
en_zh Dev loss: 0.7615 r:0.3892
ro_en Dev loss: 0.4403 r:0.7437
et_en Dev loss: 0.3979 r:0.6729
si_en Dev loss: 0.7299 r:0.5301
ne_en Dev loss: 0.4605 r:0.6812
ru_en Dev loss: 0.5166 r:0.7198
Current avg r:0.5590 Best avg r: 0.5655
15:53:12,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:25,199 root INFO 
id:en_de cur r: 0.1650 best r: 0.1650
15:53:38,163 root INFO 
id:en_zh cur r: 0.3972 best r: 0.3972
15:53:51,78 root INFO 
id:ro_en cur r: 0.7539 best r: 0.7539
15:54:04,2 root INFO 
id:et_en cur r: 0.6656 best r: 0.6656
15:54:42,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:13,267 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:56:13,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:56:13,280 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:56:13,286 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:56:13,291 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:56:13,297 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:56:13,303 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:56:26,162 root INFO Epoch 0 Global steps: 7000 Train loss: 0.6134
en_de Dev loss: 0.9126 r:0.1995
en_zh Dev loss: 0.7377 r:0.4113
ro_en Dev loss: 0.4194 r:0.7638
et_en Dev loss: 0.4086 r:0.6796
si_en Dev loss: 0.7348 r:0.5422
ne_en Dev loss: 0.4559 r:0.6967
ru_en Dev loss: 0.5081 r:0.7314
Current avg r:0.5749 Best avg r: 0.5749
16:00:58,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:01:11,819 root INFO 
id:en_de cur r: 0.1830 best r: 0.1830
16:01:24,711 root INFO 
id:en_zh cur r: 0.4113 best r: 0.4113
16:01:37,655 root INFO 
id:ro_en cur r: 0.7650 best r: 0.7650
16:01:50,581 root INFO 
id:et_en cur r: 0.6890 best r: 0.6890
16:02:03,558 root INFO 
id:si_en cur r: 0.5657 best r: 0.5657
16:02:16,525 root INFO 
id:ne_en cur r: 0.7141 best r: 0.7141
16:02:42,289 root INFO 
id:ru_en cur r: 0.7424 best r: 0.7424
16:02:42,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:12,663 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:04:12,670 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:04:12,676 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:04:12,681 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:04:12,686 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:04:12,692 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:04:12,697 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:04:25,556 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5982
en_de Dev loss: 0.8841 r:0.2111
en_zh Dev loss: 0.6855 r:0.4223
ro_en Dev loss: 0.3772 r:0.7692
et_en Dev loss: 0.3603 r:0.7001
si_en Dev loss: 0.5797 r:0.5768
ne_en Dev loss: 0.3989 r:0.7180
ru_en Dev loss: 0.4251 r:0.7459
Current avg r:0.5919 Best avg r: 0.5919
16:08:58,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:11,322 root INFO 
id:en_de cur r: 0.2224 best r: 0.2224
16:09:24,202 root INFO 
id:en_zh cur r: 0.4313 best r: 0.4313
16:09:37,112 root INFO 
id:ro_en cur r: 0.7731 best r: 0.7731
16:09:50,57 root INFO 
id:et_en cur r: 0.6925 best r: 0.6925
16:10:03,31 root INFO 
id:si_en cur r: 0.5726 best r: 0.5726
16:10:15,958 root INFO 
id:ne_en cur r: 0.7192 best r: 0.7192
16:10:41,689 root INFO 
id:ru_en cur r: 0.7442 best r: 0.7442
16:10:41,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:12,123 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:12:12,129 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:12:12,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:12:12,141 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:12:12,149 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:12:12,153 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:12:12,158 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:12:25,48 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5133
en_de Dev loss: 0.8654 r:0.2217
en_zh Dev loss: 0.6832 r:0.4456
ro_en Dev loss: 0.3618 r:0.7696
et_en Dev loss: 0.3716 r:0.6997
si_en Dev loss: 0.5738 r:0.5833
ne_en Dev loss: 0.4050 r:0.7184
ru_en Dev loss: 0.4223 r:0.7491
Current avg r:0.5982 Best avg r: 0.5982
16:16:56,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:27,296 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:57,624 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5687
en_de Dev loss: 0.8730 r:0.2263
en_zh Dev loss: 0.7298 r:0.4299
ro_en Dev loss: 0.4101 r:0.7710
et_en Dev loss: 0.3928 r:0.6941
si_en Dev loss: 0.7753 r:0.5478
ne_en Dev loss: 0.5105 r:0.6861
ru_en Dev loss: 0.5273 r:0.7206
Current avg r:0.5822 Best avg r: 0.5982
16:24:30,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:25:09,666 root INFO 
id:ro_en cur r: 0.7812 best r: 0.7812
16:25:35,510 root INFO 
id:si_en cur r: 0.5856 best r: 0.5856
16:25:48,418 root INFO 
id:ne_en cur r: 0.7209 best r: 0.7209
16:26:01,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:31,597 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:27:31,604 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:27:31,609 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:27:31,613 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:27:31,618 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:27:31,623 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:27:31,627 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:27:44,495 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5247
en_de Dev loss: 0.8792 r:0.2383
en_zh Dev loss: 0.7436 r:0.4374
ro_en Dev loss: 0.3875 r:0.7857
et_en Dev loss: 0.3837 r:0.7039
si_en Dev loss: 0.6448 r:0.5888
ne_en Dev loss: 0.4382 r:0.7168
ru_en Dev loss: 0.5119 r:0.7321
Current avg r:0.6004 Best avg r: 0.6004
16:32:17,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:43,350 root INFO 
id:en_zh cur r: 0.4395 best r: 0.4395
16:32:56,268 root INFO 
id:ro_en cur r: 0.7872 best r: 0.7872
16:33:09,239 root INFO 
id:et_en cur r: 0.7014 best r: 0.7014
16:33:35,85 root INFO 
id:ne_en cur r: 0.7269 best r: 0.7269
16:33:47,947 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:18,286 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:35:18,293 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:35:18,298 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:35:18,303 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:35:18,307 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:35:18,313 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:35:18,317 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:35:31,188 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5379
en_de Dev loss: 0.9089 r:0.2444
en_zh Dev loss: 0.7594 r:0.4475
ro_en Dev loss: 0.4062 r:0.7864
et_en Dev loss: 0.3960 r:0.7050
si_en Dev loss: 0.6460 r:0.5911
ne_en Dev loss: 0.4211 r:0.7244
ru_en Dev loss: 0.5051 r:0.7383
Current avg r:0.6053 Best avg r: 0.6053
16:40:02,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:40:28,473 root INFO 
id:en_zh cur r: 0.4411 best r: 0.4411
16:41:07,275 root INFO 
id:si_en cur r: 0.5927 best r: 0.5927
16:41:20,222 root INFO 
id:ne_en cur r: 0.7279 best r: 0.7279
16:41:33,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:43:03,512 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5729
en_de Dev loss: 0.8391 r:0.2396
en_zh Dev loss: 0.6833 r:0.4422
ro_en Dev loss: 0.3583 r:0.7841
et_en Dev loss: 0.3652 r:0.7053
si_en Dev loss: 0.5540 r:0.6007
ne_en Dev loss: 0.3959 r:0.7280
ru_en Dev loss: 0.4670 r:0.7203
Current avg r:0.6029 Best avg r: 0.6053
16:47:39,87 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:51,991 root INFO 
id:en_de cur r: 0.2369 best r: 0.2369
16:48:04,933 root INFO 
id:en_zh cur r: 0.4416 best r: 0.4416
16:48:17,844 root INFO 
id:ro_en cur r: 0.7994 best r: 0.7994
16:48:30,817 root INFO 
id:et_en cur r: 0.7076 best r: 0.7076
16:48:43,823 root INFO 
id:si_en cur r: 0.6027 best r: 0.6027
16:48:56,834 root INFO 
id:ne_en cur r: 0.7417 best r: 0.7417
16:49:09,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:40,211 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:50:40,217 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:50:40,222 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:50:40,227 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:50:40,231 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:50:40,236 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:50:40,242 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:50:53,102 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5485
en_de Dev loss: 0.8548 r:0.2504
en_zh Dev loss: 0.7292 r:0.4402
ro_en Dev loss: 0.3482 r:0.7942
et_en Dev loss: 0.3599 r:0.7087
si_en Dev loss: 0.6267 r:0.5974
ne_en Dev loss: 0.4330 r:0.7368
ru_en Dev loss: 0.4428 r:0.7340
Current avg r:0.6088 Best avg r: 0.6088
16:55:24,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:50,469 root INFO 
id:en_zh cur r: 0.4531 best r: 0.4531
16:56:03,371 root INFO 
id:ro_en cur r: 0.8008 best r: 0.8008
16:56:42,191 root INFO 
id:ne_en cur r: 0.7517 best r: 0.7517
16:57:07,905 root INFO 
id:ru_en cur r: 0.7495 best r: 0.7495
16:57:07,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:58:38,303 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:58:38,309 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:58:38,314 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:58:38,319 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:58:38,324 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:58:38,329 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:58:38,334 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:58:51,183 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5530
en_de Dev loss: 0.8451 r:0.2609
en_zh Dev loss: 0.6975 r:0.4511
ro_en Dev loss: 0.3473 r:0.7987
et_en Dev loss: 0.3702 r:0.7082
si_en Dev loss: 0.6441 r:0.6018
ne_en Dev loss: 0.3728 r:0.7521
ru_en Dev loss: 0.4229 r:0.7490
Current avg r:0.6174 Best avg r: 0.6174
17:03:22,875 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:04:53,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:06:23,802 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5221
en_de Dev loss: 0.8709 r:0.2326
en_zh Dev loss: 0.7760 r:0.4368
ro_en Dev loss: 0.4221 r:0.7885
et_en Dev loss: 0.4030 r:0.6988
si_en Dev loss: 0.8293 r:0.5634
ne_en Dev loss: 0.4494 r:0.7336
ru_en Dev loss: 0.5004 r:0.7386
Current avg r:0.5989 Best avg r: 0.6174
17:10:57,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:11:10,461 root INFO 
id:en_de cur r: 0.2591 best r: 0.2591
17:11:23,397 root INFO 
id:en_zh cur r: 0.4602 best r: 0.4602
17:11:36,379 root INFO 
id:ro_en cur r: 0.8042 best r: 0.8042
17:12:28,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:58,547 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:13:58,554 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:13:58,559 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:13:58,564 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:13:58,569 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:13:58,573 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:13:58,578 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:14:11,427 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5053
en_de Dev loss: 0.8709 r:0.2544
en_zh Dev loss: 0.7275 r:0.4576
ro_en Dev loss: 0.3626 r:0.8041
et_en Dev loss: 0.3667 r:0.7120
si_en Dev loss: 0.6697 r:0.5974
ne_en Dev loss: 0.3947 r:0.7455
ru_en Dev loss: 0.4834 r:0.7524
Current avg r:0.6176 Best avg r: 0.6176
17:18:43,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:20:14,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:21:44,653 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5418
en_de Dev loss: 0.8883 r:0.2531
en_zh Dev loss: 0.7758 r:0.4511
ro_en Dev loss: 0.4011 r:0.8035
et_en Dev loss: 0.3807 r:0.7109
si_en Dev loss: 0.7567 r:0.5976
ne_en Dev loss: 0.4948 r:0.7455
ru_en Dev loss: 0.5472 r:0.7344
Current avg r:0.6137 Best avg r: 0.6176
17:26:18,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:44,110 root INFO 
id:en_zh cur r: 0.4633 best r: 0.4633
17:26:57,56 root INFO 
id:ro_en cur r: 0.8055 best r: 0.8055
17:27:22,943 root INFO 
id:si_en cur r: 0.6105 best r: 0.6105
17:27:35,861 root INFO 
id:ne_en cur r: 0.7528 best r: 0.7528
17:28:01,608 root INFO 
id:ru_en cur r: 0.7573 best r: 0.7573
17:28:01,608 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:29:32,59 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:29:32,65 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:29:32,70 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:29:32,75 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:29:32,80 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:29:32,85 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:29:32,90 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:29:45,10 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5331
en_de Dev loss: 0.8741 r:0.2520
en_zh Dev loss: 0.7155 r:0.4593
ro_en Dev loss: 0.3620 r:0.8052
et_en Dev loss: 0.3740 r:0.7108
si_en Dev loss: 0.6038 r:0.6126
ne_en Dev loss: 0.3739 r:0.7539
ru_en Dev loss: 0.4273 r:0.7574
Current avg r:0.6216 Best avg r: 0.6216
17:34:19,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:35:50,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:37:20,743 root INFO Epoch 2 Global steps: 16100 Train loss: 0.4877
en_de Dev loss: 0.8658 r:0.2485
en_zh Dev loss: 0.7090 r:0.4550
ro_en Dev loss: 0.3472 r:0.8053
et_en Dev loss: 0.3735 r:0.7034
si_en Dev loss: 0.7013 r:0.5903
ne_en Dev loss: 0.3763 r:0.7495
ru_en Dev loss: 0.4561 r:0.7418
Current avg r:0.6134 Best avg r: 0.6216
17:41:56,105 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:43:26,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:44:56,950 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4926
en_de Dev loss: 0.8891 r:0.2451
en_zh Dev loss: 0.7349 r:0.4545
ro_en Dev loss: 0.3581 r:0.8061
et_en Dev loss: 0.3801 r:0.7057
si_en Dev loss: 0.6485 r:0.6032
ne_en Dev loss: 0.3840 r:0.7475
ru_en Dev loss: 0.4876 r:0.7409
Current avg r:0.6147 Best avg r: 0.6216
17:49:29,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:49:55,204 root INFO 
id:en_zh cur r: 0.4659 best r: 0.4659
17:50:46,956 root INFO 
id:ne_en cur r: 0.7553 best r: 0.7553
17:50:59,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:52:30,440 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4630
en_de Dev loss: 0.8630 r:0.2510
en_zh Dev loss: 0.7174 r:0.4601
ro_en Dev loss: 0.3758 r:0.8046
et_en Dev loss: 0.3699 r:0.7087
si_en Dev loss: 0.6322 r:0.6052
ne_en Dev loss: 0.3980 r:0.7524
ru_en Dev loss: 0.4824 r:0.7310
Current avg r:0.6161 Best avg r: 0.6216
17:57:02,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:58:33,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:00:03,661 root INFO Epoch 2 Global steps: 18200 Train loss: 0.5211
en_de Dev loss: 0.9090 r:0.2337
en_zh Dev loss: 0.8230 r:0.4514
ro_en Dev loss: 0.4170 r:0.7996
et_en Dev loss: 0.4182 r:0.6935
si_en Dev loss: 0.8050 r:0.5834
ne_en Dev loss: 0.4259 r:0.7362
ru_en Dev loss: 0.4752 r:0.7480
Current avg r:0.6065 Best avg r: 0.6216
18:04:35,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:05:01,666 root INFO 
id:en_zh cur r: 0.4738 best r: 0.4738
18:06:19,132 root INFO 
id:ru_en cur r: 0.7579 best r: 0.7579
18:06:19,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:07:49,513 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4951
en_de Dev loss: 0.9044 r:0.2415
en_zh Dev loss: 0.7772 r:0.4710
ro_en Dev loss: 0.4125 r:0.8029
et_en Dev loss: 0.4206 r:0.6992
si_en Dev loss: 0.9321 r:0.5800
ne_en Dev loss: 0.5515 r:0.7366
ru_en Dev loss: 0.4941 r:0.7529
Current avg r:0.6120 Best avg r: 0.6216
18:12:22,713 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:13:01,483 root INFO 
id:ro_en cur r: 0.8105 best r: 0.8105
18:13:14,420 root INFO 
id:et_en cur r: 0.7084 best r: 0.7084
18:13:27,354 root INFO 
id:si_en cur r: 0.6107 best r: 0.6107
18:13:40,284 root INFO 
id:ne_en cur r: 0.7605 best r: 0.7605
18:13:53,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:15:23,783 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4782
en_de Dev loss: 0.8622 r:0.2380
en_zh Dev loss: 0.6915 r:0.4642
ro_en Dev loss: 0.3347 r:0.8137
et_en Dev loss: 0.3782 r:0.7083
si_en Dev loss: 0.6610 r:0.6074
ne_en Dev loss: 0.3642 r:0.7551
ru_en Dev loss: 0.4391 r:0.7479
Current avg r:0.6192 Best avg r: 0.6216
18:19:56,832 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:20:35,721 root INFO 
id:ro_en cur r: 0.8112 best r: 0.8112
18:21:27,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:22:57,901 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4854
en_de Dev loss: 0.8541 r:0.2422
en_zh Dev loss: 0.7238 r:0.4578
ro_en Dev loss: 0.3280 r:0.8140
et_en Dev loss: 0.3798 r:0.7005
si_en Dev loss: 0.6712 r:0.6015
ne_en Dev loss: 0.3702 r:0.7515
ru_en Dev loss: 0.4407 r:0.7439
Current avg r:0.6159 Best avg r: 0.6216
18:27:31,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:28:10,227 root INFO 
id:ro_en cur r: 0.8192 best r: 0.8192
18:28:36,90 root INFO 
id:si_en cur r: 0.6146 best r: 0.6146
18:29:01,979 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:30:32,352 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
18:30:32,363 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:30:32,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:30:32,376 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
18:30:32,381 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
18:30:32,387 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:30:32,393 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:30:45,244 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4518
en_de Dev loss: 0.8287 r:0.2628
en_zh Dev loss: 0.6774 r:0.4649
ro_en Dev loss: 0.3143 r:0.8182
et_en Dev loss: 0.3982 r:0.7050
si_en Dev loss: 0.6353 r:0.6075
ne_en Dev loss: 0.3548 r:0.7584
ru_en Dev loss: 0.3749 r:0.7602
Current avg r:0.6253 Best avg r: 0.6253
18:35:18,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:31,270 root INFO 
id:en_de cur r: 0.2647 best r: 0.2647
18:36:48,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:38:19,253 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4637
en_de Dev loss: 0.8378 r:0.2722
en_zh Dev loss: 0.7178 r:0.4636
ro_en Dev loss: 0.3326 r:0.8159
et_en Dev loss: 0.4009 r:0.7005
si_en Dev loss: 0.7607 r:0.5944
ne_en Dev loss: 0.4633 r:0.7487
ru_en Dev loss: 0.4250 r:0.7515
Current avg r:0.6210 Best avg r: 0.6253
18:42:52,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:44:22,898 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:45:53,233 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4767
en_de Dev loss: 0.8659 r:0.2574
en_zh Dev loss: 0.7477 r:0.4619
ro_en Dev loss: 0.3876 r:0.8099
et_en Dev loss: 0.4221 r:0.6899
si_en Dev loss: 0.8941 r:0.5747
ne_en Dev loss: 0.4724 r:0.7454
ru_en Dev loss: 0.5226 r:0.7222
Current avg r:0.6088 Best avg r: 0.6253
18:50:24,720 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:55,28 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:53:25,358 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4582
en_de Dev loss: 0.8512 r:0.2715
en_zh Dev loss: 0.7331 r:0.4655
ro_en Dev loss: 0.3656 r:0.8158
et_en Dev loss: 0.3932 r:0.6992
si_en Dev loss: 0.8489 r:0.5968
ne_en Dev loss: 0.5000 r:0.7535
ru_en Dev loss: 0.4859 r:0.7374
Current avg r:0.6200 Best avg r: 0.6253
18:57:56,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:14,373 root INFO 
id:ne_en cur r: 0.7627 best r: 0.7627
18:59:27,330 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:00:57,911 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4575
en_de Dev loss: 0.9055 r:0.2597
en_zh Dev loss: 0.8159 r:0.4488
ro_en Dev loss: 0.3905 r:0.8118
et_en Dev loss: 0.4136 r:0.6997
si_en Dev loss: 0.8397 r:0.5966
ne_en Dev loss: 0.4867 r:0.7575
ru_en Dev loss: 0.5574 r:0.7245
Current avg r:0.6141 Best avg r: 0.6253
19:05:33,222 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:05:46,194 root INFO 
id:en_de cur r: 0.2686 best r: 0.2686
19:07:03,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:08:33,915 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4504
en_de Dev loss: 0.8682 r:0.2737
en_zh Dev loss: 0.7508 r:0.4526
ro_en Dev loss: 0.3681 r:0.8072
et_en Dev loss: 0.4043 r:0.6856
si_en Dev loss: 0.7881 r:0.5850
ne_en Dev loss: 0.4624 r:0.7424
ru_en Dev loss: 0.5268 r:0.7114
Current avg r:0.6083 Best avg r: 0.6253
19:13:06,165 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:14:36,535 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:16:06,897 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4677
en_de Dev loss: 0.8501 r:0.2749
en_zh Dev loss: 0.7553 r:0.4530
ro_en Dev loss: 0.3581 r:0.8137
et_en Dev loss: 0.4051 r:0.6924
si_en Dev loss: 0.7110 r:0.5956
ne_en Dev loss: 0.4086 r:0.7525
ru_en Dev loss: 0.4830 r:0.7249
Current avg r:0.6153 Best avg r: 0.6253
19:20:40,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:11,371 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:23:41,726 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4192
en_de Dev loss: 0.8704 r:0.2296
en_zh Dev loss: 0.7987 r:0.4608
ro_en Dev loss: 0.3938 r:0.8127
et_en Dev loss: 0.4099 r:0.6903
si_en Dev loss: 0.7204 r:0.5905
ne_en Dev loss: 0.4855 r:0.7492
ru_en Dev loss: 0.4978 r:0.7232
Current avg r:0.6081 Best avg r: 0.6253
19:28:13,514 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:29:43,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:31:14,190 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4198
en_de Dev loss: 0.8480 r:0.2594
en_zh Dev loss: 0.7190 r:0.4553
ro_en Dev loss: 0.3694 r:0.8134
et_en Dev loss: 0.3990 r:0.6920
si_en Dev loss: 0.7591 r:0.5820
ne_en Dev loss: 0.4210 r:0.7539
ru_en Dev loss: 0.4980 r:0.7074
Current avg r:0.6091 Best avg r: 0.6253
19:35:46,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:36:24,876 root INFO 
id:ro_en cur r: 0.8210 best r: 0.8210
19:37:16,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:38:47,81 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4331
en_de Dev loss: 0.8309 r:0.2548
en_zh Dev loss: 0.6755 r:0.4565
ro_en Dev loss: 0.3124 r:0.8186
et_en Dev loss: 0.3770 r:0.7039
si_en Dev loss: 0.5825 r:0.6051
ne_en Dev loss: 0.3659 r:0.7605
ru_en Dev loss: 0.4348 r:0.7148
Current avg r:0.6163 Best avg r: 0.6253
19:43:18,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:44:36,715 root INFO 
id:ne_en cur r: 0.7633 best r: 0.7633
19:44:49,569 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:46:19,907 root INFO Epoch 3 Global steps: 28000 Train loss: 0.4323
en_de Dev loss: 0.8546 r:0.2471
en_zh Dev loss: 0.7581 r:0.4562
ro_en Dev loss: 0.3690 r:0.8180
et_en Dev loss: 0.4069 r:0.6976
si_en Dev loss: 0.7409 r:0.5962
ne_en Dev loss: 0.3752 r:0.7641
ru_en Dev loss: 0.4989 r:0.7163
Current avg r:0.6137 Best avg r: 0.6253
19:50:51,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:52:22,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:53:52,385 root INFO Epoch 3 Global steps: 28700 Train loss: 0.3991
en_de Dev loss: 0.8469 r:0.2614
en_zh Dev loss: 0.7482 r:0.4541
ro_en Dev loss: 0.3539 r:0.8175
et_en Dev loss: 0.3976 r:0.7015
si_en Dev loss: 0.6814 r:0.6041
ne_en Dev loss: 0.3765 r:0.7616
ru_en Dev loss: 0.4743 r:0.7244
Current avg r:0.6178 Best avg r: 0.6253
19:58:23,979 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:58:36,892 root INFO 
id:en_de cur r: 0.2945 best r: 0.2945
19:59:02,667 root INFO 
id:ro_en cur r: 0.8248 best r: 0.8248
19:59:54,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:01:24,908 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4115
en_de Dev loss: 0.8274 r:0.2900
en_zh Dev loss: 0.7224 r:0.4614
ro_en Dev loss: 0.3305 r:0.8226
et_en Dev loss: 0.3860 r:0.6998
si_en Dev loss: 0.7591 r:0.5959
ne_en Dev loss: 0.4827 r:0.7589
ru_en Dev loss: 0.4762 r:0.7236
Current avg r:0.6217 Best avg r: 0.6253
20:05:57,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:06:10,805 root INFO 
id:en_de cur r: 0.3022 best r: 0.3022
20:07:15,470 root INFO 
id:ne_en cur r: 0.7641 best r: 0.7641
20:07:28,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:08:58,636 root INFO Epoch 3 Global steps: 30100 Train loss: 0.3932
en_de Dev loss: 0.8719 r:0.2783
en_zh Dev loss: 0.8296 r:0.4546
ro_en Dev loss: 0.4310 r:0.8117
et_en Dev loss: 0.4376 r:0.6918
si_en Dev loss: 0.9015 r:0.5862
ne_en Dev loss: 0.5281 r:0.7628
ru_en Dev loss: 0.5160 r:0.7289
Current avg r:0.6163 Best avg r: 0.6253
20:13:30,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:13:43,86 root INFO 
id:en_de cur r: 0.3033 best r: 0.3033
20:14:47,689 root INFO 
id:ne_en cur r: 0.7645 best r: 0.7645
20:15:00,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:16:30,879 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_de.lang_agnost_mlp.dev.best.scores
20:16:30,885 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/en_zh.lang_agnost_mlp.dev.best.scores
20:16:30,890 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ro_en.lang_agnost_mlp.dev.best.scores
20:16:30,894 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/et_en.lang_agnost_mlp.dev.best.scores
20:16:30,900 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/si_en.lang_agnost_mlp.dev.best.scores
20:16:30,904 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ne_en.lang_agnost_mlp.dev.best.scores
20:16:30,909 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run0/ru_en.lang_agnost_mlp.dev.best.scores
20:16:43,769 root INFO Epoch 3 Global steps: 30800 Train loss: 0.4210
en_de Dev loss: 0.8137 r:0.3017
en_zh Dev loss: 0.7050 r:0.4688
ro_en Dev loss: 0.3040 r:0.8217
et_en Dev loss: 0.3671 r:0.7039
si_en Dev loss: 0.6217 r:0.6119
ne_en Dev loss: 0.3600 r:0.7677
ru_en Dev loss: 0.4082 r:0.7462
Current avg r:0.6317 Best avg r: 0.6317
20:21:15,548 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:22:45,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:24:16,500 root INFO Epoch 3 Global steps: 31500 Train loss: 0.4302
en_de Dev loss: 0.8364 r:0.2882
en_zh Dev loss: 0.7663 r:0.4541
ro_en Dev loss: 0.3244 r:0.8219
et_en Dev loss: 0.3847 r:0.6985
si_en Dev loss: 0.6939 r:0.6017
ne_en Dev loss: 0.4348 r:0.7617
ru_en Dev loss: 0.4532 r:0.7324
Current avg r:0.6226 Best avg r: 0.6317
20:28:51,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:30:09,713 root INFO 
id:ne_en cur r: 0.7665 best r: 0.7665
20:30:22,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:31:52,891 root INFO Epoch 4 Global steps: 32200 Train loss: 0.4172
en_de Dev loss: 0.8519 r:0.2915
en_zh Dev loss: 0.8130 r:0.4541
ro_en Dev loss: 0.3959 r:0.8162
et_en Dev loss: 0.4177 r:0.6977
si_en Dev loss: 0.8160 r:0.5936
ne_en Dev loss: 0.5178 r:0.7643
ru_en Dev loss: 0.5797 r:0.7090
Current avg r:0.6181 Best avg r: 0.6317
20:36:24,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:37:55,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:39:25,574 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3801
en_de Dev loss: 0.8727 r:0.2641
en_zh Dev loss: 0.7837 r:0.4421
ro_en Dev loss: 0.3525 r:0.8165
et_en Dev loss: 0.4219 r:0.6931
si_en Dev loss: 0.6887 r:0.5957
ne_en Dev loss: 0.3879 r:0.7572
ru_en Dev loss: 0.4993 r:0.7189
Current avg r:0.6125 Best avg r: 0.6317
20:43:56,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:44:09,799 root INFO 
id:en_de cur r: 0.3099 best r: 0.3099
20:45:27,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:46:57,849 root INFO Epoch 4 Global steps: 33600 Train loss: 0.3697
en_de Dev loss: 0.8696 r:0.2911
en_zh Dev loss: 0.8469 r:0.4476
ro_en Dev loss: 0.3980 r:0.8126
et_en Dev loss: 0.4273 r:0.6866
si_en Dev loss: 0.8925 r:0.5822
ne_en Dev loss: 0.4845 r:0.7597
ru_en Dev loss: 0.5348 r:0.7193
Current avg r:0.6141 Best avg r: 0.6317
20:51:29,218 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:52:59,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:54:29,847 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3697
en_de Dev loss: 0.8809 r:0.2870
en_zh Dev loss: 0.8452 r:0.4454
ro_en Dev loss: 0.3858 r:0.8164
et_en Dev loss: 0.4156 r:0.6850
si_en Dev loss: 0.8363 r:0.5822
ne_en Dev loss: 0.4750 r:0.7546
ru_en Dev loss: 0.5964 r:0.7007
Current avg r:0.6102 Best avg r: 0.6317
20:59:05,193 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:59:43,877 root INFO 
id:ro_en cur r: 0.8264 best r: 0.8264
21:00:22,666 root INFO 
id:ne_en cur r: 0.7694 best r: 0.7694
21:00:35,534 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:02:06,15 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3635
en_de Dev loss: 0.8712 r:0.2640
en_zh Dev loss: 0.7572 r:0.4540
ro_en Dev loss: 0.3294 r:0.8248
et_en Dev loss: 0.4013 r:0.6966
si_en Dev loss: 0.7140 r:0.5970
ne_en Dev loss: 0.3660 r:0.7651
ru_en Dev loss: 0.4482 r:0.7351
Current avg r:0.6195 Best avg r: 0.6317
21:06:38,78 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:08:08,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:09:38,901 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3493
en_de Dev loss: 0.8317 r:0.2843
en_zh Dev loss: 0.7351 r:0.4559
ro_en Dev loss: 0.3473 r:0.8151
et_en Dev loss: 0.4204 r:0.6922
si_en Dev loss: 0.6915 r:0.5941
ne_en Dev loss: 0.3622 r:0.7592
ru_en Dev loss: 0.4243 r:0.7366
Current avg r:0.6196 Best avg r: 0.6317
21:14:12,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:15:42,510 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:17:12,781 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3747
en_de Dev loss: 0.9052 r:0.2444
en_zh Dev loss: 0.8523 r:0.4307
ro_en Dev loss: 0.3648 r:0.8195
et_en Dev loss: 0.4037 r:0.6878
si_en Dev loss: 0.7337 r:0.5866
ne_en Dev loss: 0.4087 r:0.7575
ru_en Dev loss: 0.5400 r:0.7007
Current avg r:0.6039 Best avg r: 0.6317
21:21:45,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:23:15,526 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:24:46,307 root INFO Epoch 4 Global steps: 37100 Train loss: 0.4125
en_de Dev loss: 0.8591 r:0.2444
en_zh Dev loss: 0.7860 r:0.4564
ro_en Dev loss: 0.3465 r:0.8262
et_en Dev loss: 0.4156 r:0.6882
si_en Dev loss: 0.6926 r:0.5994
ne_en Dev loss: 0.3830 r:0.7592
ru_en Dev loss: 0.5194 r:0.7121
Current avg r:0.6123 Best avg r: 0.6317
21:29:18,70 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:30:48,524 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:32:18,748 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3935
en_de Dev loss: 0.8553 r:0.2614
en_zh Dev loss: 0.8103 r:0.4527
ro_en Dev loss: 0.3849 r:0.8202
et_en Dev loss: 0.4197 r:0.6869
si_en Dev loss: 0.7922 r:0.5854
ne_en Dev loss: 0.4435 r:0.7541
ru_en Dev loss: 0.5738 r:0.6984
Current avg r:0.6084 Best avg r: 0.6317
21:36:51,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:38:21,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:39:52,49 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3705
en_de Dev loss: 0.8350 r:0.2670
en_zh Dev loss: 0.7408 r:0.4659
ro_en Dev loss: 0.3287 r:0.8245
et_en Dev loss: 0.4137 r:0.6941
si_en Dev loss: 0.7203 r:0.5972
ne_en Dev loss: 0.4442 r:0.7544
ru_en Dev loss: 0.4666 r:0.7249
Current avg r:0.6183 Best avg r: 0.6317
21:44:23,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:45:53,783 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:47:24,201 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3548
en_de Dev loss: 0.8450 r:0.2484
en_zh Dev loss: 0.7919 r:0.4449
ro_en Dev loss: 0.3345 r:0.8190
et_en Dev loss: 0.4233 r:0.6892
si_en Dev loss: 0.7213 r:0.5881
ne_en Dev loss: 0.4476 r:0.7447
ru_en Dev loss: 0.4637 r:0.7174
Current avg r:0.6074 Best avg r: 0.6317
21:51:58,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:53:28,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:54:58,929 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3179
en_de Dev loss: 0.8578 r:0.2538
en_zh Dev loss: 0.7826 r:0.4408
ro_en Dev loss: 0.3283 r:0.8227
et_en Dev loss: 0.4198 r:0.6875
si_en Dev loss: 0.6813 r:0.5864
ne_en Dev loss: 0.4576 r:0.7418
ru_en Dev loss: 0.5292 r:0.6871
Current avg r:0.6029 Best avg r: 0.6317
21:59:31,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:01:01,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:02:32,83 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3420
en_de Dev loss: 0.8647 r:0.2484
en_zh Dev loss: 0.7517 r:0.4722
ro_en Dev loss: 0.3250 r:0.8232
et_en Dev loss: 0.4111 r:0.6956
si_en Dev loss: 0.7064 r:0.5965
ne_en Dev loss: 0.4175 r:0.7562
ru_en Dev loss: 0.4761 r:0.7258
Current avg r:0.6168 Best avg r: 0.6317
22:07:03,591 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:08:34,144 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:10:04,406 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3439
en_de Dev loss: 0.8781 r:0.2675
en_zh Dev loss: 0.8021 r:0.4563
ro_en Dev loss: 0.3557 r:0.8191
et_en Dev loss: 0.4258 r:0.6844
si_en Dev loss: 0.8868 r:0.5773
ne_en Dev loss: 0.4584 r:0.7569
ru_en Dev loss: 0.5260 r:0.7074
Current avg r:0.6099 Best avg r: 0.6317
22:14:40,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:16:10,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:17:40,888 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3282
en_de Dev loss: 0.8579 r:0.2620
en_zh Dev loss: 0.7644 r:0.4499
ro_en Dev loss: 0.3346 r:0.8206
et_en Dev loss: 0.4488 r:0.6770
si_en Dev loss: 0.6916 r:0.5865
ne_en Dev loss: 0.4563 r:0.7492
ru_en Dev loss: 0.4866 r:0.7116
Current avg r:0.6081 Best avg r: 0.6317
22:22:13,965 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:23:44,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:25:14,998 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3147
en_de Dev loss: 0.8418 r:0.2508
en_zh Dev loss: 0.7647 r:0.4420
ro_en Dev loss: 0.3266 r:0.8187
et_en Dev loss: 0.4279 r:0.6758
si_en Dev loss: 0.7625 r:0.5791
ne_en Dev loss: 0.4210 r:0.7470
ru_en Dev loss: 0.4754 r:0.7067
Current avg r:0.6028 Best avg r: 0.6317
22:29:47,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:31:17,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:32:48,381 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3204
en_de Dev loss: 0.8941 r:0.2531
en_zh Dev loss: 0.7871 r:0.4682
ro_en Dev loss: 0.3621 r:0.8208
et_en Dev loss: 0.4296 r:0.6821
si_en Dev loss: 0.7964 r:0.5874
ne_en Dev loss: 0.4929 r:0.7536
ru_en Dev loss: 0.5336 r:0.7144
Current avg r:0.6114 Best avg r: 0.6317
22:37:23,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:38:54,377 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:40:24,627 root INFO Epoch 5 Global steps: 44100 Train loss: 0.3215
en_de Dev loss: 0.8942 r:0.2306
en_zh Dev loss: 0.8163 r:0.4327
ro_en Dev loss: 0.3546 r:0.8132
et_en Dev loss: 0.4242 r:0.6682
si_en Dev loss: 0.8171 r:0.5672
ne_en Dev loss: 0.4762 r:0.7430
ru_en Dev loss: 0.4922 r:0.7106
Current avg r:0.5951 Best avg r: 0.6317
22:44:56,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:46:26,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:47:57,500 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3523
en_de Dev loss: 0.8585 r:0.2239
en_zh Dev loss: 0.7999 r:0.4447
ro_en Dev loss: 0.3504 r:0.8186
et_en Dev loss: 0.4346 r:0.6780
si_en Dev loss: 0.8457 r:0.5720
ne_en Dev loss: 0.4731 r:0.7395
ru_en Dev loss: 0.5057 r:0.7050
Current avg r:0.5974 Best avg r: 0.6317
22:52:28,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:53:59,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:55:29,804 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3229
en_de Dev loss: 0.8599 r:0.2236
en_zh Dev loss: 0.7850 r:0.4320
ro_en Dev loss: 0.3416 r:0.8142
et_en Dev loss: 0.4692 r:0.6785
si_en Dev loss: 0.7578 r:0.5693
ne_en Dev loss: 0.4517 r:0.7370
ru_en Dev loss: 0.4700 r:0.7132
Current avg r:0.5954 Best avg r: 0.6317
23:00:01,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:01:31,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:03:01,936 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3352
en_de Dev loss: 0.8882 r:0.2118
en_zh Dev loss: 0.8334 r:0.4396
ro_en Dev loss: 0.3595 r:0.8197
et_en Dev loss: 0.4413 r:0.6794
si_en Dev loss: 0.8222 r:0.5818
ne_en Dev loss: 0.4803 r:0.7386
ru_en Dev loss: 0.4415 r:0.7473
Current avg r:0.6026 Best avg r: 0.6317
23:07:33,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:09:03,570 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:10:34,60 root INFO Epoch 5 Global steps: 46900 Train loss: 0.3299
en_de Dev loss: 0.8454 r:0.2495
en_zh Dev loss: 0.7589 r:0.4482
ro_en Dev loss: 0.3328 r:0.8231
et_en Dev loss: 0.4420 r:0.6812
si_en Dev loss: 0.7133 r:0.5893
ne_en Dev loss: 0.4705 r:0.7379
ru_en Dev loss: 0.4594 r:0.7244
Current avg r:0.6077 Best avg r: 0.6317
23:15:06,177 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:16:36,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:18:06,728 root INFO Epoch 5 Global steps: 47600 Train loss: 0.3156
en_de Dev loss: 0.8630 r:0.2253
en_zh Dev loss: 0.7701 r:0.4415
ro_en Dev loss: 0.3410 r:0.8183
et_en Dev loss: 0.4582 r:0.6762
si_en Dev loss: 0.7338 r:0.5809
ne_en Dev loss: 0.4292 r:0.7382
ru_en Dev loss: 0.4514 r:0.7284
Current avg r:0.6013 Best avg r: 0.6317
23:22:40,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:24:11,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:25:41,605 root INFO Epoch 6 Global steps: 48300 Train loss: 0.2984
en_de Dev loss: 0.8955 r:0.2200
en_zh Dev loss: 0.8438 r:0.4335
ro_en Dev loss: 0.3481 r:0.8200
et_en Dev loss: 0.4484 r:0.6766
si_en Dev loss: 0.7711 r:0.5846
ne_en Dev loss: 0.4549 r:0.7369
ru_en Dev loss: 0.4726 r:0.7359
Current avg r:0.6011 Best avg r: 0.6317
23:30:12,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:31:43,270 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:33:13,462 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2807
en_de Dev loss: 0.8492 r:0.2297
en_zh Dev loss: 0.7610 r:0.4477
ro_en Dev loss: 0.3204 r:0.8217
et_en Dev loss: 0.4768 r:0.6793
si_en Dev loss: 0.7125 r:0.5829
ne_en Dev loss: 0.4329 r:0.7325
ru_en Dev loss: 0.4275 r:0.7316
Current avg r:0.6036 Best avg r: 0.6317
23:37:44,930 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:39:15,148 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:40:45,298 root INFO Epoch 6 Global steps: 49700 Train loss: 0.3056
en_de Dev loss: 0.8751 r:0.2098
en_zh Dev loss: 0.8343 r:0.4302
ro_en Dev loss: 0.3777 r:0.8157
et_en Dev loss: 0.4523 r:0.6693
si_en Dev loss: 0.8121 r:0.5739
ne_en Dev loss: 0.4726 r:0.7351
ru_en Dev loss: 0.5154 r:0.7148
Current avg r:0.5927 Best avg r: 0.6317
23:45:17,292 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:46:47,546 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:48:18,156 root INFO Epoch 6 Global steps: 50400 Train loss: 0.2963
en_de Dev loss: 0.8875 r:0.2230
en_zh Dev loss: 0.8264 r:0.4412
ro_en Dev loss: 0.3840 r:0.8181
et_en Dev loss: 0.4416 r:0.6651
si_en Dev loss: 0.8490 r:0.5729
ne_en Dev loss: 0.5349 r:0.7336
ru_en Dev loss: 0.5507 r:0.7072
Current avg r:0.5945 Best avg r: 0.6317
23:52:51,406 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:54:21,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:55:52,2 root INFO Epoch 6 Global steps: 51100 Train loss: 0.2864
en_de Dev loss: 0.8768 r:0.2353
en_zh Dev loss: 0.7959 r:0.4575
ro_en Dev loss: 0.3565 r:0.8207
et_en Dev loss: 0.4674 r:0.6687
si_en Dev loss: 0.7665 r:0.5820
ne_en Dev loss: 0.4645 r:0.7334
ru_en Dev loss: 0.5070 r:0.7132
Current avg r:0.6015 Best avg r: 0.6317
00:00:25,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:01:55,494 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:03:25,727 root INFO Epoch 6 Global steps: 51800 Train loss: 0.2937
en_de Dev loss: 0.8895 r:0.2242
en_zh Dev loss: 0.8020 r:0.4514
ro_en Dev loss: 0.3631 r:0.8208
et_en Dev loss: 0.4417 r:0.6717
si_en Dev loss: 0.7730 r:0.5854
ne_en Dev loss: 0.4854 r:0.7332
ru_en Dev loss: 0.5202 r:0.7171
Current avg r:0.6005 Best avg r: 0.6317
00:07:59,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:09:29,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:00,65 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2989
en_de Dev loss: 0.8549 r:0.2373
en_zh Dev loss: 0.7476 r:0.4509
ro_en Dev loss: 0.3435 r:0.8164
et_en Dev loss: 0.4215 r:0.6780
si_en Dev loss: 0.7378 r:0.5838
ne_en Dev loss: 0.4708 r:0.7343
ru_en Dev loss: 0.4462 r:0.7300
Current avg r:0.6044 Best avg r: 0.6317
00:15:32,7 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:17:02,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:18:32,457 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2981
en_de Dev loss: 0.8683 r:0.2392
en_zh Dev loss: 0.7550 r:0.4629
ro_en Dev loss: 0.3337 r:0.8226
et_en Dev loss: 0.4471 r:0.6818
si_en Dev loss: 0.7114 r:0.5990
ne_en Dev loss: 0.4274 r:0.7352
ru_en Dev loss: 0.4338 r:0.7379
Current avg r:0.6112 Best avg r: 0.6317
00:23:05,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:24:36,216 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:26:06,706 root INFO Epoch 6 Global steps: 53900 Train loss: 0.2857
en_de Dev loss: 0.9161 r:0.1934
en_zh Dev loss: 0.8464 r:0.4224
ro_en Dev loss: 0.3853 r:0.8153
et_en Dev loss: 0.4925 r:0.6638
si_en Dev loss: 0.8638 r:0.5696
ne_en Dev loss: 0.5157 r:0.7297
ru_en Dev loss: 0.4985 r:0.7172
Current avg r:0.5874 Best avg r: 0.6317
00:30:39,252 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:32:09,777 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:33:40,111 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2909
en_de Dev loss: 0.8964 r:0.1885
en_zh Dev loss: 0.8253 r:0.4257
ro_en Dev loss: 0.3492 r:0.8162
et_en Dev loss: 0.4546 r:0.6619
si_en Dev loss: 0.8141 r:0.5696
ne_en Dev loss: 0.5223 r:0.7328
ru_en Dev loss: 0.4690 r:0.7178
Current avg r:0.5875 Best avg r: 0.6317
00:38:12,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:39:42,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:41:12,564 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2724
en_de Dev loss: 0.9013 r:0.2059
en_zh Dev loss: 0.8134 r:0.4339
ro_en Dev loss: 0.3572 r:0.8165
et_en Dev loss: 0.4774 r:0.6722
si_en Dev loss: 0.7563 r:0.5772
ne_en Dev loss: 0.4247 r:0.7408
ru_en Dev loss: 0.5011 r:0.7051
Current avg r:0.5931 Best avg r: 0.6317
00:45:48,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:47:18,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:48:49,117 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2524
en_de Dev loss: 0.9057 r:0.2049
en_zh Dev loss: 0.8433 r:0.4314
ro_en Dev loss: 0.3817 r:0.8158
et_en Dev loss: 0.4709 r:0.6695
si_en Dev loss: 0.7974 r:0.5723
ne_en Dev loss: 0.4607 r:0.7339
ru_en Dev loss: 0.5347 r:0.6957
Current avg r:0.5891 Best avg r: 0.6317
00:53:26,107 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:54:56,419 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:56:26,818 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2653
en_de Dev loss: 0.8975 r:0.1997
en_zh Dev loss: 0.8543 r:0.4291
ro_en Dev loss: 0.3927 r:0.8144
et_en Dev loss: 0.4609 r:0.6660
si_en Dev loss: 0.8018 r:0.5713
ne_en Dev loss: 0.4996 r:0.7283
ru_en Dev loss: 0.4994 r:0.7114
Current avg r:0.5886 Best avg r: 0.6317
01:00:58,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:02:28,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:03:59,79 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2529
en_de Dev loss: 0.9180 r:0.1949
en_zh Dev loss: 0.8895 r:0.4385
ro_en Dev loss: 0.4220 r:0.8120
et_en Dev loss: 0.4779 r:0.6599
si_en Dev loss: 0.9821 r:0.5573
ne_en Dev loss: 0.5932 r:0.7313
ru_en Dev loss: 0.5462 r:0.7084
Current avg r:0.5860 Best avg r: 0.6317
01:08:29,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:00,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:30,517 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2588
en_de Dev loss: 0.8889 r:0.2173
en_zh Dev loss: 0.8131 r:0.4543
ro_en Dev loss: 0.3571 r:0.8186
et_en Dev loss: 0.4745 r:0.6764
si_en Dev loss: 0.8199 r:0.5764
ne_en Dev loss: 0.5080 r:0.7330
ru_en Dev loss: 0.4545 r:0.7334
Current avg r:0.6013 Best avg r: 0.6317
01:16:02,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:33,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:03,334 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2571
en_de Dev loss: 0.8907 r:0.2089
en_zh Dev loss: 0.8128 r:0.4332
ro_en Dev loss: 0.3525 r:0.8204
et_en Dev loss: 0.5071 r:0.6709
si_en Dev loss: 0.7527 r:0.5779
ne_en Dev loss: 0.4307 r:0.7404
ru_en Dev loss: 0.4443 r:0.7330
Current avg r:0.5978 Best avg r: 0.6317
01:23:34,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:05,160 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:35,421 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2491
en_de Dev loss: 0.8936 r:0.2123
en_zh Dev loss: 0.8464 r:0.4281
ro_en Dev loss: 0.3888 r:0.8145
et_en Dev loss: 0.4748 r:0.6601
si_en Dev loss: 0.8809 r:0.5645
ne_en Dev loss: 0.5101 r:0.7360
ru_en Dev loss: 0.5368 r:0.7033
Current avg r:0.5884 Best avg r: 0.6317
01:31:06,609 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:32:36,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:07,161 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2522
en_de Dev loss: 0.8956 r:0.2311
en_zh Dev loss: 0.8339 r:0.4435
ro_en Dev loss: 0.3814 r:0.8160
et_en Dev loss: 0.4801 r:0.6618
si_en Dev loss: 0.8659 r:0.5685
ne_en Dev loss: 0.5139 r:0.7389
ru_en Dev loss: 0.5147 r:0.7184
Current avg r:0.5969 Best avg r: 0.6317
01:38:37,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:40:08,261 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:41:38,463 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2589
en_de Dev loss: 0.8783 r:0.2337
en_zh Dev loss: 0.7863 r:0.4637
ro_en Dev loss: 0.3498 r:0.8184
et_en Dev loss: 0.4737 r:0.6754
si_en Dev loss: 0.7753 r:0.5804
ne_en Dev loss: 0.4537 r:0.7407
ru_en Dev loss: 0.4633 r:0.7349
Current avg r:0.6067 Best avg r: 0.6317
01:46:12,141 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:47:42,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:49:12,569 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2499
en_de Dev loss: 0.9003 r:0.2147
en_zh Dev loss: 0.8463 r:0.4416
ro_en Dev loss: 0.3573 r:0.8218
et_en Dev loss: 0.4475 r:0.6616
si_en Dev loss: 0.8191 r:0.5708
ne_en Dev loss: 0.5632 r:0.7269
ru_en Dev loss: 0.5354 r:0.7035
Current avg r:0.5916 Best avg r: 0.6317
01:53:45,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:55:15,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:56:45,999 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2403
en_de Dev loss: 0.8849 r:0.2288
en_zh Dev loss: 0.8139 r:0.4533
ro_en Dev loss: 0.3704 r:0.8202
et_en Dev loss: 0.4947 r:0.6644
si_en Dev loss: 0.8176 r:0.5780
ne_en Dev loss: 0.4895 r:0.7279
ru_en Dev loss: 0.5162 r:0.7196
Current avg r:0.5989 Best avg r: 0.6317
02:01:16,611 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:02:47,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:04:17,332 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2325
en_de Dev loss: 0.8714 r:0.2203
en_zh Dev loss: 0.7651 r:0.4569
ro_en Dev loss: 0.3454 r:0.8198
et_en Dev loss: 0.4528 r:0.6678
si_en Dev loss: 0.7840 r:0.5772
ne_en Dev loss: 0.4495 r:0.7308
ru_en Dev loss: 0.4631 r:0.7268
Current avg r:0.5999 Best avg r: 0.6317
02:08:47,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:10:18,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:11:48,553 root INFO Epoch 7 Global steps: 63700 Train loss: 0.2403
en_de Dev loss: 0.8968 r:0.2118
en_zh Dev loss: 0.8778 r:0.4447
ro_en Dev loss: 0.3888 r:0.8169
et_en Dev loss: 0.4631 r:0.6662
si_en Dev loss: 0.8591 r:0.5737
ne_en Dev loss: 0.5643 r:0.7333
ru_en Dev loss: 0.5423 r:0.7068
Current avg r:0.5934 Best avg r: 0.6317
02:16:24,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:17:54,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:24,803 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2217
en_de Dev loss: 0.8896 r:0.2023
en_zh Dev loss: 0.7837 r:0.4505
ro_en Dev loss: 0.3528 r:0.8162
et_en Dev loss: 0.4724 r:0.6657
si_en Dev loss: 0.8073 r:0.5726
ne_en Dev loss: 0.5085 r:0.7304
ru_en Dev loss: 0.4849 r:0.7066
Current avg r:0.5920 Best avg r: 0.6317
02:23:55,881 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:25:26,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:26:56,606 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2248
en_de Dev loss: 0.9140 r:0.2005
en_zh Dev loss: 0.8348 r:0.4363
ro_en Dev loss: 0.4060 r:0.8095
et_en Dev loss: 0.4813 r:0.6490
si_en Dev loss: 0.9161 r:0.5501
ne_en Dev loss: 0.6044 r:0.7288
ru_en Dev loss: 0.5512 r:0.6970
Current avg r:0.5816 Best avg r: 0.6317
02:31:28,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:32:58,316 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:34:28,495 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2147
en_de Dev loss: 0.8980 r:0.2105
en_zh Dev loss: 0.8136 r:0.4440
ro_en Dev loss: 0.3799 r:0.8134
et_en Dev loss: 0.4690 r:0.6605
si_en Dev loss: 0.8187 r:0.5662
ne_en Dev loss: 0.4894 r:0.7339
ru_en Dev loss: 0.4867 r:0.7204
Current avg r:0.5927 Best avg r: 0.6317
02:38:59,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:40:30,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:42:00,491 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2147
en_de Dev loss: 0.9020 r:0.2012
en_zh Dev loss: 0.8213 r:0.4429
ro_en Dev loss: 0.3654 r:0.8181
et_en Dev loss: 0.4831 r:0.6634
si_en Dev loss: 0.8038 r:0.5730
ne_en Dev loss: 0.4910 r:0.7338
ru_en Dev loss: 0.4652 r:0.7276
Current avg r:0.5943 Best avg r: 0.6317
02:46:32,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:48:03,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:49:33,573 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2263
en_de Dev loss: 0.9046 r:0.1937
en_zh Dev loss: 0.8337 r:0.4265
ro_en Dev loss: 0.3832 r:0.8131
et_en Dev loss: 0.4664 r:0.6507
si_en Dev loss: 0.8740 r:0.5564
ne_en Dev loss: 0.5641 r:0.7317
ru_en Dev loss: 0.4986 r:0.7096
Current avg r:0.5831 Best avg r: 0.6317
02:54:05,519 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:55:35,729 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:57:06,41 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2224
en_de Dev loss: 0.8906 r:0.2020
en_zh Dev loss: 0.7932 r:0.4522
ro_en Dev loss: 0.3555 r:0.8194
et_en Dev loss: 0.4975 r:0.6657
si_en Dev loss: 0.7810 r:0.5746
ne_en Dev loss: 0.4499 r:0.7400
ru_en Dev loss: 0.4491 r:0.7338
Current avg r:0.5983 Best avg r: 0.6317
03:01:39,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:03:09,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:40,335 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2279
en_de Dev loss: 0.8817 r:0.2201
en_zh Dev loss: 0.8007 r:0.4429
ro_en Dev loss: 0.3333 r:0.8175
et_en Dev loss: 0.4785 r:0.6585
si_en Dev loss: 0.7563 r:0.5663
ne_en Dev loss: 0.4376 r:0.7365
ru_en Dev loss: 0.4504 r:0.7173
Current avg r:0.5942 Best avg r: 0.6317
03:09:13,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:43,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:12:13,921 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2203
en_de Dev loss: 0.8949 r:0.2119
en_zh Dev loss: 0.8193 r:0.4464
ro_en Dev loss: 0.3524 r:0.8194
et_en Dev loss: 0.4751 r:0.6597
si_en Dev loss: 0.7316 r:0.5803
ne_en Dev loss: 0.4687 r:0.7345
ru_en Dev loss: 0.4731 r:0.7241
Current avg r:0.5966 Best avg r: 0.6317
03:16:45,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:18:16,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:46,410 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2230
en_de Dev loss: 0.8851 r:0.2298
en_zh Dev loss: 0.8222 r:0.4536
ro_en Dev loss: 0.3664 r:0.8184
et_en Dev loss: 0.4880 r:0.6628
si_en Dev loss: 0.8286 r:0.5658
ne_en Dev loss: 0.5040 r:0.7355
ru_en Dev loss: 0.4597 r:0.7333
Current avg r:0.5999 Best avg r: 0.6317
03:24:19,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:25:50,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:27:20,703 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2172
en_de Dev loss: 0.8855 r:0.1953
en_zh Dev loss: 0.7782 r:0.4474
ro_en Dev loss: 0.3267 r:0.8171
et_en Dev loss: 0.4568 r:0.6658
si_en Dev loss: 0.7584 r:0.5675
ne_en Dev loss: 0.4526 r:0.7348
ru_en Dev loss: 0.4360 r:0.7283
Current avg r:0.5937 Best avg r: 0.6317
03:31:54,137 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:33:24,604 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:34:54,804 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2159
en_de Dev loss: 0.9352 r:0.1898
en_zh Dev loss: 0.8824 r:0.4464
ro_en Dev loss: 0.4003 r:0.8140
et_en Dev loss: 0.4968 r:0.6489
si_en Dev loss: 0.9367 r:0.5615
ne_en Dev loss: 0.6018 r:0.7363
ru_en Dev loss: 0.4928 r:0.7241
Current avg r:0.5887 Best avg r: 0.6317
03:39:30,326 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:41:00,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:42:30,740 root INFO Epoch 9 Global steps: 72100 Train loss: 0.1986
en_de Dev loss: 0.9279 r:0.2148
en_zh Dev loss: 0.8637 r:0.4514
ro_en Dev loss: 0.3889 r:0.8131
et_en Dev loss: 0.4926 r:0.6497
si_en Dev loss: 0.9371 r:0.5565
ne_en Dev loss: 0.5537 r:0.7265
ru_en Dev loss: 0.5305 r:0.7139
Current avg r:0.5894 Best avg r: 0.6317
03:47:04,229 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:48:34,607 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:50:04,873 root INFO Epoch 9 Global steps: 72800 Train loss: 0.2003
en_de Dev loss: 0.9116 r:0.2011
en_zh Dev loss: 0.8238 r:0.4455
ro_en Dev loss: 0.3524 r:0.8189
et_en Dev loss: 0.5186 r:0.6543
si_en Dev loss: 0.8339 r:0.5587
ne_en Dev loss: 0.5014 r:0.7208
ru_en Dev loss: 0.4526 r:0.7295
Current avg r:0.5898 Best avg r: 0.6317
03:54:35,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:56:06,188 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:57:36,351 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1998
en_de Dev loss: 0.9113 r:0.1939
en_zh Dev loss: 0.8082 r:0.4557
ro_en Dev loss: 0.3479 r:0.8169
et_en Dev loss: 0.5063 r:0.6634
si_en Dev loss: 0.8330 r:0.5606
ne_en Dev loss: 0.4414 r:0.7331
ru_en Dev loss: 0.4324 r:0.7397
Current avg r:0.5948 Best avg r: 0.6317
04:02:07,80 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:03:37,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:05:07,665 root INFO Epoch 9 Global steps: 74200 Train loss: 0.1955
en_de Dev loss: 0.9158 r:0.2019
en_zh Dev loss: 0.8336 r:0.4535
ro_en Dev loss: 0.3677 r:0.8156
et_en Dev loss: 0.4886 r:0.6579
si_en Dev loss: 0.9273 r:0.5504
ne_en Dev loss: 0.5622 r:0.7269
ru_en Dev loss: 0.4600 r:0.7389
Current avg r:0.5921 Best avg r: 0.6317
04:09:38,411 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:11:08,975 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:12:39,208 root INFO Epoch 9 Global steps: 74900 Train loss: 0.2122
en_de Dev loss: 0.9500 r:0.1882
en_zh Dev loss: 0.9059 r:0.4336
ro_en Dev loss: 0.4124 r:0.8152
et_en Dev loss: 0.5107 r:0.6568
si_en Dev loss: 0.9289 r:0.5507
ne_en Dev loss: 0.5378 r:0.7275
ru_en Dev loss: 0.5359 r:0.7185
Current avg r:0.5844 Best avg r: 0.6317
04:17:10,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:18:40,527 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:20:10,688 root INFO Epoch 9 Global steps: 75600 Train loss: 0.2023
en_de Dev loss: 0.9152 r:0.1821
en_zh Dev loss: 0.8636 r:0.4379
ro_en Dev loss: 0.3871 r:0.8142
et_en Dev loss: 0.4870 r:0.6580
si_en Dev loss: 0.9396 r:0.5527
ne_en Dev loss: 0.6362 r:0.7255
ru_en Dev loss: 0.5034 r:0.7241
Current avg r:0.5849 Best avg r: 0.6317
04:24:41,284 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:26:11,527 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:27:41,886 root INFO Epoch 9 Global steps: 76300 Train loss: 0.1979
en_de Dev loss: 0.9054 r:0.1956
en_zh Dev loss: 0.8438 r:0.4420
ro_en Dev loss: 0.3608 r:0.8136
et_en Dev loss: 0.4722 r:0.6573
si_en Dev loss: 0.8686 r:0.5569
ne_en Dev loss: 0.5548 r:0.7240
ru_en Dev loss: 0.5384 r:0.7034
Current avg r:0.5847 Best avg r: 0.6317
04:32:13,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:33:44,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:35:14,748 root INFO Epoch 9 Global steps: 77000 Train loss: 0.1878
en_de Dev loss: 0.9028 r:0.2082
en_zh Dev loss: 0.8342 r:0.4497
ro_en Dev loss: 0.3764 r:0.8171
et_en Dev loss: 0.4931 r:0.6606
si_en Dev loss: 0.8792 r:0.5603
ne_en Dev loss: 0.5228 r:0.7224
ru_en Dev loss: 0.4883 r:0.7255
Current avg r:0.5920 Best avg r: 0.6317
04:39:48,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:41:18,875 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:42:49,106 root INFO Epoch 9 Global steps: 77700 Train loss: 0.1908
en_de Dev loss: 0.9257 r:0.2101
en_zh Dev loss: 0.8525 r:0.4536
ro_en Dev loss: 0.3746 r:0.8176
et_en Dev loss: 0.5051 r:0.6650
si_en Dev loss: 0.7956 r:0.5721
ne_en Dev loss: 0.5155 r:0.7207
ru_en Dev loss: 0.4466 r:0.7430
Current avg r:0.5974 Best avg r: 0.6317
04:47:20,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:48:51,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:50:21,680 root INFO Epoch 9 Global steps: 78400 Train loss: 0.1978
en_de Dev loss: 0.9257 r:0.1742
en_zh Dev loss: 0.8810 r:0.4277
ro_en Dev loss: 0.3786 r:0.8107
et_en Dev loss: 0.4769 r:0.6437
si_en Dev loss: 0.9086 r:0.5461
ne_en Dev loss: 0.5741 r:0.7224
ru_en Dev loss: 0.5035 r:0.7170
Current avg r:0.5774 Best avg r: 0.6317
04:54:55,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:56:26,177 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:57:56,432 root INFO Epoch 9 Global steps: 79100 Train loss: 0.1829
en_de Dev loss: 0.9112 r:0.1904
en_zh Dev loss: 0.8135 r:0.4419
ro_en Dev loss: 0.3651 r:0.8119
et_en Dev loss: 0.4819 r:0.6534
si_en Dev loss: 0.8178 r:0.5578
ne_en Dev loss: 0.5110 r:0.7197
ru_en Dev loss: 0.4234 r:0.7463
Current avg r:0.5888 Best avg r: 0.6317
05:02:30,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:04:00,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:05:30,949 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1849
en_de Dev loss: 0.8907 r:0.2024
en_zh Dev loss: 0.7924 r:0.4494
ro_en Dev loss: 0.3484 r:0.8126
et_en Dev loss: 0.4640 r:0.6647
si_en Dev loss: 0.7766 r:0.5686
ne_en Dev loss: 0.4697 r:0.7227
ru_en Dev loss: 0.4496 r:0.7335
Current avg r:0.5934 Best avg r: 0.6317
05:10:02,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:11:32,724 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:13:03,230 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1789
en_de Dev loss: 0.9076 r:0.2001
en_zh Dev loss: 0.8336 r:0.4410
ro_en Dev loss: 0.3848 r:0.8063
et_en Dev loss: 0.4813 r:0.6567
si_en Dev loss: 0.8687 r:0.5563
ne_en Dev loss: 0.5311 r:0.7159
ru_en Dev loss: 0.4742 r:0.7304
Current avg r:0.5867 Best avg r: 0.6317
05:17:35,602 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:19:05,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:20:36,97 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1760
en_de Dev loss: 0.9172 r:0.1950
en_zh Dev loss: 0.8949 r:0.4449
ro_en Dev loss: 0.4311 r:0.8052
et_en Dev loss: 0.5133 r:0.6495
si_en Dev loss: 1.0075 r:0.5466
ne_en Dev loss: 0.6200 r:0.7138
ru_en Dev loss: 0.5589 r:0.7123
Current avg r:0.5810 Best avg r: 0.6317
05:25:10,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:26:40,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:28:10,890 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1861
en_de Dev loss: 0.8937 r:0.2062
en_zh Dev loss: 0.7832 r:0.4588
ro_en Dev loss: 0.3395 r:0.8165
et_en Dev loss: 0.4763 r:0.6681
si_en Dev loss: 0.7606 r:0.5761
ne_en Dev loss: 0.4652 r:0.7179
ru_en Dev loss: 0.4195 r:0.7441
Current avg r:0.5982 Best avg r: 0.6317
05:32:41,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:34:12,138 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:35:42,539 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1777
en_de Dev loss: 0.9214 r:0.2018
en_zh Dev loss: 0.8177 r:0.4573
ro_en Dev loss: 0.3581 r:0.8165
et_en Dev loss: 0.4749 r:0.6597
si_en Dev loss: 0.8603 r:0.5576
ne_en Dev loss: 0.5177 r:0.7185
ru_en Dev loss: 0.4642 r:0.7357
Current avg r:0.5925 Best avg r: 0.6317
05:40:15,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:41:45,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:43:16,84 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1840
en_de Dev loss: 0.9097 r:0.2277
en_zh Dev loss: 0.8654 r:0.4562
ro_en Dev loss: 0.3967 r:0.8120
et_en Dev loss: 0.5145 r:0.6397
si_en Dev loss: 0.9707 r:0.5440
ne_en Dev loss: 0.6096 r:0.7221
ru_en Dev loss: 0.4931 r:0.7256
Current avg r:0.5896 Best avg r: 0.6317
05:47:47,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:49:17,971 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:50:48,146 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1746
en_de Dev loss: 0.9469 r:0.1930
en_zh Dev loss: 0.8509 r:0.4539
ro_en Dev loss: 0.3596 r:0.8177
et_en Dev loss: 0.4836 r:0.6562
si_en Dev loss: 0.8770 r:0.5585
ne_en Dev loss: 0.5568 r:0.7171
ru_en Dev loss: 0.4957 r:0.7272
Current avg r:0.5891 Best avg r: 0.6317
05:55:19,34 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:56:49,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:58:19,740 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1717
en_de Dev loss: 0.9301 r:0.1964
en_zh Dev loss: 0.7994 r:0.4518
ro_en Dev loss: 0.3479 r:0.8172
et_en Dev loss: 0.4642 r:0.6573
si_en Dev loss: 0.8410 r:0.5549
ne_en Dev loss: 0.5013 r:0.7239
ru_en Dev loss: 0.4388 r:0.7366
Current avg r:0.5912 Best avg r: 0.6317
06:02:50,570 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:04:20,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:05:51,73 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1717
en_de Dev loss: 0.9429 r:0.1681
en_zh Dev loss: 0.8592 r:0.4368
ro_en Dev loss: 0.3751 r:0.8139
et_en Dev loss: 0.4569 r:0.6524
si_en Dev loss: 0.9372 r:0.5478
ne_en Dev loss: 0.6294 r:0.7201
ru_en Dev loss: 0.4858 r:0.7264
Current avg r:0.5808 Best avg r: 0.6317
06:10:21,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:11:52,25 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:13:22,197 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1664
en_de Dev loss: 0.9175 r:0.1796
en_zh Dev loss: 0.8075 r:0.4446
ro_en Dev loss: 0.3628 r:0.8119
et_en Dev loss: 0.4757 r:0.6519
si_en Dev loss: 0.9059 r:0.5441
ne_en Dev loss: 0.5864 r:0.7194
ru_en Dev loss: 0.4835 r:0.7175
Current avg r:0.5813 Best avg r: 0.6317
06:17:55,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:19:25,723 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:20:56,45 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1610
en_de Dev loss: 0.9301 r:0.1850
en_zh Dev loss: 0.8713 r:0.4377
ro_en Dev loss: 0.3705 r:0.8146
et_en Dev loss: 0.4942 r:0.6570
si_en Dev loss: 0.8829 r:0.5554
ne_en Dev loss: 0.5757 r:0.7208
ru_en Dev loss: 0.4932 r:0.7261
Current avg r:0.5852 Best avg r: 0.6317
06:25:31,336 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:27:01,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:28:31,923 root INFO Epoch 10 Global steps: 87500 Train loss: 0.1715
en_de Dev loss: 0.9270 r:0.1861
en_zh Dev loss: 0.8107 r:0.4552
ro_en Dev loss: 0.3437 r:0.8197
et_en Dev loss: 0.4563 r:0.6635
si_en Dev loss: 0.8142 r:0.5582
ne_en Dev loss: 0.4993 r:0.7205
ru_en Dev loss: 0.4738 r:0.7311
Current avg r:0.5906 Best avg r: 0.6317
06:33:04,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:34:35,5 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:36:05,421 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1628
en_de Dev loss: 0.9434 r:0.1550
en_zh Dev loss: 0.8536 r:0.4422
ro_en Dev loss: 0.3618 r:0.8175
et_en Dev loss: 0.4902 r:0.6530
si_en Dev loss: 0.8935 r:0.5500
ne_en Dev loss: 0.5614 r:0.7172
ru_en Dev loss: 0.4997 r:0.7208
Current avg r:0.5794 Best avg r: 0.6317
06:40:38,771 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:42:09,411 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:43:39,671 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1524
en_de Dev loss: 0.9365 r:0.1667
en_zh Dev loss: 0.8602 r:0.4385
ro_en Dev loss: 0.3745 r:0.8158
et_en Dev loss: 0.4941 r:0.6517
si_en Dev loss: 0.9276 r:0.5472
ne_en Dev loss: 0.5811 r:0.7126
ru_en Dev loss: 0.5348 r:0.7071
Current avg r:0.5771 Best avg r: 0.6317
06:48:11,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:49:41,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:51:11,936 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1533
en_de Dev loss: 0.9405 r:0.1778
en_zh Dev loss: 0.8179 r:0.4488
ro_en Dev loss: 0.3698 r:0.8147
et_en Dev loss: 0.4960 r:0.6516
si_en Dev loss: 0.9410 r:0.5370
ne_en Dev loss: 0.5837 r:0.7128
ru_en Dev loss: 0.4759 r:0.7255
Current avg r:0.5812 Best avg r: 0.6317
06:55:48,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:57:18,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:58:48,829 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1540
en_de Dev loss: 0.9472 r:0.1970
en_zh Dev loss: 0.7804 r:0.4596
ro_en Dev loss: 0.3222 r:0.8202
et_en Dev loss: 0.4710 r:0.6697
si_en Dev loss: 0.7951 r:0.5575
ne_en Dev loss: 0.5169 r:0.7149
ru_en Dev loss: 0.4266 r:0.7427
Current avg r:0.5945 Best avg r: 0.6317
07:03:20,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:04:50,631 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:06:20,861 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1510
en_de Dev loss: 0.9214 r:0.2168
en_zh Dev loss: 0.8227 r:0.4568
ro_en Dev loss: 0.3759 r:0.8138
et_en Dev loss: 0.4677 r:0.6638
si_en Dev loss: 0.8974 r:0.5571
ne_en Dev loss: 0.5679 r:0.7231
ru_en Dev loss: 0.4886 r:0.7271
Current avg r:0.5941 Best avg r: 0.6317
07:10:52,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:12:22,810 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:13:53,112 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1503
en_de Dev loss: 0.9538 r:0.1775
en_zh Dev loss: 0.8759 r:0.4428
ro_en Dev loss: 0.3960 r:0.8147
et_en Dev loss: 0.4891 r:0.6565
si_en Dev loss: 0.9418 r:0.5549
ne_en Dev loss: 0.5923 r:0.7170
ru_en Dev loss: 0.5125 r:0.7200
Current avg r:0.5833 Best avg r: 0.6317
07:18:24,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:19:55,4 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:21:25,471 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1540
en_de Dev loss: 0.9419 r:0.1876
en_zh Dev loss: 0.8382 r:0.4523
ro_en Dev loss: 0.3720 r:0.8163
et_en Dev loss: 0.4753 r:0.6562
si_en Dev loss: 0.9182 r:0.5479
ne_en Dev loss: 0.5655 r:0.7125
ru_en Dev loss: 0.4726 r:0.7372
Current avg r:0.5872 Best avg r: 0.6317
07:25:58,619 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:27:29,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:28:59,537 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1509
en_de Dev loss: 0.9533 r:0.1732
en_zh Dev loss: 0.8092 r:0.4555
ro_en Dev loss: 0.3445 r:0.8183
et_en Dev loss: 0.4677 r:0.6490
si_en Dev loss: 0.9446 r:0.5390
ne_en Dev loss: 0.6248 r:0.7111
ru_en Dev loss: 0.4812 r:0.7266
Current avg r:0.5818 Best avg r: 0.6317
07:33:32,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:35:02,928 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:36:33,492 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1543
en_de Dev loss: 0.9383 r:0.1913
en_zh Dev loss: 0.8047 r:0.4530
ro_en Dev loss: 0.3680 r:0.8137
et_en Dev loss: 0.4769 r:0.6625
si_en Dev loss: 0.8413 r:0.5621
ne_en Dev loss: 0.5524 r:0.7215
ru_en Dev loss: 0.4439 r:0.7425
Current avg r:0.5924 Best avg r: 0.6317
07:41:05,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:42:36,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:44:06,457 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1554
en_de Dev loss: 0.9417 r:0.1850
en_zh Dev loss: 0.8212 r:0.4619
ro_en Dev loss: 0.3932 r:0.8098
et_en Dev loss: 0.5065 r:0.6659
si_en Dev loss: 0.9012 r:0.5564
ne_en Dev loss: 0.5690 r:0.7160
ru_en Dev loss: 0.4699 r:0.7393
Current avg r:0.5906 Best avg r: 0.6317
07:48:38,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:50:09,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:51:39,478 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1575
en_de Dev loss: 0.9419 r:0.1838
en_zh Dev loss: 0.8412 r:0.4479
ro_en Dev loss: 0.3873 r:0.8068
et_en Dev loss: 0.4751 r:0.6554
si_en Dev loss: 0.9534 r:0.5511
ne_en Dev loss: 0.5299 r:0.7191
ru_en Dev loss: 0.4655 r:0.7346
Current avg r:0.5855 Best avg r: 0.6317
07:56:12,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:57:42,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:59:13,40 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1404
en_de Dev loss: 0.9313 r:0.1923
en_zh Dev loss: 0.7992 r:0.4684
ro_en Dev loss: 0.3663 r:0.8137
et_en Dev loss: 0.4860 r:0.6594
si_en Dev loss: 0.8131 r:0.5627
ne_en Dev loss: 0.5157 r:0.7206
ru_en Dev loss: 0.4459 r:0.7330
Current avg r:0.5929 Best avg r: 0.6317
08:03:44,327 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:05:14,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:06:45,212 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1406
en_de Dev loss: 0.9636 r:0.1697
en_zh Dev loss: 0.8167 r:0.4614
ro_en Dev loss: 0.3899 r:0.8097
et_en Dev loss: 0.4741 r:0.6613
si_en Dev loss: 0.9049 r:0.5585
ne_en Dev loss: 0.5892 r:0.7194
ru_en Dev loss: 0.4646 r:0.7407
Current avg r:0.5887 Best avg r: 0.6317
08:11:17,343 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:12:47,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:14:17,858 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1467
en_de Dev loss: 0.9397 r:0.1783
en_zh Dev loss: 0.7884 r:0.4615
ro_en Dev loss: 0.3623 r:0.8118
et_en Dev loss: 0.5105 r:0.6578
si_en Dev loss: 0.8215 r:0.5607
ne_en Dev loss: 0.5399 r:0.7105
ru_en Dev loss: 0.4416 r:0.7361
Current avg r:0.5881 Best avg r: 0.6317
08:18:50,132 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:20:20,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:21:50,990 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1343
en_de Dev loss: 0.9296 r:0.1987
en_zh Dev loss: 0.8049 r:0.4574
ro_en Dev loss: 0.3704 r:0.8123
et_en Dev loss: 0.4784 r:0.6631
si_en Dev loss: 0.7912 r:0.5681
ne_en Dev loss: 0.5493 r:0.7233
ru_en Dev loss: 0.4754 r:0.7358
Current avg r:0.5941 Best avg r: 0.6317
08:26:22,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:27:53,217 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:23,476 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1405
en_de Dev loss: 0.9859 r:0.1815
en_zh Dev loss: 0.9177 r:0.4463
ro_en Dev loss: 0.3945 r:0.8130
et_en Dev loss: 0.5024 r:0.6498
si_en Dev loss: 0.9669 r:0.5473
ne_en Dev loss: 0.6623 r:0.7108
ru_en Dev loss: 0.5077 r:0.7311
Current avg r:0.5828 Best avg r: 0.6317
08:33:54,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:25,34 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:36:55,246 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1354
en_de Dev loss: 0.9616 r:0.1880
en_zh Dev loss: 0.8831 r:0.4498
ro_en Dev loss: 0.3967 r:0.8130
et_en Dev loss: 0.4886 r:0.6530
si_en Dev loss: 0.8796 r:0.5552
ne_en Dev loss: 0.5851 r:0.7107
ru_en Dev loss: 0.5331 r:0.7160
Current avg r:0.5837 Best avg r: 0.6317
08:41:26,810 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:42:57,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:44:27,696 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1402
en_de Dev loss: 0.9956 r:0.1606
en_zh Dev loss: 0.8880 r:0.4544
ro_en Dev loss: 0.4441 r:0.8075
et_en Dev loss: 0.5032 r:0.6511
si_en Dev loss: 1.0016 r:0.5451
ne_en Dev loss: 0.7032 r:0.7103
ru_en Dev loss: 0.5564 r:0.7173
Current avg r:0.5780 Best avg r: 0.6317
08:49:00,13 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:50:30,364 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:52:00,670 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1413
en_de Dev loss: 0.9644 r:0.1557
en_zh Dev loss: 0.8413 r:0.4475
ro_en Dev loss: 0.3852 r:0.8064
et_en Dev loss: 0.4843 r:0.6472
si_en Dev loss: 0.9357 r:0.5423
ne_en Dev loss: 0.6025 r:0.7055
ru_en Dev loss: 0.5123 r:0.7168
Current avg r:0.5745 Best avg r: 0.6317
08:56:32,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:58:02,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:59:32,864 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1396
en_de Dev loss: 0.9649 r:0.1799
en_zh Dev loss: 0.8418 r:0.4562
ro_en Dev loss: 0.3707 r:0.8149
et_en Dev loss: 0.4787 r:0.6645
si_en Dev loss: 0.8430 r:0.5583
ne_en Dev loss: 0.5126 r:0.7163
ru_en Dev loss: 0.4558 r:0.7401
Current avg r:0.5900 Best avg r: 0.6317
09:04:04,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:05:35,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:07:05,402 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1393
en_de Dev loss: 0.9562 r:0.1685
en_zh Dev loss: 0.7737 r:0.4672
ro_en Dev loss: 0.3430 r:0.8178
et_en Dev loss: 0.4664 r:0.6618
si_en Dev loss: 0.8672 r:0.5535
ne_en Dev loss: 0.5656 r:0.7132
ru_en Dev loss: 0.4599 r:0.7312
Current avg r:0.5876 Best avg r: 0.6317
09:11:37,309 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:13:07,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:14:37,990 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1431
en_de Dev loss: 0.9529 r:0.1503
en_zh Dev loss: 0.7990 r:0.4647
ro_en Dev loss: 0.3433 r:0.8153
et_en Dev loss: 0.4854 r:0.6675
si_en Dev loss: 0.7925 r:0.5702
ne_en Dev loss: 0.4632 r:0.7234
ru_en Dev loss: 0.4364 r:0.7448
Current avg r:0.5909 Best avg r: 0.6317
09:19:11,794 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:20:42,112 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:22:12,675 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1256
en_de Dev loss: 1.0179 r:0.1338
en_zh Dev loss: 0.9020 r:0.4460
ro_en Dev loss: 0.4023 r:0.8100
et_en Dev loss: 0.4982 r:0.6486
si_en Dev loss: 0.9960 r:0.5383
ne_en Dev loss: 0.6167 r:0.7070
ru_en Dev loss: 0.5369 r:0.7168
Current avg r:0.5715 Best avg r: 0.6317
09:26:44,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:28:15,758 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:29:46,32 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1302
en_de Dev loss: 0.9913 r:0.1524
en_zh Dev loss: 0.8513 r:0.4570
ro_en Dev loss: 0.3814 r:0.8119
et_en Dev loss: 0.4924 r:0.6474
si_en Dev loss: 0.9572 r:0.5445
ne_en Dev loss: 0.6205 r:0.7108
ru_en Dev loss: 0.5132 r:0.7165
Current avg r:0.5772 Best avg r: 0.6317
09:34:18,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:49,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:37:19,510 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1231
en_de Dev loss: 0.9588 r:0.1491
en_zh Dev loss: 0.8197 r:0.4566
ro_en Dev loss: 0.3712 r:0.8126
et_en Dev loss: 0.4724 r:0.6560
si_en Dev loss: 0.9415 r:0.5433
ne_en Dev loss: 0.6120 r:0.7154
ru_en Dev loss: 0.4857 r:0.7245
Current avg r:0.5796 Best avg r: 0.6317
09:41:51,377 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:21,859 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:44:52,428 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1265
en_de Dev loss: 0.9446 r:0.1555
en_zh Dev loss: 0.7851 r:0.4592
ro_en Dev loss: 0.3537 r:0.8136
et_en Dev loss: 0.4972 r:0.6526
si_en Dev loss: 0.9615 r:0.5382
ne_en Dev loss: 0.6331 r:0.7037
ru_en Dev loss: 0.4698 r:0.7249
Current avg r:0.5782 Best avg r: 0.6317
09:49:25,258 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:50:55,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:52:26,172 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1289
en_de Dev loss: 1.0105 r:0.1584
en_zh Dev loss: 0.9340 r:0.4567
ro_en Dev loss: 0.4177 r:0.8128
et_en Dev loss: 0.5110 r:0.6618
si_en Dev loss: 0.9838 r:0.5463
ne_en Dev loss: 0.6146 r:0.7110
ru_en Dev loss: 0.5396 r:0.7323
Current avg r:0.5827 Best avg r: 0.6317
09:56:59,488 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:29,818 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:00:00,381 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1228
en_de Dev loss: 0.9683 r:0.1592
en_zh Dev loss: 0.8375 r:0.4528
ro_en Dev loss: 0.3550 r:0.8152
et_en Dev loss: 0.4973 r:0.6608
si_en Dev loss: 0.8835 r:0.5454
ne_en Dev loss: 0.5547 r:0.7094
ru_en Dev loss: 0.4410 r:0.7423
Current avg r:0.5836 Best avg r: 0.6317
10:04:34,555 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:06:05,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:35,487 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1243
en_de Dev loss: 0.9793 r:0.1733
en_zh Dev loss: 0.8766 r:0.4569
ro_en Dev loss: 0.3687 r:0.8192
et_en Dev loss: 0.4657 r:0.6658
si_en Dev loss: 0.8944 r:0.5525
ne_en Dev loss: 0.5520 r:0.7163
ru_en Dev loss: 0.4887 r:0.7335
Current avg r:0.5882 Best avg r: 0.6317
10:12:04,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:13:33,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:15:03,215 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1285
en_de Dev loss: 0.9633 r:0.1692
en_zh Dev loss: 0.8250 r:0.4629
ro_en Dev loss: 0.3611 r:0.8196
et_en Dev loss: 0.4798 r:0.6576
si_en Dev loss: 0.8809 r:0.5492
ne_en Dev loss: 0.5523 r:0.7054
ru_en Dev loss: 0.4983 r:0.7284
Current avg r:0.5846 Best avg r: 0.6317
10:19:31,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:21:01,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:22:30,891 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1305
en_de Dev loss: 0.9606 r:0.1736
en_zh Dev loss: 0.8479 r:0.4643
ro_en Dev loss: 0.3737 r:0.8208
et_en Dev loss: 0.4767 r:0.6622
si_en Dev loss: 0.9043 r:0.5542
ne_en Dev loss: 0.6020 r:0.7120
ru_en Dev loss: 0.4795 r:0.7390
Current avg r:0.5894 Best avg r: 0.6317
10:26:59,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:28:28,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:58,431 root INFO Epoch 13 Global steps: 109900 Train loss: 0.1313
en_de Dev loss: 0.9762 r:0.1684
en_zh Dev loss: 0.8581 r:0.4609
ro_en Dev loss: 0.3886 r:0.8136
et_en Dev loss: 0.4984 r:0.6566
si_en Dev loss: 0.9867 r:0.5473
ne_en Dev loss: 0.6645 r:0.7128
ru_en Dev loss: 0.5014 r:0.7373
Current avg r:0.5853 Best avg r: 0.6317
10:34:26,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:35:56,663 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:37:26,242 root INFO Epoch 13 Global steps: 110600 Train loss: 0.1211
en_de Dev loss: 0.9842 r:0.1595
en_zh Dev loss: 0.8665 r:0.4587
ro_en Dev loss: 0.3843 r:0.8134
et_en Dev loss: 0.4819 r:0.6501
si_en Dev loss: 0.9332 r:0.5453
ne_en Dev loss: 0.6017 r:0.7040
ru_en Dev loss: 0.5256 r:0.7205
Current avg r:0.5788 Best avg r: 0.6317
