14:50:29,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:50:55,139 root INFO 
id:en_zh cur r: 0.2542 best r: 0.2542
14:51:08,20 root INFO 
id:ro_en cur r: 0.0685 best r: 0.0685
14:51:20,925 root INFO 
id:et_en cur r: 0.3665 best r: 0.3665
14:51:33,827 root INFO 
id:si_en cur r: 0.3976 best r: 0.3976
14:51:46,730 root INFO 
id:ne_en cur r: 0.4078 best r: 0.4078
14:52:12,417 root INFO 
id:ru_en cur r: 0.4198 best r: 0.4198
14:52:12,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:53:42,527 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:53:42,533 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:53:42,537 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:53:42,542 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:53:42,547 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:53:42,551 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:53:42,556 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:53:55,416 root INFO Epoch 0 Global steps: 700 Train loss: 0.8555
en_de Dev loss: 0.8905 r:0.0880
en_zh Dev loss: 0.8056 r:0.2449
ro_en Dev loss: 0.7359 r:0.5696
et_en Dev loss: 0.6790 r:0.4365
si_en Dev loss: 0.7380 r:0.4323
ne_en Dev loss: 0.7027 r:0.4929
ru_en Dev loss: 0.7512 r:0.4612
Current avg r:0.3893 Best avg r: 0.3893
14:58:26,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:58:39,399 root INFO 
id:en_de cur r: 0.0256 best r: 0.0256
14:58:52,279 root INFO 
id:en_zh cur r: 0.2850 best r: 0.2850
14:59:05,172 root INFO 
id:ro_en cur r: 0.6245 best r: 0.6245
14:59:18,67 root INFO 
id:et_en cur r: 0.5341 best r: 0.5341
14:59:43,838 root INFO 
id:ne_en cur r: 0.4706 best r: 0.4706
15:00:09,512 root INFO 
id:ru_en cur r: 0.6047 best r: 0.6047
15:00:09,513 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:01:39,502 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:01:39,508 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:01:39,513 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:01:39,519 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:01:39,523 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:01:39,529 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:01:39,534 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:01:52,401 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8108
en_de Dev loss: 0.8967 r:0.1162
en_zh Dev loss: 0.7664 r:0.2943
ro_en Dev loss: 0.6858 r:0.6714
et_en Dev loss: 0.5755 r:0.5554
si_en Dev loss: 0.7155 r:0.4886
ne_en Dev loss: 0.6024 r:0.5877
ru_en Dev loss: 0.6102 r:0.6606
Current avg r:0.4820 Best avg r: 0.4820
15:06:22,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:06:47,673 root INFO 
id:en_zh cur r: 0.3088 best r: 0.3088
15:07:00,518 root INFO 
id:ro_en cur r: 0.6544 best r: 0.6544
15:07:13,366 root INFO 
id:et_en cur r: 0.6172 best r: 0.6172
15:07:26,233 root INFO 
id:si_en cur r: 0.4272 best r: 0.4272
15:07:39,131 root INFO 
id:ne_en cur r: 0.5523 best r: 0.5523
15:08:04,790 root INFO 
id:ru_en cur r: 0.6432 best r: 0.6432
15:08:04,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:09:35,77 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:09:35,83 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:09:35,87 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:09:35,92 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:09:35,97 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:09:35,101 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:09:35,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:09:47,998 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7364
en_de Dev loss: 0.9447 r:0.1244
en_zh Dev loss: 0.7768 r:0.3234
ro_en Dev loss: 0.5467 r:0.6926
et_en Dev loss: 0.4605 r:0.6405
si_en Dev loss: 0.6911 r:0.4930
ne_en Dev loss: 0.5047 r:0.6245
ru_en Dev loss: 0.5446 r:0.6931
Current avg r:0.5131 Best avg r: 0.5131
15:14:17,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:14:30,188 root INFO 
id:en_de cur r: 0.0491 best r: 0.0491
15:14:43,8 root INFO 
id:en_zh cur r: 0.3558 best r: 0.3558
15:14:55,886 root INFO 
id:ro_en cur r: 0.7079 best r: 0.7079
15:15:08,783 root INFO 
id:et_en cur r: 0.6467 best r: 0.6467
15:15:21,647 root INFO 
id:si_en cur r: 0.4633 best r: 0.4633
15:15:34,513 root INFO 
id:ne_en cur r: 0.6070 best r: 0.6070
15:16:00,129 root INFO 
id:ru_en cur r: 0.6977 best r: 0.6977
15:16:00,130 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:17:30,29 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:17:30,51 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:17:30,95 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:17:30,102 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:17:30,109 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:17:30,116 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:17:30,121 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:17:42,972 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6873
en_de Dev loss: 0.9267 r:0.1532
en_zh Dev loss: 0.7394 r:0.3770
ro_en Dev loss: 0.4531 r:0.7326
et_en Dev loss: 0.4239 r:0.6594
si_en Dev loss: 0.6955 r:0.5047
ne_en Dev loss: 0.4839 r:0.6486
ru_en Dev loss: 0.4591 r:0.7221
Current avg r:0.5425 Best avg r: 0.5425
15:22:14,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:22:27,526 root INFO 
id:en_de cur r: 0.1522 best r: 0.1522
15:22:40,344 root INFO 
id:en_zh cur r: 0.3824 best r: 0.3824
15:23:06,107 root INFO 
id:et_en cur r: 0.6638 best r: 0.6638
15:23:19,15 root INFO 
id:si_en cur r: 0.5051 best r: 0.5051
15:23:31,953 root INFO 
id:ne_en cur r: 0.6697 best r: 0.6697
15:23:44,787 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:25:14,830 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:25:14,836 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:25:14,840 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:25:14,848 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:25:14,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:25:14,858 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:25:14,864 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:25:27,714 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6494
en_de Dev loss: 0.9084 r:0.1788
en_zh Dev loss: 0.7066 r:0.4046
ro_en Dev loss: 0.4308 r:0.7274
et_en Dev loss: 0.3886 r:0.6858
si_en Dev loss: 0.6233 r:0.5400
ne_en Dev loss: 0.4324 r:0.6899
ru_en Dev loss: 0.4845 r:0.7264
Current avg r:0.5647 Best avg r: 0.5647
15:29:57,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:30:10,477 root INFO 
id:en_de cur r: 0.1636 best r: 0.1636
15:30:23,300 root INFO 
id:en_zh cur r: 0.3908 best r: 0.3908
15:30:36,146 root INFO 
id:ro_en cur r: 0.7310 best r: 0.7310
15:31:01,854 root INFO 
id:si_en cur r: 0.5153 best r: 0.5153
15:31:14,753 root INFO 
id:ne_en cur r: 0.7015 best r: 0.7015
15:31:40,459 root INFO 
id:ru_en cur r: 0.7297 best r: 0.7297
15:31:40,459 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:33:10,763 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:33:10,769 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:33:10,774 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:33:10,779 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:33:10,783 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:33:10,788 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:33:10,793 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:33:23,652 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6268
en_de Dev loss: 0.8818 r:0.1791
en_zh Dev loss: 0.6747 r:0.4217
ro_en Dev loss: 0.3820 r:0.7475
et_en Dev loss: 0.3977 r:0.6938
si_en Dev loss: 0.6344 r:0.5451
ne_en Dev loss: 0.4034 r:0.7079
ru_en Dev loss: 0.3893 r:0.7427
Current avg r:0.5768 Best avg r: 0.5768
15:37:54,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:38:33,231 root INFO 
id:ro_en cur r: 0.7356 best r: 0.7356
15:38:46,143 root INFO 
id:et_en cur r: 0.6789 best r: 0.6789
15:39:24,797 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:40:54,959 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6038
en_de Dev loss: 0.9240 r:0.1885
en_zh Dev loss: 0.7662 r:0.3947
ro_en Dev loss: 0.4395 r:0.7538
et_en Dev loss: 0.3845 r:0.6884
si_en Dev loss: 0.8046 r:0.5292
ne_en Dev loss: 0.4732 r:0.6814
ru_en Dev loss: 0.4958 r:0.7243
Current avg r:0.5658 Best avg r: 0.5768
15:45:27,0 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:45:39,942 root INFO 
id:en_de cur r: 0.1798 best r: 0.1798
15:46:05,683 root INFO 
id:ro_en cur r: 0.7581 best r: 0.7581
15:46:31,491 root INFO 
id:si_en cur r: 0.5262 best r: 0.5262
15:46:57,222 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:48:27,336 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:48:27,345 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:48:27,350 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:48:27,355 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:48:27,360 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:48:27,365 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:48:27,370 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:48:40,211 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6427
en_de Dev loss: 0.8984 r:0.2016
en_zh Dev loss: 0.7577 r:0.4136
ro_en Dev loss: 0.4077 r:0.7755
et_en Dev loss: 0.3880 r:0.6942
si_en Dev loss: 0.7216 r:0.5475
ne_en Dev loss: 0.4773 r:0.6906
ru_en Dev loss: 0.5317 r:0.7221
Current avg r:0.5779 Best avg r: 0.5779
15:53:09,959 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:53:22,890 root INFO 
id:en_de cur r: 0.1886 best r: 0.1886
15:53:35,777 root INFO 
id:en_zh cur r: 0.3912 best r: 0.3912
15:53:48,691 root INFO 
id:ro_en cur r: 0.7672 best r: 0.7672
15:54:01,606 root INFO 
id:et_en cur r: 0.6802 best r: 0.6802
15:54:40,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:10,508 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5958
en_de Dev loss: 0.9721 r:0.2103
en_zh Dev loss: 0.8698 r:0.4185
ro_en Dev loss: 0.4398 r:0.7760
et_en Dev loss: 0.4626 r:0.6873
si_en Dev loss: 0.9096 r:0.5400
ne_en Dev loss: 0.5651 r:0.6859
ru_en Dev loss: 0.6809 r:0.7120
Current avg r:0.5757 Best avg r: 0.5779
16:00:40,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:52,869 root INFO 
id:en_de cur r: 0.1958 best r: 0.1958
16:01:05,725 root INFO 
id:en_zh cur r: 0.4310 best r: 0.4310
16:01:18,601 root INFO 
id:ro_en cur r: 0.7739 best r: 0.7739
16:01:31,458 root INFO 
id:et_en cur r: 0.6845 best r: 0.6845
16:01:44,340 root INFO 
id:si_en cur r: 0.5369 best r: 0.5369
16:01:57,242 root INFO 
id:ne_en cur r: 0.7152 best r: 0.7152
16:02:10,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:03:40,106 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:03:40,113 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:03:40,118 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:03:40,122 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:03:40,129 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:03:40,136 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:03:40,140 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:03:52,979 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5721
en_de Dev loss: 0.9009 r:0.2091
en_zh Dev loss: 0.7440 r:0.4389
ro_en Dev loss: 0.3740 r:0.7799
et_en Dev loss: 0.4226 r:0.6914
si_en Dev loss: 0.8781 r:0.5537
ne_en Dev loss: 0.5850 r:0.6969
ru_en Dev loss: 0.5338 r:0.7322
Current avg r:0.5860 Best avg r: 0.5860
16:08:23,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:08:36,465 root INFO 
id:en_de cur r: 0.2040 best r: 0.2040
16:09:02,205 root INFO 
id:ro_en cur r: 0.7769 best r: 0.7769
16:09:15,97 root INFO 
id:et_en cur r: 0.6989 best r: 0.6989
16:09:28,31 root INFO 
id:si_en cur r: 0.5623 best r: 0.5623
16:09:40,962 root INFO 
id:ne_en cur r: 0.7215 best r: 0.7215
16:09:53,828 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:11:23,932 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:11:23,941 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:11:23,946 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:11:23,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:11:23,956 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:11:23,961 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:11:23,966 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:11:36,806 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5742
en_de Dev loss: 0.9072 r:0.2092
en_zh Dev loss: 0.7798 r:0.4372
ro_en Dev loss: 0.3900 r:0.7852
et_en Dev loss: 0.3873 r:0.7047
si_en Dev loss: 0.7539 r:0.5730
ne_en Dev loss: 0.4593 r:0.7160
ru_en Dev loss: 0.5448 r:0.7348
Current avg r:0.5943 Best avg r: 0.5943
16:16:08,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:16:21,640 root INFO 
id:en_de cur r: 0.2173 best r: 0.2173
16:16:47,391 root INFO 
id:ro_en cur r: 0.7796 best r: 0.7796
16:17:00,285 root INFO 
id:et_en cur r: 0.7066 best r: 0.7066
16:17:13,190 root INFO 
id:si_en cur r: 0.5728 best r: 0.5728
16:17:26,86 root INFO 
id:ne_en cur r: 0.7284 best r: 0.7284
16:17:38,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:09,203 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:19:09,209 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:19:09,213 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:19:09,218 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:19:09,223 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:19:09,227 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:19:09,232 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:19:22,70 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5425
en_de Dev loss: 0.9064 r:0.2206
en_zh Dev loss: 0.7818 r:0.4361
ro_en Dev loss: 0.3925 r:0.7900
et_en Dev loss: 0.3597 r:0.7134
si_en Dev loss: 0.6484 r:0.5823
ne_en Dev loss: 0.4337 r:0.7277
ru_en Dev loss: 0.4499 r:0.7449
Current avg r:0.6022 Best avg r: 0.6022
16:23:51,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:04,607 root INFO 
id:en_de cur r: 0.2212 best r: 0.2212
16:24:30,366 root INFO 
id:ro_en cur r: 0.7893 best r: 0.7893
16:24:56,155 root INFO 
id:si_en cur r: 0.5760 best r: 0.5760
16:25:09,46 root INFO 
id:ne_en cur r: 0.7325 best r: 0.7325
16:25:21,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:51,929 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:26:51,935 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:26:51,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:26:51,945 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:26:51,950 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:26:51,955 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:26:51,960 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:27:04,788 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5445
en_de Dev loss: 0.8596 r:0.2351
en_zh Dev loss: 0.7253 r:0.4387
ro_en Dev loss: 0.3609 r:0.7930
et_en Dev loss: 0.3626 r:0.7057
si_en Dev loss: 0.6354 r:0.5827
ne_en Dev loss: 0.4549 r:0.7262
ru_en Dev loss: 0.4652 r:0.7359
Current avg r:0.6025 Best avg r: 0.6025
16:31:35,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:32:01,229 root INFO 
id:en_zh cur r: 0.4506 best r: 0.4506
16:32:14,132 root INFO 
id:ro_en cur r: 0.7933 best r: 0.7933
16:32:39,921 root INFO 
id:si_en cur r: 0.5860 best r: 0.5860
16:32:52,815 root INFO 
id:ne_en cur r: 0.7416 best r: 0.7416
16:33:05,652 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:34:35,686 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:34:35,693 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:34:35,698 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:34:35,703 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:34:35,707 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:34:35,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:34:35,722 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:34:48,559 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5621
en_de Dev loss: 0.9078 r:0.2161
en_zh Dev loss: 0.7238 r:0.4547
ro_en Dev loss: 0.3777 r:0.7969
et_en Dev loss: 0.3972 r:0.7074
si_en Dev loss: 0.7502 r:0.5867
ne_en Dev loss: 0.5105 r:0.7365
ru_en Dev loss: 0.5200 r:0.7300
Current avg r:0.6040 Best avg r: 0.6040
16:39:19,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:32,11 root INFO 
id:en_de cur r: 0.2259 best r: 0.2259
16:40:36,481 root INFO 
id:ne_en cur r: 0.7433 best r: 0.7433
16:40:49,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:19,371 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:42:19,377 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:42:19,382 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:42:19,386 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:42:19,391 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:42:19,395 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:42:19,400 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:42:32,246 root INFO Epoch 1 Global steps: 10500 Train loss: 0.5387
en_de Dev loss: 0.8493 r:0.2315
en_zh Dev loss: 0.6881 r:0.4530
ro_en Dev loss: 0.3447 r:0.7947
et_en Dev loss: 0.3669 r:0.7046
si_en Dev loss: 0.6510 r:0.5858
ne_en Dev loss: 0.3835 r:0.7388
ru_en Dev loss: 0.4510 r:0.7315
Current avg r:0.6057 Best avg r: 0.6057
16:47:03,51 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:41,704 root INFO 
id:ro_en cur r: 0.7982 best r: 0.7982
16:48:07,488 root INFO 
id:si_en cur r: 0.5941 best r: 0.5941
16:48:20,387 root INFO 
id:ne_en cur r: 0.7516 best r: 0.7516
16:48:33,220 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:03,262 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:50:03,270 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:50:03,274 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:50:03,279 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:50:03,283 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:50:03,287 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:50:03,292 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:50:16,130 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5074
en_de Dev loss: 0.8624 r:0.2407
en_zh Dev loss: 0.7146 r:0.4504
ro_en Dev loss: 0.3355 r:0.8046
et_en Dev loss: 0.3512 r:0.7135
si_en Dev loss: 0.6272 r:0.6013
ne_en Dev loss: 0.3684 r:0.7495
ru_en Dev loss: 0.4484 r:0.7376
Current avg r:0.6139 Best avg r: 0.6139
16:54:48,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:56:18,747 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:48,860 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5021
en_de Dev loss: 0.8781 r:0.2318
en_zh Dev loss: 0.7620 r:0.4443
ro_en Dev loss: 0.3760 r:0.7998
et_en Dev loss: 0.3830 r:0.7038
si_en Dev loss: 0.6963 r:0.5874
ne_en Dev loss: 0.4231 r:0.7389
ru_en Dev loss: 0.4733 r:0.7312
Current avg r:0.6053 Best avg r: 0.6139
17:02:20,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:02:33,314 root INFO 
id:en_de cur r: 0.2274 best r: 0.2274
17:02:59,77 root INFO 
id:ro_en cur r: 0.8009 best r: 0.8009
17:03:11,979 root INFO 
id:et_en cur r: 0.7072 best r: 0.7072
17:03:50,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:20,694 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5049
en_de Dev loss: 0.8361 r:0.2446
en_zh Dev loss: 0.6832 r:0.4523
ro_en Dev loss: 0.3228 r:0.8030
et_en Dev loss: 0.3546 r:0.7115
si_en Dev loss: 0.6300 r:0.5929
ne_en Dev loss: 0.4176 r:0.7406
ru_en Dev loss: 0.4325 r:0.7397
Current avg r:0.6121 Best avg r: 0.6139
17:09:49,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:15,702 root INFO 
id:en_zh cur r: 0.4571 best r: 0.4571
17:11:32,849 root INFO 
id:ru_en cur r: 0.7438 best r: 0.7438
17:11:32,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:13:02,752 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5299
en_de Dev loss: 0.8711 r:0.2378
en_zh Dev loss: 0.7623 r:0.4535
ro_en Dev loss: 0.3783 r:0.8037
et_en Dev loss: 0.3607 r:0.7084
si_en Dev loss: 0.7488 r:0.5927
ne_en Dev loss: 0.4691 r:0.7465
ru_en Dev loss: 0.4833 r:0.7459
Current avg r:0.6126 Best avg r: 0.6139
17:17:34,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:19:04,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:34,498 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5156
en_de Dev loss: 0.9148 r:0.2137
en_zh Dev loss: 0.9582 r:0.4402
ro_en Dev loss: 0.4738 r:0.7960
et_en Dev loss: 0.4172 r:0.6956
si_en Dev loss: 0.9216 r:0.5781
ne_en Dev loss: 0.6515 r:0.7395
ru_en Dev loss: 0.6607 r:0.7061
Current avg r:0.5956 Best avg r: 0.6139
17:25:04,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:26:34,579 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:28:04,427 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5211
en_de Dev loss: 0.8891 r:0.2249
en_zh Dev loss: 0.8170 r:0.4438
ro_en Dev loss: 0.4499 r:0.7916
et_en Dev loss: 0.4218 r:0.6878
si_en Dev loss: 0.9341 r:0.5699
ne_en Dev loss: 0.5770 r:0.7379
ru_en Dev loss: 0.5122 r:0.7277
Current avg r:0.5977 Best avg r: 0.6139
17:32:36,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:49,562 root INFO 
id:en_de cur r: 0.2277 best r: 0.2277
17:33:02,391 root INFO 
id:en_zh cur r: 0.4591 best r: 0.4591
17:33:15,250 root INFO 
id:ro_en cur r: 0.8092 best r: 0.8092
17:33:40,968 root INFO 
id:si_en cur r: 0.5992 best r: 0.5992
17:33:53,831 root INFO 
id:ne_en cur r: 0.7609 best r: 0.7609
17:34:06,633 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:36,497 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4978
en_de Dev loss: 0.8514 r:0.2294
en_zh Dev loss: 0.7010 r:0.4583
ro_en Dev loss: 0.3659 r:0.8047
et_en Dev loss: 0.3794 r:0.7023
si_en Dev loss: 0.7024 r:0.5972
ne_en Dev loss: 0.3927 r:0.7576
ru_en Dev loss: 0.4643 r:0.7309
Current avg r:0.6115 Best avg r: 0.6139
17:40:08,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:21,735 root INFO 
id:en_de cur r: 0.2417 best r: 0.2417
17:40:47,420 root INFO 
id:ro_en cur r: 0.8108 best r: 0.8108
17:41:13,164 root INFO 
id:si_en cur r: 0.6123 best r: 0.6123
17:41:51,755 root INFO 
id:ru_en cur r: 0.7575 best r: 0.7575
17:41:51,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:21,810 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:43:21,817 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:43:21,822 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:43:21,826 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:43:21,831 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:43:21,837 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:43:21,842 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:43:34,670 root INFO Epoch 2 Global steps: 16100 Train loss: 0.4606
en_de Dev loss: 0.8399 r:0.2440
en_zh Dev loss: 0.6818 r:0.4595
ro_en Dev loss: 0.3388 r:0.8077
et_en Dev loss: 0.3769 r:0.7112
si_en Dev loss: 0.6542 r:0.6053
ne_en Dev loss: 0.3719 r:0.7511
ru_en Dev loss: 0.3888 r:0.7595
Current avg r:0.6198 Best avg r: 0.6198
17:48:08,203 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:21,98 root INFO 
id:en_de cur r: 0.2523 best r: 0.2523
17:48:33,965 root INFO 
id:en_zh cur r: 0.4607 best r: 0.4607
17:49:38,398 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:51:08,467 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4793
en_de Dev loss: 0.8781 r:0.2389
en_zh Dev loss: 0.7629 r:0.4581
ro_en Dev loss: 0.3800 r:0.8053
et_en Dev loss: 0.4158 r:0.6953
si_en Dev loss: 0.8276 r:0.5920
ne_en Dev loss: 0.4577 r:0.7456
ru_en Dev loss: 0.5658 r:0.7316
Current avg r:0.6095 Best avg r: 0.6198
17:55:40,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:06,226 root INFO 
id:en_zh cur r: 0.4683 best r: 0.4683
17:56:19,91 root INFO 
id:ro_en cur r: 0.8120 best r: 0.8120
17:57:10,602 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:40,684 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4774
en_de Dev loss: 0.8450 r:0.2553
en_zh Dev loss: 0.7078 r:0.4610
ro_en Dev loss: 0.3437 r:0.8089
et_en Dev loss: 0.3776 r:0.7022
si_en Dev loss: 0.7976 r:0.5912
ne_en Dev loss: 0.4836 r:0.7439
ru_en Dev loss: 0.5236 r:0.7235
Current avg r:0.6123 Best avg r: 0.6198
18:03:11,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:37,237 root INFO 
id:en_zh cur r: 0.4871 best r: 0.4871
18:03:50,139 root INFO 
id:ro_en cur r: 0.8173 best r: 0.8173
18:04:28,843 root INFO 
id:ne_en cur r: 0.7626 best r: 0.7626
18:04:41,684 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:06:11,734 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:06:11,740 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:06:11,745 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:06:11,750 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:06:11,755 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:06:11,760 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:06:11,764 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:06:24,594 root INFO Epoch 2 Global steps: 18200 Train loss: 0.5059
en_de Dev loss: 0.8326 r:0.2522
en_zh Dev loss: 0.6598 r:0.4811
ro_en Dev loss: 0.3202 r:0.8161
et_en Dev loss: 0.3687 r:0.7060
si_en Dev loss: 0.6499 r:0.6069
ne_en Dev loss: 0.3858 r:0.7552
ru_en Dev loss: 0.4226 r:0.7448
Current avg r:0.6232 Best avg r: 0.6232
18:10:55,39 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:11:33,679 root INFO 
id:ro_en cur r: 0.8205 best r: 0.8205
18:11:46,577 root INFO 
id:et_en cur r: 0.7103 best r: 0.7103
18:11:59,469 root INFO 
id:si_en cur r: 0.6185 best r: 0.6185
18:12:12,361 root INFO 
id:ne_en cur r: 0.7653 best r: 0.7653
18:12:25,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:55,208 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:13:55,215 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:13:55,220 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:13:55,225 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:13:55,229 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:13:55,234 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:13:55,239 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_ruen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:14:08,73 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4776
en_de Dev loss: 0.8365 r:0.2552
en_zh Dev loss: 0.6578 r:0.4850
ro_en Dev loss: 0.3098 r:0.8195
et_en Dev loss: 0.3583 r:0.7117
si_en Dev loss: 0.5893 r:0.6141
ne_en Dev loss: 0.3685 r:0.7571
ru_en Dev loss: 0.4186 r:0.7481
Current avg r:0.6273 Best avg r: 0.6273
18:18:37,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:50,830 root INFO 
id:en_de cur r: 0.2693 best r: 0.2693
18:20:07,889 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:21:37,713 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4642
en_de Dev loss: 0.8364 r:0.2646
en_zh Dev loss: 0.7066 r:0.4661
ro_en Dev loss: 0.3267 r:0.8112
et_en Dev loss: 0.3700 r:0.7078
si_en Dev loss: 0.6026 r:0.6091
ne_en Dev loss: 0.3736 r:0.7473
ru_en Dev loss: 0.4592 r:0.7356
Current avg r:0.6203 Best avg r: 0.6273
18:26:10,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:23,314 root INFO 
id:en_de cur r: 0.2799 best r: 0.2799
18:27:40,593 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:29:10,632 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4696
en_de Dev loss: 0.8567 r:0.2590
en_zh Dev loss: 0.7171 r:0.4605
ro_en Dev loss: 0.3378 r:0.8117
et_en Dev loss: 0.3777 r:0.7049
si_en Dev loss: 0.6705 r:0.6120
ne_en Dev loss: 0.4157 r:0.7574
ru_en Dev loss: 0.4917 r:0.7275
Current avg r:0.6190 Best avg r: 0.6273
18:33:42,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:35:13,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:43,88 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4754
en_de Dev loss: 0.8379 r:0.2364
en_zh Dev loss: 0.6826 r:0.4814
ro_en Dev loss: 0.3416 r:0.8139
et_en Dev loss: 0.3805 r:0.7014
si_en Dev loss: 0.5734 r:0.6199
ne_en Dev loss: 0.3839 r:0.7464
ru_en Dev loss: 0.4282 r:0.7302
Current avg r:0.6185 Best avg r: 0.6273
18:41:13,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:43,87 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:44:13,183 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4604
en_de Dev loss: 0.8510 r:0.2571
en_zh Dev loss: 0.7651 r:0.4639
ro_en Dev loss: 0.3848 r:0.8070
et_en Dev loss: 0.3890 r:0.7013
si_en Dev loss: 0.7011 r:0.6052
ne_en Dev loss: 0.4527 r:0.7567
ru_en Dev loss: 0.4883 r:0.7289
Current avg r:0.6172 Best avg r: 0.6273
18:48:43,338 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:50:13,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:43,503 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4659
en_de Dev loss: 0.8517 r:0.2431
en_zh Dev loss: 0.7296 r:0.4617
ro_en Dev loss: 0.3573 r:0.8094
et_en Dev loss: 0.3679 r:0.7021
si_en Dev loss: 0.6696 r:0.6085
ne_en Dev loss: 0.4567 r:0.7487
ru_en Dev loss: 0.5150 r:0.7072
Current avg r:0.6115 Best avg r: 0.6273
18:56:14,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:57:44,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:59:14,320 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4495
en_de Dev loss: 0.8792 r:0.2658
en_zh Dev loss: 0.7419 r:0.4665
ro_en Dev loss: 0.3636 r:0.8084
et_en Dev loss: 0.3735 r:0.7099
si_en Dev loss: 0.7399 r:0.6054
ne_en Dev loss: 0.5518 r:0.7531
ru_en Dev loss: 0.4570 r:0.7402
Current avg r:0.6213 Best avg r: 0.6273
19:03:43,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:35,295 root INFO 
id:et_en cur r: 0.7163 best r: 0.7163
19:05:01,99 root INFO 
id:ne_en cur r: 0.7664 best r: 0.7664
19:05:13,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:43,988 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4637
en_de Dev loss: 0.8430 r:0.2655
en_zh Dev loss: 0.7214 r:0.4581
ro_en Dev loss: 0.3212 r:0.8173
et_en Dev loss: 0.3532 r:0.7198
si_en Dev loss: 0.6249 r:0.6125
ne_en Dev loss: 0.4072 r:0.7587
ru_en Dev loss: 0.4069 r:0.7569
Current avg r:0.6270 Best avg r: 0.6273
19:11:17,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:47,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:14:17,305 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4438
en_de Dev loss: 0.8347 r:0.2610
en_zh Dev loss: 0.7293 r:0.4629
ro_en Dev loss: 0.3395 r:0.8100
et_en Dev loss: 0.3724 r:0.7073
si_en Dev loss: 0.7196 r:0.6045
ne_en Dev loss: 0.4329 r:0.7499
ru_en Dev loss: 0.4236 r:0.7468
Current avg r:0.6203 Best avg r: 0.6273
19:18:47,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:00,51 root INFO 
id:en_de cur r: 0.2913 best r: 0.2913
19:19:38,587 root INFO 
id:et_en cur r: 0.7181 best r: 0.7181
19:20:17,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:46,915 root INFO Epoch 3 Global steps: 25200 Train loss: 0.4299
en_de Dev loss: 0.8647 r:0.2770
en_zh Dev loss: 0.7053 r:0.4652
ro_en Dev loss: 0.3424 r:0.8142
et_en Dev loss: 0.3686 r:0.7148
si_en Dev loss: 0.7146 r:0.6124
ne_en Dev loss: 0.4276 r:0.7576
ru_en Dev loss: 0.4523 r:0.7387
Current avg r:0.6257 Best avg r: 0.6273
19:26:17,940 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:47,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:29:17,773 root INFO Epoch 3 Global steps: 25900 Train loss: 0.4619
en_de Dev loss: 0.8467 r:0.2644
en_zh Dev loss: 0.7228 r:0.4595
ro_en Dev loss: 0.3602 r:0.8057
et_en Dev loss: 0.3744 r:0.7023
si_en Dev loss: 0.7145 r:0.6071
ne_en Dev loss: 0.4399 r:0.7531
ru_en Dev loss: 0.4880 r:0.7267
Current avg r:0.6170 Best avg r: 0.6273
19:33:49,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:35:20,38 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:50,113 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4322
en_de Dev loss: 0.8259 r:0.2662
en_zh Dev loss: 0.6934 r:0.4605
ro_en Dev loss: 0.3264 r:0.8138
et_en Dev loss: 0.3946 r:0.7079
si_en Dev loss: 0.6394 r:0.6176
ne_en Dev loss: 0.4117 r:0.7550
ru_en Dev loss: 0.3958 r:0.7488
Current avg r:0.6242 Best avg r: 0.6273
19:41:20,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:33,81 root INFO 
id:en_de cur r: 0.2991 best r: 0.2991
19:41:58,833 root INFO 
id:ro_en cur r: 0.8207 best r: 0.8207
19:42:50,384 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:44:20,451 root INFO Epoch 3 Global steps: 27300 Train loss: 0.4362
en_de Dev loss: 0.8642 r:0.2625
en_zh Dev loss: 0.8131 r:0.4607
ro_en Dev loss: 0.3687 r:0.8140
et_en Dev loss: 0.3840 r:0.7044
si_en Dev loss: 0.7992 r:0.6100
ne_en Dev loss: 0.5602 r:0.7540
ru_en Dev loss: 0.5243 r:0.7250
Current avg r:0.6186 Best avg r: 0.6273
19:48:53,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:50:23,544 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:53,452 root INFO Epoch 3 Global steps: 28000 Train loss: 0.4142
en_de Dev loss: 0.8399 r:0.2654
en_zh Dev loss: 0.7394 r:0.4675
ro_en Dev loss: 0.3413 r:0.8130
et_en Dev loss: 0.3989 r:0.6972
si_en Dev loss: 0.7180 r:0.6079
ne_en Dev loss: 0.4306 r:0.7488
ru_en Dev loss: 0.4500 r:0.7411
Current avg r:0.6201 Best avg r: 0.6273
19:56:23,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:02,583 root INFO 
id:ro_en cur r: 0.8211 best r: 0.8211
19:57:54,104 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:59:24,149 root INFO Epoch 3 Global steps: 28700 Train loss: 0.4036
en_de Dev loss: 0.8596 r:0.2655
en_zh Dev loss: 0.7388 r:0.4741
ro_en Dev loss: 0.3734 r:0.8176
et_en Dev loss: 0.4069 r:0.6978
si_en Dev loss: 0.7312 r:0.6151
ne_en Dev loss: 0.4016 r:0.7532
ru_en Dev loss: 0.4775 r:0.7431
Current avg r:0.6238 Best avg r: 0.6273
20:03:57,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:05:27,294 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:57,356 root INFO Epoch 3 Global steps: 29400 Train loss: 0.4102
en_de Dev loss: 0.8543 r:0.2652
en_zh Dev loss: 0.7565 r:0.4553
ro_en Dev loss: 0.3670 r:0.8116
et_en Dev loss: 0.4086 r:0.6941
si_en Dev loss: 0.8030 r:0.6016
ne_en Dev loss: 0.5179 r:0.7376
ru_en Dev loss: 0.5608 r:0.7016
Current avg r:0.6096 Best avg r: 0.6273
20:11:29,250 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:59,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:29,471 root INFO Epoch 3 Global steps: 30100 Train loss: 0.4229
en_de Dev loss: 0.8489 r:0.2571
en_zh Dev loss: 0.7816 r:0.4638
ro_en Dev loss: 0.3550 r:0.8189
et_en Dev loss: 0.3829 r:0.7061
si_en Dev loss: 0.8477 r:0.6093
ne_en Dev loss: 0.5701 r:0.7512
ru_en Dev loss: 0.4748 r:0.7388
Current avg r:0.6207 Best avg r: 0.6273
20:18:59,472 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:38,9 root INFO 
id:ro_en cur r: 0.8225 best r: 0.8225
20:20:29,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:59,355 root INFO Epoch 3 Global steps: 30800 Train loss: 0.4008
en_de Dev loss: 0.8334 r:0.2721
en_zh Dev loss: 0.7090 r:0.4761
ro_en Dev loss: 0.3301 r:0.8212
et_en Dev loss: 0.3843 r:0.7068
si_en Dev loss: 0.7766 r:0.6108
ne_en Dev loss: 0.4528 r:0.7549
ru_en Dev loss: 0.4404 r:0.7489
Current avg r:0.6272 Best avg r: 0.6273
20:26:36,220 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:28:06,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:36,564 root INFO Epoch 3 Global steps: 31500 Train loss: 0.4029
en_de Dev loss: 0.8325 r:0.2791
en_zh Dev loss: 0.7815 r:0.4594
ro_en Dev loss: 0.3641 r:0.8136
et_en Dev loss: 0.4071 r:0.7001
si_en Dev loss: 0.7945 r:0.6092
ne_en Dev loss: 0.4935 r:0.7539
ru_en Dev loss: 0.5223 r:0.7234
Current avg r:0.6198 Best avg r: 0.6273
20:34:07,857 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:38,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:08,192 root INFO Epoch 4 Global steps: 32200 Train loss: 0.3511
en_de Dev loss: 0.8376 r:0.2563
en_zh Dev loss: 0.7601 r:0.4499
ro_en Dev loss: 0.3540 r:0.8116
et_en Dev loss: 0.4064 r:0.6925
si_en Dev loss: 0.8029 r:0.6018
ne_en Dev loss: 0.4957 r:0.7587
ru_en Dev loss: 0.4786 r:0.7210
Current avg r:0.6131 Best avg r: 0.6273
20:41:38,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:08,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:39,3 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3837
en_de Dev loss: 0.8434 r:0.2433
en_zh Dev loss: 0.7430 r:0.4566
ro_en Dev loss: 0.3330 r:0.8187
et_en Dev loss: 0.3923 r:0.7022
si_en Dev loss: 0.7255 r:0.6096
ne_en Dev loss: 0.3896 r:0.7551
ru_en Dev loss: 0.4582 r:0.7317
Current avg r:0.6167 Best avg r: 0.6273
20:49:09,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:39,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:10,46 root INFO Epoch 4 Global steps: 33600 Train loss: 0.3767
en_de Dev loss: 0.8576 r:0.2491
en_zh Dev loss: 0.7266 r:0.4593
ro_en Dev loss: 0.3595 r:0.8126
et_en Dev loss: 0.3818 r:0.7014
si_en Dev loss: 0.7071 r:0.6102
ne_en Dev loss: 0.4456 r:0.7578
ru_en Dev loss: 0.4927 r:0.7242
Current avg r:0.6164 Best avg r: 0.6273
20:56:42,170 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:12,349 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:42,420 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3855
en_de Dev loss: 0.8517 r:0.2612
en_zh Dev loss: 0.7932 r:0.4516
ro_en Dev loss: 0.3838 r:0.8101
et_en Dev loss: 0.3971 r:0.6903
si_en Dev loss: 0.8230 r:0.5949
ne_en Dev loss: 0.5591 r:0.7445
ru_en Dev loss: 0.4803 r:0.7362
Current avg r:0.6127 Best avg r: 0.6273
21:04:14,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:44,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:14,261 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3990
en_de Dev loss: 0.8405 r:0.2630
en_zh Dev loss: 0.7421 r:0.4593
ro_en Dev loss: 0.3483 r:0.8082
et_en Dev loss: 0.3988 r:0.6910
si_en Dev loss: 0.8032 r:0.5895
ne_en Dev loss: 0.4385 r:0.7499
ru_en Dev loss: 0.5178 r:0.7025
Current avg r:0.6090 Best avg r: 0.6273
21:11:44,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:14,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:44,763 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3891
en_de Dev loss: 0.8304 r:0.2642
en_zh Dev loss: 0.7397 r:0.4639
ro_en Dev loss: 0.3490 r:0.8093
et_en Dev loss: 0.4036 r:0.6891
si_en Dev loss: 0.7600 r:0.5991
ne_en Dev loss: 0.4455 r:0.7458
ru_en Dev loss: 0.4652 r:0.7188
Current avg r:0.6129 Best avg r: 0.6273
21:19:21,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:51,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:21,307 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3715
en_de Dev loss: 0.8635 r:0.2579
en_zh Dev loss: 0.7716 r:0.4608
ro_en Dev loss: 0.3857 r:0.8100
et_en Dev loss: 0.4134 r:0.6968
si_en Dev loss: 0.8785 r:0.6002
ne_en Dev loss: 0.5479 r:0.7487
ru_en Dev loss: 0.5770 r:0.7058
Current avg r:0.6114 Best avg r: 0.6273
21:26:52,675 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:22,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:52,925 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3818
en_de Dev loss: 0.8522 r:0.2646
en_zh Dev loss: 0.7393 r:0.4625
ro_en Dev loss: 0.3442 r:0.8114
et_en Dev loss: 0.3989 r:0.6917
si_en Dev loss: 0.7417 r:0.6030
ne_en Dev loss: 0.4304 r:0.7470
ru_en Dev loss: 0.4743 r:0.7256
Current avg r:0.6151 Best avg r: 0.6273
21:34:24,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:03,324 root INFO 
id:ro_en cur r: 0.8232 best r: 0.8232
21:35:54,871 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:24,985 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3628
en_de Dev loss: 0.8430 r:0.2522
en_zh Dev loss: 0.7057 r:0.4724
ro_en Dev loss: 0.3269 r:0.8221
et_en Dev loss: 0.3989 r:0.7022
si_en Dev loss: 0.6497 r:0.6225
ne_en Dev loss: 0.3954 r:0.7536
ru_en Dev loss: 0.4442 r:0.7424
Current avg r:0.6239 Best avg r: 0.6273
21:41:54,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:24,387 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:54,234 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3694
en_de Dev loss: 0.8518 r:0.2505
en_zh Dev loss: 0.7877 r:0.4615
ro_en Dev loss: 0.3494 r:0.8155
et_en Dev loss: 0.4001 r:0.6963
si_en Dev loss: 0.8799 r:0.6070
ne_en Dev loss: 0.5647 r:0.7519
ru_en Dev loss: 0.5016 r:0.7231
Current avg r:0.6151 Best avg r: 0.6273
21:49:26,380 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:30,643 root INFO 
id:si_en cur r: 0.6222 best r: 0.6222
21:50:56,388 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:26,504 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3748
en_de Dev loss: 0.8435 r:0.2502
en_zh Dev loss: 0.7104 r:0.4625
ro_en Dev loss: 0.3254 r:0.8166
et_en Dev loss: 0.4087 r:0.6970
si_en Dev loss: 0.6126 r:0.6257
ne_en Dev loss: 0.3692 r:0.7584
ru_en Dev loss: 0.3952 r:0.7516
Current avg r:0.6231 Best avg r: 0.6273
21:56:58,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:28,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:59,67 root INFO Epoch 5 Global steps: 39900 Train loss: 0.3426
en_de Dev loss: 0.8460 r:0.2634
en_zh Dev loss: 0.7331 r:0.4674
ro_en Dev loss: 0.3409 r:0.8176
et_en Dev loss: 0.4170 r:0.6941
si_en Dev loss: 0.6624 r:0.6221
ne_en Dev loss: 0.3880 r:0.7551
ru_en Dev loss: 0.4560 r:0.7302
Current avg r:0.6214 Best avg r: 0.6273
22:04:29,16 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:59,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:29,299 root INFO Epoch 5 Global steps: 40600 Train loss: 0.3444
en_de Dev loss: 0.8472 r:0.2485
en_zh Dev loss: 0.7604 r:0.4667
ro_en Dev loss: 0.3589 r:0.8178
et_en Dev loss: 0.4544 r:0.6937
si_en Dev loss: 0.6849 r:0.6164
ne_en Dev loss: 0.4265 r:0.7552
ru_en Dev loss: 0.4375 r:0.7440
Current avg r:0.6203 Best avg r: 0.6273
22:12:01,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:31,521 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:01,397 root INFO Epoch 5 Global steps: 41300 Train loss: 0.3445
en_de Dev loss: 0.8657 r:0.2454
en_zh Dev loss: 0.8102 r:0.4550
ro_en Dev loss: 0.3796 r:0.8142
et_en Dev loss: 0.4585 r:0.6828
si_en Dev loss: 0.8089 r:0.6037
ne_en Dev loss: 0.5473 r:0.7436
ru_en Dev loss: 0.5257 r:0.7093
Current avg r:0.6077 Best avg r: 0.6273
22:19:30,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:00,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:30,890 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3447
en_de Dev loss: 0.8546 r:0.2554
en_zh Dev loss: 0.7526 r:0.4535
ro_en Dev loss: 0.3400 r:0.8196
et_en Dev loss: 0.4292 r:0.6879
si_en Dev loss: 0.6677 r:0.6094
ne_en Dev loss: 0.4149 r:0.7397
ru_en Dev loss: 0.4463 r:0.7319
Current avg r:0.6139 Best avg r: 0.6273
22:27:04,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:34,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:04,654 root INFO Epoch 5 Global steps: 42700 Train loss: 0.3352
en_de Dev loss: 0.8632 r:0.2406
en_zh Dev loss: 0.8126 r:0.4492
ro_en Dev loss: 0.3410 r:0.8219
et_en Dev loss: 0.4189 r:0.6911
si_en Dev loss: 0.7211 r:0.6099
ne_en Dev loss: 0.4264 r:0.7431
ru_en Dev loss: 0.4814 r:0.7382
Current avg r:0.6134 Best avg r: 0.6273
22:34:34,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:04,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:34,390 root INFO Epoch 5 Global steps: 43400 Train loss: 0.3350
en_de Dev loss: 0.8446 r:0.2585
en_zh Dev loss: 0.7496 r:0.4634
ro_en Dev loss: 0.3738 r:0.8135
et_en Dev loss: 0.4405 r:0.6803
si_en Dev loss: 0.8142 r:0.5958
ne_en Dev loss: 0.4511 r:0.7410
ru_en Dev loss: 0.4742 r:0.7354
Current avg r:0.6125 Best avg r: 0.6273
22:42:04,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:35,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:05,300 root INFO Epoch 5 Global steps: 44100 Train loss: 0.3377
en_de Dev loss: 0.8488 r:0.2658
en_zh Dev loss: 0.7780 r:0.4610
ro_en Dev loss: 0.3951 r:0.8113
et_en Dev loss: 0.4681 r:0.6715
si_en Dev loss: 0.8760 r:0.5789
ne_en Dev loss: 0.4804 r:0.7379
ru_en Dev loss: 0.5083 r:0.7170
Current avg r:0.6062 Best avg r: 0.6273
22:49:38,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:08,476 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:38,325 root INFO Epoch 5 Global steps: 44800 Train loss: 0.3429
en_de Dev loss: 0.8603 r:0.2492
en_zh Dev loss: 0.8067 r:0.4566
ro_en Dev loss: 0.3566 r:0.8200
et_en Dev loss: 0.4328 r:0.6820
si_en Dev loss: 0.7744 r:0.6035
ne_en Dev loss: 0.4288 r:0.7443
ru_en Dev loss: 0.5125 r:0.7143
Current avg r:0.6100 Best avg r: 0.6273
22:57:08,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:38,365 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:08,491 root INFO Epoch 5 Global steps: 45500 Train loss: 0.3599
en_de Dev loss: 0.8707 r:0.2306
en_zh Dev loss: 0.7454 r:0.4741
ro_en Dev loss: 0.3277 r:0.8212
et_en Dev loss: 0.4305 r:0.6846
si_en Dev loss: 0.8155 r:0.5968
ne_en Dev loss: 0.4419 r:0.7412
ru_en Dev loss: 0.4566 r:0.7325
Current avg r:0.6116 Best avg r: 0.6273
23:04:40,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:10,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:40,592 root INFO Epoch 5 Global steps: 46200 Train loss: 0.3112
en_de Dev loss: 0.8582 r:0.2491
en_zh Dev loss: 0.7764 r:0.4645
ro_en Dev loss: 0.3527 r:0.8196
et_en Dev loss: 0.4346 r:0.6831
si_en Dev loss: 0.8669 r:0.5985
ne_en Dev loss: 0.4910 r:0.7423
ru_en Dev loss: 0.5128 r:0.7161
Current avg r:0.6105 Best avg r: 0.6273
23:12:14,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:43,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:13,712 root INFO Epoch 5 Global steps: 46900 Train loss: 0.3275
en_de Dev loss: 0.8544 r:0.2430
en_zh Dev loss: 0.7357 r:0.4668
ro_en Dev loss: 0.3137 r:0.8231
et_en Dev loss: 0.3907 r:0.6919
si_en Dev loss: 0.6856 r:0.6120
ne_en Dev loss: 0.4018 r:0.7538
ru_en Dev loss: 0.4331 r:0.7358
Current avg r:0.6181 Best avg r: 0.6273
23:19:44,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:14,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:44,389 root INFO Epoch 5 Global steps: 47600 Train loss: 0.3207
en_de Dev loss: 0.8489 r:0.2419
en_zh Dev loss: 0.7462 r:0.4607
ro_en Dev loss: 0.3186 r:0.8250
et_en Dev loss: 0.3985 r:0.6992
si_en Dev loss: 0.6987 r:0.6097
ne_en Dev loss: 0.3708 r:0.7539
ru_en Dev loss: 0.4239 r:0.7413
Current avg r:0.6188 Best avg r: 0.6273
23:27:18,727 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:48,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:18,861 root INFO Epoch 6 Global steps: 48300 Train loss: 0.2984
en_de Dev loss: 0.8506 r:0.2530
en_zh Dev loss: 0.7825 r:0.4533
ro_en Dev loss: 0.3713 r:0.8171
et_en Dev loss: 0.4283 r:0.6805
si_en Dev loss: 0.8280 r:0.5866
ne_en Dev loss: 0.4952 r:0.7439
ru_en Dev loss: 0.5125 r:0.7098
Current avg r:0.6063 Best avg r: 0.6273
23:34:49,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:27,728 root INFO 
id:ro_en cur r: 0.8240 best r: 0.8240
23:36:19,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:49,304 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2951
en_de Dev loss: 0.8488 r:0.2718
en_zh Dev loss: 0.7677 r:0.4556
ro_en Dev loss: 0.3771 r:0.8209
et_en Dev loss: 0.4108 r:0.6900
si_en Dev loss: 0.8060 r:0.5962
ne_en Dev loss: 0.4443 r:0.7503
ru_en Dev loss: 0.4747 r:0.7324
Current avg r:0.6167 Best avg r: 0.6273
23:42:21,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:51,765 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:21,906 root INFO Epoch 6 Global steps: 49700 Train loss: 0.2908
en_de Dev loss: 0.8481 r:0.2560
en_zh Dev loss: 0.7462 r:0.4627
ro_en Dev loss: 0.3390 r:0.8207
et_en Dev loss: 0.4353 r:0.6858
si_en Dev loss: 0.7375 r:0.5951
ne_en Dev loss: 0.4091 r:0.7433
ru_en Dev loss: 0.4613 r:0.7217
Current avg r:0.6122 Best avg r: 0.6273
23:49:51,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:21,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:51,497 root INFO Epoch 6 Global steps: 50400 Train loss: 0.3009
en_de Dev loss: 0.8605 r:0.2459
en_zh Dev loss: 0.7998 r:0.4601
ro_en Dev loss: 0.3690 r:0.8185
et_en Dev loss: 0.4440 r:0.6806
si_en Dev loss: 0.7978 r:0.5861
ne_en Dev loss: 0.4738 r:0.7385
ru_en Dev loss: 0.4800 r:0.7317
Current avg r:0.6088 Best avg r: 0.6273
23:57:24,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:53,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:23,933 root INFO Epoch 6 Global steps: 51100 Train loss: 0.2959
en_de Dev loss: 0.8614 r:0.2416
en_zh Dev loss: 0.8165 r:0.4591
ro_en Dev loss: 0.3987 r:0.8166
et_en Dev loss: 0.4463 r:0.6807
si_en Dev loss: 0.8743 r:0.5838
ne_en Dev loss: 0.5204 r:0.7375
ru_en Dev loss: 0.4868 r:0.7266
Current avg r:0.6066 Best avg r: 0.6273
00:04:53,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:06:23,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:53,847 root INFO Epoch 6 Global steps: 51800 Train loss: 0.3038
en_de Dev loss: 0.8485 r:0.2548
en_zh Dev loss: 0.7777 r:0.4628
ro_en Dev loss: 0.3466 r:0.8187
et_en Dev loss: 0.4444 r:0.6765
si_en Dev loss: 0.7164 r:0.5978
ne_en Dev loss: 0.4643 r:0.7354
ru_en Dev loss: 0.4703 r:0.7258
Current avg r:0.6103 Best avg r: 0.6273
00:12:25,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:55,932 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:26,61 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2989
en_de Dev loss: 0.8695 r:0.2541
en_zh Dev loss: 0.7851 r:0.4588
ro_en Dev loss: 0.3679 r:0.8151
et_en Dev loss: 0.4418 r:0.6745
si_en Dev loss: 0.8497 r:0.5852
ne_en Dev loss: 0.4740 r:0.7330
ru_en Dev loss: 0.5282 r:0.7101
Current avg r:0.6044 Best avg r: 0.6273
00:19:55,149 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:21:25,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:55,666 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2902
en_de Dev loss: 0.8552 r:0.2426
en_zh Dev loss: 0.7932 r:0.4563
ro_en Dev loss: 0.3591 r:0.8191
et_en Dev loss: 0.4223 r:0.6780
si_en Dev loss: 0.8068 r:0.5884
ne_en Dev loss: 0.5363 r:0.7356
ru_en Dev loss: 0.4891 r:0.7243
Current avg r:0.6063 Best avg r: 0.6273
00:27:29,60 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:59,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:29,409 root INFO Epoch 6 Global steps: 53900 Train loss: 0.2784
en_de Dev loss: 0.8529 r:0.2473
en_zh Dev loss: 0.7803 r:0.4601
ro_en Dev loss: 0.3551 r:0.8168
et_en Dev loss: 0.4163 r:0.6748
si_en Dev loss: 0.8570 r:0.5806
ne_en Dev loss: 0.5445 r:0.7411
ru_en Dev loss: 0.4962 r:0.7118
Current avg r:0.6047 Best avg r: 0.6273
00:35:01,31 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:30,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:00,773 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2931
en_de Dev loss: 0.8297 r:0.2813
en_zh Dev loss: 0.7292 r:0.4625
ro_en Dev loss: 0.3409 r:0.8164
et_en Dev loss: 0.4210 r:0.6690
si_en Dev loss: 0.8274 r:0.5773
ne_en Dev loss: 0.5240 r:0.7420
ru_en Dev loss: 0.4677 r:0.7118
Current avg r:0.6086 Best avg r: 0.6273
00:42:32,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:02,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:32,308 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2915
en_de Dev loss: 0.8437 r:0.2734
en_zh Dev loss: 0.8569 r:0.4515
ro_en Dev loss: 0.3991 r:0.8142
et_en Dev loss: 0.4490 r:0.6760
si_en Dev loss: 0.9053 r:0.5813
ne_en Dev loss: 0.5342 r:0.7482
ru_en Dev loss: 0.5256 r:0.7089
Current avg r:0.6077 Best avg r: 0.6273
00:50:03,638 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:33,660 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:53:03,728 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2553
en_de Dev loss: 0.8609 r:0.2386
en_zh Dev loss: 0.8077 r:0.4452
ro_en Dev loss: 0.3757 r:0.8105
et_en Dev loss: 0.4563 r:0.6637
si_en Dev loss: 0.8525 r:0.5749
ne_en Dev loss: 0.5466 r:0.7378
ru_en Dev loss: 0.5201 r:0.6933
Current avg r:0.5949 Best avg r: 0.6273
00:57:34,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:59:04,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:00:34,532 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2645
en_de Dev loss: 0.8444 r:0.2489
en_zh Dev loss: 0.7768 r:0.4501
ro_en Dev loss: 0.3490 r:0.8150
et_en Dev loss: 0.4522 r:0.6743
si_en Dev loss: 0.8122 r:0.5779
ne_en Dev loss: 0.4780 r:0.7444
ru_en Dev loss: 0.4947 r:0.7012
Current avg r:0.6017 Best avg r: 0.6273
01:05:04,61 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:34,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:04,178 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2654
en_de Dev loss: 0.8544 r:0.2457
en_zh Dev loss: 0.8051 r:0.4493
ro_en Dev loss: 0.3721 r:0.8149
et_en Dev loss: 0.4606 r:0.6680
si_en Dev loss: 0.8517 r:0.5743
ne_en Dev loss: 0.5336 r:0.7455
ru_en Dev loss: 0.4965 r:0.7093
Current avg r:0.6010 Best avg r: 0.6273
01:12:37,355 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:07,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:37,191 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2753
en_de Dev loss: 0.8516 r:0.2673
en_zh Dev loss: 0.7834 r:0.4547
ro_en Dev loss: 0.3344 r:0.8202
et_en Dev loss: 0.4244 r:0.6847
si_en Dev loss: 0.7357 r:0.5920
ne_en Dev loss: 0.4431 r:0.7462
ru_en Dev loss: 0.4759 r:0.7214
Current avg r:0.6124 Best avg r: 0.6273
01:20:09,98 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:38,993 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:08,853 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2695
en_de Dev loss: 0.8546 r:0.2447
en_zh Dev loss: 0.7905 r:0.4482
ro_en Dev loss: 0.3580 r:0.8178
et_en Dev loss: 0.4310 r:0.6819
si_en Dev loss: 0.8355 r:0.5850
ne_en Dev loss: 0.4906 r:0.7384
ru_en Dev loss: 0.4745 r:0.7243
Current avg r:0.6058 Best avg r: 0.6273
01:27:42,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:12,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:42,448 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2571
en_de Dev loss: 0.8663 r:0.2238
en_zh Dev loss: 0.8121 r:0.4480
ro_en Dev loss: 0.3995 r:0.8108
et_en Dev loss: 0.4347 r:0.6716
si_en Dev loss: 0.9452 r:0.5781
ne_en Dev loss: 0.5253 r:0.7443
ru_en Dev loss: 0.4966 r:0.7125
Current avg r:0.5984 Best avg r: 0.6273
01:35:12,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:36:42,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:12,643 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2510
en_de Dev loss: 0.8761 r:0.2356
en_zh Dev loss: 0.8449 r:0.4492
ro_en Dev loss: 0.3997 r:0.8120
et_en Dev loss: 0.4612 r:0.6671
si_en Dev loss: 0.8254 r:0.5849
ne_en Dev loss: 0.5735 r:0.7423
ru_en Dev loss: 0.5533 r:0.6928
Current avg r:0.5977 Best avg r: 0.6273
01:42:43,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:13,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:43,243 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2593
en_de Dev loss: 0.8741 r:0.2527
en_zh Dev loss: 0.8322 r:0.4561
ro_en Dev loss: 0.3869 r:0.8108
et_en Dev loss: 0.4650 r:0.6676
si_en Dev loss: 0.9833 r:0.5678
ne_en Dev loss: 0.5947 r:0.7387
ru_en Dev loss: 0.5052 r:0.7139
Current avg r:0.6011 Best avg r: 0.6273
01:50:12,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:42,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:53:12,803 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2493
en_de Dev loss: 0.8722 r:0.2297
en_zh Dev loss: 0.7423 r:0.4747
ro_en Dev loss: 0.3384 r:0.8162
et_en Dev loss: 0.4459 r:0.6756
si_en Dev loss: 0.7248 r:0.5870
ne_en Dev loss: 0.4296 r:0.7453
ru_en Dev loss: 0.4499 r:0.7291
Current avg r:0.6082 Best avg r: 0.6273
01:57:42,447 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:59:12,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:42,803 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2559
en_de Dev loss: 0.8590 r:0.2403
en_zh Dev loss: 0.7512 r:0.4679
ro_en Dev loss: 0.3298 r:0.8200
et_en Dev loss: 0.4417 r:0.6768
si_en Dev loss: 0.7909 r:0.5839
ne_en Dev loss: 0.4542 r:0.7474
ru_en Dev loss: 0.4643 r:0.7248
Current avg r:0.6087 Best avg r: 0.6273
02:05:16,395 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:46,605 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:08:16,743 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2561
en_de Dev loss: 0.8595 r:0.2509
en_zh Dev loss: 0.8309 r:0.4515
ro_en Dev loss: 0.3843 r:0.8144
et_en Dev loss: 0.4869 r:0.6736
si_en Dev loss: 0.9121 r:0.5714
ne_en Dev loss: 0.5031 r:0.7360
ru_en Dev loss: 0.5308 r:0.7117
Current avg r:0.6013 Best avg r: 0.6273
02:12:47,801 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:14:17,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:15:47,466 root INFO Epoch 7 Global steps: 63700 Train loss: 0.2503
en_de Dev loss: 0.8808 r:0.2278
en_zh Dev loss: 0.8246 r:0.4512
ro_en Dev loss: 0.3956 r:0.8083
et_en Dev loss: 0.4770 r:0.6544
si_en Dev loss: 0.9439 r:0.5601
ne_en Dev loss: 0.5042 r:0.7364
ru_en Dev loss: 0.5219 r:0.7007
Current avg r:0.5913 Best avg r: 0.6273
02:20:20,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:50,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:23:20,318 root INFO Epoch 8 Global steps: 64400 Train loss: 0.2397
en_de Dev loss: 0.8777 r:0.2367
en_zh Dev loss: 0.8547 r:0.4537
ro_en Dev loss: 0.4099 r:0.8105
et_en Dev loss: 0.4864 r:0.6624
si_en Dev loss: 0.9880 r:0.5575
ne_en Dev loss: 0.5615 r:0.7348
ru_en Dev loss: 0.5264 r:0.7043
Current avg r:0.5943 Best avg r: 0.6273
02:27:50,922 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:21,102 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:30:51,230 root INFO Epoch 8 Global steps: 65100 Train loss: 0.2379
en_de Dev loss: 0.8604 r:0.2270
en_zh Dev loss: 0.8056 r:0.4394
ro_en Dev loss: 0.3848 r:0.8160
et_en Dev loss: 0.4839 r:0.6662
si_en Dev loss: 0.8797 r:0.5689
ne_en Dev loss: 0.5661 r:0.7369
ru_en Dev loss: 0.4992 r:0.6970
Current avg r:0.5931 Best avg r: 0.6273
02:35:25,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:55,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:24,986 root INFO Epoch 8 Global steps: 65800 Train loss: 0.2456
en_de Dev loss: 0.8708 r:0.2321
en_zh Dev loss: 0.8210 r:0.4474
ro_en Dev loss: 0.3847 r:0.8143
et_en Dev loss: 0.5289 r:0.6659
si_en Dev loss: 0.8076 r:0.5750
ne_en Dev loss: 0.4921 r:0.7362
ru_en Dev loss: 0.4966 r:0.7065
Current avg r:0.5968 Best avg r: 0.6273
02:42:55,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:44:25,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:55,559 root INFO Epoch 8 Global steps: 66500 Train loss: 0.2267
en_de Dev loss: 0.8515 r:0.2450
en_zh Dev loss: 0.8147 r:0.4485
ro_en Dev loss: 0.3733 r:0.8165
et_en Dev loss: 0.4600 r:0.6669
si_en Dev loss: 0.9065 r:0.5678
ne_en Dev loss: 0.5796 r:0.7406
ru_en Dev loss: 0.4880 r:0.7128
Current avg r:0.5997 Best avg r: 0.6273
02:50:26,779 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:56,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:27,72 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2219
en_de Dev loss: 0.8861 r:0.2344
en_zh Dev loss: 0.8052 r:0.4613
ro_en Dev loss: 0.3821 r:0.8123
et_en Dev loss: 0.4804 r:0.6577
si_en Dev loss: 0.9135 r:0.5636
ne_en Dev loss: 0.5159 r:0.7330
ru_en Dev loss: 0.5005 r:0.7184
Current avg r:0.5972 Best avg r: 0.6273
02:57:57,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:59:27,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:57,677 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2377
en_de Dev loss: 0.8811 r:0.2330
en_zh Dev loss: 0.8120 r:0.4585
ro_en Dev loss: 0.4007 r:0.8105
et_en Dev loss: 0.4619 r:0.6630
si_en Dev loss: 0.9356 r:0.5651
ne_en Dev loss: 0.5828 r:0.7363
ru_en Dev loss: 0.5253 r:0.7097
Current avg r:0.5966 Best avg r: 0.6273
03:05:30,202 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:07:00,164 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:30,235 root INFO Epoch 8 Global steps: 68600 Train loss: 0.2307
en_de Dev loss: 0.8516 r:0.2383
en_zh Dev loss: 0.7577 r:0.4628
ro_en Dev loss: 0.3412 r:0.8174
et_en Dev loss: 0.4667 r:0.6747
si_en Dev loss: 0.7933 r:0.5778
ne_en Dev loss: 0.4849 r:0.7406
ru_en Dev loss: 0.4506 r:0.7257
Current avg r:0.6053 Best avg r: 0.6273
03:13:01,55 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:30,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:00,836 root INFO Epoch 8 Global steps: 69300 Train loss: 0.2137
en_de Dev loss: 0.8535 r:0.2495
en_zh Dev loss: 0.8207 r:0.4498
ro_en Dev loss: 0.3806 r:0.8147
et_en Dev loss: 0.4882 r:0.6678
si_en Dev loss: 0.8724 r:0.5712
ne_en Dev loss: 0.4802 r:0.7369
ru_en Dev loss: 0.4560 r:0.7281
Current avg r:0.6026 Best avg r: 0.6273
03:20:29,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:59,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:30,75 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2295
en_de Dev loss: 0.8643 r:0.2502
en_zh Dev loss: 0.7640 r:0.4760
ro_en Dev loss: 0.3589 r:0.8182
et_en Dev loss: 0.4587 r:0.6792
si_en Dev loss: 0.7751 r:0.5837
ne_en Dev loss: 0.4399 r:0.7444
ru_en Dev loss: 0.4465 r:0.7397
Current avg r:0.6130 Best avg r: 0.6273
03:28:00,216 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:30,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:59,939 root INFO Epoch 8 Global steps: 70700 Train loss: 0.2338
en_de Dev loss: 0.8949 r:0.2293
en_zh Dev loss: 0.8341 r:0.4581
ro_en Dev loss: 0.4330 r:0.8033
et_en Dev loss: 0.4712 r:0.6535
si_en Dev loss: 0.8895 r:0.5664
ne_en Dev loss: 0.5794 r:0.7392
ru_en Dev loss: 0.4909 r:0.7242
Current avg r:0.5963 Best avg r: 0.6273
03:35:30,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:00,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:30,303 root INFO Epoch 8 Global steps: 71400 Train loss: 0.2235
en_de Dev loss: 0.8858 r:0.2450
en_zh Dev loss: 0.8216 r:0.4622
ro_en Dev loss: 0.3916 r:0.8114
et_en Dev loss: 0.4725 r:0.6643
si_en Dev loss: 0.8651 r:0.5765
ne_en Dev loss: 0.5242 r:0.7382
ru_en Dev loss: 0.4938 r:0.7227
Current avg r:0.6029 Best avg r: 0.6273
03:43:01,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:32,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:46:02,516 root INFO Epoch 9 Global steps: 72100 Train loss: 0.2130
en_de Dev loss: 0.8685 r:0.2471
en_zh Dev loss: 0.7852 r:0.4517
ro_en Dev loss: 0.3757 r:0.8116
et_en Dev loss: 0.4799 r:0.6616
si_en Dev loss: 0.8380 r:0.5769
ne_en Dev loss: 0.4866 r:0.7368
ru_en Dev loss: 0.4863 r:0.7142
Current avg r:0.6000 Best avg r: 0.6273
03:50:32,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:52:02,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:53:32,580 root INFO Epoch 9 Global steps: 72800 Train loss: 0.2098
en_de Dev loss: 0.8795 r:0.2235
en_zh Dev loss: 0.7710 r:0.4495
ro_en Dev loss: 0.3797 r:0.8101
et_en Dev loss: 0.4771 r:0.6594
si_en Dev loss: 0.8413 r:0.5748
ne_en Dev loss: 0.4966 r:0.7349
ru_en Dev loss: 0.4593 r:0.7259
Current avg r:0.5969 Best avg r: 0.6273
03:58:05,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:59:35,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:01:05,515 root INFO Epoch 9 Global steps: 73500 Train loss: 0.2190
en_de Dev loss: 0.8812 r:0.2225
en_zh Dev loss: 0.7725 r:0.4554
ro_en Dev loss: 0.3755 r:0.8139
et_en Dev loss: 0.4875 r:0.6707
si_en Dev loss: 0.8192 r:0.5768
ne_en Dev loss: 0.4643 r:0.7333
ru_en Dev loss: 0.4574 r:0.7317
Current avg r:0.6006 Best avg r: 0.6273
04:05:38,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:07:08,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:38,573 root INFO Epoch 9 Global steps: 74200 Train loss: 0.2040
en_de Dev loss: 0.8922 r:0.2044
en_zh Dev loss: 0.8103 r:0.4581
ro_en Dev loss: 0.3530 r:0.8161
et_en Dev loss: 0.4704 r:0.6624
si_en Dev loss: 0.8333 r:0.5750
ne_en Dev loss: 0.5486 r:0.7282
ru_en Dev loss: 0.4861 r:0.7263
Current avg r:0.5958 Best avg r: 0.6273
04:13:07,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:37,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:16:07,283 root INFO Epoch 9 Global steps: 74900 Train loss: 0.2095
en_de Dev loss: 0.8832 r:0.2069
en_zh Dev loss: 0.8183 r:0.4603
ro_en Dev loss: 0.3862 r:0.8112
et_en Dev loss: 0.5227 r:0.6615
si_en Dev loss: 0.8949 r:0.5591
ne_en Dev loss: 0.5207 r:0.7282
ru_en Dev loss: 0.4963 r:0.7154
Current avg r:0.5918 Best avg r: 0.6273
04:20:36,747 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:22:06,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:36,540 root INFO Epoch 9 Global steps: 75600 Train loss: 0.2098
en_de Dev loss: 0.8952 r:0.2203
en_zh Dev loss: 0.8089 r:0.4673
ro_en Dev loss: 0.3890 r:0.8125
et_en Dev loss: 0.4703 r:0.6641
si_en Dev loss: 0.8975 r:0.5647
ne_en Dev loss: 0.5506 r:0.7320
ru_en Dev loss: 0.4941 r:0.7384
Current avg r:0.5999 Best avg r: 0.6273
04:28:07,776 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:37,969 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:08,119 root INFO Epoch 9 Global steps: 76300 Train loss: 0.2124
en_de Dev loss: 0.9028 r:0.2214
en_zh Dev loss: 0.8197 r:0.4700
ro_en Dev loss: 0.3621 r:0.8163
et_en Dev loss: 0.5102 r:0.6700
si_en Dev loss: 0.8308 r:0.5646
ne_en Dev loss: 0.4553 r:0.7325
ru_en Dev loss: 0.4404 r:0.7455
Current avg r:0.6029 Best avg r: 0.6273
04:35:38,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:37:08,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:38,988 root INFO Epoch 9 Global steps: 77000 Train loss: 0.2078
en_de Dev loss: 0.8833 r:0.2405
en_zh Dev loss: 0.7625 r:0.4805
ro_en Dev loss: 0.3839 r:0.8095
et_en Dev loss: 0.4759 r:0.6637
si_en Dev loss: 0.8716 r:0.5560
ne_en Dev loss: 0.4963 r:0.7378
ru_en Dev loss: 0.4806 r:0.7247
Current avg r:0.6018 Best avg r: 0.6273
04:43:10,3 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:39,888 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:46:09,747 root INFO Epoch 9 Global steps: 77700 Train loss: 0.2077
en_de Dev loss: 0.9022 r:0.2179
en_zh Dev loss: 0.7519 r:0.4739
ro_en Dev loss: 0.3471 r:0.8136
et_en Dev loss: 0.4841 r:0.6708
si_en Dev loss: 0.8034 r:0.5673
ne_en Dev loss: 0.4516 r:0.7268
ru_en Dev loss: 0.4355 r:0.7332
Current avg r:0.6005 Best avg r: 0.6273
04:50:42,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:52:12,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:41,955 root INFO Epoch 9 Global steps: 78400 Train loss: 0.2075
en_de Dev loss: 0.8854 r:0.2040
en_zh Dev loss: 0.7544 r:0.4600
ro_en Dev loss: 0.3605 r:0.8118
et_en Dev loss: 0.4619 r:0.6638
si_en Dev loss: 0.8133 r:0.5650
ne_en Dev loss: 0.4823 r:0.7305
ru_en Dev loss: 0.4479 r:0.7291
Current avg r:0.5949 Best avg r: 0.6273
04:58:12,422 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:59:42,275 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:01:12,154 root INFO Epoch 9 Global steps: 79100 Train loss: 0.2064
en_de Dev loss: 0.8808 r:0.2161
en_zh Dev loss: 0.7664 r:0.4646
ro_en Dev loss: 0.3670 r:0.8147
et_en Dev loss: 0.4683 r:0.6666
si_en Dev loss: 0.8356 r:0.5640
ne_en Dev loss: 0.4696 r:0.7295
ru_en Dev loss: 0.4441 r:0.7354
Current avg r:0.5987 Best avg r: 0.6273
05:05:43,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:07:13,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:08:44,62 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1792
en_de Dev loss: 0.8856 r:0.2059
en_zh Dev loss: 0.7646 r:0.4659
ro_en Dev loss: 0.3937 r:0.8099
et_en Dev loss: 0.4581 r:0.6589
si_en Dev loss: 0.8421 r:0.5612
ne_en Dev loss: 0.5604 r:0.7282
ru_en Dev loss: 0.4825 r:0.7239
Current avg r:0.5934 Best avg r: 0.6273
05:13:13,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:14:43,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:16:13,269 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1952
en_de Dev loss: 0.9190 r:0.1868
en_zh Dev loss: 0.7955 r:0.4688
ro_en Dev loss: 0.3887 r:0.8131
et_en Dev loss: 0.5078 r:0.6689
si_en Dev loss: 0.8450 r:0.5602
ne_en Dev loss: 0.5164 r:0.7321
ru_en Dev loss: 0.4690 r:0.7289
Current avg r:0.5941 Best avg r: 0.6273
05:20:43,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:22:13,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:23:42,870 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1860
en_de Dev loss: 0.9287 r:0.1906
en_zh Dev loss: 0.8811 r:0.4697
ro_en Dev loss: 0.4020 r:0.8155
et_en Dev loss: 0.4725 r:0.6599
si_en Dev loss: 0.9799 r:0.5603
ne_en Dev loss: 0.6506 r:0.7294
ru_en Dev loss: 0.5250 r:0.7250
Current avg r:0.5929 Best avg r: 0.6273
05:28:13,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:29:43,475 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:13,334 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1834
en_de Dev loss: 0.8968 r:0.2033
en_zh Dev loss: 0.7751 r:0.4728
ro_en Dev loss: 0.3608 r:0.8156
et_en Dev loss: 0.4872 r:0.6598
si_en Dev loss: 0.8756 r:0.5564
ne_en Dev loss: 0.5222 r:0.7278
ru_en Dev loss: 0.4803 r:0.7164
Current avg r:0.5932 Best avg r: 0.6273
05:35:42,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:12,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:42,286 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1906
en_de Dev loss: 0.8927 r:0.2183
en_zh Dev loss: 0.8071 r:0.4655
ro_en Dev loss: 0.3840 r:0.8145
et_en Dev loss: 0.4643 r:0.6641
si_en Dev loss: 0.9698 r:0.5537
ne_en Dev loss: 0.5611 r:0.7301
ru_en Dev loss: 0.4689 r:0.7286
Current avg r:0.5964 Best avg r: 0.6273
05:43:11,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:41,149 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:10,974 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1876
en_de Dev loss: 0.8884 r:0.2215
en_zh Dev loss: 0.7660 r:0.4689
ro_en Dev loss: 0.3555 r:0.8169
et_en Dev loss: 0.4982 r:0.6650
si_en Dev loss: 0.8328 r:0.5582
ne_en Dev loss: 0.4698 r:0.7290
ru_en Dev loss: 0.4190 r:0.7443
Current avg r:0.6005 Best avg r: 0.6273
05:50:40,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:10,126 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:39,984 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1882
en_de Dev loss: 0.8779 r:0.2266
en_zh Dev loss: 0.7699 r:0.4710
ro_en Dev loss: 0.3594 r:0.8130
et_en Dev loss: 0.4683 r:0.6662
si_en Dev loss: 0.8590 r:0.5572
ne_en Dev loss: 0.4745 r:0.7299
ru_en Dev loss: 0.4659 r:0.7267
Current avg r:0.5987 Best avg r: 0.6273
05:58:09,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:40,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:01:10,220 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1805
en_de Dev loss: 0.8819 r:0.2235
en_zh Dev loss: 0.7690 r:0.4684
ro_en Dev loss: 0.3725 r:0.8158
et_en Dev loss: 0.4571 r:0.6709
si_en Dev loss: 0.9194 r:0.5538
ne_en Dev loss: 0.4959 r:0.7317
ru_en Dev loss: 0.4843 r:0.7115
Current avg r:0.5965 Best avg r: 0.6273
06:05:42,315 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:12,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:42,507 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1835
en_de Dev loss: 0.8977 r:0.2335
en_zh Dev loss: 0.8652 r:0.4449
ro_en Dev loss: 0.4042 r:0.8093
et_en Dev loss: 0.5127 r:0.6694
si_en Dev loss: 0.8620 r:0.5623
ne_en Dev loss: 0.5759 r:0.7174
ru_en Dev loss: 0.4980 r:0.7195
Current avg r:0.5938 Best avg r: 0.6273
06:13:12,778 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:42,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:16:13,221 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1827
en_de Dev loss: 0.8795 r:0.1988
en_zh Dev loss: 0.7933 r:0.4506
ro_en Dev loss: 0.3537 r:0.8142
et_en Dev loss: 0.4546 r:0.6662
si_en Dev loss: 0.8234 r:0.5625
ne_en Dev loss: 0.5278 r:0.7269
ru_en Dev loss: 0.4895 r:0.7143
Current avg r:0.5905 Best avg r: 0.6273
06:20:45,953 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:22:16,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:46,445 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1884
en_de Dev loss: 0.8958 r:0.1986
en_zh Dev loss: 0.8126 r:0.4529
ro_en Dev loss: 0.3664 r:0.8111
et_en Dev loss: 0.4808 r:0.6611
si_en Dev loss: 0.8550 r:0.5554
ne_en Dev loss: 0.5692 r:0.7201
ru_en Dev loss: 0.4744 r:0.7205
Current avg r:0.5885 Best avg r: 0.6273
06:28:19,438 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:49,315 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:19,201 root INFO Epoch 10 Global steps: 87500 Train loss: 0.1886
en_de Dev loss: 0.9117 r:0.1993
en_zh Dev loss: 0.8228 r:0.4516
ro_en Dev loss: 0.3984 r:0.8128
et_en Dev loss: 0.4797 r:0.6530
si_en Dev loss: 0.9490 r:0.5498
ne_en Dev loss: 0.5557 r:0.7264
ru_en Dev loss: 0.5138 r:0.7261
Current avg r:0.5884 Best avg r: 0.6273
06:35:50,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:20,240 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:38:50,398 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1730
en_de Dev loss: 0.8883 r:0.2164
en_zh Dev loss: 0.7722 r:0.4738
ro_en Dev loss: 0.3785 r:0.8133
et_en Dev loss: 0.4766 r:0.6587
si_en Dev loss: 0.8916 r:0.5571
ne_en Dev loss: 0.5907 r:0.7256
ru_en Dev loss: 0.4345 r:0.7487
Current avg r:0.5991 Best avg r: 0.6273
06:43:20,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:44:50,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:46:20,951 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1665
en_de Dev loss: 0.9339 r:0.2019
en_zh Dev loss: 0.8657 r:0.4503
ro_en Dev loss: 0.4189 r:0.8104
et_en Dev loss: 0.5011 r:0.6532
si_en Dev loss: 0.8661 r:0.5594
ne_en Dev loss: 0.5425 r:0.7269
ru_en Dev loss: 0.5163 r:0.7279
Current avg r:0.5900 Best avg r: 0.6273
06:50:50,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:20,479 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:53:50,619 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1732
en_de Dev loss: 0.9108 r:0.1993
en_zh Dev loss: 0.8780 r:0.4519
ro_en Dev loss: 0.4120 r:0.8138
et_en Dev loss: 0.5067 r:0.6418
si_en Dev loss: 1.1317 r:0.5306
ne_en Dev loss: 0.6499 r:0.7171
ru_en Dev loss: 0.5349 r:0.7243
Current avg r:0.5827 Best avg r: 0.6273
06:58:21,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:59:51,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:21,470 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1766
en_de Dev loss: 0.8953 r:0.2088
en_zh Dev loss: 0.8495 r:0.4565
ro_en Dev loss: 0.3810 r:0.8162
et_en Dev loss: 0.5069 r:0.6526
si_en Dev loss: 0.9369 r:0.5649
ne_en Dev loss: 0.5733 r:0.7255
ru_en Dev loss: 0.4718 r:0.7318
Current avg r:0.5938 Best avg r: 0.6273
07:05:53,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:07:23,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:53,993 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1664
en_de Dev loss: 0.8788 r:0.2008
en_zh Dev loss: 0.7695 r:0.4619
ro_en Dev loss: 0.3462 r:0.8107
et_en Dev loss: 0.4572 r:0.6561
si_en Dev loss: 0.8356 r:0.5636
ne_en Dev loss: 0.5396 r:0.7264
ru_en Dev loss: 0.4389 r:0.7246
Current avg r:0.5920 Best avg r: 0.6273
07:13:26,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:14:55,912 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:16:26,31 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1726
en_de Dev loss: 0.9143 r:0.2207
en_zh Dev loss: 0.8552 r:0.4582
ro_en Dev loss: 0.4028 r:0.8095
et_en Dev loss: 0.4926 r:0.6533
si_en Dev loss: 0.8904 r:0.5604
ne_en Dev loss: 0.5398 r:0.7317
ru_en Dev loss: 0.4817 r:0.7247
Current avg r:0.5941 Best avg r: 0.6273
07:20:55,744 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:22:25,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:23:55,502 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1670
en_de Dev loss: 0.8942 r:0.2266
en_zh Dev loss: 0.8672 r:0.4570
ro_en Dev loss: 0.4000 r:0.8082
et_en Dev loss: 0.5065 r:0.6541
si_en Dev loss: 0.9319 r:0.5588
ne_en Dev loss: 0.5578 r:0.7240
ru_en Dev loss: 0.5119 r:0.7120
Current avg r:0.5915 Best avg r: 0.6273
07:28:24,939 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:29:54,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:31:25,112 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1746
en_de Dev loss: 0.9181 r:0.2421
en_zh Dev loss: 0.8411 r:0.4616
ro_en Dev loss: 0.4329 r:0.8023
et_en Dev loss: 0.5149 r:0.6470
si_en Dev loss: 0.9938 r:0.5466
ne_en Dev loss: 0.6564 r:0.7185
ru_en Dev loss: 0.5974 r:0.6955
Current avg r:0.5877 Best avg r: 0.6273
07:35:55,185 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:37:25,83 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:38:54,950 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1680
en_de Dev loss: 0.8872 r:0.2300
en_zh Dev loss: 0.8456 r:0.4514
ro_en Dev loss: 0.4228 r:0.7991
et_en Dev loss: 0.5127 r:0.6321
si_en Dev loss: 1.0656 r:0.5291
ne_en Dev loss: 0.6613 r:0.7162
ru_en Dev loss: 0.5550 r:0.6968
Current avg r:0.5792 Best avg r: 0.6273
07:43:24,680 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:44:54,841 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:46:25,11 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1645
en_de Dev loss: 0.9170 r:0.2036
en_zh Dev loss: 0.8515 r:0.4662
ro_en Dev loss: 0.4048 r:0.8095
et_en Dev loss: 0.5073 r:0.6484
si_en Dev loss: 0.8987 r:0.5493
ne_en Dev loss: 0.5659 r:0.7208
ru_en Dev loss: 0.5122 r:0.7188
Current avg r:0.5881 Best avg r: 0.6273
07:50:56,5 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:52:26,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:53:56,341 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1701
en_de Dev loss: 0.9252 r:0.2102
en_zh Dev loss: 0.7952 r:0.4800
ro_en Dev loss: 0.3689 r:0.8092
et_en Dev loss: 0.4936 r:0.6654
si_en Dev loss: 0.8294 r:0.5571
ne_en Dev loss: 0.5044 r:0.7221
ru_en Dev loss: 0.4334 r:0.7464
Current avg r:0.5986 Best avg r: 0.6273
07:58:32,373 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:00:02,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:01:33,11 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1594
en_de Dev loss: 0.8787 r:0.2251
en_zh Dev loss: 0.8056 r:0.4683
ro_en Dev loss: 0.3994 r:0.8082
et_en Dev loss: 0.4924 r:0.6520
si_en Dev loss: 0.9604 r:0.5464
ne_en Dev loss: 0.5823 r:0.7252
ru_en Dev loss: 0.4855 r:0.7264
Current avg r:0.5931 Best avg r: 0.6273
08:06:02,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:07:32,483 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:09:02,773 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1510
en_de Dev loss: 0.8728 r:0.2295
en_zh Dev loss: 0.8075 r:0.4652
ro_en Dev loss: 0.3844 r:0.8109
et_en Dev loss: 0.4698 r:0.6591
si_en Dev loss: 0.8934 r:0.5575
ne_en Dev loss: 0.5690 r:0.7266
ru_en Dev loss: 0.4595 r:0.7385
Current avg r:0.5982 Best avg r: 0.6273
08:13:32,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:02,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:32,230 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1518
en_de Dev loss: 0.8912 r:0.2235
en_zh Dev loss: 0.8442 r:0.4554
ro_en Dev loss: 0.3863 r:0.8094
et_en Dev loss: 0.4907 r:0.6508
si_en Dev loss: 0.8906 r:0.5506
ne_en Dev loss: 0.5689 r:0.7209
ru_en Dev loss: 0.4392 r:0.7453
Current avg r:0.5937 Best avg r: 0.6273
08:21:02,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:22:45,485 root INFO 
id:ru_en cur r: 0.7580 best r: 0.7580
08:22:45,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:24:15,775 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1582
en_de Dev loss: 0.8903 r:0.2147
en_zh Dev loss: 0.7980 r:0.4619
ro_en Dev loss: 0.3707 r:0.8117
et_en Dev loss: 0.5242 r:0.6566
si_en Dev loss: 0.8798 r:0.5440
ne_en Dev loss: 0.5396 r:0.7222
ru_en Dev loss: 0.4128 r:0.7519
Current avg r:0.5947 Best avg r: 0.6273
08:28:47,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:30:18,222 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:31:48,456 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1496
en_de Dev loss: 0.9498 r:0.2009
en_zh Dev loss: 0.8536 r:0.4649
ro_en Dev loss: 0.4013 r:0.8124
et_en Dev loss: 0.5066 r:0.6590
si_en Dev loss: 0.9294 r:0.5531
ne_en Dev loss: 0.5513 r:0.7301
ru_en Dev loss: 0.4930 r:0.7401
Current avg r:0.5944 Best avg r: 0.6273
08:36:17,576 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:37:47,488 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:39:17,453 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1529
en_de Dev loss: 0.9087 r:0.2049
en_zh Dev loss: 0.8262 r:0.4569
ro_en Dev loss: 0.3854 r:0.8119
et_en Dev loss: 0.4689 r:0.6580
si_en Dev loss: 0.9364 r:0.5485
ne_en Dev loss: 0.6021 r:0.7294
ru_en Dev loss: 0.4812 r:0.7240
Current avg r:0.5905 Best avg r: 0.6273
08:43:46,529 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:45:16,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:46:46,892 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1583
en_de Dev loss: 0.9252 r:0.1866
en_zh Dev loss: 0.8107 r:0.4675
ro_en Dev loss: 0.3684 r:0.8120
et_en Dev loss: 0.4751 r:0.6601
si_en Dev loss: 0.8920 r:0.5501
ne_en Dev loss: 0.5675 r:0.7264
ru_en Dev loss: 0.4867 r:0.7227
Current avg r:0.5894 Best avg r: 0.6273
08:51:16,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:52:46,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:16,628 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1520
en_de Dev loss: 0.9149 r:0.1868
en_zh Dev loss: 0.7643 r:0.4760
ro_en Dev loss: 0.3541 r:0.8120
et_en Dev loss: 0.4671 r:0.6596
si_en Dev loss: 0.8834 r:0.5504
ne_en Dev loss: 0.5171 r:0.7297
ru_en Dev loss: 0.4302 r:0.7432
Current avg r:0.5940 Best avg r: 0.6273
08:58:48,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:00:18,144 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:01:47,987 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1529
en_de Dev loss: 0.9268 r:0.1729
en_zh Dev loss: 0.7953 r:0.4702
ro_en Dev loss: 0.3690 r:0.8115
et_en Dev loss: 0.4776 r:0.6551
si_en Dev loss: 0.8899 r:0.5473
ne_en Dev loss: 0.5905 r:0.7228
ru_en Dev loss: 0.4719 r:0.7293
Current avg r:0.5870 Best avg r: 0.6273
09:06:17,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:07:47,91 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:17,1 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1565
en_de Dev loss: 0.9095 r:0.1853
en_zh Dev loss: 0.8239 r:0.4656
ro_en Dev loss: 0.3776 r:0.8119
et_en Dev loss: 0.4637 r:0.6591
si_en Dev loss: 0.9611 r:0.5491
ne_en Dev loss: 0.6327 r:0.7289
ru_en Dev loss: 0.4492 r:0.7432
Current avg r:0.5919 Best avg r: 0.6273
09:13:46,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:16,64 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:45,942 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1507
en_de Dev loss: 0.9270 r:0.1913
en_zh Dev loss: 0.8271 r:0.4696
ro_en Dev loss: 0.3812 r:0.8158
et_en Dev loss: 0.4759 r:0.6592
si_en Dev loss: 0.9762 r:0.5527
ne_en Dev loss: 0.5739 r:0.7341
ru_en Dev loss: 0.5043 r:0.7363
Current avg r:0.5941 Best avg r: 0.6273
09:21:16,233 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:22:46,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:24:16,551 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1459
en_de Dev loss: 0.9416 r:0.1950
en_zh Dev loss: 0.7998 r:0.4688
ro_en Dev loss: 0.3793 r:0.8140
et_en Dev loss: 0.4859 r:0.6566
si_en Dev loss: 0.9585 r:0.5465
ne_en Dev loss: 0.5962 r:0.7313
ru_en Dev loss: 0.4660 r:0.7358
Current avg r:0.5926 Best avg r: 0.6273
09:28:47,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:17,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:31:47,896 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1418
en_de Dev loss: 0.9107 r:0.1968
en_zh Dev loss: 0.7956 r:0.4645
ro_en Dev loss: 0.3559 r:0.8148
et_en Dev loss: 0.4571 r:0.6559
si_en Dev loss: 0.9191 r:0.5474
ne_en Dev loss: 0.5364 r:0.7311
ru_en Dev loss: 0.4501 r:0.7367
Current avg r:0.5925 Best avg r: 0.6273
09:36:17,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:37:47,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:39:17,560 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1346
en_de Dev loss: 0.9143 r:0.1889
en_zh Dev loss: 0.8215 r:0.4573
ro_en Dev loss: 0.3773 r:0.8144
et_en Dev loss: 0.4812 r:0.6537
si_en Dev loss: 0.9489 r:0.5449
ne_en Dev loss: 0.5909 r:0.7296
ru_en Dev loss: 0.4582 r:0.7361
Current avg r:0.5893 Best avg r: 0.6273
09:43:46,709 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:45:16,563 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:46:46,578 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1466
en_de Dev loss: 0.9003 r:0.2171
en_zh Dev loss: 0.8219 r:0.4551
ro_en Dev loss: 0.3709 r:0.8106
et_en Dev loss: 0.4711 r:0.6594
si_en Dev loss: 0.8661 r:0.5480
ne_en Dev loss: 0.5558 r:0.7292
ru_en Dev loss: 0.4682 r:0.7311
Current avg r:0.5929 Best avg r: 0.6273
09:51:16,417 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:52:46,565 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:54:16,714 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1470
en_de Dev loss: 0.9007 r:0.2193
en_zh Dev loss: 0.8137 r:0.4680
ro_en Dev loss: 0.3774 r:0.8126
et_en Dev loss: 0.4911 r:0.6547
si_en Dev loss: 0.9732 r:0.5428
ne_en Dev loss: 0.6167 r:0.7210
ru_en Dev loss: 0.4711 r:0.7353
Current avg r:0.5934 Best avg r: 0.6273
09:58:45,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:00:15,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:01:46,178 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1443
en_de Dev loss: 0.9324 r:0.1830
en_zh Dev loss: 0.8308 r:0.4737
ro_en Dev loss: 0.4181 r:0.8105
et_en Dev loss: 0.5087 r:0.6463
si_en Dev loss: 1.0153 r:0.5427
ne_en Dev loss: 0.5940 r:0.7186
ru_en Dev loss: 0.5224 r:0.7283
Current avg r:0.5862 Best avg r: 0.6273
10:06:17,285 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:07:47,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:17,335 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1303
en_de Dev loss: 0.9563 r:0.1769
en_zh Dev loss: 0.8453 r:0.4706
ro_en Dev loss: 0.4087 r:0.8096
et_en Dev loss: 0.4936 r:0.6533
si_en Dev loss: 0.9717 r:0.5419
ne_en Dev loss: 0.5904 r:0.7210
ru_en Dev loss: 0.5123 r:0.7249
Current avg r:0.5855 Best avg r: 0.6273
10:13:47,437 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:15:17,449 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:16:47,624 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1399
en_de Dev loss: 0.9572 r:0.1912
en_zh Dev loss: 0.8730 r:0.4553
ro_en Dev loss: 0.3998 r:0.8095
et_en Dev loss: 0.4835 r:0.6543
si_en Dev loss: 0.8861 r:0.5485
ne_en Dev loss: 0.6348 r:0.7213
ru_en Dev loss: 0.5395 r:0.7143
Current avg r:0.5849 Best avg r: 0.6273
10:21:16,784 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:22:46,692 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:24:16,693 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1362
en_de Dev loss: 0.9302 r:0.1874
en_zh Dev loss: 0.8137 r:0.4725
ro_en Dev loss: 0.3804 r:0.8109
et_en Dev loss: 0.4912 r:0.6531
si_en Dev loss: 0.9274 r:0.5453
ne_en Dev loss: 0.5890 r:0.7195
ru_en Dev loss: 0.4352 r:0.7414
Current avg r:0.5900 Best avg r: 0.6273
10:28:45,760 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:30:15,634 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:31:45,629 root INFO Epoch 13 Global steps: 109900 Train loss: 0.1302
en_de Dev loss: 0.9071 r:0.1871
en_zh Dev loss: 0.8190 r:0.4696
ro_en Dev loss: 0.3802 r:0.8109
et_en Dev loss: 0.4888 r:0.6492
si_en Dev loss: 0.9967 r:0.5429
ne_en Dev loss: 0.6265 r:0.7255
ru_en Dev loss: 0.4607 r:0.7361
Current avg r:0.5888 Best avg r: 0.6273
