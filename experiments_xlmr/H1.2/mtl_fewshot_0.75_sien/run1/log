14:43:35,159 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:43:48,28 root INFO 
id:en_de cur r: 0.0941 best r: 0.0941
14:44:00,871 root INFO 
id:en_zh cur r: 0.2526 best r: 0.2526
14:44:13,743 root INFO 
id:ro_en cur r: 0.6326 best r: 0.6326
14:44:26,617 root INFO 
id:et_en cur r: 0.4871 best r: 0.4871
14:44:52,374 root INFO 
id:si_en cur r: 0.4563 best r: 0.4563
14:45:05,260 root INFO 
id:ne_en cur r: 0.3442 best r: 0.3442
14:45:18,81 root INFO 
id:ru_en cur r: 0.5414 best r: 0.5414
14:45:18,82 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:46:47,999 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
14:46:48,6 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:46:48,10 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:46:48,15 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
14:46:48,20 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
14:46:48,25 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:46:48,31 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:47:00,899 root INFO Epoch 0 Global steps: 700 Train loss: 0.8610
en_de Dev loss: 0.9396 r:0.1111
en_zh Dev loss: 0.7996 r:0.2606
ro_en Dev loss: 0.7587 r:0.6436
et_en Dev loss: 0.6010 r:0.5363
si_en Dev loss: 0.9130 r:0.4816
ne_en Dev loss: 0.6482 r:0.6241
ru_en Dev loss: 0.7084 r:0.5663
Current avg r:0.4605 Best avg r: 0.4605
14:51:28,970 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:51:41,844 root INFO 
id:en_de cur r: 0.1008 best r: 0.1008
14:51:54,677 root INFO 
id:en_zh cur r: 0.2996 best r: 0.2996
14:52:07,545 root INFO 
id:ro_en cur r: 0.6852 best r: 0.6852
14:52:20,424 root INFO 
id:et_en cur r: 0.5983 best r: 0.5983
14:52:46,179 root INFO 
id:si_en cur r: 0.4703 best r: 0.4703
14:52:59,56 root INFO 
id:ne_en cur r: 0.6412 best r: 0.6412
14:53:11,878 root INFO 
id:ru_en cur r: 0.6486 best r: 0.6486
14:53:11,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:54:41,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
14:54:41,826 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:54:41,831 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:54:41,837 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
14:54:41,842 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
14:54:41,847 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:54:41,851 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:54:54,718 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7985
en_de Dev loss: 0.9106 r:0.1374
en_zh Dev loss: 0.7489 r:0.3037
ro_en Dev loss: 0.5554 r:0.6730
et_en Dev loss: 0.4738 r:0.5947
si_en Dev loss: 0.6693 r:0.4961
ne_en Dev loss: 0.4697 r:0.6561
ru_en Dev loss: 0.5172 r:0.6714
Current avg r:0.5046 Best avg r: 0.5046
14:59:22,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:59:35,515 root INFO 
id:en_de cur r: 0.1148 best r: 0.1148
14:59:48,344 root INFO 
id:en_zh cur r: 0.3334 best r: 0.3334
15:00:01,215 root INFO 
id:ro_en cur r: 0.6898 best r: 0.6898
15:00:14,82 root INFO 
id:et_en cur r: 0.6217 best r: 0.6217
15:00:39,829 root INFO 
id:si_en cur r: 0.5084 best r: 0.5084
15:00:52,716 root INFO 
id:ne_en cur r: 0.6650 best r: 0.6650
15:01:05,537 root INFO 
id:ru_en cur r: 0.7011 best r: 0.7011
15:01:05,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:02:35,416 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:02:35,422 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:02:35,427 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:02:35,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:02:35,436 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:02:35,441 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:02:35,446 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:02:48,271 root INFO Epoch 0 Global steps: 2100 Train loss: 0.6821
en_de Dev loss: 0.9617 r:0.1248
en_zh Dev loss: 0.8083 r:0.3137
ro_en Dev loss: 0.5540 r:0.6930
et_en Dev loss: 0.4360 r:0.6574
si_en Dev loss: 0.7252 r:0.5386
ne_en Dev loss: 0.4538 r:0.6836
ru_en Dev loss: 0.4986 r:0.7141
Current avg r:0.5322 Best avg r: 0.5322
15:07:15,385 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:07:53,814 root INFO 
id:ro_en cur r: 0.7368 best r: 0.7368
15:08:06,639 root INFO 
id:et_en cur r: 0.6596 best r: 0.6596
15:08:32,304 root INFO 
id:si_en cur r: 0.5496 best r: 0.5496
15:08:45,132 root INFO 
id:ne_en cur r: 0.6913 best r: 0.6913
15:08:57,908 root INFO 
id:ru_en cur r: 0.7225 best r: 0.7225
15:08:57,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:27,523 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:10:27,531 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:10:27,539 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:10:27,543 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:10:27,548 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:10:27,552 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:10:27,557 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:10:40,380 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6748
en_de Dev loss: 1.0046 r:0.1541
en_zh Dev loss: 0.8328 r:0.3287
ro_en Dev loss: 0.5846 r:0.7428
et_en Dev loss: 0.4886 r:0.6697
si_en Dev loss: 0.7530 r:0.5645
ne_en Dev loss: 0.6492 r:0.6908
ru_en Dev loss: 0.5785 r:0.7222
Current avg r:0.5533 Best avg r: 0.5533
15:15:07,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:15:20,510 root INFO 
id:en_de cur r: 0.1736 best r: 0.1736
15:15:33,320 root INFO 
id:en_zh cur r: 0.3731 best r: 0.3731
15:15:46,171 root INFO 
id:ro_en cur r: 0.7483 best r: 0.7483
15:15:59,23 root INFO 
id:et_en cur r: 0.6886 best r: 0.6886
15:16:24,716 root INFO 
id:si_en cur r: 0.5705 best r: 0.5705
15:16:37,579 root INFO 
id:ne_en cur r: 0.7292 best r: 0.7292
15:16:50,379 root INFO 
id:ru_en cur r: 0.7360 best r: 0.7360
15:16:50,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:20,146 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:18:20,152 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:18:20,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:18:20,161 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:18:20,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:18:20,170 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:18:20,174 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:18:33,30 root INFO Epoch 0 Global steps: 3500 Train loss: 0.5788
en_de Dev loss: 0.9133 r:0.1833
en_zh Dev loss: 0.7380 r:0.3690
ro_en Dev loss: 0.4391 r:0.7496
et_en Dev loss: 0.3705 r:0.6972
si_en Dev loss: 0.6118 r:0.5841
ne_en Dev loss: 0.4144 r:0.7305
ru_en Dev loss: 0.4420 r:0.7387
Current avg r:0.5789 Best avg r: 0.5789
15:23:01,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:14,423 root INFO 
id:en_de cur r: 0.1892 best r: 0.1892
15:23:27,293 root INFO 
id:en_zh cur r: 0.3930 best r: 0.3930
15:23:40,190 root INFO 
id:ro_en cur r: 0.7547 best r: 0.7547
15:23:53,107 root INFO 
id:et_en cur r: 0.6957 best r: 0.6957
15:24:18,931 root INFO 
id:si_en cur r: 0.5770 best r: 0.5770
15:24:31,840 root INFO 
id:ne_en cur r: 0.7294 best r: 0.7294
15:24:44,688 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:14,855 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:26:14,864 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:26:14,869 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:26:14,873 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:26:14,879 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:26:14,883 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:26:14,888 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:26:27,783 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6197
en_de Dev loss: 0.8804 r:0.1938
en_zh Dev loss: 0.7011 r:0.3908
ro_en Dev loss: 0.4020 r:0.7552
et_en Dev loss: 0.3527 r:0.7080
si_en Dev loss: 0.6072 r:0.5934
ne_en Dev loss: 0.4142 r:0.7264
ru_en Dev loss: 0.4139 r:0.7404
Current avg r:0.5869 Best avg r: 0.5869
15:30:56,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:21,758 root INFO 
id:en_zh cur r: 0.4145 best r: 0.4145
15:31:34,646 root INFO 
id:ro_en cur r: 0.7739 best r: 0.7739
15:31:47,548 root INFO 
id:et_en cur r: 0.7032 best r: 0.7032
15:32:13,358 root INFO 
id:si_en cur r: 0.5941 best r: 0.5941
15:32:26,271 root INFO 
id:ne_en cur r: 0.7520 best r: 0.7520
15:32:39,111 root INFO 
id:ru_en cur r: 0.7496 best r: 0.7496
15:32:39,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:09,225 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:34:09,231 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:34:09,235 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:34:09,240 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:34:09,244 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:34:09,248 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:34:09,253 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:34:22,136 root INFO Epoch 0 Global steps: 4900 Train loss: 0.5689
en_de Dev loss: 0.9233 r:0.1942
en_zh Dev loss: 0.7111 r:0.4081
ro_en Dev loss: 0.4245 r:0.7709
et_en Dev loss: 0.3575 r:0.7188
si_en Dev loss: 0.6915 r:0.6012
ne_en Dev loss: 0.3824 r:0.7469
ru_en Dev loss: 0.4225 r:0.7530
Current avg r:0.5990 Best avg r: 0.5990
15:38:50,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:28,642 root INFO 
id:ro_en cur r: 0.7788 best r: 0.7788
15:40:20,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:41:50,138 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5848
en_de Dev loss: 0.9082 r:0.1923
en_zh Dev loss: 0.7170 r:0.4089
ro_en Dev loss: 0.4021 r:0.7758
et_en Dev loss: 0.3632 r:0.7117
si_en Dev loss: 0.6797 r:0.5975
ne_en Dev loss: 0.4321 r:0.7223
ru_en Dev loss: 0.4386 r:0.7421
Current avg r:0.5929 Best avg r: 0.5990
15:46:18,154 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:46:56,748 root INFO 
id:ro_en cur r: 0.7914 best r: 0.7914
15:47:09,652 root INFO 
id:et_en cur r: 0.7042 best r: 0.7042
15:47:48,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:49:18,263 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5468
en_de Dev loss: 0.9078 r:0.1873
en_zh Dev loss: 0.7209 r:0.4073
ro_en Dev loss: 0.3816 r:0.7936
et_en Dev loss: 0.3663 r:0.7178
si_en Dev loss: 0.8491 r:0.5894
ne_en Dev loss: 0.4582 r:0.7319
ru_en Dev loss: 0.4899 r:0.7382
Current avg r:0.5951 Best avg r: 0.5990
15:53:46,320 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:54:12,53 root INFO 
id:en_zh cur r: 0.4163 best r: 0.4163
15:54:24,930 root INFO 
id:ro_en cur r: 0.7932 best r: 0.7932
15:54:37,816 root INFO 
id:et_en cur r: 0.7145 best r: 0.7145
15:55:03,604 root INFO 
id:si_en cur r: 0.5982 best r: 0.5982
15:55:16,504 root INFO 
id:ne_en cur r: 0.7559 best r: 0.7559
15:55:29,331 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:56:59,338 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
15:56:59,346 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:56:59,353 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:56:59,357 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
15:56:59,362 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
15:56:59,366 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:56:59,371 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:57:12,248 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5672
en_de Dev loss: 0.8969 r:0.1877
en_zh Dev loss: 0.7070 r:0.4164
ro_en Dev loss: 0.3614 r:0.7932
et_en Dev loss: 0.3449 r:0.7270
si_en Dev loss: 0.7374 r:0.5997
ne_en Dev loss: 0.4354 r:0.7378
ru_en Dev loss: 0.4679 r:0.7407
Current avg r:0.6004 Best avg r: 0.6004
16:01:40,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:02:31,878 root INFO 
id:et_en cur r: 0.7149 best r: 0.7149
16:03:10,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:04:40,544 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5492
en_de Dev loss: 0.9191 r:0.1778
en_zh Dev loss: 0.7277 r:0.4146
ro_en Dev loss: 0.3779 r:0.7903
et_en Dev loss: 0.3473 r:0.7229
si_en Dev loss: 0.8357 r:0.5863
ne_en Dev loss: 0.5192 r:0.7330
ru_en Dev loss: 0.4824 r:0.7392
Current avg r:0.5949 Best avg r: 0.6004
16:09:10,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:09:35,792 root INFO 
id:en_zh cur r: 0.4183 best r: 0.4183
16:09:48,669 root INFO 
id:ro_en cur r: 0.8024 best r: 0.8024
16:10:40,155 root INFO 
id:ru_en cur r: 0.7516 best r: 0.7516
16:10:40,156 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:12:10,157 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
16:12:10,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:12:10,173 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:12:10,177 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
16:12:10,182 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
16:12:10,188 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:12:10,193 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:12:23,67 root INFO Epoch 1 Global steps: 8400 Train loss: 0.5225
en_de Dev loss: 0.8855 r:0.1802
en_zh Dev loss: 0.6885 r:0.4261
ro_en Dev loss: 0.3241 r:0.8000
et_en Dev loss: 0.3490 r:0.7187
si_en Dev loss: 0.6487 r:0.5986
ne_en Dev loss: 0.4056 r:0.7432
ru_en Dev loss: 0.3977 r:0.7454
Current avg r:0.6017 Best avg r: 0.6017
16:16:51,262 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:17:04,150 root INFO 
id:en_de cur r: 0.1898 best r: 0.1898
16:17:17,10 root INFO 
id:en_zh cur r: 0.4199 best r: 0.4199
16:18:21,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:19:51,392 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
16:19:51,402 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:19:51,406 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:19:51,411 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
16:19:51,416 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
16:19:51,423 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:19:51,428 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:20:04,324 root INFO Epoch 1 Global steps: 9100 Train loss: 0.5619
en_de Dev loss: 0.9119 r:0.1997
en_zh Dev loss: 0.7396 r:0.4250
ro_en Dev loss: 0.3944 r:0.7964
et_en Dev loss: 0.3657 r:0.7215
si_en Dev loss: 0.7522 r:0.6011
ne_en Dev loss: 0.4865 r:0.7440
ru_en Dev loss: 0.5115 r:0.7312
Current avg r:0.6027 Best avg r: 0.6027
16:24:32,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:45,514 root INFO 
id:en_de cur r: 0.2079 best r: 0.2079
16:24:58,356 root INFO 
id:en_zh cur r: 0.4361 best r: 0.4361
16:25:11,239 root INFO 
id:ro_en cur r: 0.8183 best r: 0.8183
16:25:24,133 root INFO 
id:et_en cur r: 0.7328 best r: 0.7328
16:25:49,932 root INFO 
id:si_en cur r: 0.6157 best r: 0.6157
16:26:02,841 root INFO 
id:ne_en cur r: 0.7742 best r: 0.7742
16:26:15,686 root INFO 
id:ru_en cur r: 0.7623 best r: 0.7623
16:26:15,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:27:45,752 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
16:27:45,759 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:27:45,764 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:27:45,768 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
16:27:45,773 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
16:27:45,778 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:27:45,782 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:27:58,680 root INFO Epoch 1 Global steps: 9800 Train loss: 0.5222
en_de Dev loss: 0.8616 r:0.2105
en_zh Dev loss: 0.6810 r:0.4352
ro_en Dev loss: 0.3114 r:0.8112
et_en Dev loss: 0.3762 r:0.7347
si_en Dev loss: 0.5353 r:0.6208
ne_en Dev loss: 0.3407 r:0.7674
ru_en Dev loss: 0.3700 r:0.7539
Current avg r:0.6191 Best avg r: 0.6191
16:32:26,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:33:56,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:35:26,755 root INFO Epoch 1 Global steps: 10500 Train loss: 0.4840
en_de Dev loss: 0.8780 r:0.1897
en_zh Dev loss: 0.6944 r:0.4204
ro_en Dev loss: 0.3435 r:0.7925
et_en Dev loss: 0.3529 r:0.7097
si_en Dev loss: 0.7681 r:0.5780
ne_en Dev loss: 0.5138 r:0.7340
ru_en Dev loss: 0.4521 r:0.7198
Current avg r:0.5920 Best avg r: 0.6191
16:39:54,211 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:41:24,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:42:54,80 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5040
en_de Dev loss: 0.9080 r:0.2002
en_zh Dev loss: 0.7657 r:0.4226
ro_en Dev loss: 0.3899 r:0.7992
et_en Dev loss: 0.3634 r:0.7145
si_en Dev loss: 0.8687 r:0.5908
ne_en Dev loss: 0.4736 r:0.7539
ru_en Dev loss: 0.5028 r:0.7280
Current avg r:0.6013 Best avg r: 0.6191
16:47:22,108 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:47:47,813 root INFO 
id:en_zh cur r: 0.4440 best r: 0.4440
16:48:52,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:50:22,178 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5030
en_de Dev loss: 0.8592 r:0.2008
en_zh Dev loss: 0.6685 r:0.4468
ro_en Dev loss: 0.3104 r:0.8105
et_en Dev loss: 0.3529 r:0.7210
si_en Dev loss: 0.6483 r:0.6091
ne_en Dev loss: 0.3424 r:0.7660
ru_en Dev loss: 0.3871 r:0.7522
Current avg r:0.6152 Best avg r: 0.6191
16:54:50,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:55:03,194 root INFO 
id:en_de cur r: 0.2207 best r: 0.2207
16:56:20,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:50,423 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4885
en_de Dev loss: 0.8926 r:0.2140
en_zh Dev loss: 0.7299 r:0.4400
ro_en Dev loss: 0.4257 r:0.8077
et_en Dev loss: 0.3747 r:0.7230
si_en Dev loss: 0.8150 r:0.6106
ne_en Dev loss: 0.4876 r:0.7667
ru_en Dev loss: 0.5332 r:0.7337
Current avg r:0.6137 Best avg r: 0.6191
17:02:18,379 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:48,420 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:05:18,467 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4990
en_de Dev loss: 0.8531 r:0.2098
en_zh Dev loss: 0.6798 r:0.4447
ro_en Dev loss: 0.3330 r:0.8089
et_en Dev loss: 0.3505 r:0.7256
si_en Dev loss: 0.6706 r:0.6130
ne_en Dev loss: 0.3868 r:0.7676
ru_en Dev loss: 0.4580 r:0.7331
Current avg r:0.6147 Best avg r: 0.6191
17:09:46,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:10:25,22 root INFO 
id:ro_en cur r: 0.8195 best r: 0.8195
17:11:03,679 root INFO 
id:si_en cur r: 0.6203 best r: 0.6203
17:11:29,394 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:59,411 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4883
en_de Dev loss: 0.8620 r:0.1902
en_zh Dev loss: 0.6783 r:0.4370
ro_en Dev loss: 0.2955 r:0.8140
et_en Dev loss: 0.3520 r:0.7238
si_en Dev loss: 0.5987 r:0.6129
ne_en Dev loss: 0.3390 r:0.7645
ru_en Dev loss: 0.3798 r:0.7490
Current avg r:0.6131 Best avg r: 0.6191
17:17:27,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:53,102 root INFO 
id:en_zh cur r: 0.4499 best r: 0.4499
17:18:57,435 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:20:27,462 root INFO Epoch 1 Global steps: 14700 Train loss: 0.4788
en_de Dev loss: 0.8673 r:0.1959
en_zh Dev loss: 0.6799 r:0.4457
ro_en Dev loss: 0.3123 r:0.8117
et_en Dev loss: 0.3468 r:0.7184
si_en Dev loss: 0.6951 r:0.5996
ne_en Dev loss: 0.3657 r:0.7621
ru_en Dev loss: 0.4499 r:0.7235
Current avg r:0.6081 Best avg r: 0.6191
17:24:55,772 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:21,491 root INFO 
id:en_zh cur r: 0.4514 best r: 0.4514
17:26:25,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:55,977 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5071
en_de Dev loss: 0.8962 r:0.1803
en_zh Dev loss: 0.7333 r:0.4532
ro_en Dev loss: 0.3730 r:0.8063
et_en Dev loss: 0.3925 r:0.7126
si_en Dev loss: 0.8170 r:0.5970
ne_en Dev loss: 0.4498 r:0.7578
ru_en Dev loss: 0.4884 r:0.7337
Current avg r:0.6058 Best avg r: 0.6191
17:32:25,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:51,403 root INFO 
id:en_zh cur r: 0.4669 best r: 0.4669
17:33:04,312 root INFO 
id:ro_en cur r: 0.8200 best r: 0.8200
17:33:55,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:35:25,934 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
17:35:25,946 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:35:25,952 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:35:25,963 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
17:35:25,970 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
17:35:25,976 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:35:25,984 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:35:38,884 root INFO Epoch 2 Global steps: 16100 Train loss: 0.4511
en_de Dev loss: 0.8714 r:0.1974
en_zh Dev loss: 0.6652 r:0.4706
ro_en Dev loss: 0.3286 r:0.8129
et_en Dev loss: 0.3734 r:0.7188
si_en Dev loss: 0.6250 r:0.6136
ne_en Dev loss: 0.3783 r:0.7651
ru_en Dev loss: 0.3894 r:0.7596
Current avg r:0.6197 Best avg r: 0.6197
17:40:07,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:20,11 root INFO 
id:en_de cur r: 0.2288 best r: 0.2288
17:41:37,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:43:07,399 root INFO Epoch 2 Global steps: 16800 Train loss: 0.4395
en_de Dev loss: 0.8706 r:0.2226
en_zh Dev loss: 0.7463 r:0.4465
ro_en Dev loss: 0.3563 r:0.8116
et_en Dev loss: 0.3708 r:0.7181
si_en Dev loss: 0.7916 r:0.6060
ne_en Dev loss: 0.5126 r:0.7639
ru_en Dev loss: 0.4943 r:0.7247
Current avg r:0.6133 Best avg r: 0.6197
17:47:35,625 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:48:14,266 root INFO 
id:ro_en cur r: 0.8232 best r: 0.8232
17:49:05,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:50:35,953 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_de.lang_agnost_mlp.dev.best.scores
17:50:35,959 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:50:35,965 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:50:35,970 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/et_en.lang_agnost_mlp.dev.best.scores
17:50:35,976 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/si_en.lang_agnost_mlp.dev.best.scores
17:50:35,980 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:50:35,986 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_0.75_sien/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:50:48,895 root INFO Epoch 2 Global steps: 17500 Train loss: 0.4611
en_de Dev loss: 0.8875 r:0.2128
en_zh Dev loss: 0.7141 r:0.4678
ro_en Dev loss: 0.3485 r:0.8167
et_en Dev loss: 0.3855 r:0.7178
si_en Dev loss: 0.7257 r:0.6184
ne_en Dev loss: 0.4058 r:0.7694
ru_en Dev loss: 0.4600 r:0.7542
Current avg r:0.6224 Best avg r: 0.6224
17:55:17,209 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:56:47,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:58:17,408 root INFO Epoch 2 Global steps: 18200 Train loss: 0.4597
en_de Dev loss: 0.8681 r:0.1904
en_zh Dev loss: 0.6945 r:0.4594
ro_en Dev loss: 0.3425 r:0.8130
et_en Dev loss: 0.3869 r:0.7118
si_en Dev loss: 0.6447 r:0.6212
ne_en Dev loss: 0.3647 r:0.7668
ru_en Dev loss: 0.4313 r:0.7390
Current avg r:0.6145 Best avg r: 0.6224
18:02:45,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:04:02,530 root INFO 
id:ne_en cur r: 0.7753 best r: 0.7753
18:04:15,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:45,276 root INFO Epoch 2 Global steps: 18900 Train loss: 0.4273
en_de Dev loss: 0.8775 r:0.2224
en_zh Dev loss: 0.7645 r:0.4482
ro_en Dev loss: 0.3853 r:0.8106
et_en Dev loss: 0.4116 r:0.7100
si_en Dev loss: 0.7036 r:0.6113
ne_en Dev loss: 0.3979 r:0.7687
ru_en Dev loss: 0.4530 r:0.7420
Current avg r:0.6161 Best avg r: 0.6224
18:10:13,436 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:26,332 root INFO 
id:en_de cur r: 0.2297 best r: 0.2297
18:11:43,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:13,778 root INFO Epoch 2 Global steps: 19600 Train loss: 0.4662
en_de Dev loss: 0.8524 r:0.2329
en_zh Dev loss: 0.7325 r:0.4336
ro_en Dev loss: 0.3170 r:0.8140
et_en Dev loss: 0.3479 r:0.7164
si_en Dev loss: 0.6483 r:0.6120
ne_en Dev loss: 0.3628 r:0.7655
ru_en Dev loss: 0.4397 r:0.7342
Current avg r:0.6155 Best avg r: 0.6224
18:17:42,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:19:12,265 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:42,383 root INFO Epoch 2 Global steps: 20300 Train loss: 0.4380
en_de Dev loss: 0.8521 r:0.2341
en_zh Dev loss: 0.7411 r:0.4465
ro_en Dev loss: 0.3395 r:0.8143
et_en Dev loss: 0.4120 r:0.7091
si_en Dev loss: 0.6486 r:0.6104
ne_en Dev loss: 0.3641 r:0.7589
ru_en Dev loss: 0.4486 r:0.7268
Current avg r:0.6143 Best avg r: 0.6224
18:25:10,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:40,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:10,882 root INFO Epoch 2 Global steps: 21000 Train loss: 0.4469
en_de Dev loss: 0.8726 r:0.2120
en_zh Dev loss: 0.7271 r:0.4511
ro_en Dev loss: 0.3302 r:0.8178
et_en Dev loss: 0.3820 r:0.7023
si_en Dev loss: 0.7833 r:0.6042
ne_en Dev loss: 0.4414 r:0.7585
ru_en Dev loss: 0.4926 r:0.7191
Current avg r:0.6093 Best avg r: 0.6224
18:32:39,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:34:09,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:39,396 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4157
en_de Dev loss: 0.8863 r:0.1959
en_zh Dev loss: 0.7931 r:0.4466
ro_en Dev loss: 0.3851 r:0.8091
et_en Dev loss: 0.4256 r:0.6931
si_en Dev loss: 0.9157 r:0.5847
ne_en Dev loss: 0.5485 r:0.7498
ru_en Dev loss: 0.5963 r:0.6941
Current avg r:0.5962 Best avg r: 0.6224
18:40:07,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:37,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:07,863 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4412
en_de Dev loss: 0.9217 r:0.1814
en_zh Dev loss: 0.8512 r:0.4384
ro_en Dev loss: 0.4067 r:0.8063
et_en Dev loss: 0.4589 r:0.6910
si_en Dev loss: 0.8401 r:0.5943
ne_en Dev loss: 0.5064 r:0.7515
ru_en Dev loss: 0.6244 r:0.6915
Current avg r:0.5935 Best avg r: 0.6224
18:47:36,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:06,181 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:36,247 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4187
en_de Dev loss: 0.8757 r:0.1732
en_zh Dev loss: 0.7357 r:0.4452
ro_en Dev loss: 0.3427 r:0.8115
et_en Dev loss: 0.3937 r:0.6899
si_en Dev loss: 0.7846 r:0.5926
ne_en Dev loss: 0.4830 r:0.7571
ru_en Dev loss: 0.5150 r:0.6996
Current avg r:0.5956 Best avg r: 0.6224
18:55:04,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:34,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:04,703 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4169
en_de Dev loss: 0.8516 r:0.2185
en_zh Dev loss: 0.7263 r:0.4401
ro_en Dev loss: 0.3379 r:0.8138
et_en Dev loss: 0.3849 r:0.7028
si_en Dev loss: 0.8166 r:0.5949
ne_en Dev loss: 0.4686 r:0.7658
ru_en Dev loss: 0.4615 r:0.7238
Current avg r:0.6085 Best avg r: 0.6224
19:02:34,424 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:13,42 root INFO 
id:ro_en cur r: 0.8232 best r: 0.8232
19:04:04,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:34,649 root INFO Epoch 3 Global steps: 24500 Train loss: 0.4123
en_de Dev loss: 0.8656 r:0.2227
en_zh Dev loss: 0.7434 r:0.4575
ro_en Dev loss: 0.3244 r:0.8178
et_en Dev loss: 0.3881 r:0.6998
si_en Dev loss: 0.7672 r:0.6071
ne_en Dev loss: 0.4555 r:0.7616
ru_en Dev loss: 0.4784 r:0.7250
Current avg r:0.6131 Best avg r: 0.6224
19:10:02,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:33,58 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:03,116 root INFO Epoch 3 Global steps: 25200 Train loss: 0.3805
en_de Dev loss: 0.8798 r:0.2190
en_zh Dev loss: 0.7831 r:0.4556
ro_en Dev loss: 0.4015 r:0.8147
et_en Dev loss: 0.4128 r:0.7034
si_en Dev loss: 0.9178 r:0.6028
ne_en Dev loss: 0.5300 r:0.7642
ru_en Dev loss: 0.5438 r:0.7273
Current avg r:0.6124 Best avg r: 0.6224
19:17:31,384 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:01,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:31,552 root INFO Epoch 3 Global steps: 25900 Train loss: 0.3825
en_de Dev loss: 0.8600 r:0.2242
en_zh Dev loss: 0.7439 r:0.4491
ro_en Dev loss: 0.3570 r:0.8107
et_en Dev loss: 0.4215 r:0.7005
si_en Dev loss: 0.6626 r:0.6096
ne_en Dev loss: 0.4180 r:0.7629
ru_en Dev loss: 0.4694 r:0.7228
Current avg r:0.6114 Best avg r: 0.6224
19:24:59,624 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:38,171 root INFO 
id:ro_en cur r: 0.8253 best r: 0.8253
19:26:29,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:27:59,496 root INFO Epoch 3 Global steps: 26600 Train loss: 0.4078
en_de Dev loss: 0.8465 r:0.2292
en_zh Dev loss: 0.7031 r:0.4534
ro_en Dev loss: 0.3033 r:0.8237
et_en Dev loss: 0.3725 r:0.7121
si_en Dev loss: 0.6705 r:0.6161
ne_en Dev loss: 0.3678 r:0.7688
ru_en Dev loss: 0.4345 r:0.7364
Current avg r:0.6199 Best avg r: 0.6224
19:32:27,584 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:57,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:27,427 root INFO Epoch 3 Global steps: 27300 Train loss: 0.3844
en_de Dev loss: 0.8475 r:0.2253
en_zh Dev loss: 0.7356 r:0.4401
ro_en Dev loss: 0.3295 r:0.8135
et_en Dev loss: 0.4080 r:0.6891
si_en Dev loss: 0.7708 r:0.5894
ne_en Dev loss: 0.4390 r:0.7552
ru_en Dev loss: 0.4763 r:0.7132
Current avg r:0.6037 Best avg r: 0.6224
19:39:55,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:25,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:42:55,816 root INFO Epoch 3 Global steps: 28000 Train loss: 0.3671
en_de Dev loss: 0.8807 r:0.2150
en_zh Dev loss: 0.7931 r:0.4323
ro_en Dev loss: 0.3458 r:0.8144
et_en Dev loss: 0.4097 r:0.6998
si_en Dev loss: 0.7049 r:0.6034
ne_en Dev loss: 0.4287 r:0.7585
ru_en Dev loss: 0.4749 r:0.7378
Current avg r:0.6087 Best avg r: 0.6224
19:47:24,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:54,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:24,281 root INFO Epoch 3 Global steps: 28700 Train loss: 0.3747
en_de Dev loss: 0.8545 r:0.2128
en_zh Dev loss: 0.7274 r:0.4419
ro_en Dev loss: 0.3039 r:0.8207
et_en Dev loss: 0.3992 r:0.7077
si_en Dev loss: 0.6540 r:0.6028
ne_en Dev loss: 0.3654 r:0.7626
ru_en Dev loss: 0.4029 r:0.7488
Current avg r:0.6139 Best avg r: 0.6224
19:54:52,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:22,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:57:52,865 root INFO Epoch 3 Global steps: 29400 Train loss: 0.3826
en_de Dev loss: 0.8589 r:0.2206
en_zh Dev loss: 0.7368 r:0.4432
ro_en Dev loss: 0.3165 r:0.8205
et_en Dev loss: 0.3780 r:0.7107
si_en Dev loss: 0.7013 r:0.6041
ne_en Dev loss: 0.3722 r:0.7717
ru_en Dev loss: 0.4399 r:0.7379
Current avg r:0.6155 Best avg r: 0.6224
20:02:21,342 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:51,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:05:21,530 root INFO Epoch 3 Global steps: 30100 Train loss: 0.3826
en_de Dev loss: 0.8849 r:0.1967
en_zh Dev loss: 0.8116 r:0.4294
ro_en Dev loss: 0.3509 r:0.8164
et_en Dev loss: 0.4002 r:0.6955
si_en Dev loss: 0.8017 r:0.5951
ne_en Dev loss: 0.4942 r:0.7605
ru_en Dev loss: 0.5379 r:0.7034
Current avg r:0.5996 Best avg r: 0.6224
20:09:50,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:10:28,655 root INFO 
id:ro_en cur r: 0.8255 best r: 0.8255
20:11:20,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:12:50,306 root INFO Epoch 3 Global steps: 30800 Train loss: 0.3967
en_de Dev loss: 0.8688 r:0.2093
en_zh Dev loss: 0.7200 r:0.4500
ro_en Dev loss: 0.3104 r:0.8225
et_en Dev loss: 0.3928 r:0.7070
si_en Dev loss: 0.7438 r:0.6017
ne_en Dev loss: 0.3967 r:0.7656
ru_en Dev loss: 0.4558 r:0.7329
Current avg r:0.6127 Best avg r: 0.6224
20:17:18,817 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:18:48,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:20:19,102 root INFO Epoch 3 Global steps: 31500 Train loss: 0.3800
en_de Dev loss: 0.8803 r:0.2094
en_zh Dev loss: 0.7918 r:0.4372
ro_en Dev loss: 0.3655 r:0.8142
et_en Dev loss: 0.4120 r:0.6964
si_en Dev loss: 0.8661 r:0.5857
ne_en Dev loss: 0.4742 r:0.7620
ru_en Dev loss: 0.5408 r:0.7095
Current avg r:0.6021 Best avg r: 0.6224
20:24:48,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:27,465 root INFO 
id:ro_en cur r: 0.8286 best r: 0.8286
20:26:18,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:27:49,61 root INFO Epoch 4 Global steps: 32200 Train loss: 0.3525
en_de Dev loss: 0.8633 r:0.2197
en_zh Dev loss: 0.7414 r:0.4520
ro_en Dev loss: 0.3123 r:0.8272
et_en Dev loss: 0.4086 r:0.7152
si_en Dev loss: 0.6959 r:0.6022
ne_en Dev loss: 0.4031 r:0.7617
ru_en Dev loss: 0.4390 r:0.7408
Current avg r:0.6170 Best avg r: 0.6224
20:32:17,494 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:33:47,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:35:17,662 root INFO Epoch 4 Global steps: 32900 Train loss: 0.3515
en_de Dev loss: 0.8542 r:0.2379
en_zh Dev loss: 0.7578 r:0.4404
ro_en Dev loss: 0.3380 r:0.8210
et_en Dev loss: 0.4089 r:0.6950
si_en Dev loss: 0.7556 r:0.5884
ne_en Dev loss: 0.4499 r:0.7511
ru_en Dev loss: 0.4884 r:0.7164
Current avg r:0.6072 Best avg r: 0.6224
20:39:46,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:41:16,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:42:46,461 root INFO Epoch 4 Global steps: 33600 Train loss: 0.3284
en_de Dev loss: 0.8707 r:0.2332
en_zh Dev loss: 0.8032 r:0.4284
ro_en Dev loss: 0.3512 r:0.8201
et_en Dev loss: 0.4294 r:0.6996
si_en Dev loss: 0.7501 r:0.5928
ne_en Dev loss: 0.4176 r:0.7571
ru_en Dev loss: 0.4660 r:0.7396
Current avg r:0.6101 Best avg r: 0.6224
20:47:14,995 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:48:44,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:50:14,799 root INFO Epoch 4 Global steps: 34300 Train loss: 0.3345
en_de Dev loss: 0.8716 r:0.2283
en_zh Dev loss: 0.8504 r:0.4144
ro_en Dev loss: 0.4079 r:0.8113
et_en Dev loss: 0.4451 r:0.6816
si_en Dev loss: 0.9566 r:0.5646
ne_en Dev loss: 0.5769 r:0.7461
ru_en Dev loss: 0.5687 r:0.6954
Current avg r:0.5917 Best avg r: 0.6224
20:54:43,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:56:13,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:57:43,335 root INFO Epoch 4 Global steps: 35000 Train loss: 0.3178
en_de Dev loss: 0.8528 r:0.2406
en_zh Dev loss: 0.7572 r:0.4496
ro_en Dev loss: 0.3274 r:0.8233
et_en Dev loss: 0.4417 r:0.7014
si_en Dev loss: 0.6756 r:0.5939
ne_en Dev loss: 0.3793 r:0.7585
ru_en Dev loss: 0.4285 r:0.7477
Current avg r:0.6164 Best avg r: 0.6224
21:02:11,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:03:41,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:05:11,485 root INFO Epoch 4 Global steps: 35700 Train loss: 0.3127
en_de Dev loss: 0.8873 r:0.2241
en_zh Dev loss: 0.8272 r:0.4309
ro_en Dev loss: 0.3645 r:0.8188
et_en Dev loss: 0.4458 r:0.6946
si_en Dev loss: 0.7406 r:0.5899
ne_en Dev loss: 0.4138 r:0.7504
ru_en Dev loss: 0.5285 r:0.7185
Current avg r:0.6039 Best avg r: 0.6224
21:09:39,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:11:10,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:12:40,160 root INFO Epoch 4 Global steps: 36400 Train loss: 0.3371
en_de Dev loss: 0.8596 r:0.2266
en_zh Dev loss: 0.7940 r:0.4560
ro_en Dev loss: 0.3514 r:0.8175
et_en Dev loss: 0.4363 r:0.6991
si_en Dev loss: 0.7258 r:0.5928
ne_en Dev loss: 0.4432 r:0.7545
ru_en Dev loss: 0.4453 r:0.7415
Current avg r:0.6126 Best avg r: 0.6224
21:17:08,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:18:38,601 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:20:08,676 root INFO Epoch 4 Global steps: 37100 Train loss: 0.3318
en_de Dev loss: 0.8622 r:0.2393
en_zh Dev loss: 0.8181 r:0.4373
ro_en Dev loss: 0.3484 r:0.8197
et_en Dev loss: 0.4350 r:0.6999
si_en Dev loss: 0.7149 r:0.6006
ne_en Dev loss: 0.4354 r:0.7588
ru_en Dev loss: 0.4325 r:0.7505
Current avg r:0.6152 Best avg r: 0.6224
21:24:36,949 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:26:07,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:37,221 root INFO Epoch 4 Global steps: 37800 Train loss: 0.3405
en_de Dev loss: 0.8755 r:0.2129
en_zh Dev loss: 0.8138 r:0.4243
ro_en Dev loss: 0.3474 r:0.8180
et_en Dev loss: 0.4239 r:0.6976
si_en Dev loss: 0.7420 r:0.5957
ne_en Dev loss: 0.5016 r:0.7571
ru_en Dev loss: 0.4492 r:0.7369
Current avg r:0.6061 Best avg r: 0.6224
21:32:05,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:33:35,656 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:35:05,727 root INFO Epoch 4 Global steps: 38500 Train loss: 0.3273
en_de Dev loss: 0.8730 r:0.2048
en_zh Dev loss: 0.8118 r:0.4211
ro_en Dev loss: 0.3412 r:0.8148
et_en Dev loss: 0.4181 r:0.6850
si_en Dev loss: 0.8035 r:0.5777
ne_en Dev loss: 0.4913 r:0.7523
ru_en Dev loss: 0.4960 r:0.7085
Current avg r:0.5949 Best avg r: 0.6224
21:39:34,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:41:04,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:34,446 root INFO Epoch 4 Global steps: 39200 Train loss: 0.3165
en_de Dev loss: 0.8748 r:0.2045
en_zh Dev loss: 0.7372 r:0.4518
ro_en Dev loss: 0.3068 r:0.8236
et_en Dev loss: 0.3999 r:0.6972
si_en Dev loss: 0.7418 r:0.5899
ne_en Dev loss: 0.4492 r:0.7530
ru_en Dev loss: 0.4165 r:0.7422
Current avg r:0.6089 Best avg r: 0.6224
21:47:04,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:34,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:50:04,582 root INFO Epoch 5 Global steps: 39900 Train loss: 0.2699
en_de Dev loss: 0.8959 r:0.2170
en_zh Dev loss: 0.8652 r:0.4202
ro_en Dev loss: 0.3795 r:0.8133
et_en Dev loss: 0.4732 r:0.6757
si_en Dev loss: 0.8711 r:0.5692
ne_en Dev loss: 0.5152 r:0.7482
ru_en Dev loss: 0.5260 r:0.7147
Current avg r:0.5940 Best avg r: 0.6224
21:54:33,15 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:56:03,197 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:57:33,313 root INFO Epoch 5 Global steps: 40600 Train loss: 0.2880
en_de Dev loss: 0.8889 r:0.2201
en_zh Dev loss: 0.8846 r:0.4332
ro_en Dev loss: 0.3717 r:0.8166
et_en Dev loss: 0.4600 r:0.6903
si_en Dev loss: 0.8402 r:0.5801
ne_en Dev loss: 0.5068 r:0.7507
ru_en Dev loss: 0.5382 r:0.7132
Current avg r:0.6006 Best avg r: 0.6224
22:02:01,650 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:31,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:05:01,959 root INFO Epoch 5 Global steps: 41300 Train loss: 0.2869
en_de Dev loss: 0.8540 r:0.2337
en_zh Dev loss: 0.7867 r:0.4365
ro_en Dev loss: 0.3364 r:0.8202
et_en Dev loss: 0.4498 r:0.6988
si_en Dev loss: 0.7471 r:0.5886
ne_en Dev loss: 0.4227 r:0.7501
ru_en Dev loss: 0.4519 r:0.7298
Current avg r:0.6082 Best avg r: 0.6224
22:09:30,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:11:00,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:30,526 root INFO Epoch 5 Global steps: 42000 Train loss: 0.3080
en_de Dev loss: 0.8792 r:0.2246
en_zh Dev loss: 0.8321 r:0.4488
ro_en Dev loss: 0.3605 r:0.8209
et_en Dev loss: 0.4658 r:0.6970
si_en Dev loss: 0.8715 r:0.5828
ne_en Dev loss: 0.4738 r:0.7461
ru_en Dev loss: 0.4725 r:0.7466
Current avg r:0.6095 Best avg r: 0.6224
22:16:58,567 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:18:28,672 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:58,791 root INFO Epoch 5 Global steps: 42700 Train loss: 0.2895
en_de Dev loss: 0.8759 r:0.2261
en_zh Dev loss: 0.8415 r:0.4217
ro_en Dev loss: 0.3501 r:0.8170
et_en Dev loss: 0.4729 r:0.6970
si_en Dev loss: 0.7438 r:0.5807
ne_en Dev loss: 0.4311 r:0.7470
ru_en Dev loss: 0.4715 r:0.7279
Current avg r:0.6025 Best avg r: 0.6224
22:24:27,88 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:57,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:27,175 root INFO Epoch 5 Global steps: 43400 Train loss: 0.2899
en_de Dev loss: 0.8563 r:0.2415
en_zh Dev loss: 0.7735 r:0.4318
ro_en Dev loss: 0.3294 r:0.8186
et_en Dev loss: 0.4192 r:0.6973
si_en Dev loss: 0.7984 r:0.5739
ne_en Dev loss: 0.4995 r:0.7437
ru_en Dev loss: 0.4947 r:0.7196
Current avg r:0.6038 Best avg r: 0.6224
22:31:55,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:25,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:55,734 root INFO Epoch 5 Global steps: 44100 Train loss: 0.2867
en_de Dev loss: 0.8698 r:0.2248
en_zh Dev loss: 0.8223 r:0.4305
ro_en Dev loss: 0.3411 r:0.8215
et_en Dev loss: 0.4517 r:0.6992
si_en Dev loss: 0.7181 r:0.5877
ne_en Dev loss: 0.3999 r:0.7480
ru_en Dev loss: 0.4710 r:0.7320
Current avg r:0.6062 Best avg r: 0.6224
22:39:24,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:54,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:24,512 root INFO Epoch 5 Global steps: 44800 Train loss: 0.2779
en_de Dev loss: 0.8800 r:0.2316
en_zh Dev loss: 0.8139 r:0.4319
ro_en Dev loss: 0.3709 r:0.8197
et_en Dev loss: 0.4112 r:0.7015
si_en Dev loss: 0.8377 r:0.5801
ne_en Dev loss: 0.5172 r:0.7463
ru_en Dev loss: 0.4969 r:0.7347
Current avg r:0.6066 Best avg r: 0.6224
22:46:52,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:23,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:53,233 root INFO Epoch 5 Global steps: 45500 Train loss: 0.2997
en_de Dev loss: 0.8880 r:0.2398
en_zh Dev loss: 0.8853 r:0.4304
ro_en Dev loss: 0.3727 r:0.8226
et_en Dev loss: 0.4517 r:0.6954
si_en Dev loss: 0.8368 r:0.5883
ne_en Dev loss: 0.4411 r:0.7530
ru_en Dev loss: 0.5263 r:0.7390
Current avg r:0.6098 Best avg r: 0.6224
22:54:21,667 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:51,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:21,959 root INFO Epoch 5 Global steps: 46200 Train loss: 0.2833
en_de Dev loss: 0.8623 r:0.2252
en_zh Dev loss: 0.7927 r:0.4385
ro_en Dev loss: 0.3152 r:0.8211
et_en Dev loss: 0.4264 r:0.6954
si_en Dev loss: 0.7321 r:0.5816
ne_en Dev loss: 0.4342 r:0.7445
ru_en Dev loss: 0.4017 r:0.7515
Current avg r:0.6082 Best avg r: 0.6224
23:01:50,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:20,585 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:50,702 root INFO Epoch 5 Global steps: 46900 Train loss: 0.2767
en_de Dev loss: 0.8779 r:0.2256
en_zh Dev loss: 0.8503 r:0.4254
ro_en Dev loss: 0.3512 r:0.8186
et_en Dev loss: 0.4304 r:0.6864
si_en Dev loss: 0.8170 r:0.5748
ne_en Dev loss: 0.4944 r:0.7427
ru_en Dev loss: 0.5293 r:0.7095
Current avg r:0.5976 Best avg r: 0.6224
23:09:19,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:49,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:19,506 root INFO Epoch 5 Global steps: 47600 Train loss: 0.2855
en_de Dev loss: 0.8685 r:0.2137
en_zh Dev loss: 0.7973 r:0.4336
ro_en Dev loss: 0.3431 r:0.8175
et_en Dev loss: 0.4334 r:0.6825
si_en Dev loss: 0.8445 r:0.5731
ne_en Dev loss: 0.4953 r:0.7469
ru_en Dev loss: 0.4811 r:0.7217
Current avg r:0.5984 Best avg r: 0.6224
23:16:49,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:19,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:49,673 root INFO Epoch 6 Global steps: 48300 Train loss: 0.2588
en_de Dev loss: 0.8476 r:0.2452
en_zh Dev loss: 0.8101 r:0.4408
ro_en Dev loss: 0.3576 r:0.8170
et_en Dev loss: 0.4505 r:0.6829
si_en Dev loss: 0.8790 r:0.5708
ne_en Dev loss: 0.4807 r:0.7442
ru_en Dev loss: 0.4861 r:0.7241
Current avg r:0.6036 Best avg r: 0.6224
23:24:17,948 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:48,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:18,270 root INFO Epoch 6 Global steps: 49000 Train loss: 0.2582
en_de Dev loss: 0.8476 r:0.2480
en_zh Dev loss: 0.7750 r:0.4514
ro_en Dev loss: 0.3474 r:0.8163
et_en Dev loss: 0.4610 r:0.6872
si_en Dev loss: 0.8221 r:0.5680
ne_en Dev loss: 0.4589 r:0.7426
ru_en Dev loss: 0.4488 r:0.7323
Current avg r:0.6065 Best avg r: 0.6224
23:31:46,598 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:16,771 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:34:46,904 root INFO Epoch 6 Global steps: 49700 Train loss: 0.2392
en_de Dev loss: 0.8625 r:0.2345
en_zh Dev loss: 0.7638 r:0.4538
ro_en Dev loss: 0.3346 r:0.8146
et_en Dev loss: 0.4369 r:0.6825
si_en Dev loss: 0.8009 r:0.5672
ne_en Dev loss: 0.4495 r:0.7405
ru_en Dev loss: 0.4638 r:0.7254
Current avg r:0.6026 Best avg r: 0.6224
23:39:15,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:45,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:15,257 root INFO Epoch 6 Global steps: 50400 Train loss: 0.2668
en_de Dev loss: 0.8689 r:0.2103
en_zh Dev loss: 0.8316 r:0.4317
ro_en Dev loss: 0.3671 r:0.8095
et_en Dev loss: 0.4458 r:0.6683
si_en Dev loss: 0.8684 r:0.5569
ne_en Dev loss: 0.4820 r:0.7412
ru_en Dev loss: 0.5243 r:0.6981
Current avg r:0.5880 Best avg r: 0.6224
23:46:43,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:13,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:44,143 root INFO Epoch 6 Global steps: 51100 Train loss: 0.2476
en_de Dev loss: 0.8745 r:0.2239
en_zh Dev loss: 0.8140 r:0.4479
ro_en Dev loss: 0.3615 r:0.8138
et_en Dev loss: 0.4399 r:0.6773
si_en Dev loss: 0.7899 r:0.5709
ne_en Dev loss: 0.4621 r:0.7473
ru_en Dev loss: 0.4932 r:0.7202
Current avg r:0.6002 Best avg r: 0.6224
23:54:12,496 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:42,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:57:12,476 root INFO Epoch 6 Global steps: 51800 Train loss: 0.2614
en_de Dev loss: 0.8666 r:0.2389
en_zh Dev loss: 0.7990 r:0.4496
ro_en Dev loss: 0.3560 r:0.8140
et_en Dev loss: 0.4445 r:0.6823
si_en Dev loss: 0.8962 r:0.5675
ne_en Dev loss: 0.5394 r:0.7455
ru_en Dev loss: 0.4606 r:0.7330
Current avg r:0.6044 Best avg r: 0.6224
00:01:40,492 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:03:10,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:40,639 root INFO Epoch 6 Global steps: 52500 Train loss: 0.2622
en_de Dev loss: 0.8550 r:0.2295
en_zh Dev loss: 0.7530 r:0.4425
ro_en Dev loss: 0.3149 r:0.8160
et_en Dev loss: 0.4216 r:0.6816
si_en Dev loss: 0.8041 r:0.5668
ne_en Dev loss: 0.4908 r:0.7431
ru_en Dev loss: 0.4462 r:0.7205
Current avg r:0.6000 Best avg r: 0.6224
00:09:08,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:38,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:12:09,1 root INFO Epoch 6 Global steps: 53200 Train loss: 0.2564
en_de Dev loss: 0.8685 r:0.2225
en_zh Dev loss: 0.7596 r:0.4586
ro_en Dev loss: 0.3233 r:0.8172
et_en Dev loss: 0.4680 r:0.6824
si_en Dev loss: 0.7282 r:0.5731
ne_en Dev loss: 0.4505 r:0.7395
ru_en Dev loss: 0.4336 r:0.7327
Current avg r:0.6037 Best avg r: 0.6224
00:16:37,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:07,324 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:37,420 root INFO Epoch 6 Global steps: 53900 Train loss: 0.2484
en_de Dev loss: 0.8997 r:0.2143
en_zh Dev loss: 0.8573 r:0.4394
ro_en Dev loss: 0.3755 r:0.8193
et_en Dev loss: 0.4652 r:0.6833
si_en Dev loss: 0.8852 r:0.5671
ne_en Dev loss: 0.5134 r:0.7367
ru_en Dev loss: 0.5219 r:0.7204
Current avg r:0.5972 Best avg r: 0.6224
00:24:05,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:25:35,786 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:05,879 root INFO Epoch 6 Global steps: 54600 Train loss: 0.2472
en_de Dev loss: 0.8915 r:0.2122
en_zh Dev loss: 0.8306 r:0.4326
ro_en Dev loss: 0.3508 r:0.8136
et_en Dev loss: 0.4544 r:0.6716
si_en Dev loss: 0.8704 r:0.5489
ne_en Dev loss: 0.4986 r:0.7241
ru_en Dev loss: 0.5009 r:0.7061
Current avg r:0.5870 Best avg r: 0.6224
00:31:34,38 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:33:04,148 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:34,211 root INFO Epoch 6 Global steps: 55300 Train loss: 0.2443
en_de Dev loss: 0.8648 r:0.2196
en_zh Dev loss: 0.8238 r:0.4284
ro_en Dev loss: 0.3530 r:0.8143
et_en Dev loss: 0.4524 r:0.6842
si_en Dev loss: 0.8322 r:0.5678
ne_en Dev loss: 0.5052 r:0.7363
ru_en Dev loss: 0.4554 r:0.7244
Current avg r:0.5964 Best avg r: 0.6224
00:39:03,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:33,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:03,947 root INFO Epoch 7 Global steps: 56000 Train loss: 0.2142
en_de Dev loss: 0.8749 r:0.2206
en_zh Dev loss: 0.8493 r:0.4274
ro_en Dev loss: 0.3581 r:0.8170
et_en Dev loss: 0.4470 r:0.6801
si_en Dev loss: 0.8414 r:0.5644
ne_en Dev loss: 0.5128 r:0.7321
ru_en Dev loss: 0.4861 r:0.7325
Current avg r:0.5963 Best avg r: 0.6224
00:46:32,139 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:02,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:32,309 root INFO Epoch 7 Global steps: 56700 Train loss: 0.2197
en_de Dev loss: 0.8693 r:0.2274
en_zh Dev loss: 0.8247 r:0.4380
ro_en Dev loss: 0.3625 r:0.8120
et_en Dev loss: 0.4580 r:0.6763
si_en Dev loss: 0.8763 r:0.5591
ne_en Dev loss: 0.5281 r:0.7324
ru_en Dev loss: 0.5164 r:0.7155
Current avg r:0.5944 Best avg r: 0.6224
00:54:00,659 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:30,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:00,880 root INFO Epoch 7 Global steps: 57400 Train loss: 0.2302
en_de Dev loss: 0.8889 r:0.2356
en_zh Dev loss: 0.8210 r:0.4536
ro_en Dev loss: 0.3698 r:0.8139
et_en Dev loss: 0.4544 r:0.6831
si_en Dev loss: 0.8580 r:0.5727
ne_en Dev loss: 0.4697 r:0.7376
ru_en Dev loss: 0.4485 r:0.7511
Current avg r:0.6068 Best avg r: 0.6224
01:01:29,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:02:59,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:29,74 root INFO Epoch 7 Global steps: 58100 Train loss: 0.2258
en_de Dev loss: 0.8601 r:0.2413
en_zh Dev loss: 0.7591 r:0.4543
ro_en Dev loss: 0.3250 r:0.8179
et_en Dev loss: 0.4333 r:0.6835
si_en Dev loss: 0.7909 r:0.5685
ne_en Dev loss: 0.4691 r:0.7404
ru_en Dev loss: 0.4451 r:0.7295
Current avg r:0.6051 Best avg r: 0.6224
01:08:57,45 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:27,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:11:57,267 root INFO Epoch 7 Global steps: 58800 Train loss: 0.2228
en_de Dev loss: 0.8614 r:0.2382
en_zh Dev loss: 0.7937 r:0.4360
ro_en Dev loss: 0.3389 r:0.8154
et_en Dev loss: 0.4420 r:0.6785
si_en Dev loss: 0.8680 r:0.5597
ne_en Dev loss: 0.4761 r:0.7356
ru_en Dev loss: 0.4654 r:0.7247
Current avg r:0.5983 Best avg r: 0.6224
01:16:25,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:17:55,598 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:25,657 root INFO Epoch 7 Global steps: 59500 Train loss: 0.2225
en_de Dev loss: 0.8847 r:0.2262
en_zh Dev loss: 0.8080 r:0.4372
ro_en Dev loss: 0.3478 r:0.8158
et_en Dev loss: 0.4730 r:0.6751
si_en Dev loss: 0.7872 r:0.5619
ne_en Dev loss: 0.4412 r:0.7340
ru_en Dev loss: 0.4778 r:0.7224
Current avg r:0.5961 Best avg r: 0.6224
01:23:53,868 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:24:06,724 root INFO 
id:en_de cur r: 0.2334 best r: 0.2334
01:24:19,563 root INFO 
id:en_zh cur r: 0.4680 best r: 0.4680
01:25:23,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:26:53,781 root INFO Epoch 7 Global steps: 60200 Train loss: 0.2173
en_de Dev loss: 0.8750 r:0.2428
en_zh Dev loss: 0.8029 r:0.4571
ro_en Dev loss: 0.3773 r:0.8148
et_en Dev loss: 0.4677 r:0.6737
si_en Dev loss: 0.9584 r:0.5469
ne_en Dev loss: 0.6061 r:0.7310
ru_en Dev loss: 0.4906 r:0.7268
Current avg r:0.5990 Best avg r: 0.6224
01:31:21,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:32:52,101 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:22,191 root INFO Epoch 7 Global steps: 60900 Train loss: 0.2241
en_de Dev loss: 0.8802 r:0.2367
en_zh Dev loss: 0.8259 r:0.4478
ro_en Dev loss: 0.3746 r:0.8162
et_en Dev loss: 0.5070 r:0.6759
si_en Dev loss: 0.9487 r:0.5498
ne_en Dev loss: 0.5043 r:0.7343
ru_en Dev loss: 0.4798 r:0.7295
Current avg r:0.5986 Best avg r: 0.6224
01:38:50,316 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:40:20,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:41:50,447 root INFO Epoch 7 Global steps: 61600 Train loss: 0.2205
en_de Dev loss: 0.8796 r:0.2239
en_zh Dev loss: 0.8029 r:0.4510
ro_en Dev loss: 0.3612 r:0.8140
et_en Dev loss: 0.4723 r:0.6667
si_en Dev loss: 0.9186 r:0.5465
ne_en Dev loss: 0.5480 r:0.7358
ru_en Dev loss: 0.4907 r:0.7262
Current avg r:0.5949 Best avg r: 0.6224
01:46:18,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:47:48,741 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:49:18,831 root INFO Epoch 7 Global steps: 62300 Train loss: 0.2133
en_de Dev loss: 0.8985 r:0.2106
en_zh Dev loss: 0.7736 r:0.4569
ro_en Dev loss: 0.3339 r:0.8171
et_en Dev loss: 0.4578 r:0.6807
si_en Dev loss: 0.7945 r:0.5594
ne_en Dev loss: 0.4734 r:0.7332
ru_en Dev loss: 0.4975 r:0.7187
Current avg r:0.5966 Best avg r: 0.6224
01:53:47,42 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:55:17,105 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:56:47,128 root INFO Epoch 7 Global steps: 63000 Train loss: 0.2115
en_de Dev loss: 0.8971 r:0.2192
en_zh Dev loss: 0.8214 r:0.4487
ro_en Dev loss: 0.3785 r:0.8120
et_en Dev loss: 0.4782 r:0.6738
si_en Dev loss: 0.8875 r:0.5524
ne_en Dev loss: 0.5257 r:0.7334
ru_en Dev loss: 0.5306 r:0.7144
Current avg r:0.5934 Best avg r: 0.6224
02:01:17,312 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:02:47,846 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:04:18,106 root INFO Epoch 8 Global steps: 63700 Train loss: 0.1577
en_de Dev loss: 0.8787 r:0.2173
en_zh Dev loss: 0.7711 r:0.4457
ro_en Dev loss: 0.3265 r:0.8178
et_en Dev loss: 0.4398 r:0.6812
si_en Dev loss: 0.7667 r:0.5608
ne_en Dev loss: 0.4590 r:0.7347
ru_en Dev loss: 0.4314 r:0.7403
Current avg r:0.5997 Best avg r: 0.6224
02:08:47,65 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:10:17,615 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:11:48,150 root INFO Epoch 8 Global steps: 64400 Train loss: 0.1937
en_de Dev loss: 0.9048 r:0.2191
en_zh Dev loss: 0.8415 r:0.4427
ro_en Dev loss: 0.3805 r:0.8147
et_en Dev loss: 0.4662 r:0.6722
si_en Dev loss: 0.9091 r:0.5556
ne_en Dev loss: 0.5581 r:0.7314
ru_en Dev loss: 0.5269 r:0.7251
Current avg r:0.5944 Best avg r: 0.6224
02:16:17,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:16:42,992 root INFO 
id:en_zh cur r: 0.4682 best r: 0.4682
02:17:47,668 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:19:18,152 root INFO Epoch 8 Global steps: 65100 Train loss: 0.1911
en_de Dev loss: 0.8979 r:0.2231
en_zh Dev loss: 0.8268 r:0.4543
ro_en Dev loss: 0.3816 r:0.8144
et_en Dev loss: 0.5087 r:0.6792
si_en Dev loss: 0.8752 r:0.5624
ne_en Dev loss: 0.4888 r:0.7351
ru_en Dev loss: 0.4529 r:0.7445
Current avg r:0.6019 Best avg r: 0.6224
02:23:47,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:25:17,680 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:26:48,25 root INFO Epoch 8 Global steps: 65800 Train loss: 0.1881
en_de Dev loss: 0.8991 r:0.2109
en_zh Dev loss: 0.8101 r:0.4514
ro_en Dev loss: 0.3897 r:0.8120
et_en Dev loss: 0.4645 r:0.6734
si_en Dev loss: 0.9873 r:0.5474
ne_en Dev loss: 0.6165 r:0.7296
ru_en Dev loss: 0.5029 r:0.7232
Current avg r:0.5926 Best avg r: 0.6224
02:31:16,143 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:32:46,78 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:34:15,981 root INFO Epoch 8 Global steps: 66500 Train loss: 0.1990
en_de Dev loss: 0.8965 r:0.2396
en_zh Dev loss: 0.8135 r:0.4560
ro_en Dev loss: 0.3824 r:0.8148
et_en Dev loss: 0.4464 r:0.6849
si_en Dev loss: 0.8943 r:0.5605
ne_en Dev loss: 0.5150 r:0.7338
ru_en Dev loss: 0.4621 r:0.7478
Current avg r:0.6053 Best avg r: 0.6224
02:38:44,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:40:14,321 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:41:44,341 root INFO Epoch 8 Global steps: 67200 Train loss: 0.2033
en_de Dev loss: 0.9157 r:0.2225
en_zh Dev loss: 0.8318 r:0.4612
ro_en Dev loss: 0.3843 r:0.8169
et_en Dev loss: 0.4754 r:0.6813
si_en Dev loss: 0.8595 r:0.5656
ne_en Dev loss: 0.5401 r:0.7290
ru_en Dev loss: 0.4920 r:0.7427
Current avg r:0.6028 Best avg r: 0.6224
02:46:12,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:46:38,144 root INFO 
id:en_zh cur r: 0.4691 best r: 0.4691
02:47:42,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:49:12,562 root INFO Epoch 8 Global steps: 67900 Train loss: 0.2036
en_de Dev loss: 0.8884 r:0.2151
en_zh Dev loss: 0.7368 r:0.4655
ro_en Dev loss: 0.3324 r:0.8159
et_en Dev loss: 0.4632 r:0.6842
si_en Dev loss: 0.7772 r:0.5669
ne_en Dev loss: 0.4720 r:0.7320
ru_en Dev loss: 0.4461 r:0.7385
Current avg r:0.6026 Best avg r: 0.6224
02:53:40,731 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:55:10,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:56:40,607 root INFO Epoch 8 Global steps: 68600 Train loss: 0.1857
en_de Dev loss: 0.9066 r:0.1996
en_zh Dev loss: 0.8133 r:0.4485
ro_en Dev loss: 0.3888 r:0.8098
et_en Dev loss: 0.4836 r:0.6692
si_en Dev loss: 0.9788 r:0.5478
ne_en Dev loss: 0.6039 r:0.7258
ru_en Dev loss: 0.5003 r:0.7264
Current avg r:0.5896 Best avg r: 0.6224
03:01:08,897 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:02:38,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:04:09,24 root INFO Epoch 8 Global steps: 69300 Train loss: 0.1801
en_de Dev loss: 0.8907 r:0.1907
en_zh Dev loss: 0.7702 r:0.4589
ro_en Dev loss: 0.3337 r:0.8167
et_en Dev loss: 0.4635 r:0.6790
si_en Dev loss: 0.8185 r:0.5565
ne_en Dev loss: 0.5219 r:0.7252
ru_en Dev loss: 0.4578 r:0.7326
Current avg r:0.5942 Best avg r: 0.6224
03:08:37,244 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:10:07,752 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:11:38,226 root INFO Epoch 8 Global steps: 70000 Train loss: 0.2049
en_de Dev loss: 0.8819 r:0.2096
en_zh Dev loss: 0.7831 r:0.4544
ro_en Dev loss: 0.3442 r:0.8173
et_en Dev loss: 0.4795 r:0.6671
si_en Dev loss: 0.8730 r:0.5546
ne_en Dev loss: 0.5340 r:0.7308
ru_en Dev loss: 0.4659 r:0.7327
Current avg r:0.5952 Best avg r: 0.6224
03:16:07,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:17:37,702 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:19:08,203 root INFO Epoch 8 Global steps: 70700 Train loss: 0.1904
en_de Dev loss: 0.8816 r:0.2290
en_zh Dev loss: 0.7894 r:0.4547
ro_en Dev loss: 0.3563 r:0.8155
et_en Dev loss: 0.4668 r:0.6661
si_en Dev loss: 0.9048 r:0.5557
ne_en Dev loss: 0.6452 r:0.7262
ru_en Dev loss: 0.4918 r:0.7256
Current avg r:0.5961 Best avg r: 0.6224
03:23:37,124 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:24:02,967 root INFO 
id:en_zh cur r: 0.4725 best r: 0.4725
03:25:07,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:26:38,127 root INFO Epoch 8 Global steps: 71400 Train loss: 0.1931
en_de Dev loss: 0.8699 r:0.2290
en_zh Dev loss: 0.7472 r:0.4667
ro_en Dev loss: 0.3258 r:0.8178
et_en Dev loss: 0.4656 r:0.6730
si_en Dev loss: 0.8417 r:0.5552
ne_en Dev loss: 0.5136 r:0.7214
ru_en Dev loss: 0.4433 r:0.7359
Current avg r:0.5999 Best avg r: 0.6224
03:31:08,446 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:31:34,162 root INFO 
id:en_zh cur r: 0.4737 best r: 0.4737
03:32:38,515 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:34:08,552 root INFO Epoch 9 Global steps: 72100 Train loss: 0.1698
en_de Dev loss: 0.8890 r:0.2369
en_zh Dev loss: 0.8265 r:0.4641
ro_en Dev loss: 0.3775 r:0.8138
et_en Dev loss: 0.5019 r:0.6761
si_en Dev loss: 0.8981 r:0.5585
ne_en Dev loss: 0.5194 r:0.7252
ru_en Dev loss: 0.4772 r:0.7370
Current avg r:0.6017 Best avg r: 0.6224
03:38:36,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:40:06,765 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:41:36,776 root INFO Epoch 9 Global steps: 72800 Train loss: 0.1782
en_de Dev loss: 0.8829 r:0.2201
en_zh Dev loss: 0.7986 r:0.4509
ro_en Dev loss: 0.3611 r:0.8149
et_en Dev loss: 0.4810 r:0.6687
si_en Dev loss: 0.8531 r:0.5580
ne_en Dev loss: 0.5084 r:0.7276
ru_en Dev loss: 0.4750 r:0.7267
Current avg r:0.5953 Best avg r: 0.6224
03:46:04,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:47:35,15 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:49:05,60 root INFO Epoch 9 Global steps: 73500 Train loss: 0.1659
en_de Dev loss: 0.8875 r:0.2286
en_zh Dev loss: 0.8242 r:0.4500
ro_en Dev loss: 0.3504 r:0.8188
et_en Dev loss: 0.4658 r:0.6656
si_en Dev loss: 0.8630 r:0.5545
ne_en Dev loss: 0.5163 r:0.7320
ru_en Dev loss: 0.4894 r:0.7269
Current avg r:0.5966 Best avg r: 0.6224
03:53:33,225 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:55:03,251 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:56:33,140 root INFO Epoch 9 Global steps: 74200 Train loss: 0.1705
en_de Dev loss: 0.9017 r:0.2168
en_zh Dev loss: 0.8027 r:0.4580
ro_en Dev loss: 0.3551 r:0.8166
et_en Dev loss: 0.4712 r:0.6694
si_en Dev loss: 0.8972 r:0.5529
ne_en Dev loss: 0.5403 r:0.7301
ru_en Dev loss: 0.4693 r:0.7371
Current avg r:0.5973 Best avg r: 0.6224
04:01:01,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:02:31,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:04:01,192 root INFO Epoch 9 Global steps: 74900 Train loss: 0.1630
en_de Dev loss: 0.8874 r:0.2227
en_zh Dev loss: 0.8056 r:0.4550
ro_en Dev loss: 0.3655 r:0.8149
et_en Dev loss: 0.4978 r:0.6602
si_en Dev loss: 0.8321 r:0.5589
ne_en Dev loss: 0.5383 r:0.7279
ru_en Dev loss: 0.5002 r:0.7182
Current avg r:0.5940 Best avg r: 0.6224
04:08:29,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:10:00,186 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:11:30,656 root INFO Epoch 9 Global steps: 75600 Train loss: 0.1668
en_de Dev loss: 0.8939 r:0.2366
en_zh Dev loss: 0.8277 r:0.4644
ro_en Dev loss: 0.3768 r:0.8147
et_en Dev loss: 0.5123 r:0.6672
si_en Dev loss: 0.9216 r:0.5588
ne_en Dev loss: 0.5950 r:0.7261
ru_en Dev loss: 0.4958 r:0.7360
Current avg r:0.6005 Best avg r: 0.6224
04:15:59,534 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:17:30,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:19:00,540 root INFO Epoch 9 Global steps: 76300 Train loss: 0.1863
en_de Dev loss: 0.8743 r:0.2258
en_zh Dev loss: 0.8010 r:0.4510
ro_en Dev loss: 0.3298 r:0.8172
et_en Dev loss: 0.4633 r:0.6708
si_en Dev loss: 0.8156 r:0.5571
ne_en Dev loss: 0.5120 r:0.7170
ru_en Dev loss: 0.4819 r:0.7234
Current avg r:0.5946 Best avg r: 0.6224
04:23:29,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:24:59,647 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:26:29,989 root INFO Epoch 9 Global steps: 77000 Train loss: 0.1647
en_de Dev loss: 0.8736 r:0.2268
en_zh Dev loss: 0.7661 r:0.4626
ro_en Dev loss: 0.3279 r:0.8191
et_en Dev loss: 0.4601 r:0.6771
si_en Dev loss: 0.8177 r:0.5655
ne_en Dev loss: 0.5307 r:0.7230
ru_en Dev loss: 0.4478 r:0.7386
Current avg r:0.6018 Best avg r: 0.6224
04:30:58,575 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:32:28,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:33:58,756 root INFO Epoch 9 Global steps: 77700 Train loss: 0.1675
en_de Dev loss: 0.8863 r:0.2163
en_zh Dev loss: 0.7923 r:0.4614
ro_en Dev loss: 0.3417 r:0.8160
et_en Dev loss: 0.4984 r:0.6753
si_en Dev loss: 0.7942 r:0.5595
ne_en Dev loss: 0.4750 r:0.7251
ru_en Dev loss: 0.4352 r:0.7425
Current avg r:0.5994 Best avg r: 0.6224
04:38:26,900 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:39:57,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:41:27,110 root INFO Epoch 9 Global steps: 78400 Train loss: 0.1736
en_de Dev loss: 0.8819 r:0.2097
en_zh Dev loss: 0.7558 r:0.4538
ro_en Dev loss: 0.3206 r:0.8138
et_en Dev loss: 0.4430 r:0.6598
si_en Dev loss: 0.8046 r:0.5485
ne_en Dev loss: 0.5564 r:0.7218
ru_en Dev loss: 0.4133 r:0.7430
Current avg r:0.5929 Best avg r: 0.6224
04:45:55,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:46:21,36 root INFO 
id:en_zh cur r: 0.4790 best r: 0.4790
04:47:25,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:48:55,531 root INFO Epoch 9 Global steps: 79100 Train loss: 0.1705
en_de Dev loss: 0.8933 r:0.2117
en_zh Dev loss: 0.7646 r:0.4679
ro_en Dev loss: 0.3327 r:0.8180
et_en Dev loss: 0.4626 r:0.6671
si_en Dev loss: 0.8689 r:0.5507
ne_en Dev loss: 0.5076 r:0.7287
ru_en Dev loss: 0.4419 r:0.7421
Current avg r:0.5980 Best avg r: 0.6224
04:53:25,75 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:54:55,145 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:56:25,140 root INFO Epoch 10 Global steps: 79800 Train loss: 0.1466
en_de Dev loss: 0.9268 r:0.2083
en_zh Dev loss: 0.8146 r:0.4707
ro_en Dev loss: 0.3842 r:0.8150
et_en Dev loss: 0.5086 r:0.6702
si_en Dev loss: 0.8775 r:0.5599
ne_en Dev loss: 0.5120 r:0.7248
ru_en Dev loss: 0.4992 r:0.7421
Current avg r:0.5987 Best avg r: 0.6224
05:00:53,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:02:23,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:03:53,218 root INFO Epoch 10 Global steps: 80500 Train loss: 0.1545
en_de Dev loss: 0.9427 r:0.2114
en_zh Dev loss: 0.7790 r:0.4663
ro_en Dev loss: 0.3394 r:0.8178
et_en Dev loss: 0.4567 r:0.6797
si_en Dev loss: 0.8539 r:0.5588
ne_en Dev loss: 0.5484 r:0.7274
ru_en Dev loss: 0.4422 r:0.7521
Current avg r:0.6019 Best avg r: 0.6224
05:08:22,25 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:09:52,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:11:22,946 root INFO Epoch 10 Global steps: 81200 Train loss: 0.1562
en_de Dev loss: 0.9020 r:0.2082
en_zh Dev loss: 0.7448 r:0.4680
ro_en Dev loss: 0.3332 r:0.8173
et_en Dev loss: 0.4836 r:0.6654
si_en Dev loss: 0.8011 r:0.5578
ne_en Dev loss: 0.5331 r:0.7234
ru_en Dev loss: 0.4343 r:0.7372
Current avg r:0.5967 Best avg r: 0.6224
05:15:51,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:17:22,428 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:18:52,933 root INFO Epoch 10 Global steps: 81900 Train loss: 0.1548
en_de Dev loss: 0.9238 r:0.1996
en_zh Dev loss: 0.8173 r:0.4672
ro_en Dev loss: 0.3893 r:0.8114
et_en Dev loss: 0.5002 r:0.6548
si_en Dev loss: 0.9551 r:0.5460
ne_en Dev loss: 0.5906 r:0.7151
ru_en Dev loss: 0.5117 r:0.7207
Current avg r:0.5878 Best avg r: 0.6224
05:23:21,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:24:52,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:26:22,585 root INFO Epoch 10 Global steps: 82600 Train loss: 0.1581
en_de Dev loss: 0.9148 r:0.2097
en_zh Dev loss: 0.8125 r:0.4647
ro_en Dev loss: 0.3772 r:0.8155
et_en Dev loss: 0.4945 r:0.6707
si_en Dev loss: 0.8838 r:0.5556
ne_en Dev loss: 0.5203 r:0.7204
ru_en Dev loss: 0.5200 r:0.7245
Current avg r:0.5944 Best avg r: 0.6224
05:30:50,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:32:20,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:33:50,815 root INFO Epoch 10 Global steps: 83300 Train loss: 0.1463
en_de Dev loss: 0.8932 r:0.2084
en_zh Dev loss: 0.7906 r:0.4677
ro_en Dev loss: 0.3598 r:0.8160
et_en Dev loss: 0.4736 r:0.6661
si_en Dev loss: 0.8856 r:0.5538
ne_en Dev loss: 0.5719 r:0.7208
ru_en Dev loss: 0.4530 r:0.7383
Current avg r:0.5959 Best avg r: 0.6224
05:38:19,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:39:49,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:41:19,194 root INFO Epoch 10 Global steps: 84000 Train loss: 0.1524
en_de Dev loss: 0.9009 r:0.1978
en_zh Dev loss: 0.7840 r:0.4597
ro_en Dev loss: 0.3533 r:0.8122
et_en Dev loss: 0.4925 r:0.6589
si_en Dev loss: 0.8937 r:0.5398
ne_en Dev loss: 0.5552 r:0.7151
ru_en Dev loss: 0.4547 r:0.7311
Current avg r:0.5878 Best avg r: 0.6224
05:45:47,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:47:17,473 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:48:47,567 root INFO Epoch 10 Global steps: 84700 Train loss: 0.1549
en_de Dev loss: 0.8787 r:0.2292
en_zh Dev loss: 0.7672 r:0.4624
ro_en Dev loss: 0.3388 r:0.8189
et_en Dev loss: 0.4586 r:0.6691
si_en Dev loss: 0.8198 r:0.5573
ne_en Dev loss: 0.5244 r:0.7137
ru_en Dev loss: 0.4302 r:0.7476
Current avg r:0.5997 Best avg r: 0.6224
05:53:15,750 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:45,695 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:56:15,730 root INFO Epoch 10 Global steps: 85400 Train loss: 0.1511
en_de Dev loss: 0.9030 r:0.2171
en_zh Dev loss: 0.7776 r:0.4709
ro_en Dev loss: 0.3684 r:0.8121
et_en Dev loss: 0.4904 r:0.6676
si_en Dev loss: 0.8280 r:0.5558
ne_en Dev loss: 0.5271 r:0.7215
ru_en Dev loss: 0.4481 r:0.7423
Current avg r:0.5982 Best avg r: 0.6224
06:00:44,19 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:01:09,758 root INFO 
id:en_zh cur r: 0.4823 best r: 0.4823
06:02:14,438 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:03:44,969 root INFO Epoch 10 Global steps: 86100 Train loss: 0.1490
en_de Dev loss: 0.9058 r:0.2075
en_zh Dev loss: 0.7644 r:0.4809
ro_en Dev loss: 0.3481 r:0.8169
et_en Dev loss: 0.4726 r:0.6735
si_en Dev loss: 0.8255 r:0.5589
ne_en Dev loss: 0.5478 r:0.7158
ru_en Dev loss: 0.4391 r:0.7440
Current avg r:0.5996 Best avg r: 0.6224
06:08:13,785 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:44,344 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:11:14,908 root INFO Epoch 10 Global steps: 86800 Train loss: 0.1503
en_de Dev loss: 0.9116 r:0.2131
en_zh Dev loss: 0.8107 r:0.4668
ro_en Dev loss: 0.3550 r:0.8143
et_en Dev loss: 0.4812 r:0.6636
si_en Dev loss: 0.8739 r:0.5479
ne_en Dev loss: 0.5671 r:0.7126
ru_en Dev loss: 0.4474 r:0.7428
Current avg r:0.5944 Best avg r: 0.6224
06:15:43,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:17:14,202 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:44,720 root INFO Epoch 10 Global steps: 87500 Train loss: 0.1533
en_de Dev loss: 0.8992 r:0.1901
en_zh Dev loss: 0.8075 r:0.4594
ro_en Dev loss: 0.3224 r:0.8208
et_en Dev loss: 0.4592 r:0.6773
si_en Dev loss: 0.8290 r:0.5545
ne_en Dev loss: 0.5199 r:0.7176
ru_en Dev loss: 0.4425 r:0.7372
Current avg r:0.5938 Best avg r: 0.6224
06:23:15,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:24:45,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:26:15,519 root INFO Epoch 11 Global steps: 88200 Train loss: 0.1299
en_de Dev loss: 0.9016 r:0.2040
en_zh Dev loss: 0.8089 r:0.4573
ro_en Dev loss: 0.3722 r:0.8118
et_en Dev loss: 0.5034 r:0.6572
si_en Dev loss: 0.9266 r:0.5456
ne_en Dev loss: 0.6175 r:0.7123
ru_en Dev loss: 0.4765 r:0.7271
Current avg r:0.5879 Best avg r: 0.6224
06:30:43,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:32:13,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:33:44,42 root INFO Epoch 11 Global steps: 88900 Train loss: 0.1389
en_de Dev loss: 0.9241 r:0.1909
en_zh Dev loss: 0.8372 r:0.4536
ro_en Dev loss: 0.3892 r:0.8119
et_en Dev loss: 0.5050 r:0.6579
si_en Dev loss: 0.9667 r:0.5457
ne_en Dev loss: 0.5742 r:0.7224
ru_en Dev loss: 0.4670 r:0.7403
Current avg r:0.5890 Best avg r: 0.6224
06:38:12,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:39:42,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:41:12,412 root INFO Epoch 11 Global steps: 89600 Train loss: 0.1472
en_de Dev loss: 0.8908 r:0.2107
en_zh Dev loss: 0.7898 r:0.4518
ro_en Dev loss: 0.3436 r:0.8147
et_en Dev loss: 0.4640 r:0.6716
si_en Dev loss: 0.8894 r:0.5465
ne_en Dev loss: 0.5625 r:0.7161
ru_en Dev loss: 0.4201 r:0.7503
Current avg r:0.5945 Best avg r: 0.6224
06:45:40,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:10,654 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:48:40,520 root INFO Epoch 11 Global steps: 90300 Train loss: 0.1357
en_de Dev loss: 0.9369 r:0.1914
en_zh Dev loss: 0.8347 r:0.4577
ro_en Dev loss: 0.3717 r:0.8158
et_en Dev loss: 0.4995 r:0.6585
si_en Dev loss: 0.9142 r:0.5526
ne_en Dev loss: 0.6179 r:0.7165
ru_en Dev loss: 0.5001 r:0.7374
Current avg r:0.5900 Best avg r: 0.6224
06:53:08,490 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:38,583 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:08,647 root INFO Epoch 11 Global steps: 91000 Train loss: 0.1432
en_de Dev loss: 0.9163 r:0.2050
en_zh Dev loss: 0.7823 r:0.4671
ro_en Dev loss: 0.3361 r:0.8184
et_en Dev loss: 0.4912 r:0.6740
si_en Dev loss: 0.8193 r:0.5565
ne_en Dev loss: 0.5087 r:0.7181
ru_en Dev loss: 0.4312 r:0.7510
Current avg r:0.5986 Best avg r: 0.6224
07:00:37,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:07,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:03:38,261 root INFO Epoch 11 Global steps: 91700 Train loss: 0.1401
en_de Dev loss: 0.9546 r:0.1781
en_zh Dev loss: 0.8334 r:0.4584
ro_en Dev loss: 0.3728 r:0.8174
et_en Dev loss: 0.4892 r:0.6622
si_en Dev loss: 0.8808 r:0.5555
ne_en Dev loss: 0.5752 r:0.7121
ru_en Dev loss: 0.4854 r:0.7345
Current avg r:0.5883 Best avg r: 0.6224
07:08:07,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:09:37,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:11:08,512 root INFO Epoch 11 Global steps: 92400 Train loss: 0.1431
en_de Dev loss: 0.9495 r:0.1929
en_zh Dev loss: 0.8046 r:0.4694
ro_en Dev loss: 0.3576 r:0.8165
et_en Dev loss: 0.5109 r:0.6707
si_en Dev loss: 0.8182 r:0.5599
ne_en Dev loss: 0.5000 r:0.7170
ru_en Dev loss: 0.4314 r:0.7570
Current avg r:0.5976 Best avg r: 0.6224
07:15:37,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:08,245 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:18:38,770 root INFO Epoch 11 Global steps: 93100 Train loss: 0.1319
en_de Dev loss: 0.9101 r:0.2055
en_zh Dev loss: 0.8000 r:0.4645
ro_en Dev loss: 0.3906 r:0.8109
et_en Dev loss: 0.5183 r:0.6520
si_en Dev loss: 0.9482 r:0.5430
ne_en Dev loss: 0.5701 r:0.7156
ru_en Dev loss: 0.4785 r:0.7301
Current avg r:0.5888 Best avg r: 0.6224
07:23:07,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:24:37,325 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:07,360 root INFO Epoch 11 Global steps: 93800 Train loss: 0.1345
en_de Dev loss: 0.9612 r:0.1732
en_zh Dev loss: 0.8118 r:0.4711
ro_en Dev loss: 0.3737 r:0.8130
et_en Dev loss: 0.5118 r:0.6586
si_en Dev loss: 0.9227 r:0.5465
ne_en Dev loss: 0.5698 r:0.7165
ru_en Dev loss: 0.4949 r:0.7297
Current avg r:0.5869 Best avg r: 0.6224
07:30:35,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:05,821 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:33:35,891 root INFO Epoch 11 Global steps: 94500 Train loss: 0.1410
en_de Dev loss: 0.9224 r:0.1899
en_zh Dev loss: 0.7763 r:0.4748
ro_en Dev loss: 0.3383 r:0.8156
et_en Dev loss: 0.5049 r:0.6571
si_en Dev loss: 0.8074 r:0.5470
ne_en Dev loss: 0.5189 r:0.7119
ru_en Dev loss: 0.4361 r:0.7310
Current avg r:0.5896 Best avg r: 0.6224
07:38:04,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:39:34,313 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:41:04,354 root INFO Epoch 11 Global steps: 95200 Train loss: 0.1419
en_de Dev loss: 0.9247 r:0.2016
en_zh Dev loss: 0.7904 r:0.4788
ro_en Dev loss: 0.3540 r:0.8170
et_en Dev loss: 0.4977 r:0.6718
si_en Dev loss: 0.8853 r:0.5577
ne_en Dev loss: 0.5399 r:0.7190
ru_en Dev loss: 0.4302 r:0.7551
Current avg r:0.6001 Best avg r: 0.6224
07:45:33,943 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:04,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:48:34,177 root INFO Epoch 12 Global steps: 95900 Train loss: 0.1263
en_de Dev loss: 0.9493 r:0.2059
en_zh Dev loss: 0.7983 r:0.4749
ro_en Dev loss: 0.3711 r:0.8179
et_en Dev loss: 0.4964 r:0.6688
si_en Dev loss: 0.9360 r:0.5459
ne_en Dev loss: 0.7010 r:0.7132
ru_en Dev loss: 0.4580 r:0.7435
Current avg r:0.5957 Best avg r: 0.6224
07:53:02,504 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:54:32,576 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:56:02,680 root INFO Epoch 12 Global steps: 96600 Train loss: 0.1297
en_de Dev loss: 0.9423 r:0.2077
en_zh Dev loss: 0.8138 r:0.4712
ro_en Dev loss: 0.3752 r:0.8134
et_en Dev loss: 0.5240 r:0.6697
si_en Dev loss: 0.8489 r:0.5571
ne_en Dev loss: 0.5731 r:0.7211
ru_en Dev loss: 0.4521 r:0.7480
Current avg r:0.5983 Best avg r: 0.6224
08:00:30,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:01,13 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:03:31,43 root INFO Epoch 12 Global steps: 97300 Train loss: 0.1226
en_de Dev loss: 0.9470 r:0.1962
en_zh Dev loss: 0.8297 r:0.4621
ro_en Dev loss: 0.3726 r:0.8145
et_en Dev loss: 0.4866 r:0.6766
si_en Dev loss: 0.9349 r:0.5515
ne_en Dev loss: 0.5548 r:0.7210
ru_en Dev loss: 0.4646 r:0.7473
Current avg r:0.5956 Best avg r: 0.6224
08:07:59,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:09:29,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:10:59,533 root INFO Epoch 12 Global steps: 98000 Train loss: 0.1322
en_de Dev loss: 0.9101 r:0.2186
en_zh Dev loss: 0.8088 r:0.4621
ro_en Dev loss: 0.3824 r:0.8142
et_en Dev loss: 0.5112 r:0.6631
si_en Dev loss: 0.9324 r:0.5467
ne_en Dev loss: 0.5661 r:0.7191
ru_en Dev loss: 0.4749 r:0.7382
Current avg r:0.5946 Best avg r: 0.6224
08:15:27,641 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:16:57,538 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:18:27,471 root INFO Epoch 12 Global steps: 98700 Train loss: 0.1245
en_de Dev loss: 0.9377 r:0.2007
en_zh Dev loss: 0.7994 r:0.4638
ro_en Dev loss: 0.3547 r:0.8152
et_en Dev loss: 0.4678 r:0.6729
si_en Dev loss: 0.8801 r:0.5479
ne_en Dev loss: 0.5454 r:0.7109
ru_en Dev loss: 0.4689 r:0.7386
Current avg r:0.5929 Best avg r: 0.6224
08:22:55,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:24:25,895 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:25:55,992 root INFO Epoch 12 Global steps: 99400 Train loss: 0.1216
en_de Dev loss: 0.9276 r:0.1811
en_zh Dev loss: 0.7747 r:0.4650
ro_en Dev loss: 0.3307 r:0.8168
et_en Dev loss: 0.4685 r:0.6594
si_en Dev loss: 0.8127 r:0.5449
ne_en Dev loss: 0.5428 r:0.7083
ru_en Dev loss: 0.4464 r:0.7348
Current avg r:0.5872 Best avg r: 0.6224
08:30:24,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:31:54,422 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:33:24,494 root INFO Epoch 12 Global steps: 100100 Train loss: 0.1190
en_de Dev loss: 0.9118 r:0.1990
en_zh Dev loss: 0.7839 r:0.4630
ro_en Dev loss: 0.3367 r:0.8192
et_en Dev loss: 0.4597 r:0.6716
si_en Dev loss: 0.8275 r:0.5529
ne_en Dev loss: 0.5315 r:0.7162
ru_en Dev loss: 0.4471 r:0.7377
Current avg r:0.5942 Best avg r: 0.6224
08:37:52,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:39:22,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:40:53,13 root INFO Epoch 12 Global steps: 100800 Train loss: 0.1272
en_de Dev loss: 0.9304 r:0.2076
en_zh Dev loss: 0.8305 r:0.4616
ro_en Dev loss: 0.3744 r:0.8128
et_en Dev loss: 0.4699 r:0.6617
si_en Dev loss: 0.9598 r:0.5439
ne_en Dev loss: 0.6111 r:0.7111
ru_en Dev loss: 0.4836 r:0.7328
Current avg r:0.5902 Best avg r: 0.6224
08:45:21,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:46:51,293 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:48:21,157 root INFO Epoch 12 Global steps: 101500 Train loss: 0.1263
en_de Dev loss: 0.9310 r:0.1949
en_zh Dev loss: 0.8303 r:0.4522
ro_en Dev loss: 0.3679 r:0.8127
et_en Dev loss: 0.4803 r:0.6640
si_en Dev loss: 0.9346 r:0.5506
ne_en Dev loss: 0.6209 r:0.7139
ru_en Dev loss: 0.4864 r:0.7343
Current avg r:0.5889 Best avg r: 0.6224
08:52:49,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:54:19,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:55:49,433 root INFO Epoch 12 Global steps: 102200 Train loss: 0.1223
en_de Dev loss: 0.9271 r:0.2062
en_zh Dev loss: 0.8057 r:0.4668
ro_en Dev loss: 0.3525 r:0.8182
et_en Dev loss: 0.4708 r:0.6717
si_en Dev loss: 0.9460 r:0.5472
ne_en Dev loss: 0.6341 r:0.7098
ru_en Dev loss: 0.4908 r:0.7357
Current avg r:0.5937 Best avg r: 0.6224
09:00:17,759 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:47,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:03:17,963 root INFO Epoch 12 Global steps: 102900 Train loss: 0.1269
en_de Dev loss: 0.9361 r:0.2001
en_zh Dev loss: 0.7853 r:0.4640
ro_en Dev loss: 0.3377 r:0.8173
et_en Dev loss: 0.4710 r:0.6634
si_en Dev loss: 0.8752 r:0.5496
ne_en Dev loss: 0.5950 r:0.7034
ru_en Dev loss: 0.4589 r:0.7305
Current avg r:0.5898 Best avg r: 0.6224
09:07:47,643 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:09:17,762 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:47,827 root INFO Epoch 13 Global steps: 103600 Train loss: 0.1152
en_de Dev loss: 0.9220 r:0.1951
en_zh Dev loss: 0.7954 r:0.4600
ro_en Dev loss: 0.3491 r:0.8130
et_en Dev loss: 0.4792 r:0.6602
si_en Dev loss: 0.8906 r:0.5432
ne_en Dev loss: 0.5701 r:0.7093
ru_en Dev loss: 0.4569 r:0.7342
Current avg r:0.5878 Best avg r: 0.6224
09:15:16,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:16:46,194 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:18:16,271 root INFO Epoch 13 Global steps: 104300 Train loss: 0.1187
en_de Dev loss: 0.9701 r:0.1940
en_zh Dev loss: 0.8690 r:0.4545
ro_en Dev loss: 0.3724 r:0.8154
et_en Dev loss: 0.4778 r:0.6599
si_en Dev loss: 1.0017 r:0.5486
ne_en Dev loss: 0.6547 r:0.7132
ru_en Dev loss: 0.5344 r:0.7249
Current avg r:0.5872 Best avg r: 0.6224
09:22:44,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:24:14,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:25:44,653 root INFO Epoch 13 Global steps: 105000 Train loss: 0.1133
en_de Dev loss: 0.9678 r:0.2046
en_zh Dev loss: 0.8464 r:0.4596
ro_en Dev loss: 0.3983 r:0.8114
et_en Dev loss: 0.5091 r:0.6616
si_en Dev loss: 0.9362 r:0.5485
ne_en Dev loss: 0.5895 r:0.7100
ru_en Dev loss: 0.4877 r:0.7390
Current avg r:0.5907 Best avg r: 0.6224
09:30:12,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:31:42,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:33:13,29 root INFO Epoch 13 Global steps: 105700 Train loss: 0.1170
en_de Dev loss: 0.9287 r:0.2020
en_zh Dev loss: 0.7778 r:0.4645
ro_en Dev loss: 0.3382 r:0.8171
et_en Dev loss: 0.4635 r:0.6739
si_en Dev loss: 0.8130 r:0.5586
ne_en Dev loss: 0.5328 r:0.7117
ru_en Dev loss: 0.4379 r:0.7380
Current avg r:0.5951 Best avg r: 0.6224
09:37:41,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:39:11,222 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:40:41,111 root INFO Epoch 13 Global steps: 106400 Train loss: 0.1141
en_de Dev loss: 0.9295 r:0.1914
en_zh Dev loss: 0.7722 r:0.4749
ro_en Dev loss: 0.3526 r:0.8128
et_en Dev loss: 0.4661 r:0.6697
si_en Dev loss: 0.8890 r:0.5495
ne_en Dev loss: 0.5759 r:0.7146
ru_en Dev loss: 0.4244 r:0.7497
Current avg r:0.5947 Best avg r: 0.6224
09:45:09,199 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:46:39,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:48:09,390 root INFO Epoch 13 Global steps: 107100 Train loss: 0.1188
en_de Dev loss: 0.9338 r:0.2016
en_zh Dev loss: 0.7658 r:0.4674
ro_en Dev loss: 0.3544 r:0.8158
et_en Dev loss: 0.4577 r:0.6764
si_en Dev loss: 0.8675 r:0.5562
ne_en Dev loss: 0.5852 r:0.7043
ru_en Dev loss: 0.4407 r:0.7454
Current avg r:0.5953 Best avg r: 0.6224
09:52:37,617 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:54:07,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:55:37,822 root INFO Epoch 13 Global steps: 107800 Train loss: 0.1108
en_de Dev loss: 0.9316 r:0.2089
en_zh Dev loss: 0.7697 r:0.4744
ro_en Dev loss: 0.3464 r:0.8152
et_en Dev loss: 0.4760 r:0.6688
si_en Dev loss: 0.8101 r:0.5544
ne_en Dev loss: 0.5334 r:0.7103
ru_en Dev loss: 0.4354 r:0.7413
Current avg r:0.5962 Best avg r: 0.6224
10:00:06,90 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:01:36,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:03:06,294 root INFO Epoch 13 Global steps: 108500 Train loss: 0.1159
en_de Dev loss: 0.9448 r:0.2081
en_zh Dev loss: 0.7862 r:0.4728
ro_en Dev loss: 0.3542 r:0.8183
et_en Dev loss: 0.4693 r:0.6737
si_en Dev loss: 0.8816 r:0.5544
ne_en Dev loss: 0.5929 r:0.7060
ru_en Dev loss: 0.4565 r:0.7430
Current avg r:0.5966 Best avg r: 0.6224
10:07:34,450 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:00,182 root INFO 
id:en_zh cur r: 0.4912 best r: 0.4912
10:09:04,559 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:34,620 root INFO Epoch 13 Global steps: 109200 Train loss: 0.1122
en_de Dev loss: 0.9211 r:0.2018
en_zh Dev loss: 0.7256 r:0.4866
ro_en Dev loss: 0.3179 r:0.8193
et_en Dev loss: 0.4677 r:0.6803
si_en Dev loss: 0.7858 r:0.5577
ne_en Dev loss: 0.5320 r:0.7042
ru_en Dev loss: 0.4171 r:0.7450
Current avg r:0.5993 Best avg r: 0.6224
10:15:02,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:32,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:18:02,432 root INFO Epoch 13 Global steps: 109900 Train loss: 0.1109
en_de Dev loss: 0.9378 r:0.2013
en_zh Dev loss: 0.7920 r:0.4741
ro_en Dev loss: 0.3701 r:0.8112
et_en Dev loss: 0.4726 r:0.6595
si_en Dev loss: 0.8583 r:0.5530
ne_en Dev loss: 0.6042 r:0.7065
ru_en Dev loss: 0.4825 r:0.7242
Current avg r:0.5900 Best avg r: 0.6224
10:22:30,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:22:56,320 root INFO 
id:en_zh cur r: 0.4931 best r: 0.4931
10:24:00,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:25:30,832 root INFO Epoch 13 Global steps: 110600 Train loss: 0.1090
en_de Dev loss: 0.9424 r:0.1928
en_zh Dev loss: 0.7331 r:0.4864
ro_en Dev loss: 0.3325 r:0.8162
et_en Dev loss: 0.4714 r:0.6748
si_en Dev loss: 0.8026 r:0.5549
ne_en Dev loss: 0.5230 r:0.7105
ru_en Dev loss: 0.4064 r:0.7549
Current avg r:0.5986 Best avg r: 0.6224
10:29:58,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:31:29,107 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:32:59,150 root INFO Epoch 13 Global steps: 111300 Train loss: 0.1065
en_de Dev loss: 0.9252 r:0.1931
en_zh Dev loss: 0.7251 r:0.4888
ro_en Dev loss: 0.3126 r:0.8194
et_en Dev loss: 0.4467 r:0.6796
si_en Dev loss: 0.7650 r:0.5627
ne_en Dev loss: 0.4994 r:0.7145
ru_en Dev loss: 0.3987 r:0.7507
Current avg r:0.6013 Best avg r: 0.6224
10:37:28,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
