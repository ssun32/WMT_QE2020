14:49:23,728 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:49:49,541 root INFO 
id:en_de cur r: 0.0901 best r: 0.0901
14:50:02,442 root INFO 
id:en_zh cur r: 0.2856 best r: 0.2856
14:50:15,339 root INFO 
id:ro_en cur r: 0.6022 best r: 0.6022
14:50:28,281 root INFO 
id:et_en cur r: 0.5144 best r: 0.5144
14:50:41,250 root INFO 
id:si_en cur r: 0.4121 best r: 0.4121
14:50:54,218 root INFO 
id:ne_en cur r: 0.4837 best r: 0.4837
14:51:07,51 root INFO 
id:ru_en cur r: 0.6417 best r: 0.6417
14:51:07,51 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:52:37,512 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
14:52:37,517 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
14:52:37,522 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
14:52:37,527 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
14:52:37,532 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
14:52:37,537 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
14:52:37,542 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
14:52:50,492 root INFO Epoch 0 Global steps: 700 Train loss: 0.8454
en_de Dev loss: 0.9006 r:0.0992
en_zh Dev loss: 0.7599 r:0.2788
ro_en Dev loss: 0.5829 r:0.6294
et_en Dev loss: 0.5862 r:0.5024
si_en Dev loss: 0.7737 r:0.3954
ne_en Dev loss: 0.6190 r:0.5290
ru_en Dev loss: 0.5737 r:0.6442
Current avg r:0.4398 Best avg r: 0.4398
14:57:21,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:57:47,49 root INFO 
id:en_zh cur r: 0.2947 best r: 0.2947
14:57:59,926 root INFO 
id:ro_en cur r: 0.6371 best r: 0.6371
14:58:38,634 root INFO 
id:ne_en cur r: 0.5316 best r: 0.5316
14:58:51,451 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:00:21,627 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:00:21,633 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:00:21,637 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:00:21,643 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:00:21,652 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:00:21,658 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:00:21,663 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:00:34,588 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7470
en_de Dev loss: 0.9390 r:0.0733
en_zh Dev loss: 0.7645 r:0.2754
ro_en Dev loss: 0.5515 r:0.6465
et_en Dev loss: 0.5591 r:0.4915
si_en Dev loss: 0.7635 r:0.4131
ne_en Dev loss: 0.5737 r:0.5466
ru_en Dev loss: 0.5730 r:0.6335
Current avg r:0.4400 Best avg r: 0.4400
15:05:04,811 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:05:30,559 root INFO 
id:en_de cur r: 0.0975 best r: 0.0975
15:05:43,412 root INFO 
id:en_zh cur r: 0.3273 best r: 0.3273
15:05:56,290 root INFO 
id:ro_en cur r: 0.6542 best r: 0.6542
15:06:09,177 root INFO 
id:et_en cur r: 0.5838 best r: 0.5838
15:06:22,104 root INFO 
id:si_en cur r: 0.4630 best r: 0.4630
15:06:35,14 root INFO 
id:ne_en cur r: 0.6250 best r: 0.6250
15:06:47,842 root INFO 
id:ru_en cur r: 0.6877 best r: 0.6877
15:06:47,842 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:08:18,43 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:08:18,49 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:08:18,54 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:08:18,59 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:08:18,67 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:08:18,72 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:08:18,76 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:08:30,970 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7252
en_de Dev loss: 0.9335 r:0.1143
en_zh Dev loss: 0.7298 r:0.3399
ro_en Dev loss: 0.4846 r:0.6829
et_en Dev loss: 0.4722 r:0.6075
si_en Dev loss: 0.6755 r:0.4870
ne_en Dev loss: 0.4997 r:0.6444
ru_en Dev loss: 0.4693 r:0.7031
Current avg r:0.5113 Best avg r: 0.5113
15:13:01,136 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:13:26,897 root INFO 
id:en_de cur r: 0.1170 best r: 0.1170
15:13:39,750 root INFO 
id:en_zh cur r: 0.3293 best r: 0.3293
15:13:52,630 root INFO 
id:ro_en cur r: 0.6979 best r: 0.6979
15:14:05,521 root INFO 
id:et_en cur r: 0.5888 best r: 0.5888
15:14:31,317 root INFO 
id:ne_en cur r: 0.6310 best r: 0.6310
15:14:44,153 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:16:14,290 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:16:14,296 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:16:14,301 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:16:14,305 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:16:14,311 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:16:14,317 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:16:14,322 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:16:27,223 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6835
en_de Dev loss: 0.9570 r:0.1343
en_zh Dev loss: 0.8159 r:0.3345
ro_en Dev loss: 0.4809 r:0.7172
et_en Dev loss: 0.4663 r:0.6230
si_en Dev loss: 0.7830 r:0.4785
ne_en Dev loss: 0.4972 r:0.6433
ru_en Dev loss: 0.5684 r:0.6750
Current avg r:0.5151 Best avg r: 0.5151
15:20:57,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:21:23,353 root INFO 
id:en_de cur r: 0.1597 best r: 0.1597
15:21:36,196 root INFO 
id:en_zh cur r: 0.3381 best r: 0.3381
15:21:49,69 root INFO 
id:ro_en cur r: 0.7029 best r: 0.7029
15:22:01,960 root INFO 
id:et_en cur r: 0.6317 best r: 0.6317
15:22:14,873 root INFO 
id:si_en cur r: 0.4677 best r: 0.4677
15:22:27,770 root INFO 
id:ne_en cur r: 0.6649 best r: 0.6649
15:22:40,591 root INFO 
id:ru_en cur r: 0.7128 best r: 0.7128
15:22:40,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:24:10,639 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:24:10,645 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:24:10,650 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:24:10,654 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:24:10,660 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:24:10,665 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:24:10,670 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:24:23,556 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6524
en_de Dev loss: 0.9243 r:0.1651
en_zh Dev loss: 0.7487 r:0.3674
ro_en Dev loss: 0.4371 r:0.7286
et_en Dev loss: 0.4203 r:0.6502
si_en Dev loss: 0.6442 r:0.5117
ne_en Dev loss: 0.4728 r:0.6601
ru_en Dev loss: 0.4465 r:0.7241
Current avg r:0.5439 Best avg r: 0.5439
15:28:53,632 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:29:19,394 root INFO 
id:en_de cur r: 0.1793 best r: 0.1793
15:29:32,254 root INFO 
id:en_zh cur r: 0.3794 best r: 0.3794
15:29:45,128 root INFO 
id:ro_en cur r: 0.7163 best r: 0.7163
15:29:58,9 root INFO 
id:et_en cur r: 0.6396 best r: 0.6396
15:30:10,902 root INFO 
id:si_en cur r: 0.4826 best r: 0.4826
15:30:36,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:32:06,630 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6359
en_de Dev loss: 0.9394 r:0.1833
en_zh Dev loss: 0.7484 r:0.3880
ro_en Dev loss: 0.4825 r:0.7306
et_en Dev loss: 0.4274 r:0.6486
si_en Dev loss: 0.7588 r:0.4998
ne_en Dev loss: 0.6027 r:0.6190
ru_en Dev loss: 0.5497 r:0.7034
Current avg r:0.5390 Best avg r: 0.5439
15:36:36,858 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:37:15,441 root INFO 
id:ro_en cur r: 0.7193 best r: 0.7193
15:37:28,335 root INFO 
id:et_en cur r: 0.6533 best r: 0.6533
15:37:41,242 root INFO 
id:si_en cur r: 0.5075 best r: 0.5075
15:37:54,148 root INFO 
id:ne_en cur r: 0.6941 best r: 0.6941
15:38:06,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:39:37,40 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6465
en_de Dev loss: 0.9328 r:0.1610
en_zh Dev loss: 0.8198 r:0.3503
ro_en Dev loss: 0.4401 r:0.7289
et_en Dev loss: 0.3999 r:0.6620
si_en Dev loss: 0.6944 r:0.5174
ne_en Dev loss: 0.4861 r:0.6690
ru_en Dev loss: 0.5360 r:0.6914
Current avg r:0.5400 Best avg r: 0.5439
15:44:07,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:44:32,928 root INFO 
id:en_zh cur r: 0.4156 best r: 0.4156
15:44:45,803 root INFO 
id:ro_en cur r: 0.7629 best r: 0.7629
15:44:58,687 root INFO 
id:et_en cur r: 0.6700 best r: 0.6700
15:45:11,599 root INFO 
id:si_en cur r: 0.5234 best r: 0.5234
15:45:24,482 root INFO 
id:ne_en cur r: 0.7183 best r: 0.7183
15:45:37,298 root INFO 
id:ru_en cur r: 0.7210 best r: 0.7210
15:45:37,298 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:47:07,411 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:47:07,417 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:47:07,422 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:47:07,427 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:47:07,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:47:07,436 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:47:07,441 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:47:20,337 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6433
en_de Dev loss: 0.8951 r:0.1634
en_zh Dev loss: 0.7219 r:0.4280
ro_en Dev loss: 0.4299 r:0.7625
et_en Dev loss: 0.3810 r:0.6806
si_en Dev loss: 0.7059 r:0.5465
ne_en Dev loss: 0.5735 r:0.6874
ru_en Dev loss: 0.4753 r:0.7284
Current avg r:0.5710 Best avg r: 0.5710
15:51:50,345 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:52:16,121 root INFO 
id:en_de cur r: 0.2027 best r: 0.2027
15:52:28,963 root INFO 
id:en_zh cur r: 0.4310 best r: 0.4310
15:52:41,858 root INFO 
id:ro_en cur r: 0.7661 best r: 0.7661
15:53:07,635 root INFO 
id:si_en cur r: 0.5581 best r: 0.5581
15:53:20,542 root INFO 
id:ne_en cur r: 0.7219 best r: 0.7219
15:53:33,380 root INFO 
id:ru_en cur r: 0.7354 best r: 0.7354
15:53:33,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:55:03,456 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
15:55:03,465 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
15:55:03,471 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
15:55:03,476 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
15:55:03,481 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
15:55:03,486 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
15:55:03,491 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
15:55:16,379 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5883
en_de Dev loss: 0.8850 r:0.2043
en_zh Dev loss: 0.7042 r:0.4463
ro_en Dev loss: 0.3968 r:0.7705
et_en Dev loss: 0.3905 r:0.6777
si_en Dev loss: 0.6668 r:0.5652
ne_en Dev loss: 0.4170 r:0.7210
ru_en Dev loss: 0.4356 r:0.7463
Current avg r:0.5902 Best avg r: 0.5902
15:59:46,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:00:24,931 root INFO 
id:ro_en cur r: 0.7855 best r: 0.7855
16:01:03,591 root INFO 
id:ne_en cur r: 0.7253 best r: 0.7253
16:01:16,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:46,435 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5671
en_de Dev loss: 0.9061 r:0.1931
en_zh Dev loss: 0.7845 r:0.4148
ro_en Dev loss: 0.3681 r:0.7865
et_en Dev loss: 0.3819 r:0.6803
si_en Dev loss: 0.6651 r:0.5584
ne_en Dev loss: 0.5317 r:0.7101
ru_en Dev loss: 0.4947 r:0.7281
Current avg r:0.5816 Best avg r: 0.5902
16:07:16,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:42,146 root INFO 
id:en_de cur r: 0.2145 best r: 0.2145
16:08:07,897 root INFO 
id:ro_en cur r: 0.7890 best r: 0.7890
16:08:20,799 root INFO 
id:et_en cur r: 0.6820 best r: 0.6820
16:08:33,707 root INFO 
id:si_en cur r: 0.5609 best r: 0.5609
16:08:46,595 root INFO 
id:ne_en cur r: 0.7364 best r: 0.7364
16:08:59,424 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:29,570 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
16:10:29,577 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:10:29,582 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:10:29,588 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
16:10:29,593 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
16:10:29,598 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:10:29,602 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:10:42,479 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5576
en_de Dev loss: 0.8852 r:0.2086
en_zh Dev loss: 0.7586 r:0.4329
ro_en Dev loss: 0.3791 r:0.7876
et_en Dev loss: 0.3753 r:0.6925
si_en Dev loss: 0.6522 r:0.5674
ne_en Dev loss: 0.3956 r:0.7336
ru_en Dev loss: 0.4946 r:0.7345
Current avg r:0.5939 Best avg r: 0.5939
16:15:12,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:38,611 root INFO 
id:en_zh cur r: 0.4463 best r: 0.4463
16:15:51,483 root INFO 
id:ro_en cur r: 0.7973 best r: 0.7973
16:16:04,376 root INFO 
id:et_en cur r: 0.6978 best r: 0.6978
16:16:17,266 root INFO 
id:si_en cur r: 0.5898 best r: 0.5898
16:16:30,161 root INFO 
id:ne_en cur r: 0.7542 best r: 0.7542
16:16:42,989 root INFO 
id:ru_en cur r: 0.7527 best r: 0.7527
16:16:42,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:13,103 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
16:18:13,110 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:18:13,116 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:18:13,121 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
16:18:13,126 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
16:18:13,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:18:13,139 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:18:26,19 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5591
en_de Dev loss: 0.8617 r:0.1794
en_zh Dev loss: 0.6602 r:0.4424
ro_en Dev loss: 0.3218 r:0.7925
et_en Dev loss: 0.3542 r:0.7075
si_en Dev loss: 0.5704 r:0.5881
ne_en Dev loss: 0.3603 r:0.7509
ru_en Dev loss: 0.3779 r:0.7594
Current avg r:0.6029 Best avg r: 0.6029
16:22:56,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:24:27,272 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:25:57,749 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5419
en_de Dev loss: 0.8746 r:0.2048
en_zh Dev loss: 0.7577 r:0.4253
ro_en Dev loss: 0.3951 r:0.7867
et_en Dev loss: 0.3945 r:0.6874
si_en Dev loss: 0.6396 r:0.5715
ne_en Dev loss: 0.4395 r:0.7348
ru_en Dev loss: 0.4680 r:0.7446
Current avg r:0.5936 Best avg r: 0.6029
16:30:28,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:31:58,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:29,85 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5269
en_de Dev loss: 0.8668 r:0.2061
en_zh Dev loss: 0.7370 r:0.4276
ro_en Dev loss: 0.3377 r:0.7994
et_en Dev loss: 0.3701 r:0.6927
si_en Dev loss: 0.6558 r:0.5687
ne_en Dev loss: 0.3712 r:0.7463
ru_en Dev loss: 0.4228 r:0.7471
Current avg r:0.5983 Best avg r: 0.6029
16:37:59,469 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:39:29,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:40:59,525 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5416
en_de Dev loss: 0.8516 r:0.2011
en_zh Dev loss: 0.7127 r:0.4361
ro_en Dev loss: 0.3221 r:0.7995
et_en Dev loss: 0.3732 r:0.6907
si_en Dev loss: 0.6361 r:0.5774
ne_en Dev loss: 0.4127 r:0.7440
ru_en Dev loss: 0.4213 r:0.7433
Current avg r:0.5989 Best avg r: 0.6029
16:45:31,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:09,869 root INFO 
id:ro_en cur r: 0.7974 best r: 0.7974
16:47:01,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:48:31,397 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5127
en_de Dev loss: 0.9204 r:0.2054
en_zh Dev loss: 0.8591 r:0.4312
ro_en Dev loss: 0.4179 r:0.8006
et_en Dev loss: 0.4455 r:0.6843
si_en Dev loss: 0.9164 r:0.5516
ne_en Dev loss: 0.5141 r:0.7416
ru_en Dev loss: 0.5169 r:0.7353
Current avg r:0.5928 Best avg r: 0.6029
16:53:01,507 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:40,76 root INFO 
id:ro_en cur r: 0.8028 best r: 0.8028
16:54:18,753 root INFO 
id:ne_en cur r: 0.7584 best r: 0.7584
16:54:31,572 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:56:01,617 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
16:56:01,624 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
16:56:01,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
16:56:01,633 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
16:56:01,639 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
16:56:01,645 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
16:56:01,650 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
16:56:14,527 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5246
en_de Dev loss: 0.8501 r:0.2128
en_zh Dev loss: 0.6899 r:0.4481
ro_en Dev loss: 0.3158 r:0.8076
et_en Dev loss: 0.3646 r:0.6998
si_en Dev loss: 0.6000 r:0.5883
ne_en Dev loss: 0.3606 r:0.7572
ru_en Dev loss: 0.4020 r:0.7484
Current avg r:0.6089 Best avg r: 0.6089
17:00:44,421 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:22,971 root INFO 
id:ro_en cur r: 0.8054 best r: 0.8054
17:01:35,850 root INFO 
id:et_en cur r: 0.7042 best r: 0.7042
17:01:48,751 root INFO 
id:si_en cur r: 0.5969 best r: 0.5969
17:02:14,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:03:44,476 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
17:03:44,482 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:03:44,487 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:03:44,491 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
17:03:44,497 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
17:03:44,501 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:03:44,506 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:03:57,383 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4969
en_de Dev loss: 0.8795 r:0.2207
en_zh Dev loss: 0.7210 r:0.4463
ro_en Dev loss: 0.3430 r:0.8114
et_en Dev loss: 0.3770 r:0.7024
si_en Dev loss: 0.6860 r:0.5904
ne_en Dev loss: 0.3984 r:0.7561
ru_en Dev loss: 0.4571 r:0.7405
Current avg r:0.6097 Best avg r: 0.6097
17:08:27,62 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:52,776 root INFO 
id:en_de cur r: 0.2309 best r: 0.2309
17:09:05,609 root INFO 
id:en_zh cur r: 0.4568 best r: 0.4568
17:10:09,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:11:39,862 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
17:11:39,868 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:11:39,873 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:11:39,877 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
17:11:39,883 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
17:11:39,887 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:11:39,892 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:11:52,771 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5307
en_de Dev loss: 0.8645 r:0.2338
en_zh Dev loss: 0.7069 r:0.4586
ro_en Dev loss: 0.3703 r:0.8053
et_en Dev loss: 0.3761 r:0.6980
si_en Dev loss: 0.7283 r:0.5839
ne_en Dev loss: 0.4723 r:0.7547
ru_en Dev loss: 0.4777 r:0.7434
Current avg r:0.6111 Best avg r: 0.6111
17:16:23,1 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:53,7 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:22,980 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4897
en_de Dev loss: 0.8770 r:0.2097
en_zh Dev loss: 0.7331 r:0.4489
ro_en Dev loss: 0.3626 r:0.8035
et_en Dev loss: 0.4089 r:0.6873
si_en Dev loss: 0.7963 r:0.5766
ne_en Dev loss: 0.4430 r:0.7511
ru_en Dev loss: 0.4921 r:0.7271
Current avg r:0.6006 Best avg r: 0.6111
17:23:52,657 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:24:31,229 root INFO 
id:ro_en cur r: 0.8126 best r: 0.8126
17:25:22,759 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:26:52,783 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5443
en_de Dev loss: 0.8544 r:0.2195
en_zh Dev loss: 0.6952 r:0.4439
ro_en Dev loss: 0.3430 r:0.8122
et_en Dev loss: 0.3803 r:0.6949
si_en Dev loss: 0.7265 r:0.5911
ne_en Dev loss: 0.5187 r:0.7564
ru_en Dev loss: 0.4475 r:0.7345
Current avg r:0.6075 Best avg r: 0.6111
17:31:22,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:52,796 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:22,804 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5167
en_de Dev loss: 0.8742 r:0.2054
en_zh Dev loss: 0.7494 r:0.4324
ro_en Dev loss: 0.3402 r:0.8067
et_en Dev loss: 0.3870 r:0.6881
si_en Dev loss: 0.6831 r:0.5856
ne_en Dev loss: 0.4884 r:0.7480
ru_en Dev loss: 0.4713 r:0.7203
Current avg r:0.5981 Best avg r: 0.6111
17:38:52,909 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:39:31,487 root INFO 
id:ro_en cur r: 0.8129 best r: 0.8129
17:39:57,254 root INFO 
id:si_en cur r: 0.6072 best r: 0.6072
17:40:22,964 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:52,966 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4880
en_de Dev loss: 0.8689 r:0.2079
en_zh Dev loss: 0.7225 r:0.4388
ro_en Dev loss: 0.3289 r:0.8169
et_en Dev loss: 0.3675 r:0.7037
si_en Dev loss: 0.6013 r:0.6068
ne_en Dev loss: 0.4127 r:0.7511
ru_en Dev loss: 0.4446 r:0.7328
Current avg r:0.6083 Best avg r: 0.6111
17:46:23,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:53,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:23,26 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4961
en_de Dev loss: 0.8799 r:0.2017
en_zh Dev loss: 0.7087 r:0.4387
ro_en Dev loss: 0.3304 r:0.8104
et_en Dev loss: 0.3735 r:0.6965
si_en Dev loss: 0.6245 r:0.5987
ne_en Dev loss: 0.4455 r:0.7465
ru_en Dev loss: 0.4722 r:0.7235
Current avg r:0.6023 Best avg r: 0.6111
17:53:52,718 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:18,442 root INFO 
id:en_de cur r: 0.2318 best r: 0.2318
17:55:09,965 root INFO 
id:si_en cur r: 0.6103 best r: 0.6103
17:55:35,637 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:05,644 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
17:57:05,651 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
17:57:05,655 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
17:57:05,660 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
17:57:05,665 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
17:57:05,669 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
17:57:05,674 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
17:57:18,541 root INFO Epoch 1 Global steps: 17500 Train loss: 0.5145
en_de Dev loss: 0.8933 r:0.2227
en_zh Dev loss: 0.7755 r:0.4481
ro_en Dev loss: 0.3757 r:0.8158
et_en Dev loss: 0.3889 r:0.7061
si_en Dev loss: 0.7238 r:0.6074
ne_en Dev loss: 0.5084 r:0.7551
ru_en Dev loss: 0.4979 r:0.7417
Current avg r:0.6138 Best avg r: 0.6138
18:01:48,198 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:13,929 root INFO 
id:en_de cur r: 0.2331 best r: 0.2331
18:02:39,622 root INFO 
id:ro_en cur r: 0.8204 best r: 0.8204
18:03:05,392 root INFO 
id:si_en cur r: 0.6147 best r: 0.6147
18:03:18,274 root INFO 
id:ne_en cur r: 0.7595 best r: 0.7595
18:03:31,77 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:01,59 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4717
en_de Dev loss: 0.8774 r:0.2199
en_zh Dev loss: 0.7614 r:0.4441
ro_en Dev loss: 0.3079 r:0.8174
et_en Dev loss: 0.3801 r:0.6984
si_en Dev loss: 0.6189 r:0.6141
ne_en Dev loss: 0.3935 r:0.7543
ru_en Dev loss: 0.4399 r:0.7351
Current avg r:0.6119 Best avg r: 0.6138
18:09:31,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:09:56,855 root INFO 
id:en_de cur r: 0.2484 best r: 0.2484
18:10:09,690 root INFO 
id:en_zh cur r: 0.4620 best r: 0.4620
18:10:48,330 root INFO 
id:si_en cur r: 0.6158 best r: 0.6158
18:11:01,226 root INFO 
id:ne_en cur r: 0.7632 best r: 0.7632
18:11:14,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:44,90 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
18:12:44,97 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
18:12:44,102 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
18:12:44,107 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
18:12:44,113 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
18:12:44,117 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
18:12:44,122 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
18:12:57,0 root INFO Epoch 1 Global steps: 18900 Train loss: 0.5090
en_de Dev loss: 0.8398 r:0.2411
en_zh Dev loss: 0.6759 r:0.4595
ro_en Dev loss: 0.3043 r:0.8188
et_en Dev loss: 0.3836 r:0.6997
si_en Dev loss: 0.5459 r:0.6170
ne_en Dev loss: 0.3780 r:0.7623
ru_en Dev loss: 0.3861 r:0.7507
Current avg r:0.6213 Best avg r: 0.6213
18:17:27,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:57,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:27,138 root INFO Epoch 1 Global steps: 19600 Train loss: 0.5049
en_de Dev loss: 0.8557 r:0.2230
en_zh Dev loss: 0.7253 r:0.4533
ro_en Dev loss: 0.3855 r:0.8158
et_en Dev loss: 0.4008 r:0.6964
si_en Dev loss: 0.7925 r:0.6056
ne_en Dev loss: 0.5562 r:0.7531
ru_en Dev loss: 0.5354 r:0.7245
Current avg r:0.6103 Best avg r: 0.6213
18:24:56,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:26:26,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:56,739 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4867
en_de Dev loss: 0.8564 r:0.2138
en_zh Dev loss: 0.7587 r:0.4330
ro_en Dev loss: 0.3759 r:0.8098
et_en Dev loss: 0.3908 r:0.6871
si_en Dev loss: 0.7820 r:0.5949
ne_en Dev loss: 0.4192 r:0.7572
ru_en Dev loss: 0.5234 r:0.7056
Current avg r:0.6002 Best avg r: 0.6213
18:32:26,352 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:56,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:35:26,416 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4658
en_de Dev loss: 0.8499 r:0.2163
en_zh Dev loss: 0.7188 r:0.4475
ro_en Dev loss: 0.3454 r:0.8141
et_en Dev loss: 0.3919 r:0.6927
si_en Dev loss: 0.7027 r:0.5995
ne_en Dev loss: 0.4098 r:0.7497
ru_en Dev loss: 0.4774 r:0.7237
Current avg r:0.6062 Best avg r: 0.6213
18:39:57,375 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:41:27,326 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:57,297 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4469
en_de Dev loss: 0.8381 r:0.2387
en_zh Dev loss: 0.6941 r:0.4605
ro_en Dev loss: 0.3109 r:0.8177
et_en Dev loss: 0.4009 r:0.6906
si_en Dev loss: 0.6204 r:0.6096
ne_en Dev loss: 0.3823 r:0.7576
ru_en Dev loss: 0.4282 r:0.7321
Current avg r:0.6153 Best avg r: 0.6213
18:47:26,933 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:48:56,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:26,823 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4461
en_de Dev loss: 0.8483 r:0.2328
en_zh Dev loss: 0.7102 r:0.4495
ro_en Dev loss: 0.3377 r:0.8163
et_en Dev loss: 0.4013 r:0.6840
si_en Dev loss: 0.6989 r:0.5895
ne_en Dev loss: 0.4222 r:0.7531
ru_en Dev loss: 0.4760 r:0.7153
Current avg r:0.6058 Best avg r: 0.6213
18:54:56,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:26,374 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:56,264 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4455
en_de Dev loss: 0.8802 r:0.2277
en_zh Dev loss: 0.8351 r:0.4335
ro_en Dev loss: 0.4347 r:0.8092
et_en Dev loss: 0.4475 r:0.6735
si_en Dev loss: 0.9789 r:0.5637
ne_en Dev loss: 0.7347 r:0.7411
ru_en Dev loss: 0.6181 r:0.6951
Current avg r:0.5920 Best avg r: 0.6213
19:02:25,826 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:03:55,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:25,827 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4337
en_de Dev loss: 0.8725 r:0.2288
en_zh Dev loss: 0.7895 r:0.4252
ro_en Dev loss: 0.3414 r:0.8165
et_en Dev loss: 0.4050 r:0.6857
si_en Dev loss: 0.6960 r:0.5909
ne_en Dev loss: 0.4500 r:0.7566
ru_en Dev loss: 0.5407 r:0.6973
Current avg r:0.6001 Best avg r: 0.6213
19:09:55,908 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:11:13,99 root INFO 
id:ne_en cur r: 0.7695 best r: 0.7695
19:11:25,902 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:12:55,862 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4342
en_de Dev loss: 0.8456 r:0.2246
en_zh Dev loss: 0.7114 r:0.4481
ro_en Dev loss: 0.3239 r:0.8224
et_en Dev loss: 0.3875 r:0.6934
si_en Dev loss: 0.6863 r:0.6082
ne_en Dev loss: 0.3856 r:0.7685
ru_en Dev loss: 0.4708 r:0.7177
Current avg r:0.6118 Best avg r: 0.6213
19:17:25,816 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:18:04,371 root INFO 
id:ro_en cur r: 0.8212 best r: 0.8212
19:18:55,791 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:25,696 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4681
en_de Dev loss: 0.8428 r:0.2384
en_zh Dev loss: 0.7380 r:0.4431
ro_en Dev loss: 0.3308 r:0.8216
et_en Dev loss: 0.3899 r:0.6934
si_en Dev loss: 0.7067 r:0.6027
ne_en Dev loss: 0.4253 r:0.7675
ru_en Dev loss: 0.4746 r:0.7183
Current avg r:0.6121 Best avg r: 0.6213
19:24:55,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:21,317 root INFO 
id:en_de cur r: 0.2650 best r: 0.2650
19:26:38,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:08,490 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4380
en_de Dev loss: 0.8537 r:0.2326
en_zh Dev loss: 0.7701 r:0.4422
ro_en Dev loss: 0.3493 r:0.8191
et_en Dev loss: 0.3950 r:0.6903
si_en Dev loss: 0.7823 r:0.5922
ne_en Dev loss: 0.4535 r:0.7620
ru_en Dev loss: 0.4865 r:0.7209
Current avg r:0.6085 Best avg r: 0.6213
19:32:38,371 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:33:04,76 root INFO 
id:en_zh cur r: 0.4671 best r: 0.4671
19:33:55,583 root INFO 
id:ne_en cur r: 0.7705 best r: 0.7705
19:34:08,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:38,375 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4713
en_de Dev loss: 0.8652 r:0.2550
en_zh Dev loss: 0.7613 r:0.4630
ro_en Dev loss: 0.3484 r:0.8207
et_en Dev loss: 0.3909 r:0.6958
si_en Dev loss: 0.7501 r:0.6100
ne_en Dev loss: 0.4523 r:0.7675
ru_en Dev loss: 0.4925 r:0.7283
Current avg r:0.6201 Best avg r: 0.6213
19:40:08,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:40:34,132 root INFO 
id:en_de cur r: 0.2655 best r: 0.2655
19:40:46,969 root INFO 
id:en_zh cur r: 0.4699 best r: 0.4699
19:40:59,828 root INFO 
id:ro_en cur r: 0.8265 best r: 0.8265
19:41:51,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:21,213 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
19:43:21,219 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
19:43:21,227 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
19:43:21,232 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
19:43:21,236 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
19:43:21,241 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
19:43:21,245 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
19:43:34,101 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4592
en_de Dev loss: 0.8479 r:0.2596
en_zh Dev loss: 0.7112 r:0.4671
ro_en Dev loss: 0.3042 r:0.8285
et_en Dev loss: 0.3705 r:0.7029
si_en Dev loss: 0.7105 r:0.6142
ne_en Dev loss: 0.3996 r:0.7607
ru_en Dev loss: 0.4890 r:0.7224
Current avg r:0.6222 Best avg r: 0.6222
19:48:04,23 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:42,566 root INFO 
id:ro_en cur r: 0.8297 best r: 0.8297
19:49:08,357 root INFO 
id:si_en cur r: 0.6168 best r: 0.6168
19:49:34,76 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:04,380 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4707
en_de Dev loss: 0.8571 r:0.2445
en_zh Dev loss: 0.7730 r:0.4625
ro_en Dev loss: 0.3666 r:0.8300
et_en Dev loss: 0.3870 r:0.7074
si_en Dev loss: 0.7576 r:0.6204
ne_en Dev loss: 0.4865 r:0.7550
ru_en Dev loss: 0.5357 r:0.7246
Current avg r:0.6206 Best avg r: 0.6222
19:55:35,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:56:00,787 root INFO 
id:en_de cur r: 0.2756 best r: 0.2756
19:57:18,121 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:48,476 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4449
en_de Dev loss: 0.8336 r:0.2688
en_zh Dev loss: 0.7263 r:0.4543
ro_en Dev loss: 0.3220 r:0.8262
et_en Dev loss: 0.3825 r:0.7021
si_en Dev loss: 0.6746 r:0.6171
ne_en Dev loss: 0.4246 r:0.7529
ru_en Dev loss: 0.4469 r:0.7269
Current avg r:0.6212 Best avg r: 0.6222
20:03:18,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:03:44,792 root INFO 
id:en_de cur r: 0.2834 best r: 0.2834
20:04:23,510 root INFO 
id:et_en cur r: 0.7055 best r: 0.7055
20:04:36,458 root INFO 
id:si_en cur r: 0.6194 best r: 0.6194
20:05:02,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:32,579 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
20:06:32,586 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
20:06:32,590 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
20:06:32,595 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
20:06:32,600 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
20:06:32,605 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
20:06:32,609 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
20:06:45,547 root INFO Epoch 2 Global steps: 29400 Train loss: 0.4309
en_de Dev loss: 0.8454 r:0.2784
en_zh Dev loss: 0.7560 r:0.4505
ro_en Dev loss: 0.3250 r:0.8255
et_en Dev loss: 0.3695 r:0.7047
si_en Dev loss: 0.7359 r:0.6176
ne_en Dev loss: 0.4105 r:0.7604
ru_en Dev loss: 0.4530 r:0.7277
Current avg r:0.6235 Best avg r: 0.6235
20:11:15,780 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:46,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:14:16,379 root INFO Epoch 2 Global steps: 30100 Train loss: 0.4162
en_de Dev loss: 0.8467 r:0.2753
en_zh Dev loss: 0.7583 r:0.4438
ro_en Dev loss: 0.3382 r:0.8211
et_en Dev loss: 0.3810 r:0.7012
si_en Dev loss: 0.6615 r:0.6160
ne_en Dev loss: 0.3935 r:0.7595
ru_en Dev loss: 0.4478 r:0.7300
Current avg r:0.6210 Best avg r: 0.6235
20:18:46,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:51,74 root INFO 
id:si_en cur r: 0.6201 best r: 0.6201
20:20:16,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:47,241 root INFO Epoch 2 Global steps: 30800 Train loss: 0.4219
en_de Dev loss: 0.8476 r:0.2543
en_zh Dev loss: 0.7354 r:0.4443
ro_en Dev loss: 0.3401 r:0.8230
et_en Dev loss: 0.3852 r:0.6937
si_en Dev loss: 0.6387 r:0.6160
ne_en Dev loss: 0.4272 r:0.7606
ru_en Dev loss: 0.4938 r:0.7080
Current avg r:0.6143 Best avg r: 0.6235
20:26:17,639 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:26:43,367 root INFO 
id:en_zh cur r: 0.4744 best r: 0.4744
20:27:22,175 root INFO 
id:si_en cur r: 0.6248 best r: 0.6248
20:27:47,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:29:18,343 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
20:29:18,349 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
20:29:18,357 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
20:29:18,361 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
20:29:18,366 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
20:29:18,372 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
20:29:18,378 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
20:29:31,320 root INFO Epoch 2 Global steps: 31500 Train loss: 0.4357
en_de Dev loss: 0.8255 r:0.2704
en_zh Dev loss: 0.6800 r:0.4693
ro_en Dev loss: 0.2849 r:0.8290
et_en Dev loss: 0.3752 r:0.7069
si_en Dev loss: 0.6053 r:0.6211
ne_en Dev loss: 0.3510 r:0.7573
ru_en Dev loss: 0.4261 r:0.7264
Current avg r:0.6258 Best avg r: 0.6258
20:34:03,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:35:33,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:37:03,753 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_de.lang_agnost_mlp.dev.best.scores
20:37:03,759 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/en_zh.lang_agnost_mlp.dev.best.scores
20:37:03,764 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ro_en.lang_agnost_mlp.dev.best.scores
20:37:03,768 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/et_en.lang_agnost_mlp.dev.best.scores
20:37:03,773 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/si_en.lang_agnost_mlp.dev.best.scores
20:37:03,777 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ne_en.lang_agnost_mlp.dev.best.scores
20:37:03,782 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run1/ru_en.lang_agnost_mlp.dev.best.scores
20:37:16,724 root INFO Epoch 3 Global steps: 32200 Train loss: 0.4172
en_de Dev loss: 0.8334 r:0.2724
en_zh Dev loss: 0.7413 r:0.4573
ro_en Dev loss: 0.3329 r:0.8275
et_en Dev loss: 0.3894 r:0.7053
si_en Dev loss: 0.7042 r:0.6138
ne_en Dev loss: 0.3988 r:0.7647
ru_en Dev loss: 0.4255 r:0.7442
Current avg r:0.6265 Best avg r: 0.6265
20:41:47,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:43:17,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:47,866 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3837
en_de Dev loss: 0.8506 r:0.2402
en_zh Dev loss: 0.7512 r:0.4413
ro_en Dev loss: 0.3105 r:0.8287
et_en Dev loss: 0.3897 r:0.6980
si_en Dev loss: 0.6533 r:0.6152
ne_en Dev loss: 0.4065 r:0.7573
ru_en Dev loss: 0.4879 r:0.7108
Current avg r:0.6131 Best avg r: 0.6265
20:49:18,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:48,751 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:52:19,140 root INFO Epoch 3 Global steps: 33600 Train loss: 0.4122
en_de Dev loss: 0.8429 r:0.2510
en_zh Dev loss: 0.7305 r:0.4515
ro_en Dev loss: 0.3630 r:0.8235
et_en Dev loss: 0.3847 r:0.7014
si_en Dev loss: 0.7107 r:0.6200
ne_en Dev loss: 0.4602 r:0.7523
ru_en Dev loss: 0.4852 r:0.7222
Current avg r:0.6174 Best avg r: 0.6265
20:56:49,354 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:58:19,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:49,970 root INFO Epoch 3 Global steps: 34300 Train loss: 0.4047
en_de Dev loss: 0.8603 r:0.2374
en_zh Dev loss: 0.7910 r:0.4304
ro_en Dev loss: 0.3321 r:0.8190
et_en Dev loss: 0.4043 r:0.6918
si_en Dev loss: 0.7134 r:0.6068
ne_en Dev loss: 0.4131 r:0.7470
ru_en Dev loss: 0.4541 r:0.7263
Current avg r:0.6084 Best avg r: 0.6265
21:04:20,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:50,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:07:20,733 root INFO Epoch 3 Global steps: 35000 Train loss: 0.4055
en_de Dev loss: 0.8424 r:0.2391
en_zh Dev loss: 0.7724 r:0.4467
ro_en Dev loss: 0.3260 r:0.8217
et_en Dev loss: 0.3858 r:0.6916
si_en Dev loss: 0.6827 r:0.6088
ne_en Dev loss: 0.5013 r:0.7559
ru_en Dev loss: 0.4637 r:0.7189
Current avg r:0.6118 Best avg r: 0.6265
21:11:50,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:13:21,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:51,496 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3891
en_de Dev loss: 0.8513 r:0.2285
en_zh Dev loss: 0.7630 r:0.4532
ro_en Dev loss: 0.3677 r:0.8184
et_en Dev loss: 0.4043 r:0.6942
si_en Dev loss: 0.7588 r:0.6069
ne_en Dev loss: 0.4115 r:0.7560
ru_en Dev loss: 0.4805 r:0.7218
Current avg r:0.6113 Best avg r: 0.6265
21:19:22,69 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:52,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:22:22,767 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3944
en_de Dev loss: 0.8396 r:0.2528
en_zh Dev loss: 0.7460 r:0.4529
ro_en Dev loss: 0.3455 r:0.8233
et_en Dev loss: 0.3922 r:0.6970
si_en Dev loss: 0.7137 r:0.6160
ne_en Dev loss: 0.4035 r:0.7622
ru_en Dev loss: 0.4720 r:0.7220
Current avg r:0.6180 Best avg r: 0.6265
21:26:53,189 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:28:23,423 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:53,745 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3651
en_de Dev loss: 0.8871 r:0.2511
en_zh Dev loss: 0.7873 r:0.4398
ro_en Dev loss: 0.3558 r:0.8176
et_en Dev loss: 0.3994 r:0.6875
si_en Dev loss: 0.7423 r:0.6035
ne_en Dev loss: 0.5197 r:0.7644
ru_en Dev loss: 0.5103 r:0.7051
Current avg r:0.6099 Best avg r: 0.6265
21:34:23,903 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:54,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:37:24,397 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3970
en_de Dev loss: 0.8715 r:0.2031
en_zh Dev loss: 0.7753 r:0.4548
ro_en Dev loss: 0.3594 r:0.8228
et_en Dev loss: 0.4059 r:0.6932
si_en Dev loss: 0.6876 r:0.6157
ne_en Dev loss: 0.4415 r:0.7579
ru_en Dev loss: 0.5094 r:0.7071
Current avg r:0.6078 Best avg r: 0.6265
21:41:54,719 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:43:24,999 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:55,403 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3547
en_de Dev loss: 0.8662 r:0.2510
en_zh Dev loss: 0.7556 r:0.4589
ro_en Dev loss: 0.3762 r:0.8169
et_en Dev loss: 0.4294 r:0.6812
si_en Dev loss: 0.9054 r:0.5909
ne_en Dev loss: 0.4967 r:0.7549
ru_en Dev loss: 0.4940 r:0.7169
Current avg r:0.6101 Best avg r: 0.6265
21:49:25,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:49:51,670 root INFO 
id:en_zh cur r: 0.4817 best r: 0.4817
21:50:56,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:26,657 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3976
en_de Dev loss: 0.8306 r:0.2533
en_zh Dev loss: 0.6964 r:0.4705
ro_en Dev loss: 0.3157 r:0.8261
et_en Dev loss: 0.4470 r:0.6991
si_en Dev loss: 0.5985 r:0.6198
ne_en Dev loss: 0.3660 r:0.7552
ru_en Dev loss: 0.3894 r:0.7449
Current avg r:0.6241 Best avg r: 0.6265
21:56:57,295 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:27,645 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:58,95 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3695
en_de Dev loss: 0.8717 r:0.2481
en_zh Dev loss: 0.7661 r:0.4518
ro_en Dev loss: 0.3644 r:0.8190
et_en Dev loss: 0.4141 r:0.6812
si_en Dev loss: 0.7074 r:0.6001
ne_en Dev loss: 0.4648 r:0.7542
ru_en Dev loss: 0.4810 r:0.7193
Current avg r:0.6105 Best avg r: 0.6265
22:04:28,853 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:59,228 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:29,719 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3760
en_de Dev loss: 0.8330 r:0.2626
en_zh Dev loss: 0.7644 r:0.4422
ro_en Dev loss: 0.3757 r:0.8170
et_en Dev loss: 0.4140 r:0.6870
si_en Dev loss: 0.7665 r:0.5929
ne_en Dev loss: 0.4745 r:0.7526
ru_en Dev loss: 0.4879 r:0.7133
Current avg r:0.6097 Best avg r: 0.6265
22:12:00,423 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:30,775 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:15:01,166 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3855
en_de Dev loss: 0.8602 r:0.2357
en_zh Dev loss: 0.7879 r:0.4417
ro_en Dev loss: 0.3687 r:0.8178
et_en Dev loss: 0.4095 r:0.6892
si_en Dev loss: 0.8785 r:0.5881
ne_en Dev loss: 0.5637 r:0.7493
ru_en Dev loss: 0.5351 r:0.7072
Current avg r:0.6041 Best avg r: 0.6265
22:19:31,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:21:02,204 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:32,653 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3915
en_de Dev loss: 0.8608 r:0.2487
en_zh Dev loss: 0.7755 r:0.4497
ro_en Dev loss: 0.3637 r:0.8205
et_en Dev loss: 0.4099 r:0.7013
si_en Dev loss: 0.7478 r:0.6061
ne_en Dev loss: 0.3990 r:0.7561
ru_en Dev loss: 0.4796 r:0.7359
Current avg r:0.6169 Best avg r: 0.6265
22:27:04,589 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:34,876 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:30:05,313 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3422
en_de Dev loss: 0.8429 r:0.2577
en_zh Dev loss: 0.8333 r:0.4351
ro_en Dev loss: 0.3589 r:0.8159
et_en Dev loss: 0.4290 r:0.6982
si_en Dev loss: 0.7190 r:0.6065
ne_en Dev loss: 0.4087 r:0.7445
ru_en Dev loss: 0.5127 r:0.7232
Current avg r:0.6116 Best avg r: 0.6265
22:34:35,887 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:36:06,229 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:36,653 root INFO Epoch 4 Global steps: 43400 Train loss: 0.3660
en_de Dev loss: 0.8477 r:0.2343
en_zh Dev loss: 0.7737 r:0.4410
ro_en Dev loss: 0.3447 r:0.8197
et_en Dev loss: 0.4039 r:0.6905
si_en Dev loss: 0.8088 r:0.6062
ne_en Dev loss: 0.5288 r:0.7437
ru_en Dev loss: 0.4857 r:0.7161
Current avg r:0.6074 Best avg r: 0.6265
22:42:07,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:37,539 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:45:07,960 root INFO Epoch 4 Global steps: 44100 Train loss: 0.3417
en_de Dev loss: 0.8605 r:0.2566
en_zh Dev loss: 0.7733 r:0.4425
ro_en Dev loss: 0.3560 r:0.8126
et_en Dev loss: 0.4248 r:0.6823
si_en Dev loss: 0.6977 r:0.6016
ne_en Dev loss: 0.4199 r:0.7492
ru_en Dev loss: 0.5007 r:0.7087
Current avg r:0.6076 Best avg r: 0.6265
22:49:38,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:51:08,890 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:39,260 root INFO Epoch 4 Global steps: 44800 Train loss: 0.3353
en_de Dev loss: 0.8260 r:0.2808
en_zh Dev loss: 0.7498 r:0.4536
ro_en Dev loss: 0.3206 r:0.8193
et_en Dev loss: 0.4121 r:0.6836
si_en Dev loss: 0.6835 r:0.6132
ne_en Dev loss: 0.4297 r:0.7416
ru_en Dev loss: 0.4734 r:0.7197
Current avg r:0.6160 Best avg r: 0.6265
22:57:09,929 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:35,775 root INFO 
id:en_de cur r: 0.3001 best r: 0.3001
22:58:53,214 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:00:23,578 root INFO Epoch 4 Global steps: 45500 Train loss: 0.3285
en_de Dev loss: 0.8362 r:0.2781
en_zh Dev loss: 0.8118 r:0.4386
ro_en Dev loss: 0.3400 r:0.8152
et_en Dev loss: 0.4112 r:0.6764
si_en Dev loss: 0.8035 r:0.5946
ne_en Dev loss: 0.5824 r:0.7422
ru_en Dev loss: 0.5033 r:0.7057
Current avg r:0.6073 Best avg r: 0.6265
23:04:54,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:06:24,370 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:54,746 root INFO Epoch 4 Global steps: 46200 Train loss: 0.3237
en_de Dev loss: 0.8577 r:0.2577
en_zh Dev loss: 0.8238 r:0.4381
ro_en Dev loss: 0.3460 r:0.8205
et_en Dev loss: 0.4230 r:0.6803
si_en Dev loss: 0.7689 r:0.6034
ne_en Dev loss: 0.5406 r:0.7456
ru_en Dev loss: 0.5200 r:0.7140
Current avg r:0.6085 Best avg r: 0.6265
23:12:25,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:55,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:15:25,600 root INFO Epoch 4 Global steps: 46900 Train loss: 0.3486
en_de Dev loss: 0.8338 r:0.2596
en_zh Dev loss: 0.7192 r:0.4623
ro_en Dev loss: 0.3167 r:0.8176
et_en Dev loss: 0.4282 r:0.6846
si_en Dev loss: 0.6186 r:0.6104
ne_en Dev loss: 0.3838 r:0.7473
ru_en Dev loss: 0.4355 r:0.7340
Current avg r:0.6165 Best avg r: 0.6265
23:19:55,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:21:26,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:56,577 root INFO Epoch 4 Global steps: 47600 Train loss: 0.3308
en_de Dev loss: 0.8440 r:0.2298
en_zh Dev loss: 0.7826 r:0.4368
ro_en Dev loss: 0.3381 r:0.8190
et_en Dev loss: 0.4405 r:0.6807
si_en Dev loss: 0.7346 r:0.5989
ne_en Dev loss: 0.4583 r:0.7484
ru_en Dev loss: 0.4428 r:0.7279
Current avg r:0.6059 Best avg r: 0.6265
23:27:26,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:57,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:30:27,600 root INFO Epoch 4 Global steps: 48300 Train loss: 0.3358
en_de Dev loss: 0.8485 r:0.2411
en_zh Dev loss: 0.7630 r:0.4343
ro_en Dev loss: 0.3028 r:0.8233
et_en Dev loss: 0.4190 r:0.6860
si_en Dev loss: 0.6727 r:0.6084
ne_en Dev loss: 0.3949 r:0.7480
ru_en Dev loss: 0.4170 r:0.7359
Current avg r:0.6110 Best avg r: 0.6265
23:34:57,786 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:27,991 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:58,276 root INFO Epoch 4 Global steps: 49000 Train loss: 0.3415
en_de Dev loss: 0.8442 r:0.2585
en_zh Dev loss: 0.7781 r:0.4427
ro_en Dev loss: 0.3322 r:0.8231
et_en Dev loss: 0.4453 r:0.6788
si_en Dev loss: 0.7281 r:0.6072
ne_en Dev loss: 0.3914 r:0.7516
ru_en Dev loss: 0.4671 r:0.7210
Current avg r:0.6118 Best avg r: 0.6265
23:42:28,264 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:58,447 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:28,781 root INFO Epoch 4 Global steps: 49700 Train loss: 0.3422
en_de Dev loss: 0.8603 r:0.2633
en_zh Dev loss: 0.8779 r:0.4261
ro_en Dev loss: 0.3797 r:0.8197
et_en Dev loss: 0.4495 r:0.6748
si_en Dev loss: 0.8555 r:0.5972
ne_en Dev loss: 0.5268 r:0.7438
ru_en Dev loss: 0.4824 r:0.7251
Current avg r:0.6071 Best avg r: 0.6265
23:49:59,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:29,623 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:59,970 root INFO Epoch 4 Global steps: 50400 Train loss: 0.3297
en_de Dev loss: 0.8507 r:0.2462
en_zh Dev loss: 0.7770 r:0.4398
ro_en Dev loss: 0.3405 r:0.8203
et_en Dev loss: 0.4251 r:0.6736
si_en Dev loss: 0.7935 r:0.5903
ne_en Dev loss: 0.5022 r:0.7445
ru_en Dev loss: 0.4957 r:0.7089
Current avg r:0.6034 Best avg r: 0.6265
23:57:30,799 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:59:01,123 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:31,514 root INFO Epoch 4 Global steps: 51100 Train loss: 0.3318
en_de Dev loss: 0.8584 r:0.2526
en_zh Dev loss: 0.8639 r:0.4373
ro_en Dev loss: 0.4007 r:0.8180
et_en Dev loss: 0.4689 r:0.6717
si_en Dev loss: 0.9222 r:0.5896
ne_en Dev loss: 0.5234 r:0.7450
ru_en Dev loss: 0.5683 r:0.7071
Current avg r:0.6030 Best avg r: 0.6265
00:05:01,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:06:32,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:08:02,739 root INFO Epoch 4 Global steps: 51800 Train loss: 0.3292
en_de Dev loss: 0.8618 r:0.2338
en_zh Dev loss: 0.8955 r:0.4255
ro_en Dev loss: 0.4025 r:0.8134
et_en Dev loss: 0.4580 r:0.6703
si_en Dev loss: 0.9249 r:0.5842
ne_en Dev loss: 0.5044 r:0.7456
ru_en Dev loss: 0.5166 r:0.7187
Current avg r:0.5988 Best avg r: 0.6265
00:12:33,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:14:03,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:33,977 root INFO Epoch 4 Global steps: 52500 Train loss: 0.3150
en_de Dev loss: 0.8705 r:0.2346
en_zh Dev loss: 0.7728 r:0.4342
ro_en Dev loss: 0.3393 r:0.8206
et_en Dev loss: 0.4240 r:0.6787
si_en Dev loss: 0.7635 r:0.5952
ne_en Dev loss: 0.3789 r:0.7551
ru_en Dev loss: 0.4596 r:0.7284
Current avg r:0.6067 Best avg r: 0.6265
00:20:06,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:21:36,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:23:06,704 root INFO Epoch 5 Global steps: 53200 Train loss: 0.3024
en_de Dev loss: 0.8471 r:0.2456
en_zh Dev loss: 0.7938 r:0.4252
ro_en Dev loss: 0.3688 r:0.8121
et_en Dev loss: 0.4302 r:0.6683
si_en Dev loss: 0.8577 r:0.5773
ne_en Dev loss: 0.6154 r:0.7422
ru_en Dev loss: 0.5018 r:0.7006
Current avg r:0.5959 Best avg r: 0.6265
00:27:37,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:29:07,408 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:37,669 root INFO Epoch 5 Global steps: 53900 Train loss: 0.3050
en_de Dev loss: 0.8623 r:0.2278
en_zh Dev loss: 0.8060 r:0.4412
ro_en Dev loss: 0.3733 r:0.8116
et_en Dev loss: 0.4717 r:0.6665
si_en Dev loss: 0.7951 r:0.5861
ne_en Dev loss: 0.4604 r:0.7417
ru_en Dev loss: 0.4960 r:0.7080
Current avg r:0.5975 Best avg r: 0.6265
00:35:07,595 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:37,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:38:08,75 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2827
en_de Dev loss: 0.9022 r:0.1988
en_zh Dev loss: 0.9349 r:0.4217
ro_en Dev loss: 0.4326 r:0.8113
et_en Dev loss: 0.4812 r:0.6676
si_en Dev loss: 0.9446 r:0.5868
ne_en Dev loss: 0.5342 r:0.7462
ru_en Dev loss: 0.5594 r:0.7105
Current avg r:0.5919 Best avg r: 0.6265
00:42:38,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:44:08,192 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:38,345 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2733
en_de Dev loss: 0.8822 r:0.2040
en_zh Dev loss: 0.8819 r:0.4220
ro_en Dev loss: 0.3612 r:0.8161
et_en Dev loss: 0.4464 r:0.6701
si_en Dev loss: 0.8554 r:0.5900
ne_en Dev loss: 0.4649 r:0.7410
ru_en Dev loss: 0.5672 r:0.6955
Current avg r:0.5912 Best avg r: 0.6265
00:50:08,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:38,683 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:53:09,27 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2899
en_de Dev loss: 0.8718 r:0.2086
en_zh Dev loss: 0.8063 r:0.4319
ro_en Dev loss: 0.3489 r:0.8148
et_en Dev loss: 0.4383 r:0.6697
si_en Dev loss: 0.7555 r:0.5956
ne_en Dev loss: 0.5384 r:0.7394
ru_en Dev loss: 0.5418 r:0.6909
Current avg r:0.5930 Best avg r: 0.6265
00:57:38,884 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:59:09,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:00:39,297 root INFO Epoch 5 Global steps: 56700 Train loss: 0.3023
en_de Dev loss: 0.8759 r:0.2292
en_zh Dev loss: 0.8329 r:0.4373
ro_en Dev loss: 0.3687 r:0.8138
et_en Dev loss: 0.4624 r:0.6718
si_en Dev loss: 0.8149 r:0.5881
ne_en Dev loss: 0.4913 r:0.7366
ru_en Dev loss: 0.4985 r:0.7142
Current avg r:0.5987 Best avg r: 0.6265
01:05:09,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:39,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:08:09,780 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2867
en_de Dev loss: 0.8663 r:0.2286
en_zh Dev loss: 0.7733 r:0.4383
ro_en Dev loss: 0.3387 r:0.8163
et_en Dev loss: 0.4456 r:0.6749
si_en Dev loss: 0.6942 r:0.5993
ne_en Dev loss: 0.4418 r:0.7399
ru_en Dev loss: 0.4506 r:0.7264
Current avg r:0.6034 Best avg r: 0.6265
01:12:39,681 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:09,897 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:40,189 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2823
en_de Dev loss: 0.8575 r:0.2094
en_zh Dev loss: 0.7852 r:0.4296
ro_en Dev loss: 0.3315 r:0.8153
et_en Dev loss: 0.4303 r:0.6674
si_en Dev loss: 0.7620 r:0.5924
ne_en Dev loss: 0.5247 r:0.7455
ru_en Dev loss: 0.4780 r:0.7096
Current avg r:0.5956 Best avg r: 0.6265
01:20:10,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:40,408 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:10,584 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2861
en_de Dev loss: 0.8708 r:0.2242
en_zh Dev loss: 0.8395 r:0.4273
ro_en Dev loss: 0.3711 r:0.8154
et_en Dev loss: 0.4640 r:0.6678
si_en Dev loss: 0.7909 r:0.5936
ne_en Dev loss: 0.4712 r:0.7396
ru_en Dev loss: 0.5048 r:0.7141
Current avg r:0.5974 Best avg r: 0.6265
01:27:40,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:10,940 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:41,268 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2919
en_de Dev loss: 0.8592 r:0.2157
en_zh Dev loss: 0.8042 r:0.4320
ro_en Dev loss: 0.3699 r:0.8119
et_en Dev loss: 0.4553 r:0.6636
si_en Dev loss: 0.8822 r:0.5849
ne_en Dev loss: 0.6157 r:0.7302
ru_en Dev loss: 0.4767 r:0.7199
Current avg r:0.5940 Best avg r: 0.6265
01:35:11,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:36:41,490 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:11,702 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2786
en_de Dev loss: 0.8785 r:0.2184
en_zh Dev loss: 0.8164 r:0.4367
ro_en Dev loss: 0.3616 r:0.8102
et_en Dev loss: 0.4625 r:0.6698
si_en Dev loss: 0.7816 r:0.5876
ne_en Dev loss: 0.4365 r:0.7395
ru_en Dev loss: 0.4823 r:0.7230
Current avg r:0.5979 Best avg r: 0.6265
01:42:41,839 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:12,67 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:42,385 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2701
en_de Dev loss: 0.8948 r:0.2135
en_zh Dev loss: 0.8990 r:0.4228
ro_en Dev loss: 0.3942 r:0.8082
et_en Dev loss: 0.4722 r:0.6603
si_en Dev loss: 1.0073 r:0.5682
ne_en Dev loss: 0.7638 r:0.7256
ru_en Dev loss: 0.5704 r:0.7004
Current avg r:0.5856 Best avg r: 0.6265
01:50:12,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:42,930 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:53:13,290 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2920
en_de Dev loss: 0.8662 r:0.2395
en_zh Dev loss: 0.8319 r:0.4401
ro_en Dev loss: 0.3347 r:0.8204
et_en Dev loss: 0.4484 r:0.6752
si_en Dev loss: 0.7720 r:0.5919
ne_en Dev loss: 0.4775 r:0.7331
ru_en Dev loss: 0.4524 r:0.7378
Current avg r:0.6054 Best avg r: 0.6265
01:57:43,582 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:59:14,923 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:46,646 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2827
en_de Dev loss: 0.8759 r:0.2194
en_zh Dev loss: 0.8580 r:0.4257
ro_en Dev loss: 0.3839 r:0.8092
et_en Dev loss: 0.4715 r:0.6548
si_en Dev loss: 0.9564 r:0.5706
ne_en Dev loss: 0.6777 r:0.7331
ru_en Dev loss: 0.5157 r:0.7124
Current avg r:0.5893 Best avg r: 0.6265
02:05:22,49 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:53,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:08:25,389 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2960
en_de Dev loss: 0.8740 r:0.2183
en_zh Dev loss: 0.8684 r:0.4314
ro_en Dev loss: 0.4083 r:0.8112
et_en Dev loss: 0.4740 r:0.6648
si_en Dev loss: 0.9308 r:0.5844
ne_en Dev loss: 0.5720 r:0.7350
ru_en Dev loss: 0.5054 r:0.7211
Current avg r:0.5952 Best avg r: 0.6265
02:13:02,559 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:14:34,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:16:05,862 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2571
en_de Dev loss: 0.8842 r:0.2221
en_zh Dev loss: 0.8123 r:0.4292
ro_en Dev loss: 0.3662 r:0.8134
et_en Dev loss: 0.4484 r:0.6698
si_en Dev loss: 0.8098 r:0.5857
ne_en Dev loss: 0.4755 r:0.7380
ru_en Dev loss: 0.4682 r:0.7257
Current avg r:0.5977 Best avg r: 0.6265
02:20:41,212 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:22:12,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:23:44,560 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2634
en_de Dev loss: 0.8843 r:0.2200
en_zh Dev loss: 0.8805 r:0.4242
ro_en Dev loss: 0.3991 r:0.8110
et_en Dev loss: 0.4668 r:0.6575
si_en Dev loss: 0.9167 r:0.5819
ne_en Dev loss: 0.6877 r:0.7312
ru_en Dev loss: 0.5365 r:0.7038
Current avg r:0.5899 Best avg r: 0.6265
02:28:19,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:51,267 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:31:22,55 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2608
en_de Dev loss: 0.8869 r:0.2168
en_zh Dev loss: 0.8455 r:0.4363
ro_en Dev loss: 0.3735 r:0.8156
et_en Dev loss: 0.4906 r:0.6545
si_en Dev loss: 0.8631 r:0.5793
ne_en Dev loss: 0.4965 r:0.7371
ru_en Dev loss: 0.4745 r:0.7237
Current avg r:0.5948 Best avg r: 0.6265
02:35:53,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:37:23,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:54,529 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2612
en_de Dev loss: 0.8620 r:0.2162
en_zh Dev loss: 0.7885 r:0.4399
ro_en Dev loss: 0.3533 r:0.8164
et_en Dev loss: 0.4594 r:0.6564
si_en Dev loss: 0.7986 r:0.5905
ne_en Dev loss: 0.5103 r:0.7361
ru_en Dev loss: 0.5014 r:0.7079
Current avg r:0.5947 Best avg r: 0.6265
02:43:25,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:44:56,462 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:46:27,67 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2517
en_de Dev loss: 0.8703 r:0.2374
en_zh Dev loss: 0.8420 r:0.4405
ro_en Dev loss: 0.3755 r:0.8172
et_en Dev loss: 0.4820 r:0.6615
si_en Dev loss: 0.8526 r:0.5898
ne_en Dev loss: 0.5223 r:0.7414
ru_en Dev loss: 0.5198 r:0.7126
Current avg r:0.6001 Best avg r: 0.6265
02:50:58,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:52:28,966 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:59,561 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2720
en_de Dev loss: 0.8632 r:0.2270
en_zh Dev loss: 0.7893 r:0.4401
ro_en Dev loss: 0.3349 r:0.8210
et_en Dev loss: 0.4758 r:0.6651
si_en Dev loss: 0.7237 r:0.5937
ne_en Dev loss: 0.4467 r:0.7452
ru_en Dev loss: 0.4387 r:0.7273
Current avg r:0.6028 Best avg r: 0.6265
02:58:30,852 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:00:01,425 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:01:32,40 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2517
en_de Dev loss: 0.8806 r:0.2216
en_zh Dev loss: 0.8748 r:0.4289
ro_en Dev loss: 0.3944 r:0.8110
et_en Dev loss: 0.4968 r:0.6501
si_en Dev loss: 0.9037 r:0.5756
ne_en Dev loss: 0.6354 r:0.7284
ru_en Dev loss: 0.4992 r:0.7232
Current avg r:0.5912 Best avg r: 0.6265
03:06:03,477 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:07:34,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:09:04,681 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2490
en_de Dev loss: 0.8698 r:0.2476
en_zh Dev loss: 0.8315 r:0.4343
ro_en Dev loss: 0.3430 r:0.8165
et_en Dev loss: 0.5022 r:0.6606
si_en Dev loss: 0.7324 r:0.5919
ne_en Dev loss: 0.4175 r:0.7398
ru_en Dev loss: 0.4390 r:0.7366
Current avg r:0.6039 Best avg r: 0.6265
03:13:35,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:15:06,590 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:37,212 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2496
en_de Dev loss: 0.8627 r:0.2293
en_zh Dev loss: 0.8853 r:0.4236
ro_en Dev loss: 0.4070 r:0.8095
et_en Dev loss: 0.4800 r:0.6536
si_en Dev loss: 0.9349 r:0.5781
ne_en Dev loss: 0.5181 r:0.7313
ru_en Dev loss: 0.5356 r:0.7111
Current avg r:0.5909 Best avg r: 0.6265
03:21:09,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:22:40,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:24:12,231 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2420
en_de Dev loss: 0.8917 r:0.2206
en_zh Dev loss: 0.9551 r:0.4055
ro_en Dev loss: 0.4709 r:0.8043
et_en Dev loss: 0.5121 r:0.6439
si_en Dev loss: 1.0515 r:0.5587
ne_en Dev loss: 0.7460 r:0.7269
ru_en Dev loss: 0.5771 r:0.6996
Current avg r:0.5799 Best avg r: 0.6265
03:28:45,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:30:16,689 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:48,0 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2305
en_de Dev loss: 0.8944 r:0.1779
en_zh Dev loss: 0.9032 r:0.4033
ro_en Dev loss: 0.3832 r:0.8091
et_en Dev loss: 0.4813 r:0.6517
si_en Dev loss: 1.0061 r:0.5535
ne_en Dev loss: 0.6565 r:0.7275
ru_en Dev loss: 0.5469 r:0.6935
Current avg r:0.5738 Best avg r: 0.6265
03:36:21,451 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:52,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:39:24,90 root INFO Epoch 6 Global steps: 71400 Train loss: 0.2532
en_de Dev loss: 0.8639 r:0.2401
en_zh Dev loss: 0.8412 r:0.4207
ro_en Dev loss: 0.3617 r:0.8144
et_en Dev loss: 0.4660 r:0.6666
si_en Dev loss: 0.8402 r:0.5718
ne_en Dev loss: 0.5125 r:0.7338
ru_en Dev loss: 0.4641 r:0.7231
Current avg r:0.5958 Best avg r: 0.6265
03:43:56,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:45:26,855 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:46:57,412 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2427
en_de Dev loss: 0.8896 r:0.2331
en_zh Dev loss: 0.8470 r:0.4284
ro_en Dev loss: 0.3603 r:0.8159
et_en Dev loss: 0.4747 r:0.6581
si_en Dev loss: 0.9003 r:0.5689
ne_en Dev loss: 0.4836 r:0.7371
ru_en Dev loss: 0.4669 r:0.7321
Current avg r:0.5962 Best avg r: 0.6265
03:51:28,745 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:52:59,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:54:29,966 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2465
en_de Dev loss: 0.9028 r:0.2150
en_zh Dev loss: 0.8567 r:0.4317
ro_en Dev loss: 0.3804 r:0.8140
et_en Dev loss: 0.4751 r:0.6609
si_en Dev loss: 0.8394 r:0.5738
ne_en Dev loss: 0.4659 r:0.7347
ru_en Dev loss: 0.5045 r:0.7235
Current avg r:0.5934 Best avg r: 0.6265
03:59:01,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:00:31,884 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:02:02,329 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2389
en_de Dev loss: 0.8660 r:0.2249
en_zh Dev loss: 0.8623 r:0.4190
ro_en Dev loss: 0.3700 r:0.8120
et_en Dev loss: 0.5013 r:0.6557
si_en Dev loss: 0.8554 r:0.5673
ne_en Dev loss: 0.5117 r:0.7345
ru_en Dev loss: 0.4884 r:0.7165
Current avg r:0.5900 Best avg r: 0.6265
04:06:34,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:08:05,63 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:09:35,614 root INFO Epoch 7 Global steps: 74200 Train loss: 0.2229
en_de Dev loss: 0.8644 r:0.2245
en_zh Dev loss: 0.8529 r:0.4226
ro_en Dev loss: 0.3468 r:0.8166
et_en Dev loss: 0.4922 r:0.6589
si_en Dev loss: 0.8384 r:0.5683
ne_en Dev loss: 0.4923 r:0.7358
ru_en Dev loss: 0.4859 r:0.7221
Current avg r:0.5927 Best avg r: 0.6265
04:14:06,479 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:15:36,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:17:07,557 root INFO Epoch 7 Global steps: 74900 Train loss: 0.2275
en_de Dev loss: 0.9174 r:0.2168
en_zh Dev loss: 0.8824 r:0.4196
ro_en Dev loss: 0.3946 r:0.8146
et_en Dev loss: 0.4899 r:0.6612
si_en Dev loss: 0.8252 r:0.5708
ne_en Dev loss: 0.5500 r:0.7366
ru_en Dev loss: 0.4897 r:0.7277
Current avg r:0.5925 Best avg r: 0.6265
04:21:38,506 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:23:08,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:24:39,380 root INFO Epoch 7 Global steps: 75600 Train loss: 0.2186
en_de Dev loss: 0.8999 r:0.2156
en_zh Dev loss: 0.9008 r:0.4242
ro_en Dev loss: 0.3954 r:0.8114
et_en Dev loss: 0.5116 r:0.6489
si_en Dev loss: 0.8326 r:0.5641
ne_en Dev loss: 0.4817 r:0.7283
ru_en Dev loss: 0.5021 r:0.7262
Current avg r:0.5884 Best avg r: 0.6265
04:29:09,955 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:30:40,320 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:32:11,654 root INFO Epoch 7 Global steps: 76300 Train loss: 0.2258
en_de Dev loss: 0.8735 r:0.2219
en_zh Dev loss: 0.8918 r:0.4148
ro_en Dev loss: 0.3869 r:0.8108
et_en Dev loss: 0.4772 r:0.6548
si_en Dev loss: 0.9135 r:0.5635
ne_en Dev loss: 0.6322 r:0.7375
ru_en Dev loss: 0.4778 r:0.7298
Current avg r:0.5904 Best avg r: 0.6265
04:36:47,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:38:18,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:39:49,605 root INFO Epoch 7 Global steps: 77000 Train loss: 0.2196
en_de Dev loss: 0.8866 r:0.2126
en_zh Dev loss: 0.9030 r:0.4117
ro_en Dev loss: 0.4065 r:0.8073
et_en Dev loss: 0.4848 r:0.6455
si_en Dev loss: 0.9888 r:0.5607
ne_en Dev loss: 0.6691 r:0.7357
ru_en Dev loss: 0.5112 r:0.7274
Current avg r:0.5859 Best avg r: 0.6265
04:44:24,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:45:55,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:47:27,401 root INFO Epoch 7 Global steps: 77700 Train loss: 0.2329
en_de Dev loss: 0.8782 r:0.2127
en_zh Dev loss: 0.8545 r:0.4353
ro_en Dev loss: 0.3627 r:0.8131
et_en Dev loss: 0.5248 r:0.6513
si_en Dev loss: 0.7450 r:0.5834
ne_en Dev loss: 0.5381 r:0.7300
ru_en Dev loss: 0.4409 r:0.7335
Current avg r:0.5942 Best avg r: 0.6265
04:52:02,527 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:53:33,776 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:55:05,199 root INFO Epoch 7 Global steps: 78400 Train loss: 0.2171
en_de Dev loss: 0.9060 r:0.2131
en_zh Dev loss: 0.8632 r:0.4267
ro_en Dev loss: 0.3701 r:0.8072
et_en Dev loss: 0.4876 r:0.6469
si_en Dev loss: 0.8226 r:0.5684
ne_en Dev loss: 0.5156 r:0.7357
ru_en Dev loss: 0.4613 r:0.7391
Current avg r:0.5910 Best avg r: 0.6265
04:59:37,260 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:01:07,706 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:02:38,287 root INFO Epoch 7 Global steps: 79100 Train loss: 0.2222
en_de Dev loss: 0.9019 r:0.1917
en_zh Dev loss: 0.8460 r:0.4286
ro_en Dev loss: 0.3769 r:0.8104
et_en Dev loss: 0.5001 r:0.6406
si_en Dev loss: 0.8663 r:0.5671
ne_en Dev loss: 0.5275 r:0.7314
ru_en Dev loss: 0.4503 r:0.7307
Current avg r:0.5858 Best avg r: 0.6265
05:07:09,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:08:39,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:10:09,813 root INFO Epoch 7 Global steps: 79800 Train loss: 0.2149
en_de Dev loss: 0.8871 r:0.2100
en_zh Dev loss: 0.8866 r:0.4164
ro_en Dev loss: 0.4023 r:0.8088
et_en Dev loss: 0.4997 r:0.6425
si_en Dev loss: 0.8962 r:0.5581
ne_en Dev loss: 0.5278 r:0.7330
ru_en Dev loss: 0.5281 r:0.7077
Current avg r:0.5824 Best avg r: 0.6265
05:14:40,682 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:16:11,154 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:17:41,725 root INFO Epoch 7 Global steps: 80500 Train loss: 0.2150
en_de Dev loss: 0.8866 r:0.2258
en_zh Dev loss: 0.8319 r:0.4257
ro_en Dev loss: 0.3787 r:0.8106
et_en Dev loss: 0.5116 r:0.6490
si_en Dev loss: 0.8967 r:0.5617
ne_en Dev loss: 0.5393 r:0.7342
ru_en Dev loss: 0.4684 r:0.7251
Current avg r:0.5903 Best avg r: 0.6265
05:22:12,878 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:23:43,242 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:25:13,840 root INFO Epoch 7 Global steps: 81200 Train loss: 0.2245
en_de Dev loss: 0.8841 r:0.2109
en_zh Dev loss: 0.7974 r:0.4358
ro_en Dev loss: 0.3555 r:0.8177
et_en Dev loss: 0.4715 r:0.6571
si_en Dev loss: 0.8469 r:0.5659
ne_en Dev loss: 0.5536 r:0.7300
ru_en Dev loss: 0.4441 r:0.7370
Current avg r:0.5935 Best avg r: 0.6265
05:29:45,277 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:31:15,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:32:46,356 root INFO Epoch 7 Global steps: 81900 Train loss: 0.2290
en_de Dev loss: 0.9000 r:0.2141
en_zh Dev loss: 0.8431 r:0.4293
ro_en Dev loss: 0.3809 r:0.8131
et_en Dev loss: 0.5193 r:0.6351
si_en Dev loss: 0.9290 r:0.5513
ne_en Dev loss: 0.5192 r:0.7257
ru_en Dev loss: 0.4808 r:0.7281
Current avg r:0.5852 Best avg r: 0.6265
05:37:19,21 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:38:49,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:40:21,63 root INFO Epoch 7 Global steps: 82600 Train loss: 0.2212
en_de Dev loss: 0.8917 r:0.2106
en_zh Dev loss: 0.8435 r:0.4220
ro_en Dev loss: 0.3557 r:0.8168
et_en Dev loss: 0.5171 r:0.6418
si_en Dev loss: 0.8723 r:0.5586
ne_en Dev loss: 0.5128 r:0.7197
ru_en Dev loss: 0.4766 r:0.7294
Current avg r:0.5856 Best avg r: 0.6265
05:44:55,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:46:26,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:47:58,340 root INFO Epoch 7 Global steps: 83300 Train loss: 0.2127
en_de Dev loss: 0.9011 r:0.2439
en_zh Dev loss: 0.9065 r:0.4170
ro_en Dev loss: 0.4078 r:0.8125
et_en Dev loss: 0.5306 r:0.6391
si_en Dev loss: 1.0135 r:0.5500
ne_en Dev loss: 0.6379 r:0.7292
ru_en Dev loss: 0.5372 r:0.7263
Current avg r:0.5883 Best avg r: 0.6265
05:52:33,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:54:04,770 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:55:36,97 root INFO Epoch 7 Global steps: 84000 Train loss: 0.2163
en_de Dev loss: 0.8762 r:0.2157
en_zh Dev loss: 0.8467 r:0.4189
ro_en Dev loss: 0.3825 r:0.8090
et_en Dev loss: 0.5054 r:0.6322
si_en Dev loss: 0.9675 r:0.5456
ne_en Dev loss: 0.5634 r:0.7264
ru_en Dev loss: 0.4859 r:0.7228
Current avg r:0.5815 Best avg r: 0.6265
06:00:12,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:01:43,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:03:15,415 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1872
en_de Dev loss: 0.9052 r:0.2213
en_zh Dev loss: 0.9015 r:0.4256
ro_en Dev loss: 0.3956 r:0.8115
et_en Dev loss: 0.5500 r:0.6382
si_en Dev loss: 0.9785 r:0.5561
ne_en Dev loss: 0.4975 r:0.7300
ru_en Dev loss: 0.5241 r:0.7263
Current avg r:0.5870 Best avg r: 0.6265
06:07:48,768 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:09:19,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:10:49,710 root INFO Epoch 8 Global steps: 85400 Train loss: 0.2001
en_de Dev loss: 0.9180 r:0.2325
en_zh Dev loss: 0.9424 r:0.4113
ro_en Dev loss: 0.4211 r:0.8070
et_en Dev loss: 0.5154 r:0.6371
si_en Dev loss: 1.0188 r:0.5477
ne_en Dev loss: 0.5850 r:0.7247
ru_en Dev loss: 0.5708 r:0.7086
Current avg r:0.5813 Best avg r: 0.6265
06:15:20,795 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:16:51,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:18:21,558 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1941
en_de Dev loss: 0.8803 r:0.2358
en_zh Dev loss: 0.8109 r:0.4342
ro_en Dev loss: 0.3512 r:0.8092
et_en Dev loss: 0.5089 r:0.6411
si_en Dev loss: 0.8020 r:0.5587
ne_en Dev loss: 0.4842 r:0.7251
ru_en Dev loss: 0.4643 r:0.7255
Current avg r:0.5899 Best avg r: 0.6265
06:22:52,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:24:22,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:25:53,562 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1940
en_de Dev loss: 0.9086 r:0.2306
en_zh Dev loss: 0.8670 r:0.4416
ro_en Dev loss: 0.4148 r:0.8087
et_en Dev loss: 0.5605 r:0.6491
si_en Dev loss: 0.8951 r:0.5618
ne_en Dev loss: 0.5377 r:0.7294
ru_en Dev loss: 0.5206 r:0.7239
Current avg r:0.5921 Best avg r: 0.6265
06:30:24,972 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:31:55,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:33:26,165 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1994
en_de Dev loss: 0.9169 r:0.2022
en_zh Dev loss: 0.7981 r:0.4399
ro_en Dev loss: 0.3603 r:0.8095
et_en Dev loss: 0.5129 r:0.6443
si_en Dev loss: 0.8848 r:0.5581
ne_en Dev loss: 0.4991 r:0.7330
ru_en Dev loss: 0.4400 r:0.7390
Current avg r:0.5894 Best avg r: 0.6265
06:37:57,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:39:28,486 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:40:59,753 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1853
en_de Dev loss: 0.9351 r:0.2007
en_zh Dev loss: 0.9373 r:0.4182
ro_en Dev loss: 0.4182 r:0.8060
et_en Dev loss: 0.5136 r:0.6400
si_en Dev loss: 1.1288 r:0.5434
ne_en Dev loss: 0.6911 r:0.7257
ru_en Dev loss: 0.5329 r:0.7163
Current avg r:0.5786 Best avg r: 0.6265
06:45:33,208 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:47:04,348 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:48:35,556 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1901
en_de Dev loss: 0.9046 r:0.2155
en_zh Dev loss: 0.8040 r:0.4426
ro_en Dev loss: 0.3751 r:0.8091
et_en Dev loss: 0.5099 r:0.6398
si_en Dev loss: 0.9599 r:0.5508
ne_en Dev loss: 0.5835 r:0.7151
ru_en Dev loss: 0.4833 r:0.7201
Current avg r:0.5847 Best avg r: 0.6265
06:53:09,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:54:41,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:56:12,976 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1966
en_de Dev loss: 0.9047 r:0.2181
en_zh Dev loss: 0.8696 r:0.4380
ro_en Dev loss: 0.3839 r:0.8069
et_en Dev loss: 0.5242 r:0.6489
si_en Dev loss: 0.9568 r:0.5527
ne_en Dev loss: 0.5029 r:0.7273
ru_en Dev loss: 0.5054 r:0.7218
Current avg r:0.5877 Best avg r: 0.6265
07:00:48,579 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:02:20,99 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:03:51,620 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1969
en_de Dev loss: 0.9028 r:0.2142
en_zh Dev loss: 0.8409 r:0.4382
ro_en Dev loss: 0.3762 r:0.8114
et_en Dev loss: 0.5185 r:0.6531
si_en Dev loss: 0.9052 r:0.5588
ne_en Dev loss: 0.5336 r:0.7292
ru_en Dev loss: 0.4605 r:0.7444
Current avg r:0.5928 Best avg r: 0.6265
07:08:26,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:09:57,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:11:29,74 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1857
en_de Dev loss: 0.8980 r:0.2058
en_zh Dev loss: 0.8240 r:0.4451
ro_en Dev loss: 0.3477 r:0.8142
et_en Dev loss: 0.4774 r:0.6576
si_en Dev loss: 0.8580 r:0.5621
ne_en Dev loss: 0.5150 r:0.7306
ru_en Dev loss: 0.4581 r:0.7362
Current avg r:0.5931 Best avg r: 0.6265
07:16:03,347 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:17:33,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:19:04,329 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1893
en_de Dev loss: 0.9171 r:0.1862
en_zh Dev loss: 0.9361 r:0.4156
ro_en Dev loss: 0.4145 r:0.8042
et_en Dev loss: 0.5199 r:0.6325
si_en Dev loss: 1.0075 r:0.5470
ne_en Dev loss: 0.6558 r:0.7251
ru_en Dev loss: 0.5607 r:0.6999
Current avg r:0.5729 Best avg r: 0.6265
07:23:35,47 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:25:05,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:26:36,56 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1996
en_de Dev loss: 0.8973 r:0.2023
en_zh Dev loss: 0.8181 r:0.4363
ro_en Dev loss: 0.3632 r:0.8127
et_en Dev loss: 0.5074 r:0.6420
si_en Dev loss: 0.9151 r:0.5475
ne_en Dev loss: 0.5627 r:0.7235
ru_en Dev loss: 0.4701 r:0.7266
Current avg r:0.5844 Best avg r: 0.6265
07:31:07,53 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:32:37,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:34:07,728 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1934
en_de Dev loss: 0.9298 r:0.1959
en_zh Dev loss: 0.8889 r:0.4403
ro_en Dev loss: 0.4480 r:0.8105
et_en Dev loss: 0.4892 r:0.6561
si_en Dev loss: 0.9206 r:0.5597
ne_en Dev loss: 0.6011 r:0.7283
ru_en Dev loss: 0.5419 r:0.7274
Current avg r:0.5883 Best avg r: 0.6265
07:38:38,475 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:40:08,847 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:41:39,376 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1961
en_de Dev loss: 0.9130 r:0.2088
en_zh Dev loss: 0.8429 r:0.4378
ro_en Dev loss: 0.3833 r:0.8100
et_en Dev loss: 0.4897 r:0.6495
si_en Dev loss: 0.8951 r:0.5521
ne_en Dev loss: 0.5509 r:0.7262
ru_en Dev loss: 0.4792 r:0.7378
Current avg r:0.5889 Best avg r: 0.6265
07:46:12,654 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:47:43,793 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:49:15,24 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1888
en_de Dev loss: 0.8991 r:0.2060
en_zh Dev loss: 0.8383 r:0.4445
ro_en Dev loss: 0.3853 r:0.8103
et_en Dev loss: 0.4865 r:0.6438
si_en Dev loss: 0.9101 r:0.5544
ne_en Dev loss: 0.5540 r:0.7252
ru_en Dev loss: 0.4717 r:0.7376
Current avg r:0.5888 Best avg r: 0.6265
07:53:50,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:55:21,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:56:52,753 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1745
en_de Dev loss: 0.9100 r:0.2131
en_zh Dev loss: 0.8967 r:0.4261
ro_en Dev loss: 0.3965 r:0.8123
et_en Dev loss: 0.5079 r:0.6391
si_en Dev loss: 0.8929 r:0.5537
ne_en Dev loss: 0.5439 r:0.7240
ru_en Dev loss: 0.4870 r:0.7370
Current avg r:0.5865 Best avg r: 0.6265
08:01:27,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:02:59,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:04:31,40 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1779
en_de Dev loss: 0.8974 r:0.2117
en_zh Dev loss: 0.8744 r:0.4287
ro_en Dev loss: 0.3839 r:0.8101
et_en Dev loss: 0.5140 r:0.6334
si_en Dev loss: 1.0018 r:0.5413
ne_en Dev loss: 0.5810 r:0.7245
ru_en Dev loss: 0.5131 r:0.7308
Current avg r:0.5829 Best avg r: 0.6265
08:09:05,701 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:10:36,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:12:08,334 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1811
en_de Dev loss: 0.8733 r:0.2358
en_zh Dev loss: 0.7962 r:0.4323
ro_en Dev loss: 0.3546 r:0.8109
et_en Dev loss: 0.4997 r:0.6459
si_en Dev loss: 0.8028 r:0.5624
ne_en Dev loss: 0.4366 r:0.7309
ru_en Dev loss: 0.4205 r:0.7465
Current avg r:0.5949 Best avg r: 0.6265
08:16:42,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:18:14,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:19:45,611 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1681
en_de Dev loss: 0.8756 r:0.2273
en_zh Dev loss: 0.8184 r:0.4252
ro_en Dev loss: 0.3613 r:0.8088
et_en Dev loss: 0.4903 r:0.6497
si_en Dev loss: 0.8184 r:0.5590
ne_en Dev loss: 0.4773 r:0.7286
ru_en Dev loss: 0.4452 r:0.7367
Current avg r:0.5908 Best avg r: 0.6265
08:24:18,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:25:48,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:27:19,302 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1743
en_de Dev loss: 0.8802 r:0.2420
en_zh Dev loss: 0.8504 r:0.4377
ro_en Dev loss: 0.3765 r:0.8101
et_en Dev loss: 0.4890 r:0.6450
si_en Dev loss: 0.8902 r:0.5574
ne_en Dev loss: 0.5586 r:0.7270
ru_en Dev loss: 0.4596 r:0.7395
Current avg r:0.5941 Best avg r: 0.6265
08:31:50,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:33:21,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:34:51,883 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1714
en_de Dev loss: 0.8769 r:0.2505
en_zh Dev loss: 0.8434 r:0.4325
ro_en Dev loss: 0.3949 r:0.8053
et_en Dev loss: 0.4978 r:0.6509
si_en Dev loss: 0.8885 r:0.5538
ne_en Dev loss: 0.5868 r:0.7263
ru_en Dev loss: 0.5082 r:0.7297
Current avg r:0.5927 Best avg r: 0.6265
08:39:23,556 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:40:54,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:42:24,764 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1701
en_de Dev loss: 0.9093 r:0.2243
en_zh Dev loss: 0.8346 r:0.4365
ro_en Dev loss: 0.3949 r:0.8066
et_en Dev loss: 0.4736 r:0.6530
si_en Dev loss: 0.8573 r:0.5594
ne_en Dev loss: 0.5476 r:0.7264
ru_en Dev loss: 0.5050 r:0.7301
Current avg r:0.5909 Best avg r: 0.6265
08:46:56,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:48:27,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:49:57,659 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1668
en_de Dev loss: 0.9073 r:0.2142
en_zh Dev loss: 0.8203 r:0.4453
ro_en Dev loss: 0.3598 r:0.8104
et_en Dev loss: 0.5050 r:0.6540
si_en Dev loss: 0.8571 r:0.5609
ne_en Dev loss: 0.5078 r:0.7312
ru_en Dev loss: 0.4649 r:0.7296
Current avg r:0.5922 Best avg r: 0.6265
08:54:29,92 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:55:59,699 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:57:30,301 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1733
en_de Dev loss: 0.9243 r:0.2183
en_zh Dev loss: 0.8011 r:0.4497
ro_en Dev loss: 0.3674 r:0.8097
et_en Dev loss: 0.4884 r:0.6469
si_en Dev loss: 0.9014 r:0.5537
ne_en Dev loss: 0.5932 r:0.7177
ru_en Dev loss: 0.4826 r:0.7327
Current avg r:0.5898 Best avg r: 0.6265
09:02:03,186 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:03:34,611 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:05:06,113 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1672
en_de Dev loss: 0.9444 r:0.2137
en_zh Dev loss: 0.9130 r:0.4362
ro_en Dev loss: 0.4772 r:0.7991
et_en Dev loss: 0.5464 r:0.6382
si_en Dev loss: 1.1370 r:0.5384
ne_en Dev loss: 0.6799 r:0.7227
ru_en Dev loss: 0.5694 r:0.7188
Current avg r:0.5810 Best avg r: 0.6265
09:09:40,618 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:11:11,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:12:43,407 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1739
en_de Dev loss: 0.9118 r:0.2000
en_zh Dev loss: 0.7926 r:0.4544
ro_en Dev loss: 0.3665 r:0.8092
et_en Dev loss: 0.4940 r:0.6464
si_en Dev loss: 0.9370 r:0.5515
ne_en Dev loss: 0.5922 r:0.7243
ru_en Dev loss: 0.4353 r:0.7388
Current avg r:0.5892 Best avg r: 0.6265
09:17:18,370 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:18:49,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:20:21,359 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1669
en_de Dev loss: 0.9520 r:0.1879
en_zh Dev loss: 0.7827 r:0.4588
ro_en Dev loss: 0.3849 r:0.8075
et_en Dev loss: 0.4964 r:0.6380
si_en Dev loss: 0.8652 r:0.5502
ne_en Dev loss: 0.5162 r:0.7115
ru_en Dev loss: 0.4901 r:0.7192
Current avg r:0.5819 Best avg r: 0.6265
09:24:55,138 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:26:25,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:27:56,562 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1773
en_de Dev loss: 0.9371 r:0.1927
en_zh Dev loss: 0.8575 r:0.4507
ro_en Dev loss: 0.3986 r:0.8107
et_en Dev loss: 0.5311 r:0.6286
si_en Dev loss: 1.0546 r:0.5322
ne_en Dev loss: 0.5724 r:0.7078
ru_en Dev loss: 0.5079 r:0.7206
Current avg r:0.5776 Best avg r: 0.6265
09:32:28,335 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:33:59,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:35:29,734 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1708
en_de Dev loss: 0.8903 r:0.2096
en_zh Dev loss: 0.8583 r:0.4494
ro_en Dev loss: 0.3864 r:0.8118
et_en Dev loss: 0.5506 r:0.6433
si_en Dev loss: 0.9503 r:0.5504
ne_en Dev loss: 0.5215 r:0.7210
ru_en Dev loss: 0.5100 r:0.7183
Current avg r:0.5862 Best avg r: 0.6265
09:40:01,441 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:41:32,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:43:02,790 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1662
en_de Dev loss: 0.9141 r:0.2077
en_zh Dev loss: 0.8591 r:0.4567
ro_en Dev loss: 0.3856 r:0.8099
et_en Dev loss: 0.5243 r:0.6456
si_en Dev loss: 0.9027 r:0.5491
ne_en Dev loss: 0.5544 r:0.7237
ru_en Dev loss: 0.4828 r:0.7272
Current avg r:0.5886 Best avg r: 0.6265
09:47:35,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:49:06,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:50:37,77 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1552
en_de Dev loss: 0.9044 r:0.1874
en_zh Dev loss: 0.8063 r:0.4614
ro_en Dev loss: 0.3842 r:0.8104
et_en Dev loss: 0.5300 r:0.6354
si_en Dev loss: 1.0049 r:0.5330
ne_en Dev loss: 0.6506 r:0.7182
ru_en Dev loss: 0.4702 r:0.7264
Current avg r:0.5817 Best avg r: 0.6265
09:55:08,630 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:56:39,254 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:58:09,926 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1560
en_de Dev loss: 0.9207 r:0.2046
en_zh Dev loss: 0.8221 r:0.4629
ro_en Dev loss: 0.3878 r:0.8104
et_en Dev loss: 0.5145 r:0.6513
si_en Dev loss: 0.8782 r:0.5497
ne_en Dev loss: 0.5557 r:0.7197
ru_en Dev loss: 0.4928 r:0.7288
Current avg r:0.5896 Best avg r: 0.6265
10:02:41,265 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:04:11,764 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:05:42,296 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1598
en_de Dev loss: 0.9064 r:0.2080
en_zh Dev loss: 0.8025 r:0.4596
ro_en Dev loss: 0.3851 r:0.8086
et_en Dev loss: 0.5326 r:0.6394
si_en Dev loss: 0.9532 r:0.5386
ne_en Dev loss: 0.5582 r:0.7226
ru_en Dev loss: 0.4556 r:0.7348
Current avg r:0.5874 Best avg r: 0.6265
10:10:13,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:11:43,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:13:14,268 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1529
en_de Dev loss: 0.9045 r:0.2084
en_zh Dev loss: 0.8314 r:0.4616
ro_en Dev loss: 0.3691 r:0.8087
et_en Dev loss: 0.5212 r:0.6407
si_en Dev loss: 0.9380 r:0.5418
ne_en Dev loss: 0.6057 r:0.7160
ru_en Dev loss: 0.4688 r:0.7369
Current avg r:0.5877 Best avg r: 0.6265
10:17:45,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:19:15,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:20:46,60 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1576
en_de Dev loss: 0.9646 r:0.2001
en_zh Dev loss: 0.8702 r:0.4645
ro_en Dev loss: 0.4318 r:0.8094
et_en Dev loss: 0.5486 r:0.6416
si_en Dev loss: 0.9852 r:0.5471
ne_en Dev loss: 0.5808 r:0.7184
ru_en Dev loss: 0.5457 r:0.7367
Current avg r:0.5883 Best avg r: 0.6265
10:25:17,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:26:47,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:28:18,51 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1604
en_de Dev loss: 0.9390 r:0.2019
en_zh Dev loss: 0.8171 r:0.4614
ro_en Dev loss: 0.3949 r:0.8066
et_en Dev loss: 0.5321 r:0.6294
si_en Dev loss: 0.9424 r:0.5429
ne_en Dev loss: 0.6173 r:0.7150
ru_en Dev loss: 0.4648 r:0.7418
Current avg r:0.5856 Best avg r: 0.6265
