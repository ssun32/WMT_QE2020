14:44:35,710 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:01,580 root INFO 
id:en_zh cur r: 0.2724 best r: 0.2724
14:45:14,535 root INFO 
id:ro_en cur r: 0.6318 best r: 0.6318
14:45:27,501 root INFO 
id:et_en cur r: 0.5463 best r: 0.5463
14:45:40,475 root INFO 
id:si_en cur r: 0.4489 best r: 0.4489
14:45:53,440 root INFO 
id:ne_en cur r: 0.5373 best r: 0.5373
14:46:06,291 root INFO 
id:ru_en cur r: 0.6346 best r: 0.6346
14:46:06,291 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:47:36,827 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
14:47:36,833 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:47:36,838 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:47:36,843 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
14:47:36,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
14:47:36,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:47:36,858 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:47:49,819 root INFO Epoch 0 Global steps: 700 Train loss: 0.8162
en_de Dev loss: 0.9008 r:0.1076
en_zh Dev loss: 0.7611 r:0.2676
ro_en Dev loss: 0.5681 r:0.6348
et_en Dev loss: 0.5674 r:0.5803
si_en Dev loss: 0.6472 r:0.4899
ne_en Dev loss: 0.5900 r:0.6038
ru_en Dev loss: 0.5508 r:0.6396
Current avg r:0.4748 Best avg r: 0.4748
14:52:20,999 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:52:46,907 root INFO 
id:en_de cur r: 0.0871 best r: 0.0871
14:54:04,530 root INFO 
id:ru_en cur r: 0.6628 best r: 0.6628
14:54:04,531 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:55:35,115 root INFO Epoch 0 Global steps: 1400 Train loss: 0.7981
en_de Dev loss: 0.9156 r:0.1497
en_zh Dev loss: 0.8043 r:0.2471
ro_en Dev loss: 0.5795 r:0.6474
et_en Dev loss: 0.5277 r:0.5816
si_en Dev loss: 0.7277 r:0.4350
ne_en Dev loss: 0.5657 r:0.5767
ru_en Dev loss: 0.5226 r:0.6834
Current avg r:0.4744 Best avg r: 0.4748
15:00:06,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:00:45,107 root INFO 
id:ro_en cur r: 0.6533 best r: 0.6533
15:00:58,82 root INFO 
id:et_en cur r: 0.5664 best r: 0.5664
15:01:36,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:03:07,461 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:03:07,467 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:03:07,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:03:07,477 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:03:07,482 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:03:07,491 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:03:07,497 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:03:20,453 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7444
en_de Dev loss: 0.9560 r:0.1573
en_zh Dev loss: 0.8192 r:0.2605
ro_en Dev loss: 0.5430 r:0.6641
et_en Dev loss: 0.4792 r:0.6068
si_en Dev loss: 0.7364 r:0.4501
ne_en Dev loss: 0.5522 r:0.5718
ru_en Dev loss: 0.5750 r:0.6406
Current avg r:0.4787 Best avg r: 0.4787
15:07:51,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:08:17,622 root INFO 
id:en_zh cur r: 0.2988 best r: 0.2988
15:08:30,563 root INFO 
id:ro_en cur r: 0.6649 best r: 0.6649
15:08:43,533 root INFO 
id:et_en cur r: 0.6279 best r: 0.6279
15:08:56,514 root INFO 
id:si_en cur r: 0.4547 best r: 0.4547
15:09:09,490 root INFO 
id:ne_en cur r: 0.5899 best r: 0.5899
15:09:22,362 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:10:52,912 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:10:52,918 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:10:52,923 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:10:52,928 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:10:52,933 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:10:52,938 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:10:52,943 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:11:05,913 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6887
en_de Dev loss: 0.9813 r:0.1247
en_zh Dev loss: 0.7796 r:0.3367
ro_en Dev loss: 0.5143 r:0.6917
et_en Dev loss: 0.4401 r:0.6538
si_en Dev loss: 0.7308 r:0.4929
ne_en Dev loss: 0.5253 r:0.6183
ru_en Dev loss: 0.5549 r:0.6864
Current avg r:0.5149 Best avg r: 0.5149
15:15:36,823 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:16:02,641 root INFO 
id:en_zh cur r: 0.3494 best r: 0.3494
15:16:15,575 root INFO 
id:ro_en cur r: 0.6828 best r: 0.6828
15:16:28,545 root INFO 
id:et_en cur r: 0.6460 best r: 0.6460
15:16:41,510 root INFO 
id:si_en cur r: 0.5014 best r: 0.5014
15:16:54,468 root INFO 
id:ne_en cur r: 0.6289 best r: 0.6289
15:17:07,338 root INFO 
id:ru_en cur r: 0.7018 best r: 0.7018
15:17:07,338 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:18:37,838 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:18:37,843 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:18:37,848 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:18:37,853 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:18:37,858 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:18:37,863 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:18:37,868 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:18:50,811 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6473
en_de Dev loss: 0.9525 r:0.1298
en_zh Dev loss: 0.7100 r:0.3759
ro_en Dev loss: 0.4416 r:0.7044
et_en Dev loss: 0.4205 r:0.6696
si_en Dev loss: 0.6143 r:0.5242
ne_en Dev loss: 0.4608 r:0.6520
ru_en Dev loss: 0.4278 r:0.7214
Current avg r:0.5396 Best avg r: 0.5396
15:23:21,428 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:23:47,281 root INFO 
id:en_de cur r: 0.1002 best r: 0.1002
15:24:00,189 root INFO 
id:en_zh cur r: 0.3890 best r: 0.3890
15:24:13,134 root INFO 
id:ro_en cur r: 0.7136 best r: 0.7136
15:24:39,33 root INFO 
id:si_en cur r: 0.5061 best r: 0.5061
15:24:51,987 root INFO 
id:ne_en cur r: 0.6655 best r: 0.6655
15:25:04,834 root INFO 
id:ru_en cur r: 0.7123 best r: 0.7123
15:25:04,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:26:35,267 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:26:35,277 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:26:35,299 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:26:35,306 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:26:35,311 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:26:35,317 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:26:35,324 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:26:48,281 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6375
en_de Dev loss: 0.9369 r:0.1349
en_zh Dev loss: 0.6936 r:0.3994
ro_en Dev loss: 0.4198 r:0.7293
et_en Dev loss: 0.3991 r:0.6645
si_en Dev loss: 0.6721 r:0.5145
ne_en Dev loss: 0.4649 r:0.6595
ru_en Dev loss: 0.4152 r:0.7305
Current avg r:0.5475 Best avg r: 0.5475
15:31:18,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:31:44,665 root INFO 
id:en_de cur r: 0.1021 best r: 0.1021
15:31:57,569 root INFO 
id:en_zh cur r: 0.3953 best r: 0.3953
15:32:10,506 root INFO 
id:ro_en cur r: 0.7210 best r: 0.7210
15:32:23,454 root INFO 
id:et_en cur r: 0.6602 best r: 0.6602
15:32:36,429 root INFO 
id:si_en cur r: 0.5140 best r: 0.5140
15:32:49,393 root INFO 
id:ne_en cur r: 0.6821 best r: 0.6821
15:33:02,262 root INFO 
id:ru_en cur r: 0.7152 best r: 0.7152
15:33:02,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:34:32,765 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:34:32,770 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:34:32,775 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:34:32,780 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:34:32,785 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:34:32,789 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:34:32,794 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:34:45,744 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6207
en_de Dev loss: 0.9625 r:0.1503
en_zh Dev loss: 0.7125 r:0.4087
ro_en Dev loss: 0.4245 r:0.7363
et_en Dev loss: 0.3885 r:0.6707
si_en Dev loss: 0.6710 r:0.5268
ne_en Dev loss: 0.4367 r:0.6784
ru_en Dev loss: 0.4294 r:0.7319
Current avg r:0.5576 Best avg r: 0.5576
15:39:16,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:39:55,44 root INFO 
id:ro_en cur r: 0.7243 best r: 0.7243
15:40:08,19 root INFO 
id:et_en cur r: 0.6641 best r: 0.6641
15:40:46,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:42:17,464 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6361
en_de Dev loss: 0.9960 r:0.1405
en_zh Dev loss: 0.7873 r:0.3865
ro_en Dev loss: 0.4748 r:0.7419
et_en Dev loss: 0.4119 r:0.6657
si_en Dev loss: 0.8486 r:0.5014
ne_en Dev loss: 0.5270 r:0.6573
ru_en Dev loss: 0.5639 r:0.6990
Current avg r:0.5418 Best avg r: 0.5576
15:46:49,6 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:47:14,936 root INFO 
id:en_de cur r: 0.1368 best r: 0.1368
15:47:40,838 root INFO 
id:ro_en cur r: 0.7484 best r: 0.7484
15:47:53,823 root INFO 
id:et_en cur r: 0.6703 best r: 0.6703
15:48:06,821 root INFO 
id:si_en cur r: 0.5221 best r: 0.5221
15:48:19,809 root INFO 
id:ne_en cur r: 0.6945 best r: 0.6945
15:48:32,666 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:50:03,284 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:50:03,290 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:50:03,294 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:50:03,299 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:50:03,303 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:50:03,308 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:50:03,312 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:50:16,282 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6118
en_de Dev loss: 0.9377 r:0.1689
en_zh Dev loss: 0.7910 r:0.4086
ro_en Dev loss: 0.4589 r:0.7614
et_en Dev loss: 0.3979 r:0.6752
si_en Dev loss: 0.8116 r:0.5184
ne_en Dev loss: 0.5335 r:0.6691
ru_en Dev loss: 0.5728 r:0.7042
Current avg r:0.5580 Best avg r: 0.5580
15:54:47,14 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:55:12,907 root INFO 
id:en_de cur r: 0.1623 best r: 0.1623
15:55:25,835 root INFO 
id:en_zh cur r: 0.4198 best r: 0.4198
15:55:38,798 root INFO 
id:ro_en cur r: 0.7626 best r: 0.7626
15:55:51,772 root INFO 
id:et_en cur r: 0.6916 best r: 0.6916
15:56:04,747 root INFO 
id:si_en cur r: 0.5575 best r: 0.5575
15:56:17,724 root INFO 
id:ne_en cur r: 0.7267 best r: 0.7267
15:56:30,594 root INFO 
id:ru_en cur r: 0.7407 best r: 0.7407
15:56:30,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:58:01,155 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
15:58:01,161 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:58:01,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:58:01,171 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
15:58:01,176 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
15:58:01,180 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:58:01,185 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:58:14,150 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5796
en_de Dev loss: 0.9050 r:0.1817
en_zh Dev loss: 0.7096 r:0.4409
ro_en Dev loss: 0.3870 r:0.7745
et_en Dev loss: 0.3700 r:0.6984
si_en Dev loss: 0.6713 r:0.5632
ne_en Dev loss: 0.4266 r:0.7190
ru_en Dev loss: 0.4072 r:0.7453
Current avg r:0.5890 Best avg r: 0.5890
16:02:44,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:15,380 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:05:45,922 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5553
en_de Dev loss: 0.9138 r:0.1794
en_zh Dev loss: 0.7408 r:0.4270
ro_en Dev loss: 0.3886 r:0.7654
et_en Dev loss: 0.3873 r:0.6867
si_en Dev loss: 0.8072 r:0.5410
ne_en Dev loss: 0.4619 r:0.7036
ru_en Dev loss: 0.4477 r:0.7376
Current avg r:0.5773 Best avg r: 0.5890
16:10:16,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:10:42,469 root INFO 
id:en_de cur r: 0.1683 best r: 0.1683
16:11:08,334 root INFO 
id:ro_en cur r: 0.7741 best r: 0.7741
16:11:21,297 root INFO 
id:et_en cur r: 0.6941 best r: 0.6941
16:11:34,268 root INFO 
id:si_en cur r: 0.5638 best r: 0.5638
16:11:47,247 root INFO 
id:ne_en cur r: 0.7387 best r: 0.7387
16:12:00,111 root INFO 
id:ru_en cur r: 0.7461 best r: 0.7461
16:12:00,111 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:13:30,669 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
16:13:30,675 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:13:30,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:13:30,684 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
16:13:30,689 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
16:13:30,694 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:13:30,699 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:13:43,664 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5263
en_de Dev loss: 0.9194 r:0.1921
en_zh Dev loss: 0.7774 r:0.4384
ro_en Dev loss: 0.3996 r:0.7806
et_en Dev loss: 0.3660 r:0.7030
si_en Dev loss: 0.6435 r:0.5721
ne_en Dev loss: 0.3892 r:0.7312
ru_en Dev loss: 0.4511 r:0.7502
Current avg r:0.5954 Best avg r: 0.5954
16:18:14,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:18:40,159 root INFO 
id:en_de cur r: 0.1749 best r: 0.1749
16:18:53,71 root INFO 
id:en_zh cur r: 0.4282 best r: 0.4282
16:19:06,6 root INFO 
id:ro_en cur r: 0.7831 best r: 0.7831
16:19:31,933 root INFO 
id:si_en cur r: 0.5767 best r: 0.5767
16:19:44,896 root INFO 
id:ne_en cur r: 0.7433 best r: 0.7433
16:19:57,750 root INFO 
id:ru_en cur r: 0.7503 best r: 0.7503
16:19:57,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:21:28,241 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
16:21:28,247 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:21:28,251 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:21:28,256 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
16:21:28,261 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
16:21:28,265 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:21:28,269 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:21:41,215 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5624
en_de Dev loss: 0.8611 r:0.1975
en_zh Dev loss: 0.7082 r:0.4341
ro_en Dev loss: 0.3647 r:0.7879
et_en Dev loss: 0.3623 r:0.7017
si_en Dev loss: 0.5958 r:0.5814
ne_en Dev loss: 0.3663 r:0.7407
ru_en Dev loss: 0.4161 r:0.7533
Current avg r:0.5995 Best avg r: 0.5995
16:26:11,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:26:37,515 root INFO 
id:en_de cur r: 0.1806 best r: 0.1806
16:26:50,417 root INFO 
id:en_zh cur r: 0.4301 best r: 0.4301
16:27:03,356 root INFO 
id:ro_en cur r: 0.7947 best r: 0.7947
16:27:42,199 root INFO 
id:ne_en cur r: 0.7459 best r: 0.7459
16:27:55,44 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:29:25,499 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5495
en_de Dev loss: 0.8893 r:0.2042
en_zh Dev loss: 0.7862 r:0.4326
ro_en Dev loss: 0.3879 r:0.7938
et_en Dev loss: 0.3798 r:0.6989
si_en Dev loss: 0.7118 r:0.5768
ne_en Dev loss: 0.3982 r:0.7398
ru_en Dev loss: 0.5028 r:0.7349
Current avg r:0.5973 Best avg r: 0.5995
16:33:55,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:34:21,656 root INFO 
id:en_de cur r: 0.1835 best r: 0.1835
16:34:47,492 root INFO 
id:ro_en cur r: 0.7950 best r: 0.7950
16:35:13,378 root INFO 
id:si_en cur r: 0.5829 best r: 0.5829
16:35:39,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:37:09,701 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5588
en_de Dev loss: 0.8528 r:0.2170
en_zh Dev loss: 0.7315 r:0.4325
ro_en Dev loss: 0.3653 r:0.7942
et_en Dev loss: 0.3745 r:0.6967
si_en Dev loss: 0.6873 r:0.5762
ne_en Dev loss: 0.4273 r:0.7331
ru_en Dev loss: 0.4468 r:0.7360
Current avg r:0.5980 Best avg r: 0.5995
16:41:41,739 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:42:46,360 root INFO 
id:si_en cur r: 0.5916 best r: 0.5916
16:43:12,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:44:42,589 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5122
en_de Dev loss: 0.9148 r:0.1664
en_zh Dev loss: 0.8222 r:0.3943
ro_en Dev loss: 0.4182 r:0.7903
et_en Dev loss: 0.4104 r:0.6902
si_en Dev loss: 0.8164 r:0.5690
ne_en Dev loss: 0.5040 r:0.7177
ru_en Dev loss: 0.5446 r:0.6329
Current avg r:0.5658 Best avg r: 0.5995
16:49:12,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:49:38,800 root INFO 
id:en_de cur r: 0.1836 best r: 0.1836
16:49:51,714 root INFO 
id:en_zh cur r: 0.4427 best r: 0.4427
16:50:04,639 root INFO 
id:ro_en cur r: 0.8054 best r: 0.8054
16:50:17,588 root INFO 
id:et_en cur r: 0.6953 best r: 0.6953
16:50:30,547 root INFO 
id:si_en cur r: 0.6097 best r: 0.6097
16:50:43,505 root INFO 
id:ne_en cur r: 0.7467 best r: 0.7467
16:50:56,355 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:52:26,833 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
16:52:26,843 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:52:26,848 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:52:26,852 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
16:52:26,859 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
16:52:26,863 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:52:26,868 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:52:39,818 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5427
en_de Dev loss: 0.8735 r:0.1902
en_zh Dev loss: 0.7311 r:0.4462
ro_en Dev loss: 0.3208 r:0.8068
et_en Dev loss: 0.3670 r:0.7010
si_en Dev loss: 0.5930 r:0.6024
ne_en Dev loss: 0.3821 r:0.7424
ru_en Dev loss: 0.4357 r:0.7173
Current avg r:0.6009 Best avg r: 0.6009
16:57:10,235 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:57:36,81 root INFO 
id:en_de cur r: 0.2217 best r: 0.2217
16:58:53,606 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:00:24,79 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5076
en_de Dev loss: 0.8612 r:0.2089
en_zh Dev loss: 0.7295 r:0.4422
ro_en Dev loss: 0.3775 r:0.7978
et_en Dev loss: 0.3890 r:0.6991
si_en Dev loss: 0.7407 r:0.5851
ne_en Dev loss: 0.5041 r:0.7382
ru_en Dev loss: 0.4645 r:0.7281
Current avg r:0.5999 Best avg r: 0.6009
17:04:54,543 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:05:20,391 root INFO 
id:en_de cur r: 0.2308 best r: 0.2308
17:06:37,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:08:08,451 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5400
en_de Dev loss: 0.8461 r:0.2188
en_zh Dev loss: 0.6872 r:0.4468
ro_en Dev loss: 0.3409 r:0.7987
et_en Dev loss: 0.3783 r:0.6861
si_en Dev loss: 0.7017 r:0.5773
ne_en Dev loss: 0.4247 r:0.7359
ru_en Dev loss: 0.4417 r:0.7241
Current avg r:0.5983 Best avg r: 0.6009
17:12:38,833 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:13:04,661 root INFO 
id:en_zh cur r: 0.4568 best r: 0.4568
17:13:17,600 root INFO 
id:ro_en cur r: 0.8122 best r: 0.8122
17:13:56,475 root INFO 
id:ne_en cur r: 0.7492 best r: 0.7492
17:14:09,340 root INFO 
id:ru_en cur r: 0.7527 best r: 0.7527
17:14:09,340 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:15:39,868 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
17:15:39,875 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:15:39,880 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:15:39,884 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
17:15:39,889 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
17:15:39,893 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:15:39,898 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:15:52,849 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4934
en_de Dev loss: 0.8508 r:0.2304
en_zh Dev loss: 0.6953 r:0.4539
ro_en Dev loss: 0.3382 r:0.8115
et_en Dev loss: 0.3760 r:0.7001
si_en Dev loss: 0.7181 r:0.5937
ne_en Dev loss: 0.4392 r:0.7497
ru_en Dev loss: 0.4071 r:0.7503
Current avg r:0.6128 Best avg r: 0.6128
17:20:23,254 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:01,989 root INFO 
id:ro_en cur r: 0.8166 best r: 0.8166
17:21:14,936 root INFO 
id:et_en cur r: 0.7066 best r: 0.7066
17:21:53,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:23:24,191 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5105
en_de Dev loss: 0.8444 r:0.2367
en_zh Dev loss: 0.7569 r:0.4473
ro_en Dev loss: 0.3491 r:0.8110
et_en Dev loss: 0.3794 r:0.7038
si_en Dev loss: 0.7391 r:0.5935
ne_en Dev loss: 0.5853 r:0.7427
ru_en Dev loss: 0.4478 r:0.7418
Current avg r:0.6110 Best avg r: 0.6128
17:27:54,491 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:28:20,305 root INFO 
id:en_zh cur r: 0.4764 best r: 0.4764
17:28:33,237 root INFO 
id:ro_en cur r: 0.8177 best r: 0.8177
17:28:46,202 root INFO 
id:et_en cur r: 0.7100 best r: 0.7100
17:29:12,108 root INFO 
id:ne_en cur r: 0.7612 best r: 0.7612
17:29:24,957 root INFO 
id:ru_en cur r: 0.7650 best r: 0.7650
17:29:24,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:30:55,460 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
17:30:55,467 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:30:55,472 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:30:55,478 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
17:30:55,486 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
17:30:55,491 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:30:55,497 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:31:08,442 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4993
en_de Dev loss: 0.8375 r:0.2387
en_zh Dev loss: 0.6549 r:0.4741
ro_en Dev loss: 0.3075 r:0.8156
et_en Dev loss: 0.3574 r:0.7101
si_en Dev loss: 0.6118 r:0.6103
ne_en Dev loss: 0.3664 r:0.7613
ru_en Dev loss: 0.3733 r:0.7637
Current avg r:0.6248 Best avg r: 0.6248
17:35:38,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:36:04,643 root INFO 
id:en_de cur r: 0.2357 best r: 0.2357
17:37:22,201 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:38:52,676 root INFO Epoch 1 Global steps: 16100 Train loss: 0.5081
en_de Dev loss: 0.9030 r:0.2161
en_zh Dev loss: 0.9130 r:0.4467
ro_en Dev loss: 0.4850 r:0.8080
et_en Dev loss: 0.4594 r:0.7013
si_en Dev loss: 0.8781 r:0.5956
ne_en Dev loss: 0.5490 r:0.7539
ru_en Dev loss: 0.5971 r:0.7361
Current avg r:0.6083 Best avg r: 0.6248
17:43:23,18 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:44:53,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:46:23,899 root INFO Epoch 1 Global steps: 16800 Train loss: 0.5043
en_de Dev loss: 0.8431 r:0.2258
en_zh Dev loss: 0.6774 r:0.4769
ro_en Dev loss: 0.3260 r:0.8172
et_en Dev loss: 0.3675 r:0.7076
si_en Dev loss: 0.6573 r:0.6114
ne_en Dev loss: 0.4241 r:0.7524
ru_en Dev loss: 0.4166 r:0.7583
Current avg r:0.6214 Best avg r: 0.6248
17:50:54,263 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:51:20,106 root INFO 
id:en_de cur r: 0.2396 best r: 0.2396
17:51:45,950 root INFO 
id:ro_en cur r: 0.8215 best r: 0.8215
17:52:24,815 root INFO 
id:ne_en cur r: 0.7664 best r: 0.7664
17:52:37,651 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:08,111 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4764
en_de Dev loss: 0.8415 r:0.2405
en_zh Dev loss: 0.6917 r:0.4685
ro_en Dev loss: 0.3231 r:0.8186
et_en Dev loss: 0.3643 r:0.7116
si_en Dev loss: 0.6884 r:0.6082
ne_en Dev loss: 0.3857 r:0.7663
ru_en Dev loss: 0.4266 r:0.7509
Current avg r:0.6235 Best avg r: 0.6248
17:58:38,434 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:08,860 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:01:39,334 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4937
en_de Dev loss: 0.8522 r:0.2294
en_zh Dev loss: 0.6702 r:0.4696
ro_en Dev loss: 0.3198 r:0.8145
et_en Dev loss: 0.3674 r:0.7014
si_en Dev loss: 0.7756 r:0.5968
ne_en Dev loss: 0.4225 r:0.7576
ru_en Dev loss: 0.4277 r:0.7558
Current avg r:0.6179 Best avg r: 0.6248
18:06:09,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:06:48,416 root INFO 
id:ro_en cur r: 0.8231 best r: 0.8231
18:07:40,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:10,586 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4692
en_de Dev loss: 0.8509 r:0.2191
en_zh Dev loss: 0.6707 r:0.4689
ro_en Dev loss: 0.3097 r:0.8179
et_en Dev loss: 0.3776 r:0.7030
si_en Dev loss: 0.6145 r:0.6031
ne_en Dev loss: 0.3783 r:0.7528
ru_en Dev loss: 0.3784 r:0.7567
Current avg r:0.6173 Best avg r: 0.6248
18:13:40,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:15:11,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:16:41,730 root INFO Epoch 1 Global steps: 19600 Train loss: 0.5024
en_de Dev loss: 0.8521 r:0.2232
en_zh Dev loss: 0.6802 r:0.4738
ro_en Dev loss: 0.3108 r:0.8221
et_en Dev loss: 0.3563 r:0.7070
si_en Dev loss: 0.7490 r:0.6033
ne_en Dev loss: 0.4681 r:0.7582
ru_en Dev loss: 0.4250 r:0.7454
Current avg r:0.6190 Best avg r: 0.6248
18:21:12,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:21:37,851 root INFO 
id:en_zh cur r: 0.4897 best r: 0.4897
18:21:50,790 root INFO 
id:ro_en cur r: 0.8265 best r: 0.8265
18:22:16,686 root INFO 
id:si_en cur r: 0.6108 best r: 0.6108
18:22:29,645 root INFO 
id:ne_en cur r: 0.7684 best r: 0.7684
18:22:42,509 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:24:12,998 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
18:24:13,7 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
18:24:13,12 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
18:24:13,18 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
18:24:13,23 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
18:24:13,28 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
18:24:13,33 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
18:24:25,985 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4727
en_de Dev loss: 0.8444 r:0.2220
en_zh Dev loss: 0.6330 r:0.4910
ro_en Dev loss: 0.3121 r:0.8236
et_en Dev loss: 0.3583 r:0.7126
si_en Dev loss: 0.6596 r:0.6110
ne_en Dev loss: 0.4462 r:0.7631
ru_en Dev loss: 0.3984 r:0.7560
Current avg r:0.6256 Best avg r: 0.6256
18:28:56,360 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:26,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:31:57,306 root INFO Epoch 1 Global steps: 21000 Train loss: 0.5011
en_de Dev loss: 0.8591 r:0.2021
en_zh Dev loss: 0.6872 r:0.4824
ro_en Dev loss: 0.3268 r:0.8219
et_en Dev loss: 0.3712 r:0.7065
si_en Dev loss: 0.7221 r:0.6104
ne_en Dev loss: 0.4489 r:0.7623
ru_en Dev loss: 0.4305 r:0.7531
Current avg r:0.6198 Best avg r: 0.6256
18:36:29,37 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:37:59,461 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:39:29,934 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4506
en_de Dev loss: 0.8446 r:0.2182
en_zh Dev loss: 0.6755 r:0.4758
ro_en Dev loss: 0.3058 r:0.8192
et_en Dev loss: 0.3671 r:0.7046
si_en Dev loss: 0.6703 r:0.6114
ne_en Dev loss: 0.3941 r:0.7634
ru_en Dev loss: 0.4245 r:0.7429
Current avg r:0.6194 Best avg r: 0.6256
18:44:00,290 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:45:30,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:47:01,268 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4444
en_de Dev loss: 0.8525 r:0.2142
en_zh Dev loss: 0.6653 r:0.4874
ro_en Dev loss: 0.3387 r:0.8118
et_en Dev loss: 0.4016 r:0.6961
si_en Dev loss: 0.6715 r:0.6050
ne_en Dev loss: 0.4120 r:0.7642
ru_en Dev loss: 0.3942 r:0.7469
Current avg r:0.6179 Best avg r: 0.6256
18:51:31,694 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:51:57,524 root INFO 
id:en_zh cur r: 0.4965 best r: 0.4965
18:53:02,143 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:54:32,623 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4455
en_de Dev loss: 0.8563 r:0.2182
en_zh Dev loss: 0.6580 r:0.4957
ro_en Dev loss: 0.3389 r:0.8186
et_en Dev loss: 0.3918 r:0.7052
si_en Dev loss: 0.6188 r:0.6121
ne_en Dev loss: 0.3744 r:0.7665
ru_en Dev loss: 0.4168 r:0.7520
Current avg r:0.6240 Best avg r: 0.6256
18:59:02,990 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:59:28,847 root INFO 
id:en_de cur r: 0.2452 best r: 0.2452
19:00:46,402 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:02:16,889 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4682
en_de Dev loss: 0.8492 r:0.2393
en_zh Dev loss: 0.7145 r:0.4748
ro_en Dev loss: 0.3223 r:0.8207
et_en Dev loss: 0.3754 r:0.7051
si_en Dev loss: 0.6754 r:0.6082
ne_en Dev loss: 0.4494 r:0.7665
ru_en Dev loss: 0.4455 r:0.7415
Current avg r:0.6223 Best avg r: 0.6256
19:06:47,304 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:13,160 root INFO 
id:en_de cur r: 0.2584 best r: 0.2584
19:08:17,870 root INFO 
id:ne_en cur r: 0.7723 best r: 0.7723
19:08:30,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:01,159 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
19:10:01,166 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
19:10:01,171 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
19:10:01,178 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
19:10:01,182 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
19:10:01,187 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
19:10:01,191 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
19:10:14,139 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4193
en_de Dev loss: 0.8445 r:0.2567
en_zh Dev loss: 0.7092 r:0.4734
ro_en Dev loss: 0.3259 r:0.8180
et_en Dev loss: 0.3933 r:0.7063
si_en Dev loss: 0.6248 r:0.6077
ne_en Dev loss: 0.3884 r:0.7702
ru_en Dev loss: 0.4100 r:0.7526
Current avg r:0.6264 Best avg r: 0.6264
19:14:44,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:15:10,382 root INFO 
id:en_de cur r: 0.2621 best r: 0.2621
19:16:27,939 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:17:58,424 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4187
en_de Dev loss: 0.8696 r:0.2510
en_zh Dev loss: 0.7660 r:0.4557
ro_en Dev loss: 0.3656 r:0.8129
et_en Dev loss: 0.3923 r:0.6998
si_en Dev loss: 0.7728 r:0.5950
ne_en Dev loss: 0.4279 r:0.7604
ru_en Dev loss: 0.4547 r:0.7443
Current avg r:0.6170 Best avg r: 0.6264
19:22:28,738 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:22:54,564 root INFO 
id:en_de cur r: 0.2803 best r: 0.2803
19:24:12,92 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:42,532 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4207
en_de Dev loss: 0.8558 r:0.2571
en_zh Dev loss: 0.7425 r:0.4614
ro_en Dev loss: 0.3404 r:0.8177
et_en Dev loss: 0.3789 r:0.7037
si_en Dev loss: 0.7286 r:0.6019
ne_en Dev loss: 0.4254 r:0.7558
ru_en Dev loss: 0.4710 r:0.7363
Current avg r:0.6191 Best avg r: 0.6264
19:30:12,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:30:38,586 root INFO 
id:en_de cur r: 0.2875 best r: 0.2875
19:31:56,129 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:26,574 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4291
en_de Dev loss: 0.8741 r:0.2540
en_zh Dev loss: 0.7427 r:0.4713
ro_en Dev loss: 0.3428 r:0.8227
et_en Dev loss: 0.3823 r:0.7084
si_en Dev loss: 0.7847 r:0.6068
ne_en Dev loss: 0.5070 r:0.7619
ru_en Dev loss: 0.5012 r:0.7439
Current avg r:0.6242 Best avg r: 0.6264
19:37:56,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:27,350 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:57,831 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4261
en_de Dev loss: 0.8338 r:0.2557
en_zh Dev loss: 0.7157 r:0.4702
ro_en Dev loss: 0.3436 r:0.8163
et_en Dev loss: 0.3966 r:0.6982
si_en Dev loss: 0.7851 r:0.5962
ne_en Dev loss: 0.5110 r:0.7650
ru_en Dev loss: 0.4652 r:0.7304
Current avg r:0.6189 Best avg r: 0.6264
19:45:28,180 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:58,586 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:28,987 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4429
en_de Dev loss: 0.8455 r:0.2566
en_zh Dev loss: 0.7251 r:0.4762
ro_en Dev loss: 0.3481 r:0.8157
et_en Dev loss: 0.4002 r:0.6995
si_en Dev loss: 0.7076 r:0.6011
ne_en Dev loss: 0.3960 r:0.7670
ru_en Dev loss: 0.4470 r:0.7371
Current avg r:0.6219 Best avg r: 0.6264
19:52:59,346 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:29,755 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:56:00,229 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4332
en_de Dev loss: 0.8394 r:0.2786
en_zh Dev loss: 0.7332 r:0.4666
ro_en Dev loss: 0.3528 r:0.8110
et_en Dev loss: 0.4090 r:0.6866
si_en Dev loss: 0.7525 r:0.5898
ne_en Dev loss: 0.4535 r:0.7581
ru_en Dev loss: 0.4769 r:0.7253
Current avg r:0.6166 Best avg r: 0.6264
20:00:30,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:02:01,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:31,467 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
20:03:31,473 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:03:31,477 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:03:31,482 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
20:03:31,487 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
20:03:31,492 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
20:03:31,496 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
20:03:44,438 root INFO Epoch 2 Global steps: 29400 Train loss: 0.4352
en_de Dev loss: 0.8249 r:0.2661
en_zh Dev loss: 0.6742 r:0.4783
ro_en Dev loss: 0.3057 r:0.8225
et_en Dev loss: 0.3759 r:0.7050
si_en Dev loss: 0.7050 r:0.6084
ne_en Dev loss: 0.3722 r:0.7679
ru_en Dev loss: 0.4326 r:0.7375
Current avg r:0.6265 Best avg r: 0.6265
20:08:14,775 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:45,223 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:15,682 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_de.lang_agnost_mlp.dev.best.scores
20:11:15,690 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:11:15,695 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:11:15,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/et_en.lang_agnost_mlp.dev.best.scores
20:11:15,705 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/si_en.lang_agnost_mlp.dev.best.scores
20:11:15,710 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ne_en.lang_agnost_mlp.dev.best.scores
20:11:15,715 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_ende/run2/ru_en.lang_agnost_mlp.dev.best.scores
20:11:28,656 root INFO Epoch 2 Global steps: 30100 Train loss: 0.4355
en_de Dev loss: 0.8324 r:0.2617
en_zh Dev loss: 0.7028 r:0.4761
ro_en Dev loss: 0.3287 r:0.8187
et_en Dev loss: 0.4115 r:0.7009
si_en Dev loss: 0.7241 r:0.6120
ne_en Dev loss: 0.3675 r:0.7685
ru_en Dev loss: 0.3999 r:0.7551
Current avg r:0.6276 Best avg r: 0.6276
20:15:58,892 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:17:29,356 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:59,846 root INFO Epoch 2 Global steps: 30800 Train loss: 0.4325
en_de Dev loss: 0.8437 r:0.2508
en_zh Dev loss: 0.7282 r:0.4619
ro_en Dev loss: 0.3480 r:0.8152
et_en Dev loss: 0.3791 r:0.6977
si_en Dev loss: 0.7740 r:0.6028
ne_en Dev loss: 0.4777 r:0.7643
ru_en Dev loss: 0.4866 r:0.7195
Current avg r:0.6160 Best avg r: 0.6276
20:23:30,184 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:25:00,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:31,119 root INFO Epoch 2 Global steps: 31500 Train loss: 0.4247
en_de Dev loss: 0.8513 r:0.2622
en_zh Dev loss: 0.7683 r:0.4617
ro_en Dev loss: 0.3714 r:0.8190
et_en Dev loss: 0.3984 r:0.7015
si_en Dev loss: 0.8312 r:0.5968
ne_en Dev loss: 0.4775 r:0.7649
ru_en Dev loss: 0.5185 r:0.7162
Current avg r:0.6175 Best avg r: 0.6276
20:31:03,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:31:41,760 root INFO 
id:ro_en cur r: 0.8309 best r: 0.8309
20:32:07,677 root INFO 
id:si_en cur r: 0.6157 best r: 0.6157
20:32:33,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:34:03,936 root INFO Epoch 3 Global steps: 32200 Train loss: 0.4017
en_de Dev loss: 0.8408 r:0.2447
en_zh Dev loss: 0.7281 r:0.4633
ro_en Dev loss: 0.3083 r:0.8275
et_en Dev loss: 0.3897 r:0.7066
si_en Dev loss: 0.6187 r:0.6213
ne_en Dev loss: 0.3585 r:0.7671
ru_en Dev loss: 0.4099 r:0.7441
Current avg r:0.6249 Best avg r: 0.6276
20:38:34,227 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:40:04,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:35,103 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3656
en_de Dev loss: 0.8467 r:0.2416
en_zh Dev loss: 0.7379 r:0.4720
ro_en Dev loss: 0.3374 r:0.8265
et_en Dev loss: 0.3978 r:0.7017
si_en Dev loss: 0.6574 r:0.6189
ne_en Dev loss: 0.4181 r:0.7647
ru_en Dev loss: 0.4148 r:0.7508
Current avg r:0.6252 Best avg r: 0.6276
20:46:05,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:09,989 root INFO 
id:si_en cur r: 0.6178 best r: 0.6178
20:47:35,782 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:49:06,251 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3875
en_de Dev loss: 0.8491 r:0.2675
en_zh Dev loss: 0.7406 r:0.4616
ro_en Dev loss: 0.3467 r:0.8240
et_en Dev loss: 0.3994 r:0.6986
si_en Dev loss: 0.6889 r:0.6156
ne_en Dev loss: 0.3779 r:0.7645
ru_en Dev loss: 0.4328 r:0.7502
Current avg r:0.6260 Best avg r: 0.6276
20:53:36,574 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:55:07,16 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:37,509 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3866
en_de Dev loss: 0.8368 r:0.2587
en_zh Dev loss: 0.7170 r:0.4616
ro_en Dev loss: 0.3210 r:0.8256
et_en Dev loss: 0.4034 r:0.6967
si_en Dev loss: 0.7337 r:0.6064
ne_en Dev loss: 0.4085 r:0.7585
ru_en Dev loss: 0.4144 r:0.7431
Current avg r:0.6215 Best avg r: 0.6276
21:01:07,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:38,499 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:04:09,57 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3705
en_de Dev loss: 0.8302 r:0.2556
en_zh Dev loss: 0.7406 r:0.4602
ro_en Dev loss: 0.3304 r:0.8212
et_en Dev loss: 0.3976 r:0.6987
si_en Dev loss: 0.7366 r:0.5967
ne_en Dev loss: 0.4604 r:0.7533
ru_en Dev loss: 0.4898 r:0.7079
Current avg r:0.6134 Best avg r: 0.6276
21:08:39,359 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:10:09,885 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:40,434 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3954
en_de Dev loss: 0.8555 r:0.2616
en_zh Dev loss: 0.7947 r:0.4624
ro_en Dev loss: 0.3609 r:0.8207
et_en Dev loss: 0.3941 r:0.6957
si_en Dev loss: 0.9013 r:0.5954
ne_en Dev loss: 0.4867 r:0.7567
ru_en Dev loss: 0.4591 r:0.7338
Current avg r:0.6180 Best avg r: 0.6276
21:16:10,914 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:16:36,811 root INFO 
id:en_de cur r: 0.2949 best r: 0.2949
21:17:54,445 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:19:24,997 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3790
en_de Dev loss: 0.8331 r:0.2674
en_zh Dev loss: 0.7402 r:0.4595
ro_en Dev loss: 0.3129 r:0.8241
et_en Dev loss: 0.3801 r:0.7035
si_en Dev loss: 0.7300 r:0.6061
ne_en Dev loss: 0.4324 r:0.7583
ru_en Dev loss: 0.4094 r:0.7494
Current avg r:0.6241 Best avg r: 0.6276
21:23:55,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:21,322 root INFO 
id:en_de cur r: 0.3048 best r: 0.3048
21:25:38,929 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:27:09,442 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3668
en_de Dev loss: 0.8289 r:0.2800
en_zh Dev loss: 0.7800 r:0.4461
ro_en Dev loss: 0.3609 r:0.8131
et_en Dev loss: 0.4144 r:0.6871
si_en Dev loss: 0.7693 r:0.5908
ne_en Dev loss: 0.4392 r:0.7529
ru_en Dev loss: 0.4506 r:0.7309
Current avg r:0.6144 Best avg r: 0.6276
21:31:39,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:33:10,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:34:40,727 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3665
en_de Dev loss: 0.8414 r:0.2362
en_zh Dev loss: 0.7290 r:0.4586
ro_en Dev loss: 0.3438 r:0.8189
et_en Dev loss: 0.4482 r:0.6905
si_en Dev loss: 0.7203 r:0.5957
ne_en Dev loss: 0.4115 r:0.7552
ru_en Dev loss: 0.4035 r:0.7492
Current avg r:0.6149 Best avg r: 0.6276
21:39:10,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:40:41,352 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:42:11,838 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3946
en_de Dev loss: 0.8729 r:0.2360
en_zh Dev loss: 0.7928 r:0.4525
ro_en Dev loss: 0.3733 r:0.8136
et_en Dev loss: 0.4202 r:0.6875
si_en Dev loss: 0.8275 r:0.5811
ne_en Dev loss: 0.4766 r:0.7569
ru_en Dev loss: 0.4527 r:0.7430
Current avg r:0.6101 Best avg r: 0.6276
21:46:42,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:48:12,625 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:49:43,145 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3718
en_de Dev loss: 0.8451 r:0.2606
en_zh Dev loss: 0.7591 r:0.4665
ro_en Dev loss: 0.3805 r:0.8147
et_en Dev loss: 0.4247 r:0.6951
si_en Dev loss: 0.8068 r:0.5901
ne_en Dev loss: 0.4644 r:0.7554
ru_en Dev loss: 0.4557 r:0.7430
Current avg r:0.6179 Best avg r: 0.6276
21:54:13,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:55:44,10 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:57:14,547 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3491
en_de Dev loss: 0.8270 r:0.2718
en_zh Dev loss: 0.7071 r:0.4676
ro_en Dev loss: 0.3144 r:0.8211
et_en Dev loss: 0.4121 r:0.7028
si_en Dev loss: 0.6518 r:0.6019
ne_en Dev loss: 0.3702 r:0.7549
ru_en Dev loss: 0.3789 r:0.7599
Current avg r:0.6257 Best avg r: 0.6276
22:01:44,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:03:15,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:04:45,975 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3754
en_de Dev loss: 0.8561 r:0.2642
en_zh Dev loss: 0.7616 r:0.4453
ro_en Dev loss: 0.3218 r:0.8208
et_en Dev loss: 0.3975 r:0.6914
si_en Dev loss: 0.7353 r:0.5959
ne_en Dev loss: 0.4041 r:0.7534
ru_en Dev loss: 0.4556 r:0.7397
Current avg r:0.6158 Best avg r: 0.6276
22:09:16,249 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:09:42,106 root INFO 
id:en_de cur r: 0.3061 best r: 0.3061
22:10:59,670 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:12:30,133 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3758
en_de Dev loss: 0.8336 r:0.2807
en_zh Dev loss: 0.7304 r:0.4593
ro_en Dev loss: 0.3104 r:0.8267
et_en Dev loss: 0.3901 r:0.6958
si_en Dev loss: 0.7641 r:0.5922
ne_en Dev loss: 0.4230 r:0.7513
ru_en Dev loss: 0.4373 r:0.7470
Current avg r:0.6219 Best avg r: 0.6276
22:17:00,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:26,260 root INFO 
id:en_de cur r: 0.3177 best r: 0.3177
22:18:43,820 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:20:14,307 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3713
en_de Dev loss: 0.8110 r:0.2987
en_zh Dev loss: 0.7097 r:0.4535
ro_en Dev loss: 0.3078 r:0.8264
et_en Dev loss: 0.3965 r:0.6933
si_en Dev loss: 0.7101 r:0.5903
ne_en Dev loss: 0.4094 r:0.7442
ru_en Dev loss: 0.4221 r:0.7382
Current avg r:0.6207 Best avg r: 0.6276
22:24:46,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:26:16,543 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:27:46,999 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3151
en_de Dev loss: 0.8274 r:0.2913
en_zh Dev loss: 0.7735 r:0.4549
ro_en Dev loss: 0.3668 r:0.8218
et_en Dev loss: 0.4300 r:0.6873
si_en Dev loss: 0.8238 r:0.5796
ne_en Dev loss: 0.4118 r:0.7551
ru_en Dev loss: 0.4910 r:0.7201
Current avg r:0.6157 Best avg r: 0.6276
22:32:17,291 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:33:47,752 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:35:18,207 root INFO Epoch 4 Global steps: 43400 Train loss: 0.3223
en_de Dev loss: 0.8315 r:0.2857
en_zh Dev loss: 0.7573 r:0.4687
ro_en Dev loss: 0.3483 r:0.8231
et_en Dev loss: 0.4057 r:0.6995
si_en Dev loss: 0.8715 r:0.5850
ne_en Dev loss: 0.4819 r:0.7579
ru_en Dev loss: 0.4788 r:0.7324
Current avg r:0.6218 Best avg r: 0.6276
22:39:48,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:41:18,804 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:42:49,245 root INFO Epoch 4 Global steps: 44100 Train loss: 0.3409
en_de Dev loss: 0.8281 r:0.2801
en_zh Dev loss: 0.7656 r:0.4585
ro_en Dev loss: 0.3559 r:0.8171
et_en Dev loss: 0.4214 r:0.6879
si_en Dev loss: 0.8009 r:0.5733
ne_en Dev loss: 0.4494 r:0.7451
ru_en Dev loss: 0.5019 r:0.7115
Current avg r:0.6105 Best avg r: 0.6276
22:47:19,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:48:49,989 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:50:20,420 root INFO Epoch 4 Global steps: 44800 Train loss: 0.3268
en_de Dev loss: 0.8390 r:0.2663
en_zh Dev loss: 0.8014 r:0.4380
ro_en Dev loss: 0.3496 r:0.8180
et_en Dev loss: 0.4321 r:0.6850
si_en Dev loss: 0.7456 r:0.5802
ne_en Dev loss: 0.4848 r:0.7543
ru_en Dev loss: 0.4539 r:0.7269
Current avg r:0.6098 Best avg r: 0.6276
22:54:50,761 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:56:21,215 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:57:51,678 root INFO Epoch 4 Global steps: 45500 Train loss: 0.3424
en_de Dev loss: 0.8443 r:0.2577
en_zh Dev loss: 0.7776 r:0.4418
ro_en Dev loss: 0.3513 r:0.8202
et_en Dev loss: 0.4146 r:0.6924
si_en Dev loss: 0.8714 r:0.5730
ne_en Dev loss: 0.5658 r:0.7559
ru_en Dev loss: 0.4482 r:0.7318
Current avg r:0.6104 Best avg r: 0.6276
23:02:21,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:03:52,464 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:05:22,900 root INFO Epoch 4 Global steps: 46200 Train loss: 0.3255
en_de Dev loss: 0.8929 r:0.2518
en_zh Dev loss: 0.8717 r:0.4095
ro_en Dev loss: 0.3901 r:0.8162
et_en Dev loss: 0.4260 r:0.6873
si_en Dev loss: 0.8636 r:0.5673
ne_en Dev loss: 0.5373 r:0.7468
ru_en Dev loss: 0.4989 r:0.7137
Current avg r:0.5989 Best avg r: 0.6276
23:09:53,162 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:11:23,619 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:12:54,38 root INFO Epoch 4 Global steps: 46900 Train loss: 0.3158
en_de Dev loss: 0.8674 r:0.2559
en_zh Dev loss: 0.8000 r:0.4189
ro_en Dev loss: 0.3534 r:0.8160
et_en Dev loss: 0.4347 r:0.6789
si_en Dev loss: 0.8135 r:0.5720
ne_en Dev loss: 0.4799 r:0.7427
ru_en Dev loss: 0.5075 r:0.6852
Current avg r:0.5956 Best avg r: 0.6276
23:17:24,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:18:54,760 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:20:25,197 root INFO Epoch 4 Global steps: 47600 Train loss: 0.3477
en_de Dev loss: 0.8403 r:0.2551
en_zh Dev loss: 0.7548 r:0.4486
ro_en Dev loss: 0.3559 r:0.8202
et_en Dev loss: 0.4204 r:0.6838
si_en Dev loss: 0.7753 r:0.5793
ne_en Dev loss: 0.4420 r:0.7466
ru_en Dev loss: 0.5076 r:0.6936
Current avg r:0.6039 Best avg r: 0.6276
23:24:55,465 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:26:25,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:27:56,300 root INFO Epoch 4 Global steps: 48300 Train loss: 0.3311
en_de Dev loss: 0.8476 r:0.2609
en_zh Dev loss: 0.8122 r:0.4353
ro_en Dev loss: 0.3513 r:0.8190
et_en Dev loss: 0.4182 r:0.6892
si_en Dev loss: 0.7114 r:0.5827
ne_en Dev loss: 0.4343 r:0.7446
ru_en Dev loss: 0.4618 r:0.7313
Current avg r:0.6090 Best avg r: 0.6276
23:32:26,435 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:33:56,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:35:27,201 root INFO Epoch 4 Global steps: 49000 Train loss: 0.3258
en_de Dev loss: 0.8485 r:0.2629
en_zh Dev loss: 0.8319 r:0.4296
ro_en Dev loss: 0.3695 r:0.8144
et_en Dev loss: 0.4245 r:0.6761
si_en Dev loss: 0.8838 r:0.5680
ne_en Dev loss: 0.5025 r:0.7386
ru_en Dev loss: 0.5056 r:0.7160
Current avg r:0.6008 Best avg r: 0.6276
23:39:57,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:41:27,794 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:42:58,273 root INFO Epoch 4 Global steps: 49700 Train loss: 0.3149
en_de Dev loss: 0.8556 r:0.2576
en_zh Dev loss: 0.8156 r:0.4381
ro_en Dev loss: 0.3425 r:0.8184
et_en Dev loss: 0.4157 r:0.6851
si_en Dev loss: 0.8188 r:0.5730
ne_en Dev loss: 0.4371 r:0.7422
ru_en Dev loss: 0.4659 r:0.7321
Current avg r:0.6067 Best avg r: 0.6276
23:47:28,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:48:59,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:50:29,692 root INFO Epoch 4 Global steps: 50400 Train loss: 0.3085
en_de Dev loss: 0.8234 r:0.2788
en_zh Dev loss: 0.8125 r:0.4451
ro_en Dev loss: 0.3425 r:0.8238
et_en Dev loss: 0.4225 r:0.6906
si_en Dev loss: 0.8008 r:0.5823
ne_en Dev loss: 0.4276 r:0.7443
ru_en Dev loss: 0.4462 r:0.7416
Current avg r:0.6152 Best avg r: 0.6276
23:55:00,119 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:30,629 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:58:01,126 root INFO Epoch 4 Global steps: 51100 Train loss: 0.3299
en_de Dev loss: 0.8469 r:0.2850
en_zh Dev loss: 0.8142 r:0.4282
ro_en Dev loss: 0.3626 r:0.8194
et_en Dev loss: 0.4126 r:0.6825
si_en Dev loss: 0.8575 r:0.5766
ne_en Dev loss: 0.5579 r:0.7410
ru_en Dev loss: 0.4722 r:0.7262
Current avg r:0.6084 Best avg r: 0.6276
00:02:31,613 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:04:02,165 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:05:32,659 root INFO Epoch 4 Global steps: 51800 Train loss: 0.3074
en_de Dev loss: 0.8344 r:0.2908
en_zh Dev loss: 0.7653 r:0.4408
ro_en Dev loss: 0.3478 r:0.8222
et_en Dev loss: 0.4070 r:0.6862
si_en Dev loss: 0.8714 r:0.5777
ne_en Dev loss: 0.4563 r:0.7471
ru_en Dev loss: 0.4528 r:0.7413
Current avg r:0.6152 Best avg r: 0.6276
00:10:03,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:11:33,744 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:13:04,271 root INFO Epoch 4 Global steps: 52500 Train loss: 0.3065
en_de Dev loss: 0.8245 r:0.2930
en_zh Dev loss: 0.7593 r:0.4563
ro_en Dev loss: 0.3435 r:0.8208
et_en Dev loss: 0.4361 r:0.6901
si_en Dev loss: 0.8376 r:0.5830
ne_en Dev loss: 0.4484 r:0.7483
ru_en Dev loss: 0.4462 r:0.7391
Current avg r:0.6187 Best avg r: 0.6276
00:17:36,94 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:19:06,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:20:36,900 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2757
en_de Dev loss: 0.8530 r:0.2375
en_zh Dev loss: 0.7661 r:0.4433
ro_en Dev loss: 0.3392 r:0.8204
et_en Dev loss: 0.4235 r:0.6777
si_en Dev loss: 0.8446 r:0.5784
ne_en Dev loss: 0.5083 r:0.7453
ru_en Dev loss: 0.4729 r:0.7180
Current avg r:0.6029 Best avg r: 0.6276
00:25:07,204 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:26:37,713 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:28:08,188 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2908
en_de Dev loss: 0.8547 r:0.2598
en_zh Dev loss: 0.8347 r:0.4415
ro_en Dev loss: 0.3769 r:0.8206
et_en Dev loss: 0.4924 r:0.6893
si_en Dev loss: 0.7687 r:0.5863
ne_en Dev loss: 0.3948 r:0.7490
ru_en Dev loss: 0.4190 r:0.7509
Current avg r:0.6139 Best avg r: 0.6276
00:32:38,396 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:34:08,827 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:35:39,250 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2959
en_de Dev loss: 0.8746 r:0.2270
en_zh Dev loss: 0.8268 r:0.4322
ro_en Dev loss: 0.3580 r:0.8203
et_en Dev loss: 0.4274 r:0.6807
si_en Dev loss: 0.8399 r:0.5727
ne_en Dev loss: 0.4714 r:0.7417
ru_en Dev loss: 0.4686 r:0.7319
Current avg r:0.6010 Best avg r: 0.6276
00:40:09,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:41:40,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:43:10,391 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2699
en_de Dev loss: 0.8649 r:0.2440
en_zh Dev loss: 0.8085 r:0.4288
ro_en Dev loss: 0.3546 r:0.8229
et_en Dev loss: 0.4332 r:0.6863
si_en Dev loss: 0.7952 r:0.5810
ne_en Dev loss: 0.4354 r:0.7443
ru_en Dev loss: 0.4627 r:0.7333
Current avg r:0.6058 Best avg r: 0.6276
00:47:40,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:49:11,6 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:50:41,492 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2832
en_de Dev loss: 0.8693 r:0.2436
en_zh Dev loss: 0.8151 r:0.4285
ro_en Dev loss: 0.3601 r:0.8186
et_en Dev loss: 0.4476 r:0.6767
si_en Dev loss: 0.8944 r:0.5690
ne_en Dev loss: 0.4989 r:0.7442
ru_en Dev loss: 0.4600 r:0.7344
Current avg r:0.6021 Best avg r: 0.6276
00:55:11,762 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:56:42,106 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:58:12,518 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2748
en_de Dev loss: 0.9168 r:0.2444
en_zh Dev loss: 0.9657 r:0.4191
ro_en Dev loss: 0.4595 r:0.8141
et_en Dev loss: 0.4864 r:0.6691
si_en Dev loss: 1.0202 r:0.5665
ne_en Dev loss: 0.6059 r:0.7395
ru_en Dev loss: 0.6050 r:0.7035
Current avg r:0.5937 Best avg r: 0.6276
01:02:42,912 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:04:13,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:05:43,881 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2621
en_de Dev loss: 0.8875 r:0.2497
en_zh Dev loss: 0.8294 r:0.4272
ro_en Dev loss: 0.3377 r:0.8222
et_en Dev loss: 0.4488 r:0.6875
si_en Dev loss: 0.7697 r:0.5841
ne_en Dev loss: 0.4135 r:0.7453
ru_en Dev loss: 0.4717 r:0.7277
Current avg r:0.6062 Best avg r: 0.6276
01:10:13,934 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:11:44,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:13:14,632 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2656
en_de Dev loss: 0.8377 r:0.2767
en_zh Dev loss: 0.7849 r:0.4515
ro_en Dev loss: 0.3381 r:0.8191
et_en Dev loss: 0.4852 r:0.6828
si_en Dev loss: 0.7710 r:0.5858
ne_en Dev loss: 0.4158 r:0.7418
ru_en Dev loss: 0.4154 r:0.7456
Current avg r:0.6148 Best avg r: 0.6276
01:17:44,796 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:19:15,180 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:20:45,528 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2945
en_de Dev loss: 0.8595 r:0.2306
en_zh Dev loss: 0.7937 r:0.4253
ro_en Dev loss: 0.3303 r:0.8214
et_en Dev loss: 0.4618 r:0.6726
si_en Dev loss: 0.8354 r:0.5705
ne_en Dev loss: 0.4329 r:0.7430
ru_en Dev loss: 0.4425 r:0.7348
Current avg r:0.5998 Best avg r: 0.6276
01:25:15,552 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:26:45,948 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:28:16,374 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2640
en_de Dev loss: 0.8701 r:0.2187
en_zh Dev loss: 0.7771 r:0.4428
ro_en Dev loss: 0.3312 r:0.8226
et_en Dev loss: 0.4626 r:0.6726
si_en Dev loss: 0.8188 r:0.5703
ne_en Dev loss: 0.4407 r:0.7467
ru_en Dev loss: 0.4439 r:0.7356
Current avg r:0.6013 Best avg r: 0.6276
01:32:46,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:34:17,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:35:47,348 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2660
en_de Dev loss: 0.9064 r:0.2274
en_zh Dev loss: 0.8514 r:0.4427
ro_en Dev loss: 0.3913 r:0.8171
et_en Dev loss: 0.4894 r:0.6667
si_en Dev loss: 0.9278 r:0.5672
ne_en Dev loss: 0.4965 r:0.7405
ru_en Dev loss: 0.4855 r:0.7391
Current avg r:0.6001 Best avg r: 0.6276
01:40:17,536 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:41:47,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:43:18,422 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2876
en_de Dev loss: 0.8629 r:0.2296
en_zh Dev loss: 0.7822 r:0.4289
ro_en Dev loss: 0.3374 r:0.8217
et_en Dev loss: 0.4484 r:0.6719
si_en Dev loss: 0.8289 r:0.5671
ne_en Dev loss: 0.4844 r:0.7383
ru_en Dev loss: 0.4740 r:0.7218
Current avg r:0.5970 Best avg r: 0.6276
01:47:48,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:49:19,237 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:50:49,720 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2550
en_de Dev loss: 0.8537 r:0.2489
en_zh Dev loss: 0.7843 r:0.4405
ro_en Dev loss: 0.3224 r:0.8268
et_en Dev loss: 0.4407 r:0.6811
si_en Dev loss: 0.8447 r:0.5657
ne_en Dev loss: 0.4529 r:0.7473
ru_en Dev loss: 0.4386 r:0.7389
Current avg r:0.6070 Best avg r: 0.6276
01:55:20,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:56:50,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:58:21,203 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2573
en_de Dev loss: 0.9085 r:0.2336
en_zh Dev loss: 0.9044 r:0.4292
ro_en Dev loss: 0.4238 r:0.8193
et_en Dev loss: 0.4735 r:0.6686
si_en Dev loss: 1.0210 r:0.5610
ne_en Dev loss: 0.5989 r:0.7434
ru_en Dev loss: 0.5814 r:0.7135
Current avg r:0.5955 Best avg r: 0.6276
02:02:51,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:04:22,595 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:05:53,191 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2792
en_de Dev loss: 0.8550 r:0.2553
en_zh Dev loss: 0.8441 r:0.4233
ro_en Dev loss: 0.3666 r:0.8177
et_en Dev loss: 0.4690 r:0.6598
si_en Dev loss: 0.8698 r:0.5534
ne_en Dev loss: 0.5154 r:0.7391
ru_en Dev loss: 0.4878 r:0.7193
Current avg r:0.5954 Best avg r: 0.6276
02:10:25,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:11:56,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:13:27,132 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2351
en_de Dev loss: 0.8680 r:0.2466
en_zh Dev loss: 0.8416 r:0.4346
ro_en Dev loss: 0.3782 r:0.8222
et_en Dev loss: 0.4798 r:0.6631
si_en Dev loss: 0.8779 r:0.5644
ne_en Dev loss: 0.5636 r:0.7375
ru_en Dev loss: 0.5392 r:0.7087
Current avg r:0.5968 Best avg r: 0.6276
02:17:58,716 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:19:29,351 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:21:00,48 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2345
en_de Dev loss: 0.8739 r:0.2286
en_zh Dev loss: 0.8276 r:0.4241
ro_en Dev loss: 0.3620 r:0.8220
et_en Dev loss: 0.4758 r:0.6592
si_en Dev loss: 0.8702 r:0.5569
ne_en Dev loss: 0.5478 r:0.7378
ru_en Dev loss: 0.4762 r:0.7253
Current avg r:0.5934 Best avg r: 0.6276
02:25:31,602 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:27:02,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:28:33,8 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2339
en_de Dev loss: 0.8924 r:0.2160
en_zh Dev loss: 0.8234 r:0.4267
ro_en Dev loss: 0.3762 r:0.8167
et_en Dev loss: 0.4745 r:0.6567
si_en Dev loss: 0.8940 r:0.5442
ne_en Dev loss: 0.5215 r:0.7314
ru_en Dev loss: 0.4902 r:0.7248
Current avg r:0.5881 Best avg r: 0.6276
02:33:04,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:34:35,392 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:36:06,94 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2447
en_de Dev loss: 0.8993 r:0.2105
en_zh Dev loss: 0.8436 r:0.4220
ro_en Dev loss: 0.3707 r:0.8213
et_en Dev loss: 0.4800 r:0.6565
si_en Dev loss: 0.9014 r:0.5505
ne_en Dev loss: 0.5030 r:0.7380
ru_en Dev loss: 0.4802 r:0.7239
Current avg r:0.5890 Best avg r: 0.6276
02:40:37,782 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:42:08,507 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:43:39,220 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2462
en_de Dev loss: 0.9054 r:0.1985
en_zh Dev loss: 0.8606 r:0.4114
ro_en Dev loss: 0.3658 r:0.8196
et_en Dev loss: 0.4787 r:0.6526
si_en Dev loss: 0.9395 r:0.5424
ne_en Dev loss: 0.5592 r:0.7367
ru_en Dev loss: 0.4631 r:0.7305
Current avg r:0.5845 Best avg r: 0.6276
02:48:10,920 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:49:41,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:51:12,429 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2253
en_de Dev loss: 0.8749 r:0.2368
en_zh Dev loss: 0.7861 r:0.4457
ro_en Dev loss: 0.3370 r:0.8231
et_en Dev loss: 0.4627 r:0.6669
si_en Dev loss: 0.8387 r:0.5588
ne_en Dev loss: 0.4927 r:0.7375
ru_en Dev loss: 0.4310 r:0.7450
Current avg r:0.6019 Best avg r: 0.6276
02:55:44,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:57:14,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:58:45,686 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2378
en_de Dev loss: 0.8961 r:0.2312
en_zh Dev loss: 0.8493 r:0.4328
ro_en Dev loss: 0.4054 r:0.8172
et_en Dev loss: 0.4769 r:0.6571
si_en Dev loss: 0.9678 r:0.5499
ne_en Dev loss: 0.5612 r:0.7401
ru_en Dev loss: 0.4795 r:0.7385
Current avg r:0.5953 Best avg r: 0.6276
03:03:17,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:04:48,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:06:18,787 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2386
en_de Dev loss: 0.8628 r:0.2371
en_zh Dev loss: 0.7862 r:0.4494
ro_en Dev loss: 0.3481 r:0.8228
et_en Dev loss: 0.4761 r:0.6564
si_en Dev loss: 0.8552 r:0.5522
ne_en Dev loss: 0.5016 r:0.7347
ru_en Dev loss: 0.4466 r:0.7333
Current avg r:0.5980 Best avg r: 0.6276
03:10:50,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:12:21,60 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:13:51,831 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2274
en_de Dev loss: 0.8693 r:0.2317
en_zh Dev loss: 0.7999 r:0.4445
ro_en Dev loss: 0.3340 r:0.8261
et_en Dev loss: 0.4683 r:0.6533
si_en Dev loss: 0.8869 r:0.5473
ne_en Dev loss: 0.5033 r:0.7376
ru_en Dev loss: 0.4473 r:0.7347
Current avg r:0.5964 Best avg r: 0.6276
03:18:23,176 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:19:53,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:21:24,665 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2277
en_de Dev loss: 0.8865 r:0.2337
en_zh Dev loss: 0.8088 r:0.4443
ro_en Dev loss: 0.3371 r:0.8246
et_en Dev loss: 0.4836 r:0.6553
si_en Dev loss: 0.8387 r:0.5482
ne_en Dev loss: 0.5106 r:0.7351
ru_en Dev loss: 0.4632 r:0.7326
Current avg r:0.5962 Best avg r: 0.6276
03:25:56,378 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:27:27,133 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:28:57,892 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2197
en_de Dev loss: 0.8645 r:0.2334
en_zh Dev loss: 0.7889 r:0.4452
ro_en Dev loss: 0.3310 r:0.8251
et_en Dev loss: 0.4656 r:0.6550
si_en Dev loss: 0.8738 r:0.5478
ne_en Dev loss: 0.5195 r:0.7397
ru_en Dev loss: 0.4033 r:0.7517
Current avg r:0.5997 Best avg r: 0.6276
03:33:29,497 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:35:00,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:30,938 root INFO Epoch 6 Global steps: 71400 Train loss: 0.2300
en_de Dev loss: 0.9087 r:0.2331
en_zh Dev loss: 0.8377 r:0.4366
ro_en Dev loss: 0.3470 r:0.8260
et_en Dev loss: 0.4731 r:0.6606
si_en Dev loss: 0.8354 r:0.5481
ne_en Dev loss: 0.4578 r:0.7373
ru_en Dev loss: 0.4789 r:0.7258
Current avg r:0.5953 Best avg r: 0.6276
03:41:02,571 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:42:33,267 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:44:03,924 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2168
en_de Dev loss: 0.8618 r:0.2377
en_zh Dev loss: 0.7893 r:0.4359
ro_en Dev loss: 0.3192 r:0.8271
et_en Dev loss: 0.4673 r:0.6561
si_en Dev loss: 0.8526 r:0.5441
ne_en Dev loss: 0.4460 r:0.7362
ru_en Dev loss: 0.4462 r:0.7270
Current avg r:0.5949 Best avg r: 0.6276
03:48:35,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:50:06,482 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:51:37,262 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2209
en_de Dev loss: 0.8668 r:0.2398
en_zh Dev loss: 0.7970 r:0.4436
ro_en Dev loss: 0.3192 r:0.8270
et_en Dev loss: 0.4494 r:0.6686
si_en Dev loss: 0.8020 r:0.5562
ne_en Dev loss: 0.4621 r:0.7386
ru_en Dev loss: 0.4389 r:0.7360
Current avg r:0.6014 Best avg r: 0.6276
03:56:09,123 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:39,836 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:59:10,553 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2306
en_de Dev loss: 0.8549 r:0.2498
en_zh Dev loss: 0.8488 r:0.4358
ro_en Dev loss: 0.3950 r:0.8153
et_en Dev loss: 0.4951 r:0.6380
si_en Dev loss: 0.9791 r:0.5361
ne_en Dev loss: 0.6426 r:0.7294
ru_en Dev loss: 0.5224 r:0.7049
Current avg r:0.5870 Best avg r: 0.6276
04:03:42,913 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:05:13,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:06:44,118 root INFO Epoch 7 Global steps: 74200 Train loss: 0.2120
en_de Dev loss: 0.8662 r:0.2462
en_zh Dev loss: 0.8322 r:0.4497
ro_en Dev loss: 0.3814 r:0.8221
et_en Dev loss: 0.4958 r:0.6608
si_en Dev loss: 0.9001 r:0.5505
ne_en Dev loss: 0.5147 r:0.7356
ru_en Dev loss: 0.4769 r:0.7383
Current avg r:0.6004 Best avg r: 0.6276
04:11:15,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:12:45,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:14:16,251 root INFO Epoch 7 Global steps: 74900 Train loss: 0.2068
en_de Dev loss: 0.8616 r:0.2518
en_zh Dev loss: 0.8517 r:0.4341
ro_en Dev loss: 0.3981 r:0.8229
et_en Dev loss: 0.4875 r:0.6546
si_en Dev loss: 0.9684 r:0.5442
ne_en Dev loss: 0.6456 r:0.7251
ru_en Dev loss: 0.5091 r:0.7268
Current avg r:0.5942 Best avg r: 0.6276
04:18:47,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:20:18,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:21:48,788 root INFO Epoch 7 Global steps: 75600 Train loss: 0.2018
en_de Dev loss: 0.8920 r:0.2318
en_zh Dev loss: 0.8826 r:0.4293
ro_en Dev loss: 0.4100 r:0.8165
et_en Dev loss: 0.4958 r:0.6479
si_en Dev loss: 0.9880 r:0.5424
ne_en Dev loss: 0.5626 r:0.7317
ru_en Dev loss: 0.5285 r:0.7158
Current avg r:0.5879 Best avg r: 0.6276
04:26:19,688 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:27:50,150 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:29:20,634 root INFO Epoch 7 Global steps: 76300 Train loss: 0.2061
en_de Dev loss: 0.8900 r:0.2422
en_zh Dev loss: 0.8512 r:0.4427
ro_en Dev loss: 0.3826 r:0.8193
et_en Dev loss: 0.4912 r:0.6552
si_en Dev loss: 0.9782 r:0.5433
ne_en Dev loss: 0.5301 r:0.7351
ru_en Dev loss: 0.4889 r:0.7314
Current avg r:0.5956 Best avg r: 0.6276
04:33:51,471 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:35:22,50 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:36:52,543 root INFO Epoch 7 Global steps: 77000 Train loss: 0.2022
en_de Dev loss: 0.8453 r:0.2464
en_zh Dev loss: 0.7821 r:0.4332
ro_en Dev loss: 0.3414 r:0.8236
et_en Dev loss: 0.4662 r:0.6628
si_en Dev loss: 0.8721 r:0.5545
ne_en Dev loss: 0.4919 r:0.7392
ru_en Dev loss: 0.4527 r:0.7330
Current avg r:0.5989 Best avg r: 0.6276
04:41:23,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:42:53,642 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:24,180 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1984
en_de Dev loss: 0.8660 r:0.2245
en_zh Dev loss: 0.7920 r:0.4367
ro_en Dev loss: 0.3485 r:0.8201
et_en Dev loss: 0.4716 r:0.6505
si_en Dev loss: 0.9483 r:0.5413
ne_en Dev loss: 0.6016 r:0.7333
ru_en Dev loss: 0.4460 r:0.7320
Current avg r:0.5912 Best avg r: 0.6276
04:48:54,902 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:25,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:51:55,742 root INFO Epoch 7 Global steps: 78400 Train loss: 0.2071
en_de Dev loss: 0.8972 r:0.1966
en_zh Dev loss: 0.8095 r:0.4253
ro_en Dev loss: 0.3614 r:0.8165
et_en Dev loss: 0.4626 r:0.6519
si_en Dev loss: 0.8952 r:0.5390
ne_en Dev loss: 0.5661 r:0.7291
ru_en Dev loss: 0.4414 r:0.7381
Current avg r:0.5852 Best avg r: 0.6276
04:56:26,270 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:57:56,891 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:59:27,539 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1898
en_de Dev loss: 0.8724 r:0.2187
en_zh Dev loss: 0.7626 r:0.4412
ro_en Dev loss: 0.3273 r:0.8208
et_en Dev loss: 0.4704 r:0.6565
si_en Dev loss: 0.8482 r:0.5455
ne_en Dev loss: 0.5777 r:0.7289
ru_en Dev loss: 0.4249 r:0.7343
Current avg r:0.5923 Best avg r: 0.6276
05:03:58,572 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:05:29,138 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:06:59,651 root INFO Epoch 7 Global steps: 79800 Train loss: 0.2046
en_de Dev loss: 0.8986 r:0.2108
en_zh Dev loss: 0.7874 r:0.4395
ro_en Dev loss: 0.3453 r:0.8201
et_en Dev loss: 0.4822 r:0.6578
si_en Dev loss: 0.8826 r:0.5481
ne_en Dev loss: 0.5404 r:0.7294
ru_en Dev loss: 0.4654 r:0.7255
Current avg r:0.5902 Best avg r: 0.6276
05:11:30,173 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:13:00,715 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:14:31,324 root INFO Epoch 7 Global steps: 80500 Train loss: 0.2017
en_de Dev loss: 0.9307 r:0.1778
en_zh Dev loss: 0.8521 r:0.4261
ro_en Dev loss: 0.3567 r:0.8236
et_en Dev loss: 0.4909 r:0.6641
si_en Dev loss: 0.8479 r:0.5509
ne_en Dev loss: 0.5268 r:0.7316
ru_en Dev loss: 0.4912 r:0.7243
Current avg r:0.5855 Best avg r: 0.6276
05:19:02,29 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:20:32,468 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:22:03,111 root INFO Epoch 7 Global steps: 81200 Train loss: 0.2067
en_de Dev loss: 0.9259 r:0.2008
en_zh Dev loss: 0.8887 r:0.4293
ro_en Dev loss: 0.4280 r:0.8160
et_en Dev loss: 0.4975 r:0.6450
si_en Dev loss: 1.0467 r:0.5363
ne_en Dev loss: 0.6583 r:0.7318
ru_en Dev loss: 0.5551 r:0.7146
Current avg r:0.5820 Best avg r: 0.6276
05:26:34,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:04,882 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:29:35,551 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1977
en_de Dev loss: 0.9177 r:0.1954
en_zh Dev loss: 0.8631 r:0.4332
ro_en Dev loss: 0.3745 r:0.8203
et_en Dev loss: 0.4941 r:0.6527
si_en Dev loss: 0.9871 r:0.5366
ne_en Dev loss: 0.5680 r:0.7265
ru_en Dev loss: 0.4867 r:0.7328
Current avg r:0.5853 Best avg r: 0.6276
05:34:07,442 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:35:37,996 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:37:08,576 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1899
en_de Dev loss: 0.8955 r:0.2236
en_zh Dev loss: 0.8332 r:0.4447
ro_en Dev loss: 0.3585 r:0.8202
et_en Dev loss: 0.4987 r:0.6549
si_en Dev loss: 0.8997 r:0.5428
ne_en Dev loss: 0.4860 r:0.7286
ru_en Dev loss: 0.4317 r:0.7539
Current avg r:0.5955 Best avg r: 0.6276
05:41:40,197 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:10,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:44:41,506 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1936
en_de Dev loss: 0.8968 r:0.1978
en_zh Dev loss: 0.8628 r:0.4208
ro_en Dev loss: 0.3711 r:0.8189
et_en Dev loss: 0.4733 r:0.6566
si_en Dev loss: 0.9379 r:0.5373
ne_en Dev loss: 0.5521 r:0.7300
ru_en Dev loss: 0.4621 r:0.7420
Current avg r:0.5862 Best avg r: 0.6276
05:49:13,247 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:50:43,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:52:14,431 root INFO Epoch 7 Global steps: 84000 Train loss: 0.2145
en_de Dev loss: 0.9103 r:0.2058
en_zh Dev loss: 0.8317 r:0.4424
ro_en Dev loss: 0.3543 r:0.8192
et_en Dev loss: 0.4679 r:0.6582
si_en Dev loss: 0.9192 r:0.5413
ne_en Dev loss: 0.5324 r:0.7259
ru_en Dev loss: 0.4640 r:0.7387
Current avg r:0.5902 Best avg r: 0.6276
05:56:46,547 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:58:17,95 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:59:47,688 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1729
en_de Dev loss: 0.8919 r:0.2157
en_zh Dev loss: 0.8326 r:0.4449
ro_en Dev loss: 0.3705 r:0.8204
et_en Dev loss: 0.4565 r:0.6633
si_en Dev loss: 0.9417 r:0.5478
ne_en Dev loss: 0.5860 r:0.7287
ru_en Dev loss: 0.4574 r:0.7476
Current avg r:0.5955 Best avg r: 0.6276
06:04:18,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:05:49,267 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:07:19,878 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1727
en_de Dev loss: 0.8956 r:0.2093
en_zh Dev loss: 0.8257 r:0.4416
ro_en Dev loss: 0.3719 r:0.8238
et_en Dev loss: 0.4627 r:0.6690
si_en Dev loss: 0.8785 r:0.5531
ne_en Dev loss: 0.5167 r:0.7332
ru_en Dev loss: 0.4630 r:0.7395
Current avg r:0.5956 Best avg r: 0.6276
06:11:50,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:13:21,193 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:14:51,716 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1631
en_de Dev loss: 0.8892 r:0.2082
en_zh Dev loss: 0.8441 r:0.4430
ro_en Dev loss: 0.3581 r:0.8246
et_en Dev loss: 0.4746 r:0.6690
si_en Dev loss: 0.8640 r:0.5498
ne_en Dev loss: 0.4638 r:0.7352
ru_en Dev loss: 0.4458 r:0.7464
Current avg r:0.5966 Best avg r: 0.6276
06:19:22,366 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:20:52,944 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:22:23,581 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1788
en_de Dev loss: 0.8731 r:0.2110
en_zh Dev loss: 0.8134 r:0.4329
ro_en Dev loss: 0.3409 r:0.8200
et_en Dev loss: 0.4959 r:0.6553
si_en Dev loss: 0.8719 r:0.5371
ne_en Dev loss: 0.5132 r:0.7310
ru_en Dev loss: 0.4061 r:0.7469
Current avg r:0.5906 Best avg r: 0.6276
06:26:54,508 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:28:25,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:29:55,752 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1825
en_de Dev loss: 0.8879 r:0.2265
en_zh Dev loss: 0.8281 r:0.4475
ro_en Dev loss: 0.3538 r:0.8215
et_en Dev loss: 0.4710 r:0.6549
si_en Dev loss: 0.8858 r:0.5427
ne_en Dev loss: 0.4875 r:0.7289
ru_en Dev loss: 0.4656 r:0.7404
Current avg r:0.5946 Best avg r: 0.6276
06:34:26,616 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:35:57,233 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:27,809 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1686
en_de Dev loss: 0.8987 r:0.2055
en_zh Dev loss: 0.8480 r:0.4415
ro_en Dev loss: 0.3613 r:0.8197
et_en Dev loss: 0.4856 r:0.6525
si_en Dev loss: 0.9475 r:0.5333
ne_en Dev loss: 0.5808 r:0.7270
ru_en Dev loss: 0.4956 r:0.7251
Current avg r:0.5864 Best avg r: 0.6276
06:41:58,742 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:43:29,347 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:44:59,973 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1712
en_de Dev loss: 0.8872 r:0.2081
en_zh Dev loss: 0.8186 r:0.4391
ro_en Dev loss: 0.3433 r:0.8205
et_en Dev loss: 0.4784 r:0.6412
si_en Dev loss: 0.9848 r:0.5315
ne_en Dev loss: 0.6439 r:0.7266
ru_en Dev loss: 0.4589 r:0.7279
Current avg r:0.5850 Best avg r: 0.6276
06:49:30,945 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:01,551 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:52:32,189 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1818
en_de Dev loss: 0.8921 r:0.2434
en_zh Dev loss: 0.8535 r:0.4385
ro_en Dev loss: 0.3676 r:0.8183
et_en Dev loss: 0.5156 r:0.6490
si_en Dev loss: 0.9380 r:0.5388
ne_en Dev loss: 0.5034 r:0.7330
ru_en Dev loss: 0.4489 r:0.7433
Current avg r:0.5949 Best avg r: 0.6276
06:57:03,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:58:33,878 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:00:04,597 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1673
en_de Dev loss: 0.8752 r:0.2367
en_zh Dev loss: 0.7808 r:0.4465
ro_en Dev loss: 0.3600 r:0.8154
et_en Dev loss: 0.5322 r:0.6488
si_en Dev loss: 0.8569 r:0.5397
ne_en Dev loss: 0.4864 r:0.7242
ru_en Dev loss: 0.4684 r:0.7286
Current avg r:0.5914 Best avg r: 0.6276
07:04:36,357 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:06:07,12 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:07:37,680 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1696
en_de Dev loss: 0.9046 r:0.2310
en_zh Dev loss: 0.8089 r:0.4482
ro_en Dev loss: 0.3717 r:0.8182
et_en Dev loss: 0.5124 r:0.6608
si_en Dev loss: 0.9488 r:0.5385
ne_en Dev loss: 0.5146 r:0.7258
ru_en Dev loss: 0.4471 r:0.7509
Current avg r:0.5962 Best avg r: 0.6276
07:12:08,672 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:39,297 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:09,923 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1744
en_de Dev loss: 0.8849 r:0.2202
en_zh Dev loss: 0.8160 r:0.4273
ro_en Dev loss: 0.3708 r:0.8104
et_en Dev loss: 0.4669 r:0.6407
si_en Dev loss: 0.9743 r:0.5222
ne_en Dev loss: 0.6858 r:0.7135
ru_en Dev loss: 0.4883 r:0.7217
Current avg r:0.5794 Best avg r: 0.6276
07:19:40,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:21:10,850 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:22:41,348 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1699
en_de Dev loss: 0.8851 r:0.2200
en_zh Dev loss: 0.7917 r:0.4430
ro_en Dev loss: 0.3493 r:0.8188
et_en Dev loss: 0.4756 r:0.6526
si_en Dev loss: 0.8903 r:0.5380
ne_en Dev loss: 0.4932 r:0.7306
ru_en Dev loss: 0.4596 r:0.7334
Current avg r:0.5909 Best avg r: 0.6276
07:27:12,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:28:42,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:13,144 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1709
en_de Dev loss: 0.9343 r:0.2243
en_zh Dev loss: 0.8816 r:0.4382
ro_en Dev loss: 0.3702 r:0.8242
et_en Dev loss: 0.4973 r:0.6526
si_en Dev loss: 0.9241 r:0.5345
ne_en Dev loss: 0.5588 r:0.7273
ru_en Dev loss: 0.4940 r:0.7385
Current avg r:0.5914 Best avg r: 0.6276
07:34:43,541 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:36:14,17 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:44,605 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1740
en_de Dev loss: 0.9075 r:0.2248
en_zh Dev loss: 0.8200 r:0.4349
ro_en Dev loss: 0.3401 r:0.8247
et_en Dev loss: 0.4795 r:0.6517
si_en Dev loss: 0.8744 r:0.5367
ne_en Dev loss: 0.5737 r:0.7174
ru_en Dev loss: 0.4743 r:0.7331
Current avg r:0.5890 Best avg r: 0.6276
07:42:15,549 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:43:46,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:16,795 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1739
en_de Dev loss: 0.9282 r:0.1989
en_zh Dev loss: 0.8316 r:0.4364
ro_en Dev loss: 0.3854 r:0.8166
et_en Dev loss: 0.5124 r:0.6461
si_en Dev loss: 0.9682 r:0.5351
ne_en Dev loss: 0.5778 r:0.7190
ru_en Dev loss: 0.5098 r:0.7281
Current avg r:0.5829 Best avg r: 0.6276
07:49:49,300 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:51:19,879 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:50,512 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1525
en_de Dev loss: 0.9181 r:0.1962
en_zh Dev loss: 0.7732 r:0.4553
ro_en Dev loss: 0.3371 r:0.8254
et_en Dev loss: 0.4774 r:0.6572
si_en Dev loss: 0.8780 r:0.5436
ne_en Dev loss: 0.5198 r:0.7240
ru_en Dev loss: 0.4283 r:0.7521
Current avg r:0.5934 Best avg r: 0.6276
07:57:22,207 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:58:52,921 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:00:23,696 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1534
en_de Dev loss: 0.9500 r:0.1912
en_zh Dev loss: 0.8515 r:0.4475
ro_en Dev loss: 0.3942 r:0.8192
et_en Dev loss: 0.5290 r:0.6461
si_en Dev loss: 1.0329 r:0.5360
ne_en Dev loss: 0.5633 r:0.7198
ru_en Dev loss: 0.4890 r:0.7450
Current avg r:0.5864 Best avg r: 0.6276
08:04:55,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:06:26,30 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:07:56,690 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1554
en_de Dev loss: 0.9022 r:0.2149
en_zh Dev loss: 0.7869 r:0.4598
ro_en Dev loss: 0.3658 r:0.8172
et_en Dev loss: 0.4971 r:0.6471
si_en Dev loss: 0.9539 r:0.5351
ne_en Dev loss: 0.5385 r:0.7183
ru_en Dev loss: 0.4357 r:0.7531
Current avg r:0.5922 Best avg r: 0.6276
08:12:27,332 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:13:57,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:15:28,473 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1607
en_de Dev loss: 0.9389 r:0.1924
en_zh Dev loss: 0.8376 r:0.4429
ro_en Dev loss: 0.3648 r:0.8228
et_en Dev loss: 0.5116 r:0.6502
si_en Dev loss: 0.9986 r:0.5300
ne_en Dev loss: 0.5647 r:0.7209
ru_en Dev loss: 0.4484 r:0.7549
Current avg r:0.5877 Best avg r: 0.6276
08:19:59,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:21:30,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:00,668 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1496
en_de Dev loss: 0.9218 r:0.2056
en_zh Dev loss: 0.8047 r:0.4479
ro_en Dev loss: 0.3533 r:0.8208
et_en Dev loss: 0.4928 r:0.6508
si_en Dev loss: 0.9261 r:0.5380
ne_en Dev loss: 0.5387 r:0.7220
ru_en Dev loss: 0.4246 r:0.7551
Current avg r:0.5915 Best avg r: 0.6276
08:27:31,592 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:29:02,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:30:32,841 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1598
en_de Dev loss: 0.9089 r:0.1940
en_zh Dev loss: 0.8167 r:0.4436
ro_en Dev loss: 0.3364 r:0.8234
et_en Dev loss: 0.4644 r:0.6550
si_en Dev loss: 0.8863 r:0.5316
ne_en Dev loss: 0.4953 r:0.7228
ru_en Dev loss: 0.4375 r:0.7501
Current avg r:0.5886 Best avg r: 0.6276
08:35:04,146 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:34,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:38:05,479 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1522
en_de Dev loss: 0.9029 r:0.2010
en_zh Dev loss: 0.8081 r:0.4393
ro_en Dev loss: 0.3362 r:0.8232
et_en Dev loss: 0.4487 r:0.6579
si_en Dev loss: 0.8863 r:0.5337
ne_en Dev loss: 0.5318 r:0.7187
ru_en Dev loss: 0.4213 r:0.7547
Current avg r:0.5898 Best avg r: 0.6276
08:42:36,774 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:44:07,372 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:45:37,996 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1546
en_de Dev loss: 0.9014 r:0.1986
en_zh Dev loss: 0.8251 r:0.4431
ro_en Dev loss: 0.3489 r:0.8233
et_en Dev loss: 0.4992 r:0.6530
si_en Dev loss: 0.9532 r:0.5279
ne_en Dev loss: 0.5529 r:0.7172
ru_en Dev loss: 0.4659 r:0.7368
Current avg r:0.5857 Best avg r: 0.6276
08:50:09,392 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:51:39,972 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:53:10,631 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1525
en_de Dev loss: 0.8989 r:0.1867
en_zh Dev loss: 0.8203 r:0.4405
ro_en Dev loss: 0.3475 r:0.8201
et_en Dev loss: 0.4959 r:0.6392
si_en Dev loss: 1.0039 r:0.5272
ne_en Dev loss: 0.5774 r:0.7231
ru_en Dev loss: 0.4460 r:0.7385
Current avg r:0.5822 Best avg r: 0.6276
08:57:41,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:59:11,959 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:00:42,559 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1547
en_de Dev loss: 0.9160 r:0.2080
en_zh Dev loss: 0.8379 r:0.4456
ro_en Dev loss: 0.3586 r:0.8191
et_en Dev loss: 0.5135 r:0.6568
si_en Dev loss: 0.8964 r:0.5355
ne_en Dev loss: 0.5452 r:0.7205
ru_en Dev loss: 0.4546 r:0.7479
Current avg r:0.5905 Best avg r: 0.6276
09:05:13,156 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:06:43,732 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:08:14,365 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1540
en_de Dev loss: 0.9012 r:0.2059
en_zh Dev loss: 0.7929 r:0.4447
ro_en Dev loss: 0.3371 r:0.8216
et_en Dev loss: 0.4851 r:0.6510
si_en Dev loss: 0.8848 r:0.5339
ne_en Dev loss: 0.5009 r:0.7206
ru_en Dev loss: 0.4327 r:0.7477
Current avg r:0.5893 Best avg r: 0.6276
09:12:45,133 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:14:15,712 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:15:46,322 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1514
en_de Dev loss: 0.9195 r:0.2014
en_zh Dev loss: 0.8099 r:0.4425
ro_en Dev loss: 0.3638 r:0.8201
et_en Dev loss: 0.4605 r:0.6500
si_en Dev loss: 0.9785 r:0.5340
ne_en Dev loss: 0.6763 r:0.7205
ru_en Dev loss: 0.4592 r:0.7457
Current avg r:0.5877 Best avg r: 0.6276
09:20:17,68 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:21:47,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:23:18,272 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1446
en_de Dev loss: 0.9328 r:0.2095
en_zh Dev loss: 0.8246 r:0.4502
ro_en Dev loss: 0.3770 r:0.8180
et_en Dev loss: 0.5226 r:0.6405
si_en Dev loss: 0.9791 r:0.5316
ne_en Dev loss: 0.5774 r:0.7175
ru_en Dev loss: 0.4768 r:0.7411
Current avg r:0.5869 Best avg r: 0.6276
09:27:49,122 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:29:19,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:30:50,418 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1476
en_de Dev loss: 0.9182 r:0.2117
en_zh Dev loss: 0.7764 r:0.4669
ro_en Dev loss: 0.3656 r:0.8209
et_en Dev loss: 0.4970 r:0.6500
si_en Dev loss: 0.9366 r:0.5420
ne_en Dev loss: 0.5853 r:0.7147
ru_en Dev loss: 0.4540 r:0.7441
Current avg r:0.5929 Best avg r: 0.6276
09:35:21,412 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:36:52,170 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:38:22,930 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1429
en_de Dev loss: 0.9232 r:0.2077
en_zh Dev loss: 0.8146 r:0.4532
ro_en Dev loss: 0.3820 r:0.8173
et_en Dev loss: 0.5006 r:0.6438
si_en Dev loss: 1.0105 r:0.5330
ne_en Dev loss: 0.6442 r:0.7235
ru_en Dev loss: 0.4826 r:0.7373
Current avg r:0.5880 Best avg r: 0.6276
09:42:55,962 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:44:26,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:45:57,384 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1357
en_de Dev loss: 0.9327 r:0.2102
en_zh Dev loss: 0.7972 r:0.4677
ro_en Dev loss: 0.3609 r:0.8238
et_en Dev loss: 0.5170 r:0.6563
si_en Dev loss: 0.9213 r:0.5436
ne_en Dev loss: 0.5695 r:0.7213
ru_en Dev loss: 0.4397 r:0.7617
Current avg r:0.5978 Best avg r: 0.6276
09:50:28,239 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:51:58,857 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:53:29,472 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1352
en_de Dev loss: 0.9502 r:0.1955
en_zh Dev loss: 0.7908 r:0.4647
ro_en Dev loss: 0.3415 r:0.8263
et_en Dev loss: 0.4928 r:0.6549
si_en Dev loss: 0.8833 r:0.5429
ne_en Dev loss: 0.5234 r:0.7217
ru_en Dev loss: 0.4256 r:0.7607
Current avg r:0.5952 Best avg r: 0.6276
09:58:00,307 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:59:30,893 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:01:01,572 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1399
en_de Dev loss: 0.9387 r:0.1860
en_zh Dev loss: 0.8570 r:0.4412
ro_en Dev loss: 0.3786 r:0.8149
et_en Dev loss: 0.5041 r:0.6375
si_en Dev loss: 1.0035 r:0.5206
ne_en Dev loss: 0.5951 r:0.7144
ru_en Dev loss: 0.4996 r:0.7319
Current avg r:0.5781 Best avg r: 0.6276
10:05:33,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:07:03,861 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:08:34,592 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1323
en_de Dev loss: 0.9466 r:0.1876
en_zh Dev loss: 0.8097 r:0.4626
ro_en Dev loss: 0.3674 r:0.8222
et_en Dev loss: 0.5041 r:0.6516
si_en Dev loss: 0.9066 r:0.5414
ne_en Dev loss: 0.5133 r:0.7142
ru_en Dev loss: 0.4855 r:0.7392
Current avg r:0.5884 Best avg r: 0.6276
10:13:06,164 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:14:36,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:16:07,630 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1342
en_de Dev loss: 0.9102 r:0.2156
en_zh Dev loss: 0.7674 r:0.4692
ro_en Dev loss: 0.3646 r:0.8196
et_en Dev loss: 0.5039 r:0.6489
si_en Dev loss: 0.9194 r:0.5409
ne_en Dev loss: 0.5578 r:0.7253
ru_en Dev loss: 0.4310 r:0.7524
Current avg r:0.5960 Best avg r: 0.6276
10:20:39,201 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:22:09,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:23:40,641 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1391
en_de Dev loss: 0.9129 r:0.1957
en_zh Dev loss: 0.7821 r:0.4556
ro_en Dev loss: 0.3341 r:0.8211
et_en Dev loss: 0.4882 r:0.6454
si_en Dev loss: 0.8585 r:0.5424
ne_en Dev loss: 0.5175 r:0.7195
ru_en Dev loss: 0.4279 r:0.7484
Current avg r:0.5897 Best avg r: 0.6276
10:28:12,238 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:29:42,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:31:13,685 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1388
en_de Dev loss: 0.9329 r:0.2004
en_zh Dev loss: 0.8036 r:0.4614
ro_en Dev loss: 0.3479 r:0.8203
et_en Dev loss: 0.4951 r:0.6603
si_en Dev loss: 0.8511 r:0.5484
ne_en Dev loss: 0.5137 r:0.7163
ru_en Dev loss: 0.4263 r:0.7560
Current avg r:0.5947 Best avg r: 0.6276
10:35:44,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:37:15,379 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
