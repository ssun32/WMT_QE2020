14:55:17,652 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:55:30,624 root INFO 
id:en_de cur r: 0.0078 best r: 0.0078
14:56:35,428 root INFO 
id:ne_en cur r: 0.4905 best r: 0.4905
14:56:48,317 root INFO 
id:ru_en cur r: 0.5728 best r: 0.5728
14:56:48,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:58:18,860 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
14:58:18,870 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
14:58:18,876 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
14:58:18,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
14:58:18,889 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
14:58:18,896 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
14:58:18,903 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
14:58:31,829 root INFO Epoch 0 Global steps: 700 Train loss: 0.8782
en_de Dev loss: 0.8888 r:0.0244
en_zh Dev loss: 0.8143 r:0.2244
ro_en Dev loss: 0.8056 r:0.6238
et_en Dev loss: 0.7160 r:0.4036
si_en Dev loss: 0.8115 r:0.4367
ne_en Dev loss: 0.7462 r:0.5375
ru_en Dev loss: 0.7607 r:0.5840
Current avg r:0.4049 Best avg r: 0.4049
15:03:02,597 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:03:41,380 root INFO 
id:en_zh cur r: 0.1135 best r: 0.1135
15:03:54,326 root INFO 
id:ro_en cur r: 0.4271 best r: 0.4271
15:04:07,311 root INFO 
id:et_en cur r: 0.2547 best r: 0.2547
15:04:20,309 root INFO 
id:si_en cur r: 0.3645 best r: 0.3645
15:04:46,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:06:16,664 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8180
en_de Dev loss: 0.9146 r:0.0531
en_zh Dev loss: 0.7922 r:0.2401
ro_en Dev loss: 0.7536 r:0.5738
et_en Dev loss: 0.6536 r:0.3732
si_en Dev loss: 0.8188 r:0.4077
ne_en Dev loss: 0.6746 r:0.4676
ru_en Dev loss: 0.6229 r:0.6270
Current avg r:0.3918 Best avg r: 0.4049
15:10:47,484 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:11:00,431 root INFO 
id:en_de cur r: 0.0255 best r: 0.0255
15:11:26,314 root INFO 
id:en_zh cur r: 0.2751 best r: 0.2751
15:11:39,278 root INFO 
id:ro_en cur r: 0.6131 best r: 0.6131
15:11:52,274 root INFO 
id:et_en cur r: 0.4597 best r: 0.4597
15:12:05,251 root INFO 
id:si_en cur r: 0.3810 best r: 0.3810
15:12:18,224 root INFO 
id:ne_en cur r: 0.5902 best r: 0.5902
15:12:31,93 root INFO 
id:ru_en cur r: 0.6176 best r: 0.6176
15:12:31,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:14:01,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:14:01,724 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:14:01,732 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:14:01,738 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:14:01,746 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:14:01,752 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:14:01,759 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:14:14,687 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7633
en_de Dev loss: 0.9227 r:0.1085
en_zh Dev loss: 0.7650 r:0.2933
ro_en Dev loss: 0.5817 r:0.6777
et_en Dev loss: 0.5542 r:0.5252
si_en Dev loss: 0.6935 r:0.4662
ne_en Dev loss: 0.5764 r:0.5737
ru_en Dev loss: 0.5812 r:0.6547
Current avg r:0.4713 Best avg r: 0.4713
15:18:45,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:18:58,478 root INFO 
id:en_de cur r: 0.0858 best r: 0.0858
15:19:24,337 root INFO 
id:en_zh cur r: 0.2796 best r: 0.2796
15:19:37,305 root INFO 
id:ro_en cur r: 0.6619 best r: 0.6619
15:19:50,282 root INFO 
id:et_en cur r: 0.5537 best r: 0.5537
15:20:03,284 root INFO 
id:si_en cur r: 0.4399 best r: 0.4399
15:20:29,130 root INFO 
id:ru_en cur r: 0.6641 best r: 0.6641
15:20:29,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:21:59,647 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:21:59,658 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:21:59,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:21:59,670 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:21:59,680 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:21:59,686 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:21:59,693 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:22:12,628 root INFO Epoch 0 Global steps: 2800 Train loss: 0.7547
en_de Dev loss: 0.9316 r:0.1362
en_zh Dev loss: 0.7714 r:0.3081
ro_en Dev loss: 0.5304 r:0.6939
et_en Dev loss: 0.4851 r:0.6137
si_en Dev loss: 0.7116 r:0.4822
ne_en Dev loss: 0.5370 r:0.6096
ru_en Dev loss: 0.5349 r:0.6896
Current avg r:0.5047 Best avg r: 0.5047
15:26:44,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:26:57,109 root INFO 
id:en_de cur r: 0.0893 best r: 0.0893
15:27:22,969 root INFO 
id:en_zh cur r: 0.3418 best r: 0.3418
15:27:35,928 root INFO 
id:ro_en cur r: 0.7079 best r: 0.7079
15:27:48,898 root INFO 
id:et_en cur r: 0.6172 best r: 0.6172
15:28:01,867 root INFO 
id:si_en cur r: 0.5125 best r: 0.5125
15:28:14,857 root INFO 
id:ne_en cur r: 0.6584 best r: 0.6584
15:28:27,729 root INFO 
id:ru_en cur r: 0.7004 best r: 0.7004
15:28:27,730 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:29:58,316 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:29:58,327 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:29:58,333 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:29:58,339 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:29:58,345 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:29:58,354 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:29:58,362 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:30:11,298 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6613
en_de Dev loss: 0.9686 r:0.1356
en_zh Dev loss: 0.7560 r:0.3493
ro_en Dev loss: 0.4646 r:0.7211
et_en Dev loss: 0.4125 r:0.6540
si_en Dev loss: 0.6471 r:0.5210
ne_en Dev loss: 0.4684 r:0.6507
ru_en Dev loss: 0.4926 r:0.7069
Current avg r:0.5341 Best avg r: 0.5341
15:34:42,896 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:34:55,861 root INFO 
id:en_de cur r: 0.1228 best r: 0.1228
15:35:21,682 root INFO 
id:en_zh cur r: 0.3851 best r: 0.3851
15:35:34,621 root INFO 
id:ro_en cur r: 0.7218 best r: 0.7218
15:35:47,586 root INFO 
id:et_en cur r: 0.6528 best r: 0.6528
15:36:00,554 root INFO 
id:si_en cur r: 0.5237 best r: 0.5237
15:36:26,388 root INFO 
id:ru_en cur r: 0.7105 best r: 0.7105
15:36:26,389 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:37:56,970 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:37:56,980 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:37:56,986 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:37:56,992 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:37:56,998 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:37:57,4 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:37:57,10 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:38:09,930 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6278
en_de Dev loss: 0.9436 r:0.1561
en_zh Dev loss: 0.7499 r:0.3888
ro_en Dev loss: 0.4575 r:0.7349
et_en Dev loss: 0.4044 r:0.6689
si_en Dev loss: 0.6913 r:0.5334
ne_en Dev loss: 0.4777 r:0.6587
ru_en Dev loss: 0.4844 r:0.7258
Current avg r:0.5523 Best avg r: 0.5523
15:42:41,822 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:42:54,770 root INFO 
id:en_de cur r: 0.1537 best r: 0.1537
15:43:20,650 root INFO 
id:ro_en cur r: 0.7283 best r: 0.7283
15:43:59,553 root INFO 
id:ne_en cur r: 0.6640 best r: 0.6640
15:44:12,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:45:42,978 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:45:42,989 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:45:42,995 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:45:43,1 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:45:43,8 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:45:43,13 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:45:43,19 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:45:55,953 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6337
en_de Dev loss: 0.9496 r:0.1685
en_zh Dev loss: 0.7766 r:0.3911
ro_en Dev loss: 0.4704 r:0.7530
et_en Dev loss: 0.4096 r:0.6675
si_en Dev loss: 0.7318 r:0.5328
ne_en Dev loss: 0.4946 r:0.6577
ru_en Dev loss: 0.5176 r:0.7222
Current avg r:0.5561 Best avg r: 0.5561
15:50:27,599 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:50:40,550 root INFO 
id:en_de cur r: 0.1827 best r: 0.1827
15:51:06,409 root INFO 
id:en_zh cur r: 0.4086 best r: 0.4086
15:51:19,366 root INFO 
id:ro_en cur r: 0.7616 best r: 0.7616
15:51:32,329 root INFO 
id:et_en cur r: 0.6619 best r: 0.6619
15:51:45,299 root INFO 
id:si_en cur r: 0.5681 best r: 0.5681
15:51:58,265 root INFO 
id:ne_en cur r: 0.6919 best r: 0.6919
15:52:11,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:53:41,651 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
15:53:41,659 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
15:53:41,664 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
15:53:41,669 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
15:53:41,675 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
15:53:41,681 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
15:53:41,686 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
15:53:54,607 root INFO Epoch 0 Global steps: 5600 Train loss: 0.6254
en_de Dev loss: 0.9146 r:0.1765
en_zh Dev loss: 0.7132 r:0.4131
ro_en Dev loss: 0.3710 r:0.7709
et_en Dev loss: 0.3826 r:0.6785
si_en Dev loss: 0.5859 r:0.5821
ne_en Dev loss: 0.4136 r:0.6980
ru_en Dev loss: 0.4884 r:0.7033
Current avg r:0.5746 Best avg r: 0.5746
15:58:26,148 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:56,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:01:27,302 root INFO Epoch 0 Global steps: 6300 Train loss: 0.6015
en_de Dev loss: 0.9622 r:0.1882
en_zh Dev loss: 0.8296 r:0.3984
ro_en Dev loss: 0.4956 r:0.7667
et_en Dev loss: 0.4741 r:0.6526
si_en Dev loss: 0.8290 r:0.5413
ne_en Dev loss: 0.5897 r:0.6645
ru_en Dev loss: 0.5944 r:0.7005
Current avg r:0.5589 Best avg r: 0.5746
16:05:58,404 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:28,935 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:08:59,460 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5990
en_de Dev loss: 0.9711 r:0.1680
en_zh Dev loss: 0.7861 r:0.4091
ro_en Dev loss: 0.4383 r:0.7667
et_en Dev loss: 0.4158 r:0.6693
si_en Dev loss: 0.6524 r:0.5587
ne_en Dev loss: 0.4394 r:0.6862
ru_en Dev loss: 0.5337 r:0.7170
Current avg r:0.5679 Best avg r: 0.5746
16:13:30,168 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:14:08,964 root INFO 
id:ro_en cur r: 0.7749 best r: 0.7749
16:14:21,941 root INFO 
id:et_en cur r: 0.6626 best r: 0.6626
16:14:47,906 root INFO 
id:ne_en cur r: 0.6986 best r: 0.6986
16:15:00,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:16:31,249 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
16:16:31,258 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:16:31,264 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:16:31,270 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
16:16:31,276 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
16:16:31,282 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:16:31,289 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:16:44,234 root INFO Epoch 0 Global steps: 7700 Train loss: 0.6102
en_de Dev loss: 0.9697 r:0.1909
en_zh Dev loss: 0.7618 r:0.4167
ro_en Dev loss: 0.4076 r:0.7764
et_en Dev loss: 0.3964 r:0.6781
si_en Dev loss: 0.6728 r:0.5715
ne_en Dev loss: 0.4248 r:0.6987
ru_en Dev loss: 0.5122 r:0.7287
Current avg r:0.5801 Best avg r: 0.5801
16:21:15,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:21:54,200 root INFO 
id:en_zh cur r: 0.4541 best r: 0.4541
16:22:07,184 root INFO 
id:ro_en cur r: 0.7912 best r: 0.7912
16:22:20,175 root INFO 
id:et_en cur r: 0.6799 best r: 0.6799
16:22:33,158 root INFO 
id:si_en cur r: 0.5864 best r: 0.5864
16:22:46,147 root INFO 
id:ne_en cur r: 0.7206 best r: 0.7206
16:22:59,33 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:24:29,551 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
16:24:29,559 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:24:29,568 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:24:29,574 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
16:24:29,580 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
16:24:29,588 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:24:29,596 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:24:42,525 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5876
en_de Dev loss: 0.8796 r:0.1994
en_zh Dev loss: 0.6759 r:0.4499
ro_en Dev loss: 0.3442 r:0.7916
et_en Dev loss: 0.3727 r:0.6889
si_en Dev loss: 0.6624 r:0.5736
ne_en Dev loss: 0.3924 r:0.7131
ru_en Dev loss: 0.4899 r:0.7185
Current avg r:0.5907 Best avg r: 0.5907
16:29:13,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:29:52,211 root INFO 
id:ro_en cur r: 0.7966 best r: 0.7966
16:30:05,178 root INFO 
id:et_en cur r: 0.6902 best r: 0.6902
16:30:18,155 root INFO 
id:si_en cur r: 0.5871 best r: 0.5871
16:30:31,123 root INFO 
id:ne_en cur r: 0.7251 best r: 0.7251
16:30:43,984 root INFO 
id:ru_en cur r: 0.7472 best r: 0.7472
16:30:43,985 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:32:14,465 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
16:32:14,475 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:32:14,480 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:32:14,486 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
16:32:14,492 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
16:32:14,498 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:32:14,503 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:32:27,428 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5714
en_de Dev loss: 0.8699 r:0.2034
en_zh Dev loss: 0.6591 r:0.4509
ro_en Dev loss: 0.3459 r:0.7883
et_en Dev loss: 0.3726 r:0.6947
si_en Dev loss: 0.6713 r:0.5821
ne_en Dev loss: 0.3966 r:0.7187
ru_en Dev loss: 0.4211 r:0.7461
Current avg r:0.5977 Best avg r: 0.5977
16:36:58,434 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:37:11,380 root INFO 
id:en_de cur r: 0.2474 best r: 0.2474
16:38:29,79 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:39:59,694 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5361
en_de Dev loss: 0.9075 r:0.2282
en_zh Dev loss: 0.7432 r:0.4384
ro_en Dev loss: 0.4383 r:0.7882
et_en Dev loss: 0.4094 r:0.6869
si_en Dev loss: 0.8129 r:0.5664
ne_en Dev loss: 0.5560 r:0.7053
ru_en Dev loss: 0.5172 r:0.7193
Current avg r:0.5904 Best avg r: 0.5977
16:44:31,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:45:10,289 root INFO 
id:ro_en cur r: 0.8054 best r: 0.8054
16:45:23,272 root INFO 
id:et_en cur r: 0.6972 best r: 0.6972
16:45:36,257 root INFO 
id:si_en cur r: 0.5958 best r: 0.5958
16:45:49,236 root INFO 
id:ne_en cur r: 0.7402 best r: 0.7402
16:46:02,88 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:47:32,620 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
16:47:32,629 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
16:47:32,637 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
16:47:32,644 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
16:47:32,651 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
16:47:32,656 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
16:47:32,663 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
16:47:45,594 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5690
en_de Dev loss: 0.8718 r:0.2230
en_zh Dev loss: 0.7135 r:0.4426
ro_en Dev loss: 0.3420 r:0.8015
et_en Dev loss: 0.3657 r:0.7023
si_en Dev loss: 0.7422 r:0.5883
ne_en Dev loss: 0.4345 r:0.7316
ru_en Dev loss: 0.4711 r:0.7368
Current avg r:0.6037 Best avg r: 0.6037
16:52:18,829 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:53:49,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:55:19,967 root INFO Epoch 1 Global steps: 11200 Train loss: 0.5212
en_de Dev loss: 0.8920 r:0.2354
en_zh Dev loss: 0.7632 r:0.4400
ro_en Dev loss: 0.3627 r:0.8013
et_en Dev loss: 0.3836 r:0.6951
si_en Dev loss: 0.6740 r:0.5939
ne_en Dev loss: 0.4006 r:0.7295
ru_en Dev loss: 0.5024 r:0.7274
Current avg r:0.6032 Best avg r: 0.6037
16:59:51,792 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:01:09,627 root INFO 
id:ne_en cur r: 0.7446 best r: 0.7446
17:01:22,490 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:02:53,103 root INFO Epoch 1 Global steps: 11900 Train loss: 0.5216
en_de Dev loss: 0.9384 r:0.2364
en_zh Dev loss: 0.7897 r:0.4367
ro_en Dev loss: 0.3927 r:0.7996
et_en Dev loss: 0.4063 r:0.6877
si_en Dev loss: 0.7387 r:0.5853
ne_en Dev loss: 0.4589 r:0.7339
ru_en Dev loss: 0.5360 r:0.7206
Current avg r:0.6000 Best avg r: 0.6037
17:07:24,684 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:08:03,482 root INFO 
id:en_zh cur r: 0.4644 best r: 0.4644
17:08:16,442 root INFO 
id:ro_en cur r: 0.8177 best r: 0.8177
17:08:42,423 root INFO 
id:si_en cur r: 0.6105 best r: 0.6105
17:09:08,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:10:38,796 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
17:10:38,807 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:10:38,814 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:10:38,820 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
17:10:38,826 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
17:10:38,832 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:10:38,839 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:10:51,771 root INFO Epoch 1 Global steps: 12600 Train loss: 0.5259
en_de Dev loss: 0.8859 r:0.2448
en_zh Dev loss: 0.7648 r:0.4511
ro_en Dev loss: 0.3505 r:0.8115
et_en Dev loss: 0.4028 r:0.6902
si_en Dev loss: 0.7451 r:0.6041
ne_en Dev loss: 0.4932 r:0.7342
ru_en Dev loss: 0.5139 r:0.7302
Current avg r:0.6094 Best avg r: 0.6094
17:15:23,363 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:16:53,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:18:24,517 root INFO Epoch 1 Global steps: 13300 Train loss: 0.5034
en_de Dev loss: 0.8951 r:0.2307
en_zh Dev loss: 0.7368 r:0.4579
ro_en Dev loss: 0.3981 r:0.8033
et_en Dev loss: 0.4114 r:0.6872
si_en Dev loss: 0.8192 r:0.5940
ne_en Dev loss: 0.5345 r:0.7261
ru_en Dev loss: 0.5338 r:0.7338
Current avg r:0.6047 Best avg r: 0.6094
17:22:55,798 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:23:08,751 root INFO 
id:en_de cur r: 0.2514 best r: 0.2514
17:24:13,552 root INFO 
id:ne_en cur r: 0.7485 best r: 0.7485
17:24:26,401 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:25:56,946 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
17:25:56,958 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:25:56,965 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:25:56,972 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
17:25:56,979 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
17:25:56,986 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:25:56,994 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:26:09,920 root INFO Epoch 1 Global steps: 14000 Train loss: 0.5403
en_de Dev loss: 0.8743 r:0.2485
en_zh Dev loss: 0.7292 r:0.4590
ro_en Dev loss: 0.3408 r:0.8097
et_en Dev loss: 0.3670 r:0.7001
si_en Dev loss: 0.6989 r:0.6032
ne_en Dev loss: 0.4401 r:0.7421
ru_en Dev loss: 0.5355 r:0.7182
Current avg r:0.6115 Best avg r: 0.6115
17:30:41,863 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:54,829 root INFO 
id:en_de cur r: 0.2516 best r: 0.2516
17:32:12,523 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:33:43,144 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5266
en_de Dev loss: 0.9406 r:0.2522
en_zh Dev loss: 0.8227 r:0.4497
ro_en Dev loss: 0.4066 r:0.8029
et_en Dev loss: 0.4025 r:0.6921
si_en Dev loss: 0.7158 r:0.5946
ne_en Dev loss: 0.4897 r:0.7308
ru_en Dev loss: 0.5518 r:0.7257
Current avg r:0.6069 Best avg r: 0.6115
17:38:14,274 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:27,224 root INFO 
id:en_de cur r: 0.2648 best r: 0.2648
17:38:53,130 root INFO 
id:ro_en cur r: 0.8178 best r: 0.8178
17:39:06,113 root INFO 
id:et_en cur r: 0.7071 best r: 0.7071
17:39:19,109 root INFO 
id:si_en cur r: 0.6114 best r: 0.6114
17:39:32,114 root INFO 
id:ne_en cur r: 0.7498 best r: 0.7498
17:39:44,984 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:41:15,627 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
17:41:15,638 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:41:15,646 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:41:15,652 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
17:41:15,658 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
17:41:15,665 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:41:15,674 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:41:28,625 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5218
en_de Dev loss: 0.8759 r:0.2509
en_zh Dev loss: 0.7301 r:0.4661
ro_en Dev loss: 0.3601 r:0.8125
et_en Dev loss: 0.3773 r:0.7056
si_en Dev loss: 0.6605 r:0.6106
ne_en Dev loss: 0.4448 r:0.7454
ru_en Dev loss: 0.5241 r:0.7400
Current avg r:0.6187 Best avg r: 0.6187
17:46:00,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:46:13,314 root INFO 
id:en_de cur r: 0.2692 best r: 0.2692
17:46:39,212 root INFO 
id:en_zh cur r: 0.4772 best r: 0.4772
17:46:52,195 root INFO 
id:ro_en cur r: 0.8218 best r: 0.8218
17:47:05,177 root INFO 
id:et_en cur r: 0.7135 best r: 0.7135
17:47:18,159 root INFO 
id:si_en cur r: 0.6175 best r: 0.6175
17:47:44,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:14,597 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
17:49:14,613 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
17:49:14,620 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
17:49:14,628 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
17:49:14,636 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
17:49:14,643 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
17:49:14,651 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
17:49:27,573 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4977
en_de Dev loss: 0.8490 r:0.2459
en_zh Dev loss: 0.6553 r:0.4779
ro_en Dev loss: 0.2932 r:0.8213
et_en Dev loss: 0.3519 r:0.7151
si_en Dev loss: 0.5886 r:0.6208
ne_en Dev loss: 0.3720 r:0.7470
ru_en Dev loss: 0.4099 r:0.7500
Current avg r:0.6254 Best avg r: 0.6254
17:53:58,580 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:11,518 root INFO 
id:en_de cur r: 0.2749 best r: 0.2749
17:55:29,142 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:56:59,683 root INFO Epoch 1 Global steps: 16800 Train loss: 0.5149
en_de Dev loss: 0.8754 r:0.2582
en_zh Dev loss: 0.7412 r:0.4536
ro_en Dev loss: 0.3409 r:0.8056
et_en Dev loss: 0.3792 r:0.6904
si_en Dev loss: 0.6762 r:0.5949
ne_en Dev loss: 0.4639 r:0.7392
ru_en Dev loss: 0.5027 r:0.7160
Current avg r:0.6083 Best avg r: 0.6254
18:01:30,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:02:09,497 root INFO 
id:ro_en cur r: 0.8241 best r: 0.8241
18:03:01,280 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:04:31,822 root INFO Epoch 1 Global steps: 17500 Train loss: 0.5124
en_de Dev loss: 0.8721 r:0.2431
en_zh Dev loss: 0.7686 r:0.4592
ro_en Dev loss: 0.3464 r:0.8198
et_en Dev loss: 0.3760 r:0.7055
si_en Dev loss: 0.7408 r:0.6033
ne_en Dev loss: 0.4873 r:0.7414
ru_en Dev loss: 0.5269 r:0.7338
Current avg r:0.6152 Best avg r: 0.6254
18:09:02,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:33,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:12:03,792 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4972
en_de Dev loss: 0.8833 r:0.2422
en_zh Dev loss: 0.7715 r:0.4533
ro_en Dev loss: 0.3502 r:0.8183
et_en Dev loss: 0.3687 r:0.7062
si_en Dev loss: 0.7126 r:0.6030
ne_en Dev loss: 0.5610 r:0.7397
ru_en Dev loss: 0.5340 r:0.7294
Current avg r:0.6132 Best avg r: 0.6254
18:16:35,419 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:17:53,212 root INFO 
id:ne_en cur r: 0.7575 best r: 0.7575
18:18:06,84 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:19:36,735 root INFO Epoch 1 Global steps: 18900 Train loss: 0.5090
en_de Dev loss: 0.8854 r:0.2307
en_zh Dev loss: 0.7393 r:0.4555
ro_en Dev loss: 0.3266 r:0.8186
et_en Dev loss: 0.3636 r:0.7072
si_en Dev loss: 0.7253 r:0.6027
ne_en Dev loss: 0.4447 r:0.7524
ru_en Dev loss: 0.4684 r:0.7350
Current avg r:0.6146 Best avg r: 0.6254
18:24:08,365 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:13,139 root INFO 
id:si_en cur r: 0.6204 best r: 0.6204
18:25:39,9 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:27:09,556 root INFO Epoch 1 Global steps: 19600 Train loss: 0.5003
en_de Dev loss: 0.8701 r:0.2475
en_zh Dev loss: 0.7084 r:0.4567
ro_en Dev loss: 0.3284 r:0.8140
et_en Dev loss: 0.3609 r:0.7069
si_en Dev loss: 0.6808 r:0.6161
ne_en Dev loss: 0.4386 r:0.7507
ru_en Dev loss: 0.4612 r:0.7356
Current avg r:0.6182 Best avg r: 0.6254
18:31:40,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:10,961 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:34:41,501 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4787
en_de Dev loss: 0.8706 r:0.2370
en_zh Dev loss: 0.7509 r:0.4518
ro_en Dev loss: 0.3535 r:0.8144
et_en Dev loss: 0.3639 r:0.7093
si_en Dev loss: 0.6792 r:0.6117
ne_en Dev loss: 0.4228 r:0.7482
ru_en Dev loss: 0.4982 r:0.7241
Current avg r:0.6138 Best avg r: 0.6254
18:39:12,400 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:51,225 root INFO 
id:en_zh cur r: 0.4787 best r: 0.4787
18:40:55,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:42:26,492 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4904
en_de Dev loss: 0.9231 r:0.2162
en_zh Dev loss: 0.7920 r:0.4740
ro_en Dev loss: 0.3997 r:0.8193
et_en Dev loss: 0.3758 r:0.7098
si_en Dev loss: 0.8250 r:0.6104
ne_en Dev loss: 0.4449 r:0.7504
ru_en Dev loss: 0.5578 r:0.7307
Current avg r:0.6158 Best avg r: 0.6254
18:46:59,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:47:38,270 root INFO 
id:en_zh cur r: 0.4858 best r: 0.4858
18:48:04,197 root INFO 
id:et_en cur r: 0.7173 best r: 0.7173
18:48:17,174 root INFO 
id:si_en cur r: 0.6265 best r: 0.6265
18:48:42,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:50:13,565 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4755
en_de Dev loss: 0.8870 r:0.1943
en_zh Dev loss: 0.6970 r:0.4813
ro_en Dev loss: 0.3282 r:0.8187
et_en Dev loss: 0.3545 r:0.7145
si_en Dev loss: 0.6274 r:0.6243
ne_en Dev loss: 0.3915 r:0.7555
ru_en Dev loss: 0.4901 r:0.7338
Current avg r:0.6175 Best avg r: 0.6254
18:54:44,433 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:55:23,258 root INFO 
id:en_zh cur r: 0.4873 best r: 0.4873
18:56:28,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:57:58,731 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4455
en_de Dev loss: 0.8835 r:0.2087
en_zh Dev loss: 0.7176 r:0.4801
ro_en Dev loss: 0.3427 r:0.8123
et_en Dev loss: 0.3710 r:0.7063
si_en Dev loss: 0.6756 r:0.6096
ne_en Dev loss: 0.4949 r:0.7526
ru_en Dev loss: 0.5257 r:0.7110
Current avg r:0.6115 Best avg r: 0.6254
19:02:30,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:02:43,320 root INFO 
id:en_de cur r: 0.2858 best r: 0.2858
19:03:48,155 root INFO 
id:ne_en cur r: 0.7625 best r: 0.7625
19:04:01,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:05:31,578 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4511
en_de Dev loss: 0.8738 r:0.2539
en_zh Dev loss: 0.7427 r:0.4790
ro_en Dev loss: 0.3588 r:0.8133
et_en Dev loss: 0.3686 r:0.7082
si_en Dev loss: 0.8006 r:0.6098
ne_en Dev loss: 0.4980 r:0.7600
ru_en Dev loss: 0.5048 r:0.7298
Current avg r:0.6220 Best avg r: 0.6254
19:10:02,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:10:15,295 root INFO 
id:en_de cur r: 0.2893 best r: 0.2893
19:11:32,933 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:03,456 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4483
en_de Dev loss: 0.8435 r:0.2725
en_zh Dev loss: 0.7417 r:0.4743
ro_en Dev loss: 0.3538 r:0.8141
et_en Dev loss: 0.3871 r:0.6974
si_en Dev loss: 0.8039 r:0.6008
ne_en Dev loss: 0.5795 r:0.7527
ru_en Dev loss: 0.5138 r:0.7148
Current avg r:0.6181 Best avg r: 0.6254
19:17:34,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:05,110 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:20:35,702 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4516
en_de Dev loss: 0.8477 r:0.2568
en_zh Dev loss: 0.6939 r:0.4666
ro_en Dev loss: 0.3395 r:0.8147
et_en Dev loss: 0.3812 r:0.7067
si_en Dev loss: 0.6384 r:0.6206
ne_en Dev loss: 0.4210 r:0.7581
ru_en Dev loss: 0.4708 r:0.7223
Current avg r:0.6208 Best avg r: 0.6254
19:25:07,401 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:25:46,227 root INFO 
id:en_zh cur r: 0.4904 best r: 0.4904
19:26:50,924 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:21,463 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4621
en_de Dev loss: 0.8380 r:0.2588
en_zh Dev loss: 0.6749 r:0.4771
ro_en Dev loss: 0.3207 r:0.8189
et_en Dev loss: 0.3680 r:0.7040
si_en Dev loss: 0.6750 r:0.6140
ne_en Dev loss: 0.4471 r:0.7546
ru_en Dev loss: 0.4361 r:0.7350
Current avg r:0.6232 Best avg r: 0.6254
19:32:52,753 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:23,295 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:35:53,840 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4361
en_de Dev loss: 0.8339 r:0.2585
en_zh Dev loss: 0.7066 r:0.4744
ro_en Dev loss: 0.3569 r:0.8168
et_en Dev loss: 0.3893 r:0.6989
si_en Dev loss: 0.7019 r:0.6134
ne_en Dev loss: 0.5000 r:0.7402
ru_en Dev loss: 0.4843 r:0.7165
Current avg r:0.6170 Best avg r: 0.6254
19:40:24,805 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:41:03,671 root INFO 
id:ro_en cur r: 0.8278 best r: 0.8278
19:41:55,492 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:26,154 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4554
en_de Dev loss: 0.8479 r:0.2579
en_zh Dev loss: 0.7357 r:0.4705
ro_en Dev loss: 0.3222 r:0.8260
et_en Dev loss: 0.3689 r:0.7099
si_en Dev loss: 0.7310 r:0.6121
ne_en Dev loss: 0.4780 r:0.7472
ru_en Dev loss: 0.4613 r:0.7320
Current avg r:0.6222 Best avg r: 0.6254
19:47:58,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:48:10,992 root INFO 
id:en_de cur r: 0.2982 best r: 0.2982
19:49:28,690 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:50:59,338 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4167
en_de Dev loss: 0.8659 r:0.2643
en_zh Dev loss: 0.8054 r:0.4384
ro_en Dev loss: 0.3590 r:0.8209
et_en Dev loss: 0.4056 r:0.6952
si_en Dev loss: 0.6633 r:0.6149
ne_en Dev loss: 0.4359 r:0.7476
ru_en Dev loss: 0.5214 r:0.7261
Current avg r:0.6154 Best avg r: 0.6254
19:55:31,181 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:01,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:32,490 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4477
en_de Dev loss: 0.8445 r:0.2589
en_zh Dev loss: 0.7229 r:0.4539
ro_en Dev loss: 0.3177 r:0.8224
et_en Dev loss: 0.3904 r:0.7004
si_en Dev loss: 0.6434 r:0.6147
ne_en Dev loss: 0.4155 r:0.7514
ru_en Dev loss: 0.4274 r:0.7437
Current avg r:0.6208 Best avg r: 0.6254
20:03:04,372 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:35,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:05,681 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
20:06:05,692 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:06:05,698 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:06:05,704 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
20:06:05,712 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
20:06:05,718 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
20:06:05,724 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
20:06:18,664 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4496
en_de Dev loss: 0.8475 r:0.2867
en_zh Dev loss: 0.7230 r:0.4587
ro_en Dev loss: 0.3286 r:0.8226
et_en Dev loss: 0.3794 r:0.7036
si_en Dev loss: 0.6853 r:0.6092
ne_en Dev loss: 0.4135 r:0.7559
ru_en Dev loss: 0.4592 r:0.7421
Current avg r:0.6255 Best avg r: 0.6255
20:10:49,665 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:12:20,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:50,874 root INFO Epoch 2 Global steps: 29400 Train loss: 0.4440
en_de Dev loss: 0.8519 r:0.2839
en_zh Dev loss: 0.7673 r:0.4466
ro_en Dev loss: 0.3371 r:0.8238
et_en Dev loss: 0.3828 r:0.7056
si_en Dev loss: 0.6402 r:0.6143
ne_en Dev loss: 0.4534 r:0.7510
ru_en Dev loss: 0.4345 r:0.7454
Current avg r:0.6244 Best avg r: 0.6255
20:18:22,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:53,266 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:23,784 root INFO Epoch 2 Global steps: 30100 Train loss: 0.4600
en_de Dev loss: 0.8388 r:0.2892
en_zh Dev loss: 0.7701 r:0.4523
ro_en Dev loss: 0.3739 r:0.8228
et_en Dev loss: 0.4101 r:0.6984
si_en Dev loss: 0.7465 r:0.6093
ne_en Dev loss: 0.4824 r:0.7489
ru_en Dev loss: 0.4624 r:0.7470
Current avg r:0.6240 Best avg r: 0.6255
20:25:54,715 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:25,241 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:28:55,801 root INFO Epoch 2 Global steps: 30800 Train loss: 0.4670
en_de Dev loss: 0.8407 r:0.2821
en_zh Dev loss: 0.7313 r:0.4627
ro_en Dev loss: 0.3281 r:0.8233
et_en Dev loss: 0.3805 r:0.7015
si_en Dev loss: 0.6557 r:0.6169
ne_en Dev loss: 0.4753 r:0.7510
ru_en Dev loss: 0.4773 r:0.7328
Current avg r:0.6243 Best avg r: 0.6255
20:33:26,604 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:05,384 root INFO 
id:ro_en cur r: 0.8290 best r: 0.8290
20:34:57,129 root INFO 
id:ru_en cur r: 0.7549 best r: 0.7549
20:34:57,130 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:27,745 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_de.lang_agnost_mlp.dev.best.scores
20:36:27,755 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/en_zh.lang_agnost_mlp.dev.best.scores
20:36:27,763 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ro_en.lang_agnost_mlp.dev.best.scores
20:36:27,768 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/et_en.lang_agnost_mlp.dev.best.scores
20:36:27,776 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/si_en.lang_agnost_mlp.dev.best.scores
20:36:27,782 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ne_en.lang_agnost_mlp.dev.best.scores
20:36:27,788 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_enzh/run2/ru_en.lang_agnost_mlp.dev.best.scores
20:36:40,726 root INFO Epoch 2 Global steps: 31500 Train loss: 0.4352
en_de Dev loss: 0.8369 r:0.2676
en_zh Dev loss: 0.7176 r:0.4636
ro_en Dev loss: 0.2958 r:0.8291
et_en Dev loss: 0.3629 r:0.7090
si_en Dev loss: 0.5822 r:0.6262
ne_en Dev loss: 0.4010 r:0.7581
ru_en Dev loss: 0.4003 r:0.7545
Current avg r:0.6297 Best avg r: 0.6297
20:41:13,648 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:44,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:14,766 root INFO Epoch 3 Global steps: 32200 Train loss: 0.4107
en_de Dev loss: 0.8458 r:0.2581
en_zh Dev loss: 0.7405 r:0.4617
ro_en Dev loss: 0.3357 r:0.8202
et_en Dev loss: 0.3940 r:0.6913
si_en Dev loss: 0.6782 r:0.6039
ne_en Dev loss: 0.5215 r:0.7418
ru_en Dev loss: 0.4663 r:0.7131
Current avg r:0.6129 Best avg r: 0.6297
20:48:45,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:15,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:46,435 root INFO Epoch 3 Global steps: 32900 Train loss: 0.4241
en_de Dev loss: 0.8953 r:0.2442
en_zh Dev loss: 0.8708 r:0.4457
ro_en Dev loss: 0.4053 r:0.8079
et_en Dev loss: 0.4332 r:0.6714
si_en Dev loss: 0.9342 r:0.5747
ne_en Dev loss: 0.6642 r:0.7377
ru_en Dev loss: 0.5471 r:0.7013
Current avg r:0.5975 Best avg r: 0.6297
20:56:17,81 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:47,586 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:18,106 root INFO Epoch 3 Global steps: 33600 Train loss: 0.4023
en_de Dev loss: 0.8398 r:0.2734
en_zh Dev loss: 0.7816 r:0.4654
ro_en Dev loss: 0.3632 r:0.8249
et_en Dev loss: 0.4147 r:0.6990
si_en Dev loss: 0.8388 r:0.6038
ne_en Dev loss: 0.5050 r:0.7526
ru_en Dev loss: 0.5179 r:0.7291
Current avg r:0.6212 Best avg r: 0.6297
21:03:48,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:19,359 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:49,910 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3918
en_de Dev loss: 0.8589 r:0.2788
en_zh Dev loss: 0.7755 r:0.4634
ro_en Dev loss: 0.3629 r:0.8219
et_en Dev loss: 0.4390 r:0.6887
si_en Dev loss: 0.7596 r:0.5993
ne_en Dev loss: 0.4729 r:0.7459
ru_en Dev loss: 0.5260 r:0.7194
Current avg r:0.6168 Best avg r: 0.6297
21:11:20,531 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:51,40 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:21,543 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3914
en_de Dev loss: 0.8438 r:0.2561
en_zh Dev loss: 0.7178 r:0.4618
ro_en Dev loss: 0.3253 r:0.8254
et_en Dev loss: 0.3907 r:0.6969
si_en Dev loss: 0.7226 r:0.6061
ne_en Dev loss: 0.4985 r:0.7480
ru_en Dev loss: 0.4916 r:0.7250
Current avg r:0.6170 Best avg r: 0.6297
21:18:52,305 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:22,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:53,309 root INFO Epoch 3 Global steps: 35700 Train loss: 0.4040
en_de Dev loss: 0.8510 r:0.2563
en_zh Dev loss: 0.7254 r:0.4686
ro_en Dev loss: 0.3487 r:0.8215
et_en Dev loss: 0.4105 r:0.6927
si_en Dev loss: 0.8049 r:0.6021
ne_en Dev loss: 0.5323 r:0.7558
ru_en Dev loss: 0.4775 r:0.7274
Current avg r:0.6178 Best avg r: 0.6297
21:26:24,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:54,622 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:25,131 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3746
en_de Dev loss: 0.8599 r:0.2461
en_zh Dev loss: 0.6980 r:0.4737
ro_en Dev loss: 0.3017 r:0.8276
et_en Dev loss: 0.3922 r:0.6993
si_en Dev loss: 0.6222 r:0.6179
ne_en Dev loss: 0.3749 r:0.7593
ru_en Dev loss: 0.4172 r:0.7486
Current avg r:0.6246 Best avg r: 0.6297
21:33:55,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:26,503 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:57,37 root INFO Epoch 3 Global steps: 37100 Train loss: 0.4073
en_de Dev loss: 0.8722 r:0.2178
en_zh Dev loss: 0.7679 r:0.4656
ro_en Dev loss: 0.3478 r:0.8245
et_en Dev loss: 0.4083 r:0.6889
si_en Dev loss: 0.7357 r:0.6030
ne_en Dev loss: 0.4860 r:0.7535
ru_en Dev loss: 0.4872 r:0.7249
Current avg r:0.6112 Best avg r: 0.6297
21:41:27,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:58,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:28,881 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3852
en_de Dev loss: 0.8929 r:0.2194
en_zh Dev loss: 0.8066 r:0.4560
ro_en Dev loss: 0.3535 r:0.8239
et_en Dev loss: 0.3887 r:0.6981
si_en Dev loss: 0.7815 r:0.6002
ne_en Dev loss: 0.4467 r:0.7482
ru_en Dev loss: 0.4767 r:0.7374
Current avg r:0.6119 Best avg r: 0.6297
21:49:00,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:31,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:52:01,795 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3941
en_de Dev loss: 0.8669 r:0.2168
en_zh Dev loss: 0.7739 r:0.4467
ro_en Dev loss: 0.3534 r:0.8200
et_en Dev loss: 0.4252 r:0.6945
si_en Dev loss: 0.7389 r:0.5969
ne_en Dev loss: 0.4871 r:0.7454
ru_en Dev loss: 0.4373 r:0.7421
Current avg r:0.6089 Best avg r: 0.6297
21:56:33,388 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:58:04,14 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:34,551 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3923
en_de Dev loss: 0.8640 r:0.2284
en_zh Dev loss: 0.7795 r:0.4540
ro_en Dev loss: 0.3746 r:0.8205
et_en Dev loss: 0.4362 r:0.6843
si_en Dev loss: 0.8128 r:0.5988
ne_en Dev loss: 0.5782 r:0.7509
ru_en Dev loss: 0.4923 r:0.7274
Current avg r:0.6092 Best avg r: 0.6297
22:04:06,82 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:36,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:07:07,177 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3773
en_de Dev loss: 0.8718 r:0.2236
en_zh Dev loss: 0.7551 r:0.4534
ro_en Dev loss: 0.3646 r:0.8223
et_en Dev loss: 0.3986 r:0.6955
si_en Dev loss: 0.7901 r:0.5974
ne_en Dev loss: 0.5244 r:0.7487
ru_en Dev loss: 0.4941 r:0.7305
Current avg r:0.6102 Best avg r: 0.6297
22:11:37,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:13:08,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:38,987 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3831
en_de Dev loss: 0.8580 r:0.2224
en_zh Dev loss: 0.7053 r:0.4654
ro_en Dev loss: 0.3130 r:0.8260
et_en Dev loss: 0.3950 r:0.6916
si_en Dev loss: 0.6408 r:0.6097
ne_en Dev loss: 0.3886 r:0.7562
ru_en Dev loss: 0.4725 r:0.7182
Current avg r:0.6128 Best avg r: 0.6297
22:19:09,864 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:40,407 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:22:10,896 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3718
en_de Dev loss: 0.8515 r:0.2441
en_zh Dev loss: 0.7324 r:0.4631
ro_en Dev loss: 0.3378 r:0.8299
et_en Dev loss: 0.3670 r:0.7081
si_en Dev loss: 0.7457 r:0.6136
ne_en Dev loss: 0.4222 r:0.7474
ru_en Dev loss: 0.4649 r:0.7409
Current avg r:0.6210 Best avg r: 0.6297
22:26:41,669 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:28:12,166 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:42,651 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3964
en_de Dev loss: 0.8359 r:0.2497
en_zh Dev loss: 0.7554 r:0.4410
ro_en Dev loss: 0.3293 r:0.8244
et_en Dev loss: 0.4156 r:0.6892
si_en Dev loss: 0.7083 r:0.5944
ne_en Dev loss: 0.4522 r:0.7402
ru_en Dev loss: 0.4720 r:0.7152
Current avg r:0.6077 Best avg r: 0.6297
22:34:14,907 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:45,249 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:37:15,649 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3424
en_de Dev loss: 0.8407 r:0.2459
en_zh Dev loss: 0.7531 r:0.4551
ro_en Dev loss: 0.3425 r:0.8277
et_en Dev loss: 0.4292 r:0.6913
si_en Dev loss: 0.7007 r:0.6053
ne_en Dev loss: 0.4213 r:0.7442
ru_en Dev loss: 0.4481 r:0.7334
Current avg r:0.6147 Best avg r: 0.6297
22:41:46,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:43:17,360 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:47,804 root INFO Epoch 4 Global steps: 43400 Train loss: 0.3524
en_de Dev loss: 0.8526 r:0.2560
en_zh Dev loss: 0.8378 r:0.4426
ro_en Dev loss: 0.3676 r:0.8230
et_en Dev loss: 0.4238 r:0.6801
si_en Dev loss: 0.7981 r:0.5975
ne_en Dev loss: 0.5464 r:0.7480
ru_en Dev loss: 0.5216 r:0.7182
Current avg r:0.6094 Best avg r: 0.6297
22:49:19,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:49,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:52:20,353 root INFO Epoch 4 Global steps: 44100 Train loss: 0.3476
en_de Dev loss: 0.8467 r:0.2367
en_zh Dev loss: 0.7842 r:0.4471
ro_en Dev loss: 0.3503 r:0.8220
et_en Dev loss: 0.4197 r:0.6801
si_en Dev loss: 0.8494 r:0.5920
ne_en Dev loss: 0.6149 r:0.7398
ru_en Dev loss: 0.4621 r:0.7282
Current avg r:0.6066 Best avg r: 0.6297
22:56:51,537 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:58:21,867 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:52,246 root INFO Epoch 4 Global steps: 44800 Train loss: 0.3425
en_de Dev loss: 0.8593 r:0.2206
en_zh Dev loss: 0.8006 r:0.4410
ro_en Dev loss: 0.3458 r:0.8212
et_en Dev loss: 0.4188 r:0.6807
si_en Dev loss: 0.8150 r:0.5896
ne_en Dev loss: 0.6394 r:0.7348
ru_en Dev loss: 0.4922 r:0.7070
Current avg r:0.5993 Best avg r: 0.6297
23:04:23,20 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:53,484 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:07:23,863 root INFO Epoch 4 Global steps: 45500 Train loss: 0.3392
en_de Dev loss: 0.8787 r:0.2224
en_zh Dev loss: 0.8049 r:0.4505
ro_en Dev loss: 0.3751 r:0.8198
et_en Dev loss: 0.4407 r:0.6831
si_en Dev loss: 0.9006 r:0.5809
ne_en Dev loss: 0.5563 r:0.7430
ru_en Dev loss: 0.5185 r:0.7108
Current avg r:0.6015 Best avg r: 0.6297
23:11:54,879 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:13:25,211 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:55,573 root INFO Epoch 4 Global steps: 46200 Train loss: 0.3515
en_de Dev loss: 0.8616 r:0.2276
en_zh Dev loss: 0.7883 r:0.4484
ro_en Dev loss: 0.3595 r:0.8220
et_en Dev loss: 0.4099 r:0.6852
si_en Dev loss: 0.8533 r:0.5861
ne_en Dev loss: 0.5868 r:0.7448
ru_en Dev loss: 0.5294 r:0.7054
Current avg r:0.6028 Best avg r: 0.6297
23:19:26,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:56,597 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:22:26,902 root INFO Epoch 4 Global steps: 46900 Train loss: 0.3422
en_de Dev loss: 0.8808 r:0.2306
en_zh Dev loss: 0.7614 r:0.4716
ro_en Dev loss: 0.3516 r:0.8280
et_en Dev loss: 0.4354 r:0.6969
si_en Dev loss: 0.7716 r:0.6027
ne_en Dev loss: 0.5649 r:0.7439
ru_en Dev loss: 0.4929 r:0.7230
Current avg r:0.6138 Best avg r: 0.6297
23:26:58,181 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:28:28,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:59,1 root INFO Epoch 4 Global steps: 47600 Train loss: 0.3512
en_de Dev loss: 0.8678 r:0.2327
en_zh Dev loss: 0.7789 r:0.4532
ro_en Dev loss: 0.3348 r:0.8262
et_en Dev loss: 0.4180 r:0.6988
si_en Dev loss: 0.7770 r:0.5947
ne_en Dev loss: 0.4780 r:0.7435
ru_en Dev loss: 0.4600 r:0.7254
Current avg r:0.6107 Best avg r: 0.6297
23:34:29,764 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:36:00,61 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:30,443 root INFO Epoch 4 Global steps: 48300 Train loss: 0.3404
en_de Dev loss: 0.8613 r:0.2263
en_zh Dev loss: 0.8108 r:0.4431
ro_en Dev loss: 0.3699 r:0.8226
et_en Dev loss: 0.4087 r:0.6948
si_en Dev loss: 0.8090 r:0.5941
ne_en Dev loss: 0.5332 r:0.7418
ru_en Dev loss: 0.4867 r:0.7252
Current avg r:0.6068 Best avg r: 0.6297
23:42:01,407 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:31,781 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:45:02,199 root INFO Epoch 4 Global steps: 49000 Train loss: 0.3364
en_de Dev loss: 0.8566 r:0.2255
en_zh Dev loss: 0.8125 r:0.4520
ro_en Dev loss: 0.3409 r:0.8243
et_en Dev loss: 0.4003 r:0.6936
si_en Dev loss: 0.7843 r:0.5970
ne_en Dev loss: 0.4368 r:0.7506
ru_en Dev loss: 0.4777 r:0.7253
Current avg r:0.6098 Best avg r: 0.6297
23:49:33,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:51:04,489 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:34,984 root INFO Epoch 4 Global steps: 49700 Train loss: 0.3182
en_de Dev loss: 0.8719 r:0.2074
en_zh Dev loss: 0.8075 r:0.4592
ro_en Dev loss: 0.3792 r:0.8180
et_en Dev loss: 0.4448 r:0.6841
si_en Dev loss: 0.8338 r:0.5876
ne_en Dev loss: 0.5139 r:0.7451
ru_en Dev loss: 0.4831 r:0.7228
Current avg r:0.6035 Best avg r: 0.6297
23:57:06,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:58:37,406 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:00:07,761 root INFO Epoch 4 Global steps: 50400 Train loss: 0.3404
en_de Dev loss: 0.8730 r:0.2369
en_zh Dev loss: 0.8048 r:0.4514
ro_en Dev loss: 0.3542 r:0.8211
et_en Dev loss: 0.4295 r:0.6954
si_en Dev loss: 0.6962 r:0.5961
ne_en Dev loss: 0.4274 r:0.7478
ru_en Dev loss: 0.4959 r:0.7187
Current avg r:0.6096 Best avg r: 0.6297
00:04:38,690 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:06:09,124 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:39,590 root INFO Epoch 4 Global steps: 51100 Train loss: 0.3251
en_de Dev loss: 0.8586 r:0.2458
en_zh Dev loss: 0.8206 r:0.4490
ro_en Dev loss: 0.3679 r:0.8246
et_en Dev loss: 0.4329 r:0.6895
si_en Dev loss: 0.8655 r:0.5850
ne_en Dev loss: 0.5919 r:0.7462
ru_en Dev loss: 0.4808 r:0.7243
Current avg r:0.6092 Best avg r: 0.6297
00:12:11,243 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:41,704 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:15:12,52 root INFO Epoch 4 Global steps: 51800 Train loss: 0.3342
en_de Dev loss: 0.8352 r:0.2455
en_zh Dev loss: 0.7041 r:0.4706
ro_en Dev loss: 0.3011 r:0.8282
et_en Dev loss: 0.4032 r:0.6940
si_en Dev loss: 0.7192 r:0.5909
ne_en Dev loss: 0.4649 r:0.7413
ru_en Dev loss: 0.4096 r:0.7318
Current avg r:0.6146 Best avg r: 0.6297
00:19:42,888 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:21:13,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:43,547 root INFO Epoch 4 Global steps: 52500 Train loss: 0.3297
en_de Dev loss: 0.8436 r:0.2509
en_zh Dev loss: 0.7690 r:0.4720
ro_en Dev loss: 0.3653 r:0.8262
et_en Dev loss: 0.4482 r:0.6927
si_en Dev loss: 0.7593 r:0.5945
ne_en Dev loss: 0.5445 r:0.7348
ru_en Dev loss: 0.4651 r:0.7294
Current avg r:0.6144 Best avg r: 0.6297
00:27:16,828 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:47,236 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:30:17,604 root INFO Epoch 5 Global steps: 53200 Train loss: 0.3117
en_de Dev loss: 0.8744 r:0.2435
en_zh Dev loss: 0.8064 r:0.4437
ro_en Dev loss: 0.3857 r:0.8163
et_en Dev loss: 0.4412 r:0.6833
si_en Dev loss: 0.8667 r:0.5761
ne_en Dev loss: 0.5883 r:0.7250
ru_en Dev loss: 0.5182 r:0.7020
Current avg r:0.5986 Best avg r: 0.6297
00:34:48,535 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:36:18,838 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:49,152 root INFO Epoch 5 Global steps: 53900 Train loss: 0.3021
en_de Dev loss: 0.8565 r:0.2393
en_zh Dev loss: 0.7555 r:0.4562
ro_en Dev loss: 0.3662 r:0.8199
et_en Dev loss: 0.4332 r:0.6893
si_en Dev loss: 0.7952 r:0.5802
ne_en Dev loss: 0.5059 r:0.7361
ru_en Dev loss: 0.4876 r:0.7106
Current avg r:0.6045 Best avg r: 0.6297
00:42:20,460 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:50,870 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:45:21,319 root INFO Epoch 5 Global steps: 54600 Train loss: 0.3075
en_de Dev loss: 0.8474 r:0.2495
en_zh Dev loss: 0.7572 r:0.4494
ro_en Dev loss: 0.3167 r:0.8220
et_en Dev loss: 0.4340 r:0.6888
si_en Dev loss: 0.7359 r:0.5830
ne_en Dev loss: 0.5146 r:0.7346
ru_en Dev loss: 0.4403 r:0.7252
Current avg r:0.6075 Best avg r: 0.6297
00:49:52,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:51:23,282 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:53,739 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2846
en_de Dev loss: 0.8847 r:0.2397
en_zh Dev loss: 0.8029 r:0.4470
ro_en Dev loss: 0.3831 r:0.8180
et_en Dev loss: 0.4509 r:0.6771
si_en Dev loss: 0.9113 r:0.5631
ne_en Dev loss: 0.5420 r:0.7315
ru_en Dev loss: 0.5318 r:0.7100
Current avg r:0.5981 Best avg r: 0.6297
00:57:25,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:55,851 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:00:26,272 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2938
en_de Dev loss: 0.8395 r:0.2424
en_zh Dev loss: 0.7450 r:0.4527
ro_en Dev loss: 0.3154 r:0.8243
et_en Dev loss: 0.4278 r:0.6964
si_en Dev loss: 0.7538 r:0.5828
ne_en Dev loss: 0.4809 r:0.7329
ru_en Dev loss: 0.4162 r:0.7335
Current avg r:0.6093 Best avg r: 0.6297
01:04:58,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:06:28,456 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:58,899 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2777
en_de Dev loss: 0.8553 r:0.2518
en_zh Dev loss: 0.7829 r:0.4533
ro_en Dev loss: 0.3556 r:0.8245
et_en Dev loss: 0.4237 r:0.6856
si_en Dev loss: 0.8635 r:0.5801
ne_en Dev loss: 0.5398 r:0.7326
ru_en Dev loss: 0.4838 r:0.7272
Current avg r:0.6079 Best avg r: 0.6297
01:12:30,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:14:00,675 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:15:31,109 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2841
en_de Dev loss: 0.8483 r:0.2468
en_zh Dev loss: 0.7584 r:0.4569
ro_en Dev loss: 0.3295 r:0.8222
et_en Dev loss: 0.4490 r:0.6906
si_en Dev loss: 0.7342 r:0.5827
ne_en Dev loss: 0.4622 r:0.7330
ru_en Dev loss: 0.4197 r:0.7374
Current avg r:0.6099 Best avg r: 0.6297
01:20:02,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:21:33,196 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:23:03,533 root INFO Epoch 5 Global steps: 58100 Train loss: 0.3076
en_de Dev loss: 0.8461 r:0.2381
en_zh Dev loss: 0.8100 r:0.4344
ro_en Dev loss: 0.3660 r:0.8156
et_en Dev loss: 0.4431 r:0.6664
si_en Dev loss: 0.9655 r:0.5518
ne_en Dev loss: 0.6184 r:0.7275
ru_en Dev loss: 0.5026 r:0.7062
Current avg r:0.5914 Best avg r: 0.6297
01:27:34,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:29:04,691 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:30:35,15 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2915
en_de Dev loss: 0.8495 r:0.2509
en_zh Dev loss: 0.7745 r:0.4715
ro_en Dev loss: 0.3576 r:0.8200
et_en Dev loss: 0.4658 r:0.6838
si_en Dev loss: 0.7846 r:0.5829
ne_en Dev loss: 0.5552 r:0.7286
ru_en Dev loss: 0.4638 r:0.7372
Current avg r:0.6107 Best avg r: 0.6297
01:35:05,812 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:36:36,113 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:38:06,446 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2895
en_de Dev loss: 0.8524 r:0.2292
en_zh Dev loss: 0.7792 r:0.4586
ro_en Dev loss: 0.3543 r:0.8223
et_en Dev loss: 0.4166 r:0.6831
si_en Dev loss: 0.8454 r:0.5707
ne_en Dev loss: 0.5925 r:0.7280
ru_en Dev loss: 0.4583 r:0.7349
Current avg r:0.6038 Best avg r: 0.6297
01:42:37,221 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:44:07,514 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:45:37,839 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2949
en_de Dev loss: 0.8598 r:0.2254
en_zh Dev loss: 0.7770 r:0.4617
ro_en Dev loss: 0.3354 r:0.8229
et_en Dev loss: 0.4140 r:0.6853
si_en Dev loss: 0.7948 r:0.5738
ne_en Dev loss: 0.5060 r:0.7254
ru_en Dev loss: 0.4577 r:0.7316
Current avg r:0.6037 Best avg r: 0.6297
01:50:08,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:51:39,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:53:09,429 root INFO Epoch 5 Global steps: 60900 Train loss: 0.3055
en_de Dev loss: 0.8740 r:0.2197
en_zh Dev loss: 0.7648 r:0.4662
ro_en Dev loss: 0.3612 r:0.8167
et_en Dev loss: 0.4466 r:0.6790
si_en Dev loss: 0.8696 r:0.5612
ne_en Dev loss: 0.4998 r:0.7252
ru_en Dev loss: 0.5188 r:0.7069
Current avg r:0.5964 Best avg r: 0.6297
01:57:40,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:59:10,773 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:00:41,106 root INFO Epoch 5 Global steps: 61600 Train loss: 0.3003
en_de Dev loss: 0.8649 r:0.2209
en_zh Dev loss: 0.7859 r:0.4653
ro_en Dev loss: 0.3875 r:0.8210
et_en Dev loss: 0.4376 r:0.6842
si_en Dev loss: 0.9530 r:0.5620
ne_en Dev loss: 0.5208 r:0.7332
ru_en Dev loss: 0.5464 r:0.7195
Current avg r:0.6009 Best avg r: 0.6297
02:05:11,928 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:06:42,288 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:08:12,674 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2923
en_de Dev loss: 0.8342 r:0.2522
en_zh Dev loss: 0.7382 r:0.4606
ro_en Dev loss: 0.3346 r:0.8189
et_en Dev loss: 0.4424 r:0.6863
si_en Dev loss: 0.8063 r:0.5642
ne_en Dev loss: 0.5016 r:0.7264
ru_en Dev loss: 0.4660 r:0.7183
Current avg r:0.6039 Best avg r: 0.6297
02:12:43,463 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:14:13,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:15:44,170 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2944
en_de Dev loss: 0.8502 r:0.2427
en_zh Dev loss: 0.7641 r:0.4627
ro_en Dev loss: 0.3723 r:0.8172
et_en Dev loss: 0.4337 r:0.6765
si_en Dev loss: 0.8529 r:0.5676
ne_en Dev loss: 0.5448 r:0.7314
ru_en Dev loss: 0.4775 r:0.7253
Current avg r:0.6033 Best avg r: 0.6297
02:20:16,520 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:21:46,987 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:23:17,357 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2794
en_de Dev loss: 0.8518 r:0.2215
en_zh Dev loss: 0.7588 r:0.4495
ro_en Dev loss: 0.3381 r:0.8144
et_en Dev loss: 0.4627 r:0.6790
si_en Dev loss: 0.7432 r:0.5764
ne_en Dev loss: 0.4632 r:0.7253
ru_en Dev loss: 0.4640 r:0.7121
Current avg r:0.5969 Best avg r: 0.6297
02:27:48,102 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:29:18,416 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:30:48,862 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2664
en_de Dev loss: 0.8944 r:0.2346
en_zh Dev loss: 0.8380 r:0.4501
ro_en Dev loss: 0.4296 r:0.8152
et_en Dev loss: 0.4731 r:0.6682
si_en Dev loss: 0.9881 r:0.5533
ne_en Dev loss: 0.6690 r:0.7234
ru_en Dev loss: 0.5404 r:0.7216
Current avg r:0.5952 Best avg r: 0.6297
02:35:19,904 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:36:50,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:38:20,544 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2507
en_de Dev loss: 0.8572 r:0.2544
en_zh Dev loss: 0.7735 r:0.4616
ro_en Dev loss: 0.3387 r:0.8228
et_en Dev loss: 0.4255 r:0.6811
si_en Dev loss: 0.7895 r:0.5779
ne_en Dev loss: 0.5041 r:0.7274
ru_en Dev loss: 0.4663 r:0.7365
Current avg r:0.6088 Best avg r: 0.6297
02:42:52,50 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:44:22,467 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:45:52,866 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2710
en_de Dev loss: 0.8454 r:0.2643
en_zh Dev loss: 0.7392 r:0.4562
ro_en Dev loss: 0.3213 r:0.8203
et_en Dev loss: 0.4519 r:0.6749
si_en Dev loss: 0.7712 r:0.5763
ne_en Dev loss: 0.5023 r:0.7250
ru_en Dev loss: 0.4200 r:0.7343
Current avg r:0.6073 Best avg r: 0.6297
02:50:24,276 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:51:54,594 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:53:24,959 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2678
en_de Dev loss: 0.8713 r:0.2418
en_zh Dev loss: 0.7887 r:0.4515
ro_en Dev loss: 0.3511 r:0.8211
et_en Dev loss: 0.4554 r:0.6765
si_en Dev loss: 0.8604 r:0.5691
ne_en Dev loss: 0.5121 r:0.7295
ru_en Dev loss: 0.4975 r:0.7185
Current avg r:0.6012 Best avg r: 0.6297
02:57:55,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:59:26,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:56,614 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2671
en_de Dev loss: 0.8838 r:0.2446
en_zh Dev loss: 0.8206 r:0.4489
ro_en Dev loss: 0.3762 r:0.8237
et_en Dev loss: 0.4719 r:0.6702
si_en Dev loss: 0.9285 r:0.5586
ne_en Dev loss: 0.5246 r:0.7264
ru_en Dev loss: 0.5180 r:0.7253
Current avg r:0.5997 Best avg r: 0.6297
03:05:27,468 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:06:57,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:08:28,71 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2403
en_de Dev loss: 0.8764 r:0.2179
en_zh Dev loss: 0.7797 r:0.4574
ro_en Dev loss: 0.3467 r:0.8231
et_en Dev loss: 0.4669 r:0.6722
si_en Dev loss: 0.8939 r:0.5622
ne_en Dev loss: 0.5399 r:0.7297
ru_en Dev loss: 0.4486 r:0.7342
Current avg r:0.5995 Best avg r: 0.6297
03:12:59,538 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:14:29,980 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:16:00,414 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2573
en_de Dev loss: 0.8711 r:0.2114
en_zh Dev loss: 0.8119 r:0.4536
ro_en Dev loss: 0.3863 r:0.8209
et_en Dev loss: 0.4535 r:0.6771
si_en Dev loss: 0.9113 r:0.5615
ne_en Dev loss: 0.5769 r:0.7327
ru_en Dev loss: 0.4910 r:0.7179
Current avg r:0.5964 Best avg r: 0.6297
03:20:32,118 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:22:02,470 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:23:32,802 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2516
en_de Dev loss: 0.8915 r:0.2127
en_zh Dev loss: 0.7935 r:0.4699
ro_en Dev loss: 0.3520 r:0.8201
et_en Dev loss: 0.4459 r:0.6750
si_en Dev loss: 0.8271 r:0.5704
ne_en Dev loss: 0.5289 r:0.7330
ru_en Dev loss: 0.4614 r:0.7322
Current avg r:0.6019 Best avg r: 0.6297
03:28:04,351 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:29:34,646 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:31:05,9 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2539
en_de Dev loss: 0.8729 r:0.2279
en_zh Dev loss: 0.8517 r:0.4472
ro_en Dev loss: 0.3896 r:0.8179
et_en Dev loss: 0.4926 r:0.6669
si_en Dev loss: 0.9109 r:0.5583
ne_en Dev loss: 0.5505 r:0.7324
ru_en Dev loss: 0.4884 r:0.7260
Current avg r:0.5967 Best avg r: 0.6297
03:35:36,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:37:06,848 root INFO 
id:ru_en cur r: 0.7559 best r: 0.7559
03:37:06,849 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:38:37,286 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2447
en_de Dev loss: 0.8905 r:0.2084
en_zh Dev loss: 0.7939 r:0.4575
ro_en Dev loss: 0.3329 r:0.8240
et_en Dev loss: 0.4568 r:0.6879
si_en Dev loss: 0.7599 r:0.5746
ne_en Dev loss: 0.4566 r:0.7349
ru_en Dev loss: 0.4182 r:0.7513
Current avg r:0.6055 Best avg r: 0.6297
03:43:08,691 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:44:39,125 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:46:09,664 root INFO Epoch 6 Global steps: 71400 Train loss: 0.2767
en_de Dev loss: 0.8610 r:0.2365
en_zh Dev loss: 0.7902 r:0.4546
ro_en Dev loss: 0.3641 r:0.8180
et_en Dev loss: 0.4592 r:0.6829
si_en Dev loss: 0.7581 r:0.5802
ne_en Dev loss: 0.5577 r:0.7285
ru_en Dev loss: 0.4701 r:0.7296
Current avg r:0.6043 Best avg r: 0.6297
03:50:41,337 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:52:11,731 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:53:42,135 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2463
en_de Dev loss: 0.9157 r:0.2243
en_zh Dev loss: 0.8722 r:0.4463
ro_en Dev loss: 0.4294 r:0.8182
et_en Dev loss: 0.4734 r:0.6694
si_en Dev loss: 0.9097 r:0.5620
ne_en Dev loss: 0.6118 r:0.7328
ru_en Dev loss: 0.5567 r:0.7185
Current avg r:0.5959 Best avg r: 0.6297
03:58:13,523 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:59:43,909 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:01:14,221 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2407
en_de Dev loss: 0.8851 r:0.2310
en_zh Dev loss: 0.8275 r:0.4486
ro_en Dev loss: 0.3921 r:0.8174
et_en Dev loss: 0.4604 r:0.6761
si_en Dev loss: 0.8966 r:0.5673
ne_en Dev loss: 0.5784 r:0.7285
ru_en Dev loss: 0.5136 r:0.7259
Current avg r:0.5992 Best avg r: 0.6297
04:05:44,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:07:15,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:08:45,435 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2392
en_de Dev loss: 0.8797 r:0.2094
en_zh Dev loss: 0.7848 r:0.4517
ro_en Dev loss: 0.3657 r:0.8197
et_en Dev loss: 0.4619 r:0.6776
si_en Dev loss: 0.7952 r:0.5783
ne_en Dev loss: 0.4901 r:0.7238
ru_en Dev loss: 0.4489 r:0.7474
Current avg r:0.6011 Best avg r: 0.6297
04:13:18,581 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:14:48,874 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:16:19,186 root INFO Epoch 7 Global steps: 74200 Train loss: 0.2212
en_de Dev loss: 0.8832 r:0.2060
en_zh Dev loss: 0.7954 r:0.4452
ro_en Dev loss: 0.3554 r:0.8175
et_en Dev loss: 0.4884 r:0.6643
si_en Dev loss: 0.8013 r:0.5632
ne_en Dev loss: 0.5080 r:0.7256
ru_en Dev loss: 0.4531 r:0.7283
Current avg r:0.5929 Best avg r: 0.6297
04:20:49,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:22:20,96 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:23:50,391 root INFO Epoch 7 Global steps: 74900 Train loss: 0.2144
en_de Dev loss: 0.9098 r:0.1992
en_zh Dev loss: 0.8533 r:0.4467
ro_en Dev loss: 0.3670 r:0.8213
et_en Dev loss: 0.4789 r:0.6692
si_en Dev loss: 0.8716 r:0.5659
ne_en Dev loss: 0.5670 r:0.7248
ru_en Dev loss: 0.4681 r:0.7420
Current avg r:0.5956 Best avg r: 0.6297
04:28:20,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:29:51,218 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:31:21,540 root INFO Epoch 7 Global steps: 75600 Train loss: 0.2233
en_de Dev loss: 0.9004 r:0.2101
en_zh Dev loss: 0.7962 r:0.4527
ro_en Dev loss: 0.3749 r:0.8218
et_en Dev loss: 0.5005 r:0.6711
si_en Dev loss: 0.8854 r:0.5663
ne_en Dev loss: 0.5341 r:0.7313
ru_en Dev loss: 0.4542 r:0.7416
Current avg r:0.5993 Best avg r: 0.6297
04:35:52,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:37:22,566 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:38:52,989 root INFO Epoch 7 Global steps: 76300 Train loss: 0.2266
en_de Dev loss: 0.8897 r:0.2208
en_zh Dev loss: 0.8362 r:0.4436
ro_en Dev loss: 0.3620 r:0.8197
et_en Dev loss: 0.4604 r:0.6694
si_en Dev loss: 0.8983 r:0.5576
ne_en Dev loss: 0.5897 r:0.7326
ru_en Dev loss: 0.5003 r:0.7207
Current avg r:0.5949 Best avg r: 0.6297
04:43:24,415 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:44:54,789 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:46:25,199 root INFO Epoch 7 Global steps: 77000 Train loss: 0.2290
en_de Dev loss: 0.8846 r:0.1985
en_zh Dev loss: 0.7809 r:0.4518
ro_en Dev loss: 0.3636 r:0.8211
et_en Dev loss: 0.4613 r:0.6699
si_en Dev loss: 0.9140 r:0.5548
ne_en Dev loss: 0.6074 r:0.7247
ru_en Dev loss: 0.4738 r:0.7272
Current avg r:0.5926 Best avg r: 0.6297
04:50:56,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:52:26,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:53:57,127 root INFO Epoch 7 Global steps: 77700 Train loss: 0.2248
en_de Dev loss: 0.8864 r:0.2055
en_zh Dev loss: 0.8151 r:0.4493
ro_en Dev loss: 0.3757 r:0.8178
et_en Dev loss: 0.4623 r:0.6609
si_en Dev loss: 0.9603 r:0.5480
ne_en Dev loss: 0.6126 r:0.7213
ru_en Dev loss: 0.5246 r:0.7133
Current avg r:0.5880 Best avg r: 0.6297
04:58:27,751 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:59:58,62 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:01:28,332 root INFO Epoch 7 Global steps: 78400 Train loss: 0.2211
en_de Dev loss: 0.9344 r:0.2114
en_zh Dev loss: 0.9020 r:0.4454
ro_en Dev loss: 0.4228 r:0.8122
et_en Dev loss: 0.4930 r:0.6654
si_en Dev loss: 0.9845 r:0.5515
ne_en Dev loss: 0.7165 r:0.7207
ru_en Dev loss: 0.5518 r:0.7209
Current avg r:0.5897 Best avg r: 0.6297
05:05:59,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:07:30,200 root INFO 
id:ru_en cur r: 0.7570 best r: 0.7570
05:07:30,200 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:09:00,727 root INFO Epoch 7 Global steps: 79100 Train loss: 0.2228
en_de Dev loss: 0.8779 r:0.2166
en_zh Dev loss: 0.8049 r:0.4430
ro_en Dev loss: 0.3374 r:0.8209
et_en Dev loss: 0.4566 r:0.6787
si_en Dev loss: 0.8369 r:0.5625
ne_en Dev loss: 0.5490 r:0.7220
ru_en Dev loss: 0.4044 r:0.7530
Current avg r:0.5995 Best avg r: 0.6297
05:13:32,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:15:02,784 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:16:33,245 root INFO Epoch 7 Global steps: 79800 Train loss: 0.2168
en_de Dev loss: 0.9039 r:0.2178
en_zh Dev loss: 0.9291 r:0.4148
ro_en Dev loss: 0.4316 r:0.8101
et_en Dev loss: 0.5068 r:0.6462
si_en Dev loss: 1.1538 r:0.5270
ne_en Dev loss: 0.8345 r:0.7163
ru_en Dev loss: 0.5685 r:0.6973
Current avg r:0.5756 Best avg r: 0.6297
05:21:04,977 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:22:35,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:24:05,639 root INFO Epoch 7 Global steps: 80500 Train loss: 0.2231
en_de Dev loss: 0.8843 r:0.2257
en_zh Dev loss: 0.8238 r:0.4290
ro_en Dev loss: 0.3668 r:0.8211
et_en Dev loss: 0.4667 r:0.6630
si_en Dev loss: 0.9147 r:0.5578
ne_en Dev loss: 0.6078 r:0.7277
ru_en Dev loss: 0.5059 r:0.7185
Current avg r:0.5918 Best avg r: 0.6297
05:28:36,398 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:30:06,734 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:31:37,81 root INFO Epoch 7 Global steps: 81200 Train loss: 0.2164
en_de Dev loss: 0.8850 r:0.2241
en_zh Dev loss: 0.8548 r:0.4503
ro_en Dev loss: 0.3894 r:0.8235
et_en Dev loss: 0.5072 r:0.6664
si_en Dev loss: 0.9410 r:0.5576
ne_en Dev loss: 0.6063 r:0.7295
ru_en Dev loss: 0.5043 r:0.7216
Current avg r:0.5962 Best avg r: 0.6297
05:36:08,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:37:39,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:39:09,723 root INFO Epoch 7 Global steps: 81900 Train loss: 0.2206
en_de Dev loss: 0.8877 r:0.2208
en_zh Dev loss: 0.8374 r:0.4455
ro_en Dev loss: 0.3717 r:0.8202
et_en Dev loss: 0.4904 r:0.6551
si_en Dev loss: 0.8979 r:0.5539
ne_en Dev loss: 0.5913 r:0.7200
ru_en Dev loss: 0.4854 r:0.7291
Current avg r:0.5921 Best avg r: 0.6297
05:43:40,834 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:45:11,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:46:41,722 root INFO Epoch 7 Global steps: 82600 Train loss: 0.2209
en_de Dev loss: 0.9061 r:0.1925
en_zh Dev loss: 0.8271 r:0.4509
ro_en Dev loss: 0.3585 r:0.8183
et_en Dev loss: 0.4990 r:0.6578
si_en Dev loss: 0.8346 r:0.5584
ne_en Dev loss: 0.5504 r:0.7088
ru_en Dev loss: 0.4810 r:0.7225
Current avg r:0.5870 Best avg r: 0.6297
05:51:13,542 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:52:43,974 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:54:14,299 root INFO Epoch 7 Global steps: 83300 Train loss: 0.2216
en_de Dev loss: 0.8776 r:0.2206
en_zh Dev loss: 0.7598 r:0.4626
ro_en Dev loss: 0.3232 r:0.8215
et_en Dev loss: 0.4718 r:0.6701
si_en Dev loss: 0.7482 r:0.5665
ne_en Dev loss: 0.5254 r:0.7160
ru_en Dev loss: 0.4327 r:0.7342
Current avg r:0.5988 Best avg r: 0.6297
05:58:45,848 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:00:16,292 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:01:46,732 root INFO Epoch 7 Global steps: 84000 Train loss: 0.2192
en_de Dev loss: 0.8836 r:0.2452
en_zh Dev loss: 0.8311 r:0.4689
ro_en Dev loss: 0.3911 r:0.8213
et_en Dev loss: 0.4775 r:0.6682
si_en Dev loss: 0.9426 r:0.5611
ne_en Dev loss: 0.6444 r:0.7222
ru_en Dev loss: 0.5212 r:0.7262
Current avg r:0.6019 Best avg r: 0.6297
06:06:20,109 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:07:50,573 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:09:21,22 root INFO Epoch 8 Global steps: 84700 Train loss: 0.2006
en_de Dev loss: 0.9015 r:0.2137
en_zh Dev loss: 0.8701 r:0.4355
ro_en Dev loss: 0.3737 r:0.8207
et_en Dev loss: 0.4680 r:0.6561
si_en Dev loss: 0.9012 r:0.5496
ne_en Dev loss: 0.5625 r:0.7260
ru_en Dev loss: 0.5039 r:0.7173
Current avg r:0.5884 Best avg r: 0.6297
06:13:52,493 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:15:22,863 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:16:53,181 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1959
en_de Dev loss: 0.9067 r:0.2230
en_zh Dev loss: 0.8475 r:0.4462
ro_en Dev loss: 0.3792 r:0.8218
et_en Dev loss: 0.5007 r:0.6640
si_en Dev loss: 0.8648 r:0.5609
ne_en Dev loss: 0.5857 r:0.7221
ru_en Dev loss: 0.4970 r:0.7220
Current avg r:0.5943 Best avg r: 0.6297
06:21:23,931 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:22:54,289 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:24:24,647 root INFO Epoch 8 Global steps: 86100 Train loss: 0.2147
en_de Dev loss: 0.9216 r:0.2196
en_zh Dev loss: 0.8509 r:0.4502
ro_en Dev loss: 0.3927 r:0.8171
et_en Dev loss: 0.5178 r:0.6605
si_en Dev loss: 0.9034 r:0.5554
ne_en Dev loss: 0.5433 r:0.7200
ru_en Dev loss: 0.4685 r:0.7375
Current avg r:0.5943 Best avg r: 0.6297
06:28:55,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:30:25,664 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:31:55,984 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1938
en_de Dev loss: 0.9116 r:0.1961
en_zh Dev loss: 0.8246 r:0.4309
ro_en Dev loss: 0.3762 r:0.8205
et_en Dev loss: 0.4599 r:0.6563
si_en Dev loss: 0.8674 r:0.5587
ne_en Dev loss: 0.6106 r:0.7173
ru_en Dev loss: 0.5273 r:0.7089
Current avg r:0.5841 Best avg r: 0.6297
06:36:27,32 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:37:57,443 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:39:27,906 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1978
en_de Dev loss: 0.9128 r:0.2011
en_zh Dev loss: 0.7991 r:0.4431
ro_en Dev loss: 0.3407 r:0.8187
et_en Dev loss: 0.4861 r:0.6635
si_en Dev loss: 0.8011 r:0.5632
ne_en Dev loss: 0.5965 r:0.7120
ru_en Dev loss: 0.4248 r:0.7359
Current avg r:0.5911 Best avg r: 0.6297
06:43:59,410 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:45:29,825 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:47:00,265 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1857
en_de Dev loss: 0.9354 r:0.1879
en_zh Dev loss: 0.8932 r:0.4355
ro_en Dev loss: 0.4089 r:0.8174
et_en Dev loss: 0.4834 r:0.6521
si_en Dev loss: 0.9482 r:0.5471
ne_en Dev loss: 0.6976 r:0.7171
ru_en Dev loss: 0.5377 r:0.7149
Current avg r:0.5817 Best avg r: 0.6297
06:51:30,874 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:53:01,184 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:54:31,519 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1926
en_de Dev loss: 0.9207 r:0.2021
en_zh Dev loss: 0.8537 r:0.4448
ro_en Dev loss: 0.3844 r:0.8221
et_en Dev loss: 0.4788 r:0.6622
si_en Dev loss: 0.9113 r:0.5619
ne_en Dev loss: 0.6333 r:0.7223
ru_en Dev loss: 0.4752 r:0.7374
Current avg r:0.5933 Best avg r: 0.6297
06:59:02,183 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:00:32,549 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:02:02,894 root INFO Epoch 8 Global steps: 89600 Train loss: 0.2013
en_de Dev loss: 0.9031 r:0.2143
en_zh Dev loss: 0.8251 r:0.4444
ro_en Dev loss: 0.3858 r:0.8229
et_en Dev loss: 0.5172 r:0.6659
si_en Dev loss: 0.8530 r:0.5610
ne_en Dev loss: 0.5728 r:0.7222
ru_en Dev loss: 0.4682 r:0.7297
Current avg r:0.5943 Best avg r: 0.6297
07:06:33,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:08:04,2 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:09:34,451 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1840
en_de Dev loss: 0.8882 r:0.2133
en_zh Dev loss: 0.8096 r:0.4422
ro_en Dev loss: 0.3571 r:0.8234
et_en Dev loss: 0.5289 r:0.6646
si_en Dev loss: 0.8301 r:0.5587
ne_en Dev loss: 0.5252 r:0.7139
ru_en Dev loss: 0.4200 r:0.7422
Current avg r:0.5940 Best avg r: 0.6297
07:14:05,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:15:36,361 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:17:06,731 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1933
en_de Dev loss: 0.8979 r:0.2078
en_zh Dev loss: 0.8052 r:0.4430
ro_en Dev loss: 0.3439 r:0.8220
et_en Dev loss: 0.4835 r:0.6653
si_en Dev loss: 0.8077 r:0.5690
ne_en Dev loss: 0.5348 r:0.7200
ru_en Dev loss: 0.4742 r:0.7286
Current avg r:0.5937 Best avg r: 0.6297
07:21:37,867 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:23:08,258 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:24:38,532 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1904
en_de Dev loss: 0.9004 r:0.2039
en_zh Dev loss: 0.7771 r:0.4493
ro_en Dev loss: 0.3490 r:0.8163
et_en Dev loss: 0.4967 r:0.6699
si_en Dev loss: 0.8402 r:0.5599
ne_en Dev loss: 0.5723 r:0.7209
ru_en Dev loss: 0.4659 r:0.7369
Current avg r:0.5939 Best avg r: 0.6297
07:29:09,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:30:39,650 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:32:09,936 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1928
en_de Dev loss: 0.8983 r:0.1965
en_zh Dev loss: 0.7909 r:0.4451
ro_en Dev loss: 0.3492 r:0.8192
et_en Dev loss: 0.4872 r:0.6608
si_en Dev loss: 0.8801 r:0.5521
ne_en Dev loss: 0.5849 r:0.7177
ru_en Dev loss: 0.4787 r:0.7225
Current avg r:0.5877 Best avg r: 0.6297
07:36:40,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:38:11,413 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:39:41,706 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1939
en_de Dev loss: 0.9057 r:0.1773
en_zh Dev loss: 0.8302 r:0.4437
ro_en Dev loss: 0.3953 r:0.8150
et_en Dev loss: 0.4897 r:0.6563
si_en Dev loss: 1.0008 r:0.5469
ne_en Dev loss: 0.6498 r:0.7171
ru_en Dev loss: 0.5391 r:0.7108
Current avg r:0.5810 Best avg r: 0.6297
07:44:12,474 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:45:42,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:47:13,65 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1887
en_de Dev loss: 0.8951 r:0.1996
en_zh Dev loss: 0.8464 r:0.4456
ro_en Dev loss: 0.4060 r:0.8197
et_en Dev loss: 0.4920 r:0.6565
si_en Dev loss: 1.0018 r:0.5515
ne_en Dev loss: 0.6468 r:0.7131
ru_en Dev loss: 0.5302 r:0.7215
Current avg r:0.5868 Best avg r: 0.6297
07:51:44,281 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:53:14,677 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:54:45,37 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1829
en_de Dev loss: 0.9245 r:0.2010
en_zh Dev loss: 0.7887 r:0.4622
ro_en Dev loss: 0.3689 r:0.8199
et_en Dev loss: 0.4869 r:0.6672
si_en Dev loss: 0.8674 r:0.5682
ne_en Dev loss: 0.6162 r:0.7174
ru_en Dev loss: 0.4817 r:0.7399
Current avg r:0.5965 Best avg r: 0.6297
07:59:17,607 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:00:48,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:02:18,826 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1763
en_de Dev loss: 0.9353 r:0.1976
en_zh Dev loss: 0.8633 r:0.4534
ro_en Dev loss: 0.3892 r:0.8166
et_en Dev loss: 0.5068 r:0.6437
si_en Dev loss: 1.0625 r:0.5387
ne_en Dev loss: 0.6721 r:0.7116
ru_en Dev loss: 0.5440 r:0.7279
Current avg r:0.5842 Best avg r: 0.6297
08:06:49,530 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:08:19,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:09:50,393 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1669
en_de Dev loss: 0.9039 r:0.1835
en_zh Dev loss: 0.7975 r:0.4478
ro_en Dev loss: 0.3605 r:0.8133
et_en Dev loss: 0.4727 r:0.6559
si_en Dev loss: 0.8962 r:0.5470
ne_en Dev loss: 0.5050 r:0.7171
ru_en Dev loss: 0.4698 r:0.7360
Current avg r:0.5858 Best avg r: 0.6297
08:14:21,613 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:15:51,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:17:22,316 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1633
en_de Dev loss: 0.9282 r:0.1910
en_zh Dev loss: 0.8193 r:0.4472
ro_en Dev loss: 0.3534 r:0.8150
et_en Dev loss: 0.5036 r:0.6701
si_en Dev loss: 0.7927 r:0.5659
ne_en Dev loss: 0.4840 r:0.7193
ru_en Dev loss: 0.4411 r:0.7470
Current avg r:0.5937 Best avg r: 0.6297
08:21:52,921 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:23:23,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:24:53,583 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1728
en_de Dev loss: 0.9213 r:0.2018
en_zh Dev loss: 0.8305 r:0.4550
ro_en Dev loss: 0.3810 r:0.8148
et_en Dev loss: 0.4786 r:0.6591
si_en Dev loss: 0.9174 r:0.5585
ne_en Dev loss: 0.6153 r:0.7192
ru_en Dev loss: 0.4883 r:0.7354
Current avg r:0.5920 Best avg r: 0.6297
08:29:24,299 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:30:54,662 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:32:25,12 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1758
en_de Dev loss: 0.9020 r:0.2065
en_zh Dev loss: 0.8091 r:0.4593
ro_en Dev loss: 0.3693 r:0.8156
et_en Dev loss: 0.4848 r:0.6699
si_en Dev loss: 0.8658 r:0.5604
ne_en Dev loss: 0.6260 r:0.7098
ru_en Dev loss: 0.4530 r:0.7444
Current avg r:0.5951 Best avg r: 0.6297
08:36:56,566 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:38:26,983 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:39:57,438 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1628
en_de Dev loss: 0.9049 r:0.2148
en_zh Dev loss: 0.8090 r:0.4712
ro_en Dev loss: 0.3603 r:0.8198
et_en Dev loss: 0.4955 r:0.6764
si_en Dev loss: 0.8033 r:0.5691
ne_en Dev loss: 0.5297 r:0.7191
ru_en Dev loss: 0.4438 r:0.7454
Current avg r:0.6022 Best avg r: 0.6297
08:44:28,973 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:45:59,370 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:47:29,752 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1680
en_de Dev loss: 0.8931 r:0.1945
en_zh Dev loss: 0.8383 r:0.4506
ro_en Dev loss: 0.4213 r:0.8158
et_en Dev loss: 0.4930 r:0.6504
si_en Dev loss: 1.0160 r:0.5497
ne_en Dev loss: 0.7930 r:0.7068
ru_en Dev loss: 0.5742 r:0.7119
Current avg r:0.5828 Best avg r: 0.6297
08:52:01,420 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:53:31,837 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:55:02,231 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1751
en_de Dev loss: 0.8945 r:0.2120
en_zh Dev loss: 0.8221 r:0.4687
ro_en Dev loss: 0.3790 r:0.8146
et_en Dev loss: 0.5159 r:0.6604
si_en Dev loss: 0.8391 r:0.5645
ne_en Dev loss: 0.5698 r:0.7086
ru_en Dev loss: 0.4777 r:0.7325
Current avg r:0.5945 Best avg r: 0.6297
08:59:34,153 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:01:04,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:02:35,136 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1764
en_de Dev loss: 0.9273 r:0.2025
en_zh Dev loss: 0.8369 r:0.4654
ro_en Dev loss: 0.3873 r:0.8187
et_en Dev loss: 0.4900 r:0.6658
si_en Dev loss: 0.9460 r:0.5550
ne_en Dev loss: 0.6246 r:0.7149
ru_en Dev loss: 0.5076 r:0.7357
Current avg r:0.5940 Best avg r: 0.6297
09:07:06,791 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:08:37,178 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:10:07,594 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1729
en_de Dev loss: 0.8796 r:0.2124
en_zh Dev loss: 0.7870 r:0.4511
ro_en Dev loss: 0.3424 r:0.8193
et_en Dev loss: 0.4646 r:0.6554
si_en Dev loss: 0.9217 r:0.5446
ne_en Dev loss: 0.6147 r:0.7172
ru_en Dev loss: 0.4737 r:0.7168
Current avg r:0.5881 Best avg r: 0.6297
09:14:39,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:16:09,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:17:40,34 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1663
en_de Dev loss: 0.9005 r:0.1991
en_zh Dev loss: 0.7935 r:0.4565
ro_en Dev loss: 0.3495 r:0.8169
et_en Dev loss: 0.4973 r:0.6707
si_en Dev loss: 0.8639 r:0.5589
ne_en Dev loss: 0.5397 r:0.7141
ru_en Dev loss: 0.4261 r:0.7490
Current avg r:0.5950 Best avg r: 0.6297
09:22:11,910 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:23:42,375 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:25:13,76 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1659
en_de Dev loss: 0.9162 r:0.2017
en_zh Dev loss: 0.8125 r:0.4610
ro_en Dev loss: 0.3656 r:0.8192
et_en Dev loss: 0.4738 r:0.6682
si_en Dev loss: 0.8955 r:0.5528
ne_en Dev loss: 0.6197 r:0.7159
ru_en Dev loss: 0.4566 r:0.7416
Current avg r:0.5943 Best avg r: 0.6297
09:29:44,872 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:31:15,353 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:32:45,831 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1664
en_de Dev loss: 0.9094 r:0.1883
en_zh Dev loss: 0.7771 r:0.4624
ro_en Dev loss: 0.3504 r:0.8185
et_en Dev loss: 0.4401 r:0.6671
si_en Dev loss: 0.8863 r:0.5580
ne_en Dev loss: 0.6141 r:0.7136
ru_en Dev loss: 0.4446 r:0.7453
Current avg r:0.5933 Best avg r: 0.6297
09:37:17,670 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:38:48,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:40:18,536 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1704
en_de Dev loss: 0.9116 r:0.2023
en_zh Dev loss: 0.8098 r:0.4508
ro_en Dev loss: 0.3382 r:0.8179
et_en Dev loss: 0.4626 r:0.6688
si_en Dev loss: 0.8613 r:0.5557
ne_en Dev loss: 0.6081 r:0.7121
ru_en Dev loss: 0.4329 r:0.7475
Current avg r:0.5936 Best avg r: 0.6297
09:44:49,387 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:46:19,756 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:47:50,150 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1769
en_de Dev loss: 0.9218 r:0.2026
en_zh Dev loss: 0.7711 r:0.4680
ro_en Dev loss: 0.3536 r:0.8134
et_en Dev loss: 0.4823 r:0.6618
si_en Dev loss: 0.8986 r:0.5473
ne_en Dev loss: 0.5981 r:0.7220
ru_en Dev loss: 0.4292 r:0.7426
Current avg r:0.5940 Best avg r: 0.6297
09:52:22,418 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:52,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:55:23,67 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1493
en_de Dev loss: 0.9050 r:0.1833
en_zh Dev loss: 0.7541 r:0.4602
ro_en Dev loss: 0.3259 r:0.8204
et_en Dev loss: 0.4463 r:0.6752
si_en Dev loss: 0.8792 r:0.5511
ne_en Dev loss: 0.5827 r:0.7283
ru_en Dev loss: 0.4264 r:0.7471
Current avg r:0.5951 Best avg r: 0.6297
09:59:54,840 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:01:25,290 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:55,737 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1492
en_de Dev loss: 0.9032 r:0.1777
en_zh Dev loss: 0.7525 r:0.4651
ro_en Dev loss: 0.3327 r:0.8201
et_en Dev loss: 0.4543 r:0.6771
si_en Dev loss: 0.8266 r:0.5647
ne_en Dev loss: 0.4918 r:0.7274
ru_en Dev loss: 0.4106 r:0.7559
Current avg r:0.5983 Best avg r: 0.6297
10:07:26,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:56,708 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:10:27,66 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1519
en_de Dev loss: 0.9074 r:0.1824
en_zh Dev loss: 0.8306 r:0.4449
ro_en Dev loss: 0.3668 r:0.8158
et_en Dev loss: 0.4756 r:0.6666
si_en Dev loss: 0.8981 r:0.5499
ne_en Dev loss: 0.6601 r:0.7213
ru_en Dev loss: 0.4608 r:0.7363
Current avg r:0.5882 Best avg r: 0.6297
10:14:57,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:16:27,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:58,284 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1510
en_de Dev loss: 0.9019 r:0.1843
en_zh Dev loss: 0.7906 r:0.4521
ro_en Dev loss: 0.3467 r:0.8164
et_en Dev loss: 0.4846 r:0.6642
si_en Dev loss: 0.9213 r:0.5447
ne_en Dev loss: 0.6127 r:0.7122
ru_en Dev loss: 0.4138 r:0.7524
Current avg r:0.5895 Best avg r: 0.6297
10:22:28,890 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:23:59,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:25:29,636 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1550
en_de Dev loss: 0.9071 r:0.1894
en_zh Dev loss: 0.8283 r:0.4520
ro_en Dev loss: 0.4016 r:0.8092
et_en Dev loss: 0.4944 r:0.6491
si_en Dev loss: 1.0834 r:0.5339
ne_en Dev loss: 0.8562 r:0.7112
ru_en Dev loss: 0.4767 r:0.7343
Current avg r:0.5828 Best avg r: 0.6297
10:30:00,445 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:31:30,831 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:33:01,192 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1514
en_de Dev loss: 0.9124 r:0.1871
en_zh Dev loss: 0.8147 r:0.4477
ro_en Dev loss: 0.3612 r:0.8122
et_en Dev loss: 0.4742 r:0.6582
si_en Dev loss: 0.8861 r:0.5464
ne_en Dev loss: 0.5908 r:0.7098
ru_en Dev loss: 0.4603 r:0.7325
Current avg r:0.5848 Best avg r: 0.6297
10:37:32,213 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:39:02,553 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:40:32,908 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1540
en_de Dev loss: 0.9155 r:0.1755
en_zh Dev loss: 0.8298 r:0.4389
ro_en Dev loss: 0.3658 r:0.8128
et_en Dev loss: 0.4809 r:0.6455
si_en Dev loss: 0.9372 r:0.5352
ne_en Dev loss: 0.6843 r:0.7116
ru_en Dev loss: 0.5051 r:0.7131
Current avg r:0.5761 Best avg r: 0.6297
10:45:03,602 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:46:33,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:48:04,297 root INFO Epoch 10 Global steps: 110600 Train loss: 0.1568
en_de Dev loss: 0.9350 r:0.1945
en_zh Dev loss: 0.7910 r:0.4614
ro_en Dev loss: 0.3545 r:0.8126
et_en Dev loss: 0.4703 r:0.6620
si_en Dev loss: 0.8374 r:0.5477
ne_en Dev loss: 0.5714 r:0.7153
ru_en Dev loss: 0.4679 r:0.7348
Current avg r:0.5898 Best avg r: 0.6297
